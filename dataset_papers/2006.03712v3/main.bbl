\begin{thebibliography}{10}

\bibitem{HG-EF-BP-MC:18}
H.~Gouk, E.~Frank, B.~Pfahringer, and M.~Cree.
\newblock Regularisation of neural networks by enforcing lipschitz continuity.
\newblock {\em arXiv preprint arXiv:1804.04368}, 2018.

\bibitem{CF-JC-BA-AO:18}
C.~Finlay, J.~Calder, B.~Abbasi, and A.~Oberman.
\newblock Lipschitz regularized deep neural networks generalize and are
  adversarially robust.
\newblock {\em arXiv preprint arXiv:1808.09540}, 2018.

\bibitem{AK-IG-SB:16b}
A.~Kurakin, I.~Goodfellow, and S.~Bengio.
\newblock Adversarial examples in the physical world.
\newblock {\em arXiv preprint arXiv:1607.02533}, 2016.

\bibitem{EW-ZK:18}
E.~Wong and Z.~Kolter.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope.
\newblock In {\em {I}nternational {C}onference on {M}achine {L}earning}, pages
  5286--5295, 2018.

\bibitem{AR-JS-PL:18}
A.~Raghunathan, J.~Steinhardt, and P.~Liang.
\newblock Certified defenses against adversarial examples.
\newblock In {\em International Conference on Learning Representations},
  Vancouver, Canada, May 2018.

\bibitem{AI-SS-DT-LE-BT-AM:19b}
A.~Ilyas, S.~Santurkar, D.~Tsipras, L.~Engstrom, B.~Tran, and A.~Madry.
\newblock Adversarial examples are not bugs, they are features.
\newblock In {\em Advances in {N}eural {I}nformation {P}rocessing {S}ystems},
  pages 125--136, 2019.

\bibitem{AF-SMD-PF:16}
A.~Fawzi, S.~M. Dezfooli, and P.~Frossard.
\newblock Robustness of classifiers: from adversarial to random noise.
\newblock In {\em {A}dvances in {N}eural {I}nformation {P}rocessing {S}ystems},
  pages 1632--1640, 2016.

\bibitem{CS-WZ-IS-JB-DE-IG-RF:14}
C.~Szegedy, W.~Zaremba, I.~Sutskever, J.~Bruna, D.~Erhan, I.~Goodfellow, and
  R.~Fergus.
\newblock Intriguing properties of neural networks.
\newblock In {\em International Conference on Learning Representations}, Banff,
  Canada, Apr 2014.

\bibitem{FT-AK-NP-IG-DB-PM:17}
F.~Tram{\`e}r, A.~Kurakin, N.~Papernot, I.~Goodfellow, D.~Boneh, and
  P.~McDaniel.
\newblock Ensemble adversarial training: {A}ttacks and defenses.
\newblock {\em arXiv preprint arXiv:1705.07204}, 2017.

\bibitem{DK-PME-VAN-SSA:19}
D.~Kuhn, P.~M. Esfahani, V.~A. Nguyen, and S.~S. Abadeh.
\newblock Wasserstein distributionally robust optimization: {T}heory and
  applications in machine learning.
\newblock In {\em {O}perations {R}esearch \& {M}anagement {S}cience in the
  {A}ge of {A}nalytics}, pages 130--166. INFORMS, 2019.

\bibitem{PLB-DJF-MJT:17}
P.~L. Bartlett, D.~J. Foster, and M.~J. Telgarsky.
\newblock Spectrally-normalized margin bounds for neural networks.
\newblock In {\em Advances in {N}eural {I}nformation {P}rocessing {S}ystems},
  pages 6240--6249, 2017.

\bibitem{OB-YI-LL-DV-AN-AC:16}
O.~Bastani, Y.~Ioannou, L.~Lampropoulos, D.~Vytiniotis, A.~Nori, and
  A.~Criminisi.
\newblock Measuring neural net robustness with constraints.
\newblock In {\em Advances in {N}eural {I}nformation {P}rocessing {S}ystems},
  pages 2613--2621, 2016.

\bibitem{LW-HZ-HC-ZS-CJH-LD-DB-ID:18}
L.~Weng, H.~Zhang, H.~Chen, Z.~Song, C.~J. Hsieh, L.~Daniel, D.~Boning, and
  I.~Dhillon.
\newblock Towards fast computation of certified robustness for {ReLU} networks.
\newblock In {\em {I}nternational {C}onference on {M}achine {L}earning}, pages
  5276--5285, 2018.

\bibitem{SZ-YS-TL-IG:16}
S.~Zheng, Y.~Song, T.~Leung, and I.~Goodfellow.
\newblock Improving the robustness of deep neural networks via stability
  training.
\newblock In {\em {IEEE} {C}onference on {C}omputer {V}ision and {P}attern
  {R}ecognition}, pages 4480--4488, 2016.

\bibitem{TWW-HZ-PYC-JY-DS-YG-CJH-LD:18}
T.~W. Weng, H.~Zhang, P.~Y. Chen, J.~Yi, D.~Su, Y.~Gao, C.~J. Hsieh, and
  L.~Daniel.
\newblock Evaluating the robustness of neural networks: {A}n extreme value
  theory approach.
\newblock {\em arXiv preprint arXiv:1801.10578}, 2018.

\bibitem{HZ-TWW-PYC-CJH-LD:18}
H.~Zhang, T.~W. Weng, P.~Y. Chen, C.~J. Hsieh, and L.~Daniel.
\newblock Efficient neural network robustness certification with general
  activation functions.
\newblock In {\em Advances in {N}eural {I}nformation {P}rocessing {S}ystems},
  pages 4939--4948, 2018.

\bibitem{JS-RG-GS-MR:17}
J.~Sokoli{\'c}, R.~Giryes, G.~Sapiro, and M.~Rodrigues.
\newblock Robust large margin deep neural networks.
\newblock {\em IEEE Transactions on Signal Processing}, 65(16):4265--4280,
  2017.

\bibitem{PP-AK-JB-FA:20}
P.~Pauli, A.~Koch, J.~Berberich, and F.~Allg{\"o}wer.
\newblock Training robust neural networks using {L}ipschitz bounds.
\newblock {\em arXiv preprint arXiv:2005.02929}, 2020.

\bibitem{RB-MS-DZ:17}
R.~Balan, M.~Singh, and D.~Zou.
\newblock Lipschitz properties for deep convolutional networks.
\newblock {\em arXiv preprint arXiv:1701.05217}, 2017.

\bibitem{CA-JL-RG:18}
C.~Anil, J.~Lucas, and R.~Grosse.
\newblock Sorting out {L}ipschitz function approximation.
\newblock {\em arXiv preprint arXiv:1811.05381}, 2018.

\bibitem{QL-SH-CA-JL-RG-JHJ:19}
Q.~Li, S.~Haque, C.~Anil, J.~Lucas, R.~Grosse, and J.~H. Jacobsen.
\newblock Preventing gradient attenuation in {L}ipschitz constrained
  convolutional networks.
\newblock In {\em {A}dvances in {N}eural {I}nformation {P}rocessing {S}ystems},
  pages 15364--15376, 2019.

\bibitem{AV-KS:18}
A.~Virmaux and K.~Scaman.
\newblock Lipschitz regularity of deep neural networks: analysis and efficient
  estimation.
\newblock In {\em Advances in {N}eural {I}nformation {P}rocessing {S}ystems},
  pages 3835--3844, 2018.

\bibitem{MF-AR-HH-MM-GJP:19}
M.~Fazlyab, A.~Robey, H.~Hassani, M.~Morari, and G.~J. Pappas.
\newblock Efficient and accurate estimation of {L}ipschitz constants for deep
  neural networks.
\newblock In {\em Advances in {N}eural {I}nformation {P}rocessing {S}ystems},
  pages 11423--11434, 2019.

\bibitem{PLC-JCP:19}
P.~L. Combettes and J.~C. Pesquet.
\newblock Lipschitz certificates for neural network structures driven by
  averaged activation operators.
\newblock {\em arXiv preprint arXiv:1903.01014}, 2019.

\bibitem{DT-SS-LE-AT-AM:19}
D.~Tsipras, S.~Santurkar, L.~Engstrom, A.~Turner, and A.~Madry.
\newblock Robustness may be at odds with accuracy.
\newblock In {\em International Conference on Learning Representations}, Ernest
  N. Morial Convention Center, NO, USA, May 2019.

\bibitem{AJ-MS-HH:20}
A.~Javanmard, M.~Soltanolkotabi, and H.~Hassani.
\newblock Precise tradeoffs in adversarial training for linear regression.
\newblock {\em arXiv preprint arXiv:2002.10477}, 2020.

\bibitem{AAALM-VK-FP:19b}
A.~A.~Al Makdah, V.~Katewa, and F.~Pasqualetti.
\newblock Accuracy prevents robustness in perception-based control.
\newblock In {\em {A}merican {C}ontrol {C}onference}, Denver, CO, USA, July
  2020.

\bibitem{AAALM-VK-FP:19}
A.~A.~Al Makdah, V.~Katewa, and F.~Pasqualetti.
\newblock A fundamental performance limitation for adversarial classification.
\newblock {\em IEEE Control Systems Letters}, 4(1):169--174, 2019.

\bibitem{SG-HW-HY-CY-ZW-JL:19}
S.~Gui, H.~Wang, H.~Yang, C.~Yu, Z.~Wang, and J.~Liu.
\newblock Model compression with adversarial robustness: A unified optimization
  framework.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1283--1294, 2019.

\bibitem{DS-MH-BS:19}
D.~Stutz, M.~Hein, and B.~Schiele.
\newblock Disentangling adversarial robustness and generalization.
\newblock In {\em Proc. of the {IEEE} {C}onference on {C}omputer {V}ision and
  {P}attern {R}ecognition}, pages 6976--6987, 2019.

\bibitem{SY-KX-SL-HC-JHL-HZ-AZ-KM-YW-XL:19}
S.~Ye, K.~Xu, S.~Liu, H.~Cheng, J.~H. Lambrechts, H.~Zhang, A.~Zhou, K.~Ma,
  Y.~Wang, and X.~Lin.
\newblock Adversarial robustness vs. model compression, or both.
\newblock In {\em {IEEE} {I}nternational {C}onference on {C}omputer {V}ision},
  volume~2, pages 111--120, 2019.

\bibitem{PN:19}
P.~Nakkiran.
\newblock Adversarial robustness may be at odds with simplicity.
\newblock {\em arXiv preprint arXiv:1901.00532}, 2019.

\bibitem{BN-SM-AB-VT-MS-SLJ-IM:18}
B.~Neal, S.~Mittal, A.~Baratin, V.~Tantia, M.~Scicluna, S.~L. Julien, and
  I.~Mitliagkas.
\newblock A modern take on the bias-variance tradeoff in neural networks.
\newblock {\em arXiv preprint arXiv:1810.08591}, 2018.

\bibitem{CL-MW-DPK:17}
C.~Louizos, M.~Welling, and D.~P. Kingma.
\newblock Learning sparse neural networks through ${L}_0$ regularization.
\newblock {\em arXiv preprint arXiv:1712.01312}, 2017.

\bibitem{LCE:98}
L.C. Evans.
\newblock {\em Partial differential equations}.
\newblock American Mathematical Society, 1998.

\bibitem{KA-HA-LH-HU:58}
K.~Arrow, H.~Azawa, L.~Hurwicz, and H.~Uzawa.
\newblock {\em Studies in linear and non-linear programming}, volume~2.
\newblock {S}tanford {U}niversity {P}ress, 1958.

\bibitem{PB:08}
P.~Billingsley.
\newblock {\em Probability and measure}.
\newblock John {W}iley \& {S}ons, 2008.

\bibitem{MB-PN:08}
M.~Belkin and P.~Niyogi.
\newblock Towards a theoretical foundation for laplacian-based manifold
  methods.
\newblock {\em Journal of {C}omputer and {S}ystem {S}ciences},
  74(8):1289--1308, 2008.

\bibitem{AEA-XC-AR-MW-MIJ:16}
A.~El Alaoui, X.~Cheng, A.~Ramdas, M.~Wainwright, and M.~I. Jordan.
\newblock Asymptotic behavior of $\ell_p$-based {L}aplacian regularization in
  semi-supervised learning.
\newblock In {\em Conference on {L}earning {T}heory}, pages 879--906, 2016.

\bibitem{RK-AR-SS-DAS:15}
R.~Kyng, A.~Rao, S.~Sachdeva, and D.~A. Spielman.
\newblock Algorithms for {L}ipschitz learning on graphs.
\newblock In {\em Conference on {L}earning {T}heory}, pages 1190--1223, 2015.

\bibitem{RKA-TZ:07}
R.~K. Ando and T.~Zhang.
\newblock Learning on graph with {L}aplacian regularization.
\newblock In {\em Advances in {N}eural {I}nformation {P}rocessing {S}ystems},
  pages 25--32, 2007.

\bibitem{JC:19}
J.~Calder.
\newblock Consistency of {L}ipschitz learning with infinite unlabeled data and
  finite labeled data.
\newblock {\em {SIAM} {J}ournal on {M}athematics of {D}ata {S}cience},
  1(4):780--812, 2019.

\bibitem{ALB-AF:12}
A.~L. Bertozzi and A.~Flenner.
\newblock Diffuse interface models on graphs for classification of high
  dimensional data.
\newblock {\em {M}ultiscale {M}odeling and {S}imulation}, 10(3):1090--1118,
  2012.

\bibitem{EM-TK-ALB:13}
E.~Merkurjev, T.~Kostic, and A.~L. Bertozzi.
\newblock An {MBO} scheme on graphs for classification and image processing.
\newblock {\em {SIAM} {J}ournal on {I}maging {S}ciences}, 6(4):1903--1930,
  2013.

\bibitem{YL-CC-CJCB:98}
Y.~LeCun, C.~Cortes, and C.~J.~C. Burges.
\newblock The {MNIST} database of handwritten digits.
\newblock {\em URL: http://yann.lecun.com/exdb/mnist}, 1998.

\bibitem{WR:64}
W.~Rudin.
\newblock {\em Principles of {M}athematical {A}nalysis}.
\newblock McGraw-{H}ill, {I}nc., 3 edition, 1964.

\bibitem{JFB-AS:13}
J.~F. Bonnans and A.~Shapiro.
\newblock {\em Perturbation analysis of optimization problems}.
\newblock Springer, 2013.

\bibitem{KY-EH:52}
K.~Yosida and E.~Hewitt.
\newblock Finitely additive measures.
\newblock {\em {T}ransactions of the {A}merican {M}athematical {S}ociety},
  72(1):46--66, 1952.

\end{thebibliography}
