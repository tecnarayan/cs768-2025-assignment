@inproceedings{fujimoto2019off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International conference on machine learning},
  pages={2052--2062},
  year={2019},
  organization={PMLR}
}


@inproceedings{ghasemipour2021emaq,
  title={Emaq: Expected-max q-learning operator for simple yet effective offline and online rl},
  author={Ghasemipour, Seyed Kamyar Seyed and Schuurmans, Dale and Gu, Shixiang Shane},
  booktitle={International Conference on Machine Learning},
  pages={3682--3691},
  year={2021},
  organization={PMLR}
}

@article{nair2020awac,
  title={Awac: Accelerating online reinforcement learning with offline datasets},
  author={Nair, Ashvin and Gupta, Abhishek and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.09359},
  year={2020}
}

@article{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{wu2019behavior,
  title={Behavior regularized offline reinforcement learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}


@article{fujimoto2021minimalist,
  title={A minimalist approach to offline reinforcement learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={20132--20145},
  year={2021}
}

@inproceedings{
wu2022supported,
title={Supported Policy Optimization for Offline Reinforcement Learning},
author={Jialong Wu and Haixu Wu and Zihan Qiu and Jianmin Wang and Mingsheng Long},
booktitle={Advances in Neural Information Processing Systems},
year={2022},
url={https://openreview.net/forum?id=KCXQ5HoM-fy}
}

@inproceedings{
li2022distancesensitive,
title={Distance-Sensitive Offline Reinforcement Learning},
author={Jianxiong Li and Xianyuan Zhan and Haoran Xu and Xiangyu Zhu and Jingjing Liu and Ya-Qin Zhang},
booktitle={Deep Reinforcement Learning Workshop NeurIPS 2022},
year={2022},
url={https://openreview.net/forum?id=9zI55TfUntm}
}

@article{brandfonbrener2021offline,
  title={Offline rl without off-policy evaluation},
  author={Brandfonbrener, David and Whitney, Will and Ranganath, Rajesh and Bruna, Joan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={4933--4946},
  year={2021}
}

@inproceedings{
kostrikov2022offline,
title={Offline Reinforcement Learning with Implicit Q-Learning},
author={Ilya Kostrikov and Ashvin Nair and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=68n2s9ZJWF8}
}

@inproceedings{bain1995framework,
  title={A Framework for Behavioural Cloning.},
  author={Bain, Michael and Sammut, Claude},
  booktitle={Machine Intelligence 15},
  pages={103--129},
  year={1995}
}

@inproceedings{
emmons2022rvs,
title={RvS: What is Essential for Offline {RL} via Supervised Learning?},
author={Scott Emmons and Benjamin Eysenbach and Ilya Kostrikov and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=S874XAIpkR-}
}

@article{chen2021decision,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={15084--15097},
  year={2021}
}

@article{janner2021offline,
  title={Offline reinforcement learning as one big sequence modeling problem},
  author={Janner, Michael and Li, Qiyang and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={1273--1286},
  year={2021}
}

@inproceedings{
ghosh2021learning,
title={Learning to Reach Goals via Iterated Supervised Learning},
author={Dibya Ghosh and Abhishek Gupta and Ashwin Reddy and Justin Fu and Coline Manon Devin and Benjamin Eysenbach and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=rALA0Xo6yNJ}
}

@inproceedings{
yang2022rethinking,
title={Rethinking Goal-Conditioned Supervised Learning and Its Connection to Offline {RL}},
author={Rui Yang and Yiming Lu and Wenzhe Li and Hao Sun and Meng Fang and Yali Du and Xiu Li and Lei Han and Chongjie Zhang},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=KJztlfGPdwW}
}

@inproceedings{
xu2022a,
title={A Policy-Guided Imitation Approach for Offline Reinforcement Learning},
author={Haoran Xu and Li Jiang and Jianxiong Li and Xianyuan Zhan},
booktitle={Advances in Neural Information Processing Systems},
year={2022},
url={https://openreview.net/forum?id=CKbqDtZnSc}
}

@article{wang2020critic,
  title={Critic regularized regression},
  author={Wang, Ziyu and Novikov, Alexander and Zolna, Konrad and Merel, Josh S and Springenberg, Jost Tobias and Reed, Scott E and Shahriari, Bobak and Siegel, Noah and Gulcehre, Caglar and Heess, Nicolas and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7768--7778},
  year={2020}
}

@article{brandfonbrener2021quantile,
  title={Quantile Filtered Imitation Learning},
  author={Brandfonbrener, David and Whitney, William F and Ranganath, Rajesh and Bruna, Joan},
  journal={arXiv preprint arXiv:2112.00950},
  year={2021}
}

@article{peng2019advantage,
  title={Advantage-weighted regression: Simple and scalable off-policy reinforcement learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}

@article{siegel2020keep,
  title={Keep doing what worked: Behavioral modelling priors for offline reinforcement learning},
  author={Siegel, Noah Y and Springenberg, Jost Tobias and Berkenkamp, Felix and Abdolmaleki, Abbas and Neunert, Michael and Lampe, Thomas and Hafner, Roland and Heess, Nicolas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:2002.08396},
  year={2020}
}

@article{wang2018exponentially,
  title={Exponentially weighted imitation learning for batched historical data},
  author={Wang, Qing and Xiong, Jiechao and Han, Lei and Liu, Han and Zhang, Tong and others},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{chen2020bail,
  title={BAIL: Best-action imitation learning for batch deep reinforcement learning},
  author={Chen, Xinyue and Zhou, Zijian and Wang, Zheng and Wang, Che and Wu, Yanqiu and Ross, Keith},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18353--18363},
  year={2020}
}

@inproceedings{wu2021uncertainty,
  title={Uncertainty Weighted Actor-Critic for Offline Reinforcement Learning},
  author={Wu, Yue and Zhai, Shuangfei and Srivastava, Nitish and Susskind, Joshua M and Zhang, Jian and Salakhutdinov, Ruslan and Goh, Hanlin},
  booktitle={International Conference on Machine Learning},
  pages={11319--11328},
  year={2021},
  organization={PMLR}
}

@article{fu2020d4rl,
  title={D4rl: Datasets for deep data-driven reinforcement learning},
  author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.07219},
  year={2020}
}

@inproceedings{le2019batch,
  title={Batch policy learning under constraints},
  author={Le, Hoang and Voloshin, Cameron and Yue, Yisong},
  booktitle={International Conference on Machine Learning},
  pages={3703--3712},
  year={2019},
  organization={PMLR}
}

@article{wang2022diffusion,
  title={Diffusion policies as an expressive policy class for offline reinforcement learning},
  author={Wang, Zhendong and Hunt, Jonathan J and Zhou, Mingyuan},
  journal={arXiv preprint arXiv:2208.06193},
  year={2022}
}

@article{hughes2018identifying,
  title={Identifying corresponding patches in SAR and optical images with a pseudo-siamese CNN},
  author={Hughes, Lloyd H and Schmitt, Michael and Mou, Lichao and Wang, Yuanyuan and Zhu, Xiao Xiang},
  journal={IEEE Geoscience and Remote Sensing Letters},
  volume={15},
  number={5},
  pages={784--788},
  year={2018},
  publisher={IEEE}
}

@inproceedings{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International conference on machine learning},
  pages={1587--1596},
  year={2018},
  organization={PMLR}
}

@article{antos2007fitted,
  title={Fitted Q-iteration in continuous action-space MDPs},
  author={Antos, Andr{\'a}s and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  journal={Advances in neural information processing systems},
  volume={20},
  year={2007}
}

@article{kumar2020conservative,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}

@article{yarats2022don,
  title={Don't Change the Algorithm, Change the Data: Exploratory Data for Offline Reinforcement Learning},
  author={Yarats, Denis and Brandfonbrener, David and Liu, Hao and Laskin, Michael and Abbeel, Pieter and Lazaric, Alessandro and Pinto, Lerrel},
  journal={arXiv preprint arXiv:2201.13425},
  year={2022}
}

@article{schweighofer2021understanding,
  title={Understanding the Effects of Dataset Characteristics on Offline Reinforcement Learning},
  author={Schweighofer, Kajetan and Hofmarcher, Markus and Dinu, Marius-Constantin and Renz, Philipp and Bitto-Nemling, Angela and Patil, Vihang and Hochreiter, Sepp},
  journal={arXiv preprint arXiv:2111.04714},
  year={2021}
}
@article{an2021uncertainty,
  title={Uncertainty-based offline reinforcement learning with diversified q-ensemble},
  author={An, Gaon and Moon, Seungyong and Kim, Jang-Hyun and Song, Hyun Oh},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={7436--7447},
  year={2021}
}
@inproceedings{mandlekar2020iris,
  title={Iris: Implicit reinforcement without interaction at scale for learning control from offline robot manipulation data},
  author={Mandlekar, Ajay and Ramos, Fabio and Boots, Byron and Savarese, Silvio and Fei-Fei, Li and Garg, Animesh and Fox, Dieter},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={4414--4420},
  year={2020},
  organization={IEEE}
}
@article{ma2021hierarchical,
  title={A hierarchical reinforcement learning based optimization framework for large-scale dynamic pickup and delivery problems},
  author={Ma, Yi and Hao, Xiaotian and Hao, Jianye and Lu, Jiawen and Liu, Xing and Xialiang, Tong and Yuan, Mingxuan and Li, Zhigang and Tang, Jie and Meng, Zhaopeng},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={23609--23620},
  year={2021}
}
@inproceedings{hao2020dynamic,
  title={Dynamic knapsack optimization towards efficient multi-channel sequential advertising},
  author={Hao, Xiaotian and Peng, Zhaoqing and Ma, Yi and Wang, Guan and Jin, Junqi and Hao, Jianye and Chen, Shan and Bai, Rongquan and Xie, Mingzhou and Xu, Miao and others},
  booktitle={International Conference on Machine Learning},
  pages={4060--4070},
  year={2020},
  organization={PMLR}
}
@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}
@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}
@misc{zhou2020smarts,
      title={SMARTS: Scalable Multi-Agent Reinforcement Learning Training School for Autonomous Driving},
      author={Ming Zhou and Jun Luo and Julian Villella and Yaodong Yang and David Rusu and Jiayu Miao and Weinan Zhang and Montgomery Alban and Iman Fadakar and Zheng Chen and Aurora Chongxi Huang and Ying Wen and Kimia Hassanzadeh and Daniel Graves and Dong Chen and Zhengbang Zhu and Nhat Nguyen and Mohamed Elsayed and Kun Shao and Sanjeevan Ahilan and Baokuan Zhang and Jiannan Wu and Zhengang Fu and Kasra Rezaee and Peyman Yadmellat and Mohsen Rohani and Nicolas Perez Nieves and Yihan Ni and Seyedershad Banijamali and Alexander Cowen Rivers and Zheng Tian and Daniel Palenicek and Haitham bou Ammar and Hongbo Zhang and Wulong Liu and Jianye Hao and Jun Wang},
      url={https://arxiv.org/abs/2010.09776},
      primaryClass={cs.MA},
      booktitle={Proceedings of the 4th Conference on Robot Learning (CoRL)},
      year={2020},
      month={11}
 }
 @inproceedings{wang2018supervised,
  title={Supervised reinforcement learning with recurrent neural network for dynamic treatment recommendation},
  author={Wang, Lu and Zhang, Wei and He, Xiaofeng and Zha, Hongyuan},
  booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={2447--2456},
  year={2018}
}
@article{kidambi2020morel,
  title={Morel: Model-based offline reinforcement learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={21810--21823},
  year={2020}
}
@article{yu2020mopo,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James Y and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={14129--14142},
  year={2020}
}
@article{matsushima2020deployment,
  title={Deployment-efficient reinforcement learning via model-based offline optimization},
  author={Matsushima, Tatsuya and Furuta, Hiroki and Matsuo, Yutaka and Nachum, Ofir and Gu, Shixiang},
  journal={arXiv preprint arXiv:2006.03647},
  year={2020}
}
@article{argenson2020model,
  title={Model-based offline planning},
  author={Argenson, Arthur and Dulac-Arnold, Gabriel},
  journal={arXiv preprint arXiv:2008.05556},
  year={2020}
}
@article{yu2021combo,
  title={Combo: Conservative offline model-based policy optimization},
  author={Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{meera2022natural,
  title={Natural language processing},
  author={Meera, S and Geerthik, S},
  journal={Artificial Intelligent Techniques for Wireless Communication and Networking},
  pages={139--153},
  year={2022},
  publisher={Wiley Online Library}
}

@article{pan2020softmax,
  title={Softmax deep double deterministic policy gradients},
  author={Pan, Ling and Cai, Qingpeng and Huang, Longbo},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={11767--11777},
  year={2020}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={In Proc. 19th International Conference on Machine Learning},
  year={2002},
  organization={Citeseer}
}
@article{kiran2021deep,
  title={Deep reinforcement learning for autonomous driving: A survey},
  author={Kiran, B Ravi and Sobh, Ibrahim and Talpaert, Victor and Mannion, Patrick and Al Sallab, Ahmad A and Yogamani, Senthil and P{\'e}rez, Patrick},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  year={2021},
  publisher={IEEE}
}

@article{beeson2022improving,
  title={Improving TD3-BC: Relaxed Policy Constraint for Offline Learning and Stable Online Fine-Tuning},
  author={Beeson, Alex and Montana, Giovanni},
  journal={arXiv preprint arXiv:2211.11802},
  year={2022}
}
@inproceedings{xiao2021optimality,
  title={On the optimality of batch policy optimization algorithms},
  author={Xiao, Chenjun and Wu, Yifan and Mei, Jincheng and Dai, Bo and Lattimore, Tor and Li, Lihong and Szepesvari, Csaba and Schuurmans, Dale},
  booktitle={International Conference on Machine Learning},
  pages={11362--11371},
  year={2021},
  organization={PMLR}
}
@inproceedings{
xiaosample,
title={The In-Sample Softmax for Offline Reinforcement Learning},
author={Chenjun Xiao and Han Wang and Yangchen Pan and Adam White and Martha White},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023}
}

@inproceedings{abbasi2019politex,
  title={Politex: Regret bounds for policy iteration using expert prediction},
  author={Abbasi-Yadkori, Yasin and Bartlett, Peter and Bhatia, Kush and Lazic, Nevena and Szepesvari, Csaba and Weisz, Gell{\'e}rt},
  booktitle={International Conference on Machine Learning},
  pages={3692--3702},
  year={2019},
  organization={PMLR}
}
@inproceedings{mei2019principled,
  title={On principled entropy exploration in policy optimization},
  author={Mei, Jincheng and Xiao, Chenjun and Huang, Ruitong and Schuurmans, Dale and M{\"u}ller, Martin},
  booktitle={Proceedings of the 28th International Joint Conference on Artificial Intelligence},
  pages={3130--3136},
  year={2019}
}
@inproceedings{
abdolmaleki2018maximum,
title={Maximum a Posteriori Policy Optimisation},
author={Abbas Abdolmaleki and Jost Tobias Springenberg and Yuval Tassa and Remi Munos and Nicolas Heess and Martin Riedmiller},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=S1ANxQW0b},
}
@inproceedings{geist2019theory,
  title={A theory of regularized markov decision processes},
  author={Geist, Matthieu and Scherrer, Bruno and Pietquin, Olivier},
  booktitle={International Conference on Machine Learning},
  pages={2160--2169},
  year={2019},
  organization={PMLR}
}

@article{hazan2016introduction,
  title={Introduction to online convex optimization},
  author={Hazan, Elad and others},
  journal={Foundations and Trends{\textregistered} in Optimization},
  volume={2},
  number={3-4},
  pages={157--325},
  year={2016},
  publisher={Now Publishers, Inc.}
}
@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@inproceedings{mei2020global,
  title={On the global convergence rates of softmax policy gradient methods},
  author={Mei, Jincheng and Xiao, Chenjun and Szepesvari, Csaba and Schuurmans, Dale},
  booktitle={International Conference on Machine Learning},
  pages={6820--6829},
  year={2020},
  organization={PMLR}
}

@article{xiao2019maximum,
  title={Maximum entropy monte-carlo planning},
  author={Xiao, Chenjun and Huang, Ruitong and Mei, Jincheng and Schuurmans, Dale and M{\"u}ller, Martin},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{nachum2017bridging,
  title={Bridging the gap between value and policy based reinforcement learning},
  author={Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Schuurmans, Dale},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{yamagata2023q,
  title={Q-learning decision transformer: Leveraging dynamic programming for conditional sequence modelling in offline rl},
  author={Yamagata, Taku and Khalil, Ahmed and Santos-Rodriguez, Raul},
  booktitle={International Conference on Machine Learning},
  pages={38989--39007},
  year={2023},
  organization={PMLR}
}
@inproceedings{emmons2021rvs,
  title={RvS: What is Essential for Offline RL via Supervised Learning?},
  author={Emmons, Scott and Eysenbach, Benjamin and Kostrikov, Ilya and Levine, Sergey},
  booktitle={International Conference on Learning Representations},
  year={2021}
}
@article{badrinath2023waypoint,
  title={Waypoint Transformer: Reinforcement Learning via Supervised Learning with Intermediate Targets},
  author={Badrinath, Anirudhan and Flet-Berliac, Yannis and Nie, Allen and Brunskill, Emma},
  journal={arXiv preprint arXiv:2306.14069},
  year={2023}
}
@inproceedings{
tarasov2022corl,
  title={{CORL}: Research-oriented Deep Offline Reinforcement Learning Library},
  author={Denis Tarasov and Alexander Nikulin and Dmitry Akimov and Vladislav Kurenkov and Sergey Kolesnikov},
  booktitle={3rd Offline RL Workshop: Offline RL as a ''Launchpad''},
  year={2022},
  url={https://openreview.net/forum?id=SyAS49bBcv}
}
@article{park2023hiql,
  title={HIQL: Offline Goal-Conditioned RL with Latent States as Actions},
  author={Park, Seohong and Ghosh, Dibya and Eysenbach, Benjamin and Levine, Sergey},
  journal={arXiv preprint arXiv:2307.11949},
  year={2023}
}


@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}

@article{fedus2022switch,
  title={Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity},
  author={Fedus, William and Zoph, Barret and Shazeer, Noam},
  journal={The Journal of Machine Learning Research},
  volume={23},
  number={1},
  pages={5232--5270},
  year={2022},
  publisher={JMLRORG}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}


@article{gao2020making,
  title={Making pre-trained language models better few-shot learners},
  author={Gao, Tianyu and Fisch, Adam and Chen, Danqi},
  journal={arXiv preprint arXiv:2012.15723},
  year={2020}
}


@article{akyurek2022learning,
  title={What learning algorithm is in-context learning? investigations with linear models},
  author={Aky{\"u}rek, Ekin and Schuurmans, Dale and Andreas, Jacob and Ma, Tengyu and Zhou, Denny},
  journal={arXiv preprint arXiv:2211.15661},
  year={2022}
}


@article{garg2022can,
  title={What can transformers learn in-context? a case study of simple function classes},
  author={Garg, Shivam and Tsipras, Dimitris and Liang, Percy S and Valiant, Gregory},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={30583--30598},
  year={2022}
}

@article{xie2021explanation,
  title={An explanation of in-context learning as implicit bayesian inference},
  author={Xie, Sang Michael and Raghunathan, Aditi and Liang, Percy and Ma, Tengyu},
  journal={arXiv preprint arXiv:2111.02080},
  year={2021}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}


@article{zhang2022automatic,
  title={Automatic chain of thought prompting in large language models},
  author={Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Smola, Alex},
  journal={arXiv preprint arXiv:2210.03493},
  year={2022}
}

@article{yao2023tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L and Cao, Yuan and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2305.10601},
  year={2023}
}


@article{liu2023chain,
  title={Chain of hindsight aligns language models with feedback},
  author={Liu, Hao and Sferrazza, Carmelo and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2302.02676},
  volume={3},
  year={2023}
}

@article{xiao2023sample,
  title={The in-sample softmax for offline reinforcement learning},
  author={Xiao, Chenjun and Wang, Han and Pan, Yangchen and White, Adam and White, Martha},
  journal={arXiv preprint arXiv:2302.14372},
  year={2023}
}


@article{lee2023supervised,
  title={Supervised Pretraining Can Learn In-Context Reinforcement Learning},
  author={Lee, Jonathan N and Xie, Annie and Pacchiano, Aldo and Chandak, Yash and Finn, Chelsea and Nachum, Ofir and Brunskill, Emma},
  journal={arXiv preprint arXiv:2306.14892},
  year={2023}
}

@article{laskin2022context,
  title={In-context reinforcement learning with algorithm distillation},
  author={Laskin, Michael and Wang, Luyu and Oh, Junhyuk and Parisotto, Emilio and Spencer, Stephen and Steigerwald, Richie and Strouse, DJ and Hansen, Steven and Filos, Angelos and Brooks, Ethan and others},
  journal={arXiv preprint arXiv:2210.14215},
  year={2022}
}

@article{lester2021power,
  title={The power of scale for parameter-efficient prompt tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  journal={arXiv preprint arXiv:2104.08691},
  year={2021}
}

@inproceedings{zhou2022conditional,
  title={Conditional prompt learning for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16816--16825},
  year={2022}
}

@article{zhou2022learning,
  title={Learning to prompt for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal={International Journal of Computer Vision},
  volume={130},
  number={9},
  pages={2337--2348},
  year={2022},
  publisher={Springer}
}

@article{singhal2022large,
  title={Large language models encode clinical knowledge},
  author={Singhal, Karan and Azizi, Shekoofeh and Tu, Tao and Mahdavi, S Sara and Wei, Jason and Chung, Hyung Won and Scales, Nathan and Tanwani, Ajay and Cole-Lewis, Heather and Pfohl, Stephen and others},
  journal={arXiv preprint arXiv:2212.13138},
  year={2022}
}

@article{nachum2018data,
  title={Data-efficient hierarchical reinforcement learning},
  author={Nachum, Ofir and Gu, Shixiang Shane and Lee, Honglak and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{furuta2021generalized,
  title={Generalized decision transformer for offline hindsight information matching},
  author={Furuta, Hiroki and Matsuo, Yutaka and Gu, Shixiang Shane},
  journal={arXiv preprint arXiv:2111.10364},
  year={2021}
}

@inproceedings{schaul2015universal,
  title={Universal value function approximators},
  author={Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle={International conference on machine learning},
  pages={1312--1320},
  year={2015},
  organization={PMLR}
}

@article{jiang2022efficient,
  title={Efficient planning in a compact latent action space},
  author={Jiang, Zhengyao and Zhang, Tianjun and Janner, Michael and Li, Yueying and Rockt{\"a}schel, Tim and Grefenstette, Edward and Tian, Yuandong},
  journal={arXiv preprint arXiv:2208.10291},
  year={2022}
}

@article{ajay2020opal,
  title={Opal: Offline primitive discovery for accelerating offline reinforcement learning},
  author={Ajay, Anurag and Kumar, Aviral and Agrawal, Pulkit and Levine, Sergey and Nachum, Ofir},
  journal={arXiv preprint arXiv:2010.13611},
  year={2020}
}

@inproceedings{co2018self,
  title={Self-consistent trajectory autoencoder: Hierarchical reinforcement learning with trajectory embeddings},
  author={Co-Reyes, John and Liu, YuXuan and Gupta, Abhishek and Eysenbach, Benjamin and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1009--1018},
  year={2018},
  organization={PMLR}
}

@inproceedings{lynch2020learning,
  title={Learning latent plans from play},
  author={Lynch, Corey and Khansari, Mohi and Xiao, Ted and Kumar, Vikash and Tompson, Jonathan and Levine, Sergey and Sermanet, Pierre},
  booktitle={Conference on robot learning},
  pages={1113--1132},
  year={2020},
  organization={PMLR}
}

@article{chebotar2021actionable,
  title={Actionable models: Unsupervised offline reinforcement learning of robotic skills},
  author={Chebotar, Yevgen and Hausman, Karol and Lu, Yao and Xiao, Ted and Kalashnikov, Dmitry and Varley, Jake and Irpan, Alex and Eysenbach, Benjamin and Julian, Ryan and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2104.07749},
  year={2021}
}

@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@inproceedings{bacon2017option,
  title={The option-critic architecture},
  author={Bacon, Pierre-Luc and Harb, Jean and Precup, Doina},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={31},
  number={1},
  year={2017}
}

@inproceedings{wulfmeier2021data,
  title={Data-efficient hindsight off-policy option learning},
  author={Wulfmeier, Markus and Rao, Dushyant and Hafner, Roland and Lampe, Thomas and Abdolmaleki, Abbas and Hertweck, Tim and Neunert, Michael and Tirumala, Dhruva and Siegel, Noah and Heess, Nicolas and others},
  booktitle={International Conference on Machine Learning},
  pages={11340--11350},
  year={2021},
  organization={PMLR}
}

@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Pieter Abbeel, OpenAI and Zaremba, Wojciech},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{klissarov2023deep,
  title={Deep Laplacian-based Options for Temporally-Extended Exploration},
  author={Klissarov, Martin and Machado, Marlos C},
  journal={arXiv preprint arXiv:2301.11181},
  year={2023}
}

@article{lee2022multi,
  title={Multi-game decision transformers},
  author={Lee, Kuang-Huei and Nachum, Ofir and Yang, Mengjiao Sherry and Lee, Lisa and Freeman, Daniel and Guadarrama, Sergio and Fischer, Ian and Xu, Winnie and Jang, Eric and Michalewski, Henryk and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27921--27936},
  year={2022}
}

@article{reed2022generalist,
  title={A generalist agent},
  author={Reed, Scott and Zolna, Konrad and Parisotto, Emilio and Colmenarejo, Sergio Gomez and Novikov, Alexander and Barth-Maron, Gabriel and Gimenez, Mai and Sulsky, Yury and Kay, Jackie and Springenberg, Jost Tobias and others},
  journal={arXiv preprint arXiv:2205.06175},
  year={2022}
}

@article{wu2023elastic,
  title={Elastic decision transformer},
  author={Wu, Yueh-Hua and Wang, Xiaolong and Hamaya, Masashi},
  journal={arXiv preprint arXiv:2307.02484},
  year={2023}
}

@article{liu2023emergent,
  title={Emergent agentic transformer from chain of hindsight experience},
  author={Liu, Hao and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2305.16554},
  year={2023}
}

@inproceedings{bowling2023settling,
  title={Settling the reward hypothesis},
  author={Bowling, Michael and Martin, John D and Abel, David and Dabney, Will},
  booktitle={International Conference on Machine Learning},
  pages={3003--3020},
  year={2023},
  organization={PMLR}
}

@article{silver2021reward,
  title={Reward is enough},
  author={Silver, David and Singh, Satinder and Precup, Doina and Sutton, Richard S},
  journal={Artificial Intelligence},
  volume={299},
  pages={103535},
  year={2021},
  publisher={Elsevier}
}

@article{chebotar2023q,
  title={Q-transformer: Scalable offline reinforcement learning via autoregressive q-functions},
  author={Chebotar, Yevgen and Vuong, Quan and Irpan, Alex and Hausman, Karol and Xia, Fei and Lu, Yao and Kumar, Aviral and Yu, Tianhe and Herzog, Alexander and Pertsch, Karl and others},
  journal={arXiv preprint arXiv:2309.10150},
  year={2023}
}