\begin{thebibliography}{10}

\bibitem{akhter2010trajectory}
Ijaz Akhter, Yaser Sheikh, Sohaib Khan, and Takeo Kanade.
\newblock Trajectory space: A dual representation for nonrigid structure from motion.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}, 33(7):1442--1456, 2010.

\bibitem{bovik2010handbook}
Alan~C Bovik.
\newblock {\em Handbook of image and video processing}.
\newblock Academic press, 2010.

\bibitem{Cao2023HexPlaneAF}
Ang Cao and Justin Johnson.
\newblock Hexplane: A fast representation for dynamic scenes.
\newblock 2023.

\bibitem{chan2023hashing}
Cheng-Hung Chan, Cheng-Yang Yuan, Cheng Sun, and Hwann-Tzong Chen.
\newblock Hashing neural video decomposition with multiplicative residuals in space-time.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 7743--7753, 2023.

\bibitem{doersch2022tap}
Carl Doersch, Ankush Gupta, Larisa Markeeva, Adria Recasens, Lucas Smaira, Yusuf Aytar, Joao Carreira, Andrew Zisserman, and Yi~Yang.
\newblock Tap-vid: A benchmark for tracking any point in a video.
\newblock {\em Advances in Neural Information Processing Systems}, 35:13610--13626, 2022.

\bibitem{doersch2023tapir}
Carl Doersch, Yi~Yang, Mel Vecerik, Dilara Gokay, Ankush Gupta, Yusuf Aytar, Joao Carreira, and Andrew Zisserman.
\newblock Tapir: Tracking any point with per-frame initialization and temporal refinement.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 10061--10072, 2023.

\bibitem{gordon1974b}
William~J Gordon and Richard~F Riesenfeld.
\newblock B-spline curves and surfaces.
\newblock In {\em Computer aided geometric design}, pages 95--126. Elsevier, 1974.

\bibitem{harley2022particle}
Adam~W Harley, Zhaoyuan Fang, and Katerina Fragkiadaki.
\newblock Particle video revisited: Tracking through occlusions using point trajectories.
\newblock In {\em European Conference on Computer Vision}, pages 59--75. Springer, 2022.

\bibitem{huang2023inve}
Jiahui Huang, Leonid Sigal, Kwang~Moo Yi, Oliver Wang, and Joon-Young Lee.
\newblock Inve: Interactive neural video editing.
\newblock {\em arXiv preprint arXiv:2307.07663}, 2023.

\bibitem{huang2023sc}
Yi-Hua Huang, Yang-Tian Sun, Ziyi Yang, Xiaoyang Lyu, Yan-Pei Cao, and Xiaojuan Qi.
\newblock Sc-gs: Sparse-controlled gaussian splatting for editable dynamic scenes.
\newblock {\em arXiv preprint arXiv:2312.14937}, 2023.

\bibitem{huang2022flowformer}
Zhaoyang Huang, Xiaoyu Shi, Chao Zhang, Qiang Wang, Ka~Chun Cheung, Hongwei Qin, Jifeng Dai, and Hongsheng Li.
\newblock Flowformer: A transformer architecture for optical flow.
\newblock In {\em European conference on computer vision}, pages 668--685. Springer, 2022.

\bibitem{jabri2020space}
Allan Jabri, Andrew Owens, and Alexei Efros.
\newblock Space-time correspondence as a contrastive random walk.
\newblock {\em Advances in neural information processing systems}, 33:19545--19560, 2020.

\bibitem{karaev2023cotracker}
Nikita Karaev, Ignacio Rocco, Benjamin Graham, Natalia Neverova, Andrea Vedaldi, and Christian Rupprecht.
\newblock Cotracker: It is better to track together.
\newblock {\em arXiv preprint arXiv:2307.07635}, 2023.

\bibitem{kasten2021layered}
Yoni Kasten, Dolev Ofri, Oliver Wang, and Tali Dekel.
\newblock Layered neural atlases for consistent video editing.
\newblock {\em ACM Transactions on Graphics (TOG)}, 40(6):1--12, 2021.

\bibitem{ke2023repurposing}
Bingxin Ke, Anton Obukhov, Shengyu Huang, Nando Metzger, Rodrigo~Caye Daudt, and Konrad Schindler.
\newblock Repurposing diffusion-based image generators for monocular depth estimation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2024.

\bibitem{kerbl20233d}
Bernhard Kerbl, Georgios Kopanas, Thomas Leimk{\"u}hler, and George Drettakis.
\newblock 3d gaussian splatting for real-time radiance field rendering.
\newblock {\em ACM Transactions on Graphics}, 42(4):1--14, 2023.

\bibitem{kirillov2023segment}
Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander~C Berg, Wan-Yen Lo, et~al.
\newblock Segment anything.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 4015--4026, 2023.

\bibitem{kratimenos2023dynmf}
Agelos Kratimenos, Jiahui Lei, and Kostas Daniilidis.
\newblock Dynmf: Neural motion factorization for real-time dynamic view synthesis with 3d gaussian splatting.
\newblock {\em arXiv preprint arXiv:2312.00112}, 2023.

\bibitem{li2023video}
Maomao Li, Yu~Li, Tianyu Yang, Yunfei Liu, Dongxu Yue, Zhihui Lin, and Dong Xu.
\newblock A video is worth 256 bases: Spatial-temporal expectation-maximization inversion for zero-shot video editing.
\newblock {\em arXiv preprint arXiv:2312.05856}, 2023.

\bibitem{li2023vidtome}
Xirui Li, Chao Ma, Xiaokang Yang, and Ming-Hsuan Yang.
\newblock Vidtome: Video token merging for zero-shot video editing.
\newblock {\em arXiv preprint arXiv:2312.10656}, 2023.

\bibitem{li2023dynibar}
Zhengqi Li, Qianqian Wang, Forrester Cole, Richard Tucker, and Noah Snavely.
\newblock Dynibar: Neural dynamic image-based rendering.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 4273--4284, 2023.

\bibitem{lin2023gaussian}
Youtian Lin, Zuozhuo Dai, Siyu Zhu, and Yao Yao.
\newblock Gaussian-flow: 4d reconstruction with dynamic 3d gaussian particle.
\newblock {\em arXiv:2312.03431}, 2023.

\bibitem{lu2020layered}
Erika Lu, Forrester Cole, Tali Dekel, Weidi Xie, Andrew Zisserman, David Salesin, William~T Freeman, and Michael Rubinstein.
\newblock Layered neural rendering for retiming people in video.
\newblock {\em arXiv preprint arXiv:2009.07833}, 2020.

\bibitem{scaffoldgs}
Tao Lu, Yu~Mulin, Xu~Linning, Xiangli Yuanbo, Wang Limin, Lin Dahua, and Dai. Bo.
\newblock Scaffold-gs: Structured 3d gaussians for view-adaptive rendering.
\newblock {\em Conference on Computer Vision and Pattern Recognition (CVPR)}, 2024.

\bibitem{luiten2023dynamic}
Jonathon Luiten, Georgios Kopanas, Bastian Leibe, and Deva Ramanan.
\newblock Dynamic 3d gaussians: Tracking by persistent dynamic view synthesis.
\newblock In {\em 3DV}, 2024.

\bibitem{luo2020consistent}
Xuan Luo, Jia-Bin Huang, Richard Szeliski, Kevin Matzen, and Johannes Kopf.
\newblock Consistent video depth estimation.
\newblock {\em ACM Transactions on Graphics (ToG)}, 39(4):71--1, 2020.

\bibitem{ma2023maskint}
Haoyu Ma, Shahin Mahdizadehaghdam, Bichen Wu, Zhipeng Fan, Yuchao Gu, Wenliang Zhao, Lior Shapira, and Xiaohui Xie.
\newblock Maskint: Video editing via interpolative non-autoregressive masked transformers.
\newblock {\em arXiv preprint arXiv:2312.12468}, 2023.

\bibitem{mildenhall2021nerf}
Ben Mildenhall, Pratul~P Srinivasan, Matthew Tancik, Jonathan~T Barron, Ravi Ramamoorthi, and Ren Ng.
\newblock Nerf: Representing scenes as neural radiance fields for view synthesis.
\newblock {\em Communications of the ACM}, 65(1):99--106, 2021.

\bibitem{neoral2024mft}
Michal Neoral, Jon{\'a}{\v{s}} {\v{S}}er{\`y}ch, and Ji{\v{r}}{\'\i} Matas.
\newblock Mft: Long-term tracking of every pixel.
\newblock In {\em Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, pages 6837--6847, 2024.

\bibitem{oquab2023dinov2}
Maxime Oquab, Timoth{\'e}e Darcet, Th{\'e}o Moutakanni, Huy~V Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel HAZIZA, Francisco Massa, Alaaeldin El-Nouby, et~al.
\newblock Dinov2: Learning robust visual features without supervision.
\newblock {\em Transactions on Machine Learning Research}, 2023.

\bibitem{orucc2003q}
Halil Oru{\c{c}} and George~M Phillips.
\newblock q-bernstein polynomials and b{\'e}zier curves.
\newblock {\em Journal of Computational and Applied Mathematics}, 151(1):1--12, 2003.

\bibitem{ouyang2023codef}
Hao Ouyang, Qiuyu Wang, Yuxi Xiao, Qingyan Bai, Juntao Zhang, Kecheng Zheng, Xiaowei Zhou, Qifeng Chen, and Yujun Shen.
\newblock Codef: Content deformation fields for temporally consistent video processing.
\newblock {\em arXiv preprint arXiv:2308.07926}, 2023.

\bibitem{park2021hypernerf}
Keunhong Park, Utkarsh Sinha, Peter Hedman, Jonathan~T Barron, Sofien Bouaziz, Dan~B Goldman, Ricardo Martin-Brualla, and Steven~M Seitz.
\newblock Hypernerf: a higher-dimensional representation for topologically varying neural radiance fields.
\newblock {\em ACM Transactions on Graphics (TOG)}, 40(6):1--12, 2021.

\bibitem{pont20172017}
Jordi Pont-Tuset, Federico Perazzi, Sergi Caelles, Pablo Arbel{\'a}ez, Alex Sorkine-Hornung, and Luc Van~Gool.
\newblock The 2017 davis challenge on video object segmentation.
\newblock {\em arXiv preprint arXiv:1704.00675}, 2017.

\bibitem{Ranftl2022}
Ren\'{e} Ranftl, Katrin Lasinger, David Hafner, Konrad Schindler, and Vladlen Koltun.
\newblock Towards robust monocular depth estimation: Mixing datasets for zero-shot cross-dataset transfer.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}, 44(3), 2022.

\bibitem{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 10684--10695, 2022.

\bibitem{sand2008particle}
Peter Sand and Seth Teller.
\newblock Particle video: Long-range motion estimation using point trajectories.
\newblock {\em International journal of computer vision}, 80:72--91, 2008.

\bibitem{schoenberger2016sfm}
Johannes~Lutz Sch\"{o}nberger and Jan-Michael Frahm.
\newblock Structure-from-motion revisited.
\newblock In {\em Conference on Computer Vision and Pattern Recognition (CVPR)}, 2016.

\bibitem{schoenberger2016mvs}
Johannes~Lutz Sch\"{o}nberger, Enliang Zheng, Marc Pollefeys, and Jan-Michael Frahm.
\newblock Pixelwise view selection for unstructured multi-view stereo.
\newblock In {\em European Conference on Computer Vision (ECCV)}, 2016.

\bibitem{sorkine2007rigid}
Olga Sorkine and Marc Alexa.
\newblock As-rigid-as-possible surface modeling.
\newblock In {\em Symposium on Geometry processing}, volume~4, pages 109--116. Citeseer, 2007.

\bibitem{sun20243dgstream}
Jiakai Sun, Han Jiao, Guangyuan Li, Zhanjie Zhang, Lei Zhao, and Wei Xing.
\newblock 3dgstream: On-the-fly training of 3d gaussians for efficient streaming of photo-realistic free-viewpoint videos.
\newblock {\em arXiv preprint arXiv:2403.01444}, 2024.

\bibitem{teed2020raft}
Zachary Teed and Jia Deng.
\newblock Raft: Recurrent all-pairs field transforms for optical flow.
\newblock In {\em Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part II 16}, pages 402--419. Springer, 2020.

\bibitem{wang2021neural}
Chaoyang Wang, Ben Eckart, Simon Lucey, and Orazio Gallo.
\newblock Neural trajectory fields for dynamic novel view synthesis.
\newblock {\em arXiv preprint arXiv:2105.05994}, 2021.

\bibitem{wang1994representing}
John~YA Wang and Edward~H Adelson.
\newblock Representing moving images with layers.
\newblock {\em IEEE transactions on image processing}, 3(5):625--638, 1994.

\bibitem{wang2023tracking}
Qianqian Wang, Yen-Yu Chang, Ruojin Cai, Zhengqi Li, Bharath Hariharan, Aleksander Holynski, and Noah Snavely.
\newblock Tracking everything everywhere all at once.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 19795--19806, 2023.

\bibitem{wang2023gendef}
Wen Wang, Kecheng Zheng, Qiuyu Wang, Hao Chen, Zifan Shi, Ceyuan Yang, Yujun Shen, and Chunhua Shen.
\newblock Gendef: Learning generative deformation field for video generation.
\newblock {\em arXiv preprint arXiv:2312.04561}, 2023.

\bibitem{wang2002video}
Yao Wang, J{\"o}rn Ostermann, and Ya-Qin Zhang.
\newblock {\em Video processing and communications}, volume~1.
\newblock Prentice hall Upper Saddle River, NJ, 2002.

\bibitem{wu20234dgaussians}
Guanjun Wu, Taoran Yi, Jiemin Fang, Lingxi Xie, Xiaopeng Zhang, Wei Wei, Wenyu Liu, Qi~Tian, and Wang Xinggang.
\newblock 4d gaussian splatting for real-time dynamic scene rendering.
\newblock {\em arXiv preprint arXiv:2310.08528}, 2023.

\bibitem{xiao2024spatialtracker}
Yuxi Xiao, Qianqian Wang, Shangzhan Zhang, Nan Xue, Sida Peng, Yujun Shen, and Xiaowei Zhou.
\newblock Spatialtracker: Tracking any 2d pixels in 3d space.
\newblock {\em arXiv preprint arXiv:2404.04319}, 2024.

\bibitem{xu2024diffusion}
Guangkai Xu, Yongtao Ge, Mingyu Liu, Chengxiang Fan, Kangyang Xie, Zhiyue Zhao, Hao Chen, and Chunhua Shen.
\newblock Diffusion models trained with large data are transferable visual models.
\newblock {\em arXiv preprint arXiv:2403.06090}, 2024.

\bibitem{yang2024depth}
Lihe Yang, Bingyi Kang, Zilong Huang, Xiaogang Xu, Jiashi Feng, and Hengshuang Zhao.
\newblock Depth anything: Unleashing the power of large-scale unlabeled data.
\newblock {\em arXiv preprint arXiv:2401.10891}, 2024.

\bibitem{yang2023gs4d}
Zeyu Yang, Hongye Yang, Zijie Pan, Xiatian Zhu, and Li~Zhang.
\newblock Real-time photorealistic dynamic scene representation and rendering with 4d gaussian splatting.
\newblock {\em arXiv preprint arXiv 2310.10642}, 2023.

\bibitem{yang2023deformable3dgs}
Ziyi Yang, Xinyu Gao, Wen Zhou, Shaohui Jiao, Yuqing Zhang, and Xiaogang Jin.
\newblock Deformable 3d gaussians for high-fidelity monocular dynamic scene reconstruction.
\newblock {\em arXiv preprint arXiv:2309.13101}, 2023.

\bibitem{ye2022deformable}
Vickie Ye, Zhengqi Li, Richard Tucker, Angjoo Kanazawa, and Noah Snavely.
\newblock Deformable sprites for unsupervised video decomposition.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 2657--2666, 2022.

\bibitem{yu2018ds}
Chao Yu, Zuxin Liu, Xin-Jun Liu, Fugui Xie, Yi~Yang, Qi~Wei, and Qiao Fei.
\newblock Ds-slam: A semantic visual slam towards dynamic environments.
\newblock In {\em 2018 IEEE/RSJ international conference on intelligent robots and systems (IROS)}, pages 1168--1174. IEEE, 2018.

\bibitem{zhang2023adding}
Lvmin Zhang, Anyi Rao, and Maneesh Agrawala.
\newblock Adding conditional control to text-to-image diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 3836--3847, 2023.

\bibitem{zhang2023controlvideo}
Yabo Zhang, Yuxiang Wei, Dongsheng Jiang, Xiaopeng Zhang, Wangmeng Zuo, and Qi~Tian.
\newblock Controlvideo: Training-free controllable text-to-video generation.
\newblock {\em arXiv preprint arXiv:2305.13077}, 2023.

\bibitem{zhang2024fastvideoedit}
Youyuan Zhang, Xuan Ju, and James~J Clark.
\newblock Fastvideoedit: Leveraging consistency models for efficient text-to-video editing.
\newblock {\em arXiv preprint arXiv:2403.06269}, 2024.

\end{thebibliography}
