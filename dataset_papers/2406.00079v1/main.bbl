\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alayrac et~al.(2022)Alayrac, Donahue, Luc, Miech, Barr, Hasson, Lenc, Mensch, Millican, Reynolds, et~al.]{49}
Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, et~al.
\newblock Flamingo: a visual language model for few-shot learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 23716--23736, 2022.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{26}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock \emph{arXiv preprint arXiv:1607.06450}, 2016.

\bibitem[Brown et~al.(2020{\natexlab{a}})Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.]{21}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 1877--1901, 2020{\natexlab{a}}.

\bibitem[Brown et~al.(2020{\natexlab{b}})Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.]{47}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 1877--1901, 2020{\natexlab{b}}.

\bibitem[Chen et~al.(2021)Chen, Lu, Rajeswaran, Lee, Grover, Laskin, Abbeel, Srinivas, and Mordatch]{2}
Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Misha Laskin, Pieter Abbeel, Aravind Srinivas, and Igor Mordatch.
\newblock Decision transformer: Reinforcement learning via sequence modeling.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 15084--15097, 2021.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{22}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Dorfman et~al.(2021)Dorfman, Shenfeld, and Tamar]{36}
Ron Dorfman, Idan Shenfeld, and Aviv Tamar.
\newblock Offline meta reinforcement learning--identifiability challenges and effective data collection strategies.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 4607--4618, 2021.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, et~al.]{48}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Duan et~al.(2016)Duan, Schulman, Chen, Bartlett, Sutskever, and Abbeel]{32}
Yan Duan, John Schulman, Xi~Chen, Peter~L Bartlett, Ilya Sutskever, and Pieter Abbeel.
\newblock Rl2: Fast reinforcement learning via slow reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1611.02779}, 2016.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{46}
Chelsea Finn, Pieter Abbeel, and Sergey Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{International conference on machine learning}, pages 1126--1135. PMLR, 2017.

\bibitem[Fu et~al.(2022)Fu, Dao, Saab, Thomas, Rudra, and R{\'e}]{17}
Daniel~Y Fu, Tri Dao, Khaled~K Saab, Armin~W Thomas, Atri Rudra, and Christopher R{\'e}.
\newblock Hungry hungry hippos: Towards language modeling with state space models.
\newblock \emph{arXiv preprint arXiv:2212.14052}, 2022.

\bibitem[Fu et~al.(2020)Fu, Kumar, Nachum, Tucker, and Levine]{13}
Justin Fu, Aviral Kumar, Ofir Nachum, George Tucker, and Sergey Levine.
\newblock D4rl: Datasets for deep data-driven reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2004.07219}, 2020.

\bibitem[Fujimoto and Gu(2021)]{29}
Scott Fujimoto and Shixiang~Shane Gu.
\newblock A minimalist approach to offline reinforcement learning.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 20132--20145, 2021.

\bibitem[Fujimoto et~al.(2019)Fujimoto, Meger, and Precup]{39}
Scott Fujimoto, David Meger, and Doina Precup.
\newblock Off-policy deep reinforcement learning without exploration.
\newblock In \emph{International conference on machine learning}, pages 2052--2062. PMLR, 2019.

\bibitem[Grigsby et~al.(2024)Grigsby, Fan, and Zhu]{9}
Jake Grigsby, Linxi Fan, and Yuke Zhu.
\newblock Amago: Scalable in-context reinforcement learning for adaptive agents.
\newblock 2024.

\bibitem[Gu and Dao(2023)]{10}
Albert Gu and Tri Dao.
\newblock Mamba: Linear-time sequence modeling with selective state spaces.
\newblock \emph{arXiv preprint arXiv:2312.00752}, 2023.

\bibitem[Gu et~al.(2021)Gu, Goel, and R{\'e}]{12}
Albert Gu, Karan Goel, and Christopher R{\'e}.
\newblock Efficiently modeling long sequences with structured state spaces.
\newblock \emph{arXiv preprint arXiv:2111.00396}, 2021.

\bibitem[Hao~Liu(2023)]{1}
Pieter~Abbeel Hao~Liu.
\newblock Emergent agentic transformer from chain of hindsight experience.
\newblock In \emph{Proceedings of the 20th International Conference on Machine Learning (ICML 2023)}, 2023.

\bibitem[Ishii et~al.(2002)Ishii, Yoshida, and Yoshimoto]{31}
Shin Ishii, Wako Yoshida, and Junichiro Yoshimoto.
\newblock Control of exploitation--exploration meta-parameter in reinforcement learning.
\newblock \emph{Neural networks}, 15\penalty0 (4-6):\penalty0 665--687, 2002.

\bibitem[Janner et~al.(2021)Janner, Li, and Levine]{43}
Michael Janner, Qiyang Li, and Sergey Levine.
\newblock Offline reinforcement learning as one big sequence modeling problem.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 1273--1286, 2021.

\bibitem[Kumar et~al.(2019)Kumar, Fu, Soh, Tucker, and Levine]{42}
Aviral Kumar, Justin Fu, Matthew Soh, George Tucker, and Sergey Levine.
\newblock Stabilizing off-policy q-learning via bootstrapping error reduction.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Kumar et~al.(2020)Kumar, Zhou, Tucker, and Levine]{40}
Aviral Kumar, Aurick Zhou, George Tucker, and Sergey Levine.
\newblock Conservative q-learning for offline reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 1179--1191, 2020.

\bibitem[Laskin et~al.(2023)Laskin, Wang, Oh, Parisotto, Spencer, Steigerwald, Strouse, Hansen, Filos, Brooks, et~al.]{8}
Michael Laskin, Luyu Wang, Junhyuk Oh, Emilio Parisotto, Stephen Spencer, Richie Steigerwald, DJ~Strouse, Steven~Stenberg Hansen, Angelos Filos, Ethan Brooks, et~al.
\newblock In-context reinforcement learning with algorithm distillation.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.

\bibitem[Lee et~al.(2023)Lee, Xie, Pacchiano, Chandak, Finn, Nachum, and Brunskill]{3}
Jonathan~N Lee, Annie Xie, Aldo Pacchiano, Yash Chandak, Chelsea Finn, Ofir Nachum, and Emma Brunskill.
\newblock Supervised pretraining can learn in-context reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2306.14892}, 2023.

\bibitem[Lee et~al.(2022)Lee, Nachum, Yang, Lee, Freeman, Guadarrama, Fischer, Xu, Jang, Michalewski, et~al.]{14}
Kuang-Huei Lee, Ofir Nachum, Mengjiao~Sherry Yang, Lisa Lee, Daniel Freeman, Sergio Guadarrama, Ian Fischer, Winnie Xu, Eric Jang, Henryk Michalewski, et~al.
\newblock Multi-game decision transformers.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 27921--27936, 2022.

\bibitem[Mehta et~al.(2022)Mehta, Gupta, Cutkosky, and Neyshabur]{18}
Harsh Mehta, Ankit Gupta, Ashok Cutkosky, and Behnam Neyshabur.
\newblock Long range language modeling via gated state spaces.
\newblock \emph{arXiv preprint arXiv:2206.13947}, 2022.

\bibitem[Mitchell et~al.(2021)Mitchell, Rafailov, Peng, Levine, and Finn]{37}
Eric Mitchell, Rafael Rafailov, Xue~Bin Peng, Sergey Levine, and Chelsea Finn.
\newblock Offline meta-reinforcement learning with advantage weighting.
\newblock In \emph{International Conference on Machine Learning}, pages 7780--7791. PMLR, 2021.

\bibitem[Mnih et~al.(2013)Mnih, Kavukcuoglu, Silver, Graves, Antonoglou, Wierstra, and Riedmiller]{28}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin Riedmiller.
\newblock Playing atari with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1312.5602}, 2013.

\bibitem[Ni et~al.(2024)Ni, Ma, Eysenbach, and Bacon]{19}
Tianwei Ni, Michel Ma, Benjamin Eysenbach, and Pierre-Luc Bacon.
\newblock When do transformers shine in rl? decoupling memory from credit assignment.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Nichol et~al.(2018)Nichol, Achiam, and Schulman]{45}
Alex Nichol, Joshua Achiam, and John Schulman.
\newblock On first-order meta-learning algorithms.
\newblock \emph{arXiv preprint arXiv:1803.02999}, 2018.

\bibitem[Pong et~al.(2022)Pong, Nair, Smith, Huang, and Levine]{35}
Vitchyr~H Pong, Ashvin~V Nair, Laura~M Smith, Catherine Huang, and Sergey Levine.
\newblock Offline meta-reinforcement learning with online self-supervision.
\newblock In \emph{International Conference on Machine Learning}, pages 17811--17829. PMLR, 2022.

\bibitem[Radford et~al.(2018)Radford, Narasimhan, Salimans, Sutskever, et~al.]{23}
Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et~al.
\newblock Improving language understanding by generative pre-training.
\newblock 2018.

\bibitem[Reed et~al.(2022)Reed, Zolna, Parisotto, Colmenarejo, Novikov, Barth-Maron, Gimenez, Sulsky, Kay, Springenberg, et~al.]{27}
Scott Reed, Konrad Zolna, Emilio Parisotto, Sergio~Gomez Colmenarejo, Alexander Novikov, Gabriel Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay, Jost~Tobias Springenberg, et~al.
\newblock A generalist agent.
\newblock \emph{arXiv preprint arXiv:2205.06175}, 2022.

\bibitem[Smith et~al.(2022)Smith, Warrington, and Linderman]{16}
Jimmy~TH Smith, Andrew Warrington, and Scott~W Linderman.
\newblock Simplified state space layers for sequence modeling.
\newblock \emph{arXiv preprint arXiv:2208.04933}, 2022.

\bibitem[Sutton et~al.(1999)Sutton, McAllester, Singh, and Mansour]{38}
Richard~S Sutton, David McAllester, Satinder Singh, and Yishay Mansour.
\newblock Policy gradient methods for reinforcement learning with function approximation.
\newblock \emph{Advances in neural information processing systems}, 12, 1999.

\bibitem[Torabi et~al.(2018)Torabi, Warnell, and Stone]{30}
Faraz Torabi, Garrett Warnell, and Peter Stone.
\newblock Behavioral cloning from observation.
\newblock \emph{arXiv preprint arXiv:1805.01954}, 2018.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{4}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Wang et~al.(2016)Wang, Kurth-Nelson, Tirumala, Soyer, Leibo, Munos, Blundell, Kumaran, and Botvinick]{33}
Jane~X Wang, Zeb Kurth-Nelson, Dhruva Tirumala, Hubert Soyer, Joel~Z Leibo, Remi Munos, Charles Blundell, Dharshan Kumaran, and Matt Botvinick.
\newblock Learning to reinforcement learn.
\newblock \emph{arXiv preprint arXiv:1611.05763}, 2016.

\bibitem[Yu et~al.(2021)Yu, Kumar, Rafailov, Rajeswaran, Levine, and Finn]{41}
Tianhe Yu, Aviral Kumar, Rafael Rafailov, Aravind Rajeswaran, Sergey Levine, and Chelsea Finn.
\newblock Combo: Conservative offline model-based policy optimization.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 28954--28967, 2021.

\bibitem[Zahavy et~al.(2020)Zahavy, Xu, Veeriah, Hessel, Oh, van Hasselt, Silver, and Singh]{34}
Tom Zahavy, Zhongwen Xu, Vivek Veeriah, Matteo Hessel, Junhyuk Oh, Hado~P van Hasselt, David Silver, and Satinder Singh.
\newblock A self-tuning actor-critic algorithm.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 20913--20924, 2020.

\bibitem[Zhu et~al.(2024)Zhu, Liao, Zhang, Wang, Liu, and Wang]{11}
Lianghui Zhu, Bencheng Liao, Qian Zhang, Xinlong Wang, Wenyu Liu, and Xinggang Wang.
\newblock Vision mamba: Efficient visual representation learning with bidirectional state space model.
\newblock \emph{arXiv preprint arXiv:2401.09417}, 2024.

\end{thebibliography}
