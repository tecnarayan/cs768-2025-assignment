% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{tao2018digital}
F.~Tao, J.~Cheng, Q.~Qi, M.~Zhang, H.~Zhang, and F.~Sui, ``Digital twin-driven product design, manufacturing and service with big data,'' \emph{The International Journal of Advanced Manufacturing Technology}, vol.~94, pp. 3563--3576, 2018.

\bibitem{corral2020digital}
J.~Corral-Acero, F.~Margara, M.~Marciniak, C.~Rodero, F.~Loncaric, Y.~Feng, A.~Gilbert, J.~F. Fernandes, H.~A. Bukhari, A.~Wajdan \emph{et~al.}, ``The ‘digital twin’to enable the vision of precision cardiology,'' \emph{European heart journal}, vol.~41, no.~48, pp. 4556--4564, 2020.

\bibitem{simon1996sciences}
H.~A. Simon, \emph{The sciences of the artificial}.\hskip 1em plus 0.5em minus 0.4em\relax MIT press, 1996.

\bibitem{ladyman2013complex}
J.~Ladyman, J.~Lambert, and K.~Wiesner, ``What is a complex system?'' \emph{European Journal for Philosophy of Science}, vol.~3, pp. 33--67, 2013.

\bibitem{qi2018digital}
Q.~Qi and F.~Tao, ``Digital twin and big data towards smart manufacturing and industry 4.0: 360 degree comparison,'' \emph{Ieee Access}, vol.~6, pp. 3585--3593, 2018.

\bibitem{iranzo2021epidemiological}
V.~Iranzo and S.~P{\'e}rez-Gonz{\'a}lez, ``Epidemiological models and covid-19: a comparative view,'' \emph{History and Philosophy of the Life Sciences}, vol.~43, no.~3, p. 104, 2021.

\bibitem{bozic2013evolutionary}
I.~Bozic, J.~G. Reiter, B.~Allen, T.~Antal, K.~Chatterjee, P.~Shah, Y.~S. Moon, A.~Yaqubie, N.~Kelly, D.~T. Le \emph{et~al.}, ``Evolutionary dynamics of cancer in response to targeted combination therapy,'' \emph{elife}, vol.~2, p. e00747, 2013.

\bibitem{rosen2015importance}
R.~Rosen, G.~Von~Wichert, G.~Lo, and K.~D. Bettenhausen, ``About the importance of autonomy and digital twins for the future of manufacturing,'' \emph{Ifac-papersonline}, vol.~48, no.~3, pp. 567--572, 2015.

\bibitem{erol2020digital}
T.~Erol, A.~F. Mendi, and D.~Do{\u{g}}an, ``The digital twin revolution in healthcare,'' in \emph{2020 4th international symposium on multidisciplinary studies and innovative technologies (ISMSIT)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2020, pp. 1--7.

\bibitem{koza1994genetic}
J.~R. Koza, ``Genetic programming as a means for programming computers by natural selection,'' \emph{Statistics and computing}, vol.~4, pp. 87--112, 1994.

\bibitem{brunton2016discovering}
S.~L. Brunton, J.~L. Proctor, and J.~N. Kutz, ``Discovering governing equations from data by sparse identification of nonlinear dynamical systems,'' \emph{Proceedings of the national academy of sciences}, vol. 113, no.~15, pp. 3932--3937, 2016.

\bibitem{ha2018recurrent}
D.~Ha and J.~Schmidhuber, ``Recurrent world models facilitate policy evolution,'' \emph{Advances in neural information processing systems}, vol.~31, 2018.

\bibitem{yoon2019time}
J.~Yoon, D.~Jarrett, and M.~Van~der Schaar, ``Time-series generative adversarial networks,'' \emph{Advances in neural information processing systems}, vol.~32, 2019.

\bibitem{chen2018neural}
R.~T. Chen, Y.~Rubanova, J.~Bettencourt, and D.~K. Duvenaud, ``Neural ordinary differential equations,'' \emph{Advances in neural information processing systems}, vol.~31, 2018.

\bibitem{raissi2019physics}
M.~Raissi, P.~Perdikaris, and G.~E. Karniadakis, ``Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations,'' \emph{Journal of Computational physics}, vol. 378, pp. 686--707, 2019.

\bibitem{faure2023neural}
L.~Faure, B.~Mollet, W.~Liebermeister, and J.-L. Faulon, ``A neural-mechanistic hybrid approach improving the predictive power of genome-scale metabolic models,'' \emph{Nature Communications}, vol.~14, no.~1, p. 4669, 2023.

\bibitem{pinto2023general}
J.~Pinto, J.~R. Ramos, R.~S. Costa, and R.~Oliveira, ``A general hybrid modeling framework for systems biology applications: Combining mechanistic knowledge with deep neural networks under the sbml standard,'' \emph{AI}, vol.~4, no.~1, pp. 303--318, 2023.

\bibitem{wang2023hybrid}
P.~Wang, Z.~Zhu, W.~Liang, L.~Liao, and J.~Wan, ``Hybrid mechanistic and neural network modeling of nuclear reactors,'' \emph{Energy}, vol. 282, p. 128931, 2023.

\bibitem{cheng2019control}
R.~Cheng, A.~Verma, G.~Orosz, S.~Chaudhuri, Y.~Yue, and J.~Burdick, ``Control regularization for reduced variance reinforcement learning,'' in \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2019, pp. 1141--1150.

\bibitem{real2017large}
E.~Real, S.~Moore, A.~Selle, S.~Saxena, Y.~L. Suematsu, J.~Tan, Q.~V. Le, and A.~Kurakin, ``Large-scale evolution of image classifiers,'' in \emph{International conference on machine learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2017, pp. 2902--2911.

\bibitem{mundhenk2021symbolic}
T.~N. Mundhenk, M.~Landajuela, R.~Glatt, C.~P. Santiago, D.~M. Faissol, and B.~K. Petersen, ``Symbolic regression via neural-guided genetic programming population seeding,'' in \emph{Proceedings of the 35th International Conference on Neural Information Processing Systems}, 2021, pp. 24\,912--24\,923.

\bibitem{brown2020language}
T.~Brown, B.~Mann, N.~Ryder, M.~Subbiah, J.~D. Kaplan, P.~Dhariwal, A.~Neelakantan, P.~Shyam, G.~Sastry, A.~Askell \emph{et~al.}, ``Language models are few-shot learners,'' \emph{Advances in neural information processing systems}, vol.~33, pp. 1877--1901, 2020.

\bibitem{wei2022chain}
J.~Wei, X.~Wang, D.~Schuurmans, M.~Bosma, F.~Xia, E.~Chi, Q.~V. Le, D.~Zhou \emph{et~al.}, ``Chain-of-thought prompting elicits reasoning in large language models,'' \emph{Advances in neural information processing systems}, vol.~35, pp. 24\,824--24\,837, 2022.

\bibitem{chowdhery2023palm}
A.~Chowdhery, S.~Narang, J.~Devlin, M.~Bosma, G.~Mishra, A.~Roberts, P.~Barham, H.~W. Chung, C.~Sutton, S.~Gehrmann \emph{et~al.}, ``Palm: Scaling language modeling with pathways,'' \emph{Journal of Machine Learning Research}, vol.~24, no. 240, pp. 1--113, 2023.

\bibitem{kearns1994introduction}
M.~J. Kearns and U.~Vazirani, \emph{An introduction to computational learning theory}.\hskip 1em plus 0.5em minus 0.4em\relax MIT press, 1994.

\bibitem{simon1962architecture}
H.~A. Simon, ``The architecture of complexity,'' \emph{Proceedings of the American philosophical society}, vol. 106, no.~6, pp. 467--482, 1962.

\bibitem{rogers2022chaos}
T.~L. Rogers, B.~J. Johnson, and S.~B. Munch, ``Chaos is not rare in natural ecosystems,'' \emph{Nature Ecology \& Evolution}, vol.~6, no.~8, pp. 1105--1111, 2022.

\bibitem{sokolov2021hybrid}
M.~Sokolov, M.~von Stosch, H.~Narayanan, F.~Feidl, and A.~Butt{\'e}, ``Hybrid modeling—a key enabler towards realizing digital twins in biopharma?'' \emph{Current Opinion in Chemical Engineering}, vol.~34, p. 100715, 2021.

\bibitem{chaudhuri2021neurosymbolic}
S.~Chaudhuri, K.~Ellis, O.~Polozov, R.~Singh, A.~Solar-Lezama, Y.~Yue \emph{et~al.}, ``Neurosymbolic programming,'' \emph{Foundations and Trends{\textregistered} in Programming Languages}, vol.~7, no.~3, pp. 158--243, 2021.

\bibitem{tsoularis2002analysis}
A.~Tsoularis and J.~Wallace, ``Analysis of logistic growth models,'' \emph{Mathematical biosciences}, vol. 179, no.~1, pp. 21--55, 2002.

\bibitem{paszke2019pytorch}
A.~Paszke, S.~Gross, F.~Massa, A.~Lerer, J.~Bradbury, G.~Chanan, T.~Killeen, Z.~Lin, N.~Gimelshein, L.~Antiga \emph{et~al.}, ``Pytorch: An imperative style, high-performance deep learning library,'' \emph{Advances in neural information processing systems}, vol.~32, 2019.

\bibitem{kingma2014adam}
D.~P. Kingma and J.~Ba, ``Adam: A method for stochastic optimization,'' \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{holland1992genetic}
J.~H. Holland, ``Genetic algorithms,'' \emph{Scientific american}, vol. 267, no.~1, pp. 66--73, 1992.

\bibitem{rabiner1989tutorial}
L.~R. Rabiner, ``A tutorial on hidden markov models and selected applications in speech recognition,'' \emph{Proceedings of the IEEE}, vol.~77, no.~2, pp. 257--286, 1989.

\bibitem{kalman1960new}
R.~Kalman, ``A new approach to linear filtering and prediction problems,'' \emph{Trans. ASME, D}, vol.~82, pp. 35--44, 1960.

\bibitem{li2013hybrid}
L.~Li, Y.~Zhao, D.~Jiang, Y.~Zhang, F.~Wang, I.~Gonzalez, E.~Valentin, and H.~Sahli, ``Hybrid deep neural network--hidden markov model (dnn-hmm) based speech emotion recognition,'' in \emph{2013 Humaine association conference on affective computing and intelligent interaction}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2013, pp. 312--317.

\bibitem{krishnan2015deep}
R.~G. Krishnan, U.~Shalit, and D.~Sontag, ``Deep kalman filters,'' \emph{arXiv preprint arXiv:1511.05121}, 2015.

\bibitem{elman1990finding}
J.~L. Elman, ``Finding structure in time,'' \emph{Cognitive science}, vol.~14, no.~2, pp. 179--211, 1990.

\bibitem{hochreiter1997long}
S.~Hochreiter and J.~Schmidhuber, ``Long short-term memory,'' \emph{Neural computation}, vol.~9, no.~8, pp. 1735--1780, 1997.

\bibitem{cho2014learning}
K.~Cho, B.~Van~Merri{\"e}nboer, C.~Gulcehre, D.~Bahdanau, F.~Bougares, H.~Schwenk, and Y.~Bengio, ``Learning phrase representations using rnn encoder-decoder for statistical machine translation,'' \emph{arXiv preprint arXiv:1406.1078}, 2014.

\bibitem{sutskever2014sequence}
I.~Sutskever, O.~Vinyals, and Q.~V. Le, ``Sequence to sequence learning with neural networks,'' \emph{Advances in neural information processing systems}, vol.~27, 2014.

\bibitem{bahdanau2014neural}
D.~Bahdanau, K.~Cho, and Y.~Bengio, ``Neural machine translation by jointly learning to align and translate,'' \emph{arXiv preprint arXiv:1409.0473}, 2014.

\bibitem{vaswani2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez, {\L}.~Kaiser, and I.~Polosukhin, ``Attention is all you need,'' \emph{Advances in neural information processing systems}, vol.~30, 2017.

\bibitem{dupont2019augmented}
E.~Dupont, A.~Doucet, and Y.~W. Teh, ``Augmented neural odes,'' \emph{Advances in neural information processing systems}, vol.~32, 2019.

\bibitem{holt2022neural}
S.~I. Holt, Z.~Qian, and M.~van~der Schaar, ``Neural laplace: Learning diverse classes of differential equations in the laplace domain,'' in \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2022, pp. 8811--8832.

\bibitem{zaytar2016sequence}
M.~A. Zaytar and C.~El~Amrani, ``Sequence to sequence weather forecasting with long short-term memory recurrent neural networks,'' \emph{International Journal of Computer Applications}, vol. 143, no.~11, pp. 7--11, 2016.

\bibitem{devlin2018bert}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova, ``Bert: Pre-training of deep bidirectional transformers for language understanding,'' \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem{sehovac2020deep}
L.~Sehovac and K.~Grolinger, ``Deep learning for load forecasting: Sequence to sequence recurrent neural networks with attention,'' \emph{Ieee Access}, vol.~8, pp. 36\,411--36\,426, 2020.

\bibitem{holt2023neural}
S.~Holt, A.~H{\"u}y{\"u}k, Z.~Qian, H.~Sun, and M.~van~der Schaar, ``Neural laplace control for continuous-time delayed systems,'' in \emph{International Conference on Artificial Intelligence and Statistics}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2023, pp. 1747--1778.

\bibitem{schmidt2009distilling}
M.~Schmidt and H.~Lipson, ``Distilling free-form natural laws from experimental data,'' \emph{science}, vol. 324, no. 5923, pp. 81--85, 2009.

\bibitem{qian2022dcode}
\BIBentryALTinterwordspacing
Z.~Qian, K.~Kacprzyk, and M.~van~der Schaar, ``D-{CODE}: Discovering closed-form {ODE}s from observed trajectories,'' in \emph{International Conference on Learning Representations}, 2022. [Online]. Available: \url{https://openreview.net/forum?id=wENMvIsxNN}
\BIBentrySTDinterwordspacing

\bibitem{kacprzyk2024d}
K.~Kacprzyk, Z.~Qian, and M.~van~der Schaar, ``D-cipher: discovery of closed-form partial differential equations,'' \emph{Advances in Neural Information Processing Systems}, vol.~36, 2024.

\bibitem{kacprzyk2024towards}
\BIBentryALTinterwordspacing
K.~Kacprzyk, T.~Liu, and M.~van~der Schaar, ``Towards transparent time series forecasting,'' in \emph{The Twelfth International Conference on Learning Representations}, 2024. [Online]. Available: \url{https://openreview.net/forum?id=TYXtXLYHpR}
\BIBentrySTDinterwordspacing

\bibitem{cuomo2022scientific}
S.~Cuomo, V.~S. Di~Cola, F.~Giampaolo, G.~Rozza, M.~Raissi, and F.~Piccialli, ``Scientific machine learning through physics--informed neural networks: Where we are and what’s next,'' \emph{Journal of Scientific Computing}, vol.~92, no.~3, p.~88, 2022.

\bibitem{greydanus2019hamiltonian}
S.~Greydanus, M.~Dzamba, and J.~Yosinski, ``Hamiltonian neural networks,'' \emph{Advances in neural information processing systems}, vol.~32, 2019.

\bibitem{cranmer2020lagrangian}
M.~Cranmer, S.~Greydanus, S.~Hoyer, P.~Battaglia, D.~Spergel, and S.~Ho, ``Lagrangian neural networks,'' \emph{arXiv preprint arXiv:2003.04630}, 2020.

\bibitem{yin2021augmenting}
Y.~Yin, V.~Le~Guen, J.~Dona, E.~de~B{\'e}zenac, I.~Ayed, N.~Thome, and P.~Gallinari, ``Augmenting physical models with deep networks for complex dynamics forecasting,'' \emph{Journal of Statistical Mechanics: Theory and Experiment}, vol. 2021, no.~12, p. 124012, 2021.

\bibitem{takeishi2021physics}
N.~Takeishi and A.~Kalousis, ``Physics-integrated variational autoencoders for robust and interpretable generative modeling,'' \emph{Advances in Neural Information Processing Systems}, vol.~34, pp. 14\,809--14\,821, 2021.

\bibitem{qian2021integrating}
Z.~Qian, W.~Zame, L.~Fleuren, P.~Elbers, and M.~van~der Schaar, ``Integrating expert odes into neural odes: pharmacology and disease progression,'' \emph{Advances in Neural Information Processing Systems}, vol.~34, pp. 11\,364--11\,383, 2021.

\bibitem{wehenkel2023robust}
\BIBentryALTinterwordspacing
A.~Wehenkel, J.~Behrmann, H.~Hsu, G.~Sapiro, G.~Louppe, and J.-H. Jacobsen, ``Robust hybrid learning with expert augmentation,'' \emph{Transactions on Machine Learning Research}, 2023. [Online]. Available: \url{https://openreview.net/forum?id=oe4dl4MCGY}
\BIBentrySTDinterwordspacing

\bibitem{geng2017prediction}
C.~Geng, H.~Paganetti, and C.~Grassberger, ``Prediction of {{Treatment Response}} for {{Combined Chemo-}} and {{Radiation Therapy}} for {{Non-Small Cell Lung Cancer Patients Using}} a {{Bio-Mathematical Model}},'' \emph{Scientific Reports}, vol.~7, no.~1, p. 13542, Oct. 2017.

\bibitem{bica2020estimating}
I.~Bica, A.~M. Alaa, J.~Jordon, and M.~van~der Schaar, ``Estimating counterfactual treatment outcomes over time through adversarially balanced representations,'' in \emph{International {{Conference}} on {{Learning Representations}}}, 2020.

\bibitem{seedat2022continuous}
N.~Seedat, F.~Imrie, A.~Bellot, Z.~Qian, and M.~van~der Schaar, ``Continuous-time modeling of counterfactual outcomes using neural controlled differential equations,'' \emph{arXiv preprint arXiv:2206.08311}, 2022.

\bibitem{melnychuk2022causal}
V.~Melnychuk, D.~Frauen, and S.~Feuerriegel, ``Causal transformer for estimating counterfactual outcomes,'' in \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2022, pp. 15\,293--15\,329.

\bibitem{kerr2021covasim}
C.~C. Kerr, R.~M. Stuart, D.~Mistry, R.~G. Abeysuriya, K.~Rosenfeld, G.~R. Hart, R.~C. N{\'u}{\~n}ez, J.~A. Cohen, P.~Selvaraj, B.~Hagedorn \emph{et~al.}, ``Covasim: an agent-based model of covid-19 dynamics and interventions,'' \emph{PLOS Computational Biology}, vol.~17, no.~7, p. e1009149, 2021.

\bibitem{hiltunen2013temporal}
T.~Hiltunen, L.~Jones, S.~Ellner, and N.~G. Hairston~Jr, ``Temporal dynamics of a simple community with intraguild predation: an experimental test,'' \emph{Ecology}, vol.~94, no.~4, pp. 773--779, 2013.

\bibitem{OdumBarrett1972}
E.~P. Odum and G.~W. Barrett, ``Fundamentals of ecology,'' \emph{The Journal of Wildlife Management}, vol.~36, no.~4, p. 1372, 1972.

\bibitem{alvarez2020dynode}
V.~M.~M. Alvarez, R.~Ro{\c{s}}ca, and C.~G. F{\u{a}}lcu{\c{t}}escu, ``Dynode: Neural ordinary differential equations for dynamics modeling in continuous control,'' \emph{arXiv preprint arXiv:2009.04278}, 2020.

\bibitem{rumelhart1986learning}
D.~E. Rumelhart, G.~E. Hinton, and R.~J. Williams, ``Learning representations by back-propagating errors,'' \emph{nature}, vol. 323, no. 6088, pp. 533--536, 1986.

\bibitem{holt2024active}
S.~Holt, A.~H{\"u}y{\"u}k, and M.~van~der Schaar, ``Active observing in continuous-time control,'' \emph{Advances in Neural Information Processing Systems}, vol.~36, 2024.

\bibitem{holt2023deep}
\BIBentryALTinterwordspacing
S.~Holt, Z.~Qian, and M.~van~der Schaar, ``Deep generative symbolic regression,'' in \emph{The Eleventh International Conference on Learning Representations}, 2023. [Online]. Available: \url{https://openreview.net/forum?id=o7koEEMA1bR}
\BIBentrySTDinterwordspacing

\bibitem{kacprzyk2024ode}
\BIBentryALTinterwordspacing
K.~Kacprzyk, S.~Holt, J.~Berrevoets, Z.~Qian, and M.~van~der Schaar, ``{ODE} discovery for longitudinal heterogeneous treatment effects inference,'' in \emph{The Twelfth International Conference on Learning Representations}, 2024. [Online]. Available: \url{https://openreview.net/forum?id=pxI5IPeWgW}
\BIBentrySTDinterwordspacing

\bibitem{liu2024large}
\BIBentryALTinterwordspacing
T.~Liu, N.~Astorga, N.~Seedat, and M.~van~der Schaar, ``Large language models to enhance bayesian optimization,'' in \emph{The Twelfth International Conference on Learning Representations}, 2024. [Online]. Available: \url{https://openreview.net/forum?id=OOxotBmGol}
\BIBentrySTDinterwordspacing

\bibitem{yang2024large}
\BIBentryALTinterwordspacing
C.~Yang, X.~Wang, Y.~Lu, H.~Liu, Q.~V. Le, D.~Zhou, and X.~Chen, ``Large language models as optimizers,'' in \emph{The Twelfth International Conference on Learning Representations}, 2024. [Online]. Available: \url{https://openreview.net/forum?id=Bb4VGOWELI}
\BIBentrySTDinterwordspacing

\bibitem{chen2021evaluating}
M.~Chen, J.~Tworek, H.~Jun, Q.~Yuan, H.~P. D.~O. Pinto, J.~Kaplan, H.~Edwards, Y.~Burda, N.~Joseph, G.~Brockman \emph{et~al.}, ``Evaluating large language models trained on code,'' \emph{arXiv preprint arXiv:2107.03374}, 2021.

\bibitem{holt2024lmac}
\BIBentryALTinterwordspacing
S.~Holt, M.~R. Luyten, and M.~van~der Schaar, ``L2{MAC}: Large language model automatic computer for extensive code generation,'' in \emph{The Twelfth International Conference on Learning Representations}, 2024. [Online]. Available: \url{https://openreview.net/forum?id=EhrzQwsV4K}
\BIBentrySTDinterwordspacing

\bibitem{holt2024datadriven}
S.~Holt, Z.~Qian, T.~Liu, J.~Weatherall, and M.~van~der Schaar, ``Data-driven discovery of dynamical systems in pharmacology using large language models,'' in \emph{The Thirty-eighth Annual Conference on Neural Information Processing Systems}, 2024.

\bibitem{astorga2024poca}
N.~Astorga, T.~Liu, N.~Seedat, and M.~van~der Schaar, ``Partially observable cost-aware active-learning with large language models,'' in \emph{The Thirty-Eighth Annual Conference on Neural Information Processing Systems}, 2024.

\bibitem{bonnaffe2023fast}
W.~Bonnaff{\'e} and T.~Coulson, ``Fast fitting of neural ordinary differential equations by bayesian neural gradient matching to infer ecological interactions from time-series data,'' \emph{Methods in Ecology and Evolution}, vol.~14, no.~6, pp. 1543--1563, 2023.

\bibitem{kumar2017weight}
S.~K. Kumar, ``On weight initialization in deep neural networks,'' \emph{arXiv preprint arXiv:1704.08863}, 2017.

\bibitem{graves2007multi}
A.~Graves, S.~Fern{\'a}ndez, and J.~Schmidhuber, ``Multi-dimensional recurrent neural networks,'' in \emph{International conference on artificial neural networks}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2007, pp. 549--558.

\bibitem{petersen2020deep}
B.~K. Petersen, M.~L. Larma, T.~N. Mundhenk, C.~P. Santiago, S.~K. Kim, and J.~T. Kim, ``Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients,'' in \emph{International Conference on Learning Representations}, 2020.

\bibitem{hsiang2020effect}
S.~Hsiang, D.~Allen, S.~Annan-Phan, K.~Bell, I.~Bolliger, T.~Chong, H.~Druckenmiller, L.~Y. Huang, A.~Hultgren, E.~Krasovich \emph{et~al.}, ``The effect of large-scale anti-contagion policies on the covid-19 pandemic,'' \emph{Nature}, vol. 584, no. 7820, pp. 262--267, 2020.

\bibitem{bjornstad2020seirs}
O.~N. Bj{\o}rnstad, K.~Shea, M.~Krzywinski, and N.~Altman, ``The seirs model for infectious disease dynamics.'' \emph{Nature methods}, vol.~17, no.~6, pp. 557--559, 2020.

\bibitem{brauer2012mathematical}
F.~Brauer, C.~Castillo-Chavez, and C.~Castillo-Chavez, \emph{Mathematical models in population biology and epidemiology}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2012, vol.~2.

\end{thebibliography}
