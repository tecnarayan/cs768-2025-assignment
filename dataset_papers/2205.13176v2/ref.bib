@article{ma2019data,
  title={Data poisoning against differentially-private learners: Attacks and defenses},
  author={Ma, Yuzhe and Zhu, Xiaojin and Hsu, Justin},
  journal={IJCAI},
  year={2019}
}

@article{sison1995simultaneous,
  title={Simultaneous confidence intervals and sample size determination for multinomial proportions},
  author={Sison, Cristina P and Glaz, Joseph},
  journal={Journal of the American Statistical Association},
  volume={90},
  number={429},
  pages={366--369},
  year={1995},
  publisher={Taylor \& Francis}
}

@inproceedings{jia2021intrinsic,
title={Intrinsic Certified Robustness of Bagging against Data Poisoning Attacks},
author={Jinyuan Jia and Xiaoyu Cao and Neil Zhenqiang Gong},
booktitle={AAAI},
year={2021}
}

@article{nelson2008exploiting,
  title={Exploiting machine learning to subvert your spam filter.},
  author={Nelson, Blaine and Barreno, Marco and Chi, Fuching Jack and Joseph, Anthony D and Rubinstein, Benjamin IP and Saini, Udam and Sutton, Charles and Tygar, J Doug and Xia, Kai},
  journal={LEET},
  year={2008}
}

@inproceedings{biggio2012poisoning,
  title={Poisoning attacks against support vector machines},
  author={Biggio, Battista and Nelson, Blaine and Laskov, Pavel},
  booktitle={ICML},
  year={2012}
}


@inproceedings{jia2022rnn,
  title={Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks},
  author={{Jinyuan Jia, Yupei Liu, Xiaoyu Cao, and Neil Zhenqiang Gong}},
  booktitle={AAAI},
  year={2022}
}

@article{hung2019rank,
  title={Rank verification for exponential families},
  author={Hung, Kenneth and Fithian, William and others},
  journal={Annals of Statistics},
  volume={47},
  number={2},
  pages={758--782},
  year={2019},
  publisher={Institute of Mathematical Statistics}
}

@article{huang2020metapoison,
  title={MetaPoison: Practical General-purpose Clean-label Data Poisoning},
  author={Huang, W Ronny and Geiping, Jonas and Fowl, Liam and Taylor, Gavin and Goldstein, Tom},
  journal={arXiv preprint arXiv:2004.00225},
  year={2020}
}

@article{chen2017targeted,
	title="Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning",
	author="Xinyun {Chen} and Chang {Liu} and Bo {Li} and Kimberly {Lu} and Dawn {Song}",
	journal="arXiv preprint arXiv:1712.05526",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2774423163",
	year="2017"
}

@inproceedings{rebuffi2017icarl,
	title="iCaRL: Incremental Classifier and Representation Learning",
	author="Sylvestre-Alvise {Rebuffi} and Alexander {Kolesnikov} and Georg {Sperl} and Christoph H. {Lampert}",
	booktitle="2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
	volume="2017",
	pages="5533--5542",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2964189064",
	year="2017"
}

@inproceedings{liu2018trojaning,
	title="Trojaning Attack on Neural Networks",
	author="Yingqi {Liu} and Shiqing {Ma} and Yousra {Aafer} and Wen-Chuan {Lee} and Juan {Zhai} and Weihang {Wang} and Xiangyu {Zhang}",
	booktitle="Proceedings 2018 Network and Distributed System Security Symposium",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2753783305",
	year="2018"
}


@inproceedings{zhao2020clean,
	title="Clean-Label Backdoor Attacks on Video Recognition Models",
	author="Shihao {Zhao} and Xingjun {Ma} and Xiang {Zheng} and James {Bailey} and Jingjing {Chen} and Yu-Gang {Jiang}",
	booktitle="CVPR 2020: Computer Vision and Pattern Recognition",
	pages="14443--14452",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/3034414373",
	year="2020"
}

@article{turner2019label,
	title="Label-Consistent Backdoor Attacks",
	author="Alexander {Turner} and Dimitris {Tsipras} and Aleksander {Madry}",
	journal="arXiv preprint arXiv:1912.02771",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2993846550",
	year="2019"
}

@inproceedings{ji2017backdoor,
  title={Backdoor attacks against learning systems},
  author={Ji, Yujie and Zhang, Xinyang and Wang, Ting},
  booktitle={2017 IEEE Conference on Communications and Network Security (CNS)},
  pages={1--9},
  year={2017},
  organization={IEEE}
}

@article{zhang2020backdoor,
	title="Backdoor Attacks to Graph Neural Networks.",
	author="Zaixi {Zhang} and Jinyuan {Jia} and Binghui {Wang} and Neil Zhenqiang {Gong}",
	journal="arXiv preprint arXiv:2006.11165",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/3036721937",
	year="2020"
}

@inproceedings{yao2019latent,
	title="Latent Backdoor Attacks on Deep Neural Networks",
	author="Yuanshun {Yao} and Huiying {Li} and Haitao {Zheng} and Ben Y. {Zhao}",
	booktitle="CCS '19 Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security",
	pages="2041--2055",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2985913519",
	year="2019"
}

@inproceedings{mitchell1997machine,
  title={Machine learning meets natural language},
  author={Mitchell, Tom},
  booktitle={EPIA},
  pages={391},
  year={1997}
}

@article{zhai2020macer,
  title={Macer: Attack-free and scalable robust training via maximizing certified radius},
  author={Zhai, Runtian and Dan, Chen and He, Di and Zhang, Huan and Gong, Boqing and Ravikumar, Pradeep and Hsieh, Cho-Jui and Wang, Liwei},
  journal={arXiv preprint arXiv:2001.02378},
  year={2020}
}


@article{peri2019deep,
  title={Deep k-nn defense against clean-label data poisoning attacks},
  author={Peri, Neehar and Gupta, Neal and Ronny Huang, W and Fowl, Liam and Zhu, Chen and Feizi, Soheil and Goldstein, Tom and Dickerson, John P},
  journal={arXiv},
  pages={arXiv--1909},
  year={2019}
}

@article{muller2020data,
  title={Data Poisoning Attacks on Regression Learning and Corresponding Defenses},
  author={M{\"u}ller, Nicolas Michael and Kowatsch, Daniel and B{\"o}ttinger, Konstantin},
  journal={arXiv preprint arXiv:2009.07008},
  year={2020}
}

@article{koh2018stronger,
  title={Stronger data poisoning attacks break data sanitization defenses},
  author={Koh, Pang Wei and Steinhardt, Jacob and Liang, Percy},
  journal={arXiv preprint arXiv:1811.00741},
  year={2018}
}

@inproceedings{paudice2018label,
  title={Label sanitization against label flipping poisoning attacks},
  author={Paudice, Andrea and Mu{\~n}oz-Gonz{\'a}lez, Luis and Lupu, Emil C},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={5--15},
  year={2018},
  organization={Springer}
}

@inproceedings{chen2019deepinspect,
	title="DeepInspect: A Black-box Trojan Detection and Mitigation Framework for Deep Neural Networks",
	author="Huili {Chen} and Cheng {Fu} and Jishen {Zhao} and Farinaz {Koushanfar}",
	booktitle="Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence",
	pages="4658--4664",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2966689772",
	year="2019"
}

@article{guo2019tabor,
	title="TABOR: A Highly Accurate Approach to Inspecting and Restoring Trojan Backdoors in AI Systems.",
	author="Wenbo {Guo} and Lun {Wang} and Xinyu {Xing} and Min {Du} and Dawn {Song}",
	journal="arXiv preprint arXiv:1908.01763",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2966187620",
	year="2019"
}

@inproceedings{wang2019neural,
	title="Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks",
	author="Bolun {Wang} and Yuanshun {Yao} and Shawn {Shan} and Huiying {Li} and Bimal {Viswanath} and Haitao {Zheng} and Ben Y. {Zhao}",
	booktitle="2019 IEEE Symposium on Security and Privacy (SP)",
	pages="707--723",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2934843808",
	year="2019"
}

@inproceedings{tran2018spectral,
	title="Spectral Signatures in Backdoor Attacks",
	author="Brandon {Tran} and Jerry {Li} and Aleksander {Madry}",
	booktitle="Advances in Neural Information Processing Systems",
	pages="8000--8010",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2964041528",
	year="2018"
}

@article{chen2018detecting,
  title={Detecting backdoor attacks on deep neural networks by activation clustering},
  author={Chen, Bryant and Carvalho, Wilka and Baracaldo, Nathalie and Ludwig, Heiko and Edwards, Benjamin and Lee, Taesung and Molloy, Ian and Srivastava, Biplav},
  journal={arXiv preprint arXiv:1811.03728},
  year={2018}
}

@inproceedings{gao2019strip,
	title="STRIP: a defence against trojan attacks on deep neural networks",
	author="Yansong {Gao} and Change {Xu} and Derui {Wang} and Shiping {Chen} and Damith C. {Ranasinghe} and Surya {Nepal}",
	booktitle="Proceedings of the 35th Annual Computer Security Applications Conference on ",
	pages="113--125",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2990270730",
	year="2019"
}

@inproceedings{liu2019abs,
	title="ABS: Scanning Neural Networks for Back-doors by Artificial Brain Stimulation",
	author="Yingqi {Liu} and Wen-Chuan {Lee} and Guanhong {Tao} and Shiqing {Ma} and Yousra {Aafer} and Xiangyu {Zhang}",
	booktitle="CCS '19 Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security",
	pages="1265--1282",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2986013765",
	year="2019"
}

@inproceedings{qiao2019defending,
	title="Defending Neural Backdoors via Generative Distribution Modeling",
	author="Ximing {Qiao} and Yukun {Yang} and Hai {Li}",
	booktitle="NeurIPS 2019 : Thirty-third Conference on Neural Information Processing Systems",
	pages="14004--14013",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2970200861",
	year="2019"
}

@inproceedings{szegedy2014intriguing,
	title="Intriguing properties of neural networks",
	author="Christian {Szegedy} and Wojciech {Zaremba} and Ilya {Sutskever} and Joan {Bruna} and Dumitru {Erhan} and Ian {Goodfellow} and Rob {Fergus}",
	booktitle="ICLR 2014 : International Conference on Learning Representations (ICLR) 2014",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2964153729",
	year="2014"
}

@inproceedings{he2016deep,
	title="Deep Residual Learning for Image Recognition",
	author="Kaiming {He} and Xiangyu {Zhang} and Shaoqing {Ren} and Jian {Sun}",
	booktitle="2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
	pages="770--778",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2194775991",
	year="2016"
}

@inproceedings{deng2009imagenet,
	title="ImageNet: A large-scale hierarchical image database",
	author="Jia {Deng} and Wei {Dong} and Richard {Socher} and Li-Jia {Li} and Kai {Li} and Li {Fei-Fei}",
	booktitle="2009 IEEE Conference on Computer Vision and Pattern Recognition",
	pages="248--255",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2108598243",
	year="2009"
}

@article{lecun2001gradient,
	title="Gradient-based learning applied to document recognition",
	author="Yann {Lecun} and Leon {Bottou} and Yoshua {Bengio} and Patrick {Haffner}",
	journal="Intelligent Signal Processing",
	pages="306--351",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2310919327",
	year="2001"
}

@inproceedings{Rosenfeld2019CertifiedRT,
  author    = {Elan Rosenfeld and
               Ezra Winston and
               Pradeep Ravikumar and
               Zico Kolter},
  title     = {Certified Robustness to Label-Flipping Attacks via Randomized Smoothing},
  booktitle = {ICML},
  year      = {2020}
}

@inproceedings{xiao2015is,
	title="Is Feature Selection Secure against Training Data Poisoning",
	author="Huang {Xiao} and Battista {Biggio} and Gavin {Brown} and Giorgio {Fumera} and Claudia {Eckert} and Fabio {Roli}",
	booktitle="Proceedings of The 32nd International Conference on Machine Learning",
	volume="2",
	pages="1689--1698",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2167421362",
	year="2015"
}


@article{Wang2020OnCR,
  title={On Certifying Robustness against Backdoor Attacks via Randomized Smoothing},
  author={Binghui Wang and Xiaoyu Cao and Jin-Yuan Jia and Neil Zhenqiang Gong},
  journal={CVPR Workshop},
  year={2020}
}

@article{weber2020rab,
  title={RAB: Provable Robustness Against Backdoor Attacks},
  author={Weber, Maurice and Xu, Xiaojun and Karlas, Bojan and Zhang, Ce and Li, Bo},
  journal={arXiv preprint arXiv:2003.08904},
  year={2020}
}

@article{Li2020ProvableRL,
  title={Provable Robust Learning Based on Transformation-Specific Smoothing},
  author={Linyi Li and Maurice Weber and Xiaojun Xu and Luka Rimanic and Tao Xie and Ce Zhang and Bo Li},
  journal={ArXiv},
  year={2020},
  volume={abs/2002.12398}
}

@article{RN52,
  title={On the effectiveness of interval bound propagation for training verifiably robust models},
  author={Gowal, Sven and Dvijotham, Krishnamurthy and Stanforth, Robert and Bunel, Rudy and Qin, Chongli and Uesato, Jonathan and Arandjelovic, Relja and Mann, Timothy and Kohli, Pushmeet},
  journal={arXiv preprint arXiv:1810.12715},
  year={2018}
}

@inproceedings{RN54,
  title={Certified robustness to adversarial examples with differential privacy},
  author={Lecuyer, Mathias and Atlidakis, Vaggelis and Geambasu, Roxana and Hsu, Daniel and Jana, Suman},
  booktitle={2019 IEEE Symposium on Security and Privacy (SP)},
  pages={656--672},
  year={2019},
  organization={IEEE}
}

@article{RN56,
  title={Towards stable and efficient training of verifiably robust neural networks},
  author={Zhang, Huan and Chen, Hongge and Xiao, Chaowei and Li, Bo and Boning, Duane and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:1906.06316},
  year={2019}
}

@article{RN55,
  title={On the effectiveness of interval bound propagation for training verifiably robust models},
  author={Gowal, Sven and Dvijotham, Krishnamurthy and Stanforth, Robert and Bunel, Rudy and Qin, Chongli and Uesato, Jonathan and Arandjelovic, Relja and Mann, Timothy and Kohli, Pushmeet},
  journal={arXiv preprint arXiv:1810.12715},
  year={2018}
}

@inproceedings{RN41,
   author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
   title = {Attention is all you need},
   booktitle = {Advances in neural information processing systems},
   pages = {5998-6008},
   type = {Conference Proceedings},
   year={2017}
}

@article{RN45,
  title={Physical adversarial examples for object detectors},
  author={Eykholt, Kevin and Evtimov, Ivan and Fernandes, Earlence and Li, Bo and Rahmati, Amir and Tramer, Florian and Prakash, Atul and Kohno, Tadayoshi and Song, Dawn},
  journal={arXiv preprint arXiv:1807.07769},
  year={2018}
}

@article{RN46,
  title={Adversarial examples in the physical world},
  author={Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
  journal={arXiv preprint arXiv:1607.02533},
  year={2016}
}

@inproceedings{RN51,
title={Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing},
author={Jinyuan Jia and Xiaoyu Cao and Binghui Wang and Neil Zhenqiang Gong},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=BkeWw6VFwr}
}
@inproceedings{RN57,
	title="Tight Certificates of Adversarial Robustness for Randomly ensemble classifiers",
	author="Guang-He {Lee} and Yang {Yuan} and Shiyu {Chang} and Tommi S. {Jaakkola}",
	booktitle="Advances in Neural Information Processing Systems",
	pages="4911--4922",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2990740676",
	year="2019"
}

@article{zhang2020black,
	title="Black-Box Certification with Randomized Smoothing: A Functional Optimization Based Framework",
	author="Dinghuai {Zhang} and Mao {Ye} and Chengyue {Gong} and Zhanxing {Zhu} and Qiang {Liu}",
	journal="arXiv preprint arXiv:2002.09169",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/3008683143",
	year="2020"
}


@article{gao2020analyzing,
	title="Analyzing Accuracy Loss in Randomized Smoothing Defenses.",
	author="Yue {Gao} and Harrison {Rosenberg} and Kassem {Fawaz} and Somesh {Jha} and Justin {Hsu}",
	journal="arXiv preprint arXiv:2003.01595",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/3010516233",
	year="2020"
}

@inproceedings{feng2020regularized,
	title="Regularized Training and Tight Certification for ensemble classifier with Provable Robustness",
	author="Huijie {Feng} and Chunpeng {Wu} and Guoyang {Chen} and Weifeng {Zhang} and Yang {Ning}",
	booktitle="AAAI 2020 : The Thirty-Fourth AAAI Conference on Artificial Intelligence",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2997227310",
	year="2020"
}

@article{wang2020on,
	title="On Certifying Robustness against Backdoor Attacks via Randomized Smoothing.",
	author="Binghui {Wang} and Xiaoyu {Cao} and Jinyuan {Jia} and Neil Zhenqiang {Gong}",
	journal="arXiv preprint arXiv:2002.11750",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/3008901592",
	year="2020"
}


@article{kumar2020curse,
	title="Curse of Dimensionality on Randomized Smoothing for Certifiable Robustness.",
	author="Aounon {Kumar} and Alexander {Levine} and Tom {Goldstein} and Soheil {Feizi}",
	journal="arXiv preprint arXiv:2002.03239",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/3005384972",
	year="2020"
}

@inproceedings{dvijotham2020a,
	title="A FRAMEWORK FOR ROBUSTNESS CERTIFICATION OF ensemble classifierS USING F-DIVERGENCES",
	author="Krishnamurthy {Dvijotham} and Jamie {Hayes} and Borja {Balle} and Zico {Kolter} and Chongli {Qin} and Andras {Gyorgy} and Kai {Xiao} and Sven {Gowal} and Pushmeet {Kohli}",
	booktitle="ICLR 2020 : Eighth International Conference on Learning Representations",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2996463194",
	year="2020"
}

@misc{diamond2016cvxpy,
Author = {Steven Diamond and Stephen Boyd},
Title = {CVXPY: A Python-Embedded Modeling Language for Convex Optimization},
Year = {2016},
Eprint = {arXiv:1603.00943},
}

@article{yang2020randomized,
	title="Randomized Smoothing of All Shapes and Sizes.",
	author="Greg {Yang} and Tony {Duan} and Edward {Hu} and Hadi {Salman} and Ilya P. {Razenshteyn} and Jerry {Li}",
	journal="arXiv preprint arXiv:2002.08118",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/3008151842",
	year="2020"
}

@article{mohapatra2020rethinking,
	title="Rethinking Randomized Smoothing for Adversarial Robustness.",
	author="Jeet {Mohapatra} and Ching-Yun {Ko} and Tsui-Wei {Weng} and Sijia {Liu} and Pin-Yu {Chen} and Luca {Daniel}",
	journal="arXiv preprint arXiv:2003.01249",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/3009096484",
	year="2020"
}
@article{teng2019ell_1,
	title="$\ell_1$ Adversarial robustness certifications: a Randomized Smoothing Approach",
	author="Jiaye {Teng} and Guang-He {Lee} and Yang {Yuan}",
	journal="",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2996921661",
	year="2019"
}

@inproceedings{jia2020certified1,
	title="Certified Robustness for Top-k Predictions against Adversarial Perturbations via Randomized Smoothing",
	author="Jinyuan {Jia} and Xiaoyu {Cao} and Binghui {Wang} and Neil Zhenqiang {Gong}",
	booktitle="ICLR 2020 : Eighth International Conference on Learning Representations",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2995053405",
	year="2020"
}

@inproceedings{jia2020certified2,
	title="Certified Robustness of Community Detection against Adversarial Structural Perturbation via Randomized Smoothing",
	author="Jinyuan {Jia} and Binghui {Wang} and Xiaoyu {Cao} and Neil Zhenqiang {Gong}",
	booktitle="WWW 2020 : The Web Conference",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/3012737746",
	year="2020"
}

@inproceedings{guo2018countering,
	title="Countering Adversarial Images using Input Transformations",
	author="Chuan {Guo} and Mayank {Rana} and Moustapha {Cisse} and Laurens van der {Maaten}",
	booktitle="ICLR 2018 : International Conference on Learning Representations 2018",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2963001136",
	year="2018"
}

@article{neyman1933on,
	title="On the Problem of the Most Efficient Tests of Statistical Hypotheses",
	author="Jerzy {Neyman} and Egon Sharpe {Pearson}",
	journal="Philosophical Transactions of the Royal Society A",
	volume="231",
	pages="289--337",
	notes="Sourced from Microsoft Academic - https://academic.microsoft.com/paper/2166843037",
	year="1933"
}
@article{RN7,
   author = {Athalye, Anish and Carlini, Nicholas and Wagner, David},
   title = {Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples},
   journal = {arXiv preprint arXiv:1802.00420},
   year = {2018},
   type = {Journal Article}
}

@article{RN10,
   author = {Carlini, Nicholas and Katz, Guy and Barrett, Clark and Dill, David L},
   title = {Provably minimally-distorted adversarial examples},
   journal = {arXiv preprint arXiv:1709.10207},
   year = {2017},
   type = {Journal Article}
}

@inproceedings{RN30,
   author = {Carlini, Nicholas and Wagner, David},
   title = {Towards evaluating the robustness of neural networks},
   booktitle = {2017 IEEE Symposium on Security and Privacy (SP)},
   publisher = {IEEE},
   pages = {39-57},
   ISBN = {1509055339},
   type = {Conference Proceedings}
}

@inproceedings{RN39,
  title={Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models},
  author={Chen, Pin-Yu and Zhang, Huan and Sharma, Yash and Yi, Jinfeng and Hsieh, Cho-Jui},
  booktitle={Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security},
  pages={15--26},
  year={2017},
  organization={ACM}
}

@inproceedings{RN11,
   author = {Cisse, Moustapha and Bojanowski, Piotr and Grave, Edouard and Dauphin, Yann and Usunier, Nicolas},
   title = {Parseval networks: Improving robustness to adversarial examples},
   booktitle = {Proceedings of the 34th International Conference on Machine Learning-Volume 70},
   publisher = {JMLR. org},
   pages = {854-863},
   year = {2017},
   type = {Conference Proceedings}
}

@article{RN40,
  title={Adv-bnn: Improved adversarial defense through robust bayesian neural network},
  author={Liu, Xuanqing and Li, Yao and Wu, Chongruo and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:1810.01279},
  year={2018}
}

@article{RN2,
   author = {Cohen, Jeremy M and Rosenfeld, Elan and Kolter, J Zico},
   title = {Certified adversarial robustness via randomized smoothing},
   journal = {arXiv preprint arXiv:1902.02918},
   year = {2019},
   type = {Journal Article}
}

@article{RN12,
   author = {Croce, Francesco and Andriushchenko, Maksym and Hein, Matthias},
   title = {Provable robustness of relu networks via maximization of linear regions},
   journal = {arXiv preprint arXiv:1810.07481},
   year = {2018},
   type = {Journal Article}
}

@inproceedings{RN13,
   author = {Fawzi, Alhussein and Moosavi-Dezfooli, Seyed-Mohsen and Frossard, Pascal},
   title = {Robustness of classifiers: from adversarial to random noise},
   booktitle = {Advances in Neural Information Processing Systems},
   pages = {1632-1640},
   type = {Conference Proceedings}
}

@article{RN14,
   author = {Fischetti, Matteo and Jo, Jason},
   title = {Deep neural networks and mixed integer linear optimization},
   journal = {Constraints},
   volume = {23},
   number = {3},
   pages = {296-309},
   ISSN = {1383-7133},
   year = {2018},
   type = {Journal Article}
}

@article{RN15,
   author = {Ford, Nic and Gilmer, Justin and Carlini, Nicolas and Cubuk, Dogus},
   title = {Adversarial examples are a natural consequence of test error in noise},
   journal = {arXiv preprint arXiv:1901.10513},
   year = {2019},
   type = {Journal Article}
}

@article{RN6,
   author = {Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
   title = {Explaining and harnessing adversarial examples},
   journal = {arXiv preprint arXiv:1412.6572},
   year = {2014},
   type = {Journal Article}
}

@article{RN32,
   author = {Guo, Chuan and Rana, Mayank and Cisse, Moustapha and Van Der Maaten, Laurens},
   title = {Countering adversarial images using input transformations},
   journal = {arXiv preprint arXiv:1711.00117},
   year = {2017},
   type = {Journal Article}
}

@article{RN16,
   author = {Kannan, Harini and Kurakin, Alexey and Goodfellow, Ian},
   title = {Adversarial logit pairing},
   journal = {arXiv preprint arXiv:1803.06373},
   year = {2018},
   type = {Journal Article}
}

@article{RN29,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@article{RN17,
   author = {Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
   title = {Adversarial machine learning at scale},
   journal = {arXiv preprint arXiv:1611.01236},
   year = {2016},
   type = {Journal Article}
}

@inproceedings{RN18,
   author = {Lecuyer, Mathias and Atlidakis, Vaggelis and Geambasu, Roxana and Hsu, Daniel and Jana, Suman},
   title = {Certified robustness to adversarial examples with differential privacy},
   booktitle = {2019 IEEE Symposium on Security and Privacy (SP)},
   publisher = {IEEE},
   pages = {656-672},
   ISBN = {153866660X},
   year = {2019},
   type = {Conference Proceedings}
}

@article{RN37,
   author = {Li, Bai and Chen, Changyou and Wang, Wenlin and Carin, Lawrence},
   title = {Second-order adversarial attack and certifiable robustness},
   journal = {arXiv preprint arXiv:1809.03113},
   year = {2018},
   type = {Journal Article}
}

@inproceedings{RN38,
  title={Certified Adversarial Robustness with Additive Noise},
  author={Li, Bai and Chen, Changyou and Wang, Wenlin and Carin, Lawrence},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9459--9469},
  year={2019}
}


@article{RN19,
   author = {Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
   title = {Towards deep learning models resistant to adversarial attacks},
   journal = {arXiv preprint arXiv:1706.06083},
   year = {2017},
   type = {Journal Article}
}

@inproceedings{RN20,
   author = {Mirman, Matthew and Gehr, Timon and Vechev, Martin},
   title = {Differentiable abstract interpretation for provably robust neural networks},
   booktitle = {International Conference on Machine Learning},
   pages = {3575-3583},
   type = {Conference Proceedings}
}

@inproceedings{RN22,
   author = {Raghunathan, Aditi and Steinhardt, Jacob and Liang, Percy S},
   title = {Semidefinite relaxations for certifying robustness to adversarial examples},
   booktitle = {Advances in Neural Information Processing Systems},
   pages = {10877-10887},
   year = {2018},
   type = {Conference Proceedings}   
}

@inproceedings{Steinhardt2017CertifiedDF,
  title={Certified Defenses for Data Poisoning Attacks},
  author={Jacob Steinhardt and Pang Wei Koh and Percy Liang},
  booktitle={NIPS},
  year={2017}
}

@article{Tramr2016StealingML,
  title={Stealing Machine Learning Models via Prediction APIs},
  author={Florian Tram{\`e}r and Fan Zhang and Ari Juels and Michael K. Reiter and Thomas Ristenpart},
  journal={ArXiv},
  year={2016},
  volume={abs/1609.02943}
}

@inproceedings{RN1,
   author = {Salman, Hadi and Li, Jerry and Razenshteyn, Ilya and Zhang, Pengchuan and Zhang, Huan and Bubeck, Sebastien and Yang, Greg},
   title = {Provably robust deep learning via adversarially trained ensemble classifiers},
   booktitle = {Advances in Neural Information Processing Systems},
   pages = {11289-11300},
   type = {Conference Proceedings},
   year = {2019}
}


@article{RN34,
   author = {Samangouei, Pouya and Kabkab, Maya and Chellappa, Rama},
   title = {Defense-gan: Protecting classifiers against adversarial attacks using generative models},
   journal = {arXiv preprint arXiv:1805.06605},
   year = {2018},
   type = {Journal Article}
}

@article{RN8,
   author = {Shafahi, Ali and Najibi, Mahyar and Ghiasi, Amin and Xu, Zheng and Dickerson, John and Studer, Christoph and Davis, Larry S and Taylor, Gavin and Goldstein, Tom},
   title = {Adversarial Training for Free!},
   journal = {arXiv preprint arXiv:1904.12843},
   year = {2019},
   type = {Journal Article}
}

@article{RN4,
   author = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
   title = {Intriguing properties of neural networks},
   journal = {arXiv preprint arXiv:1312.6199},
   year = {2013},
   type = {Journal Article}
}

@article{RN23,
   author = {Tjeng, Vincent and Xiao, Kai and Tedrake, Russ},
   title = {Evaluating robustness of neural networks with mixed integer programming},
   journal = {arXiv preprint arXiv:1711.07356},
   year = {2017},
   type = {Journal Article}
}

@article{RN24,
   author = {Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Madry, Aleksander},
   title = {Robustness may be at odds with accuracy},
   journal = {arXiv preprint arXiv:1805.12152},
   year = {2018},
   type = {Journal Article}
}

@article{RN25,
   author = {Weng, Tsui-Wei and Zhang, Huan and Chen, Pin-Yu and Yi, Jinfeng and Su, Dong and Gao, Yupeng and Hsieh, Cho-Jui and Daniel, Luca},
   title = {Evaluating the robustness of neural networks: An extreme value theory approach},
   journal = {arXiv preprint arXiv:1801.10578},
   year = {2018},
   type = {Journal Article}
}

@inproceedings{RN9,
   author = {Wong, Eric and Schmidt, Frank and Metzen, Jan Hendrik and Kolter, J Zico},
   title = {Scaling provable adversarial defenses},
   booktitle = {Advances in Neural Information Processing Systems},
   pages = {8400-8409},
   year = {2018},
   type = {Conference Proceedings}
}

@article{RN26,
  title={Provable defenses against adversarial examples via the convex outer adversarial polytope},
  author={Wong, Eric and Kolter, J Zico},
  journal={arXiv preprint arXiv:1711.00851},
  year={2017}
}

@unpublished{RN53,
   author = {Daquan Lin},
   title = {Feature attack},
   url={https://github.com/Line290/FeatureAttack},
   year = {2019},
}

@article{RN33,
   author = {Xie, Cihang and Wang, Jianyu and Zhang, Zhishuai and Ren, Zhou and Yuille, Alan},
   title = {Mitigating adversarial effects through randomization},
   journal = {arXiv preprint arXiv:1711.01991},
   year = {2017},
   type = {Journal Article}
}

@inproceedings{RN28,
   author = {Zantedeschi, Valentina and Nicolae, Maria-Irina and Rawat, Ambrish},
   title = {Efficient defenses against adversarial attacks},
   booktitle = {Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security},
   publisher = {ACM},
   pages = {39-49},
   ISBN = {1450352022},
   type = {Conference Proceedings}
}

@article{RN35,
   author = {Zhang, Huan and Chen, Hongge and Xiao, Chaowei and Li, Bo and Boning, Duane and Hsieh, Cho-Jui},
   title = {Towards Stable and Efficient Training of Verifiably Robust Neural Networks},
   journal = {arXiv preprint arXiv:1906.06316},
   year = {2019},
   type = {Journal Article}
}


@inproceedings{RN36,
   author = {Zhang, Haichao and Wang, Jianyu},
   title = {Defense against adversarial attacks using feature scattering-based adversarial training},
   booktitle = {Advances in Neural Information Processing Systems},
   pages = {1829-1839},
   type = {Conference Proceedings}
}

@article{RN5,
   author = {Zhang, Hongyang and Yu, Yaodong and Jiao, Jiantao and Xing, Eric P and Ghaoui, Laurent El and Jordan, Michael I},
   title = {Theoretically principled trade-off between robustness and accuracy},
   journal = {arXiv preprint arXiv:1901.08573},
   year = {2019},
   type = {Journal Article}
}



@inproceedings{lee2019tight,
  title={Tight Certificates of Adversarial Robustness for Randomly Smoothed Classifiers},
  author={Guang-He Lee and Yang Yuan and Shiyu Chang and Tommi S. Jaakkola},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}

@inproceedings{schuchardt2021collective,
    title={Collective Robustness Certificates: Exploiting Interdependence in Graph Neural Networks},
    author={Jan Schuchardt and Aleksandar Bojchevski and Johannes Klicpera and Stephan G{\"u}nnemann},
    booktitle={ICLR},
    year={2021}
}

@inproceedings{levine2021deep,
    title     = {Deep Partition Aggregation: Provable Defenses against General Poisoning Attacks},
  author    = {Alexander Levine and
               Soheil Feizi},
  booktitle = {ICLR},
  year      = {2021}
}

@inproceedings{cohen2019certified,
  title={Certified adversarial robustness via randomized smoothing},
  author={Cohen, Jeremy and Rosenfeld, Elan and Kolter, Zico},
  booktitle={International Conference on Machine Learning},
  pages={1310--1320},
  year={2019},
  organization={PMLR}
}

@inproceedings{yang2020randomized,
	title={Randomized smoothing of all shapes and sizes},
	author="Greg {Yang} and Tony {Duan} and Edward {Hu} and Hadi {Salman} and Ilya P. {Razenshteyn} and Jerry {Li}",
	booktitle={ICML},
	year={2020}
}

@inproceedings{athalye2018obfuscated,
   author = {Athalye, Anish and Carlini, Nicholas and Wagner, David},
   title = {Obfuscated gradients give a false sense of security: circumventing defenses to adversarial examples},
   Booktitle = {ICML},
   year = {2018}
}

@inproceedings{steinhardt2017certified,
  title={Certified defenses for data poisoning attacks},
  author={Steinhardt, Jacob and Koh, Pang Wei and Liang, Percy},
  booktitle={Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages={3520--3532},
  year={2017}
}

@inproceedings{min2014nin,
    title={Network in network},
    author={Min Lin, Qiang Chen, Shuicheng Yan},
    booktitle={ICLR},
    year={2014}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  journal={JMLR}
}

@article{peter2002bag,
author = {Bühlmann, Peter and Yu, B.},
year = {2002},
title = {Analyzing Bagging},
journal = {Annals of Statistics}
}

@article{lecun2010mnist,
  title={{MNIST} handwritten digit database},
  author={LeCun, Yann and Cortes, Corinna and Burges, CJ},
  journal={[Online]. Available: http://yann. lecun. com/exdb/mnist},
  year={2010}
}

@software{gurobi,
  author = {{Gurobi Optimization}},
  title = {Gurobi Optimizer Reference Manual},
  url = {https://www.gurobi.com},
  version = {9.0},
  year={2021}
}

@article{breiman1996bagging,
  title={Bagging predictors},
  author={Breiman, Leo},
  journal={Machine learning},
  year={1996}
}

@inproceedings{biggio2011bagging,
  title={Bagging classifiers for fighting poisoning attacks in adversarial classification tasks},
  author={Biggio, Battista and Corona, Igino and Fumera, Giorgio and Giacinto, Giorgio and Roli, Fabio},
  booktitle={International workshop on multiple classifier systems},
  year={2011}
}

@inproceedings{tramer2020on,
  author    = {Florian Tram{\`{e}}r and
               Nicholas Carlini and
               Wieland Brendel and
               Aleksander Madry},
  title     = {On Adaptive Attacks to Adversarial Example Defenses},
  booktitle = {NeurIPS},
  year      = {2020}
}

@article{moro2014data,
  title={A data-driven approach to predict the success of bank telemarketing},
  author={Moro, S{\'e}rgio and Cortez, Paulo and Rita, Paulo},
  journal={Decision Support Systems},
  year={2014}
}

@article{harries1999splice,
  title={Splice-2 comparative evaluation: Electricity pricing},
  author={Harries, Michael and Wales, New South},
  year={1999},
  journal={Technical report}
}

@article{duchi2013local,
  title={Local privacy, data processing inequalities, and minimax rates},
  author={Duchi, John C and Jordan, Michael I and Wainwright, Martin J},
  journal={arXiv preprint arXiv:1302.3203},
  year={2013},
  publisher={Citeseer}
}

@article{xiao2017fashion,
  title={Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms},
  author={Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  journal={arXiv},
  year={2017}
}

@article{kononenko1989bayesian,
  title={Bayesian neural networks},
  author={Kononenko, Igor},
  journal={Biological Cybernetics},
  year={1989}
}

@inproceedings{newensemble,
author = {Bifet, Albert and Holmes, Geoff and Pfahringer, Bernhard and Kirkby, Richard and Gavald\`{a}, Ricard},
title = {New Ensemble Methods for Evolving Data Streams},
year = {2009},
booktitle = {KDD}
}

@book{BILP,
  title={Practical Optimization: a Gentle Introduction},
  author={John W. Chinneck},
  url={https://www.optimization101.org},
  year={2015},
}

@book{fujishige2005submodular,
  title={Submodular Functions and Optimization},
  author={Fujishige, S.},
  isbn={9780080461625},
  lccn={2005051368},
  series={ISSN},
  url={https://books.google.co.jp/books?id=gdcRXdoV89QC},
  year={2005},
  publisher={Elsevier Science}
}

@article{quantumDecom,
   title={Decomposition Algorithms for Solving NP-hard Problems on a Quantum Annealer},
   journal={Journal of Signal Processing Systems},
   author={Pelofske, Elijah and Hahn, Georg and Djidjev, Hristo},
   year={2020}
}

@article{RAO20082768,
title = {Solving some NP-complete problems using split decomposition},
journal = {Discrete Applied Mathematics},
year = {2008},
author = {Michaël Rao}
}

@article{li2020multivariate,
  title={Multivariate financial time-series prediction with certified robustness},
  author={Li, Hui and Cui, Yunpeng and Wang, Shuo and Liu, Juan and Qin, Jinyuan and Yang, Yilin},
  journal={IEEE Access},
  year={2020},
  publisher={IEEE}
}