% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{Fou13}
S.~Foucart and H.~Rauhut, \emph{A Mathematical Introduction to Compressive
  Sensing}.\hskip 1em plus 0.5em minus 0.4em\relax Springer New York, 2013.

\bibitem{wainwright2019high}
M.~J. Wainwright, \emph{High-dimensional statistics: A non-asymptotic
  viewpoint}.\hskip 1em plus 0.5em minus 0.4em\relax Cambridge University
  Press, 2019, vol.~48.

\bibitem{Wai09a}
M.~Wainwright, ``Sharp thresholds for high-dimensional and noisy sparsity
  recovery using $\ell_{1}$-constrained quadratic programming ({L}asso),''
  \emph{IEEE Trans. Inf. Theory}, vol.~55, no.~5, pp. 2183--2202, May 2009.

\bibitem{Don13}
D.~L. {Donoho}, A.~{Javanmard}, and A.~{Montanari}, ``Information-theoretically
  optimal compressed sensing via spatial coupling and approximate message
  passing,'' \emph{IEEE Trans. Inf. Theory}, vol.~59, no.~11, pp. 7434--7464,
  Nov. 2013.

\bibitem{Ame14}
D.~Amelunxen, M.~Lotz, M.~B. McCoy, and J.~A. Tropp, ``Living on the edge:
  Phase transitions in convex programs with random data,'' \emph{Information
  and Inference}, vol.~3, no.~3, pp. 224--294, 2014.

\bibitem{Wen2016}
J.~Wen, Z.~Zhou, J.~Wang, X.~Tang, and Q.~Mo, ``A sharp condition for exact
  support recovery with orthogonal matching pursuit,'' \emph{IEEE Trans. Sig.
  Proc.}, vol.~65, no.~6, pp. 1370--1382, 2016.

\bibitem{Wai09}
M.~Wainwright, ``Information-theoretic limits on sparsity recovery in the
  high-dimensional and noisy setting,'' \emph{IEEE Trans. Inf. Theory},
  vol.~55, no.~12, pp. 5728--5741, Dec. 2009.

\bibitem{Ari13}
E.~Arias-Castro, E.~J. Candes, and M.~A. Davenport, ``On the fundamental limits
  of adaptive sensing,'' \emph{IEEE Trans. Inf. Theory}, vol.~59, no.~1, pp.
  472--481, Jan. 2013.

\bibitem{Can13}
E.~J. Candes and M.~A. Davenport, ``How well can we estimate a sparse vector?''
  \emph{Appl. Comp. Harm. Analysis}, vol.~34, no.~2, pp. 317--323, 2013.

\bibitem{Sca15}
J.~Scarlett and V.~Cevher, ``Limits on support recovery with probabilistic
  models: An information-theoretic framework,'' \emph{IEEE Trans. Inf. Theory},
  vol.~63, no.~1, pp. 593--620, 2017.

\bibitem{boufounos20081}
P.~T. Boufounos and R.~G. Baraniuk, ``1-bit compressive sensing,'' in
  \emph{Conf. Inf. Sci. Syst. (CISS)}.\hskip 1em plus 0.5em minus 0.4em\relax
  IEEE, 2008, pp. 16--21.

\bibitem{gupta2010sample}
A.~Gupta, R.~Nowak, and B.~Recht, ``Sample complexity for 1-bit compressed
  sensing and sparse classification,'' in \emph{Int. Symp. Inf. Theory
  (ISIT)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2010, pp. 1553--1557.

\bibitem{zhu2015towards}
R.~Zhu and Q.~Gu, ``Towards a lower sample complexity for robust one-bit
  compressed sensing,'' in \emph{Int. Conf. Mach. Learn. (ICML)}, 2015, pp.
  739--747.

\bibitem{zhang2014efficient}
L.~Zhang, J.~Yi, and R.~Jin, ``Efficient algorithms for robust one-bit
  compressive sensing,'' in \emph{Int. Conf. Mach. Learn. (ICML)}, 2014, pp.
  820--828.

\bibitem{gopi2013one}
S.~Gopi, P.~Netrapalli, P.~Jain, and A.~Nori, ``One-bit compressed sensing:
  Provable support and vector recovery,'' in \emph{Int. Conf. Mach. Learn.
  (ICML)}, 2013, pp. 154--162.

\bibitem{ai2014one}
A.~Ai, A.~Lapanowski, Y.~Plan, and R.~Vershynin, ``One-bit compressed sensing
  with non-{G}aussian measurements,'' \emph{Linear Algebra Appl.}, vol. 441,
  pp. 222--239, 2014.

\bibitem{awasthi2016learning}
P.~Awasthi, M.~F. Balcan, N.~Haghtalab, and H.~Zhang, ``Learning and 1-bit
  compressed sensing under asymmetric noise,'' \emph{J. Mach. Learn. Res.},
  vol.~49, no. June, pp. 152--192, 2016.

\bibitem{boufounos2010reconstruction}
P.~T. Boufounos, ``Reconstruction of sparse signals from distorted randomized
  measurements,'' in \emph{Int. Conf. Acoust. Sp. Sig. Proc. (ICASSP)}, 2010,
  pp. 3998--4001.

\bibitem{Fos19}
D.~Foster, \emph{Generative Deep Learning : Teaching Machines to Paint, Write,
  Compose and Play}.\hskip 1em plus 0.5em minus 0.4em\relax O'Reilly Media,
  Inc, USA, 2019.

\bibitem{Bor17}
A.~Bora, A.~Jalal, E.~Price, and A.~G. Dimakis, ``Compressed sensing using
  generative models,'' in \emph{Int. Conf. Mach. Learn. (ICML)}, 2017, pp.
  537--546.

\bibitem{boufounos2009greedy}
P.~T. Boufounos, ``Greedy sparse signal reconstruction from sign
  measurements,'' in \emph{Conf. Rec. Asilomar. Conf. Sig. Syst. Comput.
  (ACSSC)}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2009, pp. 1305--1309.

\bibitem{laska2011trust}
J.~N. Laska, Z.~Wen, W.~Yin, and R.~G. Baraniuk, ``Trust, but verify: Fast and
  accurate signal recovery from 1-bit compressive measurements,'' \emph{IEEE
  Trans. Sig. Proc.}, vol.~59, no.~11, pp. 5289--5301, 2011.

\bibitem{zymnis2009compressed}
A.~Zymnis, S.~Boyd, and E.~Candes, ``Compressed sensing with quantized
  measurements,'' \emph{IEEE Sig. Proc. Lett.}, vol.~17, no.~2, pp. 149--152,
  2009.

\bibitem{acharya2017improved}
J.~Acharya, A.~Bhattacharyya, and P.~Kamath, ``Improved bounds for universal
  one-bit compressive sensing,'' in \emph{Int. Symp. Inf. Theory (ISIT)}, 2017,
  pp. 2353--2357.

\bibitem{plan2012robust}
Y.~Plan and R.~Vershynin, ``Robust 1-bit compressed sensing and sparse logistic
  regression: A convex programming approach,'' \emph{IEEE Trans. Inf. Theory},
  vol.~59, no.~1, pp. 482--494, 2012.

\bibitem{plan2013one}
------, ``One-bit compressed sensing by linear programming,'' \emph{Comm. Pure
  Appl. Math.}, vol.~66, no.~8, pp. 1275--1297, 2013.

\bibitem{dirksen2018non}
S.~Dirksen and S.~Mendelson, ``Non-{G}aussian hyperplane tessellations and
  robust one-bit compressed sensing,'' \emph{https://arxiv.org/abs/1805.09409},
  2018.

\bibitem{li2018survey}
Z.~Li, W.~Xu, X.~Zhang, and J.~Lin, ``A survey on one-bit compressed sensing:
  Theory and applications,'' \emph{Front. Comput. Sci.}, vol.~12, no.~2, pp.
  217--230, 2018.

\bibitem{knudson2016one}
K.~Knudson, R.~Saab, and R.~Ward, ``One-bit compressive sensing with norm
  estimation,'' \emph{IEEE Trans. Inf. Theory}, vol.~62, no.~5, pp. 2748--2758,
  2016.

\bibitem{xu2018quantized}
C.~Xu and L.~Jacques, ``Quantized compressive sensing with {RIP} matrices: The
  benefit of dithering,'' \emph{https://arxiv.org/abs/1801.05870}, 2018.

\bibitem{jacques2017time}
L.~Jacques and V.~Cambareri, ``Time for dithering: Fast and quantized random
  embeddings via the restricted isometry property,'' \emph{Inf. Inference},
  vol.~6, no.~4, pp. 441--476, 2017.

\bibitem{jacques2013robust}
L.~Jacques, J.~N. Laska, P.~T. Boufounos, and R.~G. Baraniuk, ``Robust 1-bit
  compressive sensing via binary stable embeddings of sparse vectors,''
  \emph{IEEE Trans. Inf. Theory}, vol.~59, no.~4, pp. 2082--2102, 2013.

\bibitem{Sha18}
V.~Shah and C.~Hegde, ``Solving linear inverse problems using {GAN} priors: An
  algorithm with provable guarantees,'' in \emph{IEEE Int. Conf. Acoust. Sp.
  Sig. Proc. (ICASSP)}, 2018, pp. 4609--4613.

\bibitem{peng2020solving}
P.~Peng, S.~Jalali, and X.~Yuan, ``Solving inverse problems via
  auto-encoders,'' \emph{IEEE J. Sel. Areas Inf. Theory}, vol.~1, no.~1, pp.
  312--323, 2020.

\bibitem{Dha18}
M.~Dhar, A.~Grover, and S.~Ermon, ``Modeling sparse deviations for compressed
  sensing using generative models,'' in \emph{Int. Conf. Mach. Learn. (ICML)},
  2018.

\bibitem{Han18}
P.~Hand and V.~Voroninski, ``Global guarantees for enforcing deep generative
  priors by empirical risk,'' in \emph{Conf. Learn. Theory (COLT)}, 2018.

\bibitem{kamath2019lower}
A.~Kamath, S.~Karmalkar, and E.~Price, ``Lower bounds for compressed sensing
  with generative models,'' \emph{https://arxiv.org/abs/1912.02938}, 2019.

\bibitem{liu2020information}
Z.~Liu and J.~Scarlett, ``Information-theoretic lower bounds for compressive
  sensing with generative models,'' \emph{IEEE J. Sel. Areas Inf. Theory},
  vol.~1, no.~1, pp. 292--303, 2020.

\bibitem{qiu2019robust}
S.~Qiu, X.~Wei, and Z.~Yang, ``Robust one-bit recovery via {R}e{LU} generative
  networks: Improved statistical rates and global landscape analysis,''
  \emph{https://arxiv.org/abs/1908.05368}, 2019.

\bibitem{oymak2015near}
S.~Oymak and B.~Recht, ``Near-optimal bounds for binary embeddings of arbitrary
  sets,'' \emph{https://arxiv.org/abs/1512.04433}, 2015.

\bibitem{vempala2005random}
S.~S. Vempala, \emph{The random projection method}.\hskip 1em plus 0.5em minus
  0.4em\relax American Mathematical Soc., 2005, vol.~65.

\bibitem{vershynin2010introduction}
R.~Vershynin, ``Introduction to the non-asymptotic analysis of random
  matrices,'' \emph{https://arxiv.org/abs/1011.3027}, 2010.

\bibitem{Flo19}
L.~Flodin, V.~Gandikota, and A.~Mazumdar, ``Superset technique for approximate
  recovery in one-bit compressed sensing,'' in \emph{Conf. Neur. Inf. Proc.
  Sys. (NeurIPS)}, 2019.

\bibitem{goemans1995improved}
M.~X. Goemans and D.~P. Williamson, ``Improved approximation algorithms for
  maximum cut and satisfiability problems using semidefinite programming,''
  \emph{J. ACM}, vol.~42, no.~6, pp. 1115--1145, 1995.

\bibitem{jacques2013quantized}
L.~Jacques and C.~D. Vleeschouwer, ``Quantized iterative hard thresholding:
  Bridging 1-bit and high-resolution quantized compressed sensing,'' in
  \emph{Int. Conf. Samp. Theory Apps. (SampTA)}, 2013.

\bibitem{Tib96}
R.~Tibshirani, ``Regression shrinkage and selection via the lasso,'' \emph{J.
  Royal Stat. Soc. Series B}, pp. 267--288, 1996.

\bibitem{alon2004probabilistic}
N.~Alon and J.~H. Spencer, \emph{The probabilistic method}.\hskip 1em plus
  0.5em minus 0.4em\relax John Wiley \& Sons, 2004.

\bibitem{lorentz1996constructive}
G.~G. Lorentz, M.~von Golitschek, and Y.~Makovoz, \emph{Constructive
  approximation: {A}dvanced problems}.\hskip 1em plus 0.5em minus 0.4em\relax
  Springer, 1996, vol. 304.

\end{thebibliography}
