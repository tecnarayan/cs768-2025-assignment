\begin{thebibliography}{10}

\bibitem{bengio2013estimating}
Yoshua Bengio, Nicholas L{\'e}onard, and Aaron Courville.
\newblock Estimating or propagating gradients through stochastic neurons for
  conditional computation.
\newblock {\em arXiv preprint arXiv:1308.3432}, 2013.

\bibitem{bogo2017dynamic}
Federica Bogo, Javier Romero, Gerard Pons-Moll, and Michael~J Black.
\newblock Dynamic faust: Registering human bodies in motion.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 6233--6242, 2017.

\bibitem{chabra2020deep}
Rohan Chabra, Jan~E Lenssen, Eddy Ilg, Tanner Schmidt, Julian Straub, Steven
  Lovegrove, and Richard Newcombe.
\newblock Deep local shapes: Learning local sdf priors for detailed 3d
  reconstruction.
\newblock In {\em European Conference on Computer Vision}, pages 608--625.
  Springer, 2020.

\bibitem{chang2015shapenet}
Angel~X Chang, Thomas Funkhouser, Leonidas Guibas, Pat Hanrahan, Qixing Huang,
  Zimo Li, Silvio Savarese, Manolis Savva, Shuran Song, Hao Su, et~al.
\newblock Shapenet: An information-rich 3d model repository.
\newblock {\em arXiv preprint arXiv:1512.03012}, 2015.

\bibitem{chang2022maskgit}
Huiwen Chang, Han Zhang, Lu~Jiang, Ce~Liu, and William~T Freeman.
\newblock Maskgit: Masked generative image transformer.
\newblock {\em arXiv preprint arXiv:2202.04200}, 2022.

\bibitem{chen2021multiresolution}
Zhang Chen, Yinda Zhang, Kyle Genova, Sean Fanello, Sofien Bouaziz, Christian
  H{\"a}ne, Ruofei Du, Cem Keskin, Thomas Funkhouser, and Danhang Tang.
\newblock Multiresolution deep implicit functions for 3d shape representation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 13087--13096, 2021.

\bibitem{chen2019bsp}
Zhiqin Chen, Andrea Tagliasacchi, and Hao Zhang.
\newblock Bsp-net: Generating compact meshes via binary space partitioning.
\newblock {\em arXiv preprint arXiv:1911.06971}, 2019.

\bibitem{cheng2022autoregressive}
An-Chieh Cheng, Xueting Li, Sifei Liu, Min Sun, and Ming-Hsuan Yang.
\newblock Autoregressive 3d shape generation via canonical mapping.
\newblock {\em arXiv preprint arXiv:2204.01955}, 2022.

\bibitem{chibane2020implicit}
Julian Chibane, Thiemo Alldieck, and Gerard Pons-Moll.
\newblock Implicit functions in feature space for 3d shape reconstruction and
  completion.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 6970--6981, 2020.

\bibitem{choy20163d}
Christopher~B Choy, Danfei Xu, JunYoung Gwak, Kevin Chen, and Silvio Savarese.
\newblock 3d-r2n2: A unified approach for single and multi-view 3d object
  reconstruction.
\newblock In {\em European conference on computer vision}, pages 628--644.
  Springer, 2016.

\bibitem{collins2022abo}
Jasmine Collins, Shubham Goel, Kenan Deng, Achleshwar Luthra, Leon Xu, Erhan
  Gundogdu, Xi~Zhang, Tomas F~Yago Vicente, Thomas Dideriksen, Himanshu Arora,
  et~al.
\newblock Abo: Dataset and benchmarks for real-world 3d object understanding.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 21126--21136, 2022.

\bibitem{dai2017shape}
Angela Dai, Charles Ruizhongtai~Qi, and Matthias Nie{\ss}ner.
\newblock Shape completion using 3d-encoder-predictor cnns and shape synthesis.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 5868--5877, 2017.

\bibitem{deng2020cvxnet}
Boyang Deng, Kyle Genova, Soroosh Yazdani, Sofien Bouaziz, Geoffrey Hinton, and
  Andrea Tagliasacchi.
\newblock Cvxnet: Learnable convex decomposition.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 31--44, 2020.

\bibitem{DBLP:journals/corr/DinhKB14}
Laurent Dinh, David Krueger, and Yoshua Bengio.
\newblock {NICE:} non-linear independent components estimation.
\newblock In Yoshua Bengio and Yann LeCun, editors, {\em International
  Conference on Learning Representations (ICLR)}, 2015.

\bibitem{dosovitskiy2020vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock {\em ICLR}, 2021.

\bibitem{esser2021taming}
Patrick Esser, Robin Rombach, and Bjorn Ommer.
\newblock Taming transformers for high-resolution image synthesis.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 12873--12883, 2021.

\bibitem{genova2020local}
Kyle Genova, Forrester Cole, Avneesh Sud, Aaron Sarna, and Thomas Funkhouser.
\newblock Local deep implicit functions for 3d shape.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 4857--4866, 2020.

\bibitem{genova2019learning}
Kyle Genova, Forrester Cole, Daniel Vlasic, Aaron Sarna, William~T Freeman, and
  Thomas Funkhouser.
\newblock Learning shape templates with structured implicit functions.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision}, pages 7154--7164, 2019.

\bibitem{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock {\em Advances in Neural Information Processing Systems},
  27:2672--2680, 2014.

\bibitem{guo2021pct}
Meng-Hao Guo, Jun-Xiong Cai, Zheng-Ning Liu, Tai-Jiang Mu, Ralph~R Martin, and
  Shi-Min Hu.
\newblock Pct: Point cloud transformer.
\newblock {\em Computational Visual Media}, 7(2):187--199, 2021.

\bibitem{heusel2017gans}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp
  Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash
  equilibrium.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{holtzman2019curious}
Ari Holtzman, Jan Buys, Li~Du, Maxwell Forbes, and Yejin Choi.
\newblock The curious case of neural text degeneration.
\newblock {\em arXiv preprint arXiv:1904.09751}, 2019.

\bibitem{jiang2020local}
Chiyu Jiang, Avneesh Sud, Ameesh Makadia, Jingwei Huang, Matthias Nie{\ss}ner,
  Thomas Funkhouser, et~al.
\newblock Local implicit grid representations for 3d scenes.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 6001--6010, 2020.

\bibitem{DBLP:journals/corr/KingmaW13}
Diederik~P. Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock In Yoshua Bengio and Yann LeCun, editors, {\em International
  Conference on Learning Representations (ICLR)}, 2014.

\bibitem{lecun2006tutorial}
Yann LeCun, Sumit Chopra, Raia Hadsell, M~Ranzato, and F~Huang.
\newblock A tutorial on energy-based learning.
\newblock {\em Predicting structured data}, 1(0), 2006.

\bibitem{li2022learning}
Tianyang Li, Xin Wen, Yu-Shen Liu, Hua Su, and Zhizhong Han.
\newblock Learning deep implicit functions for 3d shapes with dynamic code
  clouds.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 12840--12850, 2022.

\bibitem{li2016fpnn}
Yangyan Li, Soeren Pirk, Hao Su, Charles~R Qi, and Leonidas~J Guibas.
\newblock Fpnn: Field probing neural networks for 3d data.
\newblock {\em Advances in neural information processing systems}, 29, 2016.

\bibitem{lorensen1987marching}
William~E Lorensen and Harvey~E Cline.
\newblock Marching cubes: A high resolution 3d surface construction algorithm.
\newblock {\em ACM siggraph computer graphics}, 21(4):163--169, 1987.

\bibitem{mescheder2019occupancy}
Lars Mescheder, Michael Oechsle, Michael Niemeyer, Sebastian Nowozin, and
  Andreas Geiger.
\newblock Occupancy networks: Learning 3d reconstruction in function space.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 4460--4470, 2019.

\bibitem{michalkiewicz2019deep}
Mateusz Michalkiewicz, Jhony~K Pontes, Dominic Jack, Mahsa Baktashmotlagh, and
  Anders Eriksson.
\newblock Deep level sets: Implicit surface representations for 3d shape
  inference.
\newblock {\em arXiv preprint arXiv:1901.06802}, 2019.

\bibitem{mildenhall2020nerf}
Ben Mildenhall, Pratul~P Srinivasan, Matthew Tancik, Jonathan~T Barron, Ravi
  Ramamoorthi, and Ren Ng.
\newblock Nerf: Representing scenes as neural radiance fields for view
  synthesis.
\newblock In {\em European conference on computer vision}, pages 405--421.
  Springer, 2020.

\bibitem{mittal2022autosdf}
Paritosh Mittal, Yen-Chi Cheng, Maneesh Singh, and Shubham Tulsiani.
\newblock Autosdf: Shape priors for 3d completion, reconstruction and
  generation.
\newblock {\em arXiv preprint arXiv:2203.09516}, 2022.

\bibitem{nash2020polygen}
Charlie Nash, Yaroslav Ganin, SM~Ali Eslami, and Peter Battaglia.
\newblock Polygen: An autoregressive generative model of 3d meshes.
\newblock In {\em International Conference on Machine Learning}, pages
  7220--7229. PMLR, 2020.

\bibitem{pang2022masked}
Yatian Pang, Wenxiao Wang, Francis~EH Tay, Wei Liu, Yonghong Tian, and Li~Yuan.
\newblock Masked autoencoders for point cloud self-supervised learning.
\newblock {\em arXiv preprint arXiv:2203.06604}, 2022.

\bibitem{para2021generative}
Wamiq Para, Paul Guerrero, Tom Kelly, Leonidas~J Guibas, and Peter Wonka.
\newblock Generative layout modeling using constraint graphs.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 6690--6700, 2021.

\bibitem{park2019deepsdf}
Jeong~Joon Park, Peter Florence, Julian Straub, Richard Newcombe, and Steven
  Lovegrove.
\newblock Deepsdf: Learning continuous signed distance functions for shape
  representation.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 165--174, 2019.

\bibitem{parmar2021cleanfid}
Gaurav Parmar, Richard Zhang, and Jun-Yan Zhu.
\newblock On aliased resizing and surprising subtleties in gan evaluation.
\newblock In {\em CVPR}, 2022.

\bibitem{paschalidou2021atiss}
Despoina Paschalidou, Amlan Kar, Maria Shugrina, Karsten Kreis, Andreas Geiger,
  and Sanja Fidler.
\newblock Atiss: Autoregressive transformers for indoor scene synthesis.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{peng2020convolutional}
Songyou Peng, Michael Niemeyer, Lars Mescheder, Marc Pollefeys, and Andreas
  Geiger.
\newblock Convolutional occupancy networks.
\newblock In {\em European Conference on Computer Vision}, pages 523--540.
  Springer, 2020.

\bibitem{qi2017pointnet}
Charles~R Qi, Hao Su, Kaichun Mo, and Leonidas~J Guibas.
\newblock Pointnet: Deep learning on point sets for 3d classification and
  segmentation.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 652--660, 2017.

\bibitem{qi2017pointnet++}
Charles~Ruizhongtai Qi, Li~Yi, Hao Su, and Leonidas~J Guibas.
\newblock Pointnet++: Deep hierarchical feature learning on point sets in a
  metric space.
\newblock In {\em Advances in neural information processing systems}, pages
  5099--5108, 2017.

\bibitem{radford2019language}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
  Sutskever.
\newblock Language models are unsupervised multitask learners.
\newblock 2019.

\bibitem{rezende2015variational}
Danilo Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock In {\em International Conference on Machine Learning}, pages
  1530--1538, 2015.

\bibitem{riegler2017octnet}
Gernot Riegler, Ali Osman~Ulusoy, and Andreas Geiger.
\newblock Octnet: Learning deep 3d representations at high resolutions.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 3577--3586, 2017.

\bibitem{salimans2017pixelcnn++}
Tim Salimans, Andrej Karpathy, Xi~Chen, and Diederik~P Kingma.
\newblock Pixelcnn++: Improving the pixelcnn with discretized logistic mixture
  likelihood and other modifications.
\newblock {\em arXiv preprint arXiv:1701.05517}, 2017.

\bibitem{sun2020pointgrow}
Yongbin Sun, Yue Wang, Ziwei Liu, Joshua Siegel, and Sanjay Sarma.
\newblock Pointgrow: Autoregressively learned point cloud generation with
  self-attention.
\newblock In {\em Proceedings of the IEEE/CVF Winter Conference on Applications
  of Computer Vision}, pages 61--70, 2020.

\bibitem{tancik2020meta}
Matthew Tancik, Ben Mildenhall, Terrance Wang, Divi Schmidt, Pratul~P.
  Srinivasan, Jonathan~T. Barron, and Ren Ng.
\newblock Learned initializations for optimizing coordinate-based neural
  representations.
\newblock In {\em CVPR}, 2021.

\bibitem{tang2021sa}
Jiapeng Tang, Jiabao Lei, Dan Xu, Feiying Ma, Kui Jia, and Lei Zhang.
\newblock Sa-convonet: Sign-agnostic optimization of convolutional occupancy
  networks.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 6504--6513, 2021.

\bibitem{tang2022neural}
Jiapeng Tang, Markhasin Lev, Wang Bi, Thies Justus, and Matthias Nie{\ss}ner.
\newblock Neural shape deformation priors.
\newblock In {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{tatarchenko2019single}
Maxim Tatarchenko, Stephan~R Richter, Ren{\'e} Ranftl, Zhuwen Li, Vladlen
  Koltun, and Thomas Brox.
\newblock What do single-view 3d reconstruction networks learn?
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 3405--3414, 2019.

\bibitem{thomas2019kpconv}
Hugues Thomas, Charles~R Qi, Jean-Emmanuel Deschaud, Beatriz Marcotegui,
  Fran{\c{c}}ois Goulette, and Leonidas~J Guibas.
\newblock Kpconv: Flexible and deformable convolution for point clouds.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision}, pages 6411--6420, 2019.

\bibitem{van2016conditional}
Aaron Van~den Oord, Nal Kalchbrenner, Lasse Espeholt, Oriol Vinyals, Alex
  Graves, et~al.
\newblock Conditional image generation with pixelcnn decoders.
\newblock {\em Advances in Neural Information Processing Systems},
  29:4790--4798, 2016.

\bibitem{van2017neural}
Aaron Van Den~Oord, Oriol Vinyals, et~al.
\newblock Neural discrete representation learning.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{van2016pixel}
Aaron Van~Oord, Nal Kalchbrenner, and Koray Kavukcuoglu.
\newblock Pixel recurrent neural networks.
\newblock In {\em International Conference on Machine Learning}, pages
  1747--1756, 2016.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{wang2021sceneformer}
Xinpeng Wang, Chandan Yeshwanth, and Matthias Nie{\ss}ner.
\newblock Sceneformer: Indoor scene generation with transformers.
\newblock In {\em 2021 International Conference on 3D Vision (3DV)}, pages
  106--115. IEEE, 2021.

\bibitem{wang2019dynamic}
Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay~E Sarma, Michael~M Bronstein, and
  Justin~M Solomon.
\newblock Dynamic graph cnn for learning on point clouds.
\newblock {\em Acm Transactions On Graphics (tog)}, 38(5):1--12, 2019.

\bibitem{wu2019pointconv}
Wenxuan Wu, Zhongang Qi, and Li~Fuxin.
\newblock Pointconv: Deep convolutional networks on 3d point clouds.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 9621--9630, 2019.

\bibitem{xie2016theory}
Jianwen Xie, Yang Lu, Song-Chun Zhu, and Yingnian Wu.
\newblock A theory of generative convnet.
\newblock In {\em International Conference on Machine Learning}, pages
  2635--2644. PMLR, 2016.

\bibitem{xie2021generative}
Jianwen Xie, Yifei Xu, Zilong Zheng, Song-Chun Zhu, and Ying~Nian Wu.
\newblock Generative pointnet: Deep energy-based learning on unordered point
  sets for 3d generation, reconstruction and classification.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 14976--14985, 2021.

\bibitem{xie2018learning}
Jianwen Xie, Zilong Zheng, Ruiqi Gao, Wenguan Wang, Song-Chun Zhu, and
  Ying~Nian Wu.
\newblock Learning descriptor networks for 3d shape synthesis and analysis.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 8629--8638, 2018.

\bibitem{xie2020generative}
Jianwen Xie, Zilong Zheng, Ruiqi Gao, Wenguan Wang, Song-Chun Zhu, and
  Ying~Nian Wu.
\newblock Generative voxelnet: learning energy-based models for 3d shape
  synthesis and analysis.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  2020.

\bibitem{xie2021neural}
Yiheng Xie, Towaki Takikawa, Shunsuke Saito, Or~Litany, Shiqin Yan, Numair
  Khan, Federico Tombari, James Tompkin, Vincent Sitzmann, and Srinath Sridhar.
\newblock Neural fields in visual computing and beyond.
\newblock {\em Computer Graphics Forum}, 2022.

\bibitem{yan2022shapeformer}
Xingguang Yan, Liqiang Lin, Niloy~J Mitra, Dani Lischinski, Danny Cohen-Or, and
  Hui Huang.
\newblock Shapeformer: Transformer-based shape completion via sparse
  representation.
\newblock {\em arXiv preprint arXiv:2201.10326}, 2022.

\bibitem{yu2021point}
Xumin Yu, Lulu Tang, Yongming Rao, Tiejun Huang, Jie Zhou, and Jiwen Lu.
\newblock Point-bert: Pre-training 3d point cloud transformers with masked
  point modeling.
\newblock {\em arXiv preprint arXiv:2111.14819}, 2021.

\bibitem{zhang2022training}
Biao Zhang and Peter Wonka.
\newblock Training data generating networks: Shape reconstruction via bi-level
  optimization.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{zhao2021point}
Hengshuang Zhao, Li~Jiang, Jiaya Jia, Philip~HS Torr, and Vladlen Koltun.
\newblock Point transformer.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 16259--16268, 2021.

\end{thebibliography}
