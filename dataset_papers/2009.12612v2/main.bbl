\begin{thebibliography}{10}

\bibitem{cpo_main}
Joshua Achiam, David Held, Aviv Tamar, and Pieter Abbeel.
\newblock Constrained policy optimization.
\newblock In Doina Precup and Yee~Whye Teh, editors, {\em Proceedings of the
  34th International Conference on Machine Learning, {ICML} 2017, Sydney, NSW,
  Australia, 6-11 August 2017}, volume~70 of {\em Proceedings of Machine
  Learning Research}, pages 22--31. {PMLR}, 2017.

\bibitem{AkametaluKFZGT14}
Anayo~K. Akametalu, Shahab Kaynama, Jaime~F. Fisac, Melanie~Nicole Zeilinger,
  Jeremy~H. Gillula, and Claire~J. Tomlin.
\newblock Reachability-based safe learning with gaussian processes.
\newblock In {\em 53rd {IEEE} Conference on Decision and Control, {CDC} 2014,
  Los Angeles, CA, USA, December 15-17, 2014}, pages 1424--1431, 2014.

\bibitem{AlshiekhBEKNT18}
Mohammed Alshiekh, Roderick Bloem, R{\"{u}}diger Ehlers, Bettina
  K{\"{o}}nighofer, Scott Niekum, and Ufuk Topcu.
\newblock Safe reinforcement learning via shielding.
\newblock In Sheila~A. McIlraith and Kilian~Q. Weinberger, editors, {\em
  Proceedings of the Thirty-Second {AAAI} Conference on Artificial
  Intelligence, (AAAI-18), the 30th innovative Applications of Artificial
  Intelligence (IAAI-18), and the 8th {AAAI} Symposium on Educational Advances
  in Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February
  2-7, 2018}, pages 2669--2678. {AAAI} Press, 2018.

\bibitem{charon}
Greg Anderson, Shankara Pailoor, Isil Dillig, and Swarat Chaudhuri.
\newblock Optimization and abstraction: a synergistic approach for analyzing
  neural network robustness.
\newblock In {\em Proceedings of the 40th ACM SIGPLAN Conference on Programming
  Language Design and Implementation}, pages 731--744, 2019.

\bibitem{viper}
Osbert Bastani, Yewen Pu, and Armando Solar-Lezama.
\newblock Verifiable reinforcement learning via policy extraction.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2494--2504, 2018.

\bibitem{berkenkamp2017safe}
Felix Berkenkamp, Matteo Turchetta, Angela Schoellig, and Andreas Krause.
\newblock Safe model-based reinforcement learning with stability guarantees.
\newblock In {\em Advances in neural information processing systems}, pages
  908--918, 2017.

\bibitem{chow2018lyapunov}
Yinlam Chow, Ofir Nachum, Edgar Duenez-Guzman, and Mohammad Ghavamzadeh.
\newblock A {L}yapunov-based approach to safe reinforcement learning.
\newblock In {\em Advances in neural information processing systems}, pages
  8092--8101, 2018.

\bibitem{ChowNDG18}
Yinlam Chow, Ofir Nachum, Edgar~A. Du{\'{e}}{\~{n}}ez{-}Guzm{\'{a}}n, and
  Mohammad Ghavamzadeh.
\newblock A lyapunov-based approach to safe reinforcement learning.
\newblock In {\em Advances in Neural Information Processing Systems 31: Annual
  Conference on Neural Information Processing Systems 2018, NeurIPS 2018, 3-8
  December 2018, Montr{\'{e}}al, Canada}, pages 8103--8112.

\bibitem{cousot1977}
Patrick Cousot and Radhia Cousot.
\newblock Abstract interpretation: a unified lattice model for static analysis
  of programs by construction or approximation of fixpoints.
\newblock In {\em Proceedings of the 4th ACM SIGACT-SIGPLAN symposium on
  Principles of programming languages}, pages 238--252. ACM, 1977.

\bibitem{dalal_safe_2018}
Gal Dalal, Krishnamurthy Dvijotham, Matej Vecerik, Todd Hester, Cosmin
  Paduraru, and Yuval Tassa.
\newblock Safe {Exploration} in {Continuous} {Action} {Spaces}.
\newblock January 2018.

\bibitem{fulton2018safe}
Nathan Fulton and Andr{\'e} Platzer.
\newblock Safe reinforcement learning via formal methods: Toward safe control
  through proof and learning.
\newblock In {\em Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem{fulton2019verifiably}
Nathan Fulton and Andr{\'e} Platzer.
\newblock Verifiably safe off-model reinforcement learning.
\newblock In {\em International Conference on Tools and Algorithms for the
  Construction and Analysis of Systems}, pages 413--430. Springer, 2019.

\bibitem{garcia2015comprehensive}
Javier Garc{\i}a and Fernando Fern{\'a}ndez.
\newblock A comprehensive survey on safe reinforcement learning.
\newblock {\em Journal of Machine Learning Research}, 16(1):1437--1480, 2015.

\bibitem{garcia_comprehensive_nodate}
Javier GarcÄ±a and Fernando Fernandez.
\newblock A {Comprehensive} {Survey} on {Safe} {Reinforcement} {Learning}.
\newblock page~44.

\bibitem{ai2}
Timon Gehr, Matthew Mirman, Dana Drachsler-Cohen, Petar Tsankov, Swarat
  Chaudhuri, and Martin Vechev.
\newblock Ai2: Safety and robustness certification of neural networks with
  abstract interpretation.
\newblock In {\em 2018 IEEE Symposium on Security and Privacy (SP)}, pages
  3--18. IEEE, 2018.

\bibitem{GillulaT12}
Jeremy~H. Gillula and Claire~J. Tomlin.
\newblock Guaranteed safe online learning via reachability: tracking a ground
  target using a quadrotor.
\newblock In {\em {IEEE} International Conference on Robotics and Automation,
  {ICRA} 2012, 14-18 May, 2012, St. Paul, Minnesota, {USA}}, pages 2723--2730,
  2012.

\bibitem{ivanov2019verisig}
Radoslav Ivanov, James Weimer, Rajeev Alur, George~J Pappas, and Insup Lee.
\newblock Verisig: verifying safety properties of hybrid systems with neural
  network controllers.
\newblock In {\em Proceedings of the 22nd ACM International Conference on
  Hybrid Systems: Computation and Control}, pages 169--178, 2019.

\bibitem{reluplex}
Guy Katz, Clark Barrett, David~L Dill, Kyle Julian, and Mykel~J Kochenderfer.
\newblock Reluplex: An efficient smt solver for verifying deep neural networks.
\newblock In {\em International Conference on Computer Aided Verification},
  pages 97--117. Springer, 2017.

\bibitem{Marabou}
Guy Katz, Derek~A. Huang, Duligur Ibeling, Kyle Julian, Christopher Lazarus,
  Rachel Lim, Parth Shah, Shantanu Thakoor, Haoze Wu, Aleksandar Zeljic,
  David~L. Dill, Mykel~J. Kochenderfer, and Clark~W. Barrett.
\newblock The marabou framework for verification and analysis of deep neural
  networks.
\newblock In Isil Dillig and Serdar Tasiran, editors, {\em Computer Aided
  Verification - 31st International Conference, {CAV} 2019, New York City, NY,
  USA, July 15-18, 2019, Proceedings, Part {I}}, volume 11561 of {\em Lecture
  Notes in Computer Science}, pages 443--452. Springer, 2019.

\bibitem{le2019batch}
Hoang~M Le, Cameron Voloshin, and Yisong Yue.
\newblock Batch policy learning under constraints.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2019.

\bibitem{li_temporal_2019}
Xiao Li and Calin Belta.
\newblock Temporal {Logic} {Guided} {Safe} {Reinforcement} {Learning} {Using}
  {Control} {Barrier} {Functions}.
\newblock {\em arXiv:1903.09885 [cs, stat]}, March 2019.
\newblock arXiv: 1903.09885.

\bibitem{NN:DDPG}
Timothy~P. Lillicrap, Jonathan~J. Hunt, Alexander Pritzel, Nicolas Heess, Tom
  Erez, Yuval Tassa, David Silver, and Daan Wierstra.
\newblock Continuous control with deep reinforcement learning.
\newblock {\em CoRR}, abs/1509.02971, 2015.

\bibitem{MoldovanA12}
Teodor~Mihai Moldovan and Pieter Abbeel.
\newblock Safe exploration in markov decision processes.
\newblock In {\em Proceedings of the 29th International Conference on Machine
  Learning, {ICML} 2012, Edinburgh, Scotland, UK, June 26 - July 1, 2012}.
  icml.cc / Omnipress, 2012.

\bibitem{PerkinsB02}
Theodore~J. Perkins and Andrew~G. Barto.
\newblock Lyapunov design for safe reinforcement learning.
\newblock {\em J. Mach. Learn. Res.}, 3:803--832, 2002.

\bibitem{Ray2019}
Alex Ray, Joshua Achiam, and Dario Amodei.
\newblock {Benchmarking Safe Exploration in Deep Reinforcement Learning}.
\newblock 2019.

\bibitem{dagger}
St{\'{e}}phane Ross, Geoffrey~J. Gordon, and Drew Bagnell.
\newblock A reduction of imitation learning and structured prediction to
  no-regret online learning.
\newblock In {\em Proceedings of the Fourteenth International Conference on
  Artificial Intelligence and Statistics, {AISTATS} 2011, Fort Lauderdale, USA,
  April 11-13, 2011}, pages 627--635, 2011.

\bibitem{sun2019formal}
Xiaowu Sun, Haitham Khedr, and Yasser Shoukry.
\newblock Formal verification of neural network controlled autonomous systems.
\newblock In {\em Proceedings of the 22nd ACM International Conference on
  Hybrid Systems: Computation and Control}, pages 147--156, 2019.

\bibitem{sutton2000policy}
Richard~S Sutton, David~A McAllester, Satinder~P Singh, and Yishay Mansour.
\newblock Policy gradient methods for reinforcement learning with function
  approximation.
\newblock In {\em Advances in neural information processing systems}, pages
  1057--1063, 2000.

\bibitem{propel}
Abhinav Verma, Hoang Le, Yisong Yue, and Swarat Chaudhuri.
\newblock Imitation-projected programmatic reinforcement learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  15726--15737, 2019.

\bibitem{pirl}
Abhinav Verma, Vijayaraghavan Murali, Rishabh Singh, Pushmeet Kohli, and Swarat
  Chaudhuri.
\newblock Programmatically interpretable reinforcement learning.
\newblock In {\em International Conference on Machine Learning}, pages
  5052--5061, 2018.

\bibitem{reluval}
Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana.
\newblock Formal security analysis of neural networks using symbolic intervals.
\newblock In {\em 27th $\{$USENIX$\}$ Security Symposium ($\{$USENIX$\}$
  Security 18)}, pages 1599--1614, 2018.

\bibitem{ZhuShielding}
He~Zhu, Zikang Xiong, Stephen Magill, and Suresh Jagannathan.
\newblock An inductive synthesis framework for verifiable reinforcement
  learning.
\newblock {\em CoRR}, abs/1907.07273, 2019.

\end{thebibliography}
