@article{mermillod2013stability,
  title={The stability-plasticity dilemma: Investigating the continuum from catastrophic forgetting to age-limited learning effects},
  author={Mermillod, Martial and Bugaiska, Aur{\'e}lia and Bonin, Patrick},
  journal={Frontiers in psychology},
  volume={4},
  pages={504},
  year={2013},
  publisher={Frontiers}
}

@article{caccia2021special,
  title={SPeCiaL: Self-Supervised Pretraining for Continual Learning},
  author={Caccia, Lucas and Pineau, Joelle},
  journal={arXiv preprint arXiv:2106.09065},
  year={2021}
}

@article{Douillard2021ContinuumSM,
  title={Continuum: Simple Management of Complex Continual Learning Scenarios},
  author={Arthur Douillard and Timoth{\'e}e Lesort},
  journal={ArXiv},
  year={2021},
  volume={abs/2102.06253}
}

@misc{lesort2021continual,
      title={Continual Learning in Deep Networks: an Analysis of the Last Layer}, 
      author={Timothée Lesort and Thomas George and Irina Rish},
      year={2021},
      eprint={2106.01834},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@misc{khetarpal2020continual,
      title={Towards Continual Reinforcement Learning: A Review and Perspectives}, 
      author={Khimya Khetarpal and Matthew Riemer and Irina Rish and Doina Precup},
      year={2020},
      eprint={2012.13490},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{article,
author = {Hadsell, Raia and Rao, Dushyant and Rusu, Andrei and Pascanu, Razvan},
year = {2020},
month = {12},
pages = {1028-1040},
title = {Embracing Change: Continual Learning in Deep Neural Networks},
volume = {24},
journal = {Trends in Cognitive Sciences},
doi = {10.1016/j.tics.2020.09.004}
}

@InProceedings{lomonaco2021avalanche,
    title={Avalanche: an End-to-End Library for Continual Learning},
    author={Vincenzo Lomonaco and Lorenzo Pellegrini and Andrea Cossu and Antonio Carta and Gabriele Graffieti and Tyler L. Hayes and Matthias De Lange and Marc Masana and Jary Pomponi and Gido van de Ven and Martin Mundt and Qi She and Keiland Cooper and Jeremy Forest and Eden Belouadah and Simone Calderara and German I. Parisi and Fabio Cuzzolin and Andreas Tolias and Simone Scardapane and Luca Antiga and Subutai Amhad and Adrian Popescu and Christopher Kanan and Joost van de Weijer and Tinne Tuytelaars and Davide Bacciu and Davide Maltoni},
    booktitle={Proceedings of IEEE Conference on Computer Vision and Pattern Recognition},
    series={2nd Continual Learning in Computer Vision Workshop},
    year={2021}
}

@article{Lomonaco2020CVPR2C,
  title={CVPR 2020 Continual Learning in Computer Vision Competition: Approaches, Results, Current Challenges and Future Directions},
  author={Vincenzo Lomonaco and Lorenzo Pellegrini and Pau Rodr{\'i}guez and Massimo Caccia and Qi She and Yu Chen and Quentin Jodelet and Ruiping Wang and Zheda Mai and David V{\'a}zquez and German Ignacio Parisi and Nikhil Churamani and Marc Pickett and Issam H. Laradji and Davide Maltoni},
  journal={ArXiv},
  year={2020},
  volume={abs/2009.09929}
}

@misc{mundt2021clevacompass,
      title={CLEVA-Compass: A Continual Learning EValuation Assessment Compass to Promote Research Transparency and Comparability}, 
      author={Martin Mundt and Steven Lang and Quentin Delfosse and Kristian Kersting},
      year={2021},
      eprint={2110.03331},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{von2021learning,
  title={Learning where to learn: Gradient sparsity in meta and continual learning},
  author={von Oswald, Johannes and Zhao, Dominic and Kobayashi, Seijin and Schug, Simon and Caccia, Massimo and Zucchet, Nicolas and Sacramento, Jo{\~a}o},
  journal={NeurIPS 2021},
  year={2021}
}

@misc{normandin2021sequoia,
      title={Sequoia: A Software Framework to Unify Continual Learning Research}, 
      author={Fabrice Normandin and Florian Golemo and Oleksiy Ostapenko and Pau Rodriguez and Matthew D Riemer and Julio Hurtado and Khimya Khetarpal and Dominic Zhao and Ryan Lindeborg and Timothée Lesort and Laurent Charlin and Irina Rish and Massimo Caccia},
      year={2021},
      eprint={2108.01005},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{mundt2020wholistic,
      title={A Wholistic View of Continual Learning with Deep Neural Networks: Forgotten Lessons and the Bridge to Active and Open World Learning}, 
      author={Martin Mundt and Yong Won Hong and Iuliia Pliushch and Visvanathan Ramesh},
      year={2020},
      eprint={2009.01797},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{DeLange2019ContinualLA,
  title={Continual learning: A comparative study on how to defy forgetting in classification tasks},
  author={Matthias De Lange and Rahaf Aljundi and Marc Masana and Sarah Parisot and Xu Jia and Ale{\vs} Leonardis and Gregory G. Slabaugh and Tinne Tuytelaars},
  journal={ArXiv},
  year={2019},
  volume={abs/1909.08383}
}

@article{caccia2021reducing,
  title={Reducing Representation Drift in Online Continual Learning},
  author={Caccia, Lucas and Aljundi, Rahaf and Tuytelaars, Tinne and Pineau, Joelle and Belilovsky, Eugene},
  journal={arXiv preprint arXiv:2104.05025},
  year={2021}
}


@article{french1997pseudo,
  title={Pseudo-recurrent connectionist networks: An approach to the'sensitivity-stability'dilemma},
  author={French, Robert M},
  journal={Connection Science},
  volume={9},
  number={4},
  pages={353--380},
  year={1997},
  publisher={Taylor \& Francis}
}
@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Springer}
}
@article{whittington2017approximation,
  title={An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity},
  author={Whittington, James CR and Bogacz, Rafal},
  journal={Neural computation},
  volume={29},
  number={5},
  pages={1229--1262},
  year={2017},
  publisher={MIT Press}
}
@article{chaudhry2019continual,
  title={Continual learning with tiny episodic memories},
  author={Chaudhry, Arslan and Rohrbach, Marcus and Elhoseiny, Mohamed and Ajanthan, Thalaiyasingam and Dokania, Puneet K and Torr, Philip HS and Ranzato, M},
  year={2019}
}
@inproceedings{serra2018overcoming,
  title={Overcoming catastrophic forgetting with hard attention to the task},
  author={Serra, Joan and Suris, Didac and Miron, Marius and Karatzoglou, Alexandros},
  booktitle={International Conference on Machine Learning},
  pages={4548--4557},
  year={2018},
  organization={PMLR}
}
@inproceedings{madan2021fast,     
title={Fast And Slow Learning Of Recurrent Independent Mechanisms},
author={Kanika Madan and Nan Rosemary Ke and Anirudh Goyal and Bernhard Sch{\"o}lkopf and Yoshua Bengio},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=Lc28QAB4ypz}
}
@article{goyal2021coordination,
  title={Coordination Among Neural Modules Through a Shared Global Workspace},
  author={Goyal, Anirudh and Didolkar, Aniket and Lamb, Alex and Badola, Kartikeya and Ke, Nan Rosemary and Rahaman, Nasim and Binas, Jonathan and Blundell, Charles and Mozer, Michael and Bengio, Yoshua},
  journal={arXiv preprint arXiv:2103.01197},
  year={2021}
}

%---
@article{Gupta2018UnsupervisedMF,
  title={Unsupervised Meta-Learning for Reinforcement Learning},
  author={Abhishek Gupta and Benjamin Eysenbach and Chelsea Finn and Sergey Levine},
  journal={ArXiv},
  year={2018},
  volume={abs/1806.04640}
}

@article{van2019three,
  title={Three scenarios for continual learning},
  author={van de Ven, Gido M and Tolias, Andreas S},
  journal={arXiv preprint arXiv:1904.07734},
  year={2019}
}

%------ Semi supervised 
@article{zhang2017mixup,
  title={mixup: Beyond empirical risk minimization},
  author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1710.09412},
  year={2017}
}
@inproceedings{rasmus2015semi,
  title={Semi-supervised learning with ladder networks},
  author={Rasmus, Antti and Berglund, Mathias and Honkala, Mikko and Valpola, Harri and Raiko, Tapani},
  booktitle={Advances in neural information processing systems},
  pages={3546--3554},
  year={2015}
}
@article{miyato2018virtual,
  title={Virtual adversarial training: a regularization method for supervised and semi-supervised learning},
  author={Miyato, Takeru and Maeda, Shin-ichi and Koyama, Masanori and Ishii, Shin},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={8},
  pages={1979--1993},
  year={2018},
  publisher={IEEE}
}
@inproceedings{tarvainen2017mean,
  title={Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results},
  author={Tarvainen, Antti and Valpola, Harri},
  booktitle={Advances in neural information processing systems},
  pages={1195--1204},
  year={2017}
}
@article{verma2019interpolation,
  title={Interpolation consistency training for semi-supervised learning},
  author={Verma, Vikas and Lamb, Alex and Kannala, Juho and Bengio, Yoshua and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1903.03825},
  year={2019}
}
@article{ma2018noise,
  title={Noise contrastive estimation and negative sampling for conditional models: Consistency and statistical efficiency},
  author={Ma, Zhuang and Collins, Michael},
  journal={arXiv preprint arXiv:1809.01812},
  year={2018}
}
%--------------------------------
@article{kingma2014adam,           
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{pathak2016context,
  title={Context encoders: Feature learning by inpainting},
  author={Pathak, Deepak and Krahenbuhl, Philipp and Donahue, Jeff and Darrell, Trevor and Efros, Alexei A},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2536--2544},
  year={2016}
}
@inproceedings{hadsell2006dimensionality,
  title={Dimensionality reduction by learning an invariant mapping},
  author={Hadsell, Raia and Chopra, Sumit and LeCun, Yann},
  booktitle={2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)},
  volume={2},
  pages={1735--1742},
  year={2006},
  organization={IEEE}
}

@article{antoniou2020defining,
  title={Defining Benchmarks for Continual Few-Shot Learning},
  author={Antoniou, Antreas and Patacchiola, Massimiliano and Ochal, Mateusz and Storkey, Amos},
  journal={arXiv preprint arXiv:2004.11967},
  year={2020}
}
@misc{
guillaume2020ovainn,
title={OvA-{\{}INN{\}}: Continual Learning with Invertible Neural Networks},
author={HOCQUET Guillaume and BICHLER Olivier and QUERLIOZ Damien},
year={2020},
url={https://openreview.net/forum?id=rJxcBpNKPr}
}
@inproceedings{ballard1987modular,
  title={Modular Learning in Neural Networks.},
  author={Ballard, Dana H},
  booktitle={AAAI},
  pages={279--284},
  year={1987}
}
@inproceedings{ritter2018online,       
  title={Online structured laplace approximations for overcoming catastrophic forgetting},
  author={Ritter, Hippolyt and Botev, Aleksandar and Barber, David},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3738--3748},
  year={2018}
}
@misc{he2015deep,
  title={Deep residual learning for image recognition. CoRR abs/1512.03385 (2015)},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  year={2015}
}
@TECHREPORT{Krizhevsky09learningmultiple,
    author = {Alex Krizhevsky},             
    title = {Learning multiple layers of features from tiny images},
    institution = {},
    year = {2009}
}
@article{srinivas2020curl,    
  title={Curl: Contrastive unsupervised representations for reinforcement learning},
  author={Srinivas, Aravind and Laskin, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2004.04136},
  year={2020}
}
@article{li2020prototypical,
  title={Prototypical Contrastive Learning of Unsupervised Representations},
  author={Li, Junnan and Zhou, Pan and Xiong, Caiming and Socher, Richard and Hoi, Steven CH},
  journal={arXiv preprint arXiv:2005.04966},
  year={2020}
}
@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2020}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}
@article{farquhar2018towards,
  title={Towards robust evaluations of continual learning},
  author={Farquhar, Sebastian and Gal, Yarin},
  journal={arXiv preprint arXiv:1805.09733},
  year={2018}
}
@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}
@article{Sun2019UnsupervisedDA,
  title={Unsupervised Domain Adaptation through Self-Supervision},
  author={Yan-yan Sun and Eric Tzeng and Trevor Darrell and Alexei A. Efros},
  journal={ArXiv},
  year={2019},
  volume={abs/1909.11825}
}

@article{Larsson2017ColorizationAA,
  title={Colorization as a Proxy Task for Visual Understanding},
  author={Gustav Larsson and Michael Maire and Gregory Shakhnarovich},
  journal={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017},
  pages={840-849}
}

@misc{lesort2021understanding,
      title={Understanding Continual Learning Settings with Data Distribution Drift Analysis}, 
      author={Timothée Lesort and Massimo Caccia and Irina Rish},
      year={2021},
      eprint={2104.01678},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{Carlucci2019DomainGB,
  title={Domain Generalization by Solving Jigsaw Puzzles},
  author={Fabio Maria Carlucci and Antonio D'Innocente and Silvia Bucci and Barbara Caputo and Tatiana Tommasi},
  journal={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019},
  pages={2224-2233}
}

@inproceedings{Hendrycks2019UsingSL,
  title={Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty},
  author={Dan Hendrycks and Mantas Mazeika and Saurav Kadavath and Dawn Song},
  booktitle={NeurIPS},
  year={2019}
}

@article{Gidaris2018UnsupervisedRL,
  title={Unsupervised Representation Learning by Predicting Image Rotations},
  author={Spyros Gidaris and Praveer Singh and Nikos Komodakis},
  journal={ArXiv},
  year={2018},
  volume={abs/1803.07728}
}

@article{Zhai2019S4LSS,
  title={S4L: Self-Supervised Semi-Supervised Learning},
  author={Xiaohua Zhai and Avital Oliver and Alexander Kolesnikov and Lucas Beyer},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.03670}
}

@incollection{dosovitskiy2014exemplarcnn,  
title = {Discriminative Unsupervised Feature Learning with Convolutional Neural Networks},
author = {Dosovitskiy, Alexey and Springenberg, Jost Tobias and Riedmiller, Martin and Brox, Thomas},
booktitle = {Advances in Neural Information Processing Systems 27},
editor = {Z. Ghahramani and M. Welling and C. Cortes and N. D. Lawrence and K. Q. Weinberger},
pages = {766--774},
year = {2014},
publisher = {Curran Associates, Inc.}}

@inproceedings{doersch2015patch,
author = {Doersch, Carl and Gupta, Abhinav and Efros, Alexei A.},
title = {Unsupervised Visual Representation Learning by Context Prediction},
year = {2015},
isbn = {9781467383912},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICCV.2015.167},
doi = {10.1109/ICCV.2015.167},
booktitle = {Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV)},
pages = {1422–1430},
numpages = {9},
series = {ICCV ’15}
}


@incollection{OML,
    crossref={javed2019om}
}
@incollection{javed2019oml,
title = {Meta-Learning Representations for Continual Learning},
author = {Javed, Khurram and White, Martha},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {1820--1830},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8458-meta-learning-representations-for-continual-learning.pdf}
}

@inproceedings{noroozi2016unsupervised,
  title={Unsupervised learning of visual representations by solving jigsaw puzzles},
  author={Noroozi, Mehdi and Favaro, Paolo},
  booktitle={European Conference on Computer Vision},
  pages={69--84},
  year={2016},
  organization={Springer}
}

@inproceedings{zhang2016colorful,
  title={Colorful image colorization},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A},
  booktitle={European conference on computer vision},
  pages={649--666},
  year={2016},
  organization={Springer}
}

@inproceedings{zhang2017split,
  title={Split-brain autoencoders: Unsupervised learning by cross-channel prediction},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1058--1067},
  year={2017}
}

@inproceedings{misra2016shuffle,
  title={Shuffle and learn: unsupervised learning using temporal order verification},
  author={Misra, Ishan and Zitnick, C Lawrence and Hebert, Martial},
  booktitle={European Conference on Computer Vision},
  pages={527--544},
  year={2016},
  organization={Springer}
}
@article{de2019continual,
  title={Continual learning: A comparative study on how to defy forgetting in classification tasks},
  author={De Lange, Matthias and Aljundi, Rahaf and Masana, Marc and Parisot, Sarah and Jia, Xu and Leonardis, Ales and Slabaugh, Gregory and Tuytelaars, Tinne},
  journal={arXiv preprint arXiv:1909.08383},
  year={2019}
}

@article{li2017learning,
  title={Learning without forgetting},
  author={Li, Zhizhong and Hoiem, Derek},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={40},
  number={12},
  pages={2935--2947},
  year={2017},
  publisher={IEEE}
}

@inproceedings{lopez2017gradient,
  title={Gradient episodic memory for continual learning},
  author={Lopez-Paz, David and Ranzato, Marc'Aurelio},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6467--6476},
  year={2017}
}

@inproceedings{
chaudhry2018efficient,
title={Efficient Lifelong Learning with A-{GEM}},
author={Arslan Chaudhry and Marc’Aurelio Ranzato and Marcus Rohrbach and Mohamed Elhoseiny},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=Hkf2_sC5FX},
}

@inproceedings{mallya2018packnet,
  title={Packnet: Adding multiple tasks to a single network by iterative pruning},
  author={Mallya, Arun and Lazebnik, Svetlana},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7765--7773},
  year={2018}
}

@InProceedings{pmlr-v70-finn17a,
  title = 	 {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
  author = 	 {Chelsea Finn and Pieter Abbeel and Sergey Levine},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1126--1135},
  year = 	 {2017},
  editor = 	 {Doina Precup and Yee Whye Teh},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {International Convention Centre, Sydney, Australia},
  month = 	 {06--11 Aug},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/finn17a/finn17a.pdf},
  url = 	 {http://proceedings.mlr.press/v70/finn17a.html},
  abstract = 	 {We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.}
}

@inproceedings{carmon2019unlabeled,
  title={Unlabeled data improves adversarial robustness},
  author={Carmon, Yair and Raghunathan, Aditi and Schmidt, Ludwig and Duchi, John C and Liang, Percy S},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11190--11201},
  year={2019}
}

@article{FRENCH1999128,
title = "Catastrophic forgetting in connectionist networks",
journal = "Trends in Cognitive Sciences",
volume = "3",
number = "4",
pages = "128 - 135",
year = "1999",
issn = "1364-6613",
doi = "https://doi.org/10.1016/S1364-6613(99)01294-2",
url = "http://www.sciencedirect.com/science/article/pii/S1364661399012942",
author = "Robert M. French",
keywords = "Catastrophic forgetting, Connectionist networks, Connectionism, Memory, Learning, Interference",
abstract = "All natural cognitive systems, and, in particular, our own, gradually forget previously learned information. Plausible models of human cognition should therefore exhibit similar patterns of gradual forgetting of old information as new information is acquired. Only rarely does new learning in natural cognitive systems completely disrupt or erase previously learned information; that is, natural cognitive systems do not, in general, forget ‘catastrophically’. Unfortunately, though, catastrophic forgetting does occur under certain circumstances in distributed connectionist networks. The very features that give these networks their remarkable abilities to generalize, to function in the presence of degraded input, and so on, are found to be the root cause of catastrophic forgetting. The challenge in this field is to discover how to keep the advantages of distributed connectionist networks while avoiding the problem of catastrophic forgetting. In this article the causes, consequences and numerous solutions to the problem of catastrophic forgetting in neural networks are examined. The review will consider how the brain might have overcome this problem and will also explore the consequences of this solution for distributed connectionist networks."
}

@inproceedings{distillation2015,
title	= {Distilling the Knowledge in a Neural Network},
author	= {Geoffrey Hinton and Oriol Vinyals and Jeffrey Dean},
year	= {2015},
URL	= {http://arxiv.org/abs/1503.02531},
booktitle	= {NIPS Deep Learning and Representation Learning Workshop}
}

@inproceedings{adam2015,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6980},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{SimCLR,
    crossref = {chen2020simple}
 }
@article{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  journal={arXiv preprint arXiv:2002.05709},
  year={2020}
}

@inproceedings{VAE,
  author    = {Diederik P. Kingma and
               Max Welling},
  title     = {Auto-Encoding Variational Bayes},
  booktitle = {2nd International Conference on Learning Representations, {ICLR} 2014,
               Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings},
  year      = {2014},
  url       = {http://arxiv.org/abs/1312.6114},
  timestamp = {Thu, 04 Apr 2019 13:20:07 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/KingmaW13},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{MoCo,
    crossref={He2019MomentumCF}
}
@article{He2019MomentumCF,
  title={Momentum Contrast for Unsupervised Visual Representation Learning},
  author={Kaiming He and Haoqi Fan and Yuxin Wu and Saining Xie and Ross B. Girshick},
  journal={ArXiv},
  year={2019},
  volume={abs/1911.05722}
}

@article{multi-task-ssl-ood-detection,
    crossref={Albuquerque2020ImprovingOG}
}
@article{Albuquerque2020ImprovingOG,
  title={Improving out-of-distribution generalization via multi-task self-supervised pretraining},
  author={Isabela Albuquerque and Nikhil Naik and Junnan Li and Nitish Shirish Keskar and Richard Socher},
  journal={ArXiv},
  year={2020},
  volume={abs/2003.13525}
}
@article{caccia2020online,
  title={Online Fast Adaptation and Knowledge Accumulation: a New Approach to Continual Learning},
  author={Caccia, Massimo and Rodriguez, Pau and Ostapenko, Oleksiy and Normandin, Fabrice and Lin, Min and Caccia, Lucas and Laradji, Issam and Rish, Irina and Lacoste, Alexande and Vazquez, David and others},
  journal={arXiv preprint arXiv:2003.05856},
  year={2020}
}
@misc{shazeer2017outrageously,
      title={Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer}, 
      author={Noam Shazeer and Azalia Mirhoseini and Krzysztof Maziarz and Andy Davis and Quoc Le and Geoffrey Hinton and Jeff Dean},
      year={2017},
      eprint={1701.06538},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{rao2019continual,
  title={Continual Unsupervised Representation Learning},
  author={Rao, Dushyant and Visin, Francesco and Rusu, Andrei and Pascanu, Razvan and Teh, Yee Whye and Hadsell, Raia},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7645--7655},
  year={2019}
}
@article{smith2019unsupervised,
  title={Unsupervised Progressive Learning and the STAM Architecture},
  author={Smith, James and Dovrolis, Constantine},
  journal={arXiv preprint arXiv:1904.02021},
  year={2019}
}
























%------------------
@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}
@article{gunasekar2018characterizing,
  title={Characterizing implicit bias in terms of optimization geometry},
  author={Gunasekar, Suriya and Lee, Jason and Soudry, Daniel and Srebro, Nathan},
  journal={arXiv preprint arXiv:1802.08246},
  year={2018}
}
@inproceedings{neyshabur2017exploring, 
  title={Exploring generalization in deep learning},
  author={Neyshabur, Behnam and Bhojanapalli, Srinadh and McAllester, David and Srebro, Nati},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5947--5956},
  year={2017}
}
@article{soudry2018implicit,
  title={The implicit bias of gradient descent on separable data},
  author={Soudry, Daniel and Hoffer, Elad and Nacson, Mor Shpigel and Gunasekar, Suriya and Srebro, Nathan},
  journal={The Journal of Machine Learning Research},
  volume={19},
  number={1},
  pages={2822--2878},
  year={2018},
  publisher={JMLR. org}
}
@article{goodfellow2013empirical,
  title={An empirical investigation of catastrophic forgetting in gradient-based neural networks},
  author={Goodfellow, Ian J and Mirza, Mehdi and Xiao, Da and Courville, Aaron and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1312.6211},
  year={2013}
}
@article{parisi2019continual, 
  title={Continual lifelong learning with neural networks: A review},
  author={Parisi, German I and Kemker, Ronald and Part, Jose L and Kanan, Christopher and Wermter, Stefan},
  journal={Neural Networks},
  year={2019},
  publisher={Elsevier}
}

@article{farquhar2018towards,
  title={Towards robust evaluations of continual learning},
  author={Farquhar, Sebastian and Gal, Yarin},
  journal={arXiv preprint arXiv:1805.09733},
  year={2018}
}
@article{lecun-mnisthandwrittendigit-2010,
  added-at = {2010-06-28T21:16:30.000+0200},
  author = {LeCun, Yann and Cortes, Corinna},
  biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
  groups = {public},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  interhash = {21b9d0558bd66279df9452562df6e6f3},
  intrahash = {935bad99fa1f65e03c25b315aa3c1032},
  keywords = {MSc _checked character_recognition mnist network neural},
  lastchecked = {2016-01-14 14:24:11},
  timestamp = {2016-07-12T19:25:30.000+0200},
  title = {{MNIST} handwritten digit database},
  url = {http://yann.lecun.com/exdb/mnist/},
  username = {mhwombat},
  year = 2010
}


@inproceedings{imagenet_cvpr09,
        AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
        TITLE = {{ImageNet: A Large-Scale Hierarchical Image Database}},
        BOOKTITLE = {CVPR09},
        YEAR = {2009},
        BIBSOURCE = "http://www.image-net.org/papers/imagenet_cvpr09.bib"}
@article{he2019momentum, 
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  journal={arXiv preprint arXiv:1911.05722},
  year={2019}
}
@inproceedings{tishby2015deep,
  title={Deep learning and the information bottleneck principle},
  author={Tishby, Naftali and Zaslavsky, Noga},
  booktitle={2015 IEEE Information Theory Workshop (ITW)},
  pages={1--5},
  year={2015},
  organization={IEEE}
}
@article{ghorbani2019investigation,
  title={An investigation into neural net optimization via hessian eigenvalue density},
  author={Ghorbani, Behrooz and Krishnan, Shankar and Xiao, Ying},
  journal={arXiv preprint arXiv:1901.10159},
  year={2019}
}
@article{liang2017fisher,
  title={Fisher-rao metric, geometry, and complexity of neural networks},
  author={Liang, Tengyuan and Poggio, Tomaso and Rakhlin, Alexander and Stokes, James},
  journal={arXiv preprint arXiv:1711.01530},
  year={2017}
}
@article{wang2018identifying,
  title={Identifying generalization properties in neural networks},
  author={Wang, Huan and Keskar, Nitish Shirish and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:1809.07402},
  year={2018}
}
@article{jastrzebski2018relation,
  title={On the relation between the sharpest directions of DNN loss and the SGD step length},
  author={Jastrzebski, Stanislaw and Kenton, Zachary and Ballas, Nicolas and Fischer, Asja and Bengio, Yoshua and Storkey, Amos},
  journal={arXiv preprint arXiv:1807.05031},
  year={2018}
}
@article{sagun2017empirical,
  title={Empirical analysis of the hessian of over-parametrized neural networks},
  author={Sagun, Levent and Evci, Utku and Guney, V Ugur and Dauphin, Yann and Bottou, Leon},
  journal={arXiv preprint arXiv:1706.04454},
  year={2017}
}
@inproceedings{dinh2017sharp,
  title={Sharp minima can generalize for deep nets},
  author={Dinh, Laurent and Pascanu, Razvan and Bengio, Samy and Bengio, Yoshua},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1019--1028},
  year={2017},
  organization={JMLR. org}
}
@inproceedings{hinton93keeping,
  title={Keeping neural networks simple by minimising the description length of weights. 1993},
  author={Hinton, GE and von Cramp, D},
  booktitle={Proceedings of COLT-93},
  pages={5--13}
}
@inproceedings{hochreiter1995simplifying,
  title={Simplifying neural nets by discovering flat minima},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  booktitle={Advances in neural information processing systems},
  pages={529--536},
  year={1995}
}
@article{jiang2019fantastic,
  title={Fantastic Generalization Measures and Where to Find Them},
  author={Jiang, Yiding and Neyshabur, Behnam and Mobahi, Hossein and Krishnan, Dilip and Bengio, Samy},
  journal={arXiv preprint arXiv:1912.02178},
  year={2019}
}
@article{petzka2020feature,
  title={Feature-Robustness, Flatness and Generalization Error for Deep Neural Networks},
  author={Petzka, Henning and Adilova, Linara and Kamp, Michael and Sminchisescu, Cristian},
  journal={arXiv preprint arXiv:2001.00939},
  year={2020}
}
@article{achille2018emergence,
  title={Emergence of invariance and disentanglement in deep representations},
  author={Achille, Alessandro and Soatto, Stefano},
  journal={The Journal of Machine Learning Research},
  volume={19},
  number={1},
  pages={1947--1980},
  year={2018},
  publisher={JMLR. org}
}
@inproceedings{mcallester1999pac,
  title={PAC-Bayesian model averaging},
  author={McAllester, David A},
  booktitle={Proceedings of the twelfth annual conference on Computational learning theory},
  pages={164--170},
  year={1999}
}
@article{keskar2016large,
  title={On large-batch training for deep learning: Generalization gap and sharp minima},
  author={Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
  journal={arXiv preprint arXiv:1609.04836},
  year={2016}
}
@article{chaudhari2019entropy,
  title={Entropy-sgd: Biasing gradient descent into wide valleys},
  author={Chaudhari, Pratik and Choromanska, Anna and Soatto, Stefano and LeCun, Yann and Baldassi, Carlo and Borgs, Christian and Chayes, Jennifer and Sagun, Levent and Zecchina, Riccardo},
  journal={Journal of Statistical Mechanics: Theory and Experiment},
  volume={2019},
  number={12},
  pages={124018},
  year={2019},
  publisher={IOP Publishing}
}
@article{izmailov2018averaging,
  title={Averaging weights leads to wider optima and better generalization},
  author={Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},
  journal={arXiv preprint arXiv:1803.05407},
  year={2018}
}
@article{achille2018information,
  title={Information dropout: Learning optimal representations through noisy computation},
  author={Achille, Alessandro and Soatto, Stefano},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={40},
  number={12},
  pages={2897--2905},
  year={2018},
  publisher={IEEE}
}
@inproceedings{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  booktitle={Advances in neural information processing systems},
  pages={8571--8580},
  year={2018}
}

}
@article{maddox2020rethinking,
  title={Rethinking Parameter Counting in Deep Models: Effective Dimensionality Revisited},
  author={Maddox, Wesley and J, Benton and Gregory, Wilson, Andrew and Gordon },
  journal={arXiv preprint arXiv:2003.02139},
  year={2020}
}





%%%%%%Continual Learning 
@article{schwarz2018progress, 
  title={Progress \& compress: A scalable framework for continual learning},
  author={Schwarz, Jonathan and Luketina, Jelena and Czarnecki, Wojciech M and Grabska-Barwinska, Agnieszka and Teh, Yee Whye and Pascanu, Razvan and Hadsell, Raia},
  journal={arXiv preprint arXiv:1805.06370},
  year={2018}
}
@article{Dyn_expand_net_Lee,
  author    = {Jeongtae Lee and
               Jaehong Yoon and
               Eunho Yang and
               Sung Ju Hwang},
  title     = {Lifelong Learning with Dynamically Expandable Networks},
  journal   = {CoRR},
  volume    = {abs/1708.01547},
  year      = {2017},
}

@inproceedings{paszke2019pytorch,
  title={PyTorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2019}
}
@inproceedings{ostapenko2019learning,
  title={Learning to remember: A synaptic plasticity driven framework for continual learning},
  author={Ostapenko, Oleksiy and Puscas, Mihai and Klein, Tassilo and Jahnichen, Patrick and Nabi, Moin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11321--11329},
  year={2019}
}
@inproceedings{xu2018,
 title={Reinforced Continual Learning},
 author={J. Xu and Z. Zhu,},
 booktitle={Advances in Neural Information Processing Systems (NIPS)},
 year={2018}
 }

@inproceedings{shin2017continual,
  title={Continual learning with deep generative replay},
  author={Shin, Hanul and Lee, Jung Kwon and Kim, Jaehong and Kim, Jiwon},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{rolnick2019experience,
  title={Experience replay for continual learning},
  author={Rolnick, David and Ahuja, Arun and Schwarz, Jonathan and Lillicrap, Timothy and Wayne, Gregory},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}

@inproceedings{isele2018selective,
  title={Selective experience replay for lifelong learning},
  author={Isele, David and Cosgun, Akansel},
  booktitle={AAAI conference on artificial intelligence},
  year={2018}
}

@inproceedings{rebuffi2017icarl,
  title={icarl: Incremental classifier and representation learning},
  author={Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Sperl, Georg and Lampert, Christoph H},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  year={2017}
}

@inproceedings{graves2011practical,
  title={Practical variational inference for neural networks},
  author={Graves, Alex},
  booktitle={Advances in neural information processing systems (NIPS)},
  year={2011}
}

@incollection{Thrun95,
  title={Lifelong robot learning},
  author={Thrun, Sebastian and Mitchell, Tom M},
  booktitle={The biology and technology of intelligent autonomous agents},
  pages={165--196},
  year={1995},
  publisher={Springer}
}

@article{Farquhar18,
  title={Towards Robust Evaluations of Continual Learning},
  author={Farquhar, Sebastian and Gal, Yarin},
  journal={arXiv preprint arXiv:1805.09733},
  year={2018}
}

@article{xiao2017fashion,
  title={Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms},
  author={Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  journal={arXiv preprint arXiv:1708.07747},
  year={2017}
}

@article{lake2015human,
  title={Human-level concept learning through probabilistic program induction},
  author={Lake, Brenden M and Salakhutdinov, Ruslan and Tenenbaum, Joshua B},
  journal={Science},
  volume={350},
  number={6266},
  pages={1332--1338},
  year={2015},
  publisher={American Association for the Advancement of Science}
}

@article{lacoste2018uncertainty,
  title={Uncertainty in multitask transfer learning},
  author={Lacoste, Alexandre and Oreshkin, Boris and Chung, Wonchang and Boquet, Thomas and Rostamzadeh, Negar and Krueger, David},
  journal={arXiv preprint arXiv:1806.07528},
  year={2018}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@inproceedings{Chaudhry19,
  title={Efficient Lifelong Learning with {A-GEM}},
  author={Chaudhry, Arslan and Ranzato, Marc’Aurelio and Rohrbach, Marcus and Elhoseiny, Mohamed},
  booktitle={International Conference of Learning Representations (ICLR)},
  year={2019}
}

@incollection{Lopez-Paz17,
  title = {Gradient Episodic Memory for Continual Learning},
  author = {Lopez-Paz, David and Ranzato, Marc-Aurelio},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year = {2017},
}
@inproceedings{rezende2015variational,
  title={Variational inference with normalizing flows},
  author={Rezende, Danilo and Mohamed, Shakir},
  booktitle={International conference on machine learning},
  pages={1530--1538},
  year={2015},
  organization={PMLR}
}
@inproceedings{Shin17,
  title={Continual learning with deep generative replay},
  author={Shin, Hanul and Lee, Jung Kwon and Kim, Jaehong and Kim, Jiwon},
  booktitle={Advances in Neural Information Processing Systems (NIPS)},
  year={2017}
}

@ARTICLE{Goodfellow13,
  author = {{Goodfellow}, I.~J. and {Mirza}, M. and {Xiao}, D. and {Courville}, A. and {Bengio}, Y.},
  title = "{An Empirical Investigation of Catastrophic Forgetting in Gradient-Based Neural Networks}",
  journal = {ArXiv e-prints},
  year = 2013,
}

@misc{lange2019continual,
  title={Continual learning: A comparative study on how to defy forgetting in classification tasks},
  author={Matthias De Lange and Rahaf Aljundi and Marc Masana and Sarah Parisot and Xu Jia and Ales Leonardis and Gregory Slabaugh and Tinne Tuytelaars},
  year={2019},
  eprint={1909.08383},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}

@article{lesort2019continual,
  title={Continual Learning for Robotics},
  author={Timothée Lesort and Vincenzo Lomonaco and Andrei Stoian and Davide Maltoni and David Filliat and Natalia Díaz-Rodríguez},
  journal   = {ArXiv},
  volume    = {abs/1907.00182},
  year      = {2019},
}

@article{Parisi18review,
  title = "Continual lifelong learning with neural networks: A review",
  journal = "Neural Networks",
  volume = "113",
  pages = "54 - 71",
  year = "2019",
  author = "German I. Parisi and Ronald Kemker and Jose L. Part and Christopher Kanan and Stefan Wermter",
}

@article{Swaroop2019ImprovingAU,
  title={Improving and Understanding Variational Continual Learning},
  author={Siddharth Swaroop and Cuong V. Nguyen and Thang D. Bui and Richard E. Turner},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.02099}
}

@article{Ebrahimi2019UncertaintyguidedCL,
  title={Uncertainty-guided Continual Learning with Bayesian Neural Networks},
  author={Sayna Ebrahimi and Mohamed Elhoseiny and Trevor Darrell and Marcus Rohrbach},
  journal={ArXiv},
  year={2019},
  volume={abs/1906.02425}
}

@incollection{NIPS2019_8690,
  title = {Uncertainty-based Continual Learning with Adaptive Regularization},
  author = {Ahn, Hongjoon and Cha, Sungmin and Lee, Donggyu and Moon, Taesup},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year = {2019},
}

@misc{zeno2018task,
  title={Task Agnostic Continual Learning Using Online Variational Bayes},
  author={Chen Zeno and Itay Golan and Elad Hoffer and Daniel Soudry},
  year={2018},
  eprint={1803.10123},
  archivePrefix={arXiv},
  primaryClass={stat.ML}
}

@inproceedings{He18,
  title={Overcoming Catastrophic Interference using Conceptor-Aided Backpropagation},
  author={Xu He and Herbert Jaeger},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018},
}

@article{Serra18,
  title = 	 {Overcoming Catastrophic Forgetting with Hard Attention to the Task},
  author = 	 {Serra, Joan and Suris, Didac and Miron, Marius and Karatzoglou, Alexandros},
  journal   = {International Conference on Machine Learning (ICML)},
  year = 	 {2018},
}

@inproceedings{Chaudhry18,
  title={Riemannian Walk for Incremental Learning: Understanding Forgetting and Intransigence},
  author={Chaudhry, Arslan and Dokania, Puneet K and Ajanthan, Thalaiyasingam and Torr, Philip HS},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2018}
}

@article{Aljundi17,
  author    = {Rahaf Aljundi and Francesca Babiloni and Mohamed Elhoseiny and Marcus Rohrbach and Tinne Tuytelaars},
  title     = {Memory Aware Synapses: Learning what (not) to forget},
  journal   = {CoRR},
  volume    = {abs/1711.09601},
  year      = {2017},
}

@inproceedings{Nguyen17,
  title={Variational Continual Learning},
  author={Cuong V. Nguyen and Yingzhen Li and Thang D. Bui and Richard E. Turner},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018},
}

@InProceedings{Zenke17,       
  title = 	 {Continual Learning Through Synaptic Intelligence},
  author = 	 {{Zenke}, Friedeman and {Poole}, Ben and {Ganguli}, Surya },
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2017},
}

@article{Li17,
  title={Learning without forgetting},
  author={Li, Zhizhong and Hoiem, Derek},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI0},
  year={2017},
}

@misc{li2019continual,
  title={Continual Learning Using Bayesian Neural Networks},
  author={HongLin Li and Payam Barnaghi and Shirin Enshaeifar and Frieder Ganz},
  year={2019},
  eprint={1910.04112},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

@misc{rosenfeld2018incremental,
  title={Incremental Learning through Deep Adaptation},
  author={Amir Rosenfeld and John K. Tsotsos},
  year={2018},
  url={https://openreview.net/forum?id=ryj0790hb},
}

@misc{farajtabar2019orthogonal,
  title={Orthogonal Gradient Descent for Continual Learning},
  author={Mehrdad Farajtabar and Navid Azizan and Alex Mott and Ang Li},
  year={2019},
  eprint={1910.07104},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

@inproceedings{Aljundi2019Gradient,
  title = {Gradient based sample selection for online continual learning},
  author = {Aljundi, Rahaf and Lin, Min and Goujaud, Baptiste and Bengio, Yoshua},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year = {2019},
}

@incollection{Aljundi2019Online,
title = {Online Continual Learning with Maximal Interfered Retrieval},
author = {Aljundi, Rahaf and Caccia, Lucas and Belilovsky, Eugene and Caccia, Massimo and Lin, Min and Charlin, Laurent and Tuytelaars, Tinne },
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {11849--11860},
year = {2019},
publisher = {Curran Associates, Inc.},
}

@article{Ven2018GenerativeRW,
  title={Generative replay with feedback connections as a general strategy for continual learning},
  author={Michiel van der Ven and Andreas S. Tolias},
  journal={ArXiv},
  year={2018},
  volume={abs/1809.10635}
}

@inproceedings{Javed2019Meta,
  title = {Meta-Learning Representations for Continual Learning},
  author = {Javed, Khurram and White, Martha},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year = {2019},
}

@misc{luo2019learning,
  title={Learning from the Past: Continual Meta-Learning via Bayesian Graph Modeling},
  author={Yadan Luo and Zi Huang and Zheng Zhang and Ziwei Wang and Mahsa Baktashmotlagh and Yang Yang},
  year={2019},
  eprint={1911.04695},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

@InProceedings{pmlr-v97-finn19a,
  title = 	 {Online Meta-Learning},
  author = 	 {Finn, Chelsea and Rajeswaran, Aravind and Kakade, Sham and Levine, Sergey},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2019},
}

@inproceedings{NIPS2019_9112,
  title = {Reconciling meta-learning and continual learning with online mixtures of tasks},
  author = {Jerfel, Ghassen and Grant, Erin and Griffiths, Tom and Heller, Katherine A},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year = {2019},
}

@inproceedings{nagabandi2018deep,
  title={Deep Online Learning Via Meta-Learning: Continual Adaptation for Model-Based {RL}},
  author={Anusha Nagabandi and Chelsea Finn and Sergey Levine},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2019},
}

@misc{rao2019continual,
  title={Continual Unsupervised Representation Learning},
  author={Dushyant Rao and Francesco Visin and Andrei A. Rusu and Yee Whye Teh and Razvan Pascanu and Raia Hadsell},
  year={2019},
  eprint={1910.14481},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

@inproceedings{lesort2018generative,
  TITLE = {{Generative Models from the perspective of Continual Learning}},
  AUTHOR = {Lesort, Timoth{\'e}e and Caselles-Dupr{\'e}, Hugo and Garcia-Ortiz, Michael and Goudou, Jean-Fran{\c c}ois and Filliat, David},
  BOOKTITLE = {{International Joint Conference on Neural Networks (IJCNN)}},
  YEAR = {2019},
}

@article{Ramapuram17,
  title={Lifelong Generative Modeling},
  author={Ramapuram, Jason and Gregorova, Magda and Kalousis, Alexandros},
  journal={arXiv preprint arXiv:1705.09847},
  year={2017}
}

@inproceedings{Alet2018ModularM,
  title={Modular meta-learning},
  author={Ferran Alet and Tom{\'a}s Lozano-P{\'e}rez and Leslie Pack Kaelbling},
  booktitle={CoRL},
  year={2018}
}

@inproceedings{toneva2018an,
  title={An Empirical Study of Example Forgetting during Deep Neural Network Learning},
  author={Mariya Toneva and Alessandro Sordoni and Remi Tachet des Combes and Adam Trischler and Yoshua Bengio and Geoffrey J. Gordon},
  booktitle={International Conference on Learning Representations},
  year={2019},
}

@misc{anonymous2020continual,
  title={Continual learning with hypernetworks},
  author={Johannes von Oswald and Christian Henning and João Sacramento and Benjamin F. Grewe},
  year={2019},
  eprint={1906.00695},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}

@article{He2019TaskAC,
  title={Task Agnostic Continual Learning via Meta Learning},
  author={Xu He and Jakub Sygnowski and Alexandre Galashov and Andrei A. Rusu and Yee Whye Teh and Razvan Pascanu},
  journal={ArXiv},
  year={2019},
  volume={abs/1906.05201}
}

@article{Harrison2019ContinuousMW,
  title={Continuous Meta-Learning without Tasks},
  author={James Harrison and Apoorva Sharma and Chelsea Finn and Marco Pavone},
  journal={ArXiv},
  year={2019},
  volume={abs/1912.08866}
}

@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017},
}

@article{raghu2019rapid,
  title={Rapid learning or feature reuse? towards understanding the effectiveness of maml},
  author={Raghu, Aniruddh and Raghu, Maithra and Bengio, Samy and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1909.09157},
  year={2019}
}

@article{thrun1995lifelong,
  title={Lifelong robot learning},
  author={Thrun, Sebastian and Mitchell, Tom M},
  journal={Robotics and autonomous systems},
  volume={15},
  number={1-2},
  pages={25--46},
  year={1995},
}

@article{hassabis2017neuroscience,
  title={Neuroscience-inspired artificial intelligence},
  author={Hassabis, Demis and Kumaran, Dharshan and Summerfield, Christopher and Botvinick, Matthew},
  journal={Neuron},
  volume={95},
  number={2},
  pages={245--258},
  year={2017},
}

@article{parisi2019continual,
  title={Continual lifelong learning with neural networks: A review},
  author={Parisi, German I and Kemker, Ronald and Part, Jose L and Kanan, Christopher and Wermter, Stefan},
  journal={Neural Networks},
  year={2019},
}

@techreport{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  institution={Citeseer}
}

@book{schunk2012learning,
  title={Learning theories an educational perspective sixth edition},
  author={Schunk, Dale H},
  year={2012},
  publisher={Pearson}
}

@incollection{mccloskey1989catastrophic,
  title={Catastrophic interference in connectionist networks: The sequential learning problem},
  author={McCloskey, Michael and Cohen, Neal J},
  booktitle={Psychology of learning and motivation},
  volume={24},
  pages={109--165},
  year={1989},
  publisher={Elsevier}
}

@article{soltoggio2015short,
  title={Short-term plasticity as cause--effect hypothesis testing in distal reward learning},
  author={Soltoggio, Andrea},
  journal={Biological cybernetics},
  volume={109},
  number={1},
  pages={75--94},
  year={2015},
}

@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
}

@article{rusu2016progressive,
  title={Progressive neural networks},
  author={Rusu, Andrei A and Rabinowitz, Neil C and Desjardins, Guillaume and Soyer, Hubert and Kirkpatrick, James and Kavukcuoglu, Koray and Pascanu, Razvan and Hadsell, Raia},
  journal={arXiv preprint arXiv:1606.04671},
  year={2016}
}

@InProceedings{lomonaco2017core50,
  title = {CORe50: a New Dataset and Benchmark for Continuous Object Recognition},
  author = {Vincenzo Lomonaco and Davide Maltoni},
  booktitle = {Annual Conference on Robot Learning},
  year = {2017},
}


@article{lesort2019,
  title={Core50: a new dataset and benchmark for continuous object recognition},
  author={Lesort, Timothée and Lomonaco, Vincenzo and Stoian, Andrei and Maltoni, Davide and Filliat, David and Díaz-Rodríguez, Natalia},
  journal={arXiv preprint arXiv:1907.00182},
  year={2019}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  year={2009},
}
@article{vuorio2018meta,
  title={Meta continual learning},
  author={Vuorio, Risto and Cho, Dong-Yeon and Kim, Daejoong and Kim, Jiwon},
  journal={arXiv preprint arXiv:1806.06928},
  year={2018}
}

@article{hannan1957FTL,
  author = {Hannan, J.},
  title={Approximation to bayes risk in repeated play}, journal={Contributions to the Theory of Games},
  year={1957}
}

@inproceedings{vinyals2016matching,
  title={Matching networks for one shot learning},
  author={Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Wierstra, Daan and others},
  booktitle={Advances in neural information processing systems},
  pages={3630--3638},
  year={2016}
}
@inproceedings{snell2017prototypical,
  title={Prototypical networks for few-shot learning},
  author={Snell, Jake and Swersky, Kevin and Zemel, Richard},
  booktitle={Advances in neural information processing systems},
  pages={4077--4087},
  year={2017}
}
\textbf{@inproceedings{sung2018learning,
  title={Learning to compare: Relation network for few-shot learning},
  author={Sung, Flood and Yang, Yongxin and Zhang, Li and Xiang, Tao and Torr, Philip HS and Hospedales, Timothy M},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1199--1208},
  year={2018}
}}

@article{ren2018meta,
  title={Meta-learning for semi-supervised few-shot classification},
  author={Ren, Mengye and Triantafillou, Eleni and Ravi, Sachin and Snell, Jake and Swersky, Kevin and Tenenbaum, Joshua B and Larochelle, Hugo and Zemel, Richard S},
  journal={arXiv preprint arXiv:1803.00676},
  year={2018}
}

@article{caccia2019online,
  title={Online Learned Continual Compression with Stacked Quantization Module},
  author={Lucas Caccia and Eugene Belilovsky and Massimo Caccia and Joelle Pineau},
  journal={ArXiv},
  year={2019},
  volume={abs/1911.08019}
}

@article{Lesort2019RegularizationSF,
  title={Regularization Shortcomings for Continual Learning},
  author={Timoth{\'e}e Lesort and Andrei Stoian and David Filliat},
  journal={ArXiv},
  year={2019},
  volume={abs/1912.03049}
}
@article{Padakandla2019ReinforcementLI,
  title={Reinforcement Learning in Non-Stationary Environments},
  author={Sindhu Padakandla and J. PrabuchandranK. and Shalabh Bhatnagar},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.03970}
}
@article{dziugaite2017computing,
  title={Computing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training data},
  author={Dziugaite, Gintare Karolina and Roy, Daniel M},
  journal={arXiv preprint arXiv:1703.11008},
  year={2017}
}
@article{gama2014survey,
  title={A survey on concept drift adaptation},
  author={Gama, Jo{\~a}o and {\v{Z}}liobait{\.e}, Indr{\.e} and Bifet, Albert and Pechenizkiy, Mykola and Bouchachia, Abdelhamid},
  journal={ACM computing surveys (CSUR)},
  volume={46},
  number={4},
  pages={1--37},
  year={2014},
  publisher={ACM New York, NY, USA}
}

@article{lomonaco2019fine,
  title={Fine-Grained Continual Learning},
  author={Lomonaco, Vincenzo and Maltoni, Davide and Pellegrini, Lorenzo},
  journal={arXiv preprint arXiv:1907.03799},
  year={2019}
}

@article{lomonaco2019continual,
  title={Continual reinforcement learning in 3d non-stationary environments},
  author={Lomonaco, Vincenzo and Desai, Karan and Culurciello, Eugenio and Maltoni, Davide},
  journal={arXiv preprint arXiv:1905.10112},
  year={2019}
}

@article{hidasi2015session,
  title={Session-based recommendations with recurrent neural networks},
  author={Hidasi, Bal{\'a}zs and Karatzoglou, Alexandros and Baltrunas, Linas and Tikk, Domonkos},
  journal={arXiv preprint arXiv:1511.06939},
  year={2015}
}

@article{beaulieu2020learning,
  title={Learning to Continually Learn},
  author={Beaulieu, Shawn and Frati, Lapo and Miconi, Thomas and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff and Cheney, Nick},
  journal={arXiv preprint arXiv:2002.09571},
  year={2020}
}

@article{riemer2018learning,
  title={Learning to learn without forgetting by maximizing transfer and minimizing interference},
  author={Riemer, Matthew and Cases, Ignacio and Ajemian, Robert and Liu, Miao and Rish, Irina and Tu, Yuhai and Tesauro, Gerald},
  journal={arXiv preprint arXiv:1810.11910},
  year={2018}
}

@book{kaelbling1993learning,
  title={Learning in embedded systems},
  author={Kaelbling, Leslie Pack},
  year={1993}
}

@article{kaelbling1991foundations,
  title={Foundations of learning in autonomous agents},
  author={Kaelbling, Leslie Pack},
  journal={Robotics and Autonomous Systems},
  volume={8},
  number={1-2},
  pages={131--144},
  year={1991},
  publisher={Elsevier}
}

@article{kaelbling1987architecture,
  title={An architecture for intelligent reactive systems},
  author={Kaelbling, Leslie Pack and others},
  journal={Reasoning about actions and plans},
  pages={395--410},
  publisher={Morgan Kaufmann San Matteo, CA},
  year={1987}
}

@inproceedings{kaelbling1992adaptable,
  title={An adaptable mobile robot},
  author={Kaelbling, Leslie},
  year={1992}
}

@article{kaelbling1996reinforcement,
  title={Reinforcement learning: A survey},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W},
  journal={Journal of artificial intelligence research},
  volume={4},
  pages={237--285},
  year={1996}
}
@phdthesis{schmidhuber1987evolutionary,
  title={Evolutionary principles in self-referential learning, or on learning how to learn: the meta-meta-... hook},
  author={Schmidhuber, J{\"u}rgen},
  year={1987},
  school={Technische Universit{\"a}t M{\"u}nchen}
}
@article{ravi2016optimization,
  title={Optimization as a model for few-shot learning},
  author={Ravi, Sachin and Larochelle, Hugo},
  journal={ICLR},
  year={2016}
}
@inproceedings{oreshkin2018tadam,
  title={Tadam: Task dependent adaptive metric for improved few-shot learning},
  author={Oreshkin, Boris and L{\'o}pez, Pau Rodr{\'\i}guez and Lacoste, Alexandre},
  booktitle={Advances in Neural Information Processing Systems},
  pages={721--731},
  year={2018}
}
@article{spigler2019meta,
  title={Meta-learnt priors slow down catastrophic forgetting in neural networks},
  author={Spigler, Giacomo},
  journal={arXiv preprint arXiv:1909.04170},
  year={2019}
}
@article{berry1985bandit,
  title={Bandit problems: sequential allocation of experiments (Monographs on statistics and applied probability)},
  author={Berry, Donald A and Fristedt, Bert},
  publisher={Springer},
  year={1985}
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2020}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}
@techreport{zhu2005semi,
  title={Semi-supervised learning literature survey},
  author={Zhu, Xiaojin Jerry},
  year={2005},
  institution={University of Wisconsin-Madison Department of Computer Sciences}
}

@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}
@article{Sun2019UnsupervisedDA,
  title={Unsupervised Domain Adaptation through Self-Supervision},
  author={Yan-yan Sun and Eric Tzeng and Trevor Darrell and Alexei A. Efros},
  journal={ArXiv},
  year={2019},
  volume={abs/1909.11825}
}

@article{Larsson2017ColorizationAA,
  title={Colorization as a Proxy Task for Visual Understanding},
  author={Gustav Larsson and Michael Maire and Gregory Shakhnarovich},
  journal={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017},
  pages={840-849}
}
@inproceedings{Hendrycks2019UsingSL,
  title={Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty},
  author={Dan Hendrycks and Mantas Mazeika and Saurav Kadavath and Dawn Song},
  booktitle={NeurIPS},
  year={2019}
}
@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{Gidaris2018UnsupervisedRL,
  title={Unsupervised Representation Learning by Predicting Image Rotations},
  author={Spyros Gidaris and Praveer Singh and Nikos Komodakis},
  journal={ArXiv},
  year={2018},
  volume={abs/1803.07728}
}

@article{Zhai2019S4LSS,
  title={S4L: Self-Supervised Semi-Supervised Learning},
  author={Xiaohua Zhai and Avital Oliver and Alexander Kolesnikov and Lucas Beyer},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.03670}
}
@incollection{OML,
    crossref={javed2019om}
}
@inproceedings{zhang2017split,
  title={Split-brain autoencoders: Unsupervised learning by cross-channel prediction},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1058--1067},
  year={2017}
}
@inproceedings{
chaudhry2018efficient,
title={Efficient Lifelong Learning with A-{GEM}},
author={Arslan Chaudhry and Marc’Aurelio Ranzato and Marcus Rohrbach and Mohamed Elhoseiny},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=Hkf2_sC5FX},
}

@inproceedings{mallya2018packnet,
  title={Packnet: Adding multiple tasks to a single network by iterative pruning},
  author={Mallya, Arun and Lazebnik, Svetlana},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7765--7773},
  year={2018}
}

@InProceedings{pmlr-v70-finn17a,
  title = 	 {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
  author = 	 {Chelsea Finn and Pieter Abbeel and Sergey Levine},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1126--1135},
  year = 	 {2017},
  editor = 	 {Doina Precup and Yee Whye Teh},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {International Convention Centre, Sydney, Australia},
  month = 	 {06--11 Aug},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/finn17a/finn17a.pdf},
  url = 	 {http://proceedings.mlr.press/v70/finn17a.html},
  abstract = 	 {We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.}
}
@article{gupta2020unreasonable,
  title={The unreasonable effectiveness of Batch-Norm statistics in addressing catastrophic forgetting across medical institutions},
  author={Gupta, Sharut and Singh, Praveer and Chang, Ken and Aggarwal, Mehak and Arun, Nishanth and Qu, Liangqiong and Hoebel, Katharina and Patel, Jay and Gidwani, Mishka and Vaswani, Ashwin and others},
  journal={arXiv preprint arXiv:2011.08096},
  year={2020}
}
@inproceedings{carmon2019unlabeled,
  title={Unlabeled data improves adversarial robustness},
  author={Carmon, Yair and Raghunathan, Aditi and Schmidt, Ludwig and Duchi, John C and Liang, Percy S},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11190--11201},
  year={2019}
}

@article{FRENCH1999128,
title = "Catastrophic forgetting in connectionist networks",
journal = "Trends in Cognitive Sciences",
volume = "3",
number = "4",
pages = "128 - 135",
year = "1999",
issn = "1364-6613",
doi = "https://doi.org/10.1016/S1364-6613(99)01294-2",
url = "http://www.sciencedirect.com/science/article/pii/S1364661399012942",
author = "Robert M. French",
keywords = "Catastrophic forgetting, Connectionist networks, Connectionism, Memory, Learning, Interference",
abstract = "All natural cognitive systems, and, in particular, our own, gradually forget previously learned information. Plausible models of human cognition should therefore exhibit similar patterns of gradual forgetting of old information as new information is acquired. Only rarely does new learning in natural cognitive systems completely disrupt or erase previously learned information; that is, natural cognitive systems do not, in general, forget ‘catastrophically’. Unfortunately, though, catastrophic forgetting does occur under certain circumstances in distributed connectionist networks. The very features that give these networks their remarkable abilities to generalize, to function in the presence of degraded input, and so on, are found to be the root cause of catastrophic forgetting. The challenge in this field is to discover how to keep the advantages of distributed connectionist networks while avoiding the problem of catastrophic forgetting. In this article the causes, consequences and numerous solutions to the problem of catastrophic forgetting in neural networks are examined. The review will consider how the brain might have overcome this problem and will also explore the consequences of this solution for distributed connectionist networks."
}

@inproceedings{distillation2015,
title	= {Distilling the Knowledge in a Neural Network},
author	= {Geoffrey Hinton and Oriol Vinyals and Jeffrey Dean},
year	= {2015},
URL	= {http://arxiv.org/abs/1503.02531},
booktitle	= {NIPS Deep Learning and Representation Learning Workshop}
}

@inproceedings{DBLP:journals/corr/KingmaW13,
  author    = {Diederik P. Kingma and
               Max Welling},
  title     = {Auto-Encoding Variational Bayes},
  booktitle = {2nd International Conference on Learning Representations, {ICLR} 2014,
               Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings},
  year      = {2014},
  url       = {http://arxiv.org/abs/1312.6114},
  timestamp = {Thu, 04 Apr 2019 13:20:07 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/KingmaW13},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{multi-task-ssl-ood-detection,
    crossref={Albuquerque2020ImprovingOG}
}
@article{Albuquerque2020ImprovingOG,
  title={Improving out-of-distribution generalization via multi-task self-supervised pretraining},
  author={Isabela Albuquerque and Nikhil Naik and Junnan Li and Nitish Shirish Keskar and Richard Socher},
  journal={ArXiv},
  year={2020},
  volume={abs/2003.13525}
}

@inproceedings{Wu2017TowardsUG,
  title={Towards Understanding Generalization of Deep Learning : Perspective of Loss Landscapes},
  author={Lei Wu},
  year={2017}
}


@inproceedings{Li2018VisualizingTL,
  title={Visualizing the Loss Landscape of Neural Nets},
  author={Hao Li and Zheng Xu and Gavin Taylor and Tom Goldstein},
  booktitle={NeurIPS},
  year={2018}
}

@article{Smith2018ABP,
  title={A Bayesian Perspective on Generalization and Stochastic Gradient Descent},
  author={Samuel L. Smith and Quoc V. Le},
  journal={ArXiv},
  year={2018},
  volume={abs/1710.06451}
}

@article{Zhang2017UnderstandingDL,
  title={Understanding deep learning requires rethinking generalization},
  author={Chiyuan Zhang and Samy Bengio and Moritz Hardt and Benjamin Recht and Oriol Vinyals},
  journal={ArXiv},
  year={2017},
  volume={abs/1611.03530}
}

@inproceedings{Arpit2017ACL,
  title={A Closer Look at Memorization in Deep Networks},
  author={Devansh Arpit and Stanislaw Jastrzebski and Nicolas Ballas and David Krueger and Emmanuel Bengio and Maxinder S. Kanwal and Tegan Maharaj and Asja Fischer and Aaron C. Courville and Yoshua Bengio and Simon Lacoste-Julien},
  booktitle={ICML},
  year={2017}
}

@article{Advani2017HighdimensionalDO,
  title={High-dimensional dynamics of generalization error in neural networks},
  author={Madhu S. Advani and Andrew M. Saxe},
  journal={ArXiv},
  year={2017},
  volume={abs/1710.03667}
}

@inproceedings{Dauphin2014IdentifyingAA,
  title={Identifying and attacking the saddle point problem in high-dimensional non-convex optimization},
  author={Yann Dauphin and Razvan Pascanu and Çaglar G{\"u}lçehre and Kyunghyun Cho and Surya Ganguli and Yoshua Bengio},
  booktitle={NIPS},
  year={2014}
}

@article{Soudry2016NoBL,
  title={No bad local minima: Data independent training error guarantees for multilayer neural networks},
  author={Daniel Soudry and Yair Carmon},
  journal={ArXiv},
  year={2016},
  volume={abs/1605.08361}
}

@article{Safran2016OnTQ,
  title={On the Quality of the Initial Basin in Overspecified Neural Networks},
  author={Itay Safran and Ohad Shamir},
  journal={ArXiv},
  year={2016},
  volume={abs/1511.04210}
}

@article{Lin2016WhyDD,
  title={Why Does Deep and Cheap Learning Work So Well?},
  author={Henry W. Lin and Max Tegmark},
  journal={Journal of Statistical Physics},
  year={2016},
  volume={168},
  pages={1223-1247}
}

@article{Swirszcz2016LocalMI,
  title={Local minima in training of neural networks},
  author={Grzegorz Swirszcz and Wojciech Marian Czarnecki and Razvan Pascanu},
  journal={arXiv: Machine Learning},
  year={2016}
}

@article{Draxler2018EssentiallyNB,
  title={Essentially No Barriers in Neural Network Energy Landscape},
  author={Felix Draxler and Kambis Veschgini and Manfred Salmhofer and Fred A. Hamprecht},
  journal={ArXiv},
  year={2018},
  volume={abs/1803.00885}
}

@inproceedings{Garipov2018LossSM,
  title={Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs},
  author={Timur Garipov and Pavel Izmailov and Dmitrii Podoprikhin and Dmitry P. Vetrov and Andrew Gordon Wilson},
  booktitle={NeurIPS},
  year={2018}
}

@article{Nguyen2019OnCS,
  title={On Connected Sublevel Sets in Deep Learning},
  author={Quynh Nguyen},
  journal={ArXiv},
  year={2019},
  volume={abs/1901.07417}
}

@article{Baldi1989NeuralNA,
  title={Neural networks and principal component analysis: Learning from examples without local minima},
  author={Pierre Baldi and Kurt Hornik},
  journal={Neural Networks},
  year={1989},
  volume={2},
  pages={53-58}
}
@inproceedings{zhou2004learning,
  title={Learning with local and global consistency},
  author={Zhou, Dengyong and Bousquet, Olivier and Lal, Thomas N and Weston, Jason and Sch{\"o}lkopf, Bernhard},
  booktitle={Advances in neural information processing systems},
  pages={321--328},
  year={2004}
}
@article{chapelle2009semi,
  title={Semi-supervised learning (chapelle, o. et al., eds.; 2006)[book reviews]},
  author={Chapelle, Olivier and Scholkopf, Bernhard and Zien, Alexander},
  journal={IEEE Transactions on Neural Networks},
  volume={20},
  number={3},
  pages={542--542},
  year={2009},
  publisher={IEEE}
}
% -----------

@article{wu2018memory,    
  title={Memory replay gans: Learning to generate new categories without forgetting},
  author={Wu, Chenshen and Herranz, Luis and Liu, Xialei and van de Weijer, Joost and Raducanu, Bogdan and others},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  pages={5962--5972},
  year={2018}
}
@inproceedings{kim2019learning,
  title={Learning not to learn: Training deep neural networks with biased data},
  author={Kim, Byungju and Kim, Hyunwoo and Kim, Kyungsu and Kim, Sungjin and Kim, Junmo},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9012--9020},
  year={2019}
}

@article{rosenbaum2019routing,   
  title={Routing networks and the challenges of modular and compositional computation},
  author={Rosenbaum, Clemens and Cases, Ignacio and Riemer, Matthew and Klinger, Tim},
  journal={arXiv preprint arXiv:1904.12774},
  year={2019}
}
@inproceedings{hu2017learning,
  title={Learning to reason: End-to-end module networks for visual question answering},
  author={Hu, Ronghang and Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Saenko, Kate},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={804--813},
  year={2017}
}
@inproceedings{andreas2016neural,
  title={Neural module networks},
  author={Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={39--48},
  year={2016}
}
@article{corona2020modularity,         
  title={Modularity Improves Out-of-Domain Instruction Following},
  author={Corona, Rodolfo and Fried, Daniel and Devin, Coline and Klein, Dan and Darrell, Trevor},
  journal={arXiv preprint arXiv:2010.12764},
  year={2020}
}
@article{amer2019review,
  title={A review of modularization techniques in artificial neural networks},
  author={Amer, Mohammed and Maul, Tom{\'a}s},
  journal={Artificial Intelligence Review},
  volume={52},
  number={1},
  pages={527--561},
  year={2019},
  publisher={Springer}
}
@article{deleu2018effects,
  title={The effects of negative adaptation in model-agnostic meta-learning},
  author={Deleu, Tristan and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1812.02159},
  year={2018}
}
@article{pezeshki2020gradient,
  title={Gradient Starvation: A Learning Proclivity in Neural Networks},
  author={Pezeshki, Mohammad and Kaba, S{\'e}kou-Oumar and Bengio, Yoshua and Courville, Aaron and Precup, Doina and Lajoie, Guillaume},
  journal={arXiv preprint arXiv:2011.09468},
  year={2020}
}
@article{antoniou2018train,
  title={How to train your maml},
  author={Antoniou, Antreas and Edwards, Harrison and Storkey, Amos},
  journal={arXiv preprint arXiv:1810.09502},
  year={2018}
}
@article{kobyzev2020normalizing,
  title={Normalizing flows: An introduction and review of current methods},
  author={Kobyzev, Ivan and Prince, Simon and Brubaker, Marcus},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2020},
  publisher={IEEE}
}
@inproceedings{behrmann2019invertible,
  title={Invertible residual networks},
  author={Behrmann, Jens and Grathwohl, Will and Chen, Ricky TQ and Duvenaud, David and Jacobsen, J{\"o}rn-Henrik},
  booktitle={International Conference on Machine Learning},
  pages={573--582},
  year={2019},
  organization={PMLR}
}
@article{wang2020further,
  title={Further Analysis of Outlier Detection with Deep Generative Models},
  author={Wang, Ziyu and Dai, Bin and Wipf, David and Zhu, Jun},
  journal={arXiv preprint arXiv:2010.13064},
  year={2020}
}
@article{hendrycks2018deep,
  title={Deep anomaly detection with outlier exposure},
  author={Hendrycks, Dan and Mazeika, Mantas and Dietterich, Thomas},
  journal={arXiv preprint arXiv:1812.04606},
  year={2018}
}
@article{nalisnick2018deep,
  title={Do deep generative models know what they don't know?},
  author={Nalisnick, Eric and Matsukawa, Akihiro and Teh, Yee Whye and Gorur, Dilan and Lakshminarayanan, Balaji},
  journal={arXiv preprint arXiv:1810.09136},
  year={2018}
}
@inproceedings{ioffe2015batch, 
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={PMLR}
}
@article{netzer2011reading,
  title={Reading digits in natural images with unsupervised feature learning},
  author={Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
  year={2011}
}
@InProceedings{cimpoi14describing,
  Author    = {M. Cimpoi and S. Maji and I. Kokkinos and S. Mohamed and and A. Vedaldi},
  Title     = {Describing Textures in the Wild},
  Booktitle = {Proceedings of the {IEEE} Conf. on Computer Vision and Pattern Recognition ({CVPR})},
  Year      = {2014}}
@article{gulrajani2020search,
  title={In search of lost domain generalization},
  author={Gulrajani, Ishaan and Lopez-Paz, David},
  journal={arXiv preprint arXiv:2007.01434},
  year={2020}
}
@inproceedings{rosenstein2005transfer,
  title={To transfer or not to transfer},
  author={Rosenstein, Michael T and Marx, Zvika and Kaelbling, Leslie Pack and Dietterich, Thomas G},
  booktitle={NIPS 2005 workshop on transfer learning},
  volume={898},
  pages={1--4},
  year={2005}
}
@inproceedings{finn2019online,
  title={Online meta-learning},
  author={Finn, Chelsea and Rajeswaran, Aravind and Kakade, Sham and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1920--1930},
  year={2019},
  organization={PMLR}
}
@article{lee2020neural,
  title={A neural dirichlet process mixture model for task-free continual learning},
  author={Lee, Soochan and Ha, Junsoo and Zhang, Dongsu and Kim, Gunhee},
  journal={arXiv preprint arXiv:2001.00689},
  year={2020}
}
@article{he2019task,
  title={Task agnostic continual learning via meta learning},
  author={He, Xu and Sygnowski, Jakub and Galashov, Alexandre and Rusu, Andrei A and Teh, Yee Whye and Pascanu, Razvan},
  journal={arXiv preprint arXiv:1906.05201},
  year={2019}
}
@article{yang2020multi,
  title={Multi-task reinforcement learning with soft modularization},
  author={Yang, Ruihan and Xu, Huazhe and Wu, Yi and Wang, Xiaolong},
  journal={arXiv preprint arXiv:2003.13661},
  year={2020}
}
@article{nichol2018first,
  title={On first-order meta-learning algorithms},
  author={Nichol, Alex and Achiam, Joshua and Schulman, John},
  journal={arXiv preprint arXiv:1803.02999},
  year={2018}
}
@article{hadsell2020embracing,
  title={Embracing Change: Continual Learning in Deep Neural Networks},
  author={Hadsell, Raia and Rao, Dushyant and Rusu, Andrei A and Pascanu, Razvan},
  journal={Trends in Cognitive Sciences},
  year={2020},
  publisher={Elsevier}
}
@article{hocquet2020ova,
  title={Ova-inn: Continual learning with invertible neural networks},
  author={Hocquet, Guillaume and Bichler, Olivier and Querlioz, Damien},
  journal={arXiv preprint arXiv:2006.13772},
  year={2020}
}
@article{andreas2016learning,
  title={Learning to compose neural networks for question answering},
  author={Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Klein, Dan},
  journal={arXiv preprint arXiv:1601.01705},
  year={2016}
}
@article{veniat2020efficient,
  title={Efficient Continual Learning with Modular Networks and Task-Driven Priors},
  author={Veniat, Tom and Denoyer, Ludovic and Ranzato, Marc'Aurelio},
  journal={arXiv preprint arXiv:2012.12631},
  year={2020}
}
@article{mendez2020lifelong,     
  title={Lifelong Learning of Compositional Structures},
  author={Mendez, Jorge A and Eaton, Eric},
  journal={arXiv preprint arXiv:2007.07732},
  year={2020}
}
@article{meyerson2017beyond, 
  title={Beyond shared hierarchies: Deep multitask learning through soft layer ordering},
  author={Meyerson, Elliot and Miikkulainen, Risto},
  journal={arXiv preprint arXiv:1711.00108},
  year={2017}
}
@article{dinh2014nice,
  title={Nice: Non-linear independent components estimation},
  author={Dinh, Laurent and Krueger, David and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1410.8516},
  year={2014}
}
@article{kirsch2018modular,    
  title={Modular networks: Learning to decompose neural computation},
  author={Kirsch, Louis and Kunze, Julius and Barber, David},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  pages={2408--2418},
  year={2018}
}
@inproceedings{aljundi2017expert,
  title={Expert gate: Lifelong learning with a network of experts},
  author={Aljundi, Rahaf and Chakravarty, Punarjay and Tuytelaars, Tinne},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3366--3375},
  year={2017}
}
@inproceedings{jerfel2019reconciling,
  title={Reconciling meta-learning and continual learning with online mixtures of tasks},
  author={Jerfel, Ghassen and Grant, Erin and Griffiths, Tom and Heller, Katherine A},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9122--9133},
  year={2019}
}
@article{collins2013cognitive,
  title={Cognitive control over learning: Creating, clustering, and generalizing task-set structure.},
  author={Collins, Anne GE and Frank, Michael J},
  journal={Psychological review},
  volume={120},
  number={1},
  pages={190},
  year={2013},
  publisher={American Psychological Association}
}
@article{barnes1959fate,
  title={" Fate" of first-list associations in transfer theory.},
  author={Barnes, Jean M and Underwood, Benton J},
  journal={Journal of experimental psychology},
  volume={58},
  number={2},
  pages={97},
  year={1959},
  publisher={American Psychological Association}
}
@article{ellefsen2015neural,
  title={Neural modularity helps organisms evolve to learn new skills without forgetting old skills},
  author={Ellefsen, Kai Olav and Mouret, Jean-Baptiste and Clune, Jeff},
  journal={PLoS Comput Biol},
  volume={11},
  number={4},
  pages={e1004128},
  year={2015},
  publisher={Public Library of Science}
}
@article{clune2013evolutionary,
  title={The evolutionary origins of modularity},
  author={Clune, Jeff and Mouret, Jean-Baptiste and Lipson, Hod},
  journal={Proceedings of the Royal Society b: Biological sciences},
  volume={280},
  number={1755},
  pages={20122863},
  year={2013},
  publisher={The Royal Society}
}
@article{sunmulti,
  title={Multi-digit mnist for few-shot learning, 2019},
  author={Sun, Shao-Hua},
  journal={URL https://github. com/shaohua0116/MultiDigitMNIST}
}
@inproceedings{sun2020test,
  title={Test-time training with self-supervision for generalization under distribution shifts},
  author={Sun, Yu and Wang, Xiaolong and Liu, Zhuang and Miller, John and Efros, Alexei and Hardt, Moritz},
  booktitle={International Conference on Machine Learning},
  pages={9229--9248},
  year={2020},
  organization={PMLR}
}
@inproceedings{purushwalkam2019task,
  title={Task-driven modular networks for zero-shot compositional learning},
  author={Purushwalkam, Senthil and Nickel, Maximilian and Gupta, Abhinav and Ranzato, Marc'Aurelio},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3593--3602},
  year={2019}
}
@article{goyal2019recurrent,
  title={Recurrent independent mechanisms},
  author={Goyal, Anirudh and Lamb, Alex and Hoffmann, Jordan and Sodhani, Shagun and Levine, Sergey and Bengio, Yoshua and Sch{\"o}lkopf, Bernhard},
  journal={arXiv preprint arXiv:1909.10893},
  year={2019}
}
@article{grant2018recasting,
  title={Recasting gradient-based meta-learning as hierarchical bayes},
  author={Grant, Erin and Finn, Chelsea and Levine, Sergey and Darrell, Trevor and Griffiths, Thomas},
  journal={arXiv preprint arXiv:1801.08930},
  year={2018}
}
@inproceedings{parascandolo2018learning,
  title={Learning independent causal mechanisms},
  author={Parascandolo, Giambattista and Kilbertus, Niki and Rojas-Carulla, Mateo and Sch{\"o}lkopf, Bernhard},
  booktitle={International Conference on Machine Learning},
  pages={4036--4044},
  year={2018},
  organization={PMLR}
}
@article{harrison2019continuous,
  title={Continuous meta-learning without tasks},
  author={Harrison, James and Sharma, Apoorva and Finn, Chelsea and Pavone, Marco},
  journal={arXiv preprint arXiv:1912.08866},
  year={2019}
}
@article{hannan1957approximation,
  title={Approximation to Bayes risk in repeated play},
  author={Hannan, James},
  journal={Contributions to the Theory of Games},
  volume={3},
  pages={97--139},
  year={1957}
}
@book{pearl2009causality,
  title={Causality},
  author={Pearl, Judea},
  year={2009},
  publisher={Cambridge university press}
}
@inproceedings{scholkopf2012causal,
  title={On causal and anticausal learning},
  author={Sch{\"o}lkopf, B and Janzing, D and Peters, J and Sgouritsa, E and Zhang, K and Mooij, J},
  booktitle={29th International Conference on Machine Learning (ICML 2012)},
  pages={1255--1262},
  year={2012},
  organization={International Machine Learning Society}
}
@book{peters2017elements,
  title={Elements of causal inference: foundations and learning algorithms},
  author={Peters, Jonas and Janzing, Dominik and Sch{\"o}lkopf, Bernhard},
  year={2017},
  publisher={The MIT Press}
}
@book{baldwin2000design,
  title={Design rules: The power of modularity},
  author={Baldwin, Carliss Young and Clark, Kim B and Clark, Kim B and others},
  volume={1},
  year={2000},
  publisher={MIT press}
}
@inproceedings{chang2018automatically,
  title={Automatically Composing Representation Transformations as a Means for Generalization},
  author={Chang, Michael and Gupta, Abhishek and Levine, Sergey and Griffiths, Thomas L},
  booktitle={International Conference on Learning Representations},
  year={2018}
}
@inproceedings{bahdanau2018systematic,
  title={Systematic Generalization: What Is Required and Can It Be Learned?},
  author={Bahdanau, Dzmitry and Murty, Shikhar and Noukhovitch, Michael and Nguyen, Thien Huu and de Vries, Harm and Courville, Aaron},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{
csordas2020neural,
title={Are Neural Nets Modular? Inspecting Functional Modularity Through Differentiable Weight Masks},
author={R{\'o}bert Csord{\'a}s and Sjoerd van Steenkiste and J{\"u}rgen Schmidhuber},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=7uVcpu-gMD}
}
@article{wang2020generalizing,
  title={Generalizing from a few examples: A survey on few-shot learning},
  author={Wang, Yaqing and Yao, Quanming and Kwok, James T and Ni, Lionel M},
  journal={ACM Computing Surveys (CSUR)},
  volume={53},
  number={3},
  pages={1--34},
  year={2020},
  publisher={ACM New York, NY, USA}
}
@article{reddy1977speech,
  title={Speech understanding systems: A summary of results of the five-year research effort},
  author={Reddy, D Raj and others},
  journal={Department of Computer Science. Camegie-Mell University, Pittsburgh, PA},
  volume={17},
  pages={138},
  year={1977}
}
@article{sporns2016modular,
  title={Modular brain networks},
  author={Sporns, Olaf and Betzel, Richard F},
  journal={Annual review of psychology},
  volume={67},
  pages={613--640},
  year={2016},
  publisher={Annual Reviews}
}
@article{sternberg2011modular,
  title={Modular processes in mind and brain},
  author={Sternberg, Saul},
  journal={Cognitive neuropsychology},
  volume={28},
  number={3-4},
  pages={156--208},
  year={2011},
  publisher={Taylor \& Francis}
}