@article{geiger2019jamming,
  title={Jamming transition as a paradigm to understand the loss landscape of deep neural networks},
  author={Geiger, Mario and Spigler, Stefano and d'Ascoli, St{\'e}phane and Sagun, Levent and Baity-Jesi, Marco and Biroli, Giulio and Wyart, Matthieu},
  journal={Physical Review E},
  volume={100},
  number={1},
  pages={012115},
  year={2019},
  publisher={APS}
}

@article{kunin2020neural,
  title={Neural Mechanics: Symmetry and Broken Conservation Laws in Deep Learning Dynamics},
  author={Kunin, Daniel and Sagastuy-Brena, Javier and Ganguli, Surya and Yamins, Daniel LK and Tanaka, Hidenori},
  journal={arXiv preprint arXiv:2012.04728},
  year={2020}
}

@article{lee2019wide,
  title={Wide neural networks of any depth evolve as linear models under gradient descent},
  author={Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel S and Bahri, Yasaman and Novak, Roman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
  journal={arXiv preprint arXiv:1902.06720},
  year={2019}
}

@article{fukumizu2019semi,
  title={Semi-flat minima and saddle points by embedding neural networks to overparameterization},
  author={Fukumizu, Kenji and Yamaguchi, Shoichiro and Mototake, Yoh-ichi and Tanaka, Mirai},
  journal={arXiv preprint arXiv:1906.04868},
  year={2019}
}

@article{draxler2018essentially,
  title={Essentially no barriers in neural network energy landscape},
  author={Draxler, Felix and Veschgini, Kambis and Salmhofer, Manfred and Hamprecht, Fred A},
  journal={arXiv preprint arXiv:1803.00885},
  year={2018}
}

@article{garipov2018loss,
  title={Loss surfaces, mode connectivity, and fast ensembling of dnns},
  author={Garipov, Timur and Izmailov, Pavel and Podoprikhin, Dmitrii and Vetrov, Dmitry P and Wilson, Andrew G},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  pages={8789--8798},
  year={2018}
}

@inproceedings{frankle2020linear,
  title={Linear mode connectivity and the lottery ticket hypothesis},
  author={Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel and Carbin, Michael},
  booktitle={International Conference on Machine Learning},
  pages={3259--3269},
  year={2020},
  organization={PMLR}
}

@inproceedings{fort2019large,
  title={Large scale structure of neural network loss landscapes},
  author={Fort, Stanislav and Jastrzebski, Stanislaw},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6709--6717},
  year={2019}
}

@article{fort2020deep,
  title={Deep learning versus kernel learning: an empirical study of loss landscape geometry and the time evolution of the Neural Tangent Kernel},
  author={Fort, Stanislav and Dziugaite, Gintare Karolina and Paul, Mansheej and Kharaghani, Sepideh and Roy, Daniel M and Ganguli, Surya},
  journal={arXiv preprint arXiv:2010.15110},
  year={2020}
}

@inproceedings{choromanska2015loss,
  title={The loss surfaces of multilayer networks},
  author={Choromanska, Anna and Henaff, Mikael and Mathieu, Michael and Arous, G{\'e}rard Ben and LeCun, Yann},
  booktitle={Artificial intelligence and statistics},
  pages={192--204},
  year={2015}
}

@inproceedings{du2017gradient,
  title={Gradient descent can take exponential time to escape saddle points},
  author={Du, Simon S and Jin, Chi and Lee, Jason D and Jordan, Michael I and Singh, Aarti and Poczos, Barnabas},
  booktitle={Advances in neural information processing systems},
  pages={1067--1077},
  year={2017}
}

@inproceedings{du2019gradient,
  title={Gradient descent finds global minima of deep neural networks},
  author={Du, Simon and Lee, Jason and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
  booktitle={International Conference on Machine Learning},
  pages={1675--1685},
  year={2019},
  organization={PMLR}
}

@book{sagan2013symmetric,
  title={The symmetric group: representations, combinatorial algorithms, and symmetric functions},
  author={Sagan, Bruce E},
  volume={203},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@book{kung2009combinatorics,
  title={Combinatorics: the Rota way},
  author={Kung, Joseph PS and Rota, Gian-Carlo and Yan, Catherine H},
  year={2009},
  publisher={Cambridge University Press}
}

@article{hornik1989multilayer,
  title={Multilayer feedforward networks are universal approximators.},
  author={Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert and others},
  journal={Neural networks},
  volume={2},
  number={5},
  pages={359--366},
  year={1989}
}

@article{hornik1991approximation,
  title={Approximation capabilities of multilayer feedforward networks},
  author={Hornik, Kurt},
  journal={Neural networks},
  volume={4},
  number={2},
  pages={251--257},
  year={1991},
  publisher={Elsevier}
}

@inproceedings{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  booktitle={Advances in neural information processing systems},
  pages={8571--8580},
  year={2018}
}

@article{chizat2018global,
  title={On the global convergence of gradient descent for over-parameterized models using optimal transport},
  author={Chizat, Lenaic and Bach, Francis},
  journal={Advances in neural information processing systems},
  volume={31},
  pages={3036--3046},
  year={2018}
}

@inproceedings{dauphin2014identifying,
  title={Identifying and attacking the saddle point problem in high-dimensional non-convex optimization},
  author={Dauphin, Yann N and Pascanu, Razvan and Gulcehre, Caglar and Cho, Kyunghyun and Ganguli, Surya and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2933--2941},
  year={2014}
}

@inproceedings{kawaguchi2016deep,
  title={Deep learning without poor local minima},
  author={Kawaguchi, Kenji},
  booktitle={Advances in neural information processing systems},
  pages={586--594},
  year={2016}
}

@book{milne2000calculus,
  title={The calculus of finite differences},
  author={Milne-Thomson, Louis Melville},
  year={2000},
  publisher={American Mathematical Soc.}
}

@article{wei2008dynamics,
  title={Dynamics of learning near singularities in layered networks},
  author={Wei, Haikun and Zhang, Jun and Cousseau, Florent and Ozeki, Tomoko and Amari, Shun-ichi},
  journal={Neural computation},
  volume={20},
  number={3},
  pages={813--843},
  year={2008},
  publisher={MIT Press}
}

@book{bishop2006pattern,
  title={Pattern recognition and machine learning},
  author={Bishop, Christopher M},
  year={2006},
  publisher={springer}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
  volume={1},
  number={2},
  year={2016},
  publisher={MIT press Cambridge}
}

@article{gonen2011multiple,
  title={Multiple kernel learning algorithms},
  author={G{\"o}nen, Mehmet and Alpayd{\i}n, Ethem},
  journal={The Journal of Machine Learning Research},
  volume={12},
  pages={2211--2268},
  year={2011},
  publisher={JMLR. org}
}

@article{arora2019fine,
  title={Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks},
  author={Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
  journal={arXiv preprint arXiv:1901.08584},
  year={2019}
}

@article{du2018gradient,
  title={Gradient descent provably optimizes over-parameterized neural networks},
  author={Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
  journal={arXiv preprint arXiv:1810.02054},
  year={2018}
}

@article{frankle2018lottery,
  title={The lottery ticket hypothesis: Finding sparse, trainable neural networks},
  author={Frankle, Jonathan and Carbin, Michael},
  journal={arXiv preprint arXiv:1803.03635},
  year={2018}
}

@inproceedings{arora2019implicit,
  title={Implicit regularization in deep matrix factorization},
  author={Arora, Sanjeev and Cohen, Nadav and Hu, Wei and Luo, Yuping},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7413--7424},
  year={2019}
}

@article{fukumizu2000local,
  title={Local minima and plateaus in hierarchical structures of multilayer perceptrons},
  author={Fukumizu, Kenji and Amari, Shun-ichi},
  journal={Neural networks},
  volume={13},
  number={3},
  pages={317--327},
  year={2000},
  publisher={Elsevier}
}

@article{lee2020finite,
  title={Finite versus infinite neural networks: an empirical study},
  author={Lee, Jaehoon and Schoenholz, Samuel S and Pennington, Jeffrey and Adlam, Ben and Xiao, Lechao and Novak, Roman and Sohl-Dickstein, Jascha},
  journal={arXiv preprint arXiv:2007.15801},
  year={2020}
}

@article{nguyen2019connected,
  title={On connected sublevel sets in deep learning},
  author={Nguyen, Quynh},
  journal={arXiv preprint arXiv:1901.07417},
  year={2019}
}

@article{freeman2016topology,
  title={Topology and geometry of half-rectified network optimization},
  author={Freeman, C Daniel and Bruna, Joan},
  journal={arXiv preprint arXiv:1611.01540},
  year={2016}
}

@inproceedings{kuditipudi2019explaining,
  title={Explaining landscape connectivity of low-cost solutions for multilayer nets},
  author={Kuditipudi, Rohith and Wang, Xiang and Lee, Holden and Zhang, Yi and Li, Zhiyuan and Hu, Wei and Ge, Rong and Arora, Sanjeev},
  booktitle={Advances in Neural Information Processing Systems},
  pages={14601--14610},
  year={2019}
}

@article{jin2017escape,
  title={How to escape saddle points efficiently},
  author={Jin, Chi and Ge, Rong and Netrapalli, Praneeth and Kakade, Sham M and Jordan, Michael I},
  journal={arXiv preprint arXiv:1703.00887},
  year={2017}
}

@article{cooper2020critical,
  title={The critical locus of overparameterized neural networks},
  author={Cooper, Y},
  journal={arXiv preprint arXiv:2005.04210},
  year={2020}
}

@article{brea2019weight,
  title={Weight-space symmetry in deep networks gives rise to permutation saddles, connected by equal-loss valleys across the loss landscape},
  author={Brea, Johanni and Simsek, Berfin and Illing, Bernd and Gerstner, Wulfram},
  journal={arXiv preprint arXiv:1907.02911},
  year={2019}
}

@article{sagun2014explorations,
  title={Explorations on high dimensional landscapes},
  author={Sagun, Levent and Guney, V Ugur and Arous, Gerard Ben and LeCun, Yann},
  journal={arXiv preprint arXiv:1412.6615},
  year={2014}
}

@article{sagun2017empirical,
  title={Empirical analysis of the hessian of over-parametrized neural networks},
  author={Sagun, Levent and Evci, Utku and Guney, V Ugur and Dauphin, Yann and Bottou, Leon},
  journal={arXiv preprint arXiv:1706.04454},
  year={2017}
}

@article{lengyel2020genni,
  title={GENNI: Visualising the Geometry of Equivalences for Neural Network Identifiability},
  author={Lengyel, Daniel and Petangoda, Janith and Falk, Isak and Highnam, Kate and Lazarou, Michalis and Kolbeinsson, Arinbj{\"o}rn and Deisenroth, Marc Peter and Jennings, Nicholas R},
  journal={arXiv preprint arXiv:2011.07407},
  year={2020}
}

@article{Kingma14,
 keywords = {Computer Science - Learning},
 author = {{Kingma}, D.~P. and {Ba}, J.},
 adsnote = {Provided by the SAO/NASA Astrophysics Data System},
 archiveprefix = "arXiv",
 eprint = {1412.6980},
 primaryclass = "cs.LG",
 year = 2014,
 url = {https://arxiv.org/abs/1412.6980},
 month = dec,
 journal = {ArXiv e-prints},
 title = "{Adam: A Method for Stochastic Optimization}",
 adsurl = {http://adsabs.harvard.edu/abs/2014arXiv1412.6980K}
}
@misc{Johnson,
 author = {Steven G. Johnson},
 title = {The NLopt nonlinear-optimization package},
 url = {http://github.com/stevengj/nlopt}
}
@inproceedings{Glorot10,
 title = {Understanding the difficulty of training deep feedforward neural networks},
 author = {Xavier Glorot and Yoshua Bengio},
 booktitle = {Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
 pages = {249--256},
 year = {2010},
 editor = {Yee Whye Teh and Mike Titterington},
 volume = {9},
 series = {Proceedings of Machine Learning Research},
 address = {Chia Laguna Resort, Sardinia, Italy},
 month = {13--15 May},
 publisher = {JMLR Workshop and Conference Proceedings},
 url = {http://proceedings.mlr.press/v9/glorot10a.html},
}

@article{bray2007statistics,
  title={Statistics of critical points of Gaussian fields on large-dimensional spaces},
  author={Bray, Alan J and Dean, David S},
  journal={Physical review letters},
  volume={98},
  number={15},
  pages={150201},
  year={2007},
  publisher={APS}
}

@article{lee2019first,
  title={First-order methods almost always avoid strict saddle points},
  author={Lee, Jason D and Panageas, Ioannis and Piliouras, Georgios and Simchowitz, Max and Jordan, Michael I and Recht, Benjamin},
  journal={Mathematical programming},
  volume={176},
  number={1},
  pages={311--337},
  year={2019},
  publisher={Springer}
}

@article{gluch2021noether,
  title={Noether: The More Things Change, the More Stay the Same},
  author={G{\l}uch, Grzegorz and Urbanke, R{\"u}diger},
  journal={arXiv preprint arXiv:2104.05508},
  year={2021}
}

@article{auffinger2013random,
  title={Random matrices and complexity of spin glasses},
  author={Auffinger, Antonio and Arous, G{\'e}rard Ben and {\v{C}}ern{\`y}, Ji{\v{r}}{\'\i}},
  journal={Communications on Pure and Applied Mathematics},
  volume={66},
  number={2},
  pages={165--201},
  year={2013},
  publisher={Wiley Online Library}
}