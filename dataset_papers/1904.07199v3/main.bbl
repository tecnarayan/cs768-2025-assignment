\begin{thebibliography}{46}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Achille and Soatto(2016)]{informationdropout}
Alessandro Achille and Stefano Soatto.
\newblock Information dropout: Learning optimal representations through noisy
  computation.
\newblock \emph{arXiv preprint arXiv:1611.01353}, 2016.

\bibitem[Alemi et~al.(2016)Alemi, Fischer, Dillon, and Murphy]{alemi2016deep}
Alexander Alemi, Ian Fischer, Joshua Dillon, and Kevin Murphy.
\newblock Deep variational information bottleneck.
\newblock \emph{arXiv preprint arXiv:1612.00410}, 2016.

\bibitem[Alemi et~al.(2018)Alemi, Poole, Fischer, Dillon, Saurous, and
  Murphy]{alemi2018fixing}
Alexander Alemi, Ben Poole, Ian Fischer, Joshua Dillon, Rif~A Saurous, and
  Kevin Murphy.
\newblock Fixing a broken elbo.
\newblock In \emph{International Conference on Machine Learning}, pages
  159--168, 2018.

\bibitem[Barber and Agakov(2003)]{barber2003algorithm}
David Barber and Felix~V Agakov.
\newblock The im algorithm: a variational approach to information maximization.
\newblock In \emph{Advances in neural information processing systems}, page
  None, 2003.

\bibitem[Belghazi et~al.(2018)Belghazi, Rajeswar, Baratin, Hjelm, and
  Courville]{belghazi2018mine}
Ishmael Belghazi, Sai Rajeswar, Aristide Baratin, R~Devon Hjelm, and Aaron
  Courville.
\newblock Mine: mutual information neural estimation.
\newblock \emph{arXiv preprint arXiv:1801.04062}, 2018.

\bibitem[Bowman et~al.(2015)Bowman, Vilnis, Vinyals, Dai, J{\'{o}}zefowicz, and
  Bengio]{bowman2016}
Samuel~R. Bowman, Luke Vilnis, Oriol Vinyals, Andrew~M. Dai, Rafal
  J{\'{o}}zefowicz, and Samy Bengio.
\newblock Generating sentences from a continuous space.
\newblock \emph{CoRR}, abs/1511.06349, 2015.
\newblock URL \url{http://arxiv.org/abs/1511.06349}.

\bibitem[Braithwaite and Kleijn(2018)]{braithwaite2018bounded}
DT~Braithwaite and W~Bastiaan Kleijn.
\newblock Bounded information rate variational autoencoders.
\newblock \emph{arXiv preprint arXiv:1807.07306}, 2018.

\bibitem[Burda et~al.(2015)Burda, Grosse, and
  Salakhutdinov]{burda2015importance}
Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov.
\newblock Importance weighted autoencoders.
\newblock \emph{arXiv preprint arXiv:1509.00519}, 2015.

\bibitem[Burgess et~al.(2018)Burgess, Higgins, Pal, Matthey, Watters,
  Desjardins, and Lerchner]{burgess2018understanding}
Christopher~P Burgess, Irina Higgins, Arka Pal, Loic Matthey, Nick Watters,
  Guillaume Desjardins, and Alexander Lerchner.
\newblock Understanding disentangling in beta-vae.
\newblock \emph{arXiv preprint arXiv:1804.03599}, 2018.

\bibitem[Chen et~al.(2018)Chen, Li, Grosse, and Duvenaud]{chen2018isolating}
Tian~Qi Chen, Xuechen Li, Roger Grosse, and David Duvenaud.
\newblock Isolating sources of disentanglement in variational autoencoders.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Chen et~al.(2016)Chen, Kingma, Salimans, Duan, Dhariwal, Schulman,
  Sutskever, and Abbeel]{chen2016variational}
Xi~Chen, Diederik~P Kingma, Tim Salimans, Yan Duan, Prafulla Dhariwal, John
  Schulman, Ilya Sutskever, and Pieter Abbeel.
\newblock Variational lossy autoencoder.
\newblock \emph{arXiv preprint arXiv:1611.02731}, 2016.

\bibitem[Cover and Thomas(2006)]{cover}
Thomas~M Cover and Joy~A Thomas.
\newblock \emph{Elements of information theory}.
\newblock Wiley-Interscience, 2006.

\bibitem[Dillon et~al.(2017)Dillon, Langmore, Tran, Brevdo, Vasudevan, Moore,
  Patton, Alemi, Hoffman, and Saurous]{dillon2017tensorflow}
Joshua~V Dillon, Ian Langmore, Dustin Tran, Eugene Brevdo, Srinivas Vasudevan,
  Dave Moore, Brian Patton, Alex Alemi, Matt Hoffman, and Rif~A Saurous.
\newblock Tensorflow distributions.
\newblock \emph{arXiv preprint arXiv:1711.10604}, 2017.

\bibitem[Gao et~al.(2019)Gao, Brekelmans, Ver~Steeg, and Galstyan]{gao2018auto}
Shuyang Gao, Rob Brekelmans, Greg Ver~Steeg, and Aram Galstyan.
\newblock Auto-encoding total correlation explanation.
\newblock \emph{AISTATS}, 2019.

\bibitem[Germain et~al.(2015)Germain, Gregor, Murray, and
  Larochelle]{germain2015made}
Mathieu Germain, Karol Gregor, Iain Murray, and Hugo Larochelle.
\newblock Made: Masked autoencoder for distribution estimation.
\newblock In \emph{International Conference on Machine Learning}, pages
  881--889, 2015.

\bibitem[Gretton et~al.(2012)Gretton, Borgwardt, Rasch, Sch{\"o}lkopf, and
  Smola]{gretton2012kernel}
Arthur Gretton, Karsten~M Borgwardt, Malte~J Rasch, Bernhard Sch{\"o}lkopf, and
  Alexander Smola.
\newblock A kernel two-sample test.
\newblock \emph{Journal of Machine Learning Research}, 13\penalty0
  (Mar):\penalty0 723--773, 2012.

\bibitem[Griffith and Koch(2014)]{griffith}
Virgil Griffith and Christof Koch.
\newblock Quantifying synergistic mutual information.
\newblock In \emph{Guided Self-Organization: Inception}, pages 159--190.
  Springer, 2014.

\bibitem[Higgins et~al.(2017)Higgins, Matthey, Pal, Christopher~Burgess, and
  Lerchner]{higgins2017}
Irina Higgins, Loic Matthey, Arka Pal, Matthew Botvinick Shakir~Mohamed
  Christopher~Burgess, Xavier~Glorot, and Alexander Lerchner.
\newblock "beta-vae: Learning basic visual concepts with a constrained
  variational framework.".
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2017.

\bibitem[Hoffman and Johnson(2016)]{elbosurgery}
Matthew~D Hoffman and Matthew~J Johnson.
\newblock Elbo surgery: yet another way to carve up the variational evidence
  lower bound.
\newblock In \emph{Workshop in Advances in Approximate Bayesian Inference,
  NIPS}, 2016.

\bibitem[Kim and Mnih(2018)]{kim2018disentangling}
Hyunjik Kim and Andriy Mnih.
\newblock Disentangling by factorising.
\newblock \emph{arXiv preprint arXiv:1802.05983}, 2018.

\bibitem[Kingma and Welling(2013)]{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Kingma et~al.(2016)Kingma, Salimans, Jozefowicz, Chen, Sutskever, and
  Welling]{kingma2016improved}
Diederik~P Kingma, Tim Salimans, Rafal Jozefowicz, Xi~Chen, Ilya Sutskever, and
  Max Welling.
\newblock Improved variational inference with inverse autoregressive flow.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  4743--4751, 2016.

\bibitem[Kolchinsky et~al.(2017)Kolchinsky, Tracey, and
  Wolpert]{kolchinsky2017nonlinear}
Artemy Kolchinsky, Brendan~D Tracey, and David~H Wolpert.
\newblock Nonlinear information bottleneck.
\newblock \emph{arXiv preprint arXiv:1705.02436}, 2017.

\bibitem[Lake et~al.(2015)Lake, Salakhutdinov, and Tenenbaum]{lake2015human}
Brenden~M Lake, Ruslan Salakhutdinov, and Joshua~B Tenenbaum.
\newblock Human-level concept learning through probabilistic program induction.
\newblock \emph{Science}, 350\penalty0 (6266):\penalty0 1332--1338, 2015.

\bibitem[Lastras-Montano(2018)]{infolowerbounds}
Luis~A. Lastras-Montano.
\newblock Information theoretic lower bounds on negative log likelihood.
\newblock 2018.
\newblock URL \url{https://openreview.net/forum?id=rkemqsC9Fm}.

\bibitem[Locatello et~al.(2019)Locatello, Bauer, Lucic, Raetsch, Gelly,
  Sch{\"o}lkopf, and Bachem]{locatello2018challenging}
Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly,
  Bernhard Sch{\"o}lkopf, and Olivier Bachem.
\newblock Challenging common assumptions in the unsupervised learning of
  disentangled representations.
\newblock In \emph{International Conference on Machine Learning}, pages
  4114--4124, 2019.

\bibitem[Mathieu et~al.(2019)Mathieu, Rainforth, Siddharth, and
  Teh]{mathieu2019disentangling}
Emile Mathieu, Tom Rainforth, N~Siddharth, and Yee~Whye Teh.
\newblock Disentangling disentanglement in variational autoencoders.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Matthey et~al.(2017)Matthey, Higgins, Hassabis, and
  Lerchner]{dsprites17}
Loic Matthey, Irina Higgins, Demis Hassabis, and Alexander Lerchner.
\newblock dsprites: Disentanglement testing sprites dataset.
\newblock https://github.com/deepmind/dsprites-dataset/, 2017.

\bibitem[McAllester and Statos(2018)]{mcallester2018formal}
David McAllester and Karl Statos.
\newblock Formal limitations on the measurement of mutual information.
\newblock \emph{arXiv preprint arXiv:1811.04251}, 2018.

\bibitem[Moyer et~al.(2018)Moyer, Gao, Brekelmans, Galstyan, and
  Ver~Steeg]{moyer2018invariant}
Daniel Moyer, Shuyang Gao, Rob Brekelmans, Aram Galstyan, and Greg Ver~Steeg.
\newblock Invariant representations without adversarial training.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  9084--9093, 2018.

\bibitem[Papamakarios et~al.(2017)Papamakarios, Murray, and
  Pavlakou]{papamakarios2017masked}
George Papamakarios, Iain Murray, and Theo Pavlakou.
\newblock Masked autoregressive flow for density estimation.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2338--2347, 2017.

\bibitem[Phuong et~al.(2018)Phuong, Welling, Kushman, Tomioka, and
  Nowozin]{phuong2018mutual}
Mary Phuong, Max Welling, Nate Kushman, Ryota Tomioka, and Sebastian Nowozin.
\newblock The mutual autoencoder: Controlling information in latent code
  representations.
\newblock 2018.
\newblock URL \url{https://openreview.net/forum?id=HkbmWqxCZ}.

\bibitem[Poole et~al.(2019)Poole, Ozair, Van Den~Oord, Alemi, and
  Tucker]{poole2019variational}
Ben Poole, Sherjil Ozair, Aaron Van Den~Oord, Alex Alemi, and George Tucker.
\newblock On variational bounds of mutual information.
\newblock In \emph{International Conference on Machine Learning}, pages
  5171--5180, 2019.

\bibitem[Rezende and Mohamed(2015)]{rezende2015variational}
Danilo Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock In \emph{International Conference on Machine Learning}, pages
  1530--1538, 2015.

\bibitem[Rezende and Viola(2018)]{rezende2018taming}
Danilo~Jimenez Rezende and Fabio Viola.
\newblock Taming vaes.
\newblock \emph{arXiv preprint arXiv:1810.00597}, 2018.

\bibitem[Rezende et~al.(2014)Rezende, Mohamed, and
  Wierstra]{rezende2014stochastic}
Danilo~Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock In \emph{International Conference on Machine Learning}, pages
  1278--1286, 2014.

\bibitem[Rosca et~al.(2018)Rosca, Lakshminarayanan, and
  Mohamed]{rosca2018distribution}
Mihaela Rosca, Balaji Lakshminarayanan, and Shakir Mohamed.
\newblock Distribution matching in variational inference.
\newblock \emph{arXiv preprint arXiv:1802.06847}, 2018.

\bibitem[Salakhutdinov and Murray(2008)]{salakhutdinov2008quantitative}
Ruslan Salakhutdinov and Iain Murray.
\newblock On the quantitative analysis of deep belief networks.
\newblock In \emph{Proceedings of the 25th international conference on Machine
  learning}, pages 872--879. ACM, 2008.

\bibitem[Tishby et~al.(2000)Tishby, Pereira, and Bialek]{tishby2000information}
Naftali Tishby, Fernando~C Pereira, and William Bialek.
\newblock The information bottleneck method.
\newblock \emph{arXiv preprint physics/0004057}, 2000.

\bibitem[Tomczak and Welling(2017)]{tomczak2017vae}
Jakub~M Tomczak and Max Welling.
\newblock Vae with a vampprior.
\newblock \emph{AIStats 2018}, 2017.
\newblock URL \url{arXiv preprint arXiv:1705.07120}.

\bibitem[Tschannen et~al.(2018)Tschannen, Bachem, and
  Lucic]{tschannen2018recent}
Michael Tschannen, Olivier Bachem, and Mario Lucic.
\newblock Recent advances in autoencoder-based representation learning.
\newblock \emph{arXiv preprint arXiv:1812.05069}, 2018.

\bibitem[van Steenkiste et~al.(2019)van Steenkiste, Locatello, Schmidhuber, and
  Bachem]{van2019disentangled}
Sjoerd van Steenkiste, Francesco Locatello, J{\"u}rgen Schmidhuber, and Olivier
  Bachem.
\newblock Are disentangled representations helpful for abstract visual
  reasoning?
\newblock \emph{arXiv preprint arXiv:1905.12506}, 2019.

\bibitem[Watanabe(1960)]{watanabe}
Satosi Watanabe.
\newblock Information theoretical analysis of multivariate correlation.
\newblock \emph{IBM Journal of research and development}, 4\penalty0
  (1):\penalty0 66--82, 1960.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{xiao2017}
Han Xiao, Kashif Rasul, and Roland Vollgraf.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms.
\newblock 2017.

\bibitem[Zhao et~al.(2017)Zhao, Song, and Ermon]{infovae}
Shengjia Zhao, Jiaming Song, and Stefano Ermon.
\newblock Infovae: Information maximizing variational autoencoders.
\newblock \emph{CoRR}, abs/1706.02262, 2017.
\newblock URL \url{http://arxiv.org/abs/1706.02262}.

\bibitem[Zhao et~al.(2018)Zhao, Song, and Ermon]{zhao2018lagrangian}
Shengjia Zhao, Jiaming Song, and Stefano Ermon.
\newblock The information autoencoding family: A lagrangian perspective on
  latent variable generative models.
\newblock \emph{CoRR}, abs/1806.06514, 2018.
\newblock URL \url{http://arxiv.org/abs/1806.06514}.

\end{thebibliography}
