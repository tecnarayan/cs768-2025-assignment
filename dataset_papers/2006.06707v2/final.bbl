\begin{thebibliography}{62}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Allen et~al.(2019)Allen, Shelhamer, Shin, and
  Tenenbaum]{allen2019infinite}
Allen, K.~R., Shelhamer, E., Shin, H., and Tenenbaum, J.~B.
\newblock Infinite mixture prototypes for few-shot learning.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning}, pp.\  232--241, 2019.

\bibitem[Andrychowicz et~al.(2016)Andrychowicz, Denil, Gomez, Hoffman, Pfau,
  Schaul, Shillingford, and de~Freitas]{andrychowicz2016learning}
Andrychowicz, M., Denil, M., Gomez, S., Hoffman, M.~W., Pfau, D., Schaul, T.,
  Shillingford, B., and de~Freitas, N.
\newblock Learning to learn by gradient descent by gradient descent.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Aravind~Rajeswaran(2019)]{rajeswaran2019meta}
Aravind~Rajeswaran, Chelsea~Finn, S. K. S.~L.
\newblock Meta-learning with implicit gradients.
\newblock \emph{arXiv preprint arXiv:1909.04630}, 2019.

\bibitem[Avron et~al.(2016)Avron, Sindhwani, Yang, and Mahoney]{avron2016quasi}
Avron, H., Sindhwani, V., Yang, J., and Mahoney, M.~W.
\newblock Quasi-monte carlo feature maps for shift-invariant kernels.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 4096--4133, 2016.

\bibitem[Bach et~al.(2004)Bach, Lanckriet, and Jordan]{bach2004multiple}
Bach, F.~R., Lanckriet, G.~R., and Jordan, M.~I.
\newblock Multiple kernel learning, conic duality, and the smo algorithm.
\newblock In \emph{Proceedings of the twenty-first international conference on
  Machine learning}, pp.\ ~6, 2004.

\bibitem[Bauer et~al.(2017)Bauer, Rojas-Carulla, {\'S}wi{\k{a}}tkowski,
  Sch{\"o}lkopf, and Turner]{bauer2017discriminative}
Bauer, M., Rojas-Carulla, M., {\'S}wi{\k{a}}tkowski, J.~B., Sch{\"o}lkopf, B.,
  and Turner, R.~E.
\newblock Discriminative k-shot learning using probabilistic models.
\newblock \emph{arXiv preprint arXiv:1706.00326}, 2017.

\bibitem[Bertinetto et~al.(2019)Bertinetto, Henriques, Torr, and
  Vedaldi]{bertinetto2018meta}
Bertinetto, L., Henriques, J.~F., Torr, P.~H., and Vedaldi, A.
\newblock Meta-learning with differentiable closed-form solvers.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Bishop(2006)]{bishop2006pattern}
Bishop, C.~M.
\newblock \emph{Pattern recognition and machine learning}.
\newblock springer, 2006.

\bibitem[Bullins et~al.(2018)Bullins, Zhang, and Zhang]{bullins2018not}
Bullins, B., Zhang, C., and Zhang, Y.
\newblock Not-so-random features.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Carratino et~al.(2018)Carratino, Rudi, and
  Rosasco]{carratino2018learning}
Carratino, L., Rudi, A., and Rosasco, L.
\newblock Learning with sgd and random features.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  10192--10203, 2018.

\bibitem[Chang et~al.(2017)Chang, Li, Yang, and Poczos]{chang2017data}
Chang, W.-C., Li, C.-L., Yang, Y., and Poczos, B.
\newblock Data-driven random fourier features using stein effect.
\newblock \emph{arXiv preprint arXiv:1705.08525}, 2017.

\bibitem[Chen et~al.(2017)Chen, Hoffman, Colmenarejo, Denil, Lillicrap,
  Botvinick, and De~Freitas]{chen2017learning}
Chen, Y., Hoffman, M.~W., Colmenarejo, S.~G., Denil, M., Lillicrap, T.~P.,
  Botvinick, M., and De~Freitas, N.
\newblock Learning to learn without gradient descent by gradient descent.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pp.\  748--756. JMLR. org, 2017.

\bibitem[Devos et~al.(2019)Devos, Chatel, and Grossglauser]{devosreproducing}
Devos, A., Chatel, S., and Grossglauser, M.
\newblock Reproducing meta-learning with differentiable closed-form solvers.
\newblock In \emph{ICLR Workshop}, 2019.

\bibitem[Duvenaud et~al.(2013)Duvenaud, Lloyd, Grosse, Tenenbaum, and
  Ghahramani]{duvenaud2013structure}
Duvenaud, D., Lloyd, J.~R., Grosse, R., Tenenbaum, J.~B., and Ghahramani, Z.
\newblock Structure discovery in nonparametric regression through compositional
  kernel search.
\newblock \emph{arXiv preprint arXiv:1302.4922}, 2013.

\bibitem[Finn \& Levine(2018)Finn and Levine]{finn2018}
Finn, C. and Levine, S.
\newblock Meta-learning and universality: Deep representations and gradient
  descent can approximate any learning algorithm.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{finn2017model}
Finn, C., Abbeel, P., and Levine, S.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1126--1135. JMLR. org, 2017.

\bibitem[Finn et~al.(2018)Finn, Xu, and Levine]{finn2018probabilistic}
Finn, C., Xu, K., and Levine, S.
\newblock Probabilistic model-agnostic meta-learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  9516--9527, 2018.

\bibitem[Garcia \& Bruna(2018)Garcia and Bruna]{garcia2018few}
Garcia, V. and Bruna, J.
\newblock Few-shot learning with graph neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[G{\"a}rtner et~al.(2002)G{\"a}rtner, Flach, Kowalczyk, and
  Smola]{gartner2002multi}
G{\"a}rtner, T., Flach, P.~A., Kowalczyk, A., and Smola, A.~J.
\newblock Multi-instance kernels.
\newblock In \emph{International Conference on Machine Learning}, 2002.

\bibitem[Gers \& Schmidhuber(2000)Gers and Schmidhuber]{gers2000recurrent}
Gers, F.~A. and Schmidhuber, J.
\newblock Recurrent nets that time and count.
\newblock In \emph{Proceedings of the IEEE-INNS-ENNS International Joint
  Conference on Neural Networks}, volume~3, pp.\  189--194. IEEE, 2000.

\bibitem[Gidaris \& Komodakis(2018)Gidaris and Komodakis]{gidaris2018dynamic}
Gidaris, S. and Komodakis, N.
\newblock Dynamic few-shot visual learning without forgetting.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition},
  pp.\  4367--4375, 2018.

\bibitem[G{\"o}nen \& Alpayd{\i}n(2011)G{\"o}nen and
  Alpayd{\i}n]{gonen2011multiple}
G{\"o}nen, M. and Alpayd{\i}n, E.
\newblock Multiple kernel learning algorithms.
\newblock \emph{Journal of machine learning research}, 12\penalty0
  (Jul):\penalty0 2211--2268, 2011.

\bibitem[Gordon et~al.(2019)Gordon, Bronskill, Bauer, Nowozin, and
  Turner]{gordon2018meta}
Gordon, J., Bronskill, J., Bauer, M., Nowozin, S., and Turner, R.~E.
\newblock Meta-learning probabilistic inference for prediction.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Graves \& Schmidhuber(2005)Graves and
  Schmidhuber]{graves2005framewise}
Graves, A. and Schmidhuber, J.
\newblock Framewise phoneme classification with bidirectional lstm and other
  neural network architectures.
\newblock \emph{Neural networks}, 18\penalty0 (5-6):\penalty0 602--610, 2005.

\bibitem[Hensman et~al.(2017)Hensman, Durrande, and
  Solin]{hensman2017variational}
Hensman, J., Durrande, N., and Solin, A.
\newblock Variational fourier features for gaussian processes.
\newblock \emph{The Journal of Machine Learning Research}, 18\penalty0
  (1):\penalty0 5537--5588, 2017.

\bibitem[Hochreiter \& Schmidhuber(1997)Hochreiter and
  Schmidhuber]{hochreiter1997long}
Hochreiter, S. and Schmidhuber, J.
\newblock Long short-term memory.
\newblock \emph{Neural computation}, 9\penalty0 (8):\penalty0 1735--1780, 1997.

\bibitem[Hofmann et~al.(2008)Hofmann, Sch{\"o}lkopf, and
  Smola]{hofmann2008kernel}
Hofmann, T., Sch{\"o}lkopf, B., and Smola, A.~J.
\newblock Kernel methods in machine learning.
\newblock \emph{The annals of statistics}, pp.\  1171--1220, 2008.

\bibitem[Kim et~al.(2019)Kim, Mnih, Schwarz, Garnelo, Eslami, Rosenbaum,
  Vinyals, and Teh]{kim2019attentive}
Kim, H., Mnih, A., Schwarz, J., Garnelo, M., Eslami, A., Rosenbaum, D.,
  Vinyals, O., and Teh, Y.~W.
\newblock Attentive neural processes.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kingma \& Welling(2013)Kingma and Welling]{kingma2013auto}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Koch(2015)]{koch2015siamese}
Koch, G.
\newblock Siamese neural networks for one-shot image recognition.
\newblock In \emph{ICML Workshop}, 2015.

\bibitem[Krizhevsky et~al.(2009)]{krizhevsky2009learning}
Krizhevsky, A. et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, Citeseer, 2009.

\bibitem[Lake et~al.(2015)Lake, Salakhutdinov, and Tenenbaum]{lake2015human}
Lake, B.~M., Salakhutdinov, R., and Tenenbaum, J.~B.
\newblock Human-level concept learning through probabilistic program induction.
\newblock \emph{Science}, 350\penalty0 (6266):\penalty0 1332--1338, 2015.

\bibitem[Li et~al.(2019)Li, Chang, Mroueh, Yang, and Poczos]{li2019implicit}
Li, C.-L., Chang, W.-C., Mroueh, Y., Yang, Y., and Poczos, B.
\newblock Implicit kernel learning.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence
  and Statistics}, pp.\  2007--2016, 2019.

\bibitem[Li et~al.(2017)Li, Zhou, Chen, and Li]{li2017meta}
Li, Z., Zhou, F., Chen, F., and Li, H.
\newblock Meta-sgd: Learning to learn quickly for few-shot learning.
\newblock \emph{arXiv preprint arXiv:1707.09835}, 2017.

\bibitem[Mishra et~al.(2018)Mishra, Rohaninejad, Chen, and
  Abbeel]{mishra2018simple}
Mishra, N., Rohaninejad, M., Chen, X., and Abbeel, P.
\newblock A simple neural attentive meta-learner.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Munkhdalai et~al.(2017)Munkhdalai, Yuan, Mehri, and
  Trischler]{munkhdalai2017rapid}
Munkhdalai, T., Yuan, X., Mehri, S., and Trischler, A.
\newblock Rapid adaptation with conditionally shifted neurons.
\newblock \emph{arXiv preprint arXiv:1712.09926}, 2017.

\bibitem[Oreshkin et~al.(2018)Oreshkin, L{\'o}pez, and
  Lacoste]{oreshkin2018tadam}
Oreshkin, B., L{\'o}pez, P.~R., and Lacoste, A.
\newblock Tadam: Task dependent adaptive metric for improved few-shot learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  721--731, 2018.

\bibitem[Qiao et~al.(2018)Qiao, Liu, Shen, and Yuille]{qiao2018few}
Qiao, S., Liu, C., Shen, W., and Yuille, A.~L.
\newblock Few-shot image recognition by predicting parameters from activations.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition},
  pp.\  7229--7238, 2018.

\bibitem[Rahimi \& Recht(2007)Rahimi and Recht]{rahimi2008random}
Rahimi, A. and Recht, B.
\newblock Random features for large-scale kernel machines.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1177--1184, 2007.

\bibitem[Ravi \& Larochelle(2017)Ravi and Larochelle]{ravi2017optimization}
Ravi, S. and Larochelle, H.
\newblock Optimization as a model for few-shot learning.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Rezende et~al.(2014)Rezende, Mohamed, and
  Wierstra]{rezende2014stochastic}
Rezende, D.~J., Mohamed, S., and Wierstra, D.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock \emph{arXiv preprint arXiv:1401.4082}, 2014.

\bibitem[Rudin(1962)]{rudin1962fourier}
Rudin, W.
\newblock \emph{Fourier analysis on groups}, volume 121967.
\newblock Wiley Online Library, 1962.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, et~al.]{russakovsky2015imagenet}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
  Karpathy, A., Khosla, A., Bernstein, M., et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{IJCV}, 115\penalty0 (3):\penalty0 211--252, 2015.

\bibitem[Rusu et~al.(2019)Rusu, Rao, Sygnowski, Vinyals, Pascanu, Osindero, and
  Hadsell]{rusu2018meta}
Rusu, A.~A., Rao, D., Sygnowski, J., Vinyals, O., Pascanu, R., Osindero, S.,
  and Hadsell, R.
\newblock Meta-learning with latent embedding optimization.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Satorras \& Estrach(2018)Satorras and Estrach]{satorras2018few}
Satorras, V.~G. and Estrach, J.~B.
\newblock Few-shot learning with graph neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[{Schmidhuber}(1992)]{Schmidhuber1992}
{Schmidhuber}, J.
\newblock Learning to control fast-weight memories: An alternative to dynamic
  recurrent networks.
\newblock \emph{Neural Computation}, 4\penalty0 (1):\penalty0 131--139, 1992.

\bibitem[Schuster \& Paliwal(1997)Schuster and
  Paliwal]{schuster1997bidirectional}
Schuster, M. and Paliwal, K.~K.
\newblock Bidirectional recurrent neural networks.
\newblock \emph{IEEE transactions on Signal Processing}, 45\penalty0
  (11):\penalty0 2673--2681, 1997.

\bibitem[Shervashidze et~al.(2011)Shervashidze, Schweitzer, Leeuwen, Mehlhorn,
  and Borgwardt]{shervashidze2011weisfeiler}
Shervashidze, N., Schweitzer, P., Leeuwen, E. J.~v., Mehlhorn, K., and
  Borgwardt, K.~M.
\newblock Weisfeiler-lehman graph kernels.
\newblock \emph{Journal of Machine Learning Research}, 12\penalty0
  (Sep):\penalty0 2539--2561, 2011.

\bibitem[Sinha \& Duchi(2016)Sinha and Duchi]{sinha2016learning}
Sinha, A. and Duchi, J.~C.
\newblock Learning kernels with random features.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1298--1306, 2016.

\bibitem[Snell et~al.(2017)Snell, Swersky, and Zemel]{snell2017prototypical}
Snell, J., Swersky, K., and Zemel, R.
\newblock Prototypical networks for few-shot learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  4077--4087, 2017.

\bibitem[Sohn et~al.(2015)Sohn, Lee, and Yan]{sohn2015learning}
Sohn, K., Lee, H., and Yan, X.
\newblock Learning structured output representation using deep conditional
  generative models.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  3483--3491, 2015.

\bibitem[Sung et~al.(2018)Sung, Yang, Zhang, Xiang, Torr, and
  Hospedales]{sung2018learning}
Sung, F., Yang, Y., Zhang, L., Xiang, T., Torr, P.~H., and Hospedales, T.~M.
\newblock Learning to compare: Relation network for few-shot learning.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition},
  pp.\  1199--1208, 2018.

\bibitem[Thrun \& Pratt(2012)Thrun and Pratt]{thrun2012learning}
Thrun, S. and Pratt, L.
\newblock \emph{Learning to learn}.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Titsias et~al.(2019)Titsias, Schwarz, Matthews, Pascanu, and
  Teh]{titsias2019functional}
Titsias, M.~K., Schwarz, J., Matthews, A. G. d.~G., Pascanu, R., and Teh, Y.~W.
\newblock Functional regularisation for continual learning using gaussian
  processes.
\newblock \emph{arXiv preprint arXiv:1901.11356}, 2019.

\bibitem[Vinyals et~al.(2016)Vinyals, Blundell, Lillicrap, Wierstra,
  et~al.]{vinyals2016matching}
Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et~al.
\newblock Matching networks for one shot learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3630--3638, 2016.

\bibitem[Wilson \& Adams(2013)Wilson and Adams]{wilson2013gaussian}
Wilson, A. and Adams, R.
\newblock Gaussian process kernels for pattern discovery and extrapolation.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1067--1075, 2013.

\bibitem[Yang et~al.(2015)Yang, Wilson, Smola, and Song]{yang2015carte}
Yang, Z., Wilson, A., Smola, A., and Song, L.
\newblock A la carte--learning fast kernels.
\newblock In \emph{Artificial Intelligence and Statistics}, pp.\  1098--1106,
  2015.

\bibitem[Yu et~al.(2016)Yu, Suresh, Choromanski, Holtmann-Rice, and
  Kumar]{yu2016orthogonal}
Yu, F. X.~X., Suresh, A.~T., Choromanski, K.~M., Holtmann-Rice, D.~N., and
  Kumar, S.
\newblock Orthogonal random features.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1975--1983, 2016.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and
  Komodakis]{zagoruyko2016wide}
Zagoruyko, S. and Komodakis, N.
\newblock Wide residual networks.
\newblock \emph{arXiv preprint arXiv:1605.07146}, 2016.

\bibitem[Zaheer et~al.(2017)Zaheer, Kottur, Ravanbakhsh, Poczos, Salakhutdinov,
  and Smola]{zaheer2017deep}
Zaheer, M., Kottur, S., Ravanbakhsh, S., Poczos, B., Salakhutdinov, R.~R., and
  Smola, A.~J.
\newblock Deep sets.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3391--3401, 2017.

\bibitem[Zintgraf et~al.(2019)Zintgraf, Shiarli, Kurin, Hofmann, and
  Whiteson]{zintgraf2019fast}
Zintgraf, L., Shiarli, K., Kurin, V., Hofmann, K., and Whiteson, S.
\newblock Fast context adaptation via meta-learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  7693--7702, 2019.

\end{thebibliography}
