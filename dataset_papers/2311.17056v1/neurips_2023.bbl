\begin{thebibliography}{10}

\bibitem{balakrishnan2013detecting}
G.~Balakrishnan, F.~Durand, and J.~Guttag.
\newblock Detecting pulse from head motions in video.
\newblock In {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 3430--3437, 2013.

\bibitem{bian2022learning}
Z.~Bian, A.~Jabri, A.~A. Efros, and A.~Owens.
\newblock Learning pixel trajectories with multiscale contrastive random walks.
\newblock {\em CVPR}, 2022.

\bibitem{brox2004high}
T.~Brox, A.~Bruhn, N.~Papenberg, and J.~Weickert.
\newblock High accuracy optical flow estimation based on a theory for warping.
\newblock In {\em European conference on computer vision}, pages 25--36. Springer, 2004.

\bibitem{chang2019argoverse}
M.-F. Chang, J.~Lambert, P.~Sangkloy, J.~Singh, S.~Bak, A.~Hartnett, D.~Wang, P.~Carr, S.~Lucey, D.~Ramanan, et~al.
\newblock Argoverse: 3d tracking and forecasting with rich maps.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 8748--8757, 2019.

\bibitem{chen2015modal}
J.~G. Chen, N.~Wadhwa, Y.-J. Cha, F.~Durand, W.~T. Freeman, and O.~Buyukozturk.
\newblock Modal identification of simple structures with high-speed video using motion magnification.
\newblock {\em Journal of Sound and Vibration}, 345:58--71, 2015.

\bibitem{ciftci2022deepfakes}
U.~A. Ciftci and I.~Demir.
\newblock How do deepfakes move? motion magnification for deepfake source detection.
\newblock {\em arXiv preprint arXiv:2212.14033}, 2022.

\bibitem{conotter2014physiologically}
V.~Conotter, E.~Bodnari, G.~Boato, and H.~Farid.
\newblock Physiologically-based detection of computer generated faces in video.
\newblock In {\em 2014 IEEE International Conference on Image Processing (ICIP)}, pages 248--252. IEEE, 2014.

\bibitem{Dave:2020:ECCV}
A.~Dave, T.~Khurana, P.~Tokmakov, C.~Schmid, and D.~Ramanan.
\newblock Tao: A large-scale benchmark for tracking any object.
\newblock In {\em European Conference on Computer Vision}, 2020.

\bibitem{doersch2022tap}
C.~Doersch, A.~Gupta, L.~Markeeva, A.~Recasens, L.~Smaira, Y.~Aytar, J.~Carreira, A.~Zisserman, and Y.~Yang.
\newblock Tap-vid: A benchmark for tracking any point in a video.
\newblock {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{dosovitskiy2015flownet}
A.~Dosovitskiy, P.~Fischer, E.~Ilg, P.~Hausser, C.~Hazirbas, V.~Golkov, P.~Van Der~Smagt, D.~Cremers, and T.~Brox.
\newblock Flownet: Learning optical flow with convolutional networks.
\newblock In {\em Proceedings of the IEEE international conference on computer vision}, pages 2758--2766, 2015.

\bibitem{elgharib2015video}
M.~Elgharib, M.~Hefeeda, F.~Durand, and W.~T. Freeman.
\newblock Video magnification in presence of large motions.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pages 4119--4127, 2015.

\bibitem{everingham2015pascal}
M.~Everingham, S.~A. Eslami, L.~Van~Gool, C.~K. Williams, J.~Winn, and A.~Zisserman.
\newblock The pascal visual object classes challenge: A retrospective.
\newblock {\em International journal of computer vision}, 111:98--136, 2015.

\bibitem{fan2019lasot}
H.~Fan, L.~Lin, F.~Yang, P.~Chu, G.~Deng, S.~Yu, H.~Bai, Y.~Xu, C.~Liao, and H.~Ling.
\newblock Lasot: A high-quality benchmark for large-scale single object tracking.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 5374--5383, 2019.

\bibitem{felzenszwalb2004efficient}
P.~Felzenszwalb and D.~Huttenlocher.
\newblock Efficient belief propagation for early vision.
\newblock In {\em Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.}, volume~1, pages I--I. IEEE, 2004.

\bibitem{feng2023motionmag}
B.~Y. Feng, H.~AlZayer, M.~Rubinstein, W.~T. Freeman, and J.-B. Huang.
\newblock Visualizing subtle motions with time-varying neural fields.
\newblock In {\em International Conference on Computer Vision (ICCV)}, 2023.

\bibitem{fischer2015flownet}
P.~Fischer, A.~Dosovitskiy, E.~Ilg, P.~H{\"a}usser, C.~Haz{\i}rba{\c{s}}, V.~Golkov, P.~Van~der Smagt, D.~Cremers, and T.~Brox.
\newblock Flownet: Learning optical flow with convolutional networks.
\newblock {\em arXiv preprint arXiv:1504.06852}, 2015.

\bibitem{flotho2022lagrangian}
P.~Flotho, C.~Heiss, G.~Steidl, and D.~J. Strauss.
\newblock Lagrangian motion magnification with double sparse optical flow decomposition.
\newblock {\em arXiv preprint arXiv:2204.07636}, 2022.

\bibitem{gandelsman2022test}
Y.~Gandelsman, Y.~Sun, X.~Chen, and A.~Efros.
\newblock Test-time training with masked autoencoders.
\newblock {\em Advances in Neural Information Processing Systems}, 35:29374--29385, 2022.

\bibitem{gao2022magformer}
S.~Gao, Y.~Feng, L.~Yang, X.~Liu, Z.~Zhu, D.~Doermann, and B.~Zhang.
\newblock Magformer: Hybrid video motion magnification transformer from eulerian and lagrangian perspectives.
\newblock 2022.

\bibitem{geng2022comparing}
D.~Geng, M.~Hamilton, and A.~Owens.
\newblock Comparing correspondences: Video prediction with correspondence-wise losses.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 3365--3376, 2022.

\bibitem{goyal2022ifor}
A.~Goyal, A.~Mousavian, C.~Paxton, Y.-W. Chao, B.~Okorn, J.~Deng, and D.~Fox.
\newblock Ifor: Iterative flow minimization for robotic object rearrangement.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 2022.

\bibitem{harley2022particle}
A.~W. Harley, Z.~Fang, and K.~Fragkiadaki.
\newblock Particle video revisited: Tracking through occlusions using point trajectories.
\newblock In {\em European Conference on Computer Vision}, 2022.

\bibitem{hornschunck1981hs}
B.~Horn and B.~Schunck.
\newblock Determining optical flow.
\newblock In {\em Artificial Intelligence}, pages 185--203, 1981.

\bibitem{hui2018liteflownet}
T.-W. Hui, X.~Tang, and C.~C. Loy.
\newblock Liteflownet: A lightweight convolutional neural network for optical flow estimation.
\newblock In {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 8981--8989, 2018.

\bibitem{ilg2017flownet}
E.~Ilg, N.~Mayer, T.~Saikia, M.~Keuper, A.~Dosovitskiy, and T.~Brox.
\newblock Flownet 2.0: Evolution of optical flow estimation with deep networks.
\newblock In {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 2462--2470, 2017.

\bibitem{jabri2020space}
A.~Jabri, A.~Owens, and A.~Efros.
\newblock Space-time correspondence as a contrastive random walk.
\newblock {\em Advances in neural information processing systems}, 33:19545--19560, 2020.

\bibitem{jonschkowski2020matters}
R.~Jonschkowski, A.~Stone, J.~T. Barron, A.~Gordon, K.~Konolige, and A.~Angelova.
\newblock What matters in unsupervised optical flow.
\newblock {\em arXiv preprint arXiv:2006.04902}, 2020.

\bibitem{kalluri2023flavr}
T.~Kalluri, D.~Pathak, M.~Chandraker, and D.~Tran.
\newblock Flavr: Flow-agnostic video representations for fast frame interpolation.
\newblock In {\em Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, pages 2071--2082, 2023.

\bibitem{kirillov2023segany}
A.~Kirillov, E.~Mintun, N.~Ravi, H.~Mao, C.~Rolland, L.~Gustafson, T.~Xiao, S.~Whitehead, A.~C. Berg, W.-Y. Lo, P.~Doll{\'a}r, and R.~Girshick.
\newblock Segment anything.
\newblock {\em arXiv:2304.02643}, 2023.

\bibitem{lin2014microsoft}
T.-Y. Lin, M.~Maire, S.~Belongie, J.~Hays, P.~Perona, D.~Ramanan, P.~Doll{\'a}r, and C.~L. Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13}, pages 740--755. Springer, 2014.

\bibitem{liu2009beyond}
C.~Liu et~al.
\newblock {\em Beyond pixels: exploring new representations and applications for motion analysis}.
\newblock PhD thesis, Massachusetts Institute of Technology, 2009.

\bibitem{liu2005motion}
C.~Liu, A.~Torralba, W.~T. Freeman, F.~Durand, and E.~H. Adelson.
\newblock Motion magnification.
\newblock {\em ACM transactions on graphics (TOG)}, 24(3):519--526, 2005.

\bibitem{liu2020learning}
L.~Liu, J.~Zhang, R.~He, Y.~Liu, Y.~Wang, Y.~Tai, D.~Luo, C.~Wang, J.~Li, and F.~Huang.
\newblock Learning by analogy: Reliable supervision from transformations for unsupervised optical flow estimation.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition(CVPR)}, 2020.

\bibitem{liu2019ddflow}
P.~Liu, I.~King, M.~R. Lyu, and J.~Xu.
\newblock Ddflow: Learning optical flow with unlabeled data distillation.
\newblock In {\em Proceedings of the AAAI Conference on Artificial Intelligence}, volume~33, pages 8770--8777, 2019.

\bibitem{lucas1981iterative}
B.~D. Lucas, T.~Kanade, et~al.
\newblock An iterative image registration technique with an application to stereo vision.
\newblock Vancouver, British Columbia, 1981.

\bibitem{mai2022motion}
L.~Mai and F.~Liu.
\newblock Motion-adjustable neural implicit video representation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 10738--10747, 2022.

\bibitem{mayer2016large}
N.~Mayer, E.~Ilg, P.~Hausser, P.~Fischer, D.~Cremers, A.~Dosovitskiy, and T.~Brox.
\newblock A large dataset to train convolutional networks for disparity, optical flow, and scene flow estimation.
\newblock In {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 4040--4048, 2016.

\bibitem{menze2015object}
M.~Menze and A.~Geiger.
\newblock Object scene flow for autonomous vehicles.
\newblock In {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 3061--3070, 2015.

\bibitem{mildenhall2021nerf}
B.~Mildenhall, P.~P. Srinivasan, M.~Tancik, J.~T. Barron, R.~Ramamoorthi, and R.~Ng.
\newblock Nerf: Representing scenes as neural radiance fields for view synthesis.
\newblock {\em Communications of the ACM}, 2021.

\bibitem{oh2018learning}
T.-H. Oh, R.~Jaroensri, C.~Kim, M.~Elgharib, F.~Durand, W.~T. Freeman, and W.~Matusik.
\newblock Learning-based video motion magnification.
\newblock In {\em Proceedings of the European Conference on Computer Vision (ECCV)}, pages 633--648, 2018.

\bibitem{perez2022video}
E.~P{\'e}rez and E.~Zappa.
\newblock Video motion magnification to improve the accuracy of vision-based vibration measurements.
\newblock {\em IEEE Transactions on Instrumentation and Measurement}, 71:1--12, 2022.

\bibitem{0PontTuset2017}
J.~Pont-Tuset, F.~Perazzi, S.~Caelles, P.~Arbel\'aez, A.~Sorkine-Hornung, and L.~{Van Gool}.
\newblock The 2017 davis challenge on video object segmentation.
\newblock {\em arXiv:1704.00675}, 2017.

\bibitem{ranjan2017optical}
A.~Ranjan and M.~J. Black.
\newblock Optical flow estimation using a spatial pyramid network.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pages 4161--4170, 2017.

\bibitem{ren2017unsupervised}
Z.~Ren, J.~Yan, B.~Ni, B.~Liu, X.~Yang, and H.~Zha.
\newblock Unsupervised deep learning for optical flow estimation.
\newblock In {\em Thirty-First AAAI Conference on Artificial Intelligence}, 2017.

\bibitem{ronneberger2015u}
O.~Ronneberger, P.~Fischer, and T.~Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In {\em Medical Image Computing and Computer-Assisted Intervention--MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18}, pages 234--241. Springer, 2015.

\bibitem{sigurdsson2016hollywood}
G.~A. Sigurdsson, G.~Varol, X.~Wang, A.~Farhadi, I.~Laptev, and A.~Gupta.
\newblock Hollywood in homes: Crowdsourcing data collection for activity understanding.
\newblock In {\em Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11--14, 2016, Proceedings, Part I 14}, pages 510--526. Springer, 2016.

\bibitem{simoncelli1995steerable}
E.~P. Simoncelli and W.~T. Freeman.
\newblock The steerable pyramid: A flexible architecture for multi-scale derivative computation.
\newblock In {\em Proceedings., International Conference on Image Processing}, volume~3, pages 444--447. IEEE, 1995.

\bibitem{singh2023lightweight}
J.~Singh, S.~Murala, and G.~Kosuru.
\newblock Lightweight network for video motion magnification.
\newblock In {\em Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, pages 2041--2050, 2023.

\bibitem{sun2010secrets}
D.~Sun, S.~Roth, and M.~J. Black.
\newblock Secrets of optical flow estimation and their principles.
\newblock In {\em 2010 IEEE computer society conference on computer vision and pattern recognition}, pages 2432--2439. IEEE, 2010.

\bibitem{sun2014quantitative}
D.~Sun, S.~Roth, and M.~J. Black.
\newblock A quantitative analysis of current practices in optical flow estimation and the principles behind them.
\newblock {\em International Journal of Computer Vision}, 106:115--137, 2014.

\bibitem{sun2018pwc}
D.~Sun, X.~Yang, M.-Y. Liu, and J.~Kautz.
\newblock Pwc-net: Cnns for optical flow using pyramid, warping, and cost volume.
\newblock In {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 8934--8943, 2018.

\bibitem{sun2020test}
Y.~Sun, X.~Wang, Z.~Liu, J.~Miller, A.~Efros, and M.~Hardt.
\newblock Test-time training with self-supervision for generalization under distribution shifts.
\newblock In {\em International conference on machine learning}, pages 9229--9248. PMLR, 2020.

\bibitem{szeliski2022computer}
R.~Szeliski.
\newblock {\em Computer vision: algorithms and applications}.
\newblock Springer Nature, 2022.

\bibitem{teed2020raft}
Z.~Teed and J.~Deng.
\newblock Raft: Recurrent all-pairs field transforms for optical flow.
\newblock In {\em Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part II 16}, pages 402--419. Springer, 2020.

\bibitem{teed2021droid}
Z.~Teed and J.~Deng.
\newblock Droid-slam: Deep visual slam for monocular, stereo, and rgb-d cameras.
\newblock {\em Advances in neural information processing systems}, 34:16558--16569, 2021.

\bibitem{thomee2016yfcc100m}
B.~Thomee, D.~A. Shamma, G.~Friedland, B.~Elizalde, K.~Ni, D.~Poland, D.~Borth, and L.-J. Li.
\newblock Yfcc100m: The new data in multimedia research.
\newblock {\em Communications of the ACM}, 59(2):64--73, 2016.

\bibitem{wadhwa2017motion}
N.~Wadhwa, J.~G. Chen, J.~B. Sellon, D.~Wei, M.~Rubinstein, R.~Ghaffari, D.~M. Freeman, O.~B{\"u}y{\"u}k{\"o}zt{\"u}rk, P.~Wang, S.~Sun, et~al.
\newblock Motion microscopy for visualizing and quantifying small motions.
\newblock {\em Proceedings of the National Academy of Sciences}, 114(44):11639--11644, 2017.

\bibitem{wadhwa2013phase}
N.~Wadhwa, M.~Rubinstein, F.~Durand, and W.~T. Freeman.
\newblock Phase-based video motion processing.
\newblock {\em ACM Transactions on Graphics (TOG)}, 32(4):1--10, 2013.

\bibitem{wadhwa2014riesz}
N.~Wadhwa, M.~Rubinstein, F.~Durand, and W.~T. Freeman.
\newblock Riesz pyramids for fast phase-based video magnification.
\newblock In {\em 2014 IEEE International Conference on Computational Photography (ICCP)}, pages 1--10. IEEE, 2014.

\bibitem{wang2021unidentified}
W.~Wang, M.~Feiszli, H.~Wang, and D.~Tran.
\newblock Unidentified video objects: A benchmark for dense, open-world segmentation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 10776--10785, 2021.

\bibitem{wang2018occlusion}
Y.~Wang, Y.~Yang, Z.~Yang, L.~Zhao, P.~Wang, and W.~Xu.
\newblock Occlusion aware unsupervised learning of optical flow.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pages 4884--4893, 2018.

\bibitem{wang2004ssim}
Z.~Wang, A.~Bovik, H.~Sheikh, and E.~Simoncelli.
\newblock Image quality assessment: from error visibility to structural similarity.
\newblock {\em IEEE Transactions on Image Processing}, 13(4):600--612, 2004.

\bibitem{wei2022novel}
M.~Wei, W.~Zheng, Y.~Zong, X.~Jiang, C.~Lu, and J.~Liu.
\newblock A novel micro-expression recognition approach using attention-based magnification-adaptive networks.
\newblock In {\em ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 2420--2424. IEEE, 2022.

\bibitem{wu2012eulerian}
H.-Y. Wu, M.~Rubinstein, E.~Shih, J.~Guttag, F.~Durand, and W.~Freeman.
\newblock Eulerian video magnification for revealing subtle changes in the world.
\newblock {\em ACM transactions on graphics (TOG)}, 31(4):1--8, 2012.

\bibitem{xu2022gmflow}
H.~Xu, J.~Zhang, J.~Cai, H.~Rezatofighi, and D.~Tao.
\newblock Gmflow: Learning optical flow via global matching.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 8121--8130, 2022.

\bibitem{xue2019video}
T.~Xue, B.~Chen, J.~Wu, D.~Wei, and W.~T. Freeman.
\newblock Video enhancement with task-oriented flow.
\newblock {\em International Journal of Computer Vision (IJCV)}, 127(8):1106--1125, 2019.

\bibitem{yang2019volumetric}
G.~Yang and D.~Ramanan.
\newblock Volumetric correspondence networks for optical flow.
\newblock In {\em Advances in neural information processing systems}, pages 794--805, 2019.

\bibitem{vos2019}
L.~Yang, Y.~Fan, and N.~Xu.
\newblock The 2nd large-scale video object segmentation challenge - video object segmentation track, Oct. 2019.

\bibitem{yu2020bdd100k}
F.~Yu, H.~Chen, X.~Wang, W.~Xian, Y.~Chen, F.~Liu, V.~Madhavan, and T.~Darrell.
\newblock Bdd100k: A diverse driving dataset for heterogeneous multitask learning.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 2636--2645, 2020.

\bibitem{yu2019free}
J.~Yu, Z.~Lin, J.~Yang, X.~Shen, X.~Lu, and T.~S. Huang.
\newblock Free-form image inpainting with gated convolution.
\newblock In {\em Proceedings of the IEEE/CVF international conference on computer vision}, pages 4471--4480, 2019.

\bibitem{yu2016back}
J.~J. Yu, A.~W. Harley, and K.~G. Derpanis.
\newblock Back to basics: Unsupervised learning of optical flow via brightness constancy and motion smoothness.
\newblock In {\em Computer Vision - ECCV 2016 Workshops, Part 3}, 2016.

\bibitem{zhang2017video}
Y.~Zhang, S.~L. Pintea, and J.~C. Van~Gemert.
\newblock Video acceleration magnification.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pages 529--537, 2017.

\end{thebibliography}
