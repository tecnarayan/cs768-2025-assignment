\begin{thebibliography}{49}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agostinelli et~al.(2023)Agostinelli, Denk, Borsos, Engel, Verzetti, Caillon, Huang, Jansen, Roberts, Tagliasacchi, et~al.]{musiclm}
Agostinelli, A., Denk, T.~I., Borsos, Z., Engel, J., Verzetti, M., Caillon, A., Huang, Q., Jansen, A., Roberts, A., Tagliasacchi, M., et~al.
\newblock Musiclm: Generating music from text.
\newblock \emph{arXiv preprint arXiv:2301.11325}, 2023.

\bibitem[Baevski et~al.(2020)Baevski, Zhou, rahman Mohamed, and Auli]{Baevski2020wav2vec2A}
Baevski, A., Zhou, H., rahman Mohamed, A., and Auli, M.
\newblock wav2vec 2.0: A framework for self-supervised learning of speech representations.
\newblock \emph{ArXiv}, abs/2006.11477, 2020.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:219966759}.

\bibitem[Benetos et~al.(2019)Benetos, Dixon, Duan, and Ewert]{Benetos2019Automatic}
Benetos, E., Dixon, S., Duan, Z., and Ewert, S.
\newblock Automatic music transcription: An overview.
\newblock \emph{IEEE Signal Processing Magazine}, 36:\penalty0 20--30, 2019.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:57191022}.

\bibitem[Bittner et~al.(2022)Bittner, Bosch, Rubinstein, Meseguer-Brocal, and Ewert]{Bittner2022ALI}
Bittner, R.~M., Bosch, J.~J., Rubinstein, D., Meseguer-Brocal, G., and Ewert, S.
\newblock A lightweight instrument-agnostic model for polyphonic note transcription and multipitch estimation.
\newblock \emph{ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pp.\  781--785, 2022.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:247595162}.

\bibitem[Copet et~al.(2023)Copet, Kreuk, Gat, Remez, Kant, Synnaeve, Adi, and D{\'e}fossez]{musicgen}
Copet, J., Kreuk, F., Gat, I., Remez, T., Kant, D., Synnaeve, G., Adi, Y., and D{\'e}fossez, A.
\newblock Simple and controllable music generation.
\newblock \emph{arXiv preprint arXiv:2306.05284}, 2023.

\bibitem[Dongchao et~al.(2023)Dongchao, Jinchuan, Xu, Rongjie, Songxiang, Xuankai, Jiatong, Sheng, Jiang, Xixin, Zhou, and Helen]{uniaudio}
Dongchao, Y., Jinchuan, T., Xu, T., Rongjie, H., Songxiang, L., Xuankai, C., Jiatong, S., Sheng, Z., Jiang, B., Xixin, W., Zhou, Z., and Helen, M.
\newblock Uniaudio: An audio foundation model toward universal audio generation.
\newblock \emph{arXiv preprint arXiv:2310.00704}, 2023.

\bibitem[Défossez et~al.(2022)Défossez, Copet, Synnaeve, and Adi]{defossez2022highfi}
Défossez, A., Copet, J., Synnaeve, G., and Adi, Y.
\newblock High fidelity neural audio compression.
\newblock \emph{arXiv preprint arXiv:2210.13438}, 2022.

\bibitem[Evans et~al.(2024)Evans, Carr, Taylor, Hawley, and Pons]{evans2024fast}
Evans, Z., Carr, C., Taylor, J., Hawley, S.~H., and Pons, J.
\newblock Fast timing-conditioned latent audio diffusion.
\newblock \emph{arXiv preprint arXiv:2402.04825}, 2024.

\bibitem[Forsgren \& Martiros(2022)Forsgren and Martiros]{forsgren2022riffusion}
Forsgren, S. and Martiros, H.
\newblock Riffusion-stable diffusion for real-time music generation.
\newblock 2022.
\newblock URL \url{https://riffusion. com/about}.

\bibitem[Hawthorne et~al.(2018)Hawthorne, Stasyuk, Roberts, Simon, Huang, Dieleman, Elsen, Engel, and Eck]{Hawthorne2018EnablingFP}
Hawthorne, C., Stasyuk, A., Roberts, A., Simon, I., Huang, C.-Z.~A., Dieleman, S., Elsen, E., Engel, J., and Eck, D.
\newblock Enabling factorized piano music modeling and generation with the maestro dataset.
\newblock In \emph{ICLR}, volume abs/1810.12247, 2018.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:53094405}.

\bibitem[Hawthorne et~al.(2021)Hawthorne, Simon, Swavely, Manilow, and Engel]{Hawthorne2021SequencetoSequencePT}
Hawthorne, C., Simon, I., Swavely, R., Manilow, E., and Engel, J.
\newblock Sequence-to-sequence piano transcription with transformers.
\newblock In \emph{International Society for Music Information Retrieval Conference}, 2021.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:236134377}.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{Ho2020Denoising}
Ho, J., Jain, A., and Abbeel, P.
\newblock Denoising diffusion probabilistic models.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H. (eds.), \emph{Advances in Neural Information Processing Systems}, volume~33, pp.\  6840--6851. Curran Associates, Inc., 2020.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2020/file/4c5bcfec8584af0d967f1ab10179ca4b-Paper.pdf}.

\bibitem[Hsu \& Su(2021)Hsu and Su]{hsu2021vocano}
Hsu, J.-Y. and Su, L.
\newblock {VOCANO}: A note transcription framework for singing voice in polyphonic music.
\newblock In \emph{Proc. International Society of Music Information Retrieval Conference (ISMIR)}, 2021.

\bibitem[Hsu et~al.(2021)Hsu, Bolte, Tsai, Lakhotia, Salakhutdinov, and rahman Mohamed]{Hsu2021HuBERTSS}
Hsu, W.-N., Bolte, B., Tsai, Y.-H.~H., Lakhotia, K., Salakhutdinov, R., and rahman Mohamed, A.
\newblock Hubert: Self-supervised speech representation learning by masked prediction of hidden units.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 29:\penalty0 3451--3460, 2021.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:235421619}.

\bibitem[Huang et~al.(2023)Huang, Park, Wang, Denk, Ly, Chen, Zhang, Zhang, Yu, Frank, et~al.]{noise2music}
Huang, Q., Park, D.~S., Wang, T., Denk, T.~I., Ly, A., Chen, N., Zhang, Z., Zhang, Z., Yu, J., Frank, C., et~al.
\newblock Noise2music: Text-conditioned music generation with diffusion models.
\newblock \emph{arXiv preprint arXiv:2302.03917}, 2023.

\bibitem[Hung et~al.(2019)Hung, Wang, Yang, and Wang]{Hung2019ImprovingAJ}
Hung, H.-T., Wang, C.-Y., Yang, Y.-H., and Wang, H.-M.
\newblock Improving automatic jazz melody generation by transfer learning techniques.
\newblock \emph{2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}, pp.\  339--346, 2019.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:201666995}.

\bibitem[Kilgour et~al.(2019)Kilgour, Zuluaga, Roblek, and Sharifi]{Kilgour2019FrchetAD}
Kilgour, K., Zuluaga, M., Roblek, D., and Sharifi, M.
\newblock Fr{\'e}chet audio distance: A reference-free metric for evaluating music enhancement algorithms.
\newblock In \emph{Interspeech}, 2019.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{International Conference on Learning Representations}, 12 2014.

\bibitem[Kong et~al.(2019)Kong, Cao, Iqbal, Wang, Wang, and Plumbley]{Kong2019PANNsLP}
Kong, Q., Cao, Y., Iqbal, T., Wang, Y., Wang, W., and Plumbley, M.~D.
\newblock Panns: Large-scale pretrained audio neural networks for audio pattern recognition.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 28, 2019.

\bibitem[Kreuk et~al.(2022)Kreuk, Synnaeve, Polyak, Singer, D'efossez, Copet, Parikh, Taigman, and Adi]{Kreuk2022AudioGenTG}
Kreuk, F., Synnaeve, G., Polyak, A., Singer, U., D'efossez, A., Copet, J., Parikh, D., Taigman, Y., and Adi, Y.
\newblock Audiogen: Textually guided audio generation.
\newblock \emph{ArXiv}, abs/2209.15352, 2022.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:252668761}.

\bibitem[Kumar et~al.(2024)Kumar, Seetharaman, Luebs, Kumar, and Kumar]{dac}
Kumar, R., Seetharaman, P., Luebs, A., Kumar, I., and Kumar, K.
\newblock High-fidelity audio compression with improved rvqgan.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Lam et~al.(2024)Lam, Tian, Li, Yin, Feng, Tu, Ji, Xia, Ma, Song, et~al.]{melody}
Lam, M.~W., Tian, Q., Li, T., Yin, Z., Feng, S., Tu, M., Ji, Y., Xia, R., Ma, M., Song, X., et~al.
\newblock Efficient neural music generation.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Le et~al.(2023)Le, Vyas, Shi, Karrer, Sari, Moritz, Williamson, Manohar, Adi, Mahadeokar, and Hsu]{Le2023VoiceboxTM}
Le, M., Vyas, A., Shi, B., Karrer, B., Sari, L., Moritz, R., Williamson, M., Manohar, V., Adi, Y., Mahadeokar, J., and Hsu, W.-N.
\newblock Voicebox: Text-guided multilingual universal speech generation at scale.
\newblock In \emph{NeurIPS}, 2023.

\bibitem[Li et~al.(2023{\natexlab{a}})Li, Chen, Yao, Wang, Wang, and Wang]{jen1}
Li, P., Chen, B., Yao, Y., Wang, Y., Wang, A., and Wang, A.
\newblock Jen-1: Text-guided universal music generation with omnidirectional diffusion models.
\newblock \emph{arXiv preprint arXiv:2308.04729}, 2023{\natexlab{a}}.

\bibitem[Li et~al.(2023{\natexlab{b}})Li, Yuan, Zhang, Ma, Chen, Yin, Lin, Ragni, Benetos, Gyenge, Dannenberg, Liu, Chen, Xia, Shi, Huang, Guo, and Fu]{mert}
Li, Y., Yuan, R., Zhang, G., Ma, Y., Chen, X., Yin, H., Lin, C., Ragni, A., Benetos, E., Gyenge, N., Dannenberg, R., Liu, R., Chen, W., Xia, G., Shi, Y., Huang, W., Guo, Y., and Fu, J.
\newblock Mert: Acoustic music understanding model with large-scale self-supervised training, 2023{\natexlab{b}}.

\bibitem[Lipman et~al.(2023)Lipman, Chen, Ben-Hamu, Nickel, and Le]{Lipman2022FlowMF}
Lipman, Y., Chen, R. T.~Q., Ben-Hamu, H., Nickel, M., and Le, M.
\newblock Flow matching for generative modeling.
\newblock In \emph{ICLR}, 2023.

\bibitem[Liu et~al.(2023{\natexlab{a}})Liu, Chen, Yuan, Mei, Liu, Mandic, Wang, and Plumbley]{liu2023audioldm}
Liu, H., Chen, Z., Yuan, Y., Mei, X., Liu, X., Mandic, D., Wang, W., and Plumbley, M.~D.
\newblock {AudioLDM}: Text-to-audio generation with latent diffusion models.
\newblock \emph{Proceedings of the International Conference on Machine Learning}, 2023{\natexlab{a}}.

\bibitem[Liu et~al.(2023{\natexlab{b}})Liu, Tian, Yuan, Liu, Mei, Kong, Wang, Wang, Wang, and Plumbley]{audio-ldm2}
Liu, H., Tian, Q., Yuan, Y., Liu, X., Mei, X., Kong, Q., Wang, Y., Wang, W., Wang, Y., and Plumbley, M.~D.
\newblock Audioldm 2: Learning holistic audio generation with self-supervised pretraining.
\newblock \emph{arXiv preprint arXiv:2308.05734}, 2023{\natexlab{b}}.

\bibitem[Liu et~al.(2023{\natexlab{c}})Liu, Zhu, Liu, Yuan, Huang, Liang, Cao, Kong, Plumbley, and Wang]{liu2023wavjourney}
Liu, X., Zhu, Z., Liu, H., Yuan, Y., Huang, Q., Liang, J., Cao, Y., Kong, Q., Plumbley, M.~D., and Wang, W.
\newblock Wavjourney: Compositional audio creation with large language models.
\newblock \emph{arXiv preprint arXiv:2307.14335}, 2023{\natexlab{c}}.

\bibitem[Luo et~al.(2023)Luo, Yan, Hu, and Zhao]{Luo2023DiffFoleySV}
Luo, S., Yan, C., Hu, C., and Zhao, H.
\newblock Diff-foley: Synchronized video-to-audio synthesis with latent diffusion models.
\newblock In \emph{CVPR}, volume abs/2306.17203, 2023.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:259309037}.

\bibitem[Müller(2015)]{muller2015fundamentals}
Müller, M.
\newblock \emph{Fundamentals of Music Processing}.
\newblock 01 2015.
\newblock ISBN 978-3-319-21944-8.
\newblock \doi{10.1007/978-3-319-21945-5}.

\bibitem[Pasad et~al.(2023)Pasad, Shi, and Livescu]{Pasad2023comparative}
Pasad, A., Shi, B., and Livescu, K.
\newblock Comparative layer-wise analysis of self-supervised speech models.
\newblock In \emph{ICASSP}, 2023.

\bibitem[Pasini et~al.(2023)Pasini, Lattner, and Fazekas]{Pasini2023SelfSupervisedMS}
Pasini, M., Lattner, S., and Fazekas, G.
\newblock Self-supervised music source separation using vector-quantized source category estimates.
\newblock \emph{ArXiv}, abs/2311.13058, 2023.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:265351916}.

\bibitem[Press et~al.(2021)Press, Smith, and Lewis]{Press2021TrainST}
Press, O., Smith, N.~A., and Lewis, M.
\newblock Train short, test long: Attention with linear biases enables input length extrapolation.
\newblock \emph{ArXiv}, abs/2108.12409, 2021.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:237347130}.

\bibitem[Rombach et~al.(2021)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2021highresolution}
Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B.
\newblock High-resolution image synthesis with latent diffusion models, 2021.

\bibitem[Salimans et~al.(2016)Salimans, Goodfellow, Zaremba, Cheung, Radford, and Chen]{Salimans2016ImprovedTF}
Salimans, T., Goodfellow, I.~J., Zaremba, W., Cheung, V., Radford, A., and Chen, X.
\newblock Improved techniques for training gans.
\newblock \emph{ArXiv}, abs/1606.03498, 2016.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:1687220}.

\bibitem[Schneider et~al.(2023)Schneider, Jin, and Schölkopf]{schneider2023mousai}
Schneider, F., Jin, Z., and Schölkopf, B.
\newblock Mo\^usai: Text-to-music generation with long-context latent diffusion.
\newblock 01 2023.
\newblock \doi{10.48550/arXiv.2301.11757}.

\bibitem[Shaul et~al.(2023)Shaul, Perez, Chen, Thabet, Pumarola, and Lipman]{shaul2023bespoke}
Shaul, N., Perez, J., Chen, R. T.~Q., Thabet, A., Pumarola, A., and Lipman, Y.
\newblock Bespoke solvers for generative flow models.
\newblock \emph{arXiv:2310.19075}, 2023.
\newblock URL \url{https://arxiv.org/abs/2310.19075}.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and Ganguli]{Dickstein2015deep}
Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., and Ganguli, S.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock \emph{JMLR}, 2015.

\bibitem[Song et~al.(2020)Song, Meng, and Ermon]{song2020denoising}
Song, J., Meng, C., and Ermon, S.
\newblock Denoising diffusion implicit models.
\newblock \emph{arXiv:2010.02502}, October 2020.
\newblock URL \url{https://arxiv.org/abs/2010.02502}.

\bibitem[Song et~al.(2021)Song, Sohl-Dickstein, Kingma, Kumar, Ermon, and Poole]{song2021scorebased}
Song, Y., Sohl-Dickstein, J., Kingma, D.~P., Kumar, A., Ermon, S., and Poole, B.
\newblock Score-based generative modeling through stochastic differential equations.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=PxTIG12RRHS}.

\bibitem[Su et~al.(2019)Su, Chen, Su, and Yang]{Su2019tent}
Su, T.-W., Chen, Y.-P., Su, L., and Yang, y.-h.
\newblock Tent: Technique-embedded note tracking for real-world guitar solo recordings.
\newblock \emph{Transactions of the International Society for Music Information Retrieval}, 2:\penalty0 15--28, 07 2019.
\newblock \doi{10.5334/tismir.23}.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{Vaswani2017AttentionIA}
Vaswani, A., Shazeer, N.~M., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N., Kaiser, L., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In \emph{Neural Information Processing Systems}, 2017.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:13756489}.

\bibitem[Vyas et~al.(2023)Vyas, Shi, Le, Tjandra, Wu, Guo, Zhang, Zhang, Adkins, Ngan, Wang, Cruz, Akula, Akinyemi, Ellis, Moritz, Yungster, Rakotoarison, Tan, Summers, Wood, Lane, Williamson, and Hsu]{Vyas2023AudioboxUA}
Vyas, A., Shi, B., Le, M., Tjandra, A., Wu, Y.-C., Guo, B., Zhang, J., Zhang, X., Adkins, R., Ngan, W., Wang, J., Cruz, I., Akula, B., Akinyemi, A.~T., Ellis, B., Moritz, R., Yungster, Y., Rakotoarison, A., Tan, L., Summers, C., Wood, C., Lane, J., Williamson, M., and Hsu, W.-N.
\newblock Audiobox: Unified audio generation with natural language prompts.
\newblock 2023.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:266551778}.

\bibitem[Wang et~al.(2023)Wang, Chen, Wu, Zhang, Zhou, Liu, Chen, Liu, Wang, Li, He, Zhao, and Wei]{Wang2023NeuralCL}
Wang, C., Chen, S., Wu, Y., Zhang, Z.-H., Zhou, L., Liu, S., Chen, Z., Liu, Y., Wang, H., Li, J., He, L., Zhao, S., and Wei, F.
\newblock Neural codec language models are zero-shot text to speech synthesizers.
\newblock \emph{ArXiv}, abs/2301.02111, 2023.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:255440307}.

\bibitem[Yang et~al.(2023)Yang, Tian, Tan, Huang, Liu, Chang, Shi, Zhao, Bian, Wu, Zhao, and Meng]{yang2023uniaudio}
Yang, D., Tian, J., Tan, X., Huang, R., Liu, S., Chang, X., Shi, J., Zhao, S., Bian, J., Wu, X., Zhao, Z., and Meng, H.
\newblock Uniaudio: An audio foundation model toward universal audio generation.
\newblock \emph{arXiv preprint arXiv:2310.00704}, 2023.

\bibitem[Zeghidour et~al.(2021)Zeghidour, Luebs, Omran, Skoglund, and Tagliasacchi]{zeghidour2021soundstream}
Zeghidour, N., Luebs, A., Omran, A., Skoglund, J., and Tagliasacchi, M.
\newblock Soundstream: An end-to-end neural audio codec.
\newblock 2021.

\bibitem[Zheng et~al.(2023)Zheng, Le, Shaul, Lipman, Grover, and Chen]{Zheng2023GuidedFF}
Zheng, Q., Le, M., Shaul, N., Lipman, Y., Grover, A., and Chen, R. T.~Q.
\newblock Guided flows for generative modeling and decision making.
\newblock \emph{ArXiv}, abs/2311.13443, 2023.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:265351587}.

\bibitem[Ziv et~al.(2024)Ziv, Gat, Lan, Remez, Kreuk, Défossez, Copet, Synnaeve, and Adi]{ziv2024masked}
Ziv, A., Gat, I., Lan, G.~L., Remez, T., Kreuk, F., Défossez, A., Copet, J., Synnaeve, G., and Adi, Y.
\newblock Masked audio generation using a single non-autoregressive transformer.
\newblock \emph{arXiv:2401.04577}, 2024.
\newblock URL \url{https://arxiv.org/abs/2401.04577}.

\end{thebibliography}
