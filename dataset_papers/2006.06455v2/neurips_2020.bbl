\begin{thebibliography}{10}

\bibitem{das2019tarmac}
Abhishek Das, Th{\'e}ophile Gervet, Joshua Romoff, Dhruv Batra, Devi Parikh,
  Mike Rabbat, and Joelle Pineau.
\newblock Tarmac: Targeted multi-agent communication.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2019.

\bibitem{fehr2018normative}
Ernst Fehr and Ivo Schurtenberger.
\newblock Normative foundations of human cooperation.
\newblock {\em Nature Human Behaviour}, 2(7):458--468, 2018.

\bibitem{foerster2016learning}
Jakob Foerster, Ioannis~Alexandros Assael, Nando de~Freitas, and Shimon
  Whiteson.
\newblock Learning to communicate with deep multi-agent reinforcement learning.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2016.

\bibitem{foerster2018counterfactual}
Jakob Foerster, Gregory Farquhar, Triantafyllos Afouras, Nantas Nardelli, and
  Shimon Whiteson.
\newblock Counterfactual multi-agent policy gradients.
\newblock In {\em AAAI Conference on Artificial Intelligence (AAAI)}, 2018.

\bibitem{iqbal2019actor}
Shariq Iqbal and Fei Sha.
\newblock Actor-attention-critic for multi-agent reinforcement learning.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2019.

\bibitem{jaques2019social}
Natasha Jaques, Angeliki Lazaridou, Edward Hughes, Caglar Gulcehre, Pedro
  Ortega, Dj~Strouse, Joel~Z Leibo, and Nando De~Freitas.
\newblock Social influence as intrinsic motivation for multi-agent deep
  reinforcement learning.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2019.

\bibitem{jiang2020graph}
Jiechuan Jiang, Chen Dun, Tiejun Huang, and Zongqing Lu.
\newblock Graph convolutional reinforcement learning.
\newblock In {\em International Conference on Learning Representation (ICLR)},
  2020.

\bibitem{jiang2018learning}
Jiechuan Jiang and Zongqing Lu.
\newblock Learning attentional communication for multi-agent cooperation.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2018.

\bibitem{kim2018learning}
Daewoo Kim, Sangwoo Moon, David Hostallero, Wan~Ju Kang, Taeyoung Lee,
  Kyunghwan Son, and Yung Yi.
\newblock Learning to schedule communication in multi-agent reinforcement
  learning.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2019.

\bibitem{lowe2017multi}
Ryan Lowe, Yi~Wu, Aviv Tamar, Jean Harb, OpenAI~Pieter Abbeel, and Igor
  Mordatch.
\newblock Multi-agent actor-critic for mixed cooperative-competitive
  environments.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2017.

\bibitem{mnih2014recurrent}
Volodymyr Mnih, Nicolas Heess, Alex Graves, et~al.
\newblock Recurrent models of visual attention.
\newblock In {\em Advances in neural information processing systems (NeurIPS)},
  2014.

\bibitem{mnih2015human}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei~A Rusu, Joel Veness,
  Marc~G Bellemare, Alex Graves, Martin Riedmiller, Andreas~K Fidjeland, Georg
  Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock {\em Nature}, 518(7540):529, 2015.

\bibitem{peng2017multiagent}
Peng Peng, Ying Wen, Yaodong Yang, Quan Yuan, Zhenkun Tang, Haitao Long, and
  Jun Wang.
\newblock Multiagent bidirectionally-coordinated nets: Emergence of human-level
  coordination in learning to play starcraft combat games.
\newblock {\em arXiv preprint arXiv:1703.10069}, 2017.

\bibitem{rashid2018qmix}
Tabish Rashid, Mikayel Samvelyan, Christian~Schroeder de~Witt, Gregory
  Farquhar, Jakob Foerster, and Shimon Whiteson.
\newblock Qmix: Monotonic value function factorisation for deep multi-agent
  reinforcement learning.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2018.

\bibitem{shalev2016safe}
Shai Shalev-Shwartz, Shaked Shammah, and Amnon Shashua.
\newblock Safe, multi-agent, reinforcement learning for autonomous driving.
\newblock {\em arXiv preprint arXiv:1610.03295}, 2016.

\bibitem{silver2016mastering}
David Silver, Aja Huang, Chris~J Maddison, Arthur Guez, Laurent Sifre, George
  Van Den~Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda
  Panneershelvam, Marc Lanctot, et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock {\em nature}, 529(7587):484, 2016.

\bibitem{singh2019individualized}
Amanpreet Singh, Tushar Jain, and Sainbayar Sukhbaatar.
\newblock Individualized controlled continuous communication model for
  multiagent cooperative and competitive tasks.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2019.

\bibitem{son2019qtran}
Kyunghwan Son, Daewoo Kim, Wan~Ju Kang, David~Earl Hostallero, and Yung Yi.
\newblock Qtran: Learning to factorize with transformation for cooperative
  multi-agent reinforcement learning.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2019.

\bibitem{sukhbaatar2016learning}
Sainbayar Sukhbaatar, Rob Fergus, et~al.
\newblock Learning multiagent communication with backpropagation.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2016.

\bibitem{sunehag2018vdn}
Peter Sunehag, Guy Lever, Audrunas Gruslys, Wojciech~Marian Czarnecki, Vinicius
  Zambaldi, Max Jaderberg, Marc Lanctot, Nicolas Sonnerat, Joel~Z. Leibo, Karl
  Tuyls, and Thore Graepel.
\newblock Value-decomposition networks for cooperative multi-agent learning
  based on team reward.
\newblock In {\em International Conference on Autonomous Agents and MultiAgent
  Systems (AAMAS)}, 2018.

\bibitem{tan1993multi}
Ming Tan.
\newblock Multi-agent reinforcement learning: Independent vs. cooperative
  agents.
\newblock In {\em International Conference on Machine Learning (ICML)}, 1993.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em Advances in neural information processing systems (NeurIPS)},
  2017.

\bibitem{vinyals2019grandmaster}
Oriol Vinyals, Igor Babuschkin, Wojciech~M Czarnecki, Micha{\"e}l Mathieu,
  Andrew Dudzik, Junyoung Chung, David~H Choi, Richard Powell, Timo Ewalds,
  Petko Georgiev, et~al.
\newblock Grandmaster level in starcraft ii using multi-agent reinforcement
  learning.
\newblock {\em Nature}, 575(7782):350--354, 2019.

\bibitem{wang2020learning}
Tonghan Wang, Jianhao Wang, Chongyi Zheng, and Chongjie Zhang.
\newblock Learning nearly decomposable value functions via communication
  minimization.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2020.

\bibitem{wei2019colight}
Hua Wei, Nan Xu, Huichu Zhang, Guanjie Zheng, Xinshi Zang, Chacha Chen, Weinan
  Zhang, Yanmin Zhu, Kai Xu, and Zhenhui Li.
\newblock Colight: Learning network-level cooperation for traffic signal
  control.
\newblock {\em arXiv preprint arXiv:1905.05717}, 2019.

\bibitem{yang2018recurrent}
Yaodong Yang, Jianye Hao, Mingyang Sun, Zan Wang, Changjie Fan, and Goran
  Strbac.
\newblock Recurrent deep multiagent q-learning for autonomous brokers in smart
  grid.
\newblock In {\em International Joint Conferences on Artificial Intelligence
  (IJCAI)}, 2018.

\bibitem{zhang2019efficient}
Sai~Qian Zhang, Qi~Zhang, and Jieyu Lin.
\newblock Efficient communication in multi-agent reinforcement learning via
  variance based control.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2019.

\end{thebibliography}
