\begin{thebibliography}{10}

\bibitem{agueh2011barycenters}
Martial Agueh and Guillaume Carlier.
\newblock Barycenters in the {W}asserstein space.
\newblock {\em SIAM Journal on Mathematical Analysis}, 43(2):904--924, 2011.

\bibitem{altschuler2021averaging}
Jason~M Altschuler, Sinho Chewi, Patrik Gerber, and Austin~J Stromme.
\newblock Averaging on the bures-wasserstein manifold: dimension-free
  convergence of gradient descent.
\newblock {\em arXiv preprint arXiv:2106.08502}, 2021.

\bibitem{alvarez2016fixed}
Pedro~C {\'A}lvarez-Esteban, E~Del~Barrio, JA~Cuesta-Albertos, and
  C~Matr{\'a}n.
\newblock A fixed-point approach to barycenters in {W}asserstein space.
\newblock {\em Journal of Mathematical Analysis and Applications},
  441(2):744--762, 2016.

\bibitem{amos2017input}
Brandon Amos, Lei Xu, and J~Zico Kolter.
\newblock Input convex neural networks.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 146--155. JMLR. org, 2017.

\bibitem{arjovsky2017wasserstein}
Martin Arjovsky, Soumith Chintala, and L{\'e}on Bottou.
\newblock Wasserstein {GAN}.
\newblock {\em arXiv preprint arXiv:1701.07875}, 2017.

\bibitem{barannikov2021representation}
Serguei Barannikov, Ilya Trofimov, Nikita Balabin, and Evgeny Burnaev.
\newblock Representation topology divergence: A method for comparing neural
  network representations.
\newblock In Kamalika Chaudhuri, Stefanie Jegelka, Le~Song, Csaba Szepesvari,
  Gang Niu, and Sivan Sabato, editors, {\em Proceedings of the 39th
  International Conference on Machine Learning}, volume 162 of {\em Proceedings
  of Machine Learning Research}, pages 1607--1626. PMLR, 17--23 Jul 2022.

\bibitem{barannikov2021manifold}
Serguei Barannikov, Ilya Trofimov, Grigorii Sotnikov, Ekaterina Trimbach,
  Alexander Korotin, Alexander Filippov, and Evgeny Burnaev.
\newblock Manifold topology divergence: a framework for comparing data
  manifolds.
\newblock {\em Advances in Neural Information Processing Systems},
  34:7294--7305, 2021.

\bibitem{bespalov2021data}
Iaroslav Bespalov, Nazar Buzun, Oleg Kachan, and Dmitry~V Dylov.
\newblock Data augmentation with manifold barycenters.
\newblock {\em arXiv preprint arXiv:2104.00925}, 2021.

\bibitem{bigot2019data}
J{\'e}r{\'e}mie Bigot, Elsa Cazelles, and Nicolas Papadakis.
\newblock Data-driven regularization of wasserstein barycenters with an
  application to multivariate density registration.
\newblock {\em Information and Inference: A Journal of the IMA}, 8(4):719--755,
  2019.

\bibitem{bonneel2015sliced}
Nicolas Bonneel, Julien Rabin, Gabriel Peyr{\'e}, and Hanspeter Pfister.
\newblock Sliced and radon wasserstein barycenters of measures.
\newblock {\em Journal of Mathematical Imaging and Vision}, 51(1):22--45, 2015.

\bibitem{brenier1991polar}
Yann Brenier.
\newblock Polar factorization and monotone rearrangement of vector-valued
  functions.
\newblock {\em Communications on pure and applied mathematics}, 44(4):375--417,
  1991.

\bibitem{chen2019gradual}
Yucheng Chen, Matus Telgarsky, Chao Zhang, Bolton Bailey, Daniel Hsu, and Jian
  Peng.
\newblock A gradual, semi-discrete approach to generative network training via
  explicit {W}asserstein minimization.
\newblock In {\em International Conference on Machine Learning}, pages
  1071--1080. PMLR, 2019.

\bibitem{chewi2020gradient}
Sinho Chewi, Tyler Maunu, Philippe Rigollet, and Austin~J Stromme.
\newblock Gradient descent algorithms for bures-wasserstein barycenters.
\newblock In {\em Conference on Learning Theory}, pages 1276--1304. PMLR, 2020.

\bibitem{chi2021variational}
Jinjin Chi, Zhiyao Yang, Jihong Ouyang, and Ximing Li.
\newblock Variational wasserstein barycenters with c-cyclical monotonicity.
\newblock {\em arXiv preprint arXiv:2110.11707}, 2021.

\bibitem{colombo2021automatic}
Pierre Colombo, Guillaume Staerman, Chloe Clavel, and Pablo Piantanida.
\newblock Automatic text evaluation through the lens of wasserstein
  barycenters, 2021.

\bibitem{daaloul2021sampling}
Chiheb Daaloul, Thibaut~Le Gouic, Jacques Liandrat, and Magali Tournus.
\newblock Sampling from the wasserstein barycenter.
\newblock {\em arXiv preprint arXiv:2105.01706}, 2021.

\bibitem{dognin2019wasserstein}
Pierre Dognin, Igor Melnyk, Youssef Mroueh, Jerret Ross, Cicero~Dos Santos, and
  Tom Sercu.
\newblock Wasserstein barycenter model ensembling.
\newblock {\em arXiv preprint arXiv:1902.04999}, 2019.

\bibitem{etmann2020iunets}
Christian Etmann, Rihuan Ke, and Carola-Bibiane Sch{\"o}nlieb.
\newblock iunets: learnable invertible up-and downsampling for large-scale
  inverse problems.
\newblock In {\em 2020 IEEE 30th International Workshop on Machine Learning for
  Signal Processing (MLSP)}, pages 1--6. IEEE, 2020.

\bibitem{fan2020scalable}
Jiaojiao Fan, Amirhossein Taghvaei, and Yongxin Chen.
\newblock Scalable computations of {W}asserstein barycenter via input convex
  neural networks.
\newblock {\em arXiv preprint arXiv:2007.04462}, 2020.

\bibitem{fenchel1949conjugate}
Werner Fenchel.
\newblock On conjugate convex functions.
\newblock {\em Canadian Journal of Mathematics}, 1(1):73--77, 1949.

\bibitem{genevay2016stochastic}
Aude Genevay, Marco Cuturi, Gabriel Peyr{\'e}, and Francis Bach.
\newblock Stochastic optimization for large-scale optimal transport.
\newblock In {\em Advances in neural information processing systems}, pages
  3440--3448, 2016.

\bibitem{genevay2017gan}
Aude Genevay, Gabriel Peyr{\'e}, and Marco Cuturi.
\newblock Gan and vae from an optimal transport point of view.
\newblock {\em arXiv preprint arXiv:1706.01807}, 2017.

\bibitem{heusel2017gans}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp
  Hochreiter.
\newblock {GAN}s trained by a two time-scale update rule converge to a local
  nash equilibrium.
\newblock In {\em Advances in neural information processing systems}, pages
  6626--6637, 2017.

\bibitem{inouye2021iterative}
David~I Inouye, Zeyu Zhou, Ziyu Gong, and Pradeep Ravikumar.
\newblock Iterative barycenter flows.
\newblock {\em arXiv preprint arXiv:2104.07232}, 2021.

\bibitem{kantorovitch1958translocation}
Leonid Kantorovitch.
\newblock On the translocation of masses.
\newblock {\em Management Science}, 5(1):1--4, 1958.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{koldasbayeva2022large}
Diana Koldasbayeva, Polina Tregubova, Dmitrii Shadrin, Mikhail Gasanov, and
  Maria Pukalchik.
\newblock Large-scale forecasting of heracleum sosnowskyi habitat suitability
  under the climate change on publicly available data.
\newblock {\em Scientific reports}, 12(1):1--11, 2022.

\bibitem{korotin2019wasserstein}
Alexander Korotin, Vage Egiazarian, Arip Asadulaev, Alexander Safin, and Evgeny
  Burnaev.
\newblock Wasserstein-2 generative networks.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{korotin2021neural}
Alexander Korotin, Lingxiao Li, Aude Genevay, Justin~M Solomon, Alexander
  Filippov, and Evgeny Burnaev.
\newblock Do neural optimal transport solvers work? a continuous wasserstein-2
  benchmark.
\newblock {\em Advances in Neural Information Processing Systems},
  34:14593--14605, 2021.

\bibitem{korotin2021continuous}
Alexander Korotin, Lingxiao Li, Justin Solomon, and Evgeny Burnaev.
\newblock Continuous wasserstein-2 barycenter estimation without minimax
  optimization.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{korotin2021mixability}
Alexander Korotin, Vladimir Vâ€™yugin, and Evgeny Burnaev.
\newblock Mixability of integral losses: A key to efficient online aggregation
  of functional and probabilistic forecasts.
\newblock {\em Pattern Recognition}, 120:108175, 2021.

\bibitem{lacombe2021learning}
Julien Lacombe, Julie Digne, Nicolas Courty, and Nicolas Bonneel.
\newblock Learning to generate wasserstein barycenters.
\newblock {\em arXiv preprint arXiv:2102.12178}, 2021.

\bibitem{lecun-mnisthandwrittendigit-2010}
Yann LeCun and Corinna Cortes.
\newblock {MNIST} handwritten digit database.
\newblock 2010.

\bibitem{li2020continuous}
Lingxiao Li, Aude Genevay, Mikhail Yurochkin, and Justin Solomon.
\newblock Continuous regularized {W}asserstein barycenters.
\newblock {\em arXiv preprint arXiv:2008.12534}, 2020.

\bibitem{liu2019wasserstein}
Huidong Liu, Xianfeng Gu, and Dimitris Samaras.
\newblock Wasserstein {GAN} with quadratic transport cost.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision}, pages 4832--4841, 2019.

\bibitem{liu2015faceattributes}
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.
\newblock Deep learning face attributes in the wild.
\newblock In {\em Proceedings of International Conference on Computer Vision
  (ICCV)}, December 2015.

\bibitem{lu2020large}
Guansong Lu, Zhiming Zhou, Jian Shen, Cheng Chen, Weinan Zhang, and Yong Yu.
\newblock Large-scale optimal transport via adversarial training with
  cycle-consistency.
\newblock {\em arXiv preprint arXiv:2003.06635}, 2020.

\bibitem{lucic2018gans}
Mario Lucic, Karol Kurach, Marcin Michalski, Sylvain Gelly, and Olivier
  Bousquet.
\newblock Are {GAN}s created equal? a large-scale study.
\newblock In {\em Advances in neural information processing systems}, pages
  700--709, 2018.

\bibitem{lyu2021barycenteric}
Boyang Lyu, Thuan Nguyen, Prakash Ishwar, Matthias Scheutz, and Shuchin Aeron.
\newblock Barycenteric distribution alignment and manifold-restricted
  invertibility for domain generalization, 2021.

\bibitem{makkuva2019optimal}
Ashok~Vardhan Makkuva, Amirhossein Taghvaei, Sewoong Oh, and Jason~D Lee.
\newblock Optimal transport mapping via input convex neural networks.
\newblock {\em arXiv preprint arXiv:1908.10962}, 2019.

\bibitem{metelli2019propagating}
Alberto~Maria Metelli, Amarildo Likmeta, and Marcello Restelli.
\newblock Propagating uncertainty in reinforcement learning via wasserstein
  barycenters.
\newblock In {\em 33rd Conference on Neural Information Processing Systems,
  NeurIPS 2019}, pages 4335--4347. Curran Associates, Inc., 2019.

\bibitem{mokrov2021large}
Petr Mokrov, Alexander Korotin, Lingxiao Li, Aude Genevay, Justin~M Solomon,
  and Evgeny Burnaev.
\newblock Large-scale wasserstein gradient flows.
\newblock {\em Advances in Neural Information Processing Systems},
  34:15243--15256, 2021.

\bibitem{montesuma2021wasserstein}
Eduardo~Fernandes Montesuma and Fred Maurice~Ngole Mboula.
\newblock Wasserstein barycenter for multi-source domain adaptation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 16785--16793, 2021.

\bibitem{mroueh2019wasserstein}
Youssef Mroueh.
\newblock Wasserstein style transfer.
\newblock {\em arXiv preprint arXiv:1905.12828}, 2019.

\bibitem{murecsan2017fruit}
Horea Mure{\c{s}}an and Mihai Oltean.
\newblock Fruit recognition from images using deep learning.
\newblock {\em arXiv preprint arXiv:1712.00580}, 2017.

\bibitem{nhan2019threeplayer}
Quan~Hoang Nhan~Dam, Trung Le, Tu~Dinh Nguyen, Hung Bui, and Dinh Phung.
\newblock Threeplayer {W}asserstein {GAN} via amortised duality.
\newblock In {\em Proc. of the 28th Int. Joint Conf. on Artificial Intelligence
  (IJCAI)}, 2019.

\bibitem{paris2021online}
Quentin Paris.
\newblock Online learning with exponential weights in metric spaces.
\newblock {\em arXiv preprint arXiv:2103.14389}, 2021.

\bibitem{peyre2019computational}
Gabriel Peyr{\'e}, Marco Cuturi, et~al.
\newblock Computational optimal transport.
\newblock {\em Foundations and Trends{\textregistered} in Machine Learning},
  11(5-6):355--607, 2019.

\bibitem{rabin2014adaptive}
Julien Rabin, Sira Ferradans, and Nicolas Papadakis.
\newblock Adaptive color transfer with relaxed optimal transport.
\newblock In {\em 2014 IEEE International Conference on Image Processing
  (ICIP)}, pages 4852--4856. IEEE, 2014.

\bibitem{rabin2011wasserstein}
Julien Rabin, Gabriel Peyr{\'e}, Julie Delon, and Marc Bernot.
\newblock Wasserstein barycenter and its application to texture mixing.
\newblock In {\em International Conference on Scale Space and Variational
  Methods in Computer Vision}, pages 435--446. Springer, 2011.

\bibitem{rockafellar1976integral}
R~Tyrrell Rockafellar.
\newblock Integral functionals, normal integrands and measurable selections.
\newblock In {\em Nonlinear operators and the calculus of variations}, pages
  157--207. Springer, 1976.

\bibitem{ronneberger2015u}
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In {\em International Conference on Medical image computing and
  computer-assisted intervention}, pages 234--241. Springer, 2015.

\bibitem{rout2021generative}
Litu Rout, Alexander Korotin, and Evgeny Burnaev.
\newblock Generative modeling with optimal transport maps.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{santambrogio2015optimal}
Filippo Santambrogio.
\newblock Optimal transport for applied mathematicians.
\newblock {\em Birk{\"a}user, NY}, 55(58-63):94, 2015.

\bibitem{seguy2017large}
Vivien Seguy, Bharath~Bhushan Damodaran, R{\'e}mi Flamary, Nicolas Courty,
  Antoine Rolet, and Mathieu Blondel.
\newblock Large-scale optimal transport and mapping estimation.
\newblock {\em arXiv preprint arXiv:1711.02283}, 2017.

\bibitem{simon2020barycenters}
Dror Simon and Aviad Aberdam.
\newblock Barycenters of natural images constrained wasserstein barycenters for
  image morphing.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 7910--7919, 2020.

\bibitem{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock {\em arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{solomon2015convolutional}
Justin Solomon, Fernando De~Goes, Gabriel Peyr{\'e}, Marco Cuturi, Adrian
  Butscher, Andy Nguyen, Tao Du, and Leonidas Guibas.
\newblock Convolutional {W}asserstein distances: Efficient optimal
  transportation on geometric domains.
\newblock {\em ACM Transactions on Graphics (TOG)}, 34(4):1--11, 2015.

\bibitem{srivastava2015wasp}
Sanvesh Srivastava, Volkan Cevher, Quoc Dinh, and David Dunson.
\newblock Wasp: Scalable bayes via barycenters of subset posteriors.
\newblock In {\em Artificial Intelligence and Statistics}, pages 912--920,
  2015.

\bibitem{srivastava2018scalable}
Sanvesh Srivastava, Cheng Li, and David~B Dunson.
\newblock Scalable bayes via barycenter in {W}asserstein space.
\newblock {\em The Journal of Machine Learning Research}, 19(1):312--346, 2018.

\bibitem{staudt2022uniqueness}
Thomas Staudt, Shayan Hundrieser, and Axel Munk.
\newblock On the uniqueness of kantorovich potentials.
\newblock {\em arXiv preprint arXiv:2201.08316}, 2022.

\bibitem{taghvaei20192}
Amirhossein Taghvaei and Amin Jalali.
\newblock 2-{W}asserstein approximation via restricted convex potentials with
  application to improved training for {GAN}s.
\newblock {\em arXiv preprint arXiv:1902.07197}, 2019.

\bibitem{vidal2019progressive}
Jules Vidal, Joseph Budin, and Julien Tierny.
\newblock Progressive wasserstein barycenters of persistence diagrams.
\newblock {\em IEEE transactions on visualization and computer graphics},
  26(1):151--161, 2019.

\bibitem{villani2003topics}
C{\'e}dric Villani.
\newblock {\em Topics in optimal transportation}.
\newblock Number~58. American Mathematical Soc., 2003.

\bibitem{villani2008optimal}
C{\'e}dric Villani.
\newblock {\em Optimal transport: old and new}, volume 338.
\newblock Springer Science \& Business Media, 2008.

\bibitem{xiao2017fashion}
Han Xiao, Kashif Rasul, and Roland Vollgraf.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms.
\newblock {\em arXiv preprint arXiv:1708.07747}, 2017.

\bibitem{xie2019scalable}
Yujia Xie, Minshuo Chen, Haoming Jiang, Tuo Zhao, and Hongyuan Zha.
\newblock On scalable and efficient computation of large scale optimal
  transport.
\newblock volume~97 of {\em Proceedings of Machine Learning Research}, pages
  6882--6892, Long Beach, California, USA, 09--15 Jun 2019. PMLR.

\bibitem{yu2014fine}
Aron Yu and Kristen Grauman.
\newblock Fine-grained visual comparisons with local learning.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 192--199, 2014.

\end{thebibliography}
