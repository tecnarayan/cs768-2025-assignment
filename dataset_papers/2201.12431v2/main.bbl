\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aharoni \& Goldberg(2020)Aharoni and
  Goldberg]{aharoni2020unsupervised}
Aharoni, R. and Goldberg, Y.
\newblock Unsupervised domain clusters in pretrained language models.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pp.\  7747--7763, 2020.

\bibitem[Baevski \& Auli(2019)Baevski and Auli]{baevski2018adaptive}
Baevski, A. and Auli, M.
\newblock Adaptive input representations for neural language modeling.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Barrault et~al.(2019)Barrault, Bojar, Costa-juss{\`a}, Federmann,
  Fishel, Graham, Haddow, Huck, Koehn, Malmasi, Monz, M{\"u}ller, Pal, Post,
  and Zampieri]{barrault-etal-2019-findings}
Barrault, L., Bojar, O., Costa-juss{\`a}, M.~R., Federmann, C., Fishel, M.,
  Graham, Y., Haddow, B., Huck, M., Koehn, P., Malmasi, S., Monz, C.,
  M{\"u}ller, M., Pal, S., Post, M., and Zampieri, M.
\newblock Findings of the 2019 conference on machine translation ({WMT}19).
\newblock In \emph{Proceedings of the Fourth Conference on Machine Translation
  (Volume 2: Shared Task Papers, Day 1)}, pp.\  1--61, Florence, Italy, August
  2019. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/W19-5301}.
\newblock URL \url{https://aclanthology.org/W19-5301}.

\bibitem[Borgeaud et~al.(2021)Borgeaud, Mensch, Hoffmann, Cai, Rutherford,
  Millican, Driessche, Lespiau, Damoc, Clark, et~al.]{borgeaud2021improving}
Borgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K.,
  Driessche, G. v.~d., Lespiau, J.-B., Damoc, B., Clark, A., et~al.
\newblock Improving language models by retrieving from trillions of tokens.
\newblock \emph{arXiv preprint arXiv:2112.04426}, 2021.

\bibitem[Chen et~al.(2018)Chen, Wang, Li, Ren, Li, Zhu, Li, Liu, Zhang, and
  Wang]{chen18sptag}
Chen, Q., Wang, H., Li, M., Ren, G., Li, S., Zhu, J., Li, J., Liu, C., Zhang,
  L., and Wang, J.
\newblock \emph{SPTAG: A library for fast approximate nearest neighbor search},
  2018.
\newblock URL \url{https://github.com/Microsoft/SPTAG}.

\bibitem[Giles et~al.(1992)Giles, Miller, Chen, Chen, Sun, and
  Lee]{giles1992learning}
Giles, C.~L., Miller, C.~B., Chen, D., Chen, H.-H., Sun, G.-Z., and Lee, Y.-C.
\newblock Learning and extracting finite state automata with second-order
  recurrent neural networks.
\newblock \emph{Neural Computation}, 4\penalty0 (3):\penalty0 393--405, 1992.

\bibitem[Grave et~al.(2017)Grave, Cisse, and Joulin]{grave2017unbounded}
Grave, E., Cisse, M.~M., and Joulin, A.
\newblock Unbounded cache model for online language modeling with open
  vocabulary.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Gu et~al.(2018)Gu, Wang, Cho, and Li]{gu2018search}
Gu, J., Wang, Y., Cho, K., and Li, V.~O.
\newblock Search engine guided neural machine translation.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~32, 2018.

\bibitem[Guo et~al.(2020)Guo, Sun, Lindgren, Geng, Simcha, Chern, and
  Kumar]{guo2020accelerating}
Guo, R., Sun, P., Lindgren, E., Geng, Q., Simcha, D., Chern, F., and Kumar, S.
\newblock Accelerating large-scale inference with anisotropic vector
  quantization.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  3887--3896. PMLR, 2020.

\bibitem[Guu et~al.(2018)Guu, Hashimoto, Oren, and Liang]{guu2018generating}
Guu, K., Hashimoto, T.~B., Oren, Y., and Liang, P.
\newblock Generating sentences by editing prototypes.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  6:\penalty0 437--450, 2018.

\bibitem[Guu et~al.(2020)Guu, Lee, Tung, Pasupat, and Chang]{guu2020realm}
Guu, K., Lee, K., Tung, Z., Pasupat, P., and Chang, M.-W.
\newblock {REALM}: Retrieval-augmented language model pre-training.
\newblock \emph{arXiv preprint arXiv:2002.08909}, 2020.

\bibitem[Hashimoto et~al.(2018)Hashimoto, Guu, Oren, and
  Liang]{hashimoto2018retrieve}
Hashimoto, T.~B., Guu, K., Oren, Y., and Liang, P.
\newblock A retrieve-and-edit framework for predicting structured outputs.
\newblock In \emph{Proceedings of the 32nd International Conference on Neural
  Information Processing Systems}, pp.\  10073--10083, 2018.

\bibitem[Hayati et~al.(2018)Hayati, Olivier, Avvaru, Yin, Tomasic, and
  Neubig]{hayati2018retrieval}
Hayati, S.~A., Olivier, R., Avvaru, P., Yin, P., Tomasic, A., and Neubig, G.
\newblock Retrieval-based neural code generation.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  925--930, 2018.

\bibitem[He et~al.(2020)He, Berg-Kirkpatrick, and Neubig]{he2020learning}
He, J., Berg-Kirkpatrick, T., and Neubig, G.
\newblock Learning sparse prototypes for text generation.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[He et~al.(2021)He, Neubig, and Berg-Kirkpatrick]{he2021efficient}
He, J., Neubig, G., and Berg-Kirkpatrick, T.
\newblock Efficient nearest neighbor language models.
\newblock In \emph{Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  5703--5714, 2021.

\bibitem[Jiang et~al.(2021)Jiang, Wang, Cao, Cheng, Huang, and
  Li]{jiang2021learning}
Jiang, Q., Wang, M., Cao, J., Cheng, S., Huang, S., and Li, L.
\newblock Learning kernel-smoothed machine translation with retrieved examples.
\newblock In \emph{Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  7280--7290, 2021.

\bibitem[Johnson et~al.(2019)Johnson, Douze, and J{\'e}gou]{johnson2019billion}
Johnson, J., Douze, M., and J{\'e}gou, H.
\newblock Billion-scale similarity search with gpus.
\newblock \emph{IEEE Transactions on Big Data}, 2019.

\bibitem[Joulin et~al.(2017)Joulin, Ciss{\'e}, Grangier, J{\'e}gou,
  et~al.]{joulin2017efficient}
Joulin, A., Ciss{\'e}, M., Grangier, D., J{\'e}gou, H., et~al.
\newblock Efficient softmax approximation for gpus.
\newblock In \emph{International conference on machine learning}, pp.\
  1302--1310. PMLR, 2017.

\bibitem[Karpukhin et~al.(2020)Karpukhin, Oguz, Min, Lewis, Wu, Edunov, Chen,
  and Yih]{karpukhin2020dense}
Karpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., and
  Yih, W.-t.
\newblock Dense passage retrieval for open-domain question answering.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pp.\  6769--6781, 2020.

\bibitem[Khandelwal et~al.(2020)Khandelwal, Levy, Jurafsky, Zettlemoyer, and
  Lewis]{khandelwal2020generalization}
Khandelwal, U., Levy, O., Jurafsky, D., Zettlemoyer, L., and Lewis, M.
\newblock Generalization through memorization: Nearest neighbor language
  models.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=HklBjCEKvH}.

\bibitem[Khandelwal et~al.(2021)Khandelwal, Fan, Jurafsky, Zettlemoyer, and
  Lewis]{khandelwal2021nearest}
Khandelwal, U., Fan, A., Jurafsky, D., Zettlemoyer, L., and Lewis, M.
\newblock Nearest neighbor machine translation.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=7wCBOfJ8hJM}.

\bibitem[Koehn \& Knowles(2017)Koehn and Knowles]{koehn2017six}
Koehn, P. and Knowles, R.
\newblock Six challenges for neural machine translation.
\newblock In \emph{Proceedings of the First Workshop on Neural Machine
  Translation}, pp.\  28--39, 2017.

\bibitem[Lin et~al.(2019)Lin, Zhu, Gormley, and Eisner]{lin2019neural}
Lin, C.-C., Zhu, H., Gormley, M.~R., and Eisner, J.
\newblock Neural finite-state transducers: Beyond rational relations.
\newblock In \emph{Proceedings of the 2019 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pp.\  272--283, 2019.

\bibitem[Meng et~al.(2022)Meng, Zong, Li, Sun, Zhang, Wu, and
  Li]{meng2022gnnlm}
Meng, Y., Zong, S., Li, X., Sun, X., Zhang, T., Wu, F., and Li, J.
\newblock {GNN}-{LM}: Language modeling based on global contexts via {GNN}.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=BS49l-B5Bql}.

\bibitem[Merity et~al.(2017)Merity, Xiong, Bradbury, and
  Socher]{merity2016pointer}
Merity, S., Xiong, C., Bradbury, J., and Socher, R.
\newblock Pointer sentinel mixture models.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Neubig \& Dyer(2016)Neubig and Dyer]{neubig2016generalizing}
Neubig, G. and Dyer, C.
\newblock Generalizing and hybridizing count-based and neural language models.
\newblock In \emph{Proceedings of the 2016 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  1163--1172, 2016.

\bibitem[Ng et~al.(2019)Ng, Yee, Baevski, Ott, Auli, and
  Edunov]{ng2019facebook}
Ng, N., Yee, K., Baevski, A., Ott, M., Auli, M., and Edunov, S.
\newblock Facebook fair’s wmt19 news translation task submission.
\newblock In \emph{Proceedings of the Fourth Conference on Machine Translation
  (Volume 2: Shared Task Papers, Day 1)}, pp.\  314--319, 2019.

\bibitem[Omlin \& Giles(1996)Omlin and Giles]{omlin1996extraction}
Omlin, C.~W. and Giles, C.~L.
\newblock Extraction of rules from discrete-time recurrent neural networks.
\newblock \emph{Neural networks}, 9\penalty0 (1):\penalty0 41--52, 1996.

\bibitem[Peng et~al.(2018)Peng, Schwartz, Thomson, and Smith]{peng2018rational}
Peng, H., Schwartz, R., Thomson, S., and Smith, N.~A.
\newblock Rational recurrences.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  1203--1214, 2018.

\bibitem[Ram et~al.(2021)Ram, Shachaf, Levy, Berant, and
  Globerson]{ram2021learning}
Ram, O., Shachaf, G., Levy, O., Berant, J., and Globerson, A.
\newblock Learning to retrieve passages without supervision.
\newblock \emph{arXiv preprint arXiv:2112.07708}, 2021.

\bibitem[Rastogi et~al.(2016)Rastogi, Cotterell, and
  Eisner]{rastogi2016weighting}
Rastogi, P., Cotterell, R., and Eisner, J.
\newblock Weighting finite-state transductions with neural context.
\newblock In \emph{Proceedings of the 2016 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pp.\  623--633, 2016.

\bibitem[Rijhwani et~al.(2021)Rijhwani, Rosenblum, Anastasopoulos, and
  Neubig]{rijhwani2021lexically}
Rijhwani, S., Rosenblum, D., Anastasopoulos, A., and Neubig, G.
\newblock Lexically-aware semi-supervised learning for ocr post-correction.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  9:\penalty0 1285--1302, 2021.

\bibitem[Rubin et~al.(2021)Rubin, Herzig, and Berant]{rubin2021learning}
Rubin, O., Herzig, J., and Berant, J.
\newblock Learning to retrieve prompts for in-context learning.
\newblock \emph{arXiv preprint arXiv:2112.08633}, 2021.

\bibitem[Schwartz et~al.(2018)Schwartz, Thomson, and
  Smith]{schwartz2018bridging}
Schwartz, R., Thomson, S., and Smith, N.~A.
\newblock Bridging cnns, rnns, and weighted finite-state machines.
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pp.\  295--305, 2018.

\bibitem[Sennrich et~al.(2016)Sennrich, Haddow, and Birch]{sennrich2016neural}
Sennrich, R., Haddow, B., and Birch, A.
\newblock Neural machine translation of rare words with subword units.
\newblock In \emph{Proceedings of the 54th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pp.\  1715--1725,
  2016.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  6000--6010, 2017.

\bibitem[Weiss et~al.(2018)Weiss, Goldberg, and Yahav]{weiss2018extracting}
Weiss, G., Goldberg, Y., and Yahav, E.
\newblock Extracting automata from recurrent neural networks using queries and
  counterexamples.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5247--5256. PMLR, 2018.

\bibitem[Weiss et~al.(2019)Weiss, Goldberg, and Yahav]{weiss2019learning}
Weiss, G., Goldberg, Y., and Yahav, E.
\newblock Learning deterministic weighted automata with queries and
  counterexamples.
\newblock \emph{Advances in Neural Information Processing Systems},
  32:\penalty0 8560--8571, 2019.

\bibitem[Xu et~al.(2021)Xu, He, Neubig, and Hellendoorn]{xu2021capturing}
Xu, F.~F., He, J., Neubig, G., and Hellendoorn, V.~J.
\newblock Capturing structural locality in non-parametric language models.
\newblock \emph{arXiv preprint arXiv:2110.02870}, 2021.

\bibitem[Yogatama et~al.(2021)Yogatama, de~Masson~d’Autume, and
  Kong]{yogatama2021adaptive}
Yogatama, D., de~Masson~d’Autume, C., and Kong, L.
\newblock Adaptive semiparametric language models.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  9:\penalty0 362--373, 2021.

\bibitem[Zhang et~al.(2018)Zhang, Utiyama, Sumita, Neubig, and
  Nakamura]{zhang2018guiding}
Zhang, J., Utiyama, M., Sumita, E., Neubig, G., and Nakamura, S.
\newblock Guiding neural machine translation with retrieved translation pieces.
\newblock In \emph{Proceedings of the 2018 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long Papers)}, pp.\  1325--1335, 2018.

\end{thebibliography}
