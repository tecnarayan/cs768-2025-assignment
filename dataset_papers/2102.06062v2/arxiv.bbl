\begin{thebibliography}{105}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.(2015)Abadi, Agarwal, Barham, Brevdo, Chen, Citro,
  Corrado, Davis, Dean, Devin, Ghemawat, Goodfellow, Harp, Irving, Isard, Jia,
  Jozefowicz, Kaiser, Kudlur, Levenberg, Man\'{e}, Monga, Moore, Murray, Olah,
  Schuster, Shlens, Steiner, Sutskever, Talwar, Tucker, Vanhoucke, Vasudevan,
  Vi\'{e}gas, Vinyals, Warden, Wattenberg, Wicke, Yu, and
  Zheng]{tensorflow2015-whitepaper}
M.~Abadi, A.~Agarwal, P.~Barham, E.~Brevdo, Z.~Chen, C.~Citro, G.~S. Corrado,
  A.~Davis, J.~Dean, M.~Devin, S.~Ghemawat, I.~Goodfellow, A.~Harp, G.~Irving,
  M.~Isard, Y.~Jia, R.~Jozefowicz, L.~Kaiser, M.~Kudlur, J.~Levenberg,
  D.~Man\'{e}, R.~Monga, S.~Moore, D.~Murray, C.~Olah, M.~Schuster, J.~Shlens,
  B.~Steiner, I.~Sutskever, K.~Talwar, P.~Tucker, V.~Vanhoucke, V.~Vasudevan,
  F.~Vi\'{e}gas, O.~Vinyals, P.~Warden, M.~Wattenberg, M.~Wicke, Y.~Yu, and
  X.~Zheng.
\newblock {TensorFlow}: Large-scale machine learning on heterogeneous systems,
  2015.
\newblock Software available from \url{tensorflow.org}.

\bibitem[Abadi et~al.(2016)Abadi, Chu, Goodfellow, McMahan, Mironov, Talwar,
  and Zhang]{abadi2016deep}
M.~Abadi, A.~Chu, I.~Goodfellow, H.~B. McMahan, I.~Mironov, K.~Talwar, and
  L.~Zhang.
\newblock Deep learning with differential privacy.
\newblock In \emph{CCS}, pages 308--318, 2016.

\bibitem[Abowd(2018)]{abowd2018us}
J.~M. Abowd.
\newblock The {US Census Bureau} adopts differential privacy.
\newblock In \emph{KDD}, pages 2867--2867, 2018.

\bibitem[Acharya et~al.(2020)Acharya, Bonawitz, Kairouz, Ramage, and
  Sun]{acharya2020context}
J.~Acharya, K.~Bonawitz, P.~Kairouz, D.~Ramage, and Z.~Sun.
\newblock Context aware local differential privacy.
\newblock In \emph{ICML}, pages 52--62, 2020.

\bibitem[Agarwal and Ganichev(2019)]{agarwal2019auto}
A.~Agarwal and I.~Ganichev.
\newblock Auto-vectorizing tensorflow graphs: Jacobians, auto-batching and
  beyond.
\newblock \emph{arXiv:1903.04243}, 2019.

\bibitem[Agarwal et~al.(2009)Agarwal, Bartlett, Ravikumar, and
  Wainwright]{agarwal_information_2009}
A.~Agarwal, P.~Bartlett, P.~Ravikumar, and M.~J. Wainwright.
\newblock Information-theoretic lower bounds on the oracle complexity of convex
  optimization.
\newblock In \emph{NIPS}, page 1â€“9, 2009.

\bibitem[Alon et~al.(2019)Alon, Livni, Malliaris, and Moran]{AlonLMM19}
N.~Alon, R.~Livni, M.~Malliaris, and S.~Moran.
\newblock Private {PAC} learning implies finite {L}ittlestone dimension.
\newblock In \emph{STOC}, pages 852--860, 2019.

\bibitem[Anderson(2021)]{MaskedLARK21}
E.~Anderson.
\newblock Masked learning, aggregation and reporting workflow (masked lark).
\newblock
  \url{https://github.com/WICG/privacy-preserving-ads/blob/main/MaskedLARK.md},
  2021.

\bibitem[{Apple Differential Privacy Team}(2017)]{dp2017learning}
{Apple Differential Privacy Team}.
\newblock Learning with privacy at scale.
\newblock \emph{Apple Machine Learning Journal}, 2017.

\bibitem[Bassily et~al.(2014)Bassily, Smith, and
  Thakurta]{bassily-private-2014}
R.~Bassily, A.~Smith, and A.~Thakurta.
\newblock Private empirical risk minimization: Efficient algorithms and tight
  error bounds.
\newblock In \emph{FOCS}, pages 464--473, 2014.

\bibitem[Bassily et~al.(2019{\natexlab{a}})Bassily, Feldman, Talwar, and
  Thakurta]{bassily-sco-arxiv}
R.~Bassily, V.~Feldman, K.~Talwar, and A.~Thakurta.
\newblock Private stochastic convex optimization with optimal rates.
\newblock \emph{arXiv:1908.09970}, 2019{\natexlab{a}}.

\bibitem[Bassily et~al.(2019{\natexlab{b}})Bassily, Feldman, Talwar, and
  Thakurta]{BassilyFTT19}
R.~Bassily, V.~Feldman, K.~Talwar, and A.~G. Thakurta.
\newblock Private stochastic convex optimization with optimal rates.
\newblock In \emph{NeurIPS}, pages 11279--11288, 2019{\natexlab{b}}.

\bibitem[Beimel et~al.(2016)Beimel, Nissim, and Stemmer]{beimel2013private}
A.~Beimel, K.~Nissim, and U.~Stemmer.
\newblock Private learning and sanitization: Pure vs. approximate differential
  privacy.
\newblock \emph{ToC}, 12(1):\penalty0 1--61, 2016.

\bibitem[Bousquet et~al.(2003)Bousquet, Boucheron, and
  Lugosi]{bousquet2003introduction}
O.~Bousquet, S.~Boucheron, and G.~Lugosi.
\newblock Introduction to statistical learning theory.
\newblock In \emph{Summer School on Machine Learning}, pages 169--207.
  Springer, 2003.

\bibitem[Bu et~al.(2020)Bu, Dong, Long, and Su]{gaussiandp}
Z.~Bu, J.~Dong, Q.~Long, and W.~J. Su.
\newblock Deep learning with {G}aussian differential privacy.
\newblock \emph{Harvard Data Science Review}, 2020\penalty0 (23), 2020.

\bibitem[Caron et~al.(2021)Caron, Touvron, Misra, J{\'e}gou, Mairal,
  Bojanowski, and Joulin]{caron2021emerging}
M.~Caron, H.~Touvron, I.~Misra, H.~J{\'e}gou, J.~Mairal, P.~Bojanowski, and
  A.~Joulin.
\newblock Emerging properties in self-supervised vision transformers.
\newblock \emph{arXiv:2104.14294}, 2021.

\bibitem[Chan et~al.(2012)Chan, Shi, and Song]{chan2012optimal}
T.~H. Chan, E.~Shi, and D.~Song.
\newblock Optimal lower bound for differentially private multi-party
  aggregation.
\newblock In \emph{ESA}, pages 277--288, 2012.

\bibitem[Chaudhuri and Hsu(2011)]{chaudhuri2011sample}
K.~Chaudhuri and D.~Hsu.
\newblock Sample complexity bounds for differentially private learning.
\newblock In \emph{COLT}, pages 155--186, 2011.

\bibitem[Chaudhuri et~al.(2011)Chaudhuri, Monteleoni, and
  Sarwate]{chaudhuri2011differentially}
K.~Chaudhuri, C.~Monteleoni, and A.~D. Sarwate.
\newblock Differentially private empirical risk minimization.
\newblock \emph{JMLR}, 12\penalty0 (3), 2011.

\bibitem[Chen and Lee(2020)]{9378011}
C.~Chen and J.~Lee.
\newblock Stochastic adaptive line search for differentially private
  optimization.
\newblock In \emph{Big Data}, pages 1011--1020, 2020.

\bibitem[Chen et~al.(2019)Chen, Liao, Chen, and Zhang]{chen2019understanding}
P.~Chen, B.~Liao, G.~Chen, and S.~Zhang.
\newblock Understanding and utilizing deep neural networks trained with noisy
  labels.
\newblock In \emph{ICML}, pages 1062--1070, 2019.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Kornblith, Norouzi, and
  Hinton]{chen2020simple}
T.~Chen, S.~Kornblith, M.~Norouzi, and G.~Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{ICML}, pages 1597--1607, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Kornblith, Swersky, Norouzi, and
  Hinton]{chen2020big}
T.~Chen, S.~Kornblith, K.~Swersky, M.~Norouzi, and G.~Hinton.
\newblock Big self-supervised models are strong semi-supervised learners.
\newblock In \emph{NeurIPS}, 2020{\natexlab{b}}.

\bibitem[Cheu et~al.(2019)Cheu, Smith, Ullman, Zeber, and
  Zhilyaev]{cheu2019distributed}
A.~Cheu, A.~Smith, J.~Ullman, D.~Zeber, and M.~Zhilyaev.
\newblock Distributed differential privacy via shuffling.
\newblock In \emph{EUROCRYPT}, pages 375--403, 2019.

\bibitem[Clanuwat et~al.(2018)Clanuwat, Bober-Irizar, Kitamoto, Lamb, Yamamoto,
  and Ha]{kmnist}
T.~Clanuwat, M.~Bober-Irizar, A.~Kitamoto, A.~Lamb, K.~Yamamoto, and D.~Ha.
\newblock Deep learning for classical {J}apanese literature.
\newblock \emph{arXiv:1812.01718}, 2018.

\bibitem[Dangel et~al.(2019)Dangel, Kunstner, and Hennig]{dangel2019backpack}
F.~Dangel, F.~Kunstner, and P.~Hennig.
\newblock Backpack: Packing more into backprop.
\newblock \emph{arXiv:1912.10985}, 2019.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
J.~Deng, W.~Dong, R.~Socher, L.-J. Li, K.~Li, and L.~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{CVPR}, pages 248--255, 2009.

\bibitem[DeVries and Taylor(2017)]{devries2017improved}
T.~DeVries and G.~W. Taylor.
\newblock Improved regularization of convolutional neural networks with cutout.
\newblock \emph{arXiv:1708.04552}, 2017.

\bibitem[Ding et~al.(2017)Ding, Kulkarni, and Yekhanin]{ding2017collecting}
B.~Ding, J.~Kulkarni, and S.~Yekhanin.
\newblock Collecting telemetry data privately.
\newblock In \emph{NIPS}, pages 3571--3580, 2017.

\bibitem[Duchi et~al.(2013)Duchi, Jordan, and Wainwright]{duchi2013local}
J.~C. Duchi, M.~I. Jordan, and M.~J. Wainwright.
\newblock Local privacy and minimax bounds: sharp rates for probability
  estimation.
\newblock In \emph{NIPS}, pages 1529--1537, 2013.

\bibitem[Duchi et~al.(2018)Duchi, Jordan, and Wainwright]{duchi_minimax}
J.~C. Duchi, M.~I. Jordan, and M.~J. Wainwright.
\newblock Minimax optimal procedures for locally private estimation.
\newblock \emph{JASA}, 113\penalty0 (521):\penalty0 182--201, 2018.

\bibitem[Dwork and Roth(2014)]{dwork2014algorithmic}
C.~Dwork and A.~Roth.
\newblock The algorithmic foundations of differential privacy.
\newblock \emph{Foundations and Trends in Theoretical Computer Science},
  9\penalty0 (3-4):\penalty0 211--407, 2014.

\bibitem[Dwork et~al.(2006{\natexlab{a}})Dwork, Kenthapadi, McSherry, Mironov,
  and Naor]{DworkKMMN06}
C.~Dwork, K.~Kenthapadi, F.~McSherry, I.~Mironov, and M.~Naor.
\newblock Our data, ourselves: Privacy via distributed noise generation.
\newblock In \emph{EUROCRYPT}, pages 486--503, 2006{\natexlab{a}}.

\bibitem[Dwork et~al.(2006{\natexlab{b}})Dwork, McSherry, Nissim, and
  Smith]{DworkMNS06}
C.~Dwork, F.~McSherry, K.~Nissim, and A.~D. Smith.
\newblock Calibrating noise to sensitivity in private data analysis.
\newblock In \emph{TCC}, pages 265--284, 2006{\natexlab{b}}.

\bibitem[Erlingsson et~al.(2014)Erlingsson, Pihur, and
  Korolova]{erlingsson2014rappor}
{\'U}.~Erlingsson, V.~Pihur, and A.~Korolova.
\newblock Rappor: Randomized aggregatable privacy-preserving ordinal response.
\newblock In \emph{CCS}, pages 1054--1067, 2014.

\bibitem[Erlingsson et~al.(2019)Erlingsson, Feldman, Mironov, Raghunathan,
  Talwar, and Thakurta]{erlingsson2019amplification}
{\'U}.~Erlingsson, V.~Feldman, I.~Mironov, A.~Raghunathan, K.~Talwar, and
  A.~Thakurta.
\newblock Amplification by shuffling: From local to central differential
  privacy via anonymity.
\newblock In \emph{SODA}, pages 2468--2479, 2019.

\bibitem[Esfandiari et~al.(2021)Esfandiari, Mirrokni, Syed, and
  Vassilvitskii]{esfandiari2021label}
H.~Esfandiari, V.~Mirrokni, U.~Syed, and S.~Vassilvitskii.
\newblock Label differential privacy via clustering.
\newblock \emph{arXiv:2110.02159}, 2021.

\bibitem[Evfimievski et~al.(2003)Evfimievski, Gehrke, and
  Srikant]{evfimievski2003limiting}
A.~Evfimievski, J.~Gehrke, and R.~Srikant.
\newblock Limiting privacy breaches in privacy preserving data mining.
\newblock In \emph{PODS}, pages 211--222, 2003.

\bibitem[Feldman and Zrnic(2020)]{feldman2020individual}
V.~Feldman and T.~Zrnic.
\newblock Individual privacy accounting via a {R}\'{e}nyi filter.
\newblock \emph{arXiv:2008.11193}, 2020.

\bibitem[Feldman et~al.(2020)Feldman, Koren, and Talwar]{bassily_private_2020}
V.~Feldman, T.~Koren, and K.~Talwar.
\newblock Private stochastic convex optimization: Optimal rates in linear time.
\newblock In \emph{STOC}, page 439â€“449, 2020.

\bibitem[Ghosh et~al.(2012)Ghosh, Roughgarden, and Sundararajan]{GhoshRS12}
A.~Ghosh, T.~Roughgarden, and M.~Sundararajan.
\newblock Universally utility-maximizing privacy mechanisms.
\newblock \emph{SICOMP}, 41\penalty0 (6):\penalty0 1673--1693, 2012.

\bibitem[Goodfellow(2015)]{goodfellow2015efficient}
I.~Goodfellow.
\newblock Efficient per-example gradient computations.
\newblock \emph{arXiv:1510.01799}, 2015.

\bibitem[Greenberg(2016)]{greenberg2016apple}
A.~Greenberg.
\newblock {Apple's} ``differential privacy'' is about collecting your data --
  but not your data.
\newblock \emph{Wired, June}, 13, 2016.

\bibitem[Grill et~al.(2020)Grill, Strub, Altch{\'e}, Tallec, Richemond,
  Buchatskaya, Doersch, Pires, Guo, Azar, et~al.]{grill2020bootstrap}
J.-B. Grill, F.~Strub, F.~Altch{\'e}, C.~Tallec, P.~H. Richemond,
  E.~Buchatskaya, C.~Doersch, B.~A. Pires, Z.~D. Guo, M.~G. Azar, et~al.
\newblock Bootstrap your own latent: A new approach to self-supervised
  learning.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Gupta et~al.(2010)Gupta, Ligett, McSherry, Roth, and
  Talwar]{gupta2010differentially}
A.~Gupta, K.~Ligett, F.~McSherry, A.~Roth, and K.~Talwar.
\newblock Differentially private combinatorial optimization.
\newblock In \emph{SODA}, pages 1106--1125, 2010.

\bibitem[Han et~al.(2018)Han, Yao, Yu, Niu, Xu, Hu, Tsang, and
  Sugiyama]{han2018co}
B.~Han, Q.~Yao, X.~Yu, G.~Niu, M.~Xu, W.~Hu, I.~Tsang, and M.~Sugiyama.
\newblock Co-teaching: Robust training of deep neural networks with extremely
  noisy labels.
\newblock In \emph{NeurIPS}, pages 8527--8537, 2018.

\bibitem[Han et~al.(2020)Han, Niu, Yu, Yao, Xu, Tsang, and
  Sugiyama]{han2020sigua}
B.~Han, G.~Niu, X.~Yu, Q.~Yao, M.~Xu, I.~W. Tsang, and M.~Sugiyama.
\newblock Sigua: Forgetting may make learning with noisy labels more robust.
\newblock In \emph{ICML}, pages 4006--4016, 2020.

\bibitem[Hardt and Talwar(2010)]{HardtT10}
M.~Hardt and K.~Talwar.
\newblock On the geometry of differential privacy.
\newblock In \emph{STOC}, pages 705--714, 2010.

\bibitem[Harper and Konstan(2015)]{MovieLens}
F.~M. Harper and J.~A. Konstan.
\newblock The {MovieLens} datasets: History and context.
\newblock \emph{ACM Trans. Interact. Intell. Syst.}, 5\penalty0 (4), 2015.

\bibitem[Harutyunyan et~al.(2020)Harutyunyan, Reing, Steeg, and
  Galstyan]{harutyunyan2020improving}
H.~Harutyunyan, K.~Reing, G.~V. Steeg, and A.~Galstyan.
\newblock Improving generalization by controlling label-noise information in
  neural network weights.
\newblock In \emph{ICML}, pages 4071--4081, 2020.

\bibitem[He et~al.(2016{\natexlab{a}})He, Zhang, Ren, and Sun]{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{CVPR}, pages 770--778, 2016{\natexlab{a}}.

\bibitem[He et~al.(2016{\natexlab{b}})He, Zhang, Ren, and Sun]{he2016identity}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Identity mappings in deep residual networks.
\newblock In \emph{ECCV}, pages 630--645, 2016{\natexlab{b}}.

\bibitem[He et~al.(2020)He, Fan, Wu, Xie, and Girshick]{he2020momentum}
K.~He, H.~Fan, Y.~Wu, S.~Xie, and R.~Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{CVPR}, pages 9729--9738, 2020.

\bibitem[He et~al.(2017)He, Liao, Zhang, Nie, Hu, and Chua]{he2017neural}
X.~He, L.~Liao, H.~Zhang, L.~Nie, X.~Hu, and T.-S. Chua.
\newblock Neural collaborative filtering.
\newblock In \emph{WWW}, pages 173--182, 2017.

\bibitem[Hu et~al.(2020)Hu, Li, and Yu]{hu2019simple}
W.~Hu, Z.~Li, and D.~Yu.
\newblock Simple and effective regularization methods for training on noisily
  labeled data with generalization guarantee.
\newblock In \emph{ICLR}, 2020.

\bibitem[Jiang et~al.(2020)Jiang, Huang, Liu, and Yang]{jiang2020beyond}
L.~Jiang, D.~Huang, M.~Liu, and W.~Yang.
\newblock Beyond synthetic noise: Deep learning on controlled noisy labels.
\newblock In \emph{ICML}, pages 4804--4815, 2020.

\bibitem[Kairouz et~al.(2016)Kairouz, Bonawitz, and
  Ramage]{kairouz2016discrete}
P.~Kairouz, K.~Bonawitz, and D.~Ramage.
\newblock Discrete distribution estimation under local privacy.
\newblock In \emph{ICML}, pages 2436--2444, 2016.

\bibitem[Kasiviswanathan et~al.(2011)Kasiviswanathan, Lee, Nissim,
  Raskhodnikova, and Smith]{kasiviswanathan2011can}
S.~P. Kasiviswanathan, H.~K. Lee, K.~Nissim, S.~Raskhodnikova, and A.~Smith.
\newblock What can we learn privately?
\newblock \emph{SICOMP}, 40\penalty0 (3):\penalty0 793--826, 2011.

\bibitem[Kifer et~al.(2012)Kifer, Smith, and Thakurta]{kifer_private_2012}
D.~Kifer, A.~Smith, and A.~Thakurta.
\newblock Private convex empirical risk minimization and high-dimensional
  regression.
\newblock In \emph{COLT}, pages 25.1--25.40, 2012.

\bibitem[Krizhevsky(2009)]{cifar}
A.~Krizhevsky.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical Report TR-2009, University of Toronto, 2009.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and Haffner]{mnist}
Y.~LeCun, L.~Bottou, Y.~Bengio, and P.~Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Ledoux and Talagrand(2013)]{ledoux2013probability}
M.~Ledoux and M.~Talagrand.
\newblock \emph{Probability in Banach Spaces: Isoperimetry and Processes}.
\newblock Springer Science \& Business Media, 2013.

\bibitem[Liu et~al.(2021)Liu, Vietri, Steinke, Ullman, and
  Wu]{liu2021leveraging}
T.~Liu, G.~Vietri, T.~Steinke, J.~Ullman, and Z.~S. Wu.
\newblock Leveraging public data for practical private query release.
\newblock In \emph{ICML}, 2021.

\bibitem[Lukasik et~al.(2020)Lukasik, Bhojanapalli, Menon, and
  Kumar]{lukasik2020does}
M.~Lukasik, S.~Bhojanapalli, A.~K. Menon, and S.~Kumar.
\newblock Does label smoothing mitigate label noise?
\newblock In \emph{ICML}, pages 6448--6458, 2020.

\bibitem[Ma et~al.(2020)Ma, Huang, Wang, Romano, Erfani, and
  Bailey]{ma2020normalized}
X.~Ma, H.~Huang, Y.~Wang, S.~Romano, S.~Erfani, and J.~Bailey.
\newblock Normalized loss functions for deep learning with noisy labels.
\newblock In \emph{ICML}, pages 6543--6553, 2020.

\bibitem[Malek et~al.(2021)Malek, Mironov, Prasad, Shilov, and
  Tram{\`e}r]{malek2021antipodes}
M.~Malek, I.~Mironov, K.~Prasad, I.~Shilov, and F.~Tram{\`e}r.
\newblock Antipodes of label differential privacy: {PATE and ALIBI}.
\newblock In \emph{NeurIPS}, 2021.

\bibitem[McMahan et~al.(2018)McMahan, Ramage, Talwar, and
  Zhang]{mcmahan2017learning}
H.~B. McMahan, D.~Ramage, K.~Talwar, and L.~Zhang.
\newblock Learning differentially private recurrent language models.
\newblock In \emph{ICLR}, 2018.

\bibitem[McSherry(2010)]{McSherry10}
F.~McSherry.
\newblock Privacy integrated queries: an extensible platform for
  privacy-preserving data analysis.
\newblock \emph{CACM}, 53\penalty0 (9):\penalty0 89--97, 2010.

\bibitem[Menon et~al.(2019)Menon, Rawat, Reddi, and Kumar]{menon2019can}
A.~K. Menon, A.~S. Rawat, S.~J. Reddi, and S.~Kumar.
\newblock Can gradient clipping mitigate label noise?
\newblock In \emph{ICLR}, 2019.

\bibitem[Nalpas and Dutton(2020)]{chrome-blog-post}
M.~Nalpas and S.~Dutton.
\newblock {A more private way to measure ad conversions, the Event Conversion
  Measurement API}, October 2020.
\newblock
  \url{https://web.dev/conversion-measurement/#how-this-api-preserves-user-privacy}.

\bibitem[Nasr et~al.(2020)Nasr, Shokri, et~al.]{nasr2020improving}
M.~Nasr, R.~Shokri, et~al.
\newblock Improving deep learning with differential privacy using gradient
  encoding and denoising.
\newblock \emph{arXiv:2007.11524}, 2020.

\bibitem[Natarajan et~al.(2013)Natarajan, Dhillon, Ravikumar, and
  Tewari]{natarajan2013learning}
N.~Natarajan, I.~S. Dhillon, P.~Ravikumar, and A.~Tewari.
\newblock Learning with noisy labels.
\newblock In \emph{NIPS}, volume~26, pages 1196--1204, 2013.

\bibitem[Nemirovsky and Yudin(1983)]{nemirovsky_problem_1983}
A.~S. Nemirovsky and D.~B. Yudin.
\newblock \emph{Problem Complexity and Method Efficiency in Optimization}.
\newblock Wiley, Chichester, 1983.

\bibitem[Nguyen et~al.(2019)Nguyen, Mummadi, Ngo, Nguyen, Beggel, and
  Brox]{nguyen2019self}
D.~T. Nguyen, C.~K. Mummadi, T.~P.~N. Ngo, T.~H.~P. Nguyen, L.~Beggel, and
  T.~Brox.
\newblock Self: Learning to filter noisy labels with self-ensembling.
\newblock In \emph{ICLR}, 2019.

\bibitem[Papernot et~al.(2017)Papernot, Abadi, Erlingsson, Goodfellow, and
  Talwar]{papernot2016semi}
N.~Papernot, M.~Abadi, U.~Erlingsson, I.~Goodfellow, and K.~Talwar.
\newblock Semi-supervised knowledge transfer for deep learning from private
  training data.
\newblock In \emph{ICLR}, 2017.

\bibitem[Papernot et~al.(2018)Papernot, Song, Mironov, Raghunathan, Talwar, and
  Erlingsson]{papernot2018scalable}
N.~Papernot, S.~Song, I.~Mironov, A.~Raghunathan, K.~Talwar, and
  {\'U}.~Erlingsson.
\newblock Scalable private learning with {PATE}.
\newblock In \emph{ICLR}, 2018.

\bibitem[Papernot et~al.(2021)Papernot, Thakurta, Song, Chien, and
  Erlingsson]{papernot2020tempered}
N.~Papernot, A.~Thakurta, S.~Song, S.~Chien, and {\'U}.~Erlingsson.
\newblock Tempered sigmoid activations for deep learning with differential
  privacy.
\newblock In \emph{AAAI}, 2021.

\bibitem[Phan et~al.(2020)Phan, Thai, Hu, Jin, Sun, and Dou]{phan2020scalable}
H.~Phan, M.~T. Thai, H.~Hu, R.~Jin, T.~Sun, and D.~Dou.
\newblock Scalable differential privacy with certified robustness in
  adversarial learning.
\newblock In \emph{ICML}, pages 7683--7694, 2020.

\bibitem[Pleiss et~al.(2020)Pleiss, Zhang, Elenberg, and
  Weinberger]{pleiss2020identifying}
G.~Pleiss, T.~Zhang, E.~R. Elenberg, and K.~Q. Weinberger.
\newblock Identifying mislabeled data using the area under the margin ranking.
\newblock In \emph{ICML}, 2020.

\bibitem[Radebaugh and Erlingsson(2019)]{tf-privacy}
C.~Radebaugh and U.~Erlingsson.
\newblock {Introducing TensorFlow Privacy: Learning with Differential Privacy
  for Training Data}, March 2019.
\newblock \url{blog.tensorflow.org}.

\bibitem[Shamir and Zhang(2013)]{shamir-stochastic-2013}
O.~Shamir and T.~Zhang.
\newblock Stochastic gradient descent for non-smooth optimization: Convergence
  results and optimal averaging schemes.
\newblock In \emph{ICML}, page Iâ€“71â€“Iâ€“79, 2013.

\bibitem[Shankland(2014)]{CNET2014Google}
S.~Shankland.
\newblock How {Google} tricks itself to protect {Chrome} user privacy.
\newblock \emph{CNET, October}, 2014.

\bibitem[Shokri and Shmatikov(2015)]{shokri2015privacy}
R.~Shokri and V.~Shmatikov.
\newblock Privacy-preserving deep learning.
\newblock In \emph{CCS}, pages 1310--1321, 2015.

\bibitem[Smith et~al.(2018)Smith, {\'A}lvarez, Zwiessele, and
  Lawrence]{Smith2018DifferentiallyPR}
M.~T. Smith, M.~A. {\'A}lvarez, M.~Zwiessele, and N.~Lawrence.
\newblock Differentially private regression with {G}aussian processes.
\newblock In \emph{AISTATS}, 2018.

\bibitem[Smith et~al.(2019)Smith, {\'A}lvarez, and
  Lawrence]{Smith2019DifferentiallyPR}
M.~T. Smith, M.~A. {\'A}lvarez, and N.~Lawrence.
\newblock Differentially private regression and classification with sparse
  {G}aussian processes.
\newblock \emph{arXiv:1909.09147}, 2019.

\bibitem[Song et~al.(2019)Song, Kim, Park, and Lee]{song2019prestopping}
H.~Song, M.~Kim, D.~Park, and J.-G. Lee.
\newblock Prestopping: How does early stopping help generalization against
  label noise?
\newblock \emph{arXiv:1911.08059}, 2019.

\bibitem[Song et~al.(2020)Song, Kim, Park, and Lee]{song2020learning}
H.~Song, M.~Kim, D.~Park, and J.-G. Lee.
\newblock Learning from noisy labels with deep neural networks: A survey.
\newblock \emph{arXiv:2007.08199}, 2020.

\bibitem[Song et~al.(2013)Song, Chaudhuri, and Sarwate]{song2013stochastic}
S.~Song, K.~Chaudhuri, and A.~D. Sarwate.
\newblock Stochastic gradient descent with differentially private updates.
\newblock In \emph{GlobalSIP}, pages 245--248, 2013.

\bibitem[Steinke and Ullman(2016)]{SteinkeU16}
T.~Steinke and J.~Ullman.
\newblock Between pure and approximate differential privacy.
\newblock \emph{J. Priv. Confidentiality}, 7\penalty0 (2), 2016.

\bibitem[Subramani et~al.(2020)Subramani, Vadivelu, and
  Kamath]{subramani2020enabling}
P.~Subramani, N.~Vadivelu, and G.~Kamath.
\newblock Enabling fast differentially private {SGD} via just-in-time
  compilation and vectorization.
\newblock In \emph{PPML}, 2020.

\bibitem[Szegedy et~al.(2015)Szegedy, Liu, Jia, Sermanet, Reed, Anguelov,
  Erhan, Vanhoucke, and Rabinovich]{szegedy2015going}
C.~Szegedy, W.~Liu, Y.~Jia, P.~Sermanet, S.~Reed, D.~Anguelov, D.~Erhan,
  V.~Vanhoucke, and A.~Rabinovich.
\newblock Going deeper with convolutions.
\newblock In \emph{CVPR}, pages 1--9, 2015.

\bibitem[Testuggine and Mironov(2020)]{pytorch-privacy}
D.~Testuggine and I.~Mironov.
\newblock {PyTorch Differential Privacy Series Part 1: DP-SGD Algorithm
  Explained}, August 2020.
\newblock \url{medium.com}.

\bibitem[Tram{\`e}r and Boneh(2021)]{tramer2020differentially}
F.~Tram{\`e}r and D.~Boneh.
\newblock Differentially private learning needs better features (or much more
  data).
\newblock In \emph{ICLR}, 2021.

\bibitem[Wang and Xu(2019)]{wang2019sparse}
D.~Wang and J.~Xu.
\newblock On sparse linear regression in the local differential privacy model.
\newblock In \emph{ICML}, pages 6628--6637, 2019.

\bibitem[Wang et~al.(2017)Wang, Ye, and Xu]{wang_differentially_2017}
D.~Wang, M.~Ye, and J.~Xu.
\newblock Differentially private empirical risk minimization revisited: Faster
  and more general.
\newblock In \emph{NIPS}, pages 2719--2728, 2017.

\bibitem[Warner(1965)]{warner1965randomized}
S.~L. Warner.
\newblock Randomized response: A survey technique for eliminating evasive
  answer bias.
\newblock \emph{JASA}, 60\penalty0 (309):\penalty0 63--69, 1965.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{fashionmnist}
H.~Xiao, K.~Rasul, and R.~Vollgraf.
\newblock {Fashion-MNIST}: a novel image dataset for benchmarking machine
  learning algorithms.
\newblock \emph{arXiv:1708.07747}, 2017.

\bibitem[Yu et~al.(2019{\natexlab{a}})Yu, Liu, Pu, Gursoy, and
  Truex]{yu2019differentially}
L.~Yu, L.~Liu, C.~Pu, M.~E. Gursoy, and S.~Truex.
\newblock Differentially private model publishing for deep learning.
\newblock In \emph{S \& P}, pages 332--349, 2019{\natexlab{a}}.

\bibitem[Yu et~al.(2019{\natexlab{b}})Yu, Han, Yao, Niu, Tsang, and
  Sugiyama]{yu2019does}
X.~Yu, B.~Han, J.~Yao, G.~Niu, I.~W. Tsang, and M.~Sugiyama.
\newblock How does disagreement help generalization against label corruption?
\newblock In \emph{ICML}, pages 7164--7173, 2019{\natexlab{b}}.

\bibitem[Yuan et~al.(2021)Yuan, Shen, Mironov, and
  Nascimento]{yuan2021practical}
S.~Yuan, M.~Shen, I.~Mironov, and A.~C. Nascimento.
\newblock Practical, label private deep learning training based on secure
  multiparty computation and differential privacy.
\newblock \emph{Cryptology ePrint Archive}, 2021.

\bibitem[Zhang et~al.(2018)Zhang, Cisse, Dauphin, and
  Lopez-Paz]{zhang2017mixup}
H.~Zhang, M.~Cisse, Y.~N. Dauphin, and D.~Lopez-Paz.
\newblock Mixup: Beyond empirical risk minimization.
\newblock In \emph{ICLR}, 2018.

\bibitem[Zhang et~al.(2012)Zhang, Zhang, Xiao, Yang, and
  Winslett]{zhang2012functional}
J.~Zhang, Z.~Zhang, X.~Xiao, Y.~Yang, and M.~Winslett.
\newblock Functional mechanism: regression analysis under differential privacy.
\newblock \emph{VLDB}, 5\penalty0 (11):\penalty0 1364--1375, 2012.

\bibitem[Zhang et~al.(2017)Zhang, Zheng, Mou, and Wang]{zhang_efficient_2017}
J.~Zhang, K.~Zheng, W.~Mou, and L.~Wang.
\newblock Efficient private {ERM} for smooth objectives.
\newblock In \emph{IJCAI}, pages 3922--3928, 2017.

\bibitem[Zhang and Sabuncu(2018)]{zhang2018generalized}
Z.~Zhang and M.~Sabuncu.
\newblock Generalized cross entropy loss for training deep neural networks with
  noisy labels.
\newblock In \emph{NeurIPS}, pages 8778--8788, 2018.

\bibitem[Zheng et~al.(2020)Zheng, Wu, Goswami, Goswami, Metaxas, and
  Chen]{zhengerror}
S.~Zheng, P.~Wu, A.~Goswami, M.~Goswami, D.~Metaxas, and C.~Chen.
\newblock Error-bounded correction of noisy labels.
\newblock In \emph{ICML}, pages 11447--11457, 2020.

\end{thebibliography}
