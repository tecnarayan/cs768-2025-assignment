\begin{thebibliography}{10}

\bibitem{ba2016layer}
J.~L. Ba, J.~R. Kiros, and G.~E. Hinton.
\newblock Layer normalization.
\newblock {\em arXiv}, 1607.06450, 2016.
\newblock \url{http://arxiv.org/abs/1607.06450}.

\bibitem{baars1993cognitive}
B.~J. Baars.
\newblock {\em A cognitive theory of consciousness}.
\newblock Cambridge University Press, 1993.

\bibitem{baars2002conscious}
B.~J. Baars.
\newblock The conscious access hypothesis: origins and recent evidence.
\newblock {\em Trends in cognitive sciences}, 6(1):47--52, 2002.

\bibitem{bahdanau2014neural}
D.~Bahdanau, K.~Cho, and Y.~Bengio.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock {\em arXiv}, 1409.0473, 2014.
\newblock \url{https://arxiv.org/abs/1409.0473}.

\bibitem{barrow1977parametric}
H.~G. Barrow, J.~M. Tenenbaum, R.~C. Bolles, and H.~C. Wolf.
\newblock Parametric correspondence and {Chamfer} matching: 2 new techniques
  for image matching.
\newblock Technical report, SRI International Menlo Park CA Artificial
  Intelligence Center, 1977.

\bibitem{bellemare2017distributional}
M.~G. Bellemare, W.~Dabney, and R.~Munos.
\newblock A distributional perspective on reinforcement learning.
\newblock {\em International Conference on Machine Learning}, 2017.
\newblock \url{https://arxiv.org/abs/1707.06887}.

\bibitem{bengio2017consciousness}
Y.~Bengio.
\newblock The consciousness prior.
\newblock {\em arXiv}, 1709.08568, 2017.
\newblock \url{http://arxiv.org/abs/1709.08568}.

\bibitem{borgefors1988hierarchical}
G.~Borgefors.
\newblock Hierarchical chamfer matching: A parametric edge matching algorithm.
\newblock {\em IEEE Transactions on pattern analysis and machine intelligence},
  10(6):849--865, 1988.

\bibitem{carion2020end}
N.~Carion, F.~Massa, G.~Synnaeve, N.~Usunier, A.~Kirillov, and S.~Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock {\em European Conference on Computer Vision}, 2020.
\newblock \url{https://arxiv.org/abs/2005.12872}.

\bibitem{chevalier2018babyai}
M.~Chevalier-Boisvert, D.~Bahdanau, S.~Lahlou, L.~Willems, C.~Saharia, T.~H.
  Nguyen, and Y.~Bengio.
\newblock Babyai: A platform to study the sample efficiency of grounded
  language learning.
\newblock {\em International Conference on Learning Representations}, 2018.
\newblock \url{http://arxiv.org/abs/1810.08272}.

\bibitem{chevalierboisvert2018minigrid}
M.~Chevalier-Boisvert, L.~Willems, and S.~Pal.
\newblock Minimalistic gridworld environment for openai gym.
\newblock {\em GitHub repository}, 2018.
\newblock \url{https://github.com/maximecb/gym-minigrid}.

\bibitem{conant1970every}
R.~C. Conant and W.~Ross~Ashby.
\newblock Every good regulator of a system must be a model of that system.
\newblock {\em International Journal of Systems Science}, 1(2):89--97, 1970.

\bibitem{davidson2020investigating}
G.~Davidson and B.~M. Lake.
\newblock Investigating simple object representations in model-free deep
  reinforcement learning.
\newblock {\em arXiv}, 2002.06703, 2020.
\newblock \url{https://arxiv.org/abs/2002.06703}.

\bibitem{dehane2017consciousness}
S.~Dehaene, H.~Lau, and S.~Kouider.
\newblock What is consciousness, and could machines have it?
\newblock {\em Science}, 358, 2020.
\newblock \url{https://science.sciencemag.org/content/358/6362/486}.

\bibitem{goyal2020inductive}
A.~Goyal and Y.~Bengio.
\newblock Inductive biases for deep learning of higher-level cognition.
\newblock {\em arXiv}, 2011.15091, 2020.
\newblock \url{https://arxiv.org/abs/2011.15091}.

\bibitem{ha2018world}
D.~Ha and J.~Schmidhuber.
\newblock Recurrent world models facilitate policy evolution.
\newblock In {\em Conference on Neural Information Processing Systems},
  volume~31, 2018.
\newblock
  \url{https://papers.nips.cc/paper/2018/hash/2de5d16682c3c35007e4e92982f1a2ba-Abstract.html}.

\bibitem{hafner2020discrete}
D.~Hafner, T.~P. Lillicrap, M.~Norouzi, and J.~Ba.
\newblock Mastering {Atari} with discrete world models.
\newblock In {\em International Conference on Learning Representations}, 2021.
\newblock \url{https://arxiv.org/abs/2010.02193}.

\bibitem{hamrick2020role}
J.~B. Hamrick, A.~L. Friesen, F.~Behbahani, A.~Guez, F.~Viola, S.~Witherspoon,
  T.~Anthony, L.~Buesing, P.~Velickovic, and T.~Weber.
\newblock On the role of planning in model-based deep reinforcement learning.
\newblock {\em arXiv}, 2011.04021, 2020.
\newblock \url{https://arxiv.org/abs/2011.04021}.

\bibitem{hessel2017rainbow}
M.~Hessel, J.~Modayil, H.~van Hasselt, T.~Schaul, G.~Ostrovski, W.~Dabney,
  D.~Horgan, B.~Piot, M.~G. Azar, and D.~Silver.
\newblock Rainbow: Combining improvements in deep reinforcement learning.
\newblock {\em AAAI Conference on Artificial Intelligence}, 2017.
\newblock \url{http://arxiv.org/abs/1710.02298}.

\bibitem{horgan2018distributed}
D.~Horgan, J.~Quan, D.~Budden, G.~Barth{-}Maron, M.~Hessel, H.~van Hasselt, and
  D.~Silver.
\newblock Distributed prioritized experience replay.
\newblock {\em International Conference on Learning Representations}, 2018.
\newblock \url{http://arxiv.org/abs/1803.00933}.

\bibitem{hui2020babyai}
D.~Y.-T. Hui, M.~Chevalier-Boisvert, D.~Bahdanau, and Y.~Bengio.
\newblock Babyai 1.1.
\newblock {\em arXiv}, 2007.12770, 2020.
\newblock \url{http://arxiv.org/abs/2007.12770}.

\bibitem{jaderberg2016unreal}
M.~Jaderberg, V.~Mnih, W.~M. Czarnecki, T.~Schaul, J.~Z. Leibo, D.~Silver, and
  K.~Kavukcuoglu.
\newblock Reinforcement learning with unsupervised auxiliary tasks.
\newblock {\em International Conference on Representation Learning}, 2017.
\newblock \url{http://arxiv.org/abs/1611.05397}.

\bibitem{janner2019trust}
M.~Janner, J.~Fu, M.~Zhang, and S.~Levine.
\newblock When to trust your model: Model-based policy optimization.
\newblock {\em arXiv}, 1906.08253, 2019.
\newblock \url{http://arxiv.org/abs/1906.08253}.

\bibitem{kaiser2019model}
L.~Kaiser, M.~Babaeizadeh, P.~Milos, B.~Osinski, R.~H. Campbell, K.~Czechowski,
  D.~Erhan, C.~Finn, P.~Kozakowski, S.~Levine, et~al.
\newblock Model-based reinforcement learning for atari.
\newblock {\em arXiv}, 1903.00374, 2019.
\newblock \url{http://arxiv.org/abs/1903.00374}.

\bibitem{ke2018sparse}
N.~R. Ke, A.~Goyal, O.~Bilaniuk, J.~Binas, M.~C. Mozer, C.~Pal, and Y.~Bengio.
\newblock Sparse attentive backtracking: Temporal credit assignment through
  reminding.
\newblock {\em arXiv}, 1809.03702, 2018.
\newblock \url{http://arxiv.org/abs/1809.03702}.

\bibitem{khetarpal2021temporally}
K.~Khetarpal, Z.~Ahmed, G.~Comanici, and D.~Precup.
\newblock Temporally abstract partial models.
\newblock In {\em Conference on Neural Information Processing Systems}, 2021.
\newblock \url{http://arxiv.org/abs/2108.03213}.

\bibitem{kingma2014adam}
D.~P. Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em International Conference on Learning Representations}, 2014.
\newblock \url{http://arxiv.org/abs/1412.6980}.

\bibitem{kosiorek2020conditional}
A.~R. Kosiorek, H.~Kim, and D.~J. Rezende.
\newblock Conditional set generation with transformers.
\newblock {\em arXiv}, 2006.16841, 2020.
\newblock \url{http://arxiv.org/abs/2006.16841}.

\bibitem{lowe2020contrasting}
S.~L{\"{o}}we, K.~Greff, R.~Jonschkowski, A.~Dosovitskiy, and T.~Kipf.
\newblock Learning object-centric video models by contrasting sets.
\newblock {\em arXiv}, 2011.10287, 2020.
\newblock \url{https://arxiv.org/abs/2011.10287}.

\bibitem{mnih2015human}
V.~Mnih, K.~Kavukcuoglu, D.~Silver, A.~A. Rusu, J.~Veness, M.~G. Bellemare,
  A.~Graves, M.~Riedmiller, A.~K. Fidjeland, G.~Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock {\em nature}, 518(7540):529--533, 2015.
\newblock \url{https://www.nature.com/articles/nature14236}.

\bibitem{moerland2020model}
T.~M. Moerland, J.~Broekens, and C.~M. Jonker.
\newblock Model-based reinforcement learning: A survey.
\newblock {\em arXiv}, 2006.16712, 2020.
\newblock \url{http://arxiv.org/abs/2006.16712}.

\bibitem{mu2020refactoring}
T.~Mu, J.~Gu, Z.~Jia, H.~Tang, and H.~Su.
\newblock Refactoring policy for compositional generalizability using
  self-supervised object proposals.
\newblock In {\em Conference on Neural Information Processing Systems},
  volume~33, 2020.
\newblock \url{https://arxiv.org/abs/2011.00971}.

\bibitem{porada2021modeling}
I.~Porada, K.~Suleman, A.~Trischler, and J.~C.~K. Cheung.
\newblock Modeling event plausibility with consistent conceptual abstraction.
\newblock In {\em Conference of the North American Chapter of the Association
  for Computational Linguistics: Human Language Technologies}, pages
  1732--1743, 2021.
\newblock \url{https://arxiv.org/abs/2104.10247}.

\bibitem{rao2009survey}
A.~V. Rao.
\newblock A survey of numerical methods for optimal control.
\newblock {\em Advances in the Astronautical Sciences}, 135(1):497--528, 2009.

\bibitem{richards2005robust}
A.~G. Richards.
\newblock {\em Robust constrained model predictive control}.
\newblock PhD thesis, Massachusetts Institute of Technology, 2005.
\newblock \url{https://dspace.mit.edu/handle/1721.1/28914}.

\bibitem{schrittwieser2020mastering}
J.~Schrittwieser, I.~Antonoglou, T.~Hubert, K.~Simonyan, L.~Sifre, S.~Schmitt,
  A.~Guez, E.~Lockhart, D.~Hassabis, T.~Graepel, et~al.
\newblock Mastering {Atari}, {Go}, {Chess} and {Shogi} by planning with a
  learned model.
\newblock {\em Nature}, 588(7839):604--609, 2020.
\newblock \url{https://arxiv.org/abs/1911.08265}.

\bibitem{silver2016mastering}
D.~Silver, A.~Huang, C.~J. Maddison, A.~Guez, L.~Sifre, G.~Van Den~Driessche,
  J.~Schrittwieser, I.~Antonoglou, V.~Panneershelvam, M.~Lanctot, et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock {\em Nature}, 529(7587):484--489, 2016.
\newblock \url{https://www.nature.com/articles/nature16961}.

\bibitem{silver2017mastering}
D.~Silver, J.~Schrittwieser, K.~Simonyan, I.~Antonoglou, A.~Huang, A.~Guez,
  T.~Hubert, L.~Baker, M.~Lai, A.~Bolton, et~al.
\newblock Mastering the game of go without human knowledge.
\newblock {\em Nature}, 550(7676):354--359, 2017.
\newblock \url{https://www.nature.com/articles/nature24270}.

\bibitem{silver2016predictron}
D.~Silver, H.~van Hasselt, M.~Hessel, T.~Schaul, A.~Guez, T.~Harley,
  G.~Dulac{-}Arnold, D.~P. Reichert, N.~C. Rabinowitz, A.~Barreto, and
  T.~Degris.
\newblock The predictron: End-to-end learning and planning.
\newblock {\em International Conference on Machine Learning}, 2016.
\newblock \url{http://arxiv.org/abs/1612.08810}.

\bibitem{sutton1991dyna}
R.~S. Sutton.
\newblock Dyna, an integrated architecture for learning, planning, and
  reacting.
\newblock {\em SIGART Bulletin}, 2(4):160â€“163, 1991.
\newblock \url{https://dl.acm.org/doi/10.1145/122344.122377}.

\bibitem{sutton2018reinforcement}
R.~S. Sutton and A.~G. Barto.
\newblock {\em Reinforcement learning: An introduction}.
\newblock MIT press, 2018.
\newblock \url{http://incompleteideas.net/book/the-book-2nd.html}.

\bibitem{talvitie2008simple}
E.~Talvitie and S.~Singh.
\newblock Simple local models for complex dynamical systems.
\newblock In {\em Conference on Neural Information Processing Systems},
  volume~21, pages 1617--1624. Citeseer, 2008.
\newblock
  \url{https://papers.nips.cc/paper/2008/hash/f76a89f0cb91bc419542ce9fa43902dc-Abstract.html}.

\bibitem{vangulick2004consciousness}
R.~van Gulick.
\newblock Consciousness.
\newblock In E.~N. Zalta, editor, {\em Stanford Encyclopedia of Philosophy}.
  Stanford: Metaphysics Research Lab, 2004.

\bibitem{hasselt2015double}
H.~van Hasselt, A.~Guez, and D.~Silver.
\newblock Deep reinforcement learning with double q-learning.
\newblock {\em AAAI Conference on Artificial Intelligence}, 2015.
\newblock \url{http://arxiv.org/abs/1509.06461}.

\bibitem{vaswani2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  L.~Kaiser, and I.~Polosukhin.
\newblock Attention is all you need.
\newblock {\em International Conference on Neural Information Processing
  Systems}, 2017.
\newblock \url{https://arxiv.org/abs/1706.03762}.

\bibitem{vinyals2019grandmaster}
O.~Vinyals, I.~Babuschkin, W.~M. Czarnecki, M.~Mathieu, A.~Dudzik, J.~Chung,
  D.~H. Choi, R.~Powell, T.~Ewalds, P.~Georgiev, et~al.
\newblock Grandmaster level in {StarCraft II} using multi-agent reinforcement
  learning.
\newblock {\em Nature}, 575(7782):350--354, 2019.
\newblock \url{https://www.nature.com/articles/s41586-019-1724-z}.

\bibitem{wang2018nervenet}
T.~Wang, R.~Liao, J.~Ba, and S.~Fidler.
\newblock Nervenet: Learning structured policy with graph neural networks.
\newblock In {\em International Conference on Learning Representations}, 2018.
\newblock \url{https://openreview.net/forum?id=S1sqHMZCb}.

\bibitem{wang2018leap}
X.~Wang, W.~Xiong, H.~Wang, and W.~Y. Wang.
\newblock Look before you leap: Bridging model-free and model-based
  reinforcement learning for planned-ahead vision-and-language navigation.
\newblock In {\em European Conference on Computer Vision}, 2018.
\newblock \url{http://arxiv.org/abs/1803.07729}.

\bibitem{xie2019differentiable}
S.~M. Xie and S.~Ermon.
\newblock Differentiable subset sampling.
\newblock In {\em International Joint Conference on Artificial Intelligence},
  2019.
\newblock \url{https://arxiv.org/abs/1901.10517}.

\bibitem{zaheer2017sets}
M.~Zaheer, S.~Kottur, S.~Ravanbhakhsh, B.~P{\'o}czos, R.~Salakhutdinov, and
  A.~J. Smola.
\newblock Deep sets.
\newblock {\em Conference on Neural Information Processing Systems}, 2017.
\newblock \url{https://arxiv.org/abs/1703.06114}.

\bibitem{zakharov2020episodic}
A.~Zakharov, M.~Crosby, and Z.~Fountas.
\newblock Episodic memory for learning subjective-timescale models.
\newblock {\em arXiv}, 2010.01430, 2020.
\newblock \url{http://arxiv.org/abs/2010.01430}.

\end{thebibliography}
