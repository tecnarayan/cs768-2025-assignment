\begin{thebibliography}{46}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal(2013)]{agarwal2013selective}
Alekh Agarwal.
\newblock Selective sampling algorithms for cost-sensitive multiclass
  prediction.
\newblock In \emph{International Conference on Machine Learning}, 2013.

\bibitem[Agarwal et~al.(2014)Agarwal, Hsu, Kale, Langford, Li, and
  Schapire]{agarwal2014taming}
Alekh Agarwal, Daniel Hsu, Satyen Kale, John Langford, Lihong Li, and Robert~E.
  Schapire.
\newblock Taming the monster: A fast and simple algorithm for contextual
  bandits.
\newblock In \emph{International Conference on Machine Learning}, 2014.

\bibitem[Arora et~al.(2012)Arora, Hazan, and Kale]{arora2012multiplicative}
Sanjeev Arora, Elad Hazan, and Satyen Kale.
\newblock The multiplicative weights update method: a meta-algorithm and
  applications.
\newblock \emph{Theory of Computing}, 2012.

\bibitem[Balcan and Long(2013)]{balcan2013active}
Maria~Florina Balcan and Philip~M. Long.
\newblock Active and passive learning of linear separators under log-concave
  distributions.
\newblock In \emph{Conference on Learning Theory}, 2013.

\bibitem[Balcan et~al.(2006)Balcan, Beygelzimer, and
  Langford]{balcan2006agnostic}
Maria~Florina Balcan, Alina Beygelzimer, and John Langford.
\newblock Agnostic active learning.
\newblock In \emph{International Conference on Machine Learning}, 2006.

\bibitem[Balcan et~al.(2007)Balcan, Broder, and Zhang]{balcan2007margin}
Maria~Florina Balcan, Andrei Broder, and Tong Zhang.
\newblock Margin based active learning.
\newblock In \emph{Conference on Learning Theory}, 2007.

\bibitem[Beygelzimer et~al.(2009)Beygelzimer, Dasgupta, and
  Langford]{BeygelDL09}
Alina Beygelzimer, Sanjoy Dasgupta, and John Langford.
\newblock Importance weighted active learning.
\newblock In \emph{International Conference on Machine Learning}, 2009.

\bibitem[Beygelzimer et~al.(2010)Beygelzimer, Hsu, Langford, and
  Zhang]{BeygelHLZ10}
Alina Beygelzimer, Daniel Hsu, John Langford, and Tong Zhang.
\newblock Agnostic active learning without constraints.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2010.

\bibitem[Carpentier et~al.(2017)Carpentier, Locatelli, and
  Kpotufe]{carpentier2017adaptivity}
Alexandra Carpentier, Andrea Locatelli, and Samory Kpotufe.
\newblock Adaptivity to noise parameters in nonparametric active learning.
\newblock In \emph{Conference on Learning Theory}, 2017.

\bibitem[Castro and Nowak(2008)]{Castro2008}
R.M. Castro and R.D. Nowak.
\newblock Minimax bounds for active learning.
\newblock \emph{Transaction on Information Theory}, 2008.

\bibitem[Castro et~al.(2005)Castro, Willett, and Nowak]{castro2005faster}
Rui Castro, Rebecca Willett, and Robert~D. Nowak.
\newblock Faster rates in regression via active learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2005.

\bibitem[Cavallanti et~al.(2011)Cavallanti, Cesa-Bianchi, and
  Gentile]{Cavallanti2011}
Giovanni Cavallanti, Nicolo Cesa-Bianchi, and Claudio Gentile.
\newblock Learning noisy linear classifiers via adaptive and selective
  sampling.
\newblock \emph{Machine Learning}, 2011.

\bibitem[Chang et~al.(2015)Chang, Krishnamurthy, Agarwal, Daum\'e~III, and
  Langford]{chang2015learning}
Kai-Wei Chang, Akshay Krishnamurthy, Alekh Agarwal, Hal Daum\'e~III, and John
  Langford.
\newblock Learning to search better than your teacher.
\newblock In \emph{International Conference on Machine Learning}, 2015.

\bibitem[Dasgupta et~al.(2007)Dasgupta, Hsu, and Monteleoni]{DasguptaHM07}
Sanjoy Dasgupta, Daniel Hsu, and Claire Monteleoni.
\newblock A general agnostic active learning algorithm.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2007.

\bibitem[{Daum\'e III} et~al.(2009){Daum\'e III}, Langford, and
  Marcu]{daume09searn}
Hal {Daum\'e III}, John Langford, and Daniel Marcu.
\newblock Search-based structured prediction.
\newblock \emph{Machine Learning}, 2009.

\bibitem[Dekel et~al.(2010)Dekel, Gentile, and Sridharan]{Dekel2010}
Ofer Dekel, Claudio Gentile, and Karthik Sridharan.
\newblock Robust selective sampling from single and multiple teachers.
\newblock In \emph{Conference on Learning Theory}, 2010.

\bibitem[Duchi et~al.(2010)Duchi, Hazan, and Singer]{adagrad}
John Duchi, Elad Hazan, and Yoram Singer.
\newblock Adaptive subgradient methods for online learning and stochastic
  optimization.
\newblock In \emph{Conference on Learning Theory}, 2010.

\bibitem[Foster et~al.(2018)Foster, Agarwal, Dudik, Luo, and
  Schapire]{foster2018practical}
Dylan Foster, Alekh Agarwal, Miroslav Dudik, Haipeng Luo, and Robert Schapire.
\newblock Practical contextual bandits with regression oracles.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Hanneke(2014)]{Hanneke2014}
Steve Hanneke.
\newblock Theory of disagreement-based active learning.
\newblock \emph{Foundations and Trends in Machine Learning}, 2014.

\bibitem[Hanneke and Yang(2012)]{hanneke2012surrogate}
Steve Hanneke and Liu Yang.
\newblock Surrogate losses in passive and active learning.
\newblock \emph{arXiv:1207.3772}, 2012.

\bibitem[Hanneke and Yang(2015)]{hanneke2015minimax}
Steve Hanneke and Liu Yang.
\newblock Minimax analysis of active learning.
\newblock \emph{Journal of Machine Learning Research}, 2015.

\bibitem[Haussler(1995)]{haussler1995sphere}
David Haussler.
\newblock {Sphere packing numbers for subsets of the Boolean n-cube with
  bounded Vapnik-Chervonenkis dimension}.
\newblock \emph{Journal of Combinatorial Theory, Series A}, 1995.

\bibitem[Hsu(2010)]{hsu2010algorithms}
Daniel Hsu.
\newblock \emph{Algorithms for Active Learning}.
\newblock PhD thesis, University of California at San Diego, 2010.

\bibitem[Huang et~al.(2015)Huang, Agarwal, Hsu, Langford, and
  Schapire]{huang2015efficient}
Tzu-Kuo Huang, Alekh Agarwal, Daniel Hsu, John Langford, and Robert~E.
  Schapire.
\newblock Efficient and parsimonious agnostic active learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2015.

\bibitem[Karampatziakis and Langford(2011)]{invariant}
Nikos Karampatziakis and John Langford.
\newblock Online importance weight aware updates.
\newblock In \emph{Uncertainty in Artificial Intelligence}, 2011.

\bibitem[Krishnamurthy et~al.(2017)Krishnamurthy, Agarwal, Huang, Daum{\'e},
  and Langford]{krishnamurthy2017active}
Akshay Krishnamurthy, Alekh Agarwal, Tzu-Kuo Huang, Hal Daum{\'e}, III, and
  John Langford.
\newblock Active learning for cost-sensitive classification.
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Langford and Beygelzimer(2005)]{langford2005sensitive}
John Langford and Alina Beygelzimer.
\newblock Sensitive error correcting output codes.
\newblock In \emph{Conference on Learning Theory}, 2005.

\bibitem[Lewis et~al.(2004)Lewis, Yang, Rose, and Li]{lewis2004rcv1}
David~D. Lewis, Yiming Yang, Tony~G. Rose, and Fan Li.
\newblock Rcv1: A new benchmark collection for text categorization research.
\newblock \emph{Journal of Machine Learning Research}, 2004.
\newblock Data available at
  \url{http://www.jmlr.org/papers/volume5/lewis04a/lyrl2004_rcv1v2_README.htm}.

\bibitem[Liang et~al.(2015)Liang, Rakhlin, and Sridharan]{liang2015learning}
Tengyuan Liang, Alexander Rakhlin, and Karthik Sridharan.
\newblock Learning with square loss: Localization through offset rademacher
  complexity.
\newblock In \emph{Conference on Learning Theory}, 2015.

\bibitem[Mammen and Tsybakov(1999)]{mammen1999smooth}
Enno Mammen and Alexandre~B. Tsybakov.
\newblock Smooth discrimination analysis.
\newblock \emph{The Annals of Statistics}, 1999.

\bibitem[Massart and N{\'e}d{\'e}lec(2006)]{massart2006risk}
Pascal Massart and {\'E}lodie N{\'e}d{\'e}lec.
\newblock Risk bounds for statistical learning.
\newblock \emph{The Annals of Statistics}, 2006.

\bibitem[Minsker(2012)]{Minsker2012plug}
Stanislav Minsker.
\newblock Plug-in approach to active learning.
\newblock \emph{Journal of Machine Learning Research}, 2012.

\bibitem[Orabona and Cesa-Bianchi(2011)]{Orabona2011}
Francesco Orabona and Nicolo Cesa-Bianchi.
\newblock Better algorithms for selective sampling.
\newblock In \emph{International Conference on Machine Learning}, 2011.

\bibitem[Plotkin et~al.(1995)Plotkin, Shmoys, and Tardos]{plotkin1995fast}
Serge~A. Plotkin, David~B. Shmoys, and {\'E}va Tardos.
\newblock Fast approximation algorithms for fractional packing and covering
  problems.
\newblock \emph{Mathematics of Operations Research}, 1995.

\bibitem[Rakhlin and Sridharan(2017)]{rakhlin2017equivalence}
Alexander Rakhlin and Karthik Sridharan.
\newblock On equivalence of martingale tail bounds and deterministic regret
  inequalities.
\newblock In \emph{Proceedings of the 2017 Conference on Learning Theory},
  2017.

\bibitem[Rakhlin et~al.(2017)Rakhlin, Sridharan, Tsybakov,
  et~al.]{rakhlin2017empirical}
Alexander Rakhlin, Karthik Sridharan, Alexandre~B Tsybakov, et~al.
\newblock Empirical entropy, minimax regret and minimax risk.
\newblock \emph{Bernoulli}, 2017.

\bibitem[Ross and Bagnell(2014)]{ross2014reinforcement}
Stephane Ross and J.~Andrew Bagnell.
\newblock Reinforcement and imitation learning via interactive no-regret
  learning.
\newblock \emph{arXiv:1406.5979}, 2014.

\bibitem[Ross et~al.(2013)Ross, Mineiro, and Langford]{normalized}
Stephane Ross, Paul Mineiro, and John Langford.
\newblock Normalized online learning.
\newblock In \emph{Uncertainty in Artificial Intelligence}, 2013.

\bibitem[Settles(2012)]{settles2012active}
Burr Settles.
\newblock Active learning.
\newblock \emph{Synthesis Lectures on Artificial Intelligence and Machine
  Learning}, 2012.

\bibitem[Shi et~al.(2015)Shi, Steinhardt, and Liang]{shi15sampling}
Tianlian Shi, Jacob Steinhardt, and Percy Liang.
\newblock Learning where to sample in structured prediction.
\newblock In \emph{Artificial Intelligence and Statistics}, 2015.

\bibitem[Silla~Jr. and Freitas(2011)]{silla2011survey}
Carlos~N. Silla~Jr. and Alex~A. Freitas.
\newblock A survey of hierarchical classification across different application
  domains.
\newblock \emph{Data Mining and Knowledge Discovery}, 2011.

\bibitem[Sun et~al.(2017)Sun, Venkatraman, Gordon, Boots, and
  Bagnell]{sun2017deeply}
Wen Sun, Arun Venkatraman, Geoffrey~J. Gordon, Byron Boots, and J.~Andrew
  Bagnell.
\newblock Deeply {A}ggre{V}a{T}e{D}: Differentiable imitation learning for
  sequential prediction.
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Syrgkanis et~al.(2016)Syrgkanis, Krishnamurthy, and
  Schapire]{syrgkanis2016}
Vasilis Syrgkanis, Akshay Krishnamurthy, and Robert~E. Schapire.
\newblock Efficient algorithms for adversarial contextual learning.
\newblock In \emph{International Conference on Machine Learning}, 2016.

\bibitem[Szegedy et~al.(2015)Szegedy, Liu, Jia, Sermanet, Reed, Anguelov,
  Erhan, Vanhoucke, and Rabinovich]{Inception15}
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott~E. Reed,
  Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich.
\newblock Going deeper with convolutions.
\newblock In \emph{Computer Vision and Pattern Recognition}, 2015.

\bibitem[Tsybakov(2004)]{tsybakov2004optimal}
Alexandre~B. Tsybakov.
\newblock Optimal aggregation of classifiers in statistical learning.
\newblock \emph{Annals of Statistics}, 2004.

\bibitem[Zhang and Chaudhuri(2014)]{zhang2014beyond}
Chicheng Zhang and Kamalika Chaudhuri.
\newblock Beyond disagreement-based agnostic active learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2014.

\end{thebibliography}
