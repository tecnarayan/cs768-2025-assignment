\begin{thebibliography}{30}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahmadi and Majumdar(2017)]{ahmadi2017dsos}
A.~A. Ahmadi and A.~Majumdar.
\newblock {DSOS} and {SDSOS} optimization: more tractable alternatives to sum
  of squares and semidefinite optimization.
\newblock \emph{arXiv preprint arXiv:1706.02586}, 2017.

\bibitem[Athalye and Sutskever(2017)]{athalye2017synthesizing}
A.~Athalye and I.~Sutskever.
\newblock Synthesizing robust adversarial examples.
\newblock \emph{arXiv preprint arXiv:1707.07397}, 2017.

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and
  Wagner]{athalye2018obfuscated}
A.~Athalye, N.~Carlini, and D.~Wagner.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock \emph{arXiv preprint arXiv:1802.00420}, 2018.

\bibitem[Brown et~al.(2017)Brown, Mané, Roy, Abadi, and
  Gilmer]{brown2017adversarial}
T.~B. Brown, D.~Mané, A.~Roy, M.~Abadi, and J.~Gilmer.
\newblock Adversarial patch.
\newblock \emph{arXiv preprint arXiv:1712.09665}, 2017.

\bibitem[Carlini and Wagner(2017)]{carlini2017towards}
N.~Carlini and D.~Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{IEEE Symposium on Security and Privacy}, pages 39--57, 2017.

\bibitem[Carlini et~al.(2016)Carlini, Mishra, Vaidya, Zhang, Sherr, Shields,
  Wagner, and Zhou]{carlini2016hidden}
N.~Carlini, P.~Mishra, T.~Vaidya, Y.~Zhang, M.~Sherr, C.~Shields, D.~Wagner,
  and W.~Zhou.
\newblock Hidden voice commands.
\newblock In \emph{USENIX Security}, 2016.

\bibitem[Carlini et~al.(2017)Carlini, Katz, Barrett, and
  Dill]{carlini2017ground}
N.~Carlini, G.~Katz, C.~Barrett, and D.~L. Dill.
\newblock Ground-truth adversarial examples.
\newblock \emph{arXiv}, 2017.

\bibitem[Dvijotham et~al.(2018{\natexlab{a}})Dvijotham, Gowal, Stanforth,
  Arandjelovic, O'Donoghue, Uesato, and Kohli]{dvijotham2018training}
K.~Dvijotham, S.~Gowal, R.~Stanforth, R.~Arandjelovic, B.~O'Donoghue,
  J.~Uesato, and P.~Kohli.
\newblock Training verified learners with learned verifiers.
\newblock \emph{arXiv preprint arXiv:1805.10265}, 2018{\natexlab{a}}.

\bibitem[Dvijotham et~al.(2018{\natexlab{b}})Dvijotham, Stanforth, Gowal, Mann,
  and Kohli]{dvijotham2018dual}
K.~Dvijotham, R.~Stanforth, S.~Gowal, T.~Mann, and P.~Kohli.
\newblock A dual approach to scalable verification of deep networks.
\newblock \emph{arXiv preprint arXiv:1803.06567}, 2018{\natexlab{b}}.

\bibitem[Ehlers(2017)]{ehlers2017formal}
R.~Ehlers.
\newblock Formal verification of piece-wise linear feed-forward neural
  networks.
\newblock In \emph{International Symposium on Automated Technology for
  Verification and Analysis (ATVA)}, pages 269--286, 2017.

\bibitem[Evtimov et~al.(2017)Evtimov, Eykholt, Fernandes, Kohno, Li, Prakash,
  Rahmati, and Song]{evtimov2017robust}
I.~Evtimov, K.~Eykholt, E.~Fernandes, T.~Kohno, B.~Li, A.~Prakash, A.~Rahmati,
  and D.~Song.
\newblock Robust physical-world attacks on machine learning models.
\newblock \emph{arXiv}, 2017.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow2015explaining}
I.~J. Goodfellow, J.~Shlens, and C.~Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2015.

\bibitem[Hein and Andriushchenko(2017)]{hein2017formal}
M.~Hein and M.~Andriushchenko.
\newblock Formal guarantees on the robustness of a classifier against
  adversarial manipulation.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pages 2263--2273, 2017.

\bibitem[Huang et~al.(2017)Huang, Papernot, Goodfellow, Duan, and
  Abbeel]{huang2017adversarial}
S.~Huang, N.~Papernot, I.~Goodfellow, Y.~Duan, and P.~Abbeel.
\newblock Adversarial attacks on neural network policies.
\newblock \emph{arXiv}, 2017.

\bibitem[Jia and Liang(2017)]{jia2017adversarial}
R.~Jia and P.~Liang.
\newblock Adversarial examples for evaluating reading comprehension systems.
\newblock In \emph{Empirical Methods in Natural Language Processing (EMNLP)},
  2017.

\bibitem[Katz et~al.(2017{\natexlab{a}})Katz, Barrett, Dill, Julian, and
  Kochenderfer]{katz2017reluplex}
G.~Katz, C.~Barrett, D.~Dill, K.~Julian, and M.~Kochenderfer.
\newblock Reluplex: An efficient {SMT} solver for verifying deep neural
  networks.
\newblock \emph{arXiv preprint arXiv:1702.01135}, 2017{\natexlab{a}}.

\bibitem[Katz et~al.(2017{\natexlab{b}})Katz, Barrett, Dill, Julian, and
  Kochenderfer]{katz2017towards}
G.~Katz, C.~Barrett, D.~L. Dill, K.~Julian, and M.~J. Kochenderfer.
\newblock Towards proving the adversarial robustness of deep neural networks.
\newblock \emph{arXiv}, 2017{\natexlab{b}}.

\bibitem[Kolter and Wong(2017)]{kolter2017provable}
J.~Z. Kolter and E.~Wong.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope (published at {ICML} 2018).
\newblock \emph{arXiv preprint arXiv:1711.00851}, 2017.

\bibitem[L{\"{o}}fberg(2004)]{lofberg2004}
J.~L{\"{o}}fberg.
\newblock {YALMIP}: A toolbox for modeling and optimization in {MATLAB}.
\newblock In \emph{CACSD}, 2004.

\bibitem[Lu et~al.(2017)Lu, Sibai, Fabry, and Forsyth]{lu2017no}
J.~Lu, H.~Sibai, E.~Fabry, and D.~Forsyth.
\newblock No need to worry about adversarial examples in object detection in
  autonomous vehicles.
\newblock \emph{arXiv preprint arXiv:1707.03501}, 2017.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2018towards}
A.~Madry, A.~Makelov, L.~Schmidt, D.~Tsipras, and A.~Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Papernot et~al.(2016)Papernot, McDaniel, Wu, Jha, and
  Swami]{papernot2016distillation}
N.~Papernot, P.~McDaniel, X.~Wu, S.~Jha, and A.~Swami.
\newblock Distillation as a defense to adversarial perturbations against deep
  neural networks.
\newblock In \emph{IEEE Symposium on Security and Privacy}, pages 582--597,
  2016.

\bibitem[Raghunathan et~al.(2018)Raghunathan, Steinhardt, and
  Liang]{raghunathan2018certified}
A.~Raghunathan, J.~Steinhardt, and P.~Liang.
\newblock Certified defenses against adversarial examples.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Sharif et~al.(2016)Sharif, Bhagavatula, Bauer, and
  Reiter]{sharif2016accessorize}
M.~Sharif, S.~Bhagavatula, L.~Bauer, and M.~K. Reiter.
\newblock Accessorize to a crime: Real and stealthy attacks on state-of-the-art
  face recognition.
\newblock In \emph{ACM SIGSAC Conference on Computer and Communications
  Security}, pages 1528--1540, 2016.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2014intriguing}
C.~Szegedy, W.~Zaremba, I.~Sutskever, J.~Bruna, D.~Erhan, I.~Goodfellow, and
  R.~Fergus.
\newblock Intriguing properties of neural networks.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2014.

\bibitem[Tjeng and Tedrake(2017)]{tjeng2017verifying}
V.~Tjeng and R.~Tedrake.
\newblock Verifying neural networks with mixed integer programming.
\newblock \emph{arXiv preprint arXiv:1711.07356}, 2017.

\bibitem[Vershynin(2010)]{vershynin2010introduction}
R.~Vershynin.
\newblock Introduction to the non-asymptotic analysis of random matrices.
\newblock \emph{arXiv}, 2010.

\bibitem[Weng et~al.(2018)Weng, Zhang, Chen, Song, Hsieh, Boning, Dhillon, and
  Daniel]{weng2018towards}
T.~Weng, H.~Zhang, H.~Chen, Z.~Song, C.~Hsieh, D.~Boning, I.~S. Dhillon, and
  L.~Daniel.
\newblock Towards fast computation of certified robustness for relu networks.
\newblock \emph{arXiv preprint arXiv:1804.09699}, 2018.

\bibitem[Wong and Kolter(2018)]{wong2018provable}
E.~Wong and J.~Z. Kolter.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2018.

\bibitem[Wong et~al.(2018)Wong, Schmidt, Metzen, and Kolter]{wong2018scaling}
E.~Wong, F.~Schmidt, J.~H. Metzen, and J.~Z. Kolter.
\newblock Scaling provable adversarial defenses.
\newblock \emph{arXiv preprint arXiv:1805.12514}, 2018.

\end{thebibliography}
