@book{Sutton2018,
  author = {Sutton, Richard S. and Barto, Andrew G.},
  edition = {Second},
  publisher = {The MIT Press},
  title = {Reinforcement Learning: An Introduction},
  year = {2018},
  isbn = {9780262039246}
}

@article{Fu2020,
  title={{D4RL}: Datasets for Deep Data-Driven Reinforcement Learning},
  author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.07219},
  year={2020}
}

@InProceedings{gulcehre2020,
  title={{RL} {U}nplugged: A Suite of Benchmarks for Offline Reinforcement Learning},
  author={Gulcehre, Caglar and Wang, Ziyu and Novikov, Alexander and Paine, Thomas and G{\'o}mez, Sergio and Zolna, Konrad and Agarwal, Rishabh and Merel, Josh S and Mankowitz, Daniel J and Paduraru, Cosmin and others},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS 2020)},
  volume={33},
  pages={7248--7259},
  year={2020},
  url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/51200d29d1fc15f5a71c1dab4bb54f7c-Paper.pdf}
}

@inproceedings{
kumar2021implicit,
title={Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning},
author={Aviral Kumar and Rishabh Agarwal and Dibya Ghosh and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=O9bnihsFfXU}
}


@InProceedings{Yu2020,
author = {Yu, Fisher and Chen, Haofeng and Wang, Xin and Xian, Wenqi and Chen, Yingying and Liu, Fangchen and Madhavan, Vashisht and Darrell, Trevor},
title = {{BDD100K}: A Diverse Driving Dataset for Heterogeneous Multitask Learning},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2020)},
year = {2020},
doi = {10.1109/CVPR42600.2020.00271}
}

@article{Ernst2005,
  title={Tree-Based Batch Mode Reinforcement Learning},
  author={Damien Ernst and Pierre Geurts and Louis Wehenkel},
  journal={Journal of Machine Learning Research},
  year={2005},
  volume={6},
  pages={503-556},
  url     = {http://jmlr.org/papers/v6/ernst05a.html}
}


@InProceedings{Agarwal2020,
  title = 	 {An Optimistic Perspective on Offline Reinforcement Learning},
  author =       {Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning (ICML 2020)},
  pages = 	 {104--114},
  year = 	 {2020},
   url = 	 {https://proceedings.mlr.press/v119/agarwal20c.html}
}


@inproceedings{Kumar2020,
  title={Conservative {Q}-Learning for Offline Reinforcement Learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS 2020)},
  volume = {33},
  pages = {1179--1191},
  year={2020},
  url = {https://proceedings.neurips.cc/paper/2020/file/0d2b2061826a5df3221116a5085a6052-Paper.pdf}
}

@inproceedings{Fu2021,
  title={Benchmarks for Deep Off-Policy Evaluation},
  author={Justin Fu and Mohammad Norouzi and Ofir Nachum and G. Tucker and Ziyun Wang and Alexander Novikov and Mengjiao Yang and Michael R. Zhang and Yutian Chen and Aviral Kumar and Cosmin Paduraru and Sergey Levine and Tom Le Paine},
  booktitle={The 9th International Conference on Learning Representations (ICLR 2021)},
  year={2021},
  url = {https://openreview.net/pdf?id=kWSeGEeHvF8}
}

@inproceedings{Irpan2019,
  title={Off-Policy Evaluation via Off-Policy Classification},
  author={Irpan, Alexander and Rao, Kanishka and Bousmalis, Konstantinos and Harris, Chris and Ibarz, Julian and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS 2019)},
  volume = {32},
  year={2019},
  url = {https://proceedings.neurips.cc/paper/2019/file/b5b03f06271f8917685d14cea7c6c50a-Paper.pdf}
}

@article{Paine2020,
  title={Hyperparameter Selection for Offline Reinforcement Learning},
  author={Tom Le Paine and Cosmin Paduraru and Andrea Michi and Caglar Gulcehre and Konrad Zolna and Alexander Novikov and Ziyun Wang and Nando de Freitas},
  journal={arXiv preprint arXiv:2007.09055},
  year={2020}
}

@book{Geron2019,
    author    = {G{\'e}ron, Aur{\'e}lien},
    edition = {Second},
    title     = {Hands-On Machine Learning with {S}cikit-Learn, {K}eras and {T}ensor{F}low},
    year      = {2019},
    publisher = {O’Reilly},
    isbn = {9781492032649}
}

@book{Busoniu2010,
    author={Lucian Busoniu and Robert Babuska and Bart De Schutter and Damien Ernst},
    title     = {Reinforcement Learning and Dynamic Programming Using Function Approximators},
    year      = {2010},
    publisher = {CRC Press},
    isbn = {9781439821084}
}

@article{Levine2020,
  title={Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems},
  author={Sergey Levine and Aviral Kumar and G. Tucker and Justin Fu},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{Lagoudakis2003,
  title={Least-Squares Policy Iteration},
  author={Michail G. Lagoudakis and Ronald E. Parr},
  journal={Journal of Machine Learning Research},
  year={2003},
  volume={4},
  pages={1107-1149},
  url = {https://www.jmlr.org/papers/v4/lagoudakis03a.html}
}

@book{Putterman1994,
  author = {Martin L. Puterman},
  publisher = {John Wiley \& Sons},
  title = {{M}arkov Decision Processes: Discrete Stochastic Dynamic Programming},
  year = {1994},
  doi = {10.1002/9780470316887}
}

@article{Mnih2015,
  title={Human-Level Control through Deep Reinforcement Learning},
  author={Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Andrei A. Rusu and Joel Veness and Marc G. Bellemare and Alex Graves and Martin A. Riedmiller and Andreas Fidjeland and Georg Ostrovski and Stig Petersen and Charlie Beattie and Amir Sadik and Ioannis Antonoglou and Helen King and Dharshan Kumaran and Daan Wierstra and Shane Legg and Demis Hassabis},
  journal={Nature},
  year={2015},
  volume={518},
  pages={529-533},
  doi = {10.1038/nature14236}
}

@inproceedings{Precup2000,
  title={Eligibility Traces for Off-Policy Policy Evaluation},
  author={Doina Precup and Richard S. Sutton and Satinder Singh},
  booktitle={Proceedings of the 17th International Confrence on Machine Learning (ICML 2000)},
  pages={80},
  year={2000},
  url = {https://scholarworks.umass.edu/cs_faculty_pubs/80}
}


@InProceedings{Thomas2016,
  title = 	 {Data-Efficient Off-Policy Policy Evaluation for Reinforcement Learning},
  author = 	 {Thomas, Philip and Brunskill, Emma},
  booktitle = 	 {Proceedings of the 33rd International Conference on Machine Learning (ICML 2016)},
  pages = 	 {2139--2148},
  year = 	 {2016},
  url = {https://proceedings.mlr.press/v48/thomasa16.html}
}


@InProceedings{Le2019,
  title = 	 {Batch Policy Learning under Constraints},
  author =       {Le, Hoang and Voloshin, Cameron and Yue, Yisong},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning (ICML 2019)},
  pages = 	 {3703--3712},
  year = 	 {2019},
  url = {http://proceedings.mlr.press/v97/le19a.html}
}


@inproceedings{Zhang2021,
title={Autoregressive Dynamics Models for Offline Policy Evaluation and Optimization},
author={Michael R Zhang and Thomas Paine and Ofir Nachum and Cosmin Paduraru and George Tucker and ziyu wang and Mohammad Norouzi},
booktitle={The 9th International Conference on Learning Representations (ICLR 2021)},
year={2021},
url = {https://openreview.net/pdf?id=kmqjgSNXby}
}

@article{Sutton1991,
author = {Sutton, Richard S.},
title = {Dyna, an Integrated Architecture for Learning, Planning, and Reacting},
year = {1991},
volume = {2},
number = {4},
journal = {SIGART Bull.},
pages = {160–163},
doi = {10.1145/122344.122377}
}


@article{Farahmand2010,
  title={Model Selection in Reinforcement Learning},
  author={Amir Massoud Farahmand and Csaba Szepesvari},
  journal={Machine Learning},
  year={2010},
  volume={85},
  pages={299-332},
  doi = {10.1007/s10994-011-5254-7}
}

@book{Vapnik1998,
  title     = "Statistical Learning Theory",
  author    = "Vapnik, Vladimir N",
  publisher = "John Wiley \& Sons",
  year      =  1998,
  isbn = 9780471030034
}

@article{Bellemare2013,
  author = {M. G. Bellemare and Y. Naddaf and J. Veness and M. Bowling},
  title = {The Arcade Learning Environment: An Evaluation Platform for General Agents},
  journal = {Journal of Artificial Intelligence Research},
  volume = {47},
  pages = {253--279},
  year = {2013},
  doi = {10.1613/jair.3912}
}

@inproceedings{Randlov1998,
author = {Randl\o{}v, Jette and Alstr\o{}m, Preben},
title = {Learning to Drive a Bicycle Using Reinforcement Learning and Shaping},
year = {1998},
booktitle = {Proceedings of the 15th International Conference on Machine Learning (ICML 1998)},
pages = {463–471}
}

@article{Luckett2020,
  title={Estimating Dynamic Treatment Regimes in Mobile Health Using {V}-Learning},
  author={Daniel J. Luckett and Eric B. Laber and Anna R. Kahkoska and David M. Maahs and Elizabeth J. Mayer‐Davis and Michael R. Kosorok},
  journal={Journal of the American Statistical Association},
  year={2020},
  volume={115},
  pages={692-706},
  doi = {10.1080/01621459.2018.1537919}
}

@inproceedings{Hasselt2016,
author = {Hasselt, Hado van and Guez, Arthur and Silver, David},
title = {Deep Reinforcement Learning with Double {Q}-Learning},
year = {2016},
booktitle = {Proceedings of the 30th AAAI Conference on Artificial Intelligence (AAAI-2016)},
pages = {2094–2100},
doi = {10.1609/aaai.v30i1.10295}
}


@InProceedings{Wang2016,
  title = 	 {Dueling Network Architectures for Deep Reinforcement Learning},
  author = 	 {Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Hasselt, Hado and Lanctot, Marc and Freitas, Nando},
  booktitle = 	 {Proceedings of the 33rd International Conference on Machine Learning (ICML 2016)},
  pages = 	 {1995--2003},
  year = 	 {2016},
  url = {http://proceedings.mlr.press/v48/wangf16.html}
}



@article{ILSVRC15,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet} Large Scale Visual Recognition Challenge},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
volume={115},
number={3},
pages={211-252},
doi = {10.1007/s11263-015-0816-y}
}

@misc{Krizhevsky2009,
  title={Learning Multiple Layers of Features from Tiny Images},
  author={Alex Krizhevsky},
  year={2009},
  url = {https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf}
}


@InProceedings{Ioffe2015,
  title = 	 {{B}atch {N}ormalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author = 	 {Ioffe, Sergey and Szegedy, Christian},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning (ICML 2015)},
  pages = 	 {448--456},
  year = 	 {2015},
  url = {http://proceedings.mlr.press/v37/ioffe15.html}
}


@InProceedings{He2016,
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
title = {Deep Residual Learning for Image Recognition},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2016)},
year = {2016},
doi = {10.1109/CVPR.2016.90}
}

@InProceedings{Hu2018,
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={{S}queeze-and-{E}xcitation Networks}, 
  year={2018},
  pages={7132-7141},
  doi = {10.1109/CVPR.2018.00745}
}
 
@InProceedings{Chollet2017,
author = {Chollet, Francois},
title = {Xception: Deep Learning With Depthwise Separable Convolutions},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2017)},
year = {2017},
doi = {10.1109/CVPR.2017.195}
}

@inproceedings{Dozat2016,
	title        = {Incorporating {N}esterov Momentum into {A}dam},
	author       = {Dozat, Timothy},
	booktitle    = {The 4th International Conference on Learning Representations (ICLR 2016)},
	year         = 2016,
	url = {https://openreview.net/pdf/OM0jvwB8jIp57ZJjtNEZ.pdf}
}

@article{Senior2013,
  title={An Empirical Study of Learning Rates in Deep Neural Networks for Speech Recognition},
  author={Andrew W. Senior and Georg Heigold and Marc'Aurelio Ranzato and Ke Yang},
  journal={IEEE International Conference on Acoustics, Speech and Signal Processing},
  year={2013},
  pages={6724-6728},
  doi = {10.1109/ICASSP.2013.6638963}
}

@book{Hastie2009,
  author = {Trevor Hastie and Robert Tibshirani and Jerome Friedman},
  title = {The Elements of Statistical Learning},
  publisher = {Springer},
  year = {2009},
  doi = {10.1007/978-0-387-84858-7}
}




@inproceedings{Lillicrap2016,
	title        = {Continuous Control with Deep Reinforcement Learning},
	author       = {Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Manfred Otto Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
	booktitle    = {The 4th International Conference on Learning Representations (ICLR 2016)},
	year   = 2016,
	url = {https://arxiv.org/pdf/1509.02971v6.pdf}
}


@book{Kotz2006,
    author = {Samuel Kotz and Campbell B. Read and N. Balakrishnan and Brani Vidakovic and Norman L. Johnson},
    title     = {Encyclopedia of Statistical Sciences},
    year      = {2006},
    publisher = {John Wiley {\&} Sons},
    doi = {10.1002/0471667196}
}


@article{Fujimoto2022,
  author    = {Scott Fujimoto and
               David Meger and
               Doina Precup and
               Ofir Nachum and
               Shixiang Shane Gu},
  title     = {Why Should {I} Trust You, {B}ellman? The {B}ellman Error is a Poor Replacement for Value Error},
  journal    = {arXiv preprint arXiv:2201.12417},
  year      = {2022}
}


@InProceedings{Espeholt2018,
  title = 	 {{IMPALA}: Scalable Distributed Deep-{RL} with Importance Weighted Actor-Learner Architectures},
  author =       {Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Vlad and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and Legg, Shane and Kavukcuoglu, Koray},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning (ICML 2018)},
  pages = 	 {1407--1416},
  year = 	 {2018},
  url = {http://proceedings.mlr.press/v80/espeholt18a.html}
}






@misc{tf2015,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}

@misc{Agarwal2022,
  title = {Reinforcement Learning: Theory and Algorithms},
  author = {Alekh Agarwal and Nan Jiang and Sham M. Kakade and Wen Sun},
  note = {A working draft},
  year = 	 {2022},
  url = {https://rltheorybook.github.io/}
}


@article{Liao2021,
  title={Off-Policy Estimation of Long-Term Average Outcomes with Applications to Mobile Health},
  author={Liao, Peng and Klasnja, Predrag and Murphy, Susan},
  journal={Journal of the American Statistical Association},
  volume={116},
  number={533},
  pages={382--391},
  year={2021},
  doi={10.1080/01621459.2020.1807993}
}

@article{Yu2021,
  title={Reinforcement Learning in Healthcare: A Survey},
  author={Yu, Chao and Liu, Jiming and Nemati, Shamim and Yin, Guosheng},
  journal={ACM Computing Surveys (CSUR)},
  volume={55},
  number={1},
  pages={1--36},
  year={2021},
  doi={10.1145/3477600}
}


@book{Kazdin2000,
  title={Encyclopedia of Psychology},
  author={Kazdin, Alan E and American Psychological Association and others},
  volume={8},
  year={2000},
  publisher={American Psychological Association Washington, DC},
  isbn = {9781557981875}
}

@article{Klasnja2015,
  title={Microrandomized Trials: An Experimental Design for Developing Just-in-Time Adaptive Interventions},
  author={Klasnja, Predrag and Hekler, Eric B and Shiffman, Saul and Boruvka, Audrey and Almirall, Daniel and Tewari, Ambuj and Murphy, Susan A},
  journal={Health Psychology},
  volume={34},
  number={S},
  pages={1220},
  year={2015},
  doi={10.1037/hea0000305}
}


@InProceedings{Jiang2016,
  title = 	 {Doubly Robust Off-Policy Value Evaluation for Reinforcement Learning},
  author = 	 {Jiang, Nan and Li, Lihong},
  booktitle = 	 {Proceedings of the 33rd International Conference on Machine Learning (ICML 2016)},
  pages = 	 {652--661},
  year = 	 {2016},
  url = {http://proceedings.mlr.press/v48/jiang16.html}
}



@InProceedings{Xie2019,
  title={Towards Optimal Off-Policy Evaluation for Reinforcement Learning with Marginalized Importance Sampling},
  author={Xie, Tengyang and Ma, Yifei and Wang, Yu-Xiang},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS 2019)},
  volume={32},
  year={2019},
  url = {https://proceedings.neurips.cc/paper/2019/file/4ffb0d2ba92f664c2281970110a2e071-Paper.pdf}
}

@inproceedings{Yang2020,
  title={Off-Policy Evaluation via the Regularized {L}agrangian},
  author={Yang, Mengjiao and Nachum, Ofir and Dai, Bo and Li, Lihong and Schuurmans, Dale},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS 2020)},
  volume={33},
  pages={6551--6561},
  year={2020},
  url = {https://proceedings.neurips.cc//paper/2020/file/488e4104520c6aab692863cc1dba45af-Paper.pdf}
}

@inproceedings{Baird1995,
  title={Residual Algorithms: Reinforcement Learning with Function Approximation},
  author={Leemon Baird},
  booktitle={Proceedings of the 12th International Conference on Machine Learning (ICML 1995)},
  pages={30--37},
  year={1995},
  doi = {10.1016/B978-1-55860-377-6.50013-X}
}


@InProceedings{Xie2021,
  title = 	 {Batch Value-Function Approximation with Only Realizability},
  author =       {Xie, Tengyang and Jiang, Nan},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning (ICML 2021)},
  pages = 	 {11404--11413},
  year = 	 {2021},
  url = {https://proceedings.mlr.press/v139/xie21d.html}
}


@InProceedings{Zhang2021ps,
  title={Towards Hyperparameter-Free Policy Selection for Offline Reinforcement Learning},
  author={Zhang, Siyuan and Jiang, Nan},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS 2021)},
  volume={34},
  pages={12864--12875},
  year={2021},
  url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/6add07cf50424b14fdf649da87843d01-Paper.pdf}
}


@inproceedings{Munos2005,
author = {Munos, R\'{e}mi},
title = {Error Bounds for Approximate Value Iteration},
year = {2005},
booktitle = {Proceedings of the 20th National Conference on Artificial Intelligence (AAAI-05)},
pages = {1006–-1011},
url = {https://www.aaaipress.org/Papers/AAAI/2005/AAAI05-159.pdf}
}

@article{Munos2008,
  author  = {R{{\'e}}mi Munos and Csaba Szepesv{{\'a}}ri},
  title   = {Finite-Time Bounds for Fitted Value Iteration},
  journal = {Journal of Machine Learning Research},
  year    = {2008},
  volume  = {9},
  number  = {27},
  pages   = {815--857},
  url     = {http://jmlr.org/papers/v9/munos08a.html}
}

@inproceedings{Antos2007,
  title={Value-Iteration based Fitted Policy Iteration: Learning with a Single Trajectory},
  author={Antos, Andr{\'a}s and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  booktitle={2007 IEEE international symposium on approximate dynamic programming and reinforcement learning},
  pages={330--337},
  year={2007},
  doi = {10.1109/ADPRL.2007.368207}
}

@article{Lee2022,
  title={Oracle Inequalities for Model Selection in Offline Reinforcement Learning},
  author={Lee, Jonathan N and Tucker, George and Nachum, Ofir and Dai, Bo and Brunskill, Emma},
  journal={arXiv preprint arXiv:2211.02016},
  year={2022}
}

@article{Miyaguchi2022,
  title={Hyperparameter Selection Methods for Fitted {Q}-Evaluation with Error Guarantee},
  author={Kohei Miyaguchi},
  journal={arXiv preprint arXiv:2201.02300v2},
  year={2022}
}

@InProceedings{Fujimoto2020,
  title = 	 {Off-Policy Deep Reinforcement Learning without Exploration},
  author =       {Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning (ICML 2019)},
  pages = 	 {2052--2062},
  year = 	 {2019},
  url = {http://proceedings.mlr.press/v97/fujimoto19a.html}
}

@InProceedings{Antos2007fqi,
  title={Fitted {Q}-Iteration in Continuous Action-Space {MDP}s},
  author={Antos, Andr{\'a}s and Munos, R{\'e}mi and  Szepesv{\'a}ri, Csaba and},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS 2007)},
  volume={20},
  pages={9--16},
  year={2007},
  url = {https://papers.nips.cc/paper_files/paper/2007/file/da0d1111d2dc5d489242e60ebcbaf988-Paper.pdf}
}


@InProceedings{Fan2020,
  title = 	 {A Theoretical Analysis of Deep {Q}-Learning},
  author =       {Fan, Jianqing and Wang, Zhaoran and Xie, Yuchen and Yang, Zhuoran},
  booktitle = 	 {Proceedings of the 2nd Conference on Learning for Dynamics and Control (L4DC 2020)},
  pages = 	 {486--489},
  year = 	 {2020},
  url = 	 {https://proceedings.mlr.press/v120/yang20a.html}
}


@InProceedings{Chen2019,
  title = 	 {Information-Theoretic Considerations in Batch Reinforcement Learning},
  author =       {Chen, Jinglin and Jiang, Nan},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning (ICML 2019)},
  pages = 	 {1042--1051},
  year = 	 {2019},
  url = {https://proceedings.mlr.press/v97/chen19e.html}
}

@article{dopamine,
  title={Dopamine: A Research Framework for Deep Reinforcement Learning},
  author={Pablo Samuel Castro and
               Subhodeep Moitra and
               Carles Gelada and
               Saurabh Kumar and
               Marc G. Bellemare},
  journal={arXiv preprint arXiv:1812.06110v1},
  year={2018}
}

@article{Kostrikov2020,
  title={Statistical Bootstrapping for Uncertainty Estimation in Off-Policy Evaluation},
  author={Ilya Kostrikov and Ofir Nachum},
  journal={arXiv preprint arXiv:2007.13609v1},
  year={2020}
}


@InProceedings{Glorot2010,
  title = 	 {Understanding the Difficulty of Training Deep Feedforward Neural Networks},
  author = 	 {Glorot, Xavier and Bengio, Yoshua},
  booktitle = 	 {Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics (AISTATS 2010)},
  pages = 	 {249--256},
  year = 	 {2010},
  url = {https://proceedings.mlr.press/v9/glorot10a.html},
}


@InProceedings{He2015,
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
title = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on {I}mage{N}et Classification},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV 2015)},
pages = {1026--1034},
year = {2015},
doi = {10.1109/ICCV.2015.123}
}

@InProceedings{Chen2022,
  title = 	 {On Well-Posedness and Minimax Optimal Rates of Nonparametric {Q}-Function Estimation in Off-Policy Evaluation},
  author =       {Chen, Jinglin and Jiang, Nan},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning (ICML 2022)},
  pages = 	 {3558--3582},
  year = 	 {2022},
  url = {https://proceedings.mlr.press/v162/chen22u.html}
}

@article{Uehara2022,
  title={Finite Sample Analysis of Minimax Offline Reinforcement Learning: Completeness, Fast Rates and First-Order Efficiency},
  author={Uehara, Masatoshi and Imaizumi, Masaaki and Jiang, Nan and Kallus, Nathan and Sun, Wen and Xie, Tengyang},
  journal={arXiv preprint arXiv:2102.02981},
  year={2021}
}


@InProceedings{Tang2021,
  title = 	 {Model Selection for Offline Reinforcement Learning: Practical Considerations for Healthcare Settings},
  author =       {Tang, Shengpu and Wiens, Jenna},
  booktitle = 	 {Proceedings of the 6th Machine Learning for Healthcare Conference (MLHC 2021)},
  pages = 	 {2--35},
  year = 	 {2021},
  url = {https://proceedings.mlr.press/v149/tang21a.html}
}

@article{schrittwieser2021,
  title={Online and Offline Reinforcement Learning by Planning with a Learned Model},
  author={Schrittwieser, Julian and Hubert, Thomas and Mandhane, Amol and Barekatain, Mohammadamin and Antonoglou, Ioannis and Silver, David},
  journal={Advances in Neural Information Processing Systems (NeurIPS 2021)},
  volume={34},
  pages={27580--27591},
  year={2021},
  url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/e8258e5140317ff36c7f8225a3bf9590-Paper.pdf}
}

@article{Yu2021combo,
  title={{COMBO}: Conservative Offline Model-Based Policy Optimization},
  author={Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems (NeurIPS 2021)},
  volume={34},
  pages={28954--28967},
  year={2021},
  url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/f29a179746902e331572c483c45e5086-Paper.pdf}
}


@InProceedings{Rafailov2021,
  title = 	 {Offline Reinforcement Learning from Images with Latent Space Models},
  author =       {Rafailov, Rafael and Yu, Tianhe and Rajeswaran, Aravind and Finn, Chelsea},
  booktitle = 	 {Proceedings of the 3rd Conference on Learning for Dynamics and Control (L4DC 2021)},
  pages = 	 {1154--1168},
  year = 	 {2021},
  url = {https://proceedings.mlr.press/v144/rafailov21a.html}
}

@ARTICLE{Prudencio2023,
  author={Prudencio, Rafael Figueiredo and Maximo, Marcos R. O. A. and Colombini, Esther Luna},
  journal={IEEE Transactions on Neural Networks and Learning Systems (Early Access)}, 
  title={A Survey on Offline Reinforcement Learning: Taxonomy, Review, and Open Problems}, 
  year={2023},
  pages={1-0},
  doi={10.1109/TNNLS.2023.3250269}}


@article{Wu2019,
  title={Behavior Regularized Offline Reinforcement Learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@inproceedings{Kalashnikov2018,
  title={{QT}-{O}pt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  booktitle={2nd Conference on Robot Learning (CoRL 2018)},
  year={2018},
  doi = {10.48550/arXiv.1806.10293}
}

@ARTICLE{Khan2021,
  author={Kahn, Gregory and Abbeel, Pieter and Levine, Sergey},
  journal={IEEE Robotics and Automation Letters}, 
  title={{BADGR}: An Autonomous Self-Supervised Learning-Based Navigation System}, 
  year={2021},
  volume={6},
  number={2},
  pages={1312-1319},
  doi={10.1109/LRA.2021.3057023}
}

@article{Janner2019,
  title={When to Trust Your Model: Model-Based Policy Optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems (NeurIPS2019)},
  volume={32},
  year={2019},
  url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/5faf461eff3099671ad63c6f3f094f7f-Paper.pdf}
}

@InProceedings{Voloshin2021,
  title={Empirical Study of Off-Policy Policy Evaluation for Reinforcement Learning},
  author={Voloshin, Cameron and Le, Hoang M and Jiang, Nan and Yue, Yisong},
  booktitle={35th Conference on Neural Information Processing Systems (NeurIPS 2021) Track on Datasets and Benchmarks},
  year={2021},
  url = {https://openreview.net/pdf?id=IsK8iKbL-I}
}

@inproceedings{Thomas2015,
author = {Thomas, Philip and Theocharous, Georgios and Ghavamzadeh, Mohammad},
title = {High-Confidence Off-Policy Evaluation},
year = {2015},
booktitle = {Proceedings of the 29th AAAI Conference on Artificial Intelligence (AAAI-15)},
pages = {2094–2100},
doi = {10.1609/aaai.v29i1.9541}
}

@article{Shi2021,
    author = {Shi, Chengchun and Zhang, Sheng and Lu, Wenbin and Song, Rui},
    title = {Statistical Inference of the Value Function for Reinforcement Learning in Infinite-Horizon Settings},
    journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
    volume = {84},
    number = {3},
    pages = {765-793},
    year = {2021},
    doi = {10.1111/rssb.12465}
}

@article{Yang2021,
  title={Pessimistic Model Selection for Offline Deep Reinforcement Learning},
  author={Yang, Chao-Han Huck and Qi, Zhengling and Cui, Yifan and Chen, Pin-Yu},
  journal={arXiv preprint arXiv:2111.14346},
  year={2021}
}

@inproceedings{Kumar2021,
  title={A Workflow for Offline Model-Free Robotic Reinforcement Learning},
  author={Kumar, Aviral and Singh, Anikait and Tian, Stephen and Finn, Chelsea and Levine, Sergey},
  booktitle={5th Conference on Robot Learning (CoRL 2021)},
  year={2021},
  doi = {10.48550/arXiv.2109.10813}
}

@InProceedings{Nie2022,
  title={Data-Efficient Pipeline for Offline Reinforcement Learning with Limited Data},
  author={Nie, Allen and Flet-Berliac, Yannis and Jordan, Deon and Steenbergen, William and Brunskill, Emma},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS 2022)},
  volume={35},
  pages={14810--14823},
  year={2022}
}


@InProceedings{Voloshin2021model,
  title = 	 {Minimax Model Learning},
  author =       {Voloshin, Cameron and Jiang, Nan and Yue, Yisong},
  booktitle = 	 {Proceedings of The 24th International Conference on Artificial Intelligence and Statistics (AISTATS 2021)},
  pages = 	 {1612--1620},
  year = 	 {2021},
  url = {https://proceedings.mlr.press/v130/voloshin21a.html}
}

@ARTICLE{Arulkumaran2017,
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  title={Deep Reinforcement Learning: A Brief Survey}, 
  journal={IEEE Signal Processing Magazine}, 
  volume={34},
  number={6},
  pages={26-38},
  year={2017},
  doi={10.1109/MSP.2017.2743240}}

@article{Osa2018,
  title={An Algorithmic Perspective on Imitation Learning},
  author={Osa, Takayuki and Pajarinen, Joni and Neumann, Gerhard and Bagnell, J Andrew and Abbeel, Pieter and Peters, Jan and others},
  journal={Foundations and Trends{\textregistered} in Robotics},
  volume={7},
  number={1-2},
  pages={1--179},
  year={2018},
  doi = {10.1561/2300000053}
}


@InProceedings{Schulman2015,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning (ICML 2015)},
  pages = 	 {1889--1897},
  year = 	 {2015},
  url = {https://proceedings.mlr.press/v37/schulman15.html}
}

@inproceedings{Dabney2018,
  title={Distributional Reinforcement Learning with Quantile Regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc and Munos, R{\'e}mi},
  booktitle={Proceedings of the 32nd AAAI Conference on Artificial Intelligence (AAAI-18)},
  year={2018},
  doi = {10.1609/aaai.v32i1.11791}
}

@article{Weltz2022,
title = {Reinforcement Learning Methods in Public Health},
journal = {Clinical Therapeutics},
volume = {44},
number = {1},
pages = {139-154},
year = {2022},
author = {Justin Weltz and Alex Volfovsky and Eric B. Laber},
doi = {10.1016/j.clinthera.2021.11.002}
}

@book{Tsiatis2021,
  author = {Tsiatis, Anastasios A and Davidian, Marie and Holloway, Shannon T and Laber, Eric B},
  publisher = {CRC Press},
  edition = {First},
  title = {Dynamic Treatment Regimes: Statistical Methods for Precision Medicine},
  year = {2019},
  doi = {10.1201/9780429192692}
}

@article{Shi2022,
author = {Chengchun Shi and Jin Zhu and Shen Ye and Shikai Luo and Hongtu Zhu and Rui Song},
title = {Off-Policy Confidence Interval Estimation with Confounded Markov Decision Process},
journal = {Journal of the American Statistical Association},
volume = {0},
number = {0},
pages = {1-12},
year  = {2022},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.2022.2110878}
}

@article{Liao2022,
author = {Peng Liao and Zhengling Qi and Runzhe Wan and Predrag Klasnja and Susan A. Murphy},
title = {Batch policy learning in Average Reward {M}arkov Decision Processes},
volume = {50},
journal = {The Annals of Statistics},
number = {6},
pages = {3364 -- 3387},
year = {2022},
doi = {10.1214/22-AOS2231}
}


@InProceedings{Zhu2020,
  title = 	 {Causal Effect Estimation and Optimal Dose Suggestions in Mobile Health},
  author =       {Zhu, Liangyu and Lu, Wenbin and Song, Rui},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning (ICML 2020)},
  pages = 	 {11588--11598},
  year = 	 {2020},
  url = {https://proceedings.mlr.press/v119/zhu20c.html}
}







