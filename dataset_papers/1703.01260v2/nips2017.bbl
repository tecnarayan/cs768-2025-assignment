\begin{thebibliography}{32}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abel et~al.(2016)Abel, Agarwal, Diaz, Krishnamurthy, and
  Schapire]{gradient-boosting-Abel-16}
Abel, David, Agarwal, Alekh, Diaz, Fernando, Krishnamurthy, Akshay, and
  Schapire, Robert~E.
\newblock Exploratory gradient boosting for reinforcement learning in complex
  domains.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2016.

\bibitem[Achiam \& Sastry(2017)Achiam and Sastry]{surprise-achiam-16}
Achiam, Joshua and Sastry, Shankar.
\newblock Surprise-based intrinsic motivation for deep reinforcement learning.
\newblock \emph{CoRR}, abs/1703.01732, 2017.

\bibitem[Barto \& Mahadevan(2003)Barto and Mahadevan]{hrl_survey}
Barto, Andrew~G. and Mahadevan, Sridhar.
\newblock Recent advances in hierarchical reinforcement learning.
\newblock \emph{Discrete Event Dynamic Systems}, 13\penalty0 (1-2), 2003.

\bibitem[Bellemare et~al.(2016)Bellemare, Srinivasan, Ostrovski, Schaul,
  Saxton, and Munos]{unifying-bellemare-16}
Bellemare, Marc~G., Srinivasan, Sriram, Ostrovski, Georg, Schaul, Tom, Saxton,
  David, and Munos, Remi.
\newblock Unifying count-based exploration and intrinsic motivation.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2016.

\bibitem[Brafman \& Tennenholtz(2002)Brafman and Tennenholtz]{rmax-brafman-02}
Brafman, Ronen~I. and Tennenholtz, Moshe.
\newblock R-max – a general polynomial time algorithm for near-optimal
  reinforcement learning.
\newblock \emph{Journal of Machine Learning Research (JMLR)}, 2002.

\bibitem[Bubeck \& Cesa-Bianchi(2012)Bubeck and Cesa-Bianchi]{regret_analysis}
Bubeck, Sébastien and Cesa-Bianchi, Nicolò.
\newblock Regret analysis of stochastic and nonstochastic multi-armed bandit
  problems.
\newblock \emph{Foundations and Trends® in Machine Learning}, 5, 2012.

\bibitem[Chapelle \& Li(2011)Chapelle and Li]{cl-eets-11}
Chapelle, O. and Li, Lihong.
\newblock An empirical evaluation of thompson sampling.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2011.

\bibitem[Chentanez et~al.(2005)Chentanez, Barto, and Singh]{Intrinsic}
Chentanez, Nuttapong, Barto, Andrew~G, and Singh, Satinder~P.
\newblock {Intrinsically Motivated Reinforcement Learning}.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)}.
  MIT Press, 2005.

\bibitem[Duan et~al.(2016)Duan, Chen, Houthooft, Schulman, and
  Abbeel]{benchmarking-rocky}
Duan, Yan, Chen, Xi, Houthooft, Rein, Schulman, John, and Abbeel, Pieter.
\newblock Benchmarking deep reinforcement learning for continuous control.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2016.

\bibitem[Florensa et~al.(2017)Florensa, Duan, and Abbeel]{stochastic-nn}
Florensa, Carlos~Campo, Duan, Yan, and Abbeel, Pieter.
\newblock Stochastic neural networks for hierarchical reinforcement learning.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2017.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{gan-goodfellow}
Goodfellow, Ian, Pouget-Abadie, Jean, Mirza, Mehdi, Xu, Bing, Warde-Farley,
  David, Ozair, Sherjil, Courville, Aaron, and Bengio, Yoshua.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)}.
  2014.

\bibitem[Heess et~al.(2016)Heess, Wayne, Tassa, Lillicrap, Riedmiller, and
  Silver]{modulatedloco}
Heess, Nicolas, Wayne, Gregory, Tassa, Yuval, Lillicrap, Timothy~P.,
  Riedmiller, Martin~A., and Silver, David.
\newblock Learning and transfer of modulated locomotor controllers.
\newblock \emph{CoRR}, abs/1610.05182, 2016.

\bibitem[Houthooft et~al.(2016)Houthooft, Chen, Duan, Schulman, Turck, and
  Abbeel]{vime-houthooft-16}
Houthooft, Rein, Chen, Xi, Duan, Yan, Schulman, John, Turck, Filip~De, and
  Abbeel, Pieter.
\newblock Vime: Variational information maximizing exploration.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2016.

\bibitem[Kakade et~al.(2003)Kakade, Kearns, and Langford]{explmetric-kakade-03}
Kakade, Sham, Kearns, Michael, and Langford, John.
\newblock Exploration in metric state spaces.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2003.

\bibitem[Kearns \& Singh(2002)Kearns and Singh]{norlpt-kearns-02}
Kearns, Michael and Singh, Satinder.
\newblock Near-optimal reinforcement learning in polynomial time.
\newblock \emph{Machine Learning}, 2002.

\bibitem[Kolter \& Ng(2009)Kolter and Ng]{bayesexp-kolter-09}
Kolter, J.~Zico and Ng, Andrew~Y.
\newblock Near-bayesian exploration in polynomial time.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2009.

\bibitem[Kulkarni et~al.(2016)Kulkarni, Narasimhan, Saeedi, and
  Tenenbaum]{KulkarniHierarchical}
Kulkarni, Tejas~D, Narasimhan, Karthik, Saeedi, Ardavan, and Tenenbaum, Josh.
\newblock Hierarchical deep reinforcement learning: Integrating temporal
  abstraction and intrinsic motivation.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)}.
  2016.

\bibitem[Lillicrap et~al.(2015)Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa,
  Silver, and Wierstra]{ddpg}
Lillicrap, Timothy~P., Hunt, Jonathan~J., Pritzel, Alexander, Heess, Nicolas,
  Erez, Tom, Tassa, Yuval, Silver, David, and Wierstra, Daan.
\newblock Continuous control with deep reinforcement learning.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2015.

\bibitem[Malisiewicz et~al.(2011)Malisiewicz, Gupta, and Efros]{exemplarsvm}
Malisiewicz, Tomasz, Gupta, Abhinav, and Efros, Alexei~A.
\newblock Ensemble of exemplar-svms for object detection and beyond.
\newblock In \emph{International Conference on Computer Vision (ICCV)}, 2011.

\bibitem[Mathieu et~al.(2015)Mathieu, Couprie, and
  LeCun]{DBLP:journals/corr/MathieuCL15}
Mathieu, Micha{\"{e}}l, Couprie, Camille, and LeCun, Yann.
\newblock Deep multi-scale video prediction beyond mean square error.
\newblock \emph{CoRR}, abs/1511.05440, 2015.
\newblock URL \url{http://arxiv.org/abs/1511.05440}.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, Petersen, Beattie, Sadik,
  Antonoglou, King, Kumaran, Wierstra, Legg, and Hassabis]{mnih-dqn-2015}
Mnih, Volodymyr, Kavukcuoglu, Koray, Silver, David, Rusu, Andrei~A., Veness,
  Joel, Bellemare, Marc~G., Graves, Alex, Riedmiller, Martin, Fidjeland,
  Andreas~K., Ostrovski, Georg, Petersen, Stig, Beattie, Charles, Sadik, Amir,
  Antonoglou, Ioannis, King, Helen, Kumaran, Dharshan, Wierstra, Daan, Legg,
  Shane, and Hassabis, Demis.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529--533, 02 2015.

\bibitem[Oh et~al.(2015)Oh, Guo, Lee, Lewis, and Singh]{acvp-oh-15}
Oh, Junhyuk, Guo, Xiaoxiao, Lee, Honglak, Lewis, Richard, and Singh, Satinder.
\newblock Action-conditional video prediction using deep networks in atari
  games.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2015.

\bibitem[Osband et~al.(2016)Osband, Blundell, and
  Alexander~Pritzel]{bdqn-osband-16}
Osband, Ian, Blundell, Charles, and Alexander~Pritzel, Benjamin Van~Roy.
\newblock Deep exploration via bootstrapped {DQN}.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2016.

\bibitem[Pathak et~al.(2017)Pathak, Agrawal, Efros, and
  Darrell]{pathakICMl17curiosity}
Pathak, Deepak, Agrawal, Pulkit, Efros, Alexei~A., and Darrell, Trevor.
\newblock Curiosity-driven exploration by self-supervised prediction.
\newblock In \emph{International Conference on Machine Learning ({ICML})},
  2017.

\bibitem[Pazis \& Parr(2013)Pazis and Parr]{cpace-pazis-13}
Pazis, Jason and Parr, Ronald.
\newblock Pac optimal exploration in continuous space markov decision
  processes.
\newblock In \emph{AAAI Conference on Artificial Intelligence (AAAI)}, 2013.

\bibitem[Salimans et~al.(2016)Salimans, Goodfellow, Zaremba, Cheung, Radford,
  and Chen]{DBLP:conf/nips/SalimansGZCRCC16}
Salimans, Tim, Goodfellow, Ian~J., Zaremba, Wojciech, Cheung, Vicki, Radford,
  Alec, and Chen, Xi.
\newblock Improved techniques for training gans.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2016.

\bibitem[Schmidhuber(1990)]{Schmidhuber:1991:PIC:116517.116542}
Schmidhuber, J\"{u}rgen.
\newblock A possibility for implementing curiosity and boredom in
  model-building neural controllers.
\newblock In \emph{Proceedings of the First International Conference on
  Simulation of Adaptive Behavior on From Animals to Animats}, Cambridge, MA,
  USA, 1990. MIT Press.
\newblock ISBN 0-262-63138-5.

\bibitem[Schulman et~al.(2015)Schulman, Levine, Moritz, Jordan, and
  Abbeel]{trpo-schulman-16}
Schulman, John, Levine, Sergey, Moritz, Philipp, Jordan, Michael~I., and
  Abbeel, Pieter.
\newblock Trust region policy optimization.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2015.

\bibitem[Stadie et~al.(2015)Stadie, Levine, and Abbeel]{exploration-stadie-15}
Stadie, Bradly~C., Levine, Sergey, and Abbeel, Pieter.
\newblock Incentivizing exploration in reinforcement learning with deep
  predictive models.
\newblock \emph{CoRR}, abs/1507.00814, 2015.

\bibitem[Stolle \& Precup(2002)Stolle and Precup]{learningoptions}
Stolle, Martin and Precup, Doina.
\newblock \emph{Learning Options in Reinforcement Learning}.
\newblock Springer Berlin Heidelberg, Berlin, Heidelberg, 2002.
\newblock ISBN 978-3-540-45622-3.
\newblock \doi{10.1007/3-540-45622-8_16}.

\bibitem[Strehl \& Littman(2009)Strehl and Littman]{mbieeb-strehl-08}
Strehl, Alexander~L. and Littman, Michael~L.
\newblock An analysis of model-based interval estimation for markov decision
  processes.
\newblock \emph{Journal of Computer and System Sciences}, 2009.

\bibitem[Tang et~al.(2016)Tang, Houthooft, Foote, Stooke, Chen, Duan, Schulman,
  Turck, and Abbeel]{hashexp-tang-16}
Tang, Haoran, Houthooft, Rein, Foote, Davis, Stooke, Adam, Chen, Xi, Duan, Yan,
  Schulman, John, Turck, Filip~De, and Abbeel, Pieter.
\newblock {\#}exploration: {A} study of count-based exploration for deep
  reinforcement learning.
\newblock \emph{CoRR}, abs/1611.04717, 2016.

\end{thebibliography}
