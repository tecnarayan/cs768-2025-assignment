\begin{thebibliography}{36}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Advani \& Saxe(2017)Advani and Saxe]{advani-17}
Advani, M.~S. and Saxe, A.~M.
\newblock High-dimensional dynamics of generalization error in neural networks.
\newblock \emph{arXiv preprint arXiv:1710.03667}, 2017.
\newblock URL \url{http://arxiv.org/abs/1710.03667}.

\bibitem[Au et~al.(2018)Au, Cébron, Dahlqvist, Gabriel, and Male]{au-18}
Au, B., Cébron, G., Dahlqvist, A., Gabriel, F., and Male, C.
\newblock Large permutation invariant random matrices are asymptotically free
  over the diagonal, 2018.
\newblock To appear in Annals of Probability.

\bibitem[Bai \& Wang(2008)Bai and Wang]{bai-2008}
Bai, Z. and Wang, Z.
\newblock Large sample covariance matrices without independence structures in
  columns.
\newblock \emph{Statistica Sinicia}, 18:\penalty0 425--442, 2008.

\bibitem[Bartlett et~al.(2019)Bartlett, Long, Lugosi, and Tsigler]{bartlett-19}
Bartlett, P.~L., Long, P.~M., Lugosi, G., and Tsigler, A.
\newblock Benign overfitting in linear regression.
\newblock \emph{arXiv preprint arXiv:1906.11300}, 2019.
\newblock URL \url{http://arxiv.org/abs/1906.11300}.

\bibitem[Belkin et~al.(2018)Belkin, Hsu, Ma, and Mandal]{belkin-18}
Belkin, M., Hsu, D., Ma, S., and Mandal, S.
\newblock Reconciling modern machine learning and the bias-variance trade-off.
\newblock \emph{arXiv preprint arXiv:1812.11118}, 2018.
\newblock URL \url{http://arxiv.org/abs/1812.11118}.

\bibitem[Belkin et~al.(2019)Belkin, Hsu, and Xu]{belkin-19}
Belkin, M., Hsu, D., and Xu, J.
\newblock Two models of double descent for weak features.
\newblock \emph{arXiv preprint arXiv:1903.07571}, 2019.
\newblock URL \url{http://arxiv.org/abs/1903.07571}.

\bibitem[Benigni \& P{\'e}ch{\'e}(2019)Benigni and P{\'e}ch{\'e}]{benigni-2019}
Benigni, L. and P{\'e}ch{\'e}, S.
\newblock Eigenvalue distribution of nonlinear models of random matrices.
\newblock \emph{arXiv preprint arXiv:1904.03090}, 2019.
\newblock URL \url{http://arxiv.org/abs/1904.03090}.

\bibitem[Bishop(2006)]{bishop-06}
Bishop, C.~M.
\newblock \emph{Pattern recognition and machine learning}.
\newblock springer, 2006.

\bibitem[Caponnetto \& De~Vito(2007)Caponnetto and De~Vito]{caponnetto-07}
Caponnetto, A. and De~Vito, E.
\newblock Optimal rates for the regularized least-squares algorithm.
\newblock \emph{Foundations of Computational Mathematics}, 7\penalty0
  (3):\penalty0 331--368, 2007.

\bibitem[d'Ascoli et~al.(2020)d'Ascoli, Refinetti, Biroli, and
  Krzakala]{ascoli-20}
d'Ascoli, S., Refinetti, M., Biroli, G., and Krzakala, F.
\newblock Double trouble in double descent: Bias and variance (s) in the lazy
  regime.
\newblock \emph{arXiv preprint arXiv:2003.01054}, 2020.

\bibitem[Dobriban \& Wager(2018)Dobriban and Wager]{dobriban2018}
Dobriban, E. and Wager, S.
\newblock High-dimensional asymptotics of prediction: Ridge regression and
  classification.
\newblock \emph{Ann. Statist.}, 46\penalty0 (1):\penalty0 247--279, 02 2018.
\newblock \doi{10.1214/17-AOS1549}.
\newblock URL \url{https://doi.org/10.1214/17-AOS1549}.

\bibitem[Eaton(2007)]{eaton-07}
Eaton, M.
\newblock Multivariate statistics: A vector space approach.
\newblock \emph{Journal of the American Statistical Association}, 80, 01 2007.
\newblock \doi{10.2307/20461449}.

\bibitem[Gabriel(2015)]{gabriel-15}
Gabriel, F.
\newblock Combinatorial theory of permutation-invariant random matrices ii:
  Cumulants, freeness and {L}evy processes.
\newblock \emph{arXiv preprint arXiv:1507.02465}, 2015.
\newblock URL \url{http://arxiv.org/abs/1507.02465}.

\bibitem[Geiger et~al.(2019)Geiger, Jacot, Spigler, Gabriel, Sagun, d'Ascoli,
  Biroli, Hongler, and Wyart]{geiger-19}
Geiger, M., Jacot, A., Spigler, S., Gabriel, F., Sagun, L., d'Ascoli, S.,
  Biroli, G., Hongler, C., and Wyart, M.
\newblock Scaling description of generalization with number of parameters in
  deep learning.
\newblock \emph{arXiv preprint arXiv:1901.01608}, 2019.
\newblock URL \url{http://arxiv.org/abs/1901.01608}.

\bibitem[Geman et~al.(1992)Geman, Bienenstock, and Doursat]{geman-92}
Geman, S., Bienenstock, E., and Doursat, R.
\newblock Neural networks and the bias/variance dilemma.
\newblock \emph{Neural computation}, 4\penalty0 (1):\penalty0 1--58, 1992.

\bibitem[Hastie et~al.(2019)Hastie, Montanari, Rosset, and
  Tibshirani]{hastie-19}
Hastie, T., Montanari, A., Rosset, S., and Tibshirani, R.~J.
\newblock Surprises in high-dimensional ridgeless least squares interpolation.
\newblock \emph{arXiv preprint arXiv:1903.08560}, 2019.
\newblock URL \url{http://arxiv.org/abs/1903.08560}.

\bibitem[Jacot et~al.(2018)Jacot, Gabriel, and Hongler]{jacot-18}
Jacot, A., Gabriel, F., and Hongler, C.
\newblock Neural tangent kernel: Convergence and generalization in neural
  networks.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Liu \& Dobriban(2020)Liu and Dobriban]{liu-20}
Liu, S. and Dobriban, E.
\newblock Ridge regression: Structure, cross-validation, and sketching.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=HklRwaEKwB}.

\bibitem[Louart et~al.(2017)Louart, Liao, and Couillet]{louart-17}
Louart, C., Liao, Z., and Couillet, R.
\newblock A random matrix approach to neural networks.
\newblock \emph{The Annals of Applied Probability}, 28, 02 2017.
\newblock \doi{10.1214/17-AAP1328}.

\bibitem[Marteau{-}Ferey et~al.(2019)Marteau{-}Ferey, Ostrovskii, Bach, and
  Rudi]{marteau-19}
Marteau{-}Ferey, U., Ostrovskii, D., Bach, F., and Rudi, A.
\newblock Beyond least-squares: Fast rates for regularized empirical risk
  minimization through self-concordance.
\newblock \emph{CoRR}, abs/1902.03046, 2019.
\newblock URL \url{http://arxiv.org/abs/1902.03046}.

\bibitem[Mei \& Montanari(2019)Mei and Montanari]{mei-19}
Mei, S. and Montanari, A.
\newblock The generalization error of random features regression: Precise
  asymptotics and double descent curve.
\newblock \emph{arXiv preprint arXiv:1908.05355}, 2019.
\newblock URL \url{http://arxiv.org/abs/1908.05355}.

\bibitem[Nakkiran et~al.(2019)Nakkiran, Kaplun, Bansal, Yang, Barak, and
  Sutskever]{nakkiran-19}
Nakkiran, P., Kaplun, G., Bansal, Y., Yang, T., Barak, B., and Sutskever, I.
\newblock Deep double descent: Where bigger models and more data hurt.
\newblock \emph{arXiv preprint arXiv:1912.02292}, 2019.
\newblock URL \url{http://arxiv.org/abs/1912.02292}.

\bibitem[Neal et~al.(2018)Neal, Mittal, Baratin, Tantia, Scicluna,
  Lacoste-Julien, and Mitliagkas]{neal-18}
Neal, B., Mittal, S., Baratin, A., Tantia, V., Scicluna, M., Lacoste-Julien,
  S., and Mitliagkas, I.
\newblock A modern take on the bias-variance tradeoff in neural networks.
\newblock \emph{arXiv preprint arXiv:1810.08591}, 2018.
\newblock URL \url{http://arxiv.org/abs/1810.08591}.

\bibitem[Neyshabur et~al.(2014)Neyshabur, Tomioka, and Srebro]{neyshabur-14}
Neyshabur, B., Tomioka, R., and Srebro, N.
\newblock In search of the real inductive bias: On the role of implicit
  regularization in deep learning.
\newblock \emph{arXiv preprint arXiv:1412.6614}, 2014.
\newblock URL \url{http://arxiv.org/abs/1412.6614}.

\bibitem[Rahimi \& Recht(2008)Rahimi and Recht]{rahimi-08}
Rahimi, A. and Recht, B.
\newblock Random features for large-scale kernel machines.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1177--1184, 2008.

\bibitem[Rahimi \& Recht(2009)Rahimi and Recht]{rahimi-09}
Rahimi, A. and Recht, B.
\newblock Weighted sums of random kitchen sinks: Replacing minimization with
  randomization in learning.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1313--1320, 2009.

\bibitem[Rudi \& Rosasco(2017)Rudi and Rosasco]{rudi-17}
Rudi, A. and Rosasco, L.
\newblock Generalization properties of learning with random features.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3215--3225, 2017.

\bibitem[Sch{\"o}lkopf et~al.(1998)Sch{\"o}lkopf, Smola, and
  M{\"u}ller]{Scholkopf-1998}
Sch{\"o}lkopf, B., Smola, A., and M{\"u}ller, K.-R.
\newblock {Nonlinear component analysis as a kernel eigenvalue problem}.
\newblock \emph{Neural Computation}, 10\penalty0 (5):\penalty0 1299--1319,
  1998.

\bibitem[Silverstein(1995)]{silverstein-1995}
Silverstein, J.
\newblock Strong convergence of the empirical distribution of eigenvalues of
  large dimensional random matrices.
\newblock \emph{Journal of Multivariate Analysis}, 55\penalty0 (2):\penalty0
  331 -- 339, 1995.
\newblock ISSN 0047-259X.
\newblock \doi{https://doi.org/10.1006/jmva.1995.1083}.
\newblock URL
  \url{http://www.sciencedirect.com/science/article/pii/S0047259X85710834}.

\bibitem[Speicher(2017)]{speicher-17}
Speicher, R.
\newblock Free probability and random matrices.
\newblock In \emph{Free Probability and Random Matrices}, 2017.

\bibitem[Spigler et~al.(2018)Spigler, Geiger, d'Ascoli, Sagun, Biroli, and
  Wyart]{spigler-18}
Spigler, S., Geiger, M., d'Ascoli, S., Sagun, L., Biroli, G., and Wyart, M.
\newblock A jamming transition from under-to over-parametrization affects loss
  landscape and generalization.
\newblock \emph{arXiv preprint arXiv:1810.09665}, 2018.
\newblock URL \url{http://arxiv.org/abs/1810.09665}.

\bibitem[Sriperumbudur \& Szab{\'o}(2015)Sriperumbudur and
  Szab{\'o}]{sriperumbudur-15}
Sriperumbudur, B. and Szab{\'o}, Z.
\newblock Optimal rates for random fourier features.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1144--1152, 2015.

\bibitem[Yang et~al.(2012)Yang, Li, Mahdavi, Jin, and Zhou]{yang-12}
Yang, T., Li, Y.-F., Mahdavi, M., Jin, R., and Zhou, Z.-H.
\newblock Nystr{\"o}m method vs random {F}ourier features: A theoretical and
  empirical comparison.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  476--484, 2012.

\bibitem[Yu et~al.(2016)Yu, Suresh, Choromanski, Holtmann-Rice, and
  Kumar]{yu-16}
Yu, F. X.~X., Suresh, A.~T., Choromanski, K.~M., Holtmann-Rice, D.~N., and
  Kumar, S.
\newblock Orthogonal random features.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1975--1983, 2016.

\bibitem[Zhang et~al.(2016)Zhang, Bengio, Hardt, Recht, and Vinyals]{zhang-16}
Zhang, C., Bengio, S., Hardt, M., Recht, B., and Vinyals, O.
\newblock Understanding deep learning requires rethinking generalization.
\newblock \emph{arXiv preprint arXiv:1611.03530}, 2016.
\newblock URL \url{http://arxiv.org/abs/1611.03530}.

\bibitem[Zhang(2003)]{zhang-03}
Zhang, T.
\newblock Effective dimension and generalization of kernel learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  471--478, 2003.

\end{thebibliography}
