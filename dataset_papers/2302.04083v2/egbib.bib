@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@inproceedings{du2021efficient,
  title={Efficient Sharpness-aware Minimization for Improved Training of Neural Networks},
  author={Du, Jiawei and Yan, Hanshu and Feng, Jiashi and Zhou, Joey Tianyi and Zhen, Liangli and Goh, Rick Siow Mong and Tan, Vincent},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{liu2022towards,
  title={Towards efficient and scalable sharpness-aware minimization},
  author={Liu, Yong and Mai, Siqi and Chen, Xiangning and Hsieh, Cho-Jui and You, Yang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12360--12370},
  year={2022}
}

@article{bottou2018optimization,
  title={Optimization methods for large-scale machine learning},
  author={Bottou, L{\'e}on and Curtis, Frank E and Nocedal, Jorge},
  journal={Siam Review},
  volume={60},
  number={2},
  pages={223--311},
  year={2018},
  publisher={SIAM}
}

@inproceedings{kwon2021asam,
  title={Asam: Adaptive sharpness-aware minimization for scale-invariant learning of deep neural networks},
  author={Kwon, Jungmin and Kim, Jeongseop and Park, Hyunseo and Choi, In Kwon},
  booktitle={International Conference on Machine Learning},
  pages={5905--5914},
  year={2021},
  organization={PMLR}
}

@incollection{bottou2010large,
  title={Large-scale machine learning with stochastic gradient descent},
  author={Bottou, L{\'e}on},
  booktitle={Proceedings of COMPSTAT'2010},
  pages={177--186},
  year={2010},
  publisher={Springer}
}

@article{wang2021field,
  title={A field guide to federated optimization},
  author={Wang, Jianyu and Charles, Zachary and Xu, Zheng and Joshi, Gauri and McMahan, H Brendan and Al-Shedivat, Maruan and Andrew, Galen and Avestimehr, Salman and Daly, Katharine and Data, Deepesh and others},
  journal={arXiv preprint arXiv:2107.06917},
  year={2021}
}

@article{nedic2009distributed,
  title={Distributed subgradient methods for multi-agent optimization},
  author={Nedic, Angelia and Ozdaglar, Asuman},
  journal={IEEE Transactions on Automatic Control},
  volume={54},
  number={1},
  pages={48--61},
  year={2009},
  publisher={IEEE}
}

@article{salem2018ml,
  title={Ml-leaks: Model and data independent membership inference attacks and defenses on machine learning models},
  author={Salem, Ahmed and Zhang, Yang and Humbert, Mathias and Berrang, Pascal and Fritz, Mario and Backes, Michael},
  journal={In Annual Network and Distributed System Security Symposium (NDSS 2019)},
  year={2019}
}



@article{2019Advances,
  title={Advances and Open Problems in Federated Learning},
  author={McMahan, H Brendan and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={14},
  number={1},
  year={2021},
  publisher={Now Publishers, Inc.}
}
@article{izmailov2018averaging,
  title={Averaging weights leads to wider optima and better generalization},
  author={Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},
  journal={arXiv preprint arXiv:1803.05407},
  year={2018}
}
@article{li2018visualizing,
  title={Visualizing the loss landscape of neural nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@article{li2019federated,
title={Federated Learning: Challenges, Methods, and Future Directions.},
author={Li, Tian and Sahu, Anit Kumar and Talwalkar, Ameet and Smith, Virginia},
journal={arXiv: Learning},
year={2019}}

@inproceedings{chen2021communication,
  title={Communication efficient primal-dual algorithm for nonconvex nonsmooth distributed optimization},
  author={Chen, Congliang and Zhang, Jiawei and Shen, Li and Zhao, Peilin and Luo, Zhiquan},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1594--1602},
  year={2021},
  organization={PMLR}
}

@article{sun2023fedspeed,
  title={Fedspeed: Larger local interval, less communication round, and higher generalization accuracy},
  author={Sun, Yan and Shen, Li and Huang, Tiansheng and Ding, Liang and Tao, Dacheng},
  journal={arXiv preprint arXiv:2302.10429},
  year={2023}
}

@article{zhong2022improving,
  title={Improving Sharpness-Aware Minimization with Fisher Mask for Better Generalization on Language Models},
  author={Zhong, Qihuang and Ding, Liang and Shen, Li and Mi, Peng and Liu, Juhua and Du, Bo and Tao, Dacheng},
  journal={arXiv preprint arXiv:2210.05497},
  year={2022}
}

@article{mi2022make,
  title={Make sharpness-aware minimization stronger: A sparsified perturbation approach},
  author={Mi, Peng and Shen, Li and Ren, Tianhe and Zhou, Yiyi and Sun, Xiaoshuai and Ji, Rongrong and Tao, Dacheng},
  journal={arXiv preprint arXiv:2210.05177},
  year={2022}
}

@article{xiao2017fashion,
  title={Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms},
  author={Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  journal={arXiv preprint arXiv:1708.07747},
  year={2017},
  }
@inproceedings{
reddi2020adaptive,
title={Adaptive Federated Optimization},
author={Sashank J. Reddi and Zachary Charles and Manzil Zaheer and Zachary Garrett and Keith Rush and Jakub Kone{\v{c}}n{\'y} and Sanjiv Kumar and Hugh Brendan McMahan},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=LkFG3lB13U5}
}


@article{sahu2018convergence,
  title={On the convergence of federated optimization in heterogeneous networks},
  author={Sahu, Anit Kumar and Li, Tian and Sanjabi, Maziar and Zaheer, Manzil and Talwalkar, Ameet and Smith, Virginia},
  journal={arXiv preprint arXiv:1812.06127},
  pages={3},
  year={2018}
}


@inproceedings{lian2017can,
  title={Can decentralized algorithms outperform centralized algorithms? a case study for decentralized parallel stochastic gradient descent},
  author={Lian, Xiangru and Zhang, Ce and Zhang, Huan and Hsieh, Cho-Jui and Zhang, Wei and Liu, Ji},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5330--5340},
  year={2017}
}

@article{shi2023make,
  title={Make Landscape Flatter in Differentially Private Federated Learning},
  author={Shi, Yifan and Liu, Yingqi and Wei, Kang and Shen, Li and Wang, Xueqian and Tao, Dacheng},
  journal={arXiv preprint arXiv:2303.11242},
  year={2023}
}

@inproceedings{yu2020proactive,
  title={Proactive content caching for internet-of-vehicles based on peer-to-peer federated learning},
  author={Yu, Zhengxin and Hu, Jia and Min, Geyong and Xu, Han and Mills, Jed},
  booktitle={2020 IEEE 26th International Conference on Parallel and Distributed Systems (ICPADS)},
  pages={601--608},
  year={2020},
  organization={IEEE}
}

@article{nguyen2022novel,
  title={A novel decentralized federated learning approach to train on globally distributed, poor quality, and protected private medical data},
  author={Nguyen, TV and Dakka, MA and Diakiw, SM and VerMilyea, MD and Perugini, M and Hall, JMM and Perugini, D},
  journal={Scientific Reports},
  volume={12},
  number={1},
  pages={8888},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

@article{zhang2020personalized,
  title={Personalized federated learning with first order model optimization},
  author={Zhang, Michael and Sapra, Karan and Fidler, Sanja and Yeung, Serena and Alvarez, Jose M},
  journal={arXiv preprint arXiv:2012.08565},
  year={2020}
}

@inproceedings{li2021ditto,
  title={Ditto: Fair and robust federated learning through personalization},
  author={Li, Tian and Hu, Shengyuan and Beirami, Ahmad and Smith, Virginia},
  booktitle={International Conference on Machine Learning},
  pages={6357--6368},
  year={2021},
  organization={PMLR}
}

@inproceedings{huang2021personalized,
  title={Personalized cross-silo federated learning on non-iid data},
  author={Huang, Yutao and Chu, Lingyang and Zhou, Zirui and Wang, Lanjun and Liu, Jiangchuan and Pei, Jian and Zhang, Yong},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={9},
  pages={7865--7873},
  year={2021}
}
@article{deng2020adaptive,
  title={Adaptive personalized federated learning},
  author={Deng, Yuyang and Kamani, Mohammad Mahdi and Mahdavi, Mehrdad},
  journal={arXiv preprint arXiv:2003.13461},
  year={2020}
}
@article{chen2021bridging,
  title={On bridging generic and personalized federated learning for image classification},
  author={Chen, Hong-You and Chao, Wei-Lun},
  journal={arXiv preprint arXiv:2107.00778},
  year={2021}
}

@inproceedings{yao2020pyhessian,
  title={Pyhessian: Neural networks through the lens of the hessian},
  author={Yao, Zhewei and Gholami, Amir and Keutzer, Kurt and Mahoney, Michael W},
  booktitle={2020 IEEE international conference on big data (Big data)},
  pages={581--590},
  year={2020},
  organization={IEEE}
}

@article{wang2022accelerating,
  title={Accelerating decentralized federated learning in heterogeneous edge computing},
  author={Wang, Lun and Xu, Yang and Xu, Hongli and Chen, Min and Huang, Liusheng},
  journal={IEEE Transactions on Mobile Computing},
  year={2022},
  publisher={IEEE}
}

@article{wang2020learning,
  title={Learning in the air: Secure federated learning for UAV-assisted crowdsensing},
  author={Wang, Yuntao and Su, Zhou and Zhang, Ning and Benslimane, Abderrahim},
  journal={IEEE Transactions on network science and engineering},
  volume={8},
  number={2},
  pages={1055--1069},
  year={2020},
  publisher={IEEE}
}

@inproceedings{kang2022blockchain,
  title={Blockchain-based federated learning for industrial metaverses: Incentive scheme with optimal aoi},
  author={Kang, Jiawen and Ye, Dongdong and Nie, Jiangtian and Xiao, Jiang and Deng, Xianjun and Wang, Siming and Xiong, Zehui and Yu, Rong and Niyato, Dusit},
  booktitle={2022 IEEE International Conference on Blockchain (Blockchain)},
  pages={71--78},
  year={2022},
  organization={IEEE}
}
@ARTICLE{LiJunBlockchain,
  author={Li, Jun and Shao, Yumeng and Wei, Kang and Ding, Ming and Ma, Chuan and Shi, Long and Han, Zhu and Poor, H. Vincent},
  journal={IEEE Transactions on Parallel and Distributed Systems}, 
  title={Blockchain Assisted Decentralized Federated Learning (BLADE-FL): Performance Analysis and Resource Allocation}, 
  year={2022},
  volume={33},
  number={10},
  pages={2401-2415},
  doi={10.1109/TPDS.2021.3138848}}
  
@article{beltran2022decentralized,
  title={Decentralized Federated Learning: Fundamentals, State-of-the-art, Frameworks, Trends, and Challenges},
  author={Beltr{\'a}n, Enrique Tom{\'a}s Mart{\'\i}nez and P{\'e}rez, Mario Quiles and S{\'a}nchez, Pedro Miguel S{\'a}nchez and Bernal, Sergio L{\'o}pez and Bovet, G{\'e}r{\^o}me and P{\'e}rez, Manuel Gil and P{\'e}rez, Gregorio Mart{\'\i}nez and Celdr{\'a}n, Alberto Huertas},
  journal={arXiv preprint arXiv:2211.08413},
  year={2022}
}


@article{shalev2011pegasos,
  title={Pegasos: Primal estimated sub-gradient solver for svm},
  author={Shalev-Shwartz, Shai and Singer, Yoram and Srebro, Nathan and Cotter, Andrew},
  journal={Mathematical programming},
  volume={127},
  number={1},
  pages={3--30},
  year={2011},
  publisher={Springer}
}


@article{boyd2004fastest,
  title={Fastest mixing Markov chain on a graph},
  author={Boyd, Stephen and Diaconis, Persi and Xiao, Lin},
  journal={SIAM review},
  volume={46},
  number={4},
  pages={667--689},
  year={2004},
  publisher={SIAM}
}



@article{nemirovski2009robust,
  title={Robust stochastic approximation approach to stochastic programming},
  author={Nemirovski, Arkadi and Juditsky, Anatoli and Lan, Guanghui and Shapiro, Alexander},
  journal={SIAM Journal on optimization},
  volume={19},
  number={4},
  pages={1574--1609},
  year={2009},
  publisher={SIAM}
}


@article{robbins1951a,
title={A Stochastic Approximation Method},
author={Robbins, Herbert and Monro, Sutton},
journal={Annals of Mathematical Statistics},
volume={22},
number={3},
pages={400--407},
year={1951}}


@inproceedings{lalitha2018fully,
  title={Fully decentralized federated learning},
  author={Lalitha, Anusha and Shekhar, Shubhanshu and Javidi, Tara and Koushanfar, Farinaz},
  booktitle={Third workshop on Bayesian Deep Learning (NeurIPS)},
  year={2018}
}

@article{nguyen2018sgd,
  title={SGD and Hogwild! convergence without the bounded gradients assumption},
  author={Nguyen, Lam M and Nguyen, Phuong Ha and van Dijk, Marten and Richt{\'a}rik, Peter and Scheinberg, Katya and Tak{\'a}{\v{c}}, Martin},
  journal={arXiv preprint arXiv:1802.03801},
  year={2018}
}

@article{ghadimi2013stochastic,
  title={Stochastic first-and zeroth-order methods for nonconvex stochastic programming},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={SIAM Journal on Optimization},
  volume={23},
  number={4},
  pages={2341--2368},
  year={2013},
  publisher={SIAM}
}


@article{polyak1964some,
title={Some methods of speeding up the convergence of iteration methods},
author={Polyak, B T},
journal={Ussr Computational Mathematics and Mathematical Physics},
volume={4},
number={5},
pages={1--17},
year={1964}}


@inproceedings{sutskever2013importance,
  title={On the importance of initialization and momentum in deep learning},
  author={Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1139--1147},
  year={2013}
}


@book{nesterov2018lectures,
  title={Lectures on convex optimization},
  author={Nesterov, Yurii},
  volume={137},
  year={2018},
  publisher={Springer}
}

@article{sun2019convergence,
  title={Convergence rates of accelerated proximal gradient algorithms under independent noise},
  author={Sun, Tao and Barrio, Roberto and Jiang, Hao and Cheng, Lizhi},
  journal={Numerical Algorithms},
  volume={81},
  number={2},
  pages={631--654},
  year={2019},
  publisher={Springer}
}


@inproceedings{sun2018markov,
  title={On Markov chain gradient descent},
  author={Sun, Tao and Sun, Yuejiao and Yin, Wotao},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9896--9905},
  year={2018}
}


@article{polyak1963gradient,
  title={Gradient methods for minimizing functionals},
  author={Polyak, Boris Teodorovich},
  journal={Zhurnal Vychislitel'noi Matematiki i Matematicheskoi Fiziki},
  volume={3},
  number={4},
  pages={643--653},
  year={1963},
  publisher={Russian Academy of Sciences, Branch of Mathematical Sciences}
}

@article{lojasiewicz1963topological,
  title={A topological property of real analytic subsets},
  author={Lojasiewicz, Stanislaw},
  journal={Coll. du CNRS, Les {\'e}quations aux d{\'e}riv{\'e}es partielles},
  volume={117},
  pages={87--89},
  year={1963}
}

@inproceedings{karimi2016linear,
  title={Linear convergence of gradient and proximal-gradient methods under the polyak-{\l}ojasiewicz condition},
  author={Karimi, Hamed and Nutini, Julie and Schmidt, Mark},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={795--811},
  year={2016},
  organization={Springer}
}


@inproceedings{reddi2016stochastic,
  title={Stochastic variance reduction for nonconvex optimization},
  author={Reddi, Sashank J and Hefny, Ahmed and Sra, Suvrit and Poczos, Barnabas and Smola, Alex},
  booktitle={International conference on machine learning},
  pages={314--323},
  year={2016}
}

@inproceedings{Rong2022DisPFL,
  author    = {Rong Dai and
               Li Shen and
               Fengxiang He and
               Xinmei Tian and
               Dacheng Tao},
  title     = {DisPFL: Towards Communication-Efficient Personalized Federated Learning
               via Decentralized Sparse Training},
  booktitle = {International Conference on Machine Learning, {ICML}},
  series    = {Proceedings of Machine Learning Research},
  pages     = {4587--4604},
  publisher = {{PMLR}},
  year      = {2022},
  
}

@inproceedings{Andriushchenko2022Towards,
  author    = {Maksym Andriushchenko and
               Nicolas Flammarion},
  title     = {Towards Understanding Sharpness-Aware Minimization},
  booktitle = {International Conference on Machine Learning, {ICML}},
  series    = {Proceedings of Machine Learning Research},
  pages     = {639--668},
  publisher = {{PMLR}},
  year      = {2022}
}

@inproceedings{koloskova2019decentralized,
  title={Decentralized stochastic optimization and gossip algorithms with compressed communication},
  author={Koloskova, Anastasia and Stich, Sebastian and Jaggi, Martin},
  booktitle={International Conference on Machine Learning},
  pages={3478--3487},
  year={2019},
  organization={PMLR}
}

@inproceedings{zhu2022topology,
  title={Topology-aware Generalization of Decentralized SGD},
  author={Zhu, Tongtian and He, Fengxiang and Zhang, Lan and Niu, Zhengyang and Song, Mingli and Tao, Dacheng},
  booktitle={International Conference on Machine Learning, {ICML}},
  pages={27479--27503},
  year={2022},
  organization={PMLR}
}

@article{balles2017dissecting,
  title={Dissecting adam: The sign, magnitude and variance of stochastic gradients},
  author={Balles, Lukas and Hennig, Philipp},
  journal={arXiv preprint arXiv:1705.07774},
  year={2017}
}


@article{lei2019stochastic,
  title={Stochastic Gradient Descent for Nonconvex Learning without Bounded Gradient Assumptions},
  author={Lei, Yunwen and Hu, Ting and Tang, Ke},
  journal={arXiv preprint arXiv:1902.00908},
  year={2019}
}

@inproceedings{gong2021ensemble,
  title={Ensemble Attention Distillation for Privacy-Preserving Federated Learning},
  author={Gong, Xuan and Sharma, Abhishek and Karanam, Srikrishna and Wu, Ziyan and Chen, Terrence and Doermann, David and Innanje, Arun},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={15076--15086},
  year={2021}
}

@inproceedings{lin2020ensemble,
  title={Ensemble Distillation for Robust Model Fusion in Federated Learning},
  author={Lin, Tao and Kong, Lingjing and Stich, Sebastian U and Jaggi, Martin},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}

@inproceedings{
acar2021federated,
title={Federated Learning Based on Dynamic Regularization},
author={Durmus Alp Emre Acar and Yue Zhao and Ramon Matas and Matthew Mattina and Paul Whatmough and Venkatesh Saligrama},
booktitle={International Conference on Learning Representations},
year={2021}
}

@inproceedings{yang2021achieving,
title={Achieving Linear Speedup with Partial Worker Participation in Non-{IID} Federated Learning},
author={Haibo Yang and Minghong Fang and Jia Liu},
booktitle={International Conference on Learning Representations},
year={2021}
}

@inproceedings{Li2020On,
title={On the Convergence of FedAvg on Non-IID Data},
author={Xiang Li and Kaixuan Huang and Wenhao Yang and Shusen Wang and Zhihua Zhang},
booktitle={International Conference on Learning Representations},
year={2020}
}

@inproceedings{Zhao2022Penalizing,
  author    = {Yang Zhao and
               Hao Zhang and
               Xiuyuan Hu},
  title     = {Penalizing Gradient Norm for Efficiently Improving Generalization
               in Deep Learning},
  booktitle = {International Conference on Machine Learning, {ICML}},
  pages     = {26982--26992},
  publisher = {{PMLR}},
  year      = {2022},
}

@inproceedings{Abbas2022Sharp-MAML,
  author    = {Momin Abbas and
               Quan Xiao and
               Lisha Chen and
               Pin{-}Yu Chen and
               Tianyi Chen},
  title     = {Sharp-MAML: Sharpness-Aware Model-Agnostic Meta Learning},
  booktitle = {International Conference on Machine Learning, {ICML}},
  pages     = {10--32},
  year      = {2022},
}


@article{li2022trainable,
  title={Trainable Weight Averaging for Fast Convergence and Better Generalization},
  author={Li, Tao and Huang, Zhehao and Tao, Qinghua and Wu, Yingwen and Huang, Xiaolin},
  journal={arXiv preprint arXiv:2205.13104},
  year={2022}
}

@article{Caldarola2022Improving,
  author    = {Debora Caldarola and
               Barbara Caputo and
               Marco Ciccone},
  title     = {Improving Generalization in Federated Learning by Seeking Flat Minima},
  journal   = {CoRR},
  volume    = {abs/2203.11834},
  year      = {2022},
}

@article{zhang2022net,
  title={Net-fleet: Achieving linear convergence speedup for fully decentralized federated learning with heterogeneous data},
  author={Zhang, Xin and Fang, Minghong and Liu, Zhuqing and Yang, Haibo and Liu, Jia and Zhu, Zhengyuan},
  journal={arXiv preprint arXiv:2208.08490},
  year={2022}
}

@article{rakhlin2011making,
  title={Making gradient descent optimal for strongly convex stochastic optimization},
  author={Rakhlin, Alexander and Shamir, Ohad and Sridharan, Karthik},
  journal={arXiv preprint arXiv:1109.5647},
  year={2011}
}

@article{yuan2021defed,
  title={DeFed: A Principled Decentralized and Privacy-Preserving Federated Learning Algorithm},
  author={Yuan, Ye and Chen, Ruijuan and Sun, Chuan and Wang, Maolin and Hua, Feng and Yi, Xinlei and Yang, Tao and Liu, Jun},
  journal={arXiv preprint arXiv:2107.07171},
  year={2021}
}

@article{nguyen2018sgd,
  title={SGD and Hogwild! convergence without the bounded gradients assumption},
  author={Nguyen, Lam M and Nguyen, Phuong Ha and van Dijk, Marten and Richt{\'a}rik, Peter and Scheinberg, Katya and Tak{\'a}{\v{c}}, Martin},
  journal={arXiv preprint arXiv:1802.03801},
  year={2018}
}

@article{lalitha2019peer,
  title={Peer-to-peer federated learning on graphs},
  author={Lalitha, Anusha and Kilinc, Osman Cihan and Javidi, Tara and Koushanfar, Farinaz},
  journal={arXiv preprint arXiv:1901.11173},
  year={2019}
}

@article{roy2019braintorrent,
  title={Braintorrent: A peer-to-peer environment for decentralized federated learning},
  author={Roy, Abhijit Guha and Siddiqui, Shayan and P{\"o}lsterl, Sebastian and Navab, Nassir and Wachinger, Christian},
  journal={arXiv preprint arXiv:1905.06731},
  year={2019}
}

@article{warnat2021swarm,
  title={Swarm learning for decentralized and confidential clinical machine learning},
  author={Warnat-Herresthal, Stefanie and Schultze, Hartmut and Shastry, Krishnaprasad Lingadahalli and Manamohan, Sathyanarayanan and Mukherjee, Saikat and Garg, Vishesh and Sarveswara, Ravi and H{\"a}ndler, Kristian and Pickkers, Peter and Aziz, N Ahmad and others},
  journal={Nature},
  pages={265--270},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{zhu2021data,
  title={Data-Free Knowledge Distillation for Heterogeneous Federated Learning},
  author={Zhu, Zhuangdi and Hong, Junyuan and Zhou, Jiayu},
  journal={arXiv preprint arXiv:2105.10056},
  year={2021}
}

@article{robbins1951stochastic,
  title={A stochastic approximation method},
  author={Robbins, Herbert and Monro, Sutton},
  journal={The annals of mathematical statistics},
  pages={400--407},
  year={1951},
  publisher={JSTOR}
}

@article{karimireddy2019error,
  title={Error feedback fixes signsgd and other gradient compression schemes},
  author={Karimireddy, Sai Praneeth and Rebjock, Quentin and Stich, Sebastian U and Jaggi, Martin},
  journal={arXiv preprint arXiv:1901.09847},
  year={2019}
}

@ARTICLE{Li2020fl,
  author={Li, Tian and Sahu, Anit Kumar and Talwalkar, Ameet and Smith, Virginia},
  journal={IEEE Signal Processing Magazine}, 
  title={Federated Learning: {Challenges}, Methods, and Future Directions}, 
  year={2020},
  volume={},
  number={},
  pages={50-60},}

@article{li2020federated,
  title={Federated optimization in heterogeneous networks},
  author={Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
  journal={Proceedings of Machine Learning and Systems},
  pages={429--450},
  year={2020}
}

@article{kairouz2021Advances,
  title={Advances and open problems in federated learning},
  author={Kairouz, Peter and McMahan, H Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and others},
  journal={Foundations and Trends in Machine Learning},
  volume={},
  number={},
  pages={1-210},
  year={2021},}

@inproceedings{Durmus2021Federated,
  author    = {Durmus Alp Emre Acar and
               Yue Zhao and
               Ramon Matas Navarro and
               Matthew Mattina and
               Paul N. Whatmough and
               Venkatesh Saligrama},
  title     = {Federated Learning Based on Dynamic Regularization},
  booktitle = {9th International Conference on Learning Representations, {ICLR}},
  year      = {2021},
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Citeseer}
}

@article{wang2022fedadmm,
  title={FedADMM: A Federated Primal-Dual Algorithm Allowing Partial Participation},
  author={Wang, Han and Marella, Siddartha and Anderson, James},
  journal={arXiv preprint arXiv:2203.15104},
  year={2022}
}

@inproceedings{foster2018uniform,
  title={Uniform convergence of gradients for non-convex learning and optimization},
  author={Foster, Dylan J and Sekhari, Ayush and Sridharan, Karthik},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8745--8756},
  year={2018}
}

@inproceedings{sun2017asynchronous,
  title={Asynchronous coordinate descent under more realistic assumptions},
  author={Sun, Tao and Hannah, Robert and Yin, Wotao},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6182--6190},
  year={2017}
}

@article{sun2018non,
  title={Non-ergodic Convergence Analysis of Heavy-Ball Algorithms},
  author={Sun, Tao and Yin, Penghang and Li, Dongsheng and Huang, Chun and Guan, Lei and Jiang, Hao},
  journal={AAAI   Conference on Artificial Intelligence},
  year={2019}
}
@inproceedings{agarwal2010optimal,
  title={Optimal Algorithms for Online Convex Optimization with Multi-Point Bandit Feedback.},
  author={Agarwal, Alekh and Dekel, Ofer and Xiao, Lin},
  booktitle={COLT},
  pages={28--40},
  year={2010},
  organization={Citeseer}
}

@inproceedings{papernot2017practical,
  title={Practical black-box attacks against machine learning},
  author={Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z Berkay and Swami, Ananthram},
  booktitle={Proceedings of the 2017 ACM on Asia conference on computer and communications security},
  pages={506--519},
  year={2017},
  organization={ACM}
}

@inproceedings{karimireddy2020scaffold,
  title={Scaffold: Stochastic controlled averaging for federated learning},
  author={Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
  booktitle={International Conference on Machine Learning},
  pages={5132--5143},
  year={2020},
  organization={PMLR}
}

@article{shamir2017optimal,
  title={An Optimal Algorithm for Bandit and Zero-Order Convex Optimization with Two-Point Feedback.},
  author={Shamir, Ohad},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={52},
  pages={1--11},
  year={2017}
}



@incollection{robbins1971convergence,
  title={A convergence theorem for non negative almost supermartingales and some applications},
  author={Robbins, Herbert and Siegmund, David},
  booktitle={Optimizing methods in statistics},
  pages={233--257},
  year={1971},
  publisher={Elsevier}
}

@article{rakhlin2011making,
  title={Making gradient descent optimal for strongly convex stochastic optimization},
  author={Rakhlin, Alexander and Shamir, Ohad and Sridharan, Karthik},
  journal={arXiv preprint arXiv:1109.5647},
  year={2011}
}

@article{lei2019stochastic,
  title={Stochastic Gradient Descent for Nonconvex Learning without Bounded Gradient Assumptions},
  author={Lei, Yunwen and Hu, Ting and Tang, Ke},
  journal={arXiv preprint arXiv:1902.00908},
  year={2019}
}

@inproceedings{riedmiller1993direct,
  title={A direct adaptive method for faster backpropagation learning: The RPROP algorithm},
  author={Riedmiller, Martin and Braun, Heinrich},
  booktitle={Proceedings of the IEEE international conference on neural networks},
  volume={1993},
  pages={586--591},
  year={1993},
  organization={San Francisco}
}

@article{tieleman2012lecture,
  title={Lecture 6.5-rmsprop, coursera: Neural networks for machine learning},
  author={Tieleman, Tijmen and Hinton, Geoffrey},
  journal={University of Toronto, Technical Report},
  year={2012}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={ICLR},
  year={2014}
}

@inproceedings{seide20141,
  title={1-bit stochastic gradient descent and its application to data-parallel distributed training of speech dnns},
  author={Seide, Frank and Fu, Hao and Droppo, Jasha and Li, Gang and Yu, Dong},
  booktitle={Fifteenth Annual Conference of the International Speech Communication Association},
  year={2014}
}
@inproceedings{alistarh2017qsgd,
  title={{QSGD}: Communication-efficient {SGD} via gradient quantization and encoding},
  author={Alistarh, Dan and Grubic, Demjan and Li, Jerry and Tomioka, Ryota and Vojnovic, Milan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1709--1720},
  year={2017}
}

@article{bernstein2018signsgd,
  title={signSGD with majority vote is communication efficient and fault tolerant},
  author={Bernstein, Jeremy and Zhao, Jiawei and Azizzadenesheli, Kamyar and Anandkumar, Anima},
  journal={arXiv},
  year={2018}
}

@article{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={arXiv preprint arXiv:1706.06083},
  year={2017}
}
@inproceedings{yu2019parallel,
  title={Parallel restarted SGD with faster convergence and less communication: Demystifying why model averaging works for deep learning},
  author={Yu, Hao and Yang, Sen and Zhu, Shenghuo},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  pages={5693--5700},
  year={2019}
}
@article{makhzani2015adversarial,
  title={Adversarial autoencoders},
  author={Makhzani, Alireza and Shlens, Jonathon and Jaitly, Navdeep and Goodfellow, Ian and Frey, Brendan},
  journal={arXiv preprint arXiv:1511.05644},
  year={2015}
}

@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}

@article{liu2018signsgd,
  title={signSGD via zeroth-order oracle},
  author={Liu, Sijia and Chen, Pin-Yu and Chen, Xiangyi and Hong, Mingyi},
  year={2018}
}
@inproceedings{koloskova2020unified,
  title={A unified theory of decentralized sgd with changing topology and local updates},
  author={Koloskova, Anastasia and Loizou, Nicolas and Boreiri, Sadra and Jaggi, Martin and Stich, Sebastian},
  booktitle={International Conference on Machine Learning},
  pages={5381--5393},
  year={2020},
  organization={PMLR}
}

@inproceedings{chen2018lag,
  title={LAG: Lazily aggregated gradient for communication-efficient distributed learning},
  author={Chen, Tianyi and Giannakis, Georgios and Sun, Tao and Yin, Wotao},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5050--5060},
  year={2018}
}

@inproceedings{xu2019signprox,
  title={signProx: One-Bit Proximal Algorithm for Nonconvex Stochastic Optimization},
  author={Xu, Xiaojian and Kamilov, Ulugbek S},
  booktitle={ICASSP 2019},
  pages={7800--7804},
  year={2019},
  organization={IEEE}
}

@inproceedings{li2014scaling,
  title={Scaling distributed machine learning with the parameter server},
  author={Li, Mu and Andersen, David G and Park, Jun Woo and Smola, Alexander J and Ahmed, Amr and Josifovski, Vanja and Long, James and Shekita, Eugene J and Su, Bor-Yiing},
  booktitle={11th $\{$USENIX$\}$ Symposium on Operating Systems Design and Implementation ($\{$OSDI$\}$ 14)},
  pages={583--598},
  year={2014}
}


@article{bernstein2018signsgd,
  title={signSGD: Compressed optimisation for non-convex problems},
  author={Bernstein, Jeremy and Wang, Yu-Xiang and Azizzadenesheli, Kamyar and Anandkumar, Anima},
  journal={ICML},
  year={2018}
}
@inproceedings{zinkevich2010parallelized,
  title={Parallelized stochastic gradient descent},
  author={Zinkevich, Martin and Weimer, Markus and Li, Lihong and Smola, Alex J},
  booktitle={Advances in neural information processing systems},
  pages={2595--2603},
  year={2010}
}

@article{ye2021deepca,
  title={DeEPCA: Decentralized Exact PCA with Linear Convergence Rate.},
  author={Ye, Haishan and Zhang, Tong},
  journal={J. Mach. Learn. Res.},
  volume={22},
  number={238},
  pages={1--27},
  year={2021}
}

@article{ye2020decentralized,
  title={Decentralized accelerated proximal gradient descent},
  author={Ye, Haishan and Zhou, Ziang and Luo, Luo and Zhang, Tong},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18308--18317},
  year={2020}
}

@article{hsu2019measuring,
  title={Measuring the effects of non-identical data distribution for federated visual classification},
  author={Hsu, Tzu-Ming Harry and Qi, Hang and Brown, Matthew},
  journal={arXiv preprint arXiv:1909.06335},
  year={2019}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}


@inproceedings{sun2019communication,
  title={Communication-efficient distributed learning via lazily aggregated quantized gradients},
  author={Sun, Jun and Chen, Tianyi and Giannakis, Georgios and Yang, Zaiyue},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3365--3375},
  year={2019}
}
@inproceedings{sun2018markov,
  title={On Markov Chain Gradient Descent},
  author={Sun, Tao and Sun, Yuejiao and Yin, Wotao},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9917--9926},
  year={2018}
}

@article{robbins1951stochastic,
  title={A Stochastic Approximation Method},
  author={Robbins, Herbert and Monro, S},
  journal={Annals Math Statistics},
  volume={22},
  pages={400--407},
  year={1951}
}

@inproceedings{dean2012large,
  title={Large scale distributed deep networks},
  author={Dean, Jeffrey and Corrado, Greg and Monga, Rajat and Chen, Kai and Devin, Matthieu and Mao, Mark and Senior, Andrew and Tucker, Paul and Yang, Ke and Le, Quoc V and others},
  booktitle={Advances in  Neural Information Processing Systems},
  pages={1223--1231},
  year={2012}
}

@article{nesterov2017random,
  title={Random gradient-free minimization of convex functions},
  author={Nesterov, Yurii and Spokoiny, Vladimir},
  journal={Foundations of Computational Mathematics},
  volume={17},
  number={2},
  pages={527--566},
  year={2017},
  publisher={Springer}
}

@article{duchi2015optimal,
  title={Optimal rates for zero-order convex optimization: The power of two function evaluations},
  author={Duchi, John C and Jordan, Michael I and Wainwright, Martin J and Wibisono, Andre},
  journal={IEEE Transactions on Information Theory},
  volume={61},
  number={5},
  pages={2788--2806},
  year={2015},
  publisher={IEEE}
}

@article{shamir2017optimal,
  title={An Optimal Algorithm for Bandit and Zero-Order Convex Optimization with Two-Point Feedback.},
  author={Shamir, Ohad},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={52},
  pages={1--11},
  year={2017}
}


@inproceedings{agarwal2010optimal,
  title={Optimal Algorithms for Online Convex Optimization with Multi-Point Bandit Feedback.},
  author={Agarwal, Alekh and Dekel, Ofer and Xiao, Lin},
  booktitle={COLT},
  pages={28--40},
  year={2010},
  organization={Citeseer}
}



@inproceedings{li2014scaling,
  title={Scaling Distributed Machine Learning with the Parameter Server.},
  author={Li, Mu and Andersen, David G and Park, Jun Woo and Smola, Alexander J and Ahmed, Amr and Josifovski, Vanja and Long, James and Shekita, Eugene J and Su, Bor-Yiing},
  booktitle={OSDI},
  volume={14},
  pages={583--598},
  year={2014}
}




@inproceedings{lian2018a,
  title={Asynchronous decentralized parallel stochastic gradient descent},
  author={Lian, Xiangru and Zhang, Wei and Zhang, Ce and Liu, Ji},
  booktitle={Proceedings of the 35th International Conference on Machine Learning},
  pages={3043-3052},
  year={2018}
}


@article{sun2018markovb,
  title={Markov Chain Block Coordinate Descent},
  author={Sun, Tao and Sun, Yuejiao and Xu, Yangyang and Yin, Wotao},
  journal={arXiv preprint arXiv:1811.08990},
  year={2018}
}


@book{meyn2012markov,
  title={Markov chains and stochastic stability},
  author={Meyn, Sean P and Tweedie, Richard L},
  year={2012},
  publisher={Springer Science \&amp; Business Media}
}

@article{ram2009incremental,
  title={Incremental stochastic subgradient algorithms for convex optimization},
  author={Ram, S Sundhar and Nedi{\'c}, A and Veeravalli, Venugopal V},
  journal={SIAM Journal on Optimization},
  volume={20},
  number={2},
  pages={691-717},
  year={2009},
  publisher={SIAM}
}

@inproceedings{johansson2007simple,
  title={A simple peer-to-peer algorithm for distributed optimization in sensor networks},
  author={Johansson, Bjorn and Rabi, Maben and Johansson, Mikael},
  booktitle={Decision and Control, 2007 46th IEEE Conference on},
  pages={4705-4710},
  year={2007},
  organization={IEEE}
}


@inproceedings{boyd2005gossip,
  title={Gossip algorithms: Design, analysis and applications},
  author={Boyd, Stephen and Ghosh, Arpita and Prabhakar, Balaji and Shah, Devavrat},
  booktitle={INFOCOM 2005. 24th Annual Joint Conference of the IEEE Computer and Communications Societies. Proceedings IEEE},
  volume={3},
  pages={1653--1664},
  year={2005},
  organization={IEEE}
}


@article{olfati2007consensus,
  title={Consensus and cooperation in networked multi-agent systems},
  author={Olfati-Saber, Reza and Fax, J Alex and Murray, Richard M},
  journal={Proceedings of the IEEE},
  volume={95},
  number={1},
  pages={215--233},
  year={2007},
  publisher={IEEE}
}


@inproceedings{schenato2007distributed,
  title={A distributed consensus protocol for clock synchronization in wireless sensor network},
  author={Schenato, Luca and Gamba, Giovanni},
  booktitle={2007 46th ieee conference on decision and control},
  pages={2289--2294},
  year={2007},
  organization={IEEE}
}



@article{aysal2009broadcast,
  title={Broadcast gossip algorithms for consensus},
  author={Aysal, Tuncer Can and Yildiz, Mehmet Ercan and Sarwate, Anand D and Scaglione, Anna},
  journal={IEEE Transactions on Signal processing},
  volume={57},
  number={7},
  pages={2748--2761},
  year={2009},
  publisher={IEEE}
}

@inproceedings{chen2012fast,
  title={A fast distributed proximal-gradient method},
  author={Chen, Annie I and Ozdaglar, Asuman},
  booktitle={Communication, Control, and Computing (Allerton), 2012 50th Annual Allerton Conference on},
  pages={601--608},
  year={2012},
  organization={IEEE}
}


@article{jakovetic2014fast,
  title={Fast distributed gradient methods},
  author={Jakoveti{\'c}, Du{\v{s}}an and Xavier, Joao and Moura, Jos{\'e} MF},
  journal={IEEE Transactions on Automatic Control},
  volume={59},
  number={5},
  pages={1131--1146},
  year={2014},
  publisher={IEEE}
}

@article{matei2011performance,
  title={Performance evaluation of the consensus-based distributed subgradient method under random communication topologies},
  author={Matei, Ion and Baras, John S},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={5},
  number={4},
  pages={754--771},
  year={2011},
  publisher={IEEE}
}





@article{yuan2016convergence,
  title={On the convergence of decentralized gradient descent},
  author={Yuan, Kun and Ling, Qing and Yin, Wotao},
  journal={SIAM Journal on Optimization},
  volume={26},
  number={3},
  pages={1835--1854},
  year={2016},
  publisher={SIAM}
}

@article{chang2015multi,
  title={Multi-Agent Distributed Optimization via Inexact Consensus ADMM.},
  author={Chang, Tsung-Hui and Hong, Mingyi and Wang, Xiangfeng},
  journal={IEEE Trans. Signal Processing},
  volume={63},
  number={2},
  pages={482--497},
  year={2015}
}

@article{schizas2008consensus,
  title={Consensus in ad hoc WSNs with noisy links Part I: Distributed estimation of deterministic signals},
  author={Schizas, Ioannis D and Ribeiro, Alejandro and Giannakis, Georgios B},
  journal={IEEE Transactions on Signal Processing},
  volume={56},
  number={1},
  pages={350--364},
  year={2008},
  publisher={IEEE}
}

@article{shi2014linear,
  title={On the Linear Convergence of the ADMM in Decentralized Consensus Optimization.},
  author={Shi, Wei and Ling, Qing and Yuan, Kun and Wu, Gang and Yin, Wotao},
  journal={IEEE Trans. Signal Processing},
  volume={62},
  number={7},
  pages={1750--1761},
  year={2014}
}

@article{wu2018decentralized,
  title={Decentralized consensus optimization with asynchrony and delays},
  author={Wu, Tianyu and Yuan, Kun and Ling, Qing and Yin, Wotao and Sayed, Ali H},
  journal={IEEE Transactions on Signal and Information Processing over Networks},
  volume={4},
  number={2},
  pages={293--307},
  year={2018},
  publisher={IEEE}
}

@inproceedings{ram2009asynchronous,
  title={Asynchronous gossip algorithms for stochastic optimization},
  author={Ram, S Sundhar and Nedi{\'c}, A and Veeravalli, Venugopal V},
  booktitle={Decision and Control, 2009 held jointly with the 2009 28th Chinese Control Conference. CDC/CCC 2009. Proceedings of the 48th IEEE Conference on},
  pages={3581--3586},
  year={2009},
  organization={IEEE}
}

@incollection{ram2010asynchronous2,
  title={Asynchronous gossip algorithm for stochastic optimization: Constant stepsize analysis},
  author={Ram, S Sundhar and Nedi{\'c}, Angelia and Veeravalli, Venu V},
  booktitle={Recent Advances in Optimization and its Applications in Engineering},
  pages={51--60},
  year={2010},
  publisher={Springer}
}

@article{srivastava2011distributed,
  title={Distributed asynchronous constrained stochastic optimization},
  author={Srivastava, Kunal and Nedic, Angelia},
  journal={IEEE Journal of Selected Topics in Signal Processing},
  volume={5},
  number={4},
  pages={772--790},
  year={2011},
  publisher={IEEE}
}

@article{ram2010distributed,
  title={Distributed stochastic subgradient projection algorithms for convex optimization},
  author={Ram, S Sundhar and Nedi{\'c}, Angelia and Veeravalli, Venugopal V},
  journal={Journal of optimization theory and applications},
  volume={147},
  number={3},
  pages={516--545},
  year={2010},
  publisher={Springer}
}

@inproceedings{sirb2016consensus,
  title={Consensus optimization with delayed and stochastic gradients on decentralized networks},
  author={Sirb, Benjamin and Ye, Xiaojing},
  booktitle={Big Data (Big Data), 2016 IEEE International Conference on},
  pages={76--85},
  year={2016},
  organization={IEEE}
}



@article{lan2017communication,
  title={Communication-efficient algorithms for decentralized and stochastic optimization},
  author={Lan, Guanghui and Lee, Soomin and Zhou, Yi},
  journal={Mathematical Programming},
  volume={180},
  number={1},
  pages={237--284},
  year={2020},
  publisher={Springer}
}

@article{johansson2009randomized,
  title={A randomized incremental subgradient method for distributed optimization in networked systems},
  author={Johansson, Bj{\"o}rn and Rabi, Maben and Johansson, Mikael},
  journal={SIAM Journal on Optimization},
  volume={20},
  number={3},
  pages={1157-1170},
  year={2009},
  publisher={SIAM}
}


@article{duchi2012ergodic,
  title={Ergodic mirror descent},
  author={Duchi, John C and Agarwal, Alekh and Johansson, Mikael and Jordan, Michael I},
  journal={SIAM Journal on Optimization},
  volume={22},
  number={4},
  pages={1549-1578},
  year={2012},
  publisher={SIAM}
}


@article{zeng2018nonconvex,
  title={On nonconvex decentralized gradient descent},
  author={Zeng, Jinshan and Yin, Wotao},
  journal={IEEE Transactions on Signal Processing},
  volume={66},
  number={11},
  pages={2834--2848},
  year={2018},
  publisher={IEEE}
}

@article{montenegro2006mathematical,
  title={Mathematical aspects of mixing times in Markov chains},
  author={Montenegro, Ravi and Tetali, Prasad and others},
  journal={Foundations and Trends{\textregistered} in Theoretical Computer Science},
  volume={1},
  number={3},
  pages={237--354},
  year={2006},
  publisher={Now Publishers, Inc.}
}

@article{shi2015extra,
  title={Extra: An exact first-order algorithm for decentralized consensus optimization},
  author={Shi, Wei and Ling, Qing and Wu, Gang and Yin, Wotao},
  journal={SIAM Journal on Optimization},
  volume={25},
  number={2},
  pages={944--966},
  year={2015},
  publisher={SIAM}
}

@article{hosseini2016online,
  title={Online Distributed Convex Optimization on Dynamic Networks.},
  author={Hosseini, Saghar and Chapman, Airlie and Mesbahi, Mehran},
  journal={IEEE Trans. Automat. Contr.},
  volume={61},
  number={11},
  pages={3545--3550},
  year={2016}
}

@inproceedings{mcmahan2014delay,
  title={Delay-tolerant algorithms for asynchronous distributed online learning},
  author={McMahan, Brendan and Streeter, Matthew},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2915--2923},
  year={2014}
}



@inproceedings{xing2020decentralized,
  title={Decentralized Federated Learning via {SGD} over Wireless {D2D} Networks},
  author={Xing, Hong and Simeone, Osvaldo and Bi, Suzhi},
  booktitle={2020 IEEE 21st International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)},
  pages={1--5},
  year={2020},
  organization={IEEE}
}




@inproceedings{sun2019non,
  title={Non-ergodic convergence analysis of heavy-ball algorithms},
  author={Sun, Tao and Yin, Penghang and Li, Dongsheng and Huang, Chun and Guan, Lei and Jiang, Hao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={5033--5040},
  year={2019}
}



@article{xin2019distributed,
  title={Distributed heavy-ball: A generalization and acceleration of first-order methods with gradient tracking},
  author={Xin, Ran and Khan, Usman A},
  journal={IEEE Transactions on Automatic Control},
  year={2019},
  publisher={IEEE}
}


@book{yang2019federated,
  title={Federated learning},
  author={Yang, Qiang and Liu, Yang and Cheng, Yong and Kang, Yan and Chen, Tianjian and Yu, Han},
  year={2019},
  publisher={Morgan \& Claypool Publishers}
}


@inproceedings{li2014communication,
  title={Communication efficient distributed machine learning with the parameter server},
  author={Li, Mu and Andersen, David G and Smola, Alexander J and Yu, Kai},
  booktitle={Advances in Neural Information Processing Systems},
  pages={19--27},
  year={2014}
}

@inproceedings{reisizadeh2018quantized,
  title={Quantized decentralized consensus optimization},
  author={Reisizadeh, Amirhossein and Mokhtari, Aryan and Hassani, Hamed and Pedarsani, Ramtin},
  booktitle={2018 IEEE Conference on Decision and Control (CDC)},
  pages={5838--5843},
  year={2018},
  organization={IEEE}
}

@article{mcmahan2017communication,
title={Communication-Efficient Learning of Deep Networks from Decentralized Data},
author={Mcmahan, H Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and Arcas, Blaise Aguera Y},
booktitle={Artificial intelligence and statistics},
pages={1273--1282},
year={2017},
organization={PMLR}}


@article{magnusson2019maintaining,
  title={On maintaining linear convergence of distributed learning and optimization under limited communication},
  author={Magn{\'u}sson, Sindri and Shokri-Ghadikolaei, Hossein and Li, Na},
  journal={IEEE Transactions on Signal Processing},
  volume={68},
  pages={6101--6116},
  year={2020},
  publisher={IEEE}
}


@inproceedings{li2019feddane,
  title={Feddane: A federated Newton-type method},
  author={Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smithy, Virginia},
  booktitle={2019 53rd Asilomar Conference on Signals, Systems, and Computers},
  pages={1227--1231},
  year={2019},
  organization={IEEE}
}


@inproceedings{
li2019convergence,
title={On the Convergence of FedAvg on Non-{IID} Data},
author={Xiang Li and Kaixuan Huang and Wenhao Yang and Shusen Wang and Zhihua Zhang},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HJxNAnVtDS}
}

@inproceedings{foret2021sharpnessaware,
title={Sharpness-aware Minimization for Efficiently Improving Generalization},
author={Pierre Foret and Ariel Kleiner and Hossein Mobahi and Behnam Neyshabur},
booktitle={International Conference on Learning Representations},
year={2021}
}

@inproceedings{Qu2022Generalized,
  author    = {Zhe Qu and
               Xingyu Li and
               Rui Duan and
               Yao Liu and
               Bo Tang and
               Zhuo Lu},
  title     = {Generalized Federated Learning via Sharpness Aware Minimization},
  booktitle = {International Conference on Machine Learning, {ICML} },
  pages     = {18250--18280},
  year = {2022}
}

@article{khaled2019first,
  title={First analysis of local gd on heterogeneous data},
  author={Khaled, Ahmed and Mishchenko, Konstantin and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:1909.04715},
  year={2019}
}
@inproceedings{ghadimi2015global,
  title={Global convergence of the heavy-ball method for convex optimization},
  author={Ghadimi, Euhanna and Feyzmahdavian, Hamid Reza and Johansson, Mikael},
  booktitle={2015 European Control Conference (ECC)},
  pages={310--315},
  year={2015},
  organization={IEEE}
}


@article{li2020communication,
  author    = {Boyue Li and
               Shicong Cen and
               Yuxin Chen and
               Yuejie Chi},
  title     = {Communication-Efficient Distributed Optimization in Networks with  Gradient Tracking and Variance Reduction},
  journal   = {Journal of Machine Learning Research, {JMLR}},
  pages     = {180:1--180:51},
  year      = {2020},
}
@article{lecun2010mnist,
  title={MNIST handwritten digit database},
  author={LeCun, Yann and Cortes, Corinna and Burges, CJ},
  year={2010}
}

@article{Sun2022Decentralized,
  author={Sun, Tao and Li, Dongsheng and Wang, Bao},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Decentralized Federated Averaging}, 
  year={2022},
}

@ARTICLE{Hashemi2022On,
  author={Hashemi, Abolfazl and Acharya, Anish and Das, Rudrajit and Vikalo, Haris and Sanghavi, Sujay and Dhillon, Inderjit},
  journal={IEEE Transactions on Parallel and Distributed Systems, {TPDS}}, 
  title={On the Benefits of Multiple Gossip Steps in Communication-Constrained Decentralized Federated Learning}, 
  year={2022},
  pages={2727-2739},
  }

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}
