\begin{thebibliography}{10}

\bibitem{anandkumar2012high}
Animashree Anandkumar, Vincent~YF Tan, Furong Huang, and Alan~S Willsky.
\newblock High-dimensional gaussian graphical model selection: Walk summability
  and local separation criterion.
\newblock {\em Journal of Machine Learning Research}, 13(Aug):2293--2337, 2012.

\bibitem{bartlett2005local}
Peter~L Bartlett, Olivier Bousquet, Shahar Mendelson, et~al.
\newblock Local rademacher complexities.
\newblock {\em The Annals of Statistics}, 33(4):1497--1537, 2005.

\bibitem{basso2005reverse}
Katia Basso, Adam~A Margolin, Gustavo Stolovitzky, Ulf Klein, Riccardo
  Dalla-Favera, and Andrea Califano.
\newblock Reverse engineering of regulatory networks in human b cells.
\newblock {\em Nature genetics}, 37(4):382, 2005.

\bibitem{birge2001alternative}
Lucien Birg{\'e} et~al.
\newblock An alternative point of view on lepski’s method.
\newblock {\em Lecture Notes-Monograph Series}, 36:113--133, 2001.

\bibitem{blitzstein2014introduction}
Joseph~K Blitzstein and Jessica Hwang.
\newblock {\em Introduction to probability}.
\newblock Chapman and Hall/CRC, 2014.

\bibitem{bollobas2013modern}
B{\'e}la Bollob{\'a}s.
\newblock {\em Modern graph theory}, volume 184.
\newblock Springer Science \& Business Media, 2013.

\bibitem{bresler2015efficiently}
Guy Bresler.
\newblock Efficiently learning ising models on arbitrary graphs.
\newblock In {\em Proceedings of the forty-seventh annual ACM symposium on
  Theory of computing}, pages 771--782. ACM, 2015.

\bibitem{learning-rbm}
Guy Bresler, Frederic Koehler, and Ankur Moitra.
\newblock Learning restricted boltzmann machines via influence maximization.
\newblock In {\em Proceedings of the ACM Symposium on Theory of Computing},
  2019.

\bibitem{bubeck2015convex}
S{\'e}bastien Bubeck et~al.
\newblock Convex optimization: Algorithms and complexity.
\newblock {\em Foundations and Trends{\textregistered} in Machine Learning},
  8(3-4):231--357, 2015.

\bibitem{buhlmann2014high}
Peter B{\"u}hlmann, Markus Kalisch, and Lukas Meier.
\newblock High-dimensional statistics with a view toward applications in
  biology.
\newblock {\em Annual Review of Statistics and Its Application}, 1:255--278,
  2014.

\bibitem{cai2016estimating}
T~Tony Cai, Weidong Liu, Harrison~H Zhou, et~al.
\newblock Estimating sparse precision matrix: Optimal rates of convergence and
  adaptive estimation.
\newblock {\em The Annals of Statistics}, 44(2):455--488, 2016.

\bibitem{cai2011constrained}
Tony Cai, Weidong Liu, and Xi~Luo.
\newblock A constrained $\ell_1$ minimization approach to sparse precision
  matrix estimation.
\newblock {\em Journal of the American Statistical Association},
  106(494):594--607, 2011.

\bibitem{candes2014towards}
Emmanuel~J Cand{\`e}s and Carlos Fernandez-Granda.
\newblock Towards a mathematical theory of super-resolution.
\newblock {\em Communications on pure and applied Mathematics}, 67(6):906--956,
  2014.

\bibitem{das2011submodular}
Abhimanyu Das and David Kempe.
\newblock Submodular meets spectral: greedy algorithms for subset selection,
  sparse approximation and dictionary selection.
\newblock In {\em Proceedings of the 28th International Conference on
  International Conference on Machine Learning}, pages 1057--1064. Omnipress,
  2011.

\bibitem{dempster1972covariance}
Arthur~P Dempster.
\newblock Covariance selection.
\newblock {\em Biometrics}, pages 157--175, 1972.

\bibitem{ding2011cover}
Jian Ding, James~R Lee, and Yuval Peres.
\newblock Cover times, blanket times, and majorizing measures.
\newblock In {\em Proceedings of the forty-third annual ACM symposium on Theory
  of computing}, pages 61--70. ACM, 2011.

\bibitem{elenberg2016restricted}
Ethan~R Elenberg, Rajiv Khanna, Alexandros~G Dimakis, and Sahand Negahban.
\newblock Restricted strong convexity implies weak submodularity.
\newblock {\em arXiv preprint arXiv:1612.00804}, 2016.

\bibitem{fiedler1962matrices}
Miroslav Fiedler and Vlastimil Ptak.
\newblock On matrices with non-positive off-diagonal elements and positive
  principal minors.
\newblock {\em Czechoslovak Mathematical Journal}, 12(3):382--400, 1962.

\bibitem{friedli2017statistical}
Sacha Friedli and Yvan Velenik.
\newblock {\em Statistical mechanics of lattice systems: a concrete
  mathematical introduction}.
\newblock Cambridge University Press, 2017.

\bibitem{friedman2008sparse}
Jerome Friedman, Trevor Hastie, and Robert Tibshirani.
\newblock Sparse inverse covariance estimation with the graphical lasso.
\newblock {\em Biostatistics}, 9(3):432--441, 2008.

\bibitem{griffiths1969rigorous}
Robert~B Griffiths.
\newblock Rigorous results for ising ferromagnets of arbitrary spin.
\newblock {\em Journal of Mathematical Physics}, 10(9):1559--1565, 1969.

\bibitem{hebiri2012correlations}
Mohamed Hebiri and Johannes Lederer.
\newblock How correlations influence lasso prediction.
\newblock {\em IEEE Transactions on Information Theory}, 59(3):1846--1854,
  2012.

\bibitem{bignquic}
Cho-Jui Hsieh, M{\'a}ty{\'a}s~A Sustik, Inderjit~S Dhillon, Pradeep~K
  Ravikumar, and Russell Poldrack.
\newblock Big \& quic: Sparse inverse covariance estimation for a million
  variables.
\newblock In {\em Advances in neural information processing systems}, pages
  3165--3173, 2013.

\bibitem{hsu2012random}
Daniel Hsu, Sham~M Kakade, and Tong Zhang.
\newblock Random design analysis of ridge regression.
\newblock In {\em Conference on learning theory}, pages 9--1, 2012.

\bibitem{huang2010learning}
Shuai Huang, Jing Li, Liang Sun, Jieping Ye, Adam Fleisher, Teresa Wu, Kewei
  Chen, Eric Reiman, Alzheimer's Disease~NeuroImaging Initiative, et~al.
\newblock Learning brain connectivity of alzheimer's disease by sparse inverse
  covariance estimation.
\newblock {\em NeuroImage}, 50(3):935--949, 2010.

\bibitem{keener2011theoretical}
Robert~W Keener.
\newblock {\em Theoretical statistics: Topics for a core course}.
\newblock Springer, 2011.

\bibitem{klivans2017learning}
Adam Klivans and Raghu Meka.
\newblock Learning graphical models using multiplicative weights.
\newblock In {\em 2017 IEEE 58th Annual Symposium on Foundations of Computer
  Science (FOCS)}, pages 343--354. IEEE, 2017.

\bibitem{koltchinskii2014l_1}
Vladimir Koltchinskii and Stanislav Minsker.
\newblock $ l\_1 $-penalization in functional linear regression with
  subgaussian design.
\newblock {\em Journal de l’{\'E}cole polytechnique-Math{\'e}matiques},
  1:269--330, 2014.

\bibitem{laurent2000adaptive}
Beatrice Laurent and Pascal Massart.
\newblock Adaptive estimation of a quadratic functional by model selection.
\newblock {\em Annals of Statistics}, pages 1302--1338, 2000.

\bibitem{lauritzen2017maximum}
Steffen Lauritzen, Caroline Uhler, and Piotr Zwiernik.
\newblock Maximum likelihood estimation in gaussian models under total
  positivity.
\newblock {\em arXiv preprint arXiv:1702.04031}, 2017.

\bibitem{lauritzen1996graphical}
Steffen~L Lauritzen.
\newblock {\em Graphical models}, volume~17.
\newblock Clarendon Press, 1996.

\bibitem{lauritzen2011elements}
Steffen~L Lauritzen.
\newblock Elements of graphical models.
\newblock {\em Lectures from the XXXVIth International Probability Summer
  School in St-Flour, France}, 2011.

\bibitem{mgs2013}
Yifei Ma, Roman Garnett, and Jeff Schneider.
\newblock Sigma-optimality for active learning on gaussian random fields.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2751--2759, 2013.

\bibitem{mahalanabis2012subset}
Satyaki Mahalanabis and Daniel Stefankovic.
\newblock Subset selection for gaussian markov random fields.
\newblock {\em arXiv preprint arXiv:1209.5991}, 2012.

\bibitem{malioutov2006walk}
Dmitry~M Malioutov, Jason~K Johnson, and Alan~S Willsky.
\newblock Walk-sums and belief propagation in gaussian graphical models.
\newblock {\em Journal of Machine Learning Research}, 7(Oct):2031--2064, 2006.

\bibitem{meinshausen2006high}
Nicolai Meinshausen, Peter B{\"u}hlmann, et~al.
\newblock High-dimensional graphs and variable selection with the lasso.
\newblock {\em The annals of statistics}, 34(3):1436--1462, 2006.

\bibitem{mendelson2014learning}
Shahar Mendelson.
\newblock Learning without concentration.
\newblock In {\em Conference on Learning Theory}, pages 25--39, 2014.

\bibitem{menendez2010gene}
Patricia Men{\'e}ndez, Yiannis~AI Kourmpetis, Cajo~JF ter Braak, and Fred~A van
  Eeuwijk.
\newblock Gene regulatory networks from multifactorial perturbations using
  graphical lasso: application to the dream4 challenge.
\newblock {\em PloS one}, 5(12):e14147, 2010.

\bibitem{misra18}
Sidhant Misra, Marc Vuffray, and Andrey~Y. Lokhov.
\newblock Information theoretic optimal learning of gaussian graphical models.
\newblock {\em CoRR}, abs/1703.04886, 2018.

\bibitem{natarajan1995sparse}
Balas~Kausik Natarajan.
\newblock Sparse approximate solutions to linear systems.
\newblock {\em SIAM journal on computing}, 24(2):227--234, 1995.

\bibitem{rasmussen2003gaussian}
Carl~Edward Rasmussen.
\newblock Gaussian processes in machine learning.
\newblock In {\em Summer School on Machine Learning}, pages 63--71. Springer,
  2003.

\bibitem{ravikumar2011high}
Pradeep Ravikumar, Martin~J Wainwright, Garvesh Raskutti, Bin Yu, et~al.
\newblock High-dimensional covariance estimation by minimizing
  $\ell_1$-penalized log-determinant divergence.
\newblock {\em Electronic Journal of Statistics}, 5:935--980, 2011.

\bibitem{rigollet2015high}
Phillippe Rigollet and Jan-Christian H{\"u}tter.
\newblock High dimensional statistics.
\newblock {\em Lecture notes for course 18S997}, 2015.

\bibitem{ruozzi2009graph}
Nicholas Ruozzi, Justin Thaler, and Sekhar Tatikonda.
\newblock Graph covers and quadratic minimization.
\newblock In {\em 2009 47th Annual Allerton Conference on Communication,
  Control, and Computing (Allerton)}, pages 1590--1596. IEEE, 2009.

\bibitem{schafer2005learning}
Juliane Sch{\"a}fer and Korbinian Strimmer.
\newblock Learning large-scale graphical gaussian models from genomic data.
\newblock In {\em AIP Conference Proceedings}, volume 776, pages 263--276. AIP,
  2005.

\bibitem{shalev2014understanding}
Shai Shalev-Shwartz and Shai Ben-David.
\newblock {\em Understanding machine learning: From theory to algorithms}.
\newblock Cambridge university press, 2014.

\bibitem{sheffield2007gaussian}
Scott Sheffield.
\newblock Gaussian free fields for mathematicians.
\newblock {\em Probability theory and related fields}, 139(3-4):521--541, 2007.

\bibitem{slawski2015estimation}
Martin Slawski and Matthias Hein.
\newblock Estimation of positive definite m-matrices and structure learning for
  attractive gaussian markov random fields.
\newblock {\em Linear Algebra and its Applications}, 473:145--179, 2015.

\bibitem{srebro2010smoothness}
Nathan Srebro, Karthik Sridharan, and Ambuj Tewari.
\newblock Smoothness, low noise and fast rates.
\newblock In {\em Advances in neural information processing systems}, pages
  2199--2207, 2010.

\bibitem{tropp2007signal}
Joel~A Tropp and Anna~C Gilbert.
\newblock Signal recovery from random measurements via orthogonal matching
  pursuit.
\newblock {\em IEEE Transactions on information theory}, 53(12):4655--4666,
  2007.

\bibitem{van2013lasso}
Sara van~de Geer, Johannes Lederer, et~al.
\newblock The lasso, correlated design, and improved oracle inequalities.
\newblock In {\em From Probability to Statistics and Back: High-Dimensional
  Models and Processes--A Festschrift in Honor of Jon A. Wellner}, pages
  303--316. Institute of Mathematical Statistics, 2013.

\bibitem{varoquaux2010brain}
Ga{\"e}l Varoquaux, Alexandre Gramfort, Jean-Baptiste Poline, and Bertrand
  Thirion.
\newblock Brain covariance selection: better individual functional connectivity
  models using population prior.
\newblock In {\em Advances in neural information processing systems}, pages
  2334--2342, 2010.

\bibitem{vershynin2018high}
Roman Vershynin.
\newblock {\em High-dimensional probability: An introduction with applications
  in data science}, volume~47.
\newblock Cambridge University Press, 2018.

\bibitem{vuffray2016interaction}
Marc Vuffray, Sidhant Misra, Andrey Lokhov, and Michael Chertkov.
\newblock Interaction screening: Efficient and sample-optimal learning of ising
  models.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2595--2603, 2016.

\bibitem{wang2010information}
Wei Wang, Martin~J Wainwright, and Kannan Ramchandran.
\newblock Information-theoretic bounds on model selection for gaussian markov
  random fields.
\newblock In {\em 2010 IEEE International Symposium on Information Theory},
  pages 1373--1377. IEEE, 2010.

\bibitem{weiss2000correctness}
Yair Weiss and William~T Freeman.
\newblock Correctness of belief propagation in gaussian graphical models of
  arbitrary topology.
\newblock In {\em Advances in neural information processing systems}, pages
  673--679, 2000.

\bibitem{wille2004sparse}
Anja Wille, Philip Zimmermann, Eva Vranov{\'a}, Andreas F{\"u}rholz, Oliver
  Laule, Stefan Bleuler, Lars Hennig, Amela Preli{\'c}, Peter von Rohr, Lothar
  Thiele, et~al.
\newblock Sparse graphical gaussian modeling of the isoprenoid gene network in
  arabidopsis thaliana.
\newblock {\em Genome biology}, 5(11):R92, 2004.

\bibitem{zhang2014lower}
Yuchen Zhang, Martin~J Wainwright, and Michael~I Jordan.
\newblock Lower bounds on the performance of polynomial-time algorithms for
  sparse linear regression.
\newblock In {\em Conference on Learning Theory}, pages 921--948, 2014.

\bibitem{zhou2009adaptive}
Shuheng Zhou, Sara van~de Geer, and Peter B{\"u}hlmann.
\newblock Adaptive lasso for high dimensional regression and gaussian graphical
  modeling.
\newblock {\em arXiv preprint arXiv:0903.2515}, 2009.

\bibitem{zhu2003semi}
Xiaojin Zhu, Zoubin Ghahramani, and John~D Lafferty.
\newblock Semi-supervised learning using gaussian fields and harmonic
  functions.
\newblock In {\em Proceedings of the 20th International conference on Machine
  learning (ICML-03)}, pages 912--919, 2003.

\bibitem{zhu2003combining}
Xiaojin Zhu, John Lafferty, and Zoubin Ghahramani.
\newblock Combining active learning and semi-supervised learning using gaussian
  fields and harmonic functions.
\newblock In {\em ICML 2003 workshop on the continuum from labeled to unlabeled
  data in machine learning and data mining}, volume~3, 2003.

\end{thebibliography}
