\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bai et~al.()Bai, Srivastava, and Russell]{baimarkovian}
Aijun Bai, Siddharth Srivastava, and Stuart Russell.
\newblock Markovian state and action abstractions for mdps via hierarchical
  mcts.

\bibitem[Baram et~al.(2016)Baram, Zahavy, and Mannor]{visdynamics2}
Nir Baram, Tom Zahavy, and Shie Mannor.
\newblock Spatio-temporal abstractions in reinforcement learning through neural
  encoding.
\newblock \emph{European Workshop on Reinforcement Learning (EWRL)}, 2016.

\bibitem[Bellemare et~al.(2012)Bellemare, Naddaf, Veness, and
  Bowling]{bellemare2012arcade}
Marc~G Bellemare, Yavar Naddaf, Joel Veness, and Michael Bowling.
\newblock The arcade learning environment: {A}n evaluation platform for general
  agents.
\newblock \emph{arXiv preprint arXiv:1207.4708}, 2012.

\bibitem[Bellemare et~al.(2015)Bellemare, Ostrovski, Guez, Thomas, and
  Munos]{bellemare2015increasing}
Marc~G Bellemare, Georg Ostrovski, Arthur Guez, Philip~S Thomas, and R{\'e}mi
  Munos.
\newblock Increasing the action gap: {N}ew operators for reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:1512.04860}, 2015.

\bibitem[Ben~Zrihem et~al.(2016)Ben~Zrihem, Zahavy, and Mannor]{visdynamics}
Nir Ben~Zrihem, Tom Zahavy, and Shie Mannor.
\newblock Visualizing dynamics: from t-sne to semi-mdps.
\newblock \emph{Workshop on Human Interpretability in Machine Learning (ICML)},
  2016.

\bibitem[Dayan and Hinton(1993)]{dayan}
Peter Dayan and Geoffrey~E Hinton.
\newblock Feudal reinforcement learning.
\newblock pages 271--271. Morgan Kaufmann Publishers, 1993.

\bibitem[Dean and Lin(1995)]{dean1995decomposition}
Thomas Dean and Shieu-Hong Lin.
\newblock Decomposition techniques for planning in stochastic domains.
\newblock 1995.

\bibitem[Dietterich(2000)]{dietterich2000hierarchical}
Thomas~G Dietterich.
\newblock Hierarchical reinforcement learning with the {MAXQ} value function
  decomposition.
\newblock \emph{J. Artif. Intell. Res.(JAIR)}, 13:\penalty0 227--303, 2000.

\bibitem[Engel and Mannor(2001)]{engel2001learning}
Yaakov Engel and Shie Mannor.
\newblock Learning embedded maps of markov processes.
\newblock In \emph{in Proceedings of ICML 2001}. Citeseer, 2001.

\bibitem[Erhan et~al.(2009)Erhan, Bengio, Courville, and
  Vincent]{erhan2009visualizing}
Dumitru Erhan, Yoshua Bengio, Aaron Courville, and Pascal Vincent.
\newblock Visualizing higher-layer features of a deep network.
\newblock \emph{Dept. IRO, Universit{\'e} de Montr{\'e}al, Tech. Rep}, 4323,
  2009.

\bibitem[Francis and Wonham(1975)]{francis1975internal}
Bruce~A Francis and William~M Wonham.
\newblock The internal model principle for linear multivariable regulators.
\newblock \emph{Applied mathematics and optimization}, 2\penalty0 (2), 1975.

\bibitem[Gordon(1995)]{gordon1995stable}
Geoffrey~J Gordon.
\newblock Stable function approximation in dynamic programming.
\newblock 1995.

\bibitem[Hallak et~al.(2013)Hallak, Di-Castro, and Mannor]{hallak2013model}
Assaf Hallak, Dotan Di-Castro, and Shie Mannor.
\newblock Model selection in markovian processes.
\newblock In \emph{Proceedings of the 19th ACM SIGKDD international conference
  on Knowledge discovery and data mining}. ACM, 2013.

\bibitem[Hauskrecht et~al.(1998)Hauskrecht, Meuleau, Kaelbling, Dean, and
  Boutilier]{hauskrecht1998hierarchical}
Milos Hauskrecht, Nicolas Meuleau, Leslie~Pack Kaelbling, Thomas Dean, and
  Craig Boutilier.
\newblock Hierarchical solution of {M}arkov decision processes using
  macro-actions.
\newblock In \emph{Proceedings of the Fourteenth conference on Uncertainty in
  artificial intelligence}, pages 220--229. Morgan Kaufmann Publishers Inc.,
  1998.

\bibitem[Kulkarni et~al.(2016)Kulkarni, Narasimhan, Saeedi, and
  Tenenbaum]{kulkarni2016hierarchical}
Tejas~D Kulkarni, Karthik~R Narasimhan, Ardavan Saeedi, and Joshua~B Tenenbaum.
\newblock Hierarchical deep reinforcement learning: Integrating temporal
  abstraction and intrinsic motivation.
\newblock \emph{arXiv preprint arXiv:1604.06057}, 2016.

\bibitem[Levine et~al.(2015)Levine, Finn, Darrell, and Abbeel]{levine2015end}
Sergey Levine, Chelsea Finn, Trevor Darrell, and Pieter Abbeel.
\newblock End-to-end training of deep visuomotor policies.
\newblock \emph{arXiv preprint arXiv:1504.00702}, 2015.

\bibitem[Lin(1993)]{lin1993reinforcement}
Long-Ji Lin.
\newblock Reinforcement learning for robots using neural networks.
\newblock Technical report, DTIC Document, 1993.

\bibitem[Lunga et~al.(2014)Lunga, Prasad, Crawford, and
  Ersoy]{lunga2014manifold}
Dalton Lunga, Santasriya Prasad, Melba~M Crawford, and Ozan Ersoy.
\newblock Manifold-learning-based feature extraction for classification of
  hyperspectral data: a review of advances in manifold learning.
\newblock \emph{Signal Processing Magazine, IEEE}, 31\penalty0 (1):\penalty0
  55--66, 2014.

\bibitem[MacQueen et~al.(1967)]{macqueen1967some}
James MacQueen et~al.
\newblock Some methods for classification and analysis of multivariate
  observations.
\newblock 1967.

\bibitem[Mankowitz et~al.(2014)Mankowitz, Mann, and Mannor]{Mann2014b}
Daniel~J Mankowitz, Timothy~A Mann, and Shie Mannor.
\newblock Time regularized interrupting options.
\newblock \emph{Internation Conference on Machine Learning}, 2014.

\bibitem[Mankowitz et~al.(2016)Mankowitz, Mann, and
  Mannor]{mankowitz2016adaptive}
Daniel~J Mankowitz, Timothy~A Mann, and Shie Mannor.
\newblock Adaptive skills, adaptive partitions (asap).
\newblock \emph{Advances in Neural Information Processing Systems (NIPS-30)},
  2016.

\bibitem[Mann et~al.(2015)Mann, Mannor, and Precup]{mann2015approximate}
Timothy~A Mann, Shie Mannor, and Doina Precup.
\newblock Approximate value iteration with temporally extended actions.
\newblock \emph{Journal of Artificial Intelligence Research}, 53\penalty0
  (1):\penalty0 375--438, 2015.

\bibitem[Mannor et~al.(2004)Mannor, Menache, Hoze, and
  Klein]{mannor2004dynamic}
Shie Mannor, Ishai Menache, Amit Hoze, and Uri Klein.
\newblock Dynamic abstraction in reinforcement learning via clustering.
\newblock In \emph{Proceedings of the twenty-first international conference on
  Machine learning}, page~71. ACM, 2004.

\bibitem[Menache et~al.(2002)Menache, Mannor, and Shimkin]{menache2002q}
Ishai Menache, Shie Mannor, and Nahum Shimkin.
\newblock Q-cutâ€”dynamic discovery of sub-goals in reinforcement learning.
\newblock In \emph{Machine Learning: ECML 2002}, pages 295--306. Springer,
  2002.

\bibitem[Mnih et~al.(2013)Mnih, Kavukcuoglu, Silver, Graves, Antonoglou,
  Wierstra, and Riedmiller]{mnih2013playing}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis
  Antonoglou, Daan Wierstra, and Martin Riedmiller.
\newblock Playing atari with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1312.5602}, 2013.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{mnih2015human}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei~A Rusu, Joel Veness,
  Marc~G Bellemare, Alex Graves, Martin Riedmiller, Andreas~K Fidjeland, Georg
  Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540), 2015.

\bibitem[Moore(1991)]{moore-variableresolution}
Andrew Moore.
\newblock Variable resolution dynamic programming: Efficiently learning action
  maps in multivariate real-valued state-spaces.
\newblock In L.~Birnbaum and G.~Collins, editors, \emph{Machine Learning:
  Proceedings of the Eighth International Conference}. Morgan Kaufmann, June
  1991.

\bibitem[Nair et~al.(2015)Nair, Srinivasan, Blackwell, Alcicek, Fearon,
  De~Maria, Panneershelvam, Suleyman, Beattie, Petersen,
  et~al.]{nair2015massively}
Arun Nair, Praveen Srinivasan, Sam Blackwell, Cagdas Alcicek, Rory Fearon,
  Alessandro De~Maria, Vedavyas Panneershelvam, Mustafa Suleyman, Charles
  Beattie, Stig Petersen, et~al.
\newblock Massively parallel methods for deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1507.04296}, 2015.

\bibitem[Nguyen et~al.(2014)Nguyen, Yosinski, and Clune]{nguyen2014deep}
Anh Nguyen, Jason Yosinski, and Jeff Clune.
\newblock Deep neural networks are easily fooled: {H}igh confidence predictions
  for unrecognizable images.
\newblock \emph{arXiv preprint arXiv:1412.1897}, 2014.

\bibitem[Parr(1998)]{parr1998flexible}
Ronald Parr.
\newblock Flexible decomposition algorithms for weakly coupled {M}arkov
  decision problems.
\newblock In \emph{Proceedings of the Fourteenth conference on Uncertainty in
  artificial intelligence}, pages 422--430. Morgan Kaufmann Publishers Inc.,
  1998.

\bibitem[Pitzer et~al.(2011)Pitzer, Styer, Bersch, DuHadway, and
  Becker]{icra11a}
Benjamin Pitzer, Michael Styer, Christian Bersch, Charles DuHadway, and Jan
  Becker.
\newblock Towards perceptual shared autonomy for robotic mobile manipulation.
\newblock In \emph{IEEE International Conference on Robotics Automation
  (ICRA)}, 2011.

\bibitem[Quiroga et~al.(2005)Quiroga, Reddy, Kreiman, Koch, and
  Fried]{quiroga2005invariant}
R~Quian Quiroga, Leila Reddy, Gabriel Kreiman, Christof Koch, and Itzhak Fried.
\newblock Invariant visual representation by single neurons in the human brain.
\newblock \emph{Nature}, 435\penalty0 (7045):\penalty0 1102--1107, 2005.

\bibitem[Ramachandran and Varoquaux(2011)]{ramachandran2011mayavi}
P.~Ramachandran and G.~Varoquaux.
\newblock {Mayavi: 3D Visualization of Scientific Data}.
\newblock \emph{Computing in Science \& Engineering}, 13\penalty0 (2):\penalty0
  40--51, 2011.
\newblock ISSN 1521-9615.

\bibitem[Riedmiller(2005)]{riedmiller2005neural}
Martin Riedmiller.
\newblock Neural fitted {Q} iteration--first experiences with a data efficient
  neural reinforcement learning method.
\newblock In \emph{Machine Learning: ECML 2005}, pages 317--328. Springer,
  2005.

\bibitem[Schaul et~al.(2015)Schaul, Quan, Antonoglou, and
  Silver]{schaul2015prioritized}
Tom Schaul, John Quan, Ioannis Antonoglou, and David Silver.
\newblock Prioritized experience replay.
\newblock \emph{arXiv preprint arXiv:1511.05952}, 2015.

\bibitem[Simonyan and Zisserman(2014)]{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem[{\c{S}}im{\c{s}}ek et~al.(2005){\c{S}}im{\c{s}}ek, Wolfe, and
  Barto]{csimcsek2005identifying}
{\"O}zg{\"u}r {\c{S}}im{\c{s}}ek, Alicia~P Wolfe, and Andrew~G Barto.
\newblock Identifying useful subgoals in reinforcement learning by local graph
  partitioning.
\newblock In \emph{Proceedings of the 22nd international conference on Machine
  learning}, pages 816--823. ACM, 2005.

\bibitem[Singh et~al.(1995)Singh, Jaakkola, and Jordan]{singh1}
Satinder~P Singh, Tommi Jaakkola, and Michael~I Jordan.
\newblock Reinforcement learning with soft state aggregation.
\newblock \emph{Advances in neural information processing systems}, pages
  361--368, 1995.

\bibitem[Sontag(2003)]{sontag2003adaptation}
Eduardo~D Sontag.
\newblock Adaptation and regulation with signal detection implies internal
  model.
\newblock \emph{Systems \& control letters}, 50\penalty0 (2):\penalty0
  119--126, 2003.

\bibitem[Stolle(2004)]{stolle2004automated}
Martin Stolle.
\newblock \emph{Automated discovery of options in reinforcement learning}.
\newblock PhD thesis, McGill University, 2004.

\bibitem[Sutton et~al.(1999)Sutton, Precup, and Singh]{sutton1999between}
Richard~S Sutton, Doina Precup, and Satinder Singh.
\newblock Between {MDP}s and semi-{MDP}s: {A} framework for temporal
  abstraction in reinforcement learning.
\newblock \emph{Artificial intelligence}, 112\penalty0 (1):\penalty0 181--211,
  1999.

\bibitem[Szegedy et~al.(2013)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock \emph{arXiv preprint arXiv:1312.6199}, 2013.

\bibitem[Tenenbaum et~al.(2000)Tenenbaum, De~Silva, and
  Langford]{tenenbaum2000global}
Joshua~B Tenenbaum, Vin De~Silva, and John~C Langford.
\newblock A global geometric framework for nonlinear dimensionality reduction.
\newblock \emph{Science}, 290\penalty0 (5500), 2000.

\bibitem[Tesauro(1995)]{tesauro1995temporal}
Gerald Tesauro.
\newblock Temporal difference learning and {TD}-{G}ammon.
\newblock \emph{Communications of the ACM}, 38\penalty0 (3):\penalty0 58--68,
  1995.

\bibitem[Tessler et~al.(2017)Tessler, Givony, Zahavy, Mankowitz, and
  Mannor]{tessler2016deep}
Chen Tessler, Shahar Givony, Tom Zahavy, Daniel~J Mankowitz, and Shie Mannor.
\newblock A deep hierarchical approach to lifelong learning in minecraft.
\newblock \emph{Conference on Artificial Intelligence (AAAI)}, 2017.

\bibitem[Thrun(1998)]{thrun1998learning}
Sebastian Thrun.
\newblock Learning metric-topological maps for indoor mobile robot navigation.
\newblock \emph{Artificial Intelligence}, 99\penalty0 (1):\penalty0 21--71,
  1998.

\bibitem[Tsitsiklis and Van~Roy(1997)]{tsitsiklis1997analysis}
John~N Tsitsiklis and Benjamin Van~Roy.
\newblock An analysis of temporal-difference learning with function
  approximation.
\newblock \emph{Automatic Control, IEEE Transactions on}, 42\penalty0
  (5):\penalty0 674--690, 1997.

\bibitem[Van Der~Maaten(2014)]{van2014accelerating}
Laurens Van Der~Maaten.
\newblock Accelerating t-{SNE} using tree-based algorithms.
\newblock \emph{The Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 3221--3245, 2014.

\bibitem[Van~Hasselt et~al.(2015)Van~Hasselt, Guez, and Silver]{van2015deep}
Hado Van~Hasselt, Arthur Guez, and David Silver.
\newblock Deep reinforcement learning with double q-learning.
\newblock \emph{arXiv preprint arXiv:1509.06461}, 2015.

\bibitem[Von~Luxburg(2007)]{von2007tutorial}
Ulrike Von~Luxburg.
\newblock A tutorial on spectral clustering.
\newblock \emph{Statistics and computing}, 17\penalty0 (4):\penalty0 395--416,
  2007.

\bibitem[Wang et~al.(2015)Wang, de~Freitas, and Lanctot]{wang2015dueling}
Ziyu Wang, Nando de~Freitas, and Marc Lanctot.
\newblock Dueling network architectures for deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1511.06581}, 2015.

\bibitem[Yosinski et~al.(2014)Yosinski, Clune, Bengio, and
  Lipson]{yosinski2014transferable}
Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson.
\newblock How transferable are features in deep neural networks?
\newblock pages 3320--3328, 2014.

\bibitem[Zahavy et~al.(2016)Zahavy, Zrihem, and Mannor]{Zahavy2016}
Tom Zahavy, Nir~Ben Zrihem, and Shie Mannor.
\newblock Graying the black box: Understanding dqns.
\newblock \emph{Proceedings of the 33 rd International Conference on Machine
  Learning (ICML-16), JMLR: volume48}, 2016.

\bibitem[Zeiler and Fergus(2014)]{zeiler2014visualizing}
Matthew~D Zeiler and Rob Fergus.
\newblock Visualizing and understanding convolutional networks.
\newblock pages 818--833, 2014.

\end{thebibliography}
