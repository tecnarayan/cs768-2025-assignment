
@article{lee2008existence,
  title={{Existence of Asymptotic Solutions to Semi-linear Partial Difference Equations}},
  author={{Jason D. Lee} and Neuberger, John},
  journal={Joint Mathematics Meetings},
  pages={},
  year={2008}
}

@article{lee2010practical,
  title={{Practical Large-Scale Optimization for Max-Norm Regularization}},
  author={{Jason D. Lee} and Recht, Ben and Srebro, Nathan and Tropp, Joel and Salakhutdinov, Ruslan},
  journal={Neural Information Processing Systems (NIPS)},
  pages={1297--1305},
  year={2010}
}

@article{little2009estimation,
  title={{Estimation of Intrinsic Dimensionality of Samples from Noisy Low-Dimensional Manifolds in High Dimensions with Multiscale SVD}},
  author={Little, Anna V. and {Jason D. Lee} and Jung, Yoon-Mo and Maggioni, Mauro},
  journal={IEEE Workshop on Statistical Signal Processing (SSP)},
  pages={85--88},
  year={2009}  
}

@article{kliegl2010generalized,
  title={{Generalized DCell Structure for Load-Balanced Data Center Networks}},
  author={Kliegl, Markus and {Jason D. Lee} and Li, Jun and Zhang, Xinchao and Guo, Chuanxiong and Rinc{\'o}n, David},
  journal={IEEE Conference on Computer Communications (INFOCOM)},
  pages={1--5},
  year={2010}
}

@article{kliegl2010generalizedtech,
  title={Generalized DCell Structure for Load-Balanced Data Center Networks},
  author={Kliegl, Markus and {Jason D. Lee} and Li, Jun and Zhang, Xinchao and Guo, Chuanxiong and Rinc{\'o}n, David},
  journal={Microsoft Research Technical Report},
  pages={1--14},
  year={2009},
  url={http://research.microsoft.com/apps/pubs/default.aspx?id=103129}
}

@article{lee2011multiscale,
  title={{Multiscale Analysis of Time Series of Graphs}},
  author={{Jason D. Lee} and Maggioni, Mauro},
  journal={International Conference on Sampling Theory and Applications (SAMPTA)},
  year={2011}
}

@article{lee2010multiscale,
  title={{Multiscale Estimation of Intrinsic Dimensionality of Point Cloud Data and Multiscale Analysis of Dynamic Graphs}},
  author={{Jason D. Lee}},
  journal={Senior Thesis, Duke University},
  year={2010}
}

@article{leemulticlass,
  title={{Multiclass Clustering using a Semidefinite Relaxation}},
  author={{Jason D. Lee}},
  journal={Tech Report},
}

@article{lee2012proximal,
  title={{Proximal Newton-type Methods for Convex Optimization}},
  author={{Jason D. Lee} and Sun, Yuekai and Saunders, Michael},
  journal={Neural Information Processing Systems (NIPS)},
  pages={836--844},
  year={2012}
}

@article{lee2012convergence,
  title={{Convergence Analysis of Inexact Proximal Newton-Type Methods}},
  author={{Jason D. Lee} and Sun, Yuekai and Saunders, Michael A},
  journal={NIPS Workshop on Optimization in Machine Learning},
  pages={},
  year={2012}
}


@article{monajemi2013deterministic,
  title={{Deterministic Matrices Matching the Compressed Sensing Phase Transitions of Gaussian Random Matrices}},
  author={Monajemi, Hatef and Jafarpour, Sina and Gavish, Matan and {
Stat 330/CME 362 Collaboration} and Donoho, David L},
  journal={Proceedings of the National Academy of Sciences},
  volume={110},
  number={4},
  pages={1181--1186},
  year={2013},
  publisher={National Acad Sciences}
}

@article{lee2014proximal,
author = {{Jason D. Lee} and Sun, Yuekai and Saunders, Michael},
title = {{Proximal Newton-Type Methods for Minimizing Composite Functions}},
journal = {SIAM Journal on Optimization},
year = {2014}
}

@article{lee2013model,
  title={{On Model Selection Consistency of Penalized M-Estimators: a Geometric Theory}},
  author={{Jason D. Lee} and Sun, Yuekai and Taylor, Jonathan E. },
  journal={Neural Information Processing Systems (NIPS)},
  pages={342--350},
  year={2013}
}

@article{lee2015modelJournal,
  title={{On Model Selection Consistency of Regularized M-Estimators}},
  author={{Jason D. Lee} and Sun, Yuekai and Taylor, Jonathan E. },
  journal={Electronic Journal of Statistics},
  year={2015}
}


@article{lee2016exact,
  title={{Exact Inference after Model Selection via the Lasso}},
  author={{Jason D. Lee} and Sun, Dennis L. and Sun, Yuekai and Taylor, Jonathan E.  },
  journal={Annals of Statistics},
  year={2016}
}

@article{lee2013using,
  title={{Using Multiple Samples to Learn Mixture Models}},
  author={{Jason D. Lee} and Gilad-Bachrach, Ran and Caruana, Rich},
  journal={Neural Information Processing Systems (NIPS)},
  pages={324--332},
  year={2013}
}

@article{lee2014learning,
  title={{Learning the Structure of Mixed Graphical Models}},
  author={{Jason D. Lee} and Hastie, Trevor J},
  journal={Journal of Computational and Graphical Statistics},
  number={},
  pages={},
  year={2014},
  publisher={Taylor \& Francis}
}

@article{lee2013structure,
  title={{Structure Learning of Mixed Graphical Models}},
  author={{Jason D. Lee} and Hastie, Trevor},
  journal={Artificial Intelligence and Statistics (AISTATS)},
  pages={388--396},
  year={2013}
}

@article{lee2014exact,
  title={{Exact Post Model Selection Inference for Marginal Screening}},
  author={{Jason D. Lee} and Taylor, Jonathan E. },
  journal={Neural Information Processing Systems (NIPS)},
  pages={1--9},
  year={2014}
}

@article{benson2014scalable,
  title={{Scalable Methods for Nonnegative Matrix Factorizations of Near-Separable Tall-and-Skinny Matrices}},
  author={Benson, Austin R and {Jason D. Lee} and Rajwa, Bartek and Gleich, David F.},
  journal={Neural Information Processing Systems (NIPS)},
  pages={1--9},
  year={2014}
}

@article{lee2015significance,
  title={{Evaluating the Statistical Significance of Biclusters}},
  author={{Jason D. Lee} and Sun, Yuekai and Taylor, Jonathan E. },
  journal={Neural Information Processing Systems (NIPS)},
  pages={1--9},
  year={2015}
}

@article{lee2017one,
  title={{Communication-Efficient Distributed Sparse Regression}},
  author={{Jason D. Lee} and Liu, Qiang and Sun, Yuekai and Taylor, Jonathan E. },
  journal={Journal of Machine Learning Research},
  year={2017}
}

@article{hastie2015fast,
  title={{Matrix Completion and Low-Rank SVD via Fast Alternating Least Squares}},
  author={Hastie, Trevor and Mazumder, Rahul and {Jason D. Lee} and Zadeh, Reza},
  journal={Journal of Machine Learning Research},
  year={2015}
}

@article{lee2016gradient,
  title={Gradient Descent Converges to Minimizers},
  author={{Jason D. Lee} and Simchowitz, Max and Jordan, Michael I and Recht, Benjamin},
  journal={Conference on Learning Theory (COLT)},
  year={2016}
}

@article{zhang2016l1,
  title={l1-regularized Neural Networks are Improperly Learnable in Polynomial Time},
  author={Zhang, Yuchen and {Jason D. Lee} and Jordan, Michael I},
  journal={International Conference on Machine Learning (ICML)},
  year={2016}
}

@article{zhang2017learning,
  title={Learning Halfspaces and Neural Networks with Random Initialization},
  author={Zhang, Yuchen and {Jason D. Lee} and Wainwright, Martin J and Jordan, Michael I},
  journal={Artificial Intelligence and Statistics (AISTATS)},
  year={2017}
}

@article{liu2016kernelized,
  title={A Kernelized Stein Discrepancy for Goodness-of-fit Tests and Model Evaluation},
  author={Liu, Qiang and {Jason D. Lee} and Jordan, Michael I},
  journal={International Conference on Machine Learning (ICML)},
  year={2016}
}

@article{lee2017distributed,
  title={Distributed Stochastic Variance Reduced Gradient Methods},
  author={{Jason D. Lee} and Ma, Tengyu and Lin, Qihang and Yang, Tianbao},
  journal={Journal of Machine Learning Research},
  year={2017}
}

@article{ge2016matrix,
  title={Matrix Completion has No Spurious Local Minimum},
  author={Ge, Rong and {Jason D. Lee} and Ma, Tengyu},
  journal={Neural Information Processing Systems (NIPS)},
  year={2016}
}

@article{jordan2018communication,
  title={Communication-efficient distributed statistical learning},
  author={Jordan, Michael I and {Jason D. Lee} and Yang, Yun},
  journal={Journal of the American Statistics Association},
  year={2018}
}

@article{liu2017black,
  title={Black-box importance sampling},
  author={Liu, Qiang and Lee, Jason D},
  journal={Artificial Intelligence and Statistics (AISTATS)},
  year={2017}
}

@article{wang2017sketching,
  title={Sketching Meets Random Projection in the Dual: A Provable Recovery Algorithm for Big and High-dimensional Data},
  author={Wang, Jialei and Lee, Jason D and Mahdavi, Mehrdad and Kolar, Mladen and Srebro, Nathan},
  journal={Electronic Journal of Statistics},
  year={2017}
}

@article{wang2017sketchingAistat,
  title={Sketching Meets Random Projection in the Dual: A Provable Recovery Algorithm for Big and High-dimensional Data},
  author={Wang, Jialei and Lee, Jason D and Mahdavi, Mehrdad and Kolar, Mladen and Srebro, Nathan},
  journal={Artificial Intelligence and Statistics (AISTATS)},
  year={2017}
}


@article{du2017gradient,
  title={Gradient Descent Can Take Exponential Time to Escape Saddle Points},
  author={Du, Simon S and Jin, Chi and Lee, Jason D and Jordan, Michael I and Singh, Aarti and Poczos, Barnabas},
  journal={Neural Information Processing Systems (NIPS)},
  year={2017}
}

@article{du2018cnn,
  title={Gradient Descent Learns One-hidden-layer CNN: Don't be Afraid of Spurious Local Minima},
  author={Du, Simon S and Lee, Jason D and Tian, Yuandong and Poczos, Barnabas and Singh, Aarti},
  journal={International Conference on Machine Learning (ICML)},
  year={2018}
}

@article{ge2018learning,
  title={Learning One-hidden-layer Neural Networks with Landscape Design},
  author={Ge, Rong and Lee, Jason D and Ma, Tengyu},
  journal={International Conference on Learning Representations (ICLR)},
  year={2018}
}

@article{lee2018first,
  title={First-order Methods Almost Always Avoid Saddle Points},
  author={Lee, Jason D and Panageas, Ioannis and Piliouras, Georgios and Simchowitz, Max and Jordan, Michael I and Recht, Benjamin},
  journal={Accepted at Math Programming},
  year={2018}
}

@article{du2018convolutional,
  title={When is a Convolutional Filter Easy to Learn?},
  author={Du, Simon S and Lee, Jason D and Tian, Yuandong},
  journal={International Conference on Learning Representations (ICLR)},
  year={2018}
}

@article{soltanolkotabi2018theoretical,
  title={Theoretical insights into the optimization landscape of over-parameterized shallow neural networks},
  author={Soltanolkotabi, Mahdi and Javanmard, Adel and Lee, Jason D},
  journal={Transactions on Information Theory},
  year={2018}
}

@article{javanmard2018flexible,
  title={A Flexible Framework for Hypothesis Testing in High-dimensions},
  author={Javanmard, Adel and Lee, Jason D},
  journal={Accepted Journal of the Royal Statistical Society Series B},
  year={}
}

@article{chen2018statistical,
  title={Statistical inference for model parameters in stochastic gradient descent},
  author={Chen, Xi and Lee, Jason D and Tong, Xin T and Zhang, Yichen and others},
  journal={The Annals of Statistics},
  volume={48},
  number={1},
  pages={251--273},
  year={2020},
  publisher={Institute of Mathematical Statistics}
}
@article{liu2018inexact,
  title={An inexact subsampled proximal Newton-type method for large-scale machine learning},
  author={Liu, Xuanqing and Hsieh, Cho-Jui and Lee, Jason D and Sun, Yuekai},
  journal={Submitted to Journal of Machine Learning Research},
  year={}
}

@article{wu2018NoSpurious,
  title={No Spurious Local Minima in a Two Node Neural Network},
  author={Wu, Chenwei and Luo, Jiajun and Lee, Jason D},
  journal={International Conference on Learning Representations (ICLR) Workshop Track},
  year={2018}
}

@article{gunasekar2018characterizing,
  title={Characterizing Implicit Bias in Terms of Optimization Geometry},
  author={Gunasekar, Suriya and Lee, Jason and Soudry, Daniel and Srebro, Nathan},
  journal={International Conference on Machine Learning (ICML)},
  year={2018}
}

@article{nacson2018convergence,
  title={Convergence of Gradient Descent on Separable Data},
  author={Nacson, Mor Shpigel and Lee, Jason D. and Gunasekar, Suriya and Srebro, Nathan and Soudry, Daniel},
  journal={Artificial Intelligence and Statistics (AISTATS) },
  year={2019}
}

@article{du2018power, 
  title={On the Power of Over-parametrization in Neural Networks with Quadratic Activation},
  author={Du, Simon S and Lee, Jason D},
  journal={International Conference on Machine Learning (ICML)},
  year={2018}
}

@article{sanjabi2018solving,
  title={Solving Approximate Wasserstein GANs to Stationarity},
  author={Sanjabi, Maziar and Ba, Jimmy and Razaviyayn, Meisam and Lee, Jason D},
  journal={Neural Information Processing Systems (NIPS)},
  year={2018}
}

@article{hong2018gradient,
  title={Gradient Primal-Dual Algorithm Converges to Second-Order Stationary Solutions for Nonconvex Distributed Optimization},
  author={Hong, Mingyi and Lee, Jason D and Razaviyayn, Meisam},
  journal={International Conference on Machine Learning (ICML)},
  year={2018}
}

@article{lee2018stochastic,
  title={Stochastic Subgradient Converges in Polynomial Time on Nonsmooth Functions},
  author={Lee, Jason D },
  journal={Unpublished},
  year={2018}
}

@article{kakade2018provable,
  title={Provably Correct Automatic Subdifferentiation for Qualified Programs},
  author={Kakade, Sham and Lee, Jason D },
  journal={Neural Information Processing Systems (NIPS)},
  year={2018}
}

@article{liang2018adding,
  title={Adding One Neuron Can Eliminate All Bad Local Minima},
  author={Liang, Shiyu and Sun, Ruoyu and Lee, Jason D and Srikant, R},
  journal={Neural Information Processing Systems (NIPS)},
  year={2018}
}

@article{davis2018stochastic,
  title={Stochastic subgradient method converges on tame functions},
  author={Davis, Damek and Drusvyatskiy, Dmitriy and Kakade, Sham and Lee, Jason D},
  journal={Foundations of Computational Mathematics},
  year={2018}
}

@article{gunasekar2018implicit,
  title={Implicit Bias of Gradient Descent on Linear Convolutional Networks},
  author={Gunasekar, Suriya and Lee, Jason and Soudry, Daniel and Srebro, Nathan},
  journal={Neural Information Processing Systems (NIPS)},
  year={2018}
}

@article{du2018algorithmic,
  title={Algorithmic Regularization in Learning Deep Homogeneous Models: Layers are Automatically Balanced},
  author={Du, Simon S and Hu, Wei and Lee, Jason D},
  journal={Neural Information Processing Systems (NIPS)},
  year={2018}
}

@article{nouiehed2018convergence,
  title={Convergence to Second-Order Stationarity for Constrained Non-Convex Optimization},
  author={Nouiehed, Maher and Lee, Jason D and Razaviyayn, Meisam},
  journal={Submitted to SIAM Journal on Optimization},
  year={2018}
}


@article{du2018gradient,
  title={Gradient Descent Finds Global Minima of Deep Neural Networks},
  author={Du, Simon S and Lee, Jason D and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
  journal={International Conference on Machine Learning (ICML)},
  year={2019}
}

@article{nacson2019lexicographic,
  title={
Lexicographic and Depth-Sensitive Margins in Homogeneous and Non-Homogeneous Training},
  author={Nacson, Mor Sphigel and Gunasekar, Suriya and Lee, Jason D and Srebro, Nathan and Soudry Daniel},
  journal={International Conference on Machine Learning (ICML)},
  year={2019}
}

@article{li2019incremental,
  title={Incremental (Sub)-Gradient Descent for Weakly Convex Optimization},
  author={Li, Xiao and Zhu, Zhihui and So, Anthony Man-Cho and Lee, Jason D.},
  journal={Submitted to SIOPT},
  year={2019}
}


@article{wei2018margin,
  title={Regularization Matters: Generalization and Optimization of Neural Nets v.s. their Induced Kernel.},
  author={Wei, Colin and Lee, Jason D and Liu, Qiang and Ma, Tengyu},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2019}
}

@article{nouiehed2019solving,
  title={Solving a class of non-convex min-max games using iterative first order methods},
  author={Nouiehed, Maher and Sanjabi, Maziar and Huang, Tianjian and Lee, Jason D and Razaviyayn, Meisam},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2019}
}

@article{cai2019neural,
  title={Neural Temporal-Difference Learning Converges to Global Optima},
  author={Cai, Qi and Yang, Zhuoran and Lee, Jason D and Wang, Zhaoran},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2019}
}


@article{bai2019beyond,
  title={Beyond Linearization: On Quadratic and Higher-Order Approximation of Wide Neural Networks},
  author={Bai, Yu and Lee, Jason D},
  journal={International Conference on Learning Representations (ICLR)},
  year={2020}
}

@article{agarwal2019optimality,
  title={Optimality and Approximation with Policy Gradient Methods in Markov Decision Processes},
  author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
  journal={Conference on Learning Theory (COLT)},
  year={2020}
}

@article{lei2019sgd,
  title={SGD Learns One-Layer Networks in WGANs},
  author={Lei, Qi and Lee, Jason D and Dimakis, Alexandros G and Daskalakis, Constantinos},
  journal={International Conference on Machine Learning (ICML)},
  year={2020}
}

@article{makkuva2019optimal,
  title={Optimal transport mapping via input convex neural networks},
  author={Makkuva, Ashok Vardhan and Taghvaei, Amirhossein and Oh, Sewoong and Lee, Jason D},
  journal={International Conference on Machine Learning (ICML)},
  year={2020}
}

@article{gao2019convergence,
  title={Convergence of Adversarial Training in Overparametrized Networks},
  author={Gao, Ruiqi and Cai, Tianle and Li, Haochuan and Wang, Liwei and Hsieh, Cho-Jui and Lee, Jason D},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2019}
}


@article{woodworth2019kernel,
  title={Kernel and Deep Regimes in Overparametrized Models},
  author={Woodworth, Blake and Gunasekar, Suriya and Lee, Jason and Soudry, Daniel and Srebro, Nathan},
  journal={Conference on Learning Theory (COLT)},
  year={2020}
}



@article{haochen2020shape,
  title={Shape Matters: Understanding the Implicit Bias of the Noise Covariance},
  author={HaoChen, Jeff Z. and Wei, Colin and Lee, Jason D. and Ma, Tengyu},
  journal={arXiv preprint arXiv:2006.08680},
  year={2020}
}

@article{du2020few,
  title={Few-shot learning via learning the representation, provably},
  author={Du, Simon S and Hu, Wei and Kakade, Sham M and Lee, Jason D and Lei, Qi},
  journal={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@article{du2020agnostic,
  title={Agnostic Q-learning with function approximation in deterministic systems: Tight bounds on approximation error and sample complexity},
  author={Du, Simon S and Lee, Jason D and Mahajan, Gaurav and Wang, Ruosong},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{moroshko2020implicit,
  title={Implicit Bias in Deep Linear Classification: Initialization Scale vs Training Accuracy},
  author={Moroshko, Edward and Gunasekar, Suriya and Woodworth, Blake and Lee, Jason D and Srebro, Nathan and Soudry, Daniel},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{chen2020towards,
  title={Towards Understanding Hierarchical Learning: Benefits of Neural Representations},
  author={Chen, Minshuo and Bai, Yu and Lee, Jason D and Zhao, Tuo and Wang, Huan and Xiong, Caiming and Socher, Richard},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{chen2020distributed,
  title={Distributed Estimation for Principal Component Analysis: a Gap-free Approach},
  author={Chen, Xi and Lee, Jason D and Li, He and Yang, Yun},
  journal={Journal of the American Statistical Association},
  year={2021}
}

@article{wu2020steepest,
  title={Steepest Descent Neural Architecture Optimization: Escaping Local Optimum with Signed Neural Splitting},
  author={Wu, Lemeng and Ye, Mao and Lei, Qi and Lee, Jason D and Liu, Qiang},
  journal={arXiv preprint arXiv:2003.10392},
  year={2020}
}

@article{fang2020modeling,
  title={Modeling from Features: a Mean-field Framework for Over-parameterized Deep Neural Networks},
  author={Fang, Cong and Lee, Jason D and Yang, Pengkun and Zhang, Tong},
  journal={arXiv preprint arXiv:2007.01452},
  year={2020}
}

@article{ji2020convergence,
  title={Convergence of Meta-Learning with Task-Specific Adaptation over Partial Parameters},
  author={Ji, Kaiyi and Lee, Jason D and Liang, Yingbin and Poor, H Vincent},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{su2020sanity,
  title={Sanity-Checking Pruning Methods: Random Tickets can Win the Jackpot},
  author={Su, Jingtong and Chen, Yihang and Cai, Tianle and Wu, Tianhao and Gao, Ruiqi and Wang, Liwei and Lee, Jason D},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{lee2020predicting,
  title={Predicting what you already know helps: Provable self-supervised learning},
  author={Lee, Jason D and Lei, Qi and Saunshi, Nikunj and Zhuo, Jiacheng},
  journal={arXiv preprint arXiv:2008.01064},
  year={2020}
}

@article{wang2020beyond,
  title={Beyond Lazy Training for Over-parameterized Tensor Decomposition},
  author={Wang, Xiang and Wu, Chenwei and Lee, Jason D and Ma, Tengyu and Ge, Rong},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{lee2020generalized,
  title={Generalized Leverage Score Sampling for Neural Networks},
  author={Lee, Jason D and Shen, Ruoqi and Song, Zhao and Wang, Mengdi and others},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{gu2020characterize,
  title={How to Characterize The Landscape of Overparameterized Convolutional Neural Networks},
  author={Gu, Yihong and Zhang, Weizhong and Fang, Cong and Lee, Jason D and Zhang, Tong},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{agarwal2020on,
  title={On the Theory of Policy Gradient Methods },
  author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
  journal={JMLR (short version at COLT)},
  year={2020}
}

@article{yang2020provable,
  title={Provable Benefits of Representation Learning in Linear Bandits},
  author={Yang, Jiaqi and Hu, Wei and Lee, Jason D and Du, Simon S},
  journal={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@article{du2021bilinear,
	title={Bilinear Classes: A Structural Framework for Provable Generalization in RL},
	author={Du, Simon S and Kakade, Sham M and Lee, Jason D and Lovett, Shachar and Mahajan, Gaurav and Sun, Wen and Wang, Ruosong},
	journal={arXiv preprint arXiv:2103.10897},
	year={2021}
}

@article{damian2021label,
  title={Escaping Global Minimizers with Label Noise SGD},
  author={Damian, Alex and Ma, Tengyu and Lee, Jason D.},
  year={2021},
}
