\begin{thebibliography}{71}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ament et~al.(2023)Ament, Daulton, Eriksson, Balandat, and Bakshy]{ament2023unexpected}
Ament, S., Daulton, S., Eriksson, D., Balandat, M., and Bakshy, E.
\newblock Unexpected improvements to expected improvement for bayesian optimization.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.
\newblock URL \url{https://openreview.net/forum?id=1vyAG6j9PE}.

\bibitem[Bakshy et~al.()Bakshy, Dworkin, Karrer, Kashin, Letham, Murthy, and Singh]{bakshy2018ae}
Bakshy, E., Dworkin, L., Karrer, B., Kashin, K., Letham, B., Murthy, A., and Singh, S.
\newblock Ae: A domain-agnostic platform for adaptive experimentation.

\bibitem[Balandat et~al.(2020)Balandat, Karrer, Jiang, Daulton, Letham, Wilson, and Bakshy]{balandat2020botorch}
Balandat, M., Karrer, B., Jiang, D.~R., Daulton, S., Letham, B., Wilson, A.~G., and Bakshy, E.
\newblock Botorch: A framework for efficient monte-carlo bayesian optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.
\newblock URL \url{http://arxiv.org/abs/1910.06403}.

\bibitem[Baptista \& Poloczek(2018)Baptista and Poloczek]{pmlr-v80-baptista18a}
Baptista, R. and Poloczek, M.
\newblock {B}ayesian optimization of combinatorial structures.
\newblock In Dy, J. and Krause, A. (eds.), \emph{Proceedings of the 35th International Conference on Machine Learning}, volume~80 of \emph{Proceedings of Machine Learning Research}, pp.\  462--471. PMLR, 10--15 Jul 2018.
\newblock URL \url{https://proceedings.mlr.press/v80/baptista18a.html}.

\bibitem[Berkenkamp et~al.(2019)Berkenkamp, Schoellig, and Krause]{bergenkamp2019noregret}
Berkenkamp, F., Schoellig, A.~P., and Krause, A.
\newblock No-regret bayesian optimization with unknown hyperparameters.
\newblock \emph{Journal of Machine Learning Research}, 20\penalty0 (50):\penalty0 1--24, 2019.
\newblock URL \url{http://jmlr.org/papers/v20/18-213.html}.

\bibitem[Bingham et~al.(2018)Bingham, Chen, Jankowiak, Obermeyer, Pradhan, Karaletsos, Singh, Szerlip, Horsfall, and Goodman]{bingham2018pyro}
Bingham, E., Chen, J.~P., Jankowiak, M., Obermeyer, F., Pradhan, N., Karaletsos, T., Singh, R., Szerlip, P., Horsfall, P., and Goodman, N.~D.
\newblock {Pyro: Deep Universal Probabilistic Programming}.
\newblock \emph{Journal of Machine Learning Research}, 2018.

\bibitem[Binois \& Wycoff(2022)Binois and Wycoff]{binois2022hdsurvey}
Binois, M. and Wycoff, N.
\newblock A survey on high-dimensional gaussian process modeling with application to bayesian optimization.
\newblock \emph{ACM Trans. Evol. Learn. Optim.}, 2\penalty0 (2), aug 2022.
\newblock \doi{10.1145/3545611}.
\newblock URL \url{https://doi.org/10.1145/3545611}.

\bibitem[Binois et~al.(2020)Binois, Ginsbourger, and Roustant]{binois2020random}
Binois, M., Ginsbourger, D., and Roustant, O.
\newblock On the choice of the low-dimensional domain for global optimization via random embeddings.
\newblock \emph{J. of Global Optimization}, 76\penalty0 (1):\penalty0 69–90, jan 2020.
\newblock ISSN 0925-5001.
\newblock \doi{10.1007/s10898-019-00839-1}.
\newblock URL \url{https://doi.org/10.1007/s10898-019-00839-1}.

\bibitem[Bull(2011)]{bull-jmlr11a}
Bull, A.~D.
\newblock Convergence rates of efficient global optimization algorithms.
\newblock 12:\penalty0 2879--2904, 2011.

\bibitem[{Cho} et~al.(2004){Cho}, {Bowman}, and {North}]{2004JApMe..43.1586C}
{Cho}, H.-K., {Bowman}, K.~P., and {North}, G.~R.
\newblock {A Comparison of Gamma and Lognormal Distributions for Characterizing Satellite Rain Rates from the Tropical Rainfall Measuring Mission.}
\newblock \emph{Journal of Applied Meteorology}, 43\penalty0 (11):\penalty0 1586--1597, November 2004.
\newblock \doi{10.1175/JAM2165.1}.

\bibitem[De~Ath et~al.(2020)De~Ath, Fieldsend, and Everson]{death2020mean}
De~Ath, G., Fieldsend, J.~E., and Everson, R.~M.
\newblock What do you mean? the role of the mean function in bayesian optimisation.
\newblock In \emph{Proceedings of the 2020 Genetic and Evolutionary Computation Conference Companion}, GECCO '20, pp.\  1623–1631, New York, NY, USA, 2020. Association for Computing Machinery.
\newblock ISBN 9781450371278.
\newblock \doi{10.1145/3377929.3398118}.
\newblock URL \url{https://doi.org/10.1145/3377929.3398118}.

\bibitem[Djolonga et~al.(2013)Djolonga, Krause, and Cevher]{NIPS2013_8d34201a}
Djolonga, J., Krause, A., and Cevher, V.
\newblock High-dimensional gaussian process bandits.
\newblock In Burges, C., Bottou, L., Welling, M., Ghahramani, Z., and Weinberger, K. (eds.), \emph{Advances in Neural Information Processing Systems}, volume~26. Curran Associates, Inc., 2013.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2013/file/8d34201a5b85900908db6cae92723617-Paper.pdf}.

\bibitem[Duembgen(2010)]{Duembgen2010BoundingSG}
Duembgen, L.
\newblock Bounding standard gaussian tail probabilities.
\newblock \emph{arXiv: Statistics Theory}, 2010.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:88512442}.

\bibitem[Duvenaud et~al.(2011)Duvenaud, Nickisch, and Rasmussen]{duvenaud2011additive}
Duvenaud, D.~K., Nickisch, H., and Rasmussen, C.
\newblock Additive gaussian processes.
\newblock In Shawe-Taylor, J., Zemel, R., Bartlett, P., Pereira, F., and Weinberger, K. (eds.), \emph{Advances in Neural Information Processing Systems}, volume~24. Curran Associates, Inc., 2011.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2011/file/4c5bde74a8f110656874902f07378009-Paper.pdf}.

\bibitem[Eduardo \& Gutmann(2022)Eduardo and Gutmann]{Eduardo2022BayesianOW}
Eduardo, A. and Gutmann, M.~U.
\newblock Bayesian optimization with informative covariance.
\newblock \emph{Trans. Mach. Learn. Res.}, 2023, 2022.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:251320397}.

\bibitem[Eriksson \& Jankowiak(2021)Eriksson and Jankowiak]{pmlr-v161-eriksson21a}
Eriksson, D. and Jankowiak, M.
\newblock High-dimensional {Bayesian} optimization with sparse axis-aligned subspaces.
\newblock In de~Campos, C. and Maathuis, M.~H. (eds.), \emph{Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial Intelligence}, volume 161 of \emph{Proceedings of Machine Learning Research}, pp.\  493--503. PMLR, 27--30 Jul 2021.
\newblock URL \url{https://proceedings.mlr.press/v161/eriksson21a.html}.

\bibitem[Eriksson et~al.(2019)Eriksson, Pearce, Gardner, Turner, and Poloczek]{eriksson2019turbo}
Eriksson, D., Pearce, M., Gardner, J., Turner, R.~D., and Poloczek, M.
\newblock Scalable global optimization via local bayesian optimization.
\newblock In Wallach, H., Larochelle, H., Beygelzimer, A., d\textquotesingle Alch\'{e}-Buc, F., Fox, E., and Garnett, R. (eds.), \emph{Advances in Neural Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.
\newblock URL \url{https://proceedings.neurips.cc/paper/2019/file/6c990b7aca7bc7058f5e98ea909e924b-Paper.pdf}.

\bibitem[Gardner et~al.(2017)Gardner, Guo, Weinberger, Garnett, and Grosse]{gardner-aistats17a}
Gardner, J., Guo, C., Weinberger, K., Garnett, R., and Grosse, R.
\newblock Discovering and {Exploiting} {Additive} {Structure} for {Bayesian} {Optimization}.
\newblock In Singh, A. and Zhu, J. (eds.), \emph{Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics ({AISTATS})}, volume~54, pp.\  1311--1319. Proceedings of Machine Learning Research, 2017.

\bibitem[Garnett et~al.(2014)Garnett, Osborne, and Hennig]{garnett2014active}
Garnett, R., Osborne, M.~A., and Hennig, P.
\newblock Active learning of linear embeddings for gaussian processes.
\newblock In \emph{Proceedings of the Thirtieth Conference on Uncertainty in Artificial Intelligence}, UAI'14, pp.\  230–239, Arlington, Virginia, USA, 2014. AUAI Press.
\newblock ISBN 9780974903910.

\bibitem[GPyOpt-authors(2016)]{gpyopt2016}
GPyOpt-authors, T.
\newblock {GPyOpt}: A bayesian optimization framework in python.
\newblock \url{http://github.com/SheffieldML/GPyOpt}, 2016.

\bibitem[Griffiths \& Hern{\'a}ndez-Lobato(2017)Griffiths and Hern{\'a}ndez-Lobato]{Griffiths2017ConstrainedBO}
Griffiths, R.-R. and Hern{\'a}ndez-Lobato, J.~M.
\newblock Constrained bayesian optimization for automatic chemical design.
\newblock \emph{arXiv: Machine Learning}, 2017.

\bibitem[Han et~al.(2021)Han, Arora, and Scarlett]{Han_Arora_Scarlett_2021}
Han, E., Arora, I., and Scarlett, J.
\newblock High-dimensional bayesian optimization via tree-structured additive models.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, 35\penalty0 (9):\penalty0 7630--7638, May 2021.
\newblock URL \url{https://ojs.aaai.org/index.php/AAAI/article/view/16933}.

\bibitem[Hansen(2006)]{hansen-eda06a}
Hansen, N.
\newblock The {CMA} evolution strategy: a comparing review.
\newblock In Lozano, J., Larranaga, P., Inza, I., and Bengoetxea, E. (eds.), \emph{Towards a new evolutionary computation. Advances on estimation of distribution algorithms}, pp.\  75--102. 2006.

\bibitem[Hellsten et~al.(2023)Hellsten, Hvarfner, Papenmeier, and Nardi]{hellsten2023highdimensional}
Hellsten, E.~O., Hvarfner, C., Papenmeier, L., and Nardi, L.
\newblock High-dimensional bayesian optimization with group testing, 2023.

\bibitem[Hutter et~al.(2011)Hutter, Hoos, and Leyton-Brown]{smac}
Hutter, F., Hoos, H.~H., and Leyton-Brown, K.
\newblock Sequential model-based optimization for general algorithm configuration.
\newblock In \emph{Learning and Intelligent Optimization}, 2011.

\bibitem[Hvarfner et~al.(2023)Hvarfner, Hellsten, Hutter, and Nardi]{hvarfner2023selfcorrecting}
Hvarfner, C., Hellsten, E.~O., Hutter, F., and Nardi, L.
\newblock Self-correcting bayesian optimization through bayesian active learning.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.
\newblock URL \url{https://openreview.net/forum?id=dX9MjUtP1A}.

\bibitem[Jones et~al.(1998)Jones, Schonlau, and Welch]{jones-jgo98a}
Jones, D., Schonlau, M., and Welch, W.
\newblock Efficient global optimization of expensive black box functions.
\newblock 13:\penalty0 455--492, 1998.

\bibitem[Jones(2001)]{jones-jgo01a}
Jones, D.~R.
\newblock A taxonomy of global optimization methods based on response surfaces.
\newblock 21:\penalty0 345--383, 2001.

\bibitem[Kandasamy et~al.(2015)Kandasamy, Schneider, and Póczos]{kandasamy-icml15a}
Kandasamy, K., Schneider, J., and Póczos, B.
\newblock High {Dimensional} {Bayesian} {Optimisation} and {Bandits} via {Additive} {Models}.
\newblock In Bach, F. and Blei, D. (eds.), \emph{Proceedings of the 32nd International Conference on Machine Learning ({ICML}'15)}, volume~37, pp.\  295--304. Omnipress, 2015.

\bibitem[Karvonen \& Oates(2023)Karvonen and Oates]{JMLR:v24:22-1153}
Karvonen, T. and Oates, C.~J.
\newblock Maximum likelihood estimation in gaussian process regression is ill-posed.
\newblock \emph{Journal of Machine Learning Research}, 24\penalty0 (120):\penalty0 1--47, 2023.
\newblock URL \url{http://jmlr.org/papers/v24/22-1153.html}.

\bibitem[Kirschner et~al.(2019)Kirschner, Mutny, Hiller, Ischebeck, and Krause]{pmlr-v97-kirschner19a}
Kirschner, J., Mutny, M., Hiller, N., Ischebeck, R., and Krause, A.
\newblock Adaptive and safe {B}ayesian optimization in high dimensions via one-dimensional subspaces.
\newblock In Chaudhuri, K. and Salakhutdinov, R. (eds.), \emph{Proceedings of the 36th International Conference on Machine Learning}, volume~97 of \emph{Proceedings of Machine Learning Research}, pp.\  3429--3438. PMLR, 09--15 Jun 2019.
\newblock URL \url{https://proceedings.mlr.press/v97/kirschner19a.html}.

\bibitem[K{\"o}ppen(2000)]{koppencurse}
K{\"o}ppen, M.
\newblock The curse of dimensionality.
\newblock \emph{5th online world conference on soft computing in industrial applications (WSC5)}, 2000.

\bibitem[Krause et~al.(2008)Krause, Singh, and Guestrin]{JMLR:v9:krause08a}
Krause, A., Singh, A., and Guestrin, C.
\newblock Near-optimal sensor placements in gaussian processes: Theory, efficient algorithms and empirical studies.
\newblock \emph{Journal of Machine Learning Research}, 9\penalty0 (8):\penalty0 235--284, 2008.
\newblock URL \url{http://jmlr.org/papers/v9/krause08a.html}.

\bibitem[Letham et~al.(2020)Letham, Calandra, Rai, and Bakshy]{letham2020re}
Letham, B., Calandra, R., Rai, A., and Bakshy, E.
\newblock {Re-examining linear embeddings for high-dimensional Bayesian optimization}.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 1546--1558, 2020.

\bibitem[Li et~al.(2017)Li, Gupta, Rana, Nguyen, Venkatesh, and Shilton]{li2017dropout}
Li, C., Gupta, S., Rana, S., Nguyen, V., Venkatesh, S., and Shilton, A.
\newblock High dimensional bayesian optimization using dropout.
\newblock In \emph{Proceedings of the 26th International Joint Conference on Artificial Intelligence}, IJCAI'17, pp.\  2096–2102. AAAI Press, 2017.
\newblock ISBN 9780999241103.

\bibitem[Malu et~al.(2021)Malu, Dasarathy, and Spanias]{maju2021hdsurvey}
Malu, M., Dasarathy, G., and Spanias, A.
\newblock Bayesian optimization in high-dimensional spaces: A brief survey.
\newblock In \emph{2021 12th International Conference on Information, Intelligence, Systems and Applications (IISA)}, pp.\  1--8, 2021.
\newblock \doi{10.1109/IISA52424.2021.9555522}.

\bibitem[Maus et~al.(2022)Maus, Jones, Moore, Kusner, Bradshaw, and Gardner]{NEURIPS2022_ded98d28}
Maus, N., Jones, H., Moore, J., Kusner, M.~J., Bradshaw, J., and Gardner, J.
\newblock Local latent space bayesian optimization over structured inputs.
\newblock In Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A. (eds.), \emph{Advances in Neural Information Processing Systems}, volume~35, pp.\  34505--34518. Curran Associates, Inc., 2022.

\bibitem[Moore et~al.(2016)Moore, Chua, Berry, and Gair]{Moore_2016}
Moore, C.~J., Chua, A. J.~K., Berry, C. P.~L., and Gair, J.~R.
\newblock Fast methods for training gaussian processes on large datasets.
\newblock \emph{Royal Society Open Science}, 3\penalty0 (5):\penalty0 160125, May 2016.
\newblock ISSN 2054-5703.
\newblock \doi{10.1098/rsos.160125}.
\newblock URL \url{http://dx.doi.org/10.1098/rsos.160125}.

\bibitem[M{\"u}ller et~al.(2021)M{\"u}ller, von Rohr, and Trimpe]{GIBO}
M{\"u}ller, S., von Rohr, A., and Trimpe, S.
\newblock Local policy search with bayesian optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Nayebi et~al.(2019)Nayebi, Munteanu, and Poloczek]{nayebi2019framework}
Nayebi, A., Munteanu, A., and Poloczek, M.
\newblock {A framework for Bayesian optimization in embedded subspaces}.
\newblock In \emph{International Conference on Machine Learning}, pp.\  4752--4761. PMLR, 2019.

\bibitem[Nemhauser et~al.(1978)Nemhauser, Wolsey, and Fisher]{nemhauser1978submod}
Nemhauser, G.~L., Wolsey, L.~A., and Fisher, M.~L.
\newblock An analysis of approximations for maximizing submodular set functions--i.
\newblock \emph{Math. Program.}, 14\penalty0 (1):\penalty0 265–294, dec 1978.
\newblock ISSN 0025-5610.
\newblock \doi{10.1007/BF01588971}.
\newblock URL \url{https://doi.org/10.1007/BF01588971}.

\bibitem[Nguyen et~al.(2022)Nguyen, Wu, Gardner, and Garnett]{NEURIPS2022_555479a2}
Nguyen, Q., Wu, K., Gardner, J., and Garnett, R.
\newblock Local bayesian optimization via maximizing probability of descent.
\newblock In Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A. (eds.), \emph{Advances in Neural Information Processing Systems}, volume~35, pp.\  13190--13202. Curran Associates, Inc., 2022.

\bibitem[Ober et~al.(2021)Ober, Rasmussen, and van~der Wilk]{pmlr-v161-ober21a}
Ober, S.~W., Rasmussen, C.~E., and van~der Wilk, M.
\newblock The promises and pitfalls of deep kernel learning.
\newblock In de~Campos, C. and Maathuis, M.~H. (eds.), \emph{Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial Intelligence}, volume 161 of \emph{Proceedings of Machine Learning Research}, pp.\  1206--1216. PMLR, 27--30 Jul 2021.
\newblock URL \url{https://proceedings.mlr.press/v161/ober21a.html}.

\bibitem[Oh et~al.(2018)Oh, Gavves, and Welling]{oh18bock}
Oh, C., Gavves, E., and Welling, M.
\newblock {BOCK} : {B}ayesian optimization with cylindrical kernels.
\newblock In Dy, J. and Krause, A. (eds.), \emph{Proceedings of the 35th International Conference on Machine Learning}, volume~80 of \emph{Proceedings of Machine Learning Research}, pp.\  3868--3877. PMLR, 10--15 Jul 2018.
\newblock URL \url{https://proceedings.mlr.press/v80/oh18a.html}.

\bibitem[Osborne(2010)]{osborne2010bayesian}
Osborne, M.~A.
\newblock \emph{Bayesian Gaussian processes for sequential prediction, optimisation and quadrature}.
\newblock PhD thesis, Oxford University, UK, 2010.

\bibitem[Papenmeier et~al.(2022)Papenmeier, Nardi, and Poloczek]{papenmeier2022increasing}
Papenmeier, L., Nardi, L., and Poloczek, M.
\newblock Increasing the scope as you learn: Adaptive bayesian optimization in nested subspaces.
\newblock In Oh, A.~H., Agarwal, A., Belgrave, D., and Cho, K. (eds.), \emph{Advances in Neural Information Processing Systems}, 2022.
\newblock URL \url{https://openreview.net/forum?id=e4Wf6112DI}.

\bibitem[Papenmeier et~al.(2023)Papenmeier, Nardi, and Poloczek]{papenmeier2023bounce}
Papenmeier, L., Nardi, L., and Poloczek, M.
\newblock {Bounce: a Reliable Bayesian Optimization Algorithm for Combinatorial and Mixed Spaces}.
\newblock \emph{arXiv preprint arXiv:2307.00618}, 2023.

\bibitem[Rana et~al.(2017)Rana, Li, Gupta, Nguyen, and Venkatesh]{rana2017elastic}
Rana, S., Li, C., Gupta, S., Nguyen, V., and Venkatesh, S.
\newblock High dimensional {B}ayesian optimization with elastic {G}aussian process.
\newblock In Precup, D. and Teh, Y.~W. (eds.), \emph{Proceedings of the 34th International Conference on Machine Learning}, volume~70 of \emph{Proceedings of Machine Learning Research}, pp.\  2883--2891. PMLR, 06--11 Aug 2017.
\newblock URL \url{https://proceedings.mlr.press/v70/rana17a.html}.

\bibitem[Rasmussen \& Williams(2006)Rasmussen and Williams]{rasmussen-book06a}
Rasmussen, C. and Williams, C.
\newblock \emph{Gaussian Processes for Machine Learning}.
\newblock The MIT Press, 2006.

\bibitem[Rolland et~al.(2018)Rolland, Scarlett, Bogunovic, and Cevher]{pmlr-v84-rolland18a}
Rolland, P., Scarlett, J., Bogunovic, I., and Cevher, V.
\newblock High-dimensional bayesian optimization via additive models with overlapping groups.
\newblock In Storkey, A. and Perez-Cruz, F. (eds.), \emph{Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics}, volume~84 of \emph{Proceedings of Machine Learning Research}, pp.\  298--307. PMLR, 09--11 Apr 2018.
\newblock URL \url{https://proceedings.mlr.press/v84/rolland18a.html}.

\bibitem[Rothfuss et~al.(2021{\natexlab{a}})Rothfuss, Fortuin, Josifoski, and Krause]{pmlr-v139-rothfuss21a}
Rothfuss, J., Fortuin, V., Josifoski, M., and Krause, A.
\newblock Pacoh: Bayes-optimal meta-learning with pac-guarantees.
\newblock In Meila, M. and Zhang, T. (eds.), \emph{Proceedings of the 38th International Conference on Machine Learning}, volume 139 of \emph{Proceedings of Machine Learning Research}, pp.\  9116--9126. PMLR, 18--24 Jul 2021{\natexlab{a}}.
\newblock URL \url{https://proceedings.mlr.press/v139/rothfuss21a.html}.

\bibitem[Rothfuss et~al.(2021{\natexlab{b}})Rothfuss, Heyn, Chen, and Krause]{rothfuss2021fpacoh}
Rothfuss, J., Heyn, D., Chen, J., and Krause, A.
\newblock Meta-learning reliable priors in the function space.
\newblock In \emph{Advances in Neural Information Processing Systems}, volume~34, 2021{\natexlab{b}}.

\bibitem[{\v{S}}ehi{\'c} et~al.(2021){\v{S}}ehi{\'c}, Gramfort, Salmon, and Nardi]{vsehic2021lassobench}
{\v{S}}ehi{\'c}, K., Gramfort, A., Salmon, J., and Nardi, L.
\newblock Lasso{B}ench: {A} {H}igh-{D}imensional {H}yperparameter {O}ptimization {B}enchmark {S}uite for {L}asso.
\newblock \emph{arXiv preprint arXiv:2111.02790}, 2021.

\bibitem[Siivola et~al.(2017)Siivola, Vehtari, Vanhatalo, Gonz{\'a}lez, and Andersen]{Siivola2017CORRECTINGBO}
Siivola, E., Vehtari, A., Vanhatalo, J.~P., Gonz{\'a}lez, J.~I., and Andersen, M.~R.
\newblock Correcting boundary over-exploration deficiencies in bayesian optimization with virtual derivative sign observations.
\newblock \emph{2018 IEEE 28th International Workshop on Machine Learning for Signal Processing (MLSP)}, pp.\  1--6, 2017.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:53236252}.

\bibitem[Snoek et~al.(2012{\natexlab{a}})Snoek, Larochelle, and Adams]{snoek-nips12a}
Snoek, J., Larochelle, H., and Adams, R.
\newblock Practical {B}ayesian optimization of machine learning algorithms.
\newblock In Bartlett, P., Pereira, F., Burges, C., Bottou, L., and Weinberger, K. (eds.), \emph{Proceedings of the 26th International Conference on Advances in Neural Information Processing Systems ({N}eur{IPS}'12)}, pp.\  2960--2968, 2012{\natexlab{a}}.

\bibitem[Snoek et~al.(2012{\natexlab{b}})Snoek, Larochelle, and Adams]{spearmint}
Snoek, J., Larochelle, H., and Adams, R.~P.
\newblock Practical bayesian optimization of machine learning algorithms.
\newblock Advances in Neural Information Processing Systems, pp.\  2951–2959, Red Hook, NY, USA, 2012{\natexlab{b}}. Curran Associates Inc.

\bibitem[Snoek et~al.(2014)Snoek, Swersky, Zemel, and Adams]{snoek-icml14a}
Snoek, J., Swersky, K., Zemel, R., and Adams, R.
\newblock Input warping for {Bayesian} optimization of non-stationary functions.
\newblock In Xing, E. and Jebara, T. (eds.), \emph{Proceedings of the 31th International Conference on Machine Learning, ({ICML}'14)}, pp.\  1674--1682. Omnipress, 2014.

\bibitem[Song et~al.(2022)Song, Xue, Huang, and Qian]{song2022monte}
Song, L., Xue, K., Huang, X., and Qian, C.
\newblock Monte carlo tree search based variable selection for high dimensional bayesian optimization.
\newblock In Oh, A.~H., Agarwal, A., Belgrave, D., and Cho, K. (eds.), \emph{Advances in Neural Information Processing Systems}, 2022.
\newblock URL \url{https://openreview.net/forum?id=SUzPos_pUC}.

\bibitem[Srinivas et~al.(2010)Srinivas, Krause, Kakade, and Seeger]{srninivas-icml10a}
Srinivas, N., Krause, A., Kakade, S., and Seeger, M.
\newblock {G}aussian process optimization in the bandit setting: No regret and experimental design.
\newblock In F{\"u}rnkranz, J. and Joachims, T. (eds.), \emph{Proceedings of the 27th International Conference on Machine Learning ({ICML}'10)}, pp.\  1015--1022. Omnipress, 2010.

\bibitem[Srinivas et~al.(2012)Srinivas, Krause, Kakade, and Seeger]{Srinivas_2012}
Srinivas, N., Krause, A., Kakade, S.~M., and Seeger, M.~W.
\newblock Information-theoretic regret bounds for gaussian process optimization in the bandit setting.
\newblock \emph{IEEE Transactions on Information Theory}, 58\penalty0 (5):\penalty0 3250–3265, May 2012.
\newblock ISSN 1557-9654.
\newblock \doi{10.1109/tit.2011.2182033}.
\newblock URL \url{http://dx.doi.org/10.1109/TIT.2011.2182033}.

\bibitem[Swersky et~al.(2014)Swersky, Duvenaud, Snoek, Hutter, and Osborne]{swersky2014raiders}
Swersky, K., Duvenaud, D., Snoek, J., Hutter, F., and Osborne, M.~A.
\newblock Raiders of the lost architecture: Kernels for bayesian optimization in conditional parameter spaces, 2014.

\bibitem[Swersky(2017)]{swersky2017improving}
Swersky, K.~J.
\newblock \emph{Improving Bayesian Optimization for Machine Learning using Expert Priors}.
\newblock PhD thesis, 2017.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{todorov2012mujoco}
Todorov, E., Erez, T., and Tassa, Y.
\newblock Mujoco: A physics engine for model-based control.
\newblock In \emph{2012 IEEE/RSJ International Conference on Intelligent Robots and Systems}, pp.\  5026--5033. IEEE, 2012.
\newblock \doi{10.1109/IROS.2012.6386109}.

\bibitem[Wan et~al.(2021)Wan, Nguyen, Ha, Ru, Lu, and Osborne]{pmlr-v139-wan21b}
Wan, X., Nguyen, V., Ha, H., Ru, B., Lu, C., and Osborne, M.~A.
\newblock Think global and act local: Bayesian optimisation over high-dimensional categorical and mixed search spaces.
\newblock In Meila, M. and Zhang, T. (eds.), \emph{Proceedings of the 38th International Conference on Machine Learning}, volume 139 of \emph{Proceedings of Machine Learning Research}, pp.\  10663--10674. PMLR, 18--24 Jul 2021.
\newblock URL \url{https://proceedings.mlr.press/v139/wan21b.html}.

\bibitem[Wang et~al.(2020)Wang, Fonseca, and Tian]{NEURIPS2020_e2ce14e8}
Wang, L., Fonseca, R., and Tian, Y.
\newblock Learning search space partition for black-box optimization using monte carlo tree search.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H. (eds.), \emph{Advances in Neural Information Processing Systems}, volume~33, pp.\  19511--19522. Curran Associates, Inc., 2020.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2020/file/e2ce14e81dba66dbff9cbc35ecfdb704-Paper.pdf}.

\bibitem[Wang et~al.(2016)Wang, Hutter, Zoghi, Matheson, and De~Feitas]{wang2016bayesian}
Wang, Z., Hutter, F., Zoghi, M., Matheson, D., and De~Feitas, N.
\newblock Bayesian optimization in a billion dimensions via random embeddings.
\newblock \emph{Journal of Artificial Intelligence Research}, 55:\penalty0 361--387, 2016.

\bibitem[Wang et~al.(2017)Wang, Li, Jegelka, and Kohli]{pmlr-v70-wang17h}
Wang, Z., Li, C., Jegelka, S., and Kohli, P.
\newblock Batched high-dimensional {B}ayesian optimization via structural kernel learning.
\newblock In Precup, D. and Teh, Y.~W. (eds.), \emph{Proceedings of the 34th International Conference on Machine Learning}, volume~70 of \emph{Proceedings of Machine Learning Research}, pp.\  3656--3664. PMLR, 06--11 Aug 2017.
\newblock URL \url{https://proceedings.mlr.press/v70/wang17h.html}.

\bibitem[Williams \& Rasmussen(1995)Williams and Rasmussen]{NIPS1995_7cce53cf}
Williams, C. and Rasmussen, C.
\newblock Gaussian processes for regression.
\newblock In Touretzky, D., Mozer, M., and Hasselmo, M. (eds.), \emph{Advances in Neural Information Processing Systems}, volume~8. MIT Press, 1995.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/1995/file/7cce53cf90577442771720a370c3c723-Paper.pdf}.

\bibitem[Wu et~al.(2023)Wu, Kim, Garnett, and Gardner]{wu2023the}
Wu, K., Kim, K., Garnett, R., and Gardner, J.~R.
\newblock The behavior and convergence of local bayesian optimization.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.
\newblock URL \url{https://openreview.net/forum?id=9KtX12YmA7}.

\bibitem[Yao et~al.(2020)Yao, Vehtari, and Gelman]{yao2020stacking}
Yao, Y., Vehtari, A., and Gelman, A.
\newblock Stacking for non-mixing bayesian computations: The curse and blessing of multimodal posteriors, 2020.

\bibitem[Ziomek \& Bou~Ammar(2023)Ziomek and Bou~Ammar]{pmlr-v202-ziomek23a}
Ziomek, J.~K. and Bou~Ammar, H.
\newblock Are random decompositions all we need in high dimensional {B}ayesian optimisation?
\newblock In Krause, A., Brunskill, E., Cho, K., Engelhardt, B., Sabato, S., and Scarlett, J. (eds.), \emph{Proceedings of the 40th International Conference on Machine Learning}, volume 202 of \emph{Proceedings of Machine Learning Research}, pp.\  43347--43368. PMLR, 23--29 Jul 2023.
\newblock URL \url{https://proceedings.mlr.press/v202/ziomek23a.html}.

\end{thebibliography}
