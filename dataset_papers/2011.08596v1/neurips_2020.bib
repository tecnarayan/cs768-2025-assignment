@article{AJCC,
author = {Kattan, Michael W. and Hess, Kenneth R. and Amin, Mahul B. and Lu, Ying and Moons, Karl G.M. and Gershenwald, Jeffrey E. and Gimotty, Phyllis A. and Guinney, Justin H. and Halabi, Susan and Lazar, Alexander J. and Mahar, Alyson L. and Patel, Tushar and Sargent, Daniel J. and Weiser, Martin R. and Compton, Carolyn and members of the AJCC Precision Medicine Core},
title = {American Joint Committee on Cancer acceptance criteria for inclusion of risk models for individualized prognosis in the practice of precision medicine},
journal = {CA: A Cancer Journal for Clinicians},

volume = {66},
number = {5},
pages = {370-374},
keywords = {decision making, evidence-based medicine, patient preferences, personalized medicine},
doi = {10.3322/caac.21339},
url = {https://acsjournals.onlinelibrary.wiley.com/doi/abs/10.3322/caac.21339},
eprint = {https://acsjournals.onlinelibrary.wiley.com/doi/pdf/10.3322/caac.21339},
abstract = {The American Joint Committee on Cancer (AJCC) has increasingly recognized the need for more personalized probabilistic predictions than those delivered by ordinal staging systems, particularly through the use of accurate risk models or calculators. However, judging the quality and acceptability of a risk model is complex. The AJCC Precision Medicine Core conducted a 2-day meeting to discuss characteristics necessary for a quality risk model in cancer patients. More specifically, the committee established inclusion and exclusion criteria necessary for a risk model to potentially be endorsed by the AJCC. This committee reviewed and discussed relevant literature before creating a checklist unique to this need of AJCC risk model endorsement. The committee identified 13 inclusion and 3 exclusion criteria for AJCC risk model endorsement in cancer. The emphasis centered on performance metrics, implementation clarity, and clinical relevance. The facilitation of personalized probabilistic predictions for cancer patients holds tremendous promise, and these criteria will hopefully greatly accelerate this process. Moreover, these criteria might be useful for a general audience when trying to judge the potential applicability of a published risk model in any clinical domain. CA Cancer J Clin 2016;66:370–374. © 2016 American Cancer Society.},
year = {2016}
}

@misc{lundberg2017unified,
    title={A Unified Approach to Interpreting Model Predictions},
    author={Scott Lundberg and Su-In Lee},
    year={2017},
    eprint={1705.07874},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}

@inproceedings{Yoon2019INVASEIV,
  title={INVASE: Instance-wise Variable Selection using Neural Networks},
  author={Jinsung Yoon and James Jordon and Mihaela van der Schaar},
  booktitle={ICLR},
  year={2019}
}

@misc{koh2017understanding,
    title={Understanding Black-box Predictions via Influence Functions},
    author={Pang Wei Koh and Percy Liang},
    year={2017},
    eprint={1703.04730},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@misc{chen2018learning,
    title={Learning to Explain: An Information-Theoretic Perspective on Model Interpretation},
    author={Jianbo Chen and Le Song and Martin J. Wainwright and Michael I. Jordan},
    year={2018},
    eprint={1802.07814},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{zhang2018interpreting,
    title={Interpreting Neural Network Judgments via Minimal, Stable, and Symbolic Corrections},
    author={Xin Zhang and Armando Solar-Lezama and Rishabh Singh},
    year={2018},
    eprint={1802.07384},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}





@misc{lipton2016mythos,
    title={The Mythos of Model Interpretability},
    author={Zachary C. Lipton},
    year={2016},
    eprint={1606.03490},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{10.1145/3205455.3205539,
author = {Orzechowski, Patryk and La Cava, William and Moore, Jason H.},
title = {Where Are We Now? A Large Benchmark Study of Recent Symbolic Regression Methods},
year = {2018},
isbn = {9781450356183},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3205455.3205539},
doi = {10.1145/3205455.3205539},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1183–1190},
numpages = {8},
keywords = {symbolic regression, genetic programming, machine learning, benchmarking},
location = {Kyoto, Japan},
series = {GECCO ’18}
}

@misc{ribeiro2016i,
    title={"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
    author={Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin},
    year={2016},
    eprint={1602.04938},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{ahuja2018optimal,
    title={Optimal Piecewise Local-Linear Approximations},
    author={Kartik Ahuja and William Zame and Mihaela van der Schaar},
    year={2018},
    eprint={1806.10270},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{
jordon2018knockoffgan,
title={Knockoff{GAN}: Generating Knockoffs for Feature Selection using Generative Adversarial Networks},
author={James Jordon and Jinsung Yoon and Mihaela van der Schaar},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=ByeZ5jC5YQ},
}

@inproceedings{SM2019,
	author = {Ahmed M. Alaa, Mihaela van der Schaar},
	title = {Demystifying Black-box Models with Symbolic Metamodels},
	booktitle = {Neural Information Processing Systems},
	year = {2019}
}


@Article{zbMATH03147701,
 Author = {A. N. {Kolmogorov}},
 Title = {{On the representation of continuous functions of many variables by superposition of continuous functions of one variable and addition.}},
 FJournal = {{Doklady Akademii Nauk SSSR}},
 Journal = {{Dokl. Akad. Nauk SSSR}},
 ISSN = {0002-3264},
 Volume = {114},
 Pages = {953--956},
 Year = {1957},
 Publisher = {Academy of Sciences of the Union of Soviet Socialist Republics - USSR (Akademiya Nauk SSSR)},
 Language = {Russian},
 MSC2010 = {26B40},
 Zbl = {0090.27103}
}

@article{10.2307/1994273,
 ISSN = {00029947},
 URL = {http://www.jstor.org/stable/1994273},
 author = {David A. Sprecher},
 journal = {Transactions of the American Mathematical Society},
 pages = {340--355},
 publisher = {American Mathematical Society},
 title = {On the Structure of Continuous Functions of Several Variables},
 volume = {115},
 year = {1965}
}

@dataset{meijer,
author = {Beals, Richard and Szmigielski, Jacek},
year = {2013},
month = {08},
pages = {},
title = {Meijer G–Functions: A Gentle Introduction},
volume = {60},
journal = {Notices of the American Mathematical Society},
doi = {10.1090/notimanid1016}
}

@inproceedings{10.1145/258726.258784,
author = {Roach, Kelly},
title = {Meijer G Function Representations},
year = {1997},
isbn = {0897918754},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/258726.258784},
doi = {10.1145/258726.258784},
booktitle = {Proceedings of the 1997 International Symposium on Symbolic and Algebraic Computation},
pages = {205–211},
numpages = {7},
location = {Kihei, Maui, Hawaii, USA},
series = {ISSAC ’97}
}

@book{luke1969special,
  title={The Special Functions and Their Approximations},
  author={Luke, Y.L.},
  isbn={9780080955605},
  series={ISSN},
  url={https://books.google.co.uk/books?id=huuO6mKbVoEC},
  year={1969},
  publisher={Elsevier Science}
}



@book{andrews1999special,
  title={Special functions},
  author={Andrews, George E and Askey, Richard and Roy, Ranjan},
  volume={71},
  year={1999},
  publisher={Cambridge university press}
}







@book{hastie2009elements,
  title={The elements of statistical learning: data mining, inference, and prediction},
  author={Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year={2009},
  publisher={Springer Science \& Business Media}
}

@book{hastie2015statistical,
  title={Statistical learning with sparsity: the lasso and generalizations},
  author={Hastie, Trevor and Tibshirani, Robert and Wainwright, Martin},
  year={2015},
  publisher={CRC press}
}


@ARTICLE{2020SciPy-NMeth,
       author = {{Virtanen}, Pauli and {Gommers}, Ralf and {Oliphant},
         Travis E. and {Haberland}, Matt and {Reddy}, Tyler and
         {Cournapeau}, David and {Burovski}, Evgeni and {Peterson}, Pearu
         and {Weckesser}, Warren and {Bright}, Jonathan and {van der Walt},
         St{\'e}fan J.  and {Brett}, Matthew and {Wilson}, Joshua and
         {Jarrod Millman}, K.  and {Mayorov}, Nikolay and {Nelson}, Andrew
         R.~J. and {Jones}, Eric and {Kern}, Robert and {Larson}, Eric and
         {Carey}, CJ and {Polat}, {\.I}lhan and {Feng}, Yu and {Moore},
         Eric W. and {Vand erPlas}, Jake and {Laxalde}, Denis and
         {Perktold}, Josef and {Cimrman}, Robert and {Henriksen}, Ian and
         {Quintero}, E.~A. and {Harris}, Charles R and {Archibald}, Anne M.
         and {Ribeiro}, Ant{\^o}nio H. and {Pedregosa}, Fabian and
         {van Mulbregt}, Paul and {Contributors}, SciPy 1. 0},
        title = "{SciPy 1.0: Fundamental Algorithms for Scientific
                  Computing in Python}",
      journal = {Nature Methods},
      year = "2020",
      volume={17},
      pages={261--272},
      adsurl = {https://rdcu.be/b08Wh},
      doi = {https://doi.org/10.1038/s41592-019-0686-2},
}

@article{KURKOVA1992501,
title = "Kolmogorov's theorem and multilayer neural networks",
journal = "Neural Networks",
volume = "5",
number = "3",
pages = "501 - 506",
year = "1992",
issn = "0893-6080",
doi = "https://doi.org/10.1016/0893-6080(92)90012-8",
url = "http://www.sciencedirect.com/science/article/pii/0893608092900128",
author = "Věra Kůrková",
keywords = "Feedforward neural networks, Multilayer perceptron type networks, Sigmoidal activation function, Approximations of continuous functions, Uniform approximation, Universal approximation capabilities, Estimates of number of hidden units, Modulus of continuity",
abstract = "Taking advantage of techniques developed by Kolmogorov, we give a direct proof of the universal approximation capabilities of perceptron type networks with two hidden layers. From our proof, we derive estimates of numbers of hidden units based on properties of the function being approximated and the accuracy of its approximation."
}

@article{HORNIK1989359,
title = "Multilayer feedforward networks are universal approximators",
journal = "Neural Networks",
volume = "2",
number = "5",
pages = "359 - 366",
year = "1989",
issn = "0893-6080",
doi = "https://doi.org/10.1016/0893-6080(89)90020-8",
url = "http://www.sciencedirect.com/science/article/pii/0893608089900208",
author = "Kurt Hornik and Maxwell Stinchcombe and Halbert White",
keywords = "Feedforward networks, Universal approximation, Mapping networks, Network representation capability, Stone-Weierstrass Theorem, Squashing functions, Sigma-Pi networks, Back-propagation networks",
abstract = "This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators."
}

@article{symbore,
author = {Menezes, Telmo and Roth, Camille},
year = {2014},
month = {09},
pages = {},
title = {Symbolic regression of generative network models},
volume = {4},
journal = {Scientific Reports},
doi = {10.1038/srep06284}
}



@manual{mpmath,
  key     = {mpmath},
  author  = {Fredrik Johansson and others},
  title   = {mpmath: a {P}ython library for arbitrary-precision floating-point arithmetic (version 0.18)},
  note    = {{\tt http://mpmath.org/}},
  month   = {December},
  year    = {2013},
}

@article{10.1137/0905013,
author = {Diaconis, Persi and Shahshahani, Mehrdad},
title = {On Nonlinear Functions of Linear Combinations},
year = {1984},
issue_date = {March 1984},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {5},
number = {1},
issn = {0196-5204},
url = {https://doi.org/10.1137/0905013},
doi = {10.1137/0905013},
journal = {SIAM J. Sci. Stat. Comput.},
month = mar,
pages = {175–191},
numpages = {17},
keywords = {nonlinear high-dimensional nonparametric regression, polynomials, Schwartz distributions, approximation theory}
}



@article{huber1985projection,
  title={Projection pursuit},
  author={Huber, Peter J},
  journal={The annals of Statistics},
  pages={435--475},
  year={1985},
  publisher={JSTOR}
}

@article{friedmann1981,
 ISSN = {01621459},
 URL = {http://www.jstor.org/stable/2287576},
 abstract = {A new method for nonparametric multiple regression is presented. The procedure models the regression surface as a sum of general smooth functions of linear combinations of the predictor variables in an iterative manner. It is more general than standard stepwise and stagewise regression procedures, does not require the definition of a metric in the predictor space, and lends itself to graphical interpretation.},
 author = {Jerome H. Friedman and Werner Stuetzle},
 journal = {Journal of the American Statistical Association},
 number = {376},
 pages = {817--823},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {Projection Pursuit Regression},
 volume = {76},
 year = {1981}
}

@article{jones1987,
author = "Jones, Lee K.",
doi = "10.1214/aos/1176350382",
fjournal = "The Annals of Statistics",
journal = "Ann. Statist.",
month = "06",
number = "2",
pages = "880--882",
publisher = "The Institute of Mathematical Statistics",
title = "On a Conjecture of Huber Concerning the Convergence of Projection Pursuit Regression",
url = "https://doi.org/10.1214/aos/1176350382",
volume = "15",
year = "1987"
}

@article{roosen1993logistic,
  title={Logistic response projection pursuit},
  author={Roosen, Charles B. and Hastie, Trevor J.},
  journal={AT\&T Bell Laboratories, Doc. BL011214-930806-09TM, Murray Hill, NJ},
  year={1993}
}

@InProceedings{morton1992,
author="Morton, Sally C.",
editor="Page, Connie
and LePage, Raoul",
title="Interpretable Exploratory Projection Pursuit",
booktitle="Computing Science and Statistics",
year="1992",
publisher="Springer New York",
address="New York, NY",
pages="470--474",
abstract="I propose a modification of exploratory projection pursuit which trades accuracy for interpretability in the resulting description. Interpretability, a generalization of parsimony, is based on the ideas of rotation in factor analysis and of entropy. It is defined as the simplicity of the coefficients which specify the description's projections. A weighted optimization approach similar to roughness penalty curve-fitting is used to search for a more understandable description, with interpretability replacing smoothness. A real data example is presented. The method retains the nonlinear versatility of projection pursuit but has more intuitive appeal.",
isbn="978-1-4612-2856-1"
}

@article{langley1989data,
  title={Data-driven approaches to empirical discovery},
  author={Langley, Pat and Zytkow, Jan M},
  journal={Artificial Intelligence},
  volume={40},
  number={1-3},
  pages={283--312},
  year={1989},
  publisher={Elsevier}
}

@article{hastie1986,
author = "Hastie, Trevor and Tibshirani, Robert",
doi = "10.1214/ss/1177013604",
fjournal = "Statistical Science",
journal = "Statist. Sci.",
month = "08",
number = "3",
pages = "297--310",
publisher = "The Institute of Mathematical Statistics",
title = "Generalized Additive Models",
url = "https://doi.org/10.1214/ss/1177013604",
volume = "1",
year = "1986"
}

@misc{shrikumar2017learning,
    title={Learning Important Features Through Propagating Activation Differences},
    author={Avanti Shrikumar and Peyton Greenside and Anshul Kundaje},
    year={2017},
    eprint={1704.02685},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@incollection{tsang2018,
title = {Neural Interaction Transparency (NIT): Disentangling Learned Interactions for Improved Interpretability},
author = {Tsang, Michael and Liu, Hanpeng and Purushotham, Sanjay and Murali, Pavankumar and Liu, Yan},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {5804--5813},
year = {2018},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7822-neural-interaction-transparency-nit-disentangling-learned-interactions-for-improved-interpretability.pdf}
}

@inproceedings{lou2013,
author = {Lou, Yin and Caruana, Rich and Gehrke, Johannes and Hooker, Giles},
title = {Accurate Intelligible Models with Pairwise Interactions},
year = {2013},
isbn = {9781450321747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2487575.2487579},
doi = {10.1145/2487575.2487579},
booktitle = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {623–631},
numpages = {9},
keywords = {classification, regression, interaction detection},
location = {Chicago, Illinois, USA},
series = {KDD ’13}
}

@inproceedings{Chen:2016:XST:2939672.2939785,
 author = {Chen, Tianqi and Guestrin, Carlos},
 title = {{XGBoost}: A Scalable Tree Boosting System},
 booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '16},
 year = {2016},
 isbn = {978-1-4503-4232-2},
 location = {San Francisco, California, USA},
 pages = {785--794},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2939672.2939785},
 doi = {10.1145/2939672.2939785},
 acmid = {2939785},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {large-scale machine learning},
}

@article{CORTEZ2009547,
title = "Modeling wine preferences by data mining from physicochemical properties",
journal = "Decision Support Systems",
volume = "47",
number = "4",
pages = "547 - 553",
year = "2009",
note = "Smart Business Networks: Concepts and Empirical Evidence",
issn = "0167-9236",
doi = "https://doi.org/10.1016/j.dss.2009.05.016",
url = "http://www.sciencedirect.com/science/article/pii/S0167923609001377",
author = "Paulo Cortez and António Cerdeira and Fernando Almeida and Telmo Matos and José Reis",
keywords = "Sensory preferences, Regression, Variable selection, Model selection, Support vector machines, Neural networks",
}

@article{hastie2007forward,
  title={Forward stagewise regression and the monotone lasso},
  author={Hastie, Trevor and Taylor, Jonathan and Tibshirani, Robert and Walther, Guenther and others},
  journal={Electronic Journal of Statistics},
  volume={1},
  pages={1--29},
  year={2007},
  publisher={The Institute of Mathematical Statistics and the Bernoulli Society}
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@article{glockle1993fox,
  title={Fox function representation of non-Debye relaxation processes},
  author={Gl{\"o}ckle, Walter G and Nonnenmacher, Theo F},
  journal={Journal of Statistical Physics},
  volume={71},
  number={3-4},
  pages={741--757},
  year={1993},
  publisher={Springer}
}

@misc{zhang2017mixup,
    title={mixup: Beyond Empirical Risk Minimization},
    author={Hongyi Zhang and Moustapha Cisse and Yann N. Dauphin and David Lopez-Paz},
    year={2017},
    eprint={1710.09412},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{Cheng1998,
author = {Yeh, I-Cheng},
year = {1998},
month = {12},
pages = {1797-1808},
title = {Modeling of Strength of High-Performance Concrete Using Artificial Neural Networks.” Cement and Concrete research, 28(12), 1797-1808},
volume = {28},
journal = {Cement and Concrete Research},
doi = {10.1016/S0008-8846(98)00165-3}
}


@article{cox1972,
 ISSN = {00359246},
 URL = {http://www.jstor.org/stable/2985181},
 abstract = {The analysis of censored failure times is considered. It is assumed that on each individual are available values of one or more explanatory variables. The hazard function (age-specific failure rate) is taken to be a function of the explanatory variables and unknown regression coefficients multiplied by an arbitrary and unknown function of time. A conditional likelihood is obtained, leading to inferences about the unknown regression coefficients. Some generalizations are outlined.},
 author = {D. R. Cox},
 journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
 number = {2},
 pages = {187--220},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Regression Models and Life-Tables},
 volume = {34},
 year = {1972}
}
@misc{Dua2019 ,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

@book{bateman1953higher,
  title={Higher Transcendental Functions [Volumes I-III]},
  author={Bateman, Harry},
  volume={1},
  year={1953},
  publisher={McGraw-Hill Book Company}
}



@inproceedings{sklearn_api,
  author    = {Lars Buitinck and Gilles Louppe and Mathieu Blondel and
               Fabian Pedregosa and Andreas Mueller and Olivier Grisel and
               Vlad Niculae and Peter Prettenhofer and Alexandre Gramfort
               and Jaques Grobler and Robert Layton and Jake VanderPlas and
               Arnaud Joly and Brian Holt and Ga{\"{e}}l Varoquaux},
  title     = {{API} design for machine learning software: experiences from the scikit-learn
               project},
  booktitle = {ECML PKDD Workshop: Languages for Data Mining and Machine Learning},
  year      = {2013},
  pages = {108--122},
}