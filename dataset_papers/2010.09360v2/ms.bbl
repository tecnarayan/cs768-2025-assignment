\begin{thebibliography}{36}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Achille \& Soatto(2016)Achille and Soatto]{Achille2016}
Achille, A. and Soatto, S.
\newblock Information dropout: learning optimal representations through noise.
\newblock \emph{IEEE Trans. Pattern Anal. Mach. Intell.}, 2016.

\bibitem[Bengio et~al.(2013)Bengio, Courville, and Vincent]{Bengio2013}
Bengio, Y., Courville, A., and Vincent, P.
\newblock Representation learning: A review and new perspectives.
\newblock \emph{IEEE Trans. Pattern Anal. Mach. Intell.}, 2013.

\bibitem[Bishop(2006)]{Bishop2006}
Bishop, C.~M.
\newblock \emph{Pattern Recognition and Machine Learning (Information Science
  and Statistics)}.
\newblock Springer-Verlag, 2006.

\bibitem[Bouchacourt et~al.(2018)Bouchacourt, Tomioka, and
  Nowozin]{Bouchacourt2018_MLVAE}
Bouchacourt, D., Tomioka, R., and Nowozin, S.
\newblock Multi-level variational autoencoder: Learning disentangled
  representations from grouped observations.
\newblock In \emph{Proc. of the 32nd AAAI Conf. on Artif. Intel.}, AAAI, 2018.

\bibitem[Burgess et~al.(2017)Burgess, Higgins, Pal, Matthey, Watters,
  Desjardins, and Lerchner]{Burgess2017_AnnealedVAE}
Burgess, C.~P., Higgins, I., Pal, A., Matthey, L., Watters, N., Desjardins, G.,
  and Lerchner, A.
\newblock Understanding disentangling in {\(\beta\)}-vae.
\newblock In \emph{Proc. of the 30th Int. Conf. on Neural Inf. Proc. Sys.},
  NeurIPS, 2017.

\bibitem[Chen \& Batmanghelich(2020{\natexlab{a}})Chen and
  Batmanghelich]{Chen2020}
Chen, J. and Batmanghelich, K.
\newblock Weakly supervised disentanglement by pairwise similarities.
\newblock In \emph{Proc. of the 34th AAAI Conf. on Artif. Intel.}, AAAI,
  2020{\natexlab{a}}.

\bibitem[Chen \& Batmanghelich(2020{\natexlab{b}})Chen and
  Batmanghelich]{Chen2020_ROVAE}
Chen, J. and Batmanghelich, K.
\newblock Robust ordinal vae: Employing noisy pairwise comparisons for
  disentanglement.
\newblock \emph{ArXiv}, 2020{\natexlab{b}}.

\bibitem[Chen et~al.(2018)Chen, Li, Grosse, and Duvenaud]{Chen2018_betaTCVAE}
Chen, T.~Q., Li, X., Grosse, R.~B., and Duvenaud, D.~K.
\newblock Isolating sources of disentanglement in variational autoencoders.
\newblock In \emph{Proc. of the 31st Int. Conf. on Neural Inf. Proc. Sys.},
  NeurIPS, 2018.

\bibitem[Cheung et~al.(2015)Cheung, Livezey, Bansal, and Olshausen]{Cheung2015}
Cheung, B., Livezey, J.~A., Bansal, A.~K., and Olshausen, B.~A.
\newblock Discovering hidden factors of variation in deep networks.
\newblock In \emph{CoRR}, 2015.

\bibitem[Comon(1994)]{Comon1994ICA}
Comon, P.
\newblock Independent component analysis, a new concept?
\newblock \emph{Signal Process.}, 36:\penalty0 287–314, 1994.

\bibitem[Higgins et~al.(2017)Higgins, Matthey, Pal, Burgess, Glorot, Botvinick,
  Mohamed, and Lerchner]{Higgins2017_betaVAE}
Higgins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X., Botvinick, M.~M.,
  Mohamed, S., and Lerchner, A.
\newblock beta-vae: Learning basic visual concepts with a constrained
  variational framework.
\newblock In \emph{Proc. of the 5th Int. Conf. on Learn. Repr.}, ICLR, 2017.

\bibitem[Hoffman \& Johnson(2016)Hoffman and Johnson]{Hoffman2016_ELBO}
Hoffman, M.~D. and Johnson, M.~J.
\newblock Elbo surgery: yet another way to carve up the variational evidence
  lower bound.
\newblock In \emph{Workshop in Adv. in Approx. Bayes. Infer.}, NeurIPS, 2016.

\bibitem[Hosoya(2019)]{Hosoya2019_GVAE}
Hosoya, H.
\newblock Group-based learning of disentangled representations with
  generalizability for novel contents.
\newblock In \emph{Proc. of the 28th Int. Joint Conf. on Artif. Intel.}, IJCAI,
  2019.

\bibitem[Hyv{\"a}rinen \& Pajunen(1999)Hyv{\"a}rinen and
  Pajunen]{Hyvarinen1999NonlinearICA}
Hyv{\"a}rinen, A. and Pajunen, P.
\newblock Nonlinear independent component analysis: Existence and uniqueness
  results.
\newblock \emph{Neural networks}, 12:\penalty0 429--439, 1999.

\bibitem[Khemakhem et~al.(2020)Khemakhem, Kingma., Mont, and
  Hyv{\"a}rinen]{Hyvarinen2020_IVAE}
Khemakhem, I., Kingma., D.~P., Mont, R.~P., and Hyv{\"a}rinen, A.
\newblock Variational autoencoders and nonlinear ica: A unifying framework.
\newblock In \emph{Proc. of the 23rd Int. Conf. on Artif. Intel. and Stat.},
  AISTATS, 2020.

\bibitem[Kim \& Mnih(2018)Kim and Mnih]{Kim2018_FactorVAE}
Kim, H. and Mnih, A.
\newblock Disentangling by factorising.
\newblock In \emph{Proc. of the 35th Int. Conf. on Mach. Learn.}, ICML, 2018.

\bibitem[Kingma \& Welling(2014)Kingma and Welling]{Kingma2013VAE}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational bayes.
\newblock In \emph{Proc. of the 2nd Int. Conf. on Learn. Repr.}, ICLR, 2014.

\bibitem[Kingma et~al.(2014)Kingma, Mohamed, Rezende, and
  Welling]{Kingma2014SSVAE}
Kingma, D.~P., Mohamed, S., Rezende, D.~J., and Welling, M.
\newblock Semi-supervised learning with deep generative models.
\newblock In \emph{Proc. of the 27th Int. Conf. on Neural Inf. Proc. Sys.},
  NeurIPS, 2014.

\bibitem[Klys et~al.(2018)Klys, Snell, and Zemel]{Klys2018}
Klys, J., Snell, J., and Zemel, R.
\newblock Learning latent subspaces in variational autoencoders.
\newblock In \emph{Proc. of the 31st Int. Conf. on Neural Inf. Proc. Sys.},
  NeurIPS, 2018.

\bibitem[Kumar \& Poole(2020)Kumar and Poole]{Kumar2020}
Kumar, A. and Poole, B.
\newblock On implicit regularization in $\beta$-{VAE}s.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, ICML, 2020.

\bibitem[Kumar et~al.(2018)Kumar, Sattigeri, and
  Balakrishnan]{Kumar2018_DIPVAE}
Kumar, A., Sattigeri, P., and Balakrishnan, A.
\newblock Variational inference of disentangled latent concepts from unlabeled
  observations.
\newblock In \emph{Proc. of the 6th Int. Conf. on Learn. Repr.}, ICLR, 2018.

\bibitem[LeCun et~al.(2004)LeCun, Huang, and Bottou]{LeCun2004_smallnorb}
LeCun, Y., Huang, F.~J., and Bottou, L.
\newblock Learning methods for generic object recognition with invariance to
  pose and lighting.
\newblock In \emph{Proc. of the 2004 IEEE Comput. Society Conf. on Comput.
  Vision and Pat. Recogn.}, CVPR, 2004.

\bibitem[Locatello et~al.(2019)Locatello, Bauer, Lucic, Gelly, Sch{\"{o}}lkopf,
  and Bachem]{Locatello2019}
Locatello, F., Bauer, S., Lucic, M., Gelly, S., Sch{\"{o}}lkopf, B., and
  Bachem, O.
\newblock Challenging common assumptions in the unsupervised learning of
  disentangled representations.
\newblock In \emph{Proc. of the 36th Int. Conf. on Mach. Learn.}, ICML, 2019.

\bibitem[Locatello et~al.(2020{\natexlab{a}})Locatello, Poole, R{\"{a}}tsch,
  Sch{\"{o}}lkopf, Bachem, and Tschannen]{Locatello2020}
Locatello, F., Poole, B., R{\"{a}}tsch, G., Sch{\"{o}}lkopf, B., Bachem, O.,
  and Tschannen, M.
\newblock Weakly-supervised disentanglement without compromises.
\newblock In \emph{Proc. of the 37th Int. Conf. on Mach. Learn.}, ICML,
  2020{\natexlab{a}}.

\bibitem[Locatello et~al.(2020{\natexlab{b}})Locatello, Tschannen, Bauer,
  R{\"{a}}tsch, Sch{\"{o}}lkopf, and Bachem]{Locatello2019_SSVAE}
Locatello, F., Tschannen, M., Bauer, S., R{\"{a}}tsch, G., Sch{\"{o}}lkopf, B.,
  and Bachem, O.
\newblock Disentangling factors of variation using few labels.
\newblock In \emph{Proc. of the 8th Int. Conf. on Learn. Repr.}, ICLR,
  2020{\natexlab{b}}.

\bibitem[Makhzani \& Frey(2017)Makhzani and Frey]{Makhzani2017}
Makhzani, A. and Frey, B.~J.
\newblock Pixelgan autoencoders.
\newblock In \emph{Proc. of the 30th Int. Conf. on Neural Inf. Proc. Sys.},
  NeurIPS, 2017.

\bibitem[Mathieu et~al.(2019)Mathieu, Rainforth, Siddharth, and
  Teh]{Mathieu2019}
Mathieu, E., Rainforth, T., Siddharth, N., and Teh, Y.~W.
\newblock Disentangling disentanglement in variational autoencoders.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning}, ICML, 2019.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{pytorch}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Kopf, A., Yang, E.,
  DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L.,
  Bai, J., and Chintala, S.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In \emph{Proc. of the 32nd Int. Conf. on Neural Inf. Proc. Sys.},
  NeurIPS. 2019.

\bibitem[Reed et~al.(2015)Reed, Zhang, Zhang, and Lee]{Scott2015_cars}
Reed, S.~E., Zhang, Y., Zhang, Y., and Lee, H.
\newblock Deep visual analogy-making.
\newblock In \emph{Proc. of the 28th Int. Conf. on Neural Inf. Proc. Sys.},
  NeurIPS. Curran Associates, Inc., 2015.

\bibitem[Rezende et~al.(2014)Rezende, Mohamed, and Wiestra]{Rezende2014VAE}
Rezende, D.~J., Mohamed, S., and Wiestra, D.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock In \emph{Proc. of the 31st Int. Conf. on Mach. Learn.}, ICML, 2014.

\bibitem[Ridgeway \& Mozer(2018)Ridgeway and Mozer]{Ridgeway2018}
Ridgeway, K. and Mozer, M.~C.
\newblock Learning deep disentangled embeddings with the f-statistic loss.
\newblock In \emph{Proc. of the 31st Int. Conf. on Neural Inf. Proc. Sys.},
  NeurIPS, 2018.

\bibitem[Shu et~al.(2020)Shu, Chen, Kumar, Ermon, and Poole]{Shu2020}
Shu, R., Chen, Y., Kumar, A., Ermon, S., and Poole, B.
\newblock Weakly supervised disentanglement with guarantees.
\newblock In \emph{Proc. of the 8th Int. Conf. on Learn. Repr.}, ICLR, 2020.

\bibitem[Siddharth et~al.(2017)Siddharth, Paige, van~de Meent, Desmaison,
  Goodman, Kohli, Wood, and Torr]{Siddarth2017SSVAE}
Siddharth, N., Paige, B., van~de Meent, J., Desmaison, A., Goodman, N., Kohli,
  P., Wood, F., and Torr, P.
\newblock Learning disentangled representations with semi-supervised deep
  generative models.
\newblock In \emph{Proc. of the 30th Int. Conf. on Neural Inf. Proc. Sys.},
  NeurIPS, 2017.

\bibitem[Tishby et~al.(1999)Tishby, Pereira, and Bialek]{Tishby1999}
Tishby, N., Pereira, F.~C., and Bialek, W.
\newblock The information bottleneck method.
\newblock In \emph{Proc. of the 34th Annual Allert. Conf. on Comm. Contr and
  Comput.}, 1999.

\bibitem[Titsias \& Lázaro-Gredilla(2014)Titsias and
  Lázaro-Gredilla]{titsias14}
Titsias, M. and Lázaro-Gredilla, M.
\newblock Doubly stochastic variational bayes for non-conjugate inference.
\newblock In \emph{Proc. of the 31st Int. Conf. on Mach. Learn.}, ICML, 2014.

\bibitem[Zhao et~al.(2019)Zhao, Song, and Ermon]{Zhao2019_InfoVAE}
Zhao, S., Song, J., and Ermon, S.
\newblock Infovae: Balancing learning and inference in variational
  autoencoders.
\newblock In \emph{Proc. of the 33rd AAAI Conf. on Artif. Intel.}, AAAI, 2019.

\end{thebibliography}
