\begin{thebibliography}{34}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bassily et~al.(2016)Bassily, Nissim, Smith, Steinke, Stemmer, and
  Ullman]{BassilyNSSSU16}
Raef Bassily, Kobbi Nissim, Adam Smith, Thomas Steinke, Uri Stemmer, and
  Jonathan Ullman.
\newblock Algorithmic stability for adaptive data analysis.
\newblock In \emph{Proceedings of the forty-eighth annual ACM symposium on
  Theory of Computing}, pages 1046--1059. ACM, 2016.

\bibitem[Berk et~al.(2013)Berk, Brown, Buja, Zhang, Zhao, et~al.]{Berk+13}
Richard Berk, Lawrence Brown, Andreas Buja, Kai Zhang, Linda Zhao, et~al.
\newblock Valid post-selection inference.
\newblock \emph{The Annals of Statistics}, 41\penalty0 (2):\penalty0 802--837,
  2013.

\bibitem[Bi et~al.(2017)Bi, Markovic, Xia, and Taylor]{BiMXT-inferactive17}
Nan Bi, Jelena Markovic, Lucy Xia, and Jonathan Taylor.
\newblock Inferactive data analysis.
\newblock \emph{arXiv:1707.06692 [math.ST]}, 2017.

\bibitem[Buja et~al.(2015)Buja, Berk, Brown, George, Pitkin, Traskin, Zhao, and
  Zhang]{Buja+15}
Andreas Buja, Richard Berk, Lawrence Brown, Edward George, Emil Pitkin, Mikhail
  Traskin, Linda Zhao, and Kai Zhang.
\newblock Models as approximations: A conspiracy of random regressors and model
  deviations against classical inference in regression.
\newblock \emph{Statistical Science}, 1460, 2015.

\bibitem[Bun et~al.(2017)Bun, Steinke, and Ullman]{BunSU17}
Mark Bun, Thomas Steinke, and Jonathan Ullman.
\newblock Make up your mind: The price of online queries in differential
  privacy.
\newblock In \emph{Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium
  on Discrete Algorithms}, pages 1306--1325. Society for Industrial and Applied
  Mathematics, 2017.

\bibitem[Cummings et~al.(2016)Cummings, Ligett, Nissim, Roth, and
  Wu]{CummingsLNRW16}
Rachel Cummings, Katrina Ligett, Kobbi Nissim, Aaron Roth, and Zhiwei~Steven
  Wu.
\newblock Adaptive learning with robust generalization guarantees.
\newblock In \emph{COLT}, 2016.

\bibitem[Dwork et~al.(2006)Dwork, McSherry, Nissim, and Smith]{DworkMNS06}
Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith.
\newblock Calibrating noise to sensitivity in private data analysis.
\newblock In \emph{TCC}, 2006.

\bibitem[Dwork et~al.(2015{\natexlab{a}})Dwork, Feldman, Hardt, Pitassi,
  Reingold, and Roth]{DworkFHPRR-nips-15}
Cynthia Dwork, Vitaly Feldman, Moritz Hardt, Toniann Pitassi, Omer Reingold,
  and Aaron Roth.
\newblock Generalization in adaptive data analysis and holdout reuse.
\newblock In \emph{NIPS}, 2015{\natexlab{a}}.

\bibitem[Dwork et~al.(2015{\natexlab{b}})Dwork, Feldman, Hardt, Pitassi,
  Reingold, and Roth]{DworkFHPRR15}
Cynthia Dwork, Vitaly Feldman, Moritz Hardt, Toniann Pitassi, Omer Reingold,
  and Aaron Roth.
\newblock Preserving statistical validity in adaptive data analysis.
\newblock In \emph{STOC}, 2015{\natexlab{b}}.

\bibitem[Dwork et~al.(2015{\natexlab{c}})Dwork, Smith, Steinke, Ullman, and
  Vadhan]{DworkSSUV15}
Cynthia Dwork, Adam Smith, Thomas Steinke, Jonathan Ullman, and Salil Vadhan.
\newblock Robust traceability from trace amounts.
\newblock In \emph{Foundations of Computer Science (FOCS), 2015 IEEE 56th
  Annual Symposium on}, pages 650--669. IEEE, 2015{\natexlab{c}}.

\bibitem[Efron(2014)]{Efron14}
Bradley Efron.
\newblock Estimation and accuracy after model selection.
\newblock \emph{Journal of the American Statistical Association}, 109\penalty0
  (507):\penalty0 991--1007, 2014.

\bibitem[Elder(2016)]{Elder16}
Sam Elder.
\newblock Challenges in bayesian adaptive data analysis.
\newblock \emph{CoRR}, abs/1604.02492, 2016.

\bibitem[Elder(2017)]{Elder17}
Sam Elder.
\newblock Bayesian adaptive data analysis guarantees from subgaussianity.
\newblock \emph{arXiv preprint arXiv:1611.00065}, 2017.

\bibitem[Feldman and Steinke(2017)]{FeldmanS17}
Vitaly Feldman and Thomas Steinke.
\newblock Generalization for adaptively-chosen estimators via stable median.
\newblock In \emph{{COLT} 2017 - The 30th Annual Conference on Learning
  Theory}, 2017.

\bibitem[Fish et~al.(2017)Fish, Reyzin, and Rubinstein]{FishRR17}
Benjamin Fish, Lev Reyzin, and Benjamin I.~P. Rubinstein.
\newblock Sublinear-time adaptive data analysis.
\newblock \emph{ArXiv CoRR}, abs/1709.09778, 2017.

\bibitem[Fithian et~al.(2014)Fithian, Sun, and Taylor]{FithianST14}
William Fithian, Dennis Sun, and Jonathan Taylor.
\newblock Optimal inference after model selection.
\newblock \emph{arXiv preprint arXiv:1410.2597}, 2014.

\bibitem[Freedman and Freedman(1983)]{Freedman83}
David~A Freedman and David~A Freedman.
\newblock A note on screening regression equations.
\newblock \emph{the american statistician}, 37\penalty0 (2):\penalty0 152--155,
  1983.

\bibitem[Gelman and Loken(2014)]{GelmanL13}
Andrew Gelman and Eric Loken.
\newblock The statistical crisis in science.
\newblock \emph{Am Sci}, 102\penalty0 (6):\penalty0 460, 2014.

\bibitem[Hardt and Ullman(2014)]{HardtU14}
Moritz Hardt and Jonathan Ullman.
\newblock Preventing false discovery in interactive data analysis is hard.
\newblock In \emph{Foundations of Computer Science (FOCS), 2014 IEEE 55th
  Annual Symposium on}, pages 454--463. IEEE, 2014.

\bibitem[Hurvich and Tsai(1990)]{HurvichT90}
Clifford~M Hurvich and Chih-Ling Tsai.
\newblock The impact of model selection on inference in linear regression.
\newblock \emph{The American Statistician}, 44\penalty0 (3):\penalty0 214--217,
  1990.

\bibitem[Ioannidis(2005)]{Ioannidis05}
John P.~A. Ioannidis.
\newblock Why most published research findings are false?
\newblock \emph{{PLoS} Medicine}, 2(8):124, August 2005.

\bibitem[Kearns(1993)]{Kearns93}
Michael~J. Kearns.
\newblock Efficient noise-tolerant learning from statistical queries.
\newblock In \emph{STOC}, 1993.

\bibitem[Leeb and P{\"o}tscher(2005)]{leeb2005model}
Hannes Leeb and Benedikt~M P{\"o}tscher.
\newblock Model selection and inference: Facts and fiction.
\newblock \emph{Econometric Theory}, 21\penalty0 (01):\penalty0 21--59, 2005.

\bibitem[Leeb and P{\"o}tscher(2006)]{leeb2006can}
Hannes Leeb and Benedikt~M P{\"o}tscher.
\newblock Can one estimate the conditional distribution of post-model-selection
  estimators?
\newblock \emph{The Annals of Statistics}, pages 2554--2591, 2006.

\bibitem[Nie et~al.(2017)Nie, Tian, Taylor, and Zou]{zou17}
Xinkun Nie, Xiaoying Tian, Jonathan Taylor, and James Zou.
\newblock Why adaptively collected data have negative bias and how to correct
  for it.
\newblock 2017.

\bibitem[P{\"o}tscher(1991)]{Potscher91}
Benedikt~M P{\"o}tscher.
\newblock Effects of model selection on inference.
\newblock \emph{Econometric Theory}, 1991.

\bibitem[Rogers et~al.(2016)Rogers, Roth, Smith, and Thakkar]{RogersRST16}
Ryan Rogers, Aaron Roth, Adam Smith, and Om~Thakkar.
\newblock Max-information, differential privacy, and post-selection hypothesis
  testing.
\newblock In \emph{IEEE 57th Annual Symposium on Foundations of Computer
  Science, FOCS}, pages 487--494, 2016.

\bibitem[Russo and Zou(2016)]{RussoZ15}
Daniel Russo and James Zou.
\newblock Controlling bias in adaptive data analysis using information theory.
\newblock In \emph{AISTATS}, 2016.

\bibitem[Steinke and Ullman(2015)]{SteinkeU14}
Thomas Steinke and Jonathan Ullman.
\newblock Interactive fingerprinting codes and the hardness of preventing false
  discovery.
\newblock In \emph{Conference on Learning Theory}, pages 1588--1628, 2015.

\bibitem[Steinke and Ullman(2017)]{SteinkeU17}
Thomas Steinke and Jonathan Ullman.
\newblock Tight lower bounds for differentially private selection.
\newblock In \emph{Foundations of Computer Science (FOCS), 2017 IEEE 58th
  Annual Symposium on}, pages 552--563. IEEE, 2017.

\bibitem[Taylor and Tibshirani(2015)]{TaylorT15}
Jonathan Taylor and Robert~J Tibshirani.
\newblock Statistical learning and selective inference.
\newblock \emph{Proceedings of the National Academy of Sciences}, 112\penalty0
  (25):\penalty0 7629--7634, 2015.

\bibitem[Wang(2017)]{WangThesis}
Yu-Xiang Wang.
\newblock \emph{New Paradigms and Optimality Guarantees in Statistical Learning
  and Estimation}.
\newblock PhD thesis, Carnegie Mellon University, 2017.

\bibitem[Wang et~al.(2016)Wang, Lei, and Fienberg]{WangLF16}
Yu-Xiang Wang, Jing Lei, and Stephen~E. Fienberg.
\newblock A minimax theory for adaptive data analysis.
\newblock \emph{CoRR}, abs/1602.04287, 2016.

\bibitem[Xu and Raginsky(2017)]{XR17}
Aolin Xu and Maxim Raginsky.
\newblock Information-theoretic analysis of generalization capability of
  learning algorithms.
\newblock In \emph{NIPS 2017, 4-9 December 2017, Long Beach, CA, {USA}}, pages
  2521--2530, 2017.

\end{thebibliography}
