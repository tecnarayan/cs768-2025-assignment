\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.(2015)Abadi, Agarwal, Barham, Brevdo, Chen, Citro,
  Corrado, Davis, Dean, Devin, et~al.]{tensorflow2015-whitepaper}
M.~Abadi, A.~Agarwal, P.~Barham, E.~Brevdo, Z.~Chen, C.~Citro, G.~S. Corrado,
  A.~Davis, J.~Dean, M.~Devin, et~al.
\newblock {TensorFlow}: Large-scale machine learning on heterogeneous systems,
  2015.
\newblock URL \url{http://tensorflow.org/}.

\bibitem[Bagnell et~al.(2003)Bagnell, Kakade, Ng, and
  Schneider]{bagnell2003policy}
J.~A. Bagnell, S.~Kakade, A.~Y. Ng, and J.~G. Schneider.
\newblock Policy search by dynamic programming.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  831--838, 2003.

\bibitem[Bai et~al.(2010)Bai, Hsu, Lee, and Ngo]{bai2010monte}
H.~Bai, D.~Hsu, W.~S. Lee, and V.~A. Ngo.
\newblock Monte carlo value iteration for continuous-state {POMDP}s.
\newblock In \emph{Algorithmic Foundations of Robotics IX}, pages 175--191,
  2010.

\bibitem[Bakker et~al.(2003)Bakker, Zhumatiy, Gruener, and
  Schmidhuber]{bakker2003robot}
B.~Bakker, V.~Zhumatiy, G.~Gruener, and J.~Schmidhuber.
\newblock A robot that reinforcement-learns to identify and memorize important
  previous observations.
\newblock In \emph{International Conference on Intelligent Robots and Systems},
  pages 430--435, 2003.

\bibitem[Baxter and Bartlett(2001)]{baxter2001infinite}
J.~Baxter and P.~L. Bartlett.
\newblock Infinite-horizon policy-gradient estimation.
\newblock \emph{Journal of Artificial Intelligence Research}, 15:\penalty0
  319--350, 2001.

\bibitem[Boots et~al.(2011)Boots, Siddiqi, and Gordon]{boots2011closing}
B.~Boots, S.~M. Siddiqi, and G.~J. Gordon.
\newblock Closing the learning-planning loop with predictive state
  representations.
\newblock \emph{The International Journal of Robotics Research}, 30\penalty0
  (7):\penalty0 954--966, 2011.

\bibitem[Cho et~al.(2014)Cho, Van~Merri{\"e}nboer, Gulcehre, Bahdanau,
  Bougares, Schwenk, and Bengio]{cho2014learning}
K.~Cho, B.~Van~Merri{\"e}nboer, C.~Gulcehre, D.~Bahdanau, F.~Bougares,
  H.~Schwenk, and Y.~Bengio.
\newblock Learning phrase representations using {RNN} encoder-decoder for
  statistical machine translation.
\newblock \emph{arXiv preprint arXiv:1406.1078}, 2014.

\bibitem[Gupta et~al.(2017)Gupta, Davidson, Levine, Sukthankar, and
  Malik]{gupta2017cognitive}
S.~Gupta, J.~Davidson, S.~Levine, R.~Sukthankar, and J.~Malik.
\newblock Cognitive mapping and planning for visual navigation.
\newblock \emph{arXiv preprint arXiv:1702.03920}, 2017.

\bibitem[Haarnoja et~al.(2016)Haarnoja, Ajay, Levine, and
  Abbeel]{haarnoja2016backprop}
T.~Haarnoja, A.~Ajay, S.~Levine, and P.~Abbeel.
\newblock Backprop kf: Learning discriminative deterministic state estimators.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  4376--4384, 2016.

\bibitem[Hausknecht and Stone(2015)]{hausknecht2015deep}
M.~J. Hausknecht and P.~Stone.
\newblock Deep recurrent {Q}-learning for partially observable {MDP}s.
\newblock \emph{arXiv preprint}, 2015.
\newblock URL \url{http://arxiv.org/abs/1507.06527}.

\bibitem[Hochreiter and Schmidhuber(1997)]{hochreiter1997long}
S.~Hochreiter and J.~Schmidhuber.
\newblock Long short-term memory.
\newblock \emph{Neural Computation}, 9\penalty0 (8):\penalty0 1735--1780, 1997.

\bibitem[Howard and Roy(2003)]{radish}
A.~Howard and N.~Roy.
\newblock The robotics data set repository (radish), 2003.
\newblock URL \url{http://radish.sourceforge.net/}.

\bibitem[Hsiao et~al.(2007)Hsiao, Kaelbling, and
  Lozano-P{\'e}rez]{hsiao2007grasping}
K.~Hsiao, L.~P. Kaelbling, and T.~Lozano-P{\'e}rez.
\newblock Grasping {POMDP}s.
\newblock In \emph{International Conference on Robotics and Automation}, pages
  4685--4692, 2007.

\bibitem[Ji et~al.(2013)Ji, Xu, Yang, and Yu]{ji2013}
S.~Ji, W.~Xu, M.~Yang, and K.~Yu.
\newblock 3{D} convolutional neural networks for human action recognition.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 35\penalty0 (1):\penalty0 221--231, 2013.

\bibitem[Jonschkowski and Brock(2016)]{jonschkowski2016}
R.~Jonschkowski and O.~Brock.
\newblock End-to-end learnable histogram filters.
\newblock In \emph{Workshop on Deep Learning for Action and Interaction at
  NIPS}, 2016.
\newblock URL
  \url{http://www.robotics.tu-berlin.de/fileadmin/fg170/Publikationen_pdf/Jonschkowski-16-NIPS-WS.pdf}.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2012imagenet}
A.~Krizhevsky, I.~Sutskever, and G.~E. Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1097--1105, 2012.

\bibitem[Kurniawati et~al.(2008)Kurniawati, Hsu, and Lee]{kurniawati2008sarsop}
H.~Kurniawati, D.~Hsu, and W.~S. Lee.
\newblock Sarsop: Efficient point-based {POMDP} planning by approximating
  optimally reachable belief spaces.
\newblock In \emph{Robotics: Science and Systems}, volume 2008, 2008.

\bibitem[Littman et~al.(1995)Littman, Cassandra, and
  Kaelbling]{littman1995learning}
M.~L. Littman, A.~R. Cassandra, and L.~P. Kaelbling.
\newblock Learning policies for partially observable environments: Scaling up.
\newblock In \emph{International Conference on Machine Learning}, pages
  362--370, 1995.

\bibitem[Littman et~al.(2002)Littman, Sutton, and Singh]{littman2002predictive}
M.~L. Littman, R.~S. Sutton, and S.~Singh.
\newblock Predictive representations of state.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1555--1562, 2002.

\bibitem[Mirowski et~al.(2016)Mirowski, Pascanu, Viola, Soyer, Ballard, Banino,
  Denil, Goroshin, Sifre, Kavukcuoglu, et~al.]{mirowski2016learning}
P.~Mirowski, R.~Pascanu, F.~Viola, H.~Soyer, A.~Ballard, A.~Banino, M.~Denil,
  R.~Goroshin, L.~Sifre, K.~Kavukcuoglu, et~al.
\newblock Learning to navigate in complex environments.
\newblock \emph{arXiv preprint arXiv:1611.03673}, 2016.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{mnih2015human}
V.~Mnih, K.~Kavukcuoglu, D.~Silver, A.~A. Rusu, J.~Veness, M.~G. Bellemare,
  A.~Graves, M.~Riedmiller, A.~K. Fidjeland, G.~Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529--533, 2015.

\bibitem[Ng et~al.(1999)Ng, Harada, and Russell]{ng1999policy}
A.~Y. Ng, D.~Harada, and S.~Russell.
\newblock Policy invariance under reward transformations: Theory and
  application to reward shaping.
\newblock In \emph{International Conference on Machine Learning}, pages
  278--287, 1999.

\bibitem[Okada et~al.(2017)Okada, Rigazio, and Aoshima]{OkaRig17}
M.~Okada, L.~Rigazio, and T.~Aoshima.
\newblock Path integral networks: End-to-end differentiable optimal control.
\newblock \emph{arXiv preprint arXiv:1706.09597}, 2017.

\bibitem[Papadimitriou and Tsitsiklis(1987)]{papadimitriou1987complexity}
C.~H. Papadimitriou and J.~N. Tsitsiklis.
\newblock The complexity of {M}arkov decision processes.
\newblock \emph{Mathematics of Operations Research}, 12\penalty0 (3):\penalty0
  441--450, 1987.

\bibitem[Pineau et~al.(2003)Pineau, Gordon, and Thrun]{pineau2003applying}
J.~Pineau, G.~J. Gordon, and S.~Thrun.
\newblock Applying metric-trees to belief-point {POMDP}s.
\newblock In \emph{Advances in Neural Information Processing Systems}, page
  None, 2003.

\bibitem[Shani et~al.(2005)Shani, Brafman, and Shimony]{shani2005model}
G.~Shani, R.~I. Brafman, and S.~E. Shimony.
\newblock Model-based online learning of {POMDP}s.
\newblock In \emph{European Conference on Machine Learning}, pages 353--364,
  2005.

\bibitem[Shani et~al.(2013)Shani, Pineau, and Kaplow]{shani2013survey}
G.~Shani, J.~Pineau, and R.~Kaplow.
\newblock A survey of point-based {POMDP} solvers.
\newblock \emph{Autonomous Agents and Multi-agent Systems}, 27\penalty0
  (1):\penalty0 1--51, 2013.

\bibitem[Shankar et~al.(2016)Shankar, Dwivedy, and
  Guha]{shankar2016reinforcement}
T.~Shankar, S.~K. Dwivedy, and P.~Guha.
\newblock Reinforcement learning via recurrent convolutional neural networks.
\newblock In \emph{International Conference on Pattern Recognition}, pages
  2592--2597, 2016.

\bibitem[Silver and Veness(2010)]{silver2010monte}
D.~Silver and J.~Veness.
\newblock Monte-carlo planning in large {POMDP}s.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2164--2172, 2010.

\bibitem[Silver et~al.(2016{\natexlab{a}})Silver, Huang, Maddison, Guez, Sifre,
  Van Den~Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot,
  et~al.]{silver2016mastering}
D.~Silver, A.~Huang, C.~J. Maddison, A.~Guez, L.~Sifre, G.~Van Den~Driessche,
  J.~Schrittwieser, I.~Antonoglou, V.~Panneershelvam, M.~Lanctot, et~al.
\newblock Mastering the game of {G}o with deep neural networks and tree search.
\newblock \emph{Nature}, 529\penalty0 (7587):\penalty0 484--489,
  2016{\natexlab{a}}.

\bibitem[Silver et~al.(2016{\natexlab{b}})Silver, van Hasselt, Hessel, Schaul,
  Guez, Harley, Dulac-Arnold, Reichert, Rabinowitz, Barreto,
  et~al.]{silver2016predictron}
D.~Silver, H.~van Hasselt, M.~Hessel, T.~Schaul, A.~Guez, T.~Harley,
  G.~Dulac-Arnold, D.~Reichert, N.~Rabinowitz, A.~Barreto, et~al.
\newblock The predictron: End-to-end learning and planning.
\newblock \emph{arXiv preprint}, 2016{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/1612.08810}.

\bibitem[Spaan and Vlassis(2005)]{spaan2005perseus}
M.~T. Spaan and N.~Vlassis.
\newblock Perseus: Randomized point-based value iteration for {POMDP}s.
\newblock \emph{Journal of Artificial Intelligence Research}, 24:\penalty0
  195--220, 2005.

\bibitem[Stachniss()]{unibonn}
C.~Stachniss.
\newblock Robotics {2D}-laser dataset.
\newblock URL \url{http://www.ipb.uni-bonn.de/datasets/}.

\bibitem[Tamar et~al.(2016)Tamar, Levine, Abbeel, Wu, and
  Thomas]{tamar2016value}
A.~Tamar, S.~Levine, P.~Abbeel, Y.~Wu, and G.~Thomas.
\newblock Value iteration networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2146--2154, 2016.

\bibitem[Tieleman and Hinton(2012)]{tieleman2012lecture}
T.~Tieleman and G.~Hinton.
\newblock Lecture 6.5 - rmsprop: Divide the gradient by a running average of
  its recent magnitude.
\newblock \emph{COURSERA: Neural networks for machine learning}, pages 26--31,
  2012.

\bibitem[Xingjian et~al.(2015)Xingjian, Chen, Wang, Yeung, Wong, and
  Woo]{xingjian2015convolutional}
S.~Xingjian, Z.~Chen, H.~Wang, D.-Y. Yeung, W.-k. Wong, and W.-c. Woo.
\newblock Convolutional {LSTM} network: A machine learning approach for
  precipitation nowcasting.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  802--810, 2015.

\bibitem[Ye et~al.(2017)Ye, Somani, Hsu, and Lee]{ye2017despot}
N.~Ye, A.~Somani, D.~Hsu, and W.~S. Lee.
\newblock Despot: Online {POMDP} planning with regularization.
\newblock \emph{Journal of Artificial Intelligence Research}, 58:\penalty0
  231--266, 2017.

\end{thebibliography}
