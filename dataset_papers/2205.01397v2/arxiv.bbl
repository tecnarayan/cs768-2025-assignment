\begin{thebibliography}{39}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Andreassen et~al.(2021)Andreassen, Bahri, Neyshabur, and
  Roelofs]{andreassen2021evolution}
Anders Andreassen, Yasaman Bahri, Behnam Neyshabur, and Rebecca Roelofs.
\newblock The evolution of out-of-distribution robustness throughout
  fine-tuning.
\newblock 2021.
\newblock \url{https://arxiv.org/abs/2106.15831}.

\bibitem[Barbu et~al.(2019)Barbu, Mayo, Alverio, Luo, Wang, Gutfreund,
  Tenenbaum, and Katz]{objectnet}
Andrei Barbu, David Mayo, Julian Alverio, William Luo, Christopher Wang, Dan
  Gutfreund, Josh Tenenbaum, and Boris Katz.
\newblock Objectnet: A large-scale bias-controlled dataset for pushing the
  limits of object recognition models.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2019.
\newblock
  \url{https://proceedings.neurips.cc/paper/2019/file/97af07a14cacba681feacf3012730892-Paper.pdf}.

\bibitem[Caron et~al.(2020)Caron, Misra, Mairal, Goyal, Bojanowski, and
  Joulin]{caron2020unsupervised}
Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Piotr Bojanowski, and
  Armand Joulin.
\newblock Unsupervised learning of visual features by contrasting cluster
  assignments.
\newblock 2020.
\newblock \url{https://arxiv.org/abs/2006.09882}.

\bibitem[Changpinyo et~al.(2021)Changpinyo, Sharma, Ding, and
  Soricut]{changpinyo2021conceptual}
Soravit Changpinyo, Piyush Sharma, Nan Ding, and Radu Soricut.
\newblock Conceptual 12m: Pushing web-scale image-text pre-training to
  recognize long-tail visual concepts.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2021.
\newblock \url{https://arxiv.org/abs/2102.08981}.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Kornblith, Norouzi, and
  Hinton]{simclr2020}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey~E. Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning, {ICML} 2020, 13-18 July 2020, Virtual Event}, volume 119 of
  \emph{Proceedings of Machine Learning Research}. {PMLR}, 2020{\natexlab{a}}.
\newblock \url{http://proceedings.mlr.press/v119/chen20j.html}.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Kornblith, Swersky, Norouzi, and
  Hinton]{chen2020big}
Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey
  Hinton.
\newblock Big self-supervised models are strong semi-supervised learners.
\newblock 2020{\natexlab{b}}.
\newblock \url{https://arxiv.org/abs/2006.10029}.

\bibitem[Chen and He(2020)]{chen2020exploring}
Xinlei Chen and Kaiming He.
\newblock Exploring simple siamese representation learning. corr abs/2011.10566
  (2020).
\newblock 2020.
\newblock \url{https://arxiv.org/abs/2011.10566}.

\bibitem[Chen et~al.(2015)Chen, Fang, Lin, Vedantam, Gupta, Doll{\'a}r, and
  Zitnick]{chen2015microsoft}
Xinlei Chen, Hao Fang, Tsung-Yi Lin, Ramakrishna Vedantam, Saurabh Gupta, Piotr
  Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco captions: Data collection and evaluation server.
\newblock 2015.
\newblock \url{https://arxiv.org/abs/1504.00325}.

\bibitem[Cubuk et~al.(2020)Cubuk, Zoph, Shlens, and Le]{cubuk2020randaugment}
Ekin~D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc~V Le.
\newblock Randaugment: Practical automated data augmentation with a reduced
  search space.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  Workshops}, 2020.
\newblock \url{https://arxiv.org/abs/1909.13719}.

\bibitem[Desai and Johnson(2021)]{Desai021}
Karan Desai and Justin Johnson.
\newblock Virtex: Learning visual representations from textual annotations.
\newblock In \emph{{IEEE} Conference on Computer Vision and Pattern
  Recognition, {CVPR} 2021, virtual, June 19-25, 2021}, pages 11162--11173.
  Computer Vision Foundation / {IEEE}, 2021.
\newblock URL
  \url{https://openaccess.thecvf.com/content/CVPR2021/html/Desai\_VirTex\_Learning\_Visual\_Representations\_From\_Textual\_Annotations\_CVPR\_2021\_paper.html}.

\bibitem[Desai et~al.(2021)Desai, Kaul, Aysola, and Johnson]{desai2021redcaps}
Karan Desai, Gaurav Kaul, Zubin~Trivadi Aysola, and Justin Johnson.
\newblock Redcaps: Web-curated image-text data created by the people, for the
  people.
\newblock 2021.
\newblock \url{https://arxiv.org/abs/2111.11431}.

\bibitem[Devillers et~al.(2021)Devillers, Choksi, Bielawski, and
  VanRullen]{devillers2021does}
Benjamin Devillers, Bhavin Choksi, Romain Bielawski, and Rufin VanRullen.
\newblock Does language help generalization in vision models?
\newblock 2021.
\newblock \url{https://arxiv.org/abs/2104.08313}.

\bibitem[Djolonga et~al.(2021)Djolonga, Yung, Tschannen, Romijnders, Beyer,
  Kolesnikov, Puigcerver, Minderer, D'Amour, Moldovan, Gelly, Houlsby, Zhai,
  and Lucic]{Djolonga_2021_CVPR}
Josip Djolonga, Jessica Yung, Michael Tschannen, Rob Romijnders, Lucas Beyer,
  Alexander Kolesnikov, Joan Puigcerver, Matthias Minderer, Alexander D'Amour,
  Dan Moldovan, Sylvain Gelly, Neil Houlsby, Xiaohua Zhai, and Mario Lucic.
\newblock On robustness and transferability of convolutional neural networks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, June 2021.
\newblock \url{https://arxiv.org/abs/2007.08558}.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and
  Houlsby]{vit2020}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{CoRR}, abs/2010.11929, 2020.
\newblock \url{https://arxiv.org/abs/2010.11929}.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{2016 {IEEE} Conference on Computer Vision and Pattern
  Recognition, {CVPR} 2016, Las Vegas, NV, USA, June 27-30, 2016}, pages
  770--778. {IEEE} Computer Society, 2016.
\newblock \doi{10.1109/CVPR.2016.90}.
\newblock \url{https://doi.org/10.1109/CVPR.2016.90}.

\bibitem[He et~al.(2021)He, Chen, Xie, Li, Doll{\'a}r, and
  Girshick]{he2021masked}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'a}r, and Ross
  Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock 2021.
\newblock \url{https://arxiv.org/abs/2111.06377}.

\bibitem[Heckel and Yilmaz(2021)]{heckel2021early}
Reinhard Heckel and Fatih~Furkan Yilmaz.
\newblock Early stopping in deep networks: Double descent and how to eliminate
  it.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=tlV90jvZbw}.

\bibitem[Hendrycks et~al.(2019)Hendrycks, Zhao, Basart, Steinhardt, and
  Song]{hendrycks2019natural}
Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, and Dawn Song.
\newblock Natural adversarial examples.(2019).
\newblock 2019.
\newblock \url{https://arxiv.org/abs/1907.07174}.

\bibitem[Hendrycks et~al.(2021)Hendrycks, Basart, Mu, Kadavath, Wang, Dorundo,
  Desai, Zhu, Parajuli, Guo, et~al.]{hendrycks2021many}
Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan
  Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et~al.
\newblock The many faces of robustness: A critical analysis of
  out-of-distribution generalization.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, 2021.
\newblock \url{https://arxiv.org/abs/2006.16241}.

\bibitem[Jain et~al.(2019)Jain, Lennan, John, and Tran]{idealods2019imagededup}
Tanuj Jain, Christopher Lennan, Zubin John, and Dat Tran.
\newblock Imagededup.
\newblock \url{https://github.com/idealo/imagededup}, 2019.

\bibitem[Jia et~al.(2021)Jia, Yang, Xia, Chen, Parekh, Pham, Le, Sung, Li, and
  Duerig]{jia2021scaling}
Chao Jia, Yinfei Yang, Ye~Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc~V.
  Le, Yunhsuan Sung, Zhen Li, and Tom Duerig.
\newblock Scaling up visual and vision-language representation learning with
  noisy text supervision, 2021.
\newblock \url{https://arxiv.org/abs/2102.05918}.

\bibitem[Miller(1995)]{wordnet}
George~A. Miller.
\newblock Wordnet: A lexical database for english.
\newblock \emph{Commun. ACM}, Nov 1995.
\newblock \url{https://doi.org/10.1145/219717.219748}.

\bibitem[Miller et~al.(2021)Miller, Taori, Raghunathan, Sagawa, Koh, Shankar,
  Liang, Carmon, and Schmidt]{miller2021accuracy}
John~P Miller, Rohan Taori, Aditi Raghunathan, Shiori Sagawa, Pang~Wei Koh,
  Vaishaal Shankar, Percy Liang, Yair Carmon, and Ludwig Schmidt.
\newblock Accuracy on the line: on the strong correlation between
  out-of-distribution and in-distribution generalization.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2021.
\newblock \url{https://arxiv.org/abs/2107.04649}.

\bibitem[Mu et~al.(2021)Mu, Kirillov, Wagner, and Xie]{mu2021slip}
Norman Mu, Alexander Kirillov, David Wagner, and Saining Xie.
\newblock Slip: Self-supervision meets language-image pre-training.
\newblock 2021.
\newblock \url{https://arxiv.org/abs/2112.12750}.

\bibitem[Ordonez et~al.(2011)Ordonez, Kulkarni, and Berg]{ordonez2011im2text}
Vicente Ordonez, Girish Kulkarni, and Tamara Berg.
\newblock Im2text: Describing images using 1 million captioned photographs.
\newblock \emph{Advances in neural information processing systems}, 24, 2011.
\newblock
  \url{https://proceedings.neurips.cc/paper/2011/file/5dd9db5e033da9c6fb5ba83c7a7ebea9-Paper.pdf}.

\bibitem[Pham et~al.(2021)Pham, Dai, Ghiasi, Liu, Yu, Luong, Tan, and
  Le]{basic2021}
Hieu Pham, Zihang Dai, Golnaz Ghiasi, Hanxiao Liu, Adams~Wei Yu, Minh{-}Thang
  Luong, Mingxing Tan, and Quoc~V. Le.
\newblock Combined scaling for zero-shot transfer learning.
\newblock \emph{CoRR}, abs/2111.10050, 2021.
\newblock \url{https://arxiv.org/abs/2111.10050}.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, Krueger, and Sutskever]{radford21a}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  Gretchen Krueger, and Ilya Sutskever.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In Marina Meila and Tong Zhang, editors, \emph{Proceedings of the
  38th International Conference on Machine Learning, {ICML} 2021, 18-24 July
  2021, Virtual Event}, volume 139 of \emph{Proceedings of Machine Learning
  Research}. {PMLR}, 2021.
\newblock \url{http://proceedings.mlr.press/v139/radford21a.html}.

\bibitem[Recht et~al.(2019)Recht, Roelofs, Schmidt, and
  Shankar]{recht2019imagenet}
Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar.
\newblock Do imagenet classifiers generalize to imagenet?
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2019.
\newblock \url{https://arxiv.org/abs/1902.10811}.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, et~al.]{russakovsky2015imagenet}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{International journal of computer vision}, 115\penalty0
  (3):\penalty0 211--252, 2015.

\bibitem[Sariyildiz et~al.(2020)Sariyildiz, Perez, and Larlus]{SariyildizPL20}
Mert~B{\"{u}}lent Sariyildiz, Julien Perez, and Diane Larlus.
\newblock Learning visual representations with caption annotations.
\newblock In Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan{-}Michael
  Frahm, editors, \emph{Computer Vision - {ECCV} 2020 - 16th European
  Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part {VIII}},
  volume 12353 of \emph{Lecture Notes in Computer Science}, pages 153--170.
  Springer, 2020.
\newblock \doi{10.1007/978-3-030-58598-3\_10}.
\newblock URL \url{https://doi.org/10.1007/978-3-030-58598-3\_10}.

\bibitem[Schuhmann et~al.(2021)Schuhmann, Vencu, Beaumont, Kaczmarczyk, Mullis,
  Katta, Coombes, Jitsev, and Komatsuzaki]{schuhmann2021laion}
Christoph Schuhmann, Richard Vencu, Romain Beaumont, Robert Kaczmarczyk,
  Clayton Mullis, Aarush Katta, Theo Coombes, Jenia Jitsev, and Aran
  Komatsuzaki.
\newblock Laion-400m: Open dataset of clip-filtered 400 million image-text
  pairs.
\newblock 2021.
\newblock \url{https://arxiv.org/abs/2111.02114}.

\bibitem[Shankar et~al.(2020)Shankar, Roelofs, Mania, Fang, Recht, and
  Schmidt]{shankar2020evaluating}
Vaishaal Shankar, Rebecca Roelofs, Horia Mania, Alex Fang, Benjamin Recht, and
  Ludwig Schmidt.
\newblock Evaluating machine accuracy on imagenet.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2020.
\newblock \url{https://proceedings.mlr.press/v119/shankar20c.html}.

\bibitem[Sharma et~al.(2018)Sharma, Ding, Goodman, and
  Soricut]{sharma2018conceptual}
Piyush Sharma, Nan Ding, Sebastian Goodman, and Radu Soricut.
\newblock Conceptual captions: A cleaned, hypernymed, image alt-text dataset
  for automatic image captioning.
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, 2018.

\bibitem[Srinivasan et~al.(2021)Srinivasan, Raman, Chen, Bendersky, and
  Najork]{srinivasan2021wit}
Krishna Srinivasan, Karthik Raman, Jiecao Chen, Michael Bendersky, and Marc
  Najork.
\newblock Wit: Wikipedia-based image text dataset for multimodal multilingual
  machine learning.
\newblock 2021.
\newblock \url{https://arxiv.org/abs/2103.01913}.

\bibitem[Taori et~al.(2020)Taori, Dave, Shankar, Carlini, Recht, and
  Schmidt]{taori2020measuring}
Rohan Taori, Achal Dave, Vaishaal Shankar, Nicholas Carlini, Benjamin Recht,
  and Ludwig Schmidt.
\newblock Measuring robustness to natural distribution shifts in image
  classification.
\newblock 2020.
\newblock \url{https://arxiv.org/abs/2007.00644}.

\bibitem[Thomee et~al.(2016)Thomee, Shamma, Friedland, Elizalde, Ni, Poland,
  Borth, and Li]{thomee2016yfcc100m}
Bart Thomee, David~A Shamma, Gerald Friedland, Benjamin Elizalde, Karl Ni,
  Douglas Poland, Damian Borth, and Li-Jia Li.
\newblock Yfcc100m: The new data in multimedia research.
\newblock \emph{Communications of the ACM}, 59\penalty0 (2):\penalty0 64--73,
  2016.

\bibitem[Wang et~al.(2019)Wang, Ge, Xing, and Lipton]{wang2019learning}
Haohan Wang, Songwei Ge, Eric~P Xing, and Zachary~C Lipton.
\newblock Learning robust global representations by penalizing local predictive
  power.
\newblock 2019.
\newblock \url{https://arxiv.org/abs/1905.13549}.

\bibitem[Zhai et~al.(2021)Zhai, Wang, Mustafa, Steiner, Keysers, Kolesnikov,
  and Beyer]{lit}
Xiaohua Zhai, Xiao Wang, Basil Mustafa, Andreas Steiner, Daniel Keysers,
  Alexander Kolesnikov, and Lucas Beyer.
\newblock Lit: Zero-shot transfer with locked-image text tuning.
\newblock \emph{CoRR}, 2021.
\newblock \url{https://arxiv.org/abs/2111.07991}.

\bibitem[Zhang et~al.(2020)Zhang, Jiang, Miura, Manning, and
  Langlotz]{ZhangConvirt}
Yuhao Zhang, Hang Jiang, Yasuhide Miura, Christopher~D. Manning, and Curtis~P.
  Langlotz.
\newblock Contrastive learning of medical visual representations from paired
  images and text.
\newblock \emph{CoRR}, abs/2010.00747, 2020.
\newblock URL \url{https://arxiv.org/abs/2010.00747}.

\end{thebibliography}
