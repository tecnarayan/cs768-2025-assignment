

@article{berner2019dota,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and D{\k{e}}biak, Przemys{\l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}

@article{perolat2022mastering,
  title={Mastering the game of Stratego with model-free multiagent reinforcement learning},
  author={Perolat, Julien and De Vylder, Bart and Hennes, Daniel and Tarassov, Eugene and Strub, Florian and de Boer, Vincent and Muller, Paul and Connor, Jerome T and Burch, Neil and Anthony, Thomas and others},
  journal={Science},
  volume={378},
  number={6623},
  pages={990--996},
  year={2022},
  publisher={American Association for the Advancement of Science}
}

@article{papoudakis2020benchmarking,
  title={Benchmarking multi-agent deep reinforcement learning algorithms in cooperative tasks},
  author={Papoudakis, Georgios and Christianos, Filippos and Sch{\"a}fer, Lukas and Albrecht, Stefano V},
  journal={arXiv preprint arXiv:2006.07869},
  year={2020}
}

@article{sunehag2017value,
  title={Value-decomposition networks for cooperative multi-agent learning},
  author={Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others},
  journal={arXiv preprint arXiv:1706.05296},
  year={2017}
}

@inproceedings{rashid2018qmix,
  title={Qmix: Monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and Schroeder, Christian and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  booktitle={International conference on machine learning},
  pages={4295--4304},
  year={2018},
  organization={PMLR}
}

@inproceedings{foerster2018counterfactual,
  title={Counterfactual multi-agent policy gradients},
  author={Foerster, Jakob and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  year={2018}
}

@article{lowe2017multi,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and Wu, Yi I and Tamar, Aviv and Harb, Jean and Pieter Abbeel, OpenAI and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{hong2022rethinking,
  title={Rethinking Individual Global Max in Cooperative Multi-Agent Reinforcement Learning},
  author={Hong, Yitian and Jin, Yaochu and Tang, Yang},
  journal={arXiv preprint arXiv:2209.09640},
  year={2022}
}


@inproceedings{lauer2000algorithm,
  title={An algorithm for distributed reinforcement learning in cooperative multi-agent systems},
  author={Lauer, Martin and Riedmiller, Martin},
  booktitle={In Proceedings of the Seventeenth International Conference on Machine Learning},
  year={2000},
  organization={Citeseer}
}

@article{claus1998dynamics,
  title={The dynamics of reinforcement learning in cooperative multiagent systems},
  author={Claus, Caroline and Boutilier, Craig},
  journal={AAAI/IAAI},
  volume={1998},
  number={746-752},
  pages={2},
  year={1998}
}


@article{wei2018multiagent,
  title={Multiagent soft q-learning},
  author={Wei, Ermo and Wicke, Drew and Freelan, David and Luke, Sean},
  journal={arXiv preprint arXiv:1804.09817},
  year={2018}
}

@article{peng2021facmac,
  title={Facmac: Factored multi-agent centralised policy gradients},
  author={Peng, Bei and Rashid, Tabish and Schroeder de Witt, Christian and Kamienny, Pierre-Alexandre and Torr, Philip and B{\"o}hmer, Wendelin and Whiteson, Shimon},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={12208--12221},
  year={2021}
}

@inproceedings{omidshafiei2017deep,
  title={Deep decentralized multi-task multi-agent reinforcement learning under partial observability},
  author={Omidshafiei, Shayegan and Pazis, Jason and Amato, Christopher and How, Jonathan P and Vian, John},
  booktitle={International Conference on Machine Learning},
  pages={2681--2690},
  year={2017},
  organization={PMLR}
}

@article{palmer2017lenient,
  title={Lenient multi-agent deep reinforcement learning},
  author={Palmer, Gregory and Tuyls, Karl and Bloembergen, Daan and Savani, Rahul},
  journal={arXiv preprint arXiv:1707.04402},
  year={2017}
}

@article{de2020independent,
  title={Is independent learning all you need in the starcraft multi-agent challenge?},
  author={De Witt, Christian Schroeder and Gupta, Tarun and Makoviichuk, Denys and Makoviychuk, Viktor and Torr, Philip HS and Sun, Mingfei and Whiteson, Shimon},
  journal={arXiv preprint arXiv:2011.09533},
  year={2020}
}

@article{matignon2012independent,
  title={Independent reinforcement learners in cooperative markov games: a survey regarding coordination problems},
  author={Matignon, Laetitia and Laurent, Guillaume J and Le Fort-Piat, Nadine},
  journal={The Knowledge Engineering Review},
  volume={27},
  number={1},
  pages={1--31},
  year={2012},
  publisher={Cambridge University Press}
}

@article{jiang2023best,
  title={Best Possible Q-Learning},
  author={Jiang, Jiechuan and Lu, Zongqing},
  journal={arXiv preprint arXiv:2302.01188},
  year={2023}
}

@article{rashid2020weighted,
  title={Weighted qmix: Expanding monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Farquhar, Gregory and Peng, Bei and Whiteson, Shimon},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={10199--10210},
  year={2020}
}


@article{rashid2020monotonic,
  title={Monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and De Witt, Christian Schroeder and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={7234--7284},
  year={2020},
  publisher={JMLRORG}
}

@article{yu2022surprising,
  title={The surprising effectiveness of ppo in cooperative multi-agent games},
  author={Yu, Chao and Velu, Akash and Vinitsky, Eugene and Gao, Jiaxuan and Wang, Yu and Bayen, Alexandre and Wu, Yi},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24611--24624},
  year={2022}
}


@article{sun2022monotonic,
  title={Monotonic improvement guarantees under non-stationarity for decentralized ppo},
  author={Sun, Mingfei and Devlin, Sam and Beck, Jacob and Hofmann, Katja and Whiteson, Shimon},
  journal={arXiv preprint arXiv:2202.00082},
  year={2022}
}


@article{wang2023order,
  title={Order Matters: Agent-by-agent Policy Optimization},
  author={Wang, Xihuai and Tian, Zheng and Wan, Ziyu and Wen, Ying and Wang, Jun and Zhang, Weinan},
  journal={arXiv preprint arXiv:2302.06205},
  year={2023}
}

@article{ghosh2020operator,
  title={An operator view of policy gradient methods},
  author={Ghosh, Dibya and C Machado, Marlos and Le Roux, Nicolas},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3397--3406},
  year={2020}
}

@article{bernstein2002complexity,
  title={The complexity of decentralized control of Markov decision processes},
  author={Bernstein, Daniel S and Givan, Robert and Immerman, Neil and Zilberstein, Shlomo},
  journal={Mathematics of operations research},
  volume={27},
  number={4},
  pages={819--840},
  year={2002},
  publisher={INFORMS}
}

@inproceedings{van2016deep,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={30},
  year={2016}
}

@article{abdolmaleki2018maximum,
  title={Maximum a posteriori policy optimisation},
  author={Abdolmaleki, Abbas and Springenberg, Jost Tobias and Tassa, Yuval and Munos, Remi and Heess, Nicolas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1806.06920},
  year={2018}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Reinforcement learning},
  pages={5--32},
  year={1992},
  publisher={Springer}
}

@article{carroll2019utility,
  title={On the utility of learning about humans for human-ai coordination},
  author={Carroll, Micah and Shah, Rohin and Ho, Mark K and Griffiths, Tom and Seshia, Sanjit and Abbeel, Pieter and Dragan, Anca},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{maas2013rectifier,
  title={Rectifier nonlinearities improve neural network acoustic models},
  author={Maas, Andrew L and Hannun, Awni Y and Ng, Andrew Y and others},
  booktitle={Proc. icml},
  volume={30},
  year={2013},
  organization={Atlanta, Georgia, USA}
}

@inproceedings{matignon2007hysteretic,
  title={Hysteretic q-learning: an algorithm for decentralized reinforcement learning in cooperative multi-agent teams},
  author={Matignon, La{\"e}titia and Laurent, Guillaume J and Le Fort-Piat, Nadine},
  booktitle={2007 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={64--69},
  year={2007},
  organization={IEEE}
}

@inproceedings{panait2006lenient,
  title={Lenient learners in cooperative multiagent systems},
  author={Panait, Liviu and Sullivan, Keith and Luke, Sean},
  booktitle={Proceedings of the fifth international joint conference on Autonomous agents and multiagent systems},
  pages={801--803},
  year={2006}
}

@article{wei2016lenient,
  title={Lenient learning in independent-learner stochastic cooperative games},
  author={Wei, Ermo and Luke, Sean},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2914--2955},
  year={2016},
  publisher={JMLR. org}
}

@book{wiegand2004analysis,
  title={An analysis of cooperative coevolutionary algorithms},
  author={Wiegand, Rudolf Paul},
  year={2004},
  publisher={George Mason University}
}

@article{kapetanakis2002reinforcement,
  title={Reinforcement learning of coordination in cooperative multi-agent systems},
  author={Kapetanakis, Spiros and Kudenko, Daniel},
  journal={AAAI/IAAI},
  volume={2002},
  pages={326--331},
  year={2002}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016},
  organization={PMLR}
}

@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}

@article{kuba2021trust,
  title={Trust region policy optimisation in multi-agent reinforcement learning},
  author={Kuba, Jakub Grudzien and Chen, Ruiqing and Wen, Muning and Wen, Ying and Sun, Fanglei and Wang, Jun and Yang, Yaodong},
  journal={arXiv preprint arXiv:2109.11251},
  year={2021}
}


@inproceedings{hamalainen2020ppo,
  title={PPO-CMA: Proximal policy optimization with covariance matrix adaptation},
  author={H{\"a}m{\"a}l{\"a}inen, Perttu and Babadi, Amin and Ma, Xiaoxiao and Lehtinen, Jaakko},
  booktitle={2020 IEEE 30th International Workshop on Machine Learning for Signal Processing (MLSP)},
  pages={1--6},
  year={2020},
  organization={IEEE}
}

@article{hansen2006cma,
  title={The CMA evolution strategy: a comparing review},
  author={Hansen, Nikolaus},
  journal={Towards a new evolutionary computation: Advances in the estimation of distribution algorithms},
  pages={75--102},
  year={2006},
  publisher={Springer}
}

@inproceedings{oh2018self,
  title={Self-imitation learning},
  author={Oh, Junhyuk and Guo, Yijie and Singh, Satinder and Lee, Honglak},
  booktitle={International Conference on Machine Learning},
  pages={3878--3887},
  year={2018},
  organization={PMLR}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{yu2023learning,
  title={Learning Zero-Shot Cooperation with Humans, Assuming Humans Are Biased},
  author={Yu, Chao and Gao, Jiaxuan and Liu, Weilin and Xu, Botian and Tang, Hao and Yang, Jiaqi and Wang, Yu and Wu, Yi},
  journal={arXiv preprint arXiv:2302.01605},
  year={2023}
}

@article{samvelyan2019starcraft,
  title={The starcraft multi-agent challenge},
  author={Samvelyan, Mikayel and Rashid, Tabish and De Witt, Christian Schroeder and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim GJ and Hung, Chia-Man and Torr, Philip HS and Foerster, Jakob and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1902.04043},
  year={2019}
}

@article{busoniu2008comprehensive,
  title={A comprehensive survey of multiagent reinforcement learning},
  author={Busoniu, Lucian and Babuska, Robert and De Schutter, Bart},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  volume={38},
  number={2},
  pages={156--172},
  year={2008},
  publisher={IEEE}
}

@article{vinyals2019grandmaster,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group UK London}
}

% RESP
@inproceedings{peters2010relative,
  title={Relative entropy policy search},
  author={Peters, Jan and Mulling, Katharina and Altun, Yasemin},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={24},
  pages={1607--1612},
  year={2010}
}


@article{terry2021pettingzoo,
  title={Pettingzoo: Gym for multi-agent reinforcement learning},
  author={Terry, J and Black, Benjamin and Grammel, Nathaniel and Jayakumar, Mario and Hari, Ananth and Sullivan, Ryan and Santos, Luis S and Dieffendahl, Clemens and Horsch, Caroline and Perez-Vicente, Rodrigo and others},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={15032--15043},
  year={2021}
}

@inproceedings{hu2023optimistic,
  title={Optimistic Thompson sampling-based algorithms for episodic reinforcement learning},
  author={Hu, Bingshan and Zhang, Tianyue H and Hegde, Nidhi and Schmidt, Mark},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={890--899},
  year={2023},
  organization={PMLR}
}

@article{russo2018tutorial,
  title={A tutorial on thompson sampling},
  author={Russo, Daniel J and Van Roy, Benjamin and Kazerouni, Abbas and Osband, Ian and Wen, Zheng and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={11},
  number={1},
  pages={1--96},
  year={2018},
  publisher={Now Publishers, Inc.}
}

@article{chapelle2011empirical,
  title={An empirical evaluation of thompson sampling},
  author={Chapelle, Olivier and Li, Lihong},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={Proceedings of the Nineteenth International Conference on Machine Learning},
  pages={267--274},
  year={2002}
}

@article{hu2021policy,
  title={Policy regularization via noisy advantage values for cooperative multi-agent actor-critic methods},
  author={Hu, Jian and Hu, Siyue and Liao, Shih-wei},
  journal={arXiv preprint arXiv:2106.14334},
  year={2021}
}


@article{mahajan2019maven,
  title={Maven: Multi-agent variational exploration},
  author={Mahajan, Anuj and Rashid, Tabish and Samvelyan, Mikayel and Whiteson, Shimon},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{jaques2019social,
  title={Social influence as intrinsic motivation for multi-agent deep reinforcement learning},
  author={Jaques, Natasha and Lazaridou, Angeliki and Hughes, Edward and Gulcehre, Caglar and Ortega, Pedro and Strouse, DJ and Leibo, Joel Z and De Freitas, Nando},
  booktitle={International conference on machine learning},
  pages={3040--3049},
  year={2019},
  organization={PMLR}
}

@article{li2022pmic,
  title={Pmic: Improving multi-agent reinforcement learning with progressive mutual information collaboration},
  author={Li, Pengyi and Tang, Hongyao and Yang, Tianpei and Hao, Xiaotian and Sang, Tong and Zheng, Yan and Hao, Jianye and Taylor, Matthew E and Tao, Wenyuan and Wang, Zhen and others},
  journal={arXiv preprint arXiv:2203.08553},
  year={2022}
}

@inproceedings{zhao2023conditionally,
  title={Conditionally optimistic exploration for cooperative deep multi-agent reinforcement learning},
  author={Zhao, Xutong and Pan, Yangchen and Xiao, Chenjun and Chandar, Sarath and Rajendran, Janarthanan},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={2529--2540},
  year={2023},
  organization={PMLR}
}

@inproceedings{liu2021cooperative,
  title={Cooperative exploration for multi-agent deep reinforcement learning},
  author={Liu, Iou-Jen and Jain, Unnat and Yeh, Raymond A and Schwing, Alexander},
  booktitle={International conference on machine learning},
  pages={6826--6836},
  year={2021},
  organization={PMLR}
}

@article{munos2014bandits,
  title={From bandits to monte-carlo tree search: The optimistic principle applied to optimization and planning},
  author={Munos, R{\'e}mi and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={7},
  number={1},
  pages={1--129},
  year={2014},
  publisher={Now Publishers, Inc.}
}

@article{imagawa2019optimistic,
  title={Optimistic proximal policy optimization},
  author={Imagawa, Takahisa and Hiraoka, Takuya and Tsuruoka, Yoshimasa},
  journal={arXiv preprint arXiv:1906.11075},
  year={2019}
}