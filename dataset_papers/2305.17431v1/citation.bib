@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@article{2020t5,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1-67},
  url     = {http://jmlr.org/papers/v21/20-074.html}
}

@inproceedings{song2017end,
  title={An end-to-end spatio-temporal attention model for human action recognition from skeleton data},
  author={Song, Sijie and Lan, Cuiling and Xing, Junliang and Zeng, Wenjun and Liu, Jiaying},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={31},
  number={1},
  year={2017}
}

@article{BarTal2022Text2LIVETL,
  title={Text2LIVE: Text-Driven Layered Image and Video Editing},
  author={Omer Bar-Tal and Dolev Ofri-Amar and Rafail Fridman and Yoni Kasten and Tali Dekel},
  journal={ArXiv},
  year={2022},
  volume={abs/2204.02491}
}


@article{Tzaban2022StitchII,
  title={Stitch it in Time: GAN-Based Facial Editing of Real Videos},
  author={Rotem Tzaban and Ron Mokady and Rinon Gal and Amit H. Bermano and Daniel Cohen-Or},
  journal={SIGGRAPH Asia 2022 Conference Papers},
  year={2022}
}
@article{yang2022Vtoonify,
  title={VToonify: Controllable High-Resolution Portrait Video Style Transfer},
  author={Yang, Shuai and Jiang, Liming and Liu, Ziwei and Loy, Chen Change},
  journal={ACM Transactions on Graphics (TOG)},
  volume={41},
  number={6},
  articleno={203},
  pages={1--15},
  year={2022},
  publisher={ACM New York, NY, USA},
  doi={10.1145/3550454.3555437},
}


@article{shin2023edit,
  title={Edit-A-Video: Single Video Editing with Object-Aware Consistency},
  author={Shin, Chaehun and Kim, Heeseung and Lee, Che Hyun and Lee, Sang-gil and Yoon, Sungroh},
  journal={arXiv preprint arXiv:2303.07945},
  year={2023}
}

@article{liu2023video,
  title={Video-P2P: Video Editing with Cross-attention Control},
  author={Liu, Shaoteng and Zhang, Yuechen and Li, Wenbo and Lin, Zhe and Jia, Jiaya},
  journal={arXiv preprint arXiv:2303.04761},
  year={2023}
}

@article{qi2023fatezero,
  title={FateZero: Fusing Attentions for Zero-shot Text-based Video Editing},
  author={Qi, Chenyang and Cun, Xiaodong and Zhang, Yong and Lei, Chenyang and Wang, Xintao and Shan, Ying and Chen, Qifeng},
  journal={arXiv preprint arXiv:2303.09535},
  year={2023}
}

@article{ceylan2023pix2video,
  title={Pix2Video: Video Editing using Image Diffusion},
  author={Ceylan, Duygu and Huang, Chun-Hao Paul and Mitra, Niloy J},
  journal={arXiv preprint arXiv:2303.12688},
  year={2023}
}


@article{bolya2022token,
  title={Token Merging: Your ViT But Faster},
  author={Bolya, Daniel and Fu, Cheng-Yang and Dai, Xiaoliang and Zhang, Peizhao and Feichtenhofer, Christoph and Hoffman, Judy},
  journal={arXiv preprint arXiv:2210.09461},
  year={2022}
}

@inproceedings{wang2021pyramid,
  title={Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={568--578},
  year={2021}
}

@article{ling2021editgan,
  title={Editgan: High-precision semantic image editing},
  author={Ling, Huan and Kreis, Karsten and Li, Daiqing and Kim, Seung Wook and Torralba, Antonio and Fidler, Sanja},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={16331--16345},
  year={2021}
}

@article{jing2019neural,
  title={Neural style transfer: A review},
  author={Jing, Yongcheng and Yang, Yezhou and Feng, Zunlei and Ye, Jingwen and Yu, Yizhou and Song, Mingli},
  journal={IEEE transactions on visualization and computer graphics},
  volume={26},
  number={11},
  pages={3365--3385},
  year={2019},
  publisher={IEEE}
}

@inproceedings{jing2018stroke,
  title={Stroke controllable fast style transfer with adaptive receptive fields},
  author={Jing, Yongcheng and Liu, Yang and Yang, Yezhou and Feng, Zunlei and Yu, Yizhou and Tao, Dacheng and Song, Mingli},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={238--254},
  year={2018}
}

@inproceedings{jing2022learning,
  title={Learning graph neural networks for image style transfer},
  author={Jing, Yongcheng and Mao, Yining and Yang, Yiding and Zhan, Yibing and Song, Mingli and Wang, Xinchao and Tao, Dacheng},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part VII},
  pages={111--128},
  year={2022},
  organization={Springer}
}

@inproceedings{jing2020dynamic,
  title={Dynamic instance normalization for arbitrary style transfer},
  author={Jing, Yongcheng and Liu, Xiao and Ding, Yukang and Wang, Xinchao and Ding, Errui and Song, Mingli and Wen, Shilei},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={4369--4376},
  year={2020}
}

@article{nichol2021glide,
  title={Glide: Towards photorealistic image generation and editing with text-guided diffusion models},
  author={Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
  journal={arXiv preprint arXiv:2112.10741},
  year={2021}
}

@inproceedings{saharia2022palette,
  title={Palette: Image-to-image diffusion models},
  author={Saharia, Chitwan and Chan, William and Chang, Huiwen and Lee, Chris and Ho, Jonathan and Salimans, Tim and Fleet, David and Norouzi, Mohammad},
  booktitle={ACM SIGGRAPH 2022 Conference Proceedings},
  pages={1--10},
  year={2022}
}

@inproceedings{bertasius2021space,
  title={Is space-time attention all you need for video understanding?},
  author={Bertasius, Gedas and Wang, Heng and Torresani, Lorenzo},
  booktitle={ICML},
  volume={2},
  number={3},
  pages={4},
  year={2021}
}

@article{ho2019axial,
  title={Axial attention in multidimensional transformers},
  author={Ho, Jonathan and Kalchbrenner, Nal and Weissenborn, Dirk and Salimans, Tim},
  journal={arXiv preprint arXiv:1912.12180},
  year={2019}
}

@inproceedings{arnab2021vivit,
  title={Vivit: A video vision transformer},
  author={Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lu{\v{c}}i{\'c}, Mario and Schmid, Cordelia},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6836--6846},
  year={2021}
}

@article{dhariwal2021diffusion,
  title={Diffusion models beat gans on image synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8780--8794},
  year={2021}
}

@inproceedings{3d-unet,
  title={3D U-Net: learning dense volumetric segmentation from sparse annotation},
  author={{\c{C}}i{\c{c}}ek, {\"O}zg{\"u}n and Abdulkadir, Ahmed and Lienkamp, Soeren S and Brox, Thomas and Ronneberger, Olaf},
  booktitle={Medical Image Computing and Computer-Assisted Intervention--MICCAI 2016: 19th International Conference, Athens, Greece, October 17-21, 2016, Proceedings, Part II 19},
  pages={424--432},
  year={2016},
  organization={Springer}
}

@inproceedings{Karras2019stylegan2,
  title     = {Analyzing and Improving the Image Quality of {StyleGAN}},
  author    = {Tero Karras and Samuli Laine and Miika Aittala and Janne Hellsten and Jaakko Lehtinen and Timo Aila},
  booktitle = {Proc. CVPR},
  year      = {2020}
}

@inproceedings{song2020improved,
  author    = {Yang Song and Stefano Ermon},
  editor    = {Hugo Larochelle and
               Marc'Aurelio Ranzato and
               Raia Hadsell and
               Maria{-}Florina Balcan and
               Hsuan{-}Tien Lin},
  title     = {Improved Techniques for Training Score-Based Generative Models},
  booktitle = {Advances in Neural Information Processing Systems 33: Annual Conference
               on Neural Information Processing Systems 2020, NeurIPS 2020, December
               6-12, 2020, virtual},
  year      = {2020}
}

@inproceedings{
  song2021scorebased,
  title={Score-Based Generative Modeling through Stochastic Differential Equations},
  author={Yang Song and Jascha Sohl-Dickstein and Diederik P Kingma and Abhishek Kumar and Stefano Ermon and Ben Poole},
  booktitle={International Conference on Learning Representations},
  year={2021},
  url={https://openreview.net/forum?id=PxTIG12RRHS}
}

@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}


% ========== REFERENCE ==========
@article{liu2023pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={ACM Computing Surveys},
  volume={55},
  number={9},
  pages={1--35},
  year={2023},
  publisher={ACM New York, NY}
}

@article{mokady2022null,
  title={Null-text Inversion for Editing Real Images using Guided Diffusion Models},
  author={Mokady, Ron and Hertz, Amir and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2211.09794},
  year={2022}
}

@article{tumanyan2022plug,
  title={Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation},
  author={Tumanyan, Narek and Geyer, Michal and Bagon, Shai and Dekel, Tali},
  journal={arXiv preprint arXiv:2211.12572},
  year={2022}
}

@article{parmar2023zero,
  title={Zero-shot Image-to-Image Translation},
  author={Parmar, Gaurav and Singh, Krishna Kumar and Zhang, Richard and Li, Yijun and Lu, Jingwan and Zhu, Jun-Yan},
  journal={arXiv preprint arXiv:2302.03027},
  year={2023}
}

@article{wu2022tune,
  title={Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation},
  author={Wu, Jay Zhangjie and Ge, Yixiao and Wang, Xintao and Lei, Weixian and Gu, Yuchao and Hsu, Wynne and Shan, Ying and Qie, Xiaohu and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2212.11565},
  year={2022}
}

@article{molad2023dreamix,
  title={Dreamix: Video Diffusion Models are General Video Editors},
  author={Molad, Eyal and Horwitz, Eliahu and Valevski, Dani and Acha, Alex Rav and Matias, Yossi and Pritch, Yael and Leviathan, Yaniv and Hoshen, Yedid},
  journal={arXiv preprint arXiv:2302.01329},
  year={2023}
}

@article{esser2023structure,
  title={Structure and Content-Guided Video Synthesis with Diffusion Models},
  author={Esser, Patrick and Chiu, Johnathan and Atighehchian, Parmida and Granskog, Jonathan and Germanidis, Anastasis},
  journal={arXiv preprint arXiv:2302.03011},
  year={2023}
}

@article{gur2020hierarchical,
  title={Hierarchical patch vae-gan: Generating diverse videos from a single sample},
  author={Gur, Shir and Benaim, Sagie and Wolf, Lior},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={16761--16772},
  year={2020}
}

@inproceedings{arora2021singan-gif,
  title={Singan-gif: Learning a generative video model from a single gif},
  author={Arora, Rajat and Lee, Yong Jae},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={1310--1319},
  year={2021}
}

@inproceedings{haim2022diverse,
  title={Diverse generation from a single video made possible},
  author={Haim, Niv and Feinstein, Ben and Granot, Niv and Shocher, Assaf and Bagon, Shai and Dekel, Tali and Irani, Michal},
  booktitle={European Conference on Computer Vision},
  pages={491--509},
  year={2022},
  organization={Springer}
}

@article{zhou2018non,
  title={Non-stationary texture synthesis by adversarial expansion},
  author={Zhou, Yang and Zhu, Zhen and Bai, Xiang and Lischinski, Dani and Cohen-Or, Daniel and Huang, Hui},
  journal={arXiv preprint arXiv:1805.04487},
  year={2018}
}

@inproceedings{shocher2018zero,
  title={“zero-shot” super-resolution using deep internal learning},
  author={Shocher, Assaf and Cohen, Nadav and Irani, Michal},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3118--3126},
  year={2018}
}

@article{liao2017visual,
  title={Visual attribute transfer through deep image analogy},
  author={Liao, Jing and Yao, Yuan and Yuan, Lu and Hua, Gang and Kang, Sing Bing},
  journal={arXiv preprint arXiv:1705.01088},
  year={2017}
}

@inproceedings{hertzmann2001image,
  title={Image analogies},
  author={Hertzmann, Aaron and Jacobs, Charles E and Oliver, Nuria and Curless, Brian and Salesin, David H},
  booktitle={Proceedings of the 28th annual conference on Computer graphics and interactive techniques},
  pages={327--340},
  year={2001}
}

@inproceedings{shaham2019singan,
  title={Singan: Learning a generative model from a single natural image},
  author={Shaham, Tamar Rott and Dekel, Tali and Michaeli, Tomer},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4570--4580},
  year={2019}
}

@inproceedings{benaim2021structural,
  title={Structural analogy from a single image pair},
  author={Benaim, Saguy and Mokady, Ron and Bermano, Amit and Wolf, Lior},
  booktitle={Computer Graphics Forum},
  volume={40},
  number={1},
  pages={249--265},
  year={2021},
  organization={Wiley Online Library}
}

@article{siarohin2019first,
  title={First order motion model for image animation},
  author={Siarohin, Aliaksandr and Lathuili{\`e}re, St{\'e}phane and Tulyakov, Sergey and Ricci, Elisa and Sebe, Nicu},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{siarohin2019animating,
  title={Animating arbitrary objects via deep motion transfer},
  author={Siarohin, Aliaksandr and Lathuili{\`e}re, St{\'e}phane and Tulyakov, Sergey and Ricci, Elisa and Sebe, Nicu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2377--2386},
  year={2019}
}

@inproceedings{ren2020human,
  title={Human motion transfer from poses in the wild},
  author={Ren, Jian and Chai, Menglei and Tulyakov, Sergey and Fang, Chen and Shen, Xiaohui and Yang, Jianchao},
  booktitle={European Conference on Computer Vision},
  pages={262--279},
  year={2020},
  organization={Springer}
}

@article{lee2019metapix,
  title={Metapix: Few-shot video retargeting},
  author={Lee, Jessica and Ramanan, Deva and Girdhar, Rohit},
  journal={arXiv preprint arXiv:1910.04742},
  year={2019}
}

@inproceedings{chan2019everybody,
  title={Everybody dance now},
  author={Chan, Caroline and Ginosar, Shiry and Zhou, Tinghui and Efros, Alexei A},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={5933--5942},
  year={2019}
}

@article{aberman2020unpaired,
  title={Unpaired motion style transfer from video to animation},
  author={Aberman, Kfir and Weng, Yijia and Lischinski, Dani and Cohen-Or, Daniel and Chen, Baoquan},
  journal={ACM Transactions on Graphics (TOG)},
  volume={39},
  number={4},
  pages={64--1},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{wang2019few,
  title={Few-shot video-to-video synthesis},
  author={Wang, Ting-Chun and Liu, Ming-Yu and Tao, Andrew and Liu, Guilin and Kautz, Jan and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1910.12713},
  year={2019}
}

@article{wang2018video,
  title={Video-to-video synthesis},
  author={Wang, Ting-Chun and Liu, Ming-Yu and Zhu, Jun-Yan and Liu, Guilin and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1808.06601},
  year={2018}
}

@inproceedings{mallya2020world,
  title={World-consistent video-to-video synthesis},
  author={Mallya, Arun and Wang, Ting-Chun and Sapra, Karan and Liu, Ming-Yu},
  booktitle={European Conference on Computer Vision},
  pages={359--378},
  year={2020},
  organization={Springer}
}

@inproceedings{blattmann2021ipoke,
  title={ipoke: Poking a still image for controlled stochastic video synthesis},
  author={Blattmann, Andreas and Milbich, Timo and Dorkenwald, Michael and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={14707--14717},
  year={2021}
}

@article{schuhmann2022laion,
  title={LAION-5B: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={arXiv preprint arXiv:2210.08402},
  year={2022}
}

@article{singer2022make,
  title={Make-a-video: Text-to-video generation without text-video data},
  author={Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and others},
  journal={arXiv preprint arXiv:2209.14792},
  year={2022}
}

@article{ho2022imagen,
  title={Imagen video: High definition video generation with diffusion models},
  author={Ho, Jonathan and Chan, William and Saharia, Chitwan and Whang, Jay and Gao, Ruiqi and Gritsenko, Alexey and Kingma, Diederik P and Poole, Ben and Norouzi, Mohammad and Fleet, David J and others},
  journal={arXiv preprint arXiv:2210.02303},
  year={2022}
}

@article{Khachatryan2023Text2VideoZeroTD,
  title={Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators},
  author={Levon Khachatryan and Andranik Movsisyan and Vahram Tadevosyan and Roberto Henschel and Zhangyang Wang and Shant Navasardyan and Humphrey Shi},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.13439}
}

@article{An2023LatentShiftLD,
  title={Latent-Shift: Latent Diffusion with Temporal Shift for Efficient Text-to-Video Generation},
  author={Jie An and Songyang Zhang and Harry Yang and Sonal Gupta and Jia-Bin Huang and Jiebo Luo and Xiaoyue Yin},
  journal={ArXiv},
  year={2023},
  volume={abs/2304.08477}
}

@article{ho2022video,
title={Video diffusion models},
author={Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J},
journal={arXiv:2204.03458},
year={2022}
}

@article{ge2022long,
  title={Long video generation with time-agnostic vqgan and time-sensitive transformer},
  author={Ge, Songwei and Hayes, Thomas and Yang, Harry and Yin, Xi and Pang, Guan and Jacobs, David and Huang, Jia-Bin and Parikh, Devi},
  journal={arXiv preprint arXiv:2204.03638},
  year={2022}
}

@article{hong2022cogvideo,
  title={CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers},
  author={Hong, Wenyi and Ding, Ming and Zheng, Wendi and Liu, Xinghan and Tang, Jie},
  journal={arXiv preprint arXiv:2205.15868},
  year={2022}
}


@misc{transformer,
  doi = {10.48550/ARXIV.1706.03762},
  
  url = {https://arxiv.org/abs/1706.03762},
  
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Attention Is All You Need},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{film,
  doi = {10.48550/ARXIV.2202.04901},
  
  url = {https://arxiv.org/abs/2202.04901},
  
  author = {Reda, Fitsum and Kontkanen, Janne and Tabellion, Eric and Sun, Deqing and Pantofaru, Caroline and Curless, Brian},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {FILM: Frame Interpolation for Large Motion},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{torresani,
  doi = {10.48550/ARXIV.2102.05095},
  
  url = {https://arxiv.org/abs/2102.05095},
  
  author = {Bertasius, Gedas and Wang, Heng and Torresani, Lorenzo},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Is Space-Time Attention All You Need for Video Understanding?},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{vivit,
  doi = {10.48550/ARXIV.2103.15691},
  
  url = {https://arxiv.org/abs/2103.15691},
  
  author = {Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lučić, Mario and Schmid, Cordelia},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {ViViT: A Video Vision Transformer},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{cascaded,
  doi = {10.48550/ARXIV.2106.15282},
  
  url = {https://arxiv.org/abs/2106.15282},
  
  author = {Ho, Jonathan and Saharia, Chitwan and Chan, William and Fleet, David J. and Norouzi, Mohammad and Salimans, Tim},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Cascaded Diffusion Models for High Fidelity Image Generation},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{nuwa,
  doi = {10.48550/ARXIV.2111.12417},
  
  url = {https://arxiv.org/abs/2111.12417},
  
  author = {Wu, Chenfei and Liang, Jian and Ji, Lei and Yang, Fan and Fang, Yuejian and Jiang, Daxin and Duan, Nan},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {NÜWA: Visual Synthesis Pre-training for Neural visUal World creAtion},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{ddpm,
  doi = {10.48550/ARXIV.2006.11239},
  
  url = {https://arxiv.org/abs/2006.11239},
  
  author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Denoising Diffusion Probabilistic Models},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{dpvg,
  doi = {10.48550/ARXIV.2203.09481},
  
  url = {https://arxiv.org/abs/2203.09481},
  
  author = {Yang, Ruihan and Srivastava, Prakhar and Mandt, Stephan},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Diffusion Probabilistic Modeling for Video Generation},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{clip,
  doi = {10.48550/ARXIV.2103.00020},
  
  url = {https://arxiv.org/abs/2103.00020},
  
  author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Learning Transferable Visual Models From Natural Language Supervision},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{gpt3,
  author    = {Tom B. Brown and
               Benjamin Mann and
               Nick Ryder and
               Melanie Subbiah and
               Jared Kaplan and
               Prafulla Dhariwal and
               Arvind Neelakantan and
               Pranav Shyam and
               Girish Sastry and
               Amanda Askell and
               Sandhini Agarwal and
               Ariel Herbert{-}Voss and
               Gretchen Krueger and
               Tom Henighan and
               Rewon Child and
               Aditya Ramesh and
               Daniel M. Ziegler and
               Jeffrey Wu and
               Clemens Winter and
               Christopher Hesse and
               Mark Chen and
               Eric Sigler and
               Mateusz Litwin and
               Scott Gray and
               Benjamin Chess and
               Jack Clark and
               Christopher Berner and
               Sam McCandlish and
               Alec Radford and
               Ilya Sutskever and
               Dario Amodei},
  title     = {Language Models are Few-Shot Learners},
  journal   = {CoRR},
  volume    = {abs/2005.14165},
  year      = {2020},
  url       = {https://arxiv.org/abs/2005.14165},
  eprinttype = {arXiv},
  eprint    = {2005.14165},
  timestamp = {Wed, 03 Jun 2020 11:36:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2005-14165.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@article{roberta,
  author    = {Yinhan Liu and
               Myle Ott and
               Naman Goyal and
               Jingfei Du and
               Mandar Joshi and
               Danqi Chen and
               Omer Levy and
               Mike Lewis and
               Luke Zettlemoyer and
               Veselin Stoyanov},
  title     = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
  journal   = {CoRR},
  volume    = {abs/1907.11692},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.11692},
  eprinttype = {arXiv},
  eprint    = {1907.11692},
  timestamp = {Thu, 01 Aug 2019 08:59:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-11692.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{actionsurvey,
author = {Guo, Guodong and Lai, Alice},
year = {2014},
month = {10},
pages = {3343–3361},
title = {A survey on still image based human action recognition},
volume = {47},
journal = {Pattern Recognition},
doi = {10.1016/j.patcog.2014.04.018}
}

@inproceedings{actionsurvey2,
author = {Girish, Deeptha and Singh, Vineeta and Ralescu, Anca},
year = {2020},
month = {06},
pages = {1523-1529},
title = {Understanding action recognition in still images},
doi = {10.1109/CVPRW50498.2020.00193}
}

@misc{makeascene,
  doi = {10.48550/ARXIV.2203.13131},
  
  url = {https://arxiv.org/abs/2203.13131},
  
  author = {Gafni, Oran and Polyak, Adam and Ashual, Oron and Sheynin, Shelly and Parikh, Devi and Taigman, Yaniv},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), Graphics (cs.GR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Make-A-Scene: Scene-Based Text-to-Image Generation with Human Priors},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{parti,
  doi = {10.48550/ARXIV.2206.10789},
  
  url = {https://arxiv.org/abs/2206.10789},
  
  author = {Yu, Jiahui and Xu, Yuanzhong and Koh, Jing Yu and Luong, Thang and Baid, Gunjan and Wang, Zirui and Vasudevan, Vijay and Ku, Alexander and Yang, Yinfei and Ayan, Burcu Karagol and Hutchinson, Ben and Han, Wei and Parekh, Zarana and Li, Xin and Zhang, Han and Baldridge, Jason and Wu, Yonghui},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Scaling Autoregressive Models for Content-Rich Text-to-Image Generation},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{imagen,
  doi = {10.48550/ARXIV.2205.11487},
  
  url = {https://arxiv.org/abs/2205.11487},
  
  author = {Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily and Ghasemipour, Seyed Kamyar Seyed and Ayan, Burcu Karagol and Mahdavi, S. Sara and Lopes, Rapha Gontijo and Salimans, Tim and Ho, Jonathan and Fleet, David J and Norouzi, Mohammad},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{dalle2,
  doi = {10.48550/ARXIV.2204.06125},
  
  url = {https://arxiv.org/abs/2204.06125},
  
  author = {Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Hierarchical Text-Conditional Image Generation with CLIP Latents},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{laion5b,
	title        = {{LAION-5B:} LAION-5B: A NEW ERA OF OPEN LARGE-SCALE MULTI-MODAL DATASETS},
	author       = {Christoph Schuhmann and Richard Vencu and Romain Beaumont and Theo Coombes and Cade Gordon and Aarush Katta and Robert Kaczmarczyk and Jenia Jitsev},
	year         = 2022,
	howpublished = {\url{https://laion.ai/laion-5b-a-new-era-of-open-large-scale-multi-modal-datasets/}}
}


@misc{VDM,
  doi = {10.48550/ARXIV.2204.03458},
  
  url = {https://arxiv.org/abs/2204.03458},
  
  author = {Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J.},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Video Diffusion Models},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{CogVideo,
  doi = {10.48550/ARXIV.2205.15868},
  
  url = {https://arxiv.org/abs/2205.15868},
  
  author = {Hong, Wenyi and Ding, Ming and Zheng, Wendi and Liu, Xinghan and Tang, Jie},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{bain2021frozen,
  title={Frozen in time: A joint video and image encoder for end-to-end retrieval},
  author={Bain, Max and Nagrani, Arsha and Varol, G{\"u}l and Zisserman, Andrew},
  booktitle={ICCV},
  pages={1728--1738},
  year={2021}
}


@article{clark2019adversarial,
  title={Adversarial video generation on complex datasets},
  author={Clark, Aidan and Donahue, Jeff and Simonyan, Karen},
  journal={arXiv preprint arXiv:1907.06571},
  year={2019}
}

@article{ding2022cogview2,
  title={CogView2: Faster and Better Text-to-Image Generation via Hierarchical Transformers},
  author={Ding, Ming and Zheng, Wendi and Hong, Wenyi and Tang, Jie},
  journal={arXiv preprint arXiv:2204.14217},
  year={2022}
}

@article{goodfellow2014generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={NIPS},
  year={2014}
}

@inproceedings{gupta2018imagine,
  title={Imagine this! scripts to compositions to videos},
  author={Gupta, Tanmay and Schwenk, Dustin and Farhadi, Ali and Hoiem, Derek and Kembhavi, Aniruddha},
  booktitle={ECCV},
  pages={598--613},
  year={2018}
}

@inproceedings{gu2022vector,
  title={Vector quantized diffusion model for text-to-image synthesis},
  author={Gu, Shuyang and Chen, Dong and Bao, Jianmin and Wen, Fang and Zhang, Bo and Chen, Dongdong and Yuan, Lu and Guo, Baining},
  booktitle={CVPR},
  pages={10696--10706},
  year={2022}
}

@article{hayes2022mugen,
  title={MUGEN: A Playground for Video-Audio-Text Multimodal Understanding and GENeration},
  author={Hayes, Thomas and Zhang, Songyang and Yin, Xi and Pang, Guan and Sheng, Sasha and Yang, Harry and Ge, Songwei and Hu, Isabelle and Parikh, Devi},
  journal={ECCV},
  year={2022}
}

@inproceedings{hong2018inferring,
  title={Inferring semantic layout for hierarchical text-to-image synthesis},
  author={Hong, Seunghoon and Yang, Dingdong and Choi, Jongwook and Lee, Honglak},
  booktitle={CVPR},
  pages={7986--7994},
  year={2018}
}

@inproceedings{li2018video,
  title={Video generation from text},
  author={Li, Yitong and Min, Martin and Shen, Dinghan and Carlson, David and Carin, Lawrence},
  booktitle={AAAI},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{liu2019cross,
  title={Cross-modal dual learning for sentence-to-video generation},
  author={Liu, Yue and Wang, Xin and Yuan, Yitian and Zhu, Wenwu},
  booktitle={Proceedings of the 27th ACM International Conference on Multimedia},
  pages={1239--1247},
  year={2019}
}

@inproceedings{marwah2017attentive,
  title={Attentive semantic video generation using captions},
  author={Marwah, Tanya and Mittal, Gaurav and Balasubramanian, Vineeth N},
  booktitle={ICCV},
  pages={1426--1434},
  year={2017}
}

@inproceedings{mittal2017sync,
  title={Sync-draw: Automatic video generation using deep recurrent attentive architectures},
  author={Mittal, Gaurav and Marwah, Tanya and Balasubramanian, Vineeth N},
  booktitle={Proceedings of the 25th ACM international conference on Multimedia},
  pages={1096--1104},
  year={2017}
}
@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

@article{kingma2021variational,
  title={Variational diffusion models},
  author={Kingma, Diederik and Salimans, Tim and Poole, Ben and Ho, Jonathan},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={21696--21707},
  year={2021}
}

@inproceedings{pan2017create,
  title={To create what you tell: Generating videos from captions},
  author={Pan, Yingwei and Qiu, Zhaofan and Yao, Ting and Li, Houqiang and Mei, Tao},
  booktitle={Proceedings of the 25th ACM international conference on Multimedia},
  pages={1789--1798},
  year={2017}
}

@inproceedings{parmar2021cleanfid,
  title={On Aliased Resizing and Surprising Subtleties in GAN Evaluation},
  author={Parmar, Gaurav and Zhang, Richard and Zhu, Jun-Yan},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{qiu2017learning,
  title={Learning spatio-temporal representation with pseudo-3d residual networks},
  author={Qiu, Zhaofan and Yao, Ting and Mei, Tao},
  booktitle={ICCV},
  pages={5533--5541},
  year={2017}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={ICML},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}

@article{reda2022film,
  title={FILM: Frame Interpolation for Large Motion},
  author={Reda, Fitsum and Kontkanen, Janne and Tabellion, Eric and Sun, Deqing and Pantofaru, Caroline and Curless, Brian},
  journal={arXiv preprint arXiv:2202.04901},
  year={2022}
}

@inproceedings{reed2016generative,
  title={Generative adversarial text to image synthesis},
  author={Reed, Scott and Akata, Zeynep and Yan, Xinchen and Logeswaran, Lajanugen and Schiele, Bernt and Lee, Honglak},
  booktitle={ICML},
  pages={1060--1069},
  year={2016},
  organization={PMLR}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={CVPR},
  pages={10684--10695},
  year={2022}
}

@article{saito2020train,
  title={Train sparsely, generate densely: Memory-efficient unsupervised training of high-resolution temporal gan},
  author={Saito, Masaki and Saito, Shunta and Koyama, Masanori and Kobayashi, Sosuke},
  journal={International Journal of Computer Vision},
  volume={128},
  number={10},
  pages={2586--2606},
  year={2020},
  publisher={Springer}
}

@article{schuhmannlaion,
  title={LAION-5B: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Gordon, Cade W and Wightman, Ross and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Schramowski, Patrick and Kundurthy, Srivatsa R and Crowson, Katherine and others}
}

@article{soomro2012ucf101,
  title={UCF101: A dataset of 101 human actions classes from videos in the wild},
  author={Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
  journal={arXiv preprint arXiv:1212.0402},
  year={2012}
}

@article{tian2021good,
  title={A good image generator is what you need for high-resolution video synthesis},
  author={Tian, Yu and Ren, Jian and Chai, Menglei and Olszewski, Kyle and Peng, Xi and Metaxas, Dimitris N and Tulyakov, Sergey},
  journal={ICLR},
  year={2021}
}



@article{voleti2022mcvd,
  title={MCVD: Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation},
  author={Voleti, Vikram and Jolicoeur-Martineau, Alexia and Pal, Christopher},
  journal={NeurIPS},
  year={2022}
}

@article{wu2021godiva,
  title={Godiva: Generating open-domain videos from natural descriptions},
  author={Wu, Chenfei and Huang, Lun and Zhang, Qianxi and Li, Binyang and Ji, Lei and Yang, Fan and Sapiro, Guillermo and Duan, Nan},
  journal={arXiv preprint arXiv:2104.14806},
  year={2021}
}

@inproceedings{xie2018rethinking,
  title={Rethinking spatiotemporal feature learning: Speed-accuracy trade-offs in video classification},
  author={Xie, Saining and Sun, Chen and Huang, Jonathan and Tu, Zhuowen and Murphy, Kevin},
  booktitle={ECCV},
  pages={305--321},
  year={2018}
}

@inproceedings{xu2016msr,
  title={Msr-vtt: A large video description dataset for bridging video and language},
  author={Xu, Jun and Mei, Tao and Yao, Ting and Rui, Yong},
  booktitle={CVPR},
  pages={5288--5296},
  year={2016}
}

@inproceedings{xu2018attngan,
  title={Attngan: Fine-grained text to image generation with attentional generative adversarial networks},
  author={Xu, Tao and Zhang, Pengchuan and Huang, Qiuyuan and Zhang, Han and Gan, Zhe and Huang, Xiaolei and He, Xiaodong},
  booktitle={CVPR},
  pages={1316--1324},
  year={2018}
}

@inproceedings{xue2022advancing,
  title={Advancing High-Resolution Video-Language Representation with Large-Scale Video Transcriptions},
  author={Xue, Hongwei and Hang, Tiankai and Zeng, Yanhong and Sun, Yuchong and Liu, Bei and Yang, Huan and Fu, Jianlong and Guo, Baining},
  booktitle={CVPR},
  pages={5036--5045},
  year={2022}
}

@article{yan2021videogpt,
  title={Videogpt: Video generation using vq-vae and transformers},
  author={Yan, Wilson and Zhang, Yunzhi and Abbeel, Pieter and Srinivas, Aravind},
  journal={arXiv preprint arXiv:2104.10157},
  year={2021}
}

@inproceedings{ye20193d,
  title={3D depthwise convolution: Reducing model parameters in 3D vision tasks},
  author={Ye, Rongtian and Liu, Fangyu and Zhang, Liqiang},
  booktitle={Canadian Conference on Artificial Intelligence},
  pages={186--199},
  year={2019},
  organization={Springer}
}

@article{yu2021vector,
  title={Vector-quantized image modeling with improved vqgan},
  author={Yu, Jiahui and Li, Xin and Koh, Jing Yu and Zhang, Han and Pang, Ruoming and Qin, James and Ku, Alexander and Xu, Yuanzhong and Baldridge, Jason and Wu, Yonghui},
  journal={arXiv preprint arXiv:2110.04627},
  year={2021}
}

@article{yu2022generating,
  title={Generating videos with dynamics-aware implicit generative adversarial networks},
  author={Yu, Sihyun and Tack, Jihoon and Mo, Sangwoo and Kim, Hyunsu and Kim, Junho and Ha, Jung-Woo and Shin, Jinwoo},
  journal={ICLR},
  year={2022}
}

@inproceedings{zhang2017stackgan,
  title={Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks},
  author={Zhang, Han and Xu, Tao and Li, Hongsheng and Zhang, Shaoting and Wang, Xiaogang and Huang, Xiaolei and Metaxas, Dimitris N},
  booktitle={ICCV},
  pages={5907--5915},
  year={2017}
}

@inproceedings{zhang2021cross,
  title={Cross-modal contrastive learning for text-to-image generation},
  author={Zhang, Han and Koh, Jing Yu and Baldridge, Jason and Lee, Honglak and Yang, Yinfei},
  booktitle={CVPR},
  pages={833--842},
  year={2021}
}


@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={International Conference on Medical image computing and computer-assisted intervention},
  pages={234--241},
  year={2015},
  organization={Springer}
}
@inproceedings{chollet2017xception,
  title={Xception: Deep learning with depthwise separable convolutions},
  author={Chollet, Fran{\c{c}}ois},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1251--1258},
  year={2017}
}

@inproceedings{vqvae,
  title={Neural Discrete Representation Learning},
  author={Aaron van den Oord and Oriol Vinyals and Koray Kavukcuoglu},
  booktitle={NeurIPS},
  year={2018},
}

@article{villegas2022phenaki,
  title={Phenaki: Variable length video generation from open domain textual description},
  author={Villegas, Ruben and Babaeizadeh, Mohammad and Kindermans, Pieter-Jan and Moraldo, Hernan and Zhang, Han and Saffar, Mohammad Taghi and Castro, Santiago and Kunze, Julius and Erhan, Dumitru},
  journal={arXiv preprint arXiv:2210.02399},
  year={2022}
}


@inproceedings{lake2011one,
  title={One shot learning of simple visual concepts},
  author={Lake, Brenden and Salakhutdinov, Ruslan and Gross, Jason and Tenenbaum, Joshua},
  booktitle={Proceedings of the annual meeting of the cognitive science society},
  volume={33},
  number={33},
  year={2011}
}

@article{lake2013one,
  title={One-shot learning by inverting a compositional causal process},
  author={Lake, Brenden M and Salakhutdinov, Russ R and Tenenbaum, Josh},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}

@InProceedings{Bain21,
  author       = "Max Bain and Arsha Nagrani and G{\"u}l Varol and Andrew Zisserman",
  title        = "Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval",
  booktitle    = "IEEE International Conference on Computer Vision",
  year         = "2021",
}

@article{hertz2022prompt,
  title={Prompt-to-prompt image editing with cross attention control},
  author={Hertz, Amir and Mokady, Ron and Tenenbaum, Jay and Aberman, Kfir and Pritch, Yael and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2208.01626},
  year={2022}
}

@article{gal2022image,
  title={An image is worth one word: Personalizing text-to-image generation using textual inversion},
  author={Gal, Rinon and Alaluf, Yuval and Atzmon, Yuval and Patashnik, Or and Bermano, Amit H and Chechik, Gal and Cohen-Or, Daniel},
  journal={arXiv preprint arXiv:2208.01618},
  year={2022}
}

@article{couairon2022diffedit,
  title={DiffEdit: Diffusion-based semantic image editing with mask guidance},
  author={Couairon, Guillaume and Verbeek, Jakob and Schwenk, Holger and Cord, Matthieu},
  journal={arXiv preprint arXiv:2210.11427},
  year={2022}
}

@article{kawar2022imagic,
  title={Imagic: Text-Based Real Image Editing with Diffusion Models},
  author={Kawar, Bahjat and Zada, Shiran and Lang, Oran and Tov, Omer and Chang, Huiwen and Dekel, Tali and Mosseri, Inbar and Irani, Michal},
  journal={arXiv preprint arXiv:2210.09276},
  year={2022}
}

@article{wu2022unifying,
  title={Unifying Diffusion Models' Latent Space, with Applications to CycleDiffusion and Guidance},
  author={Wu, Chen Henry and De la Torre, Fernando},
  journal={arXiv preprint arXiv:2210.05559},
  year={2022}
}

@article{liew2022magicmix,
  title={MagicMix: Semantic Mixing with Diffusion Models},
  author={Liew, Jun Hao and Yan, Hanshu and Zhou, Daquan and Feng, Jiashi},
  journal={arXiv preprint arXiv:2210.16056},
  year={2022}
}

@inproceedings{esser2021taming,
  title={Taming transformers for high-resolution image synthesis},
  author={Esser, Patrick and Rombach, Robin and Ommer, Bjorn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12873--12883},
  year={2021}
}
@inproceedings{alaluf2021restyle,
  title={Restyle: A residual-based stylegan encoder via iterative refinement},
  author={Alaluf, Yuval and Patashnik, Or and Cohen-Or, Daniel},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={6711--6720},
  year={2021}
}
@inproceedings{richardson2021encoding,
  title={Encoding in style: a stylegan encoder for image-to-image translation},
  author={Richardson, Elad and Alaluf, Yuval and Patashnik, Or and Nitzan, Yotam and Azar, Yaniv and Shapiro, Stav and Cohen-Or, Daniel},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2287--2296},
  year={2021}
}
@article{tov2021designing,
  title={Designing an encoder for stylegan image manipulation},
  author={Tov, Omer and Alaluf, Yuval and Nitzan, Yotam and Patashnik, Or and Cohen-Or, Daniel},
  journal={ACM Transactions on Graphics (TOG)},
  volume={40},
  number={4},
  pages={1--14},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{van2017neural,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{saharia2022photorealistic,
  title={Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily and Ghasemipour, Seyed Kamyar Seyed and Ayan, Burcu Karagol and Mahdavi, S Sara and Lopes, Rapha Gontijo and others},
  journal={arXiv preprint arXiv:2205.11487},
  year={2022}
}

@article{hessel2021clipscore,
  title={Clipscore: A reference-free evaluation metric for image captioning},
  author={Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Bras, Ronan Le and Choi, Yejin},
  journal={arXiv preprint arXiv:2104.08718},
  year={2021}
}

@inproceedings{park2021benchmark,
  title={Benchmark for compositional text-to-image synthesis},
  author={Park, Dong Huk and Azadi, Samaneh and Liu, Xihui and Darrell, Trevor and Rohrbach, Anna},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)},
  year={2021}
}

@inproceedings{huang2022real,
  title={Real-time intermediate flow estimation for video frame interpolation},
  author={Huang, Zhewei and Zhang, Tianyuan and Heng, Wen and Shi, Boxin and Zhou, Shuchang},
  booktitle={European Conference on Computer Vision},
  pages={624--642},
  year={2022},
  organization={Springer}
}

@inproceedings{bao2019depth,
  title={Depth-aware video frame interpolation},
  author={Bao, Wenbo and Lai, Wei-Sheng and Ma, Chao and Zhang, Xiaoyun and Gao, Zhiyong and Yang, Ming-Hsuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3703--3712},
  year={2019}
}

@article{nikankin2022sinfusion,
  title={SinFusion: Training Diffusion Models on a Single Image or Video},
  author={Nikankin, Yaniv and Haim, Niv and Irani, Michal},
  journal={arXiv preprint arXiv:2211.11743},
  year={2022}
}

@article{zhou2022magicvideo,
  title={MagicVideo: Efficient Video Generation With Latent Diffusion Models},
  author={Zhou, Daquan and Wang, Weimin and Yan, Hanshu and Lv, Weiwei and Zhu, Yizhe and Feng, Jiashi},
  journal={arXiv preprint arXiv:2211.11018},
  year={2022}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@inproceedings{wang2017multi,
  title={Multi-attention network for one shot learning},
  author={Wang, Peng and Liu, Lingqiao and Shen, Chunhua and Huang, Zi and Van Den Hengel, Anton and Tao Shen, Heng},
  booktitle={proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2721--2729},
  year={2017}
}

@article{song2020denoising,
  title={Denoising diffusion implicit models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  journal={arXiv preprint arXiv:2010.02502},
  year={2020}
}

@article{ho2022classifier,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint arXiv:2207.12598},
  year={2022}
}

@article{ruiz2022dreambooth,
  title={Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation},
  author={Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},
  journal={arXiv preprint arXiv:2208.12242},
  year={2022}
}

@inproceedings{
villegas2023phenaki,
title={Phenaki: Variable Length Video Generation from Open Domain Textual Descriptions},
author={Ruben Villegas and Mohammad Babaeizadeh and Pieter-Jan Kindermans and Hernan Moraldo and Han Zhang and Mohammad Taghi Saffar and Santiago Castro and Julius Kunze and Dumitru Erhan},
booktitle={ICLR},
year={2023},
}

@inproceedings{wu2022nuwa,
 author = {Wu, Chenfei and Liang, Jian and Ji, Lei and Yang, Fan and Fang, Yuejian and Jiang, Daxin and Duan, Nan},
 booktitle = {ECCV},
 title = {N{\"u}WA: Visual synthesis pre-training for neural visual world creation},
 year = {2022}
}

@article{Blattmann2023AlignYL,
  title={Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models},
  author={A. Blattmann and Robin Rombach and Huan Ling and Tim Dockhorn and Seung Wook Kim and Sanja Fidler and Karsten Kreis},
  journal={ArXiv},
  year={2023},
  volume={abs/2304.08818}
}
@article{brooks2022instructpix2pix,
  title={Instructpix2pix: Learning to follow image editing instructions},
  author={Brooks, Tim and Holynski, Aleksander and Efros, Alexei A},
  journal={arXiv preprint arXiv:2211.09800},
  year={2022}
}
@article{kumari2022multi,
  title={Multi-Concept Customization of Text-to-Image Diffusion},
  author={Kumari, Nupur and Zhang, Bingliang and Zhang, Richard and Shechtman, Eli and Zhu, Jun-Yan},
  journal={arXiv preprint arXiv:2212.04488},
  year={2022}
}

@article{Wang2023ZeroShotVE,
  title={Zero-Shot Video Editing Using Off-The-Shelf Image Diffusion Models},
  author={Wen Wang and Kan Xie and Zide Liu and Hao Chen and Yue Cao and Xinlong Wang and Chunhua Shen},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.17599}
}

@inproceedings{bn,
  title = 	 {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author = 	 {Ioffe, Sergey and Szegedy, Christian},
  booktitle = 	 {ICML},
  year = 	 {2015}
}

@article{layernorm,
  title={Layer Normalization},
  author={Jimmy Ba and Jamie Ryan Kiros and Geoffrey E. Hinton},
  journal={ArXiv},
  year={2016},
  volume={abs/1607.06450}
}


@article{InstanceNT,
  title={Instance Normalization: The Missing Ingredient for Fast Stylization},
  author={Dmitry Ulyanov and Andrea Vedaldi and Victor S. Lempitsky},
  journal={ArXiv},
  year={2016},
  volume={abs/1607.08022}
}
@article{davis,
  title={The 2017 davis challenge on video object segmentation},
  author={Pont-Tuset, Jordi and Perazzi, Federico and Caelles, Sergi and Arbel{\'a}ez, Pablo and Sorkine-Hornung, Alex and Van Gool, Luc},
  journal={arXiv preprint arXiv:1704.00675},
  year={2017}
}

@article{Li2023BLIP2BL,
  title={BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models},
  author={Junnan Li and Dongxu Li and Silvio Savarese and Steven Hoi},
  journal={ArXiv},
  year={2023},
  volume={abs/2301.12597}
}

@article{Miyato2018SpectralNF,
  title={Spectral Normalization for Generative Adversarial Networks},
  author={Takeru Miyato and Toshiki Kataoka and Masanori Koyama and Yuichi Yoshida},
  journal={ArXiv},
  year={2018},
  volume={abs/1802.05957}
}
@inproceedings{Salimans2016WeightNA,
  title={Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks},
  author={Tim Salimans and Diederik P. Kingma},
  booktitle={NIPS},
  year={2016}
}
@article{Kingma2013AutoEncodingVB,
  title={Auto-Encoding Variational Bayes},
  author={Diederik P. Kingma and Max Welling},
  journal={CoRR},
  year={2013},
  volume={abs/1312.6114}
}
@article{Hu2021MakeIM,
  title={Make It Move: Controllable Image-to-Video Generation with Text Descriptions},
  author={Yaosi Hu and Chong Luo and Zhenzhong Chen},
  journal={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021},
  pages={18198-18207}
}
@article{softmax,
  title={On the Properties of the Softmax Function with Application in Game Theory and Reinforcement Learning},
  author={Bolin Gao and Lacra Pavel},
  journal={ArXiv},
  year={2017},
  volume={abs/1704.00805}
}