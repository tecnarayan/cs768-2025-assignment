\begin{thebibliography}{141}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abboud et~al.(2020)Abboud, Ceylan, Grohe, and Lukasiewicz]{Abb+2020}
R.~Abboud, I.~I. Ceylan, M.~Grohe, and T.~Lukasiewicz.
\newblock The surprising power of graph neural networks with random node initialization.
\newblock \emph{arXiv preprint}, 2020.

\bibitem[Abboud et~al.(2022)Abboud, Dimitrov, and Ceylan]{Abboud2022-sl}
R.~Abboud, R.~Dimitrov, and I.~I. Ceylan.
\newblock Shortest path networks for graph property prediction.
\newblock In \emph{Learning on Graphs Conference}, 2022.

\bibitem[Abu-El-Haija et~al.(2019)Abu-El-Haija, Perozzi, Kapoor, Alipourfard, Lerman, Harutyunyan, Ver~Steeg, and Galstyan]{Hai+2019}
S.~Abu-El-Haija, B.~Perozzi, A.~Kapoor, N.~Alipourfard, K.~Lerman, H.~Harutyunyan, G.~Ver~Steeg, and A.~Galstyan.
\newblock Mixhop: Higher-order graph convolutional architectures via sparsified neighborhood mixing.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Ahmed et~al.(2023)Ahmed, Zeng, Niepert, and Van~den Broeck]{ahmed2022simple}
K.~Ahmed, Z.~Zeng, M.~Niepert, and G.~Van~den Broeck.
\newblock Simple: A gradient estimator for k-subset sampling.
\newblock In \emph{International Conference on Learning Representations}, 2023.

\bibitem[Alon and Yahav(2021)]{Alon2020}
U.~Alon and E.~Yahav.
\newblock On the bottleneck of graph neural networks and its practical implications.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Arnaiz-Rodr{\'\i}guez et~al.(2022)Arnaiz-Rodr{\'\i}guez, Begga, Escolano, and Oliver]{arnaiz2022diffwire}
A.~Arnaiz-Rodr{\'\i}guez, A.~Begga, F.~Escolano, and N.~Oliver.
\newblock Diffwire: Inductive graph rewiring via the lovasz bound.
\newblock \emph{arXiv preprint}, 2022.

\bibitem[Arvind et~al.(2015)Arvind, K{\"{o}}bler, Rattan, and Verbitsky]{Arv+2015}
V.~Arvind, J.~K{\"{o}}bler, G.~Rattan, and O.~Verbitsky.
\newblock On the power of color refinement.
\newblock In \emph{International Symposium on Fundamentals of Computation Theory}, 2015.

\bibitem[Babai and Kucera(1979)]{Bab+1979}
L.~Babai and L.~Kucera.
\newblock Canonical labelling of graphs in linear average time.
\newblock In \emph{Annual Symposium on Foundations of Computer Science (sfcs 1979)}, 1979.

\bibitem[Babai et~al.(1980)Babai, Erdos, and Selkow]{Bab+1980}
L.~Babai, P.~Erdos, and S.~M. Selkow.
\newblock Random graph isomorphism.
\newblock \emph{SIAM Journal on computing}, 9\penalty0 (3):\penalty0 628--635, 1980.

\bibitem[Banerjee et~al.(2022)Banerjee, Karhadkar, Wang, Alon, and Mont{\'u}far]{Banerjee2022-yd}
P.~K. Banerjee, K.~Karhadkar, Y.~G. Wang, U.~Alon, and G.~Mont{\'u}far.
\newblock Oversquashing in gnns through the lens of information contraction and graph expansion.
\newblock In \emph{Annual Allerton Conference on Communication, Control, and Computing (Allerton)}, 2022.

\bibitem[Barbero et~al.(2023)Barbero, Velingker, Saberi, Bronstein, and Di~Giovanni]{barbero2023locality}
F.~Barbero, A.~Velingker, A.~Saberi, M.~Bronstein, and F.~Di~Giovanni.
\newblock Locality-aware graph-rewiring in gnns.
\newblock \emph{arXiv preprint}, 2023.

\bibitem[Barceló et~al.(2020)Barceló, Kostylev, Monet, Pérez, Reutter, and Silva]{Barceló2020The}
P.~Barceló, E.~V. Kostylev, M.~Monet, J.~Pérez, J.~Reutter, and J.~P. Silva.
\newblock The logical expressiveness of graph neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Baskin et~al.(1997)Baskin, Palyulin, and Zefirov]{bas+1997}
I.~I. Baskin, V.~A. Palyulin, and N.~S. Zefirov.
\newblock A neural device for searching direct correlations between structures and properties of chemical compounds.
\newblock \emph{Journal of Chemical Information and Computer Sciences}, 37\penalty0 (4):\penalty0 715--721, 1997.

\bibitem[Battaglia et~al.(2018)Battaglia, Hamrick, Bapst, Sanchez-Gonzalez, Zambaldi, Malinowski, Tacchetti, Raposo, Santoro, Faulkner, et~al.]{battaglia2018relational}
P.~W. Battaglia, J.~B. Hamrick, V.~Bapst, A.~Sanchez-Gonzalez, V.~Zambaldi, M.~Malinowski, A.~Tacchetti, D.~Raposo, A.~Santoro, R.~Faulkner, et~al.
\newblock Relational inductive biases, deep learning, and graph networks.
\newblock \emph{arXiv preprint}, 2018.

\bibitem[Black et~al.(2023)Black, Wan, Nayyeri, and Wang]{black2023understanding}
M.~Black, Z.~Wan, A.~Nayyeri, and Y.~Wang.
\newblock Understanding oversquashing in gnns through the lens of effective resistance.
\newblock In \emph{International Conference on Machine Learning}, 2023.

\bibitem[Bober et~al.(2022)Bober, Monod, Saucan, and Webster]{Bober2022-md}
J.~Bober, A.~Monod, E.~Saucan, and K.~N. Webster.
\newblock Rewiring networks for graph neural network training using discrete geometry.
\newblock \emph{arXiv preprint}, 2022.

\bibitem[Bodnar et~al.(2021)Bodnar, Frasca, Wang, Otter, Montufar, Lio, and Bronstein]{Bod+2021}
C.~Bodnar, F.~Frasca, Y.~Wang, N.~Otter, G.~F. Montufar, P.~Lio, and M.~Bronstein.
\newblock {W}eisfeiler and {L}ehman go topological: Message passing simplicial networks.
\newblock In \emph{International Conference on Machine Learning}, 2021.

\bibitem[Bouritsas et~al.(2022)Bouritsas, Frasca, Zafeiriou, and Bronstein]{botsas2020improving}
G.~Bouritsas, F.~Frasca, S.~Zafeiriou, and M.~M. Bronstein.
\newblock Improving graph neural network expressivity via subgraph isomorphism counting.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 45\penalty0 (1):\penalty0 657--668, 2022.

\bibitem[Br{\"u}el-Gabrielsson et~al.(2022)Br{\"u}el-Gabrielsson, Yurochkin, and Solomon]{bruel2022rewiring}
R.~Br{\"u}el-Gabrielsson, M.~Yurochkin, and J.~Solomon.
\newblock Rewiring with positional encodings for graph neural networks.
\newblock \emph{arXiv preprint}, 2022.

\bibitem[Bruna et~al.(2014)Bruna, Zaremba, Szlam, and LeCun]{Bru+2014}
J.~Bruna, W.~Zaremba, A.~Szlam, and Y.~LeCun.
\newblock Spectral networks and deep locally connected networks on graphs.
\newblock In \emph{International Conference on Learning Representation}, 2014.

\bibitem[Böker et~al.(2023)Böker, Levie, Huang, Villar, and Morris]{Boe+2023}
J.~Böker, R.~Levie, N.~Huang, S.~Villar, and C.~Morris.
\newblock Fine-grained expressivity of graph neural networks.
\newblock In \emph{NeurIPS}, 2023.

\bibitem[Cai et~al.(2023)Cai, Hy, Yu, and Wang]{cai2023connection}
C.~Cai, T.~S. Hy, R.~Yu, and Y.~Wang.
\newblock On the connection between {MPNN} and graph transformer.
\newblock \emph{arXiv preprint}, 2023.

\bibitem[Cai et~al.(1992)Cai, F{\"u}rer, and Immerman]{Cai+1992}
J.-Y. Cai, M.~F{\"u}rer, and N.~Immerman.
\newblock An optimal lower bound on the number of variables for graph identification.
\newblock \emph{Combinatorica}, 12\penalty0 (4):\penalty0 389--410, 1992.

\bibitem[Cappart et~al.(2023)Cappart, Ch{\'{e}}telat, Khalil, Lodi, Morris, and Veli\v{c}kovi\'{c}]{Cap+2023}
Q.~Cappart, D.~Ch{\'{e}}telat, E.~B. Khalil, A.~Lodi, C.~Morris, and P.~Veli\v{c}kovi\'{c}.
\newblock Combinatorial optimization and reasoning with graph neural networks.
\newblock \emph{Journal of Machine Learning Research}, 24\penalty0 (130):\penalty0 1--61, 2023.

\bibitem[Chen et~al.(2022{\natexlab{a}})Chen, O’Bray, and Borgwardt]{Chen22a}
D.~Chen, L.~O’Bray, and K.~Borgwardt.
\newblock Structure-aware transformer for graph representation learning.
\newblock In \emph{International Conference on Machine Learning}, 2022{\natexlab{a}}.

\bibitem[Chen et~al.(2022{\natexlab{b}})Chen, Gao, Li, and He]{chen2022nagphormer}
J.~Chen, K.~Gao, G.~Li, and K.~He.
\newblock Nagphormer: A tokenized graph transformer for node classification in large graphs.
\newblock \emph{arXiv preprint}, 2022{\natexlab{b}}.

\bibitem[Chen et~al.(2020)Chen, Wu, and Zaki]{chen2020iterative}
Y.~Chen, L.~Wu, and M.~Zaki.
\newblock Iterative deep graph learning for graph neural networks: Better and robust node embeddings.
\newblock \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Craven et~al.(1998)Craven, DiPasquo, Freitag, McCallum, Mitchell, Nigam, and Slattery]{webkb1998}
M.~Craven, D.~DiPasquo, D.~Freitag, A.~McCallum, T.~Mitchell, K.~Nigam, and S.~Slattery.
\newblock Learning to extract symbolic knowledge from the world wide web.
\newblock \emph{AAAI/IAAI}, 3\penalty0 (3.6):\penalty0 2, 1998.

\bibitem[de~Haan et~al.(2020)de~Haan, Cohen, and Welling]{de2020natural}
P.~de~Haan, T.~S. Cohen, and M.~Welling.
\newblock Natural graph networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Deac et~al.(2022)Deac, Lackenby, and Veli{\v{c}}kovi{\'c}]{Deac2022-lu}
A.~Deac, M.~Lackenby, and P.~Veli{\v{c}}kovi{\'c}.
\newblock Expander graph propagation.
\newblock In \emph{Learning on Graphs Conference}, 2022.

\bibitem[Defferrard et~al.(2016)Defferrard, Bresson, and Vandergheynst]{Defferrard2016}
M.~Defferrard, X.~Bresson, and P.~Vandergheynst.
\newblock Convolutional neural networks on graphs with fast localized spectral filtering.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Di~Giovanni et~al.(2023)Di~Giovanni, Giusti, Barbero, Luise, Lio, and Bronstein]{Di_Giovanni2023-up}
F.~Di~Giovanni, L.~Giusti, F.~Barbero, G.~Luise, P.~Lio, and M.~M. Bronstein.
\newblock On over-squashing in message passing neural networks: The impact of width, depth, and topology.
\newblock In \emph{International Conference on Machine Learning}, 2023.

\bibitem[Duvenaud et~al.(2015)Duvenaud, Maclaurin, Aguilera{-}Iparraguirre, G{\'{o}}mez{-}Bombarelli, Hirzel, Aspuru{-}Guzik, and Adams]{Duv+2015}
D.~Duvenaud, D.~Maclaurin, J.~Aguilera{-}Iparraguirre, R.~G{\'{o}}mez{-}Bombarelli, T.~Hirzel, A.~Aspuru{-}Guzik, and R.~P. Adams.
\newblock Convolutional networks on graphs for learning molecular fingerprints.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2015.

\bibitem[Dwivedi and Bresson(2020)]{Dwivedi2020-cd}
V.~P. Dwivedi and X.~Bresson.
\newblock A generalization of transformer networks to graphs.
\newblock \emph{ArXiv preprint}, 2020.

\bibitem[Dwivedi et~al.(2022{\natexlab{a}})Dwivedi, Luu, Laurent, Bengio, and Bresson]{dwivedi2022graph}
V.~P. Dwivedi, A.~T. Luu, T.~Laurent, Y.~Bengio, and X.~Bresson.
\newblock Graph neural networks with learnable structural and positional representations.
\newblock In \emph{International Conference on Learning Representations}, 2022{\natexlab{a}}.

\bibitem[Dwivedi et~al.(2022{\natexlab{b}})Dwivedi, Ramp{\'a}{\v{s}}ek, Galkin, Parviz, Wolf, Luu, and Beaini]{Dwivedi2022-vv}
V.~P. Dwivedi, L.~Ramp{\'a}{\v{s}}ek, M.~Galkin, A.~Parviz, G.~Wolf, A.~T. Luu, and D.~Beaini.
\newblock Long range graph benchmark.
\newblock \emph{Advances in Neural Information Processing Systems}, 2022{\natexlab{b}}.

\bibitem[Easley et~al.(2012)Easley, Kleinberg, et~al.]{Eas+2010}
D.~Easley, J.~Kleinberg, et~al.
\newblock Networks, crowds, and markets.
\newblock \emph{Cambridge Books}, 2012.

\bibitem[Errica et~al.(2023)Errica, Christiansen, Zaverkin, Maruyama, Niepert, and Alesiani]{errica2023adaptive}
F.~Errica, H.~Christiansen, V.~Zaverkin, T.~Maruyama, M.~Niepert, and F.~Alesiani.
\newblock Adaptive message passing: A general framework to mitigate oversmoothing, oversquashing, and underreaching.
\newblock \emph{arXiv preprint}, 2023.

\bibitem[Fatemi et~al.(2021)Fatemi, El~Asri, and Kazemi]{fatemi2021slaps}
B.~Fatemi, L.~El~Asri, and S.~M. Kazemi.
\newblock Slaps: Self-supervision improves structure learning for graph neural networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Fatemi et~al.(2023)Fatemi, Abu-El-Haija, Tsitsulin, Kazemi, Zelle, Bulut, Halcrow, and Perozzi]{fatemi2023ugsl}
B.~Fatemi, S.~Abu-El-Haija, A.~Tsitsulin, M.~Kazemi, D.~Zelle, N.~Bulut, J.~Halcrow, and B.~Perozzi.
\newblock Ugsl: A unified framework for benchmarking graph structure learning.
\newblock \emph{arXiv preprint}, 2023.

\bibitem[Fey et~al.(2020)Fey, Yuen, and Weichert]{fey2020hierarchical}
M.~Fey, J.-G. Yuen, and F.~Weichert.
\newblock Hierarchical inter-message passing for learning on molecular graphs.
\newblock \emph{arXiv preprint}, 2020.

\bibitem[Franceschi et~al.(2019)Franceschi, Niepert, Pontil, and He]{franceschi2019learning}
L.~Franceschi, M.~Niepert, M.~Pontil, and X.~He.
\newblock Learning discrete structures for graph neural networks.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Frasca et~al.(2020)Frasca, Rossi, Eynard, Chamberlain, Bronstein, and Monti]{frasca2020sign}
F.~Frasca, E.~Rossi, D.~Eynard, B.~Chamberlain, M.~Bronstein, and F.~Monti.
\newblock Sign: Scalable inception graph neural networks.
\newblock \emph{arXiv preprint}, 2020.

\bibitem[Gama et~al.(2019)Gama, Marques, Leus, and Ribeiro]{Gam+2019}
F.~Gama, A.~G. Marques, G.~Leus, and A.~Ribeiro.
\newblock Convolutional neural network architectures for signals supported on graphs.
\newblock \emph{IEEE Transactions on Signal Processing}, 67\penalty0 (4):\penalty0 1034--1049, 2019.

\bibitem[Gao and Ji(2019)]{gao2019unets}
H.~Gao and S.~Ji.
\newblock Graph {U-Nets}.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Gasteiger et~al.(2019)Gasteiger, Wei{\ss}enberger, and G{\"u}nnemann]{Kli+2019}
J.~Gasteiger, S.~Wei{\ss}enberger, and S.~G{\"u}nnemann.
\newblock Diffusion improves graph learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Geisler et~al.(2024)Geisler, Kosmala, Herbst, and G{\"u}nnemann]{geisler2024spatio}
S.~Geisler, A.~Kosmala, D.~Herbst, and S.~G{\"u}nnemann.
\newblock Spatio-spectral graph neural networks.
\newblock \emph{arXiv preprint}, 2024.

\bibitem[Gilmer et~al.(2017)Gilmer, Schoenholz, Riley, Vinyals, and Dahl]{Gil+2017}
J.~Gilmer, S.~S. Schoenholz, P.~F. Riley, O.~Vinyals, and G.~E. Dahl.
\newblock Neural message passing for quantum chemistry.
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Giusti et~al.(2023{\natexlab{a}})Giusti, Battiloro, Testa, Di~Lorenzo, Sardellitti, and Barbarossa]{giusti2022cell}
L.~Giusti, C.~Battiloro, L.~Testa, P.~Di~Lorenzo, S.~Sardellitti, and S.~Barbarossa.
\newblock Cell attention networks.
\newblock In \emph{International Joint Conference on Neural Networks}, 2023{\natexlab{a}}.

\bibitem[Giusti et~al.(2023{\natexlab{b}})Giusti, Reu, Ceccarelli, Bodnar, and Li{\`o}]{giusti2023cin}
L.~Giusti, T.~Reu, F.~Ceccarelli, C.~Bodnar, and P.~Li{\`o}.
\newblock Cin++: Enhancing topological message passing.
\newblock \emph{arXiv preprint}, 2023{\natexlab{b}}.

\bibitem[Goller and K{\"{u}}chler(1996)]{Gol+1996}
C.~Goller and A.~K{\"{u}}chler.
\newblock Learning task-dependent distributed representations by backpropagation through structure.
\newblock In \emph{International Conference on Neural Networks}, 1996.

\bibitem[Grohe(2017)]{Gro2017}
M.~Grohe.
\newblock \emph{Descriptive complexity, canonisation, and definable graph structure theory}.
\newblock Cambridge University Press, 2017.

\bibitem[Grohe(2021)]{Gro+2021}
M.~Grohe.
\newblock The logic of graph neural networks.
\newblock In \emph{Symposium on Logic in Computer Science}, 2021.

\bibitem[Gromiha and Selvaraj(1999)]{GROMIHA199949}
M.~M. Gromiha and S.~Selvaraj.
\newblock Importance of long-range interactions in protein folding.
\newblock \emph{Biophysical Chemistry}, 77\penalty0 (1):\penalty0 49--68, 1999.

\bibitem[Gutteridge et~al.(2023)Gutteridge, Dong, Bronstein, and Di~Giovanni]{Gutteridge2023-wx}
B.~Gutteridge, X.~Dong, M.~M. Bronstein, and F.~Di~Giovanni.
\newblock Drew: dynamically rewired message passing with delay.
\newblock In \emph{International Conference on Machine Learning}, 2023.

\bibitem[Hamilton et~al.(2017)Hamilton, Ying, and Leskovec]{Ham+2017}
W.~L. Hamilton, Z.~Ying, and J.~Leskovec.
\newblock Inductive representation learning on large graphs.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[He et~al.(2023)He, Hooi, Laurent, Perold, LeCun, and Bresson]{He2022-wq}
X.~He, B.~Hooi, T.~Laurent, A.~Perold, Y.~LeCun, and X.~Bresson.
\newblock A generalization of vit/mlp-mixer to graphs.
\newblock In \emph{International Conference on Machine Learning}, 2023.

\bibitem[Hu et~al.(2019)Hu, Zhu, Wu, Wang, and Tan]{hu2019hierarchical}
F.~Hu, Y.~Zhu, S.~Wu, L.~Wang, and T.~Tan.
\newblock Hierarchical graph convolutional networks for semi-supervised node classification.
\newblock \emph{arXiv preprint}, 2019.

\bibitem[Hu et~al.(2020)Hu, Fey, Zitnik, Dong, Ren, Liu, Catasta, and Leskovec]{hu2020ogb}
W.~Hu, M.~Fey, M.~Zitnik, Y.~Dong, H.~Ren, B.~Liu, M.~Catasta, and J.~Leskovec.
\newblock Open graph benchmark: Datasets for machine learning on graphs.
\newblock \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Huang et~al.(2019)Huang, Li, Li, Liu, and Li]{attpool}
J.~Huang, Z.~Li, N.~Li, S.~Liu, and G.~Li.
\newblock {AttPool:} towards hierarchical feature representation in graph convolutional networks via attention mechanism.
\newblock In \emph{IEEE/CVF International Conference on Computer Vision}, 2019.

\bibitem[Huang et~al.(2021)Huang, Zhang, Xi, Liu, and Zhou]{huang2021scaling}
Z.~Huang, S.~Zhang, C.~Xi, T.~Liu, and M.~Zhou.
\newblock Scaling up graph neural networks via graph coarsening.
\newblock In \emph{SIGKDD Conference on Knowledge Discovery \& Data Mining}, 2021.

\bibitem[Husic et~al.(2020)Husic, Charron, Lemm, Wang, P{\'e}rez, Majewski, Kr{\"a}mer, Chen, Olsson, de~Fabritiis, et~al.]{husic2020coarse}
B.~E. Husic, N.~E. Charron, D.~Lemm, J.~Wang, A.~P{\'e}rez, M.~Majewski, A.~Kr{\"a}mer, Y.~Chen, S.~Olsson, G.~de~Fabritiis, et~al.
\newblock Coarse graining molecular dynamics with graph neural networks.
\newblock \emph{The Journal of Chemical Physics}, 153\penalty0 (19), 2020.

\bibitem[Hussain et~al.(2022)Hussain, Zaki, and Subramanian]{hussain2022egt}
M.~S. Hussain, M.~J. Zaki, and D.~Subramanian.
\newblock Global self-attention as a replacement for graph convolution.
\newblock In \emph{SIGKDD Conference on Knowledge Discovery and Data Mining}, 2022.

\bibitem[Ishiguro et~al.(2019)Ishiguro, Maeda, and Koyama]{ishiguro2019graph}
K.~Ishiguro, S.-i. Maeda, and M.~Koyama.
\newblock Graph warp module: an auxiliary module for boosting the power of graph neural networks in molecular graph analysis.
\newblock \emph{arXiv preprint}, 2019.

\bibitem[Jin et~al.(2017)Jin, Coley, Barzilay, and Jaakkola]{zinc1}
W.~Jin, C.~Coley, R.~Barzilay, and T.~Jaakkola.
\newblock Predicting organic reaction outcomes with {W}eisfeiler-{L}ehman network.
\newblock \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Jin et~al.(2020)Jin, Ma, Liu, Tang, Wang, and Tang]{jin2020graph}
W.~Jin, Y.~Ma, X.~Liu, X.~Tang, S.~Wang, and J.~Tang.
\newblock Graph structure learning for robust graph neural networks.
\newblock \emph{arXiv preprint}, 2020.

\bibitem[Jumper et~al.(2021)Jumper, Evans, Pritzel, Green, Figurnov, Ronneberger, Tunyasuvunakool, Bates, {\v{Z}}{\'\i}dek, Potapenko, et~al.]{Jum+2021}
J.~Jumper, R.~Evans, A.~Pritzel, T.~Green, M.~Figurnov, O.~Ronneberger, K.~Tunyasuvunakool, R.~Bates, A.~{\v{Z}}{\'\i}dek, A.~Potapenko, et~al.
\newblock Highly accurate protein structure prediction with alphafold.
\newblock \emph{Nature}, 596\penalty0 (7873):\penalty0 583--589, 2021.

\bibitem[Karhadkar et~al.(2022)Karhadkar, Banerjee, and Mont{\'u}far]{Karhadkar2022-uz}
K.~Karhadkar, P.~K. Banerjee, and G.~Mont{\'u}far.
\newblock {FoSR}: First-order spectral rewiring for addressing oversquashing in gnns.
\newblock \emph{arXiv preprint}, 2022.

\bibitem[Kazi et~al.(2022)Kazi, Cosmo, Ahmadi, Navab, and Bronstein]{kazi2022differentiable}
A.~Kazi, L.~Cosmo, S.-A. Ahmadi, N.~Navab, and M.~M. Bronstein.
\newblock Differentiable graph module (dgm) for graph convolutional networks.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 45\penalty0 (2):\penalty0 1606--1617, 2022.

\bibitem[Kiefer and McKay(2020)]{Kie+2020}
S.~Kiefer and B.~D. McKay.
\newblock The iteration number of {Colour Refinement}.
\newblock In \emph{International Colloquium on Automata, Languages, and Programming}, pages 73:1--73:19, 2020.

\bibitem[Kim et~al.(2022)Kim, Nguyen, Min, Cho, Lee, Lee, and Hong]{Kim+2022}
J.~Kim, T.~D. Nguyen, S.~Min, S.~Cho, M.~Lee, H.~Lee, and S.~Hong.
\newblock Pure transformers are powerful graph learners.
\newblock \emph{arXiv preprint}, 2022.

\bibitem[Kingma and Ba(2015)]{Kin+2015}
D.~P. Kingma and J.~Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Kipf and Welling(2017)]{Kip+2017}
T.~N. Kipf and M.~Welling.
\newblock Semi-supervised classification with graph convolutional networks.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Kireev(1995)]{Kir+1995}
D.~B. Kireev.
\newblock Chemnet: A novel neural network based method for graph/property mapping.
\newblock \emph{Journal of Chemical Information and Computer Sciences}, 35\penalty0 (2):\penalty0 175--180, 1995.

\bibitem[Levie et~al.(2019)Levie, Monti, Bresson, and Bronstein]{Lev+2019}
R.~Levie, F.~Monti, X.~Bresson, and M.~M. Bronstein.
\newblock {CayleyNets}: Graph convolutional neural networks with complex rational spectral filters.
\newblock \emph{{IEEE} Transactions on Signal Processing}, 67\penalty0 (1):\penalty0 97--109, 2019.

\bibitem[Li et~al.(2017)Li, Cai, and He]{li2017learning}
J.~Li, D.~Cai, and X.~He.
\newblock Learning graph-level representation for drug discovery.
\newblock \emph{arXiv preprint}, 2017.

\bibitem[Li et~al.(2020)Li, Chen, Zhang, and Tsang]{li2020gxn}
M.~Li, S.~Chen, Y.~Zhang, and I.~Tsang.
\newblock Graph cross networks with vertex infomax pooling.
\newblock \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Li et~al.(2023)Li, Zhou, Yao, Rong, Zhang, and Han]{li2023long}
X.~Li, Z.~Zhou, J.~Yao, Y.~Rong, L.~Zhang, and B.~Han.
\newblock Long-range neural atom learning for molecular graphs.
\newblock \emph{arXiv preprint}, 2023.

\bibitem[Liang et~al.(2021)Liang, Gurukar, and Parthasarathy]{liang2021mile}
J.~Liang, S.~Gurukar, and S.~Parthasarathy.
\newblock Mile: A multi-level framework for scalable graph embedding.
\newblock In \emph{AAAI Conference on Web and Social Media}, 2021.

\bibitem[Liu et~al.(2021)Liu, Wang, and Ji]{Liu2021-nm}
M.~Liu, Z.~Wang, and S.~Ji.
\newblock Non-local graph neural networks.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 44\penalty0 (12):\penalty0 10270--10276, 2021.

\bibitem[Liu et~al.(2022{\natexlab{a}})Liu, Wang, Wu, Chen, Guo, and Shi]{liu2022compact}
N.~Liu, X.~Wang, L.~Wu, Y.~Chen, X.~Guo, and C.~Shi.
\newblock Compact graph structure learning via mutual information compression.
\newblock In \emph{ACM Web Conference 2022}, 2022{\natexlab{a}}.

\bibitem[Liu et~al.(2022{\natexlab{b}})Liu, Zheng, Zhang, Chen, Peng, and Pan]{liu2022towards}
Y.~Liu, Y.~Zheng, D.~Zhang, H.~Chen, H.~Peng, and S.~Pan.
\newblock Towards unsupervised deep graph structure learning.
\newblock In \emph{ACM Web Conference 2022}, 2022{\natexlab{b}}.

\bibitem[Ma et~al.(2023)Ma, Lin, Lim, Romero-Soriano, Dokania, Coates, Torr, and Lim]{ma2023grit}
L.~Ma, C.~Lin, D.~Lim, A.~Romero-Soriano, P.~K. Dokania, M.~Coates, P.~Torr, and S.-N. Lim.
\newblock Graph inductive biases in transformers without message passing.
\newblock In \emph{International Conference on Machine Learning}, 2023.

\bibitem[Maron et~al.(2019{\natexlab{a}})Maron, Ben{-}Hamu, Serviansky, and Lipman]{Mar+2019}
H.~Maron, H.~Ben{-}Hamu, H.~Serviansky, and Y.~Lipman.
\newblock Provably powerful graph networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019{\natexlab{a}}.

\bibitem[Maron et~al.(2019{\natexlab{b}})Maron, Ben{-}Hamu, Shamir, and Lipman]{Mar+2019c}
H.~Maron, H.~Ben{-}Hamu, N.~Shamir, and Y.~Lipman.
\newblock Invariant and equivariant graph networks.
\newblock In \emph{International Conference on Learning Representations}, 2019{\natexlab{b}}.

\bibitem[Merkwirth and Lengauer(2005)]{Mer+2005}
C.~Merkwirth and T.~Lengauer.
\newblock Automatic generation of complementary descriptors with molecular graph networks.
\newblock \emph{Journal of Chemical Information and Modeling}, 45\penalty0 (5):\penalty0 1159--1168, 2005.

\bibitem[Mialon et~al.(2021)Mialon, Chen, Selosse, and Mairal]{mialon2021graphit}
G.~Mialon, D.~Chen, M.~Selosse, and J.~Mairal.
\newblock Graphit: Encoding graph structure in transformers.
\newblock \emph{arXiv preprint}, 2021.

\bibitem[Micheli(2009)]{mic+2009}
A.~Micheli.
\newblock Neural network for graphs: {A} contextual constructive approach.
\newblock \emph{{IEEE} Transactions on Neural Networks}, 20\penalty0 (3):\penalty0 498--511, 2009.

\bibitem[Micheli and Sestito(2005)]{mic+2005}
A.~Micheli and A.~S. Sestito.
\newblock A new neural network model for contextual processing of graphs.
\newblock In \emph{Italian Workshop on Neural Nets Neural Nets and International Workshop on Natural and Artificial Immune Systems}, 2005.

\bibitem[Minervini et~al.(2023)Minervini, Franceschi, and Niepert]{minervini23aimle}
P.~Minervini, L.~Franceschi, and M.~Niepert.
\newblock Adaptive perturbation-based gradient estimation for discrete latent variable models.
\newblock In \emph{{AAAI}}, 2023.

\bibitem[Monti et~al.(2017)Monti, Boscaini, Masci, Rodol{\`{a}}, Svoboda, and Bronstein]{Mon+2017}
F.~Monti, D.~Boscaini, J.~Masci, E.~Rodol{\`{a}}, J.~Svoboda, and M.~M. Bronstein.
\newblock Geometric deep learning on graphs and manifolds using mixture model {CNNs}.
\newblock In \emph{{IEEE} Conference on Computer Vision and Pattern Recognition}, 2017.

\bibitem[Morris et~al.(2019)Morris, Ritzert, Fey, Hamilton, Lenssen, Rattan, and Grohe]{Mor+2019}
C.~Morris, M.~Ritzert, M.~Fey, W.~L. Hamilton, J.~E. Lenssen, G.~Rattan, and M.~Grohe.
\newblock {W}eisfeiler and {L}eman go neural: Higher-order graph neural networks.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2019.

\bibitem[Morris et~al.(2020{\natexlab{a}})Morris, Kriege, Bause, Kersting, Mutzel, and Neumann]{Mor+2020}
C.~Morris, N.~M. Kriege, F.~Bause, K.~Kersting, P.~Mutzel, and M.~Neumann.
\newblock {TUDataset}: A collection of benchmark datasets for learning with graphs.
\newblock \emph{arXiv preprint}, 2020{\natexlab{a}}.

\bibitem[Morris et~al.(2020{\natexlab{b}})Morris, Rattan, and Mutzel]{Morris2020b}
C.~Morris, G.~Rattan, and P.~Mutzel.
\newblock {Weisfeiler and Leman} go sparse: Towards higher-order graph embeddings.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020{\natexlab{b}}.

\bibitem[Morris et~al.(2021)Morris, Lipman, Maron, Rieck, Kriege, Grohe, Fey, and Borgwardt]{Mor+2022}
C.~Morris, Y.~Lipman, H.~Maron, B.~Rieck, N.~M. Kriege, M.~Grohe, M.~Fey, and K.~Borgwardt.
\newblock Weisfeiler and {L}eman go machine learning: The story so far.
\newblock \emph{arXiv preprint}, 2021.

\bibitem[Morris et~al.(2023)Morris, Geerts, T{\"{o}}nshoff, and Grohe]{Mor+2023}
C.~Morris, F.~Geerts, J.~T{\"{o}}nshoff, and M.~Grohe.
\newblock {WL} meet {VC}.
\newblock In \emph{ICML}, 2023.

\bibitem[M{\"u}ller et~al.(2023)M{\"u}ller, Galkin, Morris, and Ramp{\'a}{\v{s}}ek]{Mue+2023}
L.~M{\"u}ller, M.~Galkin, C.~Morris, and L.~Ramp{\'a}{\v{s}}ek.
\newblock Attending to graph transformers.
\newblock \emph{arXiv preprint}, 2023.

\bibitem[Murphy et~al.(2019)Murphy, Srinivasan, Rao, and Ribeiro]{Mur+2019b}
R.~Murphy, B.~Srinivasan, V.~Rao, and B.~Ribeiro.
\newblock Relational pooling for graph representations.
\newblock In \emph{International Conference on Machine Learning}, pages 4663--4673, 2019.

\bibitem[Müller and Morris(2024)]{Mue+2024b}
L.~Müller and C.~Morris.
\newblock Towards principled graph transformers.
\newblock In \emph{NeurIPS}, 2024.

\bibitem[Namazi et~al.(2022)Namazi, Ghalebi, Williamson, and Mahyar]{namazi2022smgrl}
R.~Namazi, E.~Ghalebi, S.~Williamson, and H.~Mahyar.
\newblock Smgrl: Scalable multi-resolution graph representation learning.
\newblock \emph{arXiv preprint}, 2022.

\bibitem[Neumann et~al.(2016)Neumann, Garnett, Bauckhage, and Kersting]{Neu+2016}
M.~Neumann, R.~Garnett, C.~Bauckhage, and K.~Kersting.
\newblock Propagation kernels: efficient graph kernels from propagated information.
\newblock \emph{Machine learning}, 102:\penalty0 209--245, 2016.

\bibitem[Niepert et~al.(2021)Niepert, Minervini, and Franceschi]{Niepert2021-pa}
M.~Niepert, P.~Minervini, and L.~Franceschi.
\newblock Implicit {MLE}: Backpropagating through discrete exponential family distributions.
\newblock \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Papp et~al.(2021)Papp, Martinkus, Faber, and Wattenhofer]{Pap+2021}
P.~A. Papp, K.~Martinkus, L.~Faber, and R.~Wattenhofer.
\newblock {DropGNN}: Random dropouts increase the expressiveness of graph neural networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Park et~al.(2023)Park, Ryu, Kim, Woo, Yun, and Ahn]{park2023nonbacktracking}
S.~Park, N.~Ryu, G.~Kim, D.~Woo, S.-Y. Yun, and S.~Ahn.
\newblock Non-backtracking graph neural networks.
\newblock \emph{arXiv preprint}, 2023.

\bibitem[Pei et~al.(2020)Pei, Wei, Chang, Lei, and Yang]{webkb}
H.~Pei, B.~Wei, K.~C.-C. Chang, Y.~Lei, and B.~Yang.
\newblock Geom-gcn: Geometric graph convolutional networks.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Pham et~al.(2017)Pham, Tran, Dam, and Venkatesh]{pham2017graph}
T.~Pham, T.~Tran, H.~Dam, and S.~Venkatesh.
\newblock Graph classification via deep learning with virtual nodes.
\newblock \emph{arXiv preprint}, 2017.

\bibitem[Platonov et~al.(2023)Platonov, Kuznedelev, Diskin, Babenko, and Prokhorenkova]{platonov2023critical}
O.~Platonov, D.~Kuznedelev, M.~Diskin, A.~Babenko, and L.~Prokhorenkova.
\newblock A critical look at the evaluation of gnns under heterophily: Are we really making progress?
\newblock \emph{arXiv preprint}, 2023.

\bibitem[Qian et~al.(2023)Qian, Manolache, Ahmed, Zeng, den Broeck, Niepert, and Morris]{qian2023probabilistically}
C.~Qian, A.~Manolache, K.~Ahmed, Z.~Zeng, G.~V. den Broeck, M.~Niepert, and C.~Morris.
\newblock Probabilistically rewired message-passing neural networks, 2023.

\bibitem[Qian et~al.(2024)Qian, Chételat, and Morris]{qian2023exploring}
C.~Qian, D.~Chételat, and C.~Morris.
\newblock Exploring the power of graph neural networks in solving linear optimization problems.
\newblock In \emph{AISTATS}, 2024.

\bibitem[Ramp{\'a}{\v{s}}ek and Wolf(2021)]{rampavsek2021hierarchical}
L.~Ramp{\'a}{\v{s}}ek and G.~Wolf.
\newblock Hierarchical graph neural nets can capture long-range interactions.
\newblock In \emph{IEEE International Workshop on Machine Learning for Signal Processing}, 2021.

\bibitem[Ramp{\'a}{\v{s}}ek et~al.(2022)Ramp{\'a}{\v{s}}ek, Galkin, Dwivedi, Luu, Wolf, and Beaini]{Rampasek2022-uc}
L.~Ramp{\'a}{\v{s}}ek, M.~Galkin, V.~P. Dwivedi, A.~T. Luu, G.~Wolf, and D.~Beaini.
\newblock Recipe for a general, powerful, scalable graph transformer.
\newblock \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Ranjan et~al.(2020)Ranjan, Sanyal, and Talukdar]{ranjan2020asap}
E.~Ranjan, S.~Sanyal, and P.~Talukdar.
\newblock Asap: Adaptive structure aware pooling for learning hierarchical graph representations.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2020.

\bibitem[Rosenbluth et~al.(2024)Rosenbluth, T{\"o}nshoff, Ritzert, Kisin, and Grohe]{rosenbluth2024distinguished}
E.~Rosenbluth, J.~T{\"o}nshoff, M.~Ritzert, B.~Kisin, and M.~Grohe.
\newblock Distinguished in uniform: Self-attention vs. virtual nodes.
\newblock In \emph{International Conference on Learning Representations}, 2024.

\bibitem[Saha et~al.(2023)Saha, Mendez, Russell, and Bowden]{saha2023learning}
A.~Saha, O.~Mendez, C.~Russell, and R.~Bowden.
\newblock Learning adaptive neighborhoods for graph neural networks.
\newblock \emph{arXiv preprint}, 2023.

\bibitem[Saunders and Voth(2013)]{saunders2013coarse}
M.~G. Saunders and G.~A. Voth.
\newblock Coarse-graining methods for computational biology.
\newblock \emph{Annual Review of Biophysics}, 42:\penalty0 73--93, 2013.

\bibitem[Scarselli et~al.(2008)Scarselli, Gori, Tsoi, Hagenbuchner, and Monfardini]{Sca+2009}
F.~Scarselli, M.~Gori, A.~C. Tsoi, M.~Hagenbuchner, and G.~Monfardini.
\newblock The graph neural network model.
\newblock \emph{IEEE Transactions on Neural Networks}, 20\penalty0 (1):\penalty0 61--80, 2008.

\bibitem[Schlichtkrull et~al.(2018)Schlichtkrull, Kipf, Bloem, van~den Berg, Titov, and Welling]{Sch+2019}
M.~Schlichtkrull, T.~N. Kipf, P.~Bloem, R.~van~den Berg, I.~Titov, and M.~Welling.
\newblock Modeling relational data with graph convolutional networks.
\newblock In \emph{The Semantic Web}, pages 593--607, 2018.

\bibitem[Shervashidze et~al.(2009)Shervashidze, Vishwanathan, Petri, Mehlhorn, and Borgwardt]{She+2009}
N.~Shervashidze, S.~Vishwanathan, T.~Petri, K.~Mehlhorn, and K.~Borgwardt.
\newblock Efficient graphlet kernels for large graph comparison.
\newblock In \emph{AISTATS}, 2009.

\bibitem[Shervashidze et~al.(2011)Shervashidze, Schweitzer, Van~Leeuwen, Mehlhorn, and Borgwardt]{She+2011}
N.~Shervashidze, P.~Schweitzer, E.~J. Van~Leeuwen, K.~Mehlhorn, and K.~M. Borgwardt.
\newblock Weisfeiler-lehman graph kernels.
\newblock \emph{Journal of Machine Learning Research}, 12\penalty0 (9), 2011.

\bibitem[Shirzad et~al.(2023)Shirzad, Velingker, Venkatachalam, Sutherland, and Sinop]{Shi+2023}
H.~Shirzad, A.~Velingker, B.~Venkatachalam, D.~J. Sutherland, and A.~K. Sinop.
\newblock Exphormer: Sparse transformers for graphs.
\newblock \emph{arXiv preprint}, 2023.

\bibitem[Southern et~al.(2024)Southern, Di~Giovanni, Bronstein, and Lutzeyer]{southern2024understanding}
J.~Southern, F.~Di~Giovanni, M.~Bronstein, and J.~F. Lutzeyer.
\newblock Understanding virtual nodes: Oversmoothing, oversquashing, and node heterogeneity.
\newblock \emph{arXiv preprint}, 2024.

\bibitem[Sperduti and Starita(1997)]{Spe+1997}
A.~Sperduti and A.~Starita.
\newblock Supervised neural networks for the classification of structures.
\newblock \emph{IEEE Transactions on Neural Networks}, 8\penalty0 (3):\penalty0 714--35, 1997.

\bibitem[Topping et~al.(2021)Topping, Di~Giovanni, Chamberlain, Dong, and Bronstein]{Topping2021-iy}
J.~Topping, F.~Di~Giovanni, B.~P. Chamberlain, X.~Dong, and M.~M. Bronstein.
\newblock Understanding over-squashing and bottlenecks on graphs via curvature.
\newblock \emph{arXiv preprint}, 2021.

\bibitem[Tönshoff et~al.(2023)Tönshoff, Ritzert, Rosenbluth, and Grohe]{wdtgg}
J.~Tönshoff, M.~Ritzert, E.~Rosenbluth, and M.~Grohe.
\newblock Where did the gap go? reassessing the long-range graph benchmark.
\newblock \emph{arXiv preprint}, 2023.

\bibitem[Veli\v{c}kovi\'{c} et~al.(2018)Veli\v{c}kovi\'{c}, Cucurull, Casanova, Romero, Li{\`{o}}, and Bengio]{Vel+2018}
P.~Veli\v{c}kovi\'{c}, G.~Cucurull, A.~Casanova, A.~Romero, P.~Li{\`{o}}, and Y.~Bengio.
\newblock Graph attention networks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Weisfeiler and Leman(1968)]{Wei+1968}
B.~Weisfeiler and A.~Leman.
\newblock The reduction of a graph to canonical form and the algebra which appears therein.
\newblock \emph{nti, Series}, 2\penalty0 (9):\penalty0 12--16, 1968.

\bibitem[Wong et~al.(2023)Wong, Zheng, Valeri, Donghia, Anahtar, Omori, Li, Cubillos-Ruiz, Krishnan, Jin, Manson, Friedrichs, Helbig, Hajian, Fiejtek, Wagner, Soutter, Earl, Stokes, Renner, and Collins]{Won+2023}
F.~Wong, E.~J. Zheng, J.~A. Valeri, N.~M. Donghia, M.~N. Anahtar, S.~Omori, A.~Li, A.~Cubillos-Ruiz, A.~Krishnan, W.~Jin, A.~L. Manson, J.~Friedrichs, R.~Helbig, B.~Hajian, D.~K. Fiejtek, F.~F. Wagner, H.~H. Soutter, A.~M. Earl, J.~M. Stokes, L.~D. Renner, and J.~J. Collins.
\newblock Discovery of a structural class of antibiotics with explainable deep learning.
\newblock \emph{Nature}, 2023.

\bibitem[Wu et~al.(2021)Wu, Jain, Wright, Mirhoseini, Gonzalez, and Stoica]{Wu2022-vr}
Z.~Wu, P.~Jain, M.~Wright, A.~Mirhoseini, J.~E. Gonzalez, and I.~Stoica.
\newblock Representing long-range context for graph neural networks with global attention.
\newblock \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Xie and Ermon(2019)]{xie2019subsets}
S.~M. Xie and S.~Ermon.
\newblock Reparameterizable subset sampling via continuous relaxations.
\newblock \emph{International Joint Conference on Artificial Intelligence}, 2019.

\bibitem[Xu et~al.(2018)Xu, Li, Tian, Sonobe, Kawarabayashi, and Jegelka]{Xu+2018}
K.~Xu, C.~Li, Y.~Tian, T.~Sonobe, K.-i. Kawarabayashi, and S.~Jegelka.
\newblock Representation learning on graphs with jumping knowledge networks.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Xu et~al.(2019)Xu, Hu, Leskovec, and Jegelka]{xu2018how}
K.~Xu, W.~Hu, J.~Leskovec, and S.~Jegelka.
\newblock How powerful are graph neural networks?
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Ying et~al.(2021)Ying, Cai, Luo, Zheng, Ke, He, Shen, and Liu]{graphormer}
C.~Ying, T.~Cai, S.~Luo, S.~Zheng, G.~Ke, D.~He, Y.~Shen, and T.-Y. Liu.
\newblock Do transformers really perform badly for graph representation?
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 28877--28888, 2021.

\bibitem[Ying et~al.(2018)Ying, You, Morris, Ren, Hamilton, and Leskovec]{ying2018diffpool}
Z.~Ying, J.~You, C.~Morris, X.~Ren, W.~Hamilton, and J.~Leskovec.
\newblock Hierarchical graph representation learning with differentiable pooling.
\newblock \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Younesian et~al.(2023)Younesian, Thanapalasingam, van Krieken, Daza, and Bloem]{younesian2023grapes}
T.~Younesian, T.~Thanapalasingam, E.~van Krieken, D.~Daza, and P.~Bloem.
\newblock {GRAPES}: Learning to sample graphs for scalable graph neural networks.
\newblock \emph{arXiv preprint}, 2023.

\bibitem[Yu et~al.(2021)Yu, Zhang, Jiang, Wu, and Yang]{yu2021graph}
D.~Yu, R.~Zhang, Z.~Jiang, Y.~Wu, and Y.~Yang.
\newblock Graph-revised convolutional network.
\newblock In \emph{European Conference on Machine Learning and Knowledge Discovery in Databases}, 2021.

\bibitem[Zhang et~al.(2018)Zhang, Cui, Neumann, and Chen]{Zha+2018}
M.~Zhang, Z.~Cui, M.~Neumann, and Y.~Chen.
\newblock An end-to-end deep learning architecture for graph classification.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2018.

\bibitem[Zhao et~al.(2021)Zhao, Liu, Neves, Woodford, Jiang, and Shah]{zhao2021data}
T.~Zhao, Y.~Liu, L.~Neves, O.~Woodford, M.~Jiang, and N.~Shah.
\newblock Data augmentation for graph neural networks.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2021.

\bibitem[Zhong et~al.(2023)Zhong, Li, and Pang]{zhong2023hierarchical}
Z.~Zhong, C.-T. Li, and J.~Pang.
\newblock Hierarchical message-passing graph neural networks.
\newblock \emph{Data Mining and Knowledge Discovery}, 37\penalty0 (1):\penalty0 381--408, 2023.

\bibitem[Zhou et~al.(2023{\natexlab{a}})Zhou, Zhou, Mao, Zhou, Chen, Tan, Zha, Feng, Chen, and Wang]{OpenGSL}
Z.~Zhou, S.~Zhou, B.~Mao, X.~Zhou, J.~Chen, Q.~Tan, D.~Zha, Y.~Feng, C.~Chen, and C.~Wang.
\newblock {OpenGSL}: A comprehensive benchmark for graph structure learning, 2023{\natexlab{a}}.

\bibitem[Zhou et~al.(2023{\natexlab{b}})Zhou, Zhou, Mao, Zhou, Chen, Tan, Zha, Wang, Feng, and Chen]{zhou2023opengsl}
Z.~Zhou, S.~Zhou, B.~Mao, X.~Zhou, J.~Chen, Q.~Tan, D.~Zha, C.~Wang, Y.~Feng, and C.~Chen.
\newblock {OpenGSL}: A comprehensive benchmark for graph structure learning.
\newblock \emph{arXiv preprint}, 2023{\natexlab{b}}.

\bibitem[Zou et~al.(2023)Zou, Peng, Huang, Yang, Li, Wu, Liu, and Yu]{zou2023se}
D.~Zou, H.~Peng, X.~Huang, R.~Yang, J.~Li, J.~Wu, C.~Liu, and P.~S. Yu.
\newblock {SE-GSL}: A general and effective graph structure learning framework through structural entropy optimization.
\newblock \emph{arXiv preprint}, 2023.

\end{thebibliography}
