@string{JASA = {Journal of the American Statistical Association}}
@string{JC = {Journal of Classification}}
@string{JSPI = {Journal of Statistical Planning and Inference}}
@string{JRSSB = {Journal of the Royal Statistical Society, Series B}}
@string{SAGMB = {Statistical Applications in Genetics and Molecular Biology}}
@string{NIPS = {Advances in Neural Information Processing Systems}}
@string{AOS = {Annals of Statistics}}
@string{AOAS = {Annals of Applied Statistics}}
@string{JMLR = {Journal of Machine Learning Research}}
@string{EJS = {Electronic Journal of Statistics}}
@string{AISTATS = {International Conference on Artificial Intelligence and Statistics}}
@string{UAI = {Conference on Uncertainty in Artificial Intelligence}}
@string{ICML = {International Conference on Machine Learning}}
@string{COLT = {Conference on Learning Theory}}
@string{ICLR = {International Conference on Learning Representations}}
@string{TIT = {IEEE Transactions on Information Theory}}
@inproceedings{shani2020optimistic,
	title        = {Optimistic Policy Optimization with Bandit Feedback},
	author       = {Shani, Lior and Efroni, Yonathan and Rosenberg, Aviv and Mannor, Shie},
	year         = 2020,
	booktitle    = {ICML},
	pages        = {8604--8613}
}
@inproceedings{xie2019towards,
	title        = {Towards optimal off-policy evaluation for reinforcement learning with marginalized importance sampling},
	author       = {Xie, Tengyang and Ma, Yifei and Wang, Yu-Xiang},
	year         = 2019,
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {9668--9678}
}
@inproceedings{jong2007model,
	title        = {Model-based function approximation in reinforcement learning},
	author       = {Jong, Nicholas K and Stone, Peter},
	year         = 2007,
	booktitle    = {Conference on Autonomous Agents and Multiagent Systems},
	pages        = {1--8}
}
@inproceedings{duan2020minimaxoptimal,
  title={Minimax-optimal off-policy evaluation with linear function approximation},
  author={Duan, Yaqi and Jia, Zeyu and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={2701--2709},
  year={2020}
}
 
@inproceedings{schulman2015trust,
	title        = {Trust region policy optimization},
	author       = {Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
	year         = 2015,
	booktitle    = {ICML},
	pages        = {1889--1897}
}
@incollection{baird1995residual,
	title        = {Residual algorithms: Reinforcement learning with function approximation},
	author       = {Baird, Leemon},
	year         = 1995,
	booktitle    = {Machine Learning},
	publisher    = {Elsevier},
	pages        = {30--37}
}
@article{yang2019reinforcement,
	title        = {Reinforcement Learning in Feature Space: Matrix Bandit, Kernels, and Regret Bound},
	author       = {Yang, Lin and Wang, Mengdi},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1905.10389}
}
@article{precup2000eligibility,
	title        = {Eligibility traces for off-policy policy evaluation},
	author       = {Precup, Doina},
	year         = 2000,
	journal      = {Computer Science Department Faculty Publication Series},
	pages        = 80
}
@inproceedings{cheng2020trajectory,
	title        = {Trajectory-wise control variates for variance reduction in policy gradient methods},
	author       = {Cheng, Ching-An and Yan, Xinyan and Boots, Byron},
	year         = 2020,
	booktitle    = {Conference on Robot Learning},
	pages        = {1379--1394}
}
@article{DBLP:journals/corr/abs-1910-09066,
	title        = {From Importance Sampling to Doubly Robust Policy Gradient},
	author       = {Jiawei Huang and Nan Jiang},
	year         = 2019,
	journal      = {CoRR},
	volume       = {abs/1910.09066},
	url          = {http://arxiv.org/abs/1910.09066},
	archiveprefix = {arXiv},
	eprint       = {1910.09066},
	timestamp    = {Tue, 22 Oct 2019 18:17:16 +0200},
	biburl       = {https://dblp.org/rec/journals/corr/abs-1910-09066.bib},
	bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{kumar2020conservative,
  title={Conservative {Q}-Learning for Offline Reinforcement Learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.04779},
  year={2020}
}
@article{buckman2020importance,
  title={The importance of pessimism in fixed-dataset policy optimization},
  author={Buckman, Jacob and Gelada, Carles and Bellemare, Marc G},
  journal={arXiv preprint arXiv:2009.06799},
  year={2020}
}
@book{imbens2015causal,
	title        = {Causal inference in statistics, social, and biomedical sciences},
	author       = {Imbens, Guido W and Rubin, Donald B},
	year         = 2015,
	publisher    = {Cambridge University Press}
}
@inproceedings{abbasi2011improved,
	title        = {Improved algorithms for linear stochastic bandits},
	author       = {Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
	year         = 2011,
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {2312--2320}
}
@article{chowdhury2017kernelized,
	title        = {On kernelized multi-armed bandits},
	author       = {Chowdhury, Sayak Ray and Gopalan, Aditya},
	year         = 2017,
	journal      = {arXiv preprint arXiv:1704.00445}
}
@misc{wang2020provably,
	title        = {Provably Efficient Causal Reinforcement Learning with Confounded Observational Data},
	author       = {Lingxiao Wang and Zhuoran Yang and Zhaoran Wang},
	year         = 2020,
	eprint       = {2006.12311},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
@inproceedings{jin2020provably,
	title        = {Provably efficient reinforcement learning with linear function approximation},
	author       = {Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
	year         = 2020,
	booktitle    = {Conference on Learning Theory},
	pages        = {2137--2143}
}
@article{10.1561/2200000048,
	title        = {An Introduction to Matrix Concentration Inequalities},
	author       = {Tropp, Joel A.},
	year         = 2015,
	month        = may,
	journal      = {Foundations and Trends in Machine Learning},
	publisher    = {Now Publishers Inc.},
	address      = {Hanover, MA, USA},
	volume       = 8,
	number       = {1–2},
	pages        = {1–230},
	doi          = {10.1561/2200000048},
	issn         = {1935-8237},
	issue_date   = {05 2015},
	abstract     = {Random matrices now play a role in many areas of theoretical, applied,and computational mathematics. Therefore, it is desirable to have toolsfor studying random matrices that are flexible, easy to use, and powerful.Over the last fifteen years, researchers have developed a remarkablefamily of results, called matrix concentration inequalities, that achieveall of these goals.This monograph offers an invitation to the field of matrix concentrationinequalities. It begins with some history of random matrix theory;it describes a flexible model for random matrices that is suitablefor many problems; and it discusses the most important matrix concentrationresults. To demonstrate the value of these techniques, thepresentation includes examples drawn from statistics, machine learning,optimization, combinatorics, algorithms, scientific computing, andbeyond.},
	numpages     = 230
}
@incollection{yu1997assouad,
	title        = {Assouad, {F}ano, and {L}e {C}am},
	author       = {Yu, Bin},
	year         = 1997,
	booktitle    = {Festschrift for Lucien Le Cam},
	publisher    = {Springer},
	pages        = {423--435}
}
@book{le2012asymptotic,
	title        = {Asymptotic methods in statistical decision theory},
	author       = {Le Cam, Lucien},
	year         = 2012,
	publisher    = {Springer}
}
@inproceedings{kakade2002approximately,
	title        = {Approximately optimal approximate reinforcement learning},
	author       = {Kakade, Sham and Langford, John},
	year         = 2002,
	booktitle    = {ICML},
	volume       = 2,
	pages        = {267--274}
}
@inproceedings{cai2020provably,
	title        = {Provably efficient exploration in policy optimization},
	author       = {Cai, Qi and Yang, Zhuoran and Jin, Chi and Wang, Zhaoran},
	year         = 2020,
	booktitle    = {International Conference on Machine Learning},
	pages        = {1283--1294}
}
@incollection{lange2012batch,
	title        = {Batch reinforcement learning},
	author       = {Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
	year         = 2012,
	booktitle    = {Reinforcement learning},
	publisher    = {Springer},
	pages        = {45--73}
}
@article{li2020sample,
	title        = {Sample Complexity of Asynchronous {Q}-Learning: Sharper Analysis and Variance Reduction},
	author       = {Li, Gen and Wei, Yuting and Chi, Yuejie and Gu, Yuantao and Chen, Yuxin},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2006.03041}
}
@article{qu2020finite,
	title        = {Finite-Time Analysis of Asynchronous Stochastic Approximation and {Q}-Learning},
	author       = {Qu, Guannan and Wierman, Adam},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2002.00260}
}
@article{chen2019information,
	title        = {Information-theoretic considerations in batch reinforcement learning},
	author       = {Chen, Jinglin and Jiang, Nan},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1905.00360}
}
@inproceedings{fan2020theoretical,
	title        = {A theoretical analysis of deep {Q}-learning},
	author       = {Fan, Jianqing and Wang, Zhaoran and Xie, Yuchen and Yang, Zhuoran},
	year         = 2020,
	booktitle    = {Learning for Dynamics and Control},
	pages        = {486--489}
}
@article{munos2008finite,
	title        = {Finite-time bounds for fitted value iteration},
	author       = {Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
	year         = 2008,
	journal      = {Journal of Machine Learning Research},
	volume       = 9,
	number       = {May},
	pages        = {815--857}
}
@inproceedings{farahmand2010error,
	title        = {Error propagation for approximate policy and value iteration},
	author       = {Farahmand, Amir-massoud and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
	year         = 2010,
	booktitle      = {Advances in Neural Information Processing Systems}
}
@article{scherrer2015approximate,
	title        = {Approximate modified policy iteration and its application to the game of {T}etris.},
	author       = {Scherrer, Bruno and Ghavamzadeh, Mohammad and Gabillon, Victor and Lesner, Boris and Geist, Matthieu},
	year         = 2015,
	journal      = JMLR,
	volume       = 16,
	pages        = {1629--1676}
}
@article{antos2008learning,
	title        = {Learning near-optimal policies with {B}ellman-residual minimization based fitted policy iteration and a single sample path},
	author       = {Antos, Andr{\'a}s and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
	year         = 2008,
	journal      = {Machine Learning},
	publisher    = {Springer},
	volume       = 71,
	number       = 1,
	pages        = {89--129}
}
@inproceedings{antos2007fitted,
	title        = {Fitted {Q}-iteration in continuous action-space {MDP}s},
	author       = {Antos, Andr{\'a}s and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
	year         = 2007,
	booktitle      = {Advances in Neural Information Processing Systems}
}
@article{farahmand2016regularized,
	title        = {Regularized policy iteration with nonparametric function spaces},
	author       = {Farahmand, Amir-massoud and Ghavamzadeh, Mohammad and Szepesv{\'a}ri, Csaba and Mannor, Shie},
	year         = 2016,
	journal      = JMLR,
	publisher    = {JMLR. org},
	volume       = 17,
	number       = 1,
	pages        = {4809--4874}
}
@article{yin2020near,
	title        = {Near Optimal Provable Uniform Convergence in Off-Policy Evaluation for Reinforcement Learning},
	author       = {Yin, Ming and Bai, Yu and Wang, Yu-Xiang},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2007.03760}
}
@article{liao2020batch,
	title        = {Batch Policy Learning in Average Reward {M}arkov Decision Processes},
	author       = {Liao, Peng and Qi, Zhengling and Murphy, Susan},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2007.11771}
}
@inproceedings{uehara2020minimax,
	title        = {Minimax weight and {Q}-function learning for off-policy evaluation},
	author       = {Uehara, Masatoshi and Huang, Jiawei and Jiang, Nan},
	year         = 2020,
	booktitle    = {International Conference on Machine Learning},
	pages        = {9659--9668}
}
@inproceedings{zhang2019gendice,
	title        = {Gen{DICE}: Generalized Offline Estimation of Stationary Values},
	author       = {Zhang, Ruiyi and Dai, Bo and Li, Lihong and Schuurmans, Dale},
	year         = 2020,
	booktitle    = {International Conference on Learning Representations}
}
@inproceedings{yang2020off,
	title        = {Off-Policy Evaluation via the Regularized {L}agrangian},
	author       = {Yang, Mengjiao and Nachum, Ofir and Dai, Bo and Li, Lihong and Schuurmans, Dale},
	year         = 2020,
	booktitle    = NIPS
}
@article{tang2019doubly,
	title        = {Doubly robust bias reduction in infinite horizon off-policy estimation},
	author       = {Tang, Ziyang and Feng, Yihao and Li, Lihong and Zhou, Dengyong and Liu, Qiang},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1910.07186}
}
@inproceedings{liu2018breaking,
	title        = {Breaking the curse of horizon: Infinite-horizon off-policy estimation},
	author       = {Liu, Qiang and Li, Lihong and Tang, Ziyang and Zhou, Dengyong},
	year         = 2018,
	booktitle    = NIPS
}
@article{xie2020q,
	title        = {{$Q^{\star}$}-Approximation Schemes for Batch Reinforcement Learning: A Theoretical Comparison},
	author       = {Xie, Tengyang and Jiang, Nan},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2003.03924}
}
@article{kallus2020doubly,
	title        = {Doubly Robust Off-Policy Value and Gradient Estimation for Deterministic Policies},
	author       = {Kallus, Nathan and Uehara, Masatoshi},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2006.03900}
}
@article{wang2020statistical,
	title        = {What are the Statistical Limits of Offline {RL} with Linear Function Approximation?},
	author       = {Wang, Ruosong and Foster, Dean P and Kakade, Sham M},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2010.11895}
}
@article{xie2020batch,
	title        = {Batch value-function approximation with only realizability},
	author       = {Xie, Tengyang and Jiang, Nan},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2008.04990}
}
@inproceedings{nachum2019dualdice,
	title        = {Dual{DICE}: Behavior-agnostic estimation of discounted stationary distribution corrections},
	author       = {Nachum, Ofir and Chow, Yinlam and Dai, Bo and Li, Lihong},
	year         = 2019,
	booktitle    = {Advances in Neural Information Processing Systems}
}
@article{kallus2019efficiently,
  title={Efficiently Breaking the Curse of Horizon in Off-Policy Evaluation with Double Reinforcement Learning},
  author={Kallus, Nathan and Uehara, Masatoshi},
    year={2019},
  journal={arXiv preprint arXiv:1909.05850}
}


@article{nachum2019algaedice,
	title        = {Algae{DICE}: Policy gradient from arbitrary experience},
	author       = {Nachum, Ofir and Dai, Bo and Kostrikov, Ilya and Chow, Yinlam and Li, Lihong and Schuurmans, Dale},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1912.02074}
}
@article{nachum2020reinforcement,
	title        = {Reinforcement learning via {F}enchel-{R}ockafellar duality},
	author       = {Nachum, Ofir and Dai, Bo},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2001.01866}
}
@inproceedings{jiang2020minimax,
	title        = {Minimax Value Interval for Off-Policy Evaluation and Policy Optimization},
	author       = {Jiang, Nan and Huang, Jiawei},
	year         = 2020,
	booktitle      = {Advances in Neural Information Processing Systems}
}
@inproceedings{zhang2020variational,
	title        = {Variational policy gradient method for reinforcement learning with general utilities},
	author       = {Zhang, Junyu and Koppel, Alec and Bedi, Amrit Singh and Szepesv{\'a}ri, Csaba and Wang, Mengdi},
	year         = 2020,
	booktitle      = {Advances in Neural Information Processing Systems}
}
@article{levine2020offline,
	title        = {Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
	author       = {Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2005.01643}
}
@article{fu2020d4rl,
	title        = {{D4RL}: Datasets for deep data-driven reinforcement learning},
	author       = {Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2004.07219}
}
@inproceedings{fujimoto2019off,
	title        = {Off-policy deep reinforcement learning without exploration},
	author       = {Fujimoto, Scott and Meger, David and Precup, Doina},
	year         = 2019,
	booktitle    = {International Conference on Machine Learning},
	pages        = {2052--2062}
}
@inproceedings{kumar2019stabilizing,
	title        = {Stabilizing off-policy {Q}-learning via bootstrapping error reduction},
	author       = {Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
	year         = 2019,
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {11784--11794}
}
@article{wu2019behavior,
	title        = {Behavior regularized offline reinforcement learning},
	author       = {Wu, Yifan and Tucker, George and Nachum, Ofir},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1911.11361}
}
@article{liu2020provably,
	title        = {Provably good batch reinforcement learning without great exploration},
	author       = {Liu, Yao and Swaminathan, Adith and Agarwal, Alekh and Brunskill, Emma},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2007.08202}
}
@inproceedings{wang2020critic,
	title        = {Critic regularized regression},
	author       = {Wang, Ziyu and Novikov, Alexander and Zolna, Konrad and Merel, Josh S and Springenberg, Jost Tobias and Reed, Scott E and Shahriari, Bobak and Siegel, Noah and Gulcehre, Caglar and Heess, Nicolas and others},
	year         = 2020,
	booktitle      = {Advances in Neural Information Processing Systems}
}
@article{siegel2020keep,
	title        = {Keep doing what worked: Behavioral modelling priors for offline reinforcement learning},
	author       = {Siegel, Noah Y and Springenberg, Jost Tobias and Berkenkamp, Felix and Abdolmaleki, Abbas and Neunert, Michael and Lampe, Thomas and Hafner, Roland and Riedmiller, Martin},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2002.08396}
}
@article{nair2020accelerating,
	title        = {Accelerating online reinforcement learning with offline datasets},
	author       = {Nair, Ashvin and Dalal, Murtaza and Gupta, Abhishek and Levine, Sergey},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2006.09359}
}
@article{yu2020mopo,
	title        = {{MOPO}: Model-based Offline Policy Optimization},
	author       = {Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2005.13239}
}
@article{kidambi2020morel,
	title        = {{MOReL}: Model-Based Offline Reinforcement Learning},
	author       = {Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2005.05951}
}
@inproceedings{laroche2019safe,
	title        = {Safe policy improvement with baseline bootstrapping},
	author       = {Laroche, Romain and Trichelair, Paul and Des Combes, Remi Tachet},
	year         = 2019,
	booktitle    = {International Conference on Machine Learning},
	pages        = {3652--3661}
}
@inproceedings{agarwal2020optimistic,
	title        = {An optimistic perspective on offline reinforcement learning},
	author       = {Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
	year         = 2020,
	booktitle    = {International Conference on Machine Learning},
	pages        = {104--114}
}
@article{gulcehre2020rl,
	title        = {{RL} {U}nplugged: Benchmarks for offline reinforcement learning},
	author       = {Gulcehre, Caglar and Wang, Ziyu and Novikov, Alexander and Paine, Tom Le and Colmenarejo, Sergio G{\'o}mez and Zolna, Konrad and Agarwal, Rishabh and Merel, Josh and Mankowitz, Daniel and Paduraru, Cosmin and others},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2006.13888}
}
@article{azar2017minimax,
	title        = {Minimax regret bounds for reinforcement learning},
	author       = {Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
	year         = 2017,
	journal      = {arXiv preprint arXiv:1703.05449}
}
@inproceedings{jin2018q,
	title        = {Is {Q}-learning provably efficient?},
	author       = {Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
	year         = 2018,
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {4863--4873}
}
@article{yang2020bridging,
	title        = {Bridging Exploration and General Function Approximation in Reinforcement Learning: Provably Efficient Kernel and Neural Value Iterations},
	author       = {Yang, Zhuoran and Jin, Chi and Wang, Zhaoran and Wang, Mengdi and Jordan, Michael I},
	year         = 2020,
	journal      = {arXiv preprint arXiv:2011.04622}
}
@inproceedings{osband2014model,
	title        = {Model-based reinforcement learning and the eluder dimension},
	author       = {Osband, Ian and Van Roy, Benjamin},
	year         = 2014,
	booktitle      = {Advances in Neural Information Processing Systems}
}
@inproceedings{russo2013eluder,
	title        = {Eluder dimension and the sample complexity of optimistic exploration},
	author       = {Russo, Daniel and Van Roy, Benjamin},
	year         = 2013,
	booktitle    = {Advances in Neural Information Processing Systems},
	pages        = {2256--2264}
}
@inproceedings{wang2020reinforcement,
	title        = {Reinforcement Learning with General Value Function Approximation: Provably Efficient Approach via Bounded Eluder Dimension},
	author       = {Wang, Ruosong and Salakhutdinov, Russ R and Yang, Lin},
	year         = 2020,
	booktitle      = {Advances in Neural Information Processing Systems}
}
@inproceedings{yang2019sample,
	title        = {Sample-Optimal Parametric {Q}-Learning Using Linearly Additive Features},
	author       = {Yang, Lin and Wang, Mengdi},
	year         = 2019,
	booktitle    = {International Conference on Machine Learning},
	pages        = {6995--7004}
}
@article{still2012information,
	title        = {An information-theoretic approach to curiosity-driven reinforcement learning},
	author       = {Still, Susanne and Precup, Doina},
	year         = 2012,
	journal      = {Theory in Biosciences},
	publisher    = {Springer},
	volume       = 131,
	number       = 3,
	pages        = {139--148}
}
@article{schmidhuber2010formal,
	title        = {Formal theory of creativity, fun, and intrinsic motivation (1990--2010)},
	author       = {Schmidhuber, J{\"u}rgen},
	year         = 2010,
	journal      = {IEEE Transactions on Autonomous Mental Development},
	publisher    = {Ieee},
	volume       = 2,
	number       = 3,
	pages        = {230--247}
}
@inproceedings{schmidhuber1991curious,
	title        = {Curious model-building control systems},
	author       = {Schmidhuber, J{\"u}rgen},
	year         = 1991,
	booktitle    = {International Joint Conference on Neural Networks},
	pages        = {1458--1463}
}
@inproceedings{sun2011planning,
	title        = {Planning to be surprised: Optimal {B}ayesian exploration in dynamic environments},
	author       = {Sun, Yi and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
	year         = 2011,
	booktitle    = {International Conference on Artificial General Intelligence},
	pages        = {41--51}
}
@inproceedings{houthooft2016vime,
	title        = {{VIME}: Variational information maximizing exploration},
	author       = {Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
	year         = 2016,
	booktitle      = {Advances in Neural Information Processing Systems}
}
@article{donoho1994ideal,
	title        = {Ideal spatial adaptation by wavelet shrinkage},
	author       = {Donoho, David L and Johnstone, Jain M},
	year         = 1994,
	journal      = {Biometrika},
	publisher    = {Oxford University Press},
	volume       = 81,
	number       = 3,
	pages        = {425--455}
}
@article{fan2001variable,
	title        = {Variable selection via nonconcave penalized likelihood and its oracle properties},
	author       = {Fan, Jianqing and Li, Runze},
	year         = 2001,
	journal      = JASA,
	publisher    = {Taylor \& Francis},
	volume       = 96,
	number       = 456,
	pages        = {1348--1360}
}
@article{zou2006adaptive,
	title        = {The adaptive {L}asso and its oracle properties},
	author       = {Zou, Hui},
	year         = 2006,
	journal      = JASA,
	publisher    = {Taylor \& Francis},
	volume       = 101,
	number       = 476,
	pages        = {1418--1429}
}
@article{ayoub2020model,
  title={Model-Based Reinforcement Learning with Value-Targeted Regression},
  author={Ayoub, Alex and Jia, Zeyu and Szepesvari, Csaba and Wang, Mengdi and Yang, Lin F},
  journal={arXiv preprint arXiv:2006.01107},
  year={2020}
}



@inproceedings{yin2020asymptotic,
	title = {Asymptotically Efficient Off-Policy Evaluation for Tabular Reinforcement Learning},
	author = {Yin, Ming and Wang, Yu-Xiang},
	booktitle = {International Conference on Artificial Intelligence and Statistics},
	pages = {3948--3958},
	year = {2020} }




	@inproceedings{jiang2016doubly,
	  title={Doubly robust off-policy value evaluation for reinforcement learning},
	  author={Jiang, Nan and Li, Lihong},
	  booktitle={International Conference on Machine Learning},
	  pages={652--661},
	  year={2016}
	}

	@inproceedings{thomas2016data,
  title={Data-efficient off-policy policy evaluation for reinforcement learning},
  author={Thomas, Philip and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={2139--2148},
  year={2016}
}



@inproceedings{farajtabar2018more,
  title={More Robust Doubly Robust Off-policy Evaluation},
  author={Farajtabar, Mehrdad and Chow, Yinlam and Ghavamzadeh, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={1447--1456},
  year={2018}
}



@inproceedings{liu2019neural,
  title={Neural trust region/proximal policy optimization attains globally optimal policy},
  author={Liu, Boyi and Cai, Qi and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10565--10576},
  year={2019}
}


@inproceedings{wang2019neural,
  title={Neural Policy Gradient Methods: Global Optimality and Rates of Convergence},
  author={Wang, Lingxiao and Cai, Qi and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={International Conference on Learning Representations},
  year={2019}
}



@article{fu2020single,
  title={Single-timescale actor-critic provably finds globally optimal policy},
  author={Fu, Zuyue and Yang, Zhuoran and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2008.00483},
  year={2020}
}

@article{jaques2019way,
  title={Way off-policy batch deep reinforcement learning of implicit human preferences in dialog},
  author={Jaques, Natasha and Ghandeharioun, Asma and Shen, Judy Hanwen and Ferguson, Craig and Lapedriza, Agata and Jones, Noah and Gu, Shixiang and Picard, Rosalind},
  journal={arXiv preprint arXiv:1907.00456},
  year={2019}
}

@article{russo2018learning,
  title={Learning to optimize via information-directed sampling},
  author={Russo, Daniel and Van Roy, Benjamin},
  journal={Operations Research},
  volume={66},
  number={1},
  pages={230--252},
  year={2018}
}

@article{russo2016information,
  title={An information-theoretic analysis of {T}hompson sampling},
  author={Russo, Daniel and Van Roy, Benjamin},
  journal=JMLR,
  volume={17},
  number={1},
  pages={2442--2471},
  year={2016}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{silver2016mastering,
	Author = {Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc},
	Date-Added = {2018-08-04 01:14:31 +0000},
	Date-Modified = {2018-08-04 01:14:32 +0000},
	Journal = {Nature},
	Number = {7587},
	Pages = {484--489},
	Publisher = {Nature Research},
	Title = {Mastering the game of {G}o with deep neural networks and tree search},
	Volume = {529},
	Year = {2016}}

@article{silver2017mastering,
	Author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian},
	Journal = {Nature},
	Number = {7676},
	Pages = {354},
	Publisher = {Nature Publishing Group},
	Title = {Mastering the game of {G}o without human knowledge},
	Volume = {550},
	Year = {2017}}

@article{vinyals2017starcraft,
  title={Star{C}raft {II}: A new challenge for reinforcement learning},
  author={Vinyals, Oriol and Ewalds, Timo and Bartunov, Sergey and Georgiev, Petko and Vezhnevets, Alexander Sasha and Yeo, Michelle and Makhzani, Alireza and K{\"u}ttler, Heinrich and Agapiou, John and Schrittwieser, Julian and others},
  journal={arXiv preprint arXiv:1708.04782},
  year={2017}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={Nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{bellemare2013arcade,
  title={The {A}rcade {L}earning {E}nvironment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012}
}

@article{gottesman2019guidelines,
  title={Guidelines for reinforcement learning in healthcare},
  author={Gottesman, O and Johansson, F and Komorowski, M and Faisal, A and Sontag, D and Doshi-Velez, F and Celi, LA},
  journal={Nature Medicine},
  volume={25},
  number={1},
  pages={16--32},
  year={2019}
}

@article{shalev2016safe,
  title={Safe, multi-agent, reinforcement learning for autonomous driving},
  author={Shalev-Shwartz, Shai and Shammah, Shaked and Shashua, Amnon},
  journal={arXiv preprint arXiv:1610.03295},
  year={2016}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT}
}

@book{szepesvari2010algorithms,
  title={Algorithms for reinforcement learning},
  author={Szepesv{\'a}ri, Csaba},
  year={2010},
  publisher={Morgan \& Claypool}
}

@article{jaksch2010near,
  title={Near-optimal Regret Bounds for Reinforcement Learning.},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={4},
  pages={8--36},
  year={2010}
}

@article{chakraborty2014dynamic,
  title={Dynamic treatment regimes},
  author={Chakraborty, Bibhas and Murphy, Susan A},
  journal={Annual Review of Statistics and Its Application},
  volume={1},
  pages={447--464},
  year={2014}
}

@inproceedings{sun2020scalability,
  title={Scalability in perception for autonomous driving: {W}aymo open dataset},
  author={Sun, Pei and Kretzschmar, Henrik and Dotiwalla, Xerxes and Chouard, Aurelien and Patnaik, Vijaysai and Tsui, Paul and Guo, James and Zhou, Yin and Chai, Yuning and Caine, Benjamin and others},
  booktitle={Computer Vision and Pattern Recognition},
  pages={2446--2454},
  year={2020}
}

@book{lattimore2020bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge}
}

@book{agarwal2019reinforcement,
  title={Reinforcement learning: {T}heory and algorithms},
  author={Agarwal, Alekh and Jiang, Nan and Kakade, Sham M},
  year={2020},
  publisher={MIT}
}

@article{xie2018off,
  title={Off-policy evaluation and learning from logged bandit feedback: Error reduction via surrogate policy},
  author={Xie, Yuan and Liu, Boyi and Liu, Qiang and Wang, Zhaoran and Zhou, Yuan and Peng, Jian},
  journal={arXiv preprint arXiv:1808.00232},
  year={2018}
}

@article{yang2020function,
  title={On function approximation in reinforcement learning: Optimism in the face of large state spaces},
  author={Yang, Zhuoran and Jin, Chi and Wang, Zhaoran and Wang, Mengdi and Jordan, Michael I},
  journal={arXiv preprint arXiv:2011.04622},
  year={2020}
}

@book{steinwart2008support,
  title={Support vector machines},
  author={Steinwart, Ingo and Christmann, Andreas},
  year={2008},
  publisher={Springer Science \& Business Media}
}

@article{srinivas2009gaussian,
  title={Gaussian process optimization in the bandit setting: No regret and experimental design},
  author={Srinivas, Niranjan and Krause, Andreas and Kakade, Sham M and Seeger, Matthias},
  journal={arXiv preprint arXiv:0912.3995},
  year={2009}
}

@article{zhang2005learning,
  title={Learning bounds for kernel regression using effective data dimensionality},
  author={Zhang, Tong},
  journal={Neural Computation},
  volume={17},
  number={9},
  pages={2077--2098},
  year={2005},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@book{yurinsky2006sums,
  title={Sums and Gaussian vectors},
  author={Yurinsky, Vadim},
  year={2006},
  publisher={Springer}
}



@inproceedings{zanette2021cautiously,
  title={Cautiously optimistic policy optimization and exploration with linear function approximation},
  author={Zanette, Andrea and Cheng, Ching-An and Agarwal, Alekh},
  booktitle={Conference on Learning Theory},
  pages={4473--4525},
  year={2021},
  organization={PMLR}
}

@book{vershynin2018high,
  title={High-dimensional probability: An introduction with applications in data science},
  author={Vershynin, Roman},
  volume={47},
  year={2018},
  publisher={Cambridge university press}
}
 