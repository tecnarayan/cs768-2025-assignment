\begin{thebibliography}{39}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Becker and Hinton(1992)]{becker1992self}
Suzanna Becker and Geoffrey~E Hinton.
\newblock Self-organizing neural network that discovers surfaces in random-dot
  stereograms.
\newblock \emph{Nature}, 355\penalty0 (6356):\penalty0 161--163, 1992.

\bibitem[Dosovitskiy et~al.(2014)Dosovitskiy, Springenberg, Riedmiller, and
  Brox]{dosovitskiy2014discriminative}
Alexey Dosovitskiy, Jost~Tobias Springenberg, Martin Riedmiller, and Thomas
  Brox.
\newblock Discriminative unsupervised feature learning with convolutional
  neural networks.
\newblock In \emph{Advances in neural information processing systems}, pages
  766--774, 2014.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Wu et~al.(2018)Wu, Xiong, Yu, and Lin]{wu2018unsupervised}
Zhirong Wu, Yuanjun Xiong, Stella~X Yu, and Dahua Lin.
\newblock Unsupervised feature learning via non-parametric instance
  discrimination.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 3733--3742, 2018.

\bibitem[Hjelm et~al.(2018)Hjelm, Fedorov, Lavoie-Marchildon, Grewal, Bachman,
  Trischler, and Bengio]{hjelm2018learning}
R~Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil
  Bachman, Adam Trischler, and Yoshua Bengio.
\newblock Learning deep representations by mutual information estimation and
  maximization.
\newblock \emph{arXiv preprint arXiv:1808.06670}, 2018.

\bibitem[Bachman et~al.(2019)Bachman, Hjelm, and
  Buchwalter]{bachman2019learning}
Philip Bachman, R~Devon Hjelm, and William Buchwalter.
\newblock Learning representations by maximizing mutual information across
  views.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  15509--15519, 2019.

\bibitem[H{\'e}naff et~al.(2019)H{\'e}naff, Razavi, Doersch, Eslami, and
  Oord]{henaff2019data}
Olivier~J H{\'e}naff, Ali Razavi, Carl Doersch, SM~Eslami, and Aaron van~den
  Oord.
\newblock Data-efficient image recognition with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1905.09272}, 2019.

\bibitem[Tian et~al.(2019)Tian, Krishnan, and Isola]{tian2019contrastive}
Yonglong Tian, Dilip Krishnan, and Phillip Isola.
\newblock Contrastive multiview coding.
\newblock \emph{arXiv preprint arXiv:1906.05849}, 2019.

\bibitem[Misra and van~der Maaten(2019)]{misra2019self}
Ishan Misra and Laurens van~der Maaten.
\newblock Self-supervised learning of pretext-invariant representations.
\newblock \emph{arXiv preprint arXiv:1912.01991}, 2019.

\bibitem[He et~al.(2019)He, Fan, Wu, Xie, and Girshick]{he2019momentum}
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock \emph{arXiv preprint arXiv:1911.05722}, 2019.

\bibitem[Li et~al.(2020)Li, Zhou, Xiong, Socher, and Hoi]{li2020prototypical}
Junnan Li, Pan Zhou, Caiming Xiong, Richard Socher, and Steven~CH Hoi.
\newblock Prototypical contrastive learning of unsupervised representations.
\newblock \emph{arXiv preprint arXiv:2005.04966}, 2020.

\bibitem[Tian et~al.(2020{\natexlab{a}})Tian, Sun, Poole, Krishnan, Schmid, and
  Isola]{tian2020makes}
Yonglong Tian, Chen Sun, Ben Poole, Dilip Krishnan, Cordelia Schmid, and
  Phillip Isola.
\newblock What makes for good views for contrastive learning.
\newblock \emph{arXiv preprint arXiv:2005.10243}, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Kornblith, Norouzi, and
  Hinton]{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock \emph{arXiv preprint arXiv:2002.05709}, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Kornblith, Swersky, Norouzi, and
  Hinton]{chen2020big}
Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey
  Hinton.
\newblock Big self-supervised models are strong semi-supervised learners.
\newblock \emph{arXiv preprint arXiv:2006.10029}, 2020{\natexlab{b}}.

\bibitem[Sohn(2016)]{sohn2016improved}
Kihyuk Sohn.
\newblock Improved deep metric learning with multi-class n-pair loss objective.
\newblock In \emph{Advances in neural information processing systems}, pages
  1857--1865, 2016.

\bibitem[Wang and Isola(2020)]{wang2020understanding}
Tongzhou Wang and Phillip Isola.
\newblock Understanding contrastive representation learning through alignment
  and uniformity on the hypersphere.
\newblock \emph{arXiv preprint arXiv:2005.10242}, 2020.

\bibitem[Rabin et~al.(2011)Rabin, Peyr{\'e}, Delon, and
  Bernot]{rabin2011wasserstein}
Julien Rabin, Gabriel Peyr{\'e}, Julie Delon, and Marc Bernot.
\newblock Wasserstein barycenter and its application to texture mixing.
\newblock In \emph{International Conference on Scale Space and Variational
  Methods in Computer Vision}, pages 435--446. Springer, 2011.

\bibitem[Bonneel et~al.(2015)Bonneel, Rabin, Peyr{\'e}, and
  Pfister]{bonneel2015sliced}
Nicolas Bonneel, Julien Rabin, Gabriel Peyr{\'e}, and Hanspeter Pfister.
\newblock Sliced and radon wasserstein barycenters of measures.
\newblock \emph{Journal of Mathematical Imaging and Vision}, 51\penalty0
  (1):\penalty0 22--45, 2015.

\bibitem[Kolouri et~al.(2019)Kolouri, Nadjahi, Simsekli, Badeau, and
  Rohde]{kolouri2019generalized}
Soheil Kolouri, Kimia Nadjahi, Umut Simsekli, Roland Badeau, and Gustavo Rohde.
\newblock Generalized sliced wasserstein distances.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  261--272, 2019.

\bibitem[Poole et~al.(2019)Poole, Ozair, Oord, Alemi, and
  Tucker]{poole2019variational}
Ben Poole, Sherjil Ozair, Aaron van~den Oord, Alexander~A Alemi, and George
  Tucker.
\newblock On variational bounds of mutual information.
\newblock \emph{arXiv preprint arXiv:1905.06922}, 2019.

\bibitem[You et~al.(2017)You, Gitman, and Ginsburg]{you2017large}
Yang You, Igor Gitman, and Boris Ginsburg.
\newblock Large batch training of convolutional networks.
\newblock \emph{arXiv preprint arXiv:1708.03888}, 2017.

\bibitem[Grill et~al.(2020)Grill, Strub, Altché, Tallec, Richemond,
  Buchatskaya, Doersch, Pires, Guo, Azar, Piot, Kavukcuoglu, Munos, and
  Valko]{grill2020bootstrap}
Jean-Bastien Grill, Florian Strub, Florent Altché, Corentin Tallec, Pierre~H.
  Richemond, Elena Buchatskaya, Carl Doersch, Bernardo~Avila Pires,
  Zhaohan~Daniel Guo, Mohammad~Gheshlaghi Azar, Bilal Piot, Koray Kavukcuoglu,
  Rémi Munos, and Michal Valko.
\newblock Bootstrap your own latent: A new approach to self-supervised
  learning, 2020.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan,
  Doll{\'a}r, and Zitnick]{lin2014microsoft}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In \emph{European conference on computer vision}, pages 740--755.
  Springer, 2014.

\bibitem[Kingma and Welling(2013)]{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Rezende et~al.(2014)Rezende, Mohamed, and
  Wierstra]{rezende2014stochastic}
Danilo~Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock \emph{arXiv preprint arXiv:1401.4082}, 2014.

\bibitem[Caron et~al.(2020)Caron, Misra, Mairal, Goyal, Bojanowski, and
  Joulin]{caron2020unsupervised}
Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Piotr Bojanowski, and
  Armand Joulin.
\newblock Unsupervised learning of visual features by contrasting cluster
  assignments.
\newblock \emph{arXiv preprint arXiv:2006.09882}, 2020.

\bibitem[McAllester and Stratos(2020)]{mcallester2020formal}
David McAllester and Karl Stratos.
\newblock Formal limitations on the measurement of mutual information.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 875--884, 2020.

\bibitem[Song and Ermon(2019)]{song2019understanding}
Jiaming Song and Stefano Ermon.
\newblock Understanding the limitations of variational mutual information
  estimators.
\newblock \emph{arXiv preprint arXiv:1910.06222}, 2019.

\bibitem[Tschannen et~al.(2019)Tschannen, Djolonga, Rubenstein, Gelly, and
  Lucic]{tschannen2019mutual}
Michael Tschannen, Josip Djolonga, Paul~K Rubenstein, Sylvain Gelly, and Mario
  Lucic.
\newblock On mutual information maximization for representation learning.
\newblock \emph{arXiv preprint arXiv:1907.13625}, 2019.

\bibitem[Arora et~al.(2019)Arora, Khandeparkar, Khodak, Plevrakis, and
  Saunshi]{arora2019theoretical}
Sanjeev Arora, Hrishikesh Khandeparkar, Mikhail Khodak, Orestis Plevrakis, and
  Nikunj Saunshi.
\newblock A theoretical analysis of contrastive unsupervised representation
  learning.
\newblock \emph{arXiv preprint arXiv:1902.09229}, 2019.

\bibitem[Tsai et~al.(2020)Tsai, Wu, Salakhutdinov, and
  Morency]{tsai2020demystifying}
Yao-Hung~Hubert Tsai, Yue Wu, Ruslan Salakhutdinov, and Louis-Philippe Morency.
\newblock Demystifying self-supervised learning: An information-theoretical
  framework.
\newblock \emph{arXiv preprint arXiv:2006.05576}, 2020.

\bibitem[Tosh et~al.(2020)Tosh, Krishnamurthy, and Hsu]{tosh2020contrastive}
Christopher Tosh, Akshay Krishnamurthy, and Daniel Hsu.
\newblock Contrastive learning, multi-view redundancy, and linear models.
\newblock \emph{arXiv preprint arXiv:2008.10150}, 2020.

\bibitem[Tian et~al.(2020{\natexlab{b}})Tian, Yu, Chen, and
  Ganguli]{tian2020understanding}
Yuandong Tian, Lantao Yu, Xinlei Chen, and Surya Ganguli.
\newblock Understanding self-supervised learning with dual deep networks.
\newblock \emph{arXiv preprint arXiv:2010.00578}, 2020{\natexlab{b}}.

\bibitem[Lee et~al.(2020)Lee, Lei, Saunshi, and Zhuo]{lee2020predicting}
Jason~D Lee, Qi~Lei, Nikunj Saunshi, and Jiacheng Zhuo.
\newblock Predicting what you already know helps: Provable self-supervised
  learning.
\newblock \emph{arXiv preprint arXiv:2008.01064}, 2020.

\bibitem[Zhao et~al.(2020)Zhao, Wu, Lau, and Lin]{zhao2020makes}
Nanxuan Zhao, Zhirong Wu, Rynson~WH Lau, and Stephen Lin.
\newblock What makes instance discrimination good for transfer learning?
\newblock \emph{arXiv preprint arXiv:2006.06606}, 2020.

\bibitem[Purushwalkam and Gupta(2020)]{purushwalkam2020demystifying}
Senthil Purushwalkam and Abhinav Gupta.
\newblock Demystifying contrastive self-supervised learning: Invariances,
  augmentations and dataset biases.
\newblock \emph{arXiv preprint arXiv:2007.13916}, 2020.

\bibitem[Hermann and Lampinen(2020)]{hermann2020shapes}
Katherine~L Hermann and Andrew~K Lampinen.
\newblock What shapes feature representations? exploring datasets,
  architectures, and training.
\newblock \emph{arXiv preprint arXiv:2006.12433}, 2020.

\bibitem[Shah et~al.(2020)Shah, Tamuly, Raghunathan, Jain, and
  Netrapalli]{shah2020pitfalls}
Harshay Shah, Kaustav Tamuly, Aditi Raghunathan, Prateek Jain, and Praneeth
  Netrapalli.
\newblock The pitfalls of simplicity bias in neural networks.
\newblock \emph{arXiv preprint arXiv:2006.07710}, 2020.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\end{thebibliography}
