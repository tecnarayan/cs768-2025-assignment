// related work

@inproceedings{li2015delving,
  title={Delving into egocentric actions},
  author={Li, Yin and Ye, Zhefan and Rehg, James M},
  booktitle={CVPR},
  pages={287--295},
  year={2015}
}

@inproceedings{wray2021semantic,
  title={On Semantic Similarity in Video Retrieval},
  author={Wray, Michael and Doughty, Hazel and Damen, Dima},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{patrick2020support,
  title={Support-set bottlenecks for video-text representation learning},
  author={Patrick, Mandela and Huang, Po-Yao and Asano, Yuki and Metze, Florian and Hauptmann, Alexander and Henriques, Joao and Vedaldi, Andrea},
  booktitle={ICLR},
  year={2020}
}

@InProceedings{chen2021multimodal,
    author    = {Chen, Brian and Rouditchenko, Andrew and Duarte, Kevin and Kuehne, Hilde and Thomas, Samuel and Boggust, Angie and Panda, Rameswar and Kingsbury, Brian and Feris, Rogerio and Harwath, David and Glass, James and Picheny, Michael and Chang, Shih-Fu},
    title     = {Multimodal Clustering Networks for Self-Supervised Learning From Unlabeled Videos},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {8012-8021}
}

@InProceedings{chun2021probabilistic,
    author    = {Chun, Sanghyuk and Oh, Seong Joon and de Rezende, Rafael Sampaio and Kalantidis, Yannis and Larlus, Diane},
    title     = {Probabilistic Embeddings for Cross-Modal Retrieval},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    pages     = {8415-8424}
}

@inproceedings{sigurdsson2016hollywood,
	title={Hollywood in homes: Crowdsourcing data collection for activity understanding},
	author={Sigurdsson, Gunnar A and Varol, G{\"u}l and Wang, Xiaolong and Farhadi, Ali and Laptev, Ivan and Gupta, Abhinav},
	booktitle={ECCV},
	pages={510--526},
	year={2016},
	organization={Springer}
}

@inproceedings{zhou2018towards,
	title={Towards automatic learning of procedures from web instructional videos},
	author={Zhou, Luowei and Xu, Chenliang and Corso, Jason J},
	booktitle={AAAI},
	year={2018}
}

@inproceedings{krishna2017dense,
	title={Dense-captioning events in videos},
	author={Krishna, Ranjay and Hata, Kenji and Ren, Frederic and Fei-Fei, Li and Carlos Niebles, Juan},
	booktitle={ICCV},
	pages={706--715},
	year={2017}
}

@inproceedings{sharma2018conceptual,
	title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
	author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
	booktitle={ACL},
	pages={2556--2565},
	year={2018}
}

@article{damen2022rescaling,
	title={Rescaling Egocentric Vision: Collection, Pipeline and Challenges for EPIC-KITCHENS-100},
	author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Furnari, Antonino and Kazakos, Evangelos and Ma, Jian and Moltisanti, Davide and Munro, Jonathan and Perrett, Toby and Price, Will and others},
	journal={IJCV},
	volume={130},
	number={1},
	pages={33--55},
	year={2022},
	publisher={Springer}
}

@inproceedings{damen2018scaling,
	title={Scaling egocentric vision: The epic-kitchens dataset},
	author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Fidler, Sanja and Furnari, Antonino and Kazakos, Evangelos and Moltisanti, Davide and Munro, Jonathan and Perrett, Toby and Price, Will and others},
	booktitle={ECCV},
	pages={720--736},
	year={2018}
}

@inproceedings{lee2012discovering,
	title={Discovering important people and objects for egocentric video summarization},
	author={Lee, Yong Jae and Ghosh, Joydeep and Grauman, Kristen},
	booktitle={CVPR},
	pages={1346--1353},
	year={2012},
	organization={IEEE}
}

@article{sigurdsson2018charades,
	title={Charades-ego: A large-scale dataset of paired third and first person videos},
	author={Sigurdsson, Gunnar A and Gupta, Abhinav and Schmid, Cordelia and Farhadi, Ali and Alahari, Karteek},
	journal={arXiv preprint arXiv:1804.09626},
	year={2018}
}

@inproceedings{fathi2012social,
	title={Social interactions: A first-person perspective},
	author={Fathi, Alircza and Hodgins, Jessica K and Rehg, James M},
	booktitle={CVPR},
	pages={1226--1233},
	year={2012},
	organization={IEEE}
}

@inproceedings{bain2021frozen,
	title={Frozen in time: A joint video and image encoder for end-to-end retrieval},
	author={Bain, Max and Nagrani, Arsha and Varol, G{\"u}l and Zisserman, Andrew},
	booktitle={ICCV},
	pages={1728--1738},
	year={2021}
}


@inproceedings{miech2020end,
	title={End-to-end learning of visual representations from uncurated instructional videos},
	author={Miech, Antoine and Alayrac, Jean-Baptiste and Smaira, Lucas and Laptev, Ivan and Sivic, Josef and Zisserman, Andrew},
	booktitle={CVPR},
	pages={9879--9889},
	year={2020}
}
@article{luo2020univl,
	title={Univl: A unified video and language pre-training model for multimodal understanding and generation},
	author={Luo, Huaishao and Ji, Lei and Shi, Botian and Huang, Haoyang and Duan, Nan and Li, Tianrui and Li, Jason and Bharti, Taroon and Zhou, Ming},
	journal={arXiv preprint arXiv:2002.06353},
	year={2020}
}

@inproceedings{clipbert,
	title={Less is more: Clipbert for video-and-language learning via sparse sampling},
	author={Lei, Jie and Li, Linjie and Zhou, Luowei and Gan, Zhe and Berg, Tamara L and Bansal, Mohit and Liu, Jingjing},
	booktitle={CVPR},
	pages={7331--7341},
	year={2021}
}

@inproceedings{miech2019howto100m,
	title={Howto100m: Learning a text-video embedding by watching hundred million narrated video clips},
	author={Miech, Antoine and Zhukov, Dimitri and Alayrac, Jean-Baptiste and Tapaswi, Makarand and Laptev, Ivan and Sivic, Josef},
	booktitle={ICCV},
	pages={2630--2640},
	year={2019}
}
@inproceedings{grauman2021ego4d,
  title={Ego4d: Around the world in 3,000 hours of egocentric video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and others},
  booktitle={CVPR},
  pages={18995--19012},
  year={2022}
}

@inproceedings{xu2016msr,
	title={Msr-vtt: A large video description dataset for bridging video and language},
	author={Xu, Jun and Mei, Tao and Yao, Ting and Rui, Yong},
	booktitle={CVPR},
	pages={5288--5296},
	year={2016}
}
@article{rohrbach2017movie,
	title={Movie description},
	author={Rohrbach, Anna and Torabi, Atousa and Rohrbach, Marcus and Tandon, Niket and Pal, Christopher and Larochelle, Hugo and Courville, Aaron and Schiele, Bernt},
	journal={IJCV},
	volume={123},
	number={1},
	pages={94--120},
	year={2017},
	publisher={Springer}
}
// experiments
@inproceedings{zhang2020learning,
	title={Learning 2d temporal adjacent networks for moment localization with natural language},
	author={Zhang, Songyang and Peng, Houwen and Fu, Jianlong and Luo, Jiebo},
	booktitle={AAAI},
	volume={34},
	number={07},
	pages={12870--12877},
	year={2020}
}

@inproceedings{zhang2020span,
  title={Span-based Localizing Network for Natural Language Video Localization},
  author={Zhang, Hao and Sun, Aixin and Jing, Wei and Zhou, Joey Tianyi},
  booktitle={ACL},
  pages={6543--6554},
  year={2020}
}

@inproceedings{wray2019fine,
	title={Fine-grained action retrieval through multiple parts-of-speech embeddings},
	author={Wray, Michael and Larlus, Diane and Csurka, Gabriela and Damen, Dima},
	booktitle={ICCV},
	pages={450--459},
	year={2019}
}

@inproceedings{kazakos2019epic,
	title={Epic-fusion: Audio-visual temporal binding for egocentric action recognition},
	author={Kazakos, Evangelos and Nagrani, Arsha and Zisserman, Andrew and Damen, Dima},
	booktitle={ICCV},
	pages={5492--5501},
	year={2019}
}

@inproceedings{xie2018rethinking,
	title={Rethinking spatiotemporal feature learning: Speed-accuracy trade-offs in video classification},
	author={Xie, Saining and Sun, Chen and Huang, Jonathan and Tu, Zhuowen and Murphy, Kevin},
	booktitle={ECCV},
	pages={305--321},
	year={2018}
}

@inproceedings{graves2005bidirectional,
	title={Bidirectional LSTM networks for improved phoneme classification and recognition},
	author={Graves, Alex and Fern{\'a}ndez, Santiago and Schmidhuber, J{\"u}rgen},
	booktitle={ICANN},
	pages={799--804},
	year={2005},
	organization={Springer}
}

@inproceedings{carreira2017quo,
	title={Quo vadis, action recognition? a new model and the kinetics dataset},
	author={Carreira, Joao and Zisserman, Andrew},
	booktitle={CVPR},
	pages={6299--6308},
	year={2017}
}

@inproceedings{sigurdsson2018actor,
	title={Actor and observer: Joint modeling of first and third-person videos},
	author={Sigurdsson, Gunnar A and Gupta, Abhinav and Schmid, Cordelia and Farhadi, Ali and Alahari, Karteek},
	booktitle={CVPR},
	pages={7396--7404},
	year={2018}
}

@inproceedings{li2021ego,
	title={Ego-exo: Transferring visual representations from third-person to first-person videos},
	author={Li, Yanghao and Nagarajan, Tushar and Xiong, Bo and Grauman, Kristen},
	booktitle={CVPR},
	pages={6943--6953},
	year={2021}
}

@inproceedings{choi2020unsupervised,
	title={Unsupervised and semi-supervised domain adaptation for action recognition from drones},
	author={Choi, Jinwoo and Sharma, Gaurav and Chandraker, Manmohan and Huang, Jia-Bin},
	booktitle={WACV},
	pages={1717--1726},
	year={2020}
}

@article{gong2014diverse,
	title={Diverse sequential subset selection for supervised video summarization},
	author={Gong, Boqing and Chao, Wei-Lun and Grauman, Kristen and Sha, Fei},
	journal={NeurIPS},
	volume={27},
	year={2014}
}


@inproceedings{sharghi2017query,
	title={Query-focused video summarization: Dataset, evaluation, and a memory network based approach},
	author={Sharghi, Aidean and Laurel, Jacob S and Gong, Boqing},
	booktitle={CVPR},
	pages={4788--4797},
	year={2017}
}


@inproceedings{radford2021learning,
	title={Learning transferable visual models from natural language supervision},
	author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
	booktitle={ICML},
	pages={8748--8763},
	year={2021},
	organization={PMLR}
}

@inproceedings{xu2021videoclip,
	title={VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding},
	author={Xu, Hu and Ghosh, Gargi and Huang, Po-Yao and Okhonko, Dmytro and Aghajanyan, Armen and Metze, Florian and Zettlemoyer, Luke and Feichtenhofer, Christoph},
	booktitle={EMNLP},
	pages={6787--6800},
	year={2021}
}

@inproceedings{msrvttqamsvdqa,
  title={Video question answering via gradually refined attention over appearance and motion},
  author={Xu, Dejing and Zhao, Zhou and Xiao, Jun and Wu, Fei and Zhang, Hanwang and He, Xiangnan and Zhuang, Yueting},
  booktitle={MM},
  pages={1645--1653},
  year={2017}
}

@article{oatrans,
  title={Object-aware Video-language Pre-training for Retrieval},
  author={Wang, Alex Jinpeng and Ge, Yixiao and Cai, Guanyu and Yan, Rui and Lin, Xudong and Shan, Ying and Qie, Xiaohu and Shou, Mike Zheng},
  journal={CVPR},
  year={2022}
}

@inproceedings{timesformer,
  title={Is space-time attention all you need for video understanding?},
  author={Bertasius, Gedas and Wang, Heng and Torresani, Lorenzo},
  booktitle={ICML},
  volume={2},
  number={3},
  pages={4},
  year={2021}
}

@article{distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@article{infonce,
  title={Representation learning with contrastive predictive coding},
  author={Van den Oord, Aaron and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv e-prints},
  pages={arXiv--1807},
  year={2018}
}

@inproceedings{mil_nce,
  title={End-to-end learning of visual representations from uncurated instructional videos},
  author={Miech, Antoine and Alayrac, Jean-Baptiste and Smaira, Lucas and Laptev, Ivan and Sivic, Josef and Zisserman, Andrew},
  booktitle={CVPR},
  pages={9879--9889},
  year={2020}
}

@inproceedings{zhao2021video,
	title={Video self-stitching graph network for temporal action localization},
	author={Zhao, Chen and Thabet, Ali K and Ghanem, Bernard},
	booktitle={ICCV},
	pages={13658--13667},
	year={2021}
}

@inproceedings{clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{slowfast,
  title={Slowfast networks for video recognition},
  author={Feichtenhofer, Christoph and Fan, Haoqi and Malik, Jitendra and He, Kaiming},
  booktitle={ICCV},
  pages={6202--6211},
  year={2019}
}

@inproceedings{lei2021less,
  title={Less is more: Clipbert for video-and-language learning via sparse sampling},
  author={Lei, Jie and Li, Linjie and Zhou, Luowei and Gan, Zhe and Berg, Tamara L and Bansal, Mohit and Liu, Jingjing},
  booktitle={CVPR},
  pages={7331--7341},
  year={2021}
}

@InProceedings{Sun_2019_ICCV,
author = {Sun, Chen and Myers, Austin and Vondrick, Carl and Murphy, Kevin and Schmid, Cordelia},
title = {VideoBERT: A Joint Model for Video and Language Representation Learning},
booktitle = {ICCV},
month = {October},
year = {2019}
}

@article{escorcia2019temporal,
  title={Temporal localization of moments in video collections with natural language},
  author={Escorcia, Victor and Soldan, Mattia and Sivic, Josef and Ghanem, Bernard and Russell, Bryan},
  journal={arXiv preprint arXiv:1907.12763},
  year={2019}
}

@inproceedings{miech2021thinking,
  title={Thinking fast and slow: Efficient text-to-visual retrieval with transformers},
  author={Miech, Antoine and Alayrac, Jean-Baptiste and Laptev, Ivan and Sivic, Josef and Zisserman, Andrew},
  booktitle={CVPR},
  pages={9826--9836},
  year={2021}
}

@article{xu2021vlm,
  title={VLM: Task-agnostic video-language model pre-training for video understanding},
  author={Xu, Hu and Ghosh, Gargi and Huang, Po-Yao and Arora, Prahal and Aminzadeh, Masoumeh and Feichtenhofer, Christoph and Metze, Florian and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2105.09996},
  year={2021}
}

@inproceedings{yu2018joint,
  title={A joint sequence fusion model for video question answering and retrieval},
  author={Yu, Youngjae and Kim, Jongseok and Kim, Gunhee},
  booktitle={ECCV},
  pages={471--487},
  year={2018}
}

@inproceedings{zhu2020actbert,
  title={Actbert: Learning global-local video-text representations},
  author={Zhu, Linchao and Yang, Yi},
  booktitle={CVPR},
  pages={8746--8755},
  year={2020}
}
@article{li2020hero,
  title={Hero: Hierarchical encoder for video+ language omni-representation pre-training},
  author={Li, Linjie and Chen, Yen-Chun and Cheng, Yu and Gan, Zhe and Yu, Licheng and Liu, Jingjing},
  journal={arXiv preprint arXiv:2005.00200},
  year={2020}
}

@inproceedings{zhou2018end,
  title={End-to-end dense video captioning with masked transformer},
  author={Zhou, Luowei and Zhou, Yingbo and Corso, Jason J and Socher, Richard and Xiong, Caiming},
  booktitle={CVPR},
  pages={8739--8748},
  year={2018}
}

@inproceedings{hendricks2018localizing,
  title={Localizing Moments in Video with Temporal Language},
  author={Hendricks, Lisa Anne and Wang, Oliver and Shechtman, Eli and Sivic, Josef and Darrell, Trevor and Russell, Bryan},
  booktitle={EMNLP},
  year={2018}
}

@inproceedings{caba2015activitynet,
  title={Activitynet: A large-scale video benchmark for human activity understanding},
  author={Caba Heilbron, Fabian and Escorcia, Victor and Ghanem, Bernard and Carlos Niebles, Juan},
  booktitle={CVPR},
  pages={961--970},
  year={2015}
}

@inproceedings{ma2002user,
  title={A user attention model for video summarization},
  author={Ma, Yu-Fei and Lu, Lie and Zhang, Hong-Jiang and Li, Mingjing},
  booktitle={MM},
  pages={533--542},
  year={2002}
}

@inproceedings{gammulle2019predicting,
  title={Predicting the future: A jointly learnt model for action anticipation},
  author={Gammulle, Harshala and Denman, Simon and Sridharan, Sridha and Fookes, Clinton},
  booktitle={ICCV},
  pages={5562--5571},
  year={2019}
}

@inproceedings{abu2018will,
  title={When will you do what?-anticipating temporal occurrences of activities},
  author={Abu Farha, Yazan and Richard, Alexander and Gall, Juergen},
  booktitle={CVPR},
  pages={5343--5352},
  year={2018}
}

#CTRL Charades-STA
@InProceedings{Gao_2017_ICCV,
    author = "{Gao Jiyang, Sun Chen, Yang Zhenheng, Nevatia, Ram}",
    title = "{TALL: Temporal Activity Localization via Language Query}",
    booktitle = {ICCV},
    year = {2017}
}

@inproceedings{soldan2021vlg,
  title={VLG-Net: Video-language graph matching network for video grounding},
  author={Soldan, Mattia and Xu, Mengmeng and Qu, Sisi and Tegner, Jesper and Ghanem, Bernard},
  booktitle={ICCV},
  pages={3224--3234},
  year={2021}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{dosovitskiy2020image,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={ICLR},
  year={2020}
}

% wl
@inproceedings{chen2017sca,
  title={Sca-cnn: Spatial and channel-wise attention in convolutional networks for image captioning},
  author={Chen, Long and Zhang, Hanwang and Xiao, Jun and Nie, Liqiang and Shao, Jian and Liu, Wei and Chua, Tat-Seng},
  booktitle={CVPR},
  pages={5659--5667},
  year={2017}
}

@inproceedings{jiang2018recurrent,
  title={Recurrent fusion network for image captioning},
  author={Jiang, Wenhao and Ma, Lin and Jiang, Yu-Gang and Liu, Wei and Zhang, Tong},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={499--515},
  year={2018}
}

@inproceedings{chen2021human,
  title={Human-like controllable image captioning with verb-specific semantic roles},
  author={Chen, Long and Jiang, Zhihong and Xiao, Jun and Liu, Wei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16846--16856},
  year={2021}
}

@inproceedings{wang2018reconstruction,
  title={Reconstruction network for video captioning},
  author={Wang, Bairui and Ma, Lin and Zhang, Wei and Liu, Wei},
  booktitle={CVPR},
  pages={7622--7631},
  year={2018}
}

@inproceedings{wang2019controllable,
  title={Controllable video captioning with pos sequence guidance based on gated fusion network},
  author={Wang, Bairui and Ma, Lin and Zhang, Wei and Jiang, Wenhao and Wang, Jingwen and Liu, Wei},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={2641--2650},
  year={2019}
}

@inproceedings{chen2020learning,
  title={Learning modality interaction for temporal sentence localization and event captioning in videos},
  author={Chen, Shaoxiang and Jiang, Wenhao and Liu, Wei and Jiang, Yu-Gang},
  booktitle={European Conference on Computer Vision},
  pages={333--351},
  year={2020},
  organization={Springer}
}

@article{miech2018learning,
  title={Learning a text-video embedding from incomplete and heterogeneous data},
  author={Miech, Antoine and Laptev, Ivan and Sivic, Josef},
  journal={arXiv preprint arXiv:1804.02516},
  year={2018}
}

@inproceedings{liu2022video,
  title={Video swin transformer},
  author={Liu, Ze and Ning, Jia and Cao, Yue and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Hu, Han},
  booktitle={CVPR},
  pages={3202--3211},
  year={2022}
}

@article{lei2018tvqa,
  title={Tvqa: Localized, compositional video question answering},
  author={Lei, Jie and Yu, Licheng and Bansal, Mohit and Berg, Tamara L},
  journal={arXiv preprint arXiv:1809.01696},
  year={2018}
}

@inproceedings{yang2021just,
  title={Just ask: Learning to answer questions from millions of narrated videos},
  author={Yang, Antoine and Miech, Antoine and Sivic, Josef and Laptev, Ivan and Schmid, Cordelia},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1686--1697},
  year={2021}
}

@inproceedings{anne2017localizing,
  title={Localizing moments in video with natural language},
  author={Anne Hendricks, Lisa and Wang, Oliver and Shechtman, Eli and Sivic, Josef and Darrell, Trevor and Russell, Bryan},
  booktitle={ICCV},
  pages={5803--5812},
  year={2017}
}

@inproceedings{wong2022assistq,
  title={AssistQ: Affordance-centric Question-driven Task Completion for Egocentric Assistant},
  author={Wong, Benita and Chen, Joya and Wu, You and Lei, Stan Weixian and Mao, Dongxing and Gao, Difei and Shou, Mike Zheng},
  booktitle={ECCV},
  year={2022}
}

@inproceedings{wang2022object,
  title={Object-aware Video-language Pre-training for Retrieval},
  author={Wang, Jinpeng and Ge, Yixiao and Cai, Guanyu and Yan, Rui and Lin, Xudong and Shan, Ying and Qie, Xiaohu and Shou, Mike Zheng},
  booktitle={CVPR},
  pages={3313--3322},
  year={2022}
}

@article{lei2021detecting,
  title={Detecting Moments and Highlights in Videos via Natural Language Queries},
  author={Lei, Jie and Berg, Tamara L and Bansal, Mohit},
  journal={NeurIPS},
  volume={34},
  pages={11846--11858},
  year={2021}
}