\begin{thebibliography}{}

\bibitem[Adel et~al., 2017]{adel2017unsupervised}
Adel, T., Zhao, H., and Wong, A. (2017).
\newblock Unsupervised domain adaptation with a relaxed covariate shift
  assumption.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~31.

\bibitem[Ahuja et~al., 2020]{ahuja2020invariant}
Ahuja, K., Shanmugam, K., Varshney, K., and Dhurandhar, A. (2020).
\newblock Invariant risk minimization games.
\newblock In {\em International Conference on Machine Learning}, pages
  145--155. PMLR.

\bibitem[Ajakan et~al., 2014]{ajakan2014domain}
Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., and Marchand, M.
  (2014).
\newblock Domain-adversarial neural networks.
\newblock {\em arXiv preprint arXiv:1412.4446}.

\bibitem[Arjovsky et~al., 2019]{arjovsky2019invariant}
Arjovsky, M., Bottou, L., Gulrajani, I., and Lopez-Paz, D. (2019).
\newblock Invariant risk minimization.
\newblock {\em arXiv preprint arXiv:1907.02893}.

\bibitem[Becker et~al., 2013]{becker2013non}
Becker, C.~J., Christoudias, C.~M., and Fua, P. (2013).
\newblock Non-linear domain adaptation with boosting.
\newblock In {\em Neural Information Processing Systems (NIPS)}, number CONF.

\bibitem[Ben-David et~al., 2010]{ben2010theory}
Ben-David, S., Blitzer, J., Crammer, K., Kulesza, A., Pereira, F., and Vaughan,
  J.~W. (2010).
\newblock A theory of learning from different domains.
\newblock {\em Machine learning}, 79(1-2):151--175.

\bibitem[Berthelot et~al., 2019]{berthelot2019remixmatch}
Berthelot, D., Carlini, N., Cubuk, E.~D., Kurakin, A., Sohn, K., Zhang, H., and
  Raffel, C. (2019).
\newblock Remixmatch: Semi-supervised learning with distribution matching and
  augmentation anchoring.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Caron et~al., 2020]{caron2020unsupervised}
Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., and Joulin, A.
  (2020).
\newblock Unsupervised learning of visual features by contrasting cluster
  assignments.

\bibitem[Chen et~al., 2020a]{chen2020homm}
Chen, C., Fu, Z., Chen, Z., Jin, S., Cheng, Z., Jin, X., and Hua, X.-S.
  (2020a).
\newblock Homm: Higher-order moment matching for unsupervised domain
  adaptation.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pages 3422--3429.

\bibitem[Chen et~al., 2020b]{chen2020simple}
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G. (2020b).
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In {\em International conference on machine learning}, pages
  1597--1607. PMLR.

\bibitem[Chen et~al., 2020c]{chen2020self}
Chen, Y., Wei, C., Kumar, A., and Ma, T. (2020c).
\newblock Self-training avoids using spurious features under domain shift.
\newblock {\em arXiv preprint arXiv:2006.10032}.

\bibitem[Cortes et~al., 2010]{cortes2010learning}
Cortes, C., Mansour, Y., and Mohri, M. (2010).
\newblock Learning bounds for importance weighting.
\newblock In {\em Advances in neural information processing systems}, pages
  442--450.

\bibitem[Cortes et~al., 2015]{cortes2015adaptation}
Cortes, C., Mohri, M., and Mu{\~n}oz~Medina, A. (2015).
\newblock Adaptation algorithm and theory based on generalized discrepancy.
\newblock In {\em Proceedings of the 21th ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, pages 169--178.

\bibitem[Ganin et~al., 2016]{ganin2016domain}
Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette,
  F., Marchand, M., and Lempitsky, V. (2016).
\newblock Domain-adversarial training of neural networks.
\newblock {\em The Journal of Machine Learning Research}, 17(1):2096--2030.

\bibitem[Ghifary et~al., 2015]{ghifary2015domain}
Ghifary, M., Kleijn, W.~B., Zhang, M., and Balduzzi, D. (2015).
\newblock Domain generalization for object recognition with multi-task
  autoencoders.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 2551--2559.

\bibitem[Glorot et~al., 2011]{glorot2011domain}
Glorot, X., Bordes, A., and Bengio, Y. (2011).
\newblock Domain adaptation for large-scale sentiment classification: A deep
  learning approach.
\newblock In {\em ICML}.

\bibitem[Gong et~al., 2012]{gong2012geodesic}
Gong, B., Shi, Y., Sha, F., and Grauman, K. (2012).
\newblock Geodesic flow kernel for unsupervised domain adaptation.
\newblock In {\em 2012 IEEE Conference on Computer Vision and Pattern
  Recognition}, pages 2066--2073. IEEE.

\bibitem[Gopalan et~al., 2011]{gopalan2011domain}
Gopalan, R., Li, R., and Chellappa, R. (2011).
\newblock Domain adaptation for object recognition: An unsupervised approach.
\newblock In {\em 2011 international conference on computer vision}, pages
  999--1006. IEEE.

\bibitem[Gretton et~al., 2007]{gretton2007kernel}
Gretton, A., Borgwardt, K., Rasch, M., Sch{\"o}lkopf, B., and Smola, A.~J.
  (2007).
\newblock A kernel method for the two-sample-problem.
\newblock In {\em Advances in neural information processing systems}, pages
  513--520.

\bibitem[Grill et~al., 2020]{grill2020bootstrap}
Grill, J.-B., Strub, F., Altch{\'e}, F., Tallec, C., Richemond, P.~H.,
  Buchatskaya, E., Doersch, C., Pires, B.~A., Guo, Z.~D., Azar, M.~G., et~al.
  (2020).
\newblock Bootstrap your own latent: A new approach to self-supervised
  learning.
\newblock {\em arXiv preprint arXiv:2006.07733}.

\bibitem[Gulrajani and Lopez-Paz, 2020]{gulrajani2020search}
Gulrajani, I. and Lopez-Paz, D. (2020).
\newblock In search of lost domain generalization.
\newblock {\em arXiv preprint arXiv:2007.01434}.

\bibitem[He and Zhang, 2019]{he2019multi}
He, Z. and Zhang, L. (2019).
\newblock Multi-adversarial faster-rcnn for unrestricted object detection.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 6668--6677.

\bibitem[Heckman, 1979]{heckman1979sample}
Heckman, J.~J. (1979).
\newblock Sample selection bias as a specification error.
\newblock {\em Econometrica: Journal of the econometric society}, pages
  153--161.

\bibitem[Hoffman et~al., 2018]{hoffman2018cycada}
Hoffman, J., Tzeng, E., Park, T., Zhu, J.-Y., Isola, P., Saenko, K., Efros, A.,
  and Darrell, T. (2018).
\newblock Cycada: Cycle-consistent adversarial domain adaptation.
\newblock In {\em International conference on machine learning}, pages
  1989--1998. PMLR.

\bibitem[Hong et~al., 2018]{hong2018conditional}
Hong, W., Wang, Z., Yang, M., and Yuan, J. (2018).
\newblock Conditional generative adversarial network for structured domain
  adaptation.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 1335--1344.

\bibitem[Huang et~al., 2006]{huang2006correcting}
Huang, J., Gretton, A., Borgwardt, K., Sch{\"o}lkopf, B., and Smola, A. (2006).
\newblock Correcting sample selection bias by unlabeled data.
\newblock {\em Advances in neural information processing systems}, 19:601--608.

\bibitem[Javed et~al., 2020]{javed2020learning}
Javed, K., White, M., and Bengio, Y. (2020).
\newblock Learning causal models online.
\newblock {\em arXiv preprint arXiv:2006.07461}.

\bibitem[Jhuo et~al., 2012]{jhuo2012robust}
Jhuo, I.-H., Liu, D., Lee, D., and Chang, S.-F. (2012).
\newblock Robust visual domain adaptation with low-rank reconstruction.
\newblock In {\em 2012 IEEE conference on computer vision and pattern
  recognition}, pages 2168--2175. IEEE.

\bibitem[Junguang~Jiang, 2020]{dalib}
Junguang~Jiang, Bo~Fu, M.~L. (2020).
\newblock Transfer-learning-library.
\newblock \url{https://github.com/thuml/Transfer-Learning-Library}.

\bibitem[Kanamori et~al., 2011]{kanamori2011f}
Kanamori, T., Suzuki, T., and Sugiyama, M. (2011).
\newblock $ f $-divergence estimation and two-sample homogeneity test under
  semiparametric density-ratio models.
\newblock {\em IEEE transactions on information theory}, 58(2):708--720.

\bibitem[Krueger et~al., 2020]{krueger2020out}
Krueger, D., Caballero, E., Jacobsen, J.-H., Zhang, A., Binas, J., Priol,
  R.~L., and Courville, A. (2020).
\newblock Out-of-distribution generalization via risk extrapolation (rex).
\newblock {\em arXiv preprint arXiv:2003.00688}.

\bibitem[Kumar et~al., 2020]{kumar2020understanding}
Kumar, A., Ma, T., and Liang, P. (2020).
\newblock Understanding self-training for gradual domain adaptation.
\newblock {\em arXiv preprint arXiv:2002.11361}.

\bibitem[Lee et~al., 2019]{lee2019sliced}
Lee, C.-Y., Batra, T., Baig, M.~H., and Ulbricht, D. (2019).
\newblock Sliced wasserstein discrepancy for unsupervised domain adaptation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10285--10295.

\bibitem[Li et~al., 2020]{li2020rethinking}
Li, B., Wang, Y., Che, T., Zhang, S., Zhao, S., Xu, P., Zhou, W., Bengio, Y.,
  and Keutzer, K. (2020).
\newblock Rethinking distributional matching based domain adaptation.
\newblock {\em arXiv preprint arXiv:2006.13352}.

\bibitem[Li et~al., 2018]{li2018learning}
Li, D., Yang, Y., Song, Y.-Z., and Hospedales, T. (2018).
\newblock Learning to generalize: Meta-learning for domain generalization.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~32.

\bibitem[Lin et~al., 2002]{lin2002support}
Lin, Y., Lee, Y., and Wahba, G. (2002).
\newblock Support vector machines for classification in nonstandard situations.
\newblock {\em Machine learning}, 46(1):191--202.

\bibitem[Liu et~al., 2019]{liu2019butterfly}
Liu, F., Lu, J., Han, B., Niu, G., Zhang, G., and Sugiyama, M. (2019).
\newblock Butterfly: A panacea for all difficulties in wildly unsupervised
  domain adaptation.
\newblock {\em arXiv preprint arXiv:1905.07720}.

\bibitem[Long et~al., 2015]{long2015learning}
Long, M., Cao, Y., Wang, J., and Jordan, M. (2015).
\newblock Learning transferable features with deep adaptation networks.
\newblock In {\em International conference on machine learning}, pages 97--105.
  PMLR.

\bibitem[Long et~al., 2017a]{long2017conditional}
Long, M., Cao, Z., Wang, J., and Jordan, M.~I. (2017a).
\newblock Conditional adversarial domain adaptation.
\newblock {\em arXiv preprint arXiv:1705.10667}.

\bibitem[Long et~al., 2017b]{long2017deep}
Long, M., Zhu, H., Wang, J., and Jordan, M.~I. (2017b).
\newblock Deep transfer learning with joint adaptation networks.
\newblock In {\em International conference on machine learning}, pages
  2208--2217. PMLR.

\bibitem[Menon and Ong, 2016]{menon2016linking}
Menon, A. and Ong, C.~S. (2016).
\newblock Linking losses for density ratio and class-probability estimation.
\newblock In {\em International Conference on Machine Learning}, pages
  304--313. PMLR.

\bibitem[Mitrovic et~al., 2020]{mitrovic2020representation}
Mitrovic, J., McWilliams, B., Walker, J., Buesing, L., and Blundell, C. (2020).
\newblock Representation learning via invariant causal mechanisms.
\newblock {\em arXiv preprint arXiv:2010.07922}.

\bibitem[Miyato et~al., 2018]{miyato2018virtual}
Miyato, T., Maeda, S.-i., Koyama, M., and Ishii, S. (2018).
\newblock Virtual adversarial training: a regularization method for supervised
  and semi-supervised learning.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  41(8):1979--1993.

\bibitem[Parascandolo et~al., 2020]{parascandolo2020learning}
Parascandolo, G., Neitz, A., Orvieto, A., Gresele, L., and Sch{\"o}lkopf, B.
  (2020).
\newblock Learning explanations that are hard to vary.
\newblock {\em arXiv preprint arXiv:2009.00329}.

\bibitem[Pei et~al., 2018]{pei2018multi}
Pei, Z., Cao, Z., Long, M., and Wang, J. (2018).
\newblock Multi-adversarial domain adaptation.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~32.

\bibitem[Qiao et~al., 2018]{qiao2018deep}
Qiao, S., Shen, W., Zhang, Z., Wang, B., and Yuille, A. (2018).
\newblock Deep co-training for semi-supervised image recognition.
\newblock In {\em Proceedings of the european conference on computer vision
  (eccv)}, pages 135--152.

\bibitem[Quionero-Candela et~al., 2009]{quionero2009dataset}
Quionero-Candela, J., Sugiyama, M., Schwaighofer, A., and Lawrence, N.~D.
  (2009).
\newblock {\em Dataset shift in machine learning}.

\bibitem[Roy et~al., 2019]{roy2019unsupervised}
Roy, S., Siarohin, A., Sangineto, E., Bulo, S.~R., Sebe, N., and Ricci, E.
  (2019).
\newblock Unsupervised domain adaptation using feature-whitening and consensus
  loss.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 9471--9480.

\bibitem[Saenko et~al., 2010]{saenko2010adapting}
Saenko, K., Kulis, B., Fritz, M., and Darrell, T. (2010).
\newblock Adapting visual category models to new domains.
\newblock In {\em European conference on computer vision}, pages 213--226.
  Springer.

\bibitem[Sagawa et~al., 2019]{sagawa2019distributionally}
Sagawa, S., Koh, P.~W., Hashimoto, T.~B., and Liang, P. (2019).
\newblock Distributionally robust neural networks for group shifts: On the
  importance of regularization for worst-case generalization.
\newblock {\em arXiv preprint arXiv:1911.08731}.

\bibitem[Santurkar et~al., 2021]{santurkar2021breeds}
Santurkar, S., Tsipras, D., and Madry, A. (2021).
\newblock {\{}BREEDS{\}}: Benchmarks for subpopulation shift.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Shimodaira, 2000]{shimodaira2000improving}
Shimodaira, H. (2000).
\newblock Improving predictive inference under covariate shift by weighting the
  log-likelihood function.
\newblock {\em Journal of statistical planning and inference}, 90(2):227--244.

\bibitem[Shu et~al., 2018]{shu2018dirt}
Shu, R., Bui, H.~H., Narui, H., and Ermon, S. (2018).
\newblock A dirt-t approach to unsupervised domain adaptation.
\newblock {\em arXiv preprint arXiv:1802.08735}.

\bibitem[Shu et~al., 2019]{shu2019transferable}
Shu, Y., Cao, Z., Long, M., and Wang, J. (2019).
\newblock Transferable curriculum for weakly-supervised domain adaptation.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 4951--4958.

\bibitem[Sohn et~al., 2020]{sohn2020fixmatch}
Sohn, K., Berthelot, D., Carlini, N., Zhang, Z., Zhang, H., Raffel, C.~A.,
  Cubuk, E.~D., Kurakin, A., and Li, C.-L. (2020).
\newblock Fixmatch: Simplifying semi-supervised learning with consistency and
  confidence.
\newblock {\em Advances in Neural Information Processing Systems}, 33.

\bibitem[Sugiyama et~al., 2012]{sugiyama2012density}
Sugiyama, M., Suzuki, T., and Kanamori, T. (2012).
\newblock Density-ratio matching under the bregman divergence: a unified
  framework of density-ratio estimation.
\newblock {\em Annals of the Institute of Statistical Mathematics},
  64(5):1009--1044.

\bibitem[Sugiyama et~al., 2008]{sugiyama2008direct}
Sugiyama, M., Suzuki, T., Nakajima, S., Kashima, H., von B{\"u}nau, P., and
  Kawanabe, M. (2008).
\newblock Direct importance estimation for covariate shift adaptation.
\newblock {\em Annals of the Institute of Statistical Mathematics},
  60(4):699--746.

\bibitem[Tzeng et~al., 2017]{tzeng2017adversarial}
Tzeng, E., Hoffman, J., Saenko, K., and Darrell, T. (2017).
\newblock Adversarial discriminative domain adaptation.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 7167--7176.

\bibitem[Uehara et~al., 2016]{uehara2016generative}
Uehara, M., Sato, I., Suzuki, M., Nakayama, K., and Matsuo, Y. (2016).
\newblock Generative adversarial nets from a density ratio estimation
  perspective.
\newblock {\em arXiv preprint arXiv:1610.02920}.

\bibitem[Venkateswara et~al., 2017]{venkateswara2017deep}
Venkateswara, H., Eusebio, J., Chakraborty, S., and Panchanathan, S. (2017).
\newblock Deep hashing network for unsupervised domain adaptation.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 5018--5027.

\bibitem[Wei and Ma, 2019]{wei2019improved}
Wei, C. and Ma, T. (2019).
\newblock Improved sample complexities for deep networks and robust
  classification via an all-layer margin.
\newblock {\em arXiv preprint arXiv:1910.04284}.

\bibitem[Wei et~al., 2021]{wei2021theoretical}
Wei, C., Shen, K., Chen, Y., and Ma, T. (2021).
\newblock Theoretical analysis of self-training with deep networks on unlabeled
  data.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Wu et~al., 2019]{wu2019domain}
Wu, Y., Winston, E., Kaushik, D., and Lipton, Z. (2019).
\newblock Domain adaptation with asymmetrically-relaxed distribution alignment.
\newblock In {\em International Conference on Machine Learning}, pages
  6872--6881. PMLR.

\bibitem[Xie et~al., 2020]{xie2020unsupervised}
Xie, Q., Dai, Z., Hovy, E., Luong, T., and Le, Q. (2020).
\newblock Unsupervised data augmentation for consistency training.
\newblock {\em Advances in Neural Information Processing Systems}, 33.

\bibitem[Xie et~al., 2019]{xie2019multi}
Xie, R., Yu, F., Wang, J., Wang, Y., and Zhang, L. (2019).
\newblock Multi-level domain adaptive learning for cross-domain detection.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision Workshops}, pages 0--0.

\bibitem[Xu et~al., 2021]{xu2021how}
Xu, K., Zhang, M., Li, J., Du, S.~S., Kawarabayashi, K.-I., and Jegelka, S.
  (2021).
\newblock How neural networks extrapolate: From feedforward to graph neural
  networks.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Xu et~al., 2018]{xu2018deep}
Xu, R., Chen, Z., Zuo, W., Yan, J., and Lin, L. (2018).
\newblock Deep cocktail network: Multi-source unsupervised domain adaptation
  with category shift.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 3964--3973.

\bibitem[Ye et~al., 2021]{ye2021theoretical}
Ye, H., Xie, C., Cai, T., Li, R., Li, Z., and Wang, L. (2021).
\newblock Towards a theoretical framework of out-of-distribution
  generalization.

\bibitem[Zadrozny, 2004]{zadrozny2004learning}
Zadrozny, B. (2004).
\newblock Learning and evaluating classifiers under sample selection bias.
\newblock In {\em Proceedings of the twenty-first international conference on
  Machine learning}, page 114.

\bibitem[Zhang et~al., 2013]{zhang2013domain}
Zhang, K., Sch{\"o}lkopf, B., Muandet, K., and Wang, Z. (2013).
\newblock Domain adaptation under target and conditional shift.
\newblock In {\em International Conference on Machine Learning}, pages
  819--827.

\bibitem[Zhang, 2019]{zhang2019transfer}
Zhang, L. (2019).
\newblock Transfer adaptation learning: A decade survey.
\newblock {\em arXiv preprint arXiv:1903.04687}.

\bibitem[Zhang et~al., 2019]{zhang2019bridging}
Zhang, Y., Liu, T., Long, M., and Jordan, M. (2019).
\newblock Bridging theory and algorithm for domain adaptation.
\newblock In {\em International Conference on Machine Learning}, pages
  7404--7413. PMLR.

\bibitem[Zhao et~al., 2019a]{zhao2019learning}
Zhao, H., Combes, R. T.~d., Zhang, K., and Gordon, G.~J. (2019a).
\newblock On learning invariant representation for domain adaptation.
\newblock {\em arXiv preprint arXiv:1901.09453}.

\bibitem[Zhao et~al., 2020a]{zhao2020fundamental}
Zhao, H., Dan, C., Aragam, B., Jaakkola, T.~S., Gordon, G.~J., and Ravikumar,
  P. (2020a).
\newblock Fundamental limits and tradeoffs in invariant representation
  learning.
\newblock {\em arXiv preprint arXiv:2012.10713}.

\bibitem[Zhao et~al., 2018]{zhao2018adversarial}
Zhao, H., Zhang, S., Wu, G., Moura, J.~M., Costeira, J.~P., and Gordon, G.~J.
  (2018).
\newblock Adversarial multiple source domain adaptation.
\newblock {\em Advances in neural information processing systems},
  31:8559--8570.

\bibitem[Zhao et~al., 2019b]{zhao2019multi}
Zhao, S., Li, B., Yue, X., Gu, Y., Xu, P., Hu, R., Chai, H., and Keutzer, K.
  (2019b).
\newblock Multi-source domain adaptation for semantic segmentation.
\newblock {\em arXiv preprint arXiv:1910.12181}.

\bibitem[Zhao et~al., 2020b]{zhao2020review}
Zhao, S., Yue, X., Zhang, S., Li, B., Zhao, H., Wu, B., Krishna, R., Gonzalez,
  J.~E., Sangiovanni-Vincentelli, A.~L., Seshia, S.~A., et~al. (2020b).
\newblock A review of single-source deep unsupervised visual domain adaptation.
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems}.

\bibitem[Zhu et~al., 2019]{zhu2019adapting}
Zhu, X., Pang, J., Yang, C., Shi, J., and Lin, D. (2019).
\newblock Adapting object detectors via selective cross-domain alignment.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 687--696.

\bibitem[Zhuang et~al., 2020]{zhuang2020comprehensive}
Zhuang, F., Qi, Z., Duan, K., Xi, D., Zhu, Y., Zhu, H., Xiong, H., and He, Q.
  (2020).
\newblock A comprehensive survey on transfer learning.
\newblock {\em Proceedings of the IEEE}, 109(1):43--76.

\end{thebibliography}
