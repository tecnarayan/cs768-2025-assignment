@inproceedings{ioffe2015batch,
	title={Batch normalization: accelerating deep network training by reducing internal covariate shift},
	author={Ioffe, Sergey and Szegedy, Christian},
	booktitle={Proceedings of the 32nd International Conference on International Conference on Machine Learning-Volume 37},
	pages={448--456},
	year={2015},
	organization={JMLR. org}
}

@InProceedings{xie2022adai,
  title = 	 {Adaptive Inertia: Disentangling the Effects of Adaptive Learning Rate and Momentum},
  author =       {Xie, Zeke and Wang, Xinrui and Zhang, Huishuai and Sato, Issei and Sugiyama, Masashi},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {24430--24459},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
}

@INPROCEEDINGS{zhu2015aligning,
  author={Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},
  booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books}, 
  year={2015},
  volume={},
  number={},
  pages={19-27},
}

@article{izsak2021how,
  title={How to train {BERT} with an academic budget},
  author={Izsak, Peter and Berchansky, Moshe and Levy, Omer},
  journal={arXiv preprint arXiv:2104.07705},
  year={2021}
}

@article{liu2019roberta,
  title={{R}o{BERT}a: A robustly optimized {BERT} pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@INPROCEEDINGS{deng2009imagenet,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={ImageNet: A large-scale hierarchical image database}, 
  year={2009},
  volume={},
  number={},
  pages={248-255},
  doi={10.1109/CVPR.2009.5206848}}


@InProceedings{he2015delving,
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	title = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on {ImageNet} Classification},
	booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
	month = {December},
	year = {2015}
}

@inproceedings{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  booktitle={International Conference on Learning Representations},
  year={2014},
}

@article{cifar10,
title= {{CIFAR}-10 ({C}anadian {I}nstitute for {A}dvanced {R}esearch)},
journal= {},
author= {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
year= {},
url= {http://www.cs.toronto.edu/~kriz/cifar.html},
keywords= {Dataset},
terms= {}
}

@inproceedings{ioffe2015batch,
	title={Batch normalization: accelerating deep network training by reducing internal covariate shift},
	author={Ioffe, Sergey and Szegedy, Christian},
	booktitle={Proceedings of the 32nd International Conference on International Conference on Machine Learning-Volume 37},
	pages={448--456},
	year={2015},
	organization={JMLR. org}
}

@article{granziol2021learning,
  author  = {Diego Granziol and Stefan Zohren and Stephen Roberts},
  title   = {Learning Rates as a Function of Batch Size: A Random Matrix Theory Approach to Neural Network Training},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {173},
  pages   = {1--65}
}

@misc{hinton2012rmsprop,
author={Tijmen Tieleman and Geoffrey Hinton},
title={Lecture 6.5-rmsprop: Divide the gradient by a running average of its
recent magnitude.},
organization={COURSERA: Neural networks for machine learning},
year={2012},
pages={26--31},
url = {https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf},
}

@misc{wandb,
title = {Experiment Tracking with Weights and Biases},
year = {2020},
note = {Software available from wandb.com},
url={https://www.wandb.com/},
author = {Biewald, Lukas},
}

@book{kloeden2011numerical,
  title={Numerical Solution of Stochastic Differential Equations},
  author={Kloeden, P.E. and Platen, E.},
  isbn={9783540540625},
  lccn={92015916},
  series={Stochastic Modelling and Applied Probability},
  url={https://books.google.com/books?id=BCvtssom1CMC},
  year={2011},
  publisher={Springer Berlin Heidelberg}
}

@article{ramachandran2017searching,
  title={Searching for activation functions},
  author={Ramachandran, Prajit and Zoph, Barret and Le, Quoc V},
  journal={arXiv preprint arXiv:1710.05941},
  year={2017}
}

@inproceedings{arora2019fine,
  title={Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks},
  author={Arora, Sanjeev and Du, Simon and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={322--332},
  year={2019},
  organization={PMLR}
}

@inproceedings{allenzhu2019learning,
 author = {Allen-Zhu, Zeyuan and Li, Yuanzhi and Liang, Yingyu},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Learning and Generalization in Overparameterized Neural Networks, Going Beyond Two Layers},
 url = {https://proceedings.neurips.cc/paper/2019/file/62dad6e273d32235ae02b7d321578ee8-Paper.pdf},
 volume = {32},
 year = {2019}
}

@misc{he2016identity,
      title={Identity Mappings in Deep Residual Networks}, 
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2016},
      eprint={1603.05027},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@incollection{santurkar2018does,
	title = {How Does Batch Normalization Help Optimization?},
	author = {Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew and Madry, Aleksander},
	booktitle = {Advances in Neural Information Processing Systems 31},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	pages = {2483--2493},
	year = {2018},
	publisher = {Curran Associates, Inc.},
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and others},
  year={2009},
  publisher={Citeseer}
}

@INPROCEEDINGS{smith2017cyclical,
  author={L. N. {Smith}},
  booktitle={2017 IEEE Winter Conference on Applications of Computer Vision (WACV)}, 
  title={Cyclical Learning Rates for Training Neural Networks}, 
  year={2017},
  volume={},
  number={},
  pages={464-472},
  doi={10.1109/WACV.2017.58}
}

@InProceedings{kohler2019exp,
	title = 	 {Exponential convergence rates for Batch Normalization: The power of length-direction decoupling in non-convex optimization},
	author = 	 {Kohler, Jonas and Daneshmand, Hadi and Lucchi, Aurelien and Hofmann, Thomas and Zhou, Ming and Neymeyr, Klaus},
	booktitle = 	 {Proceedings of Machine Learning Research},
	pages = 	 {806--815},
	year = 	 {2019},
	editor = 	 {Chaudhuri, Kamalika and Sugiyama, Masashi},
	volume = 	 {89},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {},
	month = 	 {16--18 Apr},
	publisher = 	 {PMLR}
}

@article{wu2018wngrad,
	title={WNGrad: Learn the Learning Rate in Gradient Descent},
	author={Wu, Xiaoxia and Ward, Rachel and Bottou, L{\'e}on},
	journal={arXiv preprint arXiv:1803.02865},
	year={2018}
}

@article{ward2018adagrad,
	title={AdaGrad stepsizes: Sharp convergence over nonconvex landscapes, from any initialization},
	author={Ward, Rachel and Wu, Xiaoxia and Bottou, Leon},
	journal={arXiv preprint arXiv:1806.01811},
	year={2018}
}

@article{li2018convergence,
	title={On the Convergence of Stochastic Gradient Descent with Adaptive Stepsizes},
	author={Li, Xiaoyu and Orabona, Francesco},
	journal={arXiv preprint arXiv:1805.08114},
	year={2018}
}

@article{zou2018convergence,
	title={On the Convergence of AdaGrad with Momentum for Training Deep Neural Networks},
	author={Zou, Fangyu and Shen, Li},
	journal={arXiv preprint arXiv:1808.03408},
	year={2018}
}


@article{zhou2018on,
	title={On the Convergence of Adaptive Gradient Methods for Nonconvex Optimization},
	author={Zhou, Dongruo and Tang, Yiqi and Yang, Ziyan and Cao, Yuan and Gu, Quanquan},
	journal={arXiv preprint arXiv:1808.05671},
	year={2018}
}

@inproceedings{salimans2016weight,
	title={Weight normalization: A simple reparameterization to accelerate training of deep neural networks},
	author={Salimans, Tim and Kingma, Diederik P},
	booktitle={Advances in Neural Information Processing Systems},
	pages={901--909},
	year={2016}
}

@article{ba2016layer,
	title={Layer normalization},
	author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
	journal={arXiv preprint arXiv:1607.06450},
	year={2016}
}

@InProceedings{simsekli2019tailindex, 
  title = 	 {A Tail-Index Analysis of Stochastic Gradient Noise in Deep Neural Networks},
  author =       {Simsekli, Umut and Sagun, Levent and Gurbuzbalaban, Mert},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {5827--5837},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
}

@article{wu2018group,
	title={Group normalization},
	author={Wu, Yuxin and He, Kaiming},
	journal={arXiv preprint arXiv:1803.08494},
	year={2018}
}

@inproceedings{glorot2011deep,
	title={Deep sparse rectifier neural networks},
	author={Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
	booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
	pages={315--323},
	year={2011}
}

@inproceedings{dugas2001incorporating,
	title={Incorporating second-order functional knowledge for better option pricing},
	author={Dugas, Charles and Bengio, Yoshua and B{\'e}lisle, Fran{\c{c}}ois and Nadeau, Claude and Garcia, Ren{\'e}},
	booktitle={Advances in neural information processing systems},
	pages={472--478},
	year={2001}
}

@inproceedings{nair2010rectified,
	title={Rectified linear units improve restricted boltzmann machines},
	author={Nair, Vinod and Hinton, Geoffrey E},
	booktitle={Proceedings of the 27th international conference on machine learning (ICML-10)},
	pages={807--814},
	year={2010}
}

@inproceedings{
kunin2021neural,
title={Neural Mechanics: Symmetry and Broken Conservation Laws in Deep Learning Dynamics},
author={Daniel Kunin and Javier Sagastuy-Brena and Surya Ganguli and Daniel LK Yamins and Hidenori Tanaka},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{li2020reconciling,
 author = {Li, Zhiyuan and Lyu, Kaifeng and Arora, Sanjeev},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {14544--14555},
 publisher = {Curran Associates, Inc.},
 title = {Reconciling Modern Deep Learning with Traditional Optimization Analyses: The Intrinsic Learning Rate},
 volume = {33},
 year = {2020}
}



@inproceedings{cho2017riemannian,
	title={Riemannian approach to batch normalization},
	author={Cho, Minhyung and Lee, Jaehyung},
	booktitle={Advances in Neural Information Processing Systems},
	pages={5225--5235},
	year={2017}
}

@inproceedings{he2016deep,
	title={Deep residual learning for image recognition},
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={770--778},
	year={2016}
}

@inproceedings{huang2017densely,
	title={Densely Connected Convolutional Networks},
	author={Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q},
	booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages={2261--2269},
	year={2017},
	organization={IEEE}
}

@inproceedings{szegedy2017inception,
	title={Inception-v4, inception-resnet and the impact of residual connections on learning.},
	author={Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alexander A},
	booktitle={AAAI},
	volume={4},
	pages={12},
	year={2017}
}

@inproceedings{ioffe2017renorm,
	title={Batch renormalization: Towards reducing minibatch dependence in batch-normalized models},
	author={Ioffe, Sergey},
	booktitle={Advances in Neural Information Processing Systems},
	pages={1945--1953},
	year={2017}
}

@InProceedings{wen2020empirical, 
    title = {An Empirical Study of Stochastic Gradient Descent with Structured Covariance Noise}, 
    author = {Wen, Yeming and Luk, Kevin and Gazeau, Maxime and Zhang, Guodong and Chan, Harris and Ba, Jimmy}, 
    booktitle = {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics}, 
    pages = {3621--3631}, year = {2020}, editor = {Silvia Chiappa and Roberto Calandra}, 
    volume = {108}, series = {Proceedings of Machine Learning Research}, 
    month = {26--28 Aug}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v108/wen20a/wen20a.pdf}, url = { http://proceedings.mlr.press/v108/wen20a.html }}

@article{ulyanov2016IN,
	title={Instance Normalization: The Missing Ingredient for Fast Stylization},
	author={Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
	journal={arXiv preprint arXiv:1607.08022},
	year={2016}
}

@article{jain2017non,
	title={Non-convex optimization for machine learning},
	author={Jain, Prateek and Kar, Purushottam and others},
	journal={Foundations and Trends{\textregistered} in Machine Learning},
	volume={10},
	number={3-4},
	pages={142--336},
	year={2017},
	publisher={Now Publishers, Inc.}
}

@article{duchi2011adagrad,
	title={Adaptive subgradient methods for online learning and stochastic optimization},
	author={Duchi, John and Hazan, Elad and Singer, Yoram},
	journal={Journal of Machine Learning Research},
	volume={12},
	number={Jul},
	pages={2121--2159},
	year={2011}
}

@inproceedings{kingma2014adam,
	title={Adam: A Method for Stochastic Optimization},
	author={Diederik P. Kingma and Jimmy Ba},
	booktitle={International Conference on Learning Representations},
	year={2015}
}

@article{clevert2015elu,
	title={Fast and accurate deep network learning by exponential linear units (elus)},
	author={Clevert, Djork-Arn{\'e} and Unterthiner, Thomas and Hochreiter, Sepp},
	journal={arXiv preprint arXiv:1511.07289},
	year={2015}
}

@inproceedings{dugas2001softplus,
	title={Incorporating second-order functional knowledge for better option pricing},
	author={Dugas, Charles and Bengio, Yoshua and B{\'e}lisle, Fran{\c{c}}ois and Nadeau, Claude and Garcia, Ren{\'e}},
	booktitle={Advances in neural information processing systems},
	pages={472--478},
	year={2001}
}

@inproceedings{ge2015escaping,
	title={Escaping from saddle points—online stochastic gradient for tensor decomposition},
	author={Ge, Rong and Huang, Furong and Jin, Chi and Yuan, Yang},
	booktitle={Conference on Learning Theory},
	pages={797--842},
	year={2015}
}

@inproceedings{maas2013leakyrelu,
	title={Rectifier nonlinearities improve neural network acoustic models},
	author={Maas, Andrew L and Hannun, Awni Y and Ng, Andrew Y},
	booktitle={in ICML Workshop on Deep Learning for Audio, Speech and Language Processing},
	year={2013},
	organization={Citeseer}
}

@incollection{bjorck2018understanding,
	title = {Understanding Batch Normalization},
	author = {Bjorck, Nils and Gomes, Carla P and Selman, Bart and Weinberger, Kilian Q},
	booktitle = {Advances in Neural Information Processing Systems 31},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	pages = {7694--7705},
	year = {2018},
	publisher = {Curran Associates, Inc.}
}

@inproceedings{nguyen2019first,
  author    = {Thanh Huy Nguyen and
               Umut Simsekli and
               Mert G{\"{u}}rb{\"{u}}zbalaban and
               Ga{\"{e}}l Richard},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {First Exit Time Analysis of Stochastic Gradient Descent Under Heavy-Tailed
               Gradient Noise},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, December
               8-14, 2019, Vancouver, BC, Canada},
  pages     = {273--283},
  year      = {2019},
  url       = {https://proceedings.neurips.cc/paper/2019/hash/a97da629b098b75c294dffdc3e463904-Abstract.html},
  biburl    = {https://dblp.org/rec/conf/nips/NguyenSGR19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{hodgkinson2020multiplicative,
      title={Multiplicative noise and heavy tails in stochastic optimization}, 
      author={Liam Hodgkinson and Michael W. Mahoney},
      year={2020},
      eprint={2006.06293},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}



@InProceedings{wenzel2020how, 
    title = {How Good is the {B}ayes Posterior in Deep Neural Networks Really?}, 
    author = {Wenzel, Florian and Roth, Kevin and Veeling, Bastiaan and Swiatkowski, Jakub and Tran, Linh and Mandt, Stephan and Snoek, Jasper and Salimans, Tim and Jenatton, Rodolphe and Nowozin, Sebastian}, 
    booktitle = {Proceedings of the 37th International Conference on Machine Learning}, 
    pages = {10248--10259}, year = {2020}, editor = {Hal Daumé III and Aarti Singh}, 
    volume = {119}, series = {Proceedings of Machine Learning Research}, month = {13--18 Jul}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v119/wenzel20a/wenzel20a.pdf}, url = { http://proceedings.mlr.press/v119/wenzel20a.html } }

@article{zhang2018effectiveness,
	title={Effectiveness of Scaled Exponentially-Regularized Linear Units (SERLUs)},
	author={Zhang, Guoqiang and Li, Haopeng},
	journal={arXiv preprint arXiv:1807.10117},
	year={2018}
}

@article{ghadimi2013stochastic,
	title={Stochastic first-and zeroth-order methods for nonconvex stochastic programming},
	author={Ghadimi, Saeed and Lan, Guanghui},
	journal={SIAM Journal on Optimization},
	volume={23},
	number={4},
	pages={2341--2368},
	year={2013},
	publisher={SIAM}
}

@article{vapnik1999overview,
	title={An overview of statistical learning theory},
	author={Vapnik, Vladimir Naumovich},
	journal={IEEE transactions on neural networks},
	volume={10},
	number={5},
	pages={988--999},
	year={1999},
	publisher={IEEE}
}
@book{vapnik2013nature,
	title={The nature of statistical learning theory},
	author={Vapnik, Vladimir},
	year={2013},
	publisher={Springer science \& business media}
}

@inproceedings{zhang2017rethinking,
	title={Understanding deep learning requires rethinking generalization},
	author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
	booktitle={International Conference on Learning Representations},
	year={2017}
}

@inproceedings{szegedy2016rethinking,
	author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
	title = {Rethinking the Inception Architecture for Computer Vision},
	booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2016}
}

@inproceedings{neyshabur2017norm,
	title={A {PAC}-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks},
	author={Behnam Neyshabur and Srinadh Bhojanapalli and Nathan Srebro},
	booktitle={International Conference on Learning Representations},
	year={2018}
}

@incollection{bartlett2017norm,
	title = {Spectrally-normalized margin bounds for neural networks},
	author = {Bartlett, Peter L and Foster, Dylan J and Telgarsky, Matus J},
	booktitle = {Advances in Neural Information Processing Systems 30},
	editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	pages = {6240--6249},
	year = {2017},
	publisher = {Curran Associates, Inc.}
}

@article{li2018intrinsic,
	title={Measuring the intrinsic dimension of objective landscapes},
	author={Li, Chunyuan and Farkhoor, Heerad and Liu, Rosanne and Yosinski, Jason},
	journal={arXiv preprint arXiv:1804.08838},
	year={2018}
}

@article{soudry2018implicit,
	author  = {Daniel Soudry and Elad Hoffer and Mor Shpigel Nacson and Suriya Gunasekar and Nathan Srebro},
	title   = {The Implicit Bias of Gradient Descent on Separable Data},
	journal = {Journal of Machine Learning Research},
	year    = {2018},
	volume  = {19},
	number  = {70},
	pages   = {1-57}
}

@inproceedings{soudry2018iclrImplicit,
	title={The Implicit Bias of Gradient Descent on Separable Data},
	author={Daniel Soudry and Elad Hoffer and Nathan Srebro},
	booktitle={International Conference on Learning Representations},
	year={2018}
}

@inproceedings{li2018algorithmic,
	title = {Algorithmic Regularization in Over-parameterized Matrix Sensing and Neural Networks with Quadratic Activations},
	author = {Li, Yuanzhi and Ma, Tengyu and Zhang, Hongyang},
	booktitle = {Proceedings of the 31st  Conference On Learning Theory},
	pages = {2--47},
	year = {2018},
	editor = {Bubeck, S\'ebastien and Perchet, Vianney and Rigollet, Philippe},
	volume = {75},
	series = {Proceedings of Machine Learning Research},
	address = {},
	month = {06--09 Jul},
	publisher = {PMLR}
}


@InProceedings{wu2020noisy, 
title = {On the Noisy Gradient Descent that Generalizes as {SGD}}, 
author = {Wu, Jingfeng and Hu, Wenqing and Xiong, Haoyi and Huan, Jun and Braverman, Vladimir and Zhu, Zhanxing}, booktitle = {Proceedings of the 37th International Conference on Machine Learning}, 
pages = {10367--10376}, year = {2020}, editor = {Hal Daumé III and Aarti Singh}, 
volume = {119}, series = {Proceedings of Machine Learning Research}, month = {13--18 Jul}}

@InProceedings{du2018power,
	title = 	 {On the Power of Over-parametrization in Neural Networks with Quadratic Activation},
	author = 	 {Du, Simon and Lee, Jason},
	booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
	pages = 	 {1329--1338},
	year = 	 {2018},
	editor = 	 {Dy, Jennifer and Krause, Andreas},
	volume = 	 {80},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Stockholmsm\"{a}ssan, Stockholm Sweden},
	month = 	 {10--15 Jul},
	publisher = 	 {PMLR}
}

@article{hu2019diffusion,
  title={On the diffusion approximation of nonconvex stochastic gradient descent},
  author={Hu, Wenqing and Li, Chris Junchi and Li, Lei and Liu, Jian-Guo},
  journal={Annals of Mathematical Sciences and Applications},
  volume={4},
  number={1},
  year={2019}
}

@article{klusowski2018approximation,
	title={Approximation by Combinations of ReLU and Squared ReLU Ridge Functions With $\ell^1$ and $\ell^0$ Controls},
	author={Klusowski, Jason M and Barron, Andrew R},
	journal={IEEE Transactions on Information Theory},
	volume={64},
	number={12},
	pages={7649--7656},
	year={2018},
	publisher={IEEE}
}

@article{li2019better,
	title={Better Approximations of High Dimensional Smooth Functions by Deep Neural Networks with Rectified Power Units},
	author={Li, Bo and Tang, Shanshan and Yu, Haijun},
	journal={arXiv preprint arXiv:1903.05858},
	year={2019}
}

@InProceedings{zhong2017recovery,
	title = {Recovery Guarantees for One-hidden-layer Neural Networks},
	author = {Kai Zhong and Zhao Song and Prateek Jain and Peter L. Bartlett and Inderjit S. Dhillon},
	booktitle = {Proceedings of the 34th International Conference on Machine Learning},
	pages = {4140--4149},
	year = {2017},
	editor = {Doina Precup and Yee Whye Teh},
	volume = {70},
	series = {Proceedings of Machine Learning Research},
	address = {International Convention Centre, Sydney, Australia},
	month = {06--11 Aug},
	publisher = {PMLR}
}

@incollection{gunasekar2018implicit,
	title = {Implicit Bias of Gradient Descent on Linear Convolutional Networks},
	author = {Gunasekar, Suriya and Lee, Jason D and Soudry, Daniel and Srebro, Nati},
	booktitle = {Advances in Neural Information Processing Systems 31},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	pages = {9482--9491},
	year = {2018},
	publisher = {Curran Associates, Inc.}
}

@article{mou2017generalization,
	title={Generalization bounds of SGLD for non-convex learning: Two theoretical viewpoints},
	author={Mou, Wenlong and Wang, Liwei and Zhai, Xiyu and Zheng, Kai},
	journal={arXiv preprint arXiv:1707.05947},
	year={2017}
}

@misc{allenzhu2018gobeyond,
	Author = {Zeyuan Allen-Zhu and Yuanzhi Li and Yingyu Liang},
	Title = {Learning and Generalization in Overparameterized Neural Networks, Going Beyond Two Layers},
	Year = {2018},
	Eprint = {arXiv:1811.04918},
}







@InProceedings{allenzhu2018convergence,
	title = 	 {A Convergence Theory for Deep Learning via Over-Parameterization},
	author = 	 {Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
	booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
	pages = 	 {242--252},
	year = 	 {2019},
	editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
	volume = 	 {97},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Long Beach, California, USA},
	month = 	 {09--15 Jun},
	publisher = 	 {PMLR}
}

@InProceedings{du2018global,
	title = 	 {Gradient Descent Finds Global Minima of Deep Neural Networks},
	author = 	 {Du, Simon and Lee, Jason and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
	booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
	pages = 	 {1675--1685},
	year = 	 {2019},
	editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
	volume = 	 {97},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Long Beach, California, USA},
	month = 	 {09--15 Jun},
	publisher = 	 {PMLR}
}

@article{zou2018stochastic,
	title={Stochastic gradient descent optimizes over-parameterized deep relu networks},
	author={Zou, Difan and Cao, Yuan and Zhou, Dongruo and Gu, Quanquan},
	journal={arXiv preprint arXiv:1811.08888},
	year={2018}
}

@incollection{du2018algorithmic,
	title = {Algorithmic Regularization in Learning Deep Homogeneous Models: Layers are Automatically Balanced},
	author = {Du, Simon S. and Hu, Wei and Lee, Jason D.},
	booktitle = {Advances in Neural Information Processing Systems 31},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	pages = {382--393},
	year = {2018},
	publisher = {Curran Associates, Inc.}
}

@inproceedings{
	du2018gradient,
	title={Gradient Descent Provably Optimizes Over-parameterized Neural Networks},
	author={Simon S. Du and Xiyu Zhai and Barnabas Poczos and Aarti Singh},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@article{clarke1975generalized,
	title={Generalized gradients and applications},
	author={Clarke, Frank H.},
	journal={Transactions of the American Mathematical Society},
	volume={205},
	pages={247--262},
	year={1975}
}


@book{clarke1990optimization,
	author = {Clarke, Frank H},
	title = {Optimization and Nonsmooth Analysis},
	publisher = {Society for Industrial and Applied Mathematics},
	year = {1990},
	doi = {10.1137/1.9781611971309}
}

@article{drusvyatskiy2015curves,
  title={Curves of descent},
  author={Drusvyatskiy, Dmitriy and Ioffe, Alexander D and Lewis, Adrian S},
  journal={SIAM Journal on Control and Optimization},
  volume={53},
  number={1},
  pages={114--138},
  year={2015},
  publisher={SIAM}
}

@book{clarke2008nonsmooth,
	title={Nonsmooth analysis and control theory},
	author={Clarke, Francis H. and Ledyaev, Yuri S. and Stern, Ronald J. and Wolenski, Peter R.},
	volume={178},
	year={2008},
	publisher={Springer Science \& Business Media}
}

@article{davis2018stochastic,
	author={Davis, Damek
	and Drusvyatskiy, Dmitriy
	and Kakade, Sham
	and Lee, Jason D.},
	title={Stochastic Subgradient Method Converges on Tame Functions},
	journal={Foundations of Computational Mathematics},
	volume={20},
	number={1},
	year={2020},
	month={Feb},
	pages={119-154}
}

@article{ma2019implicit,
	title={Implicit regularization in nonconvex statistical estimation: Gradient descent converges linearly for phase retrieval, matrix completion, and blind deconvolution},
	author={Ma, Cong and Wang, Kaizheng and Chi, Yuejie and Chen, Yuxin},
	journal={Foundations of Computational Mathematics},
	year={2019},
	month={Aug},
	day={05}
}

@inproceedings{
	ji2018gradient,
	title={Gradient descent aligns the layers of deep linear networks},
	author={Ziwei Ji and Matus Telgarsky},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@article{xu2018gradient,
	title={When Will Gradient Methods Converge to Max-margin Classifier under ReLU Models?},
	author={Tengyu Xu and Yi Zhou and Kaiyi Ji and Yingbin Liang},
	journal={arXiv preprint arXiv:1806.04339},
	year={2018}
}

@incollection{wei2018margin,
	title = {Regularization Matters: Generalization and Optimization of Neural Nets v.s. their Induced Kernel},
	author = {Wei, Colin and Lee, Jason D and Liu, Qiang and Ma, Tengyu},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {9709--9721},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@article{li2018decision,
	title={On the decision boundary of deep neural networks},
	author={Li, Yu and Richtarik, Peter and Ding, Lizhong and Gao, Xin},
	journal={arXiv preprint arXiv:1808.05385},
	year={2018}
}

@inproceedings{nacson2018stochastic,
	title = {Stochastic Gradient Descent on Separable Data: Exact Convergence with a Fixed Learning Rate},
	author = {Nacson, Mor Shpigel and Srebro, Nathan and Soudry, Daniel},
	booktitle = {Proceedings of Machine Learning Research},
	pages = {3051--3059},
	year = {2019},
	editor = {Chaudhuri, Kamalika and Sugiyama, Masashi},
	volume = {89},
	series = {Proceedings of Machine Learning Research},
	address = {},
	month = {16--18 Apr},
	publisher = {PMLR}
}


@InProceedings{nacson2019convergence,
	title = {Convergence of Gradient Descent on Separable Data},
	author = {Nacson, Mor Shpigel and Lee, Jason and Gunasekar, Suriya and Savarese, Pedro Henrique Pamplona and Srebro, Nathan and Soudry, Daniel},
	booktitle = {Proceedings of Machine Learning Research},
	pages = {3420--3428},
	year = {2019},
	editor = {Chaudhuri, Kamalika and Sugiyama, Masashi},
	volume = {89},
	series = {Proceedings of Machine Learning Research},
	address = {},
	month = {16--18 Apr},
	publisher = {PMLR}
}


@article{ji2018risk,
	title={Risk and parameter convergence of logistic regression},
	author={Ji, Ziwei and Telgarsky, Matus},
	journal={arXiv preprint arXiv:1803.07300},
	year={2018}
}

@InProceedings{ji2019risk,
	title = {The implicit bias of gradient descent on nonseparable data},
	author = {Ji, Ziwei and Telgarsky, Matus},
	booktitle = {Proceedings of the Thirty-Second Conference on Learning Theory},
	pages = {1772--1798},
	year = {2019},
	editor = {Beygelzimer, Alina and Hsu, Daniel},
	volume = {99},
	series = {Proceedings of Machine Learning Research},
	address = {Phoenix, USA},
	month = {25--28 Jun},
	publisher = {PMLR}
}

@article{ji2019refined,
	title={A refined primal-dual analysis of the implicit bias},
	author={Ji, Ziwei and Telgarsky, Matus},
	journal={arXiv preprint arXiv:1906.04540},
	year={2019}
}

@InProceedings{gunasekar2018characterizing,
	title = 	 {Characterizing Implicit Bias in Terms of Optimization Geometry},
	author = 	 {Gunasekar, Suriya and Lee, Jason and Soudry, Daniel and Srebro, Nathan},
	booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
	pages = 	 {1832--1841},
	year = 	 {2018},
	editor = 	 {Dy, Jennifer and Krause, Andreas},
	volume = 	 {80},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Stockholmsmässan, Stockholm Sweden},
	month = 	 {10--15 Jul},
	publisher = 	 {PMLR},
}

@incollection{wilson2017marginal,
	title = {The Marginal Value of Adaptive Gradient Methods in Machine Learning},
	author = {Wilson, Ashia C and Roelofs, Rebecca and Stern, Mitchell and Srebro, Nati and Recht, Benjamin},
	booktitle = {Advances in Neural Information Processing Systems 30},
	editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	pages = {4148--4158},
	year = {2017},
	publisher = {Curran Associates, Inc.}
}

@article{banburski2019theory,
	title={Theory {III}: Dynamics and Generalization in Deep Networks},
	author={Andrzej Banburski and Qianli Liao and Brando Miranda and Tomaso Poggio and Lorenzo Rosasco and Jack Hidary},
	journal={CBMM Memo No: 090, version 20},
	year={2019}
}


@inproceedings{ali2018continuous,
	title = 	 {A Continuous-Time View of Early Stopping for Least Squares Regression},
	author = 	 {Ali, Alnur and Kolter, J. Zico and Tibshirani, Ryan J.},
	booktitle =  {Proceedings of Machine Learning Research},
	pages = 	 {1370--1378},
	year = 	 {2019},
	editor = 	 {Chaudhuri, Kamalika and Sugiyama, Masashi},
	volume = 	 {89},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {},
	month = 	 {16--18 Apr},
	publisher =  {PMLR}
}

@incollection{suggala2018connecting,
	title = {Connecting Optimization and Regularization Paths},
	author = {Suggala, Arun and Prasad, Adarsh and Ravikumar, Pradeep K},
	booktitle = {Advances in Neural Information Processing Systems 31},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	pages = {10608--10619},
	year = {2018},
	publisher = {Curran Associates, Inc.}
}

@inproceedings{
	azizan2018stochastic,
	title={Stochastic Gradient/Mirror Descent: Minimax Optimality and Implicit Regularization},
	author={Navid Azizan and Babak Hassibi},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@inproceedings{keskar2016large,
	title={On large-batch training for deep learning: Generalization gap and sharp minima},
	author={Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
	booktitle={International Conference on Learning Representations},
	year={2017}
}

@inproceedings{dinh2017sharp,
	title={Sharp minima can generalize for deep nets},
	author={Dinh, Laurent and Pascanu, Razvan and Bengio, Samy and Bengio, Yoshua},
	booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
	pages={1019--1028},
	year={2017},
	organization={JMLR.org}
}

@article{yi2019positively,
	title={Positively Scale-Invariant Flatness of ReLU Neural Networks},
	author={Yi, Mingyang and Meng, Qi and Chen, Wei and Ma, Zhi-ming and Liu, Tie-Yan},
	journal={arXiv preprint arXiv:1903.02237},
	year={2019}
}

@incollection{lee2019wide,
	title = {Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent},
	author = {Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel and Bahri, Yasaman and Novak, Roman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {8570--8581},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@inproceedings{
	li2020exp,
	title={An Exponential Learning Rate Schedule for Deep Learning},
	author={Zhiyuan Li and Sanjeev Arora},
	booktitle={International Conference on Learning Representations},
	year={2020}
}


@incollection{jacot2018ntk,
title = {Neural Tangent Kernel: Convergence and Generalization in Neural Networks},
author = {Jacot, Arthur and Gabriel, Franck and Hongler, Clement},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {8571--8580},
year = {2018},
publisher = {Curran Associates, Inc.}
}

@incollection{rosset2004margin,
title = {Margin Maximizing Loss Functions},
author = {Rosset, Saharon and Ji Zhu and Trevor J. Hastie},
booktitle = {Advances in Neural Information Processing Systems 16},
editor = {S. Thrun and L. K. Saul and B. Sch\"{o}lkopf},
pages = {1237--1244},
year = {2004},
publisher = {MIT Press}
}

@article{SokolicGSR17,
  author    = {Jure Sokolic and
               Raja Giryes and
               Guillermo Sapiro and
               Miguel R. D. Rodrigues},
  title     = {Robust Large Margin Deep Neural Networks},
  journal   = {{IEEE} Trans. Signal Processing},
  volume    = {65},
  number    = {16},
  pages     = {4265--4280},
  year      = {2017},
  doi       = {10.1109/TSP.2017.2708039},
  timestamp = {Fri, 02 Nov 2018 09:33:28 +0100}
}

@InProceedings{arora2018compression,
  title = 	 {Stronger Generalization Bounds for Deep Nets via a Compression Approach},
  author = 	 {Arora, Sanjeev and Ge, Rong and Neyshabur, Behnam and Zhang, Yi},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {254--263},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR}
}







@InProceedings{croce2019provable,
  title = 	 {Provable Robustness of ReLU networks via Maximization of Linear Regions},
  author = 	 {Croce, Francesco and Andriushchenko, Maksym and Hein, Matthias},
  booktitle = 	 {Proceedings of Machine Learning Research},
  pages = 	 {2057--2066},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Sugiyama, Masashi},
  volume = 	 {89},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {16--18 Apr},
  publisher = 	 {PMLR}
}

@InProceedings{nacson2019lexicographic,
	title = 	 {Lexicographic and Depth-Sensitive Margins in Homogeneous and Non-Homogeneous Deep Models},
	author = 	 {Nacson, Mor Shpigel and Gunasekar, Suriya and Lee, Jason and Srebro, Nathan and Soudry, Daniel},
	booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
	pages = 	 {4683--4692},
	year = 	 {2019},
	editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
	volume = 	 {97},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Long Beach, California, USA},
	month = 	 {09--15 Jun},
	publisher = 	 {PMLR}
}

@article{dutta2013approximate,
  title={Approximate {KKT} points and a proximity measure for termination},
  author={Dutta, Joydeep and Deb, Kalyanmoy and Tulshyan, Rupesh and Arora, Ramnik},
  journal={Journal of Global Optimization},
  volume={56},
  number={4},
  pages={1463--1499},
  year={2013},
  publisher={Springer}
}

@incollection{du2017exp,
title = {Gradient Descent Can Take Exponential Time to Escape Saddle Points},
author = {Du, Simon S and Jin, Chi and Lee, Jason D and Jordan, Michael I and Singh, Aarti and Poczos, Barnabas},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {1067--1077},
year = {2017},
publisher = {Curran Associates, Inc.}
}

@incollection{gidel2019implicit,
	title = {Implicit Regularization of Discrete Gradient Dynamics in Linear Neural Networks},
	author = {Gidel, Gauthier and Bach, Francis and Lacoste-Julien, Simon},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {3196--3206},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@incollection{arora2019implicit,
	title = {Implicit Regularization in Deep Matrix Factorization},
	author = {Arora, Sanjeev and Cohen, Nadav and Hu, Wei and Luo, Yuping},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {7411--7422},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@article{blanc2019implicit,
	title={Implicit regularization for deep neural networks driven by an Ornstein-Uhlenbeck like process},
	author={Blanc, Guy and Gupta, Neha and Valiant, Gregory and Valiant, Paul},
	journal={arXiv preprint arXiv:1904.09080},
	year={2019}
}

@incollection{neyshabur2015pathsgd,
	title = {Path-{SGD}: {P}ath-Normalized Optimization in Deep Neural Networks},
	author = {Neyshabur, Behnam and Salakhutdinov, Ruslan R and Srebro, Nati},
	booktitle = {Advances in Neural Information Processing Systems 28},
	editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
	pages = {2422--2430},
	year = {2015},
	publisher = {Curran Associates, Inc.}
}

@inproceedings{neyshabur2014search,
	author    = {Behnam Neyshabur and Ryota Tomioka and Nathan Srebro},
	title     = {In Search of the Real Inductive Bias: On the Role of Implicit Regularization in Deep Learning},
	booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Workshop Track Proceedings},
	year      = {2015}
}

@INPROCEEDINGS{carlini2017towards, 
	author={Nicholas Carlini and David Wagner}, 
	booktitle={2017 IEEE Symposium on Security and Privacy (SP)}, 
	title={Towards Evaluating the Robustness of Neural Networks}, 
	year={2017}, 
	pages={39-57}, 
	doi={10.1109/SP.2017.49}, 
	ISSN={2375-1207}, 
	month={May},}

@book{coste2002an,
	title="An Introduction to O-minimal Geometry",
	author="Michel {Coste}",
	year={2002}
}

@article{dries1996geometric,
	title="Geometric categories and o-minimal structures",
	author="Lou van den {Dries} and Chris {Miller}",
	journal="Duke Mathematical Journal",
	volume="84",
	number="2",
	pages="497--540",
	year={1996}
}

@InProceedings{He_2015_ICCV,
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	title = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on {ImageNet} Classification},
	booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
	month = {December},
	year = {2015}
}

@inproceedings{
	zhang2018residual,
	title={Fixup Initialization: Residual Learning Without Normalization},
	author={Hongyi Zhang and Yann N. Dauphin and Tengyu Ma},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@incollection{giorgi2004mathematicsChapter4,
	title = "{Chapter IV - Nonsmooth Optimization Problems}",
	author = "Giorgi, Giorgio and Guerraggio, Angelo and Thierfelder, J{\"o}rg",
	booktitle = "Mathematics of Optimization",
	publisher = "Elsevier Science",
	address = "Amsterdam",
	pages = "359 - 457",
	year = {2004},
	isbn = "978-0-444-50550-7"
}

@inproceedings{
	szegedy2013intriguing,
	title={Intriguing properties of neural networks},
	author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
	booktitle={International Conference on Learning Representations},
	year={2013}
}

@InProceedings{biggio2013evasion,
	author="Biggio, Battista
	and Corona, Igino
	and Maiorca, Davide
	and Nelson, Blaine
	and {\v{S}}rndi{\'{c}}, Nedim
	and Laskov, Pavel
	and Giacinto, Giorgio
	and Roli, Fabio",
	editor="Blockeel, Hendrik
	and Kersting, Kristian
	and Nijssen, Siegfried
	and {\v{Z}}elezn{\'y}, Filip",
	title="Evasion Attacks against Machine Learning at Test Time",
	booktitle="Machine Learning and Knowledge Discovery in Databases",
	year={2013},
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="387--402",
}

@article{ramdas2016towards,
	title={Towards a deeper geometric, analytic and algorithmic understanding of margins},
	author={Ramdas, Aaditya and Pena, Javier},
	journal={Optimization Methods and Software},
	volume={31},
	number={2},
	pages={377--391},
	year={2016},
	publisher={Taylor \& Francis}
}

@InProceedings{telgarsky13margins,
	title = 	 {Margins, Shrinkage, and Boosting},
	author = 	 {Matus Telgarsky},
	booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning},
	pages = 	 {307--315},
	year = 	 {2013},
	editor = 	 {Sanjoy Dasgupta and David McAllester},
	volume = 	 {28},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Atlanta, Georgia, USA},
	month = 	 {17--19 Jun},
	publisher = 	 {PMLR}
}

@article{schapire1998boosting,
	author = "Schapire, Robert E. and Freund, Yoav and Bartlett, Peter and Lee, Wee Sun",
	doi = "10.1214/aos/1024691352",
	fjournal = "The Annals of Statistics",
	journal = "Ann. Statist.",
	month = "10",
	number = "5",
	pages = "1651--1686",
	publisher = "The Institute of Mathematical Statistics",
	title = "Boosting the margin: A new explanation for the effectiveness of voting methods",
	volume = "26",
	year = "1998"
}

@book{schapire2012boosting,
	author = {Schapire, Robert E. and Freund, Yoav},
	title = {Boosting: Foundations and Algorithms},
	year = {2012},
	isbn = {0262017180, 9780262017183},
	publisher = {The MIT Press},
}

@article{shalev2010equivalence,
	title={On the equivalence of weak learnability and linear separability: New relaxations and efficient boosting algorithms},
	author={Shalev-Shwartz, Shai and Singer, Yoram},
	journal={Machine learning},
	volume={80},
	number={2-3},
	pages={141--163},
	year={2010},
	publisher={Springer}
}


@InProceedings{athalye2018obfuscated,
	title = 	 {Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples},
	author = 	 {Athalye, Anish and Carlini, Nicholas and Wagner, David},
	booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
	pages = 	 {274--283},
	year = 	 {2018},
	editor = 	 {Dy, Jennifer and Krause, Andreas},
	volume = 	 {80},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Stockholmsmässan, Stockholm Sweden},
	month = 	 {10--15 Jul},
	publisher = 	 {PMLR}
}

@article{absil2005convergence,
	title={Convergence of the iterates of descent methods for analytic cost functions},
	author={Absil, Pierre-Antoine and Mahony, Robert and Andrews, Benjamin},
	journal={SIAM Journal on Optimization},
	volume={16},
	number={2},
	pages={531--547},
	year={2005},
	publisher={SIAM}
}

@article{curry1944method,
	title={The method of steepest descent for non-linear minimization problems},
	author={Curry, Haskell B},
	journal={Quarterly of Applied Mathematics},
	volume={2},
	number={3},
	pages={258--261},
	year={1944}
}

@article{zoutendijk1976mathematical,
	title={Mathematical programming methods},
	author={Zoutendijk, Guus},
	year={1976},
	publisher={North-Holland}
}

@book{palis2012geometric,
	title={Geometric theory of dynamical systems: an introduction},
	author={Palis, J Jr and De Melo, Welington},
	year={2012},
	publisher={Springer Science \& Business Media}
}







@InProceedings{golowich18a,
	title = 	 {Size-Independent  Sample Complexity of Neural Networks},
	author = 	 {Golowich, Noah and Rakhlin, Alexander and Shamir, Ohad},
	booktitle = 	 {Proceedings of the 31st  Conference On Learning Theory},
	pages = 	 {297--299},
	year = 	 {2018},
	editor = 	 {Bubeck, S\'ebastien and Perchet, Vianney and Rigollet, Philippe},
	volume = 	 {75},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {},
	month = 	 {06--09 Jul},
	publisher = 	 {PMLR}
}

@article{li2018tighter,
	title={On tighter generalization bound for deep neural networks: {CNNs}, {R}es{N}ets, and beyond},
	author={Li, Xingguo and Lu, Junwei and Wang, Zhaoran and Haupt, Jarvis and Zhao, Tuo},
	journal={arXiv preprint arXiv:1806.05159},
	year={2018}
}

@inproceedings{
	wei2020improved,
	title={Improved Sample Complexities for Deep Neural Networks and Robust Classification via an All-Layer Margin},
	author={Colin Wei and Tengyu Ma},
	booktitle={International Conference on Learning Representations},
	year={2020}
}







@InProceedings{anil2019sorting,
	title = 	 {Sorting Out {L}ipschitz Function Approximation},
	author = 	 {Anil, Cem and Lucas, James and Grosse, Roger},
	booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
	pages = 	 {291--301},
	year = 	 {2019},
	editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
	volume = 	 {97},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Long Beach, California, USA},
	month = 	 {09--15 Jun},
	publisher = 	 {PMLR}
}


@InProceedings{precup2017parseval,
title = 	 {Parseval Networks: Improving Robustness to Adversarial Examples},
author = 	 {Moustapha Cisse and Piotr Bojanowski and Edouard Grave and Yann Dauphin and Nicolas Usunier},
booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
pages = 	 {854--863},
year = 	 {2017},
editor = 	 {Doina Precup and Yee Whye Teh},
volume = 	 {70},
series = 	 {Proceedings of Machine Learning Research},
address = 	 {International Convention Centre, Sydney, Australia},
month = 	 {06--11 Aug},
publisher = 	 {PMLR}
}

@incollection{allen2019can,
title = {Can SGD Learn Recurrent Neural Networks with Provable Generalization?},
author = {Allen-Zhu, Zeyuan and Li, Yuanzhi},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {10331--10341},
year = {2019},
publisher = {Curran Associates, Inc.},
}

@incollection{du2019graph,
title = {Graph Neural Tangent Kernel: Fusing Graph Neural Networks with Graph Kernels},
author = {Du, Simon S and Hou, Kangcheng and Salakhutdinov, Russ R and Poczos, Barnabas and Wang, Ruosong and Xu, Keyulu},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {5723--5733},
year = {2019},
publisher = {Curran Associates, Inc.}
}


@incollection{yehudai2019RF,
title = {On the Power and Limitations of Random Features for Understanding Neural Networks},
author = {Yehudai, Gilad and Shamir, Ohad},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {6598--6608},
year = {2019},
publisher = {Curran Associates, Inc.}
}


@incollection{allen2019resnet,
title = {What Can ResNet Learn Efficiently, Going Beyond Kernels?},
author = {Allen-Zhu, Zeyuan and Li, Yuanzhi},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {9017--9028},
year = {2019},
publisher = {Curran Associates, Inc.}
}

@article{allen2019backward,
	title={Backward Feature Correction: How Deep Learning Performs Deep Learning},
	author={Zeyuan Allen-Zhu and Yuanzhi Li},
	journal={arXiv preprint arXiv:2001.04413},
	year={2020}
}

@incollection{ghorbani2019lazy,
title = {Limitations of Lazy Training of Two-layers Neural Network},
author = {Ghorbani, Behrooz and Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {9111--9121},
year = {2019},
publisher = {Curran Associates, Inc.}
}

@article{daniely2020parities,
	title={Learning Parities with Neural Networks},
	author={Amit Daniely and Eran Malach},
	journal={arXiv preprint arXiv:2002.07400},
	year={2020}
}

@inproceedings{
ji2020polylogarithmic,
title={Polylogarithmic width suffices for gradient descent to achieve arbitrarily small test error with shallow ReLU networks},
author={Ziwei Ji and Matus Telgarsky},
booktitle={International Conference on Learning Representations},
year={2020}
}

@inproceedings{welling11langevin,
	title = {Bayesian Learning via Stochastic Gradient Langevin Dynamics},
	author = {Welling, Max and Teh, Yee Whye},
	year = {2011},
	isbn = {9781450306195},
	publisher = {Omnipress},
	address = {Madison, WI, USA},
	booktitle = {Proceedings of the 28th International Conference on International Conference on Machine Learning},
	pages = {681-688},
	numpages = {8},
	location = {Bellevue, Washington, USA},
	series = {ICML '11}
}

@incollection{li19learningrate,
	title = {Towards Explaining the Regularization Effect of Initial Large Learning Rate in Training Neural Networks},
	author = {Li, Yuanzhi and Wei, Colin and Ma, Tengyu},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {11674--11685},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@article{shi2020learning,
	title={On Learning Rates and Schr\"{o}dinger Operators},
	author={Shi, Bin and Su, Weijie J and Jordan, Michael I},
	journal={arXiv preprint arXiv:2004.06977},
	year={2020}
}

@inproceedings{
	zhang2018three,
	title={Three Mechanisms of Weight Decay Regularization},
	author={Guodong Zhang and Chaoqi Wang and Bowen Xu and Roger Grosse},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@inproceedings{
	hoffer2018fix,
	title={Fix your classifier: the marginal value of training the last weight layer},
	author={Elad Hoffer and Itay Hubara and Daniel Soudry},
	booktitle={International Conference on Learning Representations},
	year={2018}
}

@inproceedings{
chaudhari2018stochastic,
title={Stochastic gradient descent performs variational inference, converges to limit cycles for deep networks},
author={Pratik Chaudhari and Stefano Soatto},
booktitle={International Conference on Learning Representations},
year={2018}
}

@article{you2020limit,
  title={The Limit of the Batch Size},
  author={You, Yang and Wang, Yuhui and Zhang, Huan and Zhang, Zhao and Demmel, James and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:2006.08517},
  year={2020}
}

@inproceedings{
loshchilov2018decoupled,
title={Decoupled Weight Decay Regularization},
author={Ilya Loshchilov and Frank Hutter},
booktitle={International Conference on Learning Representations},
year={2019}
}

@incollection{bengio2012practical,
	title={Practical recommendations for gradient-based training of deep architectures},
	author={Bengio, Yoshua},
	booktitle={Neural networks: Tricks of the trade},
	pages={437--478},
	year={2012},
	publisher={Springer}
}

@inproceedings{
	smith2018a,
	title={A Bayesian Perspective on Generalization and Stochastic Gradient Descent},
	author={Samuel L. Smith and Quoc V. Le},
	booktitle={International Conference on Learning Representations},
	year={2018}
}

@article{hochreiter1997flat,
	title={Flat minima},
	author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
	journal={Neural Computation},
	volume={9},
	number={1},
	pages={1--42},
	year={1997},
	publisher={MIT Press}
}

@inproceedings{
	smith2018dont,
	title={Don't Decay the Learning Rate, Increase the Batch Size},
	author={Samuel L. Smith and Pieter-Jan Kindermans and Quoc V. Le},
	booktitle={International Conference on Learning Representations},
	year={2018}
}

@incollection{li2018visualizing,
	title = {Visualizing the Loss Landscape of Neural Nets},
	author = {Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
	booktitle = {Advances in Neural Information Processing Systems 31},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	pages = {6389--6399},
	year = {2018},
	publisher = {Curran Associates, Inc.}
}

@inproceedings{izmailov2018averaging,
	title = "Averaging weights leads to wider optima and better generalization",
	author = "Pavel Izmailov and Dmitrii Podoprikhin and Timur Garipov and Dmitry Vetrov and Wilson, {Andrew Gordon}",
	year = "2018",
	month = jan,
	day = "1",
	language = "English (US)",
	series = "34th Conference on Uncertainty in Artificial Intelligence 2018, UAI 2018",
	publisher = "Association For Uncertainty in Artificial Intelligence (AUAI)",
	pages = "876--885",
	editor = "Ricardo Silva and Amir Globerson and Amir Globerson",
	booktitle = "34th Conference on Uncertainty in Artificial Intelligence 2018, UAI 2018",
	note = "34th Conference on Uncertainty in Artificial Intelligence 2018, UAI 2018 ; Conference date: 06-08-2018 Through 10-08-2018",
}

@incollection{he2019asym,
	title = {Asymmetric Valleys: Beyond Sharp and Flat Local Minima},
	author = {He, Haowei and Huang, Gao and Yuan, Yang},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {2553--2564},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@article{netzer2011reading,
  title={Reading digits in natural images with unsupervised feature learning},
  author={Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
  year={2011}
}

@misc{smith2021origin,
      title={On the Origin of Implicit Regularization in Stochastic Gradient Descent}, 
      author={Samuel L. Smith and Benoit Dherin and David G. T. Barrett and Soham De},
      year={2021},
      eprint={2101.12176},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{foret2020sharpnessaware,
      title={Sharpness-Aware Minimization for Efficiently Improving Generalization}, 
      author={Pierre Foret and Ariel Kleiner and Hossein Mobahi and Behnam Neyshabur},
      year={2020},
      eprint={2010.01412},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@incollection{hanson1989comparing,
	title = {Comparing Biases for Minimal Network Construction with Back-Propagation},
	author = {Stephen Jose Hanson and Lorien Y. Pratt},
	booktitle = {Advances in Neural Information Processing Systems 1},
	editor = {D. S. Touretzky},
	pages = {177--185},
	year = {1989},
	publisher = {Morgan-Kaufmann}
}

@inproceedings{garipov2018loss,
  title={Loss surfaces, mode connectivity, and fast ensembling of dnns},
  author={Garipov, Timur and Izmailov, Pavel and Podoprikhin, Dmitrii and Vetrov, Dmitry P and Wilson, Andrew G},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8789--8798},
  year={2018}
}

@article{draxler2018essentially,
  title={Essentially no barriers in neural network energy landscape},
  author={Draxler, Felix and Veschgini, Kambis and Salmhofer, Manfred and Hamprecht, Fred A},
  journal={arXiv preprint arXiv:1803.00885},
  year={2018}
}

@article{loshchilov2016sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1608.03983},
  year={2016}
}

@inproceedings{smith2019super,
  title={Super-convergence: Very fast training of neural networks using large learning rates},
  author={Smith, Leslie N and Topin, Nicholay},
  booktitle={Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications},
  volume={11006},
  pages={1100612},
  year={2019},
  organization={International Society for Optics and Photonics}
}

@inproceedings{li2017stochastic,
  title={Stochastic modified equations and adaptive stochastic gradient algorithms},
  author={Li, Qianxiao and Tai, Cheng and Weinan, E},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2101--2110},
  year={2017},
  organization={JMLR. org}
}

@incollection{hoffer2018norm,
	title = {Norm matters: efficient and accurate normalization schemes in deep networks},
	author = {Hoffer, Elad and Banner, Ron and Golan, Itay and Soudry, Daniel},
	booktitle = {Advances in Neural Information Processing Systems 31},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	pages = {2160--2170},
	year = {2018},
	publisher = {Curran Associates, Inc.}
}

@incollection{hoffer2017train,
	title = {Train longer, generalize better: closing the generalization gap in large batch training of neural networks},
	author = {Hoffer, Elad and Hubara, Itay and Soudry, Daniel},
	booktitle = {Advances in Neural Information Processing Systems 30},
	editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	pages = {1731--1741},
	year = {2017},
	publisher = {Curran Associates, Inc.}
}

@article{wen2019interplay,
	title={Interplay between optimization and generalization of stochastic gradient descent with covariance noise},
	author={Wen, Yeming and Luk, Kevin and Gazeau, Maxime and Zhang, Guodong and Chan, Harris and Ba, Jimmy},
	journal={arXiv preprint arXiv:1902.08234},
	year={2019}
}

@Inbook{LeCun2012efficient,
	author="LeCun, Yann A.
	and Bottou, L{\'e}on
	and Orr, Genevieve B.
	and M{\"u}ller, Klaus-Robert",
	editor="Montavon, Gr{\'e}goire
	and Orr, Genevi{\`e}ve B.
	and M{\"u}ller, Klaus-Robert",
	title="Efficient BackProp",
	bookTitle="Neural Networks: Tricks of the Trade: Second Edition",
	year="2012",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="9--48",
	isbn="978-3-642-35289-8",
	doi="10.1007/978-3-642-35289-8_3",
}

@article{shallue2019measuring,
	author  = {Christopher J. Shallue and Jaehoon Lee and Joseph Antognini and Jascha Sohl-Dickstein and Roy Frostig and George E. Dahl},
	title   = {Measuring the Effects of Data Parallelism on Neural Network Training},
	journal = {Journal of Machine Learning Research},
	year    = {2019},
	volume  = {20},
	number  = {112},
	pages   = {1-49},
	url     = {http://jmlr.org/papers/v20/18-789.html}
}


@article{van2017l2,
	title={L2 regularization versus batch and weight normalization},
	author={van Laarhoven, Twan},
	journal={arXiv preprint arXiv:1706.05350},
	year={2017}
}







@InProceedings{cai2019aquantitative,
	title = 	 {A Quantitative Analysis of the Effect of Batch Normalization on Gradient Descent},
	author = 	 {Cai, Yongqiang and Li, Qianxiao and Shen, Zuowei},
	booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
	pages = 	 {882--890},
	year = 	 {2019},
	editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
	volume = 	 {97},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Long Beach, California, USA},
	month = 	 {09--15 Jun},
	publisher = 	 {PMLR}
}

 @inproceedings{zagoruyko16wide,
	title={Wide Residual Networks},
	author={Sergey Zagoruyko and Nikos Komodakis},
	year={2016},
	month={September},
	pages={87.1-87.12},
	articleno={87},
	numpages={12},
	booktitle={Proceedings of the British Machine Vision Conference (BMVC)},
	publisher={BMVA Press},
	editor={Richard C. Wilson, Edwin R. Hancock and William A. P. Smith},
	doi={10.5244/C.30.87},
	isbn={1-901725-59-6}
}

@inproceedings{
xie2021diffusion,
title={A Diffusion Theory For Deep Learning Dynamics: Stochastic Gradient Descent Exponentially Favors Flat Minima},
author={Zeke Xie and Issei Sato and Masashi Sugiyama},
booktitle={International Conference on Learning Representations},
year={2021},
}


@article{bovier2004metastability,
	author = {Bovier, Anton, Eckhoff, Michael, Gayrard, Véronique, Klein, Markus},
	journal = {Journal of the European Mathematical Society},
	keywords = {metastability; reversible diffusion processes; potential theory; capacity; exit times; Ito stochastic differential equation; reversible diffusion processes; Ito stochastic differential equation},
	language = {eng},
	number = {4},
	pages = {399-424},
	publisher = {European Mathematical Society Publishing House},
	title = {Metastability in reversible diffusion processes I: Sharp asymptotics for capacities and exit times},
	volume = {006},
	year = {2004},
}

@InProceedings{zhu2019anisotropic, 
title = {The Anisotropic Noise in Stochastic Gradient Descent: Its Behavior of Escaping from Sharp Minima and Regularization Effects}, 
author = {Zhu, Zhanxing and Wu, Jingfeng and Yu, Bing and Wu, Lei and Ma, Jinwen}, 
booktitle = {Proceedings of the 36th International Conference on Machine Learning}, pages = {7654--7663}, 
year = {2019}, editor = {Kamalika Chaudhuri and Ruslan Salakhutdinov}, volume = {97}, 
series = {Proceedings of Machine Learning Research}, month = {09--15 Jun}, 
}

@inproceedings{cheng2020stochastic,
  title={Stochastic gradient and langevin processes},
  author={Cheng, Xiang and Yin, Dong and Bartlett, Peter and Jordan, Michael},
  booktitle={International Conference on Machine Learning},
  pages={1810--1819},
  year={2020},
  organization={PMLR}
}

@misc{smith2020generalization,
    title={On the Generalization Benefit of Noise in Stochastic Gradient Descent},
    author={Samuel L. Smith and Erich Elsen and Soham De},
    year={2020},
    eprint={2006.15081},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{goyal2017accurate,
  title={Accurate, large minibatch sgd: Training imagenet in 1 hour},
  author={Goyal, Priya and Doll{\'a}r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  journal={arXiv preprint arXiv:1706.02677},
  year={2017}
}


@article{mandt2017stochastic,
  title={Stochastic gradient descent as approximate bayesian inference},
  author={Mandt, Stephan and Hoffman, Matthew D and Blei, David M},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={4873--4907},
  year={2017},
  publisher={JMLR. org}
}


@article{lewkowycz2020training,
	title={On the training dynamics of deep networks with $ L\_2 $ regularization},
	author={Lewkowycz, Aitor and Gur-Ari, Guy},
	journal={arXiv preprint arXiv:2006.08643},
	year={2020}
}

@inproceedings{
cohen2021gradient,
title={Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability},
author={Jeremy Cohen and Simran Kaur and Yuanzhi Li and J Zico Kolter and Ameet Talwalkar},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=jh-rTtvkGeM}
}

@article{krizhevsky2014one,
  title={One weird trick for parallelizing convolutional neural networks},
  author={Krizhevsky, Alex},
  journal={arXiv preprint arXiv:1404.5997},
  year={2014}
}

@article{protter1997euler,
  title={The Euler scheme for L{\'e}vy driven stochastic differential equations},
  author={Protter, Philip and Talay, Denis and others},
  journal={The Annals of Probability},
  volume={25},
  number={1},
  pages={393--423},
  year={1997},
  publisher={Institute of Mathematical Statistics}
}

@article{mohammadi2015estimating,
  title={On estimating the tail index and the spectral measure of multivariate  $\alpha$-stable distributions},
  author={Mohammadi, Mohammad and Mohammadpour, Adel and Ogata, Hiroaki},
  journal={Metrika},
  volume={78},
  number={5},
  pages={549--561},
  year={2015},
  publisher={Springer}
}

@inproceedings{zhang2020adaptive,
 author = {Zhang, Jingzhao and Karimireddy, Sai Praneeth and Veit, Andreas and Kim, Seungyeon and Reddi, Sashank and Kumar, Sanjiv and Sra, Suvrit},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {15383--15393},
 publisher = {Curran Associates, Inc.},
 title = {Why are Adaptive Methods Good for Attention Models?},
 volume = {33},
 year = {2020}
}

@book{ken1999levy,
  title={L{\'e}vy processes and infinitely divisible distributions},
  author={Ken-Iti, Sato},
  year={1999},
  publisher={Cambridge university press}
}

@misc{
zhang2020why,
title={Why {\{}ADAM{\}} Beats {\{}SGD{\}} for Attention Models	},
author={Jingzhao Zhang and Sai Praneeth Karimireddy and Andreas Veit and Seungyeon Kim and Sashank J Reddi and Sanjiv Kumar and Suvrit Sra},
year={2020},
url={https://openreview.net/forum?id=SJx37TEtDH}
}

@inproceedings{zhou2020theoretically,
 author = {Zhou, Pan and Feng, Jiashi and Ma, Chao and Xiong, Caiming and Hoi, Steven Chu Hong and E, Weinan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {21285--21296},
 publisher = {Curran Associates, Inc.},
 title = {Towards Theoretically Understanding Why {SGD} Generalizes Better Than {A}dam in Deep Learning},
 volume = {33},
 year = {2020}
}



@article{li2019stochastic,
  author  = {Qianxiao Li and Cheng Tai and Weinan E},
  title   = {Stochastic Modified Equations and Dynamics of Stochastic Gradient Algorithms {I}: Mathematical Foundations},
  journal = {Journal of Machine Learning Research},
  year    = {2019},
  volume  = {20},
  number  = {40},
  pages   = {1-47}
}

@InProceedings{ma2020qualitative,
  title = 	 {A Qualitative Study of the Dynamic Behavior for Adaptive Gradient Algorithms},
  author =       {Ma, Chao and Wu, Lei and E, Weinan},
  booktitle = 	 {Proceedings of the 2nd Mathematical and Scientific Machine Learning Conference},
  pages = 	 {671--692},
  year = 	 {2022},
  editor = 	 {Bruna, Joan and Hesthaven, Jan and Zdeborova, Lenka},
  volume = 	 {145},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {16--19 Aug},
  publisher =    {PMLR},
}

@incollection{santurkar2018does,
	title = {How Does Batch Normalization Help Optimization?},
	author = {Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew and Madry, Aleksander},
	booktitle = {Advances in Neural Information Processing Systems 31},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	pages = {2483--2493},
	year = {2018},
	publisher = {Curran Associates, Inc.},
}

@article{kohler2018towards,
	title={Towards a Theoretical Understanding of Batch Normalization},
	author={Kohler, Jonas and Daneshmand, Hadi and Lucchi, Aurelien and Zhou, Ming and Neymeyr, Klaus and Hofmann, Thomas},
	journal={arXiv preprint arXiv:1805.10694},
	year={2018}
}

@article{wu2018wngrad,
	title={WNGrad: Learn the Learning Rate in Gradient Descent},
	author={Wu, Xiaoxia and Ward, Rachel and Bottou, L{\'e}on},
	journal={arXiv preprint arXiv:1803.02865},
	year={2018}
}

@article{ward2018adagrad,
	title={AdaGrad stepsizes: Sharp convergence over nonconvex landscapes, from any initialization},
	author={Ward, Rachel and Wu, Xiaoxia and Bottou, Leon},
	journal={arXiv preprint arXiv:1806.01811},
	year={2018}
}

@article{li2018convergence,
	title={On the Convergence of Stochastic Gradient Descent with Adaptive Stepsizes},
	author={Li, Xiaoyu and Orabona, Francesco},
	journal={arXiv preprint arXiv:1805.08114},
	year={2018}
}

@article{zou2018convergence,
	title={On the Convergence of AdaGrad with Momentum for Training Deep Neural Networks},
	author={Zou, Fangyu and Shen, Li},
	journal={arXiv preprint arXiv:1808.03408},
	year={2018}
}

@article{zhou2018on,
	title={On the Convergence of Adaptive Gradient Methods for Nonconvex Optimization},
	author={Zhou, Dongruo and Tang, Yiqi and Yang, Ziyan and Cao, Yuan and Gu, Quanquan},
	journal={arXiv preprint arXiv:1808.05671},
	year={2018}
}

@inproceedings{salimans2016weight,
	title={Weight normalization: A simple reparameterization to accelerate training of deep neural networks},
	author={Salimans, Tim and Kingma, Diederik P},
	booktitle={Advances in Neural Information Processing Systems},
	pages={901--909},
	year={2016}
}


@inproceedings{arora2018optimization,
  title={On the optimization of deep networks: Implicit acceleration by overparameterization},
  author={Arora, Sanjeev and Cohen, N and Hazan, Elad},
  booktitle={35th International Conference on Machine Learning},
  year={2018}
}
@article{ba2016layer,
	title={Layer normalization},
	author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
	journal={arXiv preprint arXiv:1607.06450},
	year={2016}
}

@article{wu2018group,
	title={Group normalization},
	author={Wu, Yuxin and He, Kaiming},
	journal={arXiv preprint arXiv:1803.08494},
	year={2018}
}

@inproceedings{glorot2011deep,
	title={Deep sparse rectifier neural networks},
	author={Glorot, Xavier and Bordes, Antoine and Bengio, Yoshua},
	booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
	pages={315--323},
	year={2011}
}

@inproceedings{dugas2001incorporating,
	title={Incorporating second-order functional knowledge for better option pricing},
	author={Dugas, Charles and Bengio, Yoshua and B{\'e}lisle, Fran{\c{c}}ois and Nadeau, Claude and Garcia, Ren{\'e}},
	booktitle={Advances in neural information processing systems},
	pages={472--478},
	year={2001}
}

@inproceedings{nair2010rectified,
	title={Rectified linear units improve restricted boltzmann machines},
	author={Nair, Vinod and Hinton, Geoffrey E},
	booktitle={Proceedings of the 27th international conference on machine learning (ICML-10)},
	pages={807--814},
	year={2010}
}

@inproceedings{cho2017riemannian,
	title={Riemannian approach to batch normalization},
	author={Cho, Minhyung and Lee, Jaehyung},
	booktitle={Advances in Neural Information Processing Systems},
	pages={5225--5235},
	year={2017}
}



@inproceedings{huang2017densely,
	title={Densely Connected Convolutional Networks},
	author={Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q},
	booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages={2261--2269},
	year={2017},
	organization={IEEE}
}

@inproceedings{szegedy2017inception,
	title={Inception-v4, inception-resnet and the impact of residual connections on learning.},
	author={Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alexander A},
	booktitle={AAAI},
	volume={4},
	pages={12},
	year={2017}
}

@inproceedings{ioffe2017renorm,
	title={Batch renormalization: Towards reducing minibatch dependence in batch-normalized models},
	author={Ioffe, Sergey},
	booktitle={Advances in Neural Information Processing Systems},
	pages={1945--1953},
	year={2017}
}

@article{ulyanov2016IN,
	title={Instance Normalization: The Missing Ingredient for Fast Stylization},
	author={Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
	journal={arXiv preprint arXiv:1607.08022},
	year={2016}
}

@article{jain2017non,
	title={Non-convex optimization for machine learning},
	author={Jain, Prateek and Kar, Purushottam and others},
	journal={Foundations and Trends{\textregistered} in Machine Learning},
	volume={10},
	number={3-4},
	pages={142--336},
	year={2017},
	publisher={Now Publishers, Inc.}
}


@book{vapnik2013nature,
	title={The nature of statistical learning theory},
	author={Vapnik, Vladimir},
	year={2013},
	publisher={Springer science \& business media}
}

@inproceedings{zhang2017rethinking,
	title={Understanding deep learning requires rethinking generalization},
	author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
	booktitle={International Conference on Learning Representations},
	year={2017}
}

@inproceedings{szegedy2016rethinking,
	author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
	title = {Rethinking the Inception Architecture for Computer Vision},
	booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2016}
}

@inproceedings{neyshabur2017norm,
	title={A {PAC}-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks},
	author={Behnam Neyshabur and Srinadh Bhojanapalli and Nathan Srebro},
	booktitle={International Conference on Learning Representations},
	year={2018}
}

@incollection{bartlett2017norm,
	title = {Spectrally-normalized margin bounds for neural networks},
	author = {Bartlett, Peter L and Foster, Dylan J and Telgarsky, Matus J},
	booktitle = {Advances in Neural Information Processing Systems 30},
	editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	pages = {6240--6249},
	year = {2017},
	publisher = {Curran Associates, Inc.}
}

@article{li2018intrinsic,
	title={Measuring the intrinsic dimension of objective landscapes},
	author={Li, Chunyuan and Farkhoor, Heerad and Liu, Rosanne and Yosinski, Jason},
	journal={arXiv preprint arXiv:1804.08838},
	year={2018}
}


@inproceedings{soudry2018iclrImplicit,
	title={The Implicit Bias of Gradient Descent on Separable Data},
	author={Daniel Soudry and Elad Hoffer and Nathan Srebro},
	booktitle={International Conference on Learning Representations},
	year={2018}
}


@article{soudry2018implicit,
	author  = {Daniel Soudry and Elad Hoffer and Mor Shpigel Nacson and Suriya Gunasekar and Nathan Srebro},
	title   = {The Implicit Bias of Gradient Descent on Separable Data},
	journal = {Journal of Machine Learning Research},
	year    = {2018},
	volume  = {19},
	number  = {70},
	pages   = {1-57}
}


@inproceedings{li2018algorithmic,
	title = {Algorithmic Regularization in Over-parameterized Matrix Sensing and Neural Networks with Quadratic Activations},
	author = {Li, Yuanzhi and Ma, Tengyu and Zhang, Hongyang},
	booktitle = {Proceedings of the 31st  Conference On Learning Theory},
	pages = {2--47},
	year = {2018},
	editor = {Bubeck, S\'ebastien and Perchet, Vianney and Rigollet, Philippe},
	volume = {75},
	series = {Proceedings of Machine Learning Research},
	address = {},
	month = {06--09 Jul},
	publisher = {PMLR}
}

@InProceedings{du2018power,
	title = 	 {On the Power of Over-parametrization in Neural Networks with Quadratic Activation},
	author = 	 {Du, Simon and Lee, Jason},
	booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
	pages = 	 {1329--1338},
	year = 	 {2018},
	editor = 	 {Dy, Jennifer and Krause, Andreas},
	volume = 	 {80},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Stockholmsm\"{a}ssan, Stockholm Sweden},
	month = 	 {10--15 Jul},
	publisher = 	 {PMLR}
}

@article{klusowski2018approximation,
	title={Approximation by Combinations of ReLU and Squared ReLU Ridge Functions With $\ell^1$ and $\ell^0$ Controls},
	author={Klusowski, Jason M and Barron, Andrew R},
	journal={IEEE Transactions on Information Theory},
	volume={64},
	number={12},
	pages={7649--7656},
	year={2018},
	publisher={IEEE}
}

@article{li2019better,
	title={Better Approximations of High Dimensional Smooth Functions by Deep Neural Networks with Rectified Power Units},
	author={Li, Bo and Tang, Shanshan and Yu, Haijun},
	journal={arXiv preprint arXiv:1903.05858},
	year={2019}
}

@InProceedings{zhong2017recovery,
	title = {Recovery Guarantees for One-hidden-layer Neural Networks},
	author = {Kai Zhong and Zhao Song and Prateek Jain and Peter L. Bartlett and Inderjit S. Dhillon},
	booktitle = {Proceedings of the 34th International Conference on Machine Learning},
	pages = {4140--4149},
	year = {2017},
	editor = {Doina Precup and Yee Whye Teh},
	volume = {70},
	series = {Proceedings of Machine Learning Research},
	address = {International Convention Centre, Sydney, Australia},
	month = {06--11 Aug},
	publisher = {PMLR}
}

@incollection{gunasekar2018implicit,
	title = {Implicit Bias of Gradient Descent on Linear Convolutional Networks},
	author = {Gunasekar, Suriya and Lee, Jason D and Soudry, Daniel and Srebro, Nati},
	booktitle = {Advances in Neural Information Processing Systems 31},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	pages = {9482--9491},
	year = {2018},
	publisher = {Curran Associates, Inc.}
}

@article{mou2017generalization,
	title={Generalization bounds of SGLD for non-convex learning: Two theoretical viewpoints},
	author={Mou, Wenlong and Wang, Liwei and Zhai, Xiyu and Zheng, Kai},
	journal={arXiv preprint arXiv:1707.05947},
	year={2017}
}

@misc{allenzhu2018gobeyond,
	Author = {Zeyuan Allen-Zhu and Yuanzhi Li and Yingyu Liang},
	Title = {Learning and Generalization in Overparameterized Neural Networks, Going Beyond Two Layers},
	Year = {2018},
	Eprint = {arXiv:1811.04918},
}







@InProceedings{allenzhu2018convergence,
	title = 	 {A Convergence Theory for Deep Learning via Over-Parameterization},
	author = 	 {Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
	booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
	pages = 	 {242--252},
	year = 	 {2019},
	editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
	volume = 	 {97},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Long Beach, California, USA},
	month = 	 {09--15 Jun},
	publisher = 	 {PMLR},
	pdf = 	 {http://proceedings.mlr.press/v97/allen-zhu19a/allen-zhu19a.pdf},
}

@InProceedings{du2018global,
	title = 	 {Gradient Descent Finds Global Minima of Deep Neural Networks},
	author = 	 {Du, Simon and Lee, Jason and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
	booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
	pages = 	 {1675--1685},
	year = 	 {2019},
	editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
	volume = 	 {97},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Long Beach, California, USA},
	month = 	 {09--15 Jun},
	publisher = 	 {PMLR}
}

@article{zou2018stochastic,
	title={Stochastic gradient descent optimizes over-parameterized deep relu networks},
	author={Zou, Difan and Cao, Yuan and Zhou, Dongruo and Gu, Quanquan},
	journal={arXiv preprint arXiv:1811.08888},
	year={2018}
}

@incollection{du2018algorithmic,
	title = {Algorithmic Regularization in Learning Deep Homogeneous Models: Layers are Automatically Balanced},
	author = {Du, Simon S. and Hu, Wei and Lee, Jason D.},
	booktitle = {Advances in Neural Information Processing Systems 31},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	pages = {382--393},
	year = {2018},
	publisher = {Curran Associates, Inc.}
}

@inproceedings{
	du2018gradient,
	title={Gradient Descent Provably Optimizes Over-parameterized Neural Networks},
	author={Simon S. Du and Xiyu Zhai and Barnabas Poczos and Aarti Singh},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@article{clarke1975generalized,
	title={Generalized gradients and applications},
	author={Clarke, Frank H.},
	journal={Transactions of the American Mathematical Society},
	volume={205},
	pages={247--262},
	year={1975}
}


@book{clarke1990optimization,
	author = {Clarke, Frank H},
	title = {Optimization and Nonsmooth Analysis},
	publisher = {Society for Industrial and Applied Mathematics},
	year = {1990},
	doi = {10.1137/1.9781611971309}
}

@article{drusvyatskiy2015curves,
  title={Curves of descent},
  author={Drusvyatskiy, Dmitriy and Ioffe, Alexander D and Lewis, Adrian S},
  journal={SIAM Journal on Control and Optimization},
  volume={53},
  number={1},
  pages={114--138},
  year={2015},
  publisher={SIAM}
}

@book{clarke2008nonsmooth,
	title={Nonsmooth analysis and control theory},
	author={Clarke, Francis H. and Ledyaev, Yuri S. and Stern, Ronald J. and Wolenski, Peter R.},
	volume={178},
	year={2008},
	publisher={Springer Science \& Business Media}
}

@article{davis2018stochastic,
	author={Davis, Damek
	and Drusvyatskiy, Dmitriy
	and Kakade, Sham
	and Lee, Jason D.},
	title={Stochastic Subgradient Method Converges on Tame Functions},
	journal={Foundations of Computational Mathematics},
	volume={20},
	number={1},
	year={2020},
	month={Feb},
	pages={119-154}
}

@article{ma2019implicit,
	title={Implicit regularization in nonconvex statistical estimation: Gradient descent converges linearly for phase retrieval, matrix completion, and blind deconvolution},
	author={Ma, Cong and Wang, Kaizheng and Chi, Yuejie and Chen, Yuxin},
	journal={Foundations of Computational Mathematics},
	year={2019},
	month={Aug},
	day={05}
}

@inproceedings{
	ji2018gradient,
	title={Gradient descent aligns the layers of deep linear networks},
	author={Ziwei Ji and Matus Telgarsky},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@article{xu2018gradient,
	title={When Will Gradient Methods Converge to Max-margin Classifier under ReLU Models?},
	author={Tengyu Xu and Yi Zhou and Kaiyi Ji and Yingbin Liang},
	journal={arXiv preprint arXiv:1806.04339},
	year={2018}
}

@incollection{wei2018margin,
	title = {Regularization Matters: Generalization and Optimization of Neural Nets v.s. their Induced Kernel},
	author = {Wei, Colin and Lee, Jason D and Liu, Qiang and Ma, Tengyu},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {9709--9721},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@article{li2018decision,
	title={On the decision boundary of deep neural networks},
	author={Li, Yu and Richtarik, Peter and Ding, Lizhong and Gao, Xin},
	journal={arXiv preprint arXiv:1808.05385},
	year={2018}
}

@inproceedings{nacson2018stochastic,
	title = {Stochastic Gradient Descent on Separable Data: Exact Convergence with a Fixed Learning Rate},
	author = {Nacson, Mor Shpigel and Srebro, Nathan and Soudry, Daniel},
	booktitle = {Proceedings of Machine Learning Research},
	pages = {3051--3059},
	year = {2019},
	editor = {Chaudhuri, Kamalika and Sugiyama, Masashi},
	volume = {89},
	series = {Proceedings of Machine Learning Research},
	address = {},
	month = {16--18 Apr},
	publisher = {PMLR}
}


@InProceedings{nacson2019convergence,
	title = {Convergence of Gradient Descent on Separable Data},
	author = {Nacson, Mor Shpigel and Lee, Jason and Gunasekar, Suriya and Savarese, Pedro Henrique Pamplona and Srebro, Nathan and Soudry, Daniel},
	booktitle = {Proceedings of Machine Learning Research},
	pages = {3420--3428},
	year = {2019},
	editor = {Chaudhuri, Kamalika and Sugiyama, Masashi},
	volume = {89},
	series = {Proceedings of Machine Learning Research},
	address = {},
	month = {16--18 Apr},
	publisher = {PMLR}
}


@article{ji2018risk,
	title={Risk and parameter convergence of logistic regression},
	author={Ji, Ziwei and Telgarsky, Matus},
	journal={arXiv preprint arXiv:1803.07300},
	year={2018}
}

@InProceedings{ji2019risk,
	title = {The implicit bias of gradient descent on nonseparable data},
	author = {Ji, Ziwei and Telgarsky, Matus},
	booktitle = {Proceedings of the Thirty-Second Conference on Learning Theory},
	pages = {1772--1798},
	year = {2019},
	editor = {Beygelzimer, Alina and Hsu, Daniel},
	volume = {99},
	series = {Proceedings of Machine Learning Research},
	address = {Phoenix, USA},
	month = {25--28 Jun},
	publisher = {PMLR}
}

@article{ji2019refined,
	title={A refined primal-dual analysis of the implicit bias},
	author={Ji, Ziwei and Telgarsky, Matus},
	journal={arXiv preprint arXiv:1906.04540},
	year={2019}
}

@InProceedings{gunasekar2018characterizing,
	title = 	 {Characterizing Implicit Bias in Terms of Optimization Geometry},
	author = 	 {Gunasekar, Suriya and Lee, Jason and Soudry, Daniel and Srebro, Nathan},
	booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
	pages = 	 {1832--1841},
	year = 	 {2018},
	editor = 	 {Dy, Jennifer and Krause, Andreas},
	volume = 	 {80},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Stockholmsmässan, Stockholm Sweden},
	month = 	 {10--15 Jul},
	publisher = 	 {PMLR},
}

@incollection{wilson2017marginal,
	title = {The Marginal Value of Adaptive Gradient Methods in Machine Learning},
	author = {Wilson, Ashia C and Roelofs, Rebecca and Stern, Mitchell and Srebro, Nati and Recht, Benjamin},
	booktitle = {Advances in Neural Information Processing Systems 30},
	editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	pages = {4148--4158},
	year = {2017},
	publisher = {Curran Associates, Inc.}
}

@article{banburski2019theory,
	title={Theory {III}: Dynamics and Generalization in Deep Networks},
	author={Andrzej Banburski and Qianli Liao and Brando Miranda and Tomaso Poggio and Lorenzo Rosasco and Jack Hidary},
	journal={CBMM Memo No: 090, version 20},
	year={2019}
}


@inproceedings{ali2018continuous,
	title = 	 {A Continuous-Time View of Early Stopping for Least Squares Regression},
	author = 	 {Ali, Alnur and Kolter, J. Zico and Tibshirani, Ryan J.},
	booktitle =  {Proceedings of Machine Learning Research},
	pages = 	 {1370--1378},
	year = 	 {2019},
	editor = 	 {Chaudhuri, Kamalika and Sugiyama, Masashi},
	volume = 	 {89},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {},
	month = 	 {16--18 Apr},
	publisher =  {PMLR}
}

@incollection{suggala2018connecting,
	title = {Connecting Optimization and Regularization Paths},
	author = {Suggala, Arun and Prasad, Adarsh and Ravikumar, Pradeep K},
	booktitle = {Advances in Neural Information Processing Systems 31},
	editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	pages = {10608--10619},
	year = {2018},
	publisher = {Curran Associates, Inc.}
}

@inproceedings{
	azizan2018stochastic,
	title={Stochastic Gradient/Mirror Descent: Minimax Optimality and Implicit Regularization},
	author={Navid Azizan and Babak Hassibi},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@article{keskar2016large,
	title={On large-batch training for deep learning: Generalization gap and sharp minima},
	author={Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
	journal={arXiv preprint arXiv:1609.04836},
	year={2016}
}

@inproceedings{dinh2017sharp,
	title={Sharp minima can generalize for deep nets},
	author={Dinh, Laurent and Pascanu, Razvan and Bengio, Samy and Bengio, Yoshua},
	booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
	pages={1019--1028},
	year={2017},
	organization={JMLR.org}
}

@article{yi2019positively,
	title={Positively Scale-Invariant Flatness of ReLU Neural Networks},
	author={Yi, Mingyang and Meng, Qi and Chen, Wei and Ma, Zhi-ming and Liu, Tie-Yan},
	journal={arXiv preprint arXiv:1903.02237},
	year={2019}
}

@article{jastrzkebski2017three,
  title={Three factors influencing minima in {SGD}},
  author={Jastrz\k{e}bski, Stanis{\l}aw and Kenton, Zachary and Arpit, Devansh and Ballas, Nicolas and Fischer, Asja and Bengio, Yoshua and Storkey, Amos},
  journal={arXiv preprint arXiv:1711.04623},
  year={2017}
}

@incollection{lee2019wide,
	title = {Wide Neural Networks of Any Depth Evolve as Linear Models Under Gradient Descent},
	author = {Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel and Bahri, Yasaman and Novak, Roman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {8570--8581},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@inproceedings{
	arora2018theoretical,
	title={Theoretical Analysis of Auto Rate-Tuning by Batch Normalization},
	author={Sanjeev Arora and Zhiyuan Li and Kaifeng Lyu},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@incollection{arora2019exact,
	title = {On Exact Computation with an Infinitely Wide Neural Net},
	author = {Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Russ R and Wang, Ruosong},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {8139--8148},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@incollection{jacot2018ntk,
title = {Neural Tangent Kernel: Convergence and Generalization in Neural Networks},
author = {Jacot, Arthur and Gabriel, Franck and Hongler, Clement},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {8571--8580},
year = {2018},
publisher = {Curran Associates, Inc.}
}

@incollection{rosset2004margin,
title = {Margin Maximizing Loss Functions},
author = {Rosset, Saharon and Ji Zhu and Trevor J. Hastie},
booktitle = {Advances in Neural Information Processing Systems 16},
editor = {S. Thrun and L. K. Saul and B. Sch\"{o}lkopf},
pages = {1237--1244},
year = {2004},
publisher = {MIT Press}
}

@article{SokolicGSR17,
  author    = {Jure Sokolic and
               Raja Giryes and
               Guillermo Sapiro and
               Miguel R. D. Rodrigues},
  title     = {Robust Large Margin Deep Neural Networks},
  journal   = {{IEEE} Trans. Signal Processing},
  volume    = {65},
  number    = {16},
  pages     = {4265--4280},
  year      = {2017},
  doi       = {10.1109/TSP.2017.2708039},
  timestamp = {Fri, 02 Nov 2018 09:33:28 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/tsp/SokolicGSR17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{arora2018compression,
  title = 	 {Stronger Generalization Bounds for Deep Nets via a Compression Approach},
  author = 	 {Arora, Sanjeev and Ge, Rong and Neyshabur, Behnam and Zhang, Yi},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {254--263},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR}
}







@InProceedings{croce2019provable,
  title = 	 {Provable Robustness of ReLU networks via Maximization of Linear Regions},
  author = 	 {Croce, Francesco and Andriushchenko, Maksym and Hein, Matthias},
  booktitle = 	 {Proceedings of Machine Learning Research},
  pages = 	 {2057--2066},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Sugiyama, Masashi},
  volume = 	 {89},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {16--18 Apr},
  publisher = 	 {PMLR}
}

@InProceedings{nacson2019lexicographic,
	title = 	 {Lexicographic and Depth-Sensitive Margins in Homogeneous and Non-Homogeneous Deep Models},
	author = 	 {Nacson, Mor Shpigel and Gunasekar, Suriya and Lee, Jason and Srebro, Nathan and Soudry, Daniel},
	booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
	pages = 	 {4683--4692},
	year = 	 {2019},
	editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
	volume = 	 {97},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Long Beach, California, USA},
	month = 	 {09--15 Jun},
	publisher = 	 {PMLR}
}

@article{dutta2013approximate,
  title={Approximate {KKT} points and a proximity measure for termination},
  author={Dutta, Joydeep and Deb, Kalyanmoy and Tulshyan, Rupesh and Arora, Ramnik},
  journal={Journal of Global Optimization},
  volume={56},
  number={4},
  pages={1463--1499},
  year={2013},
  publisher={Springer}
}

@incollection{du2017exp,
title = {Gradient Descent Can Take Exponential Time to Escape Saddle Points},
author = {Du, Simon S and Jin, Chi and Lee, Jason D and Jordan, Michael I and Singh, Aarti and Poczos, Barnabas},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {1067--1077},
year = {2017},
publisher = {Curran Associates, Inc.}
}

@incollection{gidel2019implicit,
	title = {Implicit Regularization of Discrete Gradient Dynamics in Linear Neural Networks},
	author = {Gidel, Gauthier and Bach, Francis and Lacoste-Julien, Simon},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {3196--3206},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@incollection{arora2019implicit,
	title = {Implicit Regularization in Deep Matrix Factorization},
	author = {Arora, Sanjeev and Cohen, Nadav and Hu, Wei and Luo, Yuping},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {7411--7422},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@article{blanc2019implicit,
	title={Implicit regularization for deep neural networks driven by an Ornstein-Uhlenbeck like process},
	author={Blanc, Guy and Gupta, Neha and Valiant, Gregory and Valiant, Paul},
	journal={arXiv preprint arXiv:1904.09080},
	year={2019}
}

@incollection{neyshabur2015pathsgd,
	title = {Path-{SGD}: {P}ath-Normalized Optimization in Deep Neural Networks},
	author = {Neyshabur, Behnam and Salakhutdinov, Ruslan R and Srebro, Nati},
	booktitle = {Advances in Neural Information Processing Systems 28},
	editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
	pages = {2422--2430},
	year = {2015},
	publisher = {Curran Associates, Inc.}
}

@inproceedings{neyshabur2014search,
	author    = {Behnam Neyshabur and Ryota Tomioka and Nathan Srebro},
	title     = {In Search of the Real Inductive Bias: On the Role of Implicit Regularization in Deep Learning},
	booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Workshop Track Proceedings},
	year      = {2015}
}

@INPROCEEDINGS{carlini2017towards,
	author={Nicholas Carlini and David Wagner},
	booktitle={2017 IEEE Symposium on Security and Privacy (SP)},
	title={Towards Evaluating the Robustness of Neural Networks},
	year={2017},
	pages={39-57},
	doi={10.1109/SP.2017.49},
	ISSN={2375-1207},
	month={May},}

@book{coste2002an,
	title="An Introduction to O-minimal Geometry",
	author="Michel {Coste}",
	year="2002"
}

@article{dries1996geometric,
	title="Geometric categories and o-minimal structures",
	author="Lou van den {Dries} and Chris {Miller}",
	journal="Duke Mathematical Journal",
	volume="84",
	number="2",
	pages="497--540",
	year="1996"
}

@inproceedings{li2021validity,
 author = {Li, Zhiyuan and Malladi, Sadhika and Arora, Sanjeev},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {12712--12725},
 publisher = {Curran Associates, Inc.},
 title = {On the Validity of Modeling SGD with Stochastic Differential Equations (SDEs)},
 volume = {34},
 year = {2021}
}

@inproceedings{
	zhang2018residual,
	title={Fixup Initialization: Residual Learning Without Normalization},
	author={Hongyi Zhang and Yann N. Dauphin and Tengyu Ma},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@incollection{giorgi2004mathematicsChapter4,
	title = "{Chapter IV - Nonsmooth Optimization Problems}",
	author = "Giorgi, Giorgio and Guerraggio, Angelo and Thierfelder, J{\"o}rg",
	booktitle = "Mathematics of Optimization",
	publisher = "Elsevier Science",
	address = "Amsterdam",
	pages = "359 - 457",
	year = "2004",
	isbn = "978-0-444-50550-7"
}

@inproceedings{
	szegedy2013intriguing,
	title={Intriguing properties of neural networks},
	author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
	booktitle={International Conference on Learning Representations},
	year={2013}
}

@InProceedings{biggio2013evasion,
	author="Biggio, Battista
	and Corona, Igino
	and Maiorca, Davide
	and Nelson, Blaine
	and {\v{S}}rndi{\'{c}}, Nedim
	and Laskov, Pavel
	and Giacinto, Giorgio
	and Roli, Fabio",
	editor="Blockeel, Hendrik
	and Kersting, Kristian
	and Nijssen, Siegfried
	and {\v{Z}}elezn{\'y}, Filip",
	title="Evasion Attacks against Machine Learning at Test Time",
	booktitle="Machine Learning and Knowledge Discovery in Databases",
	year="2013",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="387--402",
}

@article{ramdas2016towards,
	title={Towards a deeper geometric, analytic and algorithmic understanding of margins},
	author={Ramdas, Aaditya and Pena, Javier},
	journal={Optimization Methods and Software},
	volume={31},
	number={2},
	pages={377--391},
	year={2016},
	publisher={Taylor \& Francis}
}

@InProceedings{telgarsky13margins,
	title = 	 {Margins, Shrinkage, and Boosting},
	author = 	 {Matus Telgarsky},
	booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning},
	pages = 	 {307--315},
	year = 	 {2013},
	editor = 	 {Sanjoy Dasgupta and David McAllester},
	volume = 	 {28},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Atlanta, Georgia, USA},
	month = 	 {17--19 Jun},
	publisher = 	 {PMLR}
}

@article{schapire1998boosting,
	author = "Schapire, Robert E. and Freund, Yoav and Bartlett, Peter and Lee, Wee Sun",
	doi = "10.1214/aos/1024691352",
	fjournal = "The Annals of Statistics",
	journal = "Ann. Statist.",
	month = "10",
	number = "5",
	pages = "1651--1686",
	publisher = "The Institute of Mathematical Statistics",
	title = "Boosting the margin: A new explanation for the effectiveness of voting methods",
	volume = "26",
	year = "1998"
}

@book{schapire2012boosting,
	author = {Schapire, Robert E. and Freund, Yoav},
	title = {Boosting: Foundations and Algorithms},
	year = {2012},
	isbn = {0262017180, 9780262017183},
	publisher = {The MIT Press},
}

@article{shalev2010equivalence,
	title={On the equivalence of weak learnability and linear separability: New relaxations and efficient boosting algorithms},
	author={Shalev-Shwartz, Shai and Singer, Yoram},
	journal={Machine learning},
	volume={80},
	number={2-3},
	pages={141--163},
	year={2010},
	publisher={Springer}
}


@InProceedings{athalye2018obfuscated,
	title = 	 {Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples},
	author = 	 {Athalye, Anish and Carlini, Nicholas and Wagner, David},
	booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
	pages = 	 {274--283},
	year = 	 {2018},
	editor = 	 {Dy, Jennifer and Krause, Andreas},
	volume = 	 {80},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Stockholmsmässan, Stockholm Sweden},
	month = 	 {10--15 Jul},
	publisher = 	 {PMLR},
	pdf = 	 {http://proceedings.mlr.press/v80/athalye18a/athalye18a.pdf},
}

@article{absil2005convergence,
	title={Convergence of the iterates of descent methods for analytic cost functions},
	author={Absil, Pierre-Antoine and Mahony, Robert and Andrews, Benjamin},
	journal={SIAM Journal on Optimization},
	volume={16},
	number={2},
	pages={531--547},
	year={2005},
	publisher={SIAM}
}

@article{curry1944method,
	title={The method of steepest descent for non-linear minimization problems},
	author={Curry, Haskell B},
	journal={Quarterly of Applied Mathematics},
	volume={2},
	number={3},
	pages={258--261},
	year={1944}
}

@article{zoutendijk1976mathematical,
	title={Mathematical programming methods},
	author={Zoutendijk, Guus},
	year={1976},
	publisher={North-Holland}
}

@book{palis2012geometric,
	title={Geometric theory of dynamical systems: an introduction},
	author={Palis, J Jr and De Melo, Welington},
	year={2012},
	publisher={Springer Science \& Business Media}
}







@InProceedings{golowich18a,
	title = 	 {Size-Independent  Sample Complexity of Neural Networks},
	author = 	 {Golowich, Noah and Rakhlin, Alexander and Shamir, Ohad},
	booktitle = 	 {Proceedings of the 31st  Conference On Learning Theory},
	pages = 	 {297--299},
	year = 	 {2018},
	editor = 	 {Bubeck, S\'ebastien and Perchet, Vianney and Rigollet, Philippe},
	volume = 	 {75},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {},
	month = 	 {06--09 Jul},
	publisher = 	 {PMLR}
}

@article{li2018tighter,
	title={On tighter generalization bound for deep neural networks: {CNNs}, {R}es{N}ets, and beyond},
	author={Li, Xingguo and Lu, Junwei and Wang, Zhaoran and Haupt, Jarvis and Zhao, Tuo},
	journal={arXiv preprint arXiv:1806.05159},
	year={2018}
}

@inproceedings{
	wei2020improved,
	title={Improved Sample Complexities for Deep Neural Networks and Robust Classification via an All-Layer Margin},
	author={Colin Wei and Tengyu Ma},
	booktitle={International Conference on Learning Representations},
	year={2020}
}







@InProceedings{anil2019sorting,
	title = 	 {Sorting Out {L}ipschitz Function Approximation},
	author = 	 {Anil, Cem and Lucas, James and Grosse, Roger},
	booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
	pages = 	 {291--301},
	year = 	 {2019},
	editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
	volume = 	 {97},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Long Beach, California, USA},
	month = 	 {09--15 Jun},
	publisher = 	 {PMLR}
}


@InProceedings{precup2017parseval,
title = 	 {Parseval Networks: Improving Robustness to Adversarial Examples},
author = 	 {Moustapha Cisse and Piotr Bojanowski and Edouard Grave and Yann Dauphin and Nicolas Usunier},
booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
pages = 	 {854--863},
year = 	 {2017},
editor = 	 {Doina Precup and Yee Whye Teh},
volume = 	 {70},
series = 	 {Proceedings of Machine Learning Research},
address = 	 {International Convention Centre, Sydney, Australia},
month = 	 {06--11 Aug},
publisher = 	 {PMLR}
}

@incollection{allen2019can,
title = {Can SGD Learn Recurrent Neural Networks with Provable Generalization?},
author = {Allen-Zhu, Zeyuan and Li, Yuanzhi},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {10331--10341},
year = {2019},
publisher = {Curran Associates, Inc.},
}

@incollection{du2019graph,
title = {Graph Neural Tangent Kernel: Fusing Graph Neural Networks with Graph Kernels},
author = {Du, Simon S and Hou, Kangcheng and Salakhutdinov, Russ R and Poczos, Barnabas and Wang, Ruosong and Xu, Keyulu},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {5723--5733},
year = {2019},
publisher = {Curran Associates, Inc.}
}


@incollection{yehudai2019RF,
title = {On the Power and Limitations of Random Features for Understanding Neural Networks},
author = {Yehudai, Gilad and Shamir, Ohad},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {6598--6608},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8886-on-the-power-and-limitations-of-random-features-for-understanding-neural-networks.pdf}
}


@incollection{allen2019resnet,
title = {What Can ResNet Learn Efficiently, Going Beyond Kernels?},
author = {Allen-Zhu, Zeyuan and Li, Yuanzhi},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {9017--9028},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9103-what-can-resnet-learn-efficiently-going-beyond-kernels.pdf}
}

@article{allen2019backward,
	title={Backward Feature Correction: How Deep Learning Performs Deep Learning},
	author={Zeyuan Allen-Zhu and Yuanzhi Li},
	journal={arXiv preprint arXiv:2001.04413},
	year={2020}
}

@incollection{ghorbani2019lazy,
title = {Limitations of Lazy Training of Two-layers Neural Network},
author = {Ghorbani, Behrooz and Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {9111--9121},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9111-limitations-of-lazy-training-of-two-layers-neural-network.pdf}
}

@incollection{chizat2019lazy,
	title = {On Lazy Training in Differentiable Programming},
	author = {Chizat, L\'{e}na\"{\i}c and Oyallon, Edouard and Bach, Francis},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {2937--2947},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@article{daniely2020parities,
	title={Learning Parities with Neural Networks},
	author={Amit Daniely and Eran Malach},
	journal={arXiv preprint arXiv:2002.07400},
	year={2020}
}

@inproceedings{
ji2020polylogarithmic,
title={Polylogarithmic width suffices for gradient descent to achieve arbitrarily small test error with shallow ReLU networks},
author={Ziwei Ji and Matus Telgarsky},
booktitle={International Conference on Learning Representations},
year={2020}
}

@inproceedings{welling11langevin,
	title = {Bayesian Learning via Stochastic Gradient Langevin Dynamics},
	author = {Welling, Max and Teh, Yee Whye},
	year = {2011},
	isbn = {9781450306195},
	publisher = {Omnipress},
	address = {Madison, WI, USA},
	booktitle = {Proceedings of the 28th International Conference on International Conference on Machine Learning},
	pages = {681-688},
	numpages = {8},
	location = {Bellevue, Washington, USA},
	series = {ICML '11}
}

@incollection{li19learningrate,
	title = {Towards Explaining the Regularization Effect of Initial Large Learning Rate in Training Neural Networks},
	author = {Li, Yuanzhi and Wei, Colin and Ma, Tengyu},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d' Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {11674--11685},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@article{shi2020learning,
	title={On Learning Rates and Schr$\backslash$" odinger Operators},
	author={Shi, Bin and Su, Weijie J and Jordan, Michael I},
	journal={arXiv preprint arXiv:2004.06977},
	year={2020}
}

@inproceedings{
	zhang2018three,
	title={Three Mechanisms of Weight Decay Regularization},
	author={Guodong Zhang and Chaoqi Wang and Bowen Xu and Roger Grosse},
	booktitle={International Conference on Learning Representations},
	year={2019}
}

@inproceedings{
	hoffer2018fix,
	title={Fix your classifier: the marginal value of training the last weight layer},
	author={Elad Hoffer and Itay Hubara and Daniel Soudry},
	booktitle={International Conference on Learning Representations},
	year={2018}
}

@inproceedings{
gissin2020the,
title={The Implicit Bias of Depth: How Incremental Learning Drives Generalization},
author={Daniel Gissin and Shai Shalev-Shwartz and Amit Daniely},
booktitle={International Conference on Learning Representations},
year={2020}
}

@inproceedings{fazel2001rank,
  title={A rank minimization heuristic with application to minimum order system approximation},
  author={Fazel, Maryam and Hindi, Haitham and Boyd, Stephen P},
  booktitle={Proceedings of the 2001 American Control Conference.(Cat. No. 01CH37148)},
  volume={6},
  pages={4734--4739},
  year={2001},
  organization={IEEE}
}

@article{belabbas2020implicit,
  title={On implicit regularization: Morse functions and applications to matrix factorization},
  author={Belabbas, Mohamed Ali},
  journal={arXiv preprint arXiv:2001.04264},
  year={2020}
}

@article{razin2020implicit,
  title={Implicit Regularization in Deep Learning May Not Be Explainable by Norms},
  author={Noam Razin and Nadav Cohen},
  journal={arXiv preprint arXiv:2005.06398},
  year={2020}
}

@article{lee2017first,
  title={First-order methods almost always avoid saddle points},
  author={Lee, Jason D and Panageas, Ioannis and Piliouras, Georgios and Simchowitz, Max and Jordan, Michael I and Recht, Benjamin},
  journal={arXiv preprint arXiv:1710.07406},
  year={2017}
}

@incollection{panageas19firstorder,
	title = {First-order methods almost always avoid saddle points: The case of vanishing step-sizes},
	author = {Panageas, Ioannis and Piliouras, Georgios and Wang, Xiao},
	booktitle = {Advances in Neural Information Processing Systems 32},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {6474--6483},
	year = {2019},
	publisher = {Curran Associates, Inc.}
}

@incollection{gunasekar2017implicit,
title = {Implicit Regularization in Matrix Factorization},
author = {Gunasekar, Suriya and Woodworth, Blake E and Bhojanapalli, Srinadh and Neyshabur, Behnam and Srebro, Nati},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {6151--6159},
year = {2017},
publisher = {Curran Associates, Inc.}
}

@inproceedings{wang2014rank,
  title={Rank-one matrix pursuit for matrix completion},
  author={Wang, Zheng and Lai, Ming-Jun and Lu, Zhaosong and Fan, Wei and Davulcu, Hasan and Ye, Jieping},
  booktitle={International Conference on Machine Learning},
  pages={91--99},
  year={2014}
}

@article{diamond2016cvxpy,
  author  = {Steven Diamond and Stephen Boyd},
  title   = {{CVXPY}: {A} {P}ython-embedded modeling language for convex optimization},
  journal = {Journal of Machine Learning Research},
  year    = {2016},
  volume  = {17},
  number  = {83},
  pages   = {1--5},
}

@article{agrawal2018rewriting,
  author  = {Agrawal, Akshay and Verschueren, Robin and Diamond, Steven and Boyd, Stephen},
  title   = {A rewriting system for convex optimization problems},
  journal = {Journal of Control and Decision},
  year    = {2018},
  volume  = {5},
  number  = {1},
  pages   = {42--60},
}

@article{wu2017towards,
  title={Towards understanding generalization of deep learning: Perspective of loss landscapes},
  author={Wu, Lei and Zhu, Zhanxing and others},
  journal={arXiv preprint arXiv:1706.10239},
  year={2017}
}

@article{HiriartUrruty1999clarke,
	author    = {Jean{-}Baptiste Hiriart{-}Urruty and
	A. S. Lewis},
	title     = {The Clarke and Michel-Penot Subdifferentials of the Eigenvalues of
	a Symmetric Matrix},
	journal   = {Comput. Optim. Appl.},
	volume    = {13},
	number    = {1-3},
	pages     = {13--23},
	year      = {1999},
	doi       = {10.1023/A:1008644520093},
	timestamp = {Tue, 14 Jul 2020 14:28:36 +0200},
	biburl    = {https://dblp.org/rec/journals/coap/Hiriart-UrrutyL99.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{lojasiewicz1965ensembles,
	title={Ensembles semi-analytiques},
	author={Łojasiewicz, Stanisław},
	journal={IHES notes},
	year={1965}
}

@article{bezanson2012julia,
  title={Julia: A fast dynamic language for technical computing},
  author={Bezanson, Jeff and Karpinski, Stefan and Shah, Viral B and Edelman, Alan},
  journal={arXiv preprint arXiv:1209.5145},
  year={2012}
}

  @incollection{pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.}
}


@inproceedings{
	lyu2020Gradient,
	title={Gradient Descent Maximizes the Margin of Homogeneous Neural Networks},
	author={Kaifeng Lyu and Jian Li},
	booktitle={International Conference on Learning Representations},
	year={2020}
}

@InProceedings{chizat20logistic,
	title = {Implicit Bias of Gradient Descent for Wide Two-layer Neural Networks Trained with the Logistic Loss},
	author = {Chizat, L\'ena\"ic and Bach, Francis},
	pages = {1305--1338},
	year = {2020},
	editor = {Jacob Abernethy and Shivani Agarwal},
	volume = {125},
	series = {Proceedings of Machine Learning Research},
	address = {}, month = {09--12 Jul},
	publisher = {PMLR}
}


@article{moroshko2020implicit,
	title={Implicit Bias in Deep Linear Classification: Initialization Scale vs Training Accuracy},
	author={Moroshko, Edward and Gunasekar, Suriya and Woodworth, Blake and Lee, Jason D and Srebro, Nathan and Soudry, Daniel},
	journal={arXiv preprint arXiv:2007.06738},
	year={2020}
}

@article{chi2019nonconvex,
	title={Nonconvex optimization meets low-rank matrix factorization: An overview},
	author={Chi, Yuejie and Lu, Yue M and Chen, Yuxin},
	journal={IEEE Transactions on Signal Processing},
	volume={67},
	number={20},
	pages={5239--5269},
	year={2019},
	publisher={IEEE}
}

@inproceedings{
	jiang2020Fantastic,
	title={Fantastic Generalization Measures and Where to Find Them},
	author={Yiding Jiang and Behnam Neyshabur and Hossein Mobahi and Dilip Krishnan and Samy Bengio},
	booktitle={International Conference on Learning Representations},
	year={2020}
}

@inproceedings{ji2020directional,
	author = {Ji, Ziwei and Telgarsky, Matus},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
	pages = {17176--17186},
	publisher = {Curran Associates, Inc.},
	title = {Directional convergence and alignment in deep learning},
	volume = {33},
	year = {2020}
}

@inproceedings{shah2020pitfalls,
	author = {Shah, Harshay and Tamuly, Kaustav and Raghunathan, Aditi and Jain, Prateek and Netrapalli, Praneeth},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
	pages = {9573--9585},
	publisher = {Curran Associates, Inc.},
	title = {The Pitfalls of Simplicity Bias in Neural Networks},
	volume = {33},
	year = {2020}
}

@inproceedings{hu2020surprising,
	author = {Hu, Wei and Xiao, Lechao and Adlam, Ben and Pennington, Jeffrey},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
	pages = {17116--17128},
	publisher = {Curran Associates, Inc.},
	title = {The Surprising Simplicity of the Early-Time Learning Dynamics of Neural Networks},
	volume = {33},
	year = {2020}
}


@article{choi2019empirical,
  title={On empirical comparisons of optimizers for deep learning},
  author={Choi, Dami and Shallue, Christopher J and Nado, Zachary and Lee, Jaehoon and Maddison, Chris J and Dahl, George E},
  journal={arXiv preprint arXiv:1910.05446},
  year={2019}
}

@inproceedings{
you2020lamb,
title={Large Batch Optimization for Deep Learning: Training {BERT} in 76 minutes},
author={Yang You and Jing Li and Sashank Reddi and Jonathan Hseu and Sanjiv Kumar and Srinadh Bhojanapalli and Xiaodan Song and James Demmel and Kurt Keutzer and Cho-Jui Hsieh},
booktitle={International Conference on Learning Representations},
year={2020}
}

@inproceedings{
wang2018glue,
title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
author={Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},
booktitle={International Conference on Learning Representations},
year={2019},
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}


@inproceedings{
merity2017pointer,
title={Pointer Sentinel Mixture Models},
author={Stephen Merity and Caiming Xiong and James Bradbury and Richard Socher},
booktitle={International Conference on Learning Representations},
year={2017},
}

@inproceedings{zhuang2020adabelief,
 author = {Zhuang, Juntang and Tang, Tommy and Ding, Yifan and Tatikonda, Sekhar C and Dvornek, Nicha and Papademetris, Xenophon and Duncan, James},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {18795--18806},
 publisher = {Curran Associates, Inc.},
 title = {Ada{B}elief Optimizer: Adapting Stepsizes by the Belief in Observed Gradients},
 volume = {33},
 year = {2020}
}

@inproceedings{
luo2018adaptive,
title={Adaptive Gradient Methods with Dynamic Bound of Learning Rate},
author={Liangchen Luo and Yuanhao Xiong and Yan Liu},
booktitle={International Conference on Learning Representations},
year={2019},
}


@InProceedings{pmlr-v80-shazeer18a,
  title = 	 {Adafactor: Adaptive Learning Rates with Sublinear Memory Cost},
  author =       {Shazeer, Noam and Stern, Mitchell},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {4596--4604},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
}


@inproceedings{
amsgrad,
title={On the Convergence of {A}dam and Beyond},
author={Sashank J. Reddi and Satyen Kale and Sanjiv Kumar},
booktitle={International Conference on Learning Representations},
year={2018},
}


@inproceedings{
ma2018quasihyperbolic,
title={Quasi-hyperbolic momentum and {A}dam for deep learning},
author={Jerry Ma and Denis Yarats},
booktitle={International Conference on Learning Representations},
year={2019},
}


@article{you2017scaling,
  title={Scaling sgd batch size to 32k for imagenet training},
  author={You, Yang and Gitman, Igor and Ginsburg, Boris},
  journal={arXiv preprint arXiv:1708.03888},
  volume={6},
  number={12},
  pages={6},
  year={2017}
}

@article{mcmahan2010adaptive,
  title={Adaptive bound optimization for online convex optimization},
  author={McMahan, H Brendan and Streeter, Matthew},
  journal={arXiv preprint arXiv:1002.4908},
  year={2010}
}

@article{zeiler2012adadelta,
  title={Adadelta: an adaptive learning rate method},
  author={Zeiler, Matthew D},
  journal={arXiv preprint arXiv:1212.5701},
  year={2012}
}

@inproceedings{dozat2016incorporating,
  author          = {Dozat, Timothy},
  maintitle       = {International Conference on Learning Representations},
  booktitle       = {Workshop},
  title           = {Incorporating {N}esterov momentum into {A}dam},
  year            = {2016}
}


@inproceedings{padam,
author = {Chen, Jinghui and Zhou, Dongruo and Tang, Yiqi and Yang, Ziyan and Cao, Yuan and Gu, Quanquan},
title = {Closing the Generalization Gap of Adaptive Gradient Methods in Training Deep Neural Networks},
year = {2021},
isbn = {9780999241165},
abstract = {Adaptive gradient methods, which adopt historical gradient information to automatically adjust the learning rate, despite the nice property of fast convergence, have been observed to generalize worse than stochastic gradient descent (SGD) with momentum in training deep neural networks. This leaves how to close the generalization gap of adaptive gradient methods an open problem. In this work, we show that adaptive gradient methods such as Adam, Amsgrad, are sometimes "over adapted". We design a new algorithm, called Partially adaptive momentum estimation method, which unifies the Adam/Amsgrad with SGD by introducing a partial adaptive parameter p, to achieve the best from both worlds. We also prove the convergence rate of our proposed algorithm to a stationary point in the stochastic nonconvex optimization setting. Experiments on standard benchmarks show that our proposed algorithm can maintain fast convergence rate as Adam/Amsgrad while generalizing as well as SGD in training deep neural networks. These results would suggest practitioners pick up adaptive gradient methods once again for faster training of deep neural networks.},
booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence},
articleno = {452},
numpages = {9},
location = {Yokohama, Yokohama, Japan},
series = {IJCAI'20}
}



@inproceedings{yogi,
 author = {Zaheer, Manzil and Reddi, Sashank and Sachan, Devendra and Kale, Satyen and Kumar, Sanjiv},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Adaptive Methods for Nonconvex Optimization},
 volume = {31},
 year = {2018}
}



@article{wettig2022should,
  title={Should You Mask 15\% in Masked Language Modeling?},
  author={Wettig, Alexander and Gao, Tianyu and Zhong, Zexuan and Chen, Danqi},
  journal={arXiv preprint arXiv:2202.08005},
  year={2022}
}


@article{
	strubell2019energy,
	title={Energy and Policy Considerations for Modern Deep Learning Research},
	volume={34},
	number={09},
	journal={Proceedings of the AAAI Conference on Artificial Intelligence},
	author={Strubell, Emma and Ganesh, Ananya and McCallum,
	Andrew}, year={2020}, month={Apr}, pages={13693-13696}
}
