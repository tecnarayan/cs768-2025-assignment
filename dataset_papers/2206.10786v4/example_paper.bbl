\begin{thebibliography}{51}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahn et~al.(2019)Ahn, Zhu, Hartikainen, Ponte, Gupta, Levine, and
  Kumar]{robel}
Ahn, M., Zhu, H., Hartikainen, K., Ponte, H., Gupta, A., Levine, S., and Kumar,
  V.
\newblock Robel: Robotics benchmarks for learning with low-cost robots.
\newblock 2019.
\newblock \doi{10.48550/ARXIV.1909.11639}.

\bibitem[Andrychowicz et~al.(2016)Andrychowicz, Denil, G\'{o}mez, Hoffman,
  Pfau, Schaul, Shillingford, and de~Freitas]{l2lwgd}
Andrychowicz, M., Denil, M., G\'{o}mez, S., Hoffman, M.~W., Pfau, D., Schaul,
  T., Shillingford, B., and de~Freitas, N.
\newblock Learning to learn by gradient descent by gradient descent.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and Bottou]{wgan}
Arjovsky, M., Chintala, S., and Bottou, L.
\newblock {W}asserstein generative adversarial networks.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning}, 06--11 Aug 2017.

\bibitem[Attia et~al.(2020)Attia, Grover, Jin, Severson, Cheong, Liao, Chen,
  Perkins, Yang, Herring, Aykol, Harris, Braatz, Ermon, and
  Chueh]{attia2019closed}
Attia, P., Grover, A., Jin, N., Severson, K., Cheong, B., Liao, J., Chen,
  M.~H., Perkins, N., Yang, Z., Herring, P., Aykol, M., Harris, S., Braatz, R.,
  Ermon, S., and Chueh, W.
\newblock Closed-loop optimization of extreme fast charging for batteries using
  machine learning.
\newblock \emph{Nature}, 2020.

\bibitem[Bijl et~al.(2016)Bijl, Schön, van Wingerden, and Verhaegen]{new_bo}
Bijl, H., Schön, T.~B., van Wingerden, J.-W., and Verhaegen, M.
\newblock A sequential monte carlo approach to thompson sampling for bayesian
  optimization, 2016.

\bibitem[Brockman et~al.(2016)Brockman, Cheung, Pettersson, Schneider,
  Schulman, Tang, and Zaremba]{openaigym}
Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang,
  J., and Zaremba, W.
\newblock Openai gym, 2016.

\bibitem[Brookes et~al.(2019)Brookes, Park, and Listgarten]{cbas}
Brookes, D., Park, H., and Listgarten, J.
\newblock Conditioning by adaptive sampling for robust design.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning}, volume~97 of \emph{Proceedings of Machine Learning Research}, pp.\
   773--782. PMLR, 09--15 Jun 2019.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan,
  Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess,
  Clark, Berner, McCandlish, Radford, Sutskever, and Amodei]{gpt3}
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.~D., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S.,
  Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler,
  D., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray,
  S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever,
  I., and Amodei, D.
\newblock Language models are few-shot learners.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H.
  (eds.), \emph{Advances in Neural Information Processing Systems}, volume~33,
  pp.\  1877--1901. Curran Associates, Inc., 2020.

\bibitem[Chang(2021)]{bayesnn_1}
Chang, D.~T.
\newblock Bayesian neural networks: Essentials, 2021.

\bibitem[Chen et~al.(2021)Chen, Lu, Rajeswaran, Lee, Grover, Laskin, Abbeel,
  Srinivas, and Mordatch]{chen2021decisiontransformer}
Chen, L., Lu, K., Rajeswaran, A., Lee, K., Grover, A., Laskin, M., Abbeel, P.,
  Srinivas, A., and Mordatch, I.
\newblock Decision transformer: Reinforcement learning via sequence modeling.
\newblock \emph{arXiv preprint arXiv:2106.01345}, 2021.

\bibitem[Chen et~al.(2017)Chen, Hoffman, Colmenarejo, Denil, Lillicrap,
  Botvinick, and de~Freitas]{l2lwogd}
Chen, Y., Hoffman, M.~W., Colmenarejo, S.~G., Denil, M., Lillicrap, T.~P.,
  Botvinick, M., and de~Freitas, N.
\newblock Learning to learn without gradient descent by gradient descent.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning}, 2017.

\bibitem[Fannjiang \& Listgarten(2020)Fannjiang and Listgarten]{autocbas}
Fannjiang, C. and Listgarten, J.
\newblock Autofocused oracles for model-based design, 2020.

\bibitem[Fu \& Levine(2021)Fu and Levine]{nemo}
Fu, J. and Levine, S.
\newblock Offline model-based optimization via normalized maximum likelihood
  estimation.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Garivier et~al.(2016)Garivier, Kaufmann, and
  Lattimore]{bandit_exp_then_commit}
Garivier, A., Kaufmann, E., and Lattimore, T.
\newblock On explore-then-commit strategies.
\newblock In \emph{Proceedings of the 30th International Conference on Neural
  Information Processing Systems}, 2016.

\bibitem[Garnelo et~al.(2018{\natexlab{a}})Garnelo, Rosenbaum, Maddison,
  Ramalho, Saxton, Shanahan, Teh, Rezende, and Eslami]{cnp}
Garnelo, M., Rosenbaum, D., Maddison, C., Ramalho, T., Saxton, D., Shanahan,
  M., Teh, Y.~W., Rezende, D., and Eslami, S. M.~A.
\newblock Conditional neural processes.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning}, Proceedings of Machine Learning Research. PMLR, 10--15 Jul
  2018{\natexlab{a}}.

\bibitem[Garnelo et~al.(2018{\natexlab{b}})Garnelo, Schwarz, Rosenbaum, Viola,
  Rezende, Eslami, and Teh]{garnelo2018neural}
Garnelo, M., Schwarz, J., Rosenbaum, D., Viola, F., Rezende, D.~J., Eslami, S.,
  and Teh, Y.~W.
\newblock Neural processes.
\newblock \emph{arXiv preprint arXiv:1807.01622}, 2018{\natexlab{b}}.

\bibitem[Goan \& Fookes(2020)Goan and Fookes]{bayesnn_2}
Goan, E. and Fookes, C.
\newblock Bayesian neural networks: An introduction and survey.
\newblock In \emph{Case Studies in Applied Bayesian Data Science}, pp.\
  45--87. Springer International Publishing, 2020.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{GAN}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
  S., Courville, A., and Bengio, Y.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2014.

\bibitem[Gordon et~al.(2019)Gordon, Bruinsma, Foong, Requeima, Dubois, and
  Turner]{gordon2019convolutional}
Gordon, J., Bruinsma, W.~P., Foong, A.~Y., Requeima, J., Dubois, Y., and
  Turner, R.~E.
\newblock Convolutional conditional neural processes.
\newblock \emph{arXiv preprint arXiv:1910.13556}, 2019.

\bibitem[Grover et~al.(2018)Grover, Markov, Attia, Jin, Perkins, Cheong, Chen,
  Yang, Harris, Chueh, and Ermon]{aistats18b}
Grover, A., Markov, T., Attia, P., Jin, N., Perkins, N., Cheong, B., Chen, M.,
  Yang, Z., Harris, S., Chueh, W., and Ermon, S.
\newblock Best arm identification in multi-armed bandits with delayed feedback.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics (AISTATS)}, 2018.

\bibitem[Guo et~al.(2021)Guo, Agrawal, Grover, Muthukumar, and
  Pananjady]{guo2021learning}
Guo, W., Agrawal, K.~K., Grover, A., Muthukumar, V., and Pananjady, A.
\newblock Learning from an exploring demonstrator: Optimal reward estimation
  for bandits.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics (AISTATS)}, 2021.

\bibitem[Jacq et~al.(2019)Jacq, Geist, Paiva, and
  Pietquin]{learningfromlearner}
Jacq, A., Geist, M., Paiva, A., and Pietquin, O.
\newblock Learning from a learner.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning}, 09--15 Jun 2019.

\bibitem[Janner et~al.(2021)Janner, Li, and Levine]{janner2021sequence}
Janner, M., Li, Q., and Levine, S.
\newblock Offline reinforcement learning as one big sequence modeling problem.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Joachims et~al.(2018{\natexlab{a}})Joachims, Swaminathan, and
  de~Rijke]{Joachims/etal/18a_bandit}
Joachims, T., Swaminathan, A., and de~Rijke, M.
\newblock Deep learning with logged bandit feedback.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018{\natexlab{a}}.

\bibitem[Joachims et~al.(2018{\natexlab{b}})Joachims, Swaminathan, and
  de~Rijke]{joachims2018deep_bandit}
Joachims, T., Swaminathan, A., and de~Rijke, M.
\newblock Deep learning with logged bandit feedback.
\newblock In \emph{International Conference on Learning Representations},
  2018{\natexlab{b}}.

\bibitem[Krizhevsky et~al.()Krizhevsky, Nair, and Hinton]{krizhevsky2010cifar}
Krizhevsky, A., Nair, V., and Hinton, G.
\newblock Cifar-10 (canadian institute for advanced research).

\bibitem[Kumar \& Levine(2020)Kumar and Levine]{mins}
Kumar, A. and Levine, S.
\newblock Model inversion networks for model-based optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Larson et~al.(2019)Larson, Menickelly, and Wild]{der_free_opt}
Larson, J., Menickelly, M., and Wild, S.~M.
\newblock Derivative-free optimization methods.
\newblock \emph{Acta Numerica}, 28:\penalty0 287--404, may 2019.
\newblock \doi{10.1017/s0962492919000060}.

\bibitem[Mirza \& Osindero(2014)Mirza and Osindero]{cgan}
Mirza, M. and Osindero, S.
\newblock Conditional generative adversarial nets, 2014.

\bibitem[Nguyen \& Grover(2022)Nguyen and Grover]{nguyen2022transformer}
Nguyen, T. and Grover, A.
\newblock Transformer neural processes: Uncertainty-aware meta learning via
  sequence modeling.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2022.

\bibitem[Nguyen \& Osborne(2020)Nguyen and Osborne]{pmlr-v119-nguyen20d}
Nguyen, V. and Osborne, M.~A.
\newblock Knowing the what but not the where in {B}ayesian optimization.
\newblock In III, H.~D. and Singh, A. (eds.), \emph{Proceedings of the 37th
  International Conference on Machine Learning}, volume 119, pp.\  7317--7326,
  2020.

\bibitem[Nowozin et~al.(2016)Nowozin, Cseke, and Tomioka]{fgan}
Nowozin, S., Cseke, B., and Tomioka, R.
\newblock f-gan: Training generative neural samplers using variational
  divergence minimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, and
  Sutskever]{radford2019language}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I.
\newblock Language models are unsupervised multitask learners.
\newblock 2019.

\bibitem[Riquelme et~al.(2018)Riquelme, Tucker, and
  Snoek]{riquelme2018deepbandit}
Riquelme, C., Tucker, G., and Snoek, J.
\newblock Deep bayesian bandits showdown: An empirical comparison of bayesian
  deep networks for thompson sampling.
\newblock \emph{arXiv preprint arXiv:1802.09127}, 2018.

\bibitem[Schmidhuber(2019)]{udrl}
Schmidhuber, J.
\newblock Reinforcement learning upside down: Don't predict rewards -- just map
  them to actions, 2019.

\bibitem[Shahriari et~al.(2016)Shahriari, Swersky, Wang, Adams, and
  de~Freitas]{nando-bayesopt}
Shahriari, B., Swersky, K., Wang, Z., Adams, R.~P., and de~Freitas, N.
\newblock Taking the human out of the loop: A review of bayesian optimization.
\newblock \emph{Proceedings of the IEEE}, 104\penalty0 (1):\penalty0 148--175,
  2016.

\bibitem[Singh et~al.(2019)Singh, Yoon, Son, and Ahn]{singh2019sequential}
Singh, G., Yoon, J., Son, Y., and Ahn, S.
\newblock Sequential neural processes.
\newblock \emph{arXiv preprint arXiv:1906.10264}, 2019.

\bibitem[Snoek et~al.(2012)Snoek, Larochelle, and Adams]{snoek_bayesopt}
Snoek, J., Larochelle, H., and Adams, R.~P.
\newblock Practical bayesian optimization of machine learning algorithms, 2012.

\bibitem[Srinivas et~al.(2010)Srinivas, Krause, Kakade, and
  Seeger]{ICML-2010-SrinivasKKS}
Srinivas, N., Krause, A., Kakade, S., and Seeger, M.~W.
\newblock {Gaussian Process Optimization in the Bandit Setting: No Regret and
  Experimental Design}.
\newblock In \emph{{Proceedings of the 27th International Conference on Machine
  Learning}}, pp.\  1015--1022. {Omnipress}, 2010.

\bibitem[Sutton et~al.(1999)Sutton, McAllester, Singh, and Mansour]{reinforce}
Sutton, R.~S., McAllester, D., Singh, S., and Mansour, Y.
\newblock Policy gradient methods for reinforcement learning with function
  approximation.
\newblock In \emph{Advances in Neural Information Processing Systems}, 1999.

\bibitem[Swaminathan \& Joachims(2015)Swaminathan and
  Joachims]{JMLR:v16:swaminathan15a_bandit}
Swaminathan, A. and Joachims, T.
\newblock Batch learning from logged bandit feedback through counterfactual
  risk minimization.
\newblock \emph{Journal of Machine Learning Research}, 16\penalty0
  (52):\penalty0 1731--1755, 2015.

\bibitem[Swersky et~al.(2013)Swersky, Snoek, and Adams]{NIPS2013_f33ba15e}
Swersky, K., Snoek, J., and Adams, R.~P.
\newblock Multi-task bayesian optimization.
\newblock In Burges, C., Bottou, L., Welling, M., Ghahramani, Z., and
  Weinberger, K. (eds.), \emph{Advances in Neural Information Processing
  Systems}, 2013.

\bibitem[Trabucco et~al.(2021)Trabucco, Kumar, Geng, and Levine]{coms}
Trabucco, B., Kumar, A., Geng, X., and Levine, S.
\newblock Conservative objective models for effective offline model-based
  optimization.
\newblock In \emph{Proceedings of the 38th International Conference on Machine
  Learning}, 18--24 Jul 2021.

\bibitem[Trabucco et~al.(2022)Trabucco, Geng, Kumar, and Levine]{design-bench}
Trabucco, B., Geng, X., Kumar, A., and Levine, S.
\newblock Design-bench: Benchmarks for data-driven offline model-based
  optimization.
\newblock \emph{CoRR}, abs/2202.08450, 2022.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{transformer}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, L.~u., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In Guyon, I., Luxburg, U.~V., Bengio, S., Wallach, H., Fergus, R.,
  Vishwanathan, S., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, 2017.

\bibitem[Wilson et~al.(2017)Wilson, Moriconi, Hutter, and Deisenroth]{qei}
Wilson, J.~T., Moriconi, R., Hutter, F., and Deisenroth, M.~P.
\newblock The reparameterization trick for acquisition functions, 2017.

\bibitem[Yu et~al.(2021)Yu, Ahn, Song, and Shin]{yu2021roma}
Yu, S., Ahn, S., Song, L., and Shin, J.
\newblock Ro{MA}: Robust model adaptation for offline model-based optimization.
\newblock In Beygelzimer, A., Dauphin, Y., Liang, P., and Vaughan, J.~W.
  (eds.), \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Zhang et~al.(2022)Zhang, Fu, Bengio, and Courville]{zhang2022unifying}
Zhang, D., Fu, J., Bengio, Y., and Courville, A.
\newblock Unifying likelihood-free inference with black-box sequence design and
  beyond.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=1HxTO6CTkz}.

\bibitem[Zheng et~al.(2022)Zheng, Zhang, and Grover]{onlinedt}
Zheng, Q., Zhang, A., and Grover, A.
\newblock Online decision transformer.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pp.\
  27042--27059, 2022.

\bibitem[Zheng et~al.(2023)Zheng, Henaff, Amos, and Grover]{zheng2022semi}
Zheng, Q., Henaff, M., Amos, B., and Grover, A.
\newblock Semi-supervised offline reinforcement learning with action-free
  trajectories.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2023.

\bibitem[Zhu et~al.(2023)Zhu, Dang, and Grover]{zhuscaling}
Zhu, B., Dang, M., and Grover, A.
\newblock Scaling pareto-efficient decision making via offline multi-objective
  rl.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2023.

\end{thebibliography}
