@article{AH2014,
  title={An ensemble-based system for automatic screening of diabetic retinopathy},
  author={Antal, B{\'a}lint and Hajdu, Andr{\'a}s},
  journal={Knowledge-Based Systems},
  volume={60},
  pages={20--27},
  year={2014},
  publisher={Elsevier}
}
@article{BBCG2008,
  title={A simple proof of the {P}oincar{\'e} inequality for a large class of probability measures},
  author={Bakry, Dominique and Barthe, Franck and Cattiaux, Patrick and Guillin, Arnaud},
  journal={Electronic Communications in Probability},
  volume={13},
  pages={60--66},
  year={2008},
  publisher={Institute of Mathematical Statistics and Bernoulli Society}
}
@article{BCESZ2022,
  title={Towards a theory of non-log-concave sampling: first-order stationarity guarantees for Langevin Monte Carlo},
  author={Balasubramanian, Krishnakumar and Chewi, Sinho and Erdogdu, Murat A and Salim, Adil and Zhang, Matthew},
  journal={arXiv preprint arXiv:2202.05214},
  year={2022}
}
@article{BM1999,
  title={A strong approximation theorem for stochastic recursive algorithms},
  author={Borkar, Vivek S and Mitter, Sanjoy K},
  journal={Journal of Optimization Theory and Applications},
  volume={100},
  number={3},
  pages={499--513},
  year={1999},
  publisher={Springer}
}
@book{BD2016,
  title={Metastability: a Potential-Theoretic Approach},
  author={Bovier, Anton and Den Hollander, Frank},
  volume={351},
  year={2016},
  publisher={Springer}
}
@article{CGW2010,
  title={A note on {T}alagrand's transportation inequality and logarithmic {S}obolev inequality},
  author={Cattiaux, Patrick and Guillin, Arnaud and Wu, Li-Ming},
  journal={Probability Theory and Related Fields},
  volume={148},
  number={1},
  pages={285--304},
  year={2010},
  publisher={Springer}
}
@inproceedings{CFMBJ2018,
  title={On the theory of variance reduction for stochastic gradient {M}onte {C}arlo},
  author={Chatterji, Niladri and Flammarion, Nicolas and Ma, Yian and Bartlett, Peter and Jordan, Michael},
  booktitle={International Conference on Machine Learning},
  pages={764--773},
  year={2018},
  organization={PMLR}
}
@article{CLX2021,
  title={Approximation to stochastic variance reduced gradient {L}angevin dynamics by stochastic delay differential equations},
  author={Chen, Peng and Lu, Jianya and Xu, Lihu},
  journal={arXiv preprint arXiv:2106.04357},
  year={2021}
}
@article{CELSZ2021,
  title={Analysis of {L}angevin {M}onte {C}arlo from {P}oincar$\backslash$'e to {L}og-{S}obolev},
  author={Chewi, Sinho and Erdogdu, Murat A and Li, Mufan Bill and Shen, Ruoqi and Zhang, Matthew},
  journal={arXiv preprint arXiv:2112.12662},
  year={2021}
}
@article{CHS1987,
  title={Diffusion for global optimization in $\mathbb{R}^n$},
  author={Chiang, Tzuu-Shuh and Hwang, Chii-Ruey and Sheu, Shuenn Jyi},
  journal={SIAM Journal on Control and Optimization},
  volume={25},
  number={3},
  pages={737--753},
  year={1987},
  publisher={SIAM}
}
@article{D2017a,
  title={Theoretical guarantees for approximate sampling from smooth and log-concave densities},
  author={Dalalyan, Arnak S},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={79},
  number={3},
  pages={651--676},
  year={2017},
  publisher={Wiley Online Library}
}
@inproceedings{D2017b,
  title={Further and stronger analogy between sampling and optimization: {L}angevin {M}onte {C}arlo and gradient descent},
  author={Dalalyan, Arnak},
  booktitle={Conference on Learning Theory},
  pages={678--689},
  year={2017},
  organization={PMLR}
}
@misc{DG2019,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} {M}achine {L}earning {R}epository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences"
}
@article{DJWPSX2016,
  title={Variance reduction in stochastic gradient {L}angevin dynamics},
  author={Dubey, Kumar Avinava and J Reddi, Sashank and Williamson, Sinead A and Poczos, Barnabas and Smola, Alexander J and Xing, Eric P},
  journal={Advances in Neural Information Processing Systems},
  volume={29},
  pages={1154--1162},
  year={2016}
}
@article{GGZ2021,
  title={{Global convergence of stochastic gradient {H}amiltonian {M}onte {C}arlo for nonconvex stochastic optimization: nonasymptotic performance bounds and momentum-based acceleration}},
  author={Gao, Xuefeng and G{\"u}rb{\"u}zbalaban, Mert and Zhu, Lingjiong},
  journal={Operations Research, $\mathrm{to\ appear}$},
  year={2021},
  publisher={INFORMS}
}
@article{GM1991,
  title={{Recursive stochastic algorithms for global optimization in $\mathbb{R}^d$}},
  author={Gelfand, Saul B and Mitter, Sanjoy K},
  journal={SIAM Journal on Control and Optimization},
  volume={29},
  number={5},
  pages={999--1018},
  year={1991},
  publisher={SIAM}
}
@article{HS1986,
  title={Logarithmic {S}obolev inequalities and stochastic {I}sing models},
  author={Holley, Richard and Stroock, Daniel W},
  year={1986},
  publisher={Laboratory for Information and Decision Systems, Massachusetts Institute of~â€¦}
}
@inproceedings{HB2021,
  title={Stochastic Gradient {L}angevin Dynamics with Variance Reduction},
  author={Huang, Zhishen and Becker, Stephen},
  booktitle={2021 International Joint Conference on Neural Networks},
  pages={1--8},
  year={2021},
  organization={IEEE}
}
@article{H1980,
  title={{Laplace's method revisited: weak convergence of probability measures}},
  author={Hwang, Chii-Ruey},
  journal={The Annals of Probability},
  pages={1177--1182},
  year={1980},
  volume={8},
  number={6},
  publisher={JSTOR}
}
@inproceedings{JGNKJ2017,
  title={{How to escape saddle points efficiently}},
  author={Jin, Chi and Ge, Rong and Netrapalli, Praneeth and Kakade, Sham M and Jordan, Michael I},
  booktitle={International Conference on Machine Learning},
  pages={1724--1732},
  year={2017},
  organization={PMLR}
}
@article{JZ2013,
  title={{Accelerating stochastic gradient descent using predictive variance reduction}},
  author={Johnson, Rie and Zhang, Tong},
  journal={Advances in Neural Information Processing Systems},
  volume={26},
  pages={315--323},
  year={2013}
}
@article{JKO1998,
  title={{The variational formulation of the Fokker--Planck equation}},
  author={Jordan, Richard and Kinderlehrer, David and Otto, Felix},
  journal={SIAM Journal on Mathematical Analysis},
  volume={29},
  number={1},
  pages={1--17},
  year={1998},
  publisher={SIAM}
}
@article{LE2020,
  title={{Riemannian langevin algorithm for solving semidefinite programs}},
  author={Li, Mufan Bill and Erdogdu, Murat A},
  journal={arXiv preprint arXiv:2010.11176v4},
  year={2020}
}
@article{LWME2019,
  title={{Stochastic Runge-Kutta accelerates Langevin Monte Carlo and beyond}},
  author={Li, Xuechen and Wu, Yi and Mackey, Lester and Erdogdu, Murat A},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}
@article{L2019,
  title={{SSRGD}: {S}imple stochastic recursive gradient descent for escaping saddle points},
  author={Li, Zhize},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}
@article{LZCZL2019,
  title={{Stochastic gradient Hamiltonian Monte Carlo with variance reduction for Bayesian inference}},
  author={Li, Zhize and Zhang, Tianyi and Cheng, Shuyu and Zhu, Jun and Li, Jian},
  journal={Machine Learning},
  volume={108},
  number={8},
  pages={1701--1727},
  year={2019},
  publisher={Springer}
}
@article{MSH2002,
  title={{Ergodicity for {SDE}s and approximations: locally Lipschitz vector fields and degenerate noise}},
  author={Mattingly, Jonathan C and Stuart, Andrew M and Higham, Desmond J},
  journal={Stochastic Processes and their Applications},
  volume={101},
  number={2},
  pages={185--232},
  year={2002},
  publisher={Elsevier}
}
@article{MS2014,
  title={{Poincar{\'e} and logarithmic Sobolev inequalities by decomposition of the energy landscape}},
  author={Menz, Georg and Schlichting, Andr{\'e}},
  journal={The Annals of Probability},
  volume={42},
  number={5},
  pages={1809--1884},
  year={2014},
  publisher={Institute of Mathematical Statistics}
}
@article{MS2022,
  title={{Escaping saddle points with bias-variance reduced local perturbed SGD for communication efficient nonconvex distributed learning}},
  author={Murata, Tomoya and Suzuki, Taiji},
  journal={Submitted},
  year={2022},
}
@inproceedings{NLST2017a,
  title={{SARAH: A novel method for machine learning problems using stochastic recursive gradient}},
  author={Nguyen, Lam M and Liu, Jie and Scheinberg, Katya and Tak{\'a}{\v{c}}, Martin},
  booktitle={International Conference on Machine Learning},
  pages={2613--2621},
  year={2017},
  organization={PMLR}
}
@article{NLST2017b,
  title={{Stochastic recursive gradient algorithm for nonconvex optimization}},
  author={Nguyen, Lam M and Liu, Jie and Scheinberg, Katya and Tak{\'a}{\v{c}}, Martin},
  journal={arXiv preprint arXiv:1705.07261},
  year={2017}
}
@article{OV2000,
  title={{Generalization of an inequality by Talagrand and links with the logarithmic Sobolev inequality}},
  author={Otto, Felix and Villani, C{\'e}dric},
  journal={Journal of Functional Analysis},
  volume={173},
  number={2},
  pages={361--400},
  year={2000},
  publisher={Elsevier}
}
@article{P2008,
  title={Estimation of information theoretic measures for continuous random variables},
  author={P{\'e}rez-Cruz, Fernando},
  journal={Advances in neural information processing systems},
  volume={21},
  year={2008}
}
@article{PNPT2020,
  title={{ProxSARAH: An efficient algorithmic framework for stochastic composite nonconvex optimization.}},
  author={Pham, Nhan H and Nguyen, Lam M and Phan, Dzung T and Tran-Dinh, Quoc},
  journal={Journal of Machine Learning Research},
  volume={21},
  number={110},
  pages={1--48},
  year={2020}
}
@inproceedings{RRT2017,
  title={{Non-convex learning via stochastic gradient langevin dynamics: a nonasymptotic analysis}},
  author={Raginsky, Maxim and Rakhlin, Alexander and Telgarsky, Matus},
  booktitle={Conference on Learning Theory},
  pages={1674--1703},
  year={2017},
  organization={PMLR}
}
@inproceedings{RHSPS2016,
  title={{Stochastic variance reduction for nonconvex optimization}},
  author={Reddi, Sashank J and Hefny, Ahmed and Sra, Suvrit and Poczos, Barnabas and Smola, Alex},
  booktitle={International conference on machine learning},
  pages={314--323},
  year={2016},
  organization={PMLR}
}
@article{VW2019,
  title={{Rapid convergence of the unadjusted Langevin algorithm: Isoperimetry suffices}},
  author={Vempala, Santosh and Wibisono, Andre},
  journal={Advances in Neural Information Processing Systems},
  pages={8094--8106},
  volume={32},
  year={2019}
}
@incollection{V2009,
  title={{The Wasserstein distances}},
  author={Villani, C{\'e}dric},
  booktitle={Optimal transport},
  pages={93--111},
  year={2009},
  publisher={Springer}
}
@book{W2019,
  title={{High-Dimensional Statistics: A Non-Asymptotic Viewpoint}},
  author={Wainwright, Martin J},
  volume={48},
  year={2019},
  publisher={Cambridge University Press}
}
@article{WJZLT2019,
  title={{SpiderBoost and momentum: Faster variance reduction algorithms}},
  author={Wang, Zhe and Ji, Kaiyi and Zhou, Yi and Liang, Yingbin and Tarokh, Vahid},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}
@inproceedings{WT2011,
  title={{Bayesian learning via stochastic gradient Langevin dynamics}},
  author={Welling, Max and Teh, Yee W},
  booktitle={International Conference on Machine Learning},
  pages={681--688},
  year={2011},
  organization={Citeseer}
}
@inproceedings{W2018,
  title={{Sampling as optimization in the space of measures: The Langevin dynamics as a composite optimization problem}},
  author={Wibisono, Andre},
  booktitle={Conference on Learning Theory},
  pages={2093--3027},
  year={2018},
  organization={PMLR}
}
@article{XCZG2017,
  title={{Global convergence of Langevin dynamics based algorithms for nonconvex optimization}},
  author={Xu, Pan and Chen, Jinghui and Zou, Difan and Gu, Quanquan},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}
@inproceedings{ZXG2018,
  title={{Subsampled stochastic variance-reduced gradient Langevin dynamics}},
  author={Zou, Difan and Xu, Pan and Gu, Quanquan},
  booktitle={International Conference on Uncertainty in Artificial Intelligence},
  year={2018}
}
@inproceedings{ZXG2019a,
  title={{Sampling from non-log-concave distributions via variance-reduced gradient Langevin dynamics}},
  author={Zou, Difan and Xu, Pan and Gu, Quanquan},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2936--2945},
  year={2019},
  organization={PMLR}
}
@article{ZXG2019b,
  title={{Stochastic gradient Hamiltonian Monte Carlo methods with recursive variance reduction}},
  author={Zou, Difan and Xu, Pan and Gu, Quanquan},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={3835--3846},
  year={2019}
}
@inproceedings{ZXG2020,
  title={{Faster convergence of stochastic gradient Langevin Dynamics for non-log-concave sampling}},
  author={Zou, Difan and Xu, Pan and Gu, Quanquan},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={1152--1162},
  year={2021},
  organization={PMLR}
}
