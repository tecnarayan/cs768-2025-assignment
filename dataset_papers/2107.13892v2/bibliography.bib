@article{kairouz2019advances,
	title={Advances and Open Problems in Federated Learning},
	author={Peter Kairouz and et~al.},
	year={2019},
	journal={arXiv preprint arXiv:1912.04977}
}

@inproceedings{lin2020ensemble,
	title={Ensemble distillation for robust model fusion in federated learning},
	author={Tao Lin and
	Lingjing Kong and
	Sebastian U. Stich and
	Martin Jaggi},
	booktitle = {Advances in Neural Information Processing Systems},
	year={2020}
}

@inproceedings{smith2017federated,
	author = {Virginia Smith and
	Chao{-}Kai Chiang and
	Maziar Sanjabi and
	Ameet S. Talwalkar},
	booktitle = {Advances in Neural Information Processing Systems},
	pages = {4424--4434},
	title = {Federated Multi-Task Learning},
	year = {2017}
}

@inproceedings{ghosh2020efficient,
	title={An Efficient Framework for Clustered Federated Learning},
	author={Avishek Ghosh and
	Jichan Chung and
	Dong Yin and
	Kannan Ramchandran},
	booktitle = {Advances in Neural Information Processing Systems},
	year={2020}
}

@article{courbariaux2016binarized,
	title={Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1}, 
	author={Matthieu Courbariaux and Itay Hubara and Daniel Soudry and Ran El-Yaniv and Yoshua Bengio},
	year={2016},
	journal={arXiv preprint arXiv:1602.02830}
}

@inproceedings{Finn_maml17,
	author    = {Chelsea Finn and
	Pieter Abbeel and
	Sergey Levine},
	title     = {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
	booktitle = {Proceedings of the 34th International Conference on Machine Learning,
	{ICML} 2017},
	pages     = {1126--1135},
	year      = {2017}
}

@inproceedings{li2020federated,
	title={Federated Optimization in Heterogeneous Networks}, 
	author={Tian Li and Anit Kumar Sahu and Manzil Zaheer and Maziar Sanjabi and Ameet Talwalkar and Virginia Smith},
	booktitle = {Proceedings of Machine Learning and Systems 2020, MLSys},
	year={2020},
	journal={arXiv preprint arXiv:1812.06127},
}

@article{Bin_survey,
	title={Binary neural networks: A survey},
	volume={105},
	ISSN={0031-3203},
	journal={Pattern Recognition},
	publisher={Elsevier BV},
	author={Qin, Haotong and Gong, Ruihao and Liu, Xianglong and Bai, Xiao and Song, Jingkuan and Sebe, Nicu},
	year={2020},
	month={Sep},
	pages={107281}
}

@inproceedings{hanzely2020lower,
	title={Lower Bounds and Optimal Algorithms for Personalized Federated Learning}, 
	author={Filip Hanzely and Slavomír Hanzely and Samuel Horváth and Peter Richtárik},
	booktitle = {Advances in Neural Information Processing Systems},
	year={2020}
}


@article{deng2020adaptive,
	title={Adaptive Personalized Federated Learning}, 
	author={Yuyang Deng and Mohammad Mahdi Kamani and Mehrdad Mahdavi},
	journal={arXiv preprint arXiv:2003.13461},      
	year={2020},
}

@article{hanzely2020federated,
	title={Federated Learning of a Mixture of Global and Local Models}, 
	author={Filip Hanzely and Peter Richtárik},
	journal={arXiv preprint arXiv:2002.05516},
	year={2020}
}

@article{mansour2020approaches,
	title={Three Approaches for Personalization with Applications to Federated Learning}, 
	author={Yishay Mansour and Mehryar Mohri and Jae Ro and Ananda Theertha Suresh},
	journal={arXiv preprint arXiv:2002.10619},
	year={2020}
}

@inproceedings{zhang2021personalized,
	title={Personalized Federated Learning with First Order Model Optimization},
	author={Michael Zhang and Karan Sapra and Sanja Fidler and Serena Yeung and Jose M. Alvarez},
	booktitle={International Conference on Learning Representations},
	year={2021},
}


@inproceedings{dinh2020personalized,
	title={Personalized Federated Learning with Moreau Envelopes}, 
	author={Canh T. Dinh and Nguyen H. Tran and Tuan Dung Nguyen},
	booktitle = {Advances in Neural Information Processing Systems},
	year={2020}
}

@inproceedings{fallah2020personalized,
	title={Personalized Federated Learning: A Meta-Learning Approach}, 
	author={Alireza Fallah and Aryan Mokhtari and Asuman Ozdaglar},
	booktitle = {Advances in Neural Information Processing Systems},
	year={2020}
}

@article{sattler2019clustered,
	title={Clustered federated learning: Model-agnostic distributed multitask optimization under privacy constraints},
	author={Sattler, Felix and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
	journal={IEEE Transactions on Neural Networks and Learning Systems},
	year={2020}
}

@article{BinaryRelax,
	author    = {Penghang Yin and
	Shuai Zhang and
	Jiancheng Lyu and
	Stanley J. Osher and
	Yingyong Qi and
	Jack Xin},
	title     = {BinaryRelax: {A} Relaxation Approach for Training Deep Neural Networks
	with Quantized Weights},
	journal   = {{SIAM} J. Imaging Sci.},
	volume    = {11},
	number    = {4},
	pages     = {2205--2223},
	year      = {2018},
}


@article{Bolte13,
	author    = {J{\'{e}}r{\^{o}}me Bolte and
	Shoham Sabach and
	Marc Teboulle},
	title     = {Proximal alternating linearized minimization for nonconvex and nonsmooth
	problems},
	journal   = {Math. Program.},
	volume    = {146},
	number    = {1-2},
	pages     = {459--494},
	year      = {2014}
}

@inproceedings{li2017training,
	title={Training Quantized Nets: A Deeper Understanding},
	author={Hao Li and Soham De and Zheng Xu and Christoph Studer and Hanan Samet and Tom Goldstein},
	booktitle = {Advances in Neural Information Processing Systems},
	pages     = {5811--5821},
	year      = {2017},
}


@article{Rastegari_2016,
	title={XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks},
	ISBN={9783319464930},
	ISSN={1611-3349},
	journal={Lecture Notes in Computer Science},
	author={Rastegari, Mohammad and Ordonez, Vicente and Redmon, Joseph and Farhadi, Ali},
	year={2016},
	pages={525–542}
}

@ARTICLE{comprehensive_survey,
	author={L. {Deng} and G. {Li} and S. {Han} and L. {Shi} and Y. {Xie}},
	journal={Proceedings of the IEEE}, 
	title={Model Compression and Hardware Acceleration for Neural Networks: A Comprehensive Survey}, 
	year={2020},
	volume={108},
	number={4},
	pages={485-532},
}

@inproceedings{courbariaux2015binaryconnect,
	title={Binaryconnect: Training deep neural networks with binary weights during propagations},
	author={Courbariaux, Matthieu and Bengio, Yoshua and David, Jean-Pierre},
	booktitle = {Advances in Neural Information Processing Systems},
	pages     = {3123--3131},
	year      = {2015},
}

@article{cheng2018differentiable,
	title={Differentiable fine-grained quantization for deep neural network compression},
	author={Cheng, Hsin-Pai and Huang, Yuanjun and Guo, Xuyang and Huang, Yifei and Yan, Feng and Li, Hai and Chen, Yiran},
	journal={arXiv preprint arXiv:1810.10351},
	year={2018}
}

@article{Lin2019TowardEL,
	title={Toward Extremely Low Bit and Lossless Accuracy in DNNs with Progressive ADMM},
	author={Sheng Lin and Xiaolong Ma and Shaokai Ye and Geng Yuan and Kaisheng Ma and Yanzhi Wang},
	journal={ArXiv},
	year={2019},
	volume={abs/1905.00789}
}


@INPROCEEDINGS{bai2018proxquant,
	title={ProxQuant: Quantized Neural Networks via Proximal Operators},
	author={Yu Bai and Yu-Xiang Wang and Edo Liberty},
	booktitle={International Conference on Learning Representations},
	year={2019}
}



@InProceedings{Yang_2019_CVPR,
	author = {Yang, Jiwei and Shen, Xu and Xing, Jun and Tian, Xinmei and Li, Houqiang and Deng, Bing and Huang, Jianqiang and Hua, Xian-sheng},
	title = {Quantization Networks},
	booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	year = {2019}
}


@inproceedings{gong2019differentiable,
	title={Differentiable soft quantization: Bridging full-precision and low-bit neural networks},
	author={Gong, Ruihao and Liu, Xianglong and Jiang, Shenghu and Li, Tianxiang and Hu, Peng and Lin, Jiazhen and Yu, Fengwei and Yan, Junjie},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={4852--4861},
	year={2019}
}

@inproceedings{yang2019quantization,
	title={Quantization networks},
	author={Yang, Jiwei and Shen, Xu and Xing, Jun and Tian, Xinmei and Li, Houqiang and Deng, Bing and Huang, Jianqiang and Hua, Xian-sheng},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={7308--7316},
	year={2019}
}

@article{cifar10,
	title= {CIFAR-10 (Canadian Institute for Advanced Research)},
	journal= {},
	author= {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
	year= {2009},
}


@inproceedings{mcmahan2017communicationefficient,
	title={Communication-efficient learning of deep networks from decentralized data},
	author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
	booktitle={Artificial Intelligence and Statistics},
	pages={1273--1282},
	year={2017},
	organization={PMLR}
}

@inproceedings{he2015deep,
	title={Deep residual learning for image recognition},
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={770--778},
	year={2016}
}

@article{kingma2014adam,
	title={Adam: A method for stochastic optimization},
	author={Kingma, Diederik P and Ba, Jimmy},
	journal={arXiv preprint arXiv:1412.6980},
	year={2014}
}

@article{zhu2017trained,
	title={Trained ternary quantization},
	author={Zhu, Chenzhuo and Han, Song and Mao, Huizi and Dally, William J},
	journal={arXiv preprint arXiv:1612.01064},
	year={2016}
}

@misc{han2016deep,
	title={Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding}, 
	author={Song Han and Huizi Mao and William J. Dally},
	year={2016},
	eprint={1510.00149},
	archivePrefix={arXiv},
	primaryClass={cs.CV}
}

@inproceedings{stich2018sparsified,
	title={Sparsified SGD with memory},
	author={Stich, Sebastian U and Cordonnier, Jean-Baptiste and Jaggi, Martin},
	booktitle = {Advances in Neural Information Processing Systems},
	pages     = {4452--4463},
	year      = {2018},
}


@inproceedings{basu2019qsparse,
	author    = {Debraj Basu and
	Deepesh Data and
	Can Karakus and
	Suhas N. Diggavi},
	title     = {Qsparse-local-SGD: Distributed {SGD} with Quantization, Sparsification
	and Local Computations},
	booktitle = {Advances in Neural Information Processing Systems},
	pages     = {14668--14679},
	year      = {2019},
}

@inproceedings{karimireddy2019error,
	title={Error feedback fixes signsgd and other gradient compression schemes},
	author={Karimireddy, Sai Praneeth and Rebjock, Quentin and Stich, Sebastian and Jaggi, Martin},
	booktitle={International Conference on Machine Learning},
	pages={3252--3261},
	year={2019},
	organization={PMLR}
}

@inproceedings{alistarh2017,
	author = {Alistarh, Dan and Grubic, Demjan and Li, Jerry and Tomioka, Ryota and Vojnovic, Milan},
	booktitle = {Advances in Neural Information Processing Systems},
	pages = {1709--1720},
	title = {QSGD: Communication-Efficient SGD via Gradient Quantization and Encoding},
	year = {2017}
}

@inproceedings{BannerNS19,
	author    = {Ron Banner and
	Yury Nahshan and
	Daniel Soudry},
	title     = {Post training 4-bit quantization of convolutional networks for rapid-deployment},
	booktitle = {Advances in Neural Information Processing Systems},
	pages     = {7948--7956},
	year      = {2019},
}

@article{shen2020federated,
	title={Federated mutual learning},
	author={Shen, Tao and Zhang, Jie and Jia, Xinkang and Zhang, Fengda and Huang, Gang and Zhou, Pan and Kuang, Kun and Wu, Fei and Wu, Chao},
	journal={arXiv preprint arXiv:2006.16765},
	year={2020}
}

@article{li2019fedmd,
	title={Fedmd: Heterogenous federated learning via model distillation},
	author={Li, Daliang and Wang, Junpu},
	journal={arXiv preprint arXiv:1910.03581},
	year={2019}
}

@article{hinton2015distilling,
	title={Distilling the knowledge in a neural network},
	author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
	journal={arXiv preprint arXiv:1503.02531},
	year={2015}
}


@inproceedings{zhang2018deep,
	title={Deep mutual learning},
	author={Zhang, Ying and Xiang, Tao and Hospedales, Timothy M and Lu, Huchuan},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={4320--4328},
	year={2018}
}

@inproceedings{polino2018model,
	title={Model compression via distillation and quantization},
	author={Polino, Antonio and Pascanu, Razvan and Alistarh, Dan},
	booktitle={International Conference on Learning Representations},
	year={2018}
}

@article{caldas2018leaf,
	title={Leaf: A benchmark for federated settings},
	author={Caldas, Sebastian and Duddu, Sai Meher Karthik and Wu, Peter and Li, Tian and Kone{\v{c}}n{\`y}, Jakub and McMahan, H Brendan and Smith, Virginia and Talwalkar, Ameet},
	journal={arXiv preprint arXiv:1812.01097},
	year={2018}
}


@inproceedings{huang2021personalized,
	title={Personalized cross-silo federated learning on non-iid data},
	author={Huang, Yutao and Chu, Lingyang and Zhou, Zirui and Wang, Lanjun and Liu, Jiangchuan and Pei, Jian and Zhang, Yong},
	booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
	year={2021}
}

@article{nguyen2019new,
	title={New Convergence Aspects of Stochastic Gradient Algorithms.},
	author={Nguyen, Lam M and Nguyen, Phuong Ha and Richt{\'a}rik, Peter and Scheinberg, Katya and van Dijk, Marten},
	journal={Journal of Machine Learning Research},
	volume={20},
	number={176},
	pages={1--49},
	year={2019}
}

@article{singh2021squarm,
	title={Squarm-sgd: Communication-efficient momentum sgd for decentralized optimization},
	author={Singh, Navjot and Data, Deepesh and George, Jemin and Diggavi, Suhas},
	journal={IEEE Journal on Selected Areas in Information Theory},
	volume={2},
	number={3},
	pages={954--969},
	year={2021},
	publisher={IEEE}
}

@inproceedings{
	louizos2018relaxed,
	title={Relaxed Quantization for Discretized Neural Networks},
	author={Christos Louizos and Matthias Reisser and Tijmen Blankevoort and Efstratios Gavves and Max Welling},
	booktitle={International Conference on Learning Representations},
	year={2019},
	url={https://openreview.net/forum?id=HkxjYoCqKX},
}

@inproceedings{dbouk2020dbq,
	title={DBQ: A Differentiable Branch Quantizer for Lightweight Deep Neural Networks},
	author={Dbouk, Hassan and Sanghvi, Hetul and Mehendale, Mahesh and Shanbhag, Naresh},
	booktitle={European Conference on Computer Vision},
	pages={90--106},
	year={2020},
	organization={Springer}
}

@inproceedings{leng2018extremely,
	title={Extremely low bit neural network: Squeeze the last bit out with admm},
	author={Leng, Cong and Dou, Zesheng and Li, Hao and Zhu, Shenghuo and Jin, Rong},
	booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
	year={2018}
}

@InProceedings{hou2017loss,
	title={Loss-aware Binarization of Deep Networks},
	author={Hou, Lu and Yao, Quanming and Kwok, James T.},
	booktitle={International Conference on Learning Representations},
	year={2017}
}

@inproceedings{karimireddy2020scaffold,
	title={Scaffold: Stochastic controlled averaging for federated learning},
	author={Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
	booktitle={International Conference on Machine Learning},
	pages={5132--5143},
	year={2020},
	organization={PMLR}
}


@InProceedings{pmlr-v139-acar21a,
	title = 	 {Debiasing Model Updates for Improving Personalized Federated Training},
	author =       {Acar, Durmus Alp Emre and Zhao, Yue and Zhu, Ruizhao and Matas, Ramon and Mattina, Matthew and Whatmough, Paul and Saligrama, Venkatesh},
	booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
	pages = 	 {21--31},
	year = 	 {2021},
	volume = 	 {139},
	series = 	 {Proceedings of Machine Learning Research},
	month = 	 {18--24 Jul},
	publisher =    {PMLR},
	pdf = 	 {http://proceedings.mlr.press/v139/acar21a/acar21a.pdf},
	url = 	 {https://proceedings.mlr.press/v139/acar21a.html},
	abstract = 	 {We propose a novel method for federated learning that is customized specifically to the objective of a given edge device. In our proposed method, a server trains a global meta-model by collaborating with devices without actually sharing data. The trained global meta-model is then personalized locally by each device to meet its specific objective. Different from the conventional federated learning setting, training customized models for each device is hindered by both the inherent data biases of the various devices, as well as the requirements imposed by the federated architecture. We propose gradient correction methods leveraging prior works, and explicitly de-bias the meta-model in the distributed heterogeneous data setting to learn personalized device models. We present convergence guarantees of our method for strongly convex, convex and nonconvex meta objectives. We empirically evaluate the performance of our method on benchmark datasets and demonstrate significant communication savings.}
}

@article{ozkara2021qupel,
	title={QuPeL: Quantized Personalization with Applications to Federated Learning},
	author={Ozkara, Kaan and Singh, Navjot and Data, Deepesh and Diggavi, Suhas},
	journal={arXiv preprint arXiv:2102.11786},
	year={2021}
}
