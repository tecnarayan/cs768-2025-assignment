\begin{thebibliography}{10}

\bibitem{Amemiya1985}
T.~Amemiya.
\newblock {\em Advanced econometrics}.
\newblock Harvard university press, 1985.

\bibitem{BarndorffNielsen2014}
O.~Barndorff-Nielsen.
\newblock {\em Information and exponential families: in statistical theory}.
\newblock John Wiley \& Sons, 2014.

\bibitem{BarpBDGM2019}
A.~Barp, F.-X. Briol, A.~B. Duncan, M.~Girolami, and L.~Mackey.
\newblock Minimum stein discrepancy estimators.
\newblock {\em arXiv preprint arXiv:1906.08283}, 2019.

\bibitem{Besag1975}
J.~Besag.
\newblock Statistical analysis of non-lattice data.
\newblock {\em Journal of the Royal Statistical Society: Series D (The
  Statistician)}, 24(3):179--195, 1975.

\bibitem{Brown1986}
L.~D. Brown.
\newblock Fundamentals of statistical exponential families: with applications
  in statistical decision theory.
\newblock Ims, 1986.

\bibitem{CaiLL2011}
T.~Cai, W.~Liu, and X.~Luo.
\newblock A constrained $\ell_1$ minimization approach to sparse precision
  matrix estimation.
\newblock {\em Journal of the American Statistical Association},
  106(494):594--607, 2011.

\bibitem{CandesLMW2011}
E.~J. Cand{\`e}s, X.~Li, Y.~Ma, and J.~Wright.
\newblock Robust principal component analysis?
\newblock {\em Journal of the ACM (JACM)}, 58(3):1--37, 2011.

\bibitem{ChandrasekaranPW2010}
V.~Chandrasekaran, P.~A. Parrilo, and A.~S. Willsky.
\newblock Latent variable graphical model selection via convex optimization.
\newblock In {\em 2010 48th Annual Allerton Conference on Communication,
  Control, and Computing (Allerton)}, pages 1610--1613. IEEE, 2010.

\bibitem{ChwialkowskiSG2016}
K.~Chwialkowski, H.~Strathmann, and A.~Gretton.
\newblock A kernel test of goodness of fit.
\newblock In {\em International conference on machine learning}, pages
  2606--2615. PMLR, 2016.

\bibitem{DaganDDA2021}
Y.~Dagan, C.~Daskalakis, N.~Dikkala, and A.~V. Kandiros.
\newblock Learning ising models from one or multiple samples.
\newblock In {\em Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory
  of Computing}, pages 161--168, 2021.

\bibitem{DaiLDHGSS2019}
B.~Dai, Z.~Liu, H.~Dai, N.~He, A.~Gretton, L.~Song, and D.~Schuurmans.
\newblock Exponential family estimation via adversarial dynamics embedding.
\newblock {\em arXiv preprint arXiv:1904.12083}, 2019.

\bibitem{Darmois1935}
G.~Darmois.
\newblock Sur les lois de probabilit{\'e}a estimation exhaustive.
\newblock {\em CR Acad. Sci. Paris}, 260(1265):85, 1935.

\bibitem{DaskalakisGTZ2018}
C.~Daskalakis, T.~Gouleakis, C.~Tzamos, and M.~Zampetakis.
\newblock Efficient statistics, in high dimensions, from truncated samples.
\newblock In {\em 2018 IEEE 59th Annual Symposium on Foundations of Computer
  Science (FOCS)}, pages 639--649. IEEE, 2018.

\bibitem{DiakonikolasKSS2021}
I.~Diakonikolas, D.~M. Kane, A.~Stewart, and Y.~Sun.
\newblock Outlier-robust learning of ising models under dobrushin's condition.
\newblock {\em arXiv preprint arXiv:2102.02171}, 2021.

\bibitem{DuchiSSC2008}
J.~Duchi, S.~Shalev-Shwartz, Y.~Singer, and T.~Chandra.
\newblock Efficient projections onto the $\ell_1$-ball for learning in high
  dimensions.
\newblock In {\em Proceedings of the 25th international conference on Machine
  learning}, pages 272--279, 2008.

\bibitem{Ferguson2017}
T.~S. Ferguson.
\newblock {\em A course in large sample theory}.
\newblock Routledge, 2017.

\bibitem{Fisher1934}
R.~A. Fisher.
\newblock Two new properties of mathematical likelihood.
\newblock {\em Proceedings of the Royal Society of London. Series A, Containing
  Papers of a Mathematical and Physical Character}, 144(852):285--307, 1934.

\bibitem{FriedmanHT2008}
J.~Friedman, T.~Hastie, and R.~Tibshirani.
\newblock Sparse inverse covariance estimation with the graphical lasso.
\newblock {\em Biostatistics}, 9(3):432--441, 2008.

\bibitem{Hinton2002}
G.~E. Hinton.
\newblock Training products of experts by minimizing contrastive divergence.
\newblock {\em Neural computation}, 14(8):1771--1800, 2002.

\bibitem{HoggC1956}
R.~V. Hogg and A.~T. Craig.
\newblock Sufficient statistics in elementary distribution theory.
\newblock {\em Sankhy{\=a}: The Indian Journal of Statistics (1933-1960)},
  17(3):209--216, 1956.

\bibitem{Hyvarinen2007}
A.~Hyv{\"a}rinen.
\newblock Some extensions of score matching.
\newblock {\em Computational statistics \& data analysis}, 51(5):2499--2512,
  2007.

\bibitem{HyvarinenD2005}
A.~Hyv{\"a}rinen and P.~Dayan.
\newblock Estimation of non-normalized statistical models by score matching.
\newblock {\em Journal of Machine Learning Research}, 6(4), 2005.

\bibitem{Jaggi2013}
M.~Jaggi.
\newblock Revisiting frank-wolfe: Projection-free sparse convex optimization.
\newblock In {\em International Conference on Machine Learning}, pages
  427--435. PMLR, 2013.

\bibitem{JalaliRVS2011}
A.~Jalali, P.~Ravikumar, V.~Vasuki, and S.~Sanghavi.
\newblock On learning discrete graphical models using group-sparse
  regularization.
\newblock In {\em Proceedings of the Fourteenth International Conference on
  Artificial Intelligence and Statistics, {AISTATS} 2011, Fort Lauderdale, USA,
  April 11-13, 2011}, pages 378--387, 2011.

\bibitem{Jennrich1969}
R.~I. Jennrich.
\newblock Asymptotic properties of non-linear least squares estimators.
\newblock {\em Ann. Math. Statist.}, 40(2):633--643, 04 1969.

\bibitem{JerrumS1989}
M.~Jerrum and A.~Sinclair.
\newblock Approximating the permanent.
\newblock {\em SIAM journal on computing}, 18(6):1149--1178, 1989.

\bibitem{KakadeSST2010}
S.~Kakade, O.~Shamir, K.~Sindharan, and A.~Tewari.
\newblock Learning exponential families in high-dimensions: Strong convexity
  and sparsity.
\newblock In {\em Proceedings of the thirteenth international conference on
  artificial intelligence and statistics}, pages 381--388. JMLR Workshop and
  Conference Proceedings, 2010.

\bibitem{KelnerKMM2019}
J.~Kelner, F.~Koehler, R.~Meka, and A.~Moitra.
\newblock Learning some popular gaussian graphical models without condition
  number bounds.
\newblock 2019.

\bibitem{KlivansM2017}
A.~R. Klivans and R.~Meka.
\newblock Learning graphical models using multiplicative weights.
\newblock In {\em 58th {IEEE} Annual Symposium on Foundations of Computer
  Science, {FOCS} 2017, Berkeley, CA, USA, October 15-17, 2017}, pages
  343--354, 2017.

\bibitem{Koopman1936}
B.~O. Koopman.
\newblock On distributions admitting a sufficient statistic.
\newblock {\em Transactions of the American Mathematical society},
  39(3):399--409, 1936.

\bibitem{LinDS2016}
L.~Lin, M.~Drton, and A.~Shojaie.
\newblock Estimation of high-dimensional graphical models using regularized
  score matching.
\newblock {\em Electronic journal of statistics}, 10(1):806, 2016.

\bibitem{LiuLJ2016}
Q.~Liu, J.~Lee, and M.~Jordan.
\newblock A kernelized stein discrepancy for goodness-of-fit tests.
\newblock In {\em International conference on machine learning}, pages
  276--284. PMLR, 2016.

\bibitem{LiuKJC2019}
S.~Liu, T.~Kanamori, W.~Jitkrittum, and Y.~Chen.
\newblock Fisher efficient inference of intractable models.
\newblock {\em Advances in Neural Information Processing Systems},
  32:8793--8803, 2019.

\bibitem{LiuKW2019}
S.~Liu, T.~Kanamori, and D.~J. Williams.
\newblock Estimating density models with truncation boundaries.
\newblock {\em arXiv preprint arXiv:1910.03834}, 2019.

\bibitem{MeghanaN2016}
B.~Meghana and N.~He.
\newblock Lower bounds \& projected gradient descent.

\bibitem{MeinshausenB2006}
N.~Meinshausen, P.~B{\"u}hlmann, et~al.
\newblock High-dimensional graphs and variable selection with the lasso.
\newblock {\em Annals of statistics}, 34(3):1436--1462, 2006.

\bibitem{MengEH2014}
Z.~Meng, B.~Eriksson, and A.~Hero.
\newblock Learning latent variable gaussian graphical models.
\newblock In {\em International Conference on Machine Learning}, pages
  1269--1277. PMLR, 2014.

\bibitem{NaKK2019}
S.~Na, M.~Kolar, and O.~Koyejo.
\newblock Estimating differential latent variable graphical models with
  applications to brain connectivity.
\newblock {\em arXiv preprint arXiv:1909.05892}, 2019.

\bibitem{NingZL2017}
Y.~Ning, T.~Zhao, H.~Liu, et~al.
\newblock A likelihood ratio framework for high-dimensional semiparametric
  regression.
\newblock {\em Annals of Statistics}, 45(6):2299--2327, 2017.

\bibitem{Pitman1936}
E.~J.~G. Pitman.
\newblock Sufficient statistics and intrinsic accuracy.
\newblock In {\em Mathematical Proceedings of the cambridge Philosophical
  society}, volume~32, pages 567--579. Cambridge University Press, 1936.

\bibitem{RenMVL2021}
C.~X. Ren, S.~Misra, M.~Vuffray, and A.~Y. Lokhov.
\newblock Learning continuous exponential families beyond gaussian, 2021.

\bibitem{RhodesXG2020}
B.~Rhodes, K.~Xu, and M.~U. Gutmann.
\newblock Telescoping density-ratio estimation.
\newblock {\em arXiv preprint arXiv:2006.12204}, 2020.

\bibitem{RobertC2013}
C.~Robert and G.~Casella.
\newblock {\em Monte Carlo statistical methods}.
\newblock Springer Science \& Business Media, 2013.

\bibitem{ShahSW2021}
A.~Shah, D.~Shah, and G.~Wornell.
\newblock On learning continuous pairwise markov random fields.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 1153--1161. PMLR, 2021.

\bibitem{SimonFHT2013}
N.~Simon, J.~Friedman, T.~Hastie, and R.~Tibshirani.
\newblock A sparse-group lasso.
\newblock {\em Journal of computational and graphical statistics},
  22(2):231--245, 2013.

\bibitem{SriperumbudurFGHK2017}
B.~Sriperumbudur, K.~Fukumizu, A.~Gretton, A.~Hyv{\"a}rinen, and R.~Kumar.
\newblock Density estimation in infinite dimensional exponential families.
\newblock {\em Journal of Machine Learning Research}, 18, 2017.

\bibitem{StrathmannSLSG2015}
H.~Strathmann, D.~Sejdinovic, S.~Livingstone, Z.~Szabo, and A.~Gretton.
\newblock Gradient-free hamiltonian monte carlo with efficient kernel
  exponential families.
\newblock {\em arXiv preprint arXiv:1506.02564}, 2015.

\bibitem{SuggalaKR2017}
A.~S. Suggala, M.~Kolar, and P.~Ravikumar.
\newblock The expxorcist: Nonparametric graphical models via conditional
  exponential densities.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4446--4456, 2017.

\bibitem{SunKX2015}
S.~Sun, M.~Kolar, and J.~Xu.
\newblock Learning structured densities via infinite dimensional exponential
  families.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2287--2295, 2015.

\bibitem{SutherlandSAG2018}
D.~Sutherland, H.~Strathmann, M.~Arbel, and A.~Gretton.
\newblock Efficient and principled score estimation with nystr{\"o}m kernel
  exponential families.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 652--660. PMLR, 2018.

\bibitem{TanseyPSR2015}
W.~Tansey, O.~H.~M. Padilla, A.~S. Suggala, and P.~Ravikumar.
\newblock Vector-space markov random fields via exponential families.
\newblock In {\em International Conference on Machine Learning}, pages
  684--692, 2015.

\bibitem{Valiant1979}
L.~G. Valiant.
\newblock The complexity of enumeration and reliability problems.
\newblock {\em SIAM Journal on Computing}, 8(3):410--421, 1979.

\bibitem{Vaart2000}
A.~W. Van~der Vaart.
\newblock {\em Asymptotic statistics}, volume~3.
\newblock Cambridge university press, 2000.

\bibitem{VinciVSK2018}
G.~Vinci, V.~Ventura, M.~A. Smith, and R.~E. Kass.
\newblock Adjusted regularization in latent graphical models: Application to
  multiple-neuron spike count data.
\newblock {\em The annals of applied statistics}, 12(2):1068, 2018.

\bibitem{VuffrayML2019}
M.~Vuffray, S.~Misra, and A.~Y. Lokhov.
\newblock Efficient learning of discrete graphical models.
\newblock {\em CoRR}, abs/1902.00600, 2019.

\bibitem{VuffrayMLC2016}
M.~Vuffray, S.~Misra, A.~Y. Lokhov, and M.~Chertkov.
\newblock Interaction screening: Efficient and sample-optimal learning of ising
  models.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2595--2603, 2016.

\bibitem{WainwrightJW2003}
M.~J. Wainwright, T.~S. Jaakkola, and A.~S. Willsky.
\newblock Tree-reweighted belief propagation algorithms and approximate ml
  estimation by pseudo-moment matching.
\newblock In {\em AISTATS}, volume~3, page~3, 2003.

\bibitem{WainwrightJ2008}
M.~J. Wainwright and M.~I. Jordan.
\newblock Graphical models, exponential families, and variational inference.
\newblock {\em Foundations and Trends in Machine Learning}, 1(1-2):1--305,
  2008.

\bibitem{WainwrightRL2006}
M.~J. Wainwright, P.~Ravikumar, and J.~D. Lafferty.
\newblock High-dimensional graphical model selection using $\ell_1
  $-regularized logistic regression.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1465--1472, 2006.

\bibitem{WangWR2010}
W.~Wang, M.~J. Wainwright, and K.~Ramchandran.
\newblock Information-theoretic bounds on model selection for gaussian markov
  random fields.
\newblock In {\em 2010 IEEE International Symposium on Information Theory},
  pages 1373--1377. IEEE, 2010.

\bibitem{WenliangSSG2019}
L.~Wenliang, D.~Sutherland, H.~Strathmann, and A.~Gretton.
\newblock Learning deep kernels for exponential family densities.
\newblock In {\em International Conference on Machine Learning}, pages
  6737--6746. PMLR, 2019.

\bibitem{YangRAL2015}
E.~Yang, P.~Ravikumar, G.~I. Allen, and Z.~Liu.
\newblock Graphical models via univariate exponential family distributions.
\newblock {\em J. Mach. Learn. Res.}, 16:3813--3847, 2015.

\bibitem{YangNL2018}
Z.~Yang, Y.~Ning, and H.~Liu.
\newblock On semiparametric exponential family graphical models.
\newblock {\em The Journal of Machine Learning Research}, 19(1):2314--2372,
  2018.

\bibitem{YuanLZLL2016}
X.~Yuan, P.~Li, T.~Zhang, Q.~Liu, and G.~Liu.
\newblock Learning additive exponential family graphical models via $\ell_{2,1}
  $-norm regularized m-estimation.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4367--4375, 2016.

\end{thebibliography}
