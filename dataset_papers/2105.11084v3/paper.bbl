\begin{thebibliography}{127}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abate et~al.(2005)Abate, Menzel, and Tafila]{abate2005amharic}
S.~T. Abate, W.~Menzel, and B.~Tafila.
\newblock An amharic speech corpus for large vocabulary continuous speech
  recognition.
\newblock In \emph{Proc. of Interspeech}, 2005.

\bibitem[Abdel-Hamid et~al.(2012)Abdel-Hamid, Mohamed, Jiang, and
  Penn]{abdel2012applying}
O.~Abdel-Hamid, A.~Mohamed, H.~Jiang, and G.~Penn.
\newblock Applying convolutional neural networks concepts to hybrid nn-hmm
  model for speech recognition.
\newblock In \emph{Proc. of ICASSP}, 2012.

\bibitem[Amodei et~al.(2016)Amodei, Ananthanarayanan, Anubhai, Bai, Battenberg,
  Case, Casper, Catanzaro, Cheng, Chen, et~al.]{amodei2016deepspeech}
D.~Amodei, S.~Ananthanarayanan, R.~Anubhai, J.~Bai, E.~Battenberg, C.~Case,
  J.~Casper, B.~Catanzaro, Q.~Cheng, G.~Chen, et~al.
\newblock Deep speech 2: End-to-end speech recognition in english and mandarin.
\newblock In \emph{Proc. of ICML}, 2016.

\bibitem[Ardila et~al.(2020)Ardila, Branson, Davis, Henretty, Kohler, Meyer,
  Morais, Saunders, Tyers, and Weber]{ardila2019common}
R.~Ardila, M.~Branson, K.~Davis, M.~Henretty, M.~Kohler, J.~Meyer, R.~Morais,
  L.~Saunders, F.~M. Tyers, and G.~Weber.
\newblock Common voice: A massively-multilingual speech corpus.
\newblock \emph{Proc. of LREC}, 2020.

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and
  Bottou]{arjovsky2017wasserstein}
M.~Arjovsky, S.~Chintala, and L.~Bottou.
\newblock Wasserstein gan.
\newblock \emph{Proc. of ICML}, 2017.

\bibitem[Artetxe et~al.(2017)Artetxe, Labaka, and Agirre]{artetxe2017learning}
M.~Artetxe, G.~Labaka, and E.~Agirre.
\newblock Learning bilingual word embeddings with (almost) no bilingual data.
\newblock In \emph{Proc. of ACL}, 2017.

\bibitem[Artetxe et~al.(2018)Artetxe, Labaka, Agirre, and
  Cho]{artetxe2018unsupervised}
M.~Artetxe, G.~Labaka, E.~Agirre, and K.~Cho.
\newblock Unsupervised neural machine translation.
\newblock \emph{Proc. of ICLR}, 2018.

\bibitem[Baevski and Auli(2018)]{baevski2018adaptive}
A.~Baevski and M.~Auli.
\newblock Adaptive input representations for neural language modeling.
\newblock In \emph{Proc. of ICLR}, 2018.

\bibitem[Baevski et~al.(2020{\natexlab{a}})Baevski, Auli, and
  Mohamed]{baevski2019effectiveness}
A.~Baevski, M.~Auli, and A.~Mohamed.
\newblock Effectiveness of self-supervised pre-training for speech recognition.
\newblock \emph{Proc. of ICASSP}, 2020{\natexlab{a}}.

\bibitem[Baevski et~al.(2020{\natexlab{b}})Baevski, Schneider, and
  Auli]{baevski2019vqwav2vec}
A.~Baevski, S.~Schneider, and M.~Auli.
\newblock vq-wav2vec: Self-supervised learning of discrete speech
  representations.
\newblock In \emph{Proc. of ICLR}, 2020{\natexlab{b}}.

\bibitem[Baevski et~al.(2020{\natexlab{c}})Baevski, Zhou, Mohamed, and
  Auli]{baevski2020wav}
A.~Baevski, Y.~Zhou, A.~Mohamed, and M.~Auli.
\newblock wav2vec 2.0: {A} framework for self-supervised learning of speech
  representations.
\newblock In \emph{Proc. of NeurIPS}, 2020{\natexlab{c}}.

\bibitem[Bahdanau et~al.(2014)Bahdanau, Cho, and Bengio]{bahdanau2014neural}
D.~Bahdanau, K.~Cho, and Y.~Bengio.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock \emph{Proc. of ICLR}, 2014.

\bibitem[Bahl et~al.(1986)Bahl, Brown, De~Souza, and Mercer]{bahl1986maximum}
L.~Bahl, P.~Brown, P.~De~Souza, and R.~Mercer.
\newblock Maximum mutual information estimation of hidden markov model
  parameters for speech recognition.
\newblock In \emph{Proc. of ICASSP}, volume~11, pages 49--52. IEEE, 1986.

\bibitem[Bahl et~al.(1983)Bahl, Jelinek, and Mercer]{bahl1983maximum}
L.~R. Bahl, F.~Jelinek, and R.~L. Mercer.
\newblock A maximum likelihood approach to continuous speech recognition.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 1983.

\bibitem[Besacier et~al.(2015)Besacier, Gauthier, Mangeot, Bretier, Bagshaw,
  Rosec, Moudenc, Pellegrino, Voisin, Marsico, and
  Nocera]{besacier2015speechtf}
L.~Besacier, E.~Gauthier, M.~Mangeot, P.~Bretier, P.~Bagshaw, O.~Rosec,
  T.~Moudenc, F.~Pellegrino, S.~Voisin, E.~Marsico, and P.~Nocera.
\newblock Speech technologies for african languages: example of a multilingual
  calculator for education.
\newblock In \emph{Proc. of Interspeech}, 2015.

\bibitem[Bojar and Tamchyna(2011)]{bojar2011bt_pbmt}
O.~Bojar and A.~Tamchyna.
\newblock Improving translation model by monolingual data.
\newblock In \emph{Proc. of WMT}, 2011.

\bibitem[Bourlard and Morgan(2012)]{bourlard2012connectionist}
H.~A. Bourlard and N.~Morgan.
\newblock \emph{Connectionist speech recognition: a hybrid approach}, volume
  247.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Can et~al.(2018)Can, Martinez, Papadopoulos, and
  Narayanan]{can2018pykaldi}
D.~Can, V.~R. Martinez, P.~Papadopoulos, and S.~S. Narayanan.
\newblock Pykaldi: A python wrapper for kaldi.
\newblock In \emph{Proc. of ICASSP}, 2018.

\bibitem[Chen et~al.(2019)Chen, Tsai, Liu, Lee, and shan
  Lee]{chen2019completely}
K.-Y. Chen, C.-P. Tsai, D.-R. Liu, H.-Y. Lee, and L.~shan Lee.
\newblock Completely unsupervised speech recognition by a generative
  adversarial network harmonized with iteratively refined hidden markov models.
\newblock In \emph{Proc. of Interspeech}, 2019.

\bibitem[Chorowski and Jaitly(2017)]{chorowski2016towards}
J.~Chorowski and N.~Jaitly.
\newblock Towards better decoding and language model integration in sequence to
  sequence models.
\newblock \emph{Proc. of Interspeech}, 2017.

\bibitem[Chorowski et~al.(2015)Chorowski, Bahdanau, Serdyuk, Cho, and
  Bengio]{chorowski2015attention}
J.~Chorowski, D.~Bahdanau, D.~Serdyuk, K.~Cho, and Y.~Bengio.
\newblock Attention-based models for speech recognition.
\newblock \emph{Proc. of NIPS}, 2015.

\bibitem[Chung et~al.(2018)Chung, Weng, Tong, and Glass]{chung2018unsup}
Y.~Chung, W.~Weng, S.~Tong, and J.~R. Glass.
\newblock Unsupervised cross-modal alignment of speech and text embedding
  spaces.
\newblock \emph{Proc. of NIPS}, 2018.

\bibitem[Chung et~al.(2019{\natexlab{a}})Chung, Hsu, Tang, and
  Glass]{chung2019apc}
Y.~Chung, W.~Hsu, H.~Tang, and J.~R. Glass.
\newblock An unsupervised autoregressive model for speech representation
  learning.
\newblock \emph{Proc. of Interspeech}, 2019{\natexlab{a}}.

\bibitem[Chung and Glass(2018)]{chung2018speech2vec}
Y.-A. Chung and J.~Glass.
\newblock Speech2vec: A sequence-to-sequence framework for learning word
  embeddings from speech.
\newblock \emph{Proc. of Interspeech}, 2018.

\bibitem[Chung et~al.(2019{\natexlab{b}})Chung, Hsu, Tang, and
  Glass]{chung2019unsupervised}
Y.-A. Chung, W.-N. Hsu, H.~Tang, and J.~Glass.
\newblock An unsupervised autoregressive model for speech representation
  learning.
\newblock \emph{Proc. of Interspeech}, 2019{\natexlab{b}}.

\bibitem[Conneau and Lample(2019)]{conneau2019cross}
A.~Conneau and G.~Lample.
\newblock Cross-lingual language model pretraining.
\newblock \emph{Proc. of NeurIPS}, 2019.

\bibitem[Conneau et~al.(2018)Conneau, Lample, Ranzato, Denoyer, and
  J{\'{e}}gou]{conneau2018unsupmt}
A.~Conneau, G.~Lample, M.~Ranzato, L.~Denoyer, and H.~J{\'{e}}gou.
\newblock Word translation without parallel data.
\newblock \emph{Proc. of ICLR}, 2018.

\bibitem[Conneau et~al.(2020)Conneau, Baevski, Collobert, Mohamed, and
  Auli]{conneau2020unsupervised}
A.~Conneau, A.~Baevski, R.~Collobert, A.~Mohamed, and M.~Auli.
\newblock Unsupervised cross-lingual representation learning for speech
  recognition.
\newblock \emph{arXiv}, abs/2006.13979, 2020.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{Proc. of NAACL}, 2019.

\bibitem[Dieleman et~al.(2018)Dieleman, van~den Oord, and
  Simonyan]{dieleman2018challenge}
S.~Dieleman, A.~van~den Oord, and K.~Simonyan.
\newblock The challenge of realistic music generation: modelling raw audio at
  scale.
\newblock \emph{Proc of NIPS}, 2018.

\bibitem[Dong et~al.(2018)Dong, Xu, and Xu]{linhao2018transformer}
L.~Dong, S.~Xu, and B.~Xu.
\newblock Speech-transformer: A no-recurrence sequence-to-sequence model for
  speech recognition.
\newblock In \emph{Proc. of ICASSP}, 2018.

\bibitem[Edunov et~al.(2018)Edunov, Ott, Auli, and
  Grangier]{edunov2018understanding}
S.~Edunov, M.~Ott, M.~Auli, and D.~Grangier.
\newblock Understanding back-translation at scale.
\newblock In \emph{Proc. of EMNLP}, 2018.

\bibitem[Fan et~al.(2021)Fan, Li, Zhou, and Xu]{fan2021exploring}
Z.~Fan, M.~Li, S.~Zhou, and B.~Xu.
\newblock Exploring wav2vec 2.0 on speaker verification and language
  identification.
\newblock \emph{arXiv}, 2021.

\bibitem[Fer et~al.(2017)Fer, Mat{\v{e}}jka, Gr{\'e}zl, Plchot, Vesel{\`y}, and
  {\v{C}}ernock{\`y}]{fer2017multilingually}
R.~Fer, P.~Mat{\v{e}}jka, F.~Gr{\'e}zl, O.~Plchot, K.~Vesel{\`y}, and J.~H.
  {\v{C}}ernock{\`y}.
\newblock Multilingually trained bottleneck features in spoken language
  recognition.
\newblock \emph{Computer Speech \& Language}, 46, 2017.

\bibitem[Ganin et~al.(2016)Ganin, Ustinova, Ajakan, Germain, Larochelle,
  Laviolette, Marchand, and Lempitsky]{ganin2016domain}
Y.~Ganin, E.~Ustinova, H.~Ajakan, P.~Germain, H.~Larochelle, F.~Laviolette,
  M.~Marchand, and V.~Lempitsky.
\newblock Domain-adversarial training of neural networks.
\newblock \emph{The journal of machine learning research}, 17\penalty0
  (1):\penalty0 2096--2030, 2016.

\bibitem[Garofolo et~al.(1993)Garofolo, Lamel, Fisher, Fiscus, Pallett, and
  Dahlgren]{garofolo1993timit}
J.~S. Garofolo, L.~F. Lamel, W.~M. Fisher, J.~G. Fiscus, D.~S. Pallett, and
  N.~L. Dahlgren.
\newblock {The DARPA TIMIT Acoustic-Phonetic Continuous Speech Corpus CDROM}.
\newblock \emph{Linguistic Data Consortium}, 1993.

\bibitem[Gelas et~al.(2012)Gelas, Besacier, and Pellegrino]{gelas2012alffa}
H.~Gelas, L.~Besacier, and F.~Pellegrino.
\newblock {D}evelopments of {S}wahili resources for an automatic speech
  recognition system.
\newblock In \emph{Proc. of SLTU}, 2012.

\bibitem[Gish et~al.(2009)Gish, Siu, Chan, and Belfield]{gish2009unsupervised}
H.~Gish, M.~Siu, A.~Chan, and W.~Belfield.
\newblock Unsupervised training of an hmm-based speech recognizer for topic
  classification.
\newblock In \emph{Proc. of Interspeech}, 2009.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
I.~J. Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair,
  A.~Courville, and Y.~Bengio.
\newblock Generative adversarial networks.
\newblock \emph{Proc. of NIPS}, 2014.

\bibitem[Google(2021)]{google2021asr}
Google.
\newblock Google cloud: Speech-to-text.
\newblock \url{https://cloud.google.com/speech-to-text}, 2021.
\newblock Accessed: 2021-05-13.

\bibitem[Graves(2012)]{graves2012sequence}
A.~Graves.
\newblock Sequence transduction with recurrent neural networks.
\newblock \emph{Proc. of ICML workshop on Representation Learning}, 2012.

\bibitem[Graves et~al.(2006)Graves, Fernández, and Gomez]{graves2006ctc}
A.~Graves, S.~Fernández, and F.~Gomez.
\newblock Connectionist temporal classification: Labelling unsegmented sequence
  data with recurrent neural networks.
\newblock In \emph{Proc. of ICML}, 2006.

\bibitem[Gulati et~al.(2020)Gulati, Qin, Chiu, Parmar, Zhang, Yu, Han, Wang,
  Zhang, Wu, and Pang]{gulati2020conformer}
A.~Gulati, J.~Qin, C.-C. Chiu, N.~Parmar, Y.~Zhang, J.~Yu, W.~Han, S.~Wang,
  Z.~Zhang, Y.~Wu, and R.~Pang.
\newblock Conformer: Convolution-augmented transformer for speech recognition.
\newblock \emph{Proc. of Interspeech}, 2020.

\bibitem[Gulrajani et~al.(2017)Gulrajani, Ahmed, Arjovsky, Dumoulin, and
  Courville]{gulrajani2017improved}
I.~Gulrajani, F.~Ahmed, M.~Arjovsky, V.~Dumoulin, and A.~Courville.
\newblock Improved training of wasserstein gans.
\newblock \emph{Proc. of NIPS}, 2017.

\bibitem[Han et~al.(2020)Han, Zhang, Zhang, Yu, Chiu, Qin, Gulati, Pang, and
  Wu]{han2020contextnet}
W.~Han, Z.~Zhang, Y.~Zhang, J.~Yu, C.-C. Chiu, J.~Qin, A.~Gulati, R.~Pang, and
  Y.~Wu.
\newblock Contextnet: Improving convolutional neural networks for automatic
  speech recognition with global context.
\newblock \emph{Proc. of Interspeech}, 2020.

\bibitem[Hannun(2017)]{hannun2017sequence}
A.~Hannun.
\newblock Sequence modeling with ctc.
\newblock \emph{Distill}, 2017.
\newblock \doi{10.23915/distill.00008}.
\newblock https://distill.pub/2017/ctc.

\bibitem[Hannun et~al.(2020)Hannun, Pratap, Kahn, and
  Hsu]{hannun2020differentiable}
A.~Hannun, V.~Pratap, J.~Kahn, and W.-N. Hsu.
\newblock Differentiable weighted finite-state transducers.
\newblock \emph{arXiv preprint arXiv:2010.01003}, 2020.

\bibitem[Harwath and Glass(2019)]{harwath2019towards}
D.~Harwath and J.~Glass.
\newblock Towards visually grounded sub-word speech unit discovery.
\newblock In \emph{Proc. of ICASSP}, pages 3017--3021. IEEE, 2019.

\bibitem[Harwath et~al.(2020)Harwath, Hsu, and Glass]{harwath2019learning}
D.~Harwath, W.-N. Hsu, and J.~Glass.
\newblock Learning hierarchical discrete linguistic units from
  visually-grounded speech.
\newblock In \emph{Proc. of ICLR}, 2020.

\bibitem[Hayashi et~al.(2018)Hayashi, Watanabe, Zhang, Toda, Hori, Astudillo,
  and Takeda]{hayashi2018slt}
T.~Hayashi, S.~Watanabe, Y.~Zhang, T.~Toda, T.~Hori, R.~F. Astudillo, and
  K.~Takeda.
\newblock Back-translation-style data augmentation for end-to-end {ASR}.
\newblock In \emph{Proc. of SLT}, 2018.

\bibitem[Heafield(2011)]{heafield-2011-kenlm}
K.~Heafield.
\newblock {K}en{LM}: Faster and smaller language model queries.
\newblock In \emph{Proceedings of the Sixth Workshop on Statistical Machine
  Translation}, pages 187--197, Edinburgh, Scotland, July 2011. Association for
  Computational Linguistics.

\bibitem[Hinton et~al.(2012)Hinton, Deng, Yu, Dahl, Mohamed, Jaitly, Senior,
  Vanhoucke, Nguyen, Sainath, et~al.]{hinton2012deep}
G.~Hinton, L.~Deng, D.~Yu, G.~E. Dahl, A.~Mohamed, N.~Jaitly, A.~Senior,
  V.~Vanhoucke, P.~Nguyen, T.~N. Sainath, et~al.
\newblock Deep neural networks for acoustic modeling in speech recognition: The
  shared views of four research groups.
\newblock \emph{IEEE Signal processing magazine}, 29\penalty0 (6):\penalty0
  82--97, 2012.

\bibitem[Hirsh-Pasek et~al.(1987)Hirsh-Pasek, {Kemler Nelson}, Jusczyk,
  Cassidy, Druss, and Kennedy]{HIRSHPASEK1987269}
K.~Hirsh-Pasek, D.~G. {Kemler Nelson}, P.~W. Jusczyk, K.~W. Cassidy, B.~Druss,
  and L.~Kennedy.
\newblock Clauses are perceptual units for young infants.
\newblock \emph{Cognition}, 26\penalty0 (3):\penalty0 269--286, 1987.

\bibitem[Hori et~al.(2019)Hori, Astudillo, Hayashi, Zhang, Watanabe, and
  Le~Roux]{hori2019cycle}
T.~Hori, R.~Astudillo, T.~Hayashi, Y.~Zhang, S.~Watanabe, and J.~Le~Roux.
\newblock Cycle-consistency training for end-to-end speech recognition.
\newblock In \emph{Proc. of ICASSP}, 2019.

\bibitem[Hsu et~al.(2020)Hsu, Lee, Synnaeve, and Hannun]{hsu2020semi}
W.-N. Hsu, A.~Lee, G.~Synnaeve, and A.~Hannun.
\newblock Semi-supervised speech recognition via local prior matching.
\newblock \emph{arXiv preprint arXiv:2002.10336}, 2020.

\bibitem[Hsu et~al.(2021{\natexlab{a}})Hsu, Sriram, Baevski, Likhomanenko, Xu,
  Pratap, Kahn, Lee, Collobert, Synnaeve, et~al.]{hsu2021robust}
W.-N. Hsu, A.~Sriram, A.~Baevski, T.~Likhomanenko, Q.~Xu, V.~Pratap, J.~Kahn,
  A.~Lee, R.~Collobert, G.~Synnaeve, et~al.
\newblock Robust wav2vec 2.0: Analyzing domain shift in self-supervised
  pre-training.
\newblock \emph{arXiv preprint arXiv:2104.01027}, 2021{\natexlab{a}}.

\bibitem[Hsu et~al.(2021{\natexlab{b}})Hsu, Tsai, Bolte, Salakhutdinov, and
  Mohamed]{hsu2020hubert}
W.-N. Hsu, Y.-H.~H. Tsai, B.~Bolte, R.~Salakhutdinov, and A.~Mohamed.
\newblock Hubert: How much can a bad teacher benefit {ASR} pre-training?
\newblock In \emph{Proc. of ICASSP}, 2021{\natexlab{b}}.

\bibitem[Jang et~al.(2016)Jang, Gu, and Poole]{jang2016gumbel}
E.~Jang, S.~Gu, and B.~Poole.
\newblock Categorical reparameterization with gumbel-softmax.
\newblock \emph{Proc. of ICLR}, 2016.

\bibitem[Jawahar et~al.(2019)Jawahar, Sagot, and Seddah]{jawahar2019does}
G.~Jawahar, B.~Sagot, and D.~Seddah.
\newblock What does bert learn about the structure of language?
\newblock In \emph{Proc. of ACL}, 2019.

\bibitem[Jegou et~al.(2011)Jegou, Douze, and Schmid]{jegou2011ieee}
H.~Jegou, M.~Douze, and C.~Schmid.
\newblock Product quantization for nearest neighbor search.
\newblock \emph{IEEE Trans. Pattern Anal. Mach. Intell.}, 33\penalty0
  (1):\penalty0 117--128, Jan. 2011.

\bibitem[Jiang et~al.(2019)Jiang, Lei, Li, Luo, Hu, Zou, and
  Li]{jiang2019improving}
D.~Jiang, X.~Lei, W.~Li, N.~Luo, Y.~Hu, W.~Zou, and X.~Li.
\newblock Improving transformer-based speech recognition using unsupervised
  pre-training.
\newblock \emph{Proc. of Interspeech}, 2019.

\bibitem[Johnson and Jusczyk(2001)]{JOHNSON2001548}
E.~K. Johnson and P.~W. Jusczyk.
\newblock Word segmentation by 8-month-olds: When speech cues count more than
  statistics.
\newblock \emph{Journal of Memory and Language}, 44\penalty0 (4):\penalty0
  548--567, 2001.

\bibitem[Johnson et~al.(2019)Johnson, Douze, and J{\'e}gou]{johnson2017faiss}
J.~Johnson, M.~Douze, and H.~J{\'e}gou.
\newblock Billion-scale similarity search with gpus.
\newblock \emph{IEEE Transactions on Big Data}, 2019.

\bibitem[Juang et~al.(1986)Juang, Levinson, and Sondhi]{juang1986maximum}
B.-H. Juang, S.~Levinson, and M.~Sondhi.
\newblock Maximum likelihood estimation for multivariate mixture observations
  of markov chains (corresp.).
\newblock \emph{IEEE Transactions on Information Theory}, 32\penalty0
  (2):\penalty0 307--309, 1986.

\bibitem[Jusczyk et~al.(1999)Jusczyk, Houston, and Newsome]{JUSCZYK1999159}
P.~W. Jusczyk, D.~M. Houston, and M.~Newsome.
\newblock The beginnings of word segmentation in english-learning infants.
\newblock \emph{Cognitive Psychology}, 39\penalty0 (3):\penalty0 159--207,
  1999.

\bibitem[Kahn et~al.(2020{\natexlab{a}})Kahn, Lee, and Hannun]{kahn2020st}
J.~Kahn, A.~Lee, and A.~Hannun.
\newblock Self-training for end-to-end speech recognition.
\newblock In \emph{Proc. of ICASSP}, 2020{\natexlab{a}}.

\bibitem[Kahn et~al.(2020{\natexlab{b}})]{kahn2020librilight}
J.~Kahn et~al.
\newblock Libri-light: A benchmark for asr with limited or no supervision.
\newblock In \emph{Proc. of ICASSP}, 2020{\natexlab{b}}.

\bibitem[Kamper et~al.(2017{\natexlab{a}})Kamper, Jansen, and
  Goldwater]{kamper2017seg}
H.~Kamper, A.~Jansen, and S.~Goldwater.
\newblock A segmental framework for fully-unsupervised large-vocabulary speech
  recognition.
\newblock \emph{Comput. Speech Lang.}, 46\penalty0 (C), Nov.
  2017{\natexlab{a}}.

\bibitem[Kamper et~al.(2017{\natexlab{b}})Kamper, Livescu, and
  Goldwater]{kamper2017embedded}
H.~Kamper, K.~Livescu, and S.~Goldwater.
\newblock An embedded segmental k-means model for unsupervised segmentation and
  clustering of speech.
\newblock \emph{Proc. of ASRU}, 2017{\natexlab{b}}.

\bibitem[Kawakami et~al.(2020)Kawakami, Wang, Dyer, Blunsom, and van~den
  Oord]{kawakami2020learning}
K.~Kawakami, L.~Wang, C.~Dyer, P.~Blunsom, and A.~van~den Oord.
\newblock Learning robust and multilingual speech representations.
\newblock \emph{Proc. of EMNLP}, 2020.

\bibitem[Kingma and Ba(2015)]{kingma2015adam}
D.~P. Kingma and J.~Ba.
\newblock {Adam: A Method for Stochastic Optimization}.
\newblock In \emph{Proc. of ICLR}, 2015.

\bibitem[Kreuk et~al.(2020)Kreuk, Keshet, and Adi]{kreuk2020self}
F.~Kreuk, J.~Keshet, and Y.~Adi.
\newblock Self-supervised contrastive learning for unsupervised phoneme
  segmentation.
\newblock \emph{Proc. of Interspeech}, 2020.

\bibitem[Lample et~al.(2018)Lample, Denoyer, and Ranzato]{lample2018unsupmt}
G.~Lample, L.~Denoyer, and M.~Ranzato.
\newblock Unsupervised machine translation using monolingual corpora only.
\newblock In \emph{Proc. of ICLR}, 2018.

\bibitem[Lee and Glass(2012)]{lee2012anb}
C.~Lee and J.~R. Glass.
\newblock A nonparametric bayesian approach to acoustic model discovery.
\newblock In \emph{Proc. of ACL}, 2012.

\bibitem[Lee et~al.(2015)Lee, O'Donnell, and Glass]{lee2015unsupervised}
C.~Lee, T.~J. O'Donnell, and J.~R. Glass.
\newblock Unsupervised lexicon discovery from acoustic input.
\newblock \emph{TACL}, 2015.

\bibitem[Lewis et~al.(2016)Lewis, Simon, and Fennig]{lewis2016ethnologue}
M.~P. Lewis, G.~F. Simon, and C.~D. Fennig.
\newblock Ethnologue: Languages of the world, nineteenth edition.
\newblock Online version: \url{http://www.ethnologue.com}, 2016.

\bibitem[Likhomanenko et~al.(2021)Likhomanenko, Xu, Kahn, Synnaeve, and
  Collobert]{likhomanenko2021slimipl}
T.~Likhomanenko, Q.~Xu, J.~Kahn, G.~Synnaeve, and R.~Collobert.
\newblock slimipl: Language-model-free iterative pseudo-labeling.
\newblock \emph{arXiv}, 2021.

\bibitem[Liu et~al.(2019)Liu, Tu, yi~Lee, and shan Lee]{alex2019unsupervised}
A.~H. Liu, T.~Tu, H.~yi~Lee, and L.~shan Lee.
\newblock Towards unsupervised speech recognition and synthesis with quantized
  speech representation learning.
\newblock \emph{Proc. of ICASSP}, 2019.

\bibitem[Liu et~al.(2018)Liu, Chen, Lee, and shan Lee]{liu2018completely}
D.-R. Liu, K.-Y. Chen, H.-Y. Lee, and L.~shan Lee.
\newblock Completely unsupervised phoneme recognition by adversarially learning
  mapping relationships from audio embeddings.
\newblock \emph{Proc. of Interspeech}, 2018.

\bibitem[Manohar et~al.(2018)Manohar, Hadian, Povey, and
  Khudanpur]{manohar2018semi}
V.~Manohar, H.~Hadian, D.~Povey, and S.~Khudanpur.
\newblock Semi-supervised training of acoustic models using lattice-free mmi.
\newblock In \emph{Proc. of ICASSP}, 2018.

\bibitem[Mikolov et~al.(2013{\natexlab{a}})Mikolov, Le, and
  Sutskever]{mikolov2013exploiting}
T.~Mikolov, Q.~V. Le, and I.~Sutskever.
\newblock Exploiting similarities among languages for machine translation.
\newblock \emph{arXiv preprint arXiv:1309.4168}, 2013{\natexlab{a}}.

\bibitem[Mikolov et~al.(2013{\natexlab{b}})Mikolov, Sutskever, Chen, Corrado,
  and Dean]{mikolov2013word2vec}
T.~Mikolov, I.~Sutskever, K.~Chen, G.~S. Corrado, and J.~Dean.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In \emph{Proc. of NIPS}, 2013{\natexlab{b}}.

\bibitem[Mohri(1997)]{mohri1997finite}
M.~Mohri.
\newblock Finite-state transducers in language and speech processing.
\newblock \emph{Computational linguistics}, 23\penalty0 (2):\penalty0 269--311,
  1997.

\bibitem[Mohri et~al.(2002)Mohri, Pereira, and Riley]{mohri2002weighted}
M.~Mohri, F.~Pereira, and M.~Riley.
\newblock Weighted finite-state transducers in speech recognition.
\newblock \emph{Computer Speech \& Language}, 16\penalty0 (1):\penalty0 69--88,
  2002.

\bibitem[Ondel et~al.(2016)Ondel, Burget, and
  Cernock{\'y}]{ondel2016variational}
L.~Ondel, L.~Burget, and J.~Cernock{\'y}.
\newblock Variational inference for acoustic unit discovery.
\newblock In \emph{Proc. of SLTU}, 2016.

\bibitem[Ott et~al.(2019)Ott, Edunov, Baevski, Fan, Gross, Ng, Grangier, and
  Auli]{ott2019fairseq}
M.~Ott, S.~Edunov, A.~Baevski, A.~Fan, S.~Gross, N.~Ng, D.~Grangier, and
  M.~Auli.
\newblock fairseq: A fast, extensible toolkit for sequence modeling.
\newblock In \emph{Proc. of NAACL System Demonstrations}, 2019.

\bibitem[Panayotov et~al.(2015)Panayotov, Chen, Povey, and
  Khudanpur]{panayotov2015librispeech}
V.~Panayotov, G.~Chen, D.~Povey, and S.~Khudanpur.
\newblock Librispeech: an asr corpus based on public domain audio books.
\newblock In \emph{Proc. of ICASSP}, pages 5206--5210. IEEE, 2015.

\bibitem[Park et~al.(2019)Park, Chan, Zhang, Chiu, Zoph, Cubuk, and
  Le]{park2019specaugment}
D.~S. Park, W.~Chan, Y.~Zhang, C.-C. Chiu, B.~Zoph, E.~D. Cubuk, and Q.~V. Le.
\newblock Specaugment: A simple data augmentation method for automatic speech
  recognition.
\newblock In \emph{Proc. of Interspeech}, 2019.

\bibitem[Park et~al.(2020)Park, Zhang, Jia, Han, Chiu, Li, Wu, and
  Le]{park2020improved}
D.~S. Park, Y.~Zhang, Y.~Jia, W.~Han, C.-C. Chiu, B.~Li, Y.~Wu, and Q.~V. Le.
\newblock Improved noisy student training for automatic speech recognition.
\newblock \emph{Proc. of Interspeech}, 2020.

\bibitem[Park and Kim(2019)]{g2pE2019}
K.~Park and J.~Kim.
\newblock g2pe.
\newblock \url{https://github.com/Kyubyong/g2p}, 2019.

\bibitem[Pepino et~al.(2021)Pepino, Riera, and Ferrer]{pepino2021emotion}
L.~Pepino, P.~Riera, and L.~Ferrer.
\newblock Emotion recognition from speech using wav2vec 2.0 embeddings.
\newblock \emph{arXiv}, 2021.

\bibitem[Polka and Werker(1994)]{polka1994developmental}
L.~Polka and J.~F. Werker.
\newblock Developmental changes in perception of nonnative vowel contrasts.
\newblock \emph{Journal of Experimental Psychology: Human perception and
  performance}, 20\penalty0 (2):\penalty0 421, 1994.

\bibitem[Povey(2005)]{povey2005discriminative}
D.~Povey.
\newblock \emph{Discriminative training for large vocabulary speech
  recognition}.
\newblock PhD thesis, University of Cambridge, 2005.

\bibitem[Povey et~al.(2011)Povey, Ghoshal, Boulianne, Burget, Glembek, Goel,
  Hannemann, Motlicek, Qian, Schwarz, Silovsky, Stemmer, and
  Vesely]{povey2011kaldi}
D.~Povey, A.~Ghoshal, G.~Boulianne, L.~Burget, O.~Glembek, N.~Goel,
  M.~Hannemann, P.~Motlicek, Y.~Qian, P.~Schwarz, J.~Silovsky, G.~Stemmer, and
  K.~Vesely.
\newblock The kaldi speech recognition toolkit.
\newblock In \emph{Proc. of ASRU}, 2011.

\bibitem[{Pratap} et~al.(2019){Pratap}, {Hannun}, {Xu}, {Cai}, {Kahn},
  {Synnaeve}, {Liptchinsky}, and {Collobert}]{pratap2019w2l}
V.~{Pratap}, A.~{Hannun}, Q.~{Xu}, J.~{Cai}, J.~{Kahn}, G.~{Synnaeve},
  V.~{Liptchinsky}, and R.~{Collobert}.
\newblock Wav2letter++: A fast open-source speech recognition system.
\newblock In \emph{Proc. of ICASSP}, 2019.

\bibitem[Pratap et~al.(2020)Pratap, Xu, Sriram, Synnaeve, and
  Collobert]{pratap2020mls}
V.~Pratap, Q.~Xu, A.~Sriram, G.~Synnaeve, and R.~Collobert.
\newblock Mls: A large-scale multilingual dataset for speech research.
\newblock In \emph{Proc. of Interspeech}, 2020.

\bibitem[Rao et~al.(2017)Rao, Sak, and Prabhavalkar]{rao2017exploring}
K.~Rao, H.~Sak, and R.~Prabhavalkar.
\newblock Exploring architectures, data and units for streaming end-to-end
  speech recognition with rnn-transducer.
\newblock In \emph{2017 IEEE Automatic Speech Recognition and Understanding
  Workshop (ASRU)}, pages 193--199. IEEE, 2017.

\bibitem[Rasanen et~al.(2015)Rasanen, Doyle, and Frank]{rasanen2015interspeech}
O.~Rasanen, G.~Doyle, and M.~C. Frank.
\newblock Unsupervised word discovery from speech using automatic segmentation
  into syllable-like units.
\newblock In \emph{Proc. of Interspeech}, 2015.

\bibitem[Ravanelli et~al.(2018)Ravanelli, Brakel, Omologo, and
  Bengio]{ravanelli2018lgru}
M.~Ravanelli, P.~Brakel, M.~Omologo, and Y.~Bengio.
\newblock Light gated recurrent units for speech recognition.
\newblock \emph{IEEE Trans. on Emerging Topics in Comp. Intel.}, 2, 2018.

\bibitem[Ravanelli et~al.(2019)Ravanelli, Parcollet, and
  Bengio]{ravanelli2019pytorchkaldi}
M.~Ravanelli, T.~Parcollet, and Y.~Bengio.
\newblock The pytorch-kaldi speech recognition toolkit.
\newblock \emph{Proc. of ICASSP}, 2019.

\bibitem[Rivière et~al.(2020)Rivière, Joulin, Mazaré, and
  Dupoux]{rivire2020unsupervised}
M.~Rivière, A.~Joulin, P.-E. Mazaré, and E.~Dupoux.
\newblock Unsupervised pretraining transfers well across languages.
\newblock In \emph{Proc. of ICASSP}, 2020.

\bibitem[Schneider et~al.(2019)Schneider, Baevski, Collobert, and
  Auli]{schneider2019wav2vec}
S.~Schneider, A.~Baevski, R.~Collobert, and M.~Auli.
\newblock wav2vec: Unsupervised pre-training for speech recognition.
\newblock In \emph{Proc. of Interspeech}, 2019.

\bibitem[Sennrich et~al.(2015)Sennrich, Haddow, and
  Birch]{sennrich2015improving}
R.~Sennrich, B.~Haddow, and A.~Birch.
\newblock Improving neural machine translation models with monolingual data.
\newblock \emph{Proc. of ACL}, 2015.

\bibitem[Srivastava et~al.(2014)Srivastava, Hinton, Krizhevsky, Sutskever, and
  Salakhutdinov]{srivastava2014dropout}
N.~Srivastava, G.~Hinton, A.~Krizhevsky, I.~Sutskever, and R.~Salakhutdinov.
\newblock Dropout: a simple way to prevent neural networks from overfitting.
\newblock \emph{JMLR}, 2014.

\bibitem[Sutskever et~al.(2014)Sutskever, Vinyals, and
  Le]{sutskever2014sequence}
I.~Sutskever, O.~Vinyals, and Q.~V. Le.
\newblock Sequence to sequence learning with neural networks.
\newblock \emph{Proc. of NIPS}, 2014.

\bibitem[Synnaeve et~al.(2020)Synnaeve, Xu, Kahn, Likhomanenko, Grave, Pratap,
  Sriram, Liptchinsky, and Collobert]{synnaeve2020end}
G.~Synnaeve, Q.~Xu, J.~Kahn, T.~Likhomanenko, E.~Grave, V.~Pratap, A.~Sriram,
  V.~Liptchinsky, and R.~Collobert.
\newblock End-to-end {ASR}: from {Supervised} to {Semi}-{Supervised} {Learning}
  with {Modern} {Architectures}.
\newblock \emph{Proc. of ICML workshop on Self-supervision in Audio and Speech
  (SAS)}, 2020.

\bibitem[Tachbelie et~al.(2014)Tachbelie, Abate, and
  Besacier]{tachbelie2014alffa}
M.~Tachbelie, S.~T. Abate, and L.~Besacier.
\newblock Using different acoustic, lexical and language modeling units for asr
  of an under-resourced language - amharic.
\newblock \emph{Speech Communication}, 56, 2014.

\bibitem[Tan et~al.(2020)Tan, Sarkar, and Dehak]{tan_rvad}
Z.~Tan, A.~K. Sarkar, and N.~Dehak.
\newblock rvad: An unsupervised segment-based robust voice activity detection
  method.
\newblock \emph{Computer speech \& language}, 59:\penalty0 1--21, 2020.

\bibitem[Tenney et~al.(2019)Tenney, Das, and Pavlick]{tenney2019bert}
I.~Tenney, D.~Das, and E.~Pavlick.
\newblock Bert rediscovers the classical nlp pipeline.
\newblock \emph{Proc. of ACL}, 2019.

\bibitem[van~den Oord et~al.(2018)van~den Oord, Li, and Vinyals]{oord2018cpc}
A.~van~den Oord, Y.~Li, and O.~Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{Proc. of NIPS}, 2018.

\bibitem[van Niekerk et~al.(2020)van Niekerk, Nortje, and
  Kamper]{vanniekerk2020vectorquantized}
B.~van Niekerk, L.~Nortje, and H.~Kamper.
\newblock Vector-quantized neural networks for acoustic unit discovery in the
  zerospeech 2020 challenge.
\newblock \emph{Proc. of Interspeech}, 2020.

\bibitem[Varadarajan et~al.(2008)Varadarajan, Khudanpur, and
  Dupoux]{varadarajan2008unsupervised}
B.~Varadarajan, S.~Khudanpur, and E.~Dupoux.
\newblock Unsupervised learning of acoustic sub-word units.
\newblock In \emph{Proc. of ACL}, 2008.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017transformer}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  L.~Kaiser, and I.~Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{Proc. of NIPS}, 2017.

\bibitem[Vesel{\`y} et~al.(2017)Vesel{\`y}, Burget, and
  Cernock{\`y}]{vesely2017semi}
K.~Vesel{\`y}, L.~Burget, and J.~Cernock{\`y}.
\newblock Semi-supervised dnn training with word selection for asr.
\newblock In \emph{Proc. of Interspeech}, 2017.

\bibitem[Wang et~al.(2021)Wang, Wu, Pino, Baevski, Auli, and
  Conneau]{wang2021st}
C.~Wang, A.~Wu, J.~Pino, A.~Baevski, M.~Auli, and A.~Conneau.
\newblock Large-scale self- and semi-supervised learning for speech
  translation.
\newblock \emph{arXiv}, 2021.

\bibitem[Werker and Tees(1984)]{werker1984cross}
J.~F. Werker and R.~C. Tees.
\newblock Cross-language speech perception: Evidence for perceptual
  reorganization during the first year of life.
\newblock \emph{Infant behavior and development}, 7\penalty0 (1):\penalty0
  49--63, 1984.

\bibitem[Xia et~al.(2016)Xia, He, Qin, Wang, Yu, Liu, and Ma]{xia2016dual}
Y.~Xia, D.~He, T.~Qin, L.~Wang, N.~Yu, T.~Liu, and W.~Ma.
\newblock Dual learning for machine translation.
\newblock In \emph{Proc. of NeurIPS}, 2016.

\bibitem[{Xu} et~al.(2018){Xu}, {Li}, {Wang}, {Wang}, {Kang}, {Chen}, {Povey},
  and {Khudanpur}]{xu2018icassp}
H.~{Xu}, K.~{Li}, Y.~{Wang}, J.~{Wang}, S.~{Kang}, X.~{Chen}, D.~{Povey}, and
  S.~{Khudanpur}.
\newblock Neural network language modeling with letter-based features and
  importance sampling.
\newblock In \emph{Proc. of ICASSP}, 2018.

\bibitem[Xu et~al.(2020{\natexlab{a}})Xu, Baevski, Likhomanenko, Tomasello,
  Conneau, Collobert, Synnaeve, and Auli]{xu2020selftraining}
Q.~Xu, A.~Baevski, T.~Likhomanenko, P.~Tomasello, A.~Conneau, R.~Collobert,
  G.~Synnaeve, and M.~Auli.
\newblock Self-training and pre-training are complementary for speech
  recognition.
\newblock In \emph{Proc. of ICASSP}, 2020{\natexlab{a}}.

\bibitem[Xu et~al.(2020{\natexlab{b}})Xu, Likhomanenko, Kahn, Hannun, Synnaeve,
  and Collobert]{xu2020iterative}
Q.~Xu, T.~Likhomanenko, J.~Kahn, A.~Hannun, G.~Synnaeve, and R.~Collobert.
\newblock Iterative pseudo-labeling for speech recognition.
\newblock \emph{Proc. of Interspeech}, 2020{\natexlab{b}}.

\bibitem[Yeh et~al.(2019)Yeh, Chen, Yu, and Yu]{yeh2018unsupervised}
C.-K. Yeh, J.~Chen, C.~Yu, and D.~Yu.
\newblock Unsupervised speech recognition via segmental empirical output
  distribution matching.
\newblock In \emph{Proc. of ICLR}, 2019.

\bibitem[Young(1996)]{young1996large}
S.~Young.
\newblock Large vocabulary continuous speech recognition: A review.
\newblock \emph{IEEE Signal Processing Magazine}, 13\penalty0 (5):\penalty0
  45--57, 1996.

\bibitem[Zeghidour et~al.(2018)Zeghidour, Xu, Liptchinsky, Usunier, Synnaeve,
  and Collobert]{zeghidour2018w2l}
N.~Zeghidour, Q.~Xu, V.~Liptchinsky, N.~Usunier, G.~Synnaeve, and R.~Collobert.
\newblock Fully convolutional speech recognition.
\newblock \emph{arXiv}, abs/1812.06864, 2018.

\bibitem[Zeyer et~al.(2017)Zeyer, Beck, Schl{\"u}ter, and Ney]{zeyer2017ctc}
A.~Zeyer, E.~Beck, R.~Schl{\"u}ter, and H.~Ney.
\newblock Ctc in the context of generalized full-sum hmm training.
\newblock In \emph{Proc. of Interspeech}, 2017.

\bibitem[Zhang et~al.(2020{\natexlab{a}})Zhang, Wang, Zhang, Liu, Saraf, and
  Zweig]{zhang2020faster}
F.~Zhang, Y.~Wang, X.~Zhang, C.~Liu, Y.~Saraf, and G.~Zweig.
\newblock Faster, simpler and more accurate hybrid asr systems using
  wordpieces.
\newblock \emph{Proc. of Interspeech}, 2020{\natexlab{a}}.

\bibitem[Zhang and Glass(2009)]{zhang2009unsupervised}
Y.~Zhang and J.~R. Glass.
\newblock Unsupervised spoken keyword spotting via segmental dtw on gaussian
  posteriorgrams.
\newblock \emph{IEEE Workshop on Automatic Speech Recognition \&
  Understanding}, 2009.

\bibitem[Zhang et~al.(2020{\natexlab{b}})Zhang, Qin, Park, Han, Chiu, Pang, Le,
  and Wu]{zhang2020pushing}
Y.~Zhang, J.~Qin, D.~S. Park, W.~Han, C.-C. Chiu, R.~Pang, Q.~V. Le, and Y.~Wu.
\newblock Pushing the limits of semi-supervised learning for automatic speech
  recognition.
\newblock \emph{Proc. of NeurIPS SAS Workshop}, 2020{\natexlab{b}}.

\end{thebibliography}
