\begin{thebibliography}{22}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Akiyama \& Nakashima(2014)Akiyama and Nakashima]{Akiyama2014}
Akiyama, Hidehisa and Nakashima, Tomoharu.
\newblock Helios base: An open source package for the robocup soccer 2d
  simulation.
\newblock In \emph{RoboCup 2013: Robot World Cup XVII}, pp.\  528--535.
  Springer, 2014.

\bibitem[Ammar et~al.(2015)Ammar, Tutunov, and Eaton]{Ammar2015}
Ammar, Haitham~Bou, Tutunov, Rasul, and Eaton, Eric.
\newblock Safe policy search for lifelong reinforcement learning with sublinear
  regret.
\newblock \emph{arXiv preprint arXiv:1505.05798}, 2015.

\bibitem[Bacon \& Precup(2015)Bacon and Precup]{Bacon2015}
Bacon, Pierre-Luc and Precup, Doina.
\newblock The option-critic architecture.
\newblock In \emph{NIPS Deep Reinforcement Learning Workshop}, 2015.

\bibitem[Bai et~al.(2012)Bai, Wu, and Chen]{Bai2012}
Bai, Aijun, Wu, Feng, and Chen, Xiaoping.
\newblock Online planning for large mdps with maxq decomposition.
\newblock In \emph{AAMAS}, 2012.

\bibitem[da~Silva et~al.(2012)da~Silva, Konidaris, and Barto]{daSilva2012}
da~Silva, B.C., Konidaris, G.D., and Barto, A.G.
\newblock Learning parameterized skills.
\newblock In \emph{ICML}, 2012.

\bibitem[Eaton \& Ruvolo(2013)Eaton and Ruvolo]{Eaton2013}
Eaton, Eric and Ruvolo, Paul~L.
\newblock Ella: An efficient lifelong learning algorithm.
\newblock In \emph{Proceedings of the 30th international conference on machine
  learning (ICML-13)}, pp.\  507--515, 2013.

\bibitem[Fu et~al.(2015)Fu, Levine, and Abbeel]{Fu2015}
Fu, Justin, Levine, Sergey, and Abbeel, Pieter.
\newblock One-shot learning of manipulation skills with online dynamics
  adaptation and neural network priors.
\newblock \emph{arXiv preprint arXiv:1509.06841}, 2015.

\bibitem[Hausknecht \& Stone(2015)Hausknecht and Stone]{Hausknecht2015}
Hausknecht, Matthew and Stone, Peter.
\newblock Deep reinforcement learning in parameterized action space.
\newblock \emph{arXiv preprint arXiv:1511.04143}, 2015.

\bibitem[Hauskrecht(1998)]{Hauskrecht1998}
Hauskrecht, Milos, Meuleau Nicolas et.~al.
\newblock Hierarchical solution of markov decision processes using
  macro-actions.
\newblock In \emph{UAI}, pp.\  220--229, 1998.

\bibitem[Konidaris \& Barto(2009)Konidaris and Barto]{Konidaris2009}
Konidaris, George and Barto, Andrew~G.
\newblock Skill discovery in continuous reinforcement learning domains using
  skill chaining.
\newblock In \emph{NIPS}, 2009.

\bibitem[Mankowitz et~al.(2014)Mankowitz, Mann, and Mannor]{Mann2014b}
Mankowitz, Daniel~J, Mann, Timothy~A, and Mannor, Shie.
\newblock Time regularized interrupting options.
\newblock \emph{Internation Conference on Machine Learning}, 2014.

\bibitem[Mann \& Mannor(2014)Mann and Mannor]{Mann2014a}
Mann, Timothy~A and Mannor, Shie.
\newblock Scaling up approximate value iteration with options: Better policies
  with fewer iterations.
\newblock In \emph{Proceedings of the $\mathit{31}^{st}$ International
  Conference on Machine Learning}, 2014.

\bibitem[Mann et~al.(2015)Mann, Mankowitz, and Mannor]{Mann2015}
Mann, Timothy~Arthur, Mankowitz, Daniel~J, and Mannor, Shie.
\newblock Learning when to switch between skills in a high dimensional domain.
\newblock In \emph{AAAI Workshop}, 2015.

\bibitem[Masson \& Konidaris(2015)Masson and Konidaris]{Masson2015}
Masson, Warwick and Konidaris, George.
\newblock Reinforcement learning with parameterized actions.
\newblock \emph{arXiv preprint arXiv:1509.01644}, 2015.

\bibitem[Peters \& Schaal(2006)Peters and Schaal]{Peters2006}
Peters, Jan and Schaal, Stefan.
\newblock Policy gradient methods for robotics.
\newblock In \emph{Intelligent Robots and Systems, 2006 IEEE/RSJ International
  Conference on}, pp.\  2219--2225. IEEE, 2006.

\bibitem[Peters \& Schaal(2008)Peters and Schaal]{Peters2008}
Peters, Jan and Schaal, Stefan.
\newblock {Reinforcement learning of motor skills with policy gradients}.
\newblock \emph{Neural Networks}, 21:\penalty0 682--691, 2008.

\bibitem[Precup \& Sutton(1997)Precup and Sutton]{Precup1997}
Precup, Doina and Sutton, Richard~S.
\newblock Multi-time models for temporally abstract planning.
\newblock In \emph{Advances in Neural Information Processing Systems 10
  (Proceedings of NIPS'97)}, 1997.

\bibitem[Precup et~al.(1998)Precup, Sutton, and Singh]{Precup1998}
Precup, Doina, Sutton, Richard~S, and Singh, Satinder.
\newblock Theoretical results on reinforcement learning with temporally
  abstract options.
\newblock In \emph{Machine Learning: ECML-98}, pp.\  382--393. Springer, 1998.

\bibitem[Silver \& Ciosek(2012)Silver and Ciosek]{Silver2012}
Silver, David and Ciosek, Kamil.
\newblock {Compositional Planning Using Optimal Option Models}.
\newblock In \emph{Proceedings of the 29th International Conference on Machine
  Learning}, Edinburgh, 2012.

\bibitem[Sutton et~al.(1999)Sutton, Precup, and Singh]{Sutton1999}
Sutton, Richard~S, Precup, Doina, and Singh, Satinder.
\newblock {Between MDPs and semi-MDPs: A framework for temporal abstraction in
  reinforcement learning}.
\newblock \emph{Artificial Intelligence}, 1999.

\bibitem[Sutton et~al.(2000)Sutton, McAllester, Singh, and Mansour]{Sutton2000}
Sutton, Richard~S, McAllester, David, Singh, Satindar, and Mansour, Yishay.
\newblock Policy gradient methods for reinforcement learning with function
  approximation.
\newblock In \emph{NIPS}, pp.\  1057--1063, 2000.

\bibitem[Thrun \& Mitchell(1995)Thrun and Mitchell]{Thrun1995}
Thrun, Sebastian and Mitchell, Tom~M.
\newblock \emph{Lifelong robot learning}.
\newblock Springer, 1995.

\end{thebibliography}
