\begin{thebibliography}{103}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.(2016)Abadi, Chu, Goodfellow, McMahan, Mironov, Talwar, and Zhang]{abadi2016deep}
Abadi, M., Chu, A., Goodfellow, I., McMahan, H.~B., Mironov, I., Talwar, K., and Zhang, L.
\newblock Deep learning with differential privacy.
\newblock In \emph{Proceedings of the 2016 ACM SIGSAC conference on computer and communications security}, pp.\  308--318, 2016.

\bibitem[Ali et~al.(2023)Ali, Kleindessner, Wenzel, Budhathoki, Cevher, and Russell]{ali2023evaluating}
Ali, J., Kleindessner, M., Wenzel, F., Budhathoki, K., Cevher, V., and Russell, C.
\newblock Evaluating the fairness of discriminative foundation models in computer vision.
\newblock In \emph{Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society}, pp.\  809--833, 2023.

\bibitem[Allman(2013)]{allman2013sociology}
Allman, D.
\newblock The sociology of social inclusion.
\newblock \emph{Sage Open}, 3\penalty0 (1):\penalty0 2158244012471957, 2013.

\bibitem[Arjovsky et~al.(2019)Arjovsky, Bottou, Gulrajani, and Lopez-Paz]{arjovsky2019invariant}
Arjovsky, M., Bottou, L., Gulrajani, I., and Lopez-Paz, D.
\newblock Invariant risk minimization.
\newblock \emph{arXiv preprint arXiv:1907.02893}, 2019.

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and Wagner]{athalye2018obfuscated}
Athalye, A., Carlini, N., and Wagner, D.
\newblock Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples.
\newblock \emph{arXiv preprint arXiv:1802.00420}, 2018.

\bibitem[Bagdasaryan et~al.(2019)Bagdasaryan, Poursaeed, and Shmatikov]{bagdasaryan2019differential}
Bagdasaryan, E., Poursaeed, O., and Shmatikov, V.
\newblock Differential privacy has disparate impact on model accuracy.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Bai et~al.(2022)Bai, Jones, Ndousse, Askell, Chen, DasSarma, Drain, Fort, Ganguli, Henighan, et~al.]{bai2022training}
Bai, Y., Jones, A., Ndousse, K., Askell, A., Chen, A., DasSarma, N., Drain, D., Fort, S., Ganguli, D., Henighan, T., et~al.
\newblock Training a helpful and harmless assistant with reinforcement learning from human feedback.
\newblock \emph{arXiv preprint arXiv:2204.05862}, 2022.

\bibitem[Bengio et~al.(2013)Bengio, Courville, and Vincent]{bengio2013representation}
Bengio, Y., Courville, A., and Vincent, P.
\newblock Representation learning: A review and new perspectives.
\newblock \emph{IEEE transactions on pattern analysis and machine intelligence}, 35\penalty0 (8):\penalty0 1798--1828, 2013.

\bibitem[Benkler et~al.(2023)Benkler, Mosaphir, Friedman, Smart, and Schmer-Galunder]{benkler2023assessing}
Benkler, N., Mosaphir, D., Friedman, S., Smart, A., and Schmer-Galunder, S.
\newblock Assessing llms for moral value pluralism.
\newblock \emph{arXiv preprint arXiv:2312.10075}, 2023.

\bibitem[Beutel et~al.(2017)Beutel, Chen, Zhao, and Chi]{beutel2017data}
Beutel, A., Chen, J., Zhao, Z., and Chi, E.~H.
\newblock Data decisions and theoretical implications when adversarially learning fair representations.
\newblock \emph{arXiv preprint arXiv:1707.00075}, 2017.

\bibitem[Black et~al.(2022)Black, Raghavan, and Barocas]{black2022model}
Black, E., Raghavan, M., and Barocas, S.
\newblock Model multiplicity: Opportunities, concerns, and solutions.
\newblock In \emph{Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency}, pp.\  850--863, 2022.

\bibitem[Blodgett et~al.(2020)Blodgett, Barocas, Daum{\'e}~III, and Wallach]{blodgett2020language}
Blodgett, S.~L., Barocas, S., Daum{\'e}~III, H., and Wallach, H.
\newblock Language (technology) is power: A critical survey of" bias" in nlp.
\newblock \emph{arXiv preprint arXiv:2005.14050}, 2020.

\bibitem[Blodgett et~al.(2021)Blodgett, Lopez, Olteanu, Sim, and Wallach]{blodgett2021stereotyping}
Blodgett, S.~L., Lopez, G., Olteanu, A., Sim, R., and Wallach, H.
\newblock Stereotyping norwegian salmon: An inventory of pitfalls in fairness benchmark datasets.
\newblock In \emph{Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)}, pp.\  1004--1015, 2021.

\bibitem[Bolukbasi et~al.(2016)Bolukbasi, Chang, Zou, Saligrama, and Kalai]{bolukbasi2016man}
Bolukbasi, T., Chang, K.-W., Zou, J., Saligrama, V., and Kalai, A.~T.
\newblock Man is to computer programmer as woman is to homemaker? debiasing word embeddings.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.~D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 1877--1901, 2020.

\bibitem[Buolamwini \& Gebru(2018)Buolamwini and Gebru]{buolamwini2018gender}
Buolamwini, J. and Gebru, T.
\newblock Gender shades: Intersectional accuracy disparities in commercial gender classification.
\newblock In \emph{Conference on fairness, accountability and transparency}, pp.\  77--91. PMLR, 2018.

\bibitem[Carlini \& Wagner(2018)Carlini and Wagner]{carlini2018audio}
Carlini, N. and Wagner, D.
\newblock Audio adversarial examples: Targeted attacks on speech-to-text.
\newblock \emph{arXiv preprint arXiv:1801.01944}, 2018.

\bibitem[Carlini et~al.(2022{\natexlab{a}})Carlini, Ippolito, Jagielski, Lee, Tramer, and Zhang]{carlini2022quantifying}
Carlini, N., Ippolito, D., Jagielski, M., Lee, K., Tramer, F., and Zhang, C.
\newblock Quantifying memorization across neural language models.
\newblock \emph{arXiv preprint arXiv:2202.07646}, 2022{\natexlab{a}}.

\bibitem[Carlini et~al.(2022{\natexlab{b}})Carlini, Jagielski, Zhang, Papernot, Terzis, and Tramer]{carlini2022privacy}
Carlini, N., Jagielski, M., Zhang, C., Papernot, N., Terzis, A., and Tramer, F.
\newblock The privacy onion effect: Memorization is relative.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 13263--13276, 2022{\natexlab{b}}.

\bibitem[Cohen et~al.(2018)Cohen, Luck, and Honari]{cohen2018distribution}
Cohen, J.~P., Luck, M., and Honari, S.
\newblock Distribution matching losses can hallucinate features in medical image translation.
\newblock In \emph{Medical Image Computing and Computer Assisted Intervention--MICCAI 2018: 21st International Conference, Granada, Spain, September 16-20, 2018, Proceedings, Part I}, pp.\  529--536. Springer, 2018.

\bibitem[D'Amour et~al.(2022)D'Amour, Heller, Moldovan, Adlam, Alipanahi, Beutel, Chen, Deaton, Eisenstein, Hoffman, et~al.]{d2022underspecification}
D'Amour, A., Heller, K., Moldovan, D., Adlam, B., Alipanahi, B., Beutel, A., Chen, C., Deaton, J., Eisenstein, J., Hoffman, M.~D., et~al.
\newblock Underspecification presents challenges for credibility in modern machine learning.
\newblock \emph{Journal of Machine Learning Research}, 23\penalty0 (226):\penalty0 1--61, 2022.

\bibitem[Deshpande et~al.(2023)Deshpande, Murahari, Rajpurohit, Kalyan, and Narasimhan]{deshpande2023toxicity}
Deshpande, A., Murahari, V., Rajpurohit, T., Kalyan, A., and Narasimhan, K.
\newblock Toxicity in chatgpt: Analyzing persona-assigned language models.
\newblock \emph{arXiv preprint arXiv:2304.05335}, 2023.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Dodge et~al.(2020)Dodge, Ilharco, Schwartz, Farhadi, Hajishirzi, and Smith]{dodge2020fine}
Dodge, J., Ilharco, G., Schwartz, R., Farhadi, A., Hajishirzi, H., and Smith, N.
\newblock Fine-tuning pretrained language models: Weight initializations, data orders, and early stopping.
\newblock \emph{arXiv preprint arXiv:2002.06305}, 2020.

\bibitem[Du et~al.(2020)Du, Yang, Zou, and Hu]{du2020fairness}
Du, M., Yang, F., Zou, N., and Hu, X.
\newblock Fairness in deep learning: A computational perspective.
\newblock \emph{IEEE Intelligent Systems}, 36\penalty0 (4):\penalty0 25--34, 2020.

\bibitem[Dwivedi et~al.(2023)Dwivedi, Ghosh, and Dwivedi]{dwivedi2023breaking}
Dwivedi, S., Ghosh, S., and Dwivedi, S.
\newblock Breaking the bias: Gender fairness in llms using prompt engineering and in-context learning.
\newblock \emph{Rupkatha Journal on Interdisciplinary Studies in Humanities}, 15\penalty0 (4), 2023.

\bibitem[Dwork et~al.(2018)Dwork, Immorlica, Kalai, and Leiserson]{dwork2018decoupled}
Dwork, C., Immorlica, N., Kalai, A.~T., and Leiserson, M.
\newblock Decoupled classifiers for group-fair and efficient machine learning.
\newblock In \emph{Conference on fairness, accountability and transparency}, pp.\  119--133. PMLR, 2018.

\bibitem[Dziri et~al.(2022)Dziri, Milton, Yu, Zaiane, and Reddy]{dziri2022origin}
Dziri, N., Milton, S., Yu, M., Zaiane, O., and Reddy, S.
\newblock On the origin of hallucinations in conversational models: Is it the datasets or the models?
\newblock \emph{arXiv preprint arXiv:2204.07931}, 2022.

\bibitem[Fedus et~al.(2022)Fedus, Zoph, and Shazeer]{fedus2022switch}
Fedus, W., Zoph, B., and Shazeer, N.
\newblock Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity.
\newblock \emph{The Journal of Machine Learning Research}, 23\penalty0 (1):\penalty0 5232--5270, 2022.

\bibitem[Gallegos et~al.(2023)Gallegos, Rossi, Barrow, Tanjim, Kim, Dernoncourt, Yu, Zhang, and Ahmed]{gallegos2023bias}
Gallegos, I.~O., Rossi, R.~A., Barrow, J., Tanjim, M.~M., Kim, S., Dernoncourt, F., Yu, T., Zhang, R., and Ahmed, N.~K.
\newblock Bias and fairness in large language models: A survey.
\newblock \emph{arXiv preprint arXiv:2309.00770}, 2023.

\bibitem[Ganesh(2024)]{ganesh2024empirical}
Ganesh, P.
\newblock An empirical investigation into benchmarking model multiplicity for trustworthy machine learning: A case study on image classification.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, pp.\  4488--4497, 2024.

\bibitem[Ganesh et~al.(2023)Ganesh, Chang, Strobel, and Shokri]{ganesh2023impact}
Ganesh, P., Chang, H., Strobel, M., and Shokri, R.
\newblock On the impact of machine learning randomness on group fairness.
\newblock In \emph{Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency}, pp.\  1789--1800, 2023.

\bibitem[Gardner et~al.(2020)Gardner, Artzi, Basmova, Berant, Bogin, Chen, Dasigi, Dua, Elazar, Gottumukkala, et~al.]{gardner2020evaluating}
Gardner, M., Artzi, Y., Basmova, V., Berant, J., Bogin, B., Chen, S., Dasigi, P., Dua, D., Elazar, Y., Gottumukkala, A., et~al.
\newblock Evaluating models' local decision boundaries via contrast sets.
\newblock \emph{arXiv preprint arXiv:2004.02709}, 2020.

\bibitem[Ghosh et~al.(2019)Ghosh, Hong, Yin, and Ramchandran]{ghosh2019robust}
Ghosh, A., Hong, J., Yin, D., and Ramchandran, K.
\newblock Robust federated learning in a heterogeneous environment.
\newblock \emph{arXiv preprint arXiv:1906.06629}, 2019.

\bibitem[Gorban \& Tyukin(2018)Gorban and Tyukin]{gorban2018blessing}
Gorban, A.~N. and Tyukin, I.~Y.
\newblock Blessing of dimensionality: mathematical foundations of the statistical physics of data.
\newblock \emph{Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences}, 376\penalty0 (2118):\penalty0 20170237, 2018.

\bibitem[Gordon et~al.(2023)Gordon, Dujmovic, Izacard, Riedel, and Srinivasan]{gordon2023morphing}
Gordon, A., Dujmovic, J., Izacard, G., Riedel, S., and Srinivasan, K.
\newblock Morphing transformers for fine-tuning massive language models with minimal effort.
\newblock \emph{arXiv preprint arXiv:2302.03102}, 2023.

\bibitem[Guo et~al.(2018)Guo, Rana, Cisse, and Robby]{guo2018deep}
Guo, C., Rana, M., Cisse, M., and Robby.
\newblock Deep counterfeit: A black-box attack against autonomous driving models.
\newblock \emph{arXiv preprint arXiv:1801.10578}, 2018.

\bibitem[Gupta et~al.(2022)Gupta, Kassner, and Sch{\"u}tze]{gupta2022how}
Gupta, P., Kassner, N., and Sch{\"u}tze, H.
\newblock How gender debiasing affects internal model representations, and why it matters.
\newblock \emph{arXiv preprint arXiv:2204.06827}, 2022.
\newblock URL \url{https://arxiv.org/abs/2204.06827}.

\bibitem[Hall et~al.(2023)Hall, Gustafson, Adcock, Misra, and Ross]{hall2023vision}
Hall, M., Gustafson, L., Adcock, A., Misra, I., and Ross, C.
\newblock Vision-language models performing zero-shot tasks exhibit disparities between gender groups.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  2778--2785, 2023.

\bibitem[Hardt et~al.(2016)Hardt, Price, and Srebro]{hardt2016equality}
Hardt, M., Price, E., and Srebro, N.
\newblock Equality of opportunity in supervised learning.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Hargittai(2011)]{hargittai2011minding}
Hargittai, E.
\newblock Minding the digital gap: Why understanding digital inequality matters.
\newblock In \emph{Media perspectives for the 21st century}, pp.\  231--240. Routledge, 2011.

\bibitem[Hashemizadeh et~al.(2023)Hashemizadeh, Ramirez, Sukumaran, Farnadi, Lacoste-Julien, and Gallego-Posada]{hashemizadeh2023balancing}
Hashemizadeh, M., Ramirez, J., Sukumaran, R., Farnadi, G., Lacoste-Julien, S., and Gallego-Posada, J.
\newblock Balancing act: Constraining disparate impact in sparse models.
\newblock \emph{arXiv preprint arXiv:2310.20673}, 2023.

\bibitem[Hemmat et~al.(2023)Hemmat, Pezeshki, Bordes, Drozdzal, and Romero-Soriano]{hemmat2023feedback}
Hemmat, R.~A., Pezeshki, M., Bordes, F., Drozdzal, M., and Romero-Soriano, A.
\newblock Feedback-guided data synthesis for imbalanced classification.
\newblock \emph{arXiv preprint arXiv:2310.00158}, 2023.

\bibitem[Holzinger et~al.(2016)Holzinger, Plass, Kickmeier-Rust, Holzinger, Crişan, Pintea, and Palade]{holzinger2016interactive}
Holzinger, A., Plass, M., Kickmeier-Rust, M., Holzinger, K., Crişan, G.~C., Pintea, C.-M., and Palade, V.
\newblock Interactive machine learning for health informatics: when do we need the human-in-the-loop?
\newblock \emph{Brain Informatics}, 3\penalty0 (2):\penalty0 119--131, 2016.

\bibitem[Hooker(2021)]{hooker2021moving}
Hooker, S.
\newblock Moving beyond “algorithmic bias is a data problem”.
\newblock \emph{Patterns}, 2\penalty0 (4), 2021.

\bibitem[Hooker et~al.(2019)Hooker, Courville, Clark, Dauphin, and Frome]{hooker2019compressed}
Hooker, S., Courville, A., Clark, G., Dauphin, Y., and Frome, A.
\newblock What do compressed deep neural networks forget?
\newblock \emph{arXiv preprint arXiv:1911.05248}, 2019.

\bibitem[Hooker et~al.(2020)Hooker, Moorosi, Clark, Bengio, and Denton]{hooker2020characterising}
Hooker, S., Moorosi, N., Clark, G., Bengio, S., and Denton, E.
\newblock Characterising bias in compressed models.
\newblock \emph{arXiv preprint arXiv:2010.03058}, 2020.

\bibitem[Hu et~al.(2021)Hu, Shen, Wallis, Neubig, Riloff, and Brunk]{hu2021lora}
Hu, E.~J., Shen, Y., Wallis, P., Neubig, G., Riloff, E., and Brunk, M.
\newblock Lora: Low-rank adaptation of large language models.
\newblock \emph{arXiv preprint arXiv:2106.09685}, 2021.

\bibitem[Jha et~al.(2024)Jha, Prabhakaran, Denton, Laszlo, Dave, Qadri, Reddy, and Dev]{jha2024beyond}
Jha, A., Prabhakaran, V., Denton, R., Laszlo, S., Dave, S., Qadri, R., Reddy, C.~K., and Dev, S.
\newblock Beyond the surface: A global-scale analysis of visual stereotypes in text-to-image generation.
\newblock \emph{arXiv preprint arXiv:2401.06310}, 2024.

\bibitem[Ji et~al.(2023)Ji, Lee, Frieske, Yu, Su, Xu, Ishii, Bang, Madotto, and Fung]{ji2023survey}
Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y.~J., Madotto, A., and Fung, P.
\newblock Survey of hallucination in natural language generation.
\newblock \emph{ACM Computing Surveys}, 55\penalty0 (12):\penalty0 1--38, 2023.

\bibitem[Jiang et~al.(2020)Jiang, Zhang, Talwar, and Mozer]{jiang2020characterizing}
Jiang, Z., Zhang, C., Talwar, K., and Mozer, M.~C.
\newblock Characterizing structural regularities of labeled data in overparameterized models.
\newblock \emph{arXiv preprint arXiv:2002.03206}, 2020.

\bibitem[Kiela et~al.(2022)Kiela, Foka, Aktas, Lin, Baudia, and Celikyilmaz]{kiela2022evaluating}
Kiela, D., Foka, P., Aktas, O.~S., Lin, M. Y.-J., Baudia, P., and Celikyilmaz, A.
\newblock Evaluating bias and fairness in gender-neutral pretrained vision-and-language models.
\newblock In \emph{15th International Conference on Language Resources and Evaluation}, 2022.

\bibitem[Kirkpatrick et~al.(2017)Kirkpatrick, Pascanu, Rabinowitz, Veness, Desjardins, Rusu, Milan, Quan, Ramalho, Grabska-Barwinska, et~al.]{kirkpatrick2017overcoming}
Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A.~A., Milan, K., Quan, J., Ramalho, T., Grabska-Barwinska, A., et~al.
\newblock Overcoming catastrophic forgetting in neural networks.
\newblock \emph{Proceedings of the national academy of sciences}, 114\penalty0 (13):\penalty0 3521--3526, 2017.

\bibitem[Lee et~al.(2023)Lee, Phatale, Mansoor, Lu, Mesnard, Bishop, Carbune, and Rastogi]{lee2023rlaif}
Lee, H., Phatale, S., Mansoor, H., Lu, K., Mesnard, T., Bishop, C., Carbune, V., and Rastogi, A.
\newblock Rlaif: Scaling reinforcement learning from human feedback with ai feedback.
\newblock \emph{arXiv preprint arXiv:2309.00267}, 2023.

\bibitem[Liang et~al.(2021)Liang, Wu, Morency, and Salakhutdinov]{liang2021towards}
Liang, P.~P., Wu, C., Morency, L.-P., and Salakhutdinov, R.
\newblock Towards understanding and mitigating social biases in language models.
\newblock In \emph{International Conference on Machine Learning}, pp.\  6565--6576. PMLR, 2021.

\bibitem[Luccioni et~al.(2023)Luccioni, Akiki, Mitchell, and Jernite]{luccioni2023stable}
Luccioni, A.~S., Akiki, C., Mitchell, M., and Jernite, Y.
\newblock Stable bias: Analyzing societal representations in diffusion models.
\newblock \emph{arXiv preprint arXiv:2303.11408}, 2023.

\bibitem[Luo et~al.(2023)Luo, Yang, Meng, Li, Zhou, and Zhang]{luo2023empirical}
Luo, Y., Yang, Z., Meng, F., Li, Y., Zhou, J., and Zhang, Y.
\newblock An empirical study of catastrophic forgetting in large language models during continual fine-tuning.
\newblock \emph{arXiv preprint arXiv:2308.08747}, 2023.

\bibitem[Ma et~al.(2022)Ma, Wang, and Liu]{ma2022tradeoff}
Ma, X., Wang, Z., and Liu, W.
\newblock On the tradeoff between robustness and fairness.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 26230--26241, 2022.

\bibitem[Madry et~al.(2017)Madry, Makelov, Schmidt, Tsipras, and Vladu]{madry2017towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock \emph{arXiv preprint arXiv:1706.06083}, 2017.

\bibitem[Maene et~al.(2021)Maene, Li, and Moens]{maene2021towards}
Maene, J., Li, M., and Moens, M.-F.
\newblock Towards understanding iterative magnitude pruning: Why lottery tickets win.
\newblock \emph{arXiv preprint arXiv:2106.06955}, 2021.

\bibitem[Malekmohammadi et~al.(2024)Malekmohammadi, Taik, and Farnadi]{malekmohammadi2024mitigating}
Malekmohammadi, S., Taik, A., and Farnadi, G.
\newblock Mitigating disparate impact of differential privacy in federated learning through robust clustering.
\newblock \emph{arXiv preprint arXiv:2405.19272}, 2024.

\bibitem[Mao et~al.(2023)Mao, Deng, Yao, Ye, Kawaguchi, and Zou]{mao2023last}
Mao, Y., Deng, Z., Yao, H., Ye, T., Kawaguchi, K., and Zou, J.
\newblock Last-layer fairness fine-tuning is simple and effective for neural networks.
\newblock \emph{arXiv preprint arXiv:2304.03935}, 2023.

\bibitem[McMahan et~al.(2017)McMahan, Moore, Ramage, Hampson, and y~Arcas]{mcmahan2017communication}
McMahan, B., Moore, E., Ramage, D., Hampson, S., and y~Arcas, B.~A.
\newblock Communication-efficient learning of deep networks from decentralized data.
\newblock \emph{Artificial Intelligence and Statistics}, pp.\  1273--1282, 2017.

\bibitem[Mehrabi et~al.(2021)Mehrabi, Morstatter, Saxena, Lerman, and Galstyan]{mehrabi2021survey}
Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., and Galstyan, A.
\newblock A survey on bias and fairness in machine learning.
\newblock \emph{ACM Computing Surveys (CSUR)}, 54\penalty0 (6):\penalty0 1--35, 2021.

\bibitem[Melas-Kyriazi(2020)]{melas2020mathematical}
Melas-Kyriazi, L.
\newblock The mathematical foundations of manifold learning.
\newblock \emph{arXiv preprint arXiv:2011.01307}, 2020.

\bibitem[Mohanty et~al.(2022)Mohanty, Serdyukov, Petrov, and Nadeem]{mohanty2022do}
Mohanty, S., Serdyukov, P., Petrov, D., and Nadeem, M.
\newblock Do transformer modifications transfer across implementations and applications?
\newblock \emph{arXiv preprint arXiv:2204.01717}, 2022.

\bibitem[Molamohammadi et~al.(2023)Molamohammadi, Ta{\"\i}k, Le~Roux, and Farnadi]{molamohammadi2023unraveling}
Molamohammadi, M., Ta{\"\i}k, A., Le~Roux, N., and Farnadi, G.
\newblock Unraveling the interconnected axes of heterogeneity in machine learning for democratic and inclusive advancements.
\newblock In \emph{Proceedings of the 3rd ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization}, pp.\  1--12, 2023.

\bibitem[Moradi \& Farnadi(2023)Moradi and Farnadi]{moradi2023tidying}
Moradi, A. and Farnadi, G.
\newblock Tidying up the conversational recommender systems' biases.
\newblock \emph{arXiv preprint arXiv:2309.02550}, 2023.

\bibitem[Nadeem et~al.(2020)Nadeem, Bethke, and Reddy]{nadeem2020stereoset}
Nadeem, M., Bethke, A., and Reddy, S.
\newblock Stereoset: Measuring stereotypical bias in pretrained language models.
\newblock \emph{arXiv preprint arXiv:2004.09456}, 2020.

\bibitem[Natekar \& Sharma(2020)Natekar and Sharma]{natekar2020representation}
Natekar, P. and Sharma, M.
\newblock Representation based complexity measures for predicting generalization in deep learning.
\newblock \emph{arXiv preprint arXiv:2012.02775}, 2020.

\bibitem[Olteanu et~al.(2019)Olteanu, Castillo, Diaz, and K{\i}c{\i}man]{olteanu2019social}
Olteanu, A., Castillo, C., Diaz, F., and K{\i}c{\i}man, E.
\newblock Social data: Biases, methodological pitfalls, and ethical boundaries.
\newblock \emph{Frontiers in big data}, 2:\penalty0 13, 2019.

\bibitem[Passi \& Barocas(2019)Passi and Barocas]{passi2019problem}
Passi, S. and Barocas, S.
\newblock Problem formulation and fairness.
\newblock In \emph{Proceedings of the conference on fairness, accountability, and transparency}, pp.\  39--48, 2019.

\bibitem[Pedreschi et~al.(2009)Pedreschi, Ruggieri, and Turini]{pedreschi2009measuring}
Pedreschi, D., Ruggieri, S., and Turini, F.
\newblock Measuring discrimination in socially-sensitive decision records.
\newblock In \emph{Proceedings of the 2009 SIAM international conference on data mining}, pp.\  581--592. SIAM, 2009.

\bibitem[Prates et~al.(2020)Prates, Avelar, and Lamb]{prates2020assessing}
Prates, M.~O., Avelar, P.~H., and Lamb, L.~C.
\newblock Assessing gender bias in machine translation: a case study with google translate.
\newblock \emph{Neural Computing and Applications}, 32:\penalty0 6363--6381, 2020.

\bibitem[Qadri et~al.(2023)Qadri, Shelby, Bennett, and Denton]{qadri2023ai}
Qadri, R., Shelby, R., Bennett, C.~L., and Denton, E.
\newblock Ai’s regimes of representation: A community-centered study of text-to-image models in south asia.
\newblock In \emph{Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency}, pp.\  506--517, 2023.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, Sutskever, et~al.]{radford2019language}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et~al.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI blog}, 1\penalty0 (8):\penalty0 9, 2019.

\bibitem[Rao et~al.(2023)Rao, Khandelwal, Tanmay, Agarwal, and Choudhury]{rao2023ethical}
Rao, A., Khandelwal, A., Tanmay, K., Agarwal, U., and Choudhury, M.
\newblock Ethical reasoning over moral alignment: A case and framework for in-context ethical policies in llms.
\newblock \emph{arXiv preprint arXiv:2310.07251}, 2023.

\bibitem[Ravi \& Beatson(2018)Ravi and Beatson]{ravi2018amortized}
Ravi, S. and Beatson, A.
\newblock Amortized bayesian meta-learning.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Richardson et~al.(2019)Richardson, Schultz, and Crawford]{richardson2019dirty}
Richardson, R., Schultz, J.~M., and Crawford, K.
\newblock Dirty data, bad predictions: How civil rights violations impact police data, predictive policing systems, and justice.
\newblock \emph{NYUL Rev. Online}, 94:\penalty0 15, 2019.

\bibitem[Samory et~al.(2021)Samory, Sen, Kohne, Fl{\"o}ck, and Wagner]{samory2021call}
Samory, M., Sen, I., Kohne, J., Fl{\"o}ck, F., and Wagner, C.
\newblock “call me sexist, but...”: Revisiting sexism detection using psychological scales and adversarial samples.
\newblock In \emph{Proceedings of the international AAAI conference on web and social media}, volume~15, pp.\  573--584, 2021.

\bibitem[Scherrer et~al.(2023)Scherrer, Shi, Feder, and Blei]{scherrer2023evaluating}
Scherrer, N., Shi, C., Feder, A., and Blei, D.~M.
\newblock Evaluating the moral beliefs encoded in llms.
\newblock \emph{arXiv preprint arXiv:2307.14324}, 2023.

\bibitem[Schwemmer et~al.(2020)Schwemmer, Knight, Bello-Pardo, Oklobdzija, Schoonvelde, and Lockhart]{schwemmer2020diagnosing}
Schwemmer, C., Knight, C., Bello-Pardo, E.~D., Oklobdzija, S., Schoonvelde, M., and Lockhart, J.~W.
\newblock Diagnosing gender bias in image recognition systems.
\newblock \emph{Socius}, 6:\penalty0 2378023120967171, 2020.

\bibitem[Sen et~al.(2022)Sen, Samory, Wagner, and Augenstein]{sen2022counterfactually}
Sen, I., Samory, M., Wagner, C., and Augenstein, I.
\newblock Counterfactually augmented data and unintended bias: The case of sexism and hate speech detection.
\newblock \emph{arXiv preprint arXiv:2205.04238}, 2022.

\bibitem[Stafanovi{\v{c}}s et~al.(2022)Stafanovi{\v{c}}s, Grundkiewicz, and Sch{\"u}tze]{stafanovics2022mitigating}
Stafanovi{\v{c}}s, T., Grundkiewicz, R., and Sch{\"u}tze, H.
\newblock Mitigating gender bias in neural machine translation with target-side monolingual data.
\newblock In \emph{Findings of the Association for Computational Linguistics: ACL 2022}, pp.\  1798--1811, 2022.

\bibitem[Sun et~al.(2019)Sun, Gaut, Tang, Huang, ElSherief, Zhao, Mirza, Belgrave, Abebe, Frauenholz, et~al.]{sun2019mitigating}
Sun, T., Gaut, A., Tang, S., Huang, Y., ElSherief, M., Zhao, J., Mirza, D., Belgrave, E., Abebe, G., Frauenholz, S., et~al.
\newblock Mitigating gender bias in natural language processing: Literature review.
\newblock \emph{arXiv preprint arXiv:1906.08976}, 2019.

\bibitem[Suresh \& Guttag(2019)Suresh and Guttag]{suresh2019framework}
Suresh, H. and Guttag, J.~V.
\newblock A framework for understanding unintended consequences of machine learning.
\newblock \emph{arXiv preprint arXiv:1901.10002}, 2\penalty0 (8), 2019.

\bibitem[Szegedy et~al.(2013)Szegedy, Zaremba, Sutskever, Bruna, Erhan, Goodfellow, and Fergus]{szegedy2013intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock \emph{arXiv preprint arXiv:1312.6199}, 2013.

\bibitem[Tatman(2017)]{tatman2017gender}
Tatman, R.
\newblock Gender and dialect bias in youtube's automatic captions.
\newblock In \emph{Proceedings of the First ACL Workshop on Ethics in Natural Language Processing}, pp.\  53--57, 2017.

\bibitem[Tian et~al.(2020)Tian, Sun, Poole, Krishnan, Schmid, and Isola]{tian2020makes}
Tian, Y., Sun, C., Poole, B., Krishnan, D., Schmid, C., and Isola, P.
\newblock What makes for good views for contrastive learning?
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 6827--6839, 2020.

\bibitem[Tram{\`e}r et~al.(2016)Tram{\`e}r, Zhang, Juels, Reiter, and Ristenpart]{tramer2016stealing}
Tram{\`e}r, F., Zhang, F., Juels, A., Reiter, M.~K., and Ristenpart, T.
\newblock Stealing machine learning models via prediction apis.
\newblock \emph{arXiv preprint arXiv:1609.02943}, 2016.

\bibitem[Tran et~al.(2022)Tran, Fioretto, Kim, and Naidu]{tran2022pruning}
Tran, C., Fioretto, F., Kim, J.-E., and Naidu, R.
\newblock Pruning has a disparate impact on model accuracy.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 17652--17664, 2022.

\bibitem[Wan(2021)]{wan2021fairness}
Wan, A.
\newblock Fairness in representation for multilingual nlp: Insights from controlled experiments on conditional language modeling.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Wang \& Sennrich(2020)Wang and Sennrich]{wang2020exposure}
Wang, C. and Sennrich, R.
\newblock On exposure bias, hallucination and domain shift in neural machine translation.
\newblock \emph{arXiv preprint arXiv:2005.03642}, 2020.

\bibitem[Wang et~al.(2017)Wang, Chen, Diao, Wai, Korosoglou, Cheng, Chen, and Sethi]{wang2017active}
Wang, K., Chen, G.~S., Diao, R., Wai, A.~P., Korosoglou, G., Cheng, L.-F., Chen, Z., and Sethi, I.~K.
\newblock Active learning with neural networks for personalized medicine.
\newblock In \emph{2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, pp.\  135--142. IEEE, 2017.

\bibitem[Weiss et~al.(2016)Weiss, Khoshgoftaar, and Wang]{weiss2016survey}
Weiss, K., Khoshgoftaar, T.~M., and Wang, D.
\newblock A survey of transfer learning.
\newblock \emph{Journal of Big data}, 3\penalty0 (1):\penalty0 1--40, 2016.

\bibitem[Williams \& White(2003)Williams and White]{williams2003conceptualising}
Williams, C.~C. and White, R.
\newblock Conceptualising social inclusion: some lessons for action.
\newblock In \emph{Proceedings of the Institution of Civil Engineers-Municipal Engineer}, volume 156, pp.\  91--95. Thomas Telford Ltd, 2003.

\bibitem[Yang et~al.(2023)Yang, Li, Zhang, Chen, and Cheng]{yang2023exploring}
Yang, X., Li, Y., Zhang, X., Chen, H., and Cheng, W.
\newblock Exploring the limits of chatgpt for query or aspect-based text summarization.
\newblock \emph{arXiv preprint arXiv:2302.08081}, 2023.

\bibitem[Zafar et~al.(2017)Zafar, Valera, Rodriguez, and Gummadi]{zafar2017fairness}
Zafar, M.~B., Valera, I., Rodriguez, M.~G., and Gummadi, K.~P.
\newblock Fairness constraints: Mechanisms for fair classification.
\newblock \emph{IEEE Transactions on Knowledge and Data Engineering}, 29\penalty0 (7):\penalty0 1497--1510, 2017.

\bibitem[Zellers et~al.(2019)Zellers, Holtzman, Rashkin, Bisk, Farhadi, Roesner, and Choi]{zellers2019defending}
Zellers, R., Holtzman, A., Rashkin, H., Bisk, Y., Farhadi, A., Roesner, F., and Choi, Y.
\newblock Defending against neural fake news.
\newblock In \emph{Advances in neural information processing systems}, pp.\  9051--9062, 2019.

\bibitem[Zhang et~al.(2018)Zhang, Liao, Li, Lei, and Jain]{zhang2018mitigating}
Zhang, R., Liao, S., Li, Z., Lei, Z., and Jain, A.~K.
\newblock Mitigating bias in face recognition: The impact of demographic-balanced datasets.
\newblock \emph{arXiv preprint arXiv:1811.00483}, 2018.

\bibitem[Zhao et~al.(2023)Zhao, Chen, Yang, Liu, Deng, Cai, Wang, Yin, and Du]{zhao2023explainability}
Zhao, H., Chen, H., Yang, F., Liu, N., Deng, H., Cai, H., Wang, S., Yin, D., and Du, M.
\newblock Explainability for large language models: A survey.
\newblock \emph{ACM Transactions on Intelligent Systems and Technology}, 2023.

\bibitem[Zhao et~al.(2017)Zhao, Wang, Yatskar, Ordonez, and Chang]{zhao2017men}
Zhao, J., Wang, T., Yatskar, M., Ordonez, V., and Chang, K.-W.
\newblock Men also like shopping: Reducing gender bias amplification using corpus-level constraints.
\newblock \emph{arXiv preprint arXiv:1707.09457}, 2017.

\bibitem[Zhuang et~al.(2020)Zhuang, Qi, Duan, Xi, Zhu, Zhu, Xiong, and He]{zhuang2020comprehensive}
Zhuang, F., Qi, Z., Duan, K., Xi, D., Zhu, Y., Zhu, H., Xiong, H., and He, Q.
\newblock A comprehensive survey on transfer learning.
\newblock \emph{Proceedings of the IEEE}, 109\penalty0 (1):\penalty0 43--76, 2020.

\end{thebibliography}
