@inproceedings{dabney2018distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc and Munos, R{\'e}mi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{chow2015risk,
  title={Risk-sensitive and robust decision-making: a cvar optimization approach},
  author={Chow, Yinlam and Tamar, Aviv and Mannor, Shie and Pavone, Marco},
  journal={arXiv preprint arXiv:1506.02188},
  year={2015}
}

@inproceedings{mavrin2019distributional,
  title={Distributional reinforcement learning for efficient exploration},
  author={Mavrin, Borislav and Yao, Hengshuai and Kong, Linglong and Wu, Kaiwen and Yu, Yaoliang},
  booktitle={International conference on machine learning},
  pages={4424--4434},
  year={2019},
  organization={PMLR}
}

@article{clements2019estimating,
  title={Estimating risk and uncertainty in deep reinforcement learning},
  author={Clements, William R and Van Delft, Bastien and Robaglia, Beno{\^\i}t-Marie and Slaoui, Reda Bahi and Toth, S{\'e}bastien},
  journal={arXiv preprint arXiv:1905.09638},
  year={2019}
}

@inproceedings{bellemare2017distributional,
  title={A distributional perspective on reinforcement learning},
  author={Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={449--458},
  year={2017},
  organization={PMLR}
}

@inproceedings{dabney2018implicit,
  title={Implicit quantile networks for distributional reinforcement learning},
  author={Dabney, Will and Ostrovski, Georg and Silver, David and Munos, R{\'e}mi},
  booktitle={International conference on machine learning},
  pages={1096--1105},
  year={2018},
  organization={PMLR}
}

@inproceedings{stanko2019risk,
  title={Risk-averse Distributional Reinforcement Learning: A CVaR Optimization Approach.},
  author={Stanko, Silvestr and Macek, Karel},
  booktitle={IJCCI},
  pages={412--423},
  year={2019}
}

@inproceedings{singh2020improving,
  title={Improving robustness via risk averse distributional reinforcement learning},
  author={Singh, Rahul and Zhang, Qinsheng and Chen, Yongxin},
  booktitle={Learning for Dynamics and Control},
  pages={958--968},
  year={2020},
  organization={PMLR}
}

@inproceedings{o2018uncertainty,
  title={The uncertainty bellman equation and exploration},
  author={Oâ€™Donoghue, Brendan and Osband, Ian and Munos, Remi and Mnih, Volodymyr},
  booktitle={International Conference on Machine Learning},
  pages={3836--3845},
  year={2018}
}

@inproceedings{azizzadenesheli2018efficient,
  title={Efficient exploration through bayesian deep q-networks},
  author={Azizzadenesheli, Kamyar and Brunskill, Emma and Anandkumar, Animashree},
  booktitle={2018 Information Theory and Applications Workshop (ITA)},
  pages={1--9},
  year={2018},
  organization={IEEE}
}

@inproceedings{osband2017posterior,
  title={Why is posterior sampling better than optimism for reinforcement learning?},
  author={Osband, Ian and Van Roy, Benjamin},
  booktitle={International conference on machine learning},
  pages={2701--2710},
  year={2017},
  organization={PMLR}
}

@article{kim2019optimality,
  title={On the optimality of perturbations in stochastic and adversarial multi-armed bandit problems},
  author={Kim, Baekjin and Tewari, Ambuj},
  journal={arXiv preprint arXiv:1902.00610},
  year={2019}
}

@article{lee2020optimal,
  title={Optimal Algorithms for Stochastic Multi-Armed Bandits with Heavy Tailed Rewards},
  author={Lee, Kyungjae and Yang, Hongjun and Lim, Sungbin and Oh, Songhwai},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{ciosek2019better,
  title={Better exploration with optimistic actor-critic},
  author={Ciosek, Kamil and Vuong, Quan and Loftin, Robert and Hofmann, Katja},
  journal={arXiv preprint arXiv:1910.12807},
  year={2019}
}

@article{chen2017ucb,
  title={UCB exploration via Q-ensembles},
  author={Chen, Richard Y and Sidor, Szymon and Abbeel, Pieter and Schulman, John},
  journal={arXiv preprint arXiv:1706.01502},
  year={2017}
}

@article{osband2013more,
  title={(More) efficient reinforcement learning via posterior sampling},
  author={Osband, Ian and Russo, Daniel and Van Roy, Benjamin},
  journal={arXiv preprint arXiv:1306.0940},
  year={2013}
}

@article{yaari1987dual,
  title={The dual theory of choice under risk},
  author={Yaari, Menahem E},
  journal={Econometrica: Journal of the Econometric Society},
  pages={95--115},
  year={1987},
  publisher={JSTOR}
}

@article{dhaene2012remarks,
  title={Remarks on quantiles and distortion risk measures},
  author={Dhaene, Jan and Kukush, Alexander and Linders, Dani{\"e}l and Tang, Qihe},
  journal={European Actuarial Journal},
  volume={2},
  number={2},
  pages={319--328},
  year={2012},
  publisher={Springer}
}

@article{osband2016deep,
  title={Deep exploration via bootstrapped DQN},
  author={Osband, Ian and Blundell, Charles and Pritzel, Alexander and Van Roy, Benjamin},
  journal={Advances in neural information processing systems},
  volume={29},
  pages={4026--4034},
  year={2016}
}

@article{garcia2015comprehensive,
  title={A comprehensive survey on safe reinforcement learning},
  author={Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
  journal={Journal of Machine Learning Research},
  volume={16},
  number={1},
  pages={1437--1480},
  year={2015}
}

@article{esfahani2018data,
  title={Data-driven distributionally robust optimization using the Wasserstein metric: Performance guarantees and tractable reformulations},
  author={Esfahani, Peyman Mohajerin and Kuhn, Daniel},
  journal={Mathematical Programming},
  volume={171},
  number={1},
  pages={115--166},
  year={2018},
  publisher={Springer}
}

@misc{stable-baselines3,
  author = {Raffin, Antonin and Hill, Ashley and Ernestus, Maximilian and Gleave, Adam and Kanervisto, Anssi and Dormann, Noah},
  title = {Stable Baselines3},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/DLR-RM/stable-baselines3}},
}

@article{yang2019fully,
  title={Fully parameterized quantile function for distributional reinforcement learning},
  author={Yang, Derek and Zhao, Li and Lin, Zichuan and Qin, Tao and Bian, Jiang and Liu, Tie-Yan},
  journal={Advances in neural information processing systems},
  volume={32},
  pages={6193--6202},
  year={2019}
}

@article{osband2019deep,
  title={Deep Exploration via Randomized Value Functions.},
  author={Osband, Ian and Van Roy, Benjamin and Russo, Daniel J and Wen, Zheng and others},
  journal={J. Mach. Learn. Res.},
  volume={20},
  number={124},
  pages={1--62},
  year={2019}
}

@article{smirnova2019distributionally,
  title={Distributionally robust reinforcement learning},
  author={Smirnova, Elena and Dohmatob, Elvis and Mary, J{\'e}r{\'e}mie},
  journal={arXiv preprint arXiv:1902.08708},
  year={2019}
}

@article{yang2020wasserstein,
  title={Wasserstein distributionally robust stochastic control: A data-driven approach},
  author={Yang, Insoon},
  journal={IEEE Transactions on Automatic Control},
  year={2020},
  publisher={IEEE}
}

@article{tang2018exploration,
  title={Exploration by distributional reinforcement learning},
  author={Tang, Yunhao and Agrawal, Shipra},
  journal={arXiv preprint arXiv:1805.01907},
  year={2018}
}


@article{yang2021exploration,
  title={Exploration in Deep Reinforcement Learning: A Comprehensive Survey},
  author={Yang, Tianpei and Tang, Hongyao and Bai, Chenjia and Liu, Jinyi and Hao, Jianye and Meng, Zhaopeng and Liu, Peng},
  journal={arXiv preprint arXiv:2109.06668},
  year={2021}
}

@inproceedings{keramati2020being,
  title={Being optimistic to be conservative: Quickly learning a cvar policy},
  author={Keramati, Ramtin and Dann, Christoph and Tamkin, Alex and Brunskill, Emma},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  pages={4436--4443},
  year={2020}
}

@article{moerland2018potential,
  title={The potential of the return distribution for exploration in rl},
  author={Moerland, Thomas M and Broekens, Joost and Jonker, Catholijn M},
  journal={arXiv preprint arXiv:1806.04242},
  year={2018}
}

@article{rigter2021risk,
  title={Risk-Averse Bayes-Adaptive Reinforcement Learning},
  author={Rigter, Marc and Lacerda, Bruno and Hawes, Nick},
  journal={arXiv preprint arXiv:2102.05762},
  year={2021}
}

@article{rockafellar2000optimization,
  title={Optimization of conditional value-at-risk},
  author={Rockafellar, R Tyrrell and Uryasev, Stanislav and others},
  journal={Journal of risk},
  volume={2},
  pages={21--42},
  year={2000}
}

@article{chow2017risk,
  title={Risk-constrained reinforcement learning with percentile risk criteria},
  author={Chow, Yinlam and Ghavamzadeh, Mohammad and Janson, Lucas and Pavone, Marco},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={6070--6120},
  year={2017},
  publisher={JMLR. org}
}

@article{zhang2020mean,
  title={Mean-variance policy iteration for risk-averse reinforcement learning},
  author={Zhang, Shangtong and Liu, Bo and Whiteson, Shimon},
  journal={arXiv preprint arXiv:2004.10888},
  year={2020}
}

@inproceedings{choi2019distributional,
  title={Distributional deep reinforcement learning with a mixture of gaussians},
  author={Choi, Yunho and Lee, Kyungjae and Oh, Songhwai},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={9791--9797},
  year={2019},
  organization={IEEE}
}

@book{shapiro2021lectures,
  title={Lectures on stochastic programming: modeling and theory},
  author={Shapiro, Alexander and Dentcheva, Darinka and Ruszczynski, Andrzej},
  year={2021},
  publisher={SIAM}
}


@article{castro2018dopamine,
  title={Dopamine: A research framework for deep reinforcement learning},
  author={Castro, Pablo Samuel and Moitra, Subhodeep and Gelada, Carles and Kumar, Saurabh and Bellemare, Marc G},
  journal={arXiv preprint arXiv:1812.06110},
  year={2018}
}

@inproceedings{hessel2018rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Thirty-second AAAI conference on artificial intelligence},
  year={2018}
}

@article{machado2018revisiting,
  title={Revisiting the arcade learning environment: Evaluation protocols and open problems for general agents},
  author={Machado, Marlos C and Bellemare, Marc G and Talvitie, Erik and Veness, Joel and Hausknecht, Matthew and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={61},
  pages={523--562},
  year={2018}
}

@software{dqnzoo2020github,
  title = {{DQN} {Zoo}: Reference implementations of {DQN}-based agents},
  author = {John Quan and Georg Ostrovski},
  url = {http://github.com/deepmind/dqn_zoo},
  version = {1.0.0},
  year = {2020},
}

@article{mavrin2018exploration,
  title={Exploration using Distributional RL and UCB},
  author={Mavrin, Borislav and Yao, Hengshuai and Kong, Linglong and others},
  year={2018}
}

@inproceedings{ishfaq2021randomized,
  title={Randomized Exploration in Reinforcement Learning with General Value Function Approximation},
  author={Ishfaq, Haque and Cui, Qiwen and Nguyen, Viet and Ayoub, Alex and Yang, Zhuoran and Wang, Zhaoran and Precup, Doina and Yang, Lin},
  booktitle={International Conference on Machine Learning},
  pages={4607--4616},
  year={2021},
  organization={PMLR}
}

@inproceedings{kveton2020randomized,
  title={Randomized exploration in generalized linear bandits},
  author={Kveton, Branislav and Zaheer, Manzil and Szepesvari, Csaba and Li, Lihong and Ghavamzadeh, Mohammad and Boutilier, Craig},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2066--2076},
  year={2020},
  organization={PMLR}
}

@article{zhou2021non,
  title={Non-decreasing quantile function network with efficient exploration for distributional reinforcement learning},
  author={Zhou, Fan and Zhu, Zhoufan and Kuang, Qi and Zhang, Liwen},
  journal={arXiv preprint arXiv:2105.06696},
  year={2021}
}

@article{oh2022risk,
  title={Risk Perspective Exploration in Distributional Reinforcement Learning},
  author={Oh, Jihwan and Kim, Joonkee and Yun, Se-Young},
  journal={arXiv preprint arXiv:2206.14170},
  year={2022}
}

@article{even2006action,
  title={Action Elimination and Stopping Conditions for the Multi-Armed Bandit and Reinforcement Learning Problems.},
  author={Even-Dar, Eyal and Mannor, Shie and Mansour, Yishay and Mahadevan, Sridhar},
  journal={Journal of machine learning research},
  volume={7},
  number={6},
  year={2006}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{wang2000class,
  title={A class of distortion operators for pricing financial and insurance risks},
  author={Wang, Shaun S},
  journal={Journal of risk and insurance},
  pages={15--36},
  year={2000},
  publisher={JSTOR}
}

@article{tversky1992advances,
  title={Advances in prospect theory: Cumulative representation of uncertainty},
  author={Tversky, Amos and Kahneman, Daniel},
  journal={Journal of Risk and uncertainty},
  volume={5},
  number={4},
  pages={297--323},
  year={1992},
  publisher={Springer}
}

@article{chow2014algorithms,
  title={Algorithms for CVaR optimization in MDPs},
  author={Chow, Yinlam and Ghavamzadeh, Mohammad},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@inproceedings{zhang2019quota,
  title={Quota: The quantile option architecture for reinforcement learning},
  author={Zhang, Shangtong and Yao, Hengshuai},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={5797--5804},
  year={2019}
}

@article{jin2018q,
  title={Is Q-learning provably efficient?},
  author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{moskovitz2021tactical,
  title={Tactical optimism and pessimism for deep reinforcement learning},
  author={Moskovitz, Ted and Parker-Holder, Jack and Pacchiano, Aldo and Arbel, Michael and Jordan, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={12849--12863},
  year={2021}
}

@inproceedings{nguyen2021distributional,
  title={Distributional reinforcement learning via moment matching},
  author={Nguyen-Tang, Thanh and Gupta, Sunil and Venkatesh, Svetha},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={10},
  pages={9144--9152},
  year={2021}
}

@article{bellemare2013arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}