\begin{thebibliography}{77}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Andriushchenko et~al.(2020)Andriushchenko, Croce, Flammarion, and
  Hein]{andriushchenko2020square}
Andriushchenko, M., Croce, F., Flammarion, N., and Hein, M.
\newblock Square attack: a query-efficient black-box adversarial attack via
  random search.
\newblock In \emph{ECCV}, 2020.

\bibitem[Bai et~al.(2019)Bai, Feng, Wang, Dai, Xia, and Jiang]{bai2019hilbert}
Bai, Y., Feng, Y., Wang, Y., Dai, T., Xia, S.-T., and Jiang, Y.
\newblock Hilbert-based generative defense for adversarial examples.
\newblock In \emph{ICCV}, 2019.

\bibitem[Barreno et~al.(2010)Barreno, Nelson, Joseph, and
  Tygar]{barreno2010security}
Barreno, M., Nelson, B., Joseph, A.~D., and Tygar, J.~D.
\newblock The security of machine learning.
\newblock \emph{Machine Learning}, 81\penalty0 (2):\penalty0 121--148, 2010.

\bibitem[Binkowski et~al.(2018)Binkowski, Sutherland, Arbel, and
  Gretton]{MMD_GAN}
Binkowski, M., Sutherland, D.~J., Arbel, M., and Gretton, A.
\newblock Demystifying {MMD} {GAN}s.
\newblock In \emph{ICLR}, 2018.

\bibitem[Borgwardt et~al.(2006)Borgwardt, Gretton, Rasch, Kriegel,
  Sch{\"o}lkopf, and Smola]{borgwardt2006integrating}
Borgwardt, K.~M., Gretton, A., Rasch, M.~J., Kriegel, H.-P., Sch{\"o}lkopf, B.,
  and Smola, A.~J.
\newblock Integrating structured biological data by kernel maximum mean
  discrepancy.
\newblock \emph{Bioinformatics}, 22\penalty0 (14):\penalty0 e49--e57, 2006.

\bibitem[Carlini \& Wagner(2017{\natexlab{a}})Carlini and
  Wagner]{carlini2017adversarial}
Carlini, N. and Wagner, D.
\newblock Adversarial examples are not easily detected: Bypassing ten detection
  methods.
\newblock In \emph{Proceedings of the 10th ACM Workshop on Artificial
  Intelligence and Security}, pp.\  3--14, 2017{\natexlab{a}}.

\bibitem[Carlini \& Wagner(2017{\natexlab{b}})Carlini and
  Wagner]{carlini2017towards}
Carlini, N. and Wagner, D.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{2017 {IEEE} Symposium on Security and Privacy}, pp.\
  39--57. IEEE, 2017{\natexlab{b}}.

\bibitem[Chen et~al.(2015)Chen, Seff, Kornhauser, and
  Xiao]{chen2015deepdriving}
Chen, C., Seff, A., Kornhauser, A., and Xiao, J.
\newblock Deepdriving: Learning affordance for direct perception in autonomous
  driving.
\newblock In \emph{ICCV}, 2015.

\bibitem[Chen \& Friedman(2017)Chen and Friedman]{Chen2017}
Chen, H. and Friedman, J.~H.
\newblock {A new graph-based two-sample test for multivariate and object data}.
\newblock \emph{Journal of the American Statistical Association}, 112\penalty0
  (517):\penalty0 397--409, 2017.

\bibitem[Chen et~al.(2020)Chen, Liu, Chang, Cheng, Amini, and
  Wang]{Chen_2020_CVPR}
Chen, T., Liu, S., Chang, S., Cheng, Y., Amini, L., and Wang, Z.
\newblock Adversarial robustness: From self-supervised pre-training to
  fine-tuning.
\newblock In \emph{CVPR}, 2020.

\bibitem[Chwialkowski et~al.(2014)Chwialkowski, Sejdinovic, and
  Gretton]{Kacper14wildbtp}
Chwialkowski, K., Sejdinovic, D., and Gretton, A.
\newblock A wild bootstrap for degenerate kernel tests.
\newblock In \emph{NeurIPS}, 2014.

\bibitem[Chwialkowski et~al.(2015)Chwialkowski, Ramdas, Sejdinovic, and
  Gretton]{Chwialkowski2015}
Chwialkowski, K., Ramdas, A., Sejdinovic, D., and Gretton, A.
\newblock Fast two-sample testing with analytic representations of probability
  measures.
\newblock In \emph{NeurIPS}, 2015.

\bibitem[Croce \& Hein(2020)Croce and Hein]{croce2020reliable}
Croce, F. and Hein, M.
\newblock Reliable evaluation of adversarial robustness with an ensemble of
  diverse parameter-free attacks.
\newblock In \emph{ICML}, 2020.

\bibitem[Denker \& Keller(1983)Denker and Keller]{denker1983u}
Denker, M. and Keller, G.
\newblock On u-statistics and v. miseâ€™statistics for weakly dependent
  processes.
\newblock \emph{Zeitschrift f{\"u}r Wahrscheinlichkeitstheorie und verwandte
  Gebiete}, 64\penalty0 (4):\penalty0 505--522, 1983.

\bibitem[Fang et~al.(2020{\natexlab{a}})Fang, Lu, Niu, and
  Sugiyama]{fang2020rethinking}
Fang, T., Lu, N., Niu, G., and Sugiyama, M.
\newblock Rethinking importance weighting for deep learning under distribution
  shift.
\newblock In \emph{NeurIPS}, 2020{\natexlab{a}}.

\bibitem[Fang et~al.(2020{\natexlab{b}})Fang, Lu, Liu, Xuan, and
  Zhang]{fang2020open}
Fang, Z., Lu, J., Liu, F., Xuan, J., and Zhang, G.
\newblock Open set domain adaptation: Theoretical bound and algorithm.
\newblock \emph{{IEEE} Transactions on Neural Networks and Learning Systems},
  2020{\natexlab{b}}.

\bibitem[Feinman et~al.(2017)Feinman, Curtin, Shintre, and
  Gardner]{feinman2017detecting}
Feinman, R., Curtin, R.~R., Shintre, S., and Gardner, A.~B.
\newblock Detecting adversarial samples from artifacts.
\newblock \emph{arXiv:1703.00410}, 2017.

\bibitem[Ghoshdastidar et~al.(2017)Ghoshdastidar, Gutzeit, Carpentier, and von
  Luxburg]{Ghoshdastidar2017}
Ghoshdastidar, D., Gutzeit, M., Carpentier, A., and von Luxburg, U.
\newblock {Two-sample tests for large random graphs using network statistics}.
\newblock In \emph{COLT}, 2017.

\bibitem[Gong et~al.(2016)Gong, Zhang, Liu, Tao, Glymour, and
  Systems]{Gong2016}
Gong, M., Zhang, K., Liu, T., Tao, D., Glymour, C., and Systems, I.
\newblock {Domain adaptation with conditional transferable components}.
\newblock In \emph{ICML}, 2016.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{ICLR}, 2015.

\bibitem[Gretton et~al.(2005)Gretton, Bousquet, Smola, and
  Sch{\"o}lkopf]{gretton2005measuring}
Gretton, A., Bousquet, O., Smola, A., and Sch{\"o}lkopf, B.
\newblock Measuring statistical dependence with {Hilbert-Schmidt} norms.
\newblock In \emph{ALT}, 2005.

\bibitem[Gretton et~al.(2008)Gretton, Fukumizu, Teo, Song, Sch{\"o}lkopf, and
  Smola]{gretton2008kernel}
Gretton, A., Fukumizu, K., Teo, C.~H., Song, L., Sch{\"o}lkopf, B., and Smola,
  A.~J.
\newblock A kernel statistical test of independence.
\newblock In \emph{NeurIPS}, 2008.

\bibitem[Gretton et~al.(2012{\natexlab{a}})Gretton, Borgwardt, Rasch,
  Sch{\"{o}}lkopf, and Smola]{Gretton2012}
Gretton, A., Borgwardt, K.~M., Rasch, M.~J., Sch{\"{o}}lkopf, B., and Smola,
  A.~J.
\newblock {A kernel two-sample test}.
\newblock \emph{Journal of Machine Learning Research}, 13:\penalty0 723--773,
  2012{\natexlab{a}}.

\bibitem[Gretton et~al.(2012{\natexlab{b}})Gretton, Sriperumbudur, Sejdinovic,
  Strathmann, and Pontil]{Gretton2012NeurIPS}
Gretton, A., Sriperumbudur, B., Sejdinovic, D., Strathmann, H., and Pontil, M.
\newblock Optimal kernel choice for large-scale two-sample tests.
\newblock In \emph{NeurIPS}, 2012{\natexlab{b}}.

\bibitem[Grosse et~al.(2017)Grosse, Manoharan, Papernot, Backes, and
  McDaniel]{grosse2017statistical}
Grosse, K., Manoharan, P., Papernot, N., Backes, M., and McDaniel, P.
\newblock On the (statistical) detection of adversarial examples.
\newblock \emph{arXiv:1702.06280}, 2017.

\bibitem[He et~al.(2018)He, Li, and Song]{he2018decision}
He, W., Li, B., and Song, D.
\newblock Decision boundary analysis of adversarial examples.
\newblock In \emph{ICLR}, 2018.

\bibitem[Jean et~al.(2018)Jean, Xie, and Ermon]{Jean2018}
Jean, N., Xie, S.~M., and Ermon, S.
\newblock Semi-supervised deep kernel learning: Regression with unlabeled data
  by minimizing predictive variance.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Jitkrittum et~al.(2016)Jitkrittum, Szabo, Chwialkowski, and
  Gretton]{Jitkrittum2016}
Jitkrittum, W., Szabo, Z., Chwialkowski, K., and Gretton, A.
\newblock Interpretable distribution features with maximum testing power.
\newblock In \emph{NeurIPS}, 2016.

\bibitem[Jitkrittum et~al.(2017)Jitkrittum, Xu, Szabo, Fukumizu, and
  Gretton]{Jitkrittum2017}
Jitkrittum, W., Xu, W., Szabo, Z., Fukumizu, K., and Gretton, A.
\newblock A linear-time kernel goodness-of-fit test.
\newblock In \emph{NeurIPS}, 2017.

\bibitem[Kanamori et~al.(2012)Kanamori, Suzuki, and Sugiyama]{Kanamori12TIT}
Kanamori, T., Suzuki, T., and Sugiyama, M.
\newblock f-divergence estimation and two-sample homogeneity test under
  semiparametric density-ratio models.
\newblock \emph{{IEEE} Transactions on Information Theory}, 58\penalty0
  (2):\penalty0 708--720, 2012.

\bibitem[Kirchler et~al.(2020)Kirchler, Khorasani, Kloft, and
  Lippert]{Matthias:deep-test}
Kirchler, M., Khorasani, S., Kloft, M., and Lippert, C.
\newblock Two-sample testing using deep learning.
\newblock In \emph{AISTATS}, 2020.

\bibitem[Kloft \& Laskov(2012)Kloft and Laskov]{kloft2012security}
Kloft, M. and Laskov, P.
\newblock Security analysis of online centroid anomaly detection.
\newblock \emph{The Journal of Machine Learning Research}, 13\penalty0
  (1):\penalty0 3681--3724, 2012.

\bibitem[Kurakin et~al.(2017)Kurakin, Goodfellow, Bengio,
  et~al.]{kurakin2016adversarial}
Kurakin, A., Goodfellow, I., Bengio, S., et~al.
\newblock Adversarial examples in the physical world.
\newblock In \emph{ICLR}, 2017.

\bibitem[Lee et~al.(2018)Lee, Lee, Lee, and Shin]{lee2018simple}
Lee, K., Lee, K., Lee, H., and Shin, J.
\newblock A simple unified framework for detecting out-of-distribution samples
  and adversarial attacks.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Leucht \& Neumann(2013)Leucht and Neumann]{leucht2013dependentwildbtp}
Leucht, A. and Neumann, M.~H.
\newblock Dependent wild bootstrap for degenerate {U-and V-statistics}.
\newblock \emph{Journal of Multivariate Analysis}, 117:\penalty0 257--280,
  2013.

\bibitem[Li \& Vorobeychik(2014)Li and Vorobeychik]{li2014feature}
Li, B. and Vorobeychik, Y.
\newblock Feature cross-substitution in adversarial classification.
\newblock In \emph{NeurIPS}, 2014.

\bibitem[Li \& Wang(2018)Li and Wang]{LiW18TIT}
Li, S. and Wang, X.
\newblock Fully distributed sequential hypothesis testing: Algorithms and
  asymptotic analyses.
\newblock \emph{{IEEE} Trans. Information Theory}, 64\penalty0 (4):\penalty0
  2742--2758, 2018.

\bibitem[Li \& Li(2017)Li and Li]{li2017adversarial}
Li, X. and Li, F.
\newblock Adversarial examples detection in deep networks with convolutional
  filter statistics.
\newblock In \emph{ICCV}, 2017.

\bibitem[Liu et~al.(2019)Liu, Lu, Han, Niu, Zhang, and
  Sugiyama]{liu2019butterfly}
Liu, F., Lu, J., Han, B., Niu, G., Zhang, G., and Sugiyama, M.
\newblock Butterfly: A panacea for all difficulties in wildly unsupervised
  domain adaptation.
\newblock In \emph{NeurIPS {LTS} Workshop}, 2019.

\bibitem[Liu et~al.(2020{\natexlab{a}})Liu, Lu, and Zhang]{liu2020TFS}
Liu, F., Lu, J., and Zhang, G.
\newblock Multi-source heterogeneous unsupervised domain adaptation via
  fuzzy-relation neural networks.
\newblock \emph{{IEEE} Trans. Fuzzy Syst.}, 2020{\natexlab{a}}.

\bibitem[Liu et~al.(2020{\natexlab{b}})Liu, Xu, Lu, Zhang, Gretton, and
  Sutherland]{liu2020learning}
Liu, F., Xu, W., Lu, J., Zhang, G., Gretton, A., and Sutherland, D.~J.
\newblock Learning deep kernels for non-parametric two-sample tests.
\newblock In \emph{ICML}, 2020{\natexlab{b}}.

\bibitem[Lopez{-}Paz \& Oquab(2017)Lopez{-}Paz and Oquab]{Lopez:C2ST}
Lopez{-}Paz, D. and Oquab, M.
\newblock Revisiting classifier two-sample tests.
\newblock In \emph{ICLR}, 2017.

\bibitem[Ma et~al.(2018)Ma, Li, Wang, Erfani, Wijewickrema, Schoenebeck, Song,
  Houle, and Bailey]{ma2018characterizing}
Ma, X., Li, B., Wang, Y., Erfani, S.~M., Wijewickrema, S., Schoenebeck, G.,
  Song, D., Houle, M.~E., and Bailey, J.
\newblock Characterizing adversarial subspaces using local intrinsic
  dimensionality.
\newblock In \emph{ICLR}, 2018.

\bibitem[Ma et~al.(2021)Ma, Niu, Gu, Wang, Zhao, Bailey, and
  Lu]{ma2021understanding}
Ma, X., Niu, Y., Gu, L., Wang, Y., Zhao, Y., Bailey, J., and Lu, F.
\newblock Understanding adversarial attacks on deep learning based medical
  image analysis systems.
\newblock \emph{Pattern Recognition}, 2021.

\bibitem[Maaten \& Hinton(2008)Maaten and Hinton]{maaten2008visualizing}
Maaten, L. v.~d. and Hinton, G.
\newblock Visualizing data using t-sne.
\newblock \emph{Journal of machine learning research}, 9\penalty0
  (Nov):\penalty0 2579--2605, 2008.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{Madry18PGD}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{ICLR}, 2018.

\bibitem[Metzen et~al.(2017)Metzen, Genewein, Fischer, and
  Bischoff]{metzen2017detecting}
Metzen, J.~H., Genewein, T., Fischer, V., and Bischoff, B.
\newblock On detecting adversarial perturbations.
\newblock \emph{arXiv:1702.04267}, 2017.

\bibitem[Nguyen et~al.(2015)Nguyen, Yosinski, and Clune]{nguyen2015deep}
Nguyen, A., Yosinski, J., and Clune, J.
\newblock Deep neural networks are easily fooled: High confidence predictions
  for unrecognizable images.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  427--436, 2015.

\bibitem[Od{\'e}n et~al.(1975)Od{\'e}n, Wedel, et~al.]{oden1975arguments}
Od{\'e}n, A., Wedel, H., et~al.
\newblock Arguments for fisher's permutation test.
\newblock \emph{The Annals of Statistics}, 3\penalty0 (2):\penalty0 518--520,
  1975.

\bibitem[Oneto et~al.(2020)Oneto, Donini, Luise, Ciliberto, Maurer, and
  Pontil]{ODLCMP20:fair-reps}
Oneto, L., Donini, M., Luise, G., Ciliberto, C., Maurer, A., and Pontil, M.
\newblock Exploiting {MMD} and {S}inkhorn divergences for fair and transferable
  representation learning.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Rouhani et~al.(2017)Rouhani, Samragh, Javidi, and
  Koushanfar]{rouhani2017curtail}
Rouhani, B.~D., Samragh, M., Javidi, T., and Koushanfar, F.
\newblock Curtail: Characterizing and thwarting adversarial deep learning.
\newblock \emph{arXiv:1709.02538}, 2017.

\bibitem[Shao(2010)]{shao2010dependentwildbtp}
Shao, X.
\newblock The dependent wild bootstrap.
\newblock \emph{Journal of the American Statistical Association}, 105\penalty0
  (489):\penalty0 218--235, 2010.

\bibitem[Sriperumbudur et~al.(2010)Sriperumbudur, Gretton, Fukumizu,
  Sch{\"o}lkopf, and Lanckriet]{sriperumbudur2010hilbert}
Sriperumbudur, B.~K., Gretton, A., Fukumizu, K., Sch{\"o}lkopf, B., and
  Lanckriet, G.~R.
\newblock Hilbert space embeddings and metrics on probability measures.
\newblock \emph{The Journal of Machine Learning Research}, 11:\penalty0
  1517--1561, 2010.

\bibitem[Stojanov et~al.(2019)Stojanov, Gong, Carbonell, and
  Zhang]{DA_app_Stojanov}
Stojanov, P., Gong, M., Carbonell, J.~G., and Zhang, K.
\newblock Data-driven approach to multiple-source domain adaptation.
\newblock In \emph{AISTATS}, 2019.

\bibitem[Sugiyama et~al.(2011)Sugiyama, Suzuki, Itoh, Kanamori, and
  Kimura]{Sugiyama11NN}
Sugiyama, M., Suzuki, T., Itoh, Y., Kanamori, T., and Kimura, M.
\newblock Least-squares two-sample test.
\newblock \emph{Neural Networks}, 24\penalty0 (7):\penalty0 735--751, 2011.

\bibitem[Sutherland(2019)]{unbiased-var-ests}
Sutherland, D.~J.
\newblock Unbiased estimators for the variance of {MMD} estimators.
\newblock \emph{arXiv:1906.02104}, 2019.

\bibitem[Sutherland et~al.(2017)Sutherland, Tung, Strathmann, De, Ramdas,
  Smola, and Gretton]{sutherland:mmd-opt}
Sutherland, D.~J., Tung, H.-Y., Strathmann, H., De, S., Ramdas, A., Smola, A.,
  and Gretton, A.
\newblock Generative models and model criticism via optimized maximum mean
  discrepancy.
\newblock In \emph{ICLR}, 2017.

\bibitem[Szegedy et~al.(2013)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock \emph{arXiv preprint arXiv:1312.6199}, 2013.

\bibitem[Tram{\`e}r et~al.(2020)Tram{\`e}r, Behrmann, Carlini, Papernot, and
  Jacobsen]{tramer2020fundamental}
Tram{\`e}r, F., Behrmann, J., Carlini, N., Papernot, N., and Jacobsen, J.-H.
\newblock Fundamental tradeoffs between invariance and sensitivity to
  adversarial perturbations.
\newblock In \emph{ICML}, 2020.

\bibitem[Wang et~al.(2020{\natexlab{a}})Wang, Chen, Gui, Hu, Liu, and
  Wang]{wang2020once}
Wang, H., Chen, T., Gui, S., Hu, T.-K., Liu, J., and Wang, Z.
\newblock Once-for-all adversarial training: In-situ tradeoff between
  robustness and accuracy for free.
\newblock In \emph{NeurIPS}, 2020{\natexlab{a}}.

\bibitem[Wang et~al.(2019)Wang, Ma, Bailey, Yi, Zhou, and
  Gu]{wang2019convergence}
Wang, Y., Ma, X., Bailey, J., Yi, J., Zhou, B., and Gu, Q.
\newblock On the convergence and robustness of adversarial training.
\newblock In \emph{ICML}, 2019.

\bibitem[Wang et~al.(2020{\natexlab{b}})Wang, Zou, Yi, Bailey, Ma, and
  Gu]{wang2019improving}
Wang, Y., Zou, D., Yi, J., Bailey, J., Ma, X., and Gu, Q.
\newblock Improving adversarial robustness requires revisiting misclassified
  examples.
\newblock In \emph{ICLR}, 2020{\natexlab{b}}.

\bibitem[Wenliang et~al.(2019)Wenliang, Sutherland, Strathmann, and
  Gretton]{Kevin_ICML2019}
Wenliang, L., Sutherland, D.~J., Strathmann, H., and Gretton, A.
\newblock Learning deep kernels for exponential family densities.
\newblock In \emph{ICML}, 2019.

\bibitem[Wu et~al.(2020)Wu, Xia, and Wang]{wu2020adversarial}
Wu, D., Xia, S.-T., and Wang, Y.
\newblock Adversarial weight perturbation helps robust generalization.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Yamada et~al.(2011)Yamada, Suzuki, Kanamori, Hachiya, and
  Sugiyama]{Yamada11NeurIPS}
Yamada, M., Suzuki, T., Kanamori, T., Hachiya, H., and Sugiyama, M.
\newblock Relative density-ratio estimation for robust distribution comparison.
\newblock In \emph{NeurIPS}, 2011.

\bibitem[Yoshihara(1976)]{yoshihara1976limiting}
Yoshihara, K.-i.
\newblock Limiting behavior of u-statistics for stationary, absolutely regular
  processes.
\newblock \emph{Zeitschrift f{\"u}r Wahrscheinlichkeitstheorie und verwandte
  Gebiete}, 35\penalty0 (3):\penalty0 237--252, 1976.

\bibitem[Yu et~al.(2020)Yu, Liu, Gong, Zhang, Batmanghelich, and
  Tao]{yu2020label}
Yu, X., Liu, T., Gong, M., Zhang, K., Batmanghelich, K., and Tao, D.
\newblock Label-noise robust domain adaptation.
\newblock In \emph{ICML}, 2020.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and
  Komodakis]{zagoruyko2016wide}
Zagoruyko, S. and Komodakis, N.
\newblock Wide residual networks.
\newblock In \emph{BMVC}, 2016.

\bibitem[Zhang et~al.(2019)Zhang, Yu, Jiao, Xing, Ghaoui, and
  Jordan]{ZhangYJXGJ19TRADES}
Zhang, H., Yu, Y., Jiao, J., Xing, E.~P., Ghaoui, L.~E., and Jordan, M.~I.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In \emph{ICML}, 2019.

\bibitem[Zhang et~al.(2020{\natexlab{a}})Zhang, Xu, Han, Niu, Cui, Sugiyama,
  and Kankanhalli]{zhang2020attacks}
Zhang, J., Xu, X., Han, B., Niu, G., Cui, L., Sugiyama, M., and Kankanhalli, M.
\newblock Attacks which do not kill training make adversarial learning
  stronger.
\newblock In \emph{ICML}, 2020{\natexlab{a}}.

\bibitem[Zhang et~al.(2021)Zhang, Zhu, Niu, Han, Sugiyama, and
  Kankanhalli]{zhang2020geometry}
Zhang, J., Zhu, J., Niu, G., Han, B., Sugiyama, M., and Kankanhalli, M.
\newblock Geometry-aware instance-reweighted adversarial training.
\newblock In \emph{ICLR}, 2021.

\bibitem[Zhang et~al.(2020{\natexlab{b}})Zhang, Gong, Stojanov, Huang, LIU, and
  Glymour]{zhang2020domain}
Zhang, K., Gong, M., Stojanov, P., Huang, B., LIU, Q., and Glymour, C.
\newblock Domain adaptation as a problem of inference on graphical models.
\newblock In \emph{NeurIPS}, 2020{\natexlab{b}}.

\bibitem[Zhang et~al.(2020{\natexlab{c}})Zhang, Yamane, Lu, and
  Sugiyama]{zhang2020a}
Zhang, T., Yamane, I., Lu, N., and Sugiyama, M.
\newblock A one-step approach to covariate shift adaptation.
\newblock In \emph{ACML}, 2020{\natexlab{c}}.

\bibitem[Zhang et~al.(2020{\natexlab{d}})Zhang, Li, Liu, and
  Tian]{zhang2020dual}
Zhang, Y., Li, Y., Liu, T., and Tian, X.
\newblock Dual-path distillation: A unified framework to improve black-box
  attacks.
\newblock In \emph{ICML}, 2020{\natexlab{d}}.

\bibitem[Zhang et~al.(2020{\natexlab{e}})Zhang, Liu, Fang, Yuan, Zhang, and
  Lu]{zhang2020clarinet}
Zhang, Y., Liu, F., Fang, Z., Yuan, B., Zhang, G., and Lu, J.
\newblock Clarinet: {A} one-step approach towards budget-friendly unsupervised
  domain adaptation.
\newblock In \emph{IJCAI}, 2020{\natexlab{e}}.

\bibitem[Zhong et~al.(2021)Zhong, Fang, Liu, Lu, Yuan, and Zhang]{zhong2021how}
Zhong, L., Fang, Z., Liu, F., Lu, J., Yuan, B., and Zhang, G.
\newblock How does the combined risk affect the performance of unsupervised
  domain adaptation approaches?
\newblock In \emph{{AAAI}}, 2021.

\bibitem[Zhu et~al.(2021)Zhu, Zhang, Han, Liu, Niu, Yang, Kankanhalli, and
  Sugiyama]{zhu2021understanding}
Zhu, J., Zhang, J., Han, B., Liu, T., Niu, G., Yang, H., Kankanhalli, M., and
  Sugiyama, M.
\newblock Understanding the interaction of adversarial training with noisy
  labels.
\newblock \emph{arXiv preprint arXiv:2102.03482}, 2021.

\end{thebibliography}
