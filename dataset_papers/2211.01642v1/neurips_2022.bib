% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@inproceedings{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
 booktitle={NAACL},
  year={2018}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}


@inproceedings{clark2020electra,
  title={Electra: Pre-training text encoders as discriminators rather than generators},
  author={Clark, Kevin and Luong, Minh-Thang and Le, Quoc V and Manning, Christopher D},
  booktitle={ICLR},
  year={2020}
}

@article{phang2018sentence,
  title={Sentence encoders on stilts: Supplementary training on intermediate labeled-data tasks},
  author={Phang, Jason and F{\'e}vry, Thibault and Bowman, Samuel R},
  journal={arXiv preprint arXiv:1811.01088},
  year={2018}
}

@article{dodge2020fine,
  title={Fine-tuning pretrained language models: Weight initializations, data orders, and early stopping},
  author={Dodge, Jesse and Ilharco, Gabriel and Schwartz, Roy and Farhadi, Ali and Hajishirzi, Hannaneh and Smith, Noah},
  journal={arXiv preprint arXiv:2002.06305},
  year={2020}
}

@inproceedings{lee2019mixout,
  title={Mixout: Effective regularization to finetune large-scale pretrained language models},
  author={Lee, Cheolhyoung and Cho, Kyunghyun and Kang, Wanmo},
 booktitle={ICLR},
  year={2020}
}

@inproceedings{zhang2020revisiting,
  title={Revisiting few-sample BERT fine-tuning},
  author={Zhang, Tianyi and Wu, Felix and Katiyar, Arzoo and Weinberger, Kilian Q and Artzi, Yoav},
 booktitle={ICLR},
  year={2021}
}

@inproceedings{mosbach2020stability,
  title={On the stability of fine-tuning bert: Misconceptions, explanations, and strong baselines},
  author={Mosbach, Marius and Andriushchenko, Maksym and Klakow, Dietrich},
  booktitle={ICLR},
  year={2021}
}

@inproceedings{mahabadi2021variational,
  title={Variational information bottleneck for effective low-resource fine-tuning},
  author={Mahabadi, Rabeeh Karimi and Belinkov, Yonatan and Henderson, James},
  booktitle={ICLR},
  year={2021}
}

@inproceedings{aghajanyan2020better,
  title={Better fine-tuning by reducing representational collapse},
  author={Aghajanyan, Armen and Shrivastava, Akshat and Gupta, Anchit and Goyal, Naman and Zettlemoyer, Luke and Gupta, Sonal},
  booktitle={ICLR},
  year={2021}
}

@inproceedings{tu2016ranking,
  title={Ranking the parameters of deep neural networks using the fisher information},
  author={Tu, Ming and Berisha, Visar and Woolf, Martin and Seo, Jae-sun and Cao, Yu},
  booktitle={ICASSP},
  year={2016}
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@article{achille2019information,
  title={Where is the information in a deep neural network?},
  author={Achille, Alessandro and Paolini, Giovanni and Soatto, Stefano},
  journal={arXiv preprint arXiv:1905.12213},
  year={2019}
}

@inproceedings{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  booktitle={PNAS},
  year={2017},
}

@inproceedings{amari1996neural,
  title={Neural learning in structured parameter spaces-natural Riemannian gradient},
  author={Amari, Shun-ichi},
 booktitle={NeurIPS},
  year={1996}
}

@article{pascanu2013revisiting,
  title={Revisiting natural gradient for deep networks},
  author={Pascanu, Razvan and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1301.3584},
  year={2013}
}

@inproceedings{singh2020woodfisher,
  title={Woodfisher: Efficient second-order approximation for neural network compression},
  author={Singh, Sidak Pal and Alistarh, Dan},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{xu2021raise,
  title={Raise a Child in Large Language Model: Towards Effective and Generalizable Fine-tuning},
  author={Xu, Runxin and Luo, Fuli and Zhang, Zhiyuan and Tan, Chuanqi and Chang, Baobao and Huang, Songfang and Huang, Fei},
 booktitle={EMNLP},
  year={2021}
}

@inproceedings{wang2018glue,
  title={GLUE: A multi-task benchmark and analysis platform for natural language understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
  booktitle={ICLR},
  year={2019}
}

@inproceedings{wolf2020transformers,
  title={Transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  booktitle={EMNLP},
  year={2020}
}

@inproceedings{wu2021r,
  title={R-drop: regularized dropout for neural networks},
  author={Wu, Lijun and Li, Juntao and Wang, Yue and Meng, Qi and Qin, Tao and Chen, Wei and Zhang, Min and Liu, Tie-Yan and others},
  booktitle={NeurIPS},
  year={2021}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@article{lewis2019bart,
  title={Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension},
  author={Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1910.13461},
  year={2019}
}

@article{fisher1922mathematical,
  title={On the mathematical foundations of theoretical statistics},
  author={Fisher, Ronald A},
  journal={Philosophical transactions of the Royal Society of London. Series A, containing papers of a mathematical or physical character},
  volume={222},
  number={594-604},
  pages={309--368},
  year={1922},
  publisher={The Royal Society London}
}

@article{crowley2018pruning,
  title={Pruning neural networks: is it time to nip it in the bud?},
  author={Crowley, Elliot J and Turner, Jack and Storkey, Amos and O'Boyle, Michael},
  year={2018}
}

@article{martens2014new,
  title={New insights and perspectives on the natural gradient method},
  author={Martens, James},
  journal={arXiv preprint arXiv:1412.1193},
  year={2014}
}

@article{theis2018faster,
  title={Faster gaze prediction with dense networks and fisher pruning},
  author={Theis, Lucas and Korshunova, Iryna and Tejani, Alykhan and Husz{\'a}r, Ferenc},
  journal={arXiv preprint arXiv:1801.05787},
  year={2018}
}

@inproceedings{he2020deberta,
  title={Deberta: Decoding-enhanced bert with disentangled attention},
  author={He, Pengcheng and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu},
  booktitle={ICLR},
  year={2021}
}

@inproceedings{bentivogli2009fifth,
  title={The Fifth PASCAL Recognizing Textual Entailment Challenge.},
  author={Bentivogli, Luisa and Clark, Peter and Dagan, Ido and Giampiccolo, Danilo},
  booktitle={TAC},
  year={2009}
}

@inproceedings{dolan2005automatically,
  title={Automatically constructing a corpus of sentential paraphrases},
  author={Dolan, Bill and Brockett, Chris},
  booktitle={IWP},
  year={2005}
}

@article{cer2017semeval,
  title={Semeval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation},
  author={Cer, Daniel and Diab, Mona and Agirre, Eneko and Lopez-Gazpio, Inigo and Specia, Lucia},
  journal={arXiv preprint arXiv:1708.00055},
  year={2017}
}

@article{warstadt2019neural,
  title={Neural network acceptability judgments},
  author={Warstadt, Alex and Singh, Amanpreet and Bowman, Samuel R},
  journal={Transactions of the Association for Computational Linguistics},
  volume={7},
  pages={625--641},
  year={2019},
  publisher={MIT Press}
}

@inproceedings{socher2013recursive,
  title={Recursive deep models for semantic compositionality over a sentiment treebank},
  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
  booktitle={EMNLP},
  year={2013}
}

@inproceedings{rajpurkar2016squad,
  title={Squad: 100,000+ questions for machine comprehension of text},
  author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  booktitle={EMNLP},
  year={2016}
}

@article{Iyer2017,
  title={First quora dataset release: Question pairs.},
  author={Shankar Iyer, Nikhil Dandekar, and Kornel Csernai.},
  journal={\url{https://tinyurl.com/y2y8u5ed}},
  year={2017}
}

@inproceedings{williams2017broad,
  title={A broad-coverage challenge corpus for sentence understanding through inference},
  author={Williams, Adina and Nangia, Nikita and Bowman, Samuel R},
  booktitle={NAACL},
  year={2018}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
 booktitle={NeurIPS},
  year={2017}
}

@article{loshchilov2019decoupled,
  title={Decoupled weight decay regularization (2017)},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2019}
}

@inproceedings{howard2018universal,
  title={Universal language model fine-tuning for text classification},
  author={Howard, Jeremy and Ruder, Sebastian},
  booktitle={ACL},
  year={2018}
}

@inproceedings{belinkov2019adversarial,
  title={On adversarial removal of hypothesis-only bias in natural language inference},
  author={Belinkov, Yonatan and Poliak, Adam and Shieber, Stuart M and Van Durme, Benjamin and Rush, Alexander M},
  booktitle={StarSem},
  year={2019}
}

@inproceedings{bowman2015large,
  title={A large annotated corpus for learning natural language inference},
  author={Bowman, Samuel R and Angeli, Gabor and Potts, Christopher and Manning, Christopher D},
  booktitle={EMNLP},
  year={2015}
}

@inproceedings{marelli2014sick,
  title={A SICK cure for the evaluation of compositional distributional semantic models},
  author={Marelli, Marco and Menini, Stefano and Baroni, Marco and Bentivogli, Luisa and Bernardi, Raffaella and Zamparelli, Roberto},
  booktitle={LREC},
  year={2014}
}

@inproceedings{khot2018scitail,
  title={Scitail: A textual entailment dataset from science question answering},
  author={Khot, Tushar and Sabharwal, Ashish and Clark, Peter},
  booktitle={AAAI},
  year={2018}
}


@inproceedings{yang2019xlnet,
  title={Xlnet: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  booktitle={NeurIPS},
  year={2019}
}

@article{raffel2019exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={arXiv preprint arXiv:1910.10683},
  year={2019}
}

@inproceedings{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{db2021,
  title={Distance-based regularisation of deep networks for fine-tuning},
  author={Gouk H, Hospedales T M, Pontil M},
  booktitle={ICLR},
  year={2021}
}




