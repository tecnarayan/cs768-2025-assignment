@article{maitra1970stochastic,
  title={On stochastic games},
  author={Maitra, A and Parthasarathy, T},
  journal={Journal of Optimization Theory and Applications},
  volume={5},
  number={4},
  pages={289--300},
  year={1970},
  publisher={Springer}
}
@inproceedings{abbasi2011improved,
  title={Improved Algorithms for Linear Stochastic Bandits.},
  author={Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
  booktitle={NIPS},
  volume={11},
  pages={2312--2320},
  year={2011}
}

@inproceedings{cai2020provably,
  title={Provably efficient exploration in policy optimization},
  author={Cai, Qi and Yang, Zhuoran and Jin, Chi and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={1283--1294},
  year={2020},
  organization={PMLR}
}

@article{jin2020pessimism,
  title={Is Pessimism Provably Efficient for Offline RL?},
  author={Jin, Ying and Yang, Zhuoran and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2012.15085},
  year={2020}
}

@inproceedings{xie2020learning,
  title={Learning zero-sum simultaneous-move markov games using function approximation and correlated equilibrium},
  author={Xie, Qiaomin and Chen, Yudong and Wang, Zhaoran and Yang, Zhuoran},
  booktitle={Conference on Learning Theory},
  pages={3674--3682},
  year={2020},
  organization={PMLR}
}


@inproceedings{yang2019sample,
  title={Sample-optimal parametric Q-learning using linearly additive features},
  author={Yang, Lin and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={6995--7004},
  year={2019},
  organization={PMLR}
}

@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2137--2143},
  year={2020},
  organization={PMLR}
}
@article{vershynin2010introduction,
  title={Introduction to the non-asymptotic analysis of random matrices},
  author={Vershynin, Roman},
  journal={arXiv preprint arXiv:1011.3027},
  year={2010}
}
@misc{tropp2015introduction,
      title={An Introduction to Matrix Concentration Inequalities}, 
      author={Joel A. Tropp},
      year={2015},
      eprint={1501.01571},
      archivePrefix={arXiv},
      primaryClass={math.PR}
}

@article{xie2021bellman,
  title={Bellman-consistent Pessimism for Offline Reinforcement Learning},
  author={Xie, Tengyang and Cheng, Ching-An and Jiang, Nan and Mineiro, Paul and Agarwal, Alekh},
  journal={arXiv preprint arXiv:2106.06926},
  year={2021}
}

@article{uehara2021pessimistic,
  title={Pessimistic Model-based Offline Reinforcement Learning under Partial Coverage},
  author={Uehara, Masatoshi and Sun, Wen},
  journal={arXiv preprint arXiv:2107.06226},
  year={2021}
}

@article{cui2022offline,
  title={When is Offline Two-Player Zero-Sum Markov Game Solvable?},
  author={Cui, Qiwen and Du, Simon S},
  journal={arXiv preprint arXiv:2201.03522},
  year={2022}
}

@article{zhang2021multi,
  title={Multi-agent reinforcement learning: A selective overview of theories and algorithms},
  author={Zhang, Kaiqing and Yang, Zhuoran and Ba{\c{s}}ar, Tamer},
  journal={Handbook of Reinforcement Learning and Control},
  pages={321--384},
  year={2021},
  publisher={Springer}
}

%%%% Empirical examples
@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{brown2019superhuman,
  title={Superhuman AI for multiplayer poker},
  author={Brown, Noam and Sandholm, Tuomas},
  journal={Science},
  volume={365},
  number={6456},
  pages={885--890},
  year={2019},
  publisher={American Association for the Advancement of Science}
}

@article{shalev2016safe,
  title={Safe, multi-agent, reinforcement learning for autonomous driving},
  author={Shalev-Shwartz, Shai and Shammah, Shaked and Shashua, Amnon},
  journal={arXiv preprint arXiv:1610.03295},
  year={2016}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}

%%%%

@book{filar2012competitive,
  title={Competitive Markov decision processes},
  author={Filar, Jerzy and Vrieze, Koos},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@article{shapley1953stochastic,
  title={Stochastic games},
  author={Shapley, Lloyd S},
  journal={Proceedings of the national academy of sciences},
  volume={39},
  number={10},
  pages={1095--1100},
  year={1953},
  publisher={National Acad Sciences}
}


%%%% MG when model is known
@inproceedings{littman2001friend,
  title={Friend-or-foe Q-learning in general-sum games},
  author={Littman, Michael L},
  booktitle={ICML},
  volume={1},
  pages={322--328},
  year={2001}
}

@article{hu2003nash,
  title={Nash Q-learning for general-sum stochastic games},
  author={Hu, Junling and Wellman, Michael P},
  journal={Journal of machine learning research},
  volume={4},
  number={Nov},
  pages={1039--1069},
  year={2003}
}

@article{hansen2013strategy,
  title={Strategy iteration is strongly polynomial for 2-player turn-based stochastic games with a constant discount factor},
  author={Hansen, Thomas Dueholm and Miltersen, Peter Bro and Zwick, Uri},
  journal={Journal of the ACM (JACM)},
  volume={60},
  number={1},
  pages={1--16},
  year={2013},
  publisher={ACM New York, NY, USA}
}

@article{wei2020linear,
  title={Linear last-iterate convergence in constrained saddle-point optimization},
  author={Wei, Chen-Yu and Lee, Chung-Wei and Zhang, Mengxiao and Luo, Haipeng},
  journal={arXiv preprint arXiv:2006.09517},
  year={2020}
}
%%%%


%%%% MG when a simulator is available
@article{wei2017online,
  title={Online reinforcement learning in stochastic games},
  author={Wei, Chen-Yu and Hong, Yi-Te and Lu, Chi-Jen},
  journal={arXiv preprint arXiv:1712.00579},
  year={2017}
}

@article{jia2019feature,
  title={Feature-based q-learning for two-player stochastic games},
  author={Jia, Zeyu and Yang, Lin F and Wang, Mengdi},
  journal={arXiv preprint arXiv:1906.00423},
  year={2019}
}

@inproceedings{sidford2020solving,
  title={Solving discounted stochastic two-player games with near-optimal time and sample complexity},
  author={Sidford, Aaron and Wang, Mengdi and Yang, Lin and Ye, Yinyu},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2992--3002},
  year={2020},
  organization={PMLR}
}

@article{zhang2020model,
  title={Model-based multi-agent rl in zero-sum markov games with near-optimal sample complexity},
  author={Zhang, Kaiqing and Kakade, Sham M and Ba{\c{s}}ar, Tamer and Yang, Lin F},
  journal={arXiv preprint arXiv:2007.07461},
  year={2020}
}

@article{wei2021last,
  title={Last-iterate convergence of decentralized optimistic gradient descent/ascent in infinite-horizon competitive Markov games},
  author={Wei, Chen-Yu and Lee, Chung-Wei and Zhang, Mengxiao and Luo, Haipeng},
  journal={arXiv preprint arXiv:2102.04540},
  year={2021}
}
%%%%


%%%% tabular and linear 2-PLAYER MG
@inproceedings{bai2020provable,
  title={Provable self-play algorithms for competitive reinforcement learning},
  author={Bai, Yu and Jin, Chi},
  booktitle={International Conference on Machine Learning},
  pages={551--560},
  year={2020},
  organization={PMLR}
}

@article{bai2020near,
  title={Near-optimal reinforcement learning with self-play},
  author={Bai, Yu and Jin, Chi and Yu, Tiancheng},
  journal={arXiv preprint arXiv:2006.12007},
  year={2020}
}

@inproceedings{liu2021sharp,
  title={A sharp analysis of model-based reinforcement learning with self-play},
  author={Liu, Qinghua and Yu, Tiancheng and Bai, Yu and Jin, Chi},
  booktitle={International Conference on Machine Learning},
  pages={7001--7010},
  year={2021},
  organization={PMLR}
}

@article{chen2021almost,
  title={Almost Optimal Algorithms for Two-player Markov Games with Linear Function Approximation},
  author={Chen, Zixiang and Zhou, Dongruo and Gu, Quanquan},
  journal={arXiv preprint arXiv:2102.07404},
  year={2021}
}
%%%%

%%%% MG with gfa
@article{jin2021power,
  title={The Power of Exploiter: Provable Multi-Agent RL in Large State Spaces},
  author={Jin, Chi and Liu, Qinghua and Yu, Tiancheng},
  journal={arXiv preprint arXiv:2106.03352},
  year={2021}
}

@article{huang2021towards,
  title={Towards general function approximation in zero-sum markov games},
  author={Huang, Baihe and Lee, Jason D and Wang, Zhaoran and Yang, Zhuoran},
  journal={arXiv preprint arXiv:2107.14702},
  year={2021}
}
%%%%

@article{abe2020off,
  title={Off-Policy Exploitability-Evaluation in Two-Player Zero-Sum Markov Games},
  author={Abe, Kenshi and Kaneko, Yusuke},
  journal={arXiv preprint arXiv:2007.02141},
  year={2020}
}

@article{zhong2021can,
  title={Can Reinforcement Learning Find Stackelberg-Nash Equilibria in General-Sum Markov Games with Myopic Followers?},
  author={Zhong, Han and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  journal={arXiv preprint arXiv:2112.13521},
  year={2021}
}


%%% Lam method
@book{le2012asymptotic,
  title={Asymptotic methods in statistical decision theory},
  author={Le Cam, Lucien},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@misc{yu1997festschrift,
  title={Festschrift for Lucien Le Cam},
  author={Yu, Bin and Assouad, Fano and Le Cam, Lucien},
  year={1997},
  publisher={Springer}
}
%%%

%%%% Offline
@article{precup2000eligibility,
  title={Eligibility traces for off-policy policy evaluation},
  author={Precup, Doina},
  journal={Computer Science Department Faculty Publication Series},
  pages={80},
  year={2000}
}

@article{antos2008learning,
  title={Learning near-optimal policies with Bellman-residual minimization based fitted policy iteration and a single sample path},
  author={Antos, Andr{\'a}s and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  journal={Machine Learning},
  volume={71},
  number={1},
  pages={89--129},
  year={2008},
  publisher={Springer}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{rashidinejad2021bridging,
  title={Bridging offline reinforcement learning and imitation learning: A tale of pessimism},
  author={Rashidinejad, Paria and Zhu, Banghua and Ma, Cong and Jiao, Jiantao and Russell, Stuart},
  journal={arXiv preprint arXiv:2103.12021},
  year={2021}
}

@article{yin2021towards,
  title={Towards instance-optimal offline reinforcement learning with pessimism},
  author={Yin, Ming and Wang, Yu-Xiang},
  journal={Advances in neural information processing systems},
  volume={34},
  year={2021}
}

@article{uehara2021representation,
  title={Representation Learning for Online and Offline RL in Low-rank MDPs},
  author={Uehara, Masatoshi and Zhang, Xuezhou and Sun, Wen},
  journal={arXiv preprint arXiv:2110.04652},
  year={2021}
}

@article{zanette2021provable,
  title={Provable benefits of actor-critic methods for offline reinforcement learning},
  author={Zanette, Andrea and Wainwright, Martin J and Brunskill, Emma},
  journal={Advances in neural information processing systems},
  volume={34},
  year={2021}
}
%%%%

%%%% Example
@inproceedings{wang2018supervised,
  title={Supervised reinforcement learning with recurrent neural network for dynamic treatment recommendation},
  author={Wang, Lu and Zhang, Wei and He, Xiaofeng and Zha, Hongyuan},
  booktitle={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={2447--2456},
  year={2018}
}

@article{pan2017agile,
  title={Agile autonomous driving using end-to-end deep imitation learning},
  author={Pan, Yunpeng and Cheng, Ching-An and Saigol, Kamil and Lee, Keuntaek and Yan, Xinyan and Theodorou, Evangelos and Boots, Byron},
  journal={arXiv preprint arXiv:1709.07174},
  year={2017}
}

@article{fu2020d4rl,
  title={D4rl: Datasets for deep data-driven reinforcement learning},
  author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.07219},
  year={2020}
}

@article{berner2019dota,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and D{k{e}}biak, Przemys{l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}
%%%%

@article{du2019good,
  title={Is a good representation sufficient for sample efficient reinforcement learning?},
  author={Du, Simon S and Kakade, Sham M and Wang, Ruosong and Yang, Lin F},
  journal={arXiv preprint arXiv:1910.03016},
  year={2019}
}

@article{moulin1978strategically,
  title={Strategically zero-sum games: the class of games whose completely mixed equilibria cannot be improved upon},
  author={Moulin, Herv{\'e} and Vial, J-P},
  journal={International Journal of Game Theory},
  volume={7},
  number={3-4},
  pages={201--221},
  year={1978},
  publisher={Springer}
}

@article{aumann1987correlated,
  title={Correlated equilibrium as an expression of Bayesian rationality},
  author={Aumann, Robert J},
  journal={Econometrica: Journal of the Econometric Society},
  pages={1--18},
  year={1987},
  publisher={JSTOR}
}

@book{lattimore2020bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}

@inproceedings{duan2020minimax,
  title={Minimax-optimal off-policy evaluation with linear function approximation},
  author={Duan, Yaqi and Jia, Zeyu and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={2701--2709},
  year={2020},
  organization={PMLR}
}

@article{donoho1994ideal,
  title={Ideal spatial adaptation by wavelet shrinkage},
  author={Donoho, David L and Johnstone, Jain M},
  journal={biometrika},
  volume={81},
  number={3},
  pages={425--455},
  year={1994},
  publisher={Oxford University Press}
}

@article{fan2001variable,
  title={Variable selection via nonconcave penalized likelihood and its oracle properties},
  author={Fan, Jianqing and Li, Runze},
  journal={Journal of the American statistical Association},
  volume={96},
  number={456},
  pages={1348--1360},
  year={2001},
  publisher={Taylor \& Francis}
}

@article{zou2006adaptive,
  title={The adaptive lasso and its oracle properties},
  author={Zou, Hui},
  journal={Journal of the American statistical association},
  volume={101},
  number={476},
  pages={1418--1429},
  year={2006},
  publisher={Taylor \& Francis}
}