\begin{thebibliography}{16}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2010)Agarwal, Dekel, and Xiao]{AgarwalDekelXiao10}
Agarwal, A., Dekel, O., and Xiao, L.
\newblock Optimal algorithms for online convex optimization with multi-point
  bandit feedback.
\newblock In \emph{COLT}, 2010.

\bibitem[Audibert \& Bubeck(2009)Audibert and Bubeck]{AudBub09}
Audibert, J.-Y. and Bubeck, S.
\newblock Minimax policies for adversarial and stochastic bandits.
\newblock In \emph{COLT}, 2009.

\bibitem[Audibert et~al.(2010)Audibert, Bubeck, and Munos]{audbumu10}
Audibert, J.-Y., Bubeck, S., and Munos, R.
\newblock Best arm identification in multi-armed bandits.
\newblock In \emph{COLT}, 2010.

\bibitem[Auer et~al.(2002)Auer, Cesa-Bianchi, Freund, and
  Schapire]{AuerCesFrSc02}
Auer, P., Cesa-Bianchi, N., Freund, Y., and Schapire, R.
\newblock The nonstochastic multiarmed bandit problem.
\newblock \emph{SIAM J. Comput.}, 32\penalty0 (1):\penalty0 48--77, 2002.

\bibitem[Avner \& Mannor(2011)Avner and Mannor]{AvnerMannor11}
Avner, O. and Mannor, S.
\newblock Stochastic bandits with pathwise constraints.
\newblock In \emph{50th IEEE Conference on Decision and Control}, 2011.

\bibitem[Avner et~al.(2012)Avner, Mannor, and Shamir]{AMSFullVersion12}
Avner, O., Mannor, S., and Shamir, O.
\newblock Decoupling exploration and exploitation in multi-armed bandits.
\newblock arXiv:1205.2874v1 [cs.LG], 2012.

\bibitem[Bubeck et~al.(2011)Bubeck, Munos, and Stoltz]{bumust11}
Bubeck, S., Munos, R., and Stoltz, G.
\newblock Pure exploration in finitely-armed and continuous-armed bandits.
\newblock \emph{Theor. Comput. Sci.}, 412\penalty0 (19):\penalty0 1832--1852,
  2011.

\bibitem[Cesa-Bianchi \& Lugosi(2006)Cesa-Bianchi and Lugosi]{CesaBianchiLu06}
Cesa-Bianchi, N. and Lugosi, G.
\newblock \emph{Prediction, learning, and games}.
\newblock Cambridge University Press, 2006.

\bibitem[Even-Dar et~al.(2006)Even-Dar, Mannor, and
  Mansour]{Even-DarMannorMansor06}
Even-Dar, E., Mannor, S., and Mansour, Y.
\newblock Action elimination and stopping conditions for the multi-armed bandit
  and reinforcement learning problems.
\newblock \emph{Journal of Machine Learning Research}, 7:\penalty0 1079--1105,
  2006.

\bibitem[Freedman(1975)]{Freedman75}
Freedman, D.A.
\newblock On tail probabilities for martingales.
\newblock \emph{Annals of Probability}, 3:\penalty0 100--118, 1975.

\bibitem[Garivier \& Moulines(2011)Garivier and Moulines]{GariMou11}
Garivier, A. and Moulines, E.
\newblock On upper-confidence bound policies for switching bandit problems.
\newblock In \emph{ALT}, 2011.

\bibitem[Herbster \& Warmuth(1998)Herbster and Warmuth]{HerbsterWarmuth98}
Herbster, M. and Warmuth, M.~K.
\newblock Tracking the best expert.
\newblock \emph{Machine Learning}, 32\penalty0 (2):\penalty0 151--178, 1998.

\bibitem[Lai et~al.(2008)Lai, Jiang, and Poor]{LaiJiangPoor08}
Lai, L., Jiang, H., and Poor, H.~V.
\newblock Medium access in cognitive radio networks: A competitive multi-armed
  bandit framework.
\newblock In \emph{Proc. Asilomar Conference on Signals, Systems, and
  Computers}, pp.\  98--102, 2008.

\bibitem[Liu \& Zhao(2010)Liu and Zhao]{LiuZhao10}
Liu, K. and Zhao, Q.
\newblock Distributed learning in multi-armed bandit with multiple players.
\newblock \emph{IEEE Transactions on Signal Processing}, 58\penalty0
  (11):\penalty0 5667 --5681, nov. 2010.

\bibitem[Oppermann et~al.(2004)Oppermann, Hamalainen, and Iinatti]{UWBBook}
Oppermann, I., Hamalainen, M., and Iinatti, J.
\newblock \emph{UWB Theory and Application}.
\newblock Wiley, 2004.

\bibitem[Yu \& Mannor(2009)Yu and Mannor]{YuMa09}
Yu, J.~Y. and Mannor, S.
\newblock Piecewise-stationary bandit problems with side observations.
\newblock In \emph{ICML}, 2009.

\end{thebibliography}
