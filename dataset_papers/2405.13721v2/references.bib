@article{zhang2017understanding,
  title={Understanding deep learning requires rethinking generalization. ICLR 2017},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1611.03530},
  year={2017}
}

@article{zhang2021understanding,
  title={Understanding deep learning (still) requires rethinking generalization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  journal={Communications of the ACM},
  volume={64},
  number={3},
  pages={107--115},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{jiang2019fantastic,
  title={Fantastic generalization measures and where to find them},
  author={Jiang, Yiding and Neyshabur, Behnam and Mobahi, Hossein and Krishnan, Dilip and Bengio, Samy},
  journal={arXiv preprint arXiv:1912.02178},
  year={2019}
}

@article{zhang2023optimistic,
  title={Optimistic Estimate Uncovers the Potential of Nonlinear Models},
  author={Zhang, Yaoyu and Zhang, Zhongwang and Zhang, Leyang and Bai, Zhiwei and Luo, Tao and Xu, Zhi-Qin John},
  journal={arXiv preprint arXiv:2307.08921},
  year={2023}
}

@article{zhang2022linear,
  title={Linear stability hypothesis and rank stratification for nonlinear models},
  author={Zhang, Yaoyu and Zhang, Zhongwang and Zhang, Leyang and Bai, Zhiwei and Luo, Tao and Xu, Zhi-Qin John},
  journal={arXiv preprint arXiv:2211.11623},
  year={2022}
}

@article{gunasekar2017implicit,
  title={Implicit regularization in matrix factorization},
  author={Gunasekar, Suriya and Woodworth, Blake E and Bhojanapalli, Srinadh and Neyshabur, Behnam and Srebro, Nati},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{arora2019implicit,
  title={Implicit regularization in deep matrix factorization},
  author={Arora, Sanjeev and Cohen, Nadav and Hu, Wei and Luo, Yuping},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{razin2020implicit,
  title={Implicit regularization in deep learning may not be explainable by norms},
  author={Razin, Noam and Cohen, Nadav},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={21174--21187},
  year={2020}
}

@inproceedings{ji2019gradient,
  title={Gradient descent aligns the layers of deep linear networks},
  author={Ji, Ziwei and Telgarsky, Matus},
  booktitle={7th International Conference on Learning Representations, ICLR 2019},
  year={2019}
}

@article{gunasekar2018implicit,
  title={Implicit bias of gradient descent on linear convolutional networks},
  author={Gunasekar, Suriya and Lee, Jason D and Soudry, Daniel and Srebro, Nati},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{gidel2019implicit,
  title={Implicit regularization of discrete gradient dynamics in linear neural networks},
  author={Gidel, Gauthier and Bach, Francis and Lacoste-Julien, Simon},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{gissin2019implicit,
  title={The Implicit Bias of Depth: How Incremental Learning Drives Generalization},
  author={Gissin, Daniel and Shalev-Shwartz, Shai and Daniely, Amit},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{belabbas2020implicit,
  title={On implicit regularization: Morse functions and applications to matrix factorization},
  author={Belabbas, Mohamed Ali},
  journal={arXiv preprint arXiv:2001.04264},
  year={2020}
}

@article{zhou2022towards,
  title={Towards understanding the condensation of neural networks at initial training},
  author={Zhou, Hanxu and Qixuan, Zhou and Luo, Tao and Zhang, Yaoyu and Xu, Zhi-Qin},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={2184--2196},
  year={2022}
}

@article{zhang2021embedding,
  title={Embedding principle of loss landscape of deep neural networks},
  author={Zhang, Yaoyu and Zhang, Zhongwang and Luo, Tao and Xu, Zhiqin J},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={14848--14859},
  year={2021}
}

@article{embedding2021long,           
  title={Embedding Principle: A Hierarchical Structure of Loss Landscape of Deep Neural Networks},
  author={Yaoyu Zhang and
               Yuqing Li and
               Zhongwang Zhang and
               Tao Luo and
               Zhi{-}Qin John Xu},
  journal={Journal of Machine Learning},
  volume={1},                      
  number={1},               
  pages={60--113},              
  year={2022},                      
}

@article{bai2022embedding,
  title={Embedding principle in depth for the loss landscape analysis of deep neural networks},
  author={Bai, Zhiwei and Luo, Tao and Xu, Zhi-Qin John and Zhang, Yaoyu},
  journal={arXiv preprint arXiv:2205.13283},
  year={2022}
}

@article{fukumizu2019semi,
  title={Semi-flat minima and saddle points by embedding neural networks to overparameterization},
  author={Fukumizu, Kenji and Yamaguchi, Shoichiro and Mototake, Yoh-ichi and Tanaka, Mirai},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={13868--13876},
  year={2019}
}
@InProceedings{csimcsek2021geometry,
  title = 	 {Geometry of the Loss Landscape in Overparameterized Neural Networks: Symmetries and Invariances},
  author =       {Simsek, Berfin and Ged, Fran{\c{c}}ois and Jacot, Arthur and Spadaro, Francesco and Hongler, Clement and Gerstner, Wulfram and Brea, Johanni},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {9722--9732},
  year = 	 {2021},
  publisher =    {PMLR},
}

@inproceedings{li2020towards,
  title={Towards Resolving the Implicit Bias of Gradient Descent for Matrix Factorization: Greedy Low-Rank Learning},
  author={Li, Zhiyuan and Luo, Yuping and Lyu, Kaifeng},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{jin2023understanding,
  title={Understanding incremental learning of gradient descent: A fine-grained analysis of matrix sensing},
  author={Jin, Jikai and Li, Zhiyuan and Lyu, Kaifeng and Du, Simon Shaolei and Lee, Jason D},
  booktitle={International Conference on Machine Learning},
  pages={15200--15238},
  year={2023},
  organization={PMLR}
}

@inproceedings{li2018algorithmic,
  title={Algorithmic regularization in over-parameterized matrix sensing and neural networks with quadratic activations},
  author={Li, Yuanzhi and Ma, Tengyu and Zhang, Hongyang},
  booktitle={Conference On Learning Theory},
  pages={2--47},
  year={2018},
  organization={PMLR}
}

@article{luo2021phase,
  title={Phase diagram for two-layer ReLU neural networks at infinite-width limit},
  author={Luo, Tao and Xu, Zhi-Qin John and Ma, Zheng and Zhang, Yaoyu},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={71},
  pages={1--47},
  year={2021}
}

@article{chizat2019lazy,
  title={On lazy training in differentiable programming},
  author={Chizat, Lenaic and Oyallon, Edouard and Bach, Francis},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{lee2019first,
  title={First-order methods almost always avoid strict saddle points},
  author={Lee, Jason D and Panageas, Ioannis and Piliouras, Georgios and Simchowitz, Max and Jordan, Michael I and Recht, Benjamin},
  journal={Mathematical programming},
  volume={176},
  pages={311--337},
  year={2019},
  publisher={Springer}
}

@inproceedings{lee2016gradient,
  title={Gradient descent only converges to minimizers},
  author={Lee, Jason D and Simchowitz, Max and Jordan, Michael I and Recht, Benjamin},
  booktitle={Conference on learning theory},
  pages={1246--1257},
  year={2016},
  organization={PMLR}
}

@article{stoger2021small,
  title={Small random initialization is akin to spectral learning: Optimization and generalization guarantees for overparameterized low-rank matrix reconstruction},
  author={St{\"o}ger, Dominik and Soltanolkotabi, Mahdi},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={23831--23843},
  year={2021}
}

@inproceedings{du2018power,
  title={On the power of over-parametrization in neural networks with quadratic activation},
  author={Du, Simon and Lee, Jason},
  booktitle={International conference on machine learning},
  pages={1329--1338},
  year={2018},
  organization={PMLR}
}

@article{jacot2021saddle,
  title={Saddle-to-saddle dynamics in deep linear networks: Small initialization training, symmetry, and sparsity},
  author={Jacot, Arthur and Ged, Fran{\c{c}}ois and {\c{S}}im{\c{s}}ek, Berfin and Hongler, Cl{\'e}ment and Gabriel, Franck},
  journal={arXiv preprint arXiv:2106.15933},
  year={2021}
}

@article{jiang2023algorithmic,
  title={Algorithmic regularization in model-free overparametrized asymmetric matrix factorization},
  author={Jiang, Liwei and Chen, Yudong and Ding, Lijun},
  journal={SIAM Journal on Mathematics of Data Science},
  volume={5},
  number={3},
  pages={723--744},
  year={2023},
  publisher={SIAM}
}

@article{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}