\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and
  Wagner]{athalye_obfuscated_2018-1}
Athalye, A., Carlini, N., and Wagner, D.
\newblock Obfuscated {{Gradients Give}} a {{False Sense}} of {{Security}}:
  {{Circumventing Defenses}} to {{Adversarial Examples}}.
\newblock In \emph{Proc. of {{ICML}}}, pp.\  274--283, July 2018.

\bibitem[Bengio(2012)]{bengio_deep_2012}
Bengio, Y.
\newblock Deep {{Learning}} of {{Representations}} for {{Unsupervised}} and
  {{Transfer Learning}}.
\newblock In \emph{Proc. of {{ICML}}}, pp.\  17--36, June 2012.

\bibitem[Carlini \& Wagner(2017)Carlini and Wagner]{carlini_towards_2017-1}
Carlini, N. and Wagner, D.
\newblock Towards {{Evaluating}} the {{Robustness}} of {{Neural Networks}}.
\newblock In \emph{Proc. of {{IEEE S}}\&{{P}}}, pp.\  39--57, May 2017.

\bibitem[Cisse et~al.(2017)Cisse, Bojanowski, Grave, Dauphin, and
  Usunier]{cisse_parseval_2017}
Cisse, M., Bojanowski, P., Grave, E., Dauphin, Y., and Usunier, N.
\newblock Parseval networks: Improving robustness to adversarial examples.
\newblock In \emph{Proc. of {{ICML}}}, pp.\  854--863, August 2017.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow_explaining_2015}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and {{Harnessing Adversarial Examples}}.
\newblock In \emph{Proc. of {{ICLR}}}, March 2015.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he_deep_2016}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep {{Residual Learning}} for {{Image Recognition}}.
\newblock In \emph{Proc. of {{CVPR}}}, pp.\  770--778, 2016.

\bibitem[Kannan et~al.(2018)Kannan, Kurakin, and
  Goodfellow]{kannan_adversarial_2018}
Kannan, H., Kurakin, A., and Goodfellow, I.
\newblock Adversarial {{Logit Pairing}}.
\newblock \emph{arXiv preprint arXiv:1803.06373}, March 2018.

\bibitem[Kornblith et~al.(2019)Kornblith, Shlens, and
  Le]{kornblith_better_2019}
Kornblith, S., Shlens, J., and Le, Q.~V.
\newblock Do {{Better ImageNet Models Transfer Better}}?
\newblock In \emph{Proc. of {{CVPR}}}, pp.\  2661--2671, 2019.

\bibitem[Kurakin et~al.(2017)Kurakin, Goodfellow, and
  Bengio]{kurakin_adversarial_2017}
Kurakin, A., Goodfellow, I., and Bengio, S.
\newblock Adversarial {{Machine Learning}} at {{Scale}}.
\newblock In \emph{Proc. of {{ICLR}}}, February 2017.

\bibitem[Li \& Li(2018)Li and Li]{google_transfer_learning}
Li, F. and Li, J.
\newblock Cloud automl: Making ai accessible to every business.
\newblock
  \url{https://blog.google/products/google-cloud/cloud-automl-making-ai-accessible-every-business/},
  2018.

\bibitem[Liakhovich \& Mbemba(2017)Liakhovich and
  Mbemba]{microsoft_transfer_learning}
Liakhovich, O. and Mbemba, C.
\newblock Food classification with custom vision service.
\newblock
  \url{https://devblogs.microsoft.com/cse/2017/05/12/food-classification-custom-vision-service/},
  2017.

\bibitem[Lin et~al.(2019)Lin, Gan, and Han]{lin_defensive_2019-1}
Lin, J., Gan, C., and Han, S.
\newblock Defensive {{Quantization}}: {{When Efficiency Meets Robustness}}.
\newblock In \emph{Proc. of {{ICLR}}}, April 2019.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry_towards_2018}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards {{Deep Learning Models Resistant}} to {{Adversarial
  Attacks}}.
\newblock In \emph{Proc. of {{ICLR}}}, 2018.

\bibitem[Miyato et~al.(2018)Miyato, Kataoka, Koyama, and
  Yoshida]{miyato_spectral_2018}
Miyato, T., Kataoka, T., Koyama, M., and Yoshida, Y.
\newblock Spectral {{Normalization}} for {{Generative Adversarial Networks}}.
\newblock In \emph{Proc. of {{ICLR}}}, February 2018.

\bibitem[{Moosavi-Dezfooli} et~al.(2016){Moosavi-Dezfooli}, Fawzi, and
  Frossard]{moosavi-dezfooli_deepfool_2016-1}
{Moosavi-Dezfooli}, S.-M., Fawzi, A., and Frossard, P.
\newblock {{DeepFool}}: {{A Simple}} and {{Accurate Method}} to {{Fool Deep
  Neural Networks}}.
\newblock In \emph{Proc. of {{CVPR}}}, pp.\  2574--2582, June 2016.

\bibitem[Pan \& Yang(2010)Pan and Yang]{pan_survey_2010}
Pan, S.~J. and Yang, Q.
\newblock A {{Survey}} on {{Transfer Learning}}.
\newblock \emph{IEEE Transactions on Knowledge and Data Engineering},
  22\penalty0 (10):\penalty0 1345--1359, October 2010.

\bibitem[Papernot \& McDaniel(2017)Papernot and
  McDaniel]{papernot_extending_2017}
Papernot, N. and McDaniel, P.
\newblock Extending {{Defensive Distillation}}.
\newblock \emph{arXiv preprint arXiv:1705.05264}, May 2017.

\bibitem[Papernot et~al.(2016{\natexlab{a}})Papernot, McDaniel, Jha,
  Fredrikson, Celik, and Swami]{papernot_limitations_2016-1}
Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.~B., and Swami,
  A.
\newblock The {{Limitations}} of {{Deep Learning}} in {{Adversarial Settings}}.
\newblock In \emph{Proc. of {{EuroS}}\&{{P}}}, pp.\  372--387, March
  2016{\natexlab{a}}.

\bibitem[Papernot et~al.(2016{\natexlab{b}})Papernot, McDaniel, Wu, Jha, and
  Swami]{papernot_distillation_2016-1}
Papernot, N., McDaniel, P., Wu, X., Jha, S., and Swami, A.
\newblock Distillation as a {{Defense}} to {{Adversarial Perturbations Against
  Deep Neural Networks}}.
\newblock In \emph{Proc. of {{IEEE S}}\&{{P}}}, pp.\  582--597, May
  2016{\natexlab{b}}.

\bibitem[Qian \& Wegman(2019)Qian and Wegman]{qian_l2-nonexpansive_2019}
Qian, H. and Wegman, M.~N.
\newblock L2-{{Nonexpansive Neural Networks}}.
\newblock In \emph{Proc. of {{ICLR}}}, February 2019.

\bibitem[Salman et~al.(2020)Salman, Ilyas, Engstrom, Kapoor, and
  Madry]{salman_adversarially_2020}
Salman, H., Ilyas, A., Engstrom, L., Kapoor, A., and Madry, A.
\newblock Do {{Adversarially Robust ImageNet Models Transfer Better}}?
\newblock In \emph{Proc. of {{NeurIPS}}}, volume~33, pp.\  3533--3545, 2020.

\bibitem[Schmidt et~al.(2018)Schmidt, Santurkar, Tsipras, Talwar, and
  Madry]{schmidt_adversarially_2018}
Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., and Madry, A.
\newblock Adversarially {{Robust Generalization Requires More Data}}.
\newblock In \emph{Proc. of {{NeurIPS}}}, pp.\  5014--5026, 2018.

\bibitem[Shafahi et~al.(2019)Shafahi, Najibi, Ghiasi, Xu, Dickerson, Studer,
  Davis, Taylor, and Goldstein]{shafahi_adversarial_2019}
Shafahi, A., Najibi, M., Ghiasi, M.~A., Xu, Z., Dickerson, J., Studer, C.,
  Davis, L.~S., Taylor, G., and Goldstein, T.
\newblock Adversarial training for free!
\newblock In \emph{Proc. of {{NeurIPS}}}, pp.\  3358--3369, 2019.

\bibitem[Shafahi et~al.(2020)Shafahi, Saadatpanah, Zhu, Ghiasi, Studer, Jacobs,
  and Goldstein]{shafahi_adversarially_2020}
Shafahi, A., Saadatpanah, P., Zhu, C., Ghiasi, A., Studer, C., Jacobs, D., and
  Goldstein, T.
\newblock Adversarially robust transfer learning.
\newblock In \emph{Proc. of {{ICLR}}}, February 2020.

\bibitem[Shu et~al.(2018)Shu, Bui, Narui, and Ermon]{shu_dirt-t_2018}
Shu, R., Bui, H.~H., Narui, H., and Ermon, S.
\newblock A {{DIRT}}-{{T Approach}} to {{Unsupervised Domain Adaptation}}.
\newblock In \emph{Proc. of {{ICLR}}}, 2018.

\bibitem[Song et~al.(2018)Song, Kim, Nowozin, Ermon, and
  Kushman]{song_pixeldefend_2018}
Song, Y., Kim, T., Nowozin, S., Ermon, S., and Kushman, N.
\newblock {{PixelDefend}}: {{Leveraging Generative Models}} to {{Understand}}
  and {{Defend}} against {{Adversarial Examples}}.
\newblock In \emph{Proc. of {{ICLR}}}, May 2018.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy_intriguing_2014-1}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock In \emph{Proc. of {{ICLR}}}, February 2014.

\bibitem[Tramer \& Boneh(2019)Tramer and Boneh]{tramer_adversarial_2019}
Tramer, F. and Boneh, D.
\newblock Adversarial {{Training}} and {{Robustness}} for {{Multiple
  Perturbations}}.
\newblock In \emph{Proc. of {{NeurIPS}}}, pp.\  5866--5876, 2019.

\bibitem[Tram{\`e}r et~al.(2018)Tram{\`e}r, Kurakin, Papernot, Goodfellow,
  Boneh, and McDaniel]{tramer_ensemble_2018}
Tram{\`e}r, F., Kurakin, A., Papernot, N., Goodfellow, I., Boneh, D., and
  McDaniel, P.
\newblock Ensemble {{Adversarial Training}}: {{Attacks}} and {{Defenses}}.
\newblock In \emph{Proc. of {{ICLR}}}, 2018.

\bibitem[Tramer et~al.(2020)Tramer, Carlini, Brendel, and
  Madry]{tramer_adaptive_2020}
Tramer, F., Carlini, N., Brendel, W., and Madry, A.
\newblock On {{Adaptive Attacks}} to {{Adversarial Example Defenses}}.
\newblock In \emph{Proc. of {{NeurIPS}}}, volume~33, pp.\  1633--1645, 2020.

\bibitem[Tsipras et~al.(2019)Tsipras, Santurkar, Engstrom, Turner, and
  Madry]{tsipras_robustness_2019}
Tsipras, D., Santurkar, S., Engstrom, L., Turner, A., and Madry, A.
\newblock Robustness {{May Be}} at {{Odds}} with {{Accuracy}}.
\newblock In \emph{Proc. of {{ICLR}}}, September 2019.

\bibitem[Utrera et~al.(2021)Utrera, Kravitz, Erichson, Khanna, and
  Mahoney]{utrera_adversarially-trained_2020}
Utrera, F., Kravitz, E., Erichson, N.~B., Khanna, R., and Mahoney, M.~W.
\newblock Adversarially-{{Trained Deep Nets Transfer Better}}: {{Illustration}}
  on {{Image Classification}}.
\newblock In \emph{Proc. of {{ICLR}}}, 2021.

\bibitem[Wang et~al.(2018)Wang, Yao, Viswanath, Zheng, and
  Zhao]{wang_great_2018}
Wang, B., Yao, Y., Viswanath, B., Zheng, H., and Zhao, B.~Y.
\newblock With {{Great Training Comes Great Vulnerability}}: {{Practical
  Attacks}} against {{Transfer Learning}}.
\newblock In \emph{Proc. of {{USENIX Security}}}, pp.\  1281--1297, 2018.

\bibitem[Wong et~al.(2020)Wong, Rice, and Kolter]{wong_fast_2020}
Wong, E., Rice, L., and Kolter, J.~Z.
\newblock Fast is better than free: {{Revisiting}} adversarial training.
\newblock In \emph{Proc. of {{ICLR}}}, January 2020.

\bibitem[Xie \& Yuille(2019)Xie and Yuille]{xie_intriguing_2019}
Xie, C. and Yuille, A.
\newblock Intriguing properties of adversarial training at scale.
\newblock In \emph{Proc. of {{ICLR}}}, December 2019.

\bibitem[Xie et~al.(2019)Xie, Wu, van~der Maaten, Yuille, and
  He]{xie_feature_2019}
Xie, C., Wu, Y., van~der Maaten, L., Yuille, A.~L., and He, K.
\newblock Feature {{Denoising}} for {{Improving Adversarial Robustness}}.
\newblock In \emph{Proc. of {{CVPR}}}, pp.\  501--509, 2019.

\bibitem[Xie et~al.(2020)Xie, Tan, Gong, Wang, Yuille, and
  Le]{xie_adversarial_2020}
Xie, C., Tan, M., Gong, B., Wang, J., Yuille, A.~L., and Le, Q.~V.
\newblock Adversarial {{Examples Improve Image Recognition}}.
\newblock In \emph{Proc. of {{CVPR}}}, pp.\  819--828, 2020.

\bibitem[Yosinski et~al.(2014)Yosinski, Clune, Bengio, and
  Lipson]{yosinski_how_2014}
Yosinski, J., Clune, J., Bengio, Y., and Lipson, H.
\newblock How transferable are features in deep neural networks?
\newblock In \emph{Proc. of {{NeurIPS}}}, pp.\  3320--3328, 2014.

\bibitem[Zagoruyko \& Komodakis(2017)Zagoruyko and
  Komodakis]{zagoruyko_wide_2017}
Zagoruyko, S. and Komodakis, N.
\newblock Wide {{Residual Networks}}.
\newblock \emph{arXiv preprint arXiv:1605.07146}, June 2017.

\bibitem[Zhang et~al.(2019{\natexlab{a}})Zhang, Zhang, Lu, Zhu, and
  Dong]{zhang_you_2019}
Zhang, D., Zhang, T., Lu, Y., Zhu, Z., and Dong, B.
\newblock You {{Only Propagate Once}}: {{Accelerating Adversarial Training}}
  via {{Maximal Principle}}.
\newblock In \emph{Proc. of {{NeurIPS}}}, pp.\  227--238, 2019{\natexlab{a}}.

\bibitem[Zhang et~al.(2019{\natexlab{b}})Zhang, Yu, Jiao, Xing, Ghaoui, and
  Jordan]{zhang_theoretically_2019}
Zhang, H., Yu, Y., Jiao, J., Xing, E., Ghaoui, L.~E., and Jordan, M.
\newblock Theoretically {{Principled Trade}}-off between {{Robustness}} and
  {{Accuracy}}.
\newblock In \emph{Proc. of {{ICML}}}, pp.\  7472--7482, May
  2019{\natexlab{b}}.

\end{thebibliography}
