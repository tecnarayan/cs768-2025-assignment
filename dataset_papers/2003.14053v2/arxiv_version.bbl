\begin{thebibliography}{10}

\bibitem{athalye_obfuscated_2018}
Anish Athalye, Nicholas Carlini, and David Wagner.
\newblock Obfuscated {{Gradients Give}} a {{False Sense}} of {{Security}}:
  {{Circumventing Defenses}} to {{Adversarial Examples}}.
\newblock {\em arXiv:1802.00420 [cs]}, February 2018.

\bibitem{benning_modern_2018-1}
Martin Benning and Martin Burger.
\newblock Modern regularization methods for inverse problems.
\newblock {\em Acta Numerica}, 27:1--111, May 2018.

\bibitem{bonawitz_towards_2019}
Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex
  Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub Kone{\v c}n{\'y}, Stefano
  Mazzocchi, H.~Brendan McMahan, Timon Van~Overveldt, David Petrou, Daniel
  Ramage, and Jason Roselander.
\newblock Towards {{Federated Learning}} at {{Scale}}: {{System Design}}.
\newblock {\em arXiv:1902.01046 [cs, stat]}, March 2019.

\bibitem{candes_robust_2006}
E.~J. Candes, J.~Romberg, and T.~Tao.
\newblock Robust uncertainty principles: Exact signal reconstruction from
  highly incomplete frequency information.
\newblock {\em IEEE Transactions on Information Theory}, 52(2):489--509,
  February 2006.

\bibitem{chang_reversible_2017}
Bo~Chang, Lili Meng, Eldad Haber, Lars Ruthotto, David Begert, and Elliot
  Holtham.
\newblock Reversible {{Architectures}} for {{Arbitrarily Deep Residual Neural
  Networks}}.
\newblock {\em arXiv:1709.03698 [cs, stat]}, September 2017.

\bibitem{charpiat_input_2019}
Guillaume Charpiat, Nicolas Girard, Loris Felardos, and Yuliya Tarabalka.
\newblock Input {{Similarity}} from the {{Neural Network Perspective}}.
\newblock In {\em Advances in {{Neural Information Processing Systems}} 32},
  pages 5342--5351. {Curran Associates, Inc.}, 2019.

\bibitem{chilimbi_project_2014}
Trishul Chilimbi, Yutaka Suzue, Johnson Apacible, and Karthik Kalyanaraman.
\newblock Project {{Adam}}: {{Building}} an {{Efficient}} and {{Scalable Deep
  Learning Training System}}.
\newblock In {\em 11th \{\vphantom\}{{USENIX}}\vphantom\{\} {{Symposium}} on
  {{Operating Systems Design}} and {{Implementation}}
  (\{\vphantom\}{{OSDI}}\vphantom\{\} 14)}, pages 571--582, 2014.

\bibitem{dosovitskiy_generating_2016}
Alexey Dosovitskiy and Thomas Brox.
\newblock Generating {{Images}} with {{Perceptual Similarity Metrics}} based on
  {{Deep Networks}}.
\newblock In {\em Advances in {{Neural Information Processing Systems}} 29},
  pages 658--666. {Curran Associates, Inc.}, 2016.

\bibitem{dosovitskiy_inverting_2016}
Alexey Dosovitskiy and Thomas Brox.
\newblock Inverting {{Visual Representations With Convolutional Networks}}.
\newblock In {\em Proceedings of the {{IEEE Conference}} on {{Computer Vision}}
  and {{Pattern Recognition}}}, pages 4829--4837, 2016.

\bibitem{fredrikson_model_2015}
Matt Fredrikson, Somesh Jha, and Thomas Ristenpart.
\newblock Model {{Inversion Attacks}} that {{Exploit Confidence Information}}
  and {{Basic Countermeasures}}.
\newblock In {\em Proceedings of the 22nd {{ACM SIGSAC Conference}} on
  {{Computer}} and {{Communications Security}}}, {{CCS}} '15, pages 1322--1333,
  {Denver, Colorado, USA}, October 2015. {Association for Computing Machinery}.

\bibitem{ganju_property_2018}
Karan Ganju, Qi~Wang, Wei Yang, Carl~A. Gunter, and Nikita Borisov.
\newblock Property {{Inference Attacks}} on {{Fully Connected Neural Networks}}
  using {{Permutation Invariant Representations}}.
\newblock In {\em Proceedings of the 2018 {{ACM SIGSAC Conference}} on
  {{Computer}} and {{Communications Security}}}, pages 619--633, {Toronto
  Canada}, January 2018. {ACM}.

\bibitem{goldblum_truth_2019}
Micah Goldblum, Jonas Geiping, Avi Schwarzschild, Michael Moeller, and Tom
  Goldstein.
\newblock Truth or {{Backpropaganda}}? {{An Empirical Investigation}} of {{Deep
  Learning Theory}}.
\newblock {\em arXiv:1910.00359 [cs, math, stat]}, October 2019.

\bibitem{jacobsen_i-revnet_2018}
J{\"o}rn-Henrik Jacobsen, Arnold Smeulders, and Edouard Oyallon.
\newblock I-{{RevNet}}: {{Deep Invertible Networks}}.
\newblock {\em arXiv:1802.07088 [cs, stat]}, February 2018.

\bibitem{jayaraman_evaluating_2019-1}
Bargav Jayaraman and David Evans.
\newblock Evaluating {{Differentially Private Machine Learning}} in
  {{Practice}}.
\newblock {\em arXiv:1902.08874 [cs, stat]}, August 2019.

\bibitem{jochems_developing_2017}
Arthur Jochems, Timo~M. Deist, Issam El~Naqa, Marc Kessler, Chuck Mayo, Jackson
  Reeves, Shruti Jolly, Martha Matuszak, Randall Ten~Haken, Johan {van Soest},
  Cary Oberije, Corinne {Faivre-Finn}, Gareth Price, Dirk {de Ruysscher},
  Philippe Lambin, and Andre Dekker.
\newblock Developing and {{Validating}} a {{Survival Prediction Model}} for
  {{NSCLC Patients Through Distributed Learning Across}} 3 {{Countries}}.
\newblock {\em International Journal of Radiation Oncology*Biology*Physics},
  99(2):344--352, October 2017.

\bibitem{jochems_distributed_2016}
Arthur Jochems, Timo~M. Deist, Johan van Soest, Michael Eble, Paul Bulens,
  Philippe Coucke, Wim Dries, Philippe Lambin, and Andre Dekker.
\newblock Distributed learning: {{Developing}} a predictive model based on data
  from multiple hospitals without data leaving the hospital \textendash{} {{A}}
  real life proof of concept.
\newblock {\em Radiotherapy and Oncology}, 121(3):459--467, December 2016.

\bibitem{kingma_adam:_2015}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: {{A Method}} for {{Stochastic Optimization}}.
\newblock In {\em International {{Conference}} on {{Learning Representations}}
  ({{ICLR}})}, {San Diego}, May 2015.

\bibitem{koh_understanding_2017}
Pang~Wei Koh and Percy Liang.
\newblock Understanding {{Black}}-box {{Predictions}} via {{Influence
  Functions}}.
\newblock In {\em International {{Conference}} on {{Machine Learning}}}, pages
  1885--1894, July 2017.

\bibitem{konecny_federated_2015}
Jakub Kone{\v c}n{\'y}, Brendan McMahan, and Daniel Ramage.
\newblock Federated {{Optimization}}:{{Distributed Optimization Beyond}} the
  {{Datacenter}}.
\newblock {\em arXiv:1511.03575 [cs, math]}, November 2015.

\bibitem{krizhevsky_imagenet_2012}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E. Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1097--1105, 2012.

\bibitem{liu_limited_1989}
Dong~C. Liu and Jorge Nocedal.
\newblock On the limited memory {{BFGS}} method for large scale optimization.
\newblock {\em Mathematical Programming}, 45(1-3):503--528, August 1989.

\bibitem{madry_towards_2017}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards {{Deep Learning Models Resistant}} to {{Adversarial
  Attacks}}.
\newblock {\em arXiv:1706.06083 [cs, stat]}, June 2017.

\bibitem{mahendran_visualizing_2016}
Aravindh Mahendran and Andrea Vedaldi.
\newblock Visualizing {{Deep Convolutional Neural Networks Using Natural
  Pre}}-images.
\newblock {\em International Journal of Computer Vision}, 120(3):233--255,
  December 2016.

\bibitem{mcmahan_communication-efficient_2017}
H.~Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and
  Blaise~Ag{\"u}era y~Arcas.
\newblock Communication-{{Efficient Learning}} of {{Deep Networks}} from
  {{Decentralized Data}}.
\newblock {\em arXiv:1602.05629 [cs]}, February 2017.

\bibitem{mcmahan_learning_2018}
H.~Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li~Zhang.
\newblock Learning {{Differentially Private Recurrent Language Models}}.
\newblock {\em arXiv:1710.06963 [cs]}, February 2018.

\bibitem{melis_exploiting_2019}
Luca Melis, Congzheng Song, Emiliano De~Cristofaro, and Vitaly Shmatikov.
\newblock Exploiting {{Unintended Feature Leakage}} in {{Collaborative
  Learning}}.
\newblock In {\em 2019 {{IEEE Symposium}} on {{Security}} and {{Privacy}}
  ({{SP}})}, pages 691--706, May 2019.

\bibitem{phong_privacy-preserving_2017-1}
Le~Trieu Phong, Yoshinori Aono, Takuya Hayashi, Lihua Wang, and Shiho Moriai.
\newblock Privacy-{{Preserving Deep Learning}}: {{Revisited}} and {{Enhanced}}.
\newblock In {\em Applications and {{Techniques}} in {{Information Security}}},
  Communications in {{Computer}} and {{Information Science}}, pages 100--110,
  {Singapore}, 2017. {Springer}.

\bibitem{phong_privacy-preserving_2017}
Le~Trieu Phong, Yoshinori Aono, Takuya Hayashi, Lihua Wang, and Shiho Moriai.
\newblock Privacy-{{Preserving Deep Learning}} via {{Additively Homomorphic
  Encryption}}.
\newblock Technical Report 715, 2017.

\bibitem{reddi_adaptive_2020}
Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush,
  Jakub Kone{\v c}n{\'y}, Sanjiv Kumar, and H.~Brendan McMahan.
\newblock Adaptive {{Federated Optimization}}.
\newblock {\em arXiv:2003.00295 [cs, math, stat]}, February 2020.

\bibitem{rudin_nonlinear_1992}
Leonid~I. Rudin, Stanley Osher, and Emad Fatemi.
\newblock Nonlinear total variation based noise removal algorithms.
\newblock {\em Physica D: Nonlinear Phenomena}, 60(1):259--268, November 1992.

\bibitem{shokri_privacy-preserving_2015}
Reza Shokri and Vitaly Shmatikov.
\newblock Privacy-{{Preserving Deep Learning}}.
\newblock In {\em Proceedings of the 22nd {{ACM SIGSAC Conference}} on
  {{Computer}} and {{Communications Security}} - {{CCS}} '15}, pages
  1310--1321, {Denver, Colorado, USA}, 2015. {ACM Press}.

\bibitem{szegedy_intriguing_2013}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock In {\em {{arXiv}}:1312.6199 [Cs]}, December 2013.

\bibitem{veale_algorithms_2018}
Michael Veale, Reuben Binns, and Lilian Edwards.
\newblock Algorithms that remember: Model inversion attacks and data protection
  law.
\newblock {\em Philosophical Transactions of the Royal Society A: Mathematical,
  Physical and Engineering Sciences}, 376(2133):20180083, November 2018.

\bibitem{wang_beyond_2018}
Zhibo Wang, Mengkai Song, Zhifei Zhang, Yang Song, Qian Wang, and Hairong Qi.
\newblock Beyond {{Inferring Class Representatives}}: {{User}}-{{Level Privacy
  Leakage From Federated Learning}}.
\newblock {\em arXiv:1812.00535 [cs]}, December 2018.

\bibitem{yang_federated_2019}
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong.
\newblock Federated {{Machine Learning}}: {{Concept}} and {{Applications}}.
\newblock {\em arXiv:1902.04885 [cs]}, February 2019.

\bibitem{zhang_secret_2019}
Yuheng Zhang, Ruoxi Jia, Hengzhi Pei, Wenxiao Wang, Bo~Li, and Dawn Song.
\newblock The {{Secret Revealer}}: {{Generative Model}}-{{Inversion Attacks
  Against Deep Neural Networks}}.
\newblock {\em arXiv:1911.07135 [cs, stat]}, November 2019.

\bibitem{zhao_idlg_2020}
Bo~Zhao, Konda~Reddy Mopuri, and Hakan Bilen.
\newblock {{iDLG}}: {{Improved Deep Leakage}} from {{Gradients}}.
\newblock {\em arXiv:2001.02610 [cs, stat]}, January 2020.

\bibitem{zhu_deep_2019}
Ligeng Zhu, Zhijian Liu, and Song Han.
\newblock Deep {{Leakage}} from {{Gradients}}.
\newblock In {\em Advances in {{Neural Information Processing Systems}} 32},
  pages 14774--14784. {Curran Associates, Inc.}, 2019.

\end{thebibliography}
