\begin{thebibliography}{27}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Anil et~al.(2023)Anil, Borgeaud, Wu, Alayrac, Yu, Soricut, Schalkwyk,
  Dai, Hauth, Millican, Silver, Petrov, Johnson, Antonoglou, Schrittwieser,
  Glaese, Chen, Pitler, Lillicrap, Lazaridou, Firat, Molloy, Isard, Barham,
  Hennigan, Lee, Viola, Reynolds, Xu, Doherty, Collins, Meyer, Rutherford,
  Moreira, Ayoub, Goel, Tucker, Piqueras, Krikun, Barr, Savinov, Danihelka,
  Roelofs, White, Andreassen, von Glehn, Yagati, Kazemi, Gonzalez, Khalman,
  Sygnowski, and et~al.]{Gemini}
Anil, R., Borgeaud, S., Wu, Y., Alayrac, J., Yu, J., Soricut, R., Schalkwyk,
  J., Dai, A.~M., Hauth, A., Millican, K., Silver, D., Petrov, S., Johnson, M.,
  Antonoglou, I., Schrittwieser, J., Glaese, A., Chen, J., Pitler, E.,
  Lillicrap, T.~P., Lazaridou, A., Firat, O., Molloy, J., Isard, M., Barham,
  P.~R., Hennigan, T., Lee, B., Viola, F., Reynolds, M., Xu, Y., Doherty, R.,
  Collins, E., Meyer, C., Rutherford, E., Moreira, E., Ayoub, K., Goel, M.,
  Tucker, G., Piqueras, E., Krikun, M., Barr, I., Savinov, N., Danihelka, I.,
  Roelofs, B., White, A., Andreassen, A., von Glehn, T., Yagati, L., Kazemi,
  M., Gonzalez, L., Khalman, M., Sygnowski, J., and et~al.
\newblock Gemini: {A} family of highly capable multimodal models.
\newblock \emph{ArXiv preprint}, 2023.
\newblock URL \url{https://arxiv.org/abs/2312.11805}.

\bibitem[Beurer{-}Kellner et~al.(2023)Beurer{-}Kellner, Fischer, and
  Vechev]{Beurer-Kellner023}
Beurer{-}Kellner, L., Fischer, M., and Vechev, M.~T.
\newblock Prompting is programming: {A} query language for large language
  models.
\newblock \emph{Proc. {ACM} Program. Lang.}, \penalty0 ({PLDI}), 2023.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert{-}Voss, Krueger,
  Henighan, Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin,
  Gray, Chess, Clark, Berner, McCandlish, Radford, Sutskever, and
  Amodei]{BrownMRSKDSKSSA20}
Brown, T.~B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S.,
  Herbert{-}Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A.,
  Ziegler, D.~M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin,
  M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A.,
  Sutskever, I., and Amodei, D.
\newblock Language models are few-shot learners.
\newblock In \emph{Advances in Neural Information Processing Systems 33: Annual
  Conference on Neural Information Processing Systems 2020, NeurIPS 2020,
  December 6-12, 2020, virtual}, 2020.

\bibitem[Chen et~al.(2023)Chen, Borgeaud, Irving, Lespiau, Sifre, and
  Jumper]{ChenBILSJ23}
Chen, C., Borgeaud, S., Irving, G., Lespiau, J., Sifre, L., and Jumper, J.
\newblock Accelerating large language model decoding with speculative sampling.
\newblock \emph{ArXiv preprint}, 2023.

\bibitem[Chen et~al.(2021)Chen, Tworek, Jun, Yuan, de~Oliveira~Pinto, Kaplan,
  Edwards, Burda, Joseph, Brockman, Ray, Puri, Krueger, Petrov, Khlaaf, Sastry,
  Mishkin, Chan, Gray, Ryder, Pavlov, Power, Kaiser, Bavarian, Winter, Tillet,
  Such, Cummings, Plappert, Chantzis, Barnes, Herbert{-}Voss, Guss, Nichol,
  Paino, Tezak, Tang, Babuschkin, Balaji, Jain, Saunders, Hesse, Carr, Leike,
  Achiam, Misra, Morikawa, Radford, Knight, Brundage, Murati, Mayer, Welinder,
  McGrew, Amodei, McCandlish, Sutskever, and Zaremba]{ChenTJYPKEBP21}
Chen, M., Tworek, J., Jun, H., Yuan, Q., de~Oliveira~Pinto, H.~P., Kaplan, J.,
  Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger,
  G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S.,
  Ryder, N., Pavlov, M., Power, A., Kaiser, L., Bavarian, M., Winter, C.,
  Tillet, P., Such, F.~P., Cummings, D., Plappert, M., Chantzis, F., Barnes,
  E., Herbert{-}Voss, A., Guss, W.~H., Nichol, A., Paino, A., Tezak, N., Tang,
  J., Babuschkin, I., Balaji, S., Jain, S., Saunders, W., Hesse, C., Carr,
  A.~N., Leike, J., Achiam, J., Misra, V., Morikawa, E., Radford, A., Knight,
  M., Brundage, M., Murati, M., Mayer, K., Welinder, P., McGrew, B., Amodei,
  D., McCandlish, S., Sutskever, I., and Zaremba, W.
\newblock Evaluating large language models trained on code.
\newblock \emph{ArXiv preprint}, 2021.

\bibitem[Cobbe et~al.(2021)Cobbe, Kosaraju, Bavarian, Chen, Jun, Kaiser,
  Plappert, Tworek, Hilton, Nakano, et~al.]{cobbe2021training}
Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert,
  M., Tworek, J., Hilton, J., Nakano, R., et~al.
\newblock Training verifiers to solve math word problems.
\newblock \emph{ArXiv preprint}, 2021.

\bibitem[Geng et~al.(2023{\natexlab{a}})Geng, Josifoski, Peyrard, and
  West]{GengJP023}
Geng, S., Josifoski, M., Peyrard, M., and West, R.
\newblock Grammar-constrained decoding for structured {NLP} tasks without
  finetuning.
\newblock In \emph{{EMNLP}}, 2023{\natexlab{a}}.

\bibitem[Geng et~al.(2023{\natexlab{b}})Geng, Josifoski, Peyrard, and
  West]{geng2023grammar}
Geng, S., Josifoski, M., Peyrard, M., and West, R.
\newblock Grammar-constrained decoding for structured nlp tasks without
  finetuning.
\newblock In \emph{Proc. of EMNLP}, 2023{\natexlab{b}}.

\bibitem[Gerganov \& et. al.()Gerganov and et. al.]{llamacpp}
Gerganov, G. and et. al.
\newblock llama.cpp: Port of facebook's llama model in c/c++.
\newblock URL \url{https://github.com/guidance-ai/guidance}.

\bibitem[Jiang et~al.(2023)Jiang, Sablayrolles, Mensch, Bamford, Chaplot,
  Casas, Bressand, Lengyel, Lample, Saulnier, et~al.]{jiang2023mistral}
Jiang, A.~Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D.~S., Casas,
  D. d.~l., Bressand, F., Lengyel, G., Lample, G., Saulnier, L., et~al.
\newblock Mistral 7b.
\newblock \emph{ArXiv preprint}, 2023.

\bibitem[Jiang et~al.(2024)Jiang, Sablayrolles, Roux, Mensch, Savary, Bamford,
  Chaplot, de~Las~Casas, Hanna, Bressand, Lengyel, Bour, Lample, Lavaud,
  Saulnier, Lachaux, Stock, Subramanian, Yang, Antoniak, Scao, Gervet, Lavril,
  Wang, Lacroix, and Sayed]{JiangRSBLSBCLSSSALBGLLSSYATLWLE23}
Jiang, A.~Q., Sablayrolles, A., Roux, A., Mensch, A., Savary, B., Bamford, C.,
  Chaplot, D.~S., de~Las~Casas, D., Hanna, E.~B., Bressand, F., Lengyel, G.,
  Bour, G., Lample, G., Lavaud, L.~R., Saulnier, L., Lachaux, M., Stock, P.,
  Subramanian, S., Yang, S., Antoniak, S., Scao, T.~L., Gervet, T., Lavril, T.,
  Wang, T., Lacroix, T., and Sayed, W.~E.
\newblock Mixtral of experts.
\newblock \emph{ArXiv preprint}, 2024.

\bibitem[Kudo \& Richardson(2018)Kudo and Richardson]{KudoR18}
Kudo, T. and Richardson, J.
\newblock {S}entence{P}iece: A simple and language independent subword
  tokenizer and detokenizer for neural text processing.
\newblock In \emph{Proc. of EMNLP}, 2018.

\bibitem[Lundberg \& Ribeiro()Lundberg and Ribeiro]{tokenhealing}
Lundberg, S. and Ribeiro, M. T. A.~p.
\newblock The {{Art}} of {{Prompt Design}}: {{Prompt Boundaries}} and {{Token
  Healing}}.

\bibitem[Lundberg et~al.()Lundberg, Ribeiro, and et. al.]{guidance}
Lundberg, S., Ribeiro, M. T. A.~p., and et. al.
\newblock Guidance-ai/guidance: {{A}} guidance language for controlling large
  language models.
\newblock URL \url{https://github.com/guidance-ai/guidance}.

\bibitem[McNaughton \& Yamada(1960)McNaughton and Yamada]{McNaughtonY60}
McNaughton, R. and Yamada, H.
\newblock Regular expressions and state graphs for automata.
\newblock \emph{{IRE} Trans. Electron. Comput.}, \penalty0 (1), 1960.

\bibitem[OpenAI(2023)]{gpt4}
OpenAI.
\newblock {GPT-4} technical report.
\newblock \emph{ArXiv preprint}, 2023.

\bibitem[Poesia et~al.(2022)Poesia, Polozov, Le, Tiwari, Soares, Meek, and
  Gulwani]{PoesiaP00SMG22}
Poesia, G., Polozov, A., Le, V., Tiwari, A., Soares, G., Meek, C., and Gulwani,
  S.
\newblock Synchromesh: Reliable code generation from pre-trained language
  models.
\newblock In \emph{Proc. of ICLR}, 2022.

\bibitem[Scholak et~al.(2021)Scholak, Schucher, and Bahdanau]{ScholakSB21}
Scholak, T., Schucher, N., and Bahdanau, D.
\newblock {PICARD}: Parsing incrementally for constrained auto-regressive
  decoding from language models.
\newblock In \emph{Proc. of EMNLP}, 2021.

\bibitem[Sennrich et~al.(2016)Sennrich, Haddow, and Birch]{SennrichHB16a}
Sennrich, R., Haddow, B., and Birch, A.
\newblock Neural machine translation of rare words with subword units.
\newblock In \emph{Proc. of ACL}, 2016.

\bibitem[Thompson(1968)]{Thompson68}
Thompson, K.
\newblock Regular expression search algorithm.
\newblock \emph{Commun. {ACM}}, \penalty0 (6), 1968.

\bibitem[Tjong Kim~Sang(2002)]{sang2003introduction}
Tjong Kim~Sang, E.~F.
\newblock Introduction to the {C}o{NLL}-2002 shared task: Language-independent
  named entity recognition.
\newblock In \emph{{COLING}-02: The 6th Conference on Natural Language Learning
  2002 ({C}o{NLL}-2002)}, 2002.

\bibitem[Touvron et~al.(2023{\natexlab{a}})Touvron, Lavril, Izacard, Martinet,
  Lachaux, Lacroix, Rozi{\`{e}}re, Goyal, Hambro, Azhar, Rodriguez, Joulin,
  Grave, and Lample]{TouvronLIMLLRAGJGL23}
Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M., Lacroix, T.,
  Rozi{\`{e}}re, B., Goyal, N., Hambro, E., Azhar, F., Rodriguez, A., Joulin,
  A., Grave, E., and Lample, G.
\newblock Llama: Open and efficient foundation language models.
\newblock \emph{ArXiv preprint}, 2023{\natexlab{a}}.

\bibitem[Touvron et~al.(2023{\natexlab{b}})Touvron, Martin, Stone, Albert,
  Almahairi, Babaei, Bashlykov, Batra, Bhargava, Bhosale, Bikel, Blecher,
  Canton{-}Ferrer, Chen, Cucurull, Esiobu, Fernandes, Fu, Fu, Fuller, Gao,
  Goswami, Goyal, Hartshorn, Hosseini, Hou, Inan, Kardas, Kerkez, Khabsa,
  Kloumann, Korenev, Koura, Lachaux, Lavril, Lee, Liskovich, Lu, Mao, Martinet,
  Mihaylov, Mishra, Molybog, Nie, Poulton, Reizenstein, Rungta, Saladi,
  Schelten, Silva, Smith, Subramanian, Tan, Tang, Taylor, Williams, Kuan, Xu,
  Yan, Zarov, Zhang, Fan, Kambadur, Narang, Rodriguez, Stojnic, Edunov, and
  Scialom]{TouvronMSAAB23}
Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y.,
  Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., Bikel, D., Blecher, L.,
  Canton{-}Ferrer, C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu,
  J., Fu, W., Fuller, B., Gao, C., Goswami, V., Goyal, N., Hartshorn, A.,
  Hosseini, S., Hou, R., Inan, H., Kardas, M., Kerkez, V., Khabsa, M.,
  Kloumann, I., Korenev, A., Koura, P.~S., Lachaux, M., Lavril, T., Lee, J.,
  Liskovich, D., Lu, Y., Mao, Y., Martinet, X., Mihaylov, T., Mishra, P.,
  Molybog, I., Nie, Y., Poulton, A., Reizenstein, J., Rungta, R., Saladi, K.,
  Schelten, A., Silva, R., Smith, E.~M., Subramanian, R., Tan, X.~E., Tang, B.,
  Taylor, R., Williams, A., Kuan, J.~X., Xu, P., Yan, Z., Zarov, I., Zhang, Y.,
  Fan, A., Kambadur, M., Narang, S., Rodriguez, A., Stojnic, R., Edunov, S.,
  and Scialom, T.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock \emph{ArXiv preprint}, 2023{\natexlab{b}}.

\bibitem[Touvron et~al.(2023{\natexlab{c}})Touvron, Martin, Stone, Albert,
  Almahairi, Babaei, Bashlykov, Batra, Bhargava, Bhosale,
  et~al.]{touvron2023llama}
Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y.,
  Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock \emph{ArXiv preprint}, 2023{\natexlab{c}}.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, L., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems 30: Annual
  Conference on Neural Information Processing Systems 2017, December 4-9, 2017,
  Long Beach, CA, {USA}}, 2017.

\bibitem[Willard \& Louf(2023)Willard and Louf]{WillardL23}
Willard, B.~T. and Louf, R.
\newblock Efficient guided generation for large language models.
\newblock \emph{ArXiv preprint}, 2023.

\bibitem[Wolf et~al.(2019)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac,
  Rault, Louf, Funtowicz, et~al.]{wolf2019huggingface}
Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P.,
  Rault, T., Louf, R., Funtowicz, M., et~al.
\newblock Huggingface's transformers: State-of-the-art natural language
  processing.
\newblock \emph{ArXiv preprint}, 2019.

\end{thebibliography}
