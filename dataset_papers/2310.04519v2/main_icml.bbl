\begin{thebibliography}{76}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ancona et~al.(2019)Ancona, Ceolini, {\"O}ztireli, and
  Gross]{ancona2019gradient}
Marco Ancona, Enea Ceolini, Cengiz {\"O}ztireli, and Markus Gross.
\newblock Gradient-based attribution methods.
\newblock \emph{Explainable AI: Interpreting, explaining and visualizing deep
  learning}, 2019.

\bibitem[Bach et~al.(2015)Bach, Binder, Montavon, Klauschen, M{\"u}ller, and
  Samek]{LRP}
Sebastian Bach, Alexander Binder, Gr{\'e}goire Montavon, Frederick Klauschen,
  Klaus-Robert M{\"u}ller, and Wojciech Samek.
\newblock On pixel-wise explanations for non-linear classifier decisions by
  layer-wise relevance propagation.
\newblock \emph{PloS one}, 2015.

\bibitem[Belrose et~al.(2023)Belrose, Furman, Smith, Halawi, Ostrovsky,
  McKinney, Biderman, and Steinhardt]{Belrose2023ElicitingLP}
Nora Belrose, Zach Furman, Logan Smith, Danny Halawi, Igor~V. Ostrovsky, Lev
  McKinney, Stella Biderman, and Jacob Steinhardt.
\newblock Eliciting latent predictions from transformers with the tuned lens.
\newblock \emph{arXiv preprint arXiv:2303.08112}, 2023.

\bibitem[Bilodeau et~al.(2022)Bilodeau, Jaques, Koh, and
  Kim]{Bilodeau2022ImpossibilityTF}
Blair Bilodeau, Natasha Jaques, Pang~Wei Koh, and Been Kim.
\newblock Impossibility theorems for feature attribution.
\newblock \emph{Proceedings of the National Academy of Sciences of the United
  States of America}, 2022.

\bibitem[Bossard et~al.(2014)Bossard, Guillaumin, and Gool]{food101}
Lukas Bossard, Matthieu Guillaumin, and Luc~Van Gool.
\newblock Food-101 - mining discriminative components with random forests.
\newblock In \emph{European Conference on Computer Vision (ECCV)}, 2014.

\bibitem[Buolamwini \& Gebru(2018)Buolamwini and Gebru]{Buolamwini2018GenderSI}
Joy Buolamwini and Timnit Gebru.
\newblock Gender shades: Intersectional accuracy disparities in commercial
  gender classification.
\newblock In \emph{ACM Conference on Fairness, Accountability, and Transparency
  (FAccT)}, 2018.

\bibitem[Cao et~al.(2021)Cao, Sanh, and Rush]{Cao2021LowComplexityPV}
Steven Cao, Victor Sanh, and Alexander~M. Rush.
\newblock Low-complexity probing via finding subnetworks.
\newblock In \emph{North American Chapter of the Association for Computational
  Linguistics (NAACL)}, 2021.

\bibitem[Casper et~al.(2023)Casper, Li, Li, Bu, Zhang, Hariharan, and
  Hadfield{-}Menell]{benchMarking}
Stephen Casper, Yuxiao Li, Jiawei Li, Tong Bu, Kevin Zhang, Kaivalya Hariharan,
  and Dylan Hadfield{-}Menell.
\newblock Red teaming deep neural networks with feature synthesis tools.
\newblock In \emph{Conference on Neural Information Processing Systems
  (NeurIPS)}, 2023.

\bibitem[Chattopadhyay et~al.(2018)Chattopadhyay, Sarkar, Howlader, and
  Balasubramanian]{GradCam++}
Aditya Chattopadhyay, Anirban Sarkar, Prantik Howlader, and Vineeth~N.
  Balasubramanian.
\newblock Grad-cam++: Generalized gradient-based visual explanations for deep
  convolutional networks.
\newblock In \emph{{IEEE} Winter Conference on Applications of Computer Vision,
  {WACV}}, 2018.

\bibitem[Chefer et~al.(2021)Chefer, Gur, and Wolf]{ViT_saliencyMap_Main}
Hila Chefer, Shir Gur, and Lior Wolf.
\newblock Transformer interpretability beyond attention visualization.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2021.

\bibitem[Chrysostomou \& Aletras(2021)Chrysostomou and
  Aletras]{chrysostomou2021improving}
George Chrysostomou and Nikolaos Aletras.
\newblock Improving the faithfulness of attention-based explanations with
  task-specific information for text classification.
\newblock In \emph{Meeting of the Association for Computational Linguistics and
  the International Joint Conference on Natural Language Processing}, 2021.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei{-}Fei]{imagenet}
Jia Deng, Wei Dong, Richard Socher, Li{-}Jia Li, Kai Li, and Li~Fei{-}Fei.
\newblock Imagenet: {A} large-scale hierarchical image database.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2009.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{North American Chapter of the Association for Computational
  Linguistics (NAACL)}, 2018.

\bibitem[Doshi-Velez \& Kim(2017)Doshi-Velez and Kim]{DoshiVelez2017TowardsAR}
Finale Doshi-Velez and Been Kim.
\newblock Towards a rigorous science of interpretable machine learning.
\newblock \emph{arXiv preprint arXiv:1702.08608}, 2017.

\bibitem[Erhan et~al.(2009)Erhan, Bengio, Courville, and
  Vincent]{FeatureVisualizationFirstWork}
Dumitru Erhan, Yoshua Bengio, Aaron Courville, and Pascal Vincent.
\newblock Visualizing higher-layer features of a deep network.
\newblock Technical report, University of Montreal, 2009.

\bibitem[Frantar \& Alistarh(2022)Frantar and Alistarh]{OBC}
Elias Frantar and Dan Alistarh.
\newblock Optimal brain compression: {A} framework for accurate post-training
  quantization and pruning.
\newblock In \emph{Conference on Neural Information Processing Systems
  (NeurIPS)}, 2022.

\bibitem[Frantar \& Alistarh(2023)Frantar and Alistarh]{sparseGPT}
Elias Frantar and Dan Alistarh.
\newblock Sparsegpt: Massive language models can be accurately pruned in
  one-shot.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2023.

\bibitem[Geiger et~al.(2020)Geiger, Richardson, and Potts]{Geiger2020NeuralNL}
Atticus Geiger, Kyle Richardson, and Christopher Potts.
\newblock Neural natural language inference models partially embed theories of
  lexical entailment and negation.
\newblock In \emph{BlackboxNLP Workshop on Analyzing and Interpreting Neural
  Networks for NLP}, 2020.

\bibitem[Geirhos et~al.(2020)Geirhos, Jacobsen, Michaelis, Zemel, Brendel,
  Bethge, and Wichmann]{background}
Robert Geirhos, J{\"o}rn-Henrik Jacobsen, Claudio Michaelis, Richard~S. Zemel,
  Wieland Brendel, Matthias Bethge, and Felix Wichmann.
\newblock Shortcut learning in deep neural networks.
\newblock \emph{Nature Machine Intelligence}, 2020.

\bibitem[Geirhos et~al.(2023)Geirhos, Zimmermann, Bilodeau, Brendel, and
  Kim]{dontTrustYourEye}
Robert Geirhos, Roland~S. Zimmermann, Blair Bilodeau, Wieland Brendel, and Been
  Kim.
\newblock Don't trust your eyes: on the (un)reliability of feature
  visualizations.
\newblock \emph{arXiv preprint arXiv:2306.04719}, 2023.

\bibitem[Ghiasi et~al.(2022)Ghiasi, Kazemi, Borgnia, Reich, Shu, Goldblum,
  Wilson, and Goldstein]{WhatDoVisionTransformersLearn}
Amin Ghiasi, Hamid Kazemi, Eitan Borgnia, Steven Reich, Manli Shu, Micah
  Goldblum, Andrew~Gordon Wilson, and Tom Goldstein.
\newblock What do vision transformers learn? {A} visual exploration.
\newblock \emph{arXiv preprint arXiv:2212.06727}, 2022.

\bibitem[Goh et~al.(2021)Goh, Cammarata, Voss, Carter, Petrov, Schubert,
  Radford, and Olah]{multiModalNeuron}
Gabriel Goh, Nick Cammarata, Chelsea Voss, Shan Carter, Michael Petrov, Ludwig
  Schubert, Alec Radford, and Chris Olah.
\newblock Multimodal neurons in artificial neural networks.
\newblock \emph{Distill}, 6\penalty0 (3):\penalty0 e30, 2021.

\bibitem[Gomez et~al.(2022)Gomez, Fr{\'e}our, and
  Mouch{\`e}re]{gomez2022metrics}
Tristan Gomez, Thomas Fr{\'e}our, and Harold Mouch{\`e}re.
\newblock Metrics for saliency map evaluation of deep learning explanation
  methods.
\newblock In \emph{Pattern Recognition and Artificial Intelligence: Third
  International Conference, ICPRAI}. Springer, 2022.

\bibitem[Gurnee et~al.(2023)Gurnee, Nanda, Pauly, Harvey, Troitskii, and
  Bertsimas]{Gurnee2023FindingNI}
Wes Gurnee, Neel Nanda, Matthew Pauly, Katherine Harvey, Dmitrii Troitskii, and
  Dimitris Bertsimas.
\newblock Finding neurons in a haystack: Case studies with sparse probing.
\newblock \emph{Transactions of Machine Learning Research (TMLR)}, 2023.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2016.

\bibitem[Hooker et~al.(2019)Hooker, Erhan, Kindermans, and
  Kim]{hooker2019benchmark}
Sara Hooker, Dumitru Erhan, Pieter-Jan Kindermans, and Been Kim.
\newblock A benchmark for interpretability methods in deep neural networks.
\newblock \emph{arXiv preprint arXiv:1806.10758}, 2019.

\bibitem[Howard et~al.(2017)Howard, Zhu, Chen, Kalenichenko, Wang, Weyand,
  Andreetto, and Adam]{MobileNet}
Andrew~G. Howard, Menglong Zhu, Bo~Chen, Dmitry Kalenichenko, Weijun Wang,
  Tobias Weyand, Marco Andreetto, and Hartwig Adam.
\newblock Mobilenets: Efficient convolutional neural networks for mobile vision
  applications.
\newblock \emph{arXiv preprint arXiv:1704.04861}, 2017.

\bibitem[Hubara et~al.(2021)Hubara, Chmiel, Island, Banner, Naor, and
  Soudry]{hubara2021accelerated}
Itay Hubara, Brian Chmiel, Moshe Island, Ron Banner, Joseph Naor, and Daniel
  Soudry.
\newblock Accelerated sparse neural training: A provable and efficient method
  to find n: m transposable masks.
\newblock \emph{Advances in neural information processing systems}, 2021.

\bibitem[Huben et~al.(2024)Huben, Cunningham, Smith, Ewart, and
  Sharkey]{cunningham2023sae}
Robert Huben, Hoagy Cunningham, Logan~Riggs Smith, Aidan Ewart, and Lee
  Sharkey.
\newblock Sparse autoencoders find highly interpretable features in language
  models.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2024.

\bibitem[Jo \& Bengio(2017)Jo and Bengio]{background_CNN}
Jason Jo and Yoshua Bengio.
\newblock Measuring the tendency of cnns to learn surface statistical
  regularities.
\newblock \emph{arXiv preprint arXiv:1711.11561}, 2017.

\bibitem[Kokhlikyan et~al.(2020)Kokhlikyan, Miglani, Martin, Wang, Alsallakh,
  Reynolds, Melnikov, Kliushkina, Araya, Yan, et~al.]{captum}
Narine Kokhlikyan, Vivek Miglani, Miguel Martin, Edward Wang, Bilal Alsallakh,
  Jonathan Reynolds, Alexander Melnikov, Natalia Kliushkina, Carlos Araya, Siqi
  Yan, et~al.
\newblock Captum: A unified and generic model interpretability library for
  pytorch.
\newblock \emph{arXiv preprint arXiv:2009.07896}, 2020.

\bibitem[Kornblith et~al.(2019)Kornblith, Shlens, and Le]{kornblith2019better}
Simon Kornblith, Jonathon Shlens, and Quoc~V Le.
\newblock Do better imagenet models transfer better?
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2019.

\bibitem[Kramar et~al.(2024)Kramar, Lieberum, Shah, and Nanda]{Kramar2024AtPAE}
Janos Kramar, Tom Lieberum, Rohin Shah, and Neel Nanda.
\newblock {AtP*}: An efficient and scalable method for localizing llm behaviour
  to components.
\newblock \emph{arXiv preprint arXiv:2403.00745}, 2024.

\bibitem[Kuznedelev et~al.(2023)Kuznedelev, Kurtic, Frantar, and
  Alistarh]{kuznedelev2023cap}
Denis Kuznedelev, Eldar Kurtic, Elias Frantar, and Dan Alistarh.
\newblock Cap: Correlation-aware pruning for highly-accurate sparse vision
  models.
\newblock In \emph{Conference on Neural Information Processing Systems
  (NeurIPS)}, 2023.

\bibitem[Linardatos et~al.(2020)Linardatos, Papastefanopoulos, and
  Kotsiantis]{Linardatos2020ExplainableAA}
Pantelis Linardatos, Vasilis Papastefanopoulos, and Sotiris~B. Kotsiantis.
\newblock Explainable ai: A review of machine learning interpretability
  methods.
\newblock \emph{Entropy}, 2020.

\bibitem[Liu et~al.(2022)Liu, Mao, Wu, Feichtenhofer, Darrell, and
  Xie]{convnext}
Zhuang Liu, Hanzi Mao, Chao{-}Yuan Wu, Christoph Feichtenhofer, Trevor Darrell,
  and Saining Xie.
\newblock A convnet for the 2020s.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2022.

\bibitem[Liu et~al.(2023)Liu, Gan, and Tegmark]{ModularTraining}
Ziming Liu, Eric Gan, and Max Tegmark.
\newblock Seeing is believing: Brain-inspired modular training for mechanistic
  interpretability.
\newblock \emph{arXiv preprint arXiv:2305.08746}, 2023.

\bibitem[Liu et~al.(2015)Liu, Luo, Wang, and Tang]{celeba}
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.
\newblock Deep learning face attributes in the wild.
\newblock In \emph{International Conference on Computer Vision (ICCV)}, 2015.

\bibitem[Lundberg \& Lee(2017)Lundberg and Lee]{gradientShape}
Scott~M Lundberg and Su-In Lee.
\newblock A unified approach to interpreting model predictions.
\newblock In \emph{Conference on Neural Information Processing Systems
  (NeurIPS)}, 2017.

\bibitem[Meng et~al.(2022)Meng, Bau, Andonian, and Belinkov]{meng2022locating}
Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov.
\newblock Locating and editing factual associations in {GPT}.
\newblock In \emph{Conference on Neural Information Processing Systems
  (NeurIPS)}, 2022.

\bibitem[Mordvintsev et~al.()Mordvintsev, Olah, and
  Tyka]{FeatureVisualizationDeepDream}
Alexander Mordvintsev, Christopher Olah, and Mike Tyka.
\newblock Deepdream-a code example for visualizing neural networks.
\newblock \emph{Google Research}.

\bibitem[Nam et~al.(2019)Nam, Gur, Choi, Wolf, and Lee]{nam2019relative}
Woo-Jeoung Nam, Shir Gur, Jaesik Choi, Lior Wolf, and Seong-Whan Lee.
\newblock Relative attributing propagation: Interpreting the comparative
  contributions of individual units in deep neural networks.
\newblock \emph{arXiv preprint arXiv:1904.00605}, 2019.

\bibitem[Nguyen et~al.(2016)Nguyen, Yosinski, and Clune]{Multifaceted}
Anh~Mai Nguyen, Jason Yosinski, and Jeff Clune.
\newblock Multifaceted feature visualization: Uncovering the different types of
  features learned by each neuron in deep neural networks.
\newblock \emph{arXiv preprint arXiv:1602.03616}, 2016.

\bibitem[Nielsen et~al.(2022)Nielsen, Dera, Rasool, Ramachandran, and
  Bouaynaya]{Nielsen_2022}
Ian~E. Nielsen, Dimah Dera, Ghulam Rasool, Ravi~P. Ramachandran, and
  Nidhal~Carla Bouaynaya.
\newblock Robust explainability: A tutorial on gradient-based attribution
  methods for deep neural networks.
\newblock \emph{{IEEE} Signal Processing Magazine}, 2022.

\bibitem[Olah et~al.(2017)Olah, Mordvintsev, and Schubert]{olah2017feature}
Chris Olah, Alexander Mordvintsev, and Ludwig Schubert.
\newblock Feature visualization.
\newblock \emph{Distill}, 2\penalty0 (11), 2017.

\bibitem[Olah et~al.(2020)Olah, Cammarata, Schubert, Goh, Petrov, and
  Carter]{Olah2020ZoomIA}
Christopher Olah, Nick Cammarata, Ludwig Schubert, Gabriel Goh, Michael Petrov,
  and Shan Carter.
\newblock Zoom in: An introduction to circuits.
\newblock 2020.

\bibitem[O'Mahony et~al.(2023)O'Mahony, Andrearczyk, Muller, and
  Graziani]{omahony2023disentangling}
Laura O'Mahony, Vincent Andrearczyk, Henning Muller, and Mara Graziani.
\newblock Disentangling neuron representations with concept vectors.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2023.

\bibitem[Pal et~al.(2023)Pal, Sun, Yuan, Wallace, and Bau]{Pal2023FutureLA}
Koyena Pal, Jiuding Sun, Andrew Yuan, Byron~C. Wallace, and David Bau.
\newblock Future lens: Anticipating subsequent tokens from a single hidden
  state.
\newblock \emph{Conference on Computational Natural Language Learning (CoNLL)},
  2023.

\bibitem[Panousis et~al.(2023)Panousis, Ienco, and Marcos]{sparseCDMs}
Konstantinos~Panagiotis Panousis, Dino Ienco, and Diego Marcos.
\newblock Sparse linear concept discovery models.
\newblock In \emph{IEEE/CVF International Conference on Computer Vision
  (ICCV)}, 2023.

\bibitem[Peste et~al.(2021)Peste, Iofinova, Vladu, and Alistarh]{peste2021ac}
Alexandra Peste, Eugenia Iofinova, Adrian Vladu, and Dan Alistarh.
\newblock {AC/DC}: Alternating compressed/decompressed training of deep neural
  networks.
\newblock In \emph{Conference on Neural Information Processing Systems
  (NeurIPS)}, 2021.

\bibitem[Petsiuk et~al.(2018)Petsiuk, Das, and Saenko]{rise}
Vitali Petsiuk, Abir Das, and Kate Saenko.
\newblock {RISE:} randomized input sampling for explanation of black-box
  models.
\newblock In \emph{British Machine Vision Conference {BMVC}}, 2018.

\bibitem[Pierse(2021)]{pierse2021transformers}
Charles Pierse.
\newblock Transformers interpret.
\newblock \url{https://github.com/cdpierse/transformers-interpret}, 2021.

\bibitem[Rebuffi et~al.(2020)Rebuffi, Fong, Ji, and Vedaldi]{Rebuffi_2020_CVPR}
Sylvestre-Alvise Rebuffi, Ruth Fong, Xu~Ji, and Andrea Vedaldi.
\newblock There and back again: Revisiting backpropagation saliency methods.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2020.

\bibitem[Ribeiro et~al.(2016)Ribeiro, Singh, and Guestrin]{Lime}
Marco~T{\'{u}}lio Ribeiro, Sameer Singh, and Carlos Guestrin.
\newblock "why should {I} trust you?": Explaining the predictions of any
  classifier.
\newblock In \emph{Proceedings of the 22nd {ACM} {SIGKDD} International
  Conference on Knowledge Discovery and Data Mining}, 2016.

\bibitem[Scherlis et~al.(2022)Scherlis, Sachan, Jermyn, Benton, and
  Shlegeris]{scherlis2023polysemanticity}
Adam Scherlis, Kshitij Sachan, Adam~S. Jermyn, Joe Benton, and Buck Shlegeris.
\newblock Polysemanticity and capacity in neural networks.
\newblock \emph{arXiv preprint arXiv:2210.01892}, 2022.

\bibitem[Selvaraju et~al.(2017)Selvaraju, Cogswell, Das, Vedantam, Parikh, and
  Batra]{GuidedGradCam}
Ramprasaath~R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam,
  Devi Parikh, and Dhruv Batra.
\newblock Grad-cam: Visual explanations from deep networks via gradient-based
  localization.
\newblock In \emph{International Conference on Computer Vision (ICCV)}, 2017.

\bibitem[Serrano \& Smith(2019)Serrano and Smith]{serrano2019attention}
Sofia Serrano and Noah~A Smith.
\newblock Is attention interpretable?
\newblock 2019.

\bibitem[Shetty et~al.(2019)Shetty, Schiele, and Fritz]{Shetty_2019_CVPR}
Rakshith Shetty, Bernt Schiele, and Mario Fritz.
\newblock Not using the car to see the sidewalk -- quantifying and controlling
  the effects of context in classification and segmentation.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2019.

\bibitem[Shrikumar et~al.(2016)Shrikumar, Greenside, Shcherbina, and
  Kundaje]{inputXgradient}
Avanti Shrikumar, Peyton Greenside, Anna Shcherbina, and Anshul Kundaje.
\newblock Not just a black box: Learning important features through propagating
  activation differences.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2016.

\bibitem[Shrikumar et~al.(2017)Shrikumar, Greenside, and Kundaje]{deeplift}
Avanti Shrikumar, Peyton Greenside, and Anshul Kundaje.
\newblock Learning important features through propagating activation
  differences.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2017.

\bibitem[Simonyan et~al.(2013)Simonyan, Vedaldi, and
  Zisserman]{simonyan2013deep}
Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman.
\newblock Deep inside convolutional networks: Visualising image classification
  models and saliency maps.
\newblock \emph{arXiv preprint arXiv:1312.6034}, 2013.

\bibitem[Simonyan et~al.(2014)Simonyan, Vedaldi, and Zisserman]{Saliency}
Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman.
\newblock Deep inside convolutional networks: Visualising image classification
  models and saliency maps.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2014.

\bibitem[Socher et~al.(2013)Socher, Perelygin, Wu, Chuang, Manning, Ng, and
  Potts]{sst2}
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher~D. Manning,
  Andrew Ng, and Christopher Potts.
\newblock Recursive deep models for semantic compositionality over a sentiment
  treebank.
\newblock In \emph{Proceedings of the Conference on Empirical Methods in
  Natural Language Processing}, 2013.

\bibitem[Springenberg et~al.(2014)Springenberg, Dosovitskiy, Brox, and
  Riedmiller]{GuidedBackProb}
Jost~Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox, and Martin
  Riedmiller.
\newblock Striving for simplicity: The all convolutional net.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2014.

\bibitem[Sundararajan et~al.(2017{\natexlab{a}})Sundararajan, Taly, and
  Yan]{IntegratedGradients}
Mukund Sundararajan, Ankur Taly, and Qiqi Yan.
\newblock Axiomatic attribution for deep networks.
\newblock In \emph{International Conference on Machine Learning (ICML)},
  2017{\natexlab{a}}.

\bibitem[Sundararajan et~al.(2017{\natexlab{b}})Sundararajan, Taly, and
  Yan]{sundararajan2017axiomatic}
Mukund Sundararajan, Ankur Taly, and Qiqi Yan.
\newblock Axiomatic attribution for deep networks.
\newblock In \emph{International Conference on Machine Learning (ICML)},
  2017{\natexlab{b}}.

\bibitem[Voita et~al.(2019)Voita, Talbot, Moiseev, Sennrich, and
  Titov]{PartialLRP}
Elena Voita, David Talbot, Fedor Moiseev, Rico Sennrich, and Ivan Titov.
\newblock Analyzing multi-head self-attention: Specialized heads do the heavy
  lifting, the rest can be pruned.
\newblock In \emph{Proceedings of the 57th Conference of the Association for
  Computational Linguistics, {ACL}}, 2019.

\bibitem[Wang et~al.(2019)Wang, Wang, Du, Yang, Zhang, Ding, Mardziel, and
  Hu]{Wang2019ScoreCAMSV}
Haofan Wang, Zifan Wang, Mengnan Du, Fan Yang, Zijian Zhang, Sirui Ding,
  Piotr~(Peter) Mardziel, and Xia Hu.
\newblock Score-cam: Score-weighted visual explanations for convolutional
  neural networks.
\newblock \emph{IEEE/CVF Conference on Computer Vision and Pattern Recognition
  Workshops (CVPRW)}, 2019.

\bibitem[Wang et~al.(2023)Wang, Variengien, Conmy, Shlegeris, and
  Steinhardt]{Wang2022InterpretabilityIT}
Kevin Wang, Alexandre Variengien, Arthur Conmy, Buck Shlegeris, and Jacob
  Steinhardt.
\newblock Interpretability in the wild: a circuit for indirect object
  identification in gpt-2 small.
\newblock In \emph{International Conference on Learning Representations
  (International Conference on Learning Representations (ICLR))}, 2023.

\bibitem[Wei \& Zou(2019)Wei and Zou]{wei2019eda}
Jason Wei and Kai Zou.
\newblock Eda: Easy data augmentation techniques for boosting performance on
  text classification tasks.
\newblock In \emph{Conference on Empirical Methods in Natural Language
  Processing and the International Joint Conference on Natural Language
  Processing (EMNLP-IJCNLP)}, 2019.

\bibitem[Wong et~al.(2021)Wong, Santurkar, and Madry]{debugger}
Eric Wong, Shibani Santurkar, and Aleksander Madry.
\newblock Leveraging sparse linear layers for debuggable deep networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2021.

\bibitem[Yosinski et~al.()Yosinski, Clune, Nguyen, Fuchs, and
  Lipson]{DeepVisualization}
Jason Yosinski, Jeff Clune, Anh~M Nguyen, Thomas~J. Fuchs, and Hod Lipson.
\newblock Understanding neural networks through deep visualization.
\newblock \emph{arXiv preprint arXiv:1506.06579}.

\bibitem[Yu \& Xiang(2023)Yu and Xiang]{eXplainable}
Lu~Yu and Wei Xiang.
\newblock X-pruner: explainable pruning for vision transformers.
\newblock \emph{IEEE/CVF Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2023.

\bibitem[Zeiler \& Fergus(2014)Zeiler and Fergus]{Occlusion}
Matthew~D. Zeiler and Rob Fergus.
\newblock Visualizing and understanding convolutional networks.
\newblock In \emph{European Conference on Computer Vision (ICCV)}, 2014.

\bibitem[Zhang et~al.(2023)Zhang, Torres, Sicre, Avrithis, and
  Ayache]{opti-cam}
Hanwei Zhang, Felipe Torres, Ronan Sicre, Yannis Avrithis, and S.~Ayache.
\newblock Opti-cam: Optimizing saliency maps for interpretability.
\newblock \emph{arXiv preprint arXiv:2301.07002}, 2023.

\bibitem[Zhang et~al.(2015)Zhang, Zhao, and LeCun]{Zhang2015CharacterlevelCN}
Xiang Zhang, Junbo~Jake Zhao, and Yann LeCun.
\newblock Character-level convolutional networks for text classification.
\newblock In \emph{Conference on Neural Information Processing Systems
  (NeurIPS)}, 2015.

\end{thebibliography}
