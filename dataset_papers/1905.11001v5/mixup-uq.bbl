\begin{thebibliography}{10}

\bibitem{berk2017impact}
Richard Berk.
\newblock An impact assessment of machine learning risk forecasts on parole
  board decisions and recidivism.
\newblock {\em Journal of Experimental Criminology}, 13(2):193--216, 2017.

\bibitem{cer2018universal}
Daniel Cer, Yinfei Yang, Sheng-yi Kong, Nan Hua, Nicole Limtiaco, Rhomni~St
  John, Noah Constant, Mario Guajardo-Cespedes, Steve Yuan, Chris Tar, et~al.
\newblock Universal sentence encoder.
\newblock {\em arXiv preprint arXiv:1803.11175}, 2018.

\bibitem{chapelle2001vicinal}
Olivier Chapelle, Jason Weston, L{\'e}on Bottou, and Vladimir Vapnik.
\newblock Vicinal risk minimization.
\newblock In {\em Advances in neural information processing systems}, pages
  416--422, 2001.

\bibitem{coates2011analysis}
Adam Coates, Andrew Ng, and Honglak Lee.
\newblock An analysis of single-layer networks in unsupervised feature
  learning.
\newblock In {\em Proceedings of the fourteenth international conference on
  artificial intelligence and statistics}, pages 215--223, 2011.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em Computer Vision and Pattern Recognition, 2009. CVPR 2009.
  IEEE Conference on}, pages 248--255. Ieee, 2009.

\bibitem{gal2016dropout}
Yarin Gal and Zoubin Ghahramani.
\newblock Dropout as a bayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In {\em international conference on machine learning}, pages
  1050--1059, 2016.

\bibitem{geifman2017selective}
Yonatan Geifman and Ran El-Yaniv.
\newblock Selective classification for deep neural networks.
\newblock In {\em Advances in neural information processing systems}, pages
  4885--4894, 2017.

\bibitem{goyal2017accurate}
Priya Goyal, Piotr Doll{\'a}r, Ross Girshick, Pieter Noordhuis, Lukasz
  Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He.
\newblock Accurate, large minibatch sgd: Training imagenet in 1 hour.
\newblock {\em arXiv preprint arXiv:1706.02677}, 2017.

\bibitem{guo2017calibration}
Chuan Guo, Geoff Pleiss, Yu~Sun, and Kilian~Q Weinberger.
\newblock On calibration of modern neural networks.
\newblock {\em arXiv preprint arXiv:1706.04599}, 2017.

\bibitem{guo2018mixup}
Hongyu Guo, Yongyi Mao, and Richong Zhang.
\newblock Mixup as locally linear out-of-manifold regularization.
\newblock {\em arXiv preprint arXiv:1809.02499}, 2018.

\bibitem{guo2019augmenting}
Hongyu Guo, Yongyi Mao, and Richong Zhang.
\newblock Augmenting data with mixup for sentence classification: An empirical
  study.
\newblock {\em arXiv preprint arXiv:1905.08941}, 2019.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem{hendrycks2016baseline}
Dan Hendrycks and Kevin Gimpel.
\newblock A baseline for detecting misclassified and out-of-distribution
  examples in neural networks.
\newblock {\em arXiv preprint arXiv:1610.02136}, 2016.

\bibitem{howard2018universal}
Jeremy Howard and Sebastian Ruder.
\newblock Universal language model fine-tuning for text classification.
\newblock {\em arXiv preprint arXiv:1801.06146}, 2018.

\bibitem{inoue2018data}
Hiroshi Inoue.
\newblock Data augmentation by pairing samples for images classification.
\newblock {\em arXiv preprint arXiv:1801.02929}, 2018.

\bibitem{kendall2017uncertainties}
Alex Kendall and Yarin Gal.
\newblock What uncertainties do we need in bayesian deep learning for computer
  vision?
\newblock In {\em Advances in neural information processing systems}, pages
  5574--5584, 2017.

\bibitem{kim2014convolutional}
Yoon Kim.
\newblock Convolutional neural networks for sentence classification.
\newblock {\em arXiv preprint arXiv:1408.5882}, 2014.

\bibitem{krizhevsky2009learning}
Alex Krizhevsky and Geoffrey Hinton.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, Citeseer, 2009.

\bibitem{lakshminarayanan2017simple}
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell.
\newblock Simple and scalable predictive uncertainty estimation using deep
  ensembles.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6402--6413, 2017.

\bibitem{lee2017training}
Kimin Lee, Honglak Lee, Kibok Lee, and Jinwoo Shin.
\newblock Training confidence-calibrated classifiers for detecting
  out-of-distribution samples.
\newblock {\em arXiv preprint arXiv:1711.09325}, 2017.

\bibitem{levinson2011towards}
Jesse Levinson, Jake Askeland, Jan Becker, Jennifer Dolson, David Held, Soeren
  Kammel, J~Zico Kolter, Dirk Langer, Oliver Pink, Vaughan Pratt, et~al.
\newblock Towards fully autonomous driving: Systems and algorithms.
\newblock In {\em Intelligent Vehicles Symposium (IV), 2011 IEEE}, pages
  163--168. IEEE, 2011.

\bibitem{li2002learning}
Xin Li and Dan Roth.
\newblock Learning question classifiers.
\newblock In {\em Proceedings of the 19th international conference on
  Computational linguistics-Volume 1}, pages 1--7. Association for
  Computational Linguistics, 2002.

\bibitem{liang2018understanding}
Daojun Liang, Feng Yang, Tian Zhang, and Peter Yang.
\newblock Understanding mixup training methods.
\newblock {\em IEEE Access}, 6:58774--58783, 2018.

\bibitem{maas2011learning}
Andrew~L Maas, Raymond~E Daly, Peter~T Pham, Dan Huang, Andrew~Y Ng, and
  Christopher Potts.
\newblock Learning word vectors for sentiment analysis.
\newblock In {\em Proceedings of the 49th annual meeting of the association for
  computational linguistics: Human language technologies-volume 1}, pages
  142--150. Association for Computational Linguistics, 2011.

\bibitem{malkin2009multi}
Jonathan Malkin and Jeff Bilmes.
\newblock Multi-layer ratio semi-definite classifiers.
\newblock In {\em 2009 IEEE International Conference on Acoustics, Speech and
  Signal Processing}, pages 4465--4468. IEEE, 2009.

\bibitem{miotto2016deep}
Riccardo Miotto, Li~Li, Brian~A Kidd, and Joel~T Dudley.
\newblock Deep patient: an unsupervised representation to predict the future of
  patients from the electronic health records.
\newblock {\em Scientific reports}, 6:26094, 2016.

\bibitem{muller2019does}
Rafael M{\"u}ller, Simon Kornblith, and Geoffrey Hinton.
\newblock When does label smoothing help?
\newblock {\em arXiv preprint arXiv:1906.02629}, 2019.

\bibitem{pang2005seeing}
Bo~Pang and Lillian Lee.
\newblock Seeing stars: Exploiting class relationships for sentiment
  categorization with respect to rating scales.
\newblock In {\em Proceedings of the 43rd annual meeting on association for
  computational linguistics}, pages 115--124. Association for Computational
  Linguistics, 2005.

\bibitem{pennington2014glove}
Jeffrey Pennington, Richard Socher, and Christopher Manning.
\newblock Glove: Global vectors for word representation.
\newblock In {\em Proceedings of the 2014 conference on empirical methods in
  natural language processing (EMNLP)}, pages 1532--1543, 2014.

\bibitem{pereyra2017regularizing}
Gabriel Pereyra, George Tucker, Jan Chorowski, {\L}ukasz Kaiser, and Geoffrey
  Hinton.
\newblock Regularizing neural networks by penalizing confident output
  distributions.
\newblock {\em arXiv preprint arXiv:1701.06548}, 2017.

\bibitem{sensoy2018evidential}
Murat Sensoy, Lance Kaplan, and Melih Kandemir.
\newblock Evidential deep learning to quantify classification uncertainty.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  3183--3193, 2018.

\bibitem{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock {\em arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{szegedy2016rethinking}
Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew
  Wojna.
\newblock Rethinking the inception architecture for computer vision.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2818--2826, 2016.

\bibitem{thulasidasan2019combating}
Sunil Thulasidasan, Tanmoy Bhattacharya, Jeff Bilmes, Gopinath Chennupati, and
  Jamal Mohd-Yusof.
\newblock Combating label noise in deep learning using abstention.
\newblock In {\em International Conference on Machine Learning}, pages
  6234--6243, 2019.

\bibitem{vapnik2015uniform}
Vladimir~N Vapnik and A~Ya Chervonenkis.
\newblock On the uniform convergence of relative frequencies of events to their
  probabilities.
\newblock In {\em Measures of complexity}, pages 11--30. Springer, 2015.

\bibitem{verma2018manifold}
Vikas Verma, Alex Lamb, Christopher Beckham, Aaron Courville, Ioannis
  Mitliagkis, and Yoshua Bengio.
\newblock Manifold mixup: Encouraging meaningful on-manifold interpolation as a
  regularizer.
\newblock {\em arXiv preprint arXiv:1806.05236}, 2018.

\bibitem{xiao2017fashion}
Han Xiao, Kashif Rasul, and Roland Vollgraf.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms.
\newblock {\em arXiv preprint arXiv:1708.07747}, 2017.

\bibitem{xie2017aggregated}
Saining Xie, Ross Girshick, Piotr Doll{\'a}r, Zhuowen Tu, and Kaiming He.
\newblock Aggregated residual transformations for deep neural networks.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1492--1500, 2017.

\bibitem{mixup_pytorch}
Hongyi Zhang.
\newblock https://github.com/hongyi-zhang/mixup.

\bibitem{zhang2017mixup}
Hongyi Zhang, Moustapha Cisse, Yann~N Dauphin, and David Lopez-Paz.
\newblock mixup: Beyond empirical risk minimization.
\newblock {\em arXiv preprint arXiv:1710.09412}, 2017.

\bibitem{zhou2016text}
Peng Zhou, Zhenyu Qi, Suncong Zheng, Jiaming Xu, Hongyun Bao, and Bo~Xu.
\newblock Text classification improved by integrating bidirectional lstm with
  two-dimensional max pooling.
\newblock {\em arXiv preprint arXiv:1611.06639}, 2016.

\end{thebibliography}
