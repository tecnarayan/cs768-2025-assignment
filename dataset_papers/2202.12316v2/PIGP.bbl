\begin{thebibliography}{}

\bibitem[Allen and Cahn, 1972]{allen1972ground}
Allen, S.~M. and Cahn, J.~W. (1972).
\newblock Ground state structures in ordered binary alloys with second neighbor
  interactions.
\newblock {\em Acta Metallurgica}, 20(3):423--433.

\bibitem[Alvarez et~al., 2009]{alvarez2009latent}
Alvarez, M., Luengo, D., and Lawrence, N.~D. (2009).
\newblock Latent force models.
\newblock In {\em Artificial Intelligence and Statistics}, pages 9--16.

\bibitem[Alvarez et~al., 2013]{alvarez2013linear}
Alvarez, M.~A., Luengo, D., and Lawrence, N.~D. (2013).
\newblock Linear latent force models using {G}aussian processes.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  35(11):2693--2705.

\bibitem[Boyd and Vandenberghe, 2004]{Boyd04}
Boyd, S. and Vandenberghe, L. (2004).
\newblock {\em Convex Optimization}.
\newblock Cambridge University Press, Cambridge, UK.

\bibitem[Chen et~al., 2021]{chen2021solving}
Chen, Y., Hosseini, B., Owhadi, H., and Stuart, A.~M. (2021).
\newblock Solving and learning nonlinear {PDE}s with {G}aussian processes.
\newblock {\em arXiv preprint arXiv:2103.12959}.

\bibitem[Chen et~al., 2020]{chen2020physics}
Chen, Y., Lu, L., Karniadakis, G.~E., and Dal~Negro, L. (2020).
\newblock Physics-informed neural networks for inverse problems in nano-optics
  and metamaterials.
\newblock {\em Optics Express}, 28(8):11618--11633.

\bibitem[Derezinski and Mahoney, 2021]{DM21_NoticesAMS}
Derezinski, M. and Mahoney, M.~W. (2021).
\newblock Determinantal point processes in randomized numerical linear algebra.
\newblock {\em Notices of the AMS}, 68(1):34--45.

\bibitem[Drineas and Mahoney, 2016]{DM16_CACM}
Drineas, P. and Mahoney, M.~W. (2016).
\newblock {RandNLA}: Randomized numerical linear algebra.
\newblock {\em Communications of the ACM}, 59:80--90.

\bibitem[Edwards, 2022]{EdwCACM22}
Edwards, C. (2022).
\newblock Neural networks learn to speed up simulations.
\newblock {\em Communications of the ACM}, 65(5):27--29.

\bibitem[Graepel, 2003]{graepel2003solving}
Graepel, T. (2003).
\newblock Solving noisy linear operator equations by {G}aussian processes:
  Application to ordinary and partial differential equations.
\newblock In {\em ICML}, pages 234--241.

\bibitem[Hartikainen et~al., 2012]{hartikainen2012state}
Hartikainen, J., Sepp{\"a}nen, M., and S{\"a}rkk{\"a}, S. (2012).
\newblock State-space inference for non-linear latent force models with
  application to satellite orbit prediction.
\newblock In {\em ICML}.

\bibitem[Hensman et~al., 2013]{GPSVI13}
Hensman, J., Fusi, N., and Lawrence, N.~D. (2013).
\newblock Gaussian processes for big data.
\newblock In {\em Proceedings of the Conference on Uncertainty in Artificial
  Intelligence (UAI)}.

\bibitem[Kanagawa et~al., 2018]{kanagawa2018gaussian}
Kanagawa, M., Hennig, P., Sejdinovic, D., and Sriperumbudur, B.~K. (2018).
\newblock Gaussian processes and kernel methods: A review on connections and
  equivalences.
\newblock {\em arXiv preprint arXiv:1807.02582}.

\bibitem[Karniadakis et~al., 2021]{karniadakis2021physics}
Karniadakis, G.~E., Kevrekidis, I.~G., Lu, L., Perdikaris, P., Wang, S., and
  Yang, L. (2021).
\newblock Physics-informed machine learning.
\newblock {\em Nature Reviews Physics}, 3(6):422--440.

\bibitem[Kingma and Ba, 2014]{kingma2014adam}
Kingma, D.~P. and Ba, J. (2014).
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}.

\bibitem[Kingma and Welling, 2013]{kingma2013auto}
Kingma, D.~P. and Welling, M. (2013).
\newblock Auto-encoding variational {B}ayes.
\newblock {\em arXiv preprint arXiv:1312.6114}.

\bibitem[Krishnapriyan et~al., 2021]{krishnapriyan2021characterizing}
Krishnapriyan, A., Gholami, A., Zhe, S., Kirby, R., and Mahoney, M.~W. (2021).
\newblock Characterizing possible failure modes in physics-informed neural
  networks.
\newblock {\em Advances in Neural Information Processing Systems}, 34.

\bibitem[Lou et~al., 2021]{lou2021physics}
Lou, Q., Meng, X., and Karniadakis, G.~E. (2021).
\newblock Physics-informed neural networks for solving forward and inverse flow
  problems via the {B}oltzmann-{BGK} formulation.
\newblock {\em Journal of Computational Physics}, 447:110676.

\bibitem[Mahoney, 2011]{Mah-mat-rev_JRNL}
Mahoney, M.~W. (2011).
\newblock Randomized algorithms for matrices and data.
\newblock {\em Foundations and Trends in Machine Learning}, 3(2):123--224.

\bibitem[Mao et~al., 2020]{mao2020physics}
Mao, Z., Jagtap, A.~D., and Karniadakis, G.~E. (2020).
\newblock Physics-informed neural networks for high-speed flows.
\newblock {\em Computer Methods in Applied Mechanics and Engineering},
  360:112789.

\bibitem[Murray and Adams, 2010]{murray2010slice}
Murray, I. and Adams, R.~P. (2010).
\newblock Slice sampling covariance hyperparameters of latent {G}aussian
  models.
\newblock In {\em Advances in Neural Information Processing Systems}.

\bibitem[Nocedal and Wright, 2006]{NW06}
Nocedal, J. and Wright, S. (2006).
\newblock {\em Numerical Optimization}.
\newblock Springer, New York.

\bibitem[Paszke et~al., 2019]{paszke2019pytorch}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., et~al. (2019).
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock {\em Advances in Neural Information Processing Systems},
  32:8026--8037.

\bibitem[Penwarden et~al., 2021]{penwarden2021multifidelity}
Penwarden, M., Zhe, S., Narayan, A., and Kirby, R.~M. (2021).
\newblock Multifidelity modeling for physics-informed neural networks (pinns).
\newblock {\em Journal of Computational Physics}, page 110844.

\bibitem[Raissi et~al., 2017]{raissi2017machine}
Raissi, M., Perdikaris, P., and Karniadakis, G.~E. (2017).
\newblock Machine learning of linear differential equations using {G}aussian
  processes.
\newblock {\em Journal of Computational Physics}, 348:683--693.

\bibitem[Raissi et~al., 2019]{raissi2019physics}
Raissi, M., Perdikaris, P., and Karniadakis, G.~E. (2019).
\newblock Physics-informed neural networks: A deep learning framework for
  solving forward and inverse problems involving nonlinear partial differential
  equations.
\newblock {\em Journal of Computational Physics}, 378:686--707.

\bibitem[Wang et~al., 2022a]{wang2022and}
Wang, S., Yu, X., and Perdikaris, P. (2022a).
\newblock When and why {PINN}s fail to train: A neural tangent kernel
  perspective.
\newblock {\em Journal of Computational Physics}, 449:110768.

\bibitem[Wang et~al., 2022b]{wang2022physics}
Wang, Z., Xing, W., Kirby, R., and Zhe, S. (2022b).
\newblock Physics informed deep kernel learning.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 1206--1218. PMLR.

\bibitem[Ward et~al., 2020]{ward2020black}
Ward, W., Ryder, T., Prangle, D., and Alvarez, M. (2020).
\newblock Black-box inference for non-linear latent force models.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 3088--3098. PMLR.

\bibitem[Williams and Rasmussen, 2006]{williams2006gaussian}
Williams, C.~K. and Rasmussen, C.~E. (2006).
\newblock {\em Gaussian processes for machine learning}, volume~2.
\newblock MIT press Cambridge, MA.

\bibitem[Zhang et~al., 2020]{zhang2020learning}
Zhang, D., Guo, L., and Karniadakis, G.~E. (2020).
\newblock Learning in modal space: Solving time-dependent stochastic pdes using
  physics-informed neural networks.
\newblock {\em SIAM Journal on Scientific Computing}, 42(2):A639--A665.

\end{thebibliography}
