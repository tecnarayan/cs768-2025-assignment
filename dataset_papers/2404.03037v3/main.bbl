\begin{thebibliography}{48}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abdolmaleki et~al.(2018)Abdolmaleki, Springenberg, Tassa, Munos, Heess, and Riedmiller]{DBLP:conf/iclr/AbdolmalekiSTMH18}
Abdolmaleki, A., Springenberg, J.~T., Tassa, Y., Munos, R., Heess, N., and Riedmiller, M.~A.
\newblock Maximum a posteriori policy optimisation.
\newblock In \emph{6th International Conference on Learning Representations, {ICLR} 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings}. OpenReview.net, 2018.

\bibitem[Asadi et~al.(2018)Asadi, Misra, and Littman]{DBLP:conf/icml/AsadiML18}
Asadi, K., Misra, D., and Littman, M.~L.
\newblock Lipschitz continuity in model-based reinforcement learning.
\newblock In Dy, J.~G. and Krause, A. (eds.), \emph{Proceedings of the 35th International Conference on Machine Learning, {ICML}, 2018}, volume~80 of \emph{Proceedings of Machine Learning Research}, pp.\  264--273. {PMLR}, 2018.

\bibitem[Bester et~al.(2019)Bester, James, and Konidaris]{Bester2019MultiPassQF}
Bester, C.~J., James, S., and Konidaris, G.~D.
\newblock Multi-pass q-networks for deep reinforcement learning with parameterised action spaces.
\newblock \emph{ArXiv}, abs/1905.04388, 2019.

\bibitem[Bhardwaj et~al.(2020)Bhardwaj, Handa, Fox, and Boots]{DBLP:conf/l4dc/BhardwajHFB20}
Bhardwaj, M., Handa, A., Fox, D., and Boots, B.
\newblock Information theoretic model predictive q-learning.
\newblock In \emph{{L4DC}}, volume 120 of \emph{Proceedings of Machine Learning Research}, pp.\  840--850. {PMLR}, 2020.

\bibitem[Chua et~al.(2018)Chua, Calandra, McAllister, and Levine]{DBLP:conf/nips/ChuaCML18}
Chua, K., Calandra, R., McAllister, R., and Levine, S.
\newblock Deep reinforcement learning in a handful of trials using probabilistic dynamics models.
\newblock In Bengio, S., Wallach, H.~M., Larochelle, H., Grauman, K., Cesa{-}Bianchi, N., and Garnett, R. (eds.), \emph{Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montr{\'{e}}al, Canada}, pp.\  4759--4770, 2018.

\bibitem[Doshi{-}Velez \& Konidaris(2016)Doshi{-}Velez and Konidaris]{DBLP:conf/ijcai/Doshi-VelezK16}
Doshi{-}Velez, F. and Konidaris, G.~D.
\newblock Hidden parameter markov decision processes: {A} semiparametric regression approach for discovering latent task parametrizations.
\newblock In Kambhampati, S. (ed.), \emph{Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, {IJCAI} 2016, New York, NY, USA, 9-15 July 2016}, pp.\  1432--1440. {IJCAI/AAAI} Press, 2016.

\bibitem[Ebert et~al.(2018)Ebert, Finn, Dasari, Xie, Lee, and Levine]{DBLP:journals/corr/abs-1812-00568}
Ebert, F., Finn, C., Dasari, S., Xie, A., Lee, A.~X., and Levine, S.
\newblock Visual foresight: Model-based deep reinforcement learning for vision-based robotic control.
\newblock \emph{CoRR}, abs/1812.00568, 2018.

\bibitem[Fan et~al.(2019)Fan, Su, Zhang, and Yu]{Fan2019HybridAR}
Fan, Z., Su, R., Zhang, W., and Yu, Y.
\newblock Hybrid actor-critic reinforcement learning in parameterized action space.
\newblock In \emph{IJCAI}, 2019.

\bibitem[Fu et~al.(2019)Fu, Tang, Hao, Lei, Chen, and Fan]{Fu2019DeepMR}
Fu, H., Tang, H., Hao, J., Lei, Z., Chen, Y., and Fan, C.
\newblock Deep multi-agent reinforcement learning with discrete-continuous hybrid action spaces.
\newblock In \emph{IJCAI}, 2019.

\bibitem[Fu et~al.(2023{\natexlab{a}})Fu, Yao, Gottesman, Doshi{-}Velez, and Konidaris]{DBLP:conf/iclr/FuYGD023}
Fu, H., Yao, J., Gottesman, O., Doshi{-}Velez, F., and Konidaris, G.
\newblock Performance bounds for model and policy transfer in hidden-parameter mdps.
\newblock In \emph{The Eleventh International Conference on Learning Representations, {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023}. OpenReview.net, 2023{\natexlab{a}}.

\bibitem[Fu et~al.(2023{\natexlab{b}})Fu, Yu, Tiwari, Littman, and Konidaris]{DBLP:conf/icml/FuYTL023}
Fu, H., Yu, S., Tiwari, S., Littman, M.~L., and Konidaris, G.
\newblock Meta-learning parameterized skills.
\newblock In Krause, A., Brunskill, E., Cho, K., Engelhardt, B., Sabato, S., and Scarlett, J. (eds.), \emph{International Conference on Machine Learning, {ICML} 2023, 23-29 July 2023, Honolulu, Hawaii, {USA}}, volume 202 of \emph{Proceedings of Machine Learning Research}, pp.\  10461--10481. {PMLR}, 2023{\natexlab{b}}.

\bibitem[Fujimoto et~al.(2018)Fujimoto, van Hoof, and Meger]{DBLP:conf/icml/FujimotoHM18}
Fujimoto, S., van Hoof, H., and Meger, D.
\newblock Addressing function approximation error in actor-critic methods.
\newblock In Dy, J.~G. and Krause, A. (eds.), \emph{Proceedings of the 35th International Conference on Machine Learning, {ICML} 2018, Stockholmsm{\"{a}}ssan, Stockholm, Sweden, July 10-15, 2018}, volume~80 of \emph{Proceedings of Machine Learning Research}, pp.\  1582--1591. {PMLR}, 2018.

\bibitem[Garcia et~al.(1989)Garcia, Prett, and Morari]{Garcia1989ModelPC}
Garcia, C.~E., Prett, D.~M., and Morari, M.
\newblock Model predictive control: Theory and practice - a survey.
\newblock \emph{Autom.}, 25:\penalty0 335--348, 1989.

\bibitem[Gelada et~al.(2019)Gelada, Kumar, Buckman, Nachum, and Bellemare]{DBLP:conf/icml/GeladaKBNB19}
Gelada, C., Kumar, S., Buckman, J., Nachum, O., and Bellemare, M.~G.
\newblock Deepmdp: Learning continuous latent space models for representation learning.
\newblock In Chaudhuri, K. and Salakhutdinov, R. (eds.), \emph{Proceedings of the 36th International Conference on Machine Learning, {ICML} 2019}, volume~97 of \emph{Proceedings of Machine Learning Research}, pp.\  2170--2179. {PMLR}, 2019.

\bibitem[Ha \& Schmidhuber(2018)Ha and Schmidhuber]{DBLP:conf/nips/HaS18}
Ha, D. and Schmidhuber, J.
\newblock Recurrent world models facilitate policy evolution.
\newblock In \emph{NeurIPS}, pp.\  2455--2467, 2018.

\bibitem[Hafner et~al.(2019)Hafner, Lillicrap, Fischer, Villegas, Ha, Lee, and Davidson]{DBLP:conf/icml/HafnerLFVHLD19}
Hafner, D., Lillicrap, T.~P., Fischer, I., Villegas, R., Ha, D., Lee, H., and Davidson, J.
\newblock Learning latent dynamics for planning from pixels.
\newblock In \emph{{ICML}}, volume~97 of \emph{Proceedings of Machine Learning Research}, pp.\  2555--2565. {PMLR}, 2019.

\bibitem[Hafner et~al.(2020)Hafner, Lillicrap, Ba, and Norouzi]{DBLP:conf/iclr/HafnerLB020}
Hafner, D., Lillicrap, T.~P., Ba, J., and Norouzi, M.
\newblock Dream to control: Learning behaviors by latent imagination.
\newblock In \emph{{ICLR}}. OpenReview.net, 2020.

\bibitem[Hafner et~al.(2021)Hafner, Lillicrap, Norouzi, and Ba]{DBLP:conf/iclr/HafnerL0B21}
Hafner, D., Lillicrap, T.~P., Norouzi, M., and Ba, J.
\newblock Mastering atari with discrete world models.
\newblock In \emph{{ICLR}}. OpenReview.net, 2021.

\bibitem[Hafner et~al.(2023)Hafner, Pasukonis, Ba, and Lillicrap]{DBLP:journals/corr/abs-2301-04104}
Hafner, D., Pasukonis, J., Ba, J., and Lillicrap, T.~P.
\newblock Mastering diverse domains through world models.
\newblock \emph{CoRR}, abs/2301.04104, 2023.

\bibitem[Hansen et~al.(2022)Hansen, Su, and Wang]{DBLP:conf/icml/HansenSW22}
Hansen, N., Su, H., and Wang, X.
\newblock Temporal difference learning for model predictive control.
\newblock In Chaudhuri, K., Jegelka, S., Song, L., Szepesv{\'{a}}ri, C., Niu, G., and Sabato, S. (eds.), \emph{International Conference on Machine Learning, {ICML} 2022, 17-23 July 2022, Baltimore, Maryland, {USA}}, volume 162 of \emph{Proceedings of Machine Learning Research}, pp.\  8387--8406. {PMLR}, 2022.

\bibitem[Hausknecht \& Stone(2016{\natexlab{a}})Hausknecht and Stone]{Stone2016HalfFO}
Hausknecht, M. and Stone, P.
\newblock Half field offense: An environment for multiagent learning and ad hoc teamwork.
\newblock 2016{\natexlab{a}}.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:501883}.

\bibitem[Hausknecht \& Stone(2016{\natexlab{b}})Hausknecht and Stone]{DBLP:journals/corr/HausknechtS15a}
Hausknecht, M.~J. and Stone, P.
\newblock Deep reinforcement learning in parameterized action space.
\newblock In Bengio, Y. and LeCun, Y. (eds.), \emph{4th International Conference on Learning Representations, {ICLR} 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings}, 2016{\natexlab{b}}.

\bibitem[Janner et~al.(2019)Janner, Fu, Zhang, and Levine]{DBLP:conf/nips/JannerFZL19}
Janner, M., Fu, J., Zhang, M., and Levine, S.
\newblock When to trust your model: Model-based policy optimization.
\newblock In \emph{NeurIPS}, pp.\  12498--12509, 2019.

\bibitem[Kaiser et~al.(2020)Kaiser, Babaeizadeh, Milos, Osinski, Campbell, Czechowski, Erhan, Finn, Kozakowski, Levine, Mohiuddin, Sepassi, Tucker, and Michalewski]{DBLP:conf/iclr/KaiserBMOCCEFKL20}
Kaiser, L., Babaeizadeh, M., Milos, P., Osinski, B., Campbell, R.~H., Czechowski, K., Erhan, D., Finn, C., Kozakowski, P., Levine, S., Mohiuddin, A., Sepassi, R., Tucker, G., and Michalewski, H.
\newblock Model based reinforcement learning for atari.
\newblock In \emph{{ICLR}}. OpenReview.net, 2020.

\bibitem[Killian et~al.(2017)Killian, Daulton, Doshi{-}Velez, and Konidaris]{DBLP:conf/nips/KillianDDK17}
Killian, T.~W., Daulton, S., Doshi{-}Velez, F., and Konidaris, G.~D.
\newblock Robust and efficient transfer learning with hidden parameter markov decision processes.
\newblock In Guyon, I., von Luxburg, U., Bengio, S., Wallach, H.~M., Fergus, R., Vishwanathan, S. V.~N., and Garnett, R. (eds.), \emph{Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, {USA}}, pp.\  6250--6261, 2017.

\bibitem[Kingma \& Welling(2014)Kingma and Welling]{DBLP:journals/corr/KingmaW13}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational bayes.
\newblock In Bengio, Y. and LeCun, Y. (eds.), \emph{2nd International Conference on Learning Representations, {ICLR} 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings}, 2014.

\bibitem[Li et~al.(2022)Li, Tang, Zheng, Hao, Li, Wang, Meng, and Wang]{Li2021HyARAD}
Li, B., Tang, H., Zheng, Y., Hao, J., Li, P., Wang, Z., Meng, Z., and Wang, L.
\newblock Hyar: Addressing discrete-continuous action reinforcement learning via hybrid action representation.
\newblock In \emph{The Tenth International Conference on Learning Representations, {ICLR} 2022, Virtual Event, April 25-29, 2022}. OpenReview.net, 2022.

\bibitem[Lillicrap et~al.(2016)Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa, Silver, and Wierstra]{DBLP:journals/corr/LillicrapHPHETS15}
Lillicrap, T.~P., Hunt, J.~J., Pritzel, A., Heess, N., Erez, T., Tassa, Y., Silver, D., and Wierstra, D.
\newblock Continuous control with deep reinforcement learning.
\newblock In Bengio, Y. and LeCun, Y. (eds.), \emph{4th International Conference on Learning Representations, {ICLR} 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings}, 2016.

\bibitem[Lowrey et~al.(2019)Lowrey, Rajeswaran, Kakade, Todorov, and Mordatch]{DBLP:conf/iclr/LowreyRKTM19}
Lowrey, K., Rajeswaran, A., Kakade, S.~M., Todorov, E., and Mordatch, I.
\newblock Plan online, learn offline: Efficient learning and exploration via model-based control.
\newblock In \emph{{ICLR} (Poster)}. OpenReview.net, 2019.

\bibitem[Masson et~al.(2016)Masson, Ranchod, and Konidaris]{masson2016reinforcement}
Masson, W., Ranchod, P., and Konidaris, G.
\newblock Reinforcement learning with parameterized actions.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~30, 2016.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare, Graves, Riedmiller, Fidjeland, Ostrovski, Petersen, Beattie, Sadik, Antonoglou, King, Kumaran, Wierstra, Legg, and Hassabis]{DBLP:journals/nature/MnihKSRVBGRFOPB15}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare, M.~G., Graves, A., Riedmiller, M.~A., Fidjeland, A., Ostrovski, G., Petersen, S., Beattie, C., Sadik, A., Antonoglou, I., King, H., Kumaran, D., Wierstra, D., Legg, S., and Hassabis, D.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nat.}, 518\penalty0 (7540):\penalty0 529--533, 2015.

\bibitem[Nagabandi et~al.(2018)Nagabandi, Kahn, Fearing, and Levine]{DBLP:conf/icra/NagabandiKFL18}
Nagabandi, A., Kahn, G., Fearing, R.~S., and Levine, S.
\newblock Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning.
\newblock In \emph{{ICRA}}, pp.\  7559--7566. {IEEE}, 2018.

\bibitem[Neunert et~al.(2019)Neunert, Abdolmaleki, Wulfmeier, Lampe, Springenberg, Hafner, Romano, Buchli, Heess, and Riedmiller]{Neunert2019ContinuousDiscreteRL}
Neunert, M., Abdolmaleki, A., Wulfmeier, M., Lampe, T., Springenberg, J.~T., Hafner, R., Romano, F., Buchli, J., Heess, N. M.~O., and Riedmiller, M.~A.
\newblock Continuous-discrete reinforcement learning for hybrid control in robotics.
\newblock \emph{ArXiv}, abs/2001.00449, 2019.

\bibitem[Nguyen et~al.(2021)Nguyen, Shu, Pham, Bui, and Ermon]{DBLP:conf/icml/NguyenSPBE21}
Nguyen, T.~D., Shu, R., Pham, T., Bui, H., and Ermon, S.
\newblock Temporal predictive coding for model-based planning in latent space.
\newblock In \emph{{ICML}}, volume 139 of \emph{Proceedings of Machine Learning Research}, pp.\  8130--8139. {PMLR}, 2021.

\bibitem[Okada \& Taniguchi(2019)Okada and Taniguchi]{DBLP:conf/corl/OkadaT19}
Okada, M. and Taniguchi, T.
\newblock Variational inference {MPC} for bayesian model-based reinforcement learning.
\newblock In Kaelbling, L.~P., Kragic, D., and Sugiura, K. (eds.), \emph{3rd Annual Conference on Robot Learning, CoRL 2019, Osaka, Japan, October 30 - November 1, 2019, Proceedings}, volume 100 of \emph{Proceedings of Machine Learning Research}, pp.\  258--272. {PMLR}, 2019.

\bibitem[Pirotta et~al.(2015)Pirotta, Restelli, and Bascetta]{DBLP:journals/ml/PirottaRB15}
Pirotta, M., Restelli, M., and Bascetta, L.
\newblock Policy gradient in lipschitz markov decision processes.
\newblock \emph{Mach. Learn.}, 100\penalty0 (2-3):\penalty0 255--283, 2015.

\bibitem[Pong et~al.(2018)Pong, Gu, Dalal, and Levine]{DBLP:conf/iclr/PongGDL18}
Pong, V., Gu, S., Dalal, M., and Levine, S.
\newblock Temporal difference models: Model-free deep {RL} for model-based control.
\newblock In \emph{{ICLR} (Poster)}. OpenReview.net, 2018.

\bibitem[Rachelson \& Lagoudakis(2010)Rachelson and Lagoudakis]{DBLP:conf/isaim/RachelsonL10}
Rachelson, E. and Lagoudakis, M.~G.
\newblock On the locality of action domination in sequential decision making.
\newblock In \emph{International Symposium on Artificial Intelligence and Mathematics, {ISAIM} 2010, 2010}, 2010.

\bibitem[Rubinstein(1997)]{Rubinstein1997OptimizationOC}
Rubinstein, R.~Y.
\newblock Optimization of computer simulation models with rare events.
\newblock \emph{European Journal of Operational Research}, 99:\penalty0 89--112, 1997.

\bibitem[Schrittwieser et~al.(2020)Schrittwieser, Antonoglou, Hubert, Simonyan, Sifre, Schmitt, Guez, Lockhart, Hassabis, Graepel, Lillicrap, and Silver]{DBLP:journals/nature/SchrittwieserAH20}
Schrittwieser, J., Antonoglou, I., Hubert, T., Simonyan, K., Sifre, L., Schmitt, S., Guez, A., Lockhart, E., Hassabis, D., Graepel, T., Lillicrap, T.~P., and Silver, D.
\newblock Mastering atari, go, chess and shogi by planning with a learned model.
\newblock \emph{Nat.}, 588\penalty0 (7839):\penalty0 604--609, 2020.

\bibitem[Schulman et~al.(2015)Schulman, Levine, Abbeel, Jordan, and Moritz]{DBLP:conf/icml/SchulmanLAJM15}
Schulman, J., Levine, S., Abbeel, P., Jordan, M.~I., and Moritz, P.
\newblock Trust region policy optimization.
\newblock In Bach, F.~R. and Blei, D.~M. (eds.), \emph{Proceedings of the 32nd International Conference on Machine Learning, {ICML} 2015, Lille, France, 6-11 July 2015}, volume~37 of \emph{{JMLR} Workshop and Conference Proceedings}, pp.\  1889--1897. JMLR.org, 2015.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and Klimov]{DBLP:journals/corr/SchulmanWDRK17}
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O.
\newblock Proximal policy optimization algorithms.
\newblock \emph{CoRR}, abs/1707.06347, 2017.

\bibitem[Sekar et~al.(2020)Sekar, Rybkin, Daniilidis, Abbeel, Hafner, and Pathak]{DBLP:conf/icml/SekarRDAHP20}
Sekar, R., Rybkin, O., Daniilidis, K., Abbeel, P., Hafner, D., and Pathak, D.
\newblock Planning to explore via self-supervised world models.
\newblock In \emph{{ICML}}, volume 119 of \emph{Proceedings of Machine Learning Research}, pp.\  8583--8592. {PMLR}, 2020.

\bibitem[Sutton(1990)]{DBLP:conf/icml/Sutton90}
Sutton, R.~S.
\newblock Integrated architectures for learning, planning, and reacting based on approximating dynamic programming.
\newblock In Porter, B.~W. and Mooney, R.~J. (eds.), \emph{Machine Learning, Proceedings of the Seventh International Conference on Machine Learning, Austin, Texas, USA, June 21-23, 1990}, pp.\  216--224. Morgan Kaufmann, 1990.

\bibitem[Williams et~al.(2015)Williams, Aldrich, and Theodorou]{DBLP:journals/corr/WilliamsAT15}
Williams, G., Aldrich, A., and Theodorou, E.~A.
\newblock Model predictive path integral control using covariance variable importance sampling.
\newblock \emph{CoRR}, abs/1509.01149, 2015.

\bibitem[Xiong et~al.(2018)Xiong, Wang, Yang, Sun, Han, Zheng, Fu, Zhang, Liu, and Liu]{Xiong2018ParametrizedDQ}
Xiong, J., Wang, Q., Yang, Z., Sun, P., Han, L., Zheng, Y., Fu, H., Zhang, T., Liu, J., and Liu, H.
\newblock Parametrized deep q-networks learning: Reinforcement learning with discrete-continuous hybrid action space.
\newblock \emph{ArXiv}, abs/1810.06394, 2018.

\bibitem[Yu et~al.(2020)Yu, Thomas, Yu, Ermon, Zou, Levine, Finn, and Ma]{DBLP:conf/nips/YuTYEZLFM20}
Yu, T., Thomas, G., Yu, L., Ermon, S., Zou, J.~Y., Levine, S., Finn, C., and Ma, T.
\newblock {MOPO:} model-based offline policy optimization.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Zhang et~al.(2018)Zhang, Vikram, Smith, Abbeel, Johnson, and Levine]{DBLP:journals/corr/abs-1808-09105}
Zhang, M., Vikram, S., Smith, L.~M., Abbeel, P., Johnson, M.~J., and Levine, S.
\newblock {SOLAR:} deep structured latent representations for model-based reinforcement learning.
\newblock \emph{CoRR}, abs/1808.09105, 2018.

\end{thebibliography}
