\begin{thebibliography}{85}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Andrade et~al.(2020)Andrade, Costa, Mota, Ortega, Feitosa, Soto, and Heipke]{Andrade2020}
Andrade, R.~B., Costa, G. A. O.~P., Mota, G. L.~A., Ortega, M.~X., Feitosa, R.~Q., Soto, P.~J., and Heipke, C.
\newblock Evaluation of semantic segmentation methods for deforestation detection in the amazon.
\newblock \emph{The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences}, 2020.

\bibitem[Arvanitidis et~al.(2017)Arvanitidis, Hansen, and Hauberg]{Arvanitidis2017}
Arvanitidis, G., Hansen, L., and Hauberg, S.
\newblock Latent space oddity: on the curvature of deep generative models.
\newblock \emph{International Conference on Learning Representations (ICLR)}, 2017.

\bibitem[Balestriero et~al.(2022{\natexlab{a}})Balestriero, Bottou, and LeCun]{Balestriero2022}
Balestriero, R., Bottou, L., and LeCun, Y.
\newblock The effects of regularization and data augmentation are class dependent.
\newblock \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2022{\natexlab{a}}.

\bibitem[Balestriero et~al.(2022{\natexlab{b}})Balestriero, Misra, and LeCun]{Balestriero2022ADI}
Balestriero, R., Misra, I., and LeCun, Y.
\newblock A data-augmentation is worth a thousand samples: Analytical moments and sampling-free training.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2022{\natexlab{b}}.

\bibitem[Bao \& Song(2020)Bao and Song]{bao2020}
Bao, E. and Song, L.
\newblock Equivariant neural networks and equivarification.
\newblock \emph{ArXiv}, 2020.

\bibitem[Bengio et~al.(2012)Bengio, Courville, and Vincent]{Bengio2012}
Bengio, Y., Courville, A.~C., and Vincent, P.
\newblock Representation learning: A review and new perspectives.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 2012.

\bibitem[Bexten et~al.(2021)Bexten, Schmidt, Walter, and Elkmann]{Schmidt2021}
Bexten, S., Schmidt, J., Walter, C., and Elkmann, N.
\newblock Human action recognition as part of a natural machine operation framework.
\newblock In \emph{IEEE International Conference on Emerging Technologies and Factory Automation (ETFA)}, 2021.

\bibitem[Borodin(2017)]{Borodin2017}
Borodin, A.~N.
\newblock \emph{Stochastic Processes}.
\newblock Birkhäuser Cham, 2017.

\bibitem[Bronstein et~al.(2021)Bronstein, Bruna, Cohen, and Veličković]{bronstein2021geometric}
Bronstein, M.~M., Bruna, J., Cohen, T., and Veličković, P.
\newblock Geometric deep learning: Grids, groups, graphs, geodesics, and gauges.
\newblock \emph{ArXiv}, 2021.

\bibitem[Chefer et~al.(2022)Chefer, Schwartz, and Wolf]{Chefer2022}
Chefer, H., Schwartz, I., and Wolf, L.
\newblock Optimizing relevance maps of vision transformers improves robustness.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2022.

\bibitem[Chen et~al.(2019)Chen, Dobriban, and Lee]{Chen2019InvarianceRV}
Chen, S., Dobriban, E., and Lee, J.
\newblock Invariance reduces variance: Understanding data augmentation in deep learning and beyond.
\newblock \emph{ArXiv}, 2019.

\bibitem[Cheng et~al.(2018)Cheng, Qiu, Calderbank, and Sapiro]{RotDCF}
Cheng, X., Qiu, Q., Calderbank, R., and Sapiro, G.
\newblock Rotdcf: Decomposition of convolutional filters for rotation-equivariant deep networks.
\newblock \emph{ArXiv}, 2018.

\bibitem[Cohen \& Welling(2016)Cohen and Welling]{cohen2016group}
Cohen, T. and Welling, M.
\newblock Group equivariant convolutional networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2016.

\bibitem[Dao et~al.(2019)Dao, Gu, Ratner, Smith, De~Sa, and Re]{kernelDA2019}
Dao, T., Gu, A., Ratner, A., Smith, V., De~Sa, C., and Re, C.
\newblock A kernel theory of modern data augmentation.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2019.

\bibitem[Delchevalerie et~al.(2021)Delchevalerie, Bibal, Fr\'{e}nay, and Mayer]{delchevalerie2021}
Delchevalerie, V., Bibal, A., Fr\'{e}nay, B., and Mayer, A.
\newblock Achieving rotational invariance with bessel-convolutional neural networks.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2021.

\bibitem[Detlefsen et~al.(2018)Detlefsen, Freifeld, and Hauberg]{Detlefsen2018}
Detlefsen, N.~S., Freifeld, O., and Hauberg, S.
\newblock Deep diffeomorphic transformer networks.
\newblock \emph{Conference on Computer Vision and Pattern Recognition (CVPR)}, 2018.

\bibitem[Djolonga et~al.(2021)Djolonga, Yung, Tschannen, Romijnders, Beyer, Kolesnikov, Puigcerver, Minderer, D’Amour, Moldovan, Gelly, Houlsby, Zhai, and Lucic]{Djolonga2021}
Djolonga, J., Yung, J., Tschannen, M., Romijnders, R., Beyer, L., Kolesnikov, A., Puigcerver, J., Minderer, M., D’Amour, A., Moldovan, D., Gelly, S., Houlsby, N., Zhai, X., and Lucic, M.
\newblock On robustness and transferability of convolutional neural networks.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2021.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and Houlsby]{Dosovitskiy2020}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., Uszkoreit, J., and Houlsby, N.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock \emph{International Conference on Learning Representations (ICLR)}, 2021.

\bibitem[Duvenaud et~al.(2020)Duvenaud, Wang, Jacobsen, Swersky, Norouzi, and Grathwohl]{Duvenaud2020}
Duvenaud, D., Wang, J., Jacobsen, J., Swersky, K., Norouzi, M., and Grathwohl, W.
\newblock Your classifier is secretly an energy based model and you should treat it like one.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2020.

\bibitem[Ecker et~al.(2019)Ecker, Sinz, Froudarakis, Fahey, Cadena, Walker, Cobos, Reimer, Tolias, and Bethge]{ecker2018rotationequivariant}
Ecker, A.~S., Sinz, F.~H., Froudarakis, E., Fahey, P.~G., Cadena, S.~A., Walker, E.~Y., Cobos, E., Reimer, J., Tolias, A.~S., and Bethge, M.
\newblock A rotation-equivariant convolutional neural network model of primary visual cortex.
\newblock \emph{International Conference on Learning Representations (ICLR)}, 2019.

\bibitem[Engstrom et~al.(2019)Engstrom, Tran, Tsipras, Schmidt, and Madry]{Engstrom2019}
Engstrom, L., Tran, B., Tsipras, D., Schmidt, L., and Madry, A.
\newblock Exploring the landscape of spatial robustness.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2019.

\bibitem[Esteves et~al.(2018)Esteves, Allen-Blanchette, Zhou, and Daniilidis]{PolarTransformer}
Esteves, C., Allen-Blanchette, C., Zhou, X., and Daniilidis, K.
\newblock Polar transformer networks.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2018.

\bibitem[Gal \& Ghahramani(2016)Gal and Ghahramani]{Gal2016}
Gal, Y. and Ghahramani, Z.
\newblock Dropout as a bayesian approximation: Representing model uncertainty in deep learning.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2016.

\bibitem[Geifman et~al.(2018)Geifman, Uziel, and El-Yaniv]{Geifman2018}
Geifman, Y., Uziel, G., and El-Yaniv, R.
\newblock Bias-reduced uncertainty estimation for deep neural classifiers.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2018.

\bibitem[Gens \& Domingos(2014)Gens and Domingos]{Gens2014}
Gens, R. and Domingos, P.
\newblock Deep symmetry networks.
\newblock In \emph{International Conference on Neural Information Processing Systems (NeurIPS)}, 2014.

\bibitem[Ghamizi et~al.(2022)Ghamizi, Cordy, Papadakis, and Traon]{Ghamizi2023}
Ghamizi, S., Cordy, M., Papadakis, M., and Traon, Y.~L.
\newblock On evaluating adversarial robustness of chest x-ray classification: Pitfalls and best practices.
\newblock In \emph{ArXiv}, 2022.

\bibitem[Goodfellow et~al.(2009)Goodfellow, Le, Saxe, Lee, and Ng]{Goodfellow2009}
Goodfellow, I.~J., Le, Q.~V., Saxe, A.~M., Lee, H., and Ng, A.~Y.
\newblock Measuring invariances in deep networks.
\newblock In \emph{International Conference on Neural Information Processing Systems (NeurIPS)}, 2009.

\bibitem[Graf(2006)]{Graf2006}
Graf, M.
\newblock Coordinate transformations in object recognition.
\newblock \emph{Psychological bulletin}, 2006.

\bibitem[Gómez et~al.(2020)Gómez, Neira, Hernández Hoyos, Arbeláez, and Forero-Romero]{Gomez2020}
Gómez, C., Neira, M., Hernández Hoyos, M., Arbeláez, P., and Forero-Romero, J.~E.
\newblock {Classifying image sequences of astronomical transients with deep neural networks}.
\newblock \emph{Monthly Notices of the Royal Astronomical Society}, 2020.

\bibitem[Gómez et~al.(2008)Gómez, Shutter, and Rouder]{Gomez2008}
Gómez, P., Shutter, J., and Rouder, J.
\newblock Memory for objects in canonical and noncanonical viewpoints.
\newblock \emph{Psychonomic bulletin and review}, 2008.

\bibitem[Hall(2015)]{hall2015lie}
Hall, B.
\newblock \emph{Lie Groups, Lie Algebras, and Representations: An Elementary Introduction}.
\newblock Graduate Texts in Mathematics. Springer International Publishing, 2015.

\bibitem[Harris et~al.(2001)Harris, Harris, and Caine]{Harris2001}
Harris, I.~M., Harris, J.~A., and Caine, D.
\newblock {Object Orientation Agnosia: A Failure to Find the Axis?}
\newblock \emph{Journal of Cognitive Neuroscience}, 2001.

\bibitem[Hendrycks \& Gimpel(2016)Hendrycks and Gimpel]{GELU}
Hendrycks, D. and Gimpel, K.
\newblock Gaussian error linear units (gelus).
\newblock \emph{ArXiv}, 2016.

\bibitem[Hernández-García \& König(2018)Hernández-García and König]{Hernandez2018}
Hernández-García, A. and König, P.
\newblock Data augmentation instead of explicit regularization.
\newblock \emph{ArXiv}, 2018.

\bibitem[Hu et~al.(2019)Hu, Zagoruyko, and Komodakis]{hu2019exploring}
Hu, S.~X., Zagoruyko, S., and Komodakis, N.
\newblock Exploring weight symmetry in deep neural networks.
\newblock \emph{Computer Vision and Image Understanding}, 2019.

\bibitem[Huang et~al.(2021)Huang, Sankar, Amini, Kottur, Geramifard, Razaviyayn, and Beirami]{Huang2021}
Huang, T., Sankar, C., Amini, P., Kottur, S., Geramifard, A., Razaviyayn, M., and Beirami, A.
\newblock Dair: Data augmented invariant regularization.
\newblock \emph{ArXiv}, 2021.

\bibitem[Inoue(2020)]{Inoue2020}
Inoue, Y.
\newblock Satellite- and drone-based remote sensing of crops and soils for smart farming – a review.
\newblock \emph{Soil Science and Plant Nutrition}, 2020.

\bibitem[Ioffe \& Szegedy(2015)Ioffe and Szegedy]{BatchNorm}
Ioffe, S. and Szegedy, C.
\newblock Batch normalization: Accelerating deep network training by reducing internal covariate shift.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2015.

\bibitem[Jaderberg et~al.(2015)Jaderberg, Simonyan, Zisserman, and Kavukcuoglu]{jaderberg2016spatial}
Jaderberg, M., Simonyan, K., Zisserman, A., and Kavukcuoglu, K.
\newblock Spatial transformer networks.
\newblock In \emph{International Conference on Neural Information Processing Systems (NeurIPS)}, 2015.

\bibitem[Kaba et~al.(2023)Kaba, Mondal, Zhang, Bengio, and Ravanbakhsh]{Kaba2023}
Kaba, S.-O., Mondal, A.~K., Zhang, Y., Bengio, Y., and Ravanbakhsh, S.
\newblock Equivariance with learned canonicalization functions.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2023.

\bibitem[Konkle \& Oliva(2011)Konkle and Oliva]{Konkle2011}
Konkle, T. and Oliva, A.
\newblock Canonical visual size for real-world objects.
\newblock \emph{Journal of experimental psychology, human perception and performance}, 2011.

\bibitem[Kotelevskii et~al.(2022)Kotelevskii, Artemenkov, Fedyanin, Noskov, Fishkov, Shelmanov, Vazhentsev, Petiushko, and Panov]{kotelevskii2022}
Kotelevskii, N., Artemenkov, A., Fedyanin, K., Noskov, F., Fishkov, A., Shelmanov, A., Vazhentsev, A., Petiushko, A., and Panov, M.
\newblock Nonparametric uncertainty quantification for single deterministic neural network.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2022.

\bibitem[Lakshminarayanan et~al.(2017)Lakshminarayanan, Pritzel, and Blundell]{Lakshminarayanan2017}
Lakshminarayanan, B., Pritzel, A., and Blundell, C.
\newblock Simple and scalable predictive uncertainty estimation using deep ensembles.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2017.

\bibitem[Landau \& Binder(2005)Landau and Binder]{Landau2005}
Landau, D. and Binder, K.
\newblock \emph{A Guide to Monte Carlo Simulations in Statistical Physics}.
\newblock Cambridge University Press, 2005.

\bibitem[Lecun et~al.(1998)Lecun, Bottou, Bengio, and Haffner]{LeNet}
Lecun, Y., Bottou, L., Bengio, Y., and Haffner, P.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 1998.

\bibitem[Lecun et~al.(2006)Lecun, Chopra, Hadsell, Ranzato, and Huang]{LeCun2006}
Lecun, Y., Chopra, S., Hadsell, R., Ranzato, M., and Huang, F.
\newblock A tutorial on energy-based learning.
\newblock \emph{Predicting structured data}, 2006.

\bibitem[Lee et~al.(2018)Lee, Lee, Lee, and Shin]{Lee2018}
Lee, K., Lee, K., Lee, H., and Shin, J.
\newblock A simple unified framework for detecting out-of-distribution samples and adversarial attacks.
\newblock In \emph{International Conference on Neural Information Processing Systems (NeurIPS)}, 2018.

\bibitem[Leibo et~al.(2011)Leibo, Mutch, and Poggio]{Leibo2011}
Leibo, J., Mutch, J., and Poggio, T.
\newblock Learning to discount transformations as the computational goal of visual cortex.
\newblock \emph{Nature Precedings}, 2011.

\bibitem[LeJeune et~al.(2019)LeJeune, Balestriero, Javadi, and Baraniuk]{LeJeune2019}
LeJeune, D., Balestriero, R., Javadi, H., and Baraniuk, R.~G.
\newblock Implicit rugosity regularization via data augmentation.
\newblock \emph{ArXiv}, 2019.

\bibitem[Li et~al.(2018)Li, Xu, Taylor, Studer, and Goldstein]{Li2018}
Li, H., Xu, Z., Taylor, G., Studer, C., and Goldstein, T.
\newblock Visualizing the loss landscape of neural nets.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, 2018.

\bibitem[Lin \& Lucey(2017)Lin and Lucey]{Lin2017}
Lin, C.-H. and Lucey, S.
\newblock Inverse compositional spatial transformer networks.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition (CVPR)}, 2017.

\bibitem[Liu et~al.(2020)Liu, Wang, Owens, and Li]{Liu2020}
Liu, W., Wang, X., Owens, J., and Li, Y.
\newblock Energy-based out-of-distribution detection.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2020.

\bibitem[Liu et~al.(2022)Liu, Mao, Wu, Feichtenhofer, Darrell, and Xie]{convnext}
Liu, Z., Mao, H., Wu, C.-Y., Feichtenhofer, C., Darrell, T., and Xie, S.
\newblock A convnet for the 2020s.
\newblock \emph{IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2022.

\bibitem[Loshchilov \& Hutter(2017)Loshchilov and Hutter]{AdamW}
Loshchilov, I. and Hutter, F.
\newblock Decoupled weight decay regularization.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2017.

\bibitem[Marcos et~al.(2017)Marcos, Volpi, Komodakis, and Tuia]{Marcos_2017}
Marcos, D., Volpi, M., Komodakis, N., and Tuia, D.
\newblock Rotation equivariant vector field networks.
\newblock In \emph{IEEE International Conference on Computer Vision (ICCV)}, 2017.

\bibitem[Moen et~al.(2019)Moen, Bannon, Kudo, Graf, Covert, and Valen]{Moen2019}
Moen, E., Bannon, D., Kudo, T., Graf, W., Covert, M., and Valen, D.
\newblock Deep learning for cellular image analysis.
\newblock \emph{Nature Methods}, 2019.

\bibitem[Mondal et~al.(2023)Mondal, Panigrahi, Kaba, Rajeswar, and Ravanbakhsh]{Mondal2023}
Mondal, A.~K., Panigrahi, S.~S., Kaba, S.-O., Rajeswar, S., and Ravanbakhsh, S.
\newblock Equivariant adaptation of large pretrained models.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2023.

\bibitem[Moon et~al.(2020)Moon, Kim, Shin, and Hwang]{Moon2020}
Moon, J., Kim, J., Shin, Y., and Hwang, S.
\newblock Confidence-aware learning for deep neural networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.

\bibitem[Nash(2016)]{nash2016}
Nash, D.
\newblock \emph{A Friendly Introduction to Group Theory}.
\newblock CreateSpace Independent Publishing Platform, 2016.

\bibitem[Olah et~al.(2020)Olah, Cammarata, Voss, Schubert, and Goh]{olah2020}
Olah, C., Cammarata, N., Voss, C., Schubert, L., and Goh, G.
\newblock Naturally occurring equivariance in neural networks.
\newblock \emph{Distill}, 2020.

\bibitem[Osawa et~al.(2019)Osawa, Swaroop, Jain, Eschenhagen, Turner, Yokota, and Khan]{Osawa2019}
Osawa, K., Swaroop, S., Jain, A., Eschenhagen, R., Turner, R.~E., Yokota, R., and Khan, M.~E.
\newblock Practical deep learning with bayesian principles.
\newblock \emph{International Conference on Neural Information Processing Systems (NeurIPS)}, 2019.

\bibitem[Osband(2016)]{Osband2016}
Osband, I.
\newblock Risk versus uncertainty in deep learning: Bayes, bootstrap and the dangers of dropout.
\newblock \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2016.

\bibitem[Palmer et~al.(1981)Palmer, Rosch, and Chase]{palmer1981}
Palmer, S.~E., Rosch, E., and Chase, P.
\newblock Canonical perspective and the perception of objects.
\newblock \emph{Vision Research}, 1981.

\bibitem[Qiu et~al.(2018)Qiu, Cheng, Calderbank, and Sapiro]{dcfnet}
Qiu, Q., Cheng, X., Calderbank, R., and Sapiro, G.
\newblock {DCFNet}: Deep neural network with decomposed convolutional filters.
\newblock \emph{International Conference on Machine Learning (ICML)}, 2018.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma, Huang, Karpathy, Khosla, Bernstein, Berg, and Fei-Fei]{Imagenet2015}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.~C., and Fei-Fei, L.
\newblock {ImageNet Large Scale Visual Recognition Challenge}.
\newblock \emph{International Journal of Computer Vision (IJCV)}, 2015.

\bibitem[Sanbonmatsu et~al.(1998)Sanbonmatsu, Posavac, Kardes, and Mantel]{Sanbonmatsu1998}
Sanbonmatsu, D.~M., Posavac, S.~S., Kardes, F.~R., and Mantel, S.~P.
\newblock Selective hypothesis testing.
\newblock \emph{Psychonomic Bulletin \& Review}, 1998.

\bibitem[Schmidt \& Stober(2022)Schmidt and Stober]{Schmidt2022}
Schmidt, J. and Stober, S.
\newblock Learning continuous rotation canonicalization with radial beam sampling.
\newblock \emph{ArXiv}, 2022.

\bibitem[Schmidt et~al.(2024)Schmidt, Köhler, and Borstell]{Schmidt2024}
Schmidt, J., Köhler, B., and Borstell, H.
\newblock Reviving simulated annealing: Lifting its degeneracies for real-time job scheduling.
\newblock In \emph{Hawaii International Conference on System Sciences (HICSS)}, 2024.

\bibitem[Shakerinava et~al.(2022)Shakerinava, Mondal, and Ravanbakhsh]{Shakerinava2022}
Shakerinava, M., Mondal, A.~K., and Ravanbakhsh, S.
\newblock Structuring representations using group invariants.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2022.

\bibitem[Shorten \& Khoshgoftaar(2019)Shorten and Khoshgoftaar]{Shorten2019}
Shorten, C. and Khoshgoftaar, T.~M.
\newblock A survey on image data augmentation for deep learning.
\newblock \emph{Journal of Big Data}, 2019.

\bibitem[Shu et~al.(2018)Shu, Chen, Yu, and Han]{Shu2018}
Shu, C., Chen, X., Yu, C., and Han, H.
\newblock A refined spatial transformer network.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2018.

\bibitem[Snell et~al.(2017)Snell, Swersky, and Zemel]{Jake2017}
Snell, J., Swersky, K., and Zemel, R.
\newblock Prototypical networks for few-shot learning.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2017.

\bibitem[Stallkamp et~al.(2012)Stallkamp, Schlipsing, Salmen, and Igel]{GTSRB}
Stallkamp, J., Schlipsing, M., Salmen, J., and Igel, C.
\newblock Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition.
\newblock \emph{Neural Networks}, 2012.

\bibitem[Taghizadeh-Mehrjardi et~al.(2020)Taghizadeh-Mehrjardi, Nabiollahi, Rasoli, Kerry, and Scholten]{Mehrjardi2020}
Taghizadeh-Mehrjardi, R., Nabiollahi, K., Rasoli, L., Kerry, R., and Scholten, T.
\newblock Land suitability assessment and agricultural production sustainability using machine learning models.
\newblock \emph{Agronomy}, 2020.

\bibitem[Tai et~al.(2019)Tai, Bailis, and Valiant]{tai2019equivariant}
Tai, K.~S., Bailis, P., and Valiant, G.
\newblock {Equivariant Transformer Networks}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2019.

\bibitem[Tan \& Le(2019)Tan and Le]{efficientnet}
Tan, M. and Le, Q.
\newblock {E}fficient{N}et: Rethinking model scaling for convolutional neural networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2019.

\bibitem[Tuggener et~al.(2023)Tuggener, Stadelmann, and Schmidhuber]{Tuggener2023}
Tuggener, L., Stadelmann, T., and Schmidhuber, J.
\newblock Efficient rotation invariance in deep neural networks through artificial mental rotation.
\newblock \emph{ArXiv}, 2023.

\bibitem[Ustyuzhaninov et~al.(2020)Ustyuzhaninov, Cadena, Froudarakis, Fahey, Walker, Cobos, Reimer, Sinz, Tolias, Bethge, and Ecker]{Ustyuzhaninov2020Rotation}
Ustyuzhaninov, I., Cadena, S.~A., Froudarakis, E., Fahey, P.~G., Walker, E.~Y., Cobos, E., Reimer, J., Sinz, F.~H., Tolias, A.~S., Bethge, M., and Ecker, A.~S.
\newblock Rotation-invariant clustering of neuronal responses in primary visual cortex.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2020.

\bibitem[Wang et~al.(2021)Wang, Shelhamer, Liu, Olshausen, and Darrell]{Wang2021}
Wang, D., Shelhamer, E., Liu, S., Olshausen, B., and Darrell, T.
\newblock Tent: Fully test-time adaptation by entropy minimization.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2021.

\bibitem[Wang et~al.(2022)Wang, Fink, Van~Gool, and Dai]{Wang2022}
Wang, Q., Fink, O., Van~Gool, L., and Dai, D.
\newblock Continual test-time domain adaptation.
\newblock \emph{Conference on Computer Vision and Pattern Recognition (CVPR)}, 2022.

\bibitem[Weiler \& Cesa(2019)Weiler and Cesa]{Weiler2019}
Weiler, M. and Cesa, G.
\newblock General e(2)-equivariant steerable cnns.
\newblock In \emph{Conference on Neural Information Processing Systems (NeurIPS)}, 2019.

\bibitem[Weiler et~al.(2017)Weiler, Hamprecht, and Storath]{Weiler2017}
Weiler, M., Hamprecht, F.~A., and Storath, M.
\newblock Learning steerable filters for rotation equivariant cnns.
\newblock \emph{IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2017.

\bibitem[Wu et~al.(2024)Wu, Chi, Wang, Plataniotis, and Feng]{Wu2024}
Wu, Y., Chi, Z., Wang, Y., Plataniotis, K.~N., and Feng, S.
\newblock Test-time domain adaptation by learning domain-aware batch normalization.
\newblock In \emph{Conference on Artificial Intelligence (AAAI)}, 2024.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{FashionMNIST}
Xiao, H., Rasul, K., and Vollgraf, R.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.
\newblock \emph{ArXiv}, 2017.

\bibitem[Zhou et~al.(2020)Zhou, Knowles, and Finn]{Zhou2020}
Zhou, A., Knowles, T., and Finn, C.
\newblock Meta-learning symmetries by reparameterization.
\newblock \emph{International Conference on Learning Representations (ICLR)}, 2020.

\end{thebibliography}
