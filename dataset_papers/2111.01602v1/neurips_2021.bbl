\begin{thebibliography}{24}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbasi-Yadkori et~al.(2011)Abbasi-Yadkori, P{\'a}l, and
  Szepesv{\'a}ri]{abbasi2011improved}
Abbasi-Yadkori, Y., P{\'a}l, D., and Szepesv{\'a}ri, C.
\newblock Improved algorithms for linear stochastic bandits.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2312--2320, 2011.

\bibitem[Abbasi-Yadkori et~al.(2012)Abbasi-Yadkori, Pal, and
  Szepesvari]{abbasi2012online}
Abbasi-Yadkori, Y., Pal, D., and Szepesvari, C.
\newblock Online-to-confidence-set conversions and application to sparse
  stochastic bandits.
\newblock In \emph{Artificial Intelligence and Statistics}, pp.\  1--9. PMLR,
  2012.

\bibitem[Azoury \& Warmuth(2001)Azoury and Warmuth]{azoury2001relative}
Azoury, K.~S. and Warmuth, M.~K.
\newblock Relative loss bounds for on-line density estimation with the
  exponential family of distributions.
\newblock \emph{Machine Learning}, 43\penalty0 (3):\penalty0 211--246, 2001.

\bibitem[Bartlett et~al.(2015)Bartlett, Koolen, Malek, Takimoto, and
  Warmuth]{bartlett2015minimax}
Bartlett, P.~L., Koolen, W.~M., Malek, A., Takimoto, E., and Warmuth, M.~K.
\newblock Minimax fixed-design linear regression.
\newblock In \emph{Conference on Learning Theory}, pp.\  226--239, 2015.

\bibitem[Cella et~al.(2020)Cella, Lazaric, and Pontil]{cella2020meta}
Cella, L., Lazaric, A., and Pontil, M.
\newblock Meta-learning with stochastic linear bandits.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1360--1370. PMLR, 2020.

\bibitem[Cesa-Bianchi \& Lugosi(2006)Cesa-Bianchi and
  Lugosi]{cesa2006prediction}
Cesa-Bianchi, N. and Lugosi, G.
\newblock \emph{Prediction, learning, and games}.
\newblock Cambridge university press, 2006.

\bibitem[Cesa-Bianchi et~al.(1996)Cesa-Bianchi, Long, and
  Warmuth]{cesa1996worst}
Cesa-Bianchi, N., Long, P.~M., and Warmuth, M.~K.
\newblock Worst-case quadratic loss bounds for prediction using linear
  functions and gradient descent.
\newblock \emph{IEEE Transactions on Neural Networks}, 7\penalty0 (3):\penalty0
  604--619, 1996.

\bibitem[Cortes \& Mohri(2007)Cortes and Mohri]{cortes2007transductive}
Cortes, C. and Mohri, M.
\newblock On transductive regression.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  305--312, 2007.

\bibitem[Foster(1991)]{foster1991prediction}
Foster, D.~P.
\newblock Prediction in the worst case.
\newblock \emph{The Annals of Statistics}, pp.\  1084--1090, 1991.

\bibitem[Freedman(1975)]{freedman1975tail}
Freedman, D.~A.
\newblock On tail probabilities for martingales.
\newblock \emph{the Annals of Probability}, pp.\  100--118, 1975.

\bibitem[Gaillard et~al.(2019)Gaillard, Gerchinovitz, Huard, and
  Stoltz]{gaillard2019uniform}
Gaillard, P., Gerchinovitz, S., Huard, M., and Stoltz, G.
\newblock Uniform regret bounds over $\mathbb{R}^{d}$ for the sequential linear
  regression problem with the square loss.
\newblock In \emph{Algorithmic Learning Theory}, pp.\  404--432, 2019.

\bibitem[Kamath(2015)]{kamath2015bounds}
Kamath, G.
\newblock Bounds on the expectation of the maximum of samples from a gaussian.
\newblock \emph{URL http://www. gautamkamath. com/writings/gaussian max. pdf},
  2015.

\bibitem[Kivinen \& Warmuth(1997)Kivinen and Warmuth]{kivinen1997exponentiated}
Kivinen, J. and Warmuth, M.~K.
\newblock Exponentiated gradient versus gradient descent for linear predictors.
\newblock \emph{information and computation}, 132\penalty0 (1):\penalty0 1--63,
  1997.

\bibitem[Littlestone et~al.(1991)Littlestone, Long, and
  Warmuth]{littlestone1991line}
Littlestone, N., Long, P.~M., and Warmuth, M.~K.
\newblock On-line learning of linear functions.
\newblock In \emph{Proceedings of the twenty-third annual ACM symposium on
  Theory of computing}, pp.\  465--475, 1991.

\bibitem[Maillard(2016)]{maillard2016self}
Maillard, O.-A.
\newblock Self-normalization techniques for streaming confident regression.
\newblock 2016.

\bibitem[Malek \& Bartlett(2018)Malek and Bartlett]{malek2018horizon}
Malek, A. and Bartlett, P.~L.
\newblock Horizon-independent minimax linear regression.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  5259--5268, 2018.

\bibitem[Mourtada(2019)]{mourtada2019exact}
Mourtada, J.
\newblock Exact minimax risk for linear least squares, and the lower tail of
  sample covariance matrices.
\newblock \emph{arXiv preprint arXiv:1912.10754}, 2019.

\bibitem[Orabona et~al.(2012)Orabona, Cesa-Bianchi, and
  Gentile]{orabona2012beyond}
Orabona, F., Cesa-Bianchi, N., and Gentile, C.
\newblock Beyond logarithmic bounds in online learning.
\newblock In \emph{Artificial intelligence and statistics}, pp.\  823--831.
  PMLR, 2012.

\bibitem[Russac et~al.(2019)Russac, Vernade, and Capp{\'e}]{russac2019weighted}
Russac, Y., Vernade, C., and Capp{\'e}, O.
\newblock Weighted linear bandits for non-stationary environments.
\newblock \emph{arXiv preprint arXiv:1909.09146}, 2019.

\bibitem[Sudakov(1969)]{sudakov1969gaussian}
Sudakov, V.~N.
\newblock Gaussian measures, cauchy measures and $\varepsilon$-entropy.
\newblock In \emph{Soviet Math. Dokl}, volume~10, pp.\  310--313, 1969.

\bibitem[Tirinzoni et~al.(2020)Tirinzoni, Pirotta, Restelli, and
  Lazaric]{tirinzoni2020asymptotically}
Tirinzoni, A., Pirotta, M., Restelli, M., and Lazaric, A.
\newblock An asymptotically optimal primal-dual incremental algorithm for
  contextual linear bandits.
\newblock \emph{arXiv preprint arXiv:2010.12247}, 2020.

\bibitem[Tripuraneni \& Mackey(2019)Tripuraneni and
  Mackey]{tripuraneni2019single}
Tripuraneni, N. and Mackey, L.
\newblock Single point transductive prediction.
\newblock \emph{arXiv}, pp.\  arXiv--1908, 2019.

\bibitem[Valko et~al.(2014)Valko, Munos, Kveton, and
  Koc{\'a}k]{valko2014spectral}
Valko, M., Munos, R., Kveton, B., and Koc{\'a}k, T.
\newblock Spectral bandits for smooth graph functions.
\newblock In \emph{International Conference on Machine Learning}, pp.\  46--54.
  PMLR, 2014.

\bibitem[Vovk(2001)]{vovk2001competitive}
Vovk, V.
\newblock Competitive on-line statistics.
\newblock \emph{International Statistical Review}, 69\penalty0 (2):\penalty0
  213--248, 2001.

\end{thebibliography}
