\begin{thebibliography}{52}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Allingham et~al.(2022)Allingham, Wenzel, Mariet, Mustafa, Puigcerver,
  Houlsby, Jerfel, Fortuin, Lakshminarayanan, Snoek, Tran, Ruiz, and
  Jenatton]{moe_ensemble}
Allingham, J.~U., Wenzel, F., Mariet, Z.~E., Mustafa, B., Puigcerver, J.,
  Houlsby, N., Jerfel, G., Fortuin, V., Lakshminarayanan, B., Snoek, J., Tran,
  D., Ruiz, C.~R., and Jenatton, R.
\newblock Sparse moes meet efficient ensembles.
\newblock In \emph{Transactions on Machine Learning Research}, 2022.

\bibitem[Bachman et~al.(2019)Bachman, Hjelm, and
  Buchwalter]{Bachman2019LearningRB}
Bachman, P., Hjelm, R.~D., and Buchwalter, W.
\newblock Learning representations by maximizing mutual information across
  views.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Breiman(1996)]{bagging}
Breiman, L.
\newblock Bagging predictors.
\newblock \emph{Mach Learn}, 24:\penalty0 123--140, 1996.
\newblock \doi{https://doi.org/10.1007/BF00058655}.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{simclr}
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G.
\newblock A simple framework for contrastive learning of visual
  representations, 2020.
\newblock URL \url{https://arxiv.org/abs/2002.05709}.

\bibitem[Cohen \& Welling(2016)Cohen and Welling]{cohen2016group}
Cohen, T. and Welling, M.
\newblock Group equivariant convolutional networks.
\newblock In \emph{International conference on machine learning}, pp.\
  2990--2999. PMLR, 2016.

\bibitem[Dangovski et~al.(2021)Dangovski, Jing, Loh, Han, Srivastava, Cheung,
  Agrawal, and Soljačić]{essl}
Dangovski, R., Jing, L., Loh, C., Han, S., Srivastava, A., Cheung, B., Agrawal,
  P., and Soljačić, M.
\newblock Equivariant contrastive learning, 2021.
\newblock URL \url{https://arxiv.org/abs/2111.00899}.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern
  recognition}, pp.\  248--255. Ieee, 2009.

\bibitem[Devillers \& Lefort(2022)Devillers and Lefort]{equimod}
Devillers, A. and Lefort, M.
\newblock Equimod: An equivariance module to improve self-supervised learning,
  2022.
\newblock URL \url{https://arxiv.org/abs/2211.01244}.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and
  Houlsby]{vit}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S.,
  Uszkoreit, J., and Houlsby, N.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{ArXiv}, abs/2010.11929, 2020.

\bibitem[Dvornik et~al.(2019)Dvornik, Schmid, and Mairal]{diversity_prediction}
Dvornik, N., Schmid, C., and Mairal, J.
\newblock Diversity with cooperation: Ensemble methods for few-shot
  classification.
\newblock \emph{CoRR}, abs/1903.11341, 2019.
\newblock URL \url{http://arxiv.org/abs/1903.11341}.

\bibitem[Fort et~al.(2019)Fort, Hu, and Lakshminarayanan]{DE_losslandscape}
Fort, S., Hu, H., and Lakshminarayanan, B.
\newblock Deep ensembles: A loss landscape perspective, 2019.
\newblock URL \url{https://arxiv.org/abs/1912.02757}.

\bibitem[Gal(2016)]{Gal2016Uncertainty}
Gal, Y.
\newblock \emph{Uncertainty in Deep Learning}.
\newblock PhD thesis, University of Cambridge, 2016.

\bibitem[Gal \& Ghahramani(2015)Gal and Ghahramani]{mcdropout}
Gal, Y. and Ghahramani, Z.
\newblock Dropout as a bayesian approximation: Representing model uncertainty
  in deep learning, 2015.
\newblock URL \url{https://arxiv.org/abs/1506.02142}.

\bibitem[Gal et~al.(2017)Gal, Islam, and Ghahramani]{yarin_uq}
Gal, Y., Islam, R., and Ghahramani, Z.
\newblock Deep bayesian active learning with image data, 2017.
\newblock URL \url{https://arxiv.org/abs/1703.02910}.

\bibitem[Gidaris et~al.(2018)Gidaris, Singh, and Komodakis]{rotnet}
Gidaris, S., Singh, P., and Komodakis, N.
\newblock Unsupervised representation learning by predicting image rotations,
  2018.
\newblock URL \url{https://arxiv.org/abs/1803.07728}.

\bibitem[Hansen \& Salamon(1990)Hansen and Salamon]{nn_ensem}
Hansen, L. and Salamon, P.
\newblock Neural network ensembles.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 12\penalty0 (10):\penalty0 993--1001, 1990.
\newblock \doi{10.1109/34.58871}.

\bibitem[Havasi et~al.(2020)Havasi, Jenatton, Fort, Liu, Snoek,
  Lakshminarayanan, Dai, and Tran]{mimo}
Havasi, M., Jenatton, R., Fort, S., Liu, J.~Z., Snoek, J., Lakshminarayanan,
  B., Dai, A.~M., and Tran, D.
\newblock Training independent subnetworks for robust prediction, 2020.
\newblock URL \url{https://arxiv.org/abs/2010.06610}.

\bibitem[He et~al.(2019)He, Fan, Wu, Xie, and Girshick]{moco}
He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R.
\newblock Momentum contrast for unsupervised visual representation learning,
  2019.
\newblock URL \url{https://arxiv.org/abs/1911.05722}.

\bibitem[Hendrycks et~al.(2019)Hendrycks, Mu, Cubuk, Zoph, Gilmer, and
  Lakshminarayanan]{augmix}
Hendrycks, D., Mu, N., Cubuk, E.~D., Zoph, B., Gilmer, J., and
  Lakshminarayanan, B.
\newblock Augmix: A simple data processing method to improve robustness and
  uncertainty, 2019.
\newblock URL \url{https://arxiv.org/abs/1912.02781}.

\bibitem[Houlsby et~al.(2011)Houlsby, Huszár, Ghahramani, and
  Lengyel]{bald_uq}
Houlsby, N., Huszár, F., Ghahramani, Z., and Lengyel, M.
\newblock Bayesian active learning for classification and preference learning,
  2011.
\newblock URL \url{https://arxiv.org/abs/1112.5745}.

\bibitem[Kendall \& Gal(2017)Kendall and Gal]{kendall_diversity}
Kendall, A. and Gal, Y.
\newblock What uncertainties do we need in bayesian deep learning for computer
  vision?, 2017.
\newblock URL \url{https://arxiv.org/abs/1703.04977}.

\bibitem[Kornblith et~al.(2018)Kornblith, Shlens, and Le]{transfer2019}
Kornblith, S., Shlens, J., and Le, Q.~V.
\newblock Do better imagenet models transfer better?
\newblock \emph{2019 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pp.\  2656--2666, 2018.

\bibitem[Kumar et~al.(2022)Kumar, Raghunathan, Jones, Ma, and
  Liang]{kumar2022fine}
Kumar, A., Raghunathan, A., Jones, R., Ma, T., and Liang, P.
\newblock Fine-tuning can distort pretrained features and underperform
  out-of-distribution.
\newblock \emph{arXiv preprint arXiv:2202.10054}, 2022.

\bibitem[Lakshminarayanan et~al.(2016)Lakshminarayanan, Pritzel, and
  Blundell]{DE}
Lakshminarayanan, B., Pritzel, A., and Blundell, C.
\newblock Simple and scalable predictive uncertainty estimation using deep
  ensembles, 2016.
\newblock URL \url{https://arxiv.org/abs/1612.01474}.

\bibitem[Langley(2000)]{langley00}
Langley, P.
\newblock Crafting papers on machine learning.
\newblock In Langley, P. (ed.), \emph{Proceedings of the 17th International
  Conference on Machine Learning (ICML 2000)}, pp.\  1207--1216, Stanford, CA,
  2000. Morgan Kaufmann.

\bibitem[Lee et~al.(2016)Lee, Purushwalkam, Cogswell, Ranjan, Crandall, and
  Batra]{lee_diversity}
Lee, S., Purushwalkam, S., Cogswell, M., Ranjan, V., Crandall, D.~J., and
  Batra, D.
\newblock Stochastic multiple choice learning for training diverse deep
  ensembles.
\newblock \emph{CoRR}, abs/1606.07839, 2016.
\newblock URL \url{http://arxiv.org/abs/1606.07839}.

\bibitem[Lopes et~al.(2021)Lopes, Dauphin, and Cubuk]{no_one_rep_rules}
Lopes, R.~G., Dauphin, Y., and Cubuk, E.~D.
\newblock No one representation to rule them all: Overlapping features of
  training methods.
\newblock \emph{CoRR}, abs/2110.12899, 2021.
\newblock URL \url{https://arxiv.org/abs/2110.12899}.

\bibitem[Mania et~al.(2019)Mania, Miller, Schmidt, Hardt, and
  Recht]{modelsim2019}
Mania, H., Miller, J., Schmidt, L., Hardt, M., and Recht, B.
\newblock Model similarity mitigates test set overuse.
\newblock \emph{ArXiv}, abs/1905.12580, 2019.

\bibitem[Mustafa et~al.(2022)Mustafa, Riquelme, Puigcerver, Jenatton, and
  Houlsby]{moe2}
Mustafa, B., Riquelme, C., Puigcerver, J., Jenatton, R., and Houlsby, N.
\newblock Multimodal contrastive learning with limoe: the language-image
  mixture of experts, 2022.
\newblock URL \url{https://arxiv.org/abs/2206.02770}.

\bibitem[Noroozi \& Favaro(2016)Noroozi and Favaro]{jigsaw}
Noroozi, M. and Favaro, P.
\newblock Unsupervised learning of visual representations by solving jigsaw
  puzzles, 2016.
\newblock URL \url{https://arxiv.org/abs/1603.09246}.

\bibitem[Ovadia et~al.(2019)Ovadia, Fertig, Ren, Nado, Sculley, Nowozin,
  Dillon, Lakshminarayanan, and Snoek]{uq_ovadia}
Ovadia, Y., Fertig, E., Ren, J., Nado, Z., Sculley, D., Nowozin, S., Dillon,
  J.~V., Lakshminarayanan, B., and Snoek, J.
\newblock Can you trust your model's uncertainty? evaluating predictive
  uncertainty under dataset shift, 2019.
\newblock URL \url{https://arxiv.org/abs/1906.02530}.

\bibitem[Pang et~al.(2019)Pang, Xu, Du, Chen, and Zhu]{pang_diversity}
Pang, T., Xu, K., Du, C., Chen, N., and Zhu, J.
\newblock Improving adversarial robustness via promoting ensemble diversity,
  2019.
\newblock URL \url{https://arxiv.org/abs/1901.08846}.

\bibitem[Qui{\~{n}}onero-Candela et~al.(2006)Qui{\~{n}}onero-Candela,
  Rasmussen, Sinz, Bousquet, and Sch{\"o}lkopf]{pred_uncertainty_challenge}
Qui{\~{n}}onero-Candela, J., Rasmussen, C.~E., Sinz, F., Bousquet, O., and
  Sch{\"o}lkopf, B.
\newblock Evaluating predictive uncertainty challenge.
\newblock In Qui{\~{n}}onero-Candela, J., Dagan, I., Magnini, B., and
  d'Alch{\'e} Buc, F. (eds.), \emph{Machine Learning Challenges. Evaluating
  Predictive Uncertainty, Visual Object Classification, and Recognising Tectual
  Entailment}, pp.\  1--27, Berlin, Heidelberg, 2006. Springer Berlin
  Heidelberg.
\newblock ISBN 978-3-540-33428-6.

\bibitem[Rame \& Cord(2021)Rame and Cord]{dice}
Rame, A. and Cord, M.
\newblock Dice: Diversity in deep ensembles via conditional redundancy
  adversarial estimation, 2021.
\newblock URL \url{https://arxiv.org/abs/2101.05544}.

\bibitem[Reed et~al.(2021)Reed, Metzger, Srinivas, Darrell, and
  Keutzer]{reed2021selfaug}
Reed, C., Metzger, S., Srinivas, A., Darrell, T., and Keutzer, K.
\newblock Evaluating self-supervised pretraining without using labels.
\newblock In \emph{CVPR}, 2021.

\bibitem[Riquelme et~al.(2021)Riquelme, Puigcerver, Mustafa, Neumann, Jenatton,
  Pinto, Keysers, and Houlsby]{moe}
Riquelme, C., Puigcerver, J., Mustafa, B., Neumann, M., Jenatton, R., Pinto,
  A.~S., Keysers, D., and Houlsby, N.
\newblock Scaling vision with sparse mixture of experts, 2021.

\bibitem[Stickland \& Murray(2020)Stickland and Murray]{divensem_improve_calib}
Stickland, A.~C. and Murray, I.
\newblock Diverse ensembles improve calibration, 2020.
\newblock URL \url{https://arxiv.org/abs/2007.04206}.

\bibitem[Sun et~al.(2017)Sun, Shrivastava, Singh, and Gupta]{jft}
Sun, C., Shrivastava, A., Singh, S., and Gupta, A.~K.
\newblock Revisiting unreasonable effectiveness of data in deep learning era.
\newblock \emph{2017 IEEE International Conference on Computer Vision (ICCV)},
  pp.\  843--852, 2017.

\bibitem[Tian et~al.(2020)Tian, Sun, Poole, Krishnan, Schmid, and
  Isola]{tian2020makes}
Tian, Y., Sun, C., Poole, B., Krishnan, D., Schmid, C., and Isola, P.
\newblock What makes for good views for contrastive learning?
\newblock \emph{arXiv preprint arXiv:2005.10243}, 2020.

\bibitem[van~den Oord et~al.(2018)van~den Oord, Li, and Vinyals]{cpc}
van~den Oord, A., Li, Y., and Vinyals, O.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{ArXiv}, abs/1807.03748, 2018.

\bibitem[Van~Horn et~al.(2018)Van~Horn, Mac~Aodha, Song, Cui, Sun, Shepard,
  Adam, Perona, and Belongie]{inat}
Van~Horn, G., Mac~Aodha, O., Song, Y., Cui, Y., Sun, C., Shepard, A., Adam, H.,
  Perona, P., and Belongie, S.
\newblock The inaturalist species classification and detection dataset.
\newblock In \emph{The IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2018.

\bibitem[Weiler \& Cesa(2019)Weiler and Cesa]{weiler_general_2019}
Weiler, M. and Cesa, G.
\newblock General \${E}(2)\$-{Equivariant} {Steerable} {CNNs}.
\newblock \emph{arXiv:1911.08251}, November 2019.
\newblock URL \url{http://arxiv.org/abs/1911.08251}.

\bibitem[Weiler et~al.(2018)Weiler, Geiger, Welling, Boomsma, and
  Cohen]{weiler_3d_2018}
Weiler, M., Geiger, M., Welling, M., Boomsma, W., and Cohen, T.
\newblock {3D} {Steerable} {CNNs}: {Learning} {Rotationally} {Equivariant}
  {Features} in {Volumetric} {Data}.
\newblock \emph{arXiv:1807.02547}, October 2018.
\newblock URL \url{http://arxiv.org/abs/1807.02547}.

\bibitem[Wen et~al.(2020)Wen, Tran, and Ba]{batchensemble}
Wen, Y., Tran, D., and Ba, J.
\newblock Batchensemble: An alternative approach to efficient ensemble and
  lifelong learning.
\newblock 2020.
\newblock \doi{10.48550/ARXIV.2002.06715}.
\newblock URL \url{https://arxiv.org/abs/2002.06715}.

\bibitem[Wenzel et~al.(2020)Wenzel, Snoek, Tran, and
  Jenatton]{hyperparameter_ens}
Wenzel, F., Snoek, J., Tran, D., and Jenatton, R.
\newblock Hyperparameter ensembles for robustness and uncertainty
  quantification, 2020.
\newblock URL \url{https://arxiv.org/abs/2006.13570}.

\bibitem[Wenzel et~al.(2022)Wenzel, Dittadi, Gehler, Simon-Gabriel, Horn,
  Zietlow, Kernert, Russell, Brox, Schiele, Sch\"olkopf, and
  Locatello]{Wenzel2022AssayingOG}
Wenzel, F., Dittadi, A., Gehler, P.~V., Simon-Gabriel, C.-J., Horn, M.,
  Zietlow, D., Kernert, D., Russell, C., Brox, T., Schiele, B., Sch\"olkopf,
  B., and Locatello, F.
\newblock Assaying out-of-distribution generalization in transfer learning.
\newblock In \emph{Neural Information Processing Systems}, 2022.

\bibitem[Wilson(2020)]{wilson2020case}
Wilson, A.~G.
\newblock The case for bayesian deep learning.
\newblock \emph{arXiv preprint arXiv:2001.10995}, 2020.

\bibitem[Wolpert(1992)]{WOLPERT1992241}
Wolpert, D.~H.
\newblock Stacked generalization.
\newblock \emph{Neural Networks}, 5\penalty0 (2):\penalty0 241--259, 1992.
\newblock ISSN 0893-6080.
\newblock \doi{https://doi.org/10.1016/S0893-6080(05)80023-1}.
\newblock URL
  \url{https://www.sciencedirect.com/science/article/pii/S0893608005800231}.

\bibitem[Wortsman et~al.(2022)Wortsman, Ilharco, Gadre, Roelofs, Gontijo-Lopes,
  Morcos, Namkoong, Farhadi, Carmon, Kornblith, and Schmidt]{modelsoups}
Wortsman, M., Ilharco, G., Gadre, S.~Y., Roelofs, R., Gontijo-Lopes, R.,
  Morcos, A.~S., Namkoong, H., Farhadi, A., Carmon, Y., Kornblith, S., and
  Schmidt, L.
\newblock Model soups: averaging weights of multiple fine-tuned models improves
  accuracy without increasing inference time, 2022.
\newblock URL \url{https://arxiv.org/abs/2203.05482}.

\bibitem[Wu et~al.(2018)Wu, Xiong, Yu, and Lin]{Wu2018UnsupervisedFL}
Wu, Z., Xiong, Y., Yu, S.~X., and Lin, D.
\newblock Unsupervised feature learning via non-parametric instance
  discrimination.
\newblock \emph{2018 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, pp.\  3733--3742, 2018.

\bibitem[Xiao et~al.(2020)Xiao, Wang, Efros, and Darrell]{looc}
Xiao, T., Wang, X., Efros, A.~A., and Darrell, T.
\newblock What should not be contrastive in contrastive learning.
\newblock \emph{CoRR}, abs/2008.05659, 2020.
\newblock URL \url{https://arxiv.org/abs/2008.05659}.

\bibitem[Zhang et~al.(2016)Zhang, Isola, and Efros]{colorful}
Zhang, R., Isola, P., and Efros, A.~A.
\newblock Colorful image colorization, 2016.
\newblock URL \url{https://arxiv.org/abs/1603.08511}.

\end{thebibliography}
