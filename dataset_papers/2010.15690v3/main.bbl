\begin{thebibliography}{10}

\bibitem{NIPS2011_4443}
J.~S. Bergstra, R.~Bardenet, Y.~Bengio, and K.~Bal\'{a}zs.
\newblock Algorithms for hyper-parameter optimization.
\newblock In J.~Shawe-Taylor, R.~S. Zemel, P.~L. Bartlett, F.~Pereira, and
  K.~Q. Weinberger, editors, {\em Advances in Neural Information Processing
  Systems 24}, pages 2546--2554. Curran Associates, Inc., 2011.

\bibitem{berrouachedi2019deep}
A.~Berrouachedi, R.~Jaziri, and G.~Bernard.
\newblock Deep cascade of extra trees.
\newblock In {\em Pacific-Asia Conference on Knowledge Discovery and Data
  Mining}, pages 117--129. Springer, 2019.

\bibitem{DERT}
A.~Berrouachedi, R.~Jaziri, and G.~Bernard.
\newblock Deep extremely randomized trees.
\newblock In {\em International Conference on Neural Information Processing},
  pages 717--729. Springer, 2019.

\bibitem{biau2012}
G.~Biau.
\newblock Analysis of a random forests model.
\newblock {\em The Journal of Machine Learning Research}, 13(1):1063--1095,
  2012.

\bibitem{biau2008consistency}
G.~Biau, L.~Devroye, and G.~Lugosi.
\newblock Consistency of random forests and other averaging classifiers.
\newblock {\em Journal of Machine Learning Research}, 9(Sep):2015--2033, 2008.

\bibitem{breiman2001random}
L.~Breiman.
\newblock Random forests.
\newblock {\em Machine learning}, 45(1):5--32, 2001.

\bibitem{cribari2000note}
F.~Cribari-Neto, N.~L. Garcia, and K.~LP Vasconcellos.
\newblock A note on inverse moments of binomial variates.
\newblock {\em Brazilian Review of Econometrics}, 20(2):269--277, 2000.

\bibitem{fan2003random}
Wei Fan, Haixun Wang, Philip~S Yu, and Sheng Ma.
\newblock Is random model better? on its accuracy and efficiency.
\newblock In {\em Third IEEE International Conference on Data Mining}, pages
  51--58. IEEE, 2003.

\bibitem{feng2018multi}
J.~Feng, Y.~Yu, and Z-H Zhou.
\newblock Multi-layered gradient boosting decision trees.
\newblock In {\em Advances in neural information processing systems}, pages
  3551--3561, 2018.

\bibitem{ghods2020survey}
Alireza Ghods and Diane~J Cook.
\newblock A survey of deep network techniques all classifiers can adopt.
\newblock {\em Data Mining and Knowledge Discovery}, pages 1--42, 2020.

\bibitem{ghosh2002chessboard}
Soumyadip Ghosh and Shane~G Henderson.
\newblock Chessboard distributions and random vectors with specified marginals
  and covariance matrix.
\newblock {\em Operations Research}, 50(5):820--834, 2002.

\bibitem{ghosh2009patchwork}
Soumyadip Ghosh and Shane~G Henderson.
\newblock Patchwork distributions.
\newblock In {\em Advancing the Frontiers of Simulation}, pages 65--86.
  Springer, 2009.

\bibitem{guo2018bcdforest}
Y.~Guo, S.~Liu, Z.~Li, and X.~Shang.
\newblock Bcdforest: a boosting cascade deep forest model towards the
  classification of cancer subtypes based on gene expression data.
\newblock {\em BMC bioinformatics}, 19(5):118, 2018.

\bibitem{jeong2020lightweight}
M.~Jeong, J.~Nam, and B.~C. Ko.
\newblock Lightweight multilayer random forests for monitoring driver emotional
  status.
\newblock {\em IEEE Access}, 8:60344--60354, 2020.

\bibitem{kim2020interpretation}
S.~Kim, M.~Jeong, and B.~C. Ko.
\newblock Interpretation and simplification of deep forest.
\newblock {\em arXiv preprint arXiv:2001.04721}, 2020.

\bibitem{klusowski2018sharp}
J.~M. Klusowski.
\newblock Sharp analysis of a simple model for random forests.
\newblock {\em arXiv preprint arXiv:1805.02587}, 2018.

\bibitem{liu2020morphological}
B.~Liu, W.~Guo, X.~Chen, K.~Gao, X.~Zuo, R.~Wang, and A.~Yu.
\newblock Morphological attribute profile cube and deep random forest for small
  sample classification of hyperspectral image.
\newblock {\em IEEE Access}, 8:117096--117108, 2020.

\bibitem{ftdrf}
K.~Miller, C.~Hettinger, J.~Humpherys, T.~Jarvis, and D.~Kartchner.
\newblock Forward thinking: Building deep random forests.
\newblock {\em arXiv}, 2017.

\bibitem{DF_confidence_screening}
M.~{Pang}, K.~{Ting}, P.~{Zhao}, and Z.~{Zhou}.
\newblock Improving deep forest by confidence screening.
\newblock In {\em 2018 IEEE International Conference on Data Mining (ICDM)},
  pages 1194--1199, 2018.

\bibitem{scikit-learn}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel,
  M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, J.~Vanderplas, A.~Passos,
  D.~Cournapeau, M.~Brucher, M.~Perrot, and E.~Duchesnay.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock {\em Journal of Machine Learning Research}, 12:2825--2830, 2011.

\bibitem{su2019deep}
R.~Su, X.~Liu, L.~Wei, and Q.~Zou.
\newblock Deep-resp-forest: A deep forest model to predict anti-cancer drug
  response.
\newblock {\em Methods}, 166:91--102, 2019.

\bibitem{sun2020adaptive}
L.~{Sun}, Z.~{Mo}, F.~{Yan}, L.~{Xia}, F.~{Shan}, Z.~{Ding}, B.~{Song},
  W.~{Gao}, W.~{Shao}, F.~{Shi}, H.~{Yuan}, H.~{Jiang}, D.~{Wu}, Y.~{Wei},
  Y.~{Gao}, H.~{Sui}, D.~{Zhang}, and D.~{Shen}.
\newblock Adaptive feature selection guided deep forest for covid-19
  classification with chest ct.
\newblock {\em IEEE Journal of Biomedical and Health Informatics},
  24(10):2798--2805, 2020.

\bibitem{utkin2017discriminative}
L.~V Utkin and M.~A Ryabinin.
\newblock Discriminative metric learning with deep forest.
\newblock {\em arXiv preprint arXiv:1705.09620}, 2017.

\bibitem{utkin2020improvement}
L.~V Utkin and K.~D Zhuk.
\newblock Improvement of the deep forest classifier by a set of neural
  networks.
\newblock {\em Informatica}, 44(1), 2020.

\bibitem{zeng2020network}
X.~Zeng, S.~Zhu, Y.~Hou, P.~Zhang, L.~Li, J.~Li, L~F. Huang, S.~J Lewis,
  R.~Nussinov, and F.~Cheng.
\newblock Network-based prediction of drug--target interactions using an
  arbitrary-order proximity embedded deep forest.
\newblock {\em Bioinformatics}, 36(9):2805--2812, 2020.

\bibitem{zhang2019distributed}
Y.~Zhang, J.~Zhou, W.~Zheng, J.~Feng, L.~Li, Z.~Liu, M.~Li, Z.~Zhang, C.~Chen,
  X.~Li, et~al.
\newblock Distributed deep forest and its application to automatic detection of
  cash-out fraud.
\newblock {\em ACM Transactions on Intelligent Systems and Technology (TIST)},
  10(5):1--19, 2019.

\bibitem{zheng2016improving}
S.~Zheng, Y.~Song, T.~Leung, and I.~Goodfellow.
\newblock Improving the robustness of deep neural networks via stability
  training.
\newblock In {\em Proceedings of the ieee conference on computer vision and
  pattern recognition}, pages 4480--4488, 2016.

\bibitem{zhou2019deep}
Z~Zhou and J.~Feng.
\newblock Deep forest: Towards an alternative to deep neural networks.
\newblock In {\em Proceedings of the Twenty-Sixth International Joint
  Conference on Artificial Intelligence, {IJCAI-17}}, pages 3553--3559, 2017.

\bibitem{zhou2019deepbis}
Z.~Zhou and J.~Feng.
\newblock Deep forest.
\newblock {\em National Science Review}, 6(1):74--86, 2019.

\end{thebibliography}
