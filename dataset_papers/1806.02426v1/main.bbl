\ifdefined\DeclarePrefChars\DeclarePrefChars{'â€™-}\else\fi
\begin{thebibliography}{50}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Astrom(1965)]{astrom1965optimal}
Astrom, Karl~J.
\newblock Optimal control of markov decision processes with incomplete state
  estimation.
\newblock \emph{Journal of mathematical analysis and applications},
  10:\penalty0 174--205, 1965.

\bibitem[Azizzadenesheli et~al.(2016)Azizzadenesheli, Lazaric, and
  Anandkumar]{azizzadenesheli2016reinforcement}
Azizzadenesheli, Kamyar, Lazaric, Alessandro, and Anandkumar, Animashree.
\newblock Reinforcement learning of pomdps using spectral methods.
\newblock \emph{arXiv preprint 1602.07764}, 2016.

\bibitem[Babayan et~al.(2018)Babayan, Uchida, and Gershman]{babayan2018belief}
Babayan, Benedicte~M, Uchida, Naoshige, and Gershman, Samuel~J.
\newblock Belief state representation in the dopamine system.
\newblock \emph{Nature communications}, 9\penalty0 (1):\penalty0 1891, 2018.

\bibitem[Bakker(2002)]{bakker2002reinforcement}
Bakker, Bram.
\newblock Reinforcement learning with long short-term memory.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1475--1482, 2002.

\bibitem[Barto et~al.(1995)Barto, Bradtke, and Singh]{barto1995learning}
Barto, Andrew~G, Bradtke, Steven~J, and Singh, Satinder~P.
\newblock Learning to act using real-time dynamic programming.
\newblock \emph{Artificial intelligence}, 72\penalty0 (1-2):\penalty0 81--138,
  1995.

\bibitem[Bellemare et~al.(2014)Bellemare, Veness, and
  Talvitie]{bellemare2014skip}
Bellemare, Marc, Veness, Joel, and Talvitie, Erik.
\newblock Skip context tree switching.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1458--1466, 2014.

\bibitem[Bellemare(2015)]{bellemare2015count}
Bellemare, Marc~G.
\newblock Count-based frequency estimation with bounded memory.
\newblock In \emph{Twenty-Fourth International Joint Conference on Artificial
  Intelligence}, 2015.

\bibitem[Bellemare et~al.(2013)Bellemare, Naddaf, Veness, and
  Bowling]{bellemare2013arcade}
Bellemare, Marc~G, Naddaf, Yavar, Veness, Joel, and Bowling, Michael.
\newblock The arcade learning environment: An evaluation platform for general
  agents.
\newblock \emph{Journal of Artificial Intelligence Research}, 47:\penalty0
  253--279, 2013.

\bibitem[Burda et~al.(2016)Burda, Grosse, and
  Salakhutdinov]{burda2016importance}
Burda, Yuri, Grosse, Roger, and Salakhutdinov, Ruslan.
\newblock Importance weighted autoencoders.
\newblock In \emph{ICLR}, 2016.

\bibitem[Chung et~al.(2015)Chung, Kastner, Dinh, Goel, Courville, and
  Bengio]{chung2015recurrent}
Chung, Junyoung, Kastner, Kyle, Dinh, Laurent, Goel, Kratarth, Courville,
  Aaron~C, and Bengio, Yoshua.
\newblock A recurrent latent variable model for sequential data.
\newblock In \emph{Advances in neural information processing systems}, 2015.

\bibitem[Coquelin et~al.(2009)Coquelin, Deguest, and
  Munos]{coquelin2009particle}
Coquelin, Pierre-Arnaud, Deguest, Romain, and Munos, R{\'e}mi.
\newblock Particle filter-based policy gradient in pomdps.
\newblock In \emph{NIPS}, 2009.

\bibitem[Deisenroth \& Peters(2012)Deisenroth and
  Peters]{deisenroth2012solving}
Deisenroth, Marc~Peter and Peters, Jan.
\newblock Solving nonlinear continuous state-action-observation pomdps for
  mechanical systems with gaussian noise.
\newblock 2012.

\bibitem[Dhariwal et~al.(2017)Dhariwal, Hesse, Klimov, Nichol, Plappert,
  Radford, Schulman, Sidor, and Wu]{dhariwal2017openaibaselines}
Dhariwal, Prafulla, Hesse, Christopher, Klimov, Oleg, Nichol, Alex, Plappert,
  Matthias, Radford, Alec, Schulman, John, Sidor, Szymon, and Wu, Yuhuai.
\newblock Openai baselines, 2017.

\bibitem[Doshi-Velez et~al.(2015)Doshi-Velez, Pfau, Wood, and
  Roy]{doshi2015bayesian}
Doshi-Velez, Finale, Pfau, David, Wood, Frank, and Roy, Nicholas.
\newblock Bayesian nonparametric methods for partially-observable reinforcement
  learning.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 37\penalty0 (2):\penalty0 394--407, 2015.

\bibitem[Doucet \& Johansen(2009)Doucet and Johansen]{doucet2009tutorial}
Doucet, Arnaud and Johansen, Adam~M.
\newblock A tutorial on particle filtering and smoothing: Fifteen years later.
\newblock \emph{Handbook of nonlinear filtering}, 12\penalty0
  (656-704):\penalty0 3, 2009.

\bibitem[Foerster et~al.(2016)Foerster, Assael, de~Freitas, and
  Whiteson]{foerster2016learning}
Foerster, Jakob~N, Assael, Yannis~M, de~Freitas, Nando, and Whiteson, Shimon.
\newblock Learning to communicate to solve riddles with deep distributed
  recurrent q-networks.
\newblock \emph{arXiv preprint 1602.02672}, 2016.

\bibitem[Hausknecht \& Stone(2015)Hausknecht and Stone]{hausknecht2015deep}
Hausknecht, Matthew and Stone, Peter.
\newblock Deep recurrent q-learning for partially observable {MDP}s.
\newblock In \emph{2015 AAAI Fall Symposium Series}, 2015.

\bibitem[Heess et~al.(2015)Heess, Hunt, Lillicrap, and Silver]{heess2015memory}
Heess, Nicolas, Hunt, Jonathan~J, Lillicrap, Timothy~P, and Silver, David.
\newblock Memory-based control with recurrent neural networks.
\newblock \emph{arXiv preprint 1512.04455}, 2015.

\bibitem[Jaderberg et~al.(2016)Jaderberg, Mnih, Czarnecki, Schaul, Leibo,
  Silver, and Kavukcuoglu]{jaderberg2016reinforcement}
Jaderberg, Max, Mnih, Volodymyr, Czarnecki, Wojciech~Marian, Schaul, Tom,
  Leibo, Joel~Z, Silver, David, and Kavukcuoglu, Koray.
\newblock Reinforcement learning with unsupervised auxiliary tasks.
\newblock \emph{arXiv preprint 1611.05397}, 2016.

\bibitem[Kaelbling et~al.(1998)Kaelbling, Littman, and
  Cassandra]{kaelbling1998planning}
Kaelbling, Leslie~Pack, Littman, Michael~L, and Cassandra, Anthony~R.
\newblock Planning and acting in partially observable stochastic domains.
\newblock \emph{Artificial intelligence}, 101\penalty0 (1), 1998.

\bibitem[Karkus et~al.(2017)Karkus, Hsu, and Lee]{karkus2017qmdp}
Karkus, Peter, Hsu, David, and Lee, Wee~Sun.
\newblock Qmdp-net: Deep learning for planning under partial observability.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  4697--4707, 2017.

\bibitem[Katt et~al.(2017)Katt, Oliehoek, and Amato]{katt2017learning}
Katt, Sammie, Oliehoek, Frans~A, and Amato, Christopher.
\newblock Learning in pomdps with monte carlo tree search.
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Kingma \& Welling(2014)Kingma and Welling]{kingma2014auto}
Kingma, Diederik~P and Welling, Max.
\newblock Auto-encoding variational {B}ayes.
\newblock In \emph{ICLR}, 2014.

\bibitem[Lample \& Chaplot(2017)Lample and Chaplot]{lample2017playing}
Lample, Guillaume and Chaplot, Devendra~Singh.
\newblock Playing fps games with deep reinforcement learning.
\newblock In \emph{AAAI}, pp.\  2140--2146, 2017.

\bibitem[Le et~al.(2018)Le, Igl, Jin, Rainforth, and Wood]{le2018autoencoding}
Le, Tuan~Anh, Igl, Maximilian, Jin, Tom, Rainforth, Tom, and Wood, Frank.
\newblock Auto-encoding sequential {M}onte {C}arlo.
\newblock In \emph{ICLR}, 2018.

\bibitem[Maddison et~al.(2017)Maddison, Lawson, Tucker, Heess, Norouzi, Mnih,
  Doucet, and Teh]{maddison2017filtering}
Maddison, Chris~J, Lawson, John, Tucker, George, Heess, Nicolas, Norouzi,
  Mohammad, Mnih, Andriy, Doucet, Arnaud, and Teh, Yee.
\newblock Filtering variational objectives.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[McAllester \& Singh(1999)McAllester and
  Singh]{mcallester1999approximate}
McAllester, David~A and Singh, Satinder.
\newblock Approximate planning for factored pomdps using belief state
  simplification.
\newblock In \emph{Proceedings of the Fifteenth conference on Uncertainty in
  artificial intelligence}, 1999.

\bibitem[McCallum \& Ballard(1996)McCallum and
  Ballard]{mccallum1996reinforcement}
McCallum, Andrew~Kachites and Ballard, Dana.
\newblock \emph{Reinforcement learning with selective perception and hidden
  state}.
\newblock PhD thesis, University of Rochester. Dept. of Computer Science, 1996.

\bibitem[McCallum(1993)]{mccallum1993overcoming}
McCallum, R~Andrew.
\newblock Overcoming incomplete perception with utile distinction memory.
\newblock In \emph{Proceedings of the Tenth International Conference on Machine
  Learning}, pp.\  190--196, 1993.

\bibitem[Messias \& Whiteson(2017)Messias and Whiteson]{messias2017dynamic}
Messias, Jo{\~a}o~V and Whiteson, Shimon.
\newblock Dynamic-depth context tree weighting.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3330--3339, 2017.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{mnih2015human}
Mnih, Volodymyr, Kavukcuoglu, Koray, Silver, David, Rusu, Andrei~A, Veness,
  Joel, Bellemare, Marc~G, Graves, Alex, Riedmiller, Martin, Fidjeland,
  Andreas~K, Ostrovski, Georg, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529, 2015.

\bibitem[Mnih et~al.(2016)Mnih, Badia, Mirza, Graves, Lillicrap, Harley,
  Silver, and Kavukcuoglu]{mnih2016asynchronous}
Mnih, Volodymyr, Badia, Adria~Puigdomenech, Mirza, Mehdi, Graves, Alex,
  Lillicrap, Timothy, Harley, Tim, Silver, David, and Kavukcuoglu, Koray.
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, 2016.

\bibitem[Naesseth et~al.(2018)Naesseth, Linderman, Ranganath, and
  Blei]{naesseth2017variational}
Naesseth, Christian~A, Linderman, Scott~W, Ranganath, Rajesh, and Blei,
  David~M.
\newblock Variational sequential monte carlo.
\newblock In \emph{AISTATS (To Appear)}, 2018.

\bibitem[Narasimhan et~al.(2015)Narasimhan, Kulkarni, and
  Barzilay]{narasimhan2015language}
Narasimhan, Karthik, Kulkarni, Tejas, and Barzilay, Regina.
\newblock Language understanding for text-based games using deep reinforcement
  learning.
\newblock \emph{arXiv preprint 1506.08941}, 2015.

\bibitem[Oliehoek et~al.(2008)Oliehoek, Spaan, Whiteson, and
  Vlassis]{oliehoek2008exploiting}
Oliehoek, Frans~A, Spaan, Matthijs~TJ, Whiteson, Shimon, and Vlassis, Nikos.
\newblock Exploiting locality of interaction in factored dec-pomdps.
\newblock In \emph{Proceedings of the 7th international joint conference on
  Autonomous agents and multiagent systems-Volume 1}, 2008.

\bibitem[Pineau et~al.(2003)Pineau, Gordon, Thrun, et~al.]{pineau2003point}
Pineau, Joelle, Gordon, Geoff, Thrun, Sebastian, et~al.
\newblock Point-based value iteration: An anytime algorithm for pomdps.
\newblock In \emph{IJCAI}, volume~3, 2003.

\bibitem[Rezende et~al.(2014)Rezende, Mohamed, and
  Wierstra]{rezende2014stochastic}
Rezende, Danilo~Jimenez, Mohamed, Shakir, and Wierstra, Daan.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock In \emph{ICML}, 2014.

\bibitem[Roijers et~al.(2015)Roijers, Whiteson, and Oliehoek]{roijers2015point}
Roijers, Diederik~Marijn, Whiteson, Shimon, and Oliehoek, Frans~A.
\newblock Point-based planning for multi-objective pomdps.
\newblock In \emph{IJCAI}, pp.\  1666--1672, 2015.

\bibitem[Ross et~al.(2008)Ross, Pineau, Paquet, and Chaib-Draa]{ross2008online}
Ross, St{\'e}phane, Pineau, Joelle, Paquet, S{\'e}bastien, and Chaib-Draa,
  Brahim.
\newblock Online planning algorithms for pomdps.
\newblock \emph{Journal of Artificial Intelligence Research}, 32:\penalty0
  663--704, 2008.

\bibitem[Ross et~al.(2011)Ross, Pineau, Chaib-draa, and
  Kreitmann]{ross2011bayesian}
Ross, St{\'e}phane, Pineau, Joelle, Chaib-draa, Brahim, and Kreitmann, Pierre.
\newblock A bayesian approach for learning and planning in partially observable
  markov decision processes.
\newblock \emph{Journal of Machine Learning Research}, 2011.

\bibitem[Shani et~al.(2005)Shani, Brafman, and Shimony]{shani2005model}
Shani, Guy, Brafman, Ronen~I, and Shimony, Solomon~E.
\newblock Model-based online learning of pomdps.
\newblock In \emph{European Conference on Machine Learning}, pp.\  353--364.
  Springer, 2005.

\bibitem[Silver \& Veness(2010)Silver and Veness]{silver2010monte}
Silver, David and Veness, Joel.
\newblock Monte-carlo planning in large pomdps.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  2164--2172, 2010.

\bibitem[Sohn et~al.(2015)Sohn, Lee, and Yan]{sohn2015learning}
Sohn, Kihyuk, Lee, Honglak, and Yan, Xinchen.
\newblock Learning structured output representation using deep conditional
  generative models.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3483--3491, 2015.

\bibitem[Tamar et~al.(2016)Tamar, Wu, Thomas, Levine, and
  Abbeel]{tamar2016value}
Tamar, Aviv, Wu, Yi, Thomas, Garrett, Levine, Sergey, and Abbeel, Pieter.
\newblock Value iteration networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2154--2162, 2016.

\bibitem[Thrun(2000)]{thrun2000monte}
Thrun, Sebastian.
\newblock Monte carlo pomdps.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1064--1070, 2000.

\bibitem[Wierstra et~al.(2007)Wierstra, Foerster, Peters, and
  Schmidhuber]{wierstra2007solving}
Wierstra, Daan, Foerster, Alexander, Peters, Jan, and Schmidhuber, Juergen.
\newblock Solving deep memory pomdps with recurrent policy gradients.
\newblock In \emph{International Conference on Artificial Neural Networks},
  pp.\  697--706. Springer, 2007.

\bibitem[Willems et~al.(1995)Willems, Shtarkov, and
  Tjalkens]{willems1995context}
Willems, Frans~MJ, Shtarkov, Yuri~M, and Tjalkens, Tjalling~J.
\newblock The context-tree weighting method: basic properties.
\newblock \emph{IEEE Transactions on Information Theory}, 41\penalty0
  (3):\penalty0 653--664, 1995.

\bibitem[Wu et~al.(2017)Wu, Mansimov, Grosse, Liao, and Ba]{wu2017scalable}
Wu, Yuhuai, Mansimov, Elman, Grosse, Roger~B, Liao, Shun, and Ba, Jimmy.
\newblock Scalable trust-region method for deep reinforcement learning using
  {K}ronecker-factored approximation.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  5285--5294, 2017.

\bibitem[Zhang et~al.(2015)Zhang, Levine, McCarthy, Finn, and
  Abbeel]{zhang2015policy}
Zhang, Marvin, Levine, Sergey, McCarthy, Zoe, Finn, Chelsea, and Abbeel,
  Pieter.
\newblock Policy learning with continuous memory states for partially observed
  robotic control.
\newblock \emph{CoRR}, 2015.

\bibitem[Zhu et~al.(2017)Zhu, Li, and Poupart]{zhu2017improving}
Zhu, Pengfei, Li, Xin, and Poupart, Pascal.
\newblock On improving deep reinforcement learning for {POMDP}s.
\newblock \emph{arXiv preprint 1704.07978}, 2017.

\end{thebibliography}
