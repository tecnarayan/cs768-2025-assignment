\begin{thebibliography}{10}

\bibitem{wen2022robust}
Qingsong Wen, Linxiao Yang, Tian Zhou, and Liang Sun.
\newblock Robust time series analysis and applications: An industrial
  perspective.
\newblock In {\em Proceedings of the 28th ACM SIGKDD Conference on Knowledge
  Discovery and Data Mining}, pages 4836--4837, 2022.

\bibitem{bi2023accurate}
Kaifeng Bi, Lingxi Xie, Hengheng Zhang, Xin Chen, Xiaotao Gu, and Qi~Tian.
\newblock Accurate medium-range global weather forecasting with 3d neural
  networks.
\newblock {\em Nature}, 619(7970):533--538, 2023.

\bibitem{chen2024windfix}
Yaoran Chen, Candong Cai, Leilei Cao, Dan Zhang, Limin Kuang, Yan Peng, Huayan
  Pu, Chuhan Wu, Dai Zhou, and Yong Cao.
\newblock Windfix: Harnessing the power of self-supervised learning for
  versatile imputation of offshore wind speed time series.
\newblock {\em Energy}, 287:128995, 2024.

\bibitem{si2024timeseriesbench}
Haotian Si, Changhua Pei, Hang Cui, Jingwen Yang, Yongqian Sun, Shenglin Zhang,
  Jingjing Li, Haiming Zhang, Jing Han, Dan Pei, et~al.
\newblock Timeseriesbench: An industrial-grade benchmark for time series
  anomaly detection models.
\newblock {\em arXiv preprint arXiv:2402.10802}, 2024.

\bibitem{liu2024diffusion}
Zhen Liu, Wenbin Pei, Disen Lan, and Qianli Ma.
\newblock Diffusion language-shapelets for semi-supervised time-series
  classification.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~38, pages 14079--14087, 2024.

\bibitem{li2023causal}
Hongming Li, Shujian Yu, and Jose Principe.
\newblock Causal recurrent variational autoencoder for medical time series
  generation.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~37, pages 8562--8570, 2023.

\bibitem{lu2024trnn}
Minrong Lu and Xuerong Xu.
\newblock Trnn: An efficient time-series recurrent neural network for stock
  price prediction.
\newblock {\em Information Sciences}, 657:119951, 2024.

\bibitem{tcn}
Jean-Yves Franceschi, Aymeric Dieuleveut, and Martin Jaggi.
\newblock Unsupervised scalable representation learning for multivariate time
  series.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{He2019TemporalCN}
Yangdong He and Jiabao Zhao.
\newblock Temporal convolutional networks for anomaly detection in time series.
\newblock {\em J. Phys. Conf. Ser}, 2019.

\bibitem{pyraformer}
Shizhan Liu, Hang Yu, Cong Liao, Jianguo Li, Weiyao Lin, Alex~X Liu, and
  Schahram Dustdar.
\newblock Pyraformer: Low-complexity pyramidal attention for long-range time
  series modeling and forecasting.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{non-stationary}
Yong Liu, Haixu Wu, Jianmin Wang, and Mingsheng Long.
\newblock Non-stationary transformers: Exploring the stationarity in time
  series forecasting.
\newblock In {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{wu2021autoformer}
Haixu Wu, Jiehui Xu, Jianmin Wang, and Mingsheng Long.
\newblock Autoformer: Decomposition transformers with auto-correlation for
  long-term series forecasting.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  101--112, 2021.

\bibitem{timesnet}
Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang, and Mingsheng Long.
\newblock Timesnet: Temporal 2d-variation modeling for general time series
  analysis.
\newblock In {\em The Eleventh International Conference on Learning
  Representations}, 2023.

\bibitem{dlinear}
Ailing Zeng, Muxi Chen, Lei Zhang, and Qiang Xu.
\newblock Are transformers effective for time series forecasting?
\newblock In {\em Proceedings of the AAAI conference on artificial
  intelligence}, volume~37, pages 11121--11128, 2023.

\bibitem{lightts}
Tianping Zhang, Yizhuo Zhang, Wei Cao, Jiang Bian, Xiaohan Yi, Shun Zheng, and
  Jian Li.
\newblock Less is more: Fast multivariate time series forecasting with light
  sampling-oriented mlp structures.
\newblock {\em arXiv preprint arXiv:2207.01186}, 2022.

\bibitem{zhou2021informer}
Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong,
  and Wancai Zhang.
\newblock Informer: Beyond efficient transformer for long sequence time-series
  forecasting.
\newblock In {\em 35th AAAI Conference on Artificial Intelligence}, pages
  11106--11115, 2021.

\bibitem{zhou2022fedformer}
Tian Zhou, Ziqing Ma, Qingsong Wen, Xue Wang, Liang Sun, and Rong Jin.
\newblock {FEDformer}: Frequency enhanced decomposed transformer for long-term
  series forecasting.
\newblock In {\em Proc. 39th International Conference on Machine Learning},
  2022.

\bibitem{ni2024basisformer}
Zelin Ni, Hang Yu, Shizhan Liu, Jianguo Li, and Weiyao Lin.
\newblock Basisformer: Attention-based time series forecasting with learnable
  and interpretable basis.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{Patchformer}
Yuqi Nie, Nam~H Nguyen, Phanwadee Sinthong, and Jayant Kalagnanam.
\newblock A time series is worth 64 words: Long-term forecasting with
  transformers.
\newblock In {\em The Eleventh International Conference on Learning
  Representations}, 2022.

\bibitem{zhou2024one}
Tian Zhou, Peisong Niu, Liang Sun, Rong Jin, et~al.
\newblock One fits all: Power general time series analysis by pretrained lm.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{xu2023fits}
Zhijian Xu, Ailing Zeng, and Qiang Xu.
\newblock Fits: Modeling time series with $10 k $ parameters.
\newblock In {\em The Twelfth International Conference on Learning
  Representations}, 2023.

\bibitem{dai2024periodicity}
Tao Dai, Beiliang Wu, Peiyuan Liu, Naiqi Li, Jigang Bao, Yong Jiang, and
  Shu-Tao Xia.
\newblock Periodicity decoupling framework for long-term series forecasting.
\newblock In {\em The Twelfth International Conference on Learning
  Representations}, 2024.

\bibitem{deng2024disentangling}
Jinliang Deng, Xiusi Chen, Renhe Jiang, Du~Yin, Yi~Yang, Xuan Song, and Ivor~W
  Tsang.
\newblock Disentangling structured components: Towards adaptive, interpretable
  and scalable time series forecasting.
\newblock {\em IEEE Transactions on Knowledge and Data Engineering}, 2024.

\bibitem{wangtimemixer}
Shiyu Wang, Haixu Wu, Xiaoming Shi, Tengge Hu, Huakun Luo, Lintao Ma, James~Y
  Zhang, and JUN ZHOU.
\newblock Timemixer: Decomposable multiscale mixing for time series
  forecasting.
\newblock In {\em The Twelfth International Conference on Learning
  Representations}, 2024.

\bibitem{jin2024timellm}
Ming Jin, Shiyu Wang, Lintao Ma, Zhixuan Chu, James~Y. Zhang, Xiaoming Shi,
  Pin-Yu Chen, Yuxuan Liang, Yuan-Fang Li, Shirui Pan, and Qingsong Wen.
\newblock Time-{LLM}: Time series forecasting by reprogramming large language
  models.
\newblock In {\em The Twelfth International Conference on Learning
  Representations}, 2024.

\bibitem{liu2023itransformer}
Yong Liu, Tengge Hu, Haoran Zhang, Haixu Wu, Shiyu Wang, Lintao Ma, and
  Mingsheng Long.
\newblock itransformer: Inverted transformers are effective for time series
  forecasting.
\newblock In {\em The Twelfth International Conference on Learning
  Representations}, 2023.

\bibitem{eldele2024tslanet}
Emadeldeen Eldele, Mohamed Ragab, Zhenghua Chen, Min Wu, and Xiaoli Li.
\newblock Tslanet: Rethinking transformers for time series representation
  learning.
\newblock {\em arXiv preprint arXiv:2404.08472}, 2024.

\bibitem{Kitaev2020Reformer}
Nikita Kitaev, Lukasz Kaiser, and Anselm Levskaya.
\newblock Reformer: The efficient transformer.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{woo2022etsformer}
Gerald Woo, Chenghao Liu, Doyen Sahoo, Akshat Kumar, and Steven Hoi.
\newblock Etsformer: Exponential smoothing transformers for time-series
  forecasting.
\newblock {\em arXiv preprint arXiv:2202.01381}, 2022.

\bibitem{challu2023nhits}
Cristian Challu, Kin~G Olivares, Boris~N Oreshkin, Federico~Garza Ramirez,
  Max~Mergenthaler Canseco, and Artur Dubrawski.
\newblock N-hits: Neural hierarchical interpolation for time series
  forecasting.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~37, pages 6989--6997, 2023.

\bibitem{n-beats}
Boris~N Oreshkin, Dmitri Carpov, Nicolas Chapados, and Yoshua Bengio.
\newblock N-beats: Neural basis expansion analysis for interpretable time
  series forecasting.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{xu2021anomaly}
Jiehui Xu, Haixu Wu, Jianmin Wang, and Mingsheng Long.
\newblock Anomaly transformer: Time series anomaly detection with association
  discrepancy.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{ROCKET}
Angus Dempster, Fran\c{c}ois Petitjean, and Geoffrey~I Webb.
\newblock {ROCKET}: Exceptionally fast and accurate time series classification
  using random convolutional kernels.
\newblock {\em Data Mining and Knowledge Discovery}, 34(5):1454--1495, 2020.

\bibitem{lstnet}
Guokun Lai, Wei-Cheng Chang, Yiming Yang, and Hanxiao Liu.
\newblock Modeling long-and short-term temporal patterns with deep neural
  networks.
\newblock In {\em The 41st international ACM SIGIR conference on research \&
  development in information retrieval}, pages 95--104, 2018.

\bibitem{wu2022flowformer}
Haixu Wu, Jialong Wu, Jiehui Xu, Jianmin Wang, and Mingsheng Long.
\newblock Flowformer: Linearizing transformers with conservation flows.
\newblock In {\em International Conference on Machine Learning}, pages
  24226--24242. PMLR, 2022.

\bibitem{weatherdata}
{Wetterstation}.
\newblock {Weather}.
\newblock \url{https://www.bgc-jena.mpg.de/wetter/}.

\bibitem{trafficdata}
{PeMS}.
\newblock {Traffic}.
\newblock \url{http://pems.dot.ca.gov/}.

\bibitem{ecldata}
{UCI}.
\newblock {Electricity}.
\newblock
  \url{https://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams20112014}.

\bibitem{makridakis2018m4}
Spyros Makridakis, Evangelos Spiliotis, and Vassilios Assimakopoulos.
\newblock The m4 competition: Results, findings, conclusion and way forward.
\newblock {\em International Journal of Forecasting}, 34(4):802--808, 2018.

\bibitem{challu2022n}
Cristian Challu, Kin~G Olivares, Boris~N Oreshkin, Federico Garza, Max
  Mergenthaler, and Artur Dubrawski.
\newblock N-hits: Neural hierarchical interpolation for time series
  forecasting.
\newblock {\em arXiv preprint arXiv:2201.12886}, 2022.

\bibitem{Zhang2022LessIM}
T.~Zhang, Yizhuo Zhang, Wei Cao, J.~Bian, Xiaohan Yi, Shun Zheng, and Jian Li.
\newblock Less is more: Fast multivariate time series forecasting with light
  sampling-oriented mlp structures.
\newblock {\em arXiv preprint arXiv:2207.01186}, 2022.

\bibitem{UEA}
Anthony Bagnall, Hoang~Anh Dau, Jason Lines, Michael Flynn, James Large, Aaron
  Bostrom, Paul Southam, and Eamonn Keogh.
\newblock The uea multivariate time series classification archive, 2018.
\newblock {\em arXiv preprint arXiv:1811.00075}, 2018.

\bibitem{SMD}
Ya~Su, Youjian Zhao, Chenhao Niu, Rong Liu, Wei Sun, and Dan Pei.
\newblock Robust anomaly detection for multivariate time series through
  stochastic recurrent neural network.
\newblock In {\em Proceedings of the 25th ACM SIGKDD international conference
  on knowledge discovery \& data mining}, pages 2828--2837, 2019.

\bibitem{MSL_SMAP}
Kyle Hundman, Valentino Constantinou, Christopher Laporte, Ian Colwell, and Tom
  S{\"o}derstr{\"o}m.
\newblock Detecting spacecraft anomalies using lstms and nonparametric dynamic
  thresholding.
\newblock {\em Proceedings of the 24th ACM SIGKDD International Conference on
  Knowledge Discovery \& Data Mining}, pages 387--395, 2018.

\bibitem{SWaT}
Aditya~P Mathur and Nils~Ole Tippenhauer.
\newblock Swat: A water treatment testbed for research and training on ics
  security.
\newblock In {\em 2016 international workshop on cyber-physical systems for
  smart water networks (CySWater)}, pages 31--36. IEEE, 2016.

\bibitem{PSM}
Ahmed Abdulaal, Zhuanghua Liu, and Tomer Lancewicki.
\newblock Practical approach to asynchronous multivariate time series anomaly
  detection and localization.
\newblock In {\em Proceedings of the 27th ACM SIGKDD conference on knowledge
  discovery \& data mining}, pages 2485--2494, 2021.

\bibitem{2019Enhancing}
Shiyang Li, Xiaoyong Jin, Yao Xuan, Xiyou Zhou, Wenhu Chen, Yu-Xiang Wang, and
  Xifeng Yan.
\newblock Enhancing the locality and breaking the memory bottleneck of
  transformer on time series forecasting.
\newblock In {\em NeurIPS}, 2019.

\bibitem{NIPS2017_3f5ee243}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem{DBLP:journals/corr/KingmaB14}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock In {\em ICLR}, 2015.

\end{thebibliography}
