@inproceedings{arpit2016regularized,
  title={Why regularized auto-encoders learn sparse representation?},
  author={Arpit, Devansh and Zhou, Yingbo and Ngo, Hung and Govindaraju, Venu},
  booktitle={International Conference on Machine Learning},
  pages={136--144},
  year={2016},
  organization={PMLR}
}

@article{bills2023language,
  title={Language models can explain neurons in language models},
  author={Bills, Steven and Cammarata, Nick and Mossing, Dan and Tillman, Henk and Gao, Leo and Goh, Gabriel and Sutskever, Ilya and Leike, Jan and Wu, Jeff and Saunders, William},
  journal={URL https://openaipublic. blob. core. windows. net/neuron-explainer/paper/index. html.(Date accessed: 14.05. 2023)},
  year={2023}
}
@article{bricken2023towards,
  title={Towards monosemanticity: Decomposing language models with dictionary learning},
  author={Bricken, Trenton and Templeton, Adly and Batson, Joshua and Chen, Brian and Jermyn, Adam and Conerly, Tom and Turner, Nick and Anil, Cem and Denison, Carson and Askell, Amanda and others},
  journal={Transformer Circuits Thread},
  pages={2},
  year={2023}
}

@inproceedings{gregor2010learning,
  title={Learning fast approximations of sparse coding},
  author={Gregor, Karol and LeCun, Yann},
  booktitle={Proceedings of the 27th international conference on international conference on machine learning},
  pages={399--406},
  year={2010}
}

@article{mallat1993matching,
  title={Matching pursuits with time-frequency dictionaries},
  author={Mallat, St{\'e}phane G and Zhang, Zhifeng},
  journal={IEEE Transactions on signal processing},
  volume={41},
  number={12},
  pages={3397--3415},
  year={1993},
  publisher={IEEE}
}

@inproceedings{coates2011analysis,
  title={An analysis of single-layer networks in unsupervised feature learning},
  author={Coates, Adam and Ng, Andrew and Lee, Honglak},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={215--223},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}


@article{gao2024scaling,
  title={Scaling and evaluating sparse autoencoders},
  author={Gao, Leo and la Tour, Tom Dupr{\'e} and Tillman, Henk and Goh, Gabriel and Troll, Rajan and Radford, Alec and Sutskever, Ilya and Leike, Jan and Wu, Jeffrey},
  journal={arXiv preprint arXiv:2406.04093},
  year={2024}
}

@article{olshausen2004sparse,
  title={Sparse coding of sensory inputs},
  author={Olshausen, Bruno A and Field, David J},
  journal={Current opinion in neurobiology},
  volume={14},
  number={4},
  pages={481--487},
  year={2004},
  publisher={Elsevier}
}


@book{elad2010sparse,
  title={Sparse and redundant representations: from theory to applications in signal and image processing},
  author={Elad, Michael},
  year={2010},
  publisher={Springer Science \& Business Media}
}


@article{mardani2018neural,
  title={Neural proximal gradient descent for compressive imaging},
  author={Mardani, Morteza and Sun, Qingyun and Donoho, David and Papyan, Vardan and Monajemi, Hatef and Vasanawala, Shreyas and Pauly, John},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{aharon2006k,
  title={{K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation}},
  author={Aharon, Michal and Elad, Michael and Bruckstein, Alfred},
  journal={IEEE Transactions on signal processing},
  volume={54},
  number={11},
  pages={4311--4322},
  year={2006},
  publisher={IEEE}
}

@inproceedings{mairal2009online,
  title={Online dictionary learning for sparse coding},
  author={Mairal, Julien and Bach, Francis and Ponce, Jean and Sapiro, Guillermo},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={689--696},
  year={2009}
}

@article{rubinstein2010dictionaries,
  title={Dictionaries for sparse representation modeling},
  author={Rubinstein, Ron and Bruckstein, Alfred M and Elad, Michael},
  journal={Proceedings of the IEEE},
  volume={98},
  number={6},
  pages={1045--1057},
  year={2010},
  publisher={IEEE}
}

@inproceedings{cunningham2023sparse,
  title={Sparse Autoencoders Find Highly Interpretable Features in Language Models},
  author={Cunningham, Hoagy and Ewart, Aidan and Smith, Logan Riggs and Huben, Robert and Sharkey, Lee},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}


@inproceedings{geng2014local,
  title={On the local correctness of ℓ 1-minimization for dictionary learning},
  author={Geng, Quan and Wright, John},
  booktitle={2014 IEEE International Symposium on Information Theory},
  pages={3180--3184},
  year={2014},
  organization={IEEE}
}

@article{marks2024sparse,
  title={Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models},
  author={Marks, Samuel and Rager, Can and Michaud, Eric J and Belinkov, Yonatan and Bau, David and Mueller, Aaron},
  journal={arXiv preprint arXiv:2403.19647},
  year={2024}
}

@article{bao2015dictionary,
  title={Dictionary learning for sparse coding: Algorithms and convergence analysis},
  author={Bao, Chenglong and Ji, Hui and Quan, Yuhui and Shen, Zuowei},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={38},
  number={7},
  pages={1356--1369},
  year={2015},
  publisher={IEEE}
}

@article{ng2011sparse,
  title={Sparse autoencoder},
  author={Ng, Andrew and others},
  journal={CS294A Lecture notes},
  volume={72},
  number={2011},
  pages={1--19},
  year={2011}
}

@article{meng2017research,
  title={Research on denoising sparse autoencoder},
  author={Meng, Lingheng and Ding, Shifei and Xue, Yu},
  journal={International Journal of Machine Learning and Cybernetics},
  volume={8},
  pages={1719--1729},
  year={2017},
  publisher={Springer}
}



@article{lee2006efficient,
  title={Efficient sparse coding algorithms},
  author={Lee, Honglak and Battle, Alexis and Raina, Rajat and Ng, Andrew},
  journal={Advances in neural information processing systems},
  volume={19},
  year={2006}
}



@article{donoho1992superresolution,
  title={Superresolution via sparsity constraints},
  author={Donoho, David L},
  journal={SIAM journal on mathematical analysis},
  volume={23},
  number={5},
  pages={1309--1331},
  year={1992},
  publisher={SIAM}
}

@article{ranzato2006efficient,
  title={Efficient learning of sparse representations with an energy-based model},
  author={Ranzato, Marc'Aurelio and Poultney, Christopher and Chopra, Sumit and Cun, Yann},
  journal={Advances in neural information processing systems},
  volume={19},
  year={2006}
}


@book{dumitrescu2018dictionary,
  title={Dictionary learning algorithms and applications},
  author={Dumitrescu, Bogdan and Irofti, Paul},
  year={2018},
  publisher={Springer}
}


@inproceedings{eggert2004sparse,
  title={Sparse coding and NMF},
  author={Eggert, Julian and Korner, Edgar},
  booktitle={2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No. 04CH37541)},
  volume={4},
  pages={2529--2533},
  year={2004},
  organization={IEEE}
}


@inproceedings{hoyer2002non,
  title={Non-negative sparse coding},
  author={Hoyer, Patrik O},
  booktitle={Proceedings of the 12th IEEE workshop on neural networks for signal processing},
  pages={557--565},
  year={2002},
  organization={IEEE}
}



@article{rajamanoharan2024GatedSAE,
  title={Improving Dictionary Learning with Gated Sparse Autoencoders},
  author={Rajamanoharan, Senthooran and Conmy, Arthur and Smith, Lewis and Lieberum, Tom and Varma, Vikrant and Kram{\'a}r, J{\'a}nos and Shah, Rohin and Nanda, Neel},
  journal={arXiv preprint arXiv:2404.16014},
  year={2024}
}
@article{ferrando2024primer,
  title={A Primer on the Inner Workings of Transformer-based Language Models},
  author={Ferrando, Javier and Sarti, Gabriele and Bisazza, Arianna and Costa-juss{\`a}, Marta R},
  journal={arXiv preprint arXiv:2405.00208},
  year={2024}
}

@article{park2023linear,
  title={The linear representation hypothesis and the geometry of large language models},
  author={Park, Kiho and Choe, Yo Joong and Veitch, Victor},
  journal={arXiv preprint arXiv:2311.03658},
  year={2023}
}

@article{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}

@inproceedings{arora2015simple,
  title={Simple, efficient, and neural algorithms for sparse coding},
  author={Arora, Sanjeev and Ge, Rong and Ma, Tengyu and Moitra, Ankur},
  booktitle={Conference on learning theory},
  pages={113--149},
  year={2015},
  organization={PMLR}
}

@inproceedings{jung2014performance,
  title={Performance limits of dictionary learning for sparse coding},
  author={Jung, Alexander and Eldar, Yonina C and G{\"o}rtz, Norbert},
  booktitle={2014 22nd European Signal Processing Conference (EUSIPCO)},
  pages={765--769},
  year={2014},
  organization={IEEE}
}

@article{elad2002generalized,
  title={A generalized uncertainty principle and sparse representation in pairs of bases},
  author={Elad, Michael and Bruckstein, Alfred M},
  journal={IEEE Transactions on Information Theory},
  volume={48},
  number={9},
  pages={2558--2567},
  year={2002},
  publisher={IEEE}
}

@article{makelov2024towards,
  title={Towards Principled Evaluations of Sparse Autoencoders for Interpretability and Control},
  author={Makelov, Aleksandar and Lange, George and Nanda, Neel},
  journal={arXiv preprint arXiv:2405.08366},
  year={2024}
}

@inproceedings{yang2009linear,
  title={Linear spatial pyramid matching using sparse coding for image classification},
  author={Yang, Jianchao and Yu, Kai and Gong, Yihong and Huang, Thomas},
  booktitle={2009 IEEE Conference on computer vision and pattern recognition},
  pages={1794--1801},
  year={2009},
  organization={IEEE}
}

@inproceedings{kissane2024interpreting,
  title={Interpreting Attention Layer Outputs with Sparse Autoencoders},
  author={Kissane, Connor and Krzyzanowski, Robert and Bloom, Joseph Isaac and Conmy, Arthur and Nanda, Neel},
  booktitle={ICML 2024 Workshop on Mechanistic Interpretability},
  year={2024}
}

@article{makhzani2013k,
  title={K-sparse autoencoders},
  author={Makhzani, Alireza and Frey, Brendan},
  journal={arXiv preprint arXiv:1312.5663},
  year={2013}
}

@misc{mossing2024tdb,
  title={Transformer Debugger},
  author={Mossing, Dan and Bills, Steven and Tillman, Henk and Dupré la Tour, Tom and Cammarata, Nick and Gao, Leo and Achiam, Joshua and Yeh, Catherine and Leike, Jan and Wu, Jeff and Saunders, William},
  year={2024},
  publisher={GitHub},
  howpublished={\url{https://github.com/openai/transformer-debugger}},
}



@inproceedings{nguyen2019dynamics,
  title={On the dynamics of gradient descent for autoencoders},
  author={Nguyen, Thanh V and Wong, Raymond KW and Hegde, Chinmay},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={2858--2867},
  year={2019},
  organization={PMLR}
}

@book{christensen2003introduction,
  title={An introduction to frames and Riesz bases},
  author={Christensen, Ole and others},
  volume={7},
  year={2003},
  publisher={Springer}
}

@inproceedings{coates2011importance,
  title={The importance of encoding versus training with sparse coding and vector quantization},
  author={Coates, Adam and Ng, Andrew Y},
  booktitle={Proceedings of the 28th international conference on machine learning (ICML-11)},
  pages={921--928},
  year={2011}
}


@article{li2016sparseness,
  title={Sparseness analysis in the pretraining of deep neural networks},
  author={Li, Jun and Zhang, Tong and Luo, Wei and Yang, Jian and Yuan, Xiao-Tong and Zhang, Jian},
  journal={IEEE transactions on neural networks and learning systems},
  volume={28},
  number={6},
  pages={1425--1438},
  year={2016},
  publisher={IEEE}
}


@inproceedings{blasiok2016improved,
  title={An Improved Analysis of the ER-SpUD Dictionary Learning Algorithm},
  author={Blasiok, Jaroslaw and Nelson, Jelani},
  booktitle={43rd International Colloquium on Automata, Languages, and Programming (ICALP 2016)},
  year={2016},
  organization={Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik}
}


@article{tillmann2014computational,
  title={On the computational intractability of exact and approximate dictionary learning},
  author={Tillmann, Andreas M},
  journal={IEEE Signal Processing Letters},
  volume={22},
  number={1},
  pages={45--49},
  year={2014},
  publisher={IEEE}
}


@inproceedings{rangamani2018sparse,
  title={Sparse coding and autoencoders},
  author={Rangamani, Akshay and Mukherjee, Anirbit and Basu, Amitabh and Arora, Ashish and Ganapathi, Tejaswini and Chin, Sang and Tran, Trac D},
  booktitle={2018 IEEE International Symposium on Information Theory (ISIT)},
  pages={36--40},
  year={2018},
  organization={IEEE}
}

@article{McGrath2022Acquisition,
   title={Acquisition of chess knowledge in AlphaZero},
   volume={119},
   ISSN={1091-6490},
   url={http://dx.doi.org/10.1073/pnas.2206625119},
   DOI={10.1073/pnas.2206625119},
   number={47},
   journal={Proceedings of the National Academy of Sciences},
   publisher={Proceedings of the National Academy of Sciences},
   author={McGrath, Thomas and Kapishnikov, Andrei and Tomašev, Nenad and Pearce, Adam and Wattenberg, Martin and Hassabis, Demis and Kim, Been and Paquet, Ulrich and Kramnik, Vladimir},
   year={2022},
   month=nov }


@article{luo2017convolutional,
  title={Convolutional sparse autoencoders for image classification},
  author={Luo, Wei and Li, Jun and Yang, Jian and Xu, Wei and Zhang, Jian},
  journal={IEEE transactions on neural networks and learning systems},
  volume={29},
  number={7},
  pages={3289--3294},
  year={2017},
  publisher={IEEE}
}

@article{davis1997adaptive,
  title={Adaptive greedy approximations},
  author={Davis, Geoff and Mallat, Stephane and Avellaneda, Marco},
  journal={Constructive approximation},
  volume={13},
  pages={57--98},
  year={1997},
  publisher={Springer}
}

@article{natarajan1995sparse,
  title={Sparse approximate solutions to linear systems},
  author={Natarajan, Balas Kausik},
  journal={SIAM journal on computing},
  volume={24},
  number={2},
  pages={227--234},
  year={1995},
  publisher={SIAM}
}

@book{wright2022high,
  title={High-dimensional data analysis with low-dimensional models: Principles, computation, and applications},
  author={Wright, John and Ma, Yi},
  year={2022},
  publisher={Cambridge University Press}
}


@article{wen2015stable,
  title={Stable recovery of sparse signals via lp-minimization},
  author={Wen, Jinming and Li, Dongfang and Zhu, Fumin},
  journal={Applied and Computational Harmonic Analysis},
  volume={38},
  number={1},
  pages={161--176},
  year={2015},
  publisher={Elsevier}
}


@article{yang2018sparse,
  title={Sparse Recovery Conditions and Performance Bounds for $\ell_p$-Minimization},
  author={Yang, Chengzhu and Shen, Xinyue and Ma, Hongbing and Gu, Yuantao and So, Hing Cheung},
  journal={IEEE Transactions on Signal Processing},
  volume={66},
  number={19},
  pages={5014--5028},
  year={2018},
  publisher={IEEE}
}


@article{wang2011performance,
  title={On the Performance of Sparse Recovery Via $\ell_p$-Minimization $(0 \leq p \leq 1)$},
  author={Wang, Meng and Xu, Weiyu and Tang, Ao},
  journal={IEEE Transactions on Information Theory},
  volume={57},
  number={11},
  pages={7255--7278},
  year={2011},
  publisher={IEEE}
}


@article{chartrand2007exact,
  title={Exact reconstruction of sparse signals via nonconvex minimization},
  author={Chartrand, Rick},
  journal={IEEE Signal Processing Letters},
  volume={14},
  number={10},
  pages={707--710},
  year={2007},
  publisher={IEEE}
}


@article{zheng2017does,
  title={Does $\ell_p$-Minimization Outperform $\ell_1$-Minimization?},
  author={Zheng, Le and Maleki, Arian and Weng, Haolei and Wang, Xiaodong and Long, Teng},
  journal={IEEE Transactions on Information Theory},
  volume={63},
  number={11},
  pages={6896--6935},
  year={2017},
  publisher={IEEE}
}


@article{daubechies2004iterative,
  title={An iterative thresholding algorithm for linear inverse problems with a sparsity constraint},
  author={Daubechies, Ingrid and Defrise, Michel and De Mol, Christine},
  journal={Communications on Pure and Applied Mathematics: A Journal Issued by the Courant Institute of Mathematical Sciences},
  volume={57},
  number={11},
  pages={1413--1457},
  year={2004},
  publisher={Wiley Online Library}
}


@article{hinton1993autoencoders,
  title={Autoencoders, minimum description length and Helmholtz free energy},
  author={Hinton, Geoffrey E and Zemel, Richard},
  journal={Advances in neural information processing systems},
  volume={6},
  year={1993}
}

@article{marks2023interpreting,
  title={Interpreting reward models in rlhf-tuned language models using sparse autoencoders},
  author={Marks, Luke and Abdullah, Amir and Mendez, Luna and Arike, Rauno and Torr, Philip and Barez, Fazl},
  journal={arXiv preprint arXiv:2310.08164},
  year={2023}
}




@article{chalk2018toward,
  title={Toward a unified theory of efficient, predictive, and sparse coding},
  author={Chalk, Matthew and Marre, Olivier and Tka{\v{c}}ik, Ga{\v{s}}per},
  journal={Proceedings of the National Academy of Sciences},
  volume={115},
  number={1},
  pages={186--191},
  year={2018},
  publisher={National Acad Sciences}
}
@article{bolukbasi2021interpretability,
  title={An interpretability illusion for bert},
  author={Bolukbasi, Tolga and Pearce, Adam and Yuan, Ann and Coenen, Andy and Reif, Emily and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
  journal={arXiv preprint arXiv:2104.07143},
  year={2021}
}

@misc{anthropicSAE2024update,
  author = {Tom Conerly and Adly Templeton and Trenton Bricken and Jonathan Marcus and Tom Henighan},
  title = {Update on how we train SAEs},
  year = {2024},
  url = {https://transformer-circuits.pub/2024/april-update/index.html#training-saes},
  note = {Accessed: 2024-05-20}
}


@misc{anthropicPrivilegedBases,
  author = {Elhage, Nelson and Lasenby, Robert and Olah, Christopher},
  title = {Privileged Bases in the Transformer Residual Stream},
  year = {2023},
  url = {https://transformer-circuits.pub/2023/privileged-basis/index.html},
  note = {Accessed: 2024-05-20}
}

@misc{sharkey2023technical,
  title={Taking features out of superposition with sparse autoencoders},
  author={Sharkey, Lee and Braun, Dan and Millidge, Beren},
  year={2023},
  url={https://www.alignmentforum.org/posts/z6QQJbtpkEAX3Aojj/interim-research-report-taking-features-out-of-superposition},
note = {Accessed: 2023-05-10}
}

@article{elhage2022superposition,
  title={Toy models of superposition},
  author={Elhage, Nelson and Hume, Tristan and Olsson, Catherine and Schiefer, Nicholas and Henighan, Tom and Kravec, Shauna and Hatfield-Dodds, Zac and Lasenby, Robert and Drain, Dawn and Chen, Carol and others},
  journal={arXiv preprint arXiv:2209.10652},
  year={2022}
}

@article{elhage2022softmax,
  title={Softmax linear units},
  author={Elhage, Nelson and Hume, Tristan and Olsson, Catherine and Nanda, Neel and Henighan, Tom and Johnston, Scott and ElShowk, Sheer and Joseph, Nicholas and DasSarma, Nova and Mann, Ben and others},
  journal={Transformer Circuits Thread},
  year={2022}
}


@book{Foucart.2013,
 author = {Foucart, Simon and Rauhut, Holger},
 year = {2013},
 title = {{A Mathematical Introduction to Compressive Sensing}},
 address = {New York, NY},
 publisher = {{Springer New York}}
}

@article{yun2021transformer,
  title={Transformer visualization via dictionary learning: contextualized embedding as a linear superposition of transformer factors},
  author={Yun, Zeyu and Chen, Yubei and Olshausen, Bruno A and LeCun, Yann},
  journal={arXiv preprint arXiv:2103.15949},
  year={2021}
}

@article{li2023comprehensive,
  title={A comprehensive survey on design and application of autoencoder in deep learning},
  author={Li, Pengzhi and Pei, Yan and Li, Jianqiang},
  journal={Applied Soft Computing},
  volume={138},
  pages={110176},
  year={2023},
  publisher={Elsevier}
}


@article{olshausen1996emergence,
  title={Emergence of simple-cell receptive field properties by learning a sparse code for natural images},
  author={Olshausen, Bruno A and Field, David J},
  journal={Nature},
  volume={381},
  number={6583},
  pages={607--609},
  year={1996},
  publisher={Nature Publishing Group UK London}
}


@article{olshausen1997sparse,
  title={Sparse coding with an overcomplete basis set: A strategy employed by V1?},
  author={Olshausen, Bruno A and Field, David J},
  journal={Vision research},
  volume={37},
  number={23},
  pages={3311--3325},
  year={1997},
  publisher={Elsevier}
}

@article{bau2020units,
  author = {Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
  title = {Understanding the role of individual units in a deep neural network},
  elocation-id = {201907375},
  year = {2020},
  doi = {10.1073/pnas.1907375117},
  publisher = {National Academy of Sciences},
  issn = {0027-8424},
  URL = {https://www.pnas.org/content/early/2020/08/31/1907375117},
  journal = {Proceedings of the National Academy of Sciences}
}

@misc{wright2024suppression,
  author = {Benjamin Wright and Lee Sharkey},
  title = {Addressing Feature Suppression in Sparse Autoencoders},
  year = {2024},
  url = {https://www.lesswrong.com/posts/3JuSjTZyMzaSeTxKk/addressing-feature-suppression-in-saes},
  note = {Accessed: 2024-05-20}
}

@misc{riggs2024sqrt,
  author = {Logan Riggs and Jannik Brinkmann},
  title = {Improving Sparse Autoencoders by Square-Rooting L1 and Removing Lowest Activation Features},
  year = {2024},
  url = {https://www.lesswrong.com/posts/YiGs8qJ8aNBgwt2YN/improving-sae-s-by-sqrt-ing-l1-and-removing-lowest},
  note = {Accessed: 2024-05-20}
}

@misc{jermyn2024tanh,
  author = {Adam Jermyn and Adly Templeton and Joshua Batson and Trenton Bricken},
  title = {Tanh Penalty in Dictionary Learning},
  year = {2024},
  url = {https://transformer-circuits.pub/2024/feb-update/index.html},
  note = {Accessed: 2024-05-20}
}

@article{arora2018linear,
    title = "Linear Algebraic Structure of Word Senses, with Applications to Polysemy",
    author = "Arora, Sanjeev  and
      Li, Yuanzhi  and
      Liang, Yingyu  and
      Ma, Tengyu  and
      Risteski, Andrej",
    editor = "Lee, Lillian  and
      Johnson, Mark  and
      Toutanova, Kristina  and
      Roark, Brian",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "6",
    year = "2018",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q18-1034",
    doi = "10.1162/tacl_a_00034",
    pages = "483--495",
    abstract = "Word embeddings are ubiquitous in NLP and information retrieval, but it is unclear what they represent when the word is polysemous. Here it is shown that multiple word senses reside in linear superposition within the word embedding and simple sparse coding can recover vectors that approximately capture the senses. The success of our approach, which applies to several embedding methods, is mathematically explained using a variant of the random walk on discourses model (Arora et al., 2016). A novel aspect of our technique is that each extracted word sense is accompanied by one of about 2000 {``}discourse atoms{''} that gives a succinct description of which other words co-occur with that word sense. Discourse atoms can be of independent interest, and make the method potentially more useful. Empirical tests are used to verify and support the theory.",
}

@article{radford2019language,
  author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  number = 8,
  pages = 9,
  title = {Language models are unsupervised multitask learners},
  volume = 1,
  year = 2019
}

@inproceedings{
li2023emergent,
title={Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task},
author={Kenneth Li and Aspen K Hopkins and David Bau and Fernanda Vi{\'e}gas and Hanspeter Pfister and Martin Wattenberg},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
}

@inproceedings{nanda2023emergent,
    title = "Emergent Linear Representations in World Models of Self-Supervised Sequence Models",
    author = "Nanda, Neel  and
      Lee, Andrew  and
      Wattenberg, Martin",
    editor = "Belinkov, Yonatan  and
      Hao, Sophie  and
      Jumelet, Jaap  and
      Kim, Najoung  and
      McCarthy, Arya  and
      Mohebbi, Hosein",
    booktitle = "Proceedings of the 6th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.blackboxnlp-1.2",
    doi = "10.18653/v1/2023.blackboxnlp-1.2",
    pages = "16--30",
}

@misc{karvonen2024emergent,
      title={Emergent World Models and Latent Variable Estimation in Chess-Playing Language Models}, 
      author={Adam Karvonen},
      year={2024},
      eprint={2403.15498},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{amaldi1998nphard,
title = {On the approximability of minimizing nonzero variables or unsatisfied relations in linear systems},
journal = {Theoretical Computer Science},
volume = {209},
number = {1},
pages = {237-260},
year = {1998},
issn = {0304-3975},
doi = {https://doi.org/10.1016/S0304-3975(97)00115-1},
url = {https://www.sciencedirect.com/science/article/pii/S0304397597001151},
author = {Edoardo Amaldi and Viggo Kann},
keywords = {Linear systems, Unsatisfied relations, Nonzero variables, Approximability bounds, Designing linear classifiers},
}

@misc{lichess,
  author = {Lichess},
    year={2024},
  title = {lichess.org open database},
  url = {https://database.lichess.org},
}

@article{templeton2024scaling,
   title={Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet},
   author={Templeton, Adly and Conerly, Tom and Marcus, Jonathan and Lindsey, Jack and Bricken, Trenton and Chen, Brian and Pearce, Adam and Citro, Craig and Ameisen, Emmanuel and Jones, Andy and Cunningham, Hoagy and Turner, Nicholas L and McDougall, Callum and MacDiarmid, Monte and Freeman, C. Daniel and Sumers, Theodore R. and Rees, Edward and Batson, Joshua and Jermyn, Adam and Carter, Shan and Olah, Chris and Henighan, Tom},
   year={2024},
   journal={Transformer Circuits Thread},
   url={https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html}
}

@misc{dictionarylearning,
  author = {Marks, Samuel and Mueller, Aaron},
  title = {dictionary\_learning},
  year = {2024},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/saprmarks/dictionary_learning}},
}

@misc{SAELens,
    author = {Bloom, Joseph and Chanin, David},
    title = {SAE Lens},
    year = {2024},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/jbloomAus/SAELens}},
}

@misc{cooney2023SparseAutoencoder,
    title = {Sparse Autoencoder Library},
    author = {Alan Cooney},
    year = {2023},
    howpublished = {\url{https://github.com/ai-safety-foundation/sparse_autoencoder}},
}
