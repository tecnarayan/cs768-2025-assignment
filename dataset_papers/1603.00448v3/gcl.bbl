\begin{thebibliography}{31}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbeel \& Ng(2004)Abbeel and Ng]{an-alirl-04}
Abbeel, P. and Ng, A.
\newblock Apprenticeship learning via inverse reinforcement learning.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2004.

\bibitem[Aghasadeghi \& Bretl(2011)Aghasadeghi and Bretl]{ab-meirlpi-11}
Aghasadeghi, N. and Bretl, T.
\newblock Maximum entropy inverse reinforcement learning in continuous state
  spaces with path integrals.
\newblock In \emph{International Conference on Intelligent Robots and Systems
  (IROS)}, 2011.

\bibitem[Audiffren et~al.(2015)Audiffren, Valko, Lazaric, and
  Ghavamzadeh]{avlg-ssirl-15}
Audiffren, J., Valko, M., Lazaric, A., and Ghavamzadeh, M.
\newblock {Maximum Entropy Semi-Supervised Inverse Reinforcement Learning}.
\newblock In \emph{{International Joint Conference on Artificial Intelligence
  (IJCAI)}}, July 2015.

\bibitem[Bagnell \& Schneider(2003)Bagnell and Schneider]{bagnell2003covariant}
Bagnell, J.~A. and Schneider, J.
\newblock Covariant policy search.
\newblock In \emph{International Joint Conference on Artificial Intelligence
  (IJCAI)}, 2003.

\bibitem[Boularias et~al.(2011)Boularias, Kober, and Peters]{bkp-reirl-11}
Boularias, A., Kober, J., and Peters, J.
\newblock Relative entropy inverse reinforcement learning.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics (AISTATS)}, 2011.

\bibitem[Byravan et~al.(2015)Byravan, Monfort, Ziebart, Boots, and
  Fox]{bmzbf-gbioc-15}
Byravan, A., Monfort, M., Ziebart, B., Boots, B., and Fox, D.
\newblock Graph-based inverse optimal control for robot manipulation.
\newblock In \emph{International Joint Conference on Artificial Intelligence
  (IJCAI)}, 2015.

\bibitem[Doerr et~al.(2015)Doerr, Ratliff, Bohg, Toussaint, and
  Schaal]{drbts-dlmioc-15}
Doerr, A., Ratliff, N., Bohg, J., Toussaint, M., and Schaal, S.
\newblock Direct loss minimization inverse optimal control.
\newblock In \emph{Proceedings of Robotics: Science and Systems (R:SS)}, Rome,
  Italy, July 2015.

\bibitem[Dragan \& Srinivasa(2012)Dragan and Srinivasa]{ds-fat-12}
Dragan, Anca and Srinivasa, Siddhartha.
\newblock Formalizing assistive teleoperation.
\newblock In \emph{Proceedings of Robotics: Science and Systems (R:SS)},
  Sydney, Australia, July 2012.

\bibitem[Finn et~al.(2016)Finn, Tan, Duan, Darrell, Levine, and
  Abbeel]{ftddla-dsae-15}
Finn, Chelsea, Tan, Xin~Yu, Duan, Yan, Darrell, Trevor, Levine, Sergey, and
  Abbeel, Pieter.
\newblock Deep spatial autoencoders for visuomotor learning.
\newblock \emph{International Conference on Robotics and Automation (ICRA)},
  2016.

\bibitem[Huang \& Kitani(2014)Huang and Kitani]{hk-arfdh-14}
Huang, D. and Kitani, K.
\newblock Action-reaction: Forecasting the dynamics of human interaction.
\newblock In \emph{European Conference on Computer Vision (ECCV)}, 2014.

\bibitem[Kalakrishnan et~al.(2013)Kalakrishnan, Pastor, Righetti, and
  Schaal]{kprs-lofm-13}
Kalakrishnan, M., Pastor, P., Righetti, L., and Schaal, S.
\newblock Learning objective functions for manipulation.
\newblock In \emph{International Conference on Robotics and Automation (ICRA)},
  2013.

\bibitem[Levine \& Abbeel(2014)Levine and Abbeel]{la-lnnpg-14}
Levine, S. and Abbeel, P.
\newblock Learning neural network policies with guided policy search under
  unknown dynamics.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2014.

\bibitem[Levine \& Koltun(2012)Levine and Koltun]{lk-cioc-12}
Levine, S. and Koltun, V.
\newblock Continuous inverse optimal control with locally optimal examples.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2012.

\bibitem[Levine et~al.(2011)Levine, Popovic, and Koltun]{lpk-gpirl-11}
Levine, S., Popovic, Z., and Koltun, V.
\newblock Nonlinear inverse reinforcement learning with gaussian processes.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2011.

\bibitem[Levine et~al.(2015)Levine, Wagener, and Abbeel]{lwa-lnnpg-15}
Levine, S., Wagener, N., and Abbeel, P.
\newblock Learning contact-rich manipulation skills with guided policy search.
\newblock In \emph{International Conference on Robotics and Automation (ICRA)},
  2015.

\bibitem[Monfort et~al.(2015)Monfort, Lake, Ziebart, Lucey, and
  Tenenbaum]{mlzlt-shgpi-15}
Monfort, M., Lake, B.~M., Ziebart, B., Lucey, P., and Tenenbaum, J.
\newblock Softstar: Heuristic-guided probabilistic inference.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2746--2754, 2015.

\bibitem[Muelling et~al.(2014)Muelling, Boularias, Mohler, Sch{\"o}lkopf, and
  Peters]{mbmsp-ttirl-14}
Muelling, K., Boularias, A., Mohler, B., Sch{\"o}lkopf, B., and Peters, J.
\newblock Learning strategies in table tennis using inverse reinforcement
  learning.
\newblock \emph{Biological Cybernetics}, 108\penalty0 (5), 2014.

\bibitem[Ng et~al.(1999)Ng, Harada, and Russell]{nhr-tars-99}
Ng, A., Harada, D., and Russell, S.
\newblock Policy invariance under reward transformations: Theory and
  application to reward shaping.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 1999.

\bibitem[Ng et~al.(2000)Ng, Russell, et~al.]{nr-airl-00}
Ng, A., Russell, S., et~al.
\newblock Algorithms for inverse reinforcement learning.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2000.

\bibitem[Peters et~al.(2010)Peters, M{\"u}lling, and Alt{\"u}n]{pma-reps-10}
Peters, J., M{\"u}lling, K., and Alt{\"u}n, Y.
\newblock Relative entropy policy search.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2010.

\bibitem[Ramachandran \& Amir(2007)Ramachandran and Amir]{ra-birl-07}
Ramachandran, D. and Amir, E.
\newblock Bayesian inverse reinforcement learning.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, volume~51,
  2007.

\bibitem[Ratliff et~al.(2006)Ratliff, Bagnell, and Zinkevich]{rbz-mmp-06}
Ratliff, N., Bagnell, J.~A., and Zinkevich, M.~A.
\newblock Maximum margin planning.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2006.

\bibitem[Ratliff et~al.(2007)Ratliff, Bradley, Bagnell, and
  Chestnutt]{rbbc-bsp-07}
Ratliff, N., Bradley, D., Bagnell, J.~A., and Chestnutt, J.
\newblock Boosting structured prediction for imitation learning.
\newblock 2007.

\bibitem[Ratliff et~al.(2009)Ratliff, Silver, and Bagnell]{rsb-learch-09}
Ratliff, N., Silver, D., and Bagnell, J.~A.
\newblock Learning to search: Functional gradient techniques for imitation
  learning.
\newblock \emph{Autonomous Robots}, 27\penalty0 (1), 2009.

\bibitem[Rawlik \& Vijayakumar(2013)Rawlik and
  Vijayakumar]{rawlik2013stochastic}
Rawlik, K. and Vijayakumar, S.
\newblock On stochastic optimal control and reinforcement learning by
  approximate inference.
\newblock \emph{Robotics}, 2013.

\bibitem[Todorov(2006)]{t-lsmdp-06}
Todorov, E.
\newblock Linearly-solvable markov decision problems.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2006.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{tet-mjc-12}
Todorov, E., Erez, T., and Tassa, Y.
\newblock {MuJoCo}: A physics engine for model-based control.
\newblock In \emph{International Conference on Intelligent Robots and Systems
  (IROS)}, 2012.

\bibitem[Tzeng et~al.(2015)Tzeng, Hoffman, Darrell, and Saenko]{thds-dtad-15}
Tzeng, E., Hoffman, J., Darrell, T., and Saenko, K.
\newblock Simultaneous deep transfer across domains and tasks.
\newblock In \emph{International Conference on Computer Vision (ICCV)}, 2015.

\bibitem[Wulfmeier et~al.(2015)Wulfmeier, Ondruska, and Posner]{wop-dirl-15}
Wulfmeier, M., Ondruska, P., and Posner, I.
\newblock Maximum entropy deep inverse reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1507.04888}, 2015.

\bibitem[Ziebart(2010)]{z-mpabp-10}
Ziebart, B.
\newblock \emph{Modeling purposeful adaptive behavior with the principle of
  maximum causal entropy}.
\newblock PhD thesis, Carnegie Mellon University, 2010.

\bibitem[Ziebart et~al.(2008)Ziebart, Maas, Bagnell, and Dey]{zmbd-meirl-08}
Ziebart, B., Maas, A., Bagnell, J.~A., and Dey, A.~K.
\newblock Maximum entropy inverse reinforcement learning.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2008.

\end{thebibliography}
