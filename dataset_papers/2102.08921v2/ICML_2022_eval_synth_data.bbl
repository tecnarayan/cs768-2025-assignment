\begin{thebibliography}{39}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Adlam et~al.(2019)Adlam, Weill, and Kapoor]{adlam2019investigating}
Adlam, B., Weill, C., and Kapoor, A.
\newblock Investigating under and overfitting in wasserstein generative
  adversarial networks.
\newblock \emph{arXiv preprint arXiv:1910.14137}, 2019.

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and
  Bottou]{arjovsky2017wasserstein}
Arjovsky, M., Chintala, S., and Bottou, L.
\newblock Wasserstein gan.
\newblock \emph{arXiv preprint arXiv:1701.07875}, 2017.

\bibitem[Baqui et~al.(2020)Baqui, Bica, Marra, Ercole, and van
  Der~Schaar]{baqui2020ethnic}
Baqui, P., Bica, I., Marra, V., Ercole, A., and van Der~Schaar, M.
\newblock Ethnic and regional variations in hospital mortality from covid-19 in
  brazil: a cross-sectional observational study.
\newblock \emph{The Lancet Global Health}, 8\penalty0 (8):\penalty0
  e1018--e1026, 2020.

\bibitem[Bengio et~al.(2013)Bengio, Mesnil, Dauphin, and
  Rifai]{bengio2013better}
Bengio, Y., Mesnil, G., Dauphin, Y., and Rifai, S.
\newblock Better mixing via deep representations.
\newblock In \emph{International conference on machine learning}, pp.\
  552--560. PMLR, 2013.

\bibitem[Brock et~al.(2018)Brock, Donahue, and Simonyan]{brock2018large}
Brock, A., Donahue, J., and Simonyan, K.
\newblock Large scale gan training for high fidelity natural image synthesis.
\newblock \emph{arXiv preprint arXiv:1809.11096}, 2018.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern
  recognition}, pp.\  248--255. Ieee, 2009.

\bibitem[Flach \& Kull(2015)Flach and Kull]{flach2015precision}
Flach, P. and Kull, M.
\newblock Precision-recall-gain curves: Pr analysis done right.
\newblock \emph{Advances in neural information processing systems},
  28:\penalty0 838--846, 2015.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
  S., Courville, A., and Bengio, Y.
\newblock Generative adversarial nets.
\newblock \emph{Advances in neural information processing systems},
  27:\penalty0 2672--2680, 2014.

\bibitem[Gretton et~al.(2012)Gretton, Sejdinovic, Strathmann, Balakrishnan,
  Pontil, Fukumizu, and Sriperumbudur]{gretton2012optimal}
Gretton, A., Sejdinovic, D., Strathmann, H., Balakrishnan, S., Pontil, M.,
  Fukumizu, K., and Sriperumbudur, B.~K.
\newblock Optimal kernel choice for large-scale two-sample tests.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1205--1213. Citeseer, 2012.

\bibitem[Gulrajani et~al.(2017)Gulrajani, Ahmed, Arjovsky, Dumoulin, and
  Courville]{gulrajani2017improved}
Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., and Courville, A.
\newblock Improved training of wasserstein gans.
\newblock In \emph{Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, pp.\  5769--5779, 2017.

\bibitem[Gutmann \& Hyv{\"a}rinen(2010)Gutmann and
  Hyv{\"a}rinen]{gutmann2010noise}
Gutmann, M. and Hyv{\"a}rinen, A.
\newblock Noise-contrastive estimation: A new estimation principle for
  unnormalized statistical models.
\newblock In \emph{Proceedings of the Thirteenth International Conference on
  Artificial Intelligence and Statistics}, pp.\  297--304. JMLR Workshop and
  Conference Proceedings, 2010.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, Klambauer,
  and Hochreiter]{heusel2017gans}
Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., Klambauer, G., and
  Hochreiter, S.
\newblock Gans trained by a two time-scale update rule converge to a nash
  equilibrium.
\newblock 2017.

\bibitem[Hinton(2002)]{hinton2002training}
Hinton, G.~E.
\newblock Training products of experts by minimizing contrastive divergence.
\newblock \emph{Neural computation}, 14\penalty0 (8):\penalty0 1771--1800,
  2002.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Ho, J., Jain, A., and Abbeel, P.
\newblock Denoising diffusion probabilistic models.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Hyv{\"a}rinen et~al.(2009)Hyv{\"a}rinen, Hurri, and
  Hoyer]{hyvarinen2009estimation}
Hyv{\"a}rinen, A., Hurri, J., and Hoyer, P.~O.
\newblock Estimation of non-normalized statistical models.
\newblock In \emph{Natural Image Statistics}, pp.\  419--426. Springer, 2009.

\bibitem[Jordon et~al.(2020)Jordon, Jarrett, Yoon, Barnes, Elbers, Thoral,
  Ercole, Zhang, Belgrave, and van~der Schaar]{jordon2020hide}
Jordon, J., Jarrett, D., Yoon, J., Barnes, T., Elbers, P., Thoral, P., Ercole,
  A., Zhang, C., Belgrave, D., and van~der Schaar, M.
\newblock Hide-and-seek privacy challenge.
\newblock \emph{arXiv preprint arXiv:2007.12087}, 2020.

\bibitem[Karras et~al.(2020)Karras, Aittala, Hellsten, Laine, Lehtinen, and
  Aila]{karras2020training}
Karras, T., Aittala, M., Hellsten, J., Laine, S., Lehtinen, J., and Aila, T.
\newblock Training generative adversarial networks with limited data.
\newblock \emph{arXiv preprint arXiv:2006.06676}, 2020.

\bibitem[Kingma \& Welling(2013)Kingma and Welling]{kingma2013auto}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Kynk{\"a}{\"a}nniemi et~al.(2019)Kynk{\"a}{\"a}nniemi, Karras, Laine,
  Lehtinen, and Aila]{kynkaanniemi2019improved}
Kynk{\"a}{\"a}nniemi, T., Karras, T., Laine, S., Lehtinen, J., and Aila, T.
\newblock Improved precision and recall metric for assessing generative models.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[LeCun(1998)]{lecun1998mnist}
LeCun, Y.
\newblock The mnist database of handwritten digits.
\newblock \emph{http://yann. lecun. com/exdb/mnist/}, 1998.

\bibitem[Lucic et~al.(2018)Lucic, Kurach, Michalski, Gelly, and
  Bousquet]{lucic2018gans}
Lucic, M., Kurach, K., Michalski, M., Gelly, S., and Bousquet, O.
\newblock Are gans created equal? a large-scale study.
\newblock \emph{Advances in neural information processing systems},
  31:\penalty0 700--709, 2018.

\bibitem[Meehan et~al.(2020)Meehan, Chaudhuri, and Dasgupta]{meehan2020non}
Meehan, C., Chaudhuri, K., and Dasgupta, S.
\newblock A non-parametric test to detect data-copying in generative models.
\newblock \emph{arXiv preprint arXiv:2004.05675}, 2020.

\bibitem[Naeem et~al.(2020)Naeem, Oh, Uh, Choi, and Yoo]{naeem2020reliable}
Naeem, M.~F., Oh, S.~J., Uh, Y., Choi, Y., and Yoo, J.
\newblock Reliable fidelity and diversity metrics for generative models.
\newblock \emph{International Conference on Machine Learning (ICML)}, 2020.

\bibitem[Paszke et~al.(2017)Paszke, Gross, Chintala, Chanan, Yang, DeVito, Lin,
  Desmaison, Antiga, and Lerer]{pytorch}
Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z.,
  Desmaison, A., Antiga, L., and Lerer, A.
\newblock Automatic differentiation in pytorch.
\newblock In \emph{NIPS-W}, 2017.

\bibitem[Polonik(1997)]{polonik1997minimum}
Polonik, W.
\newblock Minimum volume sets and generalized quantile processes.
\newblock \emph{Stochastic processes and their applications}, 69\penalty0
  (1):\penalty0 1--24, 1997.

\bibitem[Ruff et~al.(2018)Ruff, Vandermeulen, Goernitz, Deecke, Siddiqui,
  Binder, M{\"u}ller, and Kloft]{ruff2018deep}
Ruff, L., Vandermeulen, R., Goernitz, N., Deecke, L., Siddiqui, S.~A., Binder,
  A., M{\"u}ller, E., and Kloft, M.
\newblock Deep one-class classification.
\newblock In \emph{International conference on machine learning}, pp.\
  4393--4402. PMLR, 2018.

\bibitem[Sajjadi et~al.(2018)Sajjadi, Bachem, Lucic, Bousquet, and
  Gelly]{sajjadi2018assessing}
Sajjadi, M.~S., Bachem, O., Lucic, M., Bousquet, O., and Gelly, S.
\newblock Assessing generative models via precision and recall.
\newblock \emph{Advances in Neural Information Processing Systems},
  31:\penalty0 5228--5237, 2018.

\bibitem[Salimans et~al.(2016)Salimans, Goodfellow, Zaremba, Cheung, Radford,
  and Chen]{salimans2016improved}
Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., and Chen,
  X.
\newblock Improved techniques for training gans.
\newblock \emph{arXiv preprint arXiv:1606.03498}, 2016.

\bibitem[Sch{\"o}lkopf et~al.(2001)Sch{\"o}lkopf, Platt, Shawe-Taylor, Smola,
  and Williamson]{scholkopf2001estimating}
Sch{\"o}lkopf, B., Platt, J.~C., Shawe-Taylor, J., Smola, A.~J., and
  Williamson, R.~C.
\newblock Estimating the support of a high-dimensional distribution.
\newblock \emph{Neural computation}, 13\penalty0 (7):\penalty0 1443--1471,
  2001.

\bibitem[Scott \& Nowak(2006)Scott and Nowak]{scott2006learning}
Scott, C.~D. and Nowak, R.~D.
\newblock Learning minimum volume sets.
\newblock \emph{The Journal of Machine Learning Research}, 7:\penalty0
  665--704, 2006.

\bibitem[SIVEP-Gripe(2020)]{SIVEP}
SIVEP-Gripe.
\newblock http://plataforma.saude.gov.br/coronavirus/dados-abertos/.
\newblock In \emph{Ministry of Health. SIVEP-Gripe public dataset, (accessed
  May 10, 2020; in Portuguese)}, 2020.

\bibitem[Sohl-Dickstein et~al.(2011)Sohl-Dickstein, Battaglino, and
  DeWeese]{sohl2011new}
Sohl-Dickstein, J., Battaglino, P.~B., and DeWeese, M.~R.
\newblock New method for parameter estimation in probabilistic models: minimum
  probability flow.
\newblock \emph{Physical review letters}, 107\penalty0 (22):\penalty0 220601,
  2011.

\bibitem[Srivastava et~al.(2015)Srivastava, Mansimov, and
  Salakhudinov]{srivastava2015unsupervised}
Srivastava, N., Mansimov, E., and Salakhudinov, R.
\newblock Unsupervised learning of video representations using lstms.
\newblock In \emph{International conference on machine learning}, pp.\
  843--852. PMLR, 2015.

\bibitem[Sutherland et~al.(2016)Sutherland, Tung, Strathmann, De, Ramdas,
  Smola, and Gretton]{sutherland2016generative}
Sutherland, D.~J., Tung, H.-Y., Strathmann, H., De, S., Ramdas, A., Smola, A.,
  and Gretton, A.
\newblock Generative models and model criticism via optimized maximum mean
  discrepancy.
\newblock \emph{arXiv preprint arXiv:1611.04488}, 2016.

\bibitem[Theis et~al.(2015)Theis, Oord, and Bethge]{theis2015note}
Theis, L., Oord, A. v.~d., and Bethge, M.
\newblock A note on the evaluation of generative models.
\newblock \emph{arXiv preprint arXiv:1511.01844}, 2015.

\bibitem[Van~Trees(2004)]{van2004detection}
Van~Trees, H.~L.
\newblock \emph{Detection, estimation, and modulation theory, part I:
  detection, estimation, and linear modulation theory}.
\newblock John Wiley \& Sons, 2004.

\bibitem[Wang et~al.(2018)Wang, Liu, Zhu, Tao, Kautz, and
  Catanzaro]{wang2018high}
Wang, T.-C., Liu, M.-Y., Zhu, J.-Y., Tao, A., Kautz, J., and Catanzaro, B.
\newblock High-resolution image synthesis and semantic manipulation with
  conditional gans.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  8798--8807, 2018.

\bibitem[Xie et~al.(2018)Xie, Lin, Wang, Wang, and Zhou]{xie2018differentially}
Xie, L., Lin, K., Wang, S., Wang, F., and Zhou, J.
\newblock Differentially private generative adversarial network.
\newblock \emph{arXiv preprint arXiv:1802.06739}, 2018.

\bibitem[Yoon et~al.(2020)Yoon, Drumright, and Van
  Der~Schaar]{yoon2020anonymization}
Yoon, J., Drumright, L.~N., and Van Der~Schaar, M.
\newblock Anonymization through data synthesis using generative adversarial
  networks (ads-gan).
\newblock \emph{IEEE Journal of Biomedical and Health Informatics}, 2020.

\end{thebibliography}
