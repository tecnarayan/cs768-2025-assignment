\begin{thebibliography}{10}

\bibitem{Aliprantis2006}
Charalambos~D. Aliprantis and Kim~C. Border.
\newblock {\em Infinite Dimensional Analysis: a Hitchhiker's Guide}.
\newblock Springer, Berlin; London, 2006.

\bibitem{Ambrosio2008}
Luigi Ambrosio, Nicola Gigli, and Giuseppe Savar{\'{e}}.
\newblock {\em Gradient flows: In Metric Spaces and in the Space of Probability
  Measures}.
\newblock Springer, 2008.

\bibitem{Aolaritei2022}
Liviu Aolaritei, Nicolas Lanzetti, Hongruyu Chen, and Florian Dörfler.
\newblock Uncertainty propagation via optimal transport ambiguity sets.
\newblock {\em arXiv preprint arXiv:2205.00343}, 2022.

\bibitem{blanchet-murthy2019}
Jose Blanchet and Karthyek Murthy.
\newblock Quantifying distributional model risk via optimal transport.
\newblock {\em Mathematics of Operations Research}, 44(2):565--600, 2019.

\bibitem{Brockman2016}
Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman,
  Jie Tang, and Wojciech Zaremba.
\newblock {OpenAI Gym}.
\newblock {\em arXiv preprint arXiv:1606.01540}, 2016.

\bibitem{Cuturi2013}
Marco Cuturi.
\newblock Sinkhorn distances: Lightspeed computation of optimal transport.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~26. Curran Associates, Inc., 2013.

\bibitem{Gao2017}
Rui Gao, Xi~Chen, and Anton~J. Kleywegt.
\newblock Wasserstein distributionally robust optimization and variation
  regularization.
\newblock {\em arXiv preprint arXiv:1712.06050}, 2017.

\bibitem{Gao2016}
Rui Gao and Anton~J. Kleywegt.
\newblock Distributionally robust stochastic optimization with {W}asserstein
  distance.
\newblock {\em arXiv preprint arXiv:1604.02199}, 2016.

\bibitem{Hill2018}
Ashley Hill, Antonin Raffin, Maximilian Ernestus, Adam Gleave, Anssi
  Kanervisto, Rene Traore, Prafulla Dhariwal, Christopher Hesse, Oleg Klimov,
  Alex Nichol, Matthias Plappert, Alec Radford, John Schulman, Szymon Sidor,
  and Yuhuai Wu.
\newblock Stable baselines.
\newblock \url{https://github.com/hill-a/stable-baselines}, 2018.

\bibitem{Kaiser2020atari}
{\L}ukasz Kaiser, Mohammad Babaeizadeh, Piotr Mi{\l}os, B{\l}a{\.z}ej
  Osi{\'n}ski, Roy~H Campbell, Konrad Czechowski, Dumitru Erhan, Chelsea Finn,
  Piotr Kozakowski, Sergey Levine, et~al.
\newblock Model based reinforcement learning for {A}tari.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{Kakade2002b}
Sham Kakade and John Langford.
\newblock Approximately optimal approximate reinforcement learning.
\newblock In {\em International Conference on Machine Learning}, pages
  267--274. PMLR, 2002.

\bibitem{Klenke2008}
Achim Klenke.
\newblock {\em Probability Theory: A Comprehensive Course}.
\newblock Springer, 2008.

\bibitem{kuhn-et-al2019survey}
Daniel Kuhn, Peyman~Mohajerin Esfahani, Viet~Anh Nguyen, and Soroosh
  Shafieezadeh-Abadeh.
\newblock Wasserstein distributionally robust optimization: Theory and
  applications in machine learning.
\newblock In {\em Operations research \& management science in the age of
  analytics}, pages 130--166. Informs, 2019.

\bibitem{lanzetti2022first}
Nicolas Lanzetti, Saverio Bolognani, and Florian D{\"o}rfler.
\newblock First-order conditions for optimization in the {W}asserstein space.
\newblock {\em arXiv preprint arXiv:2209.12197}, 2022.

\bibitem{Leuenberger1997}
David~G. Luenberger.
\newblock {\em {Optimization by vector space methods}}.
\newblock John Wiley \& Sons, 1997.

\bibitem{mao2016resourcemanagement}
Hongzi Mao, Mohammad Alizadeh, Ishai Menache, and Srikanth Kandula.
\newblock Resource management with deep reinforcement learning.
\newblock In {\em 15th ACM workshop on hot topics in networks}, pages 50--56,
  2016.

\bibitem{Mnih2016}
Volodymyr Mnih, Adria~Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy
  Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu.
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In {\em International Conference on Machine Learning}, pages
  1928--1937. PMLR, 2016.

\bibitem{mnih2013atari}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis
  Antonoglou, Daan Wierstra, and Martin Riedmiller.
\newblock Playing atari with deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1312.5602}, 2013.

\bibitem{Mohajerin2018}
Peyman Mohajerin~Esfahani and Daniel Kuhn.
\newblock Data-driven distributionally robust optimization using the
  {W}asserstein metric: performance guarantees and tractable reformulations.
\newblock {\em Mathematical Programming}, 171(1):115--166, 2018.

\bibitem{Moskovitz2020}
Ted Moskovitz, Michael Arbel, Ferenc Huszar, and Arthur Gretton.
\newblock Efficient {W}asserstein natural gradients for reinforcement learning.
\newblock {\em arXiv preprint arXiv:2010.05380}, 2020.

\bibitem{Munkres2000}
James~R. Munkres.
\newblock {\em Topology}.
\newblock Featured Titles for Topology. Prentice Hall, Incorporated, 2000.

\bibitem{Pacchiano2020}
Aldo Pacchiano, Jack Parker-Holder, Yunhao Tang, Anna Choromanska, Krzysztof
  Choromanski, and Michael~I. Jordan.
\newblock Learning to score behaviors for guided policy optimization.
\newblock In {\em International Conference on Machine Learning}, pages
  7401--7410. PMLR, 2020.

\bibitem{Peyre2019}
Gabriel Peyr{\'{e}} and Marco Cuturi.
\newblock Computational optimal transport.
\newblock {\em Foundations and Trends in Machine Learning}, 11(5-6):1--257,
  2019.

\bibitem{puterman2005}
Martin~L Puterman.
\newblock {\em Markov decision processes: discrete stochastic dynamic
  programming}.
\newblock John Wiley \& Sons, 2005.

\bibitem{rahimian2019distributionally}
Hamed Rahimian and Sanjay Mehrotra.
\newblock Distributionally robust optimization: A review.
\newblock {\em arXiv preprint arXiv:1908.05659}, 2019.

\bibitem{Richemond2017}
Pierre~H. Richemond and Brendan Maginnis.
\newblock On {W}asserstein reinforcement learning and the {F}okker-{P}lanck
  equation.
\newblock {\em arXiv preprint arXiv:1712.07185}, 2017.

\bibitem{Rockafellar2015}
Ralph~Tyrell Rockafellar.
\newblock {\em Convex Analysis}.
\newblock Princeton University Press, 2015.

\bibitem{Rudin1987}
Walter Rudin.
\newblock {\em Real and Complex Analysis, 3rd Ed.}
\newblock McGraw-Hill, Inc., USA, 1987.

\bibitem{Schulman2015}
John Schulman, Sergey Levine, Philipp Moritz, Michael~I. Jordan, and Pieter
  Abbeel.
\newblock Trust region policy optimization.
\newblock In {\em International Conference on Machine Learning}, pages
  1889--1897. PMLR, 2015.

\bibitem{Schulman2016}
John Schulman, Philipp Moritz, Sergey Levine, Michael~I. Jordan, and Pieter
  Abbeel.
\newblock High-dimensional continuous control using generalized advantage
  estimation.
\newblock In {\em International Conference on Learning Representations}, 2016.

\bibitem{Schulman2017}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock {\em arXiv preprint arXiv:1707.06347}, 2017.

\bibitem{silver2016go}
D.~Silver, A.~Huang, and C.~et~al. Maddison.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock {\em Nature 529, 484–489}, 2016.

\bibitem{Song2022}
Jun Song, Chaoyue Zhao, and Niao He.
\newblock Efficient {W}asserstein and {S}inkhorn policy optimization, 2022.

\bibitem{taskesen2021semi}
Bahar Taskesen, Soroosh Shafieezadeh-Abadeh, and Daniel Kuhn.
\newblock Semi-discrete optimal transport: Hardness, regularization and
  numerical solution.
\newblock {\em arXiv preprint arXiv:2103.06263}, 2021.

\bibitem{Terjek2021}
D{\'a}vid Terj{\'e}k and Diego Gonz{\'a}lez-S{\'a}nchez.
\newblock Optimal transport with $f$-divergence regularization and generalized
  {S}inkhorn algorithm.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 5135--5165. PMLR, 2022.

\bibitem{Todorov2012}
Emanuel Todorov, Tom Erez, and Yuval Tassa.
\newblock Mujoco: A physics engine for model-based control.
\newblock In {\em IEEE/RSJ International Conference on Intelligent Robots and
  Systems}, pages 5026--5033. IEEE, 2012.

\bibitem{Villani2008}
Cédric Villani.
\newblock {\em Optimal Transport: Old and New}.
\newblock Springer-Verlag Berlin Heidelberg, 2008.

\bibitem{ward2019improving}
Patrick~Nadeem Ward, Ariella Smofsky, and Avishek~Joey Bose.
\newblock Improving exploration in soft-actor-critic with normalizing flows
  policies.
\newblock {\em arXiv preprint arXiv:1906.02771}, 2019.

\bibitem{xenou2019boardgames}
Konstantia Xenou, Georgios Chalkiadakis, and Stergos Afantenos.
\newblock Deep reinforcement learning in strategic board game environments.
\newblock {\em Springer International Publishing}, 2019.

\bibitem{zhang-et-al2018}
Ruiyi Zhang, Changyou Chen, Chunyuan Li, and Lawrence Carin.
\newblock Policy optimization as wasserstein gradient flows.
\newblock In {\em International Conference on Machine Learning}, pages
  5737--5746. PMLR, 2018.

\bibitem{zhao-guan2018}
Chaoyue Zhao and Yongpei Guan.
\newblock Data-driven risk-averse stochastic optimization with {W}asserstein
  metric.
\newblock {\em Operations Research Letters}, 46(2):262--267, 2018.

\bibitem{Guanjie2018recommendation}
Guanjie Zheng, Fuzheng Zhang, Zihan Zheng, Yang Xiang, Nicholas~Jing Yuan, Xing
  Xie, and Zhenhui Li.
\newblock {DRN}: A deep reinforcement learning framework for news
  recommendation.
\newblock In {\em World Wide Web Conference}, pages 167--176, 2018.

\bibitem{yue2019videogames}
Yue Zheng.
\newblock Reinforcement learning and video games.
\newblock {\em arXiv preprint arXiv:1909.04751}, 2019.

\bibitem{zhou2017chemical}
Zhenpeng Zhou, Xiaocheng Li, and Richard~N Zare.
\newblock Optimizing chemical reactions with deep reinforcement learning.
\newblock {\em ACS Central Science}, 3(12):1337--1344, 2017.

\end{thebibliography}
