\begin{thebibliography}{59}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[uci()]{uci_link}
The uci machine learning repository.
\newblock URL \url{https://archive.ics.uci.edu/}.

\bibitem[Athreya et~al.(2004)Athreya, Ney, and Ney]{athreya2004branching}
K.~B. Athreya, P.~E. Ney, and P.~Ney.
\newblock \emph{Branching processes}.
\newblock Courier Corporation, 2004.

\bibitem[Ball et~al.(2008)Ball, Brunner, Myers, Strand, Alberts, and
  Tcheng]{ball2008robust}
N.~M. Ball, R.~J. Brunner, A.~D. Myers, N.~E. Strand, S.~L. Alberts, and
  D.~Tcheng.
\newblock Robust machine learning applied to astronomical data sets. iii.
  probabilistic photometric redshifts for galaxies and quasars in the sdss and
  galex.
\newblock \emph{The Astrophysical Journal}, 683\penalty0 (1):\penalty0 12,
  2008.

\bibitem[Bishop(1994)]{bishop1994mixture}
C.~M. Bishop.
\newblock Mixture density networks.
\newblock 1994.

\bibitem[Breiman(2017)]{breiman2017classification}
L.~Breiman.
\newblock \emph{Classification and regression trees}.
\newblock Routledge, 2017.

\bibitem[Cousins and Riondato(2019)]{cousins2019cadet}
C.~Cousins and M.~Riondato.
\newblock Cadet: interpretable parametric conditional density estimation with
  decision trees and forests.
\newblock \emph{Machine Learning}, 108:\penalty0 1613--1634, 2019.

\bibitem[Cover and Thomas(2012)]{cover:12:elements}
T.~M. Cover and J.~A. Thomas.
\newblock \emph{Elements of information theory}.
\newblock John Wiley \& Sons, 2012.

\bibitem[DeSantis et~al.(2014)DeSantis, Ma, Bryan, and
  Jemal]{desantis2014breast}
C.~DeSantis, J.~Ma, L.~Bryan, and A.~Jemal.
\newblock Breast cancer statistics, 2013.
\newblock \emph{CA: a cancer journal for clinicians}, 64\penalty0 (1):\penalty0
  52--62, 2014.

\bibitem[Durrieu et~al.(2018)Durrieu, Grama, Jaunatre, Pham, and
  Tricot]{durrieu2018extremefit}
G.~Durrieu, I.~Grama, K.~Jaunatre, Q.-K. Pham, and J.-M. Tricot.
\newblock Extremefit: a package for extreme quantiles.
\newblock \emph{Journal of Statistical Software}, 87:\penalty0 1--20, 2018.

\bibitem[Dutordoir et~al.(2018)Dutordoir, Salimbeni, Hensman, and
  Deisenroth]{dutordoir2018gaussian}
V.~Dutordoir, H.~Salimbeni, J.~Hensman, and M.~Deisenroth.
\newblock Gaussian process conditional density estimation.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Fan et~al.(1996)Fan, Yao, and Tong]{fan1996estimation}
J.~Fan, Q.~Yao, and H.~Tong.
\newblock Estimation of conditional densities and sensitivity measures in
  nonlinear dynamical systems.
\newblock \emph{Biometrika}, 83\penalty0 (1):\penalty0 189--206, 1996.

\bibitem[Galbrun(2022)]{galbrun2022minimum}
E.~Galbrun.
\newblock The minimum description length principle for pattern mining: A
  survey.
\newblock \emph{Data mining and knowledge discovery}, 36\penalty0 (5):\penalty0
  1679--1727, 2022.

\bibitem[Gao and Hastie(2022)]{gao2022lincde}
Z.~Gao and T.~Hastie.
\newblock Lincde: conditional density estimation via lindsey's method.
\newblock \emph{Journal of machine learning research}, 23\penalty0
  (52):\penalty0 1--55, 2022.

\bibitem[Gilleskie and Mroz(2004)]{gilleskie2004flexible}
D.~B. Gilleskie and T.~A. Mroz.
\newblock A flexible approach for estimating the effects of covariates on
  health expenditures.
\newblock \emph{Journal of health economics}, 23\penalty0 (2):\penalty0
  391--418, 2004.

\bibitem[Gr{\"u}nwald(2007)]{grunwald2007minimum}
P.~Gr{\"u}nwald.
\newblock \emph{The minimum description length principle}.
\newblock MIT press, 2007.

\bibitem[Gr{\"u}nwald and Roos(2019)]{grunwald2019minimum}
P.~Gr{\"u}nwald and T.~Roos.
\newblock Minimum description length revisited.
\newblock \emph{arXiv preprint arXiv:1908.08484}, 2019.

\bibitem[Hall et~al.(2004)Hall, Racine, and Li]{hall2004cross}
P.~Hall, J.~Racine, and Q.~Li.
\newblock Cross-validation and the estimation of conditional probability
  densities.
\newblock \emph{Journal of the American Statistical Association}, 99\penalty0
  (468):\penalty0 1015--1026, 2004.

\bibitem[Hu et~al.(2019)Hu, Rudin, and Seltzer]{hu2019optimal}
X.~Hu, C.~Rudin, and M.~Seltzer.
\newblock Optimal sparse decision trees.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Jeon and Taylor(2012)]{jeon2012using}
J.~Jeon and J.~W. Taylor.
\newblock Using conditional kernel density estimation for wind power density
  forecasting.
\newblock \emph{Journal of the American Statistical Association}, 107\penalty0
  (497):\penalty0 66--79, 2012.

\bibitem[Kontkanen and Myllym{\"a}ki(2005)]{kontkanen2005analyzing}
P.~Kontkanen and P.~Myllym{\"a}ki.
\newblock Analyzing the stochastic complexity via tree polynomials.
\newblock \emph{Unpublished manuscript}, 2005.

\bibitem[Kontkanen and Myllym{\"a}ki(2007{\natexlab{a}})]{kontkanen2007linear}
P.~Kontkanen and P.~Myllym{\"a}ki.
\newblock A linear-time algorithm for computing the multinomial stochastic
  complexity.
\newblock \emph{Information Processing Letters}, 103\penalty0 (6):\penalty0
  227--233, 2007{\natexlab{a}}.

\bibitem[Kontkanen and Myllym{\"a}ki(2007{\natexlab{b}})]{kontkanen2007mdl}
P.~Kontkanen and P.~Myllym{\"a}ki.
\newblock {MDL} histogram density estimation.
\newblock In M.~Meila and X.~Shen, editors, \emph{Proceedings of the Eleventh
  International Conference on Artificial Intelligence and Statistics}, volume~2
  of \emph{Proceedings of Machine Learning Research}. PMLR, 2007{\natexlab{b}}.

\bibitem[Kotz and Nadarajah(2000)]{kotz2000extreme}
S.~Kotz and S.~Nadarajah.
\newblock \emph{Extreme value distributions: theory and applications}.
\newblock world scientific, 2000.

\bibitem[Lantz(2019)]{lantz2019machine}
B.~Lantz.
\newblock \emph{Machine learning with R: expert techniques for predictive
  modeling}.
\newblock Packt publishing ltd, 2019.

\bibitem[Lindsey(1974)]{lindsey1974comparison}
J.~Lindsey.
\newblock Comparison of probability distributions.
\newblock \emph{Journal of the Royal Statistical Society: Series B
  (Methodological)}, 36\penalty0 (1):\penalty0 38--47, 1974.

\bibitem[Luo and Khoshgoftaar(2006)]{luo2006unsupervised}
Q.~Luo and T.~M. Khoshgoftaar.
\newblock Unsupervised multiscale color image segmentation based on mdl
  principle.
\newblock \emph{IEEE Transactions on Image Processing}, 15\penalty0
  (9):\penalty0 2755--2761, 2006.

\bibitem[Malerba et~al.(2004)Malerba, Esposito, Ceci, and
  Appice]{malerba2004top}
D.~Malerba, F.~Esposito, M.~Ceci, and A.~Appice.
\newblock Top-down induction of model trees with regression and splitting
  nodes.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 26\penalty0 (5):\penalty0 612--625, 2004.

\bibitem[Marx et~al.(2021)Marx, Yang, and van Leeuwen]{marx2021estimating}
A.~Marx, L.~Yang, and M.~van Leeuwen.
\newblock Estimating conditional mutual information for discrete-continuous
  mixtures using multi-dimensional adaptive histograms.
\newblock In \emph{Proceedings of the 2021 SIAM International Conference on
  Data Mining (SDM)}, pages 387--395. SIAM, 2021.

\bibitem[Molnar(2020)]{molnar2020interpretable}
C.~Molnar.
\newblock \emph{Interpretable machine learning}.
\newblock Lulu.com, 2020.

\bibitem[Mononen and Myllym{\"{a}}ki(2008)]{mononen:08:sub-lin-stoch-comp}
T.~Mononen and P.~Myllym{\"{a}}ki.
\newblock Computing the multinomial stochastic complexity in sub-linear time.
\newblock In \emph{Proceedings of the 4th European Workshop on Probabilistic
  Graphical Models}, pages 209--216, 2008.

\bibitem[Mussa(2013)]{mussa2013aitchison}
H.~Y. Mussa.
\newblock The aitchison and aitken kernel function revisited.
\newblock \emph{Journal of Mathematics Research}, 5\penalty0 (1):\penalty0 22,
  2013.

\bibitem[Nikolova et~al.(2012)Nikolova, Sinko, and Sutton]{nikolova2012maximum}
S.~Nikolova, A.~Sinko, and M.~Sutton.
\newblock Do maximum waiting times guarantees change clinical priorities? a
  conditional density estimation approach.
\newblock Technical report, HEDG, c/o Department of Economics, University of
  York, 2012.

\bibitem[Papageorgiou and Kontoyiannis(2024)]{papageorgiou2024posterior}
I.~Papageorgiou and I.~Kontoyiannis.
\newblock Posterior representations for bayesian context trees: Sampling,
  estimation and convergence.
\newblock \emph{Bayesian analysis}, 19\penalty0 (2):\penalty0 501--529, 2024.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion,
  Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos,
  Cournapeau, Brucher, Perrot, and Duchesnay]{scikit-learn}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel,
  M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, J.~Vanderplas, A.~Passos,
  D.~Cournapeau, M.~Brucher, M.~Perrot, and E.~Duchesnay.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock \emph{Journal of Machine Learning Research}, 12:\penalty0 2825--2830,
  2011.

\bibitem[Pospisil and Lee(2018)]{pospisil2018rfcde}
T.~Pospisil and A.~B. Lee.
\newblock Rfcde: Random forests for conditional density estimation.
\newblock \emph{arXiv preprint arXiv:1804.05753}, 2018.

\bibitem[Proen{\c{c}}a and van Leeuwen(2020)]{proencca2020interpretable}
H.~M. Proen{\c{c}}a and M.~van Leeuwen.
\newblock Interpretable multiclass classification by mdl-based rule lists.
\newblock \emph{Information Sciences}, 512:\penalty0 1372--1393, 2020.

\bibitem[Quinlan(2014)]{quinlan2014c4}
J.~R. Quinlan.
\newblock \emph{C4. 5: programs for machine learning}.
\newblock Elsevier, 2014.

\bibitem[Quinlan et~al.(1992)]{quinlan1992learning}
J.~R. Quinlan et~al.
\newblock Learning with continuous classes.
\newblock In \emph{5th Australian joint conference on artificial intelligence},
  volume~92, pages 343--348. World Scientific, 1992.

\bibitem[Rezende and Mohamed(2015)]{rezende2015variational}
D.~Rezende and S.~Mohamed.
\newblock Variational inference with normalizing flows.
\newblock In \emph{International conference on machine learning}, pages
  1530--1538. PMLR, 2015.

\bibitem[Ribeiro et~al.(2016)Ribeiro, Singh, and Guestrin]{ribeiro2016should}
M.~T. Ribeiro, S.~Singh, and C.~Guestrin.
\newblock Why should i trust you? explaining the predictions of any classifier.
\newblock In \emph{Proceedings of the 22nd ACM SIGKDD international conference
  on knowledge discovery and data mining}, pages 1135--1144, 2016.

\bibitem[Rissanen(1978)]{rissanen1978modeling}
J.~Rissanen.
\newblock Modeling by shortest data description.
\newblock \emph{Automatica}, 14\penalty0 (5):\penalty0 465--471, 1978.

\bibitem[Rissanen(1983)]{rissanen1983universal}
J.~Rissanen.
\newblock A universal prior for integers and estimation by minimum description
  length.
\newblock \emph{The Annals of statistics}, 11\penalty0 (2):\penalty0 416--431,
  1983.

\bibitem[Roos et~al.(2008)Roos, Silander, Kontkanen, and
  Myllymaki]{roos2008bayesian}
T.~Roos, T.~Silander, P.~Kontkanen, and P.~Myllymaki.
\newblock Bayesian network structure learning using factorized nml universal
  models.
\newblock In \emph{2008 Information Theory and Applications Workshop}, pages
  272--276. IEEE, 2008.

\bibitem[Rosenblatt(1969)]{rosenblatt1969conditional}
M.~Rosenblatt.
\newblock Conditional probability density and regression estimators.
\newblock \emph{Multivariate analysis II}, 25:\penalty0 31, 1969.

\bibitem[Rothfuss et~al.(2019{\natexlab{a}})Rothfuss, Ferreira, Boehm, Walther,
  Ulrich, Asfour, and Krause]{rothfuss2019noisereg}
J.~Rothfuss, F.~Ferreira, S.~Boehm, S.~Walther, M.~Ulrich, T.~Asfour, and
  A.~Krause.
\newblock Noise regularization for conditional density estimation.
\newblock \emph{arXiv:1907.08982}, 2019{\natexlab{a}}.

\bibitem[Rothfuss et~al.(2019{\natexlab{b}})Rothfuss, Ferreira, Walther, and
  Ulrich]{rothfuss2019conditional}
J.~Rothfuss, F.~Ferreira, S.~Walther, and M.~Ulrich.
\newblock Conditional density estimation with neural networks: Best practices
  and benchmarks.
\newblock \emph{arXiv preprint arXiv:1903.00954}, 2019{\natexlab{b}}.

\bibitem[Samani et~al.(2021)Samani, Stadler, Flinta, and
  Johnsson]{samani2021conditional}
F.~S. Samani, R.~Stadler, C.~Flinta, and A.~Johnsson.
\newblock Conditional density estimation of service metrics for networked
  services.
\newblock \emph{IEEE Transactions on Network and Service Management},
  18\penalty0 (2):\penalty0 2350--2364, 2021.

\bibitem[Seabold and Perktold(2010)]{seabold2010statsmodels}
S.~Seabold and J.~Perktold.
\newblock statsmodels: Econometric and statistical modeling with python.
\newblock In \emph{9th Python in Science Conference}, 2010.

\bibitem[Shtar'kov(1987)]{shtar1987universal}
Y.~M. Shtar'kov.
\newblock Universal sequential coding of single messages.
\newblock \emph{Problemy Peredachi Informatsii}, 23\penalty0 (3):\penalty0
  3--17, 1987.

\bibitem[Shu et~al.(2017)Shu, Bui, and Ghavamzadeh]{shu2017bottleneck}
R.~Shu, H.~H. Bui, and M.~Ghavamzadeh.
\newblock Bottleneck conditional density estimation.
\newblock In \emph{International conference on machine learning}, pages
  3164--3172. PMLR, 2017.

\bibitem[Silander et~al.(2018)Silander, Lepp{\"a}-Aho, J{\"a}{\"a}saari, and
  Roos]{silander2018quotient}
T.~Silander, J.~Lepp{\"a}-Aho, E.~J{\"a}{\"a}saari, and T.~Roos.
\newblock Quotient normalized maximum likelihood criterion for learning
  bayesian network structures.
\newblock In \emph{International conference on artificial intelligence and
  statistics}, pages 948--957. PMLR, 2018.

\bibitem[Stanley(2015)]{stanley2015catalan}
R.~P. Stanley.
\newblock \emph{Catalan numbers}.
\newblock Cambridge University Press, 2015.

\bibitem[Strobl and Visweswaran(2021)]{strobl2021dirac}
E.~V. Strobl and S.~Visweswaran.
\newblock Dirac delta regression: Conditional density estimation with clinical
  trials.
\newblock In \emph{The KDD'21 Workshop on Causal Discovery}, pages 78--125.
  PMLR, 2021.

\bibitem[Sugiyama et~al.(2010)Sugiyama, Takeuchi, Suzuki, Kanamori, Hachiya,
  and Okanohara]{sugiyama2010conditional}
M.~Sugiyama, I.~Takeuchi, T.~Suzuki, T.~Kanamori, H.~Hachiya, and D.~Okanohara.
\newblock Conditional density estimation via least-squares density ratio
  estimation.
\newblock In \emph{Proceedings of the Thirteenth International Conference on
  Artificial Intelligence and Statistics}, pages 781--788. JMLR Workshop and
  Conference Proceedings, 2010.

\bibitem[Trippe and Turner(2018)]{trippe2018conditional}
B.~L. Trippe and R.~E. Turner.
\newblock Conditional density estimation with bayesian normalising flows.
\newblock \emph{arXiv preprint arXiv:1802.04908}, 2018.

\bibitem[Virtanen et~al.(2020)Virtanen, Gommers, Oliphant, Haberland, Reddy,
  Cournapeau, Burovski, Peterson, Weckesser, Bright, {van der Walt}, Brett,
  Wilson, Millman, Mayorov, Nelson, Jones, Kern, Larson, Carey, Polat, Feng,
  Moore, {VanderPlas}, Laxalde, Perktold, Cimrman, Henriksen, Quintero, Harris,
  Archibald, Ribeiro, Pedregosa, {van Mulbregt}, and {SciPy 1.0
  Contributors}]{2020SciPy-NMeth}
P.~Virtanen, R.~Gommers, T.~E. Oliphant, M.~Haberland, T.~Reddy, D.~Cournapeau,
  E.~Burovski, P.~Peterson, W.~Weckesser, J.~Bright, S.~J. {van der Walt},
  M.~Brett, J.~Wilson, K.~J. Millman, N.~Mayorov, A.~R.~J. Nelson, E.~Jones,
  R.~Kern, E.~Larson, C.~J. Carey, {\.I}.~Polat, Y.~Feng, E.~W. Moore,
  J.~{VanderPlas}, D.~Laxalde, J.~Perktold, R.~Cimrman, I.~Henriksen, E.~A.
  Quintero, C.~R. Harris, A.~M. Archibald, A.~H. Ribeiro, F.~Pedregosa, P.~{van
  Mulbregt}, and {SciPy 1.0 Contributors}.
\newblock {{SciPy} 1.0: Fundamental Algorithms for Scientific Computing in
  Python}.
\newblock \emph{Nature Methods}, 17:\penalty0 261--272, 2020.
\newblock \doi{10.1038/s41592-019-0686-2}.

\bibitem[Yang and van Leeuwen(2022)]{yang2022truly}
L.~Yang and M.~van Leeuwen.
\newblock Truly unordered probabilistic rule sets for multi-class
  classification.
\newblock In \emph{Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pages 87--103. Springer, 2022.

\bibitem[Yang et~al.(2023)Yang, Baratchi, and van
  Leeuwen]{yang:20:unsupervised}
L.~Yang, M.~Baratchi, and M.~van Leeuwen.
\newblock Unsupervised discretization by two-dimensional mdl-based histogram.
\newblock \emph{Machine Learning}, pages 1--35, 2023.

\bibitem[Zhang et~al.(2023)Zhang, Xin, Seltzer, and Rudin]{zhang2023optimal}
R.~Zhang, R.~Xin, M.~Seltzer, and C.~Rudin.
\newblock Optimal sparse regression trees.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~37, pages 11270--11279, 2023.

\end{thebibliography}
