\begin{thebibliography}{69}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Achiam et~al.(2023)Achiam, Adler, Agarwal, Ahmad, Akkaya, Aleman, Almeida, Altenschmidt, Altman, Anadkat, et~al.]{achiam2023gpt}
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia~Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et~al.
\newblock Gpt-4 technical report.
\newblock \emph{arXiv preprint arXiv:2303.08774}, 2023.

\bibitem[Azizi et~al.(2023)Azizi, Kornblith, Saharia, Norouzi, and Fleet]{azizi2023synthetic}
Shekoofeh Azizi, Simon Kornblith, Chitwan Saharia, Mohammad Norouzi, and David~J. Fleet.
\newblock Synthetic data from diffusion models improves imagenet classification.
\newblock \emph{Transactions on Machine Learning Research}, 2023.
\newblock ISSN 2835-8856.
\newblock URL \url{https://openreview.net/forum?id=DlRsoxjyPm}.

\bibitem[Bansal and Grover(2023)]{bansal2023leaving}
Hritik Bansal and Aditya Grover.
\newblock Leaving reality to imagination: Robust classification via generated datasets.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2023.

\bibitem[Besnier et~al.(2020)Besnier, Jain, Bursuc, Cord, and P{\'e}rez]{besnier2020dataset}
Victor Besnier, Himalaya Jain, Andrei Bursuc, Matthieu Cord, and Patrick P{\'e}rez.
\newblock This dataset does not exist: training models from generated images.
\newblock In \emph{ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 1--5. IEEE, 2020.

\bibitem[Brooks et~al.(2023)Brooks, Holynski, and Efros]{brooks2023instructpix2pix}
Tim Brooks, Aleksander Holynski, and Alexei~A Efros.
\newblock Instructpix2pix: Learning to follow image editing instructions.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 18392--18402, 2023.

\bibitem[Canny(1986)]{canny1986computational}
John Canny.
\newblock A computational approach to edge detection.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, PAMI-8\penalty0 (6):\penalty0 679--698, 1986.

\bibitem[Chen et~al.(2023{\natexlab{a}})Chen, Xie, Chen, Hong, Li, and Yeung]{chen2023integrating}
Kai Chen, Enze Xie, Zhe Chen, Lanqing Hong, Zhenguo Li, and Dit-Yan Yeung.
\newblock Integrating geometric control into text-to-image diffusion models for high-quality detection data generation via text prompt.
\newblock \emph{arXiv preprint arXiv:2306.04607}, 2023{\natexlab{a}}.

\bibitem[Chen et~al.(2023{\natexlab{b}})Chen, Sun, Song, and Luo]{Chen_2023_ICCVdet}
Shoufa Chen, Peize Sun, Yibing Song, and Ping Luo.
\newblock Diffusiondet: Diffusion model for object detection.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}, pages 19830--19843, October 2023{\natexlab{b}}.

\bibitem[Cimpoi et~al.(2014)Cimpoi, Maji, Kokkinos, Mohamed, and Vedaldi]{cimpoi14describingdtd}
Mircea Cimpoi, Subhransu Maji, Iasonas Kokkinos, Sammy Mohamed, and Andrea Vedaldi.
\newblock Describing textures in the wild.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, 2014.

\bibitem[Connor and Khoshgoftaar(2019)]{connor2019survey}
Shorten Connor and Taghi~M Khoshgoftaar.
\newblock A survey on image data augmentation for deep learning.
\newblock \emph{Journal of big data}, 6\penalty0 (1):\penalty0 1--48, 2019.

\bibitem[Cubuk et~al.(2020)Cubuk, Zoph, Shlens, and Le]{cubuk2020randaugment}
Ekin~D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc~V Le.
\newblock Randaugment: Practical automated data augmentation with a reduced search space.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops}, pages 702--703, 2020.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei]{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern recognition}, pages 248--255. Ieee, 2009.

\bibitem[Dhariwal and Nichol(2021)]{dhariwal2021diffusionbeatgans}
Prafulla Dhariwal and Alexander Nichol.
\newblock Diffusion models beat gans on image synthesis.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 8780--8794, 2021.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and Houlsby]{dosovitskiy2020imagevit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=YicbFdNTTy}.

\bibitem[Dunlap et~al.(2023)Dunlap, Umino, Zhang, Yang, Gonzalez, and Darrell]{dunlap2023diversify}
Lisa Dunlap, Alyssa Umino, Han Zhang, Jiezhi Yang, Joseph Gonzalez, and Trevor Darrell.
\newblock Diversify your vision datasets with automatic diffusion-based augmentation.
\newblock In \emph{Proceedings of the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)}, 2023.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2023/hash/f99f7b22ad47fa6ce151730cf8d17911-Abstract-Conference.html}.

\bibitem[Fan et~al.(2023)Fan, Chen, Krishnan, Katabi, Isola, and Tian]{fan2023scaling}
Lijie Fan, Kaifeng Chen, Dilip Krishnan, Dina Katabi, Phillip Isola, and Yonglong Tian.
\newblock Scaling laws of synthetic images for model training... for now.
\newblock \emph{arXiv preprint arXiv:2312.04567}, 2023.

\bibitem[Fogel et~al.(2020)Fogel, Averbuch-Elor, Cohen, Mazor, and Litman]{fogel2020scrabblegan}
Sharon Fogel, Hadar Averbuch-Elor, Sarel Cohen, Shai Mazor, and Roee Litman.
\newblock Scrabblegan: Semi-supervised varying length handwritten text generation.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 4324--4333, 2020.

\bibitem[Gal et~al.(2023)Gal, Alaluf, Atzmon, Patashnik, Bermano, Chechik, and Cohen-or]{gal2022imagetextinversion}
Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or~Patashnik, Amit~Haim Bermano, Gal Chechik, and Daniel Cohen-or.
\newblock An image is worth one word: Personalizing text-to-image generation using textual inversion.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=NAQvF08TcyG}.

\bibitem[Ge et~al.(2023)Ge, Xu, Zhao, Joshi, Itti, and Vineet]{ge2023beyonddetseg}
Yunhao Ge, Jiashu Xu, Brian~Nlong Zhao, Neel Joshi, Laurent Itti, and Vibhav Vineet.
\newblock Beyond generation: Harnessing text to image models for object detection and segmentation.
\newblock \emph{arXiv preprint arXiv:2309.05956}, 2023.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deepresnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 770--778, 2016.

\bibitem[He et~al.(2023)He, Sun, Yu, Xue, Zhang, Torr, Bai, and Qi]{he2022synthetic}
Ruifei He, Shuyang Sun, Xin Yu, Chuhui Xue, Wenqing Zhang, Philip Torr, Song Bai, and Xiaojuan Qi.
\newblock Is synthetic data from generative models ready for image recognition?
\newblock In \emph{Proceedings of the Eleventh International Conference on Learning Representations (ICLR)}, 2023.
\newblock URL \url{https://openreview.net/forum?id=nUmCcZ5RKF}.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and Hochreiter]{heusel2017gansfid}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash equilibrium.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 6840--6851, 2020.

\bibitem[Krause et~al.(2013)Krause, Stark, Deng, and Fei-Fei]{krause20133dcars}
Jonathan Krause, Michael Stark, Jia Deng, and Li~Fei-Fei.
\newblock 3d object representations for fine-grained categorization.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer Vision Workshops}, pages 554--561, 2013.

\bibitem[Lei et~al.(2023)Lei, Chen, Zhang, Zhao, and Tao]{lei2023imagecaptions}
Shiye Lei, Hao Chen, Sen Zhang, Bo~Zhao, and Dacheng Tao.
\newblock Image captions are natural prompts for text-to-image models.
\newblock \emph{arXiv preprint arXiv:2307.08526}, 2023.

\bibitem[Li et~al.(2023{\natexlab{a}})Li, Liu, Chen, Lee, Li, and Liu]{li2023benchmarking}
Bo~Li, Haotian Liu, Liangyu Chen, Yong~Jae Lee, Chunyuan Li, and Ziwei Liu.
\newblock Benchmarking and analyzing generative data for visual recognition.
\newblock \emph{arXiv preprint arXiv:2307.13697}, 2023{\natexlab{a}}.

\bibitem[Li et~al.(2024)Li, Li, and Hoi]{li2024blipdiffusion}
Dongxu Li, Junnan Li, and Steven Hoi.
\newblock Blip-diffusion: Pre-trained subject representation for controllable text-to-image generation and editing.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Li et~al.(2023{\natexlab{b}})Li, Li, Savarese, and Hoi]{li2023blip}
Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi.
\newblock Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models.
\newblock In \emph{International conference on machine learning}, pages 19730--19742. PMLR, 2023{\natexlab{b}}.

\bibitem[Lin et~al.(2019)Lin, Zhou, Shen, Zhou, Bhagavatula, Choi, and Ren]{lin2019commongen}
Bill~Yuchen Lin, Wangchunshu Zhou, Ming Shen, Pei Zhou, Chandra Bhagavatula, Yejin Choi, and Xiang Ren.
\newblock Commongen: A constrained text generation challenge for generative commonsense reasoning.
\newblock \emph{arXiv preprint arXiv:1911.03705}, 2019.

\bibitem[Maji et~al.(2013)Maji, Rahtu, Kannala, Blaschko, and Vedaldi]{maji2013fineaircraft}
Subhransu Maji, Esa Rahtu, Juho Kannala, Matthew~B Blaschko, and Andrea Vedaldi.
\newblock Fine-grained visual classification of aircraft.
\newblock \emph{arXiv preprint arXiv:1306.5151}, 2013.

\bibitem[Marwood et~al.(2023)Marwood, Baluja, and Alon]{marwood2023diversity}
David Marwood, Shumeet Baluja, and Yair Alon.
\newblock Diversity and diffusion: Observations on synthetic image distributions with stable diffusion.
\newblock \emph{arXiv preprint arXiv:2311.00056}, 2023.

\bibitem[Meng et~al.(2022)Meng, He, Song, Song, Wu, Zhu, and Ermon]{meng2021sdedit}
Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and Stefano Ermon.
\newblock {SDE}dit: Guided image synthesis and editing with stochastic differential equations.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Moreno-Barea et~al.(2020{\natexlab{a}})Moreno-Barea, Jerez, and Franco]{moreno2020improving}
Francisco~J Moreno-Barea, Jos{\'e}~M Jerez, and Leonardo Franco.
\newblock Improving classification accuracy using data augmentation on small data sets.
\newblock \emph{Expert Systems with Applications}, 161:\penalty0 113696, 2020{\natexlab{a}}.

\bibitem[Moreno-Barea et~al.(2020{\natexlab{b}})Moreno-Barea, Jerez, and Franco]{moreno2020improvingcls}
Francisco~J Moreno-Barea, Jos{\'e}~M Jerez, and Leonardo Franco.
\newblock Improving classification accuracy using data augmentation on small data sets.
\newblock \emph{Expert Systems with Applications}, 161:\penalty0 113696, 2020{\natexlab{b}}.

\bibitem[Mou et~al.(2024)Mou, Wang, Xie, Wu, Zhang, Qi, and Shan]{mou2024t2iadapter}
Chong Mou, Xintao Wang, Liangbin Xie, Yanze Wu, Jian Zhang, Zhongang Qi, and Ying Shan.
\newblock T2i-adapter: Learning adapters to dig out more controllable ability for text-to-image diffusion models.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~38, pages 4296--4304, 2024.

\bibitem[Nguyen et~al.(2024)Nguyen, Vu, Tran, and Nguyen]{nguyen2024datasetseg}
Quang Nguyen, Truong Vu, Anh Tran, and Khoi Nguyen.
\newblock Dataset diffusion: Diffusion-based synthetic data generation for pixel-level semantic segmentation.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Nichol et~al.(2021)Nichol, Dhariwal, Ramesh, Shyam, Mishkin, McGrew, Sutskever, and Chen]{nichol2021glide}
Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen.
\newblock Glide: Towards photorealistic image generation and editing with text-guided diffusion models.
\newblock \emph{arXiv preprint arXiv:2112.10741}, 2021.

\bibitem[Nowruzi et~al.(2019)Nowruzi, Kapoor, Kolhatkar, Hassanat, Laganiere, and Rebut]{nowruzi2019howmuchrealdata}
Farzan~Erlik Nowruzi, Prince Kapoor, Dhanvin Kolhatkar, Fahed~Al Hassanat, Robert Laganiere, and Julien Rebut.
\newblock How much real data do we actually need: Analyzing object detection performance using synthetic and real data.
\newblock \emph{arXiv preprint arXiv:1907.07061}, 2019.

\bibitem[Podell et~al.(2024)Podell, English, Lacey, Blattmann, Dockhorn, M{\"u}ller, Penna, and Rombach]{podell2023sdxl}
Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas M{\"u}ller, Joe Penna, and Robin Rombach.
\newblock {SDXL}: Improving latent diffusion models for high-resolution image synthesis.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=di52zR8xgf}.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learningclip}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{International conference on machine learning}, pages 8748--8763. PMLR, 2021.

\bibitem[Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena, Zhou, Li, and Liu]{raffel2020exploring}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter~J Liu.
\newblock Exploring the limits of transfer learning with a unified text-to-text transformer.
\newblock \emph{Journal of machine learning research}, 21\penalty0 (140):\penalty0 1--67, 2020.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and Chen]{ramesh2022hierarchicaldalle2}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock \emph{arXiv preprint arXiv:2204.06125}, 1\penalty0 (2):\penalty0 3, 2022.

\bibitem[Rao et~al.(2021)Rao, Chen, Lu, and Zhou]{rao2021counterfactual}
Yongming Rao, Guangyi Chen, Jiwen Lu, and Jie Zhou.
\newblock Counterfactual attention learning for fine-grained visual categorization and re-identification.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 1025--1034, 2021.

\bibitem[Ravuri and Vinyals(2019)]{ravuri2019classification}
Suman Ravuri and Oriol Vinyals.
\newblock Classification accuracy score for conditional generative models.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 10684--10695, 2022.

\bibitem[Ruiz et~al.(2023)Ruiz, Li, Jampani, Pritch, Rubinstein, and Aberman]{ruiz2023dreambooth}
Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and Kfir Aberman.
\newblock Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 22500--22510, 2023.

\bibitem[Saharia et~al.(2022)Saharia, Chan, Saxena, Li, Whang, Denton, Ghasemipour, Gontijo~Lopes, Karagol~Ayan, Salimans, et~al.]{saharia2022photorealisticimagen}
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily~L Denton, Kamyar Ghasemipour, Raphael Gontijo~Lopes, Burcu Karagol~Ayan, Tim Salimans, et~al.
\newblock Photorealistic text-to-image diffusion models with deep language understanding.
\newblock \emph{Advances in neural information processing systems}, 35:\penalty0 36479--36494, 2022.

\bibitem[Sampath et~al.(2021)Sampath, Maurtua, Aguilar~Martin, and Gutierrez]{sampath2021survey}
Vignesh Sampath, I{\~n}aki Maurtua, Juan~Jose Aguilar~Martin, and Aitor Gutierrez.
\newblock A survey on generative adversarial networks for imbalance problems in computer vision tasks.
\newblock \emph{Journal of big Data}, 8:\penalty0 1--59, 2021.

\bibitem[Sar{\i}y{\i}ld{\i}z et~al.(2023)Sar{\i}y{\i}ld{\i}z, Alahari, Larlus, and Kalantidis]{sariyildiz2023fakeit}
Mert~B{\"u}lent Sar{\i}y{\i}ld{\i}z, Karteek Alahari, Diane Larlus, and Yannis Kalantidis.
\newblock Fake it till you make it: Learning transferable representations from synthetic imagenet clones.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 8011--8021, 2023.

\bibitem[Sauer et~al.(2023)Sauer, Lorenz, Blattmann, and Rombach]{sauer2023adversarialsdxlturbo}
Axel Sauer, Dominik Lorenz, Andreas Blattmann, and Robin Rombach.
\newblock Adversarial diffusion distillation.
\newblock \emph{arXiv preprint arXiv:2311.17042}, 2023.

\bibitem[Shipard et~al.(2023)Shipard, Wiliem, Thanh, Xiang, and Fookes]{shipard2023diversityneededcls}
Jordan Shipard, Arnold Wiliem, Kien~Nguyen Thanh, Wei Xiang, and Clinton Fookes.
\newblock Diversity is definitely needed: Improving model-agnostic zero-shot classification via stable diffusion.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 769--778, 2023.

\bibitem[Song et~al.(2021)Song, Meng, and Ermon]{song2020denoising}
Jiaming Song, Chenlin Meng, and Stefano Ermon.
\newblock Denoising diffusion implicit models.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=St1giarCHLP}.

\bibitem[Trabucco et~al.(2024)Trabucco, Doherty, Gurinas, and Salakhutdinov]{trabucco2023effective}
Brandon Trabucco, Kyle Doherty, Max Gurinas, and Ruslan Salakhutdinov.
\newblock Effective data augmentation with diffusion models.
\newblock In \emph{Proceedings of the Twelfth International Conference on Learning Representations (ICLR)}, 2024.
\newblock URL \url{https://openreview.net/forum?id=2302.07944}.

\bibitem[Tremblay et~al.(2018)Tremblay, Prakash, Acuna, Brophy, Jampani, Anil, To, Cameracci, Boochoon, and Birchfield]{tremblay2018trainingdomainrandom}
Jonathan Tremblay, Aayush Prakash, David Acuna, Mark Brophy, Varun Jampani, Cem Anil, Thang To, Eric Cameracci, Shaad Boochoon, and Stan Birchfield.
\newblock Training deep networks with synthetic data: Bridging the reality gap by domain randomization.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition workshops}, pages 969--977, 2018.

\bibitem[Varol et~al.(2017)Varol, Romero, Martin, Mahmood, Black, Laptev, and Schmid]{varol2017learningfromsyn}
Gul Varol, Javier Romero, Xavier Martin, Naureen Mahmood, Michael~J Black, Ivan Laptev, and Cordelia Schmid.
\newblock Learning from synthetic humans.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 109--117, 2017.

\bibitem[von Platen et~al.(2022)von Platen, Patil, Lozhkov, Cuenca, Lambert, Li, Davaakhuu, Culotta, and Rodrigues]{diffusers}
Patrick von Platen, Suraj Patil, Anton Lozhkov, Pedro Cuenca, Nathan Lambert, Yehao Li, Mishig Davaakhuu, Aedan~S. Culotta, and Camilo Rodrigues.
\newblock Diffusers: State-of-the-art diffusion models.
\newblock \url{https://github.com/huggingface/diffusers}, 2022.
\newblock Accessed: 2023-05-10.

\bibitem[Wah et~al.(2011)Wah, Branson, Welinder, Perona, and Belongie]{WahCUB_200_2011}
C.~Wah, S.~Branson, P.~Welinder, P.~Perona, and S.~Belongie.
\newblock The caltech-ucsd birds-200-2011 dataset.
\newblock Technical Report CNS-TR-2011-001, California Institute of Technology, 2011.

\bibitem[Wang et~al.(2024{\natexlab{a}})Wang, Gao, Chen, Zhou, Cai, Hong, Li, Jiang, Yeung, Xu, et~al.]{wang2024detdiffusion}
Yibo Wang, Ruiyuan Gao, Kai Chen, Kaiqiang Zhou, Yingjie Cai, Lanqing Hong, Zhenguo Li, Lihui Jiang, Dit-Yan Yeung, Qiang Xu, et~al.
\newblock Detdiffusion: Synergizing generative and perceptive models for enhanced data generation and perception.
\newblock \emph{arXiv preprint arXiv:2403.13304}, 2024{\natexlab{a}}.

\bibitem[Wang et~al.(2024{\natexlab{b}})Wang, Wei, Wang, Chen, Hao, Wang, He, and Tian]{wang2024enhancediffmix}
Zhicai Wang, Longhui Wei, Tan Wang, Heyu Chen, Yanbin Hao, Xiang Wang, Xiangnan He, and Qi~Tian.
\newblock Enhance image classification via inter-class image mixup with diffusion model.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 2024{\natexlab{b}}.
\newblock URL \url{https://cvpr.thecvf.com/virtual/2024/poster/31002}.

\bibitem[Wu et~al.(2023)Wu, Zhao, Shou, Zhou, and Shen]{wu2023diffumaskseg}
Weijia Wu, Yuzhong Zhao, Mike~Zheng Shou, Hong Zhou, and Chunhua Shen.
\newblock Diffumask: Synthesizing images with pixel-level annotations for semantic segmentation using diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 1206--1217, 2023.

\bibitem[Wu et~al.(2024)Wu, Zhao, Chen, Gu, Zhao, He, Zhou, Shou, and Shen]{wu2024datasetdmseg}
Weijia Wu, Yuzhong Zhao, Hao Chen, Yuchao Gu, Rui Zhao, Yefei He, Hong Zhou, Mike~Zheng Shou, and Chunhua Shen.
\newblock Datasetdm: Synthesizing data with perception annotations using diffusion models.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Xie and Tu(2015)]{xie2015holistically}
Saining Xie and Zhuowen Tu.
\newblock Holistically-nested edge detection.
\newblock In \emph{Proceedings of the IEEE international conference on computer vision}, pages 1395--1403, 2015.

\bibitem[Yang et~al.(2015)Yang, Luo, Loy, and Tang]{yang2015largecompcars}
Linjie Yang, Ping Luo, Chen~Change Loy, and Xiaoou Tang.
\newblock A large-scale car dataset for fine-grained categorization and verification.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pages 3973--3981, 2015.

\bibitem[Yu et~al.(2023)Yu, Zhu, Culatana, Krishnamoorthi, Xiao, and Lee]{yu2023diversify}
Zhuoran Yu, Chenchen Zhu, Sean Culatana, Raghuraman Krishnamoorthi, Fanyi Xiao, and Yong~Jae Lee.
\newblock Diversify, don't fine-tune: Scaling up visual recognition training with synthetic images.
\newblock \emph{arXiv preprint arXiv:2312.02253}, 2023.

\bibitem[Yun et~al.(2019)Yun, Han, Oh, Chun, Choe, and Yoo]{yun2019cutmix}
Sangdoo Yun, Dongyoon Han, Seong~Joon Oh, Sanghyuk Chun, Junsuk Choe, and Youngjoon Yoo.
\newblock Cutmix: Regularization strategy to train strong classifiers with localizable features.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pages 6023--6032, 2019.

\bibitem[Zhang et~al.(2017)Zhang, Cisse, Dauphin, and Lopez-Paz]{zhang2017mixup}
Hongyi Zhang, Moustapha Cisse, Yann~N Dauphin, and David Lopez-Paz.
\newblock mixup: Beyond empirical risk minimization.
\newblock \emph{arXiv preprint arXiv:1710.09412}, 2017.

\bibitem[Zhang et~al.(2023)Zhang, Rao, and Agrawala]{zhang2023addingcontrol}
Lvmin Zhang, Anyi Rao, and Maneesh Agrawala.
\newblock Adding conditional control to text-to-image diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 3836--3847, 2023.

\bibitem[Zhang et~al.(2018)Zhang, Isola, Efros, Shechtman, and Wang]{zhang2018unreasonablelpips}
Richard Zhang, Phillip Isola, Alexei~A Efros, Eli Shechtman, and Oliver Wang.
\newblock The unreasonable effectiveness of deep features as a perceptual metric.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 586--595, 2018.

\bibitem[Zhang et~al.(2021)Zhang, Ling, Gao, Yin, Lafleche, Barriuso, Torralba, and Fidler]{zhang2021datasetgan}
Yuxuan Zhang, Huan Ling, Jun Gao, Kangxue Yin, Jean-Francois Lafleche, Adela Barriuso, Antonio Torralba, and Sanja Fidler.
\newblock Datasetgan: Efficient labeled data factory with minimal human effort.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 10145--10155, 2021.

\end{thebibliography}
