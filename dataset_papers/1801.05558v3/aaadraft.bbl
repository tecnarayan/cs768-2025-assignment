\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amari(1998)]{AmariS98neco}
Amari, S.
\newblock Natural gradient works efficiently in learning.
\newblock \emph{Neural Computation}, 10\penalty0 (2):\penalty0 251--276, 1998.

\bibitem[Andrychowicz et~al.(2016)Andrychowicz, Denil, {G{\'{o}}mez
  Colmenarejo}, Hoffman, Pfau, Schaul, Shillingford, {De Freitas}, and
  Deepmind]{Andrychowicz2016nips}
Andrychowicz, M., Denil, M., {G{\'{o}}mez Colmenarejo}, S., Hoffman, M.~W.,
  Pfau, D., Schaul, T., Shillingford, B., {De Freitas}, N., and Deepmind, G.
\newblock {Learning to learn by gradient descent by gradient descent}.
\newblock \emph{Advances in Neural Information Processing Systems (NIPS)},
  2016.

\bibitem[Desjardins et~al.(2015)Desjardins, Simonyan, Pascanu,
  et~al.]{Desjardins2015nips}
Desjardins, G., Simonyan, K., Pascanu, R., et~al.
\newblock Natural neural networks.
\newblock 2015.

\bibitem[Edwards \& Storkey(2017)Edwards and Storkey]{Edwards2017iclr}
Edwards, H. and Storkey, A.
\newblock {Towards a Neural Statistician}.
\newblock \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2017.

\bibitem[Finn \& Levine(2017)Finn and Levine]{FinnC2017arxiv}
Finn, C. and Levine, S.
\newblock Meta-learning and universality: Deep representations and gradient
  descent can approximate any learning algorithm, 2017.
\newblock {\em Preprint arXiv:1710.11622}.

\bibitem[Finn et~al.(2017)Finn, Abbeel., and Levine]{FinnC2017icml}
Finn, C., Abbeel., P., and Levine, S.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning (ICML)}, Sydney, Australia, 2017.

\bibitem[{Fort}(2017)]{fort2017arxiv}
{Fort}, S.
\newblock {Gaussian Prototypical Networks for Few-Shot Learning on Omniglot},
  2017.
\newblock {\em Preprint arXiv:1708.02735}.

\bibitem[{Garcia} \& {Bruna}(2017){Garcia} and {Bruna}]{Garcia2017arxiv}
{Garcia}, V. and {Bruna}, J.
\newblock {Few-Shot Learning with Graph Neural Networks}, 2017.
\newblock {\em Preprint arXiv:1711.04043}.

\bibitem[Grant et~al.(2018)Grant, Finn, Levine, Darrell, and
  Griffiths]{Grant2018iclr}
Grant, E., Finn, C., Levine, S., Darrell, T., and Griffiths, T.
\newblock Recasting gradient-based meta-learning as hierarchical bayes.
\newblock \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2018.

\bibitem[Ha et~al.(2016)Ha, Dai, and Le]{Ha2017iclr}
Ha, D., Dai, A., and Le, Q.~V.
\newblock {Hypernetworks}.
\newblock \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2016.

\bibitem[Hariharan \& Girshick(2016)Hariharan and Girshick]{Hariharan2017iccv}
Hariharan, B. and Girshick, R.~B.
\newblock Low-shot visual object recognition by shrinking and hallucinating
  features.
\newblock \emph{Proceedings of the International Conference on Computer Vision
  (ICCV)}, 2016.

\bibitem[Heskes(2000)]{Heskes2000neuralcomp}
Heskes, T.
\newblock On “natural” learning and pruning in multilayered perceptrons.
\newblock \emph{Neural Computation}, 2000.

\bibitem[{Ioffe} \& {Szegedy}(2015){Ioffe} and {Szegedy}]{Ioffe2015icml}
{Ioffe}, S. and {Szegedy}, C.
\newblock {Batch Normalization: Accelerating Deep Network Training by Reducing
  Internal Covariate Shift}.
\newblock \emph{Proceedings of the International Conference on Machine Learning
  (ICML)}, 2015.

\bibitem[Jang et~al.(2017)Jang, Gu, and Poole]{Jang2017iclr}
Jang, E., Gu, S., and Poole, B.
\newblock {Categorical Reparameterization with Gumbel-Softmax}.
\newblock \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2017.

\bibitem[Kaiser et~al.(2017)Kaiser, Nachum, Roy, and Bengio]{Kaiser2017iclr}
Kaiser, L., Nachum, O., Roy, A., and Bengio, S.
\newblock {Learning to Remember Rare Events}.
\newblock \emph{ICLR}, 2017.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{KingmaDP2015iclr}
Kingma, D.~P. and Ba, J.~L.
\newblock {ADAM}: A method for stochastic optimization.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, San Diego, CA, USA, 2015.

\bibitem[Koch et~al.(2015)Koch, Zemel, and Salakhutdinov]{KochG2015icml}
Koch, G., Zemel, R., and Salakhutdinov, R.
\newblock Siamese neural networks for one-shot image recognition.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning (ICML)}, Lille, France, 2015.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{Krizhevsky2012nips}
Krizhevsky, A., Sutskever, I., and Hinton, G.~E.
\newblock {ImageNet Classification with Deep Convolutional Neural Networks}.
\newblock \emph{Advances in Neural Information Processing Systems (NIPS)},
  2012.

\bibitem[Lake et~al.(2015)Lake, Salakhutdinov, and Tenenbaum]{Lake2015science}
Lake, B.~M., Salakhutdinov, R., and Tenenbaum, J.~B.
\newblock {Human-level concept learning through probabilistic program
  induction}.
\newblock \emph{Science}, 2015.

\bibitem[{Li} et~al.(2017){Li}, {Yang}, {Song}, and {Hospedales}]{Li2017aaai}
{Li}, D., {Yang}, Y., {Song}, Y.-Z., and {Hospedales}, T.~M.
\newblock {Learning to Generalize: Meta-Learning for Domain Generalization}.
\newblock \emph{Proceedings of the AAAI National Conference on Artificial
  Intelligence (AAAI)}, 2017.

\bibitem[Li \& Malik(2016)Li and Malik]{Li2016nips}
Li, K. and Malik, J.
\newblock {Learning to Optimize}.
\newblock \emph{Advances in Neural Information Processing Systems (NIPS)},
  2016.

\bibitem[Li et~al.(2017)Li, Zhou, Chen, and Li]{Li2017arxiv}
Li, Z., Zhou, F., Chen, F., and Li, H.
\newblock {Meta-SGD: Learning to Learn Quickly for Few Shot Learning}, 2017.
\newblock {\em Preprint arXiv:1707.09835}.

\bibitem[Maddison et~al.(2017)Maddison, Mnih, and Teh]{Maddison2017iclr}
Maddison, C.~J., Mnih, A., and Teh, Y.~W.
\newblock The concrete distribution: A continuous relaxation of discrete random
  variables.
\newblock \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2017.

\bibitem[Martens \& Grosse(2015)Martens and Grosse]{Martens2015icml}
Martens, J. and Grosse, R.
\newblock Optimizing neural networks with kronecker-factored approximate
  curvature.
\newblock 2015.

\bibitem[Mishra et~al.(2018)Mishra, Rohaninejad, Chen, and
  Abbeel]{Mishra2018iclr}
Mishra, N., Rohaninejad, M., Chen, X., and Abbeel, P.
\newblock A simple neural attentive meta-learner.
\newblock \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2018.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, Petersen, Beattie, Sadik,
  Antonoglou, King, Kumaran, Wierstra, Legg, and Hassabis]{MnihV2015nature}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M., Fidjeland, A.~K., Ostrovski, G., Petersen,
  S., Beattie, C., Sadik, A., Antonoglou, I., King, H., Kumaran, D., Wierstra,
  D., Legg, S., and Hassabis, D.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518, 2015.

\bibitem[Munkhdalai \& Yu(2017)Munkhdalai and Yu]{MunkhdalaiT2017icml}
Munkhdalai, T. and Yu, H.
\newblock Meta networks.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning (ICML)}, Sydney, Australia, 2017.

\bibitem[Ravi \& Larochelle(2017)Ravi and Larochelle]{RaviS2017iclr}
Ravi, S. and Larochelle, H.
\newblock Optimization as a model for few-shot learning.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, Toulon, France, 2017.

\bibitem[Ren et~al.(2018)Ren, Ravi, Triantafillou, Snell, Swersky, Tenenbaum,
  Larochelle, and Zemel]{Ren2018iclr}
Ren, M., Ravi, S., Triantafillou, E., Snell, J., Swersky, K., Tenenbaum, J.~B.,
  Larochelle, H., and Zemel, R.~S.
\newblock Meta-learning for semi-supervised few-shot classification.
\newblock \emph{Proceedings of the International Conference on Learning
  Representations (ICLR)}, 2018.

\bibitem[Robbins \& Monro(1951)Robbins and Monro]{RobbinsH51ams}
Robbins, H. and Monro, S.
\newblock A stochastic approximation method.
\newblock \emph{The Annals of Mathematical Statistics}, 22\penalty0
  (3):\penalty0 400--407, 1951.

\bibitem[Santoro et~al.(2016)Santoro, Bartunov, Botvinick, Wierstra, and
  Lilicrap]{SantoroA2016icml}
Santoro, A., Bartunov, S., Botvinick, M., Wierstra, D., and Lilicrap, T.
\newblock Meta-learning with memory-augmented neural networks.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning (ICML)}, New York, NY, USA, 2016.

\bibitem[Schmidhuber(1987)]{SchmidhuberJ87phd}
Schmidhuber, J.
\newblock \emph{Evolutionary Principles in Self-Referential Learning}.
\newblock PhD thesis, Technical University of Munich, 1987.

\bibitem[Schmidhuber et~al.(1997)Schmidhuber, Zhao, and
  Wiering]{SchmidhuberJ97mlj}
Schmidhuber, J., Zhao, J., and Wiering, M.
\newblock Shifting inductive bias with success-story algorithm, adaptive levin
  search, and incremental self-improvement.
\newblock \emph{Machine Learning}, 28:\penalty0 105--130, 1997.

\bibitem[Snell et~al.(2017)Snell, Swersky, and Zemel]{SnellJ2017nips}
Snell, J., Swersky, K., and Zemel, R.
\newblock Prototypical networks for few-shot learning.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  volume~30, 2017.

\bibitem[{Sung} et~al.(2017){Sung}, {Yang}, {Zhang}, {Xiang}, {Torr}, and
  {Hospedales}]{Sung2017arxiv}
{Sung}, F., {Yang}, Y., {Zhang}, L., {Xiang}, T., {Torr}, P.~H.~S., and
  {Hospedales}, T.~M.
\newblock {Learning to Compare: Relation Network for Few-Shot Learning}, 2017.
\newblock {\em Preprint arXiv:1711.06025}.

\bibitem[Thrun \& Pratt(1998)Thrun and Pratt]{ThrunS98book}
Thrun, S. and Pratt, L.
\newblock \emph{Learning to Learn}.
\newblock Kluwer Academic Publishers, 1998.

\bibitem[Triantafillou et~al.(2017)Triantafillou, Zemel, and
  Urtasun]{Triantafillou2017}
Triantafillou, E., Zemel, R., and Urtasun, R.
\newblock Few-shot learning through an information retrieval lens.
\newblock \emph{Advances in Neural Information Processing Systems (NIPS)},
  2017.

\bibitem[{Tsai} \& {Salakhutdinov}(2017){Tsai} and
  {Salakhutdinov}]{tsai2017arxiv}
{Tsai}, Y.-H.~H. and {Salakhutdinov}, R.
\newblock {Improving One-Shot Learning through Fusing Side Information}, 2017.
\newblock {\em Preprint arXiv:1710.08347}.

\bibitem[Vinyals et~al.(2016)Vinyals, Blundell, Lillicrap, Kavukcuoglu, and
  Wierstra]{VinyalsO2016nips}
Vinyals, O., Blundell, C., Lillicrap, T., Kavukcuoglu, K., and Wierstra, D.
\newblock Matching networks for one shot learning.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  volume~29, 2016.

\bibitem[Weinberger et~al.(2006)Weinberger, Blitzer, and
  Saul]{WeinbergerKQ2005nips}
Weinberger, K.~Q., Blitzer, J., and Saul, L.~K.
\newblock Distance metric learning for large margin nearest neighbor
  classification.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  volume~18, 2006.

\bibitem[Xing et~al.(2003)Xing, Ng, Jordan, and Russel]{XingEP2002nips}
Xing, E.~P., Ng, A.~Y., Jordan, M.~I., and Russel, S.
\newblock Distance metric learning, with application to clustering with
  side-information.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  volume~15. MIT Press, 2003.

\end{thebibliography}
