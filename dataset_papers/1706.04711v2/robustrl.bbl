\begin{thebibliography}{10}

\bibitem{antos2008learning}
Andr{\'a}s Antos, Csaba Szepesv{\'a}ri, and R{\'e}mi Munos.
\newblock Learning near-optimal policies with bellman-residual minimization
  based fitted policy iteration and a single sample path.
\newblock {\em Machine Learning}, 71(1):89--129, 2008.

\bibitem{bagnell2001solving}
J~Andrew Bagnell, Andrew~Y Ng, and Jeff~G Schneider.
\newblock Solving uncertain markov decision processes.
\newblock 2001.

\bibitem{bertsekas2011approximate}
Dimitri~P Bertsekas.
\newblock Approximate policy iteration: A survey and some new methods.
\newblock {\em Journal of Control Theory and Applications}, 9(3):310--335,
  2011.

\bibitem{bertsekas1996temporal}
Dimitri~P Bertsekas and Sergey Ioffe.
\newblock Temporal differences-based policy iteration and applications in
  neuro-dynamic programming.
\newblock {\em Lab. for Info. and Decision Systems Report LIDS-P-2349, MIT,
  Cambridge, MA}, 1996.

\bibitem{bertsekas1995neuro}
Dimitri~P Bertsekas and John~N Tsitsiklis.
\newblock Neuro-dynamic programming: an overview.
\newblock In {\em Decision and Control, 1995., Proceedings of the 34th IEEE
  Conference on}, volume~1, pages 560--564. IEEE, 1995.

\bibitem{bertsekas2009projected}
Dimitri~P Bertsekas and Huizhen Yu.
\newblock Projected equation methods for approximate solution of large linear
  systems.
\newblock {\em Journal of Computational and Applied Mathematics},
  227(1):27--50, 2009.

\bibitem{bhatnagar2009convergent}
Shalabh Bhatnagar, Doina Precup, David Silver, Richard~S Sutton, Hamid~R Maei,
  and Csaba Szepesv{\'a}ri.
\newblock Convergent temporal-difference learning with arbitrary smooth
  function approximation.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1204--1212, 2009.

\bibitem{boyan2002technical}
Justin~A Boyan.
\newblock Technical update: Least-squares temporal difference learning.
\newblock {\em Machine Learning}, 49(2-3):233--246, 2002.

\bibitem{bradtke1996linear}
Steven~J Bradtke and Andrew~G Barto.
\newblock Linear least-squares algorithms for temporal difference learning.
\newblock {\em Machine learning}, 22(1-3):33--57, 1996.

\bibitem{brockman2016openai}
Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman,
  Jie Tang, and Wojciech Zaremba.
\newblock Openai gym.
\newblock {\em arXiv preprint arXiv:1606.01540}, 2016.

\bibitem{delage2010percentile}
Erick Delage and Shie Mannor.
\newblock Percentile optimization for markov decision processes with parameter
  uncertainty.
\newblock {\em Operations research}, 58(1):203--213, 2010.

\bibitem{farahmand2009regularized}
Amir~M Farahmand, Mohammad Ghavamzadeh, Shie Mannor, and Csaba Szepesv{\'a}ri.
\newblock Regularized policy iteration.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  441--448, 2009.

\bibitem{iyengar2005robust}
Garud~N Iyengar.
\newblock Robust dynamic programming.
\newblock {\em Mathematics of Operations Research}, 30(2):257--280, 2005.

\bibitem{lim2013reinforcement}
Shiau~Hong Lim, Huan Xu, and Shie Mannor.
\newblock Reinforcement learning in robust markov decision processes.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  701--709, 2013.

\bibitem{morimoto2005robust}
Jun Morimoto and Kenji Doya.
\newblock Robust reinforcement learning.
\newblock {\em Neural computation}, 17(2):335--359, 2005.

\bibitem{nedic2003least}
A~Nedi{\'c} and Dimitri~P Bertsekas.
\newblock Least squares policy evaluation algorithms with linear function
  approximation.
\newblock {\em Discrete Event Dynamic Systems}, 13(1):79--110, 2003.

\bibitem{nilim2003robustness}
Arnab Nilim and Laurent El~Ghaoui.
\newblock Robustness in markov decision problems with uncertain transition
  matrices.
\newblock In {\em NIPS}, pages 839--846, 2003.

\bibitem{pinto2017robust}
Lerrel Pinto, James Davidson, Rahul Sukthankar, and Abhinav Gupta.
\newblock Robust adversarial reinforcement learning.
\newblock {\em arXiv preprint arXiv:1703.02702}, 2017.

\bibitem{powell2007approximate}
Warren~B Powell.
\newblock {\em Approximate Dynamic Programming: Solving the curses of
  dimensionality}, volume 703.
\newblock John Wiley \& Sons, 2007.

\bibitem{puterman2014markov}
Martin~L Puterman.
\newblock {\em Markov decision processes: discrete stochastic dynamic
  programming}.
\newblock John Wiley \& Sons, 2014.

\bibitem{shapiro2002minimax}
Alexander Shapiro and Anton Kleywegt.
\newblock Minimax analysis of stochastic problems.
\newblock {\em Optimization Methods and Software}, 17(3):523--542, 2002.

\bibitem{sutton1998reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock {\em Reinforcement learning: An introduction}, volume~1.
\newblock MIT press Cambridge, 1998.

\bibitem{sutton2009convergent}
Richard~S Sutton, Hamid~R Maei, and Csaba Szepesv{\'a}ri.
\newblock A convergent $ o (n) $ temporal-difference algorithm for off-policy
  learning with linear function approximation.
\newblock In {\em Advances in neural information processing systems}, pages
  1609--1616, 2009.

\bibitem{sutton2009fast}
Richard~S Sutton, Hamid~Reza Maei, Doina Precup, Shalabh Bhatnagar, David
  Silver, Csaba Szepesv{\'a}ri, and Eric Wiewiora.
\newblock Fast gradient-descent methods for temporal-difference learning with
  linear function approximation.
\newblock In {\em Proceedings of the 26th Annual International Conference on
  Machine Learning}, pages 993--1000. ACM, 2009.

\bibitem{tamar2014optimizing}
Aviv Tamar, Yonatan Glassner, and Shie Mannor.
\newblock Optimizing the cvar via sampling.
\newblock {\em arXiv preprint arXiv:1404.3862}, 2014.

\bibitem{tamar2014scaling}
Aviv Tamar, Shie Mannor, and Huan Xu.
\newblock Scaling up robust mdps using function approximation.
\newblock In {\em ICML}, volume~32, page 2014, 2014.

\bibitem{todorov2012mujoco}
Emanuel Todorov, Tom Erez, and Yuval Tassa.
\newblock Mujoco: A physics engine for model-based control.
\newblock In {\em Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ
  International Conference on}, pages 5026--5033. IEEE, 2012.

\bibitem{wiesemann2013robust}
Wolfram Wiesemann, Daniel Kuhn, and Ber{\c{c}} Rustem.
\newblock Robust markov decision processes.
\newblock {\em Mathematics of Operations Research}, 38(1):153--183, 2013.

\end{thebibliography}
