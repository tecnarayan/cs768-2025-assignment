\begin{thebibliography}{42}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Behrmann et~al.(2018)Behrmann, Grathwohl, Chen, Duvenaud, and
  Jacobsen]{behrmann2018invertible}
Behrmann, J., Grathwohl, W., Chen, R.~T., Duvenaud, D., and Jacobsen, J.-H.
\newblock Invertible residual networks.
\newblock \emph{arXiv preprint arXiv:1811.00995}, 2018.

\bibitem[Blalock et~al.(2020)Blalock, Ortiz, Frankle, and
  Guttag]{blalock2020state}
Blalock, D., Ortiz, J. J.~G., Frankle, J., and Guttag, J.
\newblock What is the state of neural network pruning?
\newblock \emph{arXiv preprint arXiv:2003.03033}, 2020.

\bibitem[Bodmann(2013)]{Bodmann2013}
Bodmann, B.~G.
\newblock \emph{Frames as Codes}, pp.\  241--266.
\newblock Birkh{\"a}user Boston, Boston, 2013.
\newblock ISBN 978-0-8176-8373-3.
\newblock \doi{10.1007/978-0-8176-8373-3_7}.
\newblock URL \url{https://doi.org/10.1007/978-0-8176-8373-3_7}.

\bibitem[Cybenko(1989)]{cybenko1989approximation}
Cybenko, G.
\newblock Approximation by superpositions of a sigmoidal function.
\newblock \emph{Mathematics of control, signals and systems}, 2\penalty0
  (4):\penalty0 303--314, 1989.

\bibitem[Dalcin et~al.(2011)Dalcin, Paz, Kler, and Cosimo]{dalcin2011parallel}
Dalcin, L.~D., Paz, R.~R., Kler, P.~A., and Cosimo, A.
\newblock Parallel distributed computing using python.
\newblock \emph{Advances in Water Resources}, 34\penalty0 (9):\penalty0
  1124--1139, 2011.

\bibitem[Dean \& Barroso(2013)Dean and Barroso]{dean2013tail}
Dean, J. and Barroso, L.~A.
\newblock The tail at scale.
\newblock \emph{Communications of the ACM}, 56\penalty0 (2):\penalty0 74--80,
  2013.

\bibitem[Deng(2012)]{deng2012mnist}
Deng, L.
\newblock The mnist database of handwritten digit images for machine learning
  research.
\newblock \emph{IEEE Signal Processing Magazine}, 29\penalty0 (6):\penalty0
  141--142, 2012.

\bibitem[Dhakal et~al.(2019)Dhakal, Prakash, Yona, Talwar, and
  Himayat]{Dhakal_2019}
Dhakal, S., Prakash, S., Yona, Y., Talwar, S., and Himayat, N.
\newblock Coded federated learning.
\newblock \emph{2019 IEEE Globecom Workshops (GC Wkshps)}, Dec 2019.
\newblock \doi{10.1109/gcwkshps45667.2019.9024521}.
\newblock URL \url{http://dx.doi.org/10.1109/GCWkshps45667.2019.9024521}.

\bibitem[Engstrom et~al.(2019)Engstrom, Ilyas, Santurkar, Tsipras, Tran, and
  Madry]{engstrom2019adversarial}
Engstrom, L., Ilyas, A., Santurkar, S., Tsipras, D., Tran, B., and Madry, A.
\newblock Adversarial robustness as a prior for learned representations, 2019.

\bibitem[Goiri et~al.(2015)Goiri, Bianchini, Nagarakatte, and
  Nguyen]{goiri2015approxhadoop}
Goiri, I., Bianchini, R., Nagarakatte, S., and Nguyen, T.~D.
\newblock Approxhadoop: Bringing approximations to mapreduce frameworks.
\newblock In \emph{Proceedings of the Twentieth International Conference on
  Architectural Support for Programming Languages and Operating Systems}, pp.\
  383--397, 2015.

\bibitem[Han et~al.(2017)Han, Huang, Wang, and Zhan]{han2017clap}
Han, R., Huang, S., Wang, Z., and Zhan, J.
\newblock Clap: Component-level approximate processing for low tail latency and
  high result accuracy in cloud online services.
\newblock \emph{IEEE Transactions on Parallel and Distributed Systems},
  28\penalty0 (8):\penalty0 2190--2203, 2017.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[Hinton et~al.(2015)Hinton, Vinyals, and Dean]{hinton2015distilling}
Hinton, G., Vinyals, O., and Dean, J.
\newblock Distilling the knowledge in a neural network.
\newblock \emph{arXiv preprint arXiv:1503.02531}, 2015.

\bibitem[Howard(2019)]{imagenette}
Howard, J.
\newblock Imagenette dataset.
\newblock 2019.
\newblock URL \url{https://github.com/fastai/imagenette}.

\bibitem[Isola et~al.(2017)Isola, Zhu, Zhou, and Efros]{isola2017image}
Isola, P., Zhu, J.-Y., Zhou, T., and Efros, A.~A.
\newblock Image-to-image translation with conditional adversarial networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  1125--1134, 2017.

\bibitem[Jacobsen et~al.(2018)Jacobsen, Smeulders, and
  Oyallon]{jacobsen2018revnet}
Jacobsen, J.-H., Smeulders, A., and Oyallon, E.
\newblock i-revnet: Deep invertible networks.
\newblock \emph{arXiv preprint arXiv:1802.07088}, 2018.

\bibitem[Kendall et~al.(2018)Kendall, Gal, and Cipolla]{kendall2018multi}
Kendall, A., Gal, Y., and Cipolla, R.
\newblock Multi-task learning using uncertainty to weigh losses for scene
  geometry and semantics.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  7482--7491, 2018.

\bibitem[Kim et~al.(2020)Kim, Papamakarios, and Mnih]{kim2020lipschitz}
Kim, H., Papamakarios, G., and Mnih, A.
\newblock The lipschitz constant of self-attention, 2020.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kingma \& Dhariwal(2018)Kingma and Dhariwal]{kingma2018glow}
Kingma, D.~P. and Dhariwal, P.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock \emph{arXiv preprint arXiv:1807.03039}, 2018.

\bibitem[Kosaian et~al.(2018)Kosaian, Rashmi, and
  Venkataraman]{kosaian2018learning}
Kosaian, J., Rashmi, K., and Venkataraman, S.
\newblock Learning a code: Machine learning for approximate non-linear coded
  computation.
\newblock \emph{arXiv preprint arXiv:1806.01259}, 2018.

\bibitem[Kosaian et~al.(2019)Kosaian, Rashmi, and
  Venkataraman]{kosaian2019parity}
Kosaian, J., Rashmi, K., and Venkataraman, S.
\newblock Parity models: erasure-coded resilience for prediction serving
  systems.
\newblock In \emph{Proceedings of the 27th ACM Symposium on Operating Systems
  Principles}, pp.\  30--46, 2019.

\bibitem[Krizhevsky \& Hinton(2009)Krizhevsky and
  Hinton]{krizhevsky2009learning}
Krizhevsky, A. and Hinton, G.
\newblock Learning multiple layers of features from tiny images (technical
  report).
\newblock 2009.

\bibitem[Lee et~al.(2017)Lee, Lam, Pedarsani, Papailiopoulos, and
  Ramchandran]{lee2017speeding}
Lee, K., Lam, M., Pedarsani, R., Papailiopoulos, D., and Ramchandran, K.
\newblock Speeding up distributed machine learning using codes.
\newblock \emph{IEEE Transactions on Information Theory}, 64\penalty0
  (3):\penalty0 1514--1529, 2017.

\bibitem[Li et~al.(2016)Li, Maddah-Ali, and Avestimehr]{li2016unified}
Li, S., Maddah-Ali, M.~A., and Avestimehr, A.~S.
\newblock A unified coding framework for distributed computing with straggling
  servers.
\newblock In \emph{2016 IEEE Globecom Workshops (GC Wkshps)}, pp.\  1--6. IEEE,
  2016.

\bibitem[Liu et~al.(2015)Liu, Gao, He, Deng, Duh, and
  Wang]{liu2015representation}
Liu, X., Gao, J., He, X., Deng, L., Duh, K., and Wang, Y.-Y.
\newblock Representation learning using multi-task deep neural networks for
  semantic classification and information retrieval.
\newblock 2015.

\bibitem[Makhzani \& Frey(2017)Makhzani and Frey]{makhzani2017pixelgan}
Makhzani, A. and Frey, B.~J.
\newblock Pixelgan autoencoders.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1975--1985, 2017.

\bibitem[Mao et~al.(2017)Mao, Li, Xie, Lau, Wang, and
  Paul~Smolley]{mao2017least}
Mao, X., Li, Q., Xie, H., Lau, R.~Y., Wang, Z., and Paul~Smolley, S.
\newblock Least squares generative adversarial networks.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pp.\  2794--2802, 2017.

\bibitem[Marculescu et~al.(2018)Marculescu, Stamoulis, and
  Cai]{marculescu2018hardware}
Marculescu, D., Stamoulis, D., and Cai, E.
\newblock Hardware-aware machine learning: modeling and optimization.
\newblock In \emph{Proceedings of the International Conference on
  Computer-Aided Design}, pp.\  1--8, 2018.

\bibitem[Mirza \& Osindero(2014)Mirza and Osindero]{mirza2014conditional}
Mirza, M. and Osindero, S.
\newblock Conditional generative adversarial nets.
\newblock \emph{arXiv preprint arXiv:1411.1784}, 2014.

\bibitem[Narra et~al.(2019)Narra, Lin, Kiamari, Avestimehr, and
  Annavaram]{narra2019distributed}
Narra, K., Lin, Z., Kiamari, M., Avestimehr, S., and Annavaram, M.
\newblock Distributed matrix multiplication using speed adaptive coding.
\newblock \emph{arXiv preprint arXiv:1904.07098}, 2019.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and
  Brox]{ronneberger2015u}
Ronneberger, O., Fischer, P., and Brox, T.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In \emph{International Conference on Medical image computing and
  computer-assisted intervention}, pp.\  234--241. Springer, 2015.

\bibitem[Ruder(2017)]{ruder2017overview}
Ruder, S.
\newblock An overview of multi-task learning in deep neural networks.
\newblock \emph{arXiv preprint arXiv:1706.05098}, 2017.

\bibitem[Song et~al.(2019)Song, Meng, and Ermon]{song2019mintnet}
Song, Y., Meng, C., and Ermon, S.
\newblock Mintnet: Building invertible neural networks with masked
  convolutions.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  11004--11014, 2019.

\bibitem[Suresh et~al.(2015)Suresh, Canini, Schmid, and Feldmann]{suresh2015c3}
Suresh, L., Canini, M., Schmid, S., and Feldmann, A.
\newblock C3: Cutting tail latency in cloud data stores via adaptive replica
  selection.
\newblock In \emph{12th $\{$USENIX$\}$ Symposium on Networked Systems Design
  and Implementation ($\{$NSDI$\}$ 15)}, pp.\  513--527, 2015.

\bibitem[Tandon et~al.(2017)Tandon, Lei, Dimakis, and
  Karampatziakis]{tandon2017gradient}
Tandon, R., Lei, Q., Dimakis, A.~G., and Karampatziakis, N.
\newblock Gradient coding: Avoiding stragglers in distributed learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  3368--3376. PMLR, 2017.

\bibitem[Verma et~al.(2018)Verma, Lamb, Beckham, Najafi, Mitliagkas, Courville,
  Lopez-Paz, and Bengio]{verma2018manifold}
Verma, V., Lamb, A., Beckham, C., Najafi, A., Mitliagkas, I., Courville, A.,
  Lopez-Paz, D., and Bengio, Y.
\newblock Manifold mixup: Better representations by interpolating hidden
  states.
\newblock \emph{arXiv preprint arXiv:1806.05236}, 2018.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{xiao2017/online}
Xiao, H., Rasul, K., and Vollgraf, R.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms, 2017.

\bibitem[Yu et~al.(2019)Yu, Li, Raviv, Kalan, Soltanolkotabi, and
  Avestimehr]{pmlr-v89-yu19b}
Yu, Q., Li, S., Raviv, N., Kalan, S. M.~M., Soltanolkotabi, M., and Avestimehr,
  S.~A.
\newblock Lagrange coded computing: Optimal design for resiliency, security,
  and privacy.
\newblock volume~89 of \emph{Proceedings of Machine Learning Research}, pp.\
  1215--1225. PMLR, 16--18 Apr 2019.
\newblock URL \url{http://proceedings.mlr.press/v89/yu19b.html}.

\bibitem[Zaharia et~al.(2008)Zaharia, Konwinski, Joseph, Katz, and
  Stoica]{zaharia2008improving}
Zaharia, M., Konwinski, A., Joseph, A.~D., Katz, R.~H., and Stoica, I.
\newblock Improving mapreduce performance in heterogeneous environments.
\newblock In \emph{OSDI}, 2008.

\bibitem[Zhang et~al.(2019)Zhang, Patras, and Haddadi]{zhang2019deep}
Zhang, C., Patras, P., and Haddadi, H.
\newblock Deep learning in mobile and wireless networking: A survey.
\newblock \emph{IEEE Communications Surveys \& Tutorials}, 21\penalty0
  (3):\penalty0 2224--2287, 2019.

\bibitem[Zhang et~al.(2017)Zhang, Cisse, Dauphin, and
  Lopez-Paz]{zhang2017mixup}
Zhang, H., Cisse, M., Dauphin, Y.~N., and Lopez-Paz, D.
\newblock mixup: Beyond empirical risk minimization.
\newblock \emph{arXiv preprint arXiv:1710.09412}, 2017.

\end{thebibliography}
