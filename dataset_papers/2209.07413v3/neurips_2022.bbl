\begin{thebibliography}{30}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abdelfattah et~al.(2021)Abdelfattah, Mehrotra, Łukasz Dudziak, and
  Lane]{abdelfattah2021zerocost}
Mohamed~S. Abdelfattah, Abhinav Mehrotra, Łukasz Dudziak, and Nicholas~D.
  Lane.
\newblock Zero-cost proxies for lightweight nas, 2021.

\bibitem[Akhauri et~al.(2021)Akhauri, Niranjan, Munoz, Banerjee, Davare,
  Cocchini, Sorokin, Iyer, and Jain]{akhauri2021rhnas}
Yash Akhauri, Adithya Niranjan, J.~Pablo Munoz, Suvadeep Banerjee, Abhijit
  Davare, Pasquale Cocchini, Anton~A. Sorokin, Ravi Iyer, and Nilesh Jain.
\newblock Rhnas: Realizable hardware and neural architecture search, 2021.

\bibitem[Cai et~al.(2019)Cai, Zhu, and Han]{cai2019proxylessnas}
Han Cai, Ligeng Zhu, and Song Han.
\newblock Proxylessnas: Direct neural architecture search on target task and
  hardware, 2019.

\bibitem[Cai et~al.(2020)Cai, Gan, Wang, Zhang, and Han]{cai2020onceforall}
Han Cai, Chuang Gan, Tianzhe Wang, Zhekai Zhang, and Song Han.
\newblock Once-for-all: Train one network and specialize it for efficient
  deployment, 2020.

\bibitem[Chen et~al.(2021)Chen, Gong, and Wang]{chen2021neural}
Wuyang Chen, Xinyu Gong, and Zhangyang Wang.
\newblock Neural architecture search on imagenet in four gpu hours: A
  theoretically inspired perspective, 2021.

\bibitem[Choi et~al.(2021)Choi, Hong, Yoon, Yu, Kim, and Lee]{choi2021dance}
Kanghyun Choi, Deokki Hong, Hojae Yoon, Joonsang Yu, Youngsok Kim, and Jinho
  Lee.
\newblock Dance: Differentiable accelerator/network co-exploration, 2021.

\bibitem[Dong and Yang(2020)]{dong2020nasbench201}
Xuanyi Dong and Yi~Yang.
\newblock Nas-bench-201: Extending the scope of reproducible neural
  architecture search, 2020.

\bibitem[Dong et~al.(2021)Dong, Liu, Musial, and Gabrys]{Dong_2021}
Xuanyi Dong, Lu~Liu, Katarzyna Musial, and Bogdan Gabrys.
\newblock {NATS}-bench: Benchmarking {NAS} algorithms for architecture topology
  and size.
\newblock \emph{{IEEE} Transactions on Pattern Analysis and Machine
  Intelligence}, pages 1--1, 2021.
\newblock \doi{10.1109/tpami.2021.3054824}.
\newblock URL \url{https://doi.org/10.11092Ftpami.2021.3054824}.

\bibitem[Fortin et~al.(2012)Fortin, {De Rainville}, Gardner, Parizeau, and
  Gagn\'e]{DEAP_JMLR2012}
F\'elix-Antoine Fortin, Fran\c{c}ois-Michel {De Rainville}, Marc-Andr\'e
  Gardner, Marc Parizeau, and Christian Gagn\'e.
\newblock {DEAP}: Evolutionary algorithms made easy.
\newblock \emph{Journal of Machine Learning Research}, 13:\penalty0 2171--2175,
  jul 2012.

\bibitem[Hu et~al.(2020)Hu, Xie, Zheng, Liu, Shi, Liu, and Lin]{hu2020dsnas}
Shoukang Hu, Sirui Xie, Hehui Zheng, Chunxiao Liu, Jianping Shi, Xunying Liu,
  and Dahua Lin.
\newblock Dsnas: Direct neural architecture search without parameter
  retraining, 2020.

\bibitem[Lannelongue et~al.(2020)Lannelongue, Grealey, and
  Inouye]{lannelongue2020green}
Loïc Lannelongue, Jason Grealey, and Michael Inouye.
\newblock Green algorithms: Quantifying the carbon footprint of computation,
  2020.

\bibitem[Liu et~al.(2018)Liu, Zoph, Neumann, Shlens, Hua, Li, Fei-Fei, Yuille,
  Huang, and Murphy]{liu2018progressive}
Chenxi Liu, Barret Zoph, Maxim Neumann, Jonathon Shlens, Wei Hua, Li-Jia Li,
  Li~Fei-Fei, Alan Yuille, Jonathan Huang, and Kevin Murphy.
\newblock Progressive neural architecture search, 2018.

\bibitem[Liu et~al.(2019)Liu, Simonyan, and Yang]{liu2019darts}
Hanxiao Liu, Karen Simonyan, and Yiming Yang.
\newblock Darts: Differentiable architecture search, 2019.

\bibitem[Luo et~al.(2019)Luo, Tian, Qin, Chen, and Liu]{luo2019neural}
Renqian Luo, Fei Tian, Tao Qin, Enhong Chen, and Tie-Yan Liu.
\newblock Neural architecture optimization, 2019.

\bibitem[Mellor et~al.(2021)Mellor, Turner, Storkey, and
  Crowley]{mellor2021neural}
Joseph Mellor, Jack Turner, Amos Storkey, and Elliot~J. Crowley.
\newblock Neural architecture search without training, 2021.

\bibitem[Mu{\~{n}}oz et~al.(2021)Mu{\~{n}}oz, Lyalyushkin, Akhauri, Senina,
  Kozlov, and Jain]{bootstrapNAS}
J.~Pablo Mu{\~{n}}oz, Nikolay Lyalyushkin, Yash Akhauri, Anastasia Senina,
  Alexander Kozlov, and Nilesh Jain.
\newblock Enabling {NAS} with automated super-network generation.
\newblock \emph{CoRR}, abs/2112.10878, 2021.
\newblock URL \url{https://arxiv.org/abs/2112.10878}.

\bibitem[Parisotto et~al.(2017)Parisotto, Mohamed, Singh, Li, Zhou, and
  Kohli]{parisotto2017neuro-symbolic}
Emilio Parisotto, Abdelrahman Mohamed, Rishabh Singh, Lihong Li, Denny Zhou,
  and Pushmeet Kohli.
\newblock Neuro-symbolic program synthesis.
\newblock In \emph{5th International Conference on Learning Representations
  (ICLR 2017)}, February 2017.
\newblock URL
  \url{https://www.microsoft.com/en-us/research/publication/neuro-symbolic-program-synthesis-2/}.

\bibitem[Pham et~al.(2018)Pham, Guan, Zoph, Le, and Dean]{pham2018efficient}
Hieu Pham, Melody~Y. Guan, Barret Zoph, Quoc~V. Le, and Jeff Dean.
\newblock Efficient neural architecture search via parameter sharing, 2018.

\bibitem[Radosavovic et~al.(2019)Radosavovic, Johnson, Xie, Lo, and
  Dollár]{radosavovic2019network}
Ilija Radosavovic, Justin Johnson, Saining Xie, Wan-Yen Lo, and Piotr Dollár.
\newblock On network design spaces for visual recognition, 2019.

\bibitem[Real et~al.(2019)Real, Aggarwal, Huang, and Le]{real2019regularized}
Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc~V Le.
\newblock Regularized evolution for image classifier architecture search, 2019.

\bibitem[Real et~al.(2020)Real, Liang, So, and Le]{real2020automlzero}
Esteban Real, Chen Liang, David~R. So, and Quoc~V. Le.
\newblock Automl-zero: Evolving machine learning algorithms from scratch, 2020.

\bibitem[Tan et~al.(2019)Tan, Chen, Pang, Vasudevan, Sandler, Howard, and
  Le]{tan2019mnasnet}
Mingxing Tan, Bo~Chen, Ruoming Pang, Vijay Vasudevan, Mark Sandler, Andrew
  Howard, and Quoc~V. Le.
\newblock Mnasnet: Platform-aware neural architecture search for mobile, 2019.

\bibitem[White et~al.(2021)White, Neiswanger, Nolen, and
  Savani]{white2021study}
Colin White, Willie Neiswanger, Sam Nolen, and Yash Savani.
\newblock A study on encodings for neural architecture search, 2021.

\bibitem[Xiang et~al.(2021)Xiang, Łukasz Dudziak, Abdelfattah, Chau, Lane, and
  Wen]{xiang2021zerocost}
Lichuan Xiang, Łukasz Dudziak, Mohamed~S. Abdelfattah, Thomas Chau,
  Nicholas~D. Lane, and Hongkai Wen.
\newblock Zero-cost proxies meet differentiable architecture search, 2021.

\bibitem[Xie et~al.(2020)Xie, Zheng, Liu, and Lin]{xie2020snas}
Sirui Xie, Hehui Zheng, Chunxiao Liu, and Liang Lin.
\newblock Snas: Stochastic neural architecture search, 2020.

\bibitem[Yang et~al.(2020)Yang, Wang, Chen, Shi, Xu, Xu, Tian, and
  Xu]{yang2020cars}
Zhaohui Yang, Yunhe Wang, Xinghao Chen, Boxin Shi, Chao Xu, Chunjing Xu,
  Qi~Tian, and Chang Xu.
\newblock Cars: Continuous evolution for efficient neural architecture search,
  2020.

\bibitem[Zhang et~al.(2020)Zhang, Fu, Jiang, Li, You, Li, Chandra, and
  Lin]{zhang2020dna}
Yongan Zhang, Yonggan Fu, Weiwen Jiang, Chaojian Li, Haoran You, Meng Li, Vikas
  Chandra, and Yingyan Lin.
\newblock Dna: Differentiable network-accelerator co-search, 2020.

\bibitem[Zhang and Jia(2021)]{https://doi.org/10.48550/arxiv.2110.08616}
Zhihao Zhang and Zhihao Jia.
\newblock Gradsign: Model performance inference with theoretical insights.
\newblock 2021.
\newblock \doi{10.48550/ARXIV.2110.08616}.
\newblock URL \url{https://arxiv.org/abs/2110.08616}.

\bibitem[Zhou et~al.(2020)Zhou, Zhou, Zhang, Loy, Yi, Zhang, and
  Ouyang]{zhou2020econas}
Dongzhan Zhou, Xinchi Zhou, Wenwei Zhang, Chen~Change Loy, Shuai Yi, Xuesen
  Zhang, and Wanli Ouyang.
\newblock Econas: Finding proxies for economical neural architecture search,
  2020.

\bibitem[Zoph et~al.(2018)Zoph, Vasudevan, Shlens, and Le]{zoph2018learning}
Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc~V. Le.
\newblock Learning transferable architectures for scalable image recognition,
  2018.

\end{thebibliography}
