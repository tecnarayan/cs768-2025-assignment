@inproceedings{zhi1,
  title={Semantics Disentangling for Generalized Zero-Shot Learning},
  author={Chen, Zhi and Luo, Yadan and Qiu, Ruihong and Wang, Sen and Huang, Zi and Li, Jingjing and Zhang, Zheng},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{zhi2,
  title={Rethinking Generative Zero-Shot Learning: An Ensemble Learning Perspective for Recognising Visual Patches},
  author={Chen, Zhi and Wang, Sen and Li, Jingjing and Huang, Zi},
  booktitle={ACM MM},
  pages={3413--3421},
  year={2020}
}

@inproceedings{alexnet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={NeurIPS},
  pages={1097--1105},
  year={2012}
}

@inproceedings{inception,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={CVPR},
  pages={1--9},
  year={2015}
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  pages={770--778},
  year={2016}
}

@article{convnext,
  title={A ConvNet for the 2020s},
  author={Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
  journal={arXiv preprint arXiv:2201.03545},
  year={2022}
}


@article{mobilenets,
  title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
  author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  journal={arXiv preprint arXiv:1704.04861},
  year={2017}
}

@article{kd,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@article{fitnets,
  title={Fitnets: Hints for thin deep nets},
  author={Romero, Adriana and Ballas, Nicolas and Kahou, Samira Ebrahimi and Chassang, Antoine and Gatta, Carlo and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.6550},
  year={2014}
}

@inproceedings{sp,
  title={Similarity-preserving knowledge distillation},
  author={Tung, Frederick and Mori, Greg},
  booktitle={ICCV},
  pages={1365--1374},
  year={2019}
}

@article{kdsurvey,
  title={Knowledge distillation: A survey},
  author={Gou, Jianping and Yu, Baosheng and Maybank, Stephen J and Tao, Dacheng},
  journal={IJCV},
  volume={129},
  number={6},
  pages={1789--1819},
  year={2021},
}

@inproceedings{crd,
  title={Contrastive Representation Distillation},
  author={Yonglong Tian and Dilip Krishnan and Phillip Isola},
  booktitle={ICLR},
  year={2020}
}

@inproceedings{cid,
  title={Comprehensive Knowledge Distillation with Causal Intervention},
  author={Deng, Xiang and Zhang, Zhongfei},
  booktitle={NeurIPS},
  year={2021}
}

@inproceedings{pad,
  title={Prime-aware adaptive distillation},
  author={Zhang, Youcai and Lan, Zhonghao and Dai, Yuchen and Zeng, Fangao and Bai, Yan and Chang, Jie and Wei, Yichen},
  booktitle={ECCV},
  pages={658--674},
  year={2020},
}

@inproceedings{srrl, 
  title={Knowledge distillation via softmax regression representation learning},
  author={Jing Yang and Brais Martinez and Adrian Bulat and Georgios Tzimiropoulos},
  booktitle={ICLR},
  year={2021}  
}

@inproceedings{kr,
  title={Distilling Knowledge via Knowledge Review},
  author={Chen, Pengguang and Liu, Shu and Zhao, Hengshuang and Jia, Jiaya},
  booktitle={CVPR},
  pages={5008--5017},
  year={2021}
}

@inproceedings{afd,
  title={Show, Attend and Distill: Knowledge Distillation via Attention-based Feature Matching},
  author={Ji, Mingi and Heo, Byeongho and Park, Sungrae},
  booktitle={AAAI},
  pages={7945--7952},
  year={2021}
}

@inproceedings{semckd,
  title={Cross-layer distillation with semantic calibration},
  author={Chen, Defang and Mei, Jian-Ping and Zhang, Yuan and Wang, Can and Wang, Zhe and Feng, Yan and Chen, Chun},
  booktitle={AAAI},
  pages={7028--7036},
  year={2021}
}

@inproceedings{dml,
  title={Deep mutual learning},
  author={Zhang, Ying and Xiang, Tao and Hospedales, Timothy M and Lu, Huchuan},
  booktitle={CVPR},
  pages={4320--4328},
  year={2018}
}

@inproceedings{takd,
  title={Improved knowledge distillation via teacher assistant},
  author={Mirzadeh, Seyed Iman and Farajtabar, Mehrdad and Li, Ang and Levine, Nir and Matsukawa, Akihiro and Ghasemzadeh, Hassan},
  booktitle={AAAI},
  pages={5191--5198},
  year={2020}
}

@inproceedings{cc,
  title={Correlation congruence for knowledge distillation},
  author={Peng, Baoyun and Jin, Xiao and Liu, Jiaheng and Li, Dongsheng and Wu, Yichao and Liu, Yu and Zhou, Shunfeng and Zhang, Zhaoning},
  booktitle={ICCV},
  pages={5007--5016},
  year={2019}
}

@inproceedings{ft,
  title={Paraphrasing complex network: Network compression via factor transfer},
  author={Kim, Jangho and Park, SeongUk and Kwak, Nojun},
  booktitle={NeurIPS},
  year={2018}
}

@inproceedings{ofd,
  title={A comprehensive overhaul of feature distillation},
  author={Heo, Byeongho and Kim, Jeesoo and Yun, Sangdoo and Park, Hyojin and Kwak, Nojun and Choi, Jin Young},
  booktitle={ICCV},
  pages={1921--1930},
  year={2019}
}

@inproceedings{da1,
  title={Exploring simple siamese representation learning},
  author={Chen, Xinlei and He, Kaiming},
  booktitle={CVPR},
  pages={15750--15758},
  year={2021}
}

@inproceedings{da2,
  title={Bootstrap your own latent-a new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others},
  booktitle={NeurIPS},
  pages={21271--21284},
  year={2020}
}

@article{ensemblepaper,
  title={Wisdom of Committees: An Overlooked Approach To Faster and More Accurate Models},
  author={Wang, Xiaofang and Kondratyuk, Dan and Christiansen, Eric and Kitani, Kris M and Alon, Yair and Eban, Elad},
  journal={arXiv preprint arXiv:2012.01988},
  year={2020}
}

@article{ensemblepaper2,
  title={Ensembling neural networks: many could be better than all},
  author={Zhou, Zhi-Hua and Wu, Jianxin and Tang, Wei},
  journal={Artificial intelligence},
  volume={137},
  number={1-2},
  pages={239--263},
  year={2002},
  publisher={Elsevier}
}

@inproceedings{rkd,
  title={Relational knowledge distillation},
  author={Park, Wonpyo and Kim, Dongju and Lu, Yan and Cho, Minsu},
  booktitle={CVPR},
  pages={3967--3976},
  year={2019}
}

@article{cifar100,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  journal={Technical report},
  publisher={Citeseer}
}

@article{imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={IJCV},
  volume={115},
  number={3},
  pages={211--252},
  year={2015},
  publisher={Springer}
}

@inproceedings{densenet,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={CVPR},
  pages={4700--4708},
  year={2017}
}

@article{wrn,
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1605.07146},
  year={2016}
}

@article{vgg,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@inproceedings{mobilenetsv2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={CVPR},
  pages={4510--4520},
  year={2018}
}

@inproceedings{densetakd,
  title={Densely guided knowledge distillation using multiple teacher assistants},
  author={Son, Wonchul and Na, Jaemin and Choi, Junyong and Hwang, Wonjun},
  booktitle={ICCV},
  pages={9395--9404},
  year={2021}
}

@article{gelu,
  title={Gaussian error linear units (gelus)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@article{bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{vit,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{patient,
  title={Knowledge distillation: A good teacher is patient and consistent},
  author={Beyer, Lucas and Zhai, Xiaohua and Royer, Am{\'e}lie and Markeeva, Larisa and Anil, Rohan and Kolesnikov, Alexander},
  journal={arXiv preprint arXiv:2106.05237},
  year={2021}
}

@article{mealv2,
  title={Meal v2: Boosting vanilla resnet-50 to 80\%+ top-1 accuracy on imagenet without tricks},
  author={Shen, Zhiqiang and Savvides, Marios},
  journal={arXiv preprint arXiv:2009.08453},
  year={2020}
}












@inproceedings{shufflenet,
  title={Shufflenet: An extremely efficient convolutional neural network for mobile devices},
  author={Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
  booktitle={CVPR},
  pages={6848--6856},
  year={2018}
}


@inproceedings{fsp,
  title={A gift from knowledge distillation: Fast optimization, network minimization and transfer learning},
  author={Yim, Junho and Joo, Donggyu and Bae, Jihoon and Kim, Junmo},
  booktitle={CVPR},
  pages={4133--4141},
  year={2017}
}

@article{krw1,
  title={Knowledge distillation and student-teacher learning for visual intelligence: A review and new outlooks},
  author={Wang, Lin and Yoon, Kuk-Jin},
  journal={TPAMI},
  year={2021},
  publisher={IEEE}
}

@article{krw2,
  title={Knowledge distillation: A survey},
  author={Gou, Jianping and Yu, Baosheng and Maybank, Stephen J and Tao, Dacheng},
  journal={IJCV},
  volume={129},
  number={6},
  pages={1789--1819},
  year={2021},
  publisher={Springer}
}



@inproceedings{onlinekd,
  title={Knowledge Distillation by On-the-Fly Native Ensemble},
  author={Lan, Xu and Zhu, Xiatian and Gong, Shaogang},
  booktitle={NeurIPS},
  pages={7527--7537},
  year={2018}
}

@inproceedings{onlinekd2,
  title={Online knowledge distillation via collaborative learning},
  author={Guo, Qiushan and Wang, Xinjiang and Wu, Yichao and Yu, Zhipeng and Liang, Ding and Hu, Xiaolin and Luo, Ping},
  booktitle={CVPR},
  pages={11020--11029},
  year={2020}
}

@inproceedings{onlinekd3,
  title={Peer collaborative learning for online knowledge distillation},
  author={Wu, Guile and Gong, Shaogang},
  booktitle={AAAI},
  year={2021}
}

@article{sikd,
  title={Knowledge Distillation as Semiparametric Inference},
  author={Dao, Tri and Kamath, Govinda M and Syrgkanis, Vasilis and Mackey, Lester},
  journal={arXiv preprint arXiv:2104.09732},
  year={2021}
}

@inproceedings{searchkd,
  title={Search to distill: Pearls are everywhere but not the eyes},
  author={Liu, Yu and Jia, Xuhui and Tan, Mingxing and Vemulapalli, Raviteja and Zhu, Yukun and Green, Bradley and Wang, Xiaogang},
  booktitle={CVPR},
  pages={7539--7548},
  year={2020}
}

@inproceedings{nas,
  title={Neural architecture search with reinforcement learning},
  author={Zoph, Barret and Le, Quoc V},
  booktitle={ICLR},
  year={2017}
}

@inproceedings{at,
  title={Paying more attention to attention: improving the performance of convolutional neural networks via attention transfer},
  author={Komodakis, Nikos and Zagoruyko, Sergey},
  booktitle={ICLR},
  year={2017}
}


@inproceedings{attention1,
  title={Show, attend and tell: Neural image caption generation with visual attention},
  author={Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhudinov, Ruslan and Zemel, Rich and Bengio, Yoshua},
  booktitle={ICML},
  pages={2048--2057},
  year={2015},
}

@inproceedings{attention2,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={NeurIPS},
  pages={5998--6008},
  year={2017}
}





@article{manifoldkd,
  title={Learning student networks via feature embedding},
  author={Chen, Hanting and Wang, Yunhe and Xu, Chang and Xu, Chao and Tao, Dacheng},
  journal={TNNLS},
  volume={32},
  number={1},
  pages={25--35},
  year={2020},
  publisher={IEEE}
}

@inproceedings{irg,
  title={Knowledge distillation via instance relationship graph},
  author={Liu, Yufan and Cao, Jiajiong and Li, Bing and Yuan, Chunfeng and Hu, Weiming and Li, Yangxi and Duan, Yunqiang},
  booktitle={CVPR},
  pages={7096--7104},
  year={2019}
}

@inproceedings{lcsp,
  title={Local correlation consistency for knowledge distillation},
  author={Li, Xiaojie and Wu, Jianlong and Fang, Hongyu and Liao, Yue and Wang, Fei and Qian, Chen},
  booktitle={ECCV},
  pages={18--33},
  year={2020},
  organization={Springer}
}

@article{gkd1,
  title={Graph-based knowledge distillation by multi-head attention network},
  author={Lee, Seunghyun and Song, Byung Cheol},
  journal={arXiv preprint arXiv:1907.02226},
  year={2019}
}

@inproceedings{gkd2,
  title={Inter-region affinity distillation for road marking segmentation},
  author={Hou, Yuenan and Ma, Zheng and Liu, Chunxiao and Hui, Tak-Wai and Loy, Chen Change},
  booktitle={CVPR},
  pages={12486--12495},
  year={2020}
}

@article{gkd3,
  title={Structured knowledge distillation for dense prediction},
  author={Liu, Yifan and Shu, Changyong and Wang, Jingdong and Shen, Chunhua},
  journal={TPAMI},
  year={2020},
  publisher={IEEE}
}


@inproceedings{repvgg,
  title={Repvgg: Making vgg-style convnets great again},
  author={Ding, Xiaohan and Zhang, Xiangyu and Ma, Ningning and Han, Jungong and Ding, Guiguang and Sun, Jian},
  booktitle={CVPR},
  pages={13733--13742},
  year={2021}
}




@article{tSNE,
  author = {Maaten, Laurens and Hinton, Geoffrey},
  journal = {JMLR},
  pages = {2579--2605},
  title = {Visualizing Data using {t-SNE} },
  volume = 9,
  year = 2008,
}

@ARTICLE{free,
  author={Wolpert, D.H. and Macready, W.G.},
  journal={IEEE Trans. Evol. Comput.}, 
  title={No free lunch theorems for optimization}, 
  year={1997},
  volume={1},
  number={1},
  pages={67-82},}
  
@inproceedings{kaimingini,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={ICCV},
  pages={1026--1034},
  year={2015}
}

@article{cub200,
  title={The caltech-ucsd birds-200-2011 dataset},
  author={Wah, Catherine and Branson, Steve and Welinder, Peter and Perona, Pietro and Belongie, Serge},
  year={2011},
  journal={Technical Report CNS-TR-2011-001},
  publisher={California Institute of Technology}
}

@inproceedings{car196,
  title={3d object representations for fine-grained categorization},
  author={Krause, Jonathan and Stark, Michael and Deng, Jia and Fei-Fei, Li},
  booktitle={ICCVW},
  pages={554--561},
  year={2013}
}