\ifdefined\DeclarePrefChars\DeclarePrefChars{'’-}\else\fi
\begin{thebibliography}{50}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aas et~al.(2021)Aas, Jullum, and
  Løland]{aasExplainingIndividualPredictions2020}
Aas, K., Jullum, M., and Løland, A.
\newblock Explaining individual predictions when features are dependent: More
  accurate approximations to shapley values.
\newblock \emph{Artificial Intelligence}, 298:\penalty0 103502, 2021.

\bibitem[Adebayo et~al.(2018)Adebayo, Gilmer, Muelly, Goodfellow, Hardt, and
  Kim]{adebayoSanityChecksSaliency2018}
Adebayo, J., Gilmer, J., Muelly, M., Goodfellow, I., Hardt, M., and Kim, B.
\newblock Sanity checks for saliency maps.
\newblock In \emph{Proceedings of the 32nd {{International Conference}} on
  {{Neural Information Processing Systems}}}, {{NIPS}}'18, pp.\  9525--9536.
  {Curran Associates Inc.}, 2018.

\bibitem[Agarwal et~al.(2022)Agarwal, Krishna, Saxena, Pawelczyk, Johnson,
  Puri, Zitnik, and Lakkaraju]{agarwal2022openxai}
Agarwal, C., Krishna, S., Saxena, E., Pawelczyk, M., Johnson, N., Puri, I.,
  Zitnik, M., and Lakkaraju, H.
\newblock Open{XAI}: Towards a transparent evaluation of model explanations.
\newblock In \emph{Thirty-sixth Conference on Neural Information Processing
  Systems Datasets and Benchmarks Track}, 2022.

\bibitem[Alvarez-Melis \& Jaakkola(2018)Alvarez-Melis and
  Jaakkola]{alvarez-melisRobustnessInterpretabilityMethods2018}
Alvarez-Melis, D. and Jaakkola, T.~S.
\newblock On the {{Robustness}} of {{Interpretability Methods}}.
\newblock 2018.

\bibitem[Apley \& Zhu(2020)Apley and Zhu]{apleyVisualizingEffectsPredictor2019}
Apley, D.~W. and Zhu, J.
\newblock {Visualizing the effects of predictor variables in black box
  supervised learning models}.
\newblock \emph{Journal of the Royal Statistical Society Series B}, 82\penalty0
  (4):\penalty0 1059--1086, September 2020.

\bibitem[{Arrieta} et~al.(2020){Arrieta}, Díaz-Rodríguez, {Del Ser},
  Bennetot, Tabik, Barbado, Garcia, Gil-Lopez, Molina, Benjamins, Chatila, and
  Herrera]{arrietaExplainableArtificialIntelligence2019}
{Arrieta}, A., Díaz-Rodríguez, N., {Del Ser}, J., Bennetot, A., Tabik, S.,
  Barbado, A., Garcia, S., Gil-Lopez, S., Molina, D., Benjamins, R., Chatila,
  R., and Herrera, F.
\newblock Explainable artificial intelligence (xai): Concepts, taxonomies,
  opportunities and challenges toward responsible ai.
\newblock \emph{Information Fusion}, 58:\penalty0 82--115, 2020.

\bibitem[Bach et~al.(2015)Bach, Binder, Montavon, Klauschen, Müller, and
  Samek]{bachPixelWiseExplanationsNonLinear2015}
Bach, S., Binder, A., Montavon, G., Klauschen, F., Müller, K.-R., and Samek,
  W.
\newblock On pixel-wise explanations for non-linear classifier decisions by
  layer-wise relevance propagation.
\newblock \emph{PLOS ONE}, 10\penalty0 (7):\penalty0 1--46, 07 2015.

\bibitem[Baehrens et~al.(2010)Baehrens, Schroeter, Harmeling, Kawanabe, Hansen,
  and M\"{u}ller]{baehrensHowExplainIndividual2010}
Baehrens, D., Schroeter, T., Harmeling, S., Kawanabe, M., Hansen, K., and
  M\"{u}ller, K.-R.
\newblock How to explain individual classification decisions.
\newblock \emph{J. Mach. Learn. Res.}, 11:\penalty0 1803–1831, aug 2010.

\bibitem[Binder et~al.(2016)Binder, Bach, Montavon, Müller, and
  Samek]{binderLayerWiseRelevancePropagation2016}
Binder, A., Bach, S., Montavon, G., Müller, K.-R., and Samek, W.
\newblock Layer-{{Wise Relevance Propagation}} for {{Deep Neural Network
  Architectures}}.
\newblock In Kim, K.~J. and Joukov, N. (eds.), \emph{Information {{Science}}
  and {{Applications}} ({{ICISA}}) 2016}, Lecture {{Notes}} in {{Electrical
  Engineering}}, pp.\  913--922. {Springer}, 2016.

\bibitem[Breiman(2001)]{breimanRandomForests2001}
Breiman, L.
\newblock Random {{Forests}}.
\newblock \emph{Machine Learning}, 45\penalty0 (1):\penalty0 5--32, 2001.

\bibitem[Conger(1974)]{congerRevisedDefinitionSuppressor1974}
Conger, A.~J.
\newblock A {{Revised Definition}} for {{Suppressor Variables}}: A {{Guide To
  Their Identification}} and {{Interpretation}} , {{A Revised Definition}} for
  {{Suppressor Variables}}: A {{Guide To Their Identification}} and
  {{Interpretation}}.
\newblock \emph{Educational and Psychological Measurement}, 34\penalty0
  (1):\penalty0 35--46, 1974.

\bibitem[Doshi-Velez \& Kim(2017)Doshi-Velez and
  Kim]{doshi-velezRigorousScienceInterpretable2017}
Doshi-Velez, F. and Kim, B.
\newblock Towards {{A Rigorous Science}} of {{Interpretable Machine Learning}}.
\newblock \emph{arXiv preprint arXiv:1702.08608}, 2017.

\bibitem[Fisher et~al.(2019)Fisher, Rudin, and
  Dominici]{fisherAllModelsAre2019}
Fisher, A., Rudin, C., and Dominici, F.
\newblock All {{Models}} are {{Wrong}}, but {{Many}} are {{Useful}}:
  {{Learning}} a {{Variable}}'s {{Importance}} by {{Studying}} an {{Entire
  Class}} of {{Prediction Models Simultaneously}}.
\newblock \emph{Journal of Machine Learning Research}, 20\penalty0
  (177):\penalty0 1--81, 2019.

\bibitem[Friedman(2004)]{friedmanPathsConsistencyAdditive2004}
Friedman, E.~J.
\newblock Paths and consistency in additive cost sharing.
\newblock \emph{International Journal of Games Theory}, 32\penalty0 (4), 2004.

\bibitem[Friedman(2001)]{friedmanGreedyFunctionApproximation2001}
Friedman, J.~H.
\newblock Greedy {{Function Approximation}}: {{A Gradient Boosting Machine}}.
\newblock \emph{The Annals of Statistics}, 29\penalty0 (5):\penalty0
  1189--1232, 2001.

\bibitem[Friedman \& Wall(2005)Friedman and
  Wall]{friedmanGraphicalViewsSuppression2005}
Friedman, L. and Wall, M.
\newblock Graphical {{Views}} of {{Suppression}} and {{Multicollinearity}} in
  {{Multiple Linear Regression}}.
\newblock \emph{The American Statistician}, 59\penalty0 (2):\penalty0 127--136,
  2005.

\bibitem[Garreau \& von Luxburg(2020)Garreau and von
  Luxburg]{garreauExplainingExplainerFirst2020}
Garreau, D. and von Luxburg, U.
\newblock Explaining the explainer: A first theoretical analysis of lime.
\newblock In \emph{Proceedings of the 23rd International Conference on
  Artificial Intelligence and Statistics (AISTATS)}, volume 108 of
  \emph{Proceedings of Machine Learning Research}, pp.\  1287--1296. PMLR,
  August 2020.

\bibitem[Gevrey et~al.(2003)Gevrey, Dimopoulos, and
  Lek]{gevrey2003reviewVariableContr}
Gevrey, M., Dimopoulos, I., and Lek, S.
\newblock Review and comparison of methods to study the contribution of
  variables in artificial neural network models.
\newblock \emph{Ecological Modelling}, 160\penalty0 (3):\penalty0 249--264,
  2003.

\bibitem[Grömping(2020)]{grompingModelagnosticEffectsPlots2020}
Grömping, U.
\newblock Model-agnostic effects plots for interpreting machine learning
  models.
\newblock \emph{Reports in Mathematics, Physics and Chemistry}, \penalty0
  (1/2020), 2020.

\bibitem[Haufe et~al.(2014)Haufe, Meinecke, Görgen, Dähne, Haynes, Blankertz,
  and Bießmann]{haufeInterpretationWeightVectors2014}
Haufe, S., Meinecke, F., Görgen, K., Dähne, S., Haynes, J.-D., Blankertz, B.,
  and Bießmann, F.
\newblock On the interpretation of weight vectors of linear models in
  multivariate neuroimaging.
\newblock \emph{NeuroImage}, 87:\penalty0 96--110, 2014.

\bibitem[Hoffman(1960)]{hoffmanParamorphicRepresentationClinical1960}
Hoffman, P.~J.
\newblock The paramorphic representation of clinical judgment.
\newblock \emph{Psychological Bulletin}, 57\penalty0 (2):\penalty0 116--131,
  1960.

\bibitem[Jacovi \& Goldberg(2020)Jacovi and
  Goldberg]{jacoviFaithfullyInterpretableNLP2020}
Jacovi, A. and Goldberg, Y.
\newblock Towards faithfully interpretable {NLP} systems: How should we define
  and evaluate faithfulness?
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pp.\  4198--4205, Online, July 2020.
  Association for Computational Linguistics.

\bibitem[Janzing et~al.(2020)Janzing, Minorics, and
  Bloebaum]{janzingFeatureRelevanceQuantification2020}
Janzing, D., Minorics, L., and Bloebaum, P.
\newblock Feature relevance quantification in explainable {{AI}}: {{A}} causal
  problem.
\newblock In \emph{International {{Conference}} on {{Artificial Intelligence}}
  and {{Statistics}}}, pp.\  2907--2916. {PMLR}, 2020.

\bibitem[Jiménez-Luna et~al.(2020)Jiménez-Luna, Grisoni, and
  Schneider]{jimenezLunaDrugDiscoveryExplainable2020}
Jiménez-Luna, J., Grisoni, F., and Schneider, G.
\newblock Drug discovery with explainable artificial intelligence.
\newblock \emph{Nature Machine Intelligence}, 2\penalty0 (10):\penalty0
  573--584, 2020.

\bibitem[Kim et~al.(2018)Kim, Wattenberg, Gilmer, Cai, Wexler, Viegas, and
  Sayres]{kimInterpretabilityFeatureAttribution2018}
Kim, B., Wattenberg, M., Gilmer, J., Cai, C., Wexler, J., Viegas, F., and
  Sayres, R.
\newblock Interpretability {{Beyond Feature Attribution}}: {{Quantitative
  Testing}} with {{Concept Activation Vectors}} ({{TCAV}}).
\newblock In \emph{International {{Conference}} on {{Machine Learning}}}, pp.\
  2668--2677. {PMLR}, 2018.

\bibitem[Kindermans et~al.(2018)Kindermans, Schütt, Alber, Müller, Erhan,
  Kim, and Dähne]{kindermansLearningHowExplain2017}
Kindermans, P.-J., Schütt, K.~T., Alber, M., Müller, K.-R., Erhan, D., Kim,
  B., and Dähne, S.
\newblock Learning how to explain neural networks: Patternnet and
  patternattribution.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Kohlbrenner et~al.(2020)Kohlbrenner, Bauer, Nakajima, Binder, Samek,
  and Lapuschkin]{kohlbrenner2020TowardsBestPraticeExplNN}
Kohlbrenner, M., Bauer, A., Nakajima, S., Binder, A., Samek, W., and
  Lapuschkin, S.
\newblock Towards best practice in explaining neural network decisions with
  lrp.
\newblock In \emph{2020 International Joint Conference on Neural Networks
  (IJCNN)}, pp.\  1--7, 2020.

\bibitem[Lapuschkin et~al.(2019)Lapuschkin, Wäldchen, Binder, Montavon, Samek,
  and Müller]{lapuschkinUnmaskingCleverHans2019}
Lapuschkin, S., Wäldchen, S., Binder, A., Montavon, G., Samek, W., and
  Müller, K.-R.
\newblock Unmasking {{Clever Hans}} predictors and assessing what machines
  really learn.
\newblock \emph{Nature Communications}, 10\penalty0 (1):\penalty0 1096, 2019.

\bibitem[Lipovetsky \& Conklin(2001)Lipovetsky and
  Conklin]{lipovetskyAnalysisRegressionGame2001}
Lipovetsky, S. and Conklin, M.
\newblock Analysis of regression in game theory approach.
\newblock \emph{Applied Stochastic Models in Business and Industry},
  17\penalty0 (4):\penalty0 319--330, 2001.

\bibitem[Lundberg \& Lee(2017)Lundberg and
  Lee]{lundbergUnifiedApproachInterpreting2017}
Lundberg, S.~M. and Lee, S.-I.
\newblock A {{Unified Approach}} to {{Interpreting Model Predictions}}.
\newblock In Guyon, I., Luxburg, U.~V., Bengio, S., Wallach, H., Fergus, R.,
  Vishwanathan, S., and Garnett, R. (eds.), \emph{Advances in {{Neural
  Information Processing Systems}} 30}, pp.\  4765--4774. {Curran Associates,
  Inc.}, 2017.

\bibitem[Molnar(2020)]{molnarInterpretableMachineLearning}
Molnar, C.
\newblock \emph{Interpretable {{Machine Learning}}}.
\newblock Independently published, 2020.

\bibitem[Montavon et~al.(2017)Montavon, Bach, Binder, Samek, and
  Müller]{montavonExplainingNonLinearClassification2017}
Montavon, G., Bach, S., Binder, A., Samek, W., and Müller, K.-R.
\newblock Explaining {{NonLinear Classification Decisions}} with {{Deep Taylor
  Decomposition}}.
\newblock \emph{Pattern Recognition}, 65:\penalty0 211--222, 2017.

\bibitem[Montavon et~al.(2018)Montavon, Samek, and
  Müller]{montavon2018MethodsInterpretingNN}
Montavon, G., Samek, W., and Müller, K.-R.
\newblock Methods for interpreting and understanding deep neural networks.
\newblock \emph{Digital Signal Processing}, 73:\penalty0 1--15, 2018.
\newblock ISSN 1051-2004.

\bibitem[Ribeiro et~al.(2016)Ribeiro, Singh, and
  Guestrin]{ribeiroWhyShouldTrust2016}
Ribeiro, M.~T., Singh, S., and Guestrin, C.
\newblock " {{Why}} should {{I}} trust you?" {{Explaining}} the predictions of
  any classifier.
\newblock In \emph{Proceedings of the 22nd {{ACM SIGKDD}} International
  Conference on Knowledge Discovery and Data Mining}, pp.\  1135--1144, 2016.

\bibitem[Samek et~al.(2017)Samek, Binder, Montavon, Lapuschkin, and
  M{\"u}ller]{samekEvaluatingVisualizationWhat2015}
Samek, W., Binder, A., Montavon, G., Lapuschkin, S., and M{\"u}ller, K.
\newblock Evaluating the visualization of what a deep neural network has
  learned.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems},
  28\penalty0 (11):\penalty0 2660--2673, November 2017.

\bibitem[Selvaraju et~al.(2017)Selvaraju, Cogswell, Das, Vedantam, Parikh, and
  Batra]{selvarajuGradCAMVisualExplanations2017}
Selvaraju, R.~R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., and Batra,
  D.
\newblock Grad-{{CAM}}: {{Visual Explanations}} from {{Deep Networks}} via
  {{Gradient-Based Localization}}.
\newblock In \emph{2017 {{IEEE International Conference}} on {{Computer
  Vision}} ({{ICCV}})}, pp.\  618--626, 2017.

\bibitem[Shapley(1953)]{shapleyValueNPersonGames1953}
Shapley, L.~S.
\newblock A {{Value}} for n-{{Person Games}}.
\newblock In Kuhn, H.~W. and Tucker, A.~W. (eds.), \emph{Contributions to the
  {{Theory}} of {{Games}} ({{AM-28}}), {{Volume II}}}, pp.\  307--318.
  {Princeton University Press}, 1953.

\bibitem[Shrikumar et~al.(2017)Shrikumar, Greenside, and
  Kundaje]{shrikumarLearningImportantFeatures2017}
Shrikumar, A., Greenside, P., and Kundaje, A.
\newblock Learning {{Important Features Through Propagating Activation
  Differences}}.
\newblock 2017.

\bibitem[Simonyan et~al.(2014)Simonyan, Vedaldi, and Zisserman]{Simonyan14a}
Simonyan, K., Vedaldi, A., and Zisserman, A.
\newblock Deep inside convolutional networks: {{Visualising}} image
  classification models and saliency maps.
\newblock In \emph{Workshop at International Conference on Learning
  Representations}, 2014.

\bibitem[Sixt \& Landgraf(2022)Sixt and
  Landgraf]{sixt2022RigorousStudyDeepTylor}
Sixt, L. and Landgraf, T.
\newblock A rigorous study of the deep taylor decomposition.
\newblock \emph{Transactions on Machine Learning Research}, 2022.
\newblock ISSN 2835-8856.

\bibitem[Sixt et~al.(2020)Sixt, Granz, and
  Landgraf]{sixtWhenExplanationsLie2020}
Sixt, L., Granz, M., and Landgraf, T.
\newblock When explanations lie: Why many modified {BP} attributions fail.
\newblock In III, H.~D. and Singh, A. (eds.), \emph{Proceedings of the 37th
  International Conference on Machine Learning}, volume 119 of
  \emph{Proceedings of Machine Learning Research}, pp.\  9046--9057. PMLR,
  13--18 Jul 2020.

\bibitem[Springenberg et~al.(2015)Springenberg, Dosovitskiy, Brox, and
  Riedmiller]{springenbergStrivingSimplicityAll2015}
Springenberg, J., Dosovitskiy, A., Brox, T., and Riedmiller, M.
\newblock Striving for simplicity: The all convolutional net.
\newblock In \emph{ICLR (workshop track)}, 2015.

\bibitem[Sundararajan et~al.(2017)Sundararajan, Taly, and
  Yan]{sundararajanAxiomaticAttributionDeep2017}
Sundararajan, M., Taly, A., and Yan, Q.
\newblock Axiomatic {{Attribution}} for {{Deep Networks}}.
\newblock In \emph{{{ICML}}}, 2017.

\bibitem[Tran et~al.(2021)Tran, Kondrashova, Bradley, Williams, Pearson, and
  Waddell]{tranDeepLearningCancer2021}
Tran, K.~A., Kondrashova, O., Bradley, A., Williams, E.~D., Pearson, J.~V., and
  Waddell, N.
\newblock Deep learning in cancer diagnosis, prognosis and treatment selection.
\newblock \emph{Genome Medicine}, 13\penalty0 (1):\penalty0 152, 2021.

\bibitem[Wachter et~al.(2017)Wachter, Mittelstadt, and
  Russell]{wachterCounterfactualExplanationsOpening2017}
Wachter, S., Mittelstadt, B., and Russell, C.
\newblock Counterfactual explanations without opening the black box:
  {{Automated}} decisions and the {{GDPR}}.
\newblock \emph{Harv. JL \& Tech.}, 31:\penalty0 841, 2017.

\bibitem[Wilming et~al.(2022)Wilming, Budding, M{\"u}ller, and
  Haufe]{wilmingScrutinizingXAIUsing2022}
Wilming, R., Budding, C., M{\"u}ller, K.-R., and Haufe, S.
\newblock Scrutinizing xai using linear ground-truth data with suppressor
  variables.
\newblock \emph{Machine learning}, 111\penalty0 (5):\penalty0 1903--1923, 2022.

\bibitem[Yang \& Kim(2019)Yang and Kim]{yang2019benchmarking}
Yang, M. and Kim, B.
\newblock Benchmarking attribution methods with relative feature importance.
\newblock \emph{arXiv preprint arXiv:1907.09701}, 2019.

\bibitem[Zeiler \& Fergus(2014)Zeiler and
  Fergus]{zeilerVisualizingUnderstandingConvolutional2014}
Zeiler, M.~D. and Fergus, R.
\newblock Visualizing and {{Understanding Convolutional Networks}}.
\newblock In Fleet, D., Pajdla, T., Schiele, B., and Tuytelaars, T. (eds.),
  \emph{Computer {{Vision}} – {{ECCV}} 2014}, Lecture {{Notes}} in {{Computer
  Science}}, pp.\  818--833. {Springer International Publishing}, 2014.

\bibitem[Zien et~al.(2009)Zien, Krämer, Sonnenburg, and
  Rätsch]{zienFeatureImportanceRanking2009}
Zien, A., Krämer, N., Sonnenburg, S., and Rätsch, G.
\newblock The {{Feature Importance Ranking Measure}}.
\newblock In Buntine, W., Grobelnik, M., Mladenić, D., and Shawe-Taylor, J.
  (eds.), \emph{Machine {{Learning}} and {{Knowledge Discovery}} in
  {{Databases}}}, Lecture {{Notes}} in {{Computer Science}}, pp.\  694--709.
  {Springer}, 2009.

\bibitem[Štrumbelj \& Kononenko(2014)Štrumbelj and
  Kononenko]{strumbeljExplainingPredictionModels2014}
Štrumbelj, E. and Kononenko, I.
\newblock Explaining prediction models and individual predictions with feature
  contributions.
\newblock \emph{Knowledge and Information Systems}, 41\penalty0 (3):\penalty0
  647--665, 2014.

\end{thebibliography}
