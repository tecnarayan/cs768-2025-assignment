\begin{thebibliography}{71}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agrawal et~al.(2016)Agrawal, Nair, Abbeel, Malik, and
  Levine]{Agrawal2016LearningTP}
P.~Agrawal, A.~V. Nair, P.~Abbeel, J.~Malik, and S.~Levine.
\newblock Learning to poke by poking: Experiential learning of intuitive
  physics.
\newblock In D.~D. Lee, M.~Sugiyama, U.~V. Luxburg, I.~Guyon, and R.~Garnett,
  editors, \emph{Advances in Neural Information Processing Systems 29}, pages
  5074--5082. Curran Associates, Inc., 2016.

\bibitem[Amos et~al.(2018{\natexlab{a}})Amos, Dinh, Cabi, Rothörl, Muldal,
  Erez, Tassa, de~Freitas, and Denil]{awarenessmodels_amos}
B.~Amos, L.~Dinh, S.~Cabi, T.~Rothörl, A.~Muldal, T.~Erez, Y.~Tassa,
  N.~de~Freitas, and M.~Denil.
\newblock Learning awareness models.
\newblock In \emph{International Conference on Learning Representations},
  2018{\natexlab{a}}.
\newblock URL \url{https://openreview.net/forum?id=r1HhRfWRZ}.

\bibitem[Amos et~al.(2018{\natexlab{b}})Amos, Jimenez, Sacks, Boots, and
  Kolter]{Amos2018DifferentiableMF}
B.~Amos, I.~Jimenez, J.~Sacks, B.~Boots, and J.~Z. Kolter.
\newblock Differentiable mpc for end-to-end planning and control.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  8289--8300, 2018{\natexlab{b}}.

\bibitem[Andrychowicz et~al.(2017)Andrychowicz, Wolski, Ray, Schneider, Fong,
  Welinder, McGrew, Tobin, Abbeel, and Zaremba]{her}
M.~Andrychowicz, F.~Wolski, A.~Ray, J.~Schneider, R.~Fong, P.~Welinder,
  B.~McGrew, J.~Tobin, P.~Abbeel, and W.~Zaremba.
\newblock Hindsight experience replay.
\newblock \emph{CoRR}, abs/1707.01495, 2017.

\bibitem[Babaeizadeh et~al.(2018)Babaeizadeh, Finn, Erhan, Campbell, and
  Levine]{sv2p}
M.~Babaeizadeh, C.~Finn, D.~Erhan, R.~H. Campbell, and S.~Levine.
\newblock Stochastic variational video prediction.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=rk49Mg-CW}.

\bibitem[Banijamali et~al.(2017)Banijamali, Shu, Ghavamzadeh, Bui, and
  Ghodsi]{Banijamali2017RobustLC}
E.~Banijamali, R.~Shu, M.~Ghavamzadeh, H.~H. Bui, and A.~Ghodsi.
\newblock Robust locally-linear controllable embedding.
\newblock \emph{ArXiv}, abs/1710.05373, 2017.

\bibitem[Byravan et~al.(2019)Byravan, Springenberg, Abdolmaleki, Hafner,
  Neunert, Lampe, Siegel, Heess, and Riedmiller]{Byravan2019ImaginedVG}
A.~Byravan, J.~T. Springenberg, A.~Abdolmaleki, R.~Hafner, M.~Neunert,
  T.~Lampe, N.~Siegel, N.~M.~O. Heess, and M.~A. Riedmiller.
\newblock Imagined value gradients: Model-based policy optimization with
  transferable latent dynamics models.
\newblock \emph{ArXiv}, abs/1910.04142, 2019.

\bibitem[Chua et~al.(2018)Chua, Calandra, McAllister, and Levine]{chua_handful}
K.~Chua, R.~Calandra, R.~McAllister, and S.~Levine.
\newblock Deep reinforcement learning in a handful of trials using
  probabilistic dynamics models.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  4754--4765, 2018.

\bibitem[Codevilla et~al.(2017)Codevilla, M{\"u}ller, Dosovitskiy, L{\'o}pez,
  and Koltun]{Codevilla2017EndtoEndDV}
F.~Codevilla, M.~M{\"u}ller, A.~Dosovitskiy, A.~L{\'o}pez, and V.~Koltun.
\newblock End-to-end driving via conditional imitation learning.
\newblock \emph{2018 IEEE International Conference on Robotics and Automation
  (ICRA)}, pages 1--9, 2017.

\bibitem[Dasari et~al.(2019)Dasari, Ebert, Tian, Nair, Bucher, Schmeckpeper,
  Singh, Levine, and Finn]{Dasari2019RoboNetLM}
S.~Dasari, F.~Ebert, S.~Tian, S.~Nair, B.~Bucher, K.~Schmeckpeper, S.~Singh,
  S.~Levine, and C.~Finn.
\newblock Robonet: Large-scale multi-robot learning.
\newblock \emph{ArXiv}, abs/1910.11215, 2019.

\bibitem[Deisenroth and Rasmussen(2011)]{Deisenroth11pilco:a}
M.~Deisenroth and C.~E. Rasmussen.
\newblock Pilco: A model-based and data-efficient approach to policy search.
\newblock In \emph{Proceedings of the 28th International Conference on machine
  learning (ICML-11)}, pages 465--472, 2011.

\bibitem[Denton and Fergus(2018)]{Denton2018StochasticVG}
E.~L. Denton and R.~Fergus.
\newblock Stochastic video generation with a learned prior.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[D'Oro et~al.(2020)D'Oro, Metelli, Tirinzoni, Papini, and
  Restelli]{d2019gradient}
P.~D'Oro, A.~M. Metelli, A.~Tirinzoni, M.~Papini, and M.~Restelli.
\newblock Gradient-aware model-based policy search.
\newblock In \emph{Thirty-Fourth AAAI Conference on Artificial Intelligence},
  2020.

\bibitem[Dosovitskiy and Koltun(2016)]{Dosovitskiy2016LearningTA}
A.~Dosovitskiy and V.~Koltun.
\newblock Learning to act by predicting the future.
\newblock \emph{ArXiv}, abs/1611.01779, 2016.

\bibitem[Ebert et~al.(2017)Ebert, Finn, Lee, and Levine]{ebertskip}
F.~Ebert, C.~Finn, A.~X. Lee, and S.~Levine.
\newblock Self-supervised visual planning with temporal skip connections.
\newblock \emph{CoRR}, abs/1710.05268, 2017.

\bibitem[Ebert et~al.(2018)Ebert, Finn, Dasari, Xie, Lee, and
  Levine]{visualforesightebert}
F.~Ebert, C.~Finn, S.~Dasari, A.~Xie, A.~X. Lee, and S.~Levine.
\newblock Visual foresight: Model-based deep reinforcement learning for
  vision-based robotic control.
\newblock \emph{CoRR}, abs/1812.00568, 2018.

\bibitem[Eysenbach et~al.(2019)Eysenbach, Salakhutdinov, and Levine]{sorb}
B.~Eysenbach, R.~R. Salakhutdinov, and S.~Levine.
\newblock Search on the replay buffer: Bridging planning and reinforcement
  learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  15246--15257, 2019.

\bibitem[Fang et~al.(2019)Fang, Zhu, Garg, Savarese, and
  Fei-Fei]{Fang2019DynamicsLW}
K.~Fang, Y.~Zhu, A.~Garg, S.~Savarese, and L.~Fei-Fei.
\newblock Dynamics learning with cascaded variational inference for multi-step
  manipulation.
\newblock \emph{ArXiv}, abs/1910.13395, 2019.

\bibitem[Farahmand et~al.(2017)Farahmand, Barreto, and
  Nikovski]{pmlr-v54-farahmand17a}
A.-M. Farahmand, A.~Barreto, and D.~Nikovski.
\newblock {Value-Aware Loss Function for Model-based Reinforcement Learning}.
\newblock In A.~Singh and J.~Zhu, editors, \emph{Proceedings of the 20th
  International Conference on Artificial Intelligence and Statistics},
  volume~54 of \emph{Proceedings of Machine Learning Research}, pages
  1486--1494, Fort Lauderdale, FL, USA, 20--22 Apr 2017. PMLR.
\newblock URL \url{http://proceedings.mlr.press/v54/farahmand17a.html}.

\bibitem[Finn and Levine(2017)]{DBLP:journals/corr/FinnL16}
C.~Finn and S.~Levine.
\newblock Deep visual foresight for planning robot motion.
\newblock In \emph{2017 IEEE International Conference on Robotics and
  Automation (ICRA)}, pages 2786--2793. IEEE, 2017.

\bibitem[Finn et~al.(2016)Finn, Goodfellow, and Levine]{Finn2016UnsupervisedLF}
C.~Finn, I.~J. Goodfellow, and S.~Levine.
\newblock Unsupervised learning for physical interaction through video
  prediction.
\newblock In \emph{NIPS}, 2016.

\bibitem[Freeman et~al.(2019)Freeman, Ha, and Metz]{Freeman2019LearningTP}
D.~Freeman, D.~Ha, and L.~Metz.
\newblock Learning to predict without looking ahead: World models without
  forward prediction.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  5379--5390, 2019.

\bibitem[Gelada et~al.(2019)Gelada, Kumar, Buckman, Nachum, and
  Bellemare]{deepmdp_gelada}
C.~Gelada, S.~Kumar, J.~Buckman, O.~Nachum, and M.~G. Bellemare.
\newblock Deepmdp: Learning continuous latent space models for representation
  learning.
\newblock \emph{CoRR}, abs/1906.02736, 2019.
\newblock URL \url{http://arxiv.org/abs/1906.02736}.

\bibitem[Gregor et~al.(2019)Gregor, Rezende, Besse, Wu, Merzic, and van~den
  Oord]{Gregor2019ShapingBS}
K.~Gregor, D.~J. Rezende, F.~Besse, Y.~Wu, H.~Merzic, and A.~van~den Oord.
\newblock Shaping belief states with generative environment models for rl.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Ha and Schmidhuber(2018)]{Ha2018WorldM}
D.~Ha and J.~Schmidhuber.
\newblock World models.
\newblock \emph{ArXiv}, abs/1803.10122, 2018.

\bibitem[Haarnoja et~al.(2018)Haarnoja, Zhou, Abbeel, and
  Levine]{Haarnoja2018SoftAO}
T.~Haarnoja, A.~Zhou, P.~Abbeel, and S.~Levine.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock \emph{ArXiv}, abs/1801.01290, 2018.

\bibitem[Hafner et~al.(2019{\natexlab{a}})Hafner, Lillicrap, Ba, and
  Norouzi]{Hafner2019DreamTC}
D.~Hafner, T.~Lillicrap, J.~Ba, and M.~Norouzi.
\newblock Dream to control: Learning behaviors by latent imagination.
\newblock \emph{arXiv preprint arXiv:1912.01603}, 2019{\natexlab{a}}.

\bibitem[Hafner et~al.(2019{\natexlab{b}})Hafner, Lillicrap, Fischer, Villegas,
  Ha, Lee, and Davidson]{DBLP:journals/corr/abs-1811-04551hafner}
D.~Hafner, T.~Lillicrap, I.~Fischer, R.~Villegas, D.~Ha, H.~Lee, and
  J.~Davidson.
\newblock Learning latent dynamics for planning from pixels.
\newblock In \emph{International Conference on Machine Learning}, pages
  2555--2565, 2019{\natexlab{b}}.

\bibitem[Hartikainen et~al.(2020)Hartikainen, Geng, Haarnoja, and
  Levine]{Hartikainen2019DynamicalDL}
K.~Hartikainen, X.~Geng, T.~Haarnoja, and S.~Levine.
\newblock Dynamical distance learning for semi-supervised and unsupervised
  skill discovery.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=H1lmhaVtvr}.

\bibitem[Havens et~al.(2020)Havens, Ouyang, Nagarajan, and
  Fujita]{havens2020learning}
A.~Havens, Y.~Ouyang, P.~Nagarajan, and Y.~Fujita.
\newblock Learning latent state spaces for planning through reward prediction,
  2020.
\newblock URL \url{https://openreview.net/forum?id=ByxJjlHKwr}.

\bibitem[Ichter and Pavone(2019)]{ichterlatent}
B.~Ichter and M.~Pavone.
\newblock Robot motion planning in learned latent spaces.
\newblock \emph{IEEE Robotics and Automation Letters}, 4\penalty0 (3):\penalty0
  2407--2414, 2019.

\bibitem[Janner et~al.(2019)Janner, Fu, Zhang, and Levine]{Janner2019WhenTT}
M.~Janner, J.~Fu, M.~Zhang, and S.~Levine.
\newblock When to trust your model: Model-based policy optimization.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Kaelbling(1993)]{Kaelbling93learningto}
L.~P. Kaelbling.
\newblock Learning to achieve goals.
\newblock In \emph{IJCAI}, pages 1094--1098, 1993.

\bibitem[Kalashnikov et~al.(2018)Kalashnikov, Irpan, Pastor, Ibarz, Herzog,
  Jang, Quillen, Holly, Kalakrishnan, Vanhoucke, and Levine]{qtopt}
D.~Kalashnikov, A.~Irpan, P.~Pastor, J.~Ibarz, A.~Herzog, E.~Jang, D.~Quillen,
  E.~Holly, M.~Kalakrishnan, V.~Vanhoucke, and S.~Levine.
\newblock Qt-opt: Scalable deep reinforcement learning for vision-based robotic
  manipulation.
\newblock \emph{arxiv:Preprint}, 2018.

\bibitem[Kurutach et~al.(2018)Kurutach, Tamar, Yang, Russell, and
  Abbeel]{causalinfogan}
T.~Kurutach, A.~Tamar, G.~Yang, S.~J. Russell, and P.~Abbeel.
\newblock Learning plannable representations with causal infogan.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  8733--8744, 2018.

\bibitem[Lambert et~al.(2020)Lambert, Amos, Yadan, and
  Calandra]{Lambert2020ObjectiveMI}
N.~G. Lambert, B.~Amos, O.~Yadan, and R.~Calandra.
\newblock Objective mismatch in model-based reinforcement learning.
\newblock \emph{ArXiv}, abs/2002.04523, 2020.

\bibitem[Lee et~al.(2018)Lee, Zhang, Ebert, Abbeel, Finn, and Levine]{savp}
A.~X. Lee, R.~Zhang, F.~Ebert, P.~Abbeel, C.~Finn, and S.~Levine.
\newblock Stochastic adversarial video prediction.
\newblock \emph{CoRR}, abs/1804.01523, 2018.

\bibitem[Lee et~al.(2019)Lee, Nagabandi, Abbeel, and
  Levine]{Lee2019StochasticLA}
A.~X. Lee, A.~Nagabandi, P.~Abbeel, and S.~Levine.
\newblock Stochastic latent actor-critic: Deep reinforcement learning with a
  latent variable model.
\newblock \emph{ArXiv}, abs/1907.00953, 2019.

\bibitem[Levine et~al.(2016)Levine, Finn, Darrell, and
  Abbeel]{DBLP:journals/corr/LevineFDA15}
S.~Levine, C.~Finn, T.~Darrell, and P.~Abbeel.
\newblock End-to-end training of deep visuomotor policies.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 1334--1373, 2016.

\bibitem[Liu et~al.(2020)Liu, Kurutach, Abbeel, and
  Tamar]{liu2020hallucinative}
K.~Liu, T.~Kurutach, P.~Abbeel, and A.~Tamar.
\newblock Hallucinative topological memory for zero-shot visual planning, 2020.
\newblock URL \url{https://openreview.net/forum?id=BkgF4kSFPB}.

\bibitem[McAllister and Rasmussen(2016)]{McAllister2016ImprovingPW}
R.~McAllister and C.~E. Rasmussen.
\newblock Improving pilco with bayesian neural network dynamics models.
\newblock 2016.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, Petersen, Beattie, Sadik,
  Antonoglou, King, Kumaran, Wierstra, Legg, and
  Hassabis]{Mnih2015HumanlevelCT}
V.~Mnih, K.~Kavukcuoglu, D.~Silver, A.~A. Rusu, J.~Veness, M.~G. Bellemare,
  A.~Graves, M.~A. Riedmiller, A.~K. Fidjeland, G.~Ostrovski, S.~Petersen,
  C.~Beattie, A.~Sadik, I.~Antonoglou, H.~King, D.~Kumaran, D.~Wierstra,
  S.~Legg, and D.~Hassabis.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518:\penalty0 529--533, 2015.

\bibitem[Nagabandi et~al.(2019)Nagabandi, Konoglie, Levine, and
  Kumar]{Nagabandi2019DeepDM}
A.~Nagabandi, K.~Konoglie, S.~Levine, and V.~Kumar.
\newblock Deep dynamics models for learning dexterous manipulation.
\newblock \emph{ArXiv}, abs/1909.11652, 2019.

\bibitem[Nair et~al.(2019)Nair, Bahl, Khazatsky, Pong, Berseth, and
  Levine]{Nair2019ContextualIG}
A.~Nair, S.~Bahl, A.~Khazatsky, V.~Pong, G.~Berseth, and S.~Levine.
\newblock Contextual imagined goals for self-supervised robotic learning.
\newblock \emph{ArXiv}, abs/1910.11670, 2019.

\bibitem[Nair et~al.(2018)Nair, Pong, Dalal, Bahl, Lin, and
  Levine]{ashvinnairRIG}
A.~V. Nair, V.~Pong, M.~Dalal, S.~Bahl, S.~Lin, and S.~Levine.
\newblock Visual reinforcement learning with imagined goals.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  9191--9200, 2018.

\bibitem[Nair and Finn(2020)]{nair2020hierarchical}
S.~Nair and C.~Finn.
\newblock Hierarchical foresight: Self-supervised learning of long-horizon
  tasks via visual subgoal generation.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=H1gzR2VKDH}.

\bibitem[OpenAI(2018)]{OpenAI_dota}
OpenAI.
\newblock Openai five.
\newblock \url{https://blog.openai.com/openai-five/}, 2018.

\bibitem[OpenAI et~al.(2018)OpenAI, Andrychowicz, Baker, Chociej,
  J{\'{o}}zefowicz, McGrew, Pachocki, Pachocki, Petron, Plappert, Powell, Ray,
  Schneider, Sidor, Tobin, Welinder, Weng, and Zaremba]{openai_dexterous}
OpenAI, M.~Andrychowicz, B.~Baker, M.~Chociej, R.~J{\'{o}}zefowicz, B.~McGrew,
  J.~W. Pachocki, J.~Pachocki, A.~Petron, M.~Plappert, G.~Powell, A.~Ray,
  J.~Schneider, S.~Sidor, J.~Tobin, P.~Welinder, L.~Weng, and W.~Zaremba.
\newblock Learning dexterous in-hand manipulation.
\newblock \emph{CoRR}, abs/1808.00177, 2018.
\newblock URL \url{http://arxiv.org/abs/1808.00177}.

\bibitem[Pathak et~al.(2017)Pathak, Agrawal, Efros, and
  Darrell]{Pathak2017CuriosityDrivenEB}
D.~Pathak, P.~Agrawal, A.~A. Efros, and T.~Darrell.
\newblock Curiosity-driven exploration by self-supervised prediction.
\newblock \emph{2017 IEEE Conference on Computer Vision and Pattern Recognition
  Workshops (CVPRW)}, pages 488--489, 2017.

\bibitem[Paxton et~al.(2018)Paxton, Barnoy, Katyal, Arora, and Hager]{paxton}
C.~Paxton, Y.~Barnoy, K.~D. Katyal, R.~Arora, and G.~D. Hager.
\newblock Visual robot task planning.
\newblock \emph{CoRR}, abs/1804.00062, 2018.

\bibitem[Pinto and Gupta(2016)]{DBLP:journals/corr/PintoG15}
L.~Pinto and A.~Gupta.
\newblock Supersizing self-supervision: Learning to grasp from 50k tries and
  700 robot hours.
\newblock In \emph{2016 IEEE international conference on robotics and
  automation (ICRA)}, pages 3406--3413. IEEE, 2016.

\bibitem[Racani{\`e}re et~al.(2017)Racani{\`e}re, Weber, Reichert, Buesing,
  Guez, Rezende, Badia, Vinyals, Heess, Li, Pascanu, Battaglia, Hassabis,
  Silver, and Wierstra]{Racanire2017ImaginationAugmentedAF}
S.~Racani{\`e}re, T.~Weber, D.~P. Reichert, L.~Buesing, A.~Guez, D.~J. Rezende,
  A.~P. Badia, O.~Vinyals, N.~M.~O. Heess, Y.~Li, R.~Pascanu, P.~W. Battaglia,
  D.~Hassabis, D.~Silver, and D.~Wierstra.
\newblock Imagination-augmented agents for deep reinforcement learning.
\newblock \emph{ArXiv}, abs/1707.06203, 2017.

\bibitem[Rubinstein and Kroese(2004)]{cem}
R.~Rubinstein and D.~Kroese.
\newblock \emph{The Cross-Entropy Method: A Unified Approach to Combinatorial
  Optimization, Monte-Carlo Simulation and Machine Learning}.
\newblock 01 2004.

\bibitem[Rybkin et~al.(2020)Rybkin, Pertsch, Ebert, Jayaraman, Finn, and
  Levine]{rybkin2020goalconditioned}
O.~Rybkin, K.~Pertsch, F.~Ebert, D.~Jayaraman, C.~Finn, and S.~Levine.
\newblock Goal-conditioned video prediction, 2020.
\newblock URL \url{https://openreview.net/forum?id=B1g79grKPr}.

\bibitem[Schaul et~al.(2015)Schaul, Horgan, Gregor, and
  Silver]{pmlr-v37-schaul15}
T.~Schaul, D.~Horgan, K.~Gregor, and D.~Silver.
\newblock Universal value function approximators.
\newblock In \emph{International Conference on Machine Learning}, 2015.

\bibitem[Schrittwieser et~al.(2019)Schrittwieser, Antonoglou, Hubert, Simonyan,
  Sifre, Schmitt, Guez, Lockhart, Hassabis, Graepel, Lillicrap, and
  Silver]{Schrittwieser2019MasteringAG}
J.~Schrittwieser, I.~Antonoglou, T.~Hubert, K.~Simonyan, L.~Sifre, S.~Schmitt,
  A.~Guez, E.~Lockhart, D.~Hassabis, T.~Graepel, T.~P. Lillicrap, and
  D.~Silver.
\newblock Mastering atari, go, chess and shogi by planning with a learned
  model.
\newblock \emph{ArXiv}, abs/1911.08265, 2019.

\bibitem[Silver et~al.(2016)Silver, Huang, Maddison, Guez, Sifre, van~den
  Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot, Dieleman,
  Grewe, Nham, Kalchbrenner, Sutskever, Lillicrap, Leach, Kavukcuoglu, Graepel,
  and Hassabis]{AlphaGo}
D.~Silver, A.~Huang, C.~J. Maddison, A.~Guez, L.~Sifre, G.~van~den Driessche,
  J.~Schrittwieser, I.~Antonoglou, V.~Panneershelvam, M.~Lanctot, S.~Dieleman,
  D.~Grewe, J.~Nham, N.~Kalchbrenner, I.~Sutskever, T.~Lillicrap, M.~Leach,
  K.~Kavukcuoglu, T.~Graepel, and D.~Hassabis.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock \emph{Nature}, 529:\penalty0 484--503, 2016.
\newblock URL
  \url{http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html}.

\bibitem[Srinivas et~al.(2018)Srinivas, Jabri, Abbeel, Levine, and
  Finn]{Srinivas2018UniversalPN}
A.~Srinivas, A.~Jabri, P.~Abbeel, S.~Levine, and C.~Finn.
\newblock Universal planning networks.
\newblock \emph{ArXiv}, abs/1804.00645, 2018.

\bibitem[Sutton and Barto(2018)]{Sutton1998}
R.~S. Sutton and A.~G. Barto.
\newblock \emph{Reinforcement Learning: An Introduction}.
\newblock The MIT Press, second edition, 2018.
\newblock URL \url{http://incompleteideas.net/book/the-book-2nd.html}.

\bibitem[Thananjeyan et~al.(2019)Thananjeyan, Balakrishna, Rosolia, Li,
  McAllister, Gonzalez, Levine, Borrelli, and
  Goldberg]{Thananjeyan2019SafetyAV}
B.~Thananjeyan, A.~Balakrishna, U.~Rosolia, F.~Li, R.~McAllister, J.~E.
  Gonzalez, S.~Levine, F.~Borrelli, and K.~Goldberg.
\newblock Safety augmented value estimation from demonstrations (saved): Safe
  deep model-based rl for sparse cost robotic tasks.
\newblock 2019.

\bibitem[Veerapaneni et~al.(2019)Veerapaneni, Co-Reyes, Chang, Janner, Finn,
  Wu, Tenenbaum, and Levine]{Veerapaneni2019EntityAI}
R.~Veerapaneni, J.~D. Co-Reyes, M.~Chang, M.~Janner, C.~Finn, J.~Wu, J.~B.
  Tenenbaum, and S.~Levine.
\newblock Entity abstraction in visual model-based reinforcement learning.
\newblock \emph{ArXiv}, abs/1910.12827, 2019.

\bibitem[Villegas et~al.(2019)Villegas, Pathak, Kannan, Erhan, Le, and
  Lee]{highfidelity_villegas}
R.~Villegas, A.~Pathak, H.~Kannan, D.~Erhan, Q.~Le, and H.~Lee.
\newblock High fidelity video prediction with large stochastic recurrent neural
  networks.
\newblock 11 2019.

\bibitem[Wang et~al.(2019)Wang, Kurutach, Liu, Abbeel, and
  Tamar]{wangvisualplan}
A.~Wang, T.~Kurutach, K.~Liu, P.~Abbeel, and A.~Tamar.
\newblock Learning robotic manipulation through visual planning and acting.
\newblock \emph{CoRR}, abs/1905.04411, 2019.

\bibitem[Wang and Ba(2019)]{Wang2019ExploringMP}
T.~Wang and J.~Ba.
\newblock Exploring model-based planning with policy networks.
\newblock \emph{ArXiv}, abs/1906.08649, 2019.

\bibitem[Watter et~al.(2015)Watter, Springenberg, Boedecker, and
  Riedmiller]{e2c}
M.~Watter, J.~T. Springenberg, J.~Boedecker, and M.~A. Riedmiller.
\newblock Embed to control: {A} locally linear latent dynamics model for
  control from raw images.
\newblock \emph{CoRR}, abs/1506.07365, 2015.

\bibitem[Xie et~al.(2019)Xie, Ebert, Levine, and Finn]{xietooluse}
A.~Xie, F.~Ebert, S.~Levine, and C.~Finn.
\newblock Improvisation through physical understanding: Using novel objects as
  tools with visual foresight.
\newblock \emph{CoRR}, abs/1904.05538, 2019.

\bibitem[Yu et~al.(2019{\natexlab{a}})Yu, Quillen, He, Julian, Hausman, Finn,
  and Levine]{Yu2019MetaWorldAB}
T.~Yu, D.~Quillen, Z.~He, R.~R. Julian, K.~Hausman, C.~Finn, and S.~Levine.
\newblock Meta-world: A benchmark and evaluation for multi-task and meta
  reinforcement learning.
\newblock \emph{ArXiv}, abs/1910.10897, 2019{\natexlab{a}}.

\bibitem[Yu et~al.(2019{\natexlab{b}})Yu, Shevchuk, Sadigh, and Finn]{dpn}
T.~Yu, G.~Shevchuk, D.~Sadigh, and C.~Finn.
\newblock Unsupervised visuomotor control through distributional planning
  networks.
\newblock \emph{CoRR}, abs/1902.05542, 2019{\natexlab{b}}.

\bibitem[Zeng et~al.(2018)Zeng, Song, Welker, Lee, Rodriguez, and
  Funkhouser]{andyzengsynergy}
A.~Zeng, S.~Song, S.~Welker, J.~Lee, A.~Rodriguez, and T.~A. Funkhouser.
\newblock Learning synergies between pushing and grasping with self-supervised
  deep reinforcement learning.
\newblock \emph{CoRR}, abs/1803.09956, 2018.

\bibitem[Zhang et~al.(2018)Zhang, Vikram, Smith, Abbeel, Johnson, and
  Levine]{Zhang2018SOLARDS}
M.~Zhang, S.~Vikram, L.~Smith, P.~Abbeel, M.~J. Johnson, and S.~Levine.
\newblock Solar: Deep structured latent representations for model-based
  reinforcement learning.
\newblock \emph{ArXiv}, abs/1808.09105, 2018.

\bibitem[Łukasz Kaiser et~al.(2020)Łukasz Kaiser, Babaeizadeh, Miłos,
  Osiński, Campbell, Czechowski, Erhan, Finn, Kozakowski, Levine, Mohiuddin,
  Sepassi, Tucker, and Michalewski]{Kaiser2019ModelBasedRL}
Łukasz Kaiser, M.~Babaeizadeh, P.~Miłos, B.~Osiński, R.~H. Campbell,
  K.~Czechowski, D.~Erhan, C.~Finn, P.~Kozakowski, S.~Levine, A.~Mohiuddin,
  R.~Sepassi, G.~Tucker, and H.~Michalewski.
\newblock Model based reinforcement learning for atari.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=S1xCPJHtDB}.

\end{thebibliography}
