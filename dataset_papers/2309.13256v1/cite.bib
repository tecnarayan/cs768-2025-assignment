# security

@string{sp = "Proceedings of IEEE Symposium on Security and Privacy (S\&P)"}
@string{sec = "Proceedings of USENIX Security Symposium (SEC)"}
@string{ccs = "Proceedings of ACM Conference on Computer and Communications (CCS)"}
@string{ndss = "Proceedings of Network and Distributed System Security Symposium (NDSS)"}
@string{crypto = "Proceedings of International Crytology Conference (CRYPTO)"}
@string{cns = "Proceedings of IEEE Conference on Communications and Network Security (CNS)"}
@string{aisec = "Proceedings of ACM Workshop on Artificial Intelligence and Security (AISec)"}
@string{sacmat = "Proceedings of ACM Symposium on Access Control Models and Technologies (SACMAT)"}
@string{eurosp = "Proceedings of IEEE European Symposium on Security and Privacy (Euro S\&P)"}
@string{acsac = "Proceedings of Annual Computer Security Applications Conference (ACSAC)"}
@string{asiaccs = "Proceedings of ACM Symposium on Information, Computer and Communications Security (AsiaCCS)"}

@string{tdsc = "IEEE Transactions on Dependable and Secure Computing (TDSC)"}

# ml/dm

@string{iccv = "Proceedings of IEEE International Conference on Computer Vision (ICCV)"}
@string{cvpr = "Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"}
@string{icml = "Proceedings of IEEE Conference on Machine Learning (ICML)"}
@string{iclr = "Proceedings of International Conference on Learning Representations (ICLR)"}
@string{nips = "Proceedings of Advances in Neural Information Processing Systems (NeurIPS)"}
@string{arxiv = "ArXiv e-prints"}
@string{imc = "Proceedings of ACM Internet Measurement Conference (IMC)"}
@string{emnlp = "Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP)"}
@string{dasfaa = "Proceedings of International Conference on Database Systems for Advanced Applications (DASFAA)"}
@string{tods = "ACM Transactions on Database Systems (TODS)"}
@string{edbt  = "Proceedings of International Conference on Extending Database Technology (EDBT)"}
@string{icde = "Proceedings of International Conference on Data Engineering (ICDE)"}
@string{icdm  = "Proceedings of IEEE International Conference on Data Mining (ICDM)"}
@string{kdd  = "Proceedings of ACM International Conference on Knowledge Discovery and Data Mining (KDD)"}
@string{sdm = "SIAM International Conference on Data Mining (SDM)"}
@string{sigmod  = "Proceedings of ACM International Conference on Management of Data (SIGMOD)"}
@string{pods = "Proceedings of ACM Symposium on Principles of Database Systems (PODS)"}
@string{tkde  = "IEEE Transactions on Knowledge and Data Engineering (TKDE)"}
@string{vldb = "Proceedings of International Conference on Very Large Data Bases (VLDB)"}
@string{www = "Proceedings of International Conference on World Wide Web (WWW)"}
@string{cikm = "Proceeddings of ACM Conference on Information and Knowledge Management (CIKM)"}
@string{dsaa = "Proceedings of IEEE International Conference on Data Science and Advanced Analytics (DSAA)"}
@string{acl = "Proceedings of Annual Meeting of the Association for Computational Linguistics (ACL)"}
@string{naacl = "Proceedings of Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)"}
@string{aaai = "Proceedings of AAAI Conference on Artificial Intelligence (AAAI)"}
@string{ijcai = "Proceedings of International Joint Conference on Artificial Intelligence (IJCAI)"}

# system/networking

@string{sosp = "Proceedings of Symposium on Operating Systems Principles (SOSP)"}
@string{conext = "Proceedings of International COnference on emerging Networking EXperiments and Technologies (Co-NEXT)"}
@string{incp = "Proceedings of IEEE International Conference on Network Protocols (ICNP)"}
@string{infocom = "Proceedings of IEEE International Conference on Computer Communications (INFOCOM)"}
@string{icdcs = "Proceedings of IEEE International Conference on Distributed Computing Systems (ICDCS)"}

# programming language/software engineering

@string{fse = "Proceedings of ACM SIGSOFT International Symposium on Foundations of Software Engineering (FSE)"}
@string{icse = "Proceedings of International Conference on Software Engineering (ICSE)"}
@string{tse = "IEEE Transactions on Software Engineering (TSE)"}
@string{pldi = "Proceedings of ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)"}
@string{ase = "Proceedings of ACM/IEEE International Conference on Automated Software Engineering (ASE)"}


@inproceedings{liu2021pre,
  title="{Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing}",
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  booktitle=arxiv,
  year={2021}
}

% P-Tuning
@inproceedings{liu2021gpt,
  title={GPT understands, too},
  author={Liu, Xiao and Zheng, Yanan and Du, Zhengxiao and Ding, Ming and Qian, Yujie and Yang, Zhilin and Tang, Jie},
  booktitle=arxiv,
  year={2021}
}

% DART
@inproceedings{zhang2021differentiable,
  title="{Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners}",
  author={Zhang, Ningyu and Li, Luoqiu and Chen, Xiang and Deng, Shumin and Bi, Zhen and Tan, Chuanqi and Huang, Fei and Chen, Huajun},
  booktitle=iclr,
  year={2021}
}

% LM-BFF
@inproceedings{gao2021making,
  title="{Making Pre-trained Language Models Better Few-shot Learners}",
  author={Gao, Tianyu and Fisch, Adam and Chen, Danqi},
  booktitle=acl,
  year={2021}
}

@inproceedings{lester2021power,
  title="{The Power of Scale for Parameter-Efficient Prompt Tuning}",
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  booktitle=emnlp,
  year={2021}
}

@inproceedings{li2021prefix,
  title="{Prefix-Tuning: Optimizing Continuous Prompts for Generation}",
  author={Li, Xiang Lisa and Liang, Percy},
  booktitle=acl,
  year={2021}
}

@inproceedings{zhong2021factual,
  title="{Factual Probing Is [MASK]: Learning vs. Learning to Recall}",
  author={Zhong, Zexuan and Friedman, Dan and Chen, Danqi},
  booktitle=naacl,
  year={2021}
}

@inproceedings{shin2020autoprompt,
  title="{AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts}",
  author={Shin, Taylor and Razeghi, Yasaman and Logan IV, Robert L and Wallace, Eric and Singh, Sameer},
  booktitle=emnlp,
  year={2020}
}

@inproceedings{petroni2019language,
  title="{Language Models as Knowledge Bases?}",
  author={Petroni, Fabio and Rockt{\"a}schel, Tim and Riedel, Sebastian and Lewis, Patrick and Bakhtin, Anton and Wu, Yuxiang and Miller, Alexander},
  booktitle=emnlp,
  year={2019}
}

@article{grubbs-test,
  title="{Sample Criteria for Testing Outlying Observations}",
  author={Grubbs, Frank E},
  journal={The Annals of Mathematical Statistics},
  year={1950},
  publisher={JSTOR}
}

@article{mad,
  title="{Alternatives to the Median Absolute Deviation}",
  author={Rousseeuw, Peter J and Croux, Christophe},
  journal={Journal of the American Statistical association},
  year={1993},
  publisher={Taylor \& Francis}
}

@inproceedings{chen2021revisiting,
  title={Revisiting Self-training for Few-shot Learning of Language Model},
  author={Chen, Yiming and Zhang, Yan and Zhang, Chen and Lee, Grandee and Cheng, Ran and Li, Haizhou},
  booktitle=emnlp,
  year={2021}
}

@inproceedings{schick2021s,
  title="{Itâ€™s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners}",
  author={Schick, Timo and Sch{\"u}tze, Hinrich},
  booktitle=naacl,
  year={2021}
}


% RIPPLES
@inproceedings{kurita2020weight,
  title={Weight Poisoning Attacks on Pretrained Models},
  author={Kurita, Keita and Michel, Paul and Neubig, Graham},
  booktitle=acl,
  year={2020}
}

% POR
@inproceedings{shen2021backdoor,
  title={Backdoor Pre-trained Models Can Transfer to All},
  author={Shen, Lujia and Ji, Shouling and Zhang, Xuhong and Li, Jinfeng and Chen, Jing and Shi, Jie and Fang, Chengfang and Yin, Jianwei and Wang, Ting},
  booktitle=ccs,
  year={2021}
}

% StyleBkd
@inproceedings{qi2021mind,
  title={Mind the Style of Text! Adversarial and Backdoor Attacks Based on Text Style Transfer},
  author={Qi, Fanchao and Chen, Yangyi and Zhang, Xurui and Li, Mukai and Liu, Zhiyuan and Sun, Maosong},
  booktitle=emnlp,
  year={2021}
}

% SOS
@inproceedings{yang2021rethinking,
  title="{Rethinking Stealthiness of Backdoor Attack against NLP Models}",
  author={Yang, Wenkai and Lin, Yankai and Li, Peng and Zhou, Jie and Sun, Xu},
  booktitle=acl,
  year={2021}
}

% EP
@inproceedings{EP,
  title="{Be Careful about Poisoned Word Embeddings: Exploring the Vulnerability of the Embedding Layers in NLP Models}",
  author={Yang, Wenkai and Li, Lei and Zhang, Zhiyuan and Ren, Xuancheng and Sun, Xu and He, Bin},
  booktitle=naacl,
  year={2021}
}

% SynBkd
@inproceedings{qi2021hidden,
  title="{Hidden Killer: Invisible Textual Backdoor Attacks with Syntactic Trigger}",
  author={Qi, Fanchao and Li, Mukai and Chen, Yangyi and Zhang, Zhengyan and Liu, Zhiyuan and Wang, Yasheng and Sun, Maosong},
  booktitle=acl,
  year={2021}
}

@inproceedings{chen2021badpre,
  title="{BadPre: Task-agnostic Backdoor Attacks to Pre-trained NLP Foundation Models}",
  author={Chen, Kangjie and Meng, Yuxian and Sun, Xiaofei and Guo, Shangwei and Zhang, Tianwei and Li, Jiwei and Fan, Chun},
  booktitle=iclr,
  year={2021}
}

@inproceedings{zhang2021neural,
  title="{Neural Network Surgery: Injecting Data Patterns into Pre-trained Models with Minimal Instance-wise Side Effects}",
  author={Zhang, Zhiyuan and Ren, Xuancheng and Su, Qi and Sun, Xu and He, Bin},
  booktitle=naacl,
  year={2021}
}

@inproceedings{BadPrompt_NeurIPS2022,
title = "{BadPrompt: Backdoor Attacks on Continuous Prompts}",
author = {Cai, Xiangrui and Xu, Haidong and Xu, Sihan and Zhang, Ying and Yuan, Xiaojie},
booktitle = nips,
year = {2022}
}

@inproceedings{pan2022hidden,
  title="{Hidden Trigger Backdoor Attack on $\{$NLP$\}$ Models via Linguistic Style Manipulation}",
  author={Pan, Xudong and Zhang, Mi and Sheng, Beina and Zhu, Jiaming and Yang, Min},
  booktitle=sec,
  year={2022}
}

% BTop
@inproceedings{xu2022exploring,
    title = "{Exploring the Universal Vulnerability of Prompt-based Learning Paradigm}",
    author = "Xu, Lei  and Chen, Yangyi  and Cui, Ganqu  and Gao, Hongcheng  and Liu, Zhiyuan",
    booktitle=acl,
    year = {2022},
}

@inproceedings{duppt,
  title="{PPT: Backdoor Attacks on Pre-trained Models via Poisoned Prompt Tuning}",
  author={Du, Wei and Zhao, Yichun and Li, Boqun and Liu, Gongshen and Wang, Shilin},
  booktitle=ijcai,
  year={2022}
}

% AddSent
@article{dai2019backdoor,
  title="{A Backdoor Attack against LSTM-based Text Classification Systems}",
  author={Dai, Jiazhu and Chen, Chuanshuai and Li, Yufeng},
  journal={IEEE Access},
  volume={7},
  pages={138872--138878},
  year={2019},
  publisher={IEEE}
}

% TrojanLM
@inproceedings{zhang2021trojaning,
  title="{Trojaning Language Models for Fun and Profit}",
  author={Zhang, Xinyang and Zhang, Zheng and Ji, Shouling and Wang, Ting},
  booktitle=eurosp,
  year={2021}
}

% OpenBackdoor
@inproceedings{openbackdoor,
  title="{A Unified Evaluation of Textual Backdoor Learning: Frameworks and Benchmarks}",
  author={Cui, Ganqu and Yuan, Lifan and He, Bingxiang and Chen, Yangyi and Liu, Zhiyuan and Sun, Maosong},
  booktitle=nips,
  year={2022}
}

@inproceedings{garg2020can,
  title="{Can Adversarial Weight Perturbations Inject Neural Backdoors}",
  author={Garg, Siddhant and Kumar, Adarsh and Goel, Vibhor and Liang, Yingyu},
  booktitle=cikm,
  year={2020}
}

@inproceedings{chen2021badnl,
  title="{Badnl: Backdoor Attacks against NLP Models}",
  author={Chen, Xiaoyi and Salem, Ahmed and Backes, Michael and Ma, Shiqing and Zhang, Yang},
  booktitle={ICML 2021 Workshop on Adversarial Machine Learning},
  year={2021}
}

% LWP
@inproceedings{li2021backdoor,
  title="{Backdoor Attacks on Pre-trained Models by Layerwise Weight Poisoning}",
  author={Li, Linyang and Song, Demin and Li, Xiaonan and Zeng, Jiehang and Ma, Ruotian and Qiu, Xipeng},
  booktitle=emnlp,
  year={2021}
}



@inproceedings{imc, 
    author = {Pang, Ren and Shen, Hua and Zhang, Xinyang and Ji, Shouling and Vorobeychik, Yevgeniy and Luo, Xiapu and Liu, Alex and Wang, Ting}, 
    title = {A Tale of Evil Twins: Adversarial Inputs versus Poisoned Models}, 
    year = {2020}, 
    booktitle = ccs,
}


@inproceedings{trojanlm,
    author = {{Zhang}, Xinyang and {Zhang}, Zheng and {Ji}, Shouling and {Wang}, Ting},
    title = {Trojaning Language Models for Fun and Profit},
    year = {2021},
    booktitle = eurosp,
}

# security


@inproceedings{yao2019latent,
  title="{Latent Backdoor Attacks on Deep Neural Networks}",
  author={Yao, Yuanshun and Li, Huiying and Zheng, Haitao and Zhao, Ben Y},
  booktitle=ccs,
  year={2019}
}

@inproceedings{li2021neural,
  title="{Neural Attention Distillation: Erasing Backdoor Triggers from Deep Neural Networks}",
  author={Li, Yige and Lyu, Xixiang and Koren, Nodens and Lyu, Lingjuan and Li, Bo and Ma, Xingjun},
  booktitle=iclr,
  year={2021}
}

@inproceedings{chen2017targeted,
  title="{Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning}",
  author={Chen, Xinyun and Liu, Chang and Li, Bo and Lu, Kimberly and Song, Dawn},
  booktitle=arxiv,
  year={2017}
}

@inproceedings{gu2017badnets,
  title="{Badnets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain}",
  author={Gu, Tianyu and Dolan-Gavitt, Brendan and Garg, Siddharth},
  booktitle=arxiv,
  year={2017}
}

@inproceedings{wang2019neural,
  title="{Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks}",
  author={Wang, Bolun and Yao, Yuanshun and Shan, Shawn and Li, Huiying and Viswanath, Bimal and Zheng, Haitao and Zhao, Ben Y},
  booktitle=sp,
  year={2019}
}

@inproceedings{chen2019deepinspect,
  title="{DeepInspect: A Black-box Trojan Detection and Mitigation Framework for Deep Neural Networks.}",
  author={Chen, Huili and Fu, Cheng and Zhao, Jishen and Koushanfar, Farinaz},
  booktitle=ijcai,
  year={2019}
}

# security



@inproceedings{azizi2021t,
  title="{$\{$T-Miner$\}$: A Generative Approach to Defend Against Trojan Attacks on $\{$DNN-based$\}$ Text Classification}",
  author={Azizi, Ahmadreza and Tahmid, Ibrahim Asadullah and Waheed, Asim and Mangaokar, Neal and Pu, Jiameng and Javed, Mobin and Reddy, Chandan K and Viswanath, Bimal},
  booktitle=sec,
  year={2021}
}

@inproceedings{qi2021onion,
  title="{ONION: A Simple and Effective Defense Against Textual Backdoor Attacks}",
  author={Qi, Fanchao and Chen, Yangyi and Li, Mukai and Yao, Yuan and Liu, Zhiyuan and Sun, Maosong},
  booktitle=emnlp,
  year={2021}
}

@inproceedings{yang2021rap,
  title="{RAP: Robustness-Aware Perturbations for Defending against Backdoor Attacks on NLP Models}",
  author={Yang, Wenkai and Lin, Yankai and Li, Peng and Zhou, Jie and Sun, Xu},
  booktitle=emnlp,
  year={2021}
}

% BKI
@article{chen2021mitigating,
  title="{Mitigating Backdoor Attacks in LSTM-based Text Classification Systems by Backdoor Keyword Identification}",
  author={Chen, Chuanshuai and Dai, Jiazhu},
  journal={Neurocomputing},
  volume={452},
  pages={253--262},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{liu2022piccolo,
  title="{PICCOLO: Exposing Complex Backdoors in NLP Transformer Models}",
  author={Liu, Yingqi and Shen, Guangyu and Tao, Guanhong and An, Shengwei and Ma, Shiqing and Zhang, Xiangyu},
  booktitle=sp,
  year={2022},
}

@inproceedings{pmlr-v162-shen22e,
  title = "{Constrained Optimization with Dynamic Bound-scaling for Effective {NLP} Backdoor Defense}",
  author = {Shen, Guangyu and Liu, Yingqi and Tao, Guanhong and Xu, Qiuling and Zhang, Zhuo and An, Shengwei and Ma, Shiqing and Zhang, Xiangyu},
  booktitle = icml,
  year = {2022}
}

@inproceedings{lyu-etal-2022-study,
    title = "{A Study of the Attention Abnormality in Trojaned {BERT}s}",
    author = {Lyu, Weimin and Zheng, Songzhu  and Ma, Tengfei  and Chen, Chao},
    booktitle = naacl,
    year = {2022},
}

@article{zhang2022fine,
  title="{Fine-mixing: Mitigating Backdoors in Fine-tuned Language Models}",
  author={Zhang, Zhiyuan and Lyu, Lingjuan and Ma, Xingjun and Wang, Chenguang and Sun, Xu},
  journal={EMNLP Findings},
  year={2022}
}

@inproceedings{zhu2022moderatefitting,
    title="{Moderate-fitting as a Natural Backdoor Defender for Pre-trained Language Models}",
    author={Biru Zhu and Yujia Qin and Ganqu Cui and Yangyi Chen and Weilin Zhao and Chong Fu and Yangdong Deng and Zhiyuan Liu and Jingang Wang and Wei Wu and Maosong Sun and Ming Gu},
    booktitle=nips,
    year={2022}
}

@article{chen2022expose,
  title="{Expose Backdoors on the Way: A Feature-Based Efficient Defense against Textual Backdoor Attacks}",
  author={Chen, Sishuo and Yang, Wenkai and Zhang, Zhiyuan and Bi, Xiaohan and Sun, Xu},
  journal={Findings of EMNLP},
  year={2022}
}

% Strip
@article{gao2021design,
  title="{Design and Evaluation of a Multi-domain Trojan Detection Method on Deep Neural Networks}",
  author={Gao, Yansong and Kim, Yeonjae and Doan, Bao Gia and Zhang, Zhi and Zhang, Gongxuan and Nepal, Surya and Ranasinghe, Damith C and Kim, Hyoungshick},
  journal={IEEE Transactions on Dependable and Secure Computing},
  volume={19},
  number={4},
  pages={2349--2364},
  year={2021},
  publisher={IEEE}
}


% SST-2
@inproceedings{socher2013recursive,
  title="{Recursive Deep Models for Semantic Compositionality over a Sentiment Treebank}",
  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
  booktitle=emnlp,
  year={2013}
}

% OffensEval
@inproceedings{zampieri2019semeval,
  title="{SemEval-2019 Task 6: Identifying and Categorizing Offensive Language in Social Media (OffensEval)}",
  author={Zampieri, Marcos and Malmasi, Shervin and Nakov, Preslav and Rosenthal, Sara and Farra, Noura and Kumar, Ritesh},
  booktitle={Proceedings of the 13th International Workshop on Semantic Evaluation},
  year={2019}
}

% IMDB
@inproceedings{maas-etal-2011-learning,
    title = "{Learning Word Vectors for Sentiment Analysis}",
    author = {Maas, Andrew L.  and
      Daly, Raymond E.  and
      Pham, Peter T.  and
      Huang, Dan  and
      Ng, Andrew Y.  and
      Potts, Christopher},
    booktitle = acl,
    year = {2011}
}

% Amazon
@inproceedings{blitzer-etal-2007-biographies,
    title = "{Biographies, {B}ollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification}",
    author = "Blitzer, John  and
      Dredze, Mark  and
      Pereira, Fernando",
    booktitle = acl,
    year = {2007}
}

% Yelp
@inproceedings{NIPS2015_250cf8b5,
 title = "{Character-level Convolutional Networks for Text Classification}",
 author = {Zhang, Xiang and Zhao, Junbo and LeCun, Yann},
 booktitle = nips,
 year = {2015}
}

% Twitter
@inproceedings{founta2018large,
  title="{Large Scale Crowdsourcing and Characterization of Twitter Abusive Behavior}",
  author={Founta, Antigoni Maria and Djouvas, Constantinos and Chatzakou, Despoina and Leontiadis, Ilias and Blackburn, Jeremy and Stringhini, Gianluca and Vakali, Athena and Sirivianos, Michael and Kourtellis, Nicolas},
  booktitle={Proceedings of International AAAI Conference on Web and Social Media},
  year={2018}
}

%LingSpam
@article{sakkis2003memory,
  title="{A Memory-based Approach to Anti-spam Filtering for Mailing Lists}",
  author={Sakkis, Georgios and Androutsopoulos, Ion and Paliouras, Georgios and Karkaletsis, Vangelis and Spyropoulos, Constantine D and Stamatopoulos, Panagiotis},
  journal={Information retrieval},
  volume={6},
  number={1},
  pages={49--73},
  year={2003},
  publisher={Springer}
}

% MR
@inproceedings{MR,
  title="{Seeing Stars: Exploiting Class Relationships for Sentiment Categorization with Respect to Rating Scales}",
  author={Pang, Bo and Lee, Lillian},
  booktitle=acl,
  year={2005}
}

% CR
@inproceedings{CR,
  title="{Mining and Summarizing Customer Reviews}",
  author={Hu, Minqing and Liu, Bing},
  booktitle=kdd,
  year={2004}
}

% MPQA
@article{MPQA,
  title="{Annotating Expressions of Opinions and Emotions in Language}",
  author={Wiebe, Janyce and Wilson, Theresa and Cardie, Claire},
  journal={Language resources and evaluation},
  volume={39},
  number={2},
  pages={165--210},
  year={2005},
  publisher={Springer}
}

% Subj
@inproceedings{Subj,
  title="{A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization based on Minimum Cuts}",
  author={Pang, Bo and Lee, Lillian},
  booktitle=acl,
  year={2004}
}

% TREC
@inproceedings{TREC,
  title="{Building a Question Answering Test Collection}",
  author={Voorhees, Ellen M and Tice, Dawn M},
  booktitle={Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval},
  year={2000}
}


@article{wang2020generalizing,
  title="{Generalizing from a Few Examples: A Survey on Few-shot Learning}",
  author={Wang, Yaqing and Yao, Quanming and Kwok, James T and Ni, Lionel M},
  journal={ACM computing surveys (csur)},
  volume={53},
  number={3},
  pages={1--34},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@inproceedings{miyato2016adversarial,
  title="{Adversarial Training Methods for Semi-Supervised Text Classification}",
  author={Miyato, Takeru and Dai, Andrew M and Goodfellow, Ian},
  booktitle=iclr,
  year={2017}
}

@inproceedings{NEURIPS2020_44feb009,
 title = "{Unsupervised Data Augmentation for Consistency Training}",
 author = {Xie, Qizhe and Dai, Zihang and Hovy, Eduard and Luong, Thang and Le, Quoc},
 booktitle = nips,
 year = {2020}
}

@inproceedings{yu-etal-2018-diverse,
    title = "{Diverse Few-Shot Text Classification with Multiple Metrics}",
    author = {Yu, Mo  and
      Guo, Xiaoxiao  and
      Yi, Jinfeng  and
      Chang, Shiyu  and
      Potdar, Saloni  and
      Cheng, Yu  and
      Tesauro, Gerald  and
      Wang, Haoyu  and
      Zhou, Bowen},
    booktitle = naacl,
    year = {2018}
}

@inproceedings{yin-etal-2020-universal,
    title = "{Universal Natural Language Processing with Limited Annotations: Try Few-shot Textual Entailment as a Start}",
    author = {Yin, Wenpeng  and
      Rajani, Nazneen Fatema  and
      Radev, Dragomir  and
      Socher, Richard  and
      Xiong, Caiming},
    booktitle = emnlp,
    year = {2020}
}

@inproceedings{yu-etal-2020-bridging,
    title = "{Bridging Text and Knowledge with Multi-Prototype Embedding for Few-Shot Relational Triple Extraction}",
    author = "Yu, Haiyang  and
      Zhang, Ningyu  and
      Deng, Shumin  and
      Ye, Hongbin  and
      Zhang, Wei  and
      Chen, Huajun",
    booktitle = {Proceedings of International Conference on Computational Linguistics},
    year = {2020}
}

@inproceedings{zhang2020revisiting,
  title="{Revisiting Few-sample BERT Fine-tuning}",
  author={Zhang, Tianyi and Wu, Felix and Katiyar, Arzoo and Weinberger, Kilian Q and Artzi, Yoav},
  booktitle=iclr,
  year={2020}
}

@article{zero-shot-tuning,
  title="{Finetuned Language Models are Zero-shot Learners}",
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent Y and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  booktitle=iclr,
  year={2021}
}

@article{wang2019survey,
  title={A survey of zero-shot learning: Settings, methods, and applications},
  author={Wang, Wei and Zheng, Vincent W and Yu, Han and Miao, Chunyan},
  journal={ACM Transactions on Intelligent Systems and Technology (TIST)},
  volume={10},
  number={2},
  pages={1--37},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@article{vinyals2016matching,
  title={Matching networks for one shot learning},
  author={Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and Wierstra, Daan and others},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}


@inproceedings{devlin2018bert,
  title="{BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}",
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle=naacl,
  year={2019}
}

% GPT-2
@article{radford2019language,
  title="{Language Models are Unsupervised Multitask Learners}",
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

% T5
@article{raffel2020exploring,
  title="{Exploring the Limits of Transfer Learning with a Unified Text-to-text Transformer.}",
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J and others},
  journal={J. Mach. Learn. Res.},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

% GPT-3
@inproceedings{brown2020language,
  title="{Language Models are Few-shot Learners}",
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  booktitle=nips,
  year={2020}
}

@inproceedings{liu2019roberta,
  title="{Roberta: A Robustly Optimized BERT Pretraining Approach}",
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  booktitle=arxiv,
  year={2019}
}

