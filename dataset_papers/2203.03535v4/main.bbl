\begin{thebibliography}{10}

\bibitem{Busoniu2010}
Lucian Bu{\c{s}}oniu, Robert Babu{\v{s}}ka, and Bart De~Schutter.
\newblock {\em Multi-agent Reinforcement Learning: An Overview}, pages
  183--221.
\newblock Springer Berlin Heidelberg, Berlin, Heidelberg, 2010.

\bibitem{papoudakis19nonstationarity}
Georgios Papoudakis, Filippos Christianos, Arrasy Rahman, and Stefano~V.
  Albrecht.
\newblock Dealing with non-stationarity in multi-agent deep reinforcement
  learning.
\newblock {\em CoRR}, abs/1906.04737, 2019.

\bibitem{Nash48}
John~F. Nash.
\newblock Equilibrium points in n-person games.
\newblock {\em Proceedings of the National Academy of Sciences}, 36(1):48--49,
  1950.

\bibitem{zinkevich06cyclic}
Martin Zinkevich, Amy Greenwald, and Michael Littman.
\newblock Cyclic equilibria in markov games.
\newblock In {\em Neural Information Processing Systems (NeurIPS)}, volume~18.
  MIT Press, 2006.

\bibitem{Nowe2012}
Ann Now{\'e}, Peter Vrancx, and Yann-Micha{\"e}l De~Hauwere.
\newblock {\em Game Theory and Multi-agent Reinforcement Learning}, pages
  441--470.
\newblock Springer Berlin Heidelberg, Berlin, Heidelberg, 2012.

\bibitem{foerster17lola}
Jakob Foerster, Richard~Y. Chen, Maruan Al-Shedivat, Shimon Whiteson, Pieter
  Abbeel, and Igor Mordatch.
\newblock Learning with opponent-learning awareness.
\newblock In {\em International Conference on Autonomous Agents and MultiAgent
  Systems (AAMAS)}, page 122–130, Richland, SC, 2018.

\bibitem{letcher2018stable}
Alistair Letcher, Jakob Foerster, David Balduzzi, Tim Rocktäschel, and Shimon
  Whiteson.
\newblock Stable opponent shaping in differentiable games.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2019.

\bibitem{xie20lili}
Annie Xie, Dylan Losey, Ryan Tolsma, Chelsea Finn, and Dorsa Sadigh.
\newblock Learning latent representations to influence multi-agent interaction.
\newblock In {\em Conference on Robot Learning (CoRL)}, 2020.

\bibitem{kim21metamapg}
Dong~Ki Kim, Miao Liu, Matthew~D Riemer, Chuangchuang Sun, Marwa Abdulhai,
  Golnaz Habibi, Sebastian Lopez-Cot, Gerald Tesauro, and Jonathan How.
\newblock A policy gradient algorithm for learning to learn in multiagent
  reinforcement learning.
\newblock In {\em International Conference on Machine Learning (ICML)}, volume
  139, pages 5541--5550. PMLR, 18--24 Jul 2021.

\bibitem{wang2021influencing}
Woodrow~Zhouyuan Wang, Andy Shih, Annie Xie, and Dorsa Sadigh.
\newblock Influencing towards stable multi-agent interactions.
\newblock In {\em Conference on Robot Learning (CoRL)}, 2021.

\bibitem{lu2022modelfree}
Christopher Lu, Timon Willi, Christian A~Schroeder De~Witt, and Jakob Foerster.
\newblock Model-free opponent shaping.
\newblock In {\em International Conference on Machine Learning (ICML)}, volume
  162 of {\em Proceedings of Machine Learning Research}, pages 14398--14411.
  PMLR, 2022.

\bibitem{lowe17maddpg}
Ryan Lowe, Yi~Wu, Aviv Tamar, Jean Harb, OpenAI~Pieter Abbeel, and Igor
  Mordatch.
\newblock Multi-agent actor-critic for mixed cooperative-competitive
  environments.
\newblock In {\em Neural Information Processing Systems (NeurIPS)}, pages
  6382--6393, 2017.

\bibitem{forester17coma}
Jakob Foerster, Gregory Farquhar, Triantafyllos Afouras, Nantas Nardelli, and
  Shimon Whiteson.
\newblock Counterfactual multi-agent policy gradients.
\newblock {\em Association for the Advancement of Artificial Intelligence
  (AAAI)}, 32(1), Apr. 2018.

\bibitem{iqbal19masac}
Shariq Iqbal and Fei Sha.
\newblock Actor-attention-critic for multi-agent reinforcement learning.
\newblock In {\em International Conference on Machine Learning (ICML)},
  volume~97, pages 2961--2970. PMLR, 09--15 Jun 2019.

\bibitem{kearns2002near}
Michael Kearns and Satinder Singh.
\newblock Near-optimal reinforcement learning in polynomial time.
\newblock {\em Machine learning}, 49(2), 2002.

\bibitem{yang18mean-field-marl}
Yaodong Yang, Rui Luo, Minne Li, Ming Zhou, Weinan Zhang, and Jun Wang.
\newblock Mean field multi-agent reinforcement learning.
\newblock In {\em International Conference on Machine Learning (ICML)},
  volume~80, pages 5571--5580, 10--15 Jul 2018.

\bibitem{puterman94mdp}
Martin~L. Puterman.
\newblock {\em Markov Decision Processes: Discrete Stochastic Dynamic
  Programming}.
\newblock John Wiley \& Sons, Inc., USA, 1st edition, 1994.

\bibitem{sutton98rlbook}
Richard~S. Sutton and Andrew~G. Barto.
\newblock {\em Reinforcement Learning: An Introduction}.
\newblock The MIT Press, second edition, 2018.

\bibitem{alshedivat2018continuous}
Maruan Al-Shedivat, Trapit Bansal, Yura Burda, Ilya Sutskever, Igor Mordatch,
  and Pieter Abbeel.
\newblock Continuous adaptation via meta-learning in nonstationary and
  competitive environments.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2018.

\bibitem{daskalakis22gametheory}
Constantinos Daskalakis, Noah Golowich, and Kaiqing Zhang.
\newblock The complexity of markov equilibrium in stochastic games.
\newblock {\em CoRR}, abs/2204.03991, 2022.

\bibitem{correlated87}
Robert~J. Aumann.
\newblock Correlated equilibrium as an expression of bayesian rationality.
\newblock {\em Econometrica}, 55(1):1--18, 1987.

\bibitem{foster90stochastic}
Dean Foster and Peyton Young.
\newblock Stochastic evolutionary game dynamics.
\newblock {\em Theoretical Population Biology}, 38(2):219--232, 1990.

\bibitem{freidlin2012random}
M.I. Freidlin, J.~Sz{\"u}cs, and A.D. Wentzell.
\newblock {\em Random Perturbations of Dynamical Systems}.
\newblock Grundlehren der mathematischen Wissenschaften. Springer, 2012.

\bibitem{chasparis12stochastic}
Georgios Chasparis and {Jeff S.} Shamma.
\newblock Distributed dynamic reinforcement of efficient outcomes in multiagent
  coordination and network formation.
\newblock {\em Dynamic Games and Applications}, 2(1):18--50, 2012.

\bibitem{chasparis19perturb}
Georgios~C. Chasparis.
\newblock Stochastic stability of perturbed learning automata in
  positive-utility games.
\newblock {\em IEEE Transactions on Automatic Control}, 64(11):4454--4469,
  2019.

\bibitem{wicks05ssd}
John~R. Wicks and Amy Greenwald.
\newblock An algorithm for computing stochastically stable distributions with
  applications to multiagent learning in repeated games.
\newblock In {\em Conference on Uncertainty in Artificial Intelligence (UAI)},
  UAI'05, page 623–632, 2005.

\bibitem{haarnoja18sac}
Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock In {\em International Conference on Machine Learning (ICML)},
  volume~80, pages 1861--1870. PMLR, 2018.

\bibitem{blei17variational}
David~M. Blei, Alp Kucukelbir, and Jon~D. McAuliffe.
\newblock Variational inference: A review for statisticians.
\newblock {\em Journal of the American Statistical Association},
  112(518):859–877, Apr 2017.

\bibitem{imaml}
Aravind Rajeswaran, Chelsea Finn, Sham~M Kakade, and Sergey Levine.
\newblock Meta-learning with implicit gradients.
\newblock {\em Neural Information Processing Systems (NeurIPS)}, 32, 2019.

\bibitem{deleu2022continuous}
Tristan Deleu, David Kanaa, Leo Feng, Giancarlo Kerg, Yoshua Bengio, Guillaume
  Lajoie, and Pierre-Luc Bacon.
\newblock Continuous-time meta-learning with forward mode differentiation.
\newblock {\em arXiv preprint arXiv:2203.01443}, 2022.

\bibitem{christodoulou2019soft}
Petros Christodoulou.
\newblock Soft actor-critic for discrete action settings.
\newblock {\em CoRR}, abs/1910.07207, 2019.

\bibitem{zheng2018magent}
Lianmin Zheng, Jiacheng Yang, Han Cai, Ming Zhou, Weinan Zhang, Jun Wang, and
  Yong Yu.
\newblock Magent: A many-agent reinforcement learning platform for artificial
  collective intelligence.
\newblock In {\em Association for the Advancement of Artificial Intelligence
  (AAAI)}, 2018.

\bibitem{Watkins92q-learning}
Christopher J. C.~H. Watkins and Peter Dayan.
\newblock Q-learning.
\newblock In {\em Machine Learning}, pages 279--292, 1992.

\bibitem{hernandezLealK17survey}
Pablo Hernandez{-}Leal, Michael Kaisers, Tim Baarslag, and Enrique~Munoz
  de~Cote.
\newblock A survey of learning in multiagent environments: Dealing with
  non-stationarity.
\newblock {\em CoRR}, abs/1707.09183, 2017.

\bibitem{omidshafiei19teach}
Shayegan Omidshafiei, Dong-Ki Kim, Miao Liu, Gerald Tesauro, Matthew Riemer,
  Christopher Amato, Murray Campbell, and Jonathan~P. How.
\newblock Learning to teach in cooperative multiagent reinforcement learning.
\newblock In {\em Association for the Advancement of Artificial Intelligence
  (AAAI)}. AAAI Press, 2019.

\bibitem{wadhwania2019policy}
Samir Wadhwania, Dong-Ki Kim, Shayegan Omidshafiei, and Jonathan~P. How.
\newblock Policy distillation and value matching in multiagent reinforcement
  learning.
\newblock In {\em International Conference on Intelligent Robots and Systems
  (IROS)}, pages 8193--8200, 2019.

\bibitem{kim20hmat}
Dong-Ki Kim, Miao Liu, Shayegan Omidshafiei, Sebastian Lopez-Cot, Matthew
  Riemer, Golnaz Habibi, Gerald Tesauro, Sami Mourad, Murray Campbell, and
  Jonathan~P. How.
\newblock Learning hierarchical teaching policies for cooperative agents.
\newblock In {\em International Conference on Autonomous Agents and MultiAgent
  Systems (AAMAS)}, AAMAS '20, page 620–628, Richland, SC, 2020.
  International Foundation for Autonomous Agents and Multiagent Systems.

\bibitem{he16opponent-modeling}
He~He, Jordan Boyd-Graber, Kevin Kwok, and Hal~Daumé III.
\newblock Opponent modeling in deep reinforcement learning.
\newblock In {\em International Conference on Machine Learning (ICML)},
  volume~48, pages 1804--1813, 20--22 Jun 2016.

\bibitem{raileanu18opponent-modeling}
Roberta Raileanu, Emily Denton, Arthur Szlam, and Rob Fergus.
\newblock Modeling others using oneself in multi-agent reinforcement learning.
\newblock In {\em International Conference on Machine Learning (ICML)},
  volume~80, pages 4257--4266, 10--15 Jul 2018.

\bibitem{grover18policy-representation}
Aditya Grover, Maruan Al-Shedivat, Jayesh Gupta, Yuri Burda, and Harrison
  Edwards.
\newblock Learning policy representations in multiagent systems.
\newblock In {\em International Conference on Machine Learning (ICML)},
  volume~80, pages 1802--1811, 10--15 Jul 2018.

\bibitem{wen2018probabilistic}
Ying Wen, Yaodong Yang, Rui Luo, Jun Wang, and Wei Pan.
\newblock Probabilistic recursive reasoning for multi-agent reinforcement
  learning.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2019.

\bibitem{zhang10lookahead}
Chongjie Zhang and Victor~R. Lesser.
\newblock Multi-agent learning with policy prediction.
\newblock In {\em Association for the Advancement of Artificial Intelligence
  (AAAI)}, 2010.

\bibitem{foerster2018dice}
Jakob Foerster, Gregory Farquhar, Maruan Al-Shedivat, Tim Rockt{\"a}schel, Eric
  Xing, and Shimon Whiteson.
\newblock {D}i{CE}: The infinitely differentiable {M}onte {C}arlo estimator.
\newblock In {\em International Conference on Machine Learning (ICML)},
  volume~80, pages 1524--1533. PMLR, 2018.

\bibitem{balaguer2022good}
Jan Balaguer, Raphael Koster, Christopher Summerfield, and Andrea Tacchetti.
\newblock The good shepherd: An oracle agent for mechanism design.
\newblock {\em arXiv preprint arXiv:2202.10135}, 2022.

\bibitem{jaques19social}
Natasha Jaques, Angeliki Lazaridou, Edward Hughes, Caglar Gulcehre, Pedro
  Ortega, Dj~Strouse, Joel~Z. Leibo, and Nando De~Freitas.
\newblock Social influence as intrinsic motivation for multi-agent deep
  reinforcement learning.
\newblock In {\em International Conference on Machine Learning (ICML)},
  volume~97, pages 3040--3049. PMLR, 2019.

\bibitem{wang19}
Jane~X. Wang, Edward Hughes, Chrisantha Fernando, Wojciech~M. Czarnecki,
  Edgar~A. Du\'{e}\~{n}ez Guzm\'{a}n, and Joel~Z. Leibo.
\newblock Evolving intrinsic motivations for altruistic behavior.
\newblock In {\em International Conference on Autonomous Agents and MultiAgent
  Systems (AAMAS)}, page 683–692, Richland, SC, 2019.

\bibitem{yang20}
Jiachen Yang, Ang Li, Mehrdad Farajtabar, Peter Sunehag, Edward Hughes, and
  Hongyuan Zha.
\newblock Learning to incentivize other learning agents.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin,
  editors, {\em Neural Information Processing Systems (NeurIPS)}, volume~33,
  pages 15208--15219. Curran Associates, Inc., 2020.

\bibitem{yang22}
Jiachen Yang, Ethan Wang, Rakshit Trivedi, Tuo Zhao, and Hongyuan Zha.
\newblock Adaptive incentive design with multi-agent meta-gradient
  reinforcement learning.
\newblock In {\em International Conference on Autonomous Agents and MultiAgent
  Systems (AAMAS)}, page 1436–1445, Richland, SC, 2022.

\bibitem{leibo17socialdilemmas}
Joel~Z. Leibo, Vinicius Zambaldi, Marc Lanctot, Janusz Marecki, and Thore
  Graepel.
\newblock Multi-agent reinforcement learning in sequential social dilemmas.
\newblock In {\em International Conference on Autonomous Agents and MultiAgent
  Systems (AAMAS)}, page 464–473, Richland, SC, 2017. International
  Foundation for Autonomous Agents and Multiagent Systems.

\bibitem{wang19ssd}
Weixun Wang, Jianye Hao, Yixi Wang, and Matthew Taylor.
\newblock Achieving cooperation through deep multiagent reinforcement learning
  in sequential prisoner's dilemmas.
\newblock In {\em International Conference on Distributed Artificial
  Intelligence (DAI)}, 2019.

\bibitem{littman94markov}
Michael~L. Littman.
\newblock Markov games as a framework for multi-agent reinforcement learning.
\newblock In {\em International Conference on Machine Learning (ICML)}, pages
  157--163. Morgan Kaufmann Publishers Inc., 1994.

\bibitem{littman01friendfoe}
Michael~L. Littman.
\newblock Friend-or-foe q-learning in general-sum games.
\newblock In {\em International Conference on Machine Learning (ICML)}, page
  322–328, San Francisco, CA, USA, 2001. Morgan Kaufmann Publishers Inc.

\bibitem{wang02nash}
Xiaofeng Wang and Tuomas Sandholm.
\newblock Reinforcement learning to play an optimal nash equilibrium in team
  markov games.
\newblock In {\em Neural Information Processing Systems (NeurIPS)}, page
  1603–1610. MIT Press, 2002.

\bibitem{greenwald03correlated}
Amy Greenwald and Keith Hall.
\newblock Correlated-{Q} learning.
\newblock In {\em International Conference on Machine Learning (ICML)}, page
  242–249. AAAI Press, 2003.

\bibitem{bowling05convergence}
Michael Bowling.
\newblock Convergence and no-regret in multiagent learning.
\newblock In {\em Neural Information Processing Systems (NeurIPS)}, pages
  209--216. MIT Press, 2005.

\bibitem{Zintgraf2020VariBAD}
Luisa Zintgraf, Kyriacos Shiarlis, Maximilian Igl, Sebastian Schulze, Yarin
  Gal, Katja Hofmann, and Shimon Whiteson.
\newblock Varibad: A very good method for bayes-adaptive deep rl via
  meta-learning.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2020.

\bibitem{he16dron}
He~He, Jordan~L. Boyd{-}Graber, Kevin Kwok, and Hal~Daum{\'{e}} III.
\newblock Opponent modeling in deep reinforcement learning.
\newblock {\em CoRR}, abs/1609.05559, 2016.

\bibitem{mnih13dqn}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis
  Antonoglou, Daan Wierstra, and Martin~A. Riedmiller.
\newblock Playing atari with deep reinforcement learning.
\newblock {\em CoRR}, abs/1312.5602, 2013.

\end{thebibliography}
