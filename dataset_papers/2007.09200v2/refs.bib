
%Aigaion2 BibTeX export from LISA - Publications
%Wednesday 03 June 2020 09:39:43 PM

@article{sulam2019multi,
  title={On multi-layer basis pursuit, efficient algorithms and convolutional neural networks},
  author={Sulam, Jeremias and Aberdam, Aviad and Beck, Amir and Elad, Michael},
  journal={IEEE Trans. PAMI},
  year={2019},
}

@inproceedings{uesato2018adversarial,
  title={Adversarial risk and the dangers of evaluating against weak attacks},
  author={Uesato, Jonathan and O'Donoghue, Brendan and Oord, Aaron van den and Kohli, Pushmeet},
  booktitle={ICML},
  year={2018}
}

@article{zagoruyko2016wide,
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv:1605.07146},
  year={2016}
}

@inproceedings{warde-farley+al-2017-denoisegan-iclr,
  title={Improving Generative Adversarial Networks With Denoising Feature Matching},
  author={Warde-Farley, David and Bengio, Yoshua},
  booktitle={ICLR},
  year={2017}
}

@inproceedings{wang2018feedback,
  title={Feedback-prop: Convolutional neural network inference under partial evidence},
  author={Wang, Tianlu and Yamaguchi, Kota and Ordonez, Vicente},
  booktitle={CVPR},
  year={2018}
}

@inproceedings{meng_magnet_2017,
  title={MagNet: a  two-pronged  defense  against  adversarial  examples},
  author={Meng, Dongyu and Chen, Hao},
  booktitle={CCS},
  year={2017}
}

@article{kar_evidence_2019,
	title = {Evidence that recurrent circuits are critical to the ventral stream’s execution of core object recognition behavior},
	journal = {Nature Neuroscience},
	author = {Kar, Kohitij and Kubilius, Jonas and Schmidt, Kailyn and Issa, Elias B. and DiCarlo, James J.},
	year = {2019}
}

@inproceedings{lamb_state-reification_2019,
  title={State-Reification Networks: Improving Generalization by Modeling the Distribution of Hidden Representations},
  author={Lamb, Alex and Binas, Jonathan and Goyal, Anirudh and Subramanian, Sandeep and Mitliagkas, Ioannis and Kazakov, Denis and Bengio, Yoshua and Mozer, Michael C.},
  booktitle={ICML},
  year={2019}
}

@article{bengio_consciousness_2019,
	title = {The consciousness prior},
	journal = {arXiv:1709.08568},
	author = {Bengio, Yoshua},
	year = {2019}
}

@article{nimmagadda2015multi,
  title={Multi-object classification and unsupervised scene understanding using deep learning features and latent tree probabilistic models},
  author={Nimmagadda, Tejaswi and Anandkumar, Anima},
  journal={arXiv:1505.00308},
  year={2015}
}

@article{piekniewski2016unsupervised,
  title={Unsupervised learning from continuous video in a scalable predictive recurrent network},
  author={Piekniewski, Filip and Laurent, Patryk and Petre, Csaba and Richert, Micah and Fisher, Dimitry and Hylton, Todd},
  journal={arXiv:1607.06854},
  year={2016}
}

@inproceedings{lee2015difference,
  title={Difference target propagation},
  author={Lee, Dong-Hyun and Zhang, Saizheng and Fischer, Asja and Bengio, Yoshua},
  booktitle={ECML-PKDD},
  year={2015},
}

@article{meulemans2020theoretical,
  title={A Theoretical Framework for Target Propagation},
  author={Meulemans, Alexander and Carzaniga, Francesco S and Suykens, Johan AK and Sacramento, Jo{\~a}o and Grewe, Benjamin F},
  journal={arXiv:2006.14331},
  year={2020}
}


@article{gilmer_adversarial_2018,
	title = {Adversarial {Spheres}},
	
	abstract = {State of the art computer vision models have been shown to be vulnerable to small adversarial perturbations of the input. In other words, most images in the data distribution are both correctly classified by the model and are very close to a visually similar misclassified image. Despite substantial research interest, the cause of the phenomenon is still poorly understood and remains unsolved. We hypothesize that this counter intuitive behavior is a naturally occurring result of the high dimensional geometry of the data manifold. As a first step towards exploring this hypothesis, we study a simple synthetic dataset of classifying between two concentric high dimensional spheres. For this dataset we show a fundamental tradeoff between the amount of test error and the average distance to nearest error. In particular, we prove that any model which misclassifies a small constant fraction of a sphere will be vulnerable to adversarial perturbations of size \$O(1/{\textbackslash}sqrt\{d\})\$. Surprisingly, when we train several different architectures on this dataset, all of their error sets naturally approach this theoretical bound. As a result of the theory, the vulnerability of neural networks to small adversarial perturbations is a logical consequence of the amount of test error observed. We hope that our theoretical analysis of this very simple case will point the way forward to explore how the geometry of complex real-world data sets leads to adversarial examples.},
	urldate = {2020-06-04},
	journal = {arXiv:1801.02774 [cs]},
	author = {Gilmer, Justin and Metz, Luke and Faghri, Fartash and Schoenholz, Samuel S. and Raghu, Maithra and Wattenberg, Martin and Goodfellow, Ian},
	month = sep,
	year = {2018},
	note = {arXiv: 1801.02774},
	keywords = {68T45, Computer Science - Computer Vision and Pattern Recognition, I.2.6},
	file = {arXiv Fulltext PDF:/Users/jamesgornet/Zotero/storage/3CR3DDY2/Gilmer et al. - 2018 - Adversarial Spheres.pdf:application/pdf;arXiv.org Snapshot:/Users/jamesgornet/Zotero/storage/XRQZISTY/1801.html:text/html}
}

@article{jalal_robust_2019,
	title = {The {Robust} {Manifold} {Defense}: {Adversarial} {Training} using {Generative} {Models}},
	shorttitle = {The {Robust} {Manifold} {Defense}},
	
	abstract = {We propose a new type of attack for finding adversarial examples for image classifiers. Our method exploits spanners, i.e. deep neural networks whose input space is low-dimensional and whose output range approximates the set of images of interest. Spanners may be generators of GANs or decoders of VAEs. The key idea in our attack is to search over latent code pairs to find ones that generate nearby images with different classifier outputs. We argue that our attack is stronger than searching over perturbations of real images. Moreover, we show that our stronger attack can be used to reduce the accuracy of Defense-GAN to 3{\textbackslash}\%, resolving an open problem from the well-known paper by Athalye et al. We combine our attack with normal adversarial training to obtain the most robust known MNIST classifier, significantly improving the state of the art against PGD attacks. Our formulation involves solving a min-max problem, where the min player sets the parameters of the classifier and the max player is running our attack, and is thus searching for adversarial examples in the \{{\textbackslash}em low-dimensional\} input space of the spanner. All code and models are available at {\textbackslash}url\{https://github.com/ajiljalal/manifold-defense.git\}},
	urldate = {2020-06-04},
	journal = {arXiv:1712.09196 [cs, stat]},
	author = {Jalal, Ajil and Ilyas, Andrew and Daskalakis, Constantinos and Dimakis, Alexandros G.},
	month = jul,
	year = {2019},
	note = {arXiv: 1712.09196},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Added pseudo code for defense-gan break},
	file = {arXiv Fulltext PDF:/Users/jamesgornet/Zotero/storage/DMEFZ2HI/Jalal et al. - 2019 - The Robust Manifold Defense Adversarial Training .pdf:application/pdf;arXiv.org Snapshot:/Users/jamesgornet/Zotero/storage/M3G4TL47/1712.html:text/html}
}

@article{george_generative_2017,
	title = {A generative vision model that trains with high data efficiency and breaks text-based {CAPTCHAs}},
	journal = {Science},
	author = {George, Dileep and Lehrach, Wolfgang and Kansky, Ken and Lázaro-Gredilla, Miguel and Laan, Christopher and Marthi, Bhaskara and Lou, Xinghua and Meng, Zhaoshi and Liu, Yi and Wang, Huayan and Lavin, Alex and Phoenix, D. Scott},
	year = {2017}
}

@inproceedings{linsley_learning_2018,
  title={Learning long-range spatial dependencies with horizontal gated recurrent units},
  author={Linsley, Drew and Kim, Junkyung and Veerabadran, Vijay and Windolf, Charles and Serre, Thomas},
  booktitle={NeurIPS},
  year={2018}
}

@inproceedings{selvaraju2017grad,
  title={{Grad-CAM}: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={ICCV},
  year={2017}
}


@inproceedings{simonyan_very_2015,
  title={Very deep convolutional networks for large-scale imagerecognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  booktitle={ICLR},
  year={2015}
}

@article{li_representation_1993,
	title = {The representation of stimulus familiarity in anterior inferior temporal cortex},
	volume = {69},
	issn = {0022-3077},
	
	doi = {10.1152/jn.1993.69.6.1918},
	abstract = {1. The inferior temporal (IT) cortex plays an important role in both short- and long-term memory for visual patterns. Most previous studies of IT neurons have tested their responses in recency memory tasks, which require that the memory lasts only the length of a single behavioral trial, which may be {\textless} 1 s. To determine the role of IT neurons in longer lasting memories, we measured their responses to initially novel stimuli as the stimuli gradually became familiar to the animal. 2. Two rhesus monkeys were trained on a delayed matching to sample (DMS) task with several intervening stimuli between the sample and the final matching stimulus on each trial. The purpose of the task was to ensure that the animal attended to the stimuli and held them in memory, at least temporarily. Unlike in several previous studies, the focus was not on within-trial effects but rather on the incidental memories that built up across trials as the stimuli became familiar. Each cell was tested with a set of 20 novel stimuli (digitized pictures of objects) that the monkey had not seen before. These stimuli were used in a fixed order over the course of an hour-long recording session, and the number of intervening trials between repetitions of a given sample stimulus was varied. 3. The responses of about one-third of the cells recorded in anterior-ventral IT cortex declined systematically as the novel stimuli became familiar. After six to eight repetitions, responses reached a plateau that was approximately 40\% of the peak response. Virtually all of these cells also showed selectivity for particular visual stimuli and thus were not "novelty detectors" in the sense of cells that respond to any novel stimulus. Rather, the responses of these cells were a joint function of familiarity and specific object features such as shape and color. A few cells showed increasing responses with repetition over the recording session, but these changes were accompanied by changes in baseline firing rate, suggesting that they were caused by nonspecific effects. 4. The decrement in response with familiarity was stimulus specific and bridged {\textgreater} 150 presentations of other stimuli, the maximum tested. For some cells the maximum decrement in response occurred for those stimuli that initially elicited the largest response. There was no significant change in response to stimuli that were already familiar. 5. The same cells that showed familiarity effects also showed reduced responses to the matching stimuli at the end of each trial, compared with the responses to the samples.(ABSTRACT TRUNCATED AT 400 WORDS)},
	number = {6},
	urldate = {2020-06-01},
	journal = {Journal of Neurophysiology},
	author = {Li, L. and Miller, E. K. and Desimone, R.},
	month = jun,
	year = {1993},
	note = {Publisher: American Physiological Society},
	pages = {1918--1929},
	file = {Full Text PDF:/Users/jamesgornet/Zotero/storage/XZT99GGJ/Li et al. - 1993 - The representation of stimulus familiarity in ante.pdf:application/pdf;Snapshot:/Users/jamesgornet/Zotero/storage/FYFYBU5N/jn.1993.69.6.html:text/html}
}

@article{SchrimpfKubilius2018BrainScore,
title={Brain-Score: Which Artificial Neural Network for Object Recognition is most Brain-Like?},
author={Martin Schrimpf and Jonas Kubilius and Ha Hong and Najib J. Majaj and Rishi Rajalingham and Elias B. Issa and Kohitij Kar and Pouya Bashivan and Jonathan Prescott-Roy and Franziska Geiger and Kailyn Schmidt and Daniel L. K. Yamins and James J. DiCarlo},
journal={bioRxiv preprint},
year={2018}
}

@article{yamins_using_2016,
	title = {Using goal-driven deep learning models to understand sensory cortex},
	journal = {Nature Neuroscience},
	author = {Yamins, Daniel L. K. and DiCarlo, James J.},
	year = {2016}
}

@article{rajalingham_large-scale_2018,
	title = {Large-{Scale}, {High}-{Resolution} {Comparison} of the {Core} {Visual} {Object} {Recognition} {Behavior} of {Humans}, {Monkeys}, and {State}-of-the-{Art} {Deep} {Artificial} {Neural} {Networks}},
	volume = {38},
	copyright = {Copyright © 2018 the authors 0270-6474/18/387255-15\$15.00/0},
	issn = {0270-6474, 1529-2401},
	
	doi = {10.1523/JNEUROSCI.0388-18.2018},
	abstract = {Primates, including humans, can typically recognize objects in visual images at a glance despite naturally occurring identity-preserving image transformations (e.g., changes in viewpoint). A primary neuroscience goal is to uncover neuron-level mechanistic models that quantitatively explain this behavior by predicting primate performance for each and every image. Here, we applied this stringent behavioral prediction test to the leading mechanistic models of primate vision (specifically, deep, convolutional, artificial neural networks; ANNs) by directly comparing their behavioral signatures against those of humans and rhesus macaque monkeys. Using high-throughput data collection systems for human and monkey psychophysics, we collected more than one million behavioral trials from 1472 anonymous humans and five male macaque monkeys for 2400 images over 276 binary object discrimination tasks. Consistent with previous work, we observed that state-of-the-art deep, feedforward convolutional ANNs trained for visual categorization (termed DCNNIC models) accurately predicted primate patterns of object-level confusion. However, when we examined behavioral performance for individual images within each object discrimination task, we found that all tested DCNNIC models were significantly nonpredictive of primate performance and that this prediction failure was not accounted for by simple image attributes nor rescued by simple model modifications. These results show that current DCNNIC models cannot account for the image-level behavioral patterns of primates and that new ANN models are needed to more precisely capture the neural mechanisms underlying primate object vision. To this end, large-scale, high-resolution primate behavioral benchmarks such as those obtained here could serve as direct guides for discovering such models.
SIGNIFICANCE STATEMENT Recently, specific feedforward deep convolutional artificial neural networks (ANNs) models have dramatically advanced our quantitative understanding of the neural mechanisms underlying primate core object recognition. In this work, we tested the limits of those ANNs by systematically comparing the behavioral responses of these models with the behavioral responses of humans and monkeys at the resolution of individual images. Using these high-resolution metrics, we found that all tested ANN models significantly diverged from primate behavior. Going forward, these high-resolution, large-scale primate behavioral benchmarks could serve as direct guides for discovering better ANN models of the primate visual system.},
	language = {en},
	number = {33},
	urldate = {2020-05-26},
	journal = {Journal of Neuroscience},
	author = {Rajalingham, Rishi and Issa, Elias B. and Bashivan, Pouya and Kar, Kohitij and Schmidt, Kailyn and DiCarlo, James J.},
	month = aug,
	year = {2018},
	pmid = {30006365},
	note = {Publisher: Society for Neuroscience
Section: Research Articles},
	keywords = {object recognition, deep neural network, human, monkey, vision},
	pages = {7255--7269},
	file = {Full Text PDF:/Users/jamesgornet/Zotero/storage/5VKA9J2Q/Rajalingham et al. - 2018 - Large-Scale, High-Resolution Comparison of the Cor.pdf:application/pdf;Snapshot:/Users/jamesgornet/Zotero/storage/8MTJ37N2/7255.html:text/html}
}

@article{majaj_simple_2015,
	title = {Simple {Learned} {Weighted} {Sums} of {Inferior} {Temporal} {Neuronal} {Firing} {Rates} {Accurately} {Predict} {Human} {Core} {Object} {Recognition} {Performance}},
	volume = {35},
	copyright = {Copyright © 2015 the authors 0270-6474/15/3513402-17\$15.00/0},
	issn = {0270-6474, 1529-2401},
	
	doi = {10.1523/JNEUROSCI.5181-14.2015},
	abstract = {To go beyond qualitative models of the biological substrate of object recognition, we ask: can a single ventral stream neuronal linking hypothesis quantitatively account for core object recognition performance over a broad range of tasks? We measured human performance in 64 object recognition tests using thousands of challenging images that explore shape similarity and identity preserving object variation. We then used multielectrode arrays to measure neuronal population responses to those same images in visual areas V4 and inferior temporal (IT) cortex of monkeys and simulated V1 population responses. We tested leading candidate linking hypotheses and control hypotheses, each postulating how ventral stream neuronal responses underlie object recognition behavior. Specifically, for each hypothesis, we computed the predicted performance on the 64 tests and compared it with the measured pattern of human performance. All tested hypotheses based on low- and mid-level visually evoked activity (pixels, V1, and V4) were very poor predictors of the human behavioral pattern. However, simple learned weighted sums of distributed average IT firing rates exactly predicted the behavioral pattern. More elaborate linking hypotheses relying on IT trial-by-trial correlational structure, finer IT temporal codes, or ones that strictly respect the known spatial substructures of IT (“face patches”) did not improve predictive power. Although these results do not reject those more elaborate hypotheses, they suggest a simple, sufficient quantitative model: each object recognition task is learned from the spatially distributed mean firing rates (100 ms) of ∼60,000 IT neurons and is executed as a simple weighted sum of those firing rates.
SIGNIFICANCE STATEMENT We sought to go beyond qualitative models of visual object recognition and determine whether a single neuronal linking hypothesis can quantitatively account for core object recognition behavior. To achieve this, we designed a database of images for evaluating object recognition performance. We used multielectrode arrays to characterize hundreds of neurons in the visual ventral stream of nonhuman primates and measured the object recognition performance of {\textgreater}100 human observers. Remarkably, we found that simple learned weighted sums of firing rates of neurons in monkey inferior temporal (IT) cortex accurately predicted human performance. Although previous work led us to expect that IT would outperform V4, we were surprised by the quantitative precision with which simple IT-based linking hypotheses accounted for human behavior.},
	language = {en},
	number = {39},
	urldate = {2020-05-19},
	journal = {Journal of Neuroscience},
	author = {Majaj, Najib J. and Hong, Ha and Solomon, Ethan A. and DiCarlo, James J.},
	month = sep,
	year = {2015},
	pmid = {26424887},
	note = {Publisher: Society for Neuroscience
Section: Articles},
	keywords = {categorization, identification, invariance, IT cortex, object recognition, V4},
	pages = {13402--13418},
	file = {Full Text PDF:/Users/jamesgornet/Zotero/storage/EB4W452L/Majaj et al. - 2015 - Simple Learned Weighted Sums of Inferior Temporal .pdf:application/pdf;Snapshot:/Users/jamesgornet/Zotero/storage/RZCFNHPE/13402.html:text/html}
}


@article{schrimpf_brain-score_2018,
	title = {Brain-{Score}: {Which} {Artificial} {Neural} {Network} for {Object} {Recognition} is most {Brain}-{Like}?},
	copyright = {© 2018, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	shorttitle = {Brain-{Score}},
	
	doi = {10.1101/407007},
	abstract = {{\textless}p{\textgreater}The internal representations of early deep artificial neural networks (ANNs) were found to be remarkably similar to the internal neural representations measured experimentally in the primate brain. Here we ask, as deep ANNs have continued to evolve, are they becoming more or less brain-like? ANNs that are most functionally similar to the brain will contain mechanisms that are most like those used by the brain. We therefore developed \textit{Brain-Score} – a composite of multiple neural and behavioral benchmarks that score any ANN on how similar it is to the brain’s mechanisms for core object recognition – and we deployed it to evaluate a wide range of state-of-the-art deep ANNs. Using this scoring system, we here report that: (1) DenseNet-169, CORnet-S and ResNet-101 are the most brain-like ANNs. There remains considerable variability in neural and behavioral responses that is not predicted by any ANN, suggesting that no ANN model has yet captured all the relevant mechanisms. (3) Extending prior work, we found that gains in ANN ImageNet performance led to gains on Brain-Score. However, correlation weakened at \textit{≥} 70\% top-1 ImageNet performance, suggesting that additional guidance from neuroscience is needed to make further advances in capturing brain mechanisms. (4) We uncovered smaller (i.e. less complex) ANNs that are more brain-like than many of the best-performing ImageNet models, which suggests the opportunity to simplify ANNs to better understand the ventral stream. The scoring system used here is far from complete. However, we propose that evaluating and tracking model-benchmark correspondences through a Brain-Score that is regularly updated with new brain data is an exciting opportunity: experimental benchmarks can be used to guide machine network evolution, and machine networks are mechanistic hypotheses of the brain’s network and thus drive next experiments. To facilitate both of these, we release Brain-Score.org: a platform that hosts the neural and behavioral benchmarks, where ANNs for visual processing can be submitted to receive a Brain-Score and their rank relative to other models, and where new experimental data can be naturally incorporated.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-05-19},
	journal = {bioRxiv},
	author = {Schrimpf, Martin and Kubilius, Jonas and Hong, Ha and Majaj, Najib J. and Rajalingham, Rishi and Issa, Elias B. and Kar, Kohitij and Bashivan, Pouya and Prescott-Roy, Jonathan and Schmidt, Kailyn and Yamins, Daniel L. K. and DiCarlo, James J.},
	month = sep,
	year = {2018},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {407007},
	file = {Full Text PDF:/Users/jamesgornet/Zotero/storage/R2755S2V/Schrimpf et al. - 2018 - Brain-Score Which Artificial Neural Network for O.pdf:application/pdf;Snapshot:/Users/jamesgornet/Zotero/storage/C3VLCT7F/407007v1.html:text/html}
}


@article{friston_theory_2005,
	title = {A theory of cortical responses},
	volume = {360},
	
	doi = {10.1098/rstb.2005.1622},
	abstract = {This article concerns the nature of evoked brain responses and the principles underlying their generation. We start with the premise that the sensory brain has evolved to represent or infer the causes of changes in its sensory inputs. The problem of inference is well formulated in statistical terms. The statistical fundaments of inference may therefore afford important constraints on neuronal implementation. By formulating the original ideas of Helmholtz on perception, in terms of modern-day statistical theories, one arrives at a model of perceptual inference and learning that can explain a remarkable range of neurobiological facts.It turns out that the problems of inferring the causes of sensory input (perceptual inference) and learning the relationship between input and cause (perceptual learning) can be resolved using exactly the same principle. Specifically, both inference and learning rest on minimizing the brain's free energy, as defined in statistical physics. Furthermore, inference and learning can proceed in a biologically plausible fashion. Cortical responses can be seen as the brain’s attempt to minimize the free energy induced by a stimulus and thereby encode the most likely cause of that stimulus. Similarly, learning emerges from changes in synaptic efficacy that minimize the free energy, averaged over all stimuli encountered. The underlying scheme rests on empirical Bayes and hierarchical models of how sensory input is caused. The use of hierarchical models enables the brain to construct prior expectations in a dynamic and context-sensitive fashion. This scheme provides a principled way to understand many aspects of cortical organization and responses. The aim of this article is to encompass many apparently unrelated anatomical, physiological and psychophysical attributes of the brain within a single theoretical perspective.In terms of cortical architectures, the theoretical treatment predicts that sensory cortex should be arranged hierarchically, that connections should be reciprocal and that forward and backward connections should show a functional asymmetry (forward connections are driving, whereas backward connections are both driving and modulatory). In terms of synaptic physiology, it predicts associative plasticity and, for dynamic models, spike-timing-dependent plasticity. In terms of electrophysiology, it accounts for classical and extra classical receptive field effects and long-latency or endogenous components of evoked cortical responses. It predicts the attenuation of responses encoding prediction error with perceptual learning and explains many phenomena such as repetition suppression, mismatch negativity (MMN) and the P300 in electroencephalography. In psychophysical terms, it accounts for the behavioural correlates of these physiological phenomena, for example, priming and global precedence. The final focus of this article is on perceptual learning as measured with the MMN and the implications for empirical studies of coupling among cortical areas using evoked sensory responses.},
	number = {1456},
	urldate = {2020-05-14},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Friston, Karl},
	month = apr,
	year = {2005},
	note = {Publisher: Royal Society},
	pages = {815--836},
	file = {Full Text PDF:/Users/jamesgornet/Zotero/storage/2FPMRXWI/Friston - 2005 - A theory of cortical responses.pdf:application/pdf;Snapshot:/Users/jamesgornet/Zotero/storage/3LB4VQUH/rstb.2005.html:text/html}
}

@article{rao_predictive_1999,
	title = {Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects},
	journal = {Nature Neuroscience},
	author = {Rao, Rajesh P. N. and Ballard, Dana H.},
	year = {1999}
}

@article{lee_hierarchical_2003,
	title = {Hierarchical {Bayesian} inference in the visual cortex},
	volume = {20},
	copyright = {\&\#169; 2003 Optical Society of America},
	issn = {1520-8532},
	
	doi = {10.1364/JOSAA.20.001434},
	abstract = {Traditional views of visual processing suggest that early visual neurons in areas V1 and V2 are static spatiotemporal filters that extract local features from a visual scene. The extracted information is then channeled through a feedforward chain of modules in successively higher visual areas for further analysis. Recent electrophysiological recordings from early visual neurons in awake behaving monkeys reveal that there are many levels of complexity in the information processing of the early visual cortex, as seen in the long-latency responses of its neurons. These new findings suggest that activity in the early visual cortex is tightly coupled and highly interactive with the rest of the visual system. They lead us to propose a new theoretical setting based on the mathematical framework of hierarchical Bayesian inference for reasoning about the visual system. In this framework, the recurrent feedforward/feedback loops in the cortex serve to integrate top-down contextual priors and bottom-up observations so as to implement concurrent probabilistic inference along the visual hierarchy. We suggest that the algorithms of particle filtering and Bayesian-belief propagation might model these interactive cortical computations. We review some recent neurophysiological evidences that support the plausibility of these ideas.},
	language = {EN},
	number = {7},
	urldate = {2020-05-14},
	journal = {JOSA A},
	author = {Lee, Tai Sing and Mumford, David},
	month = jul,
	year = {2003},
	note = {Publisher: Optical Society of America},
	keywords = {Edge detection, Machine vision, Neural networks, Optical imaging, Vision modeling, Visual system},
	pages = {1434--1448},
	file = {Full Text:/Users/jamesgornet/Zotero/storage/2L5VCBTC/Lee and Mumford - 2003 - Hierarchical Bayesian inference in the visual cort.pdf:application/pdf;Snapshot:/Users/jamesgornet/Zotero/storage/8MDENVI3/abstract.html:text/html}
}

@article{felleman_distributed_1991,
	title = {Distributed hierarchical processing in the primate cerebral cortex},
	journal = {Cerebral Cortex},
	author = {Felleman, D. J. and Van Essen, D. C.},
	year = {1991}
}

@article{geirhos_imagenet-trained_2019,
	title = {{ImageNet}-trained {CNNs} are biased towards texture; increasing shape bias improves accuracy and robustness},
	
	abstract = {Convolutional Neural Networks (CNNs) are commonly thought to recognise objects by learning increasingly complex representations of object shapes. Some recent studies suggest a more important role of image textures. We here put these conflicting hypotheses to a quantitative test by evaluating CNNs and human observers on images with a texture-shape cue conflict. We show that ImageNet-trained CNNs are strongly biased towards recognising textures rather than shapes, which is in stark contrast to human behavioural evidence and reveals fundamentally different classification strategies. We then demonstrate that the same standard architecture (ResNet-50) that learns a texture-based representation on ImageNet is able to learn a shape-based representation instead when trained on "Stylized-ImageNet", a stylized version of ImageNet. This provides a much better fit for human behavioural performance in our well-controlled psychophysical lab setting (nine experiments totalling 48,560 psychophysical trials across 97 observers) and comes with a number of unexpected emergent benefits such as improved object detection performance and previously unseen robustness towards a wide range of image distortions, highlighting advantages of a shape-based representation.},
	urldate = {2020-05-12},
	journal = {arXiv:1811.12231 [cs, q-bio, stat]},
	author = {Geirhos, Robert and Rubisch, Patricia and Michaelis, Claudio and Bethge, Matthias and Wichmann, Felix A. and Brendel, Wieland},
	month = jan,
	year = {2019},
	note = {arXiv: 1811.12231},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Quantitative Biology - Neurons and Cognition, Statistics - Machine Learning},
	annote = {Comment: Accepted at ICLR 2019 (oral)},
	file = {arXiv Fulltext PDF:/Users/jamesgornet/Zotero/storage/IVIQ7XQL/Geirhos et al. - 2019 - ImageNet-trained CNNs are biased towards texture\; .pdf:application/pdf;arXiv.org Snapshot:/Users/jamesgornet/Zotero/storage/8M8GY25M/1811.html:text/html}
}

@inproceedings{szegedy_rethinking_2015,
  title={Rethinking the Inception archi-tecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
  booktitle={CVPR},
  year={2016}
}


@article{CodeForFaceIdentity,
title = "The Code for Facial Identity in the Primate Brain",
journal = "Cell",
volume = "169",
number = "6",
pages = "1013 - 1028.e14",
year = "2017",
issn = "0092-8674",
doi = "https://doi.org/10.1016/j.cell.2017.05.011",

author = "Le Chang and Doris Y. Tsao",
keywords = "inferior temporal cortex, primate vision, face processing, decoding, electrophysiology",
abstract = "Summary
Primates recognize complex objects such as faces with remarkable speed and reliability. Here, we reveal the brain’s code for facial identity. Experiments in macaques demonstrate an extraordinarily simple transformation between faces and responses of cells in face patches. By formatting faces as points in a high-dimensional linear space, we discovered that each face cell’s firing rate is proportional to the projection of an incoming face stimulus onto a single axis in this space, allowing a face cell ensemble to encode the location of any face in the space. Using this code, we could precisely decode faces from neural population responses and predict neural firing rates to faces. Furthermore, this code disavows the long-standing assumption that face cells encode specific facial identities, confirmed by engineering faces with drastically different appearance that elicited identical responses in single face cells. Our work suggests that other objects could be encoded by analogous metric coordinate systems.
PaperClip
"
}

@article{pungpapong2013iterated,
  title={An Iterated Conditional Modes/Medians Algorithm for Empirical Bayes Selection of Massive Variables},
  author={Pungpapong, Vitara and Zhang, Min and Zhang, Dabao and others},
  year={2013}
}

@inproceedings{samangouei2018defense,
  title={Defense-gan: Protecting classifiers against adversarial attacks using generative models},
  author={Samangouei, Pouya and Kabkab, Maya and Chellappa, Rama},
  booktitle={ICLR},
  year={2018}
}

@article{geirhos2017comparing,
  title={Comparing deep neural networks against humans: object recognition when the signal gets weaker},
  author={Geirhos, Robert and Janssen, David HJ and Sch{\"u}tt, Heiko H and Rauber, Jonas and Bethge, Matthias and Wichmann, Felix A},
  journal={arXiv preprint arXiv:1706.06969},
  year={2017}
}


@inproceedings{hedeeprectifier, 
author={K. {He} and X. {Zhang} and S. {Ren} and J. {Sun}}, 
booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 
title={Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification}, 
year={2015}, 
volume={}, 
number={}, 
pages={1026-1034}, 
keywords={image classification;neural nets;human-level performance;ILSVRC 2014 winner;ImageNet 2012 classification dataset;network architectures;rectifier nonlinearities;robust initialization method;overfitting risk;model fitting;PReLU;parametric rectified linear unit;rectifier neural networks;state-of-the-art neural networks;rectified activation units;ImageNet classification;Training;Computational modeling;Adaptation models;Testing;Gaussian distribution;Biological neural networks}, 
doi={10.1109/ICCV.2015.123}, 
ISSN={2380-7504}, 
month={Dec},}

@article{khaligh2014deep,
  title={Deep supervised, but not unsupervised, models may explain IT cortical representation},
  author={Khaligh-Razavi, Seyed-Mahdi and Kriegeskorte, Nikolaus},
  journal={PLoS computational biology},
  volume={10},
  number={11},
  pages={e1003915},
  year={2014},
  publisher={Public Library of Science}
}

@inproceedings{nguyen2015deep,
  title={Deep neural networks are easily fooled: High confidence predictions for unrecognizable images},
  author={Nguyen, Anh and Yosinski, Jason and Clune, Jeff},
  booktitle={CVPR},
  pages={427--436},
  year={2015}
}
@inproceedings{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  booktitle={ICLR},
  year={2014}
}


@article{lecun1998mnist,
  title={The MNIST database of handwritten digits},
  author={LeCun, Yann},
  journal={http://yann. lecun. com/exdb/mnist/}
}

@article{NRM,
    title={A Bayesian perspective of convolutional neural networks through a deconvolutional generative model},
    author={Tan Nguyen and Nhat Ho and Ankit Patel and Anima Anandkumar and Michael I. Jordan and Richard G. Baraniuk},
    journal={arXiv:1811.02657},
    year={2018}
}

@article{PredCoding1,
  title={Does predictive coding have a future?},
  author={Karl J. Friston},
  journal={Nature Neuroscience},
  year={2018},
  volume={21},
  pages={1019-1021}
}

@article{DeepCheap,
  title={Why does deep and cheap learning work so well?},
  author={Lin, Henry W and Tegmark, Max and Rolnick, David},
  journal={Journal of Statistical Physics},
  volume={168},
  number={6},
  pages={1223--1247},
  year={2017},
  publisher={Springer}
}

@article {brainscore,
	author = {Schrimpf, Martin and Kubilius, Jonas and Hong, Ha and Majaj, Najib J. and Rajalingham, Rishi and Issa, Elias B. and Kar, Kohitij and Bashivan, Pouya and Prescott-Roy, Jonathan and Schmidt, Kailyn and Yamins, Daniel L. K. and DiCarlo, James J.},
	title = {Brain-Score: Which Artificial Neural Network for Object Recognition is most Brain-Like?},
	elocation-id = {407007},
	year = {2018},
	doi = {10.1101/407007},
	publisher = {Cold Spring Harbor Laboratory},
	eprint = {https://www.biorxiv.org/content/early/2018/09/05/407007.full.pdf},
	journal = {bioRxiv}
}
@article{topdown,
author = {Gilbert, Charles and Li, Wu},
year = {2013},
month = {04},
pages = {350-363},
title = {Top-down influences on visual processing},
volume = {14},
journal = {Nature reviews. Neuroscience},
doi = {10.1038/nrn3476}
}

@article{rao1999predictive,
  title={Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects},
  author={Rao, Rajesh PN and Ballard, Dana H},
  journal={Nature Neuroscience},
  year={1999},
  publisher={Nature Publishing Group}
}

@PhdThesis{Gal2016Uncertainty,
  title={Uncertainty in Deep Learning},
  author={Gal, Yarin},
  year={2016},
  school={University of Cambridge}
}

@article{yuan2019adversarial,
  title={Adversarial examples: Attacks and defenses for deep learning},
  author={Yuan, Xiaoyong and He, Pan and Zhu, Qile and Li, Xiaolin},
  journal={IEEE transactions on neural networks and learning systems},
  year={2019},
  publisher={IEEE}
}

@INPROCEEDINGS{dodgedistortionperf, 
author={S. {Dodge} and L. {Karam}}, 
booktitle={ICCCN}, 
title={A Study and Comparison of Human and Deep Learning Recognition Performance under Visual Distortions}, 
year={2017}
}

@article{hsieh2010recognition,
  title={Recognition alters the spatial pattern of FMRI activation in early retinotopic cortex},
  author={Hsieh, P-J and Vul, E and Kanwisher, N},
  journal={Journal of neurophysiology},
  volume={103},
  number={3},
  pages={1501--1507},
  year={2010},
  publisher={American Physiological Society Bethesda, MD}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}


@article{abdelhack2018sharpening,
  title={Sharpening of hierarchical visual feature representations of blurred images},
  author={Abdelhack, Mohamed and Kamitani, Yukiyasu},
  journal={Eneuro},
  volume={5},
  number={3},
  year={2018},
  publisher={Society for Neuroscience}
}

@inproceedings{elsayed2018adversarial,
  title={Adversarial examples that fool both computer vision and time-limited humans},
  author={Elsayed, Gamaleldin and Shankar, Shreya and Cheung, Brian and Papernot, Nicolas and Kurakin, Alexey and Goodfellow, Ian and Sohl-Dickstein, Jascha},
  booktitle={NeurIPS},
  year={2018}
}


@article{kar2019evidence,
  title={Evidence that recurrent circuits are critical to the ventral stream’s execution of core object recognition behavior},
  author={Kar, Kohitij and Kubilius, Jonas and Schmidt, Kailyn and Issa, Elias B and DiCarlo, James J},
  journal={Nature Neuroscience},
  year={2019}
}

@article{kubilius_cornet_2018,
  title={CORnet: modeling the neural mechanisms of core object recognition},
  author={Kubilius, Jonas and Schrimpf, Martin and Nayebi, Aran and Bear, Daniel and Yamins, Daniel LK and DiCarlo, James J},
  journal={bioRxiv preprint},
  year={2018},
  publisher={Cold Spring Harbor Laboratory}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  pages={770--778},
  year={2016}
}

@article{mu2019mnist,
  title={Mnist-c: A robustness benchmark for computer vision},
  author={Mu, Norman and Gilmer, Justin},
  journal={arXiv preprint arXiv:1906.02337},
  year={2019}
}

@inproceedings{athalye2018obfuscated,
  title={Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples},
  author={Athalye, Anish and Carlini, Nicholas and Wagner, David},
  booktitle={ICML},
  year={2018}
}

@inproceedings{goodfellow2014explaining,
  title={Explaining and Harnessing Adversarial Examples},
  author={Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
  booktitle={ICLR},
  year={2015}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={CVPR},
  year={2017}
}

@article{lee2015visual,
  title={The visual system's internal model of the world},
  author={Lee, Tai Sing},
  journal={Proceedings of the IEEE},
  volume={103},
  number={8},
  pages={1359--1378},
  year={2015},
  publisher={IEEE}
}

@article{abbott2018brain,
  title={How the brain's face code might unlock the mysteries of perception.},
  author={Abbott, Alison},
  journal={Nature},
  volume={564},
  number={7735},
  pages={176},
  year={2018}
}

@article{DBLP:journals/corr/abs-1907-04572,
  author    = {Yujia Huang and
               Sihui Dai and
               Tan Nguyen and
               Richard G. Baraniuk and
               Anima Anandkumar},
  title     = {Out-of-Distribution Detection Using Neural Rendering Generative Models},
  volume    = {abs/1907.04572},
  year      = {2019},
  
  archivePrefix = {arXiv},
  eprint    = {1907.04572},
  timestamp = {Wed, 17 Jul 2019 10:27:36 +0200}
}

@article{tang2018recurrent,
  title={Recurrent computations for visual pattern completion},
  author={Tang, Hanlin and Schrimpf, Martin and Lotter, William and Moerman, Charlotte and Paredes, Ana and Caro, Josue Ortega and Hardesty, Walter and Cox, David and Kreiman, Gabriel},
  journal={Proceedings of the National Academy of Sciences},
  volume={115},
  number={35},
  pages={8835--8840},
  year={2018},
  publisher={National Acad Sciences}
}

@article{spoerer2017recurrent,
  title={Recurrent convolutional neural networks: a better model of biological object recognition},
  author={Spoerer, Courtney J and McClure, Patrick and Kriegeskorte, Nikolaus},
  journal={Frontiers in psychology},
  volume={8},
  pages={1551},
  year={2017},
  publisher={Frontiers}
}

@incollection{NIPS2016_6096,
title = {Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling},
author = {Wu, Jiajun and Zhang, Chengkai and Xue, Tianfan and Freeman, Bill and Tenenbaum, Josh},
booktitle = {NeurIPS 29},
editor = {D. D. Lee and M. Sugiyama and U. V. Luxburg and I. Guyon and R. Garnett},
pages = {82--90},
year = {2016},
publisher = {Curran Associates, Inc.},

}

@inproceedings{zamir2017feedback,
  title={Feedback networks},
  author={Zamir, Amir R. and Wu, Te-Lin and Sun, Lin and Shen, William B. and Shi, Bertram E. and Malik, Jitendra and Savarese, Silvio},
  booktitle={CVPR},
  year={2017}
}

@inproceedings{wen2018deep,
  title={Deep predictive coding network for object recognition},
  author={Wen, Haiguang and Han, Kuan and Shi, Junxing and Zhang, Yizhen and Culurciello, Eugenio and Liu, Zhongming},
  booktitle={ICML},
  year={2018}
}

@inproceedings{nayebi2018task,
  title={Task-driven convolutional recurrent models of the visual system},
  author={Nayebi, Aran and Bear, Daniel and Kubilius, Jonas and Kar, Kohitij and Ganguli, Surya and Sussillo, David and DiCarlo, James J and Yamins, Daniel L},
  booktitle={NeurIPS},
  year={2018}
}

@article{eickenberg2017seeing,
  title={Seeing it all: Convolutional network layers map the function of the human visual system},
  author={Eickenberg, Michael and Gramfort, Alexandre and Varoquaux, Ga{\"e}l and Thirion, Bertrand},
  journal={NeuroImage},
  year={2017},
  publisher={Elsevier}
}

@article{horikawa2017hierarchical,
  title={Hierarchical neural representation of dreamed objects revealed by brain decoding with deep neural network features},
  author={Horikawa, Tomoyasu and Kamitani, Yukiyasu},
  journal={Front Comput Neurosci},
  year={2017},
  publisher={Frontiers}
}

@article{kravitz2013ventral,
  title={The ventral visual pathway: an expanded neural framework for the processing of object quality},
  author={Kravitz, Dwight J and Saleem, Kadharbatcha S and Baker, Chris I and Ungerleider, Leslie G and Mishkin, Mortimer},
  journal={Trends in cognitive sciences},
  volume={17},
  number={1},
  pages={26--49},
  year={2013},
  publisher={Elsevier}
}

@article{kietzmann2019recurrence,
  title={Recurrence is required to capture the representational dynamics of the human visual system},
  author={Kietzmann, Tim C and Spoerer, Courtney J and S{\"o}rensen, Lynn KA and Cichy, Radoslaw M and Hauk, Olaf and Kriegeskorte, Nikolaus},
  journal={PNAS},
  year={2019},
  publisher={National Acad Sciences}
}

@incollection{doya_neural_2006,
	title = {Neural {models} of {Bayesian} {belief} {propagation}},
	isbn = {978-0-262-29418-8},
	
	language = {en},
	urldate = {2020-03-31},
	booktitle = {Bayesian {Brain}},
	publisher = {The MIT Press},
	editor = {Doya, Kenji and Ishii, Shin and Pouget, Alexandre and Rao, Rajesh P.N.},
	year = {2006},
	doi = {10.7551/mitpress/1535.003.0017},
	file = {Submitted Version:/Users/jamesgornet/Zotero/storage/5MCHUTK3/Doya et al. - 2006 - Neural Models of Bayesian Belief Propagation.pdf:application/pdf}
}


@article{friston_theory_2005,
	title = {A theory of cortical responses},
	volume = {360},
	issn = {0962-8436, 1471-2970},
	
	doi = {10.1098/rstb.2005.1622},
	language = {en},
	number = {1456},
	urldate = {2020-03-31},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Friston, Karl},
	month = apr,
	year = {2005},
	pages = {815--836},
	file = {Friston - 2005 - A theory of cortical responses.pdf:/Users/jamesgornet/Zotero/storage/JPFCVHGT/Friston - 2005 - A theory of cortical responses.pdf:application/pdf}
}



@article{friston_free-energy_2010,
	title = {The free-energy principle: a unified brain theory?},
	volume = {11},
	issn = {1471-003X, 1471-0048},
	shorttitle = {The free-energy principle},
	
	doi = {10.1038/nrn2787},
	abstract = {A free-energy principle has been proposed recently that accounts for action, perception and learning. This Review looks at some key brain theories in the biological (for example, neural Darwinism) and physical (for example, information theory and optimal control theory) sciences from the free-energy perspective. Crucially, one key theme runs through each of these theories â optimization. Furthermore, if we look closely at what is optimized, the same quantity keeps emerging, namely value (expected reward, expected utility) or its complement, surprise (prediction error, expected cost). This is the quantity that is optimized under the free-energy principle, which suggests that several global brain theories might be unified within a free-energy framework.},
	language = {en},
	number = {2},
	urldate = {2020-03-31},
	journal = {Nature Reviews Neuroscience},
	author = {Friston, Karl},
	month = feb,
	year = {2010},
	pages = {127--138},
	file = {Friston - 2010 - The free-energy principle a unified brain theory.pdf:/Users/jamesgornet/Zotero/storage/JKACAMSP/Friston - 2010 - The free-energy principle a unified brain theory.pdf:application/pdf}
}

@article{jacobs_optimal_1999,
	title = {Optimal integration of texture and motion cues to depth},
	volume = {39},
	issn = {0042-6989},
	
	doi = {10.1016/S0042-6989(99)00088-7},
	language = {en},
	number = {21},
	urldate = {2020-03-31},
	journal = {Vision Research},
	author = {Jacobs, Robert A.},
	month = oct,
	year = {1999},
	keywords = {Depth, Motion, Optimal integration, Texture},
	pages = {3621--3629},
	file = {ScienceDirect Full Text PDF:/Users/jamesgornet/Zotero/storage/YADX6ZD8/Jacobs - 1999 - Optimal integration of texture and motion cues to .pdf:application/pdf;ScienceDirect Snapshot:/Users/jamesgornet/Zotero/storage/ILPU8QD3/S0042698999000887.html:text/html}
}

@article{knill_humans_2003,
	title = {Do humans optimally integrate stereo and texture information for judgments of surface slant?},
	volume = {43},
	doi = {10.1016/S0042-6989(03)00458-9},
	abstract = {An optimal linear system for integrating visual cues to 3D surface geometry weights cues in inverse proportion to their uncertainty. The problem of integrating texture and stereo information for judgments of planar surface slant provides a strong test of optimality in human perception. Since the accuracy of slant from texture judgments changes by an order of magnitude from low to high slants, optimality predicts corresponding changes in cue weights as a function of surface slant. Furthermore, since humans show significant individual differences in their abilities to use both texture and stereo information for judgments of 3D surface geometry, the problem admits the stronger test that individual differences in subjects' thresholds for discriminating slant from the individual cues should predict individual differences in cue weights. We tested both predictions by measuring slant discrimination thresholds and stereo/texture cue weights as a function of surface slant for multiple subjects. The results bear out both predictions of optimality, with the exception of an apparent slight under-weighting of texture information. This may be accounted for by factors specific to the stimuli used to isolate stereo information in the experiments. Taken together, the results are consistent with the hypothesis that humans optimally combine the two cues to surface slant, with cue weights proportional to the subjective reliability of the cues.},
	journal = {Vision research},
	author = {Knill, David and Saunders, Jeffrey},
	month = dec,
	year = {2003},
	pages = {2539--58}
}

@article{besag1986statistical,
  title={On the statistical analysis of dirty pictures},
  author={Besag, Julian},
  journal={J. R. Statist. Soc. B},
  year={1986},
  publisher={Wiley Online Library}
}

@article{loshchilov2016sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1608.03983},
  year={2016}
}

@article{springenberg2014striving,
  title={Striving for simplicity: The all convolutional net},
  author={Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1412.6806},
  year={2014}
}

@article{kok2012less,
  title={Less is more: expectation sharpens representations in the primary visual cortex},
  author={Kok, Peter and Jehee, Janneke FM and De Lange, Floris P},
  journal={Neuron},
  year={2012},
  publisher={Elsevier}
}

@book{knill1996perception,
  title={Perception as Bayesian inference},
  author={Knill, David C and Richards, Whitman},
  year={1996},
  publisher={Cambridge University Press}
}

@article{hendrycks2019augmix,
  title={AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty},
  author={Hendrycks, Dan and Mu, Norman and Cubuk, Ekin D and Zoph, Barret and Gilmer, Justin and Lakshminarayanan, Balaji},
  journal={arXiv preprint arXiv:1912.02781},
  year={2019}
}

@article{hendrycks2019benchmarking,
  title={Benchmarking neural network robustness to common corruptions and perturbations},
  author={Hendrycks, Dan and Dietterich, Thomas},
  journal={arXiv preprint arXiv:1903.12261},
  year={2019}
}

@article{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={arXiv:1706.06083},
  year={2017}
}

@article{ulyanov2016instance,
  title={Instance normalization: The missing ingredient for fast stylization},
  author={Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
  journal={arXiv:1607.08022},
  year={2016}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv:1412.6980},
  year={2014}
}

@inproceedings{mittal2020learning,
    title={Learning to Combine Top-Down and Bottom-Up Signals in Recurrent Neural Networks with Attention over Modules},
    author={Sarthak Mittal and Alex Lamb and Anirudh Goyal and Vikram Voleti and Murray Shanahan and Guillaume Lajoie and Michael Mozer and Yoshua Bengio},
    booktitle={ICML},
    year={2020}
}

@article{goyal2019recurrent,
  title={Recurrent Independent Mechanisms},
  author={Anirudh Goyal and Alex Lamb and Jordan Hoffmann and Shagun Sodhani and Sergey Levine and Yoshua Bengio and Bernhard Schölkopf},
  journal={arXiv:1909.10893},
  year={2019}
}