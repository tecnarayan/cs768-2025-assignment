@article{barocas2016big,
  title={Big data's disparate impact},
  author={Barocas, Solon and Selbst, Andrew D},
  journal={California Law Review},
  year={2016},
  publisher={HeinOnline}
}


@inproceedings{rastegarpanah2019fighting,
  title={Fighting fire with fire: Using antidote data to improve polarization and fairness of recommender systems},
  author={Rastegarpanah, Bashir and Gummadi, Krishna P and Crovella, Mark},
  booktitle={ACM International Conference on Web Search and Data Mining},
  year={2019}
}


@article{saravanakumar2020impossibility,
  title={The Impossibility Theorem of Machine Fairness--A Causal Perspective},
  author={Saravanakumar, Kailash Karthik},
  journal={arXiv preprint arXiv:2007.06024},
  year={2020}
}


@article{mehrabi2021survey,
  title={A survey on bias and fairness in machine learning},
  author={Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  journal={ACM Computing Surveys},
  year={2021},
  publisher={ACM New York, NY, USA}
}


@book{dantzig2016linear,
  title={Linear programming and extensions},
  author={Dantzig, George},
  year={2016},
  publisher={Princeton University Press}
}


@article{chhabra2021fair,
  title={Fair Clustering Using Antidote Data},
  author={Chhabra, Anshuman and Singla, Adish and Mohapatra, Prasant},
  journal={arXiv preprint arXiv:2106.00600},
  year={2021}
}


@article{goodman2017european,
  title={European Union regulations on algorithmic decision-making and a “right to explanation”},
  author={Goodman, Bryce and Flaxman, Seth},
  journal={AI magazine},
  year={2017}
}


@book{ferguson2017rise,
  title={The rise of big data policing},
  author={Ferguson, Andrew Guthrie},
  year={2017},
  publisher={New York University Press}
}


@article{civil,
  title={Civil Rights Act of 1964, Title VII, Equal Employment Opportunities},
  author={{Civil Rights Act}},
  year={1964},
}


@article{chouldechova2017fair,
  title={Fair prediction with disparate impact: A study of bias in recidivism prediction instruments},
  author={Chouldechova, Alexandra},
  journal={Big Data},
  year={2017},
  publisher={Mary Ann Liebert, Inc. 140 Huguenot Street, 3rd Floor New Rochelle, NY 10801 USA}
}


%------------------------------------------------------------------------- Pre-processing


@inproceedings{jiang2020identifying,
  title={Identifying and correcting label bias in machine learning},
  author={Jiang, Heinrich and Nachum, Ofir},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2020},
}


@article{kamiran2012data,
  title={Data preprocessing techniques for classification without discrimination},
  author={Kamiran, Faisal and Calders, Toon},
  journal={Knowledge and Information Systems},
  year={2012},
  publisher={Springer}
}


@inproceedings{feldman2015certifying,
  title={Certifying and removing disparate impact},
  author={Feldman, Michael and Friedler, Sorelle A and Moeller, John and Scheidegger, Carlos and Venkatasubramanian, Suresh},
  booktitle={ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year={2015}
}


@inproceedings{krasanakis2018adaptive,
  title={Adaptive sensitive reweighting to mitigate bias in fairness-aware classification},
  author={Krasanakis, Emmanouil and Spyromitros-Xioufis, Eleftherios and Papadopoulos, Symeon and Kompatsiaris, Yiannis},
  booktitle={The World Wide Web Conference},
  year={2018}
}


@inproceedings{calmon2017optimized,
  title={Optimized pre-processing for discrimination prevention},
  author={Calmon, Flavio P and Wei, Dennis and Vinzamuri, Bhanukiran and Ramamurthy, Karthikeyan Natesan and Varshney, Kush R},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}


@inproceedings{yan2020fair,
  title={Fair class balancing: enhancing model fairness without observing sensitive attributes},
  author={Yan, Shen and Kao, Hsien-te and Ferrara, Emilio},
  booktitle={ACM International Conference on Information \& Knowledge Management},
  year={2020}
}


@inproceedings{zemel2013learning,
  title={Learning fair representations},
  author={Zemel, Rich and Wu, Yu and Swersky, Kevin and Pitassi, Toni and Dwork, Cynthia},
  booktitle={International Conference on Machine Learning},
  year={2013},
}


@inproceedings{wang2019repairing,
  title={Repairing without retraining: Avoiding disparate impact with counterfactual distributions},
  author={Wang, Hao and Ustun, Berk and Calmon, Flavio},
  booktitle={International Conference on Machine Learning},
  year={2019},
}


%------------------------------------------------------------------------- In-processing


@inproceedings{zhang2018mitigating,
  title={Mitigating unwanted biases with adversarial learning},
  author={Zhang, Brian Hu and Lemoine, Blake and Mitchell, Margaret},
  booktitle={The 2018 AAAI/ACM Conference on AI, Ethics, and Society},
  year={2018}
}


@inproceedings{agarwal2018reductions,
  title={A reductions approach to fair classification},
  author={Agarwal, Alekh and Beygelzimer, Alina and Dud{\'\i}k, Miroslav and Langford, John and Wallach, Hanna},
  booktitle={International Conference on Machine Learning},
  year={2018},
}


@inproceedings{zhao2019conditional,
  title={Conditional Learning of Fair Representations},
  author={Zhao, Han and Coston, Amanda and Adel, Tameem and Gordon, Geoffrey J},
  booktitle={International Conference on Learning Representations},
  year={2019}
}


@inproceedings{zafar2017fairness,
  title={Fairness constraints: Mechanisms for fair classification},
  author={Zafar, Muhammad Bilal and Valera, Isabel and Rogriguez, Manuel Gomez and Gummadi, Krishna P},
  booktitle={Artificial Intelligence and Statistics},
  year={2017},
}


@inproceedings{jiang2020wasserstein,
  title={Wasserstein fair classification},
  author={Jiang, Ray and Pacchiano, Aldo and Stepleton, Tom and Jiang, Heinrich and Chiappa, Silvia},
  booktitle={Uncertainty in Artificial Intelligence},
  year={2020},
}


@inproceedings{kearns2018preventing,
  title={Preventing fairness gerrymandering: Auditing and learning for subgroup fairness},
  author={Kearns, Michael and Neel, Seth and Roth, Aaron and Wu, Zhiwei Steven},
  booktitle={International Conference on Machine Learning},
  year={2018},
}


@inproceedings{goh2016satisfying,
  title={Satisfying real-world goals with dataset constraints},
  author={Goh, Gabriel and Cotter, Andrew and Gupta, Maya and Friedlander, Michael P},
  booktitle={Advances in Neural Information Processing Systems},
  year={2016}
}


@inproceedings{donini2018empirical,
  title={Empirical risk minimization under fairness constraints},
  author={Donini, Michele and Oneto, Luca and Ben-David, Shai and Shawe-Taylor, John and Pontil, Massimiliano},
  booktitle={Advances in Neural Information Processing Systems},
  year={2018}
}


%------------------------------------------------------------------------- Post-processing


@article{hardt2016equality,
  title={Equality of opportunity in supervised learning},
  author={Hardt, Moritz and Price, Eric and Srebro, Nati},
  journal={Advances in neural information processing systems},
  year={2016}
}


@inproceedings{pleiss2017fairness,
  title={On fairness and calibration},
  author={Pleiss, Geoff and Raghavan, Manish and Wu, Felix and Kleinberg, Jon and Weinberger, Kilian Q},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}


@inproceedings{woodworth2017learning,
  title={Learning non-discriminatory predictors},
  author={Woodworth, Blake and Gunasekar, Suriya and Ohannessian, Mesrob I and Srebro, Nathan},
  booktitle={Conference on Learning Theory},
  year={2017},
}


%------------------------------------------------------------------------- Notion


@inproceedings{dwork2012fairness,
  title={Fairness through awareness},
  author={Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Richard},
  booktitle={Innovations in Theoretical Computer Science Conference},
  year={2012}
}


@inproceedings{chen2018my,
  title={Why is my classifier discriminatory?},
  author={Chen, Irene Y and Johansson, Fredrik D and Sontag, David},
  booktitle={Advances in Neural Information Processing Systems},
  year={2018}
}


%------------------------------------------------------------------------- Tradeoff
@inproceedings{zhao2019inherent,
  title={Inherent tradeoffs in learning fair representations},
  author={Zhao, Han and Gordon, Geoff},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}




@inproceedings{dutta2020there,
  title={Is there a trade-off between fairness and accuracy? a perspective using mismatched hypothesis testing},
  author={Dutta, Sanghamitra and Wei, Dennis and Yueksel, Hazar and Chen, Pin-Yu and Liu, Sijia and Varshney, Kush},
  booktitle={International Conference on Machine Learning},
  year={2020},
}


@inproceedings{menon2018cost,
  title={The cost of fairness in binary classification},
  author={Menon, Aditya Krishna and Williamson, Robert C},
  booktitle={Conference on Fairness, Accountability and Transparency},
  year={2018},
}


%------------------------------------------------------------------------- Influence function


@inproceedings{koh2017understanding,
  title={Understanding black-box predictions via influence functions},
  author={Koh, Pang Wei and Liang, Percy},
  booktitle={International Conference on Machine Learning},
  year={2017},
}


@inproceedings{giordano2019swiss,
  title={A swiss army infinitesimal jackknife},
  author={Giordano, Ryan and Stephenson, William and Liu, Runjing and Jordan, Michael and Broderick, Tamara},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2019},
}


@article{cook1980characterizations,
  title={Characterizations of an empirical influence function for detecting influential cases in regression},
  author={Cook, R Dennis and Weisberg, Sanford},
  journal={Technometrics},
  year={1980},
  publisher={Taylor \& Francis}
}


@article{cook1977detection,
  title={Detection of influential observation in linear regression},
  author={Cook, R Dennis},
  journal={Technometrics},
  year={1977},
  publisher={Taylor \& Francis}
}


@book{hampel2011robust,
  title={Robust statistics: the approach based on influence functions},
  author={Hampel, Frank R and Ronchetti, Elvezio M and Rousseeuw, Peter J and Stahel, Werner A},
  year={2011},
  publisher={John Wiley \& Sons}
}


@article{christmann2004robustness,
  title={On robustness properties of convex risk minimization methods for pattern recognition},
  author={Christmann, Andreas and Steinwart, Ingo},
  journal={Journal of Machine Learning Research},
  year={2004},
  publisher={JMLR. org}
}


@inproceedings{liu2014efficient,
  title={Efficient approximation of cross-validation for kernel methods using Bouligand influence function},
  author={Liu, Yong and Jiang, Shali and Liao, Shizhong},
  booktitle={International Conference on Machine Learning},
  year={2014},
}


@inproceedings{koh2019accuracy,
  title={On the accuracy of influence functions for measuring group effects},
  author={Koh, Pang Wei and Ang, Kai-Siang and Teo, Hubert HK and Liang, Percy},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}


%------------------------------------------------------------------------- Misc


@article{cotter2019optimization,
  title={Optimization with Non-Differentiable Constraints with Applications to Fairness, Recall, Churn, and Other Goals.},
  author={Cotter, Andrew and Jiang, Heinrich and Gupta, Maya R and Wang, Serena and Narayan, Taman and You, Seungil and Sridharan, Karthik},
  journal={Journal of Machine Learning Research},
  year={2019}
}


@article{roth2017stabilizing,
  title={Stabilizing Training of Generative Adversarial Networks through Regularization},
  author={Roth, Kevin and Lucchi, Aurelien and Nowozin, Sebastian and Hofmann, Thomas},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}


%------------------------------------------------------------------------- Experiment


@misc{Dua:2019 ,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }


@misc{adult,
  author = {Ronny Kohavi and Barry Becker},
  title = {Adult Data Set},
  howpublished = "\url{https://archive.ics.uci.edu/ml/datasets/adult}",
}


@misc{compas,
  author = {Julia Angwin, Jeff Larson, Surya Mattu and Lauren Kirchner},
  title = {Machine bias},
  year = 2016,
}


@misc{german,
  author = {Hans Hofmann},
  title = {Statlog (German Credit Data) Data Set},
  howpublished = "\url{https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)}",
}


@misc{gurobi,
  author = {{Gurobi Optimization, LLC}},
  title = {{Gurobi Optimizer Reference Manual}},
  year = 2021,
  url = "https://www.gurobi.com"
}


@article{redmond2002data,
  title={A data-driven software tool for enabling cooperative information sharing among police departments},
  author={Redmond, Michael and Baveja, Alok},
  journal={European Journal of Operational Research},
  year={2002},
  publisher={Elsevier}
}


@InProceedings{Li_2020_CVPR,
author = {Li, Peizhao and Zhao, Han and Liu, Hongfu},
title = {Deep Fair Clustering for Visual Learning},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
month = {June},
year = {2020}
}


@inproceedings{
li2021on,
title={On Dyadic Fairness: Exploring and Mitigating Bias in Graph Connections},
author={Peizhao Li and Yifei Wang and Han Zhao and Pengyu Hong and Hongfu Liu},
booktitle={International Conference on Learning Representations},
year={2021},
}


@inproceedings{10.1145/3447548.3467225,
author = {Song, Hanyu and Li, Peizhao and Liu, Hongfu},
title = {Deep Clustering Based Fair Outlier Detection},
year = {2021},
abstract = {In this paper, we focus on the fairness issues regarding unsupervised outlier detection. Traditional algorithms, without a specific design for algorithmic fairness, could implicitly encode and propagate statistical bias in data and raise societal concerns. To correct such unfairness and deliver a fair set of potential outlier candidates, we propose Deep Clustering based Fair Outlier Detection (DCFOD) that learns a good representation for utility maximization while enforcing the learnable representation to be subgroup-invariant on the sensitive attribute. Considering the coupled and reciprocal nature between clustering and outlier detection, we leverage deep clustering to discover the intrinsic cluster structure and out-of-structure instances. Meanwhile, an adversarial training erases the sensitive pattern for instances for fairness adaptation. Technically, we propose an instance-level weighted representation learning strategy to enhance the joint deep clustering and outlier detection, where the dynamic weight module re-emphasizes contributions of likely-inliers while mitigating the negative impact from outliers. Demonstrated by experiments on eight datasets comparing to 17 outlier detection algorithms, our DCFOD method consistently achieves superior performance on both the outlier detection validity and two types of fairness notions in outlier detection.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
}


@article{lahoti2020fairness,
  title={Fairness without demographics through adversarially reweighted learning},
  author={Lahoti, Preethi and Beutel, Alex and Chen, Jilin and Lee, Kang and Prost, Flavien and Thain, Nithum and Wang, Xuezhi and Chi, Ed},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={728--740},
  year={2020}
}