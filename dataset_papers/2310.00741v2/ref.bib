@inproceedings{maynez2020faithfulness,
  title={On Faithfulness and Factuality in Abstractive Summarization},
  author={Maynez, Joshua and Narayan, Shashi and Bohnet, Bernd and McDonald, Ryan},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={1906--1919},
  year={2020}
}
@inproceedings{fabbri-etal-2022-qafacteval,
    title = "{QAF}act{E}val: Improved {QA}-Based Factual Consistency Evaluation for Summarization",
    author = "Fabbri, Alexander  and
      Wu, Chien-Sheng  and
      Liu, Wenhao  and
      Xiong, Caiming",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.187",
    doi = "10.18653/v1/2022.naacl-main.187",
    pages = "2587--2601",
    abstract = "Factual consistency is an essential quality of text summarization models in practical settings. Existing work in evaluating this dimension can be broadly categorized into two lines of research, entailment-based and question answering (QA)-based metrics, and different experimental setups often lead to contrasting conclusions as to which paradigm performs the best. In this work, we conduct an extensive comparison of entailment and QA-based metrics, demonstrating that carefully choosing the components of a QA-based metric, especially question generation and answerability classification, is critical to performance. Building on those insights, we propose an optimized metric, which we call QAFactEval, that leads to a 14{\%} average improvement over previous QA-based metrics on the SummaC factual consistency benchmark, and also outperforms the best-performing entailment-based metric. Moreover, we find that QA-based and entailment-based metrics can offer complementary signals and be combined into a single metric for a further performance boost.",
}

@inproceedings{lewis2020bart,
  title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
  author={Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Veselin and Zettlemoyer, Luke},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={7871--7880},
  year={2020}
}

@inproceedings{kryscinski2020evaluating,
 address = {Online},
 author = {Kryscinski, Wojciech  and
McCann, Bryan  and
Xiong, Caiming  and
Socher, Richard},
 booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
 doi = {10.18653/v1/2020.emnlp-main.750},
 pages = {9332--9346},
 publisher = {Association for Computational Linguistics},
 title = {Evaluating the Factual Consistency of Abstractive Text Summarization},
 url = {https://aclanthology.org/2020.emnlp-main.750},
 year = {2020}
}

@inproceedings{pagnoni2021understanding,
 address = {Online},
 author = {Pagnoni, Artidoro  and
Balachandran, Vidhisha  and
Tsvetkov, Yulia},
 booktitle = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
 doi = {10.18653/v1/2021.naacl-main.383},
 pages = {4812--4829},
 publisher = {Association for Computational Linguistics},
 title = {Understanding Factuality in Abstractive Summarization with {FRANK}: A Benchmark for Factuality Metrics},
 url = {https://aclanthology.org/2021.naacl-main.383},
 year = {2021}
}
@article{zhang2023benchmarking,
  title={Benchmarking large language models for news summarization},
  author={Zhang, Tianyi and Ladhak, Faisal and Durmus, Esin and Liang, Percy and McKeown, Kathleen and Hashimoto, Tatsunori B},
  journal={arXiv preprint arXiv:2301.13848},
  year={2023}
}
@article{kamoi2023wice,
  title={WiCE: Real-World Entailment for Claims in Wikipedia},
  author={Kamoi, Ryo and Goyal, Tanya and Rodriguez, Juan Diego and Durrett, Greg},
  journal={arXiv e-prints},
  pages={arXiv--2303},
  year={2023}
}
@inproceedings{thorne2018fever,
  title={FEVER: a Large-scale Dataset for Fact Extraction and VERification},
  author={Thorne, James and Vlachos, Andreas and Christodoulopoulos, Christos and Mittal, Arpit},
  booktitle={Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
  pages={809--819},
  year={2018}
}
@article{openai2023gpt4,
  title={{GPT}-4 Technical Report},
  author={OpenAI},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}
@inproceedings{kryscinski-etal-2019-neural,
 address = {Hong Kong, China},
 author = {Kryscinski, Wojciech  and
Keskar, Nitish Shirish  and
McCann, Bryan  and
Xiong, Caiming  and
Socher, Richard},
 booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
 doi = {10.18653/v1/D19-1051},
 pages = {540--551},
 publisher = {Association for Computational Linguistics},
 title = {Neural Text Summarization: A Critical Evaluation},
 url = {https://aclanthology.org/D19-1051},
 year = {2019}
}
@inproceedings{goodrich2019assessing,
 author = {Ben Goodrich and
Vinay Rao and
Peter J. Liu and
Mohammad Saleh},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/conf/kdd/GoodrichRLS19.bib},
 booktitle = {Proceedings of the 25th {ACM} {SIGKDD} International Conference on
Knowledge Discovery {\&} Data Mining, {KDD} 2019, Anchorage, AK, USA,
August 4-8, 2019},
 doi = {10.1145/3292500.3330955},
 editor = {Ankur Teredesai and
Vipin Kumar and
Ying Li and
R{\'{o}}mer Rosales and
Evimaria Terzi and
George Karypis},
 pages = {166--175},
 publisher = {{ACM}},
 timestamp = {Sun, 28 Jul 2019 01:00:00 +0200},
 title = {Assessing The Factual Accuracy of Generated Text},
 url = {https://doi.org/10.1145/3292500.3330955},
 year = {2019}
}
@article{chatgpt,
  title={ChatGPT: Optimizing Language Models for Dialogue},
  author={OpenAI},
  journal={OpenAI Blog},
  year={2022},
  url={https://openai.com/blog/chatgpt/}
}
@article{borji2023categorical,
  title={A categorical archive of ChatGPT failures},
  author={Borji, Ali},
  journal={arXiv preprint arXiv:2302.03494},
  year={2023}
}
@article{zhuo2023exploring,
  title={Exploring ai ethics of chatgpt: A diagnostic analysis},
  author={Zhuo, Terry Yue and Huang, Yujin and Chen, Chunyang and Xing, Zhenchang},
  journal={arXiv preprint arXiv:2301.12867},
  year={2023}
}
@misc{min2023factscore,
      title={FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation}, 
      author={Sewon Min and Kalpesh Krishna and Xinxi Lyu and Mike Lewis and Wen-tau Yih and Pang Wei Koh and Mohit Iyyer and Luke Zettlemoyer and Hannaneh Hajishirzi},
      year={2023},
      eprint={2305.14251},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{weiemergent,
  title={Emergent Abilities of Large Language Models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={Transactions on Machine Learning Research}
}
@inproceedings{DBLP:conf/nips/Wei0SBIXCLZ22,
  author       = {Jason Wei and
                  Xuezhi Wang and
                  Dale Schuurmans and
                  Maarten Bosma and
                  Brian Ichter and
                  Fei Xia and
                  Ed H. Chi and
                  Quoc V. Le and
                  Denny Zhou},
  title        = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  booktitle    = {NeurIPS},
  year         = {2022},
  url          = {http://papers.nips.cc/paper\_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html},
  timestamp    = {Thu, 11 May 2023 17:08:21 +0200},
  biburl       = {https://dblp.org/rec/conf/nips/Wei0SBIXCLZ22.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{kryscinski-etal-2020-evaluating,
    title = "Evaluating the Factual Consistency of Abstractive Text Summarization",
    author = "Kryscinski, Wojciech  and
      McCann, Bryan  and
      Xiong, Caiming  and
      Socher, Richard",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.750",
    doi = "10.18653/v1/2020.emnlp-main.750",
    pages = "9332--9346",
    abstract = "The most common metrics for assessing summarization algorithms do not account for whether summaries are factually consistent with source documents. We propose a weakly-supervised, model-based approach for verifying factual consistency and identifying conflicts between source documents and generated summaries. Training data is generated by applying a series of rule-based transformations to the sentences of source documents.The factual consistency model is then trained jointly for three tasks: 1) predict whether each summary sentence is factually consistent or not, 2) in either case, extract a span in the source document to support this consistency prediction, 3) for each summary sentence that is deemed inconsistent, extract the inconsistent span from it. Transferring this model to summaries generated by several neural models reveals that this highly scalable approach outperforms previous models, including those trained with strong supervision using datasets from related domains, such as natural language inference and fact checking. Additionally, human evaluation shows that the auxiliary span extraction tasks provide useful assistance in the process of verifying factual consistency. We also release a manually annotated dataset for factual consistency verification, code for training data generation, and trained model weights at https://github.com/salesforce/factCC.",
}
@inproceedings{wang-etal-2020-asking,
    title = "Asking and Answering Questions to Evaluate the Factual Consistency of Summaries",
    author = "Wang, Alex  and
      Cho, Kyunghyun  and
      Lewis, Mike",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.450",
    doi = "10.18653/v1/2020.acl-main.450",
    pages = "5008--5020",
    abstract = "Practical applications of abstractive summarization models are limited by frequent factual inconsistencies with respect to their input. Existing automatic evaluation metrics for summarization are largely insensitive to such errors. We propose QAGS (pronounced {``}kags{''}), an automatic evaluation protocol that is designed to identify factual inconsistencies in a generated summary. QAGS is based on the intuition that if we ask questions about a summary and its source, we will receive similar answers if the summary is factually consistent with the source. To evaluate QAGS, we collect human judgments of factual consistency on model-generated summaries for the CNN/DailyMail (Hermann et al., 2015) and XSUM (Narayan et al., 2018) summarization datasets. QAGS has substantially higher correlations with these judgments than other automatic evaluation metrics. Also, QAGS offers a natural form of interpretability: The answers and questions generated while computing QAGS indicate which tokens of a summary are inconsistent and why. We believe QAGS is a promising tool in automatically generating usable and factually consistent text. Code for QAGS will be available at https://github.com/W4ngatang/qags.",
}
@misc{gao2022rarr,
      title={RARR: Researching and Revising What Language Models Say, Using Language Models}, 
      author={Luyu Gao and Zhuyun Dai and Panupong Pasupat and Anthony Chen and Arun Tejasvi Chaganty and Yicheng Fan and Vincent Y. Zhao and Ni Lao and Hongrae Lee and Da-Cheng Juan and Kelvin Guu},
      year={2022},
      eprint={2210.08726},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{frieder2023mathematical,
  title={Mathematical capabilities of chatgpt},
  author={Frieder, Simon and Pinchetti, Luca and Griffiths, Ryan-Rhys and Salvatori, Tommaso and Lukasiewicz, Thomas and Petersen, Philipp Christian and Chevalier, Alexis and Berner, Julius},
  journal={arXiv preprint arXiv:2301.13867},
  year={2023}
}
@article{azaria2022chatgpt,
  title={ChatGPT Usage and Limitations},
  author={Azaria, Amos},
  year={2022}
}
@book{bird2009natural, 
  title={Natural language processing with Python: analyzing text with the natural language toolkit}, 
  author={Bird, Steven and Klein, Ewan and Loper, Edward}, 
  year={2009}, 
  publisher={" O'Reilly Media, Inc."} 
}
@article{chen2023evaluating,
  title={Evaluating Factual Consistency of Summaries with Large Language Models},
  author={Chen, Shiqi and Gao, Siyang and He, Junxian},
  journal={arXiv e-prints},
  pages={arXiv--2305},
  year={2023}
}

% llama
@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@inproceedings{lee-etal-2020-language,
    title = "Language Models as Fact Checkers?",
    author = "Lee, Nayeon  and
      Li, Belinda Z.  and
      Wang, Sinong  and
      Yih, Wen-tau  and
      Ma, Hao  and
      Khabsa, Madian",
    booktitle = "Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER)",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.fever-1.5",
    doi = "10.18653/v1/2020.fever-1.5",
    pages = "36--41",
    abstract = "Recent work has suggested that language models (LMs) store both common-sense and factual knowledge learned from pre-training data. In this paper, we leverage this implicit knowledge to create an effective end-to-end fact checker using a solely a language model, without any external knowledge or explicit retrieval components. While previous work on extracting knowledge from LMs have focused on the task of open-domain question answering, to the best of our knowledge, this is the first work to examine the use of language models as fact checkers. In a closed-book setting, we show that our zero-shot LM approach outperforms a random baseline on the standard FEVER task, and that our finetuned LM compares favorably with standard baselines. Though we do not ultimately outperform methods which use explicit knowledge bases, we believe our exploration shows that this method is viable and has much room for exploration.",
}

@article{fabbri-etal-2021-summeval,
    title = "{S}umm{E}val: Re-evaluating Summarization Evaluation",
    author = "Fabbri, Alexander R.  and
      Kry{\'s}ci{\'n}ski, Wojciech  and
      McCann, Bryan  and
      Xiong, Caiming  and
      Socher, Richard  and
      Radev, Dragomir",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "9",
    year = "2021",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2021.tacl-1.24",
    doi = "10.1162/tacl_a_00373",
    pages = "391--409",
    abstract = "Abstract The scarcity of comprehensive up-to-date studies on evaluation metrics for text summarization and the lack of consensus regarding evaluation protocols continue to inhibit progress. We address the existing shortcomings of summarization evaluation methods along five dimensions: 1) we re-evaluate 14 automatic evaluation metrics in a comprehensive and consistent fashion using neural summarization model outputs along with expert and crowd-sourced human annotations; 2) we consistently benchmark 23 recent summarization models using the aforementioned automatic evaluation metrics; 3) we assemble the largest collection of summaries generated by models trained on the CNN/DailyMail news dataset and share it in a unified format; 4) we implement and share a toolkit that provides an extensible and unified API for evaluating summarization models across a broad range of automatic metrics; and 5) we assemble and share the largest and most diverse, in terms of model types, collection of human judgments of model-generated summaries on the CNN/Daily Mail dataset annotated by both expert judges and crowd-source workers. We hope that this work will help promote a more complete evaluation protocol for text summarization as well as advance research in developing evaluation metrics that better correlate with human judgments.",
}

@article{tang2022understanding,
  title={Understanding factual errors in summarization: Errors, summarizers, datasets, error detectors},
  author={Tang, Liyan and Goyal, Tanya and Fabbri, Alexander R and Laban, Philippe and Xu, Jiacheng and Yahvuz, Semih and Kry{\'s}ci{\'n}ski, Wojciech and Rousseau, Justin F and Durrett, Greg},
  journal={arXiv preprint arXiv:2205.12854},
  year={2022}
}

@inproceedings{karadzhov-etal-2017-fully,
    title = "Fully Automated Fact Checking Using External Sources",
    author = "Karadzhov, Georgi  and
      Nakov, Preslav  and
      M{\`a}rquez, Llu{\'\i}s  and
      Barr{\'o}n-Cede{\~n}o, Alberto  and
      Koychev, Ivan",
    booktitle = "Proceedings of the International Conference Recent Advances in Natural Language Processing, {RANLP} 2017",
    month = sep,
    year = "2017",
    address = "Varna, Bulgaria",
    publisher = "INCOMA Ltd.",
    url = "https://doi.org/10.26615/978-954-452-049-6_046",
    doi = "10.26615/978-954-452-049-6_046",
    pages = "344--353",
    abstract = "Given the constantly growing proliferation of false claims online in recent years, there has been also a growing research interest in automatically distinguishing false rumors from factually true claims. Here, we propose a general-purpose framework for fully-automatic fact checking using external sources, tapping the potential of the entire Web as a knowledge source to confirm or reject a claim. Our framework uses a deep neural network with LSTM text encoding to combine semantic kernels with task-specific embeddings that encode a claim together with pieces of potentially relevant text fragments from the Web, taking the source reliability into account. The evaluation results show good performance on two different tasks and datasets: (i) rumor detection and (ii) fact checking of the answers to a question in community question answering forums.",
}

@inproceedings{augenstein-etal-2019-multifc,
    title = "{M}ulti{FC}: A Real-World Multi-Domain Dataset for Evidence-Based Fact Checking of Claims",
    author = "Augenstein, Isabelle  and
      Lioma, Christina  and
      Wang, Dongsheng  and
      Chaves Lima, Lucas  and
      Hansen, Casper  and
      Hansen, Christian  and
      Simonsen, Jakob Grue",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1475",
    doi = "10.18653/v1/D19-1475",
    pages = "4685--4697",
    abstract = "We contribute the largest publicly available dataset of naturally occurring factual claims for the purpose of automatic claim verification. It is collected from 26 fact checking websites in English, paired with textual sources and rich metadata, and labelled for veracity by human expert journalists. We present an in-depth analysis of the dataset, highlighting characteristics and challenges. Further, we present results for automatic veracity prediction, both with established baselines and with a novel method for joint ranking of evidence pages and predicting veracity that outperforms all baselines. Significant performance increases are achieved by encoding evidence, and by modelling metadata. Our best-performing model achieves a Macro F1 of 49.2{\%}, showing that this is a challenging testbed for claim veracity prediction.",
}

@inproceedings{wadden-etal-2020-fact,
    title = "Fact or Fiction: Verifying Scientific Claims",
    author = "Wadden, David  and
      Lin, Shanchuan  and
      Lo, Kyle  and
      Wang, Lucy Lu  and
      van Zuylen, Madeleine  and
      Cohan, Arman  and
      Hajishirzi, Hannaneh",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.609",
    doi = "10.18653/v1/2020.emnlp-main.609",
    pages = "7534--7550",
    abstract = "We introduce scientific claim verification, a new task to select abstracts from the research literature containing evidence that SUPPORTS or REFUTES a given scientific claim, and to identify rationales justifying each decision. To study this task, we construct SciFact, a dataset of 1.4K expert-written scientific claims paired with evidence-containing abstracts annotated with labels and rationales. We develop baseline models for SciFact, and demonstrate that simple domain adaptation techniques substantially improve performance compared to models trained on Wikipedia or political news. We show that our system is able to verify claims related to COVID-19 by identifying evidence from the CORD-19 corpus. Our experiments indicate that SciFact will provide a challenging testbed for the development of new systems designed to retrieve and reason over corpora containing specialized domain knowledge. Data and code for this new task are publicly available at https://github.com/allenai/scifact. A leaderboard and COVID-19 fact-checking demo are available at https://scifact.apps.allenai.org.",
}

@inproceedings{fan-etal-2020-generating,
    title = "Generating Fact Checking Briefs",
    author = "Fan, Angela  and
      Piktus, Aleksandra  and
      Petroni, Fabio  and
      Wenzek, Guillaume  and
      Saeidi, Marzieh  and
      Vlachos, Andreas  and
      Bordes, Antoine  and
      Riedel, Sebastian",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.580",
    doi = "10.18653/v1/2020.emnlp-main.580",
    pages = "7147--7161",
    abstract = "Fact checking at scale is difficult{---}while the number of active fact checking websites is growing, it remains too small for the needs of the contemporary media ecosystem. However, despite good intentions, contributions from volunteers are often error-prone, and thus in practice restricted to claim detection. We investigate how to increase the accuracy and efficiency of fact checking by providing information about the claim before performing the check, in the form of natural language briefs. We investigate passage-based briefs, containing a relevant passage from Wikipedia, entity-centric ones consisting of Wikipedia pages of mentioned entities, and Question-Answering Briefs, with questions decomposing the claim, and their answers. To produce QABriefs, we develop QABriefer, a model that generates a set of questions conditioned on the claim, searches the web for evidence, and generates answers. To train its components, we introduce QABriefDataset We show that fact checking with briefs {---} in particular QABriefs {---} increases the accuracy of crowdworkers by 10{\%} while slightly decreasing the time taken. For volunteer (unpaid) fact checkers, QABriefs slightly increase accuracy and reduce the time required by around 20{\%}.",
}

@article{li2023starcoder,
  title={StarCoder: may the source be with you!},
  author={Li, Raymond and Allal, Loubna Ben and Zi, Yangtian and Muennighoff, Niklas and Kocetkov, Denis and Mou, Chenghao and Marone, Marc and Akiki, Christopher and Li, Jia and Chim, Jenny and others},
  journal={arXiv preprint arXiv:2305.06161},
  year={2023}
}

@article{lightman2023let,
  title={Let's Verify Step by Step},
  author={Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl},
  journal={arXiv preprint arXiv:2305.20050},
  year={2023}
}

@article{taylor2022galactica,
  title={Galactica: A large language model for science},
  author={Taylor, Ross and Kardas, Marcin and Cucurull, Guillem and Scialom, Thomas and Hartshorn, Anthony and Saravia, Elvis and Poulton, Andrew and Kerkez, Viktor and Stojnic, Robert},
  journal={arXiv preprint arXiv:2211.09085},
  year={2022}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}
@inproceedings{brodersen2010balanced,
 author = {Brodersen, Kay Henning and Ong, Cheng Soon and Stephan, Klaas Enno and Buhmann, Joachim M},
 booktitle = {2010 20th international conference on pattern recognition},
 organization = {IEEE},
 pages = {3121--3124},
 title = {The balanced accuracy and its posterior distribution},
 year = {2010}
}

@inproceedings{jung-etal-2022-maieutic,
    title = "Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations",
    author = "Jung, Jaehun  and
      Qin, Lianhui  and
      Welleck, Sean  and
      Brahman, Faeze  and
      Bhagavatula, Chandra  and
      Le Bras, Ronan  and
      Choi, Yejin",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.82",
    pages = "1266--1279",
    abstract = "Pre-trained language models (LMs) struggle with consistent reasoning; recently, prompting LMs to generate explanations that self-guide the inference has emerged as a promising direction to amend this. However, these approaches are fundamentally bounded by the correctness of explanations, which themselves are often noisy and inconsistent. In this work, we develop Maieutic Prompting, which aims to infer a correct answer to a question even from the unreliable generations of LM. Maieutic Prompting induces a tree of explanations abductively (e.g. X is true, because ...) and recursively, then frames the inference as a satisfiability problem over these explanations and their logical relations. We test Maieutic Prompting for true/false QA on three challenging benchmarks that require complex commonsense reasoning. Maieutic Prompting achieves up to 20{\%} better accuracy than state-of-the-art prompting methods, and as a fully unsupervised approach, performs competitively with supervised models. We also show that Maieutic Prompting improves robustness in inference while providing interpretable rationales.",
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@misc{selfinstruct,
  title={Self-Instruct: Aligning Language Model with Self Generated Instructions},
  author={Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A. and Khashabi, Daniel and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2212.10560},
  year={2022}
}
@article{liang2022holistic,
  title={Holistic Evaluation of Language Models},
  author={Liang, Percy and Bommasani, Rishi and Lee, Tony and Tsipras, Dimitris and Soylu, Dilara and Yasunaga, Michihiro and Zhang, Yian and Narayanan, Deepak and Wu, Yuhuai and Kumar, Ananya and others},
  journal={arXiv e-prints},
  pages={arXiv--2211},
  year={2022}
}
@article{wei2023symbol,
  title={Symbol tuning improves in-context learning in language models},
  author={Wei, Jerry and Hou, Le and Lampinen, Andrew and Chen, Xiangning and Huang, Da and Tay, Yi and Chen, Xinyun and Lu, Yifeng and Zhou, Denny and Ma, Tengyu and others},
  journal={arXiv e-prints},
  pages={arXiv--2305},
  year={2023}
}

@article{raffel2020exploring,
  title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of Machine Learning Research},
  volume={21},
  pages={1--67},
  year={2020}
}

@inproceedings{honovich-etal-2022-true,
    title = "{TRUE}: Re-evaluating Factual Consistency Evaluation",
    author = "Honovich, Or  and
      Aharoni, Roee  and
      Herzig, Jonathan  and
      Taitelbaum, Hagai  and
      Kukliansy, Doron  and
      Cohen, Vered  and
      Scialom, Thomas  and
      Szpektor, Idan  and
      Hassidim, Avinatan  and
      Matias, Yossi",
    booktitle = "Proceedings of the Second DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.dialdoc-1.19",
    doi = "10.18653/v1/2022.dialdoc-1.19",
    pages = "161--175",
    abstract = "Grounded text generation systems often generate text that contains factual inconsistencies, hindering their real-world applicability. Automatic factual consistency evaluation may help alleviate this limitation by accelerating evaluation cycles, filtering inconsistent outputs and augmenting training data. While attracting increasing attention, such evaluation metrics are usually developed and evaluated in silo for a single task or dataset, slowing their adoption. Moreover, previous meta-evaluation protocols focused on system-level correlations with human annotations, which leave the example-level accuracy of such metrics unclear.In this work, we introduce TRUE: a comprehensive study of factual consistency metrics on a standardized collection of existing texts from diverse tasks, manually annotated for factual consistency. Our standardization enables an example-level meta-evaluation protocol that is more actionable and interpretable than previously reported correlations, yielding clearer quality measures. Across diverse state-of-the-art metrics and 11 datasets we find that large-scale NLI and question generation-and-answering-based approaches achieve strong and complementary results. We recommend those methods as a starting point for model and metric developers, and hope TRUE will foster progress towards even better methods.",
}
@article{laban2022summac,
  title={SummaC: Re-Visiting NLI-based Models for Inconsistency Detection in Summarization},
  author={Laban, Philippe and Schnabel, Tobias and Bennett, Paul and Hearst, Marti A},
  journal={Transactions of the Association for Computational Linguistics},
  volume={10},
  pages={163--177},
  year={2022}
}
@article{hendrycks2020measuring,
  title={Measuring Massive Multitask Language Understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv e-prints},
  pages={arXiv--2009},
  year={2020}
}
@inproceedings{lin2022truthfulqa,
  title={TruthfulQA: Measuring How Models Mimic Human Falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={3214--3252},
  year={2022}
}

@article{robertson2009probabilistic,
  title={The probabilistic relevance framework: BM25 and beyond},
  author={Robertson, Stephen and Zaragoza, Hugo and others},
  journal={Foundations and Trends{\textregistered} in Information Retrieval},
  volume={3},
  number={4},
  pages={333--389},
  year={2009},
  publisher={Now Publishers, Inc.}
}
@article{li2023halueval,
  title={HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models},
  author={Li, Junyi and Cheng, Xiaoxue and Zhao, Wayne Xin and Nie, Jian-Yun and Wen, Ji-Rong},
  journal={arXiv e-prints},
  pages={arXiv--2305},
  year={2023}
}
@article{schuster2021get,
  title={Get your vitamin C! robust fact verification with contrastive evidence},
  author={Schuster, Tal and Fisch, Adam and Barzilay, Regina},
  journal={arXiv preprint arXiv:2103.08541},
  year={2021}
}
@article{rashkin2023measuring,
  title={Measuring attribution in natural language generation models},
  author={Rashkin, Hannah and Nikolaev, Vitaly and Lamm, Matthew and Aroyo, Lora and Collins, Michael and Das, Dipanjan and Petrov, Slav and Singh Tomar, Gaurav and Turc, Iulia and Reitter, David},
  journal={Computational Linguistics},
  pages={1--66},
  year={2023}
}
@article{dziri2022evaluating,
  title={Evaluating attribution in dialogue systems: The BEGIN benchmark},
  author={Dziri, Nouha and Rashkin, Hannah and Linzen, Tal and Reitter, David},
  journal={Transactions of the Association for Computational Linguistics},
  volume={10},
  pages={1066--1083},
  year={2022},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~â€¦}
}
@article{guo2023close,
  title={How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation, and Detection},
  author={Guo, Biyang and Zhang, Xin and Wang, Ziyuan and Jiang, Minqi and Nie, Jinran and Ding, Yuxuan and Yue, Jianwei and Wu, Yupeng},
  journal={arXiv preprint arXiv:2301.07597},
  year={2023}
}
@article{laban2023llms,
  title={LLMs as Factual Reasoners: Insights from Existing Benchmarks and Beyond},
  author={Laban, Philippe and Kry{\'s}ci{\'n}ski, Wojciech and Agarwal, Divyansh and Fabbri, Alexander R and Xiong, Caiming and Joty, Shafiq and Wu, Chien-Sheng},
  journal={arXiv preprint arXiv:2305.14540},
  year={2023}
}
 @inproceedings{wang2022self,
  title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc V and Chi, Ed H and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}
@misc{vicuna2023,
    title = {Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90\%* ChatGPT Quality},
    url = {https://lmsys.org/blog/2023-03-30-vicuna/},
    author = {Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E. and Stoica, Ion and Xing, Eric P.},
    month = {March},
    year = {2023}
}
@article{hendrycks2021measuring,
  title={Measuring Mathematical Problem Solving With the MATH Dataset},
  author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv e-prints},
  pages={arXiv--2103},
  year={2021}
}
@article{DBLP:journals/corr/abs-2305-14069,
  author       = {Shiqi Chen and
                  Siyang Gao and
                  Junxian He},
  title        = {Evaluating Factual Consistency of Summaries with Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2305.14069},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.14069},
  doi          = {10.48550/arXiv.2305.14069},
  eprinttype    = {arXiv},
  eprint       = {2305.14069},
  timestamp    = {Mon, 05 Jun 2023 15:42:15 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2305-14069.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/tacl/FabbriKMXSR21,
  author       = {Alexander R. Fabbri and
                  Wojciech Kryscinski and
                  Bryan McCann and
                  Caiming Xiong and
                  Richard Socher and
                  Dragomir R. Radev},
  title        = {SummEval: Re-evaluating Summarization Evaluation},
  journal      = {Trans. Assoc. Comput. Linguistics},
  volume       = {9},
  pages        = {391--409},
  year         = {2021},
  url          = {https://doi.org/10.1162/tacl\_a\_00373},
  doi          = {10.1162/tacl\_a\_00373},
  timestamp    = {Fri, 10 Jun 2022 10:35:17 +0200},
  biburl       = {https://dblp.org/rec/journals/tacl/FabbriKMXSR21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}