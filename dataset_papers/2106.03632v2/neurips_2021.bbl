\begin{thebibliography}{59}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahuja et~al.(2020)Ahuja, Shanmugam, Varshney, and
  Dhurandhar]{ahuja2020invariant}
Kartik Ahuja, Karthikeyan Shanmugam, Kush Varshney, and Amit Dhurandhar.
\newblock Invariant risk minimization games.
\newblock In \emph{International Conference on Machine Learning}, pages
  145--155. PMLR, 2020.

\bibitem[Albuquerque et~al.(2019)Albuquerque, Monteiro, Darvishi, Falk, and
  Mitliagkas]{albuquerque2019generalizing}
Isabela Albuquerque, Jo{\~a}o Monteiro, Mohammad Darvishi, Tiago~H Falk, and
  Ioannis Mitliagkas.
\newblock Generalizing to unseen domains via distribution matching.
\newblock \emph{arXiv preprint arXiv:1911.00804}, 2019.

\bibitem[Arjovsky et~al.(2019)Arjovsky, Bottou, Gulrajani, and
  Lopez-Paz]{arjovsky2019invariant}
Martin Arjovsky, L{\'e}on Bottou, Ishaan Gulrajani, and David Lopez-Paz.
\newblock Invariant risk minimization.
\newblock \emph{arXiv preprint arXiv:1907.02893}, 2019.

\bibitem[Arora et~al.(2017)Arora, Ge, Liang, Ma, and
  Zhang]{arora2017generalization}
Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi~Zhang.
\newblock Generalization and equilibrium in generative adversarial nets
  ({GAN}s).
\newblock In \emph{International Conference on Machine Learning}, pages
  224--232. PMLR, 2017.

\bibitem[Bartlett and Mendelson(2002)]{bartlett2002rademacher}
Peter~L Bartlett and Shahar Mendelson.
\newblock Rademacher and gaussian complexities: Risk bounds and structural
  results.
\newblock \emph{Journal of Machine Learning Research}, 3\penalty0
  (Nov):\penalty0 463--482, 2002.

\bibitem[Bartlett et~al.(2006)Bartlett, Jordan, and
  McAuliffe]{bartlett2006convexity}
Peter~L Bartlett, Michael~I Jordan, and Jon~D McAuliffe.
\newblock Convexity, classification, and risk bounds.
\newblock \emph{Journal of the American Statistical Association}, 101\penalty0
  (473):\penalty0 138--156, 2006.

\bibitem[Bartlett et~al.(2019)Bartlett, Harvey, Liaw, and
  Mehrabian]{bartlett2019nearly}
Peter~L Bartlett, Nick Harvey, Christopher Liaw, and Abbas Mehrabian.
\newblock Nearly-tight {VC}-dimension and pseudodimension bounds for piecewise
  linear neural networks.
\newblock \emph{J. Mach. Learn. Res.}, 20\penalty0 (63):\penalty0 1--17, 2019.

\bibitem[Ben-David et~al.(2007)Ben-David, Blitzer, Crammer, and
  Pereira]{ben2007analysis}
Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira.
\newblock Analysis of representations for domain adaptation.
\newblock In \emph{Advances in neural information processing systems}, pages
  137--144, 2007.

\bibitem[Ben-David et~al.(2010)Ben-David, Blitzer, Crammer, Kulesza, Pereira,
  and Vaughan]{ben2010theory}
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and
  Jennifer~Wortman Vaughan.
\newblock A theory of learning from different domains.
\newblock \emph{Machine learning}, 79\penalty0 (1-2):\penalty0 151--175, 2010.

\bibitem[Blanchard et~al.(2011)Blanchard, Lee, and
  Scott]{blanchard2011generalizing}
Gilles Blanchard, Gyemin Lee, and Clayton Scott.
\newblock Generalizing from several related classification tasks to a new
  unlabeled sample.
\newblock \emph{Advances in neural information processing systems},
  24:\penalty0 2178--2186, 2011.

\bibitem[Blanchard et~al.(2021)Blanchard, Deshmukh, Dogan, Lee, and
  Scott]{blanchard2021domain}
Gilles Blanchard, Aniket~Anand Deshmukh, Urun Dogan, Gyemin Lee, and Clayton
  Scott.
\newblock Domain generalization by marginal transfer learning.
\newblock \emph{Journal of Machine Learning Research}, 22\penalty0
  (2):\penalty0 1--55, 2021.

\bibitem[Blitzer et~al.(2007)Blitzer, Crammer, Kulesza, Pereira, and
  Wortman]{blitzer2007learning}
John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer
  Wortman.
\newblock Learning bounds for domain adaptation.
\newblock In \emph{Advances in neural information processing systems}, 2007.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{ChenKNH20}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, pages 1597--1607, 2020.
\newblock URL \url{http://proceedings.mlr.press/v119/chen20j.html}.

\bibitem[Christie et~al.(2018)Christie, Fendley, Wilson, and
  Mukherjee]{christie2018functional}
Gordon Christie, Neil Fendley, James Wilson, and Ryan Mukherjee.
\newblock Functional map of the world.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 6172--6180, 2018.

\bibitem[Cohen et~al.(2019)Cohen, Rosenfeld, and Kolter]{cohen2019certified}
Jeremy Cohen, Elan Rosenfeld, and Zico Kolter.
\newblock Certified adversarial robustness via randomized smoothing.
\newblock In \emph{International Conference on Machine Learning}, pages
  1310--1320. PMLR, 2019.

\bibitem[Ganin and Lempitsky(2015)]{ganin2015unsupervised}
Yaroslav Ganin and Victor Lempitsky.
\newblock Unsupervised domain adaptation by backpropagation.
\newblock In \emph{International conference on machine learning}, pages
  1180--1189. PMLR, 2015.

\bibitem[Ganin et~al.(2016)Ganin, Ustinova, Ajakan, Germain, Larochelle,
  Laviolette, Marchand, and Lempitsky]{ganin2016domain}
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo
  Larochelle, Fran{\c{c}}ois Laviolette, Mario Marchand, and Victor Lempitsky.
\newblock Domain-adversarial training of neural networks.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 2096--2030, 2016.

\bibitem[Ghifary et~al.(2015)Ghifary, Kleijn, Zhang, and
  Balduzzi]{ghifary2015domain}
Muhammad Ghifary, W~Bastiaan Kleijn, Mengjie Zhang, and David Balduzzi.
\newblock Domain generalization for object recognition with multi-task
  autoencoders.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 2551--2559, 2015.

\bibitem[Grill et~al.(2020)Grill, Strub, Altché, Tallec, Richemond,
  Buchatskaya, Doersch, Ávila Pires, Guo, Azar, Piot, Kavukcuoglu, Munos, and
  Valko]{Grill2020bootstrap}
Jean-Bastien Grill, Florian Strub, Florent Altché, Corentin Tallec, Pierre~H.
  Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Ávila Pires, Zhaohan
  Guo, Mohammad~Gheshlaghi Azar, Bilal Piot, Koray Kavukcuoglu, Rémi Munos,
  and Michal Valko.
\newblock Bootstrap your own latent - a new approach to self-supervised
  learning.
\newblock In \emph{NeurIPS}, 2020.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2020/hash/f3ada80d5c4ee70142b17b8192b2958e-Abstract.html}.

\bibitem[Gulrajani and Lopez-Paz(2020)]{gulrajani2020search}
Ishaan Gulrajani and David Lopez-Paz.
\newblock In search of lost domain generalization.
\newblock \emph{arXiv preprint arXiv:2007.01434}, 2020.

\bibitem[He et~al.(2020)He, Fan, Wu, Xie, and Girshick]{he2020momentum}
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 9729--9738, 2020.

\bibitem[Huang et~al.(2020)Huang, Wang, Xing, and Huang]{huang2020self}
Zeyi Huang, Haohan Wang, Eric~P. Xing, and Dong Huang.
\newblock Self-challenging improves cross-domain generalization.
\newblock In \emph{ECCV}, 2020.

\bibitem[Koh et~al.(2020)Koh, Sagawa, Marklund, Xie, Zhang, Balsubramani, Hu,
  Yasunaga, Phillips, Gao, et~al.]{koh2020wilds}
Pang~Wei Koh, Shiori Sagawa, Henrik Marklund, Sang~Michael Xie, Marvin Zhang,
  Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard~Lanas Phillips,
  Irena Gao, et~al.
\newblock {WILDS}: A benchmark of in-the-wild distribution shifts.
\newblock \emph{arXiv preprint arXiv:2012.07421}, 2020.

\bibitem[Koltchinskii(2010)]{koltchinskii2010rademacher}
Vladimir Koltchinskii.
\newblock Rademacher complexities and bounding the excess risk in active
  learning.
\newblock \emph{The Journal of Machine Learning Research}, 11:\penalty0
  2457--2485, 2010.

\bibitem[Koyama and Yamaguchi(2021)]{koyama2021invariance}
Masanori Koyama and Shoichiro Yamaguchi.
\newblock When is invariance useful in an out-of-distribution generalization
  problem?, 2021.

\bibitem[Krueger et~al.(2020)Krueger, Caballero, Jacobsen, Zhang, Binas, Zhang,
  Priol, and Courville]{krueger2020out}
David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan
  Binas, Dinghuai Zhang, Remi~Le Priol, and Aaron Courville.
\newblock Out-of-distribution generalization via risk extrapolation ({Rex}).
\newblock \emph{arXiv preprint arXiv:2003.00688}, 2020.

\bibitem[Lampert et~al.(2009)Lampert, Nickisch, and
  Harmeling]{lampert2009learning}
Christoph~H Lampert, Hannes Nickisch, and Stefan Harmeling.
\newblock Learning to detect unseen object classes by between-class attribute
  transfer.
\newblock In \emph{2009 IEEE Conference on Computer Vision and Pattern
  Recognition}, pages 951--958. IEEE, 2009.

\bibitem[Li et~al.(2017)Li, Yang, Song, and Hospedales]{li2017deeper}
Da~Li, Yongxin Yang, Yi-Zhe Song, and Timothy~M Hospedales.
\newblock Deeper, broader and artier domain generalization.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 5542--5550, 2017.

\bibitem[Li et~al.(2018{\natexlab{a}})Li, Yang, Song, and
  Hospedales]{li2018learning}
Da~Li, Yongxin Yang, Yi-Zhe Song, and Timothy Hospedales.
\newblock Learning to generalize: Meta-learning for domain generalization.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~32, 2018{\natexlab{a}}.

\bibitem[Li et~al.(2018{\natexlab{b}})Li, Pan, Wang, and Kot]{li2018domain2}
Haoliang Li, Sinno~Jialin Pan, Shiqi Wang, and Alex~C Kot.
\newblock Domain generalization with adversarial feature learning.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 5400--5409, 2018{\natexlab{b}}.

\bibitem[Li et~al.(2018{\natexlab{c}})Li, Tian, Gong, Liu, Liu, Zhang, and
  Tao]{li2018deep}
Ya~Li, Xinmei Tian, Mingming Gong, Yajing Liu, Tongliang Liu, Kun Zhang, and
  Dacheng Tao.
\newblock Deep domain generalization via conditional invariant adversarial
  networks.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 624--639, 2018{\natexlab{c}}.

\bibitem[Long et~al.(2017)Long, Zhu, Wang, and Jordan]{long2017deep}
Mingsheng Long, Han Zhu, Jianmin Wang, and Michael~I Jordan.
\newblock Deep transfer learning with joint adaptation networks.
\newblock In \emph{International conference on machine learning}, pages
  2208--2217. PMLR, 2017.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2018towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Mohri et~al.(2018)Mohri, Rostamizadeh, and
  Talwalkar]{mohri2018foundations}
Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar.
\newblock \emph{Foundations of machine learning}.
\newblock MIT press, 2018.

\bibitem[Muandet et~al.(2013)Muandet, Balduzzi, and
  Sch{\"o}lkopf]{muandet2013domain}
Krikamol Muandet, David Balduzzi, and Bernhard Sch{\"o}lkopf.
\newblock Domain generalization via invariant feature representation.
\newblock In \emph{International Conference on Machine Learning}, pages 10--18.
  PMLR, 2013.

\bibitem[M{\"u}ller(1997)]{muller1997integral}
Alfred M{\"u}ller.
\newblock Integral probability metrics and their generating classes of
  functions.
\newblock \emph{Advances in Applied Probability}, pages 429--443, 1997.

\bibitem[Nam et~al.(2019)Nam, Lee, Park, Yoon, and Yoo]{nam2019reducing}
Hyeonseob Nam, HyunJae Lee, Jongchan Park, Wonjun Yoon, and Donggeun Yoo.
\newblock Reducing domain gap via style-agnostic networks.
\newblock \emph{arXiv preprint arXiv:1910.11645}, 2019.

\bibitem[Natarajan(1989)]{natarajan1989learning}
Balas~K Natarajan.
\newblock On learning sets and functions.
\newblock \emph{Machine Learning}, 4\penalty0 (1):\penalty0 67--97, 1989.

\bibitem[Peters et~al.(2016)Peters, B{\"u}hlmann, and
  Meinshausen]{peters2016causal}
Jonas Peters, Peter B{\"u}hlmann, and Nicolai Meinshausen.
\newblock Causal inference by using invariant prediction: identification and
  confidence intervals.
\newblock \emph{Journal of the Royal Statistical Society. Series B (Statistical
  Methodology)}, pages 947--1012, 2016.

\bibitem[Pezeshki et~al.(2020)Pezeshki, Kaba, Bengio, Courville, Precup, and
  Lajoie]{pezeshki2020gradient}
Mohammad Pezeshki, S{\'e}kou-Oumar Kaba, Yoshua Bengio, Aaron Courville, Doina
  Precup, and Guillaume Lajoie.
\newblock Gradient starvation: A learning proclivity in neural networks.
\newblock \emph{arXiv preprint arXiv:2011.09468}, 2020.

\bibitem[Rosenfeld et~al.(2021)Rosenfeld, Ravikumar, and
  Risteski]{rosenfeld2020risks}
Elan Rosenfeld, Pradeep~Kumar Ravikumar, and Andrej Risteski.
\newblock The risks of invariant risk minimization.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=BbNIbVPJ-42}.

\bibitem[Rudin(1987)]{rudin1987real}
Walter Rudin.
\newblock \emph{Real and complex analysis}.
\newblock McGraw-Hill Education, 1987.

\bibitem[Sagawa* et~al.(2020)Sagawa*, Koh*, Hashimoto, and
  Liang]{Sagawa*2020Distributionally}
Shiori Sagawa*, Pang~Wei Koh*, Tatsunori~B. Hashimoto, and Percy Liang.
\newblock Distributionally robust neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=ryxGuJrFvS}.

\bibitem[Shalev-Shwartz and Ben-David(2014)]{shalev2014understanding}
Shai Shalev-Shwartz and Shai Ben-David.
\newblock \emph{Understanding machine learning: From theory to algorithms}.
\newblock Cambridge university press, 2014.

\bibitem[Sinha et~al.(2017)Sinha, Namkoong, Volpi, and
  Duchi]{sinha2017certifying}
Aman Sinha, Hongseok Namkoong, Riccardo Volpi, and John Duchi.
\newblock Certifying some distributional robustness with principled adversarial
  training.
\newblock \emph{arXiv preprint arXiv:1710.10571}, 2017.

\bibitem[Sriperumbudur et~al.(2012)Sriperumbudur, Fukumizu, Gretton,
  Sch{\"o}lkopf, Lanckriet, et~al.]{sriperumbudur2009integral}
Bharath~K Sriperumbudur, Kenji Fukumizu, Arthur Gretton, Bernhard
  Sch{\"o}lkopf, Gert~RG Lanckriet, et~al.
\newblock On the empirical estimation of integral probability metrics.
\newblock \emph{Electronic Journal of Statistics}, 6:\penalty0 1550--1599,
  2012.

\bibitem[Sun and Saenko(2016)]{sun2016deep}
Baochen Sun and Kate Saenko.
\newblock Deep {CORAL}: Correlation alignment for deep domain adaptation.
\newblock In \emph{European conference on computer vision}, pages 443--450.
  Springer, 2016.

\bibitem[Tachet~des Combes et~al.(2020)Tachet~des Combes, Zhao, Wang, and
  Gordon]{tachet2020domain}
Remi Tachet~des Combes, Han Zhao, Yu-Xiang Wang, and Geoffrey~J Gordon.
\newblock Domain adaptation with conditional distribution matching and
  generalized label shift.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Tzeng et~al.(2017)Tzeng, Hoffman, Saenko, and
  Darrell]{tzeng2017adversarial}
Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell.
\newblock Adversarial discriminative domain adaptation.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 7167--7176, 2017.

\bibitem[Vapnik(1992)]{vapnik1992principles}
Vladimir Vapnik.
\newblock Principles of risk minimization for learning theory.
\newblock In \emph{Advances in neural information processing systems}, pages
  831--838, 1992.

\bibitem[Venkateswara et~al.(2017)Venkateswara, Eusebio, Chakraborty, and
  Panchanathan]{venkateswara2017deep}
Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman
  Panchanathan.
\newblock Deep hashing network for unsupervised domain adaptation.
\newblock In \emph{({IEEE}) Conference on Computer Vision and Pattern
  Recognition ({CVPR})}, 2017.

\bibitem[Volpi et~al.(2018)Volpi, Namkoong, Sener, Duchi, Murino, and
  Savarese]{volpi2018generalizing}
Riccardo Volpi, Hongseok Namkoong, Ozan Sener, John~C Duchi, Vittorio Murino,
  and Silvio Savarese.
\newblock Generalizing to unseen domains via adversarial data augmentation.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Xu et~al.(2020)Xu, Zhang, Ni, Li, Wang, Tian, and
  Zhang]{xu2020adversarial}
Minghao Xu, Jian Zhang, Bingbing Ni, Teng Li, Chengjie Wang, Qi~Tian, and
  Wenjun Zhang.
\newblock Adversarial domain adaptation with domain mixup.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pages 6502--6509, 2020.

\bibitem[Yan et~al.(2020)Yan, Song, Li, Zou, and Ren]{yan2020improve}
Shen Yan, Huan Song, Nanxiang Li, Lincan Zou, and Liu Ren.
\newblock Improve unsupervised domain adaptation with mixup training.
\newblock \emph{arXiv preprint arXiv:2001.00677}, 2020.

\bibitem[Ye et~al.(2021)Ye, Xie, Cai, Li, Li, and Wang]{ye2021theoretical}
Haotian Ye, Chuanlong Xie, Tianle Cai, Ruichen Li, Zhenguo Li, and Liwei Wang.
\newblock Towards a theoretical framework of out-of-distribution
  generalization, 2021.

\bibitem[Zhang and Yang(2021)]{zhang2017survey}
Yu~Zhang and Qiang Yang.
\newblock A survey on multi-task learning.
\newblock \emph{IEEE Transactions on Knowledge and Data Engineering}, pages
  1--1, 2021.
\newblock \doi{10.1109/TKDE.2021.3070203}.

\bibitem[Zhang et~al.(2019)Zhang, Liu, Long, and Jordan]{zhang2019bridging}
Yuchen Zhang, Tianle Liu, Mingsheng Long, and Michael Jordan.
\newblock Bridging theory and algorithm for domain adaptation.
\newblock In \emph{International Conference on Machine Learning}, pages
  7404--7413. PMLR, 2019.

\bibitem[Zhao et~al.(2018)Zhao, Zhang, Wu, Moura, Costeira, and
  Gordon]{zhao2018adversarial}
Han Zhao, Shanghang Zhang, Guanhang Wu, Jos{\'e}~MF Moura, Joao~P Costeira, and
  Geoffrey~J Gordon.
\newblock Adversarial multiple source domain adaptation.
\newblock \emph{Advances in neural information processing systems},
  31:\penalty0 8559--8570, 2018.

\bibitem[Zhao et~al.(2019)Zhao, Des~Combes, Zhang, and
  Gordon]{zhao2019learning}
Han Zhao, Remi~Tachet Des~Combes, Kun Zhang, and Geoffrey Gordon.
\newblock On learning invariant representations for domain adaptation.
\newblock In \emph{International Conference on Machine Learning}, pages
  7523--7532. PMLR, 2019.

\end{thebibliography}
