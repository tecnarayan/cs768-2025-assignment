\begin{thebibliography}{10}

\bibitem{openai2023gpt4}
OpenAI.
\newblock Gpt-4 technical report, 2023.

\bibitem{anil2023palm}
Rohan Anil, Andrew~M. Dai, and et. al.
\newblock Palm 2 technical report, 2023.

\bibitem{touvron2023llama}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample.
\newblock Llama: Open and efficient foundation language models, 2023.

\bibitem{llama2}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock {\em arXiv preprint arXiv:2307.09288}, 2023.

\bibitem{yang2023baichuan}
Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Chao Yin, Chenxu Lv, Da~Pan, Dian Wang, Dong Yan, Fan Yang, et~al.
\newblock Baichuan 2: Open large-scale language models.
\newblock {\em arXiv preprint arXiv:2309.10305}, 2023.

\bibitem{yang2022large}
Xi~Yang, Aokun Chen, Nima PourNejatian, Hoo~Chang Shin, Kaleb~E Smith, Christopher Parisien, Colin Compas, Cheryl Martin, Anthony~B Costa, Mona~G Flores, et~al.
\newblock A large language model for electronic health records.
\newblock {\em npj Digital Medicine}, 5(1):194, 2022.

\bibitem{moor2023foundation}
Michael Moor, Oishi Banerjee, Zahra Shakeri~Hossein Abad, Harlan~M Krumholz, Jure Leskovec, Eric~J Topol, and Pranav Rajpurkar.
\newblock Foundation models for generalist medical artificial intelligence.
\newblock {\em Nature}, 616(7956):259--265, 2023.

\bibitem{arora2023promise}
Anmol Arora and Ananya Arora.
\newblock The promise of large language models in health care.
\newblock {\em The Lancet}, 401(10377):641, 2023.

\bibitem{kung2023performance}
Tiffany~H Kung, Morgan Cheatham, Arielle Medenilla, Czarina Sillos, Lorie De~Leon, Camille Elepa{\~n}o, Maria Madriaga, Rimel Aggabao, Giezel Diaz-Candido, James Maningo, et~al.
\newblock Performance of chatgpt on usmle: Potential for ai-assisted medical education using large language models.
\newblock {\em PLoS digital health}, 2(2):e0000198, 2023.

\bibitem{kasneci2023chatgpt}
Enkelejda Kasneci, Kathrin Se{\ss}ler, Stefan K{\"u}chemann, Maria Bannert, Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan G{\"u}nnemann, Eyke H{\"u}llermeier, et~al.
\newblock Chatgpt for good? on opportunities and challenges of large language models for education.
\newblock {\em Learning and Individual Differences}, 103:102274, 2023.

\bibitem{katz2023gpt}
Daniel~Martin Katz, Michael~James Bommarito, Shang Gao, and Pablo Arredondo.
\newblock Gpt-4 passes the bar exam.
\newblock {\em Available at SSRN 4389233}, 2023.

\bibitem{vemprala2023chatgpt}
Sai Vemprala, Rogerio Bonatti, Arthur Bucker, and Ashish Kapoor.
\newblock Chatgpt for robotics: Design principles and model abilities.
\newblock {\em Microsoft Auton. Syst. Robot. Res}, 2:20, 2023.

\bibitem{shah2023lm}
Dhruv Shah, B{\l}a{\.z}ej Osi{\'n}ski, Sergey Levine, et~al.
\newblock Lm-nav: Robotic navigation with large pre-trained models of language, vision, and action.
\newblock In {\em Conference on Robot Learning}, pages 492--504. PMLR, 2023.

\bibitem{wu2023tidybot}
Jimmy Wu, Rika Antonova, Adam Kan, Marion Lepert, Andy Zeng, Shuran Song, Jeannette Bohg, Szymon Rusinkiewicz, and Thomas Funkhouser.
\newblock Tidybot: Personalized robot assistance with large language models.
\newblock {\em arXiv preprint arXiv:2305.05658}, 2023.

\bibitem{noauthor_undated-ae}
{ChatGPT} plugins.
\newblock \url{https://openai.com/blog/chatgpt-plugins}.
\newblock Accessed: 2023-6-7.

\bibitem{Gehman2020-zq}
Samuel Gehman, Suchin Gururangan, Maarten Sap, Yejin Choi, and Noah~A Smith.
\newblock {{R}eal{T}oxicity{P}rompts}: Evaluating neural toxic degeneration in language models.
\newblock In {\em Findings of the Association for Computational Linguistics: {EMNLP} 2020}, pages 3356--3369, Online, November 2020. Association for Computational Linguistics.

\bibitem{Weidinger2021-mm}
Laura Weidinger, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng, Mia Glaese, Borja Balle, Atoosa Kasirzadeh, et~al.
\newblock Ethical and social risks of harm from language models.
\newblock {\em arXiv preprint arXiv:2112.04359}, 2021.

\bibitem{Ganguli2022-td}
Deep Ganguli, Liane Lovitt, Jackson Kernion, Amanda Askell, Yuntao Bai, Saurav Kadavath, Ben Mann, Ethan Perez, Nicholas Schiefer, Kamal Ndousse, et~al.
\newblock Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned.
\newblock {\em arXiv preprint arXiv:2209.07858}, 2022.

\bibitem{deshpande2023toxicity}
Ameet Deshpande, Vishvak Murahari, Tanmay Rajpurohit, Ashwin Kalyan, and Karthik Narasimhan.
\newblock Toxicity in chatgpt: Analyzing persona-assigned language models.
\newblock {\em arXiv preprint arXiv:2304.05335}, 2023.

\bibitem{Christian2023-dt}
Jon Christian.
\newblock Amazing ``jailbreak'' bypasses {ChatGPT's} ethics safeguards.
\newblock \url{https://futurism.com/amazing-jailbreak-chatgpt}, February 2023.
\newblock Accessed: 2023-6-7.

\bibitem{Chilton2023-uz}
Jim Chilton.
\newblock The new risks {ChatGPT} poses to cybersecurity.
\newblock {\em Harvard Business Review}, April 2023.

\bibitem{Newman2023-hs}
Lily~Hay Newman.
\newblock {ChatGPT} scams are infiltrating the app store and google play.
\newblock {\em Wired}, May 2023.

\bibitem{Perez2022-mk}
Ethan Perez, Saffron Huang, Francis Song, Trevor Cai, Roman Ring, John Aslanides, Amelia Glaese, Nat McAleese, and Geoffrey Irving.
\newblock Red teaming language models with language models.
\newblock {\em arXiv preprint arXiv:2202.03286}, 2022.

\bibitem{Ouyang2022-lg}
Long Ouyang, Jeffrey Wu, Xu~Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et~al.
\newblock Training language models to follow instructions with human feedback.
\newblock {\em Advances in Neural Information Processing Systems}, 35:27730--27744, 2022.

\bibitem{Bai2022-mt}
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et~al.
\newblock Training a helpful and harmless assistant with reinforcement learning from human feedback.
\newblock {\em arXiv preprint arXiv:2204.05862}, 2022.

\bibitem{safe-rlhf}
Josef Dai, Xuehai Pan, Ruiyang Sun, Jiaming Ji, Xinbo Xu, Mickel Liu, Yizhou Wang, and Yaodong Yang.
\newblock Safe rlhf: Safe reinforcement learning from human feedback, 2023.

\bibitem{alpaca}
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori~B. Hashimoto.
\newblock Stanford alpaca: An instruction-following llama model.
\newblock \url{https://github.com/tatsu-lab/stanford_alpaca}, 2023.

\bibitem{3h-2021}
Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas Joseph, Ben Mann, Nova DasSarma, et~al.
\newblock A general language assistant as a laboratory for alignment.
\newblock {\em arXiv preprint arXiv:2112.00861}, 2021.

\bibitem{Xu2021-ce}
Jing Xu, Da~Ju, Margaret Li, Y-Lan Boureau, Jason Weston, and Emily Dinan.
\newblock {Bot-Adversarial} dialogue for safe conversational agents.
\newblock In {\em Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies}, pages 2950--2968, Online, June 2021. Association for Computational Linguistics.

\bibitem{Jigsaw2017-jh}
Google Jigsaw.
\newblock Perspective {API}.
\newblock \url{https://www.perspectiveapi.com/}, 2017.
\newblock Accessed: 2023-06-05.

\bibitem{Lees2022-at}
Alyssa Lees, Vinh~Q Tran, Yi~Tay, Jeffrey Sorensen, Jai Gupta, Donald Metzler, and Lucy Vasserman.
\newblock A new generation of perspective api: Efficient multilingual character-level transformers.
\newblock In {\em Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining}, pages 3197--3207, 2022.

\bibitem{SHP}
Kawin Ethayarajh, Heidi Zhang, Yizhong Wang, and Dan Jurafsky.
\newblock Stanford human preferences dataset, 2023.

\bibitem{huang2019reducing}
Po-Sen Huang, Huan Zhang, Ray Jiang, Robert Stanforth, Johannes Welbl, Jack Rae, Vishal Maini, Dani Yogatama, and Pushmeet Kohli.
\newblock Reducing sentiment bias in language models via counterfactual evaluation.
\newblock {\em arXiv preprint arXiv:1911.03064}, 2019.

\bibitem{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et~al.
\newblock Language models are few-shot learners.
\newblock {\em Advances in neural information processing systems}, 33:1877--1901, 2020.

\bibitem{srivastava2022imitation}
Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, and et. al.
\newblock Beyond the imitation game: Quantifying and extrapolating the capabilities of language models, 2022.

\bibitem{ousidhoum2021probing}
Nedjma Ousidhoum, Xinran Zhao, Tianqing Fang, Yangqiu Song, and Dit-Yan Yeung.
\newblock Probing toxic content in large pre-trained language models.
\newblock In {\em Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)}, pages 4262--4274, 2021.

\bibitem{Rauh2022-ac}
Maribeth Rauh, John Mellor, Jonathan Uesato, Po-Sen Huang, Johannes Welbl, Laura Weidinger, Sumanth Dathathri, Amelia Glaese, Geoffrey Irving, Iason Gabriel, et~al.
\newblock Characteristics of harmful text: Towards rigorous benchmarking of language models.
\newblock {\em Advances in Neural Information Processing Systems}, 35:24720--24739, 2022.

\bibitem{Shevlane2023-by}
Toby Shevlane, Sebastian Farquhar, Ben Garfinkel, Mary Phuong, Jess Whittlestone, Jade Leung, Daniel Kokotajlo, Nahema Marchal, Markus Anderljung, Noam Kolt, et~al.
\newblock Model evaluation for extreme risks.
\newblock {\em arXiv preprint arXiv:2305.15324}, 2023.

\bibitem{Lin2022-ys}
Stephanie Lin, Jacob Hilton, and Owain Evans.
\newblock {{T}ruthful{QA}}: Measuring how models mimic human falsehoods.
\newblock In {\em Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 3214--3252, Dublin, Ireland, May 2022. Association for Computational Linguistics.

\bibitem{Parrish2021-fi}
Alicia Parrish, Angelica Chen, Nikita Nangia, Vishakh Padmakumar, Jason Phang, Jana Thompson, Phu~Mon Htut, and Samuel~R Bowman.
\newblock Bbq: A hand-built bias benchmark for question answering.
\newblock {\em arXiv preprint arXiv:2110.08193}, 2021.

\bibitem{OpenAI2023-ws}
{OpenAI}.
\newblock Moderation {API}.
\newblock \url{https://platform.openai.com/docs/guides/moderation/overview}, 2023.
\newblock Accessed: 2023-6-5.

\bibitem{liu2019text}
Yang Liu and Mirella Lapata.
\newblock Text summarization with pretrained encoders.
\newblock {\em arXiv preprint arXiv:1908.08345}, 2019.

\bibitem{text-summarize-2020}
Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, and Paul~F Christiano.
\newblock Learning to summarize with human feedback.
\newblock {\em Advances in Neural Information Processing Systems}, 33:3008--3021, 2020.

\bibitem{deroy2023ready}
Aniket Deroy, Kripabandhu Ghosh, and Saptarshi Ghosh.
\newblock How ready are pre-trained abstractive models and llms for legal case judgement summarization?, 2023.

\bibitem{wang2022self}
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah~A Smith, Daniel Khashabi, and Hannaneh Hajishirzi.
\newblock Self-instruct: Aligning language model with self generated instructions.
\newblock {\em arXiv preprint arXiv:2212.10560}, 2022.

\bibitem{follow-instruction-2023}
Tianjun Zhang, Fangchen Liu, Justin Wong, Pieter Abbeel, and Joseph~E Gonzalez.
\newblock The wisdom of hindsight makes language models better instruction followers.
\newblock {\em arXiv preprint arXiv:2302.05206}, 2023.

\bibitem{cai-2022}
Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, et~al.
\newblock Constitutional ai: Harmlessness from ai feedback.
\newblock {\em arXiv preprint arXiv:2212.08073}, 2022.

\bibitem{Schulman2017-mq}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock {\em arXiv preprint arXiv:1707.06347}, 2017.

\bibitem{wu2023finegrained}
Zeqiu Wu, Yushi Hu, Weijia Shi, Nouha Dziri, Alane Suhr, Prithviraj Ammanabrolu, Noah~A. Smith, Mari Ostendorf, and Hannaneh Hajishirzi.
\newblock Fine-grained human feedback gives better rewards for language model training, 2023.

\bibitem{ci2022proactive}
Hai Ci, Mickel Liu, Xuehai Pan, Yizhou Wang, et~al.
\newblock Proactive multi-camera collaboration for 3d human pose estimation.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2022.

\bibitem{pan2022mate}
Xuehai Pan, Mickel Liu, Fangwei Zhong, Yaodong Yang, Song-Chun Zhu, and Yizhou Wang.
\newblock Mate: Benchmarking multi-agent reinforcement learning in distributed target coverage control.
\newblock {\em Advances in Neural Information Processing Systems}, 35:27862--27879, 2022.

\bibitem{Tallamraju2020-uf}
Rahul Tallamraju, Nitin Saini, Elia Bonetto, Michael Pabst, Yu~Tang Liu, Michael~J Black, and Aamir Ahmad.
\newblock {AirCapRL}: Autonomous aerial human motion capture using deep reinforcement learning.
\newblock {\em IEEE Robotics and Automation Letters}, 5(4):6678--6685, October 2020.

\bibitem{akkaya2019solving}
OpenAI, Ilge Akkaya, Marcin Andrychowicz, Maciek Chociej, Mateusz Litwin, Bob McGrew, Arthur Petron, Alex Paino, Matthias Plappert, Glenn Powell, Raphael Ribas, Jonas Schneider, Nikolas Tezak, Jerry Tworek, Peter Welinder, Lilian Weng, Qiming Yuan, Wojciech Zaremba, and Lei Zhang.
\newblock Solving rubik's cube with a robot hand.
\newblock {\em arXiv preprint arXiv:1910.07113}, 2019.

\bibitem{miki2022learning}
Takahiro Miki, Joonho Lee, Jemin Hwangbo, Lorenz Wellhausen, Vladlen Koltun, and Marco Hutter.
\newblock Learning robust perceptive locomotion for quadrupedal robots in the wild.
\newblock {\em Science Robotics}, 7(62):eabk2822, 2022.

\bibitem{andrychowicz2020learning}
OpenAI:~Marcin Andrychowicz, Bowen Baker, Maciek Chociej, Rafal Jozefowicz, Bob McGrew, Jakub Pachocki, Arthur Petron, Matthias Plappert, Glenn Powell, Alex Ray, et~al.
\newblock Learning dexterous in-hand manipulation.
\newblock {\em The International Journal of Robotics Research}, 39(1):3--20, 2020.

\bibitem{sun2023safety}
Hao Sun, Zhexin Zhang, Jiawen Deng, Jiale Cheng, and Minlie Huang.
\newblock Safety assessment of chinese large language models.
\newblock {\em arXiv preprint arXiv:2304.10436}, 2023.

\bibitem{altman2021constrained}
Eitan Altman.
\newblock {\em Constrained Markov decision processes}.
\newblock Routledge, 2021.

\bibitem{ji2023omnisafe}
Jiaming Ji, Jiayi Zhou, Borong Zhang, Juntao Dai, Xuehai Pan, Ruiyang Sun, Weidong Huang, Yiran Geng, Mickel Liu, and Yaodong Yang.
\newblock Omnisafe: An infrastructure for accelerating safe reinforcement learning research, 2023.

\bibitem{ray2019benchmarking}
Alex Ray, Joshua Achiam, and Dario Amodei.
\newblock Benchmarking safe exploration in deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1910.01708}, 7(1):2, 2019.

\bibitem{ji2023safetygymnasium}
Jiaming Ji, Borong Zhang, Jiayi Zhou, Xuehai Pan, Weidong Huang, Ruiyang Sun, Yiran Geng, Yifan Zhong, Juntao Dai, and Yaodong Yang.
\newblock Safety-gymnasium: A unified safe reinforcement learning benchmark, 2023.

\bibitem{glaese2022improving}
Amelia Glaese, Nat McAleese, Maja Tr{\k{e}}bacz, John Aslanides, Vlad Firoiu, Timo Ewalds, Maribeth Rauh, Laura Weidinger, Martin Chadwick, Phoebe Thacker, et~al.
\newblock Improving alignment of dialogue agents via targeted human judgements.
\newblock {\em arXiv preprint arXiv:2209.14375}, 2022.

\bibitem{noauthor_undated-nz}
China: hourly minimum wage by region 2023.
\newblock \url{https://www.statista.com/statistics/233886/minimum-wage-per-hour-in-china-by-city-and-province/}.
\newblock Accessed: 2023-6-7.

\end{thebibliography}
