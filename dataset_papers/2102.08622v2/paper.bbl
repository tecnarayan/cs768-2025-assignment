\begin{thebibliography}{53}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Allgower \& Georg(1990)Allgower and Georg]{allgower1990numerical}
Allgower, E.~L. and Georg, K.
\newblock \emph{Numerical continuation methods: An introduction}.
\newblock Springer, 1990.

\bibitem[Altschuler et~al.(2017)Altschuler, Weed, and
  Rigollet]{altschuler2017near}
Altschuler, J., Weed, J., and Rigollet, P.
\newblock Near-linear time approximation algorithms for optimal transport via
  {S}inkhorn iteration.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Asano et~al.(2020)Asano, Rupprecht, and Vedaldi]{asano2020self}
Asano, Y.~M., Rupprecht, C., and Vedaldi, A.
\newblock Self-labeling via simultaneous clustering and representation
  learning.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Azizzadenesheli et~al.(2019)Azizzadenesheli, Liu, Yang, and
  Anandkumar]{azizzadenesheli2019regularized}
Azizzadenesheli, K., Liu, A., Yang, F., and Anandkumar, A.
\newblock Regularized learning for domain adaptation under label shifts.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Bachman et~al.(2014)Bachman, Alsharif, and
  Precup]{bachman2014learning}
Bachman, P., Alsharif, O., and Precup, D.
\newblock Learning with pseudo-ensembles.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2014.

\bibitem[Benamou et~al.(2015)Benamou, Carlier, Cuturi, Nenna, and
  Peyr{\'e}]{benamou2015iterative}
Benamou, J.-D., Carlier, G., Cuturi, M., Nenna, L., and Peyr{\'e}, G.
\newblock Iterative {B}regman projections for regularized transportation
  problems.
\newblock \emph{SIAM Journal on Scientific Computing}, 2015.

\bibitem[Bengio et~al.(2009)Bengio, Louradour, Collobert, and
  Weston]{bengio2009curriculum}
Bengio, Y., Louradour, J., Collobert, R., and Weston, J.
\newblock Curriculum learning.
\newblock In \emph{International Conference on Machine Learning}, 2009.

\bibitem[Berthelot et~al.(2019)Berthelot, Carlini, Goodfellow, Papernot,
  Oliver, and Raffel]{berthelot2019mixmatch}
Berthelot, D., Carlini, N., Goodfellow, I., Papernot, N., Oliver, A., and
  Raffel, C.~A.
\newblock Mix{M}atch: A holistic approach to semi-supervised learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Berthelot et~al.(2020)Berthelot, Carlini, Cubuk, Kurakin, Zhang,
  Raffel, and Sohn]{kurakin2020remixmatch}
Berthelot, D., Carlini, N., Cubuk, E.~D., Kurakin, A., Zhang, H., Raffel, C.,
  and Sohn, K.
\newblock Re{M}ix{M}atch: Semi-supervised learning with distribution matching
  and augmentation anchoring.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Blum \& Mitchell(1998)Blum and Mitchell]{blum1998combining}
Blum, A. and Mitchell, T.
\newblock Combining labeled and unlabeled data with co-training.
\newblock In \emph{Conference on Computational Learning Theory}, 1998.

\bibitem[Caron et~al.(2020)Caron, Misra, Mairal, Goyal, Bojanowski, and
  Joulin]{caron2020unsupervised}
Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski, P., and Joulin, A.
\newblock Unsupervised learning of visual features by contrasting cluster
  assignments.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Chang et~al.(2007)Chang, Ratinov, and Roth]{chang2007guiding}
Chang, M.-W., Ratinov, L., and Roth, D.
\newblock Guiding semi-supervision with constraint-driven learning.
\newblock In \emph{Annual Meeting of the Association of Computational
  Linguistics}, 2007.

\bibitem[Chapelle et~al.(2008)Chapelle, Sindhwani, and
  Keerthi]{chapelle2008optimization}
Chapelle, O., Sindhwani, V., and Keerthi, S.~S.
\newblock Optimization techniques for semi-supervised support vector machines.
\newblock \emph{Journal of Machine Learning Research}, 2008.

\bibitem[Cubuk et~al.(2020)Cubuk, Zoph, Shlens, and Le]{cubuk2020randaugment}
Cubuk, E.~D., Zoph, B., Shlens, J., and Le, Q.~V.
\newblock Rand{A}ugment: Practical automated data augmentation with a reduced
  search space.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition},
  2020.

\bibitem[Cuturi(2013)]{cuturi2013sinkhorn}
Cuturi, M.
\newblock Sinkhorn distances: Lightspeed computation of optimal transport.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2013.

\bibitem[DeVries \& Taylor(2017)DeVries and Taylor]{devries2017improved}
DeVries, T. and Taylor, G.~W.
\newblock Improved regularization of convolutional neural networks with
  {C}utout.
\newblock \emph{arXiv preprint arXiv:1708.04552}, 2017.

\bibitem[Dulac-Arnold et~al.(2019)Dulac-Arnold, Zeghidour, Cuturi, Beyer, and
  Vert]{dulac2019}
Dulac-Arnold, G., Zeghidour, N., Cuturi, M., Beyer, L., and Vert, J.-P.
\newblock Deep multiclass learning from label proportions.
\newblock Technical report, arXiv, 2019.
\newblock 1905.12909.

\bibitem[Dykstra(1985)]{dykstra1985iterative}
Dykstra, R.~L.
\newblock An iterative procedure for obtaining {I}-projections onto the
  intersection of convex sets.
\newblock \emph{The Annals of Probability}, 1985.

\bibitem[Ganchev et~al.(2010)Ganchev, Gra{\c{c}}a, Gillenwater, and
  Taskar]{ganchev2010posterior}
Ganchev, K., Gra{\c{c}}a, J., Gillenwater, J., and Taskar, B.
\newblock Posterior regularization for structured latent variable models.
\newblock \emph{The Journal of Machine Learning Research}, 2010.

\bibitem[Grandvalet \& Bengio(2005)Grandvalet and Bengio]{grandvaletsemi}
Grandvalet, Y. and Bengio, Y.
\newblock Semi-supervised learning by entropy minimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2005.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017calibration}
Guo, C., Pleiss, G., Sun, Y., and Weinberger, K.~Q.
\newblock On calibration of modern neural networks.
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Hendrycks \& Gimpel(2017)Hendrycks and Gimpel]{hendrycks2016baseline}
Hendrycks, D. and Gimpel, K.
\newblock A baseline for detecting misclassified and out-of-distribution
  examples in neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Joachims(1999)]{joachims1999transductive}
Joachims, T.
\newblock Transductive inference for text classification using {Support Vector
  Machines}.
\newblock In \emph{International Conference on Machine Learning}, 1999.

\bibitem[Joachims(2003)]{joachims2003transductive}
Joachims, T.
\newblock Transductive learning via spectral graph partitioning.
\newblock In \emph{International Conference on Machine Learning}, 2003.

\bibitem[Krizhevsky(2009)]{krizhevsky2009learning}
Krizhevsky, A.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, University of Toronto, 2009.

\bibitem[Kuck \& de~Freitas(2005)Kuck and de~Freitas]{kuck2005learning}
Kuck, H. and de~Freitas, N.
\newblock Learning about individuals from group statistics.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence}, 2005.

\bibitem[Kumar et~al.(2010)Kumar, Packer, and Koller]{kumar2010self}
Kumar, M.~P., Packer, B., and Koller, D.
\newblock Self-paced learning for latent variable models.
\newblock In \emph{{Advances in Neural Information Processing Systems}}, 2010.

\bibitem[Laine \& Aila(2017)Laine and Aila]{laine2016temporal}
Laine, S. and Aila, T.
\newblock Temporal ensembling for semi-supervised learning.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Lee(2013)]{lee2013pseudo}
Lee, D.-H.
\newblock Pseudo-label: {T}he simple and efficient semi-supervised learning
  method for deep neural networks.
\newblock In \emph{ICML Workshop on Challenges in Representation Learning},
  2013.

\bibitem[Lipton et~al.(2018)Lipton, Wang, and Smola]{lipton2018detecting}
Lipton, Z.~C., Wang, Y.-X., and Smola, A.~J.
\newblock Detecting and correcting for label shift with black box predictors.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Mann \& McCallum(2008)Mann and McCallum]{mann2008generalized}
Mann, G. and McCallum, A.
\newblock Generalized expectation criteria for semi-supervised learning of
  conditional random fields.
\newblock In \emph{Annual Meeting of the Association for Computational
  Linguistics}, 2008.

\bibitem[Mann \& McCallum(2007)Mann and McCallum]{mann2007simple}
Mann, G.~S. and McCallum, A.
\newblock Simple, robust, scalable semi-supervised learning via expectation
  regularization.
\newblock In \emph{International Conference on Machine Learning}, 2007.

\bibitem[McLachlan(1975)]{mclachlan1975iterative}
McLachlan, G.~J.
\newblock Iterative reclassification procedure for constructing an
  asymptotically optimal rule of allocation in discriminant analysis.
\newblock \emph{Journal of the American Statistical Association}, 1975.

\bibitem[Musicant et~al.(2007)Musicant, Christensen, and
  Olson]{musicant2007supervised}
Musicant, D.~R., Christensen, J.~M., and Olson, J.~F.
\newblock Supervised learning by training on aggregate outputs.
\newblock In \emph{International Conference on Data Mining}, 2007.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and
  Ng]{netzer2011reading}
Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., and Ng, A.~Y.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock 2011.

\bibitem[Nigam et~al.(2000)Nigam, McCallum, Thrun, and Mitchell]{nigam2000text}
Nigam, K., McCallum, A., Thrun, S., and Mitchell, T.
\newblock Text classification from labeled and unlabeled documents using {EM}.
\newblock \emph{Machine Learning}, 2000.

\bibitem[Nowlan \& Hinton(1993)Nowlan and Hinton]{nowlan1993soft}
Nowlan, S.~J. and Hinton, G.~E.
\newblock A soft decision-directed {LMS} algorithm for blind equalization.
\newblock \emph{IEEE Transactions on Communications}, 1993.

\bibitem[Renegar(1988)]{renegar1988polynomial}
Renegar, J.
\newblock A polynomial-time algorithm, based on {N}ewton's method, for linear
  programming.
\newblock \emph{Mathematical Programming}, 1988.

\bibitem[Riloff et~al.(2003)Riloff, Wiebe, and Wilson]{riloff2003learning}
Riloff, E., Wiebe, J., and Wilson, T.
\newblock Learning subjective nouns using extraction pattern bootstrapping.
\newblock In \emph{HLT-NAACL}, 2003.

\bibitem[Rosenberg et~al.(2005)Rosenberg, Hebert, and
  Schneiderman]{rosenberg2005semi}
Rosenberg, C., Hebert, M., and Schneiderman, H.
\newblock Semi-supervised self-training of object detection models.
\newblock In \emph{IEEE Workshop on Applications of Computer Vision}, 2005.

\bibitem[Sajjadi et~al.(2016)Sajjadi, Javanmardi, and
  Tasdizen]{sajjadi2016regularization}
Sajjadi, M., Javanmardi, M., and Tasdizen, T.
\newblock Regularization with stochastic transformations and perturbations for
  deep semi-supervised learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Scudder(1965)]{scudder1965probability}
Scudder, H.
\newblock Probability of error of some adaptive pattern-recognition machines.
\newblock \emph{IEEE Transactions on Information Theory}, 1965.

\bibitem[Shen \& Sanghavi(2019)Shen and Sanghavi]{shen2019learning}
Shen, Y. and Sanghavi, S.
\newblock Learning with bad training data via {I}terative {T}rimmed {L}oss
  {M}inimization.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Sindhwani et~al.(2006)Sindhwani, Keerthi, and Chapelle]{sindhwani2006}
Sindhwani, V., Keerthi, S.~S., and Chapelle, O.
\newblock Deterministic annealing for semi-supervised kernel machines.
\newblock In \emph{International Conference on Machine Learning}, 2006.

\bibitem[Sohn et~al.(2020)Sohn, Berthelot, Li, Zhang, Carlini, Cubuk, Kurakin,
  Zhang, and Raffel]{fixmatch}
Sohn, K., Berthelot, D., Li, C.-L., Zhang, Z., Carlini, N., Cubuk, E.~D.,
  Kurakin, A., Zhang, H., and Raffel, C.
\newblock Fix{M}atch: Simplifying semi-supervised learning with consistency and
  confidence.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Tarvainen \& Valpola(2017)Tarvainen and Valpola]{tarvainen2017mean}
Tarvainen, A. and Valpola, H.
\newblock Mean teachers are better role models: Weight-averaged consistency
  targets improve semi-supervised deep learning results.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Widrow et~al.()Widrow, McCool, Larimore, and
  Johnson]{widrow1977stationary}
Widrow, B., McCool, J., Larimore, M.~G., and Johnson, C.~R.
\newblock Stationary and nonstationary learning characteristics of the {LMS}
  adaptive filter.
\newblock In \emph{Aspects of Signal Processing}.

\bibitem[Wilson(1927)]{wilson1927probable}
Wilson, E.~B.
\newblock Probable inference, the law of succession, and statistical inference.
\newblock \emph{Journal of the American Statistical Association}, 1927.

\bibitem[Xie et~al.(2019)Xie, Dai, Hovy, Luong, and Le]{xie2019unsupervised}
Xie, Q., Dai, Z., Hovy, E., Luong, M.-T., and Le, Q.~V.
\newblock Unsupervised data augmentation for consistency training.
\newblock 2019.

\bibitem[Xie et~al.(2020)Xie, Luong, Hovy, and Le]{xie2020self}
Xie, Q., Luong, M.-T., Hovy, E., and Le, Q.~V.
\newblock {Self-training with Noisy Student improves ImageNet classification}.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition},
  2020.

\bibitem[Yarowsky(1995)]{yarowsky1995unsupervised}
Yarowsky, D.
\newblock Unsupervised word sense disambiguation rivaling supervised methods.
\newblock In \emph{33rd Annual Meeting of the Association for Computational
  Linguistics}, 1995.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and Komodakis]{Zagoruyko2016WRN}
Zagoruyko, S. and Komodakis, N.
\newblock {Wide Residual Networks}.
\newblock In \emph{British Machine Vision Conference}, 2016.

\bibitem[Zhu \& Ghahramani(2002)Zhu and Ghahramani]{zhu2002}
Zhu, X. and Ghahramani, Z.
\newblock Learning from labeled and unlabeled data with label propagation.
\newblock Technical report, CMU CALD, 2002.
\newblock CMU-CALD-02-107,.

\end{thebibliography}
