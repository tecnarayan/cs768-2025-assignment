\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2020)Agarwal, Kakade, Krishnamurthy, and
  Sun]{agarwal2020flambe}
A.~Agarwal, S.~Kakade, A.~Krishnamurthy, and W.~Sun.
\newblock Flambe: Structural complexity and representation learning of low rank
  {MDPs}.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 20095--20107, 2020.

\bibitem[Anonymous(2022)]{Anon2022invariance}
Anonymous.
\newblock An analysis of attention via the lens of invariance: Approximation,
  generalization, and optimization.
\newblock \emph{Technical Report}, 2022.

\bibitem[Antos et~al.(2008)Antos, Szepesv{\'a}ri, and Munos]{antos2008learning}
A.~Antos, C.~Szepesv{\'a}ri, and R.~Munos.
\newblock Learning near-optimal policies with bellman-residual minimization
  based fitted policy iteration and a single sample path.
\newblock \emph{Machine Learning}, 71\penalty0 (1):\penalty0 89--129, 2008.

\bibitem[Bahdanau et~al.(2014)Bahdanau, Cho, and Bengio]{bahdanau2014neural}
D.~Bahdanau, K.~Cho, and Y.~Bengio.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock \emph{arXiv preprint arXiv:1409.0473}, 2014.

\bibitem[Bartlett et~al.(2017)Bartlett, Foster, and
  Telgarsky]{bartlett2017spectrally}
P.~L. Bartlett, D.~J. Foster, and M.~J. Telgarsky.
\newblock Spectrally-normalized margin bounds for neural networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem[Belghazi et~al.(2018)Belghazi, Baratin, Rajeshwar, Ozair, Bengio,
  Courville, and Hjelm]{belghazi2018mutual}
M.~I. Belghazi, A.~Baratin, S.~Rajeshwar, S.~Ozair, Y.~Bengio, A.~Courville,
  and D.~Hjelm.
\newblock Mutual information neural estimation.
\newblock In \emph{International Conference on Machine Learning}, pages
  531--540. PMLR, 2018.

\bibitem[Bronstein et~al.(2021)Bronstein, Bruna, Cohen, and
  Veli{\v{c}}kovi{\'c}]{bronstein2021geometric}
M.~M. Bronstein, J.~Bruna, T.~Cohen, and P.~Veli{\v{c}}kovi{\'c}.
\newblock Geometric deep learning: Grids, groups, graphs, geodesics, and
  gauges.
\newblock \emph{arXiv preprint arXiv:2104.13478}, 2021.

\bibitem[Chang et~al.(2021)Chang, Uehara, Sreenivas, Kidambi, and
  Sun]{chang2021mitigating}
J.~Chang, M.~Uehara, D.~Sreenivas, R.~Kidambi, and W.~Sun.
\newblock Mitigating covariate shift in imitation learning via offline data
  with partial coverage.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Chen and Jiang(2019)]{chen2019information}
J.~Chen and N.~Jiang.
\newblock Information-theoretic considerations in batch reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  1042--1051. PMLR, 2019.

\bibitem[Chen et~al.(2021)Chen, Li, Wang, Yang, Wang, and
  Zhao]{chen2021pessimism}
M.~Chen, Y.~Li, E.~Wang, Z.~Yang, Z.~Wang, and T.~Zhao.
\newblock Pessimism meets invariance: Provably efficient offline mean-field
  multi-agent {RL}.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Devroye et~al.(2018)Devroye, Mehrabian, and Reddad]{devroye2018total}
L.~Devroye, A.~Mehrabian, and T.~Reddad.
\newblock The total variation distance between high-dimensional {Gaussians}.
\newblock \emph{arXiv preprint arXiv:1810.08693}, 2018.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly,
  et~al.]{dosovitskiy2020image}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai,
  T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{In International Conference on Learning Representations}, 2021.

\bibitem[Duan et~al.(2021)Duan, Jin, and Li]{duan2021risk}
Y.~Duan, C.~Jin, and Z.~Li.
\newblock Risk bounds and rademacher complexity in batch reinforcement
  learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  2892--2902. PMLR, 2021.

\bibitem[Edelman et~al.(2021)Edelman, Goel, Kakade, and
  Zhang]{edelman2021inductive}
B.~Edelman, S.~Goel, S.~Kakade, and C.~Zhang.
\newblock Inductive biases and variable creation in self-attention mechanisms.
\newblock \emph{arXiv preprint arXiv:2110.10090}, 2021.

\bibitem[Jakubovitz et~al.(2019)Jakubovitz, Giryes, and
  Rodrigues]{jakubovitz2019generalization}
D.~Jakubovitz, R.~Giryes, and M.~R.~D. Rodrigues.
\newblock Generalization error in deep learning.
\newblock In \emph{Compressed {S}ensing and {I}ts {A}pplications}, pages
  153--193. Springer, 2019.

\bibitem[Jiang et~al.(2018)Jiang, Sun, and Fan]{jiang2018bernstein}
B.~Jiang, Q.~Sun, and J.~Fan.
\newblock Bernstein's inequality for general {Markov} chains.
\newblock \emph{arXiv preprint arXiv:1805.10721}, 2018.

\bibitem[Jin et~al.(2021)Jin, Yang, and Wang]{jin2021pessimism}
Y.~Jin, Z.~Yang, and Z.~Wang.
\newblock Is pessimism provably efficient for offline {RL}?
\newblock In \emph{International Conference on Machine Learning}, pages
  5084--5096. PMLR, 2021.

\bibitem[Lee et~al.(2019)Lee, Lee, Kim, Kosiorek, Choi, and Teh]{lee2019set}
J.~Lee, Y.~Lee, J.~Kim, A.~Kosiorek, S.~Choi, and Y.~W. Teh.
\newblock Set transformer: A framework for attention-based
  permutation-invariant neural networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  3744--3753. PMLR, 2019.

\bibitem[Li et~al.(2021)Li, Wang, Yang, Wang, Wang, Zhao, and
  Zha]{li2021permutation}
Y.~Li, L.~Wang, J.~Yang, E.~Wang, Z.~Wang, T.~Zhao, and H.~Zha.
\newblock Permutation invariant policy optimization for mean-field multi-agent
  reinforcement learning: A principled approach.
\newblock \emph{arXiv preprint arXiv:2105.08268}, 2021.

\bibitem[Liu et~al.(2020)Liu, Yeh, and Schwing]{liu2020pic}
I.~Liu, R.~A. Yeh, and A.~G. Schwing.
\newblock {PIC}: permutation invariant critic for multi-agent deep
  reinforcement learning.
\newblock In \emph{Conference on Robot Learning}, pages 590--602. PMLR, 2020.

\bibitem[Lowe et~al.(2017)Lowe, Wu, Tamar, Harb, Pieter~A., and
  Mordatch]{lowe2017multi}
R.~Lowe, Y.~I. Wu, A.~Tamar, J.~Harb, O.~Pieter~A., and I.~Mordatch.
\newblock Multi-agent actor-critic for mixed cooperative-competitive
  environments.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[McAllester(1999)]{mcallester1999some}
D.~A. McAllester.
\newblock Some {PAC-Bayesian} theorems.
\newblock \emph{Machine Learning}, 37\penalty0 (3):\penalty0 355--363, 1999.

\bibitem[McAllester(2003)]{mcallester2003simplified}
D.~A. McAllester.
\newblock Simplified {PAC-Bayesian} margin bounds.
\newblock In \emph{Learning Theory and Kernel Machines}, pages 203--215.
  Springer, 2003.

\bibitem[Menda et~al.(2018)Menda, Chen, Grana, Bono, Tracey, Kochenderfer, and
  Wolpert]{menda2018deep}
K.~Menda, Y.~Chen, J.~Grana, J.~W. Bono, B.~D. Tracey, M.~J. Kochenderfer, and
  D.~Wolpert.
\newblock Deep reinforcement learning for event-driven multi-agent decision
  processes.
\newblock \emph{IEEE Transactions on Intelligent Transportation Systems},
  20\penalty0 (4):\penalty0 1259--1268, 2018.

\bibitem[Mnih et~al.(2013)Mnih, Kavukcuoglu, Silver, Graves, Antonoglou,
  Wierstra, and Riedmiller]{mnih2013playing}
V.~Mnih, K.~Kavukcuoglu, D.~Silver, A.~Graves, I.~Antonoglou, D.~Wierstra, and
  M.~Riedmiller.
\newblock Playing atari with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1312.5602}, 2013.

\bibitem[Mohri et~al.(2018)Mohri, Rostamizadeh, and
  Talwalkar]{mohri2018foundations}
M.~Mohri, A.~Rostamizadeh, and A.~Talwalkar.
\newblock \emph{Foundations of Machine Learning}.
\newblock MIT press, 2018.

\bibitem[Mordatch and Abbeel(2018)]{mordatch2018emergence}
I.~Mordatch and P.~Abbeel.
\newblock Emergence of grounded compositional language in multi-agent
  populations.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2018.

\bibitem[Nachum et~al.(2019)Nachum, Dai, Kostrikov, Chow, Li, and
  Schuurmans]{nachum2019algaedice}
O.~Nachum, B.~Dai, I.~Kostrikov, Y.~Chow, L.~Li, and D.~Schuurmans.
\newblock Algaedice: Policy gradient from arbitrary experience.
\newblock \emph{arXiv preprint arXiv:1912.02074}, 2019.

\bibitem[Naseer et~al.(2021)Naseer, Ranasinghe, Khan, Hayat, Shahbaz~Khan, and
  Yang]{naseer2021intriguing}
M.~M. Naseer, K.~Ranasinghe, S.~H. Khan, M.~Hayat, F.~Shahbaz~Khan, and
  M.~Yang.
\newblock Intriguing properties of vision transformers.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Neyshabur et~al.(2017)Neyshabur, Bhojanapalli, and
  Srebro]{neyshabur2017pac}
B.~Neyshabur, S.~Bhojanapalli, and N.~Srebro.
\newblock A {PAC-Bayesian} approach to spectrally-normalized margin bounds for
  neural networks.
\newblock \emph{arXiv preprint arXiv:1707.09564}, 2017.

\bibitem[Paulin(2015)]{paulin2015concentration}
D.~Paulin.
\newblock Concentration inequalities for {Markov} chains by {Marton} couplings
  and spectral methods.
\newblock \emph{Electronic Journal of Probability}, 20:\penalty0 1--32, 2015.

\bibitem[Rajaraman et~al.(2020)Rajaraman, Yang, Jiao, and
  Ramchandran]{rajaraman2020toward}
N.~Rajaraman, L.~Yang, J.~Jiao, and K.~Ramchandran.
\newblock Toward the fundamental limits of imitation learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 2914--2924, 2020.

\bibitem[Ross and Bagnell(2012)]{ross2012agnostic}
S.~Ross and J.~A. Bagnell.
\newblock Agnostic system identification for model-based reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:1203.1007}, 2012.

\bibitem[Sannai et~al.(2021)Sannai, Imaizumi, and Kawano]{sannai2021improved}
A.~Sannai, M.~Imaizumi, and M.~Kawano.
\newblock Improved generalization bounds of group invariant/equivariant deep
  networks via quotient feature spaces.
\newblock In \emph{Uncertainty in Artificial Intelligence}, pages 771--780.
  PMLR, 2021.

\bibitem[Sokolic et~al.(2017)Sokolic, Giryes, Sapiro, and
  Rodrigues]{sokolic2017generalization}
J.~Sokolic, R.~Giryes, G.~Sapiro, and M.~Rodrigues.
\newblock Generalization error of invariant classifiers.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 1094--1103.
  PMLR, 2017.

\bibitem[Sonoda and Murata(2017)]{sonoda2017neural}
S.~Sonoda and N.~Murata.
\newblock Neural network with unbounded activation functions is universal
  approximator.
\newblock \emph{Applied and Computational Harmonic Analysis}, 43\penalty0
  (2):\penalty0 233--268, 2017.

\bibitem[Sun et~al.(2019)Sun, Jiang, Krishnamurthy, Agarwal, and
  Langford]{sun2019model}
W.~Sun, N.~Jiang, A.~Krishnamurthy, A.~Agarwal, and J.~Langford.
\newblock Model-based {RL} in contextual decision processes: {PAC} bounds and
  exponential improvements over model-free approaches.
\newblock In \emph{Conference on Learning Theory}, pages 2898--2933. PMLR,
  2019.

\bibitem[Tang and Ha(2021)]{tang2021sensory}
Y.~Tang and D.~Ha.
\newblock The sensory neuron as a transformer: Permutation-invariant neural
  networks for reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Telgarsky(2015)]{telgarsky2015representation}
M.~Telgarsky.
\newblock Representation benefits of deep feedforward networks.
\newblock \emph{arXiv preprint arXiv:1509.08101}, 2015.

\bibitem[Tsagris et~al.(2014)Tsagris, Beneki, and Hassani]{tsagris2014folded}
M.~Tsagris, C.~Beneki, and H.~Hassani.
\newblock On the folded normal distribution.
\newblock \emph{Mathematics}, 2\penalty0 (1):\penalty0 12--28, 2014.

\bibitem[Uehara and Sun(2021)]{uehara2021pessimistic}
M.~Uehara and W.~Sun.
\newblock Pessimistic model-based offline reinforcement learning under partial
  coverage.
\newblock \emph{arXiv preprint arXiv:2107.06226}, 2021.

\bibitem[Uehara et~al.(2020)Uehara, Huang, and Jiang]{uehara2020minimax}
M.~Uehara, J.~Huang, and N.~Jiang.
\newblock Minimax weight and {Q}-function learning for off-policy evaluation.
\newblock In \emph{International Conference on Machine Learning}, pages
  9659--9668. PMLR, 2020.

\bibitem[Wainwright(2019)]{wainwright2019high}
M.~J. Wainwright.
\newblock \emph{High-Dimensional Statistics: A Non-Asymptotic Viewpoint},
  volume~48.
\newblock Cambridge University Press, 2019.

\bibitem[Wang et~al.(2022{\natexlab{a}})Wang, Walters, and
  Platt]{wang2022mathrm}
D.~Wang, R.~Walters, and R.~Platt.
\newblock $\mathrm{SO}$(2) -equivariant reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2203.04439}, 2022{\natexlab{a}}.

\bibitem[Wang et~al.(2022{\natexlab{b}})Wang, Walters, Zhu, and
  Platt]{wang2022equivariant}
D.~Wang, R.~Walters, X.~Zhu, and R.~Platt.
\newblock {Equivariant Q Learning in Spatial Action Spaces}.
\newblock In \emph{Conference on Robot Learning}, pages 1713--1723. PMLR,
  2022{\natexlab{b}}.

\bibitem[Wang et~al.(2020)Wang, Yang, and Wang]{wang2020breaking}
L.~Wang, Z.~Yang, and Z.~Wang.
\newblock Breaking the curse of many agents: Provable mean embedding
  q-iteration for mean-field reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  10092--10103. PMLR, 2020.

\bibitem[Xie and Jiang(2020)]{xie2020q}
T.~Xie and N.~Jiang.
\newblock Q* approximation schemes for batch reinforcement learning: A
  theoretical comparison.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence}, pages
  550--559. PMLR, 2020.

\bibitem[Xie et~al.(2021)Xie, Cheng, Jiang, Mineiro, and
  Agarwal]{xie2021bellman}
T.~Xie, C.~Cheng, N.~Jiang, P.~Mineiro, and A.~Agarwal.
\newblock Bellman-consistent pessimism for offline reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Xu et~al.(2021)Xu, Zhang, Ye, Zhao, and Tan]{xu2021relation}
K.~Xu, Y.~Zhang, D.~Ye, P.~Zhao, and M.~Tan.
\newblock Relation-aware transformer for portfolio policy learning.
\newblock In \emph{Proceedings of the Twenty-Ninth International Conference on
  International Joint Conferences on Artificial Intelligence}, pages
  4647--4653, 2021.

\bibitem[Yin et~al.(2022)Yin, Duan, Wang, and Wang]{yin2022near}
M.~Yin, Y.~Duan, M.~Wang, and Y.-X. Wang.
\newblock Near-optimal offline reinforcement learning with linear
  representation: Leveraging variance information with pessimism.
\newblock \emph{arXiv preprint arXiv:2203.05804}, 2022.

\bibitem[Yuan et~al.(2021)Yuan, Chen, Wang, Yu, Shi, Jiang, Tay, Feng, and
  Yan]{yuan2021tokens}
L.~Yuan, Y.~Chen, T.~Wang, W.~Yu, Y.~Shi, Z.~Jiang, F.~E.~H. Tay, J.~Feng, and
  S.~Yan.
\newblock Tokens-to-token vit: Training vision transformers from scratch on
  {Imagenet}.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 558--567, 2021.

\bibitem[Zaheer et~al.(2017)Zaheer, Kottur, Ravanbakhsh, Poczos, Salakhutdinov,
  and Smola]{zaheer2017deep}
M.~Zaheer, S.~Kottur, S.~Ravanbakhsh, B.~Poczos, R.~R. Salakhutdinov, and A.~J.
  Smola.
\newblock Deep sets.
\newblock \emph{Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem[Zhang(2006)]{zhang2006}
T.~Zhang.
\newblock From $\varepsilon$-entropy to {KL}-entropy: Analysis of minimum
  information complexity density estimation.
\newblock \emph{The Annals of Statistics}, 34\penalty0 (5):\penalty0
  2180--2210, 2006.

\bibitem[Zhu et~al.(2021)Zhu, An, and Huang]{zhu2021understanding}
S.~Zhu, B.~An, and F.~Huang.
\newblock Understanding the generalization benefit of model invariance from a
  data perspective.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\end{thebibliography}
