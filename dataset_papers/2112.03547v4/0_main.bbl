\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alonso-Mora et~al.(2017)Alonso-Mora, Baker, and Rus]{alonso2017multi}
Alonso-Mora, J., Baker, S., and Rus, D.
\newblock Multi-robot formation control and object transport in dynamic
  environments via constrained optimization.
\newblock \emph{The International Journal of Robotics Research}, 36\penalty0
  (9):\penalty0 1000--1021, 2017.

\bibitem[B{\"o}hmer et~al.(2020)B{\"o}hmer, Kurin, and
  Whiteson]{bohmer2020deep}
B{\"o}hmer, W., Kurin, V., and Whiteson, S.
\newblock Deep coordination graphs.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  980--991. PMLR, 2020.

\bibitem[Castellini et~al.(2019)Castellini, Oliehoek, Savani, and
  Whiteson]{castellini2019representational}
Castellini, J., Oliehoek, F.~A., Savani, R., and Whiteson, S.
\newblock The representational capacity of action-value networks for
  multi-agent reinforcement learning.
\newblock In \emph{AAMAS 2019: The 18th International Conference on Autonomous
  Agents and MultiAgent Systems}, pp.\  1862--1864. International Foundation
  for Autonomous Agents and Multiagent Systems (IFAAMAS), 2019.

\bibitem[Chan(2016)]{chan2016approximation}
Chan, S.~O.
\newblock Approximation resistance from pairwise-independent subgroups.
\newblock \emph{Journal of the ACM (JACM)}, 63\penalty0 (3):\penalty0 1--32,
  2016.

\bibitem[Cho et~al.(2014)Cho, Van~Merri{\"e}nboer, Gulcehre, Bahdanau,
  Bougares, Schwenk, and Bengio]{cho2014learning}
Cho, K., Van~Merri{\"e}nboer, B., Gulcehre, C., Bahdanau, D., Bougares, F.,
  Schwenk, H., and Bengio, Y.
\newblock Learning phrase representations using rnn encoder-decoder for
  statistical machine translation.
\newblock \emph{arXiv preprint arXiv:1406.1078}, 2014.

\bibitem[Dagum \& Luby(1993)Dagum and Luby]{dagum1993approximating}
Dagum, P. and Luby, M.
\newblock Approximating probabilistic inference in bayesian belief networks is
  np-hard.
\newblock \emph{Artificial intelligence}, 60\penalty0 (1):\penalty0 141--153,
  1993.

\bibitem[Das et~al.(2019)Das, Gervet, Romoff, Batra, Parikh, Rabbat, and
  Pineau]{das2019tarmac}
Das, A., Gervet, T., Romoff, J., Batra, D., Parikh, D., Rabbat, M., and Pineau,
  J.
\newblock Tarmac: Targeted multi-agent communication.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1538--1546, 2019.

\bibitem[Edmonds(1965)]{edmonds1965paths}
Edmonds, J.
\newblock Paths, trees, and flowers.
\newblock \emph{Canadian Journal of mathematics}, 17:\penalty0 449--467, 1965.

\bibitem[Fioretto et~al.(2018)Fioretto, Pontelli, and
  Yeoh]{fioretto2018distributed}
Fioretto, F., Pontelli, E., and Yeoh, W.
\newblock Distributed constraint optimization problems and applications: A
  survey.
\newblock \emph{Journal of Artificial Intelligence Research}, 61:\penalty0
  623--698, 2018.

\bibitem[Foerster et~al.(2017)Foerster, Nardelli, Farquhar, Afouras, Torr,
  Kohli, and Whiteson]{foerster2017stabilising}
Foerster, J., Nardelli, N., Farquhar, G., Afouras, T., Torr, P.~H., Kohli, P.,
  and Whiteson, S.
\newblock Stabilising experience replay for deep multi-agent reinforcement
  learning.
\newblock In \emph{International conference on machine learning}, pp.\
  1146--1155. PMLR, 2017.

\bibitem[Foerster et~al.(2018)Foerster, Farquhar, Afouras, Nardelli, and
  Whiteson]{foerster2018counterfactual}
Foerster, J.~N., Farquhar, G., Afouras, T., Nardelli, N., and Whiteson, S.
\newblock Counterfactual multi-agent policy gradients.
\newblock In \emph{Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem[Guestrin et~al.(2001)Guestrin, Koller, and
  Parr]{guestrin2001multiagent}
Guestrin, C., Koller, D., and Parr, R.
\newblock Multiagent planning with factored mdps.
\newblock In \emph{NIPS}, volume~1, pp.\  1523--1530, 2001.

\bibitem[Guestrin et~al.(2002{\natexlab{a}})Guestrin, Lagoudakis, and
  Parr]{guestrin2002coordinated}
Guestrin, C., Lagoudakis, M., and Parr, R.
\newblock Coordinated reinforcement learning.
\newblock In \emph{ICML}, volume~2, pp.\  227--234. Citeseer,
  2002{\natexlab{a}}.

\bibitem[Guestrin et~al.(2002{\natexlab{b}})Guestrin, Venkataraman, and
  Koller]{guestrin2002context}
Guestrin, C., Venkataraman, S., and Koller, D.
\newblock Context-specific multiagent coordination and planning with factored
  mdps.
\newblock In \emph{AAAI/IAAI}, pp.\  253--259, 2002{\natexlab{b}}.

\bibitem[Hasselt(2010)]{hasselt2010double}
Hasselt, H.
\newblock Double q-learning.
\newblock \emph{Advances in neural information processing systems},
  23:\penalty0 2613--2621, 2010.

\bibitem[Jiang \& Lu(2021)Jiang and Lu]{jiang2021emergence}
Jiang, J. and Lu, Z.
\newblock The emergence of individuality.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  4992--5001. PMLR, 2021.

\bibitem[Kok \& Vlassis(2006)Kok and Vlassis]{kok2006collaborative}
Kok, J.~R. and Vlassis, N.
\newblock Collaborative multiagent reinforcement learning by payoff
  propagation.
\newblock \emph{Journal of Machine Learning Research}, 7:\penalty0 1789--1828,
  2006.

\bibitem[Kraemer \& Banerjee(2016)Kraemer and Banerjee]{kraemer2016multi}
Kraemer, L. and Banerjee, B.
\newblock Multi-agent reinforcement learning as a rehearsal for decentralized
  planning.
\newblock \emph{Neurocomputing}, 190:\penalty0 82--94, 2016.

\bibitem[Li et~al.(2020)Li, Gupta, Morales, Allen, and
  Kochenderfer]{li2020deep}
Li, S., Gupta, J.~K., Morales, P., Allen, R., and Kochenderfer, M.~J.
\newblock Deep implicit coordination graphs for multi-agent reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:2006.11438}, 2020.

\bibitem[Lowe et~al.(2017)Lowe, Wu, Tamar, Harb, Abbeel, and
  Mordatch]{lowe2017multi}
Lowe, R., Wu, Y., Tamar, A., Harb, J., Abbeel, P., and Mordatch, I.
\newblock Multi-agent actor-critic for mixed cooperative-competitive
  environments.
\newblock \emph{Neural Information Processing Systems (NIPS)}, 2017.

\bibitem[Manurangsi et~al.(2015)Manurangsi, Nakkiran, and
  Trevisan]{manurangsi2015near}
Manurangsi, P., Nakkiran, P., and Trevisan, L.
\newblock Near-optimal ugc-hardness of approximating max k-csp\_r.
\newblock \emph{arXiv preprint arXiv:1511.06558}, 2015.

\bibitem[Oliehoek et~al.(2016)Oliehoek, Amato, et~al.]{oliehoek2016concise}
Oliehoek, F.~A., Amato, C., et~al.
\newblock \emph{A concise introduction to decentralized POMDPs}, volume~1.
\newblock Springer, 2016.

\bibitem[OroojlooyJadid \& Hajinezhad(2019)OroojlooyJadid and
  Hajinezhad]{oroojlooyjadid2019review}
OroojlooyJadid, A. and Hajinezhad, D.
\newblock A review of cooperative multi-agent deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1908.03963}, 2019.

\bibitem[Panait et~al.(2006)Panait, Luke, and Wiegand]{panait2006biasing}
Panait, L., Luke, S., and Wiegand, R.~P.
\newblock Biasing coevolutionary search for optimal multiagent behaviors.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 10\penalty0
  (6):\penalty0 629--645, 2006.

\bibitem[Park \& Darwiche(2004)Park and Darwiche]{park2004complexity}
Park, J.~D. and Darwiche, A.
\newblock Complexity results and approximation strategies for map explanations.
\newblock \emph{Journal of Artificial Intelligence Research}, 21:\penalty0
  101--133, 2004.

\bibitem[Pearl(1988)]{pearl1988probabilistic}
Pearl, J.
\newblock \emph{Probabilistic Reasoning in Intelligent Systems: Networks of
  Plausible Inference}.
\newblock Morgan Kaufmann, 1988.

\bibitem[Rashid et~al.(2020{\natexlab{a}})Rashid, Farquhar, Peng, and
  Whiteson]{rashid2020weighted}
Rashid, T., Farquhar, G., Peng, B., and Whiteson, S.
\newblock Weighted qmix: Expanding monotonic value function factorisation for
  deep multi- agent reinforcement learning.
\newblock \emph{NeurIPS Proceedings 2020}, 2020{\natexlab{a}}.

\bibitem[Rashid et~al.(2020{\natexlab{b}})Rashid, Samvelyan, De~Witt, Farquhar,
  Foerster, and Whiteson]{rashid2020monotonic}
Rashid, T., Samvelyan, M., De~Witt, C.~S., Farquhar, G., Foerster, J., and
  Whiteson, S.
\newblock Monotonic value function factorisation for deep multi-agent
  reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2003.08839}, 2020{\natexlab{b}}.

\bibitem[Samvelyan et~al.(2019)Samvelyan, Rashid, de~Witt, Farquhar, Nardelli,
  Rudner, Hung, Torr, Foerster, and Whiteson]{samvelyan19smac}
Samvelyan, M., Rashid, T., de~Witt, C.~S., Farquhar, G., Nardelli, N., Rudner,
  T. G.~J., Hung, C.-M., Torr, P. H.~S., Foerster, J., and Whiteson, S.
\newblock {The} {StarCraft} {Multi}-{Agent} {Challenge}.
\newblock \emph{CoRR}, abs/1902.04043, 2019.

\bibitem[Singh et~al.(2018)Singh, Jain, and Sukhbaatar]{singh2018learning}
Singh, A., Jain, T., and Sukhbaatar, S.
\newblock Learning when to communicate at scale in multiagent cooperative and
  competitive tasks.
\newblock \emph{arXiv preprint arXiv:1812.09755}, 2018.

\bibitem[Son et~al.(2019)Son, Kim, Kang, Hostallero, and Yi]{son2019qtran}
Son, K., Kim, D., Kang, W.~J., Hostallero, D.~E., and Yi, Y.
\newblock Qtran: Learning to factorize with transformation for cooperative
  multi-agent reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5887--5896, 2019.

\bibitem[Stranders et~al.(2009)Stranders, Farinelli, Rogers, and
  Jennings]{stranders2009decentralised}
Stranders, R., Farinelli, A., Rogers, A., and Jennings, N.~R.
\newblock Decentralised coordination of mobile sensors using the max-sum
  algorithm.
\newblock In \emph{Twenty-First International Joint Conference on Artificial
  Intelligence}, 2009.

\bibitem[Sunehag et~al.(2018)Sunehag, Lever, Gruslys, Czarnecki, Zambaldi,
  Jaderberg, Lanctot, Sonnerat, Leibo, Tuyls, et~al.]{sunehag2018value}
Sunehag, P., Lever, G., Gruslys, A., Czarnecki, W.~M., Zambaldi, V., Jaderberg,
  M., Lanctot, M., Sonnerat, N., Leibo, J.~Z., Tuyls, K., et~al.
\newblock Value-decomposition networks for cooperative multi-agent learning
  based on team reward.
\newblock In \emph{Proceedings of the 17th International Conference on
  Autonomous Agents and MultiAgent Systems}, pp.\  2085--2087, 2018.

\bibitem[Tan(1993)]{tan1993multi}
Tan, M.
\newblock Multi-agent reinforcement learning: Independent vs. cooperative
  agents.
\newblock In \emph{Proceedings of the tenth international conference on machine
  learning}, pp.\  330--337, 1993.

\bibitem[Van~der Pol \& Oliehoek(2016)Van~der Pol and
  Oliehoek]{van2016coordinated}
Van~der Pol, E. and Oliehoek, F.~A.
\newblock Coordinated deep reinforcement learners for traffic light control.
\newblock \emph{Proceedings of Learning, Inference and Control of Multi-Agent
  Systems (at NIPS 2016)}, 2016.

\bibitem[Wang et~al.(2021{\natexlab{a}})Wang, Ren, Liu, Yang, and
  Zhang]{wang2020QPLEX}
Wang, J., Ren, Z., Liu, T., Yang, Y., and Zhang, C.
\newblock Qplex: Duplex dueling multi-agent q-learning.
\newblock In \emph{International Conference on Learning Representations},
  2021{\natexlab{a}}.

\bibitem[Wang et~al.(2020{\natexlab{a}})Wang, Dong, Lesser, and
  Zhang]{wang2020multi}
Wang, T., Dong, H., Lesser, V., and Zhang, C.
\newblock Multi-agent reinforcement learning with emergent roles.
\newblock In \emph{International Conference on Machine Learning},
  2020{\natexlab{a}}.

\bibitem[Wang et~al.(2020{\natexlab{b}})Wang, Gupta, Mahajan, Peng, Whiteson,
  and Zhang]{wang2020rode}
Wang, T., Gupta, T., Mahajan, A., Peng, B., Whiteson, S., and Zhang, C.
\newblock Rode: Learning roles to decompose multi-agent tasks.
\newblock \emph{arXiv preprint arXiv:2010.01523}, 2020{\natexlab{b}}.

\bibitem[Wang et~al.(2020{\natexlab{c}})Wang, Wang, Zheng, and
  Zhang]{wang2019learning}
Wang, T., Wang, J., Zheng, C., and Zhang, C.
\newblock Learning nearly decomposable value functions via communication
  minimization.
\newblock In \emph{International Conference on Learning Representations},
  2020{\natexlab{c}}.

\bibitem[Wang et~al.(2021{\natexlab{b}})Wang, Zeng, Dong, Yang, Yu, and
  Zhang]{wang2021context}
Wang, T., Zeng, L., Dong, W., Yang, Q., Yu, Y., and Zhang, C.
\newblock Context-aware sparse deep coordination graphs.
\newblock \emph{arXiv preprint arXiv:2106.02886}, 2021{\natexlab{b}}.

\bibitem[Wang et~al.(2020{\natexlab{d}})Wang, Han, Wang, Dong, and
  Zhang]{wang2020off}
Wang, Y., Han, B., Wang, T., Dong, H., and Zhang, C.
\newblock Off-policy multi-agent decomposed policy gradients.
\newblock \emph{arXiv preprint arXiv:2007.12322}, 2020{\natexlab{d}}.

\bibitem[Wei \& Luke(2016)Wei and Luke]{wei2016lenient}
Wei, E. and Luke, S.
\newblock Lenient learning in independent-learner stochastic cooperative games.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 2914--2955, 2016.

\bibitem[Wen et~al.(2019)Wen, Yang, Luo, Wang, and Pan]{wen2019probabilistic}
Wen, Y., Yang, Y., Luo, R., Wang, J., and Pan, W.
\newblock Probabilistic recursive reasoning for multi-agent reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:1901.09207}, 2019.

\bibitem[Ye et~al.(2015)Ye, Zhang, and Yang]{ye2015multi}
Ye, D., Zhang, M., and Yang, Y.
\newblock A multi-agent framework for packet routing in wireless sensor
  networks.
\newblock \emph{Sensors}, 15\penalty0 (5):\penalty0 10026--10047, 2015.

\bibitem[Yoon et~al.(2020)Yoon, Song, Shin, and Yi]{yoon2020much}
Yoon, S.-e., Song, H., Shin, K., and Yi, Y.
\newblock How much and when do we need higher-order information in hypergraphs?
  a case study on hyperedge prediction.
\newblock In \emph{Proceedings of The Web Conference 2020}, pp.\  2627--2633,
  2020.

\bibitem[Zhang \& Lesser(2011)Zhang and Lesser]{zhang2011coordinated}
Zhang, C. and Lesser, V.
\newblock Coordinated multi-agent reinforcement learning in networked
  distributed pomdps.
\newblock In \emph{Twenty-Fifth AAAI Conference on Artificial Intelligence},
  2011.

\bibitem[Zhang \& Lesser(2013)Zhang and Lesser]{zhang2013coordinating}
Zhang, C. and Lesser, V.
\newblock Coordinating multi-agent reinforcement learning with limited
  communication.
\newblock In \emph{Proceedings of the 2013 international conference on
  Autonomous agents and multi-agent systems}, pp.\  1101--1108, 2013.

\end{thebibliography}
