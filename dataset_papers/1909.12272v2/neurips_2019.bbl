\begin{thebibliography}{10}

\bibitem{abbasi2017robustness}
Mahdieh Abbasi and Christian Gagn{\'e}.
\newblock Robustness to adversarial examples through an ensemble of
  specialists.
\newblock {\em arXiv preprint arXiv:1702.06856}, 2017.

\bibitem{arnab_cvpr_2018}
Anurag Arnab, Ondrej Miksik, and Philip H.~S. Torr.
\newblock On the robustness of semantic segmentation models to adversarial
  attacks.
\newblock In {\em CVPR}, 2018.

\bibitem{pmlr-v80-athalye18a}
Anish Athalye, Nicholas Carlini, and David Wagner.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In {\em Proceedings of the 35th International Conference on Machine
  Learning}, pages 274--283, 2018.

\bibitem{bagnall2017training}
Alexander Bagnall, Razvan Bunescu, and Gordon Stewart.
\newblock Training ensembles to detect adversarial examples.
\newblock {\em arXiv preprint arXiv:1712.04006}, 2017.

\bibitem{bhagoji2018analyzing}
Arjun~Nitin Bhagoji, Supriyo Chakraborty, Prateek Mittal, and Seraphin Calo.
\newblock Analyzing federated learning through an adversarial lens.
\newblock In {\em ICML}, 2019.

\bibitem{bhagoji2017dimensionality}
Arjun~Nitin Bhagoji, Daniel Cullina, and Prateek Mittal.
\newblock Dimensionality reduction as a defense against evasion attacks on
  machine learning classifiers.
\newblock {\em arXiv preprint arXiv:1704.02654}, 2017.

\bibitem{bhagoji2018practical}
Arjun~Nitin Bhagoji, Warren He, Bo~Li, and Dawn Song.
\newblock Practical black-box attacks on deep neural networks using efficient
  query mechanisms.
\newblock In {\em European Conference on Computer Vision}, pages 158--174.
  Springer, 2018.

\bibitem{biggio2013evasion}
Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Nedim
  {\v{S}}rndi{\'c}, Pavel Laskov, Giorgio Giacinto, and Fabio Roli.
\newblock Evasion attacks against machine learning at test time.
\newblock In {\em Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pages 387--402. Springer, 2013.

\bibitem{biggio2012poisoning}
Battista Biggio, Blaine Nelson, and Pavel Laskov.
\newblock Poisoning attacks against support vector machines.
\newblock In {\em Proceedings of the 29th International Conference on Machine
  Learning (ICML-12)}, pages 1807--1814, 2012.

\bibitem{biggio2017wild}
Battista Biggio and Fabio Roli.
\newblock Wild patterns: Ten years after the rise of adversarial machine
  learning.
\newblock {\em arXiv preprint arXiv:1712.03141}, 2017.

\bibitem{brendel2017decision}
Wieland Brendel, Jonas Rauber, and Matthias Bethge.
\newblock Decision-based adversarial attacks: Reliable attacks against
  black-box machine learning models.
\newblock In {\em ICLR}, 2018.

\bibitem{brown2017superhuman}
Noam Brown and Tuomas Sandholm.
\newblock Superhuman ai for heads-up no-limit poker: Libratus beats top
  professionals.
\newblock {\em Science}, page eaao1733, 2017.

\bibitem{bubeck2018adversarial}
S{\'e}bastien Bubeck, Eric Price, and Ilya Razenshteyn.
\newblock Adversarial examples from computational constraints.
\newblock {\em arXiv preprint arXiv:1805.10204}, 2018.

\bibitem{carlini2016defensive}
Nicholas Carlini and David Wagner.
\newblock Defensive distillation is not robust to adversarial examples.
\newblock {\em arXiv preprint arXiv:1607.04311}, 2016.

\bibitem{carlini2017adversarial}
Nicholas Carlini and David Wagner.
\newblock Adversarial examples are not easily detected: Bypassing ten detection
  methods.
\newblock In {\em AISec}, 2017.

\bibitem{carlini2017magnet}
Nicholas Carlini and David Wagner.
\newblock Magnet and ``efficient defenses against adversarial attacks" are not
  robust to adversarial examples.
\newblock {\em arXiv preprint arXiv:1711.08478}, 2017.

\bibitem{carlini2017towards}
Nicholas Carlini and David Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In {\em Security and Privacy (SP), 2017 IEEE Symposium on}, pages
  39--57. IEEE, 2017.

\bibitem{carlini2018audio}
Nicholas Carlini and David Wagner.
\newblock Audio adversarial examples: Targeted attacks on speech-to-text.
\newblock In {\em DLS (IEEE SP)}, 2018.

\bibitem{chen2017ead}
Pin-Yu Chen, Yash Sharma, Huan Zhang, Jinfeng Yi, and Cho-Jui Hsieh.
\newblock Ead: elastic-net attacks to deep neural networks via adversarial
  examples.
\newblock In {\em AAAI}, 2018.

\bibitem{chen2017zoo}
Pin-Yu Chen, Huan Zhang, Yash Sharma, Jinfeng Yi, and Cho-Jui Hsieh.
\newblock Zoo: Zeroth order optimization based black-box attacks to deep neural
  networks without training substitute models.
\newblock In {\em Proceedings of the 10th ACM Workshop on Artificial
  Intelligence and Security}, pages 15--26. ACM, 2017.

\bibitem{chen2018robust}
Shang-Tse Chen, Cory Cornelius, Jason Martin, and Duen~Horng Chau.
\newblock Robust physical adversarial attack on faster r-cnn object detector.
\newblock {\em arXiv preprint arXiv:1804.05810}, 2018.

\bibitem{collobert2011natural}
Ronan Collobert, Jason Weston, L{\'e}on Bottou, Michael Karlen, Koray
  Kavukcuoglu, and Pavel Kuksa.
\newblock Natural language processing (almost) from scratch.
\newblock {\em Journal of Machine Learning Research}, 12(Aug):2493--2537, 2011.

\bibitem{cullina2018pac}
Daniel Cullina, Arjun~Nitin Bhagoji, and Prateek Mittal.
\newblock Pac-learning in the presence of adversaries.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  230--241, 2018.

\bibitem{das2018shield}
Nilaksh Das, Madhuri Shanbhogue, Shang-Tse Chen, Fred Hohman, Siwei Li,
  Li~Chen, Michael~E Kounavis, and Duen~Horng Chau.
\newblock Shield: Fast, practical defense and vaccination for deep learning
  using jpeg compression.
\newblock {\em arXiv preprint arXiv:1802.06816}, 2018.

\bibitem{deng2013new}
Li~Deng, Geoffrey Hinton, and Brian Kingsbury.
\newblock New types of deep neural network learning for speech recognition and
  related applications: An overview.
\newblock In {\em Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE
  International Conference on}, pages 8599--8603. IEEE, 2013.

\bibitem{diochnos2018adversarial}
Dimitrios Diochnos, Saeed Mahloujifar, and Mohammad Mahmoody.
\newblock Adversarial risk and robustness: General definitions and implications
  for the uniform distribution.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  10359--10368, 2018.

\bibitem{pmlr-v97-dohmatob19a}
Elvis Dohmatob.
\newblock Generalized no free lunch theorem for adversarial robustness.
\newblock In {\em Proceedings of the 36th International Conference on Machine
  Learning}, pages 1646--1654, 2019.

\bibitem{dziugaite2016study}
Gintare~Karolina Dziugaite, Zoubin Ghahramani, and Daniel~M Roy.
\newblock A study of the effect of {JPG} compression on adversarial images.
\newblock {\em arXiv preprint arXiv:1608.00853}, 2016.

\bibitem{Evtimov17}
Ivan Evtimov, Kevin Eykholt, Earlence Fernandes, Tadayoshi Kohno, Bo~Li, Atul
  Prakash, Amir Rahmati, and Dawn Song.
\newblock Robust physical-world attacks on machine learning models.
\newblock In {\em CVPR}, 2018.

\bibitem{fawzi2016robustness}
Alhussein Fawzi, Seyed-Mohsen Moosavi-Dezfooli, and Pascal Frossard.
\newblock Robustness of classifiers: from adversarial to random noise.
\newblock In {\em NIPS}, 2016.

\bibitem{fischer2017adversarial}
Volker Fischer, Mummadi~Chaithanya Kumar, Jan~Hendrik Metzen, and Thomas Brox.
\newblock Adversarial examples for semantic image segmentation.
\newblock In {\em ICLR Workshop}, 2017.

\bibitem{ford2019adversarial}
Nic Ford, Justin Gilmer, Nicolas Carlini, and Dogus Cubuk.
\newblock Adversarial examples are a natural consequence of test error in
  noise.
\newblock In {\em ICML}, 2019.

\bibitem{gilmer2018adversarial}
Justin Gilmer, Luke Metz, Fartash Faghri, Samuel~S Schoenholz, Maithra Raghu,
  Martin Wattenberg, and Ian Goodfellow.
\newblock Adversarial spheres.
\newblock In {\em ICLR}, 2018.

\bibitem{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In {\em International Conference on Learning Representations}, 2015.

\bibitem{gowal2018effectiveness}
Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel, Chongli Qin,
  Jonathan Uesato, Timothy Mann, and Pushmeet Kohli.
\newblock On the effectiveness of interval bound propagation for training
  verifiably robust models.
\newblock {\em arXiv preprint arXiv:1810.12715}, 2018.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem{hinton2012deep}
Geoffrey Hinton, Li~Deng, Dong Yu, George~E Dahl, Abdel-rahman Mohamed, Navdeep
  Jaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Tara~N Sainath,
  et~al.
\newblock Deep neural networks for acoustic modeling in speech recognition: The
  shared views of four research groups.
\newblock {\em IEEE Signal Processing Magazine}, 29(6):82--97, 2012.

\bibitem{huang2017adversarial}
Sandy Huang, Nicolas Papernot, Ian Goodfellow, Yan Duan, and Pieter Abbeel.
\newblock Adversarial attacks on neural network policies.
\newblock In {\em ICLR}, 2017.

\bibitem{ilyas2019adversarial}
Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon
  Tran, and Aleksander Madry.
\newblock Adversarial examples are not bugs, they are features.
\newblock {\em arXiv preprint arXiv:1905.02175}, 2019.

\bibitem{jagielski2018manipulating}
Matthew Jagielski, Alina Oprea, Battista Biggio, Chang Liu, Cristina
  Nita-Rotaru, and Bo~Li.
\newblock Manipulating machine learning: Poisoning attacks and countermeasures
  for regression learning.
\newblock In {\em IEEE Security and Privacy}, 2018.

\bibitem{scipyref}
Eric Jones, Travis Oliphant, Pearu Peterson, et~al.
\newblock {SciPy}: Open source scientific tools for {Python}, 2001--.
\newblock [Online; accessed 05/23/2019].

\bibitem{julian2016policy}
Kyle~D Julian, Jessica Lopez, Jeffrey~S Brush, Michael~P Owen, and Mykel~J
  Kochenderfer.
\newblock Policy compression for aircraft collision avoidance systems.
\newblock In {\em Digital Avionics Systems Conference (DASC), 2016 IEEE/AIAA
  35th}, pages 1--10. IEEE, 2016.

\bibitem{kingma2014adam}
Diederik Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{kolter2017provable}
J~Zico Kolter and Eric Wong.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope.
\newblock In {\em ICML}, 2018.

\bibitem{kos2017adversarial}
Jernej Kos, Ian Fischer, and Dawn Song.
\newblock Adversarial examples for generative models.
\newblock {\em arXiv preprint arXiv:1702.06832}, 2017.

\bibitem{kos2017delving}
Jernej Kos and Dawn Song.
\newblock Delving into adversarial attacks on deep policies.
\newblock In {\em ICLR Workshop}, 2017.

\bibitem{krizhevsky2009learning}
Alex Krizhevsky and Geoffrey Hinton.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem{Krizhevsky:2012:ICD:2999134.2999257}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E. Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In {\em Proceedings of the 25th International Conference on Neural
  Information Processing Systems - Volume 1}, NIPS'12, pages 1097--1105, USA,
  2012. Curran Associates Inc.

\bibitem{kurakin2016adversarial}
Alexey Kurakin, Ian Goodfellow, and Samy Bengio.
\newblock Adversarial examples in the physical world.
\newblock {\em arXiv preprint arXiv:1607.02533}, 2016.

\bibitem{lecun1998mnist}
Yann LeCun and Corrina Cortes.
\newblock The {MNIST} database of handwritten digits.
\newblock 1998.

\bibitem{liu2018survey}
Qiang Liu, Pan Li, Wentao Zhao, Wei Cai, Shui Yu, and Victor~CM Leung.
\newblock A survey on security threats and defensive techniques of machine
  learning: A data driven view.
\newblock {\em IEEE access}, 6:12103--12117, 2018.

\bibitem{liu2016delving}
Yanpei Liu, Xinyun Chen, Chang Liu, and Dawn Song.
\newblock Delving into transferable adversarial examples and black-box attacks.
\newblock In {\em ICLR}, 2017.

\bibitem{lu2017adversarial}
Jiajun Lu, Hussein Sibai, and Evan Fabry.
\newblock Adversarial examples that fool detectors.
\newblock {\em arXiv preprint arXiv:1712.02494}, 2017.

\bibitem{madry_towards_2017}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In {\em ICLR}, 2018.

\bibitem{mahloujifar2019curse}
Saeed Mahloujifar, Dimitrios~I Diochnos, and Mohammad Mahmoody.
\newblock The curse of concentration in robust learning: Evasion and poisoning
  attacks from concentration of measure.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 4536--4543, 2019.

\bibitem{montasser2019vc}
Omar Montasser, Steve Hanneke, and Nathan Srebro.
\newblock Vc classes are adversarially robustly learnable, but only improperly.
\newblock {\em arXiv preprint arXiv:1902.04217}, 2019.

\bibitem{moosavi2016universal}
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, and Pascal
  Frossard.
\newblock Universal adversarial perturbations.
\newblock In {\em CVPR}, 2017.

\bibitem{moosavi2015deepfool}
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard.
\newblock Deepfool: a simple and accurate method to fool deep neural networks.
\newblock In {\em CVPR}, 2016.

\bibitem{moravvcik2017deepstack}
Matej Morav{\v{c}}{\'\i}k, Martin Schmid, Neil Burch, Viliam Lis{\`y}, Dustin
  Morrill, Nolan Bard, Trevor Davis, Kevin Waugh, Michael Johanson, and Michael
  Bowling.
\newblock Deepstack: Expert-level artificial intelligence in heads-up no-limit
  poker.
\newblock {\em Science}, 356(6337):508--513, 2017.

\bibitem{mozaffari2015systematic}
Mehran Mozaffari-Kermani, Susmita Sur-Kolay, Anand Raghunathan, and Niraj~K
  Jha.
\newblock Systematic poisoning attacks on and defenses for machine learning in
  healthcare.
\newblock {\em IEEE journal of biomedical and health informatics},
  19(6):1893--1905, 2015.

\bibitem{papernot2016transferability}
Nicolas Papernot, Patrick McDaniel, and Ian Goodfellow.
\newblock Transferability in machine learning: from phenomena to black-box
  attacks using adversarial samples.
\newblock {\em arXiv preprint arXiv:1605.07277}, 2016.

\bibitem{papernot2016practical}
Nicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z~Berkay~Celik,
  and Ananthram Swami.
\newblock Practical black-box attacks against deep learning systems using
  adversarial examples.
\newblock In {\em Proceedings of the 2017 ACM Asia Conference on Computer and
  Communications Security}, 2017.

\bibitem{papernot2016limitations}
Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z~Berkay
  Celik, and Ananthram Swami.
\newblock The limitations of deep learning in adversarial settings.
\newblock In {\em 2016 IEEE European Symposium on Security and Privacy
  (EuroS\&P)}, pages 372--387. IEEE, 2016.

\bibitem{papernot2016towards}
Nicolas Papernot, Patrick McDaniel, Arunesh Sinha, and Michael Wellman.
\newblock Towards the science of security and privacy in machine learning.
\newblock {\em arXiv preprint arXiv:1611.03814}, 2016.

\bibitem{papernot2016distillation}
Nicolas Papernot, Patrick McDaniel, Xi~Wu, Somesh Jha, and Ananthram Swami.
\newblock Distillation as a defense to adversarial perturbations against deep
  neural networks.
\newblock In {\em Security and Privacy (SP), 2016 IEEE Symposium on}, pages
  582--597. IEEE, 2016.

\bibitem{raghunathan2018certified}
Aditi Raghunathan, Jacob Steinhardt, and Percy Liang.
\newblock Certified defenses against adversarial examples.
\newblock In {\em ICLR}, 2018.

\bibitem{rubinstein2009stealthy}
Benjamin~IP Rubinstein, Blaine Nelson, Ling Huang, Anthony~D Joseph, Shing-hon
  Lau, Satish Rao, Nina Taft, and JD~Tygar.
\newblock Stealthy poisoning attacks on pca-based anomaly detectors.
\newblock {\em ACM SIGMETRICS Performance Evaluation Review}, 37(2):73--74,
  2009.

\bibitem{schmidt2018adversarially}
Ludwig Schmidt, Shibani Santurkar, Dimitris Tsipras, Kunal Talwar, and
  Aleksander Madry.
\newblock Adversarially robust generalization requires more data.
\newblock {\em arXiv preprint arXiv:1804.11285}, 2018.

\bibitem{shaham2018defending}
Uri Shaham, James Garritano, Yutaro Yamada, Ethan Weinberger, Alex Cloninger,
  Xiuyuan Cheng, Kelly Stanton, and Yuval Kluger.
\newblock Defending against adversarial images using basis functions
  transformations.
\newblock {\em arXiv preprint arXiv:1803.10840}, 2018.

\bibitem{sharif2016accessorize}
Mahmood Sharif, Sruti Bhagavatula, Lujo Bauer, and Michael~K Reiter.
\newblock Accessorize to a crime: Real and stealthy attacks on state-of-the-art
  face recognition.
\newblock In {\em Proceedings of the 2016 ACM SIGSAC Conference on Computer and
  Communications Security}, pages 1528--1540. ACM, 2016.

\bibitem{silver2017mastering}
David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja
  Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton,
  et~al.
\newblock Mastering the game of go without human knowledge.
\newblock {\em Nature}, 550(7676):354, 2017.

\bibitem{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock {\em arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{sinha2017certifiable}
Aman Sinha, Hongseok Namkoong, and John Duchi.
\newblock Certifiable distributional robustness with principled adversarial
  training.
\newblock In {\em ICLR}, 2018.

\bibitem{sitawarin2018rogue}
Chawin Sitawarin, Arjun~Nitin Bhagoji, Arsalan Mosenia, Prateek Mittal, and
  Mung Chiang.
\newblock Rogue signs: Deceiving traffic sign recognition with malicious ads
  and logos.
\newblock In {\em DLS (IEEE SP)}, 2018.

\bibitem{smutz2016tree}
Charles Smutz and Angelos Stavrou.
\newblock When a tree falls: Using diversity in ensemble classifiers to
  identify evasion in malware detectors.
\newblock In {\em NDSS}, 2016.

\bibitem{suggala2019revisiting}
Arun~Sai Suggala, Adarsh Prasad, Vaishnavh Nagarajan, and Pradeep Ravikumar.
\newblock Revisiting adversarial risk.
\newblock In {\em The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 2331--2339, 2019.

\bibitem{szegedy2013intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock {\em arXiv preprint arXiv:1312.6199}, 2013.

\bibitem{tramer2017ensemble}
Florian Tram{\`e}r, Alexey Kurakin, Nicolas Papernot, Dan Boneh, and Patrick
  McDaniel.
\newblock Ensemble adversarial training: Attacks and defenses.
\newblock In {\em ICLR}, 2018.

\bibitem{tsipras2018there}
Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and
  Aleksander Madry.
\newblock There is no free lunch in adversarial robustness (but there are
  unexpected benefits).
\newblock {\em arXiv preprint arXiv:1805.12152}, 2018.

\bibitem{villani2008optimal}
C{\'e}dric Villani.
\newblock {\em Optimal transport: old and new}, volume 338.
\newblock Springer Science \& Business Media, 2008.

\bibitem{wang2017adversary}
Qinglong Wang, Wenbo Guo, Kaixuan Zhang, Alexander~G Ororbia~II, Xinyu Xing,
  Xue Liu, and C~Lee Giles.
\newblock Adversary resistant deep neural networks with an application to
  malware detection.
\newblock In {\em Proceedings of the 23rd ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, pages 1145--1153. ACM, 2017.

\bibitem{xiao2017/online}
Han Xiao, Kashif Rasul, and Roland Vollgraf.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms, 2017.

\bibitem{xie2017adversarial}
Cihang Xie, Jianyu Wang, Zhishuai Zhang, Yuyin Zhou, Lingxi Xie, and Alan
  Yuille.
\newblock Adversarial examples for semantic segmentation and object detection.
\newblock In {\em International Conference on Computer Vision. IEEE}, 2017.

\bibitem{xu2017feature}
Weilin Xu, David Evans, and Yanjun Qi.
\newblock Feature squeezing: Detecting adversarial examples in deep neural
  networks.
\newblock In {\em NDSS}, 2018.

\bibitem{yin2018rademacher}
Dong Yin, Kannan Ramchandran, and Peter Bartlett.
\newblock Rademacher complexity for adversarially robust generalization.
\newblock In {\em ICML}, 2019.

\bibitem{yuan2018commandersong}
Xuejing Yuan, Yuxuan Chen, Yue Zhao, Yunhui Long, Xiaokang Liu, Kai Chen,
  Shengzhi Zhang, Heqing Huang, Xiaofeng Wang, and Carl~A Gunter.
\newblock Commandersong: A systematic approach for practical adversarial voice
  recognition.
\newblock In {\em USENIX Security}, 2018.

\bibitem{zhang2019theoretically}
Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric~P Xing, Laurent~El Ghaoui, and
  Michael~I Jordan.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock {\em arXiv preprint arXiv:1901.08573}, 2019.

\end{thebibliography}
