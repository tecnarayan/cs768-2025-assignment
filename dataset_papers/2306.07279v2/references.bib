% 3d datasets
@article{deitke2022objaverse,
  title={Objaverse: A Universe of Annotated 3D Objects},
  author={Deitke, Matt and Schwenk, Dustin and Salvador, Jordi and Weihs, Luca and Michel, Oscar and VanderBilt, Eli and Schmidt, Ludwig and Ehsani, Kiana and Kembhavi, Aniruddha and Farhadi, Ali},
  booktitle={CVPR},
  year={2023}
}


@article{jun2023shap,
  title={Shap-e: Generating conditional 3d implicit functions},
  author={Jun, Heewoo and Nichol, Alex},
  journal={arXiv preprint arXiv:2305.02463},
  year={2023}
}

@article{collins2022abo,
  title={ABO: Dataset and Benchmarks for Real-World 3D Object Understanding},
  author={Collins, Jasmine and Goel, Shubham and Deng, Kenan and Luthra, Achleshwar and
          Xu, Leon and Gundogdu, Erhan and Zhang, Xi and Yago Vicente, Tomas F and
          Dideriksen, Thomas and Arora, Himanshu and Guillaumin, Matthieu and
          Malik, Jitendra},
  journal={CVPR},
  year={2022}
}

@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{
fu2022shapecrafter,
title={ShapeCrafter: A Recursive Text-Conditioned 3D Shape Generation Model},
author={Rao Fu and Xiao Zhan and Yiwen Chen and Daniel Ritchie and Srinath Sridhar},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=KUOKpojFr_}
}


@inproceedings{zhou20213d,
  title={3d shape generation and completion through point-voxel diffusion},
  author={Zhou, Linqi and Du, Yilun and Wu, Jiajun},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5826--5835},
  year={2021}
}


@article{zhang20233dshape2vecset,
  title={3dshape2vecset: A 3d shape representation for neural fields and generative diffusion models},
  author={Zhang, Biao and Tang, Jiapeng and Niessner, Matthias and Wonka, Peter},
  journal={arXiv preprint arXiv:2301.11445},
  year={2023}
}

@inproceedings{wei2023taps3d,
  title={TAPS3D: Text-Guided 3D Textured Shape Generation from Pseudo Supervision},
  author={Wei, Jiacheng and Wang, Hao and Feng, Jiashi and Lin, Guosheng and Yap, Kim-Hui},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16805--16815},
  year={2023}
}

@article{
luo2023neural,
title={Neural Shape Compiler: A Unified Framework for Transforming between Text, Point Cloud, and Program},
author={Tiange Luo and Honglak Lee and Justin Johnson},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023},
url={https://openreview.net/forum?id=gR9UVgH8PZ},
note={}
}

@inproceedings{lin2023magic3d,
  title={Magic3d: High-resolution text-to-3d content creation},
  author={Lin, Chen-Hsuan and Gao, Jun and Tang, Luming and Takikawa, Towaki and Zeng, Xiaohui and Huang, Xun and Kreis, Karsten and Fidler, Sanja and Liu, Ming-Yu and Lin, Tsung-Yi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={300--309},
  year={2023}
}

@article{liu2023openshape,
  title={OpenShape: Scaling Up 3D Shape Representation Towards Open-World Understanding},
  author={Liu, Minghua and Shi, Ruoxi and Kuang, Kaiming and Zhu, Yinhao and Li, Xuanlin and Han, Shizhong and Cai, Hong and Porikli, Fatih and Su, Hao},
  journal={arXiv},
  year={2023}
}

@article{chang2015shapenet,
  title={Shapenet: An information-rich 3d model repository},
  author={Chang, Angel X and Funkhouser, Thomas and Guibas, Leonidas and Hanrahan, Pat and Huang, Qixing and Li, Zimo and Savarese, Silvio and Savva, Manolis and Song, Shuran and Su, Hao and others},
  journal={arXiv},
  year={2015}
}

@article{fu20213d,
  title={3d-future: 3d furniture shape with texture},
  author={Fu, Huan and Jia, Rongfei and Gao, Lin and Gong, Mingming and Zhao, Binqiang and Maybank, Steve and Tao, Dacheng},
  journal={IJCV},
  year={2021},
}


@inproceedings{lim2013parsing,
  title={Parsing ikea objects: Fine pose estimation},
  author={Lim, Joseph J and Pirsiavash, Hamed and Torralba, Antonio},
  booktitle={ICCV},
  year={2013}
}

% 3D - text datasets
@inproceedings{chen2019text2shape,
  title={Text2shape: Generating shapes from natural language by learning joint embeddings},
  author={Chen, Kevin and Choy, Christopher B and Savva, Manolis and Chang, Angel X and Funkhouser, Thomas and Savarese, Silvio},
  booktitle={ACCV},
  year={2019},
}

@article{shapeglot,
	title	= {{ShapeGlot}: Learning Language for Shape Differentiation},
	author	= {Achlioptas, Panos and Fan, Judy and Hawkins, X.D. Robert and Goodman, D. Noah and Guibas, J. Leonidas},
	journal	= {CoRR},
	year	= {2019}
}

@inproceedings{chen2020scanrefer,
  title={Scanrefer: 3d object localization in rgb-d scans using natural language},
  author={Chen, Dave Zhenyu and Chang, Angel X and Nie{\ss}ner, Matthias},
  booktitle={ECCV},
  year={2020},
}


@book{parent2012computer,
  title={Computer animation: algorithms and techniques},
  author={Parent, Rick},
  year={2012},
  publisher={Newnes}
}

@incollection{tang20203d,
  title={3D modeling and computer graphics in virtual reality},
  author={Tang, Yuk Ming and Ho, Ho Lun},
  booktitle={Mixed Reality and Three-Dimensional Computer Graphics},
  year={2020},
  publisher={IntechOpen}
}

@inproceedings{li2023behavior,
  title={Behavior-1k: A benchmark for embodied ai with 1,000 everyday activities and realistic simulation},
  author={Li, Chengshu and Zhang, Ruohan and Wong, Josiah and Gokmen, Cem and Srivastava, Sanjana and Mart{\'\i}n-Mart{\'\i}n, Roberto and Wang, Chen and Levine, Gabrael and Lingelbach, Michael and Sun, Jiankai and others},
  booktitle={Conference on Robot Learning},
  pages={80--93},
  year={2023},
  organization={PMLR}
}

@article{afzal2020study,
  title={A study on the challenges of using robotics simulators for testing},
  author={Afzal, Afsoon and Katz, Deborah S and Goues, Claire Le and Timperley, Christopher S},
  journal={arXiv preprint arXiv:2004.07368},
  year={2020}
}

@inproceedings{dosovitskiy2017carla,
  title={CARLA: An open urban driving simulator},
  author={Dosovitskiy, Alexey and Ros, German and Codevilla, Felipe and Lopez, Antonio and Koltun, Vladlen},
  booktitle={Conference on robot learning},
  pages={1--16},
  year={2017},
  organization={PMLR}
}

% language models
@inproceedings{brown2020lang,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D. and Dhariwal, Prafulla and Neelakantan, Arvind and others},
  booktitle={NeurIPS},
  year={2020}
}


% text to 3D models
@article{seo2023let,
  title={Let 2D Diffusion Model Know 3D-Consistency for Robust Text-to-3D Generation},
  author={Seo, Junyoung and Jang, Wooseok and Kwak, Min-Seop and Ko, Jaehoon and Kim, Hyeonsu and Kim, Junho and Kim, Jin-Hwa and Lee, Jiyoung and Kim, Seungryong},
  journal={arXiv},
  year={2023}
}

@article{wu2023multi,
  title={Multiview Compressive Coding for 3D Reconstruction},
  author={Wu, Chao-Yuan and Johnson, Justin and Malik, Jitendra and Feichtenhofer, Christoph and Gkioxari, Georgia},
  journal={arXiv},
  year={2023}
}

@article{tsalicoglou2023textmesh,
  title={TextMesh: Generation of Realistic 3D Meshes From Text Prompts},
  author={Tsalicoglou, Christina and Manhardt, Fabian and Tonioni, Alessio and Niemeyer, Michael and Tombari, Federico},
  journal={arXiv},
  year={2023}
}

@article{liu2023zero,
  title={Zero-1-to-3: Zero-shot One Image to 3D Object},
  author={Liu, Ruoshi and Wu, Rundi and Van Hoorick, Basile and Tokmakov, Pavel and Zakharov, Sergey and Vondrick, Carl},
  journal={arXiv},
  year={2023}
}

@inproceedings{sanghi2022clip,
  title={Clip-forge: Towards zero-shot text-to-shape generation},
  author={Sanghi, Aditya and Chu, Hang and Lambourne, Joseph G and Wang, Ye and Cheng, Chin-Yi and Fumero, Marco and Malekshan, Kamal Rahimi},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{mittal2022autosdf,
  title={Autosdf: Shape priors for 3d completion, reconstruction and generation},
  author={Mittal, Paritosh and Cheng, Yen-Chi and Singh, Maneesh and Tulsiani, Shubham},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{holtzman2020nucleus,
    title={The Curious Case of Neural Text Degeneration},
    author={Ari Holtzman and Jan Buys and Li Du and Maxwell Forbes and Yejin Choi},
    booktitle={ICLR},
    year={2020}
}

@article{nichol2022point,
  title={Point-E: A System for Generating 3D Point Clouds from Complex Prompts},
  author={Nichol, Alex and Jun, Heewoo and Dhariwal, Prafulla and Mishkin, Pamela and Chen, Mark},
  journal={arXiv},
  year={2022}
}

@article{nichol2023shape,
  title={Shap-E: Generating Conditional 3D Implicit Functions},
  author={Nichol, Alex and Jun, Heewoo},
  journal={arXiv},
  year={2023}
}

@article{gupta20233dgen,
  title={3DGen: Triplane Latent Diffusion for Textured Mesh Generation},
  author={Gupta, Anchit and Xiong, Wenhan and Nie, Yixin and Jones, Ian and O{\u{g}}uz, Barlas},
  journal={arXiv},
  year={2023}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={NeurIPS},
  year={2017}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={NeurIPS},
  volume={33},
  year={2020}
}

@article{karras2022elucidating,
  title={Elucidating the design space of diffusion-based generative models},
  author={Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli},
  journal={NeurIPS},
  year={2022}
}

@inproceedings{nichol2021improved,
  title={Improved denoising diffusion probabilistic models},
  author={Nichol, Alexander Quinn and Dhariwal, Prafulla},
  booktitle={ICML},
  year={2021},
}

@article{song2019generative,
  title={Generative modeling by estimating gradients of the data distribution},
  author={Song, Yang and Ermon, Stefano},
  journal={NeurIPS},
  year={2019}
}

@inproceedings{sohl2015deep,
  title={Deep unsupervised learning using nonequilibrium thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={ICML},
  year={2015},
}

@article{ho2022classifier,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  booktitle={NeurIPS Workshop on Deep Generative Models and Downstream Applications},
  year={2021}
}

@inproceedings{jain2022zero,
  title={Zero-shot text-guided object generation with dream fields},
  author={Jain, Ajay and Mildenhall, Ben and Barron, Jonathan T and Abbeel, Pieter and Poole, Ben},
  booktitle={CVPR},
  year={2022}
}

@article{poole2022dreamfusion,
  title={Dreamfusion: Text-to-3d using 2d diffusion},
  author={Poole, Ben and Jain, Ajay and Barron, Jonathan T and Mildenhall, Ben},
  journal={arXiv},
  year={2022}
}

@article{shen2021deep,
  title={Deep marching tetrahedra: a hybrid representation for high-resolution 3d shape synthesis},
  author={Shen, Tianchang and Gao, Jun and Yin, Kangxue and Liu, Ming-Yu and Fidler, Sanja},
  journal={NeurIPS},
  year={2021}
}

@article{chou2022gensdf,
  title={GenSDF: Two-Stage Learning of Generalizable Signed Distance Functions},
  author={Chou, Gene and Chugunov, Ilya and Heide, Felix},
  journal={NeurIPS},
  year={2022}
}

@inproceedings{qi2017pointnet,
  title={Pointnet: Deep learning on point sets for 3d classification and segmentation},
  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
  booktitle={CVPR},
  year={2017}
}

@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={MICCAI 2015},
  year={2015},
}

@inproceedings{chan2022efficient,
  title={Efficient geometry-aware 3D generative adversarial networks},
  author={Chan, Eric R and Lin, Connor Z and Chan, Matthew A and Nagano, Koki and Pan, Boxiao and De Mello, Shalini and Gallo, Orazio and Guibas, Leonidas J and Tremblay, Jonathan and Khamis, Sameh and others},
  booktitle={CVPR},
  year={2022}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv},
  year={2013}
}

@article{van2017neural,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={NeurIPS},
  year={2017}
}

@inproceedings{esser2021taming,
  title={Taming transformers for high-resolution image synthesis},
  author={Esser, Patrick and Rombach, Robin and Ommer, Bjorn},
  booktitle={CVPR},
  year={2021}
}

% text or image datasets
@misc{commoncrawl,
    howpublished="\url{https://commoncrawl.org/the-data/}"
}

@article{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  booktitle={NeurIPS},
  year={2022}
}

@article{schuhmann2021laion,
  title={Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
  author={Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  journal={arXiv},
  year={2021}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={ECCV},
  year={2014},
}

@article{krishna2017visual,
  title={Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  author={Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  journal={IJCV},
  year={2017},
}

@inproceedings{changpinyo2021conceptual,
  title={Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts},
  author={Changpinyo, Soravit and Sharma, Piyush and Ding, Nan and Soricut, Radu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3558--3568},
  year={2021}
}

@inproceedings{sharma2018conceptual,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={ACL},
  year={2018}
}

@misc{pinkney2022pokemon,
      author = {Pinkney, Justin N. M.},
      title = {Pokemon BLIP captions},
      year={2022},
      howpublished= {\url{https://huggingface.co/datasets/lambdalabs/pokemon-blip-captions/}}
} 

@article{gilardi2023chatgpt,
  title={Chatgpt outperforms crowd-workers for text-annotation tasks},
  author={Gilardi, Fabrizio and Alizadeh, Meysam and Kubli, Ma{\"e}l},
  journal={arXiv},
  year={2023}
}

@article{ordonez2011im2text,
  title={Im2text: Describing images using 1 million captioned photographs},
  author={Ordonez, Vicente and Kulkarni, Girish and Berg, Tamara},
  journal={NeurIPS},
  year={2011}
}

@article{desai2021redcaps,
  title={Redcaps: Web-curated image-text data created by the people, for the people},
  author={Desai, Karan and Kaul, Gaurav and Aysola, Zubin and Johnson, Justin},
  journal={NeurIPS},
  year={2021}
}

@article{kirillov2023segment,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  journal={arXiv},
  year={2023}
}

@inproceedings{agrawal2019nocaps,
  title={Nocaps: Novel object captioning at scale},
  author={Agrawal, Harsh and Desai, Karan and Wang, Yufei and Chen, Xinlei and Jain, Rishabh and Johnson, Mark and Batra, Dhruv and Parikh, Devi and Lee, Stefan and Anderson, Peter},
  booktitle={ICCV},
  year={2019}
}

@inproceedings{lu2018neural,
  title={Neural baby talk},
  author={Lu, Jiasen and Yang, Jianwei and Batra, Dhruv and Parikh, Devi},
  booktitle={CVPR},
  year={2018}
}

% captioning models
@article{li2023blip,
  title={Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  journal={arXiv},
  year={2023}
}

@article{gpt4,
  title={GPT-4 Technical Report},
  author={OpenAI},
  journal={arXiv},
  year={2023}
}

@inproceedings{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={ICML},
  year={2022},
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  year={2021},
}

@article{hessel2021clipscore,
  title={Clipscore: A reference-free evaluation metric for image captioning},
  author={Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Bras, Ronan Le and Choi, Yejin},
  journal={arXiv},
  year={2021}
}

@article{fang2022eva,
  title={Eva: Exploring the limits of masked visual representation learning at scale},
  author={Fang, Yuxin and Wang, Wen and Xie, Binhui and Sun, Quan and Wu, Ledell and Wang, Xinggang and Huang, Tiejun and Wang, Xinlong and Cao, Yue},
  journal={CVPR},
  year={2023}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={ICLR},
  year={2021}
}

@article{chung2022scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Eric and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={arXiv},
  year={2022}
}

@article{wang2021simvlm,
  title={Simvlm: Simple visual language model pretraining with weak supervision},
  author={Wang, Zirui and Yu, Jiahui and Yu, Adams Wei and Dai, Zihang and Tsvetkov, Yulia and Cao, Yuan},
  journal={ICLR},
  year={2022}
}

@inproceedings{li2020oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  booktitle={ECCV},
  year={2020},
}

@inproceedings{zhang2021vinvl,
  title={Vinvl: Revisiting visual representations in vision-language models},
  author={Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{lee2020vilbertscore,
  title={Vilbertscore: Evaluating image caption using vision-and-language bert},
  author={Lee, Hwanhee and Yoon, Seunghyun and Dernoncourt, Franck and Kim, Doo Soon and Bui, Trung and Jung, Kyomin},
  booktitle={Eval4NLP},
  year={2020}
}

@inproceedings{yu2018mattnet,
  title={Mattnet: Modular attention network for referring expression comprehension},
  author={Yu, Licheng and Lin, Zhe and Shen, Xiaohui and Yang, Jimei and Lu, Xin and Bansal, Mohit and Berg, Tamara L},
  booktitle={CVPR},
  year={2018}
}

@inproceedings{lee2018stacked,
  title={Stacked cross attention for image-text matching},
  author={Lee, Kuang-Huei and Chen, Xi and Hua, Gang and Hu, Houdong and He, Xiaodong},
  booktitle={ECCV},
  year={2018}
}

@inproceedings{desai2021virtex,
  title={Virtex: Learning visual representations from textual annotations},
  author={Desai, Karan and Johnson, Justin},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{kim2021vilt,
  title={Vilt: Vision-and-language transformer without convolution or region supervision},
  author={Kim, Wonjae and Son, Bokyung and Kim, Ildoo},
  booktitle={ICML},
  year={2021},
}

@article{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  journal={NeurIPS},
  year={2019}
}

@article{jiang2019tiger,
  title={Tiger: Text-to-image grounding for image caption evaluation},
  author={Jiang, Ming and Huang, Qiuyuan and Zhang, Lei and Wang, Xin and Zhang, Pengchuan and Gan, Zhe and Diesner, Jana and Gao, Jianfeng},
  journal={EMNLP},
  year={2019}
}

@article{madhyastha2019vifidel,
  title={VIFIDEL: Evaluating the visual fidelity of image descriptions},
  author={Madhyastha, Pranava and Wang, Josiah and Specia, Lucia},
  journal={ACL},
  year={2019}
}

@inproceedings{vedantam2015cider,
  title={Cider: Consensus-based image description evaluation},
  author={Vedantam, Ramakrishna and Lawrence Zitnick, C and Parikh, Devi},
  booktitle={CVPR},
  year={2015}
}

@inproceedings{anderson2016spice,
  title={Spice: Semantic propositional image caption evaluation},
  author={Anderson, Peter and Fernando, Basura and Johnson, Mark and Gould, Stephen},
  booktitle={ECCV},
  year={2016},
}

@inproceedings{vinyals2015,
  title={Show and tell: A neural image caption generator},
  author={Vinyals, Oriol and Toshev, Alexander and Bengio, Samy and Erhan, Dumitru},
  booktitle={ICML},
  year={2015},
}

@inproceedings{chen2021,
  title={Scan2cap: Context-aware dense captioning in rgb-d scans},
  author={Chen, Zhenyu and Gholami, Ali and Nie√üner, Matthias and Chang, Angel X.},
  booktitle={CVPR},
  year={2021},
}

@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  year={2014},
}

@inproceedings{karras2020analyzing,
  title={Analyzing and improving the image quality of stylegan},
  author={Karras, Tero and Laine, Samuli and Aittala, Miika and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  booktitle={CVPR},
  year={2020}
}

% text to image models
@article{zhang2023adding,
  title={Adding conditional control to text-to-image diffusion models},
  author={Zhang, Lvmin and Agrawala, Maneesh},
  journal={arXiv},
  year={2023}
}

@inproceedings{li2019object,
  title={Object-driven text-to-image synthesis via adversarial training},
  author={Li, Wenbo and Zhang, Pengchuan and Zhang, Lei and Huang, Qiuyuan and He, Xiaodong and Lyu, Siwei and Gao, Jianfeng},
  booktitle={CVPR},
  year={2019}
}

@inproceedings{xu2018attngan,
  title={Attngan: Fine-grained text to image generation with attentional generative adversarial networks},
  author={Xu, Tao and Zhang, Pengchuan and Huang, Qiuyuan and Zhang, Han and Gan, Zhe and Huang, Xiaolei and He, Xiaodong},
  booktitle={CVPR},
  year={2018}
}

@article{dhariwal2021diffusion,
  title={Diffusion models beat gans on image synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  journal={NeurIPS},
  year={2021}
}

@article{ho2022video,
  title={Video diffusion models},
  author={Ho, Jonathan and Salimans, Tim and Gritsenko, Alexey and Chan, William and Norouzi, Mohammad and Fleet, David J},
  journal={arXiv},
  year={2022}
}

@article{ho2022cascaded,
  title={Cascaded Diffusion Models for High Fidelity Image Generation.},
  author={Ho, Jonathan and Saharia, Chitwan and Chan, William and Fleet, David J and Norouzi, Mohammad and Salimans, Tim},
  journal={JMLR},
  year={2022}
}

@inproceedings{johnson2018image,
  title={Image generation from scene graphs},
  author={Johnson, Justin and Gupta, Agrim and Fei-Fei, Li},
  booktitle={CVPR},
  year={2018}
}

@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv},
  year={2022}
}

@article{nichol2021glide,
  title={Glide: Towards photorealistic image generation and editing with text-guided diffusion models},
  author={Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
  journal={CoRR},
  year={2021}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={CVPR},
  year={2022}
}

@article{saharia2022photorealistic,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{gafni2022make,
  title={Make-a-scene: Scene-based text-to-image generation with human priors},
  author={Gafni, Oran and Polyak, Adam and Ashual, Oron and Sheynin, Shelly and Parikh, Devi and Taigman, Yaniv},
  booktitle={ECCV},
  year={2022},
}

@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={ICML},
  year={2021},
}

@article{ding2021cogview,
  title={Cogview: Mastering text-to-image generation via transformers},
  author={Ding, Ming and Yang, Zhuoyi and Hong, Wenyi and Zheng, Wendi and Zhou, Chang and Yin, Da and Lin, Junyang and Zou, Xu and Shao, Zhou and Yang, Hongxia and others},
  journal={NeurIPS},
  year={2021}
}

@inproceedings{zhang2021cross,
  title={Cross-modal contrastive learning for text-to-image generation},
  author={Zhang, Han and Koh, Jing Yu and Baldridge, Jason and Lee, Honglak and Yang, Yinfei},
  booktitle={CVPR},
  year={2021}
}

% ethics

@article{birhane2021multimodal,
  title={Multimodal datasets: misogyny, pornography, and malignant stereotypes},
  author={Birhane, Abeba and Prabhu, Vinay Uday and Kahembwe, Emmanuel},
  journal={arXiv},
  year={2021}
}

@article{gebru2018datasheets,
  title={Datasheets for datasets},
  author={Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and Daum{\'e} III, Hal and Crawford, Kate},
  journal={arXiv preprint arXiv:1803.09010},
  year={2018}
}

@inproceedings{deng2020retinaface,
  title={Retinaface: Single-shot multi-level face localisation in the wild},
  author={Deng, Jiankang and Guo, Jia and Ververas, Evangelos and Kotsia, Irene and Zafeiriou, Stefanos},
  booktitle={CVPR},
  year={2020}
}

@inproceedings{szegedy2016rethinking,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={CVPR},
  year={2016}
}

@misc{laborde23,
  author = {Gant Laborde},
  title = {Deep nn for nsfw detection},
  howpublished = "\url{https://github.com/GantMan/nsfw_model}",
  note = "[Online; accessed 7-May-2023]"
}

@misc{dirty23,
  howpublished = "\url{https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words}",
  note = "[Online; accessed 7-May-2023]"
}

@misc{ssa,
  howpublished ="\url{https://www.ssa.gov/oact/babynames/decades/century.html}",
  note = "[Online; accessed 7-May-2023]"
}


% misc

@article{gao2022get3d,
  title={Get3d: A generative model of high quality 3d textured shapes learned from images},
  author={Gao, Jun and Shen, Tianchang and Wang, Zian and Chen, Wenzheng and Yin, Kangxue and Li, Daiqing and Litany, Or and Gojcic, Zan and Fidler, Sanja},
  journal={NeurIPS},
  year={2022}
}

@article{heusel2017gans,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal={NeurIPS},
  year={2017}
}

@inproceedings{dai2017scannet,
  title={Scannet: Richly-annotated 3d reconstructions of indoor scenes},
  author={Dai, Angela and Chang, Angel X and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\ss}ner, Matthias},
  booktitle={CVPR},
  year={2017}
}

@inproceedings{sun2018pix3d,
  title={Pix3d: Dataset and methods for single-image 3d shape modeling},
  author={Sun, Xingyuan and Wu, Jiajun and Zhang, Xiuming and Zhang, Zhoutong and Zhang, Chengkai and Xue, Tianfan and Tenenbaum, Joshua B and Freeman, William T},
  booktitle={CVPR},
  year={2018}
}

@inproceedings{singh2014bigbird,
  title={Bigbird: A large-scale 3d database of object instances},
  author={Singh, Arjun and Sha, James and Narayan, Karthik S and Achim, Tudor and Abbeel, Pieter},
  booktitle={ICRA},
  year={2014},
}

@inproceedings{han2020shapecaptioner,
  title={ShapeCaptioner: Generative caption network for 3D shapes by learning a mapping from parts detected in multiple views to sentences},
  author={Han, Zhizhong and Chen, Chao and Liu, Yu-Shen and Zwicker, Matthias},
  booktitle={ACM MM},
  year={2020}
}

@misc{hu2021lora,
    title={LoRA: Low-Rank Adaptation of Large Language Models},
    author={Hu, Edward and Shen, Yelong and Wallis, Phil and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Lu and Chen, Weizhu},
    year={2021},
    archivePrefix={arXiv},
}

@article{chen2023text2tex,
  title={Text2Tex: Text-driven Texture Synthesis via Diffusion Models},
  author={Chen, Dave Zhenyu and Siddiqui, Yawar and Lee, Hsin-Ying and Tulyakov, Sergey and Nie{\ss}ner, Matthias},
  journal={arXiv},
  year={2023}
}

@article{xue2022ulip,
  title={ULIP: Learning Unified Representation of Language, Image and Point Cloud for 3D Understanding},
  author={Xue, Le and Gao, Mingfei and Xing, Chen and Mart{\'\i}n-Mart{\'\i}n, Roberto and Wu, Jiajun and Xiong, Caiming and Xu, Ran and Niebles, Juan Carlos and Savarese, Silvio},
  journal={CVPR},
  year={2023}
}

@article{xue2023ulip,
  title={ULIP-2: Towards Scalable Multimodal Pre-training For 3D Understanding},
  author={Xue, Le and Yu, Ning and Zhang, Shu and Li, Junnan and Mart{\'\i}n-Mart{\'\i}n, Roberto and Wu, Jiajun and Xiong, Caiming and Xu, Ran and Niebles, Juan Carlos and Savarese, Silvio},
  journal={arXiv},
  year={2023}
}

@misc{kakaobrain2022karlo-v1-alpha,
  title         = {Karlo-v1.0.alpha on COYO-100M and CC15M},
  author        = {Donghoon Lee and Jiseob Kim and Jisu Choi and Jongmin Kim and Minwoo Byeon and Woonhyuk Baek and Saehoon Kim},
  year          = {2022},
  howpublished  = {\url{https://github.com/kakaobrain/karlo}},
}


@inproceedings{mildenhall2020nerf,
  title={NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis},
  author={Ben Mildenhall and Pratul P. Srinivasan and Matthew Tancik and Jonathan T. Barron and Ravi Ramamoorthi and Ren Ng},
  year={2020},
  booktitle={ECCV},
}

@misc{stable-dreamfusion,
    Author = {Jiaxiang Tang},
    Year = {2022},
    Note = {https://github.com/ashawkey/stable-dreamfusion},
    Title = {Stable-dreamfusion: Text-to-3D with Stable-diffusion}
}

@inproceedings{elbanani2023lgssl,
  title = {{Learning Visual Representations via Language-Guided Sampling}},
  author = {El Banani, Mohamed and Desai, Karan and Johnson, Justin},
  booktitle = {CVPR},
  year = {2023},
}

@inproceedings{mu2022slip,
  title={Slip: Self-supervision meets language-image pre-training},
  author={Mu, Norman and Kirillov, Alexander and Wagner, David and Xie, Saining},
  booktitle={ECCV},
  year={2022},
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={NeurIPS},
  year={2022}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  year={2016}
}

@inproceedings{NIPS2012_c399862d,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 year = {2012}
}


@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  year={1997},
}

@article{schuster1997bidirectional,
  title={Bidirectional recurrent neural networks},
  author={Schuster, Mike and Paliwal, Kuldip K},
  journal={transactions on Signal Processing},
  year={1997},
}

@inproceedings{anderson2018bottom,
  title={Bottom-up and top-down attention for image captioning and visual question answering},
  author={Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
  booktitle={CVPR},
  year={2018}
}

@inproceedings{rennie2017self,
  title={Self-critical sequence training for image captioning},
  author={Rennie, Steven J and Marcheret, Etienne and Mroueh, Youssef and Ross, Jerret and Goel, Vaibhava},
  booktitle={CVPR},
  year={2017}
}