\begin{thebibliography}{18}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Auer et~al.(2007)Auer, Ortner, and Szepesv{\'a}ri]{auer2007improved}
Peter Auer, Ronald Ortner, and Csaba Szepesv{\'a}ri.
\newblock Improved rates for the stochastic continuum-armed bandit problem.
\newblock In \emph{Conference on Learning Theory}, 2007.

\bibitem[Azar et~al.(2017)Azar, Osband, and Munos]{azar2017minimax}
Mohammad~Gheshlaghi Azar, Ian Osband, and R{\'e}mi Munos.
\newblock Minimax regret bounds for reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Bubeck et~al.(2011)Bubeck, Munos, Stoltz, and
  Szepesv{\'a}ri]{bubeck2011x}
S{\'e}bastien Bubeck, R{\'e}mi Munos, Gilles Stoltz, and Csaba Szepesv{\'a}ri.
\newblock X-armed bandits.
\newblock \emph{Journal of Machine Learning Research}, 2011.

\bibitem[Dann et~al.(2017)Dann, Lattimore, and Brunskill]{dann2017unifying}
Christoph Dann, Tor Lattimore, and Emma Brunskill.
\newblock Unifying pac and regret: Uniform {PAC} bounds for episodic
  reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Jin et~al.(2018)Jin, Allen-Zhu, Bubeck, and Jordan]{jin2018q}
Chi Jin, Zeyuan Allen-Zhu, Sebastien Bubeck, and Michael~I Jordan.
\newblock Is {Q}-learning provably efficient?
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Kakade et~al.(2003)Kakade, Kearns, and
  Langford]{kakade2003exploration}
Sham Kakade, Michael~J Kearns, and John Langford.
\newblock Exploration in metric state spaces.
\newblock In \emph{International Conference on Machine Learning}, 2003.

\bibitem[Kleinberg et~al.(2019)Kleinberg, Slivkins, and
  Upfal]{kleinberg2019bandits}
Robert Kleinberg, Aleksandrs Slivkins, and Eli Upfal.
\newblock Bandits and experts in metric spaces.
\newblock \emph{Journal of the ACM}, 2019.

\bibitem[Krishnamurthy et~al.(2019)Krishnamurthy, Langford, Slivkins, and
  Zhang]{krishnamurthy2019contextual}
Akshay Krishnamurthy, John Langford, Aleksandrs Slivkins, and Chicheng Zhang.
\newblock Contextual bandits with continuous actions: Smoothing, zooming, and
  adapting.
\newblock In \emph{Conference on Learning Theory}, 2019.

\bibitem[Ni et~al.(2019)Ni, Yang, and Wang]{yang2019learning}
Chengzhuo Ni, Lin~F Yang, and Mengdi Wang.
\newblock Learning to control in metric space with optimal regret.
\newblock In \emph{Allerton Conference on Communication, Control, and
  Computing}, 2019.

\bibitem[Ortner(2013)]{ortner2013adaptive}
Ronald Ortner.
\newblock Adaptive aggregation for reinforcement learning in average reward
  markov decision processes.
\newblock \emph{Annals of Operations Research}, 2013.

\bibitem[Ortner and Ryabko(2012)]{ortner2012online}
Ronald Ortner and Daniil Ryabko.
\newblock Online regret bounds for undiscounted continuous reinforcement
  learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2012.

\bibitem[Simchowitz and Jamieson(2019)]{simchowitz2019non}
Max Simchowitz and Kevin~G Jamieson.
\newblock Non-asymptotic gap-dependent regret bounds for tabular {MDP}s.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Sinclair et~al.(2019)Sinclair, Banerjee, and Yu]{sinclair2019adaptive}
Sean~R Sinclair, Siddhartha Banerjee, and Christina~Lee Yu.
\newblock Adaptive discretization for episodic reinforcement learning in metric
  spaces.
\newblock \emph{ACM Conference on Measurement and Analysis of Computing
  Systems}, 2019.

\bibitem[Slivkins(2014)]{slivkins2014contextual}
Aleksandrs Slivkins.
\newblock Contextual bandits with similarity information.
\newblock \emph{Journal of Machine Learning Research}, 2014.

\bibitem[Song and Sun(2019)]{song2019efficient}
Zhao Song and Wen Sun.
\newblock Efficient model-free reinforcement learning in metric spaces.
\newblock \emph{arXiv:1905.00475}, 2019.

\bibitem[Touati et~al.(2020)Touati, Taiga, and Bellemare]{touati2020zooming}
Ahmed Touati, Adrien~Ali Taiga, and Marc~G Bellemare.
\newblock Zooming for efficient model-free reinforcement learning in metric
  spaces.
\newblock \emph{arXiv:2003.04069}, 2020.

\bibitem[Valko et~al.(2013)Valko, Carpentier, and Munos]{valko2013stochastic}
Michal Valko, Alexandra Carpentier, and R{\'e}mi Munos.
\newblock Stochastic simultaneous optimistic optimization.
\newblock In \emph{International Conference on Machine Learning}, 2013.

\bibitem[Zanette and Brunskill(2019)]{zanette2019tighter}
Andrea Zanette and Emma Brunskill.
\newblock Tighter problem-dependent regret bounds in reinforcement learning
  without domain knowledge using value function bounds.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\end{thebibliography}
