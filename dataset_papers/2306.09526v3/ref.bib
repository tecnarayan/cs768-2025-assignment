@article{wang2021socially,
  title={Socially-compatible behavior design of autonomous vehicles with verification on real human data},
  author={Wang, Letian and Sun, Liting and Tomizuka, Masayoshi and Zhan, Wei},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  number={2},
  pages={3421--3428},
  year={2021},
  publisher={IEEE}
}

@inproceedings{sun2020game,
  title={A game-theoretic strategy-aware interaction algorithm with validation on real traffic data},
  author={Sun, Liting and Cai, Mu and Zhan, Wei and Tomizuka, Masayoshi},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={11038--11044},
  year={2020},
  organization={IEEE}
}

@article{li2022efficient,
  title={Efficient Game-Theoretic Planning With Prediction Heuristic for Socially-Compliant Autonomous Driving},
  author={Li, Chenran and Trinh, Tu and Wang, Letian and Liu, Changliu and Tomizuka, Masayoshi and Zhan, Wei},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={4},
  pages={10248--10255},
  year={2022},
  publisher={IEEE}
}

@article{tang2022interventional,
  title={Interventional Behavior Prediction: Avoiding Overly Confident Anticipation in Interactive Prediction},
  author={Tang, Chen and Zhan, Wei and Tomizuka, Masayoshi},
  journal={arXiv preprint arXiv:2204.08665},
  year={2022}
}

@article{xiao2019maximum,
  title={Maximum entropy monte-carlo planning},
  author={Xiao, Chenjun and Huang, Ruitong and Mei, Jincheng and Schuurmans, Dale and M{\"u}ller, Martin},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{haarnoja2017reinforcement,
  title={Reinforcement learning with deep energy-based policies},
  author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1352--1361},
  year={2017},
  organization={PMLR}
}

@inproceedings{ho2016generative,
  title={Generative adversarial imitation learning},
  author={Ho, Jonathan and Ermon, Stefano},
  booktitle={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{garg2021iq,
  title={Iq-learn: Inverse soft-q learning for imitation},
  author={Garg, Divyansh and Chakraborty, Shuvam and Cundy, Chris and Song, Jiaming and Ermon, Stefano},
  booktitle={Advances in Neural Information Processing Systems},
  volume={34},
  pages={4028--4039},
  year={2021}
}

@inproceedings{mandlekar2022matters,
  title={What Matters in Learning from Offline Human Demonstrations for Robot Manipulation},
  author={Mandlekar, Ajay and Xu, Danfei and Wong, Josiah and Nasiriany, Soroush and Wang, Chen and Kulkarni, Rohun and Fei-Fei, Li and Savarese, Silvio and Zhu, Yuke and Mart{\'\i}n-Mart{\'\i}n, Roberto},
  booktitle={Conference on Robot Learning},
  pages={1678--1690},
  year={2022},
  organization={PMLR}
}

@article{bhattacharyya2022modeling,
  title={Modeling human driving behavior through generative adversarial imitation learning},
  author={Bhattacharyya, Raunak and Wulfe, Blake and Phillips, Derek J and Kuefler, Alex and Morton, Jeremy and Senanayake, Ransalu and Kochenderfer, Mykel J},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  year={2022},
  publisher={IEEE}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@article{haarnoja2018soft2,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@article{stable-baselines3,
  author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},
  title   = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {268},
  pages   = {1-8},
  url     = {http://jmlr.org/papers/v22/20-1364.html}
}

@article{gleave2022imitation,
  title={imitation: Clean Imitation Learning Implementations},
  author={Gleave, Adam and Taufeeque, Mohammad and Rocamonde, Juan and Jenner, Erik and Wang, Steven H and Toyer, Sam and Ernestus, Maximilian and Belrose, Nora and Emmons, Scott and Russell, Stuart},
  journal={arXiv preprint arXiv:2211.11972},
  year={2022}
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@article{highway-env,
  author = {Leurent, Edouard},
  title = {An Environment for Autonomous Driving Decision-Making},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/eleurent/highway-env}},
}

@inproceedings{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International conference on machine learning},
  pages={1587--1596},
  year={2018},
  organization={PMLR}
}

@inproceedings{ettinger2021large,
  title={Large scale interactive motion forecasting for autonomous driving: The waymo open motion dataset},
  author={Ettinger, Scott and Cheng, Shuyang and Caine, Benjamin and Liu, Chenxi and Zhao, Hang and Pradhan, Sabeek and Chai, Yuning and Sapp, Ben and Qi, Charles R and Zhou, Yin and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9710--9719},
  year={2021}
}

@article{zhan2019interaction,
  title={Interaction dataset: An international, adversarial and cooperative motion dataset in interactive driving scenarios with semantic maps},
  author={Zhan, Wei and Sun, Liting and Wang, Di and Shi, Haojie and Clausse, Aubrey and Naumann, Maximilian and Kummerle, Julius and Konigshof, Hendrik and Stiller, Christoph and de La Fortelle, Arnaud and others},
  journal={arXiv preprint arXiv:1910.03088},
  year={2019}
}

@article{wilson2023argoverse,
  title={Argoverse 2: Next generation datasets for self-driving perception and forecasting},
  author={Wilson, Benjamin and Qi, William and Agarwal, Tanmay and Lambert, John and Singh, Jagjeet and Khandelwal, Siddhesh and Pan, Bowen and Kumar, Ratnesh and Hartnett, Andrew and Pontes, Jhony Kaesemodel and others},
  journal={arXiv preprint arXiv:2301.00493},
  year={2023}
}

@INPROCEEDINGS{bansal2018chauffeurnet, 
    AUTHOR    = {Mayank Bansal AND Alex Krizhevsky AND Abhijit Ogale}, 
    TITLE     = {ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst}, 
    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, 
    YEAR      = {2019}, 
    ADDRESS   = {FreiburgimBreisgau, Germany}, 
    MONTH     = {June}, 
    DOI       = {10.15607/RSS.2019.XV.031} 
} 
  

@inproceedings{scheel2022urban,
  title={Urban driver: Learning to drive from real-world demonstrations using policy gradients},
  author={Scheel, Oliver and Bergamini, Luca and Wolczyk, Maciej and Osi{\'n}ski, B{\l}a{\.z}ej and Ondruska, Peter},
  booktitle={Conference on Robot Learning},
  pages={718--728},
  year={2022},
  organization={PMLR}
}

@inproceedings{espinoza2022deep,
  title={Deep interactive motion prediction and planning: Playing games with motion prediction models},
  author={Espinoza, Jose Luis Vazquez and Liniger, Alexander and Schwarting, Wilko and Rus, Daniela and Van Gool, Luc},
  booktitle={Learning for Dynamics and Control Conference},
  pages={1006--1019},
  year={2022},
  organization={PMLR}
}

@inproceedings{coulom2007efficient,
  title={Efficient selectivity and backup operators in Monte-Carlo tree search},
  author={Coulom, R{\'e}mi},
  booktitle={Computers and Games: 5th International Conference, CG 2006, Turin, Italy, May 29-31, 2006. Revised Papers 5},
  pages={72--83},
  year={2007},
  organization={Springer}
}

@inproceedings{bhattacharyya2019simulating,
  title={Simulating emergent properties of human driving behavior using multi-agent reward augmented imitation learning},
  author={Bhattacharyya, Raunak P and Phillips, Derek J and Liu, Changliu and Gupta, Jayesh K and Driggs-Campbell, Katherine and Kochenderfer, Mykel J},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={789--795},
  year={2019},
  organization={IEEE}
}

@article{li2017infogail,
  title={Infogail: Interpretable imitation learning from visual demonstrations},
  author={Li, Yunzhu and Song, Jiaming and Ermon, Stefano},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{lu2022imitation,
  title={Imitation Is Not Enough: Robustifying Imitation with Reinforcement Learning for Challenging Driving Scenarios},
  author={Lu, Yiren and Fu, Justin and Tucker, George and Pan, Xinlei and Bronstein, Eli and Roelofs, Becca and Sapp, Benjamin and White, Brandyn and Faust, Aleksandra and Whiteson, Shimon and others},
  journal={arXiv preprint arXiv:2212.11419},
  year={2022}
}

@inproceedings{judah2014imitation,
  title={Imitation learning with demonstrations and shaping rewards},
  author={Judah, Kshitij and Fern, Alan and Tadepalli, Prasad and Goetschalckx, Robby},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={28},
  year={2014}
}

@article{fujimoto2021minimalist,
  title={A minimalist approach to offline reinforcement learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={20132--20145},
  year={2021}
}

@article{kumar2020conservative,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}

@inproceedings{rhinehartdeep,
    title={Deep Imitative Models for Flexible Inference, Planning, and Control},
    author={Nicholas Rhinehart and Rowan McAllister and Sergey Levine},
    booktitle={International Conference on Learning Representations},
    year={2020},
    url={https://openreview.net/forum?id=Skl4mRNYDr}
}

@article{englert2017inverse,
  title={Inverse KKT: Learning cost functions of manipulation tasks from demonstrations},
  author={Englert, Peter and Vien, Ngo Anh and Toussaint, Marc},
  journal={The International Journal of Robotics Research},
  volume={36},
  number={13-14},
  pages={1474--1488},
  year={2017},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{hester2018deep,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  year={2018}
}

@article{vecerik2017leveraging,
  title={Leveraging demonstrations for deep reinforcement learning on robotics problems with sparse rewards},
  author={Vecerik, Mel and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1707.08817},
  year={2017}
}

@article{rajeswaran2017learning,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.10087},
  year={2017}
}

@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}

@inproceedings{51579,
title	= {Jump-Start Reinforcement Learning},
author	= {Ike Uchendu and Ted Xiao and Yao Lu and Banghua Zhu and Mengyuan Yan and Joséphine Simon and Matt Bennice and Chuyuan Kelly Fu and Cong Ma and Jiantao Jiao and Sergey Levine and Karol Hausman},
year	= {2022},
booktitle	= {NeurIPS 2021 Robot Learning Workshop, RSS 2022 Scaling Robot Learning Workshop}
}

@article{nair2020awac,
  title={Awac: Accelerating online reinforcement learning with offline datasets},
  author={Nair, Ashvin and Gupta, Abhishek and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.09359},
  year={2020}
}

@article{bojarski2016end,
  title={End to end learning for self-driving cars},
  author={Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and others},
  journal={arXiv preprint arXiv:1604.07316},
  year={2016}
}

@inproceedings{codevilla2018end,
  title={End-to-end driving via conditional imitation learning},
  author={Codevilla, Felipe and M{\"u}ller, Matthias and L{\'o}pez, Antonio and Koltun, Vladlen and Dosovitskiy, Alexey},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={4693--4700},
  year={2018},
  organization={IEEE}
}

@inproceedings{zhang2018deep,
  title={Deep imitation learning for complex manipulation tasks from virtual reality teleoperation},
  author={Zhang, Tianhao and McCarthy, Zoe and Jow, Owen and Lee, Dennis and Chen, Xi and Goldberg, Ken and Abbeel, Pieter},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={5628--5635},
  year={2018},
  organization={IEEE}
}

@article{mandlekar2020learning,
  title={Learning to generalize across long-horizon tasks from human demonstrations},
  author={Mandlekar, Ajay and Xu, Danfei and Mart{\'\i}n-Mart{\'\i}n, Roberto and Savarese, Silvio and Fei-Fei, Li},
  journal={arXiv preprint arXiv:2003.06085},
  year={2020}
}

@inproceedings{li2022dealing,
  title={Dealing with the unknown: Pessimistic offline reinforcement learning},
  author={Li, Jinning and Tang, Chen and Tomizuka, Masayoshi and Zhan, Wei},
  booktitle={Conference on Robot Learning},
  pages={1455--1464},
  year={2022},
  organization={PMLR}
}

@article{kostrikov2021offline,
  title={Offline reinforcement learning with implicit q-learning},
  author={Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.06169},
  year={2021}
}

@article{rl-zoo3,
  author = {Raffin, Antonin},
  title = {RL Baselines3 Zoo},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/DLR-RM/rl-baselines3-zoo}},
}

@article{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{wu2019behavior,
  title={Behavior regularized offline reinforcement learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@inproceedings{juozapaitis2019explainable,
  title={Explainable reinforcement learning via reward decomposition},
  author={Juozapaitis, Zoe and Koul, Anurag and Fern, Alan and Erwig, Martin and Doshi-Velez, Finale},
  booktitle={IJCAI/ECAI Workshop on explainable artificial intelligence},
  year={2019}
}

@article{van2017hybrid,
  title={Hybrid reward architecture for reinforcement learning},
  author={Van Seijen, Harm and Fatemi, Mehdi and Romoff, Joshua and Laroche, Romain and Barnes, Tavian and Tsang, Jeffrey},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{singh2020parrot,
  title={Parrot: Data-driven behavioral priors for reinforcement learning},
  author={Singh, Avi and Liu, Huihan and Zhou, Gaoyue and Yu, Albert and Rhinehart, Nicholas and Levine, Sergey},
  journal={arXiv preprint arXiv:2011.10024},
  year={2020}
}

@article{chi2023diffusion,
  title={Diffusion Policy: Visuomotor Policy Learning via Action Diffusion},
  author={Chi, Cheng and Feng, Siyuan and Du, Yilun and Xu, Zhenjia and Cousineau, Eric and Burchfiel, Benjamin and Song, Shuran},
  journal={arXiv preprint arXiv:2303.04137},
  year={2023}
}

@article{janner2022planning,
  title={Planning with diffusion for flexible behavior synthesis},
  author={Janner, Michael and Du, Yilun and Tenenbaum, Joshua B and Levine, Sergey},
  journal={arXiv preprint arXiv:2205.09991},
  year={2022}
}

@article{hansen2023idql,
  title={IDQL: Implicit Q-Learning as an Actor-Critic Method with Diffusion Policies},
  author={Hansen-Estruch, Philippe and Kostrikov, Ilya and Janner, Michael and Kuba, Jakub Grudzien and Levine, Sergey},
  journal={arXiv preprint arXiv:2304.10573},
  year={2023}
}

@article{schrittwieser2020mastering,
  title={Mastering atari, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={Nature},
  volume={588},
  number={7839},
  pages={604--609},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@article{ye2021mastering,
  title={Mastering atari games with limited data},
  author={Ye, Weirui and Liu, Shaohuai and Kurutach, Thanard and Abbeel, Pieter and Gao, Yang},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={25476--25488},
  year={2021}
}

@inproceedings{ziebart2008maximum,
  title={Maximum entropy inverse reinforcement learning.},
  author={Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K and others},
  booktitle={Aaai},
  volume={8},
  pages={1433--1438},
  year={2008},
  organization={Chicago, IL, USA}
}

@article{fu2017learning,
  title={Learning robust rewards with adversarial inverse reinforcement learning},
  author={Fu, Justin and Luo, Katie and Levine, Sergey},
  journal={arXiv preprint arXiv:1710.11248},
  year={2017}
}

@INPROCEEDINGS{6386109,
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={MuJoCo: A physics engine for model-based control}, 
  year={2012},
  volume={},
  number={},
  pages={5026-5033},
  doi={10.1109/IROS.2012.6386109}}

@inproceedings{kelly2019hg,
  title={Hg-dagger: Interactive imitation learning with human experts},
  author={Kelly, Michael and Sidrane, Chelsea and Driggs-Campbell, Katherine and Kochenderfer, Mykel J},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={8077--8083},
  year={2019},
  organization={IEEE}
}

@article{mandlekar2020human,
  title={Human-in-the-loop imitation learning using remote teleoperation},
  author={Mandlekar, Ajay and Xu, Danfei and Mart{\'\i}n-Mart{\'\i}n, Roberto and Zhu, Yuke and Fei-Fei, Li and Savarese, Silvio},
  journal={arXiv preprint arXiv:2012.06733},
  year={2020}
}

@article{xue2023guarded,
  title={Guarded Policy Optimization with Imperfect Online Demonstrations},
  author={Xue, Zhenghai and Peng, Zhenghao and Li, Quanyi and Liu, Zhihan and Zhou, Bolei},
  journal={arXiv preprint arXiv:2303.01728},
  year={2023}
}

@inproceedings{peng2022safe,
  title={Safe driving via expert guided policy optimization},
  author={Peng, Zhenghao and Li, Quanyi and Liu, Chunxiao and Zhou, Bolei},
  booktitle={Conference on Robot Learning},
  pages={1554--1563},
  year={2022},
  organization={PMLR}
}

@inproceedings{xue2022guarded,
  title={Guarded Policy Optimization with Imperfect Online Demonstrations},
  author={Xue, Zhenghai and Peng, Zhenghao and Li, Quanyi and Liu, Zhihan and Zhou, Bolei},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@inproceedings{klink2021boosted,
  title={Boosted curriculum reinforcement learning},
  author={Klink, Pascal and D'Eramo, Carlo and Peters, Jan and Pajarinen, Joni},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{jauhri2022robot,
  title={Robot learning of mobile manipulation with reachability behavior priors},
  author={Jauhri, Snehal and Peters, Jan and Chalvatzaki, Georgia},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={3},
  pages={8399--8406},
  year={2022},
  publisher={IEEE}
}

@inproceedings{tosatto2017boosted,
  title={Boosted fitted q-iteration},
  author={Tosatto, Samuele and Pirotta, Matteo and d’Eramo, Carlo and Restelli, Marcello},
  booktitle={International Conference on Machine Learning},
  pages={3434--3443},
  year={2017},
  organization={PMLR}
}