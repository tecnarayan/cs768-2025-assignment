\begin{thebibliography}{}

\bibitem[Alabi et~al., 2018]{Alabi+18}
Alabi, D., Immorlica, N., and Kalai, A. (2018).
\newblock Unleashing linear optimizers for group-fair learning and
  optimization.
\newblock In {\em {COLT}}.

\bibitem[Angwin et~al., 2016]{Angwin+16}
Angwin, J., Larson, J., Mattu, S., and Kirchner, L. (2016).
\newblock Machine bias.
\newblock {\em ProPublica, May}, 23.

\bibitem[Berahas et~al., 2019]{Berahas19}
Berahas, A.~S., Cao, L., Choromanski, K., and Scheinberg, K. (2019).
\newblock A theoretical and empirical comparison of gradient approximations in
  derivative-free optimization.
\newblock {\em arXiv preprint arXiv:1905.01332}.

\bibitem[Blake and Merz, 1998]{uci}
Blake, C. and Merz, C.~J. (1998).
\newblock {UCI} repository of machine learning databases.

\bibitem[Conn et~al., 2008]{Conn08}
Conn, A.~R., Scheinberg, K., and Vicente, L.~N. (2008).
\newblock Geometry of interpolation sets in derivative free optimization.
\newblock {\em Mathematical programming}, 111(1-2):141--172.

\bibitem[Conn et~al., 2009]{Conn09}
Conn, A.~R., Scheinberg, K., and Vicente, L.~N. (2009).
\newblock {\em Introduction to derivative-free optimization}, volume~8.
\newblock Siam.

\bibitem[Daskalaki et~al., 2006]{Daskalaki+06}
Daskalaki, S., Kopanas, I., and Avouris, N. (2006).
\newblock Evaluation of classifiers for an uneven class distribution problem.
\newblock {\em Applied Artificial Intelligence}, 20:381--417.

\bibitem[{Duchi} et~al., 2015]{Duchi}
{Duchi}, J.~C., {Jordan}, M.~I., {Wainwright}, M.~J., and {Wibisono}, A.
  (2015).
\newblock Optimal rates for zero-order convex optimization: The power of two
  function evaluations.
\newblock {\em IEEE Transactions on Information Theory}, 61(5):2788--2806.

\bibitem[Eban et~al., 2017]{Eban+17}
Eban, E., Schain, M., Mackey, A., Gordon, A., Saurous, R.~A., and Elidan, G.
  (2017).
\newblock Scalable learning of non-decomposable objectives.
\newblock In {\em AISTATS}.

\bibitem[Garmanjani and Vicente, 2013]{Garmanjani+13}
Garmanjani, R. and Vicente, L.~N. (2013).
\newblock Smoothing and worst-case complexity for direct-search methods in
  nonsmooth optimization.
\newblock {\em IMA Journal of Numerical Analysis}, 33(3):1008--1028.

\bibitem[Ghadimi et~al., 2016]{Ghadimi2016}
Ghadimi, S., Lan, G., and Zhang, H. (2016).
\newblock Mini-batch stochastic approximation methods for nonconvex stochastic
  composite optimization.
\newblock {\em Mathematical Programming}, 155(1):267--305.

\bibitem[Grabocka et~al., 2019]{Grabocka+19}
Grabocka, J., Scholz, R., and Schmidt-Thieme, L. (2019).
\newblock Learning surrogate losses.
\newblock {\em arXiv preprint arXiv:1905.10108}.

\bibitem[Huang et~al., 2019]{Huang+19}
Huang, C., Zhai, S., Talbott, W., Bautista, M.~A., Sun, S.-Y., Guestrin, C.,
  and Susskind, J. (2019).
\newblock Addressing the loss-metric mismatch with adaptive loss alignment.
\newblock In {\em ICML}.

\bibitem[{Jin} et~al., 2019]{Jin}
{Jin}, C., {Netrapalli}, P., {Ge}, R., {Kakade}, S.~M., and {Jordan}, M.~I.
  (2019).
\newblock A short note on concentration inequalities for random vectors with
  subgaussian norm.
\newblock {\em arXiv preprint arXiv:1902.03736}.

\bibitem[Joachims, 2005]{Joachims05}
Joachims, T. (2005).
\newblock A support vector method for multivariate performance measures.
\newblock In {\em ICML}.

\bibitem[Joachims et~al., 2005]{Joachims:2005}
Joachims, T., Granka, L., Pan, B., Hembrooke, H., and Gay, G. (2005).
\newblock Accurately interpreting clickthrough data as implicit feedback.
\newblock {\em Proc. SIGIR}.

\bibitem[Kar et~al., 2016]{Kar+16}
Kar, P., Li, S., Narasimhan, H., Chawla, S., and Sebastiani, F. (2016).
\newblock Online optimization methods for the quantification problem.
\newblock In {\em KDD}.

\bibitem[Kar et~al., 2014]{Kar+14}
Kar, P., Narasimhan, H., and Jain, P. (2014).
\newblock Online and stochastic gradient methods for non-decomposable loss
  functions.
\newblock In {\em NIPS}.

\bibitem[Kar et~al., 2015]{Kar+15}
Kar, P., Narasimhan, H., and Jain, P. (2015).
\newblock Surrogate functions for maximizing precision at the top.
\newblock In {\em ICML}.

\bibitem[Koyejo et~al., 2014]{Koyejo+14}
Koyejo, O., Natarajan, N., Ravikumar, P., and Dhillon, I. (2014).
\newblock Consistent binary classification with generalized performance
  metrics.
\newblock In {\em NIPS}.

\bibitem[Mackey et~al., 2018]{Mackey+18}
Mackey, A., Luo, X., and Eban, E. (2018).
\newblock Constrained classification and ranking via quantiles.
\newblock {\em arXiv preprint arXiv:1803.00067}.

\bibitem[Narasimhan, 2018]{Narasimhan18}
Narasimhan, H. (2018).
\newblock Learning with complex loss functions and constraints.
\newblock In {\em {AISTATS}}.

\bibitem[Narasimhan et~al., 2019]{Narasimhan+19}
Narasimhan, H., Cotter, A., and Gupta, M. (2019).
\newblock Optimizing generalized rate metrics through game equilibrium.
\newblock In {\em NeurIPS}.

\bibitem[Narasimhan et~al., 2015a]{Narasimhan+15b}
Narasimhan, H., Kar, P., and Jain, P. (2015a).
\newblock Optimizing non-decomposable performance measures: {A} tale of two
  classes.
\newblock In {\em ICML}.

\bibitem[Narasimhan et~al., 2015b]{Narasimhan+15}
Narasimhan, H., Ramaswamy, H., Saha, A., and Agarwal, S. (2015b).
\newblock Consistent multiclass algorithms for complex performance measures.
\newblock In {\em ICML}.

\bibitem[Narasimhan et~al., 2014]{Narasimhan+14}
Narasimhan, H., Vaish, R., and Agarwal, S. (2014).
\newblock On the statistical consistency of plug-in classifiers for
  non-decomposable performance measures.
\newblock In {\em NIPS}.

\bibitem[Nesterov and Spokoiny, 2017]{Nesterov+17}
Nesterov, Y. and Spokoiny, V. (2017).
\newblock Random gradient-free minimization of convex functions.
\newblock {\em Found. Comput. Math.}, 17(2):527--566.

\bibitem[Parambath et~al., 2014]{Parambath+14}
Parambath, S., Usunier, N., and Grandvalet, Y. (2014).
\newblock Optimizing {F}-measures by cost-sensitive classification.
\newblock In {\em NIPS}.

\bibitem[Rao et~al., 2008]{Rao+08}
Rao, R.~B., Yakhnenko, O., and Krishnapuram, B. (2008).
\newblock Kdd cup 2008 and the workshop on mining medical data.
\newblock {\em ACM SIGKDD Explorations Newsletter}, 10(2):34--38.

\bibitem[Ren et~al., 2018]{Ren+18}
Ren, M., Zeng, W., Yang, B., and Urtasun, R. (2018).
\newblock Learning to reweight examples for robust deep learning.
\newblock In {\em ICML}.

\bibitem[Tropp, 2015]{Tropp_2015}
Tropp, J.~A. (2015).
\newblock An introduction to matrix concentration inequalities.
\newblock {\em Found. Trends Mach. Learn.}, 8(1-2):1--230.

\bibitem[Wainwright, 2019]{Wainwright19}
Wainwright, M.~J. (2019).
\newblock {\em High-dimensional statistics: A non-asymptotic viewpoint},
  volume~48.
\newblock Cambridge University Press.

\bibitem[Wu et~al., 2018]{Wu+18}
Wu, L., Tian, F., Xia, Y., Fan, Y., Qin, T., Jian-Huang, L., and Liu, T.-Y.
  (2018).
\newblock Learning to teach with dynamic loss functions.
\newblock In {\em NeurIPS}, pages 6466--6477.

\bibitem[Yan et~al., 2018]{Yan+18}
Yan, B., Koyejo, O., Zhong, K., and Ravikumar, P. (2018).
\newblock Binary classification with karmic, threshold-quasi-concave metrics.
\newblock In {\em {ICML}}.

\bibitem[Ye et~al., 2012]{Ye+12}
Ye, N., Chai, K., Lee, W., and Chieu, H. (2012).
\newblock Optimizing {F}-measures: {A} tale of two approaches.
\newblock In {\em ICML}.

\bibitem[Zhao et~al., 2019]{Zhao+19}
Zhao, S., {Milani Fard}, M., Narasimhan, H., and Gupta, M.~R. (2019).
\newblock Metric-optimized example weights.
\newblock In {\em ICML}.

\end{thebibliography}
