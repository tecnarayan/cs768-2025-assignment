\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Adebayo et~al.(2018)Adebayo, Gilmer, Muelly, Goodfellow, Hardt, and
  Kim]{adebayo2018sanity}
Julius Adebayo, Justin Gilmer, Michael Muelly, Ian Goodfellow, Moritz Hardt,
  and Been Kim.
\newblock Sanity checks for saliency maps, 2018.

\bibitem[Alvarez~Melis and Jaakkola(2018)]{NIPS2018_8003}
David Alvarez~Melis and Tommi Jaakkola.
\newblock Towards robust interpretability with self-explaining neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems 31}. 2018.

\bibitem[Alvarez-Melis and Jaakkola(2018)]{alvarezmelis2018robustness}
David Alvarez-Melis and Tommi~S. Jaakkola.
\newblock On the robustness of interpretability methods, 2018.

\bibitem[Angelos et~al.(1986)Angelos, Henry, Kaufman, Lenker, and
  Kroó]{ANGELOS1986137}
James~R Angelos, Myron~S Henry, Edwin~H Kaufman, Terry~D Lenker, and András
  Kroó.
\newblock Local and global lipschitz constants.
\newblock \emph{Journal of Approximation Theory}, 46\penalty0 (2):\penalty0 137
  -- 156, 1986.

\bibitem[Arcadu et~al.(2019)Arcadu, Benmansour, Maunz, Willis, Haskova, and
  Prunotto]{Arcadu19diabetic}
Filippo Arcadu, Fethallah Benmansour, Andreas Maunz, Jeff Willis, Zdenka
  Haskova, and Marco Prunotto.
\newblock Deep learning algorithm predicts diabetic retinopathy progression in
  individual patients.
\newblock \emph{npj Digital Medicine}, 2019.

\bibitem[Binder et~al.(2016)Binder, Montavon, Bach, Müller, and
  Samek]{alex2016layerwise}
Alexander Binder, Grégoire Montavon, Sebastian Bach, Klaus-Robert Müller, and
  Wojciech Samek.
\newblock Layer-wise relevance propagation for neural networks with local
  renormalization layers, 2016.

\bibitem[Bracewell(1978)]{bracewell1978fourier}
R.N. Bracewell.
\newblock \emph{The Fourier Transform and its Applications}.
\newblock McGraw-Hill Kogakusha, Ltd., Tokyo, second edition, 1978.

\bibitem[Chen et~al.(2019)Chen, Wu, Rastogi, Liang, and Jha]{chen2019robust}
Jiefeng Chen, Xi~Wu, Vaibhav Rastogi, Yingyu Liang, and Somesh Jha.
\newblock Robust attribution regularization.
\newblock In \emph{Advances in Neural Information Processing Systems 32}. 2019.

\bibitem[{Choi} et~al.(2014){Choi}, {Cho}, {Kwac}, and {Davis}]{6977470}
J.~{Choi}, H.~{Cho}, J.~{Kwac}, and L.~S. {Davis}.
\newblock Toward sparse coding on cosine distance.
\newblock In \emph{2014 22nd International Conference on Pattern Recognition},
  2014.

\bibitem[Croce et~al.(2019)Croce, Andriushchenko, and Hein]{pmlr-v89-croce19a}
Francesco Croce, Maksym Andriushchenko, and Matthias Hein.
\newblock Provable robustness of relu networks via maximization of linear
  regions.
\newblock Proceedings of Machine Learning Research. PMLR, 2019.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{imagenet_cvpr09}
J.~Deng, W.~Dong, R.~Socher, L.-J. Li, K.~Li, and L.~Fei-Fei.
\newblock {ImageNet: A Large-Scale Hierarchical Image Database}.
\newblock In \emph{CVPR09}, 2009.

\bibitem[Dombrowski et~al.(2019)Dombrowski, Alber, Anders, Ackermann,
  M\"{u}ller, and Kessel]{dombrowski2019explanations}
Ann-Kathrin Dombrowski, Maximillian Alber, Christopher Anders, Marcel
  Ackermann, Klaus-Robert M\"{u}ller, and Pan Kessel.
\newblock Explanations can be manipulated and geometry is to blame.
\newblock In \emph{Advances in Neural Information Processing Systems 32}. 2019.

\bibitem[Etmann et~al.(2019)Etmann, Lunz, Maass, and
  Schönlieb]{etmann2019connection}
Christian Etmann, Sebastian Lunz, Peter Maass, and Carola-Bibiane Schönlieb.
\newblock On the connection between adversarial robustness and saliency map
  interpretability, 2019.

\bibitem[Ghorbani et~al.(2017)Ghorbani, Abid, and
  Zou]{Ghorbani2017InterpretationON}
Amirata Ghorbani, Abubakar Abid, and James~Y. Zou.
\newblock Interpretation of neural networks is fragile.
\newblock In \emph{31st AAAI Conference on Artificial Intelligence (AAAI)},
  2017.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Ian Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Heo et~al.(2019)Heo, Joo, and Moon]{NIPS2019_8558}
Juyeon Heo, Sunghwan Joo, and Taesup Moon.
\newblock Fooling neural network interpretations via adversarial model
  manipulation.
\newblock In \emph{Advances in Neural Information Processing Systems 32}. 2019.

\bibitem[Herrmann(1976)]{Herrmann1976LaplacianIsoparametricGG}
Leonard~R. Herrmann.
\newblock Laplacian-isoparametric grid generation scheme.
\newblock \emph{Journal of the Engineering Mechanics Division}, 102:\penalty0
  749--907, 1976.

\bibitem[Jordan et~al.(2019)Jordan, Lewis, and Dimakis]{NIPS2019_9555}
Matt Jordan, Justin Lewis, and Alexandros~G Dimakis.
\newblock Provable certificates for adversarial examples: Fitting a ball in the
  union of polytopes.
\newblock In \emph{Advances in Neural Information Processing Systems 32}. 2019.

\bibitem[Kindermans et~al.(2017)Kindermans, Hooker, Adebayo, Alber, Schütt,
  Dähne, Erhan, and Kim]{kindermans2017unreliability}
Pieter-Jan Kindermans, Sara Hooker, Julius Adebayo, Maximilian Alber,
  Kristof~T. Schütt, Sven Dähne, Dumitru Erhan, and Been Kim.
\newblock The (un)reliability of saliency methods, 2017.

\bibitem[Kokhlikyan et~al.(2019)Kokhlikyan, Miglani, Martin, Wang, Reynolds,
  Melnikov, Lunova, and Reblitz-Richardson]{captum2019github}
Narine Kokhlikyan, Vivek Miglani, Miguel Martin, Edward Wang, Jonathan
  Reynolds, Alexander Melnikov, Natalia Lunova, and Orion Reblitz-Richardson.
\newblock Pytorch captum.
\newblock \url{https://github.com/pytorch/captum}, 2019.

\bibitem[Krizhevsky(2012)]{cifar}
Alex Krizhevsky.
\newblock Learning multiple layers of features from tiny images.
\newblock \emph{University of Toronto}, 05 2012.

\bibitem[{Leino} et~al.(2018){Leino}, {Sen}, {Datta}, {Fredrikson}, and
  {Li}]{leino2018influencedirected}
K.~{Leino}, S.~{Sen}, A.~{Datta}, M.~{Fredrikson}, and L.~{Li}.
\newblock Influence-directed explanations for deep convolutional networks.
\newblock In \emph{2018 IEEE International Test Conference (ITC)}, 2018.

\bibitem[Leslie(2019)]{david2018safety}
David Leslie.
\newblock {Understanding artificial intelligence ethics and safety: A guide for
  the responsible design and implementation of AI systems in the public
  sector}, June 2019.
\newblock URL \url{https://doi.org/10.5281/zenodo.3240529}.

\bibitem[Levine et~al.(2019)Levine, Singla, and Feizi]{alex2019certifiably}
Alexander Levine, Sahil Singla, and Soheil Feizi.
\newblock Certifiably robust interpretation in deep learning, 2019.

\bibitem[Lin et~al.(2019)Lin, Khan, and Schmidt]{lin2019steins}
Wu~Lin, Mohammad~Emtiyaz Khan, and Mark Schmidt.
\newblock Stein's lemma for the reparameterization trick with exponential
  family mixtures, 2019.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{aleks2017deep}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Mamaev(2018)]{mamaev_2018}
Alexander Mamaev.
\newblock Flowers recognition, Jun 2018.
\newblock URL \url{https://www.kaggle.com/alxmamaev/flowers-recognition}.

\bibitem[Moosavi-Dezfooli et~al.(2019)Moosavi-Dezfooli, Fawzi, Uesato, and
  Frossard]{MoosaviDezfooli2019RobustnessVC}
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Jonathan Uesato, and
  P.~Frossard.
\newblock Robustness via curvature regularization, and vice versa.
\newblock \emph{2019 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 2019.

\bibitem[Noack et~al.(2019)Noack, Ahern, Dou, and Li]{noack2019does}
Adam Noack, Isaac Ahern, Dejing Dou, and Boyang Li.
\newblock Does interpretability of neural networks imply adversarial
  robustness?, 2019.

\bibitem[Omeiza et~al.(2019)Omeiza, Speakman, Cintas, and
  Weldemariam]{Omeiza2019SmoothGA}
Daniel Omeiza, Skyler Speakman, Celia Cintas, and Komminist Weldemariam.
\newblock Smooth grad-cam++: An enhanced inference level visualization
  technique for deep convolutional neural network models.
\newblock \emph{ArXiv}, abs/1908.01224, 2019.

\bibitem[Papernot et~al.(2018)Papernot, Faghri, Carlini, Goodfellow, Feinman,
  Kurakin, Xie, Sharma, Brown, Roy, Matyasko, Behzadan, Hambardzumyan, Zhang,
  Juang, Li, Sheatsley, Garg, Uesato, Gierke, Dong, Berthelot, Hendricks,
  Rauber, and Long]{papernot2018cleverhans}
Nicolas Papernot, Fartash Faghri, Nicholas Carlini, Ian Goodfellow, Reuben
  Feinman, Alexey Kurakin, Cihang Xie, Yash Sharma, Tom Brown, Aurko Roy,
  Alexander Matyasko, Vahid Behzadan, Karen Hambardzumyan, Zhishuai Zhang,
  Yi-Lin Juang, Zhi Li, Ryan Sheatsley, Abhibhav Garg, Jonathan Uesato, Willi
  Gierke, Yinpeng Dong, David Berthelot, Paul Hendricks, Jonas Rauber, and
  Rujun Long.
\newblock Technical report on the cleverhans v2.1.0 adversarial examples
  library.
\newblock 2018.

\bibitem[Paulavi{\v{c}}ius and {\v{Z}}ilinskas(2006)]{doi:10.1080}
Remigijus Paulavi{\v{c}}ius and Julius {\v{Z}}ilinskas.
\newblock Analysis of different norms and corresponding lipschitz constants for
  global optimization.
\newblock \emph{Ukio Technologinis ir Ekonominis Vystymas}, 12\penalty0
  (4):\penalty0 301--306, 2006.

\bibitem[Petsiuk et~al.(2018)Petsiuk, Das, and Saenko]{petsiuk2018rise}
Vitali Petsiuk, Abir Das, and Kate Saenko.
\newblock Rise: Randomized input sampling for explanation of black-box models.
\newblock In \emph{BMVC}, 2018.

\bibitem[Schulz et~al.(2020)Schulz, Sixt, Tombari, and
  Landgraf]{schulz2020restricting}
Karl Schulz, Leon Sixt, Federico Tombari, and Tim Landgraf.
\newblock Restricting the flow: Information bottlenecks for attribution.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Selvaraju et~al.(2019)Selvaraju, Das, Vedantam, Cogswell, Parikh, and
  Batra]{selvaraju2016gradcam}
R.~R. Selvaraju, Abhishek Das, Ramakrishna Vedantam, Michael Cogswell,
  D.~Parikh, and Dhruv Batra.
\newblock Grad-cam: Visual explanations from deep networks via gradient-based
  localization.
\newblock \emph{International Journal of Computer Vision}, 128:\penalty0
  336--359, 2019.

\bibitem[Shrikumar et~al.(2017)Shrikumar, Greenside, and
  Kundaje]{shrikumar2017learning}
Avanti Shrikumar, Peyton Greenside, and Anshul Kundaje.
\newblock Learning important features through propagating activation
  differences.
\newblock Proceedings of Machine Learning Research. PMLR, 2017.

\bibitem[Simon-Gabriel et~al.(2018)Simon-Gabriel, Ollivier, Bottou, Schölkopf,
  and Lopez-Paz]{simongabriel2018firstorder}
Carl-Johann Simon-Gabriel, Yann Ollivier, Léon Bottou, Bernhard Schölkopf,
  and David Lopez-Paz.
\newblock First-order adversarial vulnerability of neural networks and input
  dimension, 2018.

\bibitem[Simonyan et~al.(2013)Simonyan, Vedaldi, and
  Zisserman]{simonyan2013deep}
Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman.
\newblock Deep inside convolutional networks: Visualising image classification
  models and saliency maps, 2013.

\bibitem[Singh et~al.(2019)Singh, Kumari, Mangla, Sinha, Balasubramanian, and
  Krishnamurthy]{singh2019benefits}
Mayank Singh, Nupur Kumari, Puneet Mangla, Abhishek Sinha, Vineeth~N
  Balasubramanian, and Balaji Krishnamurthy.
\newblock On the benefits of attributional robustness, 2019.

\bibitem[Singla et~al.()Singla, Wallace, Feng, and Feizi]{pmlr-v97-singla19a}
Sahil Singla, Eric Wallace, Shi Feng, and Soheil Feizi.
\newblock Understanding impacts of high-order loss approximations and features
  in deep learning interpretation.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning}, Proceedings of Machine Learning Research.

\bibitem[Smilkov et~al.(2017)Smilkov, Thorat, Kim, Viégas, and
  Wattenberg]{smilkov2017smoothgrad}
Daniel Smilkov, Nikhil Thorat, Been Kim, Fernanda Viégas, and Martin
  Wattenberg.
\newblock Smoothgrad: removing noise by adding noise, 2017.

\bibitem[Sorkine et~al.(2004)Sorkine, Cohen-Or, Lipman, Alexa, R\"{o}ssl, and
  Seidel]{10.1145/1057432.1057456}
O.~Sorkine, D.~Cohen-Or, Y.~Lipman, M.~Alexa, C.~R\"{o}ssl, and H.-P. Seidel.
\newblock Laplacian surface editing.
\newblock In \emph{Proceedings of the 2004 Eurographics/ACM SIGGRAPH Symposium
  on Geometry Processing}. Association for Computing Machinery, 2004.

\bibitem[Spearman()]{spearman04}
C.~Spearman.
\newblock The proof and measurement of association between two things.
\newblock \emph{American Journal of Psychology}, pages 88--103.

\bibitem[Springenberg et~al.(2014)Springenberg, Dosovitskiy, Brox, and
  Riedmiller]{springenberg2014striving}
Jost~Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox, and Martin
  Riedmiller.
\newblock Striving for simplicity: The all convolutional net, 2014.

\bibitem[Sundararajan et~al.(2017)Sundararajan, Taly, and
  Yan]{sundararajan2017axiomatic}
Mukund Sundararajan, Ankur Taly, and Qiqi Yan.
\newblock Axiomatic attribution for deep networks.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 3319--3328. JMLR. org, 2017.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy14intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2014.
\newblock URL \url{http://arxiv.org/abs/1312.6199}.

\bibitem[Viering et~al.(2019)Viering, Wang, Loog, and
  Eisemann]{viering2019manipulate}
Tom Viering, Ziqi Wang, Marco Loog, and Elmar Eisemann.
\newblock How to manipulate cnns to make them lie: the gradcam case, 2019.

\bibitem[Virmaux and Scaman(2018)]{NIPS2018_7640}
Aladin Virmaux and Kevin Scaman.
\newblock Lipschitz regularity of deep neural networks: analysis and efficient
  estimation.
\newblock In \emph{Advances in Neural Information Processing Systems 31
  (NeurIPS)}. 2018.

\bibitem[Wang et~al.(2020)Wang, Wang, Du, Yang, Zhang, Ding, Mardziel, and
  Hu]{wang2020score}
Haofan Wang, Zifan Wang, Mengnan Du, Fan Yang, Zijian Zhang, Sirui Ding, Piotr
  Mardziel, and Xia Hu.
\newblock Score-cam: Score-weighted visual explanations for convolutional
  neural networks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition Workshops}, 2020.

\bibitem[Yeh et~al.(2019)Yeh, Hsieh, Suggala, Inouye, and
  Ravikumar]{yeh2019infidelity}
Chih-Kuan Yeh, Cheng-Yu Hsieh, Arun Suggala, David~I Inouye, and Pradeep~K
  Ravikumar.
\newblock On the (in)fidelity and sensitivity of explanations.
\newblock In \emph{Advances in Neural Information Processing Systems 32}. 2019.

\bibitem[Yoshida and Miyato(2017)]{yoshida2017spectral}
Yuichi Yoshida and Takeru Miyato.
\newblock Spectral norm regularization for improving the generalizability of
  deep learning, 2017.

\bibitem[Zeiler and Fergus(2013)]{zeiler2013visualizing}
Matthew~D Zeiler and Rob Fergus.
\newblock Visualizing and understanding convolutional networks, 2013.

\bibitem[Zhang et~al.(2017)Zhang, Liang, and Charikar]{zhang2017hitting}
Yuchen Zhang, Percy Liang, and Moses Charikar.
\newblock A hitting time analysis of stochastic gradient langevin dynamics,
  2017.

\bibitem[Zhou et~al.(2015)Zhou, Khosla, Lapedriza, Oliva, and
  Torralba]{zhou2015learning}
Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba.
\newblock Learning deep features for discriminative localization, 2015.

\end{thebibliography}
