\begin{thebibliography}{10}

\bibitem{agarwal2009information}
Alekh Agarwal, Martin~J Wainwright, Peter~L Bartlett, and Pradeep~K Ravikumar.
\newblock Information-theoretic lower bounds on the oracle complexity of convex
  optimization.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1--9, 2009.

\bibitem{allen2018make}
Zeyuan Allen-Zhu.
\newblock How to make the gradients small stochastically: Even faster convex
  and nonconvex {SGD}.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1157--1167, 2018.

\bibitem{arjevani2019lower}
Yossi Arjevani, Yair Carmon, John~C Duchi, Dylan~J Foster, Nathan Srebro, and
  Blake Woodworth.
\newblock Lower bounds for non-convex stochastic optimization.
\newblock {\em arXiv preprint arXiv:1912.02365}, 2019.

\bibitem{azagra2017extension}
Daniel Azagra and Carlos Mudarra.
\newblock An extension theorem for convex functions of class c1, 1 on hilbert
  spaces.
\newblock {\em Journal of Mathematical Analysis and Applications},
  446(2):1167--1182, 2017.

\bibitem{bertsekas2011incremental}
Dimitri~P Bertsekas.
\newblock Incremental gradient, subgradient, and proximal methods for convex
  optimization: A survey.
\newblock {\em Optimization for Machine Learning}, 2010(1-38):3, 2011.

\bibitem{bottou2018optimization}
L{\'e}on Bottou, Frank~E Curtis, and Jorge Nocedal.
\newblock Optimization methods for large-scale machine learning.
\newblock {\em Siam Review}, 60(2):223--311, 2018.

\bibitem{drori2017exact}
Yoel Drori.
\newblock The exact information-based complexity of smooth convex minimization.
\newblock {\em Journal of Complexity}, 39:1--16, 2017.

\bibitem{Article:Drori}
Yoel Drori and M.~Teboulle.
\newblock Performance of first-order methods for smooth convex minimization: a
  novel approach.
\newblock {\em Mathematical Programming}, 145(1-2):451--482, 2014.

\bibitem{duchi2011adaptive}
John Duchi, Elad Hazan, and Yoram Singer.
\newblock Adaptive subgradient methods for online learning and stochastic
  optimization.
\newblock {\em Journal of Machine Learning Research}, 12(Jul):2121--2159, 2011.

\bibitem{fang2019sharp}
Cong Fang, Zhouchen Lin, and Tong Zhang.
\newblock Sharp analysis for nonconvex {SGD} escaping from saddle points.
\newblock {\em arXiv preprint arXiv:1902.00247}, 2019.

\bibitem{fefferman2017interpolation}
Charles Fefferman, Arie Israel, and Garving~K Luli.
\newblock Interpolation of data by smooth nonnegative functions.
\newblock {\em Revista Matem{\'a}tica Iberoamericana}, 33(1):305--324, 2017.

\bibitem{foster2019complexity}
Dylan Foster, Ayush Sekhari, Ohad Shamir, Nathan Srebro, Karthik Sridharan, and
  Blake Woodworth.
\newblock The complexity of making the gradient small in stochastic convex
  optimization.
\newblock {\em arXiv preprint arXiv:1902.04686}, 2019.

\bibitem{ghadimi2013stochastic}
Saeed Ghadimi and Guanghui Lan.
\newblock Stochastic first-and zeroth-order methods for nonconvex stochastic
  programming.
\newblock {\em SIAM Journal on Optimization}, 23(4):2341--2368, 2013.

\bibitem{kiwiel2001convergence}
Krzysztof~C Kiwiel.
\newblock Convergence and efficiency of subgradient methods for quasiconvex
  minimization.
\newblock {\em Mathematical programming}, 90(1):1--25, 2001.

\bibitem{kushner2003stochastic}
Harold Kushner and G~George Yin.
\newblock {\em Stochastic approximation and recursive algorithms and
  applications}, volume~35.
\newblock Springer Science \& Business Media, 2003.

\bibitem{moulines2011non}
Eric Moulines and Francis~R Bach.
\newblock Non-asymptotic analysis of stochastic approximation algorithms for
  machine learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  451--459, 2011.

\bibitem{nemirovski2009robust}
Arkadi Nemirovski, Anatoli Juditsky, Guanghui Lan, and Alexander Shapiro.
\newblock Robust stochastic approximation approach to stochastic programming.
\newblock {\em SIAM Journal on optimization}, 19(4):1574--1609, 2009.

\bibitem{Book:NemirovskyYudin}
A.S. Nemirovski and D.B. Yudin.
\newblock Problem complexity and method efficiency in optimization.
\newblock {\em Willey-Interscience, New York}, 1983.

\bibitem{Book:Nesterov}
Y.~Nesterov.
\newblock {\em Introductory lectures on convex optimization : a basic course}.
\newblock Kluwer Academic Publ., 2004.

\bibitem{nesterov2012make}
Yurii Nesterov.
\newblock How to make the gradients small.
\newblock {\em Optima}, 88:10--11, 2012.

\bibitem{nesterov1984minimization}
Yurii~E Nesterov.
\newblock Minimization methods for nonsmooth convex and quasiconvex functions.
\newblock {\em Matekon}, 29:519--531, 1984.

\bibitem{rakhlin2012making}
Alexander Rakhlin, Ohad Shamir, and Karthik Sridharan.
\newblock Making gradient descent optimal for strongly convex stochastic
  optimization.
\newblock In {\em Proceedings of the 29th International Coference on
  International Conference on Machine Learning}, pages 1571--1578. Omnipress,
  2012.

\bibitem{shalev2014understanding}
Shai Shalev-Shwartz and Shai Ben-David.
\newblock {\em Understanding machine learning: From theory to algorithms}.
\newblock Cambridge university press, 2014.

\bibitem{simchowitz2017gap}
Max Simchowitz, Ahmed~El Alaoui, and Benjamin Recht.
\newblock On the gap between strict-saddles and true convexity: An omega (log
  d) lower bound for eigenvector approximation.
\newblock {\em arXiv preprint arXiv:1704.04548}, 2017.

\bibitem{taylor2015exact}
Adrien~B Taylor, Julien~M Hendrickx, and Fran{\c{c}}ois Glineur.
\newblock Exact worst-case performance of first-order methods for composite
  convex optimization.
\newblock {\em SIAM Journal on Optimization}, 27(3):1283--1313, 2017.

\bibitem{taylor2015smooth}
Adrien~B Taylor, Julien~M Hendrickx, and Fran{\c{c}}ois Glineur.
\newblock Smooth strongly convex interpolation and exact worst-case performance
  of first-order methods.
\newblock {\em Mathematical Programming}, 161(1-2):307--345, 2017.

\bibitem{whitney1934analytic}
Hassler Whitney.
\newblock Analytic extensions of differentiable functions defined in closed
  sets.
\newblock {\em Transactions of the American Mathematical Society},
  36(1):63--89, 1934.

\end{thebibliography}
