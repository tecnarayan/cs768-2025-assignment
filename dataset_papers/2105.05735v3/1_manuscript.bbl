\begin{thebibliography}{61}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Akcay et~al.(2018)Akcay, Atapour-Abarghouei, and
  Breckon]{akcay2018ganomaly}
Akcay, S., Atapour-Abarghouei, A., and Breckon, T.~P.
\newblock Ganomaly: Semi-supervised anomaly detection via adversarial training.
\newblock In \emph{Asian conference on computer vision}, pp.\  622--637.
  Springer, 2018.

\bibitem[Alain \& Bengio(2014)Alain and Bengio]{alain2014regularized}
Alain, G. and Bengio, Y.
\newblock What regularized auto-encoders learn from the data-generating
  distribution.
\newblock \emph{The Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 3563--3593, 2014.

\bibitem[Bergmann et~al.(2018)Bergmann, L{\"o}we, Fauser, Sattlegger, and
  Steger]{bergmann2018improving}
Bergmann, P., L{\"o}we, S., Fauser, M., Sattlegger, D., and Steger, C.
\newblock Improving unsupervised defect segmentation by applying structural
  similarity to autoencoders.
\newblock \emph{arXiv preprint arXiv:1807.02011}, 2018.

\bibitem[Bishop(1994)]{bishop1994novelty}
Bishop, C.~M.
\newblock Novelty detection and neural network validation.
\newblock \emph{IEE Proceedings-Vision, Image and Signal processing},
  141\penalty0 (4):\penalty0 217--222, 1994.

\bibitem[Bourlard \& Kamp(1988)Bourlard and Kamp]{bourlard1988auto}
Bourlard, H. and Kamp, Y.
\newblock Auto-association by multilayer perceptrons and singular value
  decomposition.
\newblock \emph{Biological cybernetics}, 59\penalty0 (4-5):\penalty0 291--294,
  1988.

\bibitem[Brehmer \& Cranmer(2020)Brehmer and Cranmer]{brehmer2020flows}
Brehmer, J. and Cranmer, K.
\newblock Flows for simultaneous manifold learning and density estimation.
\newblock \emph{arXiv preprint arXiv:2003.13913}, 2020.

\bibitem[Davidson et~al.(2018)Davidson, Falorsi, De~Cao, Kipf, and
  Tomczak]{davidson2018hyperspherical}
Davidson, T.~R., Falorsi, L., De~Cao, N., Kipf, T., and Tomczak, J.~M.
\newblock Hyperspherical variational auto-encoders.
\newblock In \emph{34th Conference on Uncertainty in Artificial Intelligence
  2018, UAI 2018}, pp.\  856--865. Association For Uncertainty in Artificial
  Intelligence (AUAI), 2018.

\bibitem[Du \& Mordatch(2019)Du and Mordatch]{du2019}
Du, Y. and Mordatch, I.
\newblock Implicit generation and modeling with energy based models.
\newblock In Wallach, H., Larochelle, H., Beygelzimer, A., d~Alche-Buc, F.,
  Fox, E., and Garnett, R. (eds.), \emph{Advances in Neural Information
  Processing Systems 32}, pp.\  3608--3618. Curran Associates, Inc., 2019.

\bibitem[Ghosh et~al.(2020)Ghosh, Sajjadi, Vergari, Black, and
  Scholkopf]{Ghosh2020From}
Ghosh, P., Sajjadi, M. S.~M., Vergari, A., Black, M., and Scholkopf, B.
\newblock From variational to deterministic autoencoders.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=S1g7tpEYDS}.

\bibitem[Gong et~al.(2019)Gong, Liu, Le, Saha, Mansour, Venkatesh, and
  Hengel]{gong2019memorizing}
Gong, D., Liu, L., Le, V., Saha, B., Mansour, M.~R., Venkatesh, S., and Hengel,
  A. v.~d.
\newblock Memorizing normality to detect anomaly: Memory-augmented deep
  autoencoder for unsupervised anomaly detection.
\newblock In \emph{IEEE International Conference on Computer Vision (ICCV)},
  2019.

\bibitem[Grathwohl et~al.(2018)Grathwohl, Chen, Bettencourt, Sutskever, and
  Duvenaud]{grathwohl2018ffjord}
Grathwohl, W., Chen, R.~T., Bettencourt, J., Sutskever, I., and Duvenaud, D.
\newblock Ffjord: Free-form continuous dynamics for scalable reversible
  generative models.
\newblock \emph{arXiv preprint arXiv:1810.01367}, 2018.

\bibitem[Grathwohl et~al.(2020)Grathwohl, Wang, Jacobsen, Duvenaud, Norouzi,
  and Swersky]{Grathwohl2020Your}
Grathwohl, W., Wang, K.-C., Jacobsen, J.-H., Duvenaud, D., Norouzi, M., and
  Swersky, K.
\newblock Your classifier is secretly an energy based model and you should
  treat it like one.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=Hkxzx0NtDB}.

\bibitem[Grenander \& Miller(1994)Grenander and
  Miller]{grenander1994representations}
Grenander, U. and Miller, M.~I.
\newblock Representations of knowledge in complex systems.
\newblock \emph{Journal of the Royal Statistical Society: Series B
  (Methodological)}, 56\penalty0 (4):\penalty0 549--581, 1994.

\bibitem[Gutmann \& Hyv{\"a}rinen(2010)Gutmann and
  Hyv{\"a}rinen]{gutmann2010noise}
Gutmann, M. and Hyv{\"a}rinen, A.
\newblock Noise-contrastive estimation: A new estimation principle for
  unnormalized statistical models.
\newblock In \emph{Proceedings of the Thirteenth International Conference on
  Artificial Intelligence and Statistics}, pp.\  297--304, 2010.

\bibitem[Hendrycks et~al.(2019)Hendrycks, Mazeika, and
  Dietterich]{hendrycks2018deep}
Hendrycks, D., Mazeika, M., and Dietterich, T.
\newblock Deep anomaly detection with outlier exposure.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=HyxCxhRcY7}.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and
  Hochreiter]{heusel2017gans}
Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., and Hochreiter, S.
\newblock Gans trained by a two time-scale update rule converge to a local nash
  equilibrium.
\newblock \emph{arXiv preprint arXiv:1706.08500}, 2017.

\bibitem[Hinton(2002)]{hinton2002training}
Hinton, G.~E.
\newblock Training products of experts by minimizing contrastive divergence.
\newblock \emph{Neural computation}, 14\penalty0 (8):\penalty0 1771--1800,
  2002.

\bibitem[Japkowicz et~al.(1995)Japkowicz, Myers, Gluck,
  et~al.]{japkowicz1995novelty}
Japkowicz, N., Myers, C., Gluck, M., et~al.
\newblock A novelty detection approach to classification.
\newblock In \emph{Proceedings of the International Joint Conference on
  Artificial Intelligence}, volume~1, pp.\  518--523, 1995.

\bibitem[Keysers et~al.(2019)Keysers, Sch{\"a}rli, Scales, Buisman, Furrer,
  Kashubin, Momchev, Sinopalnikov, Stafiniak, Tihon,
  et~al.]{keysers2019measuring}
Keysers, D., Sch{\"a}rli, N., Scales, N., Buisman, H., Furrer, D., Kashubin,
  S., Momchev, N., Sinopalnikov, D., Stafiniak, L., Tihon, T., et~al.
\newblock Measuring compositional generalization: A comprehensive method on
  realistic data.
\newblock \emph{arXiv preprint arXiv:1912.09713}, 2019.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kingma \& Dhariwal(2018)Kingma and Dhariwal]{kingma2018glow}
Kingma, D.~P. and Dhariwal, P.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  10215--10224, 2018.

\bibitem[Kingma \& Welling(2014)Kingma and Welling]{kingma2013auto}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational bayes.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2014.

\bibitem[Lan \& Dinh(2020)Lan and Dinh]{lan2020perfect}
Lan, C.~L. and Dinh, L.
\newblock Perfect density models cannot guarantee anomaly detection.
\newblock \emph{arXiv preprint arXiv:2012.03808}, 2020.

\bibitem[Lu \& Xu(2018)Lu and Xu]{lu2018anomaly}
Lu, Y. and Xu, P.
\newblock Anomaly detection for skin disease images using variational
  autoencoder.
\newblock \emph{arXiv preprint arXiv:1807.01349}, 2018.

\bibitem[Lyudchik(2016)]{lyudchik2016outlier}
Lyudchik, O.
\newblock Outlier detection using autoencoders.
\newblock Technical report, 2016.

\bibitem[Meng et~al.(2020)Meng, Yu, Song, Song, and
  Ermon]{meng2020autoregressive}
Meng, C., Yu, L., Song, Y., Song, J., and Ermon, S.
\newblock Autoregressive score matching.
\newblock \emph{arXiv preprint arXiv:2010.12810}, 2020.

\bibitem[Mikolov et~al.(2013)Mikolov, Sutskever, Chen, Corrado, and
  Dean]{mikolov2013distributed}
Mikolov, T., Sutskever, I., Chen, K., Corrado, G.~S., and Dean, J.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  3111--3119, 2013.

\bibitem[Miyato et~al.(2018)Miyato, Kataoka, Koyama, and
  Yoshida]{miyato2018spectral}
Miyato, T., Kataoka, T., Koyama, M., and Yoshida, Y.
\newblock Spectral normalization for generative adversarial networks.
\newblock \emph{arXiv preprint arXiv:1802.05957}, 2018.

\bibitem[Nalisnick et~al.(2019)Nalisnick, Matsukawa, Teh, Gorur, and
  Lakshminarayanan]{nalisnick2018do}
Nalisnick, E., Matsukawa, A., Teh, Y.~W., Gorur, D., and Lakshminarayanan, B.
\newblock Do deep generative models know what they don't know?
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=H1xwNhCcYm}.

\bibitem[Nash \& Durkan(2019)Nash and Durkan]{nash2019autoregressive}
Nash, C. and Durkan, C.
\newblock Autoregressive energy machines.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1735--1744. PMLR, 2019.

\bibitem[Ng et~al.(2011)]{ng2011sparse}
Ng, A. et~al.
\newblock Sparse autoencoder.
\newblock \emph{CS294A Lecture notes}, 2011.

\bibitem[Nijkamp et~al.(2019)Nijkamp, Hill, Zhu, and
  Wu]{Nijkamp2019nonconvergent}
Nijkamp, E., Hill, M., Zhu, S.-C., and Wu, Y.~N.
\newblock Learning non-convergent non-persistent short-run mcmc toward
  energy-based model.
\newblock In Wallach, H., Larochelle, H., Beygelzimer, A., d\textquotesingle
  Alch\'{e}-Buc, F., Fox, E., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~32, pp.\  5232--5242. Curran
  Associates, Inc., 2019.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2019/file/2bc8ae25856bc2a6a1333d1331a3b7a6-Paper.pdf}.

\bibitem[Oord et~al.(2016)Oord, Kalchbrenner, and Kavukcuoglu]{oord2016pixel}
Oord, A. v.~d., Kalchbrenner, N., and Kavukcuoglu, K.
\newblock Pixel recurrent neural networks.
\newblock \emph{arXiv preprint arXiv:1601.06759}, 2016.

\bibitem[Oord et~al.(2017)Oord, Vinyals, and Kavukcuoglu]{oord2017neural}
Oord, A. v.~d., Vinyals, O., and Kavukcuoglu, K.
\newblock Neural discrete representation learning.
\newblock \emph{arXiv preprint arXiv:1711.00937}, 2017.

\bibitem[Parisi(1981)]{parisi1981correlation}
Parisi, G.
\newblock Correlation functions and computer simulations.
\newblock \emph{Nuclear Physics B}, 180\penalty0 (3):\penalty0 378--384, 1981.

\bibitem[Pidhorskyi et~al.(2018)Pidhorskyi, Almohsen, and
  Doretto]{pidhorskyi2018generative}
Pidhorskyi, S., Almohsen, R., and Doretto, G.
\newblock Generative probabilistic novelty detection with adversarial
  autoencoders.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  6822--6833, 2018.

\bibitem[Ren et~al.(2019)Ren, Liu, Fertig, Snoek, Poplin, Depristo, Dillon, and
  Lakshminarayanan]{ren2019likelihood}
Ren, J., Liu, P.~J., Fertig, E., Snoek, J., Poplin, R., Depristo, M., Dillon,
  J., and Lakshminarayanan, B.
\newblock Likelihood ratios for out-of-distribution detection.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  14680--14691, 2019.

\bibitem[Rifai et~al.(2011)Rifai, Vincent, Muller, Glorot, and
  Bengio]{rifai2011contractive}
Rifai, S., Vincent, P., Muller, X., Glorot, X., and Bengio, Y.
\newblock Contractive auto-encoders: explicit invariance during feature
  extraction.
\newblock In \emph{Proceedings of the 28th International Conference on
  International Conference on Machine Learning}, pp.\  833--840, 2011.

\bibitem[Roberts et~al.(1996)Roberts, Tweedie, et~al.]{roberts1996exponential}
Roberts, G.~O., Tweedie, R.~L., et~al.
\newblock Exponential convergence of langevin distributions and their discrete
  approximations.
\newblock \emph{Bernoulli}, 2\penalty0 (4):\penalty0 341--363, 1996.

\bibitem[Rumelhart et~al.(1986)Rumelhart, Hinton, and Williams]{rumelhart1986}
Rumelhart, D.~E., Hinton, G.~E., and Williams, R.~J.
\newblock \emph{Learning Internal Representations by Error Propagation}, pp.\
  318–362.
\newblock MIT Press, Cambridge, MA, USA, 1986.
\newblock ISBN 026268053X.

\bibitem[Salimans et~al.(2017)Salimans, Karpathy, Chen, and
  Kingma]{salimans2017pixelcnn++}
Salimans, T., Karpathy, A., Chen, X., and Kingma, D.~P.
\newblock Pixelcnn++: Improving the pixelcnn with discretized logistic mixture
  likelihood and other modifications.
\newblock \emph{arXiv preprint arXiv:1701.05517}, 2017.

\bibitem[Serrà et~al.(2020)Serrà, Álvarez, Gómez, Slizovskaia, Núñez, and
  Luque]{Serra2020Input}
Serrà, J., Álvarez, D., Gómez, V., Slizovskaia, O., Núñez, J.~F., and
  Luque, J.
\newblock Input complexity and out-of-distribution detection with
  likelihood-based generative models.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=SyxIWpVYvr}.

\bibitem[Song \& Ermon(2020)Song and Ermon]{song2020improved}
Song, Y. and Ermon, S.
\newblock Improved techniques for training score-based generative models.
\newblock \emph{arXiv preprint arXiv:2006.09011}, 2020.

\bibitem[Song \& Kingma(2021)Song and Kingma]{song2021train}
Song, Y. and Kingma, D.~P.
\newblock How to train your energy-based models.
\newblock \emph{arXiv preprint arXiv:2101.03288}, 2021.

\bibitem[Steinwart et~al.(2005)Steinwart, Hush, and
  Scovel]{steinwart2005classification}
Steinwart, I., Hush, D., and Scovel, C.
\newblock A classification framework for anomaly detection.
\newblock \emph{Journal of Machine Learning Research}, 6\penalty0
  (Feb):\penalty0 211--232, 2005.

\bibitem[Tieleman(2008)]{tieleman2008training}
Tieleman, T.
\newblock Training restricted boltzmann machines using approximations to the
  likelihood gradient.
\newblock In \emph{Proceedings of the 25th international conference on Machine
  learning}, pp.\  1064--1071, 2008.

\bibitem[Tong et~al.(2019)Tong, Yousefzadeh, Wolf, and
  Krishnaswamy]{tong2019fixing}
Tong, A., Yousefzadeh, R., Wolf, G., and Krishnaswamy, S.
\newblock Fixing bias in reconstruction-based anomaly detection with lipschitz
  discriminators.
\newblock \emph{arXiv preprint arXiv:1905.10710}, 2019.

\bibitem[Vincent(2011)]{vincent2011connection}
Vincent, P.
\newblock A connection between score matching and denoising autoencoders.
\newblock \emph{Neural computation}, 23\penalty0 (7):\penalty0 1661--1674,
  2011.

\bibitem[Vincent et~al.(2008)Vincent, Larochelle, Bengio, and
  Manzagol]{vincent2008extracting}
Vincent, P., Larochelle, H., Bengio, Y., and Manzagol, P.-A.
\newblock Extracting and composing robust features with denoising autoencoders.
\newblock In \emph{Proceedings of the 25th international conference on Machine
  learning}, pp.\  1096--1103, 2008.

\bibitem[Wang et~al.(2004)Wang, Bovik, Sheikh, and Simoncelli]{wang2004image}
Wang, Z., Bovik, A.~C., Sheikh, H.~R., and Simoncelli, E.~P.
\newblock Image quality assessment: from error visibility to structural
  similarity.
\newblock \emph{IEEE transactions on image processing}, 13\penalty0
  (4):\penalty0 600--612, 2004.

\bibitem[Welling \& Teh(2011)Welling and Teh]{welling2011bayesian}
Welling, M. and Teh, Y.~W.
\newblock Bayesian learning via stochastic gradient langevin dynamics.
\newblock In \emph{Proceedings of the 28th international conference on machine
  learning (ICML-11)}, pp.\  681--688, 2011.

\bibitem[Wu \& He(2018)Wu and He]{wu2018group}
Wu, Y. and He, K.
\newblock Group normalization.
\newblock In \emph{Proceedings of the European conference on computer vision
  (ECCV)}, pp.\  3--19, 2018.

\bibitem[Xiao et~al.(2020)Xiao, Yan, and Amit]{xiao2020likelihood}
Xiao, Z., Yan, Q., and Amit, Y.
\newblock Likelihood regret: An out-of-distribution detection score for
  variational auto-encoder.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M.~F., and Lin,
  H. (eds.), \emph{Advances in Neural Information Processing Systems},
  volume~33, pp.\  20685--20696. Curran Associates, Inc., 2020.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2020/file/eddea82ad2755b24c4e168c5fc2ebd40-Paper.pdf}.

\bibitem[Xiao et~al.(2021)Xiao, Kreis, Kautz, and Vahdat]{xiao2021vaebm}
Xiao, Z., Kreis, K., Kautz, J., and Vahdat, A.
\newblock {\{}VAEBM{\}}: A symbiosis between variational autoencoders and
  energy-based models.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=5m3SEczOV8L}.

\bibitem[Xie et~al.(2016)Xie, Lu, Zhu, and Wu]{xie2016theory}
Xie, J., Lu, Y., Zhu, S.-C., and Wu, Y.
\newblock A theory of generative convnet.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2635--2644. PMLR, 2016.

\bibitem[Xu \& Durrett(2018)Xu and Durrett]{xu2018spherical}
Xu, J. and Durrett, G.
\newblock Spherical latent spaces for stable variational autoencoders.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  4503--4513, 2018.

\bibitem[Younes(1999)]{younes1999convergence}
Younes, L.
\newblock On the convergence of markovian stochastic algorithms with rapidly
  decreasing ergodicity rates.
\newblock \emph{Stochastics: An International Journal of Probability and
  Stochastic Processes}, 65\penalty0 (3-4):\penalty0 177--228, 1999.

\bibitem[Zhao et~al.(2019)Zhao, Zhu, and Zhang]{zhao2019latent}
Zhao, D., Zhu, J., and Zhang, B.
\newblock Latent variables on spheres for autoencoders in high dimensions.
\newblock \emph{arXiv}, pp.\  arXiv--1912, 2019.

\bibitem[Zhao et~al.(2016)Zhao, Mathieu, and LeCun]{zhao2016energy}
Zhao, J., Mathieu, M., and LeCun, Y.
\newblock Energy-based generative adversarial network.
\newblock \emph{arXiv preprint arXiv:1609.03126}, 2016.

\bibitem[Zhao et~al.(2017)Zhao, Deng, Shen, Liu, Lu, and Hua]{zhao2017spatio}
Zhao, Y., Deng, B., Shen, C., Liu, Y., Lu, H., and Hua, X.-S.
\newblock Spatio-temporal autoencoder for video anomaly detection.
\newblock In \emph{Proceedings of the 25th ACM international conference on
  Multimedia}, pp.\  1933--1941, 2017.

\bibitem[Zong et~al.(2018)Zong, Song, Min, Cheng, Lumezanu, Cho, and
  Chen]{zong2018deep}
Zong, B., Song, Q., Min, M.~R., Cheng, W., Lumezanu, C., Cho, D., and Chen, H.
\newblock Deep autoencoding gaussian mixture model for unsupervised anomaly
  detection.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=BJJLHbb0-}.

\end{thebibliography}
