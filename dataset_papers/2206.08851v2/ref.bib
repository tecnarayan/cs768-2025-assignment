% Encoding: UTF-8
@article{KONTORAVDI2008, 
title={Application of Global Sensitivity Analysis to Determine Goals for Design of Experiments: An Example Study on Antibody-Producing Cell Cultures}, volume={21}, ISSN={8756-7938}, url={http://dx.doi.org/10.1021/bp050028k}, DOI={10.1021/bp050028k}, number={4}, journal={Biotechnology Progress}, publisher={Wiley}, author={Kontoravdi, Cleo and Asprey, Steven P. and Pistikopoulos, Efstratios N. and Mantalaris, Athanasios}, year={2008}, month={Sep}, pages={1128–1135}}

@article{qin2003,
  title={A survey of industrial model predictive control technology},
  author={Qin, S Joe and Badgwell, Thomas A},
  journal={Control engineering practice},
  volume={11},
  number={7},
  pages={733--764},
  year={2003},
  publisher={Elsevier}
}

@article{mayne2016,
  title={Robust and stochastic model predictive control: Are we going in the right direction?},
  author={Mayne, David},
  journal={Annual Reviews in Control},
  volume={41},
  pages={184--192},
  year={2016},
  publisher={Elsevier}
}

@book{schiesser2012,
  title={The numerical method of lines: integration of partial differential equations},
  author={Schiesser, William E},
  year={2012},
  publisher={Elsevier}
}

@article{angeli2011,
  title={On average performance and stability of economic model predictive control},
  author={Angeli, David and Amrit, Rishi and Rawlings, James B},
  journal={IEEE transactions on automatic control},
  volume={57},
  number={7},
  pages={1615--1626},
  year={2011},
  publisher={IEEE}
}

@article{andersson2019,
  title={CasADi: a software framework for nonlinear optimization and optimal control},
  author={Andersson, Joel AE and Gillis, Joris and Horn, Greg and Rawlings, James B and Diehl, Moritz},
  journal={Mathematical Programming Computation},
  volume={11},
  number={1},
  pages={1--36},
  year={2019},
  publisher={Springer}
}

@article{de1997kinetic,
  title={A kinetic model for beer production: simulation under industrial operational conditions},
  author={de Andr{\'e}s-Toro, B and Giron-Sierra, JM and Fernandez-Conde, C and Peinado, JM and Garcia-Ochoa, F},
  journal={IFAC Proceedings Volumes},
  volume={30},
  number={5},
  pages={203--208},
  year={1997},
  publisher={Elsevier}
}

@article{rodman2016dynamic,
  title={Dynamic simulation and visualisation of fermentation: effect of process conditions on beer quality},
  author={Rodman, Alistair D and Gerogiorgis, Dimitrios I},
  journal={IFAC-PapersOnLine},
  volume={49},
  number={7},
  pages={615--620},
  year={2016},
  publisher={Elsevier}
}

@article{KONTORAVDI2010, title={Systematic development of predictive mathematical models for animal cell cultures}, volume={34}, ISSN={0098-1354}, url={http://dx.doi.org/10.1016/j.compchemeng.2010.03.012}, DOI={10.1016/j.compchemeng.2010.03.012}, number={8}, journal={Computers \& Chemical Engineering}, publisher={Elsevier BV}, author={Kontoravdi, Cleo and Pistikopoulos, Efstratios N. and Mantalaris, Athanasios}, year={2010}, month={Aug}, pages={1192–1198}}

@article{PAPATHANASIOU2017, title={Advanced model-based control strategies for the intensification of upstream and downstream processing in mAb production}, volume={33}, ISSN={8756-7938}, url={http://dx.doi.org/10.1002/btpr.2483}, DOI={10.1002/btpr.2483}, number={4}, journal={Biotechnology Progress}, publisher={Wiley}, author={Papathanasiou, Maria M. and Quiroga-Campano, Ana L. and Steinebach, Fabian and Elviro, Montaña and Mantalaris, Athanasios and Pistikopoulos, Efstratios N.}, year={2017}, month={Apr}, pages={966–988}}

@article{VILLIGER2016, title={Controlling the time evolution of mAb N-linked glycosylation - Part II: Model-based predictions}, volume={32}, ISSN={8756-7938}, url={http://dx.doi.org/10.1002/btpr.2315}, DOI={10.1002/btpr.2315}, number={5}, journal={Biotechnology Progress}, publisher={Wiley}, author={Villiger, Thomas K. and Scibona, Ernesto and Stettler, Matthieu and Broly, Hervé and Morbidelli, Massimo and Soos, Miroslav}, year={2016}, month={Jul}, pages={1135–1148}}

@article{JIMENEZ2016, title={Dynamics of immature mAb glycoform secretion during CHO cell culture: An integrated modelling framework}, volume={11}, ISSN={1860-6768}, url={http://dx.doi.org/10.1002/biot.201400663}, DOI={10.1002/biot.201400663}, number={5}, journal={Biotechnology Journal}, publisher={Wiley}, author={Jimenez del Val, Ioscani and Fan, Yuzhou and Weilguny, Dietmar}, year={2016}, month={Feb}, pages={610–623}}

@article{CLINCKE2013, title={Very high density of Chinese hamster ovary cells in perfusion by alternating tangential flow or tangential flow filtration in WAVE bioreactor™—part II: Applications for antibody production and cryopreservation}, volume={29}, ISSN={1520-6033}, url={http://dx.doi.org/10.1002/btpr.1703}, DOI={10.1002/btpr.1703}, number={3}, journal={Biotechnology Progress}, publisher={Wiley}, author={Clincke, Marie‐Françoise and Mölleryd, Carin and Samani, Puneeth K and Lindskog, Eva and Fäldt, Eric and Walsh, Kieron and Chotteau, Véronique}, year={2013}, month={May}, pages={768–777}}

@article{gomis2020model,
  title={Model-based design and control of a small-scale integrated continuous end-to-end mAb platform},
  author={Gomis-Fons, Joaqu{\'\i}n and Schwarz, Hubert and Zhang, Liang and Andersson, Niklas and Nilsson, Bernt and Castan, Andreas and Solbrand, Anita and Stevenson, Joanne and Chotteau, V{\'e}ronique},
  journal={Biotechnology progress},
  volume={36},
  number={4},
  pages={e2995},
  year={2020},
  publisher={Wiley Online Library}
}

@article{perez2009igg,
  title={IgG adsorption on a new protein A adsorbent based on macroporous hydrophilic polymers. I. Adsorption equilibrium and kinetics},
  author={Perez-Almodovar, Ernie X and Carta, Giorgio},
  journal={Journal of Chromatography A},
  volume={1216},
  number={47},
  pages={8339--8347},
  year={2009},
  publisher={Elsevier}
}

@Comment{jabref-meta: databaseType:bibtex;}

@article{wang2020human,
  title={A human monoclonal antibody blocking SARS-CoV-2 infection},
  author={Wang, Chunyan and Li, Wentao and Drabek, Dubravka and Okba, Nisreen MA and van Haperen, Rien and Osterhaus, Albert DME and van Kuppeveld, Frank JM and Haagmans, Bart L and Grosveld, Frank and Bosch, Berend-Jan},
  journal={Nature communications},
  volume={11},
  number={1},
  pages={1--6},
  year={2020},
  publisher={Nature Publishing Group}
}

@misc{antibody2020antibody,
  title={Antibody therapeutics approved or in regulatory review in the EU or US},
  author={Antibody Society},
  year={2020}
}

@inproceedings{kaplon2020antibodies,
  title={Antibodies to watch in 2020},
  author={Kaplon, H{\'e}l{\`e}ne and Muralidharan, Mrinalini and Schneider, Zita and Reichert, Janice M},
  booktitle={MAbs},
  volume={12},
  number={1},
  pages={1703531},
  year={2020},
  organization={Taylor \& Francis}
}

@article{croughan2015future,
  title={The future of industrial bioprocessing: batch or continuous?},
  author={Croughan, Matthew S and Konstantinov, Konstantin B and Cooney, Charles},
  journal={Biotechnology and bioengineering},
  volume={112},
  number={4},
  pages={648--651},
  year={2015},
  publisher={Wiley Online Library}
}

@article{nserc2018nserc,
  title={NSERC Strategic Network for the Production of Single-type Glycoform Monoclonal Antibodies},
  author={N. S. and E. R. C. of C. Government of Canada},
  journal={Natural Sciences and Engineering Research Council of Canada (NSERC)},
  year={Jun. 28, 2016},
}

@phdthesis{dizaji2016minor,
  title={Minor Whey Protein Purification Using Ion-Exchange Column Chromatography},
  author={Dizaji, Naeimeh Faraji},
  year={2016},
  school={The University of Western Ontario}
}

@inproceedings{nikolakopoulou2020,
  title={Fast model predictive control of startup of a compact modular reconfigurable system for continuous-flow pharmaceutical manufacturing},
  author={Nikolakopoulou, Anastasia and von Andrian, Matthias and Braatz, Richard D},
  booktitle={2020 American Control Conference (ACC)},
  pages={2778--2783},
  year={2020},
  organization={IEEE}
}

@article{goldrick2015development,
  title={The development of an industrial-scale fed-batch fermentation simulation},
  author={Goldrick, Stephen and {\c{S}}tefan, Andrei and Lovett, David and Montague, Gary and Lennox, Barry},
  journal={Journal of biotechnology},
  volume={193},
  pages={70--82},
  year={2015},
  publisher={Elsevier}
}

@article{openaigym,
  doi = {10.48550/ARXIV.1606.01540},
  
  url = {https://arxiv.org/abs/1606.01540},
  
  author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {OpenAI Gym},
  
  journal = {arXiv preprint arXiv:1606.0154},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{d4rl,
    title={D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
    author={Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine},
    year={2020},
    eprint={2004.07219},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    journal={arXiv preprint arXiv:2004.07219},
}


@InProceedings{d3rlpy,
  author = {Takuma Seno, Michita Imai},
  title = {d3rlpy: An Offline Deep Reinforcement Library},
  booktitle = {NeurIPS 2021 Offline Reinforcement Learning Workshop},
  month = {December},
  year = {2021}
}

@inproceedings{ray,
  title={Ray: A distributed framework for emerging $\{$AI$\}$ applications},
  author={Moritz, Philipp and Nishihara, Robert and Wang, Stephanie and Tumanov, Alexey and Liaw, Richard and Liang, Eric and Elibol, Melih and Yang, Zongheng and Paul, William and Jordan, Michael I and others},
  booktitle={13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18)},
  pages={561--577},
  year={2018}
}

@inproceedings{rllib,
  title={RLlib: Abstractions for distributed reinforcement learning},
  author={Liang, Eric and Liaw, Richard and Nishihara, Robert and Moritz, Philipp and Fox, Roy and Goldberg, Ken and Gonzalez, Joseph and Jordan, Michael and Stoica, Ion},
  booktitle={International Conference on Machine Learning},
  pages={3053--3062},
  year={2018},
  organization={PMLR}
}

@article{tune,
  title={Tune: A research platform for distributed model selection and training},
  author={Liaw, Richard and Liang, Eric and Nishihara, Robert and Moritz, Philipp and Gonzalez, Joseph E and Stoica, Ion},
  journal={arXiv preprint arXiv:1807.05118},
  year={2018}
}

@article{PLAS,
  doi = {10.48550/ARXIV.2011.07213},
  
  url = {https://arxiv.org/abs/2011.07213},
  
  author = {Zhou, Wenxuan and Bajracharya, Sujay and Held, David},
  
  keywords = {Robotics (cs.RO), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {PLAS: Latent Action Space for Offline Reinforcement Learning},
  
  publisher = {arXiv},
  
  year = {2020},
  
  journal={arXiv preprint arXiv:2011.07213},

  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{AWR,
  doi = {10.48550/ARXIV.1910.00177},
  
  url = {https://arxiv.org/abs/1910.00177},
  
  author = {Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{AWAC,
  doi = {10.48550/ARXIV.2006.09359},
  
  url = {https://arxiv.org/abs/2006.09359},
  
  author = {Nair, Ashvin and Gupta, Abhishek and Dalal, Murtaza and Levine, Sergey},
  
  keywords = {Machine Learning (cs.LG), Robotics (cs.RO), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {AWAC: Accelerating Online Reinforcement Learning with Offline Datasets},
  
  publisher = {arXiv},
  
  year = {2020},
  
  journal={arXiv preprint arXiv:2006.09359},

  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{BC,
  title={Alvinn: An autonomous land vehicle in a neural network},
  author={Pomerleau, Dean A},
  journal={Advances in neural information processing systems},
  volume={1},
  year={1988}
}

@article{CQL,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}

@article{DQN,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@misc{DoubleDQN,
  doi = {10.48550/ARXIV.1509.06461},
  
  url = {https://arxiv.org/abs/1509.06461},
  
  author = {van Hasselt, Hado and Guez, Arthur and Silver, David},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Deep Reinforcement Learning with Double Q-learning},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{DDPG,
  doi = {10.48550/ARXIV.1509.02971},
  
  url = {https://arxiv.org/abs/1509.02971},
  
  author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Continuous control with deep reinforcement learning},
  
  publisher = {arXiv},
  
  year = {2015},
  
  journal={arXiv preprint arXiv:1509.02971},

  copyright = {arXiv.org perpetual, non-exclusive license}
}


@inproceedings{TD3,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International conference on machine learning},
  pages={1587--1596},
  year={2018},
  organization={PMLR}
}

@article{SAC,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@article{BEAR,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{IMPALA,
  title={Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Vlad and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  booktitle={International conference on machine learning},
  pages={1407--1416},
  year={2018},
  organization={PMLR}
}

@misc{MBMPO,
  doi = {10.48550/ARXIV.1809.05214},
  
  url = {https://arxiv.org/abs/1809.05214},
  
  author = {Clavera, Ignasi and Rothfuss, Jonas and Schulman, John and Fujita, Yasuhiro and Asfour, Tamim and Abbeel, Pieter},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Model-Based Reinforcement Learning via Meta-Policy Optimization},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{PG,
author = {Sutton, Richard S. and McAllester, David and Singh, Satinder and Mansour, Yishay},
title = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
year = {1999},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
abstract = {Function approximation is essential to reinforcement learning, but the standard approach of approximating a value function and determining a policy from it has so far proven theoretically intractable. In this paper we explore an alternative approach in which the policy is explicitly represented by its own function approximator, independent of the value function, and is updated according to the gradient of expected reward with respect to the policy parameters. Williams's REINFORCE method and actor-critic methods are examples of this approach. Our main new result is to show that the gradient can be written in a form suitable for estimation from experience aided by an approximate action-value or advantage function. Using this result, we prove for the first time that a version of policy iteration with arbitrary differentiable function approximation is convergent to a locally optimal policy.},
booktitle = {Proceedings of the 12th International Conference on Neural Information Processing Systems},
pages = {1057–1063},
numpages = {7},
location = {Denver, CO},
series = {NIPS'99}
}

@article{PPO,
  doi = {10.48550/ARXIV.1707.06347},
  
  url = {https://arxiv.org/abs/1707.06347},
  
  author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Proximal Policy Optimization Algorithms},
  
  publisher = {arXiv},
  
  year = {2017},
  
  journal={arXiv preprint arXiv:1707.06347},

  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{problemwithddpg,
title={The problem with {\{}DDPG{\}}: understanding failures in deterministic environments with sparse rewards},
author={Guillaume Matheron and Olivier Sigaud and Nicolas Perrin},
year={2020},
url={https://openreview.net/forum?id=HyxnH64KwS},
journal={arXiv preprint arXiv:1911.11679},
}

@inproceedings{functionapproximationerror,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International conference on machine learning},
  pages={1587--1596},
  year={2018},
  organization={PMLR}
}

@inproceedings{BCQ,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International conference on machine learning},
  pages={2052--2062},
  year={2019},
  organization={PMLR}
}

@misc{MPO,
  doi = {10.48550/ARXIV.1806.06920},
  
  url = {https://arxiv.org/abs/1806.06920},
  
  author = {Abdolmaleki, Abbas and Springenberg, Jost Tobias and Tassa, Yuval and Munos, Remi and Heess, Nicolas and Riedmiller, Martin},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Information Theory (cs.IT), Robotics (cs.RO), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Maximum a Posteriori Policy Optimisation},
  
  publisher = {arXiv},
  
  year = {2018},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{RWR,
author = {Peters, Jan and Schaal, Stefan},
title = {Reinforcement Learning by Reward-Weighted Regression for Operational Space Control},
year = {2007},
isbn = {9781595937933},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1273496.1273590},
doi = {10.1145/1273496.1273590},
abstract = {Many robot control problems of practical importance, including operational space control, can be reformulated as immediate reward reinforcement learning problems. However, few of the known optimization or reinforcement learning algorithms can be used in online learning control for robots, as they are either prohibitively slow, do not scale to interesting domains of complex robots, or require trying out policies generated by random search, which are infeasible for a physical system. Using a generalization of the EM-base reinforcement learning framework suggested by Dayan & Hinton, we reduce the problem of learning with immediate rewards to a reward-weighted regression problem with an adaptive, integrated reward transformation for faster convergence. The resulting algorithm is efficient, learns smoothly without dangerous jumps in solution space, and works well in applications of complex high degree-of-freedom robots.},
booktitle = {Proceedings of the 24th International Conference on Machine Learning},
pages = {745–750},
numpages = {6},
location = {Corvalis, Oregon, USA},
series = {ICML '07}
}

@article{sonabend2020expert,
  title={Expert-supervised reinforcement learning for offline policy learning and evaluation},
  author={Sonabend, Aaron and Lu, Junwei and Celi, Leo Anthony and Cai, Tianxi and Szolovits, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={18967--18977},
  year={2020}
}

@misc{https://doi.org/10.48550/arxiv.1904.12901,
  doi = {10.48550/ARXIV.1904.12901},
  
  url = {https://arxiv.org/abs/1904.12901},
  
  author = {Dulac-Arnold, Gabriel and Mankowitz, Daniel and Hester, Todd},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Robotics (cs.RO), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Challenges of Real-World Reinforcement Learning},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{thomas2020annual,
  title={Annual Report on US Manufacturing Industry Statistics: 2020},
  author={Thomas, Douglas S and others},
  year={2020},
  publisher={Gaithersburg, Md.: National Institute of Standards and Technology}
}

@inproceedings{mahadevan1998optimizing,
  title={Optimizing Production Manufacturing Using Reinforcement Learning.},
  author={Mahadevan, Sridhar and Theocharous, Georgios},
  booktitle={FLAIRS conference},
  volume={372},
  pages={377},
  year={1998}
}

@article{OVERBECK2021170,
title = {Reinforcement Learning Based Production Control of Semi-automated Manufacturing Systems},
journal = {Procedia CIRP},
volume = {103},
pages = {170-175},
year = {2021},
note = {9th CIRP Global Web Conference – Sustainable, resilient, and agile manufacturing and service operations : Lessons from COVID-19},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2021.10.027},
url = {https://www.sciencedirect.com/science/article/pii/S2212827121008684},
author = {Leonard Overbeck and Adrien Hugues and Marvin Carl May and Andreas Kuhnle and Gisela Lanza},
keywords = {Machine Learning, Reinforcement Learning, Digital Twin, Production Control, Task Allocation, Productivity},
abstract = {In an environment which is marked by an increasing speed of changes, industrial companies have to be able to quickly adapt to new market demands and innovative technologies. This leads to a need for continuous adaption of existing production systems and the optimization of their production control. To tackle this problem digitalization of production systems has become essential for new and existing systems. Digital twins based on simulations of real production systems allow the simplification of analysis processes and, thus, a better understanding of the systems, which leads to broad optimization possibilities. In parallel, machine learning methods can be integrated to process the numerical data and discover new production control strategies. In this work, these two methods are combined to derive a production control logic in a semi-automated production system based on the chaku-chaku principle. A reinforcement learning method is integrated into the digital twin to autonomously learn a superior production control logic for the distribution of tasks between the different workers on a production line. By analyzing the influence of different reward shaping and hyper-parameter optimization on the quality and stability of the results obtained, the use of a well-configured policy-based algorithm enables an efficient management of the workers and the deduction of an optimal production control logic for the production system. The algorithm manages to define a control logic that leads to an increase in productivity while having a stable task assignment so that a transfer to daily business is possible. The approach is validated in the digital twin of a real assembly line of an automotive supplier. The results obtained suggest a new approach to optimizing production control in production lines. Production control shall be centered directly on the workers’ routines and controlled by artificial intelligence infused with a global overview of the entire production system.}
}

@misc{https://doi.org/10.48550/arxiv.2107.03015,
  doi = {10.48550/ARXIV.2107.03015},
  
  url = {https://arxiv.org/abs/2107.03015},
  
  author = {Garau-Luis, Juan Jose and Crawley, Edward and Cameron, Bruce},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Evaluating the progress of Deep Reinforcement Learning in the real world: aligning domain-agnostic and domain-specific research},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}

@article{smac,
  title = {{The} {StarCraft} {Multi}-{Agent} {Challenge}},
  author = {Mikayel Samvelyan and Tabish Rashid and Christian Schroeder de Witt and Gregory Farquhar and Nantas Nardelli and Tim G. J. Rudner and Chia-Man Hung and Philiph H. S. Torr and Jakob Foerster and Shimon Whiteson},
  journal = {CoRR},
  volume = {abs/1902.04043},
  year = {2019},
}

@article{wydmuch2018vizdoom,
  title={ViZDoom Competitions: Playing Doom from Pixels},
  author={Wydmuch, Marek and Kempka, Micha{\l} and Ja{\'s}kowski, Wojciech},
  journal={IEEE Transactions on Games},
  year={2018},
  publisher={IEEE}
}

@article{https://doi.org/10.48550/arxiv.2109.06780,
  doi = {10.48550/ARXIV.2109.06780},
  
  url = {https://arxiv.org/abs/2109.06780},
  
  author = {Hafner, Danijar},
  
  keywords = {Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Benchmarking the Spectrum of Agent Capabilities},
  
  publisher = {arXiv},
  
  year = {2021},
  
  journal={arXiv preprint arXiv:2109.06780},

  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{LanctotEtAl2019OpenSpiel,
  title     = {{OpenSpiel}: A Framework for Reinforcement Learning in Games},
  author    = {Marc Lanctot and Edward Lockhart and Jean-Baptiste Lespiau and
               Vinicius Zambaldi and Satyaki Upadhyay and Julien P\'{e}rolat and
               Sriram Srinivasan and Finbarr Timbers and Karl Tuyls and
               Shayegan Omidshafiei and Daniel Hennes and Dustin Morrill and
               Paul Muller and Timo Ewalds and Ryan Faulkner and J\'{a}nos Kram\'{a}r
               and Bart De Vylder and Brennan Saeta and James Bradbury and David Ding
               and Sebastian Borgeaud and Matthew Lai and Julian Schrittwieser and
               Thomas Anthony and Edward Hughes and Ivo Danihelka and Jonah Ryan-Davis},
  year      = {2019},
  eprint    = {1908.09453},
  archivePrefix = {arXiv},
  primaryClass = {cs.LG},
  journal   = {CoRR},
  volume    = {abs/1908.09453},
  url       = {http://arxiv.org/abs/1908.09453},
}

@inproceedings{ns3gym,
  Title = {{ns-3 meets OpenAI Gym: The Playground for Machine Learning in Networking Research}},
  Author = {Gaw{\l}owicz, Piotr and Zubow, Anatolij},
  Booktitle = {{ACM International Conference on Modeling, Analysis and Simulation of Wireless and Mobile Systems (MSWiM)}},
  Year = {2019},
  Location = {Miami Beach, USA},
  Month = {November},
  Url = {http://www.tkn.tu-berlin.de/fileadmin/fg112/Papers/2019/gawlowicz19_mswim.pdf}
}

@article{rohde2018recogym,
  title={RecoGym: A Reinforcement Learning Environment for the problem of Product Recommendation in Online Advertising},
  author={Rohde, David and Bonner, Stephen and Dunlop, Travis and Vasile, Flavian and Karatzoglou, Alexandros},
  journal={arXiv preprint arXiv:1808.00720},
  year={2018}
}

@article{cote18textworld,
  author = {Marc-Alexandre C\^ot\'e and
            \'Akos K\'ad\'ar and
            Xingdi Yuan and
            Ben Kybartas and
            Tavian Barnes and
            Emery Fine and
            James Moore and
            Ruo Yu Tao and
            Matthew Hausknecht and
            Layla El Asri and
            Mahmoud Adada and
            Wendy Tay and
            Adam Trischler},
  title = {TextWorld: A Learning Environment for Text-based Games},
  journal = {CoRR},
  volume = {abs/1806.11532},
  year = {2018}
}

@inproceedings{airsim2017fsr,
  author = {Shital Shah and Debadeepta Dey and Chris Lovett and Ashish Kapoor},
  title = {AirSim: High-Fidelity Visual and Physical Simulation for Autonomous Vehicles},
  year = {2017},
  booktitle = {Field and Service Robotics},
  eprint = {arXiv:1705.05065},
  url = {https://arxiv.org/abs/1705.05065}
}

@article{dm_control,
	doi = {10.1016/j.simpa.2020.100022},
  
	url = {https://doi.org/10.1016%2Fj.simpa.2020.100022},
  
	year = 2020,
	month = {nov},
  
	publisher = {Elsevier {BV}
},
  
	volume = {6},
  
	pages = {100022},
  
	author = {Saran Tunyasuvunakool and Alistair Muldal and Yotam Doron and Siqi Liu and Steven Bohez and Josh Merel and Tom Erez and Timothy Lillicrap and Nicolas Heess and Yuval Tassa},
  
	title = {dm{\_}control: Software and tasks for continuous control},
  
	journal = {Software Impacts}
}

@article{dota2,
  doi = {10.48550/ARXIV.1912.06680},
  
  url = {https://arxiv.org/abs/1912.06680},
  
  author = {{OpenAI} and {:} and Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and Dębiak, Przemysław and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and Józefowicz, Rafal and Gray, Scott and Olsson, Catherine and Pachocki, Jakub and Petrov, Michael and Pinto, Henrique P. d. O. and Raiman, Jonathan and Salimans, Tim and Schlatter, Jeremy and Schneider, Jonas and Sidor, Szymon and Sutskever, Ilya and Tang, Jie and Wolski, Filip and Zhang, Susan},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Dota 2 with Large Scale Deep Reinforcement Learning},
  
  publisher = {arXiv},
  
  year = {2019},
  
  journal = {arXiv preprint arXiv:1912.06680},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@book{mpc,
  title={Model predictive control},
  author={Camacho, Eduardo F and Alba, Carlos Bordons},
  year={2013},
  publisher={Springer science \& business media}
}

@INPROCEEDINGS{empc,
  author={Rawlings, James B. and Angeli, David and Bates, Cuyler N.},
  booktitle={2012 IEEE 51st IEEE Conference on Decision and Control (CDC)}, 
  title={Fundamentals of economic model predictive control}, 
  year={2012},
  volume={},
  number={},
  pages={3851-3861},
  doi={10.1109/CDC.2012.6425822}}
  
@article{nam2022skillbased,
  title={Skill-based Meta-Reinforcement Learning},
  author={Nam, Taewook and Sun, Shao-Hua and Pertsch, Karl and Hwang, Sung Ju and Lim, Joseph J},
  journal={arXiv preprint arXiv:2204.11828},
  year={2022}
}

@inproceedings{luo2022adapt,
  title={Adapt to Environment Sudden Changes by Learning a Context Sensitive Policy},
  author={Luo, Fan-Ming and Jiang, Shengyi and Yu, Yang and Zhang, Zongzhang and Zhang, Yi-Feng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence, Virtual Event},
  year={2022}
}

@inproceedings{bayesian,
  title={On Bayesian methods for seeking the extremum},
  author={Mo{\v{c}}kus, Jonas},
  booktitle={Optimization techniques IFIP technical conference},
  pages={400--404},
  year={1975},
  organization={Springer}
}

@article{MOPO,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James Y and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={14129--14142},
  year={2020}
}

@article{COMBO,
  title={Combo: Conservative offline model-based policy optimization},
  author={Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={28954--28967},
  year={2021}
}

@inproceedings{A2CA3C,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016},
  organization={PMLR}
}

@article{ARS,
  doi = {10.48550/ARXIV.1803.07055},
  
  url = {https://arxiv.org/abs/1803.07055},
  
  author = {Mania, Horia and Guy, Aurelia and Recht, Benjamin},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Optimization and Control (math.OC), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics},
  
  title = {Simple random search provides a competitive approach to reinforcement learning},
  
  publisher = {arXiv},
  
  year = {2018},
  
  journal={arXiv preprint arXiv:1803.07055},

  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{gfootball,
  title={Google research football: A novel reinforcement learning environment},
  author={Kurach, Karol and Raichuk, Anton and Sta{\'n}czyk, Piotr and Zaj{\k{a}}c, Micha{\l} and Bachem, Olivier and Espeholt, Lasse and Riquelme, Carlos and Vincent, Damien and Michalski, Marcin and Bousquet, Olivier and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={4501--4510},
  year={2020}
}

@inproceedings{mujoco,
  title={MuJoCo: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE},
  doi={10.1109/IROS.2012.6386109}
}

@article{moreisdifferent,
author = {P. W. Anderson },
title = {More Is Different},
journal = {Science},
volume = {177},
number = {4047},
pages = {393-396},
year = {1972},
doi = {10.1126/science.177.4047.393},
URL = {https://www.science.org/doi/abs/10.1126/science.177.4047.393},
eprint = {https://www.science.org/doi/pdf/10.1126/science.177.4047.393}}


@article{he2021deep,
  title={A deep reinforcement learning based multi-criteria decision support system for optimizing textile chemical process},
  author={He, Zhenglei and Tran, Kim-Phuc and Thomassey, Sebastien and Zeng, Xianyi and Xu, Jie and Yi, Changhai},
  journal={Computers in Industry},
  volume={125},
  pages={103373},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{10.1145/3424311.3424326,
author = {Wang, Lei and Wang, Yang},
title = {Application of Machine Learning for Process Control in Semiconductor Manufacturing},
year = {2020},
isbn = {9781450377348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3424311.3424326},
doi = {10.1145/3424311.3424326},
abstract = {In this article, the authors attempt to describe the core quality inspection during semiconductor manufacturing in terms of production efficiency and yield. Special focus is therefore given to photolithography, which is the most critical step for the fabrication of wafer patterns in front-end processes. Further, machine learning approaches are demonstrated and their applicability in semiconductor manufacturing industry is discussed. Also, a technical concept regarding virtual metrology for advanced process control in semiconductor production is introduced as a potential utilization case. Finally, current status and future trends in technology as well as application are summarized based on authors' perspective in the concluding section.},
booktitle = {Proceedings of the 2020 International Conference on Internet Computing for Science and Engineering},
pages = {109–111},
numpages = {3},
keywords = {Machine learning, Semiconductor manufacturing, Advanced process control, Virtual metrology, Data analytics},
location = {Male, Maldives},
series = {ICICSE '20}
}

@article{govindaiah2021applying,
  title={Applying reinforcement learning to plan manufacturing material handling},
  author={Govindaiah, Swetha and Petty, Mikel D},
  journal={Discover Artificial Intelligence},
  volume={1},
  number={1},
  pages={1--33},
  year={2021},
  publisher={Springer}
}
