\begin{thebibliography}{66}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Anastasopoulos et~al.(2021)Anastasopoulos, Bojar, Bremerman, Cattoni,
  Elbayad, Federico, Ma, Nakamura, Negri, Niehues,
  et~al.]{anastasopoulos2021findings}
Anastasopoulos, A., Bojar, O., Bremerman, J., Cattoni, R., Elbayad, M.,
  Federico, M., Ma, X., Nakamura, S., Negri, M., Niehues, J., et~al.
\newblock Findings of the {IWSLT} 2021 evaluation campaign.
\newblock In \emph{International Conference on Spoken Language Translation
  (IWSLT)}, 2021.

\bibitem[Ansari et~al.(2020)Ansari, Axelrod, Bach, Bojar, Cattoni, Dalvi,
  Durrani, Federico, Federmann, Gu, et~al.]{ansari2020findings}
Ansari, E., Axelrod, A., Bach, N., Bojar, O., Cattoni, R., Dalvi, F., Durrani,
  N., Federico, M., Federmann, C., Gu, J., et~al.
\newblock Findings of the {IWSLT} 2020 evaluation campaign.
\newblock In \emph{International Conference on Spoken Language Translation
  (IWSLT)}, 2020.

\bibitem[Ardila et~al.(2020)Ardila, Branson, Davis, Henretty, Kohler, Meyer,
  Morais, Saunders, Tyers, and Weber]{ardila2020common}
Ardila, R., Branson, M., Davis, K., Henretty, M., Kohler, M., Meyer, J.,
  Morais, R., Saunders, L., Tyers, F.~M., and Weber, G.
\newblock {Common Voice}: A massively-multilingual speech corpus.
\newblock In \emph{Proceedings of Language Resources and Evaluation Conference
  (LREC)}, 2020.

\bibitem[Baevski et~al.(2020)Baevski, Zhou, Mohamed, and
  Auli]{baevski2020wav2vec}
Baevski, A., Zhou, H., Mohamed, A., and Auli, M.
\newblock wav2vec 2.0: A framework for self-supervised learning of speech
  representations.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2020.

\bibitem[Battenberg et~al.(2020)Battenberg, Skerry-Ryan, Mariooryad, Stanton,
  Kao, Shannon, and Bagby]{battenberg2020location}
Battenberg, E., Skerry-Ryan, R., Mariooryad, S., Stanton, D., Kao, D., Shannon,
  M., and Bagby, T.
\newblock Location-relative attention mechanisms for robust long-form speech
  synthesis.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, 2020.

\bibitem[Chen et~al.(2019)Chen, Chen, Liang, Ma, Chen, Wang, and
  Xiao]{chen2019cross}
Chen, M., Chen, M., Liang, S., Ma, J., Chen, L., Wang, S., and Xiao, J.
\newblock Cross-lingual, multi-speaker text-to-speech synthesis using neural
  speaker embedding.
\newblock In \emph{Proc. Interspeech}, 2019.

\bibitem[Chiu et~al.(2018)Chiu, Tripathi, Chou, Co, Jaitly, Jaunzeikare,
  Kannan, Nguyen, Sak, Sankar, Tansuwan, Wan, Wu, and Zhang]{chiu2017speech}
Chiu, C.-C., Tripathi, A., Chou, K., Co, C., Jaitly, N., Jaunzeikare, D.,
  Kannan, A., Nguyen, P., Sak, H., Sankar, A., Tansuwan, J., Wan, N., Wu, Y.,
  and Zhang, X.
\newblock Speech recognition for medical conversations.
\newblock In \emph{Proc. Interspeech}, 2018.

\bibitem[Di~Gangi et~al.(2019)Di~Gangi, Negri, and Turchi]{di2019one}
Di~Gangi, M.~A., Negri, M., and Turchi, M.
\newblock One-to-many multilingual end-to-end speech translation.
\newblock In \emph{IEEE Automatic Speech Recognition and Understanding Workshop
  (ASRU)}, 2019.

\bibitem[Elias et~al.(2021{\natexlab{a}})Elias, Zen, Shen, Zhang, Jia,
  Skerry-Ryan, and Wu]{elias2021parallel}
Elias, I., Zen, H., Shen, J., Zhang, Y., Jia, Y., Skerry-Ryan, R., and Wu, Y.
\newblock {Parallel Tacotron 2}: A non-autoregressive neural {TTS} model with
  differentiable duration modeling.
\newblock In \emph{Proc. Interspeech}, 2021{\natexlab{a}}.

\bibitem[Elias et~al.(2021{\natexlab{b}})Elias, Zen, Shen, Zhang, Jia, Weiss,
  and Wu]{elias2020parallel}
Elias, I., Zen, H., Shen, J., Zhang, Y., Jia, Y., Weiss, R., and Wu, Y.
\newblock {Parallel Tacotron}: Non-autoregressive and controllable {TTS}.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, 2021{\natexlab{b}}.

\bibitem[Griffin \& Lim(1984)Griffin and Lim]{griffin1984signal}
Griffin, D. and Lim, J.
\newblock Signal estimation from modified short-time {F}ourier transform.
\newblock \emph{IEEE Transactions on Acoustics, Speech, and Signal Processing},
  32\penalty0 (2):\penalty0 236--243, 1984.

\bibitem[Gulati et~al.(2020)Gulati, Qin, Chiu, Parmar, Zhang, Yu, Han, Wang,
  Zhang, Wu, and Pang]{gulati2020conformer}
Gulati, A., Qin, J., Chiu, C.-C., Parmar, N., Zhang, Y., Yu, J., Han, W., Wang,
  S., Zhang, Z., Wu, Y., and Pang, R.
\newblock Conformer: Convolution-augmented transformer for speech recognition.
\newblock In \emph{Proc. Interspeech}, 2020.

\bibitem[Guo et~al.(2021)Guo, Boyer, Chang, Hayashi, Higuchi, Inaguma, Kamo,
  Li, Garcia-Romero, Shi, et~al.]{guo2021recent}
Guo, P., Boyer, F., Chang, X., Hayashi, T., Higuchi, Y., Inaguma, H., Kamo, N.,
  Li, C., Garcia-Romero, D., Shi, J., et~al.
\newblock Recent developments on espnet toolkit boosted by conformer.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pp.\  5874--5878, 2021.

\bibitem[He et~al.(2019)He, Deng, and He]{he2019robust}
He, M., Deng, Y., and He, L.
\newblock Robust sequence-to-sequence acoustic modeling with stepwise monotonic
  attention for neural {TTS}.
\newblock In \emph{Proc. Interspeech}, 2019.

\bibitem[Hochreiter \& Schmidhuber(1997)Hochreiter and
  Schmidhuber]{hochreiter1997long}
Hochreiter, S. and Schmidhuber, J.
\newblock Long short-term memory.
\newblock \emph{Neural computation}, 9\penalty0 (8):\penalty0 1735--1780, 1997.

\bibitem[Hwang et~al.(2021)Hwang, Yamamoto, Song, and Kim]{hwang2021tts}
Hwang, M.-J., Yamamoto, R., Song, E., and Kim, J.-M.
\newblock {TTS-by-TTS}: {TTS}-driven data augmentation for fast and
  high-quality speech synthesis.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pp.\  6598--6602, 2021.

\bibitem[{ITU}(2016)]{itu-f745}
{ITU}.
\newblock {ITU-T} {F.745}: Functional requirements for network-based
  speech-to-speech translation services, 2016.
\newblock {International Telecommunication Union}.

\bibitem[Jia et~al.(2018)Jia, Zhang, Weiss, Wang, Shen, Ren, Chen, Nguyen,
  Pang, Moreno, and Wu]{jia2018transfer}
Jia, Y., Zhang, Y., Weiss, R.~J., Wang, Q., Shen, J., Ren, F., Chen, Z.,
  Nguyen, P., Pang, R., Moreno, I.~L., and Wu, Y.
\newblock Transfer learning from speaker verification to multispeaker
  text-to-speech synthesis.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2018.

\bibitem[Jia et~al.(2019{\natexlab{a}})Jia, Johnson, Macherey, Weiss, Cao,
  Chiu, Ari, Laurenzo, and Wu]{jia2019leveraging}
Jia, Y., Johnson, M., Macherey, W., Weiss, R.~J., Cao, Y., Chiu, C.-C., Ari,
  N., Laurenzo, S., and Wu, Y.
\newblock Leveraging weakly supervised data to improve end-to-end
  speech-to-text translation.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, 2019{\natexlab{a}}.

\bibitem[Jia et~al.(2019{\natexlab{b}})Jia, Weiss, Biadsy, Macherey, Johnson,
  Chen, and Wu]{jia2019direct}
Jia, Y., Weiss, R.~J., Biadsy, F., Macherey, W., Johnson, M., Chen, Z., and Wu,
  Y.
\newblock Direct speech-to-speech translation with a sequence-to-sequence
  model.
\newblock In \emph{Proc. Interspeech}, 2019{\natexlab{b}}.

\bibitem[Jia et~al.(2021)Jia, Zen, Shen, Zhang, and Wu]{jia2021png}
Jia, Y., Zen, H., Shen, J., Zhang, Y., and Wu, Y.
\newblock {PnG BERT}: Augmented {BERT} on phonemes and graphemes for neural
  {TTS}.
\newblock In \emph{Proc. Interspeech}, 2021.

\bibitem[Jia et~al.(2022)Jia, Tadmor~Ramanovich, Wang, and Zen]{jia2022cvss}
Jia, Y., Tadmor~Ramanovich, M., Wang, Q., and Zen, H.
\newblock {CVSS} corpus and massively multilingual speech-to-speech
  translation.
\newblock In \emph{Proceedings of Language Resources and Evaluation Conference
  (LREC)}, 2022.

\bibitem[Kahn et~al.(2020)Kahn, Rivi{\`e}re, Zheng, Kharitonov, Xu, Mazar{\'e},
  Karadayi, Liptchinsky, Collobert, Fuegen, Likhomanenko, Synnaeve, Joulin,
  Mohamed, and Dupoux]{kahn2020libri}
Kahn, J., Rivi{\`e}re, M., Zheng, W., Kharitonov, E., Xu, Q., Mazar{\'e},
  P.-E., Karadayi, J., Liptchinsky, V., Collobert, R., Fuegen, C.,
  Likhomanenko, T., Synnaeve, G., Joulin, A., Mohamed, A., and Dupoux, E.
\newblock Libri-light: A benchmark for {ASR} with limited or no supervision.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, 2020.

\bibitem[Kalchbrenner et~al.(2018)Kalchbrenner, Elsen, Simonyan, Noury,
  Casagrande, Lockhart, Stimberg, Oord, Dieleman, and
  Kavukcuoglu]{kalchbrenner2018efficient}
Kalchbrenner, N., Elsen, E., Simonyan, K., Noury, S., Casagrande, N., Lockhart,
  E., Stimberg, F., Oord, A. v.~d., Dieleman, S., and Kavukcuoglu, K.
\newblock Efficient neural audio synthesis.
\newblock In \emph{Proceedings of International Conference on Machine Learning
  (ICML)}, 2018.

\bibitem[Kano et~al.(2021)Kano, Sakti, and Nakamura]{kano2021transformer}
Kano, T., Sakti, S., and Nakamura, S.
\newblock Transformer-based direct speech-to-speech translation with
  transcoder.
\newblock In \emph{IEEE Spoken Language Technology Workshop (SLT)}, 2021.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{kingma2015adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2015.

\bibitem[Krueger et~al.(2017)Krueger, Maharaj, Kram{\'a}r, Pezeshki, Ballas,
  Ke, Goyal, Bengio, Courville, and Pal]{krueger2017zoneout}
Krueger, D., Maharaj, T., Kram{\'a}r, J., Pezeshki, M., Ballas, N., Ke, N.~R.,
  Goyal, A., Bengio, Y., Courville, A., and Pal, C.
\newblock Zoneout: Regularizing {RNNs} by randomly preserving hidden
  activations.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2017.

\bibitem[Lavie et~al.(1997)Lavie, Waibel, Levin, Finke, Gates, Gavalda,
  Zeppenfeld, and Zhan]{lavie1997janus}
Lavie, A., Waibel, A., Levin, L., Finke, M., Gates, D., Gavalda, M.,
  Zeppenfeld, T., and Zhan, P.
\newblock {JANUS-III}: Speech-to-speech translation in multiple languages.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, 1997.

\bibitem[Lee et~al.(2021{\natexlab{a}})Lee, Gong, Duquenne, Schwenk, Chen,
  Wang, Popuri, Pino, Gu, and Hsu]{lee2021textless}
Lee, A., Gong, H., Duquenne, P.-A., Schwenk, H., Chen, P.-J., Wang, C., Popuri,
  S., Pino, J., Gu, J., and Hsu, W.-N.
\newblock Textless speech-to-speech translation on real data.
\newblock \emph{arXiv preprint arXiv:2112.08352}, 2021{\natexlab{a}}.

\bibitem[Lee et~al.(2022)Lee, Chen, Wang, Gu, Ma, Polyak, Adi, He, Tang, Pino,
  et~al.]{lee2021direct}
Lee, A., Chen, P.-J., Wang, C., Gu, J., Ma, X., Polyak, A., Adi, Y., He, Q.,
  Tang, Y., Pino, J., et~al.
\newblock Direct speech-to-speech translation with discrete units.
\newblock In \emph{Proceedings of Annual Meeting of the Association for
  Computational Linguistics (ACL)}, 2022.

\bibitem[Lee et~al.(2021{\natexlab{b}})Lee, Shin, and
  Jung]{lee2021bidirectional}
Lee, Y., Shin, J., and Jung, K.
\newblock Bidirectional variational inference for non-autoregressive
  text-to-speech.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2021{\natexlab{b}}.

\bibitem[Ma et~al.(2021)Ma, Gong, Liu, Lee, Tang, Chen, Hsu, Heafield, Koehn,
  and Pino]{ma2021direct}
Ma, X., Gong, H., Liu, D., Lee, A., Tang, Y., Chen, P.-J., Hsu, W.-N.,
  Heafield, K., Koehn, P., and Pino, J.
\newblock Direct simultaneous speech to speech translation.
\newblock \emph{arXiv preprint arXiv:2110.08250}, 2021.

\bibitem[McCarthy et~al.(2020)McCarthy, Puzon, and
  Pino]{mccarthy2020skinaugment}
McCarthy, A.~D., Puzon, L., and Pino, J.
\newblock {SkinAugment}: Auto-encoding speaker conversions for automatic speech
  translation.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, 2020.

\bibitem[Nakamura et~al.(2006)Nakamura, Markov, Nakaiwa, Kikui, Kawai,
  Jitsuhiro, Zhang, Yamamoto, Sumita, and Yamamoto]{nakamura2006atr}
Nakamura, S., Markov, K., Nakaiwa, H., Kikui, G., Kawai, H., Jitsuhiro, T.,
  Zhang, J.-S., Yamamoto, H., Sumita, E., and Yamamoto, S.
\newblock The {ATR} multilingual speech-to-speech translation system.
\newblock \emph{IEEE Transactions on Audio, Speech, and Language Processing},
  2006.

\bibitem[Narayanan et~al.(2019)Narayanan, Prabhavalkar, Chiu, Rybach, Sainath,
  and Strohman]{narayanan2019recognizing}
Narayanan, A., Prabhavalkar, R., Chiu, C.-C., Rybach, D., Sainath, T.~N., and
  Strohman, T.
\newblock Recognizing long-form speech using streaming end-to-end models.
\newblock In \emph{IEEE Automatic Speech Recognition and Understanding Workshop
  (ASRU)}, 2019.

\bibitem[Oord et~al.(2018)Oord, Li, Babuschkin, Simonyan, Vinyals, Kavukcuoglu,
  Driessche, Lockhart, Cobo, Stimberg, et~al.]{oord2018parallel}
Oord, A., Li, Y., Babuschkin, I., Simonyan, K., Vinyals, O., Kavukcuoglu, K.,
  Driessche, G., Lockhart, E., Cobo, L., Stimberg, F., et~al.
\newblock Parallel {WaveNet}: Fast high-fidelity speech synthesis.
\newblock In \emph{Proceedings of International Conference on Machine Learning
  (ICML)}, 2018.

\bibitem[Oord et~al.(2017)Oord, Vinyals, and Kavukcuoglu]{oord2017neural}
Oord, A. v.~d., Vinyals, O., and Kavukcuoglu, K.
\newblock Neural discrete representation learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2017.

\bibitem[Panayotov et~al.(2015)Panayotov, Chen, Povey, and
  Khudanpur]{panayotov2015librispeech}
Panayotov, V., Chen, G., Povey, D., and Khudanpur, S.
\newblock {LibriSpeech}: an {ASR} corpus based on public domain audio books.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, 2015.

\bibitem[Park et~al.(2019)Park, Chan, Zhang, Chiu, Zoph, Cubuk, and
  Le]{park2019specaugment}
Park, D.~S., Chan, W., Zhang, Y., Chiu, C.-C., Zoph, B., Cubuk, E.~D., and Le,
  Q.~V.
\newblock {SpecAugment}: A simple data augmentation method for automatic speech
  recognition.
\newblock In \emph{Proc. Interspeech}, 2019.

\bibitem[Park et~al.(2020)Park, Zhang, Jia, Han, Chiu, Li, Wu, and
  Le]{park2020improved}
Park, D.~S., Zhang, Y., Jia, Y., Han, W., Chiu, C.-C., Li, B., Wu, Y., and Le,
  Q.~V.
\newblock Improved noisy student training for automatic speech recognition.
\newblock In \emph{Proc. Interspeech}, 2020.

\bibitem[Pathak \& Raj(2012)Pathak and Raj]{pathak2012privacy}
Pathak, M.~A. and Raj, B.
\newblock Privacy-preserving speaker verification and identification using
  {Gaussian} mixture models.
\newblock \emph{IEEE Transactions on Audio, Speech, and Language Processing},
  21\penalty0 (2):\penalty0 397--406, 2012.

\bibitem[Peng et~al.(2020)Peng, Ping, Song, and Zhao]{peng2020non}
Peng, K., Ping, W., Song, Z., and Zhao, K.
\newblock Non-autoregressive neural text-to-speech.
\newblock In \emph{Proceedings of International Conference on Machine Learning
  (ICML)}, 2020.

\bibitem[Post et~al.(2013)Post, Kumar, Lopez, Karakos, Callison-Burch, and
  Khudanpur]{post2013improved}
Post, M., Kumar, G., Lopez, A., Karakos, D., Callison-Burch, C., and Khudanpur,
  S.
\newblock Improved speech-to-text translation with the {Fisher and Callhome
  Spanish--English} speech translation corpus.
\newblock In \emph{International Conference on Spoken Language Translation
  (IWSLT)}, 2013.

\bibitem[Ren et~al.(2019)Ren, Ruan, Tan, Qin, Zhao, Zhao, and
  Liu]{ren2019fastspeech}
Ren, Y., Ruan, Y., Tan, X., Qin, T., Zhao, S., Zhao, Z., and Liu, T.-Y.
\newblock {FastSpeech}: Fast, robust and controllable text to speech.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2019.

\bibitem[Ren et~al.(2021)Ren, Hu, Qin, Zhao, Zhao, and Liu]{ren2020fastspeech2}
Ren, Y., Hu, C., Qin, T., Zhao, S., Zhao, Z., and Liu, T.-Y.
\newblock {FastSpeech} 2: Fast and high-quality end-to-end text-to-speech.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2021.

\bibitem[Salesky et~al.(2021)Salesky, M{\"a}der, and
  Klinger]{salesky2021assessing}
Salesky, E., M{\"a}der, J., and Klinger, S.
\newblock Assessing evaluation metrics for speech-to-speech translation.
\newblock In \emph{IEEE Automatic Speech Recognition and Understanding Workshop
  (ASRU)}, 2021.

\bibitem[Shen et~al.(2018)Shen, Pang, Weiss, Schuster, Jaitly, Yang, Chen,
  Zhang, Wang, Skerrv-Ryan, Saurous, Agiomyrgiannakis, and Wu]{shen2018natural}
Shen, J., Pang, R., Weiss, R.~J., Schuster, M., Jaitly, N., Yang, Z., Chen, Z.,
  Zhang, Y., Wang, Y., Skerrv-Ryan, R., Saurous, R.~A., Agiomyrgiannakis, Y.,
  and Wu, Y.
\newblock Natural {TTS} synthesis by conditioning {WaveNet} on {Mel}
  spectrogram predictions.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, 2018.

\bibitem[Shen et~al.(2019)Shen, Nguyen, Wu, Chen, et~al.]{shen2019lingvo}
Shen, J., Nguyen, P., Wu, Y., Chen, Z., et~al.
\newblock Lingvo: A modular and scalable framework for sequence-to-sequence
  modeling.
\newblock \emph{arXiv preprint arXiv:1902.08295}, 2019.

\bibitem[Shen et~al.(2020)Shen, Jia, Chrzanowski, Zhang, Elias, Zen, and
  Wu]{shen2020non}
Shen, J., Jia, Y., Chrzanowski, M., Zhang, Y., Elias, I., Zen, H., and Wu, Y.
\newblock Non-{A}ttentive {T}acotron: Robust and controllable neural {TTS}
  synthesis including unsupervised duration modeling.
\newblock \emph{arXiv preprint arXiv:2010.04301}, 2020.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and
  Wojna]{szegedy2016rethinking}
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z.
\newblock Rethinking the inception architecture for computer vision.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pp.\  2818--2826, 2016.

\bibitem[Tjandra et~al.(2019)Tjandra, Sakti, and Nakamura]{tjandra2019speech}
Tjandra, A., Sakti, S., and Nakamura, S.
\newblock Speech-to-speech translation between untranscribed unknown languages.
\newblock In \emph{IEEE Automatic Speech Recognition and Understanding Workshop
  (ASRU)}, 2019.

\bibitem[Todisco et~al.(2019)Todisco, Wang, Vestman, Sahidullah, Delgado,
  Nautsch, Yamagishi, Evans, Kinnunen, and Lee]{todisco2019asvspoof}
Todisco, M., Wang, X., Vestman, V., Sahidullah, M., Delgado, H., Nautsch, A.,
  Yamagishi, J., Evans, N., Kinnunen, T., and Lee, K.~A.
\newblock {ASVspoof 2019}: Future horizons in spoofed and fake audio detection.
\newblock In \emph{Proc. Interspeech}, 2019.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, L., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2017.

\bibitem[Wagner et~al.(2019)Wagner, Beskow, Betz, Edlund, Gustafson,
  Eje~Henter, Le~Maguer, Malisz, Sz{\'e}kely, T{\aa}nnander,
  et~al.]{wagner2019speech}
Wagner, P., Beskow, J., Betz, S., Edlund, J., Gustafson, J., Eje~Henter, G.,
  Le~Maguer, S., Malisz, Z., Sz{\'e}kely, {\'E}., T{\aa}nnander, C., et~al.
\newblock Speech synthesis evaluation -- state-of-the-art assessment and
  suggestion for a novel research program.
\newblock In \emph{Proceedings of the 10th Speech Synthesis Workshop (SSW10)},
  2019.

\bibitem[Wahlster(2000)]{wahlster2000verbmobil}
Wahlster, W.
\newblock \emph{Verbmobil: Foundations of speech-to-speech translation}.
\newblock Springer, 2000.

\bibitem[Wan et~al.(2018)Wan, Wang, Papir, and Moreno]{wan2018generalized}
Wan, L., Wang, Q., Papir, A., and Moreno, I.~L.
\newblock Generalized end-to-end loss for speaker verification.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, 2018.

\bibitem[Wang et~al.(2021{\natexlab{a}})Wang, Wu, and Pino]{wang2020covost}
Wang, C., Wu, A., and Pino, J.
\newblock {CoVoST 2}: A massively multilingual speech-to-text translation
  corpus.
\newblock In \emph{Proc. Interspeech}, 2021{\natexlab{a}}.

\bibitem[Wang et~al.(2021{\natexlab{b}})Wang, Wu, Pino, Baevski, Auli, and
  Conneau]{wang2021large}
Wang, C., Wu, A., Pino, J., Baevski, A., Auli, M., and Conneau, A.
\newblock Large-scale self-and semi-supervised learning for speech translation.
\newblock In \emph{Proc. Interspeech}, 2021{\natexlab{b}}.

\bibitem[Wang et~al.(2020)Wang, Yamagishi, Todisco, Delgado, Nautsch, Evans,
  Sahidullah, Vestman, Kinnunen, Lee, et~al.]{wang2020asvspoof}
Wang, X., Yamagishi, J., Todisco, M., Delgado, H., Nautsch, A., Evans, N.,
  Sahidullah, M., Vestman, V., Kinnunen, T., Lee, K.~A., et~al.
\newblock {ASVspoof 2019}: A large-scale public database of synthesized,
  converted and replayed speech.
\newblock \emph{Computer Speech \& Language}, 64:\penalty0 101114, 2020.

\bibitem[Weiss et~al.(2017)Weiss, Chorowski, Jaitly, Wu, and
  Chen]{weiss2017sequence}
Weiss, R.~J., Chorowski, J., Jaitly, N., Wu, Y., and Chen, Z.
\newblock Sequence-to-sequence models can directly translate foreign speech.
\newblock In \emph{Proc. Interspeech}, 2017.

\bibitem[Xin et~al.(2021)Xin, Komatsu, Takamichi, and
  Saruwatari]{xin2021disentangled}
Xin, D., Komatsu, T., Takamichi, S., and Saruwatari, H.
\newblock Disentangled speaker and language representations using mutual
  information minimization and domain adaptation for cross-lingual {TTS}.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, 2021.

\bibitem[Yi et~al.(2020)Yi, Huang, Tian, Yamagishi, Das, Kinnunen, Ling, and
  Toda]{yi2020voice}
Yi, Z., Huang, W.-C., Tian, X., Yamagishi, J., Das, R.~K., Kinnunen, T., Ling,
  Z., and Toda, T.
\newblock Voice conversion challenge 2020: Intra-lingual semi-parallel and
  cross-lingual voice conversion.
\newblock In \emph{Proc. Joint Workshop for the Blizzard Challenge and Voice
  Conversion Challenge}, 2020.

\bibitem[Zen et~al.(2019)Zen, Dang, Clark, Zhang, Weiss, Jia, Chen, and
  Wu]{zen2019libritts}
Zen, H., Dang, V., Clark, R., Zhang, Y., Weiss, R.~J., Jia, Y., Chen, Z., and
  Wu, Y.
\newblock {LibriTTS}: A corpus derived from {LibriSpeech} for text-to-speech.
\newblock In \emph{Proc. Interspeech}, 2019.

\bibitem[Zhang et~al.(2021)Zhang, Tan, Ren, Qin, Zhang, and
  Liu]{zhang2020uwspeech}
Zhang, C., Tan, X., Ren, Y., Qin, T., Zhang, K., and Liu, T.-Y.
\newblock {UWSpeech}: Speech to speech translation for unwritten languages.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence (AAAI)}, 2021.

\bibitem[Zhang et~al.(2019)Zhang, Weiss, Zen, Wu, Chen, Skerry-Ryan, Jia,
  Rosenberg, and Ramabhadran]{zhang2019learning}
Zhang, Y., Weiss, R.~J., Zen, H., Wu, Y., Chen, Z., Skerry-Ryan, R., Jia, Y.,
  Rosenberg, A., and Ramabhadran, B.
\newblock Learning to speak fluently in a foreign language: Multilingual speech
  synthesis and cross-language voice cloning.
\newblock In \emph{Proc. Interspeech}, 2019.

\bibitem[Zheng et~al.(2019)Zheng, Wang, He, Pan, Soong, Wen, and
  Tao]{zheng2019forward}
Zheng, Y., Wang, X., He, L., Pan, S., Soong, F.~K., Wen, Z., and Tao, J.
\newblock Forward-backward decoding for regularizing end-to-end {TTS}.
\newblock In \emph{Proc. Interspeech}, 2019.

\end{thebibliography}
