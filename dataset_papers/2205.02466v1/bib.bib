
@string{jmlr =	{Journal of Machine Learning Research}}

@string{ieeeit=	{IEEE Transactions on Information Theory}}

@string{nips2015= {Advances in Neural Information Processing Systems 28}} % 2015
@string{nips2019= {Advances in Neural Information Processing Systems 32}} % 2019


@string{icml14 = {Proceedings of the 31st International Conference on Machine Learning}}
@string{icml17 = {Proceedings of the 34th International Conference on Machine Learning}}

@string{jasa =	{Journal of the American Statistical Association}}

@string{colt19 = {Proceedings of the Thirty Second Annual Conference on
		  Computational Learning Theory}}


@string{focs14 = {55th Annual Symposium on Foundations of Computer Science}}

@inproceedings{AbadiChGoMcMiTaZh16,
title = {Deep Learning with Differential Privacy},
author  = {Martin Abadi and Andy Chu and Ian Goodfellow and Brendan McMahan and Ilya Mironov and Kunal Talwar and Li Zhang},
year  = {2016},
booktitle = {23rd ACM Conference on Computer and Communications Security (ACM CCS)},
pages = {308--318}
}


@inproceedings{AgarwalSi17,
  title={The price of differential privacy for online learning},
  author={Naman Agarwal and Karan Singh},
  booktitle= icml17,
  pages={32--40},
  year={2017},
}

@inproceedings{BalleBaGa18,
  title={Privacy Amplification by Subsampling: Tight Analyses via Couplings and Divergences},
  author={Borja Balle and Gilles Barthe and Marco Gaboardi},
  booktitle= {Advances in Neural Information Processing Systems },
  volume = 31,
  pages={6277--6287},
  year={2018},
}

@inproceedings{BassilyFeTaTh19,
  title={Private stochastic convex optimization with optimal rates},
  author={Raef Bassily and Vitaly Feldman and Kunal Talwar and Abhradeep Thakurta},
  booktitle= {Advances in Neural Information Processing Systems},
  volume = 32,
  pages={11282--11291},
  year= 2019
}

@inproceedings{BassilySmTh14,
  title={Private empirical risk minimization: {E}fficient algorithms and tight error bounds},
  author={Raef Bassily and Adam Smith and Abhradeep Thakurta},
  booktitle= focs14,
  pages={464--473},
  year= 2014,
}

@article{BassilyGuNa21,
author  = {Raef Bassily and Cristobal Guzman and Anupama                 Nandi},
title =	{Non-Euclidean Differentially Private
Stochastic Convex Optimization},
year = 2021,
journal = {arXiv:2103.01278 [cs.LG]},
}

@article{BhowmickDuFrKaRo18,
author = {Abhishek Bhowmick and John Duchi and Julien Freudiger and
  Gaurav Kapoor and Ryan Rogers},
year = 2018,
title = {Protection Against Reconstruction and Its Applications in Private
Federated Learning},
journal = {arXiv:1812.00984 [stat.ML]},
}

@article{ChaudhuriMoSa11,
author = {Kamalika Chaudhuri and Claire Monteleoni and Anand D. Sarwate},
title = {Differentially private empirical risk minimization},
year = 2011,
journal = jmlr,
volume = 12,
pages = {1069--1109},
}

@inproceedings{DiaconisFr87,
  title={A dozen de Finetti-style results in search of a theory},
  author={Persi Diaconis and David Freedman},
  booktitle={Annales de l'IHP Probabilit{\'e}s et statistiques},
  volume= 23,
  pages={397--423},
  year={1987}
}

@incollection{Duchi18,
author = {John C. Duchi},
title = {Introductory Lectures on Stochastic Convex Optimization},
booktitle = {The Mathematics of Data},
series = {IAS/Park City Mathematics Series},
publisher = {American Mathematical Society},
editors=  {Michael Mahoney and John C. Duchi and Anna Gilbert},
year = 2018,
}

@misc{Duchi19,
author = {John C. Duchi},
title = {Information Theory and Statistics},
year = 2019,
howpublished = {Lecture Notes for Statistics 311/{EE} 377,
Stanford University},
note = {Accessed May 2019},
url = {http://web.stanford.edu/class/stats311/lecture-notes.pdf},
}

@inproceedings{DuchiShSiTe10,
author = {J. C. Duchi and S. Shalev-Shwartz and Y. Singer and A. Tewari},
title = {Composite Objective Mirror Descent},
year = 2010,
booktitle = {Proceedings of the Twenty Third Annual Conference on Computational Learning Theory},
}

@inproceedings{DuchiRo19,
author = {John C. Duchi and Ryan Rogers},
title = {Lower Bounds for Locally Private Estimation via Communication Complexity},
year = 2019,
booktitle = colt19,
}

@inproceedings{DworkMcNiSm06,
author = {Cynthia Dwork and Frank McSherry and Kobbi Nissim and Adam Smith},
title = {Calibrating noise to sensitivity in private data analysis},
year = 2006,
booktitle = {Proceedings of the Third Theory of Cryptography Conference},
pages = {265--284},
}

@inproceedings{DworkNaReRo15,
  title = {Pure differential privacy for rectangle queries via private partitions},
  author = {Cynthia Dwork and Moni Naor and Omer Reingold  and Guy N Rothblum},
  booktitle = {International Conference on the Theory and Application of Cryptology and Information Security},
  pages = {735--751},
  year = 2015,
}

@inproceedings{DworkNaPiRo10,
author = {Cynthia Dwork and Moni Naor and Toniann Pitassi and Guy N Rothblum},
title = {Differential privacy under continual observation},
year = 2010,
booktitle = {Proceedings of the Forty-Second Annual ACM
		  Symposium on the Theory of Computing},
pages = {715--724},
}

@inproceedings{DworkKeMcMiNa06,
author = {Cynthia Dwork and Krishnaram Kenthapadi and Frank McSherry
  and Ilya Mironov and Moni Naor},
title = {Our Data, Ourselves: Privacy Via Distributed Noise Generation},
booktitle = {Advances in Cryptology (EUROCRYPT 2006)},
year = 2006,
}

@article{DworkRo14,
 author = {Dwork, Cynthia and Roth, Aaron},
 title = {The Algorithmic Foundations of Differential Privacy},
 journal = {Foundations and Trends in Theoretical Computer Science},
 volume = {9},
 number = {3 \& 4},
 year = {2014},
 pages = {211--407},
 numpages = {197},
 publisher = {Now Publishers Inc.},
 address = {Hanover, MA, USA},
} 

@inproceedings{DworkRoVa10,
author = {Cynthia Dwork and Guy N. Rothblum and Salil P. Vadhan},
title = {Boosting and Differential Privacy},
year = 2010,
booktitle = {51st Annual Symposium on Foundations of Computer Science},
pages = {51--60},
}

@inproceedings{ErlingssonFeMiRaTaTh19,
author = {Ulfar Erlingsson and Vitaly Feldman and Ilya Mironov
  and Ananth Raghunathan and Kunal Talwar and  Abhradeep Thakurta},
title = {Amplification by Shuffling: From Local to Central Differential
  Privacy via Anonymity},
year = 2019,
booktitle = {Proceedings of the Thirtieth ACM-SIAM Symposium on Discrete Algorithms (SODA)},
}

@inproceedings{FangChLiLiZh18,
  title={{SPIDER}: {N}ear-optimal non-convex optimization via stochastic path-integrated differential estimator},
  author={Cong Fang and Chris Junchi Li and Zhouchen Lin and Tong Zhang},
  booktitle={Advances in Neural Information Processing Systems},
  volume = {31},
  pages={689--699},
  year={2018}
}

@inproceedings{FeldmanKoTa20,
  title={Private stochastic convex optimization: optimal rates in linear time},
  author={Vitaly Feldman and Tomer Koren and Kunal Talwar},
  booktitle={Proceedings of the 52nd Annual ACM on the Theory of Computing},
  pages={439--449},
  year={2020}
}



@article{FeldmanMcTa20,
  title={Hiding Among the Clones: A Simple and Nearly Optimal Analysis of Privacy Amplification by Shuffling},
  author={Vitaly Feldman and Audra McMillan and Kunal Talwar},
  journal   =  {arXiv:2012.12803 [cs.LG]},
  year={2020}
}

@inproceedings{Feldman16,
 author = {Vitaly Feldman},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {3576--3584},
 title = {Generalization of {ERM} in Stochastic Convex Optimization: {T}he Dimension Strikes Back},
 volume = {29},
 year = {2016}
}




@inproceedings{KiferSmTh12,
  title={Private convex empirical risk minimization and high-dimensional regression},
  author={Daniel Kifer and Adam Smith and Abhradeep Thakurta},
  booktitle={Proceedings of the Twenty Fifth Annual Conference on Computational Learning Theory},
  pages={25--1},
  year={2012}
}

@article{LuFrNe18,
  title={Relatively smooth convex optimization by first-order methods, and applications},
  author={Haihao Lu and Robert M Freund and Yurii Nesterov},
  journal={SIAM Journal on Optimization},
  volume= 28,
  number= 1,
  pages={333--354},
  year= 2018,
}

@inproceedings{SmithTh13,
author = {Adam Smith and Abhradeep Thakurta},
title = {({N}early) optimal algorithms for private online
  learning in full-information and bandit settings},
year = 2013,
booktitle = nips2013,
}

@book{ShalevBe14,
author = {Shai Shalev-Shwartz and Shai Ben-David},
title = {Understanding Machine Learning: From Theory to Algorithms},
year = 2014,
publisher = {Cambridge University Press},
}

@inproceedings{ShwartzShSrSr09,
  title={Stochastic Convex Optimization.},
  author={Shai Shalev-Shwartz and Ohad Shamir and Nathan Srebro  and Karthik Sridharan},
  booktitle={Proceedings of the Twenty Second Annual Conference on Computational Learning Theory},
  year={2009}
}

@article{SteinkeUl17,
author = {Thomas Steinke and Jonathan Ullman},
title = {Between Pure and Approximate Differential Privacy},
year = 2017,
journal = {Journal of Privacy and Confidentiality},
pages = {3--22},
volume = 7,
number = 2,
}

@inproceedings{TalwarThZh15,
  title={Nearly optimal private {L}asso},
  author={Kunal Talwar and Abhradeep Thakurta and Li Zhang},
  booktitle={Advances in Neural Information Processing Systems},
  volume={28},
  pages={3025--3033},
  year={2015}
}


@article{KairouzMcSoShThXu21,
  title={Practical and Private (Deep) Learning without Sampling or Shuffling},
  author={Peter Kairouz and Brendan McMahan and Shuang Song and Om Thakkar  and Abhradeep Thakurta and Zheng Xu},
  journal={arXiv:2103.00039 [cs.CR]},
  year={2021}
}

@inproceedings{JainTh14,
  title={({N}ear) dimension independent risk bounds for differentially private learning},
  author={Prateek Jain and Abhradeep Thakurta},
  booktitle= icml14,
  pages={476--484},
  year={2014}
}

@inproceedings{YurtseverSrCe19, 
  title = {Conditional Gradient Methods via Stochastic Path-Integrated Differential Estimator}, 
  author = {Alp Yurtsever  and Suvrit Sra and Volkan Cevher}, 
  booktitle = {Proceedings of the 36th International Conference on Machine Learning}, 
  pages = {7282--7291}, 
  year = {2019}, 
  volume = {97}, 
 }
 
 @article{lacoste2012simpler,
  title={A simpler approach to obtaining an O (1/t) convergence rate for the projected stochastic subgradient method},
  author={Lacoste-Julien, Simon and Schmidt, Mark and Bach, Francis},
  journal={arXiv preprint arXiv:1212.2002},
  year={2012}
}

@inproceedings{HardtRS16,
  author    = {Moritz Hardt and
               Ben Recht and
               Yoram Singer},
  title     = {Train faster, generalize better: Stability of stochastic gradient
               descent},
  booktitle = {{ICML}},
  pages     = {1225--1234},
  year      = {2016},
  url       = {http://jmlr.org/proceedings/papers/v48/hardt16.html}
}


@book{BertsimasTs97,
  title={Introduction to linear optimization},
  author={Dimitris Bertsimas  and John N Tsitsiklis },
  volume={6},
  year={1997},
  publisher={Athena Scientific Belmont, MA}
}


@article{Warner65a,
author = {Stanley Warner},
title = {Randomized response: a survey technique for eliminating evasive
answer bias},
year = 1965,
journal = jasa,
pages = {63--69},
volume = 60,
number = 309,
comment = {
  Early idea on a privacy method for surveying a population when potentially
  invasive questions are asked, as long as all that one cares to know is
  the proportion of a population belonging to some category (as opposed to
  non-marginal statistics of the category).
},
}


@inproceedings{EvfimievskiGeSr03,
author = {Alexandre V. Evfimievski and Johannes Gehrke
 and Ramakrishnan Srikant},
title = {Limiting privacy breaches in privacy preserving data mining},
year = 2003,
booktitle = {Proceedings of the Twenty-Second Symposium on Principles of
Database Systems},
pages = {211--222},
comment = {
  Looks at more local measures of privacy and proposes a quantity called
  "amplification" that is essentially identical to the differential privacy
  criterion. Specifically, there are N clients, each with data x_i, which
  they don't want to reveal to a central server; instead each client
  releases R(x_i), a randomized version of x_i. The authors measure privacy
  risk in terms of the increase/decrease in P(X_i = x_i | R(x_i)) vs.
  P(X_i = x_i), showing that this can be controlled by bounding the
  "amplification," which is max_{x, x', y} P(R(x) = y) / P(R(x') = y).
  They also suggest measuring privacy-breaches with a worst-case
  KL divergence (i.e. max_y KL(P(X | y), P(X))), because the mutual information
  can lead to privacy breaches for unlikely data x (as it is weighted by x).
},
}

@article{DuchiJoWa18,
author = {John C. Duchi and Michael I. Jordan and Martin J. Wainwright},
title = {Minimax Optimal Procedures for Locally Private Estimation
 (with discussion)},
year = 2018,
journal = jasa,
volume = 113,
number = 521,
pages = {182--215},
}


@misc{ApplePrivacy17,
author = {{Apple Differential Privacy Team}},
title = {Learning with Privacy at Scale},
year = 2017,
note = {Available at
 \url{https://machinelearning.apple.com/2017/12/06/learning-with-privacy-at-scale.html}},
}

@inproceedings{ErlingssonPiKo14,
author = {Ulfar Erlingsson and Vasyl Pihur and Aleksandra Korolova},
title = {{RAPPOR}: Randomized Aggregatable Privacy-Preserving Ordinal Response},
year = 2014,
booktitle = {Proceedings of the 21st ACM Conference on Computer
  and Communications Security (CCS)},
}


@article{ErlingssonFeMiRaSoTaTh20,
  title={Encode, shuffle, analyze privacy revisited: Formalizations and empirical evaluation},
  author={{\'U}lfar Erlingsson  and Vitaly Feldman  and Ilya Mironov  and Ananth Raghunathan  and Shuang Song  and Kunal Talwar and Abhradeep Thakurta },
  journal= {arXiv:2001.03618 [cs.CR]},
  year={2020}
}


@InProceedings{FeldmanTa21,
  title = 	 {Lossless Compression of Efficient Private Local Randomizers},
  author =       {Vitaly Feldman and Kunal Talwar},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {3208--3219},
  year = 	 {2021},
  volume = 	 {139},
  publisher =    {PMLR},

}


@article{ChenKaOz20,
  title={Breaking the communication-privacy-accuracy trilemma},
  author={Wei-Ning Chen and Peter Kairouz  and Ayfer {\"O}zg{\"u}r },
  journal={	arXiv:2007.11707 [cs.LG]},
  year={2020}
}

@inproceedings{BonawitzIvKrMaMcPaRaSeSe17,
 author = {Bonawitz, Keith and Ivanov, Vladimir and Kreuter, Ben and Marcedone, Antonio and McMahan, H. Brendan and Patel, Sarvar and Ramage, Daniel and Segal, Aaron and Seth, Karn},
 title = {Practical Secure Aggregation for Privacy-Preserving Machine Learning},
 booktitle = {Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
 year = {2017},
 pages = {1175--1191},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {federated learning, machine learning, privacy-preserving protocols, secure aggregation},
} 



@inproceedings{BeimelNiOm08,
author = {Amos Beimel and Kobbi Nissim and Eran Omri},
title = {Distributed private data analysis: Simultaneously solving
  how and what},
year = 2008,
booktitle = {Advances in Cryptology},
pages = {451--468},
series = {Lecture Notes in Computer Science},
volume = 5157,
publisher = {Springer},
comment = {Considers some distributed differential privacy ideas (something
  about combining secure function evaluation with differential privacy).
  Didn't really understand the distributed part. Shows a lower bound on
  computing the sum \sum_{i=1}^n x_i in the local privacy model, when we assume
  that x_i \in \{0, 1\}. The lower bound is of order \sqrt{n} / (\epsilon l)
  for an l-round protocol, where \epsilon is differential privacy level.
  Proof technique is by showing that under local privacy, with high probability
  deviation is of order \sqrt{n}, so the all-0s vector is indistinguishable
  (with constant probability) from a vector with P(x_i = 1) = 1/\sqrt{n}. A
  bit of a weakness in that doesn't really tackle statistical problem
  underlying the setting and doing more rounds reduces lower bound. (Don't
  quite get that one.)}
}


@InProceedings{Cheu:2019,
author="Cheu, Albert
and Smith, Adam
and Ullman, Jonathan
and Zeber, David
and Zhilyaev, Maxim",
editor="Ishai, Yuval
and Rijmen, Vincent",
title="Distributed Differential Privacy via Shuffling",
booktitle="Advances in Cryptology -- EUROCRYPT 2019",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="375--403",
abstract="We consider the problem of designing scalable, robust protocols for computing statistics about sensitive data. Specifically, we look at how best to design differentially private protocols in a distributed setting, where each user holds a private datum. The literature has mostly considered two models: the ``central'' model, in which a trusted server collects users' data in the clear, which allows greater accuracy; and the ``local'' model, in which users individually randomize their data, and need not trust the server, but accuracy is limited. Attempts to achieve the accuracy of the central model without a trusted server have so far focused on variants of cryptographic multiparty computation (MPC), which limits scalability.",
isbn="978-3-030-17653-2"
}


@inproceedings{Bittau17,
author = {Bittau, Andrea and Erlingsson, \'{U}lfar and Maniatis, Petros and Mironov, Ilya and Raghunathan, Ananth and Lie, David and Rudominer, Mitch and Kode, Ushasree and Tinnes, Julien and Seefeld, Bernhard},
title = {Prochlo: Strong Privacy for Analytics in the Crowd},
year = {2017},
isbn = {9781450350853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3132747.3132769},
doi = {10.1145/3132747.3132769},
booktitle = {Proceedings of the 26th Symposium on Operating Systems Principles},
pages = {441–459},
numpages = {19},
location = {Shanghai, China},
series = {SOSP '17}
}


@InProceedings{BalleBGN19a,
author="Balle, Borja
and Bell, James
and Gasc{\'o}n, Adri{\`a}
and Nissim, Kobbi",
editor="Boldyreva, Alexandra
and Micciancio, Daniele",
title="The Privacy Blanket of the Shuffle Model",
booktitle="Advances in Cryptology -- CRYPTO 2019",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="638--667",
isbn="978-3-030-26951-7"
}

@INPROCEEDINGS{BrennerN2010,
  author={Brenner, Hai and Nissim, Kobbi},
  booktitle={2010 IEEE 51st Annual Symposium on Foundations of Computer Science}, 
  title={Impossibility of Differentially Private Universally Optimal Mechanisms}, 
  year={2010},
  volume={},
  number={},
  pages={71-80},
  doi={10.1109/FOCS.2010.13}}

@inproceedings{GhoshRS09,
author = {Ghosh, Arpita and Roughgarden, Tim and Sundararajan, Mukund},
title = {Universally Utility-Maximizing Privacy Mechanisms},
year = {2009},
isbn = {9781605585062},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1536414.1536464},
doi = {10.1145/1536414.1536464},
abstract = {A mechanism for releasing information about a statistical database with sensitive data must resolve a trade-off between utility and privacy. Publishing fully accurate information maximizes utility while minimizing privacy, while publishing random noise accomplishes the opposite. Privacy can be rigorously quantified using the framework of differential privacy, which requires that a mechanism's output distribution is nearly the same whether or not a given database row is included or excluded. The goal of this paper is strong and general utility guarantees, subject to differential privacy. We pursue mechanisms that guarantee near-optimal utility to every potential user, independent of its side information (modeled as a prior distribution over query results) and preferences (modeled via a loss function). Our main result is: for each fixed count query and differential privacy level, there is a geometric mechanism M* -- a discrete variant of the simple and well-studied Laplace mechanism -- that is simultaneously expected loss-minimizing for every possible user, subject to the differential privacy constraint. This is an extremely strong utility guarantee: every potential user u, no matter what its side information and preferences, derives as much utility from M* as from interacting with a differentially private mechanism Mu that is optimally tailored to u. More precisely, for every user u there is an optimal mechanism Mu for it that factors into a user-independent part (the geometric mechanism M*) followed by user-specific post-processing that can be delegated to the user itself. The first part of our proof of this result characterizes the optimal differentially private mechanism for a fixed but arbitrary user in terms of a certain basic feasible solution to a linear program with constraints that encode differential privacy. The second part shows that all of the relevant vertices of this polytope (ranging over all possible users) are derivable from the geometric mechanism via suitable remappings of its range.},
booktitle = {Proceedings of the Forty-First Annual ACM Symposium on Theory of Computing},
pages = {351–360},
numpages = {10},
keywords = {differential privacy, privacy, linear programming, utility},
location = {Bethesda, MD, USA},
series = {STOC '09}
}

@inproceedings{GupteR10, author = {Gupte, Mangesh and Sundararajan, Mukund}, title = {Universally Optimal Privacy Mechanisms for Minimax Agents}, year = {2010}, isbn = {9781450300339}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/1807085.1807105}, doi = {10.1145/1807085.1807105}, abstract = {A scheme that publishes aggregate information about sensitive data must resolve the trade-off between utility to information consumers and privacy of the database participants. Differential privacy [5] is a well-established definition of privacy--this is a universal guarantee against all attackers, whatever their side-information or intent. Can we have a similar universal guarantee for utility?There are two standard models of utility considered in decision theory: Bayesian and minimax [13]. Ghosh et. al. [8] show that a certain "geometric mechanism" gives optimal utility to all Bayesian information consumers. In this paper, we prove a similar result for minimax information consumers. Our result also works for a wider class of information consumers which includes Bayesian information consumers and subsumes the result from [8].We model information consumers as minimax (risk-averse) agents, each endowed with a loss-function which models their tolerance to inaccuracies and each possessing some side-information about the query. Further, information consumers are rational in the sense that they actively combine information from the mechanism with their side-information in a way that minimizes their loss. Under this assumption of rational behavior, we show that for every fixed count query, the geometric mechanism is universally optimal for all minimax information consumers.Additionally, our solution makes it possible to release query results, when information consumers are at different levels of privacy, in a collusion-resistant manner.}, booktitle = {Proceedings of the Twenty-Ninth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems}, pages = {135–146}, numpages = {12}, keywords = {decision theory, minimax, linear algebra, universally optimal privacy, differential privacy}, location = {Indianapolis, Indiana, USA}, series = {PODS '10} }


@ARTICLE{GengKOV15,  author={Geng, Quan and Kairouz, Peter and Oh, Sewoong and Viswanath, Pramod},  journal={IEEE Journal of Selected Topics in Signal Processing},   title={The Staircase Mechanism in Differential Privacy},   year={2015},  volume={9},  number={7},  pages={1176-1184},  doi={10.1109/JSTSP.2015.2425831}}

@inbook{EdmondsNU20, author = {Edmonds, Alexander and Nikolov, Aleksandar and Ullman, Jonathan}, title = {The Power of Factorization Mechanisms in Local and Central Differential Privacy}, year = {2020}, isbn = {9781450369794}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3357713.3384297}, abstract = {We give new characterizations of the sample complexity of answering linear queries (statistical queries) in the local and central models of differential privacy: (1) In the non-interactive local model, we give the first approximate characterization of the sample complexity. Informally our bounds are tight to within polylogarithmic factors in the number of queries and desired accuracy. Our characterization extends to agnostic learning in the local model. (2) In the central model, we give a characterization of the sample complexity in the high-accuracy regime that is analogous to that of Nikolov, Talwar, and Zhang (STOC 2013), but is both quantitatively tighter and has a dramatically simpler proof. Our lower bounds apply equally to the empirical and population estimation problems. In both cases, our characterizations show that a particular factorization mechanism is approximately optimal, and the optimal sample complexity is bounded from above and below by well studied factorization norms of a matrix associated with the queries.}, booktitle = {Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing}, pages = {425–438}, numpages = {14} }

@article{KOV16jmlr,
 author = {Kairouz, Peter and Oh, Sewoong and Viswanath, Pramod},
 title = {Extremal Mechanisms for Local Differential Privacy},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
 issn = {1532-4435},
 pages = {492--542},
 numpages = {51},
 url = {http://dl.acm.org/citation.cfm?id=2946645.2946662},
 acmid = {2946662},
 publisher = {JMLR.org},
 keywords = {estimation, f-divergences, hypothesis testing, information
 theoretic utilities, local differential privacy, mutual information,
 privacy-preserving machine learning algorithms, statistical inference},
}

@inbook{CheuU21, author = {Cheu, Albert and Ullman, Jonathan}, title = {The Limits of Pan Privacy and Shuffle Privacy for Learning and Estimation}, year = {2021}, isbn = {9781450380539}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3406325.3450995}, abstract = {There has been a recent wave of interest in intermediate trust models for differential privacy that eliminate the need for a fully trusted central data collector, but overcome the limitations of local differential privacy. This interest has led to the introduction of the shuffle model (Cheu et al., EUROCRYPT 2019; Erlingsson et al., SODA 2019) and revisiting the pan-private model (Dwork et al., ITCS 2010). The message of this line of work is that, for a variety of low-dimensional problems—such as counts, means, and histograms—these intermediate models offer nearly as much power as central differential privacy. However, there has been considerably less success using these models for high-dimensional learning and estimation problems. In this work we prove the first non-trivial lower bounds for high-dimensional learning and estimation in both the pan-private model and the general multi-message shuffle model. Our lower bounds apply to a variety of problems—for example, we show that, private agnostic learning of parity functions over d bits requires Ω(2d/2) samples in these models, and privately selecting the most common attribute from a set of d choices requires Ω(d1/2) samples, both of which are exponential separations from the central model.}, booktitle = {Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing}, pages = {1081–1094}, numpages = {14} }


@article{YeBa18,
author = {Min Ye and Alexander Barg},
title = {Optimal Schemes for Discrete Distribution Estimation Under
  Locally Differential Privacy},
year = 2018,
journal = ieeeit,
volume = 64,
number = 8,
pages = {5662--5676},
}

@article{YeBa17,
  title={Asymptotically optimal private estimation under mean square loss},
  author={Min Ye and Alexander Barg},
  journal= {arXiv:1708.00059 [math.ST]} ,
  year= 2017
}