\begin{thebibliography}{10}

\bibitem{cont1}
Chris Alberti, Jeffrey Ling, Michael Collins, and David Reitter.
\newblock Fusion of detected objects in text for visual question answering.
\newblock {\em arXiv preprint arXiv:1908.05054}, 2019.

\bibitem{visualsem}
Houda Alberts, Teresa Huang, Yash Deshpande, Yibo Liu, Kyunghyun Cho, Clara
  Vania, and Iacer Calixto.
\newblock Visualsem: a high-quality knowledge graph for vision and language.
\newblock {\em arXiv preprint arXiv:2008.09150}, 2020.

\bibitem{link1}
Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana
  Yakhnenko.
\newblock Translating embeddings for modeling multi-relational data.
\newblock {\em Advances in neural information processing systems}, 26, 2013.

\bibitem{cc12m}
Soravit Changpinyo, Piyush Sharma, Nan Ding, and Radu Soricut.
\newblock Conceptual 12m: Pushing web-scale image-text pre-training to
  recognize long-tail visual concepts.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 3558--3568, 2021.

\bibitem{igpt}
Mark Chen, Alec Radford, Rewon Child, Jeffrey Wu, Heewoo Jun, David Luan, and
  Ilya Sutskever.
\newblock Generative pretraining from pixels.
\newblock In {\em International Conference on Machine Learning}, pages
  1691--1703. PMLR, 2020.

\bibitem{kgkreason}
Wenhu Chen, Wenhan Xiong, Xifeng Yan, and William Wang.
\newblock Variational knowledge graph reasoning.
\newblock {\em arXiv preprint arXiv:1803.06581}, 2018.

\bibitem{kgreason}
Xiaojun Chen, Shengbin Jia, and Yang Xiang.
\newblock A review: Knowledge reasoning over knowledge graph.
\newblock {\em Expert Systems with Applications}, 141:112948, 2020.

\bibitem{cococap}
Xinlei Chen, Hao Fang, Tsung-Yi Lin, Ramakrishna Vedantam, Saurabh Gupta, Piotr
  Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco captions: Data collection and evaluation server.
\newblock {\em arXiv preprint arXiv:1504.00325}, 2015.

\bibitem{uniter}
Yen-Chun Chen, Linjie Li, Licheng Yu, Ahmed El~Kholy, Faisal Ahmed, Zhe Gan,
  Yu~Cheng, and Jingjing Liu.
\newblock Uniter: Learning universal image-text representations.
\newblock 2019.

\bibitem{imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee, 2009.

\bibitem{bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock {\em arXiv preprint arXiv:1810.04805}, 2018.

\bibitem{vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock {\em arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{textunder2}
Hao Fei, Yafeng Ren, Yue Zhang, Donghong Ji, and Xiaohui Liang.
\newblock Enriching contextualized language model from knowledge graph for
  biomedical information extraction.
\newblock {\em Briefings in bioinformatics}, 22(3):bbaa110, 2021.

\bibitem{villa}
Zhe Gan, Yen-Chun Chen, Linjie Li, Chen Zhu, Yu~Cheng, and Jingjing Liu.
\newblock Large-scale adversarial training for vision-and-language
  representation learning.
\newblock {\em Advances in Neural Information Processing Systems},
  33:6616--6628, 2020.

\bibitem{vqa}
Yash Goyal, Tejas Khot, Douglas Summers-Stay, Dhruv Batra, and Devi Parikh.
\newblock Making the v in vqa matter: Elevating the role of image understanding
  in visual question answering.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 6904--6913, 2017.

\bibitem{recommand2}
Qingyu Guo, Fuzhen Zhuang, Chuan Qin, Hengshu Zhu, Xing Xie, Hui Xiong, and
  Qing He.
\newblock A survey on knowledge graph-based recommender systems.
\newblock {\em IEEE Transactions on Knowledge and Data Engineering}, 2020.

\bibitem{mae}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll{\'a}r, and Ross
  Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock {\em arXiv preprint arXiv:2111.06377}, 2021.

\bibitem{kgqa}
Xiao Huang, Jingyuan Zhang, Dingcheng Li, and Ping Li.
\newblock Knowledge graph embedding based question answering.
\newblock In {\em Proceedings of the twelfth ACM international conference on
  web search and data mining}, pages 105--113, 2019.

\bibitem{clipnoise}
Zhenyu Huang, Guocheng Niu, Xiao Liu, Wenbiao Ding, Xinyan Xiao, Hua Wu, and
  Xi~Peng.
\newblock Learning with noisy correspondence for cross-modal matching.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{gvqa1}
Drew~A Hudson and Christopher~D Manning.
\newblock Gqa: A new dataset for real-world visual reasoning and compositional
  question answering.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 6700--6709, 2019.

\bibitem{yfcc}
Sebastian Kalkowski, Christian Schulze, Andreas Dengel, and Damian Borth.
\newblock Real-time analysis and visualization of the yfcc100m dataset.
\newblock In {\em Proceedings of the 2015 workshop on community-organized
  multimodal mining: opportunities for novel solutions}, pages 25--30, 2015.

\bibitem{graphcls}
Michael Kampffmeyer, Yinbo Chen, Xiaodan Liang, Hao Wang, Yujia Zhang, and
  Eric~P Xing.
\newblock Rethinking knowledge graph propagation for zero-shot learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 11487--11496, 2019.

\bibitem{vilt}
Wonjae Kim, Bokyung Son, and Ildoo Kim.
\newblock Vilt: Vision-and-language transformer without convolution or region
  supervision.
\newblock In {\em International Conference on Machine Learning}, pages
  5583--5594. PMLR, 2021.

\bibitem{vgdata}
Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua
  Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David~A Shamma, et~al.
\newblock Visual genome: Connecting language and vision using crowdsourced
  dense image annotations.
\newblock {\em International journal of computer vision}, 123(1):32--73, 2017.

\bibitem{unicoder}
Gen Li, Nan Duan, Yuejian Fang, Ming Gong, and Daxin Jiang.
\newblock Unicoder-vl: A universal encoder for vision and language by
  cross-modal pre-training.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pages 11336--11344, 2020.

\bibitem{albef}
Junnan Li, Ramprasaath Selvaraju, Akhilesh Gotmare, Shafiq Joty, Caiming Xiong,
  and Steven Chu~Hong Hoi.
\newblock Align before fuse: Vision and language representation learning with
  momentum distillation.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{cont2}
Liunian~Harold Li, Mark Yatskar, Da~Yin, Cho-Jui Hsieh, and Kai-Wei Chang.
\newblock Visualbert: A simple and performant baseline for vision and language.
\newblock {\em arXiv preprint arXiv:1908.03557}, 2019.

\bibitem{oscar}
Xiujun Li, Xi~Yin, Chunyuan Li, Pengchuan Zhang, Xiaowei Hu, Lei Zhang, Lijuan
  Wang, Houdong Hu, Li~Dong, Furu Wei, et~al.
\newblock Oscar: Object-semantics aligned pre-training for vision-language
  tasks.
\newblock In {\em European Conference on Computer Vision}, pages 121--137.
  Springer, 2020.

\bibitem{kgrel2}
Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu.
\newblock Learning entity and relation embeddings for knowledge graph
  completion.
\newblock In {\em Twenty-ninth AAAI conference on artificial intelligence},
  2015.

\bibitem{link2}
Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu.
\newblock Learning entity and relation embeddings for knowledge graph
  completion.
\newblock In {\em Twenty-ninth AAAI conference on artificial intelligence},
  2015.

\bibitem{cont3}
Jiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee.
\newblock Vilbert: Pretraining task-agnostic visiolinguistic representations
  for vision-and-language tasks.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{vilbert}
Jiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee.
\newblock Vilbert: Pretraining task-agnostic visiolinguistic representations
  for vision-and-language tasks.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{eiclip}
Haoyu Ma, Handong Zhao, Zhe Lin, Ajinkya Kale, Zhangyang Wang, Tong Yu,
  Jiuxiang Gu, Sunav Choudhary, and Xiaohui Xie.
\newblock Ei-clip: Entity-aware interventional contrastive learning for
  e-commerce cross-modal retrieval.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 18051--18061, 2022.

\bibitem{wordnet}
George~A Miller.
\newblock Wordnet: a lexical database for english.
\newblock {\em Communications of the ACM}, 38(11):39--41, 1995.

\bibitem{acmix}
Xuran Pan, Chunjiang Ge, Rui Lu, Shiji Song, Guanfu Chen, Zeyi Huang, and Gao
  Huang.
\newblock On the integration of self-attention and convolution.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 815--825, 2022.

\bibitem{pointformer}
Xuran Pan, Zhuofan Xia, Shiji Song, Li~Erran Li, and Gao Huang.
\newblock 3d object detection with pointformer.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 7463--7472, 2021.

\bibitem{flickr30k}
Bryan~A Plummer, Liwei Wang, Chris~M Cervantes, Juan~C Caicedo, Julia
  Hockenmaier, and Svetlana Lazebnik.
\newblock Flickr30k entities: Collecting region-to-phrase correspondences for
  richer image-to-sentence models.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 2641--2649, 2015.

\bibitem{clip}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In {\em International Conference on Machine Learning}, pages
  8748--8763. PMLR, 2021.

\bibitem{gpt}
Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever.
\newblock Improving language understanding by generative pre-training.
\newblock 2018.

\bibitem{bpe}
Rico Sennrich, Barry Haddow, and Alexandra Birch.
\newblock Neural machine translation of rare words with subword units.
\newblock {\em arXiv preprint arXiv:1508.07909}, 2015.

\bibitem{gvqa2}
Sanket Shah, Anand Mishra, Naganand Yadati, and Partha~Pratim Talukdar.
\newblock Kvqa: Knowledge-aware visual question answering.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 8876--8884, 2019.

\bibitem{cc3m}
Piyush Sharma, Nan Ding, Sebastian Goodman, and Radu Soricut.
\newblock Conceptual captions: A cleaned, hypernymed, image alt-text dataset
  for automatic image captioning.
\newblock In {\em Proceedings of the 56th Annual Meeting of the Association for
  Computational Linguistics (Volume 1: Long Papers)}, pages 2556--2565, 2018.

\bibitem{kgrel}
Baoxu Shi and Tim Weninger.
\newblock Open-world knowledge graph completion.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~32, 2018.

\bibitem{cliplite}
Aman Shrivastava, Ramprasaath~R Selvaraju, Nikhil Naik, and Vicente Ordonez.
\newblock Clip-lite: Information efficient visual representation learning from
  textual annotations.
\newblock {\em arXiv preprint arXiv:2112.07133}, 2021.

\bibitem{flava}
Amanpreet Singh, Ronghang Hu, Vedanuj Goswami, Guillaume Couairon, Wojciech
  Galuba, Marcus Rohrbach, and Douwe Kiela.
\newblock Flava: A foundational language and vision alignment model.
\newblock {\em arXiv preprint arXiv:2112.04482}, 2021.

\bibitem{conceptnet}
Robyn Speer, Joshua Chin, and Catherine Havasi.
\newblock Conceptnet 5.5: An open multilingual graph of general knowledge.
\newblock In {\em Thirty-first AAAI conference on artificial intelligence},
  2017.

\bibitem{mlm1}
Weijie Su, Xizhou Zhu, Yue Cao, Bin Li, Lewei Lu, Furu Wei, and Jifeng Dai.
\newblock Vl-bert: Pre-training of generic visual-linguistic representations.
\newblock {\em arXiv preprint arXiv:1908.08530}, 2019.

\bibitem{vlbert}
Weijie Su, Xizhou Zhu, Yue Cao, Bin Li, Lewei Lu, Furu Wei, and Jifeng Dai.
\newblock Vl-bert: Pre-training of generic visual-linguistic representations.
\newblock {\em arXiv preprint arXiv:1908.08530}, 2019.

\bibitem{grecommand1}
Xiaoyuan Su and Taghi~M Khoshgoftaar.
\newblock A survey of collaborative filtering techniques.
\newblock {\em Advances in artificial intelligence}, 2009, 2009.

\bibitem{lxmert}
Hao Tan and Mohit Bansal.
\newblock Lxmert: Learning cross-modality encoder representations from
  transformers.
\newblock {\em arXiv preprint arXiv:1908.07490}, 2019.

\bibitem{mlm2}
Hao Tan and Mohit Bansal.
\newblock Lxmert: Learning cross-modality encoder representations from
  transformers.
\newblock {\em arXiv preprint arXiv:1908.07490}, 2019.

\bibitem{grecommand2}
Shaohua Tao, Runhe Qiu, Yuan Ping, and Hui Ma.
\newblock Multi-modal knowledge-aware reinforcement learning network for
  explainable recommendation.
\newblock {\em Knowledge-Based Systems}, 227:107217, 2021.

\bibitem{deit}
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre
  Sablayrolles, and Herv{\'e} J{\'e}gou.
\newblock Training data-efficient image transformers \& distillation through
  attention.
\newblock In {\em International Conference on Machine Learning}, pages
  10347--10357. PMLR, 2021.

\bibitem{transformer}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{glue}
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel~R
  Bowman.
\newblock Glue: A multi-task benchmark and analysis platform for natural
  language understanding.
\newblock {\em arXiv preprint arXiv:1804.07461}, 2018.

\bibitem{recommand1}
Hongwei Wang, Fuzheng Zhang, Jialin Wang, Miao Zhao, Wenjie Li, Xing Xie, and
  Minyi Guo.
\newblock Ripplenet: Propagating user preferences on the knowledge graph for
  recommender systems.
\newblock In {\em Proceedings of the 27th ACM international conference on
  information and knowledge management}, pages 417--426, 2018.

\bibitem{ofa}
Peng Wang, An~Yang, Rui Men, Junyang Lin, Shuai Bai, Zhikang Li, Jianxin Ma,
  Chang Zhou, Jingren Zhou, and Hongxia Yang.
\newblock Unifying architectures, tasks, and modalities through a simple
  sequence-to-sequence learning framework.
\newblock {\em arXiv preprint arXiv:2202.03052}, 2022.

\bibitem{kgembed}
Quan Wang, Zhendong Mao, Bin Wang, and Li~Guo.
\newblock Knowledge graph embedding: A survey of approaches and applications.
\newblock {\em IEEE Transactions on Knowledge and Data Engineering},
  29(12):2724--2743, 2017.

\bibitem{kgkreason2}
Zhouxia Wang, Tianshui Chen, Jimmy Ren, Weihao Yu, Hui Cheng, and Liang Lin.
\newblock Deep reasoning with knowledge graph for social relationship
  understanding.
\newblock {\em arXiv preprint arXiv:1807.00504}, 2018.

\bibitem{simvlm}
Zirui Wang, Jiahui Yu, Adams~Wei Yu, Zihang Dai, Yulia Tsvetkov, and Yuan Cao.
\newblock Simvlm: Simple visual language model pretraining with weak
  supervision.
\newblock {\em arXiv preprint arXiv:2108.10904}, 2021.

\bibitem{entity1}
WX~Wilcke, Peter Bloem, Victor de~Boer, RH~van~t Veer, and FAH van Harmelen.
\newblock End-to-end entity classification on multimodal knowledge graphs.
\newblock {\em arXiv preprint arXiv:2003.12383}, 2020.

\bibitem{graphseg}
Yangxin Wu, Gengwei Zhang, Yiming Gao, Xiajun Deng, Ke~Gong, Xiaodan Liang, and
  Liang Lin.
\newblock Bidirectional graph reasoning network for panoptic segmentation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2020.

\bibitem{dat}
Zhuofan Xia, Xuran Pan, Shiji Song, Li~Erran Li, and Gao Huang.
\newblock Vision transformer with deformable attention.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 4794--4803, 2022.

\bibitem{ve}
Ning Xie, Farley Lai, Derek Doran, and Asim Kadav.
\newblock Visual entailment: A novel task for fine-grained image understanding.
\newblock {\em arXiv preprint arXiv:1901.06706}, 2019.

\bibitem{sggen}
Jianwei Yang, Jiasen Lu, Stefan Lee, Dhruv Batra, and Devi Parikh.
\newblock Graph r-cnn for scene graph generation.
\newblock In {\em Proceedings of the European conference on computer vision
  (ECCV)}, pages 670--685, 2018.

\bibitem{textunder1}
Donghan Yu, Chenguang Zhu, Yiming Yang, and Michael Zeng.
\newblock Jaket: Joint pre-training of knowledge graph and language
  understanding.
\newblock {\em arXiv preprint arXiv:2010.00796}, 2020.

\bibitem{ernie}
Fei Yu, Jiji Tang, Weichong Yin, Yu~Sun, Hao Tian, Hua Wu, and Haifeng Wang.
\newblock Ernie-vil: Knowledge enhanced vision-language representations through
  scene graph.
\newblock {\em arXiv preprint arXiv:2006.16934}, 2020.

\bibitem{sgparse}
Rowan Zellers, Mark Yatskar, Sam Thomson, and Yejin Choi.
\newblock Neural motifs: Scene graph parsing with global context.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 5831--5840, 2018.

\bibitem{devlbert}
Shengyu Zhang, Tan Jiang, Tan Wang, Kun Kuang, Zhou Zhao, Jianke Zhu, Jin Yu,
  Hongxia Yang, and Fei Wu.
\newblock Devlbert: Out-of-distribution visio-linguistic pretraining with
  causality.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 1744--1747, 2021.

\bibitem{kgqa2}
Yuyu Zhang, Hanjun Dai, Zornitsa Kozareva, Alexander~J Smola, and Le~Song.
\newblock Variational reasoning for question answering with knowledge graph.
\newblock In {\em Thirty-second AAAI conference on artificial intelligence},
  2018.

\bibitem{graphcap}
Wentian Zhao, Yao Hu, Heda Wang, Xinxiao Wu, and Jiebo Luo.
\newblock Boosting entity-aware image captioning with multi-modal knowledge
  graph.
\newblock {\em arXiv preprint arXiv:2107.11970}, 2021.

\bibitem{uniperceiver}
Xizhou Zhu, Jinguo Zhu, Hao Li, Xiaoshi Wu, Xiaogang Wang, Hongsheng Li,
  Xiaohua Wang, and Jifeng Dai.
\newblock Uni-perceiver: Pre-training unified architecture for generic
  perception for zero-shot and few-shot tasks.
\newblock {\em arXiv preprint arXiv:2112.01522}, 2021.

\bibitem{k3m}
Yushan Zhu, Huaixiao Zhao, Wen Zhang, Ganqiang Ye, Hui Chen, Ningyu Zhang, and
  Huajun Chen.
\newblock Knowledge perceived multi-modal pretraining in e-commerce.
\newblock In {\em Proceedings of the 29th ACM International Conference on
  Multimedia}, pages 2744--2752, 2021.

\bibitem{zhuge2021kaleido}
Mingchen Zhuge, Dehong Gao, Deng-Ping Fan, Linbo Jin, Ben Chen, Haoming Zhou,
  Minghui Qiu, and Ling Shao.
\newblock Kaleido-bert: Vision-language pre-training on fashion domain.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 12647--12657, 2021.

\end{thebibliography}
