\begin{thebibliography}{}

\bibitem[Abstreiter et~al., 2021]{abstreiter2021diffusion}
Abstreiter, K., Mittal, S., Bauer, S., Sch{\"o}lkopf, B., and Mehrjou, A.
  (2021).
\newblock Diffusion-based representation learning.
\newblock {\em arXiv preprint arXiv:2105.14257}.

\bibitem[Bansal et~al., 2022]{bansal2022cold}
Bansal, A., Borgnia, E., Chu, H.-M., Li, J.~S., Kazemi, H., Huang, F.,
  Goldblum, M., Geiping, J., and Goldstein, T. (2022).
\newblock Cold diffusion: Inverting arbitrary image transforms without noise.
\newblock {\em arXiv preprint arXiv:2208.09392}.

\bibitem[Baranchuk et~al., 2021]{baranchuk2021label}
Baranchuk, D., Rubachev, I., Voynov, A., Khrulkov, V., and Babenko, A. (2021).
\newblock Label-efficient semantic segmentation with diffusion models.
\newblock {\em arXiv preprint arXiv:2112.03126}.

\bibitem[Chang and Lin, 2011]{chang2011libsvm}
Chang, C.-C. and Lin, C.-J. (2011).
\newblock Libsvm: a library for support vector machines.
\newblock {\em ACM transactions on intelligent systems and technology (TIST)},
  2(3):1--27.

\bibitem[Choi et~al., 2022]{choi2022perception}
Choi, J., Lee, J., Shin, C., Kim, S., Kim, H., and Yoon, S. (2022).
\newblock Perception prioritized training of diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 11472--11481.

\bibitem[Dhariwal and Nichol, 2021]{dhariwal2021diffusion}
Dhariwal, P. and Nichol, A. (2021).
\newblock Diffusion models beat gans on image synthesis.
\newblock {\em Advances in Neural Information Processing Systems},
  34:8780--8794.

\bibitem[Gao et~al., 2019]{gao2019representation}
Gao, J., He, D., Tan, X., Qin, T., Wang, L., and Liu, T.-Y. (2019).
\newblock Representation degeneration problem in training natural language
  generation models.
\newblock {\em arXiv preprint arXiv:1907.12009}.

\bibitem[Haefeli et~al., 2022]{haefeli2022diffusion}
Haefeli, K.~K., Martinkus, K., Perraudin, N., and Wattenhofer, R. (2022).
\newblock Diffusion models for graphs benefit from discrete state spaces.
\newblock {\em arXiv preprint arXiv:2210.01549}.

\bibitem[Hassani and Khasahmadi, 2020]{hassani2020contrastive}
Hassani, K. and Khasahmadi, A.~H. (2020).
\newblock Contrastive multi-view representation learning on graphs.
\newblock In {\em International conference on machine learning}, pages
  4116--4126. PMLR.

\bibitem[Ho et~al., 2020]{ho2020denoising}
Ho, J., Jain, A., and Abbeel, P. (2020).
\newblock Denoising diffusion probabilistic models.
\newblock {\em Advances in Neural Information Processing Systems},
  33:6840--6851.

\bibitem[Hou et~al., 2022]{hou2022graphmae}
Hou, Z., Liu, X., Dong, Y., Wang, C., Tang, J., et~al. (2022).
\newblock Graphmae: Self-supervised masked graph autoencoders.
\newblock {\em arXiv preprint arXiv:2205.10803}.

\bibitem[Hu et~al., 2020a]{hu2020open}
Hu, W., Fey, M., Zitnik, M., Dong, Y., Ren, H., Liu, B., Catasta, M., and
  Leskovec, J. (2020a).
\newblock Open graph benchmark: Datasets for machine learning on graphs.
\newblock {\em Advances in neural information processing systems},
  33:22118--22133.

\bibitem[Hu et~al., 2020b]{hu2020gpt}
Hu, Z., Dong, Y., Wang, K., Chang, K.-W., and Sun, Y. (2020b).
\newblock Gpt-gnn: Generative pre-training of graph neural networks.
\newblock In {\em Proceedings of the 26th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pages 1857--1867.

\bibitem[Jo et~al., 2022]{jo2022score}
Jo, J., Lee, S., and Hwang, S.~J. (2022).
\newblock Score-based generative modeling of graphs via the system of
  stochastic differential equations.
\newblock {\em arXiv preprint arXiv:2202.02514}.

\bibitem[Li et~al., 2020]{li2020sentence}
Li, B., Zhou, H., He, J., Wang, M., Yang, Y., and Li, L. (2020).
\newblock On the sentence embeddings from pre-trained language models.
\newblock {\em arXiv preprint arXiv:2011.05864}.

\bibitem[Li et~al., 2022]{li2022diffusion}
Li, X.~L., Thickstun, J., Gulrajani, I., Liang, P., and Hashimoto, T.~B.
  (2022).
\newblock Diffusion-lm improves controllable text generation.
\newblock {\em arXiv preprint arXiv:2205.14217}.

\bibitem[Preechakul et~al., 2022]{preechakul2022diffusion}
Preechakul, K., Chatthee, N., Wizadwongsa, S., and Suwajanakorn, S. (2022).
\newblock Diffusion autoencoders: Toward a meaningful and decodable
  representation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10619--10629.

\bibitem[Qiu et~al., 2020]{qiu2020gcc}
Qiu, J., Chen, Q., Dong, Y., Zhang, J., Yang, H., Ding, M., Wang, K., and Tang,
  J. (2020).
\newblock Gcc: Graph contrastive coding for graph neural network pre-training.
\newblock In {\em Proceedings of the 26th ACM SIGKDD international conference
  on knowledge discovery \& data mining}, pages 1150--1160.

\bibitem[Rombach et~al., 2022]{rombach2022high}
Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B. (2022).
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10684--10695.

\bibitem[Song et~al., 2020]{song2020denoising}
Song, J., Meng, C., and Ermon, S. (2020).
\newblock Denoising diffusion implicit models.
\newblock {\em arXiv preprint arXiv:2010.02502}.

\bibitem[Sun et~al., 2019]{sun2019infograph}
Sun, F.-Y., Hoffmann, J., Verma, V., and Tang, J. (2019).
\newblock Infograph: Unsupervised and semi-supervised graph-level
  representation learning via mutual information maximization.
\newblock {\em arXiv preprint arXiv:1908.01000}.

\bibitem[Thakoor et~al., 2021]{thakoor2021large}
Thakoor, S., Tallec, C., Azar, M.~G., Azabou, M., Dyer, E.~L., Munos, R.,
  Veli{\v{c}}kovi{\'c}, P., and Valko, M. (2021).
\newblock Large-scale representation learning on graphs via bootstrapping.
\newblock {\em arXiv preprint arXiv:2102.06514}.

\bibitem[Velickovic et~al., 2019]{velickovic2019deep}
Velickovic, P., Fedus, W., Hamilton, W.~L., Li{\`o}, P., Bengio, Y., and Hjelm,
  R.~D. (2019).
\newblock Deep graph infomax.
\newblock {\em ICLR (Poster)}, 2(3):4.

\bibitem[Xu et~al., 2021]{xu2021infogcl}
Xu, D., Cheng, W., Luo, D., Chen, H., and Zhang, X. (2021).
\newblock Infogcl: Information-aware graph contrastive learning.
\newblock {\em Advances in Neural Information Processing Systems},
  34:30414--30425.

\bibitem[Xu et~al., 2018]{xu2018powerful}
Xu, K., Hu, W., Leskovec, J., and Jegelka, S. (2018).
\newblock How powerful are graph neural networks?
\newblock {\em arXiv preprint arXiv:1810.00826}.

\bibitem[Yanardag and Vishwanathan, 2015]{yanardag2015deep}
Yanardag, P. and Vishwanathan, S. (2015).
\newblock Deep graph kernels.
\newblock In {\em Proceedings of the 21th ACM SIGKDD international conference
  on knowledge discovery and data mining}, pages 1365--1374.

\bibitem[Yang et~al., 2016]{yang2016revisiting}
Yang, Z., Cohen, W., and Salakhudinov, R. (2016).
\newblock Revisiting semi-supervised learning with graph embeddings.
\newblock In {\em International conference on machine learning}, pages 40--48.
  PMLR.

\bibitem[Ying et~al., 2018]{ying2018hierarchical}
Ying, Z., You, J., Morris, C., Ren, X., Hamilton, W., and Leskovec, J. (2018).
\newblock Hierarchical graph representation learning with differentiable
  pooling.
\newblock {\em Advances in neural information processing systems}, 31.

\bibitem[You et~al., 2021]{you2021graph}
You, Y., Chen, T., Shen, Y., and Wang, Z. (2021).
\newblock Graph contrastive learning automated.
\newblock In {\em International Conference on Machine Learning}, pages
  12121--12132. PMLR.

\bibitem[You et~al., 2020]{you2020graph}
You, Y., Chen, T., Sui, Y., Chen, T., Wang, Z., and Shen, Y. (2020).
\newblock Graph contrastive learning with augmentations.
\newblock {\em Advances in neural information processing systems},
  33:5812--5823.

\bibitem[Zhang et~al., 2021]{zhang2021canonical}
Zhang, H., Wu, Q., Yan, J., Wipf, D., and Yu, P.~S. (2021).
\newblock From canonical correlation analysis to self-supervised graph neural
  networks.
\newblock {\em Advances in Neural Information Processing Systems}, 34:76--89.

\bibitem[Zhang et~al., 2022]{zhang2022unsupervised}
Zhang, Z., Zhao, Z., and Lin, Z. (2022).
\newblock Unsupervised representation learning from pre-trained diffusion
  probabilistic models.
\newblock {\em arXiv preprint arXiv:2212.12990}.

\bibitem[Zhu et~al., 2020]{zhu2020deep}
Zhu, Y., Xu, Y., Yu, F., Liu, Q., Wu, S., and Wang, L. (2020).
\newblock Deep graph contrastive representation learning.
\newblock {\em arXiv preprint arXiv:2006.04131}.

\end{thebibliography}
