\begin{thebibliography}{45}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Andriushchenko et~al.(2020)Andriushchenko, Croce, Flammarion, and
  Hein]{andriushchenko2020square}
Andriushchenko, M., Croce, F., Flammarion, N., and Hein, M.
\newblock Square attack: a query-efficient black-box adversarial attack via
  random search.
\newblock In \emph{European Conference on Computer Vision (ECCV)}, 2020.

\bibitem[Athalye et~al.(2018{\natexlab{a}})Athalye, Carlini, and
  Wagner]{athalye2018obfuscated}
Athalye, A., Carlini, N., and Wagner, D.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In \emph{International Conference on Machine Learning {(ICML)}},
  2018{\natexlab{a}}.

\bibitem[Athalye et~al.(2018{\natexlab{b}})Athalye, Engstrom, Ilyas, and
  Kwok]{athalye2018synthesizing}
Athalye, A., Engstrom, L., Ilyas, A., and Kwok, K.
\newblock Synthesizing robust adversarial examples.
\newblock In \emph{International conference on machine learning (ICLR)},
  2018{\natexlab{b}}.

\bibitem[Atsague et~al.(2021)Atsague, Fakorede, and Tian]{atsague2021mutual}
Atsague, M., Fakorede, O., and Tian, J.
\newblock A mutual information regularization for adversarial training.
\newblock In \emph{Asian Conference on Machine Learning}, pp.\  188--203. PMLR,
  2021.

\bibitem[Blei et~al.(2017)Blei, Kucukelbir, and McAuliffe]{blei2017variational}
Blei, D.~M., Kucukelbir, A., and McAuliffe, J.~D.
\newblock Variational inference: A review for statisticians.
\newblock \emph{Journal of the American statistical Association}, 2017.

\bibitem[Blundell et~al.(2015)Blundell, Cornebise, Kavukcuoglu, and
  Wierstra]{blundell2015weight}
Blundell, C., Cornebise, J., Kavukcuoglu, K., and Wierstra, D.
\newblock Weight uncertainty in neural network.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2015.

\bibitem[Brendel et~al.(2018)Brendel, Rauber, and Bethge]{brendel2017decision}
Brendel, W., Rauber, J., and Bethge, M.
\newblock Decision-based adversarial attacks: Reliable attacks against
  black-box machine learning models.
\newblock In \emph{International Conference on Learning Representations
  {(ICLR)}}, 2018.

\bibitem[Carbone et~al.(2020)Carbone, Wicker, Laurenti, Patane, Bortolussi, and
  Sanguinetti]{Carbone21}
Carbone, G., Wicker, M., Laurenti, L., Patane, A., Bortolussi, L., and
  Sanguinetti, G.
\newblock Robustness of {{Bayesian Neural Networks}} to {{Gradient-Based
  Attacks}}.
\newblock In \emph{Advances in Neural Information Processing Systems
  {NeurIPS}}, 2020.

\bibitem[Carlini \& Wagner(2017)Carlini and Wagner]{cw}
Carlini, N. and Wagner, D.
\newblock {Towards Evaluating the Robustness of Neural Networks}.
\newblock In \emph{IEEE Symposium on Security and Privacy (S\&P)}, 2017.

\bibitem[Chen et~al.(2020)Chen, Jordan, and
  Wainwright]{chen2020hopskipjumpattack}
Chen, J., Jordan, M.~I., and Wainwright, M.~J.
\newblock Hopskipjumpattack: A query-efficient decision-based attack.
\newblock In \emph{IEEE Symposium on Security and Privacy (S\&P)}, 2020.

\bibitem[Cheng et~al.(2020)Cheng, Singh, Chen, Chen, Liu, and
  Hsieh]{cheng2019sign}
Cheng, M., Singh, S., Chen, P., Chen, P.-Y., Liu, S., and Hsieh, C.-J.
\newblock Sign-opt: A query-efficient hard-label adversarial attack.
\newblock In \emph{International Conference on Learning Representations
  {(ICLR)}}, 2020.

\bibitem[Coates et~al.(2011)Coates, Ng, and Lee]{stl10}
Coates, A., Ng, A., and Lee, H.
\newblock {An Analysis of Single Layer Networks in Unsupervised Feature
  Learning}.
\newblock In \emph{AISTATS}, 2011.

\bibitem[Eykholt et~al.(2018)Eykholt, Evtimov, Fernandes, Li, Rahmati, Xiao,
  Prakash, Kohno, and Song]{eykholt2018robust}
Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C.,
  Prakash, A., Kohno, T., and Song, D.
\newblock Robust physical-world attacks on deep learning models.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition
  {(CVPR)}}, 2018.

\bibitem[Feinman et~al.(2017)Feinman, Curtin, Shintre, and
  Gardner]{feinman2017detecting}
Feinman, R., Curtin, R.~R., Shintre, S., and Gardner, A.~B.
\newblock Detecting adversarial samples from artifacts.
\newblock \emph{arXiv preprint arXiv:1703.00410}, 2017.

\bibitem[Gal et~al.(2017)Gal, Islam, and Ghahramani]{galDeepBayesianActive2017}
Gal, Y., Islam, R., and Ghahramani, Z.
\newblock Deep {{Bayesian Active Learning}} with {{Image Data}}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2017.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and Szegedy]{fgsm}
Goodfellow, I., Shlens, J., and Szegedy, C.
\newblock {Explaining and Harnessing Adversarial Examples}.
\newblock In \emph{International Conference on Learning Representations
  {(ICLR)}}, 2015.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition {(CVPR)}}, 2016.

\bibitem[Houlsby et~al.(2011)Houlsby, Huszár, Ghahramani, and
  Lengyel]{houlsbyBayesianActiveLearning2011}
Houlsby, N., Huszár, F., Ghahramani, Z., and Lengyel, M.
\newblock Bayesian {{Active Learning}} for {{Classification}} and {{Preference
  Learning}}.
\newblock 2011.

\bibitem[Izmailov et~al.(2021)Izmailov, Vikram, Hoffman, and
  Wilson]{izmailov2021bayesian}
Izmailov, P., Vikram, S., Hoffman, M.~D., and Wilson, A.~G.
\newblock What are bayesian neural network posteriors really like?
\newblock In \emph{International Conference on Machine Learning {(ICML)}},
  2021.

\bibitem[Krizhevsky et~al.()Krizhevsky, Nair, and Hinton]{cifar10}
Krizhevsky, A., Nair, V., and Hinton, G.
\newblock Cifar-10 (canadian institute for advanced research).
\newblock URL \url{http://www.cs.toronto.edu/~kriz/cifar.html}.

\bibitem[Kurakin et~al.(2018)Kurakin, Goodfellow, Bengio, Dong, Liao, Liang,
  Pang, Zhu, Hu, Xie, et~al.]{kurakin2018adversarial}
Kurakin, A., Goodfellow, I., Bengio, S., Dong, Y., Liao, F., Liang, M., Pang,
  T., Zhu, J., Hu, X., Xie, C., et~al.
\newblock Adversarial attacks and defences competition.
\newblock In \emph{The NIPS'17 Competition: Building Intelligent Systems}.
  2018.

\bibitem[Liu \& Wang(2016)Liu and Wang]{Liu2016}
Liu, Q. and Wang, D.
\newblock {Stein Variational Gradient Descent: A General Purpose Bayesian
  Inference Algorithm}.
\newblock \emph{Advances in Neural Information Processing Systems (NIPS)},
  2016.

\bibitem[Liu et~al.(2018)Liu, Cheng, Zhang, and Hsieh]{RSE}
Liu, X., Cheng, M., Zhang, H., and Hsieh, C.-J.
\newblock Towards robust neural networks via random self-ensemble.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  {(ECCV)}}, 2018.

\bibitem[Liu et~al.(2019)Liu, Li, Chongruo, and Cho-Jui]{advbnn}
Liu, X., Li, Y., Chongruo, W., and Cho-Jui, H.
\newblock {ADV-BNN: Improved Adversarial Defense Through Robust Bayesian Neural
  Network}.
\newblock In \emph{International Conference on Learning Representations
  {(ICLR)}}, 2019.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and Vladu]{pgd}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Neyshabur et~al.(2017)Neyshabur, Bhojanapalli, Mcallester, and
  Srebro]{generalisation_deep}
Neyshabur, B., Bhojanapalli, S., Mcallester, D., and Srebro, N.
\newblock Exploring generalization in deep learning.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2017.

\bibitem[Papernot et~al.(2016{\natexlab{a}})Papernot, McDaniel, and
  Goodfellow]{papernot2016transferability}
Papernot, N., McDaniel, P., and Goodfellow, I.
\newblock Transferability in machine learning: from phenomena to black-box
  attacks using adversarial samples.
\newblock \emph{arXiv preprint arXiv:1605.07277}, 2016{\natexlab{a}}.

\bibitem[Papernot et~al.(2016{\natexlab{b}})Papernot, McDaniel, Jha,
  Fredrikson, Celik, and Swami]{jsma}
Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.~B., and Swami,
  A.
\newblock The limitations of deep learning in adversarial settings.
\newblock In \emph{IEEE European symposium on security and privacy (EuroS\&P)},
  2016{\natexlab{b}}.

\bibitem[Papernot et~al.(2016{\natexlab{c}})Papernot, McDaniel, Jha,
  Fredrikson, Celik, and Swami]{papernot2016limitations}
Papernot, N., McDaniel, P., Jha, S., Fredrikson, M., Celik, Z.~B., and Swami,
  A.
\newblock The limitations of deep learning in adversarial settings.
\newblock In \emph{2016 IEEE European symposium on security and privacy
  (EuroS\&P)}, pp.\  372--387. IEEE, 2016{\natexlab{c}}.

\bibitem[Papernot et~al.(2017)Papernot, McDaniel, Goodfellow, Jha, Celik, and
  Swami]{papernot2017practical}
Papernot, N., McDaniel, P., Goodfellow, I., Jha, S., Celik, Z.~B., and Swami,
  A.
\newblock Practical black-box attacks against machine learning.
\newblock In \emph{Proceedings of the 2017 ACM on Asia conference on computer
  and communications security {(Asia CCS)}}, 2017.

\bibitem[Schmidt et~al.(2018)Schmidt, Santurkar, Tsipras, Talwar, and
  Madry]{schmidt18}
Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., and Madry, A.
\newblock Adversarially robust generalization requires more data.
\newblock In \emph{Advances in Neural Information Processing Systems
  {(NeurIPS)}}, 2018.

\bibitem[Smith \& Gal(2018)Smith and Gal]{smith2018understanding}
Smith, L. and Gal, Y.
\newblock Understanding measures of uncertainty for adversarial example
  detection.
\newblock \emph{arXiv preprint arXiv:1803.08533}, 2018.

\bibitem[Song et~al.(2017)Song, Kim, Nowozin, Ermon, and
  Kushman]{song2017pixeldefend}
Song, Y., Kim, T., Nowozin, S., Ermon, S., and Kushman, N.
\newblock Pixeldefend: Leveraging generative models to understand and defend
  against adversarial examples.
\newblock \emph{arXiv preprint arXiv:1710.10766}, 2017.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{Szegedy2014}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock {Intriguing properties of neural networks}.
\newblock In \emph{International Conference on Learning Representations
  {(ICLR)}}, 2014.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In \emph{Advances in neural information processing systems {(NIPS)}},
  2017.

\bibitem[Vo et~al.(2022{\natexlab{a}})Vo, Abbasnejad, and Ranasinghe]{Vo2022}
Vo, V.~Q., Abbasnejad, E., and Ranasinghe, D.~C.
\newblock Ramboattack: A robust query efficient deep neural network decision
  exploit.
\newblock In \emph{Network and Distributed Systems Security (NDSS) Symposium},
  2022{\natexlab{a}}.

\bibitem[Vo et~al.(2022{\natexlab{b}})Vo, Abbasnejad, and
  Ranasinghe]{vo2022query}
Vo, V.~Q., Abbasnejad, E., and Ranasinghe, D.~C.
\newblock Query efficient decision based sparse attacks against black-box deep
  learning models.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2022{\natexlab{b}}.

\bibitem[Wang \& Liu(2019)Wang and Liu]{wang2019nonlinear}
Wang, D. and Liu, Q.
\newblock Nonlinear stein variational gradient descent for learning diversified
  mixture models.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2019.

\bibitem[Welling \& Teh(2011)Welling and Teh]{welling2011bayesian}
Welling, M. and Teh, Y.~W.
\newblock Bayesian learning via stochastic gradient langevin dynamics.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2011.

\bibitem[Wicker et~al.(2021)Wicker, Laurenti, Patane, Chen, Zhang, and
  Kwiatkowska]{wicker21}
Wicker, M., Laurenti, L., Patane, A., Chen, Z., Zhang, Z., and Kwiatkowska, M.
\newblock Bayesian {{Inference}} with {{Certifiable Adversarial Robustness}}.
\newblock In \emph{Proceedings of The 24th International Conference on
  Artificial Intelligence and Statistics (AISTATS}, 2021.

\bibitem[Xie et~al.(2019)Xie, Wu, Maaten, Yuille, and He]{xie2019feature}
Xie, C., Wu, Y., Maaten, L. v.~d., Yuille, A.~L., and He, K.
\newblock Feature denoising for improving adversarial robustness.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, 2019.

\bibitem[Ye \& Zhu(2018)Ye and Zhu]{BAL}
Ye, N. and Zhu, Z.
\newblock Bayesian adversarial learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2018.

\bibitem[Yuan et~al.(2021)Yuan, Wicker, and Laurenti]{Yuan2020}
Yuan, M., Wicker, M., and Laurenti, L.
\newblock Gradient-{{Free Adversarial Attacks}} for {{Bayesian Neural
  Networks}}.
\newblock In \emph{Advances in Approximate Bayesian Inference (AABI)}, 2021.

\bibitem[Zhu et~al.(2020)Zhu, Zhang, and Evans]{zhu2020learning}
Zhu, S., Zhang, X., and Evans, D.
\newblock Learning adversarially robust representations via worst-case mutual
  information maximization.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  11609--11618. PMLR, 2020.

\bibitem[Zimmermann(2019)]{rol2019comment}
Zimmermann, R.~S.
\newblock Comment on" adv-bnn: Improved adversarial defense through robust
  bayesian neural network".
\newblock \emph{arXiv preprint arXiv:1907.00895}, 2019.

\end{thebibliography}
