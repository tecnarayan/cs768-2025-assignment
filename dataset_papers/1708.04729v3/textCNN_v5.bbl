\begin{thebibliography}{10}

\bibitem{dai2015semi}
Andrew~M Dai and Quoc~V Le.
\newblock Semi-supervised sequence learning.
\newblock In {\em NIPS}, 2015.

\bibitem{le2014distributed}
Quoc Le and Tomas Mikolov.
\newblock Distributed representations of sentences and documents.
\newblock In {\em ICML}, 2014.

\bibitem{Johnson:2016ud}
Rie Johnson and Tong Zhang.
\newblock {Supervised and Semi-Supervised Text Categorization using LSTM for
  Region Embeddings}.
\newblock {\em arXiv}, February 2016.

\bibitem{Miyato:2016vj}
Takeru Miyato, Andrew~M Dai, and Ian Goodfellow.
\newblock {Adversarial Training Methods for Semi-Supervised Text
  Classification}.
\newblock In {\em ICLR}, May 2017.

\bibitem{Bahdanau:2014vz}
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.
\newblock {Neural Machine Translation by Jointly Learning to Align and
  Translate}.
\newblock In {\em ICLR}, 2015.

\bibitem{cho2014learning}
Kyunghyun Cho, Bart Van~Merri{\"e}nboer, Caglar Gulcehre, Dzmitry Bahdanau,
  Fethi Bougares, Holger Schwenk, and Yoshua Bengio.
\newblock Learning phrase representations using rnn encoder-decoder for
  statistical machine translation.
\newblock In {\em EMNLP}, 2014.

\bibitem{meng2015encoding}
Fandong Meng, Zhengdong Lu, Mingxuan Wang, Hang Li, Wenbin Jiang, and Qun Liu.
\newblock Encoding source language with convolutional neural network for
  machine translation.
\newblock In {\em ACL}, 2015.

\bibitem{wen2015semantically}
Tsung-Hsien Wen, Milica Gasic, Nikola Mrksic, Pei-Hao Su, David Vandyke, and
  Steve Young.
\newblock Semantically conditioned lstm-based natural language generation for
  spoken dialogue systems.
\newblock {\em arXiv}, 2015.

\bibitem{li2016deep}
Jiwei Li, Will Monroe, Alan Ritter, Michel Galley, Jianfeng Gao, and Dan
  Jurafsky.
\newblock Deep reinforcement learning for dialogue generation.
\newblock {\em arXiv}, 2016.

\bibitem{li2017adversarial}
Jiwei Li, Will Monroe, Tianlin Shi, Alan Ritter, and Dan Jurafsky.
\newblock Adversarial learning for neural dialogue generation.
\newblock {\em arXiv:1701.06547}, 2017.

\bibitem{Nallapati:2016vr}
Ramesh Nallapati, Bowen Zhou, Cicero Nogueira~dos santos, Caglar Gulcehre, and
  Bing Xiang.
\newblock {Abstractive Text Summarization Using Sequence-to-Sequence RNNs and
  Beyond}.
\newblock In {\em CoNLL}, 2016.

\bibitem{Narayan:2017ux}
Shashi Narayan, Nikos Papasarantopoulos, Mirella Lapata, and Shay~B Cohen.
\newblock {Neural Extractive Summarization with Side Information}.
\newblock {\em arXiv}, April 2017.

\bibitem{Rush:2015vh}
Alexander~M Rush, Sumit Chopra, and Jason Weston.
\newblock {A Neural Attention Model for Abstractive Sentence Summarization}.
\newblock In {\em EMNLP}, 2015.

\bibitem{sutskever2014sequence}
Ilya Sutskever, Oriol Vinyals, and Quoc~V Le.
\newblock Sequence to sequence learning with neural networks.
\newblock In {\em NIPS}, 2014.

\bibitem{mikolov2010recurrent}
Tomas Mikolov, Martin Karafi{\'a}t, Lukas Burget, Jan Cernock{\`y}, and Sanjeev
  Khudanpur.
\newblock Recurrent neural network based language model.
\newblock In {\em INTERSPEECH}, 2010.

\bibitem{hochreiter1997long}
Sepp Hochreiter and J{\"u}rgen Schmidhuber.
\newblock Long short-term memory.
\newblock In {\em Neural computation}, 1997.

\bibitem{chung2014empirical}
Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio.
\newblock Empirical evaluation of gated recurrent neural networks on sequence
  modeling.
\newblock {\em arXiv}, 2014.

\bibitem{williams1989learning}
Ronald~J Williams and David Zipser.
\newblock A learning algorithm for continually running fully recurrent neural
  networks.
\newblock {\em Neural computation}, 1(2):270--280, 1989.

\bibitem{bengio2015scheduled}
Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and Noam Shazeer.
\newblock Scheduled sampling for sequence prediction with recurrent neural
  networks.
\newblock In {\em NIPS}, 2015.

\bibitem{huszar2015not}
Ferenc Husz{\'a}r.
\newblock How (not) to train your generative model: Scheduled sampling,
  likelihood, adversary?
\newblock {\em arXiv}, 2015.

\bibitem{kalchbrenner2014convolutional}
Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom.
\newblock A convolutional neural network for modelling sentences.
\newblock In {\em ACL}, 2014.

\bibitem{kim2014convolutional}
Yoon Kim.
\newblock Convolutional neural networks for sentence classification.
\newblock In {\em EMNLP}, 2014.

\bibitem{gulrajani2016pixelvae}
Ishaan Gulrajani, Kundan Kumar, Faruk Ahmed, Adrien~Ali Taiga, Francesco Visin,
  David Vazquez, and Aaron Courville.
\newblock Pixelvae: A latent variable model for natural images.
\newblock {\em arXiv}, 2016.

\bibitem{radford2015unsupervised}
Alec Radford, Luke Metz, and Soumith Chintala.
\newblock Unsupervised representation learning with deep convolutional
  generative adversarial networks.
\newblock {\em arXiv}, 2015.

\bibitem{nair2010rectified}
Vinod Nair and Geoffrey~E Hinton.
\newblock Rectified linear units improve restricted boltzmann machines.
\newblock In {\em ICML}, pages 807--814, 2010.

\bibitem{chiswell2007mathematical}
Ian Chiswell and Wilfrid Hodges.
\newblock {\em Mathematical logic}, volume~3.
\newblock OUP Oxford, 2007.

\bibitem{gumbel1954statistical}
Emil~Julius Gumbel and Julius Lieblein.
\newblock Statistical theory of extreme values and some practical applications:
  a series of lectures.
\newblock 1954.

\bibitem{collobert2011natural}
Ronan Collobert, Jason Weston, L{\'e}on Bottou, Michael Karlen, Koray
  Kavukcuoglu, and Pavel Kuksa.
\newblock Natural language processing (almost) from scratch.
\newblock In {\em JMLR}, 2011.

\bibitem{chetlur2014cudnn}
Sharan Chetlur, Cliff Woolley, Philippe Vandermersch, Jonathan Cohen, John
  Tran, Bryan Catanzaro, and Evan Shelhamer.
\newblock cudnn: Efficient primitives for deep learning.
\newblock {\em arXiv}, 2014.

\bibitem{Yang:2016ue}
Zichao Yang, Diyi Yang, Chris Dyer, Xiaodong He, Alex Smola, and Eduard Hovy.
\newblock {Hierarchical attention networks for document classification}.
\newblock In {\em NAACL}, 2016.

\bibitem{Dieng:2016wz}
Adji~B Dieng, Chong Wang, Jianfeng Gao, and John Paisley.
\newblock {TopicRNN: A Recurrent Neural Network with Long-Range Semantic
  Dependency}.
\newblock In {\em ICLR}, 2016.

\bibitem{kingma2014semi}
Diederik~P Kingma, Shakir Mohamed, Danilo~Jimenez Rezende, and Max Welling.
\newblock Semi-supervised learning with deep generative models.
\newblock In {\em NIPS}, 2014.

\bibitem{pu2016variational}
Yunchen Pu, Zhe Gan, Ricardo Henao, Xin Yuan, Chunyuan Li, Andrew Stevens, and
  Lawrence Carin.
\newblock Variational autoencoder for deep learning of images, labels and
  captions.
\newblock In {\em NIPS}, 2016.

\bibitem{hochreiter2001gradient}
Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and J{\"u}rgen Schmidhuber.
\newblock Gradient flow in recurrent nets: the difficulty of learning long-term
  dependencies, 2001.

\bibitem{socher2011semi}
Richard Socher, Jeffrey Pennington, Eric~H Huang, Andrew~Y Ng, and
  Christopher~D Manning.
\newblock Semi-supervised recursive autoencoders for predicting sentiment
  distributions.
\newblock In {\em EMNLP}. Association for Computational Linguistics, 2011.

\bibitem{bowman2015generating}
Samuel~R Bowman, Luke Vilnis, Oriol Vinyals, Andrew~M Dai, Rafal Jozefowicz,
  and Samy Bengio.
\newblock Generating sentences from a continuous space.
\newblock {\em arXiv}, 2015.

\bibitem{Yang:2017ux}
Zichao Yang, Zhiting Hu, Ruslan Salakhutdinov, and Taylor Berg-Kirkpatrick.
\newblock {Improved Variational Autoencoders for Text Modeling using Dilated
  Convolutions}.
\newblock {\em arXiv}, February 2017.

\bibitem{hu2014convolutional}
Baotian Hu, Zhengdong Lu, Hang Li, and Qingcai Chen.
\newblock Convolutional neural network architectures for matching natural
  language sentences.
\newblock In {\em NIPS}, 2014.

\bibitem{johnson2014effective}
Rie Johnson and Tong Zhang.
\newblock Effective use of word order for text categorization with
  convolutional neural networks.
\newblock In {\em NAACL HLT}, 2015.

\bibitem{springenberg2014striving}
Jost~Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox, and Martin
  Riedmiller.
\newblock Striving for simplicity: The all convolutional net.
\newblock {\em arXiv}, 2014.

\bibitem{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In {\em ICLR}, 2015.

\bibitem{Semeniuta:2017ut}
Stanislau Semeniuta, Aliaksei Severyn, and Erhardt Barth.
\newblock {A Hybrid Convolutional Variational Autoencoder for Text Generation}.
\newblock {\em arXiv}, February 2017.

\bibitem{kalchbrenner2016neural}
Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van~den Oord, Alex
  Graves, and Koray Kavukcuoglu.
\newblock Neural machine translation in linear time.
\newblock {\em arXiv}, 2016.

\bibitem{Dauphin:2016uj}
Yann~N Dauphin, Angela Fan, Michael Auli, and David Grangier.
\newblock {Language Modeling with Gated Convolutional Networks}.
\newblock {\em arXiv}, December 2016.

\bibitem{2017arXiv170503122G}
J.~{Gehring}, M.~{Auli}, D.~{Grangier}, D.~{Yarats}, and Y.~N. {Dauphin}.
\newblock {Convolutional Sequence to Sequence Learning}.
\newblock {\em arXiv}, May 2017.

\bibitem{van2016conditional}
Aaron van~den Oord, Nal Kalchbrenner, Lasse Espeholt, Oriol Vinyals, Alex
  Graves, et~al.
\newblock Conditional image generation with pixelcnn decoders.
\newblock In {\em NIPS}, pages 4790--4798, 2016.

\bibitem{Li:2015wg}
Jiwei Li, Minh-Thang Luong, and Dan Jurafsky.
\newblock A hierarchical neural autoencoder for paragraphs and documents.
\newblock In {\em ACL}, 2015.

\bibitem{mikolov2013distributed}
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg~S Corrado, and Jeff Dean.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In {\em NIPS}, 2013.

\bibitem{wong2008extractive}
Kam-Fai Wong, Mingli Wu, and Wenjie Li.
\newblock Extractive summarization using supervised and semi-supervised
  learning.
\newblock In {\em ICCL}. Association for Computational Linguistics, 2008.

\bibitem{lin2004rouge}
Chin-Yew Lin.
\newblock Rouge: A package for automatic evaluation of summaries.
\newblock In {\em ACL workshop}, 2004.

\bibitem{papineni2002bleu}
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
\newblock Bleu: a method for automatic evaluation of machine translation.
\newblock In {\em ACL}. Association for Computational Linguistics, 2002.

\bibitem{zhang2015character}
Xiang Zhang, Junbo Zhao, and Yann LeCun.
\newblock Character-level convolutional networks for text classification.
\newblock In {\em NIPS}, pages 649--657, 2015.

\bibitem{bahdanau2016actor}
Dzmitry Bahdanau, Philemon Brakel, Kelvin Xu, Anirudh Goyal, Ryan Lowe, Joelle
  Pineau, Aaron Courville, and Yoshua Bengio.
\newblock An actor-critic algorithm for sequence prediction.
\newblock {\em arXiv}, 2016.

\bibitem{woodard1982information}
JP~Woodard and JT~Nelson.
\newblock An information theoretic measure of speech recognition performance.
\newblock In {\em Workshop on standardisation for speech I/O}, 1982.

\bibitem{kingma2014adam}
Diederik Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock In {\em ICLR}, 2015.

\bibitem{glorot2010understanding}
Xavier Glorot and Yoshua Bengio.
\newblock Understanding the difficulty of training deep feedforward neural
  networks.
\newblock In {\em AISTATS}, 2010.

\end{thebibliography}
