\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abernethy et~al.(2008)Abernethy, Bartlett, Rakhlin, and
  Tewari]{Minimax:Online}
Jacob Abernethy, Peter~L. Bartlett, Alexander Rakhlin, and Ambuj Tewari.
\newblock Optimal stragies and minimax lower bounds for online convex games.
\newblock In \emph{Proceedings of the 21st Annual Conference on Learning
  Theory}, pages 415--423, 2008.

\bibitem[Altschuler and Talwar(2018)]{altschuler2018online}
Jason Altschuler and Kunal Talwar.
\newblock Online learning over a finite action set with limited switching.
\newblock In \emph{Proceedings of the 31st Annual Conference on Learning
  Theory}, pages 1569--1573, 2018.

\bibitem[Antoniadis and Schewior(2017)]{antoniadis2017tight}
Antonios Antoniadis and Kevin Schewior.
\newblock A tight lower bound for online convex optimization with switching
  costs.
\newblock In \emph{International Workshop on Approximation and Online
  Algorithms}, pages 164--175, 2017.

\bibitem[Badiei et~al.(2015)Badiei, Li, and Wierman]{badiei2015online}
Masoud Badiei, Na~Li, and Adam Wierman.
\newblock Online convex optimization with ramp constraints.
\newblock In \emph{2015 54th IEEE Conference on Decision and Control}, pages
  6730--6736, 2015.

\bibitem[Bansal et~al.(2015)Bansal, Gupta, Krishnaswamy, Pruhs, Schewior, and
  Stein]{bansal20152}
Nikhil Bansal, Anupam Gupta, Ravishankar Krishnaswamy, Kirk Pruhs, Kevin
  Schewior, and Cliff Stein.
\newblock A 2-competitive algorithm for online convex optimization with
  switching costs.
\newblock In \emph{Algorithms and Techniques for Approximation, Randomization,
  and Combinatorial Optimization}, 2015.

\bibitem[Borodin and El-Yaniv(2005)]{borodin2005online}
Allan Borodin and Ran El-Yaniv.
\newblock \emph{Online computation and competitive analysis}.
\newblock cambridge university press, 2005.

\bibitem[Boyd and Vandenberghe(2004)]{Convex-Optimization}
Stephen Boyd and Lieven Vandenberghe.
\newblock \emph{Convex Optimization}.
\newblock Cambridge University Press, 2004.

\bibitem[Chen et~al.(2020)Chen, Yu, Lawrence, and Karbasi]{chen2019minimax}
Lin Chen, Qian Yu, Hannah Lawrence, and Amin Karbasi.
\newblock Minimax regret of switching-constrained online convex optimization:
  No phase transition.
\newblock In \emph{Advances in Neural Information Processing Systems 33}, 2020.

\bibitem[Chen et~al.(2015)Chen, Agarwal, Wierman, Barman, and
  Andrew]{chen2015online}
Niangjun Chen, Anish Agarwal, Adam Wierman, Siddharth Barman, and Lachlan~LH
  Andrew.
\newblock Online convex optimization using predictions.
\newblock In \emph{Proceedings of the 2015 ACM SIGMETRICS International
  Conference on Measurement and Modeling of Computer Systems}, pages 191--204,
  2015.

\bibitem[Chen et~al.(2016)Chen, Comden, Liu, Gandhi, and
  Wierman]{chen2016using}
Niangjun Chen, Joshua Comden, Zhenhua Liu, Anshul Gandhi, and Adam Wierman.
\newblock Using predictions in online optimization: Looking forward with an eye
  on the past.
\newblock \emph{ACM SIGMETRICS Performance Evaluation Review}, 44\penalty0
  (1):\penalty0 193--206, 2016.

\bibitem[Chen et~al.(2018)Chen, Goel, and Wierman]{chen2018smoothed}
Niangjun Chen, Gautam Goel, and Adam Wierman.
\newblock Smoothed online convex optimization in high dimensions via online
  balanced descent.
\newblock In \emph{Proceedings of the 31st Annual Conference on Learning
  Theory}, pages 1574--1594, 2018.

\bibitem[Dekel et~al.(2014)Dekel, Ding, Koren, and Peres]{dekel2014bandits}
Ofer Dekel, Jian Ding, Tomer Koren, and Yuval Peres.
\newblock Bandits with switching costs: T 2/3 regret.
\newblock In \emph{Proceedings of the 46th annual ACM symposium on Theory of
  computing}, pages 459--467, 2014.

\bibitem[Dong et~al.(2020)Dong, Li, Zhang, and Zhou]{dong2020multinomial}
Kefan Dong, Yingkai Li, Qin Zhang, and Yuan Zhou.
\newblock Multinomial logit bandit with low switching cost.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, pages 2607--2615, 2020.

\bibitem[Flaxman et~al.(2005)Flaxman, Kalai, and McMahan]{flaxman2005online}
Abraham~D Flaxman, Adam~Tauman Kalai, and H~Brendan McMahan.
\newblock Online convex optimization in the bandit setting: gradient descent
  without a gradient.
\newblock In \emph{Proceedings of the 16th annual ACM-SIAM symposium on
  Discrete algorithms}, pages 385--394, 2005.

\bibitem[Gaillard et~al.(2014)Gaillard, Stoltz, and
  Van~Erven]{gaillard2014second}
Pierre Gaillard, Gilles Stoltz, and Tim Van~Erven.
\newblock A second-order bound with excess losses.
\newblock In \emph{Proceedings of the 27th Annual Conference on Learning
  Theory}, pages 176--196, 2014.

\bibitem[Goel et~al.(2017)Goel, Chen, and Wierman]{goel2017thinking}
Gautam Goel, Niangjun Chen, and Adam Wierman.
\newblock Thinking fast and slow: Optimization decomposition across timescales.
\newblock In \emph{2017 IEEE 56th Annual Conference on Decision and Control},
  pages 1291--1298, 2017.

\bibitem[Goel et~al.(2019)Goel, Lin, Sun, and Wierman]{goel2019beyond}
Gautam Goel, Yiheng Lin, Haoyuan Sun, and Adam Wierman.
\newblock Beyond online balanced descent: An optimal algorithm for smoothed
  online optimization.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pages
  1875--1885, 2019.

\bibitem[Hazan(2016)]{Intro:Online:Convex}
Elad Hazan.
\newblock Introduction to online convex optimization.
\newblock \emph{Foundations and Trends in Optimization}, 2\penalty0
  (3-4):\penalty0 157--325, 2016.

\bibitem[Hazan and Seshadhri(2009)]{hazan2009efficient}
Elad Hazan and Comandur Seshadhri.
\newblock Efficient learning algorithms for changing environments.
\newblock In \emph{Proceedings of the 26th International Conference on Machine
  Learning}, pages 393--400, 2009.

\bibitem[Hazan et~al.(2007)Hazan, Agarwal, and Kale]{Hazan:2007:log}
Elad Hazan, Amit Agarwal, and Satyen Kale.
\newblock Logarithmic regret algorithms for online convex optimization.
\newblock \emph{Machine Learning}, 69\penalty0 (2-3):\penalty0 169--192, 2007.

\bibitem[Jaghargh et~al.(2019)Jaghargh, Krause, Lattanzi, and
  Vassilvtiskii]{jaghargh2019consistent}
Mohammad Reza~Karimi Jaghargh, Andreas Krause, Silvio Lattanzi, and Sergei
  Vassilvtiskii.
\newblock Consistent online optimization: Convex and submodular.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 2241--2250, 2019.

\bibitem[Jenatton et~al.(2016)Jenatton, Huang, and
  Archambeau]{jenatton2016adaptive}
Rodolphe Jenatton, Jim Huang, and Cdric Archambeau.
\newblock Adaptive algorithms for online convex optimization with long-term
  constraints.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, pages 402--411, 2016.

\bibitem[Joseph and de~Veciana(2012)]{joseph2012jointly}
Vinay Joseph and Gustavo de~Veciana.
\newblock Jointly optimizing multi-user rate adaptation for video transport
  over wireless systems: Mean-fairness-variability tradeoffs.
\newblock In \emph{Proceedings of the 31st Annual IEEE International Conference
  on Computer Communications}, pages 567--575, 2012.

\bibitem[Koolen et~al.(2010)Koolen, Warmuth, Kivinen,
  et~al.]{koolen2010hedging}
Wouter~M Koolen, Manfred~K Warmuth, Jyrki Kivinen, et~al.
\newblock Hedging structured concepts.
\newblock In \emph{Proceedings of the 23rd Annual Conference on Learning
  Theory}, pages 93--105, 2010.

\bibitem[Li et~al.(2018)Li, Qu, and Li]{li2018using}
Yingying Li, Guannan Qu, and Na~Li.
\newblock Using predictions in online optimization with switching costs: A fast
  algorithm and a fundamental limit.
\newblock In \emph{2018 Annual American Control Conference}, pages 3008--3013,
  2018.

\bibitem[Liakopoulos et~al.(2019)Liakopoulos, Destounis, Paschos, Spyropoulos,
  and Mertikopoulos]{liakopoulos2019cautious}
Nikolaos Liakopoulos, Apostolos Destounis, Georgios Paschos, Thrasyvoulos
  Spyropoulos, and Panayotis Mertikopoulos.
\newblock Cautious regret minimization: Online optimization with long-term
  budget constraints.
\newblock In \emph{Proceedings of the 39th International Conference on Machine
  Learning}, pages 3944--3952, 2019.

\bibitem[Lin et~al.(2012{\natexlab{a}})Lin, Liu, Wierman, and
  Andrew]{lin2012online}
Minghong Lin, Zhenhua Liu, Adam Wierman, and Lachlan~LH Andrew.
\newblock Online algorithms for geographical load balancing.
\newblock In \emph{International Green Computing Conference}, pages 1--10,
  2012{\natexlab{a}}.

\bibitem[Lin et~al.(2012{\natexlab{b}})Lin, Wierman, Andrew, and
  Thereska]{lin2012dynamic}
Minghong Lin, Adam Wierman, Lachlan~LH Andrew, and Eno Thereska.
\newblock Dynamic right-sizing for power-proportional data centers.
\newblock \emph{IEEE/ACM Transactions on Networking}, 21\penalty0 (5):\penalty0
  1378--1391, 2012{\natexlab{b}}.

\bibitem[Mahdavi et~al.(2012)Mahdavi, Jin, and Yang]{mahdavi2012trading}
Mehrdad Mahdavi, Rong Jin, and Tianbao Yang.
\newblock Trading regret for efficiency: online convex optimization with long
  term constraints.
\newblock \emph{The Journal of Machine Learning Research}, 13\penalty0
  (1):\penalty0 2503--2528, 2012.

\bibitem[Mannor et~al.(2009)Mannor, Tsitsiklis, and Yu]{mannor2009online}
Shie Mannor, John~N Tsitsiklis, and Jia~Yuan Yu.
\newblock Online learning with sample path constraints.
\newblock \emph{Journal of Machine Learning Research}, 10\penalty0 (3), 2009.

\bibitem[McMahan and Streeter(2010)]{mcmahan2010adaptive}
H~Brendan McMahan and Matthew Streeter.
\newblock Adaptive bound optimization for online convex optimization.
\newblock In \emph{Proceedings of the 23rd Annual Conference on Learning
  Theory}, pages 224--256, 2010.

\bibitem[Neely and Yu(2017)]{neely2017online}
Michael~J Neely and Hao Yu.
\newblock Online convex optimization with time-varying constraints.
\newblock \emph{arXiv preprint arXiv:1702.04783}, 2017.

\bibitem[Orabona(2019)]{orabona2019modern}
Francesco Orabona.
\newblock A modern introduction to online learning.
\newblock \emph{arXiv preprint arXiv:1912.13213}, 2019.

\bibitem[Ruan et~al.(2020)Ruan, Yang, and Zhou]{ruan2020linear}
Yufei Ruan, Jiaqi Yang, and Yuan Zhou.
\newblock Linear bandits with limited adaptivity and learning distributional
  optimal design.
\newblock \emph{arXiv preprint arXiv:2007.01980}, 2020.

\bibitem[Shalev-Shwartz(2011)]{Online:suvery}
Shai Shalev-Shwartz.
\newblock Online learning and online convex optimization.
\newblock \emph{Foundations and Trends in Machine Learning}, 4\penalty0
  (2):\penalty0 107--194, 2011.

\bibitem[Simchi-Levi and Xu(2019)]{switchbandits2019}
David Simchi-Levi and Yunzong Xu.
\newblock Phase transitions and cyclic phenomena in bandits with switching
  constraints.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pages
  7523--7532, 2019.

\bibitem[Valls et~al.(2020)Valls, Iosifidis, Leith, and
  Tassiulas]{valls2020online}
Victor Valls, George Iosifidis, Douglas Leith, and Leandros Tassiulas.
\newblock Online convex optimization with perturbed constraints: Optimal rates
  against stronger benchmarks.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 2885--2895, 2020.

\bibitem[Yi et~al.(2020)Yi, Li, Xie, and Johansson]{yi2020distributed}
Xinlei Yi, Xiuxian Li, Lihua Xie, and Karl~H Johansson.
\newblock Distributed online convex optimization with time-varying coupled
  inequality constraints.
\newblock \emph{IEEE Transactions on Signal Processing}, 68:\penalty0 731--746,
  2020.

\bibitem[Yu et~al.(2017)Yu, Neely, and Wei]{yu2017online}
Hao Yu, Michael~J Neely, and Xiaohan Wei.
\newblock Online convex optimization with stochastic constraints.
\newblock In \emph{Advances in Neural Information Processing Systems 30}, pages
  1427--1437, 2017.

\bibitem[Zanini et~al.(2010)Zanini, Atienza, De~Micheli, and
  Boyd]{zanini2010online}
Francesco Zanini, David Atienza, Giovanni De~Micheli, and Stephen~P Boyd.
\newblock Online convex optimization-based algorithm for thermal management of
  mpsocs.
\newblock In \emph{Proceedings of the 20th symposium on Great lakes symposium
  on VLSI}, pages 203--208, 2010.

\bibitem[Zinkevich(2003)]{zinkevich-2003-online}
Martin Zinkevich.
\newblock Online convex programming and generalized infinitesimal gradient
  ascent.
\newblock In \emph{Proceedings of the 20th International Conference on Machine
  Learning}, pages 928--936, 2003.

\end{thebibliography}
