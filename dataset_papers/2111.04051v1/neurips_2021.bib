
@article{sharma2020distributed,
  title={A distributed reinforcement learning based sensor node scheduling algorithm for coverage and connectivity maintenance in wireless sensor network},
  author={Sharma, Anamika and Chauhan, Siddhartha},
  journal={Wireless Networks},
  volume={26},
  number={6},
  pages={4411--4429},
  year={2020},
  publisher={Springer}
}
@inproceedings{fullmoba,
  author    = {Deheng Ye and
               Guibin Chen and
               Wen Zhang and
               Sheng Chen and
               Bo Yuan and
               Bo Liu and
               Jia Chen and
               Zhao Liu and
               Fuhao Qiu and
               Hongsheng Yu and
               Yinyuting Yin and
               Bei Shi and
               Liang Wang and
               Tengfei Shi and
               Qiang Fu and
               Wei Yang and
               Lanxiao Huang and
               Wei Liu},
  title     = {Towards Playing Full {MOBA} Games with Deep Reinforcement Learning},
  booktitle = {Advances in Neural Information Processing Systems},
  pages={21--632},
  year={2020}
}

@article{wu2020multi,
  title={Multi-agent deep reinforcement learning for urban traffic light control in vehicular networks},
  author={Wu, Tong and Zhou, Pan and Liu, Kai and Yuan, Yali and Wang, Xiumin and Huang, Huawei and Wu, Dapeng Oliver},
  journal={IEEE Transactions on Vehicular Technology},
  volume={69},
  number={8},
  pages={8243--8256},
  year={2020},
  publisher={IEEE}
}


@article{yu2019distributed,
  title={Distributed multiagent coordinated learning for autonomous driving in highways based on dynamic coordination graphs},
  author={Yu, Chao and Wang, Xin and Xu, Xin and Zhang, Minjie and Ge, Hongwei and Ren, Jiankang and Sun, Liang and Chen, Bingcai and Tan, Guozhen},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  volume={21},
  number={2},
  pages={735--748},
  year={2019},
  publisher={IEEE}
}

@article{lu2019artificial,
  title={Artificial agent: The fusion of artificial intelligence and a mobile agent for energy-efficient traffic control in wireless sensor networks},
  author={Lu, Jiayi and Feng, Luanye and Yang, Jun and Hassan, Mohammad Mehedi and Alelaiwi, Abdulhameed and Humar, Iztok},
  journal={Future Generation Computer Systems},
  year={2019},
  publisher={Elsevier}
}


@inproceedings{su2020value,
  title={Value-Decomposition Multi-Agent Actor-Critics},
  author={Su, Jianyu and Adams, Stephen and Beling, Peter},
  booktitle={Proceedings of the Conference of Association for the Advancement of Artificial Intelligence},
  volume={35},
  number={13},
  pages={11352--11360},
  year={2021}
}


@article{deisenroth2013survey,
  title={A survey on policy search for robotics},
  author={Deisenroth, Marc Peter and Neumann, Gerhard and Peters, Jan and others},
  journal={Foundations and trends in Robotics},
  volume={2},
  number={1-2},
  pages={388--403},
  year={2013},
  publisher={now publishers}
}

@article{tampuu2017multagent,
  title={Multiagent cooperation and competition with deep reinforcement learning},
  author={Tampuu, Ardi and Matiisen, Tambet and Kodelja, Dorian and Kuzovkin, Ilya and Korjus, Kristjan and Aru, Juhan and Aru, Jaan and Vicente, Raul},
  journal={PloS one},
  volume={12},
  number={4},
  pages={e0172395},
  year={2017}
}


@inproceedings{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International Conference on Machine Learning},
  pages={1587--1596},
  year={2018}
}

@article{shalev2016safe,
  title={Safe, multi-agent, reinforcement learning for autonomous driving},
  author={Shalev-Shwartz, Shai and Shammah, Shaked and Shashua, Amnon},
  journal={arXiv preprint arXiv:1610.03295},
  year={2016}
}

@inproceedings{mehdi2014cupcarbon,
  title={Cupcarbon: A multi-agent and discrete event wireless sensor network design and simulation tool},
  author={Mehdi, Kamal and Lounis, Massinissa and Bounceur, Ahc{\`e}ne and Kechadi, Tahar},
  booktitle={7th International ICST Conference on Simulation Tools and Techniques, Lisbon, Portugal, 17-19 March 2014},
  pages={126--131},
  year={2014},
  organization={Institute for Computer Science, Social Informatics and Telecommunications~…}
}


@article{grondman2012survey,
  title={A survey of actor-critic reinforcement learning: Standard and natural policy gradients},
  author={Grondman, Ivo and Busoniu, Lucian and Lopes, Gabriel AD and Babuska, Robert},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  volume={42},
  number={6},
  pages={1291--1307},
  year={2012},
  publisher={IEEE}
}

@inproceedings{zhao2011analysis,
  title={Analysis and Improvement of Policy Gradient Estimation.},
  author={Zhao, Tingting and Hachiya, Hirotaka and Niu, Gang and Sugiyama, Masashi},
  booktitle={NIPS},
  pages={262--270},
  year={2011},
  organization={Citeseer}
}


@inproceedings{ye2020mastering,
  title={Mastering complex control in moba games with deep reinforcement learning},
  author={Ye, Deheng and Liu, Zhao and Sun, Mingfei and Shi, Bei and Zhao, Peilin and Wu, Hao and Yu, Hongsheng and Yang, Shaojie and Wu, Xipeng and Guo, Qingwei and others},
  booktitle={Proceedings of the Conference of Association for the Advancement of Artificial Intelligence},
  pages={6672--6679},
  year={2020}
}

@article{HernandezLeal2017ASO,
  title={A Survey of Learning in Multiagent Environments: Dealing with Non-Stationarity},
  author={Pablo Hernandez-Leal and Michael Kaisers and Tim Baarslag and Enrique Munoz de Cote},
  journal={ArXiv},
  year={2017},
  volume={abs/1707.09183}
}


@inproceedings{Schulman2015TrustRP,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International Conference on Machine Learning},
  pages={1889--1897},
  year={2015}
}


@inproceedings{Kakade2002ApproximatelyOA,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={International Conference on Machine Learning},
  pages={267--274},
  year={2002}
}

@article{Wiering2004,
  title={Simulation and optimization of traffic in a city},
  author={Macro A. Wiering and Jilles Vreeken and Jelle van Veenen and Arne Koopman},
  journal={IEEE Intelligent Vehicles Symposium, 2004},
  year={2004},
  pages={453-458}
}

@article{cao2012overview,
  title={An overview of recent progress in the study of distributed multi-agent coordination},
  author={Yongcan Cao and Wenwu Yu and Wei Ren and Guanrong Chen},
  journal={IEEE Transactions on Industrial informatics},
  volume={9},
  number={1},
  pages={427--438},
  year={2012},
  publisher={IEEE}
}

@inproceedings{Zhang2011CoordinatedMR,
  title={Coordinated Multi-Agent Reinforcement Learning in Networked Distributed POMDPs},
  author={Chongjie Zhang and Victor Lesser},
  booktitle={AAAI},
  year={2011}
}

@inproceedings{Rashid2018QMIXMV,
  title={Qmix: Monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and Schroeder, Christian and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  booktitle={International Conference on Machine Learning},
  pages={4295--4304},
  year={2018}
}



@inproceedings{Sunehag2018ValueDecompositionNF,
  title={Value-Decomposition Networks For Cooperative Multi-Agent Learning Based On Team Reward},
  author={Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others},
  booktitle={International Conference on Autonomous Agents and MultiAgent Systems},
  pages={2085-2087},
  year={2018}
}


@inproceedings{Son2019QTRANLT,
  title={Qtran: Learning to factorize with transformation for cooperative multi-agent reinforcement learning},
  author={Son, Kyunghwan and Kim, Daewoo and Kang, Wan Ju and Hostallero, David Earl and Yi, Yung},
  booktitle={International Conference on Machine Learning},
  pages={5887--5896},
  year={2019}
}


@article{Mahajan2019MAVENMV,
  title={MAVEN: Multi-Agent Variational Exploration},
  author={Mahajan, Anuj and Rashid, Tabish and Samvelyan, Mikayel and Whiteson, Shimon},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={7613--7624},
  year={2019}
}

@article{Foerster2016LearningTC,
  title={Learning to Communicate with Deep Multi-Agent Reinforcement Learning},
  author={Foerster, Jakob and Assael, Ioannis Alexandros and de Freitas, Nando and Whiteson, Shimon},
  journal={Advances in Neural Information Processing Systems},
  volume={29},
  pages={2137--2145},
  year={2016}
}


@inproceedings{song2019convergence,
  title={Convergence of Multi-Agent Learning with a Finite Step Size in General-Sum Games},
  author={Song, Xinliang and Wang, Tonghan and Zhang, Chongjie},
  booktitle={International Conference on Autonomous Agents and MultiAgent Systems},
  pages={935--943},
  year={2019}
}

@article{papoudakis2019dealing,
  title={Dealing with non-stationarity in multi-agent deep reinforcement learning},
  author={Georgios Papoudakis and Filippos Christianos and Arrasy Rahman and Stefano V. Albrecht},
  journal={arXiv preprint arXiv:1906.04737},
  year={2019}
}

@inproceedings{spiros2002reinforcement,
  title={Reinforcement learning of coordination in cooperative MAS},
  author={Spiros, K and Daniel, K},
  booktitle={The 18th National Conference on Artificial Intelligence},
  pages={326--331},
  year={2002}
}


@inproceedings{Samvelyan2019TheSM,
  title={The StarCraft Multi-Agent Challenge},
  author={Samvelyan, Mikayel and Rashid, Tabish and Schroeder de Witt, Christian and Farquhar, Gregory and Nardelli, Nantas and Rudner, Tim GJ and Hung, Chia-Man and Torr, Philip HS and Foerster, Jakob and Whiteson, Shimon},
  booktitle={International Conference on Autonomous Agents and MultiAgent Systems},
  pages={2186--2188},
  year={2019}
}

@article{Yu2021TheSE,
  title={The Surprising Effectiveness of MAPPO in Cooperative, Multi-Agent Games},
  author={Chao Yu and Akash Velu and Eugene Vinitsky and Yu Wang and A. Bayen and Yi Wu},
  journal={ArXiv},
  year={2021},
  volume={abs/2103.01955}
}

@article{Schulman2017ProximalPO,
  title={Proximal Policy Optimization Algorithms},
  author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
  journal={ArXiv},
  year={2017},
  volume={abs/1707.06347}
}

@article{claus1998dynamics,
  title={The dynamics of reinforcement learning in cooperative multiagent systems},
  author={Claus, Caroline and Boutilier, Craig},
  journal={Proceedings of the fifteenth national/tenth conference on Artificial intelligence/Innovative applications of artificial intelligence},
  volume={1998},
  number={746-752},
  pages={2},
  year={1998}
}

@inproceedings{wang2020off,
  title={DOP: Off-Policy Multi-Agent Decomposed Policy Gradients},
  author={Wang, Yihan and Han, Beining and Wang, Tonghan and Dong, Heng and Zhang, Chongjie},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@book{levin2017markov,
  title={Markov chains and mixing times},
  author={Levin, David A and Peres, Yuval},
  volume={107},
  year={2017},
  publisher={American Mathematical Soc.}
}

@article{Mnih2013PlayingAW,
  title={Playing Atari with Deep Reinforcement Learning},
  author={V. Mnih and K. Kavukcuoglu and D. Silver and A. Graves and Ioannis Antonoglou and Daan Wierstra and Martin A. Riedmiller},
  journal={ArXiv},
  year={2013},
  volume={abs/1312.5602}
}

@article{Silver2016MasteringTG,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={D. Silver and Aja Huang and Chris J. Maddison and A. Guez and L. Sifre and G. V. D. Driessche and Julian Schrittwieser and Ioannis Antonoglou and Vedavyas Panneershelvam and Marc Lanctot and S. Dieleman and Dominik Grewe and John Nham and Nal Kalchbrenner and Ilya Sutskever and T. Lillicrap and M. Leach and K. Kavukcuoglu and T. Graepel and D. Hassabis},
  journal={Nature},
  year={2016},
  pages={484-489}
}

@article{Kober2013ReinforcementLI,
  title={Reinforcement learning in robotics: A survey},
  author={J. Kober and J. Bagnell and Jan Peters},
  journal={The International Journal of Robotics Research},
  year={2013},
  volume={32},
  pages={1238 - 1274}
}

@article{Sallab2017DeepRL,
  title={Deep reinforcement learning framework for autonomous driving},
  author={A. E. Sallab and M. Abdou and E. Perot and S. Yogamani},
  journal={Electronic Imaging},
  volume={2017},
  number={19},
  pages={70--76},
  year={2017},
  publisher={Society for Imaging Science and Technology}
}

@article{Kitano2000RoboCupRA,
  title={RoboCup Rescue: a grand challenge for multi-agent systems},
  author={H. Kitano},
  journal={Proceedings Fourth International Conference on MultiAgent Systems},
  year={2000},
  pages={5-12}
}

@article{Tuyls2007WhatEG,
  title={What evolutionary game theory tells us about multiagent learning},
  author={K. Tuyls and S. Parsons},
  journal={Artif. Intell.},
  year={2007},
  volume={171},
  pages={406-416}
}

@article{Shoham2007IfML,
  title={If multi-agent learning is the answer, what is the question?},
  author={Y. Shoham and R. Powers and T. Grenager},
  journal={Artif. Intell.},
  year={2007},
  volume={171},
  pages={365-377}
}

@article{Kraemer2016MultiagentRL,
  title={Multi-agent reinforcement learning as a rehearsal for decentralized planning},
  author={L. Kraemer and B. Banerjee},
  journal={Neurocomputing},
  year={2016},
  volume={190},
  pages={82-94}
}

@article{Watkins2004Qlearning,
  title={Q-learning},
  author={C. Watkins and P. Dayan},
  journal={Machine Learning},
  year={2004},
  volume={8},
  pages={279-292}
}

@article{Schulman2016HighDimensionalCC,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}


@article{Lowe2017MultiAgentAF,
  title={Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments},
  author={Lowe, Ryan and Wu, Yi and Tamar, Aviv and Harb, Jean and Pieter Abbeel, OpenAI and Mordatch, Igor},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  pages={6379--6390},
  year={2017}
}


@article{Pollard2000Asymptopia,
  title={Asymptopia: an exposition of statistical asymptotic theory},
  author={Pollard, David},
  url={http://www. stat. yale. edu/pollard/Books/Asymptopia},
  year={2000}
}


@article{wen2021multagent,
  title={Multi-Agent Trust Region Learning},
  author={Wen, Ying and Chen, Hui and Yang, Yaodong and Tian, Zheng and Li, Minne and Chen, Xu and Wang, Jun},
  url={https://openreview.net/forum?id=eHG7asK_v-k},
  year={2020}
}

@inproceedings{foerster2018counterfactual,
  title={Counterfactual multi-agent policy gradients},
  author={Foerster, Jakob and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
  booktitle={Proceedings of the Conference of Association for the Advancement of Artificial Intelligence},
  volume={32},
  number={2},
  pages={2974–2982},
  year={2018}
}


@article{wang2020towards,
  title={Towards understanding linear value decomposition in cooperative multi-agent q-learning},
  author={Wang, Jianhao and Ren, Zhizhou and Han, Beining and Ye, Jianing and Zhang, Chongjie},
  journal={arXiv preprint arXiv:2006.00587},
  year={2020}
}

@inproceedings{gupta2017cooperative,
  title={Cooperative multi-agent control using deep reinforcement learning},
  author={Gupta, Jayesh K and Egorov, Maxim and Kochenderfer, Mykel},
  booktitle={International Conference on Autonomous Agents and Multiagent Systems},
  pages={66--83},
  year={2017}
}


@inproceedings{sutton1999policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1057--1063},
  year={2000}
}

@incollection{kapetanakis2002reinforcement,
  title={Reinforcement learning approaches to coordination in cooperative multi-agent systems},
  author={Kapetanakis, Spiros and Kudenko, Daniel and Strens, Malcolm JA},
  booktitle={Adaptive agents and multi-agent systems},
  pages={18--32},
  year={2002}
}

@article{Sutton2005ReinforcementLA,
  title={Reinforcement Learning: An Introduction},
  author={R. Sutton and A. Barto},
  journal={IEEE Transactions on Neural Networks},
  year={2005},
  volume={16},
  pages={285-286}
}

@inproceedings{Gu2016ContinuousDQ,
  title={Continuous deep q-learning with model-based acceleration},
  author={S. Gu and T. Lillicrap and I. Sutskever and S. Levine},
  booktitle={International Conference on Machine Learning},
  pages={2829--2838},
  year={2016},
  organization={PMLR}
}

@article{Jang2017CategoricalRW,
  title={Categorical Reparameterization with Gumbel-Softmax},
  author={E. Jang and S. Gu and B. Poole},
  journal={ArXiv},
  year={2017},
  volume={abs/1611.01144}
}

@article{Bellman1966DynamicP,
  title={Dynamic programming.},
  author={R. Bellman},
  journal={Science},
  year={1966},
  volume={153 3731},
  pages={
          34-7
        }
}


@inproceedings{Silver2014DeterministicPG,
  title={Deterministic policy gradient algorithms},
  author={D. Silver and G. Lever and N. Heess and T. Degris and D. Wierstra and M. Riedmiller},
  booktitle={International conference on machine learning},
  pages={387--395},
  year={2014},
  organization={PMLR}
}


@book{Oliehoek2016ACI,
  title={A concise introduction to decentralized POMDPs},
  author={Oliehoek, Frans A and Amato, Christopher},
  year={2016},
  publisher={Springer}
}

@inproceedings{Conn2000TrustRM,
  title={Trust Region Methods},
  author={A. Conn and N. Gould and P. Toint},
  booktitle={MOS-SIAM Series on Optimization},
  year={2000}
}


@article{Mcarthur2007MultiAgentSF,
  title={Multi-Agent Systems for Power Engineering Applications—Part I: Concepts, Approaches, and Technical Challenges},
  author={S. Mcarthur and E. Davidson and V. M. Catterson and A. Dimeas and N. Hatziargyriou and F. Ponci and T. Funabashi},
  journal={IEEE Transactions on Power Systems},
  year={2007},
  volume={22},
  pages={1743-1752}
}

@inproceedings{Luck2001MultiAgentSA,
  title={Multi-Agent Systems and Applications},
  author={M. Luck and V. Mar{\'i}k and O. Step{\'a}nkov{\'a} and R. Trappl},
  booktitle={Lecture Notes in Computer Science},
  year={2001}
}

@article{Lillicrap2016ContinuousCW,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@inproceedings{Iqbal2019ActorAttentionCriticFM,
  title={Actor-attention-critic for multi-agent reinforcement learning},
  author={Shariq Iqbal and Fei Sha},
  booktitle={International Conference on Machine Learning},
  pages={2961--2970},
  year={2019},
  organization={PMLR}
}

@article{Vaswani2017AttentionIA,
  title={Attention is All you Need},
  author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Łukasz Kaiser and Illia Polosukhin},
  journal={ArXiv},
  year={2017},
  volume={abs/1706.03762}
}

@article{Wang2020TowardsUL,
  title={Towards Understanding Linear Value Decomposition in Cooperative Multi-Agent Q-Learning},
  author={Jianhao Wang and Zhizhou Ren and Beining Han and Chongjie Zhang},
  journal={ArXiv},
  year={2020},
  volume={abs/2006.00587}
}


@inproceedings{Gupta2017CooperativeMC,
  title={Cooperative multi-agent control using deep reinforcement learning},
  author={Gupta, Jayesh K and Egorov, Maxim and Kochenderfer, Mykel},
  booktitle={International Conference on Autonomous Agents and Multiagent Systems},
  pages={66--83},
  year={2017}
}

@article{Li2021DealingWN,
  title={Dealing with Non-Stationarity in Multi-Agent Reinforcement Learning via Trust Region Decomposition},
  author={Wenhao Li and Xiangfeng Wang and Bo Jin and Junjie Sheng and Hongyuan Zha},
  journal={ArXiv},
  year={2021},
  volume={abs/2102.10616}
}

@article{Li2020MultiAgentTR,
  title={Multi-Agent Trust Region Policy Optimization},
  author={Hepeng Li and Haibo He},
  journal={ArXiv},
  year={2020},
  volume={abs/2010.07916}
}



@article{Scarselli2009TheGN,
  title={The Graph Neural Network Model},
  author={Franco Scarselli and Marco Gori and Ah C. Tsoi and Markus Hagenbuchner and Gabriele Monfardini},
  journal={IEEE Transactions on Neural Networks},
  year={2009},
  volume={20},
  pages={61-80}
}

@inproceedings{Sigman20101LD,
  title={Limiting distribution for a Markov chain},
  author={Karl Sigman},
  year={2010}
}

