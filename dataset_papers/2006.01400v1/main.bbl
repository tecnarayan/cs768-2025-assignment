\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Badanidiyuru et~al.(2014)Badanidiyuru, Mirzasoleiman, Karbasi, and
  Krause]{BMKK14}
Badanidiyuru, A., Mirzasoleiman, B., Karbasi, A., and Krause, A.
\newblock Streaming submodular maximization: massive data summarization on the
  fly.
\newblock In \emph{{P}roceedings of the 20th {ACM} {SIGKDD} International
  Conference on Knowledge Discovery and Data Mining ({KDD})}, pp.\  671--680,
  2014.

\bibitem[Bahmani et~al.(2013)Bahmani, Raj, and Boufounos]{BRB13}
Bahmani, S., Raj, B., and Boufounos, P.~T.
\newblock Greedy sparsity-constrained optimization.
\newblock \emph{Journal of Machine Learning Research}, 14\penalty0
  (1):\penalty0 807--841, 2013.

\bibitem[Baldassarre et~al.(2016)Baldassarre, Li, Scarlett, Gozcu, Bogunovic,
  and Cevher]{BLSGB16}
Baldassarre, L., Li, Y., Scarlett, J., Gozcu, B., Bogunovic, I., and Cevher, V.
\newblock Learning-based compressive subsampling.
\newblock \emph{Journal of Selelected Topics in Signal Processing}, 10\penalty0
  (4):\penalty0 809--822, 2016.

\bibitem[Balkanski et~al.(2016)Balkanski, Mirzasoleiman, Krause, and
  Singer]{Balkanski2016}
Balkanski, E., Mirzasoleiman, B., Krause, A., and Singer, Y.
\newblock Learning sparse combinatorial representations via two-stage
  submodular maximization.
\newblock In \emph{Proceedings of The 33rd International Conference on Machine
  Learning (ICML)}, pp.\  2207--2216, 2016.

\bibitem[Baraniuk et~al.(2010)Baraniuk, Cevher, Duarte, and Hegde]{BCDH10}
Baraniuk, R.~G., Cevher, V., Duarte, M.~F., and Hegde, C.
\newblock Model-based compressive sensing.
\newblock \emph{{IEEE} Transactions on Information Theory}, 56\penalty0
  (4):\penalty0 1982--2001, 2010.

\bibitem[Besag(1975)]{Besag75}
Besag, J.
\newblock Statistical analysis of non-lattice data.
\newblock \emph{Journal of the Royal Statistical Society: Series D},
  24\penalty0 (3):\penalty0 179--195, 1975.

\bibitem[Bian et~al.(2017)Bian, Buhmann, Krause, and Tschiatschek]{Bian17}
Bian, A.~A., Buhmann, J.~M., Krause, A., and Tschiatschek, S.
\newblock Guarantees for greedy maximization of non-submodular functions with
  applications.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning ({ICML})}, pp.\  498--507, 2017.

\bibitem[Bresler(2015)]{Bresler15}
Bresler, G.
\newblock Efficiently learning ising models on arbitrary graphs.
\newblock In \emph{Proceedings of the Forty-Seventh Annual {ACM} on Symposium
  on Theory of Computing ({STOC})}, pp.\  771--782, 2015.

\bibitem[Cevher \& Krause(2011)Cevher and Krause]{CK11}
Cevher, V. and Krause, A.
\newblock Greedy dictionary selection for sparse representation.
\newblock \emph{IEEE Journal of Selected Topics in Signal Processing},
  5\penalty0 (5):\penalty0 979--988, 2011.

\bibitem[Chen et~al.(2018)Chen, Feldman, and Karbasi]{CFK18}
Chen, L., Feldman, M., and Karbasi, A.
\newblock Weakly submodular maximization beyond cardinality constraints: Does
  randomization help greedy?
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning ({ICML})}, pp.\  803--812, 2018.

\bibitem[Das \& Kempe(2011)Das and Kempe]{Das2011}
Das, A. and Kempe, D.
\newblock Submodular meets spectral: Greedy algorithms for subset selection,
  sparse approximation and dictionary selection.
\newblock In \emph{Proceedings of the 28th International Conference on Machine
  Learning (ICML)}, pp.\  1057--1064, 2011.

\bibitem[Elenberg et~al.(2017)Elenberg, Dimakis, Feldman, and
  Karbasi]{Elenberg2017}
Elenberg, E., Dimakis, A.~G., Feldman, M., and Karbasi, A.
\newblock Streaming weak submodularity: Interpreting neural networks on the
  fly.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)
  30}, pp.\  4047--4057. 2017.

\bibitem[Elenberg et~al.(2018)Elenberg, Khanna, Dimakis, and
  Negahban]{Elenberg18}
Elenberg, E.~R., Khanna, R., Dimakis, A.~G., and Negahban, S.
\newblock Restricted strong convexity implies weak submodularity.
\newblock \emph{Annals of Statistics}, 46\penalty0 (6B):\penalty0 3539--3568,
  2018.

\bibitem[Feige et~al.(2011)Feige, Mirrokni, and Vondr{\'{a}}k]{FMV11}
Feige, U., Mirrokni, V.~S., and Vondr{\'{a}}k, J.
\newblock Maximizing non-monotone submodular functions.
\newblock \emph{{SIAM} Journal on Computing}, 40\penalty0 (4):\penalty0
  1133--1153, 2011.

\bibitem[Feldman(2013)]{Fel13}
Feldman, M.
\newblock \emph{Maximization Problems with Submodular Objective Functions}.
\newblock PhD thesis, Computer Science Department, Technion - Israel Institute
  of Technology, 2013.

\bibitem[Feldman et~al.(2011)Feldman, Naor, Schwartz, and Ward]{FNSW11}
Feldman, M., Naor, J., Schwartz, R., and Ward, J.
\newblock Improved approximations for k-exchange systems (extended abstract).
\newblock In \emph{Proceedings of the 19th Annual European Symposium on
  Algorithms ({ESA})}, pp.\  784--798, 2011.

\bibitem[Filmus \& Ward(2014)Filmus and Ward]{FW14}
Filmus, Y. and Ward, J.
\newblock Monotone submodular maximization over a matroid via non-oblivious
  local search.
\newblock \emph{{SIAM} Journal on Computing}, 43\penalty0 (2):\penalty0
  514--542, 2014.

\bibitem[Fisher et~al.(1978)Fisher, Nemhauser, and Wolsey]{FNW78}
Fisher, M.~L., Nemhauser, G.~L., and Wolsey, L.~A.
\newblock \emph{An analysis of approximations for maximizing submodular set
  functions---II}, pp.\  73--87.
\newblock Springer Berlin Heidelberg, Berlin, Heidelberg, 1978.

\bibitem[Frank \& Wolfe(1956)Frank and Wolfe]{FW56}
Frank, M. and Wolfe, P.
\newblock An algorithm for quadratic programming.
\newblock \emph{Naval research logistics quarterly}, 3\penalty0 (1-2):\penalty0
  95--110, 1956.

\bibitem[Fujii \& Soma(2018)Fujii and Soma]{FS18}
Fujii, K. and Soma, T.
\newblock Fast greedy algorithms for dictionary selection with generalized
  sparsity constraints.
\newblock In \emph{Advances in Neural Information Processing Systems
  ({NeurIPS}) 31}, pp.\  4749--4758, 2018.

\bibitem[Fujishige(2005)]{Fujishige2005}
Fujishige, S.
\newblock \emph{Submodular Functions and Optimization}.
\newblock Elsevier, 2nd edition, 2005.

\bibitem[Golovin \& Krause(2011)Golovin and Krause]{GK11}
Golovin, D. and Krause, A.
\newblock Adaptive submodularity: Theory and applications in active learning
  and stochastic optimization.
\newblock \emph{Journal of Artificial Intelligence Research}, 42:\penalty0
  427--486, 2011.

\bibitem[Hoi et~al.(2006)Hoi, Jin, Zhu, and Lyu]{HJZL06}
Hoi, S. C.~H., Jin, R., Zhu, J., and Lyu, M.~R.
\newblock Batch mode active learning and its application to medical image
  classification.
\newblock In \emph{Proceedings of the 23rd International Conference of Machine
  Learning {(ICML})}, pp.\  417--424, 2006.

\bibitem[Huang et~al.(2009)Huang, Zhang, and Metaxas]{Huang2009}
Huang, J., Zhang, T., and Metaxas, D.
\newblock Learning with structured sparsity.
\newblock \emph{Journal of Machine Learning Research}, 12:\penalty0 3371--3412,
  2009.

\bibitem[Iyer et~al.(2013)Iyer, Jegelka, and Bilmes]{IJB13}
Iyer, R.~K., Jegelka, S., and Bilmes, J.~A.
\newblock Fast semidifferential-based submodular function optimization.
\newblock In \emph{Proceedings of the 30th International Conference on Machine
  Learning ({ICML})}, pp.\  855--863, 2013.

\bibitem[Jaggi(2013)]{Jaggi13}
Jaggi, M.
\newblock Revisiting frank-wolfe: Projection-free sparse convex optimization.
\newblock In \emph{Proceedings of the 30th International Conference on Machine
  Learning ({ICML})}, pp.\  427--435, 2013.

\bibitem[Jain et~al.(2014)Jain, Tewari, and Kar]{JTK14}
Jain, P., Tewari, A., and Kar, P.
\newblock On iterative hard thresholding methods for high-dimensional
  m-estimation.
\newblock In \emph{Advances in Neural Information Processing Systems ({NIPS})
  27}, pp.\  685--693, 2014.

\bibitem[Jain et~al.(2016)Jain, Rao, and Dhillon]{JRD16}
Jain, P., Rao, N., and Dhillon, I.~S.
\newblock Structured sparse regression via greedy hard thresholding.
\newblock In Lee, D.~D., Sugiyama, M., Luxburg, U.~V., Guyon, I., and Garnett,
  R. (eds.), \emph{Advances in Neural Information Processing Systems 29}, pp.\
  1516--1524, 2016.

\bibitem[Jalali et~al.(2011)Jalali, Johnson, and Ravikumar]{JJR11}
Jalali, A., Johnson, C.~C., and Ravikumar, P.
\newblock On learning discrete graphical models using greedy methods.
\newblock In \emph{Advances in Neural Information Processing Systems ({NIPS})
  24}, pp.\  1935--1943, 2011.

\bibitem[Klivans \& Meka(2017)Klivans and Meka]{KM17}
Klivans, A.~R. and Meka, R.
\newblock Learning graphical models using multiplicative weights.
\newblock In \emph{Proceedings of the 58th {IEEE} Annual Symposium on
  Foundations of Computer Science ({FOCS})}, pp.\  343--354, 2017.

\bibitem[Kyrillidis \& Cevher(2012)Kyrillidis and Cevher]{KC12}
Kyrillidis, A. and Cevher, V.
\newblock Combinatorial selection and least absolute shrinkage via the clash
  algorithm.
\newblock In \emph{Proceedings of the 2012 {IEEE} International Symposium on
  Information Theory ({ISIT})}, pp.\  2216--2220, 2012.

\bibitem[Lacoste{-}Julien \& Jaggi(2015)Lacoste{-}Julien and Jaggi]{LJ15}
Lacoste{-}Julien, S. and Jaggi, M.
\newblock On the global linear convergence of frank-wolfe optimization
  variants.
\newblock In \emph{Advances in Neural Information Processing Systems ({NIPS})
  28}, pp.\  496--504, 2015.

\bibitem[Lee et~al.(2009)Lee, Mirrokni, Nagarajan, and Sviridenko]{LMNS09}
Lee, J., Mirrokni, V.~S., Nagarajan, V., and Sviridenko, M.
\newblock Non-monotone submodular maximization under matroid and knapsack
  constraints.
\newblock In \emph{Proceedings of the 41st Annual {ACM} Symposium on Theory of
  Computing ({STOC})}, pp.\  323--332, 2009.

\bibitem[Lee et~al.(2010)Lee, Sviridenko, and Vondr{\'{a}}k]{LSV10}
Lee, J., Sviridenko, M., and Vondr{\'{a}}k, J.
\newblock Submodular maximization over multiple matroids via generalized
  exchange properties.
\newblock \emph{Mathematics of Operations Research}, 35\penalty0 (4):\penalty0
  795--806, 2010.

\bibitem[Lin \& Bilmes(2011)Lin and Bilmes]{LB11}
Lin, H. and Bilmes, J.~A.
\newblock A class of submodular functions for document summarization.
\newblock In \emph{Proceedings of the 49th Annual Meeting of the Association
  for Computational Linguistics: Human Language Technologies ({ACL})}, pp.\
  510--520, 2011.

\bibitem[Needell \& Tropp(2010)Needell and Tropp]{NT10}
Needell, D. and Tropp, J.~A.
\newblock Cosamp: iterative signal recovery from incomplete and inaccurate
  samples.
\newblock \emph{Communications of the {ACM}}, 53\penalty0 (12):\penalty0
  93--100, 2010.

\bibitem[Negahban et~al.(2012)Negahban, Ravikumar, Wainwright, and Yu]{NRWY12}
Negahban, S.~N., Ravikumar, P., Wainwright, M.~J., and Yu, B.
\newblock A unified framework for high-dimensional analysis of {$M$}-estimators
  with decomposable regularizers.
\newblock \emph{Statistical Science}, 27\penalty0 (4):\penalty0 538--557, 2012.

\bibitem[Nemhauser et~al.(1978)Nemhauser, Wolsey, and Fisher]{NWF78}
Nemhauser, G.~L., Wolsey, L.~A., and Fisher, M.~L.
\newblock An analysis of approximations for maximizing submodular set functions
  - {I}.
\newblock \emph{Mathematical Programming}, 14\penalty0 (1):\penalty0 265--294,
  1978.

\bibitem[Sakaue(2019)]{Sakaue19}
Sakaue, S.
\newblock Greedy and {IHT} algorithms for non-convex optimization with monotone
  costs of non-zeros.
\newblock In \emph{Proceedings of The 22nd International Conference on
  Artificial Intelligence and Statistics ({AISTATS})}, pp.\  206--215, 2019.

\bibitem[Schrijver(2003)]{Schrijver}
Schrijver, A.
\newblock \emph{Combinatorial Optimization: Polyhedra and Efficiency}.
\newblock Springer, Berlin, 2003.

\bibitem[Wu et~al.(2019)Wu, Sanghavi, and Dimakis]{WSD19}
Wu, S., Sanghavi, S., and Dimakis, A.~G.
\newblock Sparse logistic regression learns all discrete pairwise graphical
  models.
\newblock In \emph{Advances in Neural Information Processing Systems
  ({NeurIPS}) 32}, pp.\  8069--8079, 2019.

\end{thebibliography}
