\begin{thebibliography}{88}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Berrevoets et~al.(2023)Berrevoets, Kacprzyk, Qian, and van~der
  Schaar]{berrevoets2023causal}
Jeroen Berrevoets, Krzysztof Kacprzyk, Zhaozhi Qian, and Mihaela van~der
  Schaar.
\newblock Causal deep learning.
\newblock \emph{arXiv preprint arXiv:2303.02186}, 2023.

\bibitem[Bhardwaj et~al.(2017)Bhardwaj, Nambiar, and Dutta]{bhardwaj2017study}
Rohan Bhardwaj, Ankita~R Nambiar, and Debojyoti Dutta.
\newblock A study of machine learning in healthcare.
\newblock In \emph{2017 IEEE 41st Annual Computer Software and Applications
  Conference (COMPSAC)}, volume~2, pages 236--241. IEEE, 2017.

\bibitem[Berrevoets et~al.(2020)Berrevoets, Jordon, Bica, van~der Schaar,
  et~al.]{berrevoets2020organite}
Jeroen Berrevoets, James Jordon, Ioana Bica, Mihaela van~der Schaar, et~al.
\newblock Organite: Optimal transplant donor organ offering using an individual
  treatment effect.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 20037--20050, 2020.

\bibitem[van~der Schaar et~al.(2021)van~der Schaar, Alaa, Floto, Gimson,
  Scholtes, Wood, McKinney, Jarrett, Lio, and Ercole]{van2021artificial}
Mihaela van~der Schaar, Ahmed~M Alaa, Andres Floto, Alexander Gimson, Stefan
  Scholtes, Angela Wood, Eoin McKinney, Daniel Jarrett, Pietro Lio, and Ari
  Ercole.
\newblock How artificial intelligence and machine learning can help healthcare
  systems respond to covid-19.
\newblock \emph{Machine Learning}, 110\penalty0 (1):\penalty0 1--14, 2021.

\bibitem[Rajkomar et~al.(2019)Rajkomar, Dean, and Kohane]{rajkomar2019machine}
Alvin Rajkomar, Jeffrey Dean, and Isaac Kohane.
\newblock Machine learning in medicine.
\newblock \emph{New England Journal of Medicine}, 380\penalty0 (14):\penalty0
  1347--1358, 2019.

\bibitem[Berrevoets et~al.(2021)Berrevoets, Alaa, Qian, Jordon, Gimson, and Van
  Der~Schaar]{berrevoets2021learning}
Jeroen Berrevoets, Ahmed Alaa, Zhaozhi Qian, James Jordon, Alexander~ES Gimson,
  and Mihaela Van Der~Schaar.
\newblock Learning queueing policies for organ transplantation allocation using
  interpretable counterfactual survival analysis.
\newblock In \emph{International Conference on Machine Learning}, pages
  792--802. PMLR, 2021.

\bibitem[Athey et~al.(2018)]{athey2018impact}
Susan Athey et~al.
\newblock The impact of machine learning on economics.
\newblock \emph{The economics of artificial intelligence: An agenda}, pages
  507--547, 2018.

\bibitem[Athey and Imbens(2019)]{athey2019machine}
Susan Athey and Guido~W Imbens.
\newblock Machine learning methods that economists should know about.
\newblock \emph{Annual Review of Economics}, 11:\penalty0 685--725, 2019.

\bibitem[Mullainathan and Spiess(2017)]{mullainathan2017machine}
Sendhil Mullainathan and Jann Spiess.
\newblock Machine learning: an applied econometric approach.
\newblock \emph{Journal of Economic Perspectives}, 31\penalty0 (2):\penalty0
  87--106, 2017.

\bibitem[Carleo et~al.(2019)Carleo, Cirac, Cranmer, Daudet, Schuld, Tishby,
  Vogt-Maranto, and Zdeborov{\'a}]{carleo2019machine}
Giuseppe Carleo, Ignacio Cirac, Kyle Cranmer, Laurent Daudet, Maria Schuld,
  Naftali Tishby, Leslie Vogt-Maranto, and Lenka Zdeborov{\'a}.
\newblock Machine learning and the physical sciences.
\newblock \emph{Reviews of Modern Physics}, 91\penalty0 (4):\penalty0 045002,
  2019.

\bibitem[Radovic et~al.(2018)Radovic, Williams, Rousseau, Kagan, Bonacorsi,
  Himmel, Aurisano, Terao, and Wongjirad]{radovic2018machine}
Alexander Radovic, Mike Williams, David Rousseau, Michael Kagan, Daniele
  Bonacorsi, Alexander Himmel, Adam Aurisano, Kazuhiro Terao, and Taritree
  Wongjirad.
\newblock Machine learning at the energy and intensity frontiers of particle
  physics.
\newblock \emph{Nature}, 560\penalty0 (7716):\penalty0 41--48, 2018.

\bibitem[Sarma et~al.(2019)Sarma, Deng, and Duan]{sarma2019machine}
Sankar~Das Sarma, Dong-Ling Deng, and Lu-Ming Duan.
\newblock Machine learning meets quantum physics.
\newblock \emph{arXiv preprint arXiv:1903.03516}, 2019.

\bibitem[Karniadakis et~al.(2021)Karniadakis, Kevrekidis, Lu, Perdikaris, Wang,
  and Yang]{karniadakis2021physics}
George~Em Karniadakis, Ioannis~G Kevrekidis, Lu~Lu, Paris Perdikaris, Sifan
  Wang, and Liu Yang.
\newblock Physics-informed machine learning.
\newblock \emph{Nature Reviews Physics}, 3\penalty0 (6):\penalty0 422--440,
  2021.

\bibitem[Breen et~al.(2020)Breen, Foley, Boekholt, and Zwart]{breen2020newton}
Philip~G Breen, Christopher~N Foley, Tjarda Boekholt, and Simon~Portegies
  Zwart.
\newblock Newton versus the machine: solving the chaotic three-body problem
  using deep neural networks.
\newblock \emph{Monthly Notices of the Royal Astronomical Society},
  494\penalty0 (2):\penalty0 2465--2470, 2020.

\bibitem[Udrescu and Tegmark(2020)]{udrescu2020ai}
Silviu-Marian Udrescu and Max Tegmark.
\newblock Ai feynman: A physics-inspired method for symbolic regression.
\newblock \emph{Science Advances}, 6\penalty0 (16):\penalty0 eaay2631, 2020.

\bibitem[Peters(2007)]{peters2007machine}
Jan~Reinhard Peters.
\newblock \emph{Machine learning of motor skills for robotics}.
\newblock University of Southern California, 2007.

\bibitem[Peng et~al.(2018)Peng, Andrychowicz, Zaremba, and Abbeel]{peng2018sim}
Xue~Bin Peng, Marcin Andrychowicz, Wojciech Zaremba, and Pieter Abbeel.
\newblock Sim-to-real transfer of robotic control with dynamics randomization.
\newblock In \emph{2018 IEEE international conference on robotics and
  automation (ICRA)}, pages 3803--3810. IEEE, 2018.

\bibitem[Kehoe et~al.(2015)Kehoe, Patil, Abbeel, and Goldberg]{kehoe2015survey}
Ben Kehoe, Sachin Patil, Pieter Abbeel, and Ken Goldberg.
\newblock A survey of research on cloud robotics and automation.
\newblock \emph{IEEE Transactions on automation science and engineering},
  12\penalty0 (2):\penalty0 398--409, 2015.

\bibitem[Abbeel et~al.(2010)Abbeel, Coates, and Ng]{abbeel2010autonomous}
Pieter Abbeel, Adam Coates, and Andrew~Y Ng.
\newblock Autonomous helicopter aerobatics through apprenticeship learning.
\newblock \emph{The International Journal of Robotics Research}, 29\penalty0
  (13):\penalty0 1608--1639, 2010.

\bibitem[Kleiman et~al.(2019)Kleiman, Pabst, and Nagle]{kleiman2019boosting}
Yanir Kleiman, Simon Pabst, and Patrick Nagle.
\newblock Boosting vfx production with deep learning.
\newblock In \emph{ACM SIGGRAPH 2019 Talks}, pages 1--2. 2019.

\bibitem[Ring et~al.(2019)Ring, Barbier, Gales, Kent, and
  Lutz]{ring2019jumping}
Dan Ring, Johanna Barbier, Guillaume Gales, Ben Kent, and Sebastian Lutz.
\newblock Jumping in at the deep end: how to experiment with machine learning
  in post-production software.
\newblock In \emph{Proceedings of the 2019 Digital Production Symposium}, pages
  1--5, 2019.

\bibitem[Wang(2022)]{wang2022film}
Yi~Wang.
\newblock Film and television special effects production based on modern
  technology: from the perspective of statistical machine learning.
\newblock In \emph{2022 4th International Conference on Smart Systems and
  Inventive Technology (ICSSIT)}, pages 833--836. IEEE, 2022.

\bibitem[Davies et~al.(2021)Davies, Veli{\v{c}}kovi{\'c}, Buesing, Blackwell,
  Zheng, Toma{\v{s}}ev, Tanburn, Battaglia, Blundell, Juh{\'a}sz,
  et~al.]{davies2021advancing}
Alex Davies, Petar Veli{\v{c}}kovi{\'c}, Lars Buesing, Sam Blackwell, Daniel
  Zheng, Nenad Toma{\v{s}}ev, Richard Tanburn, Peter Battaglia, Charles
  Blundell, Andr{\'a}s Juh{\'a}sz, et~al.
\newblock Advancing mathematics by guiding human intuition with ai.
\newblock \emph{Nature}, 600\penalty0 (7887):\penalty0 70--74, 2021.

\bibitem[Jumper et~al.(2021)Jumper, Evans, Pritzel, Green, Figurnov,
  Ronneberger, Tunyasuvunakool, Bates, {\v{Z}}{\'\i}dek, Potapenko,
  et~al.]{jumper2021highly}
John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov,
  Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin
  {\v{Z}}{\'\i}dek, Anna Potapenko, et~al.
\newblock Highly accurate protein structure prediction with alphafold.
\newblock \emph{Nature}, 596\penalty0 (7873):\penalty0 583--589, 2021.

\bibitem[Tunyasuvunakool et~al.(2021)Tunyasuvunakool, Adler, Wu, Green,
  Zielinski, {\v{Z}}{\'\i}dek, Bridgland, Cowie, Meyer, Laydon,
  et~al.]{tunyasuvunakool2021highly}
Kathryn Tunyasuvunakool, Jonas Adler, Zachary Wu, Tim Green, Michal Zielinski,
  Augustin {\v{Z}}{\'\i}dek, Alex Bridgland, Andrew Cowie, Clemens Meyer, Agata
  Laydon, et~al.
\newblock Highly accurate protein structure prediction for the human proteome.
\newblock \emph{Nature}, 596\penalty0 (7873):\penalty0 590--596, 2021.

\bibitem[Ruff and Pappu(2021)]{RUFF2021167208}
Kiersten~M. Ruff and Rohit~V. Pappu.
\newblock Alphafold and implications for intrinsically disordered proteins.
\newblock \emph{Journal of Molecular Biology}, 433\penalty0 (20):\penalty0
  167208, 2021.
\newblock ISSN 0022-2836.
\newblock \doi{https://doi.org/10.1016/j.jmb.2021.167208}.
\newblock URL
  \url{https://www.sciencedirect.com/science/article/pii/S0022283621004411}.
\newblock From Protein Sequence to Structure at Warp Speed: How Alphafold
  Impacts Biology.

\bibitem[Koller and Friedman(2009)]{koller2009probabilistic}
Daphne Koller and Nir Friedman.
\newblock \emph{Probabilistic graphical models: principles and techniques}.
\newblock MIT press, 2009.

\bibitem[Wright(1934)]{wright1934method}
Sewall Wright.
\newblock The method of path coefficients.
\newblock \emph{The annals of mathematical statistics}, 5\penalty0
  (3):\penalty0 161--215, 1934.

\bibitem[Chickering et~al.(1995)Chickering, Geiger, and
  Heckerman]{chickering1995learning}
Max Chickering, Dan Geiger, and David Heckerman.
\newblock Learning bayesian networks: Search methods and experimental results.
\newblock In \emph{Proceedings of the fifth international workshop on
  artificial intelligence and statistics}, 1995.

\bibitem[Glymour et~al.(2019)Glymour, Zhang, and Spirtes]{glymour2019review}
Clark Glymour, Kun Zhang, and Peter Spirtes.
\newblock Review of causal discovery methods based on graphical models.
\newblock \emph{Frontiers in genetics}, 10:\penalty0 524, 2019.

\bibitem[Geiger and Pearl(1990)]{geiger1990logic}
Dan Geiger and Judea Pearl.
\newblock On the logic of causal models.
\newblock In \emph{Machine Intelligence and Pattern Recognition}, volume~9,
  pages 3--14. Elsevier, 1990.

\bibitem[Meek(2013)]{meek2013strong}
Christopher Meek.
\newblock Strong completeness and faithfulness in bayesian networks.
\newblock \emph{arXiv preprint arXiv:1302.4973}, 2013.

\bibitem[Eberhardt(2017)]{eberhardt2017introduction}
Frederick Eberhardt.
\newblock Introduction to the foundations of causal discovery.
\newblock \emph{International Journal of Data Science and Analytics},
  3\penalty0 (2):\penalty0 81--91, 2017.

\bibitem[Peters et~al.(2017)Peters, Janzing, and
  Sch{\"o}lkopf]{peters2017elements}
Jonas Peters, Dominik Janzing, and Bernhard Sch{\"o}lkopf.
\newblock \emph{Elements of causal inference: foundations and learning
  algorithms}.
\newblock The MIT Press, 2017.

\bibitem[Zheng et~al.(2018)Zheng, Aragam, Ravikumar, and Xing]{zheng2018dags}
Xun Zheng, Bryon Aragam, Pradeep Ravikumar, and Eric~P. Xing.
\newblock {DAGs with NO TEARS: Continuous Optimization for Structure Learning}.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Zheng et~al.(2020)Zheng, Dan, Aragam, Ravikumar, and
  Xing]{zheng2020learning}
Xun Zheng, Chen Dan, Bryon Aragam, Pradeep Ravikumar, and Eric~P. Xing.
\newblock {Learning sparse nonparametric DAGs}.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2020.

\bibitem[Pearl and Mackenzie(2018)]{pearl2018book}
Judea Pearl and Dana Mackenzie.
\newblock \emph{The Book of Why: The New Science of Cause and Effect}.
\newblock Hachette UK, 2018.

\bibitem[Baker(2016)]{baker20161}
Monya Baker.
\newblock 1,500 scientists lift the lid on reproducibility.
\newblock \emph{Nature}, 533\penalty0 (7604), 2016.

\bibitem[Camerer et~al.(2016)Camerer, Dreber, Forsell, Ho, Huber, Johannesson,
  Kirchler, Almenberg, Altmejd, Chan, et~al.]{camerer2016evaluating}
Colin~F Camerer, Anna Dreber, Eskil Forsell, Teck-Hua Ho, J{\"u}rgen Huber,
  Magnus Johannesson, Michael Kirchler, Johan Almenberg, Adam Altmejd, Taizan
  Chan, et~al.
\newblock Evaluating replicability of laboratory experiments in economics.
\newblock \emph{Science}, 351\penalty0 (6280):\penalty0 1433--1436, 2016.

\bibitem[Merton(1973)]{merton1973sociology}
Robert~K Merton.
\newblock \emph{The sociology of science: Theoretical and empirical
  investigations}.
\newblock University of Chicago press, 1973.

\bibitem[Stodden(2010)]{stodden2010scientific}
Victoria Stodden.
\newblock The scientific method in practice: Reproducibility in the
  computational sciences.
\newblock 2010.

\bibitem[Bhattacharya et~al.(2021)Bhattacharya, Nagarajan, Malinsky, and
  Shpitser]{bhattacharya2021differentiable}
Rohit Bhattacharya, Tushar Nagarajan, Daniel Malinsky, and Ilya Shpitser.
\newblock Differentiable causal discovery under unmeasured confounding.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 2314--2322. PMLR, 2021.

\bibitem[Kyono et~al.(2020)Kyono, Zhang, and van~der Schaar]{kyono2020castle}
Trent Kyono, Yao Zhang, and Mihaela van~der Schaar.
\newblock Castle: Regularization via auxiliary causal graph discovery.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 1501--1512, 2020.

\bibitem[Pamfil et~al.(2020)Pamfil, Sriwattanaworachai, Desai, Pilgerstorfer,
  Georgatzis, Beaumont, and Aragam]{pamfil2020dynotears}
Roxana Pamfil, Nisara Sriwattanaworachai, Shaan Desai, Philip Pilgerstorfer,
  Konstantinos Georgatzis, Paul Beaumont, and Bryon Aragam.
\newblock Dynotears: Structure learning from time-series data.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 1595--1605. PMLR, 2020.

\bibitem[Kyono et~al.(2021)Kyono, Zhang, Bellot, and van~der
  Schaar]{kyono2021miracle}
Trent Kyono, Yao Zhang, Alexis Bellot, and Mihaela van~der Schaar.
\newblock Miracle: Causally-aware imputation via learning missing data
  mechanisms.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[van Breugel et~al.(2021)van Breugel, Kyono, Berrevoets, and van~der
  Schaar]{van2021decaf}
Boris van Breugel, Trent Kyono, Jeroen Berrevoets, and Mihaela van~der Schaar.
\newblock Decaf: Generating fair synthetic data using causally-aware generative
  networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Lachapelle et~al.(2020)Lachapelle, Brouillard, Deleu, and
  Lacoste-Julien]{Lachapelle2020Gradient}
Sébastien Lachapelle, Philippe Brouillard, Tristan Deleu, and Simon
  Lacoste-Julien.
\newblock Gradient-based neural dag learning.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=rklbKA4YDS}.

\bibitem[Yu et~al.(2021)Yu, Gao, Yin, and Ji]{yu21a}
Yue Yu, Tian Gao, Naiyu Yin, and Qiang Ji.
\newblock Dags with no curl: An efficient dag structure learning approach.
\newblock In Marina Meila and Tong Zhang, editors, \emph{Proceedings of the
  38th International Conference on Machine Learning}, volume 139 of
  \emph{Proceedings of Machine Learning Research}, pages 12156--12166. PMLR,
  18--24 Jul 2021.
\newblock URL \url{https://proceedings.mlr.press/v139/yu21a.html}.

\bibitem[Yu et~al.(2019)Yu, Chen, Gao, and Yu]{yu19a}
Yue Yu, Jie Chen, Tian Gao, and Mo~Yu.
\newblock {DAG}-{GNN}: {DAG} structure learning with graph neural networks.
\newblock In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors,
  \emph{Proceedings of the 36th International Conference on Machine Learning},
  volume~97 of \emph{Proceedings of Machine Learning Research}, pages
  7154--7163. PMLR, 09--15 Jun 2019.
\newblock URL \url{https://proceedings.mlr.press/v97/yu19a.html}.

\bibitem[Bello et~al.(2022)Bello, Aragam, and Ravikumar]{bello2022dagma}
Kevin Bello, Bryon Aragam, and Pradeep~Kumar Ravikumar.
\newblock {DAGMA}: Learning {DAG}s via m-matrices and a log-determinant
  acyclicity characterization.
\newblock In Alice~H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho,
  editors, \emph{Advances in Neural Information Processing Systems}, 2022.
\newblock URL \url{https://openreview.net/forum?id=8rZYMpFUgK}.

\bibitem[Pearl(2009)]{pearl2009causality}
Judea Pearl.
\newblock \emph{Causality}.
\newblock Cambridge university press, 2009.

\bibitem[Pearl(1988)]{pearl1988probabilistic}
Judea Pearl.
\newblock \emph{Probabilistic reasoning in intelligent systems: networks of
  plausible inference}.
\newblock Morgan kaufmann, 1988.

\bibitem[Wainwright et~al.(2008)Wainwright, Jordan,
  et~al.]{wainwright2008graphical}
Martin~J Wainwright, Michael~I Jordan, et~al.
\newblock Graphical models, exponential families, and variational inference.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  1\penalty0 (1--2):\penalty0 1--305, 2008.

\bibitem[Pearl(1986)]{pearl1986fusion}
Judea Pearl.
\newblock Fusion, propagation, and structuring in belief networks.
\newblock \emph{Artificial intelligence}, 29\penalty0 (3):\penalty0 241--288,
  1986.

\bibitem[Verma and Pearl(1990{\natexlab{a}})]{verma1990causal}
Thomas Verma and Judea Pearl.
\newblock Causal networks: Semantics and expressiveness.
\newblock In \emph{Machine intelligence and pattern recognition}, volume~9,
  pages 69--76. Elsevier, 1990{\natexlab{a}}.

\bibitem[Geiger et~al.(1990{\natexlab{a}})Geiger, Verma, and
  Pearl]{geiger1990d}
Dan Geiger, Thomas Verma, and Judea Pearl.
\newblock d-separation: From theorems to algorithms.
\newblock In \emph{Machine Intelligence and Pattern Recognition}, volume~10,
  pages 139--148. Elsevier, 1990{\natexlab{a}}.

\bibitem[Geiger et~al.(1990{\natexlab{b}})Geiger, Verma, and
  Pearl]{geiger1990identifying}
Dan Geiger, Thomas Verma, and Judea Pearl.
\newblock Identifying independence in bayesian networks.
\newblock \emph{Networks}, 20\penalty0 (5):\penalty0 507--534,
  1990{\natexlab{b}}.

\bibitem[Howard and Matheson(1984)]{howard1984principles}
Ronald~A Howard and James~E Matheson.
\newblock The principles and applications of decision analysis.
\newblock \emph{Strategic Decisions Group, Palo Alto, CA}, pages 719--762,
  1984.

\bibitem[Smith(1989)]{smith1989influence}
JQ~Smith.
\newblock Influence diagrams for statistical modeling.
\newblock \emph{The Annals of Statistics}, 1, 1989.

\bibitem[Geiger and Pearl(1993)]{geiger1993logical}
Dan Geiger and Judea Pearl.
\newblock Logical and algorithmic properties of conditional independence and
  graphical models.
\newblock \emph{The annals of statistics}, 21\penalty0 (4):\penalty0
  2001--2021, 1993.

\bibitem[Meek(1995)]{meek1995strong}
Christopher Meek.
\newblock Strong completeness and faithfulness in bayesian networks.
\newblock In \emph{Proceedings of the Eleventh Conference on Uncertainty in
  Artificial Intelligence}, 1995.

\bibitem[Gao et~al.(2021)Gao, Chen, Shen, Liu, Gong, and
  Bondell]{gao2021federated}
Erdun Gao, Junjia Chen, Li~Shen, Tongliang Liu, Mingming Gong, and Howard
  Bondell.
\newblock Federated causal discovery.
\newblock \emph{arXiv preprint arXiv:2112.03555}, 2021.

\bibitem[Ng and Zhang(2022)]{ng2022towards}
Ignavier Ng and Kun Zhang.
\newblock Towards federated bayesian network structure learning with continuous
  optimization.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 8095--8111. PMLR, 2022.

\bibitem[Chen et~al.(2021)Chen, Sun, Ellington, Xing, and Song]{chen2021multi}
Xinshi Chen, Haoran Sun, Caleb Ellington, Eric Xing, and Le~Song.
\newblock Multi-task learning of order-consistent causal graphs.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 11083--11095, 2021.

\bibitem[Robinson(1977)]{robinson1977counting}
Robert~W Robinson.
\newblock Counting unlabeled acyclic digraphs.
\newblock In \emph{Combinatorial mathematics V}, pages 28--43. Springer, 1977.

\bibitem[Vowels et~al.(2021)Vowels, Camgoz, and Bowden]{vowels2021d}
Matthew~J Vowels, Necati~Cihan Camgoz, and Richard Bowden.
\newblock D’ya like dags? a survey on structure learning and causal
  discovery.
\newblock \emph{ACM Computing Surveys (CSUR)}, 2021.

\bibitem[Ng et~al.(2022)Ng, Lachapelle, Ke, Lacoste-Julien, and
  Zhang]{ng2022convergence}
Ignavier Ng, S{\'e}bastien Lachapelle, Nan~Rosemary Ke, Simon Lacoste-Julien,
  and Kun Zhang.
\newblock On the convergence of continuous constrained optimization for
  structure learning.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 8176--8198. PMLR, 2022.

\bibitem[Wei et~al.(2020)Wei, Gao, and Yu]{wei2020dags}
Dennis Wei, Tian Gao, and Yue Yu.
\newblock Dags with no fears: A closer look at continuous optimization for
  learning bayesian networks.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 3895--3906, 2020.

\bibitem[Bertsekas(2016)]{bertsekas1999}
Dimitri~P. Bertsekas.
\newblock \emph{Nonlinear Programming}.
\newblock Athena Scientific, 3\textsuperscript{rd} edition, 2016.
\newblock ISBN 978-1-886529-05-2.

\bibitem[Byrd et~al.(1995)Byrd, Lu, Nocedal, and Zhu]{byrd1995limited}
Richard~H Byrd, Peihuang Lu, Jorge Nocedal, and Ciyou Zhu.
\newblock A limited memory algorithm for bound constrained optimization.
\newblock \emph{SIAM Journal on scientific computing}, 16\penalty0
  (5):\penalty0 1190--1208, 1995.

\bibitem[Kaiser and Sipos(2022)]{kaiser2022unsuitability}
Marcus Kaiser and Maksim Sipos.
\newblock Unsuitability of {NOTEARS} for causal graph discovery when dealing
  with dimensional quantities.
\newblock \emph{Neural Processing Letters}, pages 1--9, 2022.

\bibitem[Reisach et~al.(2021)Reisach, Seiler, and Weichwald]{reisach2021beware}
Alexander~G Reisach, Christof Seiler, and Sebastian Weichwald.
\newblock Beware of the simulated dag! varsortability in additive noise models.
\newblock \emph{arXiv preprint arXiv:2102.13647}, 2021.

\bibitem[Jordan(1999)]{jordan1999learning}
Michael~Irwin Jordan.
\newblock \emph{Learning in graphical models}.
\newblock MIT press, 1999.

\bibitem[Lauritzen(1996)]{lauritzen1996graphical}
Steffen~L Lauritzen.
\newblock \emph{Graphical models}, volume~17.
\newblock Clarendon Press, 1996.

\bibitem[Barab{\'a}si and Albert(1999)]{barabasi1999emergence}
Albert-L{\'a}szl{\'o} Barab{\'a}si and R{\'e}ka Albert.
\newblock Emergence of scaling in random networks.
\newblock \emph{science}, 286\penalty0 (5439):\penalty0 509--512, 1999.

\bibitem[Spirtes et~al.(2000)Spirtes, Glymour, Scheines, and
  Heckerman]{spirtes2000causation}
Peter Spirtes, Clark~N Glymour, Richard Scheines, and David Heckerman.
\newblock \emph{Causation, prediction, and search}.
\newblock MIT press, 2000.

\bibitem[Verma and Pearl(1990{\natexlab{b}})]{verma1990}
Thomas~S. Verma and Judea Pearl.
\newblock Equivalence and synthesis of causal models.
\newblock In \emph{Proceedings of the Sixth Conference on Uncertainty in
  Artificial Intelligence}, 1990{\natexlab{b}}.

\bibitem[Ng et~al.(2020)Ng, Ghassami, and Zhang]{notears_sparsity2020}
Ignavier Ng, AmirEmad Ghassami, and Kun Zhang.
\newblock On the role of sparsity and dag constraints for learning linear dags.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin,
  editors, \emph{Advances in Neural Information Processing Systems}, volume~33,
  pages 17943--17954. Curran Associates, Inc., 2020.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2020/file/d04d42cdf14579cd294e5079e0745411-Paper.pdf}.

\bibitem[Walter(2014)]{walter2014identifiability}
Eric Walter.
\newblock \emph{Identifiability of parametric models}.
\newblock Elsevier, 2014.

\bibitem[Ghassami et~al.(2018)Ghassami, Kiyavash, Huang, and
  Zhang]{ghassami2018multi}
AmirEmad Ghassami, Negar Kiyavash, Biwei Huang, and Kun Zhang.
\newblock Multi-domain causal structure learning in linear systems.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Peters et~al.(2016)Peters, Bühlmann, and Meinshausen]{peters2015}
Jonas Peters, Peter Bühlmann, and Nicolai Meinshausen.
\newblock Causal inference by using invariant prediction: identification and
  confidence intervals.
\newblock \emph{Journal of the Royal Statistical Society. Series B (Statistical
  Methodology)}, 78\penalty0 (5):\penalty0 947--1012, 2016.
\newblock ISSN 13697412, 14679868.
\newblock URL \url{http://www.jstor.org/stable/44682904}.

\bibitem[Huang et~al.(2020)Huang, Zhang, Zhang, Ramsey, Sanchez-Romero,
  Glymour, and Sch{\"o}lkopf]{huang2020causal}
Biwei Huang, Kun Zhang, Jiji Zhang, Joseph~D Ramsey, Ruben Sanchez-Romero,
  Clark Glymour, and Bernhard Sch{\"o}lkopf.
\newblock Causal discovery from heterogeneous/nonstationary data.
\newblock \emph{J. Mach. Learn. Res.}, 21\penalty0 (89):\penalty0 1--53, 2020.

\bibitem[Zhang and Spirtes(2008)]{zhang2008detection}
Jiji Zhang and Peter Spirtes.
\newblock Detection of unfaithfulness and robust causal inference.
\newblock \emph{Minds and Machines}, 18\penalty0 (2):\penalty0 239--271, 2008.

\bibitem[Kalisch and B{\"u}hlman(2007)]{kalisch2007estimating}
Markus Kalisch and Peter B{\"u}hlman.
\newblock Estimating high-dimensional directed acyclic graphs with the
  pc-algorithm.
\newblock \emph{Journal of Machine Learning Research}, 8\penalty0 (3), 2007.

\bibitem[Zhang and Spirtes(2012)]{zhang2012strong}
Jiji Zhang and Peter~L Spirtes.
\newblock Strong faithfulness and uniform consistency in causal inference.
\newblock \emph{arXiv preprint arXiv:1212.2506}, 2012.

\bibitem[Uhler et~al.(2013)Uhler, Raskutti, B{\"u}hlmann, and
  Yu]{uhler2013geometry}
Caroline Uhler, Garvesh Raskutti, Peter B{\"u}hlmann, and Bin Yu.
\newblock Geometry of the faithfulness assumption in causal inference.
\newblock \emph{The Annals of Statistics}, pages 436--463, 2013.

\bibitem[Geiger and Heckerman(1994)]{geiger1994learning}
Dan Geiger and David Heckerman.
\newblock Learning gaussian networks.
\newblock In \emph{Uncertainty Proceedings 1994}, pages 235--243. Elsevier,
  1994.

\bibitem[Heckerman et~al.(2006)Heckerman, Meek, and
  Cooper]{heckerman2006bayesian}
David Heckerman, Christopher Meek, and Gregory Cooper.
\newblock A bayesian approach to causal discovery.
\newblock In \emph{Innovations in Machine Learning}, pages 1--28. Springer,
  2006.

\end{thebibliography}
