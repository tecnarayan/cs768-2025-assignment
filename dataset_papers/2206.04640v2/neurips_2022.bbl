\begin{thebibliography}{44}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ayoub et~al.(2020)Ayoub, Jia, Szepesvari, Wang, and
  Yang]{ayoub2020model}
Alex Ayoub, Zeyu Jia, Csaba Szepesvari, Mengdi Wang, and Lin Yang.
\newblock Model-based reinforcement learning with value-targeted regression.
\newblock In \emph{International Conference on Machine Learning}, pages
  463--474. PMLR, 2020.

\bibitem[Azar et~al.(2017)Azar, Osband, and Munos]{azar2017minimax}
Mohammad~Gheshlaghi Azar, Ian Osband, and R{\'e}mi Munos.
\newblock Minimax regret bounds for reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  263--272. PMLR, 2017.

\bibitem[Bubeck and Sellke(2020)]{bubeck2020first}
S{\'e}bastien Bubeck and Mark Sellke.
\newblock First-order bayesian regret analysis of thompson sampling.
\newblock In \emph{Algorithmic Learning Theory}, pages 196--233. PMLR, 2020.

\bibitem[Cai et~al.(2020)Cai, Yang, Jin, and Wang]{cai2020provably}
Qi~Cai, Zhuoran Yang, Chi Jin, and Zhaoran Wang.
\newblock Provably efficient exploration in policy optimization.
\newblock In \emph{International Conference on Machine Learning}, pages
  1283--1294. PMLR, 2020.

\bibitem[Cover and Thomas(1991)]{cover1991elements}
T.M. Cover and J.A. Thomas.
\newblock \emph{Elements of Information Theory}.
\newblock Wiley Series in Telecommunications and Signal Processing. Wiley,
  1991.
\newblock ISBN 9780471062592.
\newblock URL \url{https://books.google.com/books?id=CX9QAAAAMAAJ}.

\bibitem[Dann et~al.(2021)Dann, Mohri, Zhang, and Zimmert]{dann2021provably}
Christoph Dann, Mehryar Mohri, Tong Zhang, and Julian Zimmert.
\newblock A provably efficient model-free posterior sampling method for
  episodic reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Dong and Roy(2018)]{dong2018information}
Shi Dong and Benjamin~Van Roy.
\newblock An information-theoretic analysis for thompson sampling with many
  actions.
\newblock In \emph{Proceedings of the 32nd International Conference on Neural
  Information Processing Systems}, pages 4161--4169, 2018.

\bibitem[Du et~al.(2021)Du, Kakade, Lee, Lovett, Mahajan, Sun, and
  Wang]{du2021bilinear}
Simon Du, Sham Kakade, Jason Lee, Shachar Lovett, Gaurav Mahajan, Wen Sun, and
  Ruosong Wang.
\newblock Bilinear classes: A structural framework for provable generalization
  in rl.
\newblock In \emph{International Conference on Machine Learning}, pages
  2826--2836. PMLR, 2021.

\bibitem[Foster et~al.(2021)Foster, Kakade, Qian, and
  Rakhlin]{foster2021statistical}
Dylan~J Foster, Sham~M Kakade, Jian Qian, and Alexander Rakhlin.
\newblock The statistical complexity of interactive decision making.
\newblock \emph{arXiv preprint arXiv:2112.13487}, 2021.

\bibitem[Hao et~al.(2021)Hao, Lattimore, and Deng]{hao2021information}
Botao Hao, Tor Lattimore, and Wei Deng.
\newblock Information directed sampling for sparse linear bandits.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Hao et~al.(2022)Hao, Lattimore, and Qing]{hao2022contextual}
Botao Hao, Tor Lattimore, and Chao Qing.
\newblock Contextual information-directed sampling.
\newblock \emph{arXiv preprint}, 2022.

\bibitem[Jiang et~al.(2017)Jiang, Krishnamurthy, Agarwal, Langford, and
  Schapire]{jiang2017contextual}
Nan Jiang, Akshay Krishnamurthy, Alekh Agarwal, John Langford, and Robert~E
  Schapire.
\newblock Contextual decision processes with low bellman rank are
  pac-learnable.
\newblock In \emph{International Conference on Machine Learning}, pages
  1704--1713. PMLR, 2017.

\bibitem[Jin et~al.(2018)Jin, Allen-Zhu, Bubeck, and Jordan]{jin2018q}
Chi Jin, Zeyuan Allen-Zhu, Sebastien Bubeck, and Michael~I Jordan.
\newblock Is q-learning provably efficient?
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Jin et~al.(2020)Jin, Yang, Wang, and Jordan]{jin2020provably}
Chi Jin, Zhuoran Yang, Zhaoran Wang, and Michael~I Jordan.
\newblock Provably efficient reinforcement learning with linear function
  approximation.
\newblock In \emph{Conference on Learning Theory}, pages 2137--2143. PMLR,
  2020.

\bibitem[Jin et~al.(2021)Jin, Liu, and Miryoosefi]{jin2021bellman}
Chi Jin, Qinghua Liu, and Sobhan Miryoosefi.
\newblock Bellman eluder dimension: New rich classes of rl problems, and
  sample-efficient algorithms.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Kirschner and Krause(2018)]{kirschner2018information}
Johannes Kirschner and Andreas Krause.
\newblock Information directed sampling and bandits with heteroscedastic noise.
\newblock In \emph{Conference On Learning Theory}, pages 358--384. PMLR, 2018.

\bibitem[Kirschner et~al.(2020{\natexlab{a}})Kirschner, Lattimore, and
  Krause]{kirschner2020information}
Johannes Kirschner, Tor Lattimore, and Andreas Krause.
\newblock Information directed sampling for linear partial monitoring.
\newblock In \emph{Conference on Learning Theory}, pages 2328--2369. PMLR,
  2020{\natexlab{a}}.

\bibitem[Kirschner et~al.(2020{\natexlab{b}})Kirschner, Lattimore, Vernade, and
  Szepesv{\'a}ri]{kirschner2020asymptotically}
Johannes Kirschner, Tor Lattimore, Claire Vernade, and Csaba Szepesv{\'a}ri.
\newblock Asymptotically optimal information-directed sampling.
\newblock \emph{arXiv preprint arXiv:2011.05944}, 2020{\natexlab{b}}.

\bibitem[Kirschner et~al.(2021)Kirschner, Lattimore, Vernade, and
  Szepesv{\'a}ri]{kirschner2021asymptotically}
Johannes Kirschner, Tor Lattimore, Claire Vernade, and Csaba Szepesv{\'a}ri.
\newblock Asymptotically optimal information-directed sampling.
\newblock In \emph{Conference on Learning Theory}, pages 2777--2821. PMLR,
  2021.

\bibitem[Lattimore and Gyorgy(2021)]{lattimore2021mirror}
Tor Lattimore and Andras Gyorgy.
\newblock Mirror descent and the information ratio.
\newblock In \emph{Conference on Learning Theory}, pages 2965--2992. PMLR,
  2021.

\bibitem[Lattimore and Szepesv{\'a}ri(2019)]{lattimore2019information}
Tor Lattimore and Csaba Szepesv{\'a}ri.
\newblock An information-theoretic approach to minimax regret in partial
  monitoring.
\newblock In \emph{Conference on Learning Theory}, pages 2111--2139. PMLR,
  2019.

\bibitem[Liu et~al.(2018)Liu, Buccapatnam, and Shroff]{liu2018information}
Fang Liu, Swapna Buccapatnam, and Ness Shroff.
\newblock Information directed sampling for stochastic bandits with graph
  feedback.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~32, 2018.

\bibitem[Lu(2020)]{lu2020information}
Xiuyuan Lu.
\newblock \emph{Information-Directed Sampling for Reinforcement Learning}.
\newblock Stanford University, 2020.

\bibitem[Lu and Van~Roy(2019)]{lu2019information}
Xiuyuan Lu and Benjamin Van~Roy.
\newblock Information-theoretic confidence bounds for reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1911.09724}, 2019.

\bibitem[Lu et~al.(2021)Lu, Van~Roy, Dwaracherla, Ibrahimi, Osband, and
  Wen]{lu2021reinforcement}
Xiuyuan Lu, Benjamin Van~Roy, Vikranth Dwaracherla, Morteza Ibrahimi, Ian
  Osband, and Zheng Wen.
\newblock Reinforcement learning, bit by bit.
\newblock \emph{arXiv preprint arXiv:2103.04047}, 2021.

\bibitem[M{\'e}nard et~al.(2021)M{\'e}nard, Domingues, Shang, and
  Valko]{menard2021ucb}
Pierre M{\'e}nard, Omar~Darwiche Domingues, Xuedong Shang, and Michal Valko.
\newblock Ucb momentum q-learning: Correcting the bias without forgetting.
\newblock In \emph{International Conference on Machine Learning}, pages
  7609--7618. PMLR, 2021.

\bibitem[Nikolov et~al.(2018)Nikolov, Kirschner, Berkenkamp, and
  Krause]{nikolov2018information}
Nikolay Nikolov, Johannes Kirschner, Felix Berkenkamp, and Andreas Krause.
\newblock Information-directed exploration for deep reinforcement learning.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Osband and Van~Roy(2014)]{osband2014model}
Ian Osband and Benjamin Van~Roy.
\newblock Model-based reinforcement learning and the eluder dimension.
\newblock \emph{Advances in Neural Information Processing Systems}, 27, 2014.

\bibitem[Osband et~al.(2013)Osband, Russo, and Van~Roy]{osband2013more}
Ian Osband, Daniel Russo, and Benjamin Van~Roy.
\newblock (more) efficient reinforcement learning via posterior sampling.
\newblock \emph{Advances in Neural Information Processing Systems}, 26, 2013.

\bibitem[Osband et~al.(2019)Osband, Van~Roy, Russo, Wen,
  et~al.]{osband2019deep}
Ian Osband, Benjamin Van~Roy, Daniel~J Russo, Zheng Wen, et~al.
\newblock Deep exploration via randomized value functions.
\newblock \emph{J. Mach. Learn. Res.}, 20\penalty0 (124):\penalty0 1--62, 2019.

\bibitem[Osband et~al.(2021{\natexlab{a}})Osband, Wen, Asghari, Ibrahimi, Lu,
  and Van~Roy]{osband2021epistemic}
Ian Osband, Zheng Wen, Mohammad Asghari, Morteza Ibrahimi, Xiyuan Lu, and
  Benjamin Van~Roy.
\newblock Epistemic neural networks.
\newblock \emph{arXiv preprint arXiv:2107.08924}, 2021{\natexlab{a}}.

\bibitem[Osband et~al.(2021{\natexlab{b}})Osband, Wen, Asghari, Dwaracherla,
  Hao, Ibrahimi, Lawson, Lu, O'Donoghue, and Van~Roy]{osband2021evaluating}
Ian Osband, Zheng Wen, Seyed~Mohammad Asghari, Vikranth Dwaracherla, Botao Hao,
  Morteza Ibrahimi, Dieterich Lawson, Xiuyuan Lu, Brendan O'Donoghue, and
  Benjamin Van~Roy.
\newblock The neural testbed: Evaluating predictive distributions.
\newblock \emph{arXiv preprint arXiv:2110.04629}, 2021{\natexlab{b}}.

\bibitem[Russo(2019)]{russo2019worst}
Daniel Russo.
\newblock Worst-case regret bounds for exploration via randomized value
  functions.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Russo and Van~Roy(2014)]{russo2014learning}
Daniel Russo and Benjamin Van~Roy.
\newblock Learning to optimize via information-directed sampling.
\newblock \emph{Advances in Neural Information Processing Systems}, 27, 2014.

\bibitem[Russo and Van~Roy(2016)]{russo2016information}
Daniel Russo and Benjamin Van~Roy.
\newblock An information-theoretic analysis of thompson sampling.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 2442--2471, 2016.

\bibitem[Russo and Van~Roy(2018)]{russo2018learning}
Daniel Russo and Benjamin Van~Roy.
\newblock Learning to optimize via information-directed sampling.
\newblock \emph{Operations Research}, 66\penalty0 (1):\penalty0 230--252, 2018.

\bibitem[Russo and Van~Roy(2022)]{russo2022satisficing}
Daniel Russo and Benjamin Van~Roy.
\newblock Satisficing in time-sensitive bandit learning.
\newblock \emph{Mathematics of Operations Research}, 2022.

\bibitem[Tang and Polyanskiy(2021)]{tang2021capacity}
Jennifer Tang and Yury Polyanskiy.
\newblock Capacity of noisy permutation channels.
\newblock \emph{arXiv preprint arXiv:2111.00559}, 2021.

\bibitem[Wang et~al.(2020)Wang, Salakhutdinov, and Yang]{wang2020reinforcement}
Ruosong Wang, Russ~R Salakhutdinov, and Lin Yang.
\newblock Reinforcement learning with general value function approximation:
  Provably efficient approach via bounded eluder dimension.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 6123--6135, 2020.

\bibitem[Yang and Wang(2019)]{yang2019sample}
Lin Yang and Mengdi Wang.
\newblock Sample-optimal parametric q-learning using linearly additive
  features.
\newblock In \emph{International Conference on Machine Learning}, pages
  6995--7004. PMLR, 2019.

\bibitem[Zanette et~al.(2020)Zanette, Brandfonbrener, Brunskill, Pirotta, and
  Lazaric]{zanette2020frequentist}
Andrea Zanette, David Brandfonbrener, Emma Brunskill, Matteo Pirotta, and
  Alessandro Lazaric.
\newblock Frequentist regret bounds for randomized least-squares value
  iteration.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 1954--1964. PMLR, 2020.

\bibitem[Zhang(2021)]{zhang2021feel}
Tong Zhang.
\newblock Feel-good thompson sampling for contextual bandits and reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:2110.00871}, 2021.

\bibitem[Zhang et~al.(2020)Zhang, Zhou, and Ji]{zhang2020almost}
Zihan Zhang, Yuan Zhou, and Xiangyang Ji.
\newblock Almost optimal model-free reinforcement learningvia
  reference-advantage decomposition.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 15198--15207, 2020.

\bibitem[Zhou et~al.(2021)Zhou, Gu, and Szepesvari]{zhou2021nearly}
Dongruo Zhou, Quanquan Gu, and Csaba Szepesvari.
\newblock Nearly minimax optimal reinforcement learning for linear mixture
  markov decision processes.
\newblock In \emph{Conference on Learning Theory}, pages 4532--4576. PMLR,
  2021.

\end{thebibliography}
