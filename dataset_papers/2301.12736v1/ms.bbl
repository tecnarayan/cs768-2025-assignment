\begin{thebibliography}{24}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amini et~al.(2020)Amini, Schwarting, Soleimany, and
  Rus]{amini2020deep}
Amini, A., Schwarting, W., Soleimany, A., and Rus, D.
\newblock Deep evidential regression.
\newblock In \emph{Proc.\ {NeurIPS}, 33rd Advances in Neural Information
  Processing Systems}, volume~33, pp.\  14927--14937, 2020.

\bibitem[Bao et~al.(2021)Bao, Yu, and Kong]{Bao2021EvidentialDL}
Bao, W., Yu, Q., and Kong, Y.
\newblock Evidential deep learning for open set action recognition.
\newblock \emph{2021 IEEE/CVF International Conference on Computer Vision
  (ICCV)}, pp.\  13329--13338, 2021.

\bibitem[Bengs et~al.(2022)Bengs, H{\"u}llermeier, and
  Waegeman]{bengs2022pitfalls}
Bengs, V., H{\"u}llermeier, E., and Waegeman, W.
\newblock Pitfalls of epistemic uncertainty quantification through loss
  minimisation.
\newblock In \emph{Proc.\ {NeurIPS}, 35th Advances in Neural Information
  Processing Systems}, 2022.

\bibitem[Charpentier et~al.(2020)Charpentier, Z\"ugner, and
  G\"unnemann]{char_ue20}
Charpentier, B., Z\"ugner, D., and G\"unnemann, S.
\newblock Posterior network: Uncertainty estimation without {OOD} samples via
  density-based pseudo-counts.
\newblock In \emph{Proc.\ NeurIPS, 33rd Neural Information Processing Systems},
  volume~33, pp.\  1356--1367, 2020.

\bibitem[Charpentier et~al.(2022)Charpentier, Borchert, Zugner, Geisler, and
  G\"unnemann]{Charpentier2022NaturalPN}
Charpentier, B., Borchert, O., Zugner, D., Geisler, S., and G\"unnemann, S.
\newblock Natural posterior network: Deep {B}ayesian predictive uncertainty for
  exponential family distributions.
\newblock 2022.

\bibitem[Gneiting \& Raftery(2007)Gneiting and Raftery]{gneiting2007strictly}
Gneiting, T. and Raftery, A.~E.
\newblock Strictly proper scoring rules, prediction, and estimation.
\newblock \emph{Journal of the American statistical Association}, 102\penalty0
  (477):\penalty0 359--378, 2007.

\bibitem[Hammam et~al.(2022)Hammam, Bonarens, Ghobadi, and
  Stiller]{hammam2022predictive}
Hammam, A., Bonarens, F., Ghobadi, S.~E., and Stiller, C.
\newblock Predictive uncertainty quantification of deep neural networks using
  {D}irichlet distributions.
\newblock In \emph{Computer Science in Cars Symposium}, pp.\  1--10, 2022.

\bibitem[H\"ullermeier \& Waegeman(2021)H\"ullermeier and Waegeman]{mpub440}
H\"ullermeier, E. and Waegeman, W.
\newblock Aleatoric and epistemic uncertainty in machine learning: {A}n
  introduction to concepts and methods.
\newblock \emph{Machine Learning}, 110\penalty0 (3):\penalty0 457--506, 2021.
\newblock \doi{10.1007/s10994-021-05946-3}.

\bibitem[Huseljic et~al.(2020)Huseljic, Sick, Herde, and Kottke]{HuseljicSHK20}
Huseljic, D., Sick, B., Herde, M., and Kottke, D.
\newblock Separation of aleatoric and epistemic uncertainty in deterministic
  deep neural networks.
\newblock In \emph{Proc.\ {ICPR}, 25th International Conference on Pattern
  Recognition}, pp.\  9172--9179. {IEEE}, 2020.

\bibitem[Kendall \& Gal(2017)Kendall and Gal]{kend_wu17}
Kendall, A. and Gal, Y.
\newblock What uncertainties do we need in {B}ayesian deep learning for
  computer vision?
\newblock In \emph{Proc.\ NIPS, 30th Advances in Neural Information Processing
  Systems}, pp.\  5574--5584, 2017.

\bibitem[Kopetzki et~al.(2021)Kopetzki, Charpentier, Z{\"{u}}gner, Giri, and
  G{\"{u}}nnemann]{KopetzkiCZGG21}
Kopetzki, A., Charpentier, B., Z{\"{u}}gner, D., Giri, S., and G{\"{u}}nnemann,
  S.
\newblock Evaluating robustness of predictive uncertainty estimation: Are
  {D}irichlet-based models reliable?
\newblock In \emph{Proc.\ {ICML}, 38th International Conference on Machine
  Learning}, pp.\  5707--5718, 2021.

\bibitem[Ma et~al.(2021)Ma, Han, Zhang, Fu, Zhou, and Hu]{Ma2021TrustworthyMR}
Ma, H., Han, Z., Zhang, C., Fu, H., Zhou, J.~T., and Hu, Q.
\newblock Trustworthy multimodal regression with mixture of normal-inverse
  gamma distributions.
\newblock In \emph{Neural Information Processing Systems}, 2021.

\bibitem[Malinin \& Gales(2018)Malinin and Gales]{MalininG18}
Malinin, A. and Gales, M.
\newblock Predictive uncertainty estimation via prior networks.
\newblock In \emph{Proc.\ {NeurIPS}, 31st Advances in Neural Information
  Processing Systems}, pp.\  7047--7058, 2018.

\bibitem[Malinin \& Gales(2019)Malinin and Gales]{MalininG19}
Malinin, A. and Gales, M.
\newblock Reverse {KL}-divergence training of prior networks: Improved
  uncertainty and adversarial robustness.
\newblock In \emph{Proc.\ {NeurIPS}, 32nd Advances in Neural Information
  Processing Systems}, pp.\  14520--14531, 2019.

\bibitem[Malinin et~al.(2020{\natexlab{a}})Malinin, Chervontsev, Provilkov, and
  Gales]{MalininUnpub}
Malinin, A., Chervontsev, S., Provilkov, I., and Gales, M. J.~F.
\newblock Regression prior networks.
\newblock \emph{CoRR}, abs/2006.11590, 2020{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2006.11590}.

\bibitem[Malinin et~al.(2020{\natexlab{b}})Malinin, Mlodozeniec, and
  Gales]{MalininMG20}
Malinin, A., Mlodozeniec, B., and Gales, M.
\newblock Ensemble distribution distillation.
\newblock In \emph{Proc.\ {ICLR}, 8th International Conference on Learning
  Representations}, 2020{\natexlab{b}}.

\bibitem[Meinert et~al.(2022)Meinert, Gawlikowski, and
  Lavin]{meinert2022unreasonable}
Meinert, N., Gawlikowski, J., and Lavin, A.
\newblock The unreasonable effectiveness of deep evidential regression.
\newblock \emph{arXiv preprint arXiv:2205.10060}, 2022.

\bibitem[Nau(1985)]{nau1985should}
Nau, R.~F.
\newblock Should scoring rules be 'effective'?
\newblock \emph{Management Science}, 31\penalty0 (5):\penalty0 527--535, 1985.

\bibitem[Oh \& Shin(2022)Oh and Shin]{Oh_Shin_2022}
Oh, D. and Shin, B.
\newblock Improving evidential deep learning via multi-task learning.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  36\penalty0 (7):\penalty0 7895--7903, Jun. 2022.
\newblock \doi{10.1609/aaai.v36i7.20759}.
\newblock URL \url{https://ojs.aaai.org/index.php/AAAI/article/view/20759}.

\bibitem[Ovcharov(2018)]{ovcharov2018proper}
Ovcharov, E.~Y.
\newblock Proper scoring rules and {B}regman divergence.
\newblock \emph{Bernoulli}, 24\penalty0 (1):\penalty0 53--79, 2018.

\bibitem[Pandey \& Yu(2022)Pandey and Yu]{Shankar2023AAAI}
Pandey, D.~S. and Yu, Q.
\newblock Evidential conditional neural processes, 2022.
\newblock URL \url{https://arxiv.org/abs/2212.00131}.

\bibitem[Senge et~al.(2014)Senge, B\"osner, Dembczynski, Haasenritter, Hirsch,
  Donner-Banzhoff, and H\"ullermeier]{mpub272}
Senge, R., B\"osner, S., Dembczynski, K., Haasenritter, J., Hirsch, O.,
  Donner-Banzhoff, N., and H\"ullermeier, E.
\newblock Reliable classification: Learning classifiers that distinguish
  aleatoric and epistemic uncertainty.
\newblock \emph{Information Sciences}, 255:\penalty0 16--29, 2014.

\bibitem[Sensoy et~al.(2018)Sensoy, Kaplan, and Kandemir]{sens_ed18}
Sensoy, M., Kaplan, L., and Kandemir, M.
\newblock Evidential deep learning to quantify classification uncertainty.
\newblock In \emph{Proc.\ NeurIPS, 31st Conference on Neural Information
  Processing Systems}, pp.\  3183--3193, Montreal, Canada, 2018.

\bibitem[Tsiligkaridis(2021)]{tsiligkaridis2021information}
Tsiligkaridis, T.
\newblock Information aware max-norm {D}irichlet networks for predictive
  uncertainty estimation.
\newblock \emph{Neural Networks}, 135:\penalty0 105--114, 2021.

\end{thebibliography}
