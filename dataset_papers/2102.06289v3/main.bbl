\begin{thebibliography}{52}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bahnsen et~al.(2014)Bahnsen, Stojanovic, Aouada, and
  Ottersten]{bahnsen2014improving}
Bahnsen, A.~C., Stojanovic, A., Aouada, D., and Ottersten, B.
\newblock Improving credit card fraud detection with calibrated probabilities.
\newblock In \emph{Proceedings of the 2014 SIAM international conference on
  data mining}, pp.\  677--685. SIAM, 2014.

\bibitem[Berthelot et~al.(2019)Berthelot, Carlini, Goodfellow, Papernot,
  Oliver, and Raffel]{berthelot2019mixmatch}
Berthelot, D., Carlini, N., Goodfellow, I., Papernot, N., Oliver, A., and
  Raffel, C.
\newblock Mixmatch: A holistic approach to semi-supervised learning.
\newblock \emph{arXiv preprint arXiv:1905.02249}, 2019.

\bibitem[Carmon et~al.(2019)Carmon, Raghunathan, Schmidt, Liang, and
  Duchi]{carmon2019unlabeled}
Carmon, Y., Raghunathan, A., Schmidt, L., Liang, P., and Duchi, J.~C.
\newblock Unlabeled data improves adversarial robustness.
\newblock \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Chan et~al.(2020)Chan, Alaa, Qian, and Van
  Der~Schaar]{chan2020unlabelled}
Chan, A., Alaa, A., Qian, Z., and Van Der~Schaar, M.
\newblock Unlabelled data improves bayesian uncertainty calibration under
  covariate shift.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1392--1402. PMLR, 2020.

\bibitem[Chapelle et~al.(2009)Chapelle, Scholkopf, and Zien]{chapelle2009semi}
Chapelle, O., Scholkopf, B., and Zien, A.
\newblock Semi-supervised learning (chapelle, o. et al., eds.; 2006)[book
  reviews].
\newblock \emph{IEEE Transactions on Neural Networks}, 20\penalty0
  (3):\penalty0 542--542, 2009.

\bibitem[Clanuwat et~al.(2019)Clanuwat, Bober-Irizar, Kitamoto, Lamb, Yamamoto,
  and Ha]{clanuwat2019deep}
Clanuwat, T., Bober-Irizar, M., Kitamoto, A., Lamb, A., Yamamoto, K., and Ha,
  D.
\newblock Deep learning for classical japanese literature.
\newblock In \emph{NeurIPS Creativity Workshop 2019}, 2019.

\bibitem[Dan et~al.(2020)Dan, Wei, and Ravikumar]{dan2020sharp}
Dan, C., Wei, Y., and Ravikumar, P.
\newblock Sharp statistical guaratees for adversarially robust gaussian
  classification.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2345--2355. PMLR, 2020.

\bibitem[Deng et~al.(2020{\natexlab{a}})Deng, Ding, Dwork, Hong, Parmigiani,
  Patil, and Sur]{deng2020representation}
Deng, Z., Ding, F., Dwork, C., Hong, R., Parmigiani, G., Patil, P., and Sur, P.
\newblock Representation via representations: Domain generalization via
  adversarially learned invariant representations.
\newblock \emph{arXiv preprint arXiv:2006.11478}, 2020{\natexlab{a}}.

\bibitem[Deng et~al.(2020{\natexlab{b}})Deng, Dwork, Wang, and
  Zhang]{deng2020interpreting}
Deng, Z., Dwork, C., Wang, J., and Zhang, L.
\newblock Interpreting robust optimization via adversarial influence functions.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2464--2473. PMLR, 2020{\natexlab{b}}.

\bibitem[Deng et~al.(2020{\natexlab{c}})Deng, He, Huang, and
  Su]{deng2020towards}
Deng, Z., He, H., Huang, J., and Su, W.
\newblock Towards understanding the dynamics of the first-order adversaries.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2484--2493. PMLR, 2020{\natexlab{c}}.

\bibitem[Deng et~al.(2021{\natexlab{a}})Deng, Huang, and
  Kawaguchi]{deng2021shrinking}
Deng, Z., Huang, J., and Kawaguchi, K.
\newblock How shrinking gradient noise helps the performance of neural
  networks.
\newblock In \emph{2021 IEEE International Conference on Big Data (Big Data)},
  pp.\  1002--1007. IEEE, 2021{\natexlab{a}}.

\bibitem[Deng et~al.(2021{\natexlab{b}})Deng, Zhang, Ghorbani, and
  Zou]{deng2020improving}
Deng, Z., Zhang, L., Ghorbani, A., and Zou, J.
\newblock Improving adversarial robustness via unlabeled out-of-domain data.
\newblock \emph{International Conference on Artificial Intelligence and
  Statistics}, 2021{\natexlab{b}}.

\bibitem[Deng et~al.(2021{\natexlab{c}})Deng, Zhang, Ghorbani, and
  Zou]{deng2021improving}
Deng, Z., Zhang, L., Ghorbani, A., and Zou, J.
\newblock Improving adversarial robustness via unlabeled out-of-domain data.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pp.\  2845--2853. PMLR, 2021{\natexlab{c}}.

\bibitem[Deng et~al.(2021{\natexlab{d}})Deng, Zhang, Vodrahalli, Kawaguchi, and
  Zou]{deng2021adversarial}
Deng, Z., Zhang, L., Vodrahalli, K., Kawaguchi, K., and Zou, J.~Y.
\newblock Adversarial training helps transfer learning via better
  representations.
\newblock \emph{Advances in Neural Information Processing Systems}, 34,
  2021{\natexlab{d}}.

\bibitem[Foster \& Stine(2004)Foster and Stine]{foster2004variable}
Foster, D.~P. and Stine, R.~A.
\newblock Variable selection in data mining: Building a predictive model for
  bankruptcy.
\newblock \emph{Journal of the American Statistical Association}, 99\penalty0
  (466):\penalty0 303--313, 2004.

\bibitem[Foster \& Vohra(1997)Foster and Vohra]{foster1997calibrated}
Foster, D.~P. and Vohra, R.~V.
\newblock Calibrated learning and correlated equilibrium.
\newblock \emph{Games and Economic Behavior}, 21\penalty0 (1-2):\penalty0 40,
  1997.

\bibitem[Gneiting \& Raftery(2005)Gneiting and Raftery]{gneiting2005weather}
Gneiting, T. and Raftery, A.~E.
\newblock Weather forecasting with ensemble methods.
\newblock \emph{Science}, 310\penalty0 (5746):\penalty0 248--249, 2005.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Goodfellow, I.~J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D.,
  Ozair, S., Courville, A., and Bengio, Y.
\newblock Generative adversarial networks.
\newblock \emph{arXiv preprint arXiv:1406.2661}, 2014.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017calibration}
Guo, C., Pleiss, G., Sun, Y., and Weinberger, K.~Q.
\newblock On calibration of modern neural networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1321--1330. PMLR, 2017.

\bibitem[Guo et~al.(2019)Guo, Mao, and Zhang]{guo2019mixup}
Guo, H., Mao, Y., and Zhang, R.
\newblock Mixup as locally linear out-of-manifold regularization.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pp.\  3714--3722, 2019.

\bibitem[He et~al.(2016{\natexlab{a}})He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016{\natexlab{a}}.

\bibitem[He et~al.(2016{\natexlab{b}})He, Zhang, Ren, and Sun]{he2016identity}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Identity mappings in deep residual networks.
\newblock In \emph{European Conference on Computer Vision}, pp.\  630--645.
  Springer, 2016{\natexlab{b}}.

\bibitem[Huang et~al.(2020)Huang, Li, Macheret, Gabriel, and
  Ohno-Machado]{huang2020tutorial}
Huang, Y., Li, W., Macheret, F., Gabriel, R.~A., and Ohno-Machado, L.
\newblock A tutorial on calibration measurements and calibration models for
  clinical prediction models.
\newblock \emph{Journal of the American Medical Informatics Association},
  27\penalty0 (4):\penalty0 621--633, 2020.

\bibitem[Ji et~al.(2021{\natexlab{a}})Ji, Deng, Nakada, Zou, and
  Zhang]{ji2021power}
Ji, W., Deng, Z., Nakada, R., Zou, J., and Zhang, L.
\newblock The power of contrast for feature learning: A theoretical analysis.
\newblock \emph{arXiv preprint arXiv:2110.02473}, 2021{\natexlab{a}}.

\bibitem[Ji et~al.(2021{\natexlab{b}})Ji, Lu, Zhang, Deng, and
  Su]{ji2021unconstrained}
Ji, W., Lu, Y., Zhang, Y., Deng, Z., and Su, W.~J.
\newblock An unconstrained layer-peeled perspective on neural collapse.
\newblock \emph{arXiv preprint arXiv:2110.02796}, 2021{\natexlab{b}}.

\bibitem[Jiang et~al.(2012)Jiang, Osl, Kim, and
  Ohno-Machado]{jiang2012calibrating}
Jiang, X., Osl, M., Kim, J., and Ohno-Machado, L.
\newblock Calibrating predictive model estimates to support personalized
  medicine.
\newblock \emph{Journal of the American Medical Informatics Association},
  19\penalty0 (2):\penalty0 263--274, 2012.

\bibitem[Johnson et~al.(2002)Johnson, Wichern, et~al.]{johnson2002applied}
Johnson, R.~A., Wichern, D.~W., et~al.
\newblock \emph{Applied multivariate statistical analysis}, volume~5.
\newblock Prentice hall Upper Saddle River, NJ, 2002.

\bibitem[Kawaguchi et~al.(2022)Kawaguchi, Zhang, and
  Deng]{kawaguchi2022understanding}
Kawaguchi, K., Zhang, L., and Deng, Z.
\newblock Understanding dynamics of nonlinear representation learning and its
  application.
\newblock \emph{Neural Computation}, 34\penalty0 (4):\penalty0 991--1018, 2022.

\bibitem[Kim et~al.(2020)Kim, Choo, and Song]{kim2020puzzle}
Kim, J.-H., Choo, W., and Song, H.~O.
\newblock Puzzle mix: Exploiting saliency and local statistics for optimal
  mixup.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5275--5285. PMLR, 2020.

\bibitem[Krizhevsky \& Hinton(2009)Krizhevsky and
  Hinton]{krizhevsky2009learning}
Krizhevsky, A. and Hinton, G.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, Citeseer, 2009.

\bibitem[Kuleshov et~al.(2018)Kuleshov, Fenner, and
  Ermon]{kuleshov2018accurate}
Kuleshov, V., Fenner, N., and Ermon, S.
\newblock Accurate uncertainties for deep learning using calibrated regression.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2796--2804. PMLR, 2018.

\bibitem[Kumar et~al.(2019)Kumar, Liang, and Ma]{kumar2019verified}
Kumar, A., Liang, P., and Ma, T.
\newblock Verified uncertainty calibration.
\newblock In \emph{Proceedings of the 33rd International Conference on Neural
  Information Processing Systems}, pp.\  3792--3803, 2019.

\bibitem[Lakshminarayanan et~al.(2016)Lakshminarayanan, Pritzel, and
  Blundell]{lakshminarayanan2016simple}
Lakshminarayanan, B., Pritzel, A., and Blundell, C.
\newblock Simple and scalable predictive uncertainty estimation using deep
  ensembles.
\newblock \emph{arXiv preprint arXiv:1612.01474}, 2016.

\bibitem[Naeini et~al.(2015)Naeini, Cooper, and
  Hauskrecht]{naeini2015obtaining}
Naeini, M.~P., Cooper, G., and Hauskrecht, M.
\newblock Obtaining well calibrated probabilities using bayesian binning.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~29, 2015.

\bibitem[Nixon et~al.(2019)Nixon, Dusenberry, Zhang, Jerfel, and
  Tran]{nixon2019measuring}
Nixon, J., Dusenberry, M.~W., Zhang, L., Jerfel, G., and Tran, D.
\newblock Measuring calibration in deep learning.
\newblock In \emph{CVPR Workshops}, volume~2, 2019.

\bibitem[Osband et~al.(2016)Osband, Blundell, Pritzel, and
  Van~Roy]{osband2016deep}
Osband, I., Blundell, C., Pritzel, A., and Van~Roy, B.
\newblock Deep exploration via bootstrapped dqn.
\newblock \emph{arXiv preprint arXiv:1602.04621}, 2016.

\bibitem[Ovadia et~al.(2019)Ovadia, Fertig, Ren, Nado, Sculley, Nowozin,
  Dillon, Lakshminarayanan, and Snoek]{ovadia2019can}
Ovadia, Y., Fertig, E., Ren, J., Nado, Z., Sculley, D., Nowozin, S., Dillon,
  J.~V., Lakshminarayanan, B., and Snoek, J.
\newblock Can you trust your model's uncertainty? evaluating predictive
  uncertainty under dataset shift.
\newblock \emph{arXiv preprint arXiv:1906.02530}, 2019.

\bibitem[Platt et~al.(1999)]{platt1999probabilistic}
Platt, J. et~al.
\newblock Probabilistic outputs for support vector machines and comparisons to
  regularized likelihood methods.
\newblock \emph{Advances in large margin classifiers}, 10\penalty0
  (3):\penalty0 61--74, 1999.

\bibitem[Roady et~al.(2020)Roady, Hayes, and Kanan]{roady2020improved}
Roady, R., Hayes, T.~L., and Kanan, C.
\newblock Improved robustness to open set inputs via tempered mixup.
\newblock In \emph{European Conference on Computer Vision}, pp.\  186--201.
  Springer, 2020.

\bibitem[Schmidt et~al.(2018)Schmidt, Santurkar, Tsipras, Talwar, and
  Madry]{schmidt2018adversarially}
Schmidt, L., Santurkar, S., Tsipras, D., Talwar, K., and Madry, A.
\newblock Adversarially robust generalization requires more data.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Simonyan \& Zisserman(2014)Simonyan and Zisserman]{simonyan2014very}
Simonyan, K. and Zisserman, A.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem[Srivastava et~al.(2015)Srivastava, Greff, and
  Schmidhuber]{srivastava2015highway}
Srivastava, R.~K., Greff, K., and Schmidhuber, J.
\newblock Highway networks.
\newblock \emph{arXiv preprint arXiv:1505.00387}, 2015.

\bibitem[Thulasidasan et~al.(2019)Thulasidasan, Chennupati, Bilmes,
  Bhattacharya, and Michalak]{thulasidasan2019mixup}
Thulasidasan, S., Chennupati, G., Bilmes, J., Bhattacharya, T., and Michalak,
  S.
\newblock On mixup training: Improved calibration and predictive uncertainty
  for deep neural networks.
\newblock \emph{arXiv preprint arXiv:1905.11001}, 2019.

\bibitem[Tomani \& Buettner(2020)Tomani and Buettner]{tomani2020towards}
Tomani, C. and Buettner, F.
\newblock Towards trustworthy predictions from deep neural networks with fast
  adversarial calibration.
\newblock \emph{arXiv preprint arXiv:2012.10923}, 2020.

\bibitem[Verma et~al.(2019)Verma, Lamb, Beckham, Najafi, Mitliagkas, Lopez-Paz,
  and Bengio]{verma2019manifold}
Verma, V., Lamb, A., Beckham, C., Najafi, A., Mitliagkas, I., Lopez-Paz, D.,
  and Bengio, Y.
\newblock Manifold mixup: Better representations by interpolating hidden
  states.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  6438--6447. PMLR, 2019.

\bibitem[Wen et~al.(2020)Wen, Jerfel, Muller, Dusenberry, Snoek,
  Lakshminarayanan, and Tran]{wen2020combining}
Wen, Y., Jerfel, G., Muller, R., Dusenberry, M.~W., Snoek, J.,
  Lakshminarayanan, B., and Tran, D.
\newblock Combining ensembles and data augmentation can harm your calibration.
\newblock \emph{arXiv preprint arXiv:2010.09875}, 2020.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{xiao2017fashion}
Xiao, H., Rasul, K., and Vollgraf, R.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms.
\newblock \emph{arXiv preprint arXiv:1708.07747}, 2017.

\bibitem[Zhang et~al.(2017)Zhang, Cisse, Dauphin, and
  Lopez-Paz]{zhang2017mixup}
Zhang, H., Cisse, M., Dauphin, Y.~N., and Lopez-Paz, D.
\newblock mixup: Beyond empirical risk minimization.
\newblock \emph{arXiv preprint arXiv:1710.09412}, 2017.

\bibitem[Zhang et~al.(2020)Zhang, Deng, Kawaguchi, Ghorbani, and
  Zou]{zhang2020does}
Zhang, L., Deng, Z., Kawaguchi, K., Ghorbani, A., and Zou, J.
\newblock How does mixup help with robustness and generalization?
\newblock \emph{arXiv preprint arXiv:2010.04819}, 2020.

\bibitem[Zhao et~al.(2020)Zhao, Ma, and Ermon]{zhao2020individual}
Zhao, S., Ma, T., and Ermon, S.
\newblock Individual calibration with randomized forecasting.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  11387--11397. PMLR, 2020.

\bibitem[Zhu \& Goldberg(2009)Zhu and Goldberg]{zhu2009introduction}
Zhu, X. and Goldberg, A.~B.
\newblock Introduction to semi-supervised learning.
\newblock \emph{Synthesis lectures on artificial intelligence and machine
  learning}, 3\penalty0 (1):\penalty0 1--130, 2009.

\bibitem[Zhu et~al.(2003)Zhu, Ghahramani, and Lafferty]{zhu2003semi}
Zhu, X., Ghahramani, Z., and Lafferty, J.~D.
\newblock Semi-supervised learning using gaussian fields and harmonic
  functions.
\newblock In \emph{Proceedings of the 20th International conference on Machine
  learning (ICML-03)}, pp.\  912--919, 2003.

\end{thebibliography}
