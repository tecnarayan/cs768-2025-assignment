\begin{thebibliography}{51}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ackley et~al.(1985)Ackley, Hinton, and Sejnowski]{ackley1985learning}
Ackley, D.~H., Hinton, G.~E., and Sejnowski, T.~J.
\newblock A learning algorithm for {B}oltzmann machines.
\newblock \emph{Cognitive science}, 9\penalty0 (1):\penalty0 147--169, 1985.

\bibitem[Andriyash et~al.(2018)Andriyash, Vahdat, and
  Macready]{andriyash2018improved}
Andriyash, E., Vahdat, A., and Macready, W.~G.
\newblock Improved gradient-based optimization over discrete distributions.
\newblock \emph{arXiv preprint arXiv:1810.00116}, 2018.

\bibitem[Bornschein et~al.(2016)Bornschein, Shabanian, Fischer, and
  Bengio]{bornschein2016bidirectional}
Bornschein, J., Shabanian, S., Fischer, A., and Bengio, Y.
\newblock Bidirectional {H}elmholtz machines.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2511--2519, 2016.

\bibitem[Burda et~al.(2015)Burda, Grosse, and
  Salakhutdinov]{burda2015importance}
Burda, Y., Grosse, R., and Salakhutdinov, R.
\newblock Importance weighted autoencoders.
\newblock \emph{arXiv preprint arXiv:1509.00519}, 2015.

\bibitem[Caterini et~al.(2018)Caterini, Doucet, and
  Sejdinovic]{caterini2018hamiltonian}
Caterini, A.~L., Doucet, A., and Sejdinovic, D.
\newblock Hamiltonian variational auto-encoder.
\newblock In \emph{Neural Information Processing Systems}, 2018.

\bibitem[Chen et~al.(2016)Chen, Kingma, Salimans, Duan, Dhariwal, Schulman,
  Sutskever, and Abbeel]{chen2016variational}
Chen, X., Kingma, D.~P., Salimans, T., Duan, Y., Dhariwal, P., Schulman, J.,
  Sutskever, I., and Abbeel, P.
\newblock Variational lossy autoencoder.
\newblock \emph{arXiv preprint arXiv:1611.02731}, 2016.

\bibitem[Chen et~al.(2018)Chen, Mishra, Rohaninejad, and
  Abbeel]{chen2018pixelsnail}
Chen, X., Mishra, N., Rohaninejad, M., and Abbeel, P.
\newblock {P}ixel{SNAIL}: An improved autoregressive generative model.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Dinh et~al.(2014)Dinh, Krueger, and Bengio]{dinh2014nice}
Dinh, L., Krueger, D., and Bengio, Y.
\newblock Nice: Non-linear independent components estimation.
\newblock \emph{arXiv preprint arXiv:1410.8516}, 2014.

\bibitem[Dinh et~al.(2016)Dinh, Sohl-Dickstein, and Bengio]{dinh2016density}
Dinh, L., Sohl-Dickstein, J., and Bengio, S.
\newblock Density estimation using real {NVP}.
\newblock \emph{arXiv preprint arXiv:1605.08803}, 2016.

\bibitem[Grathwohl et~al.(2018)Grathwohl, Choi, Wu, Roeder, and
  Duvenaud]{grathwohl2017backpropagation}
Grathwohl, W., Choi, D., Wu, Y., Roeder, G., and Duvenaud, D.
\newblock Backpropagation through the void: Optimizing control variates for
  black-box gradient estimation.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Graves(2013)]{graves2013generating}
Graves, A.
\newblock Generating sequences with recurrent neural networks.
\newblock \emph{arXiv preprint arXiv:1308.0850}, 2013.

\bibitem[Gregor et~al.(2013)Gregor, Danihelka, Mnih, Blundell, and
  Wierstra]{gregorICML14}
Gregor, K., Danihelka, I., Mnih, A., Blundell, C., and Wierstra, D.
\newblock Deep autoregressive networks.
\newblock \emph{arXiv preprint arXiv:1310.8499}, 2013.

\bibitem[Gregor et~al.(2015)Gregor, Danihelka, Graves, Rezende, and
  Wierstra]{gregor2015draw}
Gregor, K., Danihelka, I., Graves, A., Rezende, D., and Wierstra, D.
\newblock Draw: A recurrent neural network for image generation.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1462--1471, 2015.

\bibitem[Gu et~al.(2015)Gu, Levine, Sutskever, and Mnih]{gu2015muprop}
Gu, S., Levine, S., Sutskever, I., and Mnih, A.
\newblock Mu{P}rop: Unbiased backpropagation for stochastic neural networks.
\newblock \emph{arXiv preprint arXiv:1511.05176}, 2015.

\bibitem[Gulrajani et~al.(2016)Gulrajani, Kumar, Ahmed, Taiga, Visin, Vazquez,
  and Courville]{gulrajani2016pixelvae}
Gulrajani, I., Kumar, K., Ahmed, F., Taiga, A.~A., Visin, F., Vazquez, D., and
  Courville, A.
\newblock Pixel{VAE}: A latent variable model for natural images.
\newblock \emph{arXiv preprint arXiv:1611.05013}, 2016.

\bibitem[Hinton et~al.(1995)Hinton, Dayan, Frey, and Neal]{hinton1995wake}
Hinton, G.~E., Dayan, P., Frey, B.~J., and Neal, R.~M.
\newblock The ``wake-sleep'' algorithm for unsupervised neural networks.
\newblock \emph{Science}, 268\penalty0 (5214):\penalty0 1158, 1995.

\bibitem[Hochreiter \& Schmidhuber(1997)Hochreiter and
  Schmidhuber]{hochreiter1997long}
Hochreiter, S. and Schmidhuber, J.
\newblock Long short-term memory.
\newblock \emph{Neural computation}, 9\penalty0 (8):\penalty0 1735--1780, 1997.

\bibitem[Hoffman(2017)]{hoffman2017learning}
Hoffman, M.~D.
\newblock Learning deep latent {G}aussian models with {M}arkov chain {M}onte
  {C}arlo.
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Jang et~al.(2016)Jang, Gu, and Poole]{jang2016categorical}
Jang, E., Gu, S., and Poole, B.
\newblock Categorical reparameterization with {G}umbel-{S}oftmax.
\newblock \emph{arXiv preprint arXiv:1611.01144}, 2016.

\bibitem[Khoshaman \& Amin(2018)Khoshaman and Amin]{khoshaman2018gumbolt}
Khoshaman, A.~H. and Amin, M.~H.
\newblock {G}um{B}olt: Extending {G}umbel trick to {B}oltzmann priors.
\newblock In \emph{Neural Information Processing Systems}, 2018.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kingma \& Dhariwal(2018)Kingma and Dhariwal]{kingma2018glow}
Kingma, D.~P. and Dhariwal, P.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock In Bengio, S., Wallach, H., Larochelle, H., Grauman, K.,
  Cesa-Bianchi, N., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems 31}, pp.\  10236--10245. 2018.

\bibitem[Kingma \& Welling(2014)Kingma and Welling]{kingma2014vae}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational bayes.
\newblock In \emph{The International Conference on Learning Representations
  (ICLR)}, 2014.

\bibitem[Kingma et~al.(2016)Kingma, Salimans, Jozefowicz, Chen, Sutskever, and
  Welling]{kingma2016improved}
Kingma, D.~P., Salimans, T., Jozefowicz, R., Chen, X., Sutskever, I., and
  Welling, M.
\newblock Improved variational inference with inverse autoregressive flow.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  4743--4751, 2016.

\bibitem[Lake et~al.(2015)Lake, Salakhutdinov, and Tenenbaum]{lake2015human}
Lake, B.~M., Salakhutdinov, R., and Tenenbaum, J.~B.
\newblock Human-level concept learning through probabilistic program induction.
\newblock \emph{Science}, 350\penalty0 (6266):\penalty0 1332--1338, 2015.

\bibitem[Li \& Turner(2016)Li and Turner]{li2016renyi}
Li, Y. and Turner, R.~E.
\newblock R{\'e}nyi divergence variational inference.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1073--1081, 2016.

\bibitem[Li et~al.(2017)Li, Turner, and Liu]{li2017approximate}
Li, Y., Turner, R.~E., and Liu, Q.
\newblock Approximate inference with amortised {MCMC}.
\newblock \emph{arXiv preprint arXiv:1702.08343}, 2017.

\bibitem[Maddison et~al.(2016)Maddison, Mnih, and Teh]{maddison2016concrete}
Maddison, C.~J., Mnih, A., and Teh, Y.~W.
\newblock The concrete distribution: A continuous relaxation of discrete random
  variables.
\newblock \emph{arXiv preprint arXiv:1611.00712}, 2016.

\bibitem[Mnih \& Gregor(2014)Mnih and Gregor]{mnih2014neural}
Mnih, A. and Gregor, K.
\newblock Neural variational inference and learning in belief networks.
\newblock \emph{arXiv preprint arXiv:1402.0030}, 2014.

\bibitem[Mnih \& Rezende(2016)Mnih and Rezende]{mnih2016variational}
Mnih, A. and Rezende, D.
\newblock Variational inference for {M}onte {C}arlo objectives.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2188--2196, 2016.

\bibitem[{QuPA}()]{QuPA}
{QuPA}.
\newblock Quadrant population annealing library.
\newblock \url{https://try.quadrant.ai/qupa}.
\newblock Accessed: 2019-01-01.

\bibitem[Raiko et~al.(2015)Raiko, Berglund, Alain, and
  Dinh]{raiko2014techniques}
Raiko, T., Berglund, M., Alain, G., and Dinh, L.
\newblock Techniques for learning binary stochastic feedforward neural
  networks.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2015.

\bibitem[Rezende \& Mohamed(2015)Rezende and Mohamed]{rezendeICML15}
Rezende, D.~J. and Mohamed, S.
\newblock Variational inference with normalizing flows.
\newblock \emph{arXiv preprint arXiv:1505.05770}, 2015.

\bibitem[Rezende et~al.(2014)Rezende, Mohamed, and
  Wierstra]{rezende2014stochastic}
Rezende, D.~J., Mohamed, S., and Wierstra, D.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1278--1286, 2014.

\bibitem[Roeder et~al.(2017)Roeder, Wu, and Duvenaud]{roeder2017sticking}
Roeder, G., Wu, Y., and Duvenaud, D.~K.
\newblock Sticking the landing: Simple, lower-variance gradient estimators for
  variational inference.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  6925--6934, 2017.

\bibitem[Rolfe(2016)]{rolfe2016discrete}
Rolfe, J.~T.
\newblock Discrete variational autoencoders.
\newblock \emph{arXiv preprint arXiv:1609.02200}, 2016.

\bibitem[Salakhutdinov \& Murray(2008)Salakhutdinov and
  Murray]{salakhutdinov2008dbn}
Salakhutdinov, R. and Murray, I.
\newblock On the quantitative analysis of deep belief networks.
\newblock In \emph{Proceedings of the 25th international conference on Machine
  learning}, pp.\  872--879. ACM, 2008.

\bibitem[Salimans et~al.(2015)Salimans, Kingma, and
  Welling]{salimans2015markov}
Salimans, T., Kingma, D., and Welling, M.
\newblock Markov chain {M}onte {C}arlo and variational inference: Bridging the
  gap.
\newblock In \emph{International Conference on Machine Learning}, 2015.

\bibitem[Salimans et~al.(2017)Salimans, Karpathy, Chen, and
  Kingma]{Salimans2017PixeCNN}
Salimans, T., Karpathy, A., Chen, X., and Kingma, D.~P.
\newblock Pixel{CNN}++: A {P}ixel{CNN} implementation with discretized logistic
  mixture likelihood and other modifications.
\newblock In \emph{ICLR}, 2017.

\bibitem[Sohn et~al.(2015)Sohn, Lee, and Yan]{sohn2015learning}
Sohn, K., Lee, H., and Yan, X.
\newblock Learning structured output representation using deep conditional
  generative models.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2015.

\bibitem[S{\o}nderby et~al.(2016)S{\o}nderby, Raiko, Maal{\o}e, S{\o}nderby,
  and Winther]{sonderby2016ladder}
S{\o}nderby, C.~K., Raiko, T., Maal{\o}e, L., S{\o}nderby, S.~K., and Winther,
  O.
\newblock Ladder variational autoencoders.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  3738--3746, 2016.

\bibitem[Tucker et~al.(2017)Tucker, Mnih, Maddison, Lawson, and
  Sohl-Dickstein]{tucker2017rebar}
Tucker, G., Mnih, A., Maddison, C.~J., Lawson, J., and Sohl-Dickstein, J.
\newblock {REBAR}: Low-variance, unbiased gradient estimates for discrete
  latent variable models.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2624--2633, 2017.

\bibitem[Tucker et~al.(2018)Tucker, Lawson, Gu, and Maddison]{tucker2018doubly}
Tucker, G., Lawson, D., Gu, S., and Maddison, C.~J.
\newblock Doubly reparameterized gradient estimators for {M}onte {C}arlo
  objectives.
\newblock \emph{arXiv preprint arXiv:1810.04152}, 2018.

\bibitem[Vahdat et~al.(2018{\natexlab{a}})Vahdat, Andriyash, and
  Macready]{vahdat2018dvaes}
Vahdat, A., Andriyash, E., and Macready, W.~G.
\newblock {DVAE}\#: Discrete variational autoencoders with relaxed {B}oltzmann
  priors.
\newblock In \emph{Neural Information Processing Systems}, 2018{\natexlab{a}}.

\bibitem[Vahdat et~al.(2018{\natexlab{b}})Vahdat, Macready, Bian, Khoshaman,
  and Andriyash]{Vahdat2018DVAE++}
Vahdat, A., Macready, W.~G., Bian, Z., Khoshaman, A., and Andriyash, E.
\newblock {DVAE}++: Discrete variational autoencoders with overlapping
  transformations.
\newblock In \emph{International Conference on Machine Learning (ICML)},
  2018{\natexlab{b}}.

\bibitem[Van Den~Oord et~al.(2016)Van Den~Oord, Kalchbrenner, and
  Kavukcuoglu]{van2016pixel}
Van Den~Oord, A., Kalchbrenner, N., and Kavukcuoglu, K.
\newblock Pixel recurrent neural networks.
\newblock In \emph{Proceedings of the 33rd International Conference on
  International Conference on Machine Learning}, pp.\  1747--1756. JMLR. org,
  2016.

\bibitem[Welling \& Teh(2011)Welling and Teh]{welling2011bayesian}
Welling, M. and Teh, Y.~W.
\newblock Bayesian learning via stochastic gradient {L}angevin dynamics.
\newblock In \emph{Proceedings of the 28th International Conference on Machine
  Learning (ICML-11)}, pp.\  681--688, 2011.

\bibitem[Welling et~al.(2005)Welling, Rosen-Zvi, and
  Hinton]{welling2005exponential}
Welling, M., Rosen-Zvi, M., and Hinton, G.~E.
\newblock Exponential family harmoniums with an application to information
  retrieval.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1481--1488, 2005.

\bibitem[Williams(1992)]{williams1992simple}
Williams, R.~J.
\newblock Simple statistical gradient-following algorithms for connectionist
  reinforcement learning.
\newblock In \emph{Reinforcement Learning}, pp.\  5--32. Springer, 1992.

\bibitem[Wolf et~al.(2016)Wolf, Karl, and van~der Smagt]{wolf2016variational}
Wolf, C., Karl, M., and van~der Smagt, P.
\newblock Variational inference with hamiltonian monte carlo.
\newblock \emph{arXiv preprint arXiv:1609.08203}, 2016.

\bibitem[Wu et~al.(2017)Wu, Burda, Salakhutdinov, and
  Grosse]{wu2016quantitative}
Wu, Y., Burda, Y., Salakhutdinov, R., and Grosse, R.
\newblock On the quantitative analysis of decoder-based generative models.
\newblock In \emph{The International Conference on Learning Representations
  (ICLR)}, 2017.

\end{thebibliography}
