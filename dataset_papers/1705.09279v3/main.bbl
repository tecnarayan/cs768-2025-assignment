\begin{thebibliography}{10}

\bibitem{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational {B}ayes.
\newblock {\em ICLR}, 2014.

\bibitem{rezende2014stochastic}
Danilo~Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock {\em ICML}, 2014.

\bibitem{dinh2016density}
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
\newblock Density estimation using real nvp.
\newblock {\em arXiv preprint arXiv:1605.08803}, 2016.

\bibitem{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In {\em NIPS}, 2014.

\bibitem{nowozin2016f}
Sebastian Nowozin, Botond Cseke, and Ryota Tomioka.
\newblock f-gan: Training generative neural samplers using variational
  divergence minimization.
\newblock {\em arXiv preprint arXiv:1606.00709}, 2016.

\bibitem{tran2017deep}
Dustin Tran, Rajesh Ranganath, and David~M Blei.
\newblock Deep and hierarchical implicit models.
\newblock {\em arXiv preprint arXiv:1702.08896}, 2017.

\bibitem{mohamed2016learning}
Shakir Mohamed and Balaji Lakshminarayanan.
\newblock Learning in implicit generative models.
\newblock {\em arXiv preprint arXiv:1610.03483}, 2016.

\bibitem{jordan1999introduction}
Michael~I Jordan, Zoubin Ghahramani, Tommi~S Jaakkola, and Lawrence~K Saul.
\newblock An introduction to variational methods for graphical models.
\newblock {\em Machine learning}, 37(2):183--233, 1999.

\bibitem{beal2003variational}
Matthew~J. Beal.
\newblock {\em Variational algorithms for approximate {B}ayesian inference}.
\newblock 2003.

\bibitem{ranganath2014black}
Rajesh Ranganath, Sean Gerrish, and David Blei.
\newblock Black box variational inference.
\newblock In {\em AISTATS}, 2014.

\bibitem{kucukelbir2016automatic}
Alp Kucukelbir, Dustin Tran, Rajesh Ranganath, Andrew Gelman, and David~M Blei.
\newblock Automatic differentiation variational inference.
\newblock {\em arXiv preprint arXiv:1603.00788}, 2016.

\bibitem{burda2015importance}
Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov.
\newblock Importance weighted autoencoders.
\newblock {\em ICLR}, 2016.

\bibitem{mnih2016variational}
Andriy Mnih and Danilo~J Rezende.
\newblock Variational inference for {M}onte {C}arlo objectives.
\newblock {\em arXiv preprint arXiv:1602.06725}, 2016.

\bibitem{cerou2011nonasymptotic}
Fr{\'e}d{\'e}ric C{\'e}rou, Pierre Del~Moral, and Arnaud Guyader.
\newblock A nonasymptotic theorem for unnormalized {F}eynman--{K}ac particle
  models.
\newblock {\em Ann. Inst. H. Poincar{\'e} B}, 47(3):629--649, 2011.

\bibitem{berard2014}
Jean B{\'e}rard, Pierre Del~Moral, and Arnaud Doucet.
\newblock A lognormal central limit theorem for particle approximations of
  normalizing constants.
\newblock {\em Electron. J. Probab.}, 19(94):1--28, 2014.

\bibitem{dempster1977maximum}
Arthur~P Dempster, Nan~M Laird, and Donald~B Rubin.
\newblock Maximum likelihood from incomplete data via the {EM} algorithm.
\newblock {\em J. R. Stat. Soc. Ser. B Stat. Methodol.}, pages 1--38, 1977.

\bibitem{wu1983convergence}
CF~Jeff Wu.
\newblock On the convergence properties of the {EM} algorithm.
\newblock {\em Ann. Stat.}, pages 95--103, 1983.

\bibitem{neal1998view}
Radford~M Neal and Geoffrey~E Hinton.
\newblock A view of the {EM} algorithm that justifies incremental, sparse, and
  other variants.
\newblock In {\em Learning in graphical models}, pages 355--368. Springer,
  1998.

\bibitem{hoffman2013stochastic}
Matthew~D Hoffman, David~M Blei, Chong Wang, and John~William Paisley.
\newblock Stochastic variational inference.
\newblock {\em Journal of Machine Learning Research}, 14(1):1303--1347, 2013.

\bibitem{mnih2014neural}
Andriy Mnih and Karol Gregor.
\newblock Neural variational inference and learning in belief networks.
\newblock {\em arXiv preprint arXiv:1402.0030}, 2014.

\bibitem{gal2016uncertainty}
Yarin Gal.
\newblock {\em Uncertainty in Deep Learning}.
\newblock PhD thesis, University of Cambridge, 2016.

\bibitem{doucet2009tutorial}
Arnaud Doucet and Adam~M. Johansen.
\newblock A tutorial on particle filtering and smoothing: Fifteen years later.
\newblock In D.~Crisan and B.~Rozovsky, editors, {\em The Oxford Handbook of
  Nonlinear Filtering}, pages 656--704. Oxford University Press, 2011.

\bibitem{del2004feynman}
Pierre Del~Moral.
\newblock {\em {F}eynman-{K}ac formulae: genealogical and interacting particle
  systems with applications}.
\newblock Springer Verlag, 2004.

\bibitem{del2013mean}
Pierre Del~Moral.
\newblock {\em Mean field simulation for {M}onte {C}arlo integration}.
\newblock CRC Press, 2013.

\bibitem{andrieu2010particle}
Christophe Andrieu, Arnaud Doucet, and Roman Holenstein.
\newblock Particle {M}arkov chain {M}onte {C}arlo methods.
\newblock {\em J. R. Stat. Soc. Ser. B Stat. Methodol.}, 72(3):269--342, 2010.

\bibitem{pitt2012some}
Michael~K Pitt, Ralph dos Santos~Silva, Paolo Giordani, and Robert Kohn.
\newblock On some properties of {M}arkov chain {M}onte {C}arlo simulation
  methods based on the particle filter.
\newblock {\em J. Econometrics}, 171(2):134--151, 2012.

\bibitem{wainwright2008graphical}
Martin~J Wainwright, Michael~I Jordan, et~al.
\newblock Graphical models, exponential families, and variational inference.
\newblock {\em Foundations and Trends in Machine Learning}, 1(1--2):1--305,
  2008.

\bibitem{grosse2015sandwiching}
Roger~B Grosse, Zoubin Ghahramani, and Ryan~P Adams.
\newblock Sandwiching the marginal likelihood using bidirectional {M}onte
  {C}arlo.
\newblock {\em arXiv preprint arXiv:1511.02543}, 2015.

\bibitem{burda2015accurate}
Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov.
\newblock Accurate and conservative estimates of {MRF} log-likelihood using
  reverse annealing.
\newblock In {\em AISTATS}, 2015.

\bibitem{ranganath2016operator}
Rajesh Ranganath, Dustin Tran, Jaan Altosaar, and David Blei.
\newblock Operator variational inference.
\newblock In {\em NIPS}, 2016.

\bibitem{rezende2015variational}
Danilo~Jimenez Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock {\em ICML}, 2015.

\bibitem{kingma2016improved}
Diederik~P Kingma, Tim Salimans, Rafal Jozefowicz, Xi~Chen, Ilya Sutskever, and
  Max Welling.
\newblock Improved variational inference with inverse autoregressive flow.
\newblock In {\em NIPS}, 2016.

\bibitem{salimans2015markov}
Tim Salimans, Diederik Kingma, and Max Welling.
\newblock Markov chain {M}onte {C}arlo and variational inference: Bridging the
  gap.
\newblock In {\em ICML}, 2015.

\bibitem{bornschein2014reweighted}
J{\"o}rg Bornschein and Yoshua Bengio.
\newblock Reweighted wake-sleep.
\newblock {\em ICLR}, 2015.

\bibitem{gu2015neural}
Shixiang Gu, Zoubin Ghahramani, and Richard~E Turner.
\newblock Neural adaptive sequential {M}onte {C}arlo.
\newblock In {\em NIPS}, 2015.

\bibitem{bengio2013generalized}
Yoshua Bengio, Li~Yao, Guillaume Alain, and Pascal Vincent.
\newblock Generalized denoising auto-encoders as generative models.
\newblock In {\em NIPS}, 2013.

\bibitem{naesseth2017variational}
Christian~A Naesseth, Scott~W Linderman, Rajesh Ranganath, and David~M Blei.
\newblock Variational sequential {M}onte {C}arlo.
\newblock {\em arXiv preprint arXiv:1705.11140}, 2017.

\bibitem{le2017auto}
Tuan~Anh Le, Maximilian Igl, Tom Jin, Tom Rainforth, and Frank Wood.
\newblock Auto-encoding sequential {M}onte {C}arlo.
\newblock {\em arXiv preprint arXiv:1705.10306}, 2017.

\bibitem{chung2015recurrent}
Junyoung Chung, Kyle Kastner, Laurent Dinh, Kratarth Goel, Aaron~C Courville,
  and Yoshua Bengio.
\newblock A recurrent latent variable model for sequential data.
\newblock In {\em NIPS}, 2015.

\bibitem{abadi2016tensorflow}
Mart{\'\i}n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen,
  Craig Citro, Greg~S Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, et~al.
\newblock Tensorflow: Large-scale machine learning on heterogeneous distributed
  systems.
\newblock {\em arXiv preprint arXiv:1603.04467}, 2016.

\bibitem{fraccaro2016sequential}
Marco Fraccaro, S{\o}ren~Kaae S{\o}nderby, Ulrich Paquet, and Ole Winther.
\newblock Sequential neural models with stochastic layers.
\newblock In {\em NIPS}, 2016.

\bibitem{boulanger2012modeling}
Nicolas Boulanger-Lewandowski, Yoshua Bengio, and Pascal Vincent.
\newblock Modeling temporal dependencies in high-dimensional sequences:
  Application to polyphonic music generation and transcription.
\newblock {\em ICML}, 2012.

\bibitem{bowman2015generating}
Samuel~R Bowman, Luke Vilnis, Oriol Vinyals, Andrew~M Dai, Rafal Jozefowicz,
  and Samy Bengio.
\newblock Generating sentences from a continuous space.
\newblock {\em arXiv preprint arXiv:1511.06349}, 2015.

\bibitem{veach1995optimally}
Eric Veach and Leonidas~J Guibas.
\newblock Optimally combining sampling techniques for {M}onte {C}arlo
  rendering.
\newblock In {\em Proceedings of the 22nd annual conference on Computer
  graphics and interactive techniques}, pages 419--428. ACM, 1995.

\bibitem{chib1995marginal}
Siddhartha Chib.
\newblock Marginal likelihood from the {G}ibbs output.
\newblock {\em Journal of the American Statistical Association},
  90(432):1313--1321, 1995.

\bibitem{meng1996simulating}
Xiao-Li Meng and Wing~Hung Wong.
\newblock Simulating ratios of normalizing constants via a simple identity: a
  theoretical exploration.
\newblock {\em Statistica Sinica}, pages 831--860, 1996.

\bibitem{gelman1998simulating}
Andrew Gelman and Xiao-Li Meng.
\newblock Simulating normalizing constants: From importance sampling to bridge
  sampling to path sampling.
\newblock {\em Statistical science}, pages 163--185, 1998.

\bibitem{neal2001annealed}
Radford~M Neal.
\newblock Annealed importance sampling.
\newblock {\em Statistics and computing}, 11(2):125--139, 2001.

\bibitem{neal2005linked}
Radford~M Neal.
\newblock Estimating ratios of normalizing constants using linked importance
  sampling.
\newblock {\em arXiv preprint math/0511216}, 2005.

\bibitem{skilling2006nested}
John Skilling.
\newblock Nested sampling for general {B}ayesian computation.
\newblock {\em Bayesian analysis}, 1(4):833--859, 2006.

\bibitem{elvira2015generalized}
V{\'\i}ctor Elvira, Luca Martino, David Luengo, and M{\'o}nica~F Bugallo.
\newblock Generalized multiple importance sampling.
\newblock {\em arXiv preprint arXiv:1511.03095}, 2015.

\bibitem{DelMoral2006}
Pierre Del~Moral, Arnaud Doucet, and Ajay Jasra.
\newblock Sequential {M}onte {C}arlo samplers.
\newblock {\em J. R. Stat. Soc. Ser. B Stat. Methodol.}, 68(3):411--436, 2006.

\bibitem{glorot2010understanding}
Xavier Glorot and Yoshua Bengio.
\newblock Understanding the difficulty of training deep feedforward neural
  networks.
\newblock In {\em AISTATS}, 2010.

\bibitem{kingma2014adam}
Diederik Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em ICLR}, 2015.

\end{thebibliography}
