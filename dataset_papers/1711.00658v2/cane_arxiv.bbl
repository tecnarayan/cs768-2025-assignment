\begin{thebibliography}{10}

\bibitem{russakovsky2015imagenet}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander
  C.~Berg, and Li~Fei-Fei.
\newblock Imagenet large scale visual recognition challenge.
\newblock {\em International Journal of Computer Vision (IJCV)},
  115(3):211--252, 2015.

\bibitem{mikolov2010recurrent}
Tom{\'a}{\v{s}} Mikolov, Martin Karafi{\'a}t, Luk{\'a}{\v{s}} Burget, Jan
  {\v{C}}ernock{\`y}, and Sanjeev Khudanpur.
\newblock Recurrent neural network based language model.
\newblock In {\em Eleventh Annual Conference of the International Speech
  Communication Association}, 2010.

\bibitem{gutmann2010noise}
Michael~U Gutmann and Aapo Hyv{\"a}rinen.
\newblock Noise-contrastive estimation of unnormalized statistical models, with
  applications to natural image statistics.
\newblock {\em Journal of Machine Learning Research (JMLR)}, 13(Feb):307--361,
  2012.

\bibitem{mnih2012fast}
Andriy Mnih and Yee~W Teh.
\newblock A fast and simple algorithm for training neural probabilistic
  language models.
\newblock In {\em Proceedings of the 29th International Conference on Machine
  Learning (ICML)}, pages 1751--1758, 2012.

\bibitem{mnih2013learning}
Andriy Mnih and Koray Kavukcuoglu.
\newblock Learning word embeddings efficiently with noise-contrastive
  estimation.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS)},
  pages 2265--2273, 2013.

\bibitem{vaswani2013decoding}
Ashish Vaswani, Yinggong Zhao, Victoria Fossum, and David Chiang.
\newblock Decoding with large-scale neural language models improves
  translation.
\newblock In {\em The Conference on Empirical Methods on Natural Language
  Processing (EMNLP)}, pages 1387--1392, 2013.

\bibitem{sordoni2015neural}
Alessandro Sordoni, Michel Galley, Michael Auli, Chris Brockett, Yangfeng Ji,
  Margaret Mitchell, Jian-Yun Nie, Jianfeng Gao, and Bill Dolan.
\newblock A neural network approach to context-sensitive generation of
  conversational responses.
\newblock {\em arXiv preprint arXiv:1506.06714}, 2015.

\bibitem{mikolov2013distributed}
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg~S Corrado, and Jeff Dean.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS)},
  pages 3111--3119, 2013.

\bibitem{ji2015blackout}
Shihao Ji, SVN Vishwanathan, Nadathur Satish, Michael~J Anderson, and Pradeep
  Dubey.
\newblock Blackout: Speeding up recurrent neural network language models with
  very large vocabularies.
\newblock {\em arXiv preprint arXiv:1511.06909}, 2015.

\bibitem{Titsias2016one}
Michalis~K. Titsias.
\newblock One-vs-each approximation to softmax for scalable estimation of
  probabilities.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS)},
  pages 4161--4169, 2016.

\bibitem{botev2017complementary}
Aleksandar Botev, Bowen Zheng, and David Barber.
\newblock Complementary sum sampling for likelihood approximation in large
  scale classification.
\newblock In {\em Artificial Intelligence and Statistics (AISTATS)}, pages
  1030--1038, 2017.

\bibitem{beygelzimer2009error}
Alina Beygelzimer, John Langford, and Pradeep Ravikumar.
\newblock Error-correcting tournaments.
\newblock In {\em International Conference on Algorithmic Learning Theory
  (ALT)}, pages 247--262, 2009.

\bibitem{bengio2010label}
Samy Bengio, Jason Weston, and David Grangier.
\newblock Label embedding trees for large multi-class tasks.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS)},
  pages 163--171, 2010.

\bibitem{deng2011fast}
Jia Deng, Sanjeev Satheesh, Alexander~C Berg, and Fei Li.
\newblock Fast and balanced: Efficient label tree learning for large scale
  object recognition.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS)},
  pages 567--575, 2011.

\bibitem{choromanska2015logarithmic}
Anna~E Choromanska and John Langford.
\newblock Logarithmic time online multiclass prediction.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS)},
  pages 55--63, 2015.

\bibitem{daume2016logarithmic}
Hal Daume~III, Nikos Karampatziakis, John Langford, and Paul Mineiro.
\newblock Logarithmic time one-against-some.
\newblock In {\em International Conference on Machine Learning (ICML)}, pages
  923--932, 2017.

\bibitem{jernite2016simultaneous}
Yacine Jernite, Anna Choromanska, and David Sontag.
\newblock Simultaneous learning of trees and representations for extreme
  classification and density estimation.
\newblock In {\em International Conference on Machine Learning (ICML)}, pages
  1665--1674, 2017.

\bibitem{mnih2009scalable}
Andriy Mnih and Geoffrey~E Hinton.
\newblock A scalable hierarchical distributed language model.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS)},
  pages 1081--1088, 2009.

\bibitem{morin2005hierarchical}
Frederic Morin and Yoshua Bengio.
\newblock Hierarchical probabilistic neural network language model.
\newblock In {\em The International Conference on Artificial Intelligence and
  Statistics (AISTATS)}, volume~5, pages 246--252, 2005.

\bibitem{hochreiter1997long}
Sepp Hochreiter and J{\"u}rgen Schmidhuber.
\newblock Long short-term memory.
\newblock {\em Neural Computation}, 9(8):1735--1780, 1997.

\bibitem{chang2011libsvm}
Chih-Chung Chang and Chih-Jen Lin.
\newblock Libsvm: a library for support vector machines.
\newblock {\em ACM Transactions on Intelligent Systems and Technology (TIST)},
  2(3):27, 2011.

\bibitem{geusebroek2005amsterdam}
Jan-Mark Geusebroek, Gertjan~J Burghouts, and Arnold~WM Smeulders.
\newblock The amsterdam library of object images.
\newblock {\em International Journal of Computer Vision (IJCV)},
  61(1):103--112, 2005.

\bibitem{deng2010does}
Jia Deng, Alexander~C Berg, Kai Li, and Li~Fei-Fei.
\newblock What does classifying more than 10,000 image categories tell us?
\newblock In {\em European Conference on Computer Vision (ECCV)}, pages 71--84,
  2010.

\bibitem{sanchez2011high}
Jorge S{\'a}nchez and Florent Perronnin.
\newblock High-dimensional signature compression for large-scale image
  classification.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pages 1665--1672, 2011.

\bibitem{le2013building}
Quoc~V Le.
\newblock Building high-level features using large scale unsupervised learning.
\newblock In {\em IEEE International Conference on Acoustics, Speech and Signal
  Processing (ICASSP)}, pages 8595--8598, 2013.

\bibitem{oquab2014learning}
Maxime Oquab, Leon Bottou, Ivan Laptev, and Josef Sivic.
\newblock Learning and transferring mid-level image representations using
  convolutional neural networks.
\newblock In {\em Proceedings of The IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 1717--1724, 2014.

\bibitem{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock {\em arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{mensink2013distance}
Thomas Mensink, Jakob Verbeek, Florent Perronnin, and Gabriela Csurka.
\newblock Distance-based image classification: Generalizing to new classes at
  near-zero cost.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence
  (PAMI)}, 35(11):2624--2637, 2013.

\bibitem{huang2016local}
Chen Huang, Chen~Change Loy, and Xiaoou Tang.
\newblock Local similarity-aware deep feature embedding.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1262--1270, 2016.

\end{thebibliography}
