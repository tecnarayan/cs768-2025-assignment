\begin{thebibliography}{10}

\bibitem{Kingma2014}
Diederik~P. Kingma and Max Welling.
\newblock {Auto-Encoding Variational Bayes}.
\newblock In {\em 2nd International Conference on Learning Representations,
  {ICLR} 2014}, 2014.

\bibitem{10.5555/2969033.2969125}
Ian~J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David
  Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In {\em Proceedings of the 27th International Conference on Neural
  Information Processing Systems - Volume 2}, NIPS'14, page 2672–2680, 2014.

\bibitem{makhzani2016adversarial}
Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, and Brendan
  Frey.
\newblock Adversarial autoencoders, 2016.

\bibitem{mescheder2018adversarial}
Lars Mescheder, Sebastian Nowozin, and Andreas Geiger.
\newblock Adversarial variational bayes: Unifying variational autoencoders and
  generative adversarial networks, 2018.

\bibitem{pmlr-v70-arjovsky17a}
Martin Arjovsky, Soumith Chintala, and L{\'e}on Bottou.
\newblock {W}asserstein generative adversarial networks.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning}, volume~70 of {\em Proceedings of Machine Learning Research}, pages
  214--223. PMLR, 2017.

\bibitem{tolstikhin2019wasserstein}
Ilya Tolstikhin, Olivier Bousquet, Sylvain Gelly, and Bernhard Schoelkopf.
\newblock Wasserstein auto-encoders.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{NEURIPS2019_eae27d77}
Hisham Husain, Richard Nock, and Robert~C Williamson.
\newblock A primal-dual link between gans and autoencoders.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~32, 2019.

\bibitem{pmlr-v70-arora17a}
Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi~Zhang.
\newblock Generalization and equilibrium in generative adversarial nets
  ({GAN}s).
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning}, volume~70 of {\em Proceedings of Machine Learning Research}, pages
  224--232. PMLR, 06--11 Aug 2017.

\bibitem{10.1214/19-AOS1858}
Gérard Biau, Benoît Cadre, Maxime Sangnier, and Ugo Tanielian.
\newblock {Some theoretical properties of GANS}.
\newblock {\em The Annals of Statistics}, 48:1539 -- 1566, 2020.

\bibitem{NIPS2016_cedebb6e}
Sebastian Nowozin, Botond Cseke, and Ryota Tomioka.
\newblock f-gan: Training generative neural samplers using variational
  divergence minimization.
\newblock In D.~Lee, M.~Sugiyama, U.~Luxburg, I.~Guyon, and R.~Garnett,
  editors, {\em Advances in Neural Information Processing Systems}, volume~29.
  Curran Associates, Inc., 2016.

\bibitem{li2017mmd}
Chun-Liang Li, Wei-Cheng Chang, Yu~Cheng, Yiming Yang, and Barnabás Póczos.
\newblock Mmd gan: Towards deeper understanding of moment matching network,
  2017.

\bibitem{mroueh2017sobolev}
Youssef Mroueh, Chun-Liang Li, Tom Sercu, Anant Raj, and Yu~Cheng.
\newblock Sobolev gan, 2017.

\bibitem{liang2018generative}
Tengyuan Liang.
\newblock How well generative adversarial networks learn distributions, 2020.

\bibitem{chen2020statistical}
Minshuo Chen, Wenjing Liao, Hongyuan Zha, and Tuo Zhao.
\newblock Statistical guarantees of generative adversarial networks for
  distribution estimation, 2020.

\bibitem{liu2017approximation}
Shuang Liu, Olivier Bousquet, and Kamalika Chaudhuri.
\newblock Approximation and convergence properties of generative adversarial
  learning, 2017.

\bibitem{biau2020theoretical}
Gérard Biau, Maxime Sangnier, and Ugo Tanielian.
\newblock Some theoretical insights into wasserstein gans, 2020.

\bibitem{hu2018unifying}
Zhiting Hu, Zichao Yang, Ruslan Salakhutdinov, and Eric~P. Xing.
\newblock On unifying deep generative models, 2018.

\bibitem{weed2017sharp}
Jonathan Weed and Francis Bach.
\newblock Sharp asymptotic and finite-sample rates of convergence of empirical
  measures in wasserstein distance, 2017.

\bibitem{Lei_2020}
Jing Lei.
\newblock Convergence and concentration of empirical measures under wasserstein
  distance in unbounded functional spaces.
\newblock {\em Bernoulli}, 26(1), Feb 2020.

\bibitem{singh2019minimax}
Shashank Singh and Barnabás Póczos.
\newblock Minimax distribution estimation in wasserstein distance, 2019.

\bibitem{10.5555/3327546.3327686}
Shashank Singh, Ananya Uppal, Boyue Li, Chun-Liang Li, Manzil Zaheer, and
  Barnab\'{a}s P\'{o}czos.
\newblock Nonparametric density estimation with adversarial losses.
\newblock In {\em Proceedings of the 32nd International Conference on Neural
  Information Processing Systems}, NIPS'18, page 10246–10257, 2018.

\bibitem{ijcai2020-375}
Luis~A. Perez~Rey, Vlado Menkovski, and Jim Portegies.
\newblock Diffusion variational autoencoders.
\newblock In {\em Proceedings of the Twenty-Ninth International Joint
  Conference on Artificial Intelligence, {IJCAI-20}}, pages 2704--2710.
  International Joint Conferences on Artificial Intelligence Organization, 7
  2020.

\bibitem{10.2307/2241209}
Yannis~G. Yatracos.
\newblock Rates of convergence of minimum distance estimators and kolmogorov's
  entropy.
\newblock {\em The Annals of Statistics}, 13(2):768--774, 1985.

\bibitem{Devroye2001CombinatorialMI}
L.~Devroye and G.~Lugosi.
\newblock Combinatorial methods in density estimation.
\newblock In {\em Springer series in statistics}, 2001.

\bibitem{10.2307/1428011}
Alfred Müller.
\newblock Integral probability metrics and their generating classes of
  functions.
\newblock {\em Advances in Applied Probability}, 29(2):429--443, 1997.

\bibitem{OptimalTransport}
Villani Cédric.
\newblock {\em Optimal transport : old and new}.
\newblock Grundlehren der mathematischen Wissenschaften. Springer, 2009.

\bibitem{peyre2020computational}
Gabriel Peyré and Marco Cuturi.
\newblock Computational optimal transport, 2020.

\bibitem{sriperumbudur2009integral}
Bharath~K. Sriperumbudur, Kenji Fukumizu, Arthur Gretton, Bernhard Schölkopf,
  and Gert R.~G. Lanckriet.
\newblock On integral probability metrics, $\phi$-divergences and binary
  classification, 2009.

\bibitem{Sason_2016}
Igal Sason and Sergio Verdu.
\newblock $f$ -divergence inequalities.
\newblock {\em IEEE Transactions on Information Theory}, 62(11):5973–6006,
  Nov 2016.

\bibitem{10.5555/993483}
Stephen Boyd and Lieven Vandenberghe.
\newblock {\em Convex Optimization}.
\newblock Cambridge University Press, USA, 2004.

\bibitem{ashtiani2018techniques}
Hassan Ashtiani and Abbas Mehrabian.
\newblock Some techniques in density estimation, 2018.

\bibitem{alma991004453279705596}
Villani Cédric.
\newblock {\em Topics in optimal transportation}.
\newblock Graduate studies in mathematics. American mathematical society, C
  2003.

\bibitem{Caffarelli1992TheRO}
L.~Caffarelli.
\newblock The regularity of mappings with a convex potential.
\newblock {\em Journal of the American Mathematical Society}, 5:99--104, 1992.

\bibitem{NEURIPS2019_fd95ec8d}
Minshuo Chen, Haoming Jiang, Wenjing Liao, and Tuo Zhao.
\newblock Efficient approximation of deep relu networks for functions on low
  dimensional manifolds.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~32, 2019.

\bibitem{YAROTSKY2017103}
Dmitry Yarotsky.
\newblock Error bounds for approximations with deep relu networks.
\newblock {\em Neural Networks}, 94:103--114, 2017.

\bibitem{10.1214/aoms/1177697802}
R.~M. Dudley.
\newblock {The Speed of Mean Glivenko-Cantelli Convergence}.
\newblock {\em The Annals of Mathematical Statistics}, 40(1):40 -- 50, 1969.

\bibitem{10.5555/2188385.2188410}
Arthur Gretton, Karsten~M. Borgwardt, Malte~J. Rasch, Bernhard Sch\"{o}lkopf,
  and Alexander Smola.
\newblock A kernel two-sample test.
\newblock {\em Journal of Machine Learning Research}, 13:723–773, 2012.

\bibitem{noauthororeditor}
Ramon Van~Handel.
\newblock Probability in high dimensions.
\newblock Technical report, 2016.

\end{thebibliography}
