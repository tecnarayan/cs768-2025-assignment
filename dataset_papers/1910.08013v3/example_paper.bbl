\begin{thebibliography}{17}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agrawal et~al.(2020)Agrawal, Papamarkou, and Hinkle]{agrawal2020wide}
Agrawal, D., Papamarkou, T., and Hinkle, J.
\newblock Wide neural networks with bottlenecks are deep gaussian processes.
\newblock \emph{arXiv preprint arXiv:2001.00921}, 2020.

\bibitem[Arora et~al.(2019)Arora, Du, Hu, Li, Salakhutdinov, and
  Wang]{arora2019exact}
Arora, S., Du, S.~S., Hu, W., Li, Z., Salakhutdinov, R., and Wang, R.
\newblock On exact computation with an infinitely wide neural net.
\newblock \emph{arXiv preprint arXiv:1904.11955}, 2019.

\bibitem[Bui et~al.(2016)Bui, Hern{\'a}ndez-Lobato, Hernandez-Lobato, Li, and
  Turner]{bui2016deep}
Bui, T., Hern{\'a}ndez-Lobato, D., Hernandez-Lobato, J., Li, Y., and Turner, R.
\newblock Deep gaussian processes for regression using approximate expectation
  propagation.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1472--1481, 2016.

\bibitem[Chen et~al.(2018)Chen, Rubanova, Bettencourt, and
  Duvenaud]{chen2018neural}
Chen, T.~Q., Rubanova, Y., Bettencourt, J., and Duvenaud, D.~K.
\newblock Neural ordinary differential equations.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  6571--6583, 2018.

\bibitem[Cho \& Saul(2009)Cho and Saul]{cho2009kernel}
Cho, Y. and Saul, L.~K.
\newblock Kernel methods for deep learning.
\newblock \emph{NeurIPS}, 2009.

\bibitem[Garriga-Alonso et~al.(2019)Garriga-Alonso, Rasmussen, and
  Aitchison]{garriga2019deep}
Garriga-Alonso, A., Rasmussen, C.~E., and Aitchison, L.
\newblock Deep convolutional networks as shallow {G}aussian processes.
\newblock \emph{{ICLR}}, 2019.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016identity}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Identity mappings in deep residual networks.
\newblock In \emph{European conference on computer vision}, pp.\  630--645.
  Springer, 2016.

\bibitem[Huh et~al.(2016)Huh, Agrawal, and Efros]{huh2016makes}
Huh, M., Agrawal, P., and Efros, A.~A.
\newblock What makes imagenet good for transfer learning?
\newblock \emph{arXiv preprint arXiv:1608.08614}, 2016.

\bibitem[Lee et~al.(2018)Lee, Bahri, Novak, Schoenholz, Pennington, and
  Sohl-Dickstein]{lee2018deep}
Lee, J., Bahri, Y., Novak, R., Schoenholz, S.~S., Pennington, J., and
  Sohl-Dickstein, J.
\newblock Deep neural networks as {G}aussian processes.
\newblock \emph{{ICLR}}, 2018.

\bibitem[Li et~al.(2019)Li, Wang, Yu, Du, Hu, Salakhutdinov, and
  Arora]{li2019enhanced}
Li, Z., Wang, R., Yu, D., Du, S.~S., Hu, W., Salakhutdinov, R., and Arora, S.
\newblock Enhanced convolutional neural tangent kernels.
\newblock \emph{arXiv preprint arXiv:1911.00809}, 2019.

\bibitem[Matthews et~al.(2018)Matthews, Rowland, Hron, Turner, and
  Ghahramani]{matthews2018gaussian}
Matthews, A., Rowland, M., Hron, J., Turner, R., and Ghahramani, Z.
\newblock Gaussian process behaviour in wide deep neural networks.
\newblock \emph{{ICLR}}, 2018.

\bibitem[Novak et~al.(2019)Novak, Xiao, Bahri, Lee, Yang, Hron, Abolafia,
  Pennington, and Sohl-Dickstein]{novak2019bayesian}
Novak, R., Xiao, L., Bahri, Y., Lee, J., Yang, G., Hron, J., Abolafia, D.~A.,
  Pennington, J., and Sohl-Dickstein, J.
\newblock Bayesian deep convolutional networks with many channels are
  {G}aussian processes.
\newblock \emph{{ICLR}}, 2019.

\bibitem[Ramsey(1926)]{ramsey2016truth}
Ramsey, F.~P.
\newblock Truth and probability.
\newblock In \emph{Readings in Formal Epistemology}, pp.\  21--45. Springer,
  1926.

\bibitem[Rasmussen \& Williams(2006)Rasmussen and
  Williams]{williams2006gaussian}
Rasmussen, C.~E. and Williams, C.~K.
\newblock \emph{Gaussian processes for machine learning}.
\newblock MIT press, 2006.

\bibitem[Saxe et~al.(2013)Saxe, McClelland, and Ganguli]{saxe2013exact}
Saxe, A.~M., McClelland, J.~L., and Ganguli, S.
\newblock Exact solutions to the nonlinear dynamics of learning in deep linear
  neural networks.
\newblock \emph{arXiv preprint arXiv:1312.6120}, 2013.

\bibitem[Van~der Schaaf \& van Hateren(1996)Van~der Schaaf and van
  Hateren]{van1996modelling}
Van~der Schaaf, v.~A. and van Hateren, J.~v.
\newblock Modelling the power spectra of natural images: statistics and
  information.
\newblock \emph{Vision research}, 36\penalty0 (17):\penalty0 2759--2770, 1996.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and
  Komodakis]{zagoruyko2016wide}
Zagoruyko, S. and Komodakis, N.
\newblock Wide residual networks.
\newblock \emph{arXiv preprint arXiv:1605.07146}, 2016.

\end{thebibliography}
