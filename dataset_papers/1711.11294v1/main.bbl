\begin{thebibliography}{19}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bengio et~al.(2013)Bengio, L{\'e}onard, and
  Courville]{bengio2013estimating}
Y.~Bengio, N.~L{\'e}onard, and A.~Courville.
\newblock Estimating or propagating gradients through stochastic neurons for
  conditional computation.
\newblock \emph{arXiv preprint arXiv:1308.3432}, 2013.

\bibitem[Cai et~al.(2017)Cai, He, Sun, and Vasconcelos]{cai2017deep}
Z.~Cai, X.~He, J.~Sun, and N.~Vasconcelos.
\newblock Deep learning with low precision by half-wave gaussian quantization.
\newblock \emph{arXiv preprint arXiv:1702.00953}, 2017.

\bibitem[Courbariaux et~al.(2016)Courbariaux, Hubara, Soudry, El-Yaniv, and
  Bengio]{courbariaux2016binarized}
M.~Courbariaux, I.~Hubara, D.~Soudry, R.~El-Yaniv, and Y.~Bengio.
\newblock Binarized neural networks: Training deep neural networks with weights
  and activations constrained to+ 1 or-1.
\newblock \emph{arXiv preprint arXiv:1602.02830}, 2016.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
J.~Deng, W.~Dong, R.~Socher, L.-J. Li, K.~Li, and L.~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{Computer Vision and Pattern Recognition, 2009. CVPR 2009.
  IEEE Conference on}, pages 248--255. IEEE, 2009.

\bibitem[Esser et~al.(2016)Esser, Merolla, Arthur, Cassidy, Appuswamy,
  Andreopoulos, Berg, McKinstry, Melano, Barch, et~al.]{esser2016convolutional}
S.~K. Esser, P.~A. Merolla, J.~V. Arthur, A.~S. Cassidy, R.~Appuswamy,
  A.~Andreopoulos, D.~J. Berg, J.~L. McKinstry, T.~Melano, D.~R. Barch, et~al.
\newblock Convolutional networks for fast, energy-efficient neuromorphic
  computing.
\newblock \emph{Proceedings of the National Academy of Sciences}, page
  201604850, 2016.

\bibitem[Giusti et~al.(2016)Giusti, Guzzi, Ciresan, He, Rodriguez, Fontana,
  Faessler, Forster, Schmidhuber, Di~Caro, Scaramuzza, and
  Gambardella]{giusti2016machine}
A.~Giusti, J.~Guzzi, D.~Ciresan, F.-L. He, J.~P. Rodriguez, F.~Fontana,
  M.~Faessler, C.~Forster, J.~Schmidhuber, G.~Di~Caro, D.~Scaramuzza, and
  L.~Gambardella.
\newblock A machine learning approach to visual perception of forest trails for
  mobile robots.
\newblock \emph{IEEE Robotics and Automation Letters}, 2016.

\bibitem[Govindu et~al.(2004)Govindu, Zhuo, Choi, and
  Prasanna]{govindu2004analysis}
G.~Govindu, L.~Zhuo, S.~Choi, and V.~Prasanna.
\newblock Analysis of high-performance floating-point arithmetic on fpgas.
\newblock In \emph{Parallel and Distributed Processing Symposium, 2004.
  Proceedings. 18th International}, page 149. IEEE, 2004.

\bibitem[Grabbe et~al.(2003)Grabbe, Bednara, Teich, von~zur Gathen, and
  Shokrollahi]{grabbe2003fpga}
C.~Grabbe, M.~Bednara, J.~Teich, J.~von~zur Gathen, and J.~Shokrollahi.
\newblock Fpga designs of parallel high performance gf (2233) multipliers.
\newblock In \emph{ISCAS (2)}, pages 268--271. Citeseer, 2003.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 770--778, 2016.

\bibitem[Hubara et~al.(2016)Hubara, Courbariaux, Soudry, El-Yaniv, and
  Bengio]{hubara2016quantized}
I.~Hubara, M.~Courbariaux, D.~Soudry, R.~El-Yaniv, and Y.~Bengio.
\newblock Quantized neural networks: Training neural networks with low
  precision weights and activations.
\newblock \emph{arXiv preprint arXiv:1609.07061}, 2016.

\bibitem[Ioffe and Szegedy(2015)]{ioffe2015batch}
S.~Ioffe and C.~Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock \emph{arXiv preprint arXiv:1502.03167}, 2015.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
D.~Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Liu et~al.(2016)Liu, Du, Tao, Han, Luo, Xie, Chen, and
  Chen]{liu2016cambricon}
S.~Liu, Z.~Du, J.~Tao, D.~Han, T.~Luo, Y.~Xie, Y.~Chen, and T.~Chen.
\newblock Cambricon: An instruction set architecture for neural networks.
\newblock In \emph{Proceedings of the 43rd International Symposium on Computer
  Architecture}, pages 393--405. IEEE Press, 2016.

\bibitem[Qian(1999)]{qian1999momentum}
N.~Qian.
\newblock On the momentum term in gradient descent learning algorithms.
\newblock \emph{Neural networks}, 12\penalty0 (1):\penalty0 145--151, 1999.

\bibitem[Rastegari et~al.(2016)Rastegari, Ordonez, Redmon, and
  Farhadi]{rastegari2016xnor}
M.~Rastegari, V.~Ordonez, J.~Redmon, and A.~Farhadi.
\newblock Xnor-net: Imagenet classification using binary convolutional neural
  networks.
\newblock In \emph{European Conference on Computer Vision}, pages 525--542.
  Springer, 2016.

\bibitem[Ren et~al.(2015)Ren, He, Girshick, and Sun]{ren2015faster}
S.~Ren, K.~He, R.~Girshick, and J.~Sun.
\newblock Faster r-cnn: Towards real-time object detection with region proposal
  networks.
\newblock In \emph{Advances in neural information processing systems}, pages
  91--99, 2015.

\bibitem[Toms(1990)]{toms1990training}
D.~Toms.
\newblock Training binary node feedforward neural networks by back propagation
  of error.
\newblock \emph{Electronics letters}, 26\penalty0 (21):\penalty0 1745--1746,
  1990.

\bibitem[Venkatesh et~al.(2016)Venkatesh, Nurvitadhi, and
  Marr]{venkatesh2016accelerating}
G.~Venkatesh, E.~Nurvitadhi, and D.~Marr.
\newblock Accelerating deep convolutional networks using low-precision and
  sparsity.
\newblock \emph{arXiv preprint arXiv:1610.00324}, 2016.

\bibitem[Zhou et~al.(2016)Zhou, Wu, Ni, Zhou, Wen, and Zou]{zhou2016dorefa}
S.~Zhou, Y.~Wu, Z.~Ni, X.~Zhou, H.~Wen, and Y.~Zou.
\newblock Dorefa-net: Training low bitwidth convolutional neural networks with
  low bitwidth gradients.
\newblock \emph{arXiv preprint arXiv:1606.06160}, 2016.

\end{thebibliography}
