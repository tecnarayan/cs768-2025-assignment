\begin{thebibliography}{10}

\bibitem{bao2022analytic}
{\sc Bao, F., Li, C., Zhu, J., and Zhang, B.}
\newblock Analytic-dpm: an analytic estimate of the optimal reverse variance in
  diffusion probabilistic models.
\newblock {\em arXiv preprint arXiv:2201.06503\/} (2022).

\bibitem{bengio2013representation}
{\sc Bengio, Y., Courville, A., and Vincent, P.}
\newblock Representation learning: A review and new perspectives.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence
  35}, 8 (2013), 1798--1828.

\bibitem{bin2021pinneik}
{\sc bin Waheed, U., Haghighat, E., Alkhalifah, T., Song, C., and Hao, Q.}
\newblock Pinneik: Eikonal solution using physics-informed neural networks.
\newblock {\em Computers \& Geosciences 155\/} (2021), 104833.

\bibitem{chan2016plug}
{\sc Chan, S.~H., Wang, X., and Elgendy, O.~A.}
\newblock Plug-and-play admm for image restoration: Fixed-point convergence and
  applications.
\newblock {\em IEEE Transactions on Computational Imaging 3}, 1 (2016), 84--98.

\bibitem{chi2023diffusion}
{\sc Chi, C., Feng, S., Du, Y., Xu, Z., Cousineau, E., Burchfiel, B., and Song,
  S.}
\newblock Diffusion policy: Visuomotor policy learning via action diffusion.
\newblock {\em arXiv preprint arXiv:2303.04137\/} (2023).

\bibitem{chung2022improving}
{\sc Chung, H., Sim, B., Ryu, D., and Ye, J.~C.}
\newblock Improving diffusion models for inverse problems using manifold
  constraints.
\newblock {\em arXiv preprint arXiv:2206.00941\/} (2022).

\bibitem{de2022convergence}
{\sc De~Bortoli, V.}
\newblock Convergence of denoising diffusion models under the manifold
  hypothesis.
\newblock {\em arXiv preprint arXiv:2208.05314\/} (2022).

\bibitem{delfour2011shapes}
{\sc Delfour, M.~C., and Zol{\'e}sio, J.-P.}
\newblock {\em Shapes and geometries: metrics, analysis, differential calculus,
  and optimization}.
\newblock SIAM, 2011.

\bibitem{dhariwal2021diffusion}
{\sc Dhariwal, P., and Nichol, A.}
\newblock Diffusion models beat {{GANs}} on image synthesis.
\newblock {\em Advances in Neural Information Processing Systems 34\/} (2021),
  8780--8794.

\bibitem{federer1959curvature}
{\sc Federer, H.}
\newblock Curvature measures.
\newblock {\em Transactions of the American Mathematical Society 93}, 3 (1959),
  418--491.

\bibitem{fefferman2016testing}
{\sc Fefferman, C., Mitter, S., and Narayanan, H.}
\newblock Testing the manifold hypothesis.
\newblock {\em Journal of the American Mathematical Society 29}, 4 (2016),
  983--1049.

\bibitem{heusel2017gans}
{\sc Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., and Hochreiter,
  S.}
\newblock Gans trained by a two time-scale update rule converge to a local nash
  equilibrium.
\newblock {\em Advances in neural information processing systems 30\/} (2017).

\bibitem{ho2020denoising}
{\sc Ho, J., Jain, A., and Abbeel, P.}
\newblock Denoising diffusion probabilistic models.
\newblock {\em Advances in Neural Information Processing Systems 33\/} (2020),
  6840--6851.

\bibitem{kadkhodaie2020solving}
{\sc Kadkhodaie, Z., and Simoncelli, E.~P.}
\newblock Solving linear inverse problems using the prior implicit in a
  denoiser.
\newblock {\em arXiv preprint arXiv:2007.13640\/} (2020).

\bibitem{karras2022elucidating}
{\sc Karras, T., Aittala, M., Aila, T., and Laine, S.}
\newblock Elucidating the design space of diffusion-based generative models.
\newblock {\em arXiv preprint arXiv:2206.00364\/} (2022).

\bibitem{kawar2022denoising}
{\sc Kawar, B., Elad, M., Ermon, S., and Song, J.}
\newblock Denoising diffusion restoration models.
\newblock {\em arXiv preprint arXiv:2201.11793\/} (2022).

\bibitem{kong2020diffwave}
{\sc Kong, Z., Ping, W., Huang, J., Zhao, K., and Catanzaro, B.}
\newblock Diffwave: A versatile diffusion model for audio synthesis.
\newblock {\em arXiv preprint arXiv:2009.09761\/} (2020).

\bibitem{krizhevsky2009learning}
{\sc Krizhevsky, A., Hinton, G., et~al.}
\newblock Learning multiple layers of features from tiny images.

\bibitem{le2023preconditioned}
{\sc Le~Pendu, M., and Guillemot, C.}
\newblock Preconditioned plug-and-play admm with locally adjustable denoiser
  for image restoration.
\newblock {\em SIAM Journal on Imaging Sciences 16}, 1 (2023), 393--422.

\bibitem{lichtenstein2019deep}
{\sc Lichtenstein, M., Pai, G., and Kimmel, R.}
\newblock Deep eikonal solvers.
\newblock In {\em Scale Space and Variational Methods in Computer Vision: 7th
  International Conference, SSVM 2019, Hofgeismar, Germany, June 30--July 4,
  2019, Proceedings 7\/} (2019), Springer, pp.~38--50.

\bibitem{lin2014microsoft}
{\sc Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D.,
  Doll{\'a}r, P., and Zitnick, C.~L.}
\newblock Microsoft coco: Common objects in context.
\newblock In {\em Computer Vision--ECCV 2014: 13th European Conference, Zurich,
  Switzerland, September 6-12, 2014, Proceedings, Part V 13\/} (2014),
  Springer, pp.~740--755.

\bibitem{lipman2022flow}
{\sc Lipman, Y., Chen, R.~T., Ben-Hamu, H., Nickel, M., and Le, M.}
\newblock Flow matching for generative modeling.
\newblock {\em arXiv preprint arXiv:2210.02747\/} (2022).

\bibitem{liu2022pseudo}
{\sc Liu, L., Ren, Y., Lin, Z., and Zhao, Z.}
\newblock Pseudo numerical methods for diffusion models on manifolds.
\newblock {\em arXiv preprint arXiv:2202.09778\/} (2022).

\bibitem{liu2023zero}
{\sc Liu, R., Wu, R., Van~Hoorick, B., Tokmakov, P., Zakharov, S., and
  Vondrick, C.}
\newblock Zero-1-to-3: Zero-shot one image to 3d object.
\newblock {\em arXiv preprint arXiv:2303.11328\/} (2023).

\bibitem{liu2015faceattributes}
{\sc Liu, Z., Luo, P., Wang, X., and Tang, X.}
\newblock Deep learning face attributes in the wild.
\newblock In {\em Proceedings of International Conference on Computer Vision
  (ICCV)\/} (December 2015).

\bibitem{lu2022dpm}
{\sc Lu, C., Zhou, Y., Bao, F., Chen, J., Li, C., and Zhu, J.}
\newblock Dpm-solver: A fast ode solver for diffusion probabilistic model
  sampling in around 10 steps.
\newblock {\em arXiv preprint arXiv:2206.00927\/} (2022).

\bibitem{lu2022dpmpp}
{\sc Lu, C., Zhou, Y., Bao, F., Chen, J., Li, C., and Zhu, J.}
\newblock Dpm-solver++: Fast solver for guided sampling of diffusion
  probabilistic models.
\newblock {\em arXiv preprint arXiv:2211.01095\/} (2022).

\bibitem{meng2021sdedit}
{\sc Meng, C., He, Y., Song, Y., Song, J., Wu, J., Zhu, J.-Y., and Ermon, S.}
\newblock Sdedit: Guided image synthesis and editing with stochastic
  differential equations.
\newblock In {\em International Conference on Learning Representations\/}
  (2021).

\bibitem{nichol2021improved}
{\sc Nichol, A.~Q., and Dhariwal, P.}
\newblock Improved denoising diffusion probabilistic models.
\newblock In {\em International Conference on Machine Learning\/} (2021), PMLR,
  pp.~8162--8171.

\bibitem{park2019deepsdf}
{\sc Park, J.~J., Florence, P., Straub, J., Newcombe, R., and Lovegrove, S.}
\newblock Deepsdf: Learning continuous signed distance functions for shape
  representation.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition\/} (2019), pp.~165--174.

\bibitem{poole2022dreamfusion}
{\sc Poole, B., Jain, A., Barron, J.~T., and Mildenhall, B.}
\newblock Dreamfusion: Text-to-3d using 2d diffusion.
\newblock {\em arXiv preprint arXiv:2209.14988\/} (2022).

\bibitem{pope2021intrinsic}
{\sc Pope, P., Zhu, C., Abdelkader, A., Goldblum, M., and Goldstein, T.}
\newblock The intrinsic dimension of images and its impact on learning.
\newblock {\em arXiv preprint arXiv:2104.08894\/} (2021).

\bibitem{ramesh2022hierarchical}
{\sc Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., and Chen, M.}
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock {\em arXiv preprint arXiv:2204.06125\/} (2022).

\bibitem{rick2017one}
{\sc Rick~Chang, J., Li, C.-L., Poczos, B., Vijaya~Kumar, B., and
  Sankaranarayanan, A.~C.}
\newblock One network to solve them all--solving linear inverse problems using
  deep projection models.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision\/} (2017), pp.~5888--5897.

\bibitem{rombach2022high}
{\sc Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B.}
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition\/} (2022), pp.~10684--10695.

\bibitem{saharia2022photorealistic}
{\sc Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E.,
  Ghasemipour, S. K.~S., Ayan, B.~K., Mahdavi, S.~S., Lopes, R.~G., et~al.}
\newblock Photorealistic text-to-image diffusion models with deep language
  understanding.
\newblock {\em arXiv preprint arXiv:2205.11487\/} (2022).

\bibitem{scieur2017integration}
{\sc Scieur, D., Roulet, V., Bach, F., and d'Aspremont, A.}
\newblock Integration methods and optimization algorithms.
\newblock {\em Advances in Neural Information Processing Systems 30\/} (2017).

\bibitem{sethian1996fast}
{\sc Sethian, J.~A.}
\newblock A fast marching level set method for monotonically advancing fronts.
\newblock {\em Proceedings of the National Academy of Sciences 93}, 4 (1996),
  1591--1595.

\bibitem{smith2020eikonet}
{\sc Smith, J.~D., Azizzadenesheli, K., and Ross, Z.~E.}
\newblock Eikonet: Solving the eikonal equation with deep neural networks.
\newblock {\em IEEE Transactions on Geoscience and Remote Sensing 59}, 12
  (2020), 10685--10696.

\bibitem{sohl2015deep}
{\sc Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., and Ganguli, S.}
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In {\em International Conference on Machine Learning\/} (2015), PMLR,
  pp.~2256--2265.

\bibitem{song2020denoising}
{\sc Song, J., Meng, C., and Ermon, S.}
\newblock Denoising diffusion implicit models.
\newblock {\em arXiv preprint arXiv:2010.02502\/} (2020).

\bibitem{song2023consistency}
{\sc Song, Y., Dhariwal, P., Chen, M., and Sutskever, I.}
\newblock Consistency models.
\newblock {\em arXiv preprint arXiv:2303.01469\/} (2023).

\bibitem{song2019generative}
{\sc Song, Y., and Ermon, S.}
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock {\em Advances in neural information processing systems 32\/} (2019).

\bibitem{song2020score}
{\sc Song, Y., Sohl-Dickstein, J., Kingma, D.~P., Kumar, A., Ermon, S., and
  Poole, B.}
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock {\em arXiv preprint arXiv:2011.13456\/} (2020).

\bibitem{tevet2022human}
{\sc Tevet, G., Raab, S., Gordon, B., Shafir, Y., Cohen-Or, D., and Bermano,
  A.~H.}
\newblock Human motion diffusion model.
\newblock {\em arXiv preprint arXiv:2209.14916\/} (2022).

\bibitem{vershynin2018high}
{\sc Vershynin, R.}
\newblock {\em High-dimensional probability: An introduction with applications
  in data science}, vol.~47.
\newblock Cambridge university press, 2018.

\bibitem{vincent2011connection}
{\sc Vincent, P.}
\newblock A connection between score matching and denoising autoencoders.
\newblock {\em Neural computation 23}, 7 (2011), 1661--1674.

\bibitem{welling2011bayesian}
{\sc Welling, M., and Teh, Y.~W.}
\newblock Bayesian learning via stochastic gradient langevin dynamics.
\newblock In {\em Proceedings of the 28th international conference on machine
  learning (ICML-11)\/} (2011), Citeseer, pp.~681--688.

\bibitem{zhang2022fast}
{\sc Zhang, Q., and Chen, Y.}
\newblock Fast sampling of diffusion models with exponential integrator.
\newblock {\em arXiv preprint arXiv:2204.13902\/} (2022).

\bibitem{zhao2023unipc}
{\sc Zhao, W., Bai, L., Rao, Y., Zhou, J., and Lu, J.}
\newblock Unipc: A unified predictor-corrector framework for fast sampling of
  diffusion models.
\newblock {\em arXiv preprint arXiv:2302.04867\/} (2023).

\end{thebibliography}
