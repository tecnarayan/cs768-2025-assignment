@article{dai2019transformer,
  title={Transformer-xl: Attentive language models beyond a fixed-length context},
  author={Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime and Le, Quoc V and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1901.02860},
  year={2019}
}

@article{Alvarez:2012,
 author = {\'{A}lvarez, Mauricio A. and Rosasco, Lorenzo and Lawrence, Neil D.},
 title = {Kernels for Vector-Valued Functions: A Review},
 journal = {Found. Trends Mach. Learn.},
 issue_date = {March 2012},
 volume = {4},
 number = {3},
 month = mar,
 year = {2012},
 issn = {1935-8237},
 pages = {195--266},
 numpages = {72},
 url = {http://dx.doi.org/10.1561/2200000036},
 doi = {10.1561/2200000036},
 acmid = {2344403},
 publisher = {Now Publishers Inc.},
 address = {Hanover, MA, USA},
} 

@inproceedings{evci2020rigging,
  title={Rigging the lottery: Making all tickets winners},
  author={Evci, Utku and Gale, Trevor and Menick, Jacob and Castro, Pablo Samuel and Elsen, Erich},
  booktitle={International Conference on Machine Learning},
  pages={2943--2952},
  year={2020},
  organization={PMLR}
}

@article{chaudhry2018efficient,
  title={Efficient lifelong learning with a-gem},
  author={Chaudhry, Arslan and Ranzato, Marc'Aurelio and Rohrbach, Marcus and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:1812.00420},
  year={2018}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@article{belkin2019reconciling,
  title={Reconciling modern machine-learning practice and the classical bias--variance trade-off},
  author={Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={32},
  pages={15849--15854},
  year={2019},
  publisher={National Acad Sciences}
}

@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={PMLR}
}

@inproceedings{kalchbrenner2018efficient,
  title={Efficient neural audio synthesis},
  author={Kalchbrenner, Nal and Elsen, Erich and Simonyan, Karen and Noury, Seb and Casagrande, Norman and Lockhart, Edward and Stimberg, Florian and Oord, Aaron and Dieleman, Sander and Kavukcuoglu, Koray},
  booktitle={International Conference on Machine Learning},
  pages={2410--2419},
  year={2018},
  organization={PMLR}
}

@article{nakkiran2019deep,
  title={Deep double descent: Where bigger models and more data hurt},
  author={Nakkiran, Preetum and Kaplun, Gal and Bansal, Yamini and Yang, Tristan and Barak, Boaz and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1912.02292},
  year={2019}
}

@article{adams2007bayesian,
  title={Bayesian online changepoint detection},
  author={Adams, Ryan Prescott and MacKay, David JC},
  journal={arXiv preprint arXiv:0710.3742},
  year={2007}
}

@article{milan2016forget,
  title={The forget-me-not process},
  author={Milan, Kieran and Veness, Joel and Kirkpatrick, James and Bowling, Michael and Koop, Anna and Hassabis, Demis},
  journal={Advances in Neural Information Processing Systems},
  volume={29},
  pages={3702--3710},
  year={2016}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015},
  organization={PMLR}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}
@article{frankle2019lottery,
  title={The lottery ticket hypothesis at scale},
  author={Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel M and Carbin, Michael},
  journal={arXiv preprint arXiv:1903.01611},
  volume={8},
  year={2019}
}

@article{evci2019difficulty,
  title={The difficulty of training sparse neural networks},
  author={Evci, Utku and Pedregosa, Fabian and Gomez, Aidan and Elsen, Erich},
  journal={arXiv preprint arXiv:1906.10732},
  year={2019}
}

@article{lecun2010mnist,
  title={MNIST handwritten digit database},
  author={LeCun, Yann and Cortes, Corinna and Burges, CJ},
  journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},
  volume={2},
  year={2010}
}

@article{lecun1989backpropagation,
  title={Backpropagation applied to handwritten zip code recognition},
  author={LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},
  journal={Neural computation},
  volume={1},
  number={4},
  pages={541--551},
  year={1989},
  publisher={MIT Press}
}

@article{wolczyk2021world,
  title={Continual World: A Robotic Benchmark For Continual Reinforcement Learning},
  author={Wolczyk, Maciej and Zajac, Michal and Pascanu, Razvan and Kucinski, Lukasz and Milos, Piotr},
  journal={arXiv preprint arXiv:2105.10919},
  year={2021}
}

@article{fernando2017pathnet,
  title={Pathnet: Evolution channels gradient descent in super neural networks},
  author={Fernando, Chrisantha and Banarse, Dylan and Blundell, Charles and Zwols, Yori and Ha, David and Rusu, Andrei A and Pritzel, Alexander and Wierstra, Daan},
  journal={arXiv preprint arXiv:1701.08734},
  year={2017}
}

@inproceedings{mallya2018packnet,
  title={Packnet: Adding multiple tasks to a single network by iterative pruning},
  author={Mallya, Arun and Lazebnik, Svetlana},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={7765--7773},
  year={2018}
}

@article{dettmers2019sparse,
  title={Sparse networks from scratch: Faster training without losing performance},
  author={Dettmers, Tim and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1907.04840},
  year={2019}
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  pages={1097--1105},
  year={2012}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Citeseer}
}

@article{hermann2015teaching,
  title={Teaching machines to read and comprehend},
  author={Hermann, Karl Moritz and Ko{\v{c}}isk{\`y}, Tom{\'a}{\v{s}} and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},
  journal={arXiv preprint arXiv:1506.03340},
  year={2015}
}

@inproceedings{mostafa2019parameter,
  title={Parameter efficient training of deep convolutional neural networks by dynamic sparse reparameterization},
  author={Mostafa, Hesham and Wang, Xin},
  booktitle={International Conference on Machine Learning},
  pages={4646--4655},
  year={2019},
  organization={PMLR}
}

@article{mocanu2018scalable,
  title={Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science},
  author={Mocanu, Decebal Constantin and Mocanu, Elena and Stone, Peter and Nguyen, Phuong H and Gibescu, Madeleine and Liotta, Antonio},
  journal={Nature communications},
  volume={9},
  number={1},
  pages={1--12},
  year={2018},
  publisher={Nature Publishing Group}
}

@article{lee2018snip,
  title={Snip: Single-shot network pruning based on connection sensitivity},
  author={Lee, Namhoon and Ajanthan, Thalaiyasingam and Torr, Philip HS},
  journal={arXiv preprint arXiv:1810.02340},
  year={2018}
}

@article{gale2019state,
  title={The state of sparsity in deep neural networks},
  author={Gale, Trevor and Elsen, Erich and Hooker, Sara},
  journal={arXiv preprint arXiv:1902.09574},
  year={2019}
}

@incollection{Bonilla2018,
title = {Multi-task Gaussian Process Prediction},
author = {Bonilla, Edwin V and Kian M. Chai and Christopher Williams},
booktitle = {Advances in Neural Information Processing Systems 20},
editor = {J. C. Platt and D. Koller and Y. Singer and S. T. Roweis},
pages = {153--160},
year = {2008},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/3189-multi-task-gaussian-process-prediction.pdf}
}

@InProceedings{santoro16,
  title = 	 {Meta-Learning with Memory-Augmented Neural Networks},
  author = 	 {Adam Santoro and Sergey Bartunov and Matthew Botvinick and Daan Wierstra and Timothy Lillicrap},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {1842--1850},
  year = 	 {2016},
  editor = 	 {Maria Florina Balcan and Kilian Q. Weinberger},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher = 	 {PMLR},
  abstract = 	 {Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of "one-shot learning." Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory location-based focusing mechanisms.}
}


@InProceedings{finn17a,
  title = 	 {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
  author = 	 {Chelsea Finn and Pieter Abbeel and Sergey Levine},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1126--1135},
  year = 	 {2017},
  editor = 	 {Doina Precup and Yee Whye Teh},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {International Convention Centre, Sydney, Australia},
  month = 	 {06--11 Aug},
  publisher = 	 {PMLR},
  abstract = 	 {We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.}
}

@article{Riquelme2018,
  author    = {Carlos Riquelme and
               George Tucker and
               Jasper Snoek},
  title     = {Deep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian
               Deep Networks for Thompson Sampling},
  journal   = {CoRR},
  volume    = {abs/1802.09127},
  year      = {2018}
}


@InProceedings{wilson16,
  title = 	 {Deep Kernel Learning},
  author = 	 {Andrew Gordon Wilson and Zhiting Hu and Ruslan Salakhutdinov and Eric P. Xing},
  booktitle = 	 {Proceedings of the 19th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {370--378},
  year = 	 {2016},
  editor = 	 {Arthur Gretton and Christian C. Robert},
  volume = 	 {51},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Cadiz, Spain},
  month = 	 {09--11 May},
  publisher = 	 {PMLR},
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{titsias2019functional,
  title={Functional regularisation for continual learning with gaussian processes},
  author={Titsias, Michalis K and Schwarz, Jonathan and Matthews, Alexander G de G and Pascanu, Razvan and Teh, Yee Whye},
  journal={arXiv preprint arXiv:1901.11356},
  year={2019}
}

@article{kaplanis2020continual,
  title={Continual Reinforcement Learning with Multi-Timescale Replay},
  author={Kaplanis, Christos and Clopath, Claudia and Shanahan, Murray},
  journal={arXiv preprint arXiv:2004.07530},
  year={2020}
}

@article{shin2017continual,
  title={Continual learning with deep generative replay},
  author={Shin, Hanul and Lee, Jung Kwon and Kim, Jaehong and Kim, Jiwon},
  journal={arXiv preprint arXiv:1705.08690},
  year={2017}
}

@article{van2019three,
  title={Three scenarios for continual learning},
  author={Van de Ven, Gido M and Tolias, Andreas S},
  journal={arXiv preprint arXiv:1904.07734},
  year={2019}
}

@article{sokar2021spacenet,
  title={Spacenet: Make free space for continual learning},
  author={Sokar, Ghada and Mocanu, Decebal Constantin and Pechenizkiy, Mykola},
  journal={Neurocomputing},
  volume={439},
  pages={1--11},
  year={2021},
  publisher={Elsevier}
}

@article{rolnick2018experience,
  title={Experience replay for continual learning},
  author={Rolnick, David and Ahuja, Arun and Schwarz, Jonathan and Lillicrap, Timothy P and Wayne, Greg},
  journal={arXiv preprint arXiv:1811.11682},
  year={2018}
}

@article{french1999catastrophic,
  title={Catastrophic forgetting in connectionist networks},
  author={French, Robert M},
  journal={Trends in cognitive sciences},
  volume={3},
  number={4},
  pages={128--135},
  year={1999},
  publisher={Elsevier}
}

@article{robins1995catastrophic,
  title={Catastrophic forgetting, rehearsal and pseudorehearsal},
  author={Robins, Anthony},
  journal={Connection Science},
  volume={7},
  number={2},
  pages={123--146},
  year={1995},
  publisher={Taylor \& Francis}
}

@techreport{rumelhart1985learning,
  title={Learning internal representations by error propagation},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  year={1985},
  institution={California Univ San Diego La Jolla Inst for Cognitive Science}
}

@article{jayakumar2020top,
  title={Top-kast: Top-k always sparse training},
  author={Jayakumar, Siddhant and Pascanu, Razvan and Rae, Jack and Osindero, Simon and Elsen, Erich},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20744--20754},
  year={2020}
}

@inproceedings{thimm1995evaluating,
  title={Evaluating pruning methods},
  author={Thimm, Georg and Fiesler, Emile},
  booktitle={Proceedings of the International Symposium on Artificial neural networks},
  pages={20--25},
  year={1995},
  organization={Citeseer}
}

@inproceedings{strom1997sparse,
  title={Sparse connection and pruning in large dynamic artificial neural networks},
  author={Str{\"o}m, Nikko},
  booktitle={Fifth European Conference on Speech Communication and Technology},
  year={1997}
}

@book{hassibi1993second,
  title={Second order derivatives for network pruning: Optimal brain surgeon},
  author={Hassibi, Babak and Stork, David G},
  year={1993},
  publisher={Morgan Kaufmann}
}

@inproceedings{lecun1990optimal,
  title={Optimal brain damage},
  author={LeCun, Yann and Denker, John S and Solla, Sara A},
  booktitle={Advances in neural information processing systems},
  pages={598--605},
  year={1990}
}

@inproceedings{mozer1989skeletonization,
  title={Skeletonization: A technique for trimming the fat from a network via relevance assessment},
  author={Mozer, Michael C and Smolensky, Paul},
  booktitle={Advances in neural information processing systems},
  pages={107--115},
  year={1989}
}

@article{hinton2012neural,
  title={Neural networks for machine learning lecture 6a overview of mini-batch gradient descent},
  author={Hinton, Geoffrey and Srivastava, Nitish and Swersky, Kevin},
  journal={Cited on},
  volume={14},
  number={8},
  year={2012}
}

@article{duchi2011adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization.},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of machine learning research},
  volume={12},
  number={7},
  year={2011}
}

@incollection{lecun2012efficient,
  title={Efficient backprop},
  author={LeCun, Yann A and Bottou, L{\'e}on and Orr, Genevieve B and M{\"u}ller, Klaus-Robert},
  booktitle={Neural networks: Tricks of the trade},
  pages={9--48},
  year={2012},
  publisher={Springer}
}

@inproceedings{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1026--1034},
  year={2015}
}

@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={249--256},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}



@ARTICLE{GPflow2017,
author = {Matthews, Alexander G. de G. and {van der Wilk}, Mark and Nickson, Tom and Fujii, Keisuke. and {Boukouvalas}, Alexis and {Le{‘o}n-Villagr{‘a}}, Pablo and Ghahramani, Zoubin and Hensman, James},
title = {{GP}flow: A {G}aussian process library using {T}ensor{F}low},
journal = {Journal of Machine Learning Research},
year = {2017},
month = {April},
volume = {18},
number = {40},
pages = {1-6},
}


 @incollection{williamsseeger2001,
title = {Using the Nystr\"{o}m Method to Speed Up Kernel Machines},
author = {Christopher K. I. Williams and Matthias Seeger},
booktitle = {Advances in Neural Information Processing Systems 13},
editor = {T. K. Leen and T. G. Dietterich and V. Tresp},
pages = {682--688},
year = {2001},
publisher = {MIT Press},
}

@inproceedings{HernndezLobato2016ScalableGP,
  title={Scalable Gaussian Process Classification via Expectation Propagation},
  author={Daniel Hern{\'a}ndez-Lobato and Jos{\'e} Miguel Hern{\'a}ndez-Lobato},
  booktitle={AISTATS},
  year={2016}
}

@incollection{Rai-2015,
title = {Large-Scale Bayesian Multi-Label Learning via Topic-Based Label Embeddings},
author = {Rai, Piyush and Hu, Changwei and Henao, Ricardo and Carin, Lawrence},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
pages = {3222--3230},
year = {2015},
publisher = {Curran Associates, Inc.}
}

@incollection{Bhatia-2015,
title = {Sparse Local Embeddings for Extreme Multi-label Classification},
author = {Bhatia, Kush and Jain, Himanshu and Kar, Purushottam and Varma, Manik and Jain, Prateek},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
pages = {730--738},
year = {2015},
publisher = {Curran Associates, Inc.}
}

@inproceedings{mcauley2013hidden,
  title={Hidden factors and hidden topics: understanding rating dimensions with review text},
  author={McAuley, Julian and Leskovec, Jure},
  booktitle={Proceedings of the 7th ACM conference on Recommender systems},
  pages={165--172},
  year={2013},
  organization={ACM}
}

@article{Alvarez-2011,
 author = {\'{A}lvarez, Mauricio A. and Lawrence, Neil D.},
 title = {Computationally Efficient Convolved Multiple Output Gaussian Processes},
 journal = {J. Mach. Learn. Res.},
 volume = {12},
 month = jul,
 year = {2011},
 issn = {1532-4435},
 pages = {1459--1500},
 numpages = {42},
 publisher = {JMLR.org},
} 

@book{Rasmussen-2005,
 author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
 title = {Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning)},
 year = {2005},
 isbn = {026218253X},
 publisher = {The MIT Press},
} 

@inproceedings{Prabhu-2014,
 author = {Prabhu, Yashoteja and Varma, Manik},
 title = {FastXML: A Fast, Accurate and Stable Tree-classifier for Extreme Multi-label Learning},
 booktitle = {Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 series = {KDD '14},
 year = {2014},
 isbn = {978-1-4503-2956-9},
 location = {New York, New York, USA},
 pages = {263--272},
 numpages = {10},
 publisher = {ACM},
 address = {New York, NY, USA}
} 

@InProceedings{jain17a,
  title = 	 {Scalable Generative Models for Multi-label Learning with Missing Labels},
  author = 	 {Vikas Jain and Nirbhay Modhe and Piyush Rai},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1636--1644},
  year = 	 {2017},
  editor = 	 {Doina Precup and Yee Whye Teh},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {International Convention Centre, Sydney, Australia},
  month = 	 {06--11 Aug},
  publisher = 	 {PMLR},
  abstract = 	 {We present a scalable, generative framework for multi-label learning with missing labels. Our framework consists of a latent factor model for the binary label matrix, which is coupled with an exposure model to account for label missingness (i.e., whether a zero in the label matrix is indeed a zero or denotes a missing observation). The underlying latent factor model also assumes that the low-dimensional embeddings of each label vector are directly conditioned on the respective feature vector of that example. Our generative framework admits a simple inference procedure, such that the parameter estimation reduces to a sequence of simple weighted least-square regression problems, each of which can be solved easily, efficiently, and in parallel. Moreover, inference can also be performed in an online fashion using mini-batches of training examples, which makes our framework scalable for large data sets, even when using moderate computational resources. We report both quantitative and qualitative results for our framework on several benchmark data sets, comparing it with a number of state-of-the-art methods.}
}

@article{Gibaja2015,
 author = {Gibaja, Eva and Ventura, Sebasti\'{a}n},
 title = {A Tutorial on Multilabel Learning},
 journal = {ACM Comput. Surv.},
 issue_date = {April 2015},
 volume = {47},
 number = {3},
 month = apr,
 year = {2015},
 pages = {52:1--52:38},
 numpages = {38},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@article {Gibaja2014,
author = {Gibaja, Eva and Ventura, Sebastián},
title = {Multi-label learning: a review of the state of the art and ongoing research},
journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
volume = {4},
number = {6},
publisher = {Wiley Periodicals, Inc},
pages = {411--444},
year = {2014}
}

@Article{Read2011,
author="Read, Jesse
and Pfahringer, Bernhard
and Holmes, Geoff
and Frank, Eibe",
title="Classifier chains for multi-label classification",
journal="Machine Learning",
year="2011",
month="Jun",
day="30",
volume="85",
number="3",
pages="333",
abstract="The widely known binary relevance method for multi-label classification, which considers each label as an independent binary problem, has often been overlooked in the literature due to the perceived inadequacy of not directly modelling label correlations. Most current methods invest considerable complexity to model interdependencies between labels. This paper shows that binary relevance-based methods have much to offer, and that high predictive performance can be obtained without impeding scalability to large datasets. We exemplify this with a novel classifier chains method that can model label correlations while maintaining acceptable computational complexity. We extend this approach further in an ensemble framework. An extensive empirical evaluation covers a broad range of multi-label datasets with a variety of evaluation metrics. The results illustrate the competitiveness of the chaining method against related and state-of-the-art methods, both in terms of predictive performance and time complexity."
}

@article{Zhang2013,
  abstract = {Multi-label learning studies the problem where each example is represented by a single instance while associated with a set of labels simultaneously. During the past decade, significant amount of progresses have been made towards this emerging machine learning paradigm. This paper aims to provide a timely review on this area with emphasis on state-of-the-art multi-label learning algorithms. Firstly, fundamentals on multi-label learning including formal definition and evaluation metrics are given. Secondly and primarily, eight representative multi-label learning algorithms are scrutinized under common notations with relevant analyses and discussions. Thirdly, several related learning settings are briefly summarized. As a conclusion, online resources and open research problems on multi-label learning are outlined for reference purposes.},
  author = {Zhang, M. and Zhou, Z.},
  description = {IEEE Xplore Abstract (Abstract) - A Review On Multi-Label Learning Algorithms},
  doi = {10.1109/TKDE.2013.39},
  journal = {Knowledge and Data Engineering, IEEE Transactions on},
  keywords = {classification text},
  number = 99,
  pages = 1,
  title = {A Review On Multi-Label Learning Algorithms},
  volume = {PP},
  year = 2013
}

@article{Hoffman-2013,
 author = {Hoffman, Matthew D. and Blei, David M. and Wang, Chong and Paisley, John},
 title = {Stochastic Variational Inference},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2013},
 volume = {14},
 number = {1},
 month = may,
 year = {2013},
 pages = {1303--1347},
 numpages = {45}
} 

@incollection{mikolov2013,
title = {Distributed Representations of Words and Phrases and their Compositionality},
author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
booktitle = {Advances in Neural Information Processing Systems 26},
editor = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
pages = {3111--3119},
year = {2013},
publisher = {Curran Associates, Inc.}
}

@inproceedings{Lloyd2015,
 author = {Lloyd, Chris and Gunter, Tom and Osborne, Michael A. and Roberts, Stephen J.},
 title = {Variational Inference for Gaussian Process Modulated Poisson Processes},
 booktitle = {Proceedings of the 32Nd International Conference on International Conference on Machine Learning - Volume 37},
 series = {ICML'15},
 year = {2015},
 location = {Lille, France},
 pages = {1814--1822},
 numpages = {9}
} 

@InProceedings{sheth15,
  title = 	 {Sparse Variational Inference for Generalized GP Models},
  author = 	 {Rishit Sheth and Yuyang Wang and Roni Khardon},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1302--1311},
  year = 	 {2015},
  editor = 	 {Francis Bach and David Blei},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher = 	 {PMLR},
}

@incollection{Damianou11,
title ={Variational {G}aussian Process Dynamical Systems},
author={Andreas C. Damianou and Michalis Titsias and Neil D. Lawrence},
booktitle = {Advances in Neural Information Processing Systems 24},
editor = {J. Shawe-Taylor and R.S. Zemel and P. Bartlett and F.C.N. Pereira and K.Q. Weinberger},
pages = {2510--2518},
year = {2011}
}

@inproceedings{hensman2015scalable,
  title = {Scalable {V}ariational {G}aussian {P}rocess {C}lassification},
  author = {Hensman, James and Matthews, Alexander G de G and Ghahramani, Zoubin},
  booktitle = {Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics},
  year = {2015},
}

@inproceedings{hensman2013gaussian,
  title = {{G}aussian processes for {B}ig {D}ata},
  author = {Hensman, James and Fusi, Nicolo and Lawrence, Neil D},
  booktitle = {Conference on Uncertainty in Artificial Intellegence},
  pages = {282--290},
  year = {2013},
  organization = {auai.org}
}

@InProceedings{Matthews16,
  title = 	 {On Sparse Variational Methods and the Kullback-Leibler Divergence between Stochastic Processes},
  author = 	 {Alexander G. de G. Matthews and James Hensman and Richard Turner and Zoubin Ghahramani},
  booktitle = 	 {Proceedings of the 19th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {231--239},
  year = 	 {2016},
  volume = 	 {51},
  address = 	 {Cadiz, Spain},
  month = 	 {09--11 May},
  publisher = 	 {PMLR},
}

@incollection{Bauer2016,
title = {Understanding Probabilistic Sparse Gaussian Process Approximations},
author = {Bauer, Matthias and van der Wilk, Mark and Rasmussen, Carl Edward},
booktitle = {Advances in Neural Information Processing Systems 29},
pages = {1533--1541},
year = {2016},
publisher = {Curran Associates, Inc.},
}

@inproceedings{seeger03,
  author = {Seeger, M. and Williams, C. K. I. and Lawrence, N. D.},
  title = {{Fast forward selection to speed up sparse Gaussian 
            process regression}},
  year = {2003},
  booktitle = {Ninth International Workshop on Artificial Intelligence},
  publisher = {MIT Press},
  pages = {}
}

@incollection{Snelson2006,
title = {Sparse Gaussian Processes using Pseudo-inputs},
author = {Edward Snelson and Ghahramani, Zoubin},
booktitle = {Advances in Neural Information Processing Systems 18},
editor = {Y. Weiss and B. Sch\"{o}lkopf and J. C. Platt},
pages = {1257--1264},
year = {2006},
}

@article{candela-rasmussen-05,
   author  = {Qui{\~n}onero-Candela, J. and Rasmussen, C. E.},
   title   = {{A unifying view of sparse approximate Gaussian process regression}},
   journal = {Journal of Machine Learning Research},
   year    = {2005},
   volume  = {6},
   pages   = {1939-1959}
}

@inproceedings{lawrence-seeger-herbrich-01,
  author = {Lawrence, N. D. and Seeger, M. and Herbrich, R.},
  title = {{Fast sparse Gaussian process methods: the informative vector
            machine}},
  year = {2002},
  booktitle = {Neural Information Processing Systems, 13},
  publisher = {MIT Press},
  pages = {}
}

@article{csato-opper-02,
   author  = {Csato, L. and Opper, M.},
   title   = {{Sparse online {G}aussian processes}},
   journal = {Neural Computation},
   year    = {2002},
   volume  = {14},
   pages   = {641-668}
}

@inproceedings{autoGP2017,
  year =        {2017},
  title =       {{A}uto{GP}: {E}xploring the capabilities and limitations of {G}aussian process models},
  author =      {{K}rauth, {K}arl and  {B}onilla, {E}dwin {V} and  {C}utajar, {K}urt and  {F}ilippone, {M}aurizio},
  booktitle =   {{UAI} 2017, {C}onference on {U}ncertainty in {A}rtificial {I}ntelligence, {A}ugust 11-15, 2017, {S}ydney, {A}ustralia},
  address =     {{S}ydney, {AUSTRALIA}},
  month =       {08},
}

@incollection{Dezfouli2015,
title = {Scalable {I}nference for {G}aussian {P}rocess {M}odels with {B}lack-{B}ox {L}ikelihoods},
author = {Dezfouli, Amir and Bonilla, Edwin V},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
pages = {1414--1422},
year = {2015},
}

@Article{He2012,
author="He, Jianjun
and Gu, Hong
and Wang, Zhelong",
title="Bayesian multi-instance multi-label learning using Gaussian process prior",
journal="Machine Learning",
year="2012",
month="Jul",
day="01",
volume="88",
number="1",
pages="273--295",
}

@article{Buietal2017,
  author  = {Thang D. Bui and Josiah Yan and Richard E. Turner},
  title   = {A {U}nifying {F}ramework for {G}aussian {P}rocess {P}seudo-{P}oint {A}pproximations using {P}ower {E}xpectation {P}ropagation},
  journal = {Journal of Machine Learning Research},
  year    = {2017},
  volume  = {18},
  number  = {104},
  pages   = {1-72},
}

@incollection{Buietal2017B,
title = {Streaming {S}parse {G}aussian {P}rocess {A}pproximations},
author = {Bui, Thang D and Nguyen, Cuong and Turner, Richard E},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {3299--3307},
year = {2017},
publisher = {Curran Associates, Inc.}
}


@article{schmidt2008nonnegative,
  title={Nonnegative matrix factorization with Gaussian process priors},
  author={Schmidt, Mikkel N and Laurberg, Hans},
  journal={Computational intelligence and neuroscience},
  volume={2008},
  pages={3},
  year={2008},
  publisher={Hindawi Publishing Corp.}
}

@article{alvarez2012kernels,
  title={Kernels for vector-valued functions: A review},
  author={Alvarez, Mauricio A and Rosasco, Lorenzo and Lawrence, Neil D and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={4},
  number={3},
  pages={195--266},
  year={2012},
  publisher={Now Publishers, Inc.}
}

@inproceedings{SLFM2005,
    author = {Teh, Yee W. and Seeger, Matthias and Jordan Michael},
    booktitle = {Workshop on Artificial Intelligence and Statistics 10},
    keywords = {msc},
    title = {{Semiparametric Latent Factor Models}},
    year = {2005}
}

@article{stoyan1996hans,
  title={Hans Wackernagel: Multivariate Geostatistics. An Introduction with Applications. With 75 Figures and 5 Tables. Springer-Verlag, Berlin, Heidelberg, New York, 235 pp., 1995, DM 68.-ISBN 3-540-60127-9},
  author={Stoyan, D},
  journal={Biometrical Journal},
  volume={38},
  number={4},
  pages={454--454},
  year={1996},
  publisher={Wiley Online Library}
}

@inproceedings{bonilla2008multi,
  title={Multi-task Gaussian process prediction},
  author={Bonilla, Edwin V and Chai, Kian M and Williams, Christopher},
  booktitle={Advances in neural information processing systems},
  pages={153--160},
  year={2008}
}

@phdthesis{Csato2002,
  author       = {Csato}, 
  title        = {Gaussian processes: iterative sparse approximations},
  school       = {Aston University},
  year         = 2002
}


@inproceedings{zhou2007multi,
  title={Multi-instance multi-label learning with application to scene classification},
  author={Zhou, Zhi-Hua and Zhang, Min-Ling},
  booktitle={Advances in neural information processing systems},
  pages={1609--1616},
  year={2007}
}

@inproceedings{luttinen2009variational,
  title={Variational Gaussian-process factor analysis for modeling spatio-temporal data},
  author={Luttinen, Jaakko and Ilin, Alexander},
  booktitle={Advances in neural information processing systems},
  pages={1177--1185},
  year={2009}
}

@inproceedings{attias2000variational,
  title={A {V}ariational {B}ayesian framework for graphical models},
  author={Attias, Hagai},
  booktitle={Advances in neural information processing systems},
  pages={209--215},
  year={2000}
}

@inproceedings{titsias2009variational,
  title={Variational learning of inducing variables in sparse {G}aussian processes},
  author={Titsias, Michalis K},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={567--574},
  year={2009}
}

@article{opper2009variational,
  title={The variational {G}aussian approximation revisited},
  author={Opper, Manfred and Archambeau, C{\'e}dric},
  journal={Neural computation},
  volume={21},
  number={3},
  pages={786--792},
  year={2009},
  publisher={MIT Press}
}

@article{partalas2015lshtc,
  title={LSHTC: A benchmark for large-scale text classification},
  author={Partalas, Ioannis and Kosmopoulos, Aris and Baskiotis, Nicolas and Artieres, Thierry and Paliouras, George and Gaussier, Eric and Androutsopoulos, Ion and Amini, Massih-Reza and Galinari, Patrick},
  journal={arXiv preprint arXiv:1503.08581},
  year={2015}
}

@inproceedings{jain2016extreme,
  title={Extreme multi-label loss functions for recommendation, tagging, ranking \& other missing label applications},
  author={Jain, Himanshu and Prabhu, Yashoteja and Varma, Manik},
  booktitle={Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={935--944},
  year={2016},
  organization={ACM}
}

@inproceedings{hsu2009multi,
  title={Multi-label prediction via compressed sensing},
  author={Hsu, Daniel J and Kakade, Sham M and Langford, John and Zhang, Tong},
  booktitle={Advances in neural information processing systems},
  pages={772--780},
  year={2009}
}

@inproceedings{cisse2013robust,
  title={Robust bloom filters for large multilabel classification tasks},
  author={Cisse, Moustapha M and Usunier, Nicolas and Artieres, Thierry and Gallinari, Patrick},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1851--1859},
  year={2013}
}

@article{tai2012multilabel,
  title={Multilabel classification with principal label space transformation},
  author={Tai, Farbound and Lin, Hsuan-Tien},
  journal={Neural Computation},
  volume={24},
  number={9},
  pages={2508--2542},
  year={2012},
  publisher={MIT Press}
}

@article{balasubramanian2012landmark,
  title={The landmark selection method for multiple output prediction},
  author={Balasubramanian, Krishnakumar and Lebanon, Guy},
  journal={arXiv preprint arXiv:1206.6479},
  year={2012}
}

@inproceedings{bi2013efficient,
  title={Efficient multi-label classification with many labels},
  author={Bi, Wei and Kwok, James},
  booktitle={International Conference on Machine Learning},
  pages={405--413},
  year={2013}
}

@inproceedings{zhang2011multi,
  title={Multi-label output codes using canonical correlation analysis},
  author={Zhang, Yi and Schneider, Jeff},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={873--882},
  year={2011}
}

@inproceedings{bhatia2015sparse,
  title={Sparse local embeddings for extreme multi-label classification},
  author={Bhatia, Kush and Jain, Himanshu and Kar, Purushottam and Varma, Manik and Jain, Prateek},
  booktitle={Advances in Neural Information Processing Systems},
  pages={730--738},
  year={2015}
}

@inproceedings{yu2014large,
  title={Large-scale multi-label learning with missing labels},
  author={Yu, Hsiang-Fu and Jain, Prateek and Kar, Purushottam and Dhillon, Inderjit},
  booktitle={International Conference on Machine Learning},
  pages={593--601},
  year={2014}
}

@inproceedings{chen2012feature,
  title={Feature-aware label space dimension reduction for multi-label classification},
  author={Chen, Yao-Nan and Lin, Hsuan-Tien},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1529--1537},
  year={2012}
}

@inproceedings{ferng2011multi,
  title={Multi-label classification with error-correcting codes},
  author={Ferng, C-S and Lin, H-T},
  booktitle={Asian Conference on Machine Learning},
  pages={281--295},
  year={2011}
}

@inproceedings{ji2008extracting,
  title={Extracting shared subspace for multi-label classification},
  author={Ji, Shuiwang and Tang, Lei and Yu, Shipeng and Ye, Jieping},
  booktitle={Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={381--389},
  year={2008},
  organization={ACM}
}

@article{amid2020reparameterizing,
  title={Reparameterizing mirror descent as gradient descent},
  author={Amid, Ehsan and Warmuth, Manfred K},
  journal={Advances in Neural Information Processing Systems},
  year={2020},
  note={Version 1 of the article (\url{https://arxiv.org/abs/2002.10487v1}) contains experiments with the last layer of a neural network},
}

@inproceedings{lin2014multi,
  title={Multi-label classification via feature-aware implicit label space encoding},
  author={Lin, Zijia and Ding, Guiguang and Hu, Mingqing and Wang, Jianmin},
  booktitle={International Conference on Machine Learning},
  pages={325--333},
  year={2014}
}

@inproceedings{jain2010guaranteed,
  title={Guaranteed rank minimization via singular value projection},
  author={Jain, Prateek and Meka, Raghu and Dhillon, Inderjit S},
  booktitle={Advances in Neural Information Processing Systems},
  pages={937--945},
  year={2010}
}

@inproceedings{blundell2015weight,
  title={Weight uncertainty in neural network},
  author={Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
  booktitle={International Conference on Machine Learning},
  pages={1613--1622},
  year={2015},
  organization={PMLR}
}

@article{lakshminarayanan2016simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  journal={arXiv preprint arXiv:1612.01474},
  year={2016}
}

@article{wortsman2020supermasks,
  title={Supermasks in superposition},
  author={Wortsman, Mitchell and Ramanujan, Vivek and Liu, Rosanne and Kembhavi, Aniruddha and Rastegari, Mohammad and Yosinski, Jason and Farhadi, Ali},
  journal={arXiv preprint arXiv:2006.14769},
  year={2020}
}

@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@inproceedings{sprechmann2013supervised,
  title={Supervised sparse analysis and synthesis operators},
  author={Sprechmann, Pablo and Litman, Roee and Yakar, Tal Ben and Bronstein, Alexander M and Sapiro, Guillermo},
  booktitle={Advances in Neural Information Processing Systems},
  pages={908--916},
  year={2013}
}

@article{brier1950verification,
  title={VERIFICATION OF FORECASTS EXPRESSED IN TERMS OF PROBABILITY},
  author={Glenn W Brier},
  year={1950},
  booktitle={MONTHLY WEATHER REVIEW},
  publisher={Citeseer}
}

@inproceedings{mencia2008efficient,
  title={Efficient pairwise multilabel classification for large-scale problems in the legal domain},
  author={Mencia, Eneldo Loza and F{\"u}rnkranz, Johannes},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={50--65},
  year={2008},
  organization={Springer}
}

@inproceedings{katakis2008multilabel,
  title={Multilabel text classification for automated tag suggestion},
  author={Katakis, Ioannis and Tsoumakas, Grigorios and Vlahavas, Ioannis},
  booktitle={Proceedings of the ECML/PKDD},
  volume={18},
  year={2008}
}

@inproceedings{tsoumakas2008effective,
  title={Effective and efficient multilabel classification in domains with large number of labels},
  author={Tsoumakas, Grigorios and Katakis, Ioannis and Vlahavas, Ioannis},
  booktitle={Proc. ECML/PKDD 2008 Workshop on Mining Multidimensional Data (MMD’08)},
  volume={21},
  pages={53--59},
  year={2008},
  organization={sn}
}

@article{Tsoumakas2007,
  abstract = {Nowadays, multi-label classification methods are increasingly required by modern applications, such as protein function classification, music categorization and semantic scene classification. This paper introduces the task of multi-label classification, organizes the sparse related literature into a structured presentation and performs comparative experimental results of certain multi-label classification methods. It also contributes the definition of concepts for the quantification of the multi-label nature of a data set.},
  author = {Tsoumakas, G. and Katakis, I.},
  editor = {Taniar, David},
  journal = {International Journal of Data Warehouse and Mining},
  keywords = {classification learning machine ml multi_label survey},
  number = 3,
  pages = {1--13},
  priority = {2},
  publisher = {Idea Group Publishing},
  title = {Multi Label Classification: An Overview},
  volume = 3,
  year = 2007
}

@article{lewis2004rcv1,
  title={Rcv1: A new benchmark collection for text categorization research},
  author={Lewis, David D and Yang, Yiming and Rose, Tony G and Li, Fan},
  journal={Journal of machine learning research},
  volume={5},
  number={Apr},
  pages={361--397},
  year={2004}
}

@inproceedings{snoek2006challenge,
  title={The challenge problem for automated detection of 101 semantic concepts in multimedia},
  author={Snoek, Cees GM and Worring, Marcel and Van Gemert, Jan C and Geusebroek, Jan-Mark and Smeulders, Arnold WM},
  booktitle={Proceedings of the 14th ACM international conference on Multimedia},
  pages={421--430},
  year={2006},
  organization={ACM}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={IEEE}
}

@inproceedings{weston2011wsabie,
title = {Wsabie: Scaling Up To Large Vocabulary Image Annotation},
author  = {Jason Weston and Samy Bengio and Nicolas Usunier},
year  = {2011},
booktitle = {Proceedings of the International Joint Conference on Artificial Intelligence, IJCAI}
}

@article{baglama2005augmented,
  title={Augmented implicitly restarted Lanczos bidiagonalization methods},
  author={Baglama, James and Reichel, Lothar},
  journal={SIAM Journal on Scientific Computing},
  volume={27},
  number={1},
  pages={19--42},
  year={2005},
  publisher={SIAM}
}

@inproceedings{yen2016pd,
  title={Pd-sparse: A primal and dual sparse approach to extreme multiclass and multilabel classification},
  author={Yen, Ian En-Hsu and Huang, Xiangru and Ravikumar, Pradeep and Zhong, Kai and Dhillon, Inderjit},
  booktitle={International Conference on Machine Learning},
  pages={3069--3077},
  year={2016}
}

@inproceedings{prabhu2014fastxml,
  title={Fastxml: A fast, accurate and stable tree-classifier for extreme multi-label learning},
  author={Prabhu, Yashoteja and Varma, Manik},
  booktitle={Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={263--272},
  year={2014},
  organization={ACM}
}

% Examples for Pretraining & Finetuning

@inproceedings{bengio2012deep,
  title={Deep learning of representations for unsupervised and transfer learning},
  author={Bengio, Yoshua},
  booktitle={Proceedings of ICML Workshop on Unsupervised and Transfer Learning},
  pages={17--36},
  year={2012}
}

@article{parisotto2015actor,
  title={Actor-mimic: Deep multitask and transfer reinforcement learning},
  author={Parisotto, Emilio and Ba, Jimmy Lei and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1511.06342},
  year={2015}
}

@article{lin2013network,
  title={Network in network},
  author={Lin, Min and Chen, Qiang and Yan, Shuicheng},
  journal={arXiv preprint arXiv:1312.4400},
  year={2013}
}

@article{berseth2018,
  title={Progressive Reinforcement Learning with Distillation for Multi-Skilled Motion Control},
  author={Berseth, Glen and Xie, Cheng and Cernek, Paul and Van de Panne, Michiel},
  journal={ICLR},
  year={2018}
}


@article{he2018,
  title={Overcoming Catastrophic Interference by Conceptors},
  author={He, Xu and Jaeger, Herbert},
  journal={ICLR},
  year={2018}
}

@inproceedings{yosinski2014transferable,
  title={How transferable are features in deep neural networks?},
  author={Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  booktitle={Advances in neural information processing systems},
  pages={3320--3328},
  year={2014}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{ritter2018online,
  title={Online structured laplace approximations for overcoming catastrophic forgetting},
  author={Ritter, Hippolyt and Botev, Aleksandar and Barber, David},
  journal={arXiv preprint arXiv:1805.07810},
  year={2018}
}

@article{goodfellow2013empirical,
  title={An empirical investigation of catastrophic forgetting in gradient-based neural networks},
  author={Goodfellow, Ian J and Mirza, Mehdi and Xiao, Da and Courville, Aaron and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1312.6211},
  year={2013}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  number={3},
  pages={211--252},
  year={2015},
  publisher={Springer}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{goyal2017accurate,
  title={Accurate, large minibatch sgd: Training imagenet in 1 hour},
  author={Goyal, Priya and Doll{\'a}r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  journal={arXiv preprint arXiv:1706.02677},
  year={2017}
}

@article{golkar2019continual,
  title={Continual learning via neural pruning},
  author={Golkar, Siavash and Kagan, Michael and Cho, Kyunghyun},
  journal={arXiv preprint arXiv:1903.04476},
  year={2019}
}

@article{van2018generative,
  title={Generative replay with feedback connections as a general strategy for continual learning},
  author={Van de Ven, Gido M and Tolias, Andreas S},
  journal={arXiv preprint arXiv:1809.10635},
  year={2018}
}

@article{hsu2018re,
  title={Re-evaluating continual learning scenarios: A categorization and case for strong baselines},
  author={Hsu, Yen-Chang and Liu, Yen-Cheng and Ramasamy, Anita and Kira, Zsolt},
  journal={arXiv preprint arXiv:1810.12488},
  year={2018}
}

@inproceedings{aljundi2018memory,
  title={Memory aware synapses: Learning what (not) to forget},
  author={Aljundi, Rahaf and Babiloni, Francesca and Elhoseiny, Mohamed and Rohrbach, Marcus and Tuytelaars, Tinne},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={139--154},
  year={2018}
}

% Replay buffer

@inproceedings{lopez2017gradient,
  title={Gradient Episodic Memory for Continual Learning},
  author={Lopez-Paz, David and others},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6470--6479},
  year={2017}
}

@book{thrun1996explanation,
  title={Explanation-based neural network learning: A lifelong learning approach},
  author={Thrun, Sebastian},
  volume={357},
  year={1996},
  publisher={Springer Science \& Business Media}
}

@article{kaiser2017learning,
  title={Learning to remember rare events},
  author={Kaiser, {\L}ukasz and Nachum, Ofir and Roy, Aurko and Bengio, Samy},
  journal={arXiv preprint arXiv:1703.03129},
  year={2017}
}

@article{rebuffi2016icarl,
  title={iCaRL: Incremental classifier and representation learning},
  author={Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Lampert, Christoph H},
  journal={arXiv preprint arXiv:1611.07725},
  year={2016}
}

% Uses synthetic data to replay by training a gen. model

@article{ramapuram2017lifelong,
  title={Lifelong Generative Modeling},
  author={Ramapuram, Jason and Gregorova, Magda and Kalousis, Alexandros},
  journal={arXiv preprint arXiv:1705.09847},
  year={2017}
}

@inproceedings{silver2013lifelong,
  title={Lifelong Machine Learning Systems: Beyond Learning Algorithms.},
  author={Silver, Daniel L and Yang, Qiang and Li, Lianghao},
  booktitle={AAAI Spring Symposium: Lifelong Machine Learning},
  volume={13},
  pages={05},
  year={2013}
}

% Adding additional parameters for new tasks:

@article{rusu2016progressive,
  title={Progressive neural networks},
  author={Rusu, Andrei A and Rabinowitz, Neil C and Desjardins, Guillaume and Soyer, Hubert and Kirkpatrick, James and Kavukcuoglu, Koray and Pascanu, Razvan and Hadsell, Raia},
  journal={arXiv preprint arXiv:1606.04671},
  year={2016}
}

@article{li2017learning,
  title={Learning without forgetting},
  author={Li, Zhizhong and Hoiem, Derek},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2017},
  publisher={IEEE}
}

@article{rozantsev2016beyond,
  title={Beyond sharing weights for deep domain adaptation},
  author={Rozantsev, Artem and Salzmann, Mathieu and Fua, Pascal},
  journal={arXiv preprint arXiv:1603.06432},
  year={2016}
}

@inproceedings{agostinelli2013adaptive,
  title={Adaptive multi-column deep neural networks with application to robust image denoising},
  author={Agostinelli, Forest and Anderson, Michael R and Lee, Honglak},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1493--1501},
  year={2013}
}

@inproceedings{terekhov2015knowledge,
  title={Knowledge transfer in deep block-modular neural networks},
  author={Terekhov, Alexander V and Montone, Guglielmo and O’Regan, J Kevin},
  booktitle={Conference on Biomimetic and Biohybrid Systems},
  pages={268--279},
  year={2015},
  organization={Springer}
}

@article{aljundi2016expert,
  title={Expert gate: Lifelong learning with a network of experts},
  author={Aljundi, Rahaf and Chakravarty, Punarjay and Tuytelaars, Tinne},
  journal={arXiv preprint arXiv:1611.06194},
  year={2016}
}

% EWC:

@article{nguyen2017variational,
  title={Variational Continual Learning},
  author={Nguyen, Cuong V and Li, Yingzhen and Bui, Thang D and Turner, Richard E},
  journal={arXiv preprint arXiv:1710.10628},
  year={2017}
}


@inproceedings{minka2001expectation,
  author    = {Thomas P. Minka},
  title     = {Expectation Propagation for approximate {B}ayesian inference},
  booktitle = {UAI},
  year      = {2001},
  pages     = {362-369},
 }

@INPROCEEDINGS{Pascanu+Bengio-ICLR2014,
    author = {Pascanu, Razvan and Bengio, Yoshua},
     title = {Revisiting Natural Gradient for Deep Networks},
      year = {2014},
       url = {http://arxiv.org/abs/1301.3584},
  booktitle = {ICLR},
}


@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the National Academy of Sciences},
  pages={201611835},
  year={2017},
  publisher={National Acad Sciences}
}

@article{huszar2017quadratic,
  title={On {Q}uadratic {P}enalties in {E}lastic {W}eight {C}onsolidation},
  author={Husz{\'a}r, Ferenc},
  journal={arXiv preprint arXiv:1712.03847},
  year={2017}
}

% Other methods

@inproceedings{teh2017distral,
  title={Distral: Robust multitask reinforcement learning},
  author={Teh, Yee and Bapst, Victor and Czarnecki, Wojciech M and Quan, John and Kirkpatrick, James and Hadsell, Raia and Heess, Nicolas and Pascanu, Razvan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4499--4509},
  year={2017}
}

@article{rusu2015policy,
  title={Policy distillation},
  author={Rusu, Andrei A and Colmenarejo, Sergio Gomez and Gulcehre, Caglar and Desjardins, Guillaume and Kirkpatrick, James and Pascanu, Razvan and Mnih, Volodymyr and Kavukcuoglu, Koray and Hadsell, Raia},
  journal={arXiv preprint arXiv:1511.06295},
  year={2015}
}

@inproceedings{tessler2017deep,
  title={A Deep Hierarchical Approach to Lifelong Learning in Minecraft.},
  author={Tessler, Chen and Givony, Shahar and Zahavy, Tom and Mankowitz, Daniel J and Mannor, Shie},
  booktitle={AAAI},
  pages={1553--1561},
  year={2017}
}

@article{mccloskey1989catastrophic,
  title={Catastrophic interference in connectionist networks: The sequential learning problem},
  author={McCloskey, Michael and Cohen, Neal J},
  journal={Psychology of learning and motivation},
  volume={24},
  pages={109--165},
  year={1989},
  publisher={Elsevier}
}

% Definitions of Transfer/Continual/Lifelong learning

@article{pan2010survey,
  title={A survey on transfer learning},
  author={Pan, Sinno Jialin and Yang, Qiang},
  journal={IEEE Transactions on knowledge and data engineering},
  volume={22},
  number={10},
  pages={1345--1359},
  year={2010},
  publisher={IEEE}
}

@incollection{caruana1998multitask,
  title={Multitask learning},
  author={Caruana, Rich},
  booktitle={Learning to learn},
  pages={95--133},
  year={1998},
  publisher={Springer}
}

% Misc

%RawBeast
@article{rawbeast,
  title={IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Volodymir and Ward, Tom and
          Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and Legg, Shane and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1802.01561},
  year={2018}
}

% Omniglot
@article{lake2015human,
  title={Human-level concept learning through probabilistic program induction},
  author={Lake, Brenden M and Salakhutdinov, Ruslan and Tenenbaum, Joshua B},
  journal={Science},
  volume={350},
  number={6266},
  pages={1332--1338},
  year={2015},
  publisher={American Association for the Advancement of Science}
}

@article{zeng2019continual,
  title={Continual learning of context-dependent processing in neural networks},
  author={Zeng, Guanxiong and Chen, Yang and Cui, Bo and Yu, Shan},
  journal={Nature Machine Intelligence},
  volume={1},
  number={8},
  pages={364--372},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{saha2021gradient,
  title={Gradient projection memory for continual learning},
  author={Saha, Gobinda and Garg, Isha and Roy, Kaushik},
  journal={arXiv preprint arXiv:2103.09762},
  year={2021}
}

@inproceedings{serra2018overcoming,
  title={Overcoming catastrophic forgetting with hard attention to the task},
  author={Serra, Joan and Suris, Didac and Miron, Marius and Karatzoglou, Alexandros},
  booktitle={International Conference on Machine Learning},
  pages={4548--4557},
  year={2018},
  organization={PMLR}
}

% Same dataset split + augmentation for Omniglot
@inproceedings{koch2015siamese,
  title={Siamese neural networks for one-shot image recognition},
  author={Koch, Gregory and Zemel, Richard and Salakhutdinov, Ruslan},
  booktitle={ICML Deep Learning Workshop},
  volume={2},
  year={2015}
}

% Model architecture for Omniglot
@inproceedings{vinyals2016matching,
  title={Matching networks for one shot learning},
  author={Vinyals, Oriol and Blundell, Charles and Lillicrap, Tim and Wierstra, Daan and others},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3630--3638},
  year={2016}
}

% Model architecture for Atari+Lab
@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

% Atari
@inproceedings{bellemare2012investigating,
  title={Investigating Contingency Awareness Using Atari 2600 Games.},
  author={Bellemare, Marc G and Veness, Joel and Bowling, Michael},
  booktitle={AAAI},
  year={2012}
}

% Lab
@article{beattie2016deepmind,
  title={Deepmind lab},
  author={Beattie, Charles and Leibo, Joel Z and Teplyashin, Denis and Ward, Tom and Wainwright, Marcus and K{\"u}ttler, Heinrich and Lefrancq, Andrew and Green, Simon and Vald{\'e}s, V{\'\i}ctor and Sadik, Amir and others},
  journal={arXiv preprint arXiv:1612.03801},
  year={2016}
}

@article{graves2016hybrid,
  title={Hybrid computing using a neural network with dynamic external memory},
  author={Graves, Alex and Wayne, Greg and Reynolds, Malcolm and Harley, Tim and Danihelka, Ivo and Grabska-Barwi{\'n}ska, Agnieszka and Colmenarejo, Sergio G{\'o}mez and Grefenstette, Edward and Ramalho, Tiago and Agapiou, John and others},
  journal={Nature},
  volume={538},
  number={7626},
  pages={471--476},
  year={2016},
  publisher={Nature Research}
}

@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  volume={1},
  number={1},
  year={1998},
  publisher={MIT press Cambridge}
}

@book{mackay2003information,
  title={Information theory, inference and learning algorithms},
  author={MacKay, David JC},
  year={2003},
  publisher={Cambridge university press}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@inproceedings{li2015stochastic,
  title={Stochastic expectation propagation},
  author={Li, Yingzhen and Hern{\'a}ndez-Lobato, Jos{\'e} Miguel and Turner, Richard E},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2323--2331},
  year={2015}
}

@article{FurlanelloZSIT16,
  author    = {Tommaso Furlanello and
               Jiaping Zhao and
               Andrew M. Saxe and
               Laurent Itti and
               Bosco S. Tjan},
  title     = {Active Long Term Memory Networks},
  journal   = {CoRR},
  volume    = {abs/1606.02355},
  year      = {2016},
  }
  
@article{divideconquerrl2017,
  author    = {Dibya Ghosh and
               Avi Singh and
               Aravind Rajeswaran and
               Vikash Kumar and
               Sergey Levine},
  title     = {Divide-and-Conquer Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1711.09874},
  year      = {2017},
}

@article{shu2017,
  author    = {Tianmin Shu and Caiming Xiong and Richard Socher},
  title     = {Hierarchical and Interpretable Skill Acquisition in Multi-task Reinforcement Learning
},
  journal   = {CoRR},
  volume    = {abs/1712.07294},
  year      = {2017},
}

@Article{AAAIMag11-Taylor,
  Author="Matthew E.\ Taylor and Peter Stone",
  title="An Introduction to Inter-task Transfer for Reinforcement Learning",
  journal="{AI} Magazine",
  year="2011",
  volume="32",
  number="1",
  pages="15--34",
}

@Book{Ring1995,
  author =   {Ring, Mark B.},
  title =    {Continual Learning in Reinforcement Environments},
  publisher =    {R.\ Oldenbourg Verlag},
  year =   1995,
}

@inproceedings{mnih2016a3c,
	author = {Volodymyr Mnih and Adrià Puigdomènech Badia and Mehdi Mirza and Alex Graves and Timothy P. Lillicrap and Tim Harley and David Silver and Koray Kavukcuoglu},
	booktitle = {Int'l Conf. on Machine Learning (ICML)},
	year={2016},
	title = {Asynchronous Methods for Deep Reinforcement Learning},
}

@article{schwarz2018progress,
  title={Progress \& Compress: A scalable framework for continual learning},
  author={Schwarz, Jonathan and Luketina, Jelena and Czarnecki, Wojciech M and Grabska-Barwinska, Agnieszka and Teh, Yee Whye and Pascanu, Razvan and Hadsell, Raia},
  journal={arXiv preprint arXiv:1805.06370},
  year={2018}
}
@article{louizos2017learning,
  title={Learning Sparse Neural Networks through $ L\_0 $ Regularization},
  author={Louizos, Christos and Welling, Max and Kingma, Diederik P},
  journal={arXiv preprint arXiv:1712.01312},
  year={2017}
}

@inproceedings{kusupati2020soft,
  title={Soft threshold weight reparameterization for learnable sparsity},
  author={Kusupati, Aditya and Ramanujan, Vivek and Somani, Raghav and Wortsman, Mitchell and Jain, Prateek and Kakade, Sham and Farhadi, Ali},
  booktitle={International Conference on Machine Learning},
  pages={5544--5555},
  year={2020},
  organization={PMLR}
}

@article{wortsman2019discovering,
  title={Discovering neural wirings},
  author={Wortsman, Mitchell and Farhadi, Ali and Rastegari, Mohammad},
  journal={arXiv preprint arXiv:1906.00586},
  year={2019}
}

@article{frankle2018lottery,
  title={The lottery ticket hypothesis: Finding sparse, trainable neural networks},
  author={Frankle, Jonathan and Carbin, Michael},
  journal={arXiv preprint arXiv:1803.03635},
  year={2018}
}

@article{bellec2017deep,
  title={Deep rewiring: Training very sparse deep networks},
  author={Bellec, Guillaume and Kappel, David and Maass, Wolfgang and Legenstein, Robert},
  journal={arXiv preprint arXiv:1711.05136},
  year={2017}
}

@inproceedings{molchanov2017variational,
  title={Variational dropout sparsifies deep neural networks},
  author={Molchanov, Dmitry and Ashukha, Arsenii and Vetrov, Dmitry},
  booktitle={International Conference on Machine Learning},
  pages={2498--2507},
  year={2017},
  organization={PMLR}
}

@article{isele2018selective,
  title={Selective Experience Replay for Lifelong Learning},
  author={Isele, David and Cosgun, Akansel},
  journal={arXiv preprint arXiv:1802.10269},
  year={2018}
}

@inproceedings{lake2011one,
  title={One shot learning of simple visual concepts},
  author={Lake, Brenden and Salakhutdinov, Ruslan and Gross, Jason and Tenenbaum, Joshua},
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume={33},
  number={33},
  year={2011}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{schmidhuber2013powerplay,
  title={Powerplay: Training an increasingly general problem solver by continually searching for the simplest still unsolvable problem},
  author={Schmidhuber, J{\"u}rgen},
  journal={Frontiers in psychology},
  volume={4},
  pages={313},
  year={2013},
  publisher={Frontiers}
}


@phdthesis{ring1994continual,
  title={Continual learning in reinforcement environments},
  author={Ring, Mark Bishop},
  year={1994},
  school={University of Texas at Austin Austin, Texas 78712}
}

@article{zenke2017continual,
  title={Continual learning through synaptic intelligence},
  author={Zenke, Friedemann and Poole, Ben and Ganguli, Surya},
  journal={arXiv preprint arXiv:1703.04200},
  year={2017}
}

@article{kaplanis2018continual,
  title={Continual Reinforcement Learning with Complex Synapses},
  author={Kaplanis, Christos and Shanahan, Murray and Clopath, Claudia},
  journal={arXiv preprint arXiv:1802.07239},
  year={2018}
}

@article{robins1998catastrophic,
  title={Catastrophic forgetting and the pseudorehearsal solution in Hopfield-type networks},
  author={Robins, Anthony and McCallum, Simon},
  journal={Connection Science},
  volume={10},
  number={2},
  pages={121--135},
  year={1998},
  publisher={Taylor \& Francis}
}

@article{farquhar2018towards,
  title={Towards {R}obust {E}valuations of {C}ontinual {L}earning},
  author={Farquhar, Sebastian and Gal, Yarin},
  journal={arXiv preprint arXiv:1805.09733},
  year={2018}
}

@inproceedings{bachem2015coresets,
  title={Coresets for {N}onparametric {E}stimation-the {C}ase of {DP}-Means.},
  author={Bachem, Olivier and Lucic, Mario and Krause, Andreas},
  booktitle={ICML},
  pages={209--217},
  year={2015}
}

@inproceedings{rebuffi2017icarl,
  title={icarl: Incremental classifier and representation learning},
  author={Rebuffi, Sylvestre-Alvise and Kolesnikov, Alexander and Sperl, Georg and Lampert, Christoph H},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={5533--5542},
  year={2017},
  organization={IEEE}
}

@article{al2017continuous,
  title={Continuous adaptation via meta-learning in nonstationary and competitive environments},
  author={Al-Shedivat, Maruan and Bansal, Trapit and Burda, Yuri and Sutskever, Ilya and Mordatch, Igor and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1710.03641},
  year={2017}
}

@inproceedings{eskin2004laplace,
  title={Laplace propagation},
  author={Eskin, Eleazar and Smola, Alex J and Vishwanathan, SVN},
  booktitle={Advances in neural information processing systems},
  pages={441--448},
  year={2004}
}

@inproceedings{itti2006bayesian,
  title={Bayesian surprise attracts human attention},
  author={Itti, Laurent and Baldi, Pierre F},
  booktitle={Advances in neural information processing systems},
  pages={547--554},
  year={2006}
}

@article{maaten2008visualizing,
  title={Visualizing data using t-SNE},
  author={Maaten, Laurens van der and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={Nov},
  pages={2579--2605},
  year={2008}
}

@article{garnelo2018neural,
  title={Neural processes},
  author={Garnelo, Marta and Schwarz, Jonathan and Rosenbaum, Dan and Viola, Fabio and Rezende, Danilo J and Eslami, SM and Teh, Yee Whye},
  journal={arXiv preprint arXiv:1807.01622},
  year={2018}
}

@inproceedings{yu2020meta,
  title={Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  author={Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={1094--1100},
  year={2020},
  organization={PMLR}
}

@inproceedings{Vaskevicius2019,
 author={Vaskevicius, Tomas and Kanade, Varun and Rebeschini, Patrick},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Implicit Regularization for Optimal Sparse Recovery},
 url = {https://proceedings.neurips.cc/paper/2019/file/5cf21ce30208cfffaa832c6e44bb567d-Paper.pdf},
 volume = {32},
 year = {2019}
}

@misc{zhao2019,
      title={Implicit Regularization via Hadamard Product Over-Parametrization in High-Dimensional Linear Regression}, 
      author={Peng Zhao and Yun Yang and Qiao-Chu He},
      year={2019},
      eprint={1903.09367},
      archivePrefix={arXiv},
      primaryClass={math.ST}
}


@inproceedings{Gunasekar2017,
 author = {Gunasekar, Suriya and Woodworth, Blake E and Bhojanapalli, Srinadh and Neyshabur, Behnam and Srebro, Nati},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Implicit Regularization in Matrix Factorization},
 url = {https://proceedings.neurips.cc/paper/2017/file/58191d2a914c6dae66371c9dcdc91b41-Paper.pdf},
 volume = {30},
 year = {2017}
}

@InProceedings{Li2018, 
title = {Algorithmic Regularization in Over-parameterized Matrix Sensing and Neural Networks with Quadratic Activations}, 
author = {Li, Yuanzhi and Ma, Tengyu and Zhang, Hongyang}, 
booktitle = {Proceedings of the 31st Conference On Learning Theory}, 
pages = {2--47}, 
year = {2018}, 
 }
 
@article{Beck2003,
author = {Beck, Amir and Teboulle, Marc},
title = {Mirror Descent and Nonlinear Projected Subgradient Methods for Convex Optimization},
year = {2003},
volume = {31},
number = {3},
journal = {Oper. Res. Lett.},
month = may,
pages = {167–175},
numpages = {9},
}

@inproceedings{Desjardins2015,
 author = {Desjardins, Guillaume and Simonyan, Karen and Pascanu, Razvan and kavukcuoglu, koray},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Natural Neural Networks},
 volume = {28},
 year = {2015}
}

@inproceedings{
Flennerhag2020,
title={Meta-Learning with Warped Gradient Descent},
author={Sebastian Flennerhag and Andrei A. Rusu and Razvan Pascanu and Francesco Visin and Hujun Yin and Raia Hadsell},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rkeiQlBFPB}
}

@InProceedings{LeCun86,
author="LeCun, Yann",
title="Learning Process in an Asymmetric Threshold Network",
booktitle="Disordered Systems and Biological Organization",
year="1986",
publisher="Springer Berlin Heidelberg",
pages="233--240",
}

@book{LeCun87,
title = "PhD thesis: Modeles connexionnistes de l'apprentissage (connectionist learning models)",
author = "Yann Lecun",
year = "1987",
month = jun,
language = "English (US)",
publisher = "Universite P. et M. Curie (Paris 6)",
}

@InProceedings{perpinan14, 
title = {{Distributed optimization of deeply nested systems}}, 
author = {Miguel Carreira-Perpinan and Weiran Wang}, 
booktitle = {Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics}, 
pages = {10--19}, 
year = {2014}, 
}
@inproceedings{LeeZBB14,
  author    = {Dong{-}Hyun Lee and
               Saizheng Zhang and
               Antoine Biard and
               Yoshua Bengio},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Target Propagation},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Workshop Track Proceedings},
  year      = {2015},
  }