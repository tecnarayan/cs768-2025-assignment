@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

@article{bottou2018optimization,
  title={Optimization methods for large-scale machine learning},
  author={Bottou, L{\'e}on and Curtis, Frank E and Nocedal, Jorge},
  journal={Siam Review},
  volume={60},
  number={2},
  pages={223--311},
  year={2018},
  publisher={SIAM}
}

@article{robbins1951stochastic,
  title={A stochastic approximation method},
  author={Robbins, Herbert and Monro, Sutton},
  journal={The annals of mathematical statistics},
  pages={400--407},
  year={1951},
  publisher={JSTOR}
}

@article{gurbuzbalaban2017convergence,
  title={On the convergence rate of incremental aggregated gradient algorithms},
  author={Gurbuzbalaban, Mert and Ozdaglar, Asuman and Parrilo, Pablo A},
  journal={SIAM Journal on Optimization},
  volume={27},
  number={2},
  pages={1035--1048},
  year={2017},
  publisher={SIAM}
}

@article{schmidt2017minimizing,
  title={Minimizing finite sums with the stochastic average gradient},
  author={Schmidt, Mark and Le Roux, Nicolas and Bach, Francis},
  journal={Mathematical Programming},
  volume={162},
  number={1-2},
  pages={83--112},
  year={2017},
  publisher={Springer}
}

@article{johnson2013accelerating,
  title={Accelerating stochastic gradient descent using predictive variance reduction},
  author={Johnson, Rie and Zhang, Tong},
  journal={Advances in neural information processing systems},
  volume={26},
  pages={315--323},
  year={2013},
  publisher={Citeseer}
}

@article{defazio2014saga,
  title={{SAGA}: A fast incremental gradient method with support for non-strongly convex composite objectives},
  author={Defazio, Aaron and Bach, Francis and Lacoste-Julien, Simon},
  journal={arXiv preprint arXiv:1407.0202},
  year={2014}
}

@inproceedings{defazio2014finito,
  title={Finito: A faster, permutable incremental gradient method for big data problems},
  author={Defazio, Aaron and Domke, Justin and others},
  booktitle={International Conference on Machine Learning},
  pages={1125--1133},
  year={2014},
  organization={PMLR}
}

@article{mairal2015incremental,
  title={Incremental majorization-minimization optimization with application to large-scale machine learning},
  author={Mairal, Julien},
  journal={SIAM Journal on Optimization},
  volume={25},
  number={2},
  pages={829--855},
  year={2015},
  publisher={SIAM}
}

@inproceedings{ouyang2013stochastic,
  title={Stochastic alternating direction method of multipliers},
  author={Ouyang, Hua and He, Niao and Tran, Long and Gray, Alexander},
  booktitle={International Conference on Machine Learning},
  pages={80--88},
  year={2013},
  organization={PMLR}
}

@inproceedings{bottou2009curiously,
  title={Curiously fast convergence of some stochastic gradient descent algorithms},
  author={Bottou, L{\'e}on},
  booktitle={Proceedings of the symposium on learning and data science, Paris},
  volume={8},
  pages={2624--2633},
  year={2009}
}

@article{gurbuzbalaban2019random,
  title={Why random reshuffling beats stochastic gradient descent},
  author={Gurbuzbalaban, Mert and Ozdaglar, Asu and Parrilo, Pablo A},
  journal={Mathematical Programming},
  pages={1--36},
  year={2019},
  publisher={Springer}
}

@article{ying2018stochastic,
  title={Stochastic learning under random reshuffling with constant step-sizes},
  author={Ying, Bicheng and Yuan, Kun and Vlaski, Stefan and Sayed, Ali H},
  journal={IEEE Transactions on Signal Processing},
  volume={67},
  number={2},
  pages={474--489},
  year={2018},
  publisher={IEEE}
}






@article{ying2020variance,
  title={Variance-reduced stochastic learning under random reshuffling},
  author={Ying, Bicheng and Yuan, Kun and Sayed, Ali H},
  journal={IEEE Transactions on Signal Processing},
  volume={68},
  pages={1390--1408},
  year={2020},
  publisher={IEEE}
}

@article{vanli2018global,
  title={Global convergence rate of proximal incremental aggregated gradient methods},
  author={Vanli, N Denizcan and Gurbuzbalaban, Mert and Ozdaglar, Asuman},
  journal={SIAM Journal on Optimization},
  volume={28},
  number={2},
  pages={1282--1300},
  year={2018},
  publisher={SIAM}
}

@article{park2020linear,
  title={Linear convergence of cyclic SAGA},
  author={Park, Youngsuk and Ryu, Ernest K},
  journal={Optimization Letters},
  volume={14},
  number={6},
  pages={1583--1598},
  year={2020},
  publisher={Springer}
}

@inproceedings{rajput2020closing,
  title={Closing the convergence gap of SGD without replacement},
  author={Rajput, Shashank and Gupta, Anant and Papailiopoulos, Dimitris},
  booktitle={International Conference on Machine Learning},
  pages={7964--7973},
  year={2020},
  organization={PMLR}
}

@inproceedings{safran2020good,
  title={How good is SGD with random shuffling?},
  author={Safran, Itay and Shamir, Ohad},
  booktitle={Conference on Learning Theory},
  pages={3250--3284},
  year={2020},
  organization={PMLR}
}

@article{mishchenko2020random,
  title={Random reshuffling: Simple analysis with vast improvements},
  author={Mishchenko, Konstantin and Khaled Ragab Bayoumi, Ahmed and Richt{\'a}rik, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}


@article{chow2017cyclic,
  title={Cyclic coordinate-update algorithms for fixed-point problems: Analysis and applications},
  author={Chow, Yat Tin and Wu, Tianyu and Yin, Wotao},
  journal={SIAM Journal on Scientific Computing},
  volume={39},
  number={4},
  pages={A1280--A1300},
  year={2017},
  publisher={SIAM}
}

@article{tibshirani1996regression,
  title={Regression shrinkage and selection via the lasso},
  author={Tibshirani, Robert},
  journal={Journal of the Royal Statistical Society: Series B (Methodological)},
  volume={58},
  number={1},
  pages={267--288},
  year={1996},
  publisher={Wiley Online Library}
}

@article{yu2011dual,
  title={Dual coordinate descent methods for logistic regression and maximum entropy models},
  author={Yu, Hsiang-Fu and Huang, Fang-Lan and Lin, Chih-Jen},
  journal={Machine Learning},
  volume={85},
  number={1-2},
  pages={41--75},
  year={2011},
  publisher={Springer}
}

@book{boyd2011distributed,
  title={Distributed optimization and statistical learning via the alternating direction method of multipliers},
  author={Boyd, Stephen and Parikh, Neal and Chu, Eric},
  year={2011},
  publisher={Now Publishers Inc}
}

@article{mao2020walkman,
  title={Walkman: A communication-efficient random-walk algorithm for decentralized optimization},
  author={Mao, Xianghui and Yuan, Kun and Hu, Yubin and Gu, Yuantao and Sayed, Ali H and Yin, Wotao},
  journal={IEEE Transactions on Signal Processing},
  volume={68},
  pages={2513--2528},
  year={2020},
  publisher={IEEE}
}

@article{mateos2010distributed,
  title={Distributed sparse linear regression},
  author={Mateos, Gonzalo and Bazerque, Juan Andr{\'e}s and Giannakis, Georgios B},
  journal={IEEE Transactions on Signal Processing},
  volume={58},
  number={10},
  pages={5262--5276},
  year={2010},
  publisher={IEEE}
}

@article{chen2001atomic,
  title={Atomic decomposition by basis pursuit},
  author={Chen, Scott Shaobing and Donoho, David L and Saunders, Michael A},
  journal={SIAM review},
  volume={43},
  number={1},
  pages={129--159},
  year={2001},
  publisher={SIAM}
}

@article{donoho2006compressed,
  title={Compressed sensing},
  author={Donoho, David L},
  journal={IEEE Transactions on information theory},
  volume={52},
  number={4},
  pages={1289--1306},
  year={2006},
  publisher={IEEE}
}

@inproceedings{ma2020understanding,
  title={Understanding the Impact of Model Incoherence on Convergence of Incremental SGD with Random Reshuffle},
  author={Ma, Shaocong and Zhou, Yi},
  booktitle={International Conference on Machine Learning},
  pages={6565--6574},
  year={2020},
  organization={PMLR}
}

@article{mao2018walk,
  title={Walk proximal gradient: An energy-efficient algorithm for consensus optimization},
  author={Mao, Xianghui and Gu, Yuantao and Yin, Wotao},
  journal={IEEE Internet of Things Journal},
  volume={6},
  number={2},
  pages={2048--2060},
  year={2018},
  publisher={IEEE}
}

@article{mokhtari2018surpassing,
  title={Surpassing gradient descent provably: A cyclic incremental method with linear convergence rate},
  author={Mokhtari, Aryan and Gurbuzbalaban, Mert and Ribeiro, Alejandro},
  journal={SIAM Journal on Optimization},
  volume={28},
  number={2},
  pages={1420--1447},
  year={2018},
  publisher={SIAM}
}


@article{Park2020LinearCO,
  title={Linear convergence of cyclic SAGA},
  author={Youngsuk Park and E. K. Ryu},
  journal={Optimization Letters},
  year={2020},
  volume={14},
  pages={1583-1598}
}

@inproceedings{Lin2015AUC,
  title={A Universal Catalyst for First-Order Optimization},
  author={Hongzhou Lin and J. Mairal and Z. Harchaoui},
  booktitle={NIPS},
  year={2015}
}

@article{ryu2017proximal,
  title={Proximal-proximal-gradient method},
  author={Ryu, Ernest K and Yin, Wotao},
  journal={arXiv preprint arXiv:1708.06908},
  year={2017}
}

@article{sun2019general,
  title={General proximal incremental aggregated gradient algorithms: Better and novel results under general scheme},
  author={Sun, Tao and Sun, Yuejiao and Li, Dongsheng and Liao, Qing},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={996--1006},
  year={2019}
}

@article{Yuan2016StochasticGD,
  title={Stochastic gradient descent with finite samples sizes},
  author={Kun Yuan and Bicheng Ying and Stefan Vlaski and A. Sayed},
  journal={2016 IEEE 26th International Workshop on Machine Learning for Signal Processing (MLSP)},
  year={2016},
  pages={1-6}
}

@article{Grbzbalaban2019ConvergenceRO,
  title={Convergence Rate of Incremental Gradient and Incremental Newton Methods},
  author={Mert G{\"u}rb{\"u}zbalaban and A. Ozdaglar and Parrilo, Pablo A },
  journal={SIAM Journal of Optimization},
  year={2019},
  volume={29},
  pages={2542-2565}
}


@article{Vanli2016ASC,
  title={A Stronger Convergence Result on the Proximal Incremental Aggregated Gradient Method},
  author={N. D. Vanli and Mert G{\"u}rb{\"u}zbalaban and A. Ozdaglar},
  journal={arXiv: Optimization and Control},
  year={2016}
}

@inproceedings{zhao2015stochastic,
  title={Stochastic optimization with importance sampling for regularized loss minimization},
  author={Zhao, Peilin and Zhang, Tong},
  booktitle={international conference on machine learning},
  pages={1--9},
  year={2015},
  organization={PMLR}
}

@inproceedings{haochen2019random,
  title={Random shuffling beats sgd after finite epochs},
  author={Haochen, Jeff and Sra, Suvrit},
  booktitle={International Conference on Machine Learning},
  pages={2624--2633},
  year={2019},
  organization={PMLR}
}

@article{wright2020analyzing,
  title={Analyzing random permutations for cyclic coordinate descent},
  author={Wright, Stephen and Lee, Ching-pei},
  journal={Mathematics of Computation},
  volume={89},
  number={325},
  pages={2217--2248},
  year={2020}
}

@article{gurbuzbalaban2017cyclic,
  title={When cyclic coordinate descent outperforms randomized coordinate descent},
  author={Gurbuzbalaban, Mert and Ozdaglar, Asuman and Parrilo, Pablo A and Vanli, Nuri Denizcan},
  year={2017},
  publisher={Neural Information Processing Systems Foundation, Inc.}
}

@article{lee2019random,
  title={Random permutations fix a worst case for cyclic coordinate descent},
  author={Lee, Ching-Pei and Wright, Stephen J},
  journal={IMA Journal of Numerical Analysis},
  volume={39},
  number={3},
  pages={1246--1275},
  year={2019},
  publisher={Oxford University Press}
}

@misc{sun2016worst,
  title={Worst-case Complexity of Cyclic Coordinate Descent},
  author={Sun, R and Ye, Y},
  year={2016},
  publisher={O}
}


@article{Ryu2019ScaledRG,
  title={Scaled Relative Graph: Nonexpansive operators via 2D Euclidean Geometry.},
  author={E. K. Ryu and R. Hannah and Wotao Yin},
  journal={arXiv: Optimization and Control},
  year={2019}
}

@article{HUANG2020124211,
title = {Tight coefficients of averaged operators via scaled relative graph},
journal = {Journal of Mathematical Analysis and Applications},
volume = {490},
number = {1},
pages = {124211},
year = {2020},
author = {Xinmeng Huang and Ernest K. Ryu and Wotao Yin},
}

@article{mishchenko2021proximal,
  title={Proximal and Federated Random Reshuffling},
  author={Mishchenko, Konstantin and Khaled, Ahmed and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:2102.06704},
  year={2021}
}

@article{qian2019miso,
  title={MISO is making a comeback with better proofs and rates},
  author={Qian, Xun and Sailanbayev, Alibek and Mishchenko, Konstantin and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:1906.01474},
  year={2019}
}

@inproceedings{nagaraj2019sgd,
  title={Sgd without replacement: Sharper rates for general smooth convex functions},
  author={Nagaraj, Dheeraj and Jain, Prateek and Netrapalli, Praneeth},
  booktitle={International Conference on Machine Learning},
  pages={4703--4711},
  year={2019},
  organization={PMLR}
}

@article{malinovsky2021random,
  title={Random Reshuffling with Variance Reduction: New Analysis and Better Rates},
  author={Malinovsky, Grigory and Sailanbayev, Alibek and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:2104.09342},
  year={2021}
}


@inproceedings{Krizhevsky2009LearningML,
  title={Learning Multiple Layers of Features from Tiny Images},
  author={A. Krizhevsky},
  year={2009}
}


@article{deng2012mnist,
  title={The mnist database of handwritten digit images for machine learning research},
  author={Deng, Li},
  journal={IEEE Signal Processing Magazine},
  volume={29},
  number={6},
  pages={141--142},
  year={2012},
  publisher={IEEE}
}

@inproceedings{nr,
     title={The Network Data Repository with Interactive Graph Analytics and Visualization},
     author={Ryan A. Rossi and Nesreen K. Ahmed},
     booktitle={AAAI},
     url={http://networkrepository.com},
     year={2015}
}