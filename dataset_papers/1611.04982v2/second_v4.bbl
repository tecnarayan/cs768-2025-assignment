\begin{thebibliography}{17}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal and Bottou(2014)]{agarwal2014lower}
Alekh Agarwal and Leon Bottou.
\newblock A lower bound for the optimization of finite sums.
\newblock \emph{arXiv preprint arXiv:1410.0723}, 2014.

\bibitem[Agarwal et~al.(2016)Agarwal, Bullins, and Hazan]{agarwal2016second}
Naman Agarwal, Brian Bullins, and Elad Hazan.
\newblock Second order stochastic optimization in linear time.
\newblock \emph{arXiv preprint arXiv:1602.03943}, 2016.

\bibitem[Arjevani and Shamir(2015)]{arjevani2015communication}
Yossi Arjevani and Ohad Shamir.
\newblock Communication complexity of distributed convex learning and
  optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1756--1764, 2015.

\bibitem[Arjevani and Shamir(2016{\natexlab{a}})]{arjevani2016dimension}
Yossi Arjevani and Ohad Shamir.
\newblock Dimension-free iteration complexity of finite sum optimization
  problems.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3540--3548, 2016{\natexlab{a}}.

\bibitem[Arjevani and Shamir(2016{\natexlab{b}})]{arjevani2016iteration}
Yossi Arjevani and Ohad Shamir.
\newblock On the iteration complexity of oblivious first-order optimization
  algorithms.
\newblock In \emph{Proceedings of the 33nd International Conference on Machine
  Learning}, pages 908--916, 2016{\natexlab{b}}.

\bibitem[Bollapragada et~al.(2016)Bollapragada, Byrd, and
  Nocedal]{bollapragada2016exact}
Raghu Bollapragada, Richard Byrd, and Jorge Nocedal.
\newblock Exact and inexact subsampled newton methods for optimization.
\newblock \emph{arXiv preprint arXiv:1609.08502}, 2016.

\bibitem[Boyd and Vandenberghe(2004)]{boyd2004convex}
Stephen Boyd and Lieven Vandenberghe.
\newblock \emph{Convex optimization}.
\newblock Cambridge university press, 2004.

\bibitem[Erdogdu and Montanari(2015)]{erdogdu2015convergence}
Murat~A Erdogdu and Andrea Montanari.
\newblock Convergence rates of sub-sampled newton methods.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3052--3060, 2015.

\bibitem[Lan(2015)]{lan2015optimal}
Guanghui Lan.
\newblock An optimal randomized incremental gradient method.
\newblock \emph{arXiv preprint arXiv:1507.02000}, 2015.

\bibitem[Nemirovsky and Yudin(1983)]{YudNem83}
A.~Nemirovsky and D.~Yudin.
\newblock \emph{Problem Complexity and Method Efficiency in Optimization}.
\newblock Wiley-Interscience, 1983.

\bibitem[Nesterov(2013)]{nesterov2013introductory}
Yurii Nesterov.
\newblock \emph{Introductory lectures on convex optimization: A basic course},
  volume~87.
\newblock Springer Science \& Business Media, 2013.

\bibitem[Nocedal and Wright(2006)]{nocedal2006numerical}
Jorge Nocedal and Stephen Wright.
\newblock \emph{Numerical optimization}.
\newblock Springer Science \& Business Media, 2006.

\bibitem[Pilanci and Wainwright(2015)]{pilanci2015newton}
Mert Pilanci and Martin~J Wainwright.
\newblock Newton sketch: A linear-time optimization algorithm with
  linear-quadratic convergence.
\newblock \emph{arXiv preprint arXiv:1505.02250}, 2015.

\bibitem[Roosta-Khorasani and Mahoney(2016{\natexlab{a}})]{roosta2016sub}
Farbod Roosta-Khorasani and Michael~W Mahoney.
\newblock Sub-sampled newton methods i: globally convergent algorithms.
\newblock \emph{arXiv preprint arXiv:1601.04737}, 2016{\natexlab{a}}.

\bibitem[Roosta-Khorasani and Mahoney(2016{\natexlab{b}})]{roosta2016sub2}
Farbod Roosta-Khorasani and Michael~W Mahoney.
\newblock Sub-sampled newton methods ii: Local convergence rates.
\newblock \emph{arXiv preprint arXiv:1601.04738}, 2016{\natexlab{b}}.

\bibitem[Woodworth and Srebro(2016)]{woodworth2016tight}
Blake Woodworth and Nathan Srebro.
\newblock Tight complexity bounds for optimizing composite objectives.
\newblock \emph{arXiv preprint arXiv:1605.08003}, 2016.

\bibitem[Xu et~al.(2016)Xu, Yang, Roosta-Khorasani, R{\'e}, and
  Mahoney]{xu2016sub}
Peng Xu, Jiyan Yang, Farbod Roosta-Khorasani, Christopher R{\'e}, and Michael~W
  Mahoney.
\newblock Sub-sampled newton methods with non-uniform sampling.
\newblock \emph{arXiv preprint arXiv:1607.00559}, 2016.

\end{thebibliography}
