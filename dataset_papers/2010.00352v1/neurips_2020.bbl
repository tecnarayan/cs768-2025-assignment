\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{achille2019task2vec}
Alessandro Achille, Michael Lam, Rahul Tewari, Avinash Ravichandran, Subhransu
  Maji, Charless Fowlkes, Stefano Soatto, and Pietro Perona.
\newblock Task2vec: Task embedding for meta-learning.
\newblock {\em arXiv preprint arXiv:1902.03545}, 2019.

\bibitem{aljundi2018memory}
Rahaf Aljundi, Francesca Babiloni, Mohamed Elhoseiny, Marcus Rohrbach, and
  Tinne Tuytelaars.
\newblock Memory aware synapses: Learning what (not) to forget.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 139--154, 2018.

\bibitem{aljundi2019online}
Rahaf Aljundi, Eugene Belilovsky, Tinne Tuytelaars, Laurent Charlin, Massimo
  Caccia, Min Lin, and Lucas Page-Caccia.
\newblock Online continual learning with maximal interfered retrieval.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  11849--11860, 2019.

\bibitem{aljundi2019gradient}
Rahaf Aljundi, Min Lin, Baptiste Goujaud, and Yoshua Bengio.
\newblock Gradient based sample selection for online continual learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  11816--11825, 2019.

\bibitem{alvarez1994memory}
Pablo Alvarez and Larry~R Squire.
\newblock Memory consolidation and the medial temporal lobe: a simple network
  model.
\newblock {\em Proceedings of the national academy of sciences},
  91(15):7041--7045, 1994.

\bibitem{beaulieu2020learning}
Shawn Beaulieu, Lapo Frati, Thomas Miconi, Joel Lehman, Kenneth~O Stanley, Jeff
  Clune, and Nick Cheney.
\newblock Learning to continually learn.
\newblock {\em arXiv preprint arXiv:2002.09571}, 2020.

\bibitem{becker2018interpreting}
S\"oren Becker, Marcel Ackermann, Sebastian Lapuschkin, Klaus-Robert M\"uller,
  and Wojciech Samek.
\newblock Interpreting and explaining deep neural networks for classification
  of audio signals.
\newblock {\em CoRR}, abs/1807.03418, 2018.

\bibitem{brock2017smash}
Andrew Brock, Theodore Lim, James~M Ritchie, and Nick Weston.
\newblock Smash: one-shot model architecture search through hypernetworks.
\newblock {\em arXiv preprint arXiv:1708.05344}, 2017.

\bibitem{caccia2019online}
Lucas Caccia, Eugene Belilovsky, Massimo Caccia, and Joelle Pineau.
\newblock Online learned continual compression with adaptative quantization
  module.
\newblock {\em arXiv preprint arXiv:1911.08019}, 2019.

\bibitem{caramazza2003organization}
Alfonso Caramazza and Bradford~Z Mahon.
\newblock The organization of conceptual knowledge: the evidence from
  category-specific semantic deficits.
\newblock {\em Trends in cognitive sciences}, 7(8):354--361, 2003.

\bibitem{caramazza1998domain}
Alfonso Caramazza and Jennifer~R Shelton.
\newblock Domain-specific knowledge systems in the brain: The animate-inanimate
  distinction.
\newblock {\em Journal of cognitive neuroscience}, 10(1):1--34, 1998.

\bibitem{castro2018end}
Francisco~M Castro, Manuel~J Mar{\'\i}n-Jim{\'e}nez, Nicol{\'a}s Guil, Cordelia
  Schmid, and Karteek Alahari.
\newblock End-to-end incremental learning.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 233--248, 2018.

\bibitem{chaudhry2018riemannian}
Arslan Chaudhry, Puneet~K Dokania, Thalaiyasingam Ajanthan, and Philip~HS Torr.
\newblock Riemannian walk for incremental learning: Understanding forgetting
  and intransigence.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 532--547, 2018.

\bibitem{AGEM}
Arslan Chaudhry, Marcâ€™Aurelio Ranzato, Marcus Rohrbach, and Mohamed
  Elhoseiny.
\newblock Efficient lifelong learning with a-gem.
\newblock In {\em ICLR}, 2019.

\bibitem{chaudhry2019continual}
Arslan Chaudhry, Marcus Rohrbach, Mohamed Elhoseiny, Thalaiyasingam Ajanthan,
  Puneet~K Dokania, Philip~HS Torr, and Marc'Aurelio Ranzato.
\newblock Continual learning with tiny episodic memories.
\newblock {\em arXiv preprint arXiv:1902.10486}, 2019.

\bibitem{chen2019facilitating}
Yu Chen, Tom Diethe, and Neil Lawrence.
\newblock Facilitating bayesian continual learning by natural gradients and
  stein gradients.
\newblock {\em arXiv preprint arXiv:1904.10644}, 2019.

\bibitem{de2019continual}
Matthias De~Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ales
  Leonardis, Gregory Slabaugh, and Tinne Tuytelaars.
\newblock Continual learning: A comparative study on how to defy forgetting in
  classification tasks.
\newblock {\em arXiv preprint arXiv:1909.08383}, 2019.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee, 2009.

\bibitem{diethe2018continual}
Tom Diethe, Tom Borchert, Eno Thereska, Borja de~Balle Pigem, and Neil
  Lawrence.
\newblock Continual learning in practice.
\newblock In {\em NeurIPS Continual Learning Workshop}, 2018.

\bibitem{duchi2011adaptive}
John Duchi, Elad Hazan, and Yoram Singer.
\newblock Adaptive subgradient methods for online learning and stochastic
  optimization.
\newblock {\em Journal of Machine Learning Research}, 12(Jul):2121--2159, 2011.

\bibitem{ebrahimiuncertainty}
Sayna Ebrahimi, Mohamed Elhoseiny, Trevor Darrell, and Marcus Rohrbach.
\newblock Uncertainty-guided continual learning with bayesian neural networks.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{farajtabar2019orthogonal}
Mehrdad Farajtabar, Navid Azizan, Alex Mott, and Ang Li.
\newblock Orthogonal gradient descent for continual learning, 2019.

\bibitem{finn2017model}
Chelsea Finn, Pieter Abbeel, and Sergey Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 1126--1135. JMLR. org, 2017.

\bibitem{pmlr-v97-finn19a}
Chelsea Finn, Aravind Rajeswaran, Sham Kakade, and Sergey Levine.
\newblock Online meta-learning.
\newblock In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, {\em
  Proceedings of the 36th International Conference on Machine Learning},
  volume~97 of {\em Proceedings of Machine Learning Research}, pages
  1920--1930, Long Beach, California, USA, 09--15 Jun 2019. PMLR.

\bibitem{french1999catastrophic}
Robert~M French.
\newblock Catastrophic forgetting in connectionist networks.
\newblock {\em Trends in cognitive sciences}, 3(4):128--135, 1999.

\bibitem{gonzalez2019can}
Oscar~C Gonzalez, Yury Sokolov, Giri Krishnan, and Maxim Bazhenov.
\newblock Can sleep protect memories from catastrophic forgetting?
\newblock {\em BioRxiv}, page 569038, 2019.

\bibitem{ha2016hypernetworks}
David Ha, Andrew Dai, and Quoc~V Le.
\newblock Hypernetworks.
\newblock {\em arXiv preprint arXiv:1609.09106}, 2016.

\bibitem{handjaras2016concepts}
Giacomo Handjaras, Emiliano Ricciardi, Andrea Leo, Alessandro Lenci, Luca
  Cecchetti, Mirco Cosottini, Giovanna Marotta, and Pietro Pietrini.
\newblock How concepts are encoded in the human brain: a modality independent,
  category-based cortical organization of semantic knowledge.
\newblock {\em Neuroimage}, 135:232--242, 2016.

\bibitem{hayes2019remind}
Tyler~L Hayes, Kushal Kafle, Robik Shrestha, Manoj Acharya, and Christopher
  Kanan.
\newblock Remind your neural network to prevent catastrophic forgetting.
\newblock {\em arXiv preprint arXiv:1910.02509}, 2019.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem{hinton2015distilling}
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean.
\newblock Distilling the knowledge in a neural network.
\newblock {\em arXiv preprint arXiv:1503.02531}, 2015.

\bibitem{hsu2018re}
Yen-Chang Hsu, Yen-Cheng Liu, Anita Ramasamy, and Zsolt Kira.
\newblock Re-evaluating continual learning scenarios: A categorization and case
  for strong baselines.
\newblock {\em arXiv preprint arXiv:1810.12488}, 2018.

\bibitem{hupbach2007reconsolidation}
Almut Hupbach, Rebecca Gomez, Oliver Hardt, and Lynn Nadel.
\newblock Reconsolidation of episodic memories: A subtle reminder triggers
  integration of new information.
\newblock {\em Learning \& memory}, 14(1-2):47--53, 2007.

\bibitem{Javed2019Meta}
Khurram Javed and Martha White.
\newblock Meta-learning representations for continual learning.
\newblock In H. Wallach, H. Larochelle, A. Beygelzimer, E. Fox, and R. Garnett,
  editors, {\em Advances in Neural Information Processing Systems 32}, pages
  1818--1828. Curran Associates, Inc., 2019.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{kingma2014semi}
Durk~P Kingma, Shakir Mohamed, Danilo~Jimenez Rezende, and Max Welling.
\newblock Semi-supervised learning with deep generative models.
\newblock In {\em Advances in neural information processing systems}, pages
  3581--3589, 2014.

\bibitem{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock {\em arXiv preprint arXiv:1312.6114}, 2013.

\bibitem{kirkpatrick2017overcoming}
James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume
  Desjardins, Andrei~A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka
  Grabska-Barwinska, et~al.
\newblock Overcoming catastrophic forgetting in neural networks.
\newblock {\em Proceedings of the national academy of sciences},
  114(13):3521--3526, 2017.

\bibitem{konrad2019sleep}
Carolin Konrad, Nora~D Dirks, Annegret Warmuth, Jane~S Herbert, Silvia
  Schneider, and Sabine Seehagen.
\newblock Sleep-dependent selective imitation in infants.
\newblock {\em Journal of sleep research}, 28(1):e12777, 2019.

\bibitem{kramer1992autoassociative}
Mark~A Kramer.
\newblock Autoassociative neural networks.
\newblock {\em Computers \& chemical engineering}, 16(4):313--328, 1992.

\bibitem{Krizhevsky09learningmultiple}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock {\em Citeseer}, 2009.

\bibitem{Kurle2020Continual}
Richard Kurle, Botond Cseke, Alexej Klushyn, Patrick van~der Smagt, and Stephan
  GÃ¼nnemann.
\newblock Continual learning with bayesian neural networks for non-stationary
  data.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{lecun1998mnist}
Yann LeCun.
\newblock The mnist database of handwritten digits.
\newblock {\em http://yann. lecun. com/exdb/mnist/}, 1998.

\bibitem{Lee2020A}
Soochan Lee, Junsoo Ha, Dongsu Zhang, and Gunhee Kim.
\newblock A neural dirichlet process mixture model for task-free continual
  learning.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{lesort2018generative}
Timoth{\'e}e Lesort, Hugo Caselles-Dupr{\'e}, Michael Garcia-Ortiz,
  Jean-Fran{\c c}ois Goudou, and David Filliat.
\newblock Generative models from the perspective of continual learning.
\newblock In {\em {IJCNN - International Joint Conference on Neural Networks}},
  Budapest, Hungary, Jul 2019.

\bibitem{lesort2018marginal}
Timoth{\'e}e Lesort, Alexander Gepperth, Andrei Stoian, and David Filliat.
\newblock Marginal replay vs conditional replay for continual learning.
\newblock In {\em International Conference on Artificial Neural Networks},
  pages 466--480. Springer, 2019.

\bibitem{li2018learning}
Zhizhong Li and Derek Hoiem.
\newblock Learning without forgetting.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  40(12):2935--2947, 2018.

\bibitem{lopez2017gradient}
David Lopez-Paz and Marc'Aurelio Ranzato.
\newblock Gradient episodic memory for continual learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6467--6476, 2017.

\bibitem{maaten2008visualizing}
Laurens van~der Maaten and Geoffrey Hinton.
\newblock Visualizing data using t-sne.
\newblock {\em Journal of machine learning research}, 9(Nov):2579--2605, 2008.

\bibitem{mahon2009category}
Bradford~Z Mahon, Stefano Anzellotti, Jens Schwarzbach, Massimiliano Zampini,
  and Alfonso Caramazza.
\newblock Category-specific organization in the human brain does not require
  visual experience.
\newblock {\em Neuron}, 63(3):397--405, 2009.

\bibitem{mallya2018packnet}
Arun Mallya and Svetlana Lazebnik.
\newblock Packnet: Adding multiple tasks to a single network by iterative
  pruning.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 7765--7773, 2018.

\bibitem{mccloskey1989catastrophic}
Michael McCloskey and Neal~J Cohen.
\newblock Catastrophic interference in connectionist networks: The sequential
  learning problem.
\newblock In {\em Psychology of learning and motivation}, volume~24, pages
  109--165. Elsevier, 1989.

\bibitem{mikolov2013distributed}
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg~S Corrado, and Jeff Dean.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In {\em Advances in neural information processing systems}, pages
  3111--3119, 2013.

\bibitem{mishra2017simple}
Nikhil Mishra, Mostafa Rohaninejad, Xi Chen, and Pieter Abbeel.
\newblock A simple neural attentive meta-learner.
\newblock {\em arXiv preprint arXiv:1707.03141}, 2017.

\bibitem{nguyen2017variational}
Cuong~V Nguyen, Yingzhen Li, Thang~D Bui, and Richard~E Turner.
\newblock Variational continual learning.
\newblock {\em arXiv preprint arXiv:1710.10628}, 2017.

\bibitem{nichol2018reptile}
Alex Nichol and John Schulman.
\newblock Reptile: a scalable metalearning algorithm.
\newblock {\em arXiv preprint arXiv:1803.02999}, 2, 2018.

\bibitem{pal2019zero}
Arghya Pal and Vineeth~N Balasubramanian.
\newblock Zero-shot task transfer.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 2189--2198, 2019.

\bibitem{parisi2019continual}
German~I Parisi, Ronald Kemker, Jose~L Part, Christopher Kanan, and Stefan
  Wermter.
\newblock Continual lifelong learning with neural networks: A review.
\newblock {\em Neural Networks}, 2019.

\bibitem{paszke2017automatic}
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary
  DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
\newblock Automatic differentiation in {PyTorch}.
\newblock In {\em NIPS Autodiff Workshop}, 2017.

\bibitem{pennington2014glove}
Jeffrey Pennington, Richard Socher, and Christopher~D. Manning.
\newblock Glove: Global vectors for word representation.
\newblock In {\em Empirical Methods in Natural Language Processing (EMNLP)},
  pages 1532--1543, 2014.

\bibitem{Rajasegaran2019Random}
Jathushan Rajasegaran, Munawar Hayat, Salman~H. Khan, Fahad~Shahbaz Khan, and
  Ling Shao.
\newblock Random path selection for incremental learning.
\newblock {\em CoRR}, abs/1906.01120, 2019.

\bibitem{rebuffi2017icarl}
Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and Christoph~H
  Lampert.
\newblock icarl: Incremental classifier and representation learning.
\newblock In {\em 2017 IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pages 5533--5542. IEEE, 2017.

\bibitem{riemer2018learning}
Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu, Irina Rish, Yuhai Tu,
  and Gerald Tesauro.
\newblock Learning to learn without forgetting by maximizing transfer and
  minimizing interference.
\newblock {\em arXiv preprint arXiv:1810.11910}, 2018.

\bibitem{robins1996consolidation}
Anthony Robins.
\newblock Consolidation in neural networks and in the sleeping brain.
\newblock {\em Connection Science}, 8(2):259--276, 1996.

\bibitem{rolnick2019experience}
David Rolnick, Arun Ahuja, Jonathan Schwarz, Timothy Lillicrap, and Gregory
  Wayne.
\newblock Experience replay for continual learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  348--358, 2019.

\bibitem{rosenbaum2017routing}
Clemens Rosenbaum, Tim Klinger, and Matthew Riemer.
\newblock Routing networks: Adaptive selection of non-linear functions for
  multi-task learning.
\newblock {\em arXiv preprint arXiv:1711.01239}, 2017.

\bibitem{rosenfeld2018incremental}
Amir Rosenfeld and John~K. Tsotsos.
\newblock Incremental learning through deep adaptation, 2018.

\bibitem{rusu2016progressive}
Andrei~A Rusu, Neil~C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James
  Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell.
\newblock Progressive neural networks.
\newblock {\em arXiv preprint arXiv:1606.04671}, 2016.

\bibitem{santoro2016meta}
Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy
  Lillicrap.
\newblock Meta-learning with memory-augmented neural networks.
\newblock In {\em ICML}, pages 1842--1850, 2016.

\bibitem{schwarz2018progress}
Jonathan Schwarz, Jelena Luketina, Wojciech~M Czarnecki, Agnieszka
  Grabska-Barwinska, Yee~Whye Teh, Razvan Pascanu, and Raia Hadsell.
\newblock Progress \& compress: A scalable framework for continual learning.
\newblock {\em arXiv preprint arXiv:1805.06370}, 2018.

\bibitem{serra2018overcoming}
Joan Serr{\`a}, D{\'\i}dac Sur{\'\i}s, Marius Miron, and Alexandros
  Karatzoglou.
\newblock Overcoming catastrophic forgetting with hard attention to the task.
\newblock {\em arXiv preprint arXiv:1801.01423}, 2018.

\bibitem{shen2018neural}
Falong Shen, Shuicheng Yan, and Gang Zeng.
\newblock Neural style transfer via meta networks.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 8061--8069, 2018.

\bibitem{shin2017continual}
Hanul Shin, Jung~Kwon Lee, Jaehong Kim, and Jiwon Kim.
\newblock Continual learning with deep generative replay.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2990--2999, 2017.

\bibitem{snell2017prototypical}
Jake Snell, Kevin Swersky, and Richard Zemel.
\newblock Prototypical networks for few-shot learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4077--4087, 2017.

\bibitem{squire2015memory}
Larry~R Squire, Lisa Genzel, John~T Wixted, and Richard~G Morris.
\newblock Memory consolidation.
\newblock {\em Cold Spring Harbor perspectives in biology}, 7(8):a021766, 2015.

\bibitem{sung2018learning}
Flood Sung, Yongxin Yang, Li Zhang, Tao Xiang, Philip~HS Torr, and Timothy~M
  Hospedales.
\newblock Learning to compare: Relation network for few-shot learning.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 1199--1208, 2018.

\bibitem{tamminen2010sleep}
Jakke Tamminen, Jessica~D Payne, Robert Stickgold, Erin~J Wamsley, and M~Gareth
  Gaskell.
\newblock Sleep spindle activity is associated with the integration of new
  memories and existing knowledge.
\newblock {\em Journal of Neuroscience}, 30(43):14356--14360, 2010.

\bibitem{titsias2019functional}
Michalis~K Titsias, Jonathan Schwarz, Alexander G de~G Matthews, Razvan
  Pascanu, and Yee~Whye Teh.
\newblock Functional regularisation for continual learning with gaussian
  processes.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{van2019three}
Gido~M van~de Ven and Andreas~S Tolias.
\newblock Three scenarios for continual learning.
\newblock {\em arXiv preprint arXiv:1904.07734}, 2019.

\bibitem{Ven2018GenerativeRW}
Michiel van~der Ven and Andreas~S. Tolias.
\newblock Generative replay with feedback connections as a general strategy for
  continual learning.
\newblock {\em ArXiv}, abs/1809.10635, 2018.

\bibitem{verma2019meta}
Vinay~Kumar Verma, Dhanajit Brahma, and Piyush Rai.
\newblock A meta-learning framework for generalized zero-shot learning.
\newblock {\em arXiv preprint arXiv:1909.04344}, 2019.

\bibitem{vinyals2016matching}
Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et~al.
\newblock Matching networks for one shot learning.
\newblock In {\em Advances in neural information processing systems}, pages
  3630--3638, 2016.

\bibitem{von2019continual}
Johannes von Oswald, Christian Henning, Jo{\~a}o Sacramento, and Benjamin~F
  Grewe.
\newblock Continual learning with hypernetworks.
\newblock {\em arXiv preprint arXiv:1906.00695}, 2019.

\bibitem{wilson1994reactivation}
Matthew~A Wilson and Bruce~L McNaughton.
\newblock Reactivation of hippocampal ensemble memories during sleep.
\newblock {\em Science}, 265(5172):676--679, 1994.

\bibitem{wixted2004psychology}
John~T Wixted.
\newblock The psychology and neuroscience of forgetting.
\newblock {\em Annu. Rev. Psychol.}, 55:235--269, 2004.

\bibitem{yoon2019oracle}
Jaehong Yoon, Saehoon Kim, Eunho Yang, and Sung~Ju Hwang.
\newblock Oracle: Order robust adaptive continual learning.
\newblock {\em arXiv preprint arXiv:1902.09432}, 2019.

\bibitem{zenke2017continual}
Friedemann Zenke, Ben Poole, and Surya Ganguli.
\newblock Continual learning through synaptic intelligence.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 3987--3995. JMLR. org, 2017.

\bibitem{zhang2019side}
Jeffrey~O Zhang, Alexander Sax, Amir Zamir, Leonidas Guibas, and Jitendra
  Malik.
\newblock Side-tuning: Network adaptation via additive side networks.
\newblock {\em arXiv preprint arXiv:1912.13503}, 2019.

\bibitem{zintgraf2019fast}
Luisa Zintgraf, Kyriacos Shiarli, Vitaly Kurin, Katja Hofmann, and Shimon
  Whiteson.
\newblock Fast context adaptation via meta-learning.
\newblock In {\em International Conference on Machine Learning}, pages
  7693--7702, 2019.

\end{thebibliography}
