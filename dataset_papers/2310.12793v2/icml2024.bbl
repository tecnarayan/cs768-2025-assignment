\begin{thebibliography}{102}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alhamoud et~al.(2023)Alhamoud, Hammoud, Alfarra, and
  Ghanem]{alhamoud_generalizability_2023}
Alhamoud, K., Hammoud, H. A. A.~K., Alfarra, M., and Ghanem, B.
\newblock Generalizability of {Adversarial} {Robustness} {Under} {Distribution}
  {Shifts}.
\newblock \emph{Transactions on Machine Learning Research (TMLR)}, May 2023.

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and
  Wagner]{athalye_obfuscated_2018}
Athalye, A., Carlini, N., and Wagner, D.
\newblock Obfuscated {Gradients} {Give} a {False} {Sense} of {Security}:
  {Circumventing} {Defenses} to {Adversarial} {Examples}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, July
  2018.

\bibitem[Augustin et~al.(2020)Augustin, Meinke, and
  Hein]{vedaldi_adversarial_2020}
Augustin, M., Meinke, A., and Hein, M.
\newblock Adversarial {Robustness} on {In}- and {Out}-{Distribution} {Improves}
  {Explainability}.
\newblock In \emph{European Conference on Computer Vision (ECCV)}, 2020.

\bibitem[Baek et~al.(2022)Baek, Jiang, Raghunathan, and
  Kolter]{baek_agreementontheline_2022}
Baek, C., Jiang, Y., Raghunathan, A., and Kolter, J.~Z.
\newblock Agreement-on-the-line: Predicting the performance of neural networks
  under distribution shift.
\newblock In \emph{Advances in {{Neural Information Processing Systems}}},
  volume~35, pp.\  19274--19289, 2022.

\bibitem[Bai et~al.(2023)Bai, Anderson, Kim, and Sojoudi]{bai_improving_2023}
Bai, Y., Anderson, B.~G., Kim, A., and Sojoudi, S.
\newblock Improving the {Accuracy}-{Robustness} {Trade}-{Off} of {Classifiers}
  via {Adaptive} {Smoothing}, May 2023.

\bibitem[Barbu et~al.(2019)Barbu, Mayo, Alverio, Luo, Wang, Gutfreund,
  Tenenbaum, and Katz]{barbu_objectnet_2019}
Barbu, A., Mayo, D., Alverio, J., Luo, W., Wang, C., Gutfreund, D., Tenenbaum,
  J., and Katz, B.
\newblock {ObjectNet}: {A} large-scale bias-controlled dataset for pushing the
  limits of object recognition models.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, 2019.

\bibitem[Carmon et~al.(2019)Carmon, Raghunathan, Schmidt, Duchi, and
  Liang]{carmon_unlabeled_2019}
Carmon, Y., Raghunathan, A., Schmidt, L., Duchi, J.~C., and Liang, P.~S.
\newblock Unlabeled {Data} {Improves} {Adversarial} {Robustness}.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, 2019.

\bibitem[Croce \& Hein(2020)Croce and Hein]{croce_reliable_2020}
Croce, F. and Hein, M.
\newblock Reliable {Evaluation} of {Adversarial} {Robustness} with an
  {Ensemble} of {Diverse} {Parameter}-free {Attacks}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.

\bibitem[Croce \& Hein(2022)Croce and Hein]{croce2022adversarial}
Croce, F. and Hein, M.
\newblock Adversarial robustness against multiple and single $ l\_p $-threat
  models via quick fine-tuning of robust classifiers.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  4436--4454. PMLR, 2022.

\bibitem[Croce et~al.(2021)Croce, Andriushchenko, Sehwag, Debenedetti,
  Flammarion, Chiang, Mittal, and Hein]{croce_robustbench_2021}
Croce, F., Andriushchenko, M., Sehwag, V., Debenedetti, E., Flammarion, N.,
  Chiang, M., Mittal, P., and Hein, M.
\newblock {RobustBench}: a standardized adversarial robustness benchmark.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, October
  2021.

\bibitem[Croce et~al.(2022)Croce, Gowal, Brunner, Shelhamer, Hein, and
  Cemgil]{croce2022evaluating}
Croce, F., Gowal, S., Brunner, T., Shelhamer, E., Hein, M., and Cemgil, T.
\newblock Evaluating the adversarial robustness of adaptive test-time defenses.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  4421--4435. PMLR, 2022.

\bibitem[Cubuk et~al.(2019)Cubuk, Zoph, Mane, Vasudevan, and
  Le]{cubuk_autoaugment_2019}
Cubuk, E.~D., Zoph, B., Mane, D., Vasudevan, V., and Le, Q.~V.
\newblock {AutoAugment}: {Learning} {Augmentation} {Strategies} {From} {Data}.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2019.

\bibitem[Cui et~al.(2023)Cui, Tian, Zhong, Qi, Yu, and
  Zhang]{cui_decoupled_2023}
Cui, J., Tian, Z., Zhong, Z., Qi, X., Yu, B., and Zhang, H.
\newblock Decoupled {Kullback}-{Leibler} {Divergence} {Loss}, May 2023.

\bibitem[Dai et~al.(2022)Dai, Mahloujifar, and Mittal]{dai_formulating_2022}
Dai, S., Mahloujifar, S., and Mittal, P.
\newblock Formulating {Robustness} {Against} {Unforeseen} {Attacks}.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, December
  2022.

\bibitem[Dai et~al.(2023)Dai, Mahloujifar, Xiang, Sehwag, Chen, and
  Mittal]{dai_multirobustbench_2023}
Dai, S., Mahloujifar, S., Xiang, C., Sehwag, V., Chen, P.-Y., and Mittal, P.
\newblock {MultiRobustBench}: {Benchmarking} {Robustness} {Against} {Multiple}
  {Attacks}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, May
  2023.

\bibitem[Darlow et~al.(2018)Darlow, Crowley, Antoniou, and
  Storkey]{darlow_cinic-10_2018}
Darlow, L.~N., Crowley, E.~J., Antoniou, A., and Storkey, A.~J.
\newblock {CINIC}-10 is not {ImageNet} or {CIFAR}-10, October 2018.

\bibitem[Debenedetti et~al.(2023)Debenedetti, Sehwag, and
  Mittal]{debenedetti_light_2023}
Debenedetti, E., Sehwag, V., and Mittal, P.
\newblock A {Light} {Recipe} to {Train} {Robust} {Vision} {Transformers}.
\newblock In \emph{IEEE Conference on Secure and Trustworthy Machine Learning
  (SaTML)}, February 2023.

\bibitem[Deng \& Zheng(2021)Deng and Zheng]{deng_are_2021}
Deng, W. and Zheng, L.
\newblock Are {Labels} {Always} {Necessary} for {Classifier} {Accuracy}
  {Evaluation}?
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2021.

\bibitem[Diffenderfer et~al.(2021)Diffenderfer, Bartoldson, Chaganti, Zhang,
  and Kailkhura]{diffenderfer_winning_2021}
Diffenderfer, J., Bartoldson, B., Chaganti, S., Zhang, J., and Kailkhura, B.
\newblock A {Winning} {Hand}: {Compressing} {Deep} {Networks} {Can} {Improve}
  {Out}-of-{Distribution} {Robustness}.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, 2021.

\bibitem[Ding et~al.(2020)Ding, Sharma, Lui, and Huang]{ding_mma_2020}
Ding, G.~W., Sharma, Y., Lui, K. Y.~C., and Huang, R.
\newblock {MMA} {Training}: {Direct} {Input} {Space} {Margin} {Maximization}
  through {Adversarial} {Training}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2020.

\bibitem[Dong et~al.(2020)Dong, Fu, Yang, Pang, Su, Xiao, and
  Zhu]{dong_benchmarking_2020}
Dong, Y., Fu, Q.-A., Yang, X., Pang, T., Su, H., Xiao, Z., and Zhu, J.
\newblock Benchmarking {Adversarial} {Robustness} on {Image} {Classification}.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 2020.

\bibitem[Dong et~al.(2022)Dong, Ruan, Su, Kang, Wei, and
  Zhu]{dong_viewfool_2022}
Dong, Y., Ruan, S., Su, H., Kang, C., Wei, X., and Zhu, J.
\newblock {ViewFool}: {Evaluating} the {Robustness} of {Visual} {Recognition}
  to {Adversarial} {Viewpoints}.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, December
  2022.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and
  Houlsby]{dosovitskiy_image_2021}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S.,
  Uszkoreit, J., and Houlsby, N.
\newblock An {Image} is {Worth} 16x16 {Words}: {Transformers} for {Image}
  {Recognition} at {Scale}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2021.

\bibitem[Engstrom et~al.(2019)Engstrom, Ilyas, Salman, Santurkar, and
  Tsipras]{robustness}
Engstrom, L., Ilyas, A., Salman, H., Santurkar, S., and Tsipras, D.
\newblock Robustness (python library), 2019.
\newblock URL \url{https://github.com/MadryLab/robustness}.

\bibitem[Gao et~al.(2022)Gao, Wang, Zhou, Liu, Xie, Niu, Han, and
  Cheng]{gao_fast_2022}
Gao, R., Wang, J., Zhou, K., Liu, F., Xie, B., Niu, G., Han, B., and Cheng, J.
\newblock Fast and {Reliable} {Evaluation} of {Adversarial} {Robustness} with
  {Minimum}-{Margin} {Attack}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, June
  2022.

\bibitem[Garg et~al.(2022)Garg, Balakrishnan, Lipton, Neyshabur, and
  Sedghi]{garg_leveraging_2022}
Garg, S., Balakrishnan, S., Lipton, Z.~C., Neyshabur, B., and Sedghi, H.
\newblock Leveraging unlabeled data to predict out-of-distribution performance.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2022.

\bibitem[Geirhos et~al.(2019)Geirhos, Rubisch, Michaelis, Bethge, Wichmann, and
  Brendel]{geirhos_imagenet-trained_2019}
Geirhos, R., Rubisch, P., Michaelis, C., Bethge, M., Wichmann, F.~A., and
  Brendel, W.
\newblock {ImageNet}-trained {CNNs} are biased towards texture; increasing
  shape bias improves accuracy and robustness.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2019.

\bibitem[Geirhos et~al.(2020)Geirhos, Jacobsen, Michaelis, Zemel, Brendel,
  Bethge, and Wichmann]{geirhos_shortcut_2020}
Geirhos, R., Jacobsen, J.-H., Michaelis, C., Zemel, R., Brendel, W., Bethge,
  M., and Wichmann, F.~A.
\newblock Shortcut learning in deep neural networks.
\newblock \emph{Nature Machine Intelligence}, November 2020.

\bibitem[Gilmer et~al.(2019)Gilmer, Ford, Carlini, and
  Cubuk]{gilmer_adversarial_2019}
Gilmer, J., Ford, N., Carlini, N., and Cubuk, E.
\newblock Adversarial {Examples} {Are} a {Natural} {Consequence} of {Test}
  {Error} in {Noise}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, May
  2019.

\bibitem[Gowal et~al.(2021{\natexlab{a}})Gowal, Qin, Uesato, Mann, and
  Kohli]{gowal_uncovering_2021}
Gowal, S., Qin, C., Uesato, J., Mann, T., and Kohli, P.
\newblock Uncovering the {Limits} of {Adversarial} {Training} against
  {Norm}-{Bounded} {Adversarial} {Examples}.
\newblock \emph{arXiv}, March 2021{\natexlab{a}}.

\bibitem[Gowal et~al.(2021{\natexlab{b}})Gowal, Rebufﬁ, Wiles, Stimberg,
  Calian, and Mann]{gowal_improving_2021}
Gowal, S., Rebufﬁ, S.-A., Wiles, O., Stimberg, F., Calian, D., and Mann, T.
\newblock Improving {Robustness} using {Generated} {Data}.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)},
  2021{\natexlab{b}}.

\bibitem[Guo et~al.(2018)Guo, Rana, Cisse, and Maaten]{guo_countering_2018}
Guo, C., Rana, M., Cisse, M., and Maaten, L. v.~d.
\newblock Countering {Adversarial} {Images} using {Input} {Transformations}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he_deep_2016}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep {Residual} {Learning} for {Image} {Recognition}.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2016.

\bibitem[Hendrycks \& Dietterich(2019)Hendrycks and
  Dietterich]{hendrycks_benchmarking_2019}
Hendrycks, D. and Dietterich, T.
\newblock Benchmarking {Neural} {Network} {Robustness} to {Common}
  {Corruptions} and {Perturbations}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2019.

\bibitem[Hendrycks et~al.(2021{\natexlab{a}})Hendrycks, Basart, Mu, Kadavath,
  Wang, Dorundo, Desai, Zhu, Parajuli, Guo, Song, Steinhardt, and
  Gilmer]{hendrycks_many_2021}
Hendrycks, D., Basart, S., Mu, N., Kadavath, S., Wang, F., Dorundo, E., Desai,
  R., Zhu, T., Parajuli, S., Guo, M., Song, D., Steinhardt, J., and Gilmer, J.
\newblock The {Many} {Faces} of {Robustness}: {A} {Critical} {Analysis} of
  {Out}-of-{Distribution} {Generalization}.
\newblock In \emph{IEEE/CVF International Conference on Computer Vision
  (ICCV)}, 2021{\natexlab{a}}.

\bibitem[Hendrycks et~al.(2021{\natexlab{b}})Hendrycks, Zhao, Basart,
  Steinhardt, and Song]{hendrycks_natural_2021}
Hendrycks, D., Zhao, K., Basart, S., Steinhardt, J., and Song, D.
\newblock Natural {Adversarial} {Examples}.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 2021{\natexlab{b}}.

\bibitem[Hsiung et~al.(2023)Hsiung, Tsai, Chen, and Ho]{hsiung_towards_2023}
Hsiung, L., Tsai, Y.-Y., Chen, P.-Y., and Ho, T.-Y.
\newblock Towards {Compositional} {Adversarial} {Robustness}: {Generalizing}
  {Adversarial} {Training} to {Composite} {Semantic} {Perturbations}.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 2023.

\bibitem[Hu et~al.(2018)Hu, Shen, and Sun]{hu_squeeze-and-excitation_2018}
Hu, J., Shen, L., and Sun, G.
\newblock Squeeze-and-{Excitation} {Networks}.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 2018.

\bibitem[Huang et~al.(2017)Huang, Liu, Van Der~Maaten, and
  Weinberger]{huang_densely_2017}
Huang, G., Liu, Z., Van Der~Maaten, L., and Weinberger, K.~Q.
\newblock Densely {Connected} {Convolutional} {Networks}.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, July 2017.

\bibitem[Huang et~al.(2023{\natexlab{a}})Huang, Lu, Deb, and
  Boddeti]{huang_revisiting_2023}
Huang, S., Lu, Z., Deb, K., and Boddeti, V.~N.
\newblock Revisiting {Residual} {Networks} for {Adversarial} {Robustness}.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 2023{\natexlab{a}}.

\bibitem[Huang et~al.(2023{\natexlab{b}})Huang, Zhu, Xia, Shen, Yu, Gong, Han,
  Du, and Liu]{huang2023robust}
Huang, Z., Zhu, M., Xia, X., Shen, L., Yu, J., Gong, C., Han, B., Du, B., and
  Liu, T.
\newblock Robust generalization against photon-limited corruptions via
  worst-case sharpness minimization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  16175--16185, 2023{\natexlab{b}}.

\bibitem[Ibrahim et~al.(2023)Ibrahim, Guille-Escuret, Mitliagkas, Rish,
  Krueger, and Bashivan]{ibrahim_towards_2023}
Ibrahim, A., Guille-Escuret, C., Mitliagkas, I., Rish, I., Krueger, D., and
  Bashivan, P.
\newblock Towards {Out}-of-{Distribution} {Adversarial} {Robustness}, February
  2023.

\bibitem[Jiang et~al.(2020)Jiang, Chen, Chen, and Wang]{jiang_robust_2020}
Jiang, Z., Chen, T., Chen, T., and Wang, Z.
\newblock Robust {Pre}-{Training} by {Adversarial} {Contrastive} {Learning}.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, 2020.

\bibitem[Kaufmann et~al.(2023)Kaufmann, Kang, Sun, Basart, Yin, Mazeika, Arora,
  Dziedzic, Boenisch, Brown, Steinhardt, and Hendrycks]{kaufmann_testing_2023}
Kaufmann, M., Kang, D., Sun, Y., Basart, S., Yin, X., Mazeika, M., Arora, A.,
  Dziedzic, A., Boenisch, F., Brown, T., Steinhardt, J., and Hendrycks, D.
\newblock Testing {Robustness} {Against} {Unforeseen} {Adversaries}, July 2023.

\bibitem[Kireev et~al.(2022)Kireev, Andriushchenko, and
  Flammarion]{kireev_effectiveness_2022}
Kireev, K., Andriushchenko, M., and Flammarion, N.
\newblock On the effectiveness of adversarial training against common
  corruptions.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence (UAI)},
  August 2022.

\bibitem[Krueger et~al.(2021)Krueger, Caballero, Jacobsen, Zhang, Binas, Zhang,
  Le~Priol, and Courville]{krueger2021out}
Krueger, D., Caballero, E., Jacobsen, J.-H., Zhang, A., Binas, J., Zhang, D.,
  Le~Priol, R., and Courville, A.
\newblock Out-of-distribution generalization via risk extrapolation (rex).
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5815--5826. PMLR, 2021.

\bibitem[Laidlaw \& Feizi(2019)Laidlaw and Feizi]{laidlaw_functional_2019}
Laidlaw, C. and Feizi, S.
\newblock Functional {Adversarial} {Attacks}.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, 2019.

\bibitem[Laidlaw et~al.(2021)Laidlaw, Singla, and
  Feizi]{laidlaw_perceptual_2021}
Laidlaw, C., Singla, S., and Feizi, S.
\newblock Perceptual {Adversarial} {Robustness}: {Defense} {Against} {Unseen}
  {Threat} {Models}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, January 2021.

\bibitem[Li \& Spratling(2023{\natexlab{a}})Li and Spratling]{li_improved_2023}
Li, L. and Spratling, M.
\newblock Improved {Adversarial} {Training} {Through} {Adaptive}
  {Instance}-wise {Loss} {Smoothing}, March 2023{\natexlab{a}}.

\bibitem[Li \& Spratling(2023{\natexlab{b}})Li and
  Spratling]{li_understanding_2023}
Li, L. and Spratling, M.
\newblock Understanding and combating robust overfitting via input loss
  landscape analysis and regularization.
\newblock \emph{Pattern Recognition}, April 2023{\natexlab{b}}.

\bibitem[Li \& Spratling(2023{\natexlab{c}})Li and Spratling]{li_data_2023}
Li, L. and Spratling, M.~W.
\newblock Data augmentation alone can improve adversarial training.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, February 2023{\natexlab{c}}.

\bibitem[Li et~al.(2023)Li, Qiu, and Spratling]{li_aroid_2023}
Li, L., Qiu, J., and Spratling, M.
\newblock {AROID}: {Improving} {Adversarial} {Robustness} through {Online}
  {Instance}-wise {Data} {Augmentation}, June 2023.

\bibitem[Liu et~al.(2023)Liu, Dong, Xiang, Yang, Su, Zhu, Chen, He, Xue, and
  Zheng]{liu_comprehensive_2023}
Liu, C., Dong, Y., Xiang, W., Yang, X., Su, H., Zhu, J., Chen, Y., He, Y., Xue,
  H., and Zheng, S.
\newblock A {Comprehensive} {Study} on {Robustness} of {Image} {Classification}
  {Models}: {Benchmarking} and {Rethinking}, February 2023.

\bibitem[Lu et~al.(2020)Lu, Nott, Olson, Todeschini, Vahabi, Carmon, and
  Schmidt]{lu_harder_2020}
Lu, S., Nott, B., Olson, A., Todeschini, A., Vahabi, H., Carmon, Y., and
  Schmidt, L.
\newblock Harder or {Different}?{A} {Closer} {Look} at {Distribution} {Shift}
  in {Dataset} {Reproduction}.
\newblock In \emph{ICML 2020 Workshop on Uncertainty and Ro- bustness in Deep
  Learning}, 2020.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry_towards_2018}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards {Deep} {Learning} {Models} {Resistant} to {Adversarial}
  {Attacks}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Maini et~al.(2020)Maini, Wong, and Kolter]{maini_adversarial_2020}
Maini, P., Wong, E., and Kolter, Z.
\newblock Adversarial {Robustness} {Against} the {Union} of {Multiple}
  {Perturbation} {Models}.
\newblock In \emph{International Conference on Machine Learning (ICML)},
  November 2020.

\bibitem[Mao et~al.(2022)Mao, Chen, Li, Qi, Duan, Zhang, and
  Xue]{mao2022easyrobust}
Mao, X., Chen, Y., Li, X., Qi, G., Duan, R., Zhang, R., and Xue, H.
\newblock Easyrobust: A comprehensive and easy-to-use toolkit for robust
  computer vision, 2022.

\bibitem[Miller et~al.(2021)Miller, Taori, Raghunathan, Sagawa, Koh, Shankar,
  Liang, Carmon, and Schmidt]{miller_accuracy_2021}
Miller, J.~P., Taori, R., Raghunathan, A., Sagawa, S., Koh, P.~W., Shankar, V.,
  Liang, P., Carmon, Y., and Schmidt, L.
\newblock Accuracy on the {Line}: on the {Strong} {Correlation} {Between}
  {Out}-of-{Distribution} and {In}-{Distribution} {Generalization}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, July
  2021.

\bibitem[Müller \& Hutter(2021)Müller and Hutter]{muller_trivialaugment_2021}
Müller, S.~G. and Hutter, F.
\newblock {TrivialAugment}: {Tuning}-{Free} {Yet} {State}-of-the-{Art} {Data}
  {Augmentation}.
\newblock In \emph{IEEE/CVF International Conference on Computer Vision
  (ICCV)}, 2021.

\bibitem[Pang et~al.(2020)Pang, Yang, Dong, Xu, Zhu, and
  Su]{pang_boosting_2020}
Pang, T., Yang, X., Dong, Y., Xu, K., Zhu, J., and Su, H.
\newblock Boosting {Adversarial} {Training} with {Hypersphere} {Embedding}.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, 2020.

\bibitem[Pang et~al.(2022)Pang, Lin, Yang, Zhu, and Yan]{pang_robustness_2022}
Pang, T., Lin, M., Yang, X., Zhu, J., and Yan, S.
\newblock Robustness and {Accuracy} {Could} {Be} {Reconcilable} by ({Proper})
  {Definition}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, June
  2022.

\bibitem[Rade \& Moosavi-Dezfooli(2022)Rade and
  Moosavi-Dezfooli]{rade_reducing_2022}
Rade, R. and Moosavi-Dezfooli, S.-M.
\newblock Reducing {Excessive} {Margin} to {Achieve} a {Better} {Accuracy} vs.
  {Robustness} {Trade}-off.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, March 2022.

\bibitem[Rebuffi et~al.(2021)Rebuffi, Gowal, Calian, Stimberg, Wiles, and
  Mann]{rebuffi_fixing_2021}
Rebuffi, S.-A., Gowal, S., Calian, D.~A., Stimberg, F., Wiles, O., and Mann, T.
\newblock Fixing {Data} {Augmentation} to {Improve} {Adversarial} {Robustness},
  October 2021.

\bibitem[Recht et~al.(2018)Recht, Roelofs, Schmidt, and
  Shankar]{recht_cifar-10_2018}
Recht, B., Roelofs, R., Schmidt, L., and Shankar, V.
\newblock Do {CIFAR}-10 {Classifiers} {Generalize} to {CIFAR}-10?
\newblock \emph{arXiv}, June 2018.

\bibitem[Recht et~al.(2019)Recht, Roelofs, Schmidt, and
  Shankar]{recht_imagenet_2019}
Recht, B., Roelofs, R., Schmidt, L., and Shankar, V.
\newblock Do {ImageNet} {Classiﬁers} {Generalize} to {ImageNet}?
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2019.

\bibitem[Rice et~al.(2020)Rice, Wong, and Kolter]{rice_overfitting_2020}
Rice, L., Wong, E., and Kolter, J.~Z.
\newblock Overfitting in adversarially robust deep learning.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.

\bibitem[Rony et~al.(2019)Rony, Hafemann, Oliveira, Ben~Ayed, Sabourin, and
  Granger]{rony_decoupling_2019}
Rony, J., Hafemann, L.~G., Oliveira, L.~S., Ben~Ayed, I., Sabourin, R., and
  Granger, E.
\newblock Decoupling {Direction} and {Norm} for {Efficient} {Gradient}-{Based}
  {L2} {Adversarial} {Attacks} and {Defenses}.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2019.

\bibitem[Rusak et~al.(2020)Rusak, Schott, Zimmermann, Bitterwolf, Bringmann,
  Bethge, and Brendel]{Rusak_etal20}
Rusak, E., Schott, L., Zimmermann, R.~S., Bitterwolf, J., Bringmann, O.,
  Bethge, M., and Brendel, W.
\newblock A simple way to make neural networks robust against diverse image
  corruptions.
\newblock In \emph{Proceedings of the European Conference on Computer Vision},
  2020.

\bibitem[Samangouei et~al.(2018)Samangouei, Kabkab, and
  Chellappa]{samangouei_defense-gan_2018}
Samangouei, P., Kabkab, M., and Chellappa, R.
\newblock Defense-{GAN}: {Protecting} {Classifiers} {Against} {Adversarial}
  {Attacks} {Using} {Generative} {Models}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, February 2018.

\bibitem[Sandler et~al.(2018)Sandler, Howard, Zhu, Zhmoginov, and
  Chen]{sandler_2018_mobilenetv2}
Sandler, M., Howard, A.~G., Zhu, M., Zhmoginov, A., and Chen, L.-C.
\newblock Mobilenetv2: Inverted residuals and linear bottlenecks.
\newblock \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, 2018.
\newblock \doi{10.1109/CVPR.2018.00474}.

\bibitem[Sehwag et~al.(2019)Sehwag, Bhagoji, Song, Sitawarin, Cullina, Chiang,
  and Mittal]{sehwag_analyzing_2019}
Sehwag, V., Bhagoji, A.~N., Song, L., Sitawarin, C., Cullina, D., Chiang, M.,
  and Mittal, P.
\newblock Analyzing the {Robustness} of {Open}-{World} {Machine} {Learning}.
\newblock In \emph{the 12th ACM Workshop on Artificial Intelligence and
  Security}, November 2019.

\bibitem[Sehwag et~al.(2022)Sehwag, Mahloujifar, Handina, Dai, Xiang, Chiang,
  and Mittal]{sehwag_robust_2022}
Sehwag, V., Mahloujifar, S., Handina, T., Dai, S., Xiang, C., Chiang, M., and
  Mittal, P.
\newblock Robust {Learning} {Meets} {Generative} {Models}: {Can} {Proxy}
  {Distributions} {Improve} {Adversarial} {Robustness}?
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, March 2022.

\bibitem[Shen et~al.(2021)Shen, Liu, He, Zhang, Xu, Yu, and
  Cui]{shen_towards_2021}
Shen, Z., Liu, J., He, Y., Zhang, X., Xu, R., Yu, H., and Cui, P.
\newblock Towards {Out}-{Of}-{Distribution} {Generalization}: {A} {Survey},
  August 2021.

\bibitem[Shi et~al.(2023)Shi, Daunhawer, Vogt, Torr, and Sanyal]{shi2023robust}
Shi, Y., Daunhawer, I., Vogt, J.~E., Torr, P.~H., and Sanyal, A.
\newblock How robust is unsupervised representation learning to distribution
  shift?
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}. OpenReview, 2023.

\bibitem[Simonyan \& Zisserman(2015)Simonyan and Zisserman]{simonyan_very_2015}
Simonyan, K. and Zisserman, A.
\newblock Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image}
  {Recognition}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2015.

\bibitem[Singh et~al.(2023)Singh, Croce, and Hein]{singh_revisiting_2023}
Singh, N.~D., Croce, F., and Hein, M.
\newblock Revisiting {Adversarial} {Training} for {ImageNet}: {Architectures},
  {Training} and {Generalization} across {Threat} {Models}.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, 2023.

\bibitem[Stutz et~al.(2020)Stutz, Hein, and
  Schiele]{stutz_confidence-calibrated_2020}
Stutz, D., Hein, M., and Schiele, B.
\newblock Confidence-{Calibrated} {Adversarial} {Training}: {Generalizing} to
  {Unseen} {Attacks}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.

\bibitem[Sun et~al.(2022{\natexlab{a}})Sun, Mehra, Kailkhura, Chen, Hendrycks,
  Hamm, and Mao]{Sun_etal21}
Sun, J., Mehra, A., Kailkhura, B., Chen, P.-Y., Hendrycks, D., Hamm, J., and
  Mao, Z.~M.
\newblock Certified adversarial defenses meet out-of-distribution corruptions:
  Benchmarking robustness and simple baselines.
\newblock In \emph{Proceedings of the European Conference on Computer Vision},
  2022{\natexlab{a}}.

\bibitem[Sun et~al.(2022{\natexlab{b}})Sun, Mehra, Kailkhura, Chen, Hendrycks,
  Hamm, and Mao]{sun_spectral_2022}
Sun, J., Mehra, A., Kailkhura, B., Chen, P.-Y., Hendrycks, D., Hamm, J., and
  Mao, Z.~M.
\newblock A {Spectral} {View} of {Randomized} {Smoothing} {Under} {Common}
  {Corruptions}: {Benchmarking} and {Improving} {Certified} {Robustness}.
\newblock In \emph{European Conference on Computer Vision (ECCV)},
  2022{\natexlab{b}}.

\bibitem[Szegedy et~al.(2015)Szegedy, {Wei Liu}, {Yangqing Jia}, Sermanet,
  Reed, Anguelov, Erhan, Vanhoucke, and Rabinovich]{szegedy_going_2015}
Szegedy, C., {Wei Liu}, {Yangqing Jia}, Sermanet, P., Reed, S., Anguelov, D.,
  Erhan, D., Vanhoucke, V., and Rabinovich, A.
\newblock Going deeper with convolutions.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2015.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and
  Wojna]{szegedy_rethinking_2016}
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z.
\newblock Rethinking the {Inception} {Architecture} for {Computer} {Vision}.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2016.

\bibitem[Tan \& Le(2019)Tan and Le]{tan_efficientnet_2019}
Tan, M. and Le, Q.
\newblock {EfficientNet}: {Rethinking} {Model} {Scaling} for {Convolutional}
  {Neural} {Networks}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, May
  2019.

\bibitem[Tang et~al.(2022)Tang, Gong, Wang, Liu, Wang, Chen, Yu, Liu, Song,
  Yuille, Torr, and Tao]{tang_robustart_2022}
Tang, S., Gong, R., Wang, Y., Liu, A., Wang, J., Chen, X., Yu, F., Liu, X.,
  Song, D., Yuille, A., Torr, P. H.~S., and Tao, D.
\newblock {RobustART}: {Benchmarking} {Robustness} on {Architecture} {Design}
  and {Training} {Techniques}, January 2022.

\bibitem[Taori et~al.(2020)Taori, Dave, Shankar, Carlini, Recht, and
  Schmidt]{taori_measuring_2020}
Taori, R., Dave, A., Shankar, V., Carlini, N., Recht, B., and Schmidt, L.
\newblock Measuring {Robustness} to {Natural} {Distribution} {Shifts} in
  {Image} {Classification}.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, 2020.

\bibitem[Torralba et~al.(2008)Torralba, Fergus, and Freeman]{torralba_80_2008}
Torralba, A., Fergus, R., and Freeman, W.~T.
\newblock 80 {Million} {Tiny} {Images}: {A} {Large} {Data} {Set} for
  {Nonparametric} {Object} and {Scene} {Recognition}.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence
  (T-PAMI)}, November 2008.

\bibitem[Tramer \& Boneh(2019)Tramer and Boneh]{tramer_adversarial_2019}
Tramer, F. and Boneh, D.
\newblock Adversarial {Training} and {Robustness} for {Multiple}
  {Perturbations}.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, 2019.

\bibitem[Trockman \& Kolter(2023)Trockman and Kolter]{trockman_2023_patches}
Trockman, A. and Kolter, J.~Z.
\newblock Patches are all you need?
\newblock \emph{Transactions on Machine Learning Research}, 2023.
\newblock ISSN 2835-8856.
\newblock Featured Certification.

\bibitem[Tsipras et~al.(2019)Tsipras, Santurkar, Engstrom, Turner, and
  Madry]{tsipras_robustness_2019}
Tsipras, D., Santurkar, S., Engstrom, L., Turner, A., and Madry, A.
\newblock Robustness {May} {Be} at {Odds} with {Accuracy}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2019.

\bibitem[Wang et~al.(2019)Wang, Ge, Lipton, and Xing]{wang_learning_2019-1}
Wang, H., Ge, S., Lipton, Z., and Xing, E.~P.
\newblock Learning {Robust} {Global} {Representations} by {Penalizing} {Local}
  {Predictive} {Power}.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, 2019.

\bibitem[Wang et~al.(2020)Wang, Zou, Yi, Bailey, Ma, and
  Gu]{wang_improving_2020}
Wang, Y., Zou, D., Yi, J., Bailey, J., Ma, X., and Gu, Q.
\newblock Improving {Adversarial} {Robustness} {Requires} {Revisiting}
  {Misclassified} {Examples}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2020.

\bibitem[Wang et~al.(2023)Wang, Pang, Du, Lin, Liu, and Yan]{wang_better_2023}
Wang, Z., Pang, T., Du, C., Lin, M., Liu, W., and Yan, S.
\newblock Better {Diffusion} {Models} {Further} {Improve} {Adversarial}
  {Training}.
\newblock In \emph{International Conference on Machine Learning (ICML)},
  February 2023.

\bibitem[Wong et~al.(2020)Wong, Rice, and Kolter]{wong_fast_2020}
Wong, E., Rice, L., and Kolter, J.~Z.
\newblock Fast is better than free: {Revisiting} adversarial training.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2020.

\bibitem[Wu et~al.(2020)Wu, Xia, and Wang]{wu_adversarial_2020}
Wu, D., Xia, S.-T., and Wang, Y.
\newblock Adversarial {Weight} {Perturbation} {Helps} {Robust}
  {Generalization}.
\newblock In \emph{Neural Information Processing Systems (NeurIPS)}, 2020.

\bibitem[Xiao et~al.(2018)Xiao, Zhu, Li, He, Liu, and
  Song]{xiao_spatially_2018}
Xiao, C., Zhu, J.-Y., Li, B., He, W., Liu, M., and Song, D.
\newblock Spatially {Transformed} {Adversarial} {Examples}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Xie et~al.(2017)Xie, Girshick, Dollar, Tu, and
  He]{xie_aggregated_2017}
Xie, S., Girshick, R., Dollar, P., Tu, Z., and He, K.
\newblock Aggregated {Residual} {Transformations} for {Deep} {Neural}
  {Networks}.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 2017.

\bibitem[Xu et~al.(2023)Xu, Sun, Goldblum, Goldstein, and
  Huang]{xu_exploring_2023}
Xu, Y., Sun, Y., Goldblum, M., Goldstein, T., and Huang, F.
\newblock Exploring and {Exploiting} {Decision} {Boundary} {Dynamics} for
  {Adversarial} {Robustness}.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2023.

\bibitem[Yang et~al.(2022)Yang, Wang, Zou, Zhou, Ding, Peng, Wang, Chen, Li,
  Sun, Du, Zhou, Zhang, Hendrycks, Li, and Liu]{yang_openood_2022}
Yang, J., Wang, P., Zou, D., Zhou, Z., Ding, K., Peng, W., Wang, H., Chen, G.,
  Li, B., Sun, Y., Du, X., Zhou, K., Zhang, W., Hendrycks, D., Li, Y., and Liu,
  Z.
\newblock {{OpenOOD}}: Benchmarking generalized out-of-distribution detection,
  October 2022.

\bibitem[Yu et~al.(2018)Yu, Wang, Shelhamer, and Darrell]{yu_2018_dla}
Yu, F., Wang, D., Shelhamer, E., and Darrell, T.
\newblock Deep layer aggregation.
\newblock In \emph{2018 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, pp.\  2403--2412, 2018.
\newblock \doi{10.1109/CVPR.2018.00255}.

\bibitem[Zhang et~al.(2019)Zhang, Yu, Jiao, Xing, Ghaoui, and
  Jordan]{zhang_theoretically_2019}
Zhang, H., Yu, Y., Jiao, J., Xing, E., Ghaoui, L.~E., and Jordan, M.
\newblock Theoretically {Principled} {Trade}-off between {Robustness} and
  {Accuracy}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, May
  2019.

\bibitem[Zhang et~al.(2020)Zhang, Xu, Han, Niu, Cui, Sugiyama, and
  Kankanhalli]{zhang_attacks_2020}
Zhang, J., Xu, X., Han, B., Niu, G., Cui, L., Sugiyama, M., and Kankanhalli, M.
\newblock Attacks {Which} {Do} {Not} {Kill} {Training} {Make} {Adversarial}
  {Learning} {Stronger}.
\newblock In \emph{International Conference on Machine Learning (ICML)},
  November 2020.

\bibitem[Zhang et~al.(2018)Zhang, Isola, Efros, Shechtman, and
  Wang]{zhang2018unreasonable}
Zhang, R., Isola, P., Efros, A.~A., Shechtman, E., and Wang, O.
\newblock The unreasonable effectiveness of deep features as a perceptual
  metric.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  586--595, 2018.

\bibitem[Zhao et~al.(2022)Zhao, Yu, Ma, Yu, Mei, Wang, He, Yuille, and
  Kortylewski]{zhao_oodcv_2022}
Zhao, B., Yu, S., Ma, W., Yu, M., Mei, S., Wang, A., He, J., Yuille, A., and
  Kortylewski, A.
\newblock {{OOD-CV}}: A benchmark for robustness to out-of-distribution shifts
  of individual nuisances in natural images.
\newblock In \emph{Computer Vision \textendash{} {{ECCV}} 2022: 17th European
  Conference, Tel Aviv, Israel, October 23\textendash 27, 2022, Proceedings,
  Part {{VIII}}}, pp.\  163--180, {Berlin, Heidelberg}, 2022.
  {Springer-Verlag}.
\newblock ISBN 978-3-031-20073-1.
\newblock \doi{10.1007/978-3-031-20074-8_10}.

\end{thebibliography}
