\begin{thebibliography}{98}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alwassel et~al.(2020)Alwassel, Mahajan, Torresani, Ghanem, and
  Tran]{alwassel2019self}
H.~Alwassel, D.~Mahajan, L.~Torresani, B.~Ghanem, and D.~Tran.
\newblock Self-supervised learning by cross-modal audio-video clustering.
\newblock \emph{NeurIPS}, 2020.

\bibitem[Arora et~al.(2019)Arora, Khandeparkar, Khodak, Plevrakis, and
  Saunshi]{arora2019theoretical}
S.~Arora, H.~Khandeparkar, M.~Khodak, O.~Plevrakis, and N.~Saunshi.
\newblock A theoretical analysis of contrastive unsupervised representation
  learning.
\newblock \emph{ICML}, 2019.

\bibitem[Asano et~al.(2020{\natexlab{a}})Asano, Patrick, Rupprecht, and
  Vedaldi]{asano2020labelling}
Y.~M. Asano, M.~Patrick, C.~Rupprecht, and A.~Vedaldi.
\newblock Labelling unlabelled videos from scratch with multi-modal
  self-supervision.
\newblock In \emph{NeurIPS}, 2020{\natexlab{a}}.

\bibitem[Asano et~al.(2020{\natexlab{b}})Asano, Rupprecht, and
  Vedaldi]{asano2019critical}
Y.~M. Asano, C.~Rupprecht, and A.~Vedaldi.
\newblock A critical analysis of self-supervision, or what we can learn from a
  single image.
\newblock \emph{ICLR}, 2020{\natexlab{b}}.

\bibitem[Asano et~al.(2020{\natexlab{c}})Asano, Rupprecht, and
  Vedaldi]{asano2020self}
Y.~M. Asano, C.~Rupprecht, and A.~Vedaldi.
\newblock Self-labelling via simultaneous clustering and representation
  learning.
\newblock In \emph{ICLR}, 2020{\natexlab{c}}.

\bibitem[Bachman et~al.(2019)Bachman, Hjelm, and Buchwalter]{bachman2019amdim}
P.~Bachman, R.~D. Hjelm, and W.~Buchwalter.
\newblock Learning representations by maximizing mutual information across
  views.
\newblock \emph{arXiv preprint arXiv:1906.00910}, 2019.

\bibitem[Cai et~al.(2020)Cai, Wang, Pan, Yao, and Mei]{cai2020joint}
Q.~Cai, Y.~Wang, Y.~Pan, T.~Yao, and T.~Mei.
\newblock Joint contrastive learning with infinite possibilities.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Cao et~al.(2020)Cao, Xie, Liu, Lin, Zhang, and Hu]{cao2020parametric}
Y.~Cao, Z.~Xie, B.~Liu, Y.~Lin, Z.~Zhang, and H.~Hu.
\newblock Parametric instance classification for unsupervised visual feature
  learning.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Caron et~al.(2018)Caron, Bojanowski, Joulin, and Douze]{caron2018deep}
M.~Caron, P.~Bojanowski, A.~Joulin, and M.~Douze.
\newblock Deep clustering for unsupervised learning of visual features.
\newblock In \emph{ECCV}, 2018.

\bibitem[Caron et~al.(2019)Caron, Bojanowski, Mairal, and
  Joulin]{caron2019unsupervised}
M.~Caron, P.~Bojanowski, J.~Mairal, and A.~Joulin.
\newblock Unsupervised pre-training of image features on non-curated data.
\newblock In \emph{ICCV}, 2019.

\bibitem[Caron et~al.(2020)Caron, Misra, Mairal, Goyal, Bojanowski, and
  Joulin]{caron2020unsupervised}
M.~Caron, I.~Misra, J.~Mairal, P.~Goyal, P.~Bojanowski, and A.~Joulin.
\newblock Unsupervised learning of visual features by contrasting cluster
  assignments.
\newblock \emph{NeurIPS}, 2020.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Kornblith, Norouzi, and
  Hinton]{chen2020simple}
T.~Chen, S.~Kornblith, M.~Norouzi, and G.~Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{ICML}, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Kornblith, Swersky, Norouzi, and
  Hinton]{chen2020big}
T.~Chen, S.~Kornblith, K.~Swersky, M.~Norouzi, and G.~Hinton.
\newblock Big self-supervised models are strong semi-supervised learners.
\newblock \emph{arXiv preprint arXiv:2006.10029}, 2020{\natexlab{b}}.

\bibitem[Chen and He(2020)]{chen2020exploring}
X.~Chen and K.~He.
\newblock Exploring simple siamese representation learning.
\newblock \emph{arXiv preprint arXiv:2011.10566}, 2020.

\bibitem[Chen et~al.(2020{\natexlab{c}})Chen, Fan, Girshick, and
  He]{chen2020improved}
X.~Chen, H.~Fan, R.~Girshick, and K.~He.
\newblock Improved baselines with momentum contrastive learning.
\newblock \emph{arXiv preprint arXiv:2003.04297}, 2020{\natexlab{c}}.

\bibitem[Cheng et~al.(2020)Cheng, Wang, Pan, Feng, and Zhang]{cheng2020look}
Y.~Cheng, R.~Wang, Z.~Pan, R.~Feng, and Y.~Zhang.
\newblock Look, listen, and attend: Co-attention network for self-supervised
  audio-visual representation learning.
\newblock \emph{ACM Multimedia}, 2020.

\bibitem[Chuang et~al.(2020)Chuang, Robinson, Yen-Chen, Torralba, and
  Jegelka]{chuang2020debiased}
C.-Y. Chuang, J.~Robinson, L.~Yen-Chen, A.~Torralba, and S.~Jegelka.
\newblock Debiased contrastive learning.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Doersch et~al.(2015)Doersch, Gupta, and
  Efros]{doersch2015unsupervised}
C.~Doersch, A.~Gupta, and A.~A. Efros.
\newblock Unsupervised visual representation learning by context prediction.
\newblock In \emph{ICCV}, 2015.

\bibitem[Dosovitskiy et~al.(2014)Dosovitskiy, Springenberg, Riedmiller, and
  Brox]{dosovitskiy2014discriminative}
A.~Dosovitskiy, J.~T. Springenberg, M.~Riedmiller, and T.~Brox.
\newblock Discriminative unsupervised feature learning with convolutional
  neural networks.
\newblock In \emph{NeurIPS}, 2014.

\bibitem[Duan et~al.(2018)Duan, Zheng, Lin, Lu, and Zhou]{duan2018deep}
Y.~Duan, W.~Zheng, X.~Lin, J.~Lu, and J.~Zhou.
\newblock Deep adversarial metric learning.
\newblock In \emph{CVPR}, 2018.

\bibitem[Everingham et~al.(2010)Everingham, Van~Gool, Williams, Winn, and
  Zisserman]{everingham2010pascal}
M.~Everingham, L.~Van~Gool, C.~K. Williams, J.~Winn, and A.~Zisserman.
\newblock The pascal visual object classes (voc) challenge.
\newblock \emph{IJCV}, 2010.

\bibitem[Falcon and Cho(2020)]{falcon2020framework}
W.~Falcon and K.~Cho.
\newblock A framework for contrastive self-supervised learning and designing a
  new approach.
\newblock \emph{arXiv preprint arXiv:2009.00104}, 2020.

\bibitem[Fernando et~al.(2017)Fernando, Bilen, Gavves, and
  Gould]{fernando2017self}
B.~Fernando, H.~Bilen, E.~Gavves, and S.~Gould.
\newblock Self-supervised video representation learning with odd-one-out
  networks.
\newblock In \emph{CVPR}, 2017.

\bibitem[Gansbeke et~al.(2020)Gansbeke, Vandenhende, Georgoulis, Proesmans, and
  Gool]{gansbeke2020scan}
W.~V. Gansbeke, S.~Vandenhende, S.~Georgoulis, M.~Proesmans, and L.~V. Gool.
\newblock Scan: Learning to classify images without labels.
\newblock \emph{ECCV}, 2020.

\bibitem[Gidaris et~al.(2018)Gidaris, Singh, and
  Komodakis]{gidaris2018unsupervised}
S.~Gidaris, P.~Singh, and N.~Komodakis.
\newblock Unsupervised representation learning by predicting image rotations.
\newblock In \emph{ICLR}, 2018.

\bibitem[Gomez et~al.(2017)Gomez, Patel, Rusi{\~n}ol, Karatzas, and
  Jawahar]{gomez2017self}
L.~Gomez, Y.~Patel, M.~Rusi{\~n}ol, D.~Karatzas, and C.~Jawahar.
\newblock Self-supervised learning of visual features through embedding images
  into text topic spaces.
\newblock In \emph{CVPR}, 2017.

\bibitem[Gontijo-Lopes et~al.(2020)Gontijo-Lopes, Smullin, Cubuk, and
  Dyer]{gontijo2020affinity}
R.~Gontijo-Lopes, S.~J. Smullin, E.~D. Cubuk, and E.~Dyer.
\newblock Affinity and diversity: Quantifying mechanisms of data augmentation.
\newblock \emph{arXiv preprint arXiv:2002.08973}, 2020.

\bibitem[Grill et~al.(2020)Grill, Strub, Altch{\'e}, Tallec, Richemond,
  Buchatskaya, Doersch, Pires, Guo, Azar, et~al.]{grill2020bootstrap}
J.-B. Grill, F.~Strub, F.~Altch{\'e}, C.~Tallec, P.~H. Richemond,
  E.~Buchatskaya, C.~Doersch, B.~A. Pires, Z.~D. Guo, M.~G. Azar, et~al.
\newblock Bootstrap your own latent: A new approach to self-supervised
  learning.
\newblock \emph{NeurIPS}, 2020.

\bibitem[Han et~al.(2020)Han, Xie, and Zisserman]{han2020memory}
T.~Han, W.~Xie, and A.~Zisserman.
\newblock Memory-augmented dense predictive coding for video representation
  learning.
\newblock \emph{ECCV}, 2020.

\bibitem[Harwood et~al.(2017)Harwood, Kumar, Carneiro, Reid, Drummond,
  et~al.]{harwood2017smart}
B.~Harwood, B.~Kumar, G.~Carneiro, I.~Reid, T.~Drummond, et~al.
\newblock Smart mining for deep metric learning.
\newblock In \emph{ICCV}, 2017.

\bibitem[He et~al.(2017)He, Gkioxari, Doll{\'a}r, and Girshick]{he2017mask}
K.~He, G.~Gkioxari, P.~Doll{\'a}r, and R.~Girshick.
\newblock Mask {R}-{C}{N}{N}].
\newblock In \emph{ICCV}, 2017.

\bibitem[He et~al.(2020)He, Fan, Wu, Xie, and Girshick]{he2019momentum}
K.~He, H.~Fan, Y.~Wu, S.~Xie, and R.~Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{CVPR}, 2020.

\bibitem[Hjelm and Bachman(2020)]{hjelm2020representation}
R.~D. Hjelm and P.~Bachman.
\newblock Representation learning with video deep infomax.
\newblock \emph{arXiv preprint arXiv:2007.13278}, 2020.

\bibitem[Hjelm et~al.(2019)Hjelm, Fedorov, Lavoie-Marchildon, Grewal, Bachman,
  Trischler, and Bengio]{hjelm2018learning}
R.~D. Hjelm, A.~Fedorov, S.~Lavoie-Marchildon, K.~Grewal, P.~Bachman,
  A.~Trischler, and Y.~Bengio.
\newblock Learning deep representations by mutual information estimation and
  maximization.
\newblock In \emph{ICLR}, 2019.

\bibitem[Ho and Vasconcelos(2020)]{ho2020contrastive}
C.-H. Ho and N.~Vasconcelos.
\newblock Contrastive learning with adversarial examples.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Iscen et~al.(2018)Iscen, Tolias, Avrithis, and Chum]{iscen2018mining}
A.~Iscen, G.~Tolias, Y.~Avrithis, and O.~Chum.
\newblock Mining on manifolds: Metric learning without labels.
\newblock In \emph{CVPR}, 2018.

\bibitem[Khosla et~al.(2020)Khosla, Teterwak, Wang, Sarna, Tian, Isola,
  Maschinot, Liu, and Krishnan]{khosla2020supervised}
P.~Khosla, P.~Teterwak, C.~Wang, A.~Sarna, Y.~Tian, P.~Isola, A.~Maschinot,
  C.~Liu, and D.~Krishnan.
\newblock Supervised contrastive learning.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Kim et~al.(2020)Kim, Tack, and Hwang]{kim2020adversarial}
M.~Kim, J.~Tack, and S.~J. Hwang.
\newblock Adversarial self-supervised contrastive learning.
\newblock \emph{NeurIPS}, 2020.

\bibitem[Ko and Gu(2020)]{ko2020embedding}
B.~Ko and G.~Gu.
\newblock Embedding expansion: Augmentation in embedding space for deep metric
  learning.
\newblock \emph{CVPR}, 2020.

\bibitem[Kolesnikov et~al.(2019)Kolesnikov, Zhai, and
  Beyer]{kolesnikov2019revisiting}
A.~Kolesnikov, X.~Zhai, and L.~Beyer.
\newblock Revisiting self-supervised visual representation learning.
\newblock In \emph{CVPR}, 2019.

\bibitem[Korbar et~al.(2018)Korbar, Tran, and Torresani]{korbar2018cooperative}
B.~Korbar, D.~Tran, and L.~Torresani.
\newblock Cooperative learning of audio and video models from self-supervised
  synchronization.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Lee et~al.(2017)Lee, Huang, Singh, and Yang]{lee2017unsupervised}
H.-Y. Lee, J.-B. Huang, M.~Singh, and M.-H. Yang.
\newblock Unsupervised representation learning by sorting sequences.
\newblock In \emph{ICCV}, 2017.

\bibitem[Lee et~al.(2020)Lee, Lei, Saunshi, and Zhuo]{lee2020predicting}
J.~D. Lee, Q.~Lei, N.~Saunshi, and J.~Zhuo.
\newblock Predicting what you already know helps: Provable self-supervised
  learning.
\newblock \emph{arXiv preprint arXiv:2008.01064}, 2020.

\bibitem[Li et~al.(2020)Li, Zhou, Xiong, Socher, and Hoi]{li2020prototypical}
J.~Li, P.~Zhou, C.~Xiong, R.~Socher, and S.~C. Hoi.
\newblock Prototypical contrastive learning of unsupervised representations.
\newblock \emph{arXiv preprint arXiv:2005.04966}, 2020.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan,
  Doll{\'a}r, and Zitnick]{lin2014microsoft}
T.-Y. Lin, M.~Maire, S.~Belongie, J.~Hays, P.~Perona, D.~Ramanan,
  P.~Doll{\'a}r, and C.~L. Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In \emph{ECCV}, 2014.

\bibitem[Liu and Abbeel(2020)]{liu2020hybrid}
H.~Liu and P.~Abbeel.
\newblock Hybrid discriminative-generative training via contrastive learning.
\newblock \emph{arXiv preprint arXiv:2007.09070}, 2020.

\bibitem[L{\"o}we et~al.(2019)L{\"o}we, O'Connor, and Veeling]{lowe2019putting}
S.~L{\"o}we, P.~O'Connor, and B.~Veeling.
\newblock Putting an end to end-to-end: Gradient-isolated learning of
  representations.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Maaten and Hinton(2008)]{maaten2008visualizing}
L.~v.~d. Maaten and G.~Hinton.
\newblock Visualizing data using t-sne.
\newblock \emph{JMLR}, 2008.

\bibitem[Miech et~al.(2020)Miech, Alayrac, Smaira, Laptev, Sivic, and
  Zisserman]{miech20endtoend}
A.~Miech, J.-B. Alayrac, L.~Smaira, I.~Laptev, J.~Sivic, and A.~Zisserman.
\newblock {E}nd-to-{E}nd {L}earning of {V}isual {R}epresentations from
  {U}ncurated {I}nstructional {V}ideos.
\newblock In \emph{CVPR}, 2020.

\bibitem[Mishchuk et~al.(2017)Mishchuk, Mishkin, Radenovic, and
  Matas]{mishchuk2017working}
A.~Mishchuk, D.~Mishkin, F.~Radenovic, and J.~Matas.
\newblock Working hard to know your neighbor's margins: Local descriptor
  learning loss.
\newblock In \emph{NeurIPS}, 2017.

\bibitem[Misra and van~der Maaten(2020)]{misra2019self}
I.~Misra and L.~van~der Maaten.
\newblock Self-supervised learning of pretext-invariant representations.
\newblock \emph{CVPR}, 2020.

\bibitem[Misra et~al.(2016)Misra, Zitnick, and Hebert]{misra2016shuffle}
I.~Misra, C.~L. Zitnick, and M.~Hebert.
\newblock Shuffle and learn: unsupervised learning using temporal order
  verification.
\newblock In \emph{ECCV}, 2016.

\bibitem[Noroozi and Favaro(2016)]{noroozi2016unsupervised}
M.~Noroozi and P.~Favaro.
\newblock Unsupervised learning of visual representations by solving jigsaw
  puzzles.
\newblock In \emph{ECCV}, 2016.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
A.~v.~d. Oord, Y.~Li, and O.~Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Orhan et~al.(2020)Orhan, Gupta, and Lake]{emin2020self}
A.~E. Orhan, V.~V. Gupta, and B.~M. Lake.
\newblock Self-supervised learning through the eyes of a child.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Patacchiola and Storkey(2020)]{patacchiola2020selfsupervised}
M.~Patacchiola and A.~Storkey.
\newblock Self-supervised relational reasoning for representation learning.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Patrick et~al.(2020)Patrick, Asano, Fong, Henriques, Zweig, and
  Vedaldi]{patrick2020multi}
M.~Patrick, Y.~M. Asano, R.~Fong, J.~F. Henriques, G.~Zweig, and A.~Vedaldi.
\newblock Multi-modal self-supervision from generalized data transformations.
\newblock \emph{arXiv preprint arXiv:2003.04298}, 2020.

\bibitem[Purushwalkam and Gupta(2020)]{purushwalkam2020demystifying}
S.~Purushwalkam and A.~Gupta.
\newblock Demystifying contrastive self-supervised learning: Invariances,
  augmentations and dataset biases.
\newblock \emph{NeurIPS}, 2020.

\bibitem[Rebuffi et~al.(2020)Rebuffi, Ehrhardt, Han, Vedaldi, and
  Zisserman]{rebuffi2020lsd}
S.-A. Rebuffi, S.~Ehrhardt, K.~Han, A.~Vedaldi, and A.~Zisserman.
\newblock Lsd-c: Linearly separable deep clusters.
\newblock \emph{arXiv preprint arXiv:2006.10039}, 2020.

\bibitem[Ren et~al.(2015)Ren, He, Girshick, and Sun]{ren2015faster}
S.~Ren, K.~He, R.~Girshick, and J.~Sun.
\newblock Faster r-cnn: Towards real-time object detection with region proposal
  networks.
\newblock In \emph{NeurIPS}, 2015.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, et~al.]{russakovsky2015imagenet}
O.~Russakovsky, J.~Deng, H.~Su, J.~Krause, S.~Satheesh, S.~Ma, Z.~Huang,
  A.~Karpathy, A.~Khosla, M.~Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{IJCV}, 2015.

\bibitem[Shen et~al.(2020)Shen, Liu, Liu, Savvides, and
  Darrell]{shen2020rethinking}
Z.~Shen, Z.~Liu, Z.~Liu, M.~Savvides, and T.~Darrell.
\newblock Rethinking image mixture for unsupervised visual representation
  learning.
\newblock \emph{arXiv preprint arXiv:2003.05438}, 2020.

\bibitem[Simo-Serra et~al.(2015)Simo-Serra, Trulls, Ferraz, Kokkinos, Fua, and
  Moreno-Noguer]{simo2015discriminative}
E.~Simo-Serra, E.~Trulls, L.~Ferraz, I.~Kokkinos, P.~Fua, and F.~Moreno-Noguer.
\newblock Discriminative learning of deep convolutional feature point
  descriptors.
\newblock In \emph{ICCV}, 2015.

\bibitem[Song and Ermon(2020)]{song2020multi}
J.~Song and S.~Ermon.
\newblock Multi-label contrastive predictive coding.
\newblock \emph{NeurIPS}, 2020.

\bibitem[Srivastava et~al.(2015)Srivastava, Mansimov, and
  Salakhudinov]{srivastava2015unsupervised}
N.~Srivastava, E.~Mansimov, and R.~Salakhudinov.
\newblock Unsupervised learning of video representations using {L}{S}{T}{M}s.
\newblock In \emph{ICML}, 2015.

\bibitem[Sun et~al.(2019{\natexlab{a}})Sun, Baradel, Murphy, and
  Schmid]{sun2019learning}
C.~Sun, F.~Baradel, K.~Murphy, and C.~Schmid.
\newblock Learning video representations using contrastive bidirectional
  transformer.
\newblock \emph{arXiv preprint arXiv:1906.05743}, 2019{\natexlab{a}}.

\bibitem[Sun et~al.(2019{\natexlab{b}})Sun, Myers, Vondrick, Murphy, and
  Schmid]{sun2019videobert}
C.~Sun, A.~Myers, C.~Vondrick, K.~Murphy, and C.~Schmid.
\newblock Video{B}{E}{R}{T}: A joint model for video and language
  representation learning.
\newblock In \emph{ICCV}, 2019{\natexlab{b}}.

\bibitem[Tao et~al.(2020)Tao, Wang, and Yamasaki]{tao2020selfsupervised}
L.~Tao, X.~Wang, and T.~Yamasaki.
\newblock Self-supervised video representation learning using inter-intra
  contrastive framework.
\newblock \emph{ACM Multimedia}, 2020.

\bibitem[Tian et~al.(2019)Tian, Krishnan, and Isola]{tian2019contrastive}
Y.~Tian, D.~Krishnan, and P.~Isola.
\newblock Contrastive multiview coding.
\newblock \emph{arXiv preprint arXiv:1906.05849}, 2019.

\bibitem[Tian et~al.(2020{\natexlab{a}})Tian, Sun, Poole, Krishnan, Schmid, and
  Isola]{tian2020makes}
Y.~Tian, C.~Sun, B.~Poole, D.~Krishnan, C.~Schmid, and P.~Isola.
\newblock What makes for good views for contrastive learning.
\newblock In \emph{NeurIPS}, 2020{\natexlab{a}}.

\bibitem[Tian et~al.(2020{\natexlab{b}})Tian, Yu, Chen, and
  Ganguli]{tian2020understanding}
Y.~Tian, L.~Yu, X.~Chen, and S.~Ganguli.
\newblock Understanding self-supervised learning with dual deep networks.
\newblock \emph{arXiv preprint arXiv:2010.00578}, 2020{\natexlab{b}}.

\bibitem[Tokmakov et~al.(2020)Tokmakov, Hebert, and
  Schmid]{tokmakov2020unsupervised}
P.~Tokmakov, M.~Hebert, and C.~Schmid.
\newblock Unsupervised learning of video representations via dense trajectory
  clustering.
\newblock \emph{arXiv preprint arXiv:2006.15731}, 2020.

\bibitem[Tsai et~al.(2020)Tsai, Wu, Salakhutdinov, and
  Morency]{tsai2020demystifying}
Y.-H.~H. Tsai, Y.~Wu, R.~Salakhutdinov, and L.-P. Morency.
\newblock Demystifying self-supervised learning: An information-theoretical
  framework.
\newblock \emph{arXiv preprint arXiv:2006.05576}, 2020.

\bibitem[Tschannen et~al.(2020)Tschannen, Djolonga, Rubenstein, Gelly, and
  Lucic]{tschannen2019mutual}
M.~Tschannen, J.~Djolonga, P.~K. Rubenstein, S.~Gelly, and M.~Lucic.
\newblock On mutual information maximization for representation learning.
\newblock \emph{ICLR}, 2020.

\bibitem[Verma et~al.(2019{\natexlab{a}})Verma, Lamb, Beckham, Najafi,
  Mitliagkas, Lopez-Paz, and Bengio]{verma2019manifold}
V.~Verma, A.~Lamb, C.~Beckham, A.~Najafi, I.~Mitliagkas, D.~Lopez-Paz, and
  Y.~Bengio.
\newblock Manifold mixup: Better representations by interpolating hidden
  states.
\newblock In \emph{ICML}, 2019{\natexlab{a}}.

\bibitem[Verma et~al.(2019{\natexlab{b}})Verma, Lamb, Kannala, Bengio, and
  Lopez-Paz]{verma2019interpolation}
V.~Verma, A.~Lamb, J.~Kannala, Y.~Bengio, and D.~Lopez-Paz.
\newblock Interpolation consistency training for semi-supervised learning.
\newblock \emph{IJCAI}, 2019{\natexlab{b}}.

\bibitem[Walawalkar et~al.(2020)Walawalkar, Shen, Liu, and
  Savvides]{walawalkar2020attentive}
D.~Walawalkar, Z.~Shen, Z.~Liu, and M.~Savvides.
\newblock Attentive cutmix: An enhanced data augmentation approach for deep
  learning based image classification.
\newblock In \emph{ICASSP}, 2020.

\bibitem[Wang et~al.(2020)Wang, Jiao, and Liu]{wang2020self}
J.~Wang, J.~Jiao, and Y.-H. Liu.
\newblock Self-supervised video representation learning by pace prediction.
\newblock \emph{arXiv preprint arXiv:2008.05861}, 2020.

\bibitem[Wang and Isola(2020)]{wang2020understanding}
T.~Wang and P.~Isola.
\newblock Understanding contrastive representation learning through alignment
  and uniformity on the hypersphere.
\newblock In \emph{ICML}, 2020.

\bibitem[Wei et~al.(2020)Wei, Wang, Shen, and Yuille]{wei2020co2}
C.~Wei, H.~Wang, W.~Shen, and A.~Yuille.
\newblock Co2: Consistent contrast for unsupervised visual representation
  learning.
\newblock \emph{arXiv preprint arXiv:2010.02217}, 2020.

\bibitem[Wei et~al.(2018)Wei, Lim, Zisserman, and Freeman]{wei2018learning}
D.~Wei, J.~J. Lim, A.~Zisserman, and W.~T. Freeman.
\newblock Learning and using the arrow of time.
\newblock In \emph{CVPR}, 2018.

\bibitem[Wu et~al.(2017)Wu, Manmatha, Smola, and Krahenbuhl]{wu2017sampling}
C.-Y. Wu, R.~Manmatha, A.~J. Smola, and P.~Krahenbuhl.
\newblock Sampling matters in deep embedding learning.
\newblock In \emph{ICCV}, 2017.

\bibitem[Wu et~al.(2020)Wu, Zhuang, Mosse, Yamins, and Goodman]{wu2020mutual}
M.~Wu, C.~Zhuang, M.~Mosse, D.~Yamins, and N.~Goodman.
\newblock On mutual information in contrastive learning for visual
  representations.
\newblock \emph{arXiv preprint arXiv:2005.13149}, 2020.

\bibitem[Wu et~al.(2018)Wu, Xiong, Yu, and Lin]{wu2018unsupervised}
Z.~Wu, Y.~Xiong, S.~X. Yu, and D.~Lin.
\newblock Unsupervised feature learning via non-parametric instance
  discrimination.
\newblock In \emph{CVPR}, 2018.

\bibitem[Xie et~al.(2020)Xie, Zhan, Liu, Ong, and Loy]{xie2020delving}
J.~Xie, X.~Zhan, Z.~Liu, Y.~S. Ong, and C.~C. Loy.
\newblock Delving into inter-image invariance for unsupervised visual
  representations.
\newblock \emph{arXiv preprint arXiv:2008.11702}, 2020.

\bibitem[Xiong et~al.(2020)Xiong, Ren, and Urtasun]{xiong2020loco}
Y.~Xiong, M.~Ren, and R.~Urtasun.
\newblock Loco: Local contrastive representation learning.
\newblock \emph{NeurIPS}, 2020.

\bibitem[Xu et~al.(2019)Xu, Xiao, Zhao, Shao, Xie, and Zhuang]{xu2019self}
D.~Xu, J.~Xiao, Z.~Zhao, J.~Shao, D.~Xie, and Y.~Zhuang.
\newblock Self-supervised spatiotemporal learning via video clip order
  prediction.
\newblock In \emph{CVPR}, 2019.

\bibitem[Xu et~al.(2020)Xu, Xiong, and Qi]{xu2020k}
H.~Xu, H.~Xiong, and G.-J. Qi.
\newblock K-shot contrastive learning of visual features with multiple instance
  augmentations.
\newblock \emph{arXiv preprint arXiv:2007.13310}, 2020.

\bibitem[Xuan et~al.(2020)Xuan, Stylianou, Liu, and Pless]{xuan2020hard}
H.~Xuan, A.~Stylianou, X.~Liu, and R.~Pless.
\newblock Hard negative examples are hard, but useful.
\newblock In \emph{ECCV}, 2020.

\bibitem[Yan et~al.(2020)Yan, Misra, Gupta, Ghadiyaram, and
  Mahajan]{yan2020clusterfit}
X.~Yan, I.~Misra, A.~Gupta, D.~Ghadiyaram, and D.~Mahajan.
\newblock Clusterfit: Improving generalization of visual representations.
\newblock In \emph{CVPR}, 2020.

\bibitem[Yun et~al.(2019)Yun, Han, Oh, Chun, Choe, and Yoo]{yun2019cutmix}
S.~Yun, D.~Han, S.~J. Oh, S.~Chun, J.~Choe, and Y.~Yoo.
\newblock Cutmix: Regularization strategy to train strong classifiers with
  localizable features.
\newblock In \emph{ICCV}, 2019.

\bibitem[Zhan et~al.(2020)Zhan, Xie, Liu, Ong, and Loy]{zhan2020online}
X.~Zhan, J.~Xie, Z.~Liu, Y.-S. Ong, and C.~C. Loy.
\newblock Online deep clustering for unsupervised representation learning.
\newblock In \emph{CVPR}, 2020.

\bibitem[Zhang et~al.(2018)Zhang, Cisse, Dauphin, and
  Lopez-Paz]{zhang2017mixup}
H.~Zhang, M.~Cisse, Y.~N. Dauphin, and D.~Lopez-Paz.
\newblock mixup: Beyond empirical risk minimization.
\newblock In \emph{ICLR}, 2018.

\bibitem[Zhao et~al.(2020)Zhao, Wu, Lau, and Lin]{zhao2020makes}
N.~Zhao, Z.~Wu, R.~W. Lau, and S.~Lin.
\newblock What makes instance discrimination good for transfer learning?
\newblock \emph{arXiv preprint arXiv:2006.06606}, 2020.

\bibitem[Zheng et~al.(2019)Zheng, Chen, Lu, and Zhou]{zheng2019hardness}
W.~Zheng, Z.~Chen, J.~Lu, and J.~Zhou.
\newblock Hardness-aware deep metric learning.
\newblock In \emph{CVPR}, 2019.

\bibitem[Zhong et~al.(2020)Zhong, Chen, Jin, and Hua]{zhong2020deep}
H.~Zhong, C.~Chen, Z.~Jin, and X.-S. Hua.
\newblock Deep robust clustering by contrastive learning.
\newblock \emph{arXiv preprint arXiv:2008.03030}, 2020.

\bibitem[Zhou et~al.(2020)Zhou, Yu, Bian, Hu, Ma, and Zheng]{zhou2020C2L}
H.-Y. Zhou, S.~Yu, C.~Bian, Y.~Hu, K.~Ma, and Y.~Zheng.
\newblock Comparing to learn: Surpassing imagenet pretraining on radiographs by
  comparing image representations.
\newblock In \emph{MICCAI}, 2020.

\bibitem[Zhuang et~al.(2019)Zhuang, Zhai, and Yamins]{zhuang2019local}
C.~Zhuang, A.~L. Zhai, and D.~Yamins.
\newblock Local aggregation for unsupervised learning of visual embeddings.
\newblock In \emph{ICCV}, 2019.

\end{thebibliography}
