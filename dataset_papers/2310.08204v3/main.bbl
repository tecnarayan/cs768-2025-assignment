\begin{thebibliography}{50}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahn et~al.(2019)Ahn, Cha, Lee, and Moon]{Ahn2019ucl}
Ahn, H., Cha, S., Lee, D., and Moon, T.
\newblock Uncertainty-based continual learning with adaptive regularization.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2019.

\bibitem[Aljundi et~al.(2019{\natexlab{a}})Aljundi, Caccia, Belilovsky, Caccia, Lin, Charlin, and Tuytelaars]{Aljundi2019MIR}
Aljundi, R., Caccia, L., Belilovsky, E., Caccia, M., Lin, M., Charlin, L., and Tuytelaars, T.
\newblock Online continual learning with maximally interfered retrieval.
\newblock \emph{arXiv preprint arXiv:1908.04742}, 2019{\natexlab{a}}.
\newblock URL \url{http://arxiv.org/abs/1908.04742}.

\bibitem[Aljundi et~al.(2019{\natexlab{b}})Aljundi, Kelchtermans, and Tuytelaars]{Aljundi_2019_CVPR}
Aljundi, R., Kelchtermans, K., and Tuytelaars, T.
\newblock Task-free continual learning.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)}, 2019{\natexlab{b}}.

\bibitem[Arani et~al.(2022)Arani, Sarfraz, and Zonooz]{Arani2022clser}
Arani, E., Sarfraz, F., and Zonooz, B.
\newblock Learning fast, learning slow: {A} general continual learning method based on complementary learning system.
\newblock In \emph{Proceedings of the International Conference on Learning Representations (ICLR)}, 2022.

\bibitem[Buzzega et~al.(2020)Buzzega, Boschini, Porrello, Abati, and Calderara]{Buzzega2020DER}
Buzzega, P., Boschini, M., Porrello, A., Abati, D., and Calderara, S.
\newblock Dark experience for general continual learning: a strong, simple baseline.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2020.

\bibitem[Chen et~al.(2020)Chen, Xie, Vedaldi, and Zisserman]{vggsound}
Chen, H., Xie, W., Vedaldi, A., and Zisserman, A.
\newblock Vggsound: {A} large-scale audio-visual dataset.
\newblock In \emph{{IEEE} International Conference on Acoustics, Speech and Signal Processing}, 2020.

\bibitem[Cossu et~al.(2022)Cossu, Tuytelaars, Carta, Passaro, Lomonaco, and Bacciu]{Andrea2022clpretrain}
Cossu, A., Tuytelaars, T., Carta, A., Passaro, L.~C., Lomonaco, V., and Bacciu, D.
\newblock Continual pre-training mitigates forgetting in language and vision.
\newblock \emph{arXiv preprint arXiv:2205.09357}, 2022.
\newblock URL \url{https://doi.org/10.48550/arXiv.2205.09357}.

\bibitem[Fini et~al.(2022)Fini, da~Costa, Alameda{-}Pineda, Ricci, Alahari, and Mairal]{Fini2022selfsupcl}
Fini, E., da~Costa, V. G.~T., Alameda{-}Pineda, X., Ricci, E., Alahari, K., and Mairal, J.
\newblock Self-supervised models are continual learners.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)}, 2022.

\bibitem[Gemmeke et~al.(2017)Gemmeke, Ellis, Freedman, Jansen, Lawrence, Moore, Plakal, and Ritter]{audioset}
Gemmeke, J.~F., Ellis, D. P.~W., Freedman, D., Jansen, A., Lawrence, W., Moore, R.~C., Plakal, M., and Ritter, M.
\newblock Audio set: An ontology and human-labeled dataset for audio events.
\newblock In \emph{{IEEE} International Conference on Acoustics, Speech and Signal Processing, {ICASSP}}, 2017.

\bibitem[Gong et~al.(2023)Gong, Rouditchenko, Liu, Harwath, Karlinsky, Kuehne, and Glass]{Yuan2023cav}
Gong, Y., Rouditchenko, A., Liu, A.~H., Harwath, D., Karlinsky, L., Kuehne, H., and Glass, J.~R.
\newblock Contrastive audio-visual masked autoencoder.
\newblock In \emph{Proceedings of the International Conference on Learning Representations (ICLR)}, 2023.

\bibitem[He et~al.(2022)He, Chen, Xie, Li, Doll{\'{a}}r, and Girshick]{KHe2022mae}
He, K., Chen, X., Xie, S., Li, Y., Doll{\'{a}}r, P., and Girshick, R.~B.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)}, 2022.

\bibitem[Hu et~al.(2022{\natexlab{a}})Hu, Chen, and Owens]{Hu2022MixandLocal}
Hu, X., Chen, Z., and Owens, A.
\newblock Mix and localize: Localizing sound sources in mixtures.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)}, 2022{\natexlab{a}}.

\bibitem[Hu et~al.(2022{\natexlab{b}})Hu, Luo, and Chen]{hu2022make}
Hu, Y., Luo, C., and Chen, Z.
\newblock Make it move: controllable image-to-video generation with text descriptions.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)}, 2022{\natexlab{b}}.

\bibitem[Huang et~al.(2022)Huang, Xu, Li, Baevski, Auli, Galuba, Metze, and Feichtenhofer]{Po-Yao2022audiomae}
Huang, P., Xu, H., Li, J., Baevski, A., Auli, M., Galuba, W., Metze, F., and Feichtenhofer, C.
\newblock Masked autoencoders that listen.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2022.

\bibitem[Huang et~al.(2023)Huang, Sharma, Xu, Ryali, Fan, Li, Li, Ghosh, Malik, and Feichtenhofer]{Po-Vao2022mavil}
Huang, P., Sharma, V., Xu, H., Ryali, C., Fan, H., Li, Y., Li, S., Ghosh, G., Malik, J., and Feichtenhofer, C.
\newblock Mavil: Masked audio-video learners.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2023.

\bibitem[Hwang et~al.(2022)Hwang, Yoon, Lee, and Hwang]{Hwang2023mats}
Hwang, S., Yoon, J., Lee, Y., and Hwang, S.~J.
\newblock Efficient video representation learning via masked video modeling with motion-centric token selection.
\newblock \emph{arXiv preprint arXiv:2211.10636}, 2022.
\newblock URL \url{https://doi.org/10.48550/arXiv.2211.10636}.

\bibitem[Jin et~al.(2021)Jin, Sadhu, Du, and Ren]{Jin2021GMED}
Jin, X., Sadhu, A., Du, J., and Ren, X.
\newblock Gradient-based editing of memory examples for online task-free continual learning.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2021.

\bibitem[Kirkpatrick et~al.(2016)Kirkpatrick, Pascanu, Rabinowitz, Veness, Desjardins, Rusu, Milan, Quan, Ramalho, Grabska{-}Barwinska, Hassabis, Clopath, Kumaran, and Hadsell]{Kirkpatrick2016ewc}
Kirkpatrick, J., Pascanu, R., Rabinowitz, N.~C., Veness, J., Desjardins, G., Rusu, A.~A., Milan, K., Quan, J., Ramalho, T., Grabska{-}Barwinska, A., Hassabis, D., Clopath, C., Kumaran, D., and Hadsell, R.
\newblock Overcoming catastrophic forgetting in neural networks.
\newblock \emph{arXiv preprint arXiv:1612.00796}, 2016.
\newblock URL \url{http://arxiv.org/abs/1612.00796}.

\bibitem[Korbar et~al.(2018)Korbar, Tran, and Torresani]{korbar2018cooperative}
Korbar, B., Tran, D., and Torresani, L.
\newblock Cooperative learning of audio and video models from self-supervised synchronization.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2018.

\bibitem[Lee et~al.(2023)Lee, Jang, Jo, Yoon, Kim, Kim, Ha, and Hwang]{lee2023text}
Lee, J., Jang, S., Jo, J., Yoon, J., Kim, Y., Kim, J.-H., Ha, J.-W., and Hwang, S.~J.
\newblock Text-conditioned sampling framework for text-to-image generation with masked generative models.
\newblock In \emph{Proceedings of the International Conference on Computer Vision (ICCV)}, 2023.

\bibitem[Lee et~al.(2020)Lee, Ha, Zhang, and Kim]{Lee2020cndpm}
Lee, S., Ha, J., Zhang, D., and Kim, G.
\newblock A neural dirichlet process mixture model for task-free continual learning.
\newblock In \emph{Proceedings of the International Conference on Learning Representations (ICLR)}, 2020.

\bibitem[Lee et~al.(2021)Lee, Yu, Kim, Breuel, Kautz, and Song]{Lee2021paraeffivit}
Lee, S., Yu, Y., Kim, G., Breuel, T.~M., Kautz, J., and Song, Y.
\newblock Parameter efficient multimodal transformers for video representation learning.
\newblock In \emph{Proceedings of the International Conference on Learning Representations (ICLR)}, 2021.

\bibitem[Li et~al.(2020)Li, Zareian, Zeng, Whitehead, Lu, Ji, and Chang]{li2020cross}
Li, M., Zareian, A., Zeng, Q., Whitehead, S., Lu, D., Ji, H., and Chang, S.-F.
\newblock Cross-media structured common space for multimedia event extraction.
\newblock In \emph{Proceedings of the Association for Computational Linguistics (ACL)}, 2020.

\bibitem[Liang et~al.(2022)Liang, Zhang, Kwon, Yeung, and Zou]{Liang2022MindtheGap}
Liang, W., Zhang, Y., Kwon, Y., Yeung, S., and Zou, J.~Y.
\newblock Mind the gap: Understanding the modality gap in multi-modal contrastive representation learning.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2022.

\bibitem[Liao et~al.(2022)Liao, Hu, Yang, and Rosenhahn]{liao2022text}
Liao, W., Hu, K., Yang, M.~Y., and Rosenhahn, B.
\newblock Text to image generation with semantic-spatial aware gan.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)}, 2022.

\bibitem[Lin et~al.(2023)Lin, Sung, Lei, Bansal, and Bertasius]{lin2023vision}
Lin, Y.-B., Sung, Y.-L., Lei, J., Bansal, M., and Bertasius, G.
\newblock Vision transformers are parameter-efficient audio-visual learners.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)}, 2023.

\bibitem[Liu et~al.(2023)Liu, Li, Wu, and Lee]{liu2023visual}
Liu, H., Li, C., Wu, Q., and Lee, Y.~J.
\newblock Visual instruction tuning.
\newblock \emph{arXiv preprint arXiv:2304.08485}, 2023.

\bibitem[Liu et~al.(2022)Liu, Qian, Zhou, Hu, Lin, Liu, Zhou, and Zhou]{Liu2022cmerrasing}
Liu, X., Qian, R., Zhou, H., Hu, D., Lin, W., Liu, Z., Zhou, B., and Zhou, X.
\newblock Visual sound localization in the wild by cross-modal interference erasing.
\newblock In \emph{Proceedings of the AAAI National Conference on Artificial Intelligence (AAAI)}, 2022.

\bibitem[Madaan et~al.(2022)Madaan, Yoon, Li, Liu, and Hwang]{Madaan2022lump}
Madaan, D., Yoon, J., Li, Y., Liu, Y., and Hwang, S.~J.
\newblock Representational continuity for unsupervised continual learning.
\newblock In \emph{Proceedings of the International Conference on Learning Representations (ICLR)}, 2022.

\bibitem[Mo et~al.(2023)Mo, Pian, and Tian]{Mo2023groupav}
Mo, S., Pian, W., and Tian, Y.
\newblock Class-incremental grouping network for continual audio-visual learning.
\newblock In \emph{Proceedings of the International Conference on Computer Vision (ICCV)}, 2023.

\bibitem[Nagrani et~al.(2021)Nagrani, Yang, Arnab, Jansen, Schmid, and Sun]{Nagrani2021mbt}
Nagrani, A., Yang, S., Arnab, A., Jansen, A., Schmid, C., and Sun, C.
\newblock Attention bottlenecks for multimodal fusion.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2021.

\bibitem[Pian et~al.(2023)Pian, Mo, Guo, and Tian]{Pian2023avcil}
Pian, W., Mo, S., Guo, Y., and Tian, Y.
\newblock Audio-visual class-incremental learning.
\newblock In \emph{Proceedings of the International Conference on Computer Vision (ICCV)}, 2023.

\bibitem[Rebuffi et~al.(2017)Rebuffi, Kolesnikov, Sperl, and Lampert]{Rebuffi2017icarl}
Rebuffi, S., Kolesnikov, A., Sperl, G., and Lampert, C.~H.
\newblock icarl: Incremental classifier and representation learning.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)}, 2017.

\bibitem[Rolnick et~al.(2019)Rolnick, Ahuja, Schwarz, Lillicrap, and Wayne]{Rolnick2019ER}
Rolnick, D., Ahuja, A., Schwarz, J., Lillicrap, T.~P., and Wayne, G.
\newblock Experience replay for continual learning.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2019.

\bibitem[Sarfraz et~al.(2023)Sarfraz, Arani, and Zonooz]{Sarfraz2023esmer}
Sarfraz, F., Arani, E., and Zonooz, B.
\newblock Error sensitivity modulation based experience replay: Mitigating abrupt representation drift in continual learning.
\newblock In \emph{Proceedings of the International Conference on Learning Representations (ICLR)}, 2023.

\bibitem[Tang et~al.(2022)Tang, Cho, Nie, and Bansal]{Zineng2022tvlt}
Tang, Z., Cho, J., Nie, Y., and Bansal, M.
\newblock {TVLT:} textless vision-language transformer.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2022.

\bibitem[Tian et~al.(2018)Tian, Shi, Li, Duan, and Xu]{ave}
Tian, Y., Shi, J., Li, B., Duan, Z., and Xu, C.
\newblock Audio-visual event localization in unconstrained videos.
\newblock In \emph{Proceedings of the European Conference on Computer Vision (ECCV)}, 2018.

\bibitem[Tian et~al.(2020)Tian, Li, and Xu]{Tian2020avparsing}
Tian, Y., Li, D., and Xu, C.
\newblock Unified multisensory perception: Weakly-supervised audio-visual video parsing.
\newblock In \emph{Proceedings of the European Conference on Computer Vision (ECCV)}, 2020.

\bibitem[Udandarao(2022)]{udandarao2022understanding}
Udandarao, V.
\newblock Understanding and fixing the modality gap in vision-language models.
\newblock \emph{PhD thesis, Master's thesis, University of Cambridge}, 2022.

\bibitem[Villegas et~al.(2022)Villegas, Babaeizadeh, Kindermans, Moraldo, Zhang, Saffar, Castro, Kunze, and Erhan]{villegas2022phenaki}
Villegas, R., Babaeizadeh, M., Kindermans, P.-J., Moraldo, H., Zhang, H., Saffar, M.~T., Castro, S., Kunze, J., and Erhan, D.
\newblock Phenaki: Variable length video generation from open domain textual description.
\newblock \emph{arXiv preprint arXiv:2210.02399}, 2022.

\bibitem[Vitter(1985)]{Vitter1985reservoir}
Vitter, J.~S.
\newblock Random sampling with a reservoir.
\newblock \emph{{ACM} Trans. Math. Softw.}, 1985.

\bibitem[Xiao et~al.(2020)Xiao, Lee, Grauman, Malik, and Feichtenhofer]{xiao2020audiovisual}
Xiao, F., Lee, Y.~J., Grauman, K., Malik, J., and Feichtenhofer, C.
\newblock Audiovisual slowfast networks for video recognition.
\newblock \emph{arXiv preprint arXiv:2001.08740}, 2020.

\bibitem[Xu et~al.(2016)Xu, Mei, Yao, and Rui]{Xu2016msrvtt}
Xu, J., Mei, T., Yao, T., and Rui, Y.
\newblock {MSR-VTT:} {A} large video description dataset for bridging video and language.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)}, 2016.

\bibitem[Yan et~al.(2023)Yan, Shou, Ge, Wang, Lin, Cai, and Tang]{yan2023video}
Yan, R., Shou, M.~Z., Ge, Y., Wang, J., Lin, X., Cai, G., and Tang, J.
\newblock Video-text pre-training with learned regions for retrieval.
\newblock In \emph{Proceedings of the AAAI National Conference on Artificial Intelligence (AAAI)}, 2023.

\bibitem[Yan et~al.(2022)Yan, Hong, Xu, Han, Tuytelaars, Li, and He]{Yan2022incclip}
Yan, S., Hong, L., Xu, H., Han, J., Tuytelaars, T., Li, Z., and He, X.
\newblock Generative negative text replay for continual vision-language pretraining.
\newblock In \emph{Proceedings of the European Conference on Computer Vision (ECCV)}, 2022.

\bibitem[Yoon et~al.(2018)Yoon, Yang, Lee, and Hwang]{Yoon2018den}
Yoon, J., Yang, E., Lee, J., and Hwang, S.~J.
\newblock Lifelong learning with dynamically expandable networks.
\newblock In \emph{Proceedings of the International Conference on Learning Representations (ICLR)}, 2018.

\bibitem[Yoon et~al.(2023)Yoon, Hwang, and Cao]{yoon2023continual}
Yoon, J., Hwang, S.~J., and Cao, Y.
\newblock Continual learners are incremental model generalizers.
\newblock In \emph{Proceedings of the International Conference on Machine Learning (ICML)}, 2023.

\bibitem[Zenke et~al.(2017)Zenke, Poole, and Ganguli]{Zenke2017si}
Zenke, F., Poole, B., and Ganguli, S.
\newblock Continual learning through synaptic intelligence.
\newblock In \emph{Proceedings of the International Conference on Machine Learning (ICML)}, 2017.

\bibitem[Zhou et~al.(2019)Zhou, Liu, Liu, Luo, and Wang]{zhou2019talking}
Zhou, H., Liu, Y., Liu, Z., Luo, P., and Wang, X.
\newblock Talking face generation by adversarially disentangled audio-visual representation.
\newblock In \emph{Proceedings of the AAAI National Conference on Artificial Intelligence (AAAI)}, 2019.

\bibitem[Zhou et~al.(2022)Zhou, Wang, Zhang, Sun, Zhang, Birchfield, Guo, Kong, Wang, and Zhong]{zhou2022avseg}
Zhou, J., Wang, J., Zhang, J., Sun, W., Zhang, J., Birchfield, S., Guo, D., Kong, L., Wang, M., and Zhong, Y.
\newblock Audio-visual segmentation.
\newblock In \emph{Proceedings of the European Conference on Computer Vision (ECCV)}, 2022.

\end{thebibliography}
