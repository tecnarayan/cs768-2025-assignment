\begin{thebibliography}{63}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Lundberg and Lee(2017)]{lundberg2017unified}
Scott~M Lundberg and Su-In Lee.
\newblock A unified approach to interpreting model predictions.
\newblock In \emph{Proceedings of the 31st international conference on neural
  information processing systems}, pages 4768--4777, 2017.

\bibitem[Janzing et~al.(2020)Janzing, Minorics, and
  Bl{\"o}baum]{janzing2020feature}
Dominik Janzing, Lenon Minorics, and Patrick Bl{\"o}baum.
\newblock Feature relevance quantification in explainable ai: A causal problem.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 2907--2916. PMLR, 2020.

\bibitem[Sundararajan and Najmi(2020)]{sundararajan2020many}
Mukund Sundararajan and Amir Najmi.
\newblock The many shapley values for model explanation.
\newblock In \emph{International conference on machine learning}, pages
  9269--9278. PMLR, 2020.

\bibitem[Frye et~al.(2020)Frye, de~Mijolla, Begley, Cowton, Stanley, and
  Feige]{frye2020shapley}
Christopher Frye, Damien de~Mijolla, Tom Begley, Laurence Cowton, Megan
  Stanley, and Ilya Feige.
\newblock Shapley explainability on the data manifold.
\newblock \emph{arXiv preprint arXiv:2006.01272}, 2020.

\bibitem[Aas et~al.(2021)Aas, Jullum, and L{\o}land]{aas2021explaining}
Kjersti Aas, Martin Jullum, and Anders L{\o}land.
\newblock Explaining individual predictions when features are dependent: More
  accurate approximations to shapley values.
\newblock \emph{Artificial Intelligence}, 298:\penalty0 103502, 2021.

\bibitem[Heskes et~al.(2020)Heskes, Sijben, Bucur, and
  Claassen]{heskes2020causal}
Tom Heskes, Evi Sijben, Ioan~Gabriel Bucur, and Tom Claassen.
\newblock Causal shapley values: Exploiting causal knowledge to explain
  individual predictions of complex models.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 4778--4789, 2020.

\bibitem[Wang et~al.(2021)Wang, Wiens, and Lundberg]{wang2021shapley}
Jiaxuan Wang, Jenna Wiens, and Scott Lundberg.
\newblock Shapley flow: A graph-based approach to interpreting model
  predictions.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 721--729. PMLR, 2021.

\bibitem[Covert and Lee(2021)]{covert2021improving}
Ian Covert and Su-In Lee.
\newblock Improving kernelshap: Practical shapley value estimation using linear
  regression.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 3457--3465. PMLR, 2021.

\bibitem[Lundberg et~al.(2020)Lundberg, Erion, Chen, DeGrave, Prutkin, Nair,
  Katz, Himmelfarb, Bansal, and Lee]{lundberg2020local}
Scott~M Lundberg, Gabriel Erion, Hugh Chen, Alex DeGrave, Jordan~M Prutkin,
  Bala Nair, Ronit Katz, Jonathan Himmelfarb, Nisha Bansal, and Su-In Lee.
\newblock From local explanations to global understanding with explainable ai
  for trees.
\newblock \emph{Nature machine intelligence}, 2\penalty0 (1):\penalty0 56--67,
  2020.

\bibitem[Jethani et~al.(2021{\natexlab{a}})Jethani, Sudarshan, Covert, Lee, and
  Ranganath]{jethani2021fastshap}
Neil Jethani, Mukund Sudarshan, Ian Covert, Su-In Lee, and Rajesh Ranganath.
\newblock Fastshap: Real-time shapley value estimation.
\newblock \emph{arXiv preprint arXiv:2107.07436}, 2021{\natexlab{a}}.

\bibitem[Lundberg et~al.(2018)Lundberg, Nair, Vavilala, Horibe, Eisses, Adams,
  Liston, Low, Newman, Kim, et~al.]{lundberg2018explainable}
Scott~M Lundberg, Bala Nair, Monica~S Vavilala, Mayumi Horibe, Michael~J
  Eisses, Trevor Adams, David~E Liston, Daniel King-Wai Low, Shu-Fang Newman,
  Jerry Kim, et~al.
\newblock Explainable machine-learning predictions for the prevention of
  hypoxaemia during surgery.
\newblock \emph{Nature biomedical engineering}, 2\penalty0 (10):\penalty0
  749--760, 2018.

\bibitem[Janizek et~al.(2021)Janizek, Dincer, Celik, Chen, Chen, Naxerova, and
  Lee]{janizek2021uncovering}
Joseph~D Janizek, Ayse~Berceste Dincer, Safiye Celik, Hugh Chen, William Chen,
  Kamila Naxerova, and Su-In Lee.
\newblock Uncovering expression signatures of synergistic drug response using
  an ensemble of explainable ai models.
\newblock \emph{bioRxiv}, 2021.

\bibitem[Qiu et~al.(2022)Qiu, Chen, Dincer, Lundberg, Kaeberlein, and
  Lee]{qiu2022interpretable}
Wei Qiu, Hugh Chen, Ayse~Berceste Dincer, Scott Lundberg, Matt Kaeberlein, and
  Su-In Lee.
\newblock Interpretable machine learning prediction of all-cause mortality.
\newblock \emph{medRxiv}, pages 2021--01, 2022.

\bibitem[Lipovetsky and Conklin(2001)]{lipovetsky2001analysis}
Stan Lipovetsky and Michael Conklin.
\newblock Analysis of regression in game theory approach.
\newblock \emph{Applied Stochastic Models in Business and Industry},
  17\penalty0 (4):\penalty0 319--330, 2001.

\bibitem[Breiman(2001)]{breiman2001random}
Leo Breiman.
\newblock Random forests.
\newblock \emph{Machine learning}, 45\penalty0 (1):\penalty0 5--32, 2001.

\bibitem[Owen(2014)]{owen2014sobol}
Art~B Owen.
\newblock Sobol'indices and shapley value.
\newblock \emph{SIAM/ASA Journal on Uncertainty Quantification}, 2\penalty0
  (1):\penalty0 245--251, 2014.

\bibitem[Broto et~al.(2020)Broto, Bachoc, and Depecker]{broto2020variance}
Baptiste Broto, Fran{\c{c}}ois Bachoc, and Marine Depecker.
\newblock Variance reduction for estimation of shapley effects and adaptation
  to unknown input distribution.
\newblock \emph{SIAM/ASA Journal on Uncertainty Quantification}, 8\penalty0
  (2):\penalty0 693--716, 2020.

\bibitem[Zhao and Hastie(2021)]{zhao2021causal}
Qingyuan Zhao and Trevor Hastie.
\newblock Causal interpretations of black-box models.
\newblock \emph{Journal of Business \& Economic Statistics}, 39\penalty0
  (1):\penalty0 272--281, 2021.

\bibitem[B{\'e}nard et~al.(2022)B{\'e}nard, Biau, Da~Veiga, and
  Scornet]{benard2022shaff}
Cl{\'e}ment B{\'e}nard, G{\'e}rard Biau, S{\'e}bastien Da~Veiga, and Erwan
  Scornet.
\newblock Shaff: Fast and consistent shapley effect estimates via random
  forests.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 5563--5582. PMLR, 2022.

\bibitem[Breiman et~al.(2017)Breiman, Friedman, Olshen, and
  Stone]{breiman2017classification}
Leo Breiman, Jerome~H Friedman, Richard~A Olshen, and Charles~J Stone.
\newblock \emph{Classification and regression trees}.
\newblock Routledge, 2017.

\bibitem[Chen et~al.(2018)Chen, Song, Wainwright, and Jordan]{chen2018learning}
Jianbo Chen, Le~Song, Martin Wainwright, and Michael Jordan.
\newblock Learning to explain: An information-theoretic perspective on model
  interpretation.
\newblock In \emph{International Conference on Machine Learning}, pages
  883--892. PMLR, 2018.

\bibitem[Simonyan et~al.(2013)Simonyan, Vedaldi, and
  Zisserman]{simonyan2013deep}
Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman.
\newblock Deep inside convolutional networks: Visualising image classification
  models and saliency maps.
\newblock \emph{arXiv preprint arXiv:1312.6034}, 2013.

\bibitem[Sundararajan et~al.(2017)Sundararajan, Taly, and
  Yan]{sundararajan2017axiomatic}
Mukund Sundararajan, Ankur Taly, and Qiqi Yan.
\newblock Axiomatic attribution for deep networks.
\newblock In \emph{International conference on machine learning}, pages
  3319--3328. PMLR, 2017.

\bibitem[Ancona et~al.(2017)Ancona, Ceolini, {\"O}ztireli, and
  Gross]{ancona2017towards}
Marco Ancona, Enea Ceolini, Cengiz {\"O}ztireli, and Markus Gross.
\newblock Towards better understanding of gradient-based attribution methods
  for deep neural networks.
\newblock \emph{arXiv preprint arXiv:1711.06104}, 2017.

\bibitem[Selvaraju et~al.(2017)Selvaraju, Cogswell, Das, Vedantam, Parikh, and
  Batra]{selvaraju2017grad}
Ramprasaath~R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam,
  Devi Parikh, and Dhruv Batra.
\newblock Grad-cam: Visual explanations from deep networks via gradient-based
  localization.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 618--626, 2017.

\bibitem[Adebayo et~al.(2018)Adebayo, Gilmer, Muelly, Goodfellow, Hardt, and
  Kim]{adebayo2018sanity}
Julius Adebayo, Justin Gilmer, Michael Muelly, Ian Goodfellow, Moritz Hardt,
  and Been Kim.
\newblock Sanity checks for saliency maps.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Shapley(1953{\natexlab{a}})]{shapley1953}
Lloyd~S Shapley.
\newblock A value for n-person games.
\newblock \emph{Contributions to the Theory of Games}, 2\penalty0
  (28):\penalty0 307--317, 1953{\natexlab{a}}.

\bibitem[Ghorbani and Zou(2019)]{ghorbani2019data}
Amirata Ghorbani and James Zou.
\newblock Data shapley: Equitable valuation of data for machine learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  2242--2251. PMLR, 2019.

\bibitem[Jia et~al.(2019)Jia, Dao, Wang, Hubis, Gurel, Li, Zhang, Spanos, and
  Song]{jia2019}
Ruoxi Jia, David Dao, Boxin Wang, Frances~Ann Hubis, Nezihe~Merve Gurel, Bo~Li,
  Ce~Zhang, Costas Spanos, and Dawn Song.
\newblock Efficient task-specific data valuation for nearest neighbor
  algorithms.
\newblock \emph{Proceedings of the VLDB Endowment}, 12\penalty0 (11):\penalty0
  1610--1623, 2019.

\bibitem[Ghorbani et~al.(2020)Ghorbani, Kim, and
  Zou]{ghorbani2020distributional}
Amirata Ghorbani, Michael Kim, and James Zou.
\newblock A distributional framework for data valuation.
\newblock In \emph{International Conference on Machine Learning}, pages
  3535--3544. PMLR, 2020.

\bibitem[Kwon et~al.(2021)Kwon, Rivas, and Zou]{kwon2021efficient}
Yongchan Kwon, Manuel~A Rivas, and James Zou.
\newblock Efficient computation and analysis of distributional shapley values.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 793--801. PMLR, 2021.

\bibitem[Ghorbani and Zou(2020)]{ghorbani2020neuron}
Amirata Ghorbani and James~Y Zou.
\newblock Neuron shapley: Discovering the responsible neurons.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 5922--5932, 2020.

\bibitem[Rozemberczki and Sarkar(2021)]{rozemberczki2021shapley}
Benedek Rozemberczki and Rik Sarkar.
\newblock The shapley value of classifiers in ensemble games.
\newblock In \emph{Proceedings of the 30th ACM International Conference on
  Information \& Knowledge Management}, pages 1558--1567, 2021.

\bibitem[Liu et~al.(2021)Liu, Chen, Yu, Liu, and Cui]{liu2021gtg}
Zelei Liu, Yuanyuan Chen, Han Yu, Yang Liu, and Lizhen Cui.
\newblock Gtg-shapley: Efficient and accurate participant contribution
  evaluation in federated learning.
\newblock \emph{arXiv preprint arXiv:2109.02053}, 2021.

\bibitem[Li et~al.(2021)Li, Kuang, Wang, Liu, Chen, Wu, and
  Xiao]{li2021shapley}
Jiahui Li, Kun Kuang, Baoxiang Wang, Furui Liu, Long Chen, Fei Wu, and Jun
  Xiao.
\newblock Shapley counterfactual credits for multi-agent reinforcement
  learning.
\newblock In \emph{Proceedings of the 27th ACM SIGKDD Conference on Knowledge
  Discovery \& Data Mining}, pages 934--942, 2021.

\bibitem[Rozemberczki et~al.(2022)Rozemberczki, Watson, Bayer, Yang, Kiss,
  Nilsson, and Sarkar]{rozemberczki2022shapley}
Benedek Rozemberczki, Lauren Watson, P{\'e}ter Bayer, Hao-Tsung Yang,
  Oliv{\'e}r Kiss, Sebastian Nilsson, and Rik Sarkar.
\newblock The shapley value in machine learning.
\newblock \emph{arXiv preprint arXiv:2202.05594}, 2022.

\bibitem[Shapley(1953{\natexlab{b}})]{shapley1953additive}
Lloyd~S Shapley.
\newblock \emph{Additive and non-additive set functions}.
\newblock Princeton University, 1953{\natexlab{b}}.

\bibitem[Banzhaf~III(1964)]{banzhaf1964weighted}
John~F Banzhaf~III.
\newblock Weighted voting doesn't work: A mathematical analysis.
\newblock \emph{Rutgers L. Rev.}, 19:\penalty0 317, 1964.

\bibitem[Kalai and Samet(1987)]{kalai1987weighted}
Ehud Kalai and Dov Samet.
\newblock On weighted shapley values.
\newblock \emph{International journal of game theory}, 16\penalty0
  (3):\penalty0 205--222, 1987.

\bibitem[Weber(1988)]{weber1988probabilistic}
Robert~J Weber.
\newblock Probabilistic values for games.
\newblock \emph{The Shapley Value. Essays in Honor of Lloyd S. Shapley}, pages
  101--119, 1988.

\bibitem[Kwon and Zou(2021)]{kwon2021beta}
Yongchan Kwon and James Zou.
\newblock Beta shapley: a unified and noise-reduced data valuation framework
  for machine learning.
\newblock \emph{arXiv preprint arXiv:2110.14049}, 2021.

\bibitem[Zintgraf et~al.(2017)Zintgraf, Cohen, Adel, and
  Welling]{zintgraf2017visualizing}
Luisa~M Zintgraf, Taco~S Cohen, Tameem Adel, and Max Welling.
\newblock Visualizing deep neural network decisions: Prediction difference
  analysis.
\newblock \emph{arXiv preprint arXiv:1702.04595}, 2017.

\bibitem[Guyon and Elisseeff(2003)]{guyon2003introduction}
Isabelle Guyon and Andr{\'e} Elisseeff.
\newblock An introduction to variable and feature selection.
\newblock \emph{Journal of machine learning research}, 3\penalty0
  (Mar):\penalty0 1157--1182, 2003.

\bibitem[Kumar et~al.(2020)Kumar, Venkatasubramanian, Scheidegger, and
  Friedler]{kumar2020problems}
I~Elizabeth Kumar, Suresh Venkatasubramanian, Carlos Scheidegger, and Sorelle
  Friedler.
\newblock Problems with shapley-value-based explanations as feature importance
  measures.
\newblock In \emph{International Conference on Machine Learning}, pages
  5491--5500. PMLR, 2020.

\bibitem[Shrikumar et~al.(2017)Shrikumar, Greenside, and
  Kundaje]{shrikumar2017learning}
Avanti Shrikumar, Peyton Greenside, and Anshul Kundaje.
\newblock Learning important features through propagating activation
  differences.
\newblock In \emph{International conference on machine learning}, pages
  3145--3153. PMLR, 2017.

\bibitem[Alvarez-Melis and Jaakkola(2018)]{alvarez2018robustness}
David Alvarez-Melis and Tommi~S Jaakkola.
\newblock On the robustness of interpretability methods.
\newblock \emph{arXiv preprint arXiv:1806.08049}, 2018.

\bibitem[Yeh et~al.(2019)Yeh, Hsieh, Suggala, Inouye, and
  Ravikumar]{yeh2019fidelity}
Chih-Kuan Yeh, Cheng-Yu Hsieh, Arun Suggala, David~I Inouye, and Pradeep~K
  Ravikumar.
\newblock On the (in) fidelity and sensitivity of explanations.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Petsiuk et~al.(2018)Petsiuk, Das, and Saenko]{petsiuk2018rise}
Vitali Petsiuk, Abir Das, and Kate Saenko.
\newblock Rise: Randomized input sampling for explanation of black-box models.
\newblock \emph{arXiv preprint arXiv:1806.07421}, 2018.

\bibitem[Dubey and Weber(1977)]{dubey1977probabilistic}
Pradeep Dubey and Robert~James Weber.
\newblock Probabilistic values for games.
\newblock Technical report, YALE UNIV NEW HAVEN CONN COWLES FOUNDATION FOR
  RESEARCH IN ECONOMICS, 1977.

\bibitem[Ridaoui et~al.(2018)Ridaoui, Grabisch, and
  Labreuche]{ridaoui2018axiomatisation}
Mustapha Ridaoui, Michel Grabisch, and Christophe Labreuche.
\newblock An axiomatisation of the banzhaf value and interaction index for
  multichoice games.
\newblock In \emph{International Conference on Modeling Decisions for
  Artificial Intelligence}, pages 143--155. Springer, 2018.

\bibitem[Monderer and Samet(2002)]{monderer2002variations}
Dov Monderer and Dov Samet.
\newblock Variations on the shapley value.
\newblock \emph{Handbook of game theory with economic applications},
  3:\penalty0 2055--2076, 2002.

\bibitem[Jethani et~al.(2021{\natexlab{b}})Jethani, Sudarshan, Aphinyanaphongs,
  and Ranganath]{jethani2021have}
Neil Jethani, Mukund Sudarshan, Yindalon Aphinyanaphongs, and Rajesh Ranganath.
\newblock Have we learned to explain?: How interpretability methods can learn
  to encode predictions in their interpretations.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 1459--1467. PMLR, 2021{\natexlab{b}}.

\bibitem[Covert et~al.(2020)Covert, Lundberg, and Lee]{covert2020understanding}
Ian Covert, Scott~M Lundberg, and Su-In Lee.
\newblock Understanding global feature contributions with additive importance
  measures.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 17212--17223, 2020.

\bibitem[Catav et~al.(2021)Catav, Fu, Zoabi, Meilik, Shomron, Ernst,
  Sankararaman, and Gilad-Bachrach]{catav21marginal}
Amnon Catav, Boyang Fu, Yazeed Zoabi, Ahuva Libi~Weiss Meilik, Noam Shomron,
  Jason Ernst, Sriram Sankararaman, and Ran Gilad-Bachrach.
\newblock Marginal contribution feature importance - an axiomatic approach for
  explaining data.
\newblock In Marina Meila and Tong Zhang, editors, \emph{Proceedings of the
  38th International Conference on Machine Learning}, volume 139 of
  \emph{Proceedings of Machine Learning Research}, pages 1324--1335. PMLR,
  18--24 Jul 2021.
\newblock URL \url{https://proceedings.mlr.press/v139/catav21a.html}.

\bibitem[Clevert et~al.(2015)Clevert, Unterthiner, and
  Hochreiter]{clevert2015fast}
Djork-Arn{\'e} Clevert, Thomas Unterthiner, and Sepp Hochreiter.
\newblock Fast and accurate deep network learning by exponential linear units
  (elus).
\newblock \emph{arXiv preprint arXiv:1511.07289}, 2015.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Vats and Knudson(2021)]{vats2021revisiting}
Dootika Vats and Christina Knudson.
\newblock Revisiting the gelman--rubin diagnostic.
\newblock \emph{Statistical Science}, 36\penalty0 (4):\penalty0 518--529, 2021.

\bibitem[Gelman et~al.(1995)Gelman, Carlin, Stern, and
  Rubin]{gelman1995bayesian}
Andrew Gelman, John~B Carlin, Hal~S Stern, and Donald~B Rubin.
\newblock \emph{Bayesian data analysis}.
\newblock Chapman and Hall/CRC, 1995.

\bibitem[Dua and Graff(2017)]{Dua2019}
Dheeru Dua and Casey Graff.
\newblock {UCI} machine learning repository, 2017.
\newblock URL \url{http://archive.ics.uci.edu/ml}.

\bibitem[Harrison~Jr and Rubinfeld(1978)]{harrison1978hedonic}
David Harrison~Jr and Daniel~L Rubinfeld.
\newblock Hedonic housing prices and the demand for clean air.
\newblock \emph{Journal of environmental economics and management}, 5\penalty0
  (1):\penalty0 81--102, 1978.

\bibitem[Dal~Pozzolo et~al.(2015)Dal~Pozzolo, Caelen, Johnson, and
  Bontempi]{dal2015calibrating}
Andrea Dal~Pozzolo, Olivier Caelen, Reid~A Johnson, and Gianluca Bontempi.
\newblock Calibrating probability with undersampling for unbalanced
  classification.
\newblock In \emph{2015 IEEE Symposium Series on Computational Intelligence},
  pages 159--166. IEEE, 2015.

\bibitem[Ke et~al.(2017)Ke, Meng, Finley, Wang, Chen, Ma, Ye, and
  Liu]{ke2017lightgbm}
Guolin Ke, Qi~Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei
  Ye, and Tie-Yan Liu.
\newblock Lightgbm: A highly efficient gradient boosting decision tree.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Masoomi et~al.(2021)Masoomi, Hill, Xu, Hersh, Silverman, Castaldi,
  Ioannidis, and Dy]{masoomi2021explanations}
Aria Masoomi, Davin Hill, Zhonghui Xu, Craig~P Hersh, Edwin~K Silverman,
  Peter~J Castaldi, Stratis Ioannidis, and Jennifer Dy.
\newblock Explanations of black-box models based on directional feature
  interactions.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\end{thebibliography}
