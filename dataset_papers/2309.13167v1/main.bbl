\begin{thebibliography}{100}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agrawal et~al.(2015)Agrawal, Carreira, and Malik]{agrawal2015learning}
Pulkit Agrawal, Joao Carreira, and Jitendra Malik.
\newblock Learning to see by moving.
\newblock In \emph{ICCV}, 2015.

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and
  Bottou]{arjovsky2017wasserstein}
Martin Arjovsky, Soumith Chintala, and L{\'e}on Bottou.
\newblock Wasserstein generative adversarial networks.
\newblock In \emph{ICML}, 2017.

\bibitem[Bajaj et~al.(2023)Bajaj, McLennan, Andeen, and Roy]{bajaj2023recipes}
Chandrajit Bajaj, Luke McLennan, Timothy Andeen, and Avik Roy.
\newblock Recipes for when physics fails: Recovering robust learning of physics
  informed neural networks.
\newblock \emph{Machine Learning: Science and Technology}, 2023.

\bibitem[Benamou and Brenier(2000)]{benamou2000computational}
Jean-David Benamou and Yann Brenier.
\newblock A computational fluid mechanics solution to the monge-kantorovich
  mass transfer problem.
\newblock \emph{Numerische Mathematik}, 2000.

\bibitem[Bengio et~al.(2013{\natexlab{a}})Bengio, Courville, and
  Vincent]{bengio2013representation}
Yoshua Bengio, Aaron Courville, and Pascal Vincent.
\newblock Representation learning: A review and new perspectives.
\newblock \emph{IEEE T-PAMI}, 2013{\natexlab{a}}.

\bibitem[Bengio et~al.(2013{\natexlab{b}})Bengio, L{\'e}onard, and
  Courville]{bengio2013estimating}
Yoshua Bengio, Nicholas L{\'e}onard, and Aaron Courville.
\newblock Estimating or propagating gradients through stochastic neurons for
  conditional computation.
\newblock \emph{arXiv preprint arXiv:1308.3432}, 2013{\natexlab{b}}.

\bibitem[Bouchacourt et~al.(2021)Bouchacourt, Ibrahim, and
  Deny]{bouchacourt2021addressing}
Diane Bouchacourt, Mark Ibrahim, and St{\'e}phane Deny.
\newblock Addressing the topological defects of disentanglement via distributed
  operators.
\newblock \emph{arXiv preprint arXiv:2102.05623}, 2021.

\bibitem[Brandstetter et~al.(2022)Brandstetter, Worrall, and
  Welling]{brandstetter2022message}
Johannes Brandstetter, Daniel Worrall, and Max Welling.
\newblock Message passing neural pde solvers.
\newblock \emph{ICLR}, 2022.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  et~al.
\newblock Language models are few-shot learners.
\newblock \emph{NeurIPS}, 2020.

\bibitem[Burgess and Kim(2018)]{3dshapes18}
Chris Burgess and Hyunjik Kim.
\newblock 3d shapes dataset.
\newblock https://github.com/deepmind/3dshapes-dataset/, 2018.

\bibitem[Chen et~al.(2019)Chen, Rubanova, Bettencourt, and
  Duvenaud]{chen2019neural}
Ricky T.~Q. Chen, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud.
\newblock Neural ordinary differential equations, 2019.

\bibitem[Chen et~al.(2018)Chen, Li, Grosse, and Duvenaud]{chen2018isolating}
Ricky~TQ Chen, Xuechen Li, Roger~B Grosse, and David~K Duvenaud.
\newblock Isolating sources of disentanglement in variational autoencoders.
\newblock \emph{NeurIPS}, 2018.

\bibitem[Chen et~al.(2016)Chen, Duan, Houthooft, Schulman, Sutskever, and
  Abbeel]{chen2016infogan}
Xi~Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter
  Abbeel.
\newblock Infogan: Interpretable representation learning by information
  maximizing generative adversarial nets.
\newblock \emph{NeurIPS}, 2016.

\bibitem[Chizat et~al.(2020)Chizat, Roussillon, L{\'e}ger, Vialard, and
  Peyr{\'e}]{chizat2020faster}
Lenaic Chizat, Pierre Roussillon, Flavien L{\'e}ger, Fran{\c{c}}ois-Xavier
  Vialard, and Gabriel Peyr{\'e}.
\newblock Faster wasserstein distance estimation with the sinkhorn divergence.
\newblock \emph{NeurIPS}, 2020.

\bibitem[Cohen and Welling(2015)]{cohen2015transformation}
Taco~S Cohen and Max Welling.
\newblock Transformation properties of learned visual representations.
\newblock \emph{ICLR}, 2015.

\bibitem[Cohen and Welling(2016)]{cohen2016group}
Taco~S Cohen and Max Welling.
\newblock Group equivariant convolutional networks.
\newblock In \emph{ICML}. PMLR, 2016.

\bibitem[Cohen and Welling(2017)]{cohen2017steerable}
Taco~S Cohen and Max Welling.
\newblock Steerable cnns.
\newblock \emph{ICLR}, 2017.

\bibitem[Connor et~al.(2021)Connor, Canal, and Rozell]{connor2021variational}
Marissa Connor, Gregory Canal, and Christopher Rozell.
\newblock Variational autoencoder with learned latent structure.
\newblock In \emph{AISTATS}. PMLR, 2021.

\bibitem[Cuturi(2013)]{cuturi2013sinkhorn}
Marco Cuturi.
\newblock Sinkhorn distances: Lightspeed computation of optimal transport.
\newblock \emph{NeurIPS}, 2013.

\bibitem[Dey et~al.(2021)Dey, Chen, and Ghafurian]{dey2021group}
Neel Dey, Antong Chen, and Soheil Ghafurian.
\newblock Group equivariant generative adversarial networks.
\newblock \emph{ICLR}, 2021.

\bibitem[Diaconu and Worrall(2019)]{diaconu2019learning}
Nichita Diaconu and Daniel Worrall.
\newblock Learning to convolve: A generalized weight-tying approach.
\newblock In \emph{ICML}. PMLR, 2019.

\bibitem[Dilokthanakul et~al.(2016)Dilokthanakul, Mediano, Garnelo, Lee,
  Salimbeni, Arulkumaran, and Shanahan]{dilokthanakul2017deep}
Nat Dilokthanakul, Pedro~AM Mediano, Marta Garnelo, Matthew~CH Lee, Hugh
  Salimbeni, Kai Arulkumaran, and Murray Shanahan.
\newblock Deep unsupervised clustering with gaussian mixture variational
  autoencoders.
\newblock \emph{ICLR}, 2016.

\bibitem[Ding et~al.(2020)Ding, Xu, Xu, Parmar, Yang, Welling, and
  Tu]{ding2020guided}
Zheng Ding, Yifan Xu, Weijian Xu, Gaurav Parmar, Yang Yang, Max Welling, and
  Zhuowen Tu.
\newblock Guided variational autoencoder for disentanglement learning.
\newblock In \emph{CVPR}, 2020.

\bibitem[Dinh et~al.(2017)Dinh, Sohl-Dickstein, and Bengio]{dinh2016density}
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
\newblock Density estimation using real nvp.
\newblock \emph{ICLR}, 2017.

\bibitem[Dupont(2018)]{dupont2018learning}
Emilien Dupont.
\newblock Learning disentangled joint continuous and discrete representations.
\newblock \emph{NeurIPS}, 2018.

\bibitem[Eastwood and Williams(2018)]{eastwood2018framework}
Cian Eastwood and Christopher~KI Williams.
\newblock A framework for the quantitative evaluation of disentangled
  representations.
\newblock In \emph{ICLR}, 2018.

\bibitem[Eisenberger et~al.(2022)Eisenberger, Toker, Leal-Taix{\'e}, Bernard,
  and Cremers]{eisenberger2022unified}
Marvin Eisenberger, Aysim Toker, Laura Leal-Taix{\'e}, Florian Bernard, and
  Daniel Cremers.
\newblock A unified framework for implicit sinkhorn differentiation.
\newblock In \emph{CVPR}, 2022.

\bibitem[Estermann and Wattenhofer(2023)]{estermann2023dava}
Benjamin Estermann and Roger Wattenhofer.
\newblock Dava: Disentangling adversarial variational autoencoder.
\newblock \emph{ICLR}, 2023.

\bibitem[Feydy et~al.(2019)Feydy, S{\'e}journ{\'e}, Vialard, Amari, Trouv{\'e},
  and Peyr{\'e}]{feydy2019interpolating}
Jean Feydy, Thibault S{\'e}journ{\'e}, Fran{\c{c}}ois-Xavier Vialard, Shun-ichi
  Amari, Alain Trouv{\'e}, and Gabriel Peyr{\'e}.
\newblock Interpolating between optimal transport and mmd using sinkhorn
  divergences.
\newblock In \emph{AISTATS}, 2019.

\bibitem[Finlay et~al.(2020)Finlay, Jacobsen, Nurbekyan, and
  Oberman]{finlay2020train}
Chris Finlay, J{\"o}rn-Henrik Jacobsen, Levon Nurbekyan, and Adam Oberman.
\newblock How to train your neural ode: the world of jacobian and kinetic
  regularization.
\newblock In \emph{ICML}. PMLR, 2020.

\bibitem[Finzi et~al.(2020)Finzi, Stanton, Izmailov, and
  Wilson]{finzi2020generalizing}
Marc Finzi, Samuel Stanton, Pavel Izmailov, and Andrew~Gordon Wilson.
\newblock Generalizing convolutional neural networks for equivariance to lie
  groups on arbitrary continuous data.
\newblock In \emph{ICML}. PMLR, 2020.

\bibitem[Frogner et~al.(2015)Frogner, Zhang, Mobahi, Araya, and
  Poggio]{frogner2015learning}
Charlie Frogner, Chiyuan Zhang, Hossein Mobahi, Mauricio Araya, and Tomaso~A
  Poggio.
\newblock Learning with a wasserstein loss.
\newblock \emph{NeurIPS}, 2015.

\bibitem[Goetschalckx et~al.(2019)Goetschalckx, Andonian, Oliva, and
  Isola]{goetschalckx2019ganalyze}
Lore Goetschalckx, Alex Andonian, Aude Oliva, and Phillip Isola.
\newblock Ganalyze: Toward visual definitions of cognitive image properties.
\newblock In \emph{ICCV}, 2019.

\bibitem[H{\"a}rk{\"o}nen et~al.(2020)H{\"a}rk{\"o}nen, Hertzmann, Lehtinen,
  and Paris]{harkonen2020ganspace}
Erik H{\"a}rk{\"o}nen, Aaron Hertzmann, Jaakko Lehtinen, and Sylvain Paris.
\newblock Ganspace: Discovering interpretable gan controls.
\newblock \emph{NeurIPS}, 2020.

\bibitem[Higgins et~al.(2016)Higgins, Matthey, Pal, Burgess, Glorot, Botvinick,
  Mohamed, and Lerchner]{higgins2016beta}
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot,
  Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner.
\newblock beta-vae: Learning basic visual concepts with a constrained
  variational framework.
\newblock \emph{ICLR}, 2016.

\bibitem[Higgins et~al.(2018)Higgins, Amos, Pfau, Racaniere, Matthey, Rezende,
  and Lerchner]{higgins2018towards}
Irina Higgins, David Amos, David Pfau, Sebastien Racaniere, Loic Matthey,
  Danilo Rezende, and Alexander Lerchner.
\newblock Towards a definition of disentangled representations.
\newblock \emph{arXiv preprint arXiv:1812.02230}, 2018.

\bibitem[Higgins et~al.(2021)Higgins, Chang, Langston, Hassabis, Summerfield,
  Tsao, and Botvinick]{higgins2021unsupervised}
Irina Higgins, Le~Chang, Victoria Langston, Demis Hassabis, Christopher
  Summerfield, Doris Tsao, and Matthew Botvinick.
\newblock Unsupervised deep learning identifies semantic disentanglement in
  single inferotemporal face patch neurons.
\newblock \emph{Nature communications}, 2021.

\bibitem[Hinton et~al.(2011)Hinton, Krizhevsky, and
  Wang]{hinton2011transforming}
Geoffrey~E Hinton, Alex Krizhevsky, and Sida~D Wang.
\newblock Transforming auto-encoders.
\newblock In \emph{ICANN}. Springer, 2011.

\bibitem[Hoogeboom et~al.(2022)Hoogeboom, Satorras, Vignac, and
  Welling]{hoogeboom2022equivariant}
Emiel Hoogeboom, V{\i}ctor~Garcia Satorras, Cl{\'e}ment Vignac, and Max
  Welling.
\newblock Equivariant diffusion for molecule generation in 3d.
\newblock In \emph{ICML}. PMLR, 2022.

\bibitem[Hsieh et~al.(2019)Hsieh, Zhao, Eismann, Mirabella, and
  Ermon]{hsieh2019learning}
Jun-Ting Hsieh, Shengjia Zhao, Stephan Eismann, Lucia Mirabella, and Stefano
  Ermon.
\newblock Learning neural pde solvers with convergence guarantees.
\newblock \emph{ICLR}, 2019.

\bibitem[Hu et~al.(2023)Hu, Zhang, Tang, Mettes, Zhao, and Snoek]{hu2023latent}
Vincent~Tao Hu, David~W Zhang, Meng Tang, Pascal Mettes, Deli Zhao, and Cees~GM
  Snoek.
\newblock Latent space editing in transformer-based flow matching.
\newblock In \emph{ICML Workshop}, 2023.

\bibitem[Jahanian et~al.(2020)Jahanian, Chai, and
  Isola]{jahanian2020steerability}
Ali Jahanian, Lucy Chai, and Phillip Isola.
\newblock On the" steerability" of generative adversarial networks.
\newblock \emph{ICLR}, 2020.

\bibitem[Jang et~al.(2017)Jang, Gu, and Poole]{jang2017categorical}
Eric Jang, Shixiang Gu, and Ben Poole.
\newblock Categorical reparameterization with gumbel-softmax.
\newblock \emph{ICLR}, 2017.

\bibitem[Jeong and Song(2019)]{jeong2019learning}
Yeonwoo Jeong and Hyun~Oh Song.
\newblock Learning discrete and continuous factors of data via alternating
  disentanglement.
\newblock In \emph{ICML}, 2019.

\bibitem[Keller and Welling(2021)]{keller2021topographic}
T~Anderson Keller and Max Welling.
\newblock Topographic vaes learn equivariant capsules.
\newblock \emph{NeurIPS}, 2021.

\bibitem[Kim and Mnih(2018)]{kim2018disentangling}
Hyunjik Kim and Andriy Mnih.
\newblock Disentangling by factorising.
\newblock In \emph{ICML}, 2018.

\bibitem[Kingma and Welling(2014)]{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock \emph{ICLR}, 2014.

\bibitem[Kingma and Dhariwal(2018)]{kingma2018glow}
Durk~P Kingma and Prafulla Dhariwal.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock \emph{NeurIPS}, 2018.

\bibitem[Klindt et~al.(2021)Klindt, Schott, Sharma, Ustyuzhaninov, Brendel,
  Bethge, and Paiton]{klindt2021towards}
David Klindt, Lukas Schott, Yash Sharma, Ivan Ustyuzhaninov, Wieland Brendel,
  Matthias Bethge, and Dylan Paiton.
\newblock Towards nonlinear disentanglement in natural data with temporal
  sparse coding.
\newblock \emph{ICLR}, 2021.

\bibitem[K{\"o}hler et~al.(2020)K{\"o}hler, Klein, and
  No{\'e}]{kohler2020equivariant}
Jonas K{\"o}hler, Leon Klein, and Frank No{\'e}.
\newblock Equivariant flows: exact likelihood generative learning for symmetric
  densities.
\newblock In \emph{ICML}. PMLR, 2020.

\bibitem[Kolouri et~al.(2021)Kolouri, Naderializadeh, Rohde, and
  Hoffmann]{kolouri2020wasserstein}
Soheil Kolouri, Navid Naderializadeh, Gustavo~K Rohde, and Heiko Hoffmann.
\newblock Wasserstein embedding for graph learning.
\newblock \emph{ICLR}, 2021.

\bibitem[Kumar et~al.(2018)Kumar, Sattigeri, and
  Balakrishnan]{kumar2018variational}
Abhishek Kumar, Prasanna Sattigeri, and Avinash Balakrishnan.
\newblock Variational inference of disentangled latent concepts from unlabeled
  observations.
\newblock \emph{ICLR}, 2018.

\bibitem[Kwon et~al.(2023)Kwon, Jeong, and Uh]{kwon2022diffusion}
Mingi Kwon, Jaeseok Jeong, and Youngjung Uh.
\newblock Diffusion models already have a semantic latent space.
\newblock \emph{ICLR}, 2023.

\bibitem[LeCun(1998)]{lecun1998mnist}
Yann LeCun.
\newblock The mnist database of handwritten digits.
\newblock 1998.
\newblock URL \url{http://yann.lecun.com/exdb/mnist/}.

\bibitem[LeCun et~al.(2015)LeCun, Bengio, and Hinton]{lecun2015deep}
Yann LeCun, Yoshua Bengio, and Geoffrey Hinton.
\newblock Deep learning.
\newblock \emph{nature}, 2015.

\bibitem[Lee et~al.(2015)Lee, Xie, Gallagher, Zhang, and Tu]{lee2015deeply}
Chen-Yu Lee, Saining Xie, Patrick Gallagher, Zhengyou Zhang, and Zhuowen Tu.
\newblock Deeply-supervised nets.
\newblock In \emph{AISTATS}. PMLR, 2015.

\bibitem[Lenc and Vedaldi(2015)]{lenc2015understanding}
Karel Lenc and Andrea Vedaldi.
\newblock Understanding image representations by measuring their equivariance
  and equivalence.
\newblock In \emph{CVPR}, 2015.

\bibitem[Locatello et~al.(2020)Locatello, Poole, R{\"a}tsch, Sch{\"o}lkopf,
  Bachem, and Tschannen]{locatello2020weakly}
Francesco Locatello, Ben Poole, Gunnar R{\"a}tsch, Bernhard Sch{\"o}lkopf,
  Olivier Bachem, and Michael Tschannen.
\newblock Weakly-supervised disentanglement without compromises.
\newblock In \emph{ICML}. PMLR, 2020.

\bibitem[Matthey et~al.(2017)Matthey, Higgins, Hassabis, and
  Lerchner]{dsprites17}
Loic Matthey, Irina Higgins, Demis Hassabis, and Alexander Lerchner.
\newblock dsprites: Disentanglement testing sprites dataset, 2017.
\newblock URL \url{https://github.com/deepmind/dsprites-dataset/}.

\bibitem[Neklyudov et~al.(2023)Neklyudov, Severo, and
  Makhzani]{neklyudov2023action}
Kirill Neklyudov, Daniel Severo, and Alireza Makhzani.
\newblock Action matching: A variational method for learning stochastic
  dynamics from samples.
\newblock \emph{ICML}, 2023.

\bibitem[Nie et~al.(2020)Nie, Karras, Garg, Debnath, Patney, Patel, and
  Anandkumar]{nie2020semi}
Weili Nie, Tero Karras, Animesh Garg, Shoubhik Debnath, Anjul Patney, Ankit~B
  Patel, and Anima Anandkumar.
\newblock Semi-supervised stylegan for disentanglement learning.
\newblock In \emph{ICML}, 2020.

\bibitem[Oldfield et~al.(2023)Oldfield, Tzelepis, Panagakis, Nicolaou, and
  Patras]{oldfield2022panda}
James Oldfield, Christos Tzelepis, Yannis Panagakis, Mihalis~A Nicolaou, and
  Ioannis Patras.
\newblock Panda: Unsupervised learning of parts and appearances in the feature
  maps of gans.
\newblock \emph{ICLR}, 2023.

\bibitem[Onken et~al.(2021)Onken, Fung, Li, and Ruthotto]{onken2021ot}
Derek Onken, Samy~Wu Fung, Xingjian Li, and Lars Ruthotto.
\newblock Ot-flow: Fast and accurate continuous normalizing flows via optimal
  transport.
\newblock In \emph{AAAI}, 2021.

\bibitem[Park et~al.(2023)Park, Kwon, Jo, and Uh]{park2023unsupervised}
Yong-Hyun Park, Mingi Kwon, Junghyo Jo, and Youngjung Uh.
\newblock Unsupervised discovery of semantic latent directions in diffusion
  models.
\newblock \emph{arXiv preprint arXiv:2302.12469}, 2023.

\bibitem[Patrini et~al.(2020)Patrini, van~den Berg, Forre, Carioni, Bhargav,
  Welling, Genewein, and Nielsen]{patrini2020sinkhorn}
Giorgio Patrini, Rianne van~den Berg, Patrick Forre, Marcello Carioni, Samarth
  Bhargav, Max Welling, Tim Genewein, and Frank Nielsen.
\newblock Sinkhorn autoencoders.
\newblock In \emph{UAI}, 2020.

\bibitem[Peebles et~al.(2020)Peebles, Peebles, Zhu, Efros, and
  Torralba]{peebles2020hessian}
William Peebles, John Peebles, Jun-Yan Zhu, Alexei Efros, and Antonio Torralba.
\newblock The hessian penalty: A weak prior for unsupervised disentanglement.
\newblock In \emph{ECCV}, 2020.

\bibitem[Raissi et~al.(2019)Raissi, Perdikaris, and Karniadakis]{pinns}
M.~Raissi, P.~Perdikaris, and G.E. Karniadakis.
\newblock Physics-informed neural networks: A deep learning framework for
  solving forward and inverse problems involving nonlinear partial differential
  equations.
\newblock \emph{Journal of Computational Physics}, 2019.

\bibitem[Ravanbakhsh et~al.(2017)Ravanbakhsh, Schneider, and
  Poczos]{ravanbakhsh2017equivariance}
Siamak Ravanbakhsh, Jeff Schneider, and Barnabas Poczos.
\newblock Equivariance through parameter-sharing.
\newblock In \emph{ICML}. PMLR, 2017.

\bibitem[Rezende and Mohamed(2015)]{rezende2015variational}
Danilo Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock In \emph{ICML}. PMLR, 2015.

\bibitem[Richter-Powell et~al.(2022)Richter-Powell, Lipman, and
  Chen]{richter2022neural}
Jack Richter-Powell, Yaron Lipman, and Ricky~TQ Chen.
\newblock Neural conservation laws: A divergence-free perspective.
\newblock \emph{NeurIPS}, 2022.

\bibitem[Ridgeway and Mozer(2018)]{ridgeway2018learning}
Karl Ridgeway and Michael~C Mozer.
\newblock Learning deep disentangled embeddings with the f-statistic loss.
\newblock \emph{NeurIPS}, 2018.

\bibitem[Salimans et~al.(2018)Salimans, Zhang, Radford, and
  Metaxas]{salimans2018improving}
Tim Salimans, Han Zhang, Alec Radford, and Dimitris Metaxas.
\newblock Improving gans using optimal transport.
\newblock \emph{ICLR}, 2018.

\bibitem[Satorras et~al.(2021)Satorras, Hoogeboom, Fuchs, Posner, and
  Welling]{satorras2021n}
Victor~Garcia Satorras, Emiel Hoogeboom, Fabian~B Fuchs, Ingmar Posner, and Max
  Welling.
\newblock E (n) equivariant normalizing flows.
\newblock \emph{NeurIPS}, 2021.

\bibitem[Schmidhuber(1992)]{schmidhuber1992learning}
J{\"u}rgen Schmidhuber.
\newblock Learning factorial codes by predictability minimization.
\newblock \emph{Neural computation}, 1992.

\bibitem[Schmidt and Roth(2012)]{schmidt2012learning}
Uwe Schmidt and Stefan Roth.
\newblock Learning rotation-aware features: From invariant priors to
  equivariant descriptors.
\newblock In \emph{CVPR}, 2012.

\bibitem[Shao et~al.(2020)Shao, Yao, Sun, Zhang, Liu, Liu, Wang, and
  Abdelzaher]{shao2020controlvae}
Huajie Shao, Shuochao Yao, Dachun Sun, Aston Zhang, Shengzhong Liu, Dongxin
  Liu, Jun Wang, and Tarek Abdelzaher.
\newblock Controlvae: Controllable variational autoencoder.
\newblock In \emph{ICML}. PMLR, 2020.

\bibitem[Shen and Zhou(2021)]{shen2021closed}
Yujun Shen and Bolei Zhou.
\newblock Closed-form factorization of latent semantics in gans.
\newblock In \emph{CVPR}, 2021.

\bibitem[Song et~al.(2022)Song, Sebe, and Wang]{song2022orthogonal}
Yue Song, Nicu Sebe, and Wei Wang.
\newblock Orthogonal svd covariance conditioning and latent disentanglement.
\newblock \emph{IEEE T-PAMI}, 2022.

\bibitem[Song et~al.(2023)Song, Keller, Sebe, and Welling]{song2023latent}
Yue Song, Andy Keller, Nicu Sebe, and Max Welling.
\newblock Latent traversals in generative models as potential flows.
\newblock In \emph{ICML}. PMLR, 2023.

\bibitem[Tai et~al.(2022)Tai, Li, and Ku]{tai2022hyperbolic}
Chang-Yu Tai, Ming-Yao Li, and Lun-Wei Ku.
\newblock Hyperbolic disentangled representation for fine-grained aspect
  extraction.
\newblock In \emph{AAAI}, 2022.

\bibitem[Tolstikhin et~al.(2018)Tolstikhin, Bousquet, Gelly, and
  Schoelkopf]{tolstikhin2017wasserstein}
Ilya Tolstikhin, Olivier Bousquet, Sylvain Gelly, and Bernhard Schoelkopf.
\newblock Wasserstein auto-encoders.
\newblock \emph{ICLR}, 2018.

\bibitem[Tomczak and Welling(2018)]{tomczak2018vae}
Jakub Tomczak and Max Welling.
\newblock Vae with a vampprior.
\newblock In \emph{AISTATS}. PMLR, 2018.

\bibitem[Tong et~al.(2020)Tong, Huang, Wolf, Van~Dijk, and
  Krishnaswamy]{tong2020trajectorynet}
Alexander Tong, Jessie Huang, Guy Wolf, David Van~Dijk, and Smita Krishnaswamy.
\newblock Trajectorynet: A dynamic optimal transport network for modeling
  cellular dynamics.
\newblock In \emph{ICML}. PMLR, 2020.

\bibitem[Tzelepis et~al.(2021)Tzelepis, Tzimiropoulos, and
  Patras]{Tzelepis_2021_ICCV}
Christos Tzelepis, Georgios Tzimiropoulos, and Ioannis Patras.
\newblock {WarpedGANSpace}: Finding non-linear rbf paths in {GAN} latent space.
\newblock In \emph{ICCV}, 2021.

\bibitem[Van~der Pol et~al.(2020)Van~der Pol, Worrall, van Hoof, Oliehoek, and
  Welling]{van2020mdp}
Elise Van~der Pol, Daniel Worrall, Herke van Hoof, Frans Oliehoek, and Max
  Welling.
\newblock Mdp homomorphic networks: Group symmetries in reinforcement learning.
\newblock \emph{NeurIPS}, 2020.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock \emph{NeurIPS}, 2017.

\bibitem[Villani(2009)]{villani2009optimal}
C{\'e}dric Villani.
\newblock \emph{Optimal transport: old and new}, volume 338.
\newblock Springer, 2009.

\bibitem[Villani(2021)]{villani2021topics}
C{\'e}dric Villani.
\newblock \emph{Topics in optimal transportation}, volume~58.
\newblock American Mathematical Soc., 2021.

\bibitem[Voynov and Babenko(2020)]{voynov2020unsupervised}
Andrey Voynov and Artem Babenko.
\newblock Unsupervised discovery of interpretable directions in the gan latent
  space.
\newblock In \emph{ICML}, 2020.

\bibitem[Wei et~al.(2021)Wei, Shi, Liu, Ji, Gao, Wu, and
  Zuo]{wei2021orthogonal}
Yuxiang Wei, Yupeng Shi, Xiao Liu, Zhilong Ji, Yuan Gao, Zhongqin Wu, and
  Wangmeng Zuo.
\newblock Orthogonal jacobian regularization for unsupervised disentanglement
  in image generation.
\newblock In \emph{ICCV}, 2021.

\bibitem[Whittington et~al.(2023)Whittington, Dorrell, Ganguli, and
  Behrens]{whittington2023disentanglement}
James~CR Whittington, Will Dorrell, Surya Ganguli, and Timothy Behrens.
\newblock Disentanglement with biological constraints: A theory of functional
  cell types.
\newblock In \emph{ICLR}, 2023.

\bibitem[Worrall and Welling(2019)]{worrall2019deep}
Daniel Worrall and Max Welling.
\newblock Deep scale-spaces: Equivariance over scale.
\newblock \emph{NeurIPS}, 2019.

\bibitem[Worrall et~al.(2017)Worrall, Garbin, Turmukhambetov, and
  Brostow]{worrall2017harmonic}
Daniel~E Worrall, Stephan~J Garbin, Daniyar Turmukhambetov, and Gabriel~J
  Brostow.
\newblock Harmonic networks: Deep translation and rotation equivariance.
\newblock In \emph{CVPR}, 2017.

\bibitem[Yang and Karniadakis(2020)]{yang2020potential}
Liu Yang and George~Em Karniadakis.
\newblock Potential flow generator with l 2 optimal transport regularity for
  generative models.
\newblock \emph{IEEE TNNLS}, 2020.

\bibitem[Yang et~al.(2023)Yang, Wang, Lv, and Zh]{yang2023disdiff}
Tao Yang, Yuwang Wang, Yan Lv, and Nanning Zh.
\newblock Disdiff: Unsupervised disentanglement of diffusion probabilistic
  models.
\newblock \emph{arXiv preprint arXiv:2301.13721}, 2023.

\bibitem[Yildiz et~al.(2019)Yildiz, Heinonen, and
  Lahdesmaki]{yildiz2019ode2vae}
Cagatay Yildiz, Markus Heinonen, and Harri Lahdesmaki.
\newblock Ode2vae: Deep generative second order odes with bayesian neural
  networks.
\newblock \emph{NeurIPS}, 2019.

\bibitem[Zeng et~al.(2023)Zeng, Bryngelson, and
  Sch{\"a}fer]{zeng2023competitive}
Qi~Zeng, Spencer~H Bryngelson, and Florian Sch{\"a}fer.
\newblock Competitive physics informed networks.
\newblock \emph{ICLR}, 2023.

\bibitem[Zhu et~al.(2021)Zhu, Feng, Shen, Zhao, Zha, Zhou, and
  Chen]{zhu2021low}
Jiapeng Zhu, Ruili Feng, Yujun Shen, Deli Zhao, Zheng-Jun Zha, Jingren Zhou,
  and Qifeng Chen.
\newblock Low-rank subspaces in gans.
\newblock \emph{NeurIPS}, 2021.

\bibitem[Zhu et~al.(2022)Zhu, Shen, Xu, Zhao, and Chen]{zhu2022region}
Jiapeng Zhu, Yujun Shen, Yinghao Xu, Deli Zhao, and Qifeng Chen.
\newblock Region-based semantic factorization in gans.
\newblock \emph{ICML}, 2022.

\bibitem[Zhu et~al.(2020)Zhu, Xu, and Tao]{zhu2020learning}
Xinqi Zhu, Chang Xu, and Dacheng Tao.
\newblock Learning disentangled representations with latent variation
  predictability.
\newblock In \emph{ECCV}, 2020.

\end{thebibliography}
