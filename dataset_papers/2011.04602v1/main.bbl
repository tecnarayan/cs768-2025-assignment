\begin{thebibliography}{59}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aliprantis and Border(2006)]{aliprantis2006infinite}
C.~D. Aliprantis and K.~C. Border.
\newblock Infinite dimensional analysis: a hitchhiker’s guide, 2006.

\bibitem[Ames(2014)]{ames2014numerical}
W.~F. Ames.
\newblock \emph{Numerical methods for partial differential equations}.
\newblock Academic press, 2014.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016layer}
J.~L. Ba, J.~R. Kiros, and G.~E. Hinton.
\newblock Layer normalization.
\newblock \emph{arXiv:1607.06450}, 2016.

\bibitem[Baldi(2017)]{baldi2017stochastic}
P.~Baldi.
\newblock \emph{Stochastic Calculus: An Introduction Through Theory and
  Exercises}.
\newblock Universitext. Springer International Publishing, 2017.

\bibitem[Beck et~al.(2018)Beck, Becker, Grohs, Jaafari, and
  Jentzen]{beck2018solving}
C.~Beck, S.~Becker, P.~Grohs, N.~Jaafari, and A.~Jentzen.
\newblock Solving stochastic differential equations and {Kolmogorov} equations
  by means of deep learning.
\newblock \emph{arXiv:1806.00421}, 2018.

\bibitem[Beck et~al.(2019)Beck, Weinan, and Jentzen]{beck2019machine}
C.~Beck, E.~Weinan, and A.~Jentzen.
\newblock Machine learning approximation algorithms for high-dimensional fully
  nonlinear partial differential equations and second-order backward stochastic
  differential equations.
\newblock \emph{Journal of Nonlinear Science}, 29\penalty0 (4):\penalty0
  1563--1619, 2019.

\bibitem[{Berner} et~al.(2019){Berner}, {Elbrächter}, {Grohs}, and
  {Jentzen}]{berner2019towards}
J.~{Berner}, D.~{Elbrächter}, P.~{Grohs}, and A.~{Jentzen}.
\newblock Towards a regularity theory for {ReLU} networks – chain rule and
  global error estimates.
\newblock In \emph{2019 13th International conference on Sampling Theory and
  Applications (SampTA)}, pages 1--5, 2019.

\bibitem[Berner et~al.(2020)Berner, Grohs, and Jentzen]{berner2018analysis}
J.~Berner, P.~Grohs, and A.~Jentzen.
\newblock Analysis of the generalization error: Empirical risk minimization
  over deep artificial neural networks overcomes the curse of dimensionality in
  the numerical approximation of {Black--Scholes} partial differential
  equations.
\newblock \emph{SIAM Journal on Mathematics of Data Science}, 2\penalty0
  (3):\penalty0 631--657, 2020.

\bibitem[Black and Scholes(1973)]{black1973pricing}
F.~Black and M.~Scholes.
\newblock The pricing of options and corporate liabilities.
\newblock \emph{Journal of political economy}, 81\penalty0 (3):\penalty0
  637--654, 1973.

\bibitem[Crandall et~al.(1992)Crandall, Ishii, and Lions]{crandall1992user}
M.~G. Crandall, H.~Ishii, and P.-L. Lions.
\newblock User’s guide to viscosity solutions of second order partial
  differential equations.
\newblock \emph{Bulletin of the American mathematical society}, 27\penalty0
  (1):\penalty0 1--67, 1992.

\bibitem[Cucker and Smale(2002)]{cucker2002mathematical}
F.~Cucker and S.~Smale.
\newblock On the mathematical foundations of learning.
\newblock \emph{Bulletin of the American mathematical society}, 39\penalty0
  (1):\penalty0 1--49, 2002.

\bibitem[Eigel et~al.(2018)Eigel, Schneider, Trunschke, and
  Wolf]{eigel2018variational}
M.~Eigel, R.~Schneider, P.~Trunschke, and S.~Wolf.
\newblock Variational {Monte Carlo}-bridging concepts of machine learning and
  high dimensional partial differential equations.
\newblock \emph{arXiv:1810.01348}, 2018.

\bibitem[Ekström and Tysk(2010)]{EKSTROM2010498}
E.~Ekström and J.~Tysk.
\newblock The {Black–Scholes} equation in stochastic volatility models.
\newblock \emph{Journal of Mathematical Analysis and Applications},
  368\penalty0 (2):\penalty0 498 -- 507, 2010.

\bibitem[Elbr{\"a}chter et~al.(2018)Elbr{\"a}chter, Grohs, Jentzen, and
  Schwab]{elbrachter2018dnn}
D.~Elbr{\"a}chter, P.~Grohs, A.~Jentzen, and C.~Schwab.
\newblock {DNN} expression rate analysis of high-dimensional {PDEs}:
  Application to option pricing.
\newblock \emph{arXiv:1809.07669}, 2018.

\bibitem[Evans and Gariepy(2015)]{Evans2015MeasureEdition}
L.~C. Evans and R.~F. Gariepy.
\newblock \emph{{Measure Theory and Fine Properties of Functions, Revised
  Edition}}.
\newblock Textbooks in Mathematics. CRC Press, 2015.

\bibitem[Friedman(2012)]{friedman2012}
A.~Friedman.
\newblock \emph{Stochastic Differential Equations and Applications}.
\newblock Dover Books on Mathematics. Dover Publications, 2012.

\bibitem[Gall(2016)]{gall2016}
J.~Gall.
\newblock \emph{Brownian Motion, Martingales, and Stochastic Calculus}.
\newblock Graduate Texts in Mathematics. Springer International Publishing,
  2016.

\bibitem[Giles(2015)]{giles_2015}
M.~B. Giles.
\newblock {Multilevel Monte Carlo} methods.
\newblock \emph{Acta Numerica}, 24:\penalty0 259–328, 2015.

\bibitem[Graham and Talay(2013)]{graham2013stochastic}
C.~Graham and D.~Talay.
\newblock \emph{Stochastic Simulation and {Monte Carlo} Methods: Mathematical
  Foundations of Stochastic Simulation}.
\newblock Stochastic Modelling and Applied Probability. Springer Berlin
  Heidelberg, 2013.

\bibitem[Grohs et~al.(2018)Grohs, Hornung, Jentzen, and
  Von~Wurstemberger]{grohs2018proof}
P.~Grohs, F.~Hornung, A.~Jentzen, and P.~Von~Wurstemberger.
\newblock A proof that artificial neural networks overcome the curse of
  dimensionality in the numerical approximation of {Black-Scholes} partial
  differential equations.
\newblock \emph{arXiv:1809.02362}, 2018.

\bibitem[Grohs et~al.(2019)Grohs, Perekrestenko, Elbr{\"{a}}chter, and
  B{\"{o}}lcskei]{Grohs2019DeepTheory}
P.~Grohs, D.~Perekrestenko, D.~Elbr{\"{a}}chter, and H.~B{\"{o}}lcskei.
\newblock {Deep Neural Network Approximation Theory}.
\newblock \emph{arxiv:1901.02220}, 2019.

\bibitem[G{\"u}hring et~al.(2019)G{\"u}hring, Kutyniok, and
  Petersen]{guhring2019error}
I.~G{\"u}hring, G.~Kutyniok, and P.~Petersen.
\newblock Error bounds for approximations with deep {ReLU} neural networks in
  ${W^{s,p}}$ norms.
\newblock \emph{Analysis and Applications}, pages 1--57, 2019.

\bibitem[Hairer et~al.(2015)Hairer, Hutzenthaler, Jentzen,
  et~al.]{hairer2015loss}
M.~Hairer, M.~Hutzenthaler, A.~Jentzen, et~al.
\newblock Loss of regularity for {Kolmogorov} equations.
\newblock \emph{The Annals of Probability}, 43\penalty0 (2):\penalty0 468--527,
  2015.

\bibitem[Han et~al.(2018)Han, Jentzen, and Weinan]{han2018solving}
J.~Han, A.~Jentzen, and E.~Weinan.
\newblock Solving high-dimensional partial differential equations using deep
  learning.
\newblock \emph{Proceedings of the National Academy of Sciences}, 115\penalty0
  (34):\penalty0 8505--8510, 2018.

\bibitem[Hasselmann(1976)]{hasselmann1976stochastic}
K.~Hasselmann.
\newblock Stochastic climate models part i. theory.
\newblock \emph{tellus}, 28\penalty0 (6):\penalty0 473--485, 1976.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem[Hesthaven and Ubbiali(2018)]{hesthaven2018non}
J.~S. Hesthaven and S.~Ubbiali.
\newblock Non-intrusive reduced order modeling of nonlinear problems using
  neural networks.
\newblock \emph{Journal of Computational Physics}, 363:\penalty0 55--78, 2018.

\bibitem[Hoeffding(1963)]{hoeffding1963}
W.~Hoeffding.
\newblock Probability inequalities for sums of bounded random variables.
\newblock \emph{Journal of the American Statistical Association}, 58\penalty0
  (301):\penalty0 13--30, 1963.

\bibitem[Hutzenthaler et~al.(2019)Hutzenthaler, Jentzen, Kruse, and
  Nguyen]{hutzenthaler2019proof}
M.~Hutzenthaler, A.~Jentzen, T.~Kruse, and T.~A. Nguyen.
\newblock A proof that rectified deep neural networks overcome the curse of
  dimensionality in the numerical approximation of semilinear heat equations.
\newblock \emph{arXiv:1901.10854}, 2019.

\bibitem[Ioffe and Szegedy(2015)]{ioffe2015batch}
S.~Ioffe and C.~Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock \emph{arXiv:1502.03167}, 2015.

\bibitem[Jarrow(2011)]{jarrow2011risk}
R.~A. Jarrow.
\newblock Risk management models: construction, testing, usage.
\newblock \emph{The Journal of Derivatives}, 18\penalty0 (4):\penalty0 89--98,
  2011.

\bibitem[Jentzen et~al.(2018)Jentzen, Salimova, and Welti]{jentzen2018proof}
A.~Jentzen, D.~Salimova, and T.~Welti.
\newblock A proof that deep artificial neural networks overcome the curse of
  dimensionality in the numerical approximation of {Kolmogorov} partial
  differential equations with constant diffusion and nonlinear drift
  coefficients.
\newblock \emph{arXiv:1809.07321}, 2018.

\bibitem[Khoo et~al.(2017)Khoo, Lu, and Ying]{khoo2017solving}
Y.~Khoo, J.~Lu, and L.~Ying.
\newblock Solving parametric {PDE} problems with artificial neural networks.
\newblock \emph{arXiv:1707.03351}, 2017.

\bibitem[Kloeden and Platen(1992)]{KloedenPlaten1992}
P.~E. Kloeden and E.~Platen.
\newblock \emph{Numerical solution of stochastic differential equations},
  volume~23 of \emph{Applications of Mathematics (New York)}.
\newblock Springer-Verlag, Berlin, 1992.

\bibitem[Kutyniok et~al.(2019)Kutyniok, Petersen, Raslan, and
  Schneider]{kutyniok2019theoretical}
G.~Kutyniok, P.~Petersen, M.~Raslan, and R.~Schneider.
\newblock A theoretical analysis of deep neural networks and parametric {PDEs}.
\newblock \emph{arXiv:1904.00377}, 2019.

\bibitem[Laakmann and Petersen(2020)]{laakmann2020efficient}
F.~Laakmann and P.~Petersen.
\newblock Efficient approximation of solutions of parametric linear transport
  equations by {ReLU} {DNNs}.
\newblock \emph{arXiv:2001.11441}, 2020.

\bibitem[Li et~al.(2018)Li, Jamieson, Rostamizadeh, Gonina, Hardt, Recht, and
  Talwalkar]{li2018massively}
L.~Li, K.~Jamieson, A.~Rostamizadeh, E.~Gonina, M.~Hardt, B.~Recht, and
  A.~Talwalkar.
\newblock Massively parallel hyperparameter tuning.
\newblock \emph{arXiv:1810.05934}, 2018.

\bibitem[Liaw et~al.(2018)Liaw, Liang, Nishihara, Moritz, Gonzalez, and
  Stoica]{liaw2018tune}
R.~Liaw, E.~Liang, R.~Nishihara, P.~Moritz, J.~E. Gonzalez, and I.~Stoica.
\newblock Tune: A research platform for distributed model selection and
  training.
\newblock \emph{arXiv:1807.05118}, 2018.

\bibitem[Loshchilov and Hutter(2017)]{loshchilov2017decoupled}
I.~Loshchilov and F.~Hutter.
\newblock Decoupled weight decay regularization.
\newblock \emph{arXiv:1711.05101}, 2017.

\bibitem[Montufar et~al.(2014)Montufar, Pascanu, Cho, and
  Bengio]{montufar2014number}
G.~F. Montufar, R.~Pascanu, K.~Cho, and Y.~Bengio.
\newblock On the number of linear regions of deep neural networks.
\newblock In \emph{Advances in neural information processing systems}, pages
  2924--2932, 2014.

\bibitem[Pascucci(2005)]{pascucci2005kolmogorov}
A.~Pascucci.
\newblock Kolmogorov equations in physics and in finance.
\newblock In \emph{Elliptic and parabolic problems}, pages 353--364. Springer,
  2005.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{NEURIPS2019_9015}
A.~Paszke, S.~Gross, F.~Massa, A.~Lerer, J.~Bradbury, G.~Chanan, T.~Killeen,
  Z.~Lin, N.~Gimelshein, L.~Antiga, A.~Desmaison, A.~Kopf, E.~Yang, Z.~DeVito,
  M.~Raison, A.~Tejani, S.~Chilamkurthy, B.~Steiner, L.~Fang, J.~Bai, and
  S.~Chintala.
\newblock {PyTorch}: An imperative style, high-performance deep learning
  library.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pages
  8024--8035. Curran Associates, Inc., 2019.

\bibitem[Petersen and Voigtlaender(2018)]{petersen2018optimal}
P.~Petersen and F.~Voigtlaender.
\newblock Optimal approximation of piecewise smooth functions using deep {ReLU}
  neural networks.
\newblock \emph{Neural Networks}, 108:\penalty0 296--330, 2018.

\bibitem[Pironneau and Achdou(2009)]{pironneau09}
O.~Pironneau and Y.~Achdou.
\newblock Partial differential equations for option pricing.
\newblock \emph{Handbook of Numerical Analysis}, 15:\penalty0 369--495, 2009.

\bibitem[Pollard(2002)]{pollard2002}
D.~Pollard.
\newblock \emph{A User's Guide to Measure Theoretic Probability}.
\newblock Cambridge Series in Statistical and Probabilistic Mathematics.
  Cambridge University Press, 2002.

\bibitem[Raissi et~al.(2019)Raissi, Perdikaris, and
  Karniadakis]{raissi2019physics}
M.~Raissi, P.~Perdikaris, and G.~E. Karniadakis.
\newblock Physics-informed neural networks: A deep learning framework for
  solving forward and inverse problems involving nonlinear partial differential
  equations.
\newblock \emph{Journal of Computational Physics}, 378:\penalty0 686--707,
  2019.

\bibitem[Reisinger and Zhang(2019)]{reisinger2019rectified}
C.~Reisinger and Y.~Zhang.
\newblock Rectified deep neural networks overcome the curse of dimensionality
  for nonsmooth value functions in zero-sum games of nonlinear stiff systems.
\newblock \emph{arXiv:1903.06652}, 2019.

\bibitem[{Ruder}(2016)]{Ruder2016}
S.~{Ruder}.
\newblock {An overview of gradient descent optimization algorithms}.
\newblock \emph{arXiv:1609.04747}, 2016.

\bibitem[Schwab and Zech(2019)]{schwab2019deep}
C.~Schwab and J.~Zech.
\newblock Deep learning in high dimension: Neural network expression rates for
  generalized polynomial chaos expansions in {UQ}.
\newblock \emph{Analysis and Applications}, 17\penalty0 (01):\penalty0 19--55,
  2019.

\bibitem[Seydel(2006)]{seydel2006tools}
R.~Seydel.
\newblock \emph{Tools for computational finance}, volume~3.
\newblock Springer, 2006.

\bibitem[Sirignano and Spiliopoulos(2018)]{sirignano2018dgm}
J.~Sirignano and K.~Spiliopoulos.
\newblock {DGM}: A deep learning algorithm for solving partial differential
  equations.
\newblock \emph{Journal of Computational Physics}, 375:\penalty0 1339--1364,
  2018.

\bibitem[Thuburn(2005)]{thuburn2005climate}
J.~Thuburn.
\newblock Climate sensitivities via a fokker--planck adjoint approach.
\newblock \emph{Quarterly Journal of the Royal Meteorological Society: A
  journal of the atmospheric sciences, applied meteorology and physical
  oceanography}, 131\penalty0 (605):\penalty0 73--92, 2005.

\bibitem[Vapnik(1998)]{vapnik1998statistical}
V.~Vapnik.
\newblock \emph{Statistical learning theory. 1998}, volume~3.
\newblock Wiley, New York, 1998.

\bibitem[Weinan and Yu(2018)]{weinan2018deep}
E.~Weinan and B.~Yu.
\newblock The deep {Ritz} method: a deep learning-based numerical algorithm for
  solving variational problems.
\newblock \emph{Communications in Mathematics and Statistics}, 6\penalty0
  (1):\penalty0 1--12, 2018.

\bibitem[Weinan et~al.(2017)Weinan, Han, and Jentzen]{weinan2017deep}
E.~Weinan, J.~Han, and A.~Jentzen.
\newblock Deep learning-based numerical methods for high-dimensional parabolic
  partial differential equations and backward stochastic differential
  equations.
\newblock \emph{Communications in Mathematics and Statistics}, 5\penalty0
  (4):\penalty0 349--380, 2017.

\bibitem[Widder(1976)]{widder1976heat}
D.~V. Widder.
\newblock \emph{The heat equation}, volume~67.
\newblock Academic Press, 1976.

\bibitem[Wilmott(2000)]{wilmott2000use}
P.~Wilmott.
\newblock The use, misuse and abuse of mathematics in finance.
\newblock \emph{Philosophical Transactions of the Royal Society of London.
  Series A: Mathematical, Physical and Engineering Sciences}, 358\penalty0
  (1765):\penalty0 63--73, 2000.

\bibitem[Yarotsky(2017)]{yarotsky2017error}
D.~Yarotsky.
\newblock Error bounds for approximations with deep {ReLU} networks.
\newblock \emph{Neural Networks}, 94:\penalty0 103--114, 2017.

\bibitem[Yu et~al.(2018)Yu, Wang, Shelhamer, and Darrell]{yu2018deep}
F.~Yu, D.~Wang, E.~Shelhamer, and T.~Darrell.
\newblock Deep layer aggregation.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2403--2412, 2018.

\end{thebibliography}
