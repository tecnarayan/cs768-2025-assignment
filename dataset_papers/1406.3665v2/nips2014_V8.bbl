\begin{thebibliography}{10}

\bibitem{nesterov2012efficiency}
Y.~Nesterov.
\newblock Efficiency of coordinate descent methods on huge-scale optimization
  problems.
\newblock {\em SIAM Journal on Optimization}, 22(2):341--362, 2012.

\bibitem{richtarik2012efficient}
P.~Richt{\'a}rik and M.~Tak{\'a}{\v{c}}.
\newblock Efficient serial and parallel coordinate descent methods for
  huge-scale truss topology design.
\newblock In {\em Operations Research Proceedings}, pages 27--32. Springer,
  2012.

\bibitem{lee2013efficient}
Y.~T. Lee and A.~Sidford.
\newblock Efficient accelerated coordinate descent methods and faster
  algorithms for solving linear systems.
\newblock In {\em 54th Annual Symposium on Foundations of Computer Science
  (FOCS)}, pages 147--156. IEEE, 2013.

\bibitem{necoara2013efficient}
I.~Necoara and D.~Clipici.
\newblock Efficient parallel coordinate descent algorithm for convex
  optimization problems with separable constraints: application to distributed
  {MPC}.
\newblock {\em Journal of Process Control}, 23(3):243--253, 2013.

\bibitem{nesterov2013gradient}
Y.~Nesterov.
\newblock Gradient methods for minimizing composite functions.
\newblock {\em Mathematical Programming}, 140(1):125--161, 2013.

\bibitem{tseng2009coordinate}
P.~Tseng and S.~Yun.
\newblock A coordinate gradient descent method for nonsmooth separable
  minimization.
\newblock {\em Mathematical Programming}, 117(1-2):387--423, 2009.

\bibitem{beck2009fast}
A.~Beck and M.~Teboulle.
\newblock A fast iterative shrinkage-thresholding algorithm for linear inverse
  problems.
\newblock {\em SIAM Journal on Imaging Sciences}, 2(1):183--202, 2009.

\bibitem{wright2009sparse}
S.~J. Wright, R.~D. Nowak, and M.~Figueiredo.
\newblock Sparse reconstruction by separable approximation.
\newblock {\em IEEE Transactions on Signal Processing}, 57(7):2479--2493, 2009.

\bibitem{facchinei2013flexible}
F.~Facchinei, S.~Sagratella, and G.~Scutari.
\newblock Flexible parallel algorithms for big data optimization.
\newblock {\em arXiv preprint arXiv:1311.2444}, 2013.

\bibitem{bradley2011parallel}
J.~K. Bradley, A.~Kyrola, D.~Bickson, and C.~Guestrin.
\newblock Parallel coordinate descent for $\ell_1$-regularized loss
  minimization.
\newblock {\em arXiv preprint arXiv:1105.5379}, 2011.

\bibitem{scherrer2012feature}
C.~Scherrer, A.~Tewari, M.~Halappanavar, and D.~Haglin.
\newblock Feature clustering for accelerating parallel coordinate descent.
\newblock In {\em NIPS}, pages 28--36, 2012.

\bibitem{scherrer2012scaling}
C.~Scherrer, M.~Halappanavar, A.~Tewari, and D.~Haglin.
\newblock Scaling up coordinate descent algorithms for large $\ell_1$
  regularization problems.
\newblock {\em arXiv preprint arXiv:1206.6409}, 2012.

\bibitem{peng2013parallel}
Z.~Peng, M.~Yan, and W.~Yin.
\newblock Parallel and distributed sparse optimization.
\newblock {\em preprint}, 2013.

\bibitem{necoaradistributed}
I.~Necoara and D.~Clipici.
\newblock Distributed coordinate descent methods for composite minimization.
\newblock {\em arXiv preprint arXiv:1312.5302}, 2013.

\bibitem{richtarik2012parallel}
P.~Richt{\'a}rik and M.~Tak{\'a}{\v{c}}.
\newblock Parallel coordinate descent methods for big data optimization.
\newblock {\em arXiv preprint arXiv:1212.0873}, 2012.

\bibitem{richtarik2013optimal}
P.~Richt{\'a}rik and M.~Tak{\'a}{\v{c}}.
\newblock On optimal probabilities in stochastic coordinate descent methods.
\newblock {\em arXiv preprint arXiv:1310.3438}, 2013.

\bibitem{fercoq2013accelerated}
O.~Fercoq and P.~Richt{\'a}rik.
\newblock Accelerated, parallel and proximal coordinate descent.
\newblock {\em arXiv preprint arXiv:1312.5799}, 2013.

\bibitem{fercoq2014fast}
O.~Fercoq, Z.~Qu, P.~Richt{\'a}rik, and M.~Tak{\'a}{\v{c}}.
\newblock Fast distributed coordinate descent for non-strongly convex losses.
\newblock {\em arXiv preprint arXiv:1405.5300}, 2014.

\bibitem{fercoq2013smooth}
O.~Fercoq and P.~Richt{\'a}rik.
\newblock Smooth minimization of nonsmooth functions with parallel coordinate
  descent methods.
\newblock {\em arXiv preprint arXiv:1309.5885}, 2013.

\bibitem{patrascu2013random}
A.~Patrascu and I.~Necoara.
\newblock A random coordinate descent algorithm for large-scale sparse
  nonconvex optimization.
\newblock In {\em European Control Conference (ECC)}, pages 2789--2794. IEEE,
  2013.

\bibitem{razaviyayn2013unified}
M.~Razaviyayn, M.~Hong, and Z.-Q. Luo.
\newblock A unified convergence analysis of block successive minimization
  methods for nonsmooth optimization.
\newblock {\em SIAM Journal on Optimization}, 23(2):1126--1153, 2013.

\bibitem{niu2011hogwild}
F.~Niu, B.~Recht, C.~R{\'e}, and S.~J. Wright.
\newblock Hogwild!: A lock-free approach to parallelizing stochastic gradient
  descent.
\newblock {\em Advances in Neural Information Processing Systems}, 24:693--701,
  2011.

\bibitem{liu2013asynchronous}
J.~Liu, S.~J. Wright, C.~R{\'e}, and V.~Bittorf.
\newblock An asynchronous parallel stochastic coordinate descent algorithm.
\newblock {\em arXiv preprint arXiv:1311.1873}, 2013.

\bibitem{mairal2013optimization}
J.~Mairal.
\newblock Optimization with first-order surrogate functions.
\newblock {\em arXiv preprint arXiv:1305.3120}, 2013.

\bibitem{mairal2014incremental}
J.~Mairal.
\newblock Incremental majorization-minimization optimization with application
  to large-scale machine learning.
\newblock {\em arXiv preprint arXiv:1402.4419}, 2014.

\bibitem{razaviyayn2013stochastic}
M.~Razaviyayn, M.~Sanjabi, and Z.-Q. Luo.
\newblock A stochastic successive minimization method for nonsmooth nonconvex
  optimization with applications to transceiver design in wireless
  communication networks.
\newblock {\em arXiv preprint arXiv:1307.4457}, 2013.

\bibitem{bertsekas1996neuroBook}
D.~P. Bertsekas and J.~N. Tsitsiklis.
\newblock Neuro-dynamic programming.
\newblock 1996.

\bibitem{hong2013iteration}
M.~Hong, X.~Wang, M.~Razaviyayn, and Z.-Q. Luo.
\newblock Iteration complexity analysis of block coordinate descent methods.
\newblock {\em arXiv preprint arXiv:1310.6957}, 2013.

\bibitem{nesterov2004introductory}
Y.~Nesterov.
\newblock {\em Introductory lectures on convex optimization: A basic course},
  volume~87.
\newblock Springer, 2004.

\end{thebibliography}
