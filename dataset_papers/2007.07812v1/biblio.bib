@BOOK{sutton1998reinforcement,
  title = {Reinforcement Learning: An Introduction},
  publisher = {Bradford Book},
  year = {1998},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  series = {A Bradford book},
  isbn = {9780262193986},
  lccn = {97026416}
}
@inproceedings{pirotta2013adaptive,
  title={Adaptive step-size for policy gradient methods},
  author={Pirotta, Matteo and Restelli, Marcello and Bascetta, Luca},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1394--1402},
  year={2013}
}

@inproceedings{ziebart2008navigate,
  title={Navigate like a cabbie: Probabilistic reasoning from observed context-aware behavior},
  author={Ziebart, Brian D and Maas, Andrew L and Dey, Anind K and Bagnell, J Andrew},
  booktitle={Proceedings of the 10th international conference on Ubiquitous computing},
  pages={322--331},
  year={2008}
}
@inproceedings{vogel2012improving,
  title={Improving hybrid vehicle fuel efficiency using inverse reinforcement learning},
  author={Vogel, Adam and Ramachandran, Deepak and Gupta, Rakesh and Raux, Antoine},
  booktitle={Twenty-Sixth AAAI Conference on Artificial Intelligence},
  year={2012}
}

@inproceedings{abbeel2007application,
  title={An application of reinforcement learning to aerobatic helicopter flight},
  author={Abbeel, Pieter and Coates, Adam and Quigley, Morgan and Ng, Andrew Y},
  booktitle={Advances in neural information processing systems},
  pages={1--8},
  year={2007}
}
@inproceedings{chung2010mobile,
  title={A mobile robot that understands pedestrian spatial behaviors},
  author={Chung, Shu-Yun and Huang, Han-Pang},
  booktitle={2010 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5861--5866},
  year={2010},
  organization={IEEE}
}

@inproceedings{abbeel2004apprenticeship,
  title={Apprenticeship learning via inverse reinforcement learning},
  author={Abbeel, Pieter and Ng, Andrew Y},
  booktitle={Proceedings of the twenty-first international conference on Machine learning},
  pages={1},
  year={2004}
}
@article{baxter2001infinite,
  title={Infinite-horizon policy-gradient estimation},
  author={Baxter, Jonathan and Bartlett, Peter L},
  journal={Journal of Artificial Intelligence Research},
  volume={15},
  pages={319--350},
  year={2001}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@inproceedings{peters2006policy,
  title={Policy gradient methods for robotics},
  author={Peters, Jan and Schaal, Stefan},
  booktitle={2006 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={2219--2225},
  year={2006},
  organization={IEEE}
}
@article{peters2008reinforcement,
  title={Reinforcement learning of motor skills with policy gradients},
  author={Peters, Jan and Schaal, Stefan},
  journal={Neural networks},
  volume={21},
  number={4},
  pages={682--697},
  year={2008},
  publisher={Elsevier}
}

@book{puterman1994markov,
	Address = {New York, NY, USA},
	Author = {Puterman, Martin L.},
	Isbn = {0471619779},
	Publisher = {John Wiley \& Sons, Inc.},
	Title = {Markov Decision Processes: Discrete Stochastic Dynamic Programming},
	Year = {1994}
}

@article{wedin1973perturbation,
  title={Perturbation theory for pseudo-inverses},
  author={Wedin, Perke},
  journal={BIT Numerical Mathematics},
  volume={13},
  number={2},
  pages={217--232},
  year={1973},
  publisher={Springer}
}

@article{hussein2017imitation,
  title={Imitation learning: A survey of learning methods},
  author={Hussein, Ahmed and Gaber, Mohamed Medhat and Elyan, Eyad and Jayne, Chrisina},
  journal={ACM Computing Surveys (CSUR)},
  volume={50},
  number={2},
  pages={21},
  year={2017},
  publisher={ACM}
}
@InProceedings{lflpaper,
  title = 	 {Learning from a Learner},
  author = 	 {Jacq, Alexis and Geist, Matthieu and Paiva, Ana and Pietquin, Olivier},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {2990--2999},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Long Beach, California, USA},
  month = 	 {09--15 Jun},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/jacq19a/jacq19a.pdf},
  url = 	 {http://proceedings.mlr.press/v97/jacq19a.html},
}

@article{argall2009survey,
  title={A survey of robot learning from demonstration},
  author={Argall, Brenna D and Chernova, Sonia and Veloso, Manuela and Browning, Brett},
  journal={Robotics and autonomous systems},
  volume={57},
  number={5},
  pages={469--483},
  year={2009},
  publisher={Elsevier}
}
@article{tseng2001convergence,
  title={Convergence of a block coordinate descent method for nondifferentiable minimization},
  author={Tseng, Paul},
  journal={Journal of optimization theory and applications},
  volume={109},
  number={3},
  pages={475--494},
  year={2001},
  publisher={Springer}
}

@article{fixeddesign,
author    = {Philippe Rigollet},
title     = { High-Dimensional Statistics. Spring 2015},
journal = {Massachusetts Institute of Technology: MIT OpenCourseWare},
year = {2015}
}

@article{DBLP:journals/ftrob/OsaPNBA018,
  author    = {Takayuki Osa and
               Joni Pajarinen and
               Gerhard Neumann and
               J. Andrew Bagnell and
               Pieter Abbeel and
               Jan Peters},
  title     = {An Algorithmic Perspective on Imitation Learning},
  journal   = {Foundations and Trends in Robotics},
  volume    = {7},
  number    = {1-2},
  pages     = {1--179},
  year      = {2018},
  url       = {https://doi.org/10.1561/2300000053},
  doi       = {10.1561/2300000053},
  timestamp = {Mon, 16 Sep 2019 14:44:14 +0200},
  biburl    = {https://dblp.org/rec/journals/ftrob/OsaPNBA018.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ziebart2008maximum,
  author    = {Brian D. Ziebart and
               Andrew L. Maas and
               J. Andrew Bagnell and
               Anind K. Dey},
  editor    = {Dieter Fox and
               Carla P. Gomes},
  title     = {Maximum Entropy Inverse Reinforcement Learning},
  booktitle = {Proceedings of the Twenty-Third {AAAI} Conference on Artificial Intelligence,
               {AAAI} 2008, Chicago, Illinois, USA, July 13-17, 2008},
  pages     = {1433--1438},
  publisher = {{AAAI} Press},
  year      = {2008},
  url       = {http://www.aaai.org/Library/AAAI/2008/aaai08-227.php},
  timestamp = {Mon, 10 Dec 2012 17:36:53 +0100},
  biburl    = {https://dblp.org/rec/conf/aaai/ZiebartMBD08.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{nemeth2010learning,
  title={Learning in autism: implicitly superb},
  author={Nemeth, Dezso and Janacsek, Karolina and Balogh, Virag and Londe, Zsuzsa and Mingesz, Robert and Fazekas, Marta and Jambori, Szilvia and Danyi, Izabella and Vetro, Agnes},
  journal={PloS one},
  volume={5},
  number={7},
  year={2010},
  publisher={Public Library of Science}
}

@article{abrams1988implicit,
  title={Implicit learning: Robustness in the face of psychiatric disorders},
  author={Abrams, Michael and Reber, Arthur S},
  journal={Journal of Psycholinguistic Research},
  volume={17},
  number={5},
  pages={425--439},
  year={1988},
  publisher={Springer}
}

##Related work

@inproceedings{shum2019theory,
  title={Theory of minds: Understanding behavior in groups through inverse planning},
  author={Shum, Michael and Kleiman-Weiner, Max and Littman, Michael L and Tenenbaum, Joshua B},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={6163--6170},
  year={2019}
}

@inproceedings{rabinowitz2018machine,
  title={Machine Theory of Mind},
  author={Rabinowitz, Neil and Perbet, Frank and Song, Francis and Zhang, Chiyuan and Eslami, SM Ali and Botvinick, Matthew},
  booktitle={International Conference on Machine Learning},
  pages={4218--4227},
  year={2018}
}

@inproceedings{ng2000algorithms,
  author    = {Andrew Y. Ng and
               Stuart J. Russell},
  title     = {Algorithms for Inverse Reinforcement Learning},
  booktitle = {Proceedings of the Seventeenth International Conference on Machine
               Learning {(ICML} 2000), Stanford University, Stanford, CA, USA, June
               29 - July 2, 2000},
  pages     = {663--670},
  publisher = {Morgan Kaufmann},
  year      = {2000}
}

@inproceedings{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4299--4307},
  year={2017}
}

@article{goyal2019first,
  title={A First-Order Approach To Accelerated Value Iteration},
  author={Goyal, Vineet and Grand-Clement, Julien},
  journal={arXiv preprint arXiv:1905.09963},
  year={2019}
}

@inproceedings{chen2013noisy,
  title={Noisy and missing data regression: Distribution-oblivious support recovery},
  author={Chen, Yudong and Caramanis, Constantine},
  booktitle={International Conference on Machine Learning},
  pages={383--391},
  year={2013}
}

@article{chen2012orthogonal,
  title={Orthogonal matching pursuit with noisy and missing data: Low and high dimensional results},
  author={Chen, Yudong and Caramanis, Constantine},
  journal={arXiv preprint arXiv:1206.0823},
  year={2012}
}

@article{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}
@inproceedings{mcwilliams2014fast,
  title={Fast and robust least squares estimation in corrupted linear models},
  author={McWilliams, Brian and Krummenacher, Gabriel and Lucic, Mario and Buhmann, Joachim M},
  booktitle={Advances in Neural Information Processing Systems},
  pages={415--423},
  year={2014}
}
@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}
@article{DBLP:journals/corr/BrockmanCPSSTZ16,
  author    = {Greg Brockman and
               Vicki Cheung and
               Ludwig Pettersson and
               Jonas Schneider and
               John Schulman and
               Jie Tang and
               Wojciech Zaremba},
  title     = {OpenAI Gym},
  journal   = {CoRR},
  volume    = {abs/1606.01540},
  year      = {2016}
}

@article{schulman2017equivalence,
  title={Equivalence between policy gradients and soft q-learning},
  author={Schulman, John and Chen, Xi and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1704.06440},
  year={2017}
}
@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1057--1063},
  year={2000}
}

@book{casella2002statistical,
  title={Statistical inference},
  author={Casella, George and Berger, Roger L},
  volume={2},
  year={2002},
  publisher={Duxbury Pacific Grove, CA}
}

@article{spokoiny2012parametric,
  title={Parametric estimation. Finite sample theory},
  author={Spokoiny, Vladimir and others},
  journal={The Annals of Statistics},
  volume={40},
  number={6},
  pages={2877--2909},
  year={2012},
  publisher={Institute of Mathematical Statistics}
}

@inproceedings{ibarz2018reward,
  title={Reward learning from human preferences and demonstrations in Atari},
  author={Ibarz, Borja and Leike, Jan and Pohlen, Tobias and Irving, Geoffrey and Legg, Shane and Amodei, Dario},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8011--8023},
  year={2018}
}

@inproceedings{balakrishna2019policy,
  author    = {Ashwin Balakrishna and
               Brijen Thananjeyan and
               Jonathan Lee and
               Felix Li and
               Arsh Zahed and
               Joseph E. Gonzalez and
               Ken Goldberg},
  editor    = {Leslie Pack Kaelbling and
               Danica Kragic and
               Komei Sugiura},
  title     = {On-Policy Robot Imitation Learning from a Converging Supervisor},
  booktitle = {3rd Annual Conference on Robot Learning, CoRL 2019, Osaka, Japan,
               October 30 - November 1, 2019, Proceedings},
  series    = {Proceedings of Machine Learning Research},
  volume    = {100},
  pages     = {24--41},
  publisher = {{PMLR}},
  year      = {2019},
  url       = {http://proceedings.mlr.press/v100/balakrishna20a.html},
  timestamp = {Mon, 25 May 2020 15:01:26 +0200},
  biburl    = {https://dblp.org/rec/conf/corl/BalakrishnaTLLZ19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{castro2019inverse,
  title={Inverse Reinforcement Learning with Multiple Ranked Experts},
  author={Castro, Pablo Samuel and Li, Shijian and Zhang, Daqing},
  journal={arXiv preprint arXiv:1907.13411},
  year={2019}
}
@article{leike2018scalable,
  title={Scalable agent alignment via reward modeling: a research direction},
  author={Leike, Jan and Krueger, David and Everitt, Tom and Martic, Miljan and Maini, Vishal and Legg, Shane},
  journal={arXiv preprint arXiv:1811.07871},
  year={2018}
}
@inproceedings{brown2019extrapolating,
  title={Extrapolating Beyond Suboptimal Demonstrations via Inverse Reinforcement Learning from Observations},
  author={Brown, Daniel and Goo, Wonjoon and Nagarajan, Prabhat and Niekum, Scott},
  booktitle={International Conference on Machine Learning},
  pages={783--792},
  year={2019}
}


@inproceedings{metelli2017compatible,
  title={Compatible reward inverse reinforcement learning},
  author={Metelli, Alberto Maria and Pirotta, Matteo and Restelli, Marcello},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2050--2059},
  year={2017}
}

@inproceedings{brown2019machine,
  title={Machine teaching for inverse reinforcement learning: Algorithms and applications},
  author={Brown, Daniel S and Niekum, Scott},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={7749--7758},
  year={2019}
}
@inproceedings{pirotta2016inverse,
  author    = {Matteo Pirotta and
               Marcello Restelli},
  editor    = {Dale Schuurmans and
               Michael P. Wellman},
  title     = {Inverse Reinforcement Learning through Policy Gradient Minimization},
  booktitle = {Proceedings of the Thirtieth {AAAI} Conference on Artificial Intelligence,
               February 12-17, 2016, Phoenix, Arizona, {USA}},
  pages     = {1993--1999},
  publisher = {{AAAI} Press},
  year      = {2016},
  url       = {http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12482},
  timestamp = {Wed, 05 Apr 2017 12:53:50 +0200},
  biburl    = {https://dblp.org/rec/conf/aaai/PirottaR16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{shteingart2014reinforcement,
  title={Reinforcement learning and human behavior},
  author={Shteingart, Hanan and Loewenstein, Yonatan},
  journal={Current Opinion in Neurobiology},
  volume={25},
  pages={93--98},
  year={2014},
  publisher={Elsevier}
}
