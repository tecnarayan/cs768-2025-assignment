@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



BEVFusion (MIT)
Liu, Z., Tang, H., Amini, A., Yang, X., Mao, H., Rus, D. L., & Han, S. (2023, May). Bevfusion: Multi-task multi-sensor fusion with unified bird's-eye view representation. In 2023 IEEE International Conference on Robotics and Automation (ICRA) (pp. 2774-2781). IEEE.
@inproceedings{liu2023bevfusion,
  title={{BEVFusion}: Multi-task multi-sensor fusion with unified bird's-eye view representation},
  author={Liu, Z. and Tang, H. and Amini, A. and Yang, X. and Mao, H. and Rus, D. and Han, S.},
  booktitle={International Conference on Robotics and Automation (ICRA)},
  pages={2774--2781},
  year={2023}
}

TARL
Nunes, L., Wiesmann, L., Marcuzzi, R., Chen, X., Behley, J., & Stachniss, C. (2023). Temporal Consistent 3D LiDAR Representation Learning for Semantic Perception in Autonomous Driving. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 5217-5228).
@inproceedings{nunes2023temporal,
  title={Temporal Consistent 3{D} {LiDAR} Representation Learning for Semantic Perception in Autonomous Driving},
  author={Nunes, L. and Wiesmann, L. and Marcuzzi, R. and Chen, X. and Behley, J. and Stachniss, C.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={5217--5228},
  year={2023}
}

PointContrast
Xie, S., Gu, J., Guo, D., Qi, C. R., Guibas, L., & Litany, O. (2020). Pointcontrast: Unsupervised pre-training for 3d point cloud understanding. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part III 16 (pp. 574-591). Springer International Publishing.
@inproceedings{xie2020pointcontrast,
  title={{PointContrast}: Unsupervised pre-training for 3{D} point cloud understanding},
  author={Xie, S. and Gu, J. and Guo, D. and Qi, C.R. and Guibas, L. and Litany, O.},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={574--591},
  year={2020}
}

DepthContrast
Zhang, Z., Girdhar, R., Joulin, A., & Misra, I. (2021). Self-supervised pretraining of 3d features on any point-cloud. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 10252-10263).
@inproceedings{zhang2021self,
  title={Self-supervised pretraining of 3{D} features on any point-cloud},
  author={Zhang, Z. and Girdhar, R. and Joulin, A. and Misra, I.},
  booktitle={International Conference on Computer Vision (ICCV)},
  pages={10252--10263},
  year={2021}
}

SegContrast
Nunes, L., Marcuzzi, R., Chen, X., Behley, J., & Stachniss, C. (2022). SegContrast: 3D point cloud feature representation learning through self-supervised segment discrimination. IEEE Robotics and Automation Letters, 7(2), 2116-2123.
@article{nunes2022segcontrast,
  title={{SegContrast}: 3{D} point cloud feature representation learning through self-supervised segment discrimination},
  author={Nunes, L. and Marcuzzi, R. and Chen, X. and Behley, J. and Stachniss, C.},
  journal={Robotics and Automation Letters (RA-L)},
  volume={7},
  number={2},
  pages={2116--2123},
  year={2022}
}

ALSO
Boulch, A., Sautier, C., Michele, B., Puy, G., & Marlet, R. (2023). ALSO: Automotive Lidar Self-supervision by Occupancy estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 13455-13465).
@inproceedings{boulch2023also,
  title={{ALSO}: Automotive {LiDAR} Self-supervision by Occupancy estimation},
  author={Boulch, A. and Sautier, C. and Michele, B. and Puy, G. and Marlet, R.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={13455--13465},
  year={2023}
}

STSSL
Wu, Y., Zhang, T., Ke, W., Süsstrunk, S., & Salzmann, M. (2023). Spatiotemporal Self-supervised Learning for Point Clouds in the Wild. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 5251-5260).
@inproceedings{wu2023spatiotemporal,
  title={Spatiotemporal Self-supervised Learning for Point Clouds in the Wild},
  author={Wu, Y. and Zhang, T. and Ke, W. and S{\"u}sstrunk, S. and Salzmann, M.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={5251--5260},
  year={2023}
}

PPKT
Liu, Y. C., Huang, Y. K., Chiang, H. Y., Su, H. T., Liu, Z. Y., Chen, C. T., ... & Hsu, W. H. (2021). Learning from 2d: Contrastive pixel-to-point knowledge transfer for 3d pretraining. arXiv preprint arXiv:2104.04687.
@article{liu2021learning,
  title={{Learning from 2D}: Contrastive pixel-to-point knowledge transfer for 3{D} pretraining},
  author={Liu, Y. and Huang, Y. and Chiang, H. and Su, H. and Liu, Z. and Chen, C. and Tseng, C. and Hsu, W.H.},
  journal={arXiv preprint},
  year={2021}
}

SLidR
Sautier, C., Puy, G., Gidaris, S., Boulch, A., Bursuc, A., & Marlet, R. (2022). Image-to-lidar self-supervised distillation for autonomous driving data. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 9891-9901).
@inproceedings{sautier2022image,
  title={Image-to-{LiDAR} self-supervised distillation for autonomous driving data},
  author={Sautier, C. and Puy, G. and Gidaris, S. and Boulch, A. and Bursuc, A. and Marlet, R.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={9891--9901},
  year={2022}
}

ST-SLidR
Mahmoud, A., Hu, J. S., Kuai, T., Harakeh, A., Paull, L., & Waslander, S. L. (2023). Self-Supervised Image-to-Point Distillation via Semantically Tolerant Contrastive Loss. arXiv preprint arXiv:2301.05709.
@article{mahmoud2023self,
  title={Self-Supervised Image-to-Point Distillation via Semantically Tolerant Contrastive Loss},
  author={Mahmoud, A. and Hu, J.S.K. and Kuai, T. and Harakeh, A. and Paull, L. and Waslander, S.L.},
  journal={arXiv preprint},
  year={2023}
}

Contrastive Scene Contexts
Hou, J., Graham, B., Nießner, M., & Xie, S. (2021). Exploring data-efficient 3d scene understanding with contrastive scene contexts. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 15587-15597).
@inproceedings{hou2021exploring,
  title={Exploring data-efficient 3{D} scene understanding with contrastive scene contexts},
  author={Hou, J. and Graham, B. and Nie{\ss}ner, M. and Xie, S.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={15587--15597},
  year={2021}
}

4DContrast
Chen, Y., Nießner, M., & Dai, A. (2022, November). 4dcontrast: Contrastive learning with dynamic correspondences for 3d scene understanding. In Computer Vision–ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part XXXII (pp. 543-560). Cham: Springer Nature Switzerland.
@inproceedings{chen20224dcontrast,
  title={{4DContrast}: Contrastive learning with dynamic correspondences for 3{D} scene understanding},
  author={Chen, Y. and Nie{\ss}ner, M. and Dai, A.},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={543--560},
  year={2022}
}

MoCO
He, K., Fan, H., Wu, Y., Xie, S., & Girshick, R. (2020). Momentum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 9729-9738).
@inproceedings{he2020momentum,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, K. and Fan, H. and Wu, Y. and Xie, S. and Girshick, R.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={9729--9738},
  year={2020}
}

BERT
Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.
@article{devlin2018bert,
  title={{BERT}: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, J. and Chang, M. and Lee, K. and Toutanova, K.},
  journal={arXiv preprint},
  year={2018}
}

BEVFusion (Alibaba Group)
Liang, T., Xie, H., Yu, K., Xia, Z., Lin, Z., Wang, Y., ... & Tang, Z. (2022). Bevfusion: A simple and robust lidar-camera fusion framework. Advances in Neural Information Processing Systems, 35, 10421-10434.
@inproceedings{liang2022bevfusion,
  title={{BEVFusion}: A simple and robust {LiDAR}-camera fusion framework},
  author={Liang, T. and Xie, H. and Yu, K. and Xia, Z. and Lin, Z. and Wang, Y. and Tang, T. and Wang, B. and Tang, Z.},
  booktitle={Neural Information Processing Systems (NeurIPS)},
  pages={10421--10434},
  year={2022}
}

DeepInteraction
Yang, Z., Chen, J., Miao, Z., Li, W., Zhu, X., & Zhang, L. (2022). Deepinteraction: 3d object detection via modality interaction. Advances in Neural Information Processing Systems, 35, 1992-2005.
@inproceedings{yang2022deepinteraction,
  title={{DeepInteraction}: 3{D} object detection via modality interaction},
  author={Yang, Z. and Chen, J. and Miao, Z. and Li, W. and Zhu, X. and Zhang, L.},
  booktitle={Neural Information Processing Systems (NeurIPS)},
  pages={1992--2005},
  year={2022}
}

ProposalContrast
Yin, J., Zhou, D., Zhang, L., Fang, J., Xu, C. Z., Shen, J., & Wang, W. (2022, October). Proposalcontrast: Unsupervised pre-training for lidar-based 3D object detection. In Computer Vision–ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part XXXIX (pp. 17-33). Cham: Springer Nature Switzerland.
@inproceedings{yin2022proposalcontrast,
  title={{ProposalContrast}: Unsupervised pre-training for {LiDAR}-based 3{D} object detection},
  author={Yin, J. and Zhou, D. and Zhang, L. and Fang, J. and Xu, C. and Shen, J. and Wang, W.},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={17--33},
  year={2022}
}

Occupancy-MAE
Min, C., Zhao, D., Xiao, L., Nie, Y., & Dai, B. (2022). Voxel-mae: Masked autoencoders for pre-training large-scale point clouds. arXiv preprint arXiv:2206.09900.
@article{min2022voxel,
  title={{Occupancy-MAE}: Self-supervised Pre-training Large-scale {LiDAR} Point Clouds with Masked Occupancy Autoencoders},
  author={Min, C. and Zhao, D. and Xiao, L. and Nie, Y. and Dai, B.},
  journal={arXiv preprint},
  year={2022}
}

Voxel-MAE
Hess, G., Jaxing, J., Svensson, E., Hagerman, D., Petersson, C., & Svensson, L. (2023). Masked Autoencoder for Self-Supervised Pre-Training on Lidar Point Clouds. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 350-359).
@inproceedings{hess2023masked,
  title={Masked Autoencoder for Self-Supervised Pre-Training on {LiDAR} Point Clouds},
  author={Hess, G. and Jaxing, J. and Svensson, E. and Hagerman, D. and Petersson, C. and Svensson, L.},
  booktitle={Winter Conference on Applications of Computer Vision (WACV) workshops},
  pages={350--359},
  year={2023}
}

RANSAC
Fischler, M. A., & Bolles, R. C. (1981). Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography. Communications of the ACM, 24(6), 381-395.
@article{fischler1981random,
  title={Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography},
  author={Fischler, M.A. and Bolles, R.C.},
  journal={Communications of the ACM},
  volume={24},
  number={6},
  pages={381--395},
  year={1981},
  publisher={ACM New York, NY, USA}
}

DBSCAN
Ester, M., Kriegel, H. P., Sander, J., & Xu, X. (1996, August). A density-based algorithm for discovering clusters in large spatial databases with noise. In kdd (Vol. 96, No. 34, pp. 226-231).
@article{ester1996density,
  title={A density-based algorithm for discovering clusters in large spatial databases with noise},
  author={Ester, M. and Kriegel, H. and Sander, J. and Xu, X.},
  journal={Knowledge Discovery and Data Mining (KDD)},
  volume={96},
  number={34},
  pages={226--231},
  year={1996}
}

4D Object Discovery
Wang, Y., Chen, Y., & ZHANG, Z. X. (2022). 4d unsupervised object discovery. Advances in Neural Information Processing Systems, 35, 35563-35575.
@inproceedings{wang20224d,
  title={4{D} unsupervised object discovery},
  author={Wang, Y. and Chen, Y. and Zhang, Z.},
  booktitle={Neural Information Processing Systems (NeurIPS)},
  pages={35563--35575},
  year={2022}
}

GD-MAE
Yang, H., He, T., Liu, J., Chen, H., Wu, B., Lin, B., ... & Ouyang, W. (2023). GD-MAE: generative decoder for MAE pre-training on lidar point clouds. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 9403-9414).
@inproceedings{yang2023gd,
  title={{GD-MAE}: Generative decoder for MAE pre-training on {LiDAR} point clouds},
  author={Yang, H. and He, T. and Liu, J. and Chen, H. and Wu, B. and Lin, B. and He, X. and Ouyang, W.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={9403--9414},
  year={2023}
}

MV-JAR
Xu, R., Wang, T., Zhang, W., Chen, R., Cao, J., Pang, J., & Lin, D. (2023). MV-JAR: Masked Voxel Jigsaw and Reconstruction for LiDAR-Based Self-Supervised Pre-Training. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 13445-13454).
@inproceedings{xu2023mv,
  title={{MV-JAR}: Masked Voxel Jigsaw and Reconstruction for {LiDAR}-Based Self-Supervised Pre-Training},
  author={Xu, R. and Wang, T. and Zhang, W. and Chen, R. and Cao, J. and Pang, J. and Lin, D.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={13445--13454},
  year={2023}
}

3DSSD
Yang, Z., Sun, Y., Liu, S., & Jia, J. (2020). 3dssd: Point-based 3d single stage object detector. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 11040-11048).
@inproceedings{yang20203dssd,
  title={{3DSSD}: Point-based 3{D} single stage object detector},
  author={Yang, Z. and Sun, Y. and Liu, S. and Jia, J.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={11040--11048},
  year={2020}
}

LiDAR R-CNN
Li, Z., Wang, F., & Wang, N. (2021). Lidar r-cnn: An efficient and universal 3d object detector. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 7546-7555).
@inproceedings{li2021lidar,
  title={{LiDAR R-CNN}: An efficient and universal 3{D} object detector},
  author={Li, Z. and Wang, F. and Wang, N.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={7546--7555},
  year={2021}
}

PointPillars
Lang, A. H., Vora, S., Caesar, H., Zhou, L., Yang, J., & Beijbom, O. (2019). Pointpillars: Fast encoders for object detection from point clouds. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 12697-12705).
@inproceedings{lang2019pointpillars,
  title={{PointPillars}: Fast encoders for object detection from point clouds},
  author={Lang, A.H. and Vora, S. and Caesar, H. and Zhou, L. and Yang, J. and Beijbom, O.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={12697--12705},
  year={2019}
}

PillarNet
Shi, G., Li, R., & Ma, C. (2022, November). Pillarnet: Real-time and high-performance pillar-based 3d object detection. In Computer Vision–ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part X (pp. 35-52). Cham: Springer Nature Switzerland.
@inproceedings{shi2022pillarnet,
  title={{PillarNet}: Real-time and high-performance pillar-based 3{D} object detection},
  author={Shi, G. and Li, R. and Ma, C.},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={35--52},
  year={2022}
}

VoxelNet
Zhou, Y., & Tuzel, O. (2018). Voxelnet: End-to-end learning for point cloud based 3d object detection. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 4490-4499).
@inproceedings{zhou2018voxelnet,
  title={{VoxelNet}: End-to-end learning for point cloud based 3{D} object detection},
  author={Zhou, Y. and Tuzel, O.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={4490--4499},
  year={2018}
}

RangeDet
Fan, L., Xiong, X., Wang, F., Wang, N., & Zhang, Z. (2021). Rangedet: In defense of range view for lidar-based 3d object detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 2918-2927).
@inproceedings{fan2021rangedet,
  title={{RangeDet}: In defense of range view for {LiDAR}-based 3{D} object detection},
  author={Fan, L. and Xiong, X. and Wang, F. and Wang, N. and Zhang, Z.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={2918--2927},
  year={2021}
}

RSN
Sun, P., Wang, W., Chai, Y., Elsayed, G., Bewley, A., Zhang, X., ... & Anguelov, D. (2021). Rsn: Range sparse net for efficient, accurate lidar 3d object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 5725-5734).
@inproceedings{sun2021rsn,
  title={{RSN}: Range sparse net for efficient, accurate {LiDAR} 3{D} object detection},
  author={Sun, P. and Wang, W. and Chai, Y. and Elsayed, G. and Bewley, A. and Zhang, X. and Sminchisescu, C. and Anguelov, D.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={5725--5734},
  year={2021}
}

Image2Point
Xu, C., Yang, S., Galanti, T., Wu, B., Yue, X., Zhai, B., ... & Tomizuka, M. (2022, October). Image2Point: 3D Point-Cloud Understanding with 2D Image Pretrained Models. In Computer Vision–ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part XXXVII (pp. 638-656). Cham: Springer Nature Switzerland.
@inproceedings{xu2022image2point,
  title={{Image2Point}: 3{D} Point-Cloud Understanding with 2{D} Image Pretrained Models},
  author={Xu, C. and Yang, S. and Galanti, T. and Wu, B. and Yue, X. and Zhai, B. and Zhan, W. and Vajda, P. and Keutzer, K. and Tomizuka, M.},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={638--656},
  year={2022}
}

PointPainting
Vora, S., Lang, A. H., Helou, B., & Beijbom, O. (2020). Pointpainting: Sequential fusion for 3d object detection. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 4604-4612).
@inproceedings{vora2020pointpainting,
  title={{PointPainting}: Sequential fusion for 3{D} object detection},
  author={Vora, S. and Lang, A.H. and Helou, B. and Beijbom, O.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={4604--4612},
  year={2020}
}

FusionPainting
Xu, S., Zhou, D., Fang, J., Yin, J., Bin, Z., & Zhang, L. (2021, September). Fusionpainting: Multimodal fusion with adaptive attention for 3d object detection. In 2021 IEEE International Intelligent Transportation Systems Conference (ITSC) (pp. 3047-3054). IEEE.
@inproceedings{xu2021fusionpainting,
  title={{FusionPainting}: Multimodal fusion with adaptive attention for 3{D} object detection},
  author={Xu, S. and Zhou, D. and Fang, J. and Yin, J. and Bin, Z. and Zhang, L.},
  booktitle={International Conference on Intelligent Transportation Systems (ITSC)},
  pages={3047--3054},
  year={2021}
}

3D-CVF
Yoo, J. H., Kim, Y., Kim, J., & Choi, J. W. (2020). 3d-cvf: Generating joint camera and lidar features using cross-view spatial feature fusion for 3d object detection. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XXVII 16 (pp. 720-736). Springer International Publishing.
@inproceedings{yoo20203d,
  title={{3D-CVF}: Generating joint camera and {LiDAR} features using cross-view spatial feature fusion for 3{D} object detection},
  author={Yoo, J.H. and Kim, Y. and Kim, J. and Choi, J.W.},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={720--736},
  year={2020}
}

TransFusion
Bai, X., Hu, Z., Zhu, X., Huang, Q., Chen, Y., Fu, H., & Tai, C. L. (2022). Transfusion: Robust lidar-camera fusion for 3d object detection with transformers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 1090-1099).
@inproceedings{bai2022transfusion,
  title={{TransFusion}: Robust {LiDAR}-camera fusion for 3{D} object detection with transformers},
  author={Bai, X. and Hu, Z. and Zhu, X. and Huang, Q. and Chen, Y. and Fu, H. and Tai, C.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={1090--1099},
  year={2022}
}

UVTR
Li, Y., Chen, Y., QI, X., Li, Z., Sun, J., & Jia, J. Unifying Voxel-based Representation with Transformer for 3D Object Detection. In Advances in Neural Information Processing Systems.
@inproceedings{li2022unifying,
  title={Unifying Voxel-based Representation with Transformer for 3{D} Object Detection},
  author={Li, Y. and Chen, Y. and Qi, X. and Li, Z. and Sun, J. and Jia, J.},
  booktitle={Neural Information Processing Systems (NeurIPS)},
  pages={18442--18455},
  year={2022}
}

AutoAlignV2
Chen, Z., Li, Z., Zhang, S., Fang, L., Jiang, Q., & Zhao, F. (2022, November). Deformable Feature Aggregation for Dynamic Multi-modal 3D Object Detection. In Computer Vision–ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part VIII (pp. 628-644). Cham: Springer Nature Switzerland.
@inproceedings{chen2022autoalignv2,
  title={{AutoAlignV2}: Deformable Feature Aggregation for Dynamic Multi-Modal 3{D} Object Detection},
  author={Chen, Z. and Li, Z. and Zhang, S. and Fang, L. and Jiang, Q. and Zhao, F.},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={628--644},
  year={2022}
}

DETR
Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., & Zagoruyko, S. (2020). End-to-end object detection with transformers. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part I 16 (pp. 213-229). Springer International Publishing.
@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, N. and Massa, F. and Synnaeve, G. and Usunier, N. and Kirillov, A. and Zagoruyko, S.},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={213--229},
  year={2020}
}

Deformable DETR
Zhu, X., Su, W., Lu, L., Li, B., Wang, X., & Dai, J. Deformable DETR: Deformable Transformers for End-to-End Object Detection. In International Conference on Learning Representations.
@inproceedings{zhu2021deformable,
  title={{Deformable DETR}: Deformable Transformers for End-to-End Object Detection},
  author={Zhu, X. and Su, W. and Lu, L. and Li, B. and Wang, X. and Dai, J.},
  booktitle={ICLR},
  pages={},
  year={2021}
}

BEVFusion4D
Cai, H., Zhang, Z., Zhou, Z., Li, Z., Ding, W., & Zhao, J. (2023). BEVFusion4D: Learning LiDAR-Camera Fusion Under Bird's-Eye-View via Cross-Modality Guidance and Temporal Aggregation. arXiv preprint arXiv:2303.17099.
@article{cai2023bevfusion4d,
  title={{BEVFusion4D}: Learning {LiDAR}-Camera Fusion Under Bird's-Eye-View via Cross-Modality Guidance and Temporal Aggregation},
  author={Cai, H. and Zhang, Z. and Zhou, Z. and Li, Z. and Ding, W. and Zhao, J.},
  journal={arXiv preprint},
  year={2023}
}

Mask R-CNN
He, K., Gkioxari, G., Dollár, P., & Girshick, R. (2017). Mask r-cnn. In Proceedings of the IEEE international conference on computer vision (pp. 2961-2969).
@inproceedings{he2017mask,
  title={{Mask R-CNN}},
  author={He, K. and Gkioxari, G. and Doll{\'a}r, P. and Girshick, R.},
  booktitle={International Conference on Computer Vision (ICCV)},
  pages={2961--2969},
  year={2017}
}

DetMatch
Park, J., Xu, C., Zhou, Y., Tomizuka, M., & Zhan, W. (2022, November). Detmatch: Two teachers are better than one for joint 2d and 3d semi-supervised object detection. In Computer Vision–ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part X (pp. 370-389). Cham: Springer Nature Switzerland.
@inproceedings{park2022detmatch,
  title={{DetMatch}: Two teachers are better than one for joint 2{D} and 3{D} semi-supervised object detection},
  author={Park, J. and Xu, C. and Zhou, Y. and Tomizuka, M. and Zhan, W.},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={370--389},
  year={2022}
}

nuScenes dataset
Caesar, H., Bankiti, V., Lang, A. H., Vora, S., Liong, V. E., Xu, Q., ... & Beijbom, O. (2020). nuscenes: A multimodal dataset for autonomous driving. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 11621-11631).
@inproceedings{caesar2020nuscenes,
  title={{nuScenes}: A multimodal dataset for autonomous driving},
  author={Caesar, H. and Bankiti, V. and Lang, A.H. and Vora, S. and Liong, V.E. and Xu, Q. and Krishnan, A. and Pan, Y. and Baldan, G. and Beijbom, O.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={11621--11631},
  year={2020}
}

Waymo dataset
Sun, P., Kretzschmar, H., Dotiwalla, X., Chouard, A., Patnaik, V., Tsui, P., ... & Anguelov, D. (2020). Scalability in perception for autonomous driving: Waymo open dataset. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 2446-2454).
@inproceedings{sun2020scalability,
  title={Scalability in perception for autonomous driving: {Waymo} open dataset},
  author={Sun, P. and Kretzschmar, H. and Dotiwalla, X. and Chouard, A. and Patnaik, V. and Tsui, P. and Guo, J. and Zhou, Y. and Chai, Y. and Caine, B. and others},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={2446--2454},
  year={2020}
}

KITTI dataset
Geiger, A., Lenz, P., & Urtasun, R. (2012, June). Are we ready for autonomous driving? the kitti vision benchmark suite. In 2012 IEEE conference on computer vision and pattern recognition (pp. 3354-3361). IEEE.
@inproceedings{geiger2012we,
  title={Are we ready for autonomous driving? The {KITTI} vision benchmark suite},
  author={Geiger, A. and Lenz, P. and Urtasun, R.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={3354--3361},
  year={2012}
}

DINOv2
Oquab, M., Darcet, T., Moutakanni, T., Vo, H. V., Szafraniec, M., Khalidov, V., ... & Bojanowski, P. (2023). DINOv2: Learning Robust Visual Features without Supervision. Transactions on Machine Learning Research.
@article{oquab2024dinov2,
  title={{DINOv2}: Learning Robust Visual Features without Supervision},
  author={Oquab, M. and Darcet, T. and Moutakanni, T. and Vo, H. and Szafraniec, M. and Khalidov, V. and Fernandez, P. and Haziza, D. and Massa, F. and El-Nouby, A. and others},
  journal={Transactions on Machine Learning Research (TMLR)},
  pages={2835-8856},
  year={2024}
}

CALICO
Sun, J., Zheng, H., Zhang, Q., Prakash, A., Mao, Z. M., & Xiao, C. (2023). CALICO: Self-Supervised Camera-LiDAR Contrastive Pre-training for BEV Perception. arXiv preprint arXiv:2306.00349.
@article{sun2023calico,
  title={{CALICO}: Self-Supervised Camera-{LiDAR} Contrastive Pre-training for {BEV} Perception},
  author={Sun, J. and Zheng, H. and Zhang, Q. and Prakash, A. and Mao, Z.M. and Xiao, C.},
  journal={arXiv preprint},
  year={2023}
}

BEVDet
Huang, J., Huang, G., Zhu, Z., Ye, Y., & Du, D. (2021). Bevdet: High-performance multi-camera 3d object detection in bird-eye-view. arXiv preprint arXiv:2112.11790.
@article{huang2021bevdet,
  title={{BEVDet}: High-performance multi-camera 3{D} object detection in bird-eye-view},
  author={Huang, J. and Huang, G. and Zhu, Z. and Ye, Y. and Du, D.},
  journal={arXiv preprint},
  year={2021}
}

BEVFormer
Li, Z., Wang, W., Li, H., Xie, E., Sima, C., Lu, T., ... & Dai, J. (2022, October). Bevformer: Learning bird’s-eye-view representation from multi-camera images via spatiotemporal transformers. In European conference on computer vision (pp. 1-18). Cham: Springer Nature Switzerland.
@inproceedings{li2022bevformer,
  title={{BEVFormer}: Learning bird’s-eye-view representation from multi-camera images via spatiotemporal transformers},
  author={Li, Z. and Wang, W. and Li, H. and Xie, E. and Sima, C. and Lu, T. and Qiao, Y. and Dai, J.},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={1--18},
  year={2022}
}

Understanding and mitigating annotation bias in facial expression recognition
Chen, Y., & Joo, J. (2021). Understanding and mitigating annotation bias in facial expression recognition. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 14980-14991).
@inproceedings{chen2021understanding,
  title={Understanding and mitigating annotation bias in facial expression recognition},
  author={Chen, Y. and Joo, J.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={14980--14991},
  year={2021}
}

Point-Level Region Contrast for Object Detection Pre-Training
Bai, Y., Chen, X., Kirillov, A., Yuille, A., & Berg, A. C. (2022). Point-level region contrast for object detection pre-training. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 16061-16070).
@inproceedings{bai2022point,
  title={Point-level region contrast for object detection pre-training},
  author={Bai, Y. and Chen, X. and Kirillov, A. and Yuille, A. and Berg, A.C.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={16061--16070},
  year={2022}
}

BEVDistill
Chen, Z., Li, Z., Zhang, S., Fang, L., Jiang, Q., & Zhao, F. (2022). Bevdistill: Cross-modal bev distillation for multi-view 3d object detection. arXiv preprint arXiv:2211.09386.
@article{chen2022bevdistill,
  title={{BEVDistill}: Cross-modal {BEV} distillation for multi-view 3{D} object detection},
  author={Chen, Z. and Li, Z. and Zhang, S. and Fang, L. and Jiang, Q. and Zhao, F.},
  journal={arXiv preprint},
  year={2022}
}

Segment Any Point Cloud Sequences by Distilling Vision Foundation Models
Liu, Y., Kong, L., Cen, J., Chen, R., Zhang, W., Pan, L., ... & Liu, Z. (2023). Segment Any Point Cloud Sequences by Distilling Vision Foundation Models. arXiv preprint arXiv:2306.09347.
@article{liu2023segment,
  title={Segment Any Point Cloud Sequences by Distilling Vision Foundation Models},
  author={Liu, Y. and Kong, L. and Cen, J. and Chen, R. and Zhang, W. and Pan, L. and Chen, K. and Liu, Z.},
  journal={arXiv preprint},
  year={2023}
}

BEVDepth
Li, Y., Ge, Z., Yu, G., Yang, J., Wang, Z., Shi, Y., ... & Li, Z. (2023, June). Bevdepth: Acquisition of reliable depth for multi-view 3d object detection. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 37, No. 2, pp. 1477-1485).
@inproceedings{li2023bevdepth,
  title={{BEVDepth}: Acquisition of reliable depth for multi-view 3{D} object detection},
  author={Li, Y. and Ge, Z. and Yu, G. and Yang, J. and Wang, Z. and Shi, Y. and Sun, J. and Li, Z.},
  booktitle={Conference on Artificial Intelligence},
  pages={1477--1485},
  year={2023}
}

Lift, splat, shoot
Philion, J., & Fidler, S. (2020). Lift, splat, shoot: Encoding images from arbitrary camera rigs by implicitly unprojecting to 3d. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XIV 16 (pp. 194-210). Springer International Publishing.
@inproceedings{philion2020lift,
  title={Lift, splat, shoot: Encoding images from arbitrary camera rigs by implicitly unprojecting to 3{D}},
  author={Philion, J. and Fidler, S.},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={194--210},
  year={2020}
}

BEVerse
Zhang, Y., Zhu, Z., Zheng, W., Huang, J., Huang, G., Zhou, J., & Lu, J. (2022). Beverse: Unified perception and prediction in birds-eye-view for vision-centric autonomous driving. arXiv preprint arXiv:2205.09743.
@article{zhang2022beverse,
  title={{BEVerse}: Unified perception and prediction in birds-eye-view for vision-centric autonomous driving},
  author={Zhang, Y. and Zhu, Z. and Zheng, W. and Huang, J. and Huang, G. and Zhou, J. and Lu, J.},
  journal={arXiv preprint},
  year={2022}
}

DETR3D
Wang, Y., Guizilini, V. C., Zhang, T., Wang, Y., Zhao, H., & Solomon, J. (2022, January). Detr3d: 3d object detection from multi-view images via 3d-to-2d queries. In Conference on Robot Learning (pp. 180-191). PMLR.
@inproceedings{wang2022detr3d,
  title={{DETR3D}: 3{D} object detection from multi-view images via 3{D}-to-2{D} queries},
  author={Wang, Y. and Guizilini, V.C. and Zhang, T. and Wang, Y. and Zhao, H. and Solomon, J.},
  booktitle={Conference on Robot Learning (CoRL)},
  pages={180--191},
  year={2022}
}

ORA3D
Roh, W., Chang, G., Moon, S., Nam, G., Kim, C., Kim, Y., ... & Kim, J. (2022). Ora3d: Overlap region aware multi-view 3d object detection. arXiv preprint arXiv:2207.00865.
@article{roh2022ora3d,
  title={{ORA3D}: Overlap region aware multi-view 3{D} object detection},
  author={Roh, W. and Chang, G. and Moon, S. and Nam, G. and Kim, C. and Kim, Y. and Kim, S. and Kim, J.},
  journal={arXiv preprint},
  year={2022}
}

PolarFormer
Jiang, Y., Zhang, L., Miao, Z., Zhu, X., Gao, J., Hu, W., & Jiang, Y. G. (2023, June). Polarformer: Multi-camera 3d object detection with polar transformer. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 37, No. 1, pp. 1042-1050).
@inproceedings{jiang2023polarformer,
  title={{PolarFormer}: Multi-camera 3{D} object detection with polar transformer},
  author={Jiang, Y. and Zhang, L. and Miao, Z. and Zhu, X. and Gao, J. and Hu, W. and Jiang, Y.},
  booktitle={Conference on Artificial Intelligence},
  pages={1042--1050},
  year={2023}
}

Transformer
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing systems, 30.
@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A. and Shazeer, N. and Parmar, N. and Uszkoreit, J. and Jones, L. and Gomez, A.N. and Kaiser, {\L}. and Polosukhin, I.},
  booktitle={Neural Information Processing Systems (NeurIPS)},
  pages={5998--6008},
  year={2017}
}

GCC-3D
Liang, H., Jiang, C., Feng, D., Chen, X., Xu, H., Liang, X., ... & Van Gool, L. (2021). Exploring geometry-aware contrast and clustering harmonization for self-supervised 3d object detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 3293-3302).
@inproceedings{liang2021exploring,
  title={Exploring geometry-aware contrast and clustering harmonization for self-supervised 3{D} object detection},
  author={Liang, H. and Jiang, C. and Feng, D. and Chen, X. and Xu, H. and Liang, X. and Zhang, W. and Li, Z. and Van Gool, L.},
  booktitle={International Conference on Computer Vision (ICCV)},
  pages={3293--3302},
  year={2021}
}

SSL Definitions
Liu, X., Zhang, F., Hou, Z., Mian, L., Wang, Z., Zhang, J., & Tang, J. (2021). Self-supervised learning: Generative or contrastive. IEEE transactions on knowledge and data engineering, 35(1), 857-876.
@article{liu2021self,
  title={Self-supervised learning: Generative or contrastive},
  author={Liu, X. and Zhang, F. and Hou, Z. and Mian, L. and Wang, Z. and Zhang, J. and Tang, J.},
  journal={TKDE},
  volume={35},
  number={1},
  pages={857--876},
  year={2021}
}

SSL Robustness
Hendrycks, D., Mazeika, M., Kadavath, S., & Song, D. (2019). Using self-supervised learning can improve model robustness and uncertainty. Advances in neural information processing systems, 32.
@inproceedings{hendrycks2019using,
  title={Using self-supervised learning can improve model robustness and uncertainty},
  author={Hendrycks, D. and Mazeika, M. and Kadavath, S. and Song, D.},
  booktitle={Neural Information Processing Systems (NeurIPS)},
  pages={15663--15674},
  year={2019}
}

Supervised contrastive learning
Khosla, P., Teterwak, P., Wang, C., Sarna, A., Tian, Y., Isola, P., ... & Krishnan, D. (2020). Supervised contrastive learning. Advances in neural information processing systems, 33, 18661-18673.
@inproceedings{khosla2020supervised,
  title={Supervised contrastive learning},
  author={Khosla, P. and Teterwak, P. and Wang, C. and Sarna, A. and Tian, Y. and Isola, P. and Maschinot, A. and Liu, C. and Krishnan, D.},
  booktitle={Neural Information Processing Systems (NeurIPS)},
  pages={18661--18673},
  year={2020}
}

Oyster
Zhang, L., Yang, A. J., Xiong, Y., Casas, S., Yang, B., Ren, M., & Urtasun, R. (2023). Towards Unsupervised Object Detection From LiDAR Point Clouds. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 9317-9328).
@inproceedings{zhang2023towards,
  title={Towards Unsupervised Object Detection From {LiDAR} Point Clouds},
  author={Zhang, L. and Yang, A.J. and Xiong, Y. and Casas, S. and Yang, B. and Ren, M. and Urtasun, R.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={9317--9328},
  year={2023}
}

Automatic labeling to generate training data for online LiDAR-based moving object segmentation
Chen, X., Mersch, B., Nunes, L., Marcuzzi, R., Vizzo, I., Behley, J., & Stachniss, C. (2022). Automatic labeling to generate training data for online LiDAR-based moving object segmentation. IEEE Robotics and Automation Letters, 7(3), 6107-6114.
@article{chen2022automatic,
  title={Automatic labeling to generate training data for online LiDAR-based moving object segmentation},
  author={Chen, X. and Mersch, B. and Nunes, L. and Marcuzzi, R. and Vizzo, I. and Behley, J. and Stachniss, C.},
  journal={Robotics and Automation Letters (RA-L)},
  volume={7},
  number={3},
  pages={6107--6114},
  year={2022}
}

MODEST
You, Y., Luo, K., Phoo, C. P., Chao, W. L., Sun, W., Hariharan, B., ... & Weinberger, K. Q. (2022). Learning to detect mobile objects from lidar scans without labels. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 1130-1140).
@inproceedings{you2022learning,
  title={Learning to detect mobile objects from {LiDAR} scans without labels},
  author={You, Y. and Luo, K. and Phoo, C.P. and Chao, W. and Sun, W. and Hariharan, B. and Campbell, M. and Weinberger, K.Q.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={1130--1140},
  year={2022}
}

Motion inspired unsupervised perception and prediction in autonomous driving
Najibi, M., Ji, J., Zhou, Y., Qi, C. R., Yan, X., Ettinger, S., & Anguelov, D. (2022, October). Motion inspired unsupervised perception and prediction in autonomous driving. In European Conference on Computer Vision (pp. 424-443). Cham: Springer Nature Switzerland.
@inproceedings{najibi2022motion,
  title={Motion inspired unsupervised perception and prediction in autonomous driving},
  author={Najibi, M. and Ji, J. and Zhou, Y. and Qi, C.R. and Yan, X. and Ettinger, S. and Anguelov, D.},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={424--443},
  year={2022}
}

UniAD
Hu, Y., Yang, J., Chen, L., Li, K., Sima, C., Zhu, X., ... & Li, H. (2023). Planning-oriented autonomous driving. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 17853-17862).
@inproceedings{hu2023planning,
  title={Planning-oriented autonomous driving},
  author={Hu, Y. and Yang, J. and Chen, L. and Li, K. and Sima, C. and Zhu, X. and Chai, S. and Du, S. and Lin, T. and Wang, W. and others},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={17853--17862},
  year={2023}
}

PointRCNN
Shi, S., Wang, X., & Li, H. (2019). Pointrcnn: 3d object proposal generation and detection from point cloud. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 770-779).
@inproceedings{shi2019pointrcnn,
  title={{PointRCNN}: 3{D} object proposal generation and detection from point cloud},
  author={Shi, S. and Wang, X. and Li, H.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={770--779},
  year={2019}
}

EPNet
Huang, T., Liu, Z., Chen, X., & Bai, X. (2020). Epnet: Enhancing point features with image semantics for 3d object detection. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XV 16 (pp. 35-52). Springer International Publishing.
@inproceedings{huang2020epnet,
  title={{EPNet}: Enhancing point features with image semantics for 3{D} object detection},
  author={Huang, T. and Liu, Z. and Chen, X. and Bai, X.},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={35--52},
  year={2020}
}

MVX-Net
Sindagi, V. A., Zhou, Y., & Tuzel, O. (2019, May). Mvx-net: Multimodal voxelnet for 3d object detection. In 2019 International Conference on Robotics and Automation (ICRA) (pp. 7276-7282). IEEE.
@inproceedings{sindagi2019mvx,
  title={{MVX-Net}: Multimodal voxelnet for 3{D} object detection},
  author={Sindagi, V.A. and Zhou, Y. and Tuzel, O.},
  booktitle={International Conference on Robotics and Automation (ICRA)},
  pages={7276--7282},
  year={2019}
}

PointAugmenting
Wang, C., Ma, C., Zhu, M., & Yang, X. (2021). Pointaugmenting: Cross-modal augmentation for 3d object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 11794-11803).
@inproceedings{wang2021pointaugmenting,
  title={{PointAugmenting}: Cross-modal augmentation for 3{D} object detection},
  author={Wang, C. and Ma, C. and Zhu, M. and Yang, X.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={11794--11803},
  year={2021}
}

MVP
Yin, T., Zhou, X., & Krähenbühl, P. (2021). Multimodal virtual point 3d detection. Advances in Neural Information Processing Systems, 34, 16494-16507.
@inproceedings{yin2021multimodal,
  title={Multimodal virtual point 3{D} detection},
  author={Yin, T. and Zhou, X. and Kr{\"a}henb{\"u}hl, P.},
  booktitle={Neural Information Processing Systems (NeurIPS)},
  pages={16494--16507},
  year={2021}
}

Focals Conv-F
Chen, Y., Li, Y., Zhang, X., Sun, J., & Jia, J. (2022). Focal sparse convolutional networks for 3d object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 5428-5437).
@inproceedings{chen2022focal,
  title={Focal sparse convolutional networks for 3{D} object detection},
  author={Chen, Y. and Li, Y. and Zhang, X. and Sun, J. and Jia, J.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={5428--5437},
  year={2022}
}

Deep Continuous Fusion
Liang, M., Yang, B., Wang, S., & Urtasun, R. (2018). Deep continuous fusion for multi-sensor 3d object detection. In Proceedings of the European conference on computer vision (ECCV) (pp. 641-656).
@inproceedings{liang2018deep,
  title={Deep continuous fusion for multi-sensor 3{D} object detection},
  author={Liang, M. and Yang, B. and Wang, S. and Urtasun, R.},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={641--656},
  year={2018}
}

DeepFusion
Li, Y., Yu, A. W., Meng, T., Caine, B., Ngiam, J., Peng, D., ... & Tan, M. (2022). Deepfusion: Lidar-camera deep fusion for multi-modal 3d object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 17182-17191).
@inproceedings{li2022deepfusion,
  title={{DeepFusion}: Lidar-camera deep fusion for multi-modal 3{D} object detection},
  author={Li, Y. and Yu, A.W. and Meng, T. and Caine, B. and Ngiam, J. and Peng, D. and Shen, J. and Lu, Y. and Zhou, D. and Le, Q.V. and others},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={17182--17191},
  year={2022}
}

MV3D
Chen, X., Ma, H., Wan, J., Li, B., & Xia, T. (2017). Multi-view 3d object detection network for autonomous driving. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition (pp. 1907-1915).
@inproceedings{chen2017multi,
  title={Multi-view 3{D} object detection network for autonomous driving},
  author={Chen, X. and Ma, H. and Wan, J. and Li, B. and Xia, T.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={1907--1915},
  year={2017}
}

F-PointNet
Qi, C. R., Liu, W., Wu, C., Su, H., & Guibas, L. J. (2018). Frustum pointnets for 3d object detection from rgb-d data. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 918-927).
@inproceedings{qi2018frustum,
  title={Frustum pointnets for 3{D} object detection from {RGB-D} data},
  author={Qi, C.R. and Liu, W. and Wu, C. and Su, H. and Guibas, L.J.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={918--927},
  year={2018}
}

F-ConvNet
Wang, Z., & Jia, K. (2019, November). Frustum convnet: Sliding frustums to aggregate local point-wise features for amodal 3d object detection. In 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (pp. 1742-1749). IEEE.
@inproceedings{wang2019frustum,
  title={Frustum convnet: Sliding frustums to aggregate local point-wise features for amodal 3{D} object detection},
  author={Wang, Z. and Jia, K.},
  booktitle={IROS},
  pages={1742--1749},
  year={2019}
}

CenterFusion
Nabati, R., & Qi, H. (2021). Centerfusion: Center-based radar and camera fusion for 3d object detection. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1527-1536).
@inproceedings{nabati2021centerfusion,
  title={{CenterFusion}: Center-based radar and camera fusion for 3{D} object detection},
  author={Nabati, R. and Qi, H.},
  booktitle={Winter Conference on Applications of Computer Vision (WACV)},
  pages={1527--1536},
  year={2021}
}

FUTR3D 
Chen, X., Zhang, T., Wang, Y., Wang, Y., & Zhao, H. (2023). Futr3d: A unified sensor fusion framework for 3d detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 172-181).
@inproceedings{chen2023futr3d,
  title={{FUTR3D}: A unified sensor fusion framework for 3{D} detection},
  author={Chen, X. and Zhang, T. and Wang, Y. and Wang, Y. and Zhao, H.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={172--181},
  year={2023}
}

CMT
Yan, J., Liu, Y., Sun, J., Jia, F., Li, S., Wang, T., & Zhang, X. (2023). Cross modal transformer: Towards fast and robust 3d object detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 18268-18278).
@inproceedings{yan2023cross,
  title={Cross modal transformer: Towards fast and robust {3D} object detection},
  author={Yan, J. and Liu, Y. and Sun, J. and Jia, F. and Li, S. and Wang, T. and Zhang, X.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={18268--18278},
  year={2023}
}

BirdNet
Beltrán, J., Guindel, C., Moreno, F. M., Cruzado, D., Garcia, F., & De La Escalera, A. (2018, November). Birdnet: a 3d object detection framework from lidar information. In 2018 21st International Conference on Intelligent Transportation Systems (ITSC) (pp. 3517-3523). IEEE.
@inproceedings{beltran2018birdnet,
  title={{BirdNet}: a 3{D} object detection framework from {LiDAR} information},
  author={Beltr{\'a}n, J. and Guindel, C. and Moreno, F.M. and Cruzado, D. and Garcia, F. and De La Escalera, A.},
  booktitle={International Conference on Intelligent Transportation Systems (ITSC)},
  pages={3517--3523},
  year={2018}
}

LiDAR visibility map
Hu, P., Ziglar, J., Held, D., & Ramanan, D. (2020). What you see is what you get: Exploiting visibility for 3d object detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 11001-11009).
@inproceedings{hu2020you,
  title={What you see is what you get: Exploiting visibility for 3{D} object detection},
  author={Hu, P. and Ziglar, J. and Held, D. and Ramanan, D.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={11001--11009},
  year={2020}
}

SSN (shape loss)
Zhu, X., Ma, Y., Wang, T., Xu, Y., Shi, J., & Lin, D. (2020). Ssn: Shape signature networks for multi-class object detection from point clouds. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XXV 16 (pp. 581-597). Springer International Publishing.
@inproceedings{zhu2020ssn,
  title={{SSN}: Shape signature networks for multi-class object detection from point clouds},
  author={Zhu, X. and Ma, Y. and Wang, T. and Xu, Y. and Shi, J. and Lin, D.},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={581--597},
  year={2020}
}

synthetic data 
Nowruzi, F. E., Kapoor, P., Kolhatkar, D., Hassanat, F. A., Laganiere, R., & Rebut, J. (2019). How much real data do we actually need: Analyzing object detection performance using synthetic and real data. arXiv preprint arXiv:1907.07061.
@article{nowruzi2019much,
  title={How much real data do we actually need: Analyzing object detection performance using synthetic and real data},
  author={Nowruzi, F.E. and Kapoor, P. and Kolhatkar, D. and Al Hassanat, F. and Laganiere, R. and Rebut, J.},
  journal={International Conference on Machine Learning (ICML) Workshop},
  year={2019}
}

SAM
Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland, C., Gustafson, L., ... & Girshick, R. (2023). Segment anything. arXiv preprint arXiv:2304.02643.
@article{kirillov2023segment,
  title={Segment anything},
  author={Kirillov, A. and Mintun, E. and Ravi, N. and Mao, H. and Rolland, C. and Gustafson, L. and Xiao, T. and Whitehead, S. and Berg, A.C. and Lo, W. and others},
  journal={arXiv preprint},
  year={2023}
}

FreeSOLO
Wang, X., Yu, Z., De Mello, S., Kautz, J., Anandkumar, A., Shen, C., & Alvarez, J. M. (2022). Freesolo: Learning to segment objects without annotations. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 14176-14186).
@inproceedings{wang2022freesolo,
  title={{FreeSOLO}: Learning to segment objects without annotations},
  author={Wang, X. and Yu, Z. and De Mello, S. and Kautz, J. and Anandkumar, A. and Shen, C. and Alvarez, J.M.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={14176--14186},
  year={2022}
}

DINO and 2D object detection
Caron, M., Touvron, H., Misra, I., Jégou, H., Mairal, J., Bojanowski, P., & Joulin, A. (2021). Emerging properties in self-supervised vision transformers. In Proceedings of the IEEE/CVF international conference on computer vision (pp. 9650-9660).
@inproceedings{caron2021emerging,
  title={Emerging properties in self-supervised vision transformers},
  author={Caron, M. and Touvron, H. and Misra, I. and J{\'e}gou, H. and Mairal, J. and Bojanowski, P. and Joulin, A.},
  booktitle={International Conference on Computer Vision (ICCV)},
  pages={9650--9660},
  year={2021}
}

FORMULA
Lin, Z., Yang, Z., & Wang, Y. (2023). Foreground Guidance and Multi-Layer Feature Fusion for Unsupervised Object Discovery with Transformers. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 4043-4053).
@inproceedings{lin2023foreground,
  title={Foreground Guidance and Multi-Layer Feature Fusion for Unsupervised Object Discovery with Transformers},
  author={Lin, Z. and Yang, Z. and Wang, Y.},
  booktitle={Winter Conference on Applications of Computer Vision (WACV)},
  pages={4043--4053},
  year={2023}
}

LOST
Siméoni, O., Puy, G., Vo, H. V., Roburin, S., Gidaris, S., Bursuc, A., ... & Ponce, J. (2021). Localizing objects with self-supervised transformers and no labels. arXiv preprint arXiv:2109.14279.
@inproceedings{simeoni2021localizing,
   title={Localizing Objects with Self-Supervised Transformers and no Labels},
   author={Sim{\'e}oni, O. and Puy, G. and Vo, H.V. and Roburin, S. and Gidaris, S. and Bursuc, A. and P{\'e}rez, P. and Marlet, R. and Ponce, J.},
   booktitle={British Machine Vision Conference (BMVC)},
   year={2021}
}

DenseCL
Wang, X., Zhang, R., Shen, C., Kong, T., & Li, L. (2021). Dense contrastive learning for self-supervised visual pre-training. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 3024-3033).
@inproceedings{wang2021dense,
  title={Dense contrastive learning for self-supervised visual pre-training},
  author={Wang, X. and Zhang, R. and Shen, C. and Kong, T. and Li, L.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={3024--3033},
  year={2021}
}

Vision Transformer (ViT)
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., ... & Houlsby, N. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.
@article{dosovitskiy2020vit,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, A. and Beyer, L. and Kolesnikov, A. and Weissenborn, D. and Zhai, X. and Unterthiner, T. and Dehghani, M. and Minderer, M. and Heigold, G. and Gelly, S. and Uszkoreit, J. and Houlsby, N.},
  journal={International Conference on Learning Representations (ICLR)},
  year={2021}
}

HDBSCAN
McInnes, L., Healy, J., & Astels, S. (2017). hdbscan: Hierarchical density based clustering. J. Open Source Softw., 2(11), 205.
@article{mcinnes2017hdbscan,
  title={{HDBSCAN}: Hierarchical density based clustering},
  author={McInnes, L. and Healy, J. and Astels, S.},
  journal={Journal of Open Source Software (JOSS)},
  volume={2},
  number={11},
  pages={205},
  year={2017}
}

Efficient online segmentation for sparse 3D laser scans
Bogoslavskyi, I., & Stachniss, C. (2017). Efficient online segmentation for sparse 3D laser scans. PFG–Journal of Photogrammetry, Remote Sensing and Geoinformation Science, 85, 41-52.
@article{bogoslavskyi2017efficient,
  title={Efficient online segmentation for sparse 3{D} laser scans},
  author={Bogoslavskyi, I. and Stachniss, C.},
  journal={Journal of Photogrammetry, Remote Sensing and Geoinformation Science},
  volume={85},
  pages={41--52},
  year={2017}
}

Hungarian method
Kuhn, H. W. (1955). The Hungarian method for the assignment problem. Naval research logistics quarterly, 2(1‐2), 83-97.
@article{kuhn1955hungarian,
  title={The Hungarian method for the assignment problem},
  author={Kuhn, H.W.},
  journal={NRL},
  volume={2},
  number={1-2},
  pages={83--97},
  year={1955}
}

TokenCut
Wang, Y., Shen, X., Hu, S. X., Yuan, Y., Crowley, J. L., & Vaufreydaz, D. (2022). Self-supervised transformers for unsupervised object discovery using normalized cut. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 14543-14553).
@inproceedings{wang2022self,
  title={Self-supervised transformers for unsupervised object discovery using normalized cut},
  author={Wang, Y. and Shen, X. and Hu, S.X. and Yuan, Y. and Crowley, J.L. and Vaufreydaz, D.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={14543--14553},
  year={2022}
}

Show, match and segment: Joint weakly supervised learning of semantic matching and object co-segmentation
Chen, Y. C., Lin, Y. Y., Yang, M. H., & Huang, J. B. (2020). Show, match and segment: Joint weakly supervised learning of semantic matching and object co-segmentation. IEEE transactions on pattern analysis and machine intelligence, 43(10), 3632-3647.
@article{chen2020show,
  title={Show, match and segment: Joint weakly supervised learning of semantic matching and object co-segmentation},
  author={Chen, Y. and Lin, Y. and Yang, M. and Huang, J.},
  journal={Transactions on Pattern Analysis and Machine Intelligence (PAMI)},
  volume={43},
  number={10},
  pages={3632--3647},
  year={2020}
}

Co-attention CNNs for unsupervised object co-segmentation
Hsu, K. J., Lin, Y. Y., & Chuang, Y. Y. (2018, July). Co-attention CNNs for unsupervised object co-segmentation. In IJCAI (Vol. 1, p. 2).
@inproceedings{hsu2018co,
  title={Co-attention {CNNs} for unsupervised object co-segmentation},
  author={Hsu, K. and Lin, Y. and Chuang, Y.},
  booktitle={International Joint Conference on Artificial Intelligence (IJCAI)},
  year={2018}
}

Discriminative clustering for image co-segmentation
Joulin, A., Bach, F., & Ponce, J. (2010, June). Discriminative clustering for image co-segmentation. In 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (pp. 1943-1950). IEEE.
@inproceedings{joulin2010discriminative,
  title={Discriminative clustering for image co-segmentation},
  author={Joulin, A. and Bach, F. and Ponce, J.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={1943--1950},
  year={2010}
}

Multi-class cosegmentation
Joulin, A., Bach, F., & Ponce, J. (2012, June). Multi-class cosegmentation. In 2012 IEEE conference on computer vision and pattern recognition (pp. 542-549). IEEE.
@inproceedings{joulin2012multi,
  title={Multi-class cosegmentation},
  author={Joulin, A. and Bach, F. and Ponce, J.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={542--549},
  year={2012}
}

Object cosegmentation
Vicente, S., Rother, C., & Kolmogorov, V. (2011, June). Object cosegmentation. In CVPR 2011 (pp. 2217-2224). IEEE.
@inproceedings{vicente2011object,
  title={Object cosegmentation},
  author={Vicente, S. and Rother, C. and Kolmogorov, V.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={2217--2224},
  year={2011}
}

Unsupervised object discovery and localization in the wild: Part-based matching with bottom-up region proposals
Cho, M., Kwak, S., Schmid, C., & Ponce, J. (2015). Unsupervised object discovery and localization in the wild: Part-based matching with bottom-up region proposals. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 1201-1210).
@inproceedings{cho2015unsupervised,
  title={Unsupervised object discovery and localization in the wild: Part-based matching with bottom-up region proposals},
  author={Cho, M. and Kwak, S. and Schmid, C. and Ponce, J.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={1201--1210},
  year={2015}
}

Co-localization in real-world images
Tang, K., Joulin, A., Li, L. J., & Fei-Fei, L. (2014). Co-localization in real-world images. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 1464-1471).
@inproceedings{tang2014co,
  title={Co-localization in real-world images},
  author={Tang, K. and Joulin, A. and Li, L. and Fei-Fei, L.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={1464--1471},
  year={2014}
}

Unsupervised image matching and object discovery as optimization
Vo, H. V., Bach, F., Cho, M., Han, K., LeCun, Y., Pérez, P., & Ponce, J. (2019). Unsupervised image matching and object discovery as optimization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 8287-8296).
@inproceedings{vo2019unsupervised,
  title={Unsupervised image matching and object discovery as optimization},
  author={Vo, H.V. and Bach, F. and Cho, M. and Han, K. and LeCun, Y. and P{\'e}rez, P. and Ponce, J.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={8287--8296},
  year={2019}
}

Toward unsupervised, multi-object discovery in large-scale image collections
Vo, H. V., Pérez, P., & Ponce, J. (2020). Toward unsupervised, multi-object discovery in large-scale image collections. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part XXIII 16 (pp. 779-795). Springer International Publishing.
@inproceedings{vo2020toward,
  title={Toward unsupervised, multi-object discovery in large-scale image collections},
  author={Vo, H.V. and P{\'e}rez, P. and Ponce, J.},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={779--795},
  year={2020}
}

Large-scale unsupervised object discovery
Vo, V. H., Sizikova, E., Schmid, C., Pérez, P., & Ponce, J. (2021). Large-scale unsupervised object discovery. Advances in Neural Information Processing Systems, 34, 16764-16778.
@inproceedings{vo2021large,
  title={Large-scale unsupervised object discovery},
  author={Vo, H.V. and Sizikova, E. and Schmid, C. and P{\'e}rez, P. and Ponce, J.},
  booktitle={Neural Information Processing Systems (NeurIPS)},
  pages={16764--16778},
  year={2021}
}

LoGoNet
Li, X., Ma, T., Hou, Y., Shi, B., Yang, Y., Liu, Y., ... & He, L. (2023). LoGoNet: Towards Accurate 3D Object Detection with Local-to-Global Cross-Modal Fusion. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 17524-17534).
@inproceedings{li2023logonet,
  title={{LoGoNet}: Towards Accurate 3{D} Object Detection with Local-to-Global Cross-Modal Fusion},
  author={Li, X. and Ma, T. and Hou, Y. and Shi, B. and Yang, Y. and Liu, Y. and Wu, X. and Chen, Q. and Li, Y. and Qiao, Y. and others},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={17524--17534},
  year={2023}
}

CutLER
Wang, X., Girdhar, R., Yu, S. X., & Misra, I. (2023). Cut and learn for unsupervised object detection and instance segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 3124-3134).
@inproceedings{wang2023cut,
  title={Cut and learn for unsupervised object detection and instance segmentation},
  author={Wang, X. and Girdhar, R. and Yu, S.X. and Misra, I.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={3124--3134},
  year={2023}
}

CenterPoint
Yin, T., Zhou, X., & Krahenbuhl, P. (2021). Center-based 3d object detection and tracking. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 11784-11793).
@inproceedings{yin2021center,
  title={Center-based 3{D} object detection and tracking},
  author={Yin, T. and Zhou, X. and Krahenbuhl, P.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={11784--11793},
  year={2021}
}

mAP reference
Everingham, M., Van Gool, L., Williams, C. K., Winn, J., & Zisserman, A. (2010). The pascal visual object classes (voc) challenge. International journal of computer vision, 88, 303-338.
@article{everingham2010pascal,
  title={The pascal visual object classes (voc) challenge},
  author={Everingham, M. and Van Gool, L. and Williams, C.K.I. and Winn, J. and Zisserman, A.},
  journal={International Journal of Computer Vision (IJCV)},
  volume={88},
  pages={303--338},
  year={2010}
}

Face recognition
Barnouti, N. H., Al-Dabbagh, S. S. M., & Matti, W. E. (2016). Face recognition: A literature review. International Journal of Applied Information Systems, 11(4), 21-31.
@article{barnouti2016face,
  title={Face recognition: A literature review},
  author={Barnouti, N.H. and Al-Dabbagh, S.S.M. and Matti, W.E.},
  journal={IJAIS},
  volume={11},
  number={4},
  pages={21--31},
  year={2016}
}

RT-2
Zitkovich, B., Yu, T., Xu, S., Xu, P., Xiao, T., Xia, F., ... & Han, K. (2023, December). Rt-2: Vision-language-action models transfer web knowledge to robotic control. In Conference on Robot Learning (pp. 2165-2183). PMLR.
@inproceedings{zitkovich2023rt,
  title={{RT-2}: Vision-language-action models transfer web knowledge to robotic control},
  author={Zitkovich, B. and Yu, T. and Xu, S. and Xu, P. and Xiao, T. and Xia, F. and Wu, J. and Wohlhart, P. and Welker, S. and Wahid, A. and others},
  booktitle={Conference on Robot Learning (CoRL)},
  pages={2165--2183},
  year={2023}
}

DRIFT
Luo, K. Z., Liu, Z., Chen, X., You, Y., Benaim, S., Phoo, C. P., ... & Weinberger, K. Q. (2023). Reward Finetuning for Faster and More Accurate Unsupervised Object Discovery. arXiv preprint arXiv:2310.19080.
@article{luo2023reward,
  title={Reward Finetuning for Faster and More Accurate Unsupervised Object Discovery},
  author={Luo, K. and Liu, Z. and Chen, X. and You, Y. and Benaim, S. and Phoo, C.P. and Campbell, M. and Sun, W. and Hariharan, B. and Weinberger, K.Q.},
  journal={Neural Information Processing Systems (NeurIPS)},
  volume={36},
  year={2023}
}

Face recognition
Wang, M., & Deng, W. (2021). Deep face recognition: A survey. Neurocomputing, 429, 215-244.
@article{wang2021deep,
  title={Deep face recognition: A survey},
  author={Wang, M. and Deng, W.},
  journal={Neurocomputing},
  volume={429},
  pages={215--244},
  year={2021},
}

Person re-identification
Ye, M., Shen, J., Lin, G., Xiang, T., Shao, L., & Hoi, S. C. (2021). Deep learning for person re-identification: A survey and outlook. IEEE transactions on pattern analysis and machine intelligence, 44(6), 2872-2893.
@article{ye2021deep,
  title={Deep learning for person re-identification: A survey and outlook},
  author={Ye, M. and Shen, J. and Lin, G. and Xiang, T. and Shao, L. and Hoi, S.C.H.},
  journal={Transactions on Pattern Analysis and Machine Intelligence (PAMI)},
  volume={44},
  number={6},
  pages={2872--2893},
  year={2021}
}

ICP-Flow (scene flow estimation method of Yancong)
@inproceedings{lin2024icp,
  title={{ICP-Flow}: {LiDAR} Scene Flow Estimation with {ICP}},
  author={Lin, Y. and Caesar, H.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  year={2024}
}

Drive&Segment
Vobecky, A., Hurych, D., Siméoni, O., Gidaris, S., Bursuc, A., Pérez, P., & Sivic, J. (2022, October). Drive&segment: Unsupervised semantic segmentation of urban scenes via cross-modal distillation. In European Conference on Computer Vision (pp. 478-495). Cham: Springer Nature Switzerland.
@inproceedings{vobecky2022drive,
  title={{Drive\&Segment}: Unsupervised semantic segmentation of urban scenes via cross-modal distillation},
  author={Vobecky, A. and Hurych, D. and Sim{\'e}oni, O. and Gidaris, S. and Bursuc, A. and P{\'e}rez, P. and Sivic, J.},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={478--495},
  year={2022}
}

CAUSE
Kim, J., Lee, B. K., & Ro, Y. M. (2023). Causal unsupervised semantic segmentation. arXiv preprint arXiv:2310.07379.
@article{kim2023causal,
  title={Causal unsupervised semantic segmentation},
  author={Kim, J. and Lee, B. and Ro, Y.M.},
  journal={arXiv preprint arXiv:2310.07379},
  year={2023}
}

LISO
Baur, S., Moosmann, F., & Geiger, A. (2024). LISO: Lidar-only Self-Supervised 3D Object Detection. European Conference on Computer Vision (ECCV).
@inproceedings{baur2024liso,
  author = {Baur, S. and Moosmann, F. and Geiger, A.},
  title = {{LISO}: Lidar-only Self-Supervised {3D} Object Detection},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year = {2024}
}

RSF
Deng, D., & Zakhor, A. (2023). Rsf: Optimizing rigid scene flow from 3d point clouds without labels. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 1277-1286).
@inproceedings{deng2023rsf,
  title={{RSF}: Optimizing rigid scene flow from {3D} point clouds without labels},
  author={Deng, D. and Zakhor, A.},
  booktitle={Winter Conference on Applications of Computer Vision (WACV)},
  pages={1277--1286},
  year={2023}
}

SeMoLi
Seidenschwarz, J., Osep, A., Ferroni, F., Lucey, S., & Leal-Taixé, L. (2024). Semoli: What moves together belongs together. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 14685-14694).
@inproceedings{seidenschwarz2024semoli,
  title={{SeMoLi}: What moves together belongs together},
  author={Seidenschwarz, J. and Osep, A. and Ferroni, F. and Lucey, S. and Leal-Taix{\'e}, L.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={14685--14694},
  year={2024}
}

Chowdhury, P. N., Bhunia, A. K., Sain, A., Koley, S., Xiang, T., & Song, Y. Z. (2023). What can human sketches do for object detection?. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 15083-15094).
@inproceedings{chowdhury2023can,
  title={What can human sketches do for object detection?},
  author={Chowdhury, P.N. and Bhunia, A.K. and Sain, A. and Koley, S. and Xiang, T. and Song, Y.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={15083--15094},
  year={2023}
}

MMDetection3D
@misc{mmdet3d2020,
    title={{MMDetection3D: OpenMMLab} next-generation platform for general {3D} object detection},
    author={MMDetection3D Contributors},
    howpublished={\url{https://github.com/open-mmlab/mmdetection3d}},
    year={2020}
}

K-Means
MacQueen, J. (1967, June). Some methods for classification and analysis of multivariate observations. In Proceedings of the fifth Berkeley symposium on mathematical statistics and probability (Vol. 1, No. 14, pp. 281-297).
@inproceedings{macqueen1967some,
  title={Some methods for classification and analysis of multivariate observations},
  author={MacQueen, J.},
  booktitle={Berkeley Symposium on Mathematical Statistics and Probability (BSMSP)},
  volume={1},
  pages={281--297},
  year={1967}
}

CBGS
Zhu, B., Jiang, Z., Zhou, X., Li, Z., & Yu, G. (2019). Class-balanced grouping and sampling for point cloud 3d object detection. arXiv preprint arXiv:1908.09492.
@article{zhu2019class,
  title={Class-balanced grouping and sampling for point cloud {3D} object detection},
  author={Zhu, B. and Jiang, Z. and Zhou, X. and Li, Z. and Yu, G.},
  journal={arXiv preprint arXiv:1908.09492},
  year={2019}
}

CPD
Wu, H., Zhao, S., Huang, X., Wen, C., Li, X., & Wang, C. (2024). Commonsense Prototype for Outdoor Unsupervised 3D Object Detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 14968-14977).
@inproceedings{wu2024commonsense,
  title={Commonsense Prototype for Outdoor Unsupervised {3D} Object Detection},
  author={Wu, H. and Zhao, S. and Huang, X. and Wen, C. and Li, X. and Wang, C.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={14968--14977},
  year={2024}
}

Vision transformers need registers
@article{darcet2024vision,
  title={Vision transformers need registers},
  author={Darcet, T. and Oquab, M. and Mairal, J. and Bojanowski, P.},
  journal={International Conference on Learning Representations (ICLR)},
  year={2024}
}

I-JEPA
@inproceedings{assran2023self,
  title={Self-supervised learning from images with a joint-embedding predictive architecture},
  author={Assran, M. and Duval, Q. and Misra, I. and Bojanowski, P. and Vincent, P. and Rabbat, M. and LeCun, Y. and Ballas, N.},
  booktitle={Computer Vision and Pattern Recognition (CVPR)},
  pages={15619--15629},
  year={2023}
}
