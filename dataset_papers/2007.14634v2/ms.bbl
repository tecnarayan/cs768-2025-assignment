\begin{thebibliography}{10}

\bibitem{bekas2007estimator}
Costas Bekas, Effrosyni Kokiopoulou, and Yousef Saad.
\newblock An estimator for the diagonal of a matrix.
\newblock {\em Applied numerical mathematics}, 57(11-12):1214--1229, 2007.

\bibitem{blei2017variational}
David~M Blei, Alp Kucukelbir, and Jon~D McAuliffe.
\newblock Variational inference: A review for statisticians.
\newblock {\em Journal of the American Statistical Association},
  112(518):859--877, 2017.

\bibitem{boustati2020amortized}
Ayman Boustati, Sattar Vakili, James Hensman, and ST~John.
\newblock Amortized variance reduction for doubly stochastic objectives.
\newblock {\em arXiv preprint arXiv:2003.04125}, 2020.

\bibitem{stan}
Bob Carpenter, Andrew Gelman, Matthew~D Hoffman, Daniel Lee, Ben Goodrich,
  Michael Betancourt, Marcus Brubaker, Jiqiang Guo, Peter Li, and Allen
  Riddell.
\newblock Stan: A probabilistic programming language.
\newblock {\em Journal of statistical software}, 76(1), 2017.

\bibitem{chaloner1995bayesian}
Kathryn Chaloner and Isabella Verdinelli.
\newblock Bayesian experimental design: A review.
\newblock {\em Statistical Science}, pages 273--304, 1995.

\bibitem{cvs}
Tomas Geffner and Justin Domke.
\newblock Using large ensembles of control variates for variational inference.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  9960--9970, 2018.

\bibitem{frisk}
Andrew Gelman, Jeffrey Fagan, and Alex Kiss.
\newblock An analysis of the new york city police department's
  ``stop-and-frisk'' policy in the context of claims of racial bias.
\newblock {\em Journal of the American Statistical Association},
  102(479):813--823, 2007.

\bibitem{glasserman2013monte}
Paul Glasserman.
\newblock {\em Monte Carlo methods in financial engineering}, volume~53.
\newblock Springer Science \& Business Media, 2013.

\bibitem{backpropvoid}
Will Grathwohl, Dami Choi, Yuhuai Wu, Geoff Roeder, and David Duvenaud.
\newblock Backpropagation through the void: Optimizing control variates for
  black-box gradient estimation.
\newblock In {\em Proceedings of the International Conference on Learning
  Representations}, 2018.

\bibitem{jaakkola2000bayesian}
Tommi~S Jaakkola and Michael~I Jordan.
\newblock Bayesian parameter estimation via variational methods.
\newblock {\em Statistics and Computing}, 10(1):25--37, 2000.

\bibitem{gumbel1}
Eric Jang, Shixiang Gu, and Ben Poole.
\newblock Categorical reparameterization with gumbel-softmax.
\newblock {\em arXiv preprint arXiv:1611.01144}, 2016.

\bibitem{jordan1999introduction}
Michael~I Jordan, Zoubin Ghahramani, Tommi~S Jaakkola, and Lawrence~K Saul.
\newblock An introduction to variational methods for graphical models.
\newblock {\em Machine learning}, 37(2):183--233, 1999.

\bibitem{adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{vaes_welling}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock In {\em Proceedings of the International Conference on Learning
  Representations}, 2013.

\bibitem{advi}
Alp Kucukelbir, Dustin Tran, Rajesh Ranganath, Andrew Gelman, and David~M Blei.
\newblock Automatic differentiation variational inference.
\newblock {\em The Journal of Machine Learning Research}, 18(1):430--474, 2017.

\bibitem{gumbel2}
Chris~J Maddison, Andriy Mnih, and Yee~Whye Teh.
\newblock The concrete distribution: A continuous relaxation of discrete random
  variables.
\newblock {\em arXiv preprint arXiv:1611.00712}, 2016.

\bibitem{traylorreducevariance_adam}
Andrew Miller, Nick Foti, Alexander D'Amour, and Ryan~P Adams.
\newblock Reducing reparameterization gradient variance.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  3708--3718, 2017.

\bibitem{neuralVI_minh}
Andriy Mnih and Karol Gregor.
\newblock Neural variational inference and learning in belief networks.
\newblock In {\em International Conference on Machine Learning}, 2014.

\bibitem{VIforMCobjectives_mnih}
Andriy Mnih and Danilo Rezende.
\newblock Variational inference for monte carlo objectives.
\newblock In {\em International Conference on Machine Learning}, pages
  2188--2196, 2016.

\bibitem{mohamed2019monte}
Shakir Mohamed, Mihaela Rosca, Michael Figurnov, and Andriy Mnih.
\newblock Monte carlo gradient estimation in machine learning.
\newblock {\em arXiv preprint arXiv:1906.10652}, 2019.

\bibitem{diagLR}
Victor M-H Ong, David~J Nott, and Michael~S Smith.
\newblock Gaussian variational approximation with a factor covariance
  structure.
\newblock {\em Journal of Computational and Graphical Statistics},
  27(3):465--478, 2018.

\bibitem{mcbook}
Art~B. Owen.
\newblock {\em Monte Carlo theory, methods and examples}.
\newblock 2013.

\bibitem{viasstochastic_jordan}
John Paisley, David Blei, and Michael Jordan.
\newblock Variational bayesian inference with stochastic search.
\newblock In {\em Proceedings of the 29th International Conference on Machine
  Learning (ICML-12)}, pages 1363--1370, 2012.

\bibitem{pflug2012optimization}
Georg~Ch Pflug.
\newblock {\em Optimization of stochastic models: the interface between
  simulation and optimization}, volume 373.
\newblock Springer Science \& Business Media, 2012.

\bibitem{blackbox_blei}
Rajesh Ranganath, Sean Gerrish, and David Blei.
\newblock Black box variational inference.
\newblock In {\em Artificial Intelligence and Statistics}, pages 814--822,
  2014.

\bibitem{rezende2014stochastic}
Danilo~Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock In {\em Proceedings of the 31st International Conference on Machine
  Learning (ICML-14)}, pages 1278--1286, 2014.

\bibitem{stickingthelanding}
Geoffrey Roeder, Yuhuai Wu, and David~K Duvenaud.
\newblock Sticking the landing: Simple, lower-variance gradient estimators for
  variational inference.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6925--6934, 2017.

\bibitem{generalreparam_blei}
Francisco Ruiz, Titsias Michalis, and David Blei.
\newblock The generalized reparameterization gradient.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  460--468, 2016.

\bibitem{overdispersed_blei}
Francisco~JR Ruiz, Michalis~K Titsias, and David~M Blei.
\newblock Overdispersed black-box variational inference.
\newblock {\em arXiv preprint arXiv:1603.01140}, 2016.

\bibitem{sutton2018reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock {\em Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem{doublystochastic_titsias}
Michalis Titsias and Miguel L{\'a}zaro-Gredilla.
\newblock Doubly stochastic variational bayes for non-conjugate inference.
\newblock In {\em Proceedings of the 31st International Conference on Machine
  Learning (ICML-14)}, pages 1971--1979, 2014.

\bibitem{householderflows}
Jakub~M Tomczak and Max Welling.
\newblock Improving variational auto-encoders using householder flow.
\newblock {\em arXiv preprint arXiv:1611.09630}, 2016.

\bibitem{REBAR}
George Tucker, Andriy Mnih, Chris~J Maddison, John Lawson, and Jascha
  Sohl-Dickstein.
\newblock Rebar: Low-variance, unbiased gradient estimates for discrete latent
  variable models.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2627--2636, 2017.

\bibitem{williams_reinforce}
Ronald~J Williams.
\newblock Simple statistical gradient-following algorithms for connectionist
  reinforcement learning.
\newblock {\em Machine learning}, 8(3-4):229--256, 1992.

\bibitem{zhang2017advances}
Cheng Zhang, Judith Butepage, Hedvig Kjellstrom, and Stephan Mandt.
\newblock Advances in variational inference.
\newblock {\em arXiv preprint arXiv:1711.05597}, 2017.

\end{thebibliography}
