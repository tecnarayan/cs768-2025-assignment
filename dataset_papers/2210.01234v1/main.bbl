\begin{thebibliography}{58}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Acuna et~al.(2018)Acuna, Ling, Kar, and Fidler]{acuna2018efficient}
David Acuna, Huan Ling, Amlan Kar, and Sanja Fidler.
\newblock Efficient interactive annotation of segmentation datasets with
  polygon-rnn++.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2018.

\bibitem[Mahmood et~al.(2022{\natexlab{a}})Mahmood, Lucas, Acuna, Li, Philion,
  Alvarez, Yu, Fidler, and Law]{mahmood2022howmuch}
Rafid Mahmood, James Lucas, David Acuna, Daiqing Li, Jonah Philion, Jose~M.
  Alvarez, Zhiding Yu, Sanja Fidler, and Marc~T. Law.
\newblock How much more data do we need? estimating requirements for downstream
  tasks.
\newblock In \emph{2022 IEEE Conference on Computer Vision and Pattern
  Recognition}. Ieee, 2022{\natexlab{a}}.

\bibitem[Frey and Fisher(1999)]{frey1999modeling}
Lewis~J Frey and Douglas~H Fisher.
\newblock Modeling decision tree performance with the power law.
\newblock In \emph{Seventh International Workshop on Artificial Intelligence
  and Statistics}. PMLR, 1999.

\bibitem[Gu et~al.(2001)Gu, Hu, and Liu]{gu2001modelling}
Baohua Gu, Feifang Hu, and Huan Liu.
\newblock Modelling classification performance for large data sets.
\newblock In \emph{International Conference on Web-Age Information Management},
  pages 317--328. Springer, 2001.

\bibitem[Hestness et~al.(2017)Hestness, Narang, Ardalani, Diamos, Jun,
  Kianinejad, Patwary, Ali, Yang, and Zhou]{hestness2017deep}
Joel Hestness, Sharan Narang, Newsha Ardalani, Gregory Diamos, Heewoo Jun,
  Hassan Kianinejad, Md~Patwary, Mostofa Ali, Yang Yang, and Yanqi Zhou.
\newblock Deep learning scaling is predictable, empirically.
\newblock \emph{arXiv preprint arXiv:1712.00409}, 2017.

\bibitem[Rosenfeld et~al.(2020)Rosenfeld, Rosenfeld, Belinkov, and
  Shavit]{rosenfeld2019constructive}
Jonathan~S Rosenfeld, Amir Rosenfeld, Yonatan Belinkov, and Nir Shavit.
\newblock A constructive prediction of the generalization error across scales.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Kaplan et~al.(2020)Kaplan, McCandlish, Henighan, Brown, Chess, Child,
  Gray, Radford, Wu, and Amodei]{kaplan2020scaling}
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom~B Brown, Benjamin Chess, Rewon
  Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.
\newblock Scaling laws for neural language models.
\newblock \emph{arXiv preprint arXiv:2001.08361}, 2020.

\bibitem[Hoiem et~al.(2021)Hoiem, Gupta, Li, and
  Shlapentokh-Rothman]{hoiem2021learning}
Derek Hoiem, Tanmay Gupta, Zhizhong Li, and Michal Shlapentokh-Rothman.
\newblock Learning curves for analysis of deep networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  4287--4296. PMLR, 2021.

\bibitem[Bahri et~al.(2021)Bahri, Dyer, Kaplan, Lee, and
  Sharma]{bahri2021explaining}
Yasaman Bahri, Ethan Dyer, Jared Kaplan, Jaehoon Lee, and Utkarsh Sharma.
\newblock Explaining neural scaling laws.
\newblock \emph{arXiv preprint arXiv:2102.06701}, 2021.

\bibitem[Bisla et~al.(2021)Bisla, Saridena, and
  Choromanska]{bisla2021theoretical}
Devansh Bisla, Apoorva~Nandini Saridena, and Anna Choromanska.
\newblock A theoretical-empirical approach to estimating sample complexity of
  dnns.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 3270--3280, 2021.

\bibitem[Mikami et~al.(2021)Mikami, Fukumizu, Murai, Suzuki, Kikuchi, Suzuki,
  Maeda, and Hayashi]{mikami2021scaling}
Hiroaki Mikami, Kenji Fukumizu, Shogo Murai, Shuji Suzuki, Yuta Kikuchi, Taiji
  Suzuki, Shin-ichi Maeda, and Kohei Hayashi.
\newblock A scaling law for synthetic-to-real transfer: How much is your
  pre-training effective?
\newblock \emph{arXiv preprint arXiv:2108.11018}, 2021.

\bibitem[Acuna et~al.(2021)Acuna, Zhang, Law, and Fidler]{acuna2021f}
David Acuna, Guojun Zhang, Marc~T Law, and Sanja Fidler.
\newblock f-domain adversarial learning: Theory and algorithms.
\newblock In \emph{International Conference on Machine Learning}, pages 66--75.
  PMLR, 2021.

\bibitem[Prakash et~al.(2021)Prakash, Debnath, Lafleche, Cameracci, State,
  Birchfield, and Law]{Prakash_2021_ICCV}
Aayush Prakash, Shoubhik Debnath, Jean-Francois Lafleche, Eric Cameracci,
  Gavriel State, Stan Birchfield, and Marc~T. Law.
\newblock Self-supervised real-to-sim scene generation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 16044--16054, October 2021.

\bibitem[Acuna et~al.(2022)Acuna, Law, Zhang, and Fidler]{acuna2022domain}
David Acuna, Marc~T Law, Guojun Zhang, and Sanja Fidler.
\newblock Domain adversarial training: A game perspective.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Jones et~al.(2003)Jones, Carley, and Harrison]{jones2003introduction}
S~Jones, S~Carley, and M~Harrison.
\newblock An introduction to power and sample size estimation.
\newblock \emph{Emergency Medicine Journal: EMJ}, 20\penalty0 (5):\penalty0
  453, 2003.

\bibitem[Sun et~al.(2017)Sun, Shrivastava, Singh, and Gupta]{sun2017revisiting}
Chen Sun, Abhinav Shrivastava, Saurabh Singh, and Abhinav Gupta.
\newblock Revisiting unreasonable effectiveness of data in deep learning era.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pages 843--852, 2017.

\bibitem[Figueroa et~al.(2012)Figueroa, Zeng-Treitler, Kandula, and
  Ngo]{figueroa2012predicting}
Rosa~L Figueroa, Qing Zeng-Treitler, Sasikiran Kandula, and Long~H Ngo.
\newblock Predicting sample size required for classification performance.
\newblock \emph{BMC Medical Informatics and Decision Making}, 12\penalty0
  (1):\penalty0 1--10, 2012.

\bibitem[Viering and Loog(2021)]{viering2021shape}
Tom Viering and Marco Loog.
\newblock The shape of learning curves: a review.
\newblock \emph{arXiv preprint arXiv:2103.10948}, 2021.

\bibitem[Zhai et~al.(2022)Zhai, Kolesnikov, Houlsby, and
  Beyer]{zhai2021scaling}
Xiaohua Zhai, Alexander Kolesnikov, Neil Houlsby, and Lucas Beyer.
\newblock Scaling vision transformers.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2022.

\bibitem[Settles(2009)]{settles2009active}
Burr Settles.
\newblock Active learning literature survey.
\newblock 2009.

\bibitem[Sener and Savarese(2018)]{sener2017active}
Ozan Sener and Silvio Savarese.
\newblock Active learning for convolutional neural networks: A core-set
  approach.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Yoo and Kweon(2019)]{yoo2019learning}
Donggeun Yoo and In~So Kweon.
\newblock Learning loss for active learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 93--102, 2019.

\bibitem[Sinha et~al.(2019)Sinha, Ebrahimi, and Darrell]{sinha2019variational}
Samarth Sinha, Sayna Ebrahimi, and Trevor Darrell.
\newblock Variational adversarial active learning.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 5972--5981, 2019.

\bibitem[Mahmood et~al.(2022{\natexlab{b}})Mahmood, Fidler, and
  Law]{mahmood2021low}
Rafid Mahmood, Sanja Fidler, and Marc~T. Law.
\newblock Low-budget active learning via wasserstein distance: An integer
  programming approach.
\newblock In \emph{International Conference on Learning Representations},
  2022{\natexlab{b}}.

\bibitem[Jiang et~al.(2020)Jiang, Foret, Yak, Roy, Mobahi, Dziugaite, Bengio,
  Gunasekar, Guyon, and Neyshabur]{jiang2020neurips}
Yiding Jiang, Pierre Foret, Scott Yak, Daniel~M Roy, Hossein Mobahi,
  Gintare~Karolina Dziugaite, Samy Bengio, Suriya Gunasekar, Isabelle Guyon,
  and Behnam Neyshabur.
\newblock Neurips 2020 competition: Predicting generalization in deep learning.
\newblock \emph{arXiv preprint arXiv:2012.07976}, 2020.

\bibitem[Jiang et~al.(2021)Jiang, Natekar, Sharma, Aithal, Kashyap,
  Subramanyam, Lassance, Roy, Dziugaite, Gunasekar, et~al.]{jiang2021methods}
Yiding Jiang, Parth Natekar, Manik Sharma, Sumukh~K Aithal, Dhruva Kashyap,
  Natarajan Subramanyam, Carlos Lassance, Daniel~M Roy, Gintare~Karolina
  Dziugaite, Suriya Gunasekar, et~al.
\newblock Methods and analysis of the first competition in predicting
  generalization of deep learning.
\newblock In \emph{NeurIPS 2020 Competition and Demonstration Track}, pages
  170--190. PMLR, 2021.

\bibitem[Smith(1918)]{smith1918standard}
Kirstine Smith.
\newblock On the standard deviations of adjusted and interpolated values of an
  observed polynomial function and its constants and the guidance they give
  towards a proper choice of the distribution of observations.
\newblock \emph{Biometrika}, 12\penalty0 (1/2):\penalty0 1--85, 1918.

\bibitem[Cohn(1993)]{cohn1993neural}
David Cohn.
\newblock Neural network exploration using optimal experiment design.
\newblock \emph{Advances in neural information processing systems}, 6, 1993.

\bibitem[Emery and Nenarokomov(1998)]{emery1998optimal}
Ashley~F Emery and Aleksey~V Nenarokomov.
\newblock Optimal experiment design.
\newblock \emph{Measurement Science and Technology}, 9\penalty0 (6):\penalty0
  864, 1998.

\bibitem[Bertsimas et~al.(2015)Bertsimas, Johnson, and
  Kallus]{bertsimas2015power}
Dimitris Bertsimas, Mac Johnson, and Nathan Kallus.
\newblock The power of optimization over randomization in designing experiments
  involving small samples.
\newblock \emph{Operations Research}, 63\penalty0 (4):\penalty0 868--876, 2015.

\bibitem[Carneiro et~al.(2020)Carneiro, Lee, and Wilhelm]{carneiro2020optimal}
Pedro Carneiro, Sokbae Lee, and Daniel Wilhelm.
\newblock Optimal data collection for randomized control trials.
\newblock \emph{The Econometrics Journal}, 23\penalty0 (1):\penalty0 1--31,
  2020.

\bibitem[Zhang(2022)]{zhang2022dynamic}
Hao Zhang.
\newblock Dynamic learning and decision making via basis weight vectors.
\newblock \emph{Operations Research}, 2022.

\bibitem[Haixiang et~al.(2017)Haixiang, Yijing, Shang, Mingyun, Yuanyue, and
  Bing]{haixiang2017learning}
Guo Haixiang, Li~Yijing, Jennifer Shang, Gu~Mingyun, Huang Yuanyue, and Gong
  Bing.
\newblock Learning from class-imbalanced data: Review of methods and
  applications.
\newblock \emph{Expert systems with applications}, 73:\penalty0 220--239, 2017.

\bibitem[Van~Engelen and Hoos(2020)]{van2020survey}
Jesper~E Van~Engelen and Holger~H Hoos.
\newblock A survey on semi-supervised learning.
\newblock \emph{Machine Learning}, 109\penalty0 (2):\penalty0 373--440, 2020.

\bibitem[Ben-David et~al.(2010)Ben-David, Blitzer, Crammer, Kulesza, Pereira,
  and Vaughan]{ben2010theory}
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and
  Jennifer~Wortman Vaughan.
\newblock A theory of learning from different domains.
\newblock \emph{Machine learning}, 79\penalty0 (1):\penalty0 151--175, 2010.

\bibitem[Krizhevsky(2009)]{krizhevsky2009learning}
Alex Krizhevsky.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE Conference on Computer Vision and Pattern
  Recognition}, pages 248--255. Ieee, 2009.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 770--778, 2016.

\bibitem[Chen et~al.(2017)Chen, Papandreou, Schroff, and
  Adam]{chen2017rethinking}
Liang-Chieh Chen, George Papandreou, Florian Schroff, and Hartwig Adam.
\newblock Rethinking atrous convolution for semantic image segmentation.
\newblock \emph{arXiv preprint arXiv:1706.05587}, 2017.

\bibitem[Yu et~al.(2020)Yu, Chen, Wang, Xian, Chen, Liu, Madhavan, and
  Darrell]{yu2020bdd100k}
Fisher Yu, Haofeng Chen, Xin Wang, Wenqi Xian, Yingying Chen, Fangchen Liu,
  Vashisht Madhavan, and Trevor Darrell.
\newblock Bdd100k: A diverse driving dataset for heterogeneous multitask
  learning.
\newblock In \emph{Proceedings of the IEEE/CVF conference on Computer Vision
  and Pattern Recognition}, pages 2636--2645, 2020.

\bibitem[Caesar et~al.(2020)Caesar, Bankiti, Lang, Vora, Liong, Xu, Krishnan,
  Pan, Baldan, and Beijbom]{nuscenes2019}
Holger Caesar, Varun Bankiti, Alex~H Lang, Sourabh Vora, Venice~Erin Liong,
  Qiang Xu, Anush Krishnan, Yu~Pan, Giancarlo Baldan, and Oscar Beijbom.
\newblock nuscenes: A multimodal dataset for autonomous driving.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 11621--11631, 2020.

\bibitem[Philion and Fidler(2020)]{liftsplat}
Jonah Philion and Sanja Fidler.
\newblock Lift, splat, shoot: Encoding images from arbitrary camera rigs by
  implicitly unprojecting to 3d.
\newblock In \emph{Proceedings of the European Conference on Computer Vision},
  2020.

\bibitem[Everingham et~al.({\natexlab{a}})Everingham, Van~Gool, Williams, Winn,
  and Zisserman]{pascal-voc-2007}
Mark Everingham, Luc Van~Gool, Christopher~KI Williams, John Winn, and Andrew
  Zisserman.
\newblock The {PASCAL} {V}isual {O}bject {C}lasses {C}hallenge 2007 {(VOC2007)}
  {R}esults.
\newblock
  http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html,
  {\natexlab{a}}.

\bibitem[Everingham et~al.({\natexlab{b}})Everingham, Van~Gool, Williams, Winn,
  and Zisserman]{pascal-voc-2012}
Mark Everingham, Luc Van~Gool, Christopher~KI Williams, John Winn, and Andrew
  Zisserman.
\newblock The {PASCAL} {V}isual {O}bject {C}lasses {C}hallenge 2012 {(VOC2012)}
  {R}esults.
\newblock
  http://www.pascal-network.org/challenges/VOC/voc2012/workshop/index.html,
  {\natexlab{b}}.

\bibitem[Liu et~al.(2016)Liu, Anguelov, Erhan, Szegedy, Reed, Fu, and
  Berg]{liu2016ssd}
Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed,
  Cheng-Yang Fu, and Alexander~C Berg.
\newblock Ssd: Single shot multibox detector.
\newblock In \emph{Proceedings of the European Conference on Computer Vision},
  pages 21--37. Springer, 2016.

\bibitem[van~der Meulen and McCall(2018)]{van_der_meulen_mccall_2018}
Rob van~der Meulen and Thomas McCall.
\newblock Gartner says nearly half of cios are planning to deploy artificial
  intelligence, Feb 2018.
\newblock URL
  \url{https://www.gartner.com/en/newsroom/press-releases/2018-02-13-gartner-says-nearly-half-of-cios-are-planning-to-deploy-artificial-intelligence}.

\bibitem[ven(2019)]{venturebeat_2019}
Why do 87\% of data science projects never make it into production?, Jul 2019.
\newblock URL
  \url{https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/}.

\bibitem[Mor{\'e}(1978)]{more1978levenberg}
Jorge~J Mor{\'e}.
\newblock The levenberg-marquardt algorithm: implementation and theory.
\newblock In \emph{Numerical analysis}, pages 105--116. Springer, 1978.

\bibitem[Virtanen et~al.(2020)Virtanen, Gommers, Oliphant, Haberland, Reddy,
  Cournapeau, Burovski, Peterson, Weckesser, Bright, {van der Walt}, Brett,
  Wilson, Millman, Mayorov, Nelson, Jones, Kern, Larson, Carey, Polat, Feng,
  Moore, {VanderPlas}, Laxalde, Perktold, Cimrman, Henriksen, Quintero, Harris,
  Archibald, Ribeiro, Pedregosa, {van Mulbregt}, and {SciPy 1.0
  Contributors}]{2020SciPy-NMeth}
Pauli Virtanen, Ralf Gommers, Travis~E. Oliphant, Matt Haberland, Tyler Reddy,
  David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan
  Bright, St{\'e}fan~J. {van der Walt}, Matthew Brett, Joshua Wilson, K.~Jarrod
  Millman, Nikolay Mayorov, Andrew R.~J. Nelson, Eric Jones, Robert Kern, Eric
  Larson, C~J Carey, {\.I}lhan Polat, Yu~Feng, Eric~W. Moore, Jake
  {VanderPlas}, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen,
  E.~A. Quintero, Charles~R. Harris, Anne~M. Archibald, Ant{\^o}nio~H. Ribeiro,
  Fabian Pedregosa, Paul {van Mulbregt}, and {SciPy 1.0 Contributors}.
\newblock {{SciPy} 1.0: Fundamental Algorithms for Scientific Computing in
  Python}.
\newblock \emph{Nature Methods}, 17:\penalty0 261--272, 2020.
\newblock \doi{10.1038/s41592-019-0686-2}.

\bibitem[Puterman(2014)]{puterman2014markov}
Martin~L Puterman.
\newblock \emph{Markov decision processes: discrete stochastic dynamic
  programming}.
\newblock John Wiley \& Sons, 2014.

\bibitem[Bertsekas(2012)]{bertsekas2012dynamic}
Dimitri Bertsekas.
\newblock \emph{Dynamic programming and optimal control: Volume I}, volume~1.
\newblock Athena scientific, 2012.

\bibitem[Easley and Kiefer(1988)]{easley1988controlling}
David Easley and Nicholas~M Kiefer.
\newblock Controlling a stochastic process with unknown parameters.
\newblock \emph{Econometrica: Journal of the Econometric Society}, pages
  1045--1064, 1988.

\bibitem[Smallwood and Sondik(1973)]{smallwood1973optimal}
Richard~D Smallwood and Edward~J Sondik.
\newblock The optimal control of partially observable markov processes over a
  finite horizon.
\newblock \emph{Operations research}, 21\penalty0 (5):\penalty0 1071--1088,
  1973.

\bibitem[Zhao et~al.(2021)Zhao, Liu, Anandkumar, and Yue]{zhao2021active}
Eric Zhao, Anqi Liu, Animashree Anandkumar, and Yisong Yue.
\newblock Active learning under label shift.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 3412--3420. PMLR, 2021.

\bibitem[Ghorbani and Zou(2019)]{ghorbani2019data}
Amirata Ghorbani and James Zou.
\newblock Data shapley: Equitable valuation of data for machine learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  2242--2251. PMLR, 2019.

\bibitem[Coleman et~al.(2020)Coleman, Yeh, Mussmann, Mirzasoleiman, Bailis,
  Liang, Leskovec, and Zaharia]{coleman2019selection}
Cody Coleman, Christopher Yeh, Stephen Mussmann, Baharan Mirzasoleiman, Peter
  Bailis, Percy Liang, Jure Leskovec, and Matei Zaharia.
\newblock Selection via proxy: Efficient data selection for deep learning.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Simonyan and Zisserman(2015)]{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{International Conference on Learning Representations}, 2015.

\bibitem[Elezi et~al.(2022)Elezi, Yu, Anandkumar, Leal-Taixe, and
  Alvarez]{elezi2021towards}
Ismail Elezi, Zhiding Yu, Anima Anandkumar, Laura Leal-Taixe, and Jose~M
  Alvarez.
\newblock Not all labels are equal: Rationalizing the labeling costs for
  training object detection.
\newblock \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, 2022.

\end{thebibliography}
