\begin{thebibliography}{10}

\bibitem{bresson2017residual}
Xavier Bresson and Thomas Laurent.
\newblock Residual gated graph convnets.
\newblock {\em arXiv preprint arXiv:1711.07553}, 2017.

\bibitem{chen20gcn2}
Ming Chen, Zhewei Wei, Zengfeng Huang, Bolin Ding, and Yaliang Li.
\newblock Simple and deep graph convolutional networks.
\newblock In {\em Proceedings of the 37th International Conference on Machine Learning}, 2020.

\bibitem{pmlr-v119-chen20j}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual representations.
\newblock In {\em Proceedings of the 37th International Conference on Machine Learning}, 2020.

\bibitem{degen2008art}
J{\"o}rg Degen, Christof Wegscheid-Gerlach, Andrea Zaliani, and Matthias Rarey.
\newblock On the art of compiling and using'drug-like'chemical fragment spaces.
\newblock {\em ChemMedChem: Chemistry Enabling Drug Discovery}, 3(10):1503--1507, 2008.

\bibitem{devlin-etal-2019-bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language understanding.
\newblock In {\em Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)}, 2019.

\bibitem{dwivedi2022graph}
Vijay~Prakash Dwivedi, Anh~Tuan Luu, Thomas Laurent, Yoshua Bengio, and Xavier Bresson.
\newblock Graph neural networks with learnable structural and positional representations.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{dwivedi2022long}
Vijay~Prakash Dwivedi, Ladislav Ramp{\'a}{\v{s}}ek, Michael Galkin, Ali Parviz, Guy Wolf, Anh~Tuan Luu, and Dominique Beaini.
\newblock Long range graph benchmark.
\newblock {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{fang2022geometry}
Xiaomin Fang, Lihang Liu, Jieqiong Lei, Donglong He, Shanzhuo Zhang, Jingbo Zhou, Fan Wang, Hua Wu, and Haifeng Wang.
\newblock Geometry-enhanced molecular representation learning for property prediction.
\newblock {\em Nature Machine Intelligence}, 4(2):127--134, 2022.

\bibitem{gasteiger_dimenet_2020}
Johannes Gasteiger, Janek Gro{\ss}, and Stephan G{\"u}nnemann.
\newblock Directional message passing for molecular graphs.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{gaulton2012chembl}
Anna Gaulton, Louisa~J Bellis, A~Patricia Bento, Jon Chambers, Mark Davies, Anne Hersey, Yvonne Light, Shaun McGlinchey, David Michalovich, Bissan Al-Lazikani, et~al.
\newblock Chembl: a large-scale bioactivity database for drug discovery.
\newblock {\em Nucleic Acids Research}, 40(D1):D1100--D1107, 2012.

\bibitem{gilmer2017neural}
Justin Gilmer, Samuel~S Schoenholz, Patrick~F Riley, Oriol Vinyals, and George~E Dahl.
\newblock Neural message passing for quantum chemistry.
\newblock In {\em International Conference on Machine Learning}, 2017.

\bibitem{hamilton2017inductive}
William~L. Hamilton, Rex Ying, and Jure Leskovec.
\newblock Inductive representation learning on large graphs.
\newblock In {\em Advances in Neural Information Processing Systems}, 2017.

\bibitem{DBLP:series/ads/HeS10}
Huahai He and Ambuj~K. Singh.
\newblock Query language and access methods for graph databases.
\newblock In Charu~C. Aggarwal and Haixun Wang, editors, {\em Managing and Mining Graph Data}, volume~40 of {\em Advances in Database Systems}, pages 125--160. Springer, 2010.

\bibitem{hu2020open}
Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, and Jure Leskovec.
\newblock Open graph benchmark: Datasets for machine learning on graphs.
\newblock {\em Advances in Neural Information Processing Systems}, 2020.

\bibitem{hu2020pretraining}
Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay Pande, and Jure Leskovec.
\newblock Strategies for pre-training graph neural networks.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{hu2020gpt}
Ziniu Hu, Yuxiao Dong, Kuansan Wang, Kai-Wei Chang, and Yizhou Sun.
\newblock Gpt-gnn: Generative pre-training of graph neural networks.
\newblock In {\em Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining}, 2020.

\bibitem{hwang2020metapath}
Dasol Hwang, Jinyoung Park, Sunyoung Kwon, KyungMin Kim, Jung-Woo Ha, and Hyunwoo~J Kim.
\newblock Self-supervised auxiliary learning with meta-paths for heterogeneous graphs.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin, editors, {\em Advances in Neural Information Processing Systems}, volume~33, pages 10294--10305. Curran Associates, Inc., 2020.

\bibitem{jin2018junction}
Wengong Jin, Regina Barzilay, and Tommi Jaakkola.
\newblock Junction tree variational autoencoder for molecular graph generation.
\newblock In {\em International Conference on Machine Learning}, 2018.

\bibitem{gcn_iclr17}
Thomas~N Kipf and Max Welling.
\newblock Semi-supervised classification with graph convolutional networks.
\newblock In {\em International Conference on Learning Representations}, 2017.

\bibitem{kong2022molecule}
Xiangzhe Kong, Wenbing Huang, Zhixing Tan, and Yang Liu.
\newblock Molecule generation by principal subgraph mining and assembling.
\newblock {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{lewell1998recap}
Xiao~Qing Lewell, Duncan~B Judd, Stephen~P Watson, and Michael~M Hann.
\newblock Recap retrosynthetic combinatorial analysis procedure: a powerful new technique for identifying privileged molecular fragments with useful applications in combinatorial chemistry.
\newblock {\em Journal of Chemical Information and Computer Sciences}, 38(3):511--522, 1998.

\bibitem{li2021mol}
Juncai Li and Xiaofei Jiang.
\newblock Mol-bert: An effective molecular representation with bert for molecular property prediction.
\newblock {\em Wireless Communications and Mobile Computing}, 2021:1--7, 2021.

\bibitem{liu2022pretraining}
Shengchao Liu, Hanchen Wang, Weiyang Liu, Joan Lasenby, Hongyu Guo, and Jian Tang.
\newblock Pre-training molecular graph representation with 3d geometry.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{mayr2018large}
Andreas Mayr, G{\"u}nter Klambauer, Thomas Unterthiner, Marvin Steijaert, J{\"o}rg~K Wegner, Hugo Ceulemans, Djork-Arn{\'e} Clevert, and Sepp Hochreiter.
\newblock Large-scale comparison of machine learning methods for drug target prediction on chembl.
\newblock {\em Chemical Science}, 9(24):5441--5451, 2018.

\bibitem{oord2018representation}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock {\em arXiv preprint arXiv:1807.03748}, 2018.

\bibitem{qiu_gcc}
Jiezhong Qiu, Qibin Chen, Yuxiao Dong, Jing Zhang, Hongxia Yang, Ming Ding, Kuansan Wang, and Jie Tang.
\newblock Gcc: Graph contrastive coding for graph neural network pre-training.
\newblock In {\em Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining}, 2020.

\bibitem{rong2020grover}
Yu~Rong, Yatao Bian, Tingyang Xu, Weiyang Xie, Ying Wei, Wenbing Huang, and Junzhou Huang.
\newblock Self-supervised graph transformer on large-scale molecular data.
\newblock {\em Advances in Neural Information Processing Systems}, 2020.

\bibitem{ross2022large}
Jerret Ross, Brian Belgodere, Vijil Chenthamarakshan, Inkit Padhi, Youssef Mroueh, and Payel Das.
\newblock Large-scale chemical language representations capture molecular structure and properties.
\newblock {\em Nature Machine Intelligence}, 4(12):1256--1264, 2022.

\bibitem{schnet}
K.~T. Schütt, H.~E. Sauceda, P.-J. Kindermans, A.~Tkatchenko, and K.-R. Müller.
\newblock {SchNet – A deep learning architecture for molecules and materials}.
\newblock {\em The Journal of Chemical Physics}, 148(24), 03 2018.
\newblock 241722.

\bibitem{SHEN201929}
Jie Shen and Christos~A Nicolaou.
\newblock Molecular property prediction: recent trends in the era of artificial intelligence.
\newblock {\em Drug Discovery Today: Technologies}, 32-33:29--36, 2019.

\bibitem{pmlr-v162-stark22a}
Hannes St{\"a}rk, Dominique Beaini, Gabriele Corso, Prudencio Tossou, Christian Dallago, Stephan G{\"u}nnemann, and Pietro Li{\'o}.
\newblock 3{D} infomax improves {GNN}s for molecular property prediction.
\newblock In {\em Proceedings of the 39th International Conference on Machine Learning}, 2022.

\bibitem{sun2019infograph}
Fan-Yun Sun, Jordan Hoffman, Vikas Verma, and Jian Tang.
\newblock Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{van2008visualizing}
Laurens Van~der Maaten and Geoffrey Hinton.
\newblock Visualizing data using t-sne.
\newblock {\em Journal of Machine Learning Research}, 9(11), 2008.

\bibitem{velickovic2018graph}
Petar Veli{\v{c}}kovi{\'{c}}, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li{\`{o}}, and Yoshua Bengio.
\newblock {Graph Attention Networks}.
\newblock {\em International Conference on Learning Representations}, 2018.

\bibitem{wang2022molecular}
Yuyang Wang, Jianren Wang, Zhonglin Cao, and Amir Barati~Farimani.
\newblock Molecular contrastive learning of representations via graph neural networks.
\newblock {\em Nature Machine Intelligence}, 4(3):279--287, 2022.

\bibitem{wu2018moleculenet}
Zhenqin Wu, Bharath Ramsundar, Evan~N Feinberg, Joseph Gomes, Caleb Geniesse, Aneesh~S Pappu, Karl Leswing, and Vijay Pande.
\newblock Moleculenet: a benchmark for molecular machine learning.
\newblock {\em Chemical Science}, 9(2):513--530, 2018.

\bibitem{xia2023molebert}
Jun Xia, Chengshuai Zhao, Bozhen Hu, Zhangyang Gao, Cheng Tan, Yue Liu, Siyuan Li, and Stan~Z. Li.
\newblock Mole-{BERT}: Rethinking pre-training graph neural networks for molecules.
\newblock In {\em International Conference on Learning Representations}, 2023.

\bibitem{xia2023systematic}
Jun Xia, Yanqiao Zhu, Yuanqi Du, Yue Liu, and Stan~Z Li.
\newblock A systematic survey of chemical pre-trained models.
\newblock {\em International Joint Conference on Artificial Intelligence}, 2023.

\bibitem{xie2018crystal}
Tian Xie and Jeffrey~C Grossman.
\newblock Crystal graph convolutional neural networks for an accurate and interpretable prediction of material properties.
\newblock {\em Physical Review Letters}, 120(14):145301, 2018.

\bibitem{xie2023review}
Yaochen Xie, Zhao Xu, Jingtun Zhang, Zhengyang Wang, and Shuiwang Ji.
\newblock Self-supervised learning of graph neural networks: A unified review.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}, 45(2):2412--2429, 2023.

\bibitem{xu2018gin}
Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka.
\newblock How powerful are graph neural networks?
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{xu21graphlog}
Minghao Xu, Hang Wang, Bingbing Ni, Hongyu Guo, and Jian Tang.
\newblock Self-supervised graph-level representation learning with local and global structure.
\newblock In {\em Proceedings of the 38th International Conference on Machine Learning}, 2021.

\bibitem{xue2000molecular}
Ling Xue and Jurgen Bajorath.
\newblock Molecular descriptors in chemoinformatics, computational combinatorial chemistry, and virtual screening.
\newblock {\em Combinatorial Chemistry \& High Throughput Screening}, 3(5):363--372, 2000.

\bibitem{you2021deepgraphgo}
Ronghui You, Shuwei Yao, Hiroshi Mamitsuka, and Shanfeng Zhu.
\newblock Deepgraphgo: graph neural network for large-scale, multispecies protein function prediction.
\newblock {\em Bioinformatics}, 37(Supplement 1):i262--i271, 2021.

\bibitem{pmlr-v139-you21a}
Yuning You, Tianlong Chen, Yang Shen, and Zhangyang Wang.
\newblock Graph contrastive learning automated.
\newblock In {\em Proceedings of the 38th International Conference on Machine Learning}, 2021.

\bibitem{You2020GraphCL}
Yuning You, Tianlong Chen, Yongduo Sui, Ting Chen, Zhangyang Wang, and Yang Shen.
\newblock Graph contrastive learning with augmentations.
\newblock In {\em Advances in Neural Information Processing Systems}, 2020.

\bibitem{zeng2022imagemol}
Xiangxiang Zeng, Hongxin Xiang, Linhui Yu, Jianmin Wang, Kenli Li, Ruth Nussinov, and Feixiong Cheng.
\newblock Accurate prediction of molecular properties and drug targets using a self-supervised image representation learning framework.
\newblock {\em Nature Machine Intelligence}, 4(11):1004--1016, 2022.

\bibitem{zhang2020motif}
Shichang Zhang, Ziniu Hu, Arjun Subramonian, and Yizhou Sun.
\newblock Motif-driven contrastive learning of graph representations.
\newblock {\em arXiv preprint arXiv:2012.12533}, 2020.

\bibitem{zhang_mgssl}
Zaixi Zhang, Qi~Liu, Hao Wang, Chengqiang Lu, and Chee-Kong Lee.
\newblock Motif-based graph self-supervised learning for molecular property prediction.
\newblock In {\em Advances in Neural Information Processing Systems}, 2021.

\bibitem{zhu2022unified}
Jinhua Zhu, Yingce Xia, Lijun Wu, Shufang Xie, Tao Qin, Wengang Zhou, Houqiang Li, and Tie-Yan Liu.
\newblock Unified 2d and 3d pre-training of molecular representations.
\newblock In {\em Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining}, pages 2626--2636, 2022.

\bibitem{zhu2023dual}
Jinhua Zhu, Yingce Xia, Lijun Wu, Shufang Xie, Wengang Zhou, Tao Qin, Houqiang Li, and Tie-Yan Liu.
\newblock Dual-view molecular pre-training.
\newblock In {\em Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining}, pages 3615--3627, 2023.

\end{thebibliography}
