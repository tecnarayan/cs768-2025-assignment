\begin{thebibliography}{27}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Kraemer and Banerjee(2016)]{kraemer2016multi}
L.~Kraemer and B.~Banerjee.
\newblock Multi-agent reinforcement learning as a rehearsal for decentralized
  planning.
\newblock \emph{Neurocomputing}, 190:\penalty0 82--94, 2016.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, Petersen, Beattie, Sadik,
  Antonoglou, King, Kumaran, Wierstra, Legg, and Hassabis]{Mnih:2015}
V.~Mnih, K.~Kavukcuoglu, D.~Silver, A.~A. Rusu, J.~Veness, M.~G. Bellemare,
  A.~Graves, M.~Riedmiller, A.~K. Fidjeland, G.~Ostrovski, S.~Petersen,
  C.~Beattie, A.~Sadik, I.~Antonoglou, H.~King, D.~Kumaran, D.~Wierstra,
  S.~Legg, and D.~Hassabis.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529--533, 2015.

\bibitem[Foerster et~al.(2016)Foerster, Assael, de~Freitas, and
  Whiteson]{foerster2016learning}
J.~N. Foerster, Y.~M. Assael, N.~de~Freitas, and S.~Whiteson.
\newblock Learning to communicate to solve riddles with deep distributed
  recurrent q-networks.
\newblock \emph{arXiv preprint arXiv:1602.02672}, 2016.

\bibitem[Tan(1993)]{tan1993multi}
M.~Tan.
\newblock Multi-agent reinforcement learning: {Independent} vs. cooperative
  agents.
\newblock In \emph{ICML}, 1993.

\bibitem[Melo et~al.(2011)Melo, Spaan, and Witwicki]{melo2011querypomdp}
F.~S. Melo, M.~Spaan, and S.~J. Witwicki.
\newblock {QueryPOMDP: POMDP}-based communication in multiagent systems.
\newblock In \emph{Multi-Agent Systems}, pages 189--204. 2011.

\bibitem[Panait and Luke(2005)]{Panait2005387}
L.~Panait and S.~Luke.
\newblock Cooperative multi-agent learning: The state of the art.
\newblock \emph{Autonomous Agents and Multi-Agent Systems}, 11\penalty0
  (3):\penalty0 387--434, 2005.

\bibitem[Zhang and Lesser(2013)]{Zhang20131101}
C.~Zhang and V.~Lesser.
\newblock Coordinating multi-agent reinforcement learning with limited
  communication.
\newblock In \emph{AAMAS}, volume~2, pages 1101--1108, 2013.

\bibitem[Kasai et~al.(2008)Kasai, Tenmoto, and Kamiya]{kasai2008learning}
T.~Kasai, H.~Tenmoto, and A.~Kamiya.
\newblock Learning of communication codes in multi-agent reinforcement learning
  problem.
\newblock In \emph{IEEE Soft Computing in Industrial Applications}, pages 1--6,
  2008.

\bibitem[Giles and Jim(2002)]{giles2002learning}
C.~L. Giles and K.~C. Jim.
\newblock Learning communication for multi-agent systems.
\newblock In \emph{Innovative Concepts for Agent-Based Systems}, pages
  377--390. Springer, 2002.

\bibitem[Gregor et~al.(2015)Gregor, Danihelka, Graves, and
  Wierstra]{gregor2015draw}
K.~Gregor, I.~Danihelka, A.~Graves, and D.~Wierstra.
\newblock Draw: A recurrent neural network for image generation.
\newblock \emph{arXiv preprint arXiv:1502.04623}, 2015.

\bibitem[Courbariaux and Bengio(2016)]{courbariaux2016binarynet}
M.~Courbariaux and Y.~Bengio.
\newblock {BinaryNet}: Training deep neural networks with weights and
  activations constrained to {+1} or {-1}.
\newblock \emph{arXiv preprint arXiv:1602.02830}, 2016.

\bibitem[Hinton and Salakhutdinov(2011)]{hinton2011discovering}
G.~Hinton and R.~Salakhutdinov.
\newblock Discovering binary codes for documents by learning deep generative
  models.
\newblock \emph{Topics in Cognitive Science}, 3\penalty0 (1):\penalty0 74--91,
  2011.

\bibitem[Sutton and Barto(1998)]{SuttonBarto:1998}
R.~S. Sutton and A.~G. Barto.
\newblock \emph{Introduction to reinforcement learning}.
\newblock MIT Press, 1998.

\bibitem[Tampuu et~al.(2015)Tampuu, Matiisen, Kodelja, Kuzovkin, Korjus, Aru,
  Aru, and Vicente]{tampuu2015multiagent}
A.~Tampuu, T.~Matiisen, D.~Kodelja, I.~Kuzovkin, K.~Korjus, J.~Aru, J.~Aru, and
  R.~Vicente.
\newblock Multiagent cooperation and competition with deep reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:1511.08779}, 2015.

\bibitem[Shoham and {Leyton-Brown}(2009)]{MASfoundations09}
Y.~Shoham and K.~{Leyton-Brown}.
\newblock \emph{Multiagent Systems: {Algorithmic}, Game-Theoretic, and Logical
  Foundations}.
\newblock Cambridge University Press, New York, 2009.

\bibitem[Zawadzki et~al.(2014)Zawadzki, Lipson, and
  {Leyton-Brown}]{Zawadzki:2014}
E.~Zawadzki, A.~Lipson, and K.~{Leyton-Brown}.
\newblock Empirically evaluating multiagent learning algorithms.
\newblock \emph{arXiv preprint 1401.8074}, 2014.

\bibitem[Hausknecht and Stone(2015)]{hausknecht2015deep}
M.~Hausknecht and P.~Stone.
\newblock Deep recurrent {Q}-learning for partially observable {MDPs}.
\newblock \emph{arXiv preprint arXiv:1507.06527}, 2015.

\bibitem[Oliehoek et~al.(2008)Oliehoek, Spaan, and Vlassis]{Oliehoek08JAIR}
F.~A. Oliehoek, M.~T.~J. Spaan, and N.~Vlassis.
\newblock Optimal and approximate {Q}-value functions for decentralized
  {POMDPs}.
\newblock \emph{JAIR}, 32:\penalty0 289--353, 2008.

\bibitem[Narasimhan et~al.(2015)Narasimhan, Kulkarni, and
  Barzilay]{narasimhan2015language}
K.~Narasimhan, T.~Kulkarni, and R.~Barzilay.
\newblock Language understanding for text-based games using deep reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:1506.08941}, 2015.

\bibitem[Cho et~al.(2014)Cho, van Merri{\"e}nboer, Bahdanau, and
  Bengio]{cho2014properties}
K.~Cho, B.~van Merri{\"e}nboer, D.~Bahdanau, and Y.~Bengio.
\newblock On the properties of neural machine translation: Encoder-decoder
  approaches.
\newblock \emph{arXiv preprint arXiv:1409.1259}, 2014.

\bibitem[Hochreiter and Schmidhuber(1997)]{hochreiter1997long}
S.~Hochreiter and J.~Schmidhuber.
\newblock Long short-term memory.
\newblock \emph{Neural computation}, 9\penalty0 (8):\penalty0 1735--1780, 1997.

\bibitem[Chung et~al.(2014)Chung, Gulcehre, Cho, and
  Bengio]{chung2014empirical}
J.~Chung, C.~Gulcehre, K.~Cho, and Y.~Bengio.
\newblock Empirical evaluation of gated recurrent neural networks on sequence
  modeling.
\newblock \emph{arXiv preprint arXiv:1412.3555}, 2014.

\bibitem[Jozefowicz et~al.(2015)Jozefowicz, Zaremba, and
  Sutskever]{jozefowicz2015empirical}
R.~Jozefowicz, W.~Zaremba, and I.~Sutskever.
\newblock An empirical exploration of recurrent network architectures.
\newblock In \emph{ICML}, pages 2342--2350, 2015.

\bibitem[Ioffe and Szegedy(2015)]{ioffe2015batch}
S.~Ioffe and C.~Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In \emph{ICML}, pages 448--456, 2015.

\bibitem[Wu(2002)]{wu2002100}
W.~Wu.
\newblock 100 prisoners and a lightbulb.
\newblock Technical report, OCF, UC Berkeley, 2002.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and
  Haffner]{lecun1998gradient}
Y.~LeCun, L.~Bottou, Y.~Bengio, and P.~Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Studdert-Kennedy(2005)]{studdertkennedy05discrete}
M.~Studdert-Kennedy.
\newblock How did language go discrete?
\newblock In M.~Tallerman, editor, \emph{Language Origins: Perspectives on
  Evolution}, chapter~3. Oxford University Press, 2005.

\end{thebibliography}
