\begin{thebibliography}{10}

\bibitem{salimans2016improved}
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and
  Xi~Chen.
\newblock Improved techniques for training gans.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2234--2242, 2016.

\bibitem{metz2016unrolled}
Luke Metz, Ben Poole, David Pfau, and Jascha Sohl-Dickstein.
\newblock Unrolled generative adversarial networks.
\newblock {\em arXiv preprint arXiv:1611.02163}, 2016.

\bibitem{srivastava2014dropout}
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
  Salakhutdinov.
\newblock Dropout: A simple way to prevent neural networks from overfitting.
\newblock {\em The Journal of Machine Learning Research}, 15(1):1929--1958,
  2014.

\bibitem{x2018bourgan}
Chang Xiao, Peilin Zhong, and Changxi Zheng.
\newblock Bourgan: Generative networks with metric embeddings.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2269--2280, 2018.

\bibitem{chen2016infogan}
Xi~Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter
  Abbeel.
\newblock Infogan: Interpretable representation learning by information
  maximizing generative adversarial nets.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2172--2180, 2016.

\bibitem{bowman2016generating}
Samuel~R Bowman, Luke Vilnis, Oriol Vinyals, Andrew Dai, Rafal Jozefowicz, and
  Samy Bengio.
\newblock Generating sentences from a continuous space.
\newblock In {\em Proceedings of The 20th SIGNLL Conference on Computational
  Natural Language Learning}, pages 10--21, 2016.

\bibitem{neumann1928theorie}
J~v Neumann.
\newblock Zur theorie der gesellschaftsspiele.
\newblock {\em Mathematische annalen}, 100(1):295--320, 1928.

\bibitem{du2013minimax}
Ding-Zhu Du and Panos~M Pardalos.
\newblock {\em Minimax and applications}, volume~4.
\newblock Springer Science \& Business Media, 2013.

\bibitem{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In {\em Advances in neural information processing systems}, pages
  2672--2680, 2014.

\bibitem{arjovsky2017wasserstein}
Martin Arjovsky, Soumith Chintala, and L{\'e}on Bottou.
\newblock Wasserstein gan.
\newblock {\em arXiv preprint arXiv:1701.07875}, 2017.

\bibitem{wolpert1997no}
David~H Wolpert, William~G Macready, et~al.
\newblock No free lunch theorems for optimization.
\newblock {\em IEEE transactions on evolutionary computation}, 1(1):67--82,
  1997.

\bibitem{arora2012multiplicative}
Sanjeev Arora, Elad Hazan, and Satyen Kale.
\newblock The multiplicative weights update method: a meta-algorithm and
  applications.
\newblock {\em Theory of Computing}, 8(1):121--164, 2012.

\bibitem{che2016mode}
Tong Che, Yanran Li, Athul~Paul Jacob, Yoshua Bengio, and Wenjie Li.
\newblock Mode regularized generative adversarial networks.
\newblock {\em arXiv preprint arXiv:1612.02136}, 2016.

\bibitem{zhao2016energy}
Junbo Zhao, Michael Mathieu, and Yann LeCun.
\newblock Energy-based generative adversarial network.
\newblock {\em arXiv preprint arXiv:1609.03126}, 2016.

\bibitem{mao2017least}
Xudong Mao, Qing Li, Haoran Xie, Raymond~YK Lau, Zhen Wang, and Stephen~Paul
  Smolley.
\newblock Least squares generative adversarial networks.
\newblock In {\em 2017 IEEE International Conference on Computer Vision
  (ICCV)}, pages 2813--2821. IEEE, 2017.

\bibitem{gulrajani2017improved}
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron~C
  Courville.
\newblock Improved training of wasserstein gans.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  5769--5779, 2017.

\bibitem{saatci2017bayesian}
Yunus Saatci and Andrew~G Wilson.
\newblock Bayesian gan.
\newblock In {\em Advances in neural information processing systems}, pages
  3622--3631, 2017.

\bibitem{heusel2017gans}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp
  Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash
  equilibrium.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6626--6637, 2017.

\bibitem{brock2018large}
Andrew Brock, Jeff Donahue, and Karen Simonyan.
\newblock Large scale gan training for high fidelity natural image synthesis.
\newblock {\em arXiv preprint arXiv:1809.11096}, 2018.

\bibitem{dumoulin2016adversarially}
Vincent Dumoulin, Ishmael Belghazi, Ben Poole, Olivier Mastropietro, Alex Lamb,
  Martin Arjovsky, and Aaron Courville.
\newblock Adversarially learned inference.
\newblock {\em arXiv preprint arXiv:1606.00704}, 2016.

\bibitem{lin2017pacgan}
Zinan Lin, Ashish Khetan, Giulia Fanti, and Sewoong Oh.
\newblock Pacgan: The power of two samples in generative adversarial networks.
\newblock {\em arXiv preprint arXiv:1712.04086}, 2017.

\bibitem{srivastava2017veegan}
Akash Srivastava, Lazar Valkoz, Chris Russell, Michael~U Gutmann, and Charles
  Sutton.
\newblock Veegan: Reducing mode collapse in gans using implicit variational
  learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  3310--3320, 2017.

\bibitem{karras2017progressive}
Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen.
\newblock Progressive growing of gans for improved quality, stability, and
  variation.
\newblock {\em arXiv preprint arXiv:1710.10196}, 2017.

\bibitem{NIPS2018_7846}
Chongxuan Li, Max Welling, Jun Zhu, and Bo~Zhang.
\newblock Graphical generative adversarial networks.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, {\em Advances in Neural Information Processing
  Systems 31}, pages 6072--6083. Curran Associates, Inc., 2018.

\bibitem{locatello2018clustering}
Francesco Locatello, Damien Vincent, Ilya Tolstikhin, Gunnar R{\"a}tsch,
  Sylvain Gelly, and Bernhard Sch{\"o}lkopf.
\newblock Clustering meets implicit generative models.
\newblock {\em arXiv preprint arXiv:1804.11130}, 2018.

\bibitem{arora2017generalization}
Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi~Zhang.
\newblock Generalization and equilibrium in generative adversarial nets (gans).
\newblock {\em arXiv preprint arXiv:1703.00573}, 2017.

\bibitem{hoang2018mgan}
Quan Hoang, Tu~Dinh Nguyen, Trung Le, and Dinh Phung.
\newblock {MGAN}: Training generative adversarial nets with multiple
  generators.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{park2018megan}
David~Keetae Park, Seungjoo Yoo, Hyojin Bahng, Jaegul Choo, and Noseong Park.
\newblock Megan: Mixture of experts of generative adversarial networks for
  multimodal image generation.
\newblock {\em arXiv preprint arXiv:1805.02481}, 2018.

\bibitem{grnarova2017online}
Paulina Grnarova, Kfir~Y Levy, Aurelien Lucchi, Thomas Hofmann, and Andreas
  Krause.
\newblock An online learning approach to generative adversarial networks.
\newblock {\em arXiv preprint arXiv:1706.03269}, 2017.

\bibitem{hazan2016introduction}
Elad Hazan et~al.
\newblock Introduction to online convex optimization.
\newblock {\em Foundations and Trends{\textregistered} in Optimization},
  2(3-4):157--325, 2016.

\bibitem{freund1997decision}
Yoav Freund and Robert~E Schapire.
\newblock A decision-theoretic generalization of on-line learning and an
  application to boosting.
\newblock {\em Journal of computer and system sciences}, 55(1):119--139, 1997.

\bibitem{wang2016ensembles}
Yaxing Wang, Lichao Zhang, and Joost van~de Weijer.
\newblock Ensembles of generative adversarial networks.
\newblock {\em arXiv preprint arXiv:1612.00991}, 2016.

\bibitem{tolstikhin2017adagan}
Ilya~O Tolstikhin, Sylvain Gelly, Olivier Bousquet, Carl-Johann Simon-Gabriel,
  and Bernhard Sch{\"o}lkopf.
\newblock Adagan: Boosting generative models.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  5430--5439, 2017.

\bibitem{grover2018boosted}
Aditya Grover and Stefano Ermon.
\newblock Boosted generative models.
\newblock In {\em Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem{nowozin2016f}
Sebastian Nowozin, Botond Cseke, and Ryota Tomioka.
\newblock f-gan: Training generative neural samplers using variational
  divergence minimization.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  271--279, 2016.

\bibitem{cantelli1933sulla}
Francesco~Paolo Cantelli.
\newblock Sulla determinazione empirica delle leggi di probabilita.
\newblock {\em Giorn. Ist. Ital. Attuari}, 4(421-424), 1933.

\bibitem{amari2016information}
Shun-ichi Amari.
\newblock {\em Information geometry and its applications}.
\newblock Springer, 2016.

\bibitem{barratt2018note}
Shane Barratt and Rishi Sharma.
\newblock A note on the inception score.
\newblock {\em arXiv preprint arXiv:1801.01973}, 2018.

\bibitem{radford2015unsupervised}
Alec Radford, Luke Metz, and Soumith Chintala.
\newblock Unsupervised representation learning with deep convolutional
  generative adversarial networks.
\newblock {\em arXiv preprint arXiv:1511.06434}, 2015.

\bibitem{xiao2017fashion}
Han Xiao, Kashif Rasul, and Roland Vollgraf.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms.
\newblock {\em arXiv preprint arXiv:1708.07747}, 2017.

\bibitem{lecun1998gradient}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock {\em Proceedings of the IEEE}, 86(11):2278--2324, 1998.

\bibitem{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock {\em arXiv preprint arXiv:1312.6114}, 2013.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\end{thebibliography}
