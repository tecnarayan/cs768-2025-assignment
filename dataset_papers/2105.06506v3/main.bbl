\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Adebayo et~al.(2018)Adebayo, Gilmer, Muelly, Goodfellow, Hardt, and
  Kim]{adebayo2018sanity}
Adebayo, J., Gilmer, J., Muelly, M., Goodfellow, I., Hardt, M., and Kim, B.
\newblock Sanity checks for saliency maps.
\newblock \emph{Advances in neural information processing systems},
  31:\penalty0 9505--9515, 2018.

\bibitem[Adebayo et~al.(2020)Adebayo, Muelly, Liccardi, and
  Kim]{adebayo2020debugging}
Adebayo, J., Muelly, M., Liccardi, I., and Kim, B.
\newblock Debugging tests for model explanations.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M.~F., and Lin,
  H. (eds.), \emph{Advances in Neural Information Processing Systems},
  volume~33, pp.\  700--712. Curran Associates, Inc., 2020.

\bibitem[Alber et~al.(2019)Alber, Lapuschkin, Seegerer, H{{\"a}}gele,
  Sch{{\"u}}tt, Montavon, Samek, M{{\"u}}ller, D{{\"a}}hne, and
  Kindermans]{JMLR:v20:18-540}
Alber, M., Lapuschkin, S., Seegerer, P., H{{\"a}}gele, M., Sch{{\"u}}tt, K.~T.,
  Montavon, G., Samek, W., M{{\"u}}ller, K.-R., D{{\"a}}hne, S., and
  Kindermans, P.-J.
\newblock innvestigate neural networks!
\newblock \emph{Journal of Machine Learning Research}, 20\penalty0
  (93):\penalty0 1--8, 2019.

\bibitem[Alvarez~Melis \& Jaakkola(2018)Alvarez~Melis and
  Jaakkola]{alvarez2018}
Alvarez~Melis, D. and Jaakkola, T.
\newblock Towards robust interpretability with self-explaining neural networks.
\newblock In Bengio, S., Wallach, H., Larochelle, H., Grauman, K.,
  Cesa-Bianchi, N., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~31. Curran Associates, Inc., 2018.

\bibitem[Ancona et~al.(2018)Ancona, Ceolini, Öztireli, and
  Gross]{ancona2018towards}
Ancona, M., Ceolini, E., Öztireli, C., and Gross, M.
\newblock Towards better understanding of gradient-based attribution methods
  for deep neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Arun et~al.(2020)Arun, Gaw, Singh, Chang, Aggarwal, Chen, Hoebel,
  Gupta, Patel, Gidwani, et~al.]{arun2020assessing}
Arun, N., Gaw, N., Singh, P., Chang, K., Aggarwal, M., Chen, B., Hoebel, K.,
  Gupta, S., Patel, J., Gidwani, M., et~al.
\newblock Assessing the (un) trustworthiness of saliency maps for localizing
  abnormalities in medical imaging.
\newblock \emph{arXiv preprint arXiv:2008.02766}, 2020.

\bibitem[Bach et~al.(2015)Bach, Binder, Montavon, Klauschen, M{\"u}ller, and
  Samek]{bach2015pixel}
Bach, S., Binder, A., Montavon, G., Klauschen, F., M{\"u}ller, K.-R., and
  Samek, W.
\newblock On pixel-wise explanations for non-linear classifier decisions by
  layer-wise relevance propagation.
\newblock \emph{PloS one}, 10\penalty0 (7):\penalty0 e0130140, 2015.

\bibitem[Chattopadhay et~al.(2018)Chattopadhay, Sarkar, Howlader, and
  Balasubramanian]{chattopadhay2018grad}
Chattopadhay, A., Sarkar, A., Howlader, P., and Balasubramanian, V.~N.
\newblock Grad-cam++: Generalized gradient-based visual explanations for deep
  convolutional networks.
\newblock In \emph{2018 IEEE Winter Conference on Applications of Computer
  Vision (WACV)}, pp.\  839--847. IEEE, 2018.

\bibitem[Everingham et~al.(2015)Everingham, Eslami, Van~Gool, Williams, Winn,
  and Zisserman]{everingham2015pascal}
Everingham, M., Eslami, S.~A., Van~Gool, L., Williams, C.~K., Winn, J., and
  Zisserman, A.
\newblock The pascal visual object classes challenge: A retrospective.
\newblock \emph{International journal of computer vision}, 111\penalty0
  (1):\penalty0 98--136, 2015.

\bibitem[Gao et~al.(2019)Gao, Cheng, Zhao, Zhang, Yang, and
  Torr]{gao2019res2net}
Gao, S., Cheng, M.-M., Zhao, K., Zhang, X.-Y., Yang, M.-H., and Torr, P.~H.
\newblock Res2net: A new multi-scale backbone architecture.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 2019.

\bibitem[Hooker et~al.(2019)Hooker, Erhan, Kindermans, and
  Kim]{hooker2019benchmark}
Hooker, S., Erhan, D., Kindermans, P.-J., and Kim, B.
\newblock A benchmark for interpretability methods in deep neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  9737--9748, 2019.

\bibitem[Kindermans et~al.(2019)Kindermans, Hooker, Adebayo, Alber, Sch{\"u}tt,
  D{\"a}hne, Erhan, and Kim]{kindermans2019reliability}
Kindermans, P.-J., Hooker, S., Adebayo, J., Alber, M., Sch{\"u}tt, K.~T.,
  D{\"a}hne, S., Erhan, D., and Kim, B.
\newblock The (un) reliability of saliency methods.
\newblock In \emph{Explainable AI: Interpreting, Explaining and Visualizing
  Deep Learning}, pp.\  267--280. Springer, 2019.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and Hinton]{alexnet2012}
Krizhevsky, A., Sutskever, I., and Hinton, G.~E.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In Pereira, F., Burges, C. J.~C., Bottou, L., and Weinberger, K.~Q.
  (eds.), \emph{Advances in Neural Information Processing Systems}, volume~25.
  Curran Associates, Inc., 2012.

\bibitem[Liu et~al.(2021)Liu, Khandagale, White, and
  Neiswanger]{liu2021synthetic}
Liu, Y., Khandagale, S., White, C., and Neiswanger, W.
\newblock Synthetic benchmarks for scientific research in explainable machine
  learning.
\newblock In \emph{Thirty-fifth Conference on Neural Information Processing
  Systems Datasets and Benchmarks Track (Round 2)}, 2021.

\bibitem[Lundberg \& Lee(2017)Lundberg and Lee]{lundberg2017unified}
Lundberg, S.~M. and Lee, S.-I.
\newblock A unified approach to interpreting model predictions.
\newblock \emph{Advances in Neural Information Processing Systems},
  30:\penalty0 4765--4774, 2017.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2018towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Montavon et~al.(2017)Montavon, Lapuschkin, Binder, Samek, and
  M{\"u}ller]{montavon2017explaining}
Montavon, G., Lapuschkin, S., Binder, A., Samek, W., and M{\"u}ller, K.-R.
\newblock Explaining nonlinear classification decisions with deep taylor
  decomposition.
\newblock \emph{Pattern Recognition}, 65:\penalty0 211--222, 2017.

\bibitem[Selvaraju et~al.(2017)Selvaraju, Cogswell, Das, Vedantam, Parikh, and
  Batra]{selvaraju2017grad}
Selvaraju, R.~R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., and Batra,
  D.
\newblock Grad-cam: Visual explanations from deep networks via gradient-based
  localization.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pp.\  618--626, 2017.

\bibitem[Shah et~al.(2021)Shah, Jain, and Netrapalli]{shah2021input}
Shah, H., Jain, P., and Netrapalli, P.
\newblock Do input gradients highlight discriminative features?
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Shrikumar et~al.(2017)Shrikumar, Greenside, and
  Kundaje]{shrikumar2017learning}
Shrikumar, A., Greenside, P., and Kundaje, A.
\newblock Learning important features through propagating activation
  differences.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pp.\  3145--3153, 2017.

\bibitem[Simonyan \& Zisserman(2014)Simonyan and Zisserman]{simonyan2014very}
Simonyan, K. and Zisserman, A.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem[Simonyan et~al.(2013)Simonyan, Vedaldi, and
  Zisserman]{simonyan2013deep}
Simonyan, K., Vedaldi, A., and Zisserman, A.
\newblock Deep inside convolutional networks: Visualising image classification
  models and saliency maps, 2013.

\bibitem[Sixt et~al.(2021)Sixt, Schuessler, Popescu, Wei{\ss}, and
  Landgraf]{sixt2021users}
Sixt, L., Schuessler, M., Popescu, O.-I., Wei{\ss}, P., and Landgraf, T.
\newblock Do users benefit from interpretable vision? a user study, baseline,
  and dataset.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Smilkov et~al.(2017)Smilkov, Thorat, Kim, Vi{\'e}gas, and
  Wattenberg]{smilkov2017smoothgrad}
Smilkov, D., Thorat, N., Kim, B., Vi{\'e}gas, F., and Wattenberg, M.
\newblock Smoothgrad: removing noise by adding noise.
\newblock \emph{arXiv preprint arXiv:1706.03825}, 2017.

\bibitem[Springenberg et~al.(2015)Springenberg, Dosovitskiy, Brox, and
  Riedmiller]{springenberg2015striving}
Springenberg, J., Dosovitskiy, A., Brox, T., and Riedmiller, M.
\newblock Striving for simplicity: The all convolutional net.
\newblock In \emph{ICLR (workshop track)}, 2015.

\bibitem[Sundararajan et~al.(2017)Sundararajan, Taly, and
  Yan]{sundararajan2017axiomatic}
Sundararajan, M., Taly, A., and Yan, Q.
\newblock Axiomatic attribution for deep networks.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pp.\  3319--3328, 2017.

\bibitem[Tomsett et~al.(2020)Tomsett, Harborne, Chakraborty, Gurram, and
  Preece]{Tomsett_2020}
Tomsett, R., Harborne, D., Chakraborty, S., Gurram, P., and Preece, A.
\newblock Sanity checks for saliency metrics.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  34\penalty0 (04):\penalty0 6021–6029, Apr 2020.

\bibitem[Wachter et~al.(2017)Wachter, Mittelstadt, and
  Russell]{wachter2017counterfactual}
Wachter, S., Mittelstadt, B., and Russell, C.
\newblock Counterfactual explanations without opening the black box: Automated
  decisions and the gdpr.
\newblock \emph{Harv. JL \& Tech.}, 31:\penalty0 841, 2017.

\bibitem[Wang et~al.(2020)Wang, Wang, Du, Yang, Zhang, Ding, Mardziel, and
  Hu]{wang2020score}
Wang, H., Wang, Z., Du, M., Yang, F., Zhang, Z., Ding, S., Mardziel, P., and
  Hu, X.
\newblock Score-cam: Score-weighted visual explanations for convolutional
  neural networks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition Workshops}, pp.\  24--25, 2020.

\bibitem[Wang et~al.(2019)Wang, Chao, Garg, Hariharan, Campbell, and
  Weinberger]{wang2019pseudo}
Wang, Y., Chao, W.-L., Garg, D., Hariharan, B., Campbell, M., and Weinberger,
  K.~Q.
\newblock Pseudo-lidar from visual depth estimation: Bridging the gap in 3d
  object detection for autonomous driving.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  8445--8453, 2019.

\bibitem[Woo et~al.(2018)Woo, Park, Lee, and Kweon]{woo2018cbam}
Woo, S., Park, J., Lee, J.-Y., and Kweon, I.~S.
\newblock Cbam: Convolutional block attention module.
\newblock In \emph{Proceedings of the European conference on computer vision
  (ECCV)}, pp.\  3--19, 2018.

\bibitem[Yang \& Kim(2019)Yang and Kim]{yang2019benchmarking}
Yang, M. and Kim, B.
\newblock Benchmarking attribution methods with relative feature importance,
  2019.

\bibitem[Zeiler \& Fergus(2014)Zeiler and Fergus]{zeiler2014visualizing}
Zeiler, M.~D. and Fergus, R.
\newblock Visualizing and understanding convolutional networks.
\newblock In \emph{European conference on computer vision}, pp.\  818--833.
  Springer, 2014.

\bibitem[Zhang et~al.(2018)Zhang, Bargal, Lin, Brandt, Shen, and
  Sclaroff]{zhang2018top}
Zhang, J., Bargal, S.~A., Lin, Z., Brandt, J., Shen, X., and Sclaroff, S.
\newblock Top-down neural attention by excitation backprop.
\newblock \emph{International Journal of Computer Vision}, 126\penalty0
  (10):\penalty0 1084--1102, 2018.

\bibitem[Zhou et~al.(2016)Zhou, Khosla, Lapedriza, Oliva, and
  Torralba]{Zhou_2016_CVPR}
Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., and Torralba, A.
\newblock Learning deep features for discriminative localization.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2016.

\bibitem[Zhou et~al.(2017)Zhou, Lapedriza, Khosla, Oliva, and
  Torralba]{zhou2017places}
Zhou, B., Lapedriza, A., Khosla, A., Oliva, A., and Torralba, A.
\newblock Places: A 10 million image database for scene recognition.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2017.

\bibitem[Zhou et~al.(2022)Zhou, Booth, Ribeiro, and Shah]{zhou2022feature}
Zhou, Y., Booth, S., Ribeiro, M.~T., and Shah, J.
\newblock Do feature attribution methods correctly attribute features?
\newblock In \emph{Proceedings of the 36th AAAI Conference on Artificial
  Intelligence}. AAAI, Feb 2022.

\end{thebibliography}
