\begin{thebibliography}{10}

\bibitem{lu2011investigating}
Y.~Lu, Q.~Mei, and C.~Zhai, ``Investigating task performance of probabilistic
  topic models: an empirical study of plsa and lda,'' {\em Information
  Retrieval}, vol.~14, no.~2, pp.~178--203, 2011.

\bibitem{subramani2018novel}
S.~Subramani, V.~Sridhar, and K.~Shetty, ``A novel approach of neural topic
  modelling for document clustering,'' in {\em 2018 IEEE Symposium Series on
  Computational Intelligence (SSCI)}, pp.~2169--2173, IEEE, 2018.

\bibitem{tuan2020capturing}
L.~A. Tuan, D.~Shah, and R.~Barzilay, ``Capturing greater context for question
  generation,'' in {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, vol.~34, pp.~9065--9072, 2020.

\bibitem{wang2019open}
R.~Wang, D.~Zhou, and Y.~He, ``Open event extraction from online text using a
  generative adversarial network,'' {\em arXiv preprint arXiv:1908.09246},
  2019.

\bibitem{wang2021pandemic}
M.~Wang and P.~Mengoni, ``How pandemic spread in news: Text analysis using
  topic model,'' {\em arXiv preprint arXiv:2102.04205}, 2021.

\bibitem{nguyen2021enriching}
T.~Nguyen, A.~T. Luu, T.~Lu, and T.~Quan, ``Enriching and controlling global
  semantics for text summarization,'' {\em arXiv preprint arXiv:2109.10616},
  2021.

\bibitem{blei2003latent}
D.~M. Blei, A.~Y. Ng, and M.~I. Jordan, ``Latent dirichlet allocation,'' {\em
  the Journal of machine Learning research}, vol.~3, pp.~993--1022, 2003.

\bibitem{miao2017discovering}
Y.~Miao, E.~Grefenstette, and P.~Blunsom, ``Discovering discrete latent topics
  with neural variational inference,'' in {\em International Conference on
  Machine Learning}, pp.~2410--2419, PMLR, 2017.

\bibitem{srivastava2017autoencoding}
A.~Srivastava and C.~Sutton, ``Autoencoding variational inference for topic
  models,'' {\em arXiv preprint arXiv:1703.01488}, 2017.

\bibitem{wang2019atm}
R.~Wang, D.~Zhou, and Y.~He, ``Atm: Adversarial-neural topic model,'' {\em
  Information Processing \& Management}, vol.~56, no.~6, p.~102098, 2019.

\bibitem{wang2020neural}
R.~Wang, X.~Hu, D.~Zhou, Y.~He, Y.~Xiong, C.~Ye, and H.~Xu, ``Neural topic
  modeling with bidirectional adversarial training,'' {\em arXiv preprint
  arXiv:2004.12331}, 2020.

\bibitem{hu2020neural}
X.~Hu, R.~Wang, D.~Zhou, and Y.~Xiong, ``Neural topic modeling with
  cycle-consistent adversarial training,'' {\em arXiv preprint
  arXiv:2009.13971}, 2020.

\bibitem{nan2019topic}
F.~Nan, R.~Ding, R.~Nallapati, and B.~Xiang, ``Topic modeling with wasserstein
  autoencoders,'' {\em arXiv preprint arXiv:1907.12374}, 2019.

\bibitem{blum1998combining}
A.~Blum and T.~Mitchell, ``Combining labeled and unlabeled data with
  co-training,'' in {\em Proceedings of the eleventh annual conference on
  Computational learning theory}, pp.~92--100, 1998.

\bibitem{xu2013survey}
C.~Xu, D.~Tao, and C.~Xu, ``A survey on multi-view learning,'' {\em arXiv
  preprint arXiv:1304.5634}, 2013.

\bibitem{bachman2019learning}
P.~Bachman, R.~D. Hjelm, and W.~Buchwalter, ``Learning representations by
  maximizing mutual information across views,'' {\em arXiv preprint
  arXiv:1906.00910}, 2019.

\bibitem{chen2020simple}
T.~Chen, S.~Kornblith, M.~Norouzi, and G.~Hinton, ``A simple framework for
  contrastive learning of visual representations,'' in {\em International
  conference on machine learning}, pp.~1597--1607, PMLR, 2020.

\bibitem{tian2020makes}
Y.~Tian, C.~Sun, B.~Poole, D.~Krishnan, C.~Schmid, and P.~Isola, ``What makes
  for good views for contrastive learning,'' {\em arXiv preprint
  arXiv:2005.10243}, 2020.

\bibitem{card2017neural}
D.~Card, C.~Tan, and N.~A. Smith, ``Neural models for documents with
  metadata,'' {\em arXiv preprint arXiv:1705.09296}, 2017.

\bibitem{chuang2020debiased}
C.-Y. Chuang, J.~Robinson, L.~Yen-Chen, A.~Torralba, and S.~Jegelka, ``Debiased
  contrastive learning,'' {\em arXiv preprint arXiv:2007.00224}, 2020.

\bibitem{robinson2020contrastive}
J.~Robinson, C.-Y. Chuang, S.~Sra, and S.~Jegelka, ``Contrastive learning with
  hard negative samples,'' {\em arXiv preprint arXiv:2010.04592}, 2020.

\bibitem{chen2020big}
T.~Chen, S.~Kornblith, K.~Swersky, M.~Norouzi, and G.~Hinton, ``Big
  self-supervised models are strong semi-supervised learners,'' {\em arXiv
  preprint arXiv:2006.10029}, 2020.

\bibitem{tian2019contrastive}
Y.~Tian, D.~Krishnan, and P.~Isola, ``Contrastive multiview coding,'' {\em
  arXiv preprint arXiv:1906.05849}, 2019.

\bibitem{kingma2013auto}
D.~P. Kingma and M.~Welling, ``Auto-encoding variational bayes,'' {\em arXiv
  preprint arXiv:1312.6114}, 2013.

\bibitem{rezende2014stochastic}
D.~J. Rezende, S.~Mohamed, and D.~Wierstra, ``Stochastic backpropagation and
  approximate inference in deep generative models,'' in {\em International
  conference on machine learning}, pp.~1278--1286, PMLR, 2014.

\bibitem{miao2016neural}
Y.~Miao, L.~Yu, and P.~Blunsom, ``Neural variational inference for text
  processing,'' in {\em International conference on machine learning},
  pp.~1727--1736, PMLR, 2016.

\bibitem{ding2018coherence}
R.~Ding, R.~Nallapati, and B.~Xiang, ``Coherence-aware neural topic modeling,''
  {\em arXiv preprint arXiv:1809.02687}, 2018.

\bibitem{hoyle2020improving}
A.~Hoyle, P.~Goel, and P.~Resnik, ``Improving neural topic models using
  knowledge distillation,'' {\em arXiv preprint arXiv:2010.02377}, 2020.

\bibitem{khosla2020supervised}
P.~Khosla, P.~Teterwak, C.~Wang, A.~Sarna, Y.~Tian, P.~Isola, A.~Maschinot,
  C.~Liu, and D.~Krishnan, ``Supervised contrastive learning,'' {\em arXiv
  preprint arXiv:2004.11362}, 2020.

\bibitem{hjelm2018learning}
R.~D. Hjelm, A.~Fedorov, S.~Lavoie-Marchildon, K.~Grewal, P.~Bachman,
  A.~Trischler, and Y.~Bengio, ``Learning deep representations by mutual
  information estimation and maximization,'' {\em arXiv preprint
  arXiv:1808.06670}, 2018.

\bibitem{xie2021detco}
E.~Xie, J.~Ding, W.~Wang, X.~Zhan, H.~Xu, Z.~Li, and P.~Luo, ``Detco:
  Unsupervised contrastive learning for object detection,'' {\em arXiv preprint
  arXiv:2102.04803}, 2021.

\bibitem{sun2021fsce}
B.~Sun, B.~Li, S.~Cai, Y.~Yuan, and C.~Zhang, ``Fsce: Few-shot object detection
  via contrastive proposal encoding,'' {\em arXiv preprint arXiv:2103.05950},
  2021.

\bibitem{amrani2019learning}
E.~Amrani, R.~Ben-Ari, T.~Hakim, and A.~Bronstein, ``Learning to detect and
  retrieve objects from unlabeled videos,'' in {\em 2019 IEEE/CVF International
  Conference on Computer Vision Workshop (ICCVW)}, pp.~3713--3717, IEEE, 2019.

\bibitem{zhao2020contrastive}
X.~Zhao, R.~Vemulapalli, P.~Mansfield, B.~Gong, B.~Green, L.~Shapira, and
  Y.~Wu, ``Contrastive learning for label-efficient semantic segmentation,''
  {\em arXiv preprint arXiv:2012.06985}, 2020.

\bibitem{chaitanya2020contrastive}
K.~Chaitanya, E.~Erdil, N.~Karani, and E.~Konukoglu, ``Contrastive learning of
  global and local features for medical image segmentation with limited
  annotations,'' {\em arXiv preprint arXiv:2006.10511}, 2020.

\bibitem{ke2021universal}
T.-W. Ke, J.-J. Hwang, and S.~X. Yu, ``Universal weakly supervised segmentation
  by pixel-to-segment contrastive learning,'' {\em arXiv preprint
  arXiv:2105.00957}, 2021.

\bibitem{ho2020contrastive}
C.-H. Ho and N.~Vasconcelos, ``Contrastive learning with adversarial
  examples,'' {\em arXiv preprint arXiv:2010.12050}, 2020.

\bibitem{miyato2018virtual}
T.~Miyato, S.-i. Maeda, M.~Koyama, and S.~Ishii, ``Virtual adversarial
  training: a regularization method for supervised and semi-supervised
  learning,'' {\em IEEE transactions on pattern analysis and machine
  intelligence}, vol.~41, no.~8, pp.~1979--1993, 2018.

\bibitem{kim2020adversarial}
M.~Kim, J.~Tack, and S.~J. Hwang, ``Adversarial self-supervised contrastive
  learning,'' {\em arXiv preprint arXiv:2006.07589}, 2020.

\bibitem{you2020graph}
Y.~You, T.~Chen, Y.~Sui, T.~Chen, Z.~Wang, and Y.~Shen, ``Graph contrastive
  learning with augmentations,'' {\em Advances in Neural Information Processing
  Systems}, vol.~33, 2020.

\bibitem{sun2019infograph}
F.-Y. Sun, J.~Hoffmann, V.~Verma, and J.~Tang, ``Infograph: Unsupervised and
  semi-supervised graph-level representation learning via mutual information
  maximization,'' {\em arXiv preprint arXiv:1908.01000}, 2019.

\bibitem{li2019graph}
Y.~Li, C.~Gu, T.~Dullien, O.~Vinyals, and P.~Kohli, ``Graph matching networks
  for learning the similarity of graph structured objects,'' in {\em
  International Conference on Machine Learning}, pp.~3835--3845, PMLR, 2019.

\bibitem{hassani2020contrastive}
K.~Hassani and A.~H. Khasahmadi, ``Contrastive multi-view representation
  learning on graphs,'' in {\em International Conference on Machine Learning},
  pp.~4116--4126, PMLR, 2020.

\bibitem{logeswaran2018efficient}
L.~Logeswaran and H.~Lee, ``An efficient framework for learning sentence
  representations,'' {\em arXiv preprint arXiv:1803.02893}, 2018.

\bibitem{oord2018representation}
A.~v.~d. Oord, Y.~Li, and O.~Vinyals, ``Representation learning with
  contrastive predictive coding,'' {\em arXiv preprint arXiv:1807.03748}, 2018.

\bibitem{henaff2020data}
O.~Henaff, ``Data-efficient image recognition with contrastive predictive
  coding,'' in {\em International Conference on Machine Learning},
  pp.~4182--4192, PMLR, 2020.

\bibitem{jin2018unsupervised}
S.~Jin, A.~RoyChowdhury, H.~Jiang, A.~Singh, A.~Prasad, D.~Chakraborty, and
  E.~Learned-Miller, ``Unsupervised hard example mining from videos for
  improved object detection,'' in {\em Proceedings of the European Conference
  on Computer Vision (ECCV)}, pp.~307--324, 2018.

\bibitem{kuhn2014nonlinear}
H.~W. Kuhn and A.~W. Tucker, ``Nonlinear programming,'' in {\em Traces and
  emergence of nonlinear programming}, pp.~247--258, Springer, 2014.

\bibitem{karush1939minima}
W.~Karush, ``Minima of functions of several variables with inequalities as side
  constraints,'' {\em M. Sc. Dissertation. Dept. of Mathematics, Univ. of
  Chicago}, 1939.

\bibitem{han2021dual}
J.~Han, M.~Shoeiby, L.~Petersson, and M.~A. Armin, ``Dual contrastive learning
  for unsupervised image-to-image translation,'' {\em arXiv preprint
  arXiv:2104.07689}, 2021.

\bibitem{lang1995newsweeder}
K.~Lang, ``Newsweeder: Learning to filter netnews,'' in {\em Machine Learning
  Proceedings 1995}, pp.~331--339, Elsevier, 1995.

\bibitem{huynh2020otlda}
V.~Huynh, H.~Zhao, and D.~Phung, ``Otlda: A geometry-aware optimal transport
  approach for topic modeling,'' {\em Advances in Neural Information Processing
  Systems}, vol.~33, 2020.

\bibitem{merity2016pointer}
S.~Merity, C.~Xiong, J.~Bradbury, and R.~Socher, ``Pointer sentinel mixture
  models,'' {\em arXiv preprint arXiv:1609.07843}, 2016.

\bibitem{maas2011learning}
A.~Maas, R.~E. Daly, P.~T. Pham, D.~Huang, A.~Y. Ng, and C.~Potts, ``Learning
  word vectors for sentiment analysis,'' in {\em Proceedings of the 49th annual
  meeting of the association for computational linguistics: Human language
  technologies}, pp.~142--150, 2011.

\bibitem{wong1985entropy}
A.~K. Wong and M.~You, ``Entropy and distance of random graphs with application
  to structural pattern recognition,'' {\em IEEE Transactions on Pattern
  Analysis and Machine Intelligence}, no.~5, pp.~599--609, 1985.

\bibitem{lin1991divergence}
J.~Lin, ``Divergence measures based on the shannon entropy,'' {\em IEEE
  Transactions on Information theory}, vol.~37, no.~1, pp.~145--151, 1991.

\end{thebibliography}
