\begin{thebibliography}{10}

\bibitem{agarwal2018learning}
Naman Agarwal, Alon Gonen, and Elad Hazan.
\newblock Learning in non-convex games with an optimization oracle.
\newblock {\em arXiv preprint arXiv:1810.07362}, 2018.

\bibitem{athalye2018obfuscated}
Anish Athalye, Nicholas Carlini, and David Wagner.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock {\em arXiv preprint arXiv:1802.00420}, 2018.

\bibitem{brendel2017decision}
Wieland Brendel, Jonas Rauber, and Matthias Bethge.
\newblock Decision-based adversarial attacks: Reliable attacks against
  black-box machine learning models.
\newblock {\em arXiv preprint arXiv:1712.04248}, 2017.

\bibitem{carlini2017towards}
Nicholas Carlini and David Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In {\em 2017 ieee symposium on security and privacy (sp)}, pages
  39--57. IEEE, 2017.

\bibitem{chen2017zoo}
Pin-Yu Chen, Huan Zhang, Yash Sharma, Jinfeng Yi, and Cho-Jui Hsieh.
\newblock Zoo: Zeroth order optimization based black-box attacks to deep neural
  networks without training substitute models.
\newblock In {\em Proceedings of the 10th ACM Workshop on Artificial
  Intelligence and Security}, pages 15--26, 2017.

\bibitem{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock {\em arXiv preprint arXiv:1810.04805}, 2018.

\bibitem{du2017gradient}
Simon~S Du, Chi Jin, Jason~D Lee, Michael~I Jordan, Aarti Singh, and Barnabas
  Poczos.
\newblock Gradient descent can take exponential time to escape saddle points.
\newblock In {\em Advances in neural information processing systems}, pages
  1067--1077, 2017.

\bibitem{du2018gradient}
Simon~S Du, Xiyu Zhai, Barnabas Poczos, and Aarti Singh.
\newblock Gradient descent provably optimizes over-parameterized neural
  networks.
\newblock {\em arXiv preprint arXiv:1810.02054}, 2018.

\bibitem{gao2019convergence}
Ruiqi Gao, Tianle Cai, Haochuan Li, Liwei Wang, Cho-Jui Hsieh, and Jason~D Lee.
\newblock Convergence of adversarial training in overparametrized networks.
\newblock {\em arXiv preprint arXiv:1906.07916}, 2019.

\bibitem{ge2015escaping}
Rong Ge, Furong Huang, Chi Jin, and Yang Yuan.
\newblock Escaping from saddle pointsâ€”online stochastic gradient for tensor
  decomposition.
\newblock In {\em Conference on Learning Theory}, pages 797--842, 2015.

\bibitem{glorot2010understanding}
Xavier Glorot and Yoshua Bengio.
\newblock Understanding the difficulty of training deep feedforward neural
  networks.
\newblock In {\em Proceedings of the thirteenth international conference on
  artificial intelligence and statistics}, pages 249--256, 2010.

\bibitem{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock {\em arXiv preprint arXiv:1412.6572}, 2014.

\bibitem{guo2017countering}
Chuan Guo, Mayank Rana, Moustapha Cisse, and Laurens Van Der~Maaten.
\newblock Countering adversarial images using input transformations.
\newblock {\em arXiv preprint arXiv:1711.00117}, 2017.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem{ilyas2019adversarial}
Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon
  Tran, and Aleksander Madry.
\newblock Adversarial examples are not bugs, they are features.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  125--136, 2019.

\bibitem{jacot2018neural}
Arthur Jacot, Franck Gabriel, and Cl{\'e}ment Hongler.
\newblock Neural tangent kernel: Convergence and generalization in neural
  networks.
\newblock In {\em Advances in neural information processing systems}, pages
  8571--8580, 2018.

\bibitem{jin2017escape}
Chi Jin, Rong Ge, Praneeth Netrapalli, Sham~M Kakade, and Michael~I Jordan.
\newblock How to escape saddle points efficiently.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 1724--1732. JMLR. org, 2017.

\bibitem{liu2019rob}
Xuanqing Liu and Cho-Jui Hsieh.
\newblock Rob-gan: Generator, discriminator, and adversarial attacker.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 11234--11243, 2019.

\bibitem{madry2017towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock {\em arXiv preprint arXiv:1706.06083}, 2017.

\bibitem{papernot2017practical}
Nicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z~Berkay Celik,
  and Ananthram Swami.
\newblock Practical black-box attacks against machine learning.
\newblock In {\em Proceedings of the 2017 ACM on Asia conference on computer
  and communications security}, pages 506--519, 2017.

\bibitem{shafahi2019adversarial}
Ali Shafahi, Mahyar Najibi, Mohammad~Amin Ghiasi, Zheng Xu, John Dickerson,
  Christoph Studer, Larry~S Davis, Gavin Taylor, and Tom Goldstein.
\newblock Adversarial training for free!
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  3353--3364, 2019.

\bibitem{szegedy2013intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock {\em arXiv preprint arXiv:1312.6199}, 2013.

\bibitem{wang2019convergence}
Yisen Wang, Xingjun Ma, James Bailey, Jinfeng Yi, Bowen Zhou, and Quanquan Gu.
\newblock On the convergence and robustness of adversarial training.
\newblock In {\em International Conference on Machine Learning}, pages
  6586--6595, 2019.

\bibitem{weng2018towards}
Tsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Duane Boning,
  Inderjit~S Dhillon, and Luca Daniel.
\newblock Towards fast computation of certified robustness for relu networks.
\newblock {\em arXiv preprint arXiv:1804.09699}, 2018.

\bibitem{wong2018scaling}
Eric Wong, Frank Schmidt, Jan~Hendrik Metzen, and J~Zico Kolter.
\newblock Scaling provable adversarial defenses.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  8400--8409, 2018.

\bibitem{yin2018rademacher}
Dong Yin, Kannan Ramchandran, and Peter Bartlett.
\newblock Rademacher complexity for adversarially robust generalization.
\newblock {\em arXiv preprint arXiv:1810.11914}, 2018.

\bibitem{zhang2018efficient}
Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel.
\newblock Efficient neural network robustness certification with general
  activation functions.
\newblock In {\em Advances in neural information processing systems}, pages
  4939--4948, 2018.

\end{thebibliography}
