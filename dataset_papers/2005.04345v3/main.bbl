\begin{thebibliography}{39}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Advani \& Saxe(2017)Advani and Saxe]{advani2017high}
Advani, M.~S. and Saxe, A.~M.
\newblock High-dimensional dynamics of generalization error in neural networks.
\newblock \emph{arXiv preprint arXiv:1710.03667}, 2017.

\bibitem[Bartlett et~al.(2019)Bartlett, Long, Lugosi, and
  Tsigler]{bartlett2019benign}
Bartlett, P.~L., Long, P.~M., Lugosi, G., and Tsigler, A.
\newblock Benign overfitting in linear regression.
\newblock \emph{arXiv}, 2019.

\bibitem[Belkin et~al.(2019)Belkin, Hsu, Ma, and Mandal]{belkin2019reconciling}
Belkin, M., Hsu, D., Ma, S., and Mandal, S.
\newblock Reconciling modern machine-learning practice and the classical
  bias--variance trade-off.
\newblock \emph{Science}, 116\penalty0 (32), 2019.

\bibitem[Ben-Tal et~al.(2013)Ben-Tal, den Hertog, Waegenaere, Melenberg, and
  Rennen]{bental2013robust}
Ben-Tal, A., den Hertog, D., Waegenaere, A.~D., Melenberg, B., and Rennen, G.
\newblock Robust solutions of optimization problems affected by uncertain
  probabilities.
\newblock \emph{Management Science}, 59:\penalty0 341--357, 2013.

\bibitem[Blodgett et~al.(2016)Blodgett, Green, and O'Connor]{blodgett2016}
Blodgett, S.~L., Green, L., and O'Connor, B.
\newblock Demographic dialectal variation in social media: A case study of
  {A}frican-{A}merican {E}nglish.
\newblock In \emph{Empirical Methods in Natural Language Processing (EMNLP)},
  pp.\  1119--1130, 2016.

\bibitem[Buda et~al.(2018)Buda, Maki, and Mazurowski]{buda2018systematic}
Buda, M., Maki, A., and Mazurowski, M.~A.
\newblock A systematic study of the class imbalance problem in convolutional
  neural networks.
\newblock \emph{Neural Networks}, 106:\penalty0 249--259, 2018.

\bibitem[Buolamwini \& Gebru(2018)Buolamwini and Gebru]{buolamwini2018gender}
Buolamwini, J. and Gebru, T.
\newblock Gender shades: Intersectional accuracy disparities in commercial
  gender classification.
\newblock In \emph{Conference on Fairness, Accountability and Transparency},
  pp.\  77--91, 2018.

\bibitem[Byrd \& Lipton(2019)Byrd and Lipton]{byrd2019effect}
Byrd, J. and Lipton, Z.
\newblock What is the effect of importance weighting in deep learning?
\newblock In \emph{International Conference on Machine Learning (ICML)}, pp.\
  872--881, 2019.

\bibitem[Cao et~al.(2019)Cao, Wei, Gaidon, Arechiga, and Ma]{cao2019learning}
Cao, K., Wei, C., Gaidon, A., Arechiga, N., and Ma, T.
\newblock Learning imbalanced datasets with label-distribution-aware margin
  loss.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2019.

\bibitem[Cui et~al.(2019)Cui, Jia, Lin, Song, and Belongie]{cui2019class}
Cui, Y., Jia, M., Lin, T., Song, Y., and Belongie, S.
\newblock Class-balanced loss based on effective number of samples.
\newblock In \emph{Computer Vision and Pattern Recognition (CVPR)}, pp.\
  9268--9277, 2019.

\bibitem[Dwork et~al.(2012)Dwork, Hardt, Pitassi, Reingold, and
  Zemel]{dwork2012}
Dwork, C., Hardt, M., Pitassi, T., Reingold, O., and Zemel, R.
\newblock Fairness through awareness.
\newblock In \emph{Innovations in Theoretical Computer Science (ITCS)}, pp.\
  214--226, 2012.

\bibitem[Haixiang et~al.(2017)Haixiang, Yijing, Shang, Mingyun, Yuanyue, and
  Bing]{haixiang2017learning}
Haixiang, G., Yijing, L., Shang, J., Mingyun, G., Yuanyue, H., and Bing, G.
\newblock Learning from class-imbalanced data: Review of methods and
  applications.
\newblock \emph{Expert Systems with Applications}, 73:\penalty0 220--239, 2017.

\bibitem[Hardt et~al.(2016)Hardt, Price, and Srebo]{hardt2016}
Hardt, M., Price, E., and Srebo, N.
\newblock Equality of opportunity in supervised learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pp.\  3315--3323, 2016.

\bibitem[Hashimoto et~al.(2018)Hashimoto, Srivastava, Namkoong, and
  Liang]{hashimoto2018repeated}
Hashimoto, T.~B., Srivastava, M., Namkoong, H., and Liang, P.
\newblock Fairness without demographics in repeated loss minimization.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2018.

\bibitem[Hastie et~al.(2019)Hastie, Montanari, Rosset, and
  Tibshirani]{hastie2019surprises}
Hastie, T., Montanari, A., Rosset, S., and Tibshirani, R.~J.
\newblock Surprises in high-dimensional ridgeless least squares interpolation.
\newblock \emph{arXiv preprint arXiv:1903.08560}, 2019.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016resnet}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Computer Vision and Pattern Recognition (CVPR)}, 2016.

\bibitem[Hendrycks \& Dietterich(2019)Hendrycks and
  Dietterich]{hendrycks2019benchmarking}
Hendrycks, D. and Dietterich, T.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock \emph{arXiv preprint arXiv:1903.12261}, 2019.

\bibitem[Hendrycks et~al.(2019)Hendrycks, Zhao, Basart, Steinhardt, and
  Song]{hendrycks2019natural}
Hendrycks, D., Zhao, K., Basart, S., Steinhardt, J., and Song, D.
\newblock Natural adversarial examples.
\newblock \emph{arXiv preprint arXiv:1907.07174}, 2019.

\bibitem[Hu et~al.(2018)Hu, Niu, Sato, and Sugiyama]{hu2018does}
Hu, W., Niu, G., Sato, I., and Sugiyama, M.
\newblock Does distributionally robust supervised learning give robust
  classifiers?
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2018.

\bibitem[Ioffe \& Szegedy(2015)Ioffe and Szegedy]{ioffe2015batch}
Ioffe, S. and Szegedy, C.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pp.\
  448--456, 2015.

\bibitem[Japkowicz \& Stephen(2002)Japkowicz and Stephen]{japkowicz2002class}
Japkowicz, N. and Stephen, S.
\newblock The class imbalance problem: A systematic study.
\newblock \emph{Intelligent data analysis}, 6\penalty0 (5):\penalty0 429--449,
  2002.

\bibitem[Kleinberg et~al.(2017)Kleinberg, Mullainathan, and
  Raghavan]{kleinberg2017}
Kleinberg, J., Mullainathan, S., and Raghavan, M.
\newblock Inherent trade-offs in the fair determination of risk scores.
\newblock In \emph{Innovations in Theoretical Computer Science (ITCS)}, 2017.

\bibitem[Liu et~al.(2015)Liu, Luo, Wang, and Tang]{liu2015deep}
Liu, Z., Luo, P., Wang, X., and Tang, X.
\newblock Deep learning face attributes in the wild.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  3730--3738, 2015.

\bibitem[McCoy et~al.(2019)McCoy, Pavlick, and Linzen]{mccoy2019right}
McCoy, R.~T., Pavlick, E., and Linzen, T.
\newblock Right for the wrong reasons: Diagnosing syntactic heuristics in
  natural language inference.
\newblock In \emph{Association for Computational Linguistics (ACL)}, 2019.

\bibitem[Mei \& Montanari(2019)Mei and Montanari]{mei2019generalization}
Mei, S. and Montanari, A.
\newblock The generalization error of random features regression: Precise
  asymptotics and double descent curve.
\newblock \emph{arXiv preprint arXiv:1908.05355}, 2019.

\bibitem[Nakkiran et~al.(2019)Nakkiran, Kaplun, Bansal, Yang, Barak, and
  Sutskever]{nakkiran2019deep}
Nakkiran, P., Kaplun, G., Bansal, Y., Yang, T., Barak, B., and Sutskever, I.
\newblock Deep double descent: Where bigger models and more data hurt.
\newblock \emph{arXiv preprint arXiv:1912.02292}, 2019.

\bibitem[Namkoong \& Duchi(2017)Namkoong and Duchi]{namkoong2017variance}
Namkoong, H. and Duchi, J.
\newblock Variance regularization with convex objectives.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2017.

\bibitem[Opper(1995)]{opper1995statistical}
Opper, M.
\newblock Statistical mechanics of learning: Generalization.
\newblock \emph{The Handbook of Brain Theory and Neural Networks,}, pp.\
  922--925, 1995.

\bibitem[Oren et~al.(2019)Oren, Sagawa, Hashimoto, and Liang]{oren2019drolm}
Oren, Y., Sagawa, S., Hashimoto, T., and Liang, P.
\newblock Distributionally robust language modeling.
\newblock In \emph{Empirical Methods in Natural Language Processing (EMNLP)},
  2019.

\bibitem[Rosset et~al.(2004)Rosset, Zhu, and Hastie]{rosset2004margin}
Rosset, S., Zhu, J., and Hastie, T.~J.
\newblock Margin maximizing loss functions.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1237--1244, 2004.

\bibitem[Sagawa et~al.(2020)Sagawa, Koh, Hashimoto, and Liang]{sagawa2020group}
Sagawa, S., Koh, P.~W., Hashimoto, T.~B., and Liang, P.
\newblock Distributionally robust neural networks for group shifts: On the
  importance of regularization for worst-case generalization.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2020.

\bibitem[Shimodaira(2000)]{shimodaira2000improving}
Shimodaira, H.
\newblock Improving predictive inference under covariate shift by weighting the
  log-likelihood function.
\newblock \emph{Journal of Statistical Planning and Inference}, 90:\penalty0
  227--244, 2000.

\bibitem[Soudry et~al.(2018)Soudry, Hoffer, Nacson, Gunasekar, and
  Srebro]{soudry2018implicit}
Soudry, D., Hoffer, E., Nacson, M.~S., Gunasekar, S., and Srebro, N.
\newblock The implicit bias of gradient descent on separable data.
\newblock \emph{Journal of Machine Learning Research (JMLR)}, 19\penalty0
  (1):\penalty0 2822--2878, 2018.

\bibitem[Srivastava et~al.(2014)Srivastava, Hinton, Krizhevsky, Sutskever, and
  Salakhutdinov]{srivastava2014dropout}
Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov,
  R.
\newblock Dropout: A simple way to prevent neural networks from overfitting.
\newblock \emph{Journal of Machine Learning Research (JMLR)}, 15\penalty0
  (1):\penalty0 1929--1958, 2014.

\bibitem[Wah et~al.(2011)Wah, Branson, Welinder, Perona, and
  Belongie]{wah2011cub}
Wah, C., Branson, S., Welinder, P., Perona, P., and Belongie, S.
\newblock The {Caltech}-{UCSD} {Birds}-200-2011 dataset.
\newblock Technical report, California Institute of Technology, 2011.

\bibitem[Wen et~al.(2014)Wen, Yu, and Greiner]{wen2014robust}
Wen, J., Yu, C., and Greiner, R.
\newblock Robust learning under uncertain test distributions: Relating
  covariate shift to model misspecification.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pp.\
  631--639, 2014.

\bibitem[Yang et~al.(2020)Yang, Yu, You, Steinhardt, and
  Ma]{yang2020rethinking}
Yang, Z., Yu, Y., You, C., Steinhardt, J., and Ma, Y.
\newblock Rethinking bias-variance trade-off for generalization of neural
  networks.
\newblock \emph{arXiv preprint arXiv:2002.11328}, 2020.

\bibitem[Zhang et~al.(2017)Zhang, Bengio, Hardt, Recht, and
  Vinyals]{zhang2017understanding}
Zhang, C., Bengio, S., Hardt, M., Recht, B., and Vinyals, O.
\newblock Understanding deep learning requires rethinking generalization.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2017.

\bibitem[Zhou et~al.(2017)Zhou, Lapedriza, Khosla, Oliva, and
  Torralba]{zhou2017places}
Zhou, B., Lapedriza, A., Khosla, A., Oliva, A., and Torralba, A.
\newblock Places: A 10 million image database for scene recognition.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 40\penalty0 (6):\penalty0 1452--1464, 2017.

\end{thebibliography}
