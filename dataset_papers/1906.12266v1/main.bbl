\begin{thebibliography}{43}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Asada et~al.(1996)Asada, Noda, Tawaratsumida, and
  Hosoda]{asada1996purposive}
Minoru Asada, Shoichi Noda, Sukoya Tawaratsumida, and Koh Hosoda.
\newblock Purposive behavior acquisition for a real robot by vision-based
  reinforcement learning.
\newblock \emph{Machine learning}, 23\penalty0 (2-3):\penalty0 279--303, 1996.

\bibitem[Bengio et~al.(2009)Bengio, Louradour, Collobert, and
  Weston]{bengio2009curriculum}
Yoshua Bengio, J{\'e}r{\^o}me Louradour, Ronan Collobert, and Jason Weston.
\newblock Curriculum learning.
\newblock In \emph{Proceedings of the 26th annual international conference on
  machine learning}, pages 41--48. ACM, 2009.

\bibitem[Chaslot et~al.(2008)Chaslot, Winands, HERIK, Uiterwijk, and
  Bouzy]{chaslot2008progressive}
Guillaume M~JB Chaslot, Mark~HM Winands, H~JAAP VAN~DEN HERIK, Jos~WHM
  Uiterwijk, and Bruno Bouzy.
\newblock Progressive strategies for monte-carlo tree search.
\newblock \emph{New Mathematics and Natural Computation}, 4\penalty0
  (03):\penalty0 343--357, 2008.

\bibitem[Colombetti and Dorigo(1992)]{colombetti1992robot}
Marco Colombetti and Marco Dorigo.
\newblock \emph{Robot shaping: developing situated agents through learning}.
\newblock International Computer Science Institute, 1992.

\bibitem[Cou{\"e}toux et~al.(2011)Cou{\"e}toux, Hoock, Sokolovska, Teytaud, and
  Bonnard]{couetoux2011continuous}
Adrien Cou{\"e}toux, Jean-Baptiste Hoock, Nataliya Sokolovska, Olivier Teytaud,
  and Nicolas Bonnard.
\newblock Continuous upper confidence trees.
\newblock In \emph{International Conference on Learning and Intelligent
  Optimization}, pages 433--445. Springer, 2011.

\bibitem[Czarnecki et~al.(2018)Czarnecki, Jayakumar, Jaderberg, Hasenclever,
  Teh, Osindero, Heess, and Pascanu]{czarnecki2018mix}
Wojciech~Marian Czarnecki, Siddhant~M Jayakumar, Max Jaderberg, Leonard
  Hasenclever, Yee~Whye Teh, Simon Osindero, Nicolas Heess, and Razvan Pascanu.
\newblock Mix\&match-agent curricula for reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1806.01780}, 2018.

\bibitem[Elman(1993)]{elman1993learning}
Jeffrey~L Elman.
\newblock Learning and development in neural networks: The importance of
  starting small.
\newblock \emph{Cognition}, 48\penalty0 (1):\penalty0 71--99, 1993.

\bibitem[Espeholt et~al.(2018)Espeholt, Soyer, Munos, Simonyan, Mnih, Ward,
  Doron, Firoiu, Harley, Dunning, et~al.]{espeholt2018impala}
Lasse Espeholt, Hubert Soyer, Remi Munos, Karen Simonyan, Volodymir Mnih, Tom
  Ward, Yotam Doron, Vlad Firoiu, Tim Harley, Iain Dunning, et~al.
\newblock Impala: Scalable distributed deep-rl with importance weighted
  actor-learner architectures.
\newblock \emph{arXiv preprint arXiv:1802.01561}, 2018.

\bibitem[Florensa et~al.(2017)Florensa, Held, Wulfmeier, Zhang, and
  Abbeel]{florensa2017reverse}
Carlos Florensa, David Held, Markus Wulfmeier, Michael Zhang, and Pieter
  Abbeel.
\newblock Reverse curriculum generation for reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1707.05300}, 2017.

\bibitem[Graves et~al.(2017)Graves, Bellemare, Menick, Munos, and
  Kavukcuoglu]{graves2017automated}
Alex Graves, Marc~G Bellemare, Jacob Menick, Remi Munos, and Koray Kavukcuoglu.
\newblock Automated curriculum learning for neural networks.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 1311--1320. JMLR. org, 2017.

\bibitem[Hasselt(2010)]{hasselt2010double}
Hado~V Hasselt.
\newblock Double q-learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2613--2621, 2010.

\bibitem[Hessel et~al.(2018)Hessel, Modayil, Van~Hasselt, Schaul, Ostrovski,
  Dabney, Horgan, Piot, Azar, and Silver]{hessel2018rainbow}
Matteo Hessel, Joseph Modayil, Hado Van~Hasselt, Tom Schaul, Georg Ostrovski,
  Will Dabney, Dan Horgan, Bilal Piot, Mohammad Azar, and David Silver.
\newblock Rainbow: Combining improvements in deep reinforcement learning.
\newblock In \emph{Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem[Jaderberg et~al.(2017)Jaderberg, Dalibard, Osindero, Czarnecki,
  Donahue, Razavi, Vinyals, Green, Dunning, Simonyan,
  et~al.]{jaderberg2017population}
Max Jaderberg, Valentin Dalibard, Simon Osindero, Wojciech~M Czarnecki, Jeff
  Donahue, Ali Razavi, Oriol Vinyals, Tim Green, Iain Dunning, Karen Simonyan,
  et~al.
\newblock Population based training of neural networks.
\newblock \emph{arXiv preprint arXiv:1711.09846}, 2017.

\bibitem[Konidaris and Barto(2006)]{konidaris2006autonomous}
George Konidaris and Andrew Barto.
\newblock Autonomous shaping: Knowledge transfer in reinforcement learning.
\newblock In \emph{Proceedings of the 23rd international conference on Machine
  learning}, pages 489--496. ACM, 2006.

\bibitem[Lee et~al.(2018)Lee, Tang, Zhang, Xu, Darrell, and
  Abbeel]{lee2018modular}
Dennis Lee, Haoran Tang, Jeffrey~O Zhang, Huazhe Xu, Trevor Darrell, and Pieter
  Abbeel.
\newblock Modular architecture for starcraft ii with deep reinforcement
  learning.
\newblock In \emph{Fourteenth Artificial Intelligence and Interactive Digital
  Entertainment Conference}, 2018.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{mnih2015human}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei~A Rusu, Joel Veness,
  Marc~G Bellemare, Alex Graves, Martin Riedmiller, Andreas~K Fidjeland, Georg
  Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529, 2015.

\bibitem[Mnih et~al.(2016)Mnih, Badia, Mirza, Graves, Lillicrap, Harley,
  Silver, and Kavukcuoglu]{mnih2016asynchronous}
Volodymyr Mnih, Adria~Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy
  Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu.
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In \emph{International conference on machine learning}, pages
  1928--1937, 2016.

\bibitem[Moore(1994)]{moore1994parti}
Andrew~W Moore.
\newblock The parti-game algorithm for variable resolution reinforcement
  learning in multidimensional state-spaces.
\newblock In \emph{Advances in neural information processing systems}, pages
  711--718, 1994.

\bibitem[Munos and Moore(2002)]{munos2002variable}
R{\'e}mi Munos and Andrew Moore.
\newblock Variable resolution discretization in optimal control.
\newblock \emph{Machine learning}, 49\penalty0 (2-3):\penalty0 291--323, 2002.

\bibitem[Murali et~al.(2018)Murali, Pinto, Gandhi, and Gupta]{murali2018cassl}
Adithyavairavan Murali, Lerrel Pinto, Dhiraj Gandhi, and Abhinav Gupta.
\newblock Cassl: Curriculum accelerated self-supervised learning.
\newblock In \emph{2018 IEEE International Conference on Robotics and
  Automation (ICRA)}, pages 6453--6460. IEEE, 2018.

\bibitem[Ng et~al.(1999)Ng, Harada, and Russell]{ng1999policy}
Andrew~Y Ng, Daishi Harada, and Stuart Russell.
\newblock Policy invariance under reward transformations: Theory and
  application to reward shaping.
\newblock In \emph{ICML}, volume~99, pages 278--287, 1999.

\bibitem[Pentina et~al.(2015)Pentina, Sharmanska, and
  Lampert]{pentina2015curriculum}
Anastasia Pentina, Viktoriia Sharmanska, and Christoph~H Lampert.
\newblock Curriculum learning of multiple tasks.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 5492--5500, 2015.

\bibitem[Rashid et~al.(2018)Rashid, Samvelyan, de~Witt, Farquhar, Foerster, and
  Whiteson]{rashid2018qmix}
Tabish Rashid, Mikayel Samvelyan, Christian~Schroeder de~Witt, Gregory
  Farquhar, Jakob Foerster, and Shimon Whiteson.
\newblock Qmix: Monotonic value function factorisation for deep multi-agent
  reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1803.11485}, 2018.

\bibitem[Ruder(2017)]{ruder2017overview}
Sebastian Ruder.
\newblock An overview of multi-task learning in deep neural networks.
\newblock \emph{arXiv preprint arXiv:1706.05098}, 2017.

\bibitem[Samvelyan et~al.(2019)Samvelyan, Rashid, de~Witt, Farquhar, Nardelli,
  Rudner, Hung, Torr, Foerster, and Whiteson]{samvelyan2019starcraft}
Mikayel Samvelyan, Tabish Rashid, Christian~Schroeder de~Witt, Gregory
  Farquhar, Nantas Nardelli, Tim~GJ Rudner, Chia-Man Hung, Philip~HS Torr,
  Jakob Foerster, and Shimon Whiteson.
\newblock The starcraft multi-agent challenge.
\newblock 2019.

\bibitem[Selfridge et~al.(1985)Selfridge, Sutton, and
  Barto]{selfridge1985training}
Oliver~G Selfridge, Richard~S Sutton, and Andrew~G Barto.
\newblock Training and tracking in robotics.
\newblock In \emph{IJCAI}, pages 670--672, 1985.

\bibitem[Silver et~al.(2017)Silver, Hubert, Schrittwieser, Antonoglou, Lai,
  Guez, Lanctot, Sifre, Kumaran, Graepel, et~al.]{silver2017mastering}
David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew
  Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore
  Graepel, et~al.
\newblock Mastering chess and shogi by self-play with a general reinforcement
  learning algorithm.
\newblock \emph{arXiv preprint arXiv:1712.01815}, 2017.

\bibitem[Singh(1992)]{singh1992transfer}
Satinder~Pal Singh.
\newblock Transfer of learning by composing solutions of elemental sequential
  tasks.
\newblock \emph{Machine Learning}, 8\penalty0 (3-4):\penalty0 323--339, 1992.

\bibitem[Stanley and Miikkulainen(2004)]{stanley2004competitive}
Kenneth~O Stanley and Risto Miikkulainen.
\newblock Competitive coevolution through evolutionary complexification.
\newblock \emph{Journal of artificial intelligence research}, 21:\penalty0
  63--100, 2004.

\bibitem[Sukhbaatar et~al.(2017)Sukhbaatar, Lin, Kostrikov, Synnaeve, Szlam,
  and Fergus]{sukhbaatar2017intrinsic}
Sainbayar Sukhbaatar, Zeming Lin, Ilya Kostrikov, Gabriel Synnaeve, Arthur
  Szlam, and Rob Fergus.
\newblock Intrinsic motivation and automatic curricula via asymmetric
  self-play.
\newblock \emph{arXiv preprint arXiv:1703.05407}, 2017.

\bibitem[Sunehag et~al.(2017)Sunehag, Lever, Gruslys, Czarnecki, Zambaldi,
  Jaderberg, Lanctot, Sonnerat, Leibo, Tuyls, et~al.]{sunehag2017value}
Peter Sunehag, Guy Lever, Audrunas Gruslys, Wojciech~Marian Czarnecki, Vinicius
  Zambaldi, Max Jaderberg, Marc Lanctot, Nicolas Sonnerat, Joel~Z Leibo, Karl
  Tuyls, et~al.
\newblock Value-decomposition networks for cooperative multi-agent learning.
\newblock \emph{arXiv preprint arXiv:1706.05296}, 2017.

\bibitem[Synnaeve et~al.(2016)Synnaeve, Nardelli, Auvolat, Chintala, Lacroix,
  Lin, Richoux, and Usunier]{synnaeve2016torchcraft}
Gabriel Synnaeve, Nantas Nardelli, Alex Auvolat, Soumith Chintala, Timoth{\'e}e
  Lacroix, Zeming Lin, Florian Richoux, and Nicolas Usunier.
\newblock Torchcraft: a library for machine learning research on real-time
  strategy games.
\newblock \emph{arXiv preprint arXiv:1611.00625}, 2016.

\bibitem[Tamar et~al.(2016)Tamar, Wu, Thomas, Levine, and
  Abbeel]{tamar2016value}
Aviv Tamar, Yi~Wu, Garrett Thomas, Sergey Levine, and Pieter Abbeel.
\newblock Value iteration networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2154--2162, 2016.

\bibitem[Tan(1993)]{tan1993multi}
Ming Tan.
\newblock Multi-agent reinforcement learning: Independent vs. cooperative
  agents.
\newblock In \emph{Proceedings of the tenth international conference on machine
  learning}, pages 330--337, 1993.

\bibitem[Taylor et~al.(2007)Taylor, Stone, and Liu]{taylor2007transfer}
Matthew~E Taylor, Peter Stone, and Yaxin Liu.
\newblock Transfer learning via inter-task mappings for temporal difference
  learning.
\newblock \emph{Journal of Machine Learning Research}, 8\penalty0
  (Sep):\penalty0 2125--2167, 2007.

\bibitem[Tesauro(1995)]{tesauro1995temporal}
Gerald Tesauro.
\newblock Temporal difference learning and td-gammon.
\newblock \emph{Communications of the ACM}, 38\penalty0 (3):\penalty0 58--68,
  1995.

\bibitem[Usunier et~al.(2016)Usunier, Synnaeve, Lin, and
  Chintala]{usunier2016episodic}
Nicolas Usunier, Gabriel Synnaeve, Zeming Lin, and Soumith Chintala.
\newblock Episodic exploration for deep deterministic policies: An application
  to starcraft micromanagement tasks.
\newblock \emph{arXiv preprint arXiv:1609.02993}, 2016.

\bibitem[Vinyals et~al.(2017)Vinyals, Ewalds, Bartunov, Georgiev, Vezhnevets,
  Yeo, Makhzani, K{\"u}ttler, Agapiou, Schrittwieser,
  et~al.]{vinyals2017starcraft}
Oriol Vinyals, Timo Ewalds, Sergey Bartunov, Petko Georgiev, Alexander~Sasha
  Vezhnevets, Michelle Yeo, Alireza Makhzani, Heinrich K{\"u}ttler, John
  Agapiou, Julian Schrittwieser, et~al.
\newblock Starcraft ii: A new challenge for reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1708.04782}, 2017.

\bibitem[Vinyals et~al.(2019)Vinyals, Babuschkin, Chung, Mathieu, Jaderberg,
  Czarnecki, Dudzik, Huang, Georgiev, Powell, Ewalds, Horgan, Kroiss,
  Danihelka, Agapiou, Oh, Dalibard, Choi, Sifre, Sulsky, Vezhnevets, Molloy,
  Cai, Budden, Paine, Gulcehre, Wang, Pfaff, Pohlen, Wu, Yogatama, Cohen,
  McKinney, Smith, Schaul, Lillicrap, Apps, Kavukcuoglu, Hassabis, and
  Silver]{alphastarblog}
Oriol Vinyals, Igor Babuschkin, Junyoung Chung, Michael Mathieu, Max Jaderberg,
  Wojciech~M. Czarnecki, Andrew Dudzik, Aja Huang, Petko Georgiev, Richard
  Powell, Timo Ewalds, Dan Horgan, Manuel Kroiss, Ivo Danihelka, John Agapiou,
  Junhyuk Oh, Valentin Dalibard, David Choi, Laurent Sifre, Yury Sulsky, Sasha
  Vezhnevets, James Molloy, Trevor Cai, David Budden, Tom Paine, Caglar
  Gulcehre, Ziyu Wang, Tobias Pfaff, Toby Pohlen, Yuhuai Wu, Dani Yogatama,
  Julia Cohen, Katrina McKinney, Oliver Smith, Tom Schaul, Timothy Lillicrap,
  Chris Apps, Koray Kavukcuoglu, Demis Hassabis, and David Silver.
\newblock {AlphaStar: Mastering the Real-Time Strategy Game StarCraft II}.
\newblock
  \url{https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/},
  2019.

\bibitem[Wang et~al.(2015)Wang, Schaul, Hessel, Van~Hasselt, Lanctot, and
  De~Freitas]{wang2015dueling}
Ziyu Wang, Tom Schaul, Matteo Hessel, Hado Van~Hasselt, Marc Lanctot, and Nando
  De~Freitas.
\newblock Dueling network architectures for deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1511.06581}, 2015.

\bibitem[Watkins and Dayan(1992)]{watkins1992q}
Christopher~JCH Watkins and Peter Dayan.
\newblock Q-learning.
\newblock \emph{Machine learning}, 8\penalty0 (3-4):\penalty0 279--292, 1992.

\bibitem[Whiteson et~al.(2007)Whiteson, Taylor, Stone,
  et~al.]{whiteson2007adaptive}
Shimon Whiteson, Matthew~E Taylor, Peter Stone, et~al.
\newblock \emph{Adaptive tile coding for value function approximation}.
\newblock Computer Science Department, University of Texas at Austin, 2007.

\bibitem[Zaremba and Sutskever(2014)]{zaremba2014learning}
Wojciech Zaremba and Ilya Sutskever.
\newblock Learning to execute.
\newblock \emph{arXiv preprint arXiv:1410.4615}, 2014.

\end{thebibliography}
