@inproceedings{ng1999policy,
  title={Policy invariance under reward transformations: Theory and application to reward shaping},
  author={Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  booktitle={International Conference on Machine Learning},
  year={1999}
}

@article{abbeel2010autonomous,
  title={Autonomous helicopter aerobatics through apprenticeship learning},
  author={Abbeel, Pieter and Coates, Adam and Ng, Andrew Y},
  journal={The International Journal of Robotics Research},
  year={2010},
}

@article{andrychowicz2020learning,
  title={Learning dexterous in-hand manipulation},
  author={Andrychowicz, OpenAI: Marcin and Baker, Bowen and Chociej, Maciek and Jozefowicz, Rafal and McGrew, Bob and Pachocki, Jakub and Petron, Arthur and Plappert, Matthias and Powell, Glenn and Ray, Alex and others},
  journal={The International Journal of Robotics Research},
  year={2020},
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{pomerleau1991efficient,
  title={Efficient training of artificial neural networks for autonomous navigation},
  author={Pomerleau, Dean A},
  journal={Neural computation},
  year={1991},
  publisher={MIT Press}
}

@inproceedings{ng2000algorithms,
  title={Algorithms for inverse reinforcement learning.},
  author={Ng, Andrew Y and Russell, Stuart J and others},
  booktitle={International Conference on Machine Learning},
  year={2000}
}

@inproceedings{ross2010efficient,
  title={Efficient reductions for imitation learning},
  author={Ross, St{\'e}phane and Bagnell, Drew},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2010}
}

@inproceedings{russell1998learning,
  title={Learning agents for uncertain environments},
  author={Russell, Stuart},
  booktitle={Conference on Computational learning theory},
  year={1998}
}

@inproceedings{ho2016generative,
  title={Generative adversarial imitation learning},
  author={Ho, Jonathan and Ermon, Stefano},
  booktitle={Advances in Neural Information Processing Systems},
  year={2016}
}

@article{kostrikov2018discriminator,
  title={Discriminator-actor-critic: Addressing sample inefficiency and reward bias in adversarial imitation learning},
  author={Kostrikov, Ilya and Agrawal, Kumar Krishna and Dwibedi, Debidatta and Levine, Sergey and Tompson, Jonathan},
  journal={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{fujimoto2018addressing,
  title={Addressing Function Approximation Error in Actor-Critic Methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International Conference on Machine Learning},
  year={2018}
}

@article{ghasemipour2019divergence,
  title={A Divergence Minimization Perspective on Imitation Learning Methods},
  author={Ghasemipour, Seyed Kamyar Seyed and Zemel, Richard and Gu, Shixiang},
  journal={Conference on Robot Learning},
  year={2019}
}

@inproceedings{ziebart2008maximum,
  title={Maximum entropy inverse reinforcement learning.},
  author={Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2008},
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={International Conference on Learning Representations},
  year={2016}
}

@inproceedings{abbeel2004apprenticeship,
  title={Apprenticeship learning via inverse reinforcement learning},
  author={Abbeel, Pieter and Ng, Andrew Y},
  booktitle={International Conference on Machine Learning},
  year={2004}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  year={2015}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={Nature},
  year={2016},
}

@inproceedings{wang2019random,
  title={Random Expert Distillation: Imitation Learning via Expert Policy Support Estimation},
  author={Wang, Ruohan and Ciliberto, Carlo and Amadori, Pierluigi Vito and Demiris, Yiannis},
  booktitle={International Conference on Machine Learning},
  year={2019}
}

@inproceedings{brantley2020disagreement,
  title={Disagreement-regularized imitation learning},
  author={Brantley, Kiant{\'e} and Sun, Wen and Henaff, Mikael},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={International Conference on Intelligent Robots and Systems},
  year={2012},
}

@misc{1606.01540,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@inproceedings{hester2018deep,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2018}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International Conference on Machine Learning},
  year={2015}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={International Conference on Learning Representations},
  year={2015}
}


@article{bishop1994mixture,
  title={Mixture density networks},
  author={Bishop, Christopher M},
  year={1994},
  publisher={Aston University}
}

@article{mandlekar2021matters,
  title={What Matters in Learning from Offline Human Demonstrations for Robot Manipulation},
  author={Mandlekar, Ajay and Xu, Danfei and Wong, Josiah and Nasiriany, Soroush and Wang, Chen and Kulkarni, Rohun and Fei-Fei, Li and Savarese, Silvio and Zhu, Yuke and Mart{\'\i}n-Mart{\'\i}n, Roberto},
  journal={arXiv preprint arXiv:2108.03298},
  year={2021}
}

@article{dadashi2020primal,
  title={Primal wasserstein imitation learning},
  author={Dadashi, Robert and Hussenot, L{\'e}onard and Geist, Matthieu and Pietquin, Olivier},
  journal={International Conference on Learning Representations},
  year={2021}
}

@article{kostrikov2019imitation,
  title={Imitation learning via off-policy distribution matching},
  author={Kostrikov, Ilya and Nachum, Ofir and Tompson, Jonathan},
  journal={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{hussenot2021hyperparameter,
  title={Hyperparameter selection for imitation learning},
  author={Hussenot, L{\'e}onard and Andrychowicz, Marcin and Vincent, Damien and Dadashi, Robert and Raichuk, Anton and Ramos, Sabela and Momchev, Nikola and Girgin, Sertan and Marinier, Raphael and Stafiniak, Lukasz and others},
  booktitle={International Conference on Machine Learning},
  year={2021},
}

@techreport{bushaw1952differential,
  title={Differential equations with a discontinuous forcing term},
  author={Bushaw, Donald W.},
  year={1953},
  institution={Stevens Inst Of Tech Hoboken NJ Experimental Towing Tank}
}


@article{barto2013novelty,
  title={Novelty or surprise?},
  author={Barto, Andrew and Mirolli, Marco and Baldassarre, Gianluca},
  journal={Frontiers in psychology},
  year={2013},
  publisher={Frontiers}
}

@article{bellman,
  title={A Markovian Decision Process},
  author={R. Bellman},
  journal={Indiana University Mathematics Journal},
  year={1957},
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  year={1992},
  publisher={Springer}
}

@article{berner2019dota,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and Dkbiak, Przemyslaw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}

@article{vinyals2019grandmaster,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{bellman1956bang,
  title={On the “bang-bang” control problem},
  author={Bellman, Richard and Glicksberg, Irving and Gross, Oliver},
  journal={Quarterly of Applied Mathematics},
  year={1956}
}

@article{dulac2015deep,
  title={Deep reinforcement learning in large discrete action spaces},
  author={Dulac-Arnold, Gabriel and Evans, Richard and van Hasselt, Hado and Sunehag, Peter and Lillicrap, Timothy and Hunt, Jonathan and Mann, Timothy and Weber, Theophane and Degris, Thomas and Coppin, Ben},
  journal={arXiv preprint arXiv:1512.07679},
  year={2015}
}

@article{metz2017discrete,
  title={Discrete sequential prediction of continuous actions for deep rl},
  author={Metz, Luke and Ibarz, Julian and Jaitly, Navdeep and Davidson, James},
  journal={arXiv preprint arXiv:1705.05035},
  year={2017}
}

@inproceedings{tang2020discretizing,
  title={Discretizing continuous action space for on-policy optimization},
  author={Tang, Yunhao and Agrawal, Shipra},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2020}
}

@inproceedings{tavakoli2018action,
  title={Action branching architectures for deep reinforcement learning},
  author={Tavakoli, Arash and Pardo, Fabio and Kormushev, Petar},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{vieillard2021implicitly,
  title={Implicitly Regularized RL with Implicit Q-Values},
  author={Vieillard, Nino and Andrychowicz, Marcin and Raichuk, Anton and Pietquin, Olivier and Geist, Matthieu},
  journal={arXiv preprint arXiv:2108.07041},
  year={2021}
}


@inproceedings{neunert2020continuous,
  title={Continuous-discrete reinforcement learning for hybrid control in robotics},
  author={Neunert, Michael and Abdolmaleki, Abbas and Wulfmeier, Markus and Lampe, Thomas and Springenberg, Tobias and Hafner, Roland and Romano, Francesco and Buchli, Jonas and Heess, Nicolas and Riedmiller, Martin},
  booktitle={Conference on Robot Learning},
  year={2020},
}

@inproceedings{chernova2007confidence,
  title={Confidence-based policy learning from demonstration using gaussian mixture models},
  author={Chernova, Sonia and Veloso, Manuela},
  booktitle={International Conference on Autonomous Agents and Multiagent Systems},
  year={2007}
}

@inproceedings{calinon2007incremental,
  title={Incremental learning of gestures by imitation in a humanoid robot},
  author={Calinon, Sylvain and Billard, Aude},
  booktitle={ACM/IEEE international conference on Human-robot interaction},
  year={2007}
}

@inproceedings{rahmatizadeh2018virtual,
  title={From virtual demonstration to real-world manipulation using LSTM and MDN},
  author={Rahmatizadeh, Rouhollah and Abolghasemi, Pooya and Behal, Aman and B{\"o}l{\"o}ni, Ladislau},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{yu2018one,
  title={One-shot imitation from observing humans via domain-adaptive meta-learning},
  author={Yu, Tianhe and Finn, Chelsea and Xie, Annie and Dasari, Sudeep and Zhang, Tianhao and Abbeel, Pieter and Levine, Sergey},
  journal={Robotics: Science and Systems},
  year={2018}
}

@article{singh2020parrot,
  title={Parrot: Data-driven behavioral priors for reinforcement learning},
  author={Singh, Avi and Liu, Huihan and Zhou, Gaoyue and Yu, Albert and Rhinehart, Nicholas and Levine, Sergey},
  journal={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{le2018hierarchical,
  title={Hierarchical imitation and reinforcement learning},
  author={Le, Hoang and Jiang, Nan and Agarwal, Alekh and Dud{\'\i}k, Miroslav and Yue, Yisong and Daum{\'e}, Hal},
  booktitle={International Conference on Machine Learning},
  year={2018},
}

@inproceedings{kroemer2015towards,
  title={Towards learning hierarchical skills for multi-phase manipulation tasks},
  author={Kroemer, Oliver and Daniel, Christian and Neumann, Gerhard and Van Hoof, Herke and Peters, Jan},
  booktitle={International Conference on Robotics and Automation},
  year={2015},
  organization={IEEE}
}

@inproceedings{pastor2009learning,
  title={Learning and generalization of motor skills by learning from demonstration},
  author={Pastor, Peter and Hoffmann, Heiko and Asfour, Tamim and Schaal, Stefan},
  booktitle={International Conference on Robotics and Automation},
  year={2009},
  organization={IEEE}
}

@inproceedings{fox2019multi,
  title={Multi-task hierarchical imitation learning for home automation},
  author={Fox, Roy and Berenstein, Ron and Stoica, Ion and Goldberg, Ken},
  booktitle={International Conference on Automation Science and Engineering (CASE)},
  year={2019},
  organization={IEEE}
}

@article{manschitz2015learning,
  title={Learning movement primitive attractor goals and sequential skills from kinesthetic demonstrations},
  author={Manschitz, Simon and Kober, Jens and Gienger, Michael and Peters, Jan},
  journal={Robotics and Autonomous Systems},
  year={2015},
  publisher={Elsevier}
}

@article{ding2019goal,
  title={Goal-conditioned imitation learning},
  author={Ding, Yiming and Florensa, Carlos and Phielipp, Mariano and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  year={2019}
}

@inproceedings{lynch2020learning,
  title={Learning latent plans from play},
  author={Lynch, Corey and Khansari, Mohi and Xiao, Ted and Kumar, Vikash and Tompson, Jonathan and Levine, Sergey and Sermanet, Pierre},
  booktitle={Conference on Robot Learning},
  year={2020},
}

@article{kalashnikov2018qt,
  title={Qt-opt: Scalable deep reinforcement learning for vision-based robotic manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  journal={Conference on Robot Learning},
  year={2018}
}

@article{ryu2019caql,
  title={CAQL: Continuous action Q-learning},
  author={Ryu, Moonkyung and Chow, Yinlam and Anderson, Ross and Tjandraatmadja, Christian and Boutilier, Craig},
  journal={International Conference on Learning Representations},
  year={2020}
}

@article{simmons2019q,
  title={Q-learning for continuous actions with cross-entropy guided policies},
  author={Simmons-Edler, Riley and Eisner, Ben and Mitchell, Eric and Seung, Sebastian and Lee, Daniel},
  journal={arXiv preprint arXiv:1903.10605},
  year={2019}
}

@article{lim2018actor,
  title={Actor-Expert: A Framework for using Q-learning in Continuous Action Spaces},
  author={Lim, Sungsu and Joseph, Ajin and Le, Lei and Pan, Yangchen and White, Martha},
  journal={arXiv preprint arXiv:1810.09103},
  year={2018}
}

@article{tessler2019distributional,
  title={Distributional policy optimization: An alternative approach for continuous control},
  author={Tessler, Chen and Tennenholtz, Guy and Mannor, Shie},
  journal={Advances in Neural Information Processing Systems},
  year={2019}
}

@inproceedings{gu2016continuous,
  title={Continuous deep q-learning with model-based acceleration},
  author={Gu, Shixiang and Lillicrap, Timothy and Sutskever, Ilya and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  year={2016},
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  year={1992},
  publisher={Springer}
}

@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in Neural Information Processing Systems},
  year={2000}
}

@inproceedings{konda2000actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  booktitle={Advances in Neural Information Processing Systems},
  year={2000}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  year={2018},
}

@inproceedings{krishnan2017ddco,
  title={Ddco: Discovery of deep continuous options for robot learning from demonstrations},
  author={Krishnan, Sanjay and Fox, Roy and Stoica, Ion and Goldberg, Ken},
  booktitle={Conference on Robot Learning},
  year={2017},
}

@inproceedings{kipf2019compile,
  title={Compile: Compositional imitation learning and execution},
  author={Kipf, Thomas and Li, Yujia and Dai, Hanjun and Zambaldi, Vinicius and Sanchez-Gonzalez, Alvaro and Grefenstette, Edward and Kohli, Pushmeet and Battaglia, Peter},
  booktitle={International Conference on Machine Learning},
  year={2019},
}

@inproceedings{shankar2019discovering,
  title={Discovering motor programs by recomposing demonstrations},
  author={Shankar, Tanmay and Tulsiani, Shubham and Pinto, Lerrel and Gupta, Abhinav},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{rajeswaran2017learning,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={Robotics: Science and Systems},
  year={2017}
}

@article{vieillard2020munchausen,
  title={Munchausen reinforcement learning},
  author={Vieillard, Nino and Pietquin, Olivier and Geist, Matthieu},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}
@article{schaal1997learning,
  title={Learning from demonstration},
  author={Schaal, Stefan},
  journal={Advances in Neural Information Processing Systems},
  year={1997},
}

@article{bellemare2013arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  year={2013}
}

@article{vecerik2017leveraging,
  title={Leveraging demonstrations for deep reinforcement learning on robotics problems with sparse rewards},
  author={Vecerik, Mel and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1707.08817},
  year={2017}
}

@article{flamary2021pot,
  author  = {R{\'e}mi Flamary and Nicolas Courty and Alexandre Gramfort and Mokhtar Z. Alaya and Aur{\'e}lie Boisbunon and Stanislas Chambon and Laetitia Chapel and Adrien Corenflos and Kilian Fatras and Nemo Fournier and L{\'e}o Gautheron and Nathalie T.H. Gayraud and Hicham Janati and Alain Rakotomamonjy and Ievgen Redko and Antoine Rolet and Antony Schutz and Vivien Seguy and Danica J. Sutherland and Romain Tavenard and Alexander Tong and Titouan Vayer},
  title   = {POT: Python Optimal Transport},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
}

@article{hoffman2020acme,
  title={Acme: A research framework for distributed reinforcement learning},
  author={Hoffman, Matt and Shahriari, Bobak and Aslanides, John and Barth-Maron, Gabriel and Behbahani, Feryal and Norman, Tamara and Abdolmaleki, Abbas and Cassirer, Albin and Yang, Fan and Baumli, Kate and others},
  journal={arXiv preprint arXiv:2006.00979},
  year={2020}
}

@inproceedings{van2016deep,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2016}
}

@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={International Conference on Learning Representations},
  year={2016}
}

@misc{kannan2021robodesk,
  author = {Harini Kannan and Danijar Hafner and Chelsea Finn and Dumitru Erhan},
  title = {RoboDesk: A Multi-Task Reinforcement Learning Benchmark},
  year = {2021},
  howpublished = {\url{https://github.com/google-research/robodesk}},
}

@article{lagoudakis2003least,
  title={Least-squares policy iteration},
  author={Lagoudakis, Michail G and Parr, Ronald},
  journal={The Journal of Machine Learning Research},
  year={2003},
}

@article{browne2012survey,
  title={A survey of monte carlo tree search methods},
  author={Browne, Cameron B and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M and Cowling, Peter I and Rohlfshagen, Philipp and Tavener, Stephen and Perez, Diego and Samothrakis, Spyridon and Colton, Simon},
  journal={IEEE Transactions on Computational Intelligence and AI in games},
  year={2012},
  publisher={IEEE}
}

@inproceedings{brantley2019disagreement,
  title={Disagreement-regularized imitation learning},
  author={Brantley, Kiant{\'e} and Sun, Wen and Henaff, Mikael},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{fujimoto2021minimalist,
  title={A Minimalist Approach to Offline Reinforcement Learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={arXiv preprint arXiv:2106.06860},
  year={2021}
}

@article{wu2019behavior,
  title={Behavior regularized offline reinforcement learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@inproceedings{tang2017exploration,
  title={\# exploration: A study of count-based exploration for deep reinforcement learning},
  author={Tang, Haoran and Houthooft, Rein and Foote, Davis and Stooke, Adam and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{riedmiller2005neural,
  title={Neural fitted Q iteration--first experiences with a data efficient neural reinforcement learning method},
  author={Riedmiller, Martin},
  booktitle={European Conference on Machine Learning},
  year={2005},
  organization={Springer}
}

@book{bertsekas2000dynamic,
  title={Dynamic programming and optimal control},
  author={Bertsekas, Dimitri P},
  year={2000},
  publisher={Athena scientific Belmont}
}

@inproceedings{nair2018overcoming,
  title={Overcoming exploration in reinforcement learning with demonstrations},
  author={Nair, Ashvin and McGrew, Bob and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={IEEE International Conference on Robotics and Automation},
  year={2018},
  organization={IEEE}
}

@article{salimans2018learning,
  title={Learning Montezuma's Revenge from a Single Demonstration},
  author={Salimans, Tim and Chen, Richard},
  journal={arXiv preprint arXiv:1812.03381},
  year={2018}
}

@article{jarrett2020strictly,
  title={Strictly batch imitation learning by energy-based distribution matching},
  author={Jarrett, Daniel and Bica, Ioana and van der Schaar, Mihaela},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@article{florence2021implicit,
  title={Implicit Behavioral Cloning},
  author={Florence, Pete and Lynch, Corey and Zeng, Andy and Ramirez, Oscar and Wahid, Ayzaan and Downs, Laura and Wong, Adrian and Lee, Johnny and Mordatch, Igor and Tompson, Jonathan},
  journal={arXiv preprint arXiv:2109.00137},
  year={2021}
}

@inproceedings{amos2017input,
  title={Input convex neural networks},
  author={Amos, Brandon and Xu, Lei and Kolter, J Zico},
  booktitle={International Conference on Machine Learning},
  year={2017},
}

@inproceedings{asadi2021deep,
  title={Deep radial-basis value functions for continuous control},
  author={Asadi, Kavosh and Parikh, Neev and Parr, Ronald E and Konidaris, George D and Littman, Michael L},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2021}
}

@article{lynch2019play,
  title={Relay Policy Learning: Solving Long Horizon Tasks via Imitation and Reinforcement Learning},
  author={Gupta, Abhishek and Kumar, Vikash and Lynch, Corey and Levine, Sergey and Hausman, Karol},
  journal={Conference on Robot Learning (CoRL)},
  year={2019}
}

@article{orsini2021matters,
  title={What Matters for Adversarial Imitation Learning?},
  author={Orsini, Manu and Raichuk, Anton and Hussenot, L{\'e}onard and Vincent, Damien and Dadashi, Robert and Girgin, Sertan and Geist, Matthieu and Bachem, Olivier and Pietquin, Olivier and Andrychowicz, Marcin},
  journal={arXiv preprint arXiv:2106.00672},
  year={2021}
}

@article{tavakoli2020learning,
  title={Learning to represent action values as a hypergraph on the action vertices},
  author={Tavakoli, Arash and Fatemi, Mehdi and Kormushev, Petar},
  journal={Internation Conference in Learning Representations},
  year={2021}
}


@InProceedings{pmlr-v119-sakryukin20a,
  title = 	 {Inferring {DQN} structure for high-dimensional continuous control},
  author =       {Sakryukin, Andrey and Raissi, Chedy and Kankanhalli, Mohan},
  booktitle = 	 {International Conference on Machine Learning},
  year={2020}
}

@misc{fu2020d4rl,
    title={D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
    author={Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine},
    year={2020},
    eprint={2004.07219},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{haarnoja2018soft2,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{kumar2020conservative,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.04779},
  year={2020}
}

@article{kostrikov2021offline,
  title={Offline reinforcement learning with implicit q-learning},
  author={Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.06169},
  year={2021}
}

@InProceedings{seyde2021bang,
  title={Is Bang-Bang Control All You Need? Solving Continuous Control with Bernoulli Policies},
  author={Seyde, Tim and Gilitschenski, Igor and Schwarting, Wilko and Stellato, Bartolomeo and Riedmiller, Martin and Wulfmeier, Markus and Rus, Daniela},
  booktitle={Advances in Neural Information Processing Systems},
  year={2021}
}

@misc{tassa2020dmcontrol,
    title={dm\_control: Software and Tasks for Continuous Control},
    author={Yuval Tassa and Saran Tunyasuvunakool and Alistair Muldal and
            Yotam Doron and Siqi Liu and Steven Bohez and Josh Merel and
            Tom Erez and Timothy Lillicrap and Nicolas Heess},
    year={2020},
    eprint={2006.12983},
    archivePrefix={arXiv},
    primaryClass={cs.RO}
}
