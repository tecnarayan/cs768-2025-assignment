% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% General bilevel optimization refs
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@book{von2010market,
  title={Market Structure and Equilibrium},
  author={Von Stackelberg, Heinrich},
  year={2010},
  publisher={Springer Science \& Business Media}
}

@article{colson2007overview,
  title={An overview of bilevel optimization},
  author={Colson, Beno{\^\i}t and Marcotte, Patrice and Savard, Gilles},
  journal={Annals of Operations Research},
  volume={153},
  number={1},
  pages={235--256},
  year={2007}
}

@book{bard2013practical,
  title={Practical Bilevel Optimization: Algorithms and Applications},
  author={Bard, Jonathan F},
  volume={30},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@article{sinha2017review,
  title={{A review on bilevel optimization: From classical to evolutionary approaches and applications}},
  author={Sinha, Ankur and Malo, Pekka and Deb, Kalyanmoy},
  journal={IEEE Transactions on Evolutionary Computation},
  volume={22},
  number={2},
  pages={276--295},
  year={2017}
}


%%%%%%%%%%%%%%%%%%%%
% Kaczmarz algorithm
%%%%%%%%%%%%%%%%%%%%
@article{karczmarz1937angenaherte,
  title={{Angenaherte Auflosung von Systemen linearer Gleichungen}},
  author={Karczmarz, S},
  journal={Bull. Int. Acad. Pol. Sic. Let., Cl. Sci. Math. Nat.},
  pages={355--357},
  year={1937}
}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Stackelberg Games
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{fiez2019convergence,
  title={{Convergence of learning dynamics in Stackelberg games}},
  author={Fiez, Tanner and Chasnov, Benjamin and Ratliff, Lillian J},
  journal={arXiv preprint arXiv:1906.01217},
  year={2019}
}

@article{ratliff2021introduction,
  title={An Introduction to Learning in Games},
  author={Ratliff, Lillian},
  journal={Lecture Notes, University of Washington},
  year={2021}
}

@inproceedings{jin2020local,
  title={What is local optimality in nonconvex-nonconcave minimax optimization?},
  author={Jin, Chi and Netrapalli, Praneeth and Jordan, Michael},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={4880--4889},
  year={2020}
}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% IRM
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{arjovsky2019invariant,
  title={Invariant risk minimization},
  author={Arjovsky, Martin and Bottou, L{\'e}on and Gulrajani, Ishaan and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1907.02893},
  year={2019}
}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Differentiation through unrolling
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{maclaurin2015gradient,
  title={Gradient-based hyperparameter optimization through reversible learning},
  author={Maclaurin, Dougal and Duvenaud, David and Adams, Ryan},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={2113--2122},
  year={2015}
}

@inproceedings{domke2012generic,
  title={Generic methods for optimization-based modeling},
  author={Domke, Justin},
  booktitle={Artificial Intelligence and Statistics},
  pages={318--326},
  year={2012}
}

@inproceedings{shaban2019truncated,
  title={Truncated back-propagation for bilevel optimization},
  author={Shaban, Amirreza and Cheng, Ching-An and Hatch, Nathan and Boots, Byron},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={1723--1732},
  year={2019}
}

@inproceedings{franceschi2017forward,
  title={Forward and reverse gradient-based hyperparameter optimization},
  author={Franceschi, Luca and Donini, Michele and Frasconi, Paolo and Pontil, Massimiliano},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017}
}

@inproceedings{luketina2016scalable,
  title={Scalable gradient-based tuning of continuous regularization hyperparameters},
  author={Luketina, Jelena and Berglund, Mathias and Greff, Klaus and Raiko, Tapani},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={2952--2960},
  year={2016}
}

@inproceedings{andrychowicz2016learning,
  title={Learning to learn by gradient descent by gradient descent},
  author={Andrychowicz, Marcin and Denil, Misha and Gomez, Sergio and Hoffman, Matthew W and Pfau, David and Schaul, Tom and Shillingford, Brendan and De Freitas, Nando},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={3981--3989},
  year={2016}
}

@inproceedings{wu2018understanding,
  title={Understanding short-horizon bias in stochastic meta-optimization},
  author={Wu, Yuhuai and Ren, Mengye and Liao, Renjie and Grosse, Roger},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2018}
}

@inproceedings{fu2016drmad,
  title={{DrMAD: Distilling reverse-mode automatic differentiation for optimizing hyperparameters of deep neural networks}},
  author={Fu, Jie and Luo, Hongyin and Feng, Jiashi and Low, Kian Hsiang and Chua, Tat-Seng},
  booktitle={International Joint Conference on Artificial Intelligence (IJCAI)},
  year={2016}
}



% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Neural architecture search (NAS)
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{stanley2002evolving,
  title={Evolving neural networks through augmenting topologies},
  author={Stanley, Kenneth O and Miikkulainen, Risto},
  journal={Evolutionary Computation},
  volume={10},
  number={2},
  pages={99--127},
  year={2002}
}

@inproceedings{zoph2016neural,
  title={Neural architecture search with reinforcement learning},
  author={Zoph, Barret and Le, Quoc V},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2017}
}

@inproceedings{baker2016designing,
  title={Designing neural network architectures using reinforcement learning},
  author={Baker, Bowen and Gupta, Otkrist and Naik, Nikhil and Raskar, Ramesh},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2017}
}

@inproceedings{zoph2018learning,
  title={Learning transferable architectures for scalable image recognition},
  author={Zoph, Barret and Vasudevan, Vijay and Shlens, Jonathon and Le, Quoc V},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={8697--8710},
  year={2018}
}

@inproceedings{liu2018progressive,
  title={Progressive neural architecture search},
  author={Liu, Chenxi and Zoph, Barret and Neumann, Maxim and Shlens, Jonathon and Hua, Wei and Li, Li-Jia and Fei-Fei, Li and Yuille, Alan and Huang, Jonathan and Murphy, Kevin},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={19--34},
  year={2018}
}

@inproceedings{pham2018efficient,
  title={Efficient neural architecture search via parameters sharing},
  author={Pham, Hieu and Guan, Melody and Zoph, Barret and Le, Quoc and Dean, Jeff},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={4095--4104},
  year={2018}
}

@inproceedings{bender2018understanding,
  title={Understanding and simplifying one-shot architecture search},
  author={Bender, Gabriel and Kindermans, Pieter-Jan and Zoph, Barret and Vasudevan, Vijay and Le, Quoc},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={550--559},
  year={2018}
}

@inproceedings{liu2018darts,
  title={{DARTS: Differentiable architecture search}},
  author={Liu, Hanxiao and Simonyan, Karen and Yang, Yiming},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2019}
}

@inproceedings{xie2018snas,
  title={{SNAS: Stochastic neural architecture search}},
  author={Xie, Sirui and Zheng, Hehui and Liu, Chunxiao and Lin, Liang},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2019}
}

@inproceedings{cai2018proxylessnas,
  title={{ProxylessNAS: Direct neural architecture search on target task and hardware}},
  author={Cai, Han and Zhu, Ligeng and Han, Song},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2019}
}

@inproceedings{real2019regularized,
  title={Regularized evolution for image classifier architecture search},
  author={Real, Esteban and Aggarwal, Alok and Huang, Yanping and Le, Quoc V},
  booktitle={AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={4780--4789},
  year={2019}
}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%
% Reinforcement Learning (RL)
% %%%%%%%%%%%%%%%%%%%%%%%%%%%
@incollection{littman1994markov,
  title={Markov games as a framework for multi-agent reinforcement learning},
  author={Littman, Michael L},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={157--163},
  year={1994}
}


% %%%%%%%%%%%%%%%%%%%%%
% Proximal optimization
% %%%%%%%%%%%%%%%%%%%%%
@article{parikh2014proximal,
  title={Proximal algorithms},
  author={Parikh, Neal and Boyd, Stephen},
  journal={Foundations and Trends in Optimization},
  volume={1},
  number={3},
  pages={127--239},
  year={2014}
}

@inproceedings{farnia2020gans,
  title={{Do GANs always have Nash equilibria?}},
  author={Farnia, Farzan and Ozdaglar, Asuman},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020}
}


% %%%%%%%%%%%%%%%%%%%%%%%%
% Implicit differentiation
% %%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{larsen1996design,
  title={{Design and regularization of neural networks: The optimal use of a validation set}},
  author={Larsen, Jan and Hansen, Lars Kai and Svarer, Claus and Ohlsson, M},
  booktitle={IEEE Signal Processing Society Workshop},
  pages={62--71},
  year={1996}
}

@article{bengio2000gradient,
  title={Gradient-based optimization of hyperparameters},
  author={Bengio, Yoshua},
  journal={Neural Computation},
  volume={12},
  number={8},
  pages={1889--1900},
  year={2000}
}

@inproceedings{lorraine2020optimizing,
  title={Optimizing millions of hyperparameters by implicit differentiation},
  author={Lorraine, Jonathan and Vicol, Paul and Duvenaud, David},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={1540--1552},
  year={2020}
}

@article{blondel2021efficient,
  title={Efficient and Modular Implicit Differentiation},
  author={Blondel, Mathieu and Berthet, Quentin and Cuturi, Marco and Frostig, Roy and Hoyer, Stephan and Llinares-L{\'o}pez, Felipe and Pedregosa, Fabian and Vert, Jean-Philippe},
  journal={arXiv preprint arXiv:2105.15183},
  year={2021}
}

@inproceedings{bertrand2020implicit,
  title={{Implicit differentiation of Lasso-type models for hyperparameter optimization}},
  author={Bertrand, Quentin and Klopfenstein, Quentin and Blondel, Mathieu and Vaiter, Samuel and Gramfort, Alexandre and Salmon, Joseph},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={810--821},
  year={2020}
}

@article{bertrand2021implicit,
  title={Implicit differentiation for fast hyperparameter selection in non-smooth convex learning},
  author={Bertrand, Quentin and Klopfenstein, Quentin and Massias, Mathurin and Blondel, Mathieu and Vaiter, Samuel and Gramfort, Alexandre and Salmon, Joseph},
  journal={arXiv preprint arXiv:2105.01637},
  year={2021}
}


@inproceedings{bai2019deep,
  title={Deep equilibrium models},
  author={Bai, Shaojie and Kolter, J Zico and Koltun, Vladlen},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2019}
}


@article{hataya2020meta,
  title={Meta Approach to Data Augmentation Optimization},
  author={Hataya, Ryuichiro and Zdenek, Jan and Yoshizoe, Kazuki and Nakayama, Hideki},
  journal={arXiv preprint arXiv:2006.07965},
  year={2020}
}

@inproceedings{hataya2020faster,
  title={{Faster Autoaugment: Learning augmentation strategies using backpropagation}},
  author={Hataya, Ryuichiro and Zdenek, Jan and Yoshizoe, Kazuki and Nakayama, Hideki},
  booktitle={European Conference on Computer Vision (ECCV)},
  pages={1--16},
  year={2020}
}

@inproceedings{cubuk2020randaugment,
  title={{RandAugment: Practical automated data augmentation with a reduced search space}},
  author={Cubuk, Ekin D and Zoph, Barret and Shlens, Jonathon and Le, Quoc V},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  pages={702--703},
  year={2020}
}

@inproceedings{cheung2021modals,
  title={{MODALS: Modality-agnostic automated data augmentation in the latent space}},
  author={Cheung, Tsz-Him and Yeung, Dit-Yan},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@article{wengert_1964,
  title={A simple automatic derivative evaluation program},
  author={Wengert, Robert Edwin},
  journal={Communications of the ACM},
  year={1964},
  publisher={ACM New York, NY, USA}
}

@article{franceschi2018bilevel,
  title={Bilevel programming for hyperparameter optimization and meta-learning},
  author={Franceschi, Luca and Frasconi, Paolo and Salzo, Saverio and Grazzi, Riccardo and Pontil, Massimilano},
  journal={arXiv preprint arXiv:1806.04910},
  year={2018}
}

@inproceedings{eriba2019kornia,
  author={Riba, Edgar and Mishkin, Dmytro and Ponsa, Daniel and Rublee, Ethan and Bradski, Gary},
  title     = {{Kornia: An open source differentiable computer vision library for PyTorch}},
  booktitle = {Winter Conference on Applications of Computer Vision},
  year      = {2020},
  url       = {https://arxiv.org/pdf/1910.02190.pdf}
}

@inproceedings{peng2018jointly,
  title={{Jointly optimize data augmentation and network training: Adversarial data augmentation in human pose estimation}},
  author={Peng, Xi and Tang, Zhiqiang and Yang, Fei and Feris, Rogerio S and Metaxas, Dimitris},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={2226--2234},
  year={2018}
}

@inproceedings{mounsaveng2021learning,
  title={Learning data augmentation with online bilevel optimization for image classification},
  author={Mounsaveng, Saypraseuth and Laradji, Issam and Ben Ayed, Ismail and Vazquez, David and Pedersoli, Marco},
  booktitle={Winter Conference on Applications of Computer Vision},
  pages={1691--1700},
  year={2021}
}

@article{gudovskiy2021autodo,
  title={{AutoDO: Robust AutoAugment for biased data with label noise via scalable probabilistic implicit differentiation}},
  author={Gudovskiy, Denis and Rigazio, Luca and Ishizaka, Shun and Kozuka, Kazuki and Tsukizawa, Sotaro},
  journal={arXiv preprint arXiv:2103.05863},
  year={2021}
}

@inproceedings{tang2020onlineaugment,
  title={{OnlineAugment: Online data augmentation with less domain knowledge}},
  author={Tang, Zhiqiang and Gao, Yunhe and Karlinsky, Leonid and Sattigeri, Prasanna and Feris, Rogerio and Metaxas, Dimitris},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2020}
}

@inproceedings{raghu2020teaching,
  title={Teaching with commentaries},
  author={Raghu, Aniruddh and Raghu, Maithra and Kornblith, Simon and Duvenaud, David and Hinton, Geoffrey},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020}
}

@inproceedings{pedregosa2016hyperparameter,
  title={Hyperparameter optimization with approximate gradient},
  author={Pedregosa, Fabian},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2016}
}

@article{jaderberg2017population,
  title={Population based training of neural networks},
  author={Jaderberg, Max and Dalibard, Valentin and Osindero, Simon and Czarnecki, Wojciech M and Donahue, Jeff and Razavi, Ali and Vinyals, Oriol and Green, Tim and Dunning, Iain and Simonyan, Karen and others},
  journal={arXiv preprint arXiv:1711.09846},
  year={2017}
}

@inproceedings{ho2019population,
  title={{Population based augmentation: Efficient learning of augmentation policy schedules}},
  author={Ho, Daniel and Liang, Eric and Chen, Xi and Stoica, Ion and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={2731--2741},
  year={2019}
}



@article{d2008smooth,
  title={Smooth optimization with approximate gradient},
  author={d'Aspremont, Alexandre},
  journal={SIAM Journal on Optimization},
  volume={19},
  number={3},
  pages={1171--1183},
  year={2008}
}

@article{schmidt2011convergence,
  title={Convergence rates of inexact proximal-gradient methods for convex optimization},
  author={Schmidt, Mark and Roux, Nicolas and Bach, Francis},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={24},
  pages={1458--1466},
  year={2011}
}

@inproceedings{chen1999optimal,
  title={Optimal use of regularization and cross-validation in neural network modeling},
  author={Chen, Dingding and Hagan, Martin T},
  booktitle={International Joint Conference on Neural Networks (IJCNN)},
  volume={2},
  pages={1275--1280},
  year={1999}
}

@inproceedings{foo2008efficient,
  title={Efficient multiple hyperparameter learning for log-linear models},
  author={Foo, Chuan-sheng and Do, Chuong B and Ng, Andrew Y},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={377--384},
  year={2008}
}

@article{grazzi2020convergence,
  title={Convergence Properties of Stochastic Hypergradients},
  author={Grazzi, Riccardo and Pontil, Massimiliano and Salzo, Saverio},
  journal={arXiv preprint arXiv:2011.07122},
  year={2020}
}

@inproceedings{grazzi2020iteration,
  title={On the iteration complexity of hypergradient computation},
  author={Grazzi, Riccardo and Franceschi, Luca and Pontil, Massimiliano and Salzo, Saverio},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={3748--3758},
  year={2020}
}

@inproceedings{liao2018reviving,
  title={Reviving and improving recurrent back-propagation},
  author={Liao, Renjie and Xiong, Yuwen and Fetaya, Ethan and Zhang, Lisa and Yoon, KiJung and Pitkow, Xaq and Urtasun, Raquel and Zemel, Richard},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2018}
}




% %%%%%%%%%%%%%%%%%%%%%
% Hypernetwork-based HO
% %%%%%%%%%%%%%%%%%%%%%
@inproceedings{lorraine2018stochastic,
  title={Stochastic hyperparameter optimization through hypernetworks},
  author={Lorraine, Jonathan and Duvenaud, David},
  booktitle={NIPS Meta-Learning Workshop},
  year={2017}
}

@inproceedings{mackay2019self,
  title={{Self-Tuning Networks: Bilevel optimization of hyperparameters using structured best-response functions}},
  author={MacKay, Matthew and Vicol, Paul and Lorraine, Jon and Duvenaud, David and Grosse, Roger},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2019}
}

@article{bae2020delta,
  title={{Delta-STN: Efficient bilevel optimization for neural networks using structured response Jacobians}},
  author={Bae, Juhan and Grosse, Roger},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@inproceedings{ha2016hypernetworks,
  title={Hypernetworks},
  author={Ha, David and Dai, Andrew and Le, Quoc V},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2017}
}

@article{schmidhuber1992learning,
  title={{Learning to control fast-weight memories: An alternative to dynamic recurrent networks}},
  author={Schmidhuber, J{\"u}rgen},
  journal={Neural Computation},
  volume={4},
  number={1},
  pages={131--139},
  year={1992}
}



@article{colson2007overview,
  title={An overview of bilevel optimization},
  author={Colson, Beno{\^\i}t and Marcotte, Patrice and Savard, Gilles},
  journal={Annals of Operations Research},
  volume={153},
  number={1},
  pages={235--256},
  year={2007}
}




@software{jax2018github,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX: Composable transformations of Python+NumPy programs}},
  url = {http://github.com/google/jax},
  version = {0.2.5},
  year = {2018}
}

@inproceedings{wei2020implicit,
  title={The implicit and explicit regularization effects of dropout},
  author={Wei, Colin and Kakade, Sham and Ma, Tengyu},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020}
}

@article{srivastava2014dropout,
  title={{Dropout: A simple way to prevent neural networks from overfitting}},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014}
}


@inproceedings{liu2020generic,
  title={A generic first-order algorithmic framework for bi-level programming beyond lower-level singleton},
  author={Liu, Risheng and Mu, Pan and Yuan, Xiaoming and Zeng, Shangzhi and Zhang, Jin},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={6305--6315},
  year={2020}
}

@article{jeroslow1985polynomial,
  title={The polynomial hierarchy and a simple model for competitive analysis},
  author={Jeroslow, Robert G},
  journal={Mathematical Programming},
  volume={32},
  number={2},
  pages={146--164},
  year={1985}
}

@book{dempe2018bilevel,
  title={Bilevel Optimization: Theory, Algorithms and Applications},
  author={Dempe, Stephan},
  year={2018},
  publisher={TU Bergakademie Freiberg, Fakult{\"a}t f{\"u}r Mathematik und Informatik}
}

@article{liu2021investigating,
  title={{Investigating bi-level optimization for learning and vision from a unified perspective: A survey and beyond}},
  author={Liu, Risheng and Gao, Jiaxin and Zhang, Jin and Meng, Deyu and Lin, Zhouchen},
  journal={arXiv preprint arXiv:2101.11517},
  year={2021}
}

@inproceedings{chen2020flexible,
  title={Flexible Bilevel Image Layer Modeling For Robust Deraining},
  author={Chen, Jian and Mu, Pan and Liu, Risheng and Fan, Xin and Luo, Zhongxuan},
  booktitle={International Conference on Multimedia and Expo (ICME)},
  pages={1--6},
  year={2020}
}

@inproceedings{liubi,
  title={Bi-level Probabilistic Feature Learning for Deformable Image Registration},
  author={Liu, Risheng and Li, Zi and Zhang, Yuxi and Fan, Xin and Luo, Zhongxuan},
  booktitle={International Joint Conference on Artificial Intelligence (IJCAI)},
  pages={723--730},
  year={2020}
}


% =============================================
% Example reweighting (aka curriculum learning)
% =============================================
@article{elman1993learning,
  title={{Learning and development in neural networks: The importance of starting small}},
  author={Elman, Jeffrey L},
  journal={Cognition},
  volume={48},
  number={1},
  pages={71--99},
  year={1993}
}

@inproceedings{bengio2009curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={41--48},
  year={2009}
}

@inproceedings{ren2018learning,
  title={Learning to reweight examples for robust deep learning},
  author={Ren, Mengye and Zeng, Wenyuan and Yang, Bin and Urtasun, Raquel},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={4334--4343},
  year={2018}
}


% INFLUENCE FUNCTIONS
% ===================
@article{hampel1974influence,
  title={The influence curve and its role in robust estimation},
  author={Hampel, Frank R},
  journal={Journal of the American Statistical Association},
  volume={69},
  number={346},
  pages={383--393},
  year={1974}
}

@article{cook1980characterizations,
  title={Characterizations of an empirical influence function for detecting influential cases in regression},
  author={Cook, R Dennis and Weisberg, Sanford},
  journal={Technometrics},
  volume={22},
  number={4},
  pages={495--508},
  year={1980}
}

@article{agarwal2016second,
  title={Second-order stochastic optimization in linear time},
  author={Agarwal, Naman and Bullins, Brian and Hazan, Elad},
  journal={arXiv preprint arXiv:1602.03943},
  year={2016}
}

@article{agarwal2016second1,
  title={Second-order stochastic optimization in linear time},
  author={Agarwal, Naman and Bullins, Brian and Hazan, Elad},
  journal={Journal of Machine Learning Research},
  volume={18},
  pages={1--40},
  year={2017}
}

@inproceedings{koh2017understanding,
  title={Understanding black-box predictions via influence functions},
  author={Koh, Pang Wei and Liang, Percy},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={1885--1894},
  year={2017}
}

@article{koh2018stronger,
  title={Stronger data poisoning attacks break data sanitization defenses},
  author={Koh, Pang Wei and Steinhardt, Jacob and Liang, Percy},
  journal={arXiv preprint arXiv:1811.00741},
  year={2018}
}

@article{koh2019accuracy,
  title={On the accuracy of influence functions for measuring group effects},
  author={Koh, Pang Wei and Ang, Kai-Siang and Teo, Hubert HK and Liang, Percy},
  journal={arXiv preprint arXiv:1905.13289},
  year={2019}
}

@inproceedings{basu2020second,
  title={On Second-Order Group Influence Functions for Black-Box Predictions},
  author={Basu, Samyadeep and You, Xuchen and Feizi, Soheil},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={715--724},
  year={2020}
}

@article{basu2020influence,
  title={Influence functions in deep learning are fragile},
  author={Basu, Samyadeep and Pope, Philip and Feizi, Soheil},
  journal={arXiv preprint arXiv:2006.14651},
  year={2020}
}

@inproceedings{lee2020learning,
  title={Learning augmentation network via influence functions},
  author={Lee, Donghoon and Park, Hyunsin and Pham, Trung and Yoo, Chang D},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={10961--10970},
  year={2020}
}

@article{achille2020lqf,
  title={{LQF: Linear quadratic fine-tuning}},
  author={Achille, Alessandro and Golatkar, Aditya and Ravichandran, Avinash and Polito, Marzia and Soatto, Stefano},
  journal={arXiv preprint arXiv:2012.11140},
  year={2020}
}


% Dataset distillation
% ====================
@article{wang2018dataset,
  title={Dataset distillation},
  author={Wang, Tongzhou and Zhu, Jun-Yan and Torralba, Antonio and Efros, Alexei A},
  journal={arXiv preprint arXiv:1811.10959},
  year={2018}
}

@inproceedings{
zhao2020dataset,
title={Dataset Condensation with Gradient Matching},
author={Bo Zhao and Konda Reddy Mopuri and Hakan Bilen},
booktitle={International Conference on Learning Representations (ICLR)},
year={2021}
}

@article{sucholutsky2020less,
  title={{'Less than one'-shot learning: Learning N classes from M< N samples}},
  author={Sucholutsky, Ilia and Schonlau, Matthias},
  journal={arXiv preprint arXiv:2009.08449},
  year={2020}
}


% Meta-learning
% =============
@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={1126--1135},
  year={2017}
}

@inproceedings{rajeswaran2019meta,
  title={Meta-learning with implicit gradients},
  author={Rajeswaran, Aravind and Finn, Chelsea and Kakade, Sham and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2019}
}


% GANs
% ====
@inproceedings{goodfellow2014generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2014}
}

@inproceedings{pfau2016connecting,
  title={Connecting generative adversarial networks and actor-critic methods},
  author={Pfau, David and Vinyals, Oriol},
  booktitle={NeurIPS Workshop on Adversarial Training},
  year={2016}
}


% Implicit regularization
% =======================
@inproceedings{ali2019continuous,
  title={A continuous-time view of early stopping for least squares regression},
  author={Ali, Alnur and Kolter, J Zico and Tibshirani, Ryan J},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={1370--1378},
  year={2019}
}

@inproceedings{ali2020implicit,
  title={The implicit regularization of stochastic gradient flow for least squares},
  author={Ali, Alnur and Dobriban, Edgar and Tibshirani, Ryan},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={233--244},
  year={2020}
}

@article{morgan1989generalization,
  title={{Generalization and parameter estimation in feedforward nets: Some experiments}},
  author={Morgan, Nelson and Bourlard, Herv{\'e}},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={2},
  pages={630--637},
  year={1989}
}

@article{strand1974theory,
  title={{Theory and methods related to the singular-function expansion and Landweber’s iteration for integral equations of the first kind}},
  author={Strand, Otto Neall},
  journal={SIAM Journal on Numerical Analysis},
  volume={11},
  number={4},
  pages={798--825},
  year={1974}
}

@inproceedings{gunasekar2018implicit,
  title={Implicit regularization in matrix factorization},
  author={Gunasekar, Suriya and Woodworth, Blake and Bhojanapalli, Srinadh and Neyshabur, Behnam and Srebro, Nathan},
  booktitle={Information Theory and Applications Workshop (ITA)},
  pages={1--10},
  year={2018}
}

@inproceedings{gunasekar2018characterizing,
  title={Characterizing implicit bias in terms of optimization geometry},
  author={Gunasekar, Suriya and Lee, Jason and Soudry, Daniel and Srebro, Nathan},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={1832--1841},
  year={2018}
}

@inproceedings{nacson2019stochastic,
  title={{Stochastic gradient descent on separable data: Exact convergence with a fixed learning rate}},
  author={Nacson, Mor Shpigel and Srebro, Nathan and Soudry, Daniel},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={3051--3059},
  year={2019}
}

@article{soudry2018implicit,
  title={The implicit bias of gradient descent on separable data},
  author={Soudry, Daniel and Hoffer, Elad and Nacson, Mor Shpigel and Gunasekar, Suriya and Srebro, Nathan},
  journal={The Journal of Machine Learning Research},
  volume={19},
  number={1},
  pages={2822--2878},
  year={2018}
}

@article{suggala2018connecting,
  title={Connecting optimization and regularization paths},
  author={Suggala, Arun and Prasad, Adarsh and Ravikumar, Pradeep K},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={31},
  pages={10608--10619},
  year={2018}
}

@inproceedings{poggio2019theoretical,
  title={{Theoretical issues in deep networks: Approximation, optimization and generalization}},
  author={Poggio, Tomaso and Banburski, Andrzej and Liao, Qianli},
  booktitle={Proceedings of the National Academy of Sciences},
  year={2019}
}

@inproceedings{ji2019implicit,
  title={The implicit bias of gradient descent on nonseparable data},
  author={Ji, Ziwei and Telgarsky, Matus},
  booktitle={Conference on Learning Theory},
  pages={1772--1798},
  year={2019}
}

@techreport{friedman2003gradient,
  title={Gradient directed regularization for linear regression and classification},
  author={Friedman, Jerome and Popescu, Bogdan E},
  year={2003},
  institution={Statistics Department, Stanford University}
}

@article{yao2007early,
  title={On early stopping in gradient descent learning},
  author={Yao, Yuan and Rosasco, Lorenzo and Caponnetto, Andrea},
  journal={Constructive Approximation},
  volume={26},
  number={2},
  pages={289--315},
  year={2007}
}

@article{razin2020implicit,
  title={Implicit regularization in deep learning may not be explainable by norms},
  author={Razin, Noam and Cohen, Nadav},
  journal={arXiv preprint arXiv:2005.06398},
  year={2020}
}

@article{ji2020bilevel,
  title={{Bilevel optimization: Nonasymptotic analysis and faster algorithms}},
  author={Ji, Kaiyi and Yang, Junjie and Liang, Yingbin},
  journal={arXiv preprint arXiv:2010.07962},
  year={2020}
}



% %%%%%%%%%%%%%%%%%%
% Continual learning
% %%%%%%%%%%%%%%%%%%
@article{pham2020bilevel,
  title={Bilevel Continual Learning},
  author={Pham, Quang and Sahoo, Doyen and Liu, Chenghao and Hoi, Steven CH},
  journal={arXiv preprint arXiv:2007.15553},
  year={2020}
}

@inproceedings{pan2020continual,
  title={Continual deep learning by functional regularisation of memorable past},
  author={Pan, Pingbo and Swaroop, Siddharth and Immer, Alexander and Eschenhagen, Runa and Turner, Richard E and Khan, Mohammad Emtiyaz},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@inproceedings{von2019continual,
  title={Continual learning with hypernetworks},
  author={von Oswald, Johannes and Henning, Christian and Sacramento, Jo{\~a}o and Grewe, Benjamin F},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020}
}

@inproceedings{borsos2020coresets,
  title={Coresets via bilevel optimization for continual learning and streaming},
  author={Borsos, Zal{\'a}n and Mutn{\`y}, Mojm{\'\i}r and Krause, Andreas},
  journal={Neural Information Processing Systems (NeurIPS)},
  year={2020}
}


% %%%%%%%%%%%%%%%%%%%%
% Overparameterization
% %%%%%%%%%%%%%%%%%%%%
@inproceedings{jacot2018neural,
  title={{Neural tangent kernel: Convergence and generalization in neural networks}},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2018}
}

@inproceedings{nakkiran2019deep,
  title={{Deep double descent: Where bigger models and more data hurt}},
  author={Nakkiran, Preetum and Kaplun, Gal and Bansal, Yamini and Yang, Tristan and Barak, Boaz and Sutskever, Ilya},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020}
}

@article{belkin2018reconciling,
  title={Reconciling modern machine-learning practice and the classical bias--variance trade-off},
  author={Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={32},
  pages={15849--15854},
  year={2019}
}

@inproceedings{zhang2016understanding,
  title={Understanding deep learning requires rethinking generalization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2016}
}

@inproceedings{balaji2021understanding,
  title={Understanding overparameterization in generative adversarial networks},
  author={Balaji, Yogesh and Sajedi, Mohammadmahdi and Kalibhat, Neha Mukund and Ding, Mucong and St{\"o}ger, Dominik and Soltanolkotabi, Mahdi and Feizi, Soheil},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@inproceedings{vardi2021implicit,
  title={{Implicit regularization in ReLU networks with the square loss}},
  author={Vardi, Gal and Shamir, Ohad},
  booktitle={Conference on Learning Theory},
  pages={4224--4258},
  year={2021}
}

@article{rasmussen2000occam,
  title={Occam's razor},
  author={Rasmussen, Carl and Ghahramani, Zoubin},
  journal={Advances in neural information processing systems},
  volume={13},
  year={2000}
}

@article{bartlett2020benign,
  title={Benign overfitting in linear regression},
  author={Bartlett, Peter L and Long, Philip M and Lugosi, G{\'a}bor and Tsigler, Alexander},
  journal={Proceedings of the National Academy of Sciences},
  volume={117},
  number={48},
  pages={30063--30070},
  year={2020},
  publisher={National Acad Sciences}
}

@article{amari2020does,
  title={When Does Preconditioning Help or Hurt Generalization?},
  author={Amari, Shun-ichi and Ba, Jimmy and Grosse, Roger and Li, Xuechen and Nitanda, Atsushi and Suzuki, Taiji and Wu, Denny and Xu, Ji},
  journal={arXiv preprint arXiv:2006.10732},
  year={2020}
}

@inproceedings{arora2019fine,
  title={Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks},
  author={Arora, Sanjeev and Du, Simon and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={322--332},
  year={2019},
  organization={PMLR}
}






% %%%%%%%%%%%%%%
% Infinite width
% %%%%%%%%%%%%%%
@article{sohl2020infinite,
  title={On the infinite width limit of neural networks with a standard parameterization},
  author={Sohl-Dickstein, Jascha and Novak, Roman and Schoenholz, Samuel S and Lee, Jaehoon},
  journal={arXiv preprint arXiv:2001.07301},
  year={2020}
}

@inproceedings{lee2019wide,
  title={Wide neural networks of any depth evolve as linear models under gradient descent},
  author={Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel S and Bahri, Yasaman and Novak, Roman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2019}
}

@article{franceschi2021neural,
  title={{A neural tangent kernel perspective of GANs}},
  author={Franceschi, Jean-Yves and de B{\'e}zenac, Emmanuel and Ayed, Ibrahim and Chen, Micka{\"e}l and Lamprier, Sylvain and Gallinari, Patrick},
  journal={arXiv preprint arXiv:2106.05566},
  year={2021}
}


% %%%%%%%%%%%%%%%%%%%
% 
% %%%%%%%%%%%%%%%%%%%
@inproceedings{ba2019generalization,
  title={{Generalization of two-layer neural networks: An asymptotic viewpoint}},
  author={Ba, Jimmy and Erdogdu, Murat and Suzuki, Taiji and Wu, Denny and Zhang, Tianzong},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2019}
}

% %%%%%%%%%%%%%%%%%%%
% UCI Yacht Data
% %%%%%%%%%%%%%%%%%%%
@misc{asuncion2007uci,
  title={{UCI machine learning repository}},
  author={Asuncion, Arthur and Newman, David},
  year={2007},
  publisher={Irvine, CA, USA}
}


@article{pearlmutter1994fast,
  title={{Fast exact multiplication by the Hessian}},
  author={Pearlmutter, Barak A},
  journal={Neural Computation},
  volume={6},
  number={1},
  pages={147--160},
  year={1994}
}


@misc{tensorflow2015-whitepaper,
title={{TensorFlow: Large-scale machine learning on heterogeneous systems}},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{\i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}

@inproceedings{paszke2017automatic,
  title={{Automatic differentiation in PyTorch}},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  booktitle={NIPS Workshop Autodifferentiation},
  year={2017}
}



% %%%%%%%%%%%%%%%%%%%%%%%%%%%
% Projection onto convex sets
% %%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{stovsic2016projection,
  title={Projection on the intersection of convex sets},
  author={Sto{\v{s}}i{\'c}, Marko and Xavier, Jo{\~a}o and Dodig, Marija},
  journal={Linear Algebra and its Applications},
  volume={509},
  pages={191--205},
  year={2016}
}

@article{mishachev2019realization,
  title={On Realization of Limit Polygons in Sequential Projection Method},
  author={Mishachev, NM and Shmyrin, Anatoly Mikhailovich},
  journal={International Transaction Journal of Engineering, Management and Applied Sciences and Technologies},
  volume={10},
  number={15},
  pages={1015--1015},
  year={2019}
}

@article{angelos1998limit,
  title={{Limit cycles for successive projections onto hyperplanes in RN}},
  author={Angelos, James and Grossman, George and Kaufman, Edwin and Lenker, Terry and Rakesh, Leela},
  journal={Linear Algebra and its Applications},
  volume={285},
  number={1-3},
  pages={201--228},
  year={1998}
}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Optimistic and pessimistic BLO
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{dempe2007new,
  title={New necessary optimality conditions in optimistic bilevel programming},
  author={Dempe, S and Dutta, J and Mordukhovich, BS},
  journal={Optimization},
  volume={56},
  number={5-6},
  pages={577--604},
  year={2007}
}

@book{dempe2002foundations,
  title={Foundations of bilevel programming},
  author={Dempe, Stephan},
  year={2002},
  publisher={Springer Science \& Business Media}
}

@article{harker1988existence,
  title={Existence of optimal solutions to mathematical programs with equilibrium constraints},
  author={Harker, Patrick T and Pang, Jong-Shi},
  journal={Operations Research Letters},
  volume={7},
  number={2},
  pages={61--64},
  year={1988}
}

@article{lignola1995topological,
  title={{Topological existence and stability for Stackelberg problems}},
  author={Lignola, Maria Beatrice and Morgan, Jacqueline},
  journal={Journal of Optimization Theory and Applications},
  volume={84},
  number={1},
  pages={145--169},
  year={1995}
}

@incollection{lignola2001existence,
  title={{Existence of solutions to bilevel variational problems in Banach spaces}},
  author={Lignola, Maria Beatrice and Morgan, Jacqueline},
  booktitle={Equilibrium Problems: Nonsmooth Optimization and Variational Inequality Models},
  pages={161--174},
  year={2001},
  publisher={Springer}
}

@article{outrata1993necessary,
  title={{Necessary optimality conditions for Stackelberg problems}},
  author={Outrata, Jiri V},
  journal={Journal of Optimization Theory and Applications},
  volume={76},
  number={2},
  pages={305--320},
  year={1993}
}

% Pessimistic
% %%%%%%%%%%%
@article{dempe2014necessary,
  title={Necessary optimality conditions in pessimistic bilevel programming},
  author={Dempe, Stephan and Mordukhovich, Boris S and Zemkoho, Alain B},
  journal={Optimization},
  volume={63},
  number={4},
  pages={505--533},
  year={2014}
}

@article{loridan1996weak,
  title={{Weak via strong Stackelberg problem: New results}},
  author={Loridan, Pierre and Morgan, Jacqueline},
  journal={Journal of Global Optimization},
  volume={8},
  number={3},
  pages={263--287},
  year={1996}
}

@article{lucchetti1987existence,
  title={{Existence theorems of equilibrium points in Stackelberg games with constraints}},
  author={Lucchetti, Roberto and Mignanego, F and Pieri, G},
  journal={Optimization},
  volume={18},
  number={6},
  pages={857--866},
  year={1987}
}

@article{wiesemann2013pessimistic,
  title={Pessimistic bilevel optimization},
  author={Wiesemann, Wolfram and Tsoukalas, Angelos and Kleniati, Polyxeni-Margarita and Rustem, Ber{\c{c}}},
  journal={SIAM Journal on Optimization},
  volume={23},
  number={1},
  pages={353--380},
  year={2013}
}

@article{liu2018pessimistic,
  title={{Pessimistic bilevel optimization: A survey}},
  author={Liu, June and Fan, Yuxin and Chen, Zhong and Zheng, Yue},
  journal={International Journal of Computational Intelligence Systems},
  volume={11},
  number={1},
  pages={725--736},
  year={2018}
}

@incollection{liu2020methods,
  title={Methods for Pessimistic Bilevel Optimization},
  author={Liu, June and Fan, Yuxin and Chen, Zhong and Zheng, Yue},
  booktitle={Bilevel Optimization},
  pages={403--420},
  year={2020},
  publisher={Springer}
}



% Warm-start bilevel opt
% %%%%%%%%%%%%%%%%%%%%%%
@article{ghadimi2018approximation,
  title={Approximation methods for bilevel programming},
  author={Ghadimi, Saeed and Wang, Mengdi},
  journal={arXiv preprint arXiv:1802.02246},
  year={2018}
}

@article{hong2020two,
  title={{A two-timescale framework for bilevel optimization: Complexity analysis and application to actor-critic}},
  author={Hong, Mingyi and Wai, Hoi-To and Wang, Zhaoran and Yang, Zhuoran},
  journal={arXiv preprint arXiv:2007.05170},
  year={2020}
}


% %%%%%%%%%%%%%%%%%%%%%%
% Cold-start bilevel opt
% %%%%%%%%%%%%%%%%%%%%%%
@inproceedings{metz2019understanding,
  title={Understanding and correcting pathologies in the training of learned optimizers},
  author={Metz, Luke and Maheswaranathan, Niru and Nixon, Jeremy and Freeman, Daniel and Sohl-Dickstein, Jascha},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={4556--4565},
  year={2019}
}

@article{salimans2017evolution,
  title={Evolution strategies as a scalable alternative to reinforcement learning},
  author={Salimans, Tim and Ho, Jonathan and Chen, Xi and Sidor, Szymon and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1703.03864},
  year={2017}
}

@article{micaelli2020non,
  title={Non-greedy gradient-based hyperparameter optimization over long horizons},
  author={Micaelli, Paul and Storkey, Amos},
  journal={arXiv preprint arXiv:2007.07869},
  year={2020}
}



% %%%%%%%%%%%%
% Unrolled GAN
% %%%%%%%%%%%%

@article{metz2016unrolled,
  title={Unrolled generative adversarial networks},
  author={Metz, Luke and Poole, Ben and Pfau, David and Sohl-Dickstein, Jascha},
  journal={arXiv preprint arXiv:1611.02163},
  year={2016}
}


%%%%%%%%%%%%%%%%%
% Theoretical BLO
%%%%%%%%%%%%%%%%%

@inproceedings{ji2021bilevel,
  title={{Bilevel optimization: Convergence analysis and enhanced design}},
  author={Ji, Kaiyi and Yang, Junjie and Liang, Yingbin},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={4882--4892},
  year={2021}
}

@article{yang2021provably,
  title={Provably Faster Algorithms for Bilevel Optimization},
  author={Yang, Junjie and Ji, Kaiyi and Liang, Yingbin},
  journal={arXiv preprint arXiv:2106.04692},
  year={2021}
}

@article{ji2021lower,
  title={Lower Bounds and Accelerated Algorithms for Bilevel Optimization},
  author={Ji, Kaiyi and Liang, Yingbin},
  journal={arXiv preprint arXiv:2102.03926},
  year={2021}
}

@article{mehra2019penalty,
  title={Penalty method for inversion-free deep bilevel optimization},
  author={Mehra, Akshay and Hamm, Jihun},
  journal={arXiv preprint arXiv:1911.03432},
  year={2019}
}


@article{wu2020optimal,
  title={On the Optimal Weighted $\ell_2$ Regularization in Overparameterized Linear Regression},
  author={Wu, Denny and Xu, Ji},
  journal={arXiv preprint arXiv:2006.05800},
  year={2020}
}

@inproceedings{vicol2021unbiased,
  title={Unbiased gradient estimation in unrolled computation graphs with persistent evolution strategies},
  author={Vicol, Paul and Metz, Luke and Sohl-Dickstein, Jascha},
  booktitle={International Conference on Machine Learning},
  pages={10553--10563},
  year={2021},
  organization={PMLR}
}

@article{belkin2021fit,
  title={{Fit without fear: Remarkable mathematical phenomena of deep learning through the prism of interpolation}},
  author={Belkin, Mikhail},
  journal={Acta Numerica},
  volume={30},
  pages={203--248},
  year={2021},
  publisher={Cambridge University Press}
}

@article{gerfo2008spectral,
  title={Spectral algorithms for supervised learning},
  author={Gerfo, L Lo and Rosasco, Lorenzo and Odone, Francesca and Vito, E De and Verri, Alessandro},
  journal={Neural Computation},
  volume={20},
  number={7},
  pages={1873--1897},
  year={2008},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@misc{RosascoLecture,
  title={{9.520: Statistical Learning Theory and Applications, Lecture 7}},
  author={Lorenzo Rosasco},
  howpublished={{Lecture Notes}},
  year={2009},
  url={https://www.mit.edu/~9.520/spring09/Classes/class07_spectral.pdf},
}

% Frequency Fourier spectral bias in neural networks
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{basri2020frequency,
  title={Frequency bias in neural networks for input of non-uniform density},
  author={Basri, Ronen and Galun, Meirav and Geifman, Amnon and Jacobs, David and Kasten, Yoni and Kritchman, Shira},
  booktitle={International Conference on Machine Learning},
  pages={685--694},
  year={2020},
  organization={PMLR}
}

@inproceedings{rahaman2019spectral,
  title={On the spectral bias of neural networks},
  author={Rahaman, Nasim and Baratin, Aristide and Arpit, Devansh and Draxler, Felix and Lin, Min and Hamprecht, Fred and Bengio, Yoshua and Courville, Aaron},
  booktitle={International Conference on Machine Learning},
  pages={5301--5310},
  year={2019},
  organization={PMLR}
}

@article{tancik2020fourier,
  title={Fourier features let networks learn high frequency functions in low dimensional domains},
  author={Tancik, Matthew and Srinivasan, Pratul and Mildenhall, Ben and Fridovich-Keil, Sara and Raghavan, Nithin and Singhal, Utkarsh and Ramamoorthi, Ravi and Barron, Jonathan and Ng, Ren},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7537--7547},
  year={2020}
}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


