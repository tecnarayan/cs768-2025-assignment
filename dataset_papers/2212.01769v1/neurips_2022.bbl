\begin{thebibliography}{10}

\bibitem{mindspore}
Mindspore.
\newblock \url{https://www.mindspore.cn/}.

\bibitem{ahn2018interactive}
H.~Ahn, S.~Choi, N.~Kim, G.~Cha, and S.~Oh.
\newblock Interactive text2pickup networks for natural language-based
  human--robot collaboration.
\newblock {\em IEEE Robotics and Automation Letters}, 3(4):3308--3315, 2018.

\bibitem{chen2019uniter}
Y.-C. Chen, L.~Li, L.~Yu, A.~El~Kholy, F.~Ahmed, Z.~Gan, Y.~Cheng, and J.~Liu.
\newblock Uniter: Learning universal image-text representations.
\newblock 2019.

\bibitem{codevilla2019exploring}
F.~Codevilla, E.~Santana, A.~M. L{\'o}pez, and A.~Gaidon.
\newblock Exploring the limitations of behavior cloning for autonomous driving.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 9329--9338, 2019.

\bibitem{deng2009imagenet}
J.~Deng, W.~Dong, R.~Socher, L.-J. Li, K.~Li, and L.~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE Conference on Computer Vision and Pattern
  Recognition}, pages 248--255. Ieee, 2009.

\bibitem{devlin2018bert}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock {\em arXiv preprint arXiv:1810.04805}, 2018.

\bibitem{ding2021vision}
H.~Ding, C.~Liu, S.~Wang, and X.~Jiang.
\newblock Vision-language transformer and query generation for referring
  segmentation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 16321--16330, 2021.

\bibitem{dosovitskiy2020image}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai,
  T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock {\em arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{escalante2010segmented}
H.~J. Escalante, C.~A. Hern{\'a}ndez, J.~A. Gonzalez, A.~L{\'o}pez-L{\'o}pez,
  M.~Montes, E.~F. Morales, L.~E. Sucar, L.~Villasenor, and M.~Grubinger.
\newblock The segmented and annotated iapr tc-12 benchmark.
\newblock {\em Computer vision and image understanding}, 114(4):419--428, 2010.

\bibitem{everingham2010pascal}
M.~Everingham, L.~Van~Gool, C.~K. Williams, J.~Winn, and A.~Zisserman.
\newblock The pascal visual object classes (voc) challenge.
\newblock {\em International Journal of Computer Vision}, 88(2):303--338, 2010.

\bibitem{feng2021encoder}
G.~Feng, Z.~Hu, L.~Zhang, and H.~Lu.
\newblock Encoder fusion network with co-attention embedding for referring
  image segmentation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 15506--15515, 2021.

\bibitem{hu2020bi}
Z.~Hu, G.~Feng, J.~Sun, L.~Zhang, and H.~Lu.
\newblock Bi-directional relationship inferring network for referring image
  segmentation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 4424--4433, 2020.

\bibitem{huang2020referring}
S.~Huang, T.~Hui, S.~Liu, G.~Li, Y.~Wei, J.~Han, L.~Liu, and B.~Li.
\newblock Referring image segmentation via cross-modal progressive
  comprehension.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10488--10497, 2020.

\bibitem{hui2020linguistic}
T.~Hui, S.~Liu, S.~Huang, G.~Li, S.~Yu, F.~Zhang, and J.~Han.
\newblock Linguistic structure guided context modeling for referring image
  segmentation.
\newblock In {\em European Conference on Computer Vision}, pages 59--75.
  Springer, 2020.

\bibitem{jia2021scaling}
C.~Jia, Y.~Yang, Y.~Xia, Y.-T. Chen, Z.~Parekh, H.~Pham, Q.~Le, Y.-H. Sung,
  Z.~Li, and T.~Duerig.
\newblock Scaling up visual and vision-language representation learning with
  noisy text supervision.
\newblock In {\em International Conference on Machine Learning}, pages
  4904--4916. PMLR, 2021.

\bibitem{jing2021locate}
Y.~Jing, T.~Kong, W.~Wang, L.~Wang, L.~Li, and T.~Tan.
\newblock Locate then segment: A strong pipeline for referring image
  segmentation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 9858--9867, 2021.

\bibitem{kamath2021mdetr}
A.~Kamath, M.~Singh, Y.~LeCun, G.~Synnaeve, I.~Misra, and N.~Carion.
\newblock Mdetr-modulated detection for end-to-end multi-modal understanding.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1780--1790, 2021.

\bibitem{kazemzadeh2014referitgame}
S.~Kazemzadeh, V.~Ordonez, M.~Matten, and T.~Berg.
\newblock Referitgame: Referring to objects in photographs of natural scenes.
\newblock In {\em Proceedings of the Conference on Empirical Methods in Natural
  Language Processing (EMNLP)}, pages 787--798, 2014.

\bibitem{kim2022restr}
N.~Kim, D.~Kim, C.~Lan, W.~Zeng, and S.~Kwak.
\newblock Restr: Convolution-free referring image segmentation using
  transformers.
\newblock {\em arXiv preprint arXiv:2203.16768}, 2022.

\bibitem{kim2021vilt}
W.~Kim, B.~Son, and I.~Kim.
\newblock Vilt: Vision-and-language transformer without convolution or region
  supervision.
\newblock In {\em International Conference on Machine Learning}, pages
  5583--5594. PMLR, 2021.

\bibitem{li2020unicoder}
G.~Li, N.~Duan, Y.~Fang, M.~Gong, and D.~Jiang.
\newblock Unicoder-vl: A universal encoder for vision and language by
  cross-modal pre-training.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pages 11336--11344, 2020.

\bibitem{li2019visualbert}
L.~H. Li, M.~Yatskar, D.~Yin, C.-J. Hsieh, and K.-W. Chang.
\newblock Visualbert: A simple and performant baseline for vision and language.
\newblock {\em arXiv preprint arXiv:1908.03557}, 2019.

\bibitem{li2021grounded}
L.~H. Li, P.~Zhang, H.~Zhang, J.~Yang, C.~Li, Y.~Zhong, L.~Wang, L.~Yuan,
  L.~Zhang, J.-N. Hwang, et~al.
\newblock Grounded language-image pre-training.
\newblock {\em arXiv preprint arXiv:2112.03857}, 2021.

\bibitem{li2020oscar}
X.~Li, X.~Yin, C.~Li, P.~Zhang, X.~Hu, L.~Zhang, L.~Wang, H.~Hu, L.~Dong,
  F.~Wei, et~al.
\newblock Oscar: Object-semantics aligned pre-training for vision-language
  tasks.
\newblock In {\em European Conference on Computer Vision}, pages 121--137.
  Springer, 2020.

\bibitem{li2021mail}
Z.~Li, M.~Wang, J.~Mei, and Y.~Liu.
\newblock Mail: A unified mask-image-language trimodal network for referring
  image segmentation.
\newblock {\em arXiv preprint arXiv:2111.10747}, 2021.

\bibitem{ling2021editgan}
H.~Ling, K.~Kreis, D.~Li, S.~W. Kim, A.~Torralba, and S.~Fidler.
\newblock Editgan: High-precision semantic image editing.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{liu2021swin}
Z.~Liu, Y.~Lin, Y.~Cao, H.~Hu, Y.~Wei, Z.~Zhang, S.~Lin, and B.~Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 10012--10022, 2021.

\bibitem{loshchilov2017decoupled}
I.~Loshchilov and F.~Hutter.
\newblock Decoupled weight decay regularization.
\newblock {\em arXiv preprint arXiv:1711.05101}, 2017.

\bibitem{lu2019vilbert}
J.~Lu, D.~Batra, D.~Parikh, and S.~Lee.
\newblock Vilbert: Pretraining task-agnostic visiolinguistic representations
  for vision-and-language tasks.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{luo2020cascade}
G.~Luo, Y.~Zhou, R.~Ji, X.~Sun, J.~Su, C.-W. Lin, and Q.~Tian.
\newblock Cascade grouped attention network for referring expression
  segmentation.
\newblock In {\em Proceedings of the 28th ACM International Conference on
  Multimedia}, pages 1274--1282, 2020.

\bibitem{luo2020multi}
G.~Luo, Y.~Zhou, X.~Sun, L.~Cao, C.~Wu, C.~Deng, and R.~Ji.
\newblock Multi-task collaborative network for joint referring expression
  comprehension and segmentation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10034--10043, 2020.

\bibitem{mao2016generation}
J.~Mao, J.~Huang, A.~Toshev, O.~Camburu, A.~L. Yuille, and K.~Murphy.
\newblock Generation and comprehension of unambiguous object descriptions.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 11--20, 2016.

\bibitem{nair2010rectified}
V.~Nair and G.~E. Hinton.
\newblock Rectified linear units improve restricted boltzmann machines.
\newblock In {\em International Conference on Machine Learning}, 2010.

\bibitem{patashnik2021styleclip}
O.~Patashnik, Z.~Wu, E.~Shechtman, D.~Cohen-Or, and D.~Lischinski.
\newblock Styleclip: Text-driven manipulation of stylegan imagery.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 2085--2094, 2021.

\bibitem{pate2021natural}
S.~Pate, W.~Xu, Z.~Yang, M.~Love, S.~Ganguri, and L.~L. Wong.
\newblock Natural language for human-robot collaboration: Problems beyond
  language grounding.
\newblock {\em arXiv preprint arXiv:2110.04441}, 2021.

\bibitem{radford2021learning}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry,
  A.~Askell, P.~Mishkin, J.~Clark, et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In {\em International Conference on Machine Learning}, pages
  8748--8763. PMLR, 2021.

\bibitem{tan2019lxmert}
H.~Tan and M.~Bansal.
\newblock Lxmert: Learning cross-modality encoder representations from
  transformers.
\newblock {\em arXiv preprint arXiv:1908.07490}, 2019.

\bibitem{toromanoff2020end}
M.~Toromanoff, E.~Wirbel, and F.~Moutarde.
\newblock End-to-end model-free reinforcement learning for urban driving using
  implicit affordances.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 7153--7162, 2020.

\bibitem{van2018representation}
A.~Van~den Oord, Y.~Li, and O.~Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock {\em arXiv e-prints}, pages arXiv--1807, 2018.

\bibitem{vaswani2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  {\L}.~Kaiser, and I.~Polosukhin.
\newblock Attention is all you need.
\newblock {\em Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem{wang2021cris}
Z.~Wang, Y.~Lu, Q.~Li, X.~Tao, Y.~Guo, M.~Gong, and T.~Liu.
\newblock Cris: Clip-driven referring image segmentation.
\newblock {\em arXiv preprint arXiv:2111.15174}, 2021.

\bibitem{wu2016google}
Y.~Wu, M.~Schuster, Z.~Chen, Q.~V. Le, M.~Norouzi, W.~Macherey, M.~Krikun,
  Y.~Cao, Q.~Gao, K.~Macherey, et~al.
\newblock Google's neural machine translation system: Bridging the gap between
  human and machine translation.
\newblock {\em arXiv preprint arXiv:1609.08144}, 2016.

\bibitem{yang2021bottom}
S.~Yang, M.~Xia, G.~Li, H.-Y. Zhou, and Y.~Yu.
\newblock Bottom-up shift and reasoning for referring image segmentation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 11266--11275, 2021.

\bibitem{yang2021lavt}
Z.~Yang, J.~Wang, Y.~Tang, K.~Chen, H.~Zhao, and P.~H. Torr.
\newblock Lavt: Language-aware vision transformer for referring image
  segmentation.
\newblock {\em arXiv preprint arXiv:2112.02244}, 2021.

\bibitem{yao2021filip}
L.~Yao, R.~Huang, L.~Hou, G.~Lu, M.~Niu, H.~Xu, X.~Liang, Z.~Li, X.~Jiang, and
  C.~Xu.
\newblock Filip: Fine-grained interactive language-image pre-training.
\newblock {\em arXiv preprint arXiv:2111.07783}, 2021.

\bibitem{yu2016modeling}
L.~Yu, P.~Poirson, S.~Yang, A.~C. Berg, and T.~L. Berg.
\newblock Modeling context in referring expressions.
\newblock In {\em European Conference on Computer Vision}, pages 69--85.
  Springer, 2016.

\end{thebibliography}
