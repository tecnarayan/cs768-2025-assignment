\begin{thebibliography}{43}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.()Abadi, Barham, Chen, Chen, Davis, Dean, Devin, Ghemawat,
  Irving, Isard, et~al.]{abadi2016tensorflow}
Mart{\'\i}n Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey
  Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et~al.
\newblock Tensorflow: a system for large-scale machine learning.

\bibitem[Bardenet et~al.(2013)Bardenet, Brendel, K{\'e}gl, and
  Sebag]{bardenet2013collaborative}
R{\'e}mi Bardenet, M{\'a}ty{\'a}s Brendel, Bal{\'a}zs K{\'e}gl, and Michele
  Sebag.
\newblock Collaborative hyperparameter tuning.
\newblock In \emph{International Conference on Machine Learning}, pages
  199--207, 2013.

\bibitem[Bishop(2006)]{bishop2006}
C.M. Bishop.
\newblock \emph{Pattern recognition and machine learning}.
\newblock Springer New York, 2006.

\bibitem[Blanchard et~al.(2017)Blanchard, Deshmukh, Dogan, Lee, and
  Scott]{blanchard2017domain}
Gilles Blanchard, Aniket~Anand Deshmukh, Urun Dogan, Gyemin Lee, and Clayton
  Scott.
\newblock Domain generalization by marginal transfer learning.
\newblock \emph{arXiv preprint arXiv:1711.07910}, 2017.

\bibitem[Bouchard et~al.(2013)Bouchard, Jousselme, and
  Dor{\'e}]{bouchard2013proof}
Mathieu Bouchard, Anne-Laure Jousselme, and Pierre-Emmanuel Dor{\'e}.
\newblock A proof for the positive definiteness of the jaccard index matrix.
\newblock \emph{International Journal of Approximate Reasoning}, 54\penalty0
  (5):\penalty0 615--626, 2013.

\bibitem[Feurer et~al.(2014)Feurer, Springenberg, and Hutter]{feurer2014using}
Matthias Feurer, Jost~Tobias Springenberg, and Frank Hutter.
\newblock Using meta-learning to initialize bayesian optimization of
  hyperparameters.
\newblock In \emph{Proceedings of the 2014 International Conference on
  Meta-learning and Algorithm Selection-Volume 1201}, pages 3--10. Citeseer,
  2014.

\bibitem[Feurer et~al.(2015)Feurer, Springenberg, and
  Hutter]{feurer2015initializing}
Matthias Feurer, Jost~Tobias Springenberg, and Frank Hutter.
\newblock Initializing bayesian hyperparameter optimization via meta-learning.
\newblock 2015.

\bibitem[Feurer et~al.(2018)Feurer, Letham, and Bakshy]{feurer2018scalable}
Matthias Feurer, Benjamin Letham, and Eytan Bakshy.
\newblock Scalable meta-learning for bayesian optimization using
  ranking-weighted gaussian process ensembles.
\newblock In \emph{AutoML Workshop at ICML}, 2018.

\bibitem[Gaulton et~al.(2016)Gaulton, Hersey, Nowotka, Bento, Chambers, Mendez,
  Mutowo, Atkinson, Bellis, Cibri{\'a}n-Uhalte, et~al.]{gaulton2016chembl}
Anna Gaulton, Anne Hersey, Micha{\l} Nowotka, A~Patr{\'\i}cia Bento, Jon
  Chambers, David Mendez, Prudence Mutowo, Francis Atkinson, Louisa~J Bellis,
  Elena Cibri{\'a}n-Uhalte, et~al.
\newblock The chembl database in 2017.
\newblock \emph{Nucleic acids research}, 45\penalty0 (D1):\penalty0 D945--D954,
  2016.

\bibitem[Gomes et~al.(2012)Gomes, Prud{\^e}ncio, Soares, Rossi, and
  Carvalho]{gomes2012combining}
Taciana~AF Gomes, Ricardo~BC Prud{\^e}ncio, Carlos Soares, Andr{\'e}~LD Rossi,
  and Andr{\'e} Carvalho.
\newblock Combining meta-learning and search techniques to select parameters
  for support vector machines.
\newblock \emph{Neurocomputing}, 75\penalty0 (1):\penalty0 3--13, 2012.

\bibitem[Gretton(2015)]{gretton2015notes}
Arthur Gretton.
\newblock Notes on mean embeddings and covariance operators.
\newblock 2015.

\bibitem[Hern\'{a}ndez-Lobato et~al.(2014)Hern\'{a}ndez-Lobato, Hoffman, and
  Ghahramani]{lobato2014}
Jos{\'e}~Miguel Hern\'{a}ndez-Lobato, Matthew~W. Hoffman, and Zoubin
  Ghahramani.
\newblock Predictive entropy search for efficient global optimization of
  black-box functions.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  918--926, Cambridge, MA, USA, 2014. MIT Press.

\bibitem[Hutter et~al.(2019)Hutter, Kotthoff, and Vanschoren]{automl_book}
Frank Hutter, Lars Kotthoff, and Joaquin Vanschoren, editors.
\newblock \emph{Automatic Machine Learning: Methods, Systems, Challenges}.
\newblock Springer, 2019.

\bibitem[Jones et~al.(2001--)Jones, Oliphant, Peterson, et~al.]{scipy}
Eric Jones, Travis Oliphant, Pearu Peterson, et~al.
\newblock {SciPy}: Open source scientific tools for {Python}, 2001--.
\newblock URL \url{http://www.scipy.org/}.
\newblock [Online; accessed <today>].

\bibitem[Kim et~al.(2017)Kim, Kim, and Choi]{kim2017learning}
Jungtaek Kim, Saehoon Kim, and Seungjin Choi.
\newblock Learning to transfer initializations for bayesian hyperparameter
  optimization.
\newblock \emph{arXiv preprint arXiv:1710.06219}, 2017.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Klein et~al.(2016)Klein, Falkner, Bartels, Hennig, and
  Hutter]{klein2016fast}
Aaron Klein, Stefan Falkner, Simon Bartels, Philipp Hennig, and Frank Hutter.
\newblock Fast bayesian optimization of machine learning hyperparameters on
  large datasets.
\newblock \emph{arXiv preprint arXiv:1605.07079}, 2016.

\bibitem[Law et~al.(2018)Law, Sutherland, Sejdinovic, and
  Flaxman]{law2018bayesian}
Ho~Chung~Leon Law, Dougal Sutherland, Dino Sejdinovic, and Seth Flaxman.
\newblock Bayesian approaches to distribution regression.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 1167--1176, 2018.

\bibitem[McLeod et~al.(2018)McLeod, Osborne, and
  Roberts]{mcleod_optimization_2018}
Mark McLeod, Michael~A. Osborne, and Stephen~J. Roberts.
\newblock Optimization, fast and slow: optimally switching between local and
  {Bayesian} optimization.
\newblock In \emph{Proceedings of the {International} {Conference} on {Machine}
  {Learning} ({ICML})}, May 2018.
\newblock URL \url{http://arxiv.org/abs/1805.08610}.

\bibitem[{Michie} et~al.(1994){Michie}, {Spiegelhalter}, and
  {Taylor}]{normalise}
D.~{Michie}, D.~J. {Spiegelhalter}, and C.~C. {Taylor}.
\newblock \emph{{Machine learning, neural and statistical classification}}.
\newblock 1994.

\bibitem[Mikolov et~al.(2013)Mikolov, Sutskever, Chen, Corrado, and
  Dean]{mikolov2013distributed}
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg~S Corrado, and Jeff Dean.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In \emph{Advances in neural information processing systems}, pages
  3111--3119, 2013.

\bibitem[Mo{\v{c}}kus(1975)]{movckus1975bayesian}
J~Mo{\v{c}}kus.
\newblock On bayesian methods for seeking the extremum.
\newblock In \emph{Optimization Techniques IFIP Technical Conference}, pages
  400--404. Springer, 1975.

\bibitem[Muandet et~al.(2017)Muandet, Fukumizu, Sriperumbudur, Sch{\"o}lkopf,
  et~al.]{muandet2017kernel}
Krikamol Muandet, Kenji Fukumizu, Bharath Sriperumbudur, Bernhard
  Sch{\"o}lkopf, et~al.
\newblock Kernel mean embedding of distributions: A review and beyond.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  10\penalty0 (1-2):\penalty0 1--141, 2017.

\bibitem[Oh et~al.(2018)Oh, Gavves, and Welling]{oh2018bock}
ChangYong Oh, Efstratios Gavves, and Max Welling.
\newblock Bock: Bayesian optimization with cylindrical kernels.
\newblock \emph{arXiv preprint arXiv:1806.01619}, 2018.

\bibitem[Pedregosa et~al.(2011)Pedregosa, Varoquaux, Gramfort, Michel, Thirion,
  Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos,
  Cournapeau, Brucher, Perrot, and Duchesnay]{scikit-learn}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel,
  M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, J.~Vanderplas, A.~Passos,
  D.~Cournapeau, M.~Brucher, M.~Perrot, and E.~Duchesnay.
\newblock Scikit-learn: Machine learning in {P}ython.
\newblock \emph{Journal of Machine Learning Research}, 12:\penalty0 2825--2830,
  2011.

\bibitem[Perrone et~al.(2018)Perrone, Jenatton, Seeger, and
  Archambeau]{perrone2018scalable}
Valerio Perrone, Rodolphe Jenatton, Matthias~W Seeger, and Cedric Archambeau.
\newblock Scalable hyperparameter transfer learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  6846--6856, 2018.

\bibitem[Pfahringer et~al.()Pfahringer, Bensusan, and
  Giraud-Carrier]{pfahringer2000meta}
Bernhard Pfahringer, Hilan Bensusan, and Christophe~G Giraud-Carrier.
\newblock Meta-learning by landmarking various learning algorithms.

\bibitem[Poloczek et~al.(2016)Poloczek, Wang, and Frazier]{poloczek2016warm}
Matthias Poloczek, Jialei Wang, and Peter~I Frazier.
\newblock Warm starting bayesian optimization.
\newblock In \emph{Proceedings of the 2016 Winter Simulation Conference}, pages
  770--781. IEEE Press, 2016.

\bibitem[Rahimi and Recht(2008)]{rahimi2008random}
Ali Rahimi and Benjamin Recht.
\newblock Random features for large-scale kernel machines.
\newblock In \emph{Advances in neural information processing systems}, pages
  1177--1184, 2008.

\bibitem[Ralaivola et~al.(2005)Ralaivola, Swamidass, Saigo, and
  Baldi]{ralaivola2005graph}
Liva Ralaivola, Sanjay~J Swamidass, Hiroto Saigo, and Pierre Baldi.
\newblock Graph kernels for chemical informatics.
\newblock \emph{Neural networks}, 18\penalty0 (8):\penalty0 1093--1110, 2005.

\bibitem[Rasmussen(2004)]{rasmussen2004gaussian}
Carl~Edward Rasmussen.
\newblock Gaussian processes in machine learning.
\newblock In \emph{Advanced lectures on machine learning}, pages 63--71.
  Springer, 2004.

\bibitem[Reif et~al.(2012)Reif, Shafait, and Dengel]{reif2012meta}
Matthias Reif, Faisal Shafait, and Andreas Dengel.
\newblock Meta-learning for evolutionary parameter optimization of classifiers.
\newblock \emph{Machine learning}, 87\penalty0 (3):\penalty0 357--380, 2012.

\bibitem[Snoek et~al.(2012)Snoek, Larochelle, and Adams]{snoek2012practical}
Jasper Snoek, Hugo Larochelle, and Ryan~P Adams.
\newblock Practical bayesian optimization of machine learning algorithms.
\newblock In \emph{Advances in neural information processing systems}, pages
  2951--2959, 2012.

\bibitem[Song et~al.(2013)Song, Fukumizu, and Gretton]{song2013kernel}
Le~Song, Kenji Fukumizu, and Arthur Gretton.
\newblock Kernel embeddings of conditional distributions: A unified kernel
  framework for nonparametric inference in graphical models.
\newblock \emph{Signal Processing Magazine, IEEE}, 30\penalty0 (4):\penalty0
  98--111, 2013.

\bibitem[Springenberg et~al.(2016)Springenberg, Klein, Falkner, and
  Hutter]{springenberg2016bayesian}
Jost~Tobias Springenberg, Aaron Klein, Stefan Falkner, and Frank Hutter.
\newblock Bayesian optimization with robust bayesian neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  4134--4142, 2016.

\bibitem[Srinivas et~al.(2009)Srinivas, Krause, Kakade, and
  Seeger]{srinivas2009gaussian}
Niranjan Srinivas, Andreas Krause, Sham~M Kakade, and Matthias Seeger.
\newblock Gaussian process optimization in the bandit setting: No regret and
  experimental design.
\newblock \emph{arXiv preprint arXiv:0912.3995}, 2009.

\bibitem[Swersky et~al.(2013)Swersky, Snoek, and Adams]{swersky2013multi}
Kevin Swersky, Jasper Snoek, and Ryan~P Adams.
\newblock Multi-task bayesian optimization.
\newblock In \emph{Advances in neural information processing systems}, pages
  2004--2012, 2013.

\bibitem[Todorovski et~al.(2000)Todorovski, Brazdil, and
  Soares]{todorovski2000report}
Ljupco Todorovski, Pavel Brazdil, and Carlos Soares.
\newblock Report on the experiments with feature selection in meta-level
  learning.
\newblock In \emph{Proceedings of the PKDD-00 workshop on data mining, decision
  support, meta-learning and ILP: forum for practical problem presentation and
  prospective solutions}. Citeseer, 2000.

\bibitem[Vanschoren et~al.(2013)Vanschoren, van Rijn, Bischl, and
  Torgo]{OpenML2013}
Joaquin Vanschoren, Jan~N. van Rijn, Bernd Bischl, and Luis Torgo.
\newblock Openml: Networked science in machine learning.
\newblock \emph{SIGKDD Explorations}, 15\penalty0 (2):\penalty0 49--60, 2013.
\newblock \doi{10.1145/2641190.2641198}.
\newblock URL \url{http://doi.acm.org/10.1145/2641190.2641198}.

\bibitem[Wang et~al.(2016)Wang, Clark, Liu, and Frazier]{wang2016parallel}
Jialei Wang, Scott~C Clark, Eric Liu, and Peter~I Frazier.
\newblock Parallel bayesian global optimization of expensive functions.
\newblock \emph{arXiv preprint arXiv:1602.05149}, 2016.

\bibitem[Wilson et~al.(2016)Wilson, Hu, Salakhutdinov, and
  Xing]{wilson2016deep}
Andrew~Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, and Eric~P Xing.
\newblock Deep kernel learning.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 370--378,
  2016.

\bibitem[Wistuba et~al.(2018)Wistuba, Schilling, and
  Schmidt-Thieme]{wistuba2018scalable}
Martin Wistuba, Nicolas Schilling, and Lars Schmidt-Thieme.
\newblock Scalable gaussian process-based transfer surrogates for
  hyperparameter optimization.
\newblock \emph{Machine Learning}, 107\penalty0 (1):\penalty0 43--78, 2018.

\bibitem[Zaheer et~al.(2017)Zaheer, Kottur, Ravanbakhsh, Poczos, Salakhutdinov,
  and Smola]{zaheer2017deep}
Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan~R
  Salakhutdinov, and Alexander~J Smola.
\newblock Deep sets.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3391--3401, 2017.

\end{thebibliography}
