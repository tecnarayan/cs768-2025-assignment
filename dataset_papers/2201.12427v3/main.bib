@article{Haarnoja2018,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Kristian Hartikainen and
               George Tucker and
               Sehoon Ha and
               Jie Tan and
               Vikash Kumar and
               Henry Zhu and
               Abhishek Gupta and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic Algorithms and Applications},
  journal   = {arXiv},
  volume    = {abs/1812.05905},
  year      = {2018}
}

@article{Yu2021TAAC,
    author={Haonan Yu and Wei Xu and Haichao Zhang},
    title={{TAAC}: Temporally Abstract Actor-Critic for Continuous Control},
    journal={arXiv},
    year={2021}
}

@inproceedings{chou2017improving,
  title={Improving stochastic policy gradients in continuous control with deep reinforcement learning using the beta distribution},
  author={Chou, Po-Wei and Maturana, Daniel and Scherer, Sebastian},
  booktitle={ICML},
  pages={834--843},
  year={2017}
}

@inproceedings{Abdolmaleki2020,
  title         = {A distributional view on multi-objective policy optimization},
  author        = {Abdolmaleki, Abbas and Huang, Sandy H and Hasenclever,
                   Leonard and Neunert, Michael and Song, H Francis and
                   Zambelli, Martina and Martins, Murilo F and Heess, Nicolas
                   and Hadsell, Raia and Riedmiller, Martin},
  year          = {2020},
  booktitle     = {ICML}
}

@inproceedings{yu2020gradient,
  title={Gradient surgery for multi-task learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  booktitle={NeurIPS},
  year={2020}
}

@article{Ray2019,
    author = {Ray, Alex and Achiam, Joshua and Amodei, Dario},
    title = {{Benchmarking Safe Exploration in Deep Reinforcement Learning}},
    year = {2019}
}

@article{recovery_rl2021,
  title={Recovery rl: Safe reinforcement learning with learned recovery zones},
  author={Thananjeyan, Brijen and Balakrishna, Ashwin and Nair, Suraj and Luo, Michael and Srinivasan, Krishnan and Hwang, Minho and Gonzalez, Joseph E and Ibarz, Julian and Finn, Chelsea and Goldberg, Ken},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  number={3},
  pages={4915--4922},
  year={2021}
}


@inproceedings{Tessler2019,
  title         = {Reward Constrained Policy Optimization},
  author        = {Tessler, Chen and Mankowitz, Daniel J and Mannor, Shie},
  year          =  {2019},
  booktitle = {ICLR}
}

@article{Dalal2018,
  author    = {Gal Dalal and
               Krishnamurthy Dvijotham and
               Matej Vecer{\'{\i}}k and
               Todd Hester and
               Cosmin Paduraru and
               Yuval Tassa},
  title     = {Safe Exploration in Continuous Action Spaces},
  journal   = {CoRR},
  year      = {2018}
}

@article{Silver2016,
  author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche,   George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
  journal = {Nature},
  number = {7587},
  pages = {484--489},
  title = {Mastering the Game of {Go} with Deep Neural Networks and Tree Search},
  volume = {529},
  year = {2016}
}

@article{Vinyals2019GrandmasterLI,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Oriol Vinyals and Igor Babuschkin and Wojciech M. Czarnecki and Micha{\"e}l Mathieu and Andrew Dudzik and Junyoung Chung and David H. Choi and Richard Powell and Timo Ewalds and Petko Georgiev and Junhyuk Oh and Dan Horgan and Manuel Kroiss and Ivo Danihelka and Aja Huang and L. Sifre and Trevor Cai and John P. Agapiou and Max Jaderberg and Alexander Sasha Vezhnevets and R{\'e}mi Leblond and Tobias Pohlen and Valentin Dalibard and David Budden and Yury Sulsky and James Molloy and Tom Le Paine and Caglar Gulcehre and Ziyun Wang and Tobias Pfaff and Yuhuai Wu and Roman Ring and Dani Yogatama and Dario W{\"u}nsch and Katrina McKinney and Oliver Smith and Tom Schaul and Timothy P. Lillicrap and Koray Kavukcuoglu and Demis Hassabis and Chris Apps and David Silver},
  journal={Nature},
  year={2019},
  pages={1-5}
}

@article{OpenAI2019Five,
  author    = {Christopher Berner and
               Greg Brockman and
               Brooke Chan and
               Vicki Cheung and
               Przemyslaw Debiak and
               Christy Dennison and
               David Farhi and
               Quirin Fischer and
               Shariq Hashme and
               Christopher Hesse and
               Rafal J{\'{o}}zefowicz and
               Scott Gray and
               Catherine Olsson and
               Jakub Pachocki and
               Michael Petrov and
               Henrique Pond{\'{e}} de Oliveira Pinto and
               Jonathan Raiman and
               Tim Salimans and
               Jeremy Schlatter and
               Jonas Schneider and
               Szymon Sidor and
               Ilya Sutskever and
               Jie Tang and
               Filip Wolski and
               Susan Zhang},
  title     = {Dota 2 with Large Scale Deep Reinforcement Learning},
  journal   = {arXiv},
  year      = {2019}
}

@misc{Brockman2016,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@misc{tassa2020dmcontrol,
    title={dm\_control: Software and Tasks for Continuous Control},
    author={Yuval Tassa and Saran Tunyasuvunakool and Alistair Muldal and
            Yotam Doron and Siqi Liu and Steven Bohez and Josh Merel and
            Tom Erez and Timothy Lillicrap and Nicolas Heess},
    year={2020},
    eprint={2006.12983},
    archivePrefix={arXiv},
    primaryClass={cs.RO}
}

@inproceedings{Kim2003,
 author = {Kim, H. and Jordan, Michael and Sastry, Shankar and Ng, Andrew},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Autonomous Helicopter Flight via Reinforcement Learning},
 volume = {16},
 year = {2004}
}

@article{OpenAI2019,
  author    = {OpenAI and
               Ilge Akkaya and
               Marcin Andrychowicz and
               Maciek Chociej and
               Mateusz Litwin and
               Bob McGrew and
               Arthur Petron and
               Alex Paino and
               Matthias Plappert and
               Glenn Powell and
               Raphael Ribas and
               Jonas Schneider and
               Nikolas Tezak and
               Jerry Tworek and
               Peter Welinder and
               Lilian Weng and
               Qiming Yuan and
               Wojciech Zaremba and
               Lei Zhang},
  title     = {Solving Rubik's Cube with a Robot Hand},
  journal   = {arXiv},
  year      = {2019}
}

@article{Levine2016,
  author    = {Sergey Levine and
               Peter Pastor and
               Alex Krizhevsky and
               Deirdre Quillen},
  title     = {Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning
               and Large-Scale Data Collection},
  journal   = {arXiv},
  year      = {2016}
}

@inproceedings{Thananjeyan2021,
  author    = {Brijen Thananjeyan and
               Ashwin Balakrishna and
               Suraj Nair and
               Michael Luo and
               Krishnan Srinivasan and
               Minho Hwang and
               Joseph E. Gonzalez and
               Julian Ibarz and
               Chelsea Finn and
               Ken Goldberg},
  title     = {Recovery {RL:} Safe Reinforcement Learning with Learned Recovery Zones},
  booktitle = {ICRA},
  year      = {2021}
}

@inproceedings{Luo2021,
  author    = {Yuping Luo and
               Tengyu Ma},
  title     = {Learning Barrier Certificates: Towards Safe Reinforcement Learning
               with Zero Training-time Violations},
  booktitle = {NeurIPS},
  year      = {2021}
}

@inproceedings{berkenkamp2017safe,
      title={Safe Model-based Reinforcement Learning with Stability Guarantees}, 
      author={Felix Berkenkamp and Matteo Turchetta and Angela P. Schoellig and Andreas Krause},
      year={2017},
      booktitle={NeurIPS}
}

@inproceedings{chow2018lyapunovbased,
      title={A Lyapunov-based Approach to Safe Reinforcement Learning}, 
      author={Yinlam Chow and Ofir Nachum and Edgar Duenez-Guzman and Mohammad Ghavamzadeh},
      year={2018},
      booktitle={NeurIPS}
}

@inproceedings{turchetta2020safe,
      title={Safe Reinforcement Learning via Curriculum Induction}, 
      author={Matteo Turchetta and Andrey Kolobov and Shital Shah and Andreas Krause and Alekh Agarwal},
      year={2020},
      booktitle={NeurIPS}
}

@inproceedings{thomas2021safe,
title={Safe Reinforcement Learning by Imagining the Near Future},
author={Garrett Thomas and Yuping Luo and Tengyu Ma},
booktitle={NeurIPS},
year={2021},
}

@inproceedings{Li2021SafeRL,
  title={Safe Reinforcement Learning Using Robust Action Governor},
  author={Yutong Li and Nan Li and H. Eric Tseng and Anouck R. Girard and Dimitar Filev and Ilya V. Kolmanovsky},
  booktitle={L4DC},
  year={2021}
}

@article{miret2020safety,
      title={Safety Aware Reinforcement Learning (SARL)}, 
      author={Santiago Miret and Somdeb Majumdar and Carroll Wainwright},
      year={2020},
      journal={arXiv}
}

@article{bohez2019value,
      title={Value constrained model-free continuous control}, 
      author={Steven Bohez and Abbas Abdolmaleki and Michael Neunert and Jonas Buchli and Nicolas Heess and Raia Hadsell},
      year={2019},
      journal={arXiv}
}

@inproceedings{stooke2020responsive,
      title={Responsive Safety in Reinforcement Learning by PID Lagrangian Methods}, 
      author={Adam Stooke and Joshua Achiam and Pieter Abbeel},
      year={2020},
      booktitle={ICML}
}

@inproceedings{qin2021density,
      title={Density Constrained Reinforcement Learning}, 
      author={Zengyi Qin and Yuxiao Chen and Chuchu Fan},
      year={2021},
      booktitle={ICML}
}

@inproceedings{Zhao2020,
  author={Zhao, Wenshuai and Queralta, Jorge Peña and Westerlund, Tomi},
  booktitle={2020 IEEE Symposium Series on Computational Intelligence (SSCI)}, 
  title={Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: a Survey}, 
  year={2020}
}

@article{schulman2017proximal,
      title={Proximal Policy Optimization Algorithms}, 
      author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
      year={2017},
      journal={arXiv}
}

@inproceedings{schulman2015trust,
      title={Trust Region Policy Optimization}, 
      author={John Schulman and Sergey Levine and Philipp Moritz and Michael I. Jordan and Pieter Abbeel},
      year={2015},
      booktitle={ICML}
}

@book{Bertsekas1999,
  author = {Bertsekas, D.P.},
  publisher = {Athena Scientific},
  title = {Nonlinear Programming},
  year = 1999
}

@inproceedings{pham2018optlayer,
      title={OptLayer - Practical Constrained Optimization for Deep Reinforcement Learning in the Real World}, 
      author={Tu-Hoa Pham and Giovanni De Magistris and Ryuki Tachibana},
      year={2018},
      booktitle={ICRA}
}

@inproceedings{Amos2017,
  author    = {Brandon Amos and
               J. Zico Kolter},
  title     = {OptNet: Differentiable Optimization as a Layer in Neural Networks},
  booktitle = {ICML},
  year      = {2017}
}

@inproceedings{likhosherstov2021debiasing,
      title={Debiasing a First-order Heuristic for Approximate Bi-level Optimization}, 
      author={Valerii Likhosherstov and Xingyou Song and Krzysztof Choromanski and Jared Davis and Adrian Weller},
      year={2021},
      booktitle={ICML}
}

@inproceedings{figurnov2018implicit,
      title={Implicit Reparameterization Gradients}, 
      author={Michael Figurnov and Shakir Mohamed and Andriy Mnih},
      year={2018},
      booktitle={NeurIPS}
}

@inproceedings{Dosovitskiy17,
  title = {{CARLA}: {An} Open Urban Driving Simulator},
  author = {Alexey Dosovitskiy and German Ros and Felipe Codevilla and Antonio Lopez and Vladlen Koltun},
  booktitle = {CoRL},
  year = {2017}
}

@inproceedings{Yang2020Projection-Based,
title={Projection-Based Constrained Policy Optimization},
author={Tsung-Yen Yang and Justinian Rosca and Karthik Narasimhan and Peter J. Ramadge},
booktitle={ICLR},
year={2020}
}

@InProceedings{achiam17a,
  title = 	 {Constrained Policy Optimization},
  author =       {Joshua Achiam and David Held and Aviv Tamar and Pieter Abbeel},
  booktitle = 	 {ICML},
  year = 	 {2017}
}

@misc{Yu2022EntropyAnonymous,
    author={Anonymous},
    title={Do you need the entropy reward (in practice)?},
    note={In submission},
    year={2022},
}

@article{Yu2022Entropy,
    author={Haonan Yu and Haichao Zhang and Wei Xu},
    title={Do you need the entropy reward (in practice)?},
    journal={arXiv},
    year={2022}
}

@article{chow2019lyapunovbased,
      title={Lyapunov-based Safe Policy Optimization for Continuous Control}, 
      author={Yinlam Chow and Ofir Nachum and Aleksandra Faust and Edgar Duenez-Guzman and Mohammad Ghavamzadeh},
      year={2019},
      journal={arXiv}
}

@inproceedings{langlois2021rl,
      title={How RL Agents Behave When Their Actions Are Modified}, 
      author={Eric D. Langlois and Tom Everitt},
      year={2021},
      booktitle={AAAI}
}

@article{Roijers2013,
   title={A Survey of Multi-Objective Sequential Decision-Making},
   journal={JAIR},
   author={Diederik Marijn Roijers and Peter Vamplew and Shimon Whiteson and Richard Dazeley},
   year={2013}
}

@INPROCEEDINGS{Moffaert2013,
  author={Van Moffaert, Kristof and Drugan, Madalina M. and Nowé, Ann},
  booktitle={2013 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL)}, 
  title={Scalarized multi-objective reinforcement learning: Novel design techniques}, 
  year={2013}}
  
@article{moffaert2015,
  author  = {Kristof Van Moffaert and Ann Now{{\'e}}},
  title   = {Multi-Objective Reinforcement Learning using Sets of Pareto Dominating Policies},
  journal = {JAIR},
  year    = {2014}
}

@inproceedings{zhang2020order,
      title={First Order Constrained Optimization in Policy Space}, 
      author={Yiming Zhang and Quan Vuong and Keith W. Ross},
      year={2020},
      booktitle={NeurIPS}
}

@inproceedings{Cheng2019,
  author    = {Richard Cheng and
               G{\'{a}}bor Orosz and
               Richard M. Murray and
               Joel W. Burdick},
  title     = {End-to-End Safe Reinforcement Learning through Barrier Functions for
               Safety-Critical Continuous Control Tasks},
  booktitle = {AAAI},
  year      = {2019}
}

@inproceedings{Flet-Berliac2022,
  author    = {Yannis Flet{-}Berliac and
               Debabrota Basu},
  title     = {{SAAC:} Safe Reinforcement Learning as an Adversarial Game of Actor-Critics},
  booktitle = {Conference on Reinforcement Learning and Decision Making}, 
  year      = {2022}
}

@article{Bhatnagar2012,
	author = {Bhatnagar, Shalabh and Lakshmanan, K.},
	journal = {Journal of Optimization Theory and Applications},
	title = {An Online Actor–Critic Algorithm with Function Approximation for Constrained Markov Decision Processes},
	volume = {153},
	year = {2012},
}

@inproceedings{as2022constrained,
title={Constrained Policy Optimization via Bayesian World Models},
author={Yarden As and Ilnura Usmanova and Sebastian Curi and Andreas Krause},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=PRZoSmCinhf}
}

@inproceedings{Liu2022,
author = {Liu, Zuxin and Cen, Zhepeng and Isenbaev, Vladislav and Liu, Wei and Wu, Zhiwei and Li, Bo and Zhao, Ding},
year = {2022},
booktitle = {ICML},
title = {Constrained Variational Policy Optimization for Safe Reinforcement Learning}
}

@article{Mguni2021,
  author    = {David Mguni and
               Joel Jennings and
               Taher Jafferjee and
               Aivar Sootla and
               Yaodong Yang and
               Changmin Yu and
               Usman Islam and
               Ziyan Wang and
               Jun Wang},
  title     = {{DESTA:} {A} Framework for Safe Reinforcement Learning with Markov
               Games of Intervention},
  journal   = {arXiv},
  year      = {2021}
}