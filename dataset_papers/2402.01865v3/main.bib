@inproceedings{Lin2022OnCM,
  title={On Continual Model Refinement in Out-of-Distribution Data Streams},
  author={Bill Yuchen Lin and Sida I. Wang and Xi Victoria Lin and Robin Jia and Lin Xiao and Xiang Ren and Wen-tau Yih},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2022},
}

@inproceedings{Meng2022LocatingAE,
  title={Locating and Editing Factual Associations in GPT},
  author={Kevin Meng and David Bau and Alex Andonian and Yonatan Belinkov},
  booktitle={Neural Information Processing Systems},
  year={2022},
}

@article{Raffel2023BuildingML,
  title={Building Machine Learning Models Like Open Source Software},
  author={Colin Raffel},
  journal={Communications of the ACM},
  year={2023},
}

@article{OpenAI2023GPT4TR,
  title={GPT-4 Technical Report},
  author={OpenAI},
  journal={ArXiv},
  year={2023},
  volume={abs/2303.08774},
}

@article{Touvron2023Llama2O,
  title={Llama 2: Open Foundation and Fine-Tuned Chat Models},
  author={Hugo Touvron and Louis Martin and Kevin R. Stone and Peter Albert and Amjad Almahairi and Yasmine Babaei and Nikolay Bashlykov and Soumya Batra and Prajjwal Bhargava and Shruti Bhosale and Daniel M. Bikel and Lukas Blecher and Cristian Cant{\'o}n Ferrer and Moya Chen and Guillem Cucurull and David Esiobu and Jude Fernandes and Jeremy Fu and Wenyin Fu and Brian Fuller and Cynthia Gao and Vedanuj Goswami and Naman Goyal and Anthony S. Hartshorn and Saghar Hosseini and Rui Hou and Hakan Inan and Marcin Kardas and Viktor Kerkez and Madian Khabsa and Isabel M. Kloumann and A. V. Korenev and Punit Singh Koura and Marie-Anne Lachaux and Thibaut Lavril and Jenya Lee and Diana Liskovich and Yinghai Lu and Yuning Mao and Xavier Martinet and Todor Mihaylov and Pushkar Mishra and Igor Molybog and Yixin Nie and Andrew Poulton and Jeremy Reizenstein and Rashi Rungta and Kalyan Saladi and Alan Schelten and Ruan Silva and Eric Michael Smith and R. Subramanian and Xia Tan and Binh Tang and Ross Taylor and Adina Williams and Jian Xiang Kuan and Puxin Xu and Zhengxu Yan and Iliyan Zarov and Yuchen Zhang and Angela Fan and Melanie Kambadur and Sharan Narang and Aurelien Rodriguez and Robert Stojnic and Sergey Edunov and Thomas Scialom},
  journal={ArXiv},
  year={2023},
  volume={abs/2307.09288},
}

@inproceedings{de2021editing,
  title={Editing Factual Knowledge in Language Models},
  author={De Cao, Nicola and Aziz, Wilker and Titov, Ivan},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2021}
}

@article{robins1995catastrophic,
  title={Catastrophic forgetting, rehearsal and pseudorehearsal},
  author={Robins, Anthony},
  journal={Connection Science},
  volume={7},
  number={2},
  pages={123--146},
  year={1995},
  publisher={Taylor \& Francis}
}

@article{de2019episodic,
  title={Episodic memory in lifelong language learning},
  author={de Masson D'Autume, Cyprien and Ruder, Sebastian and Kong, Lingpeng and Yogatama, Dani},
  journal={Advances in Neural Information Processing Systems},
  year={2019}
}

@article{Jang2021TowardsCK,
  title={Towards Continual Knowledge Learning of Language Models},
  author={Joel Jang and Seonghyeon Ye and Sohee Yang and Joongbo Shin and Janghoon Han and Gyeonghun Kim and Stanley Jungkyu Choi and Minjoon Seo},
  journal={ArXiv},
  year={2021},
  volume={abs/2110.03215},
}


@inproceedings{jin-etal-2022-lifelong-pretraining,
    title = "Lifelong Pretraining: Continually Adapting Language Models to Emerging Corpora",
    author = "Jin, Xisen  and
      Zhang, Dejiao  and
      Zhu, Henghui  and
      Xiao, Wei  and
      Li, Shang-Wen  and
      Wei, Xiaokai  and
      Arnold, Andrew  and
      Ren, Xiang",
    booktitle = "North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    year = "2022",
}

@inproceedings{toneva2018empirical,
  title={An Empirical Study of Example Forgetting during Deep Neural Network Learning},
  author={Toneva, Mariya and Sordoni, Alessandro and des Combes, Remi Tachet and Trischler, Adam and Bengio, Yoshua and Gordon, Geoffrey J},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{tirumala2022memorization,
  title={Memorization without overfitting: Analyzing the training dynamics of large language models},
  author={Tirumala, Kushal and Markosyan, Aram and Zettlemoyer, Luke and Aghajanyan, Armen},
  journal={Advances in Neural Information Processing Systems},
  pages={38274--38290},
  year={2022}
}

@inproceedings{ramasesh2020anatomy,
  title={Anatomy of Catastrophic Forgetting: Hidden Representations and Task Semantics},
  author={Ramasesh, Vinay Venkatesh and Dyer, Ethan and Raghu, Maithra},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{maini2022characterizing,
  title={Characterizing datapoints via second-split forgetting},
  author={Maini, Pratyush and Garg, Saurabh and Lipton, Zachary and Kolter, J Zico},
  journal={Advances in Neural Information Processing Systems},
  year={2022}
}

@inproceedings{Karakida2021LearningCF,
  title={Learning curves for continual learning in neural networks: Self-knowledge transfer and forgetting},
  author={Ryo Karakida and Shotaro Akaho},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{Lewis2019BARTDS,
  title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
  author={Mike Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and Abdel-rahman Mohamed and Omer Levy and Veselin Stoyanov and Luke Zettlemoyer},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2019}
}

@article{lin2022unsupervised,
  title={Unsupervised cross-task generalization via retrieval augmentation},
  author={Lin, Bill Yuchen and Tan, Kangmin and Miller, Chris and Tian, Beiwen and Ren, Xiang},
  journal={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{chung2022scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Eric and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={arXiv preprint arXiv:2210.11416},
  year={2022}
}

@inproceedings{evron2022catastrophic,
  title={How catastrophic can catastrophic forgetting be in linear regression?},
  author={Evron, Itay and Moroshko, Edward and Ward, Rachel and Srebro, Nathan and Soudry, Daniel},
  booktitle={Conference on Learning Theory},
  pages={4028--4079},
  year={2022},
  organization={PMLR}
}


@inproceedings{Novak2022FastFW,
  title={Fast Finite Width Neural Tangent Kernel},
  author={Roman Novak and Jascha Narain Sohl-Dickstein and Samuel S. Schoenholz},
  booktitle={International Conference on Machine Learning},
  year={2022},
}



@inproceedings{yao2023editing,
  title={Editing Large Language Models: Problems, Methods, and Opportunities},
  author={Yunzhi Yao and Peng Wang and Bo Tian and Siyuan Cheng and Zhoubo Li and Shumin Deng and Huajun Chen and Ningyu Zhang},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2023},
}

@inproceedings{huang2022transformer,
  title={Transformer-Patcher: One Mistake Worth One Neuron},
  author={Huang, Zeyu and Shen, Yikang and Zhang, Xiaofeng and Zhou, Jie and Rong, Wenge and Xiong, Zhang},
  booktitle={International Conference on Learning Representations},
  year={2023}
}

@article{carranza2023deceptive,
  title={Deceptive Alignment Monitoring},
  author={Carranza, Andres and Pai, Dhruv and Schaeffer, Rylan and Tandon, Arnuv and Koyejo, Sanmi},
  journal={arXiv preprint arXiv:2307.10569},
  year={2023}
}

@inproceedings{onoe-etal-2023-lms,
    title = "Can {LM}s Learn New Entities from Descriptions? Challenges in Propagating Injected Knowledge",
    author = "Onoe, Yasumasa  and
      Zhang, Michael  and
      Padmanabhan, Shankar  and
      Durrett, Greg  and
      Choi, Eunsol",
    booktitle = "Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2023",
}

@inproceedings{Zhang2023PlugandPlayKI,
  title={Plug-and-Play Knowledge Injection for Pre-trained Language Models},
  author={Zhengyan Zhang and Zhiyuan Zeng and Yankai Lin and Huadong Wang and Deming Ye and Chaojun Xiao and Xu Han and Zhiyuan Liu and Peng Li and Maosong Sun and Jie Zhou},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2023},
}

@inproceedings{mitchell2021fast,
  title={Fast Model Editing at Scale},
  author={Mitchell, Eric and Lin, Charles and Bosselut, Antoine and Finn, Chelsea and Manning, Christopher D},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{DBLP:conf/nips/AljundiBTCCLP19,
  author       = {Rahaf Aljundi and
                  Eugene Belilovsky and
                  Tinne Tuytelaars and
                  Laurent Charlin and
                  Massimo Caccia and
                  Min Lin and
                  Lucas Page{-}Caccia},
  title        = {Online Continual Learning with Maximal Interfered Retrieval},
  booktitle    = {Advances in Neural Information Processing Systems},
  year         = {2019},
}

@article{Hartvigsen2022AgingWG,
  title={Aging with GRACE: Lifelong Model Editing with Discrete Key-Value Adaptors},
  author={Thomas Hartvigsen and Swami Sankaranarayanan and Hamid Palangi and Yoon Kim and Marzyeh Ghassemi},
  journal={ArXiv},
  year={2022},
  volume={abs/2211.11031},
}

@article{lee2019wide,
  title={Wide neural networks of any depth evolve as linear models under gradient descent},
  author={Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel and Bahri, Yasaman and Novak, Roman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
  journal={Advances in neural information processing systems},
  year={2019}
}

@article{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  journal={Advances in neural information processing systems},
  year={2018}
}

@inproceedings{
tao2023can,
title={Can {BERT} Refrain from Forgetting on Sequential Tasks? A Probing Study},
author={Mingxu Tao and Yansong Feng and Dongyan Zhao},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
}

@inproceedings{wu2021pretrained,
  title={Pretrained language model in continual learning: A comparative study},
  author={Wu, Tongtong and Caccia, Massimo and Li, Zhuang and Li, Yuan-Fang and Qi, Guilin and Haffari, Gholamreza},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{Yao2021RefiningLM,
  title={Refining Language Models with Compositional Explanations},
  author={Huihan Yao and Ying Chen and Qinyuan Ye and Xisen Jin and Xiang Ren},
  booktitle={Neural Information Processing Systems},
  year={2021},
}

@inproceedings{bach2022promptsource,
  title={PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts},
  author={Bach, Stephen and Sanh, Victor and Yong, Zheng Xin and Webson, Albert and Raffel, Colin and Nayak, Nihal V and Sharma, Abheesht and Kim, Taewoon and Bari, M Saiful and F{\'e}vry, Thibault and others},
  booktitle={Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
  year={2022}
}

@inproceedings{hendrycks2020measuring,
  title={Measuring Massive Multitask Language Understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{hu2021lora,
  title={LoRA: Low-Rank Adaptation of Large Language Models},
  author={Hu, Edward J and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{buzzega2020dark,
  title={Dark experience for general continual learning: a strong, simple baseline},
  author={Buzzega, Pietro and Boschini, Matteo and Porrello, Angelo and Abati, Davide and Calderara, Simone},
  journal={Advances in neural information processing systems},
  year={2020}
}

@article{suzgun2022challenging,
  title={Challenging big-bench tasks and whether chain-of-thought can solve them},
  author={Suzgun, Mirac and Scales, Nathan and Sch{\"a}rli, Nathanael and Gehrmann, Sebastian and Tay, Yi and Chung, Hyung Won and Chowdhery, Aakanksha and Le, Quoc V and Chi, Ed H and Zhou, Denny and others},
  journal={arXiv preprint arXiv:2210.09261},
  year={2022}
}

@inproceedings{
yoon2022online,
title={Online Coreset Selection for Rehearsal-based Continual Learning},
author={Jaehong Yoon and Divyam Madaan and Eunho Yang and Sung Ju Hwang},
booktitle={International Conference on Learning Representations},
year={2022},
}

@inproceedings{Aljundi2019GradientBS,
  title={Gradient based sample selection for online continual learning},
  author={Rahaf Aljundi and Min Lin and Baptiste Goujaud and Yoshua Bengio},
  booktitle={Neural Information Processing Systems},
  year={2019},
}

@inproceedings{LopezPaz2017GradientEM,
  title={Gradient Episodic Memory for Continual Learning},
  author={David Lopez-Paz and Marc'Aurelio Ranzato},
  booktitle={Neural Information Processing Systems},
  year={2017},
}

@inproceedings{
chaudhry2018efficient,
title={Efficient Lifelong Learning with A-{GEM}},
author={Arslan Chaudhry and Marc’Aurelio Ranzato and Marcus Rohrbach and Mohamed Elhoseiny},
booktitle={International Conference on Learning Representations},
year={2019},
}

@article{Buzzega2020RethinkingER,
  title={Rethinking Experience Replay: a Bag of Tricks for Continual Learning},
  author={Pietro Buzzega and Matteo Boschini and Angelo Porrello and Simone Calderara},
  journal={2020 25th International Conference on Pattern Recognition (ICPR)},
  year={2020},
}

@inproceedings{Doan2020ATA,
  title={A Theoretical Analysis of Catastrophic Forgetting through the NTK Overlap Matrix},
  author={Thang Van Doan and Mehdi Abbana Bennani and Bogdan Mazoure and Guillaume Rabusseau and Pierre Alquier},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2020},
}

@inproceedings{
jagielski2023measuring,
title={Measuring Forgetting of Memorized Training Examples},
author={Matthew Jagielski and Om Thakkar and Florian Tramer and Daphne Ippolito and Katherine Lee and Nicholas Carlini and Eric Wallace and Shuang Song and Abhradeep Guha Thakurta and Nicolas Papernot and Chiyuan Zhang},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
}

@article{Miller2017ExplanationIA,
  title={Explanation in Artificial Intelligence: Insights from the Social Sciences},
  author={Tim Miller},
  journal={Artif. Intell.},
  year={2017},
  volume={267},
  pages={1-38},
  }
@article{Ilyas2022DatamodelsPP,
  title={Datamodels: Predicting Predictions from Training Data},
  author={Andrew Ilyas and Sung Min Park and Logan Engstrom and Guillaume Leclerc and Aleksander Madry},
  journal={ArXiv},
  year={2022},
  volume={abs/2202.00622},
 }

@inproceedings{Ye2023HowPA,
  title={How Predictable Are Large Language Model Capabilities? A Case Study on BIG-bench},
  author={Qinyuan Ye and Harvey Yiyun Fu and Xiang Ren and Robin Jia},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2023},
}

@article{Xia2020PredictingPF,
  title={Predicting Performance for Natural Language Processing Tasks},
  author={Mengzhou Xia and Antonios Anastasopoulos and Ruochen Xu and Yiming Yang and Graham Neubig},
  journal={ArXiv},
  year={2020},
  volume={abs/2005.00870},
}

@inproceedings{farajtabar2020orthogonal,
  title={Orthogonal gradient descent for continual learning},
  author={Farajtabar, Mehrdad and Azizan, Navid and Mott, Alex and Li, Ang},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3762--3773},
  year={2020},
  organization={PMLR}
}

@inproceedings{
saha2021gradient,
title={Gradient Projection Memory for Continual Learning},
author={Gobinda Saha and Isha Garg and Kaushik Roy},
booktitle={International Conference on Learning Representations},
year={2021},
}

@inproceedings{Killamsetty2021GRADMATCHGM,
  title={GRAD-MATCH: Gradient Matching based Data Subset Selection for Efficient Deep Model Training},
  author={Krishnateja Killamsetty and Durga Sivasubramanian and Ganesh Ramakrishnan and Abir De and Rishabh K. Iyer},
  booktitle={International Conference on Machine Learning},
  year={2021},
  
}

@inproceedings{Mirzasoleiman2019CoresetsFD,
  title={Coresets for Data-efficient Training of Machine Learning Models},
  author={Baharan Mirzasoleiman and Jeff A. Bilmes and Jure Leskovec},
  booktitle={International Conference on Machine Learning},
  year={2019},
}

@inproceedings{KleimanPredictingTF,
  title={Predicting Task Forgetting in Large Language Models},
  author={Anat Kleiman and Jonathan Frankle and Sham M. Kakade and Mansheej Paul},
  booktitle={ICML Workshop DeployableGenerativeAI homepage},
  year={2023}
}