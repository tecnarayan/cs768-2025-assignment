\begin{thebibliography}{25}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aronszajn(1950)]{Aronszajn50}
Aronszajn, N.
\newblock Theory of reproducing kernels.
\newblock \emph{Transactions of the American Mathematical Society},
  68(3):\penalty0 337--404, 1950.

\bibitem[Arora et~al.(2012)Arora, Ge, and Moitra]{Arora+12}
Arora, S., Ge, R., and Moitra, A.
\newblock Learning topic models -- going beyond {SVD}.
\newblock In \emph{Proceedings of IEEE Foundations of Computer Science (FOCS)},
  pp.\  1--10, 2012.

\bibitem[Berlinet \& Thomas(2004)Berlinet and Thomas]{BerlinetThomas04}
Berlinet, A. and Thomas, C.
\newblock \emph{Reproducing kernel Hilbert spaces in Probability and
  Statistics}.
\newblock Kluwer Academic Publishers, 2004.

\bibitem[Blanchard et~al.(2010)Blanchard, Lee, and Scott]{Blanchard+10}
Blanchard, G., Lee, G., and Scott, C.
\newblock Semi-supervised novelty detection.
\newblock \emph{Journal of Machine Learning Research}, 11:\penalty0 2973--3009,
  2010.

\bibitem[Bouveyron \& Girard(2009)Bouveyron and Girard]{BouveyGir09}
Bouveyron, C. and Girard, S.
\newblock Robust supervised classification with mixture models: Learning from
  data with uncertain labels.
\newblock \emph{Journal of Pattern Recognition}, 42:\penalty0 2649--2658, 2009.

\bibitem[Denis et~al.(2005)Denis, Gilleron, and Letouzey]{Denis+05}
Denis, F., Gilleron, R., and Letouzey, F.
\newblock Learning from positive and unlabeled examples.
\newblock \emph{Theoretical Computer Science}, 348\penalty0 (1):\penalty0
  70--83, 2005.

\bibitem[du~Plessis \& Sugiyama(2014)du~Plessis and Sugiyama]{duPlessisSugi14}
du~Plessis, M.~C. and Sugiyama, M.
\newblock Class prior estimation from positive and unlabeled data.
\newblock \emph{IEICE Transactions on Information and Systems}, 97:\penalty0
  1358--1362, 2014.

\bibitem[Elkan \& Noto(2008)Elkan and Noto]{ElkanNoto08}
Elkan, C. and Noto, K.
\newblock Learning classifiers from only positive and unlabeled data.
\newblock In \emph{Proceedings of the 14th ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining (KDD08)}, pp.\  213--220, 2008.

\bibitem[Gretton et~al.(2012)Gretton, Borgwardt, Rasch, Scholkopf, and
  Smola]{Gretton+12}
Gretton, A., Borgwardt, K.~M., Rasch, M.~J., Scholkopf, B., and Smola, A.
\newblock A kernel two-sample test.
\newblock \emph{Journal of Machine Learning Research}, 13:\penalty0 723--773,
  2012.

\bibitem[Jain et~al.(2016)Jain, White, Trosset, and Radivojac]{Jain+16}
Jain, S., White, M., Trosset, M.~W., and Radivojac, P.
\newblock Nonparametric semi-supervised learning of class proportions.
\newblock \emph{arXiv:1601.01944}, 2016.

\bibitem[Lawrence \& Scholkopf(2001)Lawrence and Scholkopf]{LawrSchol01}
Lawrence, N. and Scholkopf, B.
\newblock Estimating a kernel {Fisher} discriminant in the presence of label
  noise.
\newblock In \emph{Proc. of the Int. Conf. in Machine Learning (ICML)}, 2001.

\bibitem[Liu et~al.(2002)Liu, Lee, Yu, and Li]{Liu+02}
Liu, B., Lee, W.~S., Yu, P.~S., and Li, X.
\newblock Partially supervised classification of text documents.
\newblock In \emph{Proc. of the Int. Conf. on Machine Learning (ICML)}, pp.\
  387--394, 2002.

\bibitem[Liu \& Tao(2016)Liu and Tao]{LiuTao15}
Liu, T. and Tao, D.
\newblock Classification with noisy labels by importance reweighting.
\newblock \emph{IEEE Transactions on pattern analysis and machine
  intelligence}, 38(3):\penalty0 447--461, 2016.

\bibitem[Long \& Servido(2010)Long and Servido]{LongServ10}
Long, P. and Servido, R.
\newblock Random classification noise defeats all convex potential boosters.
\newblock \emph{Machine Learning}, 78:\penalty0 287--304, 2010.

\bibitem[Menon et~al.(2015)Menon, van Rooyen, Ong, and Williamson]{Menon+15}
Menon, A.~K., van Rooyen, B., Ong, C.~S., and Williamson, R.~C.
\newblock Learning from corrupted binary labels via class-probability
  estimation.
\newblock In \emph{In Proc. of the Int. Conf. in Machine Learning (ICML)}, pp.\
   125--134, 2015.

\bibitem[Michelli et~al.(2006)Michelli, Xu, and Zhang]{Michelli+06}
Michelli, C., Xu, Y., and Zhang, H.
\newblock Universal kernels.
\newblock \emph{Journal of Machine Learning Research}, 7:\penalty0 2651--2667,
  2006.

\bibitem[Natarajan et~al.(2013)Natarajan, Dhillon, Ravikumar, and
  Tewari]{Natarajan+13}
Natarajan, N., Dhillon, I.~S., Ravikumar, P., and Tewari, A.
\newblock Learning with noisy labels.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)
  26}, pp.\  1196--1204, 2013.

\bibitem[Raykar et~al.(2010)Raykar, Yu, Zhao, Valadez, Florin, Bogoni, and
  Moy]{Raykar+10}
Raykar, V.~C., Yu, S., Zhao, L.~H., Valadez, G.~H., Florin, C., Bogoni, L., and
  Moy, L.
\newblock Learning from crowds.
\newblock \emph{The Journal of Machine Learning Research}, 11:\penalty0
  1297--1322, 2010.

\bibitem[Sanderson \& Scott(2014)Sanderson and Scott]{SandersonSc14}
Sanderson, T. and Scott, C.
\newblock Class proportion estimation with application to multiclass anomaly
  rejection.
\newblock In \emph{Proc. of the 17th Int. Conf. on Artificial Intelligence and
  Statistics (AISTATS)}, 2014.

\bibitem[Scott(2015)]{Scott15}
Scott, C.
\newblock A rate of convergence for mixture proportion estimation, with
  application to learning from noisy labels.
\newblock In \emph{Proc. of the Int. Conf. on Artificial Intelligence and
  Statistics (AISTATS)}, 2015.

\bibitem[Scott et~al.(2013{\natexlab{a}})Scott, Blanchard, and Handy]{Scott+13}
Scott, C., Blanchard, G., and Handy, G.
\newblock Classification with asymmetric label noise: Consistency and maximal
  denoising.
\newblock In \emph{Proc. Conf. on Learning Theory, {\em JMLR W\&CP}},
  volume~30, pp.\  489--511. 2013{\natexlab{a}}.

\bibitem[Scott et~al.(2013{\natexlab{b}})Scott, Blanchard, Handy, Pozzi, and
  Flaska]{Scott+13b}
Scott, C., Blanchard, G., Handy, G., Pozzi, S., and Flaska, M.
\newblock Classification with asymmetric label noise: Consistency and maximal
  denoising.
\newblock Technical Report arXiv:1303.1208, 2013{\natexlab{b}}.

\bibitem[Smola et~al.(2007)Smola, Gretton, Song, and Scholkopf]{Smola+07}
Smola, A., Gretton, A., Song, L., and Scholkopf, B.
\newblock A {Hilbert} space embedding for distributions.
\newblock In \emph{Algorithmic Learning Theory (ALT)}, 2007.

\bibitem[Stempfel \& Ralaivola(2009)Stempfel and Ralaivola]{StemRal09}
Stempfel, G. and Ralaivola, L.
\newblock Learning {SVM}s from sloppily labeled data.
\newblock In \emph{Proc. 19th Int. Conf. on Artificial Neural Networks: Part
  I}, pp.\  884--893, 2009.

\bibitem[Ward et~al.(2009)Ward, Hastie, Barry, Elith, and Leathwick]{Ward+09}
Ward, G., Hastie, T., Barry, S., Elith, J., and Leathwick, J.~R.
\newblock Presence-only data and the {EM} algorithm.
\newblock \emph{Biometrics}, 65:\penalty0 554--564, 2009.

\end{thebibliography}
