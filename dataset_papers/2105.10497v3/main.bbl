\begin{thebibliography}{10}

\bibitem{khan2021transformers}
Salman Khan, Muzammal Naseer, Munawar Hayat, Syed~Waqas Zamir, Fahad~Shahbaz
  Khan, and Mubarak Shah.
\newblock Transformers in vision: A survey.
\newblock {\em arXiv preprint arXiv:2101.01169}, 2021.

\bibitem{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock {\em arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{touvron2020deit}
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre
  Sablayrolles, and Herv\'e J\'egou.
\newblock Training data-efficient image transformers \& distillation through
  attention.
\newblock {\em arXiv preprint arXiv:2012.12877}, 2020.

\bibitem{yuan2021tokens}
Li~Yuan, Yunpeng Chen, Tao Wang, Weihao Yu, Yujun Shi, Francis~EH Tay, Jiashi
  Feng, and Shuicheng Yan.
\newblock Tokens-to-token vit: Training vision transformers from scratch on
  imagenet.
\newblock {\em arXiv preprint arXiv:2101.11986}, 2021.

\bibitem{ramachandran2019stand}
Prajit Ramachandran, Niki Parmar, Ashish Vaswani, Irwan Bello, Anselm Levskaya,
  and Jonathon Shlens.
\newblock Stand-alone self-attention in vision models.
\newblock {\em arXiv preprint arXiv:1906.05909}, 2019.

\bibitem{hu2019local}
Han Hu, Zheng Zhang, Zhenda Xie, and Stephen Lin.
\newblock Local relation networks for image recognition.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition},
  pages 3464--3473, 2019.

\bibitem{vaswani2021scaling}
Ashish Vaswani, Prajit Ramachandran, Aravind Srinivas, Niki Parmar, Blake
  Hechtman, and Jonathon Shlens.
\newblock Scaling local self-attention for parameter efficient visual
  backbones.
\newblock {\em arXiv preprint arXiv:2103.12731}, 2021.

\bibitem{ILSVRC15}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein,
  Alexander~C. Berg, and Li~Fei-Fei.
\newblock {ImageNet Large Scale Visual Recognition Challenge}.
\newblock {\em International Journal of Computer Vision}, 115(3):211--252,
  2015.

\bibitem{geirhos2018imagenet}
Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix~A
  Wichmann, and Wieland Brendel.
\newblock Imagenet-trained cnns are biased towards texture; increasing shape
  bias improves accuracy and robustness.
\newblock {\em arXiv preprint arXiv:1811.12231}, 2018.

\bibitem{mummadi2021does}
Chaithanya~Kumar Mummadi, Ranjitha Subramaniam, Robin Hutmacher, Julien Vitay,
  Volker Fischer, and Jan~Hendrik Metzen.
\newblock Does enhanced shape bias improve neural network robustness to common
  corruptions?
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{szegedy2013intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock {\em arXiv preprint arXiv:1312.6199}, 2013.

\bibitem{naseer2019cross}
Muzammal Naseer, Salman~H Khan, Harris Khan, Fahad~Shahbaz Khan, and Fatih
  Porikli.
\newblock Cross-domain transferability of adversarial perturbations.
\newblock {\em Advances in Neural Information Processing Systems}, 2019.

\bibitem{hendrycks2019benchmarking}
Dan Hendrycks and Thomas Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock {\em arXiv preprint arXiv:1903.12261}, 2019.

\bibitem{li2017deeper}
Da~Li, Yongxin Yang, Yi-Zhe Song, and Timothy~M Hospedales.
\newblock Deeper, broader and artier domain generalization.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition},
  pages 5542--5550, 2017.

\bibitem{shao2021adversarial}
Rulin Shao, Zhouxing Shi, Jinfeng Yi, Pin-Yu Chen, and Cho-Jui Hsieh.
\newblock On the adversarial robustness of visual transformers.
\newblock {\em arXiv preprint arXiv:2103.15670}, 2021.

\bibitem{bhojanapalli2021understanding}
Srinadh Bhojanapalli, Ayan Chakrabarti, Daniel Glasner, Daliang Li, Thomas
  Unterthiner, and Andreas Veit.
\newblock Understanding robustness of transformers for image classification.
\newblock {\em arXiv preprint arXiv:2103.14586}, 2021.

\bibitem{brown2017adversarial}
Tom~B Brown, Dandelion Man{\'e}, Aurko Roy, Mart{\'\i}n Abadi, and Justin
  Gilmer.
\newblock Adversarial patch.
\newblock {\em arXiv preprint arXiv:1712.09665}, 2017.

\bibitem{paul2021vision}
Sayak Paul and Pin-Yu Chen.
\newblock Vision transformers are robust learners.
\newblock {\em arXiv preprint arXiv:2105.07581}, 2021.

\bibitem{brendel2019approximating}
Wieland Brendel and Matthias Bethge.
\newblock Approximating cnns with bag-of-local-features models works
  surprisingly well on imagenet.
\newblock {\em arXiv preprint arXiv:1904.00760}, 2019.

\bibitem{islam2021shape}
Md~Amirul Islam, Matthew Kowal, Patrick Esser, Sen Jia, Bjorn Ommer,
  Konstantinos~G Derpanis, and Neil Bruce.
\newblock Shape or texture: Understanding discriminative features in cnns.
\newblock {\em arXiv preprint arXiv:2101.11604}, 2021.

\bibitem{foster2011lower}
David~V Foster and Peter Grassberger.
\newblock Lower bounds on mutual information.
\newblock {\em Physical Review E}, 83(1):010101, 2011.

\bibitem{tuli2021convolutional}
Shikhar Tuli, Ishita Dasgupta, Erin Grant, and Thomas~L. Griffiths.
\newblock Are convolutional neural networks or transformers more like human
  vision?
\newblock {\em arXiv preprint arXiv:2105.07197}, 2021.

\bibitem{caron2021emerging}
Mathilde Caron, Hugo Touvron, Ishan Misra, Herv{\'e} J{\'e}gou, Julien Mairal,
  Piotr Bojanowski, and Armand Joulin.
\newblock Emerging properties in self-supervised vision transformers.
\newblock {\em arXiv preprint arXiv:2104.14294}, 2021.

\bibitem{zeiler2014visualizing}
Matthew~D Zeiler and Rob Fergus.
\newblock Visualizing and understanding convolutional networks.
\newblock In {\em European Conference on Computer Vision}, pages 818--833.
  Springer, 2014.

\bibitem{yang2013saliency}
Chuan Yang, Lihe Zhang, Huchuan Lu, Xiang Ruan, and Ming-Hsuan Yang.
\newblock Saliency detection via graph-based manifold ranking.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition},
  pages 3166--3173, 2013.

\bibitem{mao2021transformer}
Yuxin Mao, Jing Zhang, Zhexiong Wan, Yuchao Dai, Aixuan Li, Yunqiu Lv, Xinyu
  Tian, Deng-Ping Fan, and Nick Barnes.
\newblock Transformer transforms salient object detection and camouflaged
  object detection.
\newblock {\em arXiv preprint arXiv:2104.10127}, 2021.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em arXiv preprint arXiv:1706.03762}, 2017.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition},
  pages 770--778, 2016.

\bibitem{forsyth2018probability}
David Forsyth.
\newblock {\em Probability and statistics for computer science}.
\newblock Springer, 2018.

\bibitem{hinton2015distilling}
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean.
\newblock Distilling the knowledge in a neural network.
\newblock {\em arXiv preprint arXiv:1503.02531}, 2015.

\bibitem{hochreiter1997long}
Sepp Hochreiter and J{\"u}rgen Schmidhuber.
\newblock Long short-term memory.
\newblock {\em Neural Computation}, 9(8):1735--1780, 1997.

\bibitem{irie2019language}
Kazuki Irie, Albert Zeyer, Ralf Schl{\"u}ter, and Hermann Ney.
\newblock Language modeling with deep transformers.
\newblock {\em arXiv preprint arXiv:1905.04226}, 2019.

\bibitem{hendrycks2020augmix}
Dan Hendrycks, Norman Mu, Ekin~D. Cubuk, Barret Zoph, Justin Gilmer, and Balaji
  Lakshminarayanan.
\newblock {AugMix}: A simple data processing method to improve robustness and
  uncertainty.
\newblock {\em International Conference on Learning Representations}, 2020.

\bibitem{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In {\em International Conference on Learning Representations}, 2014.

\bibitem{madry2017towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{Razavian2014}
A.~Razavian, Hossein Azizpour, J.~Sullivan, and S.~Carlsson.
\newblock Cnn features off-the-shelf: An astounding baseline for recognition.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  Workshops}, pages 512--519, 2014.

\bibitem{cub}
P.~Welinder, S.~Branson, T.~Mita, C.~Wah, F.~Schroff, S.~Belongie, and
  P.~Perona.
\newblock {Caltech-UCSD Birds 200}.
\newblock Technical Report CNS-TR-2010-001, California Institute of Technology,
  2010.

\bibitem{Nilsback08}
M-E. Nilsback and A.~Zisserman.
\newblock Automated flower classification over a large number of classes.
\newblock In {\em Indian Conference on Computer Vision, Graphics and Image
  Processing}, 2008.

\bibitem{van2018inaturalist}
Grant Van~Horn, Oisin Mac~Aodha, Yang Song, Yin Cui, Chen Sun, Alex Shepard,
  Hartwig Adam, Pietro Perona, and Serge Belongie.
\newblock The inaturalist species classification and detection dataset.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition},
  pages 8769--8778, 2018.

\bibitem{aircraft}
S.~Maji, J.~Kannala, E.~Rahtu, M.~Blaschko, and A.~Vedaldi.
\newblock Fine-grained visual classification of aircraft.
\newblock Technical report, 2013.

\bibitem{dtd}
M.~Cimpoi, S.~Maji, I.~Kokkinos, S.~Mohamed, , and A.~Vedaldi.
\newblock Describing textures in the wild.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition},
  pages 3606--3613, 2014.

\bibitem{gtsrb}
Sebastian Houben, Johannes Stallkamp, Jan Salmen, Marc Schlipsing, and
  Christian Igel.
\newblock Detection of traffic signs in real-world images: The {G}erman
  {T}raffic {S}ign {D}etection {B}enchmark.
\newblock In {\em International Joint Conference on Neural Networks}, 2013.

\bibitem{fungi_dataset}
Brigit Schroeder and Yin Cui.
\newblock Fgvcx fungi classification challenge 2018.
\newblock In {\em \url{github.com/visipedia/fgvcx_fungi_comp, 2018}}.

\bibitem{zhou2017places}
Bolei Zhou, Agata Lapedriza, Aditya Khosla, Aude Oliva, and Antonio Torralba.
\newblock Places: A 10 million image database for scene recognition.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  40(6):1452--1464, 2017.

\bibitem{meta_dataset}
Eleni Triantafillou, Tyler Zhu, Vincent Dumoulin, Pascal Lamblin, Kelvin Xu,
  Ross Goroshin, Carles Gelada, Kevin Swersky, Pierre{-}Antoine Manzagol, and
  Hugo Larochelle.
\newblock Meta-dataset: {A} dataset of datasets for learning to learn from few
  examples.
\newblock {\em http://arxiv.org/abs/1903.03096}, abs/1903.03096, 2019.

\bibitem{yonglong_rfs}
Yonglong Tian, Yue Wang, Dilip Krishnan, Joshua~B Tenenbaum, and Phillip Isola.
\newblock Rethinking few-shot image classification: a good embedding is all you
  need?
\newblock {\em arXiv preprint arXiv:2003.11539}, 2020.

\bibitem{yang2019fairer}
Kaiyu Yang, Klint Qinami, Li~Fei-Fei, Jia Deng, and Olga Russakovsky.
\newblock Towards fairer datasets: Filtering and balancing the distribution of
  the people subtree in the imagenet hierarchy.
\newblock In {\em ACM Conference on Fairness, Accountability, and
  Transparency}, pages 547--558, 2020.

\bibitem{yang2021study}
Kaiyu Yang, Jacqueline Yau, Li~Fei-Fei, Jia Deng, and Olga Russakovsky.
\newblock A study of face obfuscation in imagenet.
\newblock {\em arXiv preprint arXiv:2103.06191}, 2021.

\bibitem{liu2021Swin}
Ze~Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock {\em IEEE International Conference on Computer Vision}, 2021.

\bibitem{radosavovic2020designing}
Ilija Radosavovic, Raj~Prateek Kosaraju, Ross Girshick, Kaiming He, and Piotr
  Doll{\'a}r.
\newblock Designing network design spaces.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition},
  2020.

\end{thebibliography}
