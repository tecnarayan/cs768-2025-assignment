\begin{thebibliography}{}

\bibitem[Bengio et~al., 2003]{bengio2003neural}
Bengio, Y., Ducharme, R., Vincent, P., and Jauvin, C. (2003).
\newblock A neural probabilistic language model.
\newblock {\em Journal of machine learning research}, 3(Feb):1137--1155.

\bibitem[Bengio et~al., 2013]{bengio2013estimating}
Bengio, Y., L{\'e}onard, N., and Courville, A. (2013).
\newblock Estimating or propagating gradients through stochastic neurons for
  conditional computation.
\newblock {\em arXiv preprint arXiv:1308.3432}.

\bibitem[Berglund et~al., 2015]{berglund2015bidirectional}
Berglund, M., Raiko, T., Honkala, M., K{\"a}rkk{\"a}inen, L., Vetek, A., and
  Karhunen, J.~T. (2015).
\newblock Bidirectional recurrent neural networks as generative models.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  856--864.

\bibitem[Bowman et~al., 2015]{bowman2015generating}
Bowman, S.~R., Vilnis, L., Vinyals, O., Dai, A.~M., Jozefowicz, R., and Bengio,
  S. (2015).
\newblock Generating sentences from a continuous space.
\newblock {\em arXiv preprint arXiv:1511.06349}.

\bibitem[Britz et~al., 2017]{britz2017massive}
Britz, D., Goldie, A., Luong, M.-T., and Le, Q. (2017).
\newblock Massive exploration of neural machine translation architectures.
\newblock {\em arXiv preprint arXiv:1703.03906}.

\bibitem[Devlin et~al., 2018]{devlin2018bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2018).
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock {\em arXiv preprint arXiv:1810.04805}.

\bibitem[Dinh et~al., 2014]{dinh2014nice}
Dinh, L., Krueger, D., and Bengio, Y. (2014).
\newblock {NICE}: Non-linear independent components estimation.
\newblock {\em arXiv preprint arXiv:1410.8516}.

\bibitem[Dinh et~al., 2017]{dinh2017density}
Dinh, L., Sohl-Dickstein, J., and Bengio, S. (2017).
\newblock Density estimation using real nvp.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Ford et~al., 2018]{ford2018importance}
Ford, N., Duckworth, D., Norouzi, M., and Dahl, G.~E. (2018).
\newblock The importance of generation order in language modeling.
\newblock In {\em Empirical Methods in Natural Language Processing}.

\bibitem[Gu et~al., 2018]{gu2018non}
Gu, J., Bradbury, J., Xiong, C., Li, V.~O., and Socher, R. (2018).
\newblock Non-autoregressive neural machine translation.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Hoogeboom et~al., 2019]{hoogeboom2019integer}
Hoogeboom, E., Peters, J.~W., van~den Berg, R., and Welling, M. (2019).
\newblock Integer discrete flows and lossless compression.
\newblock {\em arXiv preprint arXiv:1905.07376}.

\bibitem[Jang et~al., 2017]{jang2017categorical}
Jang, E., Gu, S., and Poole, B. (2017).
\newblock Categorical reparameterization with gumbel-softmax.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Jernite et~al., 2015]{jernite2015fast}
Jernite, Y., Rush, A., and Sontag, D. (2015).
\newblock A fast variational approach for learning markov random field language
  models.
\newblock In {\em International Conference on Machine Learning}, pages
  2209--2217.

\bibitem[Kaiser et~al., 2018]{kaiser2018fast}
Kaiser, {\L}., Roy, A., Vaswani, A., Pamar, N., Bengio, S., Uszkoreit, J., and
  Shazeer, N. (2018).
\newblock Fast decoding in sequence models using discrete latent variables.
\newblock {\em arXiv preprint arXiv:1803.03382}.

\bibitem[Kingma and Dhariwal, 2018]{kingma2018glow}
Kingma, D.~P. and Dhariwal, P. (2018).
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  10236--10245.

\bibitem[Kingma et~al., 2016a]{kingma2016improved}
Kingma, D.~P., Salimans, T., Jozefowicz, R., Chen, X., Sutskever, I., and
  Welling, M. (2016a).
\newblock Improved variational inference with inverse autoregressive flow.
\newblock In {\em Advances in neural information processing systems}, pages
  4743--4751.

\bibitem[Kingma et~al., 2016b]{kingma2016improving}
Kingma, D.~P., Salimans, T., and Welling, M. (2016b).
\newblock {Improving Variational Inference with Inverse Autoregressive Flow}.
\newblock In {\em Neural Information Processing Systems}.

\bibitem[Lee et~al., 2018]{lee2018deterministic}
Lee, J., Mansimov, E., and Cho, K. (2018).
\newblock Deterministic non-autoregressive neural sequence modeling by
  iterative refinement.
\newblock {\em arXiv preprint arXiv:1802.06901}.

\bibitem[Maddison et~al., 2016]{maddison2016concrete}
Maddison, C.~J., Mnih, A., and Teh, Y.~W. (2016).
\newblock The concrete distribution: A continuous relaxation of discrete random
  variables.
\newblock {\em arXiv preprint arXiv:1611.00712}.

\bibitem[Merity et~al., 2018]{merity2018analysis}
Merity, S., Keskar, N.~S., and Socher, R. (2018).
\newblock An analysis of neural language modeling at multiple scales.
\newblock {\em arXiv preprint arXiv:1803.08240}.

\bibitem[Metz et~al., 2016]{metz2016unrolled}
Metz, L., Poole, B., Pfau, D., and Sohl-Dickstein, J. (2016).
\newblock Unrolled generative adversarial networks.
\newblock {\em arXiv preprint arXiv:1611.02163}.

\bibitem[Mikolov et~al., 2012]{mikolov2012subword}
Mikolov, T., Sutskever, I., Deoras, A., Le, H.-S., Kombrink, S., and Cernocky,
  J. (2012).
\newblock Subword language modeling with neural networks.
\newblock {\em preprint (http://www. fit. vutbr. cz/imikolov/rnnlm/char. pdf)},
  8.

\bibitem[Mnih and Teh, 2012]{mnih2012fast}
Mnih, A. and Teh, Y.~W. (2012).
\newblock A fast and simple algorithm for training neural probabilistic
  language models.
\newblock {\em arXiv preprint arXiv:1206.6426}.

\bibitem[Oord et~al., 2017]{oord2017parallel}
Oord, A. v.~d., Li, Y., Babuschkin, I., Simonyan, K., Vinyals, O., Kavukcuoglu,
  K., Driessche, G. v.~d., Lockhart, E., Cobo, L.~C., Stimberg, F., et~al.
  (2017).
\newblock Parallel wavenet: Fast high-fidelity speech synthesis.
\newblock {\em arXiv preprint arXiv:1711.10433}.

\bibitem[Papamakarios et~al., 2017]{papamakarios2017masked}
Papamakarios, G., Murray, I., and Pavlakou, T. (2017).
\newblock Masked autoregressive flow for density estimation.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2335--2344.

\bibitem[Ping et~al., 2018]{ping2018clarinet}
Ping, W., Peng, K., and Chen, J. (2018).
\newblock Clarinet: Parallel wave generation in end-to-end text-to-speech.
\newblock {\em arXiv preprint arXiv:1807.07281}.

\bibitem[Prenger et~al., 2018]{prenger2018waveglow}
Prenger, R., Valle, R., and Catanzaro, B. (2018).
\newblock Waveglow: A flow-based generative network for speech synthesis.
\newblock {\em arXiv preprint arXiv:1811.00002}.

\bibitem[Ranganath et~al., 2016]{ranganath2016hierarchical}
Ranganath, R., Tran, D., and Blei, D. (2016).
\newblock Hierarchical variational models.
\newblock In {\em International Conference on Machine Learning}, pages
  324--333.

\bibitem[Reed et~al., 2017]{reed2017parallel}
Reed, S., van~den Oord, A., Kalchbrenner, N., Colmenarejo, S.~G., Wang, Z.,
  Chen, Y., Belov, D., and de~Freitas, N. (2017).
\newblock Parallel multiscale autoregressive density estimation.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 2912--2921. JMLR. org.

\bibitem[Rezende and Mohamed, 2015]{rezende2015variational}
Rezende, D.~J. and Mohamed, S. (2015).
\newblock Variational inference with normalizing flows.
\newblock In {\em International Conference on Machine Learning}.

\bibitem[Rippel and Adams, 2013]{rippel2013high}
Rippel, O. and Adams, R.~P. (2013).
\newblock High-dimensional probability estimation with deep density models.
\newblock {\em arXiv preprint arXiv:1302.5125}.

\bibitem[Salmon et~al., 2011]{salmon2011parallel}
Salmon, J.~K., Moraes, M.~A., Dror, R.~O., and Shaw, D.~E. (2011).
\newblock Parallel random numbers: as easy as 1, 2, 3.
\newblock In {\em Proceedings of 2011 International Conference for High
  Performance Computing, Networking, Storage and Analysis}, page~16. ACM.

\bibitem[Stern et~al., 2018]{stern2018blockwise}
Stern, M., Shazeer, N., and Uszkoreit, J. (2018).
\newblock Blockwise parallel decoding for deep autoregressive models.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  10107--10116.

\bibitem[Tabak and Turner, 2013]{tabak2013family}
Tabak, E. and Turner, C.~V. (2013).
\newblock A family of nonparametric density estimation algorithms.
\newblock {\em Communications on Pure and Applied Mathematics}, 66(2):145--164.

\bibitem[Tran et~al., 2018]{tran2018bayesian}
Tran, D., Mike, D., van~der Wilk, M., and Hafner, D. (2018).
\newblock Bayesian layers: A module for neural network uncertainty.
\newblock {\em arXiv preprint arXiv:1812.03973}.

\bibitem[Vaswani et~al., 2017]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, {\L}., and Polosukhin, I. (2017).
\newblock Attention is all you need.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  5998--6008.

\bibitem[Vinyals et~al., 2015]{vinyals2015order}
Vinyals, O., Bengio, S., and Kudlur, M. (2015).
\newblock Order matters: Sequence to sequence for sets.
\newblock {\em arXiv preprint arXiv:1511.06391}.

\bibitem[Wu, 1982]{wu1982potts}
Wu, F.-Y. (1982).
\newblock The potts model.
\newblock {\em Reviews of modern physics}, 54(1):235.

\bibitem[Xia et~al., 2017]{xia2017deliberation}
Xia, Y., Tian, F., Wu, L., Lin, J., Qin, T., Yu, N., and Liu, T.-Y. (2017).
\newblock Deliberation networks: Sequence generation beyond one-pass decoding.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1784--1794.

\bibitem[Zaremba and Sutskever, 2014]{zaremba2014learning}
Zaremba, W. and Sutskever, I. (2014).
\newblock Learning to execute.
\newblock {\em arXiv preprint arXiv:1410.4615}.

\bibitem[Zhang et~al., 2016]{zhang2016architectural}
Zhang, S., Wu, Y., Che, T., Lin, Z., Memisevic, R., Salakhutdinov, R.~R., and
  Bengio, Y. (2016).
\newblock Architectural complexity measures of recurrent neural networks.
\newblock In {\em Advances in neural information processing systems}, pages
  1822--1830.

\bibitem[Ziegler and Rush, 2019]{ziegler2019latent}
Ziegler, Z.~M. and Rush, A.~M. (2019).
\newblock Latent normalizing flows for discrete sequences.
\newblock {\em arXiv preprint arXiv:1901.10548}.

\end{thebibliography}
