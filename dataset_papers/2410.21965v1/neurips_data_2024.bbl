\begin{thebibliography}{50}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ouyang et~al.(2022)Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin, Zhang, Agarwal, Slama, Ray, et~al.]{ouyang2022training}
Long Ouyang, Jeffrey Wu, Xu~Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et~al.
\newblock Training language models to follow instructions with human feedback.
\newblock \emph{Advances in neural information processing systems}, 35:\penalty0 27730--27744, 2022.

\bibitem[The()]{TheC3}
The claude 3 model family: Opus, sonnet, haiku.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:268232499}.

\bibitem[Touvron et~al.(2023)Touvron, Martin, Stone, Albert, Almahairi, Babaei, Bashlykov, Batra, Bhargava, Bhosale, Bikel, Blecher, Ferrer, Chen, Cucurull, Esiobu, Fernandes, Fu, Fu, Fuller, Gao, Goswami, Goyal, Hartshorn, Hosseini, Hou, Inan, Kardas, Kerkez, Khabsa, Kloumann, Korenev, Koura, Lachaux, Lavril, Lee, Liskovich, Lu, Mao, Martinet, Mihaylov, Mishra, Molybog, Nie, Poulton, Reizenstein, Rungta, Saladi, Schelten, Silva, Smith, Subramanian, Tan, Tang, Taylor, Williams, Kuan, Xu, Yan, Zarov, Zhang, Fan, Kambadur, Narang, Rodriguez, Stojnic, Edunov, and Scialom]{Touvron2023Llama2O}
Hugo Touvron, Louis Martin, Kevin~R. Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Daniel~M. Bikel, Lukas Blecher, Cristian~Cant{\'o}n Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony~S. Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel~M. Kloumann, A.~V. Korenev, Punit~Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric~Michael Smith, R.~Subramanian, Xia Tan, Binh Tang, Ross Taylor, Adina Williams, Jian~Xiang Kuan, Puxin Xu, Zhengxu Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and
  Thomas Scialom.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock \emph{ArXiv}, abs/2307.09288, 2023.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:259950998}.

\bibitem[Mo et~al.(2023{\natexlab{a}})Mo, Wang, Chen, and Sun]{mo2023trustworthy}
Lingbo Mo, Boshi Wang, Muhao Chen, and Huan Sun.
\newblock How trustworthy are open-source llms? an assessment under malicious demonstrations shows their vulnerabilities.
\newblock \emph{arXiv preprint arXiv:2311.09447}, 2023{\natexlab{a}}.

\bibitem[Bhatt et~al.(2023)Bhatt, Chennabasappa, Nikolaidis, Wan, Evtimov, Gabi, Song, Ahmad, Aschermann, Fontana, et~al.]{bhatt2023purple}
Manish Bhatt, Sahana Chennabasappa, Cyrus Nikolaidis, Shengye Wan, Ivan Evtimov, Dominik Gabi, Daniel Song, Faizan Ahmad, Cornelius Aschermann, Lorenzo Fontana, et~al.
\newblock Purple llama cyberseceval: A secure coding benchmark for language models.
\newblock \emph{arXiv preprint arXiv:2312.04724}, 2023.

\bibitem[Yuan et~al.(2024)Yuan, He, Dong, Wang, Zhao, Xia, Xu, Zhou, Li, Zhang, et~al.]{yuan2024r}
Tongxin Yuan, Zhiwei He, Lingzhong Dong, Yiming Wang, Ruijie Zhao, Tian Xia, Lizhen Xu, Binglin Zhou, Fangqi Li, Zhuosheng Zhang, et~al.
\newblock R-judge: Benchmarking safety risk awareness for llm agents.
\newblock \emph{arXiv preprint arXiv:2401.10019}, 2024.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Li, Han, Nakov, and Baldwin]{wang2023not}
Yuxia Wang, Haonan Li, Xudong Han, Preslav Nakov, and Timothy Baldwin.
\newblock Do-not-answer: A dataset for evaluating safeguards in llms.
\newblock \emph{arXiv preprint arXiv:2308.13387}, 2023{\natexlab{a}}.

\bibitem[Zou et~al.(2023)Zou, Wang, Kolter, and Fredrikson]{zou2023universal}
Andy Zou, Zifan Wang, J~Zico Kolter, and Matt Fredrikson.
\newblock Universal and transferable adversarial attacks on aligned language models.
\newblock \emph{arXiv preprint arXiv:2307.15043}, 2023.

\bibitem[Zhang et~al.(2023)Zhang, Lei, Wu, Sun, Huang, Long, Liu, Lei, Tang, and Huang]{zhang2023safetybench}
Zhexin Zhang, Leqi Lei, Lindong Wu, Rui Sun, Yongkang Huang, Chong Long, Xiao Liu, Xuanyu Lei, Jie Tang, and Minlie Huang.
\newblock Safetybench: Evaluating the safety of large language models with multiple choice questions.
\newblock \emph{arXiv preprint arXiv:2309.07045}, 2023.

\bibitem[Wei et~al.(2024)Wei, Haghtalab, and Steinhardt]{wei2024jailbroken}
Alexander Wei, Nika Haghtalab, and Jacob Steinhardt.
\newblock Jailbroken: How does llm safety training fail?
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Yu et~al.(2024)Yu, Liu, Liang, Cameron, Xiao, and Zhang]{yu2024don}
Zhiyuan Yu, Xiaogeng Liu, Shunning Liang, Zach Cameron, Chaowei Xiao, and Ning Zhang.
\newblock Don't listen to me: Understanding and exploring jailbreak prompts of large language models.
\newblock \emph{arXiv preprint arXiv:2403.17336}, 2024.

\bibitem[Chang et~al.(2024)Chang, Li, Liu, Wang, Wang, and Liu]{Chang2024PlayGG}
Zhiyuan Chang, Mingyang Li, Yi~Liu, Junjie Wang, Qing Wang, and Yang Liu.
\newblock Play guessing game with llm: Indirect jailbreak attack with implicit clues.
\newblock \emph{ArXiv}, abs/2402.09091, 2024.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:267657689}.

\bibitem[Zhou and Wang(2024)]{zhou2024don}
Yukai Zhou and Wenjie Wang.
\newblock Don't say no: Jailbreaking llm by suppressing refusal.
\newblock \emph{arXiv preprint arXiv:2404.16369}, 2024.

\bibitem[Zhou et~al.(2024)Zhou, Wang, Xiong, Xia, Gu, Chai, Zhu, Huang, Dou, Xi, et~al.]{zhou2024easyjailbreak}
Weikang Zhou, Xiao Wang, Limao Xiong, Han Xia, Yingshuang Gu, Mingxu Chai, Fukang Zhu, Caishuang Huang, Shihan Dou, Zhiheng Xi, et~al.
\newblock Easyjailbreak: A unified framework for jailbreaking large language models.
\newblock \emph{arXiv preprint arXiv:2403.12171}, 2024.

\bibitem[White et~al.(2023)White, Fu, Hays, Sandborn, Olea, Gilbert, Elnashar, Spencer-Smith, and Schmidt]{white2023prompt}
Jules White, Quchen Fu, Sam Hays, Michael Sandborn, Carlos Olea, Henry Gilbert, Ashraf Elnashar, Jesse Spencer-Smith, and Douglas~C Schmidt.
\newblock A prompt pattern catalog to enhance prompt engineering with chatgpt.
\newblock \emph{arXiv preprint arXiv:2302.11382}, 2023.

\bibitem[Giray(2023)]{giray2023prompt}
Louie Giray.
\newblock Prompt engineering with chatgpt: a guide for academic writers.
\newblock \emph{Annals of biomedical engineering}, 51\penalty0 (12):\penalty0 2629--2633, 2023.

\bibitem[Zhu et~al.(2023{\natexlab{a}})Zhu, Wang, Zhou, Wang, Chen, Wang, Yang, Ye, Gong, Zhang, et~al.]{zhu2023promptbench}
Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao Chen, Yidong Wang, Linyi Yang, Wei Ye, Neil~Zhenqiang Gong, Yue Zhang, et~al.
\newblock Promptbench: Towards evaluating the robustness of large language models on adversarial prompts.
\newblock \emph{arXiv preprint arXiv:2306.04528}, 2023{\natexlab{a}}.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 1877--1901, 2020.

\bibitem[Wei et~al.(2022)Wei, Wang, Schuurmans, Bosma, Xia, Chi, Le, Zhou, et~al.]{wei2022chain}
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed~Chi, Quoc~V Le, Denny Zhou, et~al.
\newblock Chain-of-thought prompting elicits reasoning in large language models.
\newblock \emph{Advances in neural information processing systems}, 35:\penalty0 24824--24837, 2022.

\bibitem[Min et~al.(2022)Min, Lyu, Holtzman, Artetxe, Lewis, Hajishirzi, and Zettlemoyer]{min2022rethinking}
Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer.
\newblock Rethinking the role of demonstrations: What makes in-context learning work?
\newblock \emph{arXiv preprint arXiv:2202.12837}, 2022.

\bibitem[Sun et~al.(2023{\natexlab{a}})Sun, Zhang, Deng, Cheng, and Huang]{sun2023safety}
Hao Sun, Zhexin Zhang, Jiawen Deng, Jiale Cheng, and Minlie Huang.
\newblock Safety assessment of chinese large language models.
\newblock \emph{arXiv preprint arXiv:2304.10436}, 2023{\natexlab{a}}.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, Chen, Pei, Xie, Kang, Zhang, Xu, Xiong, Dutta, Schaeffer, et~al.]{wang2023decodingtrust}
Boxin Wang, Weixin Chen, Hengzhi Pei, Chulin Xie, Mintong Kang, Chenhui Zhang, Chejian Xu, Zidi Xiong, Ritik Dutta, Rylan Schaeffer, et~al.
\newblock Decodingtrust: A comprehensive assessment of trustworthiness in gpt models.
\newblock In \emph{NeurIPS}, 2023{\natexlab{b}}.

\bibitem[Li et~al.(2024)Li, Dong, Wang, Hu, Zuo, Lin, Qiao, and Shao]{li2024salad}
Lijun Li, Bowen Dong, Ruohui Wang, Xuhao Hu, Wangmeng Zuo, Dahua Lin, Yu~Qiao, and Jing Shao.
\newblock Salad-bench: A hierarchical and comprehensive safety benchmark for large language models.
\newblock \emph{arXiv preprint arXiv:2402.05044}, 2024.

\bibitem[Bai et~al.(2022)Bai, Kadavath, Kundu, Askell, Kernion, Jones, Chen, Goldie, Mirhoseini, McKinnon, et~al.]{bai2022constitutional}
Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, et~al.
\newblock Constitutional ai: Harmlessness from ai feedback.
\newblock \emph{arXiv preprint arXiv:2212.08073}, 2022.

\bibitem[Rafailov et~al.(2024)Rafailov, Sharma, Mitchell, Manning, Ermon, and Finn]{rafailov2024direct}
Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher~D Manning, Stefano Ermon, and Chelsea Finn.
\newblock Direct preference optimization: Your language model is secretly a reward model.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Ethayarajh et~al.(2024)Ethayarajh, Xu, Muennighoff, Jurafsky, and Kiela]{ethayarajh2024kto}
Kawin Ethayarajh, Winnie Xu, Niklas Muennighoff, Dan Jurafsky, and Douwe Kiela.
\newblock Kto: Model alignment as prospect theoretic optimization.
\newblock \emph{arXiv preprint arXiv:2402.01306}, 2024.

\bibitem[Yuan et~al.(2023)Yuan, Yuan, Tan, Wang, Huang, and Huang]{yuan2023rrhf}
Zheng Yuan, Hongyi Yuan, Chuanqi Tan, Wei Wang, Songfang Huang, and Fei Huang.
\newblock Rrhf: Rank responses to align language models with human feedback without tears.
\newblock \emph{arXiv preprint arXiv:2304.05302}, 2023.

\bibitem[Sun et~al.(2023{\natexlab{b}})Sun, Zhang, Deng, Cheng, and Huang]{Sun2023SafetyAO}
Hao Sun, Zhexin Zhang, Jiawen Deng, Jiale Cheng, and Minlie Huang.
\newblock Safety assessment of chinese large language models.
\newblock \emph{ArXiv}, abs/2304.10436, 2023{\natexlab{b}}.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:258236069}.

\bibitem[Mo et~al.(2023{\natexlab{b}})Mo, Wang, Chen, and Sun]{Mo2023HowTA}
Lingbo Mo, Boshi Wang, Muhao Chen, and Huan Sun.
\newblock How trustworthy are open-source llms? an assessment under malicious demonstrations shows their vulnerabilities.
\newblock \emph{ArXiv}, abs/2311.09447, 2023{\natexlab{b}}.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:265220739}.

\bibitem[Liu et~al.(2024)Liu, Cai, Zhang, Yuan, and Wang]{liu2024arondight}
Yi~Liu, Chengjun Cai, Xiaoli Zhang, Xingliang Yuan, and Cong Wang.
\newblock Arondight: Red teaming large vision language models with auto-generated multi-modal jailbreak prompts.
\newblock \emph{arXiv preprint arXiv:2407.15050}, 2024.

\bibitem[Bhardwaj and Poria(2023)]{bhardwaj2023red}
Rishabh Bhardwaj and Soujanya Poria.
\newblock Red-teaming large language models using chain of utterances for safety-alignment.
\newblock \emph{arXiv preprint arXiv:2308.09662}, 2023.

\bibitem[Ji et~al.(2024)Ji, Liu, Dai, Pan, Zhang, Bian, Chen, Sun, Wang, and Yang]{ji2024beavertails}
Jiaming Ji, Mickel Liu, Josef Dai, Xuehai Pan, Chi Zhang, Ce~Bian, Boyuan Chen, Ruiyang Sun, Yizhou Wang, and Yaodong Yang.
\newblock Beavertails: Towards improved safety alignment of llm via a human-preference dataset.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Inan et~al.(2023)Inan, Upasani, Chi, Rungta, Iyer, Mao, Tontchev, Hu, Fuller, Testuggine, et~al.]{inan2023llama}
Hakan Inan, Kartikeya Upasani, Jianfeng Chi, Rashi Rungta, Krithika Iyer, Yuning Mao, Michael Tontchev, Qing Hu, Brian Fuller, Davide Testuggine, et~al.
\newblock Llama guard: Llm-based input-output safeguard for human-ai conversations.
\newblock \emph{arXiv preprint arXiv:2312.06674}, 2023.

\bibitem[Jiang et~al.(2024)Jiang, Ye, Dong, Jia, Xu, Yan, Zhang, and Zhang]{jiang2024hal}
Chaoya Jiang, Wei Ye, Mengfan Dong, Hongrui Jia, Haiyang Xu, Ming Yan, Ji~Zhang, and Shikun Zhang.
\newblock Hal-eval: A universal and fine-grained hallucination evaluation framework for large vision language models.
\newblock \emph{arXiv preprint arXiv:2402.15721}, 2024.

\bibitem[Dong et~al.(2022)Dong, Li, Dai, Zheng, Wu, Chang, Sun, Xu, and Sui]{dong2022survey}
Qingxiu Dong, Lei Li, Damai Dai, Ce~Zheng, Zhiyong Wu, Baobao Chang, Xu~Sun, Jingjing Xu, and Zhifang Sui.
\newblock A survey on in-context learning.
\newblock \emph{arXiv preprint arXiv:2301.00234}, 2022.

\bibitem[Feng et~al.(2023)Feng, Zhang, Gu, Ye, He, and Wang]{NEURIPS2023_dfc310e8}
Guhao Feng, Bohang Zhang, Yuntian Gu, Haotian Ye, Di~He, and Liwei Wang.
\newblock Towards revealing the mystery behind chain of thought: A theoretical perspective.
\newblock In A.~Oh, T.~Naumann, A.~Globerson, K.~Saenko, M.~Hardt, and S.~Levine, editors, \emph{Advances in Neural Information Processing Systems}, volume~36, pages 70757--70798. Curran Associates, Inc., 2023.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2023/file/dfc310e81992d2e4cedc09ac47eff13e-Paper-Conference.pdf}.

\bibitem[Taori et~al.(2023)Taori, Gulrajani, Zhang, Dubois, Li, Guestrin, Liang, and Hashimoto]{alpaca}
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori~B. Hashimoto.
\newblock Stanford alpaca: An instruction-following llama model.
\newblock \url{https://github.com/tatsu-lab/stanford_alpaca}, 2023.

\bibitem[cha(2023)]{chatgpt}
Chatgpt.
\newblock Website, 2023.
\newblock \url{https://openai.com/blog/chatgpt}.

\bibitem[gpt(2023)]{gpt4}
Gpt-4.
\newblock Website, 2023.
\newblock \url{https://openai.com/gpt-4}.

\bibitem[cla(2023)]{claude}
Claude.
\newblock Website, 2023.
\newblock \url{https://www.anthropic.com}.

\bibitem[Jiang et~al.(2023)Jiang, Sablayrolles, Mensch, Bamford, Chaplot, de~Las~Casas, Bressand, Lengyel, Lample, Saulnier, Lavaud, Lachaux, Stock, Scao, Lavril, Wang, Lacroix, and Sayed]{Jiang2023Mistral7}
Albert~Qiaochu Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra~Singh Chaplot, Diego de~Las~Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, L'elio~Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven~Le Scao, Thibaut Lavril, Thomas Wang, Timoth{\'e}e Lacroix, and William~El Sayed.
\newblock Mistral 7b.
\newblock \emph{ArXiv}, abs/2310.06825, 2023.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:263830494}.

\bibitem[Bai et~al.(2023)Bai, Bai, Chu, Cui, Dang, Deng, Fan, Ge, Han, Huang, Hui, Ji, Li, Lin, Lin, Liu, Liu, Lu, Lu, Ma, Men, Ren, Ren, Tan, Tan, Tu, Wang, Wang, Wang, Wu, Xu, Xu, Yang, Yang, Yang, Yang, Yang, Yao, Yu, Bowen, Yuan, Yuan, Zhang, Zhang, Zhang, Zhang, Zhou, Zhou, Zhou, and Zhu]{Bai2023QwenTR}
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenhang Ge, Yu~Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, K.~Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An~Yang, Hao Yang, Jian Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Yu~Bowen, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xing Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu.
\newblock Qwen technical report.
\newblock \emph{ArXiv}, abs/2309.16609, 2023.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:263134555}.

\bibitem[Zeng et~al.(2022)Zeng, Liu, Du, Wang, Lai, Ding, Yang, Xu, Zheng, Xia, Tam, Ma, Xue, Zhai, Chen, Zhang, Dong, and Tang]{Zeng2022GLM130BAO}
Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng~Lam Tam, Zixuan Ma, Yufei Xue, Jidong Zhai, Wenguang Chen, P.~Zhang, Yuxiao Dong, and Jie Tang.
\newblock Glm-130b: An open bilingual pre-trained model.
\newblock \emph{ArXiv}, abs/2210.02414, 2022.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:252715691}.

\bibitem[Cai et~al.(2024)Cai, Cao, Chen, Chen, Chen, Chen, Chen, Chen, Chen, Chu, wen Dong, Duan, Fan, Fei, Gao, Ge, Gu, Gu, Gui, Guo, Guo, He, Hu, Huang, Jiang, Jiao, Jin, Lei, Li, Li, Li, Li, Li, Li, Liu, Liu, Hong, Liu, Liu, Liu, Lv, Lv, Lv, Ma, Ma, Ma, Ning, Ouyang, Qiu, Qu, Shang, Shao, Song, Song, Sui, Sun, Sun, Tang, Wang, Wang, Wang, Wang, Wang, Wang, Wang, Wei, Weng, Wu, Xiong, Xu, Xu, Yan, Yan, Yang, Ye, Ying, Yu, Yu, Zang, Zhang, Zhang, Zhang, Zhang, Zhang, Zhang, Zhang, Zhang, Zhang, Zhang, Zhang, Zhao, Zhao, Zhao, Zhou, Zhou, Zhuo, Zou, Qiu, Qiao, and Lin]{Cai2024InternLM2TR}
Zheng Cai, Maosong Cao, Haojiong Chen, Kai Chen, Keyu Chen, Xin Chen, Xun Chen, Zehui Chen, Zhi Chen, Pei Chu, Xiao wen Dong, Haodong Duan, Qi~Fan, Zhaoye Fei, Yang Gao, Jiaye Ge, Chenya Gu, Yuzhe Gu, Tao Gui, Aijia Guo, Qipeng Guo, Conghui He, Yingfan Hu, Ting Huang, Tao Jiang, Penglong Jiao, Zhen Jin, Zhikai Lei, Jiaxing Li, Jingwen Li, Linyang Li, Shuaibin Li, Wei Li, Yining Li, Hongwei Liu, Jiangning Liu, Jiawei Hong, Kaiwen Liu, Kui-Jie Liu, Xiaoran Liu, Chen Lv, Haijun Lv, Kai Lv, Li~Ma, Runyuan Ma, Zerun Ma, Wenchang Ning, Linke Ouyang, Jiantao Qiu, Yuan Qu, Fukai Shang, Yunfan Shao, Demin Song, Zifan Song, Zhihao Sui, Peng Sun, Yu~Sun, Huanze Tang, Bin Wang, Guoteng Wang, Jiaqi Wang, Jiayu Wang, Rui Wang, Yudong Wang, Ziyi Wang, Xing Wei, Qizhen Weng, Fan Wu, Yingtong Xiong, Chao Xu, Rui~Ze Xu, Hang Yan, Yirong Yan, Xiaogui Yang, Haochen Ye, Huaiyuan Ying, Jia Yu, Jing Yu, Yuhang Zang, Chuyu Zhang, Li~Zhang, Pan Zhang, Peng Zhang, Ruijie Zhang, Shuo Zhang, Songyang Zhang, Wenjian Zhang, Wenwei Zhang,
  Xingcheng Zhang, Xinyue Zhang, Hui Zhao, Qian Zhao, Xiaomeng Zhao, Fen-Fang Zhou, Zaida Zhou, Jingming Zhuo, Yi-Ling Zou, Xipeng Qiu, Yu~Qiao, and Dahua Lin.
\newblock Internlm2 technical report.
\newblock \emph{ArXiv}, abs/2403.17297, 2024.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:268691939}.

\bibitem[Kaplan et~al.(2020)Kaplan, McCandlish, Henighan, Brown, Chess, Child, Gray, Radford, Wu, and Amodei]{Kaplan2020ScalingLF}
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom~B. Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeff Wu, and Dario Amodei.
\newblock Scaling laws for neural language models.
\newblock \emph{ArXiv}, abs/2001.08361, 2020.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:210861095}.

\bibitem[Ding et~al.(2023)Ding, Kuang, Ma, Cao, Xian, Chen, and Huang]{ding2023wolf}
Peng Ding, Jun Kuang, Dan Ma, Xuezhi Cao, Yunsen Xian, Jiajun Chen, and Shujian Huang.
\newblock A wolf in sheep's clothing: Generalized nested jailbreak prompts can fool large language models easily.
\newblock \emph{arXiv preprint arXiv:2311.08268}, 2023.

\bibitem[Feng et~al.(2021)Feng, Jiang, Tang, Jin, and Gao]{feng2021rethinking}
Yutong Feng, Jianwen Jiang, Mingqian Tang, Rong Jin, and Yue Gao.
\newblock Rethinking supervised pre-training for better downstream transferring.
\newblock \emph{arXiv preprint arXiv:2110.06014}, 2021.

\bibitem[Shen et~al.(2023)Shen, Chen, Backes, Shen, and Zhang]{Shen2023DoAN}
Xinyue Shen, Zeyuan~Johnson Chen, Michael Backes, Yun Shen, and Yang Zhang.
\newblock "do anything now": Characterizing and evaluating in-the-wild jailbreak prompts on large language models.
\newblock \emph{ArXiv}, abs/2308.03825, 2023.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:260704242}.

\bibitem[Zhu et~al.(2023{\natexlab{b}})Zhu, Zhang, An, Wu, Barrow, Wang, Huang, Nenkova, and Sun]{zhu2023autodan}
Sicheng Zhu, Ruiyi Zhang, Bang An, Gang Wu, Joe Barrow, Zichao Wang, Furong Huang, Ani Nenkova, and Tong Sun.
\newblock Autodan: Automatic and interpretable adversarial attacks on large language models.
\newblock \emph{arXiv preprint arXiv:2310.15140}, 2023{\natexlab{b}}.

\bibitem[Chao et~al.(2023)Chao, Robey, Dobriban, Hassani, Pappas, and Wong]{chao2023jailbreaking}
Patrick Chao, Alexander Robey, Edgar Dobriban, Hamed Hassani, George~J Pappas, and Eric Wong.
\newblock Jailbreaking black box large language models in twenty queries.
\newblock \emph{arXiv preprint arXiv:2310.08419}, 2023.

\end{thebibliography}
