@inproceedings{allen2019convergence,
  title={A convergence theory for deep learning via over-parameterization},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
  booktitle={International Conference on Machine Learning},
  pages={242--252},
  year={2019},
  organization={PMLR}
}

@inproceedings{arpit2016normalization,
  title={Normalization Propagation: A Parametric Technique for Removing Internal Covariate Shift in Deep Networks},
  author={Arpit, Devansh and Zhou, Yingbo and Kota, Bhargava and Govindaraju, Venu},
  booktitle={International Conference on Machine Learning},
  pages={1168--1176},
  year={2016}
}

@inproceedings{arpit2019initialize,
  title={How to initialize your network? robust initialization for weightnorm \& resnets},
  author={Arpit, Devansh and Campos, V{\'\i}ctor and Bengio, Yoshua},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10902--10911},
  year={2019}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@article{bachlechner2020rezero,
  title={Rezero is all you need: Fast convergence at large depth},
  author={Bachlechner, Thomas and Majumder, Bodhisattwa Prasad and Mao, Huanru Henry and Cottrell, Garrison W and McAuley, Julian},
  journal={arXiv preprint arXiv:2003.04887},
  year={2020}
}

@inproceedings{balduzzi2017shattered,
  title={The Shattered Gradients Problem: If resnets are the answer, then what is the question?},
  author={Balduzzi, David and Frean, Marcus and Leary, Lennox and Lewis, JP and Ma, Kurt Wan-Duo and McWilliams, Brian},
  booktitle={International Conference on Machine Learning},
  pages={342--350},
  year={2017}
}

@inproceedings{
bello2021lambdanetworks,
title={LambdaNetworks: Modeling long-range Interactions without Attention},
author={Irwan Bello},
booktitle={International Conference on Learning Representations {ICLR}},
year={2021},
url={https://openreview.net/forum?id=xTJEN-ggl1b}
}

@inproceedings{bengio2013advances,
  title={Advances in optimizing recurrent networks},
  author={Bengio, Yoshua and Boulanger-Lewandowski, Nicolas and Pascanu, Razvan},
  booktitle={2013 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={8624--8628},
  year={2013},
  organization={IEEE}
}

@article{bernstein2020distance,
  title={On the distance between two neural networks and the stability of learning},
  author={Bernstein, Jeremy and Vahdat, Arash and Yue, Yisong and Liu, Ming-Yu},
  journal={arXiv preprint arXiv:2002.03432},
  year={2020}
}

@inproceedings{bernstein2018signsgd,
  title={signSGD: Compressed optimisation for non-convex problems},
  author={Bernstein, Jeremy and Wang, Yu-Xiang and Azizzadenesheli, Kamyar and Anandkumar, Animashree},
  booktitle={International Conference on Machine Learning},
  pages={560--569},
  year={2018},
  organization={PMLR}
}

@inproceedings{bjorck2018understanding,
  title={Understanding batch normalization},
  author={Bjorck, Nils and Gomes, Carla P and Selman, Bart and Weinberger, Kilian Q},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7694--7705},
  year={2018}
}

@inproceedings{brock2017neural,
  title={Neural Photo Editing With Introspective Adversarial Networks},
  author={Brock, Andrew and Lim, Theodore and Ritchie, James Millar and Weston, Nicholas J},
  booktitle={5th International Conference on Learning Representations, {ICLR}},
  year={2017}
}

@inproceedings{brock2021characterizing,
  title={Characterizing signal propagation to close the performance gap in unnormalized ResNets},
  author={Brock, Andrew and De, Soham and Smith, Samuel L},
  booktitle={9th International Conference on Learning Representations, {ICLR}},
  year={2021}
}

@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1597--1607},
  year={2020},
  organization={PMLR}
}

@inproceedings{clevert2015fast,
  author    = {Djork{-}Arn{\'{e}} Clevert and
               Thomas Unterthiner and
               Sepp Hochreiter},
  title = {Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)},
  booktitle = {4th International Conference on Learning Representations, {ICLR}},
  year  = {2016},
}


@inproceedings{cubuk2019autoaugment,
  title={Autoaugment: Learning augmentation strategies from data},
  author={Cubuk, Ekin D and Zoph, Barret and Mane, Dandelion and Vasudevan, Vijay and Le, Quoc V},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={113--123},
  year={2019}
}

@inproceedings{cubuk2020randaugment,
  title={Randaugment: Practical automated data augmentation with a reduced search space},
  author={Cubuk, Ekin D and Zoph, Barret and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={702--703},
  year={2020}
}
@article{de2020batch,
  title={Batch normalization biases residual blocks towards the identity function in deep networks},
  author={De, Soham and Smith, Sam},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@misc{dean17build,
  author = {Jeff Dean and Urs H\"{o}lzle},
  title = {Build and train machine learning models on our new {Google Cloud TPUs}},
  howpublished = "\url{https://www.blog.google/products/google-cloud/google-cloud-offer-tpus-machine-learning/}",
  year = {2017},
}

@inproceedings{dosovitskiy2021an,
    title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
    author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
    booktitle={9th International Conference on Learning Representations, {ICLR}},
    year={2021},
    url={https://openreview.net/forum?id=YicbFdNTTy}
}

@article{elfwing2018sigmoid,
  title={Sigmoid-weighted linear units for neural network function approximation in reinforcement learning},
  author={Elfwing, Stefan and Uchibe, Eiji and Doya, Kenji},
  journal={Neural Networks},
  volume={107},
  pages={3--11},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{foret2021sharpnessaware,
  title={Sharpness-aware Minimization for Efficiently Improving Generalization},
  author={Pierre Foret and Ariel Kleiner and Hossein Mobahi and Behnam Neyshabur},
  booktitle={9th International Conference on Learning Representations, {ICLR}},
  year={2021},
  url={https://openreview.net/forum?id=6Tm1mposlrM}
}

@article{gitman2017comparison,
  title={Comparison of batch normalization and weight normalization algorithms for the large-scale image classification},
  author={Gitman, Igor and Ginsburg, Boris},
  journal={arXiv preprint arXiv:1709.08145},
  year={2017}
}

@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={249--256},
  year={2010}
}

@article{gong2020maxup,
  title={Maxup: A simple way to improve generalization of neural network training},
  author={Gong, Chengyue and Ren, Tongzheng and Ye, Mao and Liu, Qiang},
  journal={arXiv preprint arXiv:2002.09024},
  year={2020}
}

@article{goyal2017accurate,
  title={Accurate, large minibatch sgd: Training imagenet in 1 hour},
  author={Goyal, Priya and Doll{\'a}r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  journal={arXiv preprint arXiv:1706.02677},
  year={2017}
}

@article{graves2013generating,
  title={Generating sequences with recurrent neural networks},
  author={Graves, Alex},
  journal={arXiv preprint arXiv:1308.0850},
  year={2013}
}

@article{grill2020bootstrap,
  title={Bootstrap Your Own Latent-A New Approach to Self-Supervised Learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{gueguen2018faster,
  title={Faster neural networks straight from jpeg},
  author={Gueguen, Lionel and Sergeev, Alex and Kadlec, Ben and Liu, Rosanne and Yosinski, Jason},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  pages={3933--3944},
  year={2018}
}

@inproceedings{gulrajani2017improved,
  title={Improved Training of {W}asserstein {GAN}s},
  author={Ishaan Gulrajani and Faruk Ahmed and Mart{\'{\i}}n Arjovsky and Vincent  Dumoulin and Aaron C. Courville},
  booktitle={Advances in neural information processing systems},
  year={2017},
}

@software{haiku2020github,
  author = {Tom Hennigan and Trevor Cai and Tamara Norman and Igor Babuschkin},
  title = {{H}aiku: {S}onnet for {JAX}},
  url = {http://github.com/deepmind/dm-haiku},
  version = {0.0.3},
  year = {2020},
}

@inproceedings{hanin2018start,
  title={How to start training: The effect of initialization and architecture},
  author={Hanin, Boris and Rolnick, David},
  booktitle={Advances in Neural Information Processing Systems},
  pages={571--581},
  year={2018}
}

@Article{harris2020numpy,
author={Harris, Charles R. and Millman, K. Jarrod and van der Walt, St{\'e}fan J. and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and van Kerkwijk, Marten H. and Brett, Matthew and Haldane, Allan and del R{\'i}o, Jaime Fern{\'a}ndez and Wiebe, Mark and Peterson, Pearu and G{\'e}rard-Marchant, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
title={Array programming with NumPy},
journal={Nature},
year={2020},
month={Sep},
day={01},
volume={585},
number={7825},
pages={357-362},
issn={1476-4687},
}

@inproceedings{he2019bag,
  title={Bag of tricks for image classification with convolutional neural networks},
  author={He, Tong and Zhang, Zhi and Zhang, Hang and Zhang, Zhongyue and Xie, Junyuan and Li, Mu},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={558--567},
  year={2019}
}

@inproceedings{he2015delving,
  title={Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV)},
  pages={1026--1034},
  year={2015}
}


@inproceedings{he2016identity,
  title={Identity mappings in deep residual networks},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={European conference on computer vision},
  pages={630--645},
  year={2016},
  organization={Springer}
}

@inproceedings{he2016resnets,
  title={Deep residual learning for image recognition},
  author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  booktitle={CVPR},
  year={2016},
}

@inproceedings{he2020momentum,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9729--9738},
  year={2020}
}

@article{hendrycks2016gaussian,
  title={Gaussian error linear units ({GELUs})},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@inproceedings{hoffer2017train,
  title={Train longer, generalize better: closing the generalization gap in large batch training of neural networks},
  author={Hoffer, Elad and Hubara, Itay and Soudry, Daniel},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1731--1741},
  year={2017}
}

@article{hooker2020hardware,
  title={The hardware lottery},
  author={Hooker, Sara},
  journal={arXiv preprint arXiv:2009.06489},
  year={2020}
}

@article{howard2017mobilenets,
  title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
  author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  journal={arXiv preprint arXiv:1704.04861},
  year={2017}
}

@inproceedings{howard2019searching,
  title={Searching for mobilenetv3},
  author={Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and others},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={1314--1324},
  year={2019}
}

@inproceedings{hu2018squeeze,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7132--7141},
  year={2018}
}

@inproceedings{huang2016deep,
  title={Deep networks with stochastic depth},
  author={Huang, Gao and Sun, Yu and Liu, Zhuang and Sedra, Daniel and Weinberger, Kilian Q},
  booktitle={European conference on computer vision},
  pages={646--661},
  year={2016},
  organization={Springer}
}

@inproceedings{huang2017centered,
  title={Centered weight normalization in accelerating training of deep neural networks},
  author={Huang, Lei and Liu, Xianglong and Liu, Yang and Lang, Bo and Tao, Dacheng},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2803--2811},
  year={2017}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}

@article{huang2020normalization,
      title={Normalization Techniques in Training DNNs: Methodology, Analysis and Application}, 
      author={Lei Huang and Jie Qin and Yi Zhou and Fan Zhu and Li Liu and Ling Shao},
      journal={arXiv preprint arXiv:2009.12836},
      year={2020},
}


@article{ILSVRC2015,
  author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
  title = {Image{N}et Large Scale Visual Recognition Challenge},
  pages = {211--252},
  journal = {IJCV},
  volume = {115},
  year = {2015}
}

@inproceedings{ioffe2015batchnorm,
  title={Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author={Sergey Ioffe and Christian Szegedy},
  booktitle={ICML},
year={2015},
}

@article{ioffe2017batch,
  title={Batch renormalization: Towards reducing minibatch dependence in batch-normalized models},
  author={Ioffe, Sergey},
  journal={arXiv preprint arXiv:1702.03275},
  year={2017}
}

@article{jacot2019freeze,
  title={Freeze and chaos for dnns: an NTK view of batch normalization, checkerboard and boundary effects},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  journal={arXiv preprint arXiv:1907.05715},
  year={2019}
}

@software{jax2018github,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and Skye Wanderman-Milne},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.1.55},
  year = {2018},
}

@inproceedings{jiang2018on,
  title={On Computation and Generalization of Generative Adversarial Networks under Spectrum Control},
  author={Haoming Jiang and Zhehui Chen and Minshuo Chen and Feng Liu and Dingding Wang and Tuo Zhao},
  booktitle={7th International Conference on Learning Representations, {ICLR}},
  year={2019},
url={https://openreview.net/forum?id=rJNH6sAqY7},
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{kingma2015adam,
  title = {Adam: A Method for Stochastic Optimization},
  author = {Diederik P Kingma and Jimmy Lei Ba},
  journal = {3rd International Conference on Learning Representations {ICLR}},
  year = {2015},
}

@inproceedings{kingma2018glow,
  title={Glow: Generative flow with invertible 1x1 convolutions},
  author={Kingma, Durk P and Dhariwal, Prafulla},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10215--10224},
  year={2018}
}

@inproceedings{klambauer2017self,
  title={Self-normalizing neural networks},
  author={Klambauer, G{\"u}nter and Unterthiner, Thomas and Mayr, Andreas and Hochreiter, Sepp},
  booktitle={Advances in neural information processing systems},
  pages={971--980},
  year={2017}
}

@article{kolesnikov2019large,
  title={Large scale learning of general visual representations for transfer},
  author={Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Puigcerver, Joan and Yung, Jessica and Gelly, Sylvain and Houlsby, Neil},
  journal={arXiv preprint arXiv:1912.11370},
  year={2019}
}



@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  pages={1097--1105},
  year={2012}
}

@inproceedings{laina2016deeper,
  title={Deeper depth prediction with fully convolutional residual networks},
  author={Laina, Iro and Rupprecht, Christian and Belagiannis, Vasileios and Tombari, Federico and Navab, Nassir},
  booktitle={2016 Fourth international conference on 3D vision (3DV)},
  pages={239--248},
  year={2016},
  organization={IEEE}
}

@incollection{lecun2012efficient,
  title={Efficient backprop},
  author={LeCun, Yann A and Bottou, L{\'e}on and Orr, Genevieve B and M{\"u}ller, Klaus-Robert},
  booktitle={Neural networks: Tricks of the trade},
  pages={9--48},
  year={2012},
  publisher={Springer}
}

@article{liu2020evolving,
  title={Evolving Normalization-Activation Layers},
  author={Liu, Hanxiao and Brock, Andrew and Simonyan, Karen and Le, Quoc V},
  journal={arXiv preprint arXiv:2004.02967},
  year={2020}
}

@inproceedings{long2015fully,
  title={Fully convolutional networks for semantic segmentation},
  author={Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3431--3440},
  year={2015}
}

@article{loshchilov2016sgdr,
  title={SGDR: Stochastic Gradient Descent with Warm Restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1608.03983},
  year={2016}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@article{lu2020bidirectional,
  title={Bidirectional Self-Normalizing Neural Networks},
  author={Lu, Yao and Gould, Stephen and Ajanthan, Thalaiyasingam},
  journal={arXiv preprint arXiv:2006.12169},
  year={2020}
}

@article{luo2018differentiable,
  title={Differentiable learning-to-normalize via switchable normalization},
  author={Luo, Ping and Ren, Jiamin and Peng, Zhanglin and Zhang, Ruimao and Li, Jingyu},
  journal={arXiv preprint arXiv:1806.10779},
  year={2018}
}

@article{luo2018towards,
  title={Towards understanding regularization in batch normalization},
  author={Luo, Ping and Wang, Xinjiang and Shao, Wenqi and Peng, Zhanglin},
  journal={arXiv preprint arXiv:1809.00846},
  year={2018}
}

@article{ma2018quasi,
  title={Quasi-hyperbolic momentum and adam for deep learning},
  author={Ma, Jerry and Yarats, Denis},
  journal={arXiv preprint arXiv:1810.06801},
  year={2018}
}

@inproceedings{ma2018shufflenet,
  title={Shufflenet v2: Practical guidelines for efficient cnn architecture design},
  author={Ma, Ningning and Zhang, Xiangyu and Zheng, Hai-Tao and Sun, Jian},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={116--131},
  year={2018}
}

@inproceedings{mahajan2018exploring,
  title={Exploring the limits of weakly supervised pretraining},
  author={Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and Van Der Maaten, Laurens},
  booktitle={Proceedings of the European Conference on Computer Vision {ECCV}},
  pages={181--196},
  year={2018}
}

@inproceedings{merity2018regularizing,
    title={Regularizing and Optimizing {LSTM} Language Models},
    author={Stephen Merity and Nitish Shirish Keskar and Richard Socher},
    booktitle={International Conference on Learning Representations},
    year={2018},
}

@inproceedings{mescheder2018r1gp,
title={Which Training Methods for {GAN}s do actually Converge?},
author={Lars Mescheder and Andreas Geiger and Sebastian Nowozin},
booktitle={ICML},
year={2018},
}

@inproceedings{miyato2018spectral,
title={Spectral Normalization for Generative Adversarial Networks},
author={Takeru Miyato and Toshiki Kataoka and Masanori Koyama and Yuichi Yoshida},
booktitle={6th International Conference on Learning Representations, {ICLR}},
year={2018},
}

@inproceedings{nair2010rectified,
  title={Rectified linear units improve restricted boltzmann machines},
  author={Nair, Vinod and Hinton, Geoffrey E},
  booktitle={Proceedings of the 27th international conference on machine learning (ICML-10)},
  pages={807--814},
  year={2010}
}

@article{nesterov1983,
title = {A Method for Unconstrained Convex Minimization Problem with the Rate of Convergence $ o(1/k^2)$.}, 
author = {Y. Nesterov},
journal = {Doklady AN USSR},
pages = {(269), 543-547},
year = {1983},
}

@article{owen2007robust,
  title={A robust hybrid of lasso and ridge regression},
  author={Owen, Art B},
  year={2007}
}

@inproceedings{pascanu2013difficulty,
  title={On the difficulty of training recurrent neural networks},
  author={Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={1310--1318},
  year={2013}
}

@inproceedings{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  booktitle={Advances in neural information processing systems},
  pages={8026--8037},
  year={2019}
}

@inproceedings{pham2019cradle,
  title={CRADLE: cross-backend validation to detect and localize bugs in deep learning libraries},
  author={Pham, Hung Viet and Lutellier, Thibaud and Qi, Weizhen and Tan, Lin},
  booktitle={2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)},
  pages={1027--1038},
  year={2019},
  organization={IEEE}
}

@article{pham2020meta,
  title={Meta pseudo labels},
  author={Pham, Hieu and Xie, Qizhe and Dai, Zihang and Le, Quoc V},
  journal={arXiv preprint arXiv:2003.10580},
  year={2020}
}

@article{polyak1964some,
  title = {Some Methods of Speeding Up the Convergence of Iteration Methods},
  author = {Boris Polyak},
  journal = {USSR Computational Mathematics and Mathematical Physics},
  pages = {4(5):1-17},
  year = {1964},
}

@article{qiao2019weight,
  title={Weight standardization},
  author={Qiao, Siyuan and Wang, Huiyu and Liu, Chenxi and Shen, Wei and Yuille, Alan},
  journal={arXiv preprint arXiv:1903.10520},
  year={2019}
}

@article{qin2020resizemix,
  title={ResizeMix: Mixing Data with Preserved Object Information and True Labels},
  author={Qin, Jie and Fang, Jiemin and Zhang, Qian and Liu, Wenyu and Wang, Xingang and Wang, Xinggang},
  journal={arXiv preprint arXiv:2012.11101},
  year={2020}
}

@inproceedings{radford2016dcgan,
    title={Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks},
    author={Radford, Alec and Metz, Luke and Chintala, Soumith},
    booktitle={4th International Conference on Learning Representations, {ICLR}},
    year={2016},
}

@inproceedings{radosavovic2020designing,
  title={Designing network design spaces},
  author={Radosavovic, Ilija and Kosaraju, Raj Prateek and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10428--10436},
  year={2020}
}

@inproceedings{raghu2017expressive,
  title={On the expressive power of deep neural networks},
  author={Raghu, Maithra and Poole, Ben and Kleinberg, Jon and Ganguli, Surya and Sohl-Dickstein, Jascha},
  booktitle={international conference on machine learning},
  pages={2847--2854},
  year={2017},
  organization={PMLR}
}

@article{raghu2017svcca,
  title={Svcca: Singular vector canonical correlation analysis for deep learning dynamics and interpretability},
  author={Raghu, Maithra and Gilmer, Justin and Yosinski, Jason and Sohl-Dickstein, Jascha},
  journal={Advances in neural information processing systems},
  volume={30},
  pages={6076--6085},
  year={2017}
}

@article{ramachandran2017searching,
  title={Searching for activation functions},
  author={Ramachandran, Prajit and Zoph, Barret and Le, Quoc V},
  journal={arXiv preprint arXiv:1710.05941},
  year={2017}
}

@article{richemond2020byol,
  title={BYOL works even without batch statistics},
  author={Richemond, Pierre H and Grill, Jean-Bastien and Altch{\'e}, Florent and Tallec, Corentin and Strub, Florian and Brock, Andrew and Smith, Samuel and De, Soham and Pascanu, Razvan and Piot, Bilal and others},
  journal={arXiv preprint arXiv:2010.10241},
  year={2020}
}

@inproceedings{riedmiller1992rprop,
  title={RPROP-A fast adaptive learning algorithm},
  author={Riedmiller, Martin and Braun, Heinrich},
  booktitle={Proc. of ISCIS VII, Universitat},
  year={1992},
  organization={Citeseer}
}

@article{robbins1951A,
  title = {A Stochastic Approximation Method.},
  author = {Herbert Robbins and Sutton Monro},
  journal = {The Annals of Mathematical Statistics},
  pages = {22(3):400-407},
  year = {1951},
}

@inproceedings{rota2018place,
  title={In-place activated batchnorm for memory-optimized training of dnns},
  author={Rota Bul{\`o}, Samuel and Porzi, Lorenzo and Kontschieder, Peter},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5639--5647},
  year={2018}
}


@inproceedings{salimans2016weight,
  title={Weight normalization: A simple reparameterization to accelerate training of deep neural networks},
  author={Salimans, Tim and Kingma, Durk P},
  booktitle={Advances in neural information processing systems},
  pages={901--909},
  year={2016}
}

@inproceedings{sandler2018mobilenetv2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4510--4520},
  year={2018}
}

@inproceedings{sandler2019non,
  title={Non-discriminative data or weak model? on the relative importance of data and model resolution},
  author={Sandler, Mark and Baccash, Jonathan and Zhmoginov, Andrey and Howard, Andrew},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops},
  pages={0--0},
  year={2019}
}

@inproceedings{santurkar2018does,
  title={How does batch normalization help optimization?},
  author={Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew and Madry, Aleksander},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2483--2493},
  year={2018}
}

@article{saxe2013exact,
  title={Exact solutions to the nonlinear dynamics of learning in deep linear neural networks},
  author={Saxe, Andrew M and McClelland, James L and Ganguli, Surya},
  journal={arXiv preprint arXiv:1312.6120},
  year={2013}
}

@inproceedings{
  sedghi2018conv_svs,
  title={The Singular Values of Convolutional Layers},
  author={Hanie Sedghi and Vineet Gupta and Philip M. Long},
  booktitle={7th International Conference on Learning Representations, {ICLR}},
  year={2019},
  url={https://openreview.net/forum?id=rJevYoA9Fm},
}

@inproceedings{seetharaman2020autoclip,
  title={AutoClip: Adaptive gradient clipping for source separation networks},
  author={Seetharaman, Prem and Wichern, Gordon and Pardo, Bryan and Le Roux, Jonathan},
  booktitle={2020 IEEE 30th International Workshop on Machine Learning for Signal Processing (MLSP)},
  pages={1--6},
  year={2020},
  organization={IEEE}
}

@inproceedings{shang2016understanding,
  title={Understanding and improving convolutional neural networks via concatenated rectified linear units},
  author={Shang, Wenling and Sohn, Kihyuk and Almeida, Diogo and Lee, Honglak},
  booktitle={international conference on machine learning},
  pages={2217--2225},
  year={2016}
}

@article{shao2020normalization,
  title={Is normalization indispensable for training deep neural network?},
  author={Shao, Jie and Hu, Kai and Wang, Changhu and Xue, Xiangyang and Raj, Bhiksha},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{shen2020powernorm,
  title={Powernorm: Rethinking batch normalization in transformers},
  author={Shen, Sheng and Yao, Zhewei and Gholami, Amir and Mahoney, Michael and Keutzer, Kurt},
  booktitle={International Conference on Machine Learning},
  pages={8741--8751},
  year={2020},
  organization={PMLR}
}

@inproceedings{silberman2012indoor,
  title={Indoor segmentation and support inference from rgbd images},
  author={Silberman, Nathan and Hoiem, Derek and Kohli, Pushmeet and Fergus, Rob},
  booktitle={European conference on computer vision},
  pages={746--760},
  year={2012},
  organization={Springer}
}

@inproceedings{simonyan2015vgg,
title={Very Deep Convolutional Networks for Large-Scale Image Recognition},
author={Simonyan, Karen and Zisserman, Andrew},
booktitle={3rd International Conference on Learning Representations, {ICLR}},
year={2015},
}

@inproceedings{singh2019evalnorm,
  title={Evalnorm: Estimating batch normalization statistics for evaluation},
  author={Singh, Saurabh and Shrivastava, Abhinav},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3633--3641},
  year={2019}
}

@inproceedings{smith2020generalization,
  title={On the Generalization Benefit of Noise in Stochastic Gradient Descent},
  author={Smith, Samuel and Elsen, Erich and De, Soham},
  booktitle={International Conference on Machine Learning},
  pages={9058--9067},
  year={2020},
  organization={PMLR}
}

@article{srinivas2021bottleneck,
  title={Bottleneck Transformers for Visual Recognition},
  author={Srinivas, Aravind and Lin, Tsung-Yi and Parmar, Niki and Shlens, Jonathon and Abbeel, Pieter and Vaswani, Ashish},
  journal={arXiv preprint arXiv:2101.11605},
  year={2021}
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@article{srivastava2015highway,
  title={Highway networks},
  author={Srivastava, Rupesh Kumar and Greff, Klaus and Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:1505.00387},
  year={2015}
}


@article{summers2019four,
  title={Four things everyone should know to improve batch normalization},
  author={Summers, Cecilia and Dinneen, Michael J},
  journal={arXiv preprint arXiv:1906.03548},
  year={2019}
}

@inproceedings{sun17revisiting,
  author    = {Chen Sun and Abhinav Shrivastava and Saurabh Singh and Abhinav Gupta},
  title     = {Revisiting Unreasonable Effectiveness of Data in Deep Learning Era},
  booktitle = {ICCV},
  year      = {2017},
}

@inproceedings{sutskever2013importance,
  title={On the importance of initialization and momentum in deep learning},
  author={Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
  booktitle={International conference on machine learning},
  pages={1139--1147},
  year={2013}
}

@article{szegedy2016inception,
  title={Inception-v4, inception-resnet and the impact of residual connections on learning},
  author={Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alex},
  journal={arXiv preprint arXiv:1602.07261},
  year={2016}
}

@inproceedings{szegedy2016rethinking,
  title={Rethinking the Inception Architecture for Computer Vision},
  author={Szegedy, C and Vanhoucke, V and Ioffe, S and Shlens, J and Wojna, Z},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={2818--2826},
  year={2016}
}



@article{taki2017deep,
  title={Deep residual networks and weight initialization},
  author={Taki, Masato},
  journal={arXiv preprint arXiv:1709.02956},
  year={2017}
}

@inproceedings{tan2019efficientnet,
  title={EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International Conference on Machine Learning},
  pages={6105--6114},
  year={2019}
}

@article{tieleman2012rmsprop,
  title = {RMSProp: Divide the Gradient by a Running Average of Its
  Recent Magnitude},
  author = {Tijmen Tieleman and Geoffrey Hinton},
  journal = {COURSERA: Neural networks for machine learning},
  pages = {4(2):26-31},
  year = {2012},
}

@inproceedings{touvron2019fixing,
  title={Fixing the train-test resolution discrepancy},
  author={Touvron, Hugo and Vedaldi, Andrea and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8252--8262},
  year={2019}
}

@article{touvron2020training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  journal={arXiv preprint arXiv:2012.12877},
  year={2020}
}

@misc{tpu,
  author = {Google},
  title = {{Cloud TPUs}},
  howpublished = "\url{https://cloud.google.com/tpu/}",
  year = {2021},
}

@misc{tpu_performance,
  author = {Google},
  title = {{Cloud TPU Performance Guide}},
  howpublished = "\url{https://cloud.google.com/tpu/docs/performance-guide}",
  year = {2021},
}

@article{ulyanov2016instance,
  title={Instance normalization: The missing ingredient for fast stylization},
  author={Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
  journal={arXiv preprint arXiv:1607.08022},
  year={2016}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  journal={arXiv preprint arXiv:1706.03762},
  year={2017}
}


@inproceedings{wu2018group,
  title={Group normalization},
  author={Wu, Yuxin and He, Kaiming},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={3--19},
  year={2018}
}

@inproceedings{xiao2018dynamical,
  title={Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10,000-Layer Vanilla Convolutional Neural Networks},
  author={Xiao, Lechao and Bahri, Yasaman and Sohl-Dickstein, Jascha and Schoenholz, Samuel and Pennington, Jeffrey},
  booktitle={International Conference on Machine Learning},
  pages={5393--5402},
  year={2018}
}

@inproceedings{xie2017aggregated,
  title={Aggregated residual transformations for deep neural networks},
  author={Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and Tu, Zhuowen and He, Kaiming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1492--1500},
  year={2017}
}

@inproceedings{xie2020self,
  title={Self-training with noisy student improves imagenet classification},
  author={Xie, Qizhe and Luong, Minh-Thang and Hovy, Eduard and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10687--10698},
  year={2020}
}

@article{xiong2020mobiledets,
  title={MobileDets: Searching for Object Detection Architectures for Mobile Accelerators},
  author={Xiong, Yunyang and Liu, Hanxiao and Gupta, Suyog and Akin, Berkin and Bender, Gabriel and Kindermans, Pieter-Jan and Tan, Mingxing and Singh, Vikas and Chen, Bo},
  journal={arXiv preprint arXiv:2004.14525},
  year={2020}
}

@inproceedings{yang2017mean,
  title={Mean field residual networks: On the edge of chaos},
  author={Yang, Ge and Schoenholz, Samuel},
  booktitle={Advances in neural information processing systems},
  pages={7103--7114},
  year={2017}
}

@article{yang2019mean,
  title={A mean field theory of batch normalization},
  author={Yang, Greg and Pennington, Jeffrey and Rao, Vinay and Sohl-Dickstein, Jascha and Schoenholz, Samuel S},
  journal={arXiv preprint arXiv:1902.08129},
  year={2019}
}

@article{you2017large,
  title={Large batch training of convolutional networks},
  author={You, Yang and Gitman, Igor and Ginsburg, Boris},
  journal={arXiv preprint arXiv:1708.03888},
  year={2017}
}

@inproceedings{you2019large,
  title={Large batch optimization for deep learning: Training bert in 76 minutes},
  author={You, Yang and Li, Jing and Reddi, Sashank and Hseu, Jonathan and Kumar, Sanjiv and Bhojanapalli, Srinadh and Song, Xiaodan and Demmel, James and Keutzer, Kurt and Hsieh, Cho-Jui},
  booktitle={7th International Conference on Learning Representations, {ICLR}},
  year={2019}
}

@inproceedings{yun2019cutmix,
  title={Cutmix: Regularization strategy to train strong classifiers with localizable features},
  author={Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={6023--6032},
  year={2019}
}

@article{zhang2019fixup,
  title={Fixup initialization: Residual learning without normalization},
  author={Zhang, Hongyi and Dauphin, Yann N and Ma, Tengyu},
  journal={arXiv preprint arXiv:1901.09321},
  year={2019}
}

@article{zhang2017mixup,
  title={mixup: Beyond empirical risk minimization},
  author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1710.09412},
  year={2017}
}


@article{zagoruyko2016wide,
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1605.07146},
  year={2016}
}

@inproceedings{wei2020circumventing,
  author    = {Longhui Wei and
               An Xiao and
               Lingxi Xie and
               Xiaopeng Zhang and
               Xin Chen and
               Qi Tian},
  title     = {Circumventing Outliers of AutoAugment with Knowledge Distillation},
  booktitle = {{ECCV}},
  pages     = {608--625},
  year      = {2020},
}

@article{zhang2019algorithmic,
  title={Which algorithmic choices matter at which batch sizes? insights from a noisy quadratic model},
  author={Zhang, Guodong and Li, Lala and Nado, Zachary and Martens, James and Sachdeva, Sushant and Dahl, George E and Shallue, Christopher J and Grosse, Roger},
  journal={arXiv preprint arXiv:1907.04164},
  year={2019}
}


@inproceedings{zhang2019gradient,
  title={Why gradient clipping accelerates training: A theoretical justification for adaptivity},
  author={Zhang, Jingzhao and He, Tianxing and Sra, Suvrit and Jadbabaie, Ali},
  booktitle={8th International Conference on Learning Representations, {ICLR}},
  year={2020},
  url={https://openreview.net/forum?id=BJgnXpVYwS},
}

@inproceedings{zhang2019self,
  title={Self-attention generative adversarial networks},
  author={Zhang, Han and Goodfellow, Ian and Metaxas, Dimitris and Odena, Augustus},
  booktitle={International conference on machine learning},
  pages={7354--7363},
  year={2019},
  organization={PMLR}
}

@article{zhang2020adaptive,
  title={Why are Adaptive Methods Good for Attention Models?},
  author={Zhang, Jingzhao and Karimireddy, Sai Praneeth and Veit, Andreas and Kim, Seungyeon and Reddi, Sashank and Kumar, Sanjiv and Sra, Suvrit},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}


