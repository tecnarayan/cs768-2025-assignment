From Cloze to Comprehension: Retrofitting Pre-trained Masked Language Model to Pre-trained Machine Reader