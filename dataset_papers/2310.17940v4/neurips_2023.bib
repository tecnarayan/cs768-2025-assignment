@inproceedings{grissom-ii-etal-2014-dont,
    title = "Don{'}t Until the Final Verb Wait: Reinforcement Learning for Simultaneous Machine Translation",
    author = "Grissom II, Alvin  and
      He, He  and
      Boyd-Graber, Jordan  and
      Morgan, John  and
      Daum{\'e} III, Hal",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D14-1140",
    doi = "10.3115/v1/D14-1140",
    pages = "1342--1352",
}
@inproceedings{gu-etal-2017-learning,
    title = "Learning to Translate in Real-time with Neural Machine Translation",
    author = "Gu, Jiatao  and
      Neubig, Graham  and
      Cho, Kyunghyun  and
      Li, Victor O.K.",
    booktitle = "Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 1, Long Papers",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/E17-1099",
    pages = "1053--1062",
    abstract = "Translating in real-time, a.k.a.simultaneous translation, outputs translation words before the input sentence ends, which is a challenging problem for conventional machine translation methods. We propose a neural machine translation (NMT) framework for simultaneous translation in which an agent learns to make decisions on when to translate from the interaction with a pre-trained NMT environment. To trade off quality and delay, we extensively explore various targets for delay and design a method for beam-search applicable in the simultaneous MT setting. Experiments against state-of-the-art baselines on two language pairs demonstrate the efficacy of the proposed framework both quantitatively and qualitatively.",
}
@article{Chen2019,
abstract = {Despite the success of neural machine translation (NMT), simultaneous neural machine translation (SNMT), the task of translating in real time before a full sentence has been observed, remains challenging due to the syntactic structure difference and simultaneity requirements. In this paper, we propose a general framework to improve simultaneous translation with a pretrained consecutive neural machine translation (CNMT) model. Our framework contains two parts: prefix translation that utilizes a pretrained CNMT model to better translate source prefixes and a stopping criterion that determines when to stop the prefix translation. Experiments on three translation corpora and two language pairs show the efficacy of the proposed framework on balancing the quality and latency in simultaneous translation.},
archivePrefix = {arXiv},
arxivId = {1911.03154},
author = {Chen, Yun and Li, Liangyou and Jiang, Xin and Chen, Xiao and Liu, Qun},
eprint = {1911.03154},
file = {:Users/zhangshaolei/Documents/计算所/论文/Machine Translation/Simultaneous Translation/How to Do Simultaneous Translation Better with Consecutive Neural Machine Translation?.pdf:pdf},
title = {{How to Do Simultaneous Translation Better with Consecutive Neural Machine Translation?}},
url = {http://arxiv.org/abs/1911.03154},
year = {2019}
}
@article{Cho2016,
title={Can neural machine translation do simultaneous translation?}, 
      author       = {Kyunghyun Cho and
                  Masha Esipova},
  journal      = {CoRR},
  volume       = {abs/1606.02012},
  year         = {2016},
  url          = {http://arxiv.org/abs/1606.02012},
  eprinttype    = {arXiv},
  eprint       = {1606.02012},
  timestamp    = {Mon, 13 Aug 2018 16:47:35 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/ChoE16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{zheng-etal-2019-speculative,
    title = "Speculative Beam Search for Simultaneous Translation",
    author = "Zheng, Renjie  and
      Ma, Mingbo  and
      Zheng, Baigong  and
      Huang, Liang",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1144",
    doi = "10.18653/v1/D19-1144",
    pages = "1395--1402",
    abstract = "Beam search is universally used in (full-sentence) machine translation but its application to simultaneous translation remains highly non-trivial, where output words are committed on the fly. In particular, the recently proposed wait-k policy (Ma et al., 2018) is a simple and effective method that (after an initial wait) commits one output word on receiving each input word, making beam search seemingly inapplicable. To address this challenge, we propose a new speculative beam search algorithm that hallucinates several steps into the future in order to reach a more accurate decision by implicitly benefiting from a target language model. This idea makes beam search applicable for the first time to the generation of a single word in each step. Experiments over diverse language pairs show large improvement compared to previous work.",
}
@inproceedings{dalvi-etal-2018-incremental,
    title = "Incremental Decoding and Training Methods for Simultaneous Translation in Neural Machine Translation",
    author = "Dalvi, Fahim  and
      Durrani, Nadir  and
      Sajjad, Hassan  and
      Vogel, Stephan",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-2079",
    doi = "10.18653/v1/N18-2079",
    pages = "493--499",
    abstract = "We address the problem of simultaneous translation by modifying the Neural MT decoder to operate with dynamically built encoder and attention. We propose a tunable agent which decides the best segmentation strategy for a user-defined BLEU loss and Average Proportion (AP) constraint. Our agent outperforms previously proposed Wait-if-diff and Wait-if-worse agents (Cho and Esipova, 2016) on BLEU with a lower latency. Secondly we proposed data-driven changes to Neural MT training to better match the incremental decoding framework.",
}
@inproceedings{sennrich-etal-2016-neural,
    title = "Neural Machine Translation of Rare Words with Subword Units",
    author = "Sennrich, Rico  and
      Haddow, Barry  and
      Birch, Alexandra",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P16-1162",
    doi = "10.18653/v1/P16-1162",
    pages = "1715--1725",
}
@inproceedings{ma-etal-2019-stacl,
    title = "{STACL}: Simultaneous Translation with Implicit Anticipation and Controllable Latency using Prefix-to-Prefix Framework",
    author = "Ma, Mingbo  and
      Huang, Liang  and
      Xiong, Hao  and
      Zheng, Renjie  and
      Liu, Kaibo  and
      Zheng, Baigong  and
      Zhang, Chuanqiang  and
      He, Zhongjun  and
      Liu, Hairong  and
      Li, Xing  and
      Wu, Hua  and
      Wang, Haifeng",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1289",
    doi = "10.18653/v1/P19-1289",
    pages = "3025--3036",
    abstract = "Simultaneous translation, which translates sentences before they are finished, is use- ful in many scenarios but is notoriously dif- ficult due to word-order differences. While the conventional seq-to-seq framework is only suitable for full-sentence translation, we pro- pose a novel prefix-to-prefix framework for si- multaneous translation that implicitly learns to anticipate in a single translation model. Within this framework, we present a very sim- ple yet surprisingly effective {``}wait-k{''} policy trained to generate the target sentence concur- rently with the source sentence, but always k words behind. Experiments show our strat- egy achieves low latency and reasonable qual- ity (compared to full-sentence translation) on 4 directions: zh鈫攅n and de鈫攅n.",
}
@inproceedings{oda-etal-2015-syntax,
    title = "Syntax-based Simultaneous Translation through Prediction of Unseen Syntactic Constituents",
    author = "Oda, Yusuke  and
      Neubig, Graham  and
      Sakti, Sakriani  and
      Toda, Tomoki  and
      Nakamura, Satoshi",
    booktitle = "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = jul,
    year = "2015",
    address = "Beijing, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P15-1020",
    doi = "10.3115/v1/P15-1020",
    pages = "198--207",
}
@inproceedings{He2015,
    title = "Syntax-based Rewriting for Simultaneous Machine Translation",
    author = "He, He  and
      Grissom II, Alvin  and
      Morgan, John  and
      Boyd-Graber, Jordan  and
      Daum{\'e} III, Hal",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D15-1006",
    doi = "10.18653/v1/D15-1006",
    pages = "55--64",
}
@inproceedings{siahbani-etal-2018-simultaneous,
    title = "Simultaneous Translation using Optimized Segmentation",
    author = "Siahbani, Maryam  and
      Shavarani, Hassan  and
      Alinejad, Ashkan  and
      Sarkar, Anoop",
    booktitle = "Proceedings of the 13th Conference of the Association for Machine Translation in the {A}mericas (Volume 1: Research Papers)",
    month = mar,
    year = "2018",
    address = "Boston, MA",
    publisher = "Association for Machine Translation in the Americas",
    url = "https://www.aclweb.org/anthology/W18-1815",
    pages = "154--167",
}
@inproceedings{Ma2019a,
title={Monotonic Multihead Attention},
author={Xutai Ma and Juan Miguel Pino and James Cross and Liezl Puzon and Jiatao Gu},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=Hyg96gBKPS}
}
@inproceedings{Zheng2019b,
    title = "Simpler and Faster Learning of Adaptive Policies for Simultaneous Translation",
    author = "Zheng, Baigong  and
      Zheng, Renjie  and
      Ma, Mingbo  and
      Huang, Liang",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1137",
    doi = "10.18653/v1/D19-1137",
    pages = "1349--1354",
    abstract = "Simultaneous translation is widely useful but remains challenging. Previous work falls into two main categories: (a) fixed-latency policies such as Ma et al. (2019) and (b) adaptive policies such as Gu et al. (2017). The former are simple and effective, but have to aggressively predict future content due to diverging source-target word order; the latter do not anticipate, but suffer from unstable and inefficient training. To combine the merits of both approaches, we propose a simple supervised-learning framework to learn an adaptive policy from oracle READ/WRITE sequences generated from parallel text. At each step, such an oracle sequence chooses to WRITE the next target word if the available source sentence context provides enough information to do so, otherwise READ the next source word. Experiments on German{\textless}={\textgreater}English show that our method, without retraining the underlying NMT model, can learn flexible policies with better BLEU scores and similar latencies compared to previous work.",
}
@inproceedings{Zheng2019a,
    title = "Simultaneous Translation with Flexible Policy via Restricted Imitation Learning",
    author = "Zheng, Baigong  and
      Zheng, Renjie  and
      Ma, Mingbo  and
      Huang, Liang",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1582",
    doi = "10.18653/v1/P19-1582",
    pages = "5816--5822",
    abstract = "Simultaneous translation is widely useful but remains one of the most difficult tasks in NLP. Previous work either uses fixed-latency policies, or train a complicated two-staged model using reinforcement learning. We propose a much simpler single model that adds a {``}delay{''} token to the target vocabulary, and design a restricted dynamic oracle to greatly simplify training. Experiments on Chinese {\textless}-{\textgreater} English simultaneous translation show that our work leads to flexible policies that achieve better BLEU scores and lower latencies compared to both fixed and RL-learned policies.",
}
@inproceedings{Arivazhagan2019,
title = "Monotonic Infinite Lookback Attention for Simultaneous Machine Translation",
    author = "Arivazhagan, Naveen  and
      Cherry, Colin  and
      Macherey, Wolfgang  and
      Chiu, Chung-Cheng  and
      Yavuz, Semih  and
      Pang, Ruoming  and
      Li, Wei  and
      Raffel, Colin",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'\i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1126",
    doi = "10.18653/v1/P19-1126",
    pages = "1313--1323",
    abstract = "Simultaneous machine translation begins to translate each source sentence before the source speaker is finished speaking, with applications to live and streaming scenarios. Simultaneous systems must carefully schedule their reading of the source sentence to balance quality against latency. We present the first simultaneous translation system to learn an adaptive schedule jointly with a neural machine translation (NMT) model that attends over all source tokens read thus far. We do so by introducing Monotonic Infinite Lookback (MILk) attention, which maintains both a hard, monotonic attention head to schedule the reading of the source sentence, and a soft attention head that extends from the monotonic head back to the beginning of the source. We show that MILk{'}s adaptive schedule allows it to arrive at latency-quality trade-offs that are favorable to those of a recently proposed wait-k strategy for many latency values.",
}
@incollection{NIPS2017_7181,
title = {Attention is All you Need},
author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {5998--6008},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf}
}
@inproceedings{zhang-etal-2018-accelerating,
    title = "Accelerating Neural Transformer via an Average Attention Network",
    author = "Zhang, Biao  and
      Xiong, Deyi  and
      Su, Jinsong",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P18-1166",
    doi = "10.18653/v1/P18-1166",
    pages = "1789--1798",
    abstract = "With parallelizable attention networks, the neural Transformer is very fast to train. However, due to the auto-regressive architecture and self-attention in the decoder, the decoding procedure becomes slow. To alleviate this issue, we propose an average attention network as an alternative to the self-attention network in the decoder of the neural Transformer. The average attention network consists of two layers, with an average layer that models dependencies on previous positions and a gating layer that is stacked over the average layer to enhance the expressiveness of the proposed attention network. We apply this network on the decoder part of the neural Transformer to replace the original target-side self-attention model. With masking tricks and dynamic programming, our model enables the neural Transformer to decode sentences over four times faster than its original version with almost no loss in training time and translation performance. We conduct a series of experiments on WMT17 translation tasks, where on 6 different language pairs, we obtain robust and consistent speed-ups in decoding.",
}
@inproceedings{Alinejad2019,
    title = "Prediction Improves Simultaneous Neural Machine Translation",
    author = "Alinejad, Ashkan  and
      Siahbani, Maryam  and
      Sarkar, Anoop",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1337",
    doi = "10.18653/v1/D18-1337",
    pages = "3022--3027",
    abstract = "Simultaneous speech translation aims to maintain translation quality while minimizing the delay between reading input and incrementally producing the output. We propose a new general-purpose prediction action which predicts future words in the input to improve quality and minimize delay in simultaneous translation. We train this agent using reinforcement learning with a novel reward function. Our agent with prediction has better translation quality and less delay compared to an agent-based simultaneous translation system without prediction.",
}
@inproceedings{bangalore-etal-2012-real,
    title = "Real-time Incremental Speech-to-Speech Translation of Dialogs",
    author = "Bangalore, Srinivas  and
      Rangarajan Sridhar, Vivek Kumar  and
      Kolan, Prakash  and
      Golipour, Ladan  and
      Jimenez, Aura",
    booktitle = "Proceedings of the 2012 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2012",
    address = "Montr{\'e}al, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N12-1048",
    pages = "437--445",
}
@inproceedings{grissom-ii-etal-2016-incremental,
    title = "Incremental Prediction of Sentence-final Verbs: Humans versus Machines",
    author = "Grissom II, Alvin  and
      Orita, Naho  and
      Boyd-Graber, Jordan",
    booktitle = "Proceedings of The 20th {SIGNLL} Conference on Computational Natural Language Learning",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/K16-1010",
    doi = "10.18653/v1/K16-1010",
    pages = "95--104",
}
@article{Ravanelli2018,
abstract = {Online speech recognition is crucial for developing natural human-machine interfaces. This modality, however, is significantly more challenging than off-line ASR, since real-time/low-latency constraints inevitably hinder the use of future information, that is known to be very helpful to perform robust predictions. A popular solution to mitigate this issue consists of feeding neural acoustic models with context windows that gather some future frames. This introduces a latency which depends on the number of employed look-ahead features. This paper explores a different approach, based on estimating the future rather than waiting for it. Our technique encourages the hidden representations of a unidirectional recurrent network to embed some useful information about the future. Inspired by a recently proposed technique called Twin Networks, we add a regularization term that forces forward hidden states to be as close as possible to cotemporal backward ones, computed by a “twin” neural network running backwards in time. The experiments, conducted on a number of datasets, recurrent architectures, input features, and acoustic conditions, have shown the effectiveness of this approach. One important advantage is that our method does not introduce any additional computation at test time if compared to standard unidirectional recurrent networks.},
archivePrefix = {arXiv},
arxivId = {1804.05374},
author = {Ravanelli, Mirco and Serdyuk, Dmitriy and Bengio, Yoshua},
doi = {10.21437/Interspeech.2018-1407},
eprint = {1804.05374},
file = {:Users/zhangshaolei/Documents/计算所/论文/Alignments/Twin Regularization for online speech recognition.pdf:pdf},
issn = {19909772},
journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
keywords = {Deep learning,Online speech recognition,Recurrent neural networks,Regularization},
mendeley-groups = {Alignments,EMNLP2020},
number = {1},
pages = {3718--3722},
title = {{Twin Regularization for online speech recognition}},
volume = {2018-Septe},
year = {2018},
url={https://www.isca-speech.org/archive_v0/Interspeech_2018/abstracts/1407.html}
}
@article{Novitasari2019,
author = {Novitasari, Sashi and Tjandra, Andros and Sakti, Sakriani and Nakamura, Satoshi},
file = {:Users/zhangshaolei/Documents/计算所/论文/Alignments/Sequence-to-Sequence Learning via Attention Transfer for Incremental Speech Recognition.pdf:pdf},
keywords = {[Electronic Manuscript]},
mendeley-groups = {Alignments,EMNLP2020},
pages = {3835--3839},
title = {{Sequence-to-Sequence Learning via Attention Transfer for Incremental Speech Recognition}},
year = {2019}
}
@inproceedings{Shigeki2000,
    title = "Simultaneous Japenese-English Interpretation Based on Early Predictoin of English Verb",
    author = " Matsubara, Shigeki
    Iwashima, Keiichi  and 
    Kawaguchi, Nobuo and 
    Toyama, Katsuhiko and 
    Inagaki, Yasuyoshi  ",
    booktitle = "Proceedings of the 4th Symposium on Natural Languauge Processing(SNLP-2000)",
    year = "2000",
    pages = "268--273",
}
@inproceedings{ott-etal-2019-fairseq,
    title = "fairseq: A Fast, Extensible Toolkit for Sequence Modeling",
    author = "Ott, Myle  and
      Edunov, Sergey  and
      Baevski, Alexei  and
      Fan, Angela  and
      Gross, Sam  and
      Ng, Nathan  and
      Grangier, David  and
      Auli, Michael",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics (Demonstrations)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-4009",
    doi = "10.18653/v1/N19-4009",
    pages = "48--53",
    abstract = "fairseq is an open-source sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling, and other text generation tasks. The toolkit is based on PyTorch and supports distributed training across multiple GPUs and machines. We also support fast mixed-precision training and inference on modern GPUs. A demo video can be found at https://www.youtube.com/watch?v=OtgDdWtHvto",
}

@misc{kn,
Author = {Geoffrey Hinton and Oriol Vinyals and Jeff Dean},
Title = {Distilling the Knowledge in a Neural Network},
Year = {2015},
Eprint = {arXiv:1503.02531},
}


@inproceedings{chen2020general,
    title = "A General Framework for Adaptation of Neural Machine Translation to Simultaneous Translation",
    author = "Chen, Yun  and
      Li, Liangyou  and
      Jiang, Xin  and
      Chen, Xiao  and
      Liu, Qun",
    booktitle = "Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing",
    month = dec,
    year = "2020",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.aacl-main.23",
    pages = "191--200",
    abstract = "Despite the success of neural machine translation (NMT), simultaneous neural machine translation (SNMT), the task of translating in real time before a full sentence has been observed, remains challenging due to the syntactic structure difference and simultaneity requirements. In this paper, we propose a general framework for adapting neural machine translation to translate simultaneously. Our framework contains two parts: prefix translation that utilizes a consecutive NMT model to translate source prefixes and a stopping criterion that determines when to stop the prefix translation. Experiments on three translation corpora and two language pairs show the efficacy of the proposed framework on balancing the quality and latency in adapting NMT to perform simultaneous translation.",
}

@inproceedings{papineni-etal-2002-bleu,
    title = "{B}leu: a Method for Automatic Evaluation of Machine Translation",
    author = "Papineni, Kishore  and
      Roukos, Salim  and
      Ward, Todd  and
      Zhu, Wei-Jing",
    booktitle = "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2002",
    address = "Philadelphia, Pennsylvania, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P02-1040",
    doi = "10.3115/1073083.1073135",
    pages = "311--318",
}


@article{future-guided, title={Future-Guided Incremental Transformer for Simultaneous Translation}, volume={35}, url={https://ojs.aaai.org/index.php/AAAI/article/view/17696}, abstractNote={Simultaneous translation (ST) starts translations synchronously while reading source sentences, and is used in many online scenarios. The previous wait-k policy is concise and achieved good results in ST. However, wait-k policy faces two weaknesses: low training speed caused by the recalculation of hidden states and lack of future source information to guide training. For the low training speed, we propose an incremental Transformer with an average embedding layer (AEL) to accelerate the speed of calculation of the hidden states during training. For future-guided training, we propose a conventional Transformer as the teacher of the incremental Transformer, and try to invisibly embed some future information in the model through knowledge distillation. We conducted experiments on Chinese-English and German-English simultaneous translation tasks and compared with the wait-k policy to evaluate the proposed method. Our method can effectively increase the training speed by about 28 times on average at different k and implicitly embed some predictive abilities in the model, achieving better translation quality than wait-k baseline.}, number={16}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Zhang, Shaolei and Feng, Yang and Li, Liangyou}, year={2021}, month={May}, pages={14428-14436} }

@misc{multipath,
author={Maha Elbayad and Laurent Besacier and Jakob Verbeek},
  title={{Efficient Wait-k Models for Simultaneous Machine Translation}},
  Year= {2020},
  booktitle={Proc. Interspeech 2020},
  pages={1461--1465},
  doi={10.21437/Interspeech.2020-1241},
  url={http://dx.doi.org/10.21437/Interspeech.2020-1241}
}

@misc{2007.05290,
Author = {Xueqing Wu and Yingce Xia and Lijun Wu and Shufang Xie and Weiqing Liu and Jiang Bian and Tao Qin and Tie-Yan Liu},
Title = {Learn to Use Future Information in Simultaneous Translation},
Year = {2020},
Eprint = {arXiv:2007.05290},
}

@inproceedings{post-2018-call,
    title = "A Call for Clarity in Reporting {BLEU} Scores",
    author = "Post, Matt",
    booktitle = "Proceedings of the Third Conference on Machine Translation: Research Papers",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6319",
    doi = "10.18653/v1/W18-6319",
    pages = "186--191",
    abstract = "The field of machine translation faces an under-recognized problem because of inconsistency in the reporting of scores from its dominant metric. Although people refer to {``}the{''} BLEU score, BLEU is in fact a parameterized metric whose values can vary wildly with changes to these parameters. These parameters are often not reported or are hard to find, and consequently, BLEU scores between papers cannot be directly compared. I quantify this variation, finding differences as high as 1.8 between commonly used configurations. The main culprit is different tokenization and normalization schemes applied to the reference. Pointing to the success of the parsing community, I suggest machine translation researchers settle upon the BLEU scheme used by the annual Conference on Machine Translation (WMT), which does not allow for user-supplied reference processing, and provide a new tool, SACREBLEU, to facilitate this.",
}

@inproceedings{zhang-etal-2020-learning-adaptive,
    title = "Learning Adaptive Segmentation Policy for Simultaneous Translation",
    author = "Zhang, Ruiqing  and
      Zhang, Chuanqiang  and
      He, Zhongjun  and
      Wu, Hua  and
      Wang, Haifeng",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.178",
    doi = "10.18653/v1/2020.emnlp-main.178",
    pages = "2280--2289",
    abstract = "Balancing accuracy and latency is a great challenge for simultaneous translation. To achieve high accuracy, the model usually needs to wait for more streaming text before translation, which results in increased latency. However, keeping low latency would probably hurt accuracy. Therefore, it is essential to segment the ASR output into appropriate units for translation. Inspired by human interpreters, we propose a novel adaptive segmentation policy for simultaneous translation. The policy learns to segment the source text by considering possible translations produced by the translation model, maintaining consistency between the segmentation and translation. Experimental results on Chinese-English and German-English translation show that our method achieves a better accuracy-latency trade-off over recently proposed state-of-the-art methods.",
}

@inproceedings{zheng-etal-2020-simultaneous,
    title = "Simultaneous Translation Policies: From Fixed to Adaptive",
    author = "Zheng, Baigong  and
      Liu, Kaibo  and
      Zheng, Renjie  and
      Ma, Mingbo  and
      Liu, Hairong  and
      Huang, Liang",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.254",
    doi = "10.18653/v1/2020.acl-main.254",
    pages = "2847--2853",
    abstract = "Adaptive policies are better than fixed policies for simultaneous translation, since they can flexibly balance the tradeoff between translation quality and latency based on the current context information. But previous methods on obtaining adaptive policies either rely on complicated training process, or underperform simple fixed policies. We design an algorithm to achieve adaptive policies via a simple heuristic composition of a set of fixed policies. Experiments on Chinese -{\textgreater} English and German -{\textgreater} English show that our adaptive policies can outperform fixed ones by up to 4 BLEU points for the same latency, and more surprisingly, it even surpasses the BLEU score of full-sentence translation in the greedy mode (and very close to beam mode), but with much lower latency.",
}



@inproceedings{chen_combining_2018,
	address = {New Orleans, Louisiana},
	title = {Combining {Character} and {Word} {Information} in {Neural} {Machine} {Translation} {Using} a {Multi}-{Level} {Attention}},
	url = {http://aclweb.org/anthology/N18-1116},
	doi = {10.18653/v1/N18-1116},
	abstract = {Natural language sentences, being hierarchical, can be represented at diﬀerent levels of granularity, like words, subwords, or characters. But most neural machine translation systems require the sentence to be represented as a sequence at a single level of granularity. It can be diﬃcult to determine which granularity is better for a particular translation task. In this paper, we improve the model by incorporating multiple levels of granularity. Speciﬁcally, we propose (1) an encoder with character attention which augments the (sub)word-level representation with character-level information; (2) a decoder with multiple attentions that enable the representations from diﬀerent levels of granularity to control the translation cooperatively. Experiments on three translation tasks demonstrate that our proposed models outperform the standard word-based model, the subword-based model and a strong characterbased model.},
	language = {en},
	urldate = {2020-12-13},
	booktitle = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of           the {Association} for {Computational} {Linguistics}: {Human} {Language}           {Technologies}, {Volume} 1 ({Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Chen, Huadong and Huang, Shujian and Chiang, David and Dai, Xinyu and Chen, Jiajun},
	year = {2018},
	pages = {1284--1293},
	file = {Chen 等。 - 2018 - Combining Character and Word Information in Neural.pdf:D\:\\Documents\\zotero\\storage\\CRXLGW9W\\Chen 等。 - 2018 - Combining Character and Word Information in Neural.pdf:application/pdf},
}

@article{ling_character-based_2015,
	title = {Character-based {Neural} {Machine} {Translation}},
	url = {http://arxiv.org/abs/1511.04586},
	abstract = {We introduce a neural machine translation model that views the input and output sentences as sequences of characters rather than words. Since word-level information provides a crucial source of bias, our input model composes representations of character sequences into representations of words (as determined by whitespace boundaries), and then these are translated using a joint attention/translation model. In the target language, the translation is modeled as a sequence of word vectors, but each word is generated one character at a time, conditional on the previous character generations in each word. As the representation and generation of words is performed at the character level, our model is capable of interpreting and generating unseen word forms. A secondary beneﬁt of this approach is that it alleviates much of the challenges associated with preprocessing/tokenization of the source and target languages. We show that our model can achieve translation results that are on par with conventional word-based models.},
	language = {en},
	urldate = {2020-12-13},
	journal = {arXiv:1511.04586 [cs]},
	author = {Ling, Wang and Trancoso, Isabel and Dyer, Chris and Black, Alan W.},
	month = nov,
	year = {2015},
	note = {arXiv: 1511.04586},
	keywords = {Computer Science - Computation and Language},
	file = {Ling 等。 - 2015 - Character-based Neural Machine Translation.pdf:D\:\\Documents\\zotero\\storage\\CSCT8RMG\\Ling 等。 - 2015 - Character-based Neural Machine Translation.pdf:application/pdf},
}

@inproceedings{gao_character-level_2020,
	address = {Online},
	title = {Character-{Level} {Translation} with {Self}-attention},
	url = {https://www.aclweb.org/anthology/2020.acl-main.145},
	doi = {10.18653/v1/2020.acl-main.145},
	language = {en},
	urldate = {2020-12-13},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Gao, Yingqiang and Nikolov, Nikola I. and Hu, Yuhuang and Hahnloser, Richard H.R.},
	year = {2020},
	pages = {1591--1604},
	file = {Gao 等。 - 2020 - Character-Level Translation with Self-attention.pdf:D\:\\Documents\\zotero\\storage\\F7U2TF2Z\\Gao 等。 - 2020 - Character-Level Translation with Self-attention.pdf:application/pdf},
}

@article{libovicky_towards_nodate,
	title = {Towards {Reasonably}-{Sized} {Character}-{Level} {Transformer} {NMT} by {Finetuning} {Subword} {Systems}},
	abstract = {Applying the Transformer architecture on the character level usually requires very deep architectures that are difﬁcult and slow to train. These problems can be partially overcome by incorporating a segmentation into tokens in the model. We show that by initially training a subword model and then ﬁnetuning it on characters, we can obtain a neural machine translation model that works at the character level without requiring token segmentation. We use only the vanilla 6-layer Transformer Base architecture. Our character-level models better capture morphological phenomena and show more robustness to noise at the expense of somewhat worse overall translation quality. Our study is a signiﬁcant step towards highperformance and easy to train character-based models that are not extremely large.},
	language = {en},
	author = {Libovický, Jindřich and Fraser, Alexander},
	pages = {8},
	file = {Libovický 和 Fraser - Towards Reasonably-Sized Character-Level Transform.pdf:D\:\\Documents\\zotero\\storage\\MJRRD9KQ\\Libovický 和 Fraser - Towards Reasonably-Sized Character-Level Transform.pdf:application/pdf},
}

@inproceedings{cherry_revisiting_2018,
	address = {Brussels, Belgium},
	title = {Revisiting {Character}-{Based} {Neural} {Machine} {Translation} with {Capacity} and {Compression}},
	url = {http://aclweb.org/anthology/D18-1461},
	doi = {10.18653/v1/D18-1461},
	abstract = {Translating characters instead of words or word-fragments has the potential to simplify the processing pipeline for neural machine translation (NMT), and improve results by eliminating hyper-parameters and manual feature engineering. However, it results in longer sequences in which each symbol contains less information, creating both modeling and computational challenges. In this paper, we show that the modeling problem can be solved by standard sequence-to-sequence architectures of sufﬁcient depth, and that deep models operating at the character level outperform identical models operating over word fragments. This result implies that alternative architectures for handling character input are better viewed as methods for reducing computation time than as improved ways of modeling longer sequences. From this perspective, we evaluate several techniques for characterlevel NMT, verify that they do not match the performance of our deep character baseline model, and evaluate the performance versus computation time tradeoffs they offer. Within this framework, we also perform the ﬁrst evaluation for NMT of conditional computation over time, in which the model learns which timesteps can be skipped, rather than having them be dictated by a ﬁxed schedule speciﬁed before training begins.},
	language = {en},
	urldate = {2020-12-13},
	booktitle = {Proceedings of the 2018 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Cherry, Colin and Foster, George and Bapna, Ankur and Firat, Orhan and Macherey, Wolfgang},
	year = {2018},
	pages = {4295--4305},
	file = {Cherry 等。 - 2018 - Revisiting Character-Based Neural Machine Translat.pdf:D\:\\Documents\\zotero\\storage\\34XY6MLZ\\Cherry 等。 - 2018 - Revisiting Character-Based Neural Machine Translat.pdf:application/pdf},
}

@article{lee_fully_2017,
	title = {Fully {Character}-{Level} {Neural} {Machine} {Translation} without {Explicit} {Segmentation}},
	volume = {5},
	issn = {2307-387X},
	url = {https://www.mitpressjournals.org/doi/abs/10.1162/tacl_a_00067},
	doi = {10.1162/tacl_a_00067},
	abstract = {Most existing machine translation systems operate at the level of words, relying on explicit segmentation to extract tokens. We introduce a neural machine translation (NMT) model that maps a source character sequence to a target character sequence without any segmentation. We employ a character-level convolutional network with max-pooling at the encoder to reduce the length of source representation, allowing the model to be trained at a speed comparable to subword-level models while capturing local regularities. Our character-to-character model outperforms a recently proposed baseline with a subwordlevel encoder on WMT’15 DE-EN and CSEN, and gives comparable performance on FIEN and RU-EN. We then demonstrate that it is possible to share a single characterlevel encoder across multiple languages by training a model on a many-to-one translation task. In this multilingual setting, the character-level encoder signiﬁcantly outperforms the subword-level encoder on all the language pairs. We observe that on CS-EN, FI-EN and RU-EN, the quality of the multilingual character-level translation even surpasses the models speciﬁcally trained on that language pair alone, both in terms of the BLEU score and human judgment.},
	language = {en},
	urldate = {2020-12-13},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Lee, Jason and Cho, Kyunghyun and Hofmann, Thomas},
	month = dec,
	year = {2017},
	pages = {365--378},
	file = {Lee 等。 - 2017 - Fully Character-Level Neural Machine Translation w.pdf:D\:\\Documents\\zotero\\storage\\J2GDN7J3\\Lee 等。 - 2017 - Fully Character-Level Neural Machine Translation w.pdf:application/pdf},
}

@inproceedings{costa-jussa_character-based_2016,
	address = {Berlin, Germany},
	title = {Character-based {Neural} {Machine} {Translation}},
	url = {https://www.aclweb.org/anthology/P16-2058},
	doi = {10.18653/v1/P16-2058},
	urldate = {2020-12-14},
	booktitle = {Proceedings of the 54th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 2: {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Costa-jussà, Marta R. and Fonollosa, José A. R.},
	month = aug,
	year = {2016},
	pages = {357--361},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\4Y83CGBE\\Costa-jussà 和 Fonollosa - 2016 - Character-based Neural Machine Translation.pdf:application/pdf},
}

@inproceedings{eriguchi_character-based_2016,
	address = {Osaka, Japan},
	title = {Character-based {Decoding} in {Tree}-to-{Sequence} {Attention}-based {Neural} {Machine} {Translation}},
	url = {https://www.aclweb.org/anthology/W16-4617},
	abstract = {This paper reports our systems (UT-AKY) submitted in the 3rd Workshop of Asian Translation 2016 (WAT'16) and their results in the English-to-Japanese translation task. Our model is based on the tree-to-sequence Attention-based NMT (ANMT) model proposed by Eriguchi et al. (2016). We submitted two ANMT systems: one with a word-based decoder and the other with a character-based decoder. Experimenting on the English-to-Japanese translation task, we have confirmed that the character-based decoder can cover almost the full vocabulary in the target language and generate translations much faster than the word-based model.},
	urldate = {2020-12-14},
	booktitle = {Proceedings of the 3rd {Workshop} on {Asian} {Translation} ({WAT2016})},
	publisher = {The COLING 2016 Organizing Committee},
	author = {Eriguchi, Akiko and Hashimoto, Kazuma and Tsuruoka, Yoshimasa},
	month = dec,
	year = {2016},
	pages = {175--183},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\6NQ8CIQV\\Eriguchi 等。 - 2016 - Character-based Decoding in Tree-to-Sequence Atten.pdf:application/pdf},
}

@inproceedings{vilar_can_2007,
	address = {Prague, Czech Republic},
	title = {Can we translate letters?},
	url = {http://portal.acm.org/citation.cfm?doid=1626355.1626360},
	doi = {10.3115/1626355.1626360},
	abstract = {Current statistical machine translation systems handle the translation process as the transformation of a string of symbols into another string of symbols. Normally the symbols dealt with are the words in different languages, sometimes with some additional information included, like morphological data. In this work we try to push the approach to the limit, working not on the level of words, but treating both the source and target sentences as a string of letters. We try to ﬁnd out if a nearly unmodiﬁed state-of-the-art translation system is able to cope with the problem and whether it is capable to further generalize translation rules, for example at the level of word sufﬁxes and translation of unseen words. Experiments are carried out for the translation of Catalan to Spanish.},
	language = {en},
	urldate = {2020-12-14},
	booktitle = {Proceedings of the {Second} {Workshop} on {Statistical} {Machine} {Translation} - {StatMT} '07},
	publisher = {Association for Computational Linguistics},
	author = {Vilar, David and Peter, Jan-T. and Ney, Hermann},
	year = {2007},
	pages = {33--39},
	file = {Vilar 等。 - 2007 - Can we translate letters.pdf:D\:\\Documents\\zotero\\storage\\7MRI9XQG\\Vilar 等。 - 2007 - Can we translate letters.pdf:application/pdf},
}

@inproceedings{nakov_combining_2012,
	address = {Jeju Island, Korea},
	title = {Combining {Word}-{Level} and {Character}-{Level} {Models} for {Machine} {Translation} {Between} {Closely}-{Related} {Languages}},
	url = {https://www.aclweb.org/anthology/P12-2059},
	urldate = {2020-12-14},
	booktitle = {Proceedings of the 50th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 2: {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Nakov, Preslav and Tiedemann, Jörg},
	month = jul,
	year = {2012},
	pages = {301--305},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\NQ2YSSQP\\Nakov 和 Tiedemann - 2012 - Combining Word-Level and Character-Level Models fo.pdf:application/pdf},
}

@inproceedings{passban_improving_2018,
	address = {New Orleans, Louisiana},
	title = {Improving {Character}-{Based} {Decoding} {Using} {Target}-{Side} {Morphological} {Information} for {Neural} {Machine} {Translation}},
	url = {https://www.aclweb.org/anthology/N18-1006},
	doi = {10.18653/v1/N18-1006},
	abstract = {Recently, neural machine translation (NMT) has emerged as a powerful alternative to conventional statistical approaches. However, its performance drops considerably in the presence of morphologically rich languages (MRLs). Neural engines usually fail to tackle the large vocabulary and high out-of-vocabulary (OOV) word rate of MRLs. Therefore, it is not suitable to exploit existing word-based models to translate this set of languages. In this paper, we propose an extension to the state-of-the-art model of Chung et al. (2016), which works at the character level and boosts the decoder with target-side morphological information. In our architecture, an additional morphology table is plugged into the model. Each time the decoder samples from a target vocabulary, the table sends auxiliary signals from the most relevant affixes in order to enrich the decoder's current state and constrain it to provide better predictions. We evaluated our model to translate English into German, Russian, and Turkish as three MRLs and observed significant improvements.},
	urldate = {2020-12-14},
	booktitle = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Passban, Peyman and Liu, Qun and Way, Andy},
	month = jun,
	year = {2018},
	pages = {58--68},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\YVK8MHBZ\\Passban 等。 - 2018 - Improving Character-Based Decoding Using Target-Si.pdf:application/pdf},
}

@inproceedings{luong_achieving_2016,
	address = {Berlin, Germany},
	title = {Achieving {Open} {Vocabulary} {Neural} {Machine} {Translation} with {Hybrid} {Word}-{Character} {Models}},
	url = {https://www.aclweb.org/anthology/P16-1100},
	doi = {10.18653/v1/P16-1100},
	urldate = {2020-12-14},
	booktitle = {Proceedings of the 54th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Luong, Minh-Thang and Manning, Christopher D.},
	month = aug,
	year = {2016},
	pages = {1054--1063},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\W8FL6TTG\\Luong 和 Manning - 2016 - Achieving Open Vocabulary Neural Machine Translati.pdf:application/pdf},
}

@inproceedings{tang_understanding_2020,
	address = {Barcelona, Spain (Online)},
	title = {Understanding {Pure} {Character}-{Based} {Neural} {Machine} {Translation}: {The} {Case} of {Translating} {Finnish} into {English}},
	shorttitle = {Understanding {Pure} {Character}-{Based} {Neural} {Machine} {Translation}},
	url = {https://www.aclweb.org/anthology/2020.coling-main.375},
	abstract = {Recent work has shown that deeper character-based neural machine translation (NMT) models can outperform subword-based models. However, it is still unclear what makes deeper character-based models successful. In this paper, we conduct an investigation into pure character-based models in the case of translating Finnish into English, including exploring the ability to learn word senses and morphological inflections and the attention mechanism. We demonstrate that word-level information is distributed over the entire character sequence rather than over a single character, and characters at different positions play different roles in learning linguistic knowledge. In addition, character-based models need more layers to encode word senses which explains why only deeper models outperform subword-based models. The attention distribution pattern shows that separators attract a lot of attention and we explore a sparse word-level attention to enforce character hidden states to capture the full word-level information. Experimental results show that the word-level attention with a single head results in 1.2 BLEU points drop.},
	urldate = {2020-12-14},
	booktitle = {Proceedings of the 28th {International} {Conference} on {Computational} {Linguistics}},
	publisher = {International Committee on Computational Linguistics},
	author = {Tang, Gongbo and Sennrich, Rico and Nivre, Joakim},
	month = dec,
	year = {2020},
	pages = {4251--4262},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\FH9K8WPI\\Tang 等。 - 2020 - Understanding Pure Character-Based Neural Machine .pdf:application/pdf},
}

@inproceedings{yang_character-aware_2016,
	address = {Osaka, Japan},
	title = {A {Character}-{Aware} {Encoder} for {Neural} {Machine} {Translation}},
	url = {https://www.aclweb.org/anthology/C16-1288},
	abstract = {This article proposes a novel character-aware neural machine translation (NMT) model that views the input sequences as sequences of characters rather than words. On the use of row convolution (Amodei et al., 2015), the encoder of the proposed model composes word-level information from the input sequences of characters automatically. Since our model doesn't rely on the boundaries between each word (as the whitespace boundaries in English), it is also applied to languages without explicit word segmentations (like Chinese). Experimental results on Chinese-English translation tasks show that the proposed character-aware NMT model can achieve comparable translation performance with the traditional word based NMT models. Despite the target side is still word based, the proposed model is able to generate much less unknown words.},
	urldate = {2020-12-14},
	booktitle = {Proceedings of {COLING} 2016, the 26th {International} {Conference} on {Computational} {Linguistics}: {Technical} {Papers}},
	publisher = {The COLING 2016 Organizing Committee},
	author = {Yang, Zhen and Chen, Wei and Wang, Feng and Xu, Bo},
	month = dec,
	year = {2016},
	pages = {3063--3070},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\9MSBG33W\\Yang 等。 - 2016 - A Character-Aware Encoder for Neural Machine Trans.pdf:application/pdf},
}

@inproceedings{ataman_importance_2019,
	address = {Hong Kong},
	title = {On the {Importance} of {Word} {Boundaries} in {Character}-level {Neural} {Machine} {Translation}},
	url = {https://www.aclweb.org/anthology/D19-5619},
	doi = {10.18653/v1/D19-5619},
	abstract = {Neural Machine Translation (NMT) models generally perform translation using a fixed-size lexical vocabulary, which is an important bottleneck on their generalization capability and overall translation quality. The standard approach to overcome this limitation is to segment words into subword units, typically using some external tools with arbitrary heuristics, resulting in vocabulary units not optimized for the translation task. Recent studies have shown that the same approach can be extended to perform NMT directly at the level of characters, which can deliver translation accuracy on-par with subword-based models, on the other hand, this requires relatively deeper networks. In this paper, we propose a more computationally-efficient solution for character-level NMT which implements a hierarchical decoding architecture where translations are subsequently generated at the level of words and characters. We evaluate different methods for open-vocabulary NMT in the machine translation task from English into five languages with distinct morphological typology, and show that the hierarchical decoding model can reach higher translation accuracy than the subword-level NMT model using significantly fewer parameters, while demonstrating better capacity in learning longer-distance contextual and grammatical dependencies than the standard character-level NMT model.},
	urldate = {2020-12-15},
	booktitle = {Proceedings of the 3rd {Workshop} on {Neural} {Generation} and {Translation}},
	publisher = {Association for Computational Linguistics},
	author = {Ataman, Duygu and Firat, Orhan and Di Gangi, Mattia A. and Federico, Marcello and Birch, Alexandra},
	month = nov,
	year = {2019},
	pages = {187--193},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\RGDIKNY4\\Ataman 等。 - 2019 - On the Importance of Word Boundaries in Character-.pdf:application/pdf},
}

@inproceedings{sennrich_how_2017,
	address = {Valencia, Spain},
	title = {How {Grammatical} is {Character}-level {Neural} {Machine} {Translation}? {Assessing} {MT} {Quality} with {Contrastive} {Translation} {Pairs}},
	shorttitle = {How {Grammatical} is {Character}-level {Neural} {Machine} {Translation}?},
	url = {https://www.aclweb.org/anthology/E17-2060},
	abstract = {Analysing translation quality in regards to specific linguistic phenomena has historically been difficult and time-consuming. Neural machine translation has the attractive property that it can produce scores for arbitrary translations, and we propose a novel method to assess how well NMT systems model specific linguistic phenomena such as agreement over long distances, the production of novel words, and the faithful translation of polarity. The core idea is that we measure whether a reference translation is more probable under a NMT model than a contrastive translation which introduces a specific type of error. We present LingEval97, a large-scale data set of 97000 contrastive translation pairs based on the WMT English-{\textbackslash}textgreaterGerman translation task, with errors automatically created with simple rules. We report results for a number of systems, and find that recently introduced character-level NMT systems perform better at transliteration than models with byte-pair encoding (BPE) segmentation, but perform more poorly at morphosyntactic agreement, and translating discontiguous units of meaning.},
	urldate = {2020-12-15},
	booktitle = {Proceedings of the 15th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}: {Volume} 2, {Short} {Papers}},
	publisher = {Association for Computational Linguistics},
	author = {Sennrich, Rico},
	month = apr,
	year = {2017},
	pages = {376--382},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\XMJD3TPK\\Sennrich - 2017 - How Grammatical is Character-level Neural Machine .pdf:application/pdf},
}

@inproceedings{gulcehre_plan_2017,
	address = {Vancouver, Canada},
	title = {Plan, {Attend}, {Generate}: {Character}-{Level} {Neural} {Machine} {Translation} with {Planning}},
	shorttitle = {Plan, {Attend}, {Generate}},
	url = {https://www.aclweb.org/anthology/W17-2627},
	doi = {10.18653/v1/W17-2627},
	abstract = {We investigate the integration of a planning mechanism into an encoder-decoder architecture with attention. We develop a model that can plan ahead when it computes alignments between the source and target sequences not only for a single time-step but for the next k time-steps as well by constructing a matrix of proposed future alignments and a commitment vector that governs whether to follow or recompute the plan. This mechanism is inspired by strategic attentive reader and writer (STRAW) model, a recent neural architecture for planning with hierarchical reinforcement learning that can also learn higher level temporal abstractions. Our proposed model is end-to-end trainable with differentiable operations. We show that our model outperforms strong baselines on character-level translation task from WMT'15 with fewer parameters and computes alignments that are qualitatively intuitive.},
	urldate = {2020-12-15},
	booktitle = {Proceedings of the 2nd {Workshop} on {Representation} {Learning} for {NLP}},
	publisher = {Association for Computational Linguistics},
	author = {Gulcehre, Caglar and Dutil, Francis and Trischler, Adam and Bengio, Yoshua},
	month = aug,
	year = {2017},
	pages = {228--234},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\GVW49G87\\Gulcehre 等。 - 2017 - Plan, Attend, Generate Character-Level Neural Mac.pdf:application/pdf},
}

@inproceedings{chung_character-level_2016,
	address = {Berlin, Germany},
	title = {A {Character}-level {Decoder} without {Explicit} {Segmentation} for {Neural} {Machine} {Translation}},
	url = {https://www.aclweb.org/anthology/P16-1160},
	doi = {10.18653/v1/P16-1160},
	urldate = {2020-12-15},
	booktitle = {Proceedings of the 54th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Chung, Junyoung and Cho, Kyunghyun and Bengio, Yoshua},
	month = aug,
	year = {2016},
	pages = {1693--1703},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\6AJ54WIY\\Chung 等。 - 2016 - A Character-level Decoder without Explicit Segment.pdf:application/pdf},
}

@inproceedings{dai_compact_2019,
	address = {Hong Kong, China},
	title = {Compact and {Robust} {Models} for {Japanese}-{English} {Character}-level {Machine} {Translation}},
	url = {https://www.aclweb.org/anthology/D19-5202},
	doi = {10.18653/v1/D19-5202},
	abstract = {Character-level translation has been proved to be able to achieve preferable translation quality without explicit segmentation, but training a character-level model needs a lot of hardware resources. In this paper, we introduced two character-level translation models which are mid-gated model and multi-attention model for Japanese-English translation. We showed that the mid-gated model achieved the better performance with respect to BLEU scores. We also showed that a relatively narrow beam of width 4 or 5 was sufficient for the mid-gated model. As for unknown words, we showed that the mid-gated model could somehow translate the one containing Katakana by coining out a close word. We also showed that the model managed to produce tolerable results for heavily noised sentences, even though the model was trained with the dataset without noise.},
	urldate = {2020-12-16},
	booktitle = {Proceedings of the 6th {Workshop} on {Asian} {Translation}},
	publisher = {Association for Computational Linguistics},
	author = {Dai, Jinan and Yamaguchi, Kazunori},
	month = nov,
	year = {2019},
	pages = {36--44},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\JY7VMKUR\\Dai 和 Yamaguchi - 2019 - Compact and Robust Models for Japanese-English Cha.pdf:application/pdf},
}

@inproceedings{nikolov_character-level_2018,
	address = {Brussels, Belgium},
	title = {Character-level {Chinese}-{English} {Translation} through {ASCII} {Encoding}},
	url = {https://www.aclweb.org/anthology/W18-6302},
	doi = {10.18653/v1/W18-6302},
	abstract = {Character-level Neural Machine Translation (NMT) models have recently achieved impressive results on many language pairs. They mainly do well for Indo-European language pairs, where the languages share the same writing system. However, for translating between Chinese and English, the gap between the two different writing systems poses a major challenge because of a lack of systematic correspondence between the individual linguistic units. In this paper, we enable character-level NMT for Chinese, by breaking down Chinese characters into linguistic units similar to that of Indo-European languages. We use the Wubi encoding scheme, which preserves the original shape and semantic information of the characters, while also being reversible. We show promising results from training Wubi-based models on the character- and subword-level with recurrent as well as convolutional models.},
	urldate = {2020-12-16},
	booktitle = {Proceedings of the {Third} {Conference} on {Machine} {Translation}: {Research} {Papers}},
	publisher = {Association for Computational Linguistics},
	author = {Nikolov, Nikola I. and Hu, Yuhuang and Tan, Mi Xue and Hahnloser, Richard H.R.},
	month = oct,
	year = {2018},
	pages = {10--16},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\R8V2PF8T\\Nikolov 等。 - 2018 - Character-level Chinese-English Translation throug.pdf:application/pdf},
}

@inproceedings{tiedemann_analyzing_2013,
	address = {Hissar, Bulgaria},
	title = {Analyzing the {Use} of {Character}-{Level} {Translation} with {Sparse} and {Noisy} {Datasets}},
	url = {https://www.aclweb.org/anthology/R13-1088},
	urldate = {2020-12-16},
	booktitle = {Proceedings of the {International} {Conference} {Recent} {Advances} in {Natural} {Language} {Processing} {RANLP} 2013},
	publisher = {INCOMA Ltd. Shoumen, BULGARIA},
	author = {Tiedemann, Jörg and Nakov, Preslav},
	month = sep,
	year = {2013},
	pages = {676--684},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\6XUPRYE7\\Tiedemann 和 Nakov - 2013 - Analyzing the Use of Character-Level Translation w.pdf:application/pdf},
}

@inproceedings{tiedemann_character-based_2012,
	address = {Avignon, France},
	title = {Character-{Based} {Pivot} {Translation} for {Under}-{Resourced} {Languages} and {Domains}},
	url = {https://www.aclweb.org/anthology/E12-1015},
	urldate = {2020-12-16},
	booktitle = {Proceedings of the 13th {Conference} of the {European} {Chapter} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Tiedemann, Jörg},
	month = apr,
	year = {2012},
	pages = {141--151},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\59YV9UNQ\\Tiedemann - 2012 - Character-Based Pivot Translation for Under-Resour.pdf:application/pdf},
}

@inproceedings{xi_enhancing_2012,
	address = {Jeju Island, Korea},
	title = {Enhancing {Statistical} {Machine} {Translation} with {Character} {Alignment}},
	url = {https://www.aclweb.org/anthology/P12-2056},
	urldate = {2020-12-16},
	booktitle = {Proceedings of the 50th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 2: {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Xi, Ning and Tang, Guangchao and Dai, Xinyu and Huang, Shujian and Chen, Jiajun},
	month = jul,
	year = {2012},
	pages = {285--290},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\C5HRGHNN\\Xi 等。 - 2012 - Enhancing Statistical Machine Translation with Cha.pdf:application/pdf},
}

@inproceedings{renduchintala_character-aware_2019,
	address = {Dublin, Ireland},
	title = {Character-{Aware} {Decoder} for {Translation} into {Morphologically} {Rich} {Languages}},
	url = {https://www.aclweb.org/anthology/W19-6624},
	urldate = {2020-12-16},
	booktitle = {Proceedings of {Machine} {Translation} {Summit} {XVII} {Volume} 1: {Research} {Track}},
	publisher = {European Association for Machine Translation},
	author = {Renduchintala, Adithya and Shapiro, Pamela and Duh, Kevin and Koehn, Philipp},
	month = aug,
	year = {2019},
	pages = {244--255},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\MBQ25CDC\\Renduchintala 等。 - 2019 - Character-Aware Decoder for Translation into Morph.pdf:application/pdf},
}

@inproceedings{kim_zero-shot_2020,
	address = {Online},
	title = {Zero-shot {North} {Korean} to {English} {Neural} {Machine} {Translation} by {Character} {Tokenization} and {Phoneme} {Decomposition}},
	url = {https://www.aclweb.org/anthology/2020.acl-srw.11},
	doi = {10.18653/v1/2020.acl-srw.11},
	abstract = {The primary limitation of North Korean to English translation is the lack of a parallel corpus; therefore, high translation accuracy cannot be achieved. To address this problem, we propose a zero-shot approach using South Korean data, which are remarkably similar to North Korean data. We train a neural machine translation model after tokenizing a South Korean text at the character level and decomposing characters into phonemes.We demonstrate that our method can effectively learn North Korean to English translation and improve the BLEU scores by +1.01 points in comparison with the baseline.},
	urldate = {2020-12-16},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}: {Student} {Research} {Workshop}},
	publisher = {Association for Computational Linguistics},
	author = {Kim, Hwichan and Hirasawa, Tosho and Komachi, Mamoru},
	month = jul,
	year = {2020},
	pages = {72--78},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\L3DPACNK\\Kim 等。 - 2020 - Zero-shot North Korean to English Neural Machine T.pdf:application/pdf},
}

@inproceedings{saunders_inference-only_2020,
	address = {Suzhou, China},
	title = {Inference-only sub-character decomposition improves translation of unseen logographic characters},
	url = {https://www.aclweb.org/anthology/2020.wat-1.21},
	abstract = {Neural Machine Translation (NMT) on logographic source languages struggles when translating `unseen' characters, which never appear in the training data. One possible approach to this problem uses sub-character decomposition for training and test sentences. However, this approach involves complete retraining, and its effectiveness for unseen character translation to non-logographic languages has not been fully explored. We investigate existing ideograph-based sub-character decomposition approaches for Chinese-to-English and Japanese-to-English NMT, for both high-resource and low-resource domains. For each language pair and domain we construct a test set where all source sentences contain at least one unseen logographic character. We find that complete sub-character decomposition often harms unseen character translation, and gives inconsistent results generally. We offer a simple alternative based on decomposition before inference for unseen characters only. Our approach allows flexible application, achieving translation adequacy improvements and requiring no additional models or training.},
	urldate = {2020-12-16},
	booktitle = {Proceedings of the 7th {Workshop} on {Asian} {Translation}},
	publisher = {Association for Computational Linguistics},
	author = {Saunders, Danielle and Feely, Weston and Byrne, Bill},
	month = dec,
	year = {2020},
	pages = {170--177},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\GD6PSEQT\\Saunders 等。 - 2020 - Inference-only sub-character decomposition improve.pdf:application/pdf},
}

@inproceedings{ebrahimi_adversarial_2018,
	address = {Santa Fe, New Mexico, USA},
	title = {On {Adversarial} {Examples} for {Character}-{Level} {Neural} {Machine} {Translation}},
	url = {https://www.aclweb.org/anthology/C18-1055},
	abstract = {Evaluating on adversarial examples has become a standard procedure to measure robustness of deep learning models. Due to the difficulty of creating white-box adversarial examples for discrete text input, most analyses of the robustness of NLP models have been done through black-box adversarial examples. We investigate adversarial examples for character-level neural machine translation (NMT), and contrast black-box adversaries with a novel white-box adversary, which employs differentiable string-edit operations to rank adversarial changes. We propose two novel types of attacks which aim to remove or change a word in a translation, rather than simply break the NMT. We demonstrate that white-box adversarial examples are significantly stronger than their black-box counterparts in different attack scenarios, which show more serious vulnerabilities than previously known. In addition, after performing adversarial training, which takes only 3 times longer than regular training, we can improve the model's robustness significantly.},
	urldate = {2020-12-16},
	booktitle = {Proceedings of the 27th {International} {Conference} on {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Ebrahimi, Javid and Lowd, Daniel and Dou, Dejing},
	month = aug,
	year = {2018},
	pages = {653--663},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\6I9X74Z4\\Ebrahimi 等。 - 2018 - On Adversarial Examples for Character-Level Neural.pdf:application/pdf},
}

@inproceedings{pennell_character-level_2011,
	address = {Chiang Mai, Thailand},
	title = {A {Character}-{Level} {Machine} {Translation} {Approach} for {Normalization} of {SMS} {Abbreviations}},
	url = {https://www.aclweb.org/anthology/I11-1109},
	urldate = {2020-12-16},
	booktitle = {Proceedings of 5th {International} {Joint} {Conference} on {Natural} {Language} {Processing}},
	publisher = {Asian Federation of Natural Language Processing},
	author = {Pennell, Deana and Liu, Yang},
	month = nov,
	year = {2011},
	pages = {974--982},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\SXRYV3HV\\Pennell 和 Liu - 2011 - A Character-Level Machine Translation Approach for.pdf:application/pdf},
}

@article{he_dynamic_2020,
	title = {Dynamic {Programming} {Encoding} for {Subword} {Segmentation} in {Neural} {Machine} {Translation}},
	url = {http://arxiv.org/abs/2005.06606},
	abstract = {This paper introduces Dynamic Programming Encoding (DPE), a new segmentation algorithm for tokenizing sentences into subword units. We view the subword segmentation of output sentences as a latent variable that should be marginalized out for learning and inference. A mixed character-subword transformer is proposed, which enables exact log marginal likelihood estimation and exact MAP inference to find target segmentations with maximum posterior probability. DPE uses a lightweight mixed character-subword transformer as a means of pre-processing parallel data to segment output sentences using dynamic programming. Empirical results on machine translation suggest that DPE is effective for segmenting output sentences and can be combined with BPE dropout for stochastic segmentation of source sentences. DPE achieves an average improvement of 0.9 BLEU over BPE (Sennrich et al., 2016) and an average improvement of 0.55 BLEU over BPE dropout (Provilkov et al., 2019) on several WMT datasets including English {\textless}={\textgreater} (German, Romanian, Estonian, Finnish, Hungarian).},
	urldate = {2020-12-25},
	journal = {arXiv:2005.06606 [cs]},
	author = {He, Xuanli and Haffari, Gholamreza and Norouzi, Mohammad},
	month = aug,
	year = {2020},
	note = {arXiv: 2005.06606},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:D\:\\Documents\\zotero\\storage\\YKPL8JP7\\He 等。 - 2020 - Dynamic Programming Encoding for Subword Segmentat.pdf:application/pdf;arXiv.org Snapshot:D\:\\Documents\\zotero\\storage\\BBDA7IYD\\2005.html:text/html},
}

@inproceedings{chen_combining_2018-1,
	address = {New Orleans, Louisiana},
	title = {Combining {Character} and {Word} {Information} in {Neural} {Machine} {Translation} {Using} a {Multi}-{Level} {Attention}},
	url = {https://www.aclweb.org/anthology/N18-1116},
	doi = {10.18653/v1/N18-1116},
	abstract = {Natural language sentences, being hierarchical, can be represented at different levels of granularity, like words, subwords, or characters. But most neural machine translation systems require the sentence to be represented as a sequence at a single level of granularity. It can be difficult to determine which granularity is better for a particular translation task. In this paper, we improve the model by incorporating multiple levels of granularity. Specifically, we propose (1) an encoder with character attention which augments the (sub)word-level representation with character-level information; (2) a decoder with multiple attentions that enable the representations from different levels of granularity to control the translation cooperatively. Experiments on three translation tasks demonstrate that our proposed models outperform the standard word-based model, the subword-based model, and a strong character-based model.},
	urldate = {2020-12-25},
	booktitle = {Proceedings of the 2018 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Chen, Huadong and Huang, Shujian and Chiang, David and Dai, Xinyu and Chen, Jiajun},
	month = jun,
	year = {2018},
	pages = {1284--1293},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\DRVV53BQ\\Chen 等。 - 2018 - Combining Character and Word Information in Neural.pdf:application/pdf},
}

@inproceedings{ma_charbert_2020,
	address = {Barcelona, Spain (Online)},
	title = {{CharBERT}: {Character}-aware {Pre}-trained {Language} {Model}},
	shorttitle = {{CharBERT}},
	url = {https://www.aclweb.org/anthology/2020.coling-main.4},
	abstract = {Most pre-trained language models (PLMs) construct word representations at subword level with Byte-Pair Encoding (BPE) or its variations, by which OOV (out-of-vocab) words are almost avoidable. However, those methods split a word into subword units and make the representation incomplete and fragile.In this paper, we propose a character-aware pre-trained language model named CharBERT improving on the previous methods (such as BERT, RoBERTa) to tackle these problems. We first construct the contextual word embedding for each token from the sequential character representations, then fuse the representations of characters and the subword representations by a novel heterogeneous interaction module. We also propose a new pre-training task named NLM (Noisy LM) for unsupervised character representation learning. We evaluate our method on question answering, sequence labeling, and text classification tasks, both on the original datasets and adversarial misspelling test sets. The experimental results show that our method can significantly improve the performance and robustness of PLMs simultaneously.},
	urldate = {2020-12-26},
	booktitle = {Proceedings of the 28th {International} {Conference} on {Computational} {Linguistics}},
	publisher = {International Committee on Computational Linguistics},
	author = {Ma, Wentao and Cui, Yiming and Si, Chenglei and Liu, Ting and Wang, Shijin and Hu, Guoping},
	month = dec,
	year = {2020},
	pages = {39--50},
	file = {Full Text PDF:D\:\\Documents\\zotero\\storage\\4V8JCCPS\\Ma 等。 - 2020 - CharBERT Character-aware Pre-trained Language Mod.pdf:application/pdf},
}

@inproceedings{li-etal-2020-bits,
    title = "{BIT}{'}s system for the {A}uto{S}im{T}rans 2020",
    author = "Li, Minqin  and
      Cheng, Haodong  and
      Wang, Yuanjie  and
      Zhang, Sijia  and
      Wu, Liting  and
      Guo, Yuhang",
    booktitle = "Proceedings of the First Workshop on Automatic Simultaneous Translation",
    month = jul,
    year = "2020",
    address = "Seattle, Washington",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.autosimtrans-1.6",
    doi = "10.18653/v1/2020.autosimtrans-1.6",
    pages = "37--44",
    abstract = "This paper describes our machine translation systems for the streaming Chinese-to-English translation task of AutoSimTrans 2020. We present a sentence length based method and a sentence boundary detection model based method for the streaming input segmentation. Experimental results of the transcription and the ASR output translation on the development data sets show that the translation system with the detection model based method outperforms the one with the length based method in BLEU score by 1.19 and 0.99 respectively under similar or better latency.",
}


@article{10.1162/neco.1991.3.1.79,
    author = {Jacobs, Robert A. and Jordan, Michael I. and Nowlan, Steven J. and Hinton, Geoffrey E.},
    title = "{Adaptive Mixtures of Local Experts}",
    journal = {Neural Computation},
    volume = {3},
    number = {1},
    pages = {79-87},
    year = {1991},
    month = {03},
    abstract = "{We present a new supervised learning procedure for systems composed of many separate networks, each of which learns to handle a subset of the complete set of training cases. The new procedure can be viewed either as a modular version of a multilayer supervised network, or as an associative version of competitive learning. It therefore provides a new link between these two apparently different approaches. We demonstrate that the learning procedure divides up a vowel discrimination task into appropriate subtasks, each of which can be solved by a very simple expert network.}",
    issn = {0899-7667},
    doi = {10.1162/neco.1991.3.1.79},
    url = {https://doi.org/10.1162/neco.1991.3.1.79},
    eprint = {https://direct.mit.edu/neco/article-pdf/3/1/79/812104/neco.1991.3.1.79.pdf},
}

@inproceedings{peng-etal-2020-mixture,
    title = "A Mixture of h - 1 Heads is Better than h Heads",
    author = "Peng, Hao  and
      Schwartz, Roy  and
      Li, Dianqi  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.587",
    doi = "10.18653/v1/2020.acl-main.587",
    pages = "6566--6577",
    abstract = "Multi-head attentive neural architectures have achieved state-of-the-art results on a variety of natural language processing tasks. Evidence has shown that they are overparameterized; attention heads can be pruned without significant performance loss. In this work, we instead {``}reallocate{''} them{---}the model learns to activate different heads on different inputs. Drawing connections between multi-head attention and mixture of experts, we propose the mixture of attentive experts model (MAE). MAE is trained using a block coordinate descent algorithm that alternates between updating (1) the responsibilities of the experts and (2) their parameters. Experiments on machine translation and language modeling show that MAE outperforms strong baselines on both tasks. Particularly, on the WMT14 English to German translation dataset, MAE improves over {``}transformer-base{''} by 0.8 BLEU, with a comparable number of parameters. Our analysis shows that our model learns to specialize different experts to different inputs.",
}

@inproceedings{guo-etal-2018-multi,
    title = "Multi-Source Domain Adaptation with Mixture of Experts",
    author = "Guo, Jiang  and
      Shah, Darsh  and
      Barzilay, Regina",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1498",
    doi = "10.18653/v1/D18-1498",
    pages = "4694--4703",
    abstract = "We propose a mixture-of-experts approach for unsupervised domain adaptation from multiple sources. The key idea is to explicitly capture the relationship between a target example and different source domains. This relationship, expressed by a point-to-set metric, determines how to combine predictors trained on various domains. The metric is learned in an unsupervised fashion using meta-training. Experimental results on sentiment analysis and part-of-speech tagging demonstrate that our approach consistently outperforms multiple baselines and can robustly handle negative transfer.",
}

@InProceedings{pmlr-v97-shen19c, 
title = {Mixture Models for Diverse Machine Translation: Tricks of the Trade}, author = {Shen, Tianxiao and Ott, Myle and Auli, Michael and Ranzato, Marc'Aurelio}, booktitle = {Proceedings of the 36th International Conference on Machine Learning}, pages = {5719--5728}, year = {2019}, editor = {Kamalika Chaudhuri and Ruslan Salakhutdinov}, volume = {97}, series = {Proceedings of Machine Learning Research}, month = {09--15 Jun}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v97/shen19c/shen19c.pdf}, url = { http://proceedings.mlr.press/v97/shen19c.html }, abstract = {Mixture models trained via EM are among the simplest, most widely used and well understood latent variable models in the machine learning literature. Surprisingly, these models have been hardly explored in text generation applications such as machine translation. In principle, they provide a latent variable to control generation and produce a diverse set of hypotheses. In practice, however, mixture models are prone to degeneracies—often only one component gets trained or the latent variable is simply ignored. We find that disabling dropout noise in responsibility computation is critical to successful training. In addition, the design choices of parameterization, prior distribution, hard versus soft EM and online versus offline assignment can dramatically affect model performance. We develop an evaluation protocol to assess both quality and diversity of generations against multiple references, and provide an extensive empirical study of several mixture model variants. Our analysis shows that certain types of mixture models are more robust and offer the best trade-off between translation quality and diversity compared to variational models and diverse decoding approaches.\footnote{Code to reproduce the results in this paper is available at \url{https://github.com/pytorch/fairseq}}} }


@misc{shazeer2017outrageously,
      title={Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer}, 
      author={Noam Shazeer and Azalia Mirhoseini and Krzysztof Maziarz and Andy Davis and Quoc Le and Geoffrey Hinton and Jeff Dean},
      year={2017},
      eprint={1701.06538},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}




@article{Chen2019,
abstract = {Despite the success of neural machine translation (NMT), simultaneous neural machine translation (SNMT), the task of translating in real time before a full sentence has been observed, remains challenging due to the syntactic structure difference and simultaneity requirements. In this paper, we propose a general framework to improve simultaneous translation with a pretrained consecutive neural machine translation (CNMT) model. Our framework contains two parts: prefix translation that utilizes a pretrained CNMT model to better translate source prefixes and a stopping criterion that determines when to stop the prefix translation. Experiments on three translation corpora and two language pairs show the efficacy of the proposed framework on balancing the quality and latency in simultaneous translation.},
archivePrefix = {arXiv},
arxivId = {1911.03154},
author = {Chen, Yun and Li, Liangyou and Jiang, Xin and Chen, Xiao and Liu, Qun},
eprint = {1911.03154},
file = {:Users/zhangshaolei/Documents/计算所/论文/Machine Translation/Simultaneous Translation/How to Do Simultaneous Translation Better with Consecutive Neural Machine Translation?.pdf:pdf},
title = {{How to Do Simultaneous Translation Better with Consecutive Neural Machine Translation?}},
url = {http://arxiv.org/abs/1911.03154},
year = {2019}
}

@inproceedings{zheng-etal-2019-speculative,
    title = "Speculative Beam Search for Simultaneous Translation",
    author = "Zheng, Renjie  and
      Ma, Mingbo  and
      Zheng, Baigong  and
      Huang, Liang",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1144",
    doi = "10.18653/v1/D19-1144",
    pages = "1395--1402",
    abstract = "Beam search is universally used in (full-sentence) machine translation but its application to simultaneous translation remains highly non-trivial, where output words are committed on the fly. In particular, the recently proposed wait-k policy (Ma et al., 2018) is a simple and effective method that (after an initial wait) commits one output word on receiving each input word, making beam search seemingly inapplicable. To address this challenge, we propose a new speculative beam search algorithm that hallucinates several steps into the future in order to reach a more accurate decision by implicitly benefiting from a target language model. This idea makes beam search applicable for the first time to the generation of a single word in each step. Experiments over diverse language pairs show large improvement compared to previous work.",
}


@inproceedings{oda-etal-2015-syntax,
    title = "Syntax-based Simultaneous Translation through Prediction of Unseen Syntactic Constituents",
    author = "Oda, Yusuke  and
      Neubig, Graham  and
      Sakti, Sakriani  and
      Toda, Tomoki  and
      Nakamura, Satoshi",
    booktitle = "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = jul,
    year = "2015",
    address = "Beijing, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P15-1020",
    doi = "10.3115/v1/P15-1020",
    pages = "198--207",
}
@inproceedings{He2015,
    title = "Syntax-based Rewriting for Simultaneous Machine Translation",
    author = "He, He  and
      Grissom II, Alvin  and
      Morgan, John  and
      Boyd-Graber, Jordan  and
      Daum{\'e} III, Hal",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D15-1006",
    doi = "10.18653/v1/D15-1006",
    pages = "55--64",
}

@inproceedings{grissom-ii-etal-2016-incremental,
    title = "Incremental Prediction of Sentence-final Verbs: Humans versus Machines",
    author = "Grissom II, Alvin  and
      Orita, Naho  and
      Boyd-Graber, Jordan",
    booktitle = "Proceedings of The 20th {SIGNLL} Conference on Computational Natural Language Learning",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/K16-1010",
    doi = "10.18653/v1/K16-1010",
    pages = "95--104",
}

@article{Novitasari2019,
author = {Novitasari, Sashi and Tjandra, Andros and Sakti, Sakriani and Nakamura, Satoshi},
file = {:Users/zhangshaolei/Documents/计算所/论文/Alignments/Sequence-to-Sequence Learning via Attention Transfer for Incremental Speech Recognition.pdf:pdf},
keywords = {[Electronic Manuscript]},
mendeley-groups = {Alignments,EMNLP2020},
pages = {3835--3839},
title = {{Sequence-to-Sequence Learning via Attention Transfer for Incremental Speech Recognition}},
year = {2019}
}
@inproceedings{Shigeki2000,
    title = "Simultaneous Japenese-English Interpretation Based on Early Predictoin of English Verb",
    author = " Matsubara, Shigeki
    Iwashima, Keiichi  and 
    Kawaguchi, Nobuo and 
    Toyama, Katsuhiko and 
    Inagaki, Yasuyoshi  ",
    booktitle = "Proceedings of the 4th Symposium on Natural Languauge Processing(SNLP-2000)",
    year = "2000",
    pages = "268--273",
}


@misc{kn,
Author = {Geoffrey Hinton and Oriol Vinyals and Jeff Dean},
Title = {Distilling the Knowledge in a Neural Network},
Year = {2015},
Eprint = {arXiv:1503.02531},
}

@inproceedings{tjandra-etal-2017-local,
    title = "Local Monotonic Attention Mechanism for End-to-End Speech And Language Processing",
    author = "Tjandra, Andros  and
      Sakti, Sakriani  and
      Nakamura, Satoshi",
    booktitle = "Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = nov,
    year = "2017",
    address = "Taipei, Taiwan",
    publisher = "Asian Federation of Natural Language Processing",
    url = "https://www.aclweb.org/anthology/I17-1044",
    pages = "431--440",
    abstract = "Recently, encoder-decoder neural networks have shown impressive performance on many sequence-related tasks. The architecture commonly uses an attentional mechanism which allows the model to learn alignments between the source and the target sequence. Most attentional mechanisms used today is based on a global attention property which requires a computation of a weighted summarization of the whole input sequence generated by encoder states. However, it is computationally expensive and often produces misalignment on the longer input sequence. Furthermore, it does not fit with monotonous or left-to-right nature in several tasks, such as automatic speech recognition (ASR), grapheme-to-phoneme (G2P), etc. In this paper, we propose a novel attention mechanism that has local and monotonic properties. Various ways to control those properties are also explored. Experimental results on ASR, G2P and machine translation between two languages with similar sentence structures, demonstrate that the proposed encoder-decoder model with local monotonic attention could achieve significant performance improvements and reduce the computational complexity in comparison with the one that used the standard global attention architecture.",
}

@inproceedings{Gaussian_Hou,
author = {Hou, Junfeng and Zhang, Shiliang and Dai, Li-Rong},
year = {2017},
month = {08},
pages = {3692-3696},
title = {Gaussian Predction Based Attention for Online End-to-End Speech Recognition},
doi = {10.21437/Interspeech.2017-751}
}

@inproceedings{Analysis_Merboldt,
author = {Merboldt, André and Zeyer, Albert and Schlüter, Ralf and Ney, Hermann},
year = {2019},
month = {09},
pages = {1398-1402},
title = {An Analysis of Local Monotonic Attention Variants},
doi = {10.21437/Interspeech.2019-2879}
}

@inproceedings{LinearTime,
  title = 	 {Online and Linear-Time Attention by Enforcing Monotonic Alignments},
  author =       {Colin Raffel and Minh-Thang Luong and Peter J. Liu and Ron J. Weiss and Douglas Eck},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {2837--2846},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/raffel17a/raffel17a.pdf},
  url = 	 {https://proceedings.mlr.press/v70/raffel17a.html},
  abstract = 	 {Recurrent neural network models with an attention mechanism have proven to be extremely effective on a wide variety of sequence-to-sequence problems. However, the fact that soft attention mechanisms perform a pass over the entire input sequence when producing each element in the output sequence precludes their use in online settings and results in a quadratic time complexity. Based on the insight that the alignment between input and output sequence elements is monotonic in many problems of interest, we propose an end-to-end differentiable method for learning monotonic alignments which, at test time, enables computing attention online and in linear time. We validate our approach on sentence summarization, machine translation, and online speech recognition problems and achieve results competitive with existing sequence-to-sequence models.}
}

@inproceedings{iwslt2015,
  title={The IWSLT 2015 Evaluation Campaign},
  author={Mauro Cettolo and Niehues Jan and St{\"u}ker Sebastian and Luisa Bentivogli and R. Cattoni and Marcello Federico},
  year={2015}
}

@article{2sigma,
 ISSN = {00031305},
 URL = {http://www.jstor.org/stable/2684253},
 abstract = {For random variables with a unimodal Lebesgue density, the 3σ rule is proved by elementary calculus. It emerges as a special case of the Vysochanskiĭ-Petunin inequality, which in turn is based on the Gauss inequality.},
 author = {Friedrich Pukelsheim},
 journal = {The American Statistician},
 number = {2},
 pages = {88--91},
 publisher = {[American Statistical Association, Taylor \& Francis, Ltd.]},
 title = {The Three Sigma Rule},
 volume = {48},
 year = {1994}
}
@inproceedings{li-etal-2018-multi,
    title = "Multi-Head Attention with Disagreement Regularization",
    author = "Li, Jian  and
      Tu, Zhaopeng  and
      Yang, Baosong  and
      Lyu, Michael R.  and
      Zhang, Tong",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1317",
    doi = "10.18653/v1/D18-1317",
    pages = "2897--2903",
    abstract = "Multi-head attention is appealing for the ability to jointly attend to information from different representation subspaces at different positions. In this work, we introduce a disagreement regularization to explicitly encourage the diversity among multiple attention heads. Specifically, we propose three types of disagreement regularization, which respectively encourage the subspace, the attended positions, and the output representation associated with each attention head to be different from other heads. Experimental results on widely-used WMT14 English-German and WMT17 Chinese-English translation tasks demonstrate the effectiveness and universality of the proposed approach.",
}
@inproceedings{liu-etal-2016-neural,
    title = "Neural Machine Translation with Supervised Attention",
    author = "Liu, Lemao  and
      Utiyama, Masao  and
      Finch, Andrew  and
      Sumita, Eiichiro",
    booktitle = "Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",
    month = dec,
    year = "2016",
    address = "Osaka, Japan",
    publisher = "The COLING 2016 Organizing Committee",
    url = "https://www.aclweb.org/anthology/C16-1291",
    pages = "3093--3102",
    abstract = "The attention mechanism is appealing for neural machine translation, since it is able to dynamically encode a source sentence by generating a alignment between a target word and source words. Unfortunately, it has been proved to be worse than conventional alignment models in alignment accuracy. In this paper, we analyze and explain this issue from the point view of reordering, and propose a supervised attention which is learned with guidance from conventional alignment models. Experiments on two Chinese-to-English translation tasks show that the supervised attention mechanism yields better alignments leading to substantial gains over the standard attention based NMT.",
}
@inproceedings{ghader-monz-2017-attention,
    title = "What does Attention in Neural Machine Translation Pay Attention to?",
    author = "Ghader, Hamidreza  and
      Monz, Christof",
    booktitle = "Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = nov,
    year = "2017",
    address = "Taipei, Taiwan",
    publisher = "Asian Federation of Natural Language Processing",
    url = "https://www.aclweb.org/anthology/I17-1004",
    pages = "30--39",
    abstract = "Attention in neural machine translation provides the possibility to encode relevant parts of the source sentence at each translation step. As a result, attention is considered to be an alignment model as well. However, there is no work that specifically studies attention and provides analysis of what is being learned by attention models. Thus, the question still remains that how attention is similar or different from the traditional alignment. In this paper, we provide detailed analysis of attention and compare it to traditional alignment. We answer the question of whether attention is only capable of modelling translational equivalent or it captures more information. We show that attention is different from alignment in some cases and is capturing useful information other than alignments.",
}


@inproceedings{luong-etal-2015-effective,
    title = "Effective Approaches to Attention-based Neural Machine Translation",
    author = "Luong, Thang  and
      Pham, Hieu  and
      Manning, Christopher D.",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D15-1166",
    doi = "10.18653/v1/D15-1166",
    pages = "1412--1421",
}




@misc{2007.05290,
Author = {Xueqing Wu and Yingce Xia and Lijun Wu and Shufang Xie and Weiqing Liu and Jiang Bian and Tao Qin and Tie-Yan Liu},
Title = {Learn to Use Future Information in Simultaneous Translation},
Year = {2020},
Eprint = {arXiv:2007.05290},
}




@article{Song2018HybridSN,
  title={Hybrid Self-Attention Network for Machine Translation},
  author={K. Song and Tan Xu and Furong Peng and Jianfeng Lu},
  journal={ArXiv},
  year={2018},
  volume={abs/1811.00253}
}
@article{journals/corr/Graves13,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Graves, Alex},
  biburl = {https://www.bibsonomy.org/bibtex/2d3697b979a78e10841dcc7eaa1998466/dblp},
  ee = {http://arxiv.org/abs/1308.0850},
  interhash = {ec0258df377a752ce87a6f7c59dea06d},
  intrahash = {d3697b979a78e10841dcc7eaa1998466},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T15:13:07.000+0200},
  title = {Generating Sequences With Recurrent Neural Networks.},
  url = {http://dblp.uni-trier.de/db/journals/corr/corr1308.html#Graves13},
  volume = {abs/1308.0850},
  year = 2013
}

@INPROCEEDINGS{9054106,
  author={E. {Battenberg} and R. J. {Skerry-Ryan} and S. {Mariooryad} and D. {Stanton} and D. {Kao} and M. {Shannon} and T. {Bagby}},
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Location-Relative Attention Mechanisms for Robust Long-Form Speech Synthesis}, 
  year={2020},
  volume={},
  number={},
  pages={6194-6198},
  doi={10.1109/ICASSP40776.2020.9054106}
}
  


@inproceedings{lee-etal-2018-deterministic,
    title = "Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement",
    author = "Lee, Jason  and
      Mansimov, Elman  and
      Cho, Kyunghyun",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1149",
    doi = "10.18653/v1/D18-1149",
    pages = "1173--1182",
    abstract = "We propose a conditional non-autoregressive neural sequence model based on iterative refinement. The proposed model is designed based on the principles of latent variable models and denoising autoencoders, and is generally applicable to any sequence generation task. We extensively evaluate the proposed model on machine translation (En-De and En-Ro) and image caption generation, and observe that it significantly speeds up decoding while maintaining the generation quality comparable to the autoregressive counterpart.",
}

@article{Hassan2018AchievingHP,
  title={Achieving Human Parity on Automatic Chinese to English News Translation},
  author={Hany Hassan and Anthony Aue and C. Chen and Vishal Chowdhary and J. Clark and C. Federmann and Xuedong Huang and Marcin Junczys-Dowmunt and W. Lewis and M. Li and Shujie Liu and T. Liu and Renqian Luo and Arul Menezes and Tao Qin and F. Seide and Xu Tan and Fei Tian and Lijun Wu and Shuangzhi Wu and Yingce Xia and Dongdong Zhang and Zhirui Zhang and M. Zhou},
  journal={ArXiv},
  year={2018},
  volume={abs/1803.05567}
}

@inproceedings{hard-code,
author = {You, Weiqiu and Sun, Simeng and Iyyer, Mohit},
year = {2020},
month = {01},
pages = {7689-7700},
title = {Hard-Coded Gaussian Attention for Neural Machine Translation},
doi = {10.18653/v1/2020.acl-main.687}
}



@misc{bahdanau2014neural,
  abstract = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},
  added-at = {2020-06-07T20:24:58.000+0200},
  author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  biburl = {https://www.bibsonomy.org/bibtex/2713375898fd7d2477f6ab6dc3dd66c2c/jan.hofmann1},
  description = {[1409.0473] Neural Machine Translation by Jointly Learning to Align and Translate},
  interhash = {bb2ca011eeafccb0bd2505c9476dcd10},
  intrahash = {713375898fd7d2477f6ab6dc3dd66c2c},
  keywords = {thema:pyramid_scene_parsing},
  note = {cite arxiv:1409.0473Comment: Accepted at ICLR 2015 as oral presentation},
  timestamp = {2020-06-07T20:24:58.000+0200},
  title = {Neural Machine Translation by Jointly Learning to Align and Translate},
  url = {http://arxiv.org/abs/1409.0473},
  year = 2014
}

@inproceedings{tu-etal-2016-modeling,
    title = "Modeling Coverage for Neural Machine Translation",
    author = "Tu, Zhaopeng  and
      Lu, Zhengdong  and
      Liu, Yang  and
      Liu, Xiaohua  and
      Li, Hang",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P16-1008",
    doi = "10.18653/v1/P16-1008",
    pages = "76--85",
}

@ARTICLE{8550728,
  author={J. {Zhang} and Y. {Zhao} and H. {Li} and C. {Zong}},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Attention With Sparsity Regularization for Neural Machine Translation and Summarization}, 
  year={2019},
  volume={27},
  number={3},
  pages={507-518},
  doi={10.1109/TASLP.2018.2883740}
}

@inproceedings{yang-etal-2018-modeling,
    title = "Modeling Localness for Self-Attention Networks",
    author = "Yang, Baosong  and
      Tu, Zhaopeng  and
      Wong, Derek F.  and
      Meng, Fandong  and
      Chao, Lidia S.  and
      Zhang, Tong",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1475",
    doi = "10.18653/v1/D18-1475",
    pages = "4449--4458",
    abstract = "Self-attention networks have proven to be of profound value for its strength of capturing global dependencies. In this work, we propose to model localness for self-attention networks, which enhances the ability of capturing useful local context. We cast localness modeling as a learnable Gaussian bias, which indicates the central and scope of the local region to be paid more attention. The bias is then incorporated into the original attention distribution to form a revised distribution. To maintain the strength of capturing long distance dependencies while enhance the ability of capturing short-range dependencies, we only apply localness modeling to lower layers of self-attention networks. Quantitative and qualitative analyses on Chinese-English and English-German translation tasks demonstrate the effectiveness and universality of the proposed approach.",
}


@article{doi:10.1080/13506285.2018.1485808,
author = {John Brand and Aaron P. Johnson},
title = {The effects of distributed and focused attention on rapid scene categorization},
journal = {Visual Cognition},
volume = {26},
number = {6},
pages = {450-462},
year  = {2018},
publisher = {Routledge},
doi = {10.1080/13506285.2018.1485808},

URL = { 
        https://doi.org/10.1080/13506285.2018.1485808
    
},
eprint = { 
        https://doi.org/10.1080/13506285.2018.1485808
    
}
,
    abstract = { ABSTRACTIt has been argued that distributed attention facilitates the rapid extraction of summary statistics that underpins rapid scene categorization. We directly examined this hypothesis by investigating whether distributed or focused attention is more compatible with the extraction of both summary statistics (Experiment 1) and semantic scene information (Experiments 2–4). Experiment 1 replicated Chong and Treisman’s (2005a) result that mean circle size judgments are more compatible with a distributed attention task than a focused attention task. Experiment 2 investigated whether this finding extends to simple scene categorization by replacing the averaging task with an animal detection task. Consistent with Experiment 1, the ability to detect the presence of an animal was more compatible with a distributed attention task than a focused attention task. Experiments 3 and 4 addressed whether distributed attention influences scene categorization tasks. When observers were asked to classify scenes based on their basic level (e.g., beach or forest; Experiment 3), there was no statistically significant difference between focused and distributed attention task conditions; however, superordinate level categorization (e.g., natural or manmade; Experiment 4) was faster when combined with a task requiring distributed attention compared to a task requiring focused attention. }
}



@article{ITO19981191,
title = "Attention and Perceptual Learning Modulate Contextual Influences on Visual Perception",
journal = "Neuron",
volume = "20",
number = "6",
pages = "1191 - 1197",
year = "1998",
issn = "0896-6273",
doi = "https://doi.org/10.1016/S0896-6273(00)80499-7",
url = "http://www.sciencedirect.com/science/article/pii/S0896627300804997",
author = "Minami Ito and Gerald Westheimer and Charles D Gilbert",
abstract = "Brightness discrimination thresholds and facilitation by lateral interaction were measured in five human observers and two monkeys. The subjects judged the brightness of one of four peripherally seen lines against a reference. This experiment was performed both when the observer was cued to the position of the test line (focused attention) and when there was no cue (distributed attention). Discrimination was better with focused than with distributed attention. When the test line had a collinear flank, its brightness was enhanced; this enhancement was four times more prominent with distributed than with focused attention. After training, thresholds improved and collinear facilitation decreased under distributed but not under focused attention. The findings show that there are fewer benefits from contextual interaction once attention is directed toward a visual location, and that the attentional effects are subject to training."
}

@article{Beck1973,
title = "The effects of concentrated and distributed attention on peripheral acuity",
journal = "Perception \& Psychophysics",
volume = "14",
number = "2",
year = "1973",
issn = "1532-5962",
doi = "https://doi.org/10.3758/BF03212381",
url = "https://link.springer.com/article/10.3758/BF03212381#citeas",
author = "Beck Jacob and Ambler Bruce",
abstract = "Two experiments studied the peripheral discriminability of a target differing in its line slope (a tilted T) and in its line arrangement (an L) when presented in briefly flashed displays of upright Ts. The results showed that: (a) an L and a tilted T were equal in discriminability when attention was focused or concentrated on one display position, (b) the discriminability of an L decreased while the discriminability of a tilted T was not statistically significantly affected as the number of display positions that attention needed to be paid to increased, and (c) the reaction time to find a disparate tilted T was less than that to find a disparate L. The results are interpreted as supporting the hypothesis that, under distributed attention in peripheral vision, the visual system is more sensitive to differences in line slope than to differences in line arrangement The results are discussed in connection with hypotheses of how selective attention affects the discriminability of a target."
}

@inproceedings{tang-etal-2019-understanding,
    title = "Understanding Neural Machine Translation by Simplification: The Case of Encoder-free Models",
    author = "Tang, Gongbo  and
      Sennrich, Rico  and
      Nivre, Joakim",
    booktitle = "Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)",
    month = sep,
    year = "2019",
    address = "Varna, Bulgaria",
    publisher = "INCOMA Ltd.",
    url = "https://www.aclweb.org/anthology/R19-1136",
    doi = "10.26615/978-954-452-056-4_136",
    pages = "1186--1193",
    abstract = "In this paper, we try to understand neural machine translation (NMT) via simplifying NMT architectures and training encoder-free NMT models. In an encoder-free model, the sums of word embeddings and positional embeddings represent the source. The decoder is a standard Transformer or recurrent neural network that directly attends to embeddings via attention mechanisms. Experimental results show (1) that the attention mechanism in encoder-free models acts as a strong feature extractor, (2) that the word embeddings in encoder-free models are competitive to those in conventional models, (3) that non-contextualized source representations lead to a big performance drop, and (4) that encoder-free models have different effects on alignment quality for German-English and Chinese-English.",
}



@inproceedings{luong-etal-2015-effective,
    title = "Effective Approaches to Attention-based Neural Machine Translation",
    author = "Luong, Thang  and
      Pham, Hieu  and
      Manning, Christopher D.",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D15-1166",
    doi = "10.18653/v1/D15-1166",
    pages = "1412--1421",
}

@inproceedings{kuang-etal-2018-attention,
    title = "Attention Focusing for Neural Machine Translation by Bridging Source and Target Embeddings",
    author = "Kuang, Shaohui  and
      Li, Junhui  and
      Branco, Ant{\'o}nio  and
      Luo, Weihua  and
      Xiong, Deyi",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P18-1164",
    doi = "10.18653/v1/P18-1164",
    pages = "1767--1776",
    abstract = "In neural machine translation, a source sequence of words is encoded into a vector from which a target sequence is generated in the decoding phase. Differently from statistical machine translation, the associations between source words and their possible target counterparts are not explicitly stored. Source and target words are at the two ends of a long information processing procedure, mediated by hidden states at both the source encoding and the target decoding phases. This makes it possible that a source word is incorrectly translated into a target word that is not any of its admissible equivalent counterparts in the target language. In this paper, we seek to somewhat shorten the distance between source and target words in that procedure, and thus strengthen their association, by means of a method we term bridging source and target word embeddings. We experiment with three strategies: (1) a source-side bridging model, where source word embeddings are moved one step closer to the output target sequence; (2) a target-side bridging model, which explores the more relevant source word embeddings for the prediction of the target sequence; and (3) a direct bridging model, which directly connects source and target word embeddings seeking to minimize errors in the translation of ones by the others. Experiments and analysis presented in this paper demonstrate that the proposed bridging models are able to significantly improve quality of both sentence translation, in general, and alignment and translation of individual source words with target words, in particular.",
}


@inproceedings{li-etal-2019-word,
    title = "On the Word Alignment from Neural Machine Translation",
    author = "Li, Xintong  and
      Li, Guanlin  and
      Liu, Lemao  and
      Meng, Max  and
      Shi, Shuming",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1124",
    doi = "10.18653/v1/P19-1124",
    pages = "1293--1303",
    abstract = "Prior researches suggest that neural machine translation (NMT) captures word alignment through its attention mechanism, however, this paper finds attention may almost fail to capture word alignment for some NMT models. This paper thereby proposes two methods to induce word alignment which are general and agnostic to specific NMT models. Experiments show that both methods induce much better word alignment than attention. This paper further visualizes the translation through the word alignment induced by NMT. In particular, it analyzes the effect of alignment errors on translation errors at word level and its quantitative analysis over many testing examples consistently demonstrate that alignment errors are likely to lead to translation errors measured by different metrics.",
}

@article{och-ney-2003-systematic,
    title = "A Systematic Comparison of Various Statistical Alignment Models",
    author = "Och, Franz Josef  and
      Ney, Hermann",
    journal = "Computational Linguistics",
    volume = "29",
    number = "1",
    year = "2003",
    url = "https://www.aclweb.org/anthology/J03-1002",
    doi = "10.1162/089120103321337421",
    pages = "19--51",
}



@inproceedings{voita-etal-2019-analyzing,
    title = "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned",
    author = "Voita, Elena  and
      Talbot, David  and
      Moiseev, Fedor  and
      Sennrich, Rico  and
      Titov, Ivan",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1580",
    doi = "10.18653/v1/P19-1580",
    pages = "5797--5808",
    abstract = "Multi-head self-attention is a key component of the Transformer, a state-of-the-art architecture for neural machine translation. In this work we evaluate the contribution made by individual attention heads to the overall performance of the model and analyze the roles played by them in the encoder. We find that the most important and confident heads play consistent and often linguistically-interpretable roles. When pruning heads using a method based on stochastic gates and a differentiable relaxation of the L0 penalty, we observe that specialized heads are last to be pruned. Our novel pruning method removes the vast majority of heads without seriously affecting performance. For example, on the English-Russian WMT dataset, pruning 38 out of 48 encoder heads results in a drop of only 0.15 BLEU.",
}

@inproceedings{shaw-etal-2018-self,
    title = "Self-Attention with Relative Position Representations",
    author = "Shaw, Peter  and
      Uszkoreit, Jakob  and
      Vaswani, Ashish",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-2074",
    doi = "10.18653/v1/N18-2074",
    pages = "464--468",
    abstract = "Relying entirely on an attention mechanism, the Transformer introduced by Vaswani et al. (2017) achieves state-of-the-art results for machine translation. In contrast to recurrent and convolutional neural networks, it does not explicitly model relative or absolute position information in its structure. Instead, it requires adding representations of absolute positions to its inputs. In this work we present an alternative approach, extending the self-attention mechanism to efficiently consider representations of the relative positions, or distances between sequence elements. On the WMT 2014 English-to-German and English-to-French translation tasks, this approach yields improvements of 1.3 BLEU and 0.3 BLEU over absolute position representations, respectively. Notably, we observe that combining relative and absolute position representations yields no further improvement in translation quality. We describe an efficient implementation of our method and cast it as an instance of relation-aware self-attention mechanisms that can generalize to arbitrary graph-labeled inputs.",
}

@article{Distance-based-2017,
author = {Im, Jinbae and Cho, Sungzoon},
year = {2017},
month = {12},
pages = {},
title = {Distance-based Self-Attention Network for Natural Language Inference}
}

@inproceedings{Self-Attentional-2018,
author = {Sperber, Matthias and Niehues, Jan and Neubig, Graham and Stüker, Sebastian and Waibel, Alex},
year = {2018},
month = {09},
pages = {3723-3727},
title = {Self-Attentional Acoustic Models},
doi = {10.21437/Interspeech.2018-1910}
}



@misc{2012.11747,
Author = {Ruining He and Anirudh Ravula and Bhargav Kanagal and Joshua Ainslie},
Title = {RealFormer: Transformer Likes Residual Attention},
Year = {2020},
Eprint = {arXiv:2012.11747},
}

@inproceedings{DBLP:conf/nips/Rasmussen99,
  added-at = {2011-02-11T18:56:55.000+0100},
  author = {Rasmussen, Carl Edward},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  biburl = {https://www.bibsonomy.org/bibtex/2f31aa43229942c878cefdd8036599164/ytyoun},
  booktitle = {NIPS},
  crossref = {DBLP:conf/nips/1999},
  editor = {Solla, Sara A. and Leen, Todd K. and M{\"u}ller, Klaus-Robert},
  ee = {http://nips.djvuzone.org/djvu/nips12/0554.djvu},
  interhash = {abb97331137ab040389dcc8ff4cff5dc},
  intrahash = {f31aa43229942c878cefdd8036599164},
  isbn = {0-262-19450-3},
  keywords = {gaussian-mixture-model},
  pages = {554-560},
  publisher = {The MIT Press},
  timestamp = {2016-06-14T14:35:37.000+0200},
  title = {The Infinite Gaussian Mixture Model},
  year = 1999
}


@article{3sigma,
 ISSN = {00031305},
 URL = {http://www.jstor.org/stable/2684253},
 abstract = {For random variables with a unimodal Lebesgue density, the 3σ rule is proved by elementary calculus. It emerges as a special case of the Vysochanskiĭ-Petunin inequality, which in turn is based on the Gauss inequality.},
 author = {Friedrich Pukelsheim},
 journal = {The American Statistician},
 number = {2},
 pages = {88--91},
 publisher = {[American Statistical Association, Taylor \& Francis, Ltd.]},
 title = {The Three Sigma Rule},
 volume = {48},
 year = {1994}
}

@inproceedings{ding-etal-2020-self,
    title = "Self-Attention with Cross-Lingual Position Representation",
    author = "Ding, Liang  and
      Wang, Longyue  and
      Tao, Dacheng",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.153",
    doi = "10.18653/v1/2020.acl-main.153",
    pages = "1679--1685",
    abstract = "Position encoding (PE), an essential part of self-attention networks (SANs), is used to preserve the word order information for natural language processing tasks, generating fixed position indices for input sequences. However, in cross-lingual scenarios, machine translation, the PEs of source and target sentences are modeled independently. Due to word order divergences in different languages, modeling the cross-lingual positional relationships might help SANs tackle this problem. In this paper, we augment SANs with \textit{cross-lingual position representations} to model the bilingually aware latent structure for the input sentence. Specifically, we utilize bracketing transduction grammar (BTG)-based reordering information to encourage SANs to learn bilingual diagonal alignments. Experimental results on WMT{'}14 English$\Rightarrow$German, WAT{'}17 Japanese$\Rightarrow$English, and WMT{'}17 Chinese$\Leftrightarrow$English translation tasks demonstrate that our approach significantly and consistently improves translation quality over strong baselines. Extensive analyses confirm that the performance gains come from the cross-lingual information.",
}

@inproceedings{wang-etal-2019-self-attention,
    title = "Self-Attention with Structural Position Representations",
    author = "Wang, Xing  and
      Tu, Zhaopeng  and
      Wang, Longyue  and
      Shi, Shuming",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1145",
    doi = "10.18653/v1/D19-1145",
    pages = "1403--1409",
    abstract = "Although self-attention networks (SANs) have advanced the state-of-the-art on various NLP tasks, one criticism of SANs is their ability of encoding positions of input words (Shaw et al., 2018). In this work, we propose to augment SANs with structural position representations to model the latent structure of the input sentence, which is complementary to the standard sequential positional representations. Specifically, we use dependency tree to represent the grammatical structure of a sentence, and propose two strategies to encode the positional relationships among words in the dependency tree. Experimental results on NIST Chinese-to-English and WMT14 English-to-German translation tasks show that the proposed approach consistently boosts performance over both the absolute and relative sequential position representations.",
}

@inproceedings{xu-etal-2019-leveraging,
    title = "Leveraging Local and Global Patterns for Self-Attention Networks",
    author = "Xu, Mingzhou  and
      Wong, Derek F.  and
      Yang, Baosong  and
      Zhang, Yue  and
      Chao, Lidia S.",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1295",
    doi = "10.18653/v1/P19-1295",
    pages = "3069--3075",
    abstract = "Self-attention networks have received increasing research attention. By default, the hidden states of each word are hierarchically calculated by attending to all words in the sentence, which assembles global information. However, several studies pointed out that taking all signals into account may lead to overlooking neighboring information (e.g. phrase pattern). To address this argument, we propose a hybrid attention mechanism to dynamically leverage both of the local and global information. Specifically, our approach uses a gating scalar for integrating both sources of the information, which is also convenient for quantifying their contributions. Experiments on various neural machine translation tasks demonstrate the effectiveness of the proposed method. The extensive analyses verify that the two types of contexts are complementary to each other, and our method gives highly effective improvements in their integration.",
}

@inproceedings{raganato-etal-2020-fixed,
    title = "Fixed Encoder Self-Attention Patterns in Transformer-Based Machine Translation",
    author = {Raganato, Alessandro  and
      Scherrer, Yves  and
      Tiedemann, J{\"o}rg},
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.findings-emnlp.49",
    doi = "10.18653/v1/2020.findings-emnlp.49",
    pages = "556--568",
    abstract = "Transformer-based models have brought a radical change to neural machine translation. A key feature of the Transformer architecture is the so-called multi-head attention mechanism, which allows the model to focus simultaneously on different parts of the input. However, recent works have shown that most attention heads learn simple, and often redundant, positional patterns. In this paper, we propose to replace all but one attention head of each encoder layer with simple fixed {--} non-learnable {--} attentive patterns that are solely based on position and do not require any external knowledge. Our experiments with different data sizes and multiple language pairs show that fixing the attention heads on the encoder side of the Transformer at training time does not impact the translation quality and even increases BLEU scores by up to 3 points in low-resource scenarios.",
}


@misc{1811.00253,
Author = {Kaitao Song and Xu Tan and Furong Peng and Jianfeng Lu},
Title = {Hybrid Self-Attention Network for Machine Translation},
Year = {2018},
Eprint = {arXiv:1811.00253},
}

@misc{2003.06381,
Author = {Yu Yuan and Serge Sharoff},
Title = {Sentence Level Human Translation Quality Estimation with Attention-based Neural Networks},
Year = {2020},
Eprint = {arXiv:2003.06381},
}

@inproceedings{ding-etal-2020-context,
    title = "Context-Aware Cross-Attention for Non-Autoregressive Translation",
    author = "Ding, Liang  and
      Wang, Longyue  and
      Wu, Di  and
      Tao, Dacheng  and
      Tu, Zhaopeng",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.coling-main.389",
    doi = "10.18653/v1/2020.coling-main.389",
    pages = "4396--4402",
    abstract = "Non-autoregressive translation (NAT) significantly accelerates the inference process by predicting the entire target sequence. However, due to the lack of target dependency modelling in the decoder, the conditional generation process heavily depends on the cross-attention. In this paper, we reveal a localness perception problem in NAT cross-attention, for which it is difficult to adequately capture source context. To alleviate this problem, we propose to enhance signals of neighbour source tokens into conventional cross-attention. Experimental results on several representative datasets show that our approach can consistently improve translation quality over strong NAT baselines. Extensive analyses demonstrate that the enhanced cross-attention achieves better exploitation of source contexts by leveraging both local and global information.",
}
@inproceedings{jain-wallace-2019-attention,
    title = "{A}ttention is not {E}xplanation",
    author = "Jain, Sarthak  and
      Wallace, Byron C.",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-1357",
    doi = "10.18653/v1/N19-1357",
    pages = "3543--3556",
    abstract = "Attention mechanisms have seen wide adoption in neural NLP models. In addition to improving predictive performance, these are often touted as affording transparency: models equipped with attention provide a distribution over attended-to input units, and this is often presented (at least implicitly) as communicating the relative importance of inputs. However, it is unclear what relationship exists between attention weights and model outputs. In this work we perform extensive experiments across a variety of NLP tasks that aim to assess the degree to which attention weights provide meaningful {``}explanations{''} for predictions. We find that they largely do not. For example, learned attention weights are frequently uncorrelated with gradient-based measures of feature importance, and one can identify very different attention distributions that nonetheless yield equivalent predictions. Our findings show that standard attention modules do not provide meaningful explanations and should not be treated as though they do.",
}


@inproceedings{10.1145/1015330.1015432,
author = {Caruana, Rich and Niculescu-Mizil, Alexandru and Crew, Geoff and Ksikes, Alex},
title = {Ensemble Selection from Libraries of Models},
year = {2004},
isbn = {1581138385},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1015330.1015432},
doi = {10.1145/1015330.1015432},
abstract = {We present a method for constructing ensembles from libraries of thousands of models. Model libraries are generated using different learning algorithms and parameter settings. Forward stepwise selection is used to add to the ensemble the models that maximize its performance. Ensemble selection allows ensembles to be optimized to performance metric such as accuracy, cross entropy, mean precision, or ROC Area. Experiments with seven test problems and ten metrics demonstrate the benefit of ensemble selection.},
booktitle = {Proceedings of the Twenty-First International Conference on Machine Learning},
pages = {18},
location = {Banff, Alberta, Canada},
series = {ICML '04}
}

@inproceedings{Liu_2018_ECCV,
author = {Liu, Xuanqing and Cheng, Minhao and Zhang, Huan and Hsieh, Cho-Jui},
title = {Towards Robust Neural Networks via Random Self-ensemble},
booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
month = {September},
year = {2018},
url = {https://openaccess.thecvf.com/content_ECCV_2018/html/Xuanqing_Liu_Towards_Robust_Neural_ECCV_2018_paper.html},
}

@article{Dutt2018CoupledEO,
title = {Coupled ensembles of neural networks},
journal = {Neurocomputing},
volume = {396},
pages = {346-357},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2018.10.092},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219304370},
author = {Anuvabh Dutt and Denis Pellerin and Georges Quénot},
keywords = {Neural net architectures, Ensemble learning, Deep learning},
}

@inproceedings{he-etal-2018-sequence,
    title = "Sequence to Sequence Mixture Model for Diverse Machine Translation",
    author = "He, Xuanli  and
      Haffari, Gholamreza  and
      Norouzi, Mohammad",
    booktitle = "Proceedings of the 22nd Conference on Computational Natural Language Learning",
    month = oct,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/K18-1056",
    doi = "10.18653/v1/K18-1056",
    pages = "583--592",
    abstract = "Sequence to sequence (SEQ2SEQ) models lack diversity in their generated translations. This can be attributed to their limitations in capturing lexical and syntactic variations in parallel corpora, due to different styles, genres, topics, or ambiguity of human translation process. In this paper, we develop a novel sequence to sequence mixture (S2SMIX) model that improves both translation diversity and quality by adopting a committee of specialized translation models rather than a single translation model. Each mixture component selects its own training dataset via optimization of the marginal log-likelihood, which leads to a soft clustering of the parallel corpus. Experiments on four language pairs demonstrate the superiority of our mixture model compared to SEQ2SEQ model with the standard and diversity encouraged beam search. Our mixture model incurs negligible additional parameters and no extra computation in the decoding time.",
}

@inproceedings{cho-etal-2019-mixture,
    title = "Mixture Content Selection for Diverse Sequence Generation",
    author = "Cho, Jaemin  and
      Seo, Minjoon  and
      Hajishirzi, Hannaneh",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1308",
    doi = "10.18653/v1/D19-1308",
    pages = "3121--3131",
    abstract = "Generating diverse sequences is important in many NLP applications such as question generation or summarization that exhibit semantically one-to-many relationships between source and the target sequences. We present a method to explicitly separate diversification from generation using a general plug-and-play module (called SELECTOR) that wraps around and guides an existing encoder-decoder model. The diversification stage uses a mixture of experts to sample different binary masks on the source sequence for diverse content selection. The generation stage uses a standard encoder-decoder model given each selected content from the source sequence. Due to the non-differentiable nature of discrete sampling and the lack of ground truth labels for binary mask, we leverage a proxy for ground truth mask and adopt stochastic hard-EM for training. In question generation (SQuAD) and abstractive summarization (CNN-DM), our method demonstrates significant improvements in accuracy, diversity and training efficiency, including state-of-the-art top-1 accuracy in both datasets, 6{\%} gain in top-5 accuracy, and 3.7 times faster training over a state-of-the-art model. Our code is publicly available at https://github.com/clovaai/FocusSeq2Seq.",
}

@inproceedings{10.1145/3219819.3220007,
author = {Ma, Jiaqi and Zhao, Zhe and Yi, Xinyang and Chen, Jilin and Hong, Lichan and Chi, Ed H.},
title = {Modeling Task Relationships in Multi-Task Learning with Multi-Gate Mixture-of-Experts},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3220007},
doi = {10.1145/3219819.3220007},
abstract = {Neural-based multi-task learning has been successfully used in many real-world large-scale applications such as recommendation systems. For example, in movie recommendations, beyond providing users movies which they tend to purchase and watch, the system might also optimize for users liking the movies afterwards. With multi-task learning, we aim to build a single model that learns these multiple goals and tasks simultaneously. However, the prediction quality of commonly used multi-task models is often sensitive to the relationships between tasks. It is therefore important to study the modeling tradeoffs between task-specific objectives and inter-task relationships. In this work, we propose a novel multi-task learning approach, Multi-gate Mixture-of-Experts (MMoE), which explicitly learns to model task relationships from data. We adapt the Mixture-of-Experts (MoE) structure to multi-task learning by sharing the expert submodels across all tasks, while also having a gating network trained to optimize each task. To validate our approach on data with different levels of task relatedness, we first apply it to a synthetic dataset where we control the task relatedness. We show that the proposed approach performs better than baseline methods when the tasks are less related. We also show that the MMoE structure results in an additional trainability benefit, depending on different levels of randomness in the training data and model initialization. Furthermore, we demonstrate the performance improvements by MMoE on real tasks including a binary classification benchmark, and a large-scale content recommendation system at Google.},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
pages = {1930–1939},
numpages = {10},
keywords = {mixture of experts, multi-task learning, neural network, recommendation system},
location = {London, United Kingdom},
series = {KDD '18}
}


@inproceedings{bahar-etal-2020-start,
    title = "Start-Before-End and End-to-End: Neural Speech Translation by {A}pp{T}ek and {RWTH} {A}achen {U}niversity",
    author = "Bahar, Parnia  and
      Wilken, Patrick  and
      Alkhouli, Tamer  and
      Guta, Andreas  and
      Golik, Pavel  and
      Matusov, Evgeny  and
      Herold, Christian",
    booktitle = "Proceedings of the 17th International Conference on Spoken Language Translation",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.iwslt-1.3",
    doi = "10.18653/v1/2020.iwslt-1.3",
    pages = "44--54",
    abstract = "AppTek and RWTH Aachen University team together to participate in the offline and simultaneous speech translation tracks of IWSLT 2020. For the offline task, we create both cascaded and end-to-end speech translation systems, paying attention to careful data selection and weighting. In the cascaded approach, we combine high-quality hybrid automatic speech recognition (ASR) with the Transformer-based neural machine translation (NMT). Our end-to-end direct speech translation systems benefit from pretraining of adapted encoder and decoder components, as well as synthetic data and fine-tuning and thus are able to compete with cascaded systems in terms of MT quality. For simultaneous translation, we utilize a novel architecture that makes dynamic decisions, learned from parallel data, to determine when to continue feeding on input or generate output words. Experiments with speech and text input show that even at low latency this architecture leads to superior translation results.",
}

@inproceedings{wilken-etal-2020-neural,
    title = "Neural Simultaneous Speech Translation Using Alignment-Based Chunking",
    author = "Wilken, Patrick  and
      Alkhouli, Tamer  and
      Matusov, Evgeny  and
      Golik, Pavel",
    booktitle = "Proceedings of the 17th International Conference on Spoken Language Translation",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.iwslt-1.29",
    doi = "10.18653/v1/2020.iwslt-1.29",
    pages = "237--246",
    abstract = "In simultaneous machine translation, the objective is to determine when to produce a partial translation given a continuous stream of source words, with a trade-off between latency and quality. We propose a neural machine translation (NMT) model that makes dynamic decisions when to continue feeding on input or generate output words. The model is composed of two main components: one to dynamically decide on ending a source chunk, and another that translates the consumed chunk. We train the components jointly and in a manner consistent with the inference conditions. To generate chunked training data, we propose a method that utilizes word alignment while also preserving enough context. We compare models with bidirectional and unidirectional encoders of different depths, both on real speech and text input. Our results on the IWSLT 2020 English-to-German task outperform a wait-k baseline by 2.6 to 3.7{\%} BLEU absolute.",
}

@inproceedings{han-etal-2020-end,
    title = "End-to-End Simultaneous Translation System for {IWSLT}2020 Using Modality Agnostic Meta-Learning",
    author = "Han, Hou Jeung  and
      Zaidi, Mohd Abbas  and
      Indurthi, Sathish Reddy  and
      Lakumarapu, Nikhil Kumar  and
      Lee, Beomseok  and
      Kim, Sangha",
    booktitle = "Proceedings of the 17th International Conference on Spoken Language Translation",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.iwslt-1.5",
    doi = "10.18653/v1/2020.iwslt-1.5",
    pages = "62--68",
    abstract = "In this paper, we describe end-to-end simultaneous speech-to-text and text-to-text translation systems submitted to IWSLT2020 online translation challenge. The systems are built by adding wait-k and meta-learning approaches to the Transformer architecture. The systems are evaluated on different latency regimes. The simultaneous text-to-text translation achieved a BLEU score of 26.38 compared to the competition baseline score of 14.17 on the low latency regime (Average latency {\mbox{$\leq$}} 3). The simultaneous speech-to-text system improves the BLEU score by 7.7 points over the competition baseline for the low latency regime (Average Latency {\mbox{$\leq$}} 1000).",
}

@inproceedings{zhang-zhang-2020-dynamic,
    title = "Dynamic Sentence Boundary Detection for Simultaneous Translation",
    author = "Zhang, Ruiqing  and
      Zhang, Chuanqiang",
    booktitle = "Proceedings of the First Workshop on Automatic Simultaneous Translation",
    month = jul,
    year = "2020",
    address = "Seattle, Washington",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.autosimtrans-1.1",
    doi = "10.18653/v1/2020.autosimtrans-1.1",
    pages = "1--9",
    abstract = "Simultaneous Translation is a great challenge in which translation starts before the source sentence finished. Most studies take transcription as input and focus on balancing translation quality and latency for each sentence. However, most ASR systems can not provide accurate sentence boundaries in realtime. Thus it is a key problem to segment sentences for the word streaming before translation. In this paper, we propose a novel method for sentence boundary detection that takes it as a multi-class classification task under the end-to-end pre-training framework. Experiments show significant improvements both in terms of translation quality and latency.",
}

@inproceedings{dyer-etal-2013-simple,
    title = "A Simple, Fast, and Effective Reparameterization of {IBM} Model 2",
    author = "Dyer, Chris  and
      Chahuneau, Victor  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2013",
    address = "Atlanta, Georgia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N13-1073",
    pages = "644--648",
}

@ARTICLE{2020arXiv201011247C,
       author = {{Chen}, Junkun and {Zheng}, Renjie and {Kita}, Atsuhito and {Ma}, Mingbo and {Huang}, Liang},
        title = "{Improving Simultaneous Translation with Pseudo References}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computation and Language},
         year = 2020,
        month = oct,
          eid = {arXiv:2010.11247},
        pages = {arXiv:2010.11247},
archivePrefix = {arXiv},
       eprint = {2010.11247},
 primaryClass = {cs.CL},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2020arXiv201011247C},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@inproceedings{elbayad-etal-2020-trac,
    title = "{ON}-{TRAC} Consortium for End-to-End and Simultaneous Speech Translation Challenge Tasks at {IWSLT} 2020",
    author = "Elbayad, Maha  and
      Nguyen, Ha  and
      Bougares, Fethi  and
      Tomashenko, Natalia  and
      Caubri{\`e}re, Antoine  and
      Lecouteux, Benjamin  and
      Est{\`e}ve, Yannick  and
      Besacier, Laurent",
    booktitle = "Proceedings of the 17th International Conference on Spoken Language Translation",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.iwslt-1.2",
    doi = "10.18653/v1/2020.iwslt-1.2",
    pages = "35--43",
    abstract = "This paper describes the ON-TRAC Consortium translation systems developed for two challenge tracks featured in the Evaluation Campaign of IWSLT 2020, offline speech translation and simultaneous speech translation. ON-TRAC Consortium is composed of researchers from three French academic laboratories: LIA (Avignon Universit{\'e}), LIG (Universit{\'e} Grenoble Alpes), and LIUM (Le Mans Universit{\'e}). Attention-based encoder-decoder models, trained end-to-end, were used for our submissions to the offline speech translation track. Our contributions focused on data augmentation and ensembling of multiple models. In the simultaneous speech translation track, we build on Transformer-based wait-k models for the text-to-text subtask. For speech-to-text simultaneous translation, we attach a wait-k MT system to a hybrid ASR system. We propose an algorithm to control the latency of the ASR+MT cascade and achieve a good latency-quality trade-off on both subtasks.",
}

@inproceedings{zheng-etal-2020-fluent,
    title = "Fluent and Low-latency Simultaneous Speech-to-Speech Translation with Self-adaptive Training",
    author = "Zheng, Renjie  and
      Ma, Mingbo  and
      Zheng, Baigong  and
      Liu, Kaibo  and
      Yuan, Jiahong  and
      Church, Kenneth  and
      Huang, Liang",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.findings-emnlp.349",
    doi = "10.18653/v1/2020.findings-emnlp.349",
    pages = "3928--3937",
    abstract = "Simultaneous speech-to-speech translation is an extremely challenging but widely useful scenario that aims to generate target-language speech only a few seconds behind the source-language speech. In addition, we have to continuously translate a speech of multiple sentences, but all recent solutions merely focus on the single-sentence scenario. As a result, current approaches will accumulate more and more latencies in later sentences when the speaker talks faster and introduce unnatural pauses into translated speech when the speaker talks slower. To overcome these issues, we propose Self-Adaptive Translation which flexibly adjusts the length of translations to accommodate different source speech rates. At similar levels of translation quality (as measured by BLEU), our method generates more fluent target speech latency than the baseline, in both Zh{\textless}-{\textgreater}En directions.",
}

@inproceedings{gaido-etal-2020-end,
    title = "End-to-End Speech-Translation with Knowledge Distillation: {FBK}@{IWSLT}2020",
    author = "Gaido, Marco  and
      Di Gangi, Mattia A.  and
      Negri, Matteo  and
      Turchi, Marco",
    booktitle = "Proceedings of the 17th International Conference on Spoken Language Translation",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.iwslt-1.8",
    doi = "10.18653/v1/2020.iwslt-1.8",
    pages = "80--88",
    abstract = "This paper describes FBK{'}s participation in the IWSLT 2020 offline speech translation (ST) task. The task evaluates systems{'} ability to translate English TED talks audio into German texts. The test talks are provided in two versions: one contains the data already segmented with automatic tools and the other is the raw data without any segmentation. Participants can decide whether to work on custom segmentation or not. We used the provided segmentation. Our system is an end-to-end model based on an adaptation of the Transformer for speech data. Its training process is the main focus of this paper and it is based on: i) transfer learning (ASR pretraining and knowledge distillation), ii) data augmentation (SpecAugment, time stretch and synthetic data), iii)combining synthetic and real data marked as different domains, and iv) multi-task learning using the CTC loss. Finally, after the training with word-level knowledge distillation is complete, our ST models are fine-tuned using label smoothed cross entropy. Our best model scored 29 BLEU on the MuST-CEn-De test set, which is an excellent result compared to recent papers, and 23.7 BLEU on the same data segmented with VAD, showing the need for researching solutions addressing this specific data condition.",
}


@inproceedings{zhang-feng-2021-icts,
    title = "{ICT}{'}s System for {A}uto{S}im{T}rans 2021: Robust Char-Level Simultaneous Translation",
    author = "Zhang, Shaolei  and
      Feng, Yang",
    booktitle = "Proceedings of the Second Workshop on Automatic Simultaneous Translation",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.autosimtrans-1.1",
    doi = "10.18653/v1/2021.autosimtrans-1.1",
    pages = "1--11",
    abstract = "Simultaneous translation (ST) outputs the translation simultaneously while reading the input sentence, which is an important component of simultaneous interpretation. In this paper, we describe our submitted ST system, which won the first place in the streaming transcription input track of the Chinese-English translation task of AutoSimTrans 2021. Aiming at the robustness of ST, we first propose char-level simultaneous translation and applied wait-k policy on it. Meanwhile, we apply two data processing methods and combine two training methods for domain adaptation. Our method enhance the ST model with stronger robustness and domain adaptability. Experiments on streaming transcription show that our method outperforms the baseline at all latency, especially at low latency, the proposed method improves about 6 BLEU. Besides, ablation studies we conduct verify the effectiveness of each module in the proposed method.",
}
@article{DeepExperts,
author = {Eigen, David and Ranzato, Marc'Aurelio and Sutskever, Ilya},
year = {2013},
month = {12},
pages = {},
title = {Learning Factored Representations in a Deep Mixture of Experts},
url="https://arxiv.org/abs/1312.4314",
}

@inproceedings{arthur-etal-2021-learning,
    title = "Learning Coupled Policies for Simultaneous Machine Translation using Imitation Learning",
    author = "Arthur, Philip  and
      Cohn, Trevor  and
      Haffari, Gholamreza",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eacl-main.233",
    pages = "2709--2719",
    abstract = "We present a novel approach to efficiently learn a simultaneous translation model with coupled programmer-interpreter policies. First, we present an algorithmic oracle to produce oracle READ/WRITE actions for training bilingual sentence-pairs using the notion of word alignments. This oracle actions are designed to capture enough information from the partial input before writing the output. Next, we perform a coupled scheduled sampling to effectively mitigate the exposure bias when learning both policies jointly with imitation learning. Experiments on six language-pairs show our method outperforms strong baselines in terms of translation quality quality while keeping the delay low.",
}

@inproceedings{garg-etal-2019-jointly,
    title = "Jointly Learning to Align and Translate with Transformer Models",
    author = "Garg, Sarthak  and
      Peitz, Stephan  and
      Nallasamy, Udhyakumar  and
      Paulik, Matthias",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1453",
    doi = "10.18653/v1/D19-1453",
    pages = "4453--4462",
    abstract = "The state of the art in machine translation (MT) is governed by neural approaches, which typically provide superior translation accuracy over statistical approaches. However, on the closely related task of word alignment, traditional statistical word alignment models often remain the go-to solution. In this paper, we present an approach to train a Transformer model to produce both accurate translations and alignments. We extract discrete alignments from the attention probabilities learnt during regular neural machine translation model training and leverage them in a multi-task framework to optimize towards translation and alignment objectives. We demonstrate that our approach produces competitive results compared to GIZA++ trained IBM alignment models without sacrificing translation accuracy and outperforms previous attempts on Transformer model based word alignment. Finally, by incorporating IBM model alignments into our multi-task training, we report significantly better alignment accuracies compared to GIZA++ on three publicly available data sets.",
}

@inproceedings{elbayad-etal-2020-online,
    title = "Online Versus Offline {NMT} Quality: An In-depth Analysis on {E}nglish-{G}erman and {G}erman-{E}nglish",
    author = "Elbayad, Maha  and
      Ustaszewski, Michael  and
      Esperan{\c{c}}a-Rodier, Emmanuelle  and
      Brunet-Manquat, Francis  and
      Verbeek, Jakob  and
      Besacier, Laurent",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2020.coling-main.443",
    doi = "10.18653/v1/2020.coling-main.443",
    pages = "5047--5058",
    abstract = "We conduct in this work an evaluation study comparing offline and online neural machine translation architectures. Two sequence-to-sequence models: convolutional Pervasive Attention (Elbayad et al. 2018) and attention-based Transformer (Vaswani et al. 2017) are considered. We investigate, for both architectures, the impact of online decoding constraints on the translation quality through a carefully designed human evaluation on English-German and German-English language pairs, the latter being particularly sensitive to latency constraints. The evaluation results allow us to identify the strengths and shortcomings of each model when we shift to the online setup.",
}

@inproceedings{vilar-etal-2006-aer,
    title = "{AER}: do we need to {``}improve{''} our alignments?",
    author = "Vilar, David  and
      Popovic, Maja  and
      Ney, Hermann",
    booktitle = "Proceedings of the Third International Workshop on Spoken Language Translation: Papers",
    month = nov # " 27-28",
    year = "2006",
    address = "Kyoto, Japan",
    url = "https://aclanthology.org/2006.iwslt-papers.7",
}

@inproceedings{liu-etal-2021-cross,
    title = "Cross Attention Augmented Transducer Networks for Simultaneous Translation",
    author = "Liu, Dan  and
      Du, Mengge  and
      Li, Xiaoxi  and
      Li, Ya  and
      Chen, Enhong",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.4",
    pages = "39--55",
    abstract = "This paper proposes a novel architecture, Cross Attention Augmented Transducer (CAAT), for simultaneous translation. The framework aims to jointly optimize the policy and translation models. To effectively consider all possible READ-WRITE simultaneous translation action paths, we adapt the online automatic speech recognition (ASR) model, RNN-T, but remove the strong monotonic constraint, which is critical for the translation task to consider reordering. To make CAAT work, we introduce a novel latency loss whose expectation can be optimized by a forward-backward algorithm. We implement CAAT with Transformer while the general CAAT architecture can also be implemented with other attention-based encoder-decoder frameworks. Experiments on both speech-to-text (S2T) and text-to-text (T2T) simultaneous translation tasks show that CAAT achieves significantly better latency-quality trade-offs compared to the state-of-the-art simultaneous translation approaches.",
}

@inproceedings{alinejad-etal-2021-translation,
    title = "Translation-based Supervision for Policy Generation in Simultaneous Neural Machine Translation",
    author = "Alinejad, Ashkan  and
      Shavarani, Hassan S.  and
      Sarkar, Anoop",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.130",
    pages = "1734--1744",
    abstract = "In simultaneous machine translation, finding an agent with the optimal action sequence of reads and writes that maintain a high level of translation quality while minimizing the average lag in producing target tokens remains an extremely challenging problem. We propose a novel supervised learning approach for training an agent that can detect the minimum number of reads required for generating each target token by comparing simultaneous translations against full-sentence translations during training to generate oracle action sequences. These oracle sequences can then be used to train a supervised model for action generation at inference time. Our approach provides an alternative to current heuristic methods in simultaneous translation by introducing a new training objective, which is easier to train than previous attempts at training the agent using reinforcement learning techniques for this task. Our experimental results show that our novel training method for action generation produces much higher quality translations while minimizing the average lag in simultaneous translation.",
}

@inproceedings{chen-etal-2021-improving-simultaneous,
    title = "Improving Simultaneous Translation by Incorporating Pseudo-References with Fewer Reorderings",
    author = "Chen, Junkun  and
      Zheng, Renjie  and
      Kita, Atsuhito  and
      Ma, Mingbo  and
      Huang, Liang",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.473",
    pages = "5857--5864",
    abstract = "Simultaneous translation is vastly different from full-sentence translation, in the sense that it starts translation before the source sentence ends, with only a few words delay. However, due to the lack of large-scale, high-quality simultaneous translation datasets, most such systems are still trained on conventional full-sentence bitexts. This is far from ideal for the simultaneous scenario due to the abundance of unnecessary long-distance reorderings in those bitexts. We propose a novel method that rewrites the target side of existing full-sentence corpora into simultaneous-style translation. Experiments on Zh$\rightarrow$En and Ja$\rightarrow$En simultaneous translation show substantial improvements (up to +2.7 BLEU) with the addition of these generated pseudo-references.",
}

@inproceedings{miao-etal-2021-generative,
    title = "A Generative Framework for Simultaneous Machine Translation",
    author = "Miao, Yishu  and
      Blunsom, Phil  and
      Specia, Lucia",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.536",
    pages = "6697--6706",
    abstract = "We propose a generative framework for simultaneous machine translation. Conventional approaches use a fixed number of source words to translate or learn dynamic policies for the number of source words by reinforcement learning. Here we formulate simultaneous translation as a structural sequence-to-sequence learning problem. A latent variable is introduced to model read or translate actions at every time step, which is then integrated out to consider all the possible translation policies. A re-parameterised Poisson prior is used to regularise the policies which allows the model to explicitly balance translation quality and latency. The experiments demonstrate the effectiveness and robustness of the generative framework, which achieves the best BLEU scores given different average translation latencies on benchmark datasets.",
}

@inproceedings{voita-etal-2019-analyzing,
    title = "Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned",
    author = "Voita, Elena  and
      Talbot, David  and
      Moiseev, Fedor  and
      Sennrich, Rico  and
      Titov, Ivan",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1580",
    doi = "10.18653/v1/P19-1580",
    pages = "5797--5808",
    abstract = "Multi-head self-attention is a key component of the Transformer, a state-of-the-art architecture for neural machine translation. In this work we evaluate the contribution made by individual attention heads to the overall performance of the model and analyze the roles played by them in the encoder. We find that the most important and confident heads play consistent and often linguistically-interpretable roles. When pruning heads using a method based on stochastic gates and a differentiable relaxation of the L0 penalty, we observe that specialized heads are last to be pruned. Our novel pruning method removes the vast majority of heads without seriously affecting performance. For example, on the English-Russian WMT dataset, pruning 38 out of 48 encoder heads results in a drop of only 0.15 BLEU.",
}


@inproceedings{di-gangi-etal-2019-must,
    title = "{M}u{ST}-{C}: a {M}ultilingual {S}peech {T}ranslation {C}orpus",
    author = "Di Gangi, Mattia A.  and
      Cattoni, Roldano  and
      Bentivogli, Luisa  and
      Negri, Matteo  and
      Turchi, Marco",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1202",
    doi = "10.18653/v1/N19-1202",
    pages = "2012--2017",
    abstract = "Current research on spoken language translation (SLT) has to confront with the scarcity of sizeable and publicly available training corpora. This problem hinders the adoption of neural end-to-end approaches, which represent the state of the art in the two parent tasks of SLT: automatic speech recognition and machine translation. To fill this gap, we created MuST-C, a multilingual speech translation corpus whose size and quality will facilitate the training of end-to-end systems for SLT from English into 8 languages. For each target language, MuST-C comprises at least 385 hours of audio recordings from English TED Talks, which are automatically aligned at the sentence level with their manual transcriptions and translations. Together with a description of the corpus creation methodology (scalable to add new data and cover new languages), we provide an empirical verification of its quality and SLT results computed with a state-of-the-art approach on each language direction.",
}

@inproceedings{Povey:192584,
      title = {The Kaldi Speech Recognition Toolkit},
      author = {Povey, Daniel and Ghoshal, Arnab and Boulianne, Gilles and  Burget, Lukas and Glembek, Ondrej and Goel, Nagendra and  Hannemann, Mirko and Motlicek, Petr and Qian, Yanmin and  Schwarz, Petr and Silovsky, Jan and Stemmer, Georg and  Vesely, Karel},
      publisher = {IEEE Signal Processing Society},
      year = {2011},
      note = {IEEE Catalog No.: CFP11SRW-USB},
      abstract = {We describe the design of Kaldi, a free, open-source  toolkit for speech recognition research. Kaldi provides a  speech recognition system based on finite-state transducers  (using the freely available OpenFst), together with  detailed documentation and scripts for building complete  recognition systems. Kaldi is written is C++, and the core  library supports modeling of arbitrary phonetic-context  sizes, acoustic modeling with subspace Gaussian mixture  models (SGMM) as well as standard Gaussian mixture models,  together with all commonly used linear and affine  transforms. Kaldi is released under the Apache License  v2.0, which is highly nonrestrictive, making it suitable  for a wide community of users.},
      url = {http://infoscience.epfl.ch/record/192584},
}

@inproceedings{kudo-richardson-2018-sentencepiece,
    title = "{S}entence{P}iece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing",
    author = "Kudo, Taku  and
      Richardson, John",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-2012",
    doi = "10.18653/v1/D18-2012",
    pages = "66--71",
    abstract = "This paper describes SentencePiece, a language-independent subword tokenizer and detokenizer designed for Neural-based text processing, including Neural Machine Translation. It provides open-source C++ and Python implementations for subword units. While existing subword segmentation tools assume that the input is pre-tokenized into word sequences, SentencePiece can train subword models directly from raw sentences, which allows us to make a purely end-to-end and language independent system. We perform a validation experiment of NMT on English-Japanese machine translation, and find that it is possible to achieve comparable accuracy to direct subword training from raw sentences. We also compare the performance of subword training and segmentation with various configurations. SentencePiece is available under the Apache 2 license at \url{https://github.com/google/sentencepiece}.",
}

@inproceedings{zhang-feng-2021-universal,
    title = "Universal Simultaneous Machine Translation with Mixture-of-Experts Wait-k Policy",
    author = "Zhang, Shaolei  and
      Feng, Yang",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.581",
    doi = "10.18653/v1/2021.emnlp-main.581",
    pages = "7306--7317",
    abstract = "Simultaneous machine translation (SiMT) generates translation before reading the entire source sentence and hence it has to trade off between translation quality and latency. To fulfill the requirements of different translation quality and latency in practical applications, the previous methods usually need to train multiple SiMT models for different latency levels, resulting in large computational costs. In this paper, we propose a universal SiMT model with Mixture-of-Experts Wait-k Policy to achieve the best translation quality under arbitrary latency with only one trained model. Specifically, our method employs multi-head attention to accomplish the mixture of experts where each head is treated as a wait-k expert with its own waiting words number, and given a test latency and source inputs, the weights of the experts are accordingly adjusted to produce the best translation. Experiments on three datasets show that our method outperforms all the strong baselines under different latency, including the state-of-the-art adaptive policy.",
}

@inproceedings{inaguma-etal-2020-espnet,
    title = "{ESP}net-{ST}: All-in-One Speech Translation Toolkit",
    author = "Inaguma, Hirofumi  and
      Kiyono, Shun  and
      Duh, Kevin  and
      Karita, Shigeki  and
      Yalta, Nelson  and
      Hayashi, Tomoki  and
      Watanabe, Shinji",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-demos.34",
    doi = "10.18653/v1/2020.acl-demos.34",
    pages = "302--311",
    abstract = "We present ESPnet-ST, which is designed for the quick development of speech-to-speech translation systems in a single framework. ESPnet-ST is a new project inside end-to-end speech processing toolkit, ESPnet, which integrates or newly implements automatic speech recognition, machine translation, and text-to-speech functions for speech translation. We provide all-in-one recipes including data pre-processing, feature extraction, training, and decoding pipelines for a wide range of benchmark datasets. Our reproducible results can match or even outperform the current state-of-the-art performances; these pre-trained models are downloadable. The toolkit is publicly available at https://github.com/espnet/espnet.",
}

@inproceedings{ma-etal-2020-simuleval,
    title = "{SIMULEVAL}: An Evaluation Toolkit for Simultaneous Translation",
    author = "Ma, Xutai  and
      Dousti, Mohammad Javad  and
      Wang, Changhan  and
      Gu, Jiatao  and
      Pino, Juan",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-demos.19",
    doi = "10.18653/v1/2020.emnlp-demos.19",
    pages = "144--150",
    abstract = "Simultaneous translation on both text and speech focuses on a real-time and low-latency scenario where the model starts translating before reading the complete source input. Evaluating simultaneous translation models is more complex than offline models because the latency is another factor to consider in addition to translation quality. The research community, despite its growing focus on novel modeling approaches to simultaneous translation, currently lacks a universal evaluation procedure. Therefore, we present SimulEval, an easy-to-use and general evaluation toolkit for both simultaneous text and speech translation. A server-client scheme is introduced to create a simultaneous translation scenario, where the server sends source input and receives predictions for evaluation and the client executes customized policies. Given a policy, it automatically performs simultaneous decoding and collectively reports several popular latency metrics. We also adapt latency metrics from text simultaneous translation to the speech task. Additionally, SimulEval is equipped with a visualization interface to provide better understanding of the simultaneous decoding process of a system. SimulEval has already been extensively used for the IWSLT 2020 shared task on simultaneous speech translation. Code will be released upon publication.",
}

@inproceedings{ma-etal-2020-simulmt,
    title = "{S}imul{MT} to {S}imul{ST}: Adapting Simultaneous Text Translation to End-to-End Simultaneous Speech Translation",
    author = "Ma, Xutai  and
      Pino, Juan  and
      Koehn, Philipp",
    booktitle = "Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing",
    month = dec,
    year = "2020",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.aacl-main.58",
    pages = "582--587",
    abstract = "We investigate how to adapt simultaneous text translation methods such as wait-$k$ and monotonic multihead attention to end-to-end simultaneous speech translation by introducing a pre-decision module. A detailed analysis is provided on the latency-quality trade-offs of combining fixed and flexible pre-decision with fixed and flexible policies. We also design a novel computation-aware latency metric, adapted from Average Lagging.",
}

@inproceedings{NIPS2013_af21d0c9,
 author = {Cuturi, Marco},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Sinkhorn Distances: Lightspeed Computation of Optimal Transport},
 url = {https://proceedings.neurips.cc/paper/2013/file/af21d0c97db2e27e13572cbf59eb343d-Paper.pdf},
 volume = {26},
 year = {2013}
}

@article{Rubner,
author = {Rubner, Yossi and Guibas, Leonidas and Tomasi, Carlo},
year = {1997},
month = {01},
booktitle = "Proceedings of the ARPA Image Understanding Workshop",
pages = {661--668},
title = {The Earth Mover''s Distance, MultiDimensional Scaling, and Color-Based Image Retrieval}
}

@inproceedings{chen-etal-2019-improving-textual,
    title = "Improving Textual Network Embedding with Global Attention via Optimal Transport",
    author = "Chen, Liqun  and
      Wang, Guoyin  and
      Tao, Chenyang  and
      Shen, Dinghan  and
      Cheng, Pengyu  and
      Zhang, Xinyuan  and
      Wang, Wenlin  and
      Zhang, Yizhe  and
      Carin, Lawrence",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1512",
    doi = "10.18653/v1/P19-1512",
    pages = "5193--5202",
    abstract = "Constituting highly informative network embeddings is an essential tool for network analysis. It encodes network topology, along with other useful side information, into low dimensional node-based feature representations that can be exploited by statistical modeling. This work focuses on learning context-aware network embeddings augmented with text data. We reformulate the network embedding problem, and present two novel strategies to improve over traditional attention mechanisms: (i) a content-aware sparse attention module based on optimal transport; and (ii) a high-level attention parsing module. Our approach yields naturally sparse and self-normalized relational inference. It can capture long-term interactions between sequences, thus addressing the challenges faced by existing textual network embedding schemes. Extensive experiments are conducted to demonstrate our model can consistently outperform alternative state-of-the-art methods.",
}

@inproceedings{chen2018improving,
title={Improving Sequence-to-Sequence Learning via Optimal Transport},
author={Liqun Chen and Yizhe Zhang and Ruiyi Zhang and Chenyang Tao and Zhe Gan and Haichao Zhang and Bai Li and Dinghan Shen and Changyou Chen and Lawrence Carin},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=S1xtAjR5tX},
}

@inproceedings{tam-etal-2019-optimal,
    title = "Optimal Transport-based Alignment of Learned Character Representations for String Similarity",
    author = "Tam, Derek  and
      Monath, Nicholas  and
      Kobren, Ari  and
      Traylor, Aaron  and
      Das, Rajarshi  and
      McCallum, Andrew",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1592",
    doi = "10.18653/v1/P19-1592",
    pages = "5907--5917",
    abstract = "String similarity models are vital for record linkage, entity resolution, and search. In this work, we present STANCE{--}a learned model for computing the similarity of two strings. Our approach encodes the characters of each string, aligns the encodings using Sinkhorn Iteration (alignment is posed as an instance of optimal transport) and scores the alignment with a convolutional neural network. We evaluate STANCE{'}s ability to detect whether two strings can refer to the same entity{--}a task we term alias detection. We construct five new alias detection datasets (and make them publicly available). We show that STANCE (or one of its variants) outperforms both state-of-the-art and classic, parameter-free similarity models on four of the five datasets. We also demonstrate STANCE{'}s ability to improve downstream tasks by applying it to an instance of cross-document coreference and show that it leads to a 2.8 point improvement in B{\^{}}3 F1 over the previous state-of-the-art approach.",
}

@inproceedings{alqahtani-etal-2021-using-optimal,
    title = "Using Optimal Transport as Alignment Objective for fine-tuning Multilingual Contextualized Embeddings",
    author = "Alqahtani, Sawsan  and
      Lalwani, Garima  and
      Zhang, Yi  and
      Romeo, Salvatore  and
      Mansour, Saab",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.329",
    doi = "10.18653/v1/2021.findings-emnlp.329",
    pages = "3904--3919",
    abstract = "Recent studies have proposed different methods to improve multilingual word representations in contextualized settings including techniques that align between source and target embedding spaces. For contextualized embeddings, alignment becomes more complex as we additionally take context into consideration. In this work, we propose using Optimal Transport (OT) as an alignment objective during fine-tuning to further improve multilingual contextualized representations for downstream cross-lingual transfer. This approach does not require word-alignment pairs prior to fine-tuning that may lead to sub-optimal matching and instead learns the word alignments within context in an unsupervised manner. It also allows different types of mappings due to soft matching between source and target sentences. We benchmark our proposed method on two tasks (XNLI and XQuAD) and achieve improvements over baselines as well as competitive results compared to similar recent works.",
}
@TechReport{RePEc:crs:wpaper:2017-86,
  author={Gabriel Peyré and Marco Cuturi},
  title={{Computational Optimal Transport}},
  year=2017,
  month=Oct,
  institution={Center for Research in Economics and Statistics},
  type={Working Papers},
  url={https://ideas.repec.org/p/crs/wpaper/2017-86.html},
  number={2017-86},
  abstract={Optimal Transport (OT) is a mathematical gem at the interface between probability, analysis and optimization. The goal of that theory is to define geometric tools that are useful to compare probability distributions. Let us briefly sketch some key ideas using a vocabulary that was first introduced by Monge two centuries ago: a probability distribution can be thought of as a pile of sand. Peaks indicate where likely observations are to appear. Given a pair of probability distributions—two different piles of sand—there are, in general, multiple ways to morph, transport or reshape the first pile so that it matches the second. To every such transport we associate an a “global” cost, using the “local” consideration of how much it costs to move a single grain of sand from one location to another. The goal of optimal transport is to find the least costly transport, and use it to derive an entire geometric toolbox for probability distributions. Despite this relatively abstract description, optimal transport theory answers many basic questions related to the way our economy works: In the “mines and factories” problem, the sand is distributed across an entire country, each grain of sand represents a unit of a useful raw resource; the target pile indicates where those resources are needed, typically in factories, where they are meant to be processed. In that scenario, one seeks the least costly way to move all these resources, knowing the entire logistic cost matrix needed to ship resources from any storage point to any factory. Transporting optimally two abstract distributions is also extremely relevant for mathematicians, in the sense that it defines a rich geometric structure on the space of probability distributions. That structure is canonical in the sense that it borrows, in arguably the most natural way, key geometric properties of the underlying “ground” space on which these distributions are defined. For instance, when the underlying space is Euclidean, key concepts s},
  keywords={},
  doi={},
}

@inproceedings{Villani2008OptimalTO,
  title={Optimal Transport: Old and New},
  author={C{\'e}dric Villani},
  year={2008},
  booktitle = {Springer Verlag},
  url = "https://link.springer.com/book/10.1007/978-3-540-71050-9#authorsandaffiliationsbook",
}
@inproceedings{xu-etal-2018-unsupervised-cross,
    title = "Unsupervised Cross-lingual Transfer of Word Embedding Spaces",
    author = "Xu, Ruochen  and
      Yang, Yiming  and
      Otani, Naoki  and
      Wu, Yuexin",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1268",
    doi = "10.18653/v1/D18-1268",
    pages = "2465--2474",
    abstract = "Cross-lingual transfer of word embeddings aims to establish the semantic mappings among words in different languages by learning the transformation functions over the corresponding word embedding spaces. Successfully solving this problem would benefit many downstream tasks such as to translate text classification models from resource-rich languages (e.g. English) to low-resource languages. Supervised methods for this problem rely on the availability of cross-lingual supervision, either using parallel corpora or bilingual lexicons as the labeled data for training, which may not be available for many low resource languages. This paper proposes an unsupervised learning approach that does not require any cross-lingual labeled data. Given two monolingual word embedding spaces for any language pair, our algorithm optimizes the transformation functions in both directions simultaneously based on distributional matching as well as minimizing the back-translation losses. We use a neural network implementation to calculate the Sinkhorn distance, a well-defined distributional similarity measure, and optimize our objective through back-propagation. Our evaluation on benchmark datasets for bilingual lexicon induction and cross-lingual word similarity prediction shows stronger or competitive performance of the proposed method compared to other state-of-the-art supervised and unsupervised baseline methods over many language pairs.",
}

@inproceedings{jalili-sabet-etal-2020-simalign,
    title = "{S}im{A}lign: High Quality Word Alignments without Parallel Training Data using Static and Contextualized Embeddings",
    author = {Jalili Sabet, Masoud  and
      Dufter, Philipp  and
      Yvon, Fran{\c{c}}ois  and
      Sch{\"u}tze, Hinrich},
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.findings-emnlp.147",
    pages = "1627--1643",
}


@InProceedings{pmlr-v37-kusnerb15,
  title = 	 {From Word Embeddings To Document Distances},
  author = 	 {Kusner, Matt and Sun, Yu and Kolkin, Nicholas and Weinberger, Kilian},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {957--966},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/kusnerb15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/kusnerb15.html},
  abstract = 	 {We present the Word Mover’s Distance (WMD), a novel distance function between text documents. Our work is based on recent results in word embeddings that learn semantically meaningful representations for words from local co-occurrences in sentences. The WMD distance measures the dissimilarity between two text documents as the minimum amount of distance that the embedded words of one document need to "travel" to reach the embedded words of another document. We show that this distance metric can be cast as an instance of the Earth Mover’s Distance, a well studied transportation problem for which several highly efficient solvers have been developed. Our metric has no hyperparameters and is straight-forward to implement. Further, we demonstrate on eight real world document classification data sets, in comparison with seven state-of-the-art baselines, that the WMD metric leads to unprecedented low k-nearest neighbor document classification error rates.}
}

@inproceedings{zhang-feng-2021-modeling-concentrated,
    title = "Modeling Concentrated Cross-Attention for Neural Machine Translation with {G}aussian Mixture Model",
    author = "Zhang, Shaolei  and
      Feng, Yang",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.121",
    doi = "10.18653/v1/2021.findings-emnlp.121",
    pages = "1401--1411",
    abstract = "Cross-attention is an important component of neural machine translation (NMT), which is always realized by dot-product attention in previous methods. However, dot-product attention only considers the pair-wise correlation between words, resulting in dispersion when dealing with long sentences and neglect of source neighboring relationships. Inspired by linguistics, the above issues are caused by ignoring a type of cross-attention, called concentrated attention, which focuses on several central words and then spreads around them. In this work, we apply Gaussian Mixture Model (GMM) to model the concentrated attention in cross-attention. Experiments and analyses we conducted on three datasets show that the proposed method outperforms the baseline and has significant improvement on alignment quality, N-gram accuracy, and long sentence translation.",
}

@inproceedings{zheng-etal-2020-fluent,
    title = "Fluent and Low-latency Simultaneous Speech-to-Speech Translation with Self-adaptive Training",
    author = "Zheng, Renjie  and
      Ma, Mingbo  and
      Zheng, Baigong  and
      Liu, Kaibo  and
      Yuan, Jiahong  and
      Church, Kenneth  and
      Huang, Liang",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.349",
    doi = "10.18653/v1/2020.findings-emnlp.349",
    pages = "3928--3937",
    abstract = "Simultaneous speech-to-speech translation is an extremely challenging but widely useful scenario that aims to generate target-language speech only a few seconds behind the source-language speech. In addition, we have to continuously translate a speech of multiple sentences, but all recent solutions merely focus on the single-sentence scenario. As a result, current approaches will accumulate more and more latencies in later sentences when the speaker talks faster and introduce unnatural pauses into translated speech when the speaker talks slower. To overcome these issues, we propose Self-Adaptive Translation which flexibly adjusts the length of translations to accommodate different source speech rates. At similar levels of translation quality (as measured by BLEU), our method generates more fluent target speech latency than the baseline, in both Zh{\textless}-{\textgreater}En directions.",
}

@ARTICLE{802909,
  author={Chong, E.K.P. and Hui, S. and Zak, S.H.},
  journal={IEEE Transactions on Automatic Control}, 
  title={An analysis of a class of neural networks for solving linear programming problems}, 
  year={1999},
  volume={44},
  number={11},
  pages={1995-2006},
  doi={10.1109/9.802909}}
  
@INPROCEEDINGS{1007531,
author={Ferreira, L.V. and Kaszkurewicz, E. and Bhaya, A.},
booktitle={Proceedings of the 2002 International Joint Conference on Neural Networks. IJCNN'02 (Cat. No.02CH37290)}, 
title={Convergence analysis of neural networks that solve linear programming problems}, 
year={2002},
volume={3},
number={},
pages={2476-2481 vol.3},
doi={10.1109/IJCNN.2002.1007531}}


@article{10.2307/1905523,
 ISSN = {00129682, 14680262},
 URL = {http://www.jstor.org/stable/1905523},
 abstract = {Activities (or production processes) are considered as building blocks out of which a technology is constructed. Postulates are developed by which activities may be combined. The main part of the paper is concerned with the discrete type model and the use of a linear maximization function for finding the "optimum" program. The mathematical problem associated with this approach is developed first in general notation and then in term sof a dynamic system of equations expressed in matrix notation. Typical problems from the fields of inter-industryrelations, transportation nutrition, warehouse storage, and air transport are given in the last section.},
 author = {George B. Dantzig},
 journal = {Econometrica},
 number = {3/4},
 pages = {200--211},
 publisher = {[Wiley, Econometric Society]},
 title = {Programming of Interdependent Activities: II Mathematical Model},
 volume = {17},
 year = {1949}
}

@article{doi:10.1137/130929886,
author = {Ferradans, Sira and Papadakis, Nicolas and Peyré, Gabriel and Aujol, Jean-François},
title = {Regularized Discrete Optimal Transport},
journal = {SIAM Journal on Imaging Sciences},
volume = {7},
number = {3},
pages = {1853-1882},
year = {2014},
doi = {10.1137/130929886},

URL = { 
        https://doi.org/10.1137/130929886
    
},
eprint = { 
        https://doi.org/10.1137/130929886
    
}
,
    abstract = { This article introduces a generalization of the discrete optimal transport, with applications to color image manipulations. This new formulation includes a relaxation of the mass conservation constraint and a regularization term. These two features are crucial for image processing tasks where one must take into account families of multimodal histograms with large mass variation across modes. The corresponding relaxed and regularized transportation problem is the solution of a convex optimization problem. Depending on the regularization used, this minimization can be solved using standard linear programming methods or first order proximal splitting schemes. The resulting transportation plan can be used as a color transfer map, which is robust to mass variation across image color palettes. Furthermore, the regularization of the transport plan helps remove colorization artifacts due to noise amplification. We also extend this framework to compute the barycenter of distributions. The barycenter is the solution of an optimization problem, which is separately convex with respect to the barycenter and the transportation plans, but not jointly convex. A block coordinate descent scheme converges to a stationary point of the energy. We show that the resulting algorithm can be used for color normalization across several images. The relaxed and regularized barycenter defines a common color palette for those images. Applying color transfer toward this average palette performs a color normalization of the input images. }
}
@inproceedings{laf,
    title = "Reducing Position Bias in Simultaneous Machine Translation with Length-Aware Framework",
    author = "Zhang, Shaolei  and
      Feng, Yang",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.467",
    pages = "6775--6788",
    abstract = "Simultaneous machine translation (SiMT) starts translating while receiving the streaming source inputs, and hence the source sentence is always incomplete during translating. Different from the full-sentence MT using the conventional seq-to-seq architecture, SiMT often applies prefix-to-prefix architecture, which forces each target word to only align with a partial source prefix to adapt to the incomplete source in streaming inputs. However, the source words in the front positions are always illusoryly considered more important since they appear in more prefixes, resulting in position bias, which makes the model pay more attention on the front source positions in testing. In this paper, we first analyze the phenomenon of position bias in SiMT, and develop a Length-Aware Framework to reduce the position bias by bridging the structural gap between SiMT and full-sentence MT. Specifically, given the streaming inputs, we first predict the full-sentence length and then fill the future source position with positional encoding, thereby turning the streaming inputs into a pseudo full-sentence. The proposed framework can be integrated into most existing SiMT methods to further improve performance. Experiments on two representative SiMT methods, including the state-of-the-art adaptive policy, show that our method successfully reduces the position bias and thereby achieves better SiMT performance.",

}
@inproceedings{dualpath,
    title = "Modeling Dual Read/Write Paths for Simultaneous Machine Translation",
    author = "Zhang, Shaolei  and
      Feng, Yang",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.176",
    pages = "2461--2477",
    abstract = "Simultaneous machine translation (SiMT) outputs translation while reading source sentence and hence requires a policy to decide whether to wait for the next source word (READ) or generate a target word (WRITE), the actions of which form a read/write path. Although the read/write path is essential to SiMT performance, no direct supervision is given to the path in the existing methods. In this paper, we propose a method of dual-path SiMT which introduces duality constraints to direct the read/write path. According to duality constraints, the read/write path in source-to-target and target-to-source SiMT models can be mapped to each other. As a result, the two SiMT models can be optimized jointly by forcing their read/write paths to satisfy the mapping. Experiments on En-Vi and De-En tasks show that our method can outperform strong baselines under all latency.",
}

@inproceedings{gma,
    title = "{G}aussian Multi-head Attention for Simultaneous Machine Translation",
    author = "Zhang, Shaolei  and
      Feng, Yang",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.238",
    pages = "3019--3030",
    abstract = "Simultaneous machine translation (SiMT) outputs translation while receiving the streaming source inputs, and hence needs a policy to determine where to start translating. The alignment between target and source words often implies the most informative source word for each target word, and hence provides the unified control over translation quality and latency, but unfortunately the existing SiMT methods do not explicitly model the alignment to perform the control. In this paper, we propose Gaussian Multi-head Attention (GMA) to develop a new SiMT policy by modeling alignment and translation in a unified manner. For SiMT policy, GMA models the aligned source position of each target word, and accordingly waits until its aligned position to start translating. To integrate the learning of alignment into the translation model, a Gaussian distribution centered on predicted aligned position is introduced as an alignment-related prior, which cooperates with translation-related soft attention to determine the final attention. Experiments on En-Vi and De-En tasks show that our method outperforms strong baselines on the trade-off between translation and latency.",
}

@inproceedings{abnar-zuidema-2020-quantifying,
    title = "Quantifying Attention Flow in Transformers",
    author = "Abnar, Samira  and
      Zuidema, Willem",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.385",
    doi = "10.18653/v1/2020.acl-main.385",
    pages = "4190--4197",
    abstract = "In the Transformer model, {``}self-attention{''} combines information from attended embeddings into the representation of the focal embedding in the next layer. Thus, across layers of the Transformer, information originating from different tokens gets increasingly mixed. This makes attention weights unreliable as explanations probes. In this paper, we consider the problem of quantifying this flow of information through self-attention. We propose two methods for approximating the attention to input tokens given attention weights, attention rollout and attention flow, as post hoc methods when we use attention weights as the relative relevance of the input tokens. We show that these methods give complementary views on the flow of information, and compared to raw attention, both yield higher correlations with importance scores of input tokens obtained using an ablation method and input gradients.",
}

@inproceedings{wiegreffe-pinter-2019-attention,
    title = "Attention is not not Explanation",
    author = "Wiegreffe, Sarah  and
      Pinter, Yuval",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1002",
    doi = "10.18653/v1/D19-1002",
    pages = "11--20",
    abstract = "Attention mechanisms play a central role in NLP systems, especially within recurrent neural network (RNN) models. Recently, there has been increasing interest in whether or not the intermediate representations offered by these modules may be used to explain the reasoning for a model{'}s prediction, and consequently reach insights regarding the model{'}s decision-making process. A recent paper claims that {`}Attention is not Explanation{'} (Jain and Wallace, 2019). We challenge many of the assumptions underlying this work, arguing that such a claim depends on one{'}s definition of explanation, and that testing it needs to take into account all elements of the model. We propose four alternative tests to determine when/whether attention can be used as explanation: a simple uniform-weights baseline; a variance calibration based on multiple random seed runs; a diagnostic framework using frozen weights from pretrained models; and an end-to-end adversarial attention training protocol. Each allows for meaningful interpretation of attention mechanisms in RNN models. We show that even when reliable adversarial distributions can be found, they don{'}t perform well on the simple diagnostic, indicating that prior work does not disprove the usefulness of attention mechanisms for explainability.",
}

@inproceedings{chen-etal-2020-accurate,
    title = "Accurate Word Alignment Induction from Neural Machine Translation",
    author = "Chen, Yun  and
      Liu, Yang  and
      Chen, Guanhua  and
      Jiang, Xin  and
      Liu, Qun",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.42",
    doi = "10.18653/v1/2020.emnlp-main.42",
    pages = "566--576",
    abstract = "Despite its original goal to jointly learn to align and translate, prior researches suggest that Transformer captures poor word alignments through its attention mechanism. In this paper, we show that attention weights do capture accurate word alignments and propose two novel word alignment induction methods Shift-Att and Shift-AET. The main idea is to induce alignments at the step when the to-be-aligned target token is the decoder input rather than the decoder output as in previous work. Shift-Att is an interpretation method that induces alignments from the attention weights of Transformer and does not require parameter update or architecture change. Shift-AET extracts alignments from an additional alignment module which is tightly integrated into Transformer and trained in isolation with supervision from symmetrized Shift-Att alignments. Experiments on three publicly available datasets demonstrate that both methods perform better than their corresponding neural baselines and Shift-AET significantly outperforms GIZA++ by 1.4-4.8 AER points.",
}

@inproceedings{ITST,
    title = "Information-Transport-based Policy for Simultaneous Translation",
    author = "Zhang, Shaolei  and
      Feng, Yang",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.65",
    doi = "10.18653/v1/2022.emnlp-main.65",
    pages = "992--1013",
    abstract = "Simultaneous translation (ST) outputs translation while receiving the source inputs, and hence requires a policy to determine whether to translate a target token or wait for the next source token. The major challenge of ST is that each target token can only be translated based on the current received source tokens, where the received source information will directly affect the translation quality. So naturally, how much source information is received for the translation of the current target token is supposed to be the pivotal evidence for the ST policy to decide between translating and waiting. In this paper, we treat the translation as information transport from source to target and accordingly propose an Information-Transport-based Simultaneous Translation (ITST). ITST quantifies the transported information weight from each source token to the current target token, and then decides whether to translate the target token according to its accumulated received information. Experiments on both text-to-text ST and speech-to-text ST (a.k.a., streaming speech translation) tasks show that ITST outperforms strong baselines and achieves state-of-the-art performance.",
}

@inproceedings{wait-info,
    title = "Wait-info Policy: Balancing Source and Target at Information Level for Simultaneous Machine Translation",
    author = "Zhang, Shaolei  and
      Guo, Shoutao  and
      Feng, Yang",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.166",
    doi = "10.18653/v1/2022.findings-emnlp.166",
    pages = "2249--2263",
    abstract = "Simultaneous machine translation (SiMT) outputs the translation while receiving the source inputs, and hence needs to balance the received source information and translated target information to make a reasonable decision between waiting for inputs or outputting translation. Previous methods always balance source and target information at the token level, either directly waiting for a fixed number of tokens or adjusting the waiting based on the current token. In this paper, we propose a Wait-info Policy to balance source and target at the information level. We first quantify the amount of information contained in each token, named info. Then during simultaneous translation, the decision of waiting or outputting is made based on the comparison results between the total info of previous target outputs and received source inputs. Experiments show that our method outperforms strong baselines under and achieves better balance via the proposed info.",
}

@inproceedings{post-eval,
    title = "Turning Fixed to Adaptive: Integrating Post-Evaluation into Simultaneous Machine Translation",
    author = "Guo, Shoutao  and
      Zhang, Shaolei  and
      Feng, Yang",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.167",
    doi = "10.18653/v1/2022.findings-emnlp.167",
    pages = "2264--2278",
    abstract = "Simultaneous machine translation (SiMT) starts its translation before reading the whole source sentence and employs either fixed or adaptive policy to generate the target sentence. Compared to the fixed policy, the adaptive policy achieves better latency-quality tradeoffs by adopting a flexible translation policy. If the policy can evaluate rationality before taking action, the probability of incorrect actions will also decrease. However, previous methods lack evaluation of actions before taking them. In this paper, we propose a method of performing the adaptive policy via integrating post-evaluation into the fixed policy. Specifically, whenever a candidate token is generated, our model will evaluate the rationality of the next action by measuring the change in the source content. Our model will then take different actions based on the evaluation results. Experiments on three translation tasks show that our method can exceed strong baselines under all latency.",
}

@inproceedings{dong-etal-2022-learning,
    title = "Learning When to Translate for Streaming Speech",
    author = "Dong, Qian  and
      Zhu, Yaoming  and
      Wang, Mingxuan  and
      Li, Lei",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.50",
    doi = "10.18653/v1/2022.acl-long.50",
    pages = "680--694",
    abstract = "How to find proper moments to generate partial sentence translation given a streaming speech input? Existing approaches waiting-and-translating for a fixed duration often break the acoustic units in speech, since the boundaries between acoustic units in speech are not even. In this paper, we propose MoSST, a simple yet effective method for translating streaming speech content. Given a usually long speech sequence, we develop an efficient monotonic segmentation module inside an encoder-decoder model to accumulate acoustic information incrementally and detect proper speech unit boundaries for the input in speech translation task. Experiments on multiple translation directions of the MuST-C dataset show that outperforms existing methods and achieves the best trade-off between translation quality (BLEU) and latency. Our code is available at https://github.com/dqqcasia/mosst.",
}

@inproceedings{wang-etal-2020-fairseq,
    title = "Fairseq {S}2{T}: Fast Speech-to-Text Modeling with Fairseq",
    author = "Wang, Changhan  and
      Tang, Yun  and
      Ma, Xutai  and
      Wu, Anne  and
      Okhonko, Dmytro  and
      Pino, Juan",
    booktitle = "Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing: System Demonstrations",
    month = dec,
    year = "2020",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.aacl-demo.6",
    pages = "33--39",
    abstract = "We introduce fairseq S2T, a fairseq extension for speech-to-text (S2T) modeling tasks such as end-to-end speech recognition and speech-to-text translation. It follows fairseq{'}s careful design for scalability and extensibility. We provide end-to-end workflows from data pre-processing, model training to offline (online) inference. We implement state-of-the-art RNN-based as well as Transformer-based models and open-source detailed training recipes. Fairseq{'}s machine translation models and language models can be seamlessly integrated into S2T workflows for multi-task learning or transfer learning. Fairseq S2T is available at https://github.com/pytorch/fairseq/tree/master/examples/speech{\_}to{\_}text.",
}



@inproceedings{zhang-etal-2020-adaptive,
    title = "Adaptive Feature Selection for End-to-End Speech Translation",
    author = "Zhang, Biao  and
      Titov, Ivan  and
      Haddow, Barry  and
      Sennrich, Rico",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.230",
    doi = "10.18653/v1/2020.findings-emnlp.230",
    pages = "2533--2544",
    abstract = "Information in speech signals is not evenly distributed, making it an additional challenge for end-to-end (E2E) speech translation (ST) to learn to focus on informative features. In this paper, we propose adaptive feature selection (AFS) for encoder-decoder based E2E ST. We first pre-train an ASR encoder and apply AFS to dynamically estimate the importance of each encoded speech feature to ASR. A ST encoder, stacked on top of the ASR encoder, then receives the filtered features from the (frozen) ASR encoder. We take L0DROP (Zhang et al., 2020) as the backbone for AFS, and adapt it to sparsify speech features with respect to both temporal and feature dimensions. Results on LibriSpeech EnFr and MuST-C benchmarks show that AFS facilitates learning of ST by pruning out {\textasciitilde}84{\%} temporal features, yielding an average translation gain of {\textasciitilde}1.3-1.6 BLEU and a decoding speedup of {\textasciitilde}1.4x. In particular, AFS reduces the performance gap compared to the cascade baseline, and outperforms it on LibriSpeech En-Fr with a BLEU score of 18.56 (without data augmentation).",
}

@inproceedings{le-etal-2020-dual,
    title = "Dual-decoder Transformer for Joint Automatic Speech Recognition and Multilingual Speech Translation",
    author = "Le, Hang  and
      Pino, Juan  and
      Wang, Changhan  and
      Gu, Jiatao  and
      Schwab, Didier  and
      Besacier, Laurent",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2020.coling-main.314",
    doi = "10.18653/v1/2020.coling-main.314",
    pages = "3520--3533",
    abstract = "We introduce dual-decoder Transformer, a new model architecture that jointly performs automatic speech recognition (ASR) and multilingual speech translation (ST). Our models are based on the original Transformer architecture (Vaswani et al., 2017) but consist of two decoders, each responsible for one task (ASR or ST). Our major contribution lies in how these decoders interact with each other: one decoder can attend to different information sources from the other via a dual-attention mechanism. We propose two variants of these architectures corresponding to two different levels of dependencies between the decoders, called the parallel and cross dual-decoder Transformers, respectively. Extensive experiments on the MuST-C dataset show that our models outperform the previously-reported highest translation performance in the multilingual settings, and outperform as well bilingual one-to-one results. Furthermore, our parallel models demonstrate no trade-off between ASR and ST compared to the vanilla multi-task architecture. Our code and pre-trained models are available at https://github.com/formiel/speech-translation.",
}

@inproceedings{zeng-etal-2021-realtrans,
    title = "{R}eal{T}ran{S}: End-to-End Simultaneous Speech Translation with Convolutional Weighted-Shrinking Transformer",
    author = "Zeng, Xingshan  and
      Li, Liangyou  and
      Liu, Qun",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.218",
    doi = "10.18653/v1/2021.findings-acl.218",
    pages = "2461--2474",
}

@inproceedings{anastasopoulos-chiang-2018-tied,
    title = "Tied Multitask Learning for Neural Speech Translation",
    author = "Anastasopoulos, Antonios  and
      Chiang, David",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1008",
    doi = "10.18653/v1/N18-1008",
    pages = "82--91",
    abstract = "We explore multitask models for neural translation of speech, augmenting them in order to reflect two intuitive notions. First, we introduce a model where the second task decoder receives information from the decoder of the first task, since higher-level intermediate representations should provide useful information. Second, we apply regularization that encourages transitivity and invertibility. We show that the application of these notions on jointly trained models improves performance on the tasks of low-resource speech transcription and translation. It also leads to better performance when using attention information for word discovery over unsegmented input.",
}

@inproceedings{NEURIPS2020_92d1e1eb,
 author = {Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {12449--12460},
 publisher = {Curran Associates, Inc.},
 title = {wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations},
 url = {https://proceedings.neurips.cc/paper/2020/file/92d1e1eb1cd6f9fba3227870bb6d7f07-Paper.pdf},
 volume = {33},
 year = {2020}
}

@INPROCEEDINGS{7178964,
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Librispeech: An ASR corpus based on public domain audio books}, 
  year={2015},
  volume={},
  number={},
  pages={5206-5210},
  doi={10.1109/ICASSP.2015.7178964}}


@inproceedings{
zhang2023hidden,
title={Hidden Markov Transformer for Simultaneous Machine Translation},
author={Shaolei Zhang and Yang Feng},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=9y0HFvaAYD6}
}


@inproceedings{zhang-etal-2020-adaptive,
    title = "Adaptive Feature Selection for End-to-End Speech Translation",
    author = "Zhang, Biao  and
      Titov, Ivan  and
      Haddow, Barry  and
      Sennrich, Rico",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.findings-emnlp.230",
    doi = "10.18653/v1/2020.findings-emnlp.230",
    pages = "2533--2544",
    abstract = "Information in speech signals is not evenly distributed, making it an additional challenge for end-to-end (E2E) speech translation (ST) to learn to focus on informative features. In this paper, we propose adaptive feature selection (AFS) for encoder-decoder based E2E ST. We first pre-train an ASR encoder and apply AFS to dynamically estimate the importance of each encoded speech feature to ASR. A ST encoder, stacked on top of the ASR encoder, then receives the filtered features from the (frozen) ASR encoder. We take L0DROP (Zhang et al., 2020) as the backbone for AFS, and adapt it to sparsify speech features with respect to both temporal and feature dimensions. Results on LibriSpeech EnFr and MuST-C benchmarks show that AFS facilitates learning of ST by pruning out {\textasciitilde}84{\%} temporal features, yielding an average translation gain of {\textasciitilde}1.3-1.6 BLEU and a decoding speedup of {\textasciitilde}1.4x. In particular, AFS reduces the performance gap compared to the cascade baseline, and outperforms it on LibriSpeech En-Fr with a BLEU score of 18.56 (without data augmentation).",
}

@inproceedings{le-etal-2020-dual,
    title = "Dual-decoder Transformer for Joint Automatic Speech Recognition and Multilingual Speech Translation",
    author = "Le, Hang  and
      Pino, Juan  and
      Wang, Changhan  and
      Gu, Jiatao  and
      Schwab, Didier  and
      Besacier, Laurent",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2020.coling-main.314",
    doi = "10.18653/v1/2020.coling-main.314",
    pages = "3520--3533",
    abstract = "We introduce dual-decoder Transformer, a new model architecture that jointly performs automatic speech recognition (ASR) and multilingual speech translation (ST). Our models are based on the original Transformer architecture (Vaswani et al., 2017) but consist of two decoders, each responsible for one task (ASR or ST). Our major contribution lies in how these decoders interact with each other: one decoder can attend to different information sources from the other via a dual-attention mechanism. We propose two variants of these architectures corresponding to two different levels of dependencies between the decoders, called the parallel and cross dual-decoder Transformers, respectively. Extensive experiments on the MuST-C dataset show that our models outperform the previously-reported highest translation performance in the multilingual settings, and outperform as well bilingual one-to-one results. Furthermore, our parallel models demonstrate no trade-off between ASR and ST compared to the vanilla multi-task architecture. Our code and pre-trained models are available at https://github.com/formiel/speech-translation.",
}


@inproceedings{NIPS2016_c7635bfd,
 author = {Foerster, Jakob and Assael, Ioannis Alexandros and de Freitas, Nando and Whiteson, Shimon},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Learning to Communicate with Deep Multi-Agent Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper/2016/file/c7635bfd99248a2cdef8249ef7bfbef4-Paper.pdf},
 volume = {29},
 year = {2016}
}

@article{SALAKHUTDINOV2009969,
title = {Semantic hashing},
journal = {International Journal of Approximate Reasoning},
volume = {50},
number = {7},
pages = {969-978},
year = {2009},
note = {Special Section on Graphical Models and Information Retrieval},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2008.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X08001813},
author = {Ruslan Salakhutdinov and Geoffrey Hinton},
keywords = {Information retrieval, Graphical models, Unsupervised learning},
abstract = {We show how to learn a deep graphical model of the word-count vectors obtained from a large set of documents. The values of the latent variables in the deepest layer are easy to infer and give a much better representation of each document than Latent Semantic Analysis. When the deepest layer is forced to use a small number of binary variables (e.g. 32), the graphical model performs “semantic hashing”: Documents are mapped to memory addresses in such a way that semantically similar documents are located at nearby addresses. Documents similar to a query document can then be found by simply accessing all the addresses that differ by only a few bits from the address of the query document. This way of extending the efficiency of hash-coding to approximate matching is much faster than locality sensitive hashing, which is the fastest current method. By using semantic hashing to filter the documents given to TF-IDF, we achieve higher accuracy than applying TF-IDF to the entire document set.}
}

@inproceedings{NIPS2016_6b180037,
 author = {Sohn, Kihyuk},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Improved Deep Metric Learning with Multi-class N-pair Loss Objective},
 url = {https://proceedings.neurips.cc/paper/2016/file/6b180037abbebea991d8b1232f8a8ca9-Paper.pdf},
 volume = {29},
 year = {2016}
}

@inproceedings{ren-etal-2020-simulspeech,
    title = "{S}imul{S}peech: End-to-End Simultaneous Speech to Text Translation",
    author = "Ren, Yi  and
      Liu, Jinglin  and
      Tan, Xu  and
      Zhang, Chen  and
      Qin, Tao  and
      Zhao, Zhou  and
      Liu, Tie-Yan",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.350",
    doi = "10.18653/v1/2020.acl-main.350",
    pages = "3787--3796",
    abstract = "In this work, we develop SimulSpeech, an end-to-end simultaneous speech to text translation system which translates speech in source language to text in target language concurrently. SimulSpeech consists of a speech encoder, a speech segmenter and a text decoder, where 1) the segmenter builds upon the encoder and leverages a connectionist temporal classification (CTC) loss to split the input streaming speech in real time, 2) the encoder-decoder attention adopts a wait-$k$ strategy for simultaneous translation. SimulSpeech is more challenging than previous cascaded systems (with simultaneous automatic speech recognition (ASR) and simultaneous neural machine translation (NMT)). We introduce two novel knowledge distillation methods to ensure the performance: 1) Attention-level knowledge distillation transfers the knowledge from the multiplication of the attention matrices of simultaneous NMT and ASR models to help the training of the attention mechanism in SimulSpeech; 2) Data-level knowledge distillation transfers the knowledge from the full-sentence NMT model and also reduces the complexity of data distribution to help on the optimization of SimulSpeech. Experiments on MuST-C English-Spanish and English-German spoken language translation datasets show that SimulSpeech achieves reasonable BLEU scores and lower delay compared to full-sentence end-to-end speech to text translation (without simultaneous translation), and better performance than the two-stage cascaded simultaneous translation model in terms of BLEU scores and translation delay.",
}



@inproceedings{zhang-etal-2022-learning,
    title = "Learning Adaptive Segmentation Policy for End-to-End Simultaneous Translation",
    author = "Zhang, Ruiqing  and
      He, Zhongjun  and
      Wu, Hua  and
      Wang, Haifeng",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.542",
    doi = "10.18653/v1/2022.acl-long.542",
    pages = "7862--7874",
    abstract = "End-to-end simultaneous speech-to-text translation aims to directly perform translation from streaming source speech to target text with high translation quality and low latency. A typical simultaneous translation (ST) system consists of a speech translation model and a policy module, which determines when to wait and when to translate. Thus the policy is crucial to balance translation quality and latency. Conventional methods usually adopt fixed policies, e.g. segmenting the source speech with a fixed length and generating translation. However, this method ignores contextual information and suffers from low translation quality. This paper proposes an adaptive segmentation policy for end-to-end ST. Inspired by human interpreters, the policy learns to segment the source streaming speech into meaningful units by considering both acoustic features and translation history, maintaining consistency between the segmentation and translation. Experimental results on English-German and Chinese-English show that our method achieves a good accuracy-latency trade-off over recently proposed state-of-the-art methods.",
}

@inproceedings{Weiss2017,
  author={Ron J. Weiss and Jan Chorowski and Navdeep Jaitly and Yonghui Wu and Zhifeng Chen},
  title={Sequence-to-Sequence Models Can Directly Translate Foreign Speech},
  year=2017,
  booktitle={Proc. Interspeech 2017},
  pages={2625--2629},
  doi={10.21437/Interspeech.2017-503},
  url={http://dx.doi.org/10.21437/Interspeech.2017-503}
}
@inproceedings{wang-etal-2020-fairseq,
    title = "Fairseq {S}2{T}: Fast Speech-to-Text Modeling with Fairseq",
    author = "Wang, Changhan  and
      Tang, Yun  and
      Ma, Xutai  and
      Wu, Anne  and
      Okhonko, Dmytro  and
      Pino, Juan",
    booktitle = "Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing: System Demonstrations",
    month = dec,
    year = "2020",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.aacl-demo.6",
    pages = "33--39",
    abstract = "We introduce fairseq S2T, a fairseq extension for speech-to-text (S2T) modeling tasks such as end-to-end speech recognition and speech-to-text translation. It follows fairseq{'}s careful design for scalability and extensibility. We provide end-to-end workflows from data pre-processing, model training to offline (online) inference. We implement state-of-the-art RNN-based as well as Transformer-based models and open-source detailed training recipes. Fairseq{'}s machine translation models and language models can be seamlessly integrated into S2T workflows for multi-task learning or transfer learning. Fairseq S2T is available at https://github.com/pytorch/fairseq/tree/master/examples/speech{\_}to{\_}text.",
}


@INPROCEEDINGS{9414897,
  author={Ma, Xutai and Wang, Yongqiang and Dousti, Mohammad Javad and Koehn, Philipp and Pino, Juan},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Streaming Simultaneous Speech Translation with Augmented Memory Transformer}, 
  year={2021},
  volume={},
  number={},
  pages={7523-7527},
  doi={10.1109/ICASSP39728.2021.9414897}}

@INPROCEEDINGS{9414276,
  author={Nguyen, Ha and Estève, Yannick and Besacier, Laurent},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={An Empirical Study of End-To-End Simultaneous Speech Translation Decoding Strategies}, 
  year={2021},
  volume={},
  number={},
  pages={7528-7532},
  doi={10.1109/ICASSP39728.2021.9414276}}

@inproceedings{chen-etal-2021-direct,
    title = "Direct Simultaneous Speech-to-Text Translation Assisted by Synchronized Streaming {ASR}",
    author = "Chen, Junkun  and
      Ma, Mingbo  and
      Zheng, Renjie  and
      Huang, Liang",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.406",
    doi = "10.18653/v1/2021.findings-acl.406",
    pages = "4618--4624",
}

@inproceedings{tang-etal-2021-improving,
    title = "Improving Speech Translation by Understanding and Learning from the Auxiliary Text Translation Task",
    author = "Tang, Yun  and
      Pino, Juan  and
      Li, Xian  and
      Wang, Changhan  and
      Genzel, Dmitriy",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.328",
    doi = "10.18653/v1/2021.acl-long.328",
    pages = "4252--4261",
    abstract = "Pretraining and multitask learning are widely used to improve the speech translation performance. In this study, we are interested in training a speech translation model along with an auxiliary text translation task. We conduct a detailed analysis to understand the impact of the auxiliary task on the primary task within the multitask learning framework. Our analysis confirms that multitask learning tends to generate similar decoder representations from different modalities and preserve more information from the pretrained text translation modules. We observe minimal negative transfer effect between the two tasks and sharing more parameters is helpful to transfer knowledge from the text task to the speech task. The analysis also reveals that the modality representation difference at the top decoder layers is still not negligible, and those layers are critical for the translation quality. Inspired by these findings, we propose three methods to improve translation quality. First, a parameter sharing and initialization strategy is proposed to enhance information sharing between the tasks. Second, a novel attention-based regularization is proposed for the encoders and pulls the representations from different modalities closer. Third, an online knowledge distillation is proposed to enhance the knowledge transfer from the text to the speech task. Our experiments show that the proposed approach improves translation performance by more than 2 BLEU over a strong baseline and achieves state-of-the-art results on the MuST-C English-German, English-French and English-Spanish language pairs.",
}

@INPROCEEDINGS{9415058,
  author={Tang, Yun and Pino, Juan and Wang, Changhan and Ma, Xutai and Genzel, Dmitriy},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={A General Multi-Task Learning Framework to Leverage Text Data for Speech to Text Tasks}, 
  year={2021},
  volume={},
  number={},
  pages={6209-6213},
  doi={10.1109/ICASSP39728.2021.9415058},
  url={https://ieeexplore.ieee.org/iel7/9413349/9413350/09415058.pdf}}

@inproceedings{zaidi22_interspeech,
  author={Mohd Abbas Zaidi and Beomseok Lee and Sangha Kim and Chanwoo Kim},
  title={{Cross-Modal Decision Regularization for Simultaneous Speech Translation}},
  year=2022,
  booktitle={Proc. Interspeech 2022},
  pages={116--120},
  doi={10.21437/Interspeech.2022-10617},
  url={https://www.isca-speech.org/archive/interspeech_2022/zaidi22_interspeech.html}
}

@INPROCEEDINGS{9054250,
  author={Dong, Linhao and Xu, Bo},
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={CIF: Continuous Integrate-And-Fire for End-To-End Speech Recognition}, 
  year={2020},
  volume={},
  number={},
  pages={6079-6083},
  doi={10.1109/ICASSP40776.2020.9054250},
  url={https://ieeexplore.ieee.org/iel7/9040208/9052899/09054250.pdf}}


@inproceedings{ye-etal-2022-cross,
    title = "Cross-modal Contrastive Learning for Speech Translation",
    author = "Ye, Rong  and
      Wang, Mingxuan  and
      Li, Lei",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.376",
    doi = "10.18653/v1/2022.naacl-main.376",
    pages = "5099--5113",
    abstract = "How can we learn unified representations for spoken utterances and their written text? Learning similar representations for semantically similar speech and text is important for speech translation. To this end, we propose ConST, a cross-modal contrastive learning method for end-to-end speech-to-text translation. We evaluate ConST and a variety of previous baselines on a popular benchmark MuST-C. Experiments show that the proposed ConST consistently outperforms the previous methods, and achieves an average BLEU of 29.4. The analysis further verifies that ConST indeed closes the representation gap of different modalities {---} its learned representation improves the accuracy of cross-modal speech-text retrieval from 4{\%} to 88{\%}. Code and models are available at https://github.com/ReneeYe/ConST.",
}


@InProceedings{pmlr-v139-wu21e,
  title = 	 {Temporally Correlated Task Scheduling for Sequence Learning},
  author =       {Wu, Xueqing and Wang, Lewen and Xia, Yingce and Liu, Weiqing and Wu, Lijun and Xie, Shufang and Qin, Tao and Liu, Tie-Yan},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {11274--11284},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/wu21e/wu21e.pdf},
  url = 	 {https://proceedings.mlr.press/v139/wu21e.html},
  abstract = 	 {Sequence learning has attracted much research attention from the machine learning community in recent years. In many applications, a sequence learning task is usually associated with multiple temporally correlated auxiliary tasks, which are different in terms of how much input information to use or which future step to predict. For example, (i) in simultaneous machine translation, one can conduct translation under different latency (i.e., how many input words to read/wait before translation); (ii) in stock trend forecasting, one can predict the price of a stock in different future days (e.g., tomorrow, the day after tomorrow). While it is clear that those temporally correlated tasks can help each other, there is a very limited exploration on how to better leverage multiple auxiliary tasks to boost the performance of the main task. In this work, we introduce a learnable scheduler to sequence learning, which can adaptively select auxiliary tasks for training depending on the model status and the current training data. The scheduler and the model for the main task are jointly trained through bi-level optimization. Experiments show that our method significantly improves the performance of simultaneous machine translation and stock trend forecasting.}
}

@INPROCEEDINGS{8269008,
  author={Kamper, Herman and Livescu, Karen and Goldwater, Sharon},
  booktitle={2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)}, 
  title={An embedded segmental K-means model for unsupervised segmentation and clustering of speech}, 
  year={2017},
  volume={},
  number={},
  pages={719-726},
  doi={10.1109/ASRU.2017.8269008},
  url={https://www.kamperh.com/papers/kamper+livescu+goldwater_asru2017.pdf}}

@article{PITT200589,
title = {The Buckeye corpus of conversational speech: labeling conventions and a test of transcriber reliability},
journal = {Speech Communication},
volume = {45},
number = {1},
pages = {89-95},
year = {2005},
issn = {0167-6393},
doi = {https://doi.org/10.1016/j.specom.2004.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0167639304000974},
author = {Mark A. Pitt and Keith Johnson and Elizabeth Hume and Scott Kiesling and William Raymond},
keywords = {Spontaneous speech corpus, Transcription, Labeling, American English},
abstract = {This paper describes the Buckeye corpus of spontaneous American English speech, a 307,000-word corpus containing the speech of 40 talkers from central Ohio, USA. The method used to elicit and record the speech is described, followed by a description of the protocol that was developed to phonemically label what talkers said. The results of a test of labeling consistency are then presented. The corpus will be made available to the scientific community when labeling is completed.}
}

@article{KAMPER2017154,
title = {A segmental framework for fully-unsupervised large-vocabulary speech recognition},
journal = {Computer Speech \& Language},
volume = {46},
pages = {154-174},
year = {2017},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2017.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S0885230816301905},
author = {Herman Kamper and Aren Jansen and Sharon Goldwater},
keywords = {Unsupervised speech processing, Representation learning, Segmentation, Clustering, Language acquisition},
abstract = {Zero-resource speech technology is a growing research area that aims to develop methods for speech processing in the absence of transcriptions, lexicons, or language modelling text. Early term discovery systems focused on identifying isolated recurring patterns in a corpus, while more recent full-coverage systems attempt to completely segment and cluster the audio into word-like units—effectively performing unsupervised speech recognition. This article presents the first attempt we are aware of to apply such a system to large-vocabulary multi-speaker data. Our system uses a Bayesian modelling framework with segmental word representations: each word segment is represented as a fixed-dimensional acoustic embedding obtained by mapping the sequence of feature frames to a single embedding vector. We compare our system on English and Xitsonga datasets to state-of-the-art baselines, using a variety of measures including word error rate (obtained by mapping the unsupervised output to ground truth transcriptions). Very high word error rates are reported—in the order of 70–80\% for speaker-dependent and 80–95\% for speaker-independent systems—highlighting the difficulty of this task. Nevertheless, in terms of cluster quality and word segmentation metrics, we show that by imposing a consistent top-down segmentation while also using bottom-up knowledge from detected syllable boundaries, both single-speaker and multi-speaker versions of our system outperform a purely bottom-up single-speaker syllable-based approach. We also show that the discovered clusters can be made less speaker- and gender-specific by using an unsupervised autoencoder-like feature extractor to learn better frame-level features (prior to embedding). Our system’s discovered clusters are still less pure than those of unsupervised term discovery systems, but provide far greater coverage.}
}

@ARTICLE{2020arXiv201207551K,
       author = {{Kamper}, Herman and {van Niekerk}, Benjamin},
        title = "{Towards unsupervised phone and word segmentation using self-supervised vector-quantized neural networks}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computation and Language, Electrical Engineering and Systems Science - Audio and Speech Processing},
         year = 2020,
        month = dec,
          eid = {arXiv:2012.07551},
        pages = {arXiv:2012.07551},
archivePrefix = {arXiv},
       eprint = {2012.07551},
 primaryClass = {cs.CL},
       url = {https://ui.adsabs.harvard.edu/abs/2020arXiv201207551K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{9789954,
  author={Bhati, Saurabhchand and Villalba, Jesús and Żelasko, Piotr and Moro-Velazquez, Laureano and Dehak, Najim},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Unsupervised Speech Segmentation and Variable Rate Representation Learning Using Segmental Contrastive Predictive Coding}, 
  year={2022},
  volume={30},
  number={},
  pages={2002-2014},
  doi={10.1109/TASLP.2022.3180684}}

@article{fuchs2022unsupervised,
  title={Unsupervised Word Segmentation using K Nearest Neighbors},
  author={Fuchs, Tzeviya Sylvia and Hoshen, Yedid and Keshet, Joseph},
  journal={arXiv preprint arXiv:2204.13094},
  url = {https://arxiv.org/abs/2204.13094},
  year={2022}
}

@inproceedings{iranzo-sanchez-etal-2022-simultaneous,
    title = "From Simultaneous to Streaming Machine Translation by Leveraging Streaming History",
    author = "Iranzo Sanchez, Javier  and
      Civera, Jorge  and
      Juan-C{\'\i}scar, Alfons",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.480",
    doi = "10.18653/v1/2022.acl-long.480",
    pages = "6972--6985",
    abstract = "Simultaneous machine translation has recently gained traction thanks to significant quality improvements and the advent of streaming applications. Simultaneous translation systems need to find a trade-off between translation quality and response time, and with this purpose multiple latency measures have been proposed. However, latency evaluations for simultaneous translation are estimated at the sentence level, not taking into account the sequential nature of a streaming scenario. Indeed, these sentence-level latency measures are not well suited for continuous stream translation, resulting in figures that are not coherent with the simultaneous translation policy of the system being assessed. This work proposes a stream-level adaptation of the current latency measures based on a re-segmentation approach applied to the output translation, that is successfully evaluated on streaming conditions for a reference IWSLT task",
}

@inproceedings{e39d9b7accfd4615ae29143a55960b0e,
title = "An Improved Speech Segmentation Quality Measure: the R-value",
author = "Okko R{\"a}s{\"a}nen and Unto Laine and Toomas Altosaar",
year = "2009",
language = "English",
url="https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=91ff68c684116aeaa4de8b407fa79bbf1e05dc3c",
booktitle = "10th Interspeech Conference, Brighton, UK, September 6-10, 2009",
}

@InProceedings{10.1007/3-540-46154-X_38,
author="Demuynck, Kris
and Laureys, Tom",
editor="Sojka, Petr
and Kope{\v{c}}ek, Ivan
and Pala, Karel",
title="A Comparison of Different Approaches to Automatic Speech Segmentation",
booktitle="Text, Speech and Dialogue",
year="2002",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="277--284",
url="https://link.springer.com/chapter/10.1007/3-540-46154-X_38",
abstract="We compare different methods for obtaining accurate speech segmentations starting from the corresponding orthography. The complete segmentation process can be decomposed into two basic steps. First, a phonetic transcription is automatically produced with the help of large vocabulary continuous speech recognition (LVCSR). Then, the phonetic information and the speech signal serve as input to a speech segmentation tool. We compare two automatic approaches to segmentation, based on the Viterbi and the Forward-Backward algorithm respectively. Further, we develop different techniques to cope with biases between automatic and manual segmentations. Experiments were performed to evaluate the generation of phonetic transcriptions as well as the different speech segmentation methods.",
isbn="978-3-540-46154-8"
}

@article{sakran2017review,
  title={A review: Automatic speech segmentation},
  author={Sakran, Alaa Ehab and Abdou, Sherif Mahdy and Hamid, Salah Eldeen and Rashwan, Mohsen},
  journal={International Journal of Computer Science and Mobile Computing},
  volume={6},
  number={4},
  url={https://www.academia.edu/download/53039593/V6I4201790.pdf},
  pages={308--315},
  year={2017}
}

@INPROCEEDINGS{607750,
  author={Petek, B. and Andersen, O. and Dalsgaard, P.},
  booktitle={Proceeding of Fourth International Conference on Spoken Language Processing. ICSLP '96}, 
  title={On the robust automatic segmentation of spontaneous speech}, 
  year={1996},
  volume={2},
  number={},
  pages={913-916 vol.2},
  doi={10.1109/ICSLP.1996.607750}}

@article{YANG2020121,
title = {On the localness modeling for the self-attention based end-to-end speech synthesis},
journal = {Neural Networks},
volume = {125},
pages = {121-130},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.01.034},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020300447},
author = {Shan Yang and Heng Lu and Shiyin Kang and Liumeng Xue and Jinba Xiao and Dan Su and Lei Xie and Dong Yu},
keywords = {Speech synthesis, Self attention, Localness modeling, Relative-position-aware, Gaussian bias},
abstract = {Attention based end-to-end speech synthesis achieves better performance in both prosody and quality compared to the conventional “front-end”–“back-end” structure. But training such end-to-end framework is usually time-consuming because of the use of recurrent neural networks. To enable parallel calculation and long-range dependency modeling, a solely self-attention based framework named Transformer is proposed recently in the end-to-end family. However, it lacks position information in sequential modeling, so that the extra position representation is crucial to achieve good performance. Besides, the weighted sum form of self-attention is conducted over the whole input sequence when computing latent representation, which may disperse the attention to the whole input sequence other than focusing on the more important neighboring input states, resulting in generation errors. In this paper, we introduce two localness modeling methods to enhance the self-attention based representation for speech synthesis, which maintain the abilities of parallel computation and global-range dependency modeling in self-attention while improving the generation stability. We systematically analyze the solely self-attention based end-to-end speech synthesis framework, and unveil the importance of local context. Then we add the proposed relative-position-aware method to enhance local edges and experiment with different architectures to examine the effectiveness of localness modeling. In order to achieve query-specific window and discard the hyper-parameter of the relative-position-aware approach, we further conduct Gaussian-based bias to enhance localness. Experimental results indicate that the two proposed localness enhanced methods can both improve the performance of the self-attention model, especially when applied to the encoder part. And the query-specific window of Gaussian bias approach is more robust compared with the fixed relative edges.}
}

@article{liang2021transformer,
  title={Transformer-based end-to-end speech recognition with residual gaussian-based self-attention},
  author={Liang, Chengdong and Xu, Menglong and Zhang, Xiao-Lei},
  journal={arXiv preprint arXiv:2103.15722},
  url={https://ui.adsabs.harvard.edu/abs/2021arXiv210315722L/abstract},
  year={2021}
}

@inproceedings{vig-belinkov-2019-analyzing,
    title = "Analyzing the Structure of Attention in a Transformer Language Model",
    author = "Vig, Jesse  and
      Belinkov, Yonatan",
    booktitle = "Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-4808",
    doi = "10.18653/v1/W19-4808",
    pages = "63--76",
    abstract = "The Transformer is a fully attention-based alternative to recurrent networks that has achieved state-of-the-art results across a range of NLP tasks. In this paper, we analyze the structure of attention in a Transformer language model, the GPT-2 small pretrained model. We visualize attention for individual instances and analyze the interaction between attention and syntax over a large corpus. We find that attention targets different parts of speech at different layer depths within the model, and that attention aligns with dependency relations most strongly in the middle layers. We also find that the deepest layers of the model capture the most distant relationships. Finally, we extract exemplar sentences that reveal highly specific patterns targeted by particular attention heads.",
}

@inproceedings{valentini2021detection,
  title={Detection and analysis of attention errors in sequence-to-sequence text-to-speech},
  author={Valentini-Botinhao, Cassia and King, Simon},
  booktitle={Interspeech 2021: The 22nd Annual Conference of the International Speech Communication Association},
  pages={2746--2750},
  year={2021},
  url={https://www.research.ed.ac.uk/en/publications/detection-and-analysis-of-attention-errors-in-sequence-to-sequenc},
  organization={ISCA}
}

@inproceedings{ding-etal-2019-saliency,
    title = "Saliency-driven Word Alignment Interpretation for Neural Machine Translation",
    author = "Ding, Shuoyang  and
      Xu, Hainan  and
      Koehn, Philipp",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Papers)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-5201",
    doi = "10.18653/v1/W19-5201",
    pages = "1--12",
    abstract = "Despite their original goal to jointly learn to align and translate, Neural Machine Translation (NMT) models, especially Transformer, are often perceived as not learning interpretable word alignments. In this paper, we show that NMT models do learn interpretable word alignments, which could only be revealed with proper interpretation methods. We propose a series of such methods that are model-agnostic, are able to be applied either offline or online, and do not require parameter update or architectural change. We show that under the force decoding setup, the alignments induced by our interpretation method are of better quality than fast-align for some systems, and when performing free decoding, they agree well with the alignments induced by automatic alignment tools.",
}
@INPROCEEDINGS{9054148,
  author={Zheng, Yibin and Li, Xinhui and Xie, Fenglong and Lu, Li},
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Improving End-to-End Speech Synthesis with Local Recurrent Neural Network Enhanced Transformer}, 
  year={2020},
  volume={},
  number={},
  pages={6734-6738},
  doi={10.1109/ICASSP40776.2020.9054148}}


@inproceedings{popovic-2017-chrf,
    title = "chr{F}++: words helping character n-grams",
    author = "Popovi{\'c}, Maja",
    booktitle = "Proceedings of the Second Conference on Machine Translation",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W17-4770",
    doi = "10.18653/v1/W17-4770",
    pages = "612--618",
}

@inproceedings{popovic-2015-chrf,
    title = "chr{F}: character n-gram {F}-score for automatic {MT} evaluation",
    author = "Popovi{\'c}, Maja",
    booktitle = "Proceedings of the Tenth Workshop on Statistical Machine Translation",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W15-3049",
    doi = "10.18653/v1/W15-3049",
    pages = "392--395",
}

@inproceedings{snover-etal-2006-ter,
    title = "A Study of Translation Edit Rate with Targeted Human Annotation",
    author = "Snover, Matthew  and
      Dorr, Bonnie  and
      Schwartz, Rich  and
      Micciulla, Linnea  and
      Makhoul, John",
    booktitle = "Proceedings of the 7th Conference of the Association for Machine Translation in the Americas: Technical Papers",
    month = aug # " 8-12",
    year = "2006",
    address = "Cambridge, Massachusetts, USA",
    publisher = "Association for Machine Translation in the Americas",
    url = "https://aclanthology.org/2006.amta-papers.25",
    pages = "223--231",
    abstract = "We examine a new, intuitive measure for evaluating machine-translation output that avoids the knowledge intensiveness of more meaning-based approaches, and the labor-intensiveness of human judgments. Translation Edit Rate (TER) measures the amount of editing that a human would have to perform to change a system output so it exactly matches a reference translation. We show that the single-reference variant of TER correlates as well with human judgments of MT quality as the four-reference variant of BLEU. We also define a human-targeted TER (or HTER) and show that it yields higher correlations with human judgments than BLEU{---}even when BLEU is given human-targeted references. Our results indicate that HTER correlates with human judgments better than HMETEOR and that the four-reference variants of TER and HTER correlate with human judgments as well as{---}or better than{---}a second human judgment does.",
}

@InProceedings{Wang_2021_CVPR,
    author    = {Wang, Feng and Liu, Huaping},
    title     = {Understanding the Behaviour of Contrastive Loss},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2021},
    url={https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Understanding_the_Behaviour_of_Contrastive_Loss_CVPR_2021_paper.pdf},
    pages     = {2495-2504}
}

@article{liu2020bridging,
  title={Bridging the modality gap for speech-to-text translation},
  author={Liu, Yuchen and Zhu, Junnan and Zhang, Jiajun and Zong, Chengqing},
  journal={arXiv preprint arXiv:2010.14920},
  url={https://arxiv.org/abs/2010.14920},
  year={2020}
}

@InProceedings{10.1007/978-3-030-60276-5_27,
author="K{\"u}rzinger, Ludwig
and Winkelbauer, Dominik
and Li, Lujun
and Watzel, Tobias
and Rigoll, Gerhard",
editor="Karpov, Alexey
and Potapova, Rodmonga",
title="CTC-Segmentation of Large Corpora for German End-to-End Speech Recognition",
url="https://link.springer.com/chapter/10.1007/978-3-030-60276-5_27",
booktitle="Speech and Computer",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="267--278",
abstract="Recent end-to-end Automatic Speech Recognition (ASR) systems demonstrated the ability to outperform conventional hybrid DNN/HMM ASR. Aside from architectural improvements in those systems, those models grew in terms of depth, parameters and model capacity. However, these models also require more training data to achieve comparable performance.",
isbn="978-3-030-60276-5"
}

@inproceedings{
nguyen2020investigating,
title={Investigating Self-supervised Pre-training for End-to-end Speech Translation},
author={Ha Nguyen and Fethi Bougares and Natalia Tomashenko and Yannick Est{\`e}ve and laurent besacier},
booktitle={ICML 2020 Workshop on Self-supervision in Audio and Speech},
year={2020},
url={https://openreview.net/forum?id=SR2L__h9q9p}
}

@ARTICLE{9226466,
  author={Le-Khac, Phuc H. and Healy, Graham and Smeaton, Alan F.},
  journal={IEEE Access}, 
  title={Contrastive Representation Learning: A Framework and Review}, 
  year={2020},
  volume={8},
  number={},
  pages={193907-193934},
  doi={10.1109/ACCESS.2020.3031549}}


@inproceedings{yarmohammadi-etal-2013-incremental,
    title = "Incremental Segmentation and Decoding Strategies for Simultaneous Translation",
    author = "Yarmohammadi, Mahsa  and
      Rangarajan Sridhar, Vivek Kumar  and
      Bangalore, Srinivas  and
      Sankaran, Baskaran",
    booktitle = "Proceedings of the Sixth International Joint Conference on Natural Language Processing",
    month = oct,
    year = "2013",
    address = "Nagoya, Japan",
    publisher = "Asian Federation of Natural Language Processing",
    url = "https://aclanthology.org/I13-1141",
    pages = "1032--1036",
}

@article{10.2307/30219116,
 ISSN = {09226567, 15730573},
 abstract = {With increasing globalization, communication across language and cultural boundaries is becoming an essential requirement of doing business, delivering education, and providing public services. Due to the considerable cost of human translation services, only a small fraction of text documents and an even smaller percentage of spoken encounters, such as international meetings and conferences, are translated, with most resorting to the use of a common language (e.g. English) or not taking place at all. Technology may provide a potentially revolutionary way out if real-time, domain-independent, simultaneous speech translation can be realized. In this paper, we present a simultaneous speech translation system based on statistical recognition and translation technology. We discuss the technology, various system improvements and propose mechanisms for user-friendly delivery of the result. Over extensive component and end-to-end system evaluations and comparisons with human translation performance, we conclude that machines can already deliver comprehensible simultaneous translation output. Moreover, while machine performance is affected by recognition errors (and thus can be improved), human performance is limited by the cognitive challenge of performing the task in real time.},
 author = {Christian Fügen and Alex Waibel and Muntsin Kolss},
 journal = {Machine Translation},
 number = {4},
 pages = {209--252},
 publisher = {Springer},
 title = {Simultaneous Translation of Lectures and Speeches},
 urldate = {2023-01-20},
 volume = {21},
 url={https://link.springer.com/article/10.1007/s10590-008-9047-0},
 year = {2007}
}

@inproceedings{rangarajan-sridhar-etal-2013-segmentation,
    title = "Segmentation Strategies for Streaming Speech Translation",
    author = "Rangarajan Sridhar, Vivek Kumar  and
      Chen, John  and
      Bangalore, Srinivas  and
      Ljolje, Andrej  and
      Chengalvarayan, Rathinavelu",
    booktitle = "Proceedings of the 2013 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2013",
    address = "Atlanta, Georgia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N13-1023",
    pages = "230--238",
}

@inproceedings{oda-etal-2014-optimizing,
    title = "Optimizing Segmentation Strategies for Simultaneous Speech Translation",
    author = "Oda, Yusuke  and
      Neubig, Graham  and
      Sakti, Sakriani  and
      Toda, Tomoki  and
      Nakamura, Satoshi",
    booktitle = "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jun,
    year = "2014",
    address = "Baltimore, Maryland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P14-2090",
    doi = "10.3115/v1/P14-2090",
    pages = "551--556",
}

@inproceedings{hamon-etal-2009-end,
    title = "End-to-End Evaluation in Simultaneous Translation",
    author = {Hamon, Olivier  and
      F{\"u}gen, Christian  and
      Mostefa, Djamel  and
      Arranz, Victoria  and
      Kolss, Muntsin  and
      Waibel, Alex  and
      Choukri, Khalid},
    booktitle = "Proceedings of the 12th Conference of the {E}uropean Chapter of the {ACL} ({EACL} 2009)",
    month = mar,
    year = "2009",
    address = "Athens, Greece",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/E09-1040",
    pages = "345--353",
}

@article{yeh2019transformer,
  title={Transformer-transducer: End-to-end speech recognition with self-attention},
  author={Yeh, Ching-Feng and Mahadeokar, Jay and Kalgaonkar, Kaustubh and Wang, Yongqiang and Le, Duc and Jain, Mahaveer and Schubert, Kjell and Fuegen, Christian and Seltzer, Michael L},
  journal={arXiv preprint arXiv:1910.12977},
  year={2019},
  url={https://arxiv.org/abs/1910.12977}
}

@article{graves2012sequence,
  title={Sequence transduction with recurrent neural networks},
  author={Graves, Alex},
  journal={arXiv preprint arXiv:1211.3711},
  year={2012},
  url={https://arxiv.org/abs/1211.3711}
}

@inproceedings{Sainath2020,
  author={Tara N. Sainath and Ruoming Pang and David Rybach and Basi García and Trevor Strohman},
  title={{Emitting Word Timings with End-to-End Models}},
  year=2020,
  booktitle={Proc. Interspeech 2020},
  pages={3615--3619},
  doi={10.21437/Interspeech.2020-1059},
  url={http://dx.doi.org/10.21437/Interspeech.2020-1059}
}

@inproceedings{yu2021fastemit,
  title={Fastemit: Low-latency streaming asr with sequence-level emission regularization},
  author={Yu, Jiahui and Chiu, Chung-Cheng and Li, Bo and Chang, Shuo-yiin and Sainath, Tara N and He, Yanzhang and Narayanan, Arun and Han, Wei and Gulati, Anmol and Wu, Yonghui and others},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6004--6008},
  year={2021},
  organization={IEEE},
  url={https://ieeexplore.ieee.org/abstract/document/9413803/}
}

@inproceedings{kim21j_interspeech,
  author={Jaeyoung Kim and Han Lu and Anshuman Tripathi and Qian Zhang and Hasim Sak},
  title={{Reducing Streaming ASR Model Delay with Self Alignment}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={3440--3444},
  doi={10.21437/Interspeech.2021-322},
  url={https://www.isca-speech.org/archive/pdfs/interspeech_2021/kim21j_interspeech.pdf}
}

@inproceedings{
chiu*2018monotonic,
title={Monotonic Chunkwise Attention},
author={Chung-Cheng Chiu* and Colin Raffel*},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=Hko85plCW},
}
@INPROCEEDINGS{9054098,
  author={Inaguma, Hirofumi and Gaur, Yashesh and Lu, Liang and Li, Jinyu and Gong, Yifan},
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Minimum Latency Training Strategies for Streaming Sequence-to-Sequence ASR}, 
  year={2020},
  volume={},
  number={},
  pages={6064-6068},
  doi={10.1109/ICASSP40776.2020.9054098},
  url={https://ieeexplore.ieee.org/abstract/document/9054098/}}

@ARTICLE{9640576,
  author={Inaguma, Hirofumi and Kawahara, Tatsuya},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Alignment Knowledge Distillation for Online Streaming Attention-Based Speech Recognition}, 
  year={2023},
  volume={31},
  number={},
  pages={1371-1385},
  doi={10.1109/TASLP.2021.3133217},
  url={https://ieeexplore.ieee.org/abstract/document/9640576/}
  
  }


@INPROCEEDINGS{9413899,
  author={Li, Bo and Gulati, Anmol and Yu, Jiahui and Sainath, Tara N. and Chiu, Chung-Cheng and Narayanan, Arun and Chang, Shuo-Yiin and Pang, Ruoming and He, Yanzhang and Qin, James and Han, Wei and Liang, Qiao and Zhang, Yu and Strohman, Trevor and Wu, Yonghui},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={A Better and Faster end-to-end Model for Streaming ASR}, 
  year={2021},
  volume={},
  number={},
  pages={5634-5638},
  doi={10.1109/ICASSP39728.2021.9413899},
  url={https://ieeexplore.ieee.org/iel7/9413349/9413350/09413899.pdf}
  }


@INPROCEEDINGS{9054715,
  author={Li, Bo and Chang, Shuo-yiin and Sainath, Tara N. and Pang, Ruoming and He, Yanzhang and Strohman, Trevor and Wu, Yonghui},
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Towards Fast and Accurate Streaming End-To-End ASR}, 
  year={2020},
  volume={},
  number={},
  pages={6069-6073},
  doi={10.1109/ICASSP40776.2020.9054715}}

@inproceedings{Inaguma2020,
  author={Hirofumi Inaguma and Masato Mimura and Tatsuya Kawahara},
  title={{Enhancing Monotonic Multihead Attention for Streaming ASR}},
  year=2020,
  booktitle={Proc. Interspeech 2020},
  pages={2137--2141},
  doi={10.21437/Interspeech.2020-1780},
  url={http://dx.doi.org/10.21437/Interspeech.2020-1780}
}
@INPROCEEDINGS{9054476,
  author={Moritz, Niko and Hori, Takaaki and Le, Jonathan},
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Streaming Automatic Speech Recognition with the Transformer Model}, 
  year={2020},
  volume={},
  number={},
  pages={6074-6078},
  doi={10.1109/ICASSP40776.2020.9054476},
  url={https://ieeexplore.ieee.org/document/9054476}
  
  }

@inproceedings{
yu2021dualmode,
title={Dual-mode {\{}ASR{\}}: Unify and Improve Streaming {\{}ASR{\}} with Full-context Modeling},
author={Jiahui Yu and Wei Han and Anmol Gulati and Chung-Cheng Chiu and Bo Li and Tara N Sainath and Yonghui Wu and Ruoming Pang},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=Pz_dcqfcKW8}
}

@inproceedings{chan16c_interspeech,
  author={William Chan and Ian Lane},
  title={{On Online Attention-Based Speech Recognition and Joint Mandarin Character-Pinyin Training}},
  year=2016,
  booktitle={Proc. Interspeech 2016},
  pages={3404--3408},
  doi={10.21437/Interspeech.2016-334},
  url={https://www.isca-speech.org/archive/interspeech_2016/chan16c_interspeech.html}
}

@inproceedings{Hou2017,
  author={Junfeng Hou and Shiliang Zhang and Li-Rong Dai},
  title={Gaussian Prediction Based Attention for Online End-to-End Speech Recognition},
  year=2017,
  booktitle={Proc. Interspeech 2017},
  pages={3692--3696},
  doi={10.21437/Interspeech.2017-751},
  url={http://dx.doi.org/10.21437/Interspeech.2017-751}
}

@misc{jaitly2016neural,
      title={A Neural Transducer}, 
      author={Navdeep Jaitly and David Sussillo and Quoc V. Le and Oriol Vinyals and Ilya Sutskever and Samy Bengio},
      year={2016},
      eprint={1511.04868},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1511.04868}
}

@ARTICLE{2017arXiv170605098R,
       author = {{Ruder}, Sebastian},
        title = "{An Overview of Multi-Task Learning in Deep Neural Networks}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning},
         year = 2017,
        month = jun,
          eid = {arXiv:1706.05098},
        pages = {arXiv:1706.05098},
          doi = {10.48550/arXiv.1706.05098},
archivePrefix = {arXiv},
       eprint = {1706.05098},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv170605098R},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{10.1093/nsr/nwx105,
    author = {Zhang, Yu and Yang, Qiang},
    title = "{An overview of multi-task learning}",
    journal = {National Science Review},
    volume = {5},
    number = {1},
    pages = {30-43},
    year = {2017},
    month = {09},
    abstract = "{As a promising area in machine learning, multi-task learning (MTL) aims to improve the performance of multiple related learning tasks by leveraging useful information among them. In this paper, we give an overview of MTL by first giving a definition of MTL. Then several different settings of MTL are introduced, including multi-task supervised learning, multi-task unsupervised learning, multi-task semi-supervised learning, multi-task active learning, multi-task reinforcement learning, multi-task online learning and multi-task multi-view learning. For each setting, representative MTL models are presented. In order to speed up the learning process, parallel and distributed MTL models are introduced. Many areas, including computer vision, bioinformatics, health informatics, speech, natural language processing, web applications and ubiquitous computing, use MTL to improve the performance of the applications involved and some representative works are reviewed. Finally, recent theoretical analyses for MTL are presented.}",
    issn = {2095-5138},
    doi = {10.1093/nsr/nwx105},
    url = {https://doi.org/10.1093/nsr/nwx105},
    eprint = {https://academic.oup.com/nsr/article-pdf/5/1/30/31567358/nwx105.pdf},
}

@inproceedings{NIPS2014_a14ac55a,
 author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Sequence to Sequence Learning with Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf},
 volume = {27},
 year = {2014}
}

@inproceedings{guo-etal-2023-learning,
    title = "Learning Optimal Policy for Simultaneous Machine Translation via Binary Search",
    author = "Guo, Shoutao  and
      Zhang, Shaolei  and
      Feng, Yang",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.130",
    doi = "10.18653/v1/2023.acl-long.130",
    pages = "2318--2333",
    abstract = "Simultaneous machine translation (SiMT) starts to output translation while reading the source sentence and needs a precise policy to decide when to output the generated translation. Therefore, the policy determines the number of source tokens read during the translation of each target token. However, it is difficult to learn a precise translation policy to achieve good latency-quality trade-offs, because there is no golden policy corresponding to parallel sentences as explicit supervision. In this paper, we present a new method for constructing the optimal policy online via binary search. By employing explicit supervision, our approach enables the SiMT model to learn the optimal policy, which can guide the model in completing the translation during inference. Experiments on four translation tasks show that our method can exceed strong baselines across all latency scenarios.",
}

@inproceedings{zhang-feng-2023-end,
    title = "End-to-End Simultaneous Speech Translation with Differentiable Segmentation",
    author = "Zhang, Shaolei  and
      Feng, Yang",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.485",
    doi = "10.18653/v1/2023.findings-acl.485",
    pages = "7659--7680",
    abstract = "End-to-end simultaneous speech translation (SimulST) outputs translation while receiving the streaming speech inputs (a.k.a. streaming speech translation), and hence needs to segment the speech inputs and then translate based on the current received speech. However, segmenting the speech inputs at unfavorable moments can disrupt the acoustic integrity and adversely affect the performance of the translation model. Therefore, learning to segment the speech inputs at those moments that are beneficial for the translation model to produce high-quality translation is the key to SimulST. Existing SimulST methods, either using the fixed-length segmentation or external segmentation model, always separate segmentation from the underlying translation model, where the gap results in segmentation outcomes that are not necessarily beneficial for the translation process. In this paper, we propose Differentiable Segmentation (DiSeg) for SimulST to directly learn segmentation from the underlying translation model. DiSeg turns hard segmentation into differentiable through the proposed expectation training, enabling it to be jointly trained with the translation model and thereby learn translation-beneficial segmentation. Experimental results demonstrate that DiSeg achieves state-of-the-art performance and exhibits superior segmentation capability.",
}

@inproceedings{fang-etal-2022-stemm,
    title = "{STEMM}: Self-learning with Speech-text Manifold Mixup for Speech Translation",
    author = "Fang, Qingkai  and
      Ye, Rong  and
      Li, Lei  and
      Feng, Yang  and
      Wang, Mingxuan",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.486",
    doi = "10.18653/v1/2022.acl-long.486",
    pages = "7050--7062",
    abstract = "How to learn a better speech representation for end-to-end speech-to-text translation (ST) with limited labeled data? Existing techniques often attempt to transfer powerful machine translation (MT) capabilities to ST, but neglect the representation discrepancy across modalities. In this paper, we propose the Speech-TExt Manifold Mixup (STEMM) method to calibrate such discrepancy. Specifically, we mix up the representation sequences of different modalities, and take both unimodal speech sequences and multimodal mixed sequences as input to the translation model in parallel, and regularize their output predictions with a self-learning framework. Experiments on MuST-C speech translation benchmark and further analysis show that our method effectively alleviates the cross-modal representation discrepancy, and achieves significant improvements over a strong baseline on eight translation directions.",
}

@inproceedings{fang-feng-2023-understanding,
    title = "Understanding and Bridging the Modality Gap for Speech Translation",
    author = "Fang, Qingkai  and
      Feng, Yang",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.884",
    doi = "10.18653/v1/2023.acl-long.884",
    pages = "15864--15881",
    abstract = "How to achieve better end-to-end speech translation (ST) by leveraging (text) machine translation (MT) data? Among various existing techniques, multi-task learning is one of the effective ways to share knowledge between ST and MT in which additional MT data can help to learn source-to-target mapping. However, due to the differences between speech and text, there is always a gap between ST and MT. In this paper, we first aim to understand this modality gap from the target-side representation differences, and link the modality gap to another well-known problem in neural machine translation: exposure bias. We find that the modality gap is relatively small during training except for some difficult cases, but keeps increasing during inference due to the cascading effect. To address these problems, we propose the Cross-modal Regularization with Scheduled Sampling (Cress) method. Specifically, we regularize the output predictions of ST and MT, whose target-side contexts are derived by sampling between ground truth words and self-generated words with a varying probability. Furthermore, we introduce token-level adaptive training which assigns different training weights to target tokens to handle difficult cases with large modality gaps. Experiments and analysis show that our approach effectively bridges the modality gap, and achieves significant improvements over a strong baseline in all eight directions of the MuST-C dataset.",
}
@inproceedings{zhou-etal-2023-cmot,
    title = "{CMOT}: Cross-modal Mixup via Optimal Transport for Speech Translation",
    author = "Zhou, Yan  and
      Fang, Qingkai  and
      Feng, Yang",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.acl-long.436",
    doi = "10.18653/v1/2023.acl-long.436",
    pages = "7873--7887",
    abstract = "End-to-end speech translation (ST) is the task of translating speech signals in the source language into text in the target language. As a cross-modal task, end-to-end ST is difficult to train with limited data. Existing methods often try to transfer knowledge from machine translation (MT), but their performances are restricted by the modality gap between speech and text. In this paper, we propose Cross-modal Mixup via Optimal Transport (CMOT) to overcome the modality gap. We find the alignment between speech and text sequences via optimal transport and then mix up the sequences from different modalities at a token level using the alignment. Experiments on the MuST-C ST benchmark demonstrate that CMOT achieves an average BLEU of 30.0 in 8 translation directions, outperforming previous methods. Further analysis shows CMOT can adaptively find the alignment between modalities, which helps alleviate the modality gap between speech and text.",
}

@inproceedings{tailor,
    title = "Simultaneous Machine Translation with Tailored Reference",
    author = "Guo, Shoutao and
    Zhang, Shaolei  and
      Feng, Yang",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    publisher = "Association for Computational Linguistics",
    url={https://arxiv.org/abs/2310.13588}
}
@misc{guo2023glancing,
      title={Glancing Future for Simultaneous Machine Translation}, 
      author={Shoutao Guo and Shaolei Zhang and Yang Feng},
      year={2023},
      eprint={2309.06179},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.06179}
}
@misc{ma2023nonautoregressive,
      title={Non-autoregressive Streaming Transformer for Simultaneous Translation}, 
      author={Zhengrui Ma and Shaolei Zhang and Shoutao Guo and Chenze Shao and Min Zhang and Yang Feng},
      year={2023},
      eprint={2310.14883},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
    url={https://arxiv.org/abs/2310.14883},
}
@misc{zhang2023bayling,
      title={BayLing: Bridging Cross-lingual Alignment and Instruction Following through Interactive Translation for Large Language Models}, 
      author={Shaolei Zhang and Qingkai Fang and Zhuocheng Zhang and Zhengrui Ma and Yan Zhou and Langlin Huang and Mengyu Bu and Shangtong Gui and Yunji Chen and Xilin Chen and Yang Feng},
      year={2023},
      eprint={2306.10968},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
    url={https://arxiv.org/abs/2306.10968},
}