@inproceedings{joulin2017efficient,
  title={Efficient softmax approximation for gpus},
  author={Joulin, Armand and Ciss{\'e}, Moustapha and Grangier, David and J{\'e}gou, Herv{\'e} and others},
  booktitle={International conference on machine learning},
  pages={1302--1310},
  year={2017},
  organization={PMLR}
}
@article{Wang2022EfficientCK,
  title={Efficient Cluster-Based k-Nearest-Neighbor Machine Translation},
  author={Dexin Wang and Kai Fan and Boxing Chen and Deyi Xiong},
  journal={ArXiv},
  year={2022},
  volume={abs/2204.06175}
}
@article{stahlberg2019nmt,
  title={On nmt search errors and model errors: Cat got your tongue?},
  author={Stahlberg, Felix and Byrne, Bill},
  journal={arXiv preprint arXiv:1908.10090},
  year={2019}
}

@article{meister2020best,
  title={Best-first beam search},
  author={Meister, Clara and Vieira, Tim and Cotterell, Ryan},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={795--809},
  year={2020},
  publisher={MIT Press}
}

@article{ney1994structuring,
  title={On structuring probabilistic dependences in stochastic language modelling},
  author={Ney, Hermann and Essen, Ute and Kneser, Reinhard},
  journal={Computer Speech \& Language},
  volume={8},
  number={1},
  pages={1--38},
  year={1994},
  publisher={Elsevier}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}
@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@article{meister2020generalized,
  title={Generalized Entropy Regularization or: There's Nothing Special about Label Smoothing},
  author={Meister, Clara and Salesky, Elizabeth and Cotterell, Ryan},
  journal={arXiv preprint arXiv:2005.00820},
  year={2020}
}

@article{pereyra2017regularizing,
  title={Regularizing neural networks by penalizing confident output distributions},
  author={Pereyra, Gabriel and Tucker, George and Chorowski, Jan and Kaiser, {\L}ukasz and Hinton, Geoffrey},
  journal={arXiv preprint arXiv:1701.06548},
  year={2017}
}

@inproceedings{szegedy2016rethinking,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2818--2826},
  year={2016}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff and others},
  journal={arXiv preprint arXiv:1503.02531},
  volume={2},
  number={7},
  year={2015}
}

@article{holtzman2019curious,
  title={The curious case of neural text degeneration},
  author={Holtzman, Ari and Buys, Jan and Du, Li and Forbes, Maxwell and Choi, Yejin},
  journal={arXiv preprint arXiv:1904.09751},
  year={2019}
}

@article{johnson2019billion,
  title={Billion-scale similarity search with {GPUs}},
  author={Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  journal={IEEE Transactions on Big Data},
  volume={7},
  number={3},
  pages={535--547},
  year={2019},
  publisher={IEEE}
}


@inproceedings{yang2022nearest,
    title = "Nearest Neighbor Knowledge Distillation for Neural Machine Translation",
    author = "Yang, Zhixian  and
      Sun, Renliang  and
      Wan, Xiaojun",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.406",
    doi = "10.18653/v1/2022.naacl-main.406",
    pages = "5546--5556",
    abstract = "k-nearest-neighbor machine translation ($k$NN-MT), proposed by Khandelwal et al. (2021), has achieved many state-of-the-art results in machine translation tasks. Although effective, $k$NN-MT requires conducting $k$NN searches through the large datastore for each decoding step during inference, prohibitively increasing the decoding cost and thus leading to the difficulty for the deployment in real-world applications. In this paper, we propose to move the time-consuming $k$NN search forward to the preprocessing phase, and then introduce $k$ Nearest Neighbor Knowledge Distillation ($k$NN-KD) that trains the base NMT model to directly learn the knowledge of $k$NN. Distilling knowledge retrieved by $k$NN can encourage the NMT model to take more reasonable target tokens into consideration, thus addressing the overcorrection problem. Extensive experimental results show that, the proposed method achieves consistent improvement over the state-of-the-art baselines including $k$NN-MT, while maintaining the same training and decoding speed as the standard NMT model.",
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@article{wang2022training,
  title={Training Data is More Valuable than You Think: A Simple and Effective Method by Retrieving from Training Data},
  author={Wang, Shuohang and Xu, Yichong and Fang, Yuwei and Liu, Yang and Sun, Siqi and Xu, Ruochen and Zhu, Chenguang and Zeng, Michael},
  journal={arXiv preprint arXiv:2203.08773},
  year={2022}
}

@article{clauset2009power,
  title={Power-law distributions in empirical data},
  author={Clauset, Aaron and Shalizi, Cosma Rohilla and Newman, Mark EJ},
  journal={SIAM review},
  volume={51},
  number={4},
  pages={661--703},
  year={2009},
  publisher={SIAM}
}

@article{yang2017breaking,
  title={Breaking the softmax bottleneck: A high-rank RNN language model},
  author={Yang, Zhilin and Dai, Zihang and Salakhutdinov, Ruslan and Cohen, William W},
  journal={arXiv preprint arXiv:1711.03953},
  year={2017}
}


@article{sennrich2015neural,
  title={Neural machine translation of rare words with subword units},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  journal={arXiv preprint arXiv:1508.07909},
  year={2015}
}

@article{alon2022neuro,
  title={Neuro-Symbolic Language Modeling with Automaton-augmented Retrieval},
  author={Alon, Uri and Xu, Frank F and He, Junxian and Sengupta, Sudipta and Roth, Dan and Neubig, Graham},
  journal={arXiv preprint arXiv:2201.12431},
  year={2022}
}

@article{he2021efficient,
  title={Efficient nearest neighbor language models},
  author={He, Junxian and Neubig, Graham and Berg-Kirkpatrick, Taylor},
  journal={arXiv preprint arXiv:2109.04212},
  year={2021}
}

@inproceedings{khandelwal20generalization,
  title={{Generalization through Memorization: Nearest Neighbor Language Models}},
  author={Khandelwal, Urvashi and Levy, Omer and Jurafsky, Dan and Zettlemoyer, Luke and Lewis, Mike},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020}
}


@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@inproceedings{carlini2020extracting,
            title={Extracting Training Data from Large Language Models},
            author={Nicholas Carlini and Florian Tram\`er and Eric Wallace and Matthew Jagielski 
             and Ariel Herbert-Voss and Katherine Lee and Adam Roberts and Tom Brown
             and Dawn Song and \'Ulfar Erlingsson and Alina Oprea and Colin Raffel},
            booktitle={USENIX Security Symposium},
            year={2021}}


@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Ponde, Henrique and Kaplan, Jared and Edwards, Harri and Burda, Yura and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{allamanis2018survey,
  title={A survey of machine learning for big code and naturalness},
  author={Allamanis, Miltiadis and Barr, Earl T and Devanbu, Premkumar and Sutton, Charles},
  journal={ACM Computing Surveys (CSUR)},
  volume={51},
  number={4},
  pages={1--37},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@article{li2021pretrained,
  title={Pretrained Language Models for Text Generation: A Survey},
  author={Li, Junyi and Tang, Tianyi and Zhao, Wayne Xin and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2105.10311},
  year={2021}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@inproceedings{hayashi2020latent,
  title={Latent relation language models},
  author={Hayashi, Hiroaki and Hu, Zecong and Xiong, Chenyan and Neubig, Graham},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  pages={7911--7918},
  year={2020}
}
@article{wood2011sequence,
  title={The sequence memoizer},
  author={Wood, Frank and Gasthaus, Jan and Archambeau, C{\'e}dric and James, Lancelot and Teh, Yee Whye},
  journal={Communications of the ACM},
  volume={54},
  number={2},
  pages={91--98},
  year={2011},
  publisher={ACM New York, NY, USA}
}

@inproceedings{shareghi2017compressed,
  title={Compressed Nonparametric Language Modelling.},
  author={Shareghi, Ehsan and Haffari, Gholamreza and Cohn, Trevor},
  booktitle={IJCAI},
  pages={2701--2707},
  year={2017}
}

@article{wallace2019universal,
  title={Universal adversarial triggers for attacking and analyzing NLP},
  author={Wallace, Eric and Feng, Shi and Kandpal, Nikhil and Gardner, Matt and Singh, Sameer},
  journal={arXiv preprint arXiv:1908.07125},
  year={2019}
}

@article{strubell2019energy,
  title={Energy and policy considerations for deep learning in NLP},
  author={Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
  journal={arXiv preprint arXiv:1906.02243},
  year={2019}
}

@inproceedings{wang2016larger,
  title={Larger-Context Language Modelling with Recurrent Neural Network},
  author={Wang, Tian and Cho, Kyunghyun},
  booktitle={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={1319--1329},
  year={2016}
}

@inproceedings{mikolov2012context,
  title={Context dependent recurrent neural network language model},
  author={Mikolov, Tomas and Zweig, Geoffrey},
  booktitle={2012 IEEE Spoken Language Technology Workshop (SLT)},
  pages={234--239},
  year={2012},
  organization={IEEE}
}


@article{khudanpur2000maximum,
  title={Maximum entropy techniques for exploiting syntactic, semantic and collocational dependencies in language modeling},
  author={Khudanpur, Sanjeev and Wu, Jun},
  journal={Computer Speech \& Language},
  volume={14},
  number={4},
  pages={355--372},
  year={2000},
  publisher={Elsevier}
}

@article{khandelwal2018sharp,
  title={Sharp nearby, fuzzy far away: How neural language models use context},
  author={Khandelwal, Urvashi and He, He and Qi, Peng and Jurafsky, Dan},
  journal={arXiv preprint arXiv:1805.04623},
  year={2018}
}

@inproceedings{britz2017effective,
  title={Effective domain mixing for neural machine translation},
  author={Britz, Denny and Le, Quoc and Pryzant, Reid},
  booktitle={Proceedings of the Second Conference on Machine Translation},
  pages={118--126},
  year={2017}
}

@inproceedings{sennrich2016controlling,
  title={Controlling politeness in neural machine translation via side constraints},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  booktitle={Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={35--40},
  year={2016}
}

@inproceedings{chu2017empirical,
  title={An empirical comparison of domain adaptation methods for neural machine translation},
  author={Chu, Chenhui and Dabre, Raj and Kurohashi, Sadao},
  booktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  pages={385--391},
  year={2017}
}

@article{grave2016improving,
  title={Improving neural language models with a continuous cache},
  author={Grave, Edouard and Joulin, Armand and Usunier, Nicolas},
  journal={arXiv preprint arXiv:1612.04426},
  year={2016}
}

@article{grave2017unbounded,
  title={Unbounded cache model for online language modeling with open vocabulary},
  author={Grave, Edouard and Ciss{\'e}, Moustapha and Joulin, Armand},
  journal={arXiv preprint arXiv:1711.02604},
  year={2017}
}

@article{hindle2016naturalness,
  title={On the naturalness of software},
  author={Hindle, Abram and Barr, Earl T and Gabel, Mark and Su, Zhendong and Devanbu, Premkumar},
  journal={Communications of the ACM},
  volume={59},
  number={5},
  pages={122--131},
  year={2016},
  publisher={ACM New York, NY, USA}
}

@article{raffel2019exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={arXiv preprint arXiv:1910.10683},
  year={2019}
}

@article{he2020learning,
  title={Learning Sparse Prototypes for Text Generation},
  author={He, Junxian and Berg-Kirkpatrick, Taylor and Neubig, Graham},
  journal={arXiv preprint arXiv:2006.16336},
  year={2020}
}

@inproceedings{hellendoorn2017deep,
  title={Are deep neural networks the best choice for modeling source code?},
  author={Hellendoorn, Vincent J and Devanbu, Premkumar},
  booktitle={Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
  pages={763--773},
  year={2017}
}

@inproceedings{alon2020structural,
  title={Structural language models of code},
  author={Alon, Uri and Sadaka, Roy and Levy, Omer and Yahav, Eran},
  booktitle={International Conference on Machine Learning},
  pages={245--256},
  year={2020},
  organization={PMLR}
}

@inproceedings{raychev2014code,
  title={Code completion with statistical language models},
  author={Raychev, Veselin and Vechev, Martin and Yahav, Eran},
  booktitle={Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  pages={419--428},
  year={2014}
}

@inproceedings{tu2014localness,
  title={On the localness of software},
  author={Tu, Zhaopeng and Su, Zhendong and Devanbu, Premkumar},
  booktitle={Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  pages={269--280},
  year={2014}
}
@article{baevski2018adaptive,
  title={Adaptive input representations for neural language modeling},
  author={Baevski, Alexei and Auli, Michael},
  journal={arXiv preprint arXiv:1809.10853},
  year={2018}
}

@inproceedings{allamanis2013mining,
  title={Mining source code repositories at massive scale using language modeling},
  author={Allamanis, Miltiadis and Sutton, Charles},
  booktitle={2013 10th Working Conference on Mining Software Repositories (MSR)},
  pages={207--216},
  year={2013},
  organization={IEEE}
}

@article{merity2016pointer,
  title={Pointer sentinel mixture models},
  author={Merity, Stephen and Xiong, Caiming and Bradbury, James and Socher, Richard},
  journal={arXiv preprint arXiv:1609.07843},
  year={2016}
}

@inproceedings{karampatsis2020big,
  title={Big code!= big vocabulary: Open-vocabulary models for source code},
  author={Karampatsis, Rafael-Michael and Babii, Hlib and Robbes, Romain and Sutton, Charles and Janes, Andrea},
  booktitle={2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)},
  pages={1073--1085},
  year={2020},
  organization={IEEE}
}

@article{guu2018generating,
  title={Generating sentences by editing prototypes},
  author={Guu, Kelvin and Hashimoto, Tatsunori B and Oren, Yonatan and Liang, Percy},
  journal={Transactions of the Association for Computational Linguistics},
  volume={6},
  pages={437--450},
  year={2018},
  publisher={MIT Press}
}

@article{hayes1986writing,
  title={Writing research and the writer.},
  author={Hayes, John R and Flower, Linda S},
  journal={American psychologist},
  volume={41},
  number={10},
  pages={1106},
  year={1986},
  publisher={American Psychological Association}
}

@inproceedings{weston2018retrieve,
  title={Retrieve and Refine: Improved Sequence Generation Models For Dialogue},
  author={Weston, Jason and Dinan, Emily and Miller, Alexander},
  booktitle={Proceedings of the 2018 EMNLP Workshop SCAI: The 2nd International Workshop on Search-Oriented Conversational AI},
  year={2018}
}

@inproceedings{wu2019response,
  title={Response generation by context-aware prototype editing},
  author={Wu, Yu and Wei, Furu and Huang, Shaohan and Wang, Yunli and Li, Zhoujun and Zhou, Ming},
  booktitle={Proceedings of AAAI},
  year={2019}
}

@inproceedings{cao2018retrieve,
  title={Retrieve, rerank and rewrite: Soft template based neural summarization},
  author={Cao, Ziqiang and Li, Wenjie and Li, Sujian and Wei, Furu},
  booktitle={Proceedings of ACL},
  year={2018}
}

@inproceedings{hashimoto2018retrieve,
  title={A retrieve-and-edit framework for predicting structured outputs},
  author={Hashimoto, Tatsunori B and Guu, Kelvin and Oren, Yonatan and Liang, Percy S},
  booktitle={Proceedings of NeurIPS},
  year={2018}
}

@inproceedings{hayati2018retrieval,
  title={Retrieval-Based Neural Code Generation},
  author={Hayati, Shirley Anugrah and Olivier, Raphael and Avvaru, Pravalika and Yin, Pengcheng and Tomasic, Anthony and Neubig, Graham},
  booktitle={Proceedings EMNLP},
  year={2018}
}

@inproceedings{li2018delete,
  title={Delete, Retrieve, Generate: a Simple Approach to Sentiment and Style Transfer},
  author={Li, Juncen and Jia, Robin and He, He and Liang, Percy},
  booktitle={Proceedings of NAACL},
  year={2018}
}

@inproceedings{wang2019neural,
  title={Neural Machine Translation with Soft Prototype},
  author={Wang, Yiren and Xia, Yingce and Tian, Fei and Gao, Fei and Qin, Tao and Zhai, Cheng Xiang and Liu, Tie-Yan},
  booktitle={Proceedings of NeurIPS},
  year={2019}
}

@article{yelp17,
  title={Yelp Dataset Challenge, Round 8},
  author={Yelp},
  url={https://www.yelp.com/dataset_challenge},
  year={2017}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}


@inproceedings{kuncoro-etal-2017-recurrent,
    title = "What Do Recurrent Neural Network Grammars Learn About Syntax?",
    author = {Kuncoro, Adhiguna  and
      Ballesteros, Miguel  and
      Kong, Lingpeng  and
      Dyer, Chris  and
      Neubig, Graham  and
      Smith, Noah A.},
    booktitle = {Proceedings of EACL},
    year = {2017},
}

@inproceedings{petroni-etal-2019-language,
    title="Language Models as Knowledge Bases?",
    author={Petroni, Fabio  and
      Rockt{\"a}schel, Tim  and
      Riedel, Sebastian  and
      Lewis, Patrick  and
      Bakhtin, Anton  and
      Wu, Yuxiang  and
      Miller, Alexander},
    booktitle={Proceedings of EMNLP},
    year={2019},
}

@article{linzen2016assessing,
	Author = {Linzen, Tal and Dupoux, Emmanuel and Goldberg, Yoav},
	Journal = {Transactions of the Association for Computational Linguistics},
	Title = {Assessing the ability of {LSTMs} to learn syntax-sensitive dependencies},
    Volume = {4},
    Pages = {521--535},
	Year = {2016}
}

@inproceedings{sundermeyer2012lstm,
  title={LSTM neural networks for language modeling},
  author={Sundermeyer, Martin and Schl{\"u}ter, Ralf and Ney, Hermann},
  booktitle={Thirteenth annual conference of the international speech communication association},
  year={2012}
}

@inproceedings{mikolov2010recurrent,
  title={Recurrent neural network based language model},
  author={Mikolov, Tom{\'a}{\v{s}} and Karafi{\'a}t, Martin and Burget, Luk{\'a}{\v{s}} and {\v{C}}ernock{\`y}, Jan and Khudanpur, Sanjeev},
  booktitle={Eleventh annual conference of the international speech communication association},
  year={2010}
}

@inproceedings{dai2019transformer,
  title={Transformer-{XL}: Attentive Language Models beyond a Fixed-Length Context},
  author={Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime G and Le, Quoc and Salakhutdinov, Ruslan},
  booktitle={Proceedings of ACL},
  year={2019}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Proceedings of NeurIPS},
  year={2017}
}

@inproceedings{al2019character,
  title={Character-level language modeling with deeper self-attention},
  author={Al-Rfou, Rami and Choe, Dokook and Constant, Noah and Guo, Mandy and Jones, Llion},
  booktitle={Proceedings of AAAI},
  year={2019}
}

@article{bengio2003neural,
  title={A neural probabilistic language model},
  author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal and Jauvin, Christian},
  journal={Journal of machine learning research},
  volume={3},
  number={Feb},
  pages={1137--1155},
  year={2003}
}

@article{devlin2018bert,
  title={B{ERT}: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@inproceedings{yang2019xlnet,
  title={X{LN}et: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  booktitle={Proceedings of NeurIPS},
  year={2019}
}


@inproceedings{merity2018regularizing,
title={Regularizing and Optimizing {LSTM} Language Models},
author={Stephen Merity and Nitish Shirish Keskar and Richard Socher},
booktitle={Proceedings of ICLR},
year={2018}
}

@inproceedings{rush2015neural,
  title={A Neural Attention Model for Abstractive Sentence Summarization},
  author={Rush, Alexander M and Chopra, Sumit and Weston, Jason},
  booktitle={Proceedings of EMNLP},
  year={2015}
}

@inproceedings{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  booktitle={Proceedings of ICLR},
  year={2015}
}

@article{hodosh2013framing,
  title={Framing image description as a ranking task: Data, models and evaluation metrics},
  author={Hodosh, Micah and Young, Peter and Hockenmaier, Julia},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={853--899},
  year={2013}
}

@inproceedings{gu2018search,
  title={Search engine guided neural machine translation},
  author={Gu, Jiatao and Wang, Yong and Cho, Kyunghyun and Li, Victor OK},
  booktitle={Proceedings of AAAI},
  year={2018}
}

@inproceedings{xu2018spherical,
  title={Spherical Latent Spaces for Stable Variational Autoencoders},
  author={Xu, Jiacheng and Durrett, Greg},
  booktitle={Proceedings of EMNLP},
  year={2018}
}

@inproceedings{he2018lagging,
title={Lagging Inference Networks and Posterior Collapse in Variational Autoencoders},
author={Junxian He and Daniel Spokoyny and Graham Neubig and Taylor Berg-Kirkpatrick},
booktitle={Proceedings of ICLR},
year={2019},
}

@inproceedings{bowman2016generating,
  title={Generating Sentences from a Continuous Space},
  author={Bowman, Samuel and Vilnis, Luke and Vinyals, Oriol and Dai, Andrew and Jozefowicz, Rafal and Bengio, Samy},
  booktitle={Proceedings of CoNLL},
  year={2016}
}

@inproceedings{li2019surprisingly,
  title={A Surprisingly Effective Fix for Deep Latent Variable Modeling of Text},
  author={Li, Bohan and He, Junxian and Neubig, Graham and Berg-Kirkpatrick, Taylor and Yang, Yiming},
  booktitle={Proceedings of EMNLP},
  year={2019}
}

@article{hoffman2013stochastic,
  title={Stochastic variational inference},
  author={Hoffman, Matthew D and Blei, David M and Wang, Chong and Paisley, John},
  journal={The Journal of Machine Learning Research},
  volume={14},
  number={1},
  pages={1303--1347},
  year={2013},
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of EMNLP},
  year={2014}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@article{blei2003latent,
  title={Latent dirichlet allocation},
  author={Blei, David M and Ng, Andrew Y and Jordan, Michael I},
  journal={Journal of machine Learning research},
  volume={3},
  number={Jan},
  pages={993--1022},
  year={2003}
}

@article{Wolf2019HuggingFacesTS,
  title={HuggingFace's Transformers: State-of-the-art Natural Language Processing},
  author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R'emi Louf and Morgan Funtowicz and Jamie Brew},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.03771}
}

@inproceedings{yin2018learning,
title={Learning to Represent Edits},
author={Pengcheng Yin and Graham Neubig and Miltiadis Allamanis and Marc Brockschmidt and Alexander L. Gaunt},
booktitle={Proceedings of ICLR},
year={2019},
}

@inproceedings{alemi2016deep,
  title={Deep variational information bottleneck},
  author={Alemi, Alexander A and Fischer, Ian and Dillon, Joshua V and Murphy, Kevin},
  booktitle={Proceedings of ICLR},
  year={2017}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Proceedings of ECCV},
  year={2014}
}

@inproceedings{lin2004orange,
  title={Orange: a method for evaluating automatic evaluation metrics for machine translation},
  author={Lin, Chin-Yew and Och, Franz Josef},
  booktitle={Proceedings of COLING},
  year={2004}
}

@article{burda2015importance,
  title={Importance weighted autoencoders},
  author={Burda, Yuri and Grosse, Roger and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1509.00519},
  year={2015}
}

@inproceedings{ott2019fairseq,
  title = {fairseq: A Fast, Extensible Toolkit for Sequence Modeling},
  author = {Myle Ott and Sergey Edunov and Alexei Baevski and Angela Fan and Sam Gross and Nathan Ng and David Grangier and Michael Auli},
  booktitle = {Proceedings of NAACL (Demo Track)},
  year = {2019},
}

@inproceedings{qi2020stanza,
    title={Stanza: A {Python} Natural Language Processing Toolkit for Many Human Languages},
    author={Qi, Peng and Zhang, Yuhao and Zhang, Yuhui and Bolton, Jason and Manning, Christopher D.},
    booktitle = {Proceedings of ACL (Demo Track)},
    year={2020}
}

@article{vsovsic2017edlib,
  title={Edlib: a C/C++ library for fast, exact sequence alignment using edit distance},
  author={{\v{S}}o{\v{s}}i{\'c}, Martin and {\v{S}}iki{\'c}, Mile},
  journal={Bioinformatics},
  volume={33},
  number={9},
  pages={1394--1395},
  year={2017}
}

@article{parzen1962estimation,
  title={On estimation of a probability density function and mode},
  author={Parzen, Emanuel},
  journal={The annals of mathematical statistics},
  volume={33},
  number={3},
  pages={1065--1076},
  year={1962},
  publisher={JSTOR}
}

@inproceedings{sordoni2015neural,
  title={A Neural Network Approach to Context-Sensitive Generation of Conversational Responses},
  author={Sordoni, Alessandro and Galley, Michel and Auli, Michael and Brockett, Chris and Ji, Yangfeng and Mitchell, Margaret and Nie, Jian-Yun and Gao, Jianfeng and Dolan, Bill},
  booktitle={Proceedings of NAACL},
  year={2015}
}

@inproceedings{kingma2016improved,
  title={Improved variational inference with inverse autoregressive flow},
  author={Kingma, Durk P and Salimans, Tim and Jozefowicz, Rafal and Chen, Xi and Sutskever, Ilya and Welling, Max},
  booktitle={Proceedings of NeurIPS},
  year={2016}
}

@inproceedings{zellers2019defending,
  title={Defending against neural fake news},
  author={Zellers, Rowan and Holtzman, Ari and Rashkin, Hannah and Bisk, Yonatan and Farhadi, Ali and Roesner, Franziska and Choi, Yejin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9051--9062},
  year={2019}
}

@book{bishop2006pattern,
  title={Pattern recognition and machine learning},
  author={Bishop, Christopher M},
  year={2006},
  publisher={springer}
}

@inproceedings{bapna2019non,
  title={Non-Parametric Adaptation for Neural Machine Translation},
  author={Bapna, Ankur and Firat, Orhan},
  booktitle={Proceedings of NAACL},
  year={2019}
}

@article{khandelwal2020nearest,
  title={Nearest Neighbor Machine Translation},
  author={Khandelwal, Urvashi and Fan, Angela and Jurafsky, Dan and Zettlemoyer, Luke and Lewis, Mike},
  journal={arXiv preprint arXiv:2010.00710},
  year={2020}
}

@inproceedings{reimers2019sentence,
  title={Sentence-{BERT}: Sentence Embeddings using Siamese BERT-Networks},
  author={Reimers, Nils and Gurevych, Iryna},
  booktitle={Proceedings of EMNLP},
  year={2019}
}

@inproceedings{demeter2020stolen,
  title={Stolen Probability: A Structural Weakness of Neural Language Models},
  author={Demeter, David and Kimmel, Gregory and Downey, Doug},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={2191--2197},
  year={2020}
}

@inproceedings{grivas2022low,
  title={Low-Rank Softmax Can Have Unargmaxable Classes in Theory but Rarely in Practice},
  author={Grivas, Andreas and Bogoychev, Nikolay and Lopez, Adam},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={6738--6758},
  year={2022}
}

@inproceedings{borgeaud2022improving,
  title={Improving language models by retrieving from trillions of tokens},
  author={Borgeaud, Sebastian and Mensch, Arthur and Hoffmann, Jordan and Cai, Trevor and Rutherford, Eliza and Millican, Katie and Van Den Driessche, George Bm and Lespiau, Jean-Baptiste and Damoc, Bogdan and Clark, Aidan and others},
  booktitle={International conference on machine learning},
  pages={2206--2240},
  year={2022},
  organization={PMLR}
}
