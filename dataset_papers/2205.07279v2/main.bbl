\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bach et~al.(2015)Bach, Binder, Montavon, Klauschen, M{\"u}ller, and
  Samek]{bach2015pixel}
Sebastian Bach, Alexander Binder, Gr{\'e}goire Montavon, Frederick Klauschen,
  Klaus-Robert M{\"u}ller, and Wojciech Samek.
\newblock On pixel-wise explanations for non-linear classifier decisions by
  layer-wise relevance propagation.
\newblock \emph{PloS one}, 10\penalty0 (7):\penalty0 e0130140, 2015.

\bibitem[Boopathy et~al.(2020)Boopathy, Liu, Zhang, Liu, Chen, Chang, and
  Daniel]{boopathy2020proper}
Akhilan Boopathy, Sijia Liu, Gaoyuan Zhang, Cynthia Liu, Pin-Yu Chen, Shiyu
  Chang, and Luca Daniel.
\newblock Proper network interpretability helps adversarial robustness in
  classification.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1014--1023. PMLR, 2020.

\bibitem[Carlini \& Wagner(2017)Carlini and Wagner]{carlini2017towards}
Nicholas Carlini and David Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{2017 IEEE Symposium on Security and Privacy (SP)}, pp.\
  39--57. IEEE Computer Society, 2017.

\bibitem[Chen et~al.(2019)Chen, Wu, Rastogi, Liang, and Jha]{chen2019robust}
Jiefeng Chen, Xi~Wu, Vaibhav Rastogi, Yingyu Liang, and Somesh Jha.
\newblock Robust attribution regularization.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  14300--14310, 2019.

\bibitem[Deeks(2019)]{deeks2019judicial}
Ashley Deeks.
\newblock The judicial demand for explainable artificial intelligence.
\newblock \emph{Columbia Law Review}, 119\penalty0 (7):\penalty0 1829--1850,
  2019.

\bibitem[Dombrowski et~al.(2019)Dombrowski, Alber, Anders, Ackermann,
  M{\"u}ller, and Kessel]{dombrowski2019explanations}
Ann-Kathrin Dombrowski, Maximillian Alber, Christopher Anders, Marcel
  Ackermann, Klaus-Robert M{\"u}ller, and Pan Kessel.
\newblock Explanations can be manipulated and geometry is to blame.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  13589--13600, 2019.

\bibitem[Engstrom et~al.(2019)Engstrom, Ilyas, Santurkar, Tsipras, Tran, and
  Madry]{engstrom2019adversarial}
Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Brandon
  Tran, and Aleksander Madry.
\newblock Adversarial robustness as a prior for learned representations.
\newblock \emph{arXiv preprint arXiv:1906.00945}, 2019.

\bibitem[Ghorbani et~al.(2019)Ghorbani, Abid, and
  Zou]{ghorbani2019interpretation}
Amirata Ghorbani, Abubakar Abid, and James Zou.
\newblock Interpretation of neural networks is fragile.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pp.\  3681--3688, 2019.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Goodman \& Flaxman(2017)Goodman and Flaxman]{goodman2017european}
Bryce Goodman and Seth Flaxman.
\newblock European union regulations on algorithmic decision-making and a
  “right to explanation”.
\newblock \emph{AI magazine}, 38\penalty0 (3):\penalty0 50--57, 2017.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[Heo et~al.(2019)Heo, Joo, and Moon]{heo2019fooling}
Juyeon Heo, Sunghwan Joo, and Taesup Moon.
\newblock Fooling neural network interpretations via adversarial model
  manipulation.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2925--2936, 2019.

\bibitem[Ivankay et~al.(2020)Ivankay, Girardi, Marchiori, and
  Frossard]{ivankay2020far}
Adam Ivankay, Ivan Girardi, Chiara Marchiori, and Pascal Frossard.
\newblock Far: A general framework for attributional robustness.
\newblock \emph{arXiv preprint arXiv:2010.07393}, 2020.

\bibitem[Ivankay et~al.(2022)Ivankay, Girardi, Marchiori, and
  Frossard]{ivankay2022fooling}
Adam Ivankay, Ivan Girardi, Chiara Marchiori, and Pascal Frossard.
\newblock Fooling explanations in text classifiers.
\newblock \emph{arXiv preprint arXiv:2206.03178}, 2022.

\bibitem[Kendall(1948)]{kendall1948rank}
Maurice~George Kendall.
\newblock Rank correlation methods.
\newblock 1948.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Krizhevsky(2009)]{krizhevsky2009learning}
Alex Krizhevsky.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Kurakin et~al.(2017)Kurakin, Goodfellow, and
  Bengio]{kurakin2016adversarial}
Alexey Kurakin, Ian~J. Goodfellow, and Samy Bengio.
\newblock Adversarial machine learning at scale.
\newblock In \emph{International Conference on Learning Representations}, 2017.
\newblock URL \url{https://openreview.net/forum?id=BJm4T4Kgx}.

\bibitem[LeCun et~al.(2010)LeCun, Cortes, and Burges]{lecun2010mnist}
Yann LeCun, Corinna Cortes, and CJ~Burges.
\newblock Mnist handwritten digit database.
\newblock \emph{ATT Labs [Online]. Available:
  http://yann.lecun.com/exdb/mnist}, 2, 2010.

\bibitem[Lorente et~al.(2021)Lorente, Lopez, Florez, Espino, Mart{\'\i}nez, and
  de~Miguel]{lorente2021explaining}
Maria Paz~Sesmero Lorente, Elena~Mag{\'a}n Lopez, Laura~Alvarez Florez,
  Agapito~Ledezma Espino, Jos{\'e} Antonio~Iglesias Mart{\'\i}nez, and
  Araceli~Sanchis de~Miguel.
\newblock Explaining deep learning-based driver models.
\newblock \emph{Applied Sciences}, 11\penalty0 (8):\penalty0 3321, 2021.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2018towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=rJzIBfZAb}.

\bibitem[Papernot et~al.(2016{\natexlab{a}})Papernot, McDaniel, Jha,
  Fredrikson, Celik, and Swami]{papernot2016limitations}
Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z~Berkay
  Celik, and Ananthram Swami.
\newblock The limitations of deep learning in adversarial settings.
\newblock In \emph{2016 IEEE European symposium on security and privacy
  (EuroS\&P)}, pp.\  372--387. IEEE, 2016{\natexlab{a}}.

\bibitem[Papernot et~al.(2016{\natexlab{b}})Papernot, McDaniel, Wu, Jha, and
  Swami]{papernot2016distillation}
Nicolas Papernot, Patrick McDaniel, Xi~Wu, Somesh Jha, and Ananthram Swami.
\newblock Distillation as a defense to adversarial perturbations against deep
  neural networks.
\newblock In \emph{2016 IEEE symposium on security and privacy (SP)}, pp.\
  582--597. IEEE, 2016{\natexlab{b}}.

\bibitem[Sarkar et~al.(2021)Sarkar, Sarkar, and
  Balasubramanian]{sarkar2021enhanced}
Anindya Sarkar, Anirban Sarkar, and Vineeth~N Balasubramanian.
\newblock Enhanced regularizers for attributional robustness.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~35, pp.\  2532--2540, 2021.

\bibitem[Shrikumar et~al.(2017)Shrikumar, Greenside, and
  Kundaje]{shrikumar2017learning}
Avanti Shrikumar, Peyton Greenside, and Anshul Kundaje.
\newblock Learning important features through propagating activation
  differences.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  3145--3153. PMLR, 2017.

\bibitem[Simonyan et~al.(2014)Simonyan, Vedaldi, and
  Zisserman]{simonyan2013deep}
Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman.
\newblock Deep inside convolutional networks: Visualising image classification
  models and saliency maps.
\newblock In \emph{2nd International Conference on Learning Representations,
  {ICLR} 2014, Banff, AB, Canada, April 14-16, 2014, Workshop Track
  Proceedings}, 2014.

\bibitem[Singh et~al.(2020{\natexlab{a}})Singh, Sengupta, and
  Lakshminarayanan]{singh2020explainable}
Amitojdeep Singh, Sourya Sengupta, and Vasudevan Lakshminarayanan.
\newblock Explainable deep learning models in medical image analysis.
\newblock \emph{Journal of Imaging}, 6\penalty0 (6):\penalty0 52,
  2020{\natexlab{a}}.

\bibitem[Singh et~al.(2020{\natexlab{b}})Singh, Kumari, Mangla, Sinha,
  Balasubramanian, and Krishnamurthy]{singh2020attributional}
Mayank Singh, Nupur Kumari, Puneet Mangla, Abhishek Sinha, Vineeth~N
  Balasubramanian, and Balaji Krishnamurthy.
\newblock Attributional robustness training using input-gradient spatial
  alignment.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference,
  Glasgow, UK, August 23--28, 2020, Proceedings, Part XXVII 16}, pp.\
  515--533. Springer, 2020{\natexlab{b}}.

\bibitem[Sundararajan et~al.(2017)Sundararajan, Taly, and
  Yan]{sundararajan2017axiomatic}
Mukund Sundararajan, Ankur Taly, and Qiqi Yan.
\newblock Axiomatic attribution for deep networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  3319--3328. PMLR, 2017.

\bibitem[Sutskever et~al.(2013)Sutskever, Martens, Dahl, and
  Hinton]{sutskever2013importance}
Ilya Sutskever, James Martens, George Dahl, and Geoffrey Hinton.
\newblock On the importance of initialization and momentum in deep learning.
\newblock In \emph{International conference on machine learning}, pp.\
  1139--1147. PMLR, 2013.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2014intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock In \emph{2nd International Conference on Learning Representations,
  ICLR 2014}, 2014.

\bibitem[Wang et~al.(2019)Wang, Zou, Yi, Bailey, Ma, and Gu]{wang2019improving}
Yisen Wang, Difan Zou, Jinfeng Yi, James Bailey, Xingjun Ma, and Quanquan Gu.
\newblock Improving adversarial robustness requires revisiting misclassified
  examples.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Wang et~al.(2020)Wang, Wang, Ramkumar, Mardziel, Fredrikson, and
  Datta]{wang2020smoothed}
Zifan Wang, Haofan Wang, Shakul Ramkumar, Piotr Mardziel, Matt Fredrikson, and
  Anupam Datta.
\newblock Smoothed geometry for robust attribution.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~33, pp.\  13623--13634. Curran Associates, Inc., 2020.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{xiao2017fashion}
Han Xiao, Kashif Rasul, and Roland Vollgraf.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms.
\newblock \emph{arXiv preprint arXiv:1708.07747}, 2017.

\bibitem[Zeiler \& Fergus(2014)Zeiler and Fergus]{zeiler2014visualizing}
Matthew~D Zeiler and Rob Fergus.
\newblock Visualizing and understanding convolutional networks.
\newblock In \emph{European conference on computer vision}, pp.\  818--833.
  Springer, 2014.

\bibitem[Zhang et~al.(2019)Zhang, Yu, Jiao, Xing, El~Ghaoui, and
  Jordan]{zhang2019theoretically}
Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El~Ghaoui, and
  Michael Jordan.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  7472--7482. PMLR, 2019.

\bibitem[Zintgraf et~al.(2017)Zintgraf, Cohen, Adel, and
  Welling]{zintgraf2017visualizing}
Luisa~M. Zintgraf, Taco~S. Cohen, Tameem Adel, and Max Welling.
\newblock Visualizing deep neural network decisions: Prediction difference
  analysis.
\newblock In \emph{International Conference on Learning Representations, {ICLR}
  2017}. OpenReview.net, 2017.
\newblock URL \url{https://openreview.net/forum?id=BJ5UeU9xx}.

\end{thebibliography}
