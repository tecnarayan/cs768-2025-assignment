\begin{thebibliography}{10}

\bibitem{balle2016end}
Johannes Ball{\'e}, Valero Laparra, and Eero~P Simoncelli.
\newblock End-to-end optimized image compression.
\newblock {\em arXiv preprint arXiv:1611.01704}, 2016.

\bibitem{balle2018variational}
Johannes Ball{\'e}, David Minnen, Saurabh Singh, Sung~Jin Hwang, and Nick
  Johnston.
\newblock Variational image compression with a scale hyperprior.
\newblock {\em arXiv preprint arXiv:1802.01436}, 2018.

\bibitem{behrmann2018invertible}
Jens Behrmann, David Duvenaud, and J{\"o}rn-Henrik Jacobsen.
\newblock Invertible residual networks.
\newblock {\em arXiv preprint arXiv:1811.00995}, 2018.

\bibitem{chen2016variational}
Xi~Chen, Diederik~P Kingma, Tim Salimans, Yan Duan, Prafulla Dhariwal, John
  Schulman, Ilya Sutskever, and Pieter Abbeel.
\newblock Variational lossy autoencoder.
\newblock {\em arXiv preprint arXiv:1611.02731}, 2016.

\bibitem{chen2018pixelsnail}
Xi~Chen, Nikhil Mishra, Mostafa Rohaninejad, and Pieter Abbeel.
\newblock Pixel{SNAIL}: An improved autoregressive generative model.
\newblock In {\em International Conference on Machine Learning}, pages
  863--871, 2018.

\bibitem{child2019generating}
Rewon Child, Scott Gray, Alec Radford, and Ilya Sutskever.
\newblock Generating long sequences with sparse transformers.
\newblock {\em arXiv preprint arXiv:1904.10509}, 2019.

\bibitem{cover2012elements}
Thomas~M Cover and Joy~A Thomas.
\newblock {\em Elements of information theory}.
\newblock John Wiley \& Sons, 2012.

\bibitem{dayan1995helmholtz}
Peter Dayan, Geoffrey~E Hinton, Radford~M Neal, and Richard~S Zemel.
\newblock The helmholtz machine.
\newblock {\em Neural computation}, 7(5):889--904, 1995.

\bibitem{deco1995higher}
Gustavo Deco and Wilfried Brauer.
\newblock Higher order statistical decorrelation without information loss.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  247--254, 1995.

\bibitem{dinh2014nice}
Laurent Dinh, David Krueger, and Yoshua Bengio.
\newblock Nice: Non-linear independent components estimation.
\newblock {\em arXiv preprint arXiv:1410.8516}, 2014.

\bibitem{dinh2016density}
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
\newblock Density estimation using {R}eal {NVP}.
\newblock {\em arXiv preprint arXiv:1605.08803}, 2016.

\bibitem{duda2013asymmetric}
Jarek Duda.
\newblock Asymmetric numeral systems: entropy coding combining speed of huffman
  coding with compression rate of arithmetic coding.
\newblock {\em arXiv preprint arXiv:1311.2540}, 2013.

\bibitem{frey1997efficient}
Brendan~J. Frey and Geoffrey~E. Hinton.
\newblock Efficient stochastic source coding and an application to a {B}ayesian
  network source model.
\newblock {\em The Computer Journal}, 40(2\_and\_3):157--165, 1997.

\bibitem{giesen2014interleaved}
Fabian Giesen.
\newblock Interleaved entropy coders.
\newblock {\em arXiv preprint arXiv:1402.3392}, 2014.

\bibitem{grathwohl2018ffjord}
Will Grathwohl, Ricky~TQ Chen, Jesse Betterncourt, Ilya Sutskever, and David
  Duvenaud.
\newblock Ffjord: Free-form continuous dynamics for scalable reversible
  generative models.
\newblock {\em arXiv preprint arXiv:1810.01367}, 2018.

\bibitem{gregor2016towards}
Karol Gregor, Frederic Besse, Danilo~Jimenez Rezende, Ivo Danihelka, and Daan
  Wierstra.
\newblock Towards conceptual compression.
\newblock In {\em Advances In Neural Information Processing Systems}, pages
  3549--3557, 2016.

\bibitem{gritsenko2019relationship}
Alexey~A Gritsenko, Jasper Snoek, and Tim Salimans.
\newblock On the relationship between normalising flows and variational-and
  denoising autoencoders.
\newblock 2019.

\bibitem{hinton1993keeping}
Geoffrey Hinton and Drew Van~Camp.
\newblock Keeping neural networks simple by minimizing the description length
  of the weights.
\newblock In {\em in Proc. of the 6th Ann. ACM Conf. on Computational Learning
  Theory}. Citeseer, 1993.

\bibitem{ho2019flow++}
Jonathan Ho, Xi~Chen, Aravind Srinivas, Yan Duan, and Pieter Abbeel.
\newblock Flow++: Improving flow-based generative models with variational
  dequantization and architecture design.
\newblock In {\em International Conference on Machine Learning}, 2019.

\bibitem{honkela2004variational}
Antti Honkela and Harri Valpola.
\newblock Variational learning and bits-back coding: an information-theoretic
  view to bayesian learning.
\newblock {\em IEEE Transactions on Neural Networks}, 15(4):800--810, 2004.

\bibitem{huffman1952method}
David~A Huffman.
\newblock A method for the construction of minimum-redundancy codes.
\newblock {\em Proceedings of the IRE}, 40(9):1098--1101, 1952.

\bibitem{kalchbrenner2017video}
Nal Kalchbrenner, A{\"a}ron Oord, Karen Simonyan, Ivo Danihelka, Oriol Vinyals,
  Alex Graves, and Koray Kavukcuoglu.
\newblock Video pixel networks.
\newblock In {\em International Conference on Machine Learning}, pages
  1771--1779, 2017.

\bibitem{kingma2018glow}
Diederik~P Kingma and Prafulla Dhariwal.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  10215--10224, 2018.

\bibitem{kingma2016improved}
Diederik~P Kingma, Tim Salimans, Rafal Jozefowicz, Xi~Chen, Ilya Sutskever, and
  Max Welling.
\newblock Improved variational inference with inverse autoregressive flow.
\newblock In {\em Advances in neural information processing systems}, pages
  4743--4751, 2016.

\bibitem{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock {\em arXiv preprint arXiv:1312.6114}, 2013.

\bibitem{kingma2019bitswap}
Friso~H Kingma, Pieter Abbeel, and Jonathan Ho.
\newblock Bit-swap: Recursive bits-back coding for lossless compression with
  hierarchical latent variables.
\newblock In {\em International Conference on Machine Learning}, 2019.

\bibitem{kraft1949device}
Leon~Gordon Kraft.
\newblock {\em A device for quantizing, grouping, and coding
  amplitude-modulated pulses}.
\newblock PhD thesis, Massachusetts Institute of Technology, 1949.

\bibitem{kumar2019videoflow}
Manoj Kumar, Mohammad Babaeizadeh, Dumitru Erhan, Chelsea Finn, Sergey Levine,
  Laurent Dinh, and Durk Kingma.
\newblock Videoflow: A flow-based generative model for video.
\newblock {\em arXiv preprint arXiv:1903.01434}, 2019.

\bibitem{maaloe2019biva}
Lars Maal{\o}e, Marco Fraccaro, Valentin Li{\'e}vin, and Ole Winther.
\newblock Biva: A very deep hierarchy of latent variables for generative
  modeling.
\newblock {\em arXiv preprint arXiv:1902.02102}, 2019.

\bibitem{mcmillan1956two}
Brockway McMillan.
\newblock Two inequalities implied by unique decipherability.
\newblock {\em IRE Transactions on Information Theory}, 2(4):115--116, 1956.

\bibitem{menick2018generating}
Jacob Menick and Nal Kalchbrenner.
\newblock Generating high fidelity images with subscale pixel networks and
  multidimensional upscaling.
\newblock {\em arXiv preprint arXiv:1812.01608}, 2018.

\bibitem{mentzer2018practical}
Fabian Mentzer, Eirikur Agustsson, Michael Tschannen, Radu Timofte, and Luc
  Van~Gool.
\newblock Practical full resolution learned lossless image compression.
\newblock {\em arXiv preprint arXiv:1811.12817}, 2018.

\bibitem{papamakarios2017masked}
George Papamakarios, Theo Pavlakou, and Iain Murray.
\newblock Masked autoregressive flow for density estimation.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2338--2347, 2017.

\bibitem{parmar2018image}
Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, {\L}ukasz Kaiser, Noam Shazeer,
  and Alexander Ku.
\newblock Image transformer.
\newblock {\em arXiv preprint arXiv:1802.05751}, 2018.

\bibitem{prenger2019waveglow}
Ryan Prenger, Rafael Valle, and Bryan Catanzaro.
\newblock Waveglow: A flow-based generative network for speech synthesis.
\newblock In {\em ICASSP 2019-2019 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pages 3617--3621. IEEE, 2019.

\bibitem{rezende2014stochastic}
Danilo~Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock {\em arXiv preprint arXiv:1401.4082}, 2014.

\bibitem{rippel2017real}
Oren Rippel and Lubomir Bourdev.
\newblock Real-time adaptive image compression.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 2922--2930. JMLR. org, 2017.

\bibitem{rissanen1976generalized}
Jorma~J Rissanen.
\newblock Generalized {K}raft inequality and arithmetic coding.
\newblock {\em IBM Journal of research and development}, 20(3):198--203, 1976.

\bibitem{salimans2017pixelcnn++}
Tim Salimans, Andrej Karpathy, Xi~Chen, and Diederik~P Kingma.
\newblock Pixel{CNN}++: Improving the {PixelCNN} with discretized logistic
  mixture likelihood and other modifications.
\newblock {\em arXiv preprint arXiv:1701.05517}, 2017.

\bibitem{theis2017lossy}
Lucas Theis, Wenzhe Shi, Andrew Cunningham, and Ferenc Husz{\'a}r.
\newblock Lossy image compression with compressive autoencoders.
\newblock {\em arXiv preprint arXiv:1703.00395}, 2017.

\bibitem{theis2016note}
Lucas Theis, AÃ¤ron van~den Oord, and Matthias Bethge.
\newblock A note on the evaluation of generative models.
\newblock In {\em International Conference on Learning Representations (ICLR
  2016)}, pages 1--10, 2016.

\bibitem{townsend2018practical}
James Townsend, Thomas Bird, and David Barber.
\newblock Practical lossless compression with latent variables using bits back
  coding.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{uria2016neural}
Benigno Uria, Marc-Alexandre C{\^o}t{\'e}, Karol Gregor, Iain Murray, and Hugo
  Larochelle.
\newblock Neural autoregressive distribution estimation.
\newblock {\em The Journal of Machine Learning Research}, 17(1):7184--7220,
  2016.

\bibitem{oord2016wavenet}
Aaron van~den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals,
  Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu.
\newblock Wavenet: A generative model for raw audio.
\newblock {\em arXiv preprint arXiv:1609.03499}, 2016.

\bibitem{oord2016pixel}
Aaron van~den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu.
\newblock Pixel recurrent neural networks.
\newblock {\em International Conference on Machine Learning (ICML)}, 2016.

\bibitem{oord2016conditional}
Aaron van~den Oord, Nal Kalchbrenner, Oriol Vinyals, Lasse Espeholt, Alex
  Graves, and Koray Kavukcuoglu.
\newblock Conditional image generation with {PixelCNN} decoders.
\newblock {\em arXiv preprint arXiv:1606.05328}, 2016.

\bibitem{wallace1968information}
Christopher~S Wallace and David~M Boulton.
\newblock An information measure for classification.
\newblock {\em The Computer Journal}, 11(2):185--194, 1968.

\end{thebibliography}
