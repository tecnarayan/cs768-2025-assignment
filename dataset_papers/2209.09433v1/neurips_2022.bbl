\begin{thebibliography}{10}

\bibitem{alwassel_2020_xdc}
Humam Alwassel, Dhruv Mahajan, Bruno Korbar, Lorenzo Torresani, Bernard Ghanem,
  and Du~Tran.
\newblock Self-supervised learning by cross-modal audio-video clustering.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2020.

\bibitem{bowman2015large}
Samuel~R Bowman, Gabor Angeli, Christopher Potts, and Christopher~D Manning.
\newblock A large annotated corpus for learning natural language inference.
\newblock In {\em EMNLP}, 2015.

\bibitem{cao-etal-2021-pause}
Lele Cao, Emil Larsson, Vilhelm von Ehrenheim, Dhiana~Deva Cavalcanti~Rocha,
  Anna Martin, and Sonja Horn.
\newblock {PAUSE}: Positive and annealed unlabeled sentence embedding.
\newblock In {\em Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, pages 10096--10107, Online and Punta Cana,
  Dominican Republic, November 2021. Association for Computational Linguistics.

\bibitem{carlsson2020semantic}
Fredrik Carlsson, Amaru~Cuba Gyllensten, Evangelia Gogoulou,
  Erik~Ylip{\"a}{\"a} Hellqvist, and Magnus Sahlgren.
\newblock Semantic re-tuning with contrastive tension.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{pmlr-v119-chen20j}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In Hal~Daum√© III and Aarti Singh, editors, {\em Proceedings of the
  37th International Conference on Machine Learning}, volume 119 of {\em
  Proceedings of Machine Learning Research}, pages 1597--1607. PMLR, 13--18 Jul
  2020.

\bibitem{chen2020uniter}
Yen-Chun Chen, Linjie Li, Licheng Yu, Ahmed El~Kholy, Faisal Ahmed, Zhe Gan,
  Yu~Cheng, and Jingjing Liu.
\newblock Uniter: Universal image-text representation learning.
\newblock In {\em European conference on computer vision}, pages 104--120.
  Springer, 2020.

\bibitem{chopra2005learning}
Sumit Chopra, Raia Hadsell, and Yann LeCun.
\newblock Learning a similarity metric discriminatively, with application to
  face verification.
\newblock In {\em 2005 IEEE Computer Society Conference on Computer Vision and
  Pattern Recognition (CVPR'05)}, volume~1, pages 539--546. IEEE, 2005.

\bibitem{chuang-etal-2022-diffcse}
Yung-Sung Chuang, Rumen Dangovski, Hongyin Luo, Yang Zhang, Shiyu Chang, Marin
  Soljacic, Shang-Wen Li, Scott Yih, Yoon Kim, and James Glass.
\newblock {D}iff{CSE}: Difference-based contrastive learning for sentence
  embeddings.
\newblock In {\em Proceedings of the 2022 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 4207--4218, Seattle, United States, July 2022.
  Association for Computational Linguistics.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee, 2009.

\bibitem{dolan2005automatically}
William~B Dolan and Chris Brockett.
\newblock Automatically constructing a corpus of sentential paraphrases.
\newblock In {\em Proceedings of the Third International Workshop on
  Paraphrasing (IWP2005)}, 2005.

\bibitem{dosovitskiy2021an}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{gao2021making}
Tianyu Gao, Adam Fisch, and Danqi Chen.
\newblock Making pre-trained language models better few-shot learners.
\newblock In {\em Association for Computational Linguistics (ACL)}, 2021.

\bibitem{gao2021simcse}
Tianyu Gao, Xingcheng Yao, and Danqi Chen.
\newblock {SimCSE}: Simple contrastive learning of sentence embeddings.
\newblock In {\em Empirical Methods in Natural Language Processing (EMNLP)},
  2021.

\bibitem{giorgi-etal-2021-declutr}
John Giorgi, Osvald Nitski, Bo~Wang, and Gary Bader.
\newblock {D}e{CLUTR}: Deep contrastive learning for unsupervised textual
  representations.
\newblock In {\em Proceedings of the 59th Annual Meeting of the Association for
  Computational Linguistics and the 11th International Joint Conference on
  Natural Language Processing (Volume 1: Long Papers)}, pages 879--895, Online,
  August 2021. Association for Computational Linguistics.

\bibitem{gong2021ssast}
Yuan Gong, Cheng-I~Jeff Lai, Yu-An Chung, and James Glass.
\newblock Ssast: Self-supervised audio spectrogram transformer.
\newblock {\em arXiv preprint arXiv:2110.09784}, 2021.

\bibitem{goswami-etal-2021-cross}
Koustava Goswami, Sourav Dutta, Haytham Assem, Theodorus Fransen, and John~P.
  McCrae.
\newblock Cross-lingual sentence embedding using multi-task learning.
\newblock In {\em Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, pages 9099--9113, Online and Punta Cana,
  Dominican Republic, November 2021. Association for Computational Linguistics.

\bibitem{gunel2020supervised}
Beliz Gunel, Jingfei Du, Alexis Conneau, and Veselin Stoyanov.
\newblock Supervised contrastive learning for pre-trained language model
  fine-tuning.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{MoCo}
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2020.

\bibitem{henaff2020data}
Olivier Henaff.
\newblock Data-efficient image recognition with contrastive predictive coding.
\newblock In {\em International Conference on Machine Learning}, pages
  4182--4192. PMLR, 2020.

\bibitem{hu2004mining}
Minqing Hu and Bing Liu.
\newblock Mining and summarizing customer reviews.
\newblock In {\em Proceedings of the tenth ACM SIGKDD international conference
  on Knowledge discovery and data mining}, pages 168--177, 2004.

\bibitem{UniT}
Ronghang Hu and Amanpreet Singh.
\newblock Transformer is all you need: Multimodal multitask learning with a
  unified transformer.
\newblock {\em CoRR}, abs/2102.10772, 2021.

\bibitem{huang-etal-2021-disentangling}
James~Y. Huang, Kuan-Hao Huang, and Kai-Wei Chang.
\newblock Disentangling semantics and syntax in sentence embeddings with
  pre-trained language models.
\newblock In {\em Proceedings of the 2021 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 1372--1379, Online, June 2021. Association for
  Computational Linguistics.

\bibitem{huang-etal-2021-whiteningbert-easy}
Junjie Huang, Duyu Tang, Wanjun Zhong, Shuai Lu, Linjun Shou, Ming Gong, Daxin
  Jiang, and Nan Duan.
\newblock {W}hitening{BERT}: An easy unsupervised sentence embedding approach.
\newblock In {\em Findings of the Association for Computational Linguistics:
  EMNLP 2021}, pages 238--244, Punta Cana, Dominican Republic, November 2021.
  Association for Computational Linguistics.

\bibitem{Jian2022LMSupCon}
Yiren Jian, Chongyang Gao, and Soroush Vosoughi.
\newblock Contrastive learning for prompt-based few-shot language learners.
\newblock In {\em Proceedings of the 2022 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 5577--5587, Seattle, United States, July 2022.
  Association for Computational Linguistics.

\bibitem{jiang2022promptbert}
Ting Jiang, Shaohan Huang, Zihan Zhang, Deqing Wang, Fuzhen Zhuang, Furu Wei,
  Haizhen Huang, Liangjie Zhang, and Qi~Zhang.
\newblock Promptbert: Improving bert sentence embeddings with prompts.
\newblock {\em arXiv preprint arXiv:2201.04337}, 2022.

\bibitem{kayal-2021-unsupervised}
Subhradeep Kayal.
\newblock Unsupervised sentence-embeddings by manifold approximation and
  projection.
\newblock In {\em Proceedings of the 16th Conference of the European Chapter of
  the Association for Computational Linguistics: Main Volume}, pages 1--11,
  Online, April 2021. Association for Computational Linguistics.

\bibitem{SupCon}
Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip
  Isola, Aaron Maschinot, Ce~Liu, and Dilip Krishnan.
\newblock Supervised contrastive learning.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin,
  editors, {\em Advances in Neural Information Processing Systems}, volume~33,
  pages 18661--18673. Curran Associates, Inc., 2020.

\bibitem{kim-etal-2021-self}
Taeuk Kim, Kang~Min Yoo, and Sang-goo Lee.
\newblock Self-guided contrastive learning for {BERT} sentence representations.
\newblock In {\em Proceedings of the 59th Annual Meeting of the Association for
  Computational Linguistics and the 11th International Joint Conference on
  Natural Language Processing (Volume 1: Long Papers)}, pages 2528--2540,
  Online, August 2021. Association for Computational Linguistics.

\bibitem{kim2021vilt}
Wonjae Kim, Bokyung Son, and Ildoo Kim.
\newblock Vilt: Vision-and-language transformer without convolution or region
  supervision.
\newblock In {\em International Conference on Machine Learning}, pages
  5583--5594. PMLR, 2021.

\bibitem{kiros2015skip}
Ryan Kiros, Yukun Zhu, Russ~R Salakhutdinov, Richard Zemel, Raquel Urtasun,
  Antonio Torralba, and Sanja Fidler.
\newblock Skip-thought vectors.
\newblock {\em Advances in neural information processing systems}, 28, 2015.

\bibitem{krizhevsky2009learning}
A~Krizhevsky.
\newblock Learning multiple layers of features from tiny images.
\newblock {\em Master's thesis, University of Tront}, 2009.

\bibitem{li-etal-2020-sentence}
Bohan Li, Hao Zhou, Junxian He, Mingxuan Wang, Yiming Yang, and Lei Li.
\newblock On the sentence embeddings from pre-trained language models.
\newblock In {\em Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 9119--9130, Online, November
  2020. Association for Computational Linguistics.

\bibitem{liu-etal-2021-dialoguecse}
Che Liu, Rui Wang, Jinghua Liu, Jian Sun, Fei Huang, and Luo Si.
\newblock {D}ialogue{CSE}: Dialogue-based contrastive learning of sentence
  embeddings.
\newblock In {\em Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, pages 2396--2406, Online and Punta Cana,
  Dominican Republic, November 2021. Association for Computational Linguistics.

\bibitem{lu202012}
Jiasen Lu, Vedanuj Goswami, Marcus Rohrbach, Devi Parikh, and Stefan Lee.
\newblock 12-in-1: Multi-task vision and language representation learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10437--10446, 2020.

\bibitem{lu2021fpt}
Kevin Lu, Aditya Grover, Pieter Abbeel, and Igor Mordatch.
\newblock Pretrained transformers as universal computation engines.
\newblock {\em arXiv preprint arXiv:2103.05247}, 2021.

\bibitem{SLIP}
Norman Mu, Alexander Kirillov, David~A. Wagner, and Saining Xie.
\newblock {SLIP:} self-supervision meets language-image pre-training.
\newblock {\em CoRR}, abs/2112.12750, 2021.

\bibitem{nie-etal-2020-adversarial}
Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, and Douwe
  Kiela.
\newblock Adversarial {NLI}: A new benchmark for natural language
  understanding.
\newblock In {\em Proceedings of the 58th Annual Meeting of the Association for
  Computational Linguistics}. Association for Computational Linguistics, 2020.

\bibitem{pagliardini-etal-2018-unsupervised}
Matteo Pagliardini, Prakhar Gupta, and Martin Jaggi.
\newblock Unsupervised learning of sentence embeddings using compositional
  n-gram features.
\newblock In {\em Proceedings of the 2018 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long Papers)}, pages 528--540, New Orleans,
  Louisiana, June 2018. Association for Computational Linguistics.

\bibitem{panayotov2015librispeech}
Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur.
\newblock Librispeech: an asr corpus based on public domain audio books.
\newblock In {\em 2015 IEEE international conference on acoustics, speech and
  signal processing (ICASSP)}, pages 5206--5210. IEEE, 2015.

\bibitem{pang2004sentimental}
Bo~Pang and Lillian Lee.
\newblock A sentimental education: sentiment analysis using subjectivity
  summarization based on minimum cuts.
\newblock In {\em Proceedings of the 42nd Annual Meeting on Association for
  Computational Linguistics}, pages 271--es, 2004.

\bibitem{pang2005seeing}
Bo~Pang and Lillian Lee.
\newblock Seeing stars: exploiting class relationships for sentiment
  categorization with respect to rating scales.
\newblock In {\em Proceedings of the 43rd Annual Meeting on Association for
  Computational Linguistics}, pages 115--124, 2005.

\bibitem{poerner-etal-2020-sentence}
Nina Poerner, Ulli Waltinger, and Hinrich Sch{\"u}tze.
\newblock Sentence meta-embeddings for unsupervised semantic textual
  similarity.
\newblock In {\em Proceedings of the 58th Annual Meeting of the Association for
  Computational Linguistics}, pages 7027--7034, Online, July 2020. Association
  for Computational Linguistics.

\bibitem{qqp}
QQP.
\newblock https://www.quora.com/q/quoradata/.
\newblock In {\em Quora}, 2022.

\bibitem{CLIP}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  Gretchen Krueger, and Ilya Sutskever.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In {\em Proceedings of the 38th International Conference on Machine
  Learning, {ICML} 2021, 18-24 July 2021, Virtual Event}, volume 139 of {\em
  Proceedings of Machine Learning Research}, pages 8748--8763. {PMLR}, 2021.

\bibitem{reimers-gurevych-2020-making}
Nils Reimers and Iryna Gurevych.
\newblock Making monolingual sentence embeddings multilingual using knowledge
  distillation.
\newblock In {\em Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 4512--4525, Online, November
  2020. Association for Computational Linguistics.

\bibitem{socher2013recursive}
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher~D Manning,
  Andrew~Y Ng, and Christopher Potts.
\newblock Recursive deep models for semantic compositionality over a sentiment
  treebank.
\newblock In {\em Proceedings of the 2013 conference on empirical methods in
  natural language processing}, pages 1631--1642, 2013.

\bibitem{su2021whitening}
Jianlin Su, Jiarun Cao, Weijie Liu, and Yangyiwen Ou.
\newblock Whitening sentence representations for better semantics and faster
  retrieval.
\newblock {\em arXiv preprint arXiv:2103.15316}, 2021.

\bibitem{su2019vl}
Weijie Su, Xizhou Zhu, Yue Cao, Bin Li, Lewei Lu, Furu Wei, and Jifeng Dai.
\newblock Vl-bert: Pre-training of generic visual-linguistic representations.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{tian2019contrastive}
Yonglong Tian, Dilip Krishnan, and Phillip Isola.
\newblock Contrastive multiview coding.
\newblock In Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm,
  editors, {\em Computer Vision -- ECCV 2020}, pages 776--794, Cham, 2020.
  Springer International Publishing.

\bibitem{tian2020makes}
Yonglong Tian, Chen Sun, Ben Poole, Dilip Krishnan, Cordelia Schmid, and
  Phillip Isola.
\newblock What makes for good views for contrastive learning.
\newblock In {\em NeurIPS}, 2020.

\bibitem{tsukagoshi-etal-2021-defsent}
Hayato Tsukagoshi, Ryohei Sasano, and Koichi Takeda.
\newblock {D}ef{S}ent: Sentence embeddings using definition sentences.
\newblock In {\em Proceedings of the 59th Annual Meeting of the Association for
  Computational Linguistics and the 11th International Joint Conference on
  Natural Language Processing (Volume 2: Short Papers)}, pages 411--418,
  Online, August 2021. Association for Computational Linguistics.

\bibitem{wang-etal-2021-tsdae-using}
Kexin Wang, Nils Reimers, and Iryna Gurevych.
\newblock {TSDAE}: Using transformer-based sequential denoising auto-encoderfor
  unsupervised sentence embedding learning.
\newblock In {\em Findings of the Association for Computational Linguistics:
  EMNLP 2021}, pages 671--688, Punta Cana, Dominican Republic, November 2021.
  Association for Computational Linguistics.

\bibitem{wang2020hypersphere}
Tongzhou Wang and Phillip Isola.
\newblock Understanding contrastive representation learning through alignment
  and uniformity on the hypersphere.
\newblock In {\em International Conference on Machine Learning}, pages
  9929--9939. PMLR, 2020.

\bibitem{warstadt2019neural}
Alex Warstadt, Amanpreet Singh, and Samuel~R Bowman.
\newblock Neural network acceptability judgments.
\newblock {\em Transactions of the Association for Computational Linguistics},
  7, 2019.

\bibitem{wiebe2005annotating}
Janyce Wiebe, Theresa Wilson, and Claire Cardie.
\newblock Annotating expressions of opinions and emotions in language.
\newblock {\em Language resources and evaluation}, 39(2):165--210, 2005.

\bibitem{wieting2018paranmt}
John Wieting and Kevin Gimpel.
\newblock Paranmt-50m: Pushing the limits of paraphrastic sentence embeddings
  with millions of machine translations.
\newblock In {\em Proceedings of the 56th Annual Meeting of the Association for
  Computational Linguistics (Volume 1: Long Papers)}, pages 451--462, 2018.

\bibitem{williams2018broad}
Adina Williams, Nikita Nangia, and Samuel~R Bowman.
\newblock A broad-coverage challenge corpus for sentence understanding through
  inference.
\newblock In {\em 2018 Conference of the North American Chapter of the
  Association for Computational Linguistics: Human Language Technologies, NAACL
  HLT 2018}, pages 1112--1122. Association for Computational Linguistics (ACL),
  2018.

\bibitem{wu2018unsupervised}
Zhirong Wu, Yuanjun Xiong, X~Yu Stella, and Dahua Lin.
\newblock Unsupervised feature learning via non-parametric instance
  discrimination.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2018.

\bibitem{wu2020clear}
Zhuofeng Wu, Sinong Wang, Jiatao Gu, Madian Khabsa, Fei Sun, and Hao Ma.
\newblock Clear: Contrastive learning for sentence representation.
\newblock {\em arXiv preprint arXiv:2012.15466}, 2020.

\bibitem{xiong2020loco}
Yuwen Xiong, Mengye Ren, and Raquel Urtasun.
\newblock Loco: Local contrastive representation learning.
\newblock {\em Advances in neural information processing systems},
  33:11142--11153, 2020.

\bibitem{yang2021auto}
Xu~Yang, Chongyang Gao, Hanwang Zhang, and Jianfei Cai.
\newblock Auto-parsing network for image captioning and visual question
  answering.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 2197--2207, 2021.

\bibitem{flickr30k}
Peter Young, Alice Lai, Micah Hodosh, and Julia Hockenmaier.
\newblock From image descriptions to visual denotations: New similarity metrics
  for semantic inference over event descriptions.
\newblock {\em TACL}, 2:67--78, 2014.

\bibitem{zhang-etal-2022-mcse}
Miaoran Zhang, Marius Mosbach, David Adelani, Michael Hedderich, and Dietrich
  Klakow.
\newblock {MCSE}: {M}ultimodal contrastive learning of sentence embeddings.
\newblock In {\em Proceedings of the 2022 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 5959--5969, Seattle, United States, July 2022.
  Association for Computational Linguistics.

\bibitem{zhang-etal-2020-unsupervised}
Yan Zhang, Ruidan He, Zuozhu Liu, Kwan~Hui Lim, and Lidong Bing.
\newblock An unsupervised sentence embedding method by mutual information
  maximization.
\newblock In {\em Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 1601--1610, Online, November
  2020. Association for Computational Linguistics.

\bibitem{zhou-etal-2022-debiased}
Kun Zhou, Beichen Zhang, Xin Zhao, and Ji-Rong Wen.
\newblock Debiased contrastive learning of unsupervised sentence
  representations.
\newblock In {\em Proceedings of the 60th Annual Meeting of the Association for
  Computational Linguistics (Volume 1: Long Papers)}, pages 6120--6130, Dublin,
  Ireland, May 2022. Association for Computational Linguistics.

\end{thebibliography}
