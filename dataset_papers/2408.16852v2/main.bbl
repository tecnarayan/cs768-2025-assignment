\begin{thebibliography}{10}

\bibitem{Agarwaletal16}
Alekh Agarwal, Animashree Anandkumar, Prateek Jain, and Praneeth Netrapalli.
\newblock Learning sparsely used overcomplete dictionaries via alternating minimization.
\newblock {\em SIAM Journal on Optimization}, 26(4):2775--2799, 2016.

\bibitem{Agarwaletal17}
Alekh Agarwal, Animashree Anandkumar, and Praneeth Netrapalli.
\newblock A clustering approach to learn sparsely-used overcomplete dictionaries.
\newblock {\em IEEE Transactions on Information Theory}, 63(1):575--592, 2017.

\bibitem{Aharonetal2006}
Michal Aharon, Michael Elad, and Alfred Bruckstein.
\newblock K-svd: An algorithm for designing overcomplete dictionaries for sparse representation.
\newblock {\em IEEE Transactions on Signal Processing}, 54(11):4311--4322, 2006.

\bibitem{Albertietal21}
Giovanni~S. Alberti, Ernesto~De Vito, Matti Lassas, Luca Ratti, and Matteo Santacesaria.
\newblock Learning the optimal tikhonov regularizer for inverse problems.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2021.

\bibitem{Amelunxenetal14}
Dennis Amelunxen, Martin Lotz, Michael~B. McCoy, and Joel~A. Tropp.
\newblock Living on the edge: Phase transitions in convex programs with random data.
\newblock {\em Information and Inference: A Journal of the IMA}, 3(3):224–294, 2014.

\bibitem{Aroraetal15}
Sanjeev Arora, Rong Ge, Tengyu Ma, and Ankur Moitra.
\newblock Simple, efficient, and neural algorithms for sparse coding.
\newblock {\em Conference on Learning Theory}, 2015.

\bibitem{Arridgeetal19}
Simon Arridge, Peter Maass, Ozan \"{O}ktem, and Carola-Bibiane Sch\"{o}nlieb.
\newblock Solving inverse problems using data-driven models.
\newblock {\em Acta Numerica}, 28:1--174, 2019.

\bibitem{Asimetal20}
Muhammad Asim, Max Daniels, Oscar Leong, Ali Ahmed, and Paul Hand.
\newblock Invertible generative models for inverse problems: mitigating representation error and dataset bias.
\newblock {\em Proceedings of the 37th International Conference on Machine Learning}, 2020.

\bibitem{Asim2018}
Muhammad Asim, Fahad Shamshad, and Ali Ahmed.
\newblock Blind image deconvolution using deep generative priors.
\newblock {\em IEEE Transactions on Computational Imaging}, 6:1493 -- 1506, 2018.

\bibitem{Baraketal15}
Boaz Barak, Jonathan~A. Kelner, and David Steurer.
\newblock Dictionary learning and tensor decomposition via the sum-of-squares method.
\newblock {\em Proceedings of the Forty-seventh Annual ACM Symposium on Theory of Computing}, page 143–151, 2015.

\bibitem{Behrmannetal18}
Jens Behrmann, Will Grathwohl, Ricky T.~Q. Chen, David Duvenaud, and J\"{o}rn-Henrik Jacobsen.
\newblock Invertible residual networks.
\newblock {\em International Conference on Machine Learning}, 2018.

\bibitem{BhaskarRecht13}
Badri Bhaskar and Benjamin Recht.
\newblock Atomic norm denoising with applications to line spectral estimation.
\newblock {\em IEEE Transactions on Signal Processing}, 61(23):5987–5999, 2013.

\bibitem{Boraetal17}
Ashish Bora, Ajil Jalal, Eric Price, and Alexandros Dimakis.
\newblock Compressed sensing using generative models.
\newblock {\em International Conference on Machine Learning}, 2017.

\bibitem{Braides-Gamma-Handbook}
Andrea Braides.
\newblock A handbook of {$\Gamma$}-convergence.
\newblock {\em Handbook of Differential Equations: Stationary Partial Differential Equations}, Volume 3, 2007.

\bibitem{CandesRecht09}
Emmanuel~J. Cand\`{e}s and Benjamin Recht.
\newblock Exact matrix completion via convex optimization.
\newblock {\em Foundations of Computational Mathematics}, 9(6):717–772, 2009.

\bibitem{Tao2006}
Emmanuel~J. Cand\`{e}s, Justin~K. Romberg, and Terence Tao.
\newblock Stable signal recovery from incomplete and inaccurate measurements.
\newblock {\em Communications on Pure and Applied Mathematics}, 59(8):1207--1223, 2006.

\bibitem{ChandrasekaranJordan13}
Venkat Chandrasekaran and Michael~I. Jordan.
\newblock Computational and statistical tradeoffs via convex relaxation.
\newblock {\em Proceedings of the National Academy of Sciences}, 110(13):E1181--E1190, 2013.

\bibitem{Chandrasekaranetal12a}
Venkat Chandrasekaran, Benjamin Recht, Pablo~A. Parrilo, and Alan~S. Willsky.
\newblock The convex geometry of linear inverse problems.
\newblock {\em Foundations of Computational Mathematics}, 12:805--849, 2012.

\bibitem{Charisopoulosetal21}
Vasileios Charisopoulos, Yudong Chen, Damek Davis, Mateo D\'{i}az, Lijun Ding, and Dmitriy Drusvyatskiy.
\newblock Low-rank matrix recovery with composite optimization: good conditioning and rapid convergence.
\newblock {\em Foundations of Computational Mathematics}, 21:1505–1593, 2021.

\bibitem{Chungetal23}
Hyungjin Chung, Jeongsol Kim, Michael~T. Mccann, Marc~L. Klasky, and Jong~Chul Ye.
\newblock Diffusion posterior sampling for general noisy inverse problems.
\newblock {\em International Conference on Learning Representations (ICLR)}, 2023.

\bibitem{Darasetal23}
Giannis Daras, Kulin Shah, Yuval Dagan, Aravind Gollakota, Alexandros~G. Dimakis, and Adam Klivans.
\newblock Ambient diffusion: Learning clean distributions from corrupted data.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2023.

\bibitem{Darestanietal21}
Mohammad~Zalbagi Darestani, Akshay~S. Chaudhari, and Reinhard Heckel.
\newblock Measuring robustness in deep learning based compressive sensing.
\newblock {\em International Conference on Machine Learning (ICML)}, 2021.

\bibitem{Daubechiesetal04}
Ingrid Daubechies, Michel Defrise, and Christine de~Mol.
\newblock An iterative thresholding algorithm for linear inverse problems with a sparsity constraint.
\newblock {\em Communications on Pure and Applied Mathematics}, 57(11):1413--1457, 2004.

\bibitem{DavisDrusvyatskiy19}
Damek Davis and Dmitriy Drusvyatskiy.
\newblock Stochastic model-based minimization of weakly convex functions.
\newblock {\em SIAM Journal on Optimization}, 29(1):207--239, 2019.

\bibitem{DavisDrusvyatskiy22}
Damek Davis and Dmitriy Drusvyatskiy.
\newblock Proximal methods avoid active strict saddles of weakly convex functions.
\newblock {\em Foundations of Computational Mathematics}, 22:561–606, 2022.

\bibitem{Donoho2006}
David Donoho.
\newblock For most large underdetermined systems of linear equations the minimal l1-norm solution is also the sparsest solution.
\newblock {\em Communications on Pure and Applied Mathematics}, 59(6):797--829, 2006.

\bibitem{EladSurvey10}
Michael Elad.
\newblock Sparse and redundant representations: From theory to applications in signal and image processing.
\newblock {\em Springer}, 2010.

\bibitem{Fanetal24}
Zhenghan Fan, Sam Buchanan, and Jeremias Sulam.
\newblock What's in a prior? learned proximal networks for inverse problems.
\newblock {\em International Conference on Learning Representations (ICLR)}, 2024.

\bibitem{FazelThesis}
Maryam Fazel.
\newblock Matrix rank minimization with applications.
\newblock {\em Ph.D. Thesis, Department of Electrical Engineering, Stanford University}, 2002.

\bibitem{Fengetal23}
Berthy~T. Feng, Jamie Smith, Michael Rubinstein, Huiwen Chang, Katherine~L. Bouman, and William~T. Freeman.
\newblock Score-based diffusion models as principled priors for inverse imaging.
\newblock {\em Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}, pages 10520--10531, 2023.

\bibitem{Gaoetal21}
Angela Gao, Jorge Castellanos, Yisong Yue, Zachary Ross, and Katherine Bouman.
\newblock Deepgem: Generalized expectation-maximization for blind inversion.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)}, 34:11592--11603, 2021.

\bibitem{Gaoetal23}
Angela~F. Gao, Oscar Leong, He~Sun, and Katherine~L. Bouman.
\newblock Image reconstruction without explicit priors.
\newblock {\em ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 1--5, 2023.

\bibitem{geom-tom-Gardner}
Richard~J. Gardner.
\newblock Geometric tomography.
\newblock {\em Cambridge: Cambridge University Press}, 2006.

\bibitem{Gardneretal06}
Richard~J. Gardner, Markus Kiderlen, and Peyman Milanfar.
\newblock Convergence of algorithms for reconstructing convex bodies and directional measures.
\newblock {\em The Annals of Statistics}, 34(3):1331–1374, 2006.

\bibitem{Goodfellow2014}
Ian~J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock {\em Advances in Neural Information Processing Systems}, 2014.

\bibitem{Goujonetal23}
Alexis Goujon, Sebastian Neumayer, Pakshal Bohra, Stanislas Ducotterd, and Michael Unser.
\newblock A neural-network-based convex regularizer for inverse problems.
\newblock {\em IEEE Transactions on Computational Imaging}, 9:781 -- 795, 2023.

\bibitem{Goujonetal24}
Alexis Goujon, Sebastian Neumayer, and Michael Unser.
\newblock Learning weakly convex regularizers for convergent image-reconstruction algorithms.
\newblock {\em SIAM Journal on Imaging Sciences}, 17(1):91--115, 2024.

\bibitem{Guntuboyina-opt-supp-functions}
Adityanand Guntuboyina.
\newblock Optimal rates of convergence for convex set estimation from support functions.
\newblock {\em Annals of Statistics}, 40(1):385--411, 2012.

\bibitem{Handetal2018}
Paul Hand, Oscar Leong, and Vlad Voroninski.
\newblock Phase retrieval under a generative prior.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)}, 31, 2018.

\bibitem{Handetal2024}
Paul Hand, Oscar Leong, and Vladislav Voroninski.
\newblock Compressive phase retrieval: Optimal sample complexity with deep generative priors.
\newblock {\em Communications on Pure and Applied Mathematics}, 77(2):1147--1223, 2024.

\bibitem{Hansen-starset-survey}
G.~Hansen, I.~Herburt, H.~Martini, and M.~Moszynska.
\newblock Starshaped sets.
\newblock {\em Aequationes Mathematicae}, 94:1001–1092, 2020.

\bibitem{Heckeletal2018}
Reinhard Heckel, Wen Huang, Paul Hand, and Vladislav Voroninski.
\newblock Rate-optimal denoising with deep neural networks.
\newblock {\em Information and Inference: A Journal of the IMA}, 10(4):1251–1285, 2021.

\bibitem{ShahDPR2019}
Rakib Hyder, Viraj Shah, Chinmay Hedge, and M.~Salman Asif.
\newblock Alternating phase projected gradient descent with generative priors for solving compressive phase retrieval.
\newblock {\em Proc. IEEE Int. Conf. Acoust., Speech, and Signal Processing (ICASSP)}, 2019.

\bibitem{TV-ROF}
Leonid I.Rudin, Stanley Osher, and Emad Fatemi.
\newblock Nonlinear total variation based noise removal algorithms.
\newblock {\em Physica D: Nonlinear Phenomena}, 60:259--268, 1992.

\bibitem{Jalaletal21}
Ajil Jalal, Marius Arvinte, Giannis Daras, Eric Price, Alexandros~G. Dimakis, and Jon Tamir.
\newblock Robust compressed sensing mri with deep generative priors.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2021.

\bibitem{Kingma2014}
Diederik~P. Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock {\em International Conference on Learning Representations (ICLR)}, 2014.

\bibitem{Kobleretal20}
Erich Kobler, Alexander Effland, Karl Kunisch, and Thomas Pock.
\newblock Total deep variation for linear inverse problems.
\newblock {\em IEEE Conference on Computer Vision and Pattern Recognition}, 2020.

\bibitem{Koehleretal21}
Frederic Koehler, Lijia Zhou, Danica~J. Sutherland, and Nathan Srebro.
\newblock Uniform convergence of interpolators: Gaussian width, norm bounds, and benign overfitting.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2021.

\bibitem{Kuretal20}
Gil Kur, Alexander Rakhlin, and Adityanand Guntuboyina.
\newblock On suboptimality of least squares with application to estimation of convex bodies.
\newblock {\em Conference on Learning Theory}, pages 2406--2424, 2020.

\bibitem{MNIST}
Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock {\em Proceedings of the IEEE}, 86(11):2278--2324, 1998.

\bibitem{Leongetal23}
Oscar Leong, Angela~F. Gao, He~Sun, and Katherine~L. Bouman.
\newblock Discovering structure from corruption for unsupervised image reconstruction.
\newblock {\em IEEE Transactions on Computational Imaging}, 9:992--1005, 2023.

\bibitem{Leongetal2022}
Oscar Leong, Eliza O'Reilly, Yong~Sheng Soh, and Venkat Chandrasekaran.
\newblock Optimal regularization for a data source.
\newblock {\em arXiv preprint arXiv:2212.13597}, 2022.

\bibitem{Lunzetal18}
Sebastian Lunz, Ozan Öktem, and Carola-Bibiane Schönlieb.
\newblock Adversarial regularizers in inverse problems.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)}, 31, 2018.

\bibitem{Lutwak1975}
Erwin Lutwak.
\newblock Dual mixed volumes.
\newblock {\em Pacific Journal of Mathematics}, 58(2):531--538, 1975.

\bibitem{Lutwak96}
Erwin Lutwak.
\newblock The brunn–minkowski–firey theory ii: Affine and geominimal surface areas.
\newblock {\em Advances in Mathematics}, 118(2):244 -- 294, 1996.

\bibitem{MairaletalSurvey14}
Julien Mairal, Francis Bach, and Jean Ponce.
\newblock Sparse modeling for image and vision processing.
\newblock {\em Foundations and Trends in Computer Graphics and Vision}, 8(2--3):85–283, 2014.

\bibitem{Mardani2017}
Morteza Mardani, Enhao Gong, Joseph~Y Cheng, Shreyas~S Vasanawala, Greg Zaharchuk, Lei Xing, and John~M Pauly.
\newblock Deep generative adversarial neural networks for compressive sensing mri.
\newblock {\em IEEE Transactions on Medical Imaging}, 38(1):167--179, 2019.

\bibitem{Milneetal22}
Tristan Milne, '{E}tienne Bilocq, and Adrian Nachman.
\newblock A new method for determining wasserstein 1 optimal transport maps from kantorovich potentials, with deep learning applications.
\newblock {\em arXiv preprint arXiv:2211.00820}, 2022.

\bibitem{Mukherjeeetal2021}
Subhadip Mukherjee, S\"{o}ren Dittmer, Zakhar Shumaylov, Sebastian Lunz, Ozan \"{O}ktem, and Carola-Bibiane Sch\"{o}nlieb.
\newblock Learned convex regularizers for inverse problems.
\newblock {\em arXiv preprint arXiv:2008.02839}, 2021.

\bibitem{OlshausenField96}
Bruno~A. Olshausen and David~J. Field.
\newblock Emergence of simple-cell receptive field properties by learning a sparse code for natural images.
\newblock {\em Nature}, 381(6583):607–609, 1996.

\bibitem{OlshausenField97}
Bruno~A. Olshausen and David~J. Field.
\newblock Sparse coding with an overcomplete basis set: A strategy employed by v1?
\newblock {\em Vision in Research}, 37(23):3311--3325, 1997.

\bibitem{Ongieetal20}
Gregory Ongie, Ajil Jalal, Christopher~A. Metzler, Richard~G. Baraniuk, Alexandros~G. Dimakis, and Rebecca Willett.
\newblock Deep learning techniques for inverse problems in imaging.
\newblock {\em IEEE Journal on Selected Areas in Information Theory}, 1(1):39--56, 2020.

\bibitem{OReillyTran22}
Eliza O'Reilly and Ngoc~Mai Tran.
\newblock Stochastic geometry to generalize the mondrian process.
\newblock {\em SIAM Journal on the Mathematics of Data Science}, 4(2):531--552, 2022.

\bibitem{OymakHassibi}
Samet Oymak and Babak Hassibi.
\newblock Sharp mse bounds for proximal denoising.
\newblock {\em Foundations of Computational Mathematics}, 16:965–1029, 2016.

\bibitem{Oymaketal18}
Samet Oymak, Benjamin Recht, and Mahdi Soltanolkotabi.
\newblock Sharp time-data tradeoffs for linear inverse problems.
\newblock {\em IEEE Transactions on Information Theory}, 64(6):4129--4158, 2018.

\bibitem{PlanVershynin16}
Yaniv Plan and Roman Vershynin.
\newblock The generalized lasso with non-linear observations.
\newblock {\em IEEE Transactions on Information Theory}, 62:1528--1537, 2016.

\bibitem{PlanVershyninYudovina17}
Yaniv Plan, Roman Vershynin, and Elena Yudovina.
\newblock High-dimensional estimation with geometric constraints.
\newblock {\em Information and Inference: A Journal of the IMA}, 6(1):1--40, 2017.

\bibitem{Pollard84}
David Pollard.
\newblock Convergence of stochastic processes.
\newblock {\em Springer-Verlag}, 1984.

\bibitem{polyanskiy_wu_info_theory}
Yury Polyanskiy and Yihong Wu.
\newblock {\em Information Theory: From Coding to Learning}.
\newblock Cambridge University Press, 2023.

\bibitem{Rechtetal10}
Benjamin Recht, Maryam Fazel, and Pablo~A. Parrilo.
\newblock Guaranteed minimum-rank solutions of linear matrix equations via nuclear norm minimization.
\newblock {\em SIAM Review}, 52(3):471–501, 2010.

\bibitem{romano2017RED}
Yaniv Romano, Michael Elad, and Peyman Milanfar.
\newblock The little engine that could: Regularization by denoising (red).
\newblock {\em SIAM Journal on Imaging Sciences}, 10(4):1804--1844, 2017.

\bibitem{Routetal23}
Litu Rout, Negin Raoof, Giannis Daras, Constantine Caramanis, Alexandros~G. Dimakis, and Sanjay Shakkottai.
\newblock Solving linear inverse problems provably via posterior sampling with latent diffusion models.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2023.

\bibitem{Rubinov2000}
A.M. Rubinov.
\newblock Radiant sets and their gauges.
\newblock {\em In: Quasidifferentiability and Related Topics}, 43:235--261, 2000.

\bibitem{Rudinetal92}
Leonid~I Rudin, Stanley Osher, and Emad Fatemi.
\newblock Nonlinear total variation based noise removal algorithms.
\newblock {\em Physica D: nonlinear phenomena}, 60(1-4):259--268, 1992.

\bibitem{Schnass14}
Karin Schnass.
\newblock On the identifiability of overcomplete dictionaries via the minimisation principle underlying k-svd.
\newblock {\em Applied and Computational Harmonic Analysis}, 37(3):464–491, 2014.

\bibitem{Schnass16}
Karin Schnass.
\newblock Convergence radius and sample complexity of itkm algorithms for dictionary learning.
\newblock {\em Applied and Computational Harmonic Analysis}, 45(1):22--58, 2016.

\bibitem{conv-bodies-Schneider}
Rolf Schneider.
\newblock Convex bodies: The brunn–minkowski theory.
\newblock {\em Cambridge: Cambridge University Press.}, 2013.

\bibitem{Shahetal12}
Parikshit Shah, Badri~Narayan Bhaskar, Gongguo Tang, and Benjamin Recht.
\newblock Linear system identification via atomic norm regularization.
\newblock {\em Proceedings of the 51st Annual Conference on Decision and Control}, 2012.

\bibitem{ShamshadAhmed21}
Fahad Shamshad and Ali Ahmed.
\newblock Compressed sensing-based robust phase retrieval via deep generative priors.
\newblock {\em IEEE Sensors Journal}, 21(2):2286 -- 2298, 2017.

\bibitem{Shumaylovetal2024}
Zakhar Shumaylov, Jeremy Budd, Subhadip Mukherjee, and Carola-Bibiane Sch\"{o}nlieb.
\newblock Weakly convex regularisers for inverse problems: Convergence of critical points and primal-dual optimisation.
\newblock {\em arXiv preprint arXiv:2402.01052}, 2024.

\bibitem{SohChandrasekaran}
Yong~Sheng Soh and Venkat Chandrasekaran.
\newblock Learning semidefinite regularizers.
\newblock {\em Foundations of Computational Mathematics}, 19:375--434, 2019.

\bibitem{SohChandrasekaran21}
Yong~Sheng Soh and Venkat Chandrasekaran.
\newblock Fitting tractable convex sets to support function evaluations.
\newblock {\em Discrete and Computational Geometry}, 66:510–551, 2021.

\bibitem{Soltanolkotabi19}
Mahdi Soltanolkotabi.
\newblock Structured signal recovery from quadratic measurements: Breaking sample complexity barriers via nonconvex optimization.
\newblock {\em IEEE Transactions on Information Theory}, 65(4):2374--2400, 2019.

\bibitem{Spielmanetal12}
Daniel~A. Spielman, Huan Wang, and John Wright.
\newblock Exact recovery of sparsely-used dictionaries.
\newblock {\em Conference on Learning Theory}, 23(37):1–18, 2012.

\bibitem{Tachellaetal22}
Juli\'{a}n Tachella, Dongdong Chen, and Mike Davies.
\newblock Unsupervised learning from incomplete measurements for inverse problems.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2022.

\bibitem{Tachellaetal23}
Juli\'{a}n Tachella, Dongdong Chen, and Mike Davies.
\newblock Sensing theorems for unsupervised learning in linear inverse problems.
\newblock {\em Journal of Machine Learning Research}, 24(39):1–45, 2023.

\bibitem{Tangetal13}
Gongguo Tang, Badri~Narayan Bhaskar, Parikshit Shah, and Benjamin Recht.
\newblock Compressed sensing off the grid.
\newblock {\em IEEE Transactions on Information Theory}, 59(11):7465–7490, 2013.

\bibitem{Tibshirani94}
Ryan Tibshirani.
\newblock Regression shrinkage and selection via the lasso.
\newblock {\em Journal of the Royal Statistical Society, Series B}, 58:267–288, 1994.

\bibitem{TikReg}
Andrey~Nikolayevich Tikhonov.
\newblock On stability of inverse problems.
\newblock {\em Dokl. Akad. Nauk SSSR}, 39(5):176--179, 1943.

\bibitem{Traonmilinetal-21}
Yann Traonmilin, R\'{e}mi Gribonval, and Samuel Vaiter.
\newblock A theory of optimal convex regularization for low-dimensional recovery.
\newblock {\em Information and Inference: A Journal of the IMA}, 13(2):iaae013, 2024.

\bibitem{venkatakrishnan2013pnp}
Singanallur~V Venkatakrishnan, Charles~A Bouman, and Brendt Wohlberg.
\newblock Plug-and-play priors for model based reconstruction.
\newblock In {\em 2013 IEEE Global Conference on Signal and Information Processing}, pages 945--948. IEEE, 2013.

\bibitem{Villani-OT}
C\'{e}dric Villani.
\newblock Topics in optimal transport.
\newblock {\em Providence, RI: American Mathematical Society}, 2003.

\end{thebibliography}
