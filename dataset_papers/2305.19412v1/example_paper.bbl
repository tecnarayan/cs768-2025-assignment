\begin{thebibliography}{89}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Araujo et~al.(2019)Araujo, Norris, and Sim]{araujo2019computing}
Araujo, A., Norris, W., and Sim, J.
\newblock Computing receptive fields of convolutional neural networks.
\newblock \emph{Distill}, 4\penalty0 (11):\penalty0 e21, 2019.

\bibitem[Bai et~al.(2021)Bai, Mei, Yuille, and Xie]{bai2021transformers}
Bai, Y., Mei, J., Yuille, A.~L., and Xie, C.
\newblock Are transformers more robust than cnns?
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 26831--26843, 2021.

\bibitem[Beyer et~al.(2022)Beyer, Zhai, Royer, Markeeva, Anil, and
  Kolesnikov]{beyer2022knowledge}
Beyer, L., Zhai, X., Royer, A., Markeeva, L., Anil, R., and Kolesnikov, A.
\newblock Knowledge distillation: A good teacher is patient and consistent.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  10925--10934, 2022.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.~D., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 1877--1901, 2020.

\bibitem[Chen et~al.(2021)Chen, Liu, Zhao, and Jia]{chen2021distilling}
Chen, P., Liu, S., Zhao, H., and Jia, J.
\newblock Distilling knowledge via knowledge review.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  5008--5017, 2021.

\bibitem[Chen et~al.(2023)Chen, Zhang, Jaiswal, Liu, and Wang]{chen2023sparse}
Chen, T., Zhang, Z., Jaiswal, A., Liu, S., and Wang, Z.
\newblock Sparse moe as the new dropout: Scaling dense and self-slimmable
  transformers.
\newblock \emph{arXiv preprint arXiv:2303.01610}, 2023.

\bibitem[Chen et~al.(2022)Chen, Liu, Qi, Zhang, Sun, and Jia]{chen2022scaling}
Chen, Y., Liu, J., Qi, X., Zhang, X., Sun, J., and Jia, J.
\newblock Scaling up kernels in 3d cnns.
\newblock \emph{arXiv preprint arXiv:2206.10555}, 2022.

\bibitem[Cho \& Hariharan(2019)Cho and Hariharan]{cho2019efficacy}
Cho, J.~H. and Hariharan, B.
\newblock On the efficacy of knowledge distillation.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pp.\  4794--4802, 2019.

\bibitem[Chowdhery et~al.(2022)Chowdhery, Narang, Devlin, Bosma, Mishra,
  Roberts, Barham, Chung, Sutton, Gehrmann, et~al.]{chowdhery2022palm}
Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A.,
  Barham, P., Chung, H.~W., Sutton, C., Gehrmann, S., et~al.
\newblock Palm: Scaling language modeling with pathways.
\newblock \emph{arXiv preprint arXiv:2204.02311}, 2022.

\bibitem[Cubuk et~al.(2020)Cubuk, Zoph, Shlens, and Le]{cubuk2020randaugment}
Cubuk, E.~D., Zoph, B., Shlens, J., and Le, Q.~V.
\newblock Randaugment: Practical automated data augmentation with a reduced
  search space.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition Workshops}, pp.\  702--703, 2020.

\bibitem[Dai et~al.(2022)Dai, Shi, Wang, Wu, Xing, Wang, Zhu, Lu, Zhou, Wang,
  et~al.]{dai2022demystify}
Dai, J., Shi, M., Wang, W., Wu, S., Xing, L., Wang, W., Zhu, X., Lu, L., Zhou,
  J., Wang, X., et~al.
\newblock Demystify transformers \& convolutions in modern image deep networks.
\newblock \emph{arXiv preprint arXiv:2211.05781}, 2022.

\bibitem[Ding et~al.(2021)Ding, Chen, Zhang, Han, and Ding]{ding2021repmlpnet}
Ding, X., Chen, H., Zhang, X., Han, J., and Ding, G.
\newblock Repmlpnet: Hierarchical vision mlp with re-parameterized locality.
\newblock \emph{arXiv preprint arXiv:2112.11081}, 2021.

\bibitem[Ding et~al.(2022)Ding, Zhang, Zhou, Han, Ding, and
  Sun]{ding2022scaling}
Ding, X., Zhang, X., Zhou, Y., Han, J., Ding, G., and Sun, J.
\newblock Scaling up your kernels to 31x31: Revisiting large kernel design in
  cnns.
\newblock \emph{arXiv preprint arXiv:2203.06717}, 2022.

\bibitem[Dong et~al.(2022)Dong, Bao, Chen, Zhang, Yu, Yuan, Chen, and
  Guo]{dong2022CSWin}
Dong, X., Bao, J., Chen, D., Zhang, W., Yu, N., Yuan, L., Chen, D., and Guo, B.
\newblock Cswin transformer: A general vision transformer backbone with
  cross-shaped windows.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  12124--12134, 2022.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, Uszkoreit, and
  Houlsby]{dosoViTskiy2021an}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S.,
  Uszkoreit, J., and Houlsby, N.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=YicbFdNTTy}.

\bibitem[Du et~al.(2022)Du, Huang, Dai, Tong, Lepikhin, Xu, Krikun, Zhou, Yu,
  Firat, et~al.]{du2022glam}
Du, N., Huang, Y., Dai, A.~M., Tong, S., Lepikhin, D., Xu, Y., Krikun, M.,
  Zhou, Y., Yu, A.~W., Firat, O., et~al.
\newblock Glam: Efficient scaling of language models with mixture-of-experts.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5547--5569. PMLR, 2022.

\bibitem[d’Ascoli et~al.(2021)d’Ascoli, Touvron, Leavitt, Morcos, Biroli,
  and Sagun]{d2021convit}
d’Ascoli, S., Touvron, H., Leavitt, M.~L., Morcos, A.~S., Biroli, G., and
  Sagun, L.
\newblock Convit: Improving vision transformers with soft convolutional
  inductive biases.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2286--2296. PMLR, 2021.

\bibitem[Fang et~al.(2021)Fang, Bao, Song, Wang, Xie, Shen, and
  Song]{fang2021mosaicking}
Fang, G., Bao, Y., Song, J., Wang, X., Xie, D., Shen, C., and Song, M.
\newblock Mosaicking to distill: Knowledge distillation from out-of-domain
  data.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 11920--11932, 2021.

\bibitem[Fang et~al.(2022)Fang, Mo, Wang, Song, Bei, Zhang, and
  Song]{fang2022up}
Fang, G., Mo, K., Wang, X., Song, J., Bei, S., Zhang, H., and Song, M.
\newblock Up to 100x faster data-free knowledge distillation.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~36, pp.\  6597--6604, 2022.

\bibitem[Guo et~al.(2022)Guo, Lu, Hou, Liu, Cheng, and Hu]{guo2022segnext}
Guo, M.-H., Lu, C.-Z., Hou, Q., Liu, Z., Cheng, M.-M., and Hu, S.-M.
\newblock Segnext: Rethinking convolutional attention design for semantic
  segmentation.
\newblock \emph{arXiv preprint arXiv:2209.08575}, 2022.

\bibitem[Han et~al.(2021)Han, Xiao, Wu, Guo, Xu, and Wang]{han2021transformer}
Han, K., Xiao, A., Wu, E., Guo, J., Xu, C., and Wang, Y.
\newblock Transformer in transformer.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[He et~al.(2016{\natexlab{a}})He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016{\natexlab{a}}.

\bibitem[He et~al.(2016{\natexlab{b}})He, Zhang, Ren, and Sun]{resnet}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{2016 IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pp.\  770--778, 2016{\natexlab{b}}.
\newblock \doi{10.1109/CVPR.2016.90}.

\bibitem[Hendrycks \& Dietterich(2019)Hendrycks and
  Dietterich]{hendrycks2019benchmarking}
Hendrycks, D. and Dietterich, T.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock \emph{arXiv preprint arXiv:1903.12261}, 2019.

\bibitem[Hendrycks et~al.(2021{\natexlab{a}})Hendrycks, Basart, Mu, Kadavath,
  Wang, Dorundo, Desai, Zhu, Parajuli, Guo, et~al.]{hendrycks2021many}
Hendrycks, D., Basart, S., Mu, N., Kadavath, S., Wang, F., Dorundo, E., Desai,
  R., Zhu, T., Parajuli, S., Guo, M., et~al.
\newblock The many faces of robustness: A critical analysis of
  out-of-distribution generalization.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  8340--8349, 2021{\natexlab{a}}.

\bibitem[Hendrycks et~al.(2021{\natexlab{b}})Hendrycks, Zhao, Basart,
  Steinhardt, and Song]{hendrycks2021natural}
Hendrycks, D., Zhao, K., Basart, S., Steinhardt, J., and Song, D.
\newblock Natural adversarial examples.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  15262--15271, 2021{\natexlab{b}}.

\bibitem[Heo et~al.(2019{\natexlab{a}})Heo, Kim, Yun, Park, Kwak, and
  Choi]{heo2019comprehensive}
Heo, B., Kim, J., Yun, S., Park, H., Kwak, N., and Choi, J.~Y.
\newblock A comprehensive overhaul of feature distillation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  1921--1930, 2019{\natexlab{a}}.

\bibitem[Heo et~al.(2019{\natexlab{b}})Heo, Lee, Yun, and
  Choi]{heo2019knowledge}
Heo, B., Lee, M., Yun, S., and Choi, J.~Y.
\newblock Knowledge transfer via distillation of activation boundaries formed
  by hidden neurons.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pp.\  3779--3787, 2019{\natexlab{b}}.

\bibitem[Hinton et~al.(2015)Hinton, Vinyals, Dean,
  et~al.]{hinton2015distilling}
Hinton, G., Vinyals, O., Dean, J., et~al.
\newblock Distilling the knowledge in a neural network.
\newblock \emph{arXiv preprint arXiv:1503.02531}, 2\penalty0 (7), 2015.

\bibitem[Howard et~al.(2017)Howard, Zhu, Chen, Kalenichenko, Wang, Weyand,
  Andreetto, and Adam]{howard2017mobilenets}
Howard, A.~G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T.,
  Andreetto, M., and Adam, H.
\newblock Mobilenets: Efficient convolutional neural networks for mobile vision
  applications.
\newblock \emph{arXiv preprint arXiv:1704.04861}, 2017.

\bibitem[Huang et~al.(2017)Huang, Liu, Van Der~Maaten, and
  Weinberger]{densenet}
Huang, G., Liu, Z., Van Der~Maaten, L., and Weinberger, K.~Q.
\newblock Densely connected convolutional networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  4700--4708, 2017.

\bibitem[Huang et~al.(2022{\natexlab{a}})Huang, You, Wang, Qian, and
  Xu]{huang2022knowledge}
Huang, T., You, S., Wang, F., Qian, C., and Xu, C.
\newblock Knowledge distillation from a stronger teacher.
\newblock \emph{arXiv preprint arXiv:2205.10536}, 2022{\natexlab{a}}.

\bibitem[Huang et~al.(2022{\natexlab{b}})Huang, Zhang, You, Wang, Qian, Cao,
  and Xu]{huang2022masked}
Huang, T., Zhang, Y., You, S., Wang, F., Qian, C., Cao, J., and Xu, C.
\newblock Masked distillation with receptive tokens.
\newblock \emph{arXiv preprint arXiv:2205.14589}, 2022{\natexlab{b}}.

\bibitem[Huang \& Wang(2017)Huang and Wang]{huang2017like}
Huang, Z. and Wang, N.
\newblock Like what you like: Knowledge distill via neuron selectivity
  transfer.
\newblock \emph{arXiv preprint arXiv:1707.01219}, 2017.

\bibitem[Jumper et~al.(2021)Jumper, Evans, Pritzel, Green, Figurnov,
  Ronneberger, Tunyasuvunakool, Bates, {\v{Z}}{\'\i}dek, Potapenko,
  et~al.]{jumper2021highly}
Jumper, J., Evans, R., Pritzel, A., Green, T., Figurnov, M., Ronneberger, O.,
  Tunyasuvunakool, K., Bates, R., {\v{Z}}{\'\i}dek, A., Potapenko, A., et~al.
\newblock Highly accurate protein structure prediction with alphafold.
\newblock \emph{Nature}, 596\penalty0 (7873):\penalty0 583--589, 2021.

\bibitem[Kim et~al.(2021)Kim, Choi, Jang, Lee, Jeong, and Kim]{kim2021dead}
Kim, B.~J., Choi, H., Jang, H., Lee, D.~G., Jeong, W., and Kim, S.~W.
\newblock Dead pixel test using effective receptive field.
\newblock \emph{arXiv preprint arXiv:2108.13576}, 2021.

\bibitem[Kim et~al.(2018)Kim, Park, and Kwak]{kim2018paraphrasing}
Kim, J., Park, S., and Kwak, N.
\newblock Paraphrasing complex network: Network compression via factor
  transfer.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2012imagenet}
Krizhevsky, A., Sutskever, I., and Hinton, G.~E.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock \emph{Advances in neural information processing systems}, 25, 2012.

\bibitem[Li et~al.(2019)Li, Zeng, Zhou, and Chen]{li2019edge}
Li, E., Zeng, L., Zhou, Z., and Chen, X.
\newblock Edge ai: On-demand accelerating deep neural network inference via
  edge computing.
\newblock \emph{IEEE Transactions on Wireless Communications}, 19\penalty0
  (1):\penalty0 447--457, 2019.

\bibitem[Li et~al.(2023)Li, Shetty, Kamath, Jaiswal, Jiang, Ding, and
  Kim]{li2023cancergpt}
Li, T., Shetty, S., Kamath, A., Jaiswal, A., Jiang, X., Ding, Y., and Kim, Y.
\newblock Cancergpt: Few-shot drug pair synergy prediction using large
  pre-trained language models.
\newblock \emph{arXiv preprint arXiv:2304.10946}, 2023.

\bibitem[Li et~al.(2022)Li, Chen, Dong, Tang, Wang, and Xu]{li2022spatial}
Li, Y., Chen, X., Dong, M., Tang, Y., Wang, Y., and Xu, C.
\newblock Spatial-channel token distillation for vision mlps.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  12685--12695. PMLR, 2022.

\bibitem[Liu et~al.(2022{\natexlab{a}})Liu, Chen, Chen, Chen, Xiao, Wu,
  Pechenizkiy, Mocanu, and Wang]{liu2022more}
Liu, S., Chen, T., Chen, X., Chen, X., Xiao, Q., Wu, B., Pechenizkiy, M.,
  Mocanu, D., and Wang, Z.
\newblock More convnets in the 2020s: Scaling up kernels beyond 51x51 using
  sparsity.
\newblock \emph{arXiv preprint arXiv:2207.03620}, 2022{\natexlab{a}}.

\bibitem[Liu et~al.(2021)Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and
  Guo]{liu2021swin}
Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., Lin, S., and Guo, B.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  10012--10022, 2021.

\bibitem[Liu et~al.(2022{\natexlab{b}})Liu, Hu, Lin, Yao, Xie, Wei, Ning, Cao,
  Zhang, Dong, Wei, and Guo]{liu2021swinv2}
Liu, Z., Hu, H., Lin, Y., Yao, Z., Xie, Z., Wei, Y., Ning, J., Cao, Y., Zhang,
  Z., Dong, L., Wei, F., and Guo, B.
\newblock Swin transformer v2: Scaling up capacity and resolution.
\newblock In \emph{International Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 2022{\natexlab{b}}.

\bibitem[Liu et~al.(2022{\natexlab{c}})Liu, Mao, Wu, Feichtenhofer, Darrell,
  and Xie]{liu2022convnet}
Liu, Z., Mao, H., Wu, C.-Y., Feichtenhofer, C., Darrell, T., and Xie, S.
\newblock A convnet for the 2020s.
\newblock \emph{arXiv preprint arXiv:2201.03545}, 2022{\natexlab{c}}.

\bibitem[Loshchilov \& Hutter(2019)Loshchilov and
  Hutter]{loshchilov2018decoupled}
Loshchilov, I. and Hutter, F.
\newblock Decoupled weight decay regularization.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=Bkg6RiCqY7}.

\bibitem[Luo et~al.(2016)Luo, Li, Urtasun, and Zemel]{luo2016understanding}
Luo, W., Li, Y., Urtasun, R., and Zemel, R.
\newblock Understanding the effective receptive field in deep convolutional
  neural networks.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Mao et~al.(2022)Mao, Qi, Chen, Li, Duan, Ye, He, and
  Xue]{mao2022towards}
Mao, X., Qi, G., Chen, Y., Li, X., Duan, R., Ye, S., He, Y., and Xue, H.
\newblock Towards robust vision transformer.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  12042--12051, 2022.

\bibitem[Mirzadeh et~al.(2020)Mirzadeh, Farajtabar, Li, Levine, Matsukawa, and
  Ghasemzadeh]{mirzadeh2020improved}
Mirzadeh, S.~I., Farajtabar, M., Li, A., Levine, N., Matsukawa, A., and
  Ghasemzadeh, H.
\newblock Improved knowledge distillation via teacher assistant.
\newblock In \emph{Proceedings of the AAAI conference on artificial
  intelligence}, volume~34, pp.\  5191--5198, 2020.

\bibitem[Park et~al.(2019)Park, Kim, Lu, and Cho]{park2019relational}
Park, W., Kim, D., Lu, Y., and Cho, M.
\newblock Relational knowledge distillation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  3967--3976, 2019.

\bibitem[Peng et~al.(2017)Peng, Zhang, Yu, Luo, and Sun]{peng2017large}
Peng, C., Zhang, X., Yu, G., Luo, G., and Sun, J.
\newblock Large kernel matters--improve semantic segmentation by global
  convolutional network.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  4353--4361, 2017.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and
  Chen]{ramesh2022hierarchical}
Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., and Chen, M.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock \emph{arXiv preprint arXiv:2204.06125}, 2022.

\bibitem[Romero et~al.(2014)Romero, Ballas, Kahou, Chassang, Gatta, and
  Bengio]{romero2014fitnets}
Romero, A., Ballas, N., Kahou, S.~E., Chassang, A., Gatta, C., and Bengio, Y.
\newblock Fitnets: Hints for thin deep nets.
\newblock \emph{arXiv preprint arXiv:1412.6550}, 2014.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, et~al.]{russakovsky2015imagenet}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
  Karpathy, A., Khosla, A., Bernstein, M., et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{International journal of computer vision}, 115\penalty0
  (3):\penalty0 211--252, 2015.

\bibitem[Simonyan \& Zisserman(2014)Simonyan and Zisserman]{simonyan2014very}
Simonyan, K. and Zisserman, A.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem[Szegedy et~al.(2015)Szegedy, Liu, Jia, Sermanet, Reed, Anguelov,
  Erhan, Vanhoucke, and Rabinovich]{szegedy2015going}
Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D.,
  Vanhoucke, V., and Rabinovich, A.
\newblock Going deeper with convolutions.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  1--9, 2015.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and
  Wojna]{szegedy2016rethinking}
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z.
\newblock Rethinking the inception architecture for computer vision.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  2818--2826, 2016.

\bibitem[Szegedy et~al.(2017)Szegedy, Ioffe, Vanhoucke, and
  Alemi]{szegedy2017inception}
Szegedy, C., Ioffe, S., Vanhoucke, V., and Alemi, A.~A.
\newblock Inception-v4, inception-resnet and the impact of residual connections
  on learning.
\newblock In \emph{Thirty-first AAAI conference on artificial intelligence},
  2017.

\bibitem[Touvron et~al.(2021{\natexlab{a}})Touvron, Bojanowski, Caron, Cord,
  El-Nouby, Grave, Izacard, Joulin, Synnaeve, Verbeek,
  et~al.]{touvron2021resmlp}
Touvron, H., Bojanowski, P., Caron, M., Cord, M., El-Nouby, A., Grave, E.,
  Izacard, G., Joulin, A., Synnaeve, G., Verbeek, J., et~al.
\newblock Resmlp: Feedforward networks for image classification with
  data-efficient training.
\newblock \emph{arXiv preprint arXiv:2105.03404}, 2021{\natexlab{a}}.

\bibitem[Touvron et~al.(2021{\natexlab{b}})Touvron, Cord, Douze, Massa,
  Sablayrolles, and J{\'e}gou]{touvron2021training}
Touvron, H., Cord, M., Douze, M., Massa, F., Sablayrolles, A., and J{\'e}gou,
  H.
\newblock Training data-efficient image transformers \& distillation through
  attention.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  10347--10357. PMLR, 2021{\natexlab{b}}.

\bibitem[Touvron et~al.(2021{\natexlab{c}})Touvron, Cord, Sablayrolles,
  Synnaeve, and J{\'e}gou]{touvron2021going}
Touvron, H., Cord, M., Sablayrolles, A., Synnaeve, G., and J{\'e}gou, H.
\newblock Going deeper with image transformers.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  32--42, 2021{\natexlab{c}}.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Wang et~al.(2019)Wang, Ge, Lipton, and Xing]{wang2019learning}
Wang, H., Ge, S., Lipton, Z., and Xing, E.~P.
\newblock Learning robust global representations by penalizing local predictive
  power.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Wang et~al.(2022)Wang, Bai, Zhou, and Xie]{wang2022can}
Wang, Z., Bai, Y., Zhou, Y., and Xie, C.
\newblock Can cnns be more robust than transformers?
\newblock \emph{arXiv preprint arXiv:2206.03452}, 2022.

\bibitem[Wei et~al.(2022)Wei, Hu, Xie, Zhang, Cao, Bao, Chen, and
  Guo]{wei2022contrastive}
Wei, Y., Hu, H., Xie, Z., Zhang, Z., Cao, Y., Bao, J., Chen, D., and Guo, B.
\newblock Contrastive learning rivals masked image modeling in fine-tuning via
  feature distillation.
\newblock \emph{arXiv preprint arXiv:2205.14141}, 2022.

\bibitem[Wightman(2019)]{rw2019timm}
Wightman, R.
\newblock {GitHub} repository: Pytorch image models.
\newblock \url{https://github.com/rwightman/pytorch-image-models}, 2019.

\bibitem[Wightman et~al.(2021)Wightman, Touvron, and
  J{\'e}gou]{wightman2021resnet}
Wightman, R., Touvron, H., and J{\'e}gou, H.
\newblock Resnet strikes back: An improved training procedure in timm.
\newblock \emph{arXiv preprint arXiv:2110.00476}, 2021.

\bibitem[Woo et~al.(2023)Woo, Debnath, Hu, Chen, Liu, Kweon, and
  Xie]{woo2023ConvNeXt}
Woo, S., Debnath, S., Hu, R., Chen, X., Liu, Z., Kweon, I.~S., and Xie, S.
\newblock Convnext v2: Co-designing and scaling convnets with masked
  autoencoders.
\newblock \emph{arXiv preprint arXiv:2301.00808}, 2023.

\bibitem[Xiao et~al.(2022)Xiao, Wu, Zhang, Liu, Pechenizkiy, Mocanu, and
  Mocanu]{xiao2022dynamic}
Xiao, Q., Wu, B., Zhang, Y., Liu, S., Pechenizkiy, M., Mocanu, E., and Mocanu,
  D.~C.
\newblock Dynamic sparse network for time series classification: Learning what
  to {\textquotedblleft}see{\textquotedblright}.
\newblock In Oh, A.~H., Agarwal, A., Belgrave, D., and Cho, K. (eds.),
  \emph{Advances in Neural Information Processing Systems}, 2022.
\newblock URL \url{https://openreview.net/forum?id=ZxOO5jfqSYw}.

\bibitem[Xie et~al.(2017)Xie, Girshick, Doll{\'a}r, Tu, and
  He]{xie2017aggregated}
Xie, S., Girshick, R., Doll{\'a}r, P., Tu, Z., and He, K.
\newblock Aggregated residual transformations for deep neural networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  1492--1500, 2017.

\bibitem[Xue et~al.(2021)Xue, Song, Wang, Chen, Wang, and
  Song]{xue2021kdexplainer}
Xue, M., Song, J., Wang, X., Chen, Y., Wang, X., and Song, M.
\newblock Kdexplainer: A task-oriented attention model for explaining knowledge
  distillation.
\newblock \emph{arXiv preprint arXiv:2105.04181}, 2021.

\bibitem[Yang et~al.(2019)Yang, Xie, Su, and Yuille]{yang2019snapshot}
Yang, C., Xie, L., Su, C., and Yuille, A.~L.
\newblock Snapshot distillation: Teacher-student optimization in one
  generation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  2859--2868, 2019.

\bibitem[Yang et~al.(2021)Yang, Martinez, Bulat, and
  Tzimiropoulos]{yang2021knowledge}
Yang, J., Martinez, B., Bulat, A., and Tzimiropoulos, G.
\newblock Knowledge distillation via softmax regression representation
  learning.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=ZzwDy_wiWv}.

\bibitem[Yang et~al.(2022{\natexlab{a}})Yang, Zhang, Hu, Chen, and
  Wang]{yang2022fast}
Yang, T., Zhang, H., Hu, W., Chen, C., and Wang, X.
\newblock Fast-parc: Position aware global kernel for convnets and vits.
\newblock \emph{arXiv preprint arXiv:2210.04020}, 2022{\natexlab{a}}.

\bibitem[Yang et~al.(2022{\natexlab{b}})Yang, Li, Gong, Zhang, Lao, Yuan, and
  Li]{yang2022rethinking}
Yang, Z., Li, Z., Gong, Y., Zhang, T., Lao, S., Yuan, C., and Li, Y.
\newblock Rethinking knowledge distillation via cross-entropy.
\newblock \emph{arXiv preprint arXiv:2208.10139}, 2022{\natexlab{b}}.

\bibitem[Yang et~al.(2022{\natexlab{c}})Yang, Li, Jiang, Gong, Yuan, Zhao, and
  Yuan]{yang2022focal}
Yang, Z., Li, Z., Jiang, X., Gong, Y., Yuan, Z., Zhao, D., and Yuan, C.
\newblock Focal and global knowledge distillation for detectors.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  4643--4652, 2022{\natexlab{c}}.

\bibitem[Yang et~al.(2022{\natexlab{d}})Yang, Li, Shao, Shi, Yuan, and
  Yuan]{yang2022masked}
Yang, Z., Li, Z., Shao, M., Shi, D., Yuan, Z., and Yuan, C.
\newblock Masked generative distillation.
\newblock \emph{arXiv preprint arXiv:2205.01529}, 2022{\natexlab{d}}.

\bibitem[Yang et~al.(2022{\natexlab{e}})Yang, Li, Zeng, Li, Yuan, and
  Li]{yang2022vitkd}
Yang, Z., Li, Z., Zeng, A., Li, Z., Yuan, C., and Li, Y.
\newblock Vitkd: Practical guidelines for vit feature knowledge distillation.
\newblock \emph{arXiv preprint arXiv:2209.02432}, 2022{\natexlab{e}}.

\bibitem[Yao et~al.(2023)Yao, ZHANG, Chen, Jia, and Yu]{yao2023distill}
Yao, X., ZHANG, Y., Chen, Z., Jia, J., and Yu, B.
\newblock Distill vision transformers to {CNN}s via low-rank representation
  approximation, 2023.
\newblock URL \url{https://openreview.net/forum?id=U4llPAUi4z}.

\bibitem[Yim et~al.(2017)Yim, Joo, Bae, and Kim]{yim2017gift}
Yim, J., Joo, D., Bae, J., and Kim, J.
\newblock A gift from knowledge distillation: Fast optimization, network
  minimization and transfer learning.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  4133--4141, 2017.

\bibitem[Yuan et~al.(2020)Yuan, Tay, Li, Wang, and Feng]{yuan2020revisiting}
Yuan, L., Tay, F.~E., Li, G., Wang, T., and Feng, J.
\newblock Revisiting knowledge distillation via label smoothing regularization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  3903--3911, 2020.

\bibitem[Yuan et~al.(2021)Yuan, Chen, Wang, Yu, Shi, Jiang, Tay, Feng, and
  Yan]{yuan2021tokens}
Yuan, L., Chen, Y., Wang, T., Yu, W., Shi, Y., Jiang, Z.-H., Tay, F.~E., Feng,
  J., and Yan, S.
\newblock Tokens-to-token vit: Training vision transformers from scratch on
  imagenet.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  558--567, 2021.

\bibitem[Yun et~al.(2019)Yun, Han, Oh, Chun, Choe, and Yoo]{yun2019cutmix}
Yun, S., Han, D., Oh, S.~J., Chun, S., Choe, J., and Yoo, Y.
\newblock Cutmix: Regularization strategy to train strong classifiers with
  localizable features.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pp.\  6023--6032, 2019.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and
  Komodakis]{zagoruyko2016paying}
Zagoruyko, S. and Komodakis, N.
\newblock Paying more attention to attention: Improving the performance of
  convolutional neural networks via attention transfer.
\newblock \emph{arXiv preprint arXiv:1612.03928}, 2016.

\bibitem[Zhang et~al.(2017)Zhang, Cisse, Dauphin, and
  Lopez-Paz]{zhang2017mixup}
Zhang, H., Cisse, M., Dauphin, Y.~N., and Lopez-Paz, D.
\newblock mixup: Beyond empirical risk minimization.
\newblock \emph{arXiv preprint arXiv:1710.09412}, 2017.

\bibitem[Zhang \& Tao(2020)Zhang and Tao]{zhang2020empowering}
Zhang, J. and Tao, D.
\newblock Empowering things with intelligence: a survey of the progress,
  challenges, and opportunities in artificial intelligence of things.
\newblock \emph{IEEE Internet of Things Journal}, 8\penalty0 (10):\penalty0
  7789--7817, 2020.

\bibitem[Zhao et~al.(2022)Zhao, Cui, Song, Qiu, and Liang]{zhao2022decoupled}
Zhao, B., Cui, Q., Song, R., Qiu, Y., and Liang, J.
\newblock Decoupled knowledge distillation.
\newblock \emph{arXiv preprint arXiv:2203.08679}, 2022.

\bibitem[Zhong et~al.(2020)Zhong, Zheng, Kang, Li, and Yang]{zhong2020random}
Zhong, Z., Zheng, L., Kang, G., Li, S., and Yang, Y.
\newblock Random erasing data augmentation.
\newblock In \emph{Proceedings of the AAAI conference on artificial
  intelligence}, volume~34, pp.\  13001--13008, 2020.

\bibitem[Zhou et~al.(2021)Zhou, Song, Chen, Zhou, Wang, Yuan, and
  Zhang]{zhou2021rethinking}
Zhou, H., Song, L., Chen, J., Zhou, Y., Wang, G., Yuan, J., and Zhang, Q.
\newblock Rethinking soft labels for knowledge distillation: A
  bias{\textendash}variance tradeoff perspective.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=gIHd-5X324}.

\end{thebibliography}
