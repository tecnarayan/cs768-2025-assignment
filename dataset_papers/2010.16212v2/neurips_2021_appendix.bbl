\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{GPAM{\etalchar{+}}14}

\bibitem[AGS08]{ambrosio2008gradient}
Luigi Ambrosio, Nicola Gigli, and Giuseppe Savar{\'e}.
\newblock {\em Gradient flows: in metric spaces and in the space of probability
  measures}.
\newblock Springer Science \& Business Media, 2008.

\bibitem[BBT17]{bauschkebolteteboulle2017descentlemma}
Heinz~H. Bauschke, J\'{e}r\^{o}me Bolte, and Marc Teboulle.
\newblock A descent lemma beyond {L}ipschitz gradient continuity: first-order
  methods revisited and applications.
\newblock {\em Math. Oper. Res.}, 42(2):330--348, 2017.

\bibitem[BDMP17]{brosse17a}
Nicolas Brosse, Alain Durmus, Eric Moulines, and Marcelo Pereyra.
\newblock Sampling from a log-concave distribution with compact support with
  proximal {L}angevin {M}onte {C}arlo.
\newblock In Satyen Kale and Ohad Shamir, editors, {\em Conference on Learning
  Theory, {COLT} 2017}, volume~65, pages 319--342, Amsterdam, Netherlands,
  07--10 Jul 2017. PMLR.

\bibitem[BEL18]{bubeck2018sampling}
S{\'e}bastien Bubeck, Ronen Eldan, and Joseph Lehec.
\newblock Sampling from a log-concave distribution with projected {L}angevin
  {M}onte {C}arlo.
\newblock {\em Discrete \& Computational Geometry}, 59(4):757--783, 2018.

\bibitem[Ber18]{Ber18}
Espen Bernton.
\newblock {L}angevin {M}onte {C}arlo and {JKO} splitting.
\newblock In S\'ebastien Bubeck, Vianney Perchet, and Philippe Rigollet,
  editors, {\em Proceedings of the 31st Conference On Learning Theory},
  volume~75 of {\em Proceedings of Machine Learning Research}, pages
  1777--1798. PMLR, 2018.

\bibitem[BGL14]{bakry2014markov}
Dominique Bakry, Ivan Gentil, and Michel Ledoux.
\newblock {\em Analysis and geometry of {M}arkov diffusion operators}, volume
  348 of {\em Grundlehren der Mathematischen Wissenschaften [Fundamental
  Principles of Mathematical Sciences]}.
\newblock Springer, Cham, 2014.

\bibitem[BGVV14]{brazitikosetal2014isotropiccvx}
Silouanos Brazitikos, Apostolos Giannopoulos, Petros Valettas, and
  Beatrice-Helen Vritsiou.
\newblock {\em Geometry of isotropic convex bodies}, volume 196 of {\em
  Mathematical Surveys and Monographs}.
\newblock American Mathematical Society, Providence, RI, 2014.

\bibitem[BL06]{borwein2006convex}
Jonathan~M. Borwein and Adrian~S. Lewis.
\newblock {\em Convex analysis and nonlinear optimization}, volume~3 of {\em
  CMS Books in Mathematics/Ouvrages de Math\'{e}matiques de la SMC}.
\newblock Springer, New York, second edition, 2006.
\newblock Theory and examples.

\bibitem[BNJ03]{blei2003latent}
David~M. Blei, Andrew~Y. Ng, and Michael~I. Jordan.
\newblock Latent {D}irichlet allocation.
\newblock {\em Journal of Machine Learning Research}, 3(Jan):993--1022, 2003.

\bibitem[Bre67]{bregman1967relaxation}
Lev~M. Bregman.
\newblock The relaxation method of finding the common point of convex sets and
  its application to the solution of problems in convex programming.
\newblock {\em USSR Computational Mathematics and Mathematical Physics},
  7(3):200--217, 1967.

\bibitem[Bub15]{bubeck2015convex}
Sébastien Bubeck.
\newblock Convex optimization: algorithms and complexity.
\newblock {\em Foundations and Trends® in Machine Learning}, 8(3-4):231--357,
  2015.

\bibitem[CB18]{cheng2018langevin}
Xiang Cheng and Peter Bartlett.
\newblock Convergence of {L}angevin {MCMC} in {KL}-divergence.
\newblock In {\em Algorithmic Learning Theory 2018}, volume~83 of {\em Proc.
  Mach. Learn. Res. (PMLR)}, page~26. Proceedings of Machine Learning Research
  PMLR, 2018.

\bibitem[CCBJ18]{cheng2017underdamped}
Xiang Cheng, Niladri~S. Chatterji, Peter~L. Bartlett, and Michael~I. Jordan.
\newblock Underdamped {L}angevin {MCMC}: a non-asymptotic analysis.
\newblock In S\'ebastien Bubeck, Vianney Perchet, and Philippe Rigollet,
  editors, {\em Proceedings of the 31st Conference On Learning Theory},
  volume~75 of {\em Proceedings of Machine Learning Research}, pages 300--323.
  PMLR, 06--09 Jul 2018.

\bibitem[CDWY18]{chen2018fast}
Yuansi Chen, Raaz Dwivedi, Martin~J. Wainwright, and Bin Yu.
\newblock Fast {MCMC} sampling algorithms on polytopes.
\newblock {\em The Journal of Machine Learning Research}, 19(1):2146--2231,
  2018.

\bibitem[CE17]{cordero2017transport}
Dario Cordero-Erausquin.
\newblock Transport inequalities for log-concave measures, quantitative forms,
  and applications.
\newblock {\em Canad. J. Math.}, 69(3):481--501, 2017.

\bibitem[CEAM{\etalchar{+}}12]{celeux2012regularization}
Gilles Celeux, Mohammed El~Anbari, Jean-Michel Marin, Christian~P. Robert,
  et~al.
\newblock Regularization in regression: comparing {B}ayesian and frequentist
  methods in a poorly informative situation.
\newblock {\em Bayesian Analysis}, 7(2):477--502, 2012.

\bibitem[CLA{\etalchar{+}}21]{chewi2020optimal}
Sinho Chewi, Chen Lu, Kwangjun Ahn, Xiang Cheng, Thibaut~Le Gouic, and Philippe
  Rigollet.
\newblock Optimal dimension dependence of the {M}etropolis-adjusted {L}angevin
  algorithm.
\newblock In Mikhail Belkin and Samory Kpotufe, editors, {\em Proceedings of
  Thirty Fourth Conference on Learning Theory}, volume 134 of {\em Proceedings
  of Machine Learning Research}, pages 1260--1300. PMLR, 15--19 Aug 2021.

\bibitem[CLGL{\etalchar{+}}20]{chewietal2020mirrorlangevin}
Sinho {Chewi}, Thibaut Le~Gouic, Chen Lu, Tyler Maunu, Philippe Rigollet, and
  Austin~J. Stromme.
\newblock Exponential ergodicity of mirror-{L}angevin diffusions.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin,
  editors, {\em Advances in Neural Information Processing Systems}, volume~33,
  pages 19573--19585. Curran Associates, Inc., 2020.

\bibitem[CT93]{chen1993convergence}
Gong Chen and Marc Teboulle.
\newblock Convergence analysis of a proximal-like minimization algorithm using
  {Bregman} functions.
\newblock {\em SIAM Journal on Optimization}, 3(3):538--543, 1993.

\bibitem[DLLW21a]{dingetal2020coordinatelangevin}
Zhiyan Ding, Qin Li, Jianfeng Lu, and Stephen~J. Wright.
\newblock Random coordinate {L}angevin {M}onte {C}arlo.
\newblock In Mikhail Belkin and Samory Kpotufe, editors, {\em Proceedings of
  Thirty Fourth Conference on Learning Theory}, volume 134 of {\em Proceedings
  of Machine Learning Research}, pages 1683--1710. PMLR, 15--19 Aug 2021.

\bibitem[DLLW21b]{dingetal2021coordinateunderdamped}
Zhiyan Ding, Qin Li, Jianfeng Lu, and Stephen~J. Wright.
\newblock Random coordinate underdamped {L}angevin {M}onte {C}arlo.
\newblock In Arindam Banerjee and Kenji Fukumizu, editors, {\em Proceedings of
  The 24th International Conference on Artificial Intelligence and Statistics},
  volume 130 of {\em Proceedings of Machine Learning Research}, pages
  2701--2709. PMLR, 13--15 Apr 2021.

\bibitem[DM{\etalchar{+}}19]{durmus2019high}
Alain Durmus, {\'E}ric Moulines, et~al.
\newblock High-dimensional {B}ayesian inference via the unadjusted {L}angevin
  algorithm.
\newblock {\em Bernoulli}, 25(4A):2854--2882, 2019.

\bibitem[DMM19]{durmus2019analysis}
Alain Durmus, Szymon Majewski, and Blazej Miasojedow.
\newblock Analysis of {L}angevin {M}onte {C}arlo via convex optimization.
\newblock {\em J. Mach. Learn. Res.}, 20:73--1, 2019.

\bibitem[DRD20]{DalRiou2020}
Arnak~S. Dalalyan and Lionel Riou-Durand.
\newblock On sampling from a log-concave density using kinetic {L}angevin
  diffusions.
\newblock {\em Bernoulli}, 26(3):1956--1988, 2020.

\bibitem[DS17]{dashtistuart2017inverse}
Masoumeh Dashti and Andrew~M. Stuart.
\newblock The {B}ayesian approach to inverse problems.
\newblock In {\em Handbook of uncertainty quantification. {V}ol. 1, 2, 3},
  pages 311--428. Springer, Cham, 2017.

\bibitem[GK96]{gyongykrylov1996strongsol}
Istv\'{a}n Gy\"{o}ngy and Nicolai Krylov.
\newblock Existence of strong solutions for {I}t\^{o}'s stochastic equations
  via approximations.
\newblock {\em Probab. Theory Related Fields}, 105(2):143--158, 1996.

\bibitem[GN20]{gustafson2020johns}
Adam Gustafson and Hariharan Narayanan.
\newblock John's walk, 2020.

\bibitem[GPAM{\etalchar{+}}14]{Gans14}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In Z.~Ghahramani, M.~Welling, C.~Cortes, N.~D. Lawrence, and K.~Q.
  Weinberger, editors, {\em Advances in Neural Information Processing Systems
  27}, pages 2672--2680. 2014.

\bibitem[GSL92]{gelfand1992bayesian}
Alan~E Gelfand, Adrian~FM Smith, and Tai-Ming Lee.
\newblock Bayesian analysis of constrained parameter and truncated data
  problems using {G}ibbs sampling.
\newblock {\em Journal of the American Statistical Association},
  87(418):523--532, 1992.

\bibitem[GWS21]{gunasekarwoodworthsrebro2020mirrorless}
Suriya Gunasekar, Blake Woodworth, and Nathan Srebro.
\newblock Mirrorless mirror descent: a natural derivation of mirror descent.
\newblock In Arindam Banerjee and Kenji Fukumizu, editors, {\em Proceedings of
  The 24th International Conference on Artificial Intelligence and Statistics},
  volume 130 of {\em Proceedings of Machine Learning Research}, pages
  2305--2313. PMLR, 13--15 Apr 2021.

\bibitem[HKRC18]{hsieh2018mirrored}
Ya-Ping Hsieh, Ali Kavis, Paul Rolland, and Volkan Cevher.
\newblock Mirrored {L}angevin dynamics.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2878--2887, 2018.

\bibitem[JA06]{johnson2006ordinal}
Valen~E Johnson and James~H Albert.
\newblock {\em Ordinal data modeling}.
\newblock Springer Science \& Business Media, 2006.

\bibitem[JKO98]{jordan1998variational}
Richard Jordan, David Kinderlehrer, and Felix Otto.
\newblock The variational formulation of the {F}okker-{P}lanck equation.
\newblock {\em SIAM Journal on Mathematical Analysis}, 29(1):1--17, 1998.

\bibitem[JN11]{juditsky2011first}
Anatoli Juditsky and Arkadi Nemirovski.
\newblock First order methods for nonsmooth convex large-scale optimization,
  {I}: general purpose methods.
\newblock {\em Optimization for Machine Learning}, pages 121--148, 2011.

\bibitem[KM06]{klein2006survival}
John~P Klein and Melvin~L Moeschberger.
\newblock {\em Survival analysis: techniques for censored and truncated data}.
\newblock Springer Science \& Business Media, 2006.

\bibitem[KN12]{kannan2012random}
Ravindran Kannan and Hariharan Narayanan.
\newblock Random walks on polytopes and an affine interior point method for
  linear programming.
\newblock {\em Mathematics of Operations Research}, 37(1):1--20, 2012.

\bibitem[KNS16]{karimi2016linear}
H.~Karimi, J.~Nutini, and M.~Schmidt.
\newblock Linear convergence of gradient and proximal-gradient methods under
  the {P}olyak-{L}ojasiewicz condition.
\newblock In {\em Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pages 795--811. Springer, 2016.

\bibitem[LFN18]{lufreundnesterov2018relativelysmooth}
Haihao Lu, Robert~M. Freund, and Yurii Nesterov.
\newblock Relatively smooth convex optimization by first-order methods, and
  applications.
\newblock {\em SIAM J. Optim.}, 28(1):333--354, 2018.

\bibitem[LG16]{legall2016stochasticcalc}
Jean-Fran\c{c}ois Le~Gall.
\newblock {\em Brownian motion, martingales, and stochastic calculus}, volume
  274 of {\em Graduate Texts in Mathematics}.
\newblock Springer, [Cham], {F}rench edition, 2016.

\bibitem[LLV20]{laddha2020strong}
Aditi Laddha, Yin~Tat Lee, and Santosh~S. Vempala.
\newblock Strong self-concordance and sampling.
\newblock In {\em Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory
  of Computing}, pages 1212--1222, 2020.

\bibitem[LS16]{lan2016sampling}
Shiwei Lan and Babak Shahbaba.
\newblock Sampling constrained probability distributions using spherical
  augmentation.
\newblock In {\em Algorithmic Advances in Riemannian Geometry and
  Applications}, pages 25--71. Springer, 2016.

\bibitem[LTVW21]{lietal2021mirrorlangevin}
Ruilin Li, Molei Tao, Santosh~S. Vempala, and Andre Wibisono.
\newblock The mirror {L}angevin algorithm converges with vanishing bias.
\newblock {\em arXiv e-prints}, 2021.

\bibitem[LV17]{lee2017geodesic}
Yin~Tat Lee and Santosh~S. Vempala.
\newblock Geodesic walks in polytopes.
\newblock In {\em Proceedings of the 49th Annual ACM SIGACT Symposium on Theory
  of Computing}, pages 927--940, 2017.

\bibitem[LV18]{lee2018convergence}
Yin~Tat Lee and Santosh~S. Vempala.
\newblock Convergence rate of {R}iemannian {H}amiltonian {M}onte {C}arlo and
  faster polytope volume computation.
\newblock In {\em Proceedings of the 50th Annual ACM SIGACT Symposium on Theory
  of Computing}, pages 1115--1121, 2018.

\bibitem[MCC{\etalchar{+}}21]{ma2019there}
Yi-An Ma, Niladri~S. Chatterji, Xiang Cheng, Nicolas Flammarion, Peter~L.
  Bartlett, and Michael~I. Jordan.
\newblock {Is there an analog of {N}esterov acceleration for gradient-based
  {MCMC}?}
\newblock {\em Bernoulli}, 27(3):1942 -- 1992, 2021.

\bibitem[MWBG12]{martin2012newtonmcmc}
James Martin, Lucas~C. Wilcox, Carsten Burstedde, and Omar Ghattas.
\newblock A stochastic {N}ewton {MCMC} method for large-scale statistical
  inverse problems with application to seismic inversion.
\newblock {\em SIAM J. Sci. Comput.}, 34(3):A1460--A1487, 2012.

\bibitem[Nes18]{nesterov2018lectures}
Yurii Nesterov.
\newblock {\em Lectures on convex optimization}, volume 137.
\newblock Springer, 2018.

\bibitem[NN94]{nesterov1994interior}
Yurii Nesterov and Arkadii Nemirovskii.
\newblock {\em Interior-point polynomial algorithms in convex programming}.
\newblock SIAM, 1994.

\bibitem[NY83]{nemirovsky1983problem}
Arkadii~Semenovich Nemirovsky and David~Borisovich Yudin.
\newblock Problem complexity and method efficiency in optimization.
\newblock 1983.

\bibitem[Ott01]{otto2001porousmedium}
Felix Otto.
\newblock The geometry of dissipative evolution equations: the porous medium
  equation.
\newblock {\em Comm. Partial Differential Equations}, 26(1-2):101--174, 2001.

\bibitem[OV00]{ottovillani2000lsi}
F.~Otto and C.~Villani.
\newblock Generalization of an inequality by {T}alagrand and links with the
  logarithmic {S}obolev inequality.
\newblock {\em J. Funct. Anal.}, 173(2):361--400, 2000.

\bibitem[Pav14]{pavliotis2014stochastic}
Grigorios~A Pavliotis.
\newblock {\em Stochastic processes and applications: diffusion processes, the
  {F}okker-{P}lanck and {L}angevin equations}, volume~60.
\newblock Springer, 2014.

\bibitem[PBJ14]{paisley2014bayesian}
John~W. Paisley, David~M. Blei, and Michael~I. Jordan.
\newblock Bayesian nonnegative matrix factorization with stochastic variational
  inference, 2014.

\bibitem[PP14]{pakman2014exact}
Ari Pakman and Liam Paninski.
\newblock Exact {H}amiltonian {M}onte {C}arlo for truncated multivariate
  {G}aussians.
\newblock {\em Journal of Computational and Graphical Statistics},
  23(2):518--542, 2014.

\bibitem[PST12]{pillaistuartthiery2012scalingmala}
Natesh~S. Pillai, Andrew~M. Stuart, and Alexandre~H. Thi\'{e}ry.
\newblock Optimal scaling and diffusion limits for the {L}angevin algorithm in
  high dimensions.
\newblock {\em Ann. Appl. Probab.}, 22(6):2320--2356, 2012.

\bibitem[RAS15]{rassoulaghaseppalainen2015largedeviations}
Firas Rassoul-Agha and Timo Sepp\"{a}l\"{a}inen.
\newblock {\em A course on large deviations with an introduction to {G}ibbs
  measures}, volume 162 of {\em Graduate Studies in Mathematics}.
\newblock American Mathematical Society, Providence, RI, 2015.

\bibitem[RC04]{RobCas04}
C.P. Robert and G.~Casella.
\newblock {\em {Monte Carlo statistical methods}}.
\newblock Springer Verlag, 2004.

\bibitem[Roc70]{rockafellar1970convex}
R~Tyrrell Rockafellar.
\newblock {\em Convex analysis}.
\newblock Number~28. Princeton University Press, 1970.

\bibitem[RR98]{roberts1998optimal}
Gareth~O. Roberts and Jeffrey~S. Rosenthal.
\newblock Optimal scaling of discrete approximations to {L}angevin diffusions.
\newblock {\em Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 60(1):255--268, 1998.

\bibitem[San15]{santambrogio2015ot}
Filippo Santambrogio.
\newblock {\em Optimal transport for applied mathematicians}, volume~87 of {\em
  Progress in Nonlinear Differential Equations and their Applications}.
\newblock Birkh\"{a}user/Springer, Cham, 2015.
\newblock Calculus of variations, PDEs, and modeling.

\bibitem[SBCR16]{simsekli2016quasinewtonlangevin}
Umut Simsekli, Roland Badeau, A.~Taylan Cemgil, and Ga\"{e}l Richard.
\newblock Stochastic quasi-{N}ewton {L}angevin {M}onte {C}arlo.
\newblock In {\em Proceedings of the 33rd International Conference on
  International Conference on Machine Learning - Volume 48}, ICML’16, page
  642–651. JMLR.org, 2016.

\bibitem[SKL20]{salim2020proximal}
Adil Salim, Anna Korba, and Giulia Luise.
\newblock The {W}asserstein proximal gradient algorithm.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin,
  editors, {\em Advances in Neural Information Processing Systems}, volume~33,
  pages 12356--12366. Curran Associates, Inc., 2020.

\bibitem[SR20]{salim2020primal}
Adil Salim and Peter Richtarik.
\newblock Primal dual interpretation of the proximal stochastic gradient
  {L}angevin algorithm.
\newblock {\em Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Str18]{stroock2018stochasticcalc}
Daniel~W. Stroock.
\newblock {\em Elements of stochastic calculus and analysis}.
\newblock CRM Short Courses. Springer, Cham, 2018.

\bibitem[TR20]{tzenraginsky2020lazytraining}
Belinda Tzen and Maxim Raginsky.
\newblock A mean-field theory of lazy training in two-layer neural nets:
  entropic regularization and controlled {M}c{K}ean-{V}lasov dynamics.
\newblock {\em arXiv preprint arXiv:2002.01987}, 2020.

\bibitem[Tsy09]{tsybakov2009nonparametric}
Alexandre~B. Tsybakov.
\newblock {\em Introduction to nonparametric estimation}.
\newblock Springer Series in Statistics. Springer, New York, 2009.
\newblock Revised and extended from the 2004 French original, Translated by
  Vladimir Zaiats.

\bibitem[Vil03]{villani2003topics}
C\'{e}dric Villani.
\newblock {\em Topics in optimal transportation}, volume~58 of {\em Graduate
  Studies in Mathematics}.
\newblock American Mathematical Society, Providence, RI, 2003.

\bibitem[Vil09]{villani2009ot}
C\'{e}dric Villani.
\newblock {\em Optimal transport}, volume 338 of {\em Grundlehren der
  Mathematischen Wissenschaften [Fundamental Principles of Mathematical
  Sciences]}.
\newblock Springer-Verlag, Berlin, 2009.
\newblock Old and new.

\bibitem[VW19]{vempala2019langevin}
Santosh~S. Vempala and Andre Wibisono.
\newblock Rapid convergence of the unadjusted {L}angevin algorithm:
  isoperimetry suffices.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, {\em Advances in Neural
  Information Processing Systems 32}, pages 8094--8106. Curran Associates,
  Inc., 2019.

\bibitem[Wib18]{Wib18}
Andre Wibisono.
\newblock Sampling as optimization in the space of measures: the {L}angevin
  dynamics as a composite optimization problem.
\newblock In S{\'{e}}bastien Bubeck, Vianney Perchet, and Philippe Rigollet,
  editors, {\em Conference on Learning Theory, {COLT} 2018, Stockholm, Sweden,
  6-9 July 2018}, volume~75 of {\em Proceedings of Machine Learning Research},
  pages 2093--3027. {PMLR}, 2018.

\bibitem[{Wib}19]{Wib19prox}
Andre {Wibisono}.
\newblock {Proximal {L}angevin algorithm: rapid convergence under
  isoperimetry}.
\newblock {\em arXiv e-prints}, November 2019.

\bibitem[WL20]{wang2020informationnewton}
Yifei {Wang} and Wuchen {Li}.
\newblock {Information Newton's flow: second-order optimization method in
  probability space}.
\newblock {\em arXiv e-prints}, January 2020.

\bibitem[ZPFP20]{zhangetal2020wassersteinmirror}
Kelvin~Shuangjian Zhang, Gabriel Peyr\'e, Jalal Fadili, and Marcelo Pereyra.
\newblock Wasserstein control of mirror {L}angevin {M}onte {C}arlo.
\newblock In Jacob Abernethy and Shivani Agarwal, editors, {\em Conference on
  Learning Theory (COLT), 2020}, volume 125, pages 3814--3841. PMLR, 09--12 Jul
  2020.

\end{thebibliography}
