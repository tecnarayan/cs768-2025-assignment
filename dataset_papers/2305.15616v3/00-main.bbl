\begin{thebibliography}{10}

\bibitem{gori2005new}
Marco Gori, Gabriele Monfardini, and Franco Scarselli.
\newblock A new model for learning in graph domains.
\newblock In {\em Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005.}, volume~2, pages 729--734. IEEE, 2005.

\bibitem{zhou2020graph}
Jie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li, and Maosong Sun.
\newblock Graph neural networks: A review of methods and applications.
\newblock {\em AI open}, 1:57--81, 2020.

\bibitem{hamilton2017inductive}
Will Hamilton, Zhitao Ying, and Jure Leskovec.
\newblock Inductive representation learning on large graphs.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{hamilton2017representation}
William~L Hamilton, Rex Ying, and Jure Leskovec.
\newblock Representation learning on graphs: Methods and applications.
\newblock {\em arXiv preprint arXiv:1709.05584}, 2017.

\bibitem{chen2020measuring}
Deli Chen, Yankai Lin, Wei Li, Peng Li, Jie Zhou, and Xu~Sun.
\newblock Measuring and relieving the over-smoothing problem for graph neural networks from the topological view.
\newblock In {\em Proceedings of the AAAI conference on artificial intelligence}, volume~34, pages 3438--3445, 2020.

\bibitem{bronstein2021geometric}
Michael~M Bronstein, Joan Bruna, Taco Cohen, and Petar Veli{\v{c}}kovi{\'c}.
\newblock Geometric deep learning: Grids, groups, graphs, geodesics, and gauges.
\newblock {\em arXiv preprint arXiv:2104.13478}, 2021.

\bibitem{zhou2020towards}
Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, and Xia Hu.
\newblock Towards deeper graph neural networks with differentiable group normalization.
\newblock {\em Advances in neural information processing systems}, 33:4917--4928, 2020.

\bibitem{cai2020note}
Chen Cai and Yusu Wang.
\newblock A note on over-smoothing for graph neural networks.
\newblock {\em arXiv preprint arXiv:2006.13318}, 2020.

\bibitem{wang2021dissecting}
Yifei Wang, Yisen Wang, Jiansheng Yang, and Zhouchen Lin.
\newblock Dissecting the diffusion process in linear graph convolutional networks.
\newblock {\em Advances in Neural Information Processing Systems}, 34:5758--5769, 2021.

\bibitem{digiovanni2023understanding}
Francesco~Di Giovanni, James Rowbottom, Benjamin~P. Chamberlain, Thomas Markovich, and Michael~M. Bronstein.
\newblock Understanding convolution on graphs via energies, 2023.

\bibitem{trask2020enforcing}
Nathaniel Trask, Andy Huang, and Xiaozhe Hu.
\newblock Enforcing exact physics in scientific machine learning: a data-driven exterior calculus on graphs.
\newblock {\em arXiv preprint arXiv:2012.11799}, 2020.

\bibitem{velivckovic2017graph}
Petar Veli{\v{c}}kovi{\'c}, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio.
\newblock Graph attention networks.
\newblock {\em arXiv preprint arXiv:1710.10903}, 2017.

\bibitem{shukla2022scalable}
Khemraj Shukla, Mengjia Xu, Nathaniel Trask, and George~E Karniadakis.
\newblock Scalable algorithms for physics-informed neural and graph networks.
\newblock {\em Data-Centric Engineering}, 3:e24, 2022.

\bibitem{rackauckas2020universal}
Christopher Rackauckas, Yingbo Ma, Julius Martensen, Collin Warner, Kirill Zubov, Rohit Supekar, Dominic Skinner, Ali Ramadhan, and Alan Edelman.
\newblock Universal differential equations for scientific machine learning.
\newblock {\em arXiv preprint arXiv:2001.04385}, 2020.

\bibitem{brunton2016discovering}
Steven~L Brunton, Joshua~L Proctor, and J~Nathan Kutz.
\newblock Discovering governing equations from data by sparse identification of nonlinear dynamical systems.
\newblock {\em Proceedings of the national academy of sciences}, 113(15):3932--3937, 2016.

\bibitem{chen2018neural}
Ricky~TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud.
\newblock Neural ordinary differential equations.
\newblock In {\em Proceedings of the 32nd International Conference on Neural Information Processing Systems}, pages 6572--6583, 2018.

\bibitem{politorchdyn}
Michael Poli, Stefano Massaroli, Atsushi Yamashita, Hajime Asama, Jinkyoo Park, and Stefano Ermon.
\newblock Torchdyn: Implicit models and neural numerical methods in pytorch.
\newblock {\em ddd}, 2020.

\bibitem{xhonneux2020continuous}
Louis-Pascal Xhonneux, Meng Qu, and Jian Tang.
\newblock Continuous graph neural networks.
\newblock In {\em International Conference on Machine Learning}, pages 10432--10441. PMLR, 2020.

\bibitem{gu2020implicit}
Fangda Gu, Heng Chang, Wenwu Zhu, Somayeh Sojoudi, and Laurent El~Ghaoui.
\newblock Implicit graph neural networks.
\newblock {\em Advances in Neural Information Processing Systems}, 33:11984--11995, 2020.

\bibitem{Greydanus2019hnn}
Samuel Greydanus, Misko Dzamba, and Jason Yosinski.
\newblock Hamiltonian neural networks.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, {\em Advances in Neural Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.

\bibitem{finzi2020simplifying}
Marc Finzi, Ke~Alexander Wang, and Andrew~G Wilson.
\newblock Simplifying hamiltonian and lagrangian neural networks via explicit constraints.
\newblock {\em Advances in neural information processing systems}, 33:13880--13889, 2020.

\bibitem{chen2021data}
Renyi Chen and Molei Tao.
\newblock Data-driven prediction of general hamiltonian dynamics via learning exactly-symplectic maps.
\newblock In {\em International Conference on Machine Learning}, pages 1717--1727. PMLR, 2021.

\bibitem{gruverdeconstructing}
Nate Gruver, Marc~Anton Finzi, Samuel~Don Stanton, and Andrew~Gordon Wilson.
\newblock Deconstructing the inductive biases of hamiltonian neural networks.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{toth2019hamiltonian}
Peter Toth, Danilo~J Rezende, Andrew Jaegle, S{\'e}bastien Racani{\`e}re, Aleksandar Botev, and Irina Higgins.
\newblock Hamiltonian generative networks.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{zhongsymplectic}
Yaofeng~Desmond Zhong, Biswadip Dey, and Amit Chakraborty.
\newblock {Symplectic ODE-Net: Learning Hamiltonian} dynamics with control.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{lutter2018deep}
Michael Lutter, Christian Ritter, and Jan Peters.
\newblock Deep lagrangian networks: Using physics as model prior for deep learning.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{cranmer2020lagrangian}
Miles Cranmer, Sam Greydanus, Stephan Hoyer, Peter Battaglia, David Spergel, and Shirley Ho.
\newblock Lagrangian neural networks.
\newblock In {\em ICLR 2020 Workshop on Integration of Deep Neural Models and Differential Equations}, 2020.

\bibitem{guha2007metriplectic}
Partha Guha.
\newblock Metriplectic structure, leibniz dynamics and dissipative systems.
\newblock {\em Journal of Mathematical Analysis and Applications}, 326(1):121--136, 2007.

\bibitem{lee2021machine}
Kookjin Lee, Nathaniel Trask, and Panos Stinis.
\newblock Machine learning structure preserving brackets for forecasting irreversible processes.
\newblock {\em Advances in Neural Information Processing Systems}, 34:5696--5707, 2021.

\bibitem{lee2022structure}
Kookjin Lee, Nathaniel Trask, and Panos Stinis.
\newblock Structure-preserving sparse identification of nonlinear dynamics for data-driven modeling.
\newblock In {\em Mathematical and Scientific Machine Learning}, pages 65--80. PMLR, 2022.

\bibitem{zhang2022gfinns}
Zhen Zhang, Yeonjong Shin, and George Em~Karniadakis.
\newblock Gfinns: Generic formalism informed neural networks for deterministic and stochastic dynamical systems.
\newblock {\em Philosophical Transactions of the Royal Society A}, 380(2229):20210207, 2022.

\bibitem{zhong2020dissipative}
Yaofeng~Desmond Zhong, Biswadip Dey, and Amit Chakraborty.
\newblock Dissipative symoden: Encoding hamiltonian dynamics with dissipation and control into deep learning.
\newblock In {\em ICLR 2020 Workshop on Integration of Deep Neural Models and Differential Equations}, 2020.

\bibitem{desai2021port}
Shaan~A Desai, Marios Mattheakis, David Sondak, Pavlos Protopapas, and Stephen~J Roberts.
\newblock Port-hamiltonian neural networks for learning explicit time-dependent dynamical systems.
\newblock {\em Physical Review E}, 104(3):034312, 2021.

\bibitem{grmela2018generic}
Miroslav Grmela.
\newblock Generic guide to the multiscale dynamics and thermodynamics.
\newblock {\em Journal of Physics Communications}, 2(3):032001, 2018.

\bibitem{raissi2019physics}
Maziar Raissi, Paris Perdikaris, and George~E Karniadakis.
\newblock Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations.
\newblock {\em Journal of Computational physics}, 378:686--707, 2019.

\bibitem{raissi2018hidden}
Maziar Raissi and George~Em Karniadakis.
\newblock Hidden physics models: Machine learning of nonlinear partial differential equations.
\newblock {\em Journal of Computational Physics}, 357:125--141, 2018.

\bibitem{masi2022multiscale}
Filippo Masi and Ioannis Stefanou.
\newblock Multiscale modeling of inelastic materials with thermodynamics-based artificial neural networks (tann).
\newblock {\em Computer Methods in Applied Mechanics and Engineering}, 398:115190, 2022.

\bibitem{patel2022thermodynamically}
Ravi~G Patel, Indu Manickam, Nathaniel~A Trask, Mitchell~A Wood, Myoungkyu Lee, Ignacio Tomas, and Eric~C Cyr.
\newblock Thermodynamically consistent physics-informed neural networks for hyperbolic systems.
\newblock {\em Journal of Computational Physics}, 449:110754, 2022.

\bibitem{hernandez2021structure}
Quercus Hern{\'a}ndez, Alberto Bad{\'\i}as, David Gonz{\'a}lez, Francisco Chinesta, and El{\'\i}as Cueto.
\newblock Structure-preserving neural networks.
\newblock {\em Journal of Computational Physics}, 426:109950, 2021.

\bibitem{yang2019adversarial}
Yibo Yang and Paris Perdikaris.
\newblock Adversarial uncertainty quantification in physics-informed neural networks.
\newblock {\em Journal of Computational Physics}, 394:136--152, 2019.

\bibitem{zhang2019quantifying}
Dongkun Zhang, Lu~Lu, Ling Guo, and George~Em Karniadakis.
\newblock Quantifying total uncertainty in physics-informed neural networks for solving forward and inverse stochastic problems.
\newblock {\em Journal of Computational Physics}, 397:108850, 2019.

\bibitem{wang2021understanding}
Sifan Wang, Yujun Teng, and Paris Perdikaris.
\newblock Understanding and mitigating gradient flow pathologies in physics-informed neural networks.
\newblock {\em SIAM Journal on Scientific Computing}, 43(5):A3055--A3081, 2021.

\bibitem{wang2022and}
Sifan Wang, Xinling Yu, and Paris Perdikaris.
\newblock When and why pinns fail to train: A neural tangent kernel perspective.
\newblock {\em Journal of Computational Physics}, 449:110768, 2022.

\bibitem{rusch2022graph}
T~Konstantin Rusch, Ben Chamberlain, James Rowbottom, Siddhartha Mishra, and Michael Bronstein.
\newblock Graph-coupled oscillator networks.
\newblock In {\em International Conference on Machine Learning}, pages 18888--18909. PMLR, 2022.

\bibitem{choi2022gread}
Jeongwhan Choi, Seoyoung Hong, Noseong Park, and Sung-Bae Cho.
\newblock Gread: Graph neural reaction-diffusion equations.
\newblock {\em arXiv preprint arXiv:2211.14208}, 2022.

\bibitem{sanchez2019hamiltonian}
Alvaro Sanchez-Gonzalez, Victor Bapst, Kyle Cranmer, and Peter Battaglia.
\newblock Hamiltonian graph networks with ode integrators.
\newblock {\em arXiv preprint arXiv:1909.12790}, 2019.

\bibitem{bishnoienhancing}
Suresh Bishnoi, Ravinder Bhattoo, Jayadeva Jayadeva, Sayan Ranu, and NM~Anoop Krishnan.
\newblock Enhancing the inductive biases of graph neural ode for modeling physical systems.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2022.

\bibitem{hernandez2022thermodynamics}
Quercus Hernandez, Alberto Badias, Francisco Chinesta, and Elias Cueto.
\newblock Thermodynamics-informed graph neural networks.
\newblock {\em IEEE Transactions on Artificial Intelligence}, 1(01):1--1, 2022.

\bibitem{chamberlain2021grand}
Ben Chamberlain, James Rowbottom, Maria~I Gorinova, Michael Bronstein, Stefan Webb, and Emanuele Rossi.
\newblock Grand: Graph neural diffusion.
\newblock In {\em International Conference on Machine Learning}, pages 1407--1418. PMLR, 2021.

\bibitem{morrison2009thoughts}
PJ~Morrison.
\newblock Thoughts on brackets and dissipation: old and new.
\newblock In {\em Journal of Physics: Conference Series}, volume 169, page 012006. IOP Publishing, 2009.

\bibitem{knill2013dirac}
Oliver Knill.
\newblock The dirac operator of a graph, 2013.

\bibitem{jiang2011statistical}
Xiaoye Jiang, Lek-Heng Lim, Yuan Yao, and Yinyu Ye.
\newblock Statistical ranking and combinatorial hodge theory.
\newblock {\em Mathematical Programming}, 127(1):203--244, 2011.

\bibitem{bochev2006principles}
Pavel~B Bochev and James~M Hyman.
\newblock Principles of mimetic discretizations of differential operators.
\newblock In {\em Compatible spatial discretizations}, pages 89--119. Springer, 2006.

\bibitem{arnold2018finite}
Douglas~N Arnold.
\newblock {\em Finite element exterior calculus}.
\newblock SIAM, 2018.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N Gomez, \L~ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In I.~Guyon, U.~Von Luxburg, S.~Bengio, H.~Wallach, R.~Fergus, S.~Vishwanathan, and R.~Garnett, editors, {\em Advances in Neural Information Processing Systems}, volume~30. Curran Associates, Inc., 2017.

\bibitem{romero2009thermodynamically}
Ignacio Romero.
\newblock Thermodynamically consistent time-stepping algorithms for non-linear thermomechanical systems.
\newblock {\em International Journal for Numerical Methods in Engineering}, 79(6):706--732, 2023/05/14 2009.

\bibitem{todorov2012mujoco}
Emanuel Todorov, Tom Erez, and Yuval Tassa.
\newblock Mujoco: {A} physics engine for model-based control.
\newblock In {\em 2012 IEEE/RSJ international conference on intelligent robots and systems}, pages 5026--5033. IEEE, 2012.

\bibitem{mccallum2000automating}
Andrew~Kachites McCallum, Kamal Nigam, Jason Rennie, and Kristie Seymore.
\newblock Automating the construction of internet portals with machine learning.
\newblock {\em Information Retrieval}, 3:127--163, 2000.

\bibitem{sen2008collective}
Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and Tina Eliassi-Rad.
\newblock Collective classification in network data.
\newblock {\em AI magazine}, 29(3):93--93, 2008.

\bibitem{namata2012query}
Galileo Namata, Ben London, Lise Getoor, Bert Huang, and U~Edu.
\newblock Query-driven active surveying for collective classification.
\newblock In {\em 10th international workshop on mining and learning with graphs}, volume~8, page~1, 2012.

\bibitem{shchur2018pitfalls}
Oleksandr Shchur, Maximilian Mumme, Aleksandar Bojchevski, and Stephan G{\"u}nnemann.
\newblock Pitfalls of graph neural network evaluation.
\newblock {\em ArXiv}, abs/1811.05868, 2018.

\bibitem{mcauley2015image}
Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den~Hengel.
\newblock Image-based recommendations on styles and substitutes.
\newblock In {\em Proceedings of the 38th international ACM SIGIR conference on research and development in information retrieval}, pages 43--52, 2015.

\bibitem{poli2019graph}
Michael Poli, Stefano Massaroli, Junyoung Park, Atsushi Yamashita, Hajime Asama, and Jinkyoo Park.
\newblock Graph neural ordinary differential equations.
\newblock {\em arXiv preprint arXiv:1911.07532}, 2019.

\bibitem{jiang2010statistical}
Xiaoye Jiang, Lek-Heng Lim, Yuan Yao, and Yinyu Ye.
\newblock Statistical ranking and combinatorial hodge theory.
\newblock {\em Mathematical Programming}, 127(1):203--244, nov 2010.

\bibitem{bloch1996the}
Anthony Bloch, P.~S. Krishnaprasad, Jerrold~E. Marsden, and Tudor~S. Ratiu.
\newblock The euler-poincar{\'e} equations and double bracket dissipation.
\newblock {\em Communications in Mathematical Physics}, 175(1):1--42, 1996.

\bibitem{holm1998the}
Darryl~D Holm, Jerrold~E Marsden, and Tudor~S Ratiu.
\newblock The euler--poincar{\'e} equations and semidirect products with applications to continuum theories.
\newblock {\em Advances in Mathematics}, 137(1):1--81, 1998.

\bibitem{oettinger2014irreversible}
Hans~Christian Oettinger.
\newblock Irreversible dynamics, onsager-casimir symmetry, and an application to turbulence.
\newblock {\em Physical Review E}, 90(4):042121, 2014.

\bibitem{gruber2023energetically}
Anthony Gruber, Max Gunzburger, Lili Ju, and Zhu Wang.
\newblock Energetically consistent model reduction for metriplectic systems.
\newblock {\em Computer Methods in Applied Mechanics and Engineering}, 404:115709, 2023.

\bibitem{renka2006simple}
Robert~J. Renka.
\newblock A simple explanation of the sobolev gradient method.
\newblock In {\em A Simple Explanation of the Sobolev Gradient Method}, 2006.

\bibitem{yu2021repulsive}
Chris Yu, Henrik Schumacher, and Keenan Crane.
\newblock Repulsive curves.
\newblock {\em ACM Trans. Graph.}, 40(2), may 2021.

\bibitem{paszke2019pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{chen2008chaos}
Joe Chen.
\newblock Chaos from simplicity: an introduction to the double pendulum.
\newblock Technical report, University of Canterbury, 2008.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{ortega2002interconnection}
Romeo Ortega, Arjan Van Der~Schaft, Bernhard Maschke, and Gerardo Escobar.
\newblock Interconnection and damping assignment passivity-based control of port-controlled hamiltonian systems.
\newblock {\em Automatica}, 38(4):585--596, 2002.

\bibitem{brockman2016openai}
Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba.
\newblock Open{AI G}ym.
\newblock {\em arXiv preprint arXiv:1606.01540}, 2016.

\bibitem{wandb}
Lukas Biewald.
\newblock Experiment tracking with weights and biases, 2020.
\newblock Software available from wandb.com.

\end{thebibliography}
