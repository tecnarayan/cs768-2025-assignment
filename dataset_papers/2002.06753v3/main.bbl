\begin{thebibliography}{25}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Altae-Tran et~al.(2017)Altae-Tran, Ramsundar, Pappu, and
  Pande]{altae2017low}
Altae-Tran, H., Ramsundar, B., Pappu, A.~S., and Pande, V.
\newblock Low data drug discovery with one-shot learning.
\newblock \emph{ACS central science}, 3\penalty0 (4):\penalty0 283--293, 2017.

\bibitem[Bertinetto et~al.(2018)Bertinetto, Henriques, Torr, and
  Vedaldi]{bertinetto2018meta}
Bertinetto, L., Henriques, J.~F., Torr, P.~H., and Vedaldi, A.
\newblock Meta-learning with differentiable closed-form solvers.
\newblock \emph{arXiv preprint arXiv:1805.08136}, 2018.

\bibitem[Boyd et~al.(2011)Boyd, Parikh, Chu, Peleato, Eckstein,
  et~al.]{boyd2011distributed}
Boyd, S., Parikh, N., Chu, E., Peleato, B., Eckstein, J., et~al.
\newblock Distributed optimization and statistical learning via the alternating
  direction method of multipliers.
\newblock \emph{Foundations and Trends{\textregistered} in Machine learning},
  3\penalty0 (1):\penalty0 1--122, 2011.

\bibitem[Chen et~al.(2019)Chen, Liu, Kira, Wang, and Huang]{chen2019closer}
Chen, W.-Y., Liu, Y.-C., Kira, Z., Wang, Y.-C.~F., and Huang, J.-B.
\newblock A closer look at few-shot classification.
\newblock \emph{arXiv preprint arXiv:1904.04232}, 2019.

\bibitem[Dhillon et~al.(2019)Dhillon, Chaudhari, Ravichandran, and
  Soatto]{dhillon2019baseline}
Dhillon, G.~S., Chaudhari, P., Ravichandran, A., and Soatto, S.
\newblock A baseline for few-shot image classification.
\newblock \emph{arXiv preprint arXiv:1909.02729}, 2019.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{finn2017model}
Finn, C., Abbeel, P., and Levine, S.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pp.\  1126--1135. JMLR. org, 2017.

\bibitem[Frosst et~al.(2019)Frosst, Papernot, and Hinton]{frosst2019analyzing}
Frosst, N., Papernot, N., and Hinton, G.
\newblock Analyzing and improving representations with the soft nearest
  neighbor loss.
\newblock \emph{arXiv preprint arXiv:1902.01889}, 2019.

\bibitem[Goldblum et~al.(2019{\natexlab{a}})Goldblum, Fowl, and
  Goldstein]{goldblum2019robust}
Goldblum, M., Fowl, L., and Goldstein, T.
\newblock Robust few-shot learning with adversarially queried meta-learners.
\newblock \emph{arXiv preprint arXiv:1910.00982}, 2019{\natexlab{a}}.

\bibitem[Goldblum et~al.(2019{\natexlab{b}})Goldblum, Geiping, Schwarzschild,
  Moeller, and Goldstein]{goldblum2019truth}
Goldblum, M., Geiping, J., Schwarzschild, A., Moeller, M., and Goldstein, T.
\newblock Truth or backpropaganda? an empirical investigation of deep learning
  theory.
\newblock In \emph{International Conference on Learning Representations},
  2019{\natexlab{b}}.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[Huang et~al.(2019{\natexlab{a}})Huang, Larochelle, and
  Lacoste{-}Julien]{huang2019centroid}
Huang, G., Larochelle, H., and Lacoste{-}Julien, S.
\newblock Centroid networks for few-shot clustering and unsupervised few-shot
  classification.
\newblock \emph{CoRR}, abs/1902.08605, 2019{\natexlab{a}}.
\newblock URL \url{http://arxiv.org/abs/1902.08605}.

\bibitem[Huang et~al.(2019{\natexlab{b}})Huang, Emam, Goldblum, Fowl, Terry,
  Huang, and Goldstein]{huang2019understanding}
Huang, W.~R., Emam, Z., Goldblum, M., Fowl, L., Terry, J.~K., Huang, F., and
  Goldstein, T.
\newblock Understanding generalization through visualizations.
\newblock \emph{arXiv preprint arXiv:1906.03291}, 2019{\natexlab{b}}.

\bibitem[Kornblith et~al.(2019{\natexlab{a}})Kornblith, Norouzi, Lee, and
  Hinton]{kornblith2019similarity}
Kornblith, S., Norouzi, M., Lee, H., and Hinton, G.
\newblock Similarity of neural network representations revisited.
\newblock \emph{arXiv preprint arXiv:1905.00414}, 2019{\natexlab{a}}.

\bibitem[Kornblith et~al.(2019{\natexlab{b}})Kornblith, Shlens, and
  Le]{kornblith2019better}
Kornblith, S., Shlens, J., and Le, Q.~V.
\newblock Do better imagenet models transfer better?
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  2661--2671, 2019{\natexlab{b}}.

\bibitem[Lee et~al.(2019)Lee, Maji, Ravichandran, and Soatto]{lee2019meta}
Lee, K., Maji, S., Ravichandran, A., and Soatto, S.
\newblock Meta-learning with differentiable convex optimization.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  10657--10665, 2019.

\bibitem[Li et~al.(2018)Li, Xu, Taylor, Studer, and
  Goldstein]{li2018visualizing}
Li, H., Xu, Z., Taylor, G., Studer, C., and Goldstein, T.
\newblock Visualizing the loss landscape of neural nets.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  6389--6399, 2018.

\bibitem[Mika et~al.(1999)Mika, Ratsch, Weston, Scholkopf, and
  Mullers]{mika1999fisher}
Mika, S., Ratsch, G., Weston, J., Scholkopf, B., and Mullers, K.-R.
\newblock Fisher discriminant analysis with kernels.
\newblock In \emph{Neural networks for signal processing IX: Proceedings of the
  1999 IEEE signal processing society workshop (cat. no. 98th8468)}, pp.\
  41--48. Ieee, 1999.

\bibitem[Nagabandi et~al.(2018)Nagabandi, Clavera, Liu, Fearing, Abbeel,
  Levine, and Finn]{nagabandi2018learning}
Nagabandi, A., Clavera, I., Liu, S., Fearing, R.~S., Abbeel, P., Levine, S.,
  and Finn, C.
\newblock Learning to adapt in dynamic, real-world environments through
  meta-reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1803.11347}, 2018.

\bibitem[Nichol \& Schulman(2018)Nichol and Schulman]{nichol2018reptile}
Nichol, A. and Schulman, J.
\newblock Reptile: a scalable metalearning algorithm.
\newblock \emph{arXiv preprint arXiv:1803.02999}, 2:\penalty0 2, 2018.

\bibitem[Oreshkin et~al.(2018)Oreshkin, L{\'o}pez, and
  Lacoste]{oreshkin2018tadam}
Oreshkin, B., L{\'o}pez, P.~R., and Lacoste, A.
\newblock Tadam: Task dependent adaptive metric for improved few-shot learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  721--731, 2018.

\bibitem[Sainath et~al.(2013)Sainath, Kingsbury, Sindhwani, Arisoy, and
  Ramabhadran]{sainath2013low}
Sainath, T.~N., Kingsbury, B., Sindhwani, V., Arisoy, E., and Ramabhadran, B.
\newblock Low-rank matrix factorization for deep neural network training with
  high-dimensional output targets.
\newblock In \emph{2013 IEEE international conference on acoustics, speech and
  signal processing}, pp.\  6655--6659. IEEE, 2013.

\bibitem[Snell et~al.(2017)Snell, Swersky, and Zemel]{snell2017prototypical}
Snell, J., Swersky, K., and Zemel, R.
\newblock Prototypical networks for few-shot learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  4077--4087, 2017.

\bibitem[Song et~al.(2019)Song, Liu, and Qin]{song2019fast}
Song, L., Liu, J., and Qin, Y.
\newblock Fast and generalized adaptation for few-shot learning.
\newblock \emph{arXiv preprint arXiv:1911.10807}, 2019.

\bibitem[Vinyals et~al.(2016)Vinyals, Blundell, Lillicrap, Wierstra,
  et~al.]{vinyals2016matching}
Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et~al.
\newblock Matching networks for one shot learning.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  3630--3638, 2016.

\bibitem[Wang et~al.(2020)Wang, Gao, Zhao, Li, Dou, and Xu]{wang2020pay}
Wang, K., Gao, X., Zhao, Y., Li, X., Dou, D., and Xu, C.-Z.
\newblock Pay attention to features, transfer learn faster {CNN}s.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=ryxyCeHtPB}.

\end{thebibliography}
