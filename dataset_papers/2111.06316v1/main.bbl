\begin{thebibliography}{49}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Li et~al.(2011)Li, Yang, Zhang, Yan, Hu, Akagi, and
  Loizou]{li2011comparative}
Junfeng Li, Lin Yang, Jianping Zhang, Yonghong Yan, Yi~Hu, Masato Akagi, and
  Philipos~C Loizou.
\newblock Comparative intelligibility investigation of single-channel
  noise-reduction algorithms for chinese, japanese, and english.
\newblock \emph{The Journal of the Acoustical Society of America}, 129\penalty0
  (5):\penalty0 3291--3301, 2011.

\bibitem[Li et~al.(2015)Li, Deng, Haeb-Umbach, and Gong]{li2015robust}
Jinyu Li, Li~Deng, Reinhold Haeb-Umbach, and Yifan Gong.
\newblock Robust automatic speech recognition: a bridge to practical
  applications.
\newblock 2015.

\bibitem[Michelsanti and Tan(2017)]{michelsanti2017conditional}
Daniel Michelsanti and Zheng-Hua Tan.
\newblock Conditional generative adversarial networks for speech enhancement
  and noise-robust speaker verification.
\newblock \emph{arXiv preprint arXiv:1709.01703}, 2017.

\bibitem[Wang(2017)]{wang2017deep}
DeLiang Wang.
\newblock Deep learning reinvents the hearing aid.
\newblock \emph{IEEE spectrum}, 54\penalty0 (3):\penalty0 32--37, 2017.

\bibitem[Lai et~al.(2016)Lai, Chen, Wang, Lu, Tsao, and Lee]{lai2016deep}
Ying-Hui Lai, Fei Chen, Syu-Siang Wang, Xugang Lu, Yu~Tsao, and Chin-Hui Lee.
\newblock A deep denoising autoencoder approach to improving the
  intelligibility of vocoded speech in cochlear implant simulation.
\newblock \emph{IEEE Transactions on Biomedical Engineering}, 64\penalty0
  (7):\penalty0 1568--1578, 2016.

\bibitem[Wang and Chen(2018)]{wang2018supervised}
DeLiang Wang and Jitong Chen.
\newblock Supervised speech separation based on deep learning: An overview.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, 26\penalty0 (10):\penalty0 1702--1726, 2018.

\bibitem[Xu et~al.(2014{\natexlab{a}})Xu, Du, Dai, and Lee]{xu2014regression}
Yong Xu, Jun Du, Li-Rong Dai, and Chin-Hui Lee.
\newblock A regression approach to speech enhancement based on deep neural
  networks.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, 23\penalty0 (1):\penalty0 7--19, 2014{\natexlab{a}}.

\bibitem[Lu et~al.(2013)Lu, Tsao, Matsuda, and Hori]{lu2013speech}
Xugang Lu, Yu~Tsao, Shigeki Matsuda, and Chiori Hori.
\newblock Speech enhancement based on deep denoising autoencoder.
\newblock In \emph{Interspeech}, volume 2013, pages 436--440, 2013.

\bibitem[Fu et~al.(2016)Fu, Tsao, and Lu]{fu2016snr}
Szu-Wei Fu, Yu~Tsao, and Xugang Lu.
\newblock Snr-aware convolutional neural network modeling for speech
  enhancement.
\newblock In \emph{Interspeech}, pages 3768--3772, 2016.

\bibitem[Chen et~al.(2015)Chen, Watanabe, Erdogan, and Hershey]{chen2015speech}
Zhuo Chen, Shinji Watanabe, Hakan Erdogan, and John~R Hershey.
\newblock Speech enhancement and recognition using multi-task learning of long
  short-term memory recurrent neural networks.
\newblock In \emph{Sixteenth Annual Conference of the International Speech
  Communication Association}, 2015.

\bibitem[Koizumi et~al.(2020)Koizumi, Yaiabe, Delcroix, Maxuxama, and
  Takeuchi]{koizumi2020speech}
Yuma Koizumi, Kohei Yaiabe, Marc Delcroix, Yoshiki Maxuxama, and Daiki
  Takeuchi.
\newblock Speech enhancement using self-adaptation and multi-head
  self-attention.
\newblock In \emph{ICASSP 2020-2020 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pages 181--185. IEEE, 2020.

\bibitem[Tzeng et~al.(2014)Tzeng, Hoffman, Zhang, Saenko, and
  Darrell]{tzeng2014deep}
Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, and Trevor Darrell.
\newblock Deep domain confusion: Maximizing for domain invariance.
\newblock \emph{arXiv preprint arXiv:1412.3474}, 2014.

\bibitem[Sun and Saenko(2016)]{sun2016deep}
Baochen Sun and Kate Saenko.
\newblock Deep coral: Correlation alignment for deep domain adaptation.
\newblock In \emph{European conference on computer vision}, pages 443--450.
  Springer, 2016.

\bibitem[Morerio et~al.(2017)Morerio, Cavazza, and Murino]{morerio2017minimal}
Pietro Morerio, Jacopo Cavazza, and Vittorio Murino.
\newblock Minimal-entropy correlation alignment for unsupervised deep domain
  adaptation.
\newblock \emph{arXiv preprint arXiv:1711.10288}, 2017.

\bibitem[Ganin and Lempitsky(2015)]{ganin2015unsupervised}
Yaroslav Ganin and Victor Lempitsky.
\newblock Unsupervised domain adaptation by backpropagation.
\newblock In \emph{International conference on machine learning}, pages
  1180--1189. PMLR, 2015.

\bibitem[Ganin et~al.(2016)Ganin, Ustinova, Ajakan, Germain, Larochelle,
  Laviolette, Marchand, and Lempitsky]{ganin2016domain}
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo
  Larochelle, Fran{\c{c}}ois Laviolette, Mario Marchand, and Victor Lempitsky.
\newblock Domain-adversarial training of neural networks.
\newblock \emph{The journal of machine learning research}, 17\penalty0
  (1):\penalty0 2096--2030, 2016.

\bibitem[Tzeng et~al.(2017)Tzeng, Hoffman, Saenko, and
  Darrell]{tzeng2017adversarial}
Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell.
\newblock Adversarial discriminative domain adaptation.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 7167--7176, 2017.

\bibitem[Ganin et~al.(2017)Ganin, Ustinova, Ajakan, Germain, Larochelle,
  Laviolette, Marchand, and Lempitsky]{ganin_book}
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo
  Larochelle, Francois Laviolette, Mario Marchand, and Victor Lempitsky.
\newblock \emph{Domain-Adversarial Training of Neural Networks}.
\newblock 09 2017.

\bibitem[Liao et~al.(2018)Liao, Tsao, Lee, and Wang]{liao2018noise}
Chien-Feng Liao, Yu~Tsao, Hung-Yi Lee, and Hsin-Min Wang.
\newblock Noise adaptive speech enhancement using domain adversarial training.
\newblock \emph{arXiv preprint arXiv:1807.07501}, 2018.

\bibitem[Serdyuk et~al.(2016)Serdyuk, Audhkhasi, Brakel, Ramabhadran, Thomas,
  and Bengio]{serdyuk2016invariant}
Dmitriy Serdyuk, Kartik Audhkhasi, Phil{\'e}mon Brakel, Bhuvana Ramabhadran,
  Samuel Thomas, and Yoshua Bengio.
\newblock Invariant representations for noisy speech recognition.
\newblock \emph{arXiv preprint arXiv:1612.01928}, 2016.

\bibitem[Tang et~al.(2020)Tang, Pan, Liu, Xu, Shi, and Shi]{tang2020srda}
Zhenjie Tang, Bin Pan, Enhai Liu, Xia Xu, Tianyang Shi, and Zhenwei Shi.
\newblock Srda-net: Super-resolution domain adaptation networks for semantic
  segmentation.
\newblock \emph{arXiv e-prints}, pages arXiv--2005, 2020.

\bibitem[Liu et~al.(2020)Liu, Chan, Hsieh, Huang, Chan, and
  Tsao]{liu2020domain}
Kai-Chun Liu, Michael Chan, Chia-Yeh Hsieh, Hsiang-Yun Huang, Chia-Tai Chan,
  and Yu~Tsao.
\newblock Domain-adaptive fall detection using deep adversarial training.
\newblock \emph{arXiv preprint arXiv:2012.10911}, 2020.

\bibitem[Zhao et~al.(2018)Zhao, Zhang, Wu, Moura, Costeira, and
  Gordon]{zhao2018adversarial}
Han Zhao, Shanghang Zhang, Guanhang Wu, Jos{\'e}~MF Moura, Joao~P Costeira, and
  Geoffrey~J Gordon.
\newblock Adversarial multiple source domain adaptation.
\newblock \emph{Advances in neural information processing systems},
  31:\penalty0 8559--8570, 2018.

\bibitem[Richard et~al.(2020)Richard, de~Mathelin, H{\'e}brail, Mougeot, and
  Vayatis]{richard2020unsupervised}
Guillaume Richard, Antoine de~Mathelin, Georges H{\'e}brail, Mathilde Mougeot,
  and Nicolas Vayatis.
\newblock Unsupervised multi-source domain adaptation for regression.
\newblock 2020.

\bibitem[Villani(2008)]{villani2008optimal}
C{\'e}dric Villani.
\newblock \emph{Optimal transport: old and new}, volume 338.
\newblock Springer Science \& Business Media, 2008.

\bibitem[Peyr{\'e} et~al.(2019)Peyr{\'e}, Cuturi,
  et~al.]{peyre2019computational}
Gabriel Peyr{\'e}, Marco Cuturi, et~al.
\newblock Computational optimal transport: With applications to data science.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  11\penalty0 (5-6):\penalty0 355--607, 2019.

\bibitem[Courty et~al.(2014)Courty, Flamary, and Tuia]{courty2014domain}
Nicolas Courty, R{\'e}mi Flamary, and Devis Tuia.
\newblock Domain adaptation with regularized optimal transport.
\newblock In \emph{Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pages 274--289. Springer, 2014.

\bibitem[Courty et~al.(2016)Courty, Flamary, Tuia, and
  Rakotomamonjy]{courty2016optimal}
Nicolas Courty, R{\'e}mi Flamary, Devis Tuia, and Alain Rakotomamonjy.
\newblock Optimal transport for domain adaptation.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 39\penalty0 (9):\penalty0 1853--1865, 2016.

\bibitem[Redko et~al.(2017)Redko, Habrard, and Sebban]{redko2017theoretical}
Ievgen Redko, Amaury Habrard, and Marc Sebban.
\newblock Theoretical analysis of domain adaptation with optimal transport.
\newblock In \emph{Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pages 737--753. Springer, 2017.

\bibitem[Courty et~al.(2017)Courty, Flamary, Habrard, and
  Rakotomamonjy]{courty2017joint}
Nicolas Courty, R{\'e}mi Flamary, Amaury Habrard, and Alain Rakotomamonjy.
\newblock Joint distribution optimal transportation for domain adaptation.
\newblock \emph{arXiv preprint arXiv:1705.08848}, 2017.

\bibitem[Damodaran et~al.(2018)Damodaran, Kellenberger, Flamary, Tuia, and
  Courty]{damodaran2018deepjdot}
Bharath~Bhushan Damodaran, Benjamin Kellenberger, R{\'e}mi Flamary, Devis Tuia,
  and Nicolas Courty.
\newblock Deepjdot: Deep joint distribution optimal transport for unsupervised
  domain adaptation.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 447--463, 2018.

\bibitem[Balaji et~al.(2020)Balaji, Chellappa, and Feizi]{balaji2020robust}
Yogesh Balaji, Rama Chellappa, and Soheil Feizi.
\newblock Robust optimal transport with applications in generative modeling and
  domain adaptation.
\newblock \emph{arXiv preprint arXiv:2010.05862}, 2020.

\bibitem[Dhouib et~al.(2020)Dhouib, Redko, and Lartizien]{dhouib2020margin}
Sofien Dhouib, Ievgen Redko, and Carole Lartizien.
\newblock Margin-aware adversarial domain adaptation with optimal transport.
\newblock In \emph{International Conference on Machine Learning}, pages
  2514--2524. PMLR, 2020.

\bibitem[Xu et~al.(2014{\natexlab{b}})Xu, Du, Dai, and Lee]{xu2014cross}
Yong Xu, Jun Du, Li-Rong Dai, and Chin-Hui Lee.
\newblock Cross-language transfer learning for deep neural network based speech
  enhancement.
\newblock In \emph{The 9th International Symposium on Chinese Spoken Language
  Processing}, pages 336--340. IEEE, 2014{\natexlab{b}}.

\bibitem[Wang and Zheng(2015)]{wang2015transfer}
Dong Wang and Thomas~Fang Zheng.
\newblock Transfer learning for speech and language processing.
\newblock In \emph{2015 Asia-Pacific Signal and Information Processing
  Association Annual Summit and Conference (APSIPA)}, pages 1225--1237. IEEE,
  2015.

\bibitem[Lee et~al.(2020)Lee, Lin, Lin, Wang, and Tsao]{lee2020seril}
Chi-Chang Lee, Yu-Chen Lin, Hsuan-Tien Lin, Hsin-Min Wang, and Yu~Tsao.
\newblock Seril: Noise adaptive speech enhancement using regularization-based
  incremental learning.
\newblock \emph{arXiv preprint arXiv:2005.11760}, 2020.

\bibitem[Wang et~al.(2020)Wang, Li, Siniscalchi, and Lee]{wang2020cross}
Sicheng Wang, Wei Li, Sabato~Marco Siniscalchi, and Chin-Hui Lee.
\newblock A cross-task transfer learning approach to adapting deep speech
  enhancement models to unseen background noise using paired senone
  classifiers.
\newblock In \emph{ICASSP 2020-2020 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pages 6219--6223. IEEE, 2020.

\bibitem[Hou et~al.(2019)Hou, Xu, Chng, and Li]{hou2019domain}
Nana Hou, Chenglin Xu, Eng~Siong Chng, and Haizhou Li.
\newblock Domain adversarial training for speech enhancement.
\newblock In \emph{2019 Asia-Pacific Signal and Information Processing
  Association Annual Summit and Conference (APSIPA ASC)}, pages 667--672. IEEE,
  2019.

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and
  Bottou]{arjovsky2017wasserstein}
Martin Arjovsky, Soumith Chintala, and L{\'e}on Bottou.
\newblock Wasserstein {G}enerative {A}dversarial {N}etworks.
\newblock In \emph{International conference on machine learning}, pages
  214--223. PMLR, 2017.

\bibitem[Gulrajani et~al.(2017)Gulrajani, Ahmed, Arjovsky, Dumoulin, and
  Courville]{gulrajani2017improved}
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron
  Courville.
\newblock Improved training of {W}asserstein {GANs}.
\newblock \emph{arXiv preprint arXiv:1704.00028}, 2017.

\bibitem[Li and Hoiem(2017)]{li2017learning}
Zhizhong Li and Derek Hoiem.
\newblock Learning without forgetting.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 40\penalty0 (12):\penalty0 2935--2947, 2017.

\bibitem[Shmelkov et~al.(2017)Shmelkov, Schmid, and
  Alahari]{shmelkov2017incremental}
Konstantin Shmelkov, Cordelia Schmid, and Karteek Alahari.
\newblock Incremental learning of object detectors without catastrophic
  forgetting.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pages 3400--3409, 2017.

\bibitem[Veaux et~al.(2013)Veaux, Yamagishi, and King]{veaux2013voice}
Christophe Veaux, Junichi Yamagishi, and Simon King.
\newblock The {V}oice {B}ank {C}orpus: Design, collection and data analysis of
  a large regional accent speech database.
\newblock In \emph{2013 international conference oriental COCOSDA held jointly
  with 2013 conference on Asian spoken language research and evaluation
  (O-COCOSDA/CASLRE)}, pages 1--4. IEEE, 2013.

\bibitem[Garofolo et~al.(1988)Garofolo, Lamel, Fisher, Fiscus, and
  Pallett]{garofolo1988getting}
John~S Garofolo, Lori~F Lamel, William~M Fisher, Jonathan~G Fiscus, and David~S
  Pallett.
\newblock Getting started with the {DARPA TIMIT CD-ROM}: An acoustic phonetic
  continuous speech database.
\newblock \emph{National Institute of Standards and Technology (NIST),
  Gaithersburgh, MD}, 107:\penalty0 16, 1988.

\bibitem[Valentini-Botinhao et~al.(2016)Valentini-Botinhao, Wang, Takaki, and
  Yamagishi]{valentini2016investigating}
Cassia Valentini-Botinhao, Xin Wang, Shinji Takaki, and Junichi Yamagishi.
\newblock Investigating {RNN}-based speech enhancement methods for noise-robust
  text-to-speech.
\newblock In \emph{SSW}, pages 146--152, 2016.

\bibitem[Thiemann et~al.(2013)Thiemann, Ito, and
  Vincent]{thiemann_joachim_2013_1227121}
Joachim Thiemann, Nobutaka Ito, and Emmanuel Vincent.
\newblock {DEMAND: a collection of multi-channel recordings of acoustic noise
  in diverse environments}, June 2013.
\newblock URL \url{https://doi.org/10.5281/zenodo.1227121}.
\newblock {Supported by Inria under the Associate Team Program VERSAMUS}.

\bibitem[Pascual et~al.(2017)Pascual, Bonafonte, and Serra]{pascual2017segan}
Santiago Pascual, Antonio Bonafonte, and Joan Serra.
\newblock Segan: Speech enhancement generative adversarial network.
\newblock \emph{arXiv preprint arXiv:1703.09452}, 2017.

\bibitem[Choy et~al.(2006)Choy, Srinivasan, and Cheu]{choy2006neural}
Min~Chee Choy, Dipti Srinivasan, and Ruey~Long Cheu.
\newblock Neural networks for continuous online learning and control.
\newblock \emph{IEEE Transactions on Neural Networks}, 17\penalty0
  (6):\penalty0 1511--1531, 2006.

\bibitem[Goodfellow et~al.(2013)Goodfellow, Mirza, Xiao, Courville, and
  Bengio]{goodfellow2013empirical}
Ian~J Goodfellow, Mehdi Mirza, Da~Xiao, Aaron Courville, and Yoshua Bengio.
\newblock An empirical investigation of catastrophic forgetting in
  gradient-based neural networks.
\newblock \emph{arXiv preprint arXiv:1312.6211}, 2013.

\end{thebibliography}
