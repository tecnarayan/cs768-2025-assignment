%% For uniform look in the appendix
@string{NIPS = {NeurIPS}}
@string{NIPS = {Advances in Neural Information Processing Systems (NeurIPS)}}
@string{COLT = {COLT}}
@string{COLT = {Proceedings of the International Conference on Computational Learning Theory (COLT)}}
@string{ICML = {ICML}}
@string{ICML = {Proceedings of the International Conference on Machine Learning (ICML)}}
@string{AISTATS = {AISTATS}}
@string{AISTATS = {Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)}}
@string{JMLR = {JMLR}}
@string{JMLR = {Journal of Machine Learning Research}}
@string{NeuralComputation = {Neural Comp.}}
@string{NeuralComputation = {Neural Computation}}
@string{HUJI = {The Hebrew University}}
@string{HUJI = {The Hebrew University of Jerusalem}}
@string{UAI = {UAI}}
@string{UAI = {Proceedings of the Conference on Uncertainty in Artificial Intelligence}}
@string{PNAS = {PNAS}}
@string{PNAS = {Proceedings of the National Academy of Science}}
@string{ACML = {ACML}}
@string{ACML = {Proceedings of the Asian Conference on Machine Learning (ACML)}}
@string{ALT = {ALT}}
@string{ALT = {Proceedings of the International Conference on Algorithmic Learning Theory (ALT)}}
@string{IEEEIT = {IEEE Transactions on Information Theory}}
@string{ACMSIGKDD = {ACM SIGKDD}}
@string{ACMSIGKDD = {Proceedings of the International Conference on Knowledge Discovery and Data Mining (ACM SIGKDD)}}
@string{ACMSIGIR = {ACM SIGIR}}
@string{ACMSIGIR = {Proceedings of the Annual International ACM SIGIR Conference on Research and Development in Information Retrieval}}
@string{ACMTCBB = {IEEE/ACM Transactions on Computational Biology and Bioinformatics (TCBB)}}
@string{JMLRWCP = {JMLR W{$\&$}CP}}
@string{JMLRWCP = {JMLR Workshop and Conference Proceedings}}
@string{PMLR = {PMLR}}
@string{PMLR = {Proceedings of Machine Learning Research}}
@string{TCS = {Theoretical Computer Science}}
@string{EWRL = {European Workshop on Reinforcement Learning (EWRL)}}
@string{WWW = {Proceedings of the International Conference on World Wide Web (WWW)}}
@string{JCSS = {Journal of Computer and System Sciences}}
@string{FOCS = {Annual IEEE Symposium on Foundations of Computer Science}}
@string{FTML = {Foundations and Trends in Machine Learning}}
@string{MLJ = {Machine Learning}}
@string{EWRL = {Proceedings of the European Workshop on Reinforcement Learning (EWRL)}}
@string{STOC = {Proceedings of the Annual Symposium on the Theory of Computing (STOC)}}
@string{AAAI = {Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)}}


@article{dinh2016density,
  title={Density estimation using real nvp},
  author={Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
  journal={arXiv preprint arXiv:1605.08803},
  year={2016}
}

@inproceedings{NIPS2013_Abbasi,
 author = {Abbasi Yadkori, Yasin and Bartlett, Peter L and Kanade, Varun and Seldin, Yevgeny and Szepesvari, Csaba},
 booktitle = NIPS,
 title = {Online Learning in Markov Decision Processes with Adversarially Chosen Transition Probability Distributions},
 year = {2013}
}
pages = {},
volume = {26},

@inproceedings{tian2021online,
  title={Online learning in unknown markov games},
  author={Tian, Yi and Wang, Yuanhao and Yu, Tiancheng and Sra, Suvrit},
  booktitle=ICML,
  year={2021},
}
  pages={10279--10288},
   organization={PMLR}


@inproceedings{wu2021reinforcement,
  title={On reinforcement learning with adversarial corruption and its application to block mdp},
  author={Wu, Tianhao and Yang, Yunchang and Du, Simon and Wang, Liwei},
  booktitle={International Conference on Machine Learning},
  pages={11296--11306},
  year={2021},
  organization={PMLR}
}


@inproceedings{wei2022model,
  title={A model selection approach for corruption robust reinforcement learning},
  author={Wei, Chen-Yu and Dann, Christoph and Zimmert, Julian},
  booktitle=ICML,
  year={2022},
 
}
  pages={1043--1096},
   organization={PMLR}
   
@inproceedings{luo2022corralling,
  title={Corralling a larger band of bandits: A case study on switching regret for linear bandits},
  author={Luo, Haipeng and Zhang, Mengxiao and Zhao, Peng and Zhou, Zhi-Hua},
  booktitle=COLT,
  year={2022},
 
}
 pages={3635--3684},
  organization={PMLR}

@inproceedings{levy2018generalizing,
  title={Generalizing Hamiltonian Monte Carlo with Neural Networks},
  author={Levy, Daniel and Hoffman, Matt D and Sohl-Dickstein, Jascha},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{foster2020adapting,
  title={Adapting to misspecification in contextual bandits},
  author={Foster, Dylan J and Gentile, Claudio and Mohri, Mehryar and Zimmert, Julian},
  journal=NIPS,
  year={2020}
}
 volume={33},
  pages={11478--11489},

@article{durkan2019neural,
  title={Neural spline flows},
  author={Durkan, Conor and Bekasov, Artur and Murray, Iain and Papamakarios, George},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{papamakarios2021normalizing,
  title={Normalizing flows for probabilistic modeling and inference},
  author={Papamakarios, George and Nalisnick, Eric and Rezende, Danilo Jimenez and Mohamed, Shakir and Lakshminarayanan, Balaji},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={57},
  pages={1--64},
  year={2021}
}

@article{hoffman2014no,
  title={The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.},
  author={Hoffman, Matthew D and Gelman, Andrew and others},
  journal={J. Mach. Learn. Res.},
  volume={15},
  number={1},
  pages={1593--1623},
  year={2014}
}

@inproceedings{thune2019nonstochastic,
  title={Nonstochastic multiarmed bandits with unrestricted delays},
  author={Thune, Tobias Sommer and Cesa-Bianchi, Nicol{\`o} and Seldin, Yevgeny},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6541--6550},
  year={2019}
}

@inproceedings{cesa2016delay,
  title={Delay and cooperation in nonstochastic bandits},
  author={Cesa-Bianchi, Nicolâ€˜o and Gentile, Claudio and Mansour, Yishay and Minora, Alberto},
  booktitle={Conference on Learning Theory},
  pages={605--622},
  year={2016}
}


@InProceedings{pmlr-v151-he22a,
  title = 	 { Near-optimal Policy Optimization Algorithms for Learning Adversarial Linear Mixture MDPs },
  author =       {He, Jiafan and Zhou, Dongruo and Gu, Quanquan},
  booktitle = 	 {Proceedings of The 25th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {4259--4280},
  year = 	 {2022},
  editor = 	 {Camps-Valls, Gustau and Ruiz, Francisco J. R. and Valera, Isabel},
  volume = 	 {151},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {28--30 Mar},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v151/he22a/he22a.pdf},
  url = 	 {https://proceedings.mlr.press/v151/he22a.html},
}


@article{van2021nonstochastic,
  title={Nonstochastic Bandits and Experts with Arm-Dependent Delays},
  author={van der Hoeven, Dirk and Cesa-Bianchi, Nicol{\`o}},
  journal={arXiv preprint arXiv:2111.01589},
  year={2021}
}

@article{bistritz2021no,
  title={No Discounted-Regret Learning in Adversarial Bandits with Delays},
  author={Bistritz, Ilai and Zhou, Zhengyuan and Chen, Xi and Bambos, Nicholas and Blanchet, Jose},
  journal={arXiv preprint arXiv:2103.04550},
  year={2021}
}

@inproceedings{dudik2011efficient,
  title={Efficient optimal learning for contextual bandits},
  author={Dudik, Miroslav and Hsu, Daniel and Kale, Satyen and Karampatziakis, Nikos and Langford, John and Reyzin, Lev and Zhang, Tong},
  booktitle={Proceedings of the Twenty-Seventh Conference on Uncertainty in Artificial Intelligence},
  pages={169--178},
  year={2011}
}

@inproceedings{vernade2017stochastic,
  title={Stochastic Bandit Models for Delayed Conversions},
  author={Vernade, Claire and Capp{\'e}, Olivier and Perchet, Vianney},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  year={2017}
}

@inproceedings{pike2018bandits,
  title={Bandits with delayed, aggregated anonymous feedback},
  author={Pike-Burke, Ciara and Agrawal, Shipra and Szepesvari, Csaba and Grunewalder, Steffen},
  booktitle={International Conference on Machine Learning},
  pages={4105--4113},
  year={2018},
  organization={PMLR}
}

@article{eisenberg2008expectation,
  title={On the expectation of the maximum of IID geometric random variables},
  author={Eisenberg, Bennett},
  journal={Statistics \& Probability Letters},
  volume={78},
  number={2},
  pages={135--143},
  year={2008},
  publisher={Elsevier}
}

@inproceedings{zhou2019learning,
  title={Learning in generalized linear contextual bandits with stochastic delays},
  author={Zhou, Zhengyuan and Xu, Renyuan and Blanchet, Jose},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5197--5208},
  year={2019}
}

@inproceedings{manegueu2020stochastic,
  title={Stochastic bandits with arm-dependent delays},
  author={Gael, Manegueu Anne and Vernade, Claire and Carpentier, Alexandra and Valko, Michal},
  booktitle={International Conference on Machine Learning},
  pages={3348--3356},
  year={2020},
  organization={PMLR}
}

@article{desautels2014parallelizing,
  title={Parallelizing exploration-exploitation tradeoffs in gaussian process bandit optimization},
  author={Desautels, Thomas and Krause, Andreas and Burdick, Joel W},
  journal={Journal of Machine Learning Research},
  volume={15},
  pages={3873--3923},
  year={2014},
  publisher={Microtome Publishing}
}

@article{weinberger2002delayed,
  title={On delayed prediction of individual sequences},
  author={Weinberger, Marcelo J and Ordentlich, Erik},
  journal={IEEE Transactions on Information Theory},
  volume={48},
  number={7},
  pages={1959--1976},
  year={2002},
  publisher={IEEE}
}

@phdthesis{ziminonline,
  author       = {Zimin, Alexander}, 
  title        = {Online Learning in Markovian Decision Processes},
  school       = {Central European University},
  year         = 2013,
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{cesa2019delay,
  title={Delay and cooperation in nonstochastic bandits},
  author={Cesa-Bianchi, Nicolo and Gentile, Claudio and Mansour, Yishay},
  journal={The Journal of Machine Learning Research},
  volume={20},
  number={1},
  pages={613--650},
  year={2019},
  publisher={JMLR. org}
}

@inproceedings{jin2019learning,
  title={Learning adversarial markov decision processes with bandit feedback and unknown transition},
  author={Jin, Chi and Jin, Tiancheng and Luo, Haipeng and Sra, Suvrit and Yu, Tiancheng},
  booktitle=ICML,
  year={2020},
}
pages={4860--4869},
organization={PMLR}

@inproceedings{zanette2018problem,
  title={Problem dependent reinforcement learning bounds which can identify bandit structure in mdps},
  author={Zanette, Andrea and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={5747--5755},
  year={2018}
}

@article{auer2002nonstochastic,
  title={The nonstochastic multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Freund, Yoav and Schapire, Robert E},
  journal={SIAM journal on computing},
  volume={32},
  number={1},
  pages={48--77},
  year={2002},
  publisher={SIAM}
}

@inproceedings{cesa2018nonstochastic,
  title={Nonstochastic bandits with composite anonymous feedback},
  author={Cesa-Bianchi, Nicolo and Gentile, Claudio and Mansour, Yishay},
  booktitle={Conference On Learning Theory},
  pages={750--773},
  year={2018}
}

@article{maurer2009empirical,
  title={Empirical Bernstein Bounds and Sample Variance Penalization},
  author={Maurer, Andreas and Pontil, Massimiliano},
  journal={stat},
  volume={1050},
  pages={21},
  year={2009},
  publisher={Citeseer}
}

@article{jin2020simultaneously,
  title={Simultaneously Learning Stochastic and Adversarial Episodic MDPs with Known Transition.},
  author={Jin, Tiancheng and Luo, Haipeng},
  journal=NIPS,
  year={2020}
}

@article{simchowitz2021exploration,
  title={Exploration and Incentives in Reinforcement Learning},
  author={Simchowitz, Max and Slivkins, Aleksandrs},
  journal={arXiv preprint arXiv:2103.00360},
  year={2021}
}

@article{lykouris2019corruption,
  title={Corruption robust exploration in episodic reinforcement learning},
  author={Lykouris, Thodoris and Simchowitz, Max and Slivkins, Aleksandrs and Sun, Wen},
  journal={arXiv preprint arXiv:1911.08689},
  year={2019}
}

@inproceedings{joulani2013online,
  title={Online learning under delayed feedback},
  author={Joulani, Pooria and Gyorgy, Andras and Szepesv{\'a}ri, Csaba},
  booktitle={International Conference on Machine Learning},
  pages={1453--1461},
  year={2013}
}

@inproceedings{gyorgy2020adapting,
  title={Adapting to delays and data in adversarial multi-armed bandits},
  author={Gyorgy, Andras and Joulani, Pooria},
  booktitle={International Conference on Machine Learning},
  pages={3988--3997},
  year={2021},
  organization={PMLR}
}

@article{joulani2020modular,
  title={A modular analysis of adaptive (non-) convex optimization: Optimism, composite objectives, variance reduction, and variational bounds},
  author={Joulani, Pooria and Gy{\"o}rgy, Andr{\'a}s and Szepesv{\'a}ri, Csaba},
  journal={Theoretical Computer Science},
  volume={808},
  pages={108--138},
  year={2020},
  publisher={Elsevier}
}

@article{beck2003mirror,
  title={Mirror descent and nonlinear projected subgradient methods for convex optimization},
  author={Beck, Amir and Teboulle, Marc},
  journal={Operations Research Letters},
  volume={31},
  number={3},
  pages={167--175},
  year={2003},
  publisher={Elsevier}
}

@article{jaksch2010near,
  title={Near-optimal Regret Bounds for Reinforcement Learning.},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={4},
  year={2010}
}

@inproceedings{bartlett2009regal,
  title={REGAL: A regularization based algorithm for reinforcement learning in weakly communicating MDPs},
  author={Bartlett, Peter L and Tewari, Ambuj},
  booktitle={Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence},
  pages={35--42},
  year={2009},
  organization={AUAI Press}
}

@inproceedings{simchowitz2019non,
  title={Non-asymptotic gap-dependent regret bounds for tabular mdps},
  author={Simchowitz, Max and Jamieson, Kevin G},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1153--1162},
  year={2019}
}

@inproceedings{zanette2020learning,
  title={Learning near optimal policies with low inherent bellman error},
  author={Zanette, Andrea and Lazaric, Alessandro and Kochenderfer, Mykel and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={10978--10989},
  year={2020},
  organization={PMLR}
}

@inproceedings{cai2019provably,
  title={Provably efficient exploration in policy optimization},
  author={Cai, Qi and Yang, Zhuoran and Jin, Chi and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={1283--1294},
  year={2020},
  organization={PMLR}
}

@inproceedings{fruit2018efficient,
  title={Efficient Bias-Span-Constrained Exploration-Exploitation in Reinforcement Learning},
  author={Fruit, Ronan and Pirotta, Matteo and Lazaric, Alessandro and Ortner, Ronald},
  booktitle={ICML 2018-The 35th International Conference on Machine Learning},
  volume={80},
  pages={1578--1586},
  year={2018}
}

@inproceedings{zanette2019tighter,
    title={Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Value Function Bounds},
    author={Zanette, Andrea and Brunskill, Emma},
    booktitle={International Conference on Machine Learning},
    pages={7304--7312},
    year={2019}
}

@inproceedings{lancewicki2021stochastic,
  author    = {Tal Lancewicki and
               Shahar Segal and
               Tomer Koren and
               Yishay Mansour},
  title     = {Stochastic Multi-Armed Bandits with Unrestricted Delay Distributions},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning,
               {ICML} 2021, 18-24 July 2021, Virtual Event},
  pages     = {5969--5978},
  publisher = {{PMLR}},
  year      = {2021},
}

@article{lancewicki2020learning,
  title={Learning adversarial markov decision processes with delayed feedback},
  author={Lancewicki, Tal and Rosenberg, Aviv and Mansour, Yishay},
  journal={arXiv preprint arXiv:2012.14843},
  year={2020}
}

@article{ito2020delay,
  title={Delay and cooperation in nonstochastic linear bandits},
  author={Ito, Shinji and Hatano, Daisuke and Sumita, Hanna and Takemura, Kei and Fukunaga, Takuro and Kakimura, Naonori and Kawarabayashi, Ken-Ichi},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={4872--4883},
  year={2020}
}

@inproceedings{jin2018q,
    title={Is q-learning provably efficient?},
    author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
    booktitle={Advances in Neural Information Processing Systems},
    pages={4863--4873},
    year={2018}
}

@inproceedings{rosenberg2021stochastic,
  author    = {Aviv Rosenberg and
               Yishay Mansour},
  editor    = {Zhi{-}Hua Zhou},
  title     = {Stochastic Shortest Path with Adversarially Changing Costs},
  booktitle = {Proceedings of the Thirtieth International Joint Conference on Artificial
               Intelligence, {IJCAI} 2021, Virtual Event / Montreal, Canada, 19-27
               August 2021},
  pages     = {2936--2942},
  publisher = {ijcai.org},
  year      = {2021},
  url       = {https://doi.org/10.24963/ijcai.2021/404},
  doi       = {10.24963/ijcai.2021/404},
  timestamp = {Wed, 25 Aug 2021 17:11:16 +0200},
  biburl    = {https://dblp.org/rec/conf/ijcai/0002M21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{rosenberg2019online,
  title={Online convex optimization in adversarial markov decision processes},
  author={Rosenberg, Aviv and Mansour, Yishay},
  booktitle=ICML,
  year={2019},
 
}
pages={5478--5486},
organization={PMLR}

@article{rosenberg2019onlineb,
  title={Online Stochastic Shortest Path with Bandit Feedback and Unknown Transition Function},
  author={Rosenberg, Aviv and Mansour, Yishay},
  journal=NIPS,
  year={2019}
}
volume={32},
  pages={2212--2221},

@article{luo2021policy,
  title={Policy optimization in adversarial mdps: Improved exploration via dilated bonuses},
  author={Luo, Haipeng and Wei, Chen-Yu and Lee, Chung-Wei},
  journal=NIPS,
  year={2021}
}
  volume={34},

@inproceedings{shani2020optimistic,
  title={Optimistic policy optimization with bandit feedback},
  author={Shani, Lior and Efroni, Yonathan and Rosenberg, Aviv and Mannor, Shie},
  booktitle={International Conference on Machine Learning},
  pages={8604--8613},
  year={2020},
  organization={PMLR}
}

@inproceedings{cai2020provably,
  title={Provably efficient exploration in policy optimization},
  author={Cai, Qi and Yang, Zhuoran and Jin, Chi and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={1283--1294},
  year={2020},
  organization={PMLR}
}

@inproceedings{derman2021acting,
  author    = {Esther Derman and
               Gal Dalal and
               Shie Mannor},
  title     = {Acting in Delayed Environments with Non-Stationary Markov Policies},
  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021,
               Virtual Event, Austria, May 3-7, 2021},
  year      = {2021}
}

@article{cohen2021asynchronous,
  title={Asynchronous Stochastic Optimization Robust to Arbitrary Delays},
  author={Cohen, Alon and Daniely, Amit and Drori, Yoel and Koren, Tomer and Schain, Mariano},
  journal={arXiv preprint arXiv:2106.11879},
  year={2021}
}

@inproceedings{vernade2020linear,
  title={Linear bandits with stochastic delayed feedback},
  author={Vernade, Claire and Carpentier, Alexandra and Lattimore, Tor and Zappella, Giovanni and Ermis, Beyza and Brueckner, Michael},
  booktitle={International Conference on Machine Learning},
  pages={9712--9721},
  year={2020},
  organization={PMLR}
}

@inproceedings{agarwal2012distributed,
  title={Distributed delayed stochastic optimization},
  author={Agarwal, Alekh and Duchi, John C},
  booktitle={2012 IEEE 51st IEEE Conference on Decision and Control (CDC)},
  pages={5451--5452},
  year={2012},
  organization={IEEE}
}

@article{howson2021delayed,
  title={Delayed Feedback in Episodic Reinforcement Learning},
  author={Howson, Benjamin and Pike-Burke, Ciara and Filippi, Sarah},
  journal={arXiv preprint arXiv:2111.07615},
  year={2021}
}

@inproceedings{efroni2019tight,
    title={Tight Regret Bounds for Model-Based Reinforcement Learning with Greedy Policies},
    author={Yonathan Efroni and Nadav Merlis and Mohammad Ghavamzadeh and Shie Mannor},
    editor={Hanna M. Wallach and Hugo Larochelle and Alina Beygelzimer and Florence d'Alch{\'{e}}{-}Buc and Emily B. Fox and Roman Garnett},
    booktitle={Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, 8-14 December 2019, Vancouver, BC, Canada},
    pages={12203--12213},
    year={2019},
}

@inproceedings{osband2013more,
    title={(More) efficient reinforcement learning via posterior sampling},
    author={Osband, Ian and Russo, Daniel and Van Roy, Benjamin},
    booktitle={Advances in Neural Information Processing Systems},
    pages={3003--3011},
    year={2013}
}

@inproceedings{yang2019sample,
  title={Sample-optimal parametric Q-learning using linearly additive features},
  author={Yang, Lin and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={6995--7004},
  year={2019},
  organization={PMLR}
}

@article{quanrud2015online,
  title={Online learning with adversarial delays},
  author={Quanrud, Kent and Khashabi, Daniel},
  journal={Advances in neural information processing systems},
  volume={28},
  pages={1270--1278},
  year={2015}
}

@inproceedings{zimmert2020optimal,
  title={An optimal algorithm for adversarial bandits with arbitrary delays},
  author={Zimmert, Julian and Seldin, Yevgeny},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3285--3294},
  year={2020},
  organization={PMLR}
}

@inproceedings{zanette2020frequentist,
  title={Frequentist regret bounds for randomized least-squares value iteration},
  author={Zanette, Andrea and Brandfonbrener, David and Brunskill, Emma and Pirotta, Matteo and Lazaric, Alessandro},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1954--1964},
  year={2020}
}

@inproceedings{osband2016generalization,
    title={Generalization and Exploration via Randomized Value Functions},
    author={Osband, Ian and Van Roy, Benjamin and Wen, Zheng},
    booktitle={International Conference on Machine Learning},
    pages={2377--2386},
    year={2016}
}

@article{osband2016lower,
  title={On lower bounds for regret in reinforcement learning},
  author={Osband, Ian and Van Roy, Benjamin},
  journal={arXiv preprint arXiv:1608.02732},
  year={2016}
}

@inproceedings{azar2017minimax,
    title={Minimax regret bounds for reinforcement learning},
    author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
    booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
    pages={263--272},
    year={2017},
    organization={JMLR. org}
}

@inproceedings{tarbouriech2019noregret,
  title={No-regret exploration in goal-oriented reinforcement learning},
  author={Tarbouriech, Jean and Garcelon, Evrard and Valko, Michal and Pirotta, Matteo and Lazaric, Alessandro},
  booktitle={International Conference on Machine Learning},
  pages={9428--9437},
  year={2020},
  organization={PMLR}
}

@article{chen2021finding,
  title={Finding the stochastic shortest path with low regret: The adversarial cost and unknown transition case},
  author={Chen, Liyu and Luo, Haipeng},
  journal={arXiv preprint arXiv:2102.05284},
  year={2021}
}

@inproceedings{cohen2020ssp,
  title={Near-optimal Regret Bounds for Stochastic Shortest Path},
  author={Rosenberg, Aviv and Cohen, Alon and Mansour, Yishay and Kaplan, Haim},
  booktitle={International Conference on Machine Learning},
  pages={8210--8219},
  year={2020},
  organization={PMLR}
}

@inproceedings{dann2017unifying,
    title={Unifying PAC and regret: Uniform PAC bounds for episodic reinforcement learning},
    author={Dann, Christoph and Lattimore, Tor and Brunskill, Emma},
    booktitle={Advances in Neural Information Processing Systems},
    pages={5713--5723},
    year={2017}
}

@article{neu2015explore,
  title={Explore no more: Improved high-probability regret bounds for non-stochastic bandits},
  author={Neu, Gergely},
  journal={Advances in Neural Information Processing Systems},
  volume={28},
  pages={3168--3176},
  year={2015}
}

@article{jin2021best,
  title={The best of both worlds: stochastic and adversarial episodic MDPs with unknown transition},
  author={Jin, Tiancheng and Huang, Longbo and Luo, Haipeng},
  journal=NIPS,
  year={2021}
}

@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2137--2143},
  year={2020}
}

@inproceedings{neu2012adversarial,
    title={The adversarial stochastic shortest path problem with unknown transition probabilities},
    author={Neu, Gergely and Gyorgy, Andras and Szepesv{\'a}ri, Csaba},
    booktitle={Artificial Intelligence and Statistics},
    pages={805--813},
    year={2012}
}

@inproceedings{neu2010loopfree,
    title={The Online Loop-free Stochastic Shortest-Path Problem},
    author={Gergely Neu and Andr{\'{a}}s Gy{\"{o}}rgy and Csaba Szepesv{\'{a}}ri},
    booktitle=COLT,
    year={2010},
}
 pages={231--243},

@inproceedings{zimin2013online,
    title={Online learning in episodic Markovian decision processes by relative entropy policy search},
    author={Alexander Zimin and Gergely Neu},
    booktitle=NIPS,
    year={2013},
}
 booktitle={Advances in Neural Information Processing Systems 26: 27th Annual Conference on Neural Information Processing Systems 2013.},
    pages={1583--1591},

@inproceedings{rosenberg2019bandit,
    title={Online Stochastic Shortest Path with Bandit Feedback and Unknown Transition Function},
    author={Rosenberg, Aviv and Mansour, Yishay},
    booktitle={Advances in Neural Information Processing Systems},
    pages={2209--2218},
    year={2019}
}

@article{even2009online,
    title={Online Markov decision processes},
    author={Even-Dar, Eyal and Kakade, Sham M and Mansour, Yishay},
    journal={Mathematics of Operations Research},
    year={2009},
}
 volume={34},
    number={3},
    pages={726--736},

@article{yu2009markov,
    title={Markov decision processes with arbitrary reward processes},
    author={Yu, Jia Yuan and Mannor, Shie and Shimkin, Nahum},
    journal={Mathematics of Operations Research},
    volume={34},
    number={3},
    pages={737--757},
    year={2009},
}

@inproceedings{neu2012unknown,
    title={The adversarial stochastic shortest path problem with unknown transition probabilities},
    author={Gergely Neu and Andr{\'{a}}s Gy{\"{o}}rgy and Csaba Szepesv{\'{a}}ri},
    booktitle={Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics, {(AISTATS)}},
    pages={805--813},
    year={2012}
}


@article{neu2014bandit,
    title={Online {Markov Decision Processes} Under Bandit Feedback},
    author={Gergely Neu and Andr{\'{a}}s Gy{\"{o}}rgy and Csaba Szepesv{\'{a}}ri and Andr{\'{a}}s Antos},
    journal={{IEEE} Trans. Automat. Contr.},
    volume={59},
    number={3},
    pages={676--691},
    year={2014}
}

@article{jin2019po,
    title={Provably Efficient Exploration in Policy Optimization},
    author={Qi Cai and Zhuoran Yang and Chi Jin and Zhaoran Wang},
    journal={CoRR},
    volume={abs/1912.05830},
    year={2019},
}

@article{chen2020minimax,
  title={Minimax Regret for Stochastic Shortest Path with Adversarial Costs and Known Transition},
  author={Chen, Liyu and Luo, Haipeng and Wei, Chen-Yu},
  journal={arXiv preprint arXiv:2012.04053},
  year={2020}
}

@article{cohen2021minimax,
  title={Minimax regret for stochastic shortest path},
  author={Cohen, Alon and Efroni, Yonathan and Mansour, Yishay and Rosenberg, Aviv},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{alon2015online,
  title={Online learning with feedback graphs: Beyond bandits},
  author={Alon, Noga and Cesa-Bianchi, Nicolo and Dekel, Ofer and Koren, Tomer},
  booktitle={Conference on Learning Theory},
  pages={23--35},
  year={2015},
}

@article{rosenberg2020adversarial,
  title={Adversarial Stochastic Shortest Path},
  author={Rosenberg, Aviv and Mansour, Yishay},
  journal={arXiv preprint arXiv:2006.11561},
  year={2020}
}

@article{walsh2009learning,
  title={Learning and planning in environments with delayed feedback},
  author={Walsh, Thomas J and Nouri, Ali and Li, Lihong and Littman, Michael L},
  journal={Autonomous Agents and Multi-Agent Systems},
  volume={18},
  number={1},
  pages={83},
  year={2009},
  publisher={Springer}
}

@inproceedings{schuitema2010control,
  title={Control delay in reinforcement learning for real-time dynamic systems: a memoryless approach},
  author={Schuitema, Erik and Bu{\c{s}}oniu, Lucian and Babu{\v{s}}ka, Robert and Jonker, Pieter},
  booktitle={2010 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={3226--3231},
  year={2010},
  organization={IEEE}
}

@article{liu2014impact,
  title={Impact of communication delays on secondary frequency control in an islanded microgrid},
  author={Liu, Shichao and Wang, Xiaoyu and Liu, Peter Xiaoping},
  journal={IEEE Transactions on Industrial Electronics},
  volume={62},
  number={4},
  pages={2021--2031},
  year={2014},
  publisher={IEEE}
}

@inproceedings{changuel2012online,
  title={Online learning for QoE-based video streaming to mobile receivers},
  author={Changuel, Nesrine and Sayadi, Bessem and Kieffer, Michel},
  booktitle={2012 IEEE Globecom Workshops},
  pages={1319--1324},
  year={2012},
  organization={IEEE}
}

@inproceedings{mahmood2018setting,
  title={Setting up a reinforcement learning task with a real-world robot},
  author={Mahmood, A Rupam and Korenkevych, Dmytro and Komer, Brent J and Bergstra, James},
  booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={4635--4640},
  year={2018},
  organization={IEEE}
}

@article{katsikopoulos2003markov,
  title={Markov decision processes with delays and asynchronous cost collection},
  author={Katsikopoulos, Konstantinos V and Engelbrecht, Sascha E},
  journal={IEEE transactions on automatic control},
  volume={48},
  number={4},
  pages={568--574},
  year={2003},
  publisher={IEEE}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}


@inproceedings{haarnoja2018soft,
  title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1861--1870},
  year={2018}
}

@article{hazan2019introduction,
  title={Introduction to online convex optimization},
  author={Hazan, Elad},
  journal={arXiv preprint arXiv:1909.05207},
  year={2019}
}

@article{chen2020delay,
  title={Delay-aware multi-agent reinforcement learning},
  author={Chen, Baiming and Xu, Mengdi and Liu, Zuxin and Li, Liang and Zhao, Ding},
  journal={arXiv preprint arXiv:2005.05441},
  year={2020}
}

@inproceedings{bistritz2019online,
  title={Online exp3 learning in adversarial bandits with delayed feedback},
  author={Bistritz, Ilai and Zhou, Zhengyuan and Chen, Xi and Bambos, Nicholas and Blanchet, Jose},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11349--11358},
  year={2019}
}

@article{kakade2001natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  journal={Advances in neural information processing systems},
  volume={14},
  pages={1531--1538},
  year={2001}
}

@inproceedings{efroni2021confidence,
  author    = {Yonathan Efroni and
               Nadav Merlis and
               Aadirupa Saha and
               Shie Mannor},
  editor    = {Marina Meila and
               Tong Zhang},
  title     = {Confidence-Budget Matching for Sequential Budgeted Learning},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning,
               {ICML} 2021, 18-24 July 2021, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {139},
  pages     = {2937--2947},
  publisher = {{PMLR}},
  year      = {2021}
}

@article{freund1997decision,
  title={A decision-theoretic generalization of on-line learning and an application to boosting},
  author={Freund, Yoav and Schapire, Robert E},
  journal={Journal of computer and system sciences},
  volume={55},
  number={1},
  pages={119--139},
  year={1997},
  publisher={Elsevier}
}

@inproceedings{lee2020closer,
	title={A Closer Look at Small-loss Bounds for Bandits with Graph Feedback},
	author={Lee, Chung-Wei and Luo, Haipeng and Zhang, Mengxiao},
	booktitle={Conference on Learning Theory},
	year={2020}
}

@inproceedings{beygelzimer2011contextual,
	title={Contextual bandit algorithms with supervised learning guarantees},
	author={Beygelzimer, Alina and Langford, John and Li, Lihong and Reyzin, Lev and Schapire, Robert},
	booktitle={Proceedings of the International Conference on Artificial Intelligence and Statistics},
	year={2011}
}

@inproceedings{maurer2009empirical,
	title={Empirical Bernstein bounds and sample variance penalization},
	author={Maurer, Andreas and Pontil, Massimiliano},
	booktitle={Proceedings of the Annual Conference on Learning Theory},
	year={2009}
}


@inproceedings{abernethy2008competing,
	title={Competing in the Dark: An Efficient Algorithm for Bandit Linear Optimization},
	author={Abernethy, Jacob D and Hazan, Elad and Rakhlin, Alexander},
	booktitle={Proceedings of the Annual Conference
	on Learning Theory},
	year={2008}
}

@inproceedings{zimin2013,
	author = {Zimin, Alexander and Neu, Gergely},
	title = {Online Learning in Episodic Markovian Decision Processes by Relative Entropy Policy Search},
	booktitle = {Proceedings of the International Conference on Neural Information Processing Systems},
	year={2013}
} 

@article{auer2002finite,
	title={Finite-time analysis of the multiarmed bandit problem},
	author={Auer, Peter and Cesa-Bianchi, Nicolo and Fischer, Paul},
	journal={Machine learning},
	year={2002},
	publisher={Springer}
}

@inproceedings{chu2011contextual,
	title={Contextual bandits with linear payoff functions},
	author={Chu, Wei and Li, Lihong and Reyzin, Lev and Schapire, Robert},
	booktitle={Proceedings of the International Conference on Artificial Intelligence and Statistics},
	year={2011}
}

@inproceedings{abbasi2011improved,
	title={Improved algorithms for linear stochastic bandits},
	author={Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
	booktitle={Proceedings of the International Conference on Neural Information Processing Systems},
	year={2011}
}

@article{jaksch2010near,
	title={Near-optimal regret bounds for reinforcement learning},
	author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
	journal={Journal of Machine Learning Research},
	year={2010}
}

@inproceedings{dekel2013better,
	title = 	 {Better Rates for Any Adversarial Deterministic MDP},
	author = 	 {Ofer Dekel and Elad Hazan},
	booktitle = 	 {Proceedings of the International Conference on Machine Learning},
	year = 	 {2013}
}

@inproceedings{arora2012deterministic,
	author = {Arora, Raman and Dekel, Ofer and Tewari, Ambuj},
	title = {Deterministic MDPs with Adversarial Rewards and Bandit Feedback},
	booktitle = {Proceedings of the Conference on Uncertainty in Artificial Intelligence},
	year = {2012},
	pages = {93--101}
} 



@inproceedings{neu2015explore,
	title={Explore no more: Improved high-probability regret bounds for non-stochastic bandits},
	author={Neu, Gergely},
	booktitle={Advances in Neural Information Processing Systems},
	year={2015}
}

@inproceedings{AllenbergAuGyOt06,
	title={Hannan consistency in on-line learning in case of unbounded losses under partial monitoring},
	author={Allenberg, Chamy and Auer, Peter and Gy{\"o}rfi, L{\'a}szl{\'o} and Ottucs{\'a}k, Gy{\"o}rgy},
	booktitle={Proceedings of the international conference on Algorithmic Learning Theory},
	pages={229--243},
	year={2006}
}

@article{auer2002nonstochastic,
	title={The nonstochastic multiarmed bandit problem},
	author={Auer, Peter and Cesa-Bianchi, Nicol{\`o} and Freund, Yoav and Schapire, Robert E},
	journal={SIAM Journal on Computing},
	year={2002}
}

@inproceedings{azar2017minimax,
	author = {Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
	title = {Minimax Regret Bounds for Reinforcement Learning},
	booktitle = {Proceedings of the International Conference on Machine Learning},
	year = {2017},
} 


@inproceedings{jin2018q,
	title={Is Q-learning provably efficient?},
	author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
	booktitle={Proceedings of the International Conference on Neural Information Processing Systems},
	pages={4868--4878},
	year={2018}
}

@inproceedings{ouyang2017learning,
	title={Learning unknown Markov Decision Processes: a thompson sampling approach},
	author={Ouyang, Yi and Gagrani, Mukul and Nayyar, Ashutosh and Jain, Rahul},
	booktitle={Proceedings of the International Conference on Neural Information Processing Systems},
	year={2017}
}

@inproceedings{fruit2018efficient,
	title={Efficient bias-span-constrained exploration-exploitation in reinforcement learning},
	author={Fruit, Ronan and Pirotta, Matteo and Lazaric, Alessandro and Ortner, Ronald},
	booktitle = 	 {Proceedings of the International Conference on Machine Learning},
	year = 	 {2018}
}

@inproceedings{zhang2019regret,
	title={Regret Minimization for Reinforcement Learning by Evaluating the Optimal Bias Function},
	author={Zhang, Zihan and Ji, Xiangyang},
	booktitle={Advances in Neural Information Processing Systems},
	year={2019}
}

@article{lee2020biasnomore,
  title={Bias no more: high-probability data-dependent regret bounds for adversarial bandits and mdps},
  author={Lee, Chung-Wei and Luo, Haipeng and Wei, Chen-Yu and Zhang, Mengxiao},
  journal=NIPS,
  year={2020}
}
  volume={33},
  pages={15522--15533},

@article{wei2019model,
	title={Model-free Reinforcement Learning in Infinite-horizon Average-reward Markov Decision Processes},
	author={Wei, Chen-Yu and Jafarnia-Jahromi, Mehdi and Luo, Haipeng and Sharma, Hiteshi and Jain, Rahul},
	journal={arXiv preprint arXiv:1910.07072},
	year={2019}
}

@inproceedings{yu2009arbitrarily,
	title={Arbitrarily modulated Markov decision processes},
	author={Yu, Jia Yuan and Mannor, Shie},
	booktitle={Proceedings of the IEEE Conference on Decision and Control},
	year={2009}
}

@article{dong2019q,
	title={Q-learning with UCB Exploration is Sample Efficient for Infinite-Horizon MDP},
	author={Dong, Kefan and Wang, Yuanhao and Chen, Xiaoyu and Wang, Liwei},
	journal={arXiv preprint arXiv:1901.09311},
	year={2019}
}

@book{Boyd2004,
	author = {Boyd, Stephen and Vandenberghe, Lieven},
	title = {Convex Optimization},
	year = {2004},
	isbn = {0521833787},
	publisher = {Cambridge University Press},
}

@book{Cesa-Bianchi:2006:PLG:1137817,
	author = {Cesa-Bianchi, Nicolo and Lugosi, Gabor},
	title = {Prediction, Learning, and Games},
	year = {2006},
	isbn = {0521841089},
	publisher = {Cambridge University Press},
} 

@article{Even-Dar:2009:OMD:1599452.1599466,
	title={Online Markov decision processes},
	author={Even-Dar, Eyal and Kakade, Sham M and Mansour, Yishay},
	journal={Mathematics of Operations Research},
	year={2009}
}

@inproceedings{DBLP:journals/corr/abs-1205-2661,
	title={REGAL: A regularization based algorithm for reinforcement learning in weakly communicating MDPs},
	author={Bartlett, Peter L and Tewari, Ambuj},
	booktitle={Proceedings of the Conference on Uncertainty in Artificial Intelligence},
	year={2009}
}

@inproceedings{zanette2019tighter,
	title={Tighter problem-dependent regret bounds in reinforcement learning without domain knowledge using value function bounds},
	author={Zanette, Andrea and Brunskill, Emma},
	booktitle={Proceedings of the International Conference on Machine Learning},
	year={2019}
}

@article{audibert2013regret,
	title={Regret in online combinatorial optimization},
	author={Audibert, Jean-Yves and Bubeck, S{\'e}bastien and Lugosi, G{\'a}bor},
	journal={Mathematics of Operations Research},
	year={2013}
}

@InProceedings{neu2012unknown,
	title = 	 {The adversarial stochastic shortest path problem with unknown transition probabilities},
	author = 	 {Gergely Neu and Andras Gyorgy and Csaba Szepesvari},
	booktitle = 	 {Proceedings of the International Conference on Artificial Intelligence and Statistics},
	year = 	 {2012}
}



@article{yu2009markov,
	title={Markov decision processes with arbitrary reward processes},
	author={Yu, Jia Yuan and Mannor, Shie and Shimkin, Nahum},
	journal={Mathematics of Operations Research},
	year={2009}
}

@misc{flp2019alttutorial,
	author  = "Ronan Fruit and Alessandro Lazaric and Matteo Pirotta",
	title        = "Regret Minimization in Infinite-Horizon Finite Markov Decision Processes",
	howpublished = "Tutorial at ALT'19",
	year         = "2019",
}

@inproceedings{dekel2014bandits,
	title={Bandits with switching costs: ${T}^{2/3}$ regret},
	author={Dekel, Ofer and Ding, Jian and Koren, Tomer and Peres, Yuval},
	booktitle={Proceedings of the annual ACM symposium on Theory of computing},
	year={2014}
}

@inproceedings{chen2021improved,
  title={Improved corruption robust algorithms for episodic reinforcement learning},
  author={Chen, Yifang and Du, Simon and Jamieson, Kevin},
  booktitle=ICML,
  year={2021},

}
pages={1561--1570},
organization={PMLR}



@article{neu2014online,
	title={Online Markov decision processes under bandit feedback},
	author={Neu, Gergely and Antos, Andras and Gy{\"o}rgy, Andr{\'a}s and Szepesv{\'a}ri, Csaba},
	journal={IEEE Transactions on Automatic Control},
	year={2014}
}

@article{cheung2019reinforcement,
	title={Reinforcement Learning under Drift},
	author={Cheung, Wang Chi and Simchi-Levi, David and Zhu, Ruihao},
	journal={arXiv preprint arXiv:1906.02922},
	year={2019}
}

@article{hazan2016introduction,
	title={Introduction to online convex optimization},
	author={Hazan, Elad and others},
	journal={Foundations and Trends{\textregistered} in Optimization},

	publisher={Now Publishers, Inc.}
}


@inproceedings{dann2017unifying,
	title={Unifying PAC and regret: Uniform PAC bounds for episodic reinforcement learning},
	author={Dann, Christoph and Lattimore, Tor and Brunskill, Emma},
	booktitle={Advances in Neural Information Processing Systems},
	year={2017}
}

@article{auer2008near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Auer, Peter and Jaksch, Thomas and Ortner, Ronald},
  journal=NIPS,
  year={2008}
}
  volume={21},

@inproceedings{wei2021non,
  title={Non-stationary reinforcement learning without prior knowledge: An optimal black-box approach},
  author={Wei, Chen-Yu and Luo, Haipeng},
  booktitle=COLT,
  year={2021},
}
  pages={4300--4354},
    organization={PMLR}

@inproceedings{pacchianobest2022,
  title={Best of Both Worlds Model Selection},
  author={Pacchiano, Aldo and Dann, Christoph and Gentile, Claudio},
  booktitle=NIPS, 
  year={2022}
}

@article{gajane2018sliding,
  title={A sliding-window algorithm for markov decision processes with arbitrarily changing rewards and transitions},
  author={Gajane, Pratik and Ortner, Ronald and Auer, Peter},
  journal={arXiv preprint arXiv:1805.10066},
  year={2018}
}

@article{cheung2023nonstationary,
  title={Nonstationary reinforcement learning: The blessing of (more) optimism},
  author={Cheung, Wang Chi and Simchi-Levi, David and Zhu, Ruihao},
  journal={Management Science},
  year={2023},
  publisher={INFORMS}
}

@inproceedings{liu2022learning,
  title={Learning markov games with adversarial opponents: Efficient algorithms and fundamental limits},
  author={Liu, Qinghua and Wang, Yuanhao and Jin, Chi},
  booktitle={International Conference on Machine Learning},
  pages={14036--14053},
  year={2022},
  organization={PMLR}
}

@inproceedings{zimmert2019optimal,
	title={An Optimal Algorithm for Stochastic and Adversarial Bandits},
	author={Zimmert, Julian and Seldin, Yevgeny},
	booktitle=AISTATS,
	year={2019}
}

@inproceedings{audibert2009minimax,
	title={Minimax policies for adversarial and stochastic bandits},
	author={Audibert, Jean-Yves and Bubeck, S{\'e}bastien},
	booktitle={Proceedings of the Annual Conference on Learning Theory},
	year={2009}
}

@inproceedings{zimmert2019beating,
	title={Beating Stochastic and Adversarial Semi-bandits Optimally and Simultaneously},
	author={Zimmert, Julian and Luo, Haipeng and Wei, Chen-Yu},
	booktitle={Proceedings of the International Conference on Machine Learning},
	year={2019}
}

@inproceedings{wei2018more,
	title={More Adaptive Algorithms for Adversarial Bandits},
	author={Wei, Chen-Yu and Luo, Haipeng},
	booktitle=COLT,
	year={2018}
}

@inproceedings{bubeck2012best,
	title={The best of both worlds: Stochastic and adversarial bandits},
	author={Bubeck, S{\'e}bastien and Slivkins, Aleksandrs},
	booktitle={Proceedings of the 23rd Annual Conference on Learning Theory},
	year={2012}
}

@inproceedings{seldin2014one,
	title={One practical algorithm for both stochastic and adversarial bandits},
	author={Seldin, Yevgeny and Slivkins, Aleksandrs},
	booktitle={Proceedings of the International Conference on Machine Learning},
	year={2014}
}

@inproceedings{seldin2017improved,
	title={An Improved Parametrization and Analysis of the EXP3++ Algorithm for Stochastic and Adversarial Bandits},
	author={Seldin, Yevgeny and Lugosi, G{\'a}bor},
	booktitle={Proceedings of the Annual Conference on Learning Theory},
	year={2017}
}

@inproceedings{auer2016algorithm,
	title={An algorithm with nearly optimal pseudo-regret for both stochastic and adversarial bandits},
	author={Auer, Peter and Chiang, Chao-Kai},
	booktitle={Proceedings of the Annual Conference on Learning Theory},
	year={2016}
}

@inproceedings{bubeck2018sparsity,
  title={Sparsity, variance and curvature in multi-armed bandits},
  author={Bubeck, S{\'e}bastien and Cohen, Michael and Li, Yuanzhi},
  booktitle={Algorithmic Learning Theory},
  year={2018}
}

@inproceedings{lykouris2018stochastic,
  title={Stochastic bandits robust to adversarial corruptions},
  author={Lykouris, Thodoris and Mirrokni, Vahab and Paes Leme, Renato},
  booktitle={Proceedings of the Annual ACM SIGACT Symposium on Theory of Computing},
  year={2018}
}

@inproceedings{gupta2019better,
  title={Better algorithms for stochastic bandits with adversarial corruptions},
  author={Gupta, Anupam and Koren, Tomer and Talwar, Kunal},
  booktitle={Proceedings of the Annual Conference on Learning Theory},
  year={2019}
}

@article{abernethy2012interior,
  title={Interior-point methods for full-information and bandit online learning},
  author={Abernethy, Jacob D and Hazan, Elad and Rakhlin, Alexander},
  journal={IEEE Transactions on Information Theory},
  year={2012},
  publisher={IEEE}
}

@inproceedings{saha2011improved,
  title={Improved regret guarantees for online smooth convex optimization with bandit feedback},
  author={Saha, Ankan and Tewari, Ambuj},
  booktitle={Proceedings of the International Conference on Artificial Intelligence and Statistics},
  year={2011}
}

@inproceedings{hazan2014bandit,
  title={Bandit convex optimization: Towards tight bounds},
  author={Hazan, Elad and Levy, Kfir},
  booktitle={Advances in Neural Information Processing Systems},
  year={2014}
}

@book{nesterov1994interior,
  title={Interior-point polynomial algorithms in convex programming},
  author={Nesterov, Yurii and Nemirovskii, Arkadii},
  year={1994},
  publisher={Siam}
}

@inproceedings{bubeck2019improved,
  title={Improved Path-length Regret Bounds for Bandits},
  author={Bubeck, S{\'e}bastien and Li, Yuanzhi and Luo, Haipeng and Wei, Chen-Yu},
  booktitle={Conference On Learning Theory},
  year={2019}
}

@article{Hazan16,
  title={Introduction to online convex optimization},
  author={Hazan, Elad},
  journal={Foundations and Trends{\textregistered} in Optimization},
  volume={2},
  number={3-4},
  pages={157--325},
  year={2016},
  publisher={Now Publishers, Inc.}
}

@inproceedings{simc2019,
	title={Non-asymptotic gap-dependent regret bounds for tabular {MDP}s},
	author={Simchowitz, Max and Jamieson, Kevin G},
	booktitle={Advances in Neural Information Processing Systems},
	pages={1151--1160},
	year={2019}
}


@article{zimmert2021optimal,
title = "{Tsallis-INF}: An optimal algorithm for stochastic and adversarial bandits",
author={Julian Zimmert and Yevgeny Seldin},
year={2021},
journal = JMLR,
},


@article{lai1985asymptotically,
  title={Asymptotically efficient adaptive allocation rules},
  author={Lai, Tze Leung and Robbins, Herbert},
  journal={Advances in applied mathematics},
  volume={6},
  number={1},
  pages={4--22},
  year={1985},
  publisher={Academic Press}
}

@inproceedings{zheng2019equipping,
  title={Equipping Experts/Bandits with Long-term Memory},
  author={Zheng, Kai and Luo, Haipeng and Diakonikolas, Ilias and Wang, Liwei},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5927--5937},
  year={2019}
}

@inproceedings{kotlowski2019bandit,
  title={Bandit principal component analysis},
  author={Kot{\l}owski, Wojciech and Neu, Gergely},
  booktitle={Conference On Learning Theory},
  year={2019}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2002}
}

@phdthesis{kakade2003sample,
	title={On the sample complexity of reinforcement learning},
  	author={Kakade, Sham Machandranath},
	year={2003},
	school={University College London},
}

@inproceedings{pogodin20a,
  title = 	 {On First-Order Bounds, Variance and Gap-Dependent Bounds for Adversarial Bandits},
  author =       {Pogodin, Roman and Lattimore, Tor},
  booktitle = 	 {Proceedings of The 35th Uncertainty in Artificial Intelligence Conference},
  year = 	 {2020},
  publisher =    {PMLR},
}
  pages = 	 {894--904},
 editor = 	 {Adams, Ryan P. and Gogate, Vibhav},
  volume = 	 {115},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {22--25 Jul},
  pdf = 	 {http://proceedings.mlr.press/v115/pogodin20a/pogodin20a.pdf},
  url = 	 {https://proceedings.mlr.press/v115/pogodin20a.html}, 
  
@InProceedings{ito21a,
  title = 	 {Parameter-Free Multi-Armed Bandit Algorithms with Hybrid Data-Dependent Regret Bounds},
  author =       {Ito, Shinji},
  booktitle = 	COLT,
  year = 	 {2021},
}

@inproceedings{agarwal2017corralling,
  title={Corralling a band of bandit algorithms},
  author={Agarwal, Alekh and Luo, Haipeng and Neyshabur, Behnam and Schapire, Robert E},
  booktitle= COLT,
  year={2017},
}
 organization={PMLR}
 pages={12--38},

@article{dann2023best,
  title={Best of Both Worlds Policy Optimization},
  author={Dann, Christoph and Wei, Chen-Yu and Zimmert, Julian},
  journal={arXiv preprint arXiv:2302.09408},
  year={2023}
}


@inproceedings{neu2010online,
 author = {Neu, Gergely and Antos, Andras and Gy\"{o}rgy, Andr\'{a}s and Szepesv\'{a}ri, Csaba},
 booktitle = NIPS,
 title = {Online Markov Decision Processes under Bandit Feedback},
 year = {2010}
}

@article{foster2016learning,
  title={Learning in games: Robustness of fast convergence},
  author={Foster, Dylan J and Li, Zhiyuan and Lykouris, Thodoris and Sridharan, Karthik and Tardos, Eva},
  journal=NIPS,
  year={2016}
}

@inproceedings{zhang2021robust,
  title={Robust policy gradient against strong data corruption},
  author={Zhang, Xuezhou and Chen, Yiding and Zhu, Xiaojin and Sun, Wen},
  booktitle={International Conference on Machine Learning},
  pages={12391--12401},
  year={2021},
  organization={PMLR}
}
