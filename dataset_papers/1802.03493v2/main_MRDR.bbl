\begin{thebibliography}{33}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bang \& Robins(2005)Bang and Robins]{Bang05DR}
Bang, H. and Robins, J.
\newblock Doubly robust estimation in missing data and causal inference models.
\newblock \emph{Biometrics}, 61:\penalty0 962--972, 2005.

\bibitem[Bottou et~al.(2013)Bottou, Peters, Qui{\~n}onero-Candela, Charles,
  Chickering, Portugaly, Ray, Simard, and Snelson]{Bottou13CR}
Bottou, L., Peters, J., Qui{\~n}onero-Candela, J., Charles, D., Chickering,
  D.~Max, Portugaly, E., Ray, D., Simard, P., and Snelson, E.
\newblock Counterfactual reasoning and learning systems: The example of
  computational advertising.
\newblock \emph{JMLR}, 14:\penalty0 3207--3260--620, 2013.

\bibitem[Brockman et~al.(2016)Brockman, Cheung, Pettersson, Schneider,
  Schulman, Tang, and Zaremba]{brockman2016openai}
Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang,
  J., and Zaremba, W.
\newblock Open{AI} {G}ym.
\newblock arXiv:1606.01540, 2016.

\bibitem[Cao et~al.(2009)Cao, Tsiatis, and Davidian]{Cao09IE}
Cao, W., Tsiatis, A., and Davidian, M.
\newblock Improving efficiency and robustness of the doubly robust estimator
  for a population mean with incomplete data.
\newblock \emph{Biometrika}, 96:\penalty0 723--734, 2009.

\bibitem[Cassel et~al.(1976)Cassel, S{\"a}rndal, and Wretman]{Cassel76SR}
Cassel, C., S{\"a}rndal, C., and Wretman, J.
\newblock Some results on generalized difference estimation and generalized
  regression estimation for finite populations.
\newblock \emph{Biometrika}, 63:\penalty0 615--620, 1976.

\bibitem[Dud{\'i}k et~al.(2011)Dud{\'i}k, Langford, and Li]{Dudik11DR}
Dud{\'i}k, M., Langford, J., and Li, L.
\newblock Doubly robust policy evaluation and learning.
\newblock In \emph{Proceedings of the 28th International Conference on Machine
  Learning}, pp.\  1097--1104, 2011.

\bibitem[Geist \& Scherrer(2014)Geist and Scherrer]{geist2014off}
Geist, M. and Scherrer, B.
\newblock Off-policy learning with eligibility traces: A survey.
\newblock \emph{The Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 289--333, 2014.

\bibitem[Gruslys et~al.(2017)Gruslys, Azar, Bellemare, and
  Munos]{gruslys2017reactor}
Gruslys, A., Azar, M., Bellemare, M., and Munos, R.
\newblock The reactor: A sample-efficient actor-critic architecture.
\newblock \emph{arXiv preprint arXiv:1704.04651}, 2017.

\bibitem[Hanna et~al.(2016)Hanna, Stone, and Niekum]{hanna2016high}
Hanna, J., Stone, P., and Niekum, S.
\newblock High confidence off-policy evaluation with models.
\newblock \emph{arXiv preprint arXiv:1606.06126}, 2016.

\bibitem[Hirano et~al.(2003)Hirano, Imbens, and Ridder]{Hirano03EE}
Hirano, K., Imbens, G., and Ridder, W.
\newblock Efficient estimation of average treatment effects using the estimated
  propensity score.
\newblock \emph{Econometrica}, 71\penalty0 (4):\penalty0 1161--1189, 2003.

\bibitem[Jiang \& Li(2016)Jiang and Li]{Jiang16DR}
Jiang, N. and Li, L.
\newblock Doubly robust off-policy value evaluation for reinforcement learning.
\newblock In \emph{Proceedings of the 33rd International Conference on Machine
  Learning}, pp.\  652--661, 2016.

\bibitem[Li et~al.(2011)Li, an~d J.~Langford, and Wang]{Li11UO}
Li, L., an~d J.~Langford, W.~Chu, and Wang, X.
\newblock Unbiased offline evaluation of contextual bandit-based news article
  recommendation algorithms.
\newblock In \emph{Proceedings of the 4th International Conference on Web
  Search and Data Mining}, pp.\  297--306, 2011.

\bibitem[Li et~al.(2015)Li, Munos, and Szepesv{\`a}ri]{Li15TM}
Li, L., Munos, R., and Szepesv{\`a}ri, Cs.
\newblock Toward minimax off-policy value estimation.
\newblock In \emph{Proceedings of the 18th International Conference on
  Artificial Intelligence and Statistics}, pp.\  608--616, 2015.

\bibitem[Louizos et~al.(2017)Louizos, Shalit, Mooij, Sontag, Zemel, and
  Welling]{Louizos17CE}
Louizos, C., Shalit, U., Mooij, J., Sontag, D., Zemel, R., and Welling, M.
\newblock Causal effect inference with deep latent-variable models.
\newblock In \emph{Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, pp.\  3076--3085, 2017.

\bibitem[Mahmood et~al.(2014)Mahmood, van Hasselt, and Sutton]{Mahmood14WI}
Mahmood, A., van Hasselt, H., and Sutton, R.
\newblock Weighted importance sampling for off-policy learning with linear
  function approximation.
\newblock In \emph{Proceedings of the 27th International Conference on Neural
  Information Processing Systems}, 2014.

\bibitem[Mandel et~al.(2014)Mandel, Liu, Levine, Brunskill, and
  Popovic]{Mandel14OP}
Mandel, T., Liu, Y., Levine, S., Brunskill, E., and Popovic, Z.
\newblock Off-policy evaluation across representations with applications to
  educational games.
\newblock In \emph{Proceedings of the 13th International Conference on
  Autonomous Agents and Multi-agent Systems}, pp.\  1077--1084, 2014.

\bibitem[Mandel et~al.(2016)Mandel, Liu, Brunskill, and Popovic]{Mandel16OE}
Mandel, T., Liu, Y., Brunskill, E., and Popovic, Z.
\newblock Offline evaluation of online reinforcement learning algorithms.
\newblock In \emph{Proceedings of the 30th Conference on Artificial
  Intelligence}, 2016.

\bibitem[Munos et~al.(2016)Munos, Stepleton, Harutyunyan, and
  Bellemare]{munos2016safe}
Munos, R., Stepleton, T., Harutyunyan, A., and Bellemare, M.
\newblock Safe and efficient off-policy reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1054--1062, 2016.

\bibitem[Murphy et~al.(2001)Murphy, van~der Laan, and Robins]{Murphy01MM}
Murphy, S., van~der Laan, M., and Robins, J.
\newblock Marginal mean models for dynamic regimes.
\newblock \emph{Journal of American Statistical Association}, 96\penalty0
  (456):\penalty0 1410--1423, 2001.

\bibitem[Paduraru(2013)]{Paduraru13OP}
Paduraru, C.
\newblock \emph{Off-policy Evaluation in {M}arkov Decision Processes}.
\newblock PhD thesis, McGill University, 2013.

\bibitem[Peshkin \& Shelton(2002)Peshkin and Shelton]{Peshkin02LS}
Peshkin, L. and Shelton, C.
\newblock Learning from scarce experience.
\newblock In \emph{Proceedings of the 19th International Conference on Machine
  Learning}, pp.\  498--505, 2002.

\bibitem[Precup et~al.(2000{\natexlab{a}})Precup, Sutton, and
  Singh]{Precup00ET}
Precup, D., Sutton, R., and Singh, S.
\newblock Eligibility traces for off-policy policy evaluation.
\newblock In \emph{Proceedings of the 17th International Conference on Machine
  Learning}, pp.\  759--766, 2000{\natexlab{a}}.

\bibitem[Precup et~al.(2000{\natexlab{b}})Precup, Sutton, and
  Singh]{precup2000eligibility}
Precup, D., Sutton, R., and Singh, S.
\newblock Eligibility traces for off-policy policy evaluation.
\newblock In \emph{ICML}, pp.\  759--766. Citeseer, 2000{\natexlab{b}}.

\bibitem[Precup et~al.(2001)Precup, Sutton, and Dasgupta]{Precup01OP}
Precup, D., Sutton, R., and Dasgupta, S.
\newblock Off-policy temporal difference learning with function approximation.
\newblock In \emph{Proceedings of the 18th International Conference on Machine
  Learning}, pp.\  417--424, 2001.

\bibitem[Robins \& Rotnitzky(1995)Robins and Rotnitzky]{Robins95SP}
Robins, J. and Rotnitzky, A.
\newblock Semi-parametric efficiency in multivariate regression models with
  missing data.
\newblock \emph{Journal of American Statistical Association}, 90:\penalty0
  122--129, 1995.

\bibitem[Robins et~al.(1994)Robins, Rotnitzky, and Zhao]{Robins94ER}
Robins, J., Rotnitzky, A., and Zhao, L.
\newblock Estimation of regression coefficients when some regressors are not
  always observed.
\newblock \emph{Journal of American Statistical Association}, 89\penalty0
  (427):\penalty0 846--866, 1994.

\bibitem[Shalit et~al.(2017)Shalit, Johansson, and Sontag]{Shalit17EI}
Shalit, U., Johansson, F., and Sontag, D.
\newblock Estimating individual treatment effect: Generalization bounds and
  algorithms.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning}, pp.\  3076--3085, 2017.

\bibitem[Sutton \& Barto(1998)Sutton and Barto]{sutton1998reinforcement}
Sutton, R. and Barto, A.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT press Cambridge, 1998.

\bibitem[Swaminathan et~al.(2017)Swaminathan, Krishnamurthy, Agarwal,
  Dud{\'i}k, Langford, Jose, and Zitouni]{Swaminathan17OP}
Swaminathan, A., Krishnamurthy, A., Agarwal, A., Dud{\'i}k, M., Langford, J.,
  Jose, D., and Zitouni, I.
\newblock Off-policy evaluation for slate recommendation.
\newblock In \emph{Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, pp.\  3635--3645, 2017.

\bibitem[Theocharous et~al.(2015)Theocharous, Thomas, and
  Ghavamzadeh]{Theocharous15PA}
Theocharous, G., Thomas, P., and Ghavamzadeh, M.
\newblock Personalized ad recommendation systems for life-time value
  optimization with guarantees.
\newblock In \emph{Proceedings of the 24th International Joint Conference on
  Artificial Intelligence}, pp.\  1806--1812, 2015.

\bibitem[Thomas \& Brunskill(2016)Thomas and Brunskill]{Thomas16DE}
Thomas, P. and Brunskill, E.
\newblock Data-efficient off-policy policy evaluation for reinforcement
  learning.
\newblock In \emph{Proceedings of the 33rd International Conference on Machine
  Learning}, pp.\  2139--2148, 2016.

\bibitem[Thomas et~al.(2015{\natexlab{a}})Thomas, Theocharous, and
  Ghavamzadeh]{Thomas15HCPE}
Thomas, P., Theocharous, G., and Ghavamzadeh, M.
\newblock High confidence off-policy evaluation.
\newblock In \emph{Proceedings of the 29th Conference on Artificial
  Intelligence}, 2015{\natexlab{a}}.

\bibitem[Thomas et~al.(2015{\natexlab{b}})Thomas, Theocharous, and
  Ghavamzadeh]{Thomas15HCPI}
Thomas, P., Theocharous, G., and Ghavamzadeh, M.
\newblock High confidence policy improvement.
\newblock In \emph{Proceedings of the 32nd International Conference on Machine
  Learning}, pp.\  2380--2388, 2015{\natexlab{b}}.

\end{thebibliography}
