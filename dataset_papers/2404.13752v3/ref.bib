@misc{zou2023representation,
      title={Representation Engineering: A Top-Down Approach to AI Transparency}, 
      author={Andy Zou and Long Phan and Sarah Chen and James Campbell and Phillip Guo and Richard Ren and Alexander Pan and Xuwang Yin and Mantas Mazeika and Ann-Kathrin Dombrowski and Shashwat Goel and Nathaniel Li and Michael J. Byun and Zifan Wang and Alex Mallen and Steven Basart and Sanmi Koyejo and Dawn Song and Matt Fredrikson and J. Zico Kolter and Dan Hendrycks},
      year={2023},
      eprint={2310.01405},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{xu2022learning,
      title={Learning to Break the Loop: Analyzing and Mitigating Repetitions for Neural Text Generation}, 
      author={Jin Xu and Xiaojiang Liu and Jianhao Yan and Deng Cai and Huayang Li and Jian Li},
      year={2022},
      eprint={2206.02369},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{ilyas2019adversarial,
      title={Adversarial Examples Are Not Bugs, They Are Features}, 
      author={Andrew Ilyas and Shibani Santurkar and Dimitris Tsipras and Logan Engstrom and Brandon Tran and Aleksander Madry},
      year={2019},
      eprint={1905.02175},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{openai2024gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{bai2022constitutional,
      title={Constitutional AI: Harmlessness from AI Feedback}, 
      author={Yuntao Bai and Saurav Kadavath and others},
      year={2022},
      eprint={2212.08073},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{li2023reinforcement,
      title={Reinforcement Learning with Human Feedback: Learning Dynamic Choices via Pessimism}, 
      author={Zihao Li and Zhuoran Yang and Mengdi Wang},
      year={2023},
      eprint={2305.18438},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{mitchell2022fast,
      title={Fast Model Editing at Scale}, 
      author={Eric Mitchell and Charles Lin and Antoine Bosselut and Chelsea Finn and Christopher D. Manning},
      year={2022},
      eprint={2110.11309},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{zhang2023sirens,
      title={Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models}, 
      author={Yue Zhang and Yafu Li and Leyang Cui and Deng Cai and Lemao Liu and Tingchen Fu and Xinting Huang and Enbo Zhao and Yu Zhang and Yulong Chen and Longyue Wang and Anh Tuan Luu and Wei Bi and Freda Shi and Shuming Shi},
      year={2023},
      eprint={2309.01219},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{Zhang2023EvaluatingTP,
  title={Evaluating the Performance of Large Language Models on GAOKAO Benchmark},
  author={Xiaotian Zhang and Chunyang Li and Yi Zong and Zhengyu Ying and Liang He and Xipeng Qiu},
  year={2023}
}

@misc{li2023inferencetime,
      title={Inference-Time Intervention: Eliciting Truthful Answers from a Language Model}, 
      author={Kenneth Li and Oam Patel and Fernanda Vi√©gas and Hanspeter Pfister and Martin Wattenberg},
      year={2023},
      eprint={2306.03341},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{qi2023finetuning,
      title={Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!}, 
      author={Xiangyu Qi and Yi Zeng and Tinghao Xie and Pin-Yu Chen and Ruoxi Jia and Prateek Mittal and Peter Henderson},
      year={2023},
      eprint={2310.03693},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{turner2023activation,
      title={Activation Addition: Steering Language Models Without Optimization}, 
      author={Alexander Matt Turner and Lisa Thiergart and David Udell and Gavin Leech and Ulisse Mini and Monte MacDiarmid},
      year={2023},
      eprint={2308.10248},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{goodfellow2014generative,
      title={Generative Adversarial Networks}, 
      author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
      year={2014},
      eprint={1406.2661},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{liu2024autodan,
      title={AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models}, 
      author={Xiaogeng Liu and Nan Xu and Muhao Chen and Chaowei Xiao},
      year={2024},
      eprint={2310.04451},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{zou2023universal,
      title={Universal and Transferable Adversarial Attacks on Aligned Language Models}, 
      author={Andy Zou and Zifan Wang and Nicholas Carlini and Milad Nasr and J. Zico Kolter and Matt Fredrikson},
      year={2023},
      eprint={2307.15043},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{hu2021lora,
      title={LoRA: Low-Rank Adaptation of Large Language Models}, 
      author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
      year={2021},
      eprint={2106.09685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{wei2023jailbreak,
title={Jailbreak and Guard Aligned Language Models with Only Few In-Context Demonstrations},
author={Wei, Zeming and Wang, Yifei and Wang, Yisen},
journal={arXiv preprint arXiv:2310.06387},
year={2023}
}

@article{wei2024weighted,
title={Weighted automata extraction and explanation of recurrent neural networks for natural language tasks},
author={Wei, Zeming and Zhang, Xiyue and Zhang, Yihao and Sun, Meng},
journal={Journal of Logical and Algebraic Methods in Programming},
volume={136},
year={2024}
}

@inproceedings{wei2023cfa,
title={Cfa: Class-wise calibrated fair adversarial training},
author={Wei, Zeming and Wang, Yifei and Guo, Yiwen and Wang, Yisen},
booktitle={CVPR},
year={2023}
}

@inproceedings{wei2023sharpness,
title={Sharpness-Aware Minimization Alone can Improve Adversarial Robustness},
author={Wei, Zeming and Zhu, Jingyu and Zhang, Yihao},
booktitle={The Second Workshop on New Frontiers in Adversarial Machine Learning},
year={2023}
}

@article{zhang2023using,
title={Using Z3 for Formal Modeling and Verification of FNN Global Robustness},
author={Zhang, Yihao and Wei, Zeming and Zhang, Xiyue and Sun, Meng},
journal={arXiv preprint arXiv:2304.10558},
year={2023}
}

@inproceedings{wei2022extracting,
title={Extracting weighted finite automata from recurrent neural networks for natural languages},
author={Wei, Zeming and Zhang, Xiyue and Sun, Meng},
booktitle={ICFEM},
year={2022}
}

@inproceedings{guo2023architecture,
title={Architecture Matters: Uncovering Implicit Mechanisms in Graph Contrastive Learning},
author={Guo, Xiaojun and Wang, Yifei and Wei, Zeming and Wang, Yisen},
booktitle={NeurIPS},
year={2023}
}

@article{piet2023jatmo,
title={Jatmo: Prompt injection defense by task-specific finetuning},
author={Piet, Julien and Alrashed, Maha and Sitawarin, Chawin and Chen, Sizhe and Wei, Zeming and Sun, Elizabeth and Alomair, Basel and Wagner, David},
journal={arXiv preprint arXiv:2312.17673},
year={2023}
}

@article{mo2024studious,
title={Studious bob fight back against jailbreaking via prompt adversarial tuning},
author={Mo, Yichuan and Wang, Yuji and Wei, Zeming and Wang, Yisen},
journal={ICLR 2024 Workshop on Secure and Trustworthy Large Language Models},
year={2024}
}

@article{wei2023characterizing,
title={Characterizing robust overfitting in adversarial training via cross-class features},
author={Wei, Zeming and Guo, Yiwen and Wang, Yisen},

journal={OpenReview preprint},
year={2023}
}

@article{zhang2024duality,
title={On the Duality Between Sharpness-Aware Minimization and Adversarial Training},
author={Zhang, Yihao and He, Hangzhou and Zhu, Jingyu and Chen, Huanran and Wang, Yifei and Wei, Zeming},
journal={arXiv preprint arXiv:2402.15152},
year={2024}
}

@article{pair,
  author       = {Patrick Chao and
                  Alexander Robey and
                  Edgar Dobriban and
                  Hamed Hassani and
                  George J. Pappas and
                  Eric Wong},
  title        = {Jailbreaking Black Box Large Language Models in Twenty Queries},
  journal      = {CoRR},
  volume       = {abs/2310.08419},
  year         = {2023}
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@article{tap,
  author       = {Anay Mehrotra and
                  Manolis Zampetakis and
                  Paul Kassianik and
                  Blaine Nelson and
                  Hyrum Anderson and
                  Yaron Singer and
                  Amin Karbasi},
  title        = {Tree of Attacks: Jailbreaking Black-Box LLMs Automatically},
  journal      = {CoRR},
  volume       = {abs/2312.02119},
  year         = {2023}
}
@article{gcg,
  author       = {Andy Zou and
                  Zifan Wang and
                  J. Zico Kolter and
                  Matt Fredrikson},
  title        = {Universal and Transferable Adversarial Attacks on Aligned Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2307.15043},
  year         = {2023}
}
@article{autodan,
  author       = {Xiaogeng Liu and
                  Nan Xu and
                  Muhao Chen and
                  Chaowei Xiao},
  title        = {AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language
                  Models},
  journal      = {CoRR},
  volume       = {abs/2310.04451},
  year         = {2023}
}
@article{base64,
  author       = {Alexander Wei and
                  Nika Haghtalab and
                  Jacob Steinhardt},
  title        = {Jailbroken: How Does {LLM} Safety Training Fail?},
  journal      = {CoRR},
  volume       = {abs/2307.02483},
  year         = {2023}
}
@article{lrl,
  author       = {Zheng Xin Yong and
                  Cristina Menghini and
                  Stephen H. Bach},
  title        = {Low-Resource Languages Jailbreak {GPT-4}},
  journal      = {CoRR},
  volume       = {abs/2310.02446},
  year         = {2023}
}

@book{tunstall2022natural,
  title={Natural Language Processing with Transformers: Building Language Applications with Hugging Face},
  author={Tunstall, L. and von Werra, L. and Wolf, T.},
  isbn={9781098103248},
  lccn={2023275986},
  url={https://books.google.com.sg/books?id=pNBpzwEACAAJ},
  year={2022},
  publisher={O'Reilly Media}
}

@misc{zhao2023chatgpt,
      title={Is ChatGPT Equipped with Emotional Dialogue Capabilities?}, 
      author={Weixiang Zhao and Yanyan Zhao and Xin Lu and Shilong Wang and Yanpeng Tong and Bing Qin},
      year={2023},
      eprint={2304.09582},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{llama2,
  author       = {Hugo Touvron and others
                  },
  title        = {Llama 2: Open Foundation and Fine-Tuned Chat Models},
  journal      = {CoRR},
  volume       = {abs/2307.09288},
  year         = {2023}
}
@article{gpt4,
  author       = {OpenAI},
  title        = {{GPT-4} Technical Report},
  journal      = {CoRR},
  volume       = {abs/2303.08774},
  year         = {2023}
}
@article{vicuna,
  author       = {Lianmin Zheng and
                  Wei{-}Lin Chiang and
                  Ying Sheng and
                  Siyuan Zhuang and
                  Zhanghao Wu and
                  Yonghao Zhuang and
                  Zi Lin and
                  Zhuohan Li and
                  Dacheng Li and
                  Eric P. Xing and
                  Hao Zhang and
                  Joseph E. Gonzalez and
                  Ion Stoica},
  title        = {Judging LLM-as-a-judge with MT-Bench and Chatbot Arena},
  journal      = {CoRR},
  volume       = {abs/2306.05685},
  year         = {2023}
}
@misc{hu2024gradient,
      title={Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes}, 
      author={Xiaomeng Hu and Pin-Yu Chen and Tsung-Yi Ho},
      year={2024},
      eprint={2403.00867},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}
@article{guanaco,
  title={QLoRA: Efficient Finetuning of Quantized LLMs},
  author={Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2305.14314},
  year={2023}
}
@misc{justinphan3110_harmful_harmless_instructions,
  author = {Justin Phan},
  title = {Harmful Harmless Instructions Dataset},
  year = {2023},
  howpublished = {\url{https://huggingface.co/datasets/justinphan3110/harmful_harmless_instructions}},
  note = {Accessed: 2024-03-30}
}
@misc{xu2023parameterefficient,
      title={Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models: A Critical Review and Assessment}, 
      author={Lingling Xu and Haoran Xie and Si-Zhao Joe Qin and Xiaohui Tao and Fu Lee Wang},
      year={2023},
      eprint={2312.12148},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{kingma2017adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{li2024deepinception,
      title={DeepInception: Hypnotize Large Language Model to Be Jailbreaker}, 
      author={Xuan Li and Zhanke Zhou and Jianing Zhu and Jiangchao Yao and Tongliang Liu and Bo Han},
      year={2024},
      eprint={2311.03191},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{yang2023shadow,
      title={Shadow Alignment: The Ease of Subverting Safely-Aligned Language Models}, 
      author={Xianjun Yang and Xiao Wang and Qi Zhang and Linda Petzold and William Yang Wang and Xun Zhao and Dahua Lin},
      year={2023},
      eprint={2310.02949},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{selfreminder,
author = {Wu, Fangzhao and Xie, Yueqi and Yi, Jingwei and Shao, Jiawei and Curl, Justin and Lyu, Lingjuan and Chen, Qifeng and Xie, Xing},
year = {2023},
month = {04},
pages = {},
title = {Defending ChatGPT against Jailbreak Attack via Self-Reminder},
doi = {10.21203/rs.3.rs-2873090/v1}
}

@misc{welleck2019neural,
      title={Neural Text Generation with Unlikelihood Training}, 
      author={Sean Welleck and Ilia Kulikov and Stephen Roller and Emily Dinan and Kyunghyun Cho and Jason Weston},
      year={2019},
      eprint={1908.04319},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{lin2021straight,
      title={Straight to the Gradient: Learning to Use Novel Tokens for Neural Text Generation}, 
      author={Xiang Lin and Simeng Han and Shafiq Joty},
      year={2021},
      eprint={2106.07207},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{zhu2018texygen,
      title={Texygen: A Benchmarking Platform for Text Generation Models}, 
      author={Yaoming Zhu and Sidi Lu and Lei Zheng and Jiaxian Guo and Weinan Zhang and Jun Wang and Yong Yu},
      year={2018},
      eprint={1802.01886},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{zhang2024alleviating,
      title={Alleviating Hallucinations of Large Language Models through Induced Hallucinations}, 
      author={Yue Zhang and Leyang Cui and Wei Bi and Shuming Shi},
      year={2024},
      eprint={2312.15710},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{lin2022truthfulqa,
      title={TruthfulQA: Measuring How Models Mimic Human Falsehoods}, 
      author={Stephanie Lin and Jacob Hilton and Owain Evans},
      year={2022},
      eprint={2109.07958},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}



@article{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={arXiv preprint arXiv:1706.06083},
  year={2017}
}


@article{shafahi2019adversarial,
  title={Adversarial training for free!},
  author={Shafahi, Ali and Najibi, Mahyar and Ghiasi, Mohammad Amin and Xu, Zheng and Dickerson, John and Studer, Christoph and Davis, Larry S and Taylor, Gavin and Goldstein, Tom},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{cai2018curriculum,
  title={Curriculum adversarial training},
  author={Cai, Qi-Zhi and Du, Min and Liu, Chang and Song, Dawn},
  journal={arXiv preprint arXiv:1805.04807},
  year={2018}
}

@inproceedings{wang2023better,
  title={Better diffusion models further improve adversarial training},
  author={Wang, Zekai and Pang, Tianyu and Du, Chao and Lin, Min and Liu, Weiwei and Yan, Shuicheng},
  booktitle={International Conference on Machine Learning},
  pages={36246--36263},
  year={2023},
  organization={PMLR}
}

@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}

@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@inproceedings{carlini2017adversarial,
  title={Adversarial examples are not easily detected: Bypassing ten detection methods},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={Proceedings of the 10th ACM workshop on artificial intelligence and security},
  pages={3--14},
  year={2017}
}

@inproceedings{athalye2018obfuscated,
  title={Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples},
  author={Athalye, Anish and Carlini, Nicholas and Wagner, David},
  booktitle={International conference on machine learning},
  pages={274--283},
  year={2018},
  organization={PMLR}
}

@inproceedings{carlini2017towards,
  title={Towards evaluating the robustness of neural networks},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={2017 ieee symposium on security and privacy (sp)},
  pages={39--57},
  year={2017},
  organization={Ieee}
}

@article{grosse2017statistical,
  title={On the (statistical) detection of adversarial examples},
  author={Grosse, Kathrin and Manoharan, Praveen and Papernot, Nicolas and Backes, Michael and McDaniel, Patrick},
  journal={arXiv preprint arXiv:1702.06280},
  year={2017}
}

@article{nie2022diffusion,
  title={Diffusion models for adversarial purification},
  author={Nie, Weili and Guo, Brandon and Huang, Yujia and Xiao, Chaowei and Vahdat, Arash and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2205.07460},
  year={2022}
}

@article{chen2023robust,
  title={Robust classification via a single diffusion model},
  author={Chen, Huanran and Dong, Yinpeng and Wang, Zhengyi and Yang, Xiao and Duan, Chengqi and Su, Hang and Zhu, Jun},
  journal={arXiv preprint arXiv:2305.15241},
  year={2023}
}

@article{grabinski2022robust,
  title={Robust models are less over-confident},
  author={Grabinski, Julia and Gavrikov, Paul and Keuper, Janis and Keuper, Margret},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={39059--39075},
  year={2022}
}

@inproceedings{allen2022feature,
  title={Feature purification: How adversarial training performs robust deep learning},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  booktitle={2021 IEEE 62nd Annual Symposium on Foundations of Computer Science (FOCS)},
  pages={977--988},
  year={2022},
  organization={IEEE}
}

@article{santurkar2019image,
  title={Image synthesis with a single (robust) classifier},
  author={Santurkar, Shibani and Ilyas, Andrew and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{srinivas2024models,
  title={Which models have perceptually-aligned gradients? an explanation via off-manifold robustness},
  author={Srinivas, Suraj and Bordt, Sebastian and Lakkaraju, Himabindu},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@article{ganin2016domain,
  title={Domain-adversarial training of neural networks},
  author={Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, Fran{\c{c}}ois and March, Mario and Lempitsky, Victor},
  journal={Journal of machine learning research},
  volume={17},
  number={59},
  pages={1--35},
  year={2016}
}

@inproceedings{sun2018domain,
  title={Domain adversarial training for accented speech recognition},
  author={Sun, Sining and Yeh, Ching-Feng and Hwang, Mei-Yuh and Ostendorf, Mari and Xie, Lei},
  booktitle={2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={4854--4858},
  year={2018},
  organization={IEEE}
}

@article{zhao2023arcl,
  title={ArCL: enhancing contrastive learning with augmentation-robust representations},
  author={Zhao, Xuyang and Du, Tianqi and Wang, Yisen and Yao, Jun and Huang, Weiran},
  journal={arXiv preprint arXiv:2303.01092},
  year={2023}
}

@article{jiang2020robust,
  title={Robust pre-training by adversarial contrastive learning},
  author={Jiang, Ziyu and Chen, Tianlong and Chen, Ting and Wang, Zhangyang},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={16199--16210},
  year={2020}
}

@article{wei2024assessing,
  title={Assessing the brittleness of safety alignment via pruning and low-rank modifications},
  author={Wei, Boyi and Huang, Kaixuan and Huang, Yangsibo and Xie, Tinghao and Qi, Xiangyu and Xia, Mengzhou and Mittal, Prateek and Wang, Mengdi and Henderson, Peter},
  journal={arXiv preprint arXiv:2402.05162},
  year={2024}
}

@article{zheng2024prompt,
  title={Prompt-driven llm safeguarding via directed representation optimization},
  author={Zheng, Chujie and Yin, Fan and Zhou, Hao and Meng, Fandong and Zhou, Jie and Chang, Kai-Wei and Huang, Minlie and Peng, Nanyun},
  journal={arXiv preprint arXiv:2401.18018},
  year={2024}
}

@article{azaria2023internal,
  title={The internal state of an llm knows when its lying},
  author={Azaria, Amos and Mitchell, Tom},
  journal={arXiv preprint arXiv:2304.13734},
  year={2023}
}

@article{simonyan2013deep,
  title={Deep inside convolutional networks: Visualising image classification models and saliency maps},
  author={Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1312.6034},
  year={2013}
}

@article{adebayo2018sanity,
  title={Sanity checks for saliency maps},
  author={Adebayo, Julius and Gilmer, Justin and Muelly, Michael and Goodfellow, Ian and Hardt, Moritz and Kim, Been},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{singh2024rethinking,
  title={Rethinking Interpretability in the Era of Large Language Models},
  author={Singh, Chandan and Inala, Jeevana Priya and Galley, Michel and Caruana, Rich and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2402.01761},
  year={2024}
}

@article{zhao2024explainability,
  title={Explainability for large language models: A survey},
  author={Zhao, Haiyan and Chen, Hanjie and Yang, Fan and Liu, Ninghao and Deng, Huiqi and Cai, Hengyi and Wang, Shuaiqiang and Yin, Dawei and Du, Mengnan},
  journal={ACM Transactions on Intelligent Systems and Technology},
  volume={15},
  number={2},
  pages={1--38},
  year={2024},
  publisher={ACM New York, NY}
}

@inproceedings{zhang2018interpretable,
  title={Interpretable convolutional neural networks},
  author={Zhang, Quanshi and Wu, Ying Nian and Zhu, Song-Chun},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={8827--8836},
  year={2018}
}

@inproceedings{mikolov2013linguistic,
  title={Linguistic regularities in continuous space word representations},
  author={Mikolov, Tom{\'a}{\v{s}} and Yih, Wen-tau and Zweig, Geoffrey},
  booktitle={Proceedings of the 2013 conference of the north american chapter of the association for computational linguistics: Human language technologies},
  pages={746--751},
  year={2013}
}


@article{liu2024dora,
  title={DoRA: Weight-Decomposed Low-Rank Adaptation},
  author={Liu, Shih-Yang and Wang, Chien-Yi and Yin, Hongxu and Molchanov, Pavlo and Wang, Yu-Chiang Frank and Cheng, Kwang-Ting and Chen, Min-Hung},
  journal={arXiv preprint arXiv:2402.09353},
  year={2024}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International conference on machine learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}
@article{pfeiffer2020mad,
  title={Mad-x: An adapter-based framework for multi-task cross-lingual transfer},
  author={Pfeiffer, Jonas and Vuli{\'c}, Ivan and Gurevych, Iryna and Ruder, Sebastian},
  journal={arXiv preprint arXiv:2005.00052},
  year={2020}
}

@article{li2021prefix,
  title={Prefix-tuning: Optimizing continuous prompts for generation},
  author={Li, Xiang Lisa and Liang, Percy},
  journal={arXiv preprint arXiv:2101.00190},
  year={2021}
}

@misc{shin2020autoprompt,
      title={AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts}, 
      author={Taylor Shin and Yasaman Razeghi and Robert L. Logan IV au2 and Eric Wallace and Sameer Singh},
      year={2020},
      eprint={2010.15980},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{huang2023can,
  title={Can large language models explain themselves? a study of llm-generated self-explanations},
  author={Huang, Shiyuan and Mamidanna, Siddarth and Jangam, Shreedhar and Zhou, Yilun and Gilpin, Leilani H},
  journal={arXiv preprint arXiv:2310.11207},
  year={2023}
}

@misc{enguehard2023sequential,
      title={Sequential Integrated Gradients: a simple but effective method for explaining language models}, 
      author={Joseph Enguehard},
      year={2023},
      eprint={2305.15853},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{sikdar2021integrated,
  title={Integrated directional gradients: Feature interaction attribution for neural NLP models},
  author={Sikdar, Sandipan and Bhattacharya, Parantapa and Heese, Kieran},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={865--878},
  year={2021}
}

@article{gurnee2023finding,
  title={Finding neurons in a haystack: Case studies with sparse probing},
  author={Gurnee, Wes and Nanda, Neel and Pauly, Matthew and Harvey, Katherine and Troitskii, Dmitrii and Bertsimas, Dimitris},
  journal={arXiv preprint arXiv:2305.01610},
  year={2023}
}

@article{mu2020compositional,
  title={Compositional explanations of neurons},
  author={Mu, Jesse and Andreas, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={17153--17163},
  year={2020}
}

@inproceedings{zhang2019theoretically,
title={Theoretically principled trade-off between robustness and accuracy},
author={Zhang, Hongyang and Yu, Yaodong and Jiao, Jiantao and Xing, Eric and El Ghaoui, Laurent and Jordan, Michael},
booktitle={ICML},
year={2019}
}

@misc{wu2024reftrepresentationfinetuninglanguage,
      title={ReFT: Representation Finetuning for Language Models}, 
      author={Zhengxuan Wu and Aryaman Arora and Zheng Wang and Atticus Geiger and Dan Jurafsky and Christopher D. Manning and Christopher Potts},
      year={2024},
      eprint={2404.03592},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.03592}, 
}

@misc{yao2023editinglargelanguagemodels,
      title={Editing Large Language Models: Problems, Methods, and Opportunities}, 
      author={Yunzhi Yao and Peng Wang and Bozhong Tian and Siyuan Cheng and Zhoubo Li and Shumin Deng and Huajun Chen and Ningyu Zhang},
      year={2023},
      eprint={2305.13172},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.13172}, 
}

@article{mo2024fight,
  title={Fight back against jailbreaking via prompt adversarial tuning},
  author={Mo, Yichuan and Wang, Yuji and Wei, Zeming and Wang, Yisen},
  journal={NeurIPS 2024},
  year={2024}
}

@inproceedings{wang2024theoretical,
  title={A Theoretical Understanding of Self-Correction through In-context Alignment},
  author={Wang, Yifei and Wu, Yuyang and Wei, Zeming and Jegelka, Stefanie and Wang, Yisen},
  booktitle={NeurIPS 2024},
  year={2024}
}

@article{huang2024can,
  title={Can Knowledge Editing Really Correct Hallucinations?},
  author={Huang, Baixiang and Chen, Canyu and Xu, Xiongxiao and Payani, Ali and Shu, Kai},
  journal={arXiv preprint arXiv:2410.16251},
  year={2024}
}

@article{chen2024can,
  title={Can Editing LLMs Inject Harm?},
  author={Chen, Canyu and Huang, Baixiang and Li, Zekun and Chen, Zhaorun and Lai, Shiyang and Xu, Xiongxiao and Gu, Jia-Chen and Gu, Jindong and Yao, Huaxiu and Xiao, Chaowei and others},
  journal={arXiv preprint arXiv:2407.20224},
  year={2024}
}

@article{dong2023robust,
  title={How Robust is Google's Bard to Adversarial Image Attacks?},
  author={Dong, Yinpeng and Chen, Huanran and Chen, Jiawei and Fang, Zhengwei and Yang, Xiao and Zhang, Yichi and Tian, Yu and Su, Hang and Zhu, Jun},
  journal={arXiv preprint arXiv:2309.11751},
  year={2023}
}

@article{chen2023rethinking,
  title={Rethinking model ensemble in transfer-based adversarial attacks},
  author={Chen, Huanran and Zhang, Yichi and Dong, Yinpeng and Yang, Xiao and Su, Hang and Zhu, Jun},
  journal={arXiv preprint arXiv:2303.09105},
  year={2023}
}

@inproceedings{zhang2024boosting,
  title={Boosting Jailbreak Attack With Momentum},
  author={Zhang, Yihao and Wei, Zeming},
  booktitle={ICLR 2024 Workshop on Reliable and Responsible Foundation Models}
}

@article{jia2024improved,
  title={Improved techniques for optimization-based jailbreaking on large language models},
  author={Jia, Xiaojun and Pang, Tianyu and Du, Chao and Huang, Yihao and Gu, Jindong and Liu, Yang and Cao, Xiaochun and Lin, Min},
  journal={arXiv preprint arXiv:2405.21018},
  year={2024}
}