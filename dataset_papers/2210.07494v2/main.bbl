\begin{thebibliography}{10}

\bibitem{kipf2016semi}
Thomas~N Kipf and Max Welling.
\newblock Semi-supervised classification with graph convolutional networks.
\newblock {\em arXiv preprint arXiv:1609.02907}, 2016.

\bibitem{velickovic2017graph}
Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro
  Lio, and Yoshua Bengio.
\newblock Graph attention networks.
\newblock {\em arXiv}, 1(2), 2017.

\bibitem{hamilton2017inductive}
Will Hamilton, Zhitao Ying, and Jure Leskovec.
\newblock Inductive representation learning on large graphs.
\newblock In {\em NeuIPS}, pages 1024--1034, 2017.

\bibitem{xu2018powerful}
Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka.
\newblock How powerful are graph neural networks?
\newblock {\em arXiv preprint arXiv:1810.00826}, 2018.

\bibitem{he2020lightgcn}
Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng Wang.
\newblock Lightgcn: Simplifying and powering graph convolution network for
  recommendation.
\newblock In {\em Proceedings of the 43rd International ACM SIGIR conference on
  research and development in Information Retrieval}, pages 639--648, 2020.

\bibitem{ying2018graph}
Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William~L Hamilton, and
  Jure Leskovec.
\newblock Graph convolutional neural networks for web-scale recommender
  systems.
\newblock In {\em Proceedings of the 24th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pages 974--983, 2018.

\bibitem{zheng2021cold}
Wenqing Zheng, Edward~W Huang, Nikhil Rao, Sumeet Katariya, Zhangyang Wang, and
  Karthik Subbian.
\newblock Cold brew: Distilling graph node representations with incomplete or
  missing neighborhoods.
\newblock {\em arXiv preprint arXiv:2111.04840}, 2021.

\bibitem{tang2009relational}
Lei Tang and Huan Liu.
\newblock Relational learning via latent social dimensions.
\newblock In {\em Proceedings of the 15th ACM SIGKDD international conference
  on Knowledge discovery and data mining}, pages 817--826, 2009.

\bibitem{gao2018large}
Hongyang Gao, Zhengyang Wang, and Shuiwang Ji.
\newblock Large-scale learnable graph convolutional networks.
\newblock In {\em Proceedings of the 24th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pages 1416--1424, 2018.

\bibitem{huang2019graph}
Xiao Huang, Qingquan Song, Yuening Li, and Xia Hu.
\newblock Graph recurrent networks with attributed random walks.
\newblock In {\em Proceedings of the 25th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pages 732--740, 2019.

\bibitem{hu2020open}
Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu,
  Michele Catasta, and Jure Leskovec.
\newblock Open graph benchmark: Datasets for machine learning on graphs.
\newblock {\em arXiv preprint arXiv:2005.00687}, 2020.

\bibitem{zitnik2017predicting}
Marinka Zitnik and Jure Leskovec.
\newblock Predicting multicellular function through multi-layer tissue
  networks.
\newblock {\em Bioinformatics}, 33(14):i190--i198, 2017.

\bibitem{hu2019strategies}
Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay Pande,
  and Jure Leskovec.
\newblock Strategies for pre-training graph neural networks.
\newblock {\em arXiv preprint arXiv:1905.12265}, 2019.

\bibitem{you2020graph}
Yuning You, Tianlong Chen, Yongduo Sui, Ting Chen, Zhangyang Wang, and Yang
  Shen.
\newblock Graph contrastive learning with augmentations.
\newblock {\em Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem{wale2008comparison}
Nikil Wale, Ian~A Watson, and George Karypis.
\newblock Comparison of descriptor spaces for chemical compound retrieval and
  classification.
\newblock {\em Knowledge and Information Systems}, 14(3):347--375, 2008.

\bibitem{li2019deepgcns}
Guohao Li, Matthias Muller, Ali Thabet, and Bernard Ghanem.
\newblock Deepgcns: Can gcns go as deep as cnns?
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 9267--9276, 2019.

\bibitem{wang2019dynamic}
Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay~E Sarma, Michael~M Bronstein, and
  Justin~M Solomon.
\newblock Dynamic graph cnn for learning on point clouds.
\newblock {\em Acm Transactions On Graphics (tog)}, 38(5):1--12, 2019.

\bibitem{li2020deepergcn}
Guohao Li, Chenxin Xiong, Ali Thabet, and Bernard Ghanem.
\newblock Deepergcn: All you need to train deeper gcns.
\newblock {\em arXiv preprint arXiv:2006.07739}, 2020.

\bibitem{klicpera2018predict}
Johannes Klicpera, Aleksandar Bojchevski, and Stephan G{\"u}nnemann.
\newblock Predict then propagate: Graph neural networks meet personalized
  pagerank.
\newblock {\em arXiv preprint arXiv:1810.05997}, 2018.

\bibitem{xu2018representation}
Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi,
  and Stefanie Jegelka.
\newblock Representation learning on graphs with jumping knowledge networks.
\newblock In {\em International Conference on Machine Learning}, pages
  5453--5462. PMLR, 2018.

\bibitem{gao2019graph}
Hongyang Gao and Shuiwang Ji.
\newblock Graph u-nets.
\newblock In {\em international conference on machine learning}, pages
  2083--2092. PMLR, 2019.

\bibitem{zhou2019multi}
Kaixiong Zhou, Qingquan Song, Xiao Huang, Daochen Zha, Na~Zou, and Xia Hu.
\newblock Multi-channel graph neural networks.
\newblock {\em arXiv preprint arXiv:1912.08306}, 2019.

\bibitem{chiang2019cluster}
Wei-Lin Chiang, Xuanqing Liu, Si~Si, Yang Li, Samy Bengio, and Cho-Jui Hsieh.
\newblock Cluster-gcn: An efficient algorithm for training deep and large graph
  convolutional networks.
\newblock In {\em Proceedings of the 25th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pages 257--266, 2019.

\bibitem{zeng2019graphsaint}
Hanqing Zeng, Hongkuan Zhou, Ajitesh Srivastava, Rajgopal Kannan, and Viktor
  Prasanna.
\newblock Graphsaint: Graph sampling based inductive learning method.
\newblock {\em arXiv preprint arXiv:1907.04931}, 2019.

\bibitem{chen2018fastgcn}
Jie Chen, Tengfei Ma, and Cao Xiao.
\newblock Fastgcn: fast learning with graph convolutional networks via
  importance sampling.
\newblock {\em arXiv preprint arXiv:1801.10247}, 2018.

\bibitem{zou2019layer}
Difan Zou, Ziniu Hu, Yewen Wang, Song Jiang, Yizhou Sun, and Quanquan Gu.
\newblock Layer-dependent importance sampling for training deep and large graph
  convolutional networks.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{wu2019simplifying}
Felix Wu, Amauri Souza, Tianyi Zhang, Christopher Fifty, Tao Yu, and Kilian
  Weinberger.
\newblock Simplifying graph convolutional networks.
\newblock In {\em International conference on machine learning}, pages
  6861--6871. PMLR, 2019.

\bibitem{frasca2020sign}
Fabrizio Frasca, Emanuele Rossi, Davide Eynard, Ben Chamberlain, Michael
  Bronstein, and Federico Monti.
\newblock Sign: Scalable inception graph neural networks.
\newblock {\em arXiv preprint arXiv:2004.11198}, 2020.

\bibitem{sun2021scalable}
Chuxiong Sun and Guoshi Wu.
\newblock Scalable and adaptive graph neural networks with self-label-enhanced
  training.
\newblock {\em arXiv preprint arXiv:2104.09376}, 2021.

\bibitem{zhang2021graph}
Wentao Zhang, Ziqi Yin, Zeang Sheng, Wen Ouyang, Xiaosen Li, Yangyu Tao, Zhi
  Yang, and Bin Cui.
\newblock Graph attention multi-layer perceptron.
\newblock {\em arXiv preprint arXiv:2108.10097}, 2021.

\bibitem{bojchevski2020scaling}
Aleksandar Bojchevski, Johannes Klicpera, Bryan Perozzi, Amol Kapoor, Martin
  Blais, Benedek R{\'o}zemberczki, Michal Lukasik, and Stephan G{\"u}nnemann.
\newblock Scaling graph neural networks with approximate pagerank.
\newblock In {\em Proceedings of the 26th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pages 2464--2473, 2020.

\bibitem{md2021distgnn}
Vasimuddin Md, Sanchit Misra, Guixiang Ma, Ramanarayan Mohanty, Evangelos
  Georganas, Alexander Heinecke, Dhiraj Kalamkar, Nesreen~K Ahmed, and
  Sasikanth Avancha.
\newblock Distgnn: Scalable distributed training for large-scale graph neural
  networks.
\newblock {\em arXiv preprint arXiv:2104.06700}, 2021.

\bibitem{liu2021exact}
Zirui Liu, Kaixiong Zhou, Fan Yang, Li~Li, Rui Chen, and Xia Hu.
\newblock Exact: Scalable graph neural networks training via extreme activation
  compression.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{chen2017stochastic}
Jianfei Chen, Jun Zhu, and Le~Song.
\newblock Stochastic training of graph convolutional networks with variance
  reduction.
\newblock {\em arXiv preprint arXiv:1710.10568}, 2017.

\bibitem{cong2020minimal}
Weilin Cong, Rana Forsati, Mahmut Kandemir, and Mehrdad Mahdavi.
\newblock Minimal variance sampling with provable guarantees for fast training
  of graph neural networks.
\newblock In {\em Proceedings of the 26th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pages 1393--1403, 2020.

\bibitem{huang2018adaptive}
Wenbing Huang, Tong Zhang, Yu~Rong, and Junzhou Huang.
\newblock Adaptive sampling towards fast graph representation learning.
\newblock {\em Advances in neural information processing systems}, 31, 2018.

\bibitem{liu2022neighbor2seq}
Meng Liu and Shuiwang Ji.
\newblock Neighbor2seq: Deep learning on massive graphs by transforming
  neighbors to sequences.
\newblock {\em arXiv preprint arXiv:2202.03341}, 2022.

\bibitem{huang2020combining}
Qian Huang, Horace He, Abhay Singh, Ser-Nam Lim, and Austin~R Benson.
\newblock Combining label propagation and simple models out-performs graph
  neural networks.
\newblock {\em arXiv preprint arXiv:2010.13993}, 2020.

\bibitem{karypis1998fast}
George Karypis and Vipin Kumar.
\newblock A fast and high quality multilevel scheme for partitioning irregular
  graphs.
\newblock {\em SIAM Journal on scientific Computing}, 20(1):359--392, 1998.

\bibitem{zhu2005semi}
Xiaojin Zhu.
\newblock {\em Semi-supervised learning with graphs}.
\newblock Carnegie Mellon University, 2005.

\bibitem{wang2007label}
Fei Wang and Changshui Zhang.
\newblock Label propagation through linear neighborhoods.
\newblock {\em IEEE Transactions on Knowledge and Data Engineering},
  20(1):55--67, 2007.

\bibitem{karasuyama2013manifold}
Masayuki Karasuyama and Hiroshi Mamitsuka.
\newblock Manifold-based similarity adaptation for label propagation.
\newblock {\em Advances in neural information processing systems},
  26:1547--1555, 2013.

\bibitem{gong2016label}
Chen Gong, Dacheng Tao, Wei Liu, Liu Liu, and Jie Yang.
\newblock Label propagation via teaching-to-learn and learning-to-teach.
\newblock {\em IEEE transactions on neural networks and learning systems},
  28(6):1452--1465, 2016.

\bibitem{liu2018learning}
Yanbin Liu, Juho Lee, Minseop Park, Saehoon Kim, Eunho Yang, Sung~Ju Hwang, and
  Yi~Yang.
\newblock Learning to propagate labels: Transductive propagation network for
  few-shot learning.
\newblock {\em arXiv preprint arXiv:1805.10002}, 2018.

\bibitem{wang2020unifying}
Hongwei Wang and Jure Leskovec.
\newblock Unifying graph convolutional neural networks and label propagation.
\newblock {\em arXiv preprint arXiv:2002.06755}, 2020.

\bibitem{chien2021node}
Eli Chien, Wei-Cheng Chang, Cho-Jui Hsieh, Hsiang-Fu Yu, Jiong Zhang, Olgica
  Milenkovic, and Inderjit~S Dhillon.
\newblock Node feature extraction by self-supervised multi-scale neighborhood
  prediction.
\newblock {\em arXiv preprint arXiv:2111.00064}, 2021.

\bibitem{mikolov2013distributed}
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg~S Corrado, and Jeff Dean.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock {\em Advances in neural information processing systems}, 26, 2013.

\bibitem{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock {\em arXiv preprint arXiv:1810.04805}, 2018.

\bibitem{fey2021gnnautoscale}
Matthias Fey, Jan~E Lenssen, Frank Weichert, and Jure Leskovec.
\newblock Gnnautoscale: Scalable and expressive graph neural networks via
  historical embeddings.
\newblock In {\em International Conference on Machine Learning}, pages
  3294--3304. PMLR, 2021.

\bibitem{ding2021vq}
Mucong Ding, Kezhi Kong, Jingling Li, Chen Zhu, John Dickerson, Furong Huang,
  and Tom Goldstein.
\newblock Vq-gnn: A universal framework to scale up graph neural networks using
  vector quantization.
\newblock {\em Advances in Neural Information Processing Systems},
  34:6733--6746, 2021.

\bibitem{li2018deeper}
Qimai Li, Zhichao Han, and Xiao-Ming Wu.
\newblock Deeper insights into graph convolutional networks for semi-supervised
  learning.
\newblock In {\em Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem{chen2022bag}
Tianlong Chen, Kaixiong Zhou, Keyu Duan, Wenqing Zheng, Peihao Wang, Xia Hu,
  and Zhangyang Wang.
\newblock Bag of tricks for training deeper graph neural networks: A
  comprehensive benchmark study.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  2022.

\bibitem{oono2020graph}
Kenta Oono and Taiji Suzuki.
\newblock Graph neural networks exponentially lose expressive power for node
  classification.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{zhou2020towards}
Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, and Xia Hu.
\newblock Towards deeper graph neural networks with differentiable group
  normalization.
\newblock {\em Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem{zhou2021dirichlet}
Kaixiong Zhou, Xiao Huang, Daochen Zha, Rui Chen, Li~Li, Soo-Hyun Choi, and Xia
  Hu.
\newblock Dirichlet energy constrained learning for deep graph neural networks.
\newblock {\em Advances in Neural Information Processing Systems},
  34:21834--21846, 2021.

\bibitem{sun2019adagcn}
Ke~Sun, Zhanxing Zhu, and Zhouchen Lin.
\newblock Adagcn: Adaboosting graph convolutional networks into deep models.
\newblock {\em arXiv preprint arXiv:1908.05081}, 2019.

\bibitem{freund1999short}
Yoav Freund, Robert Schapire, and Naoki Abe.
\newblock A short introduction to boosting.
\newblock {\em Journal-Japanese Society For Artificial Intelligence},
  14(771-780):1612, 1999.

\bibitem{hastie2009multi}
Trevor Hastie, Saharon Rosset, Ji~Zhu, and Hui Zou.
\newblock Multi-class adaboost.
\newblock {\em Statistics and its Interface}, 2(3):349--360, 2009.

\bibitem{zheng2021adaboosting}
Li~Zheng, Jun Gao, Zhao Li, and Ji~Zhang.
\newblock Adaboosting clusters on graph neural networks.
\newblock In {\em 2021 IEEE International Conference on Data Mining (ICDM)},
  pages 1523--1528. IEEE, 2021.

\bibitem{leskovec2006sampling}
Jure Leskovec and Christos Faloutsos.
\newblock Sampling from large graphs.
\newblock In {\em Proceedings of the 12th ACM SIGKDD international conference
  on Knowledge discovery and data mining}, pages 631--636, 2006.

\bibitem{fey2019fast}
Matthias Fey and Jan~Eric Lenssen.
\newblock Fast graph representation learning with pytorch geometric.
\newblock {\em arXiv preprint arXiv:1903.02428}, 2019.

\bibitem{chen2021actnn}
Jianfei Chen, Lianmin Zheng, Zhewei Yao, Dequan Wang, Ion Stoica, Michael~W
  Mahoney, and Joseph~E Gonzalez.
\newblock Actnn: Reducing training memory footprint via 2-bit activation
  compressed training.
\newblock In {\em International Conference on Machine Learning}, 2021.

\end{thebibliography}
