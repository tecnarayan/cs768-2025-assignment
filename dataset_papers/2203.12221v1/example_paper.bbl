\begin{thebibliography}{57}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alamri et~al.(2019)Alamri, Cartillier, Das, Wang, Cherian, Essa,
  Batra, Marks, Hori, Anderson, et~al.]{alamri2019audio}
Huda Alamri, Vincent Cartillier, Abhishek Das, Jue Wang, Anoop Cherian, Irfan
  Essa, Dhruv Batra, Tim~K Marks, Chiori Hori, Peter Anderson, et~al.
\newblock Audio visual scene-aware dialog.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 7558--7567, 2019.

\bibitem[Allen-Zhu and Li(2020{\natexlab{a}})]{allen2020backward}
Zeyuan Allen-Zhu and Yuanzhi Li.
\newblock Backward feature correction: How deep learning performs deep
  learning.
\newblock \emph{arXiv preprint arXiv:2001.04413}, 2020{\natexlab{a}}.

\bibitem[Allen-Zhu and Li(2020{\natexlab{b}})]{allen2020feature}
Zeyuan Allen-Zhu and Yuanzhi Li.
\newblock Feature purification: How adversarial training performs robust deep
  learning.
\newblock \emph{arXiv preprint arXiv:2005.10190}, 2020{\natexlab{b}}.

\bibitem[Allen-Zhu and Li(2020{\natexlab{c}})]{allen2020towards}
Zeyuan Allen-Zhu and Yuanzhi Li.
\newblock Towards understanding ensemble, knowledge distillation and
  self-distillation in deep learning.
\newblock \emph{arXiv preprint arXiv:2012.09816}, 2020{\natexlab{c}}.

\bibitem[Amini et~al.(2009)Amini, Usunier, and Goutte]{amini2009learning}
Massih~R Amini, Nicolas Usunier, and Cyril Goutte.
\newblock Learning from multiple partially observed views-an application to
  multilingual text categorization.
\newblock \emph{Advances in neural information processing systems},
  22:\penalty0 28--36, 2009.

\bibitem[Anandkumar et~al.(2015)Anandkumar, Ge, and
  Janzamin]{anandkumar2015analyzing}
Anima Anandkumar, Rong Ge, and Majid Janzamin.
\newblock Analyzing tensor power method dynamics in overcomplete regime, 2015.

\bibitem[Anderson et~al.(2018)Anderson, Wu, Teney, Bruce, Johnson,
  S{\"u}nderhauf, Reid, Gould, and Van Den~Hengel]{anderson2018vision}
Peter Anderson, Qi~Wu, Damien Teney, Jake Bruce, Mark Johnson, Niko
  S{\"u}nderhauf, Ian Reid, Stephen Gould, and Anton Van Den~Hengel.
\newblock Vision-and-language navigation: Interpreting visually-grounded
  navigation instructions in real environments.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 3674--3683, 2018.

\bibitem[Arora et~al.(2018)Arora, Li, Liang, Ma, and Risteski]{arora2018linear}
Sanjeev Arora, Yuanzhi Li, Yingyu Liang, Tengyu Ma, and Andrej Risteski.
\newblock Linear algebraic structure of word senses, with applications to
  polysemy.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  6:\penalty0 483--495, 2018.

\bibitem[Baltru{\v{s}}aitis et~al.(2018)Baltru{\v{s}}aitis, Ahuja, and
  Morency]{baltruvsaitis2018multimodal}
Tadas Baltru{\v{s}}aitis, Chaitanya Ahuja, and Louis-Philippe Morency.
\newblock Multimodal machine learning: A survey and taxonomy.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 41\penalty0 (2):\penalty0 423--443, 2018.

\bibitem[Chan et~al.(2016)Chan, Jaitly, Le, and Vinyals]{Chan2016ListenAA}
William Chan, Navdeep Jaitly, Quoc~V. Le, and Oriol Vinyals.
\newblock Listen, attend and spell: A neural network for large vocabulary
  conversational speech recognition.
\newblock \emph{2016 IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pages 4960--4964, 2016.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Kornblith, Norouzi, and
  Hinton]{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{International conference on machine learning}, pages
  1597--1607. PMLR, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Li, Yu, Kholy, Ahmed, Gan, Cheng,
  and Liu]{chen2020uniter}
Yen-Chun Chen, Linjie Li, Licheng Yu, Ahmed~El Kholy, Faisal Ahmed, Zhe Gan,
  Yu~Cheng, and Jingjing Liu.
\newblock Uniter: Universal image-text representation learning,
  2020{\natexlab{b}}.

\bibitem[Chernozhukov et~al.(2015)Chernozhukov, Chetverikov, and
  Kato]{chernozhukov2015comparison}
Victor Chernozhukov, Denis Chetverikov, and Kengo Kato.
\newblock Comparison and anti-concentration bounds for maxima of gaussian
  random vectors.
\newblock \emph{Probability Theory and Related Fields}, 162\penalty0
  (1):\penalty0 47--70, 2015.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{bert}
Jacob Devlin, Ming{-}Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT:} pre-training of deep bidirectional transformers for language
  understanding.
\newblock In Jill Burstein, Christy Doran, and Thamar Solorio, editors,
  \emph{{NAACL-HLT} 2019}, pages 4171--4186. Association for Computational
  Linguistics, 2019.

\bibitem[Dong et~al.(2018)Dong, Xu, and Xu]{dong2018speech}
Linhao Dong, Shuang Xu, and Bo~Xu.
\newblock Speech-transformer: a no-recurrence sequence-to-sequence model for
  speech recognition.
\newblock In \emph{2018 IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pages 5884--5888. IEEE, 2018.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, et~al.]{vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Du et~al.(2021)Du, Teng, Li, Liu, Wang, Yuan, and
  Zhao]{du2021modality}
Chenzhuang Du, Jiaye Teng, Tingle Li, Yichen Liu, Yue Wang, Yang Yuan, and Hang
  Zhao.
\newblock Modality laziness: Everybody's business is nobody's business.
\newblock 2021.

\bibitem[Du et~al.(2018)Du, Zhai, Poczos, and Singh]{du2018gradient}
Simon~S Du, Xiyu Zhai, Barnabas Poczos, and Aarti Singh.
\newblock Gradient descent provably optimizes over-parameterized neural
  networks.
\newblock \emph{arXiv preprint arXiv:1810.02054}, 2018.

\bibitem[Federici et~al.(2020)Federici, Dutta, Forr{\'e}, Kushman, and
  Akata]{federici2020learning}
Marco Federici, Anjan Dutta, Patrick Forr{\'e}, Nate Kushman, and Zeynep Akata.
\newblock Learning robust representations via multi-view information
  bottleneck.
\newblock \emph{arXiv preprint arXiv:2002.07017}, 2020.

\bibitem[Gat et~al.(2020)Gat, Schwartz, Schwing, and Hazan]{gat2020removing}
Itai Gat, Idan Schwartz, Alexander Schwing, and Tamir Hazan.
\newblock Removing bias in multi-modal classifiers: Regularization by
  maximizing functional entropies, 2020.

\bibitem[Goyal et~al.(2017)Goyal, Khot, Summers-Stay, Batra, and
  Parikh]{goyal2017making}
Yash Goyal, Tejas Khot, Douglas Summers-Stay, Dhruv Batra, and Devi Parikh.
\newblock Making the v in vqa matter: Elevating the role of image understanding
  in visual question answering, 2017.

\bibitem[Grosse et~al.(2012)Grosse, Raina, Kwong, and Ng]{grosse2012shift}
Roger Grosse, Rajat Raina, Helen Kwong, and Andrew~Y Ng.
\newblock Shift-invariance sparse coding for audio classification.
\newblock \emph{arXiv preprint arXiv:1206.5241}, 2012.

\bibitem[Gupta et~al.(2016)Gupta, Hoffman, and Malik]{gupta2016cross}
Saurabh Gupta, Judy Hoffman, and Jitendra Malik.
\newblock Cross modal distillation for supervision transfer.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2827--2836, 2016.

\bibitem[Gwon et~al.(2016)Gwon, Campbell, Brady, Sturim, Cha, and
  Kung]{gwon2016multimodal}
Youngjune Gwon, William Campbell, Kevin Brady, Douglas Sturim, Miriam Cha, and
  HT~Kung.
\newblock Multimodal sparse coding for event detection.
\newblock \emph{arXiv preprint arXiv:1605.05212}, 2016.

\bibitem[HaoChen et~al.(2021)HaoChen, Wei, Lee, and Ma]{haochen2021shape}
Jeff~Z HaoChen, Colin Wei, Jason Lee, and Tengyu Ma.
\newblock Shape matters: Understanding the implicit bias of the noise
  covariance.
\newblock In \emph{Conference on Learning Theory}, pages 2315--2357. PMLR,
  2021.

\bibitem[Huang et~al.(2021)Huang, Du, Xue, Chen, Zhao, and
  Huang]{huang2021makes}
Yu~Huang, Chenzhuang Du, Zihui Xue, Xuanyao Chen, Hang Zhao, and Longbo Huang.
\newblock What makes multi-modal learning better than single (provably), 2021.

\bibitem[Ji and Telgarsky(2019)]{ji2019polylogarithmic}
Ziwei Ji and Matus Telgarsky.
\newblock Polylogarithmic width suffices for gradient descent to achieve
  arbitrarily small test error with shallow relu networks.
\newblock \emph{arXiv preprint arXiv:1909.12292}, 2019.

\bibitem[Jiang et~al.(2018)Jiang, Zheng, Luo, and Zhang]{jiang2018rednet}
Jindong Jiang, Lunan Zheng, Fei Luo, and Zhijun Zhang.
\newblock Rednet: Residual encoder-decoder network for indoor rgb-d semantic
  segmentation.
\newblock \emph{arXiv preprint arXiv:1806.01054}, 2018.

\bibitem[Kamath(2015)]{kamath2015bounds}
Gautam Kamath.
\newblock Bounds on the expectation of the maximum of samples from a gaussian.
\newblock \emph{URL http://www. gautamkamath. com/writings/gaussian max. pdf},
  2015.

\bibitem[Li et~al.(2020{\natexlab{a}})Li, Duan, Fang, Gong, and
  Jiang]{li2020unicoder}
Gen Li, Nan Duan, Yuejian Fang, Ming Gong, and Daxin Jiang.
\newblock Unicoder-vl: A universal encoder for vision and language by
  cross-modal pre-training.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pages 11336--11344, 2020{\natexlab{a}}.

\bibitem[Li et~al.(2020{\natexlab{b}})Li, Yin, Li, Zhang, Hu, Zhang, Wang, Hu,
  Dong, Wei, et~al.]{li2020oscar}
Xiujun Li, Xi~Yin, Chunyuan Li, Pengchuan Zhang, Xiaowei Hu, Lei Zhang, Lijuan
  Wang, Houdong Hu, Li~Dong, Furu Wei, et~al.
\newblock Oscar: Object-semantics aligned pre-training for vision-language
  tasks.
\newblock In \emph{European Conference on Computer Vision}, pages 121--137.
  Springer, 2020{\natexlab{b}}.

\bibitem[Li et~al.(2018)Li, Ma, and Zhang]{li2018algorithmic}
Yuanzhi Li, Tengyu Ma, and Hongyang Zhang.
\newblock Algorithmic regularization in over-parameterized matrix sensing and
  neural networks with quadratic activations.
\newblock In \emph{Conference On Learning Theory}, pages 2--47. PMLR, 2018.

\bibitem[Li et~al.(2020{\natexlab{c}})Li, Ma, and Zhang]{li2020learning}
Yuanzhi Li, Tengyu Ma, and Hongyang~R Zhang.
\newblock Learning over-parametrized two-layer neural networks beyond ntk.
\newblock In \emph{Conference on Learning Theory}, pages 2613--2682. PMLR,
  2020{\natexlab{c}}.

\bibitem[Lin et~al.(2021)Lin, Men, Yang, Zhou, Ding, Zhang, Wang, Wang, Jiang,
  Jia, et~al.]{m6}
Junyang Lin, Rui Men, An~Yang, Chang Zhou, Ming Ding, Yichang Zhang, Peng Wang,
  Ang Wang, Le~Jiang, Xianyan Jia, et~al.
\newblock M6: A chinese multimodal pretrainer.
\newblock \emph{arXiv preprint arXiv:2103.00823}, 2021.

\bibitem[Liu et~al.(2018)Liu, Li, Xu, and Natarajan]{liu2018learn}
Kuan Liu, Yanen Li, Ning Xu, and Prem Natarajan.
\newblock Learn to combine modalities in multimodal deep learning.
\newblock \emph{arXiv preprint arXiv:1805.11730}, 2018.

\bibitem[Loshchilov and Hutter(2019)]{adamw}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock In \emph{{ICLR} 2019}, 2019.

\bibitem[Mairal et~al.(2010)Mairal, Bach, Ponce, and Sapiro]{mairal2010online}
Julien Mairal, Francis Bach, Jean Ponce, and Guillermo Sapiro.
\newblock Online learning for matrix factorization and sparse coding, 2010.

\bibitem[Ngiam et~al.(2011)Ngiam, Khosla, Kim, Nam, Lee, and
  Ng]{ngiam2011multimodal}
Jiquan Ngiam, Aditya Khosla, Mingyu Kim, Juhan Nam, Honglak Lee, and Andrew~Y
  Ng.
\newblock Multimodal deep learning.
\newblock In \emph{ICML}, 2011.

\bibitem[Olshausen and Field(1997)]{OLSHAUSEN19973311}
Bruno~A. Olshausen and David~J. Field.
\newblock Sparse coding with an overcomplete basis set: A strategy employed by
  v1?
\newblock \emph{Vision Research}, 37\penalty0 (23):\penalty0 3311--3325, 1997.
\newblock ISSN 0042-6989.

\bibitem[Sarussi et~al.(2021)Sarussi, Brutzkus, and
  Globerson]{sarussi2021towards}
Roei Sarussi, Alon Brutzkus, and Amir Globerson.
\newblock Towards understanding learning in neural networks with linear
  teachers.
\newblock \emph{arXiv preprint arXiv:2101.02533}, 2021.

\bibitem[Schneider et~al.(2019)Schneider, Baevski, Collobert, and
  Auli]{schneider2019wav2vec}
Steffen Schneider, Alexei Baevski, Ronan Collobert, and Michael Auli.
\newblock wav2vec: Unsupervised pre-training for speech recognition.
\newblock \emph{arXiv preprint arXiv:1904.05862}, 2019.

\bibitem[Shafiee et~al.(2015)Shafiee, Kamangar, and Athitsos]{shafiee2015multi}
Soheil Shafiee, Farhad Kamangar, and Vassilis Athitsos.
\newblock A multi-modal sparse coding classifier using dictionaries with
  different number of atoms.
\newblock In \emph{2015 IEEE Winter Conference on Applications of Computer
  Vision}, pages 518--525. IEEE, 2015.

\bibitem[Simonyan and Zisserman(2014)]{simonyan2014two}
Karen Simonyan and Andrew Zisserman.
\newblock Two-stream convolutional networks for action recognition in videos.
\newblock \emph{arXiv preprint arXiv:1406.2199}, 2014.

\bibitem[Sridharan and Kakade(2008)]{sridharan2008information}
Karthik Sridharan and Sham~M Kakade.
\newblock An information theoretic framework for multi-view learning.
\newblock 2008.

\bibitem[Sun et~al.(2020)Sun, Xu, Cao, Kong, Hu, Zhang, and Wang]{sun2020tcgm}
Xinwei Sun, Yilun Xu, Peng Cao, Yuqing Kong, Lingjing Hu, Shanghang Zhang, and
  Yizhou Wang.
\newblock Tcgm: An information-theoretic framework for semi-supervised
  multi-modality learning, 2020.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{transformer}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N. Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{NeurIPS 2017}, pages 5998--6008, 2017.

\bibitem[Wang et~al.(2020)Wang, Tran, and Feiszli]{wang2020makes}
Weiyao Wang, Du~Tran, and Matt Feiszli.
\newblock What makes training multi-modal classification networks hard?
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 12695--12705, 2020.

\bibitem[Wen and Li(2021)]{wen2021toward}
Zixin Wen and Yuanzhi Li.
\newblock Toward understanding the feature learning process of self-supervised
  contrastive learning.
\newblock \emph{arXiv preprint arXiv:2105.15134}, 2021.

\bibitem[Whitaker and Anderson(2016)]{whitaker2016heart}
Bradley~M Whitaker and David~V Anderson.
\newblock Heart sound classification via sparse coding.
\newblock In \emph{2016 Computing in Cardiology Conference (CinC)}, pages
  805--808. IEEE, 2016.

\bibitem[Woodworth et~al.(2020)Woodworth, Gunasekar, Lee, Moroshko, Savarese,
  Golan, Soudry, and Srebro]{woodworth2020kernel}
Blake Woodworth, Suriya Gunasekar, Jason~D Lee, Edward Moroshko, Pedro
  Savarese, Itay Golan, Daniel Soudry, and Nathan Srebro.
\newblock Kernel and rich regimes in overparametrized models.
\newblock In \emph{Conference on Learning Theory}, pages 3635--3673. PMLR,
  2020.

\bibitem[Xu et~al.(2013)Xu, Tao, and Xu]{xu2013survey}
Chang Xu, Dacheng Tao, and Chao Xu.
\newblock A survey on multi-view learning.
\newblock \emph{arXiv preprint arXiv:1304.5634}, 2013.

\bibitem[Yang et~al.(2009)Yang, Yu, Gong, and Huang]{yang2009linear}
Jianchao Yang, Kai Yu, Yihong Gong, and Thomas Huang.
\newblock Linear spatial pyramid matching using sparse coding for image
  classification.
\newblock In \emph{2009 IEEE Conference on computer vision and pattern
  recognition}, pages 1794--1801. IEEE, 2009.

\bibitem[Yang et~al.(2015)Yang, Ye, Zhan, and Jiang]{yang2015auxiliary}
Yang Yang, Han-Jia Ye, De-Chuan Zhan, and Yuan Jiang.
\newblock Auxiliary information regularized machine for multiple modality
  feature learning.
\newblock In \emph{Twenty-Fourth International Joint Conference on Artificial
  Intelligence}, 2015.

\bibitem[Yogatama et~al.(2015)Yogatama, Faruqui, Dyer, and
  Smith]{yogatama2015learning}
Dani Yogatama, Manaal Faruqui, Chris Dyer, and Noah Smith.
\newblock Learning word representations with hierarchical sparse coding.
\newblock In \emph{International Conference on Machine Learning}, pages 87--96.
  PMLR, 2015.

\bibitem[Yuan et~al.(2012)Yuan, Liu, and Yan]{yuan2012visual}
Xiao-Tong Yuan, Xiaobai Liu, and Shuicheng Yan.
\newblock Visual classification with multitask joint sparse representation.
\newblock \emph{IEEE Transactions on Image Processing}, 21\penalty0
  (10):\penalty0 4349--4360, 2012.

\bibitem[Zhang et~al.(2019)Zhang, Han, Cui, Fu, Zhou, and Hu]{zhang2019cpm}
Changqing Zhang, Zongbo Han, Yajie Cui, Huazhu Fu, Joey~Tianyi Zhou, and
  Qinghua Hu.
\newblock Cpm-nets: cross partial multi-view networks.
\newblock In \emph{Proceedings of the 33rd International Conference on Neural
  Information Processing Systems}, pages 559--569, 2019.

\bibitem[Zhao et~al.(2019)Zhao, Gan, Ma, and Torralba]{zhao2019sound}
Hang Zhao, Chuang Gan, Wei-Chiu Ma, and Antonio Torralba.
\newblock The sound of motions.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 1735--1744, 2019.

\end{thebibliography}
