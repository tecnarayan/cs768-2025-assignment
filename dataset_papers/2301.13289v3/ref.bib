@article{tsitsiklis1997analysis,
  title={An Analysis of Temporal-Difference Learning with Function Approximation},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  journal={IEEE TRANSACTIONS ON AUTOMATIC CONTROL},
  volume={42},
  number={5},
  year={1997}
}

@incollection{baird1995residual,
  title={Residual algorithms: Reinforcement learning with function approximation},
  author={Baird, Leemon},
  booktitle={Machine Learning Proceedings 1995},
  pages={30--37},
  year={1995},
  publisher={Elsevier}
}


@inproceedings{sutton2009fast,
  title={Fast gradient-descent methods for temporal-difference learning with linear function approximation},
  author={Sutton, Richard S and Maei, Hamid Reza and Precup, Doina and Bhatnagar, Shalabh and Silver, David and Szepesv{\'a}ri, Csaba and Wiewiora, Eric},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={993--1000},
  year={2009}
}
@article{maei2009convergent,
  title={Convergent temporal-difference learning with arbitrary smooth function approximation},
  author={Maei, Hamid and Szepesvari, Csaba and Bhatnagar, Shalabh and Precup, Doina and Silver, David and Sutton, Richard S},
  journal={Advances in neural information processing systems},
  volume={22},
  year={2009}
}

@article{schultz1997neural,
  title={A neural substrate of prediction and reward},
  author={Schultz, Wolfram and Dayan, Peter and Montague, P Read},
  journal={Science},
  volume={275},
  number={5306},
  pages={1593--1599},
  year={1997},
  publisher={American Association for the Advancement of Science}
}

@article{sutton1988learning,
  title={Learning to predict by the methods of temporal differences},
  author={Sutton, Richard S},
  journal={Machine learning},
  volume={3},
  number={1},
  pages={9--44},
  year={1988},
  publisher={Springer}
}

@article{bertsekas1991analysis,
  title={An analysis of stochastic shortest path problems},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  journal={Mathematics of Operations Research},
  volume={16},
  number={3},
  pages={580--595},
  year={1991},
  publisher={INFORMS}
}

@article{tsitsiklis1996analysis,
  title={Analysis of temporal-diffference learning with function approximation},
  author={Tsitsiklis, John and Van Roy, Benjamin},
  journal={Advances in neural information processing systems},
  volume={9},
  year={1996}
}

@article{cai2019neural,
  title={Neural temporal-difference learning converges to global optima},
  author={Cai, Qi and Yang, Zhuoran and Lee, Jason D and Wang, Zhaoran},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{sutton1999open,
  title={Open theoretical questions in reinforcement learning},
  author={Sutton, Richard S},
  booktitle={European Conference on Computational Learning Theory},
  pages={11--17},
  year={1999},
  organization={Springer}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{dayan1994td,
  title={TD ($\lambda$) converges with probability 1},
  author={Dayan, Peter and Sejnowski, Terrence J},
  journal={Machine Learning},
  volume={14},
  number={3},
  pages={295--301},
  year={1994},
  publisher={Springer}
}

@article{jaakkola1993convergence,
  title={Convergence of stochastic iterative dynamic programming algorithms},
  author={Jaakkola, Tommi and Jordan, Michael and Singh, Satinder},
  journal={Advances in neural information processing systems},
  volume={6},
  year={1993}
}

@inproceedings{kearns2000bias,
  title={Bias-Variance Error Bounds for Temporal Difference Updates.},
  author={Kearns, Michael J and Singh, Satinder},
  booktitle={COLT},
  pages={142--147},
  year={2000}
}

@article{tadic2001convergence,
  title={On the convergence of temporal-difference learning with linear function approximation},
  author={Tadi{\'c}, Vladislav},
  journal={Machine learning},
  volume={42},
  number={3},
  pages={241--267},
  year={2001},
  publisher={Springer}
}

@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}

@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Pieter Abbeel, OpenAI and Zaremba, Wojciech},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{wang2016sample,
  title={Sample efficient actor-critic with experience replay},
  author={Wang, Ziyu and Bapst, Victor and Heess, Nicolas and Mnih, Volodymyr and Munos, Remi and Kavukcuoglu, Koray and de Freitas, Nando},
  journal={arXiv preprint arXiv:1611.01224},
  year={2016}
}

@article{bradtke1996linear,
  title={Linear least-squares algorithms for temporal difference learning},
  author={Bradtke, Steven J and Barto, Andrew G},
  journal={Machine learning},
  volume={22},
  number={1},
  pages={33--57},
  year={1996},
  publisher={Springer}
}

@inproceedings{lazaric2010finite,
  title={Finite-sample analysis of LSTD},
  author={Lazaric, Alessandro and Ghavamzadeh, Mohammad and Munos, R{\'e}mi},
  booktitle={ICML-27th International Conference on Machine Learning},
  pages={615--622},
  year={2010}
}

@article{nedic2003least,
  title={Least squares policy evaluation algorithms with linear function approximation},
  author={Nedi{\'c}, A and Bertsekas, Dimitri P},
  journal={Discrete Event Dynamic Systems},
  volume={13},
  number={1},
  pages={79--110},
  year={2003},
  publisher={Springer}
}

@inproceedings{tagorti2015rate,
  title={On the Rate of Convergence and Error Bounds for LSTD ($\lambda$)},
  author={Tagorti, Manel and Scherrer, Bruno},
  booktitle={International Conference on Machine Learning},
  pages={1521--1529},
  year={2015},
  organization={PMLR}
}

@article{pires2012statistical,
  title={Statistical linear estimation with penalized estimators: an application to reinforcement learning},
  author={Pires, Bernardo Avila and Szepesv{\'a}ri, Csaba},
  journal={arXiv preprint arXiv:1206.6444},
  year={2012}
}


@inproceedings{bhandari2018finite,
  title={A finite time analysis of temporal difference learning with linear function approximation},
  author={Bhandari, Jalaj and Russo, Daniel and Singal, Raghav},
  booktitle={Conference on learning theory},
  pages={1691--1692},
  year={2018},
  organization={PMLR}
}

@article{prentice1989surrogate,
	title={Surrogate endpoints in clinical trials: definition and operational criteria},
	author={Prentice, Ross L},
	journal={Statistics in Medicine},
	volume={8},
	number={4},
	pages={431--440},
	year={1989},
	publisher={Wiley Online Library}
}

@techreport{athey2019surrogate,
  title={The surrogate index: Combining short-term proxies to estimate long-term treatment effects more rapidly and precisely},
  author={Athey, Susan and Chetty, Raj and Imbens, Guido W and Kang, Hyunseung},
  year={2019},
  institution={National Bureau of Economic Research}
}

@inproceedings{lu2005error,
  title={Error bounds in reinforcement learning policy evaluation},
  author={Lu, Fletcher},
  booktitle={Conference of the Canadian Society for Computational Studies of Intelligence},
  pages={438--449},
  year={2005},
  organization={Springer}
}

@inproceedings{mannor2004bias,
  title={Bias and variance in value function estimation},
  author={Mannor, Shie and Simester, Duncan and Sun, Peng and Tsitsiklis, John N},
  booktitle={Proceedings of the twenty-first international conference on Machine learning},
  pages={72},
  year={2004}
}

@article{szepesvari2010algorithms,
  title={Algorithms for reinforcement learning},
  author={Szepesv{\'a}ri, Csaba},
  journal={Synthesis lectures on artificial intelligence and machine learning},
  volume={4},
  number={1},
  pages={1--103},
  year={2010},
  publisher={Morgan \& Claypool Publishers}
}

@inproceedings{grunewalder2007optimality,
  title={Optimality of lstd and its relation to mc},
  author={Grunewalder, Steffen and Hochreiter, Sepp and Obermayer, Klaus},
  booktitle={2007 International Joint Conference on Neural Networks},
  pages={338--343},
  year={2007},
  organization={IEEE}
}

@article{grunewalder2011optimal,
  title={The optimal unbiased value estimator and its relation to LSTD, TD and MC},
  author={Gr{\"u}new{\"a}lder, Steffen and Obermayer, Klaus},
  journal={Machine learning},
  volume={83},
  number={3},
  pages={289--330},
  year={2011},
  publisher={Springer}
}

@article{khamaru2020temporal,
  title={Is temporal difference learning optimal? an instance-dependent analysis},
  author={Khamaru, Koulik and Pananjady, Ashwin and Ruan, Feng and Wainwright, Martin J and Jordan, Michael I},
  journal={arXiv preprint arXiv:2003.07337},
  year={2020}
}

@article{pananjady2020instance,
  title={Instance-dependent $\ell_\infty$-bounds for policy evaluation in tabular reinforcement learning},
  author={Pananjady, Ashwin and Wainwright, Martin J},
  journal={IEEE Transactions on Information Theory},
  volume={67},
  number={1},
  pages={566--585},
  year={2020},
  publisher={IEEE}
}

@article{farias2022markovian,
  title={Markovian Interference in Experiments},
  author={Farias, Vivek F and Li, Andrew A and Peng, Tianyi and Zheng, Andrew T},
  journal={arXiv preprint arXiv:2206.02371},
  year={2022}
}

@inproceedings{maystretemporally,
  title={Temporally-Consistent Survival Analysis},
  author={Maystre, Lucas and Russo, Daniel},
  booktitle={Advances in Neural Information Processing Systems}
}

@article{fujimoto2022should,
  title={Why Should I Trust You, Bellman? The Bellman Error is a Poor Replacement for Value Error},
  author={Fujimoto, Scott and Meger, David and Precup, Doina and Nachum, Ofir and Gu, Shixiang Shane},
  journal={arXiv preprint arXiv:2201.12417},
  year={2022}
}

@article{kallus2022efficiently,
  title={Efficiently breaking the curse of horizon in off-policy evaluation with double reinforcement learning},
  author={Kallus, Nathan and Uehara, Masatoshi},
  journal={Operations Research},
  year={2022},
  publisher={INFORMS}
}

@inproceedings{chen2020explicit,
  title={Explicit mean-square error bounds for monte-carlo and linear stochastic approximation},
  author={Chen, Shuhang and Devraj, Adithya and Busic, Ana and Meyn, Sean},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4173--4183},
  year={2020},
  organization={PMLR}
}

@techreport{baird1993advantage,
  title={Advantage updating},
  author={Baird III, Leemon C},
  year={1993},
  institution={WRIGHT LAB WRIGHT-PATTERSON AFB OH}
}

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@article{ghugare2024closing,
  title={Closing the Gap between TD Learning and Supervised Learning--A Generalisation Point of View},
  author={Ghugare, Raj and Geist, Matthieu and Berseth, Glen and Eysenbach, Benjamin},
  journal={arXiv preprint arXiv:2401.11237},
  year={2024}
}