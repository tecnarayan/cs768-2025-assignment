@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@string{eccv = "Proceedings of the European Conference on Computer Vision (ECCV)"}
@string{icml = "Proceedings of the International Conference on Machine Learning (ICML)"}
@string{iclr = "Proceedings of the International Conference on Learning Representations (ICLR)"}
@string{neurips = "Advances in Neural Information Processing Systems (NeurIPS)"}
@string{cvpr = "Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)"}
@string{iccv = "Proceedings of the International Conference on Computer Vision (ICCV)"}
@string{bmvc = "Proceedings of the British Machine Vision Conference (BMVC)"}
@string{wacv = "Proceedings of the IEEE Winter Conference on Applications of Computer Vision (WACV)"}

%start
@string{AAAI = {Proc. AAAI Conference on Artificial Intelligence (AAAI)}}
@string{ACMMM = {Proc. ACM Multimedia Conference (ACMMM)}}
@string{BMVC = {Proc. British Machine Vision Conference (BMVC)}}
@string{CVIU = {Computer Vision and Image Understanding (CVIU)}}
@string{CVPR = {Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}}
@string{ECCV = {Proc. European Conference on Computer Vision (ECCV)}}
@string{GCPR = {Proc. German Conference on Pattern Recognition (GCPR)}}
@string{ICCV = {Proc. IEEE International Conference on Computer Vision (ICCV)}}
@string{ICLR = {Proc. International Conference on Learning Representations (ICLR)}}
@string{ICML = {Proc. International Conference on Machine Learning (ICML)}}
@string{ICRA = {Proc. International Conference on Robatics and Automation (ICRA)}}
@string{IJCAI = {Proc. International Joint Conference on Artificial Intelligence (IJCAI)}}
@string{MICCAI = {Proc. Medical Image Computing and Computer-Assisted Intervention (MICCAI)}}
@string{NIPS = {Proc. Neural Information Processing Systems (NeurIPS)}}
@string{OSDI = {Proc. USENIX Conference on Operating Systems Design and Implementation (OSDI)}}
@string{WACV = {Proc. IEEE Winter Conference on Applications of Computer Vision (WACV)}}

@string{ICPR = {Proc. International Conference on Pattern Recognition (ICPR)}}

@string{IJCV = {International Journal of Computer Vision (IJCV)}}
@string{JMLR = {Journal of Machine Learning Research (JMLR)}}
@string{TIP = {IEEE Transactions on Image Processing (TIP)}}
@string{TPAMI = {IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)}}

@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = cvpr,
pages = {234--778},
year = 2005
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%deep learning
%imagenet
@inproceedings{krizhevsky2012imagenet,
  title={{Imagenet classification with deep convolutional neural networks}},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle = neurips,
  pages={1097--1105},
  year={2012}
}

@inproceedings{he2016deep,
  title={{Deep residual learning for image recognition}},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle = cvpr,
  pages={770--778},
  year={2016}
}

%googlenet
@inproceedings{szegedy2015going,
  title={{Going deeper with convolutions}},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle=cvpr,
  pages={1--9},
  year={2015}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%3D - Action Recognition --------------------------------------------------------------------------------------
@inproceedings{tran2015learning,
  title={{Learning spatiotemporal features with 3d convolutional networks}},
  author={Tran, Du and Bourdev, Lubomir and Fergus, Rob and Torresani, Lorenzo and Paluri, Manohar},
  booktitle=iccv,
  pages={4489--4497},
  year={2015}
}
@inproceedings{carreira2017quo,
  title={{Quo vadis, action recognition? a new model and the kinetics dataset}},
  author={Carreira, Joao and Zisserman, Andrew},
  booktitle=cvpr,
  pages={6299--6308},
  year={2017}
}
@inproceedings{tran2018closer,
  title={{A closer look at spatiotemporal convolutions for action recognition}},
  author={Tran, Du and Wang, Heng and Torresani, Lorenzo and Ray, Jamie and LeCun, Yann and Paluri, Manohar},
  booktitle=cvpr,
  pages={6450--6459},
  year={2018}
}
@inproceedings{feichtenhofer2020x3d,
  title={{X3D: Expanding Architectures for Efficient Video Recognition}},
  author={Feichtenhofer, Christoph},
  booktitle=cvpr,
  pages={203--213},
  year={2020}
}
@inproceedings{lin2019tsm,
  title={{Tsm: Temporal shift module for efficient video understanding}},
  author={Lin, Ji and Gan, Chuang and Han, Song},
  booktitle=iccv,
  pages={7083--7093},
  year={2019}
}
@inproceedings{kwon2020motionsqueeze,
  title={{Motionsqueeze: Neural motion feature learning for video understanding}},
  author={Kwon, Heeseung and Kim, Manjin and Kwak, Suha and Cho, Minsu},
  booktitle=eccv,
  pages={345--362},
  year={2020},
  organization={Springer}
}

%Action segmentation --------------------------------------------------------------------------------------
%ASformer
@inproceedings{yi2021asformer,
  title={ASFormer: Transformer for Action Segmentation},
  author={Yi, Fangqiu and Wen, Hongyu and Jiang, Tingting},
  booktitle=BMVC, 
  year={2021}
}

%UVAST
@inproceedings{behrmann2022unified,
  title={Unified fully and timestamp supervised temporal action segmentation via sequence to sequence translation},
  author={Behrmann, Nadine and Golestaneh, S Alireza and Kolter, Zico and Gall, J{\"u}rgen and Noroozi, Mehdi},
  booktitle=eccv,
  pages={52--68},
  year={2022},
  organization={Springer}
}
%SSTDA
@inproceedings{chen2020action,
  title={{Action segmentation with joint self-supervised temporal domain adaptation}},
  author={Chen, Min-Hung and Li, Baopu and Bao, Yingze and AlRegib, Ghassan and Kira, Zsolt},
  booktitle=cvpr,
  pages={9454--9463},
  year={2020}
}
%MSTCN
@inproceedings{farha2019ms,
  title={{Ms-tcn: Multi-stage temporal convolutional network for action segmentation}},
  author={Farha, Yazan Abu and Gall, Jurgen},
  booktitle=cvpr,
  pages={3575--3584},
  year={2019}
}

%TCN
@inproceedings{lea2017temporal,
  title={Temporal convolutional networks for action segmentation and detection},
  author={Lea, Colin and Flynn, Michael D and Vidal, Rene and Reiter, Austin and Hager, Gregory D},
  booktitle=cvpr,
  pages={156--165},
  year={2017}
}
%BCN
@inproceedings{wang2020boundary,
  title={Boundary-aware cascade networks for temporal action segmentation},
  author={Wang, Zhenzhi and Gao, Ziteng and Wang, Limin and Li, Zhifeng and Wu, Gangshan},
  booktitle=eccv,
  pages={34--51},
  year={2020},
  organization={Springer}
}
%ASRF
@inproceedings{ishikawa2021alleviating,
  title={Alleviating over-segmentation errors by detecting action boundaries},
  author={Ishikawa, Yuchi and Kasai, Seito and Aoki, Yoshimitsu and Kataoka, Hirokatsu},
  booktitle=wacv,
  pages={2322--2331},
  year={2021}
}
%DA
@inproceedings{chen2020action1,
  title={Action segmentation with mixed temporal domain adaptation},
  author={Chen, Min-Hung and Li, Baopu and Bao, Yingze and AlRegib, Ghassan},
  booktitle=wacv,
  pages={605--614},
  year={2020}
}

%SSTDA
@inproceedings{chen2020action2,
  title={Action segmentation with joint self-supervised temporal domain adaptation},
  author={Chen, Min-Hung and Li, Baopu and Bao, Yingze and AlRegib, Ghassan and Kira, Zsolt},
  booktitle=cvpr,
  pages={9454--9463},
  year={2020}
}

%HMM
@inproceedings{kuehne2016end,
  title={An end-to-end generative framework for video segmentation and recognition},
  author={Kuehne, Hilde and Gall, Juergen and Serre, Thomas},
  booktitle=wacv,
  pages={1--8},
  year={2016},
  organization={IEEE}
}
%Two stream
@inproceedings{singh2016multi,
  title={A multi-stream bi-directional recurrent neural network for fine-grained action detection},
  author={Singh, Bharat and Marks, Tim K and Jones, Michael and Tuzel, Oncel and Shao, Ming},
  booktitle=cvpr,
  pages={1961--1970},
  year={2016}
}
%Wavenet
@inproceedings{DBLP:conf/ssw/OordDZSVGKSK16,
  author    = {A{\"{a}}ron van den Oord and
               Sander Dieleman and
               Heiga Zen and
               Karen Simonyan and
               Oriol Vinyals and
               Alex Graves and
               Nal Kalchbrenner and
               Andrew W. Senior and
               Koray Kavukcuoglu},
  title     = {WaveNet: {A} Generative Model for Raw Audio},
  booktitle = {The 9th {ISCA} Speech Synthesis Workshop, Sunnyvale, CA, USA, 13-15
               September 2016},
  pages     = {125},
  publisher = {{ISCA}},
  year      = {2016},
  url       = {http://www.isca-speech.org/archive/SSW\_2016/abstracts/ssw9\_DS-4\_van\_den\_Oord.html},
  timestamp = {Mon, 01 Feb 2021 08:42:47 +0100},
  biburl    = {https://dblp.org/rec/conf/ssw/OordDZSVGKSK16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{liu2023diffusion,
  title={Diffusion action segmentation},
  author={Liu, Daochang and Li, Qiyue and Dinh, Anh-Dung and Jiang, Tingting and Shah, Mubarak and Xu, Chang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10139--10149},
  year={2023}
}

%Action prediction in early stage
@inproceedings{gammulle2019predicting,
  title={{Predicting the future: A jointly learnt model for action anticipation}},
  author={Gammulle, Harshala and Denman, Simon and Sridharan, Sridha and Fookes, Clinton},
  booktitle=cvpr,
  pages={5562--5571},
  year={2019}
}
@inproceedings{sun2019relational,
  title={{Relational action forecasting}},
  author={Sun, Chen and Shrivastava, Abhinav and Vondrick, Carl and Sukthankar, Rahul and Murphy, Kevin and Schmid, Cordelia},
  booktitle=cvpr,
  pages={273--283},
  year={2019}
}

%Sliding window
@inproceedings{rohrbach2012database,
  title={A database for fine grained activity detection of cooking activities},
  author={Rohrbach, Marcus and Amin, Sikandar and Andriluka, Mykhaylo and Schiele, Bernt},
  booktitle=cvpr,
  pages={1194--1201},
  year={2012},
  organization={IEEE}
}
@inproceedings{karaman2014fast,
  title={Fast saliency based pooling of fisher encoded dense trajectories},
  author={Karaman, Svebor and Seidenari, Lorenzo and Del Bimbo, Alberto},
  booktitle={ECCV THUMOS Workshop},
  volume={1},
  pages={5},
  year={2014}
}

%Refinement for TAS -------------------------------------
%FIFA
@inproceedings{souri2022fifa,
  title={Fifa: Fast inference approximation for action segmentation},
  author={Souri, Yaser and Farha, Yazan Abu and Despinoy, Fabien and Francesca, Gianpiero and Gall, Juergen},
  booktitle={Pattern Recognition: 43rd DAGM German Conference, DAGM GCPR 2021, Bonn, Germany, September 28--October 1, 2021, Proceedings},
  pages={282--296},
  year={2022},
  organization={Springer}
}

%HARS
@inproceedings{ahn2021refining,
  title={Refining action segmentation with hierarchical video representations},
  author={Ahn, Hyemin and Lee, Dongheui},
  booktitle=iccv,
  pages={16302--16310},
  year={2021}
}

% GTRM
@inproceedings{huang2020improving,
  title={Improving action segmentation via graph-based temporal reasoning},
  author={Huang, Yifei and Sugano, Yusuke and Sato, Yoichi},
  booktitle=cvpr,
  pages={14024--14034},
  year={2020}
}

%DTL
@article{xudon,
  title={Don't pour cereal into coffee: Differentiable temporal logic for temporal action segmentation},
  author={Xu, Ziwei and Rawat, Yogesh and Wong, Yongkang and Kankanhalli, Mohan S and Shah, Mubarak},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={14890--14903},
  year={2022}
}

%Global2Local
@inproceedings{gao2021global2local,
  title={Global2local: Efficient structure search for video action segmentation},
  author={Gao, Shang-Hua and Han, Qi and Li, Zhong-Yu and Peng, Pai and Wang, Liang and Cheng, Ming-Ming},
  booktitle=cvpr,
  pages={16805--16814},
  year={2021}
}

@article{li2020ms,
  title={Ms-tcn++: Multi-stage temporal convolutional network for action segmentation},
  author={Li, Shi-Jie and AbuFarha, Yazan and Liu, Yun and Cheng, Ming-Ming and Gall, Juergen},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  year={2020},
  publisher={IEEE}
}
%LTContext
@inproceedings{bahrami2023much,
  title={How Much Temporal Long-Term Context is Needed for Action Segmentation?},
  author={Bahrami, Emad and Francesca, Gianpiero and Gall, Juergen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={10351--10361},
  year={2023}
}
%UARL
@inproceedings{chen2022uncertainty,
  title={Uncertainty-aware representation learning for action segmentation},
  author={Chen, Lei and Li, Muheng and Duan, Yueqi and Zhou, Jie and Lu, Jiwen},
  booktitle={IJCAI},
  volume={2},
  pages={6},
  year={2022}
}

%DPRN
@article{park2022maximization,
  title={Maximization and restoration: Action segmentation through dilation passing and temporal reconstruction},
  author={Park, Junyong and Kim, Daekyum and Huh, Sejoon and Jo, Sungho},
  journal={Pattern Recognition},
  volume={129},
  pages={108764},
  year={2022},
  publisher={Elsevier}
}

%SEDT
@article{kim2022stacked,
  title={Stacked encoder--decoder transformer with boundary smoothing for action segmentation},
  author={Kim, Gyeong-hyeon and Kim, Eunwoo},
  journal={Electronics Letters},
  volume={58},
  number={25},
  pages={972--974},
  year={2022},
  publisher={Wiley Online Library}
}

%TCTr
@article{aziere2022multistage,
  title={Multistage temporal convolution transformer for action segmentation},
  author={Aziere, Nicolas and Todorovic, Sinisa},
  journal={Image and Vision Computing},
  volume={128},
  pages={104567},
  year={2022},
  publisher={Elsevier}
}

%FAMMSDTN
@article{du2022dilated,
  title={Dilated transformer with feature aggregation module for action segmentation},
  author={Du, Zexing and Wang, Qing},
  journal={Neural Processing Letters},
  pages={1--17},
  year={2022},
  publisher={Springer}
}

%BRPrompt
@inproceedings{li2022bridge,
  title={Bridge-prompt: Towards ordinal action understanding in instructional videos},
  author={Li, Muheng and Chen, Lei and Duan, Yueqi and Hu, Zhilan and Feng, Jianjiang and Zhou, Jie and Lu, Jiwen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19880--19889},
  year={2022}
}

%MCFM
@inproceedings{ishihara2022mcfm,
  title={MCFM: Mutual cross fusion module for intermediate fusion-based action segmentation},
  author={Ishihara, Kenta and Nakano, Gaku and Inoshita, Tetsuo},
  booktitle={2022 IEEE International Conference on Image Processing (ICIP)},
  pages={1701--1705},
  year={2022},
  organization={IEEE}
}

% Action anticipation--------------------------------------------------------------------------------------
%survey
@article{zhong2023survey,
  title={A Survey on Deep Learning Techniques for Action Anticipation},
  author={Zhong, Zeyun and Martin, Manuel and Voit, Michael and Gall, Juergen and Beyerer, J{\"u}rgen},
  journal={arXiv preprint arXiv:2309.17257},
  year={2023}
}

@inproceedings{gong2022future,
  title={Future Transformer for Long-term Action Anticipation},
  author={Gong, Dayoung and Lee, Joonseok and Kim, Manjin and Ha, Seong Jong and Cho, Minsu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3052--3061},
  year={2022}
}

@inproceedings{nawhal2022rethinking,
  title={Rethinking learning approaches for long-term action anticipation},
  author={Nawhal, Megha and Jyothi, Akash Abdu and Mori, Greg},
  booktitle={European Conference on Computer Vision},
  pages={558--576},
  year={2022},
  organization={Springer}
}

%A-ACT
@article{gupta2022act,
  title={A-ACT: Action Anticipation through Cycle Transformations},
  author={Gupta, Akash and Liu, Jingen and Bo, Liefeng and Roy-Chowdhury, Amit K and Mei, Tao},
  journal={arXiv preprint arXiv:2204.00942},
  year={2022}
}

@inproceedings{abu2018will,
  title={{When will you do what?-anticipating temporal occurrences of activities}},
  author={Abu Farha, Yazan and Richard, Alexander and Gall, Juergen},
  booktitle=cvpr,
  pages={5343--5352},
  year={2018}
}
@inproceedings{ke2019time,
  title={{Time-conditioned action anticipation in one shot}},
  author={Ke, Qiuhong and Fritz, Mario and Schiele, Bernt},
  booktitle=cvpr,
  pages={9925--9934},
  year={2019}
}

@inproceedings{sener2020temporal,
  title={{Temporal aggregate representations for long-range video understanding}},
  author={Sener, Fadime and Singhania, Dipika and Yao, Angela},
  booktitle=eccv,
  pages={154--171},
  year={2020},
  organization={Springer}
}
@inproceedings{farha2020long,
  title={{Long-Term Anticipation of Activities with Cycle Consistency}},
  author={Farha, Yazan Abu and Ke, Qiuhong and Schiele, Bernt and Gall, Juergen},
  booktitle=GCPR,
  year={2020},
  organization={Springer}
}
%UAAA
@inproceedings{abu2019uncertainty,
  title={Uncertainty-aware anticipation of activities},
  author={Abu Farha, Yazan and Gall, Juergen},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops},
  pages={0--0},
  year={2019}
}
%AVT
@inproceedings{girdhar2021anticipative,
  title={{Anticipative Video Transformer}},
  author={Girdhar, Rohit and Grauman, Kristen},
  booktitle=iccv,
  year={2021}
}

% HERO
@inproceedings{li2020hero,
  title={HERO: Hierarchical Encoder for Video+ Language Omni-representation Pre-training},
  author={Li, Linjie and Chen, Yen-Chun and Cheng, Yu and Gan, Zhe and Yu, Licheng and Liu, Jingjing},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={2046--2065},
  year={2020}
}

% UniVL
@article{luo2020univl,
  title={Univl: A unified video and language pre-training model for multimodal understanding and generation},
  author={Luo, Huaishao and Ji, Lei and Shi, Botian and Huang, Haoyang and Duan, Nan and Li, Tianrui and Li, Jason and Bharti, Taroon and Zhou, Ming},
  journal={arXiv preprint arXiv:2002.06353},
  year={2020}
}

% ActBert
@inproceedings{zhu2020actbert,
  title={Actbert: Learning global-local video-text representations},
  author={Zhu, Linchao and Yang, Yi},
  booktitle=cvpr,
  pages={8746--8755},
  year={2020}
}
%RULSTM
@inproceedings{furnari2019would,
  title={What would you expect? anticipating egocentric actions with rolling-unrolling lstms and modality attention},
  author={Furnari, Antonino and Farinella, Giovanni Maria},
  booktitle=iccv,
  pages={6252--6261},
  year={2019}
}
%leveraging the present to anticipate the future in videos
@inproceedings{miech2019leveraging,
  title={{Leveraging the present to anticipate the future in videos}},
  author={Miech, Antoine and Laptev, Ivan and Sivic, Josef and Wang, Heng and Torresani, Lorenzo and Tran, Du},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  pages={0--0},
  year={2019}
}
%jaccard
@inproceedings{fernando2021anticipating,
  title={Anticipating human actions by correlating past with the future with Jaccard similarity measures},
  author={Fernando, Basura and Herath, Samitha},
  booktitle=cvpr,
  pages={13224--13233},
  year={2021}
}
%zero shot
@inproceedings{sener2019zero,
  title={{Zero-shot anticipation for instructional activities}},
  author={Sener, Fadime and Yao, Angela},
  booktitle=iccv,
  pages={862--871},
  year={2019}
}

%object prompt
@inproceedings{zhang2024object,
  title={Object-centric Video Representation for Long-term Action Anticipation},
  author={Zhang, Ce and Fu, Changcheng and Wang, Shijie and Agarwal, Nakul and Lee, Kwonjoon and Choi, Chiho and Sun, Chen},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={6751--6761},
  year={2024}
}

%Dataset--------------------------------------------------------------------------------------
%Breakfast
@inproceedings{kuehne2014language,
  title={{The language of actions: Recovering the syntax and semantics of goal-directed human activities}},
  author={Kuehne, Hilde and Arslan, Ali and Serre, Thomas},
  booktitle=cvpr,
  pages={780--787},
  year={2014}
}

%50 Salads
@inproceedings{stein2013combining,
  title={{Combining embedded accelerometers with computer vision for recognizing food preparation activities}},
  author={Stein, Sebastian and McKenna, Stephen J},
  booktitle={Proceedings of the 2013 ACM international joint conference on Pervasive and ubiquitous computing},
  pages={729--738},
  year={2013}
}
%EK55
@inproceedings{Damen2018EPICKITCHENS,
   title={Scaling Egocentric Vision: The EPIC-KITCHENS Dataset},
   author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria  and Fidler, Sanja and 
           Furnari, Antonino and Kazakos, Evangelos and Moltisanti, Davide and Munro, Jonathan 
           and Perrett, Toby and Price, Will and Wray, Michael},
   booktitle=eccv,
   year={2018}
} 
%EK100
@ARTICLE{Damen2020rescaling,
           title={Rescaling Egocentric Vision: Collection, Pipeline and Challenges for EPIC-KITCHENS-100},
           author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria  and and Furnari, Antonino 
           and Ma, Jian and Kazakos, Evangelos and Moltisanti, Davide and Munro, Jonathan 
           and Perrett, Toby and Price, Will and Wray, Michael},
           journal   = IJCV,
           year      = {2021},
           Url       = {https://doi.org/10.1007/s11263-021-01531-2}
} 

%Transformer--------------------------------------------------------------------------------------
%VIT
@inproceedings{dosovitskiy2020image,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle=ICLR,
  year={2020}
}
%DETR
@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle=ECCV,
  pages={213--229},
  year={2020},
  organization={Springer}
}

%Transformer
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal=NIPS,
  volume={30},
  year={2017}
}

%AGT
@article{nawhal2021activity,
  title={Activity Graph Transformer for Temporal Action Localization},
  author={Nawhal, Megha and Mori, Greg},
  journal={arXiv preprint arXiv:2101.08540},
  year={2021}
}

%Action transformer
@inproceedings{girdhar2019video,
  title={Video action transformer network},
  author={Girdhar, Rohit and Carreira, Joao and Doersch, Carl and Zisserman, Andrew},
  booktitle=CVPR,
  pages={244--253},
  year={2019}
}

%SSTVOS
@inproceedings{duke2021sstvos,
  title={Sstvos: Sparse spatiotemporal transformers for video object segmentation},
  author={Duke, Brendan and Ahmed, Abdalla and Wolf, Christian and Aarabi, Parham and Taylor, Graham W},
  booktitle=CVPR,
  pages={5912--5921},
  year={2021}
}

%RNN
@inproceedings{chung2014empirical,
  title={Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author={Chung, Junyoung and Gulcehre, Caglar and Cho, Kyunghyun and Bengio, Yoshua},
  booktitle={NIPS 2014 Workshop on Deep Learning, December 2014},
  year={2014}
}
%LSTM
@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}
%DeiT
@inproceedings{touvron2021training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle=ICML,
  pages={10347--10357},
  year={2021},
  organization={PMLR}
}
%Swin transformer
@article{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  journal=ICCV,
  year={2021}
}

% attention augmented
@InProceedings{Bello_2019_ICCV,
author = {Bello, Irwan and Zoph, Barret and Vaswani, Ashish and Shlens, Jonathon and Le, Quoc V.},
title = {Attention Augmented Convolutional Networks},
booktitle = ICCV,
month = {October},
year = {2019}
}

% non local
@inproceedings{wang2018non,
  title={Non-local neural networks},
  author={Wang, Xiaolong and Girshick, Ross and Gupta, Abhinav and He, Kaiming},
  booktitle=CVPR,
  pages={7794--7803},
  year={2018}
}

%RSA
@inproceedings{kim2021relational,
  title={Relational Self-Attention: What's Missing in Attention for Video Understanding},
  author={Kim, Manjin and Kwon, Heeseung and Wang, Chunyu and Kwak, Suha and Cho, Minsu},
  booktitle=NIPS,
  year={2021}
}
%TimeSformer
@inproceedings{gberta_2021_ICML,
    author  = {Gedas Bertasius and Heng Wang and Lorenzo Torresani},
    title = {Is Space-Time Attention All You Need for Video Understanding?},
    booktitle   = ICML, 
    month = {July},
    year = {2021}
}

% ViViT
@inproceedings{arnab2021vivit,
  title={Vivit: A video vision transformer},
  author={Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lu{\v{c}}i{\'c}, Mario and Schmid, Cordelia},
  booktitle=ICCV,
  pages={6836--6846},
  year={2021}
}

% VidTR
@inproceedings{zhang2021vidtr,
  title={Vidtr: Video transformer without convolutions},
  author={Zhang, Yanyi and Li, Xinyu and Liu, Chunhui and Shuai, Bing and Zhu, Yi and Brattoli, Biagio and Chen, Hao and Marsic, Ivan and Tighe, Joseph},
  booktitle=ICCV,
  pages={13577--13587},
  year={2021}
}

% MViT
@inproceedings{fan2021multiscale,
  title={Multiscale vision transformers},
  author={Fan, Haoqi and Xiong, Bo and Mangalam, Karttikeya and Li, Yanghao and Yan, Zhicheng and Malik, Jitendra and Feichtenhofer, Christoph},
  booktitle=ICCV,
  pages={6824--6835},
  year={2021}
}

% Mformer
@article{patrick2021keeping,
  title={Keeping your eye on the ball: Trajectory attention in video transformers},
  author={Patrick, Mandela and Campbell, Dylan and Asano, Yuki and Misra, Ishan and Metze, Florian and Feichtenhofer, Christoph and Vedaldi, Andrea and Henriques, Jo{\~a}o F},
  journal=NIPS,
  volume={34},
  year={2021}
}

% BILBERT
@article{lu2019vilbert,
  title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  booktitile=NIPS,
  year={2019}
}

% stand alone
@inproceedings{ramachandran2019stand,
  title={Stand-alone self-attention in vision models},
  author={Ramachandran, Prajit and Parmar, Niki and Vaswani, Ashish and Bello, Irwan and Levskaya, Anselm and Shlens, Jon},
  booktitle=NIPS,
  volume={32},
  year={2019}
}

% CVT
@inproceedings{wu2021cvt,
  title={Cvt: Introducing convolutions to vision transformers},
  author={Wu, Haiping and Xiao, Bin and Codella, Noel and Liu, Mengchen and Dai, Xiyang and Yuan, Lu and Zhang, Lei},
  booktitle=ICCV,
  pages={22--31},
  year={2021}
}

% Segmenter
@inproceedings{strudel2021segmenter,
  title={Segmenter: Transformer for semantic segmentation},
  author={Strudel, Robin and Garcia, Ricardo and Laptev, Ivan and Schmid, Cordelia},
  booktitle=ICCV,
  pages={7262--7272},
  year={2021}
}

% linear transformer
@inproceedings{katharopoulos2020transformers,
  title={Transformers are rnns: Fast autoregressive transformers with linear attention},
  author={Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, Fran{\c{c}}ois},
  booktitle=ICML,
  pages={5156--5165},
  year={2020},
  organization={PMLR}
}

% linformer
@article{wang2020linformer,
  title={Linformer: Self-attention with linear complexity},
  author={Wang, Sinong and Li, Belinda Z and Khabsa, Madian and Fang, Han and Ma, Hao},
  journal={arXiv preprint arXiv:2006.04768},
  year={2020}
}

% performer
@article{choromanski2020rethinking,
  title={Rethinking attention with performers},
  author={Choromanski, Krzysztof and Likhosherstov, Valerii and Dohan, David and Song, Xingyou and Gane, Andreea and Sarlos, Tamas and Hawkins, Peter and Davis, Jared and Mohiuddin, Afroz and Kaiser, Lukasz and others},
  journal={arXiv preprint arXiv:2009.14794},
  year={2020}
}

% longformer
@article{beltagy2020longformer,
  title={Longformer: The long-document transformer},
  author={Beltagy, Iz and Peters, Matthew E and Cohan, Arman},
  journal={arXiv preprint arXiv:2004.05150},
  year={2020}
}

% bigbird
@inproceedings{zaheer2020big,
  title={Big Bird: Transformers for Longer Sequences.},
  author={Zaheer, Manzil and Guruganesh, Guru and Dubey, Kumar Avinava and Ainslie, Joshua and Alberti, Chris and Ontanon, Santiago and Pham, Philip and Ravula, Anirudh and Wang, Qifan and Yang, Li and others},
  booktitle=NIPS,
  year={2020}
}
%Parallel Decoding----------------------------------------------------------
@inproceedings{oord2018parallel,
  title={Parallel wavenet: Fast high-fidelity speech synthesis},
  author={Oord, Aaron and Li, Yazhe and Babuschkin, Igor and Simonyan, Karen and Vinyals, Oriol and Kavukcuoglu, Koray and Driessche, George and Lockhart, Edward and Cobo, Luis and Stimberg, Florian and others},
  booktitle=ICML,
  pages={3918--3926},
  year={2018},
  organization={PMLR}
}
@inproceedings{devlin2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={NAACL-HLT (1)},
  year={2019}
}
@inproceedings{gu2018non,
  title={Non-Autoregressive Neural Machine Translation},
  author={Gu, Jiatao and Bradbury, James and Xiong, Caiming and Li, Victor OK and Socher, Richard},
  booktitle=ICLR,
  year={2018}
}
%blockwise parallel decoding for deep 
@article{stern2018blockwise,
  title={Blockwise parallel decoding for deep autoregressive models},
  author={Stern, Mitchell and Shazeer, Noam and Uszkoreit, Jakob},
  journal=NIPS,
  volume={31},
  year={2018}
}
%
@inproceedings{sagong2019pepsi,
  title={{Pepsi: Fast image inpainting with parallel decoding network}},
  author={Sagong, Min-cheol and Shin, Yong-goo and Kim, Seung-wook and Park, Seung and Ko, Sung-jea},
  booktitle=CVPR,
  pages={11360--11368},
  year={2019}
}
@inproceedings{ghazvininejad2019mask,
  title={Mask-Predict: Parallel Decoding of Conditional Masked Language Models},
  author={Ghazvininejad, Marjan and Levy, Omer and Liu, Yinhan and Zettlemoyer, Luke},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={6112--6121},
  year={2019}
}
%parallel captioning
@inproceedings{wang2021end,
  title={End-to-End Dense Video Captioning with Parallel Decoding},
  author={Wang, Teng and Zhang, Ruimao and Lu, Zhichao and Zheng, Feng and Cheng, Ran and Luo, Ping},
  booktitle=ICCV,
  pages={6847--6857},
  year={2021}
}
%deformable DETR
@inproceedings{zhu2020deformable,
  title={Deformable DETR: Deformable Transformers for End-to-End Object Detection},
  author={Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
  booktitle=ICLR,
  year={2020}
}

%relational information-------------------------------------------------------------------
%GHRM
@inproceedings{zhou2021graph,
  title={Graph-Based High-Order Relation Modeling for Long-Term Action Recognition},
  author={Zhou, Jiaming and Lin, Kun-Yu and Li, Haoxin and Zheng, Wei-Shi},
  booktitle=CVPR,
  pages={8984--8993},
  year={2021}
}
%videograph
@inproceedings{hussein2019videograph,
title     = {VideoGraph: Recognizing Minutes-Long Human Activities in Videos},
author    = {Hussein, Noureldien and Gavves, Efstratios and Smeulders, Arnold WM},
booktitle = {ICCV Workshop on Scene Graph Representation and Learning},
year      = {2019}
}
@article{zhang2020temporal,
  title={Temporal reasoning graph for activity recognition},
  author={Zhang, Jingran and Shen, Fumin and Xu, Xing and Shen, Heng Tao},
  journal={IEEE Transactions on Image Processing},
  volume={29},
  pages={5491--5506},
  year={2020},
  publisher={IEEE}
}
%T2T-ViT
@inproceedings{yuan2021tokens,
  title={Tokens-to-token vit: Training vision transformers from scratch on imagenet},
  author={Yuan, Li and Chen, Yunpeng and Wang, Tao and Yu, Weihao and Shi, Yujun and Jiang, Zi-Hang and Tay, Francis EH and Feng, Jiashi and Yan, Shuicheng},
  booktitle=ICCV,
  pages={558--567},
  year={2021}
}
%PVT
@inproceedings{wang2021pyramid,
  title={Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
  author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
  booktitle=ICCV,
  pages={568--578},
  year={2021}
}

%Etc--------------------------------------------------------------------------------------
%AdamW
@inproceedings{loshchilov2017decoupled,
  title={Decoupled Weight Decay Regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle=ICLR,
  year={2018}
}
%He init
@inproceedings{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle=ICCV,
  pages={1026--1034},
  year={2015}
}

%cosineanneal
@inproceedings{loshchilov2016sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle=ICLR,
  year={2017}
}

%gru
@article{cho2014learning,
  title={Learning phrase representations using RNN encoder-decoder for statistical machine translation},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1406.1078},
  year={2014}
}

%lstm
@article{sak2014long,
  title={Long short-term memory based recurrent neural network architectures for large vocabulary speech recognition},
  author={Sak, Ha{\c{s}}im and Senior, Andrew and Beaufays, Fran{\c{c}}oise},
  journal={arXiv preprint arXiv:1402.1128},
  year={2014}
}

%trajectory forecasting
@inproceedings{pang2021trajectory,
  title={{Trajectory Prediction with Latent Belief Energy-Based Model}},
  author={Pang, Bo and Zhao, Tianyang and Xie, Xu and Wu, Ying Nian},
  booktitle=CVPR,
  pages={11814--11824},
  year={2021}
}

%generalize ioU
@inproceedings{rezatofighi2019generalized,
  title={{Generalized intersection over union: A metric and a loss for bounding box regression}},
  author={Rezatofighi, Hamid and Tsoi, Nathan and Gwak, JunYoung and Sadeghian, Amir and Reid, Ian and Savarese, Silvio},
  booktitle=CVPR,
  pages={658--666},
  year={2019}
}

%smooth l1 loss
@inproceedings{girshick2015fast,
  title={{Fast r-cnn}},
  author={Girshick, Ross},
  booktitle=ICCV,
  pages={1440--1448},
  year={2015}
}

%TSN
@InProceedings{wang2016_TemporalSegmentNetworks,
    title={Temporal Segment Networks: Towards Good Practices for Deep Action Recognition},
    author={Limin Wang and Yuanjun Xiong and Zhe Wang and Yu Qiao and Dahua Lin and
            Xiaoou Tang and Luc {Val Gool}},
    booktitle=ECCV,
    year={2016}
}

%Lab - jslee
@InProceedings{cho2021grounded,
    title={Grounded Situation Recognition with Transformers},
    author={Junhyeong Cho and Youngseok Yoon and Hyeonjun Lee and Suha Kwak},
    booktitle=BMVC,
    year={2021}
}
@inproceedings{mun2020local,
  title={Local-global video-text interactions for temporal grounding},
  author={Mun, Jonghwan and Cho, Minsu and Han, Bohyung},
  booktitle=CVPR,
  pages={10810--10819},
  year={2020}
}

@inproceedings{moon2021integralaction,
  title={Integralaction: Pose-driven feature integration for robust human action recognition in videos},
  author={Moon, Gyeongsik and Kwon, Heeseung and Lee, Kyoung Mu and Cho, Minsu},
  booktitle=CVPR,
  pages={3339--3348},
  year={2021}
}
@inproceedings{kwon2021learning,
  title={Learning self-similarity in space and time as generalized motion for video action recognition},
  author={Kwon, Heeseung and Kim, Manjin and Kwak, Suha and Cho, Minsu},
  booktitle=CVPR,
  pages={13065--13075},
  year={2021}
}

%hungarian algorithm
@article{kuhn1955hungarian,
  title={The Hungarian method for the assignment problem},
  author={Kuhn, Harold W},
  journal={Naval research logistics quarterly},
  volume={2},
  number={1-2},
  pages={83--97},
  year={1955},
  publisher={Wiley Online Library}
}

%MMTransformer
@article{roy2021action,
  title={Action anticipation using pairwise human-object interactions and transformers},
  author={Roy, Debaditya and Fernando, Basura},
  journal={In Proc. IEEE Transactions on Image Processing},
  volume={30},
  pages={8116--8129},
  year={2021},
  publisher={IEEE}
}

@inproceedings{lee2021ctrl,
  title={CTRL-C: Camera calibration TRansformer with Line-Classification},
  author={Lee, Jinwoo and Go, Hyunsung and Lee, Hyunjoon and Cho, Sunghyun and Sung, Minhyuk and Kim, Junho},
  booktitle=ICCV,
  pages={16228--16237},
  year={2021}
}

%Grammar--------------------------------------------------------------------------------------
%Neural-Network Viterbi
@inproceedings{richard2018neuralnetwork,
  title={Neuralnetwork-viterbi: A framework for weakly supervised video learning},
  author={Richard, Alexander and Kuehne, Hilde and Iqbal, Ahsan and Gall, Juergen},
  booktitle=cvpr,
  pages={7386--7395},
  year={2018}
}

%Weakly supervised learning of actions from transcripts
@article{kuehne2017weakly,
  title={Weakly supervised learning of actions from transcripts},
  author={Kuehne, Hilde and Richard, Alexander and Gall, Juergen},
  journal={Computer Vision and Image Understanding},
  volume={163},
  pages={78--89},
  year={2017},
  publisher={Elsevier}
}

@inproceedings{richard2017weakly,
  title={Weakly supervised action learning with rnn based fine-to-coarse modeling},
  author={Richard, Alexander and Kuehne, Hilde and Gall, Juergen},
  booktitle=cvpr,
  pages={754--763},
  year={2017}
}

%Differentiable grammars for videos
@inproceedings{piergiovanni2020differentiable,
  title={Differentiable grammars for videos},
  author={Piergiovanni, AJ and Angelova, Anelia and Ryoo, Michael S},
  booktitle=aaai,
  pages={11874--11881},
  year={2020}
}

%Adversarial generative grammars for human activity prediction
@inproceedings{piergiovanni2020adversarial,
  title={Adversarial generative grammars for human activity prediction},
  author={Piergiovanni, AJ and Angelova, Anelia and Toshev, Alexander and Ryoo, Michael S},
  booktitle=eccv,
  pages={507--523},
  year={2020},
  organization={Springer}
}

%Automata theory, languages, and computation
@article{hopcroft2006automata,
  title={Automata theory, languages, and computation},
  author={Hopcroft, John E and Motwani, Rajeev and Ullman, Jeffrey D},
  journal={International Edition},
  volume={24},
  number={2},
  pages={171--183},
  year={2006}
}

%Data-efficient graph grammar learning for molecular generation
@inproceedings{guo2021data,
  title={Data-Efficient Graph Grammar Learning for Molecular Generation},
  author={Guo, Minghao and Thost, Veronika and Li, Beichen and Das, Payel and Chen, Jie and Matusik, Wojciech},
  booktitle=iclr,
  year={2021}
}

% action sets
@inproceedings{richard2018action,
  title={Action sets: Weakly supervised action segmentation without ordering constraints},
  author={Richard, Alexander and Kuehne, Hilde and Gall, Juergen},
  booktitle=cvpr,
  pages={5987--5996},
  year={2018}
}

% Recognition of visual activities and interactions by stochastic parsing
@article{ivanov2000recognition,
  title={Recognition of visual activities and interactions by stochastic parsing},
  author={Ivanov, Yuri A. and Bobick, Aaron F.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={22},
  number={8},
  pages={852--872},
  year={2000},
  publisher={IEEE}
}

@inproceedings{moore2002recognizing,
  title={Recognizing multitasked activities from video using stochastic context-free grammar},
  author={Moore, Darnell and Essa, Irfan},
  booktitle=aaai,
  pages={770--776},
  year={2002}
}

@inproceedings{pirsiavash2014parsing,
  title={Parsing videos of actions with segmental grammars},
  author={Pirsiavash, Hamed and Ramanan, Deva},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={612--619},
  year={2014}
}

@inproceedings{si2011unsupervised,
  title={Unsupervised learning of event and-or grammar and semantics from video},
  author={Si, Zhangzhang and Pei, Mingtao and Yao, Benjamin and Zhu, Song-Chun},
  booktitle=iccv,
  pages={41--48},
  year={2011},
  organization={IEEE}
}
%And-or graph grammar
@inproceedings{qi2017predicting,
  title={Predicting human activities using stochastic grammar},
  author={Qi, Siyuan and Huang, Siyuan and Wei, Ping and Zhu, Song-Chun},
  booktitle=iccv,
  pages={1164--1172},
  year={2017}
}

%pose estimation grammar
@inproceedings{fang2018learning,
  title={Learning pose grammar to encode human body configuration for 3d pose estimation},
  author={Fang, Hao-Shu and Xu, Yuanlu and Wang, Wenguan and Liu, Xiaobai and Zhu, Song-Chun},
  booktitle=aaai,
  volume={32},
  number={1},
  year={2018}
}

@article{xu2021monocular,
  title={Monocular 3d pose estimation via pose grammar and data augmentation},
  author={Xu, Yuanlu and Wang, Wenguan and Liu, Tengyu and Liu, Xiaobai and Xie, Jianwen and Zhu, Song-Chun},
  journal=tpami,
  year={2021},
  publisher={IEEE}
}

%algebra story problem
@inproceedings{hong2021smart,
  title={SMART: A Situation Model for Algebra Story Problems via Attributed Grammar.},
  author={Hong, Yining and Li, Qing and Gong, Ran and Ciao, Daniel and Huang, Siyuan and Zhu, Song-Chun},
  booktitle=aaai,
  pages={13009--13017},
  year={2021}
}

%generalizaed earley parser
@inproceedings{qi2018generalized,
  title={Generalized earley parser: Bridging symbolic grammars and sequence data for future prediction},
  author={Qi, Siyuan and Jia, Baoxiong and Zhu, Song-Chun},
  booktitle=icml,
  pages={4171--4179},
  year={2018},
  organization={PMLR}
}

%neuro-symbolic
@inproceedings{li2020closed,
  title={Closed loop neural-symbolic learning via integrating neural perception, grammar parsing, and symbolic reasoning},
  author={Li, Qing and Huang, Siyuan and Hong, Yining and Chen, Yixin and Wu, Ying Nian and Zhu, Song-Chun},
  booktitle=icml,
  pages={5884--5894},
  year={2020},
  organization={PMLR}
}

%grammar induction
@inproceedings{hong2021vlgrammar,
  title={Vlgrammar: Grounded grammar induction of vision and language},
  author={Hong, Yining and Li, Qing and Zhu, Song-Chun and Huang, Siyuan},
  booktitle=iccv,
  pages={1665--1674},
  year={2021}
}

@inproceedings{wan2021unsupervised,
  title={Unsupervised vision-language grammar induction with shared structure modeling},
  author={Wan, Bo and Han, Wenjuan and Zheng, Zilong and Tuytelaars, Tinne},
  booktitle=iclr,
  year={2021}
}

%Grammar induction in NLP
@inproceedings{kim2019compound,
  title={Compound Probabilistic Context-Free Grammars for Grammar Induction},
  author={Kim, Yoon and Dyer, Chris and Rush, Alexander M},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={2369--2385},
  year={2019}
}

@inproceedings{kim2019unsupervised,
  title={Unsupervised Recurrent Neural Network Grammars},
  author={Kim, Yoon and Rush, Alexander M and Yu, Lei and Kuncoro, Adhiguna and Dyer, Chris and Melis, G{\'a}bor},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={1105--1117},
  year={2019}
}

@article{kim2021sequence,
  title={Sequence-to-sequence learning with latent neural grammars},
  author={Kim, Yoon},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={26302--26317},
  year={2021}
}

%ADIOS
@article{solan2005unsupervised,
  title={Unsupervised learning of natural languages},
  author={Solan, Zach and Horn, David and Ruppin, Eytan and Edelman, Shimon},
  journal={Proceedings of the National Academy of Sciences},
  volume={102},
  number={33},
  pages={11629--11634},
  year={2005},
  publisher={National Acad Sciences}
}

%HTK toolkit
@article{young2002htk,
  title={The HTK book},
  author={Young, Steve and Evermann, Gunnar and Gales, Mark and Hain, Thomas and Kershaw, Dan and Liu, Xunying and Moore, Gareth and Odell, Julian and Ollason, Dave and Povey, Dan and others},
  journal={Cambridge university engineering department},
  volume={3},
  number={175},
  pages={12},
  year={2002}
}

@inproceedings{vo2014stochastic,
  title={From stochastic grammar to bayes network: Probabilistic parsing of complex activity},
  author={Vo, Nam N and Bobick, Aaron F},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2641--2648},
  year={2014}
}

%GEP
@article{qi2020generalized,
  title={A generalized earley parser for human activity parsing and prediction},
  author={Qi, Siyuan and Jia, Baoxiong and Huang, Siyuan and Wei, Ping and Zhu, Song-Chun},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={43},
  number={8},
  pages={2538--2554},
  year={2020},
  publisher={IEEE}
}

%DATASETS
%GTEA
@inproceedings{fathi2011learning,
  title={Learning to recognize objects in egocentric activities},
  author={Fathi, Alireza and Ren, Xiaofeng and Rehg, James M},
  booktitle={CVPR 2011},
  pages={3281--3288},
  year={2011},
  organization={IEEE}
}


@InProceedings{Li_2019_ICCV,
author = {Li, Jun and Lei, Peng and Todorovic, Sinisa},
title = {Weakly Supervised Energy-Based Learning for Action Segmentation},
booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
month = {October},
year = {2019}
}
@article{belcak2022neural,
  title={A Neural Model for Regular Grammar Induction},
  author={Belc{\'a}k, Peter and Hofer, David and Wattenhofer, Roger},
  journal={arXiv preprint arXiv:2209.11628},
  year={2022}
}
%PCFG
@book{jelinek1992basic,
  title={Basic methods of probabilistic context free grammars},
  author={Jelinek, Frederick and Lafferty, John D and Mercer, Robert L},
  year={1992},
  publisher={Springer}
}

%Earley parser
@article{earley1970efficient,
  title={An efficient context-free parsing algorithm},
  author={Earley, Jay},
  journal={Communications of the ACM},
  volume={13},
  number={2},
  pages={94--102},
  year={1970},
  publisher={ACM New York, NY, USA}
}

%n-gram
@book{jurafsky2000speech,
  title={Speech \& language processing},
  author={Jurafsky, Dan},
  year={2000},
  publisher={Pearson Education India}
}

%finite grammars
@article{hopcroft2001introduction,
  title={Introduction to automata theory, languages, and computation},
  author={Hopcroft, John E and Motwani, Rajeev and Ullman, Jeffrey D},
  journal={Acm Sigact News},
  volume={32},
  number={1},
  pages={60--65},
  year={2001},
  publisher={ACM New York, NY, USA}
}

%--------------------------------------------------------
Diffusion models
%DDPM
@inproceedings{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  booktitle={Proceedings of the 34th International Conference on Neural Information Processing Systems},
  pages={6840--6851},
  year={2020}
}

%DDIM
@inproceedings{song2020denoising,
  title={Denoising Diffusion Implicit Models},
  author={Song, Jiaming and Meng, Chenlin and Ermon, Stefano},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

%diffusiondet
@inproceedings{chen2023diffusiondet,
  title={Diffusiondet: Diffusion model for object detection},
  author={Chen, Shoufa and Sun, Peize and Song, Yibing and Luo, Ping},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={19830--19843},
  year={2023}
}

%latent diffusion model
@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

%bit diffusion
@inproceedings{chen2022analog,
  title={Analog Bits: Generating Discrete Data using Diffusion Models with Self-Conditioning},
  author={Chen, Ting and ZHANG, Ruixiang and Hinton, Geoffrey},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

%video latent diffusion
@article{li2023videogen,
  title={Videogen: A reference-guided latent diffusion approach for high definition text-to-video generation},
  author={Li, Xin and Chu, Wenqing and Wu, Ye and Yuan, Weihang and Liu, Fanglong and Zhang, Qi and Li, Fu and Feng, Haocheng and Ding, Errui and Wang, Jingdong},
  journal={arXiv preprint arXiv:2309.00398},
  year={2023}
}

%semantic segmentation diffusion
@inproceedings{baranchuk2021label,
  title={Label-Efficient Semantic Segmentation with Diffusion Models},
  author={Baranchuk, Dmitry and Voynov, Andrey and Rubachev, Ivan and Khrulkov, Valentin and Babenko, Artem},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{song2019generative,
  title={Generative Modeling by Estimating Gradients of the Data Distribution},
  author={Song, Yang and Ermon, Stefano},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{song2020score,
  title={Score-Based Generative Modeling through Stochastic Differential Equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  booktitle={International Conference on Learning Representations},
  year={2020}
}
%diffusion mae
@article{wei2023diffusion,
  title={Diffusion Models as Masked Autoencoders},
  author={Wei, Chen and Mangalam, Karttikeya and Huang, Po-Yao and Li, Yanghao and Fan, Haoqi and Xu, Hu and Wang, Huiyu and Xie, Cihang and Yuille, Alan and Feichtenhofer, Christoph},
  journal={arXiv preprint arXiv:2304.03283},
  year={2023}
}

%FRIDO
@inproceedings{fan2023frido,
  title={Frido: Feature pyramid diffusion for complex scene image synthesis},
  author={Fan, Wan-Cyuan and Chen, Yen-Chun and Chen, DongDong and Cheng, Yu and Yuan, Lu and Wang, Yu-Chiang Frank},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  pages={579--587},
  year={2023}
}

@article{harvey2022flexible,
  title={Flexible diffusion modeling of long videos},
  author={Harvey, William and Naderiparizi, Saeid and Masrani, Vaden and Weilbach, Christian and Wood, Frank},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27953--27965},
  year={2022}
}

@article{yang2023diffusion,
  title={Diffusion probabilistic modeling for video generation},
  author={Yang, Ruihan and Srivastava, Prakhar and Mandt, Stephan},
  journal={Entropy},
  volume={25},
  number={10},
  pages={1469},
  year={2023},
  publisher={MDPI}
}

%--------------------------------------------------------
%MeMViT
@inproceedings{wu2022memvit,
  title={Memvit: Memory-augmented multiscale vision transformer for efficient long-term video recognition},
  author={Wu, Chao-Yuan and Li, Yanghao and Mangalam, Karttikeya and Fan, Haoqi and Xiong, Bo and Malik, Jitendra and Feichtenhofer, Christoph},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13587--13597},
  year={2022}
}

@inproceedings{wu2019long,
  title={Long-term feature banks for detailed video understanding},
  author={Wu, Chao-Yuan and Feichtenhofer, Christoph and Fan, Haoqi and He, Kaiming and Krahenbuhl, Philipp and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={284--293},
  year={2019}
}

@inproceedings{donahue2015long,
  title={Long-term recurrent convolutional networks for visual recognition and description},
  author={Donahue, Jeffrey and Anne Hendricks, Lisa and Guadarrama, Sergio and Rohrbach, Marcus and Venugopalan, Subhashini and Saenko, Kate and Darrell, Trevor},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2625--2634},
  year={2015}
}

%EGO-TOPO
@inproceedings{nagarajan2020ego,
  title={Ego-topo: Environment affordances from egocentric video},
  author={Nagarajan, Tushar and Li, Yanghao and Feichtenhofer, Christoph and Grauman, Kristen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={163--172},
  year={2020}
}

%EGO 4D
@inproceedings{grauman2022ego4d,
  title={Ego4d: Around the world in 3,000 hours of egocentric video},
  author={Grauman, Kristen and Westbury, Andrew and Byrne, Eugene and Chavis, Zachary and Furnari, Antonino and Girdhar, Rohit and Hamburger, Jackson and Jiang, Hao and Liu, Miao and Liu, Xingyu and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={18995--19012},
  year={2022}
}

---------------------------------------------------------------
%Curriculum learning
@inproceedings{bengio2009curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={41--48},
  year={2009}
}

%dynamic context removal for action anticipation
@inproceedings{xu2022learning,
  title={Learning to anticipate future with dynamic context removal},
  author={Xu, Xinyu and Li, Yong-Lu and Lu, Cewu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12734--12744},
  year={2022}
}
---------------------------------------------------------------
%Temporal dynamics
@inproceedings{pan2021videomoco,
  title={Videomoco: Contrastive video representation learning with temporally adversarial examples},
  author={Pan, Tian and Song, Yibing and Yang, Tianyu and Jiang, Wenhao and Liu, Wei},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11205--11214},
  year={2021}
}
---------------------------------------------------------------
%MAE
@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16000--16009},
  year={2022}
}

%VideoMAE
@article{feichtenhofer2022masked,
  title={Masked autoencoders as spatiotemporal learners},
  author={Feichtenhofer, Christoph and Li, Yanghao and He, Kaiming and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={35946--35958},
  year={2022}
}
%BEIT
@article{bao2021beit,
  title={Beit: Bert pre-training of image transformers},
  author={Bao, Hangbo and Dong, Li and Piao, Songhao and Wei, Furu},
  journal={arXiv preprint arXiv:2106.08254},
  year={2021}
}

%T5
@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

%relative position bias
@article{shaw2018self,
  title={Self-attention with relative position representations},
  author={Shaw, Peter and Uszkoreit, Jakob and Vaswani, Ashish},
  journal={arXiv preprint arXiv:1803.02155},
  year={2018}
}

%JOADAA
@inproceedings{guermal2024joadaa,
  title={JOADAA: joint online action detection and action anticipation},
  author={Guermal, Mohammed and Ali, Abid and Dai, Rui and Br{\'e}mond, Fran{\c{c}}ois},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={6889--6898},
  year={2024}
}

%TESTRA
@inproceedings{zhao2022real,
  title={Real-time online video detection with temporal smoothing transformers},
  author={Zhao, Yue and Kr{\"a}henb{\"u}hl, Philipp},
  booktitle={European Conference on Computer Vision},
  pages={485--502},
  year={2022},
  organization={Springer}
}

%MAT
@inproceedings{wang2023memory,
  title={Memory-and-Anticipation Transformer for Online Action Understanding},
  author={Wang, Jiahao and Chen, Guo and Huang, Yifei and Wang, Limin and Lu, Tong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={13824--13835},
  year={2023}
}

%RULSTM
@article{furnari2020rolling,
  title={Rolling-unrolling lstms for action anticipation from first-person video},
  author={Furnari, Antonino and Farinella, Giovanni Maria},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={43},
  number={11},
  pages={4021--4036},
  year={2020},
  publisher={IEEE}
}

%OADTR
@inproceedings{wang2021oadtr,
  title={Oadtr: Online action detection with transformers},
  author={Wang, Xiang and Zhang, Shiwei and Qing, Zhiwu and Shao, Yuanjie and Zuo, Zhengrong and Gao, Changxin and Sang, Nong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7565--7575},
  year={2021}
}

%LSTR
@article{xu2021long,
  title={Long short-term transformer for online action detection},
  author={Xu, Mingze and Xiong, Yuanjun and Chen, Hao and Li, Xinyu and Xia, Wei and Tu, Zhuowen and Soatto, Stefano},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={1086--1099},
  year={2021}
}

%Activity Grammars
@article{gong2024activity,
  title={Activity Grammars for Temporal Action Segmentation},
  author={Gong, Dayoung and Lee, Joonseok and Jung, Deunsol and Kwak, Suha and Cho, Minsu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{tong2022videomae,
  title={Videomae: Masked autoencoders are data-efficient learners for self-supervised video pre-training},
  author={Tong, Zhan and Song, Yibing and Wang, Jue and Wang, Limin},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={10078--10093},
  year={2022}
}

%pytorch
@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

%TAS survey
@article{ding2023temporal,
  title={Temporal action segmentation: An analysis of modern techniques},
  author={Ding, Guodong and Sener, Fadime and Yao, Angela},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023},
  publisher={IEEE}
}