\begin{thebibliography}{35}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Antos et~al.(2008)Antos, Szepesv{\'a}ri, and Munos]{Antos2008}
Antos, A., Szepesv{\'a}ri, C., and Munos, R.
\newblock Learning near-optimal policies with {B}ellman-residual minimization
  based fitted policy iteration and a single sample path.
\newblock \emph{Machine Learning}, 71\penalty0 (1):\penalty0 89--129, Apr 2008.

\bibitem[Antsaklis \& Michel(2007)Antsaklis and Michel]{antsaklis2007linear}
Antsaklis, P.~J. and Michel, A.~N.
\newblock A linear systems primer.
\newblock 2007.

\bibitem[Baird(1995)]{baird1995residual}
Baird, L.
\newblock Residual algorithms: reinforcement learning with function
  approximation.
\newblock In \emph{Machine Learning Proceedings}, pp.\  30--37. 1995.

\bibitem[Bertsekas(1995)]{bertsekas1995dynamic}
Bertsekas, D.~P.
\newblock \emph{Dynamic programming and optimal control}.
\newblock Athena Scientific Belmont, MA, 1995.

\bibitem[Bertsekas \& Tsitsiklis(1996)Bertsekas and
  Tsitsiklis]{bertsekas1996neuro}
Bertsekas, D.~P. and Tsitsiklis, J.~N.
\newblock \emph{Neuro-dynamic programming}.
\newblock Athena Scientific Belmont, MA, 1996.

\bibitem[Bertsekas \& Yu(2009)Bertsekas and Yu]{bertsekas2009projected}
Bertsekas, D.~P. and Yu, H.
\newblock Projected equation methods for approximate solution of large linear
  systems.
\newblock \emph{Journal of Computational and Applied Mathematics}, 227\penalty0
  (1):\penalty0 27--50, 2009.

\bibitem[Bhandari et~al.(2018)Bhandari, Russo, and Singal]{bhandari2018finite}
Bhandari, J., Russo, D., and Singal, R.
\newblock A finite time analysis of temporal difference learning with linear
  function approximation.
\newblock \emph{arXiv preprint arXiv:1806.02450}, 2018.

\bibitem[Bhatnagar et~al.(2012)Bhatnagar, Prasad, and
  Prashanth]{bhatnagar2012stochastic}
Bhatnagar, S., Prasad, H.~L., and Prashanth, L.~A.
\newblock \emph{Stochastic recursive algorithms for optimization: simultaneous
  perturbation methods}, volume 434.
\newblock Springer, 2012.

\bibitem[Bottou et~al.(2018)Bottou, Curtis, and
  Nocedal]{bottou2018optimization}
Bottou, L., Curtis, F.~E., and Nocedal, J.
\newblock Optimization methods for large-scale machine learning.
\newblock \emph{Siam Review}, 60\penalty0 (2):\penalty0 223--311, 2018.

\bibitem[Boyd \& Vandenberghe(2004)Boyd and Vandenberghe]{boyd2004}
Boyd, S. and Vandenberghe, L.
\newblock \emph{Convex optimization}.
\newblock Cambridge University Press, 2004.

\bibitem[Bradtke \& Barto(1996)Bradtke and Barto]{Bradtke1996}
Bradtke, S.~J. and Barto, A.~G.
\newblock Linear least-squares algorithms for temporal difference learning.
\newblock \emph{Machine Learning}, 22\penalty0 (1):\penalty0 33--57, Mar 1996.

\bibitem[Bubeck et~al.(2015)]{bubeck2015convex}
Bubeck, S. et~al.
\newblock Convex optimization: Algorithms and complexity.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  8\penalty0 (3-4):\penalty0 231--357, 2015.

\bibitem[Chen(1995)]{chen1995linear}
Chen, C.-T.
\newblock \emph{Linear System Theory and Design}.
\newblock Oxford University Press, Inc., 1995.

\bibitem[Dai et~al.(2017)Dai, He, Pan, Boots, and Song]{dai2017learning}
Dai, B., He, N., Pan, Y., Boots, B., and Song, L.
\newblock Learning from conditional distributions via dual embeddings.
\newblock In \emph{Artificial Intelligence and Statistics}, pp.\  1458--1467,
  2017.

\bibitem[Dai et~al.(2018)Dai, Shaw, Li, Xiao, He, Liu, Chen, and
  Song]{dai18sbeed}
Dai, B., Shaw, A., Li, L., Xiao, L., He, N., Liu, Z., Chen, J., and Song, L.
\newblock {SBEED}: Convergent reinforcement learning with nonlinear function
  approximation.
\newblock In Dy, J. and Krause, A. (eds.), \emph{Proceedings of the 35th
  International Conference on Machine Learning}, volume~80 of \emph{Proceedings
  of Machine Learning Research}, pp.\  1125--1134. PMLR, 10--15 Jul 2018.

\bibitem[Dalal et~al.(2018)Dalal, Sz{\"o}r{\'e}nyi, Thoppe, and
  Mannor]{dalal2018finite}
Dalal, G., Sz{\"o}r{\'e}nyi, B., Thoppe, G., and Mannor, S.
\newblock Finite sample analyses for {TD(0)} with function approximation.
\newblock In \emph{Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem[Dann et~al.(2014)Dann, Neumann, and Peters]{dann2014policy}
Dann, C., Neumann, G., and Peters, J.
\newblock Policy evaluation with temporal differences: A survey and comparison.
\newblock \emph{Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 809--883, 2014.

\bibitem[Geramifard et~al.(2013)Geramifard, Walsh, Tellex, Chowdhary, Roy, How,
  et~al.]{geramifard2013tutorial}
Geramifard, A., Walsh, T.~J., Tellex, S., Chowdhary, G., Roy, N., How, J.~P.,
  et~al.
\newblock A tutorial on linear function approximators for dynamic programming
  and reinforcement learning.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  6\penalty0 (4):\penalty0 375--451, 2013.

\bibitem[Gu et~al.(2016)Gu, Lillicrap, Sutskever, and Levine]{gu2016continuous}
Gu, S., Lillicrap, T., Sutskever, I., and Levine, S.
\newblock Continuous deep q-learning with model-based acceleration.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2829--2838, 2016.

\bibitem[Hasselt(2010)]{hasselt2010double}
Hasselt, H.~V.
\newblock Double {Q}-learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2613--2621, 2010.

\bibitem[Heess et~al.(2015)Heess, Hunt, Lillicrap, and Silver]{heess2015memory}
Heess, N., Hunt, J.~J., Lillicrap, T.~P., and Silver, D.
\newblock Memory-based control with recurrent neural networks.
\newblock \emph{arXiv preprint arXiv:1512.04455}, 2015.

\bibitem[Lillicrap et~al.(2015)Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa,
  Silver, and Wierstra]{lillicrap2015continuous}
Lillicrap, T.~P., Hunt, J.~J., Pritzel, A., Heess, N., Erez, T., Tassa, Y.,
  Silver, D., and Wierstra, D.
\newblock Continuous control with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1509.02971}, 2015.

\bibitem[Mahadevan et~al.(2014)Mahadevan, Liu, Thomas, Dabney, Giguere, Jacek,
  Gemp, and Liu]{mahadevan2014proximal}
Mahadevan, S., Liu, B., Thomas, P., Dabney, W., Giguere, S., Jacek, N., Gemp,
  I., and Liu, J.
\newblock Proximal reinforcement learning: {A} new theory of sequential
  decision making in primal-dual spaces.
\newblock \emph{arXiv preprint arXiv:1405.6757}, 2014.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{mnih2015human}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M., Fidjeland, A.~K., Ostrovski, G., et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529, 2015.

\bibitem[Mnih et~al.(2016)Mnih, Badia, Mirza, Graves, Lillicrap, Harley,
  Silver, and Kavukcuoglu]{mnih2016asynchronous}
Mnih, V., Badia, A.~P., Mirza, M., Graves, A., Lillicrap, T., Harley, T.,
  Silver, D., and Kavukcuoglu, K.
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In \emph{International conference on machine learning}, pp.\
  1928--1937, 2016.

\bibitem[Prashanth et~al.(2014)Prashanth, Korda, and Munos]{prashanth14}
Prashanth, L.~A., Korda, N., and Munos, R.
\newblock Fast lstd using stochastic approximation: Finite time analysis and
  application to traffic control.
\newblock In Calders, T., Esposito, F., H{\"u}llermeier, E., and Meo, R.
  (eds.), \emph{Machine Learning and Knowledge Discovery in Databases}, pp.\
  66--81. Springer Berlin Heidelberg, 2014.

\bibitem[Srikant \& Ying.(2019)Srikant and Ying.]{srikant2019}
Srikant, R. and Ying., L.
\newblock Finite-time error bounds for linear stochastic approximation and {TD}
  learning.
\newblock \emph{arXiv preprint arXiv:1902.00923}, 2019.

\bibitem[Sutton(1988)]{sutton1988learning}
Sutton, R.~S.
\newblock Learning to predict by the methods of temporal differences.
\newblock \emph{Machine learning}, 3\penalty0 (1):\penalty0 9--44, 1988.

\bibitem[Sutton et~al.(2009{\natexlab{a}})Sutton, Maei, Precup, Bhatnagar,
  Silver, Szepesv{\'a}ri, and Wiewiora]{sutton2009fast}
Sutton, R.~S., Maei, H.~R., Precup, D., Bhatnagar, S., Silver, D.,
  Szepesv{\'a}ri, C., and Wiewiora, E.
\newblock Fast gradient-descent methods for temporal-difference learning with
  linear function approximation.
\newblock In \emph{Proceedings of the 26th Annual International Conference on
  Machine Learning}, pp.\  993--1000, 2009{\natexlab{a}}.

\bibitem[Sutton et~al.(2009{\natexlab{b}})Sutton, Maei, and
  Szepesv{\'a}ri]{sutton2009convergent}
Sutton, R.~S., Maei, H.~R., and Szepesv{\'a}ri, C.
\newblock A convergent {$O(n)$} temporal-difference algorithm for off-policy
  learning with linear function approximation.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1609--1616, 2009{\natexlab{b}}.

\bibitem[Tsitsiklis \& Van~Roy(1997)Tsitsiklis and
  Van~Roy]{tsitsiklis1997analysis}
Tsitsiklis, J.~N. and Van~Roy, B.
\newblock An analysis of temporal-difference learning with function
  approximation.
\newblock \emph{IEEE Transactions on Automatic Control}, 42\penalty0
  (5):\penalty0 674--690, 1997.

\bibitem[Van~Hasselt et~al.(2016)Van~Hasselt, Guez, and Silver]{van2016deep}
Van~Hasselt, H., Guez, A., and Silver, D.
\newblock Deep reinforcement learning with double {Q}-learning.
\newblock In \emph{AAAI}, volume~2, pp.\ ~5. Phoenix, AZ, 2016.

\bibitem[Wang et~al.(2016)Wang, Schaul, Hessel, Hasselt, Lanctot, and
  Freitas]{wang2016dueling}
Wang, Z., Schaul, T., Hessel, M., Hasselt, H., Lanctot, M., and Freitas, N.
\newblock Dueling network architectures for deep reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1995--2003, 2016.

\bibitem[Watkins \& Dayan(1992)Watkins and Dayan]{watkins1992q}
Watkins, C. J. C.~H. and Dayan, P.
\newblock Q-learning.
\newblock \emph{Machine learning}, 8\penalty0 (3-4):\penalty0 279--292, 1992.

\bibitem[Yu \& Bertsekas(2009)Yu and Bertsekas]{yu2009convergence}
Yu, H. and Bertsekas, D.~P.
\newblock Convergence results for some temporal difference methods based on
  least squares.
\newblock \emph{IEEE Transactions on Automatic Control}, 54\penalty0
  (7):\penalty0 1515--1531, 2009.

\end{thebibliography}
