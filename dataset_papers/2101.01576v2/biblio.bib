@article{frost2020exkmc,
  title={ExKMC: Expanding Explainable $ k $-Means Clustering},
  author={Frost, Nave and Moshkovitz, Michal and Rashtchian, Cyrus},
  journal={arXiv preprint arXiv:2006.02399},
  year={2020}
}

@inproceedings{dasguptaexplainable-workshop,
  title={Explainable k-Means Clustering: Theory and Practice},
  author={Dasgupta, Sanjoy and Frost, Nave and Moshkovitz, Michal and Rashtchian, Cyrus},
  booktitle={XXAI: Extending Explainable AI Beyond Deep Models and Classifiers},
  maintitle={International Conference on Machine Learning},
  year={2020}
}

@article{murdoch2019interpretable,
  title={Interpretable machine learning: definitions, methods, and applications},
  author={Murdoch, W James and Singh, Chandan and Kumbier, Karl and Abbasi-Asl, Reza and Yu, Bin},
  journal={arXiv preprint arXiv:1901.04592},
  year={2019}
}

@book{molnar2020interpretable,
  title={Interpretable Machine Learning},
  author={Molnar, Christoph},
  year={2020},
  publisher={Lulu.com}
}

@inproceedings{ribeiro2016should,
  title={" Why should I trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}

@inproceedings{lundberg2017unified,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  booktitle={Advances in neural information processing systems},
  pages={4765--4774},
  year={2017}
}

@article{rudin2019stop,
  title={Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
  author={Rudin, Cynthia},
  journal={Nature Machine Intelligence},
  volume={1},
  number={5},
  pages={206--215},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{lloyd1982least,
  title={Least squares quantization in PCM},
  author={Lloyd, Stuart},
  journal={IEEE transactions on information theory},
  volume={28},
  number={2},
  pages={129--137},
  year={1982},
  publisher={IEEE}
}

@inproceedings{chen2016interpretable,
  title={Interpretable clustering via discriminative rectangle mixture model},
  author={Chen, Junxiang and Chang, Yale and Hobbs, Brian and Castaldi, Peter and Cho, Michael and Silverman, Edwin and Dy, Jennifer},
  booktitle={2016 IEEE 16th International Conference on Data Mining (ICDM)},
  pages={823--828},
  year={2016},
  organization={IEEE}
}

@inproceedings{pelleg2001mixtures,
  title={Mixtures of rectangles: Interpretable soft clustering},
  author={Pelleg, Dan and Moore, Andrew},
  booktitle={ICML},
  pages={401--408},
  year={2001}
}

@article{kauffmann2019clustering,
  title={From clustering to cluster explanations via neural networks},
  author={Kauffmann, Jacob and Esders, Malte and Montavon, Gr{\'e}goire and Samek, Wojciech and M{\"u}ller, Klaus-Robert},
  journal={arXiv preprint arXiv:1906.07633},
  year={2019}
}

% GENERAL WORKS ON EXPLAINABILITY

@ARTICLE{adadi2018peeking,  
    author={A. {Adadi} and M. {Berrada}},  
    journal={IEEE Access},   
    title={Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI)},   
    year={2018},  
    volume={6},  
    number={},  
    pages={52138-52160},  
    doi={10.1109/ACCESS.2018.2870052}}

% INTERPRETABLE CLUSTERING USING TREES

@article{chavent1998monothetic,
  title={A monothetic clustering method},
  author={Chavent, Marie},
  journal={Pattern Recognition Letters},
  volume={19},
  number={11},
  pages={989--996},
  year={1998},
  publisher={Elsevier}
}


@inproceedings{liu2000clustering,
  title={Clustering through decision tree construction},
  author={Liu, Bing and Xia, Yiyuan and Yu, Philip S},
  booktitle={Proceedings of the ninth international conference on Information and knowledge management},
  pages={20--29},
  year={2000}
}

@article{fraiman2013interpretable,
  title={Interpretable clustering using unsupervised binary trees},
  author={Fraiman, Ricardo and Ghattas, Badih and Svarc, Marcela},
  journal={Advances in Data Analysis and Classification},
  volume={7},
  number={2},
  pages={125--145},
  year={2013},
  publisher={Springer}
}

@misc{bertsimas2018interpretable,
      title={Interpretable Clustering via Optimal Trees}, 
      author={Dimitris Bertsimas and Agni Orfanoudaki and Holly Wiberg},
      year={2018},
      eprint={1812.00539},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{fisher1987knowledge,
  title={Knowledge acquisition via incremental conceptual clustering},
  author={Fisher, Douglas H},
  journal={Machine learning},
  volume={2},
  number={2},
  pages={139--172},
  year={1987},
  publisher={Springer}
}


@ARTICLE{basak2005interpretable,
  author={J. {Basak} and R. {Krishnapuram}},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Interpretable hierarchical clustering by constructing an unsupervised decision tree}, 
  year={2005},
  volume={17},
  number={1},
  pages={121-132},
  doi={10.1109/TKDE.2005.11}}
  
@ARTICLE{loyola2020explainable,  
    author={O. {Loyola-González} and A. E. {Gutierrez-Rodríguez} and M. A. {Medina-Pérez} and R. {Monroy} and J. F. {Martínez-Trinidad} and J. A. {Carrasco-Ochoa} and M. {García-Borroto}},  
    journal={IEEE Access},   
    title={An Explainable Artificial Intelligence Model for Clustering Numerical Databases},   
    year={2020},  
    volume={8},
    number={},  
    pages={52370-52384},  
    doi={10.1109/ACCESS.2020.2980581}}

% OTHER METHODS FOR INTERPRETABLE CLUSTERING

@inproceedings{saisubramanian2020balancing,
  title={Balancing the Tradeoff Between Clustering Value and Interpretability},
  author={Saisubramanian, Sandhya and Galhotra, Sainyam and Zilberstein, Shlomo},
  booktitle={Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
  pages={351--357},
  year={2020}
}


@INPROCEEDINGS{heckel2017scalable,
  author={R. {Heckel} and M. {Vlachos} and T. {Parnell} and C. {Duenner}},
  booktitle={2017 IEEE 33rd International Conference on Data Engineering (ICDE)}, 
  title={Scalable and Interpretable Product Recommendations via Overlapping Co-Clustering}, 
  year={2017},
  volume={},
  number={},
  pages={1033-1044},
  doi={10.1109/ICDE.2017.149}}

@inproceedings{gad2020excut,
  title={ExCut: Explainable Embedding-Based Clustering over Knowledge Graphs},
  author={Gad-Elrab, Mohamed H and Stepanova, Daria and Tran, Trung-Kien and Adel, Heike and Weikum, Gerhard},
  booktitle={International Semantic Web Conference},
  pages={218--237},
  year={2020},
  organization={Springer}
}

@inproceedings{inconco,
author = {Plant, Claudia and B\"{o}hm, Christian},
title = {INCONCO: Interpretable Clustering of Numerical and Categorical Objects},
year = {2011},
isbn = {9781450308137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2020408.2020584},
doi = {10.1145/2020408.2020584},
abstract = {The integrative mining of heterogeneous data and the interpretability of the data mining result are two of the most important challenges of today's data mining. It is commonly agreed in the community that, particularly in the research area of clustering, both challenges have not yet received the due attention. Only few approaches for clustering of objects with mixed-type attributes exist and those few approaches do not consider cluster-specific dependencies between numerical and categorical attributes. Likewise, only a few clustering papers address the problem of interpretability: to explain why a certain set of objects have been grouped into a cluster and what a particular cluster distinguishes from another. In this paper, we approach both challenges by constructing a relationship to the concept of data compression using the Minimum Description Length principle: a detected cluster structure is the better the more efficient it can be exploited for data compression. Following this idea, we can learn, during the run of a clustering algorithm, the optimal trade-off for attribute weights and distinguish relevant attribute dependencies from coincidental ones. We extend the efficient Cholesky decomposition to model dependencies in heterogeneous data and to ensure interpretability. Our proposed algorithm, INCONCO, successfully finds clusters in mixed type data sets, identifies the relevant attribute dependencies, and explains them using linear models and case-by-case analysis. Thereby, it outperforms existing approaches in effectiveness, as our extensive experimental evaluation demonstrates.},
booktitle = {Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1127–1135},
numpages = {9},
keywords = {minimum description length principle, clustering, mixed-type data},
location = {San Diego, California, USA},
series = {KDD '11}
}

% APPLICATIONS

@misc{horel2020explainable,
      title={Explainable Clustering and Application to Wealth Management Compliance}, 
      author={Enguerrand Horel and Kay Giesecke and Victor Storchan and Naren Chittar},
      year={2020},
      eprint={1909.13381},
      archivePrefix={arXiv},
      primaryClass={stat.AP}
}

@article{zhang2020explainable,
  title={Explainable Recommendation: A Survey and New Perspectives},
  author={Zhang, Yongfeng and Chen, Xu and others},
  journal={Foundations and Trends{\textregistered} in Information Retrieval},
  volume={14},
  number={1},
  pages={1--101},
  year={2020},
  publisher={Now Publishers, Inc.}
}

% GENERAL WORK

@phdthesis{chen2018interpretable,
  title={Interpretable Clustering Methods},
  author={Chen, Junxiang},
  year={2018},
  school={Northeastern University}
}

% NOT USED

@article{sardianos2020emergence,
  title={The emergence of explainability of intelligent systems: Delivering explainable and personalized recommendations for energy efficiency},
  author={Sardianos, Christos and Varlamis, Iraklis and Chronis, Christos and Dimitrakopoulos, George and Alsalemi, Abdullah and Himeur, Yassine and Bensaali, Faycal and Amira, Abbes},
  journal={International Journal of Intelligent Systems},
  year={2020},
  publisher={Wiley Online Library}
}

@article{frye2020asymmetric,
  title={Asymmetric Shapley values: incorporating causal knowledge into model-agnostic explainability},
  author={Frye, Christopher and Rowat, Colin and Feige, Ilya},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

% WORKS THAT CITE DASGUPTA

@inproceedings{fezer2020xplainableclusterexplorer,
  title={XplainableClusterExplorer: a novel approach for interactive feature selection for clustering},
  author={Fezer, Eric and Raab, Dominik and Theissler, Andreas},
  booktitle={Proceedings of the 13th International Symposium on Visual Information Communication and Interaction},
  pages={1--5},
  year={2020}
}

@article{marcinkevivcs2020interpretability,
  title={Interpretability and Explainability: A Machine Learning Zoo Mini-tour},
  author={Marcinkevi{\v{c}}s, Ri{\v{c}}ards and Vogt, Julia E},
  journal={arXiv preprint arXiv:2012.01805},
  year={2020}
}

@article{thrun2020explainable,
  title={Explainable AI Framework for Multivariate Hydrochemical Time Series},
  author={Thrun, Michael and Ultsch, Alfred and Breuer, Lutz},
  year={2020},
  publisher={Preprints}
}

@article{baralisexplainable,
  title={Explainable AI for Clustering Algorithms},
  author={Baralis, Elena and Pastor, Doctor Eliana and Cannone, Marcello}
}

@article{chavent1999methodes,
  title={M{\'e}thodes divisives de classification et segmentation non supervis{\'e}e: Recherche d'une typologie de la peau humaine saine},
  author={Chavent, Marie and Guinot, Christiane and Lechevallier, Yves and Tenenhaus, Michel},
  journal={Revue de statistique appliqu{\'e}e},
  volume={47},
  number={4},
  pages={87--99},
  year={1999}
}

@article{blockeel2000top,
  title={Top-down induction of clustering trees},
  author={Blockeel, Hendrik and De Raedt, Luc and Ramon, Jan},
  journal={arXiv preprint cs/0011032},
  year={2000}
}

@article{bertsimas2020interpretable,
  title={Interpretable clustering: an optimization approach},
  author={Bertsimas, Dimitris and Orfanoudaki, Agni and Wiberg, Holly},
  journal={Machine Learning},
  pages={1--50},
  year={2020},
  publisher={Springer}
}

@article{bertsimas2017optimal,
  title={Optimal classification trees},
  author={Bertsimas, Dimitris and Dunn, Jack},
  journal={Machine Learning},
  volume={106},
  number={7},
  pages={1039--1082},
  year={2017},
  publisher={Springer}
}

@book{breiman1984classification,
  title={Classification and regression trees},
  author={Breiman, Leo and Friedman, Jerome and Stone, Charles J and Olshen, Richard A},
  year={1984},
  publisher={CRC press}
}

@article{quinlan1986induction,
  title={Induction of decision trees},
  author={Quinlan, J. Ross},
  journal={Machine learning},
  volume={1},
  number={1},
  pages={81--106},
  year={1986},
  publisher={Springer}
}

@book{quinlan1993c4,
  title={C4.5: programs for machine learning},
  author={Quinlan, J Ross},
  year={1993},
  publisher={Morgan Kaufmann}
}

@misc{horel2019computationally,
      title={Computationally Efficient Feature Significance and Importance for Machine Learning Models}, 
      author={Enguerrand Horel and Kay Giesecke},
      year={2019},
      eprint={1905.09849},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@InProceedings{DBLP:conf/icml/VidalS20,
  title = 	 {Born-Again Tree Ensembles},
  author =       {Vidal, Thibaut and Schiffer, Maximilian},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {9743--9753},
  year = 	 {2020},
  editor = 	 {Hal Daumé III and Aarti Singh},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Virtual},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/vidal20a/vidal20a.pdf},,
  url = 	 {http://proceedings.mlr.press/v119/vidal20a.html},
  abstract = 	 {The use of machine learning algorithms in finance, medicine, and criminal justice can deeply impact human lives. As a consequence, research into interpretable machine learning has rapidly grown in an attempt to better control and fix possible sources of mistakes and biases. Tree ensembles, in particular, offer a good prediction quality in various domains, but the concurrent use of multiple trees reduces the interpretability of the ensemble. Against this background, we study born-again tree ensembles, i.e., the process of constructing a single decision tree of minimum size that reproduces the exact same behavior as a given tree ensemble in its entire feature space. To find such a tree, we develop a dynamic-programming based algorithm that exploits sophisticated pruning and bounding rules to reduce the number of recursive calls. This algorithm generates optimal born-again trees for many datasets of practical interest, leading to classifiers which are typically simpler and more interpretable without any other form of compromise.}
}

@article{DBLP:journals/jcss/CharikarFGKRS02,
  title={Query strategies for priced information},
  author={Charikar, Moses and Fagin, Ronald and Guruswami, Venkatesan and Kleinberg, Jon and Raghavan, Prabhakar and Sahai, Amit},
  journal={Journal of Computer and System Sciences},
  volume={64},
  number={4},
  pages={785--819},
  year={2002},
  publisher={Elsevier}
}

@article{DBLP:journals/siamcomp/LaberMP02,
  title={On binary searching with nonuniform costs},
  author={Laber, Eduardo S and Milidi{\'u}, Ruy L and Pessoa, Artur A},
  journal={SIAM Journal on Computing},
  volume={31},
  number={4},
  pages={1022--1047},
  year={2002},
  publisher={SIAM}
}

@article{DBLP:journals/siamcomp/MegiddoS84,
  title={On the complexity of some common geometric location problems},
  author={Megiddo, Nimrod and Supowit, Kenneth J},
  journal={SIAM journal on computing},
  volume={13},
  number={1},
  pages={182--196},
  year={1984},
  publisher={SIAM}
}

@article{DBLP:journals/ml/AloiseDHP09,
  title={NP-hardness of Euclidean sum-of-squares clustering},
  author={Aloise, Daniel and Deshpande, Amit and Hansen, Pierre and Popat, Preyas},
  journal={Machine learning},
  volume={75},
  number={2},
  pages={245--248},
  year={2009},
  publisher={Springer}
}

@article{DBLP:journals/comgeo/KanungoMNPSW04,
  title={A local search approximation algorithm for k-means clustering},
  author={Kanungo, Tapas and Mount, David M and Netanyahu, Nathan S and Piatko, Christine D and Silverman, Ruth and Wu, Angela Y},
  journal={Computational Geometry},
  volume={28},
  number={2-3},
  pages={89--112},
  year={2004},
  publisher={Elsevier}
}

@book{DBLP:books/daglib/0030297,
  author    = {David P. Williamson and
               David B. Shmoys},
  title     = {The Design of Approximation Algorithms},
  publisher = {Cambridge University Press},
  year      = {2011},
  url       = {http://www.cambridge.org/de/knowledge/isbn/item5759340/?site\_locale=de\_DE},
  isbn      = {978-0-521-19527-0},
  timestamp = {Wed, 09 Jan 2013 17:14:15 +0100},
  biburl    = {https://dblp.org/rec/books/daglib/0030297.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

 @InProceedings{dasgupta2020explainable, title = {Explainable k-Means and k-Medians Clustering}, author = {Moshkovitz, Michal and Dasgupta, Sanjoy and Rashtchian, Cyrus and Frost, Nave}, booktitle = {Proceedings of the 37th International Conference on Machine Learning}, pages = {7055--7065}, year = {2020}, editor = {Hal Daumé III and Aarti Singh}, volume = {119}, series = {Proceedings of Machine Learning Research}, month = {13--18 Jul}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v119/moshkovitz20a/moshkovitz20a.pdf}, url = { http://proceedings.mlr.press/v119/moshkovitz20a.html }, abstract = {Many clustering algorithms lead to cluster assignments that are hard to explain, partially because they depend on all the features of the data in a complicated way. To improve interpretability, we consider using a small decision tree to partition a data set into clusters, so that clusters can be characterized in a straightforward manner. We study this problem from a theoretical viewpoint, measuring cluster quality by the k-means and k-medians objectives. In terms of negative results, we show that popular top-down decision tree algorithms may lead to clusterings with arbitrarily large cost, and any clustering based on a tree with k leaves must incur an Omega(log k) approximation factor compared to the optimal clustering. On the positive side, for two means/medians, we show that a single threshold cut can achieve a constant factor approximation, and we give nearly-matching lower bounds; for general k > 2, we design an efficient algorithm that leads to an O(k) approximation to the optimal k-medians and an O(k^2) approximation to the optimal k-means. Prior to our work, no algorithms were known with provable guarantees independent of dimension and input size.} } 