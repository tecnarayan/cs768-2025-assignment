\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{retargeting2019siggraph}
K.~Aberman, R.~Wu, D.~Lischinski, B.~Chen, and D.~Cohen-Or.
\newblock Learning character-agnostic motion for motion retargeting in {2D}.
\newblock {\em ACM Transactions on Graphics}, 2019.

\bibitem{arandjelovic2017look}
R.~Arandjelovic and A.~Zisserman.
\newblock Look, listen and learn.
\newblock In {\em IEEE International Conference on Computer Vision}, 2017.

\bibitem{arandjelovic2017objects}
R.~Arandjelovi{\'c} and A.~Zisserman.
\newblock Objects that sound.
\newblock In {\em European Conference on Computer Vision}, 2018.

\bibitem{aytar2016soundnet}
Y.~Aytar, C.~Vondrick, and A.~Torralba.
\newblock {SoundNet}: Learning sound representations from unlabeled video.
\newblock In {\em Neural Information Processing Systems}, 2016.

\bibitem{cao2017realtime}
Z.~Cao, T.~Simon, S.-E. Wei, and Y.~Sheikh.
\newblock Realtime multi-person 2{D} pose estimation using part affinity
  fields.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition},
  2017.

\bibitem{chao2017forecasting}
Y.-W. Chao, J.~Yang, B.~L. Price, S.~Cohen, and J.~Deng.
\newblock Forecasting human dynamics from static images.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition},
  2017.

\bibitem{davis2018visual}
A.~Davis and M.~Agrawala.
\newblock Visual rhythm and beat.
\newblock {\em ACM Transactions on Graphics}, 2018.

\bibitem{Davis2014VisualMic}
A.~Davis, M.~Rubinstein, N.~Wadhwa, G.~Mysore, F.~Durand, and W.~Freeman.
\newblock The visual microphone: Passive recovery of sound from video.
\newblock {\em ACM Transactions on Graphics}, 2014.

\bibitem{denton2017unsupervised}
E.~Denton and V.~Birodkar.
\newblock Unsupervised learning of disentangled representations from video.
\newblock In {\em Neural Information Processing Systems}, 2017.

\bibitem{doersch2015unsupervised}
C.~Doersch, A.~Gupta, and A.~A. Efros.
\newblock Unsupervised visual representation learning by context prediction.
\newblock In {\em IEEE International Conference on Computer Vision}, 2015.

\bibitem{ellis2007beat}
D.~Ellis.
\newblock Beat tracking by dynamic programming.
\newblock {\em Journal of New Music Research}, 2007.

\bibitem{ephrat2018looking}
A.~Ephrat, I.~Mosseri, O.~Lang, T.~Dekel, K.~Wilson, A.~Hassidim, W.~Freeman,
  and M.~Rubinstein.
\newblock Looking to listen at the cocktail party: A speaker-independent
  audio-visual model for speech separation.
\newblock {\em ACM Transactions on Graphics}, 2018.

\bibitem{fan2012example}
R.~Fan, S.~Xu, and W.~Geng.
\newblock Example-based automatic music-driven conventional dance motion
  synthesis.
\newblock {\em IEEE Transactions on Visualization and Computer Graphics}, 2012.

\bibitem{gao2018learning}
R.~Gao, R.~Feris, and K.~Grauman.
\newblock Learning to separate object sounds by watching unlabeled video.
\newblock In {\em European Conference on Computer Vision}, 2018.

\bibitem{harwath2018jointly}
D.~Harwath, A.~Recasens, D.~Sur{\'\i}s, G.~Chuang, A.~Torralba, and J.~Glass.
\newblock Jointly discovering visual objects and spoken words from raw sensory
  input.
\newblock In {\em European Conference on Computer Vision}, 2018.

\bibitem{fid}
M.~Heusel, H.~Ramsauer, T.~Unterthiner, B.~Nessler, and S.~Hochreiter.
\newblock {GANs} trained by a two time-scale update rule converge to a local
  nash equilibrium.
\newblock In {\em Neural Information Processing Systems}, 2017.

\bibitem{karpathy2015deep}
A.~Karpathy and L.~Fei-Fei.
\newblock Deep visual-semantic alignments for generating image descriptions.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition},
  2015.

\bibitem{karras2017audio}
T.~Karras, T.~Aila, S.~Laine, A.~Herva, and J.~Lehtinen.
\newblock Audio-driven facial animation by joint end-to-end learning of pose
  and emotion.
\newblock {\em ACM Transactions on Graphics}, 2017.

\bibitem{adam}
D.~Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization.
\newblock In {\em International Conference on Learning Representations}, 2015.

\bibitem{lee2017unsupervised}
H.-Y. Lee, J.-B. Huang, M.~Singh, and M.-H. Yang.
\newblock Unsupervised representation learning by sorting sequences.
\newblock In {\em IEEE International Conference on Computer Vision}, 2017.

\bibitem{DRIT}
H.-Y. Lee, H.-Y. Tseng, J.-B. Huang, M.~K. Singh, and M.-H. Yang.
\newblock Diverse image-to-image translation via disentangled representations.
\newblock In {\em European Conference on Computer Vision}, 2018.

\bibitem{lee2013music}
M.~Lee, K.~Lee, and J.~Park.
\newblock Music similarity-based approach to generating dance motion sequence.
\newblock {\em Multimedia Tools and Applications}, 2013.

\bibitem{lu2019self}
Y.-D. Lu, H.-Y. Lee, H.-Y. Tseng, and M.-H. Yang.
\newblock Self-supervised audio spatialization with correspondence classifier.
\newblock In {\em IEEE International Conference on Image Processing}, 2019.

\bibitem{music-dance-1}
G.~Madison, F.~Gouyon, F.~Ullen, and K.~Hornstrom.
\newblock Modeling the tendency for music to induce movement in humans: First
  correlations with low-level audio descriptors across music genres.
\newblock {\em Journal of Experimental Psychology: Human Perception and
  Performance}, 2011.

\bibitem{mathieu2015deep}
M.~Mathieu, C.~Couprie, and Y.~LeCun.
\newblock Deep multi-scale video prediction beyond mean square error.
\newblock In {\em International Conference on Learning Representations}, 2016.

\bibitem{ofli2012learn2dance}
F.~Ofli, E.~Erzin, Y.~Yemez, and M.~Tekalp.
\newblock {Learn2Dance}: Learning statistical music-to-dance mappings for
  choreography synthesis.
\newblock {\em IEEE Transactions on Multimedia}, 2012.

\bibitem{owens2018audio}
A.~Owens and A.~Efros.
\newblock Audio-visual scene analysis with self-supervised multisensory
  features.
\newblock In {\em European Conference on Computer Vision}, 2018.

\bibitem{owens2016visually}
A.~Owens, P.~Isola, J.~McDermott, A.~Torralba, E.~Adelson, and W.~Freeman.
\newblock Visually indicated sounds.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition},
  2016.

\bibitem{owens2016ambient}
A.~Owens, J.~Wu, J.~McDermott, W.~Freeman, and A.~Torralba.
\newblock Ambient sound provides supervision for visual learning.
\newblock In {\em European Conference on Computer Vision}, 2016.

\bibitem{reed2016generative}
S.~Reed, Z.~Akata, X.~Yan, L.~Logeswaran, B.~Schiele, and H.~Lee.
\newblock Generative adversarial text to image synthesis.
\newblock In {\em International Conference on Machine Learning}, 2016.

\bibitem{music-dance-2}
G.~Schellenberg, A.~Krysciak, and J.~Campbell.
\newblock Perceiving emotion in melody: Interactive effects of pitch and
  rhythm.
\newblock {\em Music Perception}, 2000.

\bibitem{senocak2018learning}
A.~Senocak, T.-H. Oh, J.~Kim, M.-H. Yang, and I.-S. Kweon.
\newblock Learning to localize sound source in visual scenes.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition},
  2018.

\bibitem{shlizerman2017audio}
E.~Shlizerman, L.~Dery, H.~Schoen, and I.~Kemelmacher-Shlizerman.
\newblock Audio to body dynamics.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition},
  2018.

\bibitem{srivastava2015unsupervised}
N.~Srivastava, E.~Mansimov, and R.~Salakhudinov.
\newblock Unsupervised learning of video representations using {LSTMs}.
\newblock In {\em International Conference on Machine Learning}, 2015.

\bibitem{suwajanakorn2017synthesizing}
S.~Suwajanakorn, S.~M. Seitz, and I.~Kemelmacher-Shlizerman.
\newblock Synthesizing {Obama}: Learning lip sync from audio.
\newblock {\em ACM Transactions on Graphics}, 2017.

\bibitem{tang2018dance}
T.~Tang, J.~Jia, and H.~Mao.
\newblock Dance with melody: An {LSTM}-autoencoder approach to music-oriented
  dance synthesis.
\newblock In {\em ACM Multimedia}, 2018.

\bibitem{tulyakov2017mocogan}
S.~Tulyakov, M.-Y. Liu, X.~Yang, and J.~Kautz.
\newblock {MoCoGAN}: Decomposing motion and content for video generation.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition},
  2018.

\bibitem{vinyals2015show}
O.~Vinyals, A.~Toshev, S.~Bengio, and D.~Erhan.
\newblock Show and tell: A neural image caption generator.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition},
  2015.

\bibitem{vondrick2016generating}
C.~Vondrick, H.~Pirsiavash, and A.~Torralba.
\newblock Generating videos with scene dynamics.
\newblock In {\em Neural Information Processing Systems}, 2016.

\bibitem{walker2017pose}
J.~Walker, K.~Marino, A.~Gupta, and M.~Hebert.
\newblock The pose knows: Video forecasting by generating pose futures.
\newblock In {\em IEEE International Conference on Computer Vision}, 2017.

\bibitem{wang2018vid2vid}
T.-C. Wang, M.-Y. Liu, J.-Y. Zhu, G.~Liu, A.~Tao, J.~Kautz, and B.~Catanzaro.
\newblock Video-to-video synthesis.
\newblock In {\em Neural Information Processing Systems}, 2018.

\bibitem{yan2018mt}
X.~Yan, A.~Rastogi, R.~Villegas, K.~Sunkavalli, E.~Shechtman, S.~Hadap,
  E.~Yumer, and H.~Lee.
\newblock {MT-VAE}: Learning motion transformations to generate multimodal
  human dynamics.
\newblock In {\em European Conference on Computer Vision}, 2018.

\bibitem{yang-3d-joints}
X.~Yang and Y.~Tian.
\newblock Effective 3d action recognition using eigenjoints.
\newblock {\em Journal of Visual Communication and Image Representation}, 2014.

\bibitem{zhang2017stackgan}
H.~Zhang, T.~Xu, H.~Li, S.~Zhang, X.~Huang, X.~Wang, and D.~Metaxas.
\newblock {StackGAN}: Text to photo-realistic image synthesis with stacked
  generative adversarial networks.
\newblock In {\em IEEE International Conference on Computer Vision}, 2017.

\bibitem{zhang2018perceptual}
R.~Zhang, P.~Isola, A.~Efros, E.~Shechtman, and O.~Wang.
\newblock The unreasonable effectiveness of deep networks as a perceptual
  metric.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition},
  2018.

\bibitem{zhou2017visual}
Y.~Zhou, Z.~Wang, C.~Fang, T.~Bui, and T.~Berg.
\newblock Visual to sound: Generating natural sound for videos in the wild.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition},
  2018.

\end{thebibliography}
