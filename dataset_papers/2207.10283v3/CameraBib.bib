%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Sekitoshi Kanai at 2021-05-10 14:13:39 +0900 


%% Saved with string encoding Unicode (UTF-8) 


@string{aaai = {Proc.\ AAAI}}

@string{accv = {Proc.\ ACCV}}

@string{aistats = {Proc.\ AISTATS}}

@string{amdo = {Proc.\ AMDO}}

@string{bmvc = {Proc.\ BMVC}}

@string{camp = {Proc.\ CAMP}}

@string{csvt = {TCSVT}}

@string{cva = {IPSJ Trans.\ on CVA}}

@string{cviu = {CVIU}}

@string{cvpr = {Proc.\ CVPR}}

@string{eacl = {Proc.\ EACL}}

@string{eccv = {Proc.\ ECCV}}

@string{emnlp = {Proc.\ EMNLP}}

@string{fg = {Proc.\ FG}}

@string{icassp = {Proc.\ ICASSP}}

@string{iccp = {Proc.\ ICCP}}

@string{iccv = {Proc.\ ICCV}}

@string{icdm = {Proc.\ ICDM}}

@string{icip = {Proc.\ ICIP}}

@string{iclr = {Proc.\ ICLR}}

@string{icml = {Proc.\ ICML}}

@string{icpr = {Proc.\ ICPR}}

@string{icra = {Proc.\ ICRA}}

@string{ieeem = {IEEE Multimedia}}

@string{ijcai = {Proc.\ IJCAI}}

@string{ijcv = {IJCV}}

@string{nips = {Proc.\ NeurIPS}}

@string{pami = {TPAMI}}

@string{procams = {Proc.\ PROCAMS}}

@string{siggraph = {Proc.\ SIGGRAPH}}

@string{tdim = {Proc.\ 3DIM}}

@string{tdimpvt = {Proc.\ 3DIMPVT}}

@string{tdpvt = {Proc.\ 3DPVT}}

@string{tdv = {Proc.\ 3DV}}

@string{uai = {Proc.\ UAI}}

@string{www = {Proc.\ WWW}}


@article{doya1992bifurcations,
	author = {Doya, Kenji},
	journal = {learning (RTRL)},
	pages = {17},
	publisher = {Citeseer},
	title = {Bifurcations in the learning of recurrent neural networks 3},
	volume = {3},
	year = {1992}}

@article{pascanu2012difficulty,
	author = {Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
	journal = {arXiv preprint arXiv:1211.5063},
	title = {On the difficulty of training recurrent neural networks},
	year = {2012}}

@article{cho2014learning,
	author = {Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
	journal = {arXiv preprint arXiv:1406.1078},
	title = {Learning phrase representations using RNN encoder-decoder for statistical machine translation},
	year = {2014}}

@inproceedings{cho-al-emnlp14,
	author = {Cho, Kyunghyun and Van Merri\"{e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
	booktitle = emnlp,
	pages = {1724--1734},
	publisher = {ACL},
	title = {Learning Phrase Representations using RNN Encoder--Decoder for Statistical Machine Translation},
	year = {2014}}

@inproceedings{jozefowicz2015empirical,
	author = {Jozefowicz, Rafal and Zaremba, Wojciech and Sutskever, Ilya},
	booktitle = icml,
	pages = {2342--2350},
	title = {An empirical exploration of recurrent network architectures},
	year = {2015}}

@article{arjovsky2015unitary,
	author = {Arjovsky, Martin and Shah, Amar and Bengio, Yoshua},
	journal = {arXiv preprint arXiv:1511.06464},
	title = {Unitary Evolution Recurrent Neural Networks},
	year = {2015}}

@article{saxe2013exact,
	author = {Saxe, Andrew M and McClelland, James L and Ganguli, Surya},
	journal = {arXiv preprint arXiv:1312.6120},
	title = {Exact solutions to the nonlinear dynamics of learning in deep linear neural networks},
	year = {2013}}

@inproceedings{saxe2014exact,
	author = {Saxe, Andrew M and McClelland, James L and Ganguli, Surya},
	booktitle = iclr,
	title = {Exact solutions to the nonlinear dynamics of learning in deep linear neural networks},
	year = {2014}}

@article{haschke2005input,
	author = {Haschke, Robert and Steil, Jochen J},
	journal = {Neurocomputing},
	pages = {25--38},
	publisher = {Elsevier},
	title = {Input space bifurcation manifolds of recurrent neural networks},
	volume = {64},
	year = {2005}}

@article{miller2013subspace,
	author = {Miller, Daniel N and De Callafon, Raymond A},
	journal = {Automatica},
	number = {8},
	pages = {2468--2473},
	publisher = {Elsevier},
	title = {Subspace identification with eigenvalue constraints},
	volume = {49},
	year = {2013}}

@article{zhou2016minimal,
	author = {Zhou, Guo-Bing and Wu, Jianxin and Zhang, Chen-Lin and Zhou, Zhi-Hua},
	journal = {International Journal of Automation and Computing},
	number = {3},
	pages = {226--234},
	publisher = {Springer},
	title = {Minimal gated unit for recurrent neural networks},
	volume = {13},
	year = {2016}}

@article{zaremba2014recurrent,
	author = {Zaremba, Wojciech and Sutskever, Ilya and Vinyals, Oriol},
	journal = {arXiv preprint arXiv:1409.2329},
	title = {Recurrent neural network regularization},
	year = {2014}}

@inproceedings{belanger2015linear,
	author = {Belanger, David and Kakade, Sham},
	booktitle = icml,
	pages = {833--842},
	title = {A linear dynamical system model for text},
	year = {2015}}

@inproceedings{pasa2014pre,
	author = {Pasa, Luca and Sperduti, Alessandro},
	booktitle = {Advances in Neural Information Processing Systems},
	pages = {3572--3580},
	title = {Pre-training of recurrent neural networks via linear autoencoders},
	year = {2014}}

@article{yu2004nonlinear,
	author = {Yu, Wen},
	journal = {Information sciences},
	pages = {131--147},
	publisher = {Elsevier},
	title = {Nonlinear system identification using discrete-time recurrent neural networks with stable learning algorithms},
	volume = {158},
	year = {2004}}

@article{srivastava2014dropout,
	author = {Srivastava, Nitish and Hinton, Geoffrey E and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	journal = {Journal of Machine Learning Research},
	number = {1},
	pages = {1929--1958},
	title = {Dropout: a simple way to prevent neural networks from overfitting.},
	volume = {15},
	year = {2014}}

@article{krueger2015regularizing,
	author = {Krueger, David and Memisevic, Roland},
	journal = {arXiv preprint arXiv:1511.08400},
	title = {Regularizing RNNs by stabilizing activations},
	year = {2015}}

@inproceedings{rice2020overfitting,
	author = {Rice, Leslie and Wong, Eric and Kolter, J Zico},
	booktitle = icml,
	title = {Overfitting in adversarially robust deep learning},
	year = {2020}}

@article{krueger2015regularizing,
	author = {Krueger, David and Memisevic, Roland},
	journal = {arXiv preprint arXiv:1511.08400},
	title = {Regularizing RNNs by stabilizing activations},
	year = {2015}}

@article{chung2014empirical,
	author = {Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
	journal = {arXiv preprint arXiv:1412.3555},
	title = {Empirical evaluation of gated recurrent neural networks on sequence modeling},
	year = {2014}}

@book{horn2012matrix,
	author = {Horn, Roger A and Johnson, Charles R},
	edition = {Second},
	publisher = {Cambridge university press},
	title = {Matrix analysis (2nd ed.)},
	year = {2012}}

@inproceedings{oh2015fast,
	author = {Oh, Tae-Hyun and Matsushita, Yasuyuki and Tai, Yu-Wing and So Kweon, In},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages = {4484--4493},
	title = {Fast randomized singular value thresholding for nuclear norm minimization},
	year = {2015}}

@article{amodei2015deep,
	author = {Amodei, Dario and Anubhai, Rishita and Battenberg, Eric and Case, Carl and Casper, Jared and Catanzaro, Bryan and Chen, Jingdong and Chrzanowski, Mike and Coates, Adam and Diamos, Greg and others},
	booktitle = icml,
	title = {Deep speech 2: End-to-end speech recognition in english and mandarin},
	year = {2016}}

@inproceedings{doya1992bifurcations2,
	author = {Doya, Kenji},
	booktitle = {Proc.\ ISCAS},
	organization = {IEEE},
	pages = {2777--2780},
	title = {Bifurcations in the learning of recurrent neural networks},
	volume = {6},
	year = {1992}}

@inproceedings{doya1992bifurcations3,
	author = {Doya, Kenji},
	booktitle = {Proceedings of 1992 IEEE International Symposium on Circuits and Systems (ISCAS)},
	pages = {2777--2780},
	title = {Bifurcations in the learning of recurrent neural networks},
	volume = {6},
	year = {1992}}

@article{doya1992bifurcations,
	author = {Doya, Kenji},
	journal = {learning (RTRL)},
	pages = {17},
	publisher = {Citeseer},
	title = {Bifurcations in the learning of recurrent neural networks 3},
	volume = {3},
	year = {1992}}

@article{pascanu2012difficulty,
	author = {Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
	journal = {arXiv preprint arXiv:1211.5063},
	title = {On the difficulty of training recurrent neural networks},
	year = {2012}}

@inproceedings{pascanu2013difficulty,
	author = {Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
	booktitle = icml,
	pages = {1310--1318},
	title = {On the difficulty of training recurrent neural networks},
	year = {2013}}

@article{cho2014learning,
	author = {Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
	journal = {arXiv preprint arXiv:1406.1078},
	title = {Learning phrase representations using RNN encoder-decoder for statistical machine translation},
	year = {2014}}

@inproceedings{jozefowicz2015empirical,
	author = {Jozefowicz, Rafal and Zaremba, Wojciech and Sutskever, Ilya},
	booktitle = icml,
	pages = {2342--2350},
	title = {An empirical exploration of recurrent network architectures},
	year = {2015}}

@inproceedings{arjovsky2016unitary,
	author = {Arjovsky, Martin and Shah, Amar and Bengio, Yoshua},
	booktitle = icml,
	pages = {1120--1128},
	title = {Unitary Evolution Recurrent Neural Networks},
	year = {2016}}

@article{saxe2013exact,
	author = {Saxe, Andrew M and McClelland, James L and Ganguli, Surya},
	journal = {arXiv preprint arXiv:1312.6120},
	title = {Exact solutions to the nonlinear dynamics of learning in deep linear neural networks},
	year = {2013}}

@article{haschke2005input,
	author = {Haschke, Robert and Steil, Jochen J},
	journal = {Neurocomputing},
	pages = {25--38},
	publisher = {Elsevier},
	title = {Input space bifurcation manifolds of recurrent neural networks},
	volume = {64},
	year = {2005}}

@article{olddeepspeech2,
	author = {Amodei, Dario and Anubhai, Rishita and Battenberg, Eric and Case, Carl and Casper, Jared and Catanzaro, Bryan and Chen, Jingdong and Chrzanowski, Mike and Coates, Adam and Diamos, Greg and others},
	journal = {arXiv preprint arXiv:1512.02595},
	title = {Deep Speech 2: End-to-End Speech Recognition in English and Mandarin},
	year = {2015}}

@inproceedings{old2deepspeech2,
	author = {Amodei, Dario and Anubhai, Rishita and Battenberg, Eric and Case, Carl and Casper, Jared and Catanzaro, Bryan and Chen, Jingdong and Chrzanowski, Mike and Coates, Adam and Diamos, Greg and others},
	booktitle = icml,
	pages = {173--182},
	title = {Deep Speech 2: End-to-End Speech Recognition in English and Mandarin},
	year = {2016}}

@inproceedings{deepspeech2,
	author = {Amodei, Dario and Anubhai, Rishita and Battenberg, Eric and Case, Carl and Casper, Jared and Catanzaro, Bryan and Chen, Jingdong and Chrzanowski, Mike and Coates, Adam and Diamos, Greg and Elsen, Erich and Engel, Jesse and Fan, Linxi and Fougner, Christopher and Hannun, Awni and Jun, Billy and Han, Tony and LeGresley, Patrick and Li, Xiangang and Lin, Libby and Narang, Sharan and Ng, Andrew and Ozair, Sherjil and Prenger, Ryan and Qian, Sheng and Raiman, Jonathan and Satheesh, Sanjeev and Seetapun, David and Sengupta, Shubho and Wang, Chong and Wang, Yi and Wang, Zhiqian and Xiao, Bo and Xie, Yan and Yogatama, Dani and Zhan, Jun and Zhu, Zhenyao},
	booktitle = icml,
	pages = {173--182},
	title = {Deep Speech 2: End-to-End Speech Recognition in English and Mandarin},
	year = {2016}}

@inproceedings{imagenet,
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	booktitle = nips,
	pages = {1097--1105},
	title = {Imagenet classification with deep convolutional neural networks},
	year = {2012}}

@article{elmanrnn,
	author = {Elman, Jeffrey L},
	journal = {Cognitive science},
	number = {2},
	pages = {179--211},
	publisher = {Elsevier},
	title = {Finding structure in time},
	volume = {14},
	year = {1990}}

@misc{tractica,
	author = {Tractica},
	title = {Deep Learning for Enterprise Applications: Advertising Technology, Financial Services, Media, Manufacturing, Oil \& Gas, Retail, and Other Enterprise Markets for Deep Learning Software and Systems},
	year = {2015}}

@misc{iot,
	author = {IDC},
	title = {Explosive Internet of Things Spending to Reach \$1.7 Trillion in 2020, According to {IDC}},
	year = {2015}}

@article{lstm,
	author = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
	journal = {Neural computation},
	number = {8},
	pages = {1735--1780},
	publisher = {MIT Press},
	title = {Long short-term memory},
	volume = {9},
	year = {1997}}

@article{bengio1994learning,
	author = {Bengio, Yoshua and Simard, Patrice and Frasconi, Paolo},
	journal = {IEEE Transactions on Neural Networks},
	number = {2},
	pages = {157--166},
	publisher = {IEEE},
	title = {Learning long-term dependencies with gradient descent is difficult},
	volume = {5},
	year = {1994}}

@inproceedings{improving,
	author = {Talathi, Sachin S and Vartak, Aniket},
	booktitle = iclr,
	title = {Improving performance of recurrent neural network with relu nonlinearity},
	year = {2016}}

@article{kuan1994convergence,
	author = {Kuan, Chung-Ming and Hornik, Kurt and White, Halbert},
	journal = {Neural Computation},
	number = {3},
	pages = {420--440},
	publisher = {MIT Press},
	title = {A convergence result for learning in recurrent neural networks},
	volume = {6},
	year = {1994}}

@article{chorowski2014end,
	author = {Chorowski, Jan and Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
	journal = {arXiv preprint arXiv:1412.1602},
	title = {End-to-end continuous speech recognition using attention-based recurrent NN: first results},
	year = {2014}}

@misc{hochreiter2001gradient,
	author = {Hochreiter, Sepp and Bengio, Yoshua and Frasconi, Paolo and Schmidhuber, J{\"u}rgen},
	publisher = {A field guide to dynamical recurrent neural networks. IEEE Press},
	title = {Gradient flow in recurrent nets: the difficulty of learning long-term dependencies},
	year = {2001}}

@book{wiggins2003introduction,
	author = {Wiggins, Stephen},
	publisher = {Springer Science \& Business Media},
	title = {Introduction to applied nonlinear dynamical systems and chaos},
	volume = {2},
	year = {2003}}

@inproceedings{graves2013speech,
	author = {Graves, Alex and Mohamed, Abdel-rahman and Hinton, Geoffrey},
	booktitle = icassp,
	organization = {IEEE},
	pages = {6645--6649},
	title = {Speech recognition with deep recurrent neural networks},
	year = {2013}}

@inproceedings{inoue2013robust,
	author = {Inoue, Masaki and Imura, Jun-ichi and Kashima, Kenji and Aihara, Kazuyuki},
	booktitle = {Proceedings of 2013 IEEE 52nd Annual Conference on Decision and Control (CDC)},
	organization = {IEEE},
	pages = {1768--1773},
	title = {Robust bifurcation analysis based on the Nyquist stability criterion},
	year = {2013}}

@article{mcgraw2016personalized,
	author = {McGraw, Ian and Prabhavalkar, Rohit and Alvarez, Raziel and Arenas, Montse Gonzalez and Rao, Kanishka and Rybach, David and Alsharif, Ouais and Sak, Hasim and Gruenstein, Alexander and Beaufays, Francoise and others},
	journal = {arXiv preprint arXiv:1603.03185},
	title = {Personalized Speech recognition on mobile devices},
	year = {2016}}

@inproceedings{BaiduPersistent,
	author = {Diamos, Greg and Sengupta, Shubho and Catanzaro, Bryan and Chrzanowski, Mike and Coates, Adam and Elsen, Erich and Engel, Jesse and Hannun, Awni and Satheesh, Sanjeev},
	booktitle = iclr,
	title = {Persistent RNNs Stashing Weights on Chip},
	year = {2016}}

@inproceedings{dean2012large,
	author = {Dean, Jeffrey and Corrado, Greg and Monga, Rajat and Chen, Kai and Devin, Matthieu and Mao, Mark and Senior, Andrew and Tucker, Paul and Yang, Ke and Le, Quoc V and others},
	booktitle = nips,
	pages = {1223--1231},
	title = {Large scale distributed deep networks},
	year = {2012}}

@article{le2015simple,
	author = {Le, Quoc V and Jaitly, Navdeep and Hinton, Geoffrey E},
	journal = {arXiv preprint arXiv:1504.00941},
	title = {A simple way to initialize recurrent networks of rectified linear units},
	year = {2015}}

@book{schmidhuber2015deep,
	author = {Schmidhuber, J{\"u}rgen},
	journal = {Neural Networks},
	pages = {85--117},
	publisher = {Elsevier},
	title = {Deep learning in neural networks: An overview},
	volume = {61},
	year = {2015}}

@article{tomas,
	author = {Mikolov, Tomas},
	journal = {PhD thesis, Brno University of Technology},
	title = {Statistical language models based on Neural Networks},
	year = {2012}}

@inproceedings{graves2009offline,
	author = {Graves, Alex and Schmidhuber, J{\"u}rgen},
	booktitle = nips,
	pages = {545--552},
	title = {Offline handwriting recognition with multidimensional recurrent neural networks},
	year = {2009}}

@book{wiggins2003introduction,
	author = {Wiggins, Stephen},
	publisher = {Springer Science \& Business Media},
	title = {Introduction to applied nonlinear dynamical systems and chaos},
	volume = {2},
	year = {2003}}

@article{kuan1994convergence,
	author = {Kuan, Chung-Ming and Hornik, Kurt and White, Halbert},
	journal = {Neural Computation},
	number = {3},
	pages = {420--440},
	publisher = {MIT Press},
	title = {A convergence result for learning in recurrent neural networks},
	volume = {6},
	year = {1994}}

@article{balduzzi2016strongly,
	author = {Balduzzi, David and Ghifary, Muhammad},
	journal = {arXiv preprint arXiv:1602.02218},
	title = {Strongly-Typed Recurrent Neural Networks},
	year = {2016}}

@article{jaeger2004harnessing,
	author = {Jaeger, Herbert and Haas, Harald},
	journal = {science},
	number = {5667},
	pages = {78--80},
	publisher = {American Association for the Advancement of Science},
	title = {Harnessing nonlinearity: Predicting chaotic systems and saving energy in wireless communication},
	volume = {304},
	year = {2004}}

@article{patan2007stability,
	author = {Patan, Krzysztof},
	journal = {IEEE Transactions on Neural Networks},
	number = {3},
	pages = {660--673},
	publisher = {IEEE},
	title = {Stability analysis and the stabilization of a class of discrete-time dynamic neural networks},
	volume = {18},
	year = {2007}}

@article{barabanov2002stability,
	author = {Barabanov, Nikita E and Prokhorov, Danil V},
	journal = {IEEE Transactions on Neural Networks},
	number = {2},
	pages = {292--303},
	publisher = {IEEE},
	title = {Stability analysis of discrete-time recurrent neural networks},
	volume = {13},
	year = {2002}}

@article{suykens2000robust,
	author = {Suykens, Johan AK and De Moor, Bart and Vandewalle, Joos},
	journal = {IEEE Transactions on Neural Networks},
	number = {1},
	pages = {222--229},
	publisher = {IEEE},
	title = {Robust local stability of multilayer recurrent neural networks},
	volume = {11},
	year = {2000}}

@article{haschke2005input,
	author = {Haschke, Robert and Steil, Jochen J},
	journal = {Neurocomputing},
	pages = {25--38},
	publisher = {Elsevier},
	title = {Input space bifurcation manifolds of recurrent neural networks},
	volume = {64},
	year = {2005}}

@inproceedings{tang2016memory,
	author = {Tang, Zhiyuan and Shi, Ying and Wang, Dong and Feng, Yang and Zhang, Shiyue},
	booktitle = icassp,
	organization = {IEEE},
	pages = {2736--2740},
	title = {Memory Visualization for Gated Recurrent Neural Networks in Speech Recognition},
	year = {2017}}

@inproceedings{lu2016training,
	author = {Lu, Liang and Zhang, Xingxing and Renais, Steve},
	booktitle = icassp,
	organization = {IEEE},
	pages = {5060--5064},
	title = {On training the recurrent neural network encoder-decoder for large vocabulary end-to-end speech recognition},
	year = {2016}}

@inproceedings{jozefowicz2015empirical,
	author = {Jozefowicz, Rafal and Zaremba, Wojciech and Sutskever, Ilya},
	booktitle = icml,
	pages = {2342--2350},
	title = {An Empirical Exploration of Recurrent Network Architectures},
	year = {2015}}

@article{chorowski2014end,
	author = {Chorowski, Jan and Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
	journal = {arXiv preprint arXiv:1412.1602},
	title = {End-to-end continuous speech recognition using attention-based recurrent NN: first results},
	year = {2014}}

@inproceedings{lu2016training,
	author = {Lu, Liang and Zhang, Xingxing and Renais, Steve},
	booktitle = icassp,
	organization = {IEEE},
	pages = {5060--5064},
	title = {On training the recurrent neural network encoder-decoder for large vocabulary end-to-end speech recognition},
	year = {2016}}

@article{zeiler2012adadelta,
	author = {Zeiler, Matthew D},
	journal = {arXiv preprint arXiv:1212.5701},
	title = {ADADELTA: an adaptive learning rate method},
	year = {2012}}

@book{jaeger2002tutorial,
	author = {Jaeger, Herbert},
	publisher = {GMD-Forschungszentrum Informationstechnik},
	title = {Tutorial on training recurrent neural networks, covering BPPT, RTRL, EKF and the" echo state network" approach},
	year = {2002}}

@inproceedings{vcervnansky2007comparison,
	author = {{\v{C}}er{\v{n}}ansk{\`y}, Michal and Ti{\v{n}}o, Peter},
	booktitle = {International Conference on Artificial Neural Networks},
	organization = {Springer},
	pages = {618--627},
	title = {Comparison of echo state networks with simple recurrent networks and variable-length Markov models on symbolic sequences},
	year = {2007}}

@article{talathi2015improving,
	author = {Talathi, Sachin S and Vartak, Aniket},
	journal = {arXiv preprint arXiv:1511.03771},
	title = {Improving performance of recurrent neural network with relu nonlinearity},
	year = {2015}}

@book{strang2010calculus,
	author = {Strang, Gilbert.},
	edition = {Second},
	publisher = {Wellesley-Cambridge Press},
	title = {Calculus (2nd ed.)},
	year = {2010}}

@article{vanantwerp2000tutorial,
	author = {VanAntwerp, Jeremy G and Braatz, Richard D},
	journal = {Journal of process control},
	number = {4},
	pages = {363--385},
	publisher = {Elsevier},
	title = {A tutorial on linear and bilinear matrix inequalities},
	volume = {10},
	year = {2000}}

@article{chilali1996h,
	author = {Chilali, Mahmoud and Gahinet, Pascal},
	journal = {IEEE Transactions on automatic control},
	number = {3},
	pages = {358--367},
	publisher = {IEEE},
	title = {H $\infty$ design with pole placement constraints: an LMI approach},
	volume = {41},
	year = {1996}}

@inproceedings{toker1995np,
	author = {Toker, Onur and Ozbay, Hitay},
	booktitle = {Proc. of American Control Conference},
	organization = {IEEE},
	pages = {2525--2526},
	title = {On the NP-hardness of solving bilinear matrix inequalities and simultaneous stabilization with static output feedback},
	volume = {4},
	year = {1995}}

@article{rnnwithoutchaos,
	author = {Thomas Laurent and James von Brecht},
	journal = {arXiv preprint arXiv:1612.06212},
	title = {A recurrent neural network without chaos},
	year = {2016}}

@inproceedings{rnnwithoutchaos2017,
	author = {Thomas Laurent and James von Brecht},
	booktitle = iclr,
	title = {A recurrent neural network without chaos},
	year = {2017}}

@article{bertsekas1999nonlinear,
	author = {Bertsekas, Dimitri P},
	publisher = {Athena Scientific},
	title = {Nonlinear Programming},
	year = {1999}}

@article{collins2016capacity,
	author = {Collins, Jasmine and Sohl-Dickstein, Jascha and Sussillo, David},
	journal = {arXiv preprint arXiv:1611.09913},
	title = {Capacity and Trainability in Recurrent Neural Networks},
	year = {2016}}

@inproceedings{collins2017capacity,
	author = {Collins, Jasmine and Sohl-Dickstein, Jascha and Sussillo, David},
	booktitle = iclr,
	title = {Capacity and Trainability in Recurrent Neural Networks},
	year = {2017}}

@article{boulanger2012modeling,
	author = {Boulanger-Lewandowski, Nicolas and Bengio, Yoshua and Vincent, Pascal},
	journal = {arXiv preprint arXiv:1206.6392},
	title = {Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation and transcription},
	year = {2012}}

@inproceedings{boulanger2012modeling2,
	author = {Boulanger-Lewandowski, Nicolas and Bengio, Yoshua and Vincent, Pascal},
	booktitle = icml,
	pages = {1159--1166},
	title = {Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation and transcription},
	year = {2012}}

@article{marcus1993building,
	author = {Marcus, Mitchell P and Marcinkiewicz, Mary Ann and Santorini, Beatrice},
	journal = {Computational linguistics},
	number = {2},
	pages = {313--330},
	publisher = {MIT Press},
	title = {Building a large annotated corpus of English: The Penn Treebank},
	volume = {19},
	year = {1993}}

@inproceedings{krueger2016regularizing,
	author = {Krueger, David and Memisevic, Roland},
	booktitle = iclr,
	title = {Regularizing RNNs by stabilizing activations},
	year = {2016}}

@inproceedings{graves2014towards,
	author = {Graves, Alex and Jaitly, Navdeep},
	booktitle = {ICML},
	pages = {1764--1772},
	title = {Towards End-To-End Speech Recognition with Recurrent Neural Networks.},
	volume = {14},
	year = {2014}}

@article{halko2009finding,
	author = {Halko, N and Martinsson, PG and Tropp, JA},
	journal = {arXiv preprint arXiv:0909.4061},
	title = {FINDING STRUCTURE WITH RANDOMNESS: STOCHASTIC ALGORITHMS FOR CONSTRUCTING APPROXIMATE MATRIX DECOMPOSITIONS},
	year = {2009}}

@book{horn1991topics,
	author = {Horn, Roger A and Johnson, Charles R},
	publisher = {Cambridge university press},
	title = {Topics in matrix analysis},
	year = {1991}}

@article{tieleman2012lecture,
	author = {Tieleman, Tijmen and Hinton, Geoffrey},
	journal = {COURSERA: Neural networks for machine learning},
	number = {2},
	title = {Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude},
	volume = {4},
	year = {2012}}

@inproceedings{kingma2014adam,
	author = {Kingma, Diederik and Ba, Jimmy},
	booktitle = iclr,
	title = {Adam: A method for stochastic optimization},
	year = {2015}}

@inproceedings{chainer_learningsys2015,
	author = {Tokui, Seiya and Oono, Kenta and Hido, Shohei and Clayton, Justin},
	booktitle = {Proc. Workshop on Machine Learning Systems (LearningSys) in NIPS},
	title = {Chainer: a Next-Generation Open Source Framework for Deep Learning},
	year = {2015}}

@incollection{NIPS1995_1062,
	author = {Baldi, Pierre and Kurt Hornik},
	booktitle = nips,
	pages = {451--457},
	title = {Universal Approximation and Learning of Trajectories Using Oscillators},
	year = {1996}}

@incollection{NIPS1992_676,
	author = {Bernard Doyon and Bruno Cessac and Mathias Quoy and Manuel Samuelides},
	booktitle = nips,
	pages = {549--555},
	title = {Destabilization and Route to Chaos in Neural Networks with Random Connectivity},
	year = {1993}}

@incollection{NIPS2013_5166,
	author = {Hermans, Michiel and Schrauwen, Benjamin},
	booktitle = nips,
	pages = {190--198},
	title = {Training and Analysing Deep Recurrent Neural Networks},
	year = {2013}}

@incollection{NIPS1995_1031,
	author = {Hiroyuki Nakahara and Kenji Doya},
	booktitle = nips,
	pages = {38--44},
	title = {Dynamics of Attention as Near Saddle-Node Bifurcation Behavior},
	year = {1996}}

@incollection{NIPS2014_5346,
	author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
	booktitle = nips,
	pages = {3104--3112},
	title = {Sequence to Sequence Learning with Neural Networks},
	year = {2014}}

@inproceedings{vorontsov2017orthogonality,
	author = {Vorontsov, Eugene and Trabelsi, Chiheb and Kadoury, Samuel and Pal, Chris},
	booktitle = icml,
	title = {On orthogonality and learning recurrent networks with long term dependencies},
	year = {2017}}

@inproceedings{softmaxbottle,
	author = {Yang, Zhilin and Dai, Zihang and Salakhutdinov, Ruslan and Cohen, William W},
	booktitle = iclr,
	title = {Breaking the softmax bottleneck: a high-rank RNN language model},
	year = {2018}}

@book{goodfellow2016deep,
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	publisher = {MIT press},
	title = {Deep learning},
	year = {2016}}

@article{swish,
	author = {Prajit Ramachandran and Barret Zoph and Quoc V. Le},
	journal = {arXiv preprint arXiv:1710.05941},
	title = {Searching for Activation Functions},
	year = {2017}}

@inproceedings{relu,
	author = {Nair, Vinod and Hinton, Geoffrey E},
	booktitle = icml,
	organization = {Omnipress},
	pages = {807--814},
	title = {Rectified linear units improve restricted boltzmann machines},
	year = {2010}}

@inproceedings{lrelu,
	author = {Maas, Andrew L and Hannun, Awni Y and Ng, Andrew Y},
	booktitle = {in ICML Workshop on Deep Learning for Audio, Speech and Language Processing},
	title = {Rectifier nonlinearities improve neural network acoustic models},
	year = {2013}}

@inproceedings{prelu,
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle = iccv,
	pages = {1026--1034},
	title = {Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
	year = {2015}}

@article{elu,
	author = {Clevert, Djork-Arn{\'e} and Unterthiner, Thomas and Hochreiter, Sepp},
	journal = {arXiv preprint arXiv:1511.07289},
	title = {Fast and accurate deep network learning by exponential linear units (elus)},
	year = {2015}}

@inproceedings{resnet,
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle = cvpr,
	pages = {770--778},
	title = {Deep residual learning for image recognition},
	year = {2016}}

@incollection{softmax,
	author = {Bridle, John S},
	booktitle = {Neurocomputing},
	pages = {227--236},
	publisher = {Springer},
	title = {Probabilistic interpretation of feedforward classification network outputs, with relationships to statistical pattern recognition},
	year = {1990}}

@inproceedings{martins2016softmax,
	author = {Martins, Andre and Astudillo, Ramon},
	booktitle = icml,
	pages = {1614--1623},
	title = {From softmax to sparsemax: A sparse model of attention and multi-label classification},
	year = {2016}}

@article{grave2016efficient,
	author = {Grave, Edouard and Joulin, Armand and Ciss{\'e}, Moustapha and Grangier, David and J{\'e}gou, Herv{\'e}},
	journal = {arXiv preprint arXiv:1609.04309},
	title = {Efficient softmax approximation for {GPU}s},
	year = {2016}}

@inproceedings{joulin2017efficient,
	author = {Grave, {\'E}douard and Joulin, Armand and Ciss{\'e}, Moustapha and Grangier, David and J{\'e}gou, Herv{\'e}},
	booktitle = ICML,
	pages = {1302--1310},
	title = {Efficient softmax approximation for {GPU}s},
	year = {2017}}

@inproceedings{chen2017noisy,
	author = {Chen, Binghui and Deng, Weihong and Du, Junping},
	booktitle = cvpr,
	pages = {5372--5381},
	title = {Noisy Softmax: Improving the Generalization Ability of DCNN via Postponing the Early Softmax Saturation},
	year = {2017}}

@inproceedings{ioffe2015batch,
	author = {Ioffe, Sergey and Szegedy, Christian},
	booktitle = icml,
	pages = {448--456},
	title = {Batch normalization: Accelerating deep network training by reducing internal covariate shift},
	year = {2015}}

@inproceedings{memisevic2010gated,
	author = {Memisevic, Roland and Zach, Christopher and Pollefeys, Marc and Hinton, Geoffrey E},
	booktitle = nips,
	pages = {1603--1611},
	title = {Gated softmax classification},
	year = {2010}}

@inproceedings{de2015exploration,
	author = {de Br{\'e}bisson, Alexandre and Vincent, Pascal},
	booktitle = iclr,
	title = {An exploration of softmax alternatives belonging to the spherical loss family},
	year = {2016}}

@article{ollivier2013riemannian,
	author = {Ollivier, Yann},
	journal = {arXiv preprint arXiv:1303.0818},
	title = {Riemannian metrics for neural networks i: feedforward networks},
	year = {2013}}

@inproceedings{mohassel2017secureml,
	author = {Mohassel, Payman and Zhang, Yupeng},
	booktitle = {Security and Privacy (SP), 2017 IEEE Symposium on},
	organization = {IEEE},
	pages = {19--38},
	title = {Secureml: A system for scalable privacy-preserving machine learning},
	year = {2017}}

@inproceedings{glorot2010understanding,
	author = {Glorot, Xavier and Bengio, Yoshua},
	booktitle = aistats,
	pages = {249--256},
	title = {Understanding the difficulty of training deep feedforward neural networks},
	year = {2010}}

@book{bishop,
	author = {Bishop, Christopher M},
	publisher = {Springer-Verlag New York},
	title = {Pattern Recognition and Machine Learning.},
	year = {2006}}

@article{WT2,
	author = {Merity, Stephen and Xiong, Caiming and Bradbury, James and Socher, Richard},
	journal = {arXiv preprint arXiv:1609.07843},
	title = {Pointer sentinel mixture models},
	year = {2016}}

@inproceedings{WT2_2017,
	author = {Merity, Stephen and Xiong, Caiming and Bradbury, James and Socher, Richard},
	booktitle = iclr,
	title = {Pointer sentinel mixture models},
	year = {2017}}

@article{merity2017regularizing,
	author = {Merity, Stephen and Keskar, Nitish Shirish and Socher, Richard},
	journal = {arXiv preprint arXiv:1708.02182},
	title = {Regularizing and optimizing LSTM language models},
	year = {2017}}

@inproceedings{merity2018regularizing,
	author = {Merity, Stephen and Keskar, Nitish Shirish and Socher, Richard},
	booktitle = iclr,
	title = {Regularizing and optimizing LSTM language models},
	year = {2018}}

@book{press2007numerical,
	author = {Press, William H and Teukolsky, Saul A and Vetterling, William T and Flannery, Brian P},
	publisher = {Cambridge University Press},
	title = {Numerical Recipes 3rd Edition: The Art of Scientific Computing},
	year = {2007}}

@inproceedings{shim2017svd,
	author = {Shim, Kyuhong and Lee, Minjae and Choi, Iksoo and Boo, Yoonho and Sung, Wonyong},
	booktitle = nips,
	pages = {5469--5479},
	title = {{SVD}-Softmax: Fast Softmax Approximation on Large Vocabulary Neural Networks},
	year = {2017}}

@article{krause2017dynamic,
	author = {Krause, Ben and Kahembwe, Emmanuel and Murray, Iain and Renals, Steve},
	journal = {arXiv preprint arXiv:1709.07432},
	title = {Dynamic evaluation of neural sequence models},
	year = {2017}}

@inproceedings{aueb2016one,
	author = {Titsias, Michalis K.},
	booktitle = nips,
	pages = {4161--4169},
	title = {One-vs-each approximation to softmax for scalable estimation of probabilities},
	year = {2016}}

@inproceedings{bridle1990training,
	author = {Bridle, John S},
	booktitle = nips,
	pages = {211--217},
	title = {Training stochastic model recognition algorithms as networks can lead to maximum mutual information estimation of parameters},
	year = {1990}}

@inproceedings{krizhevsky2012imagenet,
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	booktitle = nips,
	pages = {1097--1105},
	title = {Imagenet classification with deep convolutional neural networks},
	year = {2012}}

@inproceedings{memisevic2010gated,
	author = {Memisevic, Roland and Zach, Christopher and Pollefeys, Marc and Hinton, Geoffrey E},
	booktitle = nips,
	pages = {1603--1611},
	title = {Gated softmax classification},
	year = {2010}}

@inproceedings{asadi2017alternative,
	author = {Asadi, Kavosh and Littman, Michael L},
	booktitle = icml,
	pages = {243--252},
	title = {An Alternative Softmax Operator for Reinforcement Learning},
	year = {2017}}

@book{bishop1995neural,
	author = {Bishop, Christopher M},
	publisher = {Oxford university press},
	title = {Neural Networks for Pattern Recognition},
	year = {1995}}

@article{press2017using,
	author = {Press, Ofir and Wolf, Lior},
	journal = eacl,
	pages = {157},
	title = {Using the Output Embedding to Improve Language Models},
	year = {2017}}

@article{jean2014using,
	author = {Jean, S{\'e}bastien and Cho, Kyunghyun and Memisevic, Roland and Bengio, Yoshua},
	journal = {arXiv preprint arXiv:1412.2007},
	title = {On using very large target vocabulary for neural machine translation},
	year = {2014}}

@book{bishop1995neural,
	author = {Bishop, Christopher M},
	publisher = {Oxford university press},
	title = {Neural Networks for Pattern Recognition},
	year = {1995}}

@inproceedings{joulin2017efficient,
	author = {Joulin, Armand and Ciss{\'e}, Moustapha and Grangier, David and J{\'e}gou, Herv{\'e} and others},
	booktitle = icml,
	pages = {1302--1310},
	title = {Efficient softmax approximation for GPUs},
	year = {2017}}

@techreport{41880,
	author = {Ciprian Chelba and Tomas Mikolov and Mike Schuster and Qi Ge and Thorsten Brants and Phillipp Koehn and Tony Robinson},
	institution = {Google},
	title = {One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling},
	url = {http://arxiv.org/abs/1312.3005},
	year = {2013},
	Bdsk-Url-1 = {http://arxiv.org/abs/1312.3005}}

@article{mahoney2011large,
	author = {Mahoney, Matt},
	title = {Large text compression benchmark},
	url = {http://www. mattmahoney. net/text/text. html},
	year = {2011},
	Bdsk-Url-1 = {http://www.%20mattmahoney.%20net/text/text.%20html}}

@inproceedings{kanai2017preventing,
	author = {Kanai, Sekitoshi and Fujiwara, Yasuhiro and Iwamura, Sotetsu},
	booktitle = nips,
	pages = {435--444},
	title = {Preventing gradient explosions in gated recurrent units},
	year = {2017}}

@inproceedings{sedghi2018the,
	author = {Hanie Sedghi and Vineet Gupta and Philip M. Long},
	booktitle = iclr,
	title = {The Singular Values of Convolutional Layers},
	year = {2019}}

@inproceedings{tsuzuku2018structural,
	author = {Tsuzuku, Yusuke and Sato, Issei},
	booktitle = cvpr,
	pages = {51--60},
	title = {On the Structural Sensitivity of Deep Convolutional Networks to the Directions of Fourier Basis Functions},
	year = {2019}}

@inproceedings{alexnet,
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	booktitle = nips,
	pages = {1097--1105},
	title = {Imagenet classification with deep convolutional neural networks},
	year = {2012}}

@inproceedings{vaswani2017attention,
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
	booktitle = nips,
	pages = {5998--6008},
	title = {Attention is all you need},
	year = {2017}}

@book{Jain1989,
	author = {Jain, Anil K.},
	publisher = {Prentice-Hall},
	title = {Fundamentals of Digital Image Processing},
	year = {1989}}

@article{hinton2012deep,
	author = {Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Kingsbury, Brian and others},
	journal = {IEEE Signal processing magazine},
	title = {Deep neural networks for acoustic modeling in speech recognition},
	volume = {29},
	year = {2012}}

@inproceedings{resnext,
	author = {Xie, Saining and Girshick, Ross and Doll{\'a}r, Piotr and Tu, Zhuowen and He, Kaiming},
	booktitle = cvpr,
	pages = {1492--1500},
	title = {Aggregated residual transformations for deep neural networks},
	year = {2017}}

@article{miyato2018spectral,
	author = {Miyato, Takeru and Kataoka, Toshiki and Koyama, Masanori and Yoshida, Yuichi},
	journal = iclr,
	title = {Spectral normalization for generative adversarial networks},
	year = {2018}}

@article{yoshida2017spectral,
	author = {Yoshida, Yuichi and Miyato, Takeru},
	journal = {arXiv preprint arXiv:1705.10941},
	title = {Spectral norm regularization for improving the generalizability of deep learning},
	year = {2017}}

@article{lecun1989backpropagation,
	author = {LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},
	journal = {Neural computation},
	number = {4},
	pages = {541--551},
	publisher = {MIT Press},
	title = {Backpropagation applied to handwritten zip code recognition},
	volume = {1},
	year = {1989}}

@article{yuan2019adversarial,
	author = {Yuan, Xiaoyong and He, Pan and Zhu, Qile and Li, Xiaolin},
	journal = {IEEE transactions on neural networks and learning systems},
	publisher = {IEEE},
	title = {Adversarial examples: Attacks and defenses for deep learning},
	year = {2019}}

@article{papernot2016transferability,
	author = {Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian},
	journal = {arXiv preprint arXiv:1605.07277},
	title = {Transferability in machine learning: from phenomena to black-box attacks using adversarial samples},
	year = {2016}}

@inproceedings{chen2017zoo,
	author = {Chen, Pin-Yu and Zhang, Huan and Sharma, Yash and Yi, Jinfeng and Hsieh, Cho-Jui},
	booktitle = {Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security},
	organization = {ACM},
	pages = {15--26},
	title = {Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models},
	year = {2017}}

@article{fgsm,
	author = {Goodfellow, Ian and Shlens, Jonathon and Szegedy, Christian},
	journal = {arXiv preprint arXiv:1412.6572},
	title = {Explaining and harnessing adversarial examples},
	year = {2014}}

@article{szegedy2013intriguing,
	author = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
	journal = {arXiv preprint arXiv:1312.6199},
	title = {Intriguing properties of neural networks},
	year = {2013}}

@inproceedings{pgd2,
	author = {Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
	booktitle = iclr,
	title = {Towards deep learning models resistant to adversarial attacks},
	year = {2018}}

@article{pgd,
	author = {Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
	journal = {arXiv preprint arXiv:1611.01236},
	title = {Adversarial machine learning at scale},
	year = {2016}}

@inproceedings{deepfool,
	author = {Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal},
	booktitle = cvpr,
	pages = {2574--2582},
	title = {Deepfool: a simple and accurate method to fool deep neural networks},
	year = {2016}}

@inproceedings{candw,
	author = {Carlini, Nicholas and Wagner, David},
	booktitle = {2017 IEEE Symposium on Security and Privacy (SP)},
	organization = {IEEE},
	pages = {39--57},
	title = {Towards evaluating the robustness of neural networks},
	year = {2017}}

@inproceedings{dcgan,
	author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
	booktitle = iclr,
	title = {Unsupervised representation learning with deep convolutional generative adversarial networks},
	year = {2016}}

@inproceedings{parseval,
	author = {Cisse, Moustapha and Bojanowski, Piotr and Grave, Edouard and Dauphin, Yann and Usunier, Nicolas},
	booktitle = icml,
	pages = {854--863},
	title = {Parseval networks: Improving robustness to adversarial examples},
	year = {2017}}

@inproceedings{distillation,
	author = {Papernot, Nicolas and McDaniel, Patrick and Wu, Xi and Jha, Somesh and Swami, Ananthram},
	booktitle = {2016 IEEE Symposium on Security and Privacy (SP)},
	organization = {IEEE},
	pages = {582--597},
	title = {Distillation as a defense to adversarial perturbations against deep neural networks},
	year = {2016}}

@article{SAP,
	author = {Dhillon, Guneet S and Azizzadenesheli, Kamyar and Lipton, Zachary C and Bernstein, Jeremy and Kossaifi, Jean and Khanna, Aran and Anandkumar, Anima},
	journal = iclr,
	title = {Stochastic activation pruning for robust adversarial defense},
	year = {2018}}

@inproceedings{best,
	author = {Athalye, Anish and Carlini, Nicholas and Wagner, David},
	booktitle = icml,
	pages = {274--283},
	title = {Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples},
	year = {2018}}

@inproceedings{papernot2017practical,
	author = {Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z Berkay and Swami, Ananthram},
	booktitle = {Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security},
	organization = {ACM},
	pages = {506--519},
	title = {Practical black-box attacks against machine learning},
	year = {2017}}

@inproceedings{lmt,
	author = {Tsuzuku, Yusuke and Sato, Issei and Sugiyama, Masashi},
	booktitle = nips,
	pages = {6542--6551},
	title = {Lipschitz-margin training: Scalable certification of perturbation invariance for deep neural networks},
	year = {2018}}

@article{ding2018advertorch,
	author = {Ding, Gavin Weiguang and Wang, Luyu and Jin, Xiaomeng},
	journal = {arXiv preprint arXiv:1902.07623},
	title = {{AdverTorch} v0.1: An Adversarial Robustness Toolbox based on PyTorch},
	year = {2019}}

@article{karner2003spectral,
	author = {Karner, Herbert and Schneid, Josef and Ueberhuber, Christoph W},
	journal = {Linear Algebra and Its Applications},
	pages = {301--311},
	publisher = {Elsevier},
	title = {Spectral decomposition of real circulant matrices},
	volume = {367},
	year = {2003}}

@article{proximal,
	author = {Parikh, Neal and Boyd, Stephen and others},
	journal = {Foundations and Trends{\textregistered} in Optimization},
	number = {3},
	pages = {127--239},
	publisher = {Now Publishers, Inc.},
	title = {Proximal algorithms},
	volume = {1},
	year = {2014}}

@inproceedings{brendel2018decisionbased,
	author = {Brendel, Wieland and Rauber, Jonas and Bethge, Matthias},
	booktitle = iclr,
	title = {Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models},
	year = {2018}}

@article{Boundary,
	author = {Chen, Jianbo and Jordan, Michael I},
	journal = {arXiv preprint arXiv:1904.02144},
	title = {Boundary Attack++: Query-Efficient Decision-Based Adversarial Attack},
	year = {2019}}

@inproceedings{lyu2015unified,
	author = {Lyu, Chunchuan and Huang, Kaizhu and Liang, Hai-Ning},
	booktitle = icdm,
	organization = {IEEE},
	pages = {301--309},
	title = {A unified gradient regularization family for adversarial examples},
	year = {2015}}

@inproceedings{ross2018improving,
	author = {Ross, Andrew Slavin and Doshi-Velez, Finale},
	booktitle = AAAI,
	title = {Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients},
	year = {2018}}

@inproceedings{moosavi2017universal,
	author = {Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Fawzi, Omar and Frossard, Pascal},
	booktitle = cvpr,
	pages = {1765--1773},
	title = {Universal adversarial perturbations},
	year = {2017}}

@inproceedings{pmlr-v80-ilyas18a,
	author = {Ilyas, Andrew and Engstrom, Logan and Athalye, Anish and Lin, Jessy},
	booktitle = icml,
	pages = {2137--2146},
	title = {Black-box Adversarial Attacks with Limited Queries and Information},
	year = {2018}}

@inproceedings{wen2016learning,
	author = {Wen, Wei and Wu, Chunpeng and Wang, Yandan and Chen, Yiran and Li, Hai},
	booktitle = nips,
	pages = {2074--2082},
	title = {Learning structured sparsity in deep neural networks},
	year = {2016}}

@inproceedings{NIPS2016_6504,
	author = {Wen, Wei and Wu, Chunpeng and Wang, Yandan and Chen, Yiran and Li, Hai},
	booktitle = nips,
	pages = {2074--2082},
	title = {Learning Structured Sparsity in Deep Neural Networks},
	year = {2016}}

@article{mnist,
	author = {LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick and others},
	journal = {Proceedings of the IEEE},
	number = {11},
	pages = {2278--2324},
	title = {Gradient-based learning applied to document recognition},
	volume = {86},
	year = {1998}}

@article{fmnist,
	author = {Han Xiao and Kashif Rasul and Roland Vollgraf},
	journal = {arXiv preprint arXiv:1708.07747},
	title = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},
	year = {2017}}

@techreport{cifar,
	author = {Krizhevsky, Alex and Hinton, Geoffrey},
	title = {Learning multiple layers of features from tiny images},
	year = {2009}}

@inproceedings{svhn,
	author = {Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
	booktitle = {NIPS Workshop on Deep Learning and Unsupervised Feature Learning},
	title = {Reading digits in natural images with unsupervised feature learning},
	year = {2011}}

@article{gouk2018regularisation,
	author = {Gouk, Henry and Frank, Eibe and Pfahringer, Bernhard and Cree, Michael},
	journal = {arXiv preprint arXiv:1804.04368},
	title = {Regularisation of neural networks by enforcing lipschitz continuity},
	year = {2018}}

@inproceedings{li2015accelerated,
	author = {Li, Huan and Lin, Zhouchen},
	booktitle = nips,
	pages = {379--387},
	title = {Accelerated proximal gradient methods for nonconvex programming},
	year = {2015}}

@inproceedings{schluter2018zero,
	author = {Schl{\"u}ter, Jan and Lehner, Bernhard},
	booktitle = {Proceedings of the 19th International Society for Music Information Retrieval Conference, Paris, France},
	pages = {23--27},
	title = {Zero-mean convolutions for level-invariant singing voice detection},
	year = {2018}}

@inproceedings{lin2019zero,
	author = {Lin, Kin Wah Edward and Goto, Masataka},
	booktitle = icassp,
	pages = {251--255},
	title = {Zero-mean Convolutional Network with Data Augmentation for Sound Level Invariant Singing Voice Separation},
	year = {2019}}

@inproceedings{Fp,
	author = {Yin, Dong and Gontijo Lopes, Raphael and Shlens, Jon and Cubuk, Ekin Dogus and Gilmer, Justin},
	booktitle = nips,
	pages = {13255--13265},
	title = {A Fourier Perspective on Model Robustness in Computer Vision},
	year = {2019}}

@article{lopes2019improving,
	author = {Lopes, Raphael Gontijo and Yin, Dong and Poole, Ben and Gilmer, Justin and Cubuk, Ekin D},
	journal = {arXiv preprint arXiv:1906.02611},
	title = {Improving Robustness Without Sacrificing Accuracy with Patch Gaussian Augmentation},
	year = {2019}}

@article{jo2017measuring,
	author = {Jo, Jason and Bengio, Yoshua},
	journal = {arXiv preprint arXiv:1711.11561},
	title = {Measuring the tendency of CNNs to learn surface statistical regularities},
	year = {2017}}

@article{highF,
	author = {Wang, Haohan and Wu, Xindi and Yin, Pengcheng and Xing, Eric P},
	journal = {arXiv preprint arXiv:1905.13545},
	title = {High Frequency Component Helps Explain the Generalization of Convolutional Neural Networks},
	year = {2019}}

@inproceedings{das2018shield,
	author = {Das, Nilaksh and Shanbhogue, Madhuri and Chen, Shang-Tse and Hohman, Fred and Li, Siwei and Chen, Li and Kounavis, Michael E and Chau, Duen Horng},
	booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
	organization = {ACM},
	pages = {196--204},
	title = {Shield: Fast, practical defense and vaccination for deep learning using jpeg compression},
	year = {2018}}

@inproceedings{liu2019feature,
	author = {Liu, Zihao and Liu, Qi and Liu, Tao and Xu, Nuo and Lin, Xue and Wang, Yanzhi and Wen, Wujie},
	booktitle = cvpr,
	pages = {860--868},
	title = {Feature Distillation: DNN-Oriented JPEG Compression Against Adversarial Examples},
	year = {2019}}

@inproceedings{densenet,
	author = {Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
	booktitle = cvpr,
	pages = {4700--4708},
	title = {Densely connected convolutional networks},
	year = {2017}}

@inproceedings{googlenet,
	author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	booktitle = cvpr,
	pages = {1--9},
	title = {Going deeper with convolutions},
	year = {2015}}

@inproceedings{LabelSmo,
	author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
	booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages = {2818--2826},
	title = {Rethinking the inception architecture for computer vision},
	year = {2016}}

@article{LogitSq,
	author = {Kannan, Harini and Kurakin, Alexey and Goodfellow, Ian},
	journal = {arXiv preprint arXiv:1803.06373},
	title = {Adversarial logit pairing},
	year = {2018}}

@article{imagenet,
	author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
	journal = {International journal of computer vision},
	number = {3},
	pages = {211--252},
	publisher = {Springer},
	title = {Imagenet large scale visual recognition challenge},
	volume = {115},
	year = {2015}}

@article{shafahi2019,
	author = {Shafahi, Ali and Ghiasi, Amin and Huang, Furong and Goldstein, Tom},
	journal = {arXiv preprint arXiv:1910.11585},
	title = {Label Smoothing and Logit Squeezing: A Replacement for Adversarial Training?},
	year = {2019}}

@article{summers2019improved,
	author = {Summers, Cecilia and Dinneen, Michael J},
	journal = {arXiv preprint arXiv:1906.03749},
	title = {Improved Adversarial Robustness via Logit Regularization Methods},
	year = {2019}}

@article{warde201611,
	author = {Warde-Farley, David and Goodfellow, Ian},
	journal = {Perturbations, Optimization, and Statistics},
	publisher = {MIT Press},
	title = {11 adversarial perturbations of deep neural networks},
	volume = {311},
	year = {2016}}

@inproceedings{MMC,
	author = {Tianyu Pang and Kun Xu and Yinpeng Dong and Chao Du and Ning Chen and Jun Zhu},
	booktitle = iclr,
	title = {Rethinking Softmax Cross-Entropy Loss for Adversarial Robustness},
	year = {2020}}

@article{engstrom2018evaluating,
	author = {Engstrom, Logan and Ilyas, Andrew and Athalye, Anish},
	journal = {arXiv preprint arXiv:1807.10272},
	title = {Evaluating and understanding the robustness of adversarial logit pairing},
	year = {2018}}

@article{mosbach2018logit,
	author = {Mosbach, Marius and Andriushchenko, Maksym and Trost, Thomas and Hein, Matthias and Klakow, Dietrich},
	journal = {arXiv preprint arXiv:1810.12042},
	title = {Logit pairing methods can fool gradient-based attacks},
	year = {2018}}

@inproceedings{TRADES,
	author = {Zhang, Hongyang and Yu, Yaodong and Jiao, Jiantao and Xing, Eric and Ghaoui, Laurent El and Jordan, Michael},
	booktitle = icml,
	pages = {7472--7482},
	publisher = {PMLR},
	title = {Theoretically Principled Trade-off between Robustness and Accuracy},
	volume = {97},
	year = {2019}}

@inproceedings{SPSA,
	author = {Uesato, Jonathan and O'Donoghue, Brendan and Kohli, Pushmeet and van den Oord, Aaron},
	booktitle = icml,
	pages = {5025--5034},
	publisher = {PMLR},
	title = {Adversarial Risk and the Dangers of Evaluating Against Weak Attacks},
	volume = {80},
	year = {2018}}

@article{carlini2019evaluating,
	author = {Carlini, Nicholas and Athalye, Anish and Papernot, Nicolas and Brendel, Wieland and Rauber, Jonas and Tsipras, Dimitris and Goodfellow, Ian and Madry, Aleksander and Kurakin, Alexey},
	journal = {arXiv preprint arXiv:1902.06705},
	title = {On evaluating adversarial robustness},
	year = {2019}}

@article{WRN,
	author = {Zagoruyko, Sergey and Komodakis, Nikos},
	journal = {arXiv preprint arXiv:1605.07146},
	title = {Wide residual networks},
	year = {2016}}

@inproceedings{carmon2019unlabeled,
	author = {Carmon, Yair and Raghunathan, Aditi and Schmidt, Ludwig and Duchi, John C and Liang, Percy S},
	booktitle = nips,
	pages = {11190--11201},
	title = {Unlabeled data improves adversarial robustness},
	year = {2019}}

@inproceedings{farnia2018generalizable,
	author = {Farzan Farnia and Jesse Zhang and David Tse},
	booktitle = iclr,
	title = {Generalizable Adversarial Training via Spectral Normalization},
	year = {2019}}

@incollection{NIPS2019_9319,
	author = {Fazlyab, Mahyar and Robey, Alexander and Hassani, Hamed and Morari, Manfred and Pappas, George},
	booktitle = nips,
	title = {Efficient and Accurate Estimation of Lipschitz Constants for Deep Neural Networks},
	year = {2019}}

@inproceedings{zhang2019you,
	author = {Zhang, Dinghuai and Zhang, Tianyuan and Lu, Yiping and Zhu, Zhanxing and Dong, Bin},
	booktitle = nips,
	pages = {227--238},
	title = {You only propagate once: Accelerating adversarial training via maximal principle},
	year = {2019}}

@inproceedings{shafahibatch,
	author = {Shafahi, Ali and Ghiasi, Amin and Najibi, Mahyar and Huang, Furong and Dickerson, John and Goldstein, Tom},
	booktitle = bmvc,
	title = {Batch-wise Logit-Similarity: Generalizing Logit-Squeezing and Label-Smoothing},
	year = {2019}}

@misc{ExCode,
	author = {Kuang, Liu},
	title = {pytorch-cifar},
	url = {https://github.com/kuangliu/pytorch-cifar},
	year = {2017},
	Bdsk-Url-1 = {https://github.com/kuangliu/pytorch-cifar}}

@inproceedings{SQUARE,
	author = {Andriushchenko, Maksym and Croce, Francesco and Flammarion, Nicolas and Hein, Matthias},
	booktitle = eccv,
	title = {Square attack: a query-efficient black-box adversarial attack via random search},
	year = {2020}}

@inproceedings{AutoAttack,
	author = {Croce, Francesco and Hein, Matthias},
	booktitle = icml,
	title = {Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks},
	year = {2020},
	}

@inproceedings{du2019gradient,
	author = {Du, Simon and Lee, Jason and Li, Haochuan and Wang, Liwei and Zhai, Xiyu},
	booktitle = ICML,
	pages = {1675--1685},
	title = {Gradient descent finds global minima of deep neural networks},
	year = {2019}}

@article{du2018gradient,
	author = {Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
	journal = {arXiv preprint arXiv:1810.02054},
	title = {Gradient descent provably optimizes over-parameterized neural networks},
	year = {2018}}

@inproceedings{absum,
	author = {Sekitoshi Kanai and Yasutoshi Ida and Yasuhiro Fujiwara and Masanori Yamada and Shuichi Adachi},
	booktitle = AAAI,
	pages = {4394--4403},
	title = {Absum: Simple Regularization Method for Reducing Structural Sensitivity of Convolutional Neural Networks},
	year = {2020}}

@inproceedings{mlloo,
	author = {Puyudi Yang and Jianbo Chen and Cho{-}Jui Hsieh and Jane{-}Ling Wang and Michael I. Jordan},
	booktitle = aaai,
	pages = {6639--6647},
	title = {{ML-LOO:} Detecting Adversarial Examples with Feature Attribution},
	year = {2020}}

@inproceedings{fisherdetct,
	author = {Chenxiao Zhao and P. Thomas Fletcher and Mixue Yu and Yaxin Peng and Guixu Zhang and Chaomin Shen},
	booktitle = aaai,
	pages = {5869--5876},
	title = {The Adversarial Attack and Detection under the Fisher Information Metric},
	year = {2019}}

@inproceedings{resistAA,
	author = {Partha Ghosh and Arpan Losalka and Michael J. Black},
	booktitle = aaai,
	pages = {541--548},
	title = {Resisting Adversarial Attacks Using Gaussian Mixture Variational Autoencoders},
	year = {2019}}

@inproceedings{liu2020loss,
	author = {Chen Liu and Mathieu Salzmann and Tao Lin and Ryota Tomioka and Sabine S{\"u}sstrunk},
	booktitle = nips,
	title = {On the Loss Landscape of Adversarial Training: Identifying Challenges and How to Overcome Them},
	year = {2020}}

@inproceedings{oldawp,
	author = {Dongxian Wu and Yisen Wang and TShu-Tao Xia},
	booktitle = nips,
	title = {Adversarial Weight Perturbation Improves Adversarial Training},
	url = {https://github.com/csdongxian/AWP},
	year = {2020},
	Bdsk-Url-1 = {https://github.com/csdongxian/AWP}}

@incollection{LLR,
	author = {Qin, Chongli and Martens, James and Gowal, Sven and Krishnan, Dilip and Dvijotham, Krishnamurthy and Fawzi, Alhussein and De, Soham and Stanforth, Robert and Kohli, Pushmeet},
	booktitle = nips,
	pages = {13847--13856},
	title = {Adversarial Robustness through Local Linearization},
	year = {2019}}

@misc{sun2020exploring,
	archiveprefix = {arXiv},
	author = {Xu Sun and Zhiyuan Zhang and Xuancheng Ren and Ruixuan Luo and Liangyou Li},
	eprint = {2006.05620},
	primaryclass = {cs.LG},
	title = {Exploring the Vulnerability of Deep Neural Networks: A Study of Parameter Corruption},
	year = {2020}}

@inproceedings{awp,
	author = {Dongxian Wu and Shu-tao Xia and Yisen Wang},
	booktitle = nips,
	title = {Adversarial Weight Perturbation Helps Robust Generalization},
	url = {https://github.com/csdongxian/AWP},
	year = {2020},
	Bdsk-Url-1 = {https://github.com/csdongxian/AWP}}

@inproceedings{keskar2016large,
	author = {Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
	booktitle = iclr,
	title = {On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima},
	year = {2017}}

@inproceedings{dinh2017sharp,
	author = {Dinh, Laurent and Pascanu, Razvan and Bengio, Samy and Bengio, Yoshua},
	booktitle = icml,
	pages = {1019--1028},
	title = {Sharp Minima Can Generalize For Deep Nets},
	year = {2017}}

@incollection{Explor,
	author = {Neyshabur, Behnam and Bhojanapalli, Srinadh and Mcallester, David and Srebro, Nati},
	booktitle = nips,
	pages = {5947--5956},
	title = {Exploring Generalization in Deep Learning},
	year = {2017}}

@article{sung2020s,
	author = {Sung, Wonyong and Choi, Iksoo and Park, Jinhwan and Choi, Seokhyun and Shin, Sungho},
	journal = {arXiv preprint arXiv:2009.02479},
	title = {S-SGD: Symmetrical Stochastic Gradient Descent with Weight Noise Injection for Reaching Flat Minima},
	year = {2020}}

@article{wu2019noisy,
	author = {Wu, Jingfeng and Hu, Wenqing and Xiong, Haoyi and Huan, Jun and Braverman, Vladimir and Zhu, Zhanxing},
	journal = {arXiv preprint arXiv:1906.07405},
	title = {On the Noisy Gradient Descent that Generalizes as SGD},
	year = {2019}}

@article{jastrzkebski2017three,
	author = {Jastrzebski, Stanislaw and Kenton, Zachary and Arpit, Devansh and Ballas, Nicolas and Fischer, Asja and Bengio, Yoshua and Storkey, Amos},
	journal = {arXiv preprint arXiv:1711.04623},
	title = {Three factors influencing minima in sgd},
	year = {2017}}

@inproceedings{SHAM,
	author = {Pierre Foret and Ariel Kleiner and Hossein Mobahi and Behnam Neyshabur},
	booktitle = iclr,
	title = {Sharpness-Aware Minimization for Efficiently Improving Generalization},
	year = {2021}}

@incollection{mcallester2003simplified,
	author = {McAllester, David},
	booktitle = {Learning theory and Kernel machines},
	pages = {203--215},
	publisher = {Springer},
	title = {Simplified PAC-Bayesian margin bounds},
	year = {2003}}

@inproceedings{MART,
	author = {Yisen Wang and Difan Zou and Jinfeng Yi and James Bailey and Xingjun Ma and Quanquan Gu},
	booktitle = iclr,
	title = {Improving Adversarial Robustness Requires Revisiting Misclassified Examples},
	year = {2020}
	}

@misc{gowal2020uncovering,
	archiveprefix = {arXiv},
	author = {Sven Gowal and Chongli Qin and Jonathan Uesato and Timothy Mann and Pushmeet Kohli},
	eprint = {2010.03593},
	primaryclass = {stat.ML},
	title = {Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples},
	year = {2020}}

@misc{raghunathan2019adversarial,
	archiveprefix = {arXiv},
	author = {Aditi Raghunathan and Sang Michael Xie and Fanny Yang and John C. Duchi and Percy Liang},
	eprint = {1906.06032},
	primaryclass = {cs.LG},
	title = {Adversarial Training Can Hurt Generalization},
	year = {2019}}

@incollection{unlabeled1,
	author = {Carmon, Yair and Raghunathan, Aditi and Schmidt, Ludwig and Duchi, John C and Liang, Percy S},
	booktitle = nips,
	title = {Unlabeled Data Improves Adversarial Robustness}}

@incollection{unlabeled2,
	author = {Alayrac, Jean-Baptiste and Uesato, Jonathan and Huang, Po-Sen and Fawzi, Alhussein and Stanforth, Robert and Kohli, Pushmeet},
	booktitle = nips,
	pages = {12214--12223},
	title = {Are Labels Required for Improving Adversarial Robustness?},
	year = {2019}}

@article{chaudhari2019entropy,
	author = {Chaudhari, Pratik and Choromanska, Anna and Soatto, Stefano and LeCun, Yann and Baldassi, Carlo and Borgs, Christian and Chayes, Jennifer and Sagun, Levent and Zecchina, Riccardo},
	journal = {Journal of Statistical Mechanics: Theory and Experiment},
	number = {12},
	pages = {124018},
	publisher = {IOP Publishing},
	title = {Entropy-sgd: Biasing gradient descent into wide valleys},
	url = {https://github.com/ucla-vision/entropy-sgd/tree/master/python},
	volume = {2019},
	year = {2019},
	Bdsk-Url-1 = {https://github.com/ucla-vision/entropy-sgd/tree/master/python}}

@inproceedings{dziugaite2018entropy,
	author = {Dziugaite, Gintare Karolina and Roy, Daniel},
	booktitle = icml,
	pages = {1377--1386},
	title = {Entropy-SGD optimizes the prior of a PAC-Bayes bound: Generalization properties of Entropy-SGD and data-dependent priors},
	year = {2018}}

@inproceedings{chaudhari2016entropy,
	author = {Chaudhari, Pratik and Choromanska, Anna and Soatto, Stefano and LeCun, Yann and Baldassi, Carlo and Borgs, Christian and Chayes, Jennifer and Sagun, Levent and Zecchina, Riccardo},
	booktitle = iclr,
	title = {Entropy-SGD: Biasing Gradient Descent Into Wide Valleys},
	year = {2017}}

@book{watanabe,
	author = {},
	publisher = {},
	title = {},
	year = {2012}}

@inproceedings{VisW,
	author = {Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
	booktitle = nips,
	pages = {6389--6399},
	title = {Visualizing the Loss Landscape of Neural Nets},
	volume = {31},
	year = {2018}}

@inproceedings{Wang2020Improving,
	author = {Yisen Wang and Difan Zou and Jinfeng Yi and James Bailey and Xingjun Ma and Quanquan Gu},
	booktitle = iclr,
	title = {Improving Adversarial Robustness Requires Revisiting Misclassified Examples},
	year = {2020}}

@inproceedings{cohen2019certified,
	author = {Cohen, Jeremy and Rosenfeld, Elan and Kolter, Zico},
	booktitle = icml,
	pages = {1310--1320},
	title = {Certified Adversarial Robustness via Randomized Smoothing},
	year = {2019}}

@book{NLProgram,
	author = {Bertsekas, Dimitri P},
	edition = {2nd},
	publisher = {Athena Scientific},
	title = {Nonlinear programming},
	year = {1999}}

@article{YamadaFlat,
	author = {Yamada, Masanori and Kanai, Sekitoshi and Iwata, Tomoharu and Takahashi, Tomokatsu and Yamanka, Yuki and Takahashi, Hiroshi and Kumagai, Atsutoshi},
	journal = {arXiv preprint arXiv},
	title = {Adversarial Training Makes Weight Loss Landscape Sharper in Logistic Regression},
	year = {2021}}

@inproceedings{pmlr-v119-sankararaman20a,
	author = {Sankararaman, Karthik Abinav and De, Soham and Xu, Zheng and Huang, W. Ronny and Goldstein, Tom},
	booktitle = icml,
	editor = {Hal Daum{\'e} III and Aarti Singh},
	month = {13--18 Jul},
	pages = {8469--8479},
	publisher = {PMLR},
	series = {Proceedings of Machine Learning Research},
	title = {The Impact of Neural Network Overparameterization on Gradient Confusion and Stochastic Gradient Descent},
	volume = {119},
	year = {2020}}

@article{zhou2020regret,
	author = {Zhou, Yihan and Sanches Portella, Victor and Schmidt, Mark and Harvey, Nicholas},
	journal = nips,
	title = {Regret Bounds without Lipschitz Continuity: Online Learning with Relative-Lipschitz Losses},
	volume = {33},
	year = {2020}}

@inproceedings{hardt2016train,
	author = {Hardt, Moritz and Recht, Ben and Singer, Yoram},
	booktitle = icml,
	organization = {PMLR},
	pages = {1225--1234},
	title = {Train faster, generalize better: Stability of stochastic gradient descent},
	year = {2016}
	}

@article{zhang2021flatness,
  title={Why Flatness Correlates With Generalization For Deep Neural Networks},
  author={Zhang, Shuofeng and Reid, Isaac and P{\'e}rez, Guillermo Valle and Louis, Ard},
  journal={arXiv preprint arXiv:2103.06219},
  year={2021}
}

@Misc{scipy,
  author =    {Eric Jones and Travis Oliphant and Pearu Peterson and others},
  title =     {SciPy: Open source scientific tools for Python},
  year =      {2001}
  }

@inproceedings{kim2020understanding,
  title={Understanding Catastrophic Overfitting in Single-step Adversarial Training},
  author={Kim, Hoki and Lee, Woojin and Lee, Jaewook},
  booktitle=aaai,
  year={2021}
}

@article{keskar2017improving,
  title={Improving generalization performance by switching from adam to sgd},
  author={Keskar, Nitish Shirish and Socher, Richard},
  journal={arXiv preprint arXiv:1712.07628},
  year={2017}
}

@article{ghadimi2013stochastic,
  title={Stochastic first-and zeroth-order methods for nonconvex stochastic programming},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={SIAM Journal on Optimization},
  volume={23},
  number={4},
  pages={2341--2368},
  year={2013},
  publisher={SIAM}
}

@inproceedings{hu2009accelerated,
  title={Accelerated gradient methods for stochastic optimization and online learning},
  author={Hu, Chonghai and Kwok, James Tin-Yau and Pan, Weike},
  booktitle=nips,
  year={2009}
}

@InProceedings{pmlr-v28-shamir13,
  title = 	 {Stochastic Gradient Descent for Non-smooth Optimization: Convergence Results and Optimal Averaging Schemes},
  author = 	 {Shamir, Ohad and Zhang, Tong},
  booktitle = 	 icml,
  pages = 	 {71--79},
  year = 	 {2013},
  editor = 	 {Dasgupta, Sanjoy and McAllester, David},
  volume = 	 {28},
  number =       {1},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR}
}

@article{umap,
  title={Umap: Uniform manifold approximation and projection for dimension reduction},
  author={McInnes, Leland and Healy, John and Melville, James},
  journal={arXiv preprint arXiv:1802.03426},
  year={2018}
}

@InProceedings{zhang2019gradient,
  title={Why gradient clipping accelerates training: A theoretical justification for adaptivity},
  author={Zhang, Jingzhao and He, Tianxing and Sra, Suvrit and Jadbabaie, Ali},
  booktitle=iclr,
  year={2020}
}

@InProceedings{mai2021stability,
  title={Stability and Convergence of Stochastic Gradient Clipping: Beyond Lipschitz Continuity and Smoothness},
  author={Mai, Vien V and Johansson, Mikael},
  booktitle=icml,
  year={2021}
}

@inproceedings{GAIRAT,
title={Geometry-aware Instance-reweighted Adversarial Training},
author={Jingfeng Zhang and Jianing Zhu and Gang Niu and Bo Han and Masashi Sugiyama and Mohan Kankanhalli},
booktitle=iclr,
year={2021}
}

@inproceedings{gurbuzbalaban2021heavy,
  title={The heavy-tail phenomenon in sgd},
  author={Gurbuzbalaban, Mert and Simsekli, Umut and Zhu, Lingjiong},
  booktitle=icml,
  pages={3964--3975},
  year={2021},
  organization={PMLR}
}

@inproceedings{daskalakis2021complexity,
  title={The complexity of constrained min-max optimization},
  author={Daskalakis, Constantinos and Skoulakis, Stratis and Zampetakis, Manolis},
  booktitle={Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing},
  pages={1466--1478},
  year={2021}
}
@inproceedings{Menon2020Can,
title={Can gradient clipping mitigate label noise?},
author={Aditya Krishna Menon and Ankit Singh Rawat and Sashank J. Reddi and Sanjiv Kumar},
booktitle=iclr,
year={2020}
}

@inproceedings{NEURIPS2020_b282d173,
 author = {Zhang, Bohang and Jin, Jikai and Fang, Cong and Wang, Liwei},
 booktitle = nips,
 pages = {15511--15521},
 publisher = {Curran Associates, Inc.},
 title = {Improved Analysis of Clipping Algorithms for Non-convex Optimization},
 volume = {33},
 year = {2020}
}

@inproceedings{sanyal2021how,
title={How Benign is Benign Overfitting?},
author={Amartya Sanyal and Puneet K. Dokania and Varun Kanade and Philip Torr},
booktitle=iclr,
year={2021}
}


@inproceedings{dong2022exploring,
title={Exploring Memorization in Adversarial Training},
author={Yinpeng Dong and Ke Xu and Xiao Yang and Tianyu Pang and Zhijie Deng and Hang Su and Jun Zhu},
booktitle= iclr,
year={2022}
}

@article{xu2021towards,
  title={Towards the Memorization Effect of Neural Networks in Adversarial Training},
  author={Xu, Han and Liu, Xiaorui and Wang, Wentao and Ding, Wenbiao and Wu, Zhongqin and Liu, Zitao and Jain, Anil and Tang, Jiliang},
  journal={arXiv preprint arXiv:2106.04794},
  year={2021}
}

@inproceedings{arpit2017closer,
  title={A closer look at memorization in deep networks},
  author={Arpit, Devansh and Jastrz{\k{e}}bski, Stanis{\l}aw and Ballas, Nicolas and Krueger, David and Bengio, Emmanuel and Kanwal, Maxinder S and Maharaj, Tegan and Fischer, Asja and Courville, Aaron and Bengio, Yoshua and others},
  booktitle=icml,
  pages={233--242},
  year={2017},
  organization={PMLR}
}

@article{zhang2017understanding,
  title={Understanding deep learning requires rethinking generalization.},
  author={Zhang, C and Bengio, S and Hardt, M and Recht, B and Vinyals, O},
  journal=iclr,
  year={2017}
}

@inproceedings{Li2020Implicit,
title={Implicit Bias of Gradient Descent based Adversarial Training on Separable Data},
author={Yan Li and Ethan X.Fang and Huan Xu and Tuo Zhao},
booktitle=iclr,
year={2020}
}

@inproceedings{MMA,
title={MMA Training: Direct Input Space Margin Maximization through Adversarial Training},
author={Gavin Weiguang Ding and Yash Sharma and Kry Yik Chau Lui and Ruitong Huang},
booktitle=iclr,
year={2020}
}
@inproceedings{SEAT,
title={Self-ensemble Adversarial Training for Improved Robustness},
author={Hongjun Wang and Yisen Wang},
booktitle=iclr,
year={2022}
}

@article{SAForMC,
  title={Statistical analysis of some multi-category large margin classification methods},
  author={Zhang, Tong},
  journal={Journal of Machine Learning Research},
  volume={5},
  number={Oct},
  pages={1225--1251},
  year={2004}
}
@article{bartlett2003convexity,
  title={Convexity, Classification, and Risk Bounds},
  author={Bartlett, Peter L and Jordan, Michael I and McAuliffe, Jon D},
  jornal={Technical Report 638},
  year={2003}
}

@article{lin2002support,
  title={Support vector machines and the Bayes rule in classification},
  author={Lin, Yi},
  journal={Data Mining and Knowledge Discovery},
  volume={6},
  number={3},
  pages={259--275},
  year={2002},
  publisher={Springer}
}

@article{MAIL,
  title={Probabilistic margins for instance reweighting in adversarial training},
  author={Liu, Feng and Han, Bo and Liu, Tongliang and Gong, Chen and Niu, Gang and Zhou, Mingyuan and Sugiyama, Masashi and others},
  journal=nips,
  volume={34},
  year={2021}
}

@article{FAT,
  title = 	 {Attacks Which Do Not Kill Training Make Adversarial Learning Stronger},
  author =       {Zhang, Jingfeng and Xu, Xilie and Han, Bo and Niu, Gang and Cui, Lizhen and Sugiyama, Masashi and Kankanhalli, Mohan},
  booktitle = icml,
  pages = 	 {11278--11287},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  year = 	 {2020}
}

@article{kanai2021smoothness,
  title={Smoothness Analysis of Adversarial Training},
  author={Kanai, Sekitoshi and Yamada, Masanori and Takahashi, Hiroshi and Yamanaka, Yuki and Ida, Yasutoshi},
  journal={arXiv preprint arXiv:2103.01400},
  year={2021}
}


@InProceedings{pmlr-v139-zhang21b,
  title = 	 {Towards Certifying L-infinity Robustness using Neural Networks with L-inf-dist Neurons},
  author =       {Zhang, Bohang and Cai, Tianle and Lu, Zhou and He, Di and Wang, Liwei},
  booktitle = 	 icml,
  pages = 	 {12368--12379},
  volume = 	 {139},
  year = 	 {2021}
  }

@article{huang2021training,
  title={Training Certifiably Robust Neural Networks with Efficient Local Lipschitz Bounds},
  author={Huang, Yujia and Zhang, Huan and Shi, Yuanyuan and Kolter, J Zico and Anandkumar, Anima},
  journal=nips,
  volume={34},
  year={2021}
}

@inproceedings{FAB,
  title={Minimally distorted adversarial examples with a fast adaptive boundary attack},
  author={Croce, Francesco and Hein, Matthias},
  booktitle=icml,
  pages={2196--2205},
  year={2020}
}

@article{schmidt2018adversarially,
  title={Adversarially robust generalization requires more data},
  author={Schmidt, Ludwig and Santurkar, Shibani and Tsipras, Dimitris and Talwar, Kunal and Madry, Aleksander},
  journal=nips,
  volume={31},
  year={2018}
}

@inproceedings{DDPMwithAT,
 author = {Rebuffi, Sylvestre-Alvise and Gowal, Sven and Calian, Dan Andrei and Stimberg, Florian and Wiles, Olivia and Mann, Timothy A},
 booktitle =nips,
 pages = {29935--29948},
 title = {Data Augmentation Can Improve Robustness},
 volume = {34},
 year = {2021}
}

@article{rst,
  title={Unlabeled data improves adversarial robustness},
  author={Carmon, Yair and Raghunathan, Aditi and Schmidt, Ludwig and Duchi, John C and Liang, Percy S},
  journal=nips,
  volume={32},
  year={2019}
}

@inproceedings{tsipras2018robustness,
  title={Robustness May Be at Odds with Accuracy},
  author={Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Madry, Aleksander},
  booktitle=iclr,
  year={2018}
}

@article{jordan2020exactly,
  title={Exactly computing the local lipschitz constant of relu networks},
  author={Jordan, Matt and Dimakis, Alexandros G},
  journal=nips,
  volume={33},
  pages={7344--7353},
  year={2020}
}

@inproceedings{EWAT,
title={Entropy Weighted Adversarial Training},
author={Minseon Kim and Jihoon Tack and Jinwoo Shin and Sung Ju Hwang},
booktitle={ICML 2021 Workshop on Adversarial Machine Learning},
year={2021}
}

@article{hitaj2021evaluating,
  title={Evaluating the robustness of geometry-aware instance-reweighted adversarial training},
  author={Hitaj, Dorjan and Pagnotta, Giulio and Masi, Iacopo and Mancini, Luigi V},
  journal={arXiv preprint arXiv:2103.01914},
  year={2021}
}

@inproceedings{sriramanan2021towards,
title={Towards Efficient and Effective Adversarial Training},
author={Gaurang Sriramanan and Sravanti Addepalli and Arya Baburaj and Venkatesh Babu Radhakrishnan},
booktitle=nips,
year={2021}
}

@inproceedings{rade2022reducing,
title={Reducing Excessive Margin to Achieve a Better Accuracy vs. Robustness Trade-off},
author={Rahul Rade and Seyed-Mohsen Moosavi-Dezfooli},
booktitle=iclr,
year={2022}
}

@inproceedings{schmidt2018,
title={Adversarially robust generalization requires more data},
author={Schmidt, Ludwig and Santurkar, Shibani and Tsipras, Dimitris and Talwar, Kunal and Madry, Aleksander},
booktitle=nips,
year={2018}
}

@book{mohri2012foundations,
  title={Foundations of Machine Learning},
  author={Mohri, M. and Rostamizadeh, A. and Talwalkar, A.},
  isbn={9780262018258},
  lccn={2012007249},
  series={Adaptive Computation and Machine Learning series},
  year={2012},
  publisher={MIT Press}
}

@article{Wfunction1,
  title={On the LambertW function},
  author={Corless, Robert M and Gonnet, Gaston H and Hare, David EG and Jeffrey, David J and Knuth, Donald E},
  journal={Advances in Computational mathematics},
  volume={5},
  number={1},
  pages={329--359},
  year={1996},
  publisher={Springer}
}
@article{wfunction2,
  title={Approximation of the Lambert W function and hyperpower function},
  author={Hoorfar, Abdolhossein and Hassani, Mehdi},
  journal={Research report collection},
  volume={10},
  number={2},
  year={2007},
  publisher={School of Communications and Informatics, Faculty of Engineering and Science~}
}

@inproceedings{kunin2020neural,
  title={Neural Mechanics: Symmetry and Broken Conservation Laws in Deep Learning Dynamics},
  author={Kunin, Daniel and Sagastuy-Brena, Javier and Ganguli, Surya and Yamins, Daniel LK and Tanaka, Hidenori},
  booktitle=iclr,
  year={2021}
}
@inproceedings{
lampinen2018an,
title={An analytic theory of generalization dynamics and transfer learning in deep linear networks},
author={Andrew K. Lampinen and Surya Ganguli},
booktitle=iclr,
year={2019}
}

@article{elkabetz2021continuous,
  title={Continuous vs. discrete optimization of deep neural networks},
  author={Elkabetz, Omer and Cohen, Nadav},
  journal=nips,
  volume={34},
  pages={4947--4960},
  year={2021}
}

@inproceedings{padhy2020revisiting,
  title={Revisiting one-vs-all classifiers for predictive uncertainty and out-of-distribution detection in neural networks},
  author={Padhy, Shreyas and Nado, Zachary and Ren, Jie and Liu, Jeremiah and Snoek, Jasper and Lakshminarayanan, Balaji},
  booktitle={ICML Workshop on Uncertainty and Robustness in Deep Learning},
  year={2020}
}

@article{rebuffi2021fixing,
  title={Fixing Data Augmentation to Improve Adversarial Robustness},
  author={Rebuffi, Sylvestre-Alvise and Gowal, Sven and Calian, Dan A. and Stimberg, Florian and Wiles, Olivia and Mann, Timothy},
  journal={arXiv preprint arXiv:2103.01946},
  year={2021},
  url={https://arxiv.org/pdf/2103.01946}
}

@misc{rade2021pytorch,
    title = {{PyTorch} Implementation of Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples},
    author = {Rade, Rahul},
    year = {2021},
    url = {https://github.com/imrahulr/adversarial_robustness_pytorch}
}

@inproceedings{saito2021ovanet,
  title={Ovanet: One-vs-all network for universal domain adaptation},
  author={Saito, Kuniaki and Saenko, Kate},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9000--9009},
  year={2021}
}

@article{gowal2021generated,
  title={Improving Robustness using Generated Data},
  author={Gowal, Sven and Rebuffi, Sylvestre-Alvise and Wiles, Olivia and Stimberg, Florian and Calian, Dan A. and Mann, Timothy},
  journal={arXiv preprint arXiv:2110.09468},
  year={2021},
  url={https://arxiv.org/pdf/2110.09468}
}