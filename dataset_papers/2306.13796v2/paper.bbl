\begin{thebibliography}{10}

\bibitem{abiteboul95foundation}
S.~Abiteboul, R.~Hull, and V.~Vianu.
\newblock {\em {Foundations of Databases}}.
\newblock Addison Wesley, 1995.

\bibitem{baget-decidability}
Jean-Fran\c{c}ois Baget, Marie-Laure Mugnier, Sebastian Rudolph, and Micha\"{e}l Thomazo.
\newblock Walking the complexity lines for generalized guarded existential rules.
\newblock page 712–717, 2011.

\bibitem{SPO-bounds}
Othman~El Balghiti, Adam~N. Elmachtoub, Paul Grigas, and Ambuj Tewari.
\newblock Generalization bounds in the predict-then-optimize framework.
\newblock In {\em NeurIPS}, pages 14389--14398, 2019.

\bibitem{Rademacher}
Peter~L. Bartlett and Shahar Mendelson.
\newblock Rademacher and gaussian complexities: Risk bounds and structural results.
\newblock {\em The Journal of Machine Learning Research}, 3:463–482, 2003.

\bibitem{structured-prediction-pll}
Vivien Cabannes, Alessandro Rudi, and Francis Bach.
\newblock Structured prediction with partial labelling through the infimum loss.
\newblock In {\em ICML}, page 1230–1239, 2020.

\bibitem{CCM}
Ming-Wei Chang, Lev Ratinov, and Dan Roth.
\newblock Structured learning with constrained conditional models.
\newblock {\em Machine Learning}, 88(3):399–431, 2012.

\bibitem{CHAVIRA2008772}
Mark Chavira and Adnan Darwiche.
\newblock On probabilistic inference by weighted model counting.
\newblock {\em Artificial Intelligence}, 172(6):772 -- 799, 2008.

\bibitem{proper-losses-pll}
Jes{\'{u}}s Cid{-}Sueiro.
\newblock Proper losses for learning from partial labels.
\newblock In {\em NeurIPS}, pages 1574--1582, 2012.

\bibitem{proper-losses-pll-pkdd}
Jes{\'u}s Cid-Sueiro, Dar{\'i}o Garc{\'i}a-Garc{\'i}a, and Ra{\'u}l Santos-Rodr{\'i}guez.
\newblock Consistency of losses for learning from weak labels.
\newblock In {\em ECML PKDD}, pages 197--210, 2014.

\bibitem{CKMY16-factor-graph-complexity}
Corinna Cortes, Vitaly Kuznetsov, Mehryar Mohri, and Scott Yang.
\newblock {Structured Prediction Theory Based on Factor Graph Complexity}.
\newblock In {\em NeurIPS}, 2016.

\bibitem{cour2011}
Timothee Cour, Ben Sapp, and Ben Taskar.
\newblock Learning from partial labels.
\newblock {\em Journal of Machine Learning Research}, 12:1501–1536, 2011.

\bibitem{meta-abd}
Wang-Zhou Dai and Stephen Muggleton.
\newblock Abductive knowledge induction from raw data.
\newblock In Zhi-Hua Zhou, editor, {\em IJCAI}, pages 1845--1851. AAAI, 2021.

\bibitem{ABL}
Wang-Zhou Dai, Qiuling Xu, Yang Yu, and Zhi-Hua Zhou.
\newblock {Bridging Machine Learning and Logical Reasoning by Abductive Learning}.
\newblock In {\em NeurIPS}, pages 2815--2826, 2019.

\bibitem{DBLP:books/daglib/0007534}
Artur~S. d'Avila Garcez, Krysia Broda, and Dov~M. Gabbay.
\newblock {\em Neural-symbolic learning systems: foundations and applications}.
\newblock Perspectives in neural computing. Springer, 2002.

\bibitem{SPO}
Adam~N. Elmachtoub and Paul Grigas.
\newblock Smart "predict, then optimize".
\newblock {\em CoRR}, abs/1710.08005, 2017.

\bibitem{diffilp}
Richard Evans and Edward Grefenstette.
\newblock Learning explanatory rules from noisy data.
\newblock {\em Journal of Artificial Intelligence Research}, 61(1):1–64, 2018.

\bibitem{intractability-of-01-loss}
Vitaly Feldman, Venkatesan Guruswami, Prasad Raghavendra, and Yi~Wu.
\newblock Agnostic learning of monomials by halfspaces is hard.
\newblock {\em SIAM Journal on Computing}, 41(6):1558--1590, 2012.

\bibitem{feldstein2023principled}
Jonathan Feldstein, Dominic Phillips, and Efthymia Tsamoura.
\newblock Principled and efficient motif finding for structure learning of lifted graphical models.
\newblock {\em CoRR}, abs/2302.04599, 2023.

\bibitem{mipaal}
Aaron~M. Ferber, Bryan Wilder, Bistra Dilkina, and Milind Tambe.
\newblock Mipaal: Mixed integer program as a layer.
\newblock {\em CoRR}, abs/1907.05912, 2019.

\bibitem{d-tree}
Robert Fink, Jiewen Huang, and Dan Olteanu.
\newblock Anytime approximation in probabilistic databases.
\newblock {\em {VLDB} Journal}, 22(6):823--848, 2013.

\bibitem{posterior}
Kuzman Ganchev, Jo\~{a}o Gra\c{c}a, Jennifer Gillenwater, and Ben Taskar.
\newblock Posterior regularization for structured latent variable models.
\newblock {\em Journal of Machine Learning Research}, 11:2001–2049, 2010.

\bibitem{paired-examples}
Nitish Gupta, Sameer Singh, Matt Gardner, and Dan Roth.
\newblock Paired examples as indirect supervision in latent decision models.
\newblock In {\em EMNLP}, pages 5774--5785, 2021.

\bibitem{hu-etal-2016-harnessing}
Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard Hovy, and Eric Xing.
\newblock Harnessing deep neural networks with logic rules.
\newblock In {\em ACL}, pages 2410--2420, 2016.

\bibitem{scallop}
Jiani Huang, Ziyang Li, Binghong Chen, Karan Samel, Mayur Naik, Le~Song, and Xujie Si.
\newblock Scallop: From probabilistic deductive databases to scalable differentiable reasoning.
\newblock In {\em NeurIPS}, pages 25134--25145, 2021.

\bibitem{EM-PLL}
Rong Jin and Zoubin Ghahramani.
\newblock Learning with multiple labels.
\newblock In {\em NeurIPS}, pages 897--904, 2002.

\bibitem{Kakas2017}
Antonis~C. Kakas.
\newblock Abduction.
\newblock In Claude Sammut and Geoffrey~I. Webb, editors, {\em Encyclopedia of Machine Learning and Data Mining}, pages 1--8. Springer US, Boston, MA, 2017.

\bibitem{iclr2023}
Zenan Li, Yuan Yao, Taolue Chen, Jingwei Xu, Chun Cao, Xiaoxing Ma, and Jian Lu.
\newblock Softened symbol grounding for neurosymbolic systems.
\newblock In {\em ICLR}, 2023.

\bibitem{learnability-pll}
Li-Ping Liu and Thomas~G. Dietterich.
\newblock Learnability of the superset label learning problem.
\newblock In {\em ICML}, pages 1629–--1637, 2014.

\bibitem{progressive-pll}
Jiaqi Lv, Miao Xu, Lei Feng, Gang Niu, Xin Geng, and Masashi Sugiyama.
\newblock Progressive identification of true labels for partial-label learning.
\newblock In {\em ICML}, page 6500–6510, 2020.

\bibitem{DBLP:journals/corr/abs-1907-08194}
Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, and Luc De~Raedt.
\newblock Deepproblog: Neural probabilistic logic programming.
\newblock In {\em NeurIPS}, pages 3749--3759, 2018.

\bibitem{deepproblog-approx}
Robin Manhaeve, Giuseppe Marra, and Luc De~Raedt.
\newblock {Approximate Inference for Neural Probabilistic Logic Programming}.
\newblock In {\em {KR}}, pages 475--486, 2021.

\bibitem{spigot2}
Tsvetomila Mihaylova, Vlad Niculae, and Andr{\'e} F.~T. Martins.
\newblock Understanding the mechanics of {SPIGOT}: Surrogate gradients for latent structure learning.
\newblock In {\em EMNLP}, pages 2186--2202, 2020.

\bibitem{mohri2018foundations}
M.~Mohri, A.~Rostamizadeh, and A.~Talwalkar.
\newblock {\em Foundations of Machine Learning, second edition}.
\newblock Adaptive Computation and Machine Learning series. MIT Press, 2018.

\bibitem{comboptnet}
Anselm Paulus, Michal Rolínek, Vít Musil, Brandon Amos, and Georg Martius.
\newblock Comboptnet: Fit the right np-hard problem by learning integer programming constraints, 2021.

\bibitem{spigot1}
Hao Peng, Sam Thomson, and Noah~A. Smith.
\newblock Backpropagating through structured argmax using a {SPIGOT}.
\newblock In {\em ACL}, pages 1863--1873, 2018.

\bibitem{pmlr-v48-raghunathan16}
Aditi Raghunathan, Roy Frostig, John Duchi, and Percy Liang.
\newblock Estimation from indirect supervision with linear moments.
\newblock In {\em ICML}, volume~48, pages 2568--2577, 2016.

\bibitem{roth2007global}
Dan Roth and Wen-tau Yih.
\newblock {\em Global Inference for Entity and Relation Identification via a Linear Programming Formulation}.
\newblock MIT Press, {Introduction to Statistical Relational Learning} edition, 2007.

\bibitem{UEM}
Rajhans Samdani, Ming-Wei Chang, and Dan Roth.
\newblock Unified expectation maximization.
\newblock In {\em ACL}, pages 688--698, 2012.

\bibitem{Sen_Carvalho_Riegel_Gray_2022}
Prithviraj Sen, Breno W. S. R.~de Carvalho, Ryan Riegel, and Alexander Gray.
\newblock Neuro-symbolic inductive logic programming with logical neural networks.
\newblock {\em AAAI}, 36(8):8212--8219, 2022.

\bibitem{deep-naive-pll}
Junghoon Seo and Joon~Suk Huh.
\newblock On the power of deep but naive partial label learning.
\newblock In {\em ICASSP}, pages 3820--3824, 2021.

\bibitem{understanding-ml}
Shai Shalev-Shwartz and Shai Ben-David.
\newblock {\em Understanding Machine Learning: From Theory to Algorithms}.
\newblock Cambridge University Press, USA, 2014.

\bibitem{ijcai2023p226}
Mate Soos, Divesh Aggarwal, Sourav Chakraborty, Kuldeep~S. Meel, and Maciej Obremski.
\newblock Engineering an efficient approximate dnf-counter.
\newblock In {\em IJCAI}, pages 2031--2038, 2023.

\bibitem{relaxed-supervision}
Jacob Steinhardt and Percy~S Liang.
\newblock Learning with relaxed supervision.
\newblock In {\em NeurIPS}, volume~28, 2015.

\bibitem{neurolog}
Efthymia Tsamoura, Timothy Hospedales, and Loizos Michael.
\newblock Neural-symbolic integration: A compositional perspective.
\newblock In {\em AAAI}, pages 5051--5060, 2021.

\bibitem{ltgs}
Efthymia Tsamoura, Jaehun Lee, and Jacopo Urbani.
\newblock Probabilistic reasoning at scale: Trigger graphs to the rescue.
\newblock {\em Proceedings of the ACM on Management of Data}, 1(1), 2023.

\bibitem{word-problem1}
Shyam Upadhyay, Ming-Wei Chang, Kai-Wei Chang, and Wen-tau Yih.
\newblock Learning from explicit and implicit supervision jointly for algebra word problems.
\newblock In {\em EMNLP}, pages 297--306, 2016.

\bibitem{JMLR:corrupted-learning}
Brendan van Rooyen and Robert~C. Williamson.
\newblock A theory of learning with corrupted labels.
\newblock {\em Journal of Machine Learning Research}, 18(228):1--50, 2018.

\bibitem{DBLP:journals/corr/abs-1912-02175}
Marin Vlastelica, Anselm Paulus, V{\'{\i}}t Musil, Georg Martius, and Michal Rol{\'{\i}}nek.
\newblock Differentiation of blackbox combinatorial solvers.
\newblock {\em CoRR}, abs/1912.02175, 2019.

\bibitem{PCO}
Haoyu~Peter Wang, Nan Wu, Hang Yang, Cong Hao, and Pan Li.
\newblock Unsupervised learning for combinatorial optimization with principled objective relaxation.
\newblock In S.~Koyejo, S.~Mohamed, A.~Agarwal, D.~Belgrave, K.~Cho, and A.~Oh, editors, {\em NeurIPS}, volume~35, pages 31444--31458, 2022.

\bibitem{kaifu-icml}
Kaifu Wang, Hangfeng He, Tin~D. Nguyen, Piyush Kumar, and Dan Roth.
\newblock On regularization and inference with label constraints.
\newblock In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, {\em Proceedings of the 40th International Conference on Machine Learning}, volume 202 of {\em Proceedings of Machine Learning Research}, pages 35740--35762. PMLR, 23--29 Jul 2023.

\bibitem{kaifu}
Kaifu Wang, Qiang Ning, and Dan Roth.
\newblock Learnability with indirect supervision signals.
\newblock In {\em NeurIPS}, volume~33, pages 9145--9155, 2020.

\bibitem{word-problem2}
Lei Wang, Dongxiang Zhang, Jipeng Zhang, Xing Xu, Lianli Gao, Bing~Tian Dai, and Heng~Tao Shen.
\newblock Template-based math word problem solvers with recursive neural networks.
\newblock In {\em AAAI}, pages 7144--7151, 2019.

\bibitem{wang2019satNet}
Po{-}Wei Wang, Priya~L. Donti, Bryan Wilder, and J.~Zico Kolter.
\newblock Satnet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver.
\newblock In {\em ICML}, 2019.

\bibitem{weighthed-loss-pll}
Hongwei Wen, Jingyi Cui, Hanyuan Hang, Jiabin Liu, Yisen Wang, and Zhouchen Lin.
\newblock Leveraged weighted loss for partial label learning.
\newblock {\em CoRR}, abs/2106.05731, 2021.

\bibitem{latent-sp-survey}
Zhaofeng Wu.
\newblock Learning with latent structures in natural language processing: A survey.
\newblock {\em arXiv preprint arXiv:2201.00490}, 2022.

\bibitem{pmlr-v80-xu18h}
Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, and Guy Van~den Broeck.
\newblock A semantic loss function for deep learning with symbolic knowledge.
\newblock In {\em ICML}, pages 5502--5511, 2018.

\bibitem{instance-dependent-pll}
Ning Xu, Congyu Qiao, Xin Geng, and Min-Ling Zhang.
\newblock Instance-dependent partial label learning.
\newblock In {\em NeurIPS}, volume~34, pages 27119--27130, 2021.

\bibitem{top-k-loss-consistency}
Forest Yang and Sanmi Koyejo.
\newblock On the consistency of top-k surrogate losses.
\newblock In {\em ICML}, volume 119, pages 10727--10735, 2020.

\bibitem{neurasp}
Zhun Yang, Adam Ishay, and Joohyung Lee.
\newblock {NeurASP}: Embracing neural networks into answer set programming.
\newblock In {\em {IJCAI}}, pages 1755--1762, 2020.

\bibitem{noisy-pll}
Peilin Yu, Tiffany Ding, and Stephen~H. Bach.
\newblock Learning from multiple noisy partial labelers.
\newblock In {\em PMLR}, volume 151, pages 11072--11095, 2022.

\bibitem{noisy-multiclass-learning}
Mingyuan Zhang, Jane Lee, and Shivani Agarwal.
\newblock Learning from noisy labels with no change to the training process.
\newblock In {\em ICML}, volume 139 of {\em Proceedings of Machine Learning Research}, pages 12468--12478, 2021.

\bibitem{Aggregate-observations}
Yivan Zhang, Nontawat Charoenphakdee, Zheng Wu, and Masashi Sugiyama.
\newblock Learning from aggregate observations.
\newblock {\em ArXiv}, abs/2004.06316, 2020.

\end{thebibliography}
