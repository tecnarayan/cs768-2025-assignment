@article{srinivas2019full,
  title={Full-gradient representation for neural network visualization},
  author={Srinivas, Suraj and Fleuret, Fran{\c{c}}ois},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{smilkov2017smoothgrad,
  title={Smoothgrad: removing noise by adding noise},
  author={Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
  journal={arXiv preprint arXiv:1706.03825},
  year={2017}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@article{baehrens2010explain,
  title={How to explain individual classification decisions},
  author={Baehrens, David and Schroeter, Timon and Harmeling, Stefan and Kawanabe, Motoaki and Hansen, Katja and M{\"u}ller, Klaus-Robert},
  journal={The Journal of Machine Learning Research},
  volume={11},
  pages={1803--1831},
  year={2010},
  publisher={JMLR. org}
}

@article{rudin2019stop,
  title={Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
  author={Rudin, Cynthia},
  journal={Nature machine intelligence},
  volume={1},
  number={5},
  pages={206--215},
  year={2019},
  publisher={Nature Publishing Group UK London}
}

@article{hooker2019benchmark,
  title={A benchmark for interpretability methods in deep neural networks},
  author={Hooker, Sara and Erhan, Dumitru and Kindermans, Pieter-Jan and Kim, Been},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{adebayo2018sanity,
  title={Sanity checks for saliency maps},
  author={Adebayo, Julius and Gilmer, Justin and Muelly, Michael and Goodfellow, Ian and Hardt, Moritz and Kim, Been},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{liu2018large,
  title={Large-scale celebfaces attributes (celeba) dataset},
  author={Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
  journal={Retrieved August},
  volume={15},
  number={2018},
  pages={11},
  year={2018}
}

@inproceedings{jethani2021have,
  title={Have We Learned to Explain?: How Interpretability Methods Can Learn to Encode Predictions in their Interpretations.},
  author={Jethani, Neil and Sudarshan, Mukund and Aphinyanaphongs, Yindalon and Ranganath, Rajesh},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1459--1467},
  year={2021},
  organization={PMLR}
}

@article{heo2019fooling,
  title={Fooling neural network interpretations via adversarial model manipulation},
  author={Heo, Juyeon and Joo, Sunghwan and Moon, Taesup},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{chen2019looks,
  title={This looks like that: deep learning for interpretable image recognition},
  author={Chen, Chaofan and Li, Oscar and Tao, Daniel and Barnett, Alina and Rudin, Cynthia and Su, Jonathan K},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{koh2020concept,
  title={Concept bottleneck models},
  author={Koh, Pang Wei and Nguyen, Thao and Tang, Yew Siang and Mussmann, Stephen and Pierson, Emma and Kim, Been and Liang, Percy},
  booktitle={International Conference on Machine Learning},
  pages={5338--5348},
  year={2020},
  organization={PMLR}
}

@incollection{hastie2017generalized,
  title={Generalized additive models},
  author={Hastie, Trevor J},
  booktitle={Statistical models in S},
  pages={249--307},
  year={2017},
  publisher={Routledge}
}

@inproceedings{chen2018learning,
  title={Learning to explain: An information-theoretic perspective on model interpretation},
  author={Chen, Jianbo and Song, Le and Wainwright, Martin and Jordan, Michael},
  booktitle={International Conference on Machine Learning},
  pages={883--892},
  year={2018},
  organization={PMLR}
}

@inproceedings{yoon2019invase,
  title={INVASE: Instance-wise variable selection using neural networks},
  author={Yoon, Jinsung and Jordon, James and van der Schaar, Mihaela},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@incollection{lundberg2017shap,
title = {A Unified Approach to Interpreting Model Predictions},
author = {Lundberg, Scott M and Lee, Su-In},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {4765--4774},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf}
}

@inproceedings{ribeiro2016should,
  title={" Why should i trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}

@article{han2022explanation,
  title={Which explanation should i choose? a function approximation perspective to characterizing post hoc explanations},
  author={Han, Tessa and Srinivas, Suraj and Lakkaraju, Himabindu},
  journal={arXiv preprint arXiv:2206.01254},
  year={2022}
}

@article{krishna2022disagreement,
  title={The disagreement problem in explainable machine learning: A practitioner's perspective},
  author={Krishna, Satyapriya and Han, Tessa and Gu, Alex and Pombra, Javin and Jabbari, Shahin and Wu, Steven and Lakkaraju, Himabindu},
  journal={arXiv preprint arXiv:2202.01602},
  year={2022}
}

@inproceedings{slack2020fooling,
  title={Fooling lime and shap: Adversarial attacks on post hoc explanation methods},
  author={Slack, Dylan and Hilgard, Sophie and Jia, Emily and Singh, Sameer and Lakkaraju, Himabindu},
  booktitle={Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
  pages={180--186},
  year={2020}
}

@inproceedings{lakkaraju2020fool,
  title={" How do I fool you?" Manipulating User Trust via Misleading Black Box Explanations},
  author={Lakkaraju, Himabindu and Bastani, Osbert},
  booktitle={Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
  pages={79--85},
  year={2020}
}

@inproceedings{bansal2020sam,
  title={Sam: The sensitivity of attribution methods to hyperparameters},
  author={Bansal, Naman and Agarwal, Chirag and Nguyen, Anh},
  booktitle={Proceedings of the ieee/cvf conference on computer vision and pattern recognition},
  pages={8673--8683},
  year={2020}
}

@article{samek2016evaluating,
  title={Evaluating the visualization of what a deep neural network has learned},
  author={Samek, Wojciech and Binder, Alexander and Montavon, Gr{\'e}goire and Lapuschkin, Sebastian and M{\"u}ller, Klaus-Robert},
  journal={IEEE transactions on neural networks and learning systems},
  volume={28},
  number={11},
  pages={2660--2673},
  year={2016},
  publisher={IEEE}
}

@inproceedings{fong2017interpretable,
  title={Interpretable explanations of black boxes by meaningful perturbation},
  author={Fong, Ruth C and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={3429--3437},
  year={2017}
}

@inproceedings{fong2019understanding,
  title={Understanding deep networks via extremal perturbations and smooth masks},
  author={Fong, Ruth and Patrick, Mandela and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={2950--2958},
  year={2019}
}

@article{dabkowski2017real,
  title={Real time image saliency for black box classifiers},
  author={Dabkowski, Piotr and Gal, Yarin},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{zeiler2014visualizing,
  title={Visualizing and understanding convolutional networks},
  author={Zeiler, Matthew D and Fergus, Rob},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part I 13},
  pages={818--833},
  year={2014},
  organization={Springer}
}

@article{agarwal2022openxai,
  title={Openxai: Towards a transparent evaluation of model explanations},
  author={Agarwal, Chirag and Krishna, Satyapriya and Saxena, Eshika and Pawelczyk, Martin and Johnson, Nari and Puri, Isha and Zitnik, Marinka and Lakkaraju, Himabindu},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={15784--15799},
  year={2022}
}

@article{kermany2018labeled,
  title={Labeled optical coherence tomography (oct) and chest x-ray images for classification},
  author={Kermany, Daniel and Zhang, Kang and Goldbaum, Michael and others},
  journal={Mendeley data},
  volume={2},
  number={2},
  pages={651},
  year={2018}
}

@article{JainK17,
  author = {Prateek Jain and Purushottam Kar},
  title = {Non-convex Optimization for Machine Learning},
  journal = {Foundations and TrendsÂ® in Machine Learning},
  year = {2017},
  volume = {10},
  url = {all_papers/JainK17_FTML.pdf}
}

@article{han2015learning,
  title={Learning both weights and connections for efficient neural network},
  author={Han, Song and Pool, Jeff and Tran, John and Dally, William},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{bohle2022b,
  title={B-cos networks: Alignment is all we need for interpretability},
  author={B{\"o}hle, Moritz and Fritz, Mario and Schiele, Bernt},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10329--10338},
  year={2022}
}

@inproceedings{
srinivas2021rethinking,
title={Rethinking the Role of Gradient-based Attribution Methods for Model Interpretability},
author={Suraj Srinivas and Francois Fleuret},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=dYeAHXnpWJ4}
}

@article{shah2021input,
  title={Do input gradients highlight discriminative features?},
  author={Shah, Harshay and Jain, Prateek and Netrapalli, Praneeth},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={2046--2059},
  year={2021}
}

@unpublished{aibillofrights,
    author = {The White House},
    title = {Blueprint for an AI Bill OF Rights},
    year={2022},
    url={https://www.whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf}
}

@unpublished{eugdpr,
    author = {The European Commission},
    title = {General Data Protection Regulation (GDPR)},
    year={2018},
    url={https://commission.europa.eu/law/law-topic/data-protection/reform/rules-business-and-organisations/principles-gdpr_en}
}