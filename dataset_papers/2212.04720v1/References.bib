@inproceedings{li2010contextual,
  title={A contextual-bandit approach to personalized news article recommendation},
  author={Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E},
  booktitle={Proceedings of the 19th international conference on World wide web},
  pages={661--670},
  year={2010}
}

@inproceedings{joachims2017unbiased,
  title={Unbiased learning-to-rank with biased feedback},
  author={Joachims, Thorsten and Swaminathan, Adith and Schnabel, Tobias},
  booktitle={Proceedings of the tenth ACM international conference on web search and data mining},
  pages={781--789},
  year={2017}
}

@article{bottou2013counterfactual,
  title={Counterfactual Reasoning and Learning Systems: The Example of Computational Advertising.},
  author={Bottou, L{\'e}on and Peters, Jonas and Qui{\~n}onero-Candela, Joaquin and Charles, Denis X and Chickering, D Max and Portugaly, Elon and Ray, Dipankar and Simard, Patrice and Snelson, Ed},
  journal={Journal of Machine Learning Research},
  volume={14},
  number={11},
  year={2013}
}

@inproceedings{swaminathan2015counterfactual,
  title={Counterfactual risk minimization: Learning from logged bandit feedback},
  author={Swaminathan, Adith and Joachims, Thorsten},
  booktitle={International Conference on Machine Learning},
  pages={814--823},
  year={2015},
  organization={PMLR}
}

@inproceedings{jeunen2021pessimistic,
  title={Pessimistic reward models for off-policy learning in recommendation},
  author={Jeunen, Olivier and Goethals, Bart},
  booktitle={Fifteenth ACM Conference on Recommender Systems},
  pages={63--74},
  year={2021}
}

@inproceedings{lazaric2010bayesian,
  title={Bayesian multi-task reinforcement learning},
  author={Lazaric, Alessandro and Ghavamzadeh, Mohammad},
  booktitle={ICML-27th International Conference on Machine Learning},
  pages={599--606},
  year={2010},
  organization={Omnipress}
}

@article{ laurent00adaptive,
  author = "B. Laurent and P. Massart",
  title = "Adaptive Estimation of a Quadratic Functional by Model Selection",
  journal = "The Annals of Statistics",
  volume = "28",
  number = "5",
  pages = "1302-1338",
  year = "2000"
}

@article{swaminathan2017off,
  title={Off-policy evaluation for slate recommendation},
  author={Swaminathan, Adith and Krishnamurthy, Akshay and Agarwal, Alekh and Dudik, Miro and Langford, John and Jose, Damien and Zitouni, Imed},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{jin2021pessimism,
  title={Is pessimism provably efficient for offline rl?},
  author={Jin, Ying and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={5084--5096},
  year={2021},
  organization={PMLR}
}

@article{buckman2020importance,
  title={The importance of pessimism in fixed-dataset policy optimization},
  author={Buckman, Jacob and Gelada, Carles and Bellemare, Marc G},
  journal={arXiv preprint arXiv:2009.06799},
  year={2020}
}

@article{auer2002using,
  title={Using confidence bounds for exploitation-exploration trade-offs},
  author={Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Nov},
  pages={397--422},
  year={2002}
}

@inproceedings{chu2011contextual,
  title={Contextual bandits with linear payoff functions},
  author={Chu, Wei and Li, Lihong and Reyzin, Lev and Schapire, Robert},
  booktitle={Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  pages={208--214},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{cief2022pessimistic,
  title={Pessimistic Off-Policy Optimization for Learning to Rank},
  author={Cief, Matej and Kveton, Branislav and Kompan, Michal},
  journal={arXiv preprint arXiv:2206.02593},
  year={2022}
}

@inproceedings{hong2022hierarchical,
  title={Hierarchical bayesian bandits},
  author={Hong, Joey and Kveton, Branislav and Zaheer, Manzil and Ghavamzadeh, Mohammad},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={7724--7741},
  year={2022},
  organization={PMLR}
}
