\begin{thebibliography}{10}

\bibitem{sobolev}
Robert~A. Adams and John J.~F. Fournier.
\newblock {\em Sobolev spaces}.
\newblock Pure and Applied Mathematics, v. 140. Academic Press, 2 edition,
  2003.

\bibitem{Albertini93uniquenessof}
Francesca Albertini, Eduardo~D. Sontag, and Vincent Maillot.
\newblock Uniqueness of weights for neural networks.
\newblock In {\em in Artificial Neural Networks with Applications in Speech and
  Vision}, pages 115--125. Chapman and Hall, 1993.

\bibitem{arora2018understanding}
Raman Arora, Amitabh Basu, Poorya Mianjy, and Anirbit Mukherjee.
\newblock Understanding deep neural networks with rectified linear units.
\newblock {\em Arxiv}, 2018.

\bibitem{bertinetto2016learning}
Luca Bertinetto, Jo{\~a}o~F Henriques, Jack Valmadre, Philip Torr, and Andrea
  Vedaldi.
\newblock Learning feed-forward one-shot learners.
\newblock In {\em Advances in Neural Information Processing Systems 29}. Curran
  Associates, Inc., 2016.

\bibitem{Borsuk1933}
Karol Borsuk.
\newblock Drei sätze über die n-dimensionale euklidische sphäre.
\newblock {\em Fundamenta Mathematicae}, 20(1):177--190, 1933.

\bibitem{brock2018smash}
Andrew Brock, Theo Lim, J.M. Ritchie, and Nick Weston.
\newblock {SMASH}: One-shot model architecture search through hypernetworks.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{chang2020principled}
Oscar Chang, Lampros Flokas, and Hod Lipson.
\newblock Principled weight initialization for hypernetworks.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{Chen_2019_CVPR}
Zhiqin Chen and Hao Zhang.
\newblock Learning implicit fields for generative shape modeling.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, 2019.

\bibitem{Cybenko1989}
George Cybenko.
\newblock Approximation by superpositions of a sigmoidal function.
\newblock {\em Mathematics of Control, Signals and Systems}, 2(4):303--314,
  1989.

\bibitem{devore}
Ronald~A. DeVore, Ralph Howard, and Charles Micchelli.
\newblock Optimal nonlinear approximation.
\newblock {\em Manuscripta Math}, 1989.

\bibitem{dodsonParker}
C.~T.~J. Dodson and P.~E. Parker.
\newblock {\em User's Guide to Algebraic Topology}, volume 387 of {\em
  Mathematics and Its Applications}.
\newblock Kluwer, Dordrecht, Boston, London, 1997.

\bibitem{fefferman}
Charles Fefferman and Scott Markel.
\newblock Recovering a feed-forward net from its output.
\newblock In {\em Advances in Neural Information Processing Systems 6}. Morgan
  Kaufmann Publishers Inc., 1993.

\bibitem{8953870}
Z.~{Feng}, C.~{Xu}, and D.~{Tao}.
\newblock Self-supervised representation learning by rotation feature
  decoupling.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, 2019.

\bibitem{garnelo2018conditional}
Marta Garnelo, Dan Rosenbaum, Christopher Maddison, Tiago Ramalho, David
  Saxton, Murray Shanahan, Yee~Whye Teh, Danilo Rezende, and S.~M.~Ali Eslami.
\newblock Conditional neural processes.
\newblock In {\em Proceedings of Machine Learning Research}, volume~80. PMLR,
  2018.

\bibitem{gidaris2018unsupervised}
Spyros Gidaris, Praveer Singh, and Nikos Komodakis.
\newblock Unsupervised representation learning by predicting image rotations.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{10.5555/3327546.3327644}
Izhak Golan and Ran El-Yaniv.
\newblock Deep anomaly detection using geometric transformations.
\newblock In {\em Advances in Neural Information Processing Systems 31}. Curran
  Associates Inc., 2018.

\bibitem{ha2016hypernetworks}
David Ha, Andrew~M. Dai, and Quoc~V. Le.
\newblock Hypernetworks.
\newblock In {\em International Conference on Learning Representations}, 2016.

\bibitem{hanin2017approximating}
Boris Hanin and Mark Sellke.
\newblock Approximating continuous functions by relu nets of minimal width.
\newblock {\em Arxiv}, 2018.

\bibitem{GlossarWiki:Hausdorff:1914}
Felix Hausdorff.
\newblock {\em {Grundzüge der Mengenlehre}}.
\newblock Veit and Company, Leipzig, 1914.
\newblock Das Hauptwerk von Felix Hausdorff.

\bibitem{10.1109/ICCV.2015.123}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Delving deep into rectifiers: Surpassing human-level performance on
  imagenet classification.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision (ICCV)}, ICCV ’15. IEEE Computer Society, 2015.

\bibitem{NIPS2019_9697}
Dan Hendrycks, Mantas Mazeika, Saurav Kadavath, and Dawn Song.
\newblock Using self-supervised learning can improve model robustness and
  uncertainty.
\newblock In {\em Advances in Neural Information Processing Systems 32}. Curran
  Associates, Inc., 2019.

\bibitem{Hornik1991ApproximationCO}
Kurt Hornik.
\newblock Approximation capabilities of multilayer feedforward networks.
\newblock {\em Neural Networks}, 4:251--257, 1991.

\bibitem{jayakumar2020multiplicative}
Siddhant~M. Jayakumar, Jacob Menick, Wojciech~M. Czarnecki, Jonathan Schwarz,
  Jack Rae, Simon Osindero, Yee~Whye Teh, Tim Harley, and Razvan Pascanu.
\newblock Multiplicative interactions and where to find them.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{karras2019style}
Tero Karras, Samuli Laine, and Timo Aila.
\newblock A style-based generator architecture for generative adversarial
  networks.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, 2019.

\bibitem{cifar}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem{krueger2017bayes}
David Krueger, Chin-Wei Huang, Riashat Islam, Ryan Turner, Alexandre Lacoste,
  and Aaron Courville.
\newblock Bayesian hypernetworks.
\newblock {\em arxiv}, 2017.

\bibitem{mnist}
Yann LeCun and Corinna Cortes.
\newblock {MNIST} handwritten digit database.
\newblock http://yann.lecun.com/exdb/mnist/, 2010.

\bibitem{10.5555/3327345.3327515}
Hongzhou Lin and Stefanie Jegelka.
\newblock Resnet with one-neuron hidden layers is a universal approximator.
\newblock In {\em Advances in Neural Information Processing Systems 31}. Curran
  Associates Inc., 2018.

\bibitem{Littwin_2019_ICCV}
Gidi Littwin and Lior Wolf.
\newblock Deep meta functionals for shape representation.
\newblock In {\em The IEEE International Conference on Computer Vision (ICCV)},
  2019.

\bibitem{lorraine2018stochastic}
Jonathan Lorraine and David Duvenaud.
\newblock Stochastic hyperparameter optimization through hypernetworks, 2018.

\bibitem{NIPS2017_7203}
Zhou Lu, Hongming Pu, Feicheng Wang, Zhiqiang Hu, and Liwei Wang.
\newblock The expressive power of neural networks: A view from the width.
\newblock In {\em Advances in Neural Information Processing Systems 30}. Curran
  Associates, Inc., 2017.

\bibitem{LyuShn47}
Lazar~A. Lyusternik and Lev~G. Shnirel'man.
\newblock Topological methods in variational problems and their application to
  the differential geometry of surfaces.
\newblock {\em Uspekhi Mat. Nauk}, 2:166--217, 1947.

\bibitem{10.1006/jath.1998.3304}
Vitaly Maiorov.
\newblock On best approximation by ridge functions.
\newblock {\em J. Approx. Theory}, 99(1), 1999.

\bibitem{10.1006/jath.1998.3305}
Vitaly Maiorov, Ron Meir, and Joel Ratsaby.
\newblock On the approximation of functional classes equipped with a uniform
  measure using ridge functions.
\newblock {\em J. Approx. Theory}, 99(1):95–111, 1999.

\bibitem{Maiorov99lowerbounds}
Vitaly Maiorov and Allan Pinkus.
\newblock Lower bounds for approximation by mlp neural networks.
\newblock {\em NEUROCOMPUTING}, 25:81--91, 1999.

\bibitem{Mescheder_2019_CVPR}
Lars Mescheder, Michael Oechsle, Michael Niemeyer, Sebastian Nowozin, and
  Andreas Geiger.
\newblock Occupancy networks: Learning 3d reconstruction in function space.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, 2019.

\bibitem{10.5555/3298483.3298577}
Hrushikesh Mhaskar, Qianli Liao, and Tomaso Poggio.
\newblock When and why are deep networks better than shallow ones?
\newblock In {\em Proceedings of the Thirty-First AAAI Conference on Artificial
  Intelligence}, page 2343–2349. AAAI Press, 2017.

\bibitem{Mhaskar:1996:NNO:1362203.1362213}
Hrushikesh~N. Mhaskar.
\newblock Neural networks for optimal approximation of smooth and analytic
  functions.
\newblock {\em Neural Comput.}, 8(1):164--177, 1996.

\bibitem{Park_2019_CVPR}
Jeong~Joon Park, Peter Florence, Julian Straub, Richard Newcombe, and Steven
  Lovegrove.
\newblock Deepsdf: Learning continuous signed distance functions for shape
  representation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, 2019.

\bibitem{Pinkus1985NWidthsIA}
Allan Pinkus.
\newblock {\em N-Widths in Approximation Theory}.
\newblock Springer-Verlag, 1985.

\bibitem{RockWets98}
{R. Tyrrell} Rockafellar and Roger J.-B. Wets.
\newblock {\em Variational Analysis}.
\newblock Springer Verlag, Heidelberg, Berlin, New York, 1998.

\bibitem{pmlr-v70-safran17a}
Itay Safran and Ohad Shamir.
\newblock Depth-width tradeoffs in approximating natural functions with neural
  networks.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning}, volume~70 of {\em Proceedings of Machine Learning Research}, pages
  2979--2987, International Convention Centre, Sydney, Australia, 2017. PMLR.

\bibitem{NIPS2010_3894}
Nathan Srebro, Karthik Sridharan, and Ambuj Tewari.
\newblock Smoothness, low noise and fast rates.
\newblock In {\em Advances in Neural Information Processing Systems 23}. Curran
  Associates, Inc., 2010.

\bibitem{Sussmann1992UniquenessOT}
H{\'e}ctor~J. Sussmann.
\newblock Uniqueness of the weights for minimal feedforward nets with a given
  input-output map.
\newblock {\em Neural Networks}, 5:589--593, 1992.

\bibitem{pmlr-v95-ukai18a}
Kenya Ukai, Takashi Matsubara, and Kuniaki Uehara.
\newblock Hypernetwork-based implicit posterior estimation and model averaging
  of cnn.
\newblock In {\em Proceedings of Machine Learning Research}, volume~95, pages
  176--191. PMLR, 2018.

\bibitem{vanwavenet}
A{\"a}ron van~den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol
  Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu.
\newblock Wavenet: A generative model for raw audio.
\newblock In {\em 9th ISCA Speech Synthesis Workshop}, pages 125--125, 2016.

\bibitem{nn-id-2019}
Verner Vlačić and Helmut Bölcskei.
\newblock Neural network identifiability for a family of sigmoidal
  nonlinearities.
\newblock {\em Constructive Approximation}, 2020.

\bibitem{Oswald2020Continual}
Johannes von Oswald, Christian Henning, João Sacramento, and Benjamin~F.
  Grewe.
\newblock Continual learning with hypernetworks.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{zhang2018graph}
Chris Zhang, Mengye Ren, and Raquel Urtasun.
\newblock Graph hypernetworks for neural architecture search.
\newblock In {\em International Conference on Learning Representations}, 2019.

\end{thebibliography}
