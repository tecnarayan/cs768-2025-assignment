\begin{thebibliography}{53}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2018)Agarwal, Beygelzimer, Dud{\'\i}k, Langford, and
  Wallach]{agarwal2018reductions}
Agarwal, A., Beygelzimer, A., Dud{\'\i}k, M., Langford, J., and Wallach, H.
\newblock A reductions approach to fair classification.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Barocas \& Selbst(2016)Barocas and Selbst]{barocas2016big}
Barocas, S. and Selbst, A.~D.
\newblock Big data's disparate impact.
\newblock \emph{California Law Review}, 2016.

\bibitem[Calmon et~al.(2017)Calmon, Wei, Vinzamuri, Ramamurthy, and
  Varshney]{calmon2017optimized}
Calmon, F.~P., Wei, D., Vinzamuri, B., Ramamurthy, K.~N., and Varshney, K.~R.
\newblock Optimized pre-processing for discrimination prevention.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Chen et~al.(2018)Chen, Johansson, and Sontag]{chen2018my}
Chen, I.~Y., Johansson, F.~D., and Sontag, D.
\newblock Why is my classifier discriminatory?
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Chhabra et~al.(2021)Chhabra, Singla, and Mohapatra]{chhabra2021fair}
Chhabra, A., Singla, A., and Mohapatra, P.
\newblock Fair clustering using antidote data.
\newblock \emph{arXiv preprint arXiv:2106.00600}, 2021.

\bibitem[Chouldechova(2017)]{chouldechova2017fair}
Chouldechova, A.
\newblock Fair prediction with disparate impact: A study of bias in recidivism
  prediction instruments.
\newblock \emph{Big Data}, 2017.

\bibitem[Christmann \& Steinwart(2004)Christmann and
  Steinwart]{christmann2004robustness}
Christmann, A. and Steinwart, I.
\newblock On robustness properties of convex risk minimization methods for
  pattern recognition.
\newblock \emph{Journal of Machine Learning Research}, 2004.

\bibitem[{Civil Rights Act}(1964)]{civil}
{Civil Rights Act}.
\newblock Civil rights act of 1964, title vii, equal employment opportunities.
\newblock 1964.

\bibitem[Cook(1977)]{cook1977detection}
Cook, R.~D.
\newblock Detection of influential observation in linear regression.
\newblock \emph{Technometrics}, 1977.

\bibitem[Cook \& Weisberg(1980)Cook and Weisberg]{cook1980characterizations}
Cook, R.~D. and Weisberg, S.
\newblock Characterizations of an empirical influence function for detecting
  influential cases in regression.
\newblock \emph{Technometrics}, 1980.

\bibitem[Cotter et~al.(2019)Cotter, Jiang, Gupta, Wang, Narayan, You, and
  Sridharan]{cotter2019optimization}
Cotter, A., Jiang, H., Gupta, M.~R., Wang, S., Narayan, T., You, S., and
  Sridharan, K.
\newblock Optimization with non-differentiable constraints with applications to
  fairness, recall, churn, and other goals.
\newblock \emph{Journal of Machine Learning Research}, 2019.

\bibitem[Dantzig(2016)]{dantzig2016linear}
Dantzig, G.
\newblock \emph{Linear programming and extensions}.
\newblock Princeton University Press, 2016.

\bibitem[Donini et~al.(2018)Donini, Oneto, Ben-David, Shawe-Taylor, and
  Pontil]{donini2018empirical}
Donini, M., Oneto, L., Ben-David, S., Shawe-Taylor, J., and Pontil, M.
\newblock Empirical risk minimization under fairness constraints.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Dua \& Graff(2017)Dua and Graff]{Dua:2019}
Dua, D. and Graff, C.
\newblock {UCI} machine learning repository, 2017.
\newblock URL \url{http://archive.ics.uci.edu/ml}.

\bibitem[Dutta et~al.(2020)Dutta, Wei, Yueksel, Chen, Liu, and
  Varshney]{dutta2020there}
Dutta, S., Wei, D., Yueksel, H., Chen, P.-Y., Liu, S., and Varshney, K.
\newblock Is there a trade-off between fairness and accuracy? a perspective
  using mismatched hypothesis testing.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Dwork et~al.(2012)Dwork, Hardt, Pitassi, Reingold, and
  Zemel]{dwork2012fairness}
Dwork, C., Hardt, M., Pitassi, T., Reingold, O., and Zemel, R.
\newblock Fairness through awareness.
\newblock In \emph{Innovations in Theoretical Computer Science Conference},
  2012.

\bibitem[Feldman et~al.(2015)Feldman, Friedler, Moeller, Scheidegger, and
  Venkatasubramanian]{feldman2015certifying}
Feldman, M., Friedler, S.~A., Moeller, J., Scheidegger, C., and
  Venkatasubramanian, S.
\newblock Certifying and removing disparate impact.
\newblock In \emph{ACM SIGKDD International Conference on Knowledge Discovery
  and Data Mining}, 2015.

\bibitem[Ferguson(2017)]{ferguson2017rise}
Ferguson, A.~G.
\newblock \emph{The rise of big data policing}.
\newblock New York University Press, 2017.

\bibitem[Giordano et~al.(2019)Giordano, Stephenson, Liu, Jordan, and
  Broderick]{giordano2019swiss}
Giordano, R., Stephenson, W., Liu, R., Jordan, M., and Broderick, T.
\newblock A swiss army infinitesimal jackknife.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2019.

\bibitem[Goh et~al.(2016)Goh, Cotter, Gupta, and
  Friedlander]{goh2016satisfying}
Goh, G., Cotter, A., Gupta, M., and Friedlander, M.~P.
\newblock Satisfying real-world goals with dataset constraints.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Goodman \& Flaxman(2017)Goodman and Flaxman]{goodman2017european}
Goodman, B. and Flaxman, S.
\newblock European union regulations on algorithmic decision-making and a
  “right to explanation”.
\newblock \emph{AI magazine}, 2017.

\bibitem[{Gurobi Optimization, LLC}(2021)]{gurobi}
{Gurobi Optimization, LLC}.
\newblock {Gurobi Optimizer Reference Manual}, 2021.
\newblock URL \url{https://www.gurobi.com}.

\bibitem[Hampel et~al.(2011)Hampel, Ronchetti, Rousseeuw, and
  Stahel]{hampel2011robust}
Hampel, F.~R., Ronchetti, E.~M., Rousseeuw, P.~J., and Stahel, W.~A.
\newblock \emph{Robust statistics: the approach based on influence functions}.
\newblock John Wiley \& Sons, 2011.

\bibitem[Hardt et~al.(2016)Hardt, Price, and Srebro]{hardt2016equality}
Hardt, M., Price, E., and Srebro, N.
\newblock Equality of opportunity in supervised learning.
\newblock \emph{Advances in neural information processing systems}, 2016.

\bibitem[Hofmann()]{german}
Hofmann, H.
\newblock Statlog (german credit data) data set.
\newblock
  \url{https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)}.

\bibitem[Jiang \& Nachum(2020)Jiang and Nachum]{jiang2020identifying}
Jiang, H. and Nachum, O.
\newblock Identifying and correcting label bias in machine learning.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2020.

\bibitem[Jiang et~al.(2020)Jiang, Pacchiano, Stepleton, Jiang, and
  Chiappa]{jiang2020wasserstein}
Jiang, R., Pacchiano, A., Stepleton, T., Jiang, H., and Chiappa, S.
\newblock Wasserstein fair classification.
\newblock In \emph{Uncertainty in Artificial Intelligence}, 2020.

\bibitem[Julia~Angwin \& Kirchner(2016)Julia~Angwin and Kirchner]{compas}
Julia~Angwin, Jeff~Larson, S.~M. and Kirchner, L.
\newblock Machine bias, 2016.

\bibitem[Kamiran \& Calders(2012)Kamiran and Calders]{kamiran2012data}
Kamiran, F. and Calders, T.
\newblock Data preprocessing techniques for classification without
  discrimination.
\newblock \emph{Knowledge and Information Systems}, 2012.

\bibitem[Kearns et~al.(2018)Kearns, Neel, Roth, and Wu]{kearns2018preventing}
Kearns, M., Neel, S., Roth, A., and Wu, Z.~S.
\newblock Preventing fairness gerrymandering: Auditing and learning for
  subgroup fairness.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Koh \& Liang(2017)Koh and Liang]{koh2017understanding}
Koh, P.~W. and Liang, P.
\newblock Understanding black-box predictions via influence functions.
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Koh et~al.(2019)Koh, Ang, Teo, and Liang]{koh2019accuracy}
Koh, P.~W., Ang, K.-S., Teo, H.~H., and Liang, P.
\newblock On the accuracy of influence functions for measuring group effects.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Kohavi \& Becker()Kohavi and Becker]{adult}
Kohavi, R. and Becker, B.
\newblock Adult data set.
\newblock \url{https://archive.ics.uci.edu/ml/datasets/adult}.

\bibitem[Krasanakis et~al.(2018)Krasanakis, Spyromitros-Xioufis, Papadopoulos,
  and Kompatsiaris]{krasanakis2018adaptive}
Krasanakis, E., Spyromitros-Xioufis, E., Papadopoulos, S., and Kompatsiaris, Y.
\newblock Adaptive sensitive reweighting to mitigate bias in fairness-aware
  classification.
\newblock In \emph{The World Wide Web Conference}, 2018.

\bibitem[Lahoti et~al.(2020)Lahoti, Beutel, Chen, Lee, Prost, Thain, Wang, and
  Chi]{lahoti2020fairness}
Lahoti, P., Beutel, A., Chen, J., Lee, K., Prost, F., Thain, N., Wang, X., and
  Chi, E.
\newblock Fairness without demographics through adversarially reweighted
  learning.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 728--740, 2020.

\bibitem[Li et~al.(2020)Li, Zhao, and Liu]{Li_2020_CVPR}
Li, P., Zhao, H., and Liu, H.
\newblock Deep fair clustering for visual learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, June 2020.

\bibitem[Li et~al.(2021)Li, Wang, Zhao, Hong, and Liu]{li2021on}
Li, P., Wang, Y., Zhao, H., Hong, P., and Liu, H.
\newblock On dyadic fairness: Exploring and mitigating bias in graph
  connections.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Liu et~al.(2014)Liu, Jiang, and Liao]{liu2014efficient}
Liu, Y., Jiang, S., and Liao, S.
\newblock Efficient approximation of cross-validation for kernel methods using
  bouligand influence function.
\newblock In \emph{International Conference on Machine Learning}, 2014.

\bibitem[Mehrabi et~al.(2021)Mehrabi, Morstatter, Saxena, Lerman, and
  Galstyan]{mehrabi2021survey}
Mehrabi, N., Morstatter, F., Saxena, N., Lerman, K., and Galstyan, A.
\newblock A survey on bias and fairness in machine learning.
\newblock \emph{ACM Computing Surveys}, 2021.

\bibitem[Menon \& Williamson(2018)Menon and Williamson]{menon2018cost}
Menon, A.~K. and Williamson, R.~C.
\newblock The cost of fairness in binary classification.
\newblock In \emph{Conference on Fairness, Accountability and Transparency},
  2018.

\bibitem[Pleiss et~al.(2017)Pleiss, Raghavan, Wu, Kleinberg, and
  Weinberger]{pleiss2017fairness}
Pleiss, G., Raghavan, M., Wu, F., Kleinberg, J., and Weinberger, K.~Q.
\newblock On fairness and calibration.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Rastegarpanah et~al.(2019)Rastegarpanah, Gummadi, and
  Crovella]{rastegarpanah2019fighting}
Rastegarpanah, B., Gummadi, K.~P., and Crovella, M.
\newblock Fighting fire with fire: Using antidote data to improve polarization
  and fairness of recommender systems.
\newblock In \emph{ACM International Conference on Web Search and Data Mining},
  2019.

\bibitem[Redmond \& Baveja(2002)Redmond and Baveja]{redmond2002data}
Redmond, M. and Baveja, A.
\newblock A data-driven software tool for enabling cooperative information
  sharing among police departments.
\newblock \emph{European Journal of Operational Research}, 2002.

\bibitem[Roth et~al.(2017)Roth, Lucchi, Nowozin, and
  Hofmann]{roth2017stabilizing}
Roth, K., Lucchi, A., Nowozin, S., and Hofmann, T.
\newblock Stabilizing training of generative adversarial networks through
  regularization.
\newblock \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Song et~al.(2021)Song, Li, and Liu]{10.1145/3447548.3467225}
Song, H., Li, P., and Liu, H.
\newblock Deep clustering based fair outlier detection.
\newblock In \emph{Proceedings of the 27th ACM SIGKDD Conference on Knowledge
  Discovery \& Data Mining}, 2021.

\bibitem[Wang et~al.(2019)Wang, Ustun, and Calmon]{wang2019repairing}
Wang, H., Ustun, B., and Calmon, F.
\newblock Repairing without retraining: Avoiding disparate impact with
  counterfactual distributions.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Woodworth et~al.(2017)Woodworth, Gunasekar, Ohannessian, and
  Srebro]{woodworth2017learning}
Woodworth, B., Gunasekar, S., Ohannessian, M.~I., and Srebro, N.
\newblock Learning non-discriminatory predictors.
\newblock In \emph{Conference on Learning Theory}, 2017.

\bibitem[Yan et~al.(2020)Yan, Kao, and Ferrara]{yan2020fair}
Yan, S., Kao, H.-t., and Ferrara, E.
\newblock Fair class balancing: enhancing model fairness without observing
  sensitive attributes.
\newblock In \emph{ACM International Conference on Information \& Knowledge
  Management}, 2020.

\bibitem[Zafar et~al.(2017)Zafar, Valera, Rogriguez, and
  Gummadi]{zafar2017fairness}
Zafar, M.~B., Valera, I., Rogriguez, M.~G., and Gummadi, K.~P.
\newblock Fairness constraints: Mechanisms for fair classification.
\newblock In \emph{Artificial Intelligence and Statistics}, 2017.

\bibitem[Zemel et~al.(2013)Zemel, Wu, Swersky, Pitassi, and
  Dwork]{zemel2013learning}
Zemel, R., Wu, Y., Swersky, K., Pitassi, T., and Dwork, C.
\newblock Learning fair representations.
\newblock In \emph{International Conference on Machine Learning}, 2013.

\bibitem[Zhang et~al.(2018)Zhang, Lemoine, and Mitchell]{zhang2018mitigating}
Zhang, B.~H., Lemoine, B., and Mitchell, M.
\newblock Mitigating unwanted biases with adversarial learning.
\newblock In \emph{The 2018 AAAI/ACM Conference on AI, Ethics, and Society},
  2018.

\bibitem[Zhao \& Gordon(2019)Zhao and Gordon]{zhao2019inherent}
Zhao, H. and Gordon, G.
\newblock Inherent tradeoffs in learning fair representations.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Zhao et~al.(2019)Zhao, Coston, Adel, and Gordon]{zhao2019conditional}
Zhao, H., Coston, A., Adel, T., and Gordon, G.~J.
\newblock Conditional learning of fair representations.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\end{thebibliography}
