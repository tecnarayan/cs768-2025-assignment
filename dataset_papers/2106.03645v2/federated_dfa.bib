@article{konnik2014high,
  title={High-level numerical simulations of noise in CCD and CMOS photosensors: review and tutorial},
  author={Konnik, Mikhail and Welsh, James},
  journal={arXiv preprint arXiv:1412.4031},
  year={2014}
}

@article{xiao2017fashion,
  title={Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms},
  author={Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  journal={arXiv preprint arXiv:1708.07747},
  year={2017}
}

@article{johnson2018towards,
  title={Towards practical differential privacy for SQL queries},
  author={Johnson, Noah and Near, Joseph P and Song, Dawn},
  journal={Proceedings of the VLDB Endowment},
  volume={11},
  number={5},
  pages={526--539},
  year={2018},
  publisher={VLDB Endowment}
}
@article{xu2020removing,
  title={Removing Disparate Impact of Differentially Private Stochastic Gradient Descent on Model Accuracy},
  author={Xu, Depeng and Du, Wei and Wu, Xintao},
  journal={arXiv preprint arXiv:2003.03699},
  year={2020}
}

@article{hooker2021moving,
  title={Moving beyond “algorithmic bias is a data problem”},
  author={Hooker, Sara},
  journal={Patterns},
  volume={2},
  number={4},
  pages={100241},
  year={2021},
  publisher={Elsevier}
}


@article{liu2020systematic,
  title={A Systematic Literature Review on Federated Learning: From A Model Quality Perspective},
  author={Liu, Yi and Zhang, Li and Ge, Ning and Li, Guanghao},
  journal={arXiv preprint arXiv:2012.01973},
  year={2020}
}

@article{bagdasaryan2019differential,
  title={Differential privacy has disparate impact on model accuracy},
  author={Bagdasaryan, Eugene and Poursaeed, Omid and Shmatikov, Vitaly},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={15479--15488},
  year={2019}
}


@misc{berger2019emerging,
  title={Emerging technologies towards enhancing privacy in genomic data sharing},
  author={Berger, Bonnie and Cho, Hyunghoon},
  year={2019},
  publisher={BioMed Central}
}


@inproceedings{chanyaswad2018mvg,
  title={Mvg mechanism: Differential privacy under matrix-valued query},
  author={Chanyaswad, Thee and Dytso, Alex and Poor, H Vincent and Mittal, Prateek},
  booktitle={Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security},
  pages={230--246},
  year={2018}
}


@inproceedings{abadi2016deep,
  title={Deep learning with differential privacy},
  author={Abadi, Martin and Chu, Andy and Goodfellow, Ian and McMahan, H Brendan and Mironov, Ilya and Talwar, Kunal and Zhang, Li},
  booktitle={Proceedings of the 2016 ACM SIGSAC conference on computer and communications security},
  pages={308--318},
  year={2016}
}

@inproceedings{Abay2018PrivacyPS,
  title={Privacy Preserving Synthetic Data Release Using Deep Learning},
  author={Nazmiye Ceren Abay and Y. Zhou and Murat Kantarcioglu and B. Thuraisingham and L. Sweeney},
  booktitle={ECML/PKDD},
  year={2018}
}

@article{cs2019DifferentiallyPM,
  title={Differentially Private Mixture of Generative Neural Networks},
  author={G. {\'A}cs and Luca Melis and C. Castelluccia and Emiliano De Cristofaro},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2019},
  volume={31},
  pages={1109-1121}
}

@misc{lighton2020,
    author = {LightOn},
    title = {Photonic Computing for Massively Parallel {AI} - {A} {W}hite {P}aper, v1.0},
    month = May,   
    year = {2020},
    howpublished = {\url{https://lighton.ai/wp-content/uploads/2020/05/LightOn-White-Paper-v1.0.pdf}},
    urldate = {2010-05-28}
}

@inproceedings{Nokland2016DirectFA,
  title={Direct Feedback Alignment Provides Learning in Deep Neural Networks},
  author={Arild N{\o}kland},
  booktitle={NIPS},
  year={2016}
}

@article{Reddi2020AdaptiveFO,
  title={Adaptive Federated Optimization},
  author={Sashank J. Reddi and Zachary B. Charles and M. Zaheer and Zachary A. Garrett and Keith Rush and Jakub Konecn{\'y} and S. Kumar and H. B. McMahan},
  journal={ArXiv},
  year={2020},
  volume={abs/2003.00295}
}

@article{papernot2018scalable,
  title={Scalable private learning with pate},
  author={Papernot, Nicolas and Song, Shuang and Mironov, Ilya and Raghunathan, Ananth and Talwar, Kunal and Erlingsson, {\'U}lfar},
  journal={arXiv preprint arXiv:1802.08908},
  year={2018}
}

@article{yin2021see,
  title={See through Gradients: Image Batch Recovery via GradInversion},
  author={Yin, Hongxu and Mallya, Arun and Vahdat, Arash and Alvarez, Jose M and Kautz, Jan and Molchanov, Pavlo},
  journal={arXiv preprint arXiv:2104.07586},
  year={2021}
}

@article{RodriguezBarroso2020,
   title={Federated Learning and Differential Privacy: Software tools analysis, the Sherpa.ai FL framework and methodological guidelines for preserving data privacy},
   volume={64},
   ISSN={1566-2535},
   url={http://dx.doi.org/10.1016/j.inffus.2020.07.009},
   DOI={10.1016/j.inffus.2020.07.009},
   journal={Information Fusion},
   publisher={Elsevier BV},
   author={Rodríguez-Barroso, Nuria and Stipcich, Goran and Jiménez-López, Daniel and Ruiz-Millán, José Antonio and Martínez-Cámara, Eugenio and González-Seco, Gerardo and Luzón, M. Victoria and Veganzones, Miguel Angel and Herrera, Francisco},
   year={2020},
   month={Dec},
   pages={270–292}
}

@InProceedings{pmlr-v54-mcmahan17a, 
title = {{Communication-Efficient Learning of Deep Networks from Decentralized Data}}, 
author = {Brendan McMahan and Eider Moore and Daniel Ramage and Seth Hampson and Blaise Aguera y Arcas}, 
booktitle = {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics}, 
pages = {1273--1282}, 
year = {2017}, 
editor = {Aarti Singh and Jerry Zhu}, 
volume = {54}, 
series = {Proceedings of Machine Learning Research}, 
address = {Fort Lauderdale, FL, USA}, 
month = {20--22 Apr}, 
publisher = {PMLR}, 
pdf = {http://proceedings.mlr.press/v54/mcmahan17a/mcmahan17a.pdf}, 
url = {http://proceedings.mlr.press/v54/mcmahan17a.html} }

@article{lee2020,
  author    = {Jaewoo Lee and
               Daniel Kifer},
  title     = {Differentially Private Deep Learning with Direct Feedback Alignment},
  journal   = {CoRR},
  volume    = {abs/2010.03701},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.03701},
  archivePrefix = {arXiv},
  eprint    = {2010.03701},
  timestamp = {Tue, 13 Oct 2020 15:25:23 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-03701.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
a service of Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchabout

@inproceedings{truex2020,
  author    = {Stacey Truex and
               Ling Liu and
               Ka Ho Chow and
               Mehmet Emre Gursoy and
               Wenqi Wei},
  editor    = {Aaron Yi Ding and
               Richard Mortier},
  title     = {LDP-Fed: federated learning with local differential privacy},
  booktitle = {Proceedings of the 3rd International Workshop on Edge Systems, Analytics
               and Networking, EdgeSys@EuroSys 2020, Heraklion, Greece, April 27,
               2020},
  pages     = {61--66},
  publisher = {{ACM}},
  year      = {2020},
  url       = {https://doi.org/10.1145/3378679.3394533},
  doi       = {10.1145/3378679.3394533},
  timestamp = {Mon, 25 May 2020 12:51:23 +0200},
  biburl    = {https://dblp.org/rec/conf/eurosys/Truex0CGW20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Dwork2006CalibratingNT,
  title={Calibrating Noise to Sensitivity in Private Data Analysis},
  author={C. Dwork and F. McSherry and Kobbi Nissim and A. D. Smith},
  booktitle={TCC},
  year={2006}
}
@article{launay2020direct,
  title={Direct feedback alignment scales to modern deep learning tasks and architectures},
  author={Launay, Julien and Poli, Iacopo and Boniface, Fran{\c{c}}ois and Krzakala, Florent},
  journal={arXiv preprint arXiv:2006.12878},
  year={2020}
}
@article{lillicrap2016random,
  title={Random synaptic feedback weights support error backpropagation for deep learning},
  author={Lillicrap, Timothy P and Cownden, Daniel and Tweed, Douglas B and Akerman, Colin J},
  journal={Nature communications},
  volume={7},
  number={1},
  pages={1--10},
  year={2016},
  publisher={Nature Publishing Group}
}
@article{refinetti2020dynamics,
  title={The dynamics of learning with feedback alignment},
  author={Refinetti, Maria and d'Ascoli, St{\'e}phane and Ohana, Ruben and Goldt, Sebastian},
  journal={arXiv preprint arXiv:2011.12428},
  year={2020}
}

@inproceedings{dwork2008differential,
	title={Differential privacy: A survey of results},
	author={Dwork, Cynthia},
	booktitle={International conference on theory and applications of models of computation},
	pages={1--19},
	year={2008},
	organization={Springer}
}

@article{asoodeh2020three,
	title={Three Variants of Differential Privacy: Lossless Conversion and Applications},
	author={Asoodeh, Shahab and Liao, Jiachun and Calmon, Flavio P and Kosut, Oliver and Sankar, Lalitha},
	journal={arXiv preprint arXiv:2008.06529},
	year={2020}
}
@book{pardo2018statistical,
  title={Statistical inference based on divergence measures},
  author={Pardo, Leandro},
  year={2018},
  publisher={CRC press}
}

@article{mironov2019r,
	title={R$\backslash$'enyi Differential Privacy of the Sampled Gaussian Mechanism},
	author={Mironov, Ilya and Talwar, Kunal and Zhang, Li},
	journal={arXiv preprint arXiv:1908.10530},
	year={2019}
}

@inproceedings{ohana2020kernel,
  title={Kernel computations from large-scale random features obtained by optical processing units},
  author={Ohana, Ruben and Wacker, Jonas and Dong, Jonathan and Marmin, S{\'e}bastien and Krzakala, Florent and Filippone, Maurizio and Daudet, Laurent},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={9294--9298},
  year={2020},
  organization={IEEE}
}

@inproceedings{mironov2017,
	author={I. {Mironov}},
	booktitle={2017 IEEE 30th Computer Security Foundations Symposium (CSF)}, 
	title={Rényi Differential Privacy}, 
	year={2017},
	volume={},
	number={},
	pages={263-275},
	doi={10.1109/CSF.2017.11}}

@InProceedings{balle18a, title = {Improving the {G}aussian Mechanism for Differential Privacy: Analytical Calibration and Optimal Denoising}, author = {Balle, Borja and Wang, Yu-Xiang}, booktitle = {Proceedings of the 35th International Conference on Machine Learning}, pages = {394--403}, year = {2018}, editor = {Jennifer Dy and Andreas Krause}, volume = {80}, series = {Proceedings of Machine Learning Research}, address = {Stockholmsmässan, Stockholm Sweden}, month = {10--15 Jul}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v80/balle18a/balle18a.pdf}, url = {http://proceedings.mlr.press/v80/balle18a.html}
 }

@inproceedings{renyi1961,
address = "Berkeley, Calif.",
author = "Rényi, Alfréd",
booktitle = "Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Contributions to the Theory of Statistics",
pages = "547--561",
publisher = "University of California Press",
title = "On Measures of Entropy and Information",
url = "https://projecteuclid.org/euclid.bsmsp/1200512181",
year = "1961"
}

@inproceedings{wang2019subsampled,
	title={Subsampled R{\'e}nyi differential privacy and analytical moments accountant},
	author={Wang, Yu-Xiang and Balle, Borja and Kasiviswanathan, Shiva Prasad},
	booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
	pages={1226--1235},
	year={2019},
	organization={PMLR}
}

@article{launay2020hardware,
  title={Hardware Beyond Backpropagation: a Photonic Co-Processor for Direct Feedback Alignment},
  author={Launay, Julien and Poli, Iacopo and M{\"u}ller, Kilian and Pariente, Gustave and Carron, Igor and Daudet, Laurent and Krzakala, Florent and Gigan, Sylvain},
  journal={Beyond Backpropagation Workshop, NeurIPS 2020},
  year={2020}
}

@article{frenkel2021learning,
  title={Learning without feedback: Fixed random learning signals allow for feedforward training of deep neural networks},
  author={Frenkel, Charlotte and Lefebvre, Martin and Bol, David},
  journal={Frontiers in neuroscience},
  volume={15},
  year={2021},
  publisher={Frontiers Media SA}
}

@article{xu202111,
  title={11 TOPS photonic convolutional accelerator for optical neural networks},
  author={Xu, Xingyuan and Tan, Mengxi and Corcoran, Bill and Wu, Jiayang and Boes, Andreas and Nguyen, Thach G and Chu, Sai T and Little, Brent E and Hicks, Damien G and Morandotti, Roberto and others},
  journal={Nature},
  volume={589},
  number={7840},
  pages={44--51},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{hughes2018training,
  title={Training of photonic neural networks through in situ backpropagation and gradient measurement},
  author={Hughes, Tyler W and Minkov, Momchil and Shi, Yu and Fan, Shanhui},
  journal={Optica},
  volume={5},
  number={7},
  pages={864--871},
  year={2018},
  publisher={Optical Society of America}
}

@article{guo2019end,
  title={End-to-end optical backpropagation for training neural networks},
  author={Guo, Xianxin and Barrett, TD and Wang, ZM and Lvovsky, AI},
  year={2019}
}

@article{wetzstein2020inference,
  title={Inference in artificial intelligence with deep optics and photonics},
  author={Wetzstein, Gordon and Ozcan, Aydogan and Gigan, Sylvain and Fan, Shanhui and Englund, Dirk and Solja{\v{c}}i{\'c}, Marin and Denz, Cornelia and Miller, David AB and Psaltis, Demetri},
  journal={Nature},
  volume={588},
  number={7836},
  pages={39--47},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{launay2020light,
  title={Light-in-the-loop: using a photonics co-processor for scalable training of neural networks},
  author={Launay, Julien and Poli, Iacopo and M{\"u}ller, Kilian and Carron, Igor and Daudet, Laurent and Krzakala, Florent and Gigan, Sylvain},
  journal={Hot Chips 2020},
  year={2020}
}



@article{Rumelhart86Nature,
	Abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal `hidden'units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
	Author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
	Da = {1986/10/01},
	Date-Added = {2021-05-28 07:14:21 +0000},
	Date-Modified = {2021-05-28 07:14:21 +0000},
	Doi = {10.1038/323533a0},
	Id = {Rumelhart1986},
	Isbn = {1476-4687},
	Journal = {Nature},
	Number = {6088},
	Pages = {533--536},
	Title = {Learning representations by back-propagating errors},
	Ty = {JOUR},
	Url = {https://doi.org/10.1038/323533a0},
	Volume = {323},
	Year = {1986},
	Bdsk-Url-1 = {https://doi.org/10.1038/323533a0}}
