\begin{thebibliography}{66}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Wei et~al.(2022)Wei, Wang, Schuurmans, Bosma, Ichter, Xia, Chi, Le, and Zhou]{wei2022chainofthought}
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed~H. Chi, Quoc~V. Le, and Denny Zhou.
\newblock Chain-of-thought prompting elicits reasoning in large language models.
\newblock In Sanmi Koyejo, S.~Mohamed, A.~Agarwal, Danielle Belgrave, K.~Cho, and A.~Oh, editors, \emph{Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022}, 2022.

\bibitem[Webb et~al.(2023)Webb, Holyoak, and Lu]{webb2023reasoning}
Taylor Webb, Keith~J. Holyoak, and Hongjing Lu.
\newblock Emergent analogical reasoning in large language models.
\newblock \emph{Nature Human Behaviour}, 7\penalty0 (9):\penalty0 1526--1541, Sep 2023.
\newblock ISSN 2397-3374.
\newblock \doi{10.1038/s41562-023-01659-w}.

\bibitem[Valmeekam et~al.(2023)Valmeekam, Marquez, Sreedharan, and Kambhampati]{valmeekam2023planning}
Karthik Valmeekam, Matthew Marquez, Sarath Sreedharan, and Subbarao Kambhampati.
\newblock On the planning abilities of large language models - a critical investigation.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.

\bibitem[Yu et~al.(2024)Yu, Wang, Tu, Cao, Zhang-Li, Lv, Peng, Yao, Zhang, Li, Li, Zhang, Bai, Liu, Xin, Yun, GONG, Lin, Chen, Wu, Qi, Li, Guan, Zeng, Qi, Jin, Liu, Gu, Yao, Ding, Hou, Liu, Bin, Tang, and Li]{yu2024kola}
Jifan Yu, Xiaozhi Wang, Shangqing Tu, Shulin Cao, Daniel Zhang-Li, Xin Lv, Hao Peng, Zijun Yao, Xiaohan Zhang, Hanming Li, Chunyang Li, Zheyuan Zhang, Yushi Bai, Yantao Liu, Amy Xin, Kaifeng Yun, Linlu GONG, Nianyi Lin, Jianhui Chen, Zhili Wu, Yunjia Qi, Weikai Li, Yong Guan, Kaisheng Zeng, Ji~Qi, Hailong Jin, Jinxin Liu, Yu~Gu, Yuan Yao, Ning Ding, Lei Hou, Zhiyuan Liu, Xu~Bin, Jie Tang, and Juanzi Li.
\newblock Ko{LA}: Carefully benchmarking world knowledge of large language models.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.

\bibitem[Bengio et~al.(2024)Bengio, Hinton, Yao, Song, Abbeel, Darrell, Harari, Zhang, Xue, Shalev-Shwartz, Hadfield, Clune, Maharaj, Hutter, Baydin, McIlraith, Gao, Acharya, Krueger, Dragan, Torr, Russell, Kahneman, Brauner, and Mindermann]{bengio2024airisk}
Yoshua Bengio, Geoffrey Hinton, Andrew Yao, Dawn Song, Pieter Abbeel, Trevor Darrell, Yuval~Noah Harari, Ya-Qin Zhang, Lan Xue, Shai Shalev-Shwartz, Gillian Hadfield, Jeff Clune, Tegan Maharaj, Frank Hutter, Atılım~Güneş Baydin, Sheila McIlraith, Qiqi Gao, Ashwin Acharya, David Krueger, Anca Dragan, Philip Torr, Stuart Russell, Daniel Kahneman, Jan Brauner, and Sören Mindermann.
\newblock Managing extreme ai risks amid rapid progress.
\newblock \emph{Science}, 384\penalty0 (6698):\penalty0 842--845, 2024.
\newblock \doi{10.1126/science.adn0117}.

\bibitem[Hendrycks et~al.(2021)Hendrycks, Burns, Basart, Zou, Mazeika, Song, and Steinhardt]{hendrycks2021mmlu}
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.
\newblock Measuring massive multitask language understanding.
\newblock In \emph{9th International Conference on Learning Representations, {ICLR} 2021, Virtual Event, Austria, May 3-7, 2021}. OpenReview.net, 2021.

\bibitem[Zhong et~al.(2023)Zhong, Cui, Guo, Liang, Lu, Wang, Saied, Chen, and Duan]{zhong2023agieval}
Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen, and Nan Duan.
\newblock Agieval: {A} human-centric benchmark for evaluating foundation models.
\newblock \emph{CoRR}, abs/2304.06364, 2023.

\bibitem[Clark et~al.(2018)Clark, Cowhey, Etzioni, Khot, Sabharwal, Schoenick, and Tafjord]{clark2018arc}
Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord.
\newblock Think you have solved question answering? try arc, the {AI2} reasoning challenge.
\newblock \emph{CoRR}, abs/1803.05457, 2018.

\bibitem[Pal et~al.(2022)Pal, Umapathi, and Sankarasubbu]{pall2022medmcqa}
Ankit Pal, Logesh~Kumar Umapathi, and Malaikannan Sankarasubbu.
\newblock Medmcqa: {A} large-scale multi-subject multi-choice dataset for medical domain question answering.
\newblock In Gerardo Flores, George~H. Chen, Tom~J. Pollard, Joyce~C. Ho, and Tristan Naumann, editors, \emph{Conference on Health, Inference, and Learning, {CHIL} 2022, 7-8 April 2022, Virtual Event}, volume 174 of \emph{Proceedings of Machine Learning Research}, pages 248--260. {PMLR}, 2022.

\bibitem[Nay et~al.(2023)Nay, Karamardian, Lawsky, Tao, Bhat, Jain, Lee, Choi, and Kasai]{nay2023taxlaw}
John~J. Nay, David Karamardian, Sarah~B. Lawsky, Wenting Tao, Meghana Bhat, Raghav Jain, Aaron~Travis Lee, Jonathan~H. Choi, and Jungo Kasai.
\newblock Large language models as tax attorneys: {A} case study in legal capabilities emergence.
\newblock \emph{CoRR}, abs/2306.07075, 2023.

\bibitem[Cobbe et~al.(2021)Cobbe, Kosaraju, Bavarian, Chen, Jun, Kaiser, Plappert, Tworek, Hilton, Nakano, Hesse, and Schulman]{cobbe2021gsm8k}
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman.
\newblock Training verifiers to solve math word problems.
\newblock \emph{CoRR}, abs/2110.14168, 2021.

\bibitem[Guo et~al.(2023)Guo, Jin, Liu, Huang, Shi, Supryadi, Yu, Liu, Li, Xiong, and Xiong]{guo2023survey}
Zishan Guo, Renren Jin, Chuang Liu, Yufei Huang, Dan Shi, Supryadi, Linhao Yu, Yan Liu, Jiaxuan Li, Bojian Xiong, and Deyi Xiong.
\newblock Evaluating large language models: {A} comprehensive survey.
\newblock \emph{CoRR}, abs/2310.19736, 2023.

\bibitem[Li et~al.(2024{\natexlab{a}})Li, Li, Xiang, Liu, Deng, and Garcia]{li2024canmcqreally}
Wangyue Li, Liangzhi Li, Tong Xiang, Xiao Liu, Wei Deng, and Noa Garcia.
\newblock Can multiple-choice questions really be useful in detecting the abilities of llms?
\newblock In Nicoletta Calzolari, Min{-}Yen Kan, V{\'{e}}ronique Hoste, Alessandro Lenci, Sakriani Sakti, and Nianwen Xue, editors, \emph{Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, {LREC/COLING} 2024, 20-25 May, 2024, Torino, Italy}, pages 2819--2834. {ELRA} and {ICCL}, 2024{\natexlab{a}}.

\bibitem[Oren et~al.(2024)Oren, Meister, Chatterji, Ladhak, and Hashimoto]{oren2024proving}
Yonatan Oren, Nicole Meister, Niladri~S. Chatterji, Faisal Ladhak, and Tatsunori Hashimoto.
\newblock Proving test set contamination in black-box language models.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.

\bibitem[Lin(2024)]{lin2024how}
Zhicheng Lin.
\newblock How to write effective prompts for large language models.
\newblock \emph{Nature Human Behaviour}, 8\penalty0 (4):\penalty0 611--615, Apr 2024.
\newblock \doi{10.1038/s41562-024-01847-2}.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Cheng, Guo, Yue, Ding, Xu, Wang, Hu, Zhang, and Zhang]{wang2023openqa}
Cunxiang Wang, Sirui Cheng, Qipeng Guo, Yuanhao Yue, Bowen Ding, Zhikun Xu, Yidong Wang, Xiangkun Hu, Zheng Zhang, and Yue Zhang.
\newblock Evaluating open-qa evaluation.
\newblock In Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, editors, \emph{Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023}, 2023{\natexlab{a}}.

\bibitem[Fourrier et~al.(2019)Fourrier, Habib, Launay, and Wolf]{fourrier2023what}
Clémentine Fourrier, Nathan Habib, Julien Launay, and Thomas Wolf.
\newblock What's going on with the open llm leaderboard?
\newblock \url{https://huggingface.co/blog/open-llm-leaderboard-mmlu}, 2019.

\bibitem[Schaeffer et~al.(2023)Schaeffer, Miranda, and Koyejo]{schaeffer2023emergent}
Rylan Schaeffer, Brando Miranda, and Sanmi Koyejo.
\newblock Are emergent abilities of large language models a mirage?
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert{-}Voss, Krueger, Henighan, Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess, Clark, Berner, McCandlish, Radford, Sutskever, and Amodei]{brown2020language}
Tom~B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert{-}Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel~M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei.
\newblock Language models are few-shot learners.
\newblock In Hugo Larochelle, Marc'Aurelio Ranzato, Raia Hadsell, Maria{-}Florina Balcan, and Hsuan{-}Tien Lin, editors, \emph{Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual}, 2020.

\bibitem[Golchin and Surdeanu(2024)]{golchin2024time}
Shahriar Golchin and Mihai Surdeanu.
\newblock Time travel in {LLM}s: Tracing data contamination in large language models.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.

\bibitem[Bai et~al.(2024)Bai, Feng, Balachandran, Tan, Lou, He, and Tsvetkov]{bai2024kgquiz}
Yuyang Bai, Shangbin Feng, Vidhisha Balachandran, Zhaoxuan Tan, Shiqi Lou, Tianxing He, and Yulia Tsvetkov.
\newblock Kgquiz: Evaluating the generalization of encoded knowledge in large language models.
\newblock In Tat{-}Seng Chua, Chong{-}Wah Ngo, Ravi Kumar, Hady~W. Lauw, and Roy~Ka{-}Wei Lee, editors, \emph{Proceedings of the {ACM} on Web Conference 2024, {WWW} 2024, Singapore, May 13-17, 2024}, pages 2226--2237. {ACM}, 2024.

\bibitem[Qian~Liu and Harland(2023)]{liu2023mcqhighorder}
Chandima~Daskon Qian~Liu, Navé~Wald and Tony Harland.
\newblock Multiple-choice questions (mcqs) for higher-order cognition: Perspectives of university teachers.
\newblock \emph{Innovations in Education and Teaching International}, 0\penalty0 (0):\penalty0 1--13, 2023.
\newblock \doi{10.1080/14703297.2023.2222715}.

\bibitem[Noorbehbahani et~al.(2022)Noorbehbahani, Mohammadi, and Aminazadeh]{noorbehbahani2022cheating}
Fakhroddin Noorbehbahani, Azadeh Mohammadi, and Mohammad Aminazadeh.
\newblock A systematic review of research on cheating in online exams from 2010 to 2021.
\newblock \emph{Educ Inf Technol (Dordr)}, 27\penalty0 (6):\penalty0 8413--8460, March 2022.

\bibitem[Manoharan(2019)]{manoharan2019personalization}
Sathiamoorthy Manoharan.
\newblock Cheat-resistant multiple-choice examinations using personalization.
\newblock \emph{Computers \& Education}, 130:\penalty0 139--151, 2019.
\newblock ISSN 0360-1315.
\newblock \doi{https://doi.org/10.1016/j.compedu.2018.11.007}.

\bibitem[Shin et~al.(2019)Shin, Guo, and Gierl]{shin2019mcqdistract}
Jinnie Shin, Qi~Guo, and Mark~J. Gierl.
\newblock Multiple-{Choice} {Item} {Distractor} {Development} {Using} {Topic} {Modeling} {Approaches}.
\newblock \emph{Frontiers in Psychology}, 10, 2019.
\newblock ISSN 1664-1078.
\newblock \doi{10.3389/fpsyg.2019.00825}.

\bibitem[Gierl et~al.(2017)Gierl, Bulut, Guo, and Zhang]{gierl2017mcqdistract}
Mark~J. Gierl, Okan Bulut, Qi~Guo, and Xinxin Zhang.
\newblock Developing, analyzing, and using distractors for multiple-choice tests in education: A comprehensive review.
\newblock \emph{Review of Educational Research}, 87\penalty0 (6):\penalty0 1082--1116, 2017.
\newblock \doi{10.3102/0034654317726529}.

\bibitem[Huang et~al.(2023)Huang, Bai, Zhu, Zhang, Zhang, Su, Liu, Lv, Zhang, Lei, Fu, Sun, and He]{huang2023ceval}
Yuzhen Huang, Yuzhuo Bai, Zhihao Zhu, Junlei Zhang, Jinghan Zhang, Tangjun Su, Junteng Liu, Chuancheng Lv, Yikai Zhang, Jiayi Lei, Yao Fu, Maosong Sun, and Junxian He.
\newblock C-eval: {A} multi-level multi-discipline chinese evaluation suite for foundation models.
\newblock In Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, editors, \emph{Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023}, 2023.

\bibitem[Lu et~al.(2022)Lu, Mishra, Xia, Qiu, Chang, Zhu, Tafjord, Clark, and Kalyan]{lu2022scienceqa}
Pan Lu, Swaroop Mishra, Tanglin Xia, Liang Qiu, Kai{-}Wei Chang, Song{-}Chun Zhu, Oyvind Tafjord, Peter Clark, and Ashwin Kalyan.
\newblock Learn to explain: Multimodal reasoning via thought chains for science question answering.
\newblock In Sanmi Koyejo, S.~Mohamed, A.~Agarwal, Danielle Belgrave, K.~Cho, and A.~Oh, editors, \emph{Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022}, 2022.

\bibitem[Bai et~al.(2023)Bai, Ying, Cao, Lv, He, Wang, Yu, Zeng, Xiao, Lyu, Zhang, Li, and Hou]{bai2023llmexaminer}
Yushi Bai, Jiahao Ying, Yixin Cao, Xin Lv, Yuze He, Xiaozhi Wang, Jifan Yu, Kaisheng Zeng, Yijia Xiao, Haozhe Lyu, Jiayin Zhang, Juanzi Li, and Lei Hou.
\newblock Benchmarking foundation models with language-model-as-an-examiner.
\newblock In Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, editors, \emph{Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023}, 2023.

\bibitem[Zhuang et~al.(2023)Zhuang, Liu, Ning, Huang, Lv, Huang, Zhao, Zhang, Mao, Wang, and Chen]{zhuang2023efficient}
Yan Zhuang, Qi~Liu, Yuting Ning, Weizhe Huang, Rui Lv, Zhenya Huang, Guanhao Zhao, Zheng Zhang, Qingyang Mao, Shijin Wang, and Enhong Chen.
\newblock Efficiently measuring the cognitive ability of llms: An adaptive testing perspective.
\newblock \emph{CoRR}, abs/2306.10512, 2023.

\bibitem[Li et~al.(2023{\natexlab{a}})Li, Li, and Liu]{li2023beyond}
Jiatong Li, Rui Li, and Qi~Liu.
\newblock Beyond static datasets: {A} deep interaction approach to {LLM} evaluation.
\newblock \emph{CoRR}, abs/2309.04369, 2023{\natexlab{a}}.

\bibitem[Zheng et~al.(2024{\natexlab{a}})Zheng, Wang, Zhang, Nguyen, Sun, and Chua]{zheng2024aliagent}
Jingnan Zheng, Han Wang, An~Zhang, Tai~D. Nguyen, Jun Sun, and Tat{-}Seng Chua.
\newblock Ali-agent: Assessing llms' alignment with human values via agent-based evaluation.
\newblock \emph{CoRR}, abs/2405.14125, 2024{\natexlab{a}}.

\bibitem[Ribeiro et~al.(2020)Ribeiro, Wu, Guestrin, and Singh]{ribeiro2020checklist}
Marco~Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin, and Sameer Singh.
\newblock Beyond accuracy: Behavioral testing of {NLP} models with {C}heck{L}ist.
\newblock In Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel Tetreault, editors, \emph{Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics}, pages 4902--4912, Online, July 2020. Association for Computational Linguistics.

\bibitem[Wu et~al.(2021)Wu, Ribeiro, Heer, and Weld]{wu2021polyjuice}
Tongshuang Wu, Marco~Tulio Ribeiro, Jeffrey Heer, and Daniel Weld.
\newblock Polyjuice: Generating counterfactuals for explaining, evaluating, and improving models.
\newblock In Chengqing Zong, Fei Xia, Wenjie Li, and Roberto Navigli, editors, \emph{Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)}, pages 6707--6723, Online, August 2021. Association for Computational Linguistics.

\bibitem[Elazar et~al.(2021)Elazar, Kassner, Ravfogel, Ravichander, Hovy, Sch{\"{u}}tze, and Goldberg]{elazar2021measuring}
Yanai Elazar, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Eduard~H. Hovy, Hinrich Sch{\"{u}}tze, and Yoav Goldberg.
\newblock Measuring and improving consistency in pretrained language models.
\newblock \emph{Trans. Assoc. Comput. Linguistics}, 9:\penalty0 1012--1031, 2021.

\bibitem[Fierro and S{\o}gaard(2022)]{fierro2022factualconsistency}
Constanza Fierro and Anders S{\o}gaard.
\newblock Factual consistency of multilingual pretrained language models.
\newblock In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors, \emph{Findings of the Association for Computational Linguistics: {ACL} 2022, Dublin, Ireland, May 22-27, 2022}, pages 3046--3052. Association for Computational Linguistics, 2022.

\bibitem[Jang et~al.(2022)Jang, Kwon, and Lukasiewicz]{DBLP:conf/coling/JangKL22}
Myeongjun Jang, Deuk~Sin Kwon, and Thomas Lukasiewicz.
\newblock {BECEL:} benchmark for consistency evaluation of language models.
\newblock In Nicoletta Calzolari, Chu{-}Ren Huang, Hansaem Kim, James Pustejovsky, Leo Wanner, Key{-}Sun Choi, Pum{-}Mo Ryu, Hsin{-}Hsi Chen, Lucia Donatelli, Heng Ji, Sadao Kurohashi, Patrizia Paggio, Nianwen Xue, Seokhwan Kim, Younggyun Hahm, Zhong He, Tony~Kyungil Lee, Enrico Santus, Francis Bond, and Seung{-}Hoon Na, editors, \emph{Proceedings of the 29th International Conference on Computational Linguistics, {COLING} 2022, Gyeongju, Republic of Korea, October 12-17, 2022}, pages 3680--3696. International Committee on Computational Linguistics, 2022.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, Wei, Schuurmans, Le, Chi, Narang, Chowdhery, and Zhou]{wang2023selfconsistency}
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc~V. Le, Ed~H. Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou.
\newblock Self-consistency improves chain of thought reasoning in language models.
\newblock In \emph{The Eleventh International Conference on Learning Representations, {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023}. OpenReview.net, 2023{\natexlab{b}}.

\bibitem[Rajan et~al.(2024)Rajan, Soremekun, and Chattopadhyay]{rajan2024knowledgebasedconsistency}
Sai~Sathiesh Rajan, Ezekiel~O. Soremekun, and Sudipta Chattopadhyay.
\newblock Knowledge-based consistency testing of large language models.
\newblock \emph{CoRR}, abs/2407.12830, 2024.

\bibitem[Wei et~al.(2023)Wei, Haghtalab, and Steinhardt]{wei2023jailbreak}
Alexander Wei, Nika Haghtalab, and Jacob Steinhardt.
\newblock Jailbroken: How does {LLM} safety training fail?
\newblock In Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, editors, \emph{Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023}, 2023.

\bibitem[Xu et~al.(2024)Xu, Kong, Liu, Cui, Wang, Zhang, and Kankanhalli]{xu2024promptattack}
Xilie Xu, Keyi Kong, Ning Liu, Lizhen Cui, Di~Wang, Jingfeng Zhang, and Mohan Kankanhalli.
\newblock An {LLM} can fool itself: A prompt-based adversarial attack.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.

\bibitem[Gao et~al.(2018)Gao, Lanchantin, Soffa, and Qi]{gao2018char}
Ji~Gao, Jack Lanchantin, Mary~Lou Soffa, and Yanjun Qi.
\newblock Black-box generation of adversarial text sequences to evade deep learning classifiers.
\newblock In \emph{2018 {IEEE} Security and Privacy Workshops, {SP} Workshops 2018, San Francisco, CA, USA, May 24, 2018}, pages 50--56. {IEEE} Computer Society, 2018.

\bibitem[Ebrahimi et~al.(2018)Ebrahimi, Lowd, and Dou]{ebrahimi2018char}
Javid Ebrahimi, Daniel Lowd, and Dejing Dou.
\newblock On adversarial examples for character-level neural machine translation.
\newblock In Emily~M. Bender, Leon Derczynski, and Pierre Isabelle, editors, \emph{Proceedings of the 27th International Conference on Computational Linguistics, {COLING} 2018, Santa Fe, New Mexico, USA, August 20-26, 2018}, pages 653--663. Association for Computational Linguistics, 2018.

\bibitem[Li et~al.(2023{\natexlab{b}})Li, Shi, Liu, Kong, Wu, Zhang, Huang, and Lyu]{li2023word}
Guoyi Li, Bingkang Shi, Zongzhen Liu, Dehan Kong, Yulei Wu, Xiaodan Zhang, Longtao Huang, and Honglei Lyu.
\newblock Adversarial text generation by search and learning.
\newblock In Houda Bouamor, Juan Pino, and Kalika Bali, editors, \emph{Findings of the Association for Computational Linguistics: {EMNLP} 2023, Singapore, December 6-10, 2023}, pages 15722--15738. Association for Computational Linguistics, 2023{\natexlab{b}}.

\bibitem[Lin et~al.(2021)Lin, Zou, and Ding]{lin2021sentence}
Jieyu Lin, Jiajie Zou, and Nai Ding.
\newblock Using adversarial attacks to reveal the statistical bias in machine reading comprehension models.
\newblock In Chengqing Zong, Fei Xia, Wenjie Li, and Roberto Navigli, editors, \emph{Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, {ACL/IJCNLP} 2021, (Volume 2: Short Papers), Virtual Event, August 1-6, 2021}, pages 333--342. Association for Computational Linguistics, 2021.

\bibitem[Chandrasekaran and Mago(2022)]{chandrasekaran2022evolution}
Dhivya Chandrasekaran and Vijay Mago.
\newblock Evolution of semantic similarity - {A} survey.
\newblock \emph{{ACM} Comput. Surv.}, 54\penalty0 (2):\penalty0 41:1--41:37, 2022.

\bibitem[Contributors(2023)]{2023opencompass}
OpenCompass Contributors.
\newblock Opencompass: A universal evaluation platform for foundation models.
\newblock \url{https://github.com/open-compass/opencompass}, 2023.

\bibitem[OpenAI(2023)]{openai2023gpt4}
OpenAI.
\newblock {GPT-4} technical report.
\newblock \emph{CoRR}, abs/2303.08774, 2023.

\bibitem[OpenAI(2021)]{openai2021gpt35}
OpenAI.
\newblock {GPT}-3.5 {T}urbo.
\newblock \url{https://platform.openai.com/docs/models/gpt-3-5}, 2021.

\bibitem[Google(2023)]{anil2023gemini}
Gemini~Team Google.
\newblock Gemini: {A} family of highly capable multimodal models.
\newblock \emph{CoRR}, abs/2312.11805, 2023.

\bibitem[Du et~al.(2022)Du, Qian, Liu, Ding, Qiu, Yang, and Tang]{du2022glm}
Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang.
\newblock Glm: General language model pretraining with autoregressive blank infilling.
\newblock In \emph{Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 320--335, 2022.

\bibitem[Team(2023)]{mistral2023mistral}
Mistral~AI Team.
\newblock Mistral 7{B}.
\newblock \url{https://mistral.ai/news/announcing-mistral-7b/}, 2023.

\bibitem[AI@Meta(2024)]{llama3modelcard}
AI@Meta.
\newblock Llama 3 model card.
\newblock 2024.
\newblock URL \url{https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md}.

\bibitem[Jin et~al.(2019)Jin, Dhingra, Liu, Cohen, and Lu]{jin2019pubmedqa}
Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William~W. Cohen, and Xinghua Lu.
\newblock Pubmedqa: {A} dataset for biomedical research question answering.
\newblock In Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wan, editors, \emph{Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, {EMNLP-IJCNLP} 2019, Hong Kong, China, November 3-7, 2019}, pages 2567--2577. Association for Computational Linguistics, 2019.

\bibitem[Ziems et~al.(2024)Ziems, Held, Shaikh, Chen, Zhang, and Yang]{ziems2024computationalsocialscience}
Caleb Ziems, William Held, Omar Shaikh, Jiaao Chen, Zhehao Zhang, and Diyi Yang.
\newblock Can large language models transform computational social science?
\newblock \emph{Comput. Linguistics}, 50\penalty0 (1):\penalty0 237--291, 2024.

\bibitem[Arora et~al.(2023)Arora, Singh, and Mausam]{arora2023science}
Daman Arora, Himanshu~Gaurav Singh, and Mausam.
\newblock Have llms advanced enough? {A} challenging problem solving benchmark for large language models.
\newblock In Houda Bouamor, Juan Pino, and Kalika Bali, editors, \emph{Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, {EMNLP} 2023, Singapore, December 6-10, 2023}, pages 7527--7543. Association for Computational Linguistics, 2023.

\bibitem[Aiyappa et~al.(2023)Aiyappa, An, Kwak, and Ahn]{aiyappa2023trust}
Rachith Aiyappa, Jisun An, Haewoon Kwak, and Yong{-}Yeol Ahn.
\newblock Can we trust the evaluation on chatgpt?
\newblock \emph{CoRR}, abs/2303.12767, 2023.

\bibitem[Sainz et~al.(2023)Sainz, Campos, Garc{\'{\i}}a{-}Ferrero, Etxaniz, de~Lacalle, and Agirre]{sainz2023contamination}
Oscar Sainz, Jon~Ander Campos, Iker Garc{\'{\i}}a{-}Ferrero, Julen Etxaniz, Oier~Lopez de~Lacalle, and Eneko Agirre.
\newblock {NLP} evaluation in trouble: On the need to measure {LLM} data contamination for each benchmark.
\newblock In Houda Bouamor, Juan Pino, and Kalika Bali, editors, \emph{Findings of the Association for Computational Linguistics: {EMNLP} 2023, Singapore, December 6-10, 2023}, pages 10776--10787. Association for Computational Linguistics, 2023.

\bibitem[Jacovi et~al.(2023)Jacovi, Caciularu, Goldman, and Goldberg]{jacovi2023contamination}
Alon Jacovi, Avi Caciularu, Omer Goldman, and Yoav Goldberg.
\newblock Stop uploading test data in plain text: Practical strategies for mitigating data contamination by evaluation benchmarks.
\newblock In Houda Bouamor, Juan Pino, and Kalika Bali, editors, \emph{Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, {EMNLP} 2023, Singapore, December 6-10, 2023}, pages 5075--5084. Association for Computational Linguistics, 2023.

\bibitem[Magar and Schwartz(2022)]{magar2022contamination}
Inbal Magar and Roy Schwartz.
\newblock Data contamination: From memorization to exploitation.
\newblock In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio, editors, \emph{Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), {ACL} 2022, Dublin, Ireland, May 22-27, 2022}, pages 157--165. Association for Computational Linguistics, 2022.

\bibitem[Pezeshkpour and Hruschka(2023)]{pezeshkpour2023ordering}
Pouya Pezeshkpour and Estevam Hruschka.
\newblock Large language models sensitivity to the order of options in multiple-choice questions.
\newblock \emph{CoRR}, abs/2308.11483, 2023.

\bibitem[Zheng et~al.(2024{\natexlab{b}})Zheng, Zhou, Meng, Zhou, and Huang]{zheng2024robust}
Chujie Zheng, Hao Zhou, Fandong Meng, Jie Zhou, and Minlie Huang.
\newblock Large language models are not robust multiple choice selectors.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024{\natexlab{b}}.

\bibitem[Li et~al.(2024{\natexlab{b}})Li, Li, Xiang, Liu, Deng, and Garcia]{li2024mcquseful}
Wangyue Li, Liangzhi Li, Tong Xiang, Xiao Liu, Wei Deng, and Noa Garcia.
\newblock Can multiple-choice questions really be useful in detecting the abilities of llms?
\newblock \emph{CoRR}, abs/2403.17752, 2024{\natexlab{b}}.

\bibitem[Khatun and Brown(2024)]{khatun2024mcq}
Aisha Khatun and Daniel~G. Brown.
\newblock A study on large language models' limitations in multiple-choice question answering.
\newblock \emph{CoRR}, abs/2401.07955, 2024.

\bibitem[Hu et~al.(2022)Hu, Shen, Wallis, Allen-Zhu, Li, Wang, Wang, and Chen]{hu2022lora}
Edward~J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu~Wang, and Weizhu Chen.
\newblock Lo{RA}: Low-rank adaptation of large language models.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Zheng et~al.(2024{\natexlab{c}})Zheng, Zhang, Zhang, Ye, Luo, and Ma]{zheng2024llamafactory}
Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan Ye, Zheyan Luo, and Yongqiang Ma.
\newblock Llamafactory: Unified efficient fine-tuning of 100+ language models.
\newblock \emph{arXiv preprint arXiv:2403.13372}, 2024{\natexlab{c}}.

\end{thebibliography}
