\begin{thebibliography}{30}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2018)Agarwal, Beygelzimer, Dud{\'\i}k, Langford, and
  Wallach]{agarwal2018reductions}
Agarwal, A., Beygelzimer, A., Dud{\'\i}k, M., Langford, J., and Wallach, H.
\newblock A reductions approach to fair classification.
\newblock \emph{arXiv preprint arXiv:1803.02453}, 2018.

\bibitem[Buolamwini \& Gebru(2018)Buolamwini and Gebru]{buolamwini2018gender}
Buolamwini, J. and Gebru, T.
\newblock Gender shades: Intersectional accuracy disparities in commercial
  gender classification.
\newblock In \emph{Conference on fairness, accountability and transparency},
  pp.\  77--91, 2018.

\bibitem[Carlini \& Wagner(2017)Carlini and Wagner]{carlini2017towards}
Carlini, N. and Wagner, D.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{2017 ieee symposium on security and privacy (sp)}, pp.\
  39--57. IEEE, 2017.

\bibitem[Cohen et~al.(2019)Cohen, Rosenfeld, and Kolter]{cohen2019certified}
Cohen, J.~M., Rosenfeld, E., and Kolter, J.~Z.
\newblock Certified adversarial robustness via randomized smoothing.
\newblock \emph{arXiv preprint arXiv:1902.02918}, 2019.

\bibitem[Ding et~al.(2018)Ding, Sharma, Lui, and Huang]{ding2018max}
Ding, G.~W., Sharma, Y., Lui, K. Y.~C., and Huang, R.
\newblock Max-margin adversarial (mma) training: Direct input space margin
  maximization through adversarial training.
\newblock \emph{arXiv preprint arXiv:1812.02637}, 2018.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{arXiv preprint arXiv:1412.6572}, 2014.

\bibitem[He \& Garcia(2009)He and Garcia]{he2009learning}
He, H. and Garcia, E.~A.
\newblock Learning from imbalanced data.
\newblock \emph{IEEE Transactions on knowledge and data engineering},
  21\penalty0 (9):\penalty0 1263--1284, 2009.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[Ilyas et~al.(2019)Ilyas, Santurkar, Tsipras, Engstrom, Tran, and
  Madry]{ilyas2019adversarial}
Ilyas, A., Santurkar, S., Tsipras, D., Engstrom, L., Tran, B., and Madry, A.
\newblock Adversarial examples are not bugs, they are features.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  125--136, 2019.

\bibitem[Jin et~al.(2020)Jin, Li, Xu, Wang, and Tang]{jin2020adversarial}
Jin, W., Li, Y., Xu, H., Wang, Y., and Tang, J.
\newblock Adversarial attacks and defenses on graphs: A review and empirical
  study.
\newblock \emph{arXiv preprint arXiv:2003.00653}, 2020.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Kurakin et~al.(2016)Kurakin, Goodfellow, and
  Bengio]{kurakin2016adversarial}
Kurakin, A., Goodfellow, I., and Bengio, S.
\newblock Adversarial machine learning at scale.
\newblock \emph{arXiv preprint arXiv:1611.01236}, 2016.

\bibitem[Lin et~al.(2017)Lin, Goyal, Girshick, He, and
  Doll{\'a}r]{lin2017focal}
Lin, T.-Y., Goyal, P., Girshick, R., He, K., and Doll{\'a}r, P.
\newblock Focal loss for dense object detection.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pp.\  2980--2988, 2017.

\bibitem[Madry et~al.(2017)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2017towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock \emph{arXiv preprint arXiv:1706.06083}, 2017.

\bibitem[Morgulis et~al.(2019)Morgulis, Kreines, Mendelowitz, and
  Weisglass]{morgulis2019fooling}
Morgulis, N., Kreines, A., Mendelowitz, S., and Weisglass, Y.
\newblock Fooling a real car with adversarial traffic signs.
\newblock \emph{arXiv preprint arXiv:1907.00374}, 2019.

\bibitem[Nanda et~al.(2020)Nanda, Dooley, Singla, Feizi, and
  Dickerson]{nanda2020fairness}
Nanda, V., Dooley, S., Singla, S., Feizi, S., and Dickerson, J.~P.
\newblock Fairness through robustness: Investigating robustness disparity in
  deep learning.
\newblock \emph{arXiv preprint arXiv:2006.12621}, 2020.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and
  Ng]{netzer2011reading}
Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., and Ng, A.~Y.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock 2011.

\bibitem[Shafahi et~al.(2019)Shafahi, Najibi, Ghiasi, Xu, Dickerson, Studer,
  Davis, Taylor, and Goldstein]{shafahi2019adversarial}
Shafahi, A., Najibi, M., Ghiasi, M.~A., Xu, Z., Dickerson, J., Studer, C.,
  Davis, L.~S., Taylor, G., and Goldstein, T.
\newblock Adversarial training for free!
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3358--3369, 2019.

\bibitem[Sharif et~al.(2016)Sharif, Bhagavatula, Bauer, and
  Reiter]{sharif2016accessorize}
Sharif, M., Bhagavatula, S., Bauer, L., and Reiter, M.~K.
\newblock Accessorize to a crime: Real and stealthy attacks on state-of-the-art
  face recognition.
\newblock In \emph{Proceedings of the 2016 acm sigsac conference on computer
  and communications security}, pp.\  1528--1540, 2016.

\bibitem[Szegedy et~al.(2013)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock \emph{arXiv preprint arXiv:1312.6199}, 2013.

\bibitem[Tram{\`e}r et~al.(2020)Tram{\`e}r, Behrmann, Carlini, Papernot, and
  Jacobsen]{tramer2020fundamental}
Tram{\`e}r, F., Behrmann, J., Carlini, N., Papernot, N., and Jacobsen, J.-H.
\newblock Fundamental tradeoffs between invariance and sensitivity to
  adversarial perturbations.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  9561--9571. PMLR, 2020.

\bibitem[Tsipras et~al.(2018)Tsipras, Santurkar, Engstrom, Turner, and
  Madry]{tsipras2018robustness}
Tsipras, D., Santurkar, S., Engstrom, L., Turner, A., and Madry, A.
\newblock Robustness may be at odds with accuracy.
\newblock \emph{arXiv preprint arXiv:1805.12152}, 2018.

\bibitem[Wang et~al.(2017)Wang, Ramanan, and Hebert]{wang2017learning}
Wang, Y.-X., Ramanan, D., and Hebert, M.
\newblock Learning to model the tail.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  7029--7039, 2017.

\bibitem[Wong \& Kolter(2018)Wong and Kolter]{wong2018provable}
Wong, E. and Kolter, Z.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5286--5295. PMLR, 2018.

\bibitem[Xu et~al.(2019)Xu, Ma, Liu, Deb, Liu, Tang, and
  Jain]{xu2019adversarial}
Xu, H., Ma, Y., Liu, H., Deb, D., Liu, H., Tang, J., and Jain, A.
\newblock Adversarial attacks and defenses in images, graphs and text: A
  review.
\newblock \emph{arXiv preprint arXiv:1909.08072}, 2019.

\bibitem[Zafar et~al.(2017)Zafar, Valera, Gomez~Rodriguez, and
  Gummadi]{zafar2017fairness}
Zafar, M.~B., Valera, I., Gomez~Rodriguez, M., and Gummadi, K.~P.
\newblock Fairness beyond disparate treatment \& disparate impact: Learning
  classification without disparate mistreatment.
\newblock In \emph{Proceedings of the 26th international conference on world
  wide web}, pp.\  1171--1180, 2017.

\bibitem[Zhang et~al.(2018)Zhang, Lemoine, and Mitchell]{zhang2018mitigating}
Zhang, B.~H., Lemoine, B., and Mitchell, M.
\newblock Mitigating unwanted biases with adversarial learning.
\newblock In \emph{Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics,
  and Society}, pp.\  335--340, 2018.

\bibitem[Zhang et~al.(2019{\natexlab{a}})Zhang, Zhang, Lu, Zhu, and
  Dong]{zhang2019you}
Zhang, D., Zhang, T., Lu, Y., Zhu, Z., and Dong, B.
\newblock You only propagate once: Painless adversarial training using maximal
  principle.
\newblock \emph{arXiv preprint arXiv:1905.00877}, 2\penalty0 (3),
  2019{\natexlab{a}}.

\bibitem[Zhang et~al.(2019{\natexlab{b}})Zhang, Yu, Jiao, Xing, Ghaoui, and
  Jordan]{zhang2019theoretically}
Zhang, H., Yu, Y., Jiao, J., Xing, E.~P., Ghaoui, L.~E., and Jordan, M.~I.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock \emph{arXiv preprint arXiv:1901.08573}, 2019{\natexlab{b}}.

\bibitem[Zhang et~al.(2017)Zhang, Song, and Qi]{zhang2017age}
Zhang, Z., Song, Y., and Qi, H.
\newblock Age progression/regression by conditional adversarial autoencoder.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  5810--5818, 2017.

\end{thebibliography}
