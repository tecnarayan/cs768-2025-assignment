\begin{thebibliography}{92}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi

\bibitem[{Aletras and Stevenson(2013)}]{aletras2013evaluating}
Nikolaos Aletras and Mark Stevenson. 2013.
\newblock \href {https://www.aclweb.org/anthology/W13-0102} {Evaluating topic
  coherence using distributional semantics}.
\newblock In \emph{International Conference on Computational Semantics
  ({IWCS})}. Association for Computational Linguistics.

\bibitem[{Allington et~al.(2016)Allington, Brouillette, and
  Golumbia}]{allington2016humanities}
Daniel Allington, Sarah Brouillette, and David Golumbia. 2016.
\newblock \href {https://lareviewofbooks.org/article/neoliberal-tools-
  archives-political-history-digital-humanities/} {Neoliberal tools (and
  archives): A political history of digital humanities}.
\newblock In \emph{{LA} Review of Books}.

\bibitem[{Alokaili et~al.(2019)Alokaili, Aletras, and
  Stevenson}]{alokaili-etal-2019-ranking}
Areej Alokaili, Nikolaos Aletras, and Mark Stevenson. 2019.
\newblock \href {https://aclanthology.org/W19-0404} {Re-ranking words to
  improve interpretability of automatically generated topics}.
\newblock In \emph{International Conference on Computational Semantics}.
  Association for Computational Linguistics.

\bibitem[{Bhatia et~al.(2017)Bhatia, Lau, and
  Baldwin}]{bhatia-etal-2017-automated}
Shraey Bhatia, Jey~Han Lau, and Timothy Baldwin. 2017.
\newblock \href {https://aclanthology.org/K17-1022} {An automatic approach for
  document-level topic model evaluation}.
\newblock In \emph{Conference on Computational Natural Language Learning},
  Vancouver, Canada. Association for Computational Linguistics.

\bibitem[{Bianchi et~al.(2021)Bianchi, Terragni, and
  Hovy}]{Bianchi2020PretrainingIA}
Federico Bianchi, Silvia Terragni, and Dirk Hovy. 2021.
\newblock \href {https://aclanthology.org/2021.acl-short.96} {Pre-training is a
  hot topic: Contextualized document embeddings improve topic coherence}.
\newblock In \emph{Proceedings of the Association for Computational
  Linguistics}, Online. Association for Computational Linguistics.

\bibitem[{Blei et~al.(2003)Blei, Ng, and
  Jordan}]{bleiLatentDirichletAllocation2003}
David~M. Blei, Andrew Ng, and Michael~I. Jordan. 2003.
\newblock {L}atent {D}irichlet {A}llocation.
\newblock \emph{Journal of Machine Learning Research}, 3:993--1022.

\bibitem[{Bowman et~al.(2016)Bowman, Vilnis, Vinyals, Dai, Jozefowicz, and
  Bengio}]{bowman2016generating}
Samuel~R. Bowman, Luke Vilnis, Oriol Vinyals, Andrew Dai, Rafal Jozefowicz, and
  Samy Bengio. 2016.
\newblock \href {https://www.aclweb.org/anthology/K16-1002} {Generating
  sentences from a continuous space}.
\newblock In \emph{Conference on Computational Natural Language Learning}.
  Association for Computational Linguistics.

\bibitem[{Boyd-Graber et~al.(2017)Boyd-Graber, Hu, and Mimno}]{boyd-graber-17}
Jordan Boyd-Graber, Yuening Hu, and David Mimno. 2017.
\newblock \emph{Applications of Topic Models}.
\newblock NOW Publishers.

\bibitem[{Brysbaert et~al.(2016)Brysbaert, Stevens, Mandera, and
  Keuleers}]{brysbaert2016words}
Marc Brysbaert, Michaël Stevens, Paweł Mandera, and Emmanuel Keuleers. 2016.
\newblock \href {https://www.frontiersin.org/article/10.3389/ fpsyg.2016.01116}
  {How many words do we know? {P}ractical estimates of vocabulary size
  dependent on word definition, the degree of language input and the
  participant’s age}.
\newblock In \emph{Frontiers in Psychology}.

\bibitem[{Burkhardt and
  Kramer(2019)}]{burkhardtDecouplingSparsitySmoothness2019}
Sophie Burkhardt and Stefan Kramer. 2019.
\newblock \href {https://jmlr.org/papers/v20/18-569.html} {Decoupling
  {{Sparsity}} and {{Smoothness}} in the {{Dirichlet Variational Autoencoder
  Topic Model}}}.
\newblock In \emph{Journal of Machine Learning Research}.

\bibitem[{Card et~al.(2020)Card, Henderson, Khandelwal, Jia, Mahowald, and
  Jurafsky}]{Card2020WithLP}
Dallas Card, Peter Henderson, Urvashi Khandelwal, Robin Jia, Kyle Mahowald, and
  Dan Jurafsky. 2020.
\newblock \href {https://www.aclweb.org/anthology/2020.emnlp-main.745} {With
  little power comes great responsibility}.
\newblock In \emph{Proceedings of Empirical Methods in Natural Language
  Processing}. Association for Computational Linguistics.

\bibitem[{Card et~al.(2018)Card, Tan, and Smith}]{Card2018NeuralMF}
Dallas Card, Chenhao Tan, and Noah~A. Smith. 2018.
\newblock \href {https://www.aclweb.org/anthology/P18-1189} {Neural models for
  documents with metadata}.
\newblock In \emph{Proceedings of the Association for Computational
  Linguistics}. Association for Computational Linguistics.

\bibitem[{Chang et~al.(2009)Chang, Boyd{-}Graber, Gerrish, Wang, and
  Blei}]{chang2009reading}
Jonathan Chang, Jordan~L. Boyd{-}Graber, Sean Gerrish, Chong Wang, and David~M.
  Blei. 2009.
\newblock \href
  {https://proceedings.neurips.cc/paper/2009/hash/f92586a25bb3145facd64ab20fd554ff-Abstract.html}
  {Reading tea leaves: How humans interpret topic models}.
\newblock In \emph{Proceedings of Advances in Neural Information Processing
  Systems}. Curran Associates, Inc.

\bibitem[{Chuang et~al.(2014)Chuang, Wilkerson, Weiss, Tingley, Stewart,
  Roberts, Poursabzi-Sangdeh, Grimmer, Findlater, Boyd-Graber, and
  Heer}]{Chuang2014ComputerAssistedCA}
Jason Chuang, John~D. Wilkerson, Rebecca Weiss, Dustin Tingley, Brandon~M.
  Stewart, Margaret~E. Roberts, Forough Poursabzi-Sangdeh, Justin Grimmer, Leah
  Findlater, Jordan Boyd-Graber, and Jeff Heer. 2014.
\newblock Computer-assisted content analysis : Topic models for exploring
  multiple subjective interpretations.
\newblock In \emph{Advances in Neural Information Processing Systems Workshop
  on Human-Propelled Machine Learning}.

\bibitem[{Denny and Spirling(2018)}]{denny2018text}
Matthew~J Denny and Arthur Spirling. 2018.
\newblock Text preprocessing for unsupervised learning: Why it matters, when it
  misleads, and what to do about it.
\newblock In \emph{Political Analysis}. Cambridge University Press.

\bibitem[{Dieng et~al.(2020)Dieng, Ruiz, and
  Blei}]{diengTopicModelingEmbedding2019}
Adji~B. Dieng, Francisco J.~R. Ruiz, and David~M. Blei. 2020.
\newblock \href {https://www.aclweb.org/anthology/2020.tacl-1.29} {Topic
  modeling in embedding spaces}.
\newblock \emph{Transactions of the Association for Computational Linguistics}.

\bibitem[{Ding et~al.(2018)Ding, Nallapati, and
  Xiang}]{Ding2018CoherenceAwareNT}
Ran Ding, Ramesh Nallapati, and Bing Xiang. 2018.
\newblock \href {https://www.aclweb.org/anthology/D18-1096} {Coherence-aware
  neural topic modeling}.
\newblock In \emph{Proceedings of Empirical Methods in Natural Language
  Processing}. Association for Computational Linguistics.

\bibitem[{Dodge et~al.(2019)Dodge, Gururangan, Card, Schwartz, and
  Smith}]{dodge-19}
Jesse Dodge, Suchin Gururangan, Dallas Card, Roy Schwartz, and Noah~A. Smith.
  2019.
\newblock \href {https://www.aclweb.org/anthology/D19-1224} {Show your work:
  Improved reporting of experimental results}.
\newblock In \emph{Proceedings of Empirical Methods in Natural Language
  Processing}. Association for Computational Linguistics.

\bibitem[{Doogan and Buntine(2021)}]{doogan-buntine-2021-topic}
Caitlin Doogan and Wray Buntine. 2021.
\newblock \href {https://www.aclweb.org/anthology/2021.naacl-main.300} {Topic
  model or topic twaddle? {R}e-evaluating semantic interpretability measures}.
\newblock In \emph{Conference of the North American Chapter of the Association
  for Computational Linguistics}. Association for Computational Linguistics.

\bibitem[{Eisenstein et~al.(2011)Eisenstein, Ahmed, and
  Xing}]{Eisenstein2011SparseAG}
Jacob Eisenstein, Amr Ahmed, and Eric~P. Xing. 2011.
\newblock \href {https://icml.cc/2011/papers/534\_icmlpaper.pdf} {Sparse
  additive generative models of text}.
\newblock In \emph{Proceedings of the International Conference of Machine
  Learning}. Omnipress.

\bibitem[{Ethayarajh and Jurafsky(2020)}]{ethayarajh2020utility}
Kawin Ethayarajh and Dan Jurafsky. 2020.
\newblock Utility is in the eye of the user: A critique of {NLP} leaderboard
  design.
\newblock In \emph{Proceedings of Empirical Methods in Natural Language
  Processing}. Association for Computational Linguistics.

\bibitem[{Feiveson(2002)}]{powerSim}
Alan~H. Feiveson. 2002.
\newblock \href {https://doi.org/10.1177/1536867X0200200201} {Power by
  simulation}.
\newblock In \emph{The Stata Journal}.

\bibitem[{Feng et~al.(2020)Feng, Zhang, Ding, Rao, and Xie}]{Feng2020ContextRN}
Jiachun Feng, Zusheng Zhang, Cheng Ding, Yanghui Rao, and Haoran Xie. 2020.
\newblock Context reinforced neural topic modeling over short texts.
\newblock In \emph{ArXiv}.

\bibitem[{Griffiths and Steyvers(2004)}]{Griffiths2004FindingST}
Thomas~L Griffiths and Mark Steyvers. 2004.
\newblock Finding scientific topics.
\newblock In \emph{Proceedings of the National Academy of Sciences}. National
  Academy of Sciences.

\bibitem[{Grimmer and Stewart(2013)}]{political}
Justin Grimmer and Brandon~M Stewart. 2013.
\newblock Text as data: {T}he promise and pitfalls of automatic content
  analysis methods for political texts.
\newblock In \emph{Political Analysis}. Cambridge University Press.

\bibitem[{Gui et~al.(2019)Gui, Leng, Pergola, Zhou, Xu, and
  He}]{Gui2019NeuralTM}
Lin Gui, Jia Leng, Gabriele Pergola, Yu~Zhou, Ruifeng Xu, and Yulan He. 2019.
\newblock \href {https://www.aclweb.org/anthology/D19-1350} {Neural topic model
  with reinforcement learning}.
\newblock In \emph{Proceedings of Empirical Methods in Natural Language
  Processing}. Association for Computational Linguistics.

\bibitem[{Gupta et~al.(2019{\natexlab{a}})Gupta, Chaudhary, Buettner, and
  Sch{\"u}tze}]{Gupta2019textTOvecDC}
Pankaj Gupta, Yatin Chaudhary, F.~Buettner, and Hinrich Sch{\"u}tze.
  2019{\natexlab{a}}.
\newblock \href {https://openreview.net/forum?id=rkgoyn09KQ} {{textTOvec}: Deep
  contextualized neural autoregressive models of language with distributed
  compositional prior}.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations}.

\bibitem[{Gupta et~al.(2019{\natexlab{b}})Gupta, Chaudhary, Buettner, and
  Sch{\"{u}}tze}]{Gupta2019DocumentIN}
Pankaj Gupta, Yatin Chaudhary, Florian Buettner, and Hinrich Sch{\"{u}}tze.
  2019{\natexlab{b}}.
\newblock \href {https://doi.org/10.1609/aaai.v33i01.33016505} {Document
  informed neural autoregressive topic models with distributional prior}.
\newblock In \emph{Association for the Advancement of Artificial Intelligence}.
  {AAAI} Press.

\bibitem[{He et~al.(2018)He, Zhang, Jin, Wang, Dang, and
  Li}]{He2018InteractionAwareTM}
Ruifang He, Xuefei Zhang, Di~Jin, Longbiao Wang, Jianwu Dang, and Xiangang Li.
  2018.
\newblock \href {https://www.aclweb.org/anthology/C18-1118} {Interaction-aware
  topic model for microblog conversations through network embedding and user
  attention}.
\newblock In \emph{International Conference on Computational Linguistics}.
  Association for Computational Linguistics.

\bibitem[{Honnibal et~al.(2020)Honnibal, Montani, Van~Landeghem, and
  Boyd}]{spacy}
Matthew Honnibal, Ines Montani, Sofie Van~Landeghem, and Adriane Boyd. 2020.
\newblock \href {https://doi.org/10.5281/zenodo.1212303} {{spaCy:
  Industrial-strength Natural Language Processing in Python}}.

\bibitem[{Hoyle et~al.(2020)Hoyle, Goel, and
  Resnik}]{hoyle-etal-2020-improving}
Alexander~Miserlis Hoyle, Pranav Goel, and Philip Resnik. 2020.
\newblock \href {https://www.aclweb.org/anthology/2020.emnlp-main.137}
  {{I}mproving {N}eural {T}opic {M}odels using {K}nowledge {D}istillation}.
\newblock In \emph{Proceedings of Empirical Methods in Natural Language
  Processing}. Association for Computational Linguistics.

\bibitem[{Hu et~al.(2020)Hu, Wang, Zhou, and Xiong}]{Hu2020NeuralTM}
Xuemeng Hu, Rui Wang, Deyu Zhou, and Yuxuan Xiong. 2020.
\newblock \href {https://www.aclweb.org/anthology/2020.emnlp-main.725} {Neural
  topic modeling with cycle-consistent adversarial training}.
\newblock In \emph{Proceedings of Empirical Methods in Natural Language
  Processing}. Association for Computational Linguistics.

\bibitem[{Isoaho et~al.(2021)Isoaho, Gritsenko, and
  Mäkelä}]{Karoliina2021Topic}
Karoliina Isoaho, Daria Gritsenko, and Eetu Mäkelä. 2021.
\newblock \href {https://doi.org/https://doi.org/10.1111/psj.12343} {Topic
  modeling and text analysis for qualitative policy research}.
\newblock In \emph{Policy Studies Journal}.

\bibitem[{Isonuma et~al.(2020)Isonuma, Mori, Bollegala, and
  Sakata}]{Isonuma2020TreeStructuredNT}
Masaru Isonuma, Junichiro Mori, Danushka Bollegala, and Ichiro Sakata. 2020.
\newblock \href {https://www.aclweb.org/anthology/2020.acl-main.73}
  {{T}ree-{S}tructured {N}eural {T}opic {M}odel}.
\newblock In \emph{Proceedings of the Association for Computational
  Linguistics}. Association for Computational Linguistics.

\bibitem[{Jankowiak and Obermeyer(2018)}]{Jankowiak2018PathwiseDB}
Martin Jankowiak and Fritz Obermeyer. 2018.
\newblock \href {http://proceedings.mlr.press/v80/jankowiak18a.html} {Pathwise
  derivatives beyond the reparameterization trick}.
\newblock In \emph{Proceedings of the International Conference of Machine
  Learning}. {PMLR}.

\bibitem[{Joo et~al.(2020)Joo, Lee, Park, and Moon}]{Joo2020DirichletVA}
Weonyoung Joo, Wonsung Lee, Sungrae Park, and Il-Chul Moon. 2020.
\newblock \href {https://doi.org/https://doi.org/10.1016/j.patcog.2020.107514}
  {Dirichlet variational autoencoder}.
\newblock \emph{Pattern Recognition}, 107:107514.

\bibitem[{Jung and Choi(2017)}]{Jung2017ContinuousST}
Namkyu Jung and Hyeong~In Choi. 2017.
\newblock \href {https://arxiv.org/abs/1711.08870} {Continuous semantic topic
  embedding model using variational autoencoder}.
\newblock In \emph{ArXiv}.

\bibitem[{Kingma and Ba(2015)}]{KingmaB14}
Diederik~P. Kingma and Jimmy Ba. 2015.
\newblock \href {http://arxiv.org/abs/1412.6980} {Adam: {A} method for
  stochastic optimization}.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations}.

\bibitem[{Krasnashchok and Jouili(2018)}]{krasnashchok2018improving}
Katsiaryna Krasnashchok and Salim Jouili. 2018.
\newblock \href {https://www.aclweb.org/anthology/P18-2040} {Improving topic
  quality by promoting named entities in topic modeling}.
\newblock In \emph{Proceedings of the Association for Computational
  Linguistics}. Association for Computational Linguistics.

\bibitem[{Krippendorff(2004)}]{kripp2004}
Klaus Krippendorff. 2004.
\newblock \emph{Content Analysis: an Introduction to its Methodology}.
\newblock {SAGE}.

\bibitem[{Lau et~al.(2014)Lau, Newman, and Baldwin}]{lau2014machine}
Jey~Han Lau, David Newman, and Timothy Baldwin. 2014.
\newblock \href {https://www.aclweb.org/anthology/E14-1056} {Machine reading
  tea leaves: Automatically evaluating topic coherence and topic model
  quality}.
\newblock In \emph{Conference of the North American Chapter of the Association
  for Computational Linguistics}. Association for Computational Linguistics.

\bibitem[{Levy and Goldberg(2014)}]{NIPS2014_feab05aa}
Omer Levy and Yoav Goldberg. 2014.
\newblock \href
  {https://proceedings.neurips.cc/paper/2014/hash/feab05aa91085b7a8012516bc3533958-Abstract.html}
  {Neural word embedding as implicit matrix factorization}.
\newblock In \emph{Proceedings of Advances in Neural Information Processing
  Systems}. Curran Associates, Inc.

\bibitem[{Lin et~al.(2020)Lin, Jiang, and Rao}]{Lin2020CopulaGN}
Lihui Lin, Hongyu Jiang, and Yanghui Rao. 2020.
\newblock \href {https://doi.org/10.1145/3397271.3401245} {Copula guided neural
  topic modelling for short texts}.
\newblock In \emph{Proceedings of the ACM SIGIR Conference on Research and
  Development in Information Retrieval}. {ACM}.

\bibitem[{Lin et~al.(2019)Lin, Hu, and Guo}]{Lin2019SparsemaxAR}
Tianyi Lin, Zhiyue Hu, and Xin Guo. 2019.
\newblock \href {https://doi.org/10.1145/3289600.3290957} {Sparsemax and
  relaxed wasserstein for topic sparsity}.
\newblock In \emph{International Conference on Web Search and Data Mining
  ({WSDM})}. {ACM}.

\bibitem[{Lipton(2018)}]{lipton2018mythos}
Zachary~C Lipton. 2018.
\newblock \href {https://doi.org/10.1145/3236386.3241340} {The mythos of model
  interpretability: {I}n machine learning, the concept of interpretability is
  both important and slippery.}
\newblock In \emph{Queue}. ACM.

\bibitem[{Liu et~al.(2016)Liu, Tang, Dong, Yao, and Zhou}]{Liu2016AnOO}
Lin Liu, Lin Tang, Wen Dong, Shaowen Yao, and Wei Zhou. 2016.
\newblock An overview of topic modeling and its current applications in
  bioinformatics.
\newblock In \emph{SpringerPlus}.

\bibitem[{Liu et~al.(2019)Liu, Huang, Gao, Zhang, and Wei}]{Liu2019NeuralVC}
Luyang Liu, Heyan Huang, Yang Gao, Yongfeng Zhang, and Xiaochi Wei. 2019.
\newblock \href {https://doi.org/10.1145/3308558.3313561} {Neural variational
  correlated topic modeling}.
\newblock In \emph{Proceedings of the World Wide Web Conference}. {ACM}.

\bibitem[{Lund et~al.(2019)Lund, Armstrong, Fearn, Cowley, Hales, and
  Seppi}]{lund-etal-2019-automated}
Jeffrey Lund, Piper Armstrong, Wilson Fearn, Stephen Cowley, Emily Hales, and
  Kevin Seppi. 2019.
\newblock \href {https://aclanthology.org/N19-1399} {Cross-referencing using
  fine-grained topic modeling}.
\newblock In \emph{Proceedings of the Association for Computational
  Linguistics}, Minneapolis, Minnesota. Association for Computational
  Linguistics.

\bibitem[{Mann and Whitney(1947)}]{mann1947u}
Henry~Berthold Mann and Donald~Ransom Whitney. 1947.
\newblock \href {https://doi.org/10.1214/aoms/1177730491} {{On a Test of
  Whether one of Two Random Variables is Stochastically Larger than the
  Other}}.
\newblock In \emph{The Annals of Mathematical Statistics}. Institute of
  Mathematical Statistics.

\bibitem[{Marche(2012)}]{marche2012humanities}
Stephen Marche. 2012.
\newblock \href {https://lareviewofbooks.org/article/literature-is-not-data-
  against-digital-humanities/} {Literature is not data: Against digital
  humanities}.
\newblock In \emph{{LA} Review of Books}.

\bibitem[{McCallum(2002)}]{McCallumMALLET}
Andrew~Kachites McCallum. 2002.
\newblock \href {http://mallet.cs.umass.edu/} {{MALLET}: A machine learning for
  language toolkit}.

\bibitem[{Meeks and Weingart(2012)}]{meeks2012digital}
Elijah Meeks and Scott~B Weingart. 2012.
\newblock The digital humanities contribution to topic modeling.
\newblock In \emph{Journal of Digital Humanities}.

\bibitem[{Merity et~al.(2017)Merity, Xiong, Bradbury, and
  Socher}]{merityPointerSentinelMixture2017}
Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. 2017.
\newblock \href {https://openreview.net/forum?id=Byj72udxe} {Pointer sentinel
  mixture models}.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations}.

\bibitem[{Miao et~al.(2017)Miao, Grefenstette, and
  Blunsom}]{Miao2017DiscoveringDL}
Yishu Miao, Edward Grefenstette, and Phil Blunsom. 2017.
\newblock \href {http://proceedings.mlr.press/v70/miao17a.html} {Discovering
  discrete latent topics with neural variational inference}.
\newblock In \emph{Proceedings of the International Conference of Machine
  Learning}. {PMLR}.

\bibitem[{Miao et~al.(2016)Miao, Yu, and Blunsom}]{Miao2016NeuralVI}
Yishu Miao, Lei Yu, and Phil Blunsom. 2016.
\newblock \href {http://proceedings.mlr.press/v48/miao16.html} {Neural
  variational inference for text processing}.
\newblock In \emph{Proceedings of the International Conference of Machine
  Learning}. PMLR.

\bibitem[{Mimno et~al.(2011)Mimno, Wallach, Talley, Leenders, and
  McCallum}]{mimno2011optimizing}
David Mimno, Hanna Wallach, Edmund Talley, Miriam Leenders, and Andrew
  McCallum. 2011.
\newblock \href {https://www.aclweb.org/anthology/D11-1024} {Optimizing
  semantic coherence in topic models}.
\newblock In \emph{Proceedings of Empirical Methods in Natural Language
  Processing}. Association for Computational Linguistics.

\bibitem[{Mohr and Bogdanov(2013)}]{MOHR2013545}
John~W. Mohr and Petko Bogdanov. 2013.
\newblock \href {https://www.sciencedirect.com/science/article/pii/
  S0304422X13000685} {Introduction—topic models: What they are and why they
  matter}.
\newblock In \emph{Poetics}.

\bibitem[{Morstatter and Liu(2018)}]{morstatter2018search}
Fred Morstatter and Huan Liu. 2018.
\newblock \href {http://jmlr.org/papers/v18/17-069.html} {In search of
  coherence and consensus: Measuring the interpretability of statistical
  topics}.
\newblock \emph{Journal of Machine Learning Research}.

\bibitem[{Nan et~al.(2019)Nan, Ding, Nallapati, and Xiang}]{Nan2019TopicMW}
Feng Nan, Ran Ding, Ramesh Nallapati, and Bing Xiang. 2019.
\newblock \href {https://www.aclweb.org/anthology/P19-1640} {Topic modeling
  with {W}asserstein autoencoders}.
\newblock In \emph{Proceedings of the Association for Computational
  Linguistics}. Association for Computational Linguistics.

\bibitem[{Newman et~al.(2010)Newman, Lau, Grieser, and
  Baldwin}]{newman2010automatic}
David Newman, Jey~Han Lau, Karl Grieser, and Timothy Baldwin. 2010.
\newblock \href {https://www.aclweb.org/anthology/N10-1012} {Automatic
  evaluation of topic coherence}.
\newblock In \emph{Conference of the North American Chapter of the Association
  for Computational Linguistics}. Association for Computational Linguistics.

\bibitem[{Nguyen et~al.(2015)Nguyen, Billingsley, Du, and
  Johnson}]{Nguyen2015ImprovingTM}
Dat~Quoc Nguyen, Richard Billingsley, Lan Du, and Mark Johnson. 2015.
\newblock \href {https://www.aclweb.org/anthology/Q15-1022} {Improving topic
  models with latent feature word representations}.
\newblock \emph{Transactions of the Association for Computational Linguistics}.

\bibitem[{Ning et~al.(2020)Ning, Zheng, Jiang, Wang, Yang, and
  Huang}]{Ning2020NonparametricTM}
Xuefei Ning, Y.~Zheng, Zhuxi Jiang, Y.~Wang, H.~Yang, and J.~Huang. 2020.
\newblock Nonparametric topic modeling with neural inference.
\newblock In \emph{Neurocomputing}.

\bibitem[{Panwar et~al.(2020)Panwar, Shailabh, Aggarwal, and
  Krishnamurthy}]{Panwar2020TANNTMTA}
Madhur Panwar, Shashank Shailabh, Milan Aggarwal, and Balaji Krishnamurthy.
  2020.
\newblock {TAN-NTM}: Topic attention networks for neural topic modeling.
\newblock In \emph{Proceedings of the Association for Computational
  Linguistics}.

\bibitem[{Peng et~al.(2018)Peng, Xie, Zhang, Wang, Zhang, Huang, and
  Tian}]{Peng2018NeuralST}
Min Peng, Qianqian Xie, Yanchun Zhang, Hua Wang, Xiuzhen Zhang, Jimin Huang,
  and Gang Tian. 2018.
\newblock \href {https://www.aclweb.org/anthology/P18-1217} {Neural sparse
  topical coding}.
\newblock In \emph{Proceedings of the Association for Computational
  Linguistics}. Association for Computational Linguistics.

\bibitem[{{\v R}eh{\r u}{\v r}ek and Sojka(2010)}]{rehurek_lrec}
Radim {\v R}eh{\r u}{\v r}ek and Petr Sojka. 2010.
\newblock {Software Framework for Topic Modelling with Large Corpora}.
\newblock In \emph{Proceedings of the Language Resources and Evaluation
  Conference}. ELRA.

\bibitem[{Rezaee and Ferraro(2020)}]{Rezaee2020ADV}
Mehdi Rezaee and Francis Ferraro. 2020.
\newblock \href
  {https://papers.nips.cc/paper/2020/hash/9f1d5659d5880fb427f6e04ae500fc25-Abstract.html}
  {A discrete variational recurrent topic model without the reparametrization
  trick}.
\newblock In \emph{Proceedings of Advances in Neural Information Processing
  Systems}. Curran Associates, Inc.

\bibitem[{R{\"{o}}der et~al.(2015)R{\"{o}}der, Both, and
  Hinneburg}]{roder2015exploring}
Michael R{\"{o}}der, Andreas Both, and Alexander Hinneburg. 2015.
\newblock \href {https://doi.org/10.1145/2684822.2685324} {Exploring the space
  of topic coherence measures}.
\newblock In \emph{International Conference on Web Search and Data Mining
  ({WSDM})}. {ACM}.

\bibitem[{Sandhaus(2008)}]{sandhaus2008new}
Evan Sandhaus. 2008.
\newblock The {N}ew {Y}ork {T}imes annotated corpus.
\newblock In \emph{{L}inguistic {D}ata {C}onsortium}.

\bibitem[{Schmidt(2012)}]{schmidt2012words}
Benjamin~M Schmidt. 2012.
\newblock \href {http://journalofdigitalhumanities.org/2-1/words-alone-by-
  benjamin-m-schmidt/} {Words alone: Dismantling topic models in the
  humanities}.
\newblock In \emph{Journal of Digital Humanities}.

\bibitem[{Schofield and Mimno(2016)}]{Schofield2016ComparingAT}
Alexandra Schofield and David Mimno. 2016.
\newblock \href {https://www.aclweb.org/anthology/Q16-1021} {Comparing apples
  to apple: The effects of stemmers on topic models}.
\newblock \emph{Transactions of the Association for Computational Linguistics}.

\bibitem[{Schuirmann(1987)}]{schuirmann1987comparison}
Donald~J Schuirmann. 1987.
\newblock A comparison of the two one-sided tests procedure and the power
  approach for assessing the equivalence of average bioavailability.
\newblock In \emph{Journal of pharmacokinetics and biopharmaceutics}. Springer.

\bibitem[{Silveira et~al.(2018)Silveira, Carvalho, Cristo, and
  Moens}]{Silveira2018TopicMU}
Denys Silveira, Andr\'{e} Carvalho, Marco Cristo, and Marie-Francine Moens.
  2018.
\newblock \href {https://doi.org/10.1109/IJCNN.2018.8489778} {{T}opic
  {M}odeling using {V}ariational {A}uto-{E}ncoders with {G}umbel-{S}oftmax and
  {L}ogistic-{N}ormal {M}ixture {D}istributions}.
\newblock In \emph{International Joint Conference on Neural Networks
  ({IJCNN})}.

\bibitem[{Srivastava and Sutton(2017)}]{Srivastava2017AutoencodingVI}
Akash Srivastava and Charles Sutton. 2017.
\newblock \href {https://openreview.net/forum?id=BybtVK9lg} {Autoencoding
  variational inference for topic models}.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations}.

\bibitem[{Stiennon et~al.(2020)Stiennon, Ouyang, Wu, Ziegler, Lowe, Voss,
  Radford, Amodei, and Christiano}]{Stiennon2020LearningTS}
Nisan Stiennon, Long Ouyang, Jeff Wu, Daniel~M. Ziegler, Ryan~J. Lowe, Chelsea
  Voss, Alec Radford, Dario Amodei, and Paul Christiano. 2020.
\newblock \href
  {https://proceedings.neurips.cc/paper/2020/file/1f89885d556929e98d3ef9b86448f951-Paper.pdf}
  {Learning to summarize from human feedback}.
\newblock In \emph{Proceedings of Advances in Neural Information Processing
  Systems}. Curran Associates, Inc.

\bibitem[{Strathern(1997)}]{Strathern1997ImprovingRA}
Marilyn Strathern. 1997.
\newblock \href
  {https://doi.org/10.1002/(SICI)1234-981X(199707)5:3%3C305::AID-EURO184%3E3.0.CO;2-4}
  {{I}mproving {R}atings: {A}udit in the british university system}.
\newblock In \emph{European Review}. Cambridge University Press.

\bibitem[{Terragni et~al.(2021)Terragni, Fersini, Galuzzi, Tropeano, and
  Candelieri}]{terragni2020octis}
Silvia Terragni, Elisabetta Fersini, Bruno~Giovanni Galuzzi, Pietro Tropeano,
  and Antonio Candelieri. 2021.
\newblock \href {https://www.aclweb.org/anthology/2021.eacl-demos.31} {{OCTIS}:
  Comparing and optimizing topic models is simple!}
\newblock In \emph{Conference of the North American Chapter of the Association
  for Computational Linguistics}. Association for Computational Linguistics.

\bibitem[{Thompson and Mimno(2020)}]{Thompson2020TopicMW}
Laure Thompson and D.~Mimno. 2020.
\newblock \href {https://arxiv.org/abs/2010.12626} {Topic modeling with
  contextualized word representation clusters}.
\newblock In \emph{ArXiv}.

\bibitem[{Tian et~al.(2020)Tian, Mao, and Zhang}]{Tian2020LearningVM}
Runzhi Tian, Yongyi Mao, and Richong Zhang. 2020.
\newblock \href {https://www.aclweb.org/anthology/2020.emnlp-main.101}
  {Learning {VAE}-{LDA} models with rounded reparameterization trick}.
\newblock In \emph{Proceedings of Empirical Methods in Natural Language
  Processing}. Association for Computational Linguistics.

\bibitem[{Underwood(2017)}]{underwoodGenealogy2017}
{William E} Underwood. 2017.
\newblock A genealogy of distant reading.
\newblock In \emph{Digital Humanities Quarterly}. Alliance of Digital
  Humanities Organisations.

\bibitem[{Wang et~al.(2020{\natexlab{a}})Wang, Hu, Zhou, He, Xiong, Ye, and
  Xu}]{Wang2020NeuralTM}
Rui Wang, Xuemeng Hu, Deyu Zhou, Yulan He, Yuxuan Xiong, Chenchen Ye, and
  Haiyang Xu. 2020{\natexlab{a}}.
\newblock \href {https://www.aclweb.org/anthology/2020.acl-main.32} {Neural
  topic modeling with bidirectional adversarial training}.
\newblock In \emph{Proceedings of the Association for Computational
  Linguistics}. Association for Computational Linguistics.

\bibitem[{Wang et~al.(2020{\natexlab{b}})Wang, Zhou, and He}]{Wang2019ATMAT}
Rui Wang, Deyu Zhou, and Yulan He. 2020{\natexlab{b}}.
\newblock {ATM}: Adversarial-neural topic model.
\newblock In \emph{Proceedings of the Association for Computational
  Linguistics}.

\bibitem[{Wellek(2010)}]{wellek2010testing}
Stefan Wellek. 2010.
\newblock \href {https://www.taylorfrancis.com/books/9780429092671}
  {\emph{Testing {Statistical} {Hypotheses} of {Equivalence} and
  {Noninferiority}}}.
\newblock Chapman and Hall/CRC.

\bibitem[{Wu et~al.(2020{\natexlab{a}})Wu, Rao, Zhang, Xie, Li, Wang, and
  Chen}]{Wu2020NeuralMC}
Jiemin Wu, Yanghui Rao, Zusheng Zhang, Haoran Xie, Qing Li, Fu~Lee Wang, and
  Ziye Chen. 2020{\natexlab{a}}.
\newblock \href {https://www.aclweb.org/anthology/2020.acl-main.548} {Neural
  mixed counting models for dispersed topic discovery}.
\newblock In \emph{Proceedings of the Association for Computational
  Linguistics}. Association for Computational Linguistics.

\bibitem[{Wu et~al.(2020{\natexlab{b}})Wu, Li, Zhu, and Miao}]{Wu2020ShortTT}
Xiaobao Wu, Chunping Li, Yan Zhu, and Yishu Miao. 2020{\natexlab{b}}.
\newblock \href {https://www.aclweb.org/anthology/2020.emnlp-main.138} {Short
  text topic modeling with topic distribution quantization and negative
  sampling decoder}.
\newblock In \emph{Proceedings of Empirical Methods in Natural Language
  Processing}. Association for Computational Linguistics.

\bibitem[{Yang et~al.(2020)Yang, Wu, Gu, Wang, Cao, Jin, and
  Guo}]{Yang2020GraphAT}
Liang Yang, Fan Wu, Junhua Gu, Chuan Wang, Xiaochun Cao, Di~Jin, and Yuanfang
  Guo. 2020.
\newblock \href {https://doi.org/10.1145/3366423.3380102} {Graph attention
  topic modeling network}.
\newblock In \emph{Proceedings of the World Wide Web Conference}. {ACM}.

\bibitem[{Zhang et~al.(2018)Zhang, Chen, Guo, and Zhou}]{Zhang2018WHAIWH}
Hao Zhang, Bo~Chen, Dandan Guo, and Mingyuan Zhou. 2018.
\newblock \href {https://openreview.net/forum?id=S1cZsf-RW} {{WHAI:} weibull
  hybrid autoencoding inference for deep topic modeling}.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations}.

\bibitem[{Zhao et~al.(2018)Zhao, Du, Buntine, and Zhou}]{Zhao2018DirichletBN}
He~Zhao, Lan Du, Wray~L. Buntine, and Mingyuan Zhou. 2018.
\newblock \href
  {https://proceedings.neurips.cc/paper/2018/hash/eaae5e04a259d09af85c108fe4d7dd0c-Abstract.html}
  {Dirichlet belief networks for topic structure learning}.
\newblock In \emph{Proceedings of Advances in Neural Information Processing
  Systems}. Curran Associates, Inc.

\bibitem[{Zhao et~al.(2021{\natexlab{a}})Zhao, Phung, Huynh, Le, and
  Buntine}]{zhao2021neural}
He~Zhao, Dinh Phung, Viet Huynh, Trung Le, and Wray Buntine.
  2021{\natexlab{a}}.
\newblock \href {https://openreview.net/forum?id=Oos98K9Lv-k} {Neural topic
  model via optimal transport}.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations}.

\bibitem[{Zhao et~al.(2021{\natexlab{b}})Zhao, Phung, Huynh, Jin, Du, and
  Buntine}]{Zhao2021TopicMM}
He~Zhao, Dinh~Q. Phung, Viet Huynh, Y.~Jin, Lan Du, and W.~Buntine.
  2021{\natexlab{b}}.
\newblock Topic modelling meets deep neural networks: A survey.
\newblock In \emph{ArXiv}.

\bibitem[{Zhou et~al.(2020)Zhou, Hu, and Wang}]{Zhou2020NeuralTM}
Deyu Zhou, Xuemeng Hu, and Rui Wang. 2020.
\newblock \href {https://www.aclweb.org/anthology/2020.emnlp-main.310} {Neural
  topic modeling by incorporating document relationship graph}.
\newblock In \emph{Proceedings of Empirical Methods in Natural Language
  Processing}. Association for Computational Linguistics.

\bibitem[{Zhu et~al.(2018)Zhu, Feng, and Li}]{Zhu2018GraphBTMGE}
Qile Zhu, Zheng Feng, and Xiaolin Li. 2018.
\newblock \href {https://www.aclweb.org/anthology/D18-1495} {{G}raph{BTM}:
  Graph enhanced autoencoded variational inference for biterm topic model}.
\newblock In \emph{Proceedings of Empirical Methods in Natural Language
  Processing}. Association for Computational Linguistics.

\bibitem[{Zipf(1949)}]{Zipf49}
George~K. Zipf. 1949.
\newblock \emph{Human Behaviour and the Principle of Least Effort}.
\newblock Addison-Wesley.

\end{thebibliography}
