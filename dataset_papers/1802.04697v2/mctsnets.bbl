\begin{thebibliography}{28}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Anthony et~al.(2017)Anthony, Tian, and Barber]{anthony2017thinking}
Anthony, T., Tian, Z., and Barber, D.
\newblock Thinking fast and slow with deep learning and tree search.
\newblock \emph{arXiv preprint arXiv:1705.08439}, 2017.

\bibitem[Arbib(2003)]{arbib2003handbook}
Arbib, M.~A.
\newblock \emph{The handbook of brain theory and neural networks}.
\newblock MIT press, 2003.

\bibitem[Auer(2002)]{auer2002ucb}
Auer, P.
\newblock Using confidence bounds for exploitation-exploration trade-offs.
\newblock \emph{Journal of Machine Learning Research}, 3\penalty0
  (Nov):\penalty0 397--422, 2002.

\bibitem[Baxter et~al.(1998)Baxter, Tridgell, and Weaver]{baxter1998knightcap}
Baxter, J., Tridgell, A., and Weaver, L.
\newblock Knightcap: A chess program that learns by combining td ($\lambda$)
  with game-tree search.
\newblock In \emph{Proceedings of the 15th International Conference on Machine
  Learning}, 1998.

\bibitem[Botea et~al.(2003)Botea, M{\"u}ller, and Schaeffer]{botea2003soko}
Botea, A., M{\"u}ller, M., and Schaeffer, J.
\newblock Using abstraction for planning in sokoban.
\newblock In \emph{Computers and Games}, volume 2883, pp.\  360, 2003.

\bibitem[Chang et~al.(2015)Chang, Krishnamurthy, Agarwal, Daume, and
  Langford]{chang2015learntosearch}
Chang, K.-W., Krishnamurthy, A., Agarwal, A., Daume, H., and Langford, J.
\newblock Learning to search better than your teacher.
\newblock In \emph{Proceedings of the 32nd International Conference on Machine
  Learning (ICML-15)}, pp.\  2058--2066, 2015.

\bibitem[Coulom(2006)]{coulom2006mcts}
Coulom, R.
\newblock Efficient selectivity and backup operators in monte-carlo tree
  search.
\newblock In \emph{International conference on computers and games}, pp.\
  72--83. Springer, 2006.

\bibitem[Farquhar et~al.(2017)Farquhar, Rockt{\"a}schel, Igl, and
  Whiteson]{farquhar2017treeqn}
Farquhar, G., Rockt{\"a}schel, T., Igl, M., and Whiteson, S.
\newblock Treeqn and atreec: Differentiable tree planning for deep
  reinforcement learning.
\newblock In \emph{ICLR}, 2017.

\bibitem[Hay \& Russell(2011)Hay and Russell]{hay2011metamcts}
Hay, N. and Russell, S.~J.
\newblock Metareasoning for monte carlo tree search.
\newblock Technical Report UCB/EECS-2011-119, EECS Department, University of
  California, Berkeley, 2011.

\bibitem[J{\"u}nger et~al.(2009)J{\"u}nger, Liebling, Naddef, Nemhauser,
  Pulleyblank, Reinelt, Rinaldi, and Wolsey]{junger200950}
J{\"u}nger, M., Liebling, T.~M., Naddef, D., Nemhauser, G.~L., Pulleyblank,
  W.~R., Reinelt, G., Rinaldi, G., and Wolsey, L.~A.
\newblock \emph{50 years of integer programming 1958-2008: From the early years
  to the state-of-the-art}.
\newblock Springer, 2009.

\bibitem[Knuth \& Moore(1975)Knuth and Moore]{knuth1975alphabeta}
Knuth, D.~E. and Moore, R.~W.
\newblock An analysis of alpha-beta pruning.
\newblock \emph{Artificial intelligence}, 6\penalty0 (4):\penalty0 293--326,
  1975.

\bibitem[Kocsis \& Szepesv{\'a}ri(2006)Kocsis and
  Szepesv{\'a}ri]{kocsis2006uct}
Kocsis, L. and Szepesv{\'a}ri, C.
\newblock Bandit based monte-carlo planning.
\newblock In \emph{ECML}, volume~6, pp.\  282--293. Springer, 2006.

\bibitem[Kocsis et~al.(2005)Kocsis, Szepesv{\'a}ri, and
  Winands]{kocsis2005rspsa}
Kocsis, L., Szepesv{\'a}ri, C., and Winands, M.~H.
\newblock {RSPSA}: enhanced parameter optimization in games.
\newblock In \emph{Advances in Computer Games}, pp.\  39--56. Springer, 2005.

\bibitem[Pascanu et~al.(2017)Pascanu, Li, Vinyals, Heess, Buesing,
  Racani{\`e}re, Reichert, Weber, Wierstra, and Battaglia]{pascanu2017ibp}
Pascanu, R., Li, Y., Vinyals, O., Heess, N., Buesing, L., Racani{\`e}re, S.,
  Reichert, D., Weber, T., Wierstra, D., and Battaglia, P.
\newblock Learning model-based planning from scratch.
\newblock \emph{arXiv preprint arXiv:1707.06170}, 2017.

\bibitem[Rosin(2011)]{rosin2011puct}
Rosin, C.~D.
\newblock Multi-armed bandits with episode context.
\newblock \emph{Annals of Mathematics and Artificial Intelligence}, 61\penalty0
  (3):\penalty0 203--230, 2011.

\bibitem[Russell(1995)]{russell1995rationality}
Russell, S.
\newblock Rationality and intelligence.
\newblock In \emph{Proceedings of the 14th international joint conference on
  Artificial intelligence-Volume 1}, pp.\  950--957. Morgan Kaufmann Publishers
  Inc., 1995.

\bibitem[Russell \& Wefald(1989)Russell and Wefald]{russell1989meta}
Russell, S. and Wefald, E.
\newblock On optimal game-tree search using rational meta-reasoning.
\newblock In \emph{Proceedings of the 11th international joint conference on
  Artificial intelligence-Volume 1}, pp.\  334--340, 1989.

\bibitem[Samuel(1959)]{samuel1959checkers}
Samuel, A.
\newblock Some studies in machine learning using the game of checkers.
\newblock \emph{IBM Journal of Research and Development}, 3\penalty0
  (3):\penalty0 210, 1959.

\bibitem[Schaeffer(2000)]{schaeffer2000games}
Schaeffer, J.
\newblock The games computers (and people) play.
\newblock \emph{Advances in computers}, 52:\penalty0 189--266, 2000.

\bibitem[Schaeffer et~al.(2001)Schaeffer, Hlynka, and
  Jussila]{schaeffer2001tdleaf}
Schaeffer, J., Hlynka, M., and Jussila, V.
\newblock Temporal difference learning applied to a high-performance
  game-playing program.
\newblock In \emph{Proceedings of the 17th international joint conference on
  Artificial intelligence-Volume 1}, pp.\  529--534. Morgan Kaufmann Publishers
  Inc., 2001.

\bibitem[Schulman et~al.(2015)Schulman, Heess, Weber, and
  Abbeel]{schulman2015gradient}
Schulman, J., Heess, N., Weber, T., and Abbeel, P.
\newblock Gradient estimation using stochastic computation graphs.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3528--3536, 2015.

\bibitem[Silver et~al.(2016)Silver, Huang, Maddison, Guez, Sifre, Van
  Den~Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot,
  et~al.]{silver2016mastering}
Silver, D., Huang, A., Maddison, C.~J., Guez, A., Sifre, L., Van Den~Driessche,
  G., Schrittwieser, J., Antonoglou, I., Panneershelvam, V., Lanctot, M.,
  et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock \emph{Nature}, 529\penalty0 (7587):\penalty0 484--489, 2016.

\bibitem[Silver et~al.(2017{\natexlab{a}})Silver, Schrittwieser, Simonyan,
  Antonoglou, Huang, Guez, Hubert, Baker, et~al.]{silver2017mastering}
Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez,
  A., Hubert, T., Baker, L., et~al.
\newblock Mastering the game of go without human knowledge.
\newblock \emph{Nature}, 550:\penalty0 354--359, 2017{\natexlab{a}}.

\bibitem[Silver et~al.(2017{\natexlab{b}})Silver, van Hasselt, Hessel, Schaul,
  Guez, Harley, Dulac-Arnold, Reichert, Rabinowitz, Barreto,
  et~al.]{silver2016predictron}
Silver, D., van Hasselt, H., Hessel, M., Schaul, T., Guez, A., Harley, T.,
  Dulac-Arnold, G., Reichert, D., Rabinowitz, N., Barreto, A., et~al.
\newblock The predictron: End-to-end learning and planning.
\newblock In \emph{ICML}, 2017{\natexlab{b}}.

\bibitem[Tesauro(1988)]{tesauro1988comparison}
Tesauro, G.
\newblock Connectionist learning of expert preferences by comparison training.
\newblock In \emph{Advances in Neural Information Processing}, pp.\  99--106,
  1988.

\bibitem[Tesauro(1994)]{tesauro1994tdgammon}
Tesauro, G.
\newblock {TD}-gammon, a self-teaching backgammon program, achieves
  master-level play.
\newblock \emph{Neural Computation}, 6:\penalty0 215--219, 1994.

\bibitem[Veness et~al.(2009)Veness, Silver, Blair, and
  Uther]{veness2009rootstrap}
Veness, J., Silver, D., Blair, A., and Uther, W.
\newblock Bootstrapping from game tree search.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1937--1945, 2009.

\bibitem[Weber et~al.(2017)Weber, Racani{\`e}re, Reichert, Buesing, Guez,
  Rezende, Badia, Vinyals, Heess, Li, et~al.]{weber2017imagination}
Weber, T., Racani{\`e}re, S., Reichert, D.~P., Buesing, L., Guez, A., Rezende,
  D.~J., Badia, A.~P., Vinyals, O., Heess, N., Li, Y., et~al.
\newblock Imagination-augmented agents for deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1707.06203}, 2017.

\end{thebibliography}
