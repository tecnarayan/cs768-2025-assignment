\begin{thebibliography}{65}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[As{\'\i}n et~al.(2009)As{\'\i}n, Nieuwenhuis, Oliveras, and
  Rodr{\'\i}guez-Carbonell]{asin2009cardinality}
Roberto As{\'\i}n, Robert Nieuwenhuis, Albert Oliveras, and Enric
  Rodr{\'\i}guez-Carbonell.
\newblock Cardinality networks and their applications.
\newblock In \emph{International Conference on Theory and Applications of
  Satisfiability Testing}, pages 167--180. Springer, 2009.

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and
  Wagner]{athalye2018obfuscated}
Anish Athalye, Nicholas Carlini, and David Wagner.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In Jennifer Dy and Andreas Krause, editors, \emph{Proceedings of the
  35th International Conference on Machine Learning}, volume~80 of
  \emph{Proceedings of Machine Learning Research}, pages 274--283,
  Stockholmsmässan, Stockholm Sweden, 10--15 Jul 2018. PMLR.

\bibitem[Audemard and Simon(2018)]{audemard2018glucose}
Gilles Audemard and Laurent Simon.
\newblock On the {G}lucose {SAT} solver.
\newblock \emph{International Journal on Artificial Intelligence Tools},
  27\penalty0 (01):\penalty0 1840001, 2018.

\bibitem[Baluta et~al.(2019)Baluta, Shen, Shinde, Meel, and
  Saxena]{baluta2019quantitative}
Teodora Baluta, Shiqi Shen, Shweta Shinde, Kuldeep~S Meel, and Prateek Saxena.
\newblock Quantitative verification of neural networks and its security
  applications.
\newblock In \emph{Proceedings of the 2019 ACM SIGSAC Conference on Computer
  and Communications Security}, pages 1249--1264, 2019.

\bibitem[Balyo et~al.(2017)Balyo, Heule, and Jarvisalo]{balyo2017sat}
Tom{\'a}s Balyo, Marijn~JH Heule, and Matti Jarvisalo.
\newblock {SAT} competition 2016: Recent developments.
\newblock In \emph{Thirty-First AAAI Conference on Artificial Intelligence},
  2017.

\bibitem[Bengio et~al.(2013)Bengio, L{\'e}onard, and
  Courville]{bengio2013estimating}
Yoshua Bengio, Nicholas L{\'e}onard, and Aaron Courville.
\newblock Estimating or propagating gradients through stochastic neurons for
  conditional computation.
\newblock \emph{arXiv preprint arXiv:1308.3432}, 2013.

\bibitem[Bethge et~al.(2019)Bethge, Yang, Bornstein, and
  Meinel]{bethge2019back}
Joseph Bethge, Haojin Yang, Marvin Bornstein, and Christoph Meinel.
\newblock Back to simplicity: How to train accurate bnns from scratch?
\newblock \emph{arXiv preprint arXiv:1906.08637}, 2019.

\bibitem[Biere et~al.(2009)Biere, Heule, and van Maaren]{biere2009handbook}
Armin Biere, Marijn Heule, and Hans van Maaren.
\newblock \emph{Handbook of satisfiability}, volume 185.
\newblock IOS press, 2009.

\bibitem[Buckman et~al.(2018)Buckman, Roy, Raffel, and
  Goodfellow]{buckman2018thermometer}
Jacob Buckman, Aurko Roy, Colin Raffel, and Ian Goodfellow.
\newblock Thermometer encoding: One hot way to resist adversarial examples.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Bunel et~al.(2018)Bunel, Turkaslan, Torr, Kohli, and
  Mudigonda]{bunel2018unified}
Rudy~R Bunel, Ilker Turkaslan, Philip Torr, Pushmeet Kohli, and Pawan~K
  Mudigonda.
\newblock A unified view of piecewise linear neural network verification.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  4790--4799, 2018.

\bibitem[Carlini and Wagner(2017)]{carlini2017towards}
Nicholas Carlini and David Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{2017 ieee symposium on security and privacy (sp)}, pages
  39--57. IEEE, 2017.

\bibitem[Cheng et~al.(2017)Cheng, N{\"u}hrenberg, and Ruess]{cheng2017maximum}
Chih-Hong Cheng, Georg N{\"u}hrenberg, and Harald Ruess.
\newblock Maximum resilience of artificial neural networks.
\newblock In \emph{International Symposium on Automated Technology for
  Verification and Analysis}, pages 251--268. Springer, 2017.

\bibitem[Cheng et~al.(2018)Cheng, N{\"u}hrenberg, Huang, and
  Ruess]{cheng2018verification}
Chih-Hong Cheng, Georg N{\"u}hrenberg, Chung-Hao Huang, and Harald Ruess.
\newblock Verification of binarized neural networks via inter-neuron factoring.
\newblock In \emph{Working Conference on Verified Software: Theories, Tools,
  and Experiments}, pages 279--290. Springer, 2018.

\bibitem[Cook(1971)]{cook1971complexity}
Stephen~A Cook.
\newblock The complexity of theorem-proving procedures.
\newblock In \emph{Proceedings of the third annual ACM symposium on Theory of
  computing}, pages 151--158, 1971.

\bibitem[De~Moura and Bj{\o}rner(2008)]{de2008z3}
Leonardo De~Moura and Nikolaj Bj{\o}rner.
\newblock Z3: An efficient smt solver.
\newblock In \emph{International conference on Tools and Algorithms for the
  Construction and Analysis of Systems}, pages 337--340. Springer, 2008.

\bibitem[Devriendt et~al.(2020)Devriendt, Gleixner, and
  Nordstr{\"o}m]{devriendt2020learn}
Jo~Devriendt, Ambros Gleixner, and Jakob Nordstr{\"o}m.
\newblock Learn to relax: Integrating 0-1 integer linear programming with
  pseudo-boolean conflict-driven search.
\newblock 2020.

\bibitem[Dutta et~al.(2018)Dutta, Jha, Sankaranarayanan, and
  Tiwari]{dutta2018output}
Souradeep Dutta, Susmit Jha, Sriram Sankaranarayanan, and Ashish Tiwari.
\newblock Output range analysis for deep feedforward neural networks.
\newblock In \emph{NASA Formal Methods Symposium}, pages 121--138. Springer,
  2018.

\bibitem[Dvijotham et~al.(2018)Dvijotham, Gowal, Stanforth, Arandjelovic,
  O'Donoghue, Uesato, and Kohli]{dvijotham2018training}
Krishnamurthy Dvijotham, Sven Gowal, Robert Stanforth, Relja Arandjelovic,
  Brendan O'Donoghue, Jonathan Uesato, and Pushmeet Kohli.
\newblock Training verified learners with learned verifiers.
\newblock \emph{arXiv preprint arXiv:1805.10265}, 2018.

\bibitem[E{\'e}n and S{\"o}rensson(2003)]{een2003extensible}
Niklas E{\'e}n and Niklas S{\"o}rensson.
\newblock An extensible {SAT}-solver.
\newblock In \emph{International conference on theory and applications of
  satisfiability testing}, pages 502--518. Springer, 2003.

\bibitem[Ehlers(2017)]{ehlers2017formal}
Ruediger Ehlers.
\newblock Formal verification of piece-wise linear feed-forward neural
  networks.
\newblock In \emph{International Symposium on Automated Technology for
  Verification and Analysis}, pages 269--286. Springer, 2017.

\bibitem[Fischetti and Jo(2018)]{fischetti2018deep}
Matteo Fischetti and Jason Jo.
\newblock Deep neural networks and mixed integer linear optimization.
\newblock \emph{Constraints}, 23\penalty0 (3):\penalty0 296--309, 2018.

\bibitem[Frankle and Carbin(2019)]{frankle2018the}
Jonathan Frankle and Michael Carbin.
\newblock The lottery ticket hypothesis: Finding sparse, trainable neural
  networks.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Galloway et~al.(2018)Galloway, Taylor, and
  Moussa]{galloway2018attacking}
Angus Galloway, Graham~W. Taylor, and Medhat Moussa.
\newblock Attacking binarized neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=HkTEFfZRb}.

\bibitem[Ganesh et~al.(2012)Ganesh, O’donnell, Soos, Devadas, Rinard, and
  Solar-Lezama]{ganesh2012lynx}
Vijay Ganesh, Charles~W O’donnell, Mate Soos, Srinivas Devadas, Martin~C
  Rinard, and Armando Solar-Lezama.
\newblock Lynx: A programmatic {SAT} solver for the {RNA}-folding problem.
\newblock In \emph{International Conference on Theory and Applications of
  Satisfiability Testing}, pages 143--156. Springer, 2012.

\bibitem[Gehr et~al.(2018)Gehr, Mirman, Drachsler-Cohen, Tsankov, Chaudhuri,
  and Vechev]{gehr2018ai2}
Timon Gehr, Matthew Mirman, Dana Drachsler-Cohen, Petar Tsankov, Swarat
  Chaudhuri, and Martin Vechev.
\newblock Ai2: Safety and robustness certification of neural networks with
  abstract interpretation.
\newblock In \emph{2018 IEEE Symposium on Security and Privacy (SP)}, pages
  3--18. IEEE, 2018.

\bibitem[Goodfellow et~al.(2016)Goodfellow, Bengio, and Courville]{ian2016deep}
Ian Goodfellow, Yoshua Bengio, and Aaron Courville.
\newblock \emph{Deep Learning}.
\newblock MIT Press, 2016.
\newblock \url{http://www.deeplearningbook.org}.

\bibitem[Han et~al.(2015)Han, Pool, Tran, and Dally]{han2015learning}
Song Han, Jeff Pool, John Tran, and William Dally.
\newblock Learning both weights and connections for efficient neural network.
\newblock In \emph{Advances in neural information processing systems}, pages
  1135--1143, 2015.

\bibitem[Huang et~al.(2017)Huang, Kwiatkowska, Wang, and Wu]{huang2017safety}
Xiaowei Huang, Marta Kwiatkowska, Sen Wang, and Min Wu.
\newblock Safety verification of deep neural networks.
\newblock In \emph{International Conference on Computer Aided Verification},
  pages 3--29. Springer, 2017.

\bibitem[Hubara et~al.(2016)Hubara, Courbariaux, Soudry, El-Yaniv, and
  Bengio]{hubara2016binarized}
Itay Hubara, Matthieu Courbariaux, Daniel Soudry, Ran El-Yaniv, and Yoshua
  Bengio.
\newblock Binarized neural networks.
\newblock In D.~D. Lee, M.~Sugiyama, U.~V. Luxburg, I.~Guyon, and R.~Garnett,
  editors, \emph{Advances in Neural Information Processing Systems 29}, pages
  4107--4115. Curran Associates, Inc., 2016.

\bibitem[Ioffe and Szegedy(2015)]{ioffe2015batch}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock \emph{arXiv preprint arXiv:1502.03167}, 2015.

\bibitem[Jacob et~al.(2018)Jacob, Kligys, Chen, Zhu, Tang, Howard, Adam, and
  Kalenichenko]{jacob2018quantization}
Benoit Jacob, Skirmantas Kligys, Bo~Chen, Menglong Zhu, Matthew Tang, Andrew
  Howard, Hartwig Adam, and Dmitry Kalenichenko.
\newblock Quantization and training of neural networks for efficient
  integer-arithmetic-only inference.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 2704--2713, 2018.

\bibitem[Jia and Rinard(2020)]{jia2020exploiting}
Kai Jia and Martin Rinard.
\newblock Exploiting verified neural networks via floating point numerical
  error.
\newblock \emph{arXiv preprint arXiv:2003.03021}, 2020.

\bibitem[Jonas and Evans(2020)]{jonas2020certifying}
Mainuddin~Ahmad Jonas and David Evans.
\newblock Certifying joint adversarial robustness for model ensembles.
\newblock \emph{arXiv preprint arXiv:2004.10250}, 2020.

\bibitem[Katz et~al.(2017)Katz, Barrett, Dill, Julian, and
  Kochenderfer]{katz2017reluplex}
Guy Katz, Clark Barrett, David~L Dill, Kyle Julian, and Mykel~J Kochenderfer.
\newblock Reluplex: An efficient smt solver for verifying deep neural networks.
\newblock In \emph{International Conference on Computer Aided Verification},
  pages 97--117. Springer, 2017.

\bibitem[Khalil et~al.(2019)Khalil, Gupta, and
  Dilkina]{khalil2018combinatorial}
Elias~B Khalil, Amrita Gupta, and Bistra Dilkina.
\newblock Combinatorial attacks on binarized neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Liffiton and Maglalang(2012)]{liffiton2012cardinality}
Mark~H Liffiton and Jordyn~C Maglalang.
\newblock A cardinality solver: more expressive constraints for free.
\newblock In \emph{International Conference on Theory and Applications of
  Satisfiability Testing}, pages 485--486. Springer, 2012.

\bibitem[Lomuscio and Maganti(2017)]{lomuscio2017approach}
Alessio Lomuscio and Lalit Maganti.
\newblock An approach to reachability analysis for feed-forward relu neural
  networks.
\newblock \emph{arXiv preprint arXiv:1706.07351}, 2017.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2018towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Marques-Silva et~al.(2009)Marques-Silva, Lynce, and
  Malik]{marques2009conflict}
Joao Marques-Silva, In{\^e}s Lynce, and Sharad Malik.
\newblock Conflict-driven clause learning {SAT} solvers.
\newblock In \emph{Handbook of satisfiability}, pages 131--153. ios Press,
  2009.

\bibitem[Mirman et~al.(2018)Mirman, Gehr, and Vechev]{mirman2018differentiable}
Matthew Mirman, Timon Gehr, and Martin Vechev.
\newblock Differentiable abstract interpretation for provably robust neural
  networks.
\newblock In Jennifer Dy and Andreas Krause, editors, \emph{Proceedings of the
  35th International Conference on Machine Learning}, volume~80 of
  \emph{Proceedings of Machine Learning Research}, pages 3578--3586,
  Stockholmsmässan, Stockholm Sweden, 10--15 Jul 2018. PMLR.

\bibitem[Moskewicz et~al.(2001)Moskewicz, Madigan, Zhao, Zhang, and
  Malik]{moskewicz2001chaff}
Matthew~W Moskewicz, Conor~F Madigan, Ying Zhao, Lintao Zhang, and Sharad
  Malik.
\newblock Chaff: Engineering an efficient {SAT} solver.
\newblock In \emph{Proceedings of the 38th annual Design Automation
  Conference}, pages 530--535, 2001.

\bibitem[Moss et~al.(2017)Moss, Nurvitadhi, Sim, Mishra, Marr, Subhaschandra,
  and Leong]{moss2017high}
Duncan~JM Moss, Eriko Nurvitadhi, Jaewoong Sim, Asit Mishra, Debbie Marr,
  Suchit Subhaschandra, and Philip~HW Leong.
\newblock High performance binary neural networks on the
  {Xeon}+{FPGA}\texttrademark platform.
\newblock In \emph{2017 27th International Conference on Field Programmable
  Logic and Applications (FPL)}, pages 1--4. IEEE, 2017.

\bibitem[Narodytska et~al.(2018)Narodytska, Kasiviswanathan, Ryzhyk, Sagiv, and
  Walsh]{narodytska2018verifying}
Nina Narodytska, Shiva Kasiviswanathan, Leonid Ryzhyk, Mooly Sagiv, and Toby
  Walsh.
\newblock Verifying properties of binarized deep neural networks.
\newblock In \emph{Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem[Narodytska et~al.(2020)Narodytska, Zhang, Gupta, and
  Walsh]{narodytska2020in}
Nina Narodytska, Hongce Zhang, Aarti Gupta, and Toby Walsh.
\newblock In search for a {SAT}-friendly binarized neural network architecture.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{NEURIPS2019_9015}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith
  Chintala.
\newblock {P}y{T}orch: An imperative style, high-performance deep learning
  library.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, \emph{Advances in Neural
  Information Processing Systems 32}, pages 8024--8035. Curran Associates,
  Inc., 2019.

\bibitem[Pipatsrisawat and Darwiche(2007)]{pipatsrisawat2007lightweight}
Knot Pipatsrisawat and Adnan Darwiche.
\newblock A lightweight component caching scheme for satisfiability solvers.
\newblock In \emph{International conference on theory and applications of
  satisfiability testing}, pages 294--299. Springer, 2007.

\bibitem[Raghunathan et~al.(2018)Raghunathan, Steinhardt, and
  Liang]{raghunathan2018semidefinite}
Aditi Raghunathan, Jacob Steinhardt, and Percy~S Liang.
\newblock Semidefinite relaxations for certifying robustness to adversarial
  examples.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, \emph{Advances in Neural Information Processing
  Systems 31}, pages 10877--10887. Curran Associates, Inc., 2018.

\bibitem[Rastegari et~al.(2016)Rastegari, Ordonez, Redmon, and
  Farhadi]{rastegari2016xnor}
Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, and Ali Farhadi.
\newblock Xnor-net: Imagenet classification using binary convolutional neural
  networks.
\newblock In \emph{European conference on computer vision}, pages 525--542.
  Springer, 2016.

\bibitem[Salman et~al.(2019)Salman, Yang, Zhang, Hsieh, and
  Zhang]{salman2019convex}
Hadi Salman, Greg Yang, Huan Zhang, Cho-Jui Hsieh, and Pengchuan Zhang.
\newblock A convex relaxation barrier to tight robustness verification of
  neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  9832--9842, 2019.

\bibitem[Say and Sanner(2020)]{say2020compact}
Buser Say and Scott Sanner.
\newblock Compact and efficient encodings for planning in factored state and
  action spaces with learned binarized neural network transition models.
\newblock \emph{Artificial Intelligence}, page 103291, 2020.

\bibitem[Scheibler et~al.(2015)Scheibler, Winterer, Wimmer, and
  Becker]{scheibler2015towards}
Karsten Scheibler, Leonore Winterer, Ralf Wimmer, and Bernd Becker.
\newblock Towards verification of artificial neural networks.
\newblock In \emph{MBMV}, pages 30--40, 2015.

\bibitem[Shih et~al.(2019)Shih, Darwiche, and Choi]{shih2019verifying}
Andy Shih, Adnan Darwiche, and Arthur Choi.
\newblock Verifying binarized neural networks by angluin-style learning.
\newblock In \emph{International Conference on Theory and Applications of
  Satisfiability Testing}, pages 354--370. Springer, 2019.

\bibitem[Singh et~al.(2019{\natexlab{a}})Singh, Gehr, P\"{u}schel, and
  Vechev]{singh2019an}
Gagandeep Singh, Timon Gehr, Markus P\"{u}schel, and Martin Vechev.
\newblock An abstract domain for certifying neural networks.
\newblock \emph{Proc. ACM Program. Lang.}, 3\penalty0 (POPL), January
  2019{\natexlab{a}}.
\newblock \doi{10.1145/3290354}.

\bibitem[Singh et~al.(2019{\natexlab{b}})Singh, Gehr, Püschel, and
  Vechev]{singh2018robustness}
Gagandeep Singh, Timon Gehr, Markus Püschel, and Martin Vechev.
\newblock Boosting robustness certification of neural networks.
\newblock In \emph{International Conference on Learning Representations},
  2019{\natexlab{b}}.

\bibitem[Sinz(2005)]{sinz2005towards}
Carsten Sinz.
\newblock Towards an optimal cnf encoding of boolean cardinality constraints.
\newblock In \emph{International conference on principles and practice of
  constraint programming}, pages 827--831. Springer, 2005.

\bibitem[Soos et~al.(2009)Soos, Nohl, and Castelluccia]{mate2009extending}
Mate Soos, Karsten Nohl, and Claude Castelluccia.
\newblock Extending {SAT} solvers to cryptographic problems.
\newblock In \emph{Theory and Applications of Satisfiability Testing - {SAT}
  2009, 12th International Conference, {SAT} 2009, Swansea, UK, June 30 - July
  3, 2009. Proceedings}, pages 244--257, 2009.
\newblock \doi{10.1007/978-3-642-02777-2\_24}.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Estrach, Erhan,
  Goodfellow, and Fergus]{szegedy2014intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan~Bruna Estrach,
  Dumitru Erhan, Ian Goodfellow, and Robert Fergus.
\newblock Intriguing properties of neural networks.
\newblock In \emph{2nd International Conference on Learning Representations,
  ICLR 2014}, 2014.

\bibitem[Tjeng et~al.(2019)Tjeng, Xiao, and Tedrake]{tjeng2018evaluating}
Vincent Tjeng, Kai~Y. Xiao, and Russ Tedrake.
\newblock Evaluating robustness of neural networks with mixed integer
  programming.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Tramer et~al.(2020)Tramer, Carlini, Brendel, and
  Madry]{tramer2020adaptive}
Florian Tramer, Nicholas Carlini, Wieland Brendel, and Aleksander Madry.
\newblock On adaptive attacks to adversarial example defenses.
\newblock \emph{arXiv preprint arXiv:2002.08347}, 2020.

\bibitem[Weng et~al.(2018)Weng, Zhang, Chen, Song, Hsieh, Daniel, Boning, and
  Dhillon]{weng2018towards}
Lily Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Luca Daniel,
  Duane Boning, and Inderjit Dhillon.
\newblock Towards fast computation of certified robustness for {ReLU} networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  5276--5285, 2018.

\bibitem[Wong and Kolter(2017)]{wong2017provable}
Eric Wong and J~Zico Kolter.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope.
\newblock \emph{arXiv preprint arXiv:1711.00851}, 2017.

\bibitem[Xiao et~al.(2019)Xiao, Tjeng, Shafiullah, and Madry]{xiao2018training}
Kai~Y. Xiao, Vincent Tjeng, Nur Muhammad~(Mahi) Shafiullah, and Aleksander
  Madry.
\newblock Training for faster adversarial robustness verification via inducing
  re{LU} stability.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Zhang et~al.(2018)Zhang, Weng, Chen, Hsieh, and
  Daniel]{zhang2018efficient}
Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel.
\newblock Efficient neural network robustness certification with general
  activation functions.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, \emph{Advances in Neural Information Processing
  Systems 31}, pages 4939--4948. Curran Associates, Inc., 2018.

\bibitem[Zhou et~al.(2016)Zhou, Wu, Ni, Zhou, Wen, and Zou]{zhou2016dorefa}
Shuchang Zhou, Yuxin Wu, Zekun Ni, Xinyu Zhou, He~Wen, and Yuheng Zou.
\newblock Dorefa-net: Training low bitwidth convolutional neural networks with
  low bitwidth gradients.
\newblock \emph{arXiv preprint arXiv:1606.06160}, 2016.

\end{thebibliography}
