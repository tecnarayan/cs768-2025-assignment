\begin{thebibliography}{92}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Afshari et~al.(2019)Afshari, Hare, and Tesfamariam]{constrained}
Afshari, H., Hare, W., and Tesfamariam, S.
\newblock Constrained multi-objective optimization algorithms: Review and comparison with application in reinforced concrete structures.
\newblock \emph{Applied Soft Computing}, 83:\penalty0 105631, 2019.

\bibitem[Arango et~al.(2021)Arango, Jomaa, Wistuba, and Grabocka]{hpob}
Arango, S.~P., Jomaa, H.~S., Wistuba, M., and Grabocka, J.
\newblock {HPO}-{B}: {A} large-scale reproducible benchmark for black-box {HPO} based on {O}pen{ML}.
\newblock In \emph{Proceedings of 35th Conference on Neural Information Processing Systems Datasets and Benchmarks Track}, 2021.

\bibitem[B\"{a}ck(1996)]{eabook}
B\"{a}ck, T.
\newblock \emph{Evolutionary Algorithms in Theory and Practice: Evolution Strategies, Evolutionary Programming, Genetic Algorithms}.
\newblock Oxford University Press., 1996.

\bibitem[Balandat et~al.(2020)Balandat, Karrer, Jiang, Daulton, Letham, Wilson, and Bakshy]{botorch}
Balandat, M., Karrer, B., Jiang, D.~R., Daulton, S., Letham, B., Wilson, A.~G., and Bakshy, E.
\newblock {BoTorch: A Framework for efficient Monte-Carlo {B}ayesian optimization}.
\newblock In \emph{Advances in Neural Information Processing Systems 33 (NeurIPS)}, Virtual, 2020.

\bibitem[Bian et~al.(2023)Bian, Zhou, Li, and Qian]{sto-population}
Bian, C., Zhou, Y., Li, M., and Qian, C.
\newblock Stochastic population update can provably be helpful in multi-objective evolutionary algorithms.
\newblock In \emph{Proceedings of the 32nd International Joint Conference on Artificial Intelligence (IJCAI)}, pp.\  5513--5521, Macao, SAR, China, 2023.

\bibitem[Binois \& Wycoff(2022)Binois and Wycoff]{high-dim}
Binois, M. and Wycoff, N.
\newblock A survey on high-dimensional {G}aussian process modeling with application to {B}ayesian optimization.
\newblock \emph{{ACM} Transactions on Evolutionary Learning and Optimization}, 2\penalty0 (2):\penalty0 1--26, 2022.

\bibitem[{Blank} \& {Deb}(2020){Blank} and {Deb}]{pymoo}
{Blank}, J. and {Deb}, K.
\newblock pymoo: Multi-objective optimization in {P}ython.
\newblock \emph{IEEE Access}, 8:\penalty0 89497--89509, 2020.

\bibitem[Bosman \& Thierens(2003)Bosman and Thierens]{igd}
Bosman, P. A.~N. and Thierens, D.
\newblock The balance between proximity and diversity in multiobjective evolutionary algorithms.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 7\penalty0 (2):\penalty0 174--188, 2003.

\bibitem[Byrd et~al.(1995)Byrd, Lu, Nocedal, and Zhu]{l-bfgs-b}
Byrd, R.~H., Lu, P., Nocedal, J., and Zhu, C.
\newblock A limited memory algorithm for bound constrained optimization.
\newblock \emph{SIAM Journal on Scientific Computing}, 16\penalty0 (5):\penalty0 1190--1208, 1995.

\bibitem[Cai et~al.(2019)Cai, Gan, Wang, Zhang, and Han]{resnet50}
Cai, H., Gan, C., Wang, T., Zhang, Z., and Han, S.
\newblock Once-for-all: Train one network and specialize it for efficient deployment.
\newblock \emph{arXiv:1908.09791}, 2019.

\bibitem[Chemingui et~al.(2024)Chemingui, Deshwal, Hoang, and Doppa]{pgs}
Chemingui, Y., Deshwal, A., Hoang, T.~N., and Doppa, J.~R.
\newblock Offline model-based optimization via policy-guided gradient search.
\newblock In \emph{Proceddings of the 38th {AAAI} Conference on Artificial Intelligence (AAAI)}, pp.\  11230--11239, Vancouver, Canada, 2024.

\bibitem[Chen et~al.(2022)Chen, Zhang, Fu, Liu, and Coates]{bdi}
Chen, C., Zhang, Y., Fu, J., Liu, X.~S., and Coates, M.
\newblock Bidirectional learning for offline infinite-width model-based optimization.
\newblock In \emph{Advances in Neural Information Processing Systems 35 (NeurIPS)}, New Orleans, LA, 2022.

\bibitem[Chen et~al.(2023{\natexlab{a}})Chen, Beckham, Liu, Liu, and Pal]{tri-mentoring}
Chen, C., Beckham, C., Liu, Z., Liu, X., and Pal, C.
\newblock Parallel-mentoring for offline model-based optimization.
\newblock In \emph{Advances in Neural Information Processing Systems 36 (NeurIPS)}, New Orleans, LA, 2023{\natexlab{a}}.

\bibitem[Chen et~al.(2023{\natexlab{b}})Chen, Zhang, Cao, Wu, Ma, Ye, and Wang]{nhde}
Chen, J., Zhang, Z., Cao, Z., Wu, Y., Ma, Y., Ye, T., and Wang, J.
\newblock Neural multi-objective combinatorial optimization with diversity enhancement.
\newblock In \emph{Advances in Neural Information Processing Systems 36 (NeurIPS)}, pp.\  39176â€“39188, New Orleans, LA, 2023{\natexlab{b}}.

\bibitem[Chen et~al.(2021)Chen, Peng, Fu, and Ling]{autoformer}
Chen, M., Peng, H., Fu, J., and Ling, H.
\newblock Autoformer: {S}earching transformers for visual recognition.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}, pp.\  12270--12280, Virtual, 2021.

\bibitem[Chen \& Li(2023)Chen and Li]{harmful}
Chen, T. and Li, M.
\newblock The weights can be harmful: {P}areto search versus weighted search in multi-objective search-based software engineering.
\newblock \emph{ACM Transactions on Software Engineering and Methodology}, 32\penalty0 (1):\penalty0 5:1--5:40, 2023.

\bibitem[Chen et~al.(2018)Chen, Badrinarayanan, Lee, and Rabinovich]{gradnorm}
Chen, Z., Badrinarayanan, V., Lee, C., and Rabinovich, A.
\newblock Grad{N}orm: {G}radient normalization for adaptive loss balancing in deep multitask networks.
\newblock In \emph{Proceedings of the 35th International Conference on Machine Learning (ICML)}, pp.\  793--802, Stockholm, Sweden, 2018.

\bibitem[Coello et~al.(2007)Coello, Lamont, and Veldhuizen]{coello2007evolutionary}
Coello, C. A.~C., Lamont, G.~B., and Veldhuizen, D. A.~V.
\newblock \emph{Evolutionary Algorithms for Solving Multi-objective Problems}.
\newblock Springer, 2007.

\bibitem[Dara et~al.(2022)Dara, Dhamercherla, Jadav, Babu, and Ahsan]{drug}
Dara, S., Dhamercherla, S., Jadav, S.~S., Babu, C.~M., and Ahsan, M.~J.
\newblock Machine learning in drug discovery: {A} review.
\newblock \emph{Artificial Intelligence Review}, 55\penalty0 (3):\penalty0 1947--1999, 2022.

\bibitem[Daulton et~al.(2020)Daulton, Balandat, and Bakshy]{qparego}
Daulton, S., Balandat, M., and Bakshy, E.
\newblock Differentiable expected hypervolume improvement for parallel multi-objective {B}ayesian optimization.
\newblock \emph{Advances in Neural Information Processing Systems 33 (NeurIPS)}, pp.\  9851--9864, 2020.

\bibitem[Daulton et~al.(2021)Daulton, Balandat, and Bakshy]{qnehvi}
Daulton, S., Balandat, M., and Bakshy, E.
\newblock Parallel {B}ayesian optimization of multiple noisy objectives with expected hypervolume improvement.
\newblock In \emph{Advances in Neural Information Processing Systems 34 (NeurIPS)}, pp.\  2187--2200, Virtual, 2021.

\bibitem[Daulton et~al.(2023)Daulton, Balandat, and Bakshy]{hvkg}
Daulton, S., Balandat, M., and Bakshy, E.
\newblock Hypervolume knowledge gradient: {A} lookahead approach for multi-objective {B}ayesian optimization with partial information.
\newblock In \emph{Proceedings of the 40th International Conference on Machine Learning (ICML)}, pp.\  7167--7204, Honolulu, HI, 2023.

\bibitem[Deb(2001)]{moea-book}
Deb, K.
\newblock \emph{Multi-objective optimization using evolutionary algorithms}.
\newblock Wiley, 2001.

\bibitem[Deb \& Jain(2013)Deb and Jain]{deb2013evolutionary}
Deb, K. and Jain, H.
\newblock An evolutionary many-objective optimization algorithm using reference-point-based nondominated sorting approach, part {I}: {S}olving problems with box constraints.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 18\penalty0 (4):\penalty0 577--601, 2013.

\bibitem[Deb \& Tiwari(2008)Deb and Tiwari]{omnitest}
Deb, K. and Tiwari, S.
\newblock Omni-optimizer: A generic evolutionary algorithm for single and multi-objective optimization.
\newblock \emph{European Journal of Operational Research}, 185\penalty0 (3):\penalty0 1062--1087, 2008.

\bibitem[Deb et~al.(2002{\natexlab{a}})Deb, Agrawal, Pratap, and Meyarivan]{nsgaii}
Deb, K., Agrawal, S., Pratap, A., and Meyarivan, T.
\newblock A fast and elitist multiobjective genetic algorithm: {NSGA-II}.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 6\penalty0 (2):\penalty0 182--197, 2002{\natexlab{a}}.

\bibitem[Deb et~al.(2002{\natexlab{b}})Deb, Thiele, Laumanns, and Zitzler]{dtlz}
Deb, K., Thiele, L., Laumanns, M., and Zitzler, E.
\newblock Scalable multi-objective optimization test problems.
\newblock In \emph{Proceedings of the Congress on Evolutionary Computation (CEC)}, pp.\  825--830, 2002{\natexlab{b}}.

\bibitem[Deshwal et~al.(2022)Deshwal, Belakaria, Doppa, and Kim]{bops}
Deshwal, A., Belakaria, S., Doppa, J.~R., and Kim, D.~H.
\newblock Bayesian optimization over permutation spaces.
\newblock In \emph{Proceedings of 36th {AAAI} Conference on Artificial Intelligence (AAAI)}, pp.\  6515--6523, Virtual, 2022.

\bibitem[Dong \& Yang(2020)Dong and Yang]{nas201}
Dong, X. and Yang, Y.
\newblock {NAS}-{B}ench-201: {E}xtending the scope of reproducible neural architecture search.
\newblock In \emph{Proceedings of the 8th International Conference on Learning Representations (ICLR)}, Addis Ababa, Ethiopia, 2020.

\bibitem[Dong et~al.(2021)Dong, Liu, Musial, and Gabrys]{narts}
Dong, X., Liu, L., Musial, K., and Gabrys, B.
\newblock {NATS}-{B}ench: Benchmarking {NAS} algorithms for architecture topology and size.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, 44\penalty0 (7):\penalty0 3634--3646, 2021.

\bibitem[Ehrgott(2005)]{mo-book2}
Ehrgott, M.
\newblock \emph{Multicriteria Optimization}.
\newblock Springer, 2005.

\bibitem[Emmerich et~al.(2006)Emmerich, Giannakoglou, and Naujoks]{ehvi1}
Emmerich, M.~T., Giannakoglou, K.~C., and Naujoks, B.
\newblock Single-and multiobjective evolutionary optimization assisted by {G}aussian random field metamodels.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 10\penalty0 (4):\penalty0 421--439, 2006.

\bibitem[Fabozzi et~al.(2008)Fabozzi, Markowitz, and Gupta]{portfolio}
Fabozzi, F.~J., Markowitz, H.~M., and Gupta, F.
\newblock Portfolio selection.
\newblock \emph{Handbook of Finance}, 7\penalty0 (1):\penalty0 77, 2008.

\bibitem[Fu et~al.(2020)Fu, Kumar, Nachum, Tucker, and Levine]{d4rl}
Fu, J., Kumar, A., Nachum, O., Tucker, G., and Levine, S.
\newblock {D4RL:} {D}atasets for deep data-driven reinforcement learning.
\newblock \emph{arXiv:2004.07219}, 2020.

\bibitem[Goh \& Tan(2007)Goh and Tan]{noisy}
Goh, C.~K. and Tan, K.~C.
\newblock An investigation on noisy environments in evolutionary multiobjective optimization.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 11\penalty0 (3):\penalty0 354--381, 2007.

\bibitem[Hern{\'a}ndez-Lobato et~al.(2016)Hern{\'a}ndez-Lobato, Hernandez-Lobato, Shah, and Adams]{pesmo}
Hern{\'a}ndez-Lobato, D., Hernandez-Lobato, J., Shah, A., and Adams, R.
\newblock Predictive entropy search for multi-objective {B}ayesian optimization.
\newblock In \emph{Proceedings of the 33rd International Conference on Machine Learning (ICML)}, pp.\  1492--1501, New York City, NY, 2016.

\bibitem[Hvarfner et~al.(2022)Hvarfner, Hutter, and Nardi]{jes}
Hvarfner, C., Hutter, F., and Nardi, L.
\newblock Joint entropy search for maximally-informed {B}ayesian optimization.
\newblock In \emph{Advances in Neural Information Processing Systems 35 (NeurIPS)}, pp.\  11494--11506, New Orleans, LA, 2022.

\bibitem[Ishibuchi et~al.(2014)Ishibuchi, Akedo, and Nojima]{mokp}
Ishibuchi, H., Akedo, N., and Nojima, Y.
\newblock Behavior of multiobjective evolutionary algorithms on many-objective knapsack problems.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 19\penalty0 (2):\penalty0 264--283, 2014.

\bibitem[Ishibuchi et~al.(2018)Ishibuchi, Imada, Setoguchi, and Nojima]{refpoint}
Ishibuchi, H., Imada, R., Setoguchi, Y., and Nojima, Y.
\newblock How to specify a reference point in hypervolume calculation for fair performance comparison.
\newblock \emph{Evolutionary Computation}, 26:\penalty0 411--440, 2018.

\bibitem[Ishibuchi et~al.(2022)Ishibuchi, Pang, and Shang]{refpoint2}
Ishibuchi, H., Pang, L.~M., and Shang, K.
\newblock Difficulties in fair performance comparison of multi-objective evolutionary algorithms.
\newblock \emph{IEEE Computational Intelligence Magazine}, 17\penalty0 (1):\penalty0 86--101, 2022.

\bibitem[Jain et~al.(2023)Jain, Raparthy, Hern{\'{a}}ndez{-}Garc{\'{\i}}a, Rector{-}Brooks, Bengio, Miret, and Bengio]{MOGFN}
Jain, M., Raparthy, S.~C., Hern{\'{a}}ndez{-}Garc{\'{\i}}a, A., Rector{-}Brooks, J., Bengio, Y., Miret, S., and Bengio, E.
\newblock Multi-{O}bjective {GF}low{N}ets.
\newblock In \emph{Proceedings of the 40th International Conference on Machine Learning (ICML)}, pp.\  14631--14653, Honolulu, HI, 2023.

\bibitem[Jin et~al.(2020)Jin, Barzilay, and Jaakkola]{motifs}
Jin, W., Barzilay, R., and Jaakkola, T.~S.
\newblock Hierarchical generation of molecular graphs using structural motifs.
\newblock In \emph{Proceedings of the 37th International Conference on Machine Learning (ICML)}, pp.\  4839--4848, Virtual, 2020.

\bibitem[Jin et~al.(2019)Jin, Wang, Chugh, Guo, and Miettinen]{saea}
Jin, Y., Wang, H., Chugh, T., Guo, D., and Miettinen, K.
\newblock Data-driven evolutionary optimization: {A}n overview and case studies.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 23\penalty0 (3):\penalty0 442--458, 2019.

\bibitem[Khan et~al.(2023)Khan, Cowen-Rivers, Grosnit, Robert, Greiff, Smorodina, Rawat, Akbar, Dreczkowski, Tutunov, et~al.]{antBO}
Khan, A., Cowen-Rivers, A.~I., Grosnit, A., Robert, P.~A., Greiff, V., Smorodina, E., Rawat, P., Akbar, R., Dreczkowski, K., Tutunov, R., et~al.
\newblock Toward real-world automated antibody design with combinatorial {B}ayesian optimization.
\newblock \emph{Cell Reports Methods}, 3\penalty0 (1), 2023.

\bibitem[Kim et~al.(2023)Kim, Berto, Ahn, and Park]{bootgen}
Kim, M., Berto, F., Ahn, S., and Park, J.
\newblock Bootstrapped training of score-conditioned generator for offline design of biological sequences.
\newblock In \emph{Advances in Neural Information Processing Systems 36 (NeurIPS)}, pp.\  67643â€“67661, New Orleans, LA, 2023.

\bibitem[Knowles(2006)]{parego}
Knowles, J.
\newblock Par{EGO}: A hybrid algorithm with on-line landscape approximation for expensive multiobjective optimization problems.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 10\penalty0 (1):\penalty0 50--66, 2006.

\bibitem[Konakovic~Lukovic et~al.(2020)Konakovic~Lukovic, Tian, and Matusik]{dgemo}
Konakovic~Lukovic, M., Tian, Y., and Matusik, W.
\newblock Diversity-guided multi-objective {B}ayesian optimization with batch evaluations.
\newblock In \emph{Advances in Neural Information Processing Systems 33 (NeurIPS)}, pp.\  17708--17720, Virtual, 2020.

\bibitem[Krishnamoorthy et~al.(2023)Krishnamoorthy, Mashkaria, and Grover]{ddom}
Krishnamoorthy, S., Mashkaria, S.~M., and Grover, A.
\newblock Diffusion models for black-box optimization.
\newblock In \emph{Proceedings of the 40th International Conference on Machine Learning (ICML)}, pp.\  17842--17857, Honolulu, HI, 2023.

\bibitem[Krizhevsky \& Hinton(2009)Krizhevsky and Hinton]{cifar10}
Krizhevsky, A. and Hinton, G.
\newblock Learning multiple layers of features from tiny images.
\newblock \emph{Handbook of Systemic Autoimmune Diseases}, 1\penalty0 (4), 2009.

\bibitem[Kumar \& Levine(2020)Kumar and Levine]{MINs}
Kumar, A. and Levine, S.
\newblock Model inversion networks for model-based optimization.
\newblock In \emph{Advances in Neural Information Processing Systems 33 (NeurIPS)}, Virtual, 2020.

\bibitem[Li et~al.(2021)Li, Yu, Fu, Zhang, Zhao, You, Yu, Wang, Hao, and Lin]{hwnas}
Li, C., Yu, Z., Fu, Y., Zhang, Y., Zhao, Y., You, H., Yu, Q., Wang, Y., Hao, C., and Lin, Y.
\newblock {HW-NAS-B}ench: {H}ardware-aware neural architecture search benchmark.
\newblock In \emph{Proceedings of the 9th International Conference on Learning Representations (ICLR)}, Virtual, 2021.

\bibitem[Lin et~al.(2022)Lin, Yang, Zhang, and Zhang]{psl-1}
Lin, X., Yang, Z., Zhang, X., and Zhang, Q.
\newblock Pareto set learning for expensive multi-objective optimization.
\newblock In \emph{Advances in Neural Information Processing Systems 35 (NeurIPS)}, New Orleans, LA, 2022.

\bibitem[Lu et~al.(2023)Lu, Cheng, Jin, Tan, and Deb]{mo-nas}
Lu, Z., Cheng, R., Jin, Y., Tan, K.~C., and Deb, K.
\newblock Neural architecture search as multiobjective optimization benchmarks: {P}roblem formulation and performance assessment.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 28:\penalty0 328--337, 2023.

\bibitem[Lust \& Teghem(2010)Lust and Teghem]{motsp}
Lust, T. and Teghem, J.
\newblock The multiobjective traveling salesman problem: {A} survey and a new approach.
\newblock In \emph{Advances in Multi-Objective Nature Inspired Computing}, pp.\  119--141. Springer, 2010.

\bibitem[Miettinen(1998)]{mo-book}
Miettinen, K.
\newblock \emph{Nonlinear Multiobjective Optimization}.
\newblock Kluwer, 1998.

\bibitem[Paria et~al.(2020)Paria, Kandasamy, and P{\'o}czos]{mobors}
Paria, B., Kandasamy, K., and P{\'o}czos, B.
\newblock A flexible framework for multi-objective {B}ayesian optimization using random scalarizations.
\newblock In \emph{Proceedings of the 35th Conference on Uncertainty in Artificial Intelligence (UAI)}, pp.\  766--776, Toronto, Canada, 2020.

\bibitem[Qi et~al.(2022)Qi, Su, Kumar, and Levine]{iom}
Qi, H., Su, Y., Kumar, A., and Levine, S.
\newblock Data-driven offline decision-making via invariant representation learning.
\newblock In \emph{Advances in Neural Information Processing Systems 35 (NeurIPS)}, pp.\  13226--13237, New Orleans, LA, 2022.

\bibitem[Qian et~al.(2013)Qian, Yu, and Zhou]{recombination}
Qian, C., Yu, Y., and Zhou, Z.
\newblock An analysis on recombination in multi-objective evolutionary optimization.
\newblock \emph{Artificial Intelligence}, 204:\penalty0 99--119, 2013.

\bibitem[Qian et~al.(2018)Qian, Yu, and Zhou]{noisy-ea}
Qian, C., Yu, Y., and Zhou, Z.
\newblock Analyzing evolutionary optimization in noisy environments.
\newblock \emph{Evolutionary Computation}, 26\penalty0 (1), 2018.

\bibitem[Qin et~al.(2022)Qin, Zhang, Gao, Chen, Li, Zhang, and Yu]{neorl}
Qin, R., Zhang, X., Gao, S., Chen, X., Li, Z., Zhang, W., and Yu, Y.
\newblock Neo{RL}: {A} near real-world benchmark for offline reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems 35 (NeurIPS)}, New Orleans, LA, 2022.

\bibitem[Qing et~al.(2023)Qing, Moss, Dhaene, and Couckuyt]{pf2es}
Qing, J., Moss, H.~B., Dhaene, T., and Couckuyt, I.
\newblock {PF}\({}^{\mbox{2}}\){ES}: Parallel feasible {P}areto frontier entropy search for multi-objective {B}ayesian optimization.
\newblock In \emph{Proceedings of the 26th International Conference on Artificial Intelligence and Statistics (AISTATS)}, pp.\  2565--2588, Valencia, Spain, 2023.

\bibitem[Rasmussen \& Williams(2006)Rasmussen and Williams]{gpml}
Rasmussen, C.~E. and Williams, C. K.~I.
\newblock \emph{{G}aussian {P}rocesses for {M}achine {L}earning}.
\newblock The MIT Press, Cambridge, MA, 2006.

\bibitem[Song et~al.(2022)Song, Xue, Huang, and Qian]{mctsvs}
Song, L., Xue, K., Huang, X., and Qian, C.
\newblock Monte {C}arlo tree search based variable selection for high dimensional {B}ayesian optimization.
\newblock In \emph{Advances in Neural Information Processing Systems 35 (NeurIPS)}, New Orleans, LA, 2022.

\bibitem[Stanton et~al.(2022)Stanton, Maddox, Gruver, Maffettone, Delaney, Greenside, and Wilson]{lambo}
Stanton, S., Maddox, W.~J., Gruver, N., Maffettone, P., Delaney, E., Greenside, P., and Wilson, A.~G.
\newblock Accelerating {B}ayesian optimization for biological sequence design with denoising autoencoders.
\newblock In \emph{Proceedings of the 39th International Conference on Machine Learning (ICML)}, pp.\  20459--20478, Baltimore, MD, 2022.

\bibitem[Suzuki et~al.(2020)Suzuki, Takeno, Tamura, Shitara, and Karasuyama]{pfes}
Suzuki, S., Takeno, S., Tamura, T., Shitara, K., and Karasuyama, M.
\newblock Multi-objective {B}ayesian optimization using {P}areto-frontier entropy.
\newblock In \emph{Proceedings of the 37th International Conference on Machine Learning (ICML)}, pp.\  9279--9288, Virtual, 2020.

\bibitem[Tanabe \& Ishibuchi(2020)Tanabe and Ishibuchi]{RE}
Tanabe, R. and Ishibuchi, H.
\newblock An easy-to-use real-world multi-objective optimization problem suite.
\newblock \emph{Applied Soft Computing}, 89:\penalty0 106078, 2020.

\bibitem[Thebelt et~al.(2022)Thebelt, Tsay, Lee, Sudermann{-}Merx, Walz, Shafei, and Misener]{mixed}
Thebelt, A., Tsay, C., Lee, R.~M., Sudermann{-}Merx, N., Walz, D., Shafei, B., and Misener, R.
\newblock Tree ensemble kernels for {B}ayesian optimization with known constraints over mixed-feature spaces.
\newblock In \emph{Advances in Neural Information Processing Systems 35 (NeurIPS)}, New Orleans, LA, 2022.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{mujoco}
Todorov, E., Erez, T., and Tassa, Y.
\newblock Mu{J}o{C}o: {A} physics engine for model-based control.
\newblock In \emph{{IEEE/RSJ} International Conference on Intelligent Robots and Systems (IROS)}, pp.\  5026--5033, Vilamoura, Portugal, 2012.

\bibitem[Trabucco et~al.(2021)Trabucco, Kumar, Geng, and Levine]{coms}
Trabucco, B., Kumar, A., Geng, X., and Levine, S.
\newblock Conservative objective models for effective offline model-based optimization.
\newblock In \emph{Proceedings of the 38th International Conference on Machine Learning (ICML)}, pp.\  10358--10368, Virtual, 2021.

\bibitem[Trabucco et~al.(2022)Trabucco, Geng, Kumar, and Levine]{design-bench}
Trabucco, B., Geng, X., Kumar, A., and Levine, S.
\newblock Design-{B}ench: {B}enchmarks for data-driven offline model-based optimization.
\newblock In \emph{Proceedings of the 39th International Conference on Machine Learning (ICML)}, pp.\  21658--21676, Baltimore, MD, 2022.

\bibitem[Uehara et~al.(2024)Uehara, Zhao, Hajiramezanali, Scalia, Eraslan, Lal, Levine, and Biancalani]{uehara2024bridging}
Uehara, M., Zhao, Y., Hajiramezanali, E., Scalia, G., Eraslan, G., Lal, A., Levine, S., and Biancalani, T.
\newblock Bridging model-based optimization and generative modeling via conservative fine-tuning of diffusion models.
\newblock \emph{arXiv:2405.19673}, 2024.

\bibitem[Van~Veldhuizen \& Lamont(1999)Van~Veldhuizen and Lamont]{vlmop}
Van~Veldhuizen, D.~A. and Lamont, G.~B.
\newblock Multiobjective evolutionary algorithm test suites.
\newblock In \emph{Proceedings of the 1999 ACM Symposium on Applied Computing}, pp.\  351--357, 1999.

\bibitem[Wang et~al.(2016)Wang, Hutter, Zoghi, Matheson, and de~Feitas]{rembo}
Wang, Z., Hutter, F., Zoghi, M., Matheson, D., and de~Feitas, N.
\newblock Bayesian optimization in a billion dimensions via random embeddings.
\newblock \emph{Journal of Artificial Intelligence Research}, 55\penalty0 (1):\penalty0 361--387, 2016.

\bibitem[Wistuba \& Grabocka(2021)Wistuba and Grabocka]{few-shot}
Wistuba, M. and Grabocka, J.
\newblock Few-shot {B}ayesian optimization with deep kernel surrogates.
\newblock In \emph{Proceedings of the 9th International Conference on Learning Representations (ICLR)}, Virtual, 2021.

\bibitem[Xu et~al.(2020)Xu, Tian, Ma, Rus, Sueda, and Matusik]{pgmorl}
Xu, J., Tian, Y., Ma, P., Rus, D., Sueda, S., and Matusik, W.
\newblock Prediction-guided multi-objective reinforcement learning for continuous robot control.
\newblock In \emph{Proceedings of the 37th International Conference on Machine Learning (ICML)}, pp.\  10607--10616, Virtual, 2020.

\bibitem[Ying et~al.(2019)Ying, Klein, Christiansen, Real, Murphy, and Hutter]{nas101}
Ying, C., Klein, A., Christiansen, E., Real, E., Murphy, K., and Hutter, F.
\newblock {NAS}-{B}ench-101: {T}owards reproducible neural architecture search.
\newblock In \emph{Proceedings of the 36th International Conference on Machine Learning (ICML)}, pp.\  7105--7114, Long Beach, CA, 2019.

\bibitem[Yu et~al.(2024)Yu, Zhang, He, Ma, Miao, Lu, Zhang, Kong, Gao, Xie, et~al.]{leo}
Yu, P., Zhang, D., He, H., Ma, X., Miao, R., Lu, Y., Zhang, Y., Kong, D., Gao, R., Xie, J., et~al.
\newblock Latent energy-based odyssey: Black-box optimization via expanded exploration in the energy-based latent space.
\newblock \emph{arXiv:2405.16730}, 2024.

\bibitem[Yu et~al.(2021)Yu, Ahn, Song, and Shin]{ROMA}
Yu, S., Ahn, S., Song, L., and Shin, J.
\newblock Ro{MA}: {R}obust model adaptation for offline model-based optimization.
\newblock In \emph{Advances in Neural Information Processing Systems 34 (NeurIPS)}, pp.\  4619--4631, Virtual, 2021.

\bibitem[Yu et~al.(2020)Yu, Kumar, Gupta, Levine, Hausman, and Finn]{gradient-surgery}
Yu, T., Kumar, S., Gupta, A., Levine, S., Hausman, K., and Finn, C.
\newblock Gradient surgery for multi-task learning.
\newblock In \emph{Advances in Neural Information Processing Systems 33 (NeurIPS)}, Virtual, 2020.

\bibitem[Yuan et~al.(2023)Yuan, Chen, Liu, Neiswanger, and Liu]{ict}
Yuan, Y., Chen, C., Liu, Z., Neiswanger, W., and Liu, X.
\newblock Importance-aware co-teaching for offline model-based optimization.
\newblock In \emph{Advances in Neural Information Processing Systems 36 (NeurIPS)}, New Orleans, LA, 2023.

\bibitem[Zajac \& Huber(2021)Zajac and Huber]{mocvrp}
Zajac, S. and Huber, S.
\newblock Objectives and methods in multi-objective routing problems: {A} survey and classification scheme.
\newblock \emph{European Journal of Operational Research}, 290\penalty0 (1):\penalty0 1--25, 2021.

\bibitem[Zela et~al.(2020)Zela, Siems, Zimmer, Lukasik, Keuper, and Hutter]{darts-nas}
Zela, A., Siems, J., Zimmer, L., Lukasik, J., Keuper, M., and Hutter, F.
\newblock Surrogate {NAS} benchmarks: Going beyond the limited search spaces of tabular {NAS} benchmarks.
\newblock \emph{arXiv:2008.09777}, 2020.

\bibitem[Zhang \& Li(2007)Zhang and Li]{moead}
Zhang, Q. and Li, H.
\newblock {MOEA/D:} {A} multiobjective evolutionary algorithm based on decomposition.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 11\penalty0 (6):\penalty0 712--731, 2007.

\bibitem[Zhang et~al.(2009)Zhang, Liu, Tsang, and Virginas]{moeadego}
Zhang, Q., Liu, W., Tsang, E., and Virginas, B.
\newblock Expensive multiobjective optimization by {MOEA/D} with {G}aussian process model.
\newblock \emph{IEEE Transactions on Evolutionary Computation}, 14\penalty0 (3):\penalty0 456--474, 2009.

\bibitem[Zhang \& Golovin(2020)Zhang and Golovin]{hvrs}
Zhang, R. and Golovin, D.
\newblock Random hypervolume scalarizations for provable multi-objective black box optimization.
\newblock In \emph{Proceedings of the 37th International Conference on Machine Learning (ICML)}, pp.\  11096--11105, Virtual, 2020.

\bibitem[Zhang et~al.(2023)Zhang, Lin, Xue, Chen, and Zhang]{psl-3}
Zhang, X., Lin, X., Xue, B., Chen, Y., and Zhang, Q.
\newblock Hypervolume maximization: {A} geometric view of {P}areto set learning.
\newblock In \emph{Advances in Neural Information Processing Systems 36 (NeurIPS)}, New Orleans, LA, 2023.

\bibitem[Zhang \& Yang(2022)Zhang and Yang]{mtl-survey}
Zhang, Y. and Yang, Q.
\newblock A survey on multi-task learning.
\newblock \emph{IEEE Transactions on Knowledge and Data Engineering}, 34\penalty0 (12):\penalty0 5586--5609, 2022.

\bibitem[Zhao et~al.(2022)Zhao, Wang, Yang, Zhang, Guo, and Tian]{lamoo}
Zhao, Y., Wang, L., Yang, K., Zhang, T., Guo, T., and Tian, Y.
\newblock Multi-objective optimization by learning space partitions.
\newblock In \emph{Proceedings of the 10th International Conference on Learning Representations (ICLR)}, Virtual, 2022.

\bibitem[Zhou et~al.(2019)Zhou, Yu, and Qian]{elbook}
Zhou, Z.-H., Yu, Y., and Qian, C.
\newblock \emph{Evolutionary Learning: Advances in Theories and Algorithms}.
\newblock Springer, 2019.

\bibitem[Zhu et~al.(2023)Zhu, Dang, and Grover]{d4morl}
Zhu, B., Dang, M., and Grover, A.
\newblock Scaling {P}areto-efficient decision making via offline multi-objective {RL}.
\newblock In \emph{Proceedings of the 11th International Conference on Learning Representations (ICLR)}, Kigali, Rwanda, 2023.

\bibitem[Zitzler \& Thiele(1998)Zitzler and Thiele]{hv}
Zitzler, E. and Thiele, L.
\newblock Multiobjective optimization using evolutionary algorithms: {A} comparative case study.
\newblock In \emph{Proceedings of the 5th International Conference on Parallel Problem Solving from Nature (PPSN)}, pp.\  292--304, Amsterdam, The Netherlands, 1998.

\bibitem[Zitzler et~al.(2000)Zitzler, Deb, and Thiele]{zdt}
Zitzler, E., Deb, K., and Thiele, L.
\newblock Comparison of multiobjective evolutionary algorithms: Empirical results.
\newblock \emph{Evolutionary Computation}, 8\penalty0 (2):\penalty0 173--195, 2000.

\end{thebibliography}
