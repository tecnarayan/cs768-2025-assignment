\begin{thebibliography}{21}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[B{\"u}hlmann and Yu(2003)]{buhlmann2003boosting}
Peter B{\"u}hlmann and Bin Yu.
\newblock Boosting with the l 2 loss: regression and classification.
\newblock \emph{Journal of the American Statistical Association}, 98\penalty0
  (462):\penalty0 324--339, 2003.

\bibitem[Drineas and Mahoney(2005)]{drineas2005nystrom}
Petros Drineas and Michael~W Mahoney.
\newblock On the nystr{\"o}m method for approximating a gram matrix for
  improved kernel-based learning.
\newblock \emph{journal of machine learning research}, 6\penalty0
  (Dec):\penalty0 2153--2175, 2005.

\bibitem[Fan and Jiang(2007)]{fan2007}
Jianqing Fan and Jiancheng Jiang.
\newblock Nonparametric inference with generalized likelihood ratio tests.
\newblock \emph{TEST}, 16\penalty0 (3):\penalty0 409--444, Dec 2007.
\newblock ISSN 1863-8260.

\bibitem[Fan et~al.(2001)Fan, Zhang, and Zhang]{fan2001generalized}
Jianqing Fan, Chunming Zhang, and Jian Zhang.
\newblock Generalized likelihood ratio statistics and wilks phenomenon.
\newblock \emph{The Annals of statistics}, 29\penalty0 (1):\penalty0 153--193,
  2001.

\bibitem[Golub et~al.(1979)Golub, Heath, and Wahba]{golub1979generalized}
Gene~H Golub, Michael Heath, and Grace Wahba.
\newblock Generalized cross-validation as a method for choosing a good ridge
  parameter.
\newblock \emph{Technometrics}, 21\penalty0 (2):\penalty0 215--223, 1979.

\bibitem[Guo(2002)]{guo2002inference}
Wensheng Guo.
\newblock Inference in smoothing spline analysis of variance.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 64\penalty0 (4):\penalty0 887--898, 2002.

\bibitem[Ingster(1993)]{ingster1993asymptotically}
Yuri~I Ingster.
\newblock Asymptotically minimax hypothesis testing for nonparametric
  alternatives. i, ii, iii.
\newblock \emph{Mathematical Methods of Statistics}, 2\penalty0 (2):\penalty0
  85--114, 1993.

\bibitem[Liu et~al.(2018)Liu, Shang, and Cheng]{liu2018nonparametric}
Meimei Liu, Zuofeng Shang, and Guang Cheng.
\newblock Nonparametric testing under random projection.
\newblock \emph{arXiv preprint arXiv:1802.06308}, 2018.

\bibitem[Lu et~al.(2016)Lu, Cheng, and Liu]{lu2016nonparametric}
Junwei Lu, Guang Cheng, and Han Liu.
\newblock Nonparametric heterogeneity testing for massive data.
\newblock \emph{arXiv preprint arXiv:1601.06212}, 2016.

\bibitem[Ma and Belkin(2017)]{ma2017diving}
Siyuan Ma and Mikhail Belkin.
\newblock Diving into the shallows: a computational perspective on large-scale
  shallow learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3781--3790, 2017.

\bibitem[Raskutti et~al.(2014)Raskutti, Wainwright, and Yu]{raskutti2014early}
Garvesh Raskutti, Martin~J Wainwright, and Bin Yu.
\newblock Early stopping and non-parametric regression: an optimal
  data-dependent stopping rule.
\newblock \emph{Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 335--366, 2014.

\bibitem[Rudelson and Vershynin(2013)]{rudelson2013hanson}
Mark Rudelson and Roman Vershynin.
\newblock Hanson-wright inequality and sub-gaussian concentration.
\newblock \emph{Electronic Communications in Probability}, 18\penalty0
  (82):\penalty0 1--9, 2013.

\bibitem[Sch{\"o}lkopf et~al.(1999)Sch{\"o}lkopf, Burges, and
  Smola]{scholkopf1999advances}
Bernhard Sch{\"o}lkopf, Christopher~JC Burges, and Alexander~J Smola.
\newblock \emph{Advances in kernel methods: support vector learning}.
\newblock MIT press, 1999.

\bibitem[Shang and Cheng(2013)]{shang2013local}
Zuofeng Shang and Guang Cheng.
\newblock Local and global asymptotic inference in smoothing spline models.
\newblock \emph{The Annals of Statistics}, 41\penalty0 (5):\penalty0
  2608--2638, 2013.

\bibitem[Shawe-Taylor and Cristianini(2004)]{shawe2004kernel}
John Shawe-Taylor and Nello Cristianini.
\newblock \emph{Kernel methods for pattern analysis}.
\newblock Cambridge university press, 2004.

\bibitem[Stewart(2002)]{stewart2002krylov}
Gilbert~W Stewart.
\newblock A krylov--schur algorithm for large eigenproblems.
\newblock \emph{SIAM Journal on Matrix Analysis and Applications}, 23\penalty0
  (3):\penalty0 601--614, 2002.

\bibitem[Wahba(1990)]{wahba1990spline}
Grace Wahba.
\newblock \emph{Spline models for observational data}.
\newblock SIAM, 1990.

\bibitem[Wei and Wainwright(2017)]{wei2017local}
Yuting Wei and Martin~J Wainwright.
\newblock The local geometry of testing in ellipses: Tight control via
  localized kolomogorov widths.
\newblock \emph{arXiv preprint arXiv:1712.00711}, 2017.

\bibitem[Wei et~al.(2017)Wei, Yang, and Wainwright]{wei2017early}
Yuting Wei, Fanny Yang, and Martin~J Wainwright.
\newblock Early stopping for kernel boosting algorithms: A general analysis
  with localized complexities.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  6067--6077, 2017.

\bibitem[Yao et~al.(2007)Yao, Rosasco, and Caponnetto]{yao2007early}
Yuan Yao, Lorenzo Rosasco, and Andrea Caponnetto.
\newblock On early stopping in gradient descent learning.
\newblock \emph{Constructive Approximation}, 26\penalty0 (2):\penalty0
  289--315, 2007.

\bibitem[Zhang and Yu(2005)]{zhang2005boosting}
Tong Zhang and Bin Yu.
\newblock Boosting with early stopping: Convergence and consistency.
\newblock \emph{The Annals of Statistics}, 33\penalty0 (4):\penalty0
  1538--1579, 2005.

\end{thebibliography}
