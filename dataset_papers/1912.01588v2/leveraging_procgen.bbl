\begin{thebibliography}{27}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Achiam et~al.(2019)Achiam, Ray, and Amodei]{safetygym}
J.~Achiam, A.~Ray, and D.~Amodei.
\newblock Safety gym.
\newblock \url{https://openai.com/blog/safety-gym/}, 2019.

\bibitem[{Bellemare} et~al.(2013){Bellemare}, {Naddaf}, {Veness}, and
  {Bowling}]{ale}
M.~G. {Bellemare}, Y.~{Naddaf}, J.~{Veness}, and M.~{Bowling}.
\newblock The arcade learning environment: An evaluation platform for general
  agents.
\newblock \emph{Journal of Artificial Intelligence Research}, 47:\penalty0
  253--279, jun 2013.

\bibitem[Beyret et~al.(2019)Beyret, Hern'andez-Orallo, Cheke, Halina, Shanahan,
  and Crosby]{animalai}
B.~Beyret, J.~Hern'andez-Orallo, L.~Cheke, M.~Halina, M.~Shanahan, and
  M.~Crosby.
\newblock The animal-ai environment: Training and testing animal-like
  artificial cognition.
\newblock 2019.

\bibitem[Cobbe et~al.(2019)Cobbe, Klimov, Hesse, Kim, and Schulman]{coinrun}
K.~Cobbe, O.~Klimov, C.~Hesse, T.~Kim, and J.~Schulman.
\newblock Quantifying generalization in reinforcement learning.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning, {ICML} 2019, 9-15 June 2019, Long Beach, California, {USA}}, pages
  1282--1289, 2019.
\newblock URL \url{http://proceedings.mlr.press/v97/cobbe19a.html}.

\bibitem[Espeholt et~al.(2018)Espeholt, Soyer, Munos, Simonyan, Mnih, Ward,
  Doron, Firoiu, Harley, Dunning, Legg, and Kavukcuoglu]{impala}
L.~Espeholt, H.~Soyer, R.~Munos, K.~Simonyan, V.~Mnih, T.~Ward, Y.~Doron,
  V.~Firoiu, T.~Harley, I.~Dunning, S.~Legg, and K.~Kavukcuoglu.
\newblock {IMPALA:} scalable distributed deep-rl with importance weighted
  actor-learner architectures.
\newblock \emph{CoRR}, abs/1802.01561, 2018.

\bibitem[Farebrother et~al.(2018)Farebrother, Machado, and Bowling]{gen_dqn}
J.~Farebrother, M.~C. Machado, and M.~Bowling.
\newblock Generalization and regularization in {DQN}.
\newblock \emph{CoRR}, abs/1810.00123, 2018.
\newblock URL \url{http://arxiv.org/abs/1810.00123}.

\bibitem[Glorot and Bengio(2010)]{glorot}
X.~Glorot and Y.~Bengio.
\newblock Understanding the difficulty of training deep feedforward neural
  networks.
\newblock In \emph{Proceedings of the thirteenth international conference on
  artificial intelligence and statistics}, pages 249--256, 2010.

\bibitem[Hessel et~al.(2018)Hessel, Modayil, Van~Hasselt, Schaul, Ostrovski,
  Dabney, Horgan, Piot, Azar, and Silver]{rainbow}
M.~Hessel, J.~Modayil, H.~Van~Hasselt, T.~Schaul, G.~Ostrovski, W.~Dabney,
  D.~Horgan, B.~Piot, M.~Azar, and D.~Silver.
\newblock Rainbow: Combining improvements in deep reinforcement learning.
\newblock In \emph{Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem[Hochreiter and Schmidhuber(1997)]{lstm}
S.~Hochreiter and J.~Schmidhuber.
\newblock Long short-term memory.
\newblock \emph{Neural Computation}, 9\penalty0 (8):\penalty0 1735--1780, 1997.

\bibitem[Johnson et~al.(2010)Johnson, Yannakakis, and
  Togelius]{johnson2010cellular}
L.~Johnson, G.~N. Yannakakis, and J.~Togelius.
\newblock Cellular automata for real-time generation of infinite cave levels.
\newblock In \emph{Proceedings of the 2010 Workshop on Procedural Content
  Generation in Games}, page~10. ACM, 2010.

\bibitem[Juliani et~al.(2019)Juliani, Khalifa, Berges, Harper, Henry, Crespi,
  Togelius, and Lange]{obstacle}
A.~Juliani, A.~Khalifa, V.-P. Berges, J.~Harper, H.~Henry, A.~Crespi,
  J.~Togelius, and D.~Lange.
\newblock Obstacle tower: A generalization challenge in vision, control, and
  planning.
\newblock \emph{arXiv preprint arXiv:1902.01378}, 2019.

\bibitem[Justesen et~al.(2018)Justesen, Torrado, Bontrager, Khalifa, Togelius,
  and Risi]{illuminating_gen}
N.~Justesen, R.~R. Torrado, P.~Bontrager, A.~Khalifa, J.~Togelius, and S.~Risi.
\newblock Illuminating generalization in deep reinforcement learning through
  procedural level generation.
\newblock \emph{CoRR}, abs/1806.10729, 2018.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
D.~P. Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kruskal(1956)]{kruskal}
J.~B. Kruskal.
\newblock On the shortest spanning subtree of a graph and the traveling
  salesman problem.
\newblock In \emph{Proceedings of the American Mathematical Society, 7}, pages
  48--50, 1956.

\bibitem[Lee et~al.(2019)Lee, Lee, Shin, and Lee]{lee2019simple}
K.~Lee, K.~Lee, J.~Shin, and H.~Lee.
\newblock A simple randomization technique for generalization in deep
  reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1910.05396}, 2019.

\bibitem[Machado et~al.(2018)Machado, Bellemare, Talvitie, Veness, Hausknecht,
  and Bowling]{machado18arcade}
M.~C. Machado, M.~G. Bellemare, E.~Talvitie, J.~Veness, M.~J. Hausknecht, and
  M.~Bowling.
\newblock Revisiting the arcade learning environment: Evaluation protocols and
  open problems for general agents.
\newblock \emph{Journal of Artificial Intelligence Research}, 61:\penalty0
  523--562, 2018.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, Petersen, Beattie, Sadik,
  Antonoglou, King, Kumaran, Wierstra, Legg, and Hassabis]{dqn_2}
V.~Mnih, K.~Kavukcuoglu, D.~Silver, A.~A. Rusu, J.~Veness, M.~G. Bellemare,
  A.~Graves, M.~A. Riedmiller, A.~Fidjeland, G.~Ostrovski, S.~Petersen,
  C.~Beattie, A.~Sadik, I.~Antonoglou, H.~King, D.~Kumaran, D.~Wierstra,
  S.~Legg, and D.~Hassabis.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529--533, 2015.

\bibitem[Nichol et~al.(2018)Nichol, Pfau, Hesse, Klimov, and
  Schulman]{gottalearnfast}
A.~Nichol, V.~Pfau, C.~Hesse, O.~Klimov, and J.~Schulman.
\newblock Gotta learn fast: {A} new benchmark for generalization in {RL}.
\newblock \emph{CoRR}, abs/1804.03720, 2018.
\newblock URL \url{http://arxiv.org/abs/1804.03720}.

\bibitem[Osband et~al.(2019)Osband, Doron, Hessel, Aslanides, Sezener, Saraiva,
  McKinney, Lattimore, {Sz}epesv{\'a}ri, Singh, Van~Roy, Sutton, Silver, and
  van Hasselt]{osband2019bsuite}
I.~Osband, Y.~Doron, M.~Hessel, J.~Aslanides, E.~Sezener, A.~Saraiva,
  K.~McKinney, T.~Lattimore, C.~{Sz}epesv{\'a}ri, S.~Singh, B.~Van~Roy,
  R.~Sutton, D.~Silver, and H.~van Hasselt.
\newblock Behaviour suite for reinforcement learning.
\newblock 2019.

\bibitem[Packer et~al.(2018)Packer, Gao, Kos, Kr{\"{a}}henb{\"{u}}hl, Koltun,
  and Song]{assess_gen_rl}
C.~Packer, K.~Gao, J.~Kos, P.~Kr{\"{a}}henb{\"{u}}hl, V.~Koltun, and D.~Song.
\newblock Assessing generalization in deep reinforcement learning.
\newblock \emph{CoRR}, abs/1810.12282, 2018.

\bibitem[Perez-Liebana et~al.(2018)Perez-Liebana, Liu, Khalifa, Gaina,
  Togelius, and Lucas]{gvgai}
D.~Perez-Liebana, J.~Liu, A.~Khalifa, R.~D. Gaina, J.~Togelius, and S.~M.
  Lucas.
\newblock General video game ai: a multi-track framework for evaluating agents,
  games and content generation algorithms.
\newblock \emph{arXiv preprint arXiv:1802.10363}, 2018.

\bibitem[Pfau et~al.(2018)Pfau, Nichol, Hesse, Schiavo, Schulman, and
  Klimov]{gymretro}
V.~Pfau, A.~Nichol, C.~Hesse, L.~Schiavo, J.~Schulman, and O.~Klimov.
\newblock Gym retro.
\newblock \url{https://openai.com/blog/gym-retro/}, 2018.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{ppo}
J.~Schulman, F.~Wolski, P.~Dhariwal, A.~Radford, and O.~Klimov.
\newblock Proximal policy optimization algorithms.
\newblock \emph{CoRR}, abs/1707.06347, 2017.

\bibitem[Yu et~al.(2019)Yu, Quillen, He, Julian, Hausman, Finn, and
  Levine]{metaworld}
T.~Yu, D.~Quillen, Z.~He, R.~Julian, K.~Hausman, C.~Finn, and S.~Levine.
\newblock Meta-world: A benchmark and evaluation for multi-task and
  meta-reinforcement learning, 2019.
\newblock URL \url{https://github.com/rlworkgroup/metaworld}.

\bibitem[Zhang et~al.(2018{\natexlab{a}})Zhang, Ballas, and
  Pineau]{dissect_overfitting}
A.~Zhang, N.~Ballas, and J.~Pineau.
\newblock A dissection of overfitting and generalization in continuous
  reinforcement learning.
\newblock \emph{CoRR}, abs/1806.07937, 2018{\natexlab{a}}.

\bibitem[Zhang et~al.(2018{\natexlab{b}})Zhang, Wu, and Pineau]{natural_ale}
A.~Zhang, Y.~Wu, and J.~Pineau.
\newblock Natural environment benchmarks for reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1811.06032}, 2018{\natexlab{b}}.

\bibitem[Zhang et~al.(2018{\natexlab{c}})Zhang, Vinyals, Munos, and
  Bengio]{study_overfitting}
C.~Zhang, O.~Vinyals, R.~Munos, and S.~Bengio.
\newblock A study on overfitting in deep reinforcement learning.
\newblock \emph{CoRR}, abs/1804.06893, 2018{\natexlab{c}}.
\newblock URL \url{http://arxiv.org/abs/1804.06893}.

\end{thebibliography}
