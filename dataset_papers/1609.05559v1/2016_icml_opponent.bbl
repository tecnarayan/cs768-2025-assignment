\begin{thebibliography}{25}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bard et~al.(2013)Bard, Johanson, Burch, and
  Bowling]{bard13implicit-modeling}
Bard, Nolan, Johanson, Michael, Burch, Neil, and Bowling, Michael.
\newblock Online implicit agent modelling.
\newblock In \emph{Proceedings of International Conference on Autonomous Agents
  and Multiagent Systems}, 2013.

\bibitem[Billings et~al.(1998{\natexlab{a}})Billings, Papp, Schaeffer, and
  Szafron]{opponent-modeling-in-poker}
Billings, Darse, Papp, Denis, Schaeffer, Jonathan, and Szafron, Duane.
\newblock Opponent modeling in poker.
\newblock In \emph{Association for the Advancement of Artificial Intelligence},
  1998{\natexlab{a}}.

\bibitem[Billings et~al.(1998{\natexlab{b}})Billings, Papp, Schaeffer, and
  Szafron]{poker-opp}
Billings, Darse, Papp, Denis, Schaeffer, Jonathan, and Szafron, Duane.
\newblock Opponent modeling in poker.
\newblock In \emph{Association for the Advancement of Artificial Intelligence},
  1998{\natexlab{b}}.

\bibitem[Boyd-Graber et~al.(2012)Boyd-Graber, Satinoff, He, and {Daum\'{e}
  III}]{Boyd-Graber:Satinoff:He:Daume-III-2012}
Boyd-Graber, Jordan, Satinoff, Brianna, He, He, and {Daum\'{e} III}, Hal.
\newblock Besting the quiz master: Crowdsourcing incremental classification
  games.
\newblock In \emph{Empirical Methods in Natural Language Processing}, 2012.

\bibitem[Collins(2007)]{collins-thesis-rl}
Collins, Brian.
\newblock Combining opponent modeling and model-based reinforcement learning in
  a two-player competitive game.
\newblock Master's thesis, School of Informatics, University of Edinburgh,
  2007.

\bibitem[Davidson(1999)]{davidson99opponent}
Davidson, Aaron.
\newblock Using artifical neural networks to model opponents in texas hold'em.
\newblock CMPUT 499 - Research Project Review, 1999.
\newblock URL \url{http://www.spaz.ca/aaron/poker/nnpoker.pdf}.

\bibitem[Duchi et~al.(2011)Duchi, Hazan, and Singer]{duchi2011adaptive}
Duchi, John, Hazan, Elad, and Singer, Yoram.
\newblock Adaptive subgradient methods for online learning and stochastic
  optimization.
\newblock \emph{Journal of Machine Learning Research}, 2011.

\bibitem[Eigen et~al.(2014)Eigen, Ranzato, and Sutskever]{eigen13dmoe}
Eigen, David, Ranzato, Marc'Aurelio, and Sutskever, Ilya.
\newblock Learning factored representations in a deep mixture of experts.
\newblock In \emph{ICLR Workshop}, 2014.

\bibitem[Foerster et~al.(2016)Foerster, Assael, de~Freitas, and
  Whiteson]{foerster16riddle}
Foerster, Jakob~N., Assael, Yannis~M., de~Freitas, Nando, and Whiteson, Shimon.
\newblock Learning to communicate to solve riddles with deep distributed
  recurrent q-networks.
\newblock \emph{Arxiv:1602.02672}, 2016.

\bibitem[Ganzfried \& Sandholm(2011)Ganzfried and
  Sandholm]{game-theory-opponent-modeling}
Ganzfried, Sam and Sandholm, Tuomas.
\newblock Game theory-based opponent modeling in large imperfect-information
  games.
\newblock In \emph{Proceedings of International Conference on Autonomous Agents
  and Multiagent Systems}, 2011.

\bibitem[Hausknecht \& Stone(2015)Hausknecht and Stone]{drqn}
Hausknecht, Matthew and Stone, Peter.
\newblock Deep recurrent q-learning for partially observable {MDP}s.
\newblock \emph{Arxiv:1507.06527}, 2015.

\bibitem[Jacobs et~al.(1991)Jacobs, Jordan, Nowlan, and Hinton]{moe}
Jacobs, Robert~A., Jordan, Michael~I., Nowlan, Steven~J., and Hinton,
  Geoffrey~E.
\newblock Adaptive mixtures of local experts.
\newblock \emph{Neural Computation}, 3\penalty0 (1):\penalty0 79--87, 1991.

\bibitem[Littman(1994)]{minimax-q}
Littman, Michael~L.
\newblock Markov games as a framework for multi-agent reinforcement learning.
\newblock In \emph{Proceedings of the International Conference of Machine
  Learning}, 1994.

\bibitem[Lockett et~al.(2007)Lockett, Chen, and
  Miikkulainen]{Lockett07evolvingexplicit}
Lockett, Alan~J., Chen, Charles~L., and Miikkulainen, Risto.
\newblock Evolving explicit opponent models in game playing.
\newblock In \emph{Proceeedings of the Genetic and Evolutionary Computation
  Conference}, 2007.

\bibitem[Mnih et~al.(2014)Mnih, Heess, Graves, and
  Kavukcuoglu]{mnih14visualattention}
Mnih, Volodymyr, Heess, Nicolas, Graves, Alex, and Kavukcuoglu, Koray.
\newblock Recurrent models of visual attention.
\newblock In \emph{Proceedings of Advances in Neural Information Processing
  Systems}, 2014.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, Petersen, Beattie, Sadik,
  Antonoglou, King, Kumaran, Wierstra, Legg, and Hassabis]{mnih-dqn-2015}
Mnih, Volodymyr, Kavukcuoglu, Koray, Silver, David, Rusu, Andrei~A., Veness,
  Joel, Bellemare, Marc~G., Graves, Alex, Riedmiller, Martin, Fidjeland,
  Andreas~K., Ostrovski, Georg, Petersen, Stig, Beattie, Charles, Sadik, Amir,
  Antonoglou, Ioannis, King, Helen, Kumaran, Dharshan, Wierstra, Daan, Legg,
  Shane, and Hassabis, Demis.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529--533, 02 2015.
\newblock URL \url{http://dx.doi.org/10.1038/nature14236}.

\bibitem[Richards \& Amir(2007)Richards and Amir]{scrabble-opp}
Richards, Mark and Amir, Eyal.
\newblock Opponent modeling in {S}crabble.
\newblock In \emph{International Joint Conference on Artificial Intelligence},
  2007.

\bibitem[Rubin \& Watson(2011)Rubin and Watson]{rubin11expert-imitator}
Rubin, Jonathan and Watson, Ian.
\newblock On combining decisions from multiple expert imitators for
  performance.
\newblock In \emph{International Joint Conference on Artificial Intelligence},
  2011.

\bibitem[Schadd et~al.(2007)Schadd, Bakkes, and
  Spronck]{schadd07opponentmodeling}
Schadd, Frederik, Bakkes, Er, and Spronck, Pieter.
\newblock Opponent modeling in real-time strategy games.
\newblock In \emph{Proceedings of the GAME-ON 2007}, pp.\  61--68, 2007.

\bibitem[Southey et~al.(2005)Southey, Bowling, Larson, Piccione, Burch,
  Billings, and Rayner]{bayesbluff}
Southey, Finnegan, Bowling, Michael, Larson, Bryce, Piccione, Carmelo, Burch,
  Neil, Billings, Darse, and Rayner, Chris.
\newblock Bayes' bluff: Opponent modelling in poker.
\newblock In \emph{Proceedings of Uncertainty in Artificial Intelligence},
  2005.

\bibitem[Sutton \& Barto(1998)Sutton and Barto]{rl-intro}
Sutton, Richard~S and Barto, Andrew~G.
\newblock \emph{Reinforcement learning: An introduction}, volume~1.
\newblock MIT Press Cambridge, 1998.

\bibitem[Tampuu et~al.(2015)Tampuu, Matiisen, Kodelja, Kuzovkin, Korjus, Aru,
  Aru, and Vicente]{multiagent-dqn}
Tampuu, Ardi, Matiisen, Tambet, Kodelja, Dorian, Kuzovkin, Ilya, Korjus,
  Kristjan, Aru, Juhan, Aru, Jaan, and Vicente, Raul.
\newblock Multiagent cooperation and competition with deep reinforcement
  learning.
\newblock \emph{ArXiv:1511.08779}, 2015.

\bibitem[Uther \& Veloso(2003)Uther and Veloso]{opponent-qlearning}
Uther, William and Veloso, Manuela.
\newblock Adversarial reinforcement learning.
\newblock Technical Report CMU-CS-03-107, School of Computer Science, Carnegie
  Mellon University, 2003.

\bibitem[Watkins \& Dayan(1992)Watkins and Dayan]{qlearning}
Watkins, Christopher J. C.~H. and Dayan, Peter.
\newblock Q-learning.
\newblock \emph{Machine Learning}, 8\penalty0 (3-4):\penalty0 279--292, 1992.

\bibitem[Zhang et~al.(2015)Zhang, McCarthy, Finn, Levine, and
  Abbeel]{zhang15dnnmemory}
Zhang, Marvin, McCarthy, Zoe, Finn, Chelsea, Levine, Sergey, and Abbeel,
  Pieter.
\newblock Learning deep neural network policies with continuous memory states.
\newblock \emph{ArXiv:1507.01273}, 2015.

\end{thebibliography}
