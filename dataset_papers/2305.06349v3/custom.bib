@inproceedings{
hu2022lora,
title={Lo{RA}: Low-Rank Adaptation of Large Language Models},
author={Edward J Hu and yelong shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=nZeVKeeFYf9}
}

@misc{ouyang2022training,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{Richardson2022,
  doi = {10.1609/aaai.v36i10.21371},
  url = {https://doi.org/10.1609/aaai.v36i10.21371},
  year = {2022},
  month = jun,
  publisher = {Association for the Advancement of Artificial Intelligence ({AAAI})},
  volume = {36},
  number = {10},
  pages = {11209--11219},
  author = {Kyle Richardson and Ashish Sabharwal},
  title = {Pushing the Limits of Rule Reasoning in Transformers through Natural Language Satisfiability},
  journal = {Proceedings of the {AAAI} Conference on Artificial Intelligence}
}

@inproceedings{Gaskell2022,
  doi = {10.24963/ijcai.2022/573},
  url = {https://doi.org/10.24963/ijcai.2022/573},
  year = {2022},
  month = jul,
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  author = {Alexander Gaskell and Yishu Miao and Francesca Toni and Lucia Specia},
  title = {Logically Consistent Adversarial Attacks for Soft Theorem Provers},
  booktitle = {Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence}
}

@article{Lenat_Prakash_Shepherd_1985, title={CYC: Using Common Sense Knowledge to Overcome Brittleness and Knowledge Acquisition Bottlenecks}, volume={6}, url={https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/510}, DOI={10.1609/aimag.v6i4.510}, abstractNote={The major limitations in building large software have always been (a) its brittleness when confronted by problems that were not foreseen by its builders, and (by the amount of manpower required. The recent history of expert systems, for example highlights how constricting the brittleness and knowledge acquisition bottlenecks are. Moreover, standard software methodology (e.g., working from a detailed &quot;spec&quot;) has proven of little use in AI, a field which by definition tackles ill- structured problems. How can these bottlenecks be widened? Attractive, elegant answers have included machine learning, automatic programming, and natural language understanding. But decades of work on such systems have convinced us that each of these approaches has difficulty &quot;scaling up&quot; for want a substantial base of real world knowledge.}, number={4}, journal={AI Magazine}, author={Lenat, Douglas B. and Prakash, Mayank and Shepherd, Mary}, year={1985}, month={Mar.}, pages={65} }

@article{Muggleton1994,
  doi = {10.1016/0743-1066(94)90035-3},
  url = {https://doi.org/10.1016/0743-1066(94)90035-3},
  year = {1994},
  month = may,
  publisher = {Elsevier {BV}},
  volume = {19-20},
  pages = {629--679},
  author = {Stephen Muggleton and Luc de Raedt},
  title = {Inductive Logic Programming: Theory and methods},
  journal = {The Journal of Logic Programming}
}

@article{Metaxiotis2002,
  doi = {10.1023/a:1016064126976},
  url = {https://doi.org/10.1023/a:1016064126976},
  year = {2002},
  publisher = {Springer Science and Business Media {LLC}},
  volume = {13},
  number = {4},
  pages = {253--260},
  author = {K. S. Metaxiotis and Dimitris Askounis and John Psarras},
  title = {Expert systems in production planning and scheduling: A state-of-the-art survey},
  journal = {Journal of Intelligent Manufacturing}
}

@incollection{Nunes2012,
  doi = {10.1007/978-1-4419-1428-6_790},
  url = {https://doi.org/10.1007/978-1-4419-1428-6_790},
  year = {2012},
  publisher = {Springer {US}},
  pages = {2066--2069},
  author = {Terezinha Nunes},
  title = {Logical Reasoning and Learning},
  booktitle = {Encyclopedia of the Sciences of Learning}
}

@incollection{Flach2000,
  doi = {10.1007/978-94-017-0606-3_1},
  url = {https://doi.org/10.1007/978-94-017-0606-3_1},
  year = {2000},
  publisher = {Springer Netherlands},
  pages = {1--27},
  author = {Peter A. Flach and Antonis C. Kakas},
  title = {Abductive and Inductive Reasoning: Background and Issues},
  booktitle = {Applied Logic Series}
}

@article{Goel2017,
  doi = {10.3389/fnhum.2016.00673},
  url = {https://doi.org/10.3389/fnhum.2016.00673},
  year = {2017},
  month = jan,
  publisher = {Frontiers Media {SA}},
  volume = {10},
  author = {Vinod Goel and Gorka Navarrete and Ira A. Noveck and J{\'{e}}r{\^{o}}me Prado},
  title = {Editorial: The Reasoning Brain: The Interplay between Cognitive Neuroscience and Theories of Reasoning},
  journal = {Frontiers in Human Neuroscience}
}

@inproceedings{transformer,
     author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
     booktitle = {Advances in Neural Information Processing Systems},
     editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
     pages = {},
     publisher = {Curran Associates, Inc.},
     title = {Attention is All you Need},
     url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
     volume = {30},
     year = {2017}
}

@misc{yang2022generating,
      title={Generating Natural Language Proofs with Verifier-Guided Search}, 
      author={Kaiyu Yang and Jia Deng and Danqi Chen},
      year={2022},
      eprint={2205.12443},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{Rudin2019,
  doi = {10.1038/s42256-019-0048-x},
  url = {https://doi.org/10.1038/s42256-019-0048-x},
  year = {2019},
  month = may,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {1},
  number = {5},
  pages = {206--215},
  author = {Cynthia Rudin},
  title = {Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
  journal = {Nature Machine Intelligence}
}

@misc{bhagavatula2020abductive,
      title={Abductive Commonsense Reasoning}, 
      author={Chandra Bhagavatula and Ronan Le Bras and Chaitanya Malaviya and Keisuke Sakaguchi and Ari Holtzman and Hannah Rashkin and Doug Downey and Scott Wen-tau Yih and Yejin Choi},
      year={2020},
      eprint={1908.05739},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{chowdhery2022palm,
      title={PaLM: Scaling Language Modeling with Pathways}, 
      author={Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and Parker Schuh and Kensen Shi and Sasha Tsvyashchenko and Joshua Maynez and Abhishek Rao and Parker Barnes and Yi Tay and Noam Shazeer and Vinodkumar Prabhakaran and Emily Reif and Nan Du and Ben Hutchinson and Reiner Pope and James Bradbury and Jacob Austin and Michael Isard and Guy Gur-Ari and Pengcheng Yin and Toju Duke and Anselm Levskaya and Sanjay Ghemawat and Sunipa Dev and Henryk Michalewski and Xavier Garcia and Vedant Misra and Kevin Robinson and Liam Fedus and Denny Zhou and Daphne Ippolito and David Luan and Hyeontaek Lim and Barret Zoph and Alexander Spiridonov and Ryan Sepassi and David Dohan and Shivani Agrawal and Mark Omernick and Andrew M. Dai and Thanumalayan Sankaranarayana Pillai and Marie Pellat and Aitor Lewkowycz and Erica Moreira and Rewon Child and Oleksandr Polozov and Katherine Lee and Zongwei Zhou and Xuezhi Wang and Brennan Saeta and Mark Diaz and Orhan Firat and Michele Catasta and Jason Wei and Kathy Meier-Hellstern and Douglas Eck and Jeff Dean and Slav Petrov and Noah Fiedel},
      year={2022},
      eprint={2204.02311},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{hendrycks2021measuring,
      title={Measuring Massive Multitask Language Understanding}, 
      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
      year={2021},
      eprint={2009.03300},
      archivePrefix={arXiv},
      primaryClass={cs.CY}
}

@misc{raffel2020exploring,
      title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer}, 
      author={Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
      year={2020},
      eprint={1910.10683},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{Bosselut2019DynamicKG,
     author = {Antoine Bosselut and Ronan Le Bras and and Yejin Choi},
     booktitle = {Proceedings of the 35th AAAI Conference on Artificial Intelligence (AAAI)},
     title = {Dynamic Neuro-Symbolic Knowledge Graph Construction for Zero-shot Commonsense Question Answering},
     year = {2021}
}

@misc{yang2023logical,
      title={Logical Reasoning over Natural Language as Knowledge Representation: A Survey}, 
      author={Zonglin Yang and Xinya Du and Rui Mao and Jinjie Ni and Erik Cambria},
      year={2023},
      eprint={2303.12023},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{Bayazit2023DiscoveringKS,
  title={Discovering Knowledge-Critical Subnetworks in Pretrained Language Models},
  author={Deniz Bayazit and Negar Foroutan and Zeming Chen and Gail Weiss and Antoine Bosselut},
  journal={ArXiv},
  year={2023},
  volume={abs/2310.03084},
  url={https://api.semanticscholar.org/CorpusID:263671765}
}

@misc{wolf2020huggingfaces,
      title={HuggingFace's Transformers: State-of-the-art Natural Language Processing}, 
      author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
      year={2020},
      eprint={1910.03771},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{
    meng2022locating,
    title={Locating and Editing Factual Associations in {GPT}},
    author={Kevin Meng and David Bau and Alex J Andonian and Yonatan Belinkov},
    booktitle={Advances in Neural Information Processing Systems},
    editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
    year={2022},
    url={https://openreview.net/forum?id=-h6WAS6eE4}
}

@misc{petroni2020context,
      title={How Context Affects Language Models' Factual Predictions}, 
      author={Fabio Petroni and Patrick Lewis and Aleksandra Piktus and Tim Rocktäschel and Yuxiang Wu and Alexander H. Miller and Sebastian Riedel},
      year={2020},
      eprint={2005.04611},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{
    yu2023generate,
    title={Generate rather than Retrieve: Large Language Models are Strong Context Generators},
    author={Wenhao Yu and Dan Iter and Shuohang Wang and Yichong Xu and Mingxuan Ju and Soumya Sanyal and Chenguang Zhu and Michael Zeng and Meng Jiang},
    booktitle={The Eleventh International Conference on Learning Representations },
    year={2023},
    url={https://openreview.net/forum?id=fB0hRu9GZUS}
}

@misc{carlini2021extracting,
      title={Extracting Training Data from Large Language Models}, 
      author={Nicholas Carlini and Florian Tramer and Eric Wallace and Matthew Jagielski and Ariel Herbert-Voss and Katherine Lee and Adam Roberts and Tom Brown and Dawn Song and Ulfar Erlingsson and Alina Oprea and Colin Raffel},
      year={2021},
      eprint={2012.07805},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@inproceedings{
    carlini2023quantifying,
    title={Quantifying Memorization Across Neural Language Models},
    author={Nicholas Carlini and Daphne Ippolito and Matthew Jagielski and Katherine Lee and Florian Tramer and Chiyuan Zhang},
    booktitle={The Eleventh International Conference on Learning Representations },
    year={2023},
    url={https://openreview.net/forum?id=TatRHT_1cK}
}

@misc{logiqa,
  doi = {10.48550/ARXIV.2007.08124},
  url = {https://arxiv.org/abs/2007.08124},
  author = {Liu, Jian and Cui, Leyang and Liu, Hanmeng and Huang, Dandan and Wang, Yile and Zhang, Yue},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{Metaxiotis2002ExpertSI,
  title={Expert systems in production planning and scheduling: A state-of-the-art survey},
  author={Kostas S. Metaxiotis and Dimitris Askounis and John E. Psarras},
  journal={Journal of Intelligent Manufacturing},
  year={2002},
  volume={13},
  pages={253-260}
}


@misc{folio,
  doi = {10.48550/ARXIV.2209.00840},
  url = {https://arxiv.org/abs/2209.00840},
  author = {Han, Simeng and Schoelkopf, Hailey and Zhao, Yilun and Qi, Zhenting and Riddell, Martin and Benson, Luke and Sun, Lucy and Zubova, Ekaterina and Qiao, Yujie and Burtell, Matthew and Peng, David and Fan, Jonathan and Liu, Yixin and Wong, Brian and Sailor, Malcolm and Ni, Ansong and Nan, Linyong and Kasai, Jungo and Yu, Tao and Zhang, Rui and Joty, Shafiq and Fabbri, Alexander R. and Kryscinski, Wojciech and Lin, Xi Victoria and Xiong, Caiming and Radev, Dragomir},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {FOLIO: Natural Language Reasoning with First-Order Logic},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@InProceedings{maml,
  title = 	 {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
  author =       {Chelsea Finn and Pieter Abbeel and Sergey Levine},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1126--1135},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/finn17a/finn17a.pdf},
  url = 	 {https://proceedings.mlr.press/v70/finn17a.html},
}

@misc{model_edit,
  doi = {10.48550/ARXIV.2110.11309},
  url = {https://arxiv.org/abs/2110.11309},
  author = {Mitchell, Eric and Lin, Charles and Bosselut, Antoine and Finn, Chelsea and Manning, Christopher D.},
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Fast Model Editing at Scale},
  publisher = {arXiv},
  year = {2021},
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{gpt-2,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year={2019}
}

@inproceedings{AdamW,
  title={Decoupled Weight Decay Regularization},
  author={Ilya Loshchilov and Frank Hutter},
  booktitle={International Conference on Learning Representations},
  year={2017}
}

@book{enigma-reason,
	year = {2017},
	author = {Dan Sperber and Hugo Mercier},
	title = {The Enigma of Reason},
	publisher = {Cambridge, MA, USA: Harvard University Press}
}

@inproceedings{ProofWriter,
    title = "{P}roof{W}riter: Generating Implications, Proofs, and Abductive Statements over Natural Language",
    author = "Tafjord, Oyvind  and
      Dalvi, Bhavana  and
      Clark, Peter",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.317",
    doi = "10.18653/v1/2021.findings-acl.317",
    pages = "3621--3634",
}

@inproceedings{RuleTaker,
  title     = {Transformers as Soft Reasoners over Language},
  author    = {Clark, Peter and Tafjord, Oyvind and Richardson, Kyle},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Christian Bessiere},
  pages     = {3882--3890},
  year      = {2020},
  month     = {7},
  note      = {Main track},
  doi       = {10.24963/ijcai.2020/537},
  url       = {https://doi.org/10.24963/ijcai.2020/537},
}

@inproceedings{CLUTRR,
    title = "{CLUTRR}: A Diagnostic Benchmark for Inductive Reasoning from Text",
    author = "Sinha, Koustuv  and
      Sodhani, Shagun  and
      Dong, Jin  and
      Pineau, Joelle  and
      Hamilton, William L.",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1458",
    doi = "10.18653/v1/D19-1458",
    pages = "4506--4515",
    abstract = "The recent success of natural language understanding (NLU) systems has been troubled by results highlighting the failure of these models to generalize in a systematic and robust way. In this work, we introduce a diagnostic benchmark suite, named CLUTRR, to clarify some key issues related to the robustness and systematicity of NLU systems. Motivated by the classic work on inductive logic programming, CLUTRR requires that an NLU system infer kinship relations between characters in short stories. Successful performance on this task requires both extracting relationships between entities, as well as inferring the logical rules governing these relationships. CLUTRR allows us to precisely measure a model{'}s ability for systematic generalization by evaluating on held-out combinations of logical rules, and allows us to evaluate a model{'}s robustness by adding curated noise facts. Our empirical results highlight a substantial performance gap between state-of-the-art NLU models (e.g., BERT and MAC) and a graph neural network model that works directly with symbolic inputs{---}with the graph-based model exhibiting both stronger generalization and greater robustness.",
}

@article{CLUTRR-SG,
  title={Measuring Systematic Generalization in Neural Proof Generation with Transformers},
  author={Nicolas Gontier and Koustuv Sinha and Siva Reddy and Christopher Joseph Pal},
  journal={ArXiv},
  year={2020},
  volume={abs/2009.14786}
}

@misc{neeman2022disentqa,
      title={DisentQA: Disentangling Parametric and Contextual Knowledge with Counterfactual Question Answering}, 
      author={Ella Neeman and Roee Aharoni and Or Honovich and Leshem Choshen and Idan Szpektor and Omri Abend},
      year={2022},
      eprint={2211.05655},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{ALFA,
  title={Meta-Learning with Adaptive Hyperparameters},
  author={Sungyong Baik and Myungsub Choi and Janghoon Choi and Heewon Kim and Kyoung Mu Lee},
  journal={ArXiv},
  year={2020},
  volume={abs/2011.00209}
}

@misc{fifty2021measuring,
      title={Measuring and Harnessing Transference in Multi-Task Learning}, 
      author={Christopher Fifty and Ehsan Amid and Zhe Zhao and Tianhe Yu and Rohan Anil and Chelsea Finn},
      year={2021},
      eprint={2010.15413},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{brown2020language,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{dunn2017searchqa,
      title={SearchQA: A New Q\&A Dataset Augmented with Context from a Search Engine}, 
      author={Matthew Dunn and Levent Sagun and Mike Higgins and V. Ugur Guney and Volkan Cirik and Kyunghyun Cho},
      year={2017},
      eprint={1704.05179},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{shaban2019truncated,
      title={Truncated Back-propagation for Bilevel Optimization}, 
      author={Amirreza Shaban and Ching-An Cheng and Nathan Hatch and Byron Boots},
      year={2019},
      eprint={1810.10667},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{
    meng2023massediting,
    title={Mass-Editing Memory in a Transformer},
    author={Kevin Meng and Arnab Sen Sharma and Alex J Andonian and Yonatan Belinkov and David Bau},
    booktitle={The Eleventh International Conference on Learning Representations },
    year={2023},
    url={https://openreview.net/forum?id=MkbcAHIYgyS}
}

@misc{hase2021language,
      title={Do Language Models Have Beliefs? Methods for Detecting, Updating, and Visualizing Model Beliefs}, 
      author={Peter Hase and Mona Diab and Asli Celikyilmaz and Xian Li and Zornitsa Kozareva and Veselin Stoyanov and Mohit Bansal and Srinivasan Iyer},
      year={2021},
      eprint={2111.13654},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{yao2022kformer,
      title={Kformer: Knowledge Injection in Transformer Feed-Forward Layers}, 
      author={Yunzhi Yao and Shaohan Huang and Li Dong and Furu Wei and Huajun Chen and Ningyu Zhang},
      year={2022},
      eprint={2201.05742},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{
    antoniou2018how,
    title={How to train your {MAML}},
    author={Antreas Antoniou and Harrison Edwards and Amos Storkey},
    booktitle={International Conference on Learning Representations},
    year={2019},
    url={https://openreview.net/forum?id=HJGven05Y7},
}

@misc{liu2019roberta,
      title={RoBERTa: A Robustly Optimized BERT Pretraining Approach}, 
      author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
      year={2019},
      eprint={1907.11692},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{garrett-2023-chatgpt-knots,
author = {Andrew Garrett},
title = {``ChatGPT ties itself in knots to avoid having professors be female.'' [with screenshot]},
howpublished ={\url{https://twitter.com/ndyjroo/status/1649821809154613248/}},
year={2023},
month={April},
}


@inproceedings{hwang2021comet,
  title={(Comet-) Atomic 2020: On Symbolic and Neural Commonsense Knowledge Graphs},
  author={Hwang, Jena D and Bhagavatula, Chandra and Le Bras, Ronan and Da, Jeff and Sakaguchi, Keisuke and Bosselut, Antoine and Choi, Yejin},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  pages={6384--6392},
  year={2021}
}

@inproceedings{bosselut2019comet,
  title={COMET: Commonsense Transformers for Automatic Knowledge Graph Construction},
  author={Bosselut, Antoine and Rashkin, Hannah and Sap, Maarten and Malaviya, Chaitanya and Celikyilmaz, Asli and Choi, Yejin},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={4762--4779},
  year={2019}
}


@inproceedings{yasunaga2021qa,
  title={QA-GNN: Reasoning with Language Models and Knowledge Graphs for Question Answering},
  author={Yasunaga, Michihiro and Ren, Hongyu and Bosselut, Antoine and Liang, Percy and Leskovec, Jure},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={535--546},
  year={2021}
}

@inproceedings{zhang2022greaselm,
    title={GreaseLM: Graph REASoning Enhanced Language Models for Question Answering}, 
    author={Xikun Zhang and Antoine Bosselut and Michihiro Yasunaga and Hongyu Ren and Percy Liang and Christopher D. Manning and Jure Leskovec},
    year={2022},
	booktitle = {Proceedings of the 10th International Conference for Learning Representations (ICLR)},      
}

@inproceedings{Jiang2021Anion,
 title = "{``}{I}{'}m Not Mad{''}: Commonsense Implications of Negation and Contradiction",
    author = "Jiang, Liwei  and
      Bosselut, Antoine  and
      Bhagavatula, Chandra  and
      Choi, Yejin",
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.346",
    doi = "10.18653/v1/2021.naacl-main.346",
    pages = "4380--4397"
}

@misc{liu2023evaluating,
      title={Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4}, 
      author={Hanmeng Liu and Ruoxi Ning and Zhiyang Teng and Jian Liu and Qiji Zhou and Yue Zhang},
      year={2023},
      eprint={2304.03439},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{Arabshahi2021ConverationalMH,
  title={Conversational Multi-Hop Reasoning with Neural Commonsense Knowledge and Symbolic Logic Rules},
  author={Forough Arabshahi and Jennifer Lee and Antoine Bosselut and Yejin Choi and Tom Mitchell},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2021}
}

@inproceedings{Da2020AnalyzingCE,
 author = {Jeff Da and Ronan Le Bras and Ximing Lu and Yejin Choi and Antoine Bosselut},
 title = {Analyzing Commonsense Emergence in Few-shot Knowledge Models},
 booktitle={Proceedings of the Conference on Automated Knowledge Base Construction (AKBC)},
 year={2021}
}

@inproceedings{west2021symbolic,
  title={Symbolic knowledge distillation: from general language models to commonsense models},
  author={West, Peter and Bhagavatula, Chandra and Hessel, Jack and Hwang, Jena D and Jiang, Liwei and Bras, Ronan Le and Lu, Ximing and Welleck, Sean and Choi, Yejin},
  booktitle={Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  year={2022}
}

@article{ismayilzada2022kogito,
  title={kogito: A Commonsense Knowledge Inference Toolkit},
  author={Mete Ismayilzada and Antoine Bosselut},
  journal={ArXiv},
  volume={abs/2211.08451},
  year={2022}
}

@inproceedings{gao2022comfact,
  title={Comfact: A benchmark for linking contextual commonsense knowledge},
  author={Gao, Silin and Hwang, Jena D and Kanno, Saya and Wakaki, Hiromi and Mitsufuji, Yuki and Bosselut, Antoine},
  booktitle={Findings of EMNLP},
  year={2022}
}

@inproceedings{qin-etal-2019-counterfactual,
  title = "Counterfactual Story Reasoning and Generation",
  author = "Qin, Lianhui  and
  Bosselut, Antoine  and
  Holtzman, Ari  and
  Bhagavatula, Chandra  and
  Clark, Elizabeth  and
  Choi, Yejin",
  booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
  month = nov,
  year = "2019",
  address = "Hong Kong, China",
  publisher = "Association for Computational Linguistics",
  url = "https://www.aclweb.org/anthology/D19-1509",
  doi = "10.18653/v1/D19-1509",
  pages = "5043--5053",
  abstract = "Counterfactual reasoning requires predicting how alternative events, contrary to what actually happened, might have resulted in different outcomes. Despite being considered a necessary component of AI-complete systems, few resources have been developed for evaluating counterfactual reasoning in narratives. In this paper, we propose Counterfactual Story Rewriting: given an original story and an intervening counterfactual event, the task is to minimally revise the story to make it compatible with the given counterfactual event. Solving this task will require deep understanding of causal narrative chains and counterfactual invariance, and integration of such story reasoning capabilities into conditional language generation models. We present TIMETRAVEL, a new dataset of 29,849 counterfactual rewritings, each with the original story, a counterfactual event, and human-generated revision of the original story compatible with the counterfactual event. Additionally, we include 81,407 counterfactual {``}branches{''} without a rewritten storyline to support future work on semi- or un-supervised approaches to counterfactual story rewriting. Finally, we evaluate the counterfactual rewriting capacities of several competitive baselines based on pretrained language models, and assess whether common overlap and model-based automatic metrics for text generation correlate well with human scores for counterfactual rewriting.",
  }

  @inproceedings{yasunaga-2022-dragon,
  title={Deep Bidirectional Language-Knowledge Graph Pretraining},
  author={Michihiro Yasunaga and Antoine Bosselut and Hongyu Ren and Xikun Zhang and Christopher D Manning and Percy Liang and Jure Leskovec},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022}
}

@inproceedings{helwe-etal-2021-reasoning,
  author       = {Chadi Helwe and
                  Chlo{\'{e}} Clavel and
                  Fabian M. Suchanek},
  editor       = {Danqi Chen and
                  Jonathan Berant and
                  Andrew McCallum and
                  Sameer Singh},
  title        = {Reasoning with Transformer-based Models: Deep Learning, but Shallow
                  Reasoning},
  booktitle    = {3rd Conference on Automated Knowledge Base Construction, {AKBC} 2021,
                  Virtual, October 4-8, 2021},
  year         = {2021},
  url          = {https://doi.org/10.24432/C5W300},
  doi          = {10.24432/C5W300},
  timestamp    = {Tue, 08 Mar 2022 16:02:24 +0100},
  biburl       = {https://dblp.org/rec/conf/akbc/HelweCS21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{shi-etal-2023-distractors,
  author       = {Freda Shi and
                  Xinyun Chen and
                  Kanishka Misra and
                  Nathan Scales and
                  David Dohan and
                  Ed H. Chi and
                  Nathanael Sch{\"{a}}rli and
                  Denny Zhou},
  title        = {Large Language Models Can Be Easily Distracted by Irrelevant Context},
  journal      = {CoRR},
  volume       = {abs/2302.00093},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2302.00093},
  doi          = {10.48550/arXiv.2302.00093},
  eprinttype    = {arXiv},
  eprint       = {2302.00093},
  timestamp    = {Thu, 09 Feb 2023 16:11:17 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2302-00093.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{inference-blog,
author={Chen, Carol},
title={Transformer Inference Arithmetic},
howpublished={https://kipp.ly/blog/transformer-inference-arithmetic/},
year={2022}
}

@misc{srivastava2022imitation,
      title={Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models}, 
      author={Aarohi Srivastava and Abhinav Rastogi and Abhishek Rao and Abu Awal Md Shoeb and Abubakar Abid and Adam Fisch and Adam R. Brown and Adam Santoro and Aditya Gupta and Adrià Garriga-Alonso and Agnieszka Kluska and Aitor Lewkowycz and Akshat Agarwal and Alethea Power and Alex Ray and Alex Warstadt and Alexander W. Kocurek and Ali Safaya and Ali Tazarv and Alice Xiang and Alicia Parrish and Allen Nie and Aman Hussain and Amanda Askell and Amanda Dsouza and Ambrose Slone and Ameet Rahane and Anantharaman S. Iyer and Anders Andreassen and Andrea Madotto and Andrea Santilli and Andreas Stuhlmüller and Andrew Dai and Andrew La and Andrew Lampinen and Andy Zou and Angela Jiang and Angelica Chen and Anh Vuong and Animesh Gupta and Anna Gottardi and Antonio Norelli and Anu Venkatesh and Arash Gholamidavoodi and Arfa Tabassum and Arul Menezes and Arun Kirubarajan and Asher Mullokandov and Ashish Sabharwal and Austin Herrick and Avia Efrat and Aykut Erdem and Ayla Karakaş and B. Ryan Roberts and Bao Sheng Loe and Barret Zoph and Bartłomiej Bojanowski and Batuhan Özyurt and Behnam Hedayatnia and Behnam Neyshabur and Benjamin Inden and Benno Stein and Berk Ekmekci and Bill Yuchen Lin and Blake Howald and Cameron Diao and Cameron Dour and Catherine Stinson and Cedrick Argueta and César Ferri Ramírez and Chandan Singh and Charles Rathkopf and Chenlin Meng and Chitta Baral and Chiyu Wu and Chris Callison-Burch and Chris Waites and Christian Voigt and Christopher D. Manning and Christopher Potts and Cindy Ramirez and Clara E. Rivera and Clemencia Siro and Colin Raffel and Courtney Ashcraft and Cristina Garbacea and Damien Sileo and Dan Garrette and Dan Hendrycks and Dan Kilman and Dan Roth and Daniel Freeman and Daniel Khashabi and Daniel Levy and Daniel Moseguí González and Danielle Perszyk and Danny Hernandez and Danqi Chen and Daphne Ippolito and Dar Gilboa and David Dohan and David Drakard and David Jurgens and Debajyoti Datta and Deep Ganguli and Denis Emelin and Denis Kleyko and Deniz Yuret and Derek Chen and Derek Tam and Dieuwke Hupkes and Diganta Misra and Dilyar Buzan and Dimitri Coelho Mollo and Diyi Yang and Dong-Ho Lee and Ekaterina Shutova and Ekin Dogus Cubuk and Elad Segal and Eleanor Hagerman and Elizabeth Barnes and Elizabeth Donoway and Ellie Pavlick and Emanuele Rodola and Emma Lam and Eric Chu and Eric Tang and Erkut Erdem and Ernie Chang and Ethan A. Chi and Ethan Dyer and Ethan Jerzak and Ethan Kim and Eunice Engefu Manyasi and Evgenii Zheltonozhskii and Fanyue Xia and Fatemeh Siar and Fernando Martínez-Plumed and Francesca Happé and Francois Chollet and Frieda Rong and Gaurav Mishra and Genta Indra Winata and Gerard de Melo and Germán Kruszewski and Giambattista Parascandolo and Giorgio Mariani and Gloria Wang and Gonzalo Jaimovitch-López and Gregor Betz and Guy Gur-Ari and Hana Galijasevic and Hannah Kim and Hannah Rashkin and Hannaneh Hajishirzi and Harsh Mehta and Hayden Bogar and Henry Shevlin and Hinrich Schütze and Hiromu Yakura and Hongming Zhang and Hugh Mee Wong and Ian Ng and Isaac Noble and Jaap Jumelet and Jack Geissinger and Jackson Kernion and Jacob Hilton and Jaehoon Lee and Jaime Fernández Fisac and James B. Simon and James Koppel and James Zheng and James Zou and Jan Kocoń and Jana Thompson and Jared Kaplan and Jarema Radom and Jascha Sohl-Dickstein and Jason Phang and Jason Wei and Jason Yosinski and Jekaterina Novikova and Jelle Bosscher and Jennifer Marsh and Jeremy Kim and Jeroen Taal and Jesse Engel and Jesujoba Alabi and Jiacheng Xu and Jiaming Song and Jillian Tang and Joan Waweru and John Burden and John Miller and John U. Balis and Jonathan Berant and Jörg Frohberg and Jos Rozen and Jose Hernandez-Orallo and Joseph Boudeman and Joseph Jones and Joshua B. Tenenbaum and Joshua S. Rule and Joyce Chua and Kamil Kanclerz and Karen Livescu and Karl Krauth and Karthik Gopalakrishnan and Katerina Ignatyeva and Katja Markert and Kaustubh D. Dhole and Kevin Gimpel and Kevin Omondi and Kory Mathewson and Kristen Chiafullo and Ksenia Shkaruta and Kumar Shridhar and Kyle McDonell and Kyle Richardson and Laria Reynolds and Leo Gao and Li Zhang and Liam Dugan and Lianhui Qin and Lidia Contreras-Ochando and Louis-Philippe Morency and Luca Moschella and Lucas Lam and Lucy Noble and Ludwig Schmidt and Luheng He and Luis Oliveros Colón and Luke Metz and Lütfi Kerem Şenel and Maarten Bosma and Maarten Sap and Maartje ter Hoeve and Maheen Farooqi and Manaal Faruqui and Mantas Mazeika and Marco Baturan and Marco Marelli and Marco Maru and Maria Jose Ramírez Quintana and Marie Tolkiehn and Mario Giulianelli and Martha Lewis and Martin Potthast and Matthew L. Leavitt and Matthias Hagen and Mátyás Schubert and Medina Orduna Baitemirova and Melody Arnaud and Melvin McElrath and Michael A. Yee and Michael Cohen and Michael Gu and Michael Ivanitskiy and Michael Starritt and Michael Strube and Michał Swędrowski and Michele Bevilacqua and Michihiro Yasunaga and Mihir Kale and Mike Cain and Mimee Xu and Mirac Suzgun and Mo Tiwari and Mohit Bansal and Moin Aminnaseri and Mor Geva and Mozhdeh Gheini and Mukund Varma T and Nanyun Peng and Nathan Chi and Nayeon Lee and Neta Gur-Ari Krakover and Nicholas Cameron and Nicholas Roberts and Nick Doiron and Nikita Nangia and Niklas Deckers and Niklas Muennighoff and Nitish Shirish Keskar and Niveditha S. Iyer and Noah Constant and Noah Fiedel and Nuan Wen and Oliver Zhang and Omar Agha and Omar Elbaghdadi and Omer Levy and Owain Evans and Pablo Antonio Moreno Casares and Parth Doshi and Pascale Fung and Paul Pu Liang and Paul Vicol and Pegah Alipoormolabashi and Peiyuan Liao and Percy Liang and Peter Chang and Peter Eckersley and Phu Mon Htut and Pinyu Hwang and Piotr Miłkowski and Piyush Patil and Pouya Pezeshkpour and Priti Oli and Qiaozhu Mei and Qing Lyu and Qinlang Chen and Rabin Banjade and Rachel Etta Rudolph and Raefer Gabriel and Rahel Habacker and Ramón Risco Delgado and Raphaël Millière and Rhythm Garg and Richard Barnes and Rif A. Saurous and Riku Arakawa and Robbe Raymaekers and Robert Frank and Rohan Sikand and Roman Novak and Roman Sitelew and Ronan LeBras and Rosanne Liu and Rowan Jacobs and Rui Zhang and Ruslan Salakhutdinov and Ryan Chi and Ryan Lee and Ryan Stovall and Ryan Teehan and Rylan Yang and Sahib Singh and Saif M. Mohammad and Sajant Anand and Sam Dillavou and Sam Shleifer and Sam Wiseman and Samuel Gruetter and Samuel R. Bowman and Samuel S. Schoenholz and Sanghyun Han and Sanjeev Kwatra and Sarah A. Rous and Sarik Ghazarian and Sayan Ghosh and Sean Casey and Sebastian Bischoff and Sebastian Gehrmann and Sebastian Schuster and Sepideh Sadeghi and Shadi Hamdan and Sharon Zhou and Shashank Srivastava and Sherry Shi and Shikhar Singh and Shima Asaadi and Shixiang Shane Gu and Shubh Pachchigar and Shubham Toshniwal and Shyam Upadhyay and Shyamolima and Debnath and Siamak Shakeri and Simon Thormeyer and Simone Melzi and Siva Reddy and Sneha Priscilla Makini and Soo-Hwan Lee and Spencer Torene and Sriharsha Hatwar and Stanislas Dehaene and Stefan Divic and Stefano Ermon and Stella Biderman and Stephanie Lin and Stephen Prasad and Steven T. Piantadosi and Stuart M. Shieber and Summer Misherghi and Svetlana Kiritchenko and Swaroop Mishra and Tal Linzen and Tal Schuster and Tao Li and Tao Yu and Tariq Ali and Tatsu Hashimoto and Te-Lin Wu and Théo Desbordes and Theodore Rothschild and Thomas Phan and Tianle Wang and Tiberius Nkinyili and Timo Schick and Timofei Kornev and Timothy Telleen-Lawton and Titus Tunduny and Tobias Gerstenberg and Trenton Chang and Trishala Neeraj and Tushar Khot and Tyler Shultz and Uri Shaham and Vedant Misra and Vera Demberg and Victoria Nyamai and Vikas Raunak and Vinay Ramasesh and Vinay Uday Prabhu and Vishakh Padmakumar and Vivek Srikumar and William Fedus and William Saunders and William Zhang and Wout Vossen and Xiang Ren and Xiaoyu Tong and Xinran Zhao and Xinyi Wu and Xudong Shen and Yadollah Yaghoobzadeh and Yair Lakretz and Yangqiu Song and Yasaman Bahri and Yejin Choi and Yichi Yang and Yiding Hao and Yifu Chen and Yonatan Belinkov and Yu Hou and Yufang Hou and Yuntao Bai and Zachary Seid and Zhuoye Zhao and Zijian Wang and Zijie J. Wang and Zirui Wang and Ziyi Wu},
      year={2022},
      eprint={2206.04615},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
