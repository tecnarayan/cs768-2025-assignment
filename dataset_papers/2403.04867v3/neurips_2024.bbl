\begin{thebibliography}{76}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Dwork et~al.(2006{\natexlab{a}})Dwork, McSherry, Nissim, and Smith]{dwork2006calibrating}
Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith.
\newblock Calibrating noise to sensitivity in private data analysis.
\newblock In \emph{Theory of Cryptography}, pages 265--284. Springer, 2006{\natexlab{a}}.

\bibitem[Dwork et~al.(2006{\natexlab{b}})Dwork, Kenthapadi, McSherry, Mironov, and Naor]{dwork2006approximate}
Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni Naor.
\newblock Our data, ourselves: Privacy via distributed noise generation.
\newblock In \emph{Advances in Cryptology - EUROCRYPT}, pages 486--503, 2006{\natexlab{b}}.

\bibitem[Dwork et~al.(2014)Dwork, Roth, et~al.]{dwork2014algorithmic}
Cynthia Dwork, Aaron Roth, et~al.
\newblock The algorithmic foundations of differential privacy.
\newblock \emph{Foundations and Trends in Theoretical Computer Science}, 9\penalty0 (3--4):\penalty0 211--407, 2014.

\bibitem[Kairouz et~al.(2015)Kairouz, Oh, and Viswanath]{kairouz2015composition}
Peter Kairouz, Sewoong Oh, and Pramod Viswanath.
\newblock The composition theorem for differential privacy.
\newblock In \emph{International conference on machine learning}, pages 1376--1385, 2015.

\bibitem[Murtagh and Vadhan(2015)]{murtagh2015complexity}
Jack Murtagh and Salil Vadhan.
\newblock The complexity of computing the optimal composition of differential privacy.
\newblock In \emph{Theory of Cryptography Conference}, pages 157--175, 2015.

\bibitem[Abadi et~al.(2016)Abadi, Chu, Goodfellow, McMahan, Mironov, Talwar, and Zhang]{abadi2016deep}
Martin Abadi, Andy Chu, Ian Goodfellow, H~Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li~Zhang.
\newblock Deep learning with differential privacy.
\newblock In \emph{Proceedings of the SIGSAC conference on computer and communications security}, pages 308--318, 2016.

\bibitem[Mironov(2017)]{mironov2017renyi}
Ilya Mironov.
\newblock R{\'e}nyi differential privacy.
\newblock In \emph{IEEE 30th computer security foundations symposium (CSF)}, pages 263--275, 2017.

\bibitem[Koskela et~al.(2020)Koskela, J{\"a}lk{\"o}, and Honkela]{koskela2020computing}
Antti Koskela, Joonas J{\"a}lk{\"o}, and Antti Honkela.
\newblock Computing tight differential privacy guarantees using fft.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pages 2560--2569, 2020.

\bibitem[Dong et~al.(2022)Dong, Roth, and Su]{dong2022gaussian}
Jinshuo Dong, Aaron Roth, and Weijie~J Su.
\newblock Gaussian differential privacy.
\newblock \emph{Journal of the Royal Statistical Society Series B: Statistical Methodology}, 84\penalty0 (1):\penalty0 3--37, 2022.

\bibitem[Zhu et~al.(2022)Zhu, Dong, and Wang]{zhu2022optimal}
Yuqing Zhu, Jinshuo Dong, and Yu-Xiang Wang.
\newblock Optimal accounting of differential privacy via characteristic function.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pages 4782--4817, 2022.

\bibitem[Alghamdi et~al.(2023)Alghamdi, G{\'{o}}mez, Asoodeh, Calmon, Kosut, and Sankar]{alghamdi2023saddlepoint}
Wael Alghamdi, Juan~Felipe G{\'{o}}mez, Shahab Asoodeh, Fl{\'{a}}vio~P. Calmon, Oliver Kosut, and Lalitha Sankar.
\newblock The saddle-point method in differential privacy.
\newblock In \emph{International Conference on Machine Learning}, 2023.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Mahloujifar, Wu, Jia, and Mittal]{wang2023randomized}
Jiachen~Tianhao Wang, Saeed Mahloujifar, Tong Wu, Ruoxi Jia, and Prateek Mittal.
\newblock A randomized approach to tight privacy accounting.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2023{\natexlab{a}}.

\bibitem[Kasiviswanathan et~al.(2011)Kasiviswanathan, Lee, Nissim, Raskhodnikova, and Smith]{kasiviswanathan2011can}
Shiva~Prasad Kasiviswanathan, Homin~K Lee, Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith.
\newblock What can we learn privately?
\newblock \emph{SIAM Journal on Computing}, 40\penalty0 (3):\penalty0 793--826, 2011.

\bibitem[Li et~al.(2012)Li, Qardaji, and Su]{li2012sampling}
Ninghui Li, Wahbeh Qardaji, and Dong Su.
\newblock On sampling, anonymization, and differential privacy or, k-anonymization meets differential privacy.
\newblock In \emph{Proceedings of the 7th ACM Symposium on Information, Computer and Communications Security}, pages 32--33, 2012.

\bibitem[Balle et~al.(2018)Balle, Barthe, and Gaboardi]{balle2018couplings}
Borja Balle, Gilles Barthe, and Marco Gaboardi.
\newblock Privacy amplification by subsampling: Tight analyses via couplings and divergences.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Meiser and Mohammadi(2018)]{Meiser2018Buckets}
Sebastian Meiser and Esfandiar Mohammadi.
\newblock Tight on budget? tight bounds for r-fold approximate differential privacy.
\newblock In \emph{Proceedings of the ACM SIGSAC Conference on Computer and Communications Security}, pages 247--264, 2018.

\bibitem[Koskela and Honkela(2021)]{koskela2021computing}
Antti Koskela and Antti Honkela.
\newblock Computing differential privacy guarantees for heterogeneous compositions using fft.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Koskela et~al.(2021)Koskela, J{\"a}lk{\"o}, Prediger, and Honkela]{koskela2021tight}
Antti Koskela, Joonas J{\"a}lk{\"o}, Lukas Prediger, and Antti Honkela.
\newblock Tight differential privacy for discrete-valued mechanisms and for the subsampled gaussian mechanism using fft.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pages 3358--3366, 2021.

\bibitem[Gopi et~al.(2021)Gopi, Lee, and Wutschitz]{gopi2021numerical}
Sivakanth Gopi, Yin~Tat Lee, and Lukas Wutschitz.
\newblock Numerical composition of differential privacy.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 11631--11642, 2021.

\bibitem[Doroshenko et~al.(2022)Doroshenko, Ghazi, Kamath, Kumar, and Manurangsi]{doroshenko2022connect}
Vadym Doroshenko, Badih Ghazi, Pritish Kamath, Ravi Kumar, and Pasin Manurangsi.
\newblock Connect the dots: Tighter discrete approximations of privacy loss distributions.
\newblock \emph{Proceedings on Privacy Enhancing Technologies}, 2022.

\bibitem[Ghazi et~al.(2022)Ghazi, Kamath, Kumar, and Manurangsi]{ghazi2022faster}
Badih Ghazi, Pritish Kamath, Ravi Kumar, and Pasin Manurangsi.
\newblock Faster privacy accounting via evolving discretization.
\newblock In \emph{International Conference on Machine Learning}, pages 7470--7483, 2022.

\bibitem[Ganesh(2024)]{ganesh2024tight}
Arun Ganesh.
\newblock Tight group-level dp guarantees for dp-sgd with sampling via mixture of gaussians mechanisms.
\newblock \emph{arXiv preprint arXiv:2401.10294}, 2024.

\bibitem[Vadhan(2017)]{vadhan2017complexity}
Salil Vadhan.
\newblock The complexity of differential privacy.
\newblock \emph{Tutorials on the Foundations of Cryptography}, pages 347--450, 2017.

\bibitem[Choquette-Choo et~al.(2024)Choquette-Choo, Ganesh, Steinke, and Thakurta]{Choquette2024}
Christopher~A. Choquette-Choo, Arun Ganesh, Thomas Steinke, and Abhradeep~Guha Thakurta.
\newblock Privacy amplification for matrix mechanisms.
\newblock In \emph{International Conference on Learning Representations}, 2024.

\bibitem[Barthe and Olmedo(2013)]{barthe2013beyond}
Gilles Barthe and Federico Olmedo.
\newblock Beyond differential privacy: Composition theorems and relational logic for f-divergences between probabilistic programs.
\newblock In Fedor~V. Fomin, R{\={u}}si{\c{n}}{\v{s}} Freivalds, Marta Kwiatkowska, and David Peleg, editors, \emph{Automata, Languages, and Programming}, pages 49--60, 2013.

\bibitem[Dwork and Rothblum(2016)]{dwork2016concentrated}
Cynthia Dwork and Guy~N Rothblum.
\newblock Concentrated differential privacy.
\newblock \emph{arXiv preprint arXiv:1603.01887}, 2016.

\bibitem[Bun and Steinke(2016)]{bun2016concentrated}
Mark Bun and Thomas Steinke.
\newblock Concentrated differential privacy: Simplifications, extensions, and lower bounds.
\newblock In \emph{Theory of Cryptography Conference}, pages 635--658, 2016.

\bibitem[Wang et~al.(2019)Wang, Balle, and Kasiviswanathan]{wang2019uniform}
Yu-Xiang Wang, Borja Balle, and Shiva~Prasad Kasiviswanathan.
\newblock Subsampled r{\'e}nyi differential privacy and analytical moments accountant.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence and Statistics}, pages 1226--1235, 2019.

\bibitem[Mironov et~al.(2019)Mironov, Talwar, and Zhang]{mironov2019poisson}
Ilya Mironov, Kunal Talwar, and Li~Zhang.
\newblock R{\'e}nyi differential privacy of the sampled gaussian mechanism.
\newblock \emph{arXiv preprint arXiv:1908.10530}, 2019.

\bibitem[Zhu and Wang(2019)]{zhu2019poisson}
Yuqing Zhu and Yu-Xiang Wang.
\newblock Poisson subsampled r{\'e}nyi differential privacy.
\newblock In \emph{International Conference on Machine Learning}, pages 7634--7642, 2019.

\bibitem[Balle et~al.(2020{\natexlab{a}})Balle, Barthe, Gaboardi, Hsu, and Sato]{balle2020hypothesis}
Borja Balle, Gilles Barthe, Marco Gaboardi, Justin Hsu, and Tetsuya Sato.
\newblock Hypothesis testing interpretations and renyi differential privacy.
\newblock In \emph{Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics}, volume 108, pages 2496--2506, 2020{\natexlab{a}}.

\bibitem[Asoodeh et~al.(2020)Asoodeh, Liao, Calmon, Kosut, and Sankar]{asoodeh2020better}
Shahab Asoodeh, Jiachun Liao, Flavio~P Calmon, Oliver Kosut, and Lalitha Sankar.
\newblock A better bound gives a hundred rounds: Enhanced privacy guarantees via f-divergences.
\newblock In \emph{IEEE International Symposium on Information Theory (ISIT)}, 2020.

\bibitem[Sommer et~al.(2019)Sommer, Meiser, and Mohammadi]{sommer2018privacy}
David~M. Sommer, Sebastian Meiser, and Esfandiar Mohammadi.
\newblock Privacy loss classes: The central limit theorem in differential privacy.
\newblock \emph{Proceedings on Privacy Enhancing Technologies}, 2019\penalty0 (2):\penalty0 245--269, 2019.

\bibitem[Bu et~al.(2020)Bu, Dong, Long, and Su]{bu2020deep}
Zhiqi Bu, Jinshuo Dong, Qi~Long, and Weijie~J Su.
\newblock Deep learning with gaussian differential privacy.
\newblock \emph{Harvard data science review}, 2020\penalty0 (23):\penalty0 10--1162, 2020.

\bibitem[Wang et~al.(2022)Wang, Gao, Zhang, Shen, and Su]{wang2022analytical}
Hua Wang, Sheng Gao, Huanyu Zhang, Milan Shen, and Weijie~J Su.
\newblock Analytical composition of differential privacy via the edgeworth accountant.
\newblock \emph{arXiv preprint arXiv:2206.04236}, 2022.

\bibitem[Song et~al.(2013)Song, Chaudhuri, and Sarwate]{song2013stochastic}
Shuang Song, Kamalika Chaudhuri, and Anand~D Sarwate.
\newblock Stochastic gradient descent with differentially private updates.
\newblock In \emph{IEEE global conference on signal and information processing}, pages 245--248, 2013.

\bibitem[Balle et~al.(2020{\natexlab{b}})Balle, Barthe, and Gaboardi]{balle2020privacy}
Borja Balle, Gilles Barthe, and Marco Gaboardi.
\newblock Privacy profiles and amplification by subsampling.
\newblock \emph{Journal of Privacy and Confidentiality}, 10\penalty0 (1), 2020{\natexlab{b}}.

\bibitem[Ye and Shokri(2022)]{Ye2022Iteration}
Jiayuan Ye and Reza Shokri.
\newblock Differentially private learning needs hidden state (or much faster convergence).
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 703--715, 2022.

\bibitem[Villani(2009)]{Villani2009}
C{\'e}dric Villani.
\newblock \emph{Couplings and changes of variables}, pages 5--20.
\newblock 2009.
\newblock ISBN 978-3-540-71050-9.

\bibitem[Daigavane et~al.(2022)Daigavane, Madan, Sinha, Thakurta, Aggarwal, and Jain]{daigavane2022nodelevel}
Ameya Daigavane, Gagan Madan, Aditya Sinha, Abhradeep~Guha Thakurta, Gaurav Aggarwal, and Prateek Jain.
\newblock Node-level differentially private graph neural networks.
\newblock In \emph{ICLR 2022 Workshop on PAIR{\textasciicircum}2Struct: Privacy, Accountability, Interpretability, Robustness, Reasoning on Structured Data}, 2022.

\bibitem[Ayle et~al.(2022)Ayle, Schuchardt, Gosch, Z{\"u}gner, and G{\"u}nnemann]{ayle2022training}
Morgane Ayle, Jan Schuchardt, Lukas Gosch, Daniel Z{\"u}gner, and Stephan G{\"u}nnemann.
\newblock Training differentially private graph neural networks with random walk sampling.
\newblock In \emph{Workshop on Trustworthy and Socially Responsible Machine Learning, NeurIPS}, 2022.

\bibitem[Xiang et~al.(2024)Xiang, Wang, and Wang]{zihang2024preserving}
Zihang Xiang, Tianhao Wang, and Di~Wang.
\newblock {Preserving Node-level Privacy in Graph Neural Networks}.
\newblock In \emph{IEEE Symposium on Security and Privacy (SP)}, pages 4714--4732, 2024.

\bibitem[Bun et~al.(2015)Bun, Nissim, Stemmer, and Vadhan]{bun2015differentially}
Mark Bun, Kobbi Nissim, Uri Stemmer, and Salil Vadhan.
\newblock Differentially private release and learning of threshold functions.
\newblock In \emph{2015 IEEE 56th Annual Symposium on Foundations of Computer Science}, pages 634--649, 2015.

\bibitem[Ullman(2017)]{ullman2017}
Jonathan Ullman.
\newblock Cs7880: Rigorous approaches to data privacy.
\newblock \url{https://www.khoury.northeastern.edu/home/jullman/cs7880s17/HW1sol.pdf}, 2017.
\newblock Accessed May 21, 2024.

\bibitem[Team(2024)]{dpaccountinglibrary}
Google Differential~Privacy Team.
\newblock Privacy loss distributions.
\newblock \url{https://raw.githubusercontent.com/google/differential-privacy/main/common_docs/Privacy_Loss_Distributions.pdf}, 2024.
\newblock Accessed May 22, 2024.

\bibitem[Bassily et~al.(2014)Bassily, Smith, and Thakurta]{bassily2014private}
Raef Bassily, Adam Smith, and Abhradeep Thakurta.
\newblock Private empirical risk minimization: Efficient algorithms and tight error bounds.
\newblock In \emph{IEEE 55th annual symposium on foundations of computer science}, pages 464--473, 2014.

\bibitem[Wang et~al.(2015)Wang, Fienberg, and Smola]{wang2015privacy}
Yu-Xiang Wang, Stephen Fienberg, and Alex Smola.
\newblock Privacy for free: Posterior sampling and stochastic gradient monte carlo.
\newblock In \emph{International Conference on Machine Learning}, pages 2493--2502, 2015.

\bibitem[Steinke(2022)]{steinke2022subsampling}
Thomas Steinke.
\newblock Composition of differential privacy \& privacy amplification by subsampling.
\newblock \emph{arXiv preprint arXiv:2210.00597}, 2022.

\bibitem[L{\'{e}}cuyer et~al.(2019)L{\'{e}}cuyer, Atlidakis, Geambasu, Hsu, and Jana]{lecuyer2019differential}
Mathias L{\'{e}}cuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, and Suman Jana.
\newblock Certified robustness to adversarial examples with differential privacy.
\newblock In \emph{{IEEE} Symposium on Security and Privacy}, pages 656--672, 2019.

\bibitem[Li et~al.(2019)Li, Chen, Wang, and Carin]{li2019certified}
Bai Li, Changyou Chen, Wenlin Wang, and Lawrence Carin.
\newblock Certified adversarial robustness with additive noise.
\newblock \emph{Advances in neural information processing systems}, 2019.

\bibitem[Cohen et~al.(2019)Cohen, Rosenfeld, and Kolter]{cohen2019certified}
Jeremy Cohen, Elan Rosenfeld, and Zico Kolter.
\newblock Certified adversarial robustness via randomized smoothing.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Levine and Feizi(2020)]{levine2020ablation}
Alexander Levine and Soheil Feizi.
\newblock Robustness certificates for sparse adversarial attacks by randomized ablation.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~34, pages 4585--4593, 2020.

\bibitem[Bojchevski et~al.(2020)Bojchevski, Klicpera, and G{\"u}nnemann]{bojchevski2020efficient}
Aleksandar Bojchevski, Johannes Klicpera, and Stephan G{\"u}nnemann.
\newblock Efficient robustness certificates for discrete data: Sparsity-aware randomized smoothing for graphs, images and more.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Fischer et~al.(2020)Fischer, Baader, and Vechev]{fischer2020certified}
Marc Fischer, Maximilian Baader, and Martin Vechev.
\newblock Certified defense to image transformations via randomized smoothing.
\newblock \emph{Advances in Neural information processing systems}, 2020.

\bibitem[Wu et~al.(2021)Wu, Bojchevski, Kuvshinov, and G{\"u}nnemann]{wu2021completing}
Yihan Wu, Aleksandar Bojchevski, Aleksei Kuvshinov, and Stephan G{\"u}nnemann.
\newblock Completing the picture: Randomized smoothing suffers from curse of dimensionality for a large family of distributions.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, 2021.

\bibitem[Kumar and Goldstein(2021)]{kumar2021center}
Aounon Kumar and Tom Goldstein.
\newblock Center smoothing: Certified robustness for networks with structured outputs.
\newblock \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Schuchardt and G{\"u}nnemann(2022)]{schuchardt2022invariance}
Jan Schuchardt and Stephan G{\"u}nnemann.
\newblock Invariance-aware randomized smoothing certificates.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Alfarra et~al.(2022)Alfarra, Bibi, Khan, Torr, and Ghanem]{alfarra2022deform}
Motasem Alfarra, Adel Bibi, Naeemullah Khan, Philip~HS Torr, and Bernard Ghanem.
\newblock {DeformRS}: Certifying input deformations with randomized smoothing.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, number~6, pages 6001--6009, 2022.

\bibitem[Scholten et~al.(2022)Scholten, Schuchardt, Geisler, Bojchevski, and G{\"u}nnemann]{scholten2022randomized}
Yan Scholten, Jan Schuchardt, Simon Geisler, Aleksandar Bojchevski, and Stephan G{\"u}nnemann.
\newblock Randomized message-interception smoothing: Gray-box certificates for graph neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Murarev and Petiushko(2022)]{muarev2022certified}
Nikita Murarev and Aleksandr Petiushko.
\newblock Certified robustness via randomized smoothing over multiplicative parameters of input transformations.
\newblock In \emph{International Joint Conference on Artificial Intelligence}, 2022.

\bibitem[S{\'u}keník et~al.(2022)S{\'u}keník, Kuvshinov, and G{\"u}nnemann]{sukenik2022intriguing}
Peter S{\'u}keník, Aleksei Kuvshinov, and Stephan G{\"u}nnemann.
\newblock Intriguing properties of input-dependent randomized smoothing.
\newblock In \emph{International conference on machine learning}, 2022.

\bibitem[Pautov et~al.(2022)Pautov, Kuznetsova, Tursynbek, Petiushko, and Oseledets]{pautov2022smoothed}
Mikhail Pautov, Olesya Kuznetsova, Nurislam Tursynbek, Aleksandr Petiushko, and Ivan Oseledets.
\newblock Smoothed embeddings for certified few-shot learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Schuchardt et~al.(2023{\natexlab{a}})Schuchardt, Wollschl{\"a}ger, Bojchevski, and G{\"u}nnemann]{schuchardt2023localized}
Jan Schuchardt, Tom Wollschl{\"a}ger, Aleksandar Bojchevski, and Stephan G{\"u}nnemann.
\newblock Localized randomized smoothing for collective robustness certification.
\newblock In \emph{International Conference on Learning Representations}, 2023{\natexlab{a}}.

\bibitem[Rumezhak et~al.(2023)Rumezhak, Eiras, Torr, and Bibi]{rumezhak2023rancer}
Taras Rumezhak, Francisco~Girbal Eiras, Philip~HS Torr, and Adel Bibi.
\newblock Rancer: Non-axis aligned anisotropic certification with randomized smoothing.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, pages 4672--4680, 2023.

\bibitem[Saxena et~al.(2023)Saxena, Wollschl{\"a}ger, Franco, Lorenz, and G{\"u}nnemann]{wollschlaeger2023randomized}
Aman Saxena, Tom Wollschl{\"a}ger, Nicola Franco, Jeanette~Miriam Lorenz, and Stephan G{\"u}nnemann.
\newblock Randomized smoothing-inspired quantum encoding schemes with formal robustness guarantees.
\newblock In \emph{Quantum Techniques in Machine Learning}, 2023.

\bibitem[Pfrommer et~al.(2023)Pfrommer, Anderson, and Sojoudi]{pfrommer2023projected}
Samuel Pfrommer, Brendon~G. Anderson, and Somayeh Sojoudi.
\newblock Projected randomized smoothing for certified adversarial robustness.
\newblock \emph{Transactions on Machine Learning Research}, 2023.
\newblock ISSN 2835-8856.

\bibitem[Schuchardt et~al.(2023{\natexlab{b}})Schuchardt, Scholten, and G{\"u}nnemann]{schuchardt2023provable}
Jan Schuchardt, Yan Scholten, and Stephan G{\"u}nnemann.
\newblock Provable adversarial robustness for group equivariant tasks: Graphs, point clouds, molecules, and more.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2023{\natexlab{b}}.

\bibitem[Huang et~al.(2023)Huang, Marchant, Lucas, Bauer, Ohrimenko, and Rubinstein]{huang2023rsdel}
Zhuoqun Huang, Neil Marchant, Keane Lucas, Lujo Bauer, Olya Ohrimenko, and Benjamin I.~P. Rubinstein.
\newblock {RS-Del}: Edit distance robustness certificates for sequence classifiers via randomized deletion.
\newblock In \emph{Advances in Neural Information Processing Systems}, NeurIPS, 2023.

\bibitem[Scholten et~al.(2023)Scholten, Schuchardt, Bojchevski, and G\"unnemann]{scholten2023hierarchical}
Yan Scholten, Jan Schuchardt, Aleksandar Bojchevski, and Stephan G\"unnemann.
\newblock Hierarchical randomized smoothing.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2023.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, Su, Ye, Shokri, and Su]{wang2023unified}
Chendi Wang, Buxin Su, Jiayuan Ye, Reza Shokri, and Weijie~J Su.
\newblock Unified enhancement of privacy bounds for mixture mechanisms via \$f\$-differential privacy.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023{\natexlab{b}}.

\bibitem[Altschuler and Talwar(2022)]{Altschuler2022Iteration}
Jason Altschuler and Kunal Talwar.
\newblock Privacy of noisy stochastic gradient descent: More iterations without more privacy loss.
\newblock \emph{Advances in Neural Information Processing Systems}, 35, 2022.

\bibitem[Girgis et~al.(2021)Girgis, Data, and Diggavi]{Girgis2021ShuffledSubsampled}
Antonious Girgis, Deepesh Data, and Suhas Diggavi.
\newblock R{\'e}nyi differential privacy of the subsampled shuffle model in distributed learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, volume~34, pages 29181--29192, 2021.

\bibitem[Yousefpour et~al.(2021)Yousefpour, Shilov, Sablayrolles, Testuggine, Prasad, Malek, Nguyen, Ghosh, Bharadwaj, Zhao, Cormode, and Mironov]{opacus}
Ashkan Yousefpour, Igor Shilov, Alexandre Sablayrolles, Davide Testuggine, Karthik Prasad, Mani Malek, John Nguyen, Sayan Ghosh, Akash Bharadwaj, Jessica Zhao, Graham Cormode, and Ilya Mironov.
\newblock Opacus: {U}ser-friendly differential privacy library in {PyTorch}.
\newblock \emph{arXiv preprint arXiv:2109.12298}, 2021.

\bibitem[Balle and Wang(2018)]{balle2018improving}
Borja Balle and Yu-Xiang Wang.
\newblock Improving the gaussian mechanism for differential privacy: Analytical calibration and optimal denoising.
\newblock In \emph{International Conference on Machine Learning}, pages 394--403, 2018.

\bibitem[Erlingsson et~al.(2019)Erlingsson, Feldman, Mironov, Raghunathan, Talwar, and Thakurta]{erlingsson2019shuffling}
{\'U}lfar Erlingsson, Vitaly Feldman, Ilya Mironov, Ananth Raghunathan, Kunal Talwar, and Abhradeep Thakurta.
\newblock Amplification by shuffling: From local to central differential privacy via anonymity.
\newblock In \emph{Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms}, pages 2468--2479, 2019.

\bibitem[Cheu et~al.(2019)Cheu, Smith, Ullman, Zeber, and Zhilyaev]{cheu2019distributed}
Albert Cheu, Adam Smith, Jonathan Ullman, David Zeber, and Maxim Zhilyaev.
\newblock Distributed differential privacy via shuffling.
\newblock In \emph{Advances in Cryptology--EUROCRYPT}, pages 375--403, 2019.

\end{thebibliography}
