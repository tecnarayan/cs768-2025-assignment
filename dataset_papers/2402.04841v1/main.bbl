\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Achiam et~al.(2023)Achiam, Adler, Agarwal, Ahmad, Akkaya, Aleman,
  Almeida, Altenschmidt, Altman, Anadkat, et~al.]{gpt4}
Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F.~L.,
  Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., et~al.
\newblock Gpt-4 technical report.
\newblock \emph{arXiv preprint arXiv:2303.08774}, 2023.

\bibitem[Andriluka et~al.(2014)Andriluka, Pishchulin, Gehler, and
  Schiele]{mpii}
Andriluka, M., Pishchulin, L., Gehler, P., and Schiele, B.
\newblock 2d human pose estimation: New benchmark and state of the art
  analysis.
\newblock In \emph{Proceedings of the IEEE Conference on computer Vision and
  Pattern Recognition}, pp.\  3686--3693, 2014.

\bibitem[Bai et~al.(2023)Bai, Geng, Mangalam, Bar, Yuille, Darrell, Malik, and
  Efros]{lvm}
Bai, Y., Geng, X., Mangalam, K., Bar, A., Yuille, A., Darrell, T., Malik, J.,
  and Efros, A.~A.
\newblock Sequential modeling enables scalable learning for large vision
  models.
\newblock \emph{arXiv preprint arXiv:2312.00785}, 2023.

\bibitem[Bao et~al.(2021)Bao, Dong, Piao, and Wei]{beit}
Bao, H., Dong, L., Piao, S., and Wei, F.
\newblock Beit: Bert pre-training of image transformers.
\newblock \emph{arXiv preprint arXiv:2106.08254}, 2021.

\bibitem[Bar et~al.(2022)Bar, Gandelsman, Darrell, Globerson, and Efros]{vp}
Bar, A., Gandelsman, Y., Darrell, T., Globerson, A., and Efros, A.
\newblock Visual prompting via image inpainting.
\newblock \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{gpt3}
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J.~D., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems}, 2020.

\bibitem[Chang et~al.(2023)Chang, Zhang, Barber, Maschinot, Lezama, Jiang,
  Yang, Murphy, Freeman, Rubinstein, et~al.]{muse}
Chang, H., Zhang, H., Barber, J., Maschinot, A., Lezama, J., Jiang, L., Yang,
  M.-H., Murphy, K., Freeman, W.~T., Rubinstein, M., et~al.
\newblock Muse: Text-to-image generation via masked generative transformers.
\newblock \emph{arXiv preprint arXiv:2301.00704}, 2023.

\bibitem[Chen et~al.(2020)Chen, Radford, Child, Wu, Jun, Luan, and
  Sutskever]{igpt}
Chen, M., Radford, A., Child, R., Wu, J., Jun, H., Luan, D., and Sutskever, I.
\newblock Generative pretraining from pixels.
\newblock In \emph{International conference on machine learning}, 2020.

\bibitem[Chen et~al.(2021)Chen, Saxena, Li, Fleet, and Hinton]{pix2seq}
Chen, T., Saxena, S., Li, L., Fleet, D.~J., and Hinton, G.
\newblock Pix2seq: A language modeling framework for object detection.
\newblock \emph{arXiv preprint arXiv:2109.10852}, 2021.

\bibitem[Chowdhery et~al.(2023)Chowdhery, Narang, Devlin, Bosma, Mishra,
  Roberts, Barham, Chung, Sutton, Gehrmann, et~al.]{palm}
Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A.,
  Barham, P., Chung, H.~W., Sutton, C., Gehrmann, S., et~al.
\newblock Palm: Scaling language modeling with pathways.
\newblock \emph{Journal of Machine Learning Research}, 2023.

\bibitem[Dai \& Le(2015)Dai and Le]{dai2015semi}
Dai, A.~M. and Le, Q.~V.
\newblock Semi-supervised sequence learning.
\newblock \emph{Advances in neural information processing systems}, 2015.

\bibitem[Doersch \& Zisserman(2017)Doersch and Zisserman]{doersch2017multi}
Doersch, C. and Zisserman, A.
\newblock Multi-task self-supervised visual learning.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, 2017.

\bibitem[El-Nouby et~al.(2024)El-Nouby, Klein, Zhai, Bautista, Toshev, Shankar,
  Susskind, and Joulin]{el2024scalable}
El-Nouby, A., Klein, M., Zhai, S., Bautista, M.~A., Toshev, A., Shankar, V.,
  Susskind, J.~M., and Joulin, A.
\newblock Scalable pre-training of large autoregressive image models.
\newblock \emph{arXiv preprint arXiv:2401.08541}, 2024.

\bibitem[Esser et~al.(2021)Esser, Rombach, and Ommer]{vqgan}
Esser, P., Rombach, R., and Ommer, B.
\newblock Taming transformers for high-resolution image synthesis.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, 2021.

\bibitem[Fu et~al.(2017)Fu, Huang, Zeng, Huang, Ding, and Paisley]{test2800}
Fu, X., Huang, J., Zeng, D., Huang, Y., Ding, X., and Paisley, J.
\newblock Removing rain from single images via a deep detail network.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  3855--3863, 2017.

\bibitem[He et~al.(2022)He, Chen, Xie, Li, Doll{\'a}r, and Girshick]{mae}
He, K., Chen, X., Xie, S., Li, Y., Doll{\'a}r, P., and Girshick, R.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, 2022.

\bibitem[Hinton et~al.(2015)Hinton, Vinyals, and Dean]{kd}
Hinton, G.~E., Vinyals, O., and Dean, J.
\newblock Distilling the knowledge in a neural network.
\newblock \emph{arXiv preprint arXiv: 1503.02531}, 2015.

\bibitem[Huang et~al.(2022)Huang, You, Wang, Qian, and Xu]{dist}
Huang, T., You, S., Wang, F., Qian, C., and Xu, C.
\newblock Knowledge distillation from a stronger teacher.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Jiang et~al.(2020)Jiang, Wang, Yi, Chen, Huang, Luo, Ma, and
  Jiang]{rain13k}
Jiang, K., Wang, Z., Yi, P., Chen, C., Huang, B., Luo, Y., Ma, J., and Jiang,
  J.
\newblock Multi-scale progressive fusion network for single image deraining.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  8346--8355, 2020.

\bibitem[Kang et~al.(2019)Kang, Xie, Rohrbach, Yan, Gordo, Feng, and
  Kalantidis]{kang2019decoupling}
Kang, B., Xie, S., Rohrbach, M., Yan, Z., Gordo, A., Feng, J., and Kalantidis,
  Y.
\newblock Decoupling representation and classifier for long-tailed recognition.
\newblock \emph{arXiv preprint arXiv:1910.09217}, 2019.

\bibitem[Kirillov et~al.(2023)Kirillov, Mintun, Ravi, Mao, Rolland, Gustafson,
  Xiao, Whitehead, Berg, Lo, et~al.]{sam}
Kirillov, A., Mintun, E., Ravi, N., Mao, H., Rolland, C., Gustafson, L., Xiao,
  T., Whitehead, S., Berg, A.~C., Lo, W.-Y., et~al.
\newblock Segment anything.
\newblock \emph{arXiv preprint arXiv:2304.02643}, 2023.

\bibitem[Kolesnikov et~al.(2019)Kolesnikov, Zhai, and
  Beyer]{kolesnikov2019revisiting}
Kolesnikov, A., Zhai, X., and Beyer, L.
\newblock Revisiting self-supervised visual representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, 2019.

\bibitem[Kolesnikov et~al.(2022)Kolesnikov, Susano~Pinto, Beyer, Zhai, Harmsen,
  and Houlsby]{uvim}
Kolesnikov, A., Susano~Pinto, A., Beyer, L., Zhai, X., Harmsen, J., and
  Houlsby, N.
\newblock Uvim: A unified modeling approach for vision with learned guiding
  codes.
\newblock \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Komodakis \& Zagoruyko(2017)Komodakis and
  Zagoruyko]{komodakis2017paying}
Komodakis, N. and Zagoruyko, S.
\newblock Paying more attention to attention: improving the performance of
  convolutional neural networks via attention transfer.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan,
  Doll{\'a}r, and Zitnick]{coco}
Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D.,
  Doll{\'a}r, P., and Zitnick, C.~L.
\newblock Microsoft coco: Common objects in context.
\newblock In \emph{Computer Vision--ECCV 2014: 13th European Conference,
  Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13}, 2014.

\bibitem[Lu et~al.(2022)Lu, Clark, Zellers, Mottaghi, and
  Kembhavi]{lu2022unified}
Lu, J., Clark, C., Zellers, R., Mottaghi, R., and Kembhavi, A.
\newblock Unified-io: A unified model for vision, language, and multi-modal
  tasks.
\newblock \emph{arXiv preprint arXiv:2206.08916}, 2022.

\bibitem[Park et~al.(2019)Park, Kim, Lu, and Cho]{rkd}
Park, W., Kim, D., Lu, Y., and Cho, M.
\newblock Relational knowledge distillation.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, 2019.

\bibitem[Parmar et~al.(2018)Parmar, Vaswani, Uszkoreit, Kaiser, Shazeer, Ku,
  and Tran]{parmar2018image}
Parmar, N., Vaswani, A., Uszkoreit, J., Kaiser, L., Shazeer, N., Ku, A., and
  Tran, D.
\newblock Image transformer.
\newblock In \emph{International conference on machine learning}, 2018.

\bibitem[Pathak et~al.(2016)Pathak, Krahenbuhl, Donahue, Darrell, and
  Efros]{pathak2016context}
Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., and Efros, A.~A.
\newblock Context encoders: Feature learning by inpainting.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, 2016.

\bibitem[Peng et~al.(2019)Peng, Jin, Liu, Li, Wu, Liu, Zhou, and Zhang]{cc}
Peng, B., Jin, X., Liu, J., Li, D., Wu, Y., Liu, Y., Zhou, S., and Zhang, Z.
\newblock Correlation congruence for knowledge distillation.
\newblock In \emph{International Conference on Computer Vision}, 2019.

\bibitem[Romero et~al.(2014)Romero, Ballas, Kahou, Chassang, Gatta, and
  Bengio]{fitnet}
Romero, A., Ballas, N., Kahou, S.~E., Chassang, A., Gatta, C., and Bengio, Y.
\newblock Fitnets: Hints for thin deep nets.
\newblock \emph{arXiv preprint arXiv:1412.6550}, 2014.

\bibitem[Schuhmann et~al.(2022)Schuhmann, Beaumont, Vencu, Gordon, Wightman,
  Cherti, Coombes, Katta, Mullis, Wortsman, et~al.]{laion}
Schuhmann, C., Beaumont, R., Vencu, R., Gordon, C., Wightman, R., Cherti, M.,
  Coombes, T., Katta, A., Mullis, C., Wortsman, M., et~al.
\newblock Laion-5b: An open large-scale dataset for training next generation
  image-text models.
\newblock \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Sener \& Koltun(2018)Sener and Koltun]{sener2018multi}
Sener, O. and Koltun, V.
\newblock Multi-task learning as multi-objective optimization.
\newblock \emph{Advances in neural information processing systems}, 2018.

\bibitem[Shaban et~al.(2017)Shaban, Bansal, Liu, Essa, and Boots]{pascal5i}
Shaban, A., Bansal, S., Liu, Z., Essa, I., and Boots, B.
\newblock One-shot learning for semantic segmentation.
\newblock \emph{arXiv preprint arXiv:1709.03410}, 2017.

\bibitem[Team(2023)]{internlm}
Team, I.
\newblock Internlm: A multilingual language model with progressively enhanced
  capabilities, 2023.

\bibitem[Tian et~al.(2020)Tian, Krishnan, and Isola]{crd}
Tian, Y., Krishnan, D., and Isola, P.
\newblock Contrastive representation distillation.
\newblock In \emph{IEEE/CVF International Conference on Learning
  Representations}, 2020.

\bibitem[Touvron et~al.(2023{\natexlab{a}})Touvron, Lavril, Izacard, Martinet,
  Lachaux, Lacroix, Rozi{\`e}re, Goyal, Hambro, Azhar, et~al.]{llama}
Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix,
  T., Rozi{\`e}re, B., Goyal, N., Hambro, E., Azhar, F., et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock \emph{arXiv preprint arXiv:2302.13971}, 2023{\natexlab{a}}.

\bibitem[Touvron et~al.(2023{\natexlab{b}})Touvron, Martin, Stone, Albert,
  Almahairi, Babaei, Bashlykov, Batra, Bhargava, Bhosale, et~al.]{llama2}
Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y.,
  Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock \emph{arXiv preprint arXiv:2307.09288}, 2023{\natexlab{b}}.

\bibitem[Uria et~al.(2013)Uria, Murray, and Larochelle]{uria2013rnade}
Uria, B., Murray, I., and Larochelle, H.
\newblock Rnade: The real-valued neural autoregressive density-estimator.
\newblock \emph{Advances in Neural Information Processing Systems}, 2013.

\bibitem[Van Den~Oord et~al.(2016)Van Den~Oord, Kalchbrenner, and
  Kavukcuoglu]{van2016pixel}
Van Den~Oord, A., Kalchbrenner, N., and Kavukcuoglu, K.
\newblock Pixel recurrent neural networks.
\newblock In \emph{International conference on machine learning}, 2016.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{transformer}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 2017.

\bibitem[Wang et~al.(2022)Wang, Yang, Men, Lin, Bai, Li, Ma, Zhou, Zhou, and
  Yang]{wang2022ofa}
Wang, P., Yang, A., Men, R., Lin, J., Bai, S., Li, Z., Ma, J., Zhou, C., Zhou,
  J., and Yang, H.
\newblock Ofa: Unifying architectures, tasks, and modalities through a simple
  sequence-to-sequence learning framework.
\newblock In \emph{International Conference on Machine Learning}, 2022.

\bibitem[Wang et~al.(2023)Wang, Wang, Cao, Shen, and Huang]{painter}
Wang, X., Wang, W., Cao, Y., Shen, C., and Huang, T.
\newblock Images speak in images: A generalist painter for in-context visual
  learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2023.

\bibitem[Yu et~al.(2021)Yu, Zhan, Wu, Pan, Cui, Lu, Ma, Xie, and
  Miao]{yu2021diverse}
Yu, Y., Zhan, F., Wu, R., Pan, J., Cui, K., Lu, S., Ma, F., Xie, X., and Miao,
  C.
\newblock Diverse image inpainting with bidirectional and autoregressive
  transformers.
\newblock In \emph{Proceedings of the 29th ACM International Conference on
  Multimedia}, 2021.

\bibitem[Zhang et~al.(2020)Zhang, Shi, Shi, Ma, and Bao]{tofd}
Zhang, L., Shi, Y., Shi, Z., Ma, K., and Bao, C.
\newblock Task-oriented feature distillation.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Zhang et~al.(2023)Zhang, Kang, Hooi, Yan, and Feng]{longtail}
Zhang, Y., Kang, B., Hooi, B., Yan, S., and Feng, J.
\newblock Deep long-tailed learning: A survey.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2023.

\bibitem[Zhao et~al.(2022)Zhao, Cui, Song, Qiu, and Liang]{dkd}
Zhao, B., Cui, Q., Song, R., Qiu, Y., and Liang, J.
\newblock Decoupled knowledge distillation.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, 2022.

\end{thebibliography}
