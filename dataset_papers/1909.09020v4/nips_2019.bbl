\begin{thebibliography}{10}

\bibitem{abid2018learning}
Abubakar Abid and James Zou.
\newblock Learning a warping distance from unlabeled time series using sequence
  autoencoders.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  pages 10547--10555, 2018.

\bibitem{an2015comparison}
Nguyen~Hoang An and Duong~Tuan Anh.
\newblock Comparison of strategies for multi-step-ahead prediction of time
  series using neural network.
\newblock In {\em International Conference on Advanced Computing and
  Applications (ACOMP)}, pages 142--149. IEEE, 2015.

\bibitem{bao2014multi}
Yukun Bao, Tao Xiong, and Zhongyi Hu.
\newblock Multi-step-ahead time series prediction using multiple-output support
  vector regression.
\newblock {\em Neurocomputing}, 129:482--493, 2014.

\bibitem{bellman1952theory}
Richard Bellman.
\newblock On the theory of dynamic programming.
\newblock {\em Proceedings of the National Academy of Sciences of the United
  States of America}, 38(8):716, 1952.

\bibitem{borovykh2017conditional}
Anastasia Borovykh, Sander Bohte, and Cornelis~W Oosterlee.
\newblock Conditional time series forecasting with convolutional neural
  networks.
\newblock {\em arXiv preprint arXiv:1703.04691}, 2017.

\bibitem{box2015time}
George~EP Box, Gwilym~M Jenkins, Gregory~C Reinsel, and Greta~M Ljung.
\newblock {\em Time series analysis: forecasting and control}.
\newblock John Wiley \& Sons, 2015.

\bibitem{chandra2017co}
Rohitash Chandra, Yew-Soon Ong, and Chi-Keong Goh.
\newblock Co-evolutionary multi-task learning with predictive recurrence for
  multi-step chaotic time series prediction.
\newblock {\em Neurocomputing}, 243:21--34, 2017.

\bibitem{chang2019kernel}
Wei-Cheng Chang, Chun-Liang Li, Yiming Yang, and Barnab{\'a}s P{\'o}czos.
\newblock Kernel change-point detection with auxiliary deep generative models.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2019.

\bibitem{chauhan2015anomaly}
Sucheta Chauhan and Lovekesh Vig.
\newblock Anomaly detection in \textsc{ECG} time signals via deep long
  short-term memory networks.
\newblock In {\em International Conference on Data Science and Advanced
  Analytics (DSAA)}, pages 1--7. IEEE, 2015.

\bibitem{chen2015ucr}
Yanping Chen, Eamonn Keogh, Bing Hu, Nurjahan Begum, Anthony Bagnall, Abdullah
  Mueen, and Gustavo Batista.
\newblock The \textsc{UCR} time series classification archive.
\newblock 2015.

\bibitem{cho2014learning}
Kyunghyun Cho, Bart Van~Merri{\"e}nboer, Caglar Gulcehre, Dzmitry Bahdanau,
  Fethi Bougares, Holger Schwenk, and Yoshua Bengio.
\newblock Learning phrase representations using \textsc{RNN} encoder-decoder
  for statistical machine translation.
\newblock {\em arXiv preprint arXiv:1406.1078}, 2014.

\bibitem{choi2016retain}
Edward Choi, Mohammad~Taha Bahadori, Jimeng Sun, Joshua Kulas, Andy Schuetz,
  and Walter Stewart.
\newblock \textsc{Retain}: An interpretable predictive model for healthcare
  using reverse time attention mechanism.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS)},
  pages 3504--3512, 2016.

\bibitem{cuturi2017soft}
Marco Cuturi and Mathieu Blondel.
\newblock Soft-dtw: a differentiable loss function for time-series.
\newblock In {\em International Conference on Machine Learning (ICML)}, pages
  894--903, 2017.

\bibitem{ding2015deep}
Xiao Ding, Yue Zhang, Ting Liu, and Junwen Duan.
\newblock Deep learning for event-driven stock prediction.
\newblock In {\em International Joint Conference on Artificial Intelligence
  (IJCAI)}, 2015.

\bibitem{durand2015mantra}
Thibaut Durand, Nicolas Thome, and Matthieu Cord.
\newblock Mantra: Minimum maximum latent structural svm for image
  classification and ranking.
\newblock In {\em IEEE International Conference on Computer Vision (ICCV)},
  pages 2713--2721, 2015.

\bibitem{durand2018exploiting}
Thibaut Durand, Nicolas Thome, and Matthieu Cord.
\newblock Exploiting negative evidence for deep latent structured models.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  41(2):337--351, 2018.

\bibitem{durbin2012time}
James Durbin and Siem~Jan Koopman.
\newblock {\em Time series analysis by state space methods}.
\newblock Oxford university press, 2012.

\bibitem{florita2013identifying}
Anthony Florita, Bri-Mathias Hodge, and Kirsten Orwig.
\newblock Identifying wind and solar ramping events.
\newblock In {\em 2013 IEEE Green Technologies Conference (GreenTech)}, pages
  147--152. IEEE, 2013.

\bibitem{fox2018deep}
Ian Fox, Lynn Ang, Mamta Jaiswal, Rodica Pop-Busui, and Jenna Wiens.
\newblock Deep multi-output forecasting: Learning to accurately predict blood
  glucose trajectories.
\newblock In {\em ACM SIGKDD International Conference on Knowledge Discovery \&
  Data Mining}, pages 1387--1395. ACM, 2018.

\bibitem{frias2017assessing}
Laura Fr{\'\i}as-Paredes, Ferm{\'\i}n Mallor, Mart{\'\i}n Gast{\'o}n-Romeo, and
  Teresa Le{\'o}n.
\newblock Assessing energy forecasting inaccuracy by simultaneously considering
  temporal and absolute errors.
\newblock {\em Energy Conversion and Management}, 142:533--546, 2017.

\bibitem{gal2016dropout}
Yarin Gal and Zoubin Ghahramani.
\newblock Dropout as a bayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In {\em International Conference on Machine Learning (ICML)}, pages
  1050--1059, 2016.

\bibitem{garreau2018consistent}
Damien Garreau, Sylvain Arlot, et~al.
\newblock Consistent change-point detection with kernels.
\newblock {\em Electronic Journal of Statistics}, 12(2):4440--4486, 2018.

\bibitem{ghaderi2017deep}
Amir Ghaderi, Borhan~M Sanandaji, and Faezeh Ghaderi.
\newblock Deep forecast: Deep learning-based spatio-temporal forecasting.
\newblock In {\em ICML Time Series Workshop}, 2017.

\bibitem{girard2002multiple}
Agathe Girard and Carl~Edward Rasmussen.
\newblock Multiple-step ahead prediction for non linear dynamic systems - a
  gaussian process treatment with propagation of the uncertainty.
\newblock In {\em Advances in neural information processing systems (NIPS)},
  volume~15, pages 529--536, 2002.

\bibitem{Hochreiter:1997:LSM:1246443.1246450}
Sepp Hochreiter and J\"{u}rgen Schmidhuber.
\newblock Long short-term memory.
\newblock {\em Neural Computing}, 9(8):1735--1780, November 1997.

\bibitem{hussein2016multi}
Shamina Hussein, Rohitash Chandra, and Anuraganand Sharma.
\newblock Multi-step-ahead chaotic time series prediction using coevolutionary
  recurrent neural networks.
\newblock In {\em IEEE Congress on Evolutionary Computation (CEC)}, pages
  3084--3091. IEEE, 2016.

\bibitem{hyndman2008forecasting}
Rob Hyndman, Anne~B Koehler, J~Keith Ord, and Ralph~D Snyder.
\newblock {\em Forecasting with exponential smoothing: the state space
  approach}.
\newblock Springer Science \& Business Media, 2008.

\bibitem{jeong2011weighted}
Young-Seon Jeong, Myong~K Jeong, and Olufemi~A Omitaomu.
\newblock Weighted dynamic time warping for time series classification.
\newblock {\em Pattern Recognition}, 44:2231--2240, 2011.

\bibitem{kuznetsov2018foundations}
Vitaly Kuznetsov and Zelda Mariet.
\newblock Foundations of sequence-to-sequence modeling for time series.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics (AISTATS)}, 2019.

\bibitem{lai2018modeling}
Guokun Lai, Wei-Cheng Chang, Yiming Yang, and Hanxiao Liu.
\newblock Modeling long-and short-term temporal patterns with deep neural
  networks.
\newblock In {\em ACM SIGIR Conference on Research \& Development in
  Information Retrieval}, pages 95--104. ACM, 2018.

\bibitem{laptev2017time}
Nikolay Laptev, Jason Yosinski, Li~Erran Li, and Slawek Smyl.
\newblock Time-series extreme event forecasting with neural networks at
  \textsc{U}ber.
\newblock In {\em International Conference on Machine Learning (ICML)},
  number~34, pages 1--5, 2017.

\bibitem{li2019}
Shiyang Li, Xiaoyong Jin, Yao Xuan, Xiyou Zhou, Wenhu Chen, Wang Yu-Xiang, and
  Yan Xifeng.
\newblock Enhancing the locality and breaking the memory bottleneck of
  transformer on time series forecasting.
\newblock In {\em Advances in neural information processing systems (NeurIPS)},
  2019.

\bibitem{li2015m}
Shuang Li, Yao Xie, Hanjun Dai, and Le~Song.
\newblock M-statistic for kernel change-point detection.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS)},
  pages 3366--3374, 2015.

\bibitem{li2017diffusion}
Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu.
\newblock Diffusion convolutional recurrent neural network: Data-driven traffic
  forecasting.
\newblock In {\em International Conference on Learning Representations (ICLR)},
  2018.

\bibitem{lv2015traffic}
Yisheng Lv, Yanjie Duan, Wenwen Kang, Zhengxi Li, and Fei-Yue Wang.
\newblock Traffic flow prediction with big data: a deep learning approach.
\newblock {\em IEEE Transactions on Intelligent Transportation Systems},
  16(2):865--873, 2015.

\bibitem{masum2018multi}
Shamsul Masum, Ying Liu, and John Chiverton.
\newblock Multi-step time series forecasting of electric load using machine
  learning models.
\newblock In {\em International Conference on Artificial Intelligence and Soft
  Computing}, pages 148--159. Springer, 2018.

\bibitem{mensch2018differentiable}
Arthur Mensch and Mathieu Blondel.
\newblock Differentiable dynamic programming for structured prediction and
  attention.
\newblock {\em International Conference on Machine Learning (ICML)}, 2018.

\bibitem{nowozin2014optimal}
Sebastian Nowozin.
\newblock Optimal decisions from probabilistic models: the
  intersection-over-union case.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pages 548--555, 2014.

\bibitem{qin2017dual}
Yao Qin, Dongjin Song, Haifeng Cheng, Wei Cheng, Guofei Jiang, and Garrison~W
  Cottrell.
\newblock A dual-stage attention-based recurrent neural network for time series
  prediction.
\newblock In {\em International Joint Conference on Artificial Intelligence
  (IJCAI)}, pages 2627--2633. AAAI Press, 2017.

\bibitem{rangapuram2018deep}
Syama~Sundar Rangapuram, Matthias~W Seeger, Jan Gasthaus, Lorenzo Stella,
  Yuyang Wang, and Tim Januschowski.
\newblock Deep state space models for time series forecasting.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  pages 7785--7794, 2018.

\bibitem{rivest2019new}
Fran{\c{c}}ois Rivest and Richard Kohar.
\newblock A new timing error cost function for binary time series prediction.
\newblock {\em IEEE transactions on neural networks and learning systems},
  2019.

\bibitem{robert2018hybridnet}
Thomas Robert, Nicolas Thome, and Matthieu Cord.
\newblock Hybridnet: Classification and reconstruction cooperation for
  semi-supervised learning.
\newblock In {\em European Conference on Computer Vision (ECCV)}, pages
  153--169, 2018.

\bibitem{sakoe1990dynamic}
Hiroaki Sakoe and Seibi Chiba.
\newblock Dynamic programming algorithm optimization for spoken word
  recognition.
\newblock {\em Readings in speech recognition}, 159:224, 1990.

\bibitem{salinas2017deepar}
David Salinas, Valentin Flunkert, and Jan Gasthaus.
\newblock Deep\textsc{AR}: Probabilistic forecasting with autoregressive
  recurrent networks.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2017.

\bibitem{seeger2016bayesian}
Matthias~W Seeger, David Salinas, and Valentin Flunkert.
\newblock Bayesian intermittent demand forecasting for large inventories.
\newblock In {\em Advances in Neural Information Processing Systems (NIPS)},
  pages 4646--4654, 2016.

\bibitem{sen2019}
Rajat Sen, Yu~Hsiang-Fu, and Dhillon Inderjit.
\newblock Think globally, act locally: a deep neural network approach to high
  dimensional time series forecasting.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2019.

\bibitem{sutskever2014sequence}
Ilya Sutskever, Oriol Vinyals, and Quoc~V Le.
\newblock Sequence to sequence learning with neural networks.
\newblock In {\em Advances in neural information processing systems (NIPS)},
  pages 3104--3112, 2014.

\bibitem{taieb2016bias}
Souhaib~Ben Taieb and Amir~F Atiya.
\newblock A bias and variance analysis for multistep-ahead time series
  forecasting.
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems},
  27(1):62--76, 2016.

\bibitem{taieb2012review}
Souhaib~Ben Taieb, Gianluca Bontempi, Amir~F Atiya, and Antti Sorjamaa.
\newblock A review and comparison of strategies for multi-step ahead time
  series forecasting based on the \textsc{NN5} forecasting competition.
\newblock {\em Expert systems with applications}, 39(8):7067--7083, 2012.

\bibitem{tao2018hierarchical}
Yunzhe Tao, Lin Ma, Weizhong Zhang, Jian Liu, Wei Liu, and Qiang Du.
\newblock Hierarchical attention-based recurrent highway networks for time
  series prediction.
\newblock {\em arXiv preprint arXiv:1806.00685}, 2018.

\bibitem{truong2019supervised}
Charles Truong, Laurent Oudre, and Nicolas Vayatis.
\newblock Supervised kernel change point detection with partial annotations.
\newblock In {\em International Conference on Acoustics, Speech and Signal
  Processing (ICASSP)}, pages 3147--3151. IEEE, 2019.

\bibitem{vallance2017towards}
Lo{\"\i}c Vallance, Bruno Charbonnier, Nicolas Paul, St{\'e}phanie Dubost, and
  Philippe Blanc.
\newblock Towards a standardized procedure to assess solar forecast accuracy: A
  new ramp and time alignment metric.
\newblock {\em Solar Energy}, 150:408--422, 2017.

\bibitem{van2016wavenet}
A{\"a}ron Van Den~Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol
  Vinyals, Alex Graves, Nal Kalchbrenner, Andrew~W Senior, and Koray
  Kavukcuoglu.
\newblock Wave\textsc{N}et: A generative model for raw audio.
\newblock {\em arXiv preprint arXiv:1609.03499}, 2016.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em Advances in neural information processing systems (NIPS)},
  pages 5998--6008, 2017.

\bibitem{venkatraman2015improving}
Arun Venkatraman, Martial Hebert, and J~Andrew Bagnell.
\newblock Improving multi-step prediction of learned time series models.
\newblock In {\em Twenty-Ninth AAAI Conference on Artificial Intelligence},
  2015.

\bibitem{wang2019deep}
Yuyang Wang, Alex Smola, Danielle Maddix, Jan Gasthaus, Dean Foster, and Tim
  Januschowski.
\newblock Deep factors for forecasting.
\newblock In {\em International Conference on Machine Learning (ICML)}, pages
  6607--6617, 2019.

\bibitem{wen2017multi}
Ruofeng Wen, Kari Torkkola, Balakrishnan Narayanaswamy, and Dhruv Madeka.
\newblock A multi-horizon quantile recurrent forecaster.
\newblock {\em NIPS Time Series Workshop}, 2017.

\bibitem{yu2016temporal}
Hsiang-Fu Yu, Nikhil Rao, and Inderjit~S Dhillon.
\newblock Temporal regularized matrix factorization for high-dimensional time
  series prediction.
\newblock In {\em Advances in neural information processing systems (NIPS)},
  pages 847--855, 2016.

\bibitem{yu2018lovasz}
Jiaqian Yu and Matthew~B Blaschko.
\newblock The lov{\'a}sz hinge: A novel convex surrogate for submodular losses.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence},
  2018.

\bibitem{yu2017long}
Rose Yu, Stephan Zheng, Anima Anandkumar, and Yisong Yue.
\newblock Long-term forecasting using tensor-train \textsc{RNN}s.
\newblock {\em arXiv preprint arXiv:1711.00073}, 2017.

\bibitem{yu17learning}
Rose Yu, Stephan Zheng, and Yan Liu.
\newblock Learning chaotic dynamics using tensor recurrent neural networks.
\newblock In {\em ICML Workshop on Deep Structured Prediction}, volume~17,
  2017.

\bibitem{yue2007support}
Yisong Yue, Thomas Finley, Filip Radlinski, and Thorsten Joachims.
\newblock A support vector method for optimizing average precision.
\newblock In {\em ACM SIGIR conference on Research and development in
  information retrieval}, pages 271--278. ACM, 2007.

\bibitem{zheng2017electric}
Jian Zheng, Cencen Xu, Ziang Zhang, and Xiaohua Li.
\newblock Electric load forecasting in smart grids using long-short-term-memory
  based recurrent neural network.
\newblock In {\em 51st Annual Conference on Information Sciences and Systems
  (CISS)}, pages 1--6. IEEE, 2017.

\end{thebibliography}
