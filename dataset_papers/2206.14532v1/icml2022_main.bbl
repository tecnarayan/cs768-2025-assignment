\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbasi~Koohpayegani et~al.(2020)Abbasi~Koohpayegani, Tejankar, and
  Pirsiavash]{abbasi2020compress}
Abbasi~Koohpayegani, S., Tejankar, A., and Pirsiavash, H.
\newblock Compress: Self-supervised learning by compressing representations.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 12980--12992, 2020.

\bibitem[Arani et~al.(2021)Arani, Sarfraz, and Zonooz]{Arani_2021_WACV}
Arani, E., Sarfraz, F., and Zonooz, B.
\newblock Noise as a resource for learning in knowledge distillation.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on
  Applications of Computer Vision (WACV)}, pp.\  3129--3138, January 2021.

\bibitem[Chandrasegaran et~al.(2021)Chandrasegaran, Tran, and
  Cheung]{Chandrasegaran_2021_CVPR}
Chandrasegaran, K., Tran, N.-T., and Cheung, N.-M.
\newblock A closer look at fourier spectrum discrepancies for cnn-generated
  images detection.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pp.\  7200--7209, June 2021.

\bibitem[Chiu et~al.(2018)Chiu, Sainath, Wu, Prabhavalkar, Nguyen, Chen,
  Kannan, Weiss, Rao, Gonina, Jaitly, Li, Chorowski, and Bacchiani]{chiu}
Chiu, C.-C., Sainath, T.~N., Wu, Y., Prabhavalkar, R., Nguyen, P., Chen, Z.,
  Kannan, A., Weiss, R.~J., Rao, K., Gonina, E., Jaitly, N., Li, B., Chorowski,
  J., and Bacchiani, M.
\newblock State-of-the-art speech recognition with sequence-to-sequence models.
\newblock In \emph{2018 IEEE International Conference on Acoustics, Speech and
  Signal Processing (ICASSP)}, pp.\  4774--4778, 2018.
\newblock \doi{10.1109/ICASSP.2018.8462105}.

\bibitem[Chorowski \& Jaitly(2017)Chorowski and Jaitly]{Chorowski2017}
Chorowski, J. and Jaitly, N.
\newblock Towards better decoding and language model integration in sequence to
  sequence models.
\newblock In \emph{Proc. Interspeech 2017}, pp.\  523--527, 2017.
\newblock \doi{10.21437/Interspeech.2017-343}.
\newblock URL \url{http://dx.doi.org/10.21437/Interspeech.2017-343}.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{imagenet_cvpr09}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock {ImageNet: A Large-Scale Hierarchical Image Database}.
\newblock In \emph{CVPR09}, 2009.

\bibitem[Dzanic et~al.(2020)Dzanic, Shah, and Witherden]{dzanic2020fourier}
Dzanic, T., Shah, K., and Witherden, F.
\newblock Fourier spectrum discrepancies in deep network generated images.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 3022--3032, 2020.

\bibitem[Fang et~al.(2021)Fang, Wang, Wang, Zhang, Yang, and Liu]{fang2021seed}
Fang, Z., Wang, J., Wang, L., Zhang, L., Yang, Y., and Liu, Z.
\newblock {\{}SEED{\}}: Self-supervised distillation for visual representation.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=AHm3dbp7D1D}.

\bibitem[Fellbaum(1998)]{Fellbaum1998}
Fellbaum, C. (ed.).
\newblock \emph{WordNet: An Electronic Lexical Database}.
\newblock Language, Speech, and Communication. MIT Press, Cambridge, MA, 1998.
\newblock ISBN 978-0-262-06197-1.

\bibitem[Fu et~al.(2020)Fu, Chen, Wang, Li, Lin, and Wang]{fu2020autogan}
Fu, Y., Chen, W., Wang, H., Li, H., Lin, Y., and Wang, Z.
\newblock Autogan-distiller: searching to compress generative adversarial
  networks.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, pp.\  3292--3303, 2020.

\bibitem[He et~al.(2019)He, Zhang, Zhang, Zhang, Xie, and Li]{he2019}
He, T., Zhang, Z., Zhang, H., Zhang, Z., Xie, J., and Li, M.
\newblock Bag of tricks for image classification with convolutional neural
  networks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, June 2019.

\bibitem[Heo et~al.(2019)Heo, Kim, Yun, Park, Kwak, and
  Choi]{heo2019comprehensive}
Heo, B., Kim, J., Yun, S., Park, H., Kwak, N., and Choi, J.~Y.
\newblock A comprehensive overhaul of feature distillation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  1921--1930, 2019.

\bibitem[Hinton et~al.(2015)Hinton, Vinyals, and Dean]{hinton_kd}
Hinton, G., Vinyals, O., and Dean, J.
\newblock Distilling the knowledge in a neural network.
\newblock In \emph{NIPS Deep Learning and Representation Learning Workshop},
  2015.
\newblock URL \url{http://arxiv.org/abs/1503.02531}.

\bibitem[Hu et~al.(2018)Hu, Peng, Wei, Huang, Li, Yang, and Zhou]{hu-attention}
Hu, M., Peng, Y., Wei, F., Huang, Z., Li, D., Yang, N., and Zhou, M.
\newblock Attention-guided answer distillation for machine reading
  comprehension.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  2077--2086, Brussels, Belgium,
  October-November 2018. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/D18-1232}.
\newblock URL \url{https://www.aclweb.org/anthology/D18-1232}.

\bibitem[Huang et~al.(2019)Huang, Cheng, Bapna, Firat, Chen, Chen, Lee, Ngiam,
  Le, Wu, and Chen]{huang}
Huang, Y., Cheng, Y., Bapna, A., Firat, O., Chen, D., Chen, M., Lee, H., Ngiam,
  J., Le, Q.~V., Wu, Y., and Chen, z.
\newblock Gpipe: Efficient training of giant neural networks using pipeline
  parallelism.
\newblock In Wallach, H., Larochelle, H., Beygelzimer, A., d\textquotesingle
  Alch\'{e}-Buc, F., Fox, E., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2019/file/093f65e080a295f8076b1c5722a46aa2-Paper.pdf}.

\bibitem[Jiao et~al.(2020)Jiao, Yin, Shang, Jiang, Chen, Li, Wang, and
  Liu]{jiao-tinybert}
Jiao, X., Yin, Y., Shang, L., Jiang, X., Chen, X., Li, L., Wang, F., and Liu,
  Q.
\newblock {T}iny{BERT}: Distilling {BERT} for natural language understanding.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP 2020}, pp.\  4163--4174, Online, November 2020. Association for
  Computational Linguistics.
\newblock \doi{10.18653/v1/2020.findings-emnlp.372}.
\newblock URL \url{https://www.aclweb.org/anthology/2020.findings-emnlp.372}.

\bibitem[Khosla et~al.(2020)Khosla, Teterwak, Wang, Sarna, Tian, Isola,
  Maschinot, Liu, and Krishnan]{khosla}
Khosla, P., Teterwak, P., Wang, C., Sarna, A., Tian, Y., Isola, P., Maschinot,
  A., Liu, C., and Krishnan, D.
\newblock Supervised contrastive learning.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M.~F., and Lin,
  H. (eds.), \emph{Advances in Neural Information Processing Systems},
  volume~33, pp.\  18661--18673. Curran Associates, Inc., 2020.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2020/file/d89a66c7c80a29b1bdbab0f2a1a94af8-Paper.pdf}.

\bibitem[Kwon et~al.(2020)Kwon, Na, Lee, and Kim]{kwon}
Kwon, K., Na, H., Lee, H., and Kim, N.~S.
\newblock Adaptive knowledge distillation based on entropy.
\newblock In \emph{ICASSP 2020 - 2020 IEEE International Conference on
  Acoustics, Speech and Signal Processing (ICASSP)}, pp.\  7409--7413, 2020.
\newblock \doi{10.1109/ICASSP40776.2020.9054698}.

\bibitem[Li et~al.(2020{\natexlab{a}})Li, Peng, Yuan, Wang, Liang, Lin, and
  Chang]{li2020block}
Li, C., Peng, J., Yuan, L., Wang, G., Liang, X., Lin, L., and Chang, X.
\newblock Block-wisely supervised neural architecture search with knowledge
  distillation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  1989--1998, 2020{\natexlab{a}}.

\bibitem[Li et~al.(2020{\natexlab{b}})Li, Lin, Ding, Liu, Zhu, and
  Han]{li2020gan}
Li, M., Lin, J., Ding, Y., Liu, Z., Zhu, J.-Y., and Han, S.
\newblock Gan compression: Efficient architectures for interactive conditional
  gans.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  5284--5294, 2020{\natexlab{b}}.

\bibitem[Lim et~al.(2018)Lim, Loo, Tran, Cheung, Roig, and
  Elovici]{lim2018doping}
Lim, S.~K., Loo, Y., Tran, N.~T., Cheung, N.~M., Roig, G., and Elovici, Y.
\newblock Doping: Generative data augmentation for unsupervised anomaly
  detection with gan.
\newblock In \emph{18th IEEE International Conference on Data Mining, ICDM
  2018}, pp.\  1122--1127. Institute of Electrical and Electronics Engineers
  Inc., 2018.

\bibitem[Liu et~al.(2022)Liu, Mao, Wu, Feichtenhofer, Darrell, and
  Xie]{liu2022convnet}
Liu, Z., Mao, H., Wu, C.-Y., Feichtenhofer, C., Darrell, T., and Xie, S.
\newblock A convnet for the 2020s.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  11976--11986, 2022.

\bibitem[Lopez-Paz et~al.(2016)Lopez-Paz, Sch{\"o}lkopf, Bottou, and
  Vapnik]{LopSchBotVap16}
Lopez-Paz, D., Sch{\"o}lkopf, B., Bottou, L., and Vapnik, V.
\newblock Unifying distillation and privileged information.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, November 2016.

\bibitem[Lukasik et~al.(2020)Lukasik, Bhojanapalli, Menon, and
  Kumar]{lukasik20a}
Lukasik, M., Bhojanapalli, S., Menon, A., and Kumar, S.
\newblock Does label smoothing mitigate label noise?
\newblock In III, H.~D. and Singh, A. (eds.), \emph{Proceedings of the 37th
  International Conference on Machine Learning}, volume 119 of
  \emph{Proceedings of Machine Learning Research}, pp.\  6448--6458. PMLR,
  13--18 Jul 2020.
\newblock URL \url{http://proceedings.mlr.press/v119/lukasik20a.html}.

\bibitem[Mghabbar \& Ratnamogan(2020)Mghabbar and Ratnamogan]{MghabbarR20}
Mghabbar, I. and Ratnamogan, P.
\newblock Building a multi-domain neural machine translation model using
  knowledge distillation.
\newblock In Giacomo, G.~D., Catal{\'{a}}, A., Dilkina, B., Milano, M., Barro,
  S., Bugar{\'{\i}}n, A., and Lang, J. (eds.), \emph{{ECAI} 2020 - 24th
  European Conference on Artificial Intelligence, 29 August-8 September 2020,
  Santiago de Compostela, Spain, August 29 - September 8, 2020 - Including 10th
  Conference on Prestigious Applications of Artificial Intelligence {(PAIS}
  2020)}, volume 325 of \emph{Frontiers in Artificial Intelligence and
  Applications}, pp.\  2116--2123. {IOS} Press, 2020.
\newblock \doi{10.3233/FAIA200335}.
\newblock URL \url{https://doi.org/10.3233/FAIA200335}.

\bibitem[M\"{u}ller et~al.(2019)M\"{u}ller, Kornblith, and Hinton]{muller}
M\"{u}ller, R., Kornblith, S., and Hinton, G.~E.
\newblock When does label smoothing help?
\newblock In Wallach, H., Larochelle, H., Beygelzimer, A., d\textquotesingle
  Alch\'{e}-Buc, F., Fox, E., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2019/file/f1748d6b0fd9d439f71450117eba2725-Paper.pdf}.

\bibitem[Nakashole \& Flauger(2017)Nakashole and Flauger]{nakashole-flauger}
Nakashole, N. and Flauger, R.
\newblock Knowledge distillation for bilingual dictionary induction.
\newblock In \emph{Proceedings of the 2017 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  2497--2506, Copenhagen, Denmark,
  September 2017. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/D17-1264}.
\newblock URL \url{https://www.aclweb.org/anthology/D17-1264}.

\bibitem[Peng et~al.(2019)Peng, Li, Zhang, Li, Qi, and Tang]{Peng_2019_ICCV}
Peng, Z., Li, Z., Zhang, J., Li, Y., Qi, G.-J., and Tang, J.
\newblock Few-shot image recognition with knowledge transfer.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, October 2019.

\bibitem[Pereyra et~al.(2017)Pereyra, Tucker, Chorowski, Kaiser, and
  Hinton]{pereyra}
Pereyra, G., Tucker, G., Chorowski, J., Kaiser, Å., and Hinton, G.
\newblock Regularizing neural networks by penalizing confident output
  distributions.
\newblock 01 2017.

\bibitem[Perez et~al.(2020)Perez, Sanguineti, Morerio, and
  Murino]{Perez_2020_WACV}
Perez, A., Sanguineti, V., Morerio, P., and Murino, V.
\newblock Audio-visual model distillation using acoustic images.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on
  Applications of Computer Vision (WACV)}, March 2020.

\bibitem[Real et~al.(2019)Real, Aggarwal, Huang, and Le]{aggarwal}
Real, E., Aggarwal, A., Huang, Y., and Le, Q.~V.
\newblock Regularized evolution for image classifier architecture search.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  33\penalty0 (01):\penalty0 4780--4789, Jul. 2019.
\newblock \doi{10.1609/aaai.v33i01.33014780}.
\newblock URL \url{https://ojs.aaai.org/index.php/AAAI/article/view/4405}.

\bibitem[Sandler et~al.(2018)Sandler, Howard, Zhu, Zhmoginov, and
  Chen]{sandler2018mobilenetv2}
Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., and Chen, L.-C.
\newblock Mobilenetv2: Inverted residuals and linear bottlenecks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  4510--4520, 2018.

\bibitem[Shen et~al.(2020)Shen, Lu, Li, and Kawai]{KnowledgeDR_Shen}
Shen, P., Lu, X., Li, S., and Kawai, H.
\newblock Knowledge distillation-based representation learning for
  short-utterance spoken language identification.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language
  Processing}, 28:\penalty0 2674--2683, 2020.

\bibitem[Shen et~al.(2021{\natexlab{a}})Shen, Liu, Liu, Savvides, Darrell, and
  Xing]{shen2021unmix}
Shen, Z., Liu, Z., Liu, Z., Savvides, M., Darrell, T., and Xing, E.
\newblock Un-mix: Rethinking image mixtures for unsupervised visual
  representation learning, 2021{\natexlab{a}}.

\bibitem[Shen et~al.(2021{\natexlab{b}})Shen, Liu, Xu, Chen, Cheng, and
  Savvides]{shen2021}
Shen, Z., Liu, Z., Xu, D., Chen, Z., Cheng, K.-T., and Savvides, M.
\newblock Is label smoothing truly incompatible with knowledge distillation: An
  empirical study.
\newblock In \emph{International Conference on Learning Representations},
  2021{\natexlab{b}}.
\newblock URL \url{https://openreview.net/forum?id=PObuuGVrGaZ}.

\bibitem[Szegedy et~al.(2016)Szegedy, Vanhoucke, Ioffe, Shlens, and
  Wojna]{szegedy_ls}
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z.
\newblock Rethinking the inception architecture for computer vision.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp.\  2818--2826, 2016.
\newblock \doi{10.1109/CVPR.2016.308}.

\bibitem[Tan \& Le(2019)Tan and Le]{tan2019efficientnet}
Tan, M. and Le, Q.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock In \emph{International conference on machine learning}, pp.\
  6105--6114. PMLR, 2019.

\bibitem[Tang et~al.(2021)Tang, Shivanna, Zhao, Lin, Singh, Chi, and
  Jain]{tang2021}
Tang, J., Shivanna, R., Zhao, Z., Lin, D., Singh, A., Chi, E.~H., and Jain, S.
\newblock Understanding and improving knowledge distillation, 2021.

\bibitem[Tran et~al.(2021)Tran, Tran, Nguyen, Nguyen, and Cheung]{tran2021data}
Tran, N.-T., Tran, V.-H., Nguyen, N.-B., Nguyen, T.-K., and Cheung, N.-M.
\newblock On data augmentation for gan training.
\newblock \emph{IEEE Transactions on Image Processing}, 30:\penalty0
  1882--1897, 2021.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, L.~u., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In Guyon, I., Luxburg, U.~V., Bengio, S., Wallach, H., Fergus, R.,
  Vishwanathan, S., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~30. Curran Associates, Inc., 2017.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}.

\bibitem[Wah et~al.(2011)Wah, Branson, Welinder, Perona, and
  Belongie]{WahCUB_200_2011}
Wah, C., Branson, S., Welinder, P., Perona, P., and Belongie, S.
\newblock {The Caltech-UCSD Birds-200-2011 Dataset}.
\newblock Technical Report CNS-TR-2011-001, California Institute of Technology,
  2011.

\bibitem[Wang et~al.(2021)Wang, Gong, Li, Liu, and Chandra]{alphanet-wang21i}
Wang, D., Gong, C., Li, M., Liu, Q., and Chandra, V.
\newblock Alphanet: Improved training of supernets with alpha-divergence.
\newblock In Meila, M. and Zhang, T. (eds.), \emph{Proceedings of the 38th
  International Conference on Machine Learning}, volume 139 of
  \emph{Proceedings of Machine Learning Research}, pp.\  10760--10771. PMLR,
  18--24 Jul 2021.
\newblock URL \url{https://proceedings.mlr.press/v139/wang21i.html}.

\bibitem[Yu \& Pool(2020)Yu and Pool]{ssl_gan_compress}
Yu, C. and Pool, J.
\newblock Self-supervised generative adversarial compression.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H.
  (eds.), \emph{Advances in Neural Information Processing Systems}, volume~33,
  pp.\  8235--8246. Curran Associates, Inc., 2020.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2020/file/5d79099fcdf499f12b79770834c0164a-Paper.pdf}.

\bibitem[Yu et~al.(2020)Yu, Jin, Liu, Bender, Kindermans, Tan, Huang, Song,
  Pang, and Le]{yu2020bignas}
Yu, J., Jin, P., Liu, H., Bender, G., Kindermans, P.-J., Tan, M., Huang, T.,
  Song, X., Pang, R., and Le, Q.
\newblock Bignas: Scaling up neural architecture search with big single-stage
  models.
\newblock In \emph{European Conference on Computer Vision}, pp.\  702--717.
  Springer, 2020.

\bibitem[Yuan et~al.(2020)Yuan, Tay, Li, Wang, and Feng]{Yuan_2020_CVPR}
Yuan, L., Tay, F.~E., Li, G., Wang, T., and Feng, J.
\newblock Revisiting knowledge distillation via label smoothing regularization.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2020.

\bibitem[Zhang et~al.(2020)Zhang, Song, Zhou, and Liu]{zhang_eccv20}
Zhang, M., Song, G., Zhou, H., and Liu, Y.
\newblock Discriminability distillation in group representation learning.
\newblock In Vedaldi, A., Bischof, H., Brox, T., and Frahm, J.-M. (eds.),
  \emph{Computer Vision -- ECCV 2020}, pp.\  1--19, Cham, 2020. Springer
  International Publishing.

\bibitem[Zoph et~al.(2018)Zoph, Vasudevan, Shlens, and Le]{zoph}
Zoph, B., Vasudevan, V., Shlens, J., and Le, Q.~V.
\newblock Learning transferable architectures for scalable image recognition.
\newblock In \emph{2018 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, pp.\  8697--8710, 2018.
\newblock \doi{10.1109/CVPR.2018.00907}.

\end{thebibliography}
