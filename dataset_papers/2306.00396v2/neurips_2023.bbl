\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{qna}
Moab Arar, Ariel Shamir, Amit~H. Bermano, et~al.
\newblock Learned queries for efficient local attention.
\newblock In {\em CVPR}, 2022.

\bibitem{regionvit}
Chun-Fu~(Richard) Chen, Rameswar Panda, and Quanfu Fan.
\newblock {RegionViT: Regional-to-Local Attention for Vision Transformers}.
\newblock In {\em ICLR}, 2022.

\bibitem{mmdetection}
Kai Chen, Jiaqi Wang, Jiangmiao Pang, et~al.
\newblock {MMDetection}: Open mmlab detection toolbox and benchmark.
\newblock {\em arXiv preprint arXiv:1906.07155}, 2019.

\bibitem{mobileformer}
Yinpeng Chen, Xiyang Dai, Dongdong Chen, et~al.
\newblock Mobile-former: Bridging mobilenet and transformer.
\newblock In {\em CVPR}, 2022.

\bibitem{twins}
Xiangxiang Chu, Zhi Tian, Yuqing Wang, Bo Zhang, Haibing Ren, Xiaolin Wei,
  Huaxia Xia, and Chunhua Shen.
\newblock Twins: Revisiting the design of spatial attention in vision
  transformers.
\newblock In {\em NeurIPS}, 2021.

\bibitem{CPVT}
Xiangxiang Chu, Zhi Tian, Bo Zhang, Xinlong Wang, and Chunhua Shen.
\newblock Conditional positional encodings for vision transformers.
\newblock In {\em ICLR}, 2023.

\bibitem{mmsegmentation}
MMSegmentation Contributors.
\newblock Mmsegmentation, an open source semantic segmentation toolbox, 2020.

\bibitem{randomaugment}
Ekin~D Cubuk, Barret Zoph, Jonathon Shlens, et~al.
\newblock Randaugment: Practical automated data augmentation with a reduced
  search space.
\newblock In {\em CVPRW}, 2020.

\bibitem{imagenet}
Jia Deng, Wei Dong, Richard Socher, et~al.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em CVPR}, 2009.

\bibitem{davit}
Mingyu Ding, Bin Xiao, Noel Codella, et~al.
\newblock Davit: Dual attention vision transformers.
\newblock In {\em ECCV}, 2022.

\bibitem{replknet}
Xiaohan Ding, Xiangyu Zhang, Yizhuang Zhou, Jungong Han, Guiguang Ding, and
  Jian Sun.
\newblock Scaling up your kernels to 31x31: Revisiting large kernel design in
  cnns.
\newblock 2022.

\bibitem{cswin}
Xiaoyi Dong, Jianmin Bao, Dongdong Chen, et~al.
\newblock Cswin transformer: A general vision transformer backbone with
  cross-shaped windows.
\newblock In {\em CVPR}, 2022.

\bibitem{vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em ICLR}, 2021.

\bibitem{xcit}
Alaaeldin El-Nouby, Hugo Touvron, Mathilde Caron, et~al.
\newblock Xcit: Cross-covariance image transformers.
\newblock In {\em NeurIPS}, 2021.

\bibitem{dfvit}
Li Gao, Dong Nie, Bo Li, and Xiaofeng Ren.
\newblock Doubly-fused vit: Fuse information from vision transformer doubly
  with local representation.
\newblock In {\em ECCV}, 2022.

\bibitem{cmt}
Jianyuan Guo, Kai Han, Han Wu, Chang Xu, Yehui Tang, Chunjing Xu, and Yunhe
  Wang.
\newblock Cmt: Convolutional neural networks meet vision transformers.
\newblock {\em CVPR}, 2022.

\bibitem{VAN}
Meng-Hao Guo, Cheng-Ze Lu, Zheng-Ning Liu, Ming-Ming Cheng, and Shi-Min Hu.
\newblock Visual attention network.
\newblock {\em arXiv preprint arXiv:2202.09741}, 2022.

\bibitem{tnt}
Kai Han, An Xiao, Enhua Wu, et~al.
\newblock Transformer in transformer.
\newblock In {\em NeurIPS}, 2021.

\bibitem{maskrcnn}
Kaiming He, Georgia Gkioxari, Piotr Doll{\'{a}}r, and Ross~B. Girshick.
\newblock Mask r-cnn.
\newblock In {\em ICCV}, 2017.

\bibitem{resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Sun Jian.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{pit}
Byeongho Heo, Sangdoo Yun, Dongyoon Han, et~al.
\newblock Rethinking spatial dimensions of vision transformers.
\newblock In {\em ICCV}, 2021.

\bibitem{conv2former}
Qibin Hou, Cheng-Ze Lu, Ming-Ming Cheng, and Jiashi Feng.
\newblock Conv2former: A simple transformer-style convnet for visual
  recognition.
\newblock {\em arXiv preprint arXiv:2211.11943}, 2022.

\bibitem{mobilenet}
Andrew Howard, Mark Sandler, Grace Chu, et~al.
\newblock Searching for mobilenetv3.
\newblock In {\em ICCV}, 2019.

\bibitem{droppath}
Gao Huang, Yu Sun, and Zhuang Liu.
\newblock Deep networks with stochastic depth.
\newblock In {\em ECCV}, 2016.

\bibitem{ortho}
Huaibo Huang, Xiaoqiang Zhou, and Ran He.
\newblock Orthogonal transformer: An efficient vision transformer backbone with
  token orthogonalization.
\newblock In {\em NeurIPS}, 2022.

\bibitem{lightvit}
Tao Huang, Lang Huang, Shan You, Fei Wang, Chen Qian, and Chang Xu.
\newblock Lightvit: Towards light-weight convolution-free vision transformers.
\newblock {\em arXiv preprint arXiv:2207.05557}, 2022.

\bibitem{semanticfpn}
Alexander Kirillov, Ross Girshick, Kaiming He, and Piotr Doll{\'{a}}r.
\newblock Panoptic feature pyramid networks.
\newblock In {\em CVPR}, 2019.

\bibitem{mpvit}
Youngwan Lee, Jonghee Kim, Jeffrey Willette, and Sung~Ju Hwang.
\newblock Mpvit: Multi-path vision transformer for dense prediction.
\newblock In {\em CVPR}, 2022.

\bibitem{uniformer}
Kunchang Li, Yali Wang, Peng Gao, et~al.
\newblock Uniformer: Unified transformer for efficient spatial-temporal
  representation learning.
\newblock In {\em ICLR}, 2022.

\bibitem{efficientformer}
Yanyu Li, Geng Yuan, Yang Wen, et~al.
\newblock Efficientformer: Vision transformers at mobilenet speed.
\newblock In {\em NeurIPS}, 2022.

\bibitem{localvit}
Yawei Li, Kai Zhang, Jiezhang Cao, Radu Timofte, and Luc Van~Gool.
\newblock Localvit: Bringing locality to vision transformers.
\newblock {\em arXiv preprint arXiv:2104.05707}, 2021.

\bibitem{retinanet}
Tsung{-}Yi Lin, Priya Goyal, Ross~B. Girshick, and Kaiming~He andPiotr
  Doll{\'{a}}r.
\newblock Focal loss for dense object detection.
\newblock In {\em ICCV}, 2017.

\bibitem{coco}
Tsung-Yi Lin, Michael Maire, Serge Belongie, et~al.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em ECCV}, 2014.

\bibitem{SwinTransformer}
Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock In {\em ICCV}, 2021.

\bibitem{convnext}
Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, et~al.
\newblock A convnet for the 2020s.
\newblock In {\em CVPR}, 2022.

\bibitem{adamw}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock In {\em ICLR}, 2019.

\bibitem{EdgeNeXt}
Muhammad Maaz, Abdelrahman Shaker, Hisham Cholakkal, Salman Khan, Syed~Waqas
  Zamir, Rao~Muhammad Anwer, and Fahad~Shahbaz Khan.
\newblock Edgenext: Efficiently amalgamated cnn-transformer architecture for
  mobile vision applications.
\newblock In {\em CADL}, 2022.

\bibitem{mobilevit}
Sachin Mehta and Mohammad Rastegari.
\newblock Mobilevit: Light-weight, general-purpose, and mobile-friendly vision
  transformer.
\newblock In {\em ICLR}, 2022.

\bibitem{pervit}
Juhong Min, Yucheng Zhao, Chong Luo, et~al.
\newblock Peripheral vision transformer.
\newblock In {\em NeurIPS}, 2022.

\bibitem{edgevit}
Junting Pan, Adrian Bulat, Fuwen Tan, et~al.
\newblock Edgevits: Competing light-weight cnns on mobile devices with vision
  transformers.
\newblock In {\em ECCV}, 2022.

\bibitem{litv2}
Zizheng Pan, Jianfei Cai, and Bohan Zhuang.
\newblock Fast vision transformers with hilo attention.
\newblock In {\em NeurIPS}, 2022.

\bibitem{litv1}
Zizheng Pan, Bohan Zhuang, Haoyu He, Jing Liu, and Jianfei Cai.
\newblock Less is more: Pay less attention in vision transformers.
\newblock In {\em AAAI}, 2022.

\bibitem{conformer}
Zhiliang Peng, Wei Huang, Shanzhi Gu, et~al.
\newblock Conformer: Local features coupling global representations for visual
  recognition.
\newblock In {\em ICCV}, 2021.

\bibitem{regnety}
Ilija Radosavovic, Raj~Prateek Kosaraju, Ross Girshick, Kaiming He, and Piotr
  Doll{\'a}r.
\newblock Designing network design spaces.
\newblock In {\em CVPR}, 2020.

\bibitem{dynamicvit}
Yongming Rao, Wenliang Zhao, Benlin Liu, Jiwen Lu, Jie Zhou, and Cho-Jui Hsieh.
\newblock Dynamicvit: Efficient vision transformers with dynamic token
  sparsification.
\newblock In {\em NeurIPS}, 2021.

\bibitem{hornet}
Yongming Rao, Wenliang Zhao, Yansong Tang, Jie Zhou, Ser-Lam Lim, and Jiwen Lu.
\newblock Hornet: Efficient high-order spatial interactions with recursive
  gated convolutions.
\newblock {\em NeurIPS}, 2022.

\bibitem{shunted}
Sucheng Ren, Daquan Zhou, Shengfeng He, Jiashi Feng, and Xinchao Wang.
\newblock Shunted self-attention via multi-scale token aggregation.
\newblock In {\em CVPR}, 2022.

\bibitem{inceptionformer}
Chenyang Si, Weihao Yu, Pan Zhou, Yichen Zhou, Xinchao Wang, and Shuicheng YAN.
\newblock Inception transformer.
\newblock In {\em NeurIPS}, 2022.

\bibitem{vgg}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In {\em ICLR}, 2015.

\bibitem{googlenet}
Christian Szegedy, Wei Liu, Yangqing Jia, et~al.
\newblock Going deeper with convolutions.
\newblock In {\em CVPR}, 2015.

\bibitem{efficientnet}
Mingxing Tan and Quoc Le.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock In {\em ICML}, 2019.

\bibitem{quadtree}
Shitao Tang, Jiahui Zhang, Siyu Zhu, et~al.
\newblock Quadtree attention for vision transformers.
\newblock In {\em ICLR}, 2022.

\bibitem{wave-mlp}
Yehui Tang, Kai Han, Jianyuan Guo, Chang Xu, Yanxi Li, Chao Xu, and Yunhe Wang.
\newblock An image patch is a wave: Phase-aware vision mlp.
\newblock In {\em CVPR}, 2022.

\bibitem{deit}
Hugo Touvron, Matthieu Cord, Matthijs Douze, et~al.
\newblock Training data-efficient image transformers \& distillation through
  attention.
\newblock In {\em ICML}, 2021.

\bibitem{maxvit}
Zhengzhong Tu, Hossein Talebi, Han Zhang, et~al.
\newblock Maxvit: Multi-axis vision transformer.
\newblock In {\em ECCV}, 2022.

\bibitem{attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, et~al.
\newblock Attention is all you need.
\newblock In {\em NeurIPS}, 2017.

\bibitem{pvt}
Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong
  Lu, Ping Luo, and Ling Shao.
\newblock Pyramid vision transformer: A versatile backbone for dense prediction
  without convolutions.
\newblock {\em arXiv preprint arXiv:2103.15808}, 2021.

\bibitem{pvtv2}
Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong
  Lu, Ping Luo, and Ling Shao.
\newblock Pvtv2: Improved baselines with pyramid vision transformer.
\newblock {\em Computational Visual Media}, 8(3):1--10, 2022.

\bibitem{crossformer}
Wenxiao Wang, Lu Yao, Long Chen, Binbin Lin, Deng Cai, Xiaofei He, and Wei Liu.
\newblock Crossformer: A versatile vision transformer hinging on cross-scale
  attention.
\newblock In {\em ICLR}, 2022.

\bibitem{cvt}
Haiping Wu, Bin Xiao, Noel Codella, Mengchen Liu, Xiyang Dai, Lu Yuan, and Lei
  Zhang.
\newblock Cvt: Introducing convolutions to vision transformers.
\newblock {\em arXiv preprint arXiv:2103.15808}, 2021.

\bibitem{dat}
Zhuofan Xia, Xuran Pan, Shiji Song, Li~Erran Li, and Gao Huang.
\newblock Vision transformer with deformable attention.
\newblock In {\em CVPR}, 2022.

\bibitem{upernet}
Tete Xiao, Yingcheng Liu, Bolei Zhou, Yuning Jiang, and Jian Sun.
\newblock Unified perceptual parsing for scene understanding.
\newblock In {\em ECCV}, 2018.

\bibitem{early}
Tete Xiao, Mannat Singh, Eric Mintun, et~al.
\newblock Early convolutions help transformers see better.
\newblock In {\em NeurIPS}, 2021.

\bibitem{coat}
Weijian Xu, Yifan Xu, Tyler Chang, and Zhuowen Tu.
\newblock Co-scale conv-attentional image transformers.
\newblock In {\em ICCV}, 2021.

\bibitem{LVT}
Chenglin Yang, Yilin Wang, Jianming Zhang, et~al.
\newblock Lite vision transformer with enhanced self-attention.
\newblock In {\em CVPR}, 2022.

\bibitem{focalnet}
Jianwei Yang, Chunyuan Li, Xiyang Dai, and Jianfeng Gao.
\newblock Focal modulation networks.
\newblock {\em NeurIPS}, 2022.

\bibitem{focal}
Jianwei Yang, Chunyuan Li, Pengchuan Zhang, Xiyang Dai, Bin Xiao, Lu Yuan, and
  Jianfeng Gao.
\newblock Focal self-attention for local-global interactions in vision
  transformers, 2021.

\bibitem{ScalableViT}
Rui Yang, Hailong Ma, Jie Wu, Yansong Tang, Xuefeng Xiao, Min Zheng, and Xiu
  Li.
\newblock Scalablevit: Rethinking the context-oriented generalization of vision
  transformer.
\newblock {\em ECCV}, 2022.

\bibitem{wavevit}
Ting Yao, Yingwei Pan, Yehao Li, Chong-Wah Ngo, and Tao Mei.
\newblock Wave-vit: Unifying wavelet and transformers for visual representation
  learning.
\newblock In {\em Proceedings of the European conference on computer vision
  (ECCV)}, 2022.

\bibitem{poolformer}
Weihao Yu, Mi Luo, Pan Zhou, Chenyang Si, Yichen Zhou, Xinchao Wang, Jiashi
  Feng, and Shuicheng Yan.
\newblock Metaformer is actually what you need for vision.
\newblock In {\em CVPR}, 2022.

\bibitem{ceit}
Kun Yuan, Shaopeng Guo, Ziwei Liu, et~al.
\newblock Incorporating convolution designs into visual transformers.
\newblock In {\em ICCV}, 2021.

\bibitem{t2t}
Li Yuan, Yunpeng Chen, Tao Wang, et~al.
\newblock Tokens-to-token vit: Training vision transformers from scratch on
  imagenet.
\newblock In {\em ICCV}, 2021.

\bibitem{cutmix}
Sangdoo Yun, Dongyoon Han, Seong~Joon Oh, et~al.
\newblock Cutmix: Regularization strategy to train strong classifiers with
  localizable features.
\newblock In {\em ICCV}, 2019.

\bibitem{mixup}
Hongyi Zhang, Moustapha Cisse, Yann~N Dauphin, et~al.
\newblock mixup: Beyond empirical risk minimization.
\newblock In {\em ICLR}, 2018.

\bibitem{parcnet}
Haokui Zhang, Wenze Hu, and Xiaoyu Wang.
\newblock Parc-net: Position aware circular convolution with merits from
  convnets and transformer.
\newblock In {\em ECCV}, 2022.

\bibitem{ViL}
Pengchuan Zhang, Xiyang Dai, Jianwei Yang, Bin Xiao, Lu Yuan, Lei Zhang, and
  Jianfeng Gao.
\newblock Multi-scale vision longformer: A new vision transformer for
  high-resolution image encoding.
\newblock In {\em ICCV}, 2021.

\bibitem{rest}
Qinglong Zhang and Yu bin Yang.
\newblock Rest: An efficient transformer for visual recognition.
\newblock In {\em NeurIPS}, 2021.

\bibitem{randera}
Zhun Zhong, Liang Zheng, Guoliang Kang, et~al.
\newblock Random erasing data augmentation.
\newblock In {\em AAAI}, 2020.

\bibitem{ade20k}
Bolei Zhou, Hang Zhao, Xavier Puig, et~al.
\newblock Scene parsing through ade20k dataset.
\newblock In {\em CVPR}, 2017.

\bibitem{FAN}
Daquan Zhou, Zhiding Yu, Enze Xie, et~al.
\newblock Understanding the robustness in vision transformers.
\newblock In {\em ICML}, 2022.

\bibitem{sit}
Zhuofan Zong, Kunchang Li, Guanglu Song, et~al.
\newblock Self-slimmed vision transformer.
\newblock In {\em ECCV}, 2022.

\end{thebibliography}
