\begin{thebibliography}{10}

\bibitem{baier2014mcts}
H.~Baier and M.~H. Winands.
\newblock Mcts-minimax hybrids.
\newblock {\em IEEE Transactions on Computational Intelligence and AI in
  Games}, 7(2):167--179, 2014.

\bibitem{baier2018mcts}
H.~Baier and M.~H. Winands.
\newblock Mcts-minimax hybrids with state evaluations.
\newblock {\em Journal of Artificial Intelligence Research}, 62:193--231, 2018.

\bibitem{bouzy2001computer}
B.~Bouzy and T.~Cazenave.
\newblock Computer go: an ai oriented survey.
\newblock {\em Artificial Intelligence}, 132(1):39--103, 2001.

\bibitem{bouzy2004monte}
B.~Bouzy and B.~Helmstetter.
\newblock Monte-carlo go developments.
\newblock In {\em Advances in computer games}, pages 159--174. Springer, 2004.

\bibitem{gnugo}
D.~Bump, M.~Li, W.~Iba, and et~al.
\newblock Gnugo, 2005.

\bibitem{cai2007computer}
X.~Cai and D.~C. Wunsch.
\newblock Computer go: A grand challenge to ai.
\newblock {\em Challenges for Computational Intelligence}, pages 443--465,
  2007.

\bibitem{carnap1962logical}
R.~Carnap.
\newblock Logical foundations of probability.
\newblock 1962.

\bibitem{chaslot2008monte}
G.~Chaslot, S.~Bakkes, I.~Szita, and P.~Spronck.
\newblock Monte-carlo tree search: A new framework for game ai.
\newblock {\em AIIDE}, 8:216--217, 2008.

\bibitem{coulom2006efficient}
R.~Coulom.
\newblock Efficient selectivity and backup operators in monte-carlo tree
  search.
\newblock In {\em International conference on computers and games}, pages
  72--83. Springer, 2006.

\bibitem{danihelka2022policy}
I.~Danihelka, A.~Guez, J.~Schrittwieser, and D.~Silver.
\newblock Policy improvement by planning with gumbel.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{gelly2007combining}
S.~Gelly and D.~Silver.
\newblock Combining online and offline knowledge in uct.
\newblock In {\em Proceedings of the 24th international conference on Machine
  learning}, pages 273--280, 2007.

\bibitem{gelly2008achieving}
S.~Gelly and D.~Silver.
\newblock Achieving master level play in 9 x 9 computer go.
\newblock In {\em AAAI}, volume~8, pages 1537--1540, 2008.

\bibitem{gelly2011monte}
S.~Gelly and D.~Silver.
\newblock Monte-carlo tree search and rapid action value estimation in computer
  go.
\newblock {\em Artificial Intelligence}, 175(11):1856--1875, 2011.

\bibitem{gelly2006modification}
S.~Gelly, Y.~Wang, R.~Munos, and O.~Teytaud.
\newblock {\em Modification of UCT with patterns in Monte-Carlo Go}.
\newblock PhD thesis, INRIA, 2006.

\bibitem{grill2020monte}
J.-B. Grill, F.~Altch{\'e}, Y.~Tang, T.~Hubert, M.~Valko, I.~Antonoglou, and
  R.~Munos.
\newblock Monte-carlo tree search as regularized policy optimization.
\newblock In {\em International Conference on Machine Learning}, pages
  3769--3778. PMLR, 2020.

\bibitem{haarnoja2018soft}
T.~Haarnoja, A.~Zhou, P.~Abbeel, and S.~Levine.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock In {\em International conference on machine learning}, pages
  1861--1870. PMLR, 2018.

\bibitem{hoffman2013stochastic}
M.~D. Hoffman, D.~M. Blei, C.~Wang, and J.~Paisley.
\newblock Stochastic variational inference.
\newblock {\em Journal of Machine Learning Research}, 14(5), 2013.

\bibitem{hsueh2016analysis}
C.-H. Hsueh, I.-C. Wu, W.-J. Tseng, S.-J. Yen, and J.-C. Chen.
\newblock An analysis for strength improvement of an mcts-based program playing
  chinese dark chess.
\newblock {\em Theoretical Computer Science}, 644:63--75, 2016.

\bibitem{gymgo}
E.~Huang.
\newblock Gymgo.
\newblock \url{https://github.com/aigagror/GymGo}, 2021.

\bibitem{kocsis2006bandit}
L.~Kocsis and C.~Szepesv{\'a}ri.
\newblock Bandit based monte-carlo planning.
\newblock In {\em European conference on machine learning}, pages 282--293.
  Springer, 2006.

\bibitem{lan2020learning}
L.-C. Lan, M.-Y. Tsai, T.-R. Wu, I.~Wu, C.-J. Hsieh, et~al.
\newblock Learning to stop: Dynamic simulation monte-carlo tree search.
\newblock {\em arXiv preprint arXiv:2012.07910}, 2020.

\bibitem{lorentz2015early}
R.~Lorentz.
\newblock Early playout termination in mcts.
\newblock In {\em Advances in Computer Games}, pages 12--19. Springer, 2015.

\bibitem{mnih2015human}
V.~Mnih, K.~Kavukcuoglu, D.~Silver, A.~A. Rusu, J.~Veness, M.~G. Bellemare,
  A.~Graves, M.~Riedmiller, A.~K. Fidjeland, G.~Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock {\em Nature}, 518(7540):529--533, 2015.

\bibitem{newell1982knowledge}
A.~Newell.
\newblock The knowledge level.
\newblock {\em Artificial intelligence}, 18(1):87--127, 1982.

\bibitem{rosin2011multi}
C.~D. Rosin.
\newblock Multi-armed bandits with episode context.
\newblock {\em Annals of Mathematics and Artificial Intelligence},
  61(3):203--230, 2011.

\bibitem{russell1994provably}
S.~J. Russell and D.~Subramanian.
\newblock Provably bounded-optimal agents.
\newblock {\em Journal of Artificial Intelligence Research}, 2:575--609, 1994.

\bibitem{schrittwieser2020mastering}
J.~Schrittwieser, I.~Antonoglou, T.~Hubert, K.~Simonyan, L.~Sifre, S.~Schmitt,
  A.~Guez, E.~Lockhart, D.~Hassabis, T.~Graepel, et~al.
\newblock Mastering atari, go, chess and shogi by planning with a learned
  model.
\newblock {\em Nature}, 588(7839):604--609, 2020.

\bibitem{schulman2017proximal}
J.~Schulman, F.~Wolski, P.~Dhariwal, A.~Radford, and O.~Klimov.
\newblock Proximal policy optimization algorithms.
\newblock {\em arXiv preprint arXiv:1707.06347}, 2017.

\bibitem{sephton2014heuristic}
N.~Sephton, P.~I. Cowling, E.~Powley, and N.~H. Slaven.
\newblock Heuristic move pruning in monte carlo tree search for the strategic
  card game lords of war.
\newblock In {\em 2014 IEEE Conference on Computational Intelligence and
  Games}, pages 1--7. IEEE, 2014.

\bibitem{silver2016mastering}
D.~Silver, A.~Huang, C.~J. Maddison, A.~Guez, L.~Sifre, G.~Van Den~Driessche,
  J.~Schrittwieser, I.~Antonoglou, V.~Panneershelvam, M.~Lanctot, et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock {\em Nature}, 529(7587):484--489, 2016.

\bibitem{silver2018general}
D.~Silver, T.~Hubert, J.~Schrittwieser, I.~Antonoglou, M.~Lai, A.~Guez,
  M.~Lanctot, L.~Sifre, D.~Kumaran, T.~Graepel, et~al.
\newblock A general reinforcement learning algorithm that masters chess, shogi,
  and go through self-play.
\newblock {\em Science}, 362(6419):1140--1144, 2018.

\bibitem{silver2017mastering}
D.~Silver, J.~Schrittwieser, K.~Simonyan, I.~Antonoglou, A.~Huang, A.~Guez,
  T.~Hubert, L.~Baker, M.~Lai, A.~Bolton, et~al.
\newblock Mastering the game of go without human knowledge.
\newblock {\em Nature}, 550(7676):354--359, 2017.

\bibitem{wang2007modifications}
Y.~Wang and S.~Gelly.
\newblock Modifications of uct and sequence-like simulations for monte-carlo
  go.
\newblock In {\em 2007 IEEE Symposium on Computational Intelligence and Games},
  pages 175--182. IEEE, 2007.

\bibitem{ye2021mastering}
W.~Ye, S.~Liu, T.~Kurutach, P.~Abbeel, and Y.~Gao.
\newblock Mastering atari games with limited data.
\newblock {\em Advances in Neural Information Processing Systems},
  34:25476--25488, 2021.

\end{thebibliography}
