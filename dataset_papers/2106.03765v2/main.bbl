\begin{thebibliography}{10}

\bibitem{hill2011bayesian}
Jennifer~L Hill.
\newblock Bayesian nonparametric modeling for causal inference.
\newblock {\em Journal of Computational and Graphical Statistics},
  20(1):217--240, 2011.

\bibitem{wager2018estimation}
Stefan Wager and Susan Athey.
\newblock Estimation and inference of heterogeneous treatment effects using
  random forests.
\newblock {\em Journal of the American Statistical Association},
  113(523):1228--1242, 2018.

\bibitem{johansson2016learning}
Fredrik Johansson, Uri Shalit, and David Sontag.
\newblock Learning representations for counterfactual inference.
\newblock In {\em International conference on machine learning}, pages
  3020--3029, 2016.

\bibitem{shalit2017estimating}
Uri Shalit, Fredrik~D Johansson, and David Sontag.
\newblock Estimating individual treatment effect: generalization bounds and
  algorithms.
\newblock In {\em International Conference on Machine Learning}, pages
  3076--3085. PMLR, 2017.

\bibitem{yoon2018ganite}
Jinsung Yoon, James Jordon, and Mihaela van~der Schaar.
\newblock Ganite: Estimation of individualized treatment effects using
  generative adversarial nets.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{alaa2018limits}
Ahmed Alaa and Mihaela van~der Schaar.
\newblock Limits of estimating heterogeneous treatment effects: Guidelines for
  practical algorithm design.
\newblock In {\em International Conference on Machine Learning}, pages
  129--138, 2018.

\bibitem{kunzel2019metalearners}
S{\"o}ren~R K{\"u}nzel, Jasjeet~S Sekhon, Peter~J Bickel, and Bin Yu.
\newblock Metalearners for estimating heterogeneous treatment effects using
  machine learning.
\newblock {\em Proceedings of the national academy of sciences},
  116(10):4156--4165, 2019.

\bibitem{nie2017quasi}
Xinkun Nie and Stefan Wager.
\newblock Quasi-oracle estimation of heterogeneous treatment effects.
\newblock {\em arXiv preprint arXiv:1712.04912}, 2017.

\bibitem{rubin2005causal}
Donald~B Rubin.
\newblock Causal inference using potential outcomes: Design, modeling,
  decisions.
\newblock {\em Journal of the American Statistical Association},
  100(469):322--331, 2005.

\bibitem{holland1986statistics}
Paul~W Holland.
\newblock Statistics and causal inference.
\newblock {\em Journal of the American statistical Association},
  81(396):945--960, 1986.

\bibitem{johansson2018learning}
Fredrik~D Johansson, Nathan Kallus, Uri Shalit, and David Sontag.
\newblock Learning weighted representations for generalization across designs.
\newblock {\em arXiv preprint arXiv:1802.08598}, 2018.

\bibitem{hassanpour2019counterfactual}
Negar Hassanpour and Russell Greiner.
\newblock Counterfactual regression with importance sampling weights.
\newblock In {\em IJCAI}, pages 5880--5887, 2019.

\bibitem{hassanpour2020learning}
Negar Hassanpour and Russell Greiner.
\newblock Learning disentangled representations for counterfactual regression.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{assaad2020counterfactual}
Serge Assaad, Shuxi Zeng, Chenyang Tao, Shounak Datta, Nikhil Mehta, Ricardo
  Henao, Fan Li, and Lawrence~Carin Duke.
\newblock Counterfactual representation learning with balancing weights.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 1972--1980. PMLR, 2021.

\bibitem{alaa2017deep}
Ahmed~M Alaa, Michael Weisz, and Mihaela Van Der~Schaar.
\newblock Deep counterfactual networks with propensity-dropout.
\newblock {\em arXiv preprint arXiv:1706.05966}, 2017.

\bibitem{ballman2015biomarker}
Karla~V Ballman.
\newblock Biomarker: predictive or prognostic?
\newblock {\em Journal of clinical oncology: official journal of the American
  Society of Clinical Oncology}, 33(33):3968--3971, 2015.

\bibitem{sechidis2018distinguishing}
Konstantinos Sechidis, Konstantinos Papangelou, Paul~D Metcalfe, David
  Svensson, James Weatherall, and Gavin Brown.
\newblock Distinguishing prognostic and predictive biomarkers: an information
  theoretic approach.
\newblock {\em Bioinformatics}, 34(19):3365--3376, 2018.

\bibitem{kennedy2020optimal}
Edward~H Kennedy.
\newblock Optimal doubly robust estimation of heterogeneous causal effects.
\newblock {\em arXiv preprint arXiv:2004.14497}, 2020.

\bibitem{curth2020}
Alicia Curth and Mihaela Schaar.
\newblock Nonparametric estimation of heterogeneous treatment effects: From
  theory to learning algorithms.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 1810--1818. PMLR, 2021.

\bibitem{coston2020counterfactual}
Amanda Coston, Edward~H Kennedy, and Alexandra Chouldechova.
\newblock Counterfactual predictions under runtime confounding.
\newblock {\em Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem{pearl2009causality}
Judea Pearl.
\newblock {\em Causality}.
\newblock Cambridge university press, 2009.

\bibitem{shimodaira2000improving}
Hidetoshi Shimodaira.
\newblock Improving predictive inference under covariate shift by weighting the
  log-likelihood function.
\newblock {\em Journal of statistical planning and inference}, 90(2):227--244,
  2000.

\bibitem{stone1980optimal}
Charles~J Stone.
\newblock Optimal rates of convergence for nonparametric estimators.
\newblock {\em The annals of Statistics}, pages 1348--1360, 1980.

\bibitem{athey2019generalized}
Susan Athey, Julie Tibshirani, Stefan Wager, et~al.
\newblock Generalized random forests.
\newblock {\em The Annals of Statistics}, 47(2):1148--1178, 2019.

\bibitem{hahn2017bayesian}
P~Richard Hahn, Jared~S Murray, Carlos~M Carvalho, et~al.
\newblock Bayesian regression tree models for causal inference: Regularization,
  confounding, and heterogeneous effects (with discussion).
\newblock {\em Bayesian Analysis}, 15(3):965--1056, 2020.

\bibitem{alaa2017bayesian}
Ahmed~M Alaa and Mihaela van~der Schaar.
\newblock Bayesian inference of individualized treatment effects using
  multi-task gaussian processes.
\newblock {\em Advances in Neural Information Processing Systems},
  30:3424--3432, 2017.

\bibitem{shi2019adapting}
Claudia Shi, David Blei, and Victor Veitch.
\newblock Adapting neural networks for the estimation of treatment effects.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2507--2517, 2019.

\bibitem{hatt2021estimating}
Tobias Hatt and Stefan Feuerriegel.
\newblock Estimating average treatment effects via orthogonal regularization.
\newblock {\em arXiv preprint arXiv:2101.08490}, 2021.

\bibitem{caruana1997multitask}
Rich Caruana.
\newblock Multitask learning.
\newblock {\em Machine learning}, 28(1):41--75, 1997.

\bibitem{xuhong2018explicit}
LI~Xuhong, Yves Grandvalet, and Franck Davoine.
\newblock Explicit inductive bias for transfer learning with convolutional
  networks.
\newblock In {\em International Conference on Machine Learning}, pages
  2825--2834. PMLR, 2018.

\bibitem{daume2009frustratingly}
Hal Daum{\'e}~III.
\newblock Frustratingly easy domain adaptation.
\newblock {\em arXiv preprint arXiv:0907.1815}, 2009.

\bibitem{bousmalis2016domain}
Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman, Dilip Krishnan,
  and Dumitru Erhan.
\newblock Domain separation networks.
\newblock {\em arXiv preprint arXiv:1608.06019}, 2016.

\bibitem{evgeniou2005learning}
Theodoros Evgeniou, Charles~A Micchelli, Massimiliano Pontil, and John
  Shawe-Taylor.
\newblock Learning multiple tasks with kernel methods.
\newblock {\em Journal of machine learning research}, 6(4), 2005.

\bibitem{misra2016cross}
Ishan Misra, Abhinav Shrivastava, Abhinav Gupta, and Martial Hebert.
\newblock Cross-stitch networks for multi-task learning.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 3994--4003, 2016.

\bibitem{ruder2017learning}
Sebastian Ruder, Joachim Bingel, Isabelle Augenstein, and Anders S{\o}gaard.
\newblock Latent multi-task architecture learning.
\newblock 33(01):4822--4829, 2019.

\bibitem{haussler1988quantifying}
David Haussler.
\newblock Quantifying inductive bias: Ai learning algorithms and valiant's
  learning framework.
\newblock {\em Artificial intelligence}, 36(2):177--221, 1988.

\bibitem{imai2013estimating}
Kosuke Imai, Marc Ratkovic, et~al.
\newblock Estimating treatment effect heterogeneity in randomized program
  evaluation.
\newblock {\em The Annals of Applied Statistics}, 7(1):443--470, 2013.

\bibitem{salzmann2010factorized}
Mathieu Salzmann, Carl~Henrik Ek, Raquel Urtasun, and Trevor Darrell.
\newblock Factorized orthogonal latent spaces.
\newblock In {\em Proceedings of the Thirteenth International Conference on
  Artificial Intelligence and Statistics}, pages 701--708, 2010.

\bibitem{robinson1988root}
Peter~M Robinson.
\newblock Root-n-consistent semiparametric regression.
\newblock {\em Econometrica: Journal of the Econometric Society}, pages
  931--954, 1988.

\bibitem{chernozhukov2018double}
Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian
  Hansen, Whitney Newey, and James Robins.
\newblock Double/debiased machine learning for treatment and structural
  parameters.
\newblock {\em Econometrics Journal}, pages C1--C68, 2018.

\bibitem{wang2015generalization}
Xuezhi Wang and Jeff~G Schneider.
\newblock Generalization bounds for transfer learning under model shift.
\newblock In {\em UAI}, pages 922--931, 2015.

\bibitem{du2017hypothesis}
Simon~S Du, Jayanth Koushik, Aarti Singh, and Barnab{\'a}s P{\'o}czos.
\newblock Hypothesis transfer learning via transformation functions.
\newblock In {\em Advances in neural information processing systems}, pages
  574--584, 2017.

\bibitem{baxter2000model}
Jonathan Baxter.
\newblock A model of inductive bias learning.
\newblock {\em Journal of artificial intelligence research}, 12:149--198, 2000.

\bibitem{maurer2016benefit}
Andreas Maurer, Massimiliano Pontil, and Bernardino Romera-Paredes.
\newblock The benefit of multitask representation learning.
\newblock {\em Journal of Machine Learning Research}, 17(81):1--32, 2016.

\bibitem{dorie2019automated}
Vincent Dorie, Jennifer Hill, Uri Shalit, Marc Scott, Dan Cervone, et~al.
\newblock Automated versus do-it-yourself methods for causal inference: Lessons
  learned from a data analysis competition.
\newblock {\em Statistical Science}, 34(1):43--68, 2019.

\bibitem{horvitz1952generalization}
Daniel~G Horvitz and Donovan~J Thompson.
\newblock A generalization of sampling without replacement from a finite
  universe.
\newblock {\em Journal of the American statistical Association},
  47(260):663--685, 1952.

\bibitem{robins1995semiparametric}
James~M Robins and Andrea Rotnitzky.
\newblock Semiparametric efficiency in multivariate regression models with
  missing data.
\newblock {\em Journal of the American Statistical Association},
  90(429):122--129, 1995.

\bibitem{foster2019orthogonal}
Dylan~J Foster and Vasilis Syrgkanis.
\newblock Orthogonal statistical learning.
\newblock {\em arXiv preprint arXiv:1901.09036}, 2019.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock In {\em International Conference on Learning Representations}, 2015.

\bibitem{jax2018github}
James Bradbury, Roy Frostig, Peter Hawkins, Matthew~James Johnson, Chris Leary,
  Dougal Maclaurin, George Necula, Adam Paszke, Jake Vander{P}las, Skye
  Wanderman-{M}ilne, and Qiao Zhang.
\newblock {JAX}: composable transformations of {P}ython+{N}um{P}y programs,
  2018.

\bibitem{louizos2017causal}
Christos Louizos, Uri Shalit, Joris~M Mooij, David Sontag, Richard Zemel, and
  Max Welling.
\newblock Causal effect inference with deep latent-variable models.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6446--6456, 2017.

\bibitem{almond2005costs}
Douglas Almond, Kenneth~Y Chay, and David~S Lee.
\newblock The costs of low birth weight.
\newblock {\em The Quarterly Journal of Economics}, 120(3):1031--1083, 2005.

\end{thebibliography}
