\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2017)Agarwal, Allen-Zhu, Bullins, Hazan, and
  Ma]{agarwal2017finding}
Naman Agarwal, Zeyuan Allen-Zhu, Brian Bullins, Elad Hazan, and Tengyu Ma.
\newblock Finding approximate local minima faster than gradient descent.
\newblock In \emph{Proceedings of the 49th Annual ACM SIGACT Symposium on
  Theory of Computing}, pages 1195--1199, 2017.

\bibitem[Amini and Gallinari(2003)]{amini2003semisupervised}
M.~Amini and P.~Gallinari.
\newblock Semi-supervised learning with explicit misclassification modeling.
\newblock In \emph{International Joint Conference on Artificial Intelligence
  (IJCAI)}, 2003.

\bibitem[Arjovsky et~al.(2019)Arjovsky, Bottou, Gulrajani, and Lopez-Paz]{IRM}
Martin Arjovsky, Léon Bottou, Ishaan Gulrajani, and David Lopez-Paz.
\newblock Invariant risk minimization, 2019.

\bibitem[Balcan and Blum(2010)]{balcan2010discriminative}
Maria-Florina Balcan and Avrim Blum.
\newblock A discriminative model for semi-supervised learning.
\newblock \emph{Journal of the ACM (JACM)}, 57\penalty0 (3):\penalty0 1--46,
  2010.

\bibitem[Ben-David et~al.(2008)Ben-David, Lu, and Pal]{shai2008unlabeled}
S.~Ben-David, T.~Lu, and D.~Pal.
\newblock Does unlabeled data provably help? worst-case analysis of the sample
  complexity of semi-supervised learning.
\newblock In \emph{Conference on Learning Theory (COLT)}, 2008.

\bibitem[Ben-David et~al.(2010)Ben-David, Blitzer, Crammer, Kulesza, Pereira,
  and Vaughan]{ben2010theory}
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and
  Jennifer~Wortman Vaughan.
\newblock A theory of learning from different domains.
\newblock \emph{Machine learning}, 79\penalty0 (1-2):\penalty0 151--175, 2010.

\bibitem[Berthelot et~al.(2020)Berthelot, Carlini, Cubuk, Kurakin, Sohn, Zhang,
  and Raffel]{berthelot2020remixmatch}
David Berthelot, Nicholas Carlini, Ekin~D. Cubuk, Alex Kurakin, Kihyuk Sohn,
  Han Zhang, and Colin Raffel.
\newblock Remixmatch: Semi-supervised learning with distribution matching and
  augmentation anchoring.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Blum and Mitchell(1998)]{blum98cotraining}
A.~Blum and T.~Mitchell.
\newblock Combining labeled and unlabeled data with co-training.
\newblock In \emph{Conference on Learning Theory (COLT)}, 1998.

\bibitem[Carmon et~al.(2019)Carmon, Raghunathan, Schmidt, Liang, and
  Duchi]{carmon2019unlabeled}
Y.~Carmon, A.~Raghunathan, L.~Schmidt, P.~Liang, and J.~C. Duchi.
\newblock Unlabeled data improves adversarial robustness.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2019.

\bibitem[Ganin and Lempitsky(2015)]{ganin2015domain}
Y.~Ganin and V.~Lempitsky.
\newblock Unsupervised domain adaptation by backpropagation.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pages
  1180--1189, 2015.

\bibitem[Ge et~al.(2015)Ge, Huang, Jin, and Yuan]{ge2015escaping}
Rong Ge, Furong Huang, Chi Jin, and Yang Yuan.
\newblock Escaping from saddle points—online stochastic gradient for tensor
  decomposition.
\newblock In \emph{Conference on Learning Theory}, pages 797--842, 2015.

\bibitem[Gong et~al.(2012)Gong, Sha, and Grauman]{Gong12overcomingdataset}
Boqing Gong, Fei Sha, and Kristen Grauman.
\newblock Overcoming dataset bias: An unsupervised domain adaptation approach.
\newblock In \emph{In NIPS Workshop on Large Scale Visual Recognition and
  Retrieval}, 2012.

\bibitem[Grandvalet and Bengio(2005)]{grandvalet05entropy}
Y.~Grandvalet and Y.~Bengio.
\newblock Entropy regularization.
\newblock In \emph{Semi-Supervised Learning}, 2005.

\bibitem[Gururangan et~al.(2018)Gururangan, Swayamdipta, Levy, Schwartz,
  Bowman, and Smith]{gururangan-etal-2018-annotation}
Suchin Gururangan, Swabha Swayamdipta, Omer Levy, Roy Schwartz, Samuel Bowman,
  and Noah~A. Smith.
\newblock Annotation artifacts in natural language inference data.
\newblock In \emph{Proceedings of the 2018 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 2 (Short Papers)}, pages 107--112, June 2018.

\bibitem[Heinze-Deml and Meinshausen(2017)]{heinze2017conditional}
C.~Heinze-Deml and N.~Meinshausen.
\newblock Conditional variance penalties and domain shift robustness.
\newblock \emph{arXiv preprint arXiv:1710.11469}, 2017.

\bibitem[Ilyas et~al.(2019)Ilyas, Santurkar, Tsipras, Engstrom, Tran, and
  Madry]{ilyas2019adversarial}
A.~Ilyas, S.~Santurkar, D.~Tsipras, L.~Engstrom, B.~Tran, and A.~Madry.
\newblock Adversarial examples are not bugs, they are features.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2019.

\bibitem[Jiayuan et~al.(2006)Jiayuan, J., Arthur, M., and
  Bernhard]{huang2006correcting}
H.~Jiayuan, S.~A. J., G.~Arthur, B.~K. M., and S.~Bernhard.
\newblock Correcting sample selection bias by unlabeled data.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2006.

\bibitem[Kim et~al.(2019)Kim, Kim, Kim, Kim, and Kim]{kim2019learning}
Byungju Kim, Hyunwoo Kim, Kyungsu Kim, Sungjin Kim, and Junmo Kim.
\newblock Learning not to learn: Training deep neural networks with biased
  data.
\newblock In \emph{Computer Vision and Pattern Recognition (CVPR)}, 2019.

\bibitem[Kumar et~al.(2020)Kumar, Ma, and Liang]{kumar2020gradual}
A.~Kumar, T.~Ma, and P.~Liang.
\newblock Understanding self-training for gradual domain adaptation.
\newblock \emph{arXiv preprint arXiv:2002.11361}, 2020.

\bibitem[LeCun et~al.(2010)LeCun, Cortes, and Burges]{MNIST}
Yann LeCun, Corinna Cortes, and CJ~Burges.
\newblock Mnist handwritten digit database.
\newblock \emph{ATT Labs [Online]. Available: http://yann. lecun.
  com/exdb/mnist}, 2, 2010.

\bibitem[Lee(2013)]{lee2013pseudo}
D.~Lee.
\newblock Pseudo-label: The simple and efficient semi-supervised learning
  method for deep neural networks.
\newblock In \emph{International Conference on Machine Learning (ICML)
  Workshop}, 2013.

\bibitem[Liu et~al.(2015)Liu, Luo, Wang, and Tang]{liu2015faceattributes}
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.
\newblock Deep learning face attributes in the wild.
\newblock In \emph{Proceedings of International Conference on Computer Vision
  (ICCV)}, December 2015.

\bibitem[Long et~al.(2013)Long, Wang, Ding, Sun, and Yu]{long2013transfer}
M.~Long, J.~Wang, G.~Ding, J.~Sun, and P.~S. Yu.
\newblock Transfer feature learning with joint distribution adaptation.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 2200--2207, 2013.

\bibitem[McCoy et~al.(2019)McCoy, Pavlick, and Linzen]{mccoy-etal-2019-right}
Tom McCoy, Ellie Pavlick, and Tal Linzen.
\newblock Right for the wrong reasons: Diagnosing syntactic heuristics in
  natural language inference.
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, pages 3428--3448, July 2019.

\bibitem[Miyato et~al.(2018)Miyato, Maeda, Koyama, and
  Ishii]{miyato2018virtual}
Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii.
\newblock Virtual adversarial training: a regularization method for supervised
  and semi-supervised learning.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 41\penalty0 (8):\penalty0 1979--1993, 2018.

\bibitem[Nesterov and Polyak(2006)]{nesterov2006cubic}
Yurii Nesterov and Boris~T Polyak.
\newblock Cubic regularization of newton method and its global performance.
\newblock \emph{Mathematical Programming}, 108\penalty0 (1):\penalty0 177--205,
  2006.

\bibitem[Peters et~al.(2015)Peters, Bühlmann, and
  Meinshausen]{peters2015causal}
Jonas Peters, Peter Bühlmann, and Nicolai Meinshausen.
\newblock Causal inference using invariant prediction: identification and
  confidence intervals, 2015.

\bibitem[Rigollet(2007)]{rigollet2007generalization}
P.~Rigollet.
\newblock Generalization error bounds in semi-supervised classification under
  the cluster assumption.
\newblock \emph{Journal of Machine Learning Research (JMLR)}, 8:\penalty0
  1369--1392, 2007.

\bibitem[Sagawa et~al.(2020)Sagawa, Raghunathan, Koh, and
  Liang]{sagawa2020investigation}
Shiori Sagawa, Aditi Raghunathan, Pang~Wei Koh, and Percy Liang.
\newblock An investigation of why overparameterization exacerbates spurious
  correlations.
\newblock \emph{ArXiv}, abs/2005.04345, 2020.

\bibitem[Schmidt et~al.(2018)Schmidt, Santurkar, Tsipras, Talwar, and
  Madry]{schmidt2018adversarially}
Ludwig Schmidt, Shibani Santurkar, Dimitris Tsipras, Kunal Talwar, and
  Aleksander Madry.
\newblock Adversarially robust generalization requires more data.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  5014--5026, 2018.

\bibitem[Shimodaira(2000)]{shimodaira2000improving}
H.~Shimodaira.
\newblock Improving predictive inference under covariate shift by weighting the
  log-likelihood function.
\newblock \emph{Journal of Statistical Planning and Inference}, 90:\penalty0
  227--244, 2000.

\bibitem[Shu et~al.(2018)Shu, Bui, Narui, and Ermon]{shu2018dirtt}
R.~Shu, H.~H. Bui, H.~Narui, and S.~Ermon.
\newblock A {DIRT}-{T} approach to unsupervised domain adaptation.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Singh et~al.(2008)Singh, Nowak, and Zhu]{singh2008unlabeled}
A.~Singh, R.~Nowak, and J.~Zhu.
\newblock Unlabeled data: Now it helps, now it doesn't.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2008.

\bibitem[Sohn et~al.(2020)Sohn, Berthelot, Li, Zhang, Carlini, Cubuk, Kurakin,
  Zhang, and Raffel]{sohn2020fixmatch}
K.~Sohn, D.~Berthelot, C.~Li, Z.~Zhang, N.~Carlini, E.~D. Cubuk, A.~Kurakin,
  H.~Zhang, and C.~Raffel.
\newblock Fixmatch: Simplifying semi-supervised learning with consistency and
  confidence.
\newblock \emph{arXiv}, 2020.

\bibitem[Soudry et~al.(2018)Soudry, Hoffer, and Srebro]{soudry2018the}
Daniel Soudry, Elad Hoffer, and Nathan Srebro.
\newblock The implicit bias of gradient descent on separable data.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Sugiyama et~al.(2007)Sugiyama, Krauledat, and
  Muller]{sugiyama2007covariate}
M.~Sugiyama, M.~Krauledat, and K.~Muller.
\newblock Covariate shift adaptation by importance weighted cross validation.
\newblock \emph{Journal of Machine Learning Research (JMLR)}, 8:\penalty0
  985--1005, 2007.

\bibitem[Tommasi et~al.(2015)Tommasi, Patricia, Caputo, and
  Tuytelaars]{Tommasi2017}
Tatiana Tommasi, Novi Patricia, Barbara Caputo, and Tinne Tuytelaars.
\newblock A deeper look at dataset bias.
\newblock In \emph{GCPR}, 2015.

\bibitem[Tsipras et~al.(2018)Tsipras, Santurkar, Engstrom, Turner, and
  Madry]{tsipras2018robustness}
Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, and
  Aleksander Madry.
\newblock Robustness may be at odds with accuracy.
\newblock \emph{arXiv preprint arXiv:1805.12152}, 2018.

\bibitem[Tzeng et~al.(2014)Tzeng, Hoffman, Zhang, Saenko, and
  Darrell]{tzeng2014domain}
E.~Tzeng, J.~Hoffman, N.~Zhang, K.~Saenko, and T.~Darrell.
\newblock Deep domain confusion: Maximizing for domain invariance.
\newblock \emph{arXiv preprint arXiv:1412.3474}, 2014.

\bibitem[Tzeng et~al.(2017)Tzeng, Hoffman, Saenko, and
  Darrell]{tzeng2017domain}
E.~Tzeng, J.~Hoffman, K.~Saenko, and T.~Darrell.
\newblock Adversarial discriminative domain adaptation.
\newblock In \emph{Computer Vision and Pattern Recognition (CVPR)}, 2017.

\bibitem[Uesato et~al.(2019)Uesato, Alayrac, Huang, Stanforth, Fawzi, and
  Kohli]{uesato2019are}
J.~Uesato, J.~Alayrac, P.~Huang, R.~Stanforth, A.~Fawzi, and P.~Kohli.
\newblock Are labels required for improving adversarial robustness?
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2019.

\bibitem[Vershynin(2018)]{vershynin2018high}
Roman Vershynin.
\newblock \emph{High-Dimensional Probability}.
\newblock Cambridge University Press, 2018.

\bibitem[Wang et~al.(2019)Wang, He, Lipton, and Xing]{wang2019learning}
Haohan Wang, Zexue He, Zachary~C. Lipton, and Eric~P. Xing.
\newblock Learning robust representations by projecting superficial statistics
  out.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2019.

\bibitem[Weisstein(2020)]{wolfram}
Eric~W. Weisstein.
\newblock \emph{Erfc. From MathWorld--A Wolfram Web Resource.}, 2020.
\newblock \url{http://mathworld.wolfram.com/Erfc.html}.

\bibitem[Xie et~al.(2020)Xie, Luong, Hovy, and Le]{xie2020selftraining}
Q.~Xie, M.~Luong, E.~Hovy, and Q.~V. Le.
\newblock Self-training with noisy student improves imagenet classification.
\newblock \emph{arXiv}, 2020.

\bibitem[Zhang et~al.(2019)Zhang, Liu, Long, and Jordan]{zhang2019bridging}
Yuchen Zhang, Tianle Liu, Mingsheng Long, and Michael~I Jordan.
\newblock Bridging theory and algorithm for domain adaptation.
\newblock \emph{arXiv preprint arXiv:1904.05801}, 2019.

\bibitem[Zou et~al.(2019)Zou, Yu, Liu, Kumar, and Wang]{zou2019confidence}
Y.~Zou, Z.~Yu, X.~Liu, B.~Kumar, and J.~Wang.
\newblock Confidence regularized self-training.
\newblock \emph{arXiv preprint arXiv:1908.09822}, 2019.

\end{thebibliography}
