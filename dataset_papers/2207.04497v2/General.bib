%% ATTACK
% L0 inv L2 inv
@article{li2019L0L2inv,
  title={Invisible backdoor attacks against deep neural networks},
  author={Li, Shaofeng and Zhao, Benjamin Zi Hao and Yu, Jiahao and Xue, Minhui and Kaafar, Dali and Zhu, Haojin},
  journal={arXiv preprint arXiv:1909.02742},
  year={2019}
}

% Inv sample-specific
@inproceedings{li2021invisible,
  title={Invisible backdoor attack with sample-specific triggers},
  author={Li, Yuezun and Li, Yiming and Wu, Baoyuan and Li, Longkang and He, Ran and Lyu, Siwei},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={16463--16472},
  year={2021}
}

% Trojan
@inproceedings{liu2017trojanatk,
  author    = {Yingqi Liu and
               Shiqing Ma and
               Yousra Aafer and
               Wen-Chuan Lee and
               Juan Zhai and
               Weihang Wang and
               Xiangyu Zhang},
  title     = {Trojaning Attack on Neural Networks},
  booktitle = {25th Annual Network and Distributed System Security Symposium, {NDSS}
               2018, San Diego, California, USA, February 18-221, 2018},
  publisher = {The Internet Society},
  year      = {2018},
}

% Badnets
@article{gu2017badnets,
  title={Badnets: Identifying vulnerabilities in the machine learning model supply chain},
  author={Gu, Tianyu and Dolan-Gavitt, Brendan and Garg, Siddharth},
  journal={arXiv preprint arXiv:1708.06733},
  year={2017}
}

% Natural
@inproceedings{liu2020naturalatk,
  title={Reflection backdoor: A natural backdoor attack on deep neural networks},
  author={Liu, Yunfei and Ma, Xingjun and Bailey, James and Lu, Feng},
  booktitle={European Conference on Computer Vision},
  pages={182--199},
  year={2020},
  organization={Springer}
}

% Dynamic
@article{nguyen2020dynamicatk,
  title={Input-aware dynamic backdoor attack},
  author={Nguyen, Tuan Anh and Tran, Anh},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3454--3464},
  year={2020}
}

@inproceedings{nguyen2021wanet,
title={WaNet - Imperceptible Warping-based Backdoor Attack},
author={Tuan Anh Nguyen and Anh Tuan Tran},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=eEn8KTtJOx}
}

% Blend
@article{chen2017blend,
  title={Targeted backdoor attacks on deep learning systems using data poisoning},
  author={Chen, Xinyun and Liu, Chang and Li, Bo and Lu, Kimberly and Song, Dawn},
  journal={arXiv preprint arXiv:1712.05526},
  year={2017}
}

% Clean-label atk
@article{shafahi2018clean,
  title={Poison frogs! targeted clean-label poisoning attacks on neural networks},
  author={Shafahi, Ali and Huang, W Ronny and Najibi, Mahyar and Suciu, Octavian and Studer, Christoph and Dumitras, Tudor and Goldstein, Tom},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

% Clean-label atk
@inproceedings{barni2019clean,
  title={A new backdoor attack in cnns by training set corruption without label poisoning},
  author={Barni, Mauro and Kallas, Kassem and Tondi, Benedetta},
  booktitle={2019 IEEE International Conference on Image Processing (ICIP)},
  pages={101--105},
  year={2019},
  organization={IEEE}
}

% CLB
@article{turner2019clb,
  title={Label-consistent backdoor attacks},
  author={Turner, Alexander and Tsipras, Dimitris and Madry, Aleksander},
  journal={arXiv preprint arXiv:1912.02771},
  year={2019}
}

% more examples on visible attack
@inproceedings{shokri2020bypassing,
  title={Bypassing backdoor detection algorithms in deep learning},
  author={Shokri, Reza and others},
  booktitle={2020 IEEE European Symposium on Security and Privacy (EuroS\&P)},
  pages={175--183},
  year={2020},
  organization={IEEE}
}

@inproceedings{lin2020composite,
  title={Composite backdoor attack for deep neural network by mixing existing benign features},
  author={Lin, Junyu and Xu, Lei and Liu, Yingqi and Zhang, Xiangyu},
  booktitle={Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security},
  pages={113--131},
  year={2020}
}



%% DEFENSE
% ANP
@article{wu2021ANP,
  title={Adversarial neuron pruning purifies backdoored deep models},
  author={Wu, Dongxian and Wang, Yisen},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

% IBAU
@article{zeng2021IBAU,
  title={Adversarial Unlearning of Backdoors via Implicit Hypergradient},
  author={Zeng, Yi and Chen, Si and Park, Won and Mao, Z Morley and Jin, Ming and Jia, Ruoxi},
  journal={arXiv preprint arXiv:2110.03735},
  year={2021}
}

% Neural Cleanse
@inproceedings{wang2019NC,
  title={Neural cleanse: Identifying and mitigating backdoor attacks in neural networks},
  author={Wang, Bolun and Yao, Yuanshun and Shan, Shawn and Li, Huiying and Viswanath, Bimal and Zheng, Haitao and Zhao, Ben Y},
  booktitle={2019 IEEE Symposium on Security and Privacy (SP)},
  pages={707--723},
  year={2019},
  organization={IEEE}
}

% Be asked to discuss the sparsity constraint
@inproceedings{tao2022better_sparse,
  title={Better Trigger Inversion Optimization in Backdoor Scanning},
  author={Tao, Guanhong and Shen, Guangyu and Liu, Yingqi and An, Shengwei and Xu, Qiuling and Ma, Shiqing and Li, Pan and Zhang, Xiangyu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13368--13378},
  year={2022}
}

% NAD (IBAU inspiration)
@inproceedings{li2020NAD,
  title={Neural Attention Distillation: Erasing Backdoor Triggers from Deep Neural Networks},
  author={Li, Yige and Lyu, Xixiang and Koren, Nodens and Lyu, Lingjuan and Li, Bo and Ma, Xingjun},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

% TABOR
@article{guo2019tabor,
  title={Tabor: A highly accurate approach to inspecting and restoring trojan backdoors in ai systems},
  author={Guo, Wenbo and Wang, Lun and Xing, Xinyu and Du, Min and Song, Dawn},
  journal={arXiv preprint arXiv:1908.01763},
  year={2019}
}

%REFIT
@inproceedings{chen2021refit,
  title={Refit: a unified watermark removal framework for deep learning systems with limited data},
  author={Chen, Xinyun and Wang, Wenxiao and Bender, Chris and Ding, Yiming and Jia, Ruoxi and Li, Bo and Song, Dawn},
  booktitle={Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security},
  pages={321--335},
  year={2021}
}

% got three more
% nonrecover (ibau same author)
@inproceedings{qiu2021deepsweep,
  title={Deepsweep: An evaluation framework for mitigating dnn backdoor attacks using data augmentation},
  author={Qiu, Han and Zeng, Yi and Guo, Shangwei and Zhang, Tianwei and Qiu, Meikang and Thuraisingham, Bhavani},
  booktitle={Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security},
  pages={363--377},
  year={2021}
}

% fine-pruning
@inproceedings{liu2018finepruning,
  title={Fine-pruning: Defending against backdooring attacks on deep neural networks},
  author={Liu, Kang and Dolan-Gavitt, Brendan and Garg, Siddharth},
  booktitle={International Symposium on Research in Attacks, Intrusions, and Defenses},
  pages={273--294},
  year={2018},
  organization={Springer}
}

% DP FINETUNING
@article{weber2020rab,
  title={Rab: Provable robustness against backdoor attacks},
  author={Weber, Maurice and Xu, Xiaojun and Karla{\v{s}}, Bojan and Zhang, Ce and Li, Bo},
  journal={arXiv preprint arXiv:2003.08904},
  year={2020}
}

% ENSEMBIED MODAL (NAD same type)
@article{jia2020certified,
  title={Certified robustness of nearest neighbors against data poisoning attacks},
  author={Jia, Jinyuan and Cao, Xiaoyu and Gong, Neil Zhenqiang},
  journal={arXiv preprint arXiv:2012.03765},
  year={2020}
}

% another wildchiken
@article{xu2020defending,
  title={Defending against backdoor attack on deep neural networks},
  author={Xu, Kaidi and Liu, Sijia and Chen, Pin-Yu and Zhao, Pu and Lin, Xue},
  journal={arXiv preprint arXiv:2002.12162},
  year={2020}
}

% detect poisoned data (before training)
@article{steinhardt2017certified,
  title={Certified defenses for data poisoning attacks},
  author={Steinhardt, Jacob and Koh, Pang Wei W and Liang, Percy S},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{ma2019nic,
  title={Nic: Detecting adversarial samples with neural network invariant checking},
  author={Ma, Shiqing and Liu, Yingqi},
  booktitle={Proceedings of the 26th network and distributed system security symposium (NDSS 2019)},
  year={2019}
}

@article{gao2020generative,
  title={Generative Adversarial Nets for Robust Scatter Estimation: A Proper Scoring Rule Perspective.},
  author={Gao, Chao and Yao, Yuan and Zhu, Weizhi},
  journal={J. Mach. Learn. Res.},
  volume={21},
  pages={160--1},
  year={2020}
}

@inproceedings{diakonikolas2019sever,
  title={Sever: A robust meta-algorithm for stochastic optimization},
  author={Diakonikolas, Ilias and Kamath, Gautam and Kane, Daniel and Li, Jerry and Steinhardt, Jacob and Stewart, Alistair},
  booktitle={International Conference on Machine Learning},
  pages={1596--1606},
  year={2019},
  organization={PMLR}
}

% detect poisoned model (after training)
@inproceedings{wang2020practical,
  title={Practical detection of trojan neural networks: Data-limited and data-free cases},
  author={Wang, Ren and Zhang, Gaoyuan and Liu, Sijia and Chen, Pin-Yu and Xiong, Jinjun and Wang, Meng},
  booktitle={European Conference on Computer Vision},
  pages={222--238},
  year={2020},
  organization={Springer}
}

@inproceedings{xu2021detecting,
  title={Detecting ai trojans using meta neural analysis},
  author={Xu, Xiaojun and Wang, Qi and Li, Huichen and Borisov, Nikita and Gunter, Carl A and Li, Bo},
  booktitle={2021 IEEE Symposium on Security and Privacy (SP)},
  pages={103--120},
  year={2021},
  organization={IEEE}
}

@inproceedings{shokri2017MIA,
  title={Membership inference attacks against machine learning models},
  author={Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  booktitle={2017 IEEE symposium on security and privacy (SP)},
  pages={3--18},
  year={2017},
  organization={IEEE}
}

@inproceedings{ilyas2018black,
  title={Black-box adversarial attacks with limited queries and information},
  author={Ilyas, Andrew and Engstrom, Logan and Athalye, Anish and Lin, Jessy},
  booktitle={International Conference on Machine Learning},
  pages={2137--2146},
  year={2018},
  organization={PMLR}
}

@inproceedings{chen2020frank,
  title={A Frank-Wolfe Framework for Efficient and Effective Adversarial Attacks},
  author={Chen, Jinghui and Zhou, Dongruo and Yi, Jinfeng and Gu, Quanquan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2020}
}

@article{huang2020metapoison,
  title={Metapoison: Practical general-purpose clean-label data poisoning},
  author={Huang, W Ronny and Geiping, Jonas and Fowl, Liam and Taylor, Gavin and Goldstein, Tom},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={12080--12091},
  year={2020}
}

% Model Inversion Attack
@inproceedings{fredrikson2015attack,
  title={Model inversion attacks that exploit confidence information and basic countermeasures},
  author={Fredrikson, Matt and Jha, Somesh and Ristenpart, Thomas},
  booktitle={Proceedings of the 22nd ACM SIGSAC conference on computer and communications security},
  pages={1322--1333},
  year={2015}
}

% Rays
@inproceedings{chen2020rays,
  title={Rays: A ray searching method for hard-label adversarial attack},
  author={Chen, Jinghui and Gu, Quanquan},
  booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={1739--1747},
  year={2020}
}

%% other Training-time attack
@article{feng2019learning,
  title={Learning to confuse: generating training time adversarial data with auto-encoder},
  author={Feng, Ji and Cai, Qi-Zhi and Zhou, Zhi-Hua},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{rakhsha2020policy,
  title={Policy teaching via environment poisoning: Training-time adversarial attacks against reinforcement learning},
  author={Rakhsha, Amin and Radanovic, Goran and Devidze, Rati and Zhu, Xiaojin and Singla, Adish},
  booktitle={International Conference on Machine Learning},
  pages={7974--7984},
  year={2020},
  organization={PMLR}
}

@article{ilyas2019featuresnotbugs,
  title={Adversarial examples are not bugs, they are features},
  author={Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{goodfellow2014explainingAE,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

%% Adversarial Training
@article{vorobeychik2018AML,
  title={Adversarial machine learning},
  author={Vorobeychik, Yevgeniy and Kantarcioglu, Murat},
  journal={Synthesis Lectures on Artificial Intelligence and Machine Learning},
  volume={12},
  number={3},
  pages={1--169},
  year={2018},
  publisher={Morgan \& Claypool Publishers}
}

@inproceedings{huang2011AML,
  title={Adversarial machine learning},
  author={Huang, Ling and Joseph, Anthony D and Nelson, Blaine and Rubinstein, Benjamin IP and Tygar, J Doug},
  booktitle={Proceedings of the 4th ACM workshop on Security and artificial intelligence},
  pages={43--58},
  year={2011}
}

@inproceedings{madry2018resistAdAtk,
  title={Towards Deep Learning Models Resistant to Adversarial Attacks},
  author={Aleksander Madry and Aleksandar Makelov and Ludwig Schmidt and Dimitris Tsipras and Adrian Vladu},
  booktitle={International Conference on Learning Representations},
year={2018},
  url={https://openreview.net/forum?id=rJzIBfZAb},
}

@inproceedings{peng2022learnability,
  title={Learnability Lock: Authorized Learnability Control Through Adversarial Invertible Transformations},
  author={Weiqi Peng and Jinghui Chen},
  booktitle={International Conference on Learning Representations},
year={2022},
  url={https://openreview.net/forum?id=6VpeS27viTq}
}

% PGD-Tuning
@inproceedings{croce2020reliable,
  title={Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks},
  author={Croce, Francesco and Hein, Matthias},
  booktitle={International conference on machine learning},
  pages={2206--2216},
  year={2020},
  organization={PMLR}
}

@article{tramer2017ensemble,
  title={Ensemble adversarial training: Attacks and defenses},
  author={Tram{\`e}r, Florian and Kurakin, Alexey and Papernot, Nicolas and Goodfellow, Ian and Boneh, Dan and McDaniel, Patrick},
  journal={arXiv preprint arXiv:1705.07204},
  year={2017}
}

@article{wu2021wider,
  title={Do Wider Neural Networks Really Help Adversarial Robustness?},
  author={Wu, Boxi and Chen, Jinghui and Cai, Deng and He, Xiaofei and Gu, Quanquan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{allen2022feature,
  title={Feature purification: How adversarial training performs robust deep learning},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  booktitle={2021 IEEE 62nd Annual Symposium on Foundations of Computer Science (FOCS)},
  pages={977--988},
  year={2022},
  organization={IEEE}
}

@inproceedings{zhang2020notkill,
  title={Attacks which do not kill training make adversarial learning stronger},
  author={Zhang, Jingfeng and Xu, Xilie and Han, Bo and Niu, Gang and Cui, Lizhen and Sugiyama, Masashi and Kankanhalli, Mohan},
  booktitle={International conference on machine learning},
  pages={11278--11287},
  year={2020},
  organization={PMLR}
}

@inproceedings{zhang2019theoretically,
  title={Theoretically principled trade-off between robustness and accuracy},
  author={Zhang, Hongyang and Yu, Yaodong and Jiao, Jiantao and Xing, Eric and El Ghaoui, Laurent and Jordan, Michael},
  booktitle={International conference on machine learning},
  pages={7472--7482},
  year={2019},
  organization={PMLR}
}

@article{krizhevsky2009cifar10,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Citeseer}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{
Wong2020Fast,
title={Fast is better than free: Revisiting adversarial training},
author={Eric Wong and Leslie Rice and J. Zico Kolter},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=BJx040EFvH}
}

@article{shafahi2019adversarial,
  title={Adversarial training for free!},
  author={Shafahi, Ali and Najibi, Mahyar and Ghiasi, Mohammad Amin and Xu, Zheng and Dickerson, John and Studer, Christoph and Davis, Larry S and Taylor, Gavin and Goldstein, Tom},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{chen2022efficient,
  title={Efficient robust training via backward smoothing},
  author={Chen, Jinghui and Cheng, Yu and Gan, Zhe and Gu, Quanquan and Liu, Jingjing},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)},
  year={2022}
}

% GTSRB
@inproceedings{Houben2013GTSRB,
  title={Detection of traffic signs in real-world images: The German Traffic Sign Detection Benchmark},
  author={Houben, Sebastian and Stallkamp, Johannes and Salmen, Jan and Schlipsing, Marc and Igel, Christian},
  booktitle={The 2013 international joint conference on neural networks (IJCNN)},
  pages={1--8},
  year={2013},
  organization={Ieee}
}

% Resnet-18
@inproceedings{he2016resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

% VGG
@article{simonyan2014vgg,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

% shufflenet
@inproceedings{zhang2018shufflenet,
  title={Shufflenet: An extremely efficient convolutional neural network for mobile devices},
  author={Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6848--6856},
  year={2018}
}

% shufflenet v2
@inproceedings{ma2018shufflenetv2,
  title={Shufflenet v2: Practical guidelines for efficient cnn architecture design},
  author={Ma, Ningning and Zhang, Xiangyu and Zheng, Hai-Tao and Sun, Jian},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={116--131},
  year={2018}
}

% mobilenet
@article{howard2017mobilenets,
  title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
  author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  journal={arXiv preprint arXiv:1704.04861},
  year={2017}
}

% mobilenet v2
@inproceedings{howard2018mobilnetsv2,
  author = {Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  title = {MobileNetV2: Inverted Residuals and Linear Bottlenecks},
  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2018}
}

% BatchNorm
@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={PMLR}
}

%Pytorch
@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

%% CNN APPLICATIONS
@inproceedings{he2016APPrecog,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{devlin2018APPbert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{szegedy2013APPobject,
  title={Deep neural networks for object detection},
  author={Szegedy, Christian and Toshev, Alexander and Erhan, Dumitru},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}

@article{hinton2012speech,
  title={Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups},
  author={Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N and others},
  journal={IEEE Signal processing magazine},
  volume={29},
  number={6},
  pages={82--97},
  year={2012},
  publisher={IEEE}
}

@article{zhao2019object,
  title={Object detection with deep learning: A review},
  author={Zhao, Zhong-Qiu and Zheng, Peng and Xu, Shou-tao and Wu, Xindong},
  journal={IEEE transactions on neural networks and learning systems},
  volume={30},
  number={11},
  pages={3212--3232},
  year={2019},
  publisher={IEEE}
}

%% Fine-tuning


%% Distillation
@article{gou2021knowledgedistill,
  title={Knowledge distillation: A survey},
  author={Gou, Jianping and Yu, Baosheng and Maybank, Stephen J and Tao, Dacheng},
  journal={International Journal of Computer Vision},
  volume={129},
  number={6},
  pages={1789--1819},
  year={2021},
  publisher={Springer}
}