\begin{thebibliography}{46}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Fun(2018)]{Fungi}
2018 fgcvx fungi classification challenge, 2018.
\newblock URL \url{https://www.kaggle.com/c/fungi-challenge-fgvc-2018}.

\bibitem[Abadi et~al.(2016)Abadi, Barham, Chen, Chen, Davis, Dean, Devin,
  Ghemawat, Irving, Isard, et~al.]{abadi2016tensorflow}
Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M.,
  Ghemawat, S., Irving, G., Isard, M., et~al.
\newblock Tensorflow: a system for large-scale machine learning.
\newblock In \emph{OSDI}, volume~16, pp.\  265--283, 2016.

\bibitem[Andrychowicz et~al.(2016)Andrychowicz, Denil, Gomez, Hoffman, Pfau,
  Schaul, Shillingford, and De~Freitas]{andrychowicz2016learning}
Andrychowicz, M., Denil, M., Gomez, S., Hoffman, M.~W., Pfau, D., Schaul, T.,
  Shillingford, B., and De~Freitas, N.
\newblock Learning to learn by gradient descent by gradient descent.
\newblock In \emph{NIPS}, pp.\  3981--3989, 2016.

\bibitem[Baxter(1998)]{baxter1998theoretical}
Baxter, J.
\newblock Theoretical models of learning to learn.
\newblock In \emph{Learning to learn}, pp.\  71--94. Springer, 1998.

\bibitem[Braun et~al.(2010)Braun, Mehring, and Wolpert]{braun2010structure}
Braun, D.~A., Mehring, C., and Wolpert, D.~M.
\newblock Structure learning in action.
\newblock \emph{Behavioural brain research}, 206\penalty0 (2):\penalty0
  157--165, 2010.

\bibitem[Cimpoi et~al.(2014)Cimpoi, Maji, Kokkinos, Mohamed, , and
  Vedaldi]{cimpoi14describing}
Cimpoi, M., Maji, S., Kokkinos, I., Mohamed, S., , and Vedaldi, A.
\newblock Describing textures in the wild.
\newblock In \emph{CVPR}, 2014.

\bibitem[Conneau et~al.(2017)Conneau, Kiela, Schwenk, Barrault, and
  Bordes]{conneau2017supervised}
Conneau, A., Kiela, D., Schwenk, H., Barrault, L., and Bordes, A.
\newblock Supervised learning of universal sentence representations from
  natural language inference data.
\newblock In \emph{EMNLP}, pp.\  670--680, 2017.

\bibitem[Daniely et~al.(2015)Daniely, Gonen, and
  Shalev-Shwartz]{daniely2015strongly}
Daniely, A., Gonen, A., and Shalev-Shwartz, S.
\newblock Strongly adaptive online learning.
\newblock In \emph{ICML}, pp.\  1405--1411, 2015.

\bibitem[Finn \& Levine(2017)Finn and Levine]{finn2017meta}
Finn, C. and Levine, S.
\newblock Meta-learning and universality: Deep representations and gradient
  descent can approximate any learning algorithm.
\newblock \emph{arXiv preprint arXiv:1710.11622}, 2017.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{finn2017model}
Finn, C., Abbeel, P., and Levine, S.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{ICML}, pp.\  1126--1135, 2017.

\bibitem[Finn et~al.(2018)Finn, Xu, and Levine]{finn2018probabilistic}
Finn, C., Xu, K., and Levine, S.
\newblock Probabilistic model-agnostic meta-learning.
\newblock \emph{arXiv preprint arXiv:1806.02817}, 2018.

\bibitem[Flennerhag et~al.(2018)Flennerhag, Moreno, Lawrence, and
  Damianou]{flennerhag2018transferring}
Flennerhag, S., Moreno, P.~G., Lawrence, N.~D., and Damianou, A.
\newblock Transferring knowledge across learning processes.
\newblock \emph{arXiv preprint arXiv:1812.01054}, 2018.

\bibitem[Garcia \& Bruna(2017)Garcia and Bruna]{garcia2017few}
Garcia, V. and Bruna, J.
\newblock Few-shot learning with graph neural networks.
\newblock \emph{arXiv preprint arXiv:1711.04043}, 2017.

\bibitem[Gershman et~al.(2010)Gershman, Blei, and Niv]{gershman2010context}
Gershman, S.~J., Blei, D.~M., and Niv, Y.
\newblock Context, learning, and extinction.
\newblock \emph{Psychological review}, 117\penalty0 (1):\penalty0 197, 2010.

\bibitem[Gershman et~al.(2014)Gershman, Radulescu, Norman, and
  Niv]{gershman2014statistical}
Gershman, S.~J., Radulescu, A., Norman, K.~A., and Niv, Y.
\newblock Statistical computations underlying the dynamics of memory updating.
\newblock \emph{PLoS computational biology}, 10\penalty0 (11):\penalty0
  e1003939, 2014.

\bibitem[Grant et~al.(2018)Grant, Finn, Levine, Darrell, and
  Griffiths]{grant2018recasting}
Grant, E., Finn, C., Levine, S., Darrell, T., and Griffiths, T.
\newblock Recasting gradient-based meta-learning as hierarchical bayes.
\newblock \emph{arXiv preprint arXiv:1801.08930}, 2018.

\bibitem[Gu et~al.(2018)Gu, Wang, Chen, Cho, and Li]{gu2018meta}
Gu, J., Wang, Y., Chen, Y., Cho, K., and Li, V.~O.
\newblock Meta-learning for low-resource neural machine translation.
\newblock \emph{arXiv preprint arXiv:1808.08437}, 2018.

\bibitem[Hamilton et~al.(2017)Hamilton, Ying, and
  Leskovec]{hamilton2017inductive}
Hamilton, W., Ying, Z., and Leskovec, J.
\newblock Inductive representation learning on large graphs.
\newblock In \emph{NIPS}, pp.\  1024--1034, 2017.

\bibitem[Kim \& Xing(2010)Kim and Xing]{kim2010tree}
Kim, S. and Xing, E.~P.
\newblock Tree-guided group lasso for multi-task regression with structured
  sparsity.
\newblock In \emph{ICML}, pp.\  543--550, 2010.

\bibitem[Kumar \& Daum{\'e}~III(2012)Kumar and
  Daum{\'e}~III]{kumar2012learning}
Kumar, A. and Daum{\'e}~III, H.
\newblock Learning task grouping and overlap in multi-task learning.
\newblock In \emph{ICML}, pp.\  1723--1730, 2012.

\bibitem[Kuzborskij \& Lampert(2017)Kuzborskij and Lampert]{kuzborskij2017data}
Kuzborskij, I. and Lampert, C.~H.
\newblock Data-dependent stability of stochastic gradient descent.
\newblock \emph{arXiv preprint arXiv:1703.01678}, 2017.

\bibitem[Kuzborskij \& Orabona(2017)Kuzborskij and Orabona]{kuzborskij2017fast}
Kuzborskij, I. and Orabona, F.
\newblock Fast rates by transferring from auxiliary hypotheses.
\newblock \emph{Machine Learning}, 106\penalty0 (2):\penalty0 171--195, 2017.

\bibitem[Lee \& Choi(2018)Lee and Choi]{lee2018gradient}
Lee, Y. and Choi, S.
\newblock Gradient-based meta-learning with learned layerwise metric and
  subspace.
\newblock In \emph{ICML}, pp.\  2933--2942, 2018.

\bibitem[Li \& Malik(2016)Li and Malik]{li2016learning}
Li, K. and Malik, J.
\newblock Learning to optimize.
\newblock \emph{arXiv preprint arXiv:1606.01885}, 2016.

\bibitem[Li et~al.(2017)Li, Zhou, Chen, and Li]{li2017meta}
Li, Z., Zhou, F., Chen, F., and Li, H.
\newblock Meta-sgd: Learning to learn quickly for few shot learning.
\newblock \emph{arXiv preprint arXiv:1707.09835}, 2017.

\bibitem[Lin et~al.(2013)Lin, Chen, and Yan]{lin2013network}
Lin, M., Chen, Q., and Yan, S.
\newblock Network in network.
\newblock \emph{arXiv preprint arXiv:1312.4400}, 2013.

\bibitem[Maaten \& Hinton(2008)Maaten and Hinton]{maaten2008visualizing}
Maaten, L. v.~d. and Hinton, G.
\newblock Visualizing data using t-sne.
\newblock \emph{JMLR}, 9\penalty0 (Nov):\penalty0 2579--2605, 2008.

\bibitem[Maji et~al.(2013)Maji, Kannala, Rahtu, Blaschko, and
  Vedaldi]{maji13fine-grained}
Maji, S., Kannala, J., Rahtu, E., Blaschko, M., and Vedaldi, A.
\newblock Fine-grained visual classification of aircraft.
\newblock Technical report, 2013.

\bibitem[Mishra et~al.(2018)Mishra, Rohaninejad, Chen, and
  Abbeel]{mishra2018simple}
Mishra, N., Rohaninejad, M., Chen, X., and Abbeel, P.
\newblock A simple neural attentive meta-learner.
\newblock \emph{ICLR}, 2018.

\bibitem[Munkhdalai \& Yu(2017)Munkhdalai and Yu]{munkhdalai2017meta}
Munkhdalai, T. and Yu, H.
\newblock Meta networks.
\newblock In \emph{ICML}, pp.\  2554--2563, 2017.

\bibitem[Munkhdalai et~al.(2018)Munkhdalai, Yuan, Mehri, and
  Trischler]{munkhdalai2018rapid}
Munkhdalai, T., Yuan, X., Mehri, S., and Trischler, A.
\newblock Rapid adaptation with conditionally shifted neurons.
\newblock In \emph{ICML}, pp.\  3661--3670, 2018.

\bibitem[Nguyen \& Hein(2018)Nguyen and Hein]{nguyen2018optimization}
Nguyen, Q. and Hein, M.
\newblock Optimization landscape and expressivity of deep cnns.
\newblock In \emph{ICML}, 2018.

\bibitem[Nichol \& Schulman(2018)Nichol and Schulman]{nichol2018reptile}
Nichol, A. and Schulman, J.
\newblock Reptile: a scalable metalearning algorithm.
\newblock \emph{arXiv preprint arXiv:1803.02999}, 2018.

\bibitem[Perez et~al.(2018)Perez, Strub, de~Vries, Dumoulin, and
  Courville]{perez2018film}
Perez, E., Strub, F., de~Vries, H., Dumoulin, V., and Courville, A.~C.
\newblock Film: Visual reasoning with a general conditioning layer.
\newblock In \emph{AAAI}, 2018.

\bibitem[Ravi \& Larochelle(2016)Ravi and Larochelle]{ravi2016optimization}
Ravi, S. and Larochelle, H.
\newblock Optimization as a model for few-shot learning.
\newblock \emph{ICLR}, 2016.

\bibitem[Santoro et~al.(2016)Santoro, Bartunov, Botvinick, Wierstra, and
  Lillicrap]{santoro2016meta}
Santoro, A., Bartunov, S., Botvinick, M., Wierstra, D., and Lillicrap, T.
\newblock Meta-learning with memory-augmented neural networks.
\newblock In \emph{ICML}, pp.\  1842--1850, 2016.

\bibitem[Snell et~al.(2017)Snell, Swersky, and Zemel]{snell2017prototypical}
Snell, J., Swersky, K., and Zemel, R.
\newblock Prototypical networks for few-shot learning.
\newblock In \emph{NIPS}, pp.\  4077--4087, 2017.

\bibitem[Triantafillou et~al.(2017)Triantafillou, Zemel, and
  Urtasun]{triantafillou2017few}
Triantafillou, E., Zemel, R., and Urtasun, R.
\newblock Few-shot learning through an information retrieval lens.
\newblock In \emph{NIPS}, pp.\  2255--2265, 2017.

\bibitem[Vinyals et~al.(2016)Vinyals, Blundell, Lillicrap, Wierstra,
  et~al.]{vinyals2016matching}
Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et~al.
\newblock Matching networks for one shot learning.
\newblock In \emph{NIPS}, pp.\  3630--3638, 2016.

\bibitem[Vuorio et~al.(2018)Vuorio, Sun, Hu, and Lim]{vuorio2018toward}
Vuorio, R., Sun, S.-H., Hu, H., and Lim, J.~J.
\newblock Toward multimodal model-agnostic meta-learning.
\newblock \emph{arXiv preprint arXiv:1812.07172}, 2018.

\bibitem[Wah et~al.(2011)Wah, Branson, Welinder, Perona, and
  Belongie]{WahCUB_200_2011}
Wah, C., Branson, S., Welinder, P., Perona, P., and Belongie, S.
\newblock {The Caltech-UCSD Birds-200-2011 Dataset}.
\newblock Technical Report CNS-TR-2011-001, California Institute of Technology,
  2011.

\bibitem[Xu et~al.(2015)Xu, Ba, Kiros, Cho, Courville, Salakhudinov, Zemel, and
  Bengio]{xu2015show}
Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhudinov, R., Zemel, R.,
  and Bengio, Y.
\newblock Show, attend and tell: Neural image caption generation with visual
  attention.
\newblock In \emph{ICML}, pp.\  2048--2057, 2015.

\bibitem[Yang et~al.(2018)Yang, Zhang, Xiang, Torr, and
  Hospedales]{yang2018learning}
Yang, F. S.~Y., Zhang, L., Xiang, T., Torr, P.~H., and Hospedales, T.~M.
\newblock Learning to compare: Relation network for few-shot learning.
\newblock In \emph{CVPR}, 2018.

\bibitem[Ying et~al.(2018)Ying, You, Morris, Ren, Hamilton, and
  Leskovec]{ying2018hierarchical}
Ying, Z., You, J., Morris, C., Ren, X., Hamilton, W., and Leskovec, J.
\newblock Hierarchical graph representation learning with differentiable
  pooling.
\newblock In \emph{NIPS}, pp.\  4805--4815, 2018.

\bibitem[Yoon et~al.(2018{\natexlab{a}})Yoon, Kim, Dia, Kim, Bengio, and
  Ahn]{yoon2018bayesian}
Yoon, J., Kim, T., Dia, O., Kim, S., Bengio, Y., and Ahn, S.
\newblock Bayesian model-agnostic meta-learning.
\newblock In \emph{NIPS}, pp.\  7343--7353, 2018{\natexlab{a}}.

\bibitem[Yoon et~al.(2018{\natexlab{b}})Yoon, Yang, Lee, and
  Hwang]{yoon2017lifelong}
Yoon, J., Yang, E., Lee, J., and Hwang, S.~J.
\newblock Lifelong learning with dynamically expandable networks.
\newblock In \emph{ICLR}, 2018{\natexlab{b}}.

\end{thebibliography}
