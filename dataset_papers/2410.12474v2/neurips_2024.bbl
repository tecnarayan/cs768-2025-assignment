\begin{thebibliography}{56}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{layernorm}
Jimmy~Lei Ba, Jamie~Ryan Kiros, and Geoffrey~E Hinton.
\newblock Layer normalization.
\newblock \emph{arXiv preprint arXiv:1607.06450}, 2016.

\bibitem[Baik et~al.(2020)Baik, Choi, Choi, Kim, and Lee]{alfa-fo}
Sungyong Baik, Myungsub Choi, Janghoon Choi, Heewon Kim, and Kyoung~Mu Lee.
\newblock Meta-learning with adaptive hyperparameters.
\newblock \emph{NeurIPS}, 2020.

\bibitem[Bateni et~al.(2020)Bateni, Goyal, Masrani, Wood, and Sigal]{simplecnaps}
Peyman Bateni, Raghav Goyal, Vaden Masrani, Frank Wood, and Leonid Sigal.
\newblock Improved few-shot visual classification.
\newblock \emph{CVPR}, 2020.

\bibitem[Caron et~al.(2020)Caron, Misra, Mairal, Goyal, Bojanowski, and Joulin]{swav}
Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Piotr Bojanowski, and Armand Joulin.
\newblock Unsupervised learning of visual features by contrasting cluster assignments.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 9912--9924, 2020.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Kornblith, Norouzi, and Hinton]{simclr}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual representations.
\newblock \emph{ICML}, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2019)Chen, Liu, Kira, Wang, and Huang]{closerlookfsc}
Wei-Yu Chen, Yen-Cheng Liu, Zsolt Kira, Yu-Chiang~Frank Wang, and Jia-Bin Huang.
\newblock A closer look at few-shot classification.
\newblock \emph{ICLR}, 2019.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Fan, Girshick, and He]{mocov2}
Xinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He.
\newblock Improved baselines with momentum contrastive learning.
\newblock \emph{arXiv preprint arXiv:2003.04297}, 2020{\natexlab{b}}.

\bibitem[Chopra et~al.(2005)Chopra, Hadsell, and LeCun]{chopra2005learning}
Sumit Chopra, Raia Hadsell, and Yann LeCun.
\newblock Learning a similarity metric discriminatively, with application to face verification.
\newblock \emph{CVPR}, 2005.

\bibitem[Cimpoi et~al.(2014)Cimpoi, Maji, Kokkinos, Mohamed, and Vedaldi]{dtd}
Mircea Cimpoi, Subhransu Maji, Iasonas Kokkinos, Sammy Mohamed, and Andrea Vedaldi.
\newblock Describing textures in the wild.
\newblock \emph{CVPR}, 2014.

\bibitem[Doersch et~al.(2020)Doersch, Gupta, and Zisserman]{crosstransformer}
Carl Doersch, Ankush Gupta, and Andrew Zisserman.
\newblock Crosstransformers: spatially-aware few-shot transfer.
\newblock \emph{NeurIPS}, 2020.

\bibitem[Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, et~al.]{vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock \emph{ICLR}, 2021.

\bibitem[Dvornik et~al.(2020)Dvornik, Schmid, and Mairal]{sur}
Nikita Dvornik, Cordelia Schmid, and Julien Mairal.
\newblock Selecting relevant features from a multi-domain representation for few-shot classification.
\newblock \emph{ECCV}, 2020.

\bibitem[Ethayarajh(2019)]{ethayarajh2019contextual}
Kawin Ethayarajh.
\newblock How contextual are contextualized word representations? comparing the geometry of bert, elmo, and gpt-2 embeddings.
\newblock \emph{EMNLP}, 2019.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{maml}
Chelsea Finn, Pieter Abbeel, and Sergey Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock \emph{ICML}, 2017.

\bibitem[Grill et~al.(2020)Grill, Strub, Altch{\'e}, Tallec, Richemond, Buchatskaya, Doersch, Avila~Pires, Guo, Gheshlaghi~Azar, et~al.]{byol}
Jean-Bastien Grill, Florian Strub, Florent Altch{\'e}, Corentin Tallec, Pierre Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila~Pires, Zhaohan Guo, Mohammad Gheshlaghi~Azar, et~al.
\newblock Bootstrap your own latent-a new approach to self-supervised learning.
\newblock \emph{NeurIPS}, 2020.

\bibitem[Guo et~al.(2023)Guo, Du, Dong, Hospedales, Song, and Ma]{ta2}
Yurong Guo, Ruoyi Du, Yuan Dong, Timothy Hospedales, Yi-Zhe Song, and Zhanyu Ma.
\newblock Task-aware adaptive learning for cross-domain few-shot learning.
\newblock \emph{ICCV}, 2023.

\bibitem[Hadsell et~al.(2006)Hadsell, Chopra, and LeCun]{hadsell2006dimensionality}
Raia Hadsell, Sumit Chopra, and Yann LeCun.
\newblock Dimensionality reduction by learning an invariant mapping.
\newblock \emph{CVPR}, 2006.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock \emph{CVPR}, 2016.

\bibitem[He et~al.(2020)He, Fan, Wu, Xie, and Girshick]{moco}
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock \emph{CVPR}, 2020.

\bibitem[Houben et~al.(2013)Houben, Stallkamp, Salmen, Schlipsing, and Igel]{traffic_sign}
Sebastian Houben, Johannes Stallkamp, Jan Salmen, Marc Schlipsing, and Christian Igel.
\newblock Detection of traffic signs in real-world images: The german traffic sign detection benchmark.
\newblock \emph{IJCNN}, 2013.

\bibitem[Jia et~al.(2021)Jia, Yang, Xia, Chen, Parekh, Pham, Le, Sung, Li, and Duerig]{jia2021scaling}
Chao Jia, Yinfei Yang, Ye~Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le, Yun-Hsuan Sung, Zhen Li, and Tom Duerig.
\newblock Scaling up visual and vision-language representation learning with noisy text supervision.
\newblock \emph{ICML}, 2021.

\bibitem[Jongejan et~al.(2016)Jongejan, Henry, Takashi, Kim, and Nick]{quickdraw}
Jonas Jongejan, Rowley Henry, Kawashima Takashi, Jongmin Kim, and Fox-Gieg Nick.
\newblock The quick, draw! a.i. experiment.
\newblock \emph{https://quickdraw.withgoogle.com/}, 2016.

\bibitem[Khosla et~al.(2020)Khosla, Teterwak, Wang, Sarna, Tian, Isola, Maschinot, Liu, and Krishnan]{supcon}
Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip Isola, Aaron Maschinot, Ce~Liu, and Dilip Krishnan.
\newblock Supervised contrastive learning.
\newblock \emph{NeurIPS}, 2020.

\bibitem[Kingma and Ba(2014)]{adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton, et~al.]{cifar}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock \emph{Technical Report}, 2009.

\bibitem[Lake et~al.(2015)Lake, Salakhutdinov, and Tenenbaum]{omniglot}
Brenden~M Lake, Ruslan Salakhutdinov, and Joshua~B Tenenbaum.
\newblock Human-level concept learning through probabilistic program induction.
\newblock \emph{Science}, 350\penalty0 (6266):\penalty0 1332--1338, 2015.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and Haffner]{mnist}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0 2278--2324, 1998.

\bibitem[Li et~al.(2021{\natexlab{a}})Li, Selvaraju, Gotmare, Joty, Xiong, and Hoi]{li2021align}
Junnan Li, Ramprasaath Selvaraju, Akhilesh Gotmare, Shafiq Joty, Caiming Xiong, and Steven Chu~Hong Hoi.
\newblock Align before fuse: Vision and language representation learning with momentum distillation.
\newblock \emph{NeurIPS}, 2021{\natexlab{a}}.

\bibitem[Li et~al.(2021{\natexlab{b}})Li, Liu, and Bilen]{url}
Wei-Hong Li, Xialei Liu, and Hakan Bilen.
\newblock Universal representation learning from multiple domains for few-shot classification.
\newblock \emph{ICCV}, 2021{\natexlab{b}}.

\bibitem[Li et~al.(2022)Li, Liu, and Bilen]{tsa}
Wei-Hong Li, Xialei Liu, and Hakan Bilen.
\newblock Cross-domain few-shot learning with task-specific adapters.
\newblock \emph{CVPR}, 2022.

\bibitem[Li et~al.(2021{\natexlab{c}})Li, Pogodin, Sutherland, and Gretton]{hsic_ssl}
Yazhe Li, Roman Pogodin, Danica~J Sutherland, and Arthur Gretton.
\newblock Self-supervised learning with kernel dependence maximization.
\newblock \emph{NeurIPS}, 2021{\natexlab{c}}.

\bibitem[Liang et~al.(2022)Liang, Zhang, Kwon, Yeung, and Zou]{mindgap}
Victor~Weixin Liang, Yuhui Zhang, Yongchan Kwon, Serena Yeung, and James~Y Zou.
\newblock Mind the gap: Understanding the modality gap in multi-modal contrastive representation learning.
\newblock \emph{NeurIPS}, 2022.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan, Doll{\'a}r, and Zitnick]{mscoco}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock \emph{ECCV}, 2014.

\bibitem[Liu et~al.(2020)Liu, Hamilton, Long, Jiang, and Larochelle]{urt}
Lu~Liu, William Hamilton, Guodong Long, Jing Jiang, and Hugo Larochelle.
\newblock A universal representation transformer layer for few-shot image classification.
\newblock \emph{NeurIPS}, 2020.

\bibitem[Liu et~al.(2021)Liu, Lee, Zhu, Chen, Shi, and Yang]{tri-m}
Yanbin Liu, Juho Lee, Linchao Zhu, Ling Chen, Humphrey Shi, and Yi~Yang.
\newblock A multi-mode modulator for multi-domain few-shot classification.
\newblock \emph{ICCV}, 2021.

\bibitem[Maji et~al.(2013)Maji, Rahtu, Kannala, Blaschko, and Vedaldi]{aircraft}
Subhransu Maji, Esa Rahtu, Juho Kannala, Matthew Blaschko, and Andrea Vedaldi.
\newblock Fine-grained visual classification of aircraft.
\newblock \emph{arXiv preprint arXiv:1306.5151}, 2013.

\bibitem[McInnes et~al.(2018)McInnes, Healy, and Melville]{umap}
Leland McInnes, John Healy, and James Melville.
\newblock Umap: Uniform manifold approximation and projection for dimension reduction.
\newblock \emph{arXiv preprint arXiv:1802.03426}, 2018.

\bibitem[Mu et~al.(2018)Mu, Bhat, and Viswanath]{mu2017all}
Jiaqi Mu, Suma Bhat, and Pramod Viswanath.
\newblock All-but-the-top: Simple and effective postprocessing for word representations.
\newblock \emph{ICLR}, 2018.

\bibitem[Nilsback and Zisserman(2008)]{vgg_flower}
Maria-Elena Nilsback and Andrew Zisserman.
\newblock Automated flower classification over a large number of classes.
\newblock \emph{2008 Sixth Indian Conference on Computer Vision, Graphics \& Image Processing}, 2008.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{infonce}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Perez et~al.(2018)Perez, Strub, De~Vries, Dumoulin, and Courville]{film}
Ethan Perez, Florian Strub, Harm De~Vries, Vincent Dumoulin, and Aaron Courville.
\newblock Film: Visual reasoning with a general conditioning layer.
\newblock \emph{AAAI}, 2018.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{clip}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock \emph{ICML}, 2021.

\bibitem[Requeima et~al.(2019)Requeima, Gordon, Bronskill, Nowozin, and Turner]{cnaps}
James Requeima, Jonathan Gordon, John Bronskill, Sebastian Nowozin, and Richard~E Turner.
\newblock Fast and flexible multi-task classification using conditional neural adaptive processes.
\newblock \emph{NeurIPS}, 2019.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma, Huang, Karpathy, Khosla, Bernstein, et~al.]{imagenet}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{International Journal of Computer Vision}, 115\penalty0 (3):\penalty0 211--252, 2015.

\bibitem[Schroeder and Cui(2018)]{fungi}
Brigit Schroeder and Yin Cui.
\newblock Fgvcx fungi classification challenge.
\newblock \emph{github.com/visipedia/fgvcx\_fungi\_comp}, 2018.

\bibitem[Schroff et~al.(2015)Schroff, Kalenichenko, and Philbin]{triplet}
Florian Schroff, Dmitry Kalenichenko, and James Philbin.
\newblock Facenet: A unified embedding for face recognition and clustering.
\newblock \emph{CVPR}, 2015.

\bibitem[Snell et~al.(2017)Snell, Swersky, and Zemel]{prototypical}
Jake Snell, Kevin Swersky, and Richard Zemel.
\newblock Prototypical networks for few-shot learning.
\newblock \emph{NIPS}, 2017.

\bibitem[Sohn(2016)]{n-pair_loss}
Kihyuk Sohn.
\newblock Improved deep metric learning with multi-class n-pair loss objective.
\newblock \emph{NIPS}, 2016.

\bibitem[Triantafillou et~al.(2020)Triantafillou, Zhu, Dumoulin, Lamblin, Evci, Xu, Goroshin, Gelada, Swersky, Manzagol, et~al.]{meta-dataset}
Eleni Triantafillou, Tyler Zhu, Vincent Dumoulin, Pascal Lamblin, Utku Evci, Kelvin Xu, Ross Goroshin, Carles Gelada, Kevin Swersky, Pierre-Antoine Manzagol, et~al.
\newblock Meta-dataset: A dataset of datasets for learning to learn from few examples.
\newblock \emph{ICLR}, 2020.

\bibitem[Triantafillou et~al.(2021)Triantafillou, Larochelle, Zemel, and Dumoulin]{flute}
Eleni Triantafillou, Hugo Larochelle, Richard Zemel, and Vincent Dumoulin.
\newblock Learning a universal template for few-shot dataset generalization.
\newblock \emph{ICML}, 2021.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{transformer}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock \emph{NIPS}, 2017.

\bibitem[Vinyals et~al.(2016)Vinyals, Blundell, Lillicrap, Wierstra, et~al.]{matching_net}
Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et~al.
\newblock Matching networks for one shot learning.
\newblock \emph{NIPS}, 2016.

\bibitem[Wah et~al.(2011)Wah, Branson, Welinder, Perona, and Belongie]{cu_birds}
Catherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge Belongie.
\newblock The caltech-ucsd birds-200-2011 dataset.
\newblock \emph{Technical Report CNS-TR-2011-001}, 2011.

\bibitem[Xu et~al.(2021)Xu, Ghosh, Huang, Okhonko, Aghajanyan, Metze, Zettlemoyer, and Feichtenhofer]{xu2021videoclip}
Hu~Xu, Gargi Ghosh, Po-Yao Huang, Dmytro Okhonko, Armen Aghajanyan, Florian Metze, Luke Zettlemoyer, and Christoph Feichtenhofer.
\newblock Videoclip: Contrastive pre-training for zero-shot video-text understanding.
\newblock \emph{arXiv preprint arXiv:2109.14084}, 2021.

\bibitem[Zbontar et~al.(2021)Zbontar, Jing, Misra, LeCun, and Deny]{barlowtwins}
Jure Zbontar, Li~Jing, Ishan Misra, Yann LeCun, and St{\'e}phane Deny.
\newblock Barlow twins: Self-supervised learning via redundancy reduction.
\newblock \emph{ICML}, 2021.

\bibitem[Zhang et~al.(2022)Zhang, Jiang, Miura, Manning, and Langlotz]{zhang2022contrastive}
Yuhao Zhang, Hang Jiang, Yasuhide Miura, Christopher~D Manning, and Curtis~P Langlotz.
\newblock Contrastive learning of medical visual representations from paired images and text.
\newblock In \emph{MLHC}. PMLR, 2022.

\end{thebibliography}
