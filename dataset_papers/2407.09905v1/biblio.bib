@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@article{mutti2023convex,
  title={Convex Reinforcement Learning in Finite Trials},
  author={Mutti, Mirco and De Santi, Riccardo and De Bartolomeis, Piersilvio and Restelli, Marcello},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={250},
  pages={1--42},
  year={2023}
}


@INPROCEEDINGS{chekuri_rg,
  author={Chandra Chekuri and Pal, M.},
  booktitle={46th Annual IEEE Symposium on Foundations of Computer Science (FOCS'05)}, 
  title={A recursive greedy algorithm for walks in directed graphs}, 
  year={2005},
  volume={},
  number={},
  pages={245-253},
  doi={10.1109/SFCS.2005.9}}

@inproceedings{near_optimal_safe_cov,
 author = {Prajapat, Manish and Turchetta, Matteo and Zeilinger, Melanie and Krause, Andreas},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {14998--15012},
 publisher = {Curran Associates, Inc.},
 title = {Near-Optimal Multi-Agent Learning for Safe Coverage Control},
 volume = {35},
 year = {2022}
}

@inproceedings{bian2017guaranteed,
  title={Guaranteed non-convex optimization: Submodular maximization over continuous domains},
  author={Bian, Andrew An and Mirzasoleiman, Baharan and Buhmann, Joachim and Krause, Andreas},
  booktitle={Artificial Intelligence and Statistics},
  pages={111--120},
  year={2017},
  organization={PMLR}
}

@article{karimi2017stochastic,
  title={Stochastic submodular maximization: The case of coverage functions},
  author={Karimi, Mohammad and Lucic, Mario and Hassani, Hamed and Krause, Andreas},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}


@inproceedings{asadpour2008stochastic,
  title={Stochastic submodular maximization},
  author={Asadpour, Arash and Nazerzadeh, Hamid and Saberi, Amin},
  booktitle={Internet and Network Economics: 4th International Workshop, WINE 2008, Shanghai, China, December 17-20, 2008. Proceedings 4},
  pages={477--489},
  year={2008},
  organization={Springer}
}

@article{bian2017continuous,
  title={Continuous dr-submodular maximization: Structure and algorithms},
  author={Bian, An and Levy, Kfir and Krause, Andreas and Buhmann, Joachim M},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{Chen2017InteractiveSB,
  title={Interactive Submodular Bandit},
  author={Lin Chen and Andreas Krause and Amin Karbasi},
  booktitle={NIPS},
  year={2017}
}

@inproceedings{YisongLSB,
 author = {Yue, Yisong and Guestrin, Carlos},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Shawe-Taylor and R. Zemel and P. Bartlett and F. Pereira and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Linear Submodular Bandits and their Application to Diversified Retrieval},
 url = {https://proceedings.neurips.cc/paper/2011/file/33ebd5b07dc7e407752fe773eed20635-Paper.pdf},
 volume = {24},
 year = {2011}
}

@article{hassani2017gradient,
  title={Gradient methods for submodular maximization},
  author={Hassani, Hamed and Soltanolkotabi, Mahdi and Karbasi, Amin},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{bhandari2021linear,
  title={On the linear convergence of policy gradient methods for finite mdps},
  author={Bhandari, Jalaj and Russo, Daniel},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2386--2394},
  year={2021},
  organization={PMLR}
}

@article{zahavy2021reward,
  title={Reward is enough for convex MDPs},
  author={Zahavy, Tom and O'Donoghue, Brendan and Desjardins, Guillaume and Singh, Satinder},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={25746--25759},
  year={2021}
}

@article{gorilla-kagwene,
author = {Funwi-gabga, Neba and Mateu, Jorge},
year = {2011},
month = {08},
pages = {},
title = {Understanding the nesting spatial behaviour of gorillas in the Kagwene Sanctuary, Cameroon},
volume = {26},
journal = {Stochastic Environmental Research and Risk Assessment},
doi = {10.1007/s00477-011-0541-1}
}

@article{mojmir-cox,
  author    = {Mojm{\'{\i}}r Mutn{\'{y}} and
               Andreas Krause},
  title     = {Sensing Cox Processes via Posterior Sampling and Positive Bases},
  journal   = {CoRR},
  volume    = {abs/2110.11181},
  year      = {2021},
  url       = {https://arxiv.org/abs/2110.11181},
  eprinttype = {arXiv},
  eprint    = {2110.11181},
  timestamp = {Thu, 28 Oct 2021 15:25:31 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2110-11181.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{prajapat2021competitive,
  title={Competitive policy optimization},
  author={Prajapat, Manish and Azizzadenesheli, Kamyar and Liniger, Alexander and Yue, Yisong and Anandkumar, Anima},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={64--74},
  year={2021},
  organization={PMLR}
}

@article{Liniger2017OptimizationBasedAR,
  title={Optimization-Based Autonomous Racing of 1: 43 Scale RC Cars},
  author={Alexander Liniger and Alexander Domahidi and Manfred Morari},
  journal={Optimal Control Applications and Methods},
  volume={36},
  number={5},
  pages={628--647},
  year={2015}
}
@inproceedings{schulman2015highdimensional,
  author    = {John Schulman and Philipp Moritz and
               Sergey Levine and
               Michael I. Jordan and
               Pieter Abbeel},
  title     = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
  booktitle = {4th International Conference on Learning Representations, {ICLR}},
  year      = {2016},
  timestamp = {Thu, 25 Jul 2019 14:25:38 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SchulmanMLJA15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{baird1993,
  author    = {Baird, III, Leemon C},
  title     = {Advantage Updating},
  journal   = {WRIGHT LAB WRIGHT-PATTERSON AFB OH},
  year      = {1993},
}

@inproceedings{Halperin2003inapprox,
author = {Halperin, Eran and Krauthgamer, Robert},
title = {Polylogarithmic Inapproximability},
year = {2003},
isbn = {1581136749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/780542.780628},
doi = {10.1145/780542.780628},
abstract = {We provide the first hardness result of a polylogarithmic approximation ratio for a natural NP-hard optimization problem. We show that for every fixed ε>0, the GROUP-STEINER-TREE problem admits no efficient log2-ε k approximation, where k denotes the number of groups (or, alternatively, the input size), unless NP has quasi polynomial Las-Vegas algorithms. This hardness result holds even for input graphs which are Hierarchically Well-Separated Trees, introduced by Bartal [FOCS, 1996]. For these trees (and also for general trees), our bound is nearly tight with the log-squared approximation currently known. Our results imply that for every fixed ε>0, the DIRECTED-STEINER TREE problem admits no log2-ε n--approximation, where n is the number of vertices in the graph, under the same complexity assumption.},
booktitle = {Proceedings of the Thirty-Fifth Annual ACM Symposium on Theory of Computing},
pages = {585–594},
numpages = {10},
keywords = {Steiner tree, integrality ratio, polylogarithmic approximation, approximation algorithms, hardness of approximation},
location = {San Diego, CA, USA},
series = {STOC '03}
}

@article{krause2014submodular,
  title={Submodular function maximization.},
  author={Krause, Andreas and Golovin, Daniel},
  journal={Tractability},
  volume={3},
  pages={71--104},
  year={2014}
}

@article{bilmes2022submodularity,
  title={Submodularity in machine learning and artificial intelligence},
  author={Bilmes, Jeff},
  journal={arXiv preprint arXiv:2202.00132},
  year={2022}
}

@PhdThesis{Duff2002,
  author = {Duff, Michael O'Gordon},
  school = {University of Massachusetts Amherst},
  title  = {Optimal learning: Computational procedures for Bayes -adaptive Markov decision processes},
  year   = {2002},
}
@InProceedings{Mutny2023,
  author       = {Mutn\'{y}, Mojm\'{i}r and Janik, Tadeusz and Krause, Andreas},
  booktitle    = {Proceedings of the 26th International Conference on Artificial Intelligence and Statistics (AISTATS)},
  title        = {Active Exploration via Experiment Design in Markov Chains},
  year         = {2023},
}

@InProceedings{Mutny2022,
  author    = {Mojm\'{i}r Mutn\'{y} and Andreas Krause},
  booktitle = {Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS)},
  title     = {Sensing Cox Processes via Posterior Sampling and Positive Bases},
  year      = {2022},
  abstract  = {We study adaptive sensing of Cox point processes, a widely used model from spatial statistics. We introduce three tasks: maximization of captured events, search for the maximum of the intensity function and learning level sets of the intensity function. We model the intensity function as a sample from a truncated Gaussian process, represented in a specially constructed positive basis. In this basis, the positivity constraint on the intensity function has a simple form. We show how the \emph{minimal description positive basis} can be adapted to the covariance kernel, to non-stationarity and make connections to common positive bases from prior works. Our adaptive sensing algorithms use Langevin dynamics and are based on posterior sampling (\textsc{Cox-Thompson}) and top-two posterior sampling (\textsc{Top2}) principles. With latter, the difference between samples serves as a surrogate to the uncertainty. We demonstrate the approach using examples from environmental monitoring and crime rate modeling, and compare it to the classical Bayesian experimental design approach.},
  date      = {2020},
  url       = {https://arxiv.org/abs/2110.11181},
}


@InProceedings{Mutny2021a,
  author    = {Mutn\'{y},Mojm\'{i}r and Krause, Andreas},
  booktitle = {Proc. International Conference for Machine Learning (ICML)},
  title     = {No-regret Algorithms for Capturing Events in Poisson Point Processes},
  year      = {2021},
  abstract  = {Inhomogeneous Poisson point processes are widely used  models of event occurrences. We address \emph{adaptive sensing of Poisson Point processes}, namely, maximizing the number of captured events subject to sensing costs. We encode prior assumptions on the rate function by modeling it as a member of a known \emph{reproducing kernel Hilbert space} (RKHS). By partitioning the domain into separate small regions, and using heteroscedastic linear regression, we propose a tractable estimator of Poisson process rates for two feedback models: \emph{count-record}, where exact locations of events are observed, and \emph{histogram} feedback, where only counts of events are observed. We derive provably accurate anytime confidence estimates for our estimators for sequentially acquired Poisson count data. Using these, we formulate algorithms based on optimism that provably incur sublinear count-regret. We demonstrate the practicality of the method on problems from crime modeling, revenue maximization as well as environmental monitoring.},
  url       = {http://proceedings.mlr.press/v139/mutny21a/mutny21a.pdf},
}

@InProceedings{Mutny2022b,
  author    = {Mutn\'y, Mojm\'ir and Andreas Krause},
  booktitle = {Proc. Neural Information Processing Systems (NeurIPS)},
  title     = {Experimental Design of Linear Functionals in Reproducing Kernel Hilbert Spaces},
  year      = {2022},
  month     = nov,
  abstract  = {Optimal experimental design seeks to determine the most informative allocation of experiments  to infer an unknown statistical quantity. In this work, we investigate optimal design of experiments for {\em estimation of linear functionals in reproducing kernel Hilbert spaces (RKHSs)}. This problem has been extensively studied in the linear regression setting
 under an estimability condition, which allows estimating parameters without bias. We generalize this framework to RKHSs, and allow for the linear functional to be only approximately inferred, i.e., with a fixed bias. This scenario captures many important modern applications such as estimation of gradient maps, integrals and solutions to differential equations. We provide algorithms for constructing bias-aware designs for linear functionals. We derive non-asymptotic confidence sets for fixed and adaptive designs under sub-Gaussian noise, enabling us to certify estimation with bounded error with high probability.},
  url       = {https://arxiv.org/abs/2205.13627},
}


@InProceedings{Hazan2019,
  author       = {Hazan, Elad and Kakade, Sham and Singh, Karan and Van Soest, Abby},
  booktitle    = {International Conference on Machine Learning},
  title        = {Provably efficient maximum entropy exploration},
  year         = {2019},
  organization = {PMLR},
  pages        = {2681--2691},
}


@InProceedings{Zahavy2021,
  author    = {Tom Zahavy and Brendan O’Donoghue and Guillaume Desjardins and Satinder Singh},
  booktitle = {35th Conference on Neural Information Processing Systems (NeurIPS 2021)},
  title     = {Reward is enough for convex MDPs},
  year      = {2021},
}


@Article{Belogolovsky2021,
  author  = {Stav Belogolovsky and Philip Korsunsky and Shie Mannor and Chen Tessler and Tom Zahavy},
  journal = {Machine Learning},
  title   = {Inverse reinforcement learning in contextual MDPs},
  year    = {2021},
}

@InProceedings{Tarbouriech2019,
  author    = {Tarbouriech, Jean and Lazaric, Alessandro},
  booktitle = {Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics},
  title     = {Active Exploration in Markov Decision Processes},
  year      = {2019},
  editor    = {Chaudhuri, Kamalika and Sugiyama, Masashi},
  month     = {16--18 Apr},
  pages     = {974--982},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  volume    = {89},
  abstract  = {We introduce the active exploration problem in Markov decision processes (MDPs). Each state of the MDP is characterized by a random value and the learner should gather samples to estimate the mean value of each state as accurately as possible. Similarly to active exploration in multi-armed bandit (MAB), states may have different levels of noise, so that the higher the noise, the more samples are needed. As the noise level is initially unknown, we need to trade off the exploration of the environment to estimate the noise and the exploitation of these estimates to compute a policy maximizing the accuracy of the mean predictions. We introduce a novel learning algorithm to solve this problem showing that active exploration in MDPs may be significantly more difficult than in MAB. We also derive a heuristic procedure to mitigate the negative effect of slowly mixing policies. Finally, we validate our findings on simple numerical simulations.},
  pdf       = {http://proceedings.mlr.press/v89/tarbouriech19a/tarbouriech19a.pdf},
  url       = {https://proceedings.mlr.press/v89/tarbouriech19a.html},
}


@InProceedings{tarbouriech2020active,
  author       = {Tarbouriech, Jean and Shekhar, Shubhanshu and Pirotta, Matteo and Ghavamzadeh, Mohammad and Lazaric, Alessandro},
  booktitle    = {Conference on Uncertainty in Artificial Intelligence},
  title        = {Active model estimation in markov decision processes},
  year         = {2020},
  organization = {PMLR},
  pages        = {1019--1028},
}


@article{mutti2022challenging,
  title={Challenging common assumptions in convex reinforcement learning},
  author={Mutti, Mirco and De Santi, Riccardo and De Bartolomeis, Piersilvio and Restelli, Marcello},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={4489--4502},
  year={2022}
}

@Book{Szepesvari2020,
  author    = {Csaba Szepesvari and Tor Lattimore},
  publisher = {Cambridge University Press},
  title     = {Bandit Algorithms},
  year      = {2020},
}

@Article{Wang2020,
  author        = {Ruosong Wang and Simon S. Du and Lin F. Yang and Ruslan Salakhutdinov},
  journal       = {CoRR},
  title         = {On Reward-Free Reinforcement Learning with Linear Function Approximation},
  year          = {2020},
  volume        = {abs/2006.11274},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-2006-11274.bib},
  eprint        = {2006.11274},
  timestamp     = {Tue, 23 Jun 2020 17:57:22 +0200},
  url           = {https://arxiv.org/abs/2006.11274},
}

@Article{chaloner1995bayesian,
  author    = {Chaloner, Kathryn and Verdinelli, Isabella},
  journal   = {Statistical Science},
  title     = {Bayesian experimental design: A review},
  year      = {1995},
  pages     = {273--304},
  publisher = {JSTOR},
}

@Article{Golovin2011,
  author     = {Golovin, Daniel and Krause, Andreas},
  title      = {Adaptive Submodularity: Theory and Applications in Active Learning and Stochastic Optimization},
  journal    = {J. Artif. Int. Res.},
  year       = {2011},
  volume     = {42},
  number     = {1},
  month      = sep,
  pages      = {427--486},
  issn       = {1076-9757},
  url        = {http://dl.acm.org/citation.cfm?id=2208436.2208448},
  acmid      = {2208448},
  address    = {USA},
  issue_date = {September 2011},
  numpages   = {60},
  publisher  = {AI Access Foundation},
}

@InProceedings{greedy-supermodular,
  author    = {Andrew An Bian and Joachim M. Buhmann and Andreas Krause and Sebastian Tschiatschek},
  title     = {Guarantees for Greedy Maximization of Non-submodular Functions with Applications},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  year      = {2017},
  editor    = {Doina Precup and Yee Whye Teh},
  volume    = {70},
  series    = {Proceedings of Machine Learning Research},
  publisher = {PMLR},
  month     = {06--11 Aug},
  pages     = {498--507},
  url       = {http://proceedings.mlr.press/v70/bian17a.html},
  address   = {International Convention Centre, Sydney, Australia},
  file      = {bian17a.pdf:http\://proceedings.mlr.press/v70/bian17a/bian17a.pdf:PDF},
}

@article{nemhauser1978analysis,
  title={An analysis of approximations for maximizing submodular set functions—I},
  author={Nemhauser, George L and Wolsey, Laurence A and Fisher, Marshall L},
  journal={Mathematical programming},
  volume={14},
  number={1},
  pages={265--294},
  year={1978},
  publisher={Springer}
}


@InProceedings{Vanchinathan2015,
  author    = {Vanchinathan, Hastagiri P and Marfurt, Andreas and Robelin, Charles-Antoine and Kossmann, Donald and Krause, Andreas},
  booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  title     = {Discovering valuable items from massive data},
  pages     = {1195--1204},
  year      = {2015},
}


@InProceedings{Jaggi13,
  author    = {Jaggi, Martin},
  booktitle = {Proceedings of the 30th International Conference on Machine Learning},
  title     = {Revisiting {Frank-Wolfe}: Projection-Free Sparse Convex Optimization},
  year      = {2013},
  address   = {Atlanta, Georgia, USA},
  editor    = {Dasgupta, Sanjoy and McAllester, David},
  month     = {17--19 Jun},
  number    = {1},
  pages     = {427--435},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  volume    = {28},
  abstract  = {We provide stronger and more general primal-dual convergence results for Frank-Wolfe-type algorithms (a.k.a. conditional gradient) for constrained convex optimization, enabled by a simple framework of duality gap certificates. Our analysis also holds if the linear subproblems are only solved approximately (as well as if the gradients are inexact), and is proven to be worst-case optimal in the sparsity of the obtained solutions.    On the application side, this allows us to unify a large variety of existing sparse greedy methods, in particular for optimization over convex hulls of an atomic set, even if those sets can only be approximated, including sparse (or structured sparse) vectors or matrices, low-rank matrices, permutation matrices, or max-norm bounded matrices.    We present a new general framework for convex optimization over matrix factorizations, where every Frank-Wolfe iteration will consist of a low-rank update, and discuss the broad application areas of this approach.},
  pdf       = {http://proceedings.mlr.press/v28/jaggi13.pdf},
  url       = {https://proceedings.mlr.press/v28/jaggi13.html},
}

@inproceedings{lindner2021information,
	Author = {Lindner, David and Turchetta, Matteo and Tschiatschek, Sebastian and Ciosek, Kamil and Krause, Andreas},
	Blog = {https://las.inf.ethz.ch/information-directed-reward-learning},
	Booktitle = {Proc. Neural Information Processing Systems (NeurIPS)},
	Month = {December},
	Title = {Information Directed Reward Learning for Reinforcement Learning},
	Video = {https://www.youtube.com/watch?v=1RpiZrxhV90},
	Year = {2021}}


@article{golovin2011adaptive,
  title={Adaptive submodularity: Theory and applications in active learning and stochastic optimization},
  author={Golovin, Daniel and Krause, Andreas},
  journal={Journal of Artificial Intelligence Research},
  volume={42},
  pages={427--486},
  year={2011}
}
@article{dolhansky2016deep,
  title={Deep submodular functions: Definitions and learning},
  author={Dolhansky, Brian W and Bilmes, Jeff A},
  journal={Advances in Neural Information Processing Systems},
  volume={29},
  year={2016}
}

@inproceedings{balcan2011learning,
  title={Learning submodular functions},
  author={Balcan, Maria-Florina and Harvey, Nicholas JA},
  booktitle={Proceedings of the forty-third annual ACM symposium on Theory of computing},
  pages={793--802},
  year={2011}
}

@inproceedings{Singh2009,
author = {Singh, Amarjeet and Krause, Andreas and Kaiser, William J.},
title = {Nonmyopic Adaptive Informative Path Planning for Multiple Robots},
year = {2009},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
abstract = {Many robotic path planning applications, such as search and rescue, involve uncertain environments with complex dynamics that can be only partially observed. When selecting the best subset of observation locations subject to constrained resources (such as limited time or battery capacity) it is an important problem to trade off exploration (gathering information about the environment) and exploitation (using the current knowledge about the environment most effectively) for efficiently observing these environments. Even the nonadaptive setting, where paths are planned before observations are made, is NP-hard, and has been subject to much research.In this paper, we present a novel approach to adaptive informative path planning that addresses this exploration-exploitation tradeoff. Our approach is nonmyopic, i.e. it plans ahead for possible observations that can be made in the future. We quantify the benefit of exploration through the "adaptivity gap" between an adaptive and a nonadaptive algorithm in terms of the uncertainty in the environment. Exploiting the submodularity (a diminishing returns property) and locality properties of the objective function, we develop an algorithm that performs provably near-optimally in settings where the adaptivity gap is small. In case of large gap, we use an objective function that simultaneously optimizes paths for exploration and exploitation. We also provide an algorithm to extend any single robot algorithm for adaptive informative path planning to the multi robot setting while approximately preserving the theoretical guarantee of the single robot algorithm. We extensively evaluate our approach on a search and rescue domain and a scientific monitoring problem using a real robotic system.},
booktitle = {Proceedings of the 21st International Joint Conference on Artificial Intelligence},
pages = {1843–1850},
numpages = {8},
location = {Pasadena, California, USA},
series = {IJCAI'09}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{blum2007approximation,
  title={Approximation algorithms for orienteering and discounted-reward TSP},
  author={Blum, Avrim and Chawla, Shuchi and Karger, David R and Lane, Terran and Meyerson, Adam and Minkoff, Maria},
  journal={SIAM Journal on Computing},
  volume={37},
  number={2},
  pages={653--670},
  year={2007},
  publisher={SIAM}
}

@incollection{FU_score,
title = {Chapter 19 Gradient Estimation},
editor = {Shane G. Henderson and Barry L. Nelson},
series = {Handbooks in Operations Research and Management Science},
publisher = {Elsevier},
volume = {13},
pages = {575-616},
year = {2006},
booktitle = {Simulation},
issn = {0927-0507},
doi = {https://doi.org/10.1016/S0927-0507(06)13019-4},
url = {https://www.sciencedirect.com/science/article/pii/S0927050706130194},
author = {Michael C. Fu},
abstract = {This chapter considers the problem of efficiently estimating gradients from stochastic simulation. Although the primary motivation is their use in simulation optimization, the resulting estimators can also be useful in other ways, e.g., sensitivity analysis. The main approaches described are finite differences (including simultaneous perturbations), perturbation analysis, the likelihood ratio/score function method, and the use of weak derivatives.}
}

@article{greensmith2004variance,
  title={Variance Reduction Techniques for Gradient Estimates in Reinforcement Learning.},
  author={Greensmith, Evan and Bartlett, Peter L and Baxter, Jonathan},
  journal={Journal of Machine Learning Research},
  volume={5},
  number={9},
  year={2004}
}

@article{GUNAWAN2016315,
title = {Orienteering Problem: A survey of recent variants, solution approaches and applications},
journal = {European Journal of Operational Research},
volume = {255},
number = {2},
pages = {315-332},
year = {2016},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2016.04.059},
url = {https://www.sciencedirect.com/science/article/pii/S037722171630296X},
author = {Aldy Gunawan and Hoong Chuin Lau and Pieter Vansteenwegen},
keywords = {Scheduling, Survey, Orienteering Problem, Practical Applications},
abstract = {The Orienteering Problem (OP) has received a lot of attention in the past few decades. The OP is a routing problem in which the goal is to determine a subset of nodes to visit, and in which order, so that the total collected score is maximized and a given time budget is not exceeded. A number of typical variants has been studied, such as the Team OP, the (Team) OP with Time Windows and the Time Dependent OP. Recently, a number of new variants of the OP was introduced, such as the Stochastic OP, the Generalized OP, the Arc OP, the Multi-agent OP, the Clustered OP and others. This paper focuses on a comprehensive and thorough survey of recent variants of the OP, including the proposed solution approaches. Moreover, the OP has been used as a model in many different practical applications. The most recent applications of the OP, such as the Tourist Trip Design Problem and the mobile-crowdsourcing problem are discussed. Finally, we also present some promising topics for future research.}
}


@article{sensor-placement-andreas,
author = {Krause, Andreas and Singh, Ajit and Guestrin, Carlos},
title = {Near-Optimal Sensor Placements in Gaussian Processes: Theory, Efficient Algorithms and Empirical Studies},
year = {2008},
issue_date = {6/1/2008},
publisher = {JMLR.org},
volume = {9},
issn = {1532-4435},
abstract = {When monitoring spatial phenomena, which can often be modeled as Gaussian processes (GPs), choosing sensor locations is a fundamental task. There are several common strategies to address this task, for example, geometry or disk models, placing sensors at the points of highest entropy (variance) in the GP model, and A-, D-, or E-optimal design. In this paper, we tackle the combinatorial optimization problem of maximizing the mutual information between the chosen locations and the locations which are not selected. We prove that the problem of finding the configuration that maximizes mutual information is NP-complete. To address this issue, we describe a polynomial-time approximation that is within (1-1/e) of the optimum by exploiting the submodularity of mutual information. We also show how submodularity can be used to obtain online bounds, and design branch and bound search procedures. We then extend our algorithm to exploit lazy evaluations and local structure in the GP, yielding significant speedups. We also extend our approach to find placements which are robust against node failures and uncertainties in the model. These extensions are again associated with rigorous theoretical approximation guarantees, exploiting the submodularity of the objective function. We demonstrate the advantages of our approach towards optimizing mutual information in a very extensive empirical study on two real-world data sets.},
journal = {J. Mach. Learn. Res.},
month = {jun},
pages = {235–284},
numpages = {50}
}

@article{Swarm-SLAM,
  title={Swarm slam: Challenges and perspectives},
  author={Kegeleirs, Miquel and Grisetti, Giorgio and Birattari, Mauro},
  journal={Frontiers in Robotics and AI},
  volume={8},
  pages={618268},
  year={2021},
  publisher={Frontiers Media SA}
}


@article{streeter2008online,
  title={An online algorithm for maximizing submodular functions},
  author={Streeter, Matthew and Golovin, Daniel},
  journal={Advances in Neural Information Processing Systems},
  volume={21},
  year={2008}
}


@article{streeter2009online,
  title={Online learning of assignments},
  author={Streeter, Matthew and Golovin, Daniel and Krause, Andreas},
  journal={Advances in neural information processing systems},
  volume={22},
  year={2009}
}


@ARTICLE{tohidi20,
  author={Tohidi, Ehsan and Amiri, Rouhollah and Coutino, Mario and Gesbert, David and Leus, Geert and Karbasi, Amin},
  journal={IEEE Signal Processing Magazine}, 
  title={Submodularity in Action: From Machine Learning to Signal Processing Applications}, 
  year={2020},
  volume={37},
  number={5},
  pages={120-133},
  doi={10.1109/MSP.2020.3003836}}

@inproceedings{mf,
author="Egbert Bakker and Lars Nyborg and Hans B. Pacejka",
journal="", 
publisher="SAE International",
title="Tyre Modelling for Use in Vehicle Dynamics Studies", 
booktitle="SAE Technical Paper",
year="1987",
month="02",
volume="",
pages="",
abstract="A new way of representing tyre data obtained from measurements in pure cornering and pure braking conditions has been developed in order to further improve the Dynamic Safety of vehicles. The method makes use of a formula with coefficients which describe some of the typifying quantities of a tyre, such as slip stiffnesses at zero slip and force and torque peak values. The formula is capable of describing the characteristics of side force, brake force and self aligning torque with great accuracy. This mathematical representation is limited to steady-state conditions during either pure cornering or pure braking and forms the basis for a model describing tyre behaviour during combined braking and cornering.",
number="",
doi="10.4271/870421"
} 


@article{Feige-no-other-effi-algo,
author = {Feige, Uriel},
title = {A Threshold of Ln n for Approximating Set Cover},
year = {1998},
issue_date = {July 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {4},
issn = {0004-5411},
url = {https://doi.org/10.1145/285055.285059},
doi = {10.1145/285055.285059},
abstract = {Given a collection ℱ of subsets of S = {1,…,n}, set cover is the problem of selecting as few as possible subsets from ℱ such that their union covers S,, and max k-cover is the problem of selecting k subsets from ℱ such that their union has maximum cardinality. Both these problems are NP-hard. We prove that (1 - o(1)) ln n is a threshold below which set cover cannot be approximated efficiently, unless NP has slightly superpolynomial time algorithms. This closes the gap (up to low-order terms) between the ratio of approximation achievable by the greedy alogorithm (which is (1 - o(1)) ln n), and provious results of Lund and Yanakakis, that showed hardness of approximation within a ratio of (log2 n) / 2 ≃0.72 ln n. For max k-cover, we show an approximation threshold of (1 - 1/e)(up to low-order terms), under assumption that P ≠ NP.},
journal = {J. ACM},
month = {jul},
pages = {634–652},
numpages = {19},
keywords = {approximation ratio, set cover}
}

@article{kakade2001natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  journal={Advances in neural information processing systems},
  volume={14},
  year={2001}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015},
  organization={PMLR}
}

@article{stobbe2010efficient,
  title={Efficient minimization of decomposable submodular functions},
  author={Stobbe, Peter and Krause, Andreas},
  journal={Advances in Neural Information Processing Systems},
  volume={23},
  year={2010}
}

@inproceedings{leskovec2007cost,
  title={Cost-effective outbreak detection in networks},
  author={Leskovec, Jure and Krause, Andreas and Guestrin, Carlos and Faloutsos, Christos and VanBriesen, Jeanne and Glance, Natalie},
  booktitle={Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={420--429},
  year={2007}
}


@inproceedings{kempe2003maximizing,
  title={Maximizing the spread of influence through a social network},
  author={Kempe, David and Kleinberg, Jon and Tardos, {\'E}va},
  booktitle={Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={137--146},
  year={2003}
}

@article{bhandari2019global,
  title={Global optimality guarantees for policy gradient methods},
  author={Bhandari, Jalaj and Russo, Daniel},
  journal={arXiv preprint arXiv:1906.01786},
  year={2019}
}

@inproceedings{iyer2013fast,
  title={Fast semidifferential-based submodular function optimization},
  author={Iyer, Rishabh and Jegelka, Stefanie and Bilmes, Jeff},
  booktitle={International Conference on Machine Learning},
  pages={855--863},
  year={2013},
  organization={PMLR}
}

@InProceedings{bai2018greed,
  title = {Greed is Still Good: Maximizing Monotone {S}ubmodular+{S}upermodular ({BP}) Functions},
  author = {Bai, Wenruo and Bilmes, Jeff},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {304--313},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher = {PMLR}
}

@inproceedings{gaon2020reinforcement,
  title={Reinforcement learning with non-markovian rewards},
  author={Gaon, Maor and Brafman, Ronen},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  pages={3980--3987},
  year={2020}
}

@inproceedings{de2013linear,
  title={Linear temporal logic and linear dynamic logic on finite traces},
  author={De Giacomo, Giuseppe and Vardi, Moshe Y},
  booktitle={IJCAI'13 Proceedings of the Twenty-Third international joint conference on Artificial Intelligence},
  pages={854--860},
  year={2013},
  organization={Association for Computing Machinery}
}

@inproceedings{brafman2018ltlf,
  title={LTLf/LDLf non-markovian rewards},
  author={Brafman, Ronen and De Giacomo, Giuseppe and Patrizi, Fabio},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  year={2018}
}

@article{iwata2008submodular,
  title={Submodular function minimization},
  author={Iwata, Satoru},
  journal={Mathematical Programming},
  volume={112},
  pages={45--64},
  year={2008},
  publisher={Springer}
}

@article{iyer2015polyhedral,
  title={Polyhedral aspects of submodularity, convexity and concavity},
  author={Iyer, Rishabh and Bilmes, Jeff},
  journal={arXiv preprint arXiv:1506.07329},
  year={2015}
}

@article{amir2005supermodularity,
  title={Supermodularity and complementarity in economics: An elementary survey},
  author={Amir, Rabah},
  journal={Southern Economic Journal},
  volume={71},
  number={3},
  pages={636--660},
  year={2005},
  publisher={Wiley Online Library}
}

@article{chambers2009supermodularity,
  title={Supermodularity and preferences},
  author={Chambers, Christopher P and Echenique, Federico},
  journal={Journal of Economic Theory},
  volume={144},
  number={3},
  pages={1004--1014},
  year={2009},
  publisher={Elsevier}
}

@article{prajapat2023submodular,
  title={Submodular Reinforcement Learning},
  author={Prajapat, Manish and Mutn{\`y}, Mojm{\'\i}r and Zeilinger, Melanie N and Krause, Andreas},
  journal={arXiv preprint arXiv:2307.13372},
  year={2023}
}

@article{narang2022interactive,
  title={Interactive combinatorial bandits: Balancing competitivity and complementarity},
  author={Narang, Adhyyan and Sadeghi, Omid and Ratliff, Lillian J and Fazel, Maryam and Bilmes, Jeff},
  journal={arXiv preprint arXiv:2207.03091},
  year={2022}
}

@article{chen2017interactive,
  title={Interactive submodular bandit},
  author={Chen, Lin and Krause, Andreas and Karbasi, Amin},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{gabillon2013adaptive,
  title={Adaptive submodular maximization in bandit setting},
  author={Gabillon, Victor and Kveton, Branislav and Wen, Zheng and Eriksson, Brian and Muthukrishnan, Shanmugavelayutham},
  journal={Advances in Neural Information Processing Systems},
  volume={26},
  year={2013}
}

@inproceedings{abel2021expressivity,
  title={On the Expressivity of {M}arkov Reward},
  author={Abel, David and Dabney, Will and Harutyunyan, Anna and Ho, Mark K and Littman, Michael and Precup, Doina and Singh, Satinder},
  booktitle={Advances in Neural Information Processing Systems},
  year={2021}
}

@inproceedings{hazan2019maxent,
  title={Provably Efficient Maximum Entropy Exploration},
  author={Hazan, Elad and Kakade, Sham and Singh, Karan and Van Soest, Abby},
  booktitle={International Conference on Machine Learning},
  year={2019}
}

@inproceedings{mutny2023active,
  title={Active exploration via experiment design in markov chains},
  author={Mutny, Mojmir and Janik, Tadeusz and Krause, Andreas},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={7349--7374},
  year={2023},
  organization={PMLR}
}

@inproceedings{tarbouriech2019active,
  title={Active exploration in markov decision processes},
  author={Tarbouriech, Jean and Lazaric, Alessandro},
  booktitle={The 22nd International Conference on Artificial Intelligence and Statistics},
  pages={974--982},
  year={2019},
  organization={PMLR}
}

@article{hussein2017imitation,
  title={Imitation learning: A survey of learning methods},
  author={Hussein, Ahmed and Gaber, Mohamed Medhat and Elyan, Eyad and Jayne, Chrisina},
  journal={ACM Computing Surveys (CSUR)},
  volume={50},
  number={2},
  pages={1--35},
  year={2017},
  publisher={ACM New York, NY, USA}
}

@article{osa2018algorithmic,
  title={An algorithmic perspective on imitation learning},
  author={Osa, Takayuki and Pajarinen, Joni and Neumann, Gerhard and Bagnell, J Andrew and Abbeel, Pieter and Peters, Jan and others},
  journal={Foundations and Trends{\textregistered} in Robotics},
  volume={7},
  number={1-2},
  pages={1--179},
  year={2018},
  publisher={Now Publishers, Inc.}
}

@article{state_marginal,
  title={Efficient exploration via state marginal matching},
  author={Lee, Lisa and Eysenbach, Benjamin and Parisotto, Emilio and Xing, Eric and Levine, Sergey and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1906.05274},
  year={2019}
}

@inproceedings{mutti2020intrinsically,
  title={An Intrinsically-Motivated Approach for Learning Highly Exploring and Fast Mixing Policies},
  author={Mutti, Mirco and Restelli, Marcello},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2020}
}

@inproceedings{mutti2021policy, 
  title={Task-Agnostic Exploration via Policy Gradient of a Non-Parametric State Entropy Estimate}, 
  booktitle={AAAI Conference on Artificial Intelligence}, 
  author={Mutti, Mirco and Pratissoli, Lorenzo and Restelli, Marcello}, 
  year={2021}, 
}

@inproceedings{seo2021state,
  title={State Entropy Maximization with Random Encoders for Efficient Exploration},
  author={Seo, Younggyo and Chen, Lili and Shin, Jinwoo and Lee, Honglak and Abbeel, Pieter and Lee, Kimin},
  booktitle={International Conference on Machine Learning},
  year={2021}
}

@inproceedings{yarats2021reinforcement,
  title={Reinforcement Learning with Prototypical Representations},
  author={Yarats, Denis and Fergus, Rob and Lazaric, Alessandro and Pinto, Lerrel},
  booktitle={International Conference on Machine Learning},
  year={2021}
}

@article{guo2021geometric,
  title={Geometric Entropic Exploration},
  author={Guo, Zhaohan Daniel and Azar, Mohammad Gheshlagi and Saade, Alaa and Thakoor, Shantanu and Piot, Bilal and Pires, Bernardo Avila and Valko, Michal and Mesnard, Thomas and Lattimore, Tor and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:2101.02055},
  year={2021}
}

@inproceedings{liu2021behavior,
  title={Behavior from the void: Unsupervised active pre-training},
  author={Liu, Hao and Abbeel, Pieter},
  booktitle={Advances in Neural Information Processing Systems},
  year={2021}
}

@inproceedings{mutti2022importance,
  title={The Importance of Non-Markovianity in Maximum State Entropy Exploration},
  author={Mutti, Mirco and De Santi, Riccardo and Restelli, Marcello},
  booktitle={International Conference on Machine Learning},
  year={2022}
}

@inproceedings{mutti2022unsupervised,
  title={Unsupervised reinforcement learning in multiple environments},
  author={Mutti, Mirco and Mancassola, Mattia and Restelli, Marcello},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2022}
}

@inproceedings{zhang2021exploration,
  title={Exploration by maximizing {R}{\'e}nyi entropy for reward-free {RL} framework},
  author={Zhang, Chuheng and Cai, Yuanying and Huang, Longbo and Li, Jian},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2021}
}

@inproceedings{abbeel2004apprenticeship,
  title={Apprenticeship learning via inverse reinforcement learning},
  author={Abbeel, Pieter and Ng, Andrew Y},
  booktitle={International Conference on Machine learning},
  year={2004}
}

@inproceedings{chow2015risk,
  title={Risk-sensitive and robust decision-making: a cvar optimization approach},
  author={Chow, Yinlam and Tamar, Aviv and Mannor, Shie and Pavone, Marco},
  booktitle={Advances in Neural Information Processing Systems},
  year={2015}
}

@inproceedings{tamar2015policy,
  title={Policy gradient for coherent risk measures},
  author={Tamar, Aviv and Chow, Yinlam and Ghavamzadeh, Mohammad and Mannor, Shie},
  booktitle={Advances in Neural Information Processing Systems},
  year={2015}
}

@article{chow2017risk,
  title={Risk-constrained reinforcement learning with percentile risk criteria},
  author={Chow, Yinlam and Ghavamzadeh, Mohammad and Janson, Lucas and Pavone, Marco},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={6070--6120},
  year={2017}
}

@inproceedings{ho2016generative,
  title={Generative adversarial imitation learning},
  author={Ho, Jonathan and Ermon, Stefano},
  booktitle={Advances in Neural Information Processing Systems},
  year={2016}
}

@inproceedings{kostrikov2019imitation,
  title={Imitation Learning via Off-Policy Distribution Matching},
  author={Kostrikov, Ilya and Nachum, Ofir and Tompson, Jonathan},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{ghasemipour2020divergence,
  title={A divergence minimization perspective on imitation learning methods},
  author={Ghasemipour, Seyed Kamyar Seyed and Zemel, Richard and Gu, Shixiang},
  booktitle={Conference on Robot Learning},
  year={2020}
}
  

@inproceedings{dadashi2020primal,
  title={Primal Wasserstein Imitation Learning},
  author={Dadashi, Robert and Hussenot, Leonard and Geist, Matthieu and Pietquin, Olivier},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{garcia2015comprehensive,
  title={A comprehensive survey on safe reinforcement learning},
  author={Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
  journal={Journal of Machine Learning Research},
  volume={16},
  number={1},
  pages={1437--1480},
  year={2015}
}

@article{skill_discovery,
  author    = {Karol Gregor and Danilo Rezende and Daan Wierstra},
  title     = {Variational Intrinsic Control},
  journal   = {International Conference on Learning Representations, Workshop Track},
  year      = {2017}
}

@inproceedings{eysenbach2018diversity,
  title={Diversity is All You Need: Learning Skills without a Reward Function},
  author={Eysenbach, Benjamin and Gupta, Abhishek and Ibarz, Julian and Levine, Sergey},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{hansen2019fast,
  title={Fast Task Inference with Variational Intrinsic Successor Features},
  author={Hansen, Steven and Dabney, Will and Barreto, Andre and Warde-Farley, David and Van de Wiele, Tom and Mnih, Volodymyr},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{sharma2020dynamics,
  title={Dynamics-Aware Unsupervised Discovery of Skills},
  author={Sharma, Archit and Gu, Shixiang and Levine, Sergey and Kumar, Vikash and Hausman, Karol},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{campos2020explore,
  title={Explore, discover and learn: Unsupervised discovery of state-covering skills},
  author={Campos, V{\'\i}ctor and Trott, Alexander and Xiong, Caiming and Socher, Richard and Gir{\'o}-i-Nieto, Xavier and Torres, Jordi},
  booktitle={International Conference on Machine Learning},
  year={2020}
}

@InProceedings{liu2021aps,
  title = {{APS}: Active Pretraining with Successor Features},
  author = {Liu, Hao and Abbeel, Pieter},
  booktitle = {International Conference on Machine Learning},
  year = {2021},
}

@inproceedings{he2022wasserstein,
  title={Wasserstein Unsupervised Reinforcement Learning},
  author={He, Shuncheng and Jiang, Yuhang and Zhang, Hongchang and Shao, Jianzhun and Ji, Xiangyang},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2022}
}

@article{zahavy2022discovering,
  title={Discovering Policies with DOMiNO: Diversity Optimization Maintaining Near Optimality},
  author={Zahavy, Tom and Schroecker, Yannick and Behbahani, Feryal and Baumli, Kate and Flennerhag, Sebastian and Hou, Shaobo and Singh, Satinder},
  journal={arXiv preprint arXiv:2205.13521},
  year={2022}
}

@book{altman1999constrained,
  title={Constrained Markov decision processes},
  author={Altman, Eitan},
  volume={7},
  year={1999},
  publisher={CRC Press}
}

@inproceedings{achiam2017constrained,
  title={Constrained policy optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  year={2017}
}

@inproceedings{qin2021density,
  title={Density constrained reinforcement learning},
  author={Qin, Zengyi and Chen, Yuxiao and Fan, Chuchu},
  booktitle={International Conference on Machine Learning},
  year={2021}
}

@inproceedings{bai2022achieving,
  title={Achieving zero constraint violation for constrained reinforcement learning via primal-dual approach},
  author={Bai, Qinbo and Bedi, Amrit Singh and Agarwal, Mridul and Koppel, Alec and Aggarwal, Vaneet},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2022}
}

@inproceedings{brantley2020constrained,
  title={Constrained episodic reinforcement learning in concave-convex and knapsack settings},
  author={Brantley, Kiant{\'e} and Dudik, Miro and Lykouris, Thodoris and Miryoosefi, Sobhan and Simchowitz, Max and Slivkins, Aleksandrs and Sun, Wen},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}

@inproceedings{constrained_mdp,
  title={Reinforcement learning with convex constraints},
  author={Miryoosefi, Sobhan and Brantley, Kiant{\'e} and Daume III, Hal and Dudik, Miro and Schapire, Robert E},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}

@article{zhang2020variational,
  title={Variational policy gradient method for reinforcement learning with general utilities},
  author={Zhang, Junyu and Koppel, Alec and Bedi, Amrit Singh and Szepesvari, Csaba and Wang, Mengdi},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={4572--4583},
  year={2020}
}

@article{kumar2022policy,
  title={Policy gradient for reinforcement learning with general utilities},
  author={Kumar, Navdeep and Wang, Kaixin and Levy, Kfir and Mannor, Shie},
  journal={arXiv preprint arXiv:2210.00991},
  year={2022}
}

@article{barakat2023reinforcement,
  title={Reinforcement Learning with General Utilities: Simpler Variance Reduction and Large State-Action Space},
  author={Barakat, Anas and Fatkhullin, Ilyas and He, Niao},
  journal={arXiv preprint arXiv:2306.01854},
  year={2023}
}

@inproceedings{zhang2022multi,
  title={Multi-agent reinforcement learning with general utilities via decentralized shadow reward actor-critic},
  author={Zhang, Junyu and Bedi, Amrit Singh and Wang, Mengdi and Koppel, Alec},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={8},
  pages={9031--9039},
  year={2022}
}

@inproceedings{geist2021concave,
  title={Concave Utility Reinforcement Learning: The Mean-field Game Viewpoint},
  author={Geist, Matthieu and P{\'e}rolat, Julien and Lauri{\`e}re, Mathieu and Elie, Romuald and Perrin, Sarah and Bachem, Oliver and Munos, R{\'e}mi and Pietquin, Olivier},
  booktitle={International Conference on Autonomous Agents and Multiagent Systems},
  year={2022}
}

@book{boyd2004convex,
  title={Convex optimization},
  author={Boyd, Stephen P and Vandenberghe, Lieven},
  year={2004},
  publisher={Cambridge university press}
}

@book{papadimitriou1998combinatorial,
  title={Combinatorial optimization: algorithms and complexity},
  author={Papadimitriou, Christos H and Steiglitz, Kenneth},
  year={1998},
  publisher={Courier Corporation}
}

@book{schrijver2003combinatorial,
  title={Combinatorial optimization: polyhedra and efficiency},
  author={Schrijver, Alexander and others},
  volume={24},
  number={2},
  year={2003},
  publisher={Springer}
}

@article{krause2011submodularity,
  title={Submodularity and its applications in optimized information gathering},
  author={Krause, Andreas and Guestrin, Carlos},
  journal={ACM Transactions on Intelligent Systems and Technology (TIST)},
  volume={2},
  number={4},
  pages={1--20},
  year={2011},
  publisher={ACM New York, NY, USA}
}

@article{lovasz1983submodular,
  title={Submodular functions and convexity},
  author={Lov{\'a}sz, L{\'a}szl{\'o}},
  journal={Mathematical Programming The State of the Art: Bonn 1982},
  pages={235--257},
  year={1983},
  publisher={Springer}
}

@article{gallo1989supermodular,
  title={On the supermodular knapsack problem},
  author={Gallo, Giorgio and Simeone, Bruno},
  journal={Mathematical Programming},
  volume={45},
  pages={295--309},
  year={1989},
  publisher={Springer}
}

@article{billionnet1985maximizing,
  title={Maximizing a supermodular pseudoboolean function: A polynomial algorithm for supermodular cubic functions},
  author={Billionnet, Alain and Minoux, Michel},
  journal={Discrete Applied Mathematics},
  volume={12},
  number={1},
  pages={1--11},
  year={1985},
  publisher={Elsevier}
}

@inproceedings{ji2019stochastic,
  title={Stochastic greedy algorithm is still good: maximizing submodular+ supermodular functions},
  author={Ji, Sai and Xu, Dachuan and Li, Min and Wang, Yishui and Zhang, Dongmei},
  booktitle={World Congress on Global Optimization},
  pages={488--497},
  year={2019},
  organization={Springer}
}

@article{krause2012near,
  title={Near-optimal nonmyopic value of information in graphical models},
  author={Krause, Andreas and Guestrin, Carlos E},
  journal={arXiv preprint arXiv:1207.1394},
  year={2012}
}

@article{fujishige2011submodular,
  title={A submodular function minimization algorithm based on the minimum-norm base},
  author={Fujishige, Satoru and Isotani, Shigueo},
  journal={Pacific Journal of Optimization},
  volume={7},
  number={1},
  pages={3--17},
  year={2011},
  publisher={Citeseer}
}

@article{iyer2012submodular,
  title={Submodular-Bregman and the Lov{\'a}sz-Bregman divergences with applications},
  author={Iyer, Rishabh and Bilmes, Jeff A},
  journal={Advances in Neural Information Processing Systems},
  volume={25},
  year={2012}
}

@article{yue2011linear,
  title={Linear submodular bandits and their application to diversified retrieval},
  author={Yue, Yisong and Guestrin, Carlos},
  journal={Advances in Neural Information Processing Systems},
  volume={24},
  year={2011}
}

@inproceedings{takemori2020submodular,
  title={Submodular bandit problem under multiple constraints},
  author={Takemori, Sho and Sato, Masahiro and Sonoda, Takashi and Singh, Janmajay and Ohkuma, Tomoko},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  pages={191--200},
  year={2020},
  organization={PMLR}
}

@article{chen2018contextual,
  title={Contextual combinatorial multi-armed bandits with volatile arms and submodular reward},
  author={Chen, Lixing and Xu, Jie and Lu, Zhuo},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{yu2016linear,
  title={Linear submodular bandits with a knapsack constraint},
  author={Yu, Baosheng and Fang, Meng and Tao, Dacheng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={30},
  number={1},
  year={2016}
}

@article{zhang2019online,
  title={Online continuous submodular maximization: From full-information to bandit feedback},
  author={Zhang, Mingrui and Chen, Lin and Hassani, Hamed and Karbasi, Amin},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{hiranandani2020cascading,
  title={Cascading linear submodular bandits: Accounting for position bias and diversity in online learning to rank},
  author={Hiranandani, Gaurush and Singh, Harvineet and Gupta, Prakhar and Burhanuddin, Iftikhar Ahamath and Wen, Zheng and Kveton, Branislav},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={722--732},
  year={2020},
  organization={PMLR}
}

@inproceedings{nie2022explore,
  title={An explore-then-commit algorithm for submodular maximization under full-bandit feedback},
  author={Nie, Guanyu and Agarwal, Mridul and Umrawal, Abhishek Kumar and Aggarwal, Vaneet and Quinn, Christopher John},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={1541--1551},
  year={2022},
  organization={PMLR}
}

@article{das2011submodular,
  title={Submodular meets spectral: Greedy algorithms for subset selection, sparse approximation and dictionary selection},
  author={Das, Abhimanyu and Kempe, David},
  journal={arXiv preprint arXiv:1102.3975},
  year={2011}
}

@inproceedings{brafman2019regular,
  title={Regular Decision Processes: A Model for Non-Markovian Domains.},
  author={Brafman, Ronen I and De Giacomo, Giuseppe and others},
  booktitle={IJCAI},
  pages={5516--5522},
  year={2019}
}

@article{iyer2012algorithms,
  title={Algorithms for approximate minimization of the difference between submodular functions, with applications},
  author={Iyer, Rishabh and Bilmes, Jeff},
  journal={arXiv preprint arXiv:1207.0560},
  year={2012}
}

@article{bach2013learning,
  title={Learning with submodular functions: A convex optimization perspective},
  author={Bach, Francis and others},
  journal={Foundations and Trends{\textregistered} in machine learning},
  volume={6},
  number={2-3},
  pages={145--373},
  year={2013},
  publisher={Now Publishers, Inc.}
}

@inproceedings{mitrovic2018submodularity,
  title={Submodularity on hypergraphs: From sets to sequences},
  author={Mitrovic, Marko and Feldman, Moran and Krause, Andreas and Karbasi, Amin},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1177--1184},
  year={2018},
  organization={PMLR}
}

@article{karlin1966optimal,
  title={Optimal experimental designs},
  author={Karlin, Samuel and Studden, William J},
  journal={The Annals of Mathematical Statistics},
  volume={37},
  number={4},
  pages={783--815},
  year={1966},
  publisher={JSTOR}
}

@article{clark2013supermodular,
  title={A supermodular optimization framework for leader selection under link noise in linear multi-agent systems},
  author={Clark, Andrew and Bushnell, Linda and Poovendran, Radha},
  journal={IEEE Transactions on Automatic Control},
  volume={59},
  number={2},
  pages={283--296},
  year={2013},
  publisher={IEEE}
}

@article{clark2014minimizing,
  title={Minimizing convergence error in multi-agent systems via leader selection: A supermodular optimization approach},
  author={Clark, Andrew and Alomair, Basel and Bushnell, Linda and Poovendran, Radha},
  journal={IEEE Transactions on Automatic Control},
  volume={59},
  number={6},
  pages={1480--1494},
  year={2014},
  publisher={IEEE}
}

@article{laskin2021urlb,
  title={URLB: Unsupervised reinforcement learning benchmark},
  author={Laskin, Michael and Yarats, Denis and Liu, Hao and Lee, Kimin and Zhan, Albert and Lu, Kevin and Cang, Catherine and Pinto, Lerrel and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2110.15191},
  year={2021}
}

@article{vcerny2012two,
  title={Two complexity results on c-optimality in experimental design},
  author={{\v{C}}ern{\`y}, Michal and Hlad{\'\i}k, Milan},
  journal={Computational Optimization and Applications},
  volume={51},
  number={3},
  pages={1397--1408},
  year={2012},
  publisher={Springer}
}

@article{bellman1966dynamic,
  title={Dynamic programming},
  author={Bellman, Richard},
  journal={Science},
  volume={153},
  number={3731},
  pages={34--37},
  year={1966},
  publisher={American Association for the Advancement of Science}
}

@article{thiede2022curiosity,
  title={Curiosity in exploring chemical spaces: intrinsic rewards for molecular reinforcement learning},
  author={Thiede, Luca A and Krenn, Mario and Nigam, AkshatKumar and Aspuru-Guzik, Alan},
  journal={Machine Learning: Science and Technology},
  volume={3},
  number={3},
  pages={035008},
  year={2022},
  publisher={IOP Publishing}
}

@article{narasimhan2012submodular,
  title={A submodular-supermodular procedure with applications to discriminative structure learning},
  author={Narasimhan, Mukund and Bilmes, Jeff A},
  journal={arXiv preprint arXiv:1207.1404},
  year={2012}
}

@book{rasmussen2006gaussian,
  title={Gaussian processes for machine learning},
  author={Rasmussen, Carl Edward and Williams, Christopher KI and others},
  volume={1},
  year={2006},
  publisher={Springer}
}


@article{CONFORTI1984251,
title = {Submodular set functions, matroids and the greedy algorithm: Tight worst-case bounds and some generalizations of the Rado-Edmonds theorem},
journal = {Discrete Applied Mathematics},
volume = {7},
number = {3},
pages = {251-274},
year = {1984},
issn = {0166-218X},
author = {Michele Conforti and Gérard Cornuéjols},
}

@inproceedings{zhang2016submodular,
  title={Submodular optimization with routing constraints},
  author={Zhang, Haifeng and Vorobeychik, Yevgeniy},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={30},
  number={1},
  year={2016}
}


@article{wang2020planning,
  title={Planning with Submodular Objective Functions},
  author={Wang, Ruosong and Zhang, Hanrui and Chaplot, Devendra Singh and Garagi{\'c}, Denis and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2010.11863},
  year={2020}
}

@article{sutton1999policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
  journal={Advances in neural information processing systems},
  volume={12},
  year={1999}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@article{agarwal2019reinforcement,
  title={Reinforcement learning: Theory and algorithms},
  author={Agarwal, Alekh and Jiang, Nan and Kakade, Sham M and Sun, Wen},
  journal={CS Dept., UW Seattle, Seattle, WA, USA, Tech. Rep},
  volume={32},
  pages={96},
  year={2019}
}