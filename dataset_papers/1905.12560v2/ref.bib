@article{keriven2019universal,
  title={Universal invariant and equivariant graph neural networks},
  author={Keriven, Nicolas and Peyr{\'e}, Gabriel},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@InProceedings{maron2019universality,
  title = 	 {On the Universality of Invariant Networks},
  author =       {Maron, Haggai and Fetaya, Ethan and Segol, Nimrod and Lipman, Yaron},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {4363--4371},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/maron19a/maron19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/maron19a.html},
  abstract = 	 {Constraining linear layers in neural networks to respect symmetry transformations from a group $G$ is a common design principle for invariant networks that has found many applications in machine learning. 		 In this paper, we consider a fundamental question that has received very little attention to date: Can these networks approximate any (continuous) invariant function? 		 We tackle the rather general case where $G\leq S_n$ (an arbitrary subgroup of the symmetric group) that acts on $\R^n$ by permuting coordinates. This setting includes several recent popular invariant networks. We present two main results: First, $G$-invariant networks are universal if high-order tensors are allowed. Second, there are groups $G$ for which higher-order tensors are unavoidable for obtaining universality. 		 $G$-invariant networks consisting of only first-order tensors are of special interest due to their practical value. We conclude the paper by proving a necessary condition for the universality of $G$-invariant networks that incorporate only first-order tensors. Lastly, we propose a conjecture stating that this condition is also sufficient.}
}


@article{von2007tutorial,
  title={A tutorial on spectral clustering},
  author={Von Luxburg, Ulrike},
  journal={Statistics and computing},
  volume={17},
  number={4},
  pages={395--416},
  year={2007},
  publisher={Springer}
}

@inproceedings{
maron2018invariant,
title={Invariant and Equivariant Graph Networks},
author={Haggai Maron and Heli Ben-Hamu and Nadav Shamir and Yaron Lipman},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=Syx72jC9tm},
}

@inproceedings{
xu2018powerful,
title={How Powerful are Graph Neural Networks?},
author={Keyulu Xu and Weihua Hu and Jure Leskovec and Stefanie Jegelka},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=ryGs6iA5Km},
}

@inproceedings{nowak2017note,
  title={Revised note on learning quadratic assignment with graph neural networks},
  author={Nowak, Alex and Villar, Soledad and Bandeira, Afonso S and Bruna, Joan},
  booktitle={2018 IEEE Data Science Workshop (DSW)},
  pages={1--5},
  year={2018},
  organization={IEEE}
}

@article{weisfeiler1968reduction,
  title={The reduction of a graph to canonical form and the algebra which appears therein},
  author={Weisfeiler, B and Leman, A},
  journal={Nauchno-Technicheskaya Informatsia},
  year={1968},
  volume={2(9):12-16}
}

@inproceedings{duvenaud2015convolutional,
  title={Convolutional networks on graphs for learning molecular fingerprints},
  author={Duvenaud, David K and Maclaurin, Dougal and Iparraguirre, Jorge and Bombarell, Rafael and Hirzel, Timothy and Aspuru-Guzik, Al{\'a}n and Adams, Ryan P},
  booktitle={Advances in neural information processing systems},
  pages={2224--2232},
  year={2015}
}

@inproceedings{
kipf2016semi,
title={Semi-Supervised Classification with Graph Convolutional Networks},
author={Thomas N. Kipf and Max Welling},
booktitle={International Conference on Learning Representations},
year={2017},
url={https://openreview.net/forum?id=SJU4ayYgl}
}

@inproceedings{gilmer2017neural,
  title={Neural message passing for quantum chemistry},
  author={Gilmer, Justin and Schoenholz, Samuel S and Riley, Patrick F and Vinyals, Oriol and Dahl, George E},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1263--1272},
  year={2017},
  organization={JMLR. org}
}

@article{hamilton2017representation,
  title={Representation learning on graphs: Methods and applications},
  author={Hamilton, William L and Ying, Rex and Leskovec, Jure},
  journal={arXiv preprint arXiv:1709.05584},
  year={2017}
}

@inproceedings{
velickovic2017graph,
title={Graph Attention Networks},
author={Petar Veličković and Guillem Cucurull and Arantxa Casanova and Adriana Romero and Pietro Liò and Yoshua Bengio},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=rJXMpikCZ},
}

@article{scarselli2008graph,
  title={The graph neural network model},
  author={Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
  journal={IEEE Transactions on Neural Networks},
  volume={20},
  number={1},
  pages={61--80},
  year={2008},
  publisher={IEEE}
}

@inproceedings{hamilton2017inductive,
  title={Inductive representation learning on large graphs},
  author={Hamilton, Will and Ying, Zhitao and Leskovec, Jure},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1024--1034},
  year={2017}
}

@article{wu2019comprehensive,
  title={A comprehensive survey on graph neural networks},
  author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Philip, S Yu},
  journal={IEEE transactions on neural networks and learning systems},
  volume={32},
  number={1},
  pages={4--24},
  year={2020},
  publisher={IEEE}
}

@article{cybenko1989approximation,
  title={Approximation by superpositions of a sigmoidal function},
  author={Cybenko, George},
  journal={Mathematics of control, signals and systems},
  volume={2},
  number={4},
  pages={303--314},
  year={1989},
  publisher={Springer}
}

@inproceedings{herzig2018mapping,
  title={Mapping images to scene graphs with permutation-invariant structured prediction},
  author={Herzig, Roei and Raboh, Moshiko and Chechik, Gal and Berant, Jonathan and Globerson, Amir},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7211--7221},
  year={2018}
}

@inproceedings{murphy2019relational,
  title={Relational pooling for graph representations},
  author={Murphy, Ryan and Srinivasan, Balasubramaniam and Rao, Vinayak and Ribeiro, Bruno},
  booktitle={International Conference on Machine Learning},
  pages={4663--4673},
  year={2019},
  organization={PMLR}
}

@article{morris2019higher,
  title={Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks},
  author={Morris, Christopher and Ritzert, Martin and Fey, Matthias and Hamilton, William L and Lenssen, Jan Eric and Rattan, Gaurav and Grohe, Martin},
  journal={Association for the Advancement of Artificial Intelligence},
  year={2019}
}

@article{bloemreddy2019probabilistic,
  title={Probabilistic symmetries and invariant neural networks},
  author={Bloem-Reddy, Benjamin and Teh, Yee Whye},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={3535--3595},
  year={2020},
  publisher={JMLRORG}
}

@article{yarotsky2018universal,
  title={Universal approximations of invariant maps by neural networks},
  author={Yarotsky, Dmitry},
  journal={Constructive Approximation},
  volume={55},
  number={1},
  pages={407--474},
  year={2022},
  publisher={Springer}
}

@article{ravanbakhsh2017sharing,
  title={Equivariance Through Parameter-Sharing},
  author={Ravanbakhsh, Siamak and Schneider, Jeff and Poczos, Barnabas},
  journal={Proceedings of the 34th International Conference on Machine Learning},
  year={2017}
}

@article{kondor2018convolution,
  title={On the Generalization of Equivariance and Convolution in Neural Networks to the Action of Compact Groups},
  author={Kondor, Risi and Trivedi, Shubhendu},
  journal={Proceedings of the 35th International Conference on Machine Learning},
  year={2018}
}

@article{chen2019cdsbm,
  title={Supervised Community Detection with Line Graph Neural Networks},
  author={Chen, Zhengdao and Li, Lisha and Bruna, Joan},
  journal={Internation Conference on Learning Representations},
  year={2019}
}

@article{hornik1991hornik,
  title={Approximation Capabilities of Multilayer Feedforward Networks},
  author={Hornik, Kurt},
  journal={Neural Networks},
  volume={4},
  pages={251--257},
  year={1991},
  publisher={Pergamon Press}
}

@article{ramana1994fractional,
  title={Fractional isomorphism of graphs},
  author={Ramana, Motakuri V and Scheinerman, Edward R and Ullman, Daniel},
  journal={Discrete Mathematics},
  volume={132},
  number={1-3},
  pages={247--265},
  year={1994},
  publisher={Elsevier}
}


@article{zhao1998semidefinite,
  title={Semidefinite programming relaxations for the quadratic assignment problem},
  author={Zhao, Qing and Karisch, Stefan E and Rendl, Franz and Wolkowicz, Henry},
  journal={Journal of Combinatorial Optimization},
  volume={2},
  number={1},
  pages={71--109},
  year={1998},
  publisher={Springer}
}
@inproceedings{o2014hardness,
  title={Hardness of robust graph isomorphism, Lasserre gaps, and asymmetry of random graphs},
  author={O'Donnell, Ryan and Wright, John and Wu, Chenggang and Zhou, Yuan},
  booktitle={Proceedings of the twenty-fifth annual ACM-SIAM symposium on Discrete algorithms},
  pages={1659--1677},
  year={2014},
  organization={Society for Industrial and Applied Mathematics}
}

@article{cai1992optimal,
  title={An optimal lower bound on the number of variables for graph identification},
  author={Cai, Jin-Yi and F{\"u}rer, Martin and Immerman, Neil},
  journal={Combinatorica},
  volume={12},
  number={4},
  pages={389--410},
  year={1992},
  publisher={Springer}
}

@inproceedings{yanardag2015deep,
 title={Deep graph kernels},
 author={Yanardag, Pinar and Vishwanathan, SVN},
 booktitle={Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
 pages={1365--1374},
 year={2015},
 organization={ACM}
}

@inproceedings{babai2016graph,
  title={Graph isomorphism in quasipolynomial time},
  author={Babai, L{\'a}szl{\'o}},
  booktitle={Proceedings of the forty-eighth annual ACM symposium on Theory of Computing},
  pages={684--697},
  year={2016},
  organization={ACM}
}

@article{bronstein2017geometric, 
author={M. M. {Bronstein} and J. {Bruna} and Y. {LeCun} and A. {Szlam} and P. {Vandergheynst}}, 
journal={IEEE Signal Processing Magazine}, 
title={Geometric Deep Learning: Going beyond Euclidean data}, 
year={2017}, 
volume={34}, 
number={4}, 
pages={18-42}, 
keywords={computational geometry;neural nets;geometric deep learning;Euclidean data;deep neural models;Convolution;Computational modeling;Euclidean distance;Machine learning;Convolutional codes;Social network services;Computer architecture}, 
doi={10.1109/MSP.2017.2693418}, 
ISSN={1053-5888}, 
month={July},}

@article{krzakala2013spectral,
  title={Spectral redemption in clustering sparse networks},
  author={Krzakala, Florent and Moore, Cristopher and Mossel, Elchanan and Neeman, Joe and Sly, Allan and Zdeborov{\'a}, Lenka and Zhang, Pan},
  journal={Proceedings of the National Academy of Sciences},
  volume={110},
  number={52},
  pages={20935--20940},
  year={2013},
  publisher={National Acad Sciences}
}

@article{maron2019provably,
  title={Provably powerful graph networks},
  author={Maron, Haggai and Ben-Hamu, Heli and Serviansky, Hadar and Lipman, Yaron},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{kondor2018covariant,
  title={Covariant compositional networks for learning graphs},
  author={Hy, Truong Son and Trivedi, Shubhendu and Pan, Horace and Anderson, Brandon M and Kondor, Risi},
  booktitle={Proc. International Workshop on Mining and Learning with Graphs (MLG)},
  year={2019}
}

@inproceedings{
liao2018lanczosnet,
title={LanczosNet: Multi-Scale Deep Graph Convolutional Networks},
author={Renjie Liao and Zhizhen Zhao and Raquel Urtasun and Richard Zemel},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=BkedznAqKQ},
}


@incollection{ying2018hierarchical,
	Author = {Ying, Zhitao and You, Jiaxuan and Morris, Christopher and Ren, Xiang and Hamilton, Will and Leskovec, Jure},
	Booktitle = {Advances in Neural Information Processing Systems 31},
	Editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
	Pages = {4800--4810},
	Publisher = {Curran Associates, Inc.},
	Title = {Hierarchical Graph Representation Learning with Differentiable Pooling},
	Url = {http://papers.nips.cc/paper/7729-hierarchical-graph-representation-learning-with-differentiable-pooling.pdf},
	Year = {2018},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/7729-hierarchical-graph-representation-learning-with-differentiable-pooling.pdf}}
	


@InProceedings{you2019pgnn,
  title = 	 {Position-aware Graph Neural Networks},
  author = 	 {You, Jiaxuan and Ying, Rex and Leskovec, Jure},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {7134--7143},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  pdf = 	 {http://proceedings.mlr.press/v97/you19b/you19b.pdf},
  url = 	 {http://proceedings.mlr.press/v97/you19b.html},
}

@inproceedings{kingma2014adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6980},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{xu2018representation,
  title={Representation learning on graphs with jumping knowledge networks},
  author={Xu, Keyulu and Li, Chengtao and Tian, Yonglong and Sonobe, Tomohiro and Kawarabayashi, Ken-ichi and Jegelka, Stefanie},
  booktitle={International conference on machine learning},
  pages={5453--5462},
  year={2018},
  organization={PMLR}
}

@book{bartle2014elements,
  title={The elements of integration and Lebesgue measure},
  author={Bartle, Robert G},
  year={2014},
  publisher={John Wiley \& Sons}
}

@article{tinhofer1986graph,
  title={Graph isomorphism and theorems of Birkhoff type},
  author={Tinhofer, Gottfried},
  journal={Computing (Wien. Print)},
  volume={36},
  number={4},
  pages={285--300},
  year={1986}
}

@article{tinhofer1991note,
author = {Tinhofer, G.},
title = {A Note on Compact Graphs},
year = {1991},
issue_date = {February 1991},
publisher = {Elsevier Science Publishers B. V.},
address = {NLD},
volume = {30},
number = {2},
issn = {0166-218X},
abstract = {An undirected simple graph G is called compact iff its adjacency matrix A is such that the polytope S(A) of doubly stochastic matrices X which commute with A has integral-valued extremal points only. We show that the isomorphism problem for compact graphs is polynomial. Furthermore, we prove that if a graph G is compact, then a certain naive polynomial heuristic applied to G and any partner G decides correctly whether G and G are isomorphic or not. In the last section we discuss some compactness preserving operations on graphs.},
journal = {Discrete Appl. Math.},
month = {feb},
pages = {253–264},
numpages = {12}
}

@article{chen2020can,
  title={Can graph neural networks count substructures?},
  author={Chen, Zhengdao and Chen, Lei and Villar, Soledad and Bruna, Joan},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={10383--10395},
  year={2020}
}


@article{geerts2022expressiveness,
  title={Expressiveness and approximation properties of graph neural networks},
  author={Geerts, Floris and Reutter, Juan L},
  journal={arXiv preprint arXiv:2204.04661},
  year={2022}
}

@article{geerts2020expressive,
  title={The expressive power of kth-order invariant graph networks},
  author={Geerts, Floris},
  journal={arXiv preprint arXiv:2007.12035},
  year={2020}
}

@article{furer2010combinatorial,
title = {On the power of combinatorial and spectral invariants},
journal = {Linear Algebra and its Applications},
volume = {432},
number = {9},
pages = {2373-2380},
year = {2010},
note = {Special Issue devoted to Selected Papers presented at the Workshop on Spectral Graph Theory with Applications on Computer Science, Combinatorial Optimization and Chemistry (Rio de Janeiro, 2008)},
issn = {0024-3795},
doi = {https://doi.org/10.1016/j.laa.2009.07.019},
url = {https://www.sciencedirect.com/science/article/pii/S0024379509003620},
author = {Martin Fürer},
keywords = {Edge coloring, 2-dim W-L, Spectral properties, Starlike trees},
abstract = {We extend the traditional spectral invariants (spectrum and angles) by a stronger polynomial time computable graph invariant based on the angles between projections of standard basis vectors into the eigenspaces (in addition to the usual angles between standard basis vectors and eigenspaces). The exact power of the new invariant is still an open problem. We also define combinatorial invariants based on standard graph isomorphism heuristics and compare their strengths with the spectral invariants. In particular, we show that a simple edge coloring invariant is at least as powerful as all these spectral invariants.}
}


@inbook{rattan2023spectra,
author = {Gaurav Rattan and Tim Seppelt},
title = {Weisfeiler-Leman and Graph Spectra},
booktitle = {Proceedings of the 2023 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
chapter = {},
year={2023},
publisher={SODA},
pages = {2268-2285},
doi = {10.1137/1.9781611977554.ch87},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch87},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611977554.ch87},
    abstract = { Two simple undirected graphs are cospectral if their respective adjacency matrices have the same multiset of eigenvalues. Cospectrality yields an equivalence relation on the family of graphs which is provably weaker than isomorphism. In this paper, we study cospectrality in relation to another well-studied relaxation of isomorphism, namely k-dimensional Weisfeiler-Leman (k-WL) indistinguishability. Cospectrality with respect to standard graph matrices such as the adjacency or the Laplacian matrix yields a strictly finer equivalence relation than 2-WL indistinguishability. We show that individualising one vertex plus running 1-WL already subsumes cospectrality with respect to all such graph matrices. Building on this result, we resolve an open problem of Fürer (2010) about spectral invariants and strengthen a result of Godsil (1981) about commute distances. Looking beyond 2-WL, we devise a hierarchy of graph matrices generalising the adjacency matrix such that k-WL indistinguishability after a fixed number of iterations can be captured as a spectral condition on these matrices. Precisely, we provide a spectral characterisation of k-WL indistinguishability after d iterations, for k,d ∈ ℕ. Our results can be viewed as characterisations of homomorphism indistinguishability over certain graph classes in terms of matrix equations. The study of homomorphism indistinguishability is an emerging field, to which we contribute by extending the algebraic framework of Mančinska and Roberson (2020) and Grohe et al. (2022). * The full version [45] of the paper can be accessed at https://arxiv.org/abs/2103.02972 }
}

@inproceedings{coppersmith1987arithmetic,
author = {Coppersmith, D. and Winograd, S.},
title = {Matrix Multiplication via Arithmetic Progressions},
year = {1987},
isbn = {0897912217},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/28395.28396},
doi = {10.1145/28395.28396},
abstract = {We present a new method for accelerating matrix multiplication asymptotically. This work builds on recent ideas of Volker Strassen, by using a basic trilinear form which is not a matrix product. We make novel use of the Salem-Spencer Theorem, which gives a fairly dense set of integers with no three-term arithmetic progression. Our resulting matrix exponent is 2.376.},
booktitle = {Proceedings of the Nineteenth Annual ACM Symposium on Theory of Computing},
pages = {1–6},
numpages = {6},
location = {New York, New York, USA},
series = {STOC '87}
}

@article{gama2020stability,
  title={Stability properties of graph neural networks},
  author={Gama, Fernando and Bruna, Joan and Ribeiro, Alejandro},
  journal={IEEE Transactions on Signal Processing},
  volume={68},
  pages={5680--5695},
  year={2020},
  publisher={IEEE}
}

@inproceedings{gama2019stability,
 author = {Gama, Fernando and Ribeiro, Alejandro and Bruna, Joan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Stability of Graph Scattering Transforms},
 url = {https://proceedings.neurips.cc/paper/2019/file/3ce3bd7d63a2c9c81983cc8e9bd02ae5-Paper.pdf},
 volume = {32},
 year = {2019}
}

@article{babai1980random,
  title={Random graph isomorphism},
  author={Babai, L{\'a}szl{\'o} and Erdos, Paul and Selkow, Stanley M},
  journal={SIaM Journal on computing},
  volume={9},
  number={3},
  pages={628--635},
  year={1980},
  publisher={SIAM}
}

@inproceedings{zhang2017wlnm,
author = {Zhang, Muhan and Chen, Yixin},
title = {Weisfeiler-Lehman Neural Machine for Link Prediction},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3097996},
doi = {10.1145/3097983.3097996},
abstract = {In this paper, we propose a next-generation link prediction method, Weisfeiler-Lehman Neural Machine (WLNM), which learns topological features in the form of graph patterns that promote the formation of links. WLNM has unmatched advantages including higher performance than state-of-the-art methods and universal applicability over various kinds of networks. WLNM extracts an enclosing subgraph of each target link and encodes the subgraph as an adjacency matrix. The key novelty of the encoding comes from a fast hashing-based Weisfeiler-Lehman (WL) algorithm that labels the vertices according to their structural roles in the subgraph while preserving the subgraph's intrinsic directionality. After that, a neural network is trained on these adjacency matrices to learn a predictive model. Compared with traditional link prediction methods, WLNM does not assume a particular link formation mechanism (such as common neighbors), but learns this mechanism from the graph itself. We conduct comprehensive experiments to show that WLNM not only outperforms a great number of state-of-the-art link prediction methods, but also consistently performs well across networks with different characteristics.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {575–583},
numpages = {9},
keywords = {neural network, color refinement, graph labeling, link prediction},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@inproceedings{wang2022powerful,
  title={How powerful are spectral graph neural networks},
  author={Wang, Xiyuan and Zhang, Muhan},
  booktitle={International Conference on Machine Learning},
  pages={23341--23362},
  year={2022},
  organization={PMLR}
}

@inproceedings{
azizian2021expressive,
title={Expressive Power of Invariant and Equivariant Graph Neural Networks},
author={Waiss Azizian and Marc Lelarge},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=lxHgXYN4bwl}
}