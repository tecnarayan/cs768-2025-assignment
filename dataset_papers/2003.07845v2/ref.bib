@inproceedings{ma2019tensorized,
  title={A tensorized transformer for language modeling},
  author={Ma, Xindian and Zhang, Peng and Zhang, Shuai and Duan, Nan and Hou, Yuexian and Zhou, Ming and Song, Dawei},
  booktitle=nips,
  year={2019}
}
@inproceedings{wang2019learning,
  title={Learning Deep Transformer Models for Machine Translation},
  author={Wang, Qiang and Li, Bei and Xiao, Tong and Zhu, Jingbo and Li, Changliang and Wong, Derek F and Chao, Lidia S},
  booktitle=acl,
  year={2019}
}

@inproceedings{
gao2019representation,
title={Representation Degeneration Problem in Training Natural Language Generation Models},
author={Jun Gao and Di He and Xu Tan and Tao Qin and Liwei Wang and Tieyan Liu},
booktitle=iclr,
year={2019},
}


@inproceedings{sennrich2016neural,
  title={Neural Machine Translation of Rare Words with Subword Units},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  booktitle=acl,
  year={2016}
}


@inproceedings{hou2019normalization,
  title={Normalization Helps Training of Quantized LSTM},
  author={Hou, Lu and Zhu, Jinhua and Kwok, James and Gao, Fei and Qin, Tao and Liu, Tie-yan},
  booktitle=nips,
  year={2019}
}

@inproceedings{inan2016tying,
  title={Tying word vectors and word classifiers: A loss framework for language modeling},
  author={Inan, Hakan and Khosravi, Khashayar and Socher, Richard},
  booktitle=iclr,
  year={2017}
}

@inproceedings{
baevski2018adaptive,
title={Adaptive Input Representations for Neural Language Modeling},
author={Alexei Baevski and Michael Auli},
booktitle=iclr,
year={2019},
}



@inproceedings{yang2017breaking,
  title={Breaking the softmax bottleneck: A high-rank RNN language model},
  author={Yang, Zhilin and Dai, Zihang and Salakhutdinov, Ruslan and Cohen, William W},
 booktitle=iclr,
  year={2018}
}

@inproceedings{dai2019transformer,
  title={Transformer-XL: Attentive Language Models beyond a Fixed-Length Context},
  author={Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime G and Le, Quoc and Salakhutdinov, Ruslan},
  booktitle=acl,
  year={2019}
}


@inproceedings{ott2018scaling,
  title={Scaling Neural Machine Translation},
  author={Ott, Myle and Edunov, Sergey and Grangier, David and Auli, Michael},
  booktitle={Machine Translation},
  year={2018}
}


@inproceedings{zhang2019improving,
  title={Improving Deep Transformer with Depth-Scaled Initialization and Merged Attention},
  author={Zhang, Biao and Titov, Ivan and Sennrich, Rico},
  booktitle=emnlp,
  year={2019}
}

@inproceedings{ott2019fairseq,
  title = {fairseq: A Fast, Extensible Toolkit for Sequence Modeling},
  author = {Myle Ott and Sergey Edunov and Alexei Baevski and Angela Fan and Sam Gross and Nathan Ng and David Grangier and Michael Auli},
  booktitle = {NAACL: Demonstrations},
  year = {2019},
}



@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle=cvpr,
  year={2016}
}

@article{zagoruyko2016wide,
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1605.07146},
  year={2016}
}



@article{devarakonda2017adabatch,
  title={AdaBatch: Adaptive Batch Sizes for Training Deep Neural Networks},
  author={Devarakonda, Aditya and Naumov, Maxim and Garland, Michael},
  journal={arXiv preprint arXiv:1712.02029},
  year={2017}
}


@article{zhu2018anisotropic,
  title={The Anisotropic Noise in Stochastic Gradient Descent: Its Behavior of Escaping from Minima and Regularization Effects},
  author={Zhu, Zhanxing and Wu, Jingfeng and Yu, Bing and Wu, Lei and Ma, Jinwen},
  journal={arXiv preprint arXiv:1803.00195},
  year={2018}
}


@article{balles2016coupling,
  title={Coupling adaptive batch sizes with learning rates},
  author={Balles, Lukas and Romero, Javier and Hennig, Philipp},
  journal={arXiv preprint arXiv:1612.05086},
  year={2016}
}

@inproceedings{hoffer2017train,
  title={Train longer, generalize better: closing the generalization gap in large batch training of neural networks},
  author={Hoffer, Elad and Hubara, Itay and Soudry, Daniel},
  booktitle=nips,
  year={2017}
}

@article{you2017scaling,
  title={Scaling sgd batch size to 32k for imagenet training},
  author={You, Yang and Gitman, Igor and Ginsburg, Boris},
  journal={arXiv preprint arXiv:1708.03888},
  year={2017}
}



@article{puri2018large,
  title={Large Scale Language Modeling: Converging on 40GB of Text in Four Hours},
  author={Puri, Raul and Kirby, Robert and Yakovenko, Nikolai and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1808.01371},
  year={2018}
}

@article{goodfellow6572explaining,
  title={Explaining and harnessing adversarial examples (2014)},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@inproceedings{seide20141,
  title={1-bit stochastic gradient descent and its application to data-parallel distributed training of speech dnns},
  author={Seide, Frank and Fu, Hao and Droppo, Jasha and Li, Gang and Yu, Dong},
  booktitle=interspeech,
  year={2014}
}


@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle=cvpr,
  year={2009},
 }

@article{gholami2018squeezenext,
  title={SqueezeNext: Hardware-Aware Neural Network Design},
  author={Gholami, Amir and Kwon, Kiseok and Wu, Bichen and Tai, Zizheng and Yue, Xiangyu and Jin, Peter and Zhao, Sicheng and Keutzer, Kurt},
  journal={arXiv preprint arXiv:1803.10615},
  year={2018}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle=nips,
  year={2012}
}


@article{zheng2016asynchronous,
  title={Asynchronous stochastic gradient descent with delay compensation},
  author={Zheng, Shuxin and Meng, Qi and Wang, Taifeng and Chen, Wei and Yu, Nenghai and Ma, Zhi-Ming and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:1609.08326},
  year={2016}
}

@inproceedings{agarwal2011distributed,
  title={Distributed delayed stochastic optimization},
  author={Agarwal, Alekh and Duchi, John C},
  booktitle=nips,
  year={2011}
}

@article{el1997robust,
  title={Robust solutions to least-squares problems with uncertain data},
  author={El Ghaoui, Laurent and Lebret, Herv{\'e}},
  journal={SIAM Journal on matrix analysis and applications},
  year={1997},
  publisher={SIAM}
}

@inproceedings{xu2009robust,
  title={Robust regression and {Lasso}},
  author={Xu, Huan and Caramanis, Constantine and Mannor, Shie},
  booktitle=nips,
  year={2009}
}

@inproceedings{schaul2013no,
  title={No more pesky learning rates},
  author={Schaul, Tom and Zhang, Sixin and LeCun, Yann},
  booktitle=icml,
  year={2013}
}


@inproceedings{martens2010deep,
  title={Deep learning via Hessian-free optimization.},
  author={Martens, James},
  booktitle={ICML},
  year={2010}
}

@inproceedings{moosavi2016deepfool,
  title={Deepfool: a simple and accurate method to fool deep neural networks},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal},
  booktitle=cvpr,
  year={2016}
}

@inproceedings{carlini2017towards,
  title={Towards evaluating the robustness of neural networks},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={2017 IEEE Symposium on Security and Privacy (SP)},
  year={2017},
  organization={IEEE}
}

@article{kurakin2016adversarial,
  title={Adversarial examples in the physical world},
  author={Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
  journal={arXiv preprint arXiv:1607.02533},
  year={2016}
}

@article{xu2017newton,
  title={Newton-type methods for non-convex optimization under inexact hessian information},
  author={Xu, Peng and Roosta-Khorasani, Farbod and Mahoney, Michael W},
  journal={arXiv preprint arXiv:1708.07164},
  year={2017}
}

@article{ward2018adagrad,
  title={AdaGrad stepsizes: Sharp convergence over nonconvex landscapes, from any initialization},
  author={Ward, Rachel and Wu, Xiaoxia and Bottou, Leon},
  journal={arXiv preprint arXiv:1806.01811},
  year={2018}
}

@article{duchi2011adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of Machine Learning Research},
  year={2011}
}

@article{shaham2015understanding,
  title={Understanding adversarial training: Increasing local stability of neural nets through robust optimization},
  author={Shaham, Uri and Yamada, Yutaro and Negahban, Sahand},
  journal={arXiv preprint arXiv:1511.05432},
  year={2015}
}

@inproceedings{shrivastava2017learning,
  title={Learning from Simulated and Unsupervised Images through Adversarial Training.},
  author={Shrivastava, Ashish and Pfister, Tomas and Tuzel, Oncel and Susskind, Joshua and Wang, Wenda and Webb, Russell},
  booktitle=cvpr,
  year={2017}
}

@article{szegedy2013intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal={arXiv preprint arXiv:1312.6199},
  year={2013}
}
@ONLINE{hessianflow,
  title = {anonymized version in supplementary material},
  month = Jan,
  year = 2019
}




@article{bollapragada2018progressive,
  title={A progressive batching L-BFGS method for machine learning},
  author={Bollapragada, Raghu and Mudigere, Dheevatsa and Nocedal, Jorge and Shi, Hao-Jun Michael and Tang, Ping Tak Peter},
  journal={arXiv preprint arXiv:1802.05374},
  year={2018}
}


@article{byrd2012sample,
  title={Sample size selection in optimization methods for machine learning},
  author={Byrd, Richard H and Chin, Gillian M and Nocedal, Jorge and Wu, Yuchen},
  journal={Mathematical programming},
  year={2012},
  publisher={Springer}
}


@article{bollapragada2018adaptive,
  title={Adaptive sampling strategies for stochastic optimization},
  author={Bollapragada, Raghu and Byrd, Richard and Nocedal, Jorge},
  journal={SIAM Journal on Optimization},
  year={2018},
  publisher={SIAM}
}

@inproceedings{hassibi1993second,
  title={Second order derivatives for network pruning: Optimal brain surgeon},
  author={Hassibi, Babak and Stork, David G},
  booktitle=nips,
  year={1993}
}

@inproceedings{dong2017learning,
  title={Learning to prune deep neural networks via layer-wise optimal brain surgeon},
  author={Dong, Xin and Chen, Shangyu and Pan, Sinno},
  booktitle=nips,
  year={2017}
}


@inproceedings{lecun1990optimal,
  title={Optimal brain damage},
  author={LeCun, Yann and Denker, John S and Solla, Sara A},
  booktitle=nips,
  year={1990}
}

@inproceedings{merity2016pointer,
  title={Pointer sentinel mixture models},
  author={Merity, Stephen and Xiong, Caiming and Bradbury, James and Socher, Richard},
  booktitle=iclr,
  year={2017}
}

@inproceedings{mikolov2011empirical,
  title={Empirical evaluation and combination of advanced language modeling techniques},
  author={Mikolov, Tom{\'a}{\v{s}} and Deoras, Anoop and Kombrink, Stefan and Burget, Luk{\'a}{\v{s}} and {\v{C}}ernock{\`y}, Jan},
  booktitle=interspeech,
  year={2011}
}

@article{wang2019eigendamage,
  title={EigenDamage: Structured Pruning in the Kronecker-Factored Eigenbasis},
  author={Wang, Chaoqi and Grosse, Roger and Fidler, Sanja and Zhang, Guodong},
  journal={arXiv preprint arXiv:1905.05934},
  year={2019}
}

@inproceedings{santurkar2018does,
  title={How does batch normalization help optimization?},
  author={Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew and Madry, Aleksander},
  booktitle=nips,
  year={2018}
}

@inproceedings{ioffe2015batch,
  author={Sergey Ioffe and Christian Szegedy},
  title={Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  year={2015},
  booktitle=icml,
}


@inproceedings{
fan2019reducing,
title={Reducing Transformer Depth on Demand with Structured Dropout},
author={Angela Fan and Edouard Grave and Armand Joulin},
booktitle=iclr,
year={2020},
}


@inproceedings{sandler2018mobilenetv2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle=cvpr,
  year={2018}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle=cvpr,
  year={2017}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  year={1997},
  publisher={MIT Press}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle=nips,
  year={2017}
}

@inproceedings{devlin2018bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle=naacl,
  year={2019}
}


@inproceedings{yang2019xlnet,
  title={Xlnet: Generalized autoregressive pretraining for language understanding},
  author={Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
  booktitle=nips,
  year={2019}
}

@inproceedings{socher2013recursive,
  title={Recursive deep models for semantic compositionality over a sentiment treebank},
  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
  booktitle=emnlp,
  year={2013}
}


@inproceedings{williams2018broad,
  title={A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference},
  author={Williams, Adina and Nangia, Nikita and Bowman, Samuel},
  booktitle=naacl,
  year={2018}
}


@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@inproceedings{salimans2016weight,
  title={Weight normalization: A simple reparameterization to accelerate training of deep neural networks},
  author={Salimans, Tim and Kingma, Durk P},
  booktitle=nips,
  year={2016}
}

@inproceedings{
miyato2018spectral,
title={Spectral Normalization for Generative Adversarial Networks},
author={Takeru Miyato and Toshiki Kataoka and Masanori Koyama and Yuichi Yoshida},
booktitle=iclr,
year={2018},
}


@article{qiao2019weight,
  title={Weight standardization},
  author={Qiao, Siyuan and Wang, Huiyu and Liu, Chenxi and Shen, Wei and Yuille, Alan},
  journal={arXiv preprint arXiv:1903.10520},
  year={2019}
}


@inproceedings{
wu2019pay,
title={Pay Less Attention with Lightweight and Dynamic Convolutions},
author={Felix Wu and Angela Fan and Alexei Baevski and Yann Dauphin and Michael Auli},
booktitle=iclr,
year={2019},
}

@inproceedings{jarrett2009best,
  title={What is the best multi-stage architecture for object recognition?},
  author={Jarrett, Kevin and Kavukcuoglu, Koray and Ranzato, Marc'Aurelio and LeCun, Yann},
  booktitle=iccv,
  year={2009},
}

@article{ulyanov2016instance,
  title={Instance normalization: The missing ingredient for fast stylization},
  author={Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
  journal={arXiv preprint arXiv:1607.08022},
  year={2016}
}

@inproceedings{wu2018group,
  title={Group normalization},
  author={Wu, Yuxin and He, Kaiming},
  booktitle=eccv,
  year={2018}
}

@inproceedings{li2019positional,
  title={Positional Normalization},
  author={Li, Boyi and Wu, Felix and Weinberger, Kilian Q and Belongie, Serge},
  booktitle=nips,
  year={2019}
}

@inproceedings{lin2017focal,
  title={Focal loss for dense object detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle=iccv,
  year={2017}
}

@inproceedings{webster1992tokenization,
  title={Tokenization as the initial phase in NLP},
  author={Webster, Jonathan J and Kit, Chunyu},
  booktitle=coling,
  year={1992}
}


@inproceedings{ioffe2017batch,
  title={Batch renormalization: Towards reducing minibatch dependence in batch-normalized models},
  author={Ioffe, Sergey},
  booktitle=nips,
  year={2017}
}

@inproceedings{singh2019evalnorm,
  title={EvalNorm: Estimating Batch Normalization Statistics for Evaluation},
  author={Singh, Saurabh and Shrivastava, Abhinav},
  booktitle=iccv,
  year={2019}
}

@inproceedings{
yan2020towards,
title={Towards Stabilizing Batch Statistics in Backward Propagation of Batch Normalization},
author={Junjie Yan and Ruosi Wan and Xiangyu Zhang and Wei Zhang and Yichen Wei and Jian Sun},
booktitle=iclr,
year={2020},
}

@article{yao2019pyhessian,
  title={{PyHessian}: Neural Networks Through the Lens of the {H}essian},
  author={Yao, Zhewei and Gholami, Amir and Keutzer, Kurt and Mahoney, Michael W},
  journal={arXiv preprint arXiv:1912.07145},
  year={2019}
}

@inproceedings{balduzzi2017shattered,
  title={The shattered gradients problem: If resnets are the answer, then what is the question?},
  author={Balduzzi, David and Frean, Marcus and Leary, Lennox and Lewis, JP and Ma, Kurt Wan-Duo and McWilliams, Brian},
  booktitle=icml,
  year={2017},
}

@article{im2016empirical,
  title={An empirical analysis of deep network loss surfaces},
  author={Im, Daniel Jiwoong and Tao, Michael and Branson, Kristin},
  year={2016}
}

@inproceedings{goldberger2005neighbourhood,
  title={Neighbourhood components analysis},
  author={Goldberger, Jacob and Hinton, Geoffrey E and Roweis, Sam T and Salakhutdinov, Russ R},
  booktitle=nips,
  year={2005}
}

@inproceedings{papineni2002bleu,
  title={BLEU: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle=acl,
  year={2002},
}


@inproceedings{zhang2019root,
  title={Root Mean Square Layer Normalization},
  author={Zhang, Biao and Sennrich, Rico},
  booktitle=nips,
  year={2019}
}

@inproceedings{rajpurkar2016squad,
  title={SQuAD: 100,000+ Questions for Machine Comprehension of Text},
  author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  booktitle=emnlp,
  year={2016}
}

@article{iyer2017first,
  title={First quora dataset release: Question pairs},
  author={Iyer, Shankar and Dandekar, Nikhil and Csernai, Korn{\'e}l},
  journal={data. quora. com},
  year={2017}
}

@inproceedings{cooijmans2016recurrent,
  title={Recurrent batch normalization},
  author={Cooijmans, Tim and Ballas, Nicolas and Laurent, C{\'e}sar and G{\"u}l{\c{c}}ehre, {\c{C}}a{\u{g}}lar and Courville, Aaron},
  booktitle=iclr,
  year={2017},
}

@article{nguyen2019transformers,
  title={Transformers without tears: Improving the normalization of self-attention},
  author={Nguyen, Toan Q and Salazar, Julian},
  journal={arXiv preprint arXiv:1910.05895},
  year={2019}
}

@inproceedings{xu2019understanding,
  title={Understanding and Improving Layer Normalization},
  author={Xu, Jingjing and Sun, Xu and Zhang, Zhiyuan and Zhao, Guangxiang and Lin, Junyang},
  booktitle=nips,
  year={2019}
}

@inproceedings{
zhang2019fixup,
title={Residual Learning Without Normalization via Better Initialization},
author={Hongyi Zhang and Yann N. Dauphin and Tengyu Ma},
booktitle=iclr,
year={2019},
}

@article{patro2015normalization,
  title={Normalization: A preprocessing stage},
  author={Patro, S and Sahu, Kishore Kumar},
  journal={arXiv preprint arXiv:1503.06462},
  year={2015}
}


@ONLINE{alirahimi,
author={Ali Rahimi},
 title = {NuerIPS 2017 Test-of-time award presentation},
  month = Dec,
  year = 2017
}

@inproceedings{
wang2020improving,
title={Improving Neural Language Generation with Spectrum Control},
author={Lingxiao Wang and Jing Huang and Kevin Huang and Ziniu Hu and Guangtao Wang and Quanquan Gu},
booktitle=iclr,
year={2020},
}