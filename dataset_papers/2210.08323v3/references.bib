@inproceedings{abadi2016tensorflow,
 author = {Abadi, Mart{\'\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others},
 booktitle = {12th USENIX symposium on operating systems design and implementation (OSDI 16)},
 pages = {265--283},
 title = {$\{$TensorFlow$\}$: A System for $\{$Large-Scale$\}$ Machine Learning},
 year = {2016}
}

@inproceedings{abdolmaleki2018maximum,
 author = {Abbas Abdolmaleki and
Jost Tobias Springenberg and
Yuval Tassa and
R{\'{e}}mi Munos and
Nicolas Heess and
Martin A. Riedmiller},
 booktitle = {Proc. of ICLR},
 title = {Maximum a Posteriori Policy Optimisation},
 year = {2018}
}

@inproceedings{achiam2017constrained,
 author = {Joshua Achiam and
David Held and
Aviv Tamar and
Pieter Abbeel},
 booktitle = {Proc. of ICML},
 pages = {22--31},
 title = {Constrained Policy Optimization},
 year = {2017}
}

@inproceedings{adam,
 author = {Diederik P. Kingma and
Jimmy Ba},
 booktitle = {Proc. of ICLR},
 title = {Adam: {A} Method for Stochastic Optimization},
 year = {2015}
}

@inproceedings{agarwal2020optimistic,
 author = {Rishabh Agarwal and
Dale Schuurmans and
Mohammad Norouzi},
 booktitle = {Proc. of ICML},
 pages = {104--114},
 title = {An Optimistic Perspective on Offline Reinforcement Learning},
 year = {2020}
}

@inproceedings{ahmed2019understanding,
 author = {Zafarali Ahmed and
Nicolas Le Roux and
Mohammad Norouzi and
Dale Schuurmans},
 booktitle = {Proc. of ICML},
 pages = {151--160},
 title = {Understanding the Impact of Entropy on Policy Optimization},
 year = {2019}
}

@book{altman1999constrained,
 author = {Altman, Eitan},
 publisher = {CRC Press},
 title = {Constrained Markov decision processes},
 year = {1999}
}

@article{an2021uncertainty,
 author = {An, Gaon and Moon, Seungyong and Kim, Jang-Hyun and Song, Hyun Oh},
 journal = {Proc. of NeurIPS},
 title = {Uncertainty-based offline reinforcement learning with diversified q-ensemble},
 year = {2021}
}

@inproceedings{antos2008fitted,
 author = {Andr{\'{a}}s Antos and
R{\'{e}}mi Munos and
Csaba Szepesv{\'{a}}ri},
 booktitle = {Proc. of NeurIPS},
 pages = {9--16},
 title = {Fitted Q-iteration in continuous action-space MDPs},
 year = {2007}
}

@inproceedings{argenson2021modelbased,
 author = {Arthur Argenson and
Gabriel Dulac{-}Arnold},
 booktitle = {Proc. of ICLR},
 title = {Model-Based Offline Planning},
 year = {2021}
}

@inproceedings{bai2021pessimistic,
 author = {Bai, Chenjia and Wang, Lingxiao and Yang, Zhuoran and Deng, Zhi-Hong and Garg, Animesh and Liu, Peng and Wang, Zhaoran},
 booktitle = {Proc. of ICLR},
 title = {Pessimistic Bootstrapping for Uncertainty-Driven Offline Reinforcement Learning},
 year = {2021}
}

@incollection{baird1995residual,
 author = {Baird, Leemon},
 booktitle = {Machine Learning Proceedings 1995},
 pages = {30--37},
 title = {Residual algorithms: Reinforcement learning with function approximation},
 year = {1995}
}

@article{beirami2008proofs,
 author = {Beirami, Ahmad and Cevher, Volkan and Bower, Beth and Tsianos, Konstantinos},
 journal = {Rapport technique STAT},
 title = {Proofs of alpha divergence properties},
 year = {2008}
}

@article{bertsekas1997nonlinear,
 author = {Bertsekas, Dimitri P},
 journal = {Journal of the Operational Research Society},
 title = {Nonlinear programming},
 year = {1997}
}

@book{boyd2004convex,
 author = {Boyd, Stephen and Boyd, Stephen P and Vandenberghe, Lieven},
 publisher = {Cambridge university press},
 title = {Convex optimization},
 year = {2004}
}

@article{brandfonbrener2021offline,
 author = {Brandfonbrener, David and Whitney, William F and Ranganath, Rajesh and Bruna, Joan},
 journal = {Proc. of NeurIPS},
 title = {Offline RL Without Off-Policy Evaluation},
 year = {2021}
}

@article{brandfonbrener2021quantile,
 author = {Brandfonbrener, David and Whitney, William F and Ranganath, Rajesh and Bruna, Joan},
 journal = {ArXiv preprint},
 title = {Quantile Filtered Imitation Learning},
 year = {2021}
}

@article{brockman2016openai,
 author = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
 journal = {ArXiv preprint},
 title = {Openai gym},
 year = {2016}
}

@inproceedings{buckman2020importance,
 author = {Jacob Buckman and
Carles Gelada and
Marc G. Bellemare},
 booktitle = {Proc. of ICLR},
 title = {The Importance of Pessimism in Fixed-Dataset Policy Optimization},
 year = {2021}
}

@article{cabi2019framework,
 author = {Cabi, Serkan and Colmenarejo, Sergio G{\'o}mez and Novikov, Alexander and Konyushkova, Ksenia and Reed, Scott and Jeong, Rae and Zolna, Konrad and Aytar, Yusuf and Budden, David and Vecerik, Mel and others},
 journal = {ArXiv preprint},
 title = {A Framework for Data-Driven Robotics},
 year = {2019}
}

@article{chang2021mitigating,
 author = {Chang, Jonathan and Uehara, Masatoshi and Sreenivas, Dhruv and Kidambi, Rahul and Sun, Wen},
 journal = {Proc. of NeurIPS},
 title = {Mitigating Covariate Shift in Imitation Learning via Offline Data With Partial Coverage},
 year = {2021}
}

@inproceedings{chen2020bail,
 author = {Xinyue Chen and
Zijian Zhou and
Zheng Wang and
Che Wang and
Yanqiu Wu and
Keith W. Ross},
 booktitle = {Proc. of NeurIPS},
 title = {{BAIL:} Best-Action Imitation Learning for Batch Deep Reinforcement
Learning},
 year = {2020}
}

@article{chen2021decision,
 author = {Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
 journal = {Proc. of NeurIPS},
 title = {Decision transformer: Reinforcement learning via sequence modeling},
 year = {2021}
}

@article{choi2018reinforcement,
 author = {Choi, Sungwoon and Ha, Heonseok and Hwang, Uiwon and Kim, Chanju and Ha, Jung-Woo and Yoon, Sungroh},
 journal = {ArXiv preprint},
 title = {Reinforcement learning based recommender system using biclustering technique},
 year = {2018}
}

@article{chow2017risk,
 author = {Chow, Yinlam and Ghavamzadeh, Mohammad and Janson, Lucas and Pavone, Marco},
 journal = {The Journal of Machine Learning Research},
 title = {Risk-constrained reinforcement learning with percentile risk criteria},
 year = {2017}
}

@inproceedings{chow2018path,
 author = {Yinlam Chow and
Ofir Nachum and
Mohammad Ghavamzadeh},
 booktitle = {Proc. of ICML},
 pages = {978--987},
 title = {Path Consistency Learning in Tsallis Entropy Regularized MDPs},
 year = {2018}
}

@article{christiano2016transfer,
 author = {Christiano, Paul and Shah, Zain and Mordatch, Igor and Schneider, Jonas and Blackwell, Trevor and Tobin, Joshua and Abbeel, Pieter and Zaremba, Wojciech},
 journal = {ArXiv preprint},
 title = {Transfer from simulation to real world through learning deep inverse dynamics model},
 year = {2016}
}

@inproceedings{dadashi2021offline,
 author = {Robert Dadashi and
Shideh Rezaeifar and
Nino Vieillard and
L{\'{e}}onard Hussenot and
Olivier Pietquin and
Matthieu Geist},
 booktitle = {Proc. of ICML},
 pages = {2307--2318},
 title = {Offline Reinforcement Learning with Pseudometric Learning},
 year = {2021}
}

@inproceedings{dai2017learning,
 author = {Bo Dai and
Niao He and
Yunpeng Pan and
Byron Boots and
Le Song},
 booktitle = {Proc. of AISTATS},
 pages = {1458--1467},
 title = {Learning from Conditional Distributions via Dual Embeddings},
 year = {2017}
}

@inproceedings{dai2018boosting,
 author = {Bo Dai and
Albert Shaw and
Niao He and
Lihong Li and
Le Song},
 booktitle = {Proc. of ICLR},
 title = {Boosting the Actor with Dual Critic},
 year = {2018}
}

@article{dalal2018safe,
 author = {Dalal, Gal and Dvijotham, Krishnamurthy and Vecerik, Matej and Hester, Todd and Paduraru, Cosmin and Tassa, Yuval},
 journal = {ArXiv preprint},
 title = {Safe exploration in continuous action spaces},
 year = {2018}
}

@inproceedings{degris2012off,
 author = {Degris, Thomas and White, Martha and Sutton, Richard S},
 booktitle = {Proc. of ICML},
 title = {Off-policy actor-critic},
 year = {2012}
}

@inproceedings{deng2009imagenet,
 author = {Jia Deng and
Wei Dong and
Richard Socher and
Li{-}Jia Li and
Kai Li and
Fei{-}Fei Li},
 booktitle = {Proc. of CVPR},
 pages = {248--255},
 title = {ImageNet: {A} large-scale hierarchical image database},
 year = {2009}
}

@article{DT,
 author = {Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
 journal = {Proc. of NeurIPS},
 title = {Decision transformer: Reinforcement learning via sequence modeling},
 year = {2021}
}

@article{emmons2021rvs,
 author = {Emmons, Scott and Eysenbach, Benjamin and Kostrikov, Ilya and Levine, Sergey},
 journal = {ArXiv preprint},
 title = {RvS: What is Essential for Offline RL via Supervised Learning?},
 year = {2021}
}


@article{fu2020d4rl,
 author = {Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
 journal = {ArXiv preprint},
 title = {D4rl: Datasets for deep data-driven reinforcement learning},
 year = {2020}
}

@inproceedings{fujimoto2018addressing,
 author = {Scott Fujimoto and
Herke van Hoof and
David Meger},
 booktitle = {Proc. of ICML},
 pages = {1582--1591},
 title = {Addressing Function Approximation Error in Actor-Critic Methods},
 year = {2018}
}

@inproceedings{fujimoto2019off,
 author = {Scott Fujimoto and
David Meger and
Doina Precup},
 booktitle = {Proc. of ICML},
 pages = {2052--2062},
 title = {Off-Policy Deep Reinforcement Learning without Exploration},
 year = {2019}
}

@article{fujimoto2021minimalist,
 author = {Fujimoto, Scott and Gu, Shixiang Shane},
 journal = {ArXiv preprint},
 title = {A Minimalist Approach to Offline Reinforcement Learning},
 year = {2021}
}

@article{garcia2015comprehensive,
 author = {Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
 journal = {Journal of Machine Learning Research},
 title = {A comprehensive survey on safe reinforcement learning},
 year = {2015}
}

@inproceedings{geist2019theory,
 author = {Matthieu Geist and
Bruno Scherrer and
Olivier Pietquin},
 booktitle = {Proc. of ICML},
 pages = {2160--2169},
 title = {A Theory of Regularized Markov Decision Processes},
 year = {2019}
}

@inproceedings{gelada2019off,
 author = {Carles Gelada and
Marc G. Bellemare},
 booktitle = {Proc. of AAAI},
 pages = {3647--3655},
 title = {Off-Policy Deep Reinforcement Learning by Bootstrapping the Covariate
Shift},
 year = {2019}
}

@inproceedings{ghasemipour2021emaq,
 author = {Seyed Kamyar Seyed Ghasemipour and
Dale Schuurmans and
Shixiang Shane Gu},
 booktitle = {Proc. of ICML},
 pages = {3682--3691},
 title = {EMaQ: Expected-Max Q-Learning Operator for Simple Yet Effective Offline
and Online {RL}},
 year = {2021}
}

@inproceedings{ghosh2020learning,
 author = {Dibya Ghosh and
Abhishek Gupta and
Ashwin Reddy and
Justin Fu and
Coline Manon Devin and
Benjamin Eysenbach and
Sergey Levine},
 booktitle = {Proc. of ICLR},
 title = {Learning to Reach Goals via Iterated Supervised Learning},
 year = {2021}
}

@inproceedings{goodfellow2014generative,
 author = {Ian J. Goodfellow and
Jean Pouget{-}Abadie and
Mehdi Mirza and
Bing Xu and
David Warde{-}Farley and
Sherjil Ozair and
Aaron C. Courville and
Yoshua Bengio},
 booktitle = {Proc. of NeurIPS},
 pages = {2672--2680},
 title = {Generative Adversarial Nets},
 year = {2014}
}

@article{gretton2012kernel,
 author = {Gretton, Arthur and Borgwardt, Karsten M and Rasch, Malte J and Sch{\"o}lkopf, Bernhard and Smola, Alexander},
 journal = {The Journal of Machine Learning Research},
 title = {A kernel two-sample test},
 year = {2012}
}

@article{gulcehre2021regularized,
 author = {Gulcehre, Caglar and Colmenarejo, Sergio G{\'o}mez and Wang, Ziyu and Sygnowski, Jakub and Paine, Thomas and Zolna, Konrad and Chen, Yutian and Hoffman, Matthew and Pascanu, Razvan and de Freitas, Nando},
 journal = {ArXiv preprint},
 title = {Regularized behavior value estimation},
 year = {2021}
}

@inproceedings{gulrajani2017improved,
 author = {Ishaan Gulrajani and
Faruk Ahmed and
Mart{\'{\i}}n Arjovsky and
Vincent Dumoulin and
Aaron C. Courville},
 booktitle = {Proc. of NeurIPS},
 pages = {5767--5777},
 title = {Improved Training of Wasserstein GANs},
 year = {2017}
}

@article{ha2020learning,
 author = {Ha, Sehoon and Xu, Peng and Tan, Zhenyu and Levine, Sergey and Tan, Jie},
 journal = {ArXiv preprint},
 title = {Learning to Walk in the Real World with Minimal Human Effort},
 year = {2020}
}

@inproceedings{haarnoja2017reinforcement,
 author = {Tuomas Haarnoja and
Haoran Tang and
Pieter Abbeel and
Sergey Levine},
 booktitle = {Proc. of ICML},
 pages = {1352--1361},
 title = {Reinforcement Learning with Deep Energy-Based Policies},
 year = {2017}
}

@inproceedings{haarnoja2018soft,
 author = {Tuomas Haarnoja and
Aurick Zhou and
Pieter Abbeel and
Sergey Levine},
 booktitle = {Proc. of ICML},
 pages = {1856--1865},
 title = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
with a Stochastic Actor},
 year = {2018}
}

@inproceedings{hallak2017consistent,
 author = {Assaf Hallak and
Shie Mannor},
 booktitle = {Proc. of ICML},
 pages = {1372--1383},
 title = {Consistent On-Line Off-Policy Evaluation},
 year = {2017}
}

@inproceedings{he2016dual,
 author = {Di He and
Yingce Xia and
Tao Qin and
Liwei Wang and
Nenghai Yu and
Tie{-}Yan Liu and
Wei{-}Ying Ma},
 booktitle = {Proc. of NeurIPS},
 pages = {820--828},
 title = {Dual Learning for Machine Translation},
 year = {2016}
}

@inproceedings{hinton2002stochastic,
 author = {Geoffrey E. Hinton and
Sam T. Roweis},
 booktitle = {Proc. of NeurIPS},
 pages = {833--840},
 title = {Stochastic Neighbor Embedding},
 year = {2002}
}

@article{hussein2017imitation,
 author = {Hussein, Ahmed and Gaber, Mohamed Medhat and Elyan, Eyad and Jayne, Chrisina},
 journal = {ACM Computing Surveys (CSUR)},
 title = {Imitation learning: A survey of learning methods},
 year = {2017}
}

@article{janner2021offline,
 author = {Janner, Michael and Li, Qiyang and Levine, Sergey},
 journal = {Proc. of NeurIPS},
 title = {Offline Reinforcement Learning as One Big Sequence Modeling Problem},
 year = {2021}
}

@inproceedings{jaques2020human,
 author = {Jaques, Natasha  and
Shen, Judy Hanwen  and
Ghandeharioun, Asma  and
Ferguson, Craig  and
Lapedriza, Agata  and
Jones, Noah  and
Gu, Shixiang  and
Picard, Rosalind},
 booktitle = {Proc. of EMNLP},
 pages = {3985--4003},
 title = {Human-centric dialog training via offline reinforcement learning},
 year = {2020}
}

@inproceedings{kakade2001natural,
 author = {Sham M. Kakade},
 booktitle = {Proc. of NeurIPS},
 pages = {1531--1538},
 title = {A Natural Policy Gradient},
 year = {2001}
}

@inproceedings{kakade2002approximately,
 author = {Sham M. Kakade and
John Langford},
 booktitle = {Machine Learning, Proceedings of the Nineteenth International Conference (ICML 2002), University of New South Wales, Sydney, Australia, July 8-12, 2002},
 pages = {267--274},
 title = {Approximately Optimal Approximate Reinforcement Learning},
 year = {2002}
}

@inproceedings{kakade2002natural,
 author = {Sham M. Kakade},
 booktitle = {Proc. of NeurIPS},
 pages = {1531--1538},
 title = {A Natural Policy Gradient},
 year = {2001}
}

@inproceedings{kalashnikov2018scalable,
 author = {Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
 booktitle = {Conference on Robot Learning},
 title = {Scalable deep reinforcement learning for vision-based robotic manipulation},
 year = {2018}
}

@article{kalashnikov2021mt,
 author = {Kalashnikov, Dmitry and Varley, Jacob and Chebotar, Yevgen and Swanson, Benjamin and Jonschkowski, Rico and Finn, Chelsea and Levine, Sergey and Hausman, Karol},
 journal = {ArXiv preprint},
 title = {Mt-opt: Continuous multi-task robotic reinforcement learning at scale},
 year = {2021}
}

@article{ke2019imitation,
 author = {Ke, Liyiming and Barnes, Matt and Sun, Wen and Lee, Gilwoo and Choudhury, Sanjiban and Srinivasa, Siddhartha},
 journal = {ArXiv preprint},
 title = {Imitation Learning as $ f $-Divergence Minimization},
 year = {2019}
}

@inproceedings{kidambi2020morel,
 author = {Rahul Kidambi and
Aravind Rajeswaran and
Praneeth Netrapalli and
Thorsten Joachims},
 booktitle = {Proc. of NeurIPS},
 title = {MOReL: Model-Based Offline Reinforcement Learning},
 year = {2020}
}

@inproceedings{kim2021demodice,
 author = {Kim, Geon-Hyeong and Seo, Seokin and Lee, Jongmin and Jeon, Wonseok and Hwang, HyeongJoo and Yang, Hongseok and Kim, Kee-Eung},
 booktitle = {Proc. of ICLR},
 title = {DemoDICE: Offline Imitation Learning with Supplementary Imperfect Demonstrations},
 year = {2021}
}

@inproceedings{Kingma2014-az,
 author = {Diederik P. Kingma and
Jimmy Ba},
 booktitle = {Proc. of ICLR},
 title = {Adam: {A} Method for Stochastic Optimization},
 year = {2015}
}

@inproceedings{kostrikov2019imitation,
 author = {Ilya Kostrikov and
Ofir Nachum and
Jonathan Tompson},
 booktitle = {Proc. of ICLR},
 title = {Imitation Learning via Off-Policy Distribution Matching},
 year = {2020}
}

@article{kostrikov2021iql,
 author = {Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
 journal = {ArXiv preprint},
 title = {Offline reinforcement learning with implicit q-learning},
 year = {2021}
}

@inproceedings{kostrikov2021offline,
 author = {Ilya Kostrikov and
Rob Fergus and
Jonathan Tompson and
Ofir Nachum},
 booktitle = {Proc. of ICML},
 pages = {5774--5783},
 title = {Offline Reinforcement Learning with Fisher Divergence Critic Regularization},
 year = {2021}
}

@article{kumar2019reward,
 author = {Kumar, Aviral and Peng, Xue Bin and Levine, Sergey},
 journal = {ArXiv preprint},
 title = {Reward-conditioned policies},
 year = {2019}
}

@inproceedings{kumar2019stabilizing,
 author = {Aviral Kumar and
Justin Fu and
Matthew Soh and
George Tucker and
Sergey Levine},
 booktitle = {Proc. of NeurIPS},
 pages = {11761--11771},
 title = {Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
 year = {2019}
}

@inproceedings{kumar2020conservative,
 author = {Aviral Kumar and
Aurick Zhou and
George Tucker and
Sergey Levine},
 booktitle = {Proc. of NeurIPS},
 title = {Conservative Q-Learning for Offline Reinforcement Learning},
 year = {2020}
}

@inproceedings{kumar2020discor,
 author = {Aviral Kumar and
Abhishek Gupta and
Sergey Levine},
 booktitle = {Proc. of NeurIPS},
 title = {DisCor: Corrective Feedback in Reinforcement Learning via Distribution
Correction},
 year = {2020}
}

@article{kumar2022WhenShould,
 author = {Kumar, Aviral and Hong, Joey and Singh, Anikait and Levine, Sergey},
 journal = {ArXiv preprint},
 title = {When {{Should We Prefer Offline Reinforcement Learning Over Behavioral Cloning}}?},
 year = {2022}
}

@incollection{lange2012batch,
 author = {Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
 booktitle = {Reinforcement learning},
 title = {Batch reinforcement learning},
 year = {2012}
}

@inproceedings{laroche2019safe,
 author = {Romain Laroche and
Paul Trichelair and
Remi Tachet des Combes},
 booktitle = {Proc. of ICML},
 pages = {3652--3661},
 title = {Safe Policy Improvement with Baseline Bootstrapping},
 year = {2019}
}

@inproceedings{laskin_srinivas2020curl,
 author = {Michael Laskin and
Aravind Srinivas and
Pieter Abbeel},
 booktitle = {Proc. of ICML},
 pages = {5639--5650},
 title = {{CURL:} Contrastive Unsupervised Representations for Reinforcement
Learning},
 year = {2020}
}

@article{lazaric2012finite,
 author = {Lazaric, Alessandro and Ghavamzadeh, Mohammad and Munos, R{\'e}mi},
 journal = {The Journal of Machine Learning Research},
 title = {Finite-sample analysis of least-squares policy iteration},
 year = {2012}
}

@inproceedings{le2019batch,
 author = {Hoang Minh Le and
Cameron Voloshin and
Yisong Yue},
 booktitle = {Proc. of ICML},
 pages = {3703--3712},
 title = {Batch Policy Learning under Constraints},
 year = {2019}
}

@article{lee2019tsallis,
 author = {Lee, Kyungjae and Kim, Sungyub and Lim, Sungbin and Choi, Sungjoon and Oh, Songhwai},
 journal = {ArXiv preprint},
 title = {Tsallis reinforcement learning: A unified framework for maximum entropy reinforcement learning},
 year = {2019}
}

@inproceedings{lee2020batch,
 author = {Byung{-}Jun Lee and
Jongmin Lee and
Peter Vrancx and
Dongho Kim and
Kee{-}Eung Kim},
 booktitle = {Proc. of ICML},
 pages = {5725--5735},
 title = {Batch Reinforcement Learning with Hyperparameter Gradients},
 year = {2020}
}

@inproceedings{lee2021optidice,
 author = {Lee, Jongmin and Jeon, Wonseok and Lee, Byungjun and Pineau, Joelle and Kim, Kee-Eung},
 booktitle = {Proc. of ICML},
 pages = {6120--6130},
 title = {Optidice: Offline policy optimization via stationary distribution correction estimation},
 year = {2021}
}

@book{levin2017markov,
 author = {Levin, David A and Peres, Yuval},
 publisher = {American Mathematical Soc.},
 title = {Markov chains and mixing times},
 year = {2017}
}

@article{levine2016end,
 author = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
 journal = {Journal of Machine Learning Research},
 title = {End-to-End Training of Deep Visuomotor Policies},
 year = {2016}
}

@article{levine2020offline,
 author = {Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
 journal = {ArXiv preprint},
 title = {Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
 year = {2020}
}

@article{li2022deep,
 author = {Li, Yuxi},
 journal = {ArXiv preprint},
 title = {Deep Reinforcement Learning: Opportunities and Challenges},
 year = {2022}
}

@article{li2022distance,
 author = {Li, Jianxiong and Zhan, Xianyuan and Xu, Haoran and Zhu, Xiangyu and Liu, Jingjing and Zhang, Ya-Qin},
 journal = {ArXiv preprint},
 title = {Distance-Sensitive Offline Reinforcement Learning},
 year = {2022}
}

@article{liang2018accelerated,
 author = {Liang, Qingkai and Que, Fanyu and Modiano, Eytan},
 journal = {ArXiv preprint},
 title = {Accelerated primal-dual policy optimization for safe reinforcement learning},
 year = {2018}
}

@inproceedings{Lillicrap2015-ip,
 author = {Timothy P. Lillicrap and
Jonathan J. Hunt and
Alexander Pritzel and
Nicolas Heess and
Tom Erez and
Yuval Tassa and
David Silver and
Daan Wierstra},
 booktitle = {Proc. of ICLR},
 title = {Continuous control with deep reinforcement learning},
 year = {2016}
}

@inproceedings{lillicrap2016continuous,
 author = {Timothy P. Lillicrap and
Jonathan J. Hunt and
Alexander Pritzel and
Nicolas Heess and
Tom Erez and
Yuval Tassa and
David Silver and
Daan Wierstra},
 booktitle = {Proc. of ICLR},
 title = {Continuous control with deep reinforcement learning},
 year = {2016}
}

@inproceedings{liu2018breaking,
 author = {Qiang Liu and
Lihong Li and
Ziyang Tang and
Dengyong Zhou},
 booktitle = {Proc. of NeurIPS},
 pages = {5361--5371},
 title = {Breaking the Curse of Horizon: Infinite-Horizon Off-Policy Estimation},
 year = {2018}
}

@article{liu2019deep,
 author = {Liu, Siqi and Ngiam, Kee Yuan and Feng, Mengling},
 journal = {ArXiv preprint},
 title = {Deep reinforcement learning for clinical decision support: a brief survey},
 year = {2019}
}

@inproceedings{liu2020energy,
 author = {Weitang Liu and
Xiaoyun Wang and
John D. Owens and
Yixuan Li},
 booktitle = {Proc. of NeurIPS},
 title = {Energy-based Out-of-distribution Detection},
 year = {2020}
}

@article{liu2020provably,
 author = {Liu, Yao and Swaminathan, Adith and Agarwal, Alekh and Brunskill, Emma},
 journal = {ArXiv preprint},
 title = {Provably good batch reinforcement learning without great exploration},
 year = {2020}
}

@inproceedings{liu2021curriculum,
 author = {Minghuan Liu and Hanye Zhao and Zhengyu Yang and Jian Shen and Weinan Zhang and Li Zhao and Tie-Yan Liu},
 booktitle = {Proc. of NeurIPS},
 title = {Curriculum Offline Imitating Learning},
 year = {2021}
}

@article{liu2022goal,
 author = {Liu, Minghuan and Zhu, Menghui and Zhang, Weinan},
 journal = {ArXiv preprint},
 title = {Goal-Conditioned Reinforcement Learning: Problems and Solutions},
 year = {2022}
}

@article{liu2022learning,
 author = {Liu, Hsueh-Ti Derek and Williams, Francis and Jacobson, Alec and Fidler, Sanja and Litany, Or},
 journal = {ArXiv preprint},
 title = {Learning Smooth Neural Functions via Lipschitz Regularization},
 year = {2022}
}

@article{liu2022plan,
 author = {Liu, Minghuan and Zhu, Zhengbang and Zhuang, Yuzheng and Zhang, Weinan and Hao, Jianye and Yu, Yong and Wang, Jun},
 journal = {ArXiv preprint},
 title = {Plan Your Target and Learn Your Skills: Transferable State-Only Imitation Learning via Decoupled Policy Optimization},
 year = {2022}
}

@inproceedings{lynch2020learning,
 author = {Lynch, Corey and Khansari, Mohi and Xiao, Ted and Kumar, Vikash and Tompson, Jonathan and Levine, Sergey and Sermanet, Pierre},
 booktitle = {Conference on robot learning},
 title = {Learning latent plans from play},
 year = {2020}
}

@article{mandlekar2019iris,
 author = {Mandlekar, Ajay and Ramos, Fabio and Boots, Byron and Fei-Fei, Li and Garg, Animesh and Fox, Dieter},
 journal = {ArXiv preprint},
 title = {Iris: Implicit reinforcement without interaction at scale for learning control from offline robot manipulation data},
 year = {2019}
}

@inproceedings{matsushima2020deployment,
 author = {Tatsuya Matsushima and
Hiroki Furuta and
Yutaka Matsuo and
Ofir Nachum and
Shixiang Gu},
 booktitle = {Proc. of ICLR},
 title = {Deployment-Efficient Reinforcement Learning via Model-Based Offline
Optimization},
 year = {2021}
}

@article{mirhoseini2020chip,
 author = {Mirhoseini, Azalia and Goldie, Anna and Yazgan, Mustafa and Jiang, Joe and Songhori, Ebrahim and Wang, Shen and Lee, Young-Joon and Johnson, Eric and Pathak, Omkar and Bae, Sungmin and others},
 journal = {ArXiv preprint},
 title = {Chip Placement with Deep Reinforcement Learning},
 year = {2020}
}

@inproceedings{miryoosefi2019reinforcement,
 author = {Sobhan Miryoosefi and
Kiant{\'{e}} Brantley and
Hal Daum{\'{e}} III and
Miroslav Dud{\'{\i}}k and
Robert E. Schapire},
 booktitle = {Proc. of NeurIPS},
 pages = {14070--14079},
 title = {Reinforcement Learning with Convex Constraints},
 year = {2019}
}

@inproceedings{miyato2018spectral,
 author = {Takeru Miyato and
Toshiki Kataoka and
Masanori Koyama and
Yuichi Yoshida},
 booktitle = {Proc. of ICLR},
 title = {Spectral Normalization for Generative Adversarial Networks},
 year = {2018}
}

@article{mnih2013playing,
 author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
 journal = {arXiv preprint arXiv:1312.5602},
 title = {Playing atari with deep reinforcement learning},
 year = {2013}
}

@inproceedings{mnih2014recurrent,
 author = {Volodymyr Mnih and
Nicolas Heess and
Alex Graves and
Koray Kavukcuoglu},
 booktitle = {Proc. of NeurIPS},
 pages = {2204--2212},
 title = {Recurrent Models of Visual Attention},
 year = {2014}
}

@inproceedings{mousavi2019black,
 author = {Ali Mousavi and
Lihong Li and
Qiang Liu and
Denny Zhou},
 booktitle = {Proc. of ICLR},
 title = {Black-box Off-policy Estimation for Infinite-Horizon Reinforcement
Learning},
 year = {2020}
}

@article{muandet2017kernel,
 author = {Muandet, K and Fukumizu, K and Sriperumbudur, B and Sch{\"o}lkopf, B},
 journal = {Foundations and Trends in Machine Learning},
 title = {Kernel Mean Embedding of Distributions: A Review and Beyond},
 year = {2017}
}

@inproceedings{mujoco,
 author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
 booktitle = {Proc. of IROS},
 title = {Mujoco: A physics engine for model-based control},
 year = {2012}
}

@inproceedings{munos2003error,
 author = {R{\'{e}}mi Munos},
 booktitle = {Machine Learning, Proceedings of the Twentieth International Conference (ICML 2003), August 21-24, 2003, Washington, DC, USA},
 pages = {560--567},
 title = {Error Bounds for Approximate Policy Iteration},
 year = {2003}
}

@inproceedings{munos2005error,
 author = {Munos, R{\'e}mi},
 booktitle = {Proceedings of the National Conference on Artificial Intelligence},
 title = {Error bounds for approximate value iteration},
 year = {2005}
}

@article{munos2008finite,
 author = {Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
 journal = {Journal of Machine Learning Research},
 title = {Finite-time bounds for fitted value iteration},
 year = {2008}
}

@inproceedings{nachum2017bridging,
 author = {Ofir Nachum and
Mohammad Norouzi and
Kelvin Xu and
Dale Schuurmans},
 booktitle = {Proc. of NeurIPS},
 pages = {2775--2785},
 title = {Bridging the Gap Between Value and Policy Based Reinforcement Learning},
 year = {2017}
}

@article{nachum2019algaedice,
 author = {Nachum, Ofir and Dai, Bo and Kostrikov, Ilya and Chow, Yinlam and Li, Lihong and Schuurmans, Dale},
 journal = {ArXiv preprint},
 title = {Algaedice: Policy gradient from arbitrary experience},
 year = {2019}
}

@inproceedings{nachum2019dualdice,
 author = {Ofir Nachum and
Yinlam Chow and
Bo Dai and
Lihong Li},
 booktitle = {Proc. of NeurIPS},
 pages = {2315--2325},
 title = {DualDICE: Behavior-Agnostic Estimation of Discounted Stationary Distribution
Corrections},
 year = {2019}
}

@article{nair2020accelerating,
 author = {Nair, Ashvin and Dalal, Murtaza and Gupta, Abhishek and Levine, Sergey},
 journal = {ArXiv preprint},
 title = {Accelerating online reinforcement learning with offline datasets},
 year = {2020}
}

@article{neu2017unified,
 author = {Neu, Gergely and Jonsson, Anders and G{\'o}mez, Vicen{\c{c}}},
 journal = {ArXiv preprint},
 title = {A unified view of entropy-regularized markov decision processes},
 year = {2017}
}

@article{neyshabur2014search,
 author = {Neyshabur, Behnam and Tomioka, Ryota and Srebro, Nathan},
 journal = {arXiv preprint arXiv:1412.6614},
 title = {In search of the real inductive bias: On the role of implicit regularization in deep learning},
 year = {2014}
}

@article{nguyen2010estimating,
 author = {Nguyen, XuanLong and Wainwright, Martin J and Jordan, Michael I},
 journal = {IEEE Transactions on Information Theory},
 title = {Estimating divergence functionals and the likelihood ratio by convex risk minimization},
 year = {2010}
}

@inproceedings{nowozin2016f,
 author = {Sebastian Nowozin and
Botond Cseke and
Ryota Tomioka},
 booktitle = {Proc. of NeurIPS},
 pages = {271--279},
 title = {f-GAN: Training Generative Neural Samplers using Variational Divergence
Minimization},
 year = {2016}
}

@inproceedings{paszke2019pytorch,
 author = {Adam Paszke and
Sam Gross and
Francisco Massa and
Adam Lerer and
James Bradbury and
Gregory Chanan and
Trevor Killeen and
Zeming Lin and
Natalia Gimelshein and
Luca Antiga and
Alban Desmaison and
Andreas K{\"{o}}pf and
Edward Yang and
Zachary DeVito and
Martin Raison and
Alykhan Tejani and
Sasank Chilamkurthy and
Benoit Steiner and
Lu Fang and
Junjie Bai and
Soumith Chintala},
 booktitle = {Proc. of NeurIPS},
 pages = {8024--8035},
 title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
 year = {2019}
}

@inproceedings{pathak2017curiosity,
 author = {Deepak Pathak and
Pulkit Agrawal and
Alexei A. Efros and
Trevor Darrell},
 booktitle = {Proc. of ICML},
 pages = {2778--2787},
 title = {Curiosity-driven Exploration by Self-supervised Prediction},
 year = {2017}
}

@article{peng2019advantage,
 author = {Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
 journal = {ArXiv preprint},
 title = {Advantage-weighted regression: Simple and scalable off-policy reinforcement learning},
 year = {2019}
}

@inproceedings{peters2010relative,
 author = {Jan Peters and
Katharina M{\"{u}}lling and
Yasemin Altun},
 booktitle = {Proc. of AAAI},
 title = {Relative Entropy Policy Search},
 year = {2010}
}

@inproceedings{pirotta2013safe,
 author = {Matteo Pirotta and
Marcello Restelli and
Alessio Pecorino and
Daniele Calandriello},
 booktitle = {Proc. of ICML},
 pages = {307--315},
 title = {Safe Policy Iteration},
 year = {2013}
}

@inproceedings{pomerleau1989alvinn,
 author = {Pomerleau, Dean A},
 booktitle = {Proc. of NeurIPS},
 title = {Alvinn: An autonomous land vehicle in a neural network},
 year = {1989}
}

@article{rajeswaranlearning,
 author = {Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
 journal = {ArXiv preprint},
 title = {Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
 year = {2017}
}

@inproceedings{ren2019likelihood,
 author = {Jie Ren and
Peter J. Liu and
Emily Fertig and
Jasper Snoek and
Ryan Poplin and
Mark A. DePristo and
Joshua V. Dillon and
Balaji Lakshminarayanan},
 booktitle = {Proc. of NeurIPS},
 pages = {14680--14691},
 title = {Likelihood Ratios for Out-of-Distribution Detection},
 year = {2019}
}

@book{rockafellar1970convex,
 author = {Rockafellar, R Tyrrell},
 publisher = {Princeton university press},
 title = {Convex analysis},
 year = {1970}
}

@inproceedings{ross2011reduction,
 author = {Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
 booktitle = {Proc. of AISTATS},
 title = {A reduction of imitation learning and structured prediction to no-regret online learning},
 year = {2011}
}

@article{rvs,
 author = {Emmons, Scott and Eysenbach, Benjamin and Kostrikov, Ilya and Levine, Sergey},
 journal = {International Conference on Learning Representations},
 title = {RvS: What is Essential for Offline RL via Supervised Learning?},
 year = {2022}
}

@incollection{sammut2010BehavioralCloning,
 author = {Sammut, Caude},
 booktitle = {Encyclopedia of Machine Learning},
 pages = {93--97},
 title = {Behavioral Cloning},
 year = {2010}
}

@inproceedings{sasaki2021behavioral,
 author = {Fumihiro Sasaki and
Ryota Yamashina},
 booktitle = {Proc. of ICLR},
 title = {Behavioral Cloning from Noisy Demonstrations},
 year = {2021}
}

@inproceedings{satija2020constrained,
 author = {Harsh Satija and
Philip Amortila and
Joelle Pineau},
 booktitle = {Proc. of ICML},
 pages = {8502--8511},
 title = {Constrained Markov Decision Processes via Backward Value Functions},
 year = {2020}
}

@inproceedings{schulman2015trust,
 author = {John Schulman and
Sergey Levine and
Pieter Abbeel and
Michael I. Jordan and
Philipp Moritz},
 booktitle = {Proc. of ICML},
 pages = {1889--1897},
 title = {Trust Region Policy Optimization},
 year = {2015}
}

@article{schulman2017proximal,
 author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
 journal = {ArXiv preprint},
 title = {Proximal policy optimization algorithms},
 year = {2017}
}

@inproceedings{siegel2019keep,
 author = {Noah Y. Siegel and
Jost Tobias Springenberg and
Felix Berkenkamp and
Abbas Abdolmaleki and
Michael Neunert and
Thomas Lampe and
Roland Hafner and
Nicolas Heess and
Martin A. Riedmiller},
 booktitle = {Proc. of ICLR},
 title = {Keep Doing What Worked: Behavior Modelling Priors for Offline Reinforcement
Learning},
 year = {2020}
}

@inproceedings{silver2014deterministic,
 author = {David Silver and
Guy Lever and
Nicolas Heess and
Thomas Degris and
Daan Wierstra and
Martin A. Riedmiller},
 booktitle = {Proc. of ICML},
 pages = {387--395},
 title = {Deterministic Policy Gradient Algorithms},
 year = {2014}
}

@article{silver2017mastering,
 author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
 journal = {nature},
 title = {Mastering the game of go without human knowledge},
 year = {2017}
}

@inproceedings{sohn2020brpo,
 author = {Sungryull Sohn and
Yinlam Chow and
Jayden Ooi and
Ofir Nachum and
Honglak Lee and
Ed Chi and
Craig Boutilier},
 booktitle = {Proc. of IJCAI},
 pages = {2824--2830},
 title = {{BRPO:} Batch Residual Policy Optimization},
 year = {2020}
}

@article{srivastava2019training,
 author = {Srivastava, Rupesh Kumar and Shyam, Pranav and Mutz, Filipe and Ja{\'s}kowski, Wojciech and Schmidhuber, J{\"u}rgen},
 journal = {ArXiv preprint},
 title = {Training agents using upside-down reinforcement learning},
 year = {2019}
}

@article{stable-baselines3,
 author = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},
 journal = {Journal of Machine Learning Research},
 pages = {1-8},
 title = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
 year = {2021}
}

@book{sutton1998introduction,
 author = {Sutton, Richard S and Barto, Andrew G and others},
 publisher = {MIT press Cambridge},
 title = {Introduction to reinforcement learning},
 year = {1998}
}

@article{sutton1999between,
 author = {Sutton, Richard S and Precup, Doina and Singh, Satinder},
 journal = {Artificial intelligence},
 title = {Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
 year = {1999}
}

@inproceedings{tang2021model,
 author = {Tang, Shengpu and Wiens, Jenna},
 booktitle = {Proc. of ML4H},
 title = {Model selection for offline reinforcement learning: Practical considerations for healthcare settings},
 year = {2021}
}

@article{tavner2007reliability,
 author = {Tavner, PJ and Xiang, Jiangping and Spinato, Fabio},
 journal = {Wind Energy: An International Journal for Progress and Applications in Wind Power Conversion Technology},
 title = {Reliability analysis for wind turbines},
 year = {2007}
}

@inproceedings{tessler2018reward,
 author = {Chen Tessler and
Daniel J. Mankowitz and
Shie Mannor},
 booktitle = {Proc. of ICLR},
 title = {Reward Constrained Policy Optimization},
 year = {2019}
}

@inproceedings{todorov2012mujoco,
 author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
 booktitle = {Proc. of IROS},
 title = {Mujoco: A physics engine for model-based control},
 year = {2012}
}

@inproceedings{torabi2018behavioral,
 author = {Faraz Torabi and
Garrett Warnell and
Peter Stone},
 booktitle = {Proc. of IJCAI},
 pages = {4950--4957},
 title = {Behavioral Cloning from Observation},
 year = {2018}
}

@article{TT,
 author = {Janner, Michael and Li, Qiyang and Levine, Sergey},
 journal = {Proc. of NeurIPS},
 title = {Offline Reinforcement Learning as One Big Sequence Modeling Problem},
 year = {2021}
}

@inproceedings{van2016deep,
 author = {Hado van Hasselt and
Arthur Guez and
David Silver},
 booktitle = {Proc. of AAAI},
 pages = {2094--2100},
 title = {Deep Reinforcement Learning with Double Q-Learning},
 year = {2016}
}

@article{van2018deep,
 author = {Van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
 journal = {ArXiv preprint},
 title = {Deep reinforcement learning and the deadly triad},
 year = {2018}
}

@article{vinyals2019grandmaster,
 author = {Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
 journal = {Nature},
 title = {Grandmaster level in StarCraft II using multi-agent reinforcement learning},
 year = {2019}
}

@inproceedings{virmaux2018lipschitz,
 author = {Aladin Virmaux and
Kevin Scaman},
 booktitle = {Proc. of NeurIPS},
 pages = {3839--3848},
 title = {Lipschitz regularity of deep neural networks: analysis and efficient
estimation},
 year = {2018}
}

@inproceedings{wang2008stable,
 author = {Tao Wang and
Daniel J. Lizotte and
Michael H. Bowling and
Dale Schuurmans},
 booktitle = {Proc. of NeurIPS},
 pages = {1569--1576},
 title = {Stable Dual Dynamic Programming},
 year = {2007}
}

@article{wang2017primal,
 author = {Wang, Mengdi},
 journal = {ArXiv preprint},
 title = {Primal-Dual $pi$ Learning: Sample Complexity and Sublinear Run Time for Ergodic Markov Decision Problems},
 year = {2017}
}

@inproceedings{wang2018exponentially,
 author = {Qing Wang and
Jiechao Xiong and
Lei Han and
Peng Sun and
Han Liu and
Tong Zhang},
 booktitle = {Proc. of NeurIPS},
 pages = {6291--6300},
 title = {Exponentially Weighted Imitation Learning for Batched Historical Data},
 year = {2018}
}

@inproceedings{wang2020critic,
 author = {Ziyu Wang and
Alexander Novikov and
Konrad Zolna and
Josh Merel and
Jost Tobias Springenberg and
Scott E. Reed and
Bobak Shahriari and
Noah Y. Siegel and
{\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
Nicolas Heess and
Nando de Freitas},
 booktitle = {Proc. of NeurIPS},
 title = {Critic Regularized Regression},
 year = {2020}
}

@inproceedings{wang2020truly,
 author = {Yuhui Wang and
Hao He and
Xiaoyang Tan},
 booktitle = {Proc. of UAI},
 pages = {113--122},
 title = {Truly Proximal Policy Optimization},
 year = {2019}
}

@article{watkins1992q,
 author = {Watkins, Christopher JCH and Dayan, Peter},
 journal = {Machine learning},
 title = {Q-learning},
 year = {1992}
}

@article{wu2019behavior,
 author = {Wu, Yifan and Tucker, George and Nachum, Ofir},
 journal = {ArXiv preprint},
 title = {Behavior Regularized Offline Reinforcement Learning},
 year = {2019}
}

@inproceedings{wu2019domain,
 author = {Yifan Wu and
Ezra Winston and
Divyansh Kaushik and
Zachary C. Lipton},
 booktitle = {Proc. of ICML},
 pages = {6872--6881},
 title = {Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment},
 year = {2019}
}

@inproceedings{wu2021uncertainty,
 author = {Yue Wu and
Shuangfei Zhai and
Nitish Srivastava and
Joshua M. Susskind and
Jian Zhang and
Ruslan Salakhutdinov and
Hanlin Goh},
 booktitle = {Proc. of ICML},
 pages = {11319--11328},
 title = {Uncertainty Weighted Actor-Critic for Offline Reinforcement Learning},
 year = {2021}
}

@article{xu2021offline,
 author = {Xu, Haoran and Zhan, Xianyuan and Li, Jianxiong and Yin, Honglei},
 journal = {ArXiv preprint},
 title = {Offline Reinforcement Learning with Soft Behavior Regularization},
 year = {2021}
}

@inproceedings{xu2022constraints,
 author = {Xu, Haoran and Zhan, Xianyuan and Zhu, Xiangyu},
 booktitle = {Proc. of AAAI},
 pages = {8753--8760},
 title = {Constraints penalized q-learning for safe offline reinforcement learning},
 year = {2022}
}

@inproceedings{xu2022discriminator,
 author = {Xu, Haoran and Zhan, Xianyuan and Yin, Honglei and Qin, Huiling},
 booktitle = {Proc. of ICML},
 pages = {24725-24742},
 title = {Discriminator-Weighted Offline Imitation Learning from Suboptimal Demonstrations},
 year = {2022}
}

@article{yang2022rethinking,
 author = {Yang, Rui and Lu, Yiming and Li, Wenzhe and Sun, Hao and Fang, Meng and Du, Yali and Li, Xiu and Han, Lei and Zhang, Chongjie},
 journal = {ArXiv preprint},
 title = {Rethinking Goal-conditioned Supervised Learning and Its Connection to Offline RL},
 year = {2022}
}

@inproceedings{yu2020mopo,
 author = {Tianhe Yu and
Garrett Thomas and
Lantao Yu and
Stefano Ermon and
James Y. Zou and
Sergey Levine and
Chelsea Finn and
Tengyu Ma},
 booktitle = {Proc. of NeurIPS},
 title = {{MOPO:} Model-based Offline Policy Optimization},
 year = {2020}
}

@article{yu2022leverage,
 author = {Yu, Tianhe and Kumar, Aviral and Chebotar, Yevgen and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
 journal = {ArXiv preprint},
 title = {How to Leverage Unlabeled Data in Offline Reinforcement Learning},
 year = {2022}
}

@inproceedings{zhan2022model,
  author = {Zhan, Xianyuan and Zhu, Xiangyu and Xu, Haoran},
  booktitle = {Proc. of IJCAI},
  title = {Model-based offline planning with trajectory pruning},
  year={2022}
}

@inproceedings{zhan2022deepthermal,
 author = {Zhan, Xianyuan and Xu, Haoran and Zhang, Yue and Zhu, Xiangyu and Yin, Honglei and Zheng, Yu},
 booktitle = {Proc. of AAAI},
 pages = {4680--4688},
 title = {Deepthermal: Combustion optimization for thermal power generating units using offline reinforcement learning},
 year = {2022}
}

@inproceedings{zhang2020learning,
 author = {Amy Zhang and
Rowan Thomas McAllister and
Roberto Calandra and
Yarin Gal and
Sergey Levine},
 booktitle = {Proc. of ICLR},
 title = {Learning Invariant Representations for Reinforcement Learning without
Reconstruction},
 year = {2021}
}

@article{zhang2021brac+,
 author = {Zhang, Chi and Kuppannagari, Sanmukh Rao and Prasanna, Viktor K},
 journal = {ArXiv preprint},
 title = {BRAC+: Improved Behavior Regularized Actor Critic for Offline Reinforcement Learning},
 year = {2021}
}

@inproceedings{zhou2020latent,
 author = {Zhou, Wenxuan and Bajracharya, Sujay and Held, David},
 booktitle = {Conference on Robot Learning},
 title = {Latent Action Space for Offline Reinforcement Learning},
 year = {2020}
}

@article{zolna2020offline,
 author = {Zolna, Konrad and Novikov, Alexander and Konyushkova, Ksenia and Gulcehre, Caglar and Wang, Ziyu and Aytar, Yusuf and Denil, Misha and de Freitas, Nando and Reed, Scott},
 journal = {ArXiv preprint},
 title = {Offline learning from demonstrations and unlabeled experience},
 year = {2020}
}

@inproceedings{ma2022offline,
  author={Ma, Xiaoteng and Yang, Yiqin and Hu, Hao and Liu, Qihan and Yang, Jun and Zhang, Chongjie and Zhao, Qianchuan and Liang, Bin},
  booktitle = {Proc. of ICLR},
  title={Offline Reinforcement Learning with Value-based Episodic Memory},
  year={2022}
}

@inproceedings{eysenbach2022imitating,
  author={Eysenbach, Benjamin and Udatha, Soumith and Levine, Sergey and Salakhutdinov, Ruslan},
  booktitle = {Proc. of NeurIPS},
  title={Imitating Past Successes can be Very Suboptimal},
  year={2022}
}

@inproceedings{brandfonbrener2022does,
  author={Brandfonbrener, David and Bietti, Alberto and Buckman, Jacob and Laroche, Romain and Bruna, Joan},
  booktitle = {Proc. of NeurIPS},
  title={When does return-conditioned supervised learning work for offline reinforcement learning?},
  year={2022}
}

@inproceedings{florensa2018automatic,
  title={Automatic goal generation for reinforcement learning agents},
  author={Florensa, Carlos and Held, David and Geng, Xinyang and Abbeel, Pieter},
  booktitle = {Proc. of ICML},
  year={2018},
}

@inproceedings{peters2007reinforcement,
  title={Reinforcement learning by reward-weighted regression for operational space control},
  author={Peters, Jan and Schaal, Stefan},
  booktitle = {Proc. of ICML},
  year={2007}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal = {ArXiv preprint},
  year={2016}
}

@inproceedings{xu2023offline,
  title   = {Offline RL with No OOD Actions: In-Sample Learning via Implicit Value Regularization},
  author  = {Haoran Xu and Li Jiang and Jianxiong Li and Zhuoran Yang and Zhaoran Wang and Victor Wai Kin Chan and Xianyuan Zhan},
  year    = {2023},
  booktitle = {Proc. of ICLR},
}