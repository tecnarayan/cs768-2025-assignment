\begin{thebibliography}{49}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alayrac et~al.(2019)Alayrac, Uesato, Huang, Fawzi, Stanforth, and
  Kohli]{alayrac2019improve}
Jean-Baptiste Alayrac, Jonathan Uesato, Po-Sen Huang, Alhussein Fawzi, Robert
  Stanforth, and Pushmeet Kohli.
\newblock Are labels required for improving adversarial robustness?
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32, 2019.

\bibitem[Azar et~al.(2017)Azar, Osband, and Munos]{UCBVI}
Mohammad~Gheshlaghi Azar, Ian Osband, and R{\'e}mi Munos.
\newblock Minimax regret bounds for reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  263--272, 2017.

\bibitem[Behzadan and Munir(2017)]{2017vulnerability}
Vahid Behzadan and Arslan Munir.
\newblock Vulnerability of deep reinforcement learning to policy induction
  attacks.
\newblock In \emph{International Conference on Machine Learning and Data Mining
  in Pattern Recognition}, pages 262--275. Springer, 2017.

\bibitem[Carmon et~al.(2019)Carmon, Raghunathan, Schmidt, Duchi, and
  Liang]{carmon2019unlabeled}
Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, John~C Duchi, and Percy~S
  Liang.
\newblock Unlabeled data improves adversarial robustness.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32, 2019.

\bibitem[Cheung et~al.(2020)Cheung, Simchi-Levi, and
  Zhu]{cheung2020reinforcement}
Wang~Chi Cheung, David Simchi-Levi, and Ruihao Zhu.
\newblock Reinforcement learning for non-stationary markov decision processes:
  The blessing of (more) optimism.
\newblock In \emph{International Conference on Machine Learning}, pages
  1843--1854, 2020.

\bibitem[Cicalese et~al.(2020)Cicalese, Laber, Molinaro,
  et~al.]{cicalese2020teaching}
Ferdinando Cicalese, Eduardo Laber, Marco Molinaro, et~al.
\newblock Teaching with limited information on the learner’s behaviour.
\newblock In \emph{International Conference on Machine Learning}, pages
  2016--2026, 2020.

\bibitem[Cohen et~al.(2019)Cohen, Rosenfeld, and Kolter]{cohen2019certified}
Jeremy Cohen, Elan Rosenfeld, and Zico Kolter.
\newblock Certified adversarial robustness via randomized smoothing.
\newblock In \emph{International Conference on Machine Learning}, pages
  1310--1320, 2019.

\bibitem[Dasgupta et~al.(2019)Dasgupta, Hsu, Poulis, and
  Zhu]{dasgupta19Teaching}
Sanjoy Dasgupta, Daniel Hsu, Stefanos Poulis, and Xiaojin Zhu.
\newblock Teaching a black-box learner.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning}, volume~97, pages 1547--1555, 2019.

\bibitem[Dohmatob(2019)]{dohmatob19nofreelunch}
Elvis Dohmatob.
\newblock Generalized no free lunch theorem for adversarial robustness.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning}, pages 1646--1654, 2019.

\bibitem[Fei et~al.(2020)Fei, Yang, Wang, and Xie]{POWER}
Yingjie Fei, Zhuoran Yang, Zhaoran Wang, and Qiaomin Xie.
\newblock Dynamic regret of policy optimization in non-stationary environments.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~33, pages 6743--6754, 2020.

\bibitem[Freedman(1975)]{freedman1975tail}
David~A Freedman.
\newblock On tail probabilities for martingales.
\newblock \emph{the Annals of Probability}, pages 100--118, 1975.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and Szegedy]{43405}
Ian Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Guan et~al.(2020)Guan, Ji, Bucci, Hu, Palombo, Liston, and
  Liang]{Guan:AAAI}
Z.~Guan, K.~Ji, D.~Bucci, T.~Hu, J.~Palombo, M.~Liston, and Y.~Liang.
\newblock Robust stochastic bandit algorithms under probabilistic unbounded
  adversarial attack.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, pages 4036--4043, New York City, NY, Feb. 2020.

\bibitem[He et~al.(2020)He, Zhou, and Gu]{he2020logarithmic}
Jiafan He, Dongruo Zhou, and Quanquan Gu.
\newblock Logarithmic regret for reinforcement learning with linear function
  approximation.
\newblock \emph{arXiv preprint arXiv:2011.11566}, 2020.

\bibitem[Huang et~al.(2017)Huang, Papernot, Goodfellow, Duan, and
  Abbeel]{huang2017adversarial}
Sandy Huang, Nicolas Papernot, Ian Goodfellow, Yan Duan, and Pieter Abbeel.
\newblock Adversarial attacks on neural network policies.
\newblock \emph{arXiv preprint arXiv:1702.02284}, 2017.

\bibitem[Huang and Zhu(2019)]{2019deceptive}
Yunhan Huang and Quanyan Zhu.
\newblock Deceptive reinforcement learning under adversarial manipulations on
  cost signals.
\newblock In \emph{International Conference on Decision and Game Theory for
  Security}, pages 217--237. Springer, 2019.

\bibitem[Jin et~al.(2018)Jin, Allen-Zhu, Bubeck, and Jordan]{UCB-H}
Chi Jin, Zeyuan Allen-Zhu, Sebastien Bubeck, and Michael~I Jordan.
\newblock Is q-learning provably efficient?
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~31, 2018.

\bibitem[Jun et~al.(2018)Jun, Li, Ma, and
  Zhu]{2018AdversarialAttacksonStochasticBandits}
Kwang-Sung Jun, Lihong Li, Yuzhe Ma, and Jerry Zhu.
\newblock Adversarial attacks on stochastic bandits.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~31, 2018.

\bibitem[Kos and Song(2017)]{kos2017delving}
Jernej Kos and Dawn Song.
\newblock Delving into adversarial attacks on deep policies.
\newblock \emph{arXiv preprint arXiv:1705.06452}, 2017.

\bibitem[Kurakin et~al.(2017)Kurakin, Goodfellow, and Bengio]{45816}
Alexey Kurakin, Ian~J. Goodfellow, and Samy Bengio.
\newblock Adversarial machine learning at scale.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Lee et~al.(2020)Lee, Ghadai, Tan, Hegde, and
  Sarkar]{lee2020spatiotemporally}
Xian~Yeow Lee, Sambit Ghadai, Kai~Liang Tan, Chinmay Hegde, and Soumik Sarkar.
\newblock Spatiotemporally constrained action space attacks on deep
  reinforcement learning agents.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, pages 4577--4584, 2020.

\bibitem[Li et~al.(2021)Li, Lai, and Cui]{li2021avd-lasso}
Fuwei Li, Lifeng Lai, and Shuguang Cui.
\newblock On the adversarial robustness of {LASSO} based feature selection.
\newblock \emph{IEEE Transactions on Signal Processing}, 69:\penalty0 5555--
  5567, 2021.

\bibitem[Lin et~al.(2017)Lin, Hong, Liao, Shih, Liu, and Sun]{lin2017tactics}
Yen-Chen Lin, Zhang-Wei Hong, Yuan-Hong Liao, Meng-Li Shih, Ming-Yu Liu, and
  Min Sun.
\newblock Tactics of adversarial attack on deep reinforcement learning agents.
\newblock In \emph{Proceedings of the 26th International Joint Conference on
  Artificial Intelligence}, IJCAI'17, page 3756–3762, 2017.

\bibitem[Liu and Shroff(2019)]{liu2019data}
Fang Liu and Ness Shroff.
\newblock Data poisoning attacks on stochastic bandits.
\newblock In \emph{International Conference on Machine Learning}, pages
  4042--4050, 2019.

\bibitem[Liu and Lai(2020{\natexlab{a}})]{AA&DonB}
Guanlin Liu and Lifeng Lai.
\newblock Action-manipulation attacks against stochastic bandits: Attacks and
  defense.
\newblock \emph{IEEE Transactions on Signal Processing}, 68:\penalty0
  5152--5165, 2020{\natexlab{a}}.

\bibitem[Liu and Lai(2020{\natexlab{b}})]{AAonB}
Guanlin Liu and Lifeng Lai.
\newblock Action-manipulation attacks on stochastic bandits.
\newblock In \emph{Proc. IEEE International Conference on Acoustics, Speech and
  Signal Processing}, pages 3112--3116, Barcelona, Spain, May
  2020{\natexlab{b}}.

\bibitem[Liu et~al.(2020)Liu, Yang, Chen, Zhang, Yang, Xiao, and
  Wang]{finrl2020}
Xiao-Yang Liu, Hongyang Yang, Qian Chen, Runjia Zhang, Liuqing Yang, Bowen
  Xiao, and Christina~Dan Wang.
\newblock Finrl: A deep reinforcement learning library for automated stock
  trading in quantitative finance.
\newblock \emph{Deep RL Workshop, NeurIPS 2020}, 2020.

\bibitem[Ma et~al.(2019)Ma, Zhang, Sun, and Zhu]{PolicyPoisoning}
Yuzhe Ma, Xuezhou Zhang, Wen Sun, and Jerry Zhu.
\newblock Policy poisoning in batch reinforcement learning and control.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32, 2019.

\bibitem[Mao et~al.(2020)Mao, Zhang, Zhu, Simchi{-}Levi, and
  Basar]{Model-Free-non-stationary}
Weichao Mao, Kaiqing Zhang, Ruihao Zhu, David Simchi{-}Levi, and Tamer Basar.
\newblock Is model-free learning nearly optimal for non-stationary rl?
\newblock \emph{arXiv preprint arXiv:2010.03161}, 2020.

\bibitem[Moosavi-Dezfooli et~al.(2017)Moosavi-Dezfooli, Fawzi, Fawzi, and
  Frossard]{moosavi2017universal}
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, and Pascal
  Frossard.
\newblock Universal adversarial perturbations.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1765--1773, 2017.

\bibitem[Nazari et~al.(2018)Nazari, Oroojlooy, Snyder, and Takac]{RL_business}
MohammadReza Nazari, Afshin Oroojlooy, Lawrence Snyder, and Martin Takac.
\newblock Reinforcement learning for solving the vehicle routing problem.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~31, 2018.

\bibitem[O\textquotesingle~Kelly et~al.(2018)O\textquotesingle~Kelly, Sinha,
  Namkoong, Tedrake, and Duchi]{RL_Car}
Matthew O\textquotesingle~Kelly, Aman Sinha, Hongseok Namkoong, Russ Tedrake,
  and John~C Duchi.
\newblock Scalable end-to-end autonomous vehicle testing via rare-event
  simulation.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~31, 2018.

\bibitem[Pinot et~al.(2019)Pinot, Meunier, Araujo, Kashima, Yger, Gouy-Pailler,
  and Atif]{pinot19theoretical}
Rafael Pinot, Laurent Meunier, Alexandre Araujo, Hisashi Kashima, Florian Yger,
  Cedric Gouy-Pailler, and Jamal Atif.
\newblock Theoretical evidence for adversarial robustness through
  randomization.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32, 2019.

\bibitem[Pinto et~al.(2017)Pinto, Davidson, Sukthankar, and
  Gupta]{pinto2017robust}
Lerrel Pinto, James Davidson, Rahul Sukthankar, and Abhinav Gupta.
\newblock Robust adversarial reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  2817--2826, 2017.

\bibitem[Precup(2000)]{precup2000eligibility}
Doina Precup.
\newblock Eligibility traces for off-policy policy evaluation.
\newblock \emph{Computer Science Department Faculty Publication Series},
  page~80, 2000.

\bibitem[Rakhsha et~al.(2020)Rakhsha, Radanovic, Devidze, Zhu, and
  Singla]{policyteaching}
Amin Rakhsha, Goran Radanovic, Rati Devidze, Xiaojin Zhu, and Adish Singla.
\newblock Policy teaching via environment poisoning: Training-time adversarial
  attacks against reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  7974--7984, 2020.

\bibitem[Rakhsha et~al.(2021{\natexlab{a}})Rakhsha, Radanovic, Devidze, Zhu,
  and Singla]{rakhsha2021policy}
Amin Rakhsha, Goran Radanovic, Rati Devidze, Xiaojin Zhu, and Adish Singla.
\newblock Policy teaching in reinforcement learning via environment poisoning
  attacks.
\newblock \emph{Journal of Machine Learning Research}, 22\penalty0
  (210):\penalty0 1--45, 2021{\natexlab{a}}.

\bibitem[Rakhsha et~al.(2021{\natexlab{b}})Rakhsha, Zhang, Zhu, and
  Singla]{arxiv-2102-08492}
Amin Rakhsha, Xuezhou Zhang, Xiaojin Zhu, and Adish Singla.
\newblock Reward poisoning in reinforcement learning: Attacks against unknown
  learners in unknown environments.
\newblock \emph{arXiv preprint arXiv:2102.08492}, 2021{\natexlab{b}}.

\bibitem[Sun et~al.(2021)Sun, Huo, and Huang]{ICLR2021}
Yanchao Sun, Da~Huo, and Furong Huang.
\newblock Vulnerability-aware poisoning mechanism for online rl with unknown
  dynamics.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{42503}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Thomas et~al.(2015)Thomas, Theocharous, and
  Ghavamzadeh]{thomas2015high}
Philip Thomas, Georgios Theocharous, and Mohammad Ghavamzadeh.
\newblock High-confidence off-policy evaluation.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~29, 2015.

\bibitem[Tropp et~al.(2011)]{tropp2011freedman}
Joel Tropp et~al.
\newblock Freedman's inequality for matrix martingales.
\newblock \emph{Electronic Communications in Probability}, 16:\penalty0
  262--270, 2011.

\bibitem[Wang et~al.(2019)Wang, Ma, Bailey, Yi, Zhou, and
  Gu]{wang2019convergence}
Yisen Wang, Xingjun Ma, James Bailey, Jinfeng Yi, Bowen Zhou, and Quanquan Gu.
\newblock On the convergence and robustness of adversarial training.
\newblock In \emph{ICML}, volume~1, page~2, 2019.

\bibitem[Wang et~al.(2018)Wang, Jha, and Chaudhuri]{wang2018analyzing}
Yizhen Wang, Somesh Jha, and Kamalika Chaudhuri.
\newblock Analyzing the robustness of nearest neighbors to adversarial
  examples.
\newblock In \emph{International Conference on Machine Learning}, pages
  5133--5142, 2018.

\bibitem[Yang et~al.(2021)Yang, Yang, and Du]{yang2021q}
Kunhe Yang, Lin Yang, and Simon Du.
\newblock Q-learning with logarithmic regret.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 1576--1584, 2021.

\bibitem[Zhang and Parkes(2008)]{zhang2008value}
Haoqi Zhang and David~C Parkes.
\newblock Value-based policy teaching with active indirect elicitation.
\newblock In \emph{AAAI}, volume~8, pages 208--214, 2008.

\bibitem[Zhang and Zhu(2019)]{zhang2019interpreting}
Tianyuan Zhang and Zhanxing Zhu.
\newblock Interpreting adversarially trained convolutional neural networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  7502--7511, 2019.

\bibitem[Zhang et~al.(2020)Zhang, Ma, Singla, and
  Zhu]{Adaptive-Reward-Poisoning}
Xuezhou Zhang, Yuzhe Ma, Adish Singla, and Xiaojin Zhu.
\newblock Adaptive reward-poisoning attacks against reinforcement learning.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, volume 119, pages 11225--11234, 2020.

\bibitem[Zhao et~al.(2018)Zhao, Xia, Zhang, Ding, Yin, and
  Tang]{RL_Recommendations}
Xiangyu Zhao, Long Xia, Liang Zhang, Zhuoye Ding, Dawei Yin, and Jiliang Tang.
\newblock Deep reinforcement learning for page-wise recommendations.
\newblock In \emph{Proceedings of the 12th ACM Conference on Recommender
  Systems}, page 95–103. ACM, 2018.

\end{thebibliography}
