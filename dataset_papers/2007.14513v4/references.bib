@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{liu2018darts,
  title={Darts: Differentiable architecture search},
  author={Liu, Hanxiao and Simonyan, Karen and Yang, Yiming},
  journal={arXiv preprint arXiv:1806.09055},
  year={2018}
}

@article{he2020milenas,
  title={Milenas: Efficient neural architecture search via mixed-level reformulation},
  author={He, Chaoyang and Ye, Haishan and Shen, Li and Zhang, Tong},
  journal={arXiv preprint arXiv:2003.12238},
  year={2020}
}

@article{tan2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc V},
  journal={arXiv preprint arXiv:1905.11946},
  year={2019}
}

@article{iandola2016squeezenet,
  title={SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 0.5 MB model size},
  author={Iandola, Forrest N and Han, Song and Moskewicz, Matthew W and Ashraf, Khalid and Dally, William J and Keutzer, Kurt},
  journal={arXiv preprint arXiv:1602.07360},
  year={2016}
}

@article{howard2017mobilenets,
  title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
  author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
  journal={arXiv preprint arXiv:1704.04861},
  year={2017}
}

@inproceedings{zhang2018shufflenet,
  title={Shufflenet: An extremely efficient convolutional neural network for mobile devices},
  author={Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6848--6856},
  year={2018}
}

@inproceedings{wu2019fbnet,
  title={Fbnet: Hardware-aware efficient convnet design via differentiable neural architecture search},
  author={Wu, Bichen and Dai, Xiaoliang and Zhang, Peizhao and Wang, Yanghan and Sun, Fei and Wu, Yiming and Tian, Yuandong and Vajda, Peter and Jia, Yangqing and Keutzer, Kurt},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={10734--10742},
  year={2019}
}

@article{han2015deep,
  title={Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
  author={Han, Song and Mao, Huizi and Dally, William J},
  journal={arXiv preprint arXiv:1510.00149},
  year={2015}
}

@inproceedings{he2018amc,
  title={Amc: Automl for model compression and acceleration on mobile devices},
  author={He, Yihui and Lin, Ji and Liu, Zhijian and Wang, Hanrui and Li, Li-Jia and Han, Song},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={784--800},
  year={2018}
}

@inproceedings{yang2018netadapt,
  title={Netadapt: Platform-aware neural network adaptation for mobile applications},
  author={Yang, Tien-Ju and Howard, Andrew and Chen, Bo and Zhang, Xiao and Go, Alec and Sandler, Mark and Sze, Vivienne and Adam, Hartwig},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={285--300},
  year={2018}
}

@article{kairouz2019advances,
  title={Advances and open problems in federated learning},
  author={Kairouz, Peter and McMahan, H Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Keith and Charles, Zachary and Cormode, Graham and Cummings, Rachel and others},
  journal={arXiv preprint arXiv:1912.04977},
  year={2019}
}


@article{mcmahan2016communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, H Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and others},
  journal={arXiv preprint arXiv:1602.05629},
  year={2016}
}

@article{he2019central,
  title={Central server free federated learning over single-sided trust social networks},
  author={He, Chaoyang and Tan, Conghui and Tang, Hanlin and Qiu, Shuang and Liu, Ji},
  journal={arXiv preprint arXiv:1910.04956},
  year={2019}
}

@article{wang2020federated,
  title={Federated Learning with Matched Averaging},
  author={Wang, Hongyi and Yurochkin, Mikhail and Sun, Yuekai and Papailiopoulos, Dimitris and Khazaeni, Yasaman},
  journal={arXiv preprint arXiv:2002.06440},
  year={2020}
}


@article{li2018federated,
  title={Federated optimization in heterogeneous networks},
  author={Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
  journal={arXiv preprint arXiv:1812.06127},
  year={2018}
}


@article{he2020fednas,
  title={FedNAS: Federated Deep Learning via Neural Architecture Search},
  author={He, Chaoyang and Annavaram, Murali and Avestimehr, Salman},
  journal={arXiv preprint arXiv:2004.08546},
  year={2020}
}

@article{wang2018cooperative,
  title={Cooperative SGD: A unified framework for the design and analysis of communication-efficient SGD algorithms},
  author={Wang, Jianyu and Joshi, Gauri},
  journal={arXiv preprint arXiv:1808.07576},
  year={2018}
}

@inproceedings{yu2019parallel,
  title={Parallel restarted SGD with faster convergence and less communication: Demystifying why model averaging works for deep learning},
  author={Yu, Hao and Yang, Sen and Zhu, Shenghuo},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={5693--5700},
  year={2019}
}

@article{vepakomma2018split,
  title={Split learning for health: Distributed deep learning without sharing raw patient data},
  author={Vepakomma, Praneeth and Gupta, Otkrist and Swedish, Tristan and Raskar, Ramesh},
  journal={arXiv preprint arXiv:1812.00564},
  year={2018}
}

@article{singh2019detailed,
  title={Detailed comparison of communication efficiency of split learning and federated learning},
  author={Singh, Abhishek and Vepakomma, Praneeth and Gupta, Otkrist and Raskar, Ramesh},
  journal={arXiv preprint arXiv:1909.09145},
  year={2019}
}

@article{darlow2018cinic,
  title={CINIC-10 is not ImageNet or CIFAR-10},
  author={Darlow, Luke N and Crowley, Elliot J and Antoniou, Antreas and Storkey, Amos J},
  journal={arXiv preprint arXiv:1810.03505},
  year={2018}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Citeseer}
}

@article{hsieh2019non,
  title={The Non-IID Data Quagmire of Decentralized Machine Learning},
  author={Hsieh, Kevin and Phanishayee, Amar and Mutlu, Onur and Gibbons, Phillip B},
  journal={arXiv preprint arXiv:1910.00189},
  year={2019}
}

@article{reddi2020adaptive,
  title={Adaptive Federated Optimization},
  author={Reddi, Sashank and Charles, Zachary and Zaheer, Manzil and Garrett, Zachary and Rush, Keith and Kone{\v{c}}n{\`y}, Jakub and Kumar, Sanjiv and McMahan, H Brendan},
  journal={arXiv preprint arXiv:2003.00295},
  year={2020}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{zou2019sufficient,
  title={A sufficient condition for convergences of adam and rmsprop},
  author={Zou, Fangyu and Shen, Li and Jie, Zequn and Zhang, Weizhong and Liu, Wei},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={11127--11135},
  year={2019}
}

@article{qian1999momentum,
  title={On the momentum term in gradient descent learning algorithms},
  author={Qian, Ning},
  journal={Neural networks},
  volume={12},
  number={1},
  pages={145--151},
  year={1999},
  publisher={Elsevier}
}

@book{ortega1970iterative,
  title={Iterative solution of nonlinear equations in several variables},
  author={Ortega, James M and Rheinboldt, Werner C},
  volume={30},
  year={1970},
  publisher={Siam}
}

@book{bertsekas1989parallel,
  title={Parallel and distributed computation: numerical methods},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  volume={23},
  year={1989},
  publisher={Prentice hall Englewood Cliffs, NJ}
}

@article{bolte2014proximal,
  title={Proximal alternating linearized minimization for nonconvex and nonsmooth problems},
  author={Bolte, J{\'e}r{\^o}me and Sabach, Shoham and Teboulle, Marc},
  journal={Mathematical Programming},
  volume={146},
  number={1-2},
  pages={459--494},
  year={2014},
  publisher={Springer}
}

@article{attouch2010proximal,
  title={Proximal alternating minimization and projection methods for nonconvex problems: An approach based on the Kurdyka-{\L}ojasiewicz inequality},
  author={Attouch, H{\'e}dy and Bolte, J{\'e}r{\^o}me and Redont, Patrick and Soubeyran, Antoine},
  journal={Mathematics of Operations Research},
  volume={35},
  number={2},
  pages={438--457},
  year={2010},
  publisher={INFORMS}
}

@article{wright2015coordinate,
  title={Coordinate descent algorithms},
  author={Wright, Stephen J},
  journal={Mathematical Programming},
  volume={151},
  number={1},
  pages={3--34},
  year={2015},
  publisher={Springer}
}

@article{razaviyayn2013unified,
  title={A unified convergence analysis of block successive minimization methods for nonsmooth optimization},
  author={Razaviyayn, Meisam and Hong, Mingyi and Luo, Zhi-Quan},
  journal={SIAM Journal on Optimization},
  volume={23},
  number={2},
  pages={1126--1153},
  year={2013},
  publisher={SIAM}
}

@article{gupta2018distributed,
  title={Distributed learning of deep neural network over multiple agents},
  author={Gupta, Otkrist and Raskar, Ramesh},
  journal={Journal of Network and Computer Applications},
  volume={116},
  pages={1--8},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{bucilu2006model,
  title={Model compression},
  author={BuciluÇŽ, Cristian and Caruana, Rich and Niculescu-Mizil, Alexandru},
  booktitle={Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={535--541},
  year={2006}
}

@inproceedings{ba2014deep,
  title={Do deep nets really need to be deep?},
  author={Ba, Jimmy and Caruana, Rich},
  booktitle={Advances in neural information processing systems},
  pages={2654--2662},
  year={2014}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@article{romero2014fitnets,
  title={Fitnets: Hints for thin deep nets},
  author={Romero, Adriana and Ballas, Nicolas and Kahou, Samira Ebrahimi and Chassang, Antoine and Gatta, Carlo and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1412.6550},
  year={2014}
}


@inproceedings{zhang2018deep,
  title={Deep mutual learning},
  author={Zhang, Ying and Xiang, Tao and Hospedales, Timothy M and Lu, Huchuan},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4320--4328},
  year={2018}
}


@article{anil2018large,
  title={Large scale distributed neural network training through online distillation},
  author={Anil, Rohan and Pereyra, Gabriel and Passos, Alexandre and Ormandi, Robert and Dahl, George E and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1804.03235},
  year={2018}
}

@inproceedings{song2018collaborative,
  title={Collaborative learning for deep neural networks},
  author={Song, Guocong and Chai, Wei},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1832--1841},
  year={2018}
}

@inproceedings{ahn2019wireless,
  title={Wireless federated distillation for distributed edge learning with heterogeneous data},
  author={Ahn, Jin-Hyun and Simeone, Osvaldo and Kang, Joonhyuk},
  booktitle={2019 IEEE 30th Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)},
  pages={1--6},
  year={2019},
  organization={IEEE}
}

@article{park2019distilling,
  title={Distilling on-device intelligence at the network edge},
  author={Park, Jihong and Wang, Shiqiang and Elgabli, Anis and Oh, Seungeun and Jeong, Eunjeong and Cha, Han and Kim, Hyesung and Kim, Seong-Lyun and Bennis, Mehdi},
  journal={arXiv preprint arXiv:1908.05895},
  year={2019}
}

@article{jeong2018communication,
  title={Communication-efficient on-device machine learning: Federated distillation and augmentation under non-iid private data},
  author={Jeong, Eunjeong and Oh, Seungeun and Kim, Hyesung and Park, Jihong and Bennis, Mehdi and Kim, Seong-Lyun},
  journal={arXiv preprint arXiv:1811.11479},
  year={2018}
}

@article{chen2019online,
  title={Online Knowledge Distillation with Diverse Peers},
  author={Chen, Defang and Mei, Jian-Ping and Wang, Can and Feng, Yan and Chen, Chun},
  journal={arXiv preprint arXiv:1912.00350},
  year={2019}
}

@article{tran2020hydra,
  title={Hydra: Preserving Ensemble Diversity for Model Distillation},
  author={Tran, Linh and Veeling, Bastiaan S and Roth, Kevin and Swiatkowski, Jakub and Dillon, Joshua V and Snoek, Jasper and Mandt, Stephan and Salimans, Tim and Nowozin, Sebastian and Jenatton, Rodolphe},
  journal={arXiv preprint arXiv:2001.04694},
  year={2020}
}

@inproceedings{zhu2018knowledge,
  title={Knowledge distillation by on-the-fly native ensemble},
  author={Zhu, Xiatian and Gong, Shaogang and others},
  booktitle={Advances in neural information processing systems},
  pages={7517--7527},
  year={2018}
}

@inproceedings{vongkulbhisal2019unifying,
  title={Unifying heterogeneous classifiers with distillation},
  author={Vongkulbhisal, Jayakorn and Vinayavekhin, Phongtharin and Visentini-Scarzanella, Marco},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3175--3184},
  year={2019}
}


@article{caldas2018leaf,
  title={Leaf: A benchmark for federated settings},
  author={Caldas, Sebastian and Wu, Peter and Li, Tian and Kone{\v{c}}n{\`y}, Jakub and McMahan, H Brendan and Smith, Virginia and Talwalkar, Ameet},
  journal={arXiv preprint arXiv:1812.01097},
  year={2018}
}

@article{shi2020learning,
  title={On Learning Rates and Schr$\backslash$" odinger Operators},
  author={Shi, Bin and Su, Weijie J and Jordan, Michael I},
  journal={arXiv preprint arXiv:2004.06977},
  year={2020}
}

@article{li2019exponential,
  title={An exponential learning rate schedule for deep learning},
  author={Li, Zhiyuan and Arora, Sanjeev},
  journal={arXiv preprint arXiv:1910.07454},
  year={2019}
}

@inproceedings{wangni2018gradient,
  title={Gradient sparsification for communication-efficient distributed optimization},
  author={Wangni, Jianqiao and Wang, Jialei and Liu, Ji and Zhang, Tong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1299--1309},
  year={2018}
}

@inproceedings{tang2018communication,
  title={Communication compression for decentralized training},
  author={Tang, Hanlin and Gan, Shaoduo and Zhang, Ce and Zhang, Tong and Liu, Ji},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7652--7662},
  year={2018}
}

@inproceedings{alistarh2017qsgd,
  title={QSGD: Communication-efficient SGD via gradient quantization and encoding},
  author={Alistarh, Dan and Grubic, Demjan and Li, Jerry and Tomioka, Ryota and Vojnovic, Milan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1709--1720},
  year={2017}
}

@article{bernstein2018signsgd,
  title={signSGD: Compressed optimisation for non-convex problems},
  author={Bernstein, Jeremy and Wang, Yu-Xiang and Azizzadenesheli, Kamyar and Anandkumar, Anima},
  journal={arXiv preprint arXiv:1802.04434},
  year={2018}
}

@article{lin2017deep,
  title={Deep gradient compression: Reducing the communication bandwidth for distributed training},
  author={Lin, Yujun and Han, Song and Mao, Huizi and Wang, Yu and Dally, William J},
  journal={arXiv preprint arXiv:1712.01887},
  year={2017}
}

@article{bonawitz2019towards,
  title={Towards federated learning at scale: System design},
  author={Bonawitz, Keith and Eichner, Hubert and Grieskamp, Wolfgang and Huba, Dzmitry and Ingerman, Alex and Ivanov, Vladimir and Kiddon, Chloe and Konecny, Jakub and Mazzocchi, Stefano and McMahan, H Brendan and others},
  journal={arXiv preprint arXiv:1902.01046},
  year={2019}
}

@inproceedings{paszke2019pytorch,
  title={PyTorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8024--8035},
  year={2019}
}

@inproceedings{abadi2016tensorflow,
  title={Tensorflow: A system for large-scale machine learning},
  author={Abadi, Mart{\'\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others},
  booktitle={12th $\{$USENIX$\}$ Symposium on Operating Systems Design and Implementation ($\{$OSDI$\}$ 16)},
  pages={265--283},
  year={2016}
}

@online{AI_and_Compute,
  author = {OpenAI},
  title = {AI and Compute},
  year = {2018},
  url = {https://openai.com/blog/ai-and-compute/},
  note = {https://openai.com/blog/ai-and-compute},
  urldate = {2018-05-16}
}

@article{hernandez2020measuring,
  title={Measuring the Algorithmic Efficiency of Neural Networks},
  author={Hernandez, Danny and Brown, Tom B},
  journal={arXiv preprint arXiv:2005.04305},
  year={2020}
}

@inproceedings{wang2018atomo,
  title={Atomo: Communication-efficient learning via atomic sparsification},
  author={Wang, Hongyi and Sievert, Scott and Liu, Shengchao and Charles, Zachary and Papailiopoulos, Dimitris and Wright, Stephen},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9850--9861},
  year={2018}
}



@article{so2020turboaggregate,
  title={Turbo-Aggregate: Breaking the Quadratic Aggregation Barrier in Secure Federated Learning},
  author={Jinhyun So and Basak Guler and A. Salman Avestimehr},
  journal={arXiv preprint arXiv:2002.04156},
  year={2020}
}

@article{so2020byzantineresilient,
  title={Byzantine-Resilient Secure Federated Learning},
  author={Jinhyun So and Basak Guler and A. Salman Avestimehr},
  journal={arXiv preprint arXiv:2007.11115},
  year={2020}
}


@article{elkordy2020secure,
  title={Secure Aggregation with Heterogeneous Quantization in Federated Learning},
  author={Ahmed Roushdy Elkordy and A. Salman Avestimehr},
  journal={arXiv preprint arXiv:2009.14388},
  year={2020}
}


@article{chaoyanghe2020fedml,
  Author = {He, Chaoyang and Li, Songze and So, Jinhyun and Zhang, Mi and Wang, Hongyi and Wang, Xiaoyang and Vepakomma, Praneeth and Singh, Abhishek and Qiu, Hang and Shen, Li and Zhao, Peilin and Kang, Yan and Liu, Yang and Raskar, Ramesh and Yang, Qiang and Annavaram, Murali and Avestimehr, Salman},
  Journal = {arXiv preprint arXiv:2007.13518},
  Title = {FedML: A Research Library and Benchmark for Federated Machine Learning},
  year={2020}
}

@article{wang2020tackling,
  title={Tackling the objective inconsistency problem in heterogeneous federated optimization},
  author={Wang, Jianyu and Liu, Qinghua and Liang, Hao and Joshi, Gauri and Poor, H Vincent},
  journal={arXiv preprint arXiv:2007.07481},
  year={2020}
}

@article{wang2020attack,
  title={Attack of the tails: Yes, you really can backdoor federated learning},
  author={Wang, Hongyi and Sreenivasan, Kartik and Rajput, Shashank and Vishwakarma, Harit and Agarwal, Saurabh and Sohn, Jy-yong and Lee, Kangwook and Papailiopoulos, Dimitris},
  journal={arXiv preprint arXiv:2007.05084},
  year={2020}
}

@article{lin2020ensemble,
  title={Ensemble Distillation for Robust Model Fusion in Federated Learning},
  author={Lin, Tao and Kong, Lingjing and Stich, Sebastian U and Jaggi, Martin},
  journal={arXiv preprint arXiv:2006.07242},
  year={2020}
}

@inproceedings{bistritz2020,
    title={Distributed Distillation for On-Device Learning},
    author={Bistritz, Ilai and Mann, Ariana and Bambos, Nicholas},
    booktitle = {Advances in Neural Information Processing Systems 33},
    year={2020}
}

@article{lee2020asynchronous,
  title={Asynchronous Edge Learning using Cloned Knowledge Distillation},
  author={Lee, Sang-ho and Yoo, Kiyoon and Kwak, Nojun},
  journal={arXiv preprint arXiv:2010.10338},
  year={2020}
}

@article{zhou2020distilled,
  title={Distilled One-Shot Federated Learning},
  author={Zhou, Yanlin and Pu, George and Ma, Xiyao and Li, Xiaolin and Wu, Dapeng},
  journal={arXiv preprint arXiv:2009.07999},
  year={2020}
}

@article{sun2020federated,
  title={Federated Model Distillation with Noise-Free Differential Privacy},
  author={Sun, Lichao and Lyu, Lingjuan},
  journal={arXiv preprint arXiv:2009.05537},
  year={2020}
}

@article{ma2020adaptive,
  title={Adaptive Distillation for Decentralized Learning from Heterogeneous Clients},
  author={Ma, Jiaxin and Yonetani, Ryo and Iqbal, Zahid},
  journal={arXiv preprint arXiv:2008.07948},
  year={2020}
}

@article{itahara2020distillation,
  title={Distillation-Based Semi-Supervised Federated Learning for Communication-Efficient Collaborative Training with Non-IID Private Data},
  author={Itahara, Sohei and Nishio, Takayuki and Koda, Yusuke and Morikura, Masahiro and Yamamoto, Koji},
  journal={arXiv preprint arXiv:2008.06180},
  year={2020}
}

@article{li2020model,
  title={Model-Agnostic Round-Optimal Federated Learning via Knowledge Transfer},
  author={Li, Qinbin and He, Bingsheng and Song, Dawn},
  journal={arXiv preprint arXiv:2010.01017},
  year={2020}
}