\begin{thebibliography}{10}

\bibitem{arjona2019rudder}
Jose~A Arjona-Medina, Michael Gillhofer, Michael Widrich, Thomas Unterthiner,
  Johannes Brandstetter, and Sepp Hochreiter.
\newblock Rudder: Return decomposition for delayed rewards.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  13566--13577, 2019.

\bibitem{baddeley1974working}
Alan~D Baddeley and Graham Hitch.
\newblock Working memory.
\newblock In {\em Psychology of learning and motivation}, volume~8, pages
  47--89. Elsevier, 1974.

\bibitem{bellemare2013arcade}
Marc~G Bellemare, Yavar Naddaf, Joel Veness, and Michael Bowling.
\newblock The arcade learning environment: An evaluation platform for general
  agents.
\newblock {\em Journal of Artificial Intelligence Research}, 47:253--279, 2013.

\bibitem{blundell2016model}
Charles Blundell, Benigno Uria, Alexander Pritzel, Yazhe Li, Avraham Ruderman,
  Joel~Z Leibo, Jack Rae, Daan Wierstra, and Demis Hassabis.
\newblock Model-free episodic control.
\newblock {\em arXiv preprint arXiv:1606.04460}, 2016.

\bibitem{gym_miniworld}
Maxime Chevalier-Boisvert.
\newblock gym-miniworld environment for openai gym.
\newblock \url{https://github.com/maximecb/gym-miniworld}, 2018.

\bibitem{dudai2005janus}
Yadin Dudai and Mary Carruthers.
\newblock The janus face of mnemosyne.
\newblock {\em Nature}, 434(7033):567--567, 2005.

\bibitem{farrell2012temporal}
Simon Farrell.
\newblock Temporal clustering and sequencing in short-term memory and episodic
  memory.
\newblock {\em Psychological review}, 119(2):223, 2012.

\bibitem{fortunato2019generalization}
Meire Fortunato, Melissa Tan, Ryan Faulkner, Steven Hansen,
  Adri{\`a}~Puigdom{\`e}nech Badia, Gavin Buttimore, Charlie Deck, Joel~Z
  Leibo, and Charles Blundell.
\newblock Generalization of reinforcement learners with working and episodic
  memory.
\newblock In {\em NeurIPS}, 2019.

\bibitem{gershman2017reinforcement}
Samuel~J Gershman and Nathaniel~D Daw.
\newblock Reinforcement learning and episodic memory in humans and animals: an
  integrative framework.
\newblock {\em Annual review of psychology}, 68:101--128, 2017.

\bibitem{graves2014neural}
Alex Graves, Greg Wayne, and Ivo Danihelka.
\newblock Neural turing machines.
\newblock {\em arXiv preprint arXiv:1410.5401}, 2014.

\bibitem{graves2016hybrid}
Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka
  Grabska-Barwi{\'n}ska, Sergio~G{\'o}mez Colmenarejo, Edward Grefenstette,
  Tiago Ramalho, John Agapiou, et~al.
\newblock Hybrid computing using a neural network with dynamic external memory.
\newblock {\em Nature}, 538(7626):471--476, 2016.

\bibitem{grcar2010matrix}
Joseph~F Grcar.
\newblock A matrix lower bound.
\newblock {\em Linear algebra and its applications}, 433(1):203--220, 2010.

\bibitem{ha2018recurrent}
David Ha and J{\"u}rgen Schmidhuber.
\newblock Recurrent world models facilitate policy evolution.
\newblock In {\em Advances in neural information processing systems}, pages
  2450--2462, 2018.

\bibitem{hafner2019learning}
Danijar Hafner, Timothy Lillicrap, Ian Fischer, Ruben Villegas, David Ha,
  Honglak Lee, and James Davidson.
\newblock Learning latent dynamics for planning from pixels.
\newblock In {\em International Conference on Machine Learning}, pages
  2555--2565. PMLR, 2019.

\bibitem{hafner2020mastering}
Danijar Hafner, Timothy~P Lillicrap, Mohammad Norouzi, and Jimmy Ba.
\newblock Mastering atari with discrete world models.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{hansen2018fast}
Steven Hansen, Alexander Pritzel, Pablo Sprechmann, Andr{\'e} Barreto, and
  Charles Blundell.
\newblock Fast deep reinforcement learning using online adjustments from the
  past.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  10567--10577, 2018.

\bibitem{hausknecht2015deep}
Matthew Hausknecht and Peter Stone.
\newblock Deep recurrent q-learning for partially observable mdps.
\newblock {\em arXiv preprint arXiv:1507.06527}, 2015.

\bibitem{he2019learning}
Frank~S He, Yang Liu, Alexander~G Schwing, and Jian Peng.
\newblock Learning to play in a day: Faster deep reinforcement learning by
  optimality tightening.
\newblock In {\em 5th International Conference on Learning Representations,
  ICLR 2017}, 2019.

\bibitem{hochreiter1997long}
Sepp Hochreiter and J{\"u}rgen Schmidhuber.
\newblock Long short-term memory.
\newblock {\em Neural computation}, 9(8):1735--1780, 1997.

\bibitem{hu2021generalizable}
Hao Hu, Jianing Ye, Zhizhou Ren, Guangxiang Zhu, and Chongjie Zhang.
\newblock Generalizable episodic memory for deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:2103.06469}, 2021.

\bibitem{hung2019optimizing}
Chia-Chun Hung, Timothy Lillicrap, Josh Abramson, Yan Wu, Mehdi Mirza, Federico
  Carnevale, Arun Ahuja, and Greg Wayne.
\newblock Optimizing agent behavior over long time scales by transporting
  value.
\newblock {\em Nature communications}, 10(1):1--12, 2019.

\bibitem{jaakkola1994convergence}
Tommi Jaakkola, Michael~I Jordan, and Satinder~P Singh.
\newblock On the convergence of stochastic iterative dynamic programming
  algorithms.
\newblock {\em Neural computation}, 6(6):1185--1201, 1994.

\bibitem{kaiser2019model}
Lukasz Kaiser, Mohammad Babaeizadeh, Piotr Milos, Blazej Osinski, Roy~H
  Campbell, Konrad Czechowski, Dumitru Erhan, Chelsea Finn, Piotr Kozakowski,
  Sergey Levine, et~al.
\newblock Model-based reinforcement learning for atari.
\newblock {\em arXiv preprint arXiv:1903.00374}, 2019.

\bibitem{kumaran2016learning}
Dharshan Kumaran, Demis Hassabis, and James~L McClelland.
\newblock What learning systems do intelligent agents need? complementary
  learning systems theory updated.
\newblock {\em Trends in cognitive sciences}, 20(7):512--534, 2016.

\bibitem{le2019learning}
Hung Le, Truyen Tran, and Svetha Venkatesh.
\newblock Learning to remember more with less memorization.
\newblock {\em arXiv preprint arXiv:1901.01347}, 2019.

\bibitem{pmlr-v119-le20b}
Hung Le, Truyen Tran, and Svetha Venkatesh.
\newblock Self-attentive associative memory.
\newblock In {\em Proceedings of the 37th International Conference on Machine
  Learning}, volume 119 of {\em Proceedings of Machine Learning Research},
  pages 5682--5691, Virtual, 13--18 Jul 2020. PMLR.

\bibitem{le2020neurocoder}
Hung Le and Svetha Venkatesh.
\newblock Neurocoder: Learning general-purpose computation using stored neural
  programs.
\newblock {\em arXiv preprint arXiv:2009.11443}, 2020.

\bibitem{lee2019sample}
Su~Young Lee, Choi Sungik, and Sae-Young Chung.
\newblock Sample-efficient deep reinforcement learning via episodic backward
  update.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2112--2121, 2019.

\bibitem{lengyel2008hippocampal}
M{\'a}t{\'e} Lengyel and Peter Dayan.
\newblock Hippocampal contributions to control: the third way.
\newblock In {\em Advances in neural information processing systems}, pages
  889--896, 2008.

\bibitem{lin2018episodic}
Zichuan Lin, Tianqi Zhao, Guangwen Yang, and Lintao Zhang.
\newblock Episodic memory deep q-networks.
\newblock {\em arXiv preprint arXiv:1805.07603}, 2018.

\bibitem{mcclelland1995there}
James~L McClelland, Bruce~L McNaughton, and Randall~C O'Reilly.
\newblock Why there are complementary learning systems in the hippocampus and
  neocortex: insights from the successes and failures of connectionist models
  of learning and memory.
\newblock {\em Psychological review}, 102(3):419, 1995.

\bibitem{melo2001convergence}
Francisco~S Melo.
\newblock Convergence of q-learning: A simple proof.
\newblock {\em Institute Of Systems and Robotics, Tech. Rep}, pages 1--4, 2001.

\bibitem{mnih2016asynchronous}
Volodymyr Mnih, Adria~Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy
  Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu.
\newblock Asynchronous methods for deep reinforcement learning.
\newblock In {\em International conference on machine learning}, pages
  1928--1937, 2016.

\bibitem{mnih2015human}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei~A Rusu, Joel Veness,
  Marc~G Bellemare, Alex Graves, Martin Riedmiller, Andreas~K Fidjeland, Georg
  Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock {\em nature}, 518(7540):529--533, 2015.

\bibitem{nishio2018faster}
Daichi Nishio and Satoshi Yamane.
\newblock Faster deep q-learning using neural episodic control.
\newblock In {\em 2018 IEEE 42nd Annual Computer Software and Applications
  Conference (COMPSAC)}, volume~1, pages 486--491. IEEE, 2018.

\bibitem{pritzel2017neural}
Alexander Pritzel, Benigno Uria, Sriram Srinivasan, Adria~Puigdomenech Badia,
  Oriol Vinyals, Demis Hassabis, Daan Wierstra, and Charles Blundell.
\newblock Neural episodic control.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 2827--2836. JMLR. org, 2017.

\bibitem{schaul2015prioritized}
Tom Schaul, John Quan, Ioannis Antonoglou, and David Silver.
\newblock Prioritized experience replay.
\newblock {\em arXiv preprint arXiv:1511.05952}, 2015.

\bibitem{schulman2017proximal}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock {\em arXiv preprint arXiv:1707.06347}, 2017.

\bibitem{sutton1991dyna}
Richard~S Sutton.
\newblock Dyna, an integrated architecture for learning, planning, and
  reacting.
\newblock {\em ACM Sigart Bulletin}, 2(4):160--163, 1991.

\bibitem{sutton2018reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock {\em Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem{tulving2002episodic}
Endel Tulving.
\newblock Episodic memory: From mind to brain.
\newblock {\em Annual review of psychology}, 53(1):1--25, 2002.

\bibitem{tulving1972episodic}
Endel Tulving et~al.
\newblock Episodic and semantic memory.
\newblock {\em Organization of memory}, 1:381--403, 1972.

\bibitem{watkins1992q}
Christopher~JCH Watkins and Peter Dayan.
\newblock Q-learning.
\newblock {\em Machine learning}, 8(3-4):279--292, 1992.

\bibitem{wayne2018unsupervised}
Greg Wayne, Chia-Chun Hung, David Amos, Mehdi Mirza, Arun Ahuja, Agnieszka
  Grabska-Barwinska, Jack Rae, Piotr Mirowski, Joel~Z Leibo, Adam Santoro,
  et~al.
\newblock Unsupervised predictive memory in a goal-directed agent.
\newblock {\em arXiv preprint arXiv:1803.10760}, 2018.

\bibitem{zambaldi2018deep}
Vinicius Zambaldi, David Raposo, Adam Santoro, Victor Bapst, Yujia Li, Igor
  Babuschkin, Karl Tuyls, David Reichert, Timothy Lillicrap, Edward Lockhart,
  et~al.
\newblock Deep reinforcement learning with relational inductive biases.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{zhu2019episodic}
Guangxiang Zhu, Zichuan Lin, Guangwen Yang, and Chongjie Zhang.
\newblock Episodic reinforcement learning with associative memory.
\newblock In {\em International Conference on Learning Representations}, 2019.

\end{thebibliography}
