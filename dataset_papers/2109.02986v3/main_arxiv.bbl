\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Angluin and Laird(1988)]{angluin1988learning}
Dana Angluin and Philip Laird.
\newblock Learning from noisy examples.
\newblock \emph{Machine Learning}, 2\penalty0 (4):\penalty0 343--370, 1988.

\bibitem[Arpit et~al.(2017)Arpit, Jastrz{\k{e}}bski, Ballas, Krueger, Bengio,
  Kanwal, Maharaj, Fischer, Courville, Bengio, et~al.]{arpit2017closer}
Devansh Arpit, Stanis{\l}aw Jastrz{\k{e}}bski, Nicolas Ballas, David Krueger,
  Emmanuel Bengio, Maxinder~S Kanwal, Tegan Maharaj, Asja Fischer, Aaron
  Courville, Yoshua Bengio, et~al.
\newblock A closer look at memorization in deep networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  233--242. PMLR, 2017.

\bibitem[Belkin et~al.(2006)Belkin, Niyogi, and Sindhwani]{belkin2006manifold}
Mikhail Belkin, Partha Niyogi, and Vikas Sindhwani.
\newblock Manifold regularization: A geometric framework for learning from
  labeled and unlabeled examples.
\newblock \emph{Journal of machine learning research}, 7\penalty0 (11), 2006.

\bibitem[Berthon et~al.(2021)Berthon, Han, Niu, Liu, and
  Sugiyama]{berthon2020idn}
Antonin Berthon, Bo~Han, Gang Niu, Tongliang Liu, and Masashi Sugiyama.
\newblock Confidence scores make instance-dependent label-noise learning
  possible.
\newblock In \emph{ICML}, 2021.

\bibitem[Blei et~al.(2017)Blei, Kucukelbir, and McAuliffe]{blei2017variational}
David~M Blei, Alp Kucukelbir, and Jon~D McAuliffe.
\newblock Variational inference: A review for statisticians.
\newblock \emph{Journal of the American statistical Association}, 112\penalty0
  (518):\penalty0 859--877, 2017.

\bibitem[Cheng et~al.(2021)Cheng, Zhu, Li, Gong, Sun, and
  Liu]{cheng2020learning}
Hao Cheng, Zhaowei Zhu, Xingyu Li, Yifei Gong, Xing Sun, and Yang Liu.
\newblock Learning with instance-dependent label noise: A sample sieve
  approach.
\newblock In \emph{ICLR}, 2021.

\bibitem[Cheng et~al.(2020)Cheng, Liu, Ramamohanarao, and
  Tao]{cheng2017learning}
Jiacheng Cheng, Tongliang Liu, Kotagiri Ramamohanarao, and Dacheng Tao.
\newblock Learning with bounded instance and label-dependent label noise.
\newblock In \emph{ICML}, 2020.

\bibitem[Goldberger and Ben-Reuven(2017)]{goldberger2016training}
Jacob Goldberger and Ehud Ben-Reuven.
\newblock Training deep neural-networks using a noise adaptation layer.
\newblock In \emph{ICLR}, 2017.

\bibitem[Han et~al.(2018)Han, Yao, Yu, Niu, Xu, Hu, Tsang, and
  Sugiyama]{han2018co}
Bo~Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and
  Masashi Sugiyama.
\newblock Co-teaching: Robust training of deep neural networks with extremely
  noisy labels.
\newblock In \emph{NeurIPS}, pages 8527--8537, 2018.

\bibitem[Jiang et~al.(2018)Jiang, Zhou, Leung, Li, and
  Fei-Fei]{jiang2018mentornet}
Lu~Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li~Fei-Fei.
\newblock {MentorNet}: Learning data-driven curriculum for very deep neural
  networks on corrupted labels.
\newblock In \emph{ICML}, pages 2309--2318, 2018.

\bibitem[Kingma and Welling(2013)]{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Krizhevsky(2009)]{krizhevsky2009learning}
Alex Krizhevsky.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, 2009.

\bibitem[Li et~al.(2021)Li, Liu, Han, Niu, and Sugiyama]{li2021provably}
Xuefeng Li, Tongliang Liu, Bo~Han, Gang Niu, and Masashi Sugiyama.
\newblock Provably end-to-end label-noise learning without anchor points.
\newblock In \emph{ICML}, 2021.

\bibitem[Liu and Tao(2016)]{liu2016classification}
Tongliang Liu and Dacheng Tao.
\newblock Classification with noisy labels by importance reweighting.
\newblock \emph{IEEE Transactions on pattern analysis and machine
  intelligence}, 38\penalty0 (3):\penalty0 447--461, 2016.

\bibitem[Liu(2021)]{liu2021importance}
Yang Liu.
\newblock The importance of understanding instance-level noisy labels.
\newblock \emph{ICML}, 2021.

\bibitem[Malach and Shalev-Shwartz(2017)]{malach2017decoupling}
Eran Malach and Shai Shalev-Shwartz.
\newblock Decoupling" when to update" from" how to update".
\newblock In \emph{NeurIPS}, pages 960--970, 2017.

\bibitem[Natarajan et~al.(2013)Natarajan, Dhillon, Ravikumar, and
  Tewari]{natarajan2013learning}
Nagarajan Natarajan, Inderjit~S Dhillon, Pradeep~K Ravikumar, and Ambuj Tewari.
\newblock Learning with noisy labels.
\newblock In \emph{NeurIPS}, pages 1196--1204, 2013.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and
  Y.Ng]{netzer2011svhn}
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo~Wu, and Andrew
  Y.Ng.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock In \emph{NIPS Workshop on Deep Learning and Unsupervised Feature
  Learning}, 2011.

\bibitem[Patrini et~al.(2017)Patrini, Rozza, Krishna~Menon, Nock, and
  Qu]{patrini2017making}
Giorgio Patrini, Alessandro Rozza, Aditya Krishna~Menon, Richard Nock, and
  Lizhen Qu.
\newblock Making deep neural networks robust to label noise: A loss correction
  approach.
\newblock In \emph{CVPR}, pages 1944--1952, 2017.

\bibitem[Pearl(2000)]{pearl2009causality}
Judea Pearl.
\newblock \emph{Causality: Models, Reasoning, and Inference}.
\newblock Cambridge University Press, New York, NY, USA, 2000.
\newblock ISBN 0-521-77362-8.

\bibitem[Peters et~al.(2017)Peters, Janzing, and
  Sch{\"o}lkopf]{peters2017elements}
Jonas Peters, Dominik Janzing, and Bernhard Sch{\"o}lkopf.
\newblock \emph{Elements of causal inference: foundations and learning
  algorithms}.
\newblock The MIT Press, 2017.

\bibitem[Sch{\"o}lkopf et~al.(2012)Sch{\"o}lkopf, Janzing, Peters, Sgouritsa,
  Zhang, and Mooij]{scholkopf2012causal}
B~Sch{\"o}lkopf, D~Janzing, J~Peters, E~Sgouritsa, K~Zhang, and J~Mooij.
\newblock On causal and anticausal learning.
\newblock In \emph{29th International Conference on Machine Learning (ICML
  2012)}, pages 1255--1262. International Machine Learning Society, 2012.

\bibitem[Sch{\"o}lkopf(2019)]{scholkopf2019causality}
Bernhard Sch{\"o}lkopf.
\newblock Causality for machine learning.
\newblock \emph{arXiv preprint arXiv:1911.10500}, 2019.

\bibitem[Scott(2015)]{scott2015rate}
Clayton Scott.
\newblock A rate of convergence for mixture proportion estimation, with
  application to learning from noisy labels.
\newblock In \emph{AISTATS}, pages 838--846, 2015.

\bibitem[Spirtes and Zhang(2016)]{spirtes2016causal}
Peter Spirtes and Kun Zhang.
\newblock Causal discovery and inference: concepts and recent methodological
  advances.
\newblock In \emph{Applied informatics}, volume~3, pages 1--28. SpringerOpen,
  2016.

\bibitem[Spirtes et~al.(2000)Spirtes, Glymour, Scheines, Heckerman, Meek,
  Cooper, and Richardson]{spirtes2000causation}
Peter Spirtes, Clark~N Glymour, Richard Scheines, David Heckerman, Christopher
  Meek, Gregory Cooper, and Thomas Richardson.
\newblock \emph{Causation, prediction, and search}.
\newblock MIT press, 2000.

\bibitem[Xia et~al.(2019{\natexlab{a}})Xia, Liu, Wang, Han, Gong, Niu, and
  Sugiyama]{xia2019anchor}
Xiaobo Xia, Tongliang Liu, Nannan Wang, Bo~Han, Chen Gong, Gang Niu, and
  Masashi Sugiyama.
\newblock Are anchor points really indispensable in label-noise learning?
\newblock In \emph{NeurIPS}, pages 6835--6846, 2019{\natexlab{a}}.

\bibitem[Xia et~al.(2019{\natexlab{b}})Xia, Liu, Wang, Han, Gong, Niu, and
  Sugiyama]{xia2019revision}
Xiaobo Xia, Tongliang Liu, Nannan Wang, Bo~Han, Chen Gong, Gang Niu, and
  Masashi Sugiyama.
\newblock Are anchor points really indispensable in label-noise learning?
\newblock In \emph{NeurIPS}, pages 6838--6849, 2019{\natexlab{b}}.

\bibitem[Xia et~al.(2020)Xia, Liu, Han, Wang, Gong, Liu, Niu, Tao, and
  Sugiyama]{xia2020part}
Xiaobo Xia, Tongliang Liu, Bo~Han, Nannan Wang, Mingming Gong, Haifeng Liu,
  Gang Niu, Dacheng Tao, and Masashi Sugiyama.
\newblock Part-dependent label noise: Towards instance-dependent label noise.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{xiao2017fashion}
Han Xiao, Kashif Rasul, and Roland Vollgraf.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms.
\newblock \emph{arXiv preprint arXiv:1708.07747}, 2017.

\bibitem[Xiao et~al.(2015)Xiao, Xia, Yang, Huang, and Wang]{xiao2015learning}
Tong Xiao, Tian Xia, Yi~Yang, Chang Huang, and Xiaogang Wang.
\newblock Learning from massive noisy labeled data for image classification.
\newblock In \emph{CVPR}, pages 2691--2699, 2015.

\bibitem[Yao et~al.(2020{\natexlab{a}})Yao, Yang, Han, Niu, and
  Kwok]{yao2020searching}
Quanming Yao, Hansi Yang, Bo~Han, Gang Niu, and James~T Kwok.
\newblock Searching to exploit memorization effect in learning with noisy
  labels.
\newblock In \emph{ICML}, 2020{\natexlab{a}}.

\bibitem[Yao et~al.(2020{\natexlab{b}})Yao, Liu, Han, Gong, Deng, Niu, and
  Sugiyama]{yao2020dual}
Yu~Yao, Tongliang Liu, Bo~Han, Mingming Gong, Jiankang Deng, Gang Niu, and
  Masashi Sugiyama.
\newblock Dual t: Reducing estimation error for transition matrix in
  label-noise learning.
\newblock In \emph{NeurIPS}, 2020{\natexlab{b}}.

\bibitem[Yu et~al.(2018)Yu, Liu, Gong, and Tao]{yu2018learning}
Xiyu Yu, Tongliang Liu, Mingming Gong, and Dacheng Tao.
\newblock Learning with biased complementary labels.
\newblock In \emph{ECCV}, pages 68--83, 2018.

\bibitem[Zhang et~al.(2018)Zhang, Cisse, Dauphin, and
  Lopez-Paz]{zhang2017mixup}
Hongyi Zhang, Moustapha Cisse, Yann~N Dauphin, and David Lopez-Paz.
\newblock mixup: Beyond empirical risk minimization.
\newblock In \emph{ICLR}, 2018.

\bibitem[Zhu et~al.(2021{\natexlab{a}})Zhu, Liu, and Liu]{zhu2020second}
Zhaowei Zhu, Tongliang Liu, and Yang Liu.
\newblock A second-order approach to learning with instance-dependent label
  noise.
\newblock In \emph{CVPR}, 2021{\natexlab{a}}.

\bibitem[Zhu et~al.(2021{\natexlab{b}})Zhu, Song, and
  Liu]{zhu2021clusterability}
Zhaowei Zhu, Yiwen Song, and Yang Liu.
\newblock Clusterability as an alternative to anchor points when learning with
  noisy labels.
\newblock \emph{arXiv preprint arXiv:2102.05291}, 2021{\natexlab{b}}.

\end{thebibliography}
