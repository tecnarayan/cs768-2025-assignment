\begin{thebibliography}{27}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Boopathy et~al.(2019)Boopathy, Weng, Chen, Liu, and
  Daniel]{Akhilan2019CNN-Cert}
Boopathy, A., Weng, T.-W., Chen, P.-Y., Liu, S., and Daniel, L.
\newblock Cnn-cert: An efficient framework for certifying robustness of
  convolutional neural networks.
\newblock In \emph{AAAI}, Jan 2019.

\bibitem[Carlini \& Wagner(2017)Carlini and Wagner]{carlini2017towards}
Carlini, N. and Wagner, D.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{2017 IEEE Symposium on Security and Privacy}, pp.\  39--57,
  2017.

\bibitem[Carlini \& Wagner(2018)Carlini and Wagner]{Carlini2018Audio}
Carlini, N. and Wagner, D.~A.
\newblock Audio adversarial examples: Targeted attacks on speech-to-text.
\newblock \emph{CoRR}, abs/1801.01944, 2018.

\bibitem[Cheng et~al.(2017)Cheng, N{\"u}hrenberg, and Ruess]{cheng2017maximum}
Cheng, C.-H., N{\"u}hrenberg, G., and Ruess, H.
\newblock Maximum resilience of artificial neural networks.
\newblock In \emph{International Symposium on Automated Technology for
  Verification and Analysis}, pp.\  251--268, 2017.

\bibitem[Cheng et~al.(2018)Cheng, Yi, Zhang, Chen, and
  Hsieh]{Cheng2018Seq2Sick}
Cheng, M., Yi, J., Zhang, H., Chen, P., and Hsieh, C.
\newblock Seq2sick: Evaluating the robustness of sequence-to-sequence models
  with adversarial examples.
\newblock \emph{CoRR}, abs/1803.01128, 2018.

\bibitem[Ciss{\'e} et~al.(2017)Ciss{\'e}, Adi, Neverova, and
  Keshet]{Ciss2017Houdini}
Ciss{\'e}, M., Adi, Y., Neverova, N., and Keshet, J.
\newblock Houdini: Fooling deep structured prediction models.
\newblock \emph{CoRR}, abs/1707.05373, 2017.

\bibitem[Dvijotham et~al.(2018)Dvijotham, Stanforth, Gowal, Mann, and
  Kohli]{dvijotham2018dual}
Dvijotham, K., Stanforth, R., Gowal, S., Mann, T., and Kohli, P.
\newblock A dual approach to scalable verification of deep networks.
\newblock \emph{UAI}, 2018.

\bibitem[Ebrahimi et~al.(2018{\natexlab{a}})Ebrahimi, Lowd, and
  Dou]{Ebrahimi2018Adversarial}
Ebrahimi, J., Lowd, D., and Dou, D.
\newblock On adversarial examples for character-level neural machine
  translation.
\newblock In \emph{COLING}, pp.\  653--663, 2018{\natexlab{a}}.

\bibitem[Ebrahimi et~al.(2018{\natexlab{b}})Ebrahimi, Rao, Lowd, and
  Dou]{ebrahimi2018hotflip}
Ebrahimi, J., Rao, A., Lowd, D., and Dou, D.
\newblock Hotflip: White-box adversarial examples for text classification.
\newblock In \emph{ACL}, pp.\  31--36, 2018{\natexlab{b}}.

\bibitem[Eykholt et~al.(2018)Eykholt, Evtimov, Fernandes, Li, Rahmati, Xiao,
  Prakash, Kohno, and Song]{eykholt2018robust}
Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C.,
  Prakash, A., Kohno, T., and Song, D.
\newblock Robust physical-world attacks on deep learning visual classification.
\newblock In \emph{CVPR}, pp.\  1625--1634, 2018.

\bibitem[Gao et~al.(2018)Gao, Lanchantin, Soffa, and Qi]{Gao2018Black-Box}
Gao, J., Lanchantin, J., Soffa, M.~L., and Qi, Y.
\newblock Black-box generation of adversarial text sequences to evade deep
  learning classifiers.
\newblock In \emph{2018 IEEE Security and Privacy Workshops}, pp.\  50--56,
  2018.

\bibitem[Gong \& Poellabauer(2017)Gong and Poellabauer]{Yuan2017Crafting}
Gong, Y. and Poellabauer, C.
\newblock Crafting adversarial examples for speech paralinguistics
  applications.
\newblock \emph{CoRR}, abs/1711.03280, 2017.

\bibitem[Hein \& Andriushchenko(2017)Hein and Andriushchenko]{hein2017formal}
Hein, M. and Andriushchenko, M.
\newblock Formal guarantees on the robustness of a classifier against
  adversarial manipulation.
\newblock In \emph{NIPS}, 2017.

\bibitem[Jia \& Liang(2017)Jia and Liang]{Jia2017Adversarial}
Jia, R. and Liang, P.
\newblock Adversarial examples for evaluating reading comprehension systems.
\newblock In \emph{EMNLP}, pp.\  2021--2031, 2017.

\bibitem[Katz et~al.(2017)Katz, Barrett, Dill, Julian, and
  Kochenderfer]{katz2017reluplex}
Katz, G., Barrett, C., Dill, D.~L., Julian, K., and Kochenderfer, M.~J.
\newblock Reluplex: An efficient smt solver for verifying deep neural networks.
\newblock In \emph{CAV}, pp.\  97--117, 2017.

\bibitem[Kurakin et~al.(2017)Kurakin, Goodfellow, and
  Bengio]{kurakin2017adversarial}
Kurakin, A., Goodfellow, I., and Bengio, S.
\newblock Adversarial examples in the physical world.
\newblock \emph{ICLR Workshop}, 2017.

\bibitem[Li \& Roth(2002)Li and Roth]{li2002learning}
Li, X. and Roth, D.
\newblock Learning question classifiers.
\newblock In \emph{COLING}, pp.\  1--7, 2002.

\bibitem[Papernot et~al.(2016{\natexlab{a}})Papernot, McDaniel, Swami, and
  Harang]{papernot2016crafting}
Papernot, N., McDaniel, P., Swami, A., and Harang, R.
\newblock Crafting adversarial input sequences for recurrent neural networks.
\newblock In \emph{MILCOM}, pp.\  49--54, 2016{\natexlab{a}}.

\bibitem[Papernot et~al.(2016{\natexlab{b}})Papernot, McDaniel, Swami, and
  Harang]{Papernot2016CraftingAI}
Papernot, N., McDaniel, P.~D., Swami, A., and Harang, R.~E.
\newblock Crafting adversarial input sequences for recurrent neural networks.
\newblock \emph{MILCOM}, pp.\  49--54, 2016{\natexlab{b}}.

\bibitem[Raghunathan et~al.(2018)Raghunathan, Steinhardt, and
  Liang]{raghunathan2018certified}
Raghunathan, A., Steinhardt, J., and Liang, P.
\newblock Certified defenses against adversarial examples.
\newblock \emph{ICLR}, 2018.

\bibitem[Sharif et~al.(2016)Sharif, Bhagavatula, Bauer, and
  Reiter]{sharif2016accessorize}
Sharif, M., Bhagavatula, S., Bauer, L., and Reiter, M.~K.
\newblock Accessorize to a crime: Real and stealthy attacks on state-of-the-art
  face recognition.
\newblock In \emph{Proceedings of the 2016 ACM SIGSAC Conference on Computer
  and Communications Security}, pp.\  1528--1540, 2016.

\bibitem[Singh et~al.(2018)Singh, Gehr, Mirman, P\"{u}schel, and
  Vechev]{Singh2018Fast}
Singh, G., Gehr, T., Mirman, M., P\"{u}schel, M., and Vechev, M.
\newblock Fast and effective robustness certification.
\newblock In \emph{NIPS}, pp.\  10825--10836. 2018.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2014intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock \emph{ICLR}, 2014.

\bibitem[Weng et~al.(2018{\natexlab{a}})Weng, Zhang, Chen, Song, Hsieh, Boning,
  Dhillon, and Daniel]{weng2018towards}
Weng, T.-W., Zhang, H., Chen, H., Song, Z., Hsieh, C.-J., Boning, D., Dhillon,
  I.~S., and Daniel, L.
\newblock Towards fast computation of certified robustness for relu networks.
\newblock \emph{ICML}, 2018{\natexlab{a}}.

\bibitem[Weng et~al.(2018{\natexlab{b}})Weng, Zhang, Chen, Yi, Su, Gao, Hsieh,
  and Daniel]{weng2018evaluating}
Weng, T.-W., Zhang, H., Chen, P.-Y., Yi, J., Su, D., Gao, Y., Hsieh, C.-J., and
  Daniel, L.
\newblock Evaluating the robustness of neural networks: An extreme value theory
  approach.
\newblock In \emph{ICLR}, 2018{\natexlab{b}}.

\bibitem[Zhang et~al.(2018)Zhang, Weng, Chen, Hsieh, and
  Daniel]{zhang2018crown}
Zhang, H., Weng, T.-W., Chen, P.-Y., Hsieh, C.-J., and Daniel, L.
\newblock Efficient neural network robustness certification with general
  activation functions.
\newblock In \emph{NIPS}, pp.\  4944--4953. 2018.

\bibitem[Zhao et~al.(2018)Zhao, Dua, and Singh]{zhao2018generating}
Zhao, Z., Dua, D., and Singh, S.
\newblock Generating natural adversarial examples.
\newblock In \emph{ICLR}, 2018.

\end{thebibliography}
