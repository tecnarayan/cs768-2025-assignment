% Generated by IEEEtranN.bst, version: 1.13 (2008/09/30)
\begin{thebibliography}{49}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtranN.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem[Blei et~al.(2003)Blei, Ng, and Jordan]{blei2003latent}
D.~M. Blei, A.~Y. Ng, and M.~I. Jordan, ``Latent {D}irichlet allocation,''
  \emph{JMLR}, vol.~3, pp. 993--1022, 2003.

\bibitem[Blei et~al.(2010)Blei, Griffiths, and Jordan]{blei2010nested}
D.~M. Blei, T.~L. Griffiths, and M.~I. Jordan, ``The nested {C}hinese
  restaurant process and {B}ayesian nonparametric inference of topic
  hierarchies,'' \emph{Journal of the ACM (JACM)}, vol.~57, no.~2, p.~7, 2010.

\bibitem[Paisley et~al.(2015)Paisley, Wang, Blei, and
  Jordan]{paisley2015nested}
J.~Paisley, C.~Wang, D.~M. Blei, and M.~I. Jordan, ``Nested hierarchical
  {D}irichlet processes,'' \emph{TPAMI}, vol.~37, no.~2, pp. 256--270, 2015.

\bibitem[Hinton and Salakhutdinov(2009)]{hinton2009replicated}
G.~E. Hinton and R.~R. Salakhutdinov, ``Replicated softmax: {A}n undirected
  topic model,'' in \emph{NIPS}, 2009, pp. 1607--1614.

\bibitem[Larochelle and Lauly(2012)]{larochelle2012neural}
H.~Larochelle and S.~Lauly, ``A neural autoregressive topic model,'' in
  \emph{NIPS}, 2012, pp. 2708--2716.

\bibitem[Srivastava et~al.(2013)Srivastava, Salakhutdinov, and
  Hinton]{srivastava2013modeling}
N.~Srivastava, R.~Salakhutdinov, and G.~Hinton, ``Modeling documents with a
  deep {B}oltzmann machine,'' in \emph{UAI}, 2013, pp. 616--624.

\bibitem[Srivastava and Sutton(2017)]{srivastava2016autoencoding}
A.~Srivastava and C.~Sutton, ``Autoencoding variational inference for topic
  models,'' 2017.

\bibitem[Miao et~al.(2017)Miao, Grefenstette, and Blunsom]{miao2017discovering}
Y.~Miao, E.~Grefenstette, and P.~Blunsom, ``Discovering discrete latent topics
  with neural variational inference,'' in \emph{ICML}, 2017, pp. 2410--2419.

\bibitem[Zhang et~al.(2018)Zhang, Chen, Guo, and Zhou]{zhang2018whai}
H.~Zhang, B.~Chen, D.~Guo, and M.~Zhou, ``{WHAI}: Weibull hybrid autoencoding
  inference for deep topic modeling,'' 2018.

\bibitem[Hinton et~al.(2006)Hinton, Osindero, and Teh]{hinton2006fast}
G.~E. Hinton, S.~Osindero, and Y.-W. Teh, ``A fast learning algorithm for deep
  belief nets,'' \emph{Neural computation}, vol.~18, no.~7, pp. 1527--1554,
  2006.

\bibitem[Gan et~al.(2015)Gan, Chen, Henao, Carlson, and Carin]{gan2015scalable}
Z.~Gan, C.~Chen, R.~Henao, D.~Carlson, and L.~Carin, ``Scalable deep {P}oisson
  factor analysis for topic modeling,'' in \emph{ICML}, 2015, pp. 1823--1832.

\bibitem[Ranganath et~al.(2015)Ranganath, Tang, Charlin, and
  Blei]{ranganath2015deep}
R.~Ranganath, L.~Tang, L.~Charlin, and D.~Blei, ``Deep exponential families,''
  in \emph{AISTATS}, 2015, pp. 762--771.

\bibitem[Henao et~al.(2015)Henao, Gan, Lu, and Carin]{henao2015deep}
R.~Henao, Z.~Gan, J.~Lu, and L.~Carin, ``Deep {P}oisson factor modeling,'' in
  \emph{NIPS}, 2015, pp. 2800--2808.

\bibitem[Zhou et~al.(2016)Zhou, Cong, and Chen]{zhou2016augmentable}
M.~Zhou, Y.~Cong, and B.~Chen, ``Augmentable gamma belief networks,''
  \emph{JMLR}, vol.~17, no. 163, pp. 1--44, 2016.

\bibitem[Mcauliffe and Blei(2008)]{mcauliffe2008supervised}
J.~D. Mcauliffe and D.~M. Blei, ``Supervised topic models,'' in \emph{NIPS},
  2008, pp. 121--128.

\bibitem[Rosen-Zvi et~al.(2004)Rosen-Zvi, Griffiths, Steyvers, and
  Smyth]{rosen2004author}
M.~Rosen-Zvi, T.~Griffiths, M.~Steyvers, and P.~Smyth, ``The author-topic model
  for authors and documents,'' in \emph{UAI}, 2004, pp. 487--494.

\bibitem[Zhou et~al.(2012)Zhou, Hannah, Dunson, and Carin]{zhou2012beta}
M.~Zhou, L.~Hannah, D.~B. Dunson, and L.~Carin, ``Beta-negative binomial
  process and {P}oisson factor analysis,'' in \emph{AISTATS}, 2012, pp.
  1462--1471.

\bibitem[Zhao et~al.(2017{\natexlab{a}})Zhao, Du, Buntine, and
  Liu]{zhao2017metalda}
H.~Zhao, L.~Du, W.~Buntine, and G.~Liu, ``Metalda: A topic model that
  efficiently incorporates meta information,'' in \emph{ICDM}, 2017, pp.
  635--644.

\bibitem[Lafferty and Blei(2006)]{lafferty2006correlated}
J.~D. Lafferty and D.~M. Blei, ``Correlated topic models,'' in \emph{NIPS},
  2006, pp. 147--154.

\bibitem[Teh et~al.(2012)Teh, Jordan, Beal, and Blei]{teh2012hierarchical}
Y.~Teh, M.~Jordan, M.~Beal, and D.~Blei, ``Hierarchical {D}irichlet
  processes,'' \emph{Journal of the American Statistical Association}, vol.
  101, no. 476, pp. 1566--1581, 2012.

\bibitem[Tang and Salakhutdinov(2013)]{tang2013learning}
Y.~Tang and R.~R. Salakhutdinov, ``Learning stochastic feedforward neural
  networks,'' in \emph{NIPS}, 2013, pp. 530--538.

\bibitem[Zhou(2015)]{zhou2015infinite}
M.~Zhou, ``Infinite edge partition models for overlapping community detection
  and link prediction,'' in \emph{AISTATS}, 2015, pp. 1135â€“--1143.

\bibitem[Zhou and Carin(2015)]{zhou2015negative}
M.~Zhou and L.~Carin, ``Negative binomial process count and mixture modeling,''
  \emph{TPAMI}, vol.~37, no.~2, pp. 307--320, 2015.

\bibitem[Zhao et~al.(2017{\natexlab{b}})Zhao, Du, and
  Buntine]{pmlr-v70-zhao17a}
H.~Zhao, L.~Du, and W.~Buntine, ``Leveraging node attributes for incomplete
  relational data,'' in \emph{ICML}, 2017, pp. 4072--4081.

\bibitem[Zhou(2018)]{zhou2018nonparametric}
M.~Zhou, ``Nonparametric {B}ayesian negative binomial factor analysis,''
  \emph{Bayesian Analysis}, 2018.

\bibitem[Zhao et~al.(2018{\natexlab{a}})Zhao, Du, Buntine, and
  Liu]{zhao2018leveraging}
H.~Zhao, L.~Du, W.~Buntine, and G.~Liu, ``Leveraging external information in
  topic modelling,'' \emph{KAIS}, pp. 1--33, 2018.

\bibitem[Zhou et~al.(2015)Zhou, Cong, and Chen]{zhou2015poisson}
M.~Zhou, Y.~Cong, and B.~Chen, ``The {P}oisson gamma belief network,'' in
  \emph{NIPS}, 2015, pp. 3043--3051.

\bibitem[Wallach et~al.(2009)Wallach, Mimno, and
  McCallum]{wallach2009rethinking}
H.~M. Wallach, D.~M. Mimno, and A.~McCallum, ``Rethinking {LDA}: Why priors
  matter,'' in \emph{NIPS}, 2009, pp. 1973--1981.

\bibitem[Zhao et~al.(2017{\natexlab{c}})Zhao, Du, and Buntine]{zhao2017word}
H.~Zhao, L.~Du, and W.~Buntine, ``A word embeddings informed focused topic
  model,'' in \emph{ACML}, 2017, pp. 423--438.

\bibitem[Zhao et~al.(2018{\natexlab{b}})Zhao, Du, Buntine, and
  Zhou]{zhao2018inter}
H.~Zhao, L.~Du, W.~Buntine, and M.~Zhou, ``Inter and intra topic structure
  learning with word embeddings,'' in \emph{ICML}, 2018, pp. 5887--5896.

\bibitem[Sato and Nakagawa(2010)]{sato2010topic}
I.~Sato and H.~Nakagawa, ``Topic models with power-law using {P}itman-{Y}or
  process,'' in \emph{SIGKDD}, 2010, pp. 673--682.

\bibitem[Buntine and Mishra(2014)]{buntine2014experiments}
W.~L. Buntine and S.~Mishra, ``Experiments with non-parametric topic models,''
  in \emph{SIGKDD}, 2014, pp. 881--890.

\bibitem[Chen et~al.(2015)Chen, Buntine, Ding, Xie, and
  Du]{chen2015differential}
C.~Chen, W.~Buntine, N.~Ding, L.~Xie, and L.~Du, ``Differential topic models,''
  \emph{TPAMI}, vol.~37, no.~2, pp. 230--242, 2015.

\bibitem[Lindsey et~al.(2012)Lindsey, Headden~III, and
  Stipicevic]{lindsey2012phrase}
R.~V. Lindsey, W.~P. Headden~III, and M.~J. Stipicevic, ``A phrase-discovering
  topic model using hierarchical {P}itman-{Y}or processes,'' in \emph{EMNLP},
  2012, pp. 214--222.

\bibitem[Archambeau et~al.(2015)Archambeau, Lakshminarayanan, and
  Bouchard]{archambeau2015latent}
C.~Archambeau, B.~Lakshminarayanan, and G.~Bouchard, ``Latent {IBP} compound
  {D}irichlet allocation,'' \emph{TPAMI}, vol.~37, no.~2, pp. 321--333, 2015.

\bibitem[Wood and Teh(2009)]{wood2009hierarchical}
F.~Wood and Y.~W. Teh, ``A hierarchical nonparametric {B}ayesian approach to
  statistical language model domain adaptation,'' in \emph{AISTATS}, 2009, pp.
  607--614.

\bibitem[Du et~al.(2012)Du, Buntine, and Jin]{du2012modelling}
L.~Du, W.~Buntine, and H.~Jin, ``Modelling sequential text with an adaptive
  topic model,'' in \emph{EMNLP}, 2012, pp. 535--545.

\bibitem[Kim et~al.(2012)Kim, Kim, Kim, and Oh]{kim2012modeling}
J.~H. Kim, D.~Kim, S.~Kim, and A.~Oh, ``Modeling topic hierarchies with the
  recursive chinese restaurant process,'' in \emph{CIKM}, 2012, pp. 783--792.

\bibitem[Ahmed et~al.(2013)Ahmed, Hong, and Smola]{ahmed2013nested}
A.~Ahmed, L.~Hong, and A.~Smola, ``Nested {C}hinese restaurant franchise
  process: Applications to user tracking and document modeling,'' in
  \emph{ICML}, 2013, pp. 1426--1434.

\bibitem[Li and McCallum(2006)]{li2006pachinko}
W.~Li and A.~McCallum, ``Pachinko allocation: {DAG}-structured mixture models
  of topic correlations,'' in \emph{ICML}, 2006, pp. 577--584.

\bibitem[Cong et~al.(2017)Cong, Chen, Liu, and Zhou]{cong2017deep}
Y.~Cong, B.~Chen, H.~Liu, and M.~Zhou, ``Deep latent {D}irichlet allocation
  with topic-layer-adaptive stochastic gradient {R}iemannian {MCMC},'' in
  \emph{ICML}, 2017, pp. 864--873.

\bibitem[Aletras and Stevenson(2013)]{aletras2013evaluating}
N.~Aletras and M.~Stevenson, ``Evaluating topic coherence using distributional
  semantics,'' in \emph{Proc.\ of the 10th Intnl.\ Conf.\ on Computational
  Semantics}, 2013, pp. 13--22.

\bibitem[Lau et~al.(2014)Lau, Newman, and Baldwin]{lau2014machine}
J.~H. Lau, D.~Newman, and T.~Baldwin, ``Machine reading tea leaves:
  Automatically evaluating topic coherence and topic model quality,'' in
  \emph{EACL}, 2014, pp. 530--539.

\bibitem[Yang et~al.(2015)Yang, Downey, and Boyd-Graber]{yang2015efficient}
Y.~Yang, D.~Downey, and J.~Boyd-Graber, ``Efficient methods for incorporating
  knowledge into topic models,'' in \emph{EMNLP}, 2015, pp. 308--317.

\bibitem[Hoffman et~al.(2013)Hoffman, Blei, Wang, and
  Paisley]{hoffman2013stochastic}
M.~D. Hoffman, D.~M. Blei, C.~Wang, and J.~Paisley, ``Stochastic variational
  inference,'' \emph{JMLR}, vol.~14, no.~1, pp. 1303--1347, 2013.

\bibitem[Guhaniyogi et~al.(2018)Guhaniyogi, Qamar, and
  Dunson]{guhaniyogi2018bayesian}
R.~Guhaniyogi, S.~Qamar, and D.~B. Dunson, ``Bayesian conditional density
  filtering,'' \emph{Journal of Computational and Graphical Statistics}, no.
  just-accepted, 2018.

\bibitem[Chen et~al.(2014)Chen, Fox, and Guestrin]{chen2014stochastic}
T.~Chen, E.~Fox, and C.~Guestrin, ``Stochastic gradient {H}amiltonian {M}onte
  {C}arlo,'' in \emph{ICML}, 2014, pp. 1683--1691.

\bibitem[Ding et~al.(2014)Ding, Fang, Babbush, Chen, Skeel, and
  Neven]{ding2014bayesian}
N.~Ding, Y.~Fang, R.~Babbush, C.~Chen, R.~D. Skeel, and H.~Neven, ``Bayesian
  sampling using stochastic gradient thermostats,'' in \emph{NIPS}, 2014, pp.
  3203--3211.

\bibitem[Welling and Teh(2011)]{welling2011bayesian}
M.~Welling and Y.~W. Teh, ``Bayesian learning via stochastic gradient
  {L}angevin dynamics,'' in \emph{ICML}, 2011, pp. 681--688.

\end{thebibliography}
