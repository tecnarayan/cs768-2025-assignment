\begin{thebibliography}{10}

\bibitem{Chen20_SimCLR}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey~E. Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In {\em Proc.\ Int.\ Conf.\ on Machine Learning (ICML)}, 2020.

\bibitem{Chen20_SimSiam}
Xinlei Chen and Kaiming He.
\newblock Exploring simple siamese representation learning.
\newblock In {\em {Proc.\ Int.\ Conf.\ on Computer Vision and Pattern
  Recognition (CVPR)}}, 2021.

\bibitem{barlow_zbontar21}
Jure Zbontar, Li~Jing, Ishan Misra, Yann LeCun, and St{\'e}phane Deny.
\newblock Barlow twins: Self-supervised learning via redundancy reduction.
\newblock In {\em Proc.\ Int.\ Conf.\ on Machine Learning (ICML)}, 2021.

\bibitem{He20_MoCo}
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross~B. Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In {\em {Proc.\ Int.\ Conf.\ on Computer Vision and Pattern
  Recognition (CVPR)}}. {IEEE}, 2020.

\bibitem{Swav_Caron20}
Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, and Piotr Bojanowski.
\newblock Unsupervised learning of visual features by contrasting cluster
  assignments.
\newblock In {\em {Proc.\ Adv.\ in Neural Information Processing Systems
  (NeurIPS)}}, 2020.

\bibitem{DINO_caron21}
Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\'e J\'egou, Julien Mairal,
  Piotr Bojanowski, and Armand Joulin.
\newblock Emerging properties in self-supervised vision transformers.
\newblock In {\em Proc.\ Int.\ Conf.\ on Computer Vision (ICCV)}, 2021.

\bibitem{Tian20_CMC}
Yonglong Tian, Dilip Krishnan, and Phillip Isola.
\newblock Contrastive multiview coding.
\newblock In {\em {Proc.\ Euro. Conf. on Computer Vision (ECCV)}}, 2020.

\bibitem{Oord18_CPC}
A{\"{a}}ron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock In {\em Proc.\ Adv.\ in Neural Information Processing Systems
  (NeurIPS)}, 2018.

\bibitem{Hjelm19_DeepInfoMax}
R.~Devon Hjelm, Alex Fedorov, Samuel Lavoie{-}Marchildon, Karan Grewal, Philip
  Bachman, Adam Trischler, and Yoshua Bengio.
\newblock Learning deep representations by mutual information estimation and
  maximization.
\newblock In {\em Proc.\ Int.\ Conf.\ on Learning Representations (ICLR)},
  2019.

\bibitem{Hendrycks19_SSLRobust}
Dan Hendrycks, Mantas Mazeika, Saurav Kadavath, and Dawn Song.
\newblock Using self-supervised learning can improve model robustness and
  uncertainty.
\newblock In {\em {Proc.\ Adv.\ in Neural Information Processing Systems
  (NeurIPS)}}, 2019.

\bibitem{Liu21_SSLDatasetImbalance}
Hong Liu, Jeff~Z. HaoChen, Adrien Gaidon, and Tengyu Ma.
\newblock Self-supervised learning is more robust to dataset imbalance.
\newblock In {\em Proc.\ Int.\ Conf.\ on Learning Representations (ICLR)},
  2022.

\bibitem{Ericsson21_SSLTransfer}
Linus Ericsson, Henry Gouk, and Timothy~M. Hospedales.
\newblock How well do self-supervised models transfer?
\newblock In {\em {Proc.\ Int.\ Conf.\ on Computer Vision and Pattern
  Recognition (CVPR)}}, 2021.

\bibitem{Hu20_PretrainingGNNs}
Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay~S.
  Pande, and Jure Leskovec.
\newblock Strategies for pre-training graph neural networks.
\newblock In {\em Proc.\ Int.\ Conf.\ on Learning Representations (ICLR)},
  2020.

\bibitem{Arora19_TheoreticalAnalysis}
Sanjeev Arora, Hrishikesh Khandeparkar, Mikhail Khodak, Orestis Plevrakis, and
  Nikunj Saunshi.
\newblock {A Theoretical Analysis of Contrastive Unsupervised Representation
  Learning}.
\newblock In {\em Proc.\ Int.\ Conf.\ on Machine Learning (ICML)}, 2019.

\bibitem{HaoChen_SpectralCL}
Jeff~Z. HaoChen, Colin Wei, Adrien Gaidon, and Tengyu Ma.
\newblock Provable guarantees for self-supervised deep learning with spectral
  contrastive loss.
\newblock In {\em {Proc.\ Adv.\ in Neural Information Processing Systems
  (NeurIPS)}}, 2021.

\bibitem{Tian20_WhatMakesForGoodViews}
Yonglong Tian, Chen Sun, Ben Poole, Dilip Krishnan, Cordelia Schmid, and
  Phillip Isola.
\newblock What makes for good views for contrastive learning?
\newblock In {\em {Proc.\ Adv.\ in Neural Information Processing Systems
  (NeurIPS)}}, 2020.

\bibitem{Kugelgen_ProvablySeparates}
Julius von K{\"{u}}gelgen, Yash Sharma, Luigi Gresele, Wieland Brendel,
  Bernhard Sch{\"{o}}lkopf, Michel Besserve, and Francesco Locatello.
\newblock Self-supervised learning with data augmentations provably isolates
  content from style.
\newblock In {\em {Proc.\ Adv.\ in Neural Information Processing Systems
  (NeurIPS)}}, 2021.

\bibitem{Zimmermann_Inverts}
Roland~S. Zimmermann, Yash Sharma, Steffen Schneider, Matthias Bethge, and
  Wieland Brendel.
\newblock Contrastive learning inverts the data generating process.
\newblock In {\em Proc.\ Int.\ Conf.\ on Machine Learning (ICML)}, 2021.

\bibitem{Wang_UniformityAlignment}
Tongzhou Wang and Phillip Isola.
\newblock Understanding contrastive representation learning through alignment
  and uniformity on the hypersphere.
\newblock In {\em Proc.\ Int.\ Conf.\ on Machine Learning (ICML)}, 2020.

\bibitem{Purushwalkam20_DemystifyingCL}
Senthil Purushwalkam and Abhinav Gupta.
\newblock Demystifying contrastive self-supervised learning: Invariances,
  augmentations and dataset biases.
\newblock In {\em {Proc.\ Adv.\ in Neural Information Processing Systems
  (NeurIPS)}}, 2020.

\bibitem{Grill20_BYOL}
Jean{-}Bastien Grill, Florian Strub, Florent Altch{\'{e}}, Corentin Tallec,
  Pierre~H. Richemond, Elena Buchatskaya, Carl Doersch, Bernardo~{\'{A}}vila
  Pires, Mohammad~Gheshlaghi Azar, Bilal Piot, Koray Kavukcuoglu, R{\'{e}}mi
  Munos, and Michal Valko.
\newblock Bootstrap your own latent - {A} new approach to self-supervised
  learning.
\newblock In {\em {Proc.\ Adv.\ in Neural Information Processing Systems
  (NeurIPS)}}, 2020.

\bibitem{You20_GraphContrastiveLearning}
Tianlong Chen, Yongduo Sui, Ting Chen, Zhangyang Wang, and Yang Shen.
\newblock Graph contrastive learning with augmentations.
\newblock In {\em {Proc.\ Adv.\ in Neural Information Processing Systems
  (NeurIPS)}}, 2020.

\bibitem{Hassani20_MVGRL}
Kaveh Hassani and Amir Hosein~Khas Ahmadi.
\newblock Contrastive multi-view representation learning on graphs.
\newblock In {\em Proc.\ Int.\ Conf.\ on Machine Learning (ICML)}, 2020.

\bibitem{Thakoor21_BGRL}
Shantanu Thakoor, Corentin Tallec, Mohammad~Gheshlaghi Azar, Medhi Azabou, Eva
  Dyer, R{\'{e}}mi Munos, Petar Velickovic, and Michal Valko.
\newblock Large-scale representation learning on graphs via bootstrapping.
\newblock In {\em Proc.\ Int.\ Conf.\ on Learning Representations (ICLR)},
  2022.

\bibitem{Zhu20_GCA}
Yanqiao Zhu, Yichen Xu, Feng Yu, Qiang Liu, Shu Wu, and Liang Wang.
\newblock Graph contrastive learning with adaptive augmentation.
\newblock In {\em Proc.\ ACM Conf.\ on World Wide Web (WWW)}, 2020.

\bibitem{Sun20_InfoGraph}
Fan{-}Yun Sun, Jordan Hoffmann, Vikas Verma, and Jian Tang.
\newblock Infograph: Unsupervised and semi-supervised graph-level
  representation learning via mutual information maximization.
\newblock In {\em Proc.\ Int.\ Conf.\ on Learning Representations (ICLR)},
  2020.

\bibitem{Tsai21_SSLMultiview}
Yao{-}Hung~Hubert Tsai, Yue Wu, Ruslan Salakhutdinov, and Louis{-}Philippe
  Morency.
\newblock Self-supervised learning from a multi-view perspective.
\newblock In {\em Proc.\ Int.\ Conf.\ on Learning Representations (ICLR)},
  2021.

\bibitem{Wei21_SelfTraining}
Colin Wei, Kendrick Shen, Yining Chen, and Tengyu Ma.
\newblock Theoretical analysis of self-training with deep networks on unlabeled
  data.
\newblock In {\em Proc.\ Int.\ Conf.\ on Learning Representations (ICLR)},
  2021.

\bibitem{You21_GraphCLAutomated}
Yuning You, Tianlong Chen, Yang Shen, and Zhangyang Wang.
\newblock Graph contrastive learning automated.
\newblock In {\em Proc.\ Int.\ Conf.\ on Machine Learning (ICML)}, 2021.

\bibitem{Kong20_FLAG}
Kezhi Kong, Guohao Li, Mucong Ding, Zuxuan Wu, Chen Zhu, Bernard Ghanem, Gavin
  Taylor, and Tom Goldstein.
\newblock {FLAG:} adversarial data augmentation for graph neural networks.
\newblock {\em CoRR}, 2020.

\bibitem{suresh21_AdvGCL}
Susheel Suresh, Pan Li, Cong Hao, and Jennifer Neville.
\newblock Adversarial graph augmentation to improve graph contrastive learning.
\newblock In {\em {Proc.\ Adv.\ in Neural Information Processing Systems
  (NeurIPS)}}, 2021.

\bibitem{Xia22_SimGRACE}
Jun Xia, Lirong Wu, Jintao Chen, Bozhen Hu, and Stan~Z. Li.
\newblock Simgrace: {A} simple framework for graph contrastive learning without
  data augmentation.
\newblock In {\em Proc.\ ACM Conf.\ on World Wide Web (WWW)}, 2022.

\bibitem{Bardes21_VICReg}
Adrien Bardes, Jean Ponce, and Yann LeCun.
\newblock Vicreg: Variance-invariance-covariance regularization for
  self-supervised learning.
\newblock In {\em Proc.\ Int.\ Conf.\ on Learning Representations (ICLR)},
  2021.

\bibitem{Huang_sslgen21}
Weiran Huang, Mingyang Yi, and Xuyang Zhao.
\newblock {Towards the Generalization of Contrastive Self-Supervised Learning}.
\newblock {\em arXiv}, abs/2111.00743, 2021.

\bibitem{Tian21_NoContrast}
Yuandong Tian, Xinlei Chen, and Surya Ganguli.
\newblock {Understanding self-supervised Learning Dynamics without Contrastive
  Pairs}.
\newblock In {\em Proc.\ Int.\ Conf.\ on Machine Learning (ICML)}, 2021.

\bibitem{jing2021understanding}
Li~Jing, Pascal Vincent, Yann LeCun, and Yuandong Tian.
\newblock Understanding dimensional collapse in contrastive self-supervised
  learning.
\newblock {\em arXiv preprint arXiv:2110.09348}, 2021.

\bibitem{pokle2022contrasting}
Ashwini Pokle, Jinjin Tian, Yuchen Li, and Andrej Risteski.
\newblock Contrasting the landscape of contrastive and non-contrastive
  learning.
\newblock {\em arXiv preprint arXiv:2203.15702}, 2022.

\bibitem{ziyin2022shapes}
Liu Ziyin, Ekdeep~Singh Lubana, Masahito Ueda, and Hidenori Tanaka.
\newblock What shapes the loss landscape of self-supervised learning?
\newblock {\em arXiv preprint arXiv:2210.00638}, 2022.

\bibitem{Balcan04}
Maria{-}Florina Balcan, Avrim Blum, and Ke~Yang.
\newblock Co-training and expansion: Towards bridging theory and practice.
\newblock In {\em {Proc.\ Adv.\ in Neural Information Processing Systems
  (NeurIPS)}}, 2004.

\bibitem{lubana2022orchestra}
Ekdeep~Singh Lubana, Chi~Ian Tang, Fahim Kawsar, Robert~P Dick, and Akhil
  Mathur.
\newblock Orchestra: Unsupervised federated learning via globally consistent
  clustering.
\newblock {\em arXiv preprint arXiv:2205.11506}, 2022.

\bibitem{Saunshi22_CLInductiveBias}
Nikunj Saunshi, Jordan Ash, Surbhi Goel, Dipendra Misra, Cyril Zhang, Sanjeev
  Arora, Sham Kakade, and Akshay Krishnamurthy.
\newblock Understanding contrastive learning requires incorporating inductive
  biases.
\newblock In {\em Proc.\ Int.\ Conf.\ on Machine Learning (ICML)}, 2022.

\bibitem{Trivedi21_AugCL}
Puja Trivedi, Ekdeep~Singh Lubana, Yujun Yan, Yaoqing Yang, and Danai Koutra.
\newblock Augmentations in graph contrastive learning: Current methodological
  flaws {\&} towards better practices.
\newblock In {\em Proc.\ ACM Conf.\ on World Wide Web (WWW)}, 2022.

\bibitem{fig_motiv}
SueYeon Chung, Daniel~D. Lee, and Haim Sompolinsky.
\newblock Classification and geometry of general perceptual manifolds.
\newblock {\em Phys. Rev. X}, 8, 2018.

\bibitem{Kipf_VGAE}
Thomas~N. Kipf and Max Welling.
\newblock Variational graph auto-encoders.
\newblock In {\em Bayesian Deep Learning Workshop (NeurIPS)}, 2016.

\bibitem{Falcon_AAVAE}
William Falcon, Ananya~Harsh Jha, Teddy Koker, and Kyunghyun Cho.
\newblock {AAVAE:} augmentation-augmented variational autoencoders.
\newblock {\em CoRR}, 2021.

\bibitem{kipf2017semi}
Thomas~N Kipf and Max Welling.
\newblock Semi-supervised classification with graph convolutional networks.
\newblock In {\em Proc.\ Int.\ Conf.\ on Learning Representations (ICLR)},
  2017.

\bibitem{xu2021self}
Minghao Xu, Hang Wang, Bingbing Ni, Hongyu Guo, and Jian Tang.
\newblock Self-supervised graph-level representation learning with local and
  global structure.
\newblock In {\em Proc.\ Int.\ Conf.\ on Machine Learning (ICML)}, 2021.

\bibitem{Jang17_GumbelSoftmax}
Eric Jang, Shixiang Gu, and Ben Poole.
\newblock Categorical reparameterization with gumbel-softmax.
\newblock In {\em Proc.\ Int.\ Conf.\ on Learning Representations (ICLR)},
  2017.

\bibitem{yehudai2021local}
Gilad Yehudai, Ethan Fetaya, Eli Meirom, Gal Chechik, and Haggai Maron.
\newblock From local structures to size generalization in graph neural
  networks.
\newblock In {\em Proc.\ Int.\ Conf.\ on Machine Learning (ICML)}, 2021.

\bibitem{Zitnik_Biology}
Marinka Zitnik, Rok Sosiƒç, and Jure Leskovec.
\newblock Prioritizing network communities.
\newblock {\em Nature Communications}, 2018.

\bibitem{subramanian_bace}
Govindan Subramanian, Bharath Ramsundar, Vijay Pande, and Rajiah Aldrin~Denny
  Denny.
\newblock Computational modeling of $\beta$-secretase 1 (bace-1) inhibitors
  using ligand based approaches.
\newblock {\em Journal of Chemical Information and Modeling}, 2016.

\bibitem{Sun_MoCL21}
Mengying Sun, Jing Xing, Huijun Wang, Bin Chen, and Jiayu Zhou.
\newblock Mocl: Data-driven molecular fingerprint via knowledge-aware
  contrastive learning from molecular graph.
\newblock In {\em Proc.\ {ACM} Int.\ Conf.\ on Knowledge Discovery {\&} Data
  Mining (SIGKDD)}, 2021.

\bibitem{Fey19_PyG}
Matthias Fey and Jan~E. Lenssen.
\newblock Fast graph representation learning with {PyTorch Geometric}.
\newblock In {\em ICLR Workshop on Representation Learning on Graphs and
  Manifolds}, 2019.

\bibitem{Zhu_PyGCL21}
Yanqiao Zhu, Yichen Xu, Qiang Liu, and Shu Wu.
\newblock An empirical study of graph contrastive learning.
\newblock In {\em Proc.\ Neural Information Processing Systems (NeurIPS),
  Datasets and Benchmarks Track}, 2021.

\bibitem{Poole_MIBounds}
Ben Poole, Sherjil Ozair, Aaron van~den Oord, Alexander~A. Alemi, and George
  Tucker.
\newblock {On Variational Bounds of Mutual Information}.
\newblock In {\em Proc.\ Int.\ Conf.\ on Machine Learning (ICML)}, 2019.

\bibitem{Hu19_HowPowerfulAreGNN}
Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka.
\newblock How powerful are graph neural networks?
\newblock In {\em Proc.\ Int.\ Conf.\ on Learning Representations (ICLR)},
  2019.

\bibitem{Yanardag15_DeepGraphKernels}
Pinar Yanardag and S.~V.~N. Vishwanathan.
\newblock Deep graph kernels.
\newblock In {\em Proc.\ {ACM} Int.\ Conf.\ on Knowledge Discovery {\&} Data
  Mining (SIGKDD)}, 2015.

\bibitem{Kriege12_SubgraphMatching}
Nils~M. Kriege and Petra Mutzel.
\newblock Subgraph matching kernels for attributed graphs.
\newblock In {\em Proc.\ Int.\ Conf.\ on Machine Learning (ICML)}, 2012.

\bibitem{Borgwardt05_PROTEINS}
Karsten~M. Borgwardt, Cheng~Soon Ong, Stefan Sch{\"{o}}nauer, S.~V.~N.
  Vishwanathan, Alexander~J. Smola, and Hans{-}Peter Kriegel.
\newblock Protein function prediction via graph kernels.
\newblock In {\em Proceedings Thirteenth International Conference on
  Intelligent Systems for Molecular Biology}, 2005.

\bibitem{Shervashidze11_DD}
Nino Shervashidze, Pascal Schweitzer, Erik~Jan van Leeuwen, Kurt Mehlhorn, and
  Karsten~M. Borgwardt.
\newblock Weisfeiler-lehman graph kernels.
\newblock {\em Journal of Machine Learning Research (JMLR)}, 2011.

\bibitem{Wale06_NCI1}
Nikil Wale and George Karypis.
\newblock Comparison of descriptor spaces for chemical compound retrieval and
  classification.
\newblock In {\em {Proc.\ Int.\ Conf.\ on Data Mining (ICDM)}}, 2006.

\bibitem{Qiu20_GCC}
Jiezhong Qiu, Qibin Chen, Yuxiao Dong, Jing Zhang, Hongxia Yang, Ming Ding,
  Kuansan Wang, and Jie Tang.
\newblock {GCC:} graph contrastive coding for graph neural network
  pre-training.
\newblock In {\em Proc.\ {ACM} Int.\ Conf.\ on Knowledge Discovery {\&} Data
  Mining (SIGKDD)}, 2020.

\bibitem{Kefato21_SelfGNN}
Zekarias~T. Kefato and Sarunas Girdzijauskas.
\newblock Self-supervised graph neural networks without explicit negative
  sampling.
\newblock In {\em Int.\ Workshop on Self-Supervised Learning for the Web
  (WWW'21)}, 2021.

\bibitem{Zhao20_DataAugGNN}
Tong Zhao, Yozen Liu, Leonardo Neves, Oliver~J. Woodford, Meng Jiang, and Neil
  Shah.
\newblock Data augmentation for graph neural networks.
\newblock In {\em Proc.\ Association for Advancment of Artificial Intelligence
  (AAAI)}, 2020.

\bibitem{Shafahi19_AdvTrainingFree}
Ali Shafahi, Mahyar Najibi, Amin Ghiasi, Zheng Xu, John~P. Dickerson, Christoph
  Studer, Larry~S. Davis, Gavin Taylor, and Tom Goldstein.
\newblock Adversarial training for free!
\newblock In {\em Proc.\ Adv.\ in Neural Information Processing Systems
  (NeurIPS)}, 2019.

\bibitem{Liu21_SSLGNNSurvey}
Yixin Liu, Shirui Pan, Ming Jin, Chuan Zhou, Feng Xia, and Philip~S. Yu.
\newblock Graph self-supervised learning: {A} survey.
\newblock {\em IEEE Trans.\ on Knowledge and Data Engineering}, 2022.

\bibitem{Yu18_InPainting}
Jiahui Yu, Zhe Lin, Jimei Yang, Xiaohui Shen, Xin Lu, and Thomas~S. Huang.
\newblock Generative image inpainting with contextual attention.
\newblock In {\em {Proc.\ Int.\ Conf.\ on Computer Vision and Pattern
  Recognition (CVPR)}}, 2018.

\bibitem{You20_WhenDoesSSLHelp}
Yuning You, Tianlong Chen, Zhangyang Wang, and Yang Shen.
\newblock When does self-supervision help graph convolutional networks?
\newblock In {\em {Proc.\ Int.\ Conf.\ on Machine Learning (ICML)}}, 2020.

\bibitem{Velickovic19_DGI}
Petar Velickovic, William Fedus, William~L. Hamilton, Pietro Li{\`{o}}, Yoshua
  Bengio, and R.~Devon Hjelm.
\newblock Deep graph infomax.
\newblock In {\em Proc.\ Int.\ Conf.\ on Learning Representations (ICLR)},
  2019.

\end{thebibliography}
