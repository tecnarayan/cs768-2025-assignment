\begin{thebibliography}{44}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ardizzone et~al.(2018-2022)Ardizzone, Bungert, Draxler, Köthe, Kruse, Schmier, and Sorrenson]{freia}
L.~Ardizzone, T.~Bungert, F.~Draxler, U.~Köthe, J.~Kruse, R.~Schmier, and P.~Sorrenson.
\newblock {Framework for Easily Invertible Architectures (FrEIA)}, 2018-2022.
\newblock URL \url{https://github.com/vislearn/FrEIA}.

\bibitem[Breheny and Huang(2011)]{Breheny2011coordinate}
P.~Breheny and J.~Huang.
\newblock Coordinate descent algorithms for nonconvex penalized regression, with applications to biological feature selection.
\newblock \emph{The Annals of Applied Statistics}, 5\penalty0 (1):\penalty0 232--253, 2011.

\bibitem[Buchholz et~al.(2022)Buchholz, Besserve, and Sch{\"o}lkopf]{buchholz2022function}
S.~Buchholz, M.~Besserve, and B.~Sch{\"o}lkopf.
\newblock Function classes for identifiable nonlinear independent component analysis.
\newblock \emph{arXiv preprint arXiv:2208.06406}, 2022.

\bibitem[Burgess et~al.(2018)Burgess, Higgins, Pal, Matthey, Watters, Desjardins, and Lerchner]{burgess2018understanding}
C.~P. Burgess, I.~Higgins, A.~Pal, L.~Matthey, N.~Watters, G.~Desjardins, and A.~Lerchner.
\newblock Understanding disentangling in beta-{VAE}.
\newblock \emph{Workshop on Learning Disentangled Representations at the 31st Conference on Neural Information Processing Systems}, 2018.

\bibitem[Carbonneau et~al.(2022)Carbonneau, Zaidi, Boilard, and Gagnon]{carbonneau2022measuring}
M.-A. Carbonneau, J.~Zaidi, J.~Boilard, and G.~Gagnon.
\newblock Measuring disentanglement: A review of metrics.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems}, 2022.

\bibitem[Cardoso(1998)]{cardoso1998multidimensional}
J.-F. Cardoso.
\newblock Multidimensional independent component analysis.
\newblock In \emph{Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP'98 (Cat. No. 98CH36181)}, volume~4, pages 1941--1944. IEEE, 1998.

\bibitem[Chen et~al.(2018)Chen, Li, Grosse, and Duvenaud]{chen2018isolating}
R.~T. Chen, X.~Li, R.~B. Grosse, and D.~K. Duvenaud.
\newblock Isolating sources of disentanglement in variational autoencoders.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Cohen et~al.(2017)Cohen, Afshar, Tapson, and Van~Schaik]{cohen2017emnist}
G.~Cohen, S.~Afshar, J.~Tapson, and A.~Van~Schaik.
\newblock Emnist: Extending mnist to handwritten letters.
\newblock In \emph{2017 international joint conference on neural networks (IJCNN)}, pages 2921--2926. IEEE, 2017.

\bibitem[Comon(1994)]{comon1994independent}
P.~Comon.
\newblock Independent component analysis, a new concept?
\newblock \emph{Signal processing}, 36\penalty0 (3):\penalty0 287--314, 1994.

\bibitem[Duan et~al.(2020)Duan, Matthey, Saraiva, Watters, Burgess, Lerchner, and Higgins]{duan2020unsupervised}
S.~Duan, L.~Matthey, A.~Saraiva, N.~Watters, C.~Burgess, A.~Lerchner, and I.~Higgins.
\newblock Unsupervised model selection for variational disentangled representation learning.
\newblock In \emph{ICLR}, 2020.

\bibitem[Falck et~al.(2021)Falck, Zhang, Willetts, Nicholson, Yau, and Holmes]{falck2021multi}
F.~Falck, H.~Zhang, M.~Willetts, G.~Nicholson, C.~Yau, and C.~C. Holmes.
\newblock Multi-facet clustering variational autoencoders.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 8676--8690, 2021.

\bibitem[Fan and Li(2001)]{fan2001variable}
J.~Fan and R.~Li.
\newblock Variable selection via nonconcave penalized likelihood and its oracle properties.
\newblock \emph{Journal of the American statistical Association}, 96\penalty0 (456):\penalty0 1348--1360, 2001.

\bibitem[H{\"a}lv{\"a} et~al.(2021)H{\"a}lv{\"a}, Le~Corff, Leh{\'e}ricy, So, Zhu, Gassiat, and Hyv{\"a}rinen]{halva2021disentangling}
H.~H{\"a}lv{\"a}, S.~Le~Corff, L.~Leh{\'e}ricy, J.~So, Y.~Zhu, E.~Gassiat, and A.~Hyv{\"a}rinen.
\newblock Disentangling identifiable features from noisy data with structured nonlinear {ICA}.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Hyv{\"a}rinen and Hoyer(2000)]{hyvarinen2000emergence}
A.~Hyv{\"a}rinen and P.~Hoyer.
\newblock Emergence of phase-and shift-invariant features by decomposition of natural images into independent feature subspaces.
\newblock \emph{Neural computation}, 12\penalty0 (7):\penalty0 1705--1720, 2000.

\bibitem[Hyv{\"a}rinen and Morioka(2016)]{hyvarinen2016unsupervised}
A.~Hyv{\"a}rinen and H.~Morioka.
\newblock Unsupervised feature extraction by time-contrastive learning and nonlinear {{ICA}}.
\newblock \emph{Advances in Neural Information Processing Systems}, 29:\penalty0 3765--3773, 2016.

\bibitem[Hyv{\"a}rinen and Morioka(2017)]{hyvarinen2017nonlinear}
A.~Hyv{\"a}rinen and H.~Morioka.
\newblock Nonlinear {ICA} of temporally dependent stationary sources.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pages 460--469. PMLR, 2017.

\bibitem[Hyv{\"a}rinen and Pajunen(1999)]{hyvarinen1999nonlinear}
A.~Hyv{\"a}rinen and P.~Pajunen.
\newblock Nonlinear independent component analysis: Existence and uniqueness results.
\newblock \emph{Neural networks}, 12\penalty0 (3):\penalty0 429--439, 1999.

\bibitem[Hyv{\"a}rinen et~al.(2019)Hyv{\"a}rinen, Sasaki, and Turner]{hyvarinen2019nonlinear}
A.~Hyv{\"a}rinen, H.~Sasaki, and R.~Turner.
\newblock Nonlinear {ICA} using auxiliary variables and generalized contrastive learning.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pages 859--868. PMLR, 2019.

\bibitem[Khemakhem et~al.(2020{\natexlab{a}})Khemakhem, Kingma, Monti, and Hyv{\"a}rinen]{khemakhem2020variational}
I.~Khemakhem, D.~Kingma, R.~Monti, and A.~Hyv{\"a}rinen.
\newblock Variational autoencoders and nonlinear {ICA}: A unifying framework.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pages 2207--2217. PMLR, 2020{\natexlab{a}}.

\bibitem[Khemakhem et~al.(2020{\natexlab{b}})Khemakhem, Monti, Kingma, and Hyvarinen]{khemakhem2020ice}
I.~Khemakhem, R.~Monti, D.~Kingma, and A.~Hyvarinen.
\newblock Ice-beem: Identifiable conditional energy-based deep models based on nonlinear ica.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 12768--12778, 2020{\natexlab{b}}.

\bibitem[Kingma and Dhariwal(2018)]{kingma2018glow}
D.~P. Kingma and P.~Dhariwal.
\newblock Glow: Generative flow with invertible $1$x$1$ convolutions.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Kivva et~al.(2022)Kivva, Rajendran, Ravikumar, and Aragam]{kivva2022identifiability}
B.~Kivva, G.~Rajendran, P.~Ravikumar, and B.~Aragam.
\newblock Identifiability of deep generative models without auxiliary information.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 15687--15701, 2022.

\bibitem[Klys et~al.(2018)Klys, Snell, and Zemel]{klys2018learning}
J.~Klys, J.~Snell, and R.~Zemel.
\newblock Learning latent subspaces in variational autoencoders.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Kong et~al.(2022)Kong, Xie, Yao, Zheng, Chen, Stojanov, Akinwande, and Zhang]{kong2022partial}
L.~Kong, S.~Xie, W.~Yao, Y.~Zheng, G.~Chen, P.~Stojanov, V.~Akinwande, and K.~Zhang.
\newblock Partial disentanglement for domain adaptation.
\newblock In \emph{International Conference on Machine Learning}, pages 11455--11472. PMLR, 2022.

\bibitem[Kumar et~al.(2017)Kumar, Sattigeri, and Balakrishnan]{kumar2017variational}
A.~Kumar, P.~Sattigeri, and A.~Balakrishnan.
\newblock Variational inference of disentangled latent concepts from unlabeled observations.
\newblock \emph{arXiv preprint arXiv:1711.00848}, 2017.

\bibitem[Lachapelle and Lacoste-Julien(2022)]{lachapelle2022partial}
S.~Lachapelle and S.~Lacoste-Julien.
\newblock Partial disentanglement via mechanism sparsity.
\newblock In \emph{UAI 2022 Workshop on Causal Representation Learning}, 2022.

\bibitem[Lachapelle et~al.(2022)Lachapelle, L{\'o}pez, Sharma, Everett, Priol, Lacoste, and Lacoste-Julien]{lachapelle2021disentanglement}
S.~Lachapelle, P.~R. L{\'o}pez, Y.~Sharma, K.~Everett, R.~L. Priol, A.~Lacoste, and S.~Lacoste-Julien.
\newblock Disentanglement via mechanism sparsity regularization: A new principle for nonlinear {ICA}.
\newblock \emph{Conference on Causal Learning and Reasoning}, 2022.

\bibitem[Locatello et~al.(2018)Locatello, Vincent, Tolstikhin, R{\"a}tsch, Gelly, and Sch{\"o}lkopf]{locatello2018competitive}
F.~Locatello, D.~Vincent, I.~Tolstikhin, G.~R{\"a}tsch, S.~Gelly, and B.~Sch{\"o}lkopf.
\newblock Competitive training of mixtures of independent deep generative models.
\newblock \emph{arXiv preprint arXiv:1804.11130}, 2018.

\bibitem[Locatello et~al.(2019)Locatello, Bauer, Lucic, Raetsch, Gelly, Sch{\"o}lkopf, and Bachem]{locatello2019challenging}
F.~Locatello, S.~Bauer, M.~Lucic, G.~Raetsch, S.~Gelly, B.~Sch{\"o}lkopf, and O.~Bachem.
\newblock Challenging common assumptions in the unsupervised learning of disentangled representations.
\newblock In \emph{international conference on machine learning}, pages 4114--4124. PMLR, 2019.

\bibitem[Loh and Wainwright(2017)]{Loh2017support}
P.-L. Loh and M.~J. Wainwright.
\newblock Support recovery without incoherence: A case for nonconvex regularization.
\newblock \emph{The Annals of Statistics}, 45\penalty0 (6):\penalty0 2455--2482, 2017.

\bibitem[Monge(1850)]{mongeapplications}
G.~Monge.
\newblock Applications de l'analyse {\'a} la g{\'e}om{\'e}trie, 1850.

\bibitem[Ravikumar et~al.(2008)Ravikumar, Raskutti, Wainwright, and Yu]{Ravikumar2008model}
P.~Ravikumar, G.~Raskutti, M.~J. Wainwright, and B.~Yu.
\newblock Model selection in {Gaussian} graphical models: High-dimensional consistency of $\ell_{1}$-regularized {MLE}.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2008.

\bibitem[Ravikumar et~al.(2011)Ravikumar, Wainwright, Raskutti, and Yu]{ravikumar2011high}
P.~Ravikumar, M.~J. Wainwright, G.~Raskutti, and B.~Yu.
\newblock High-dimensional covariance estimation by minimizing $\ell_1$-penalized log-determinant divergence.
\newblock \emph{Electronic Journal of Statistics}, 5:\penalty0 935--980, 2011.

\bibitem[Rubenstein et~al.(2018)Rubenstein, Sch{\"o}lkopf, and Tolstikhin]{rubenstein2018learning}
P.~Rubenstein, B.~Sch{\"o}lkopf, and I.~Tolstikhin.
\newblock Learning disentangled representations with wasserstein auto-encoders.
\newblock In \emph{6th International Conference on Learning Representations (ICLR 2018)}, 2018.

\bibitem[Sorrenson et~al.(2020)Sorrenson, Rother, and K{\"o}the]{sorrenson2020disentanglement}
P.~Sorrenson, C.~Rother, and U.~K{\"o}the.
\newblock Disentanglement by nonlinear {ICA} with general incompressible-flow networks ({GIN}).
\newblock \emph{arXiv preprint arXiv:2001.04872}, 2020.

\bibitem[Taleb and Jutten(1999)]{taleb1999source}
A.~Taleb and C.~Jutten.
\newblock Source separation in post-nonlinear mixtures.
\newblock \emph{IEEE Transactions on signal Processing}, 47\penalty0 (10):\penalty0 2807--2820, 1999.

\bibitem[Theis(2006)]{theis2006towards}
F.~Theis.
\newblock Towards a general independent subspace analysis.
\newblock \emph{Advances in Neural Information Processing Systems}, 19, 2006.

\bibitem[Von~K{\"u}gelgen et~al.(2021)Von~K{\"u}gelgen, Sharma, Gresele, Brendel, Sch{\"o}lkopf, Besserve, and Locatello]{von2021self}
J.~Von~K{\"u}gelgen, Y.~Sharma, L.~Gresele, W.~Brendel, B.~Sch{\"o}lkopf, M.~Besserve, and F.~Locatello.
\newblock Self-supervised learning with data augmentations provably isolates content from style.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 16451--16467, 2021.

\bibitem[Wainwright(2009)]{Wainwright2009sharp}
M.~J. Wainwright.
\newblock Sharp thresholds for high-dimensional and noisy sparsity recovery using $\ell_{1}$-constrained quadratic programming ({Lasso}).
\newblock \emph{IEEE Transactions on Information Theory}, 55\penalty0 (5):\penalty0 2183--2202, 2009.

\bibitem[Yang et~al.(2022)Yang, Wang, Sun, Zhang, Zhang, Li, and Yan]{annoymous2022iclr}
X.~Yang, Y.~Wang, J.~Sun, X.~Zhang, S.~Zhang, Z.~Li, and J.~Yan.
\newblock Nonlinear {ICA} using volume-preserving transformations.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Yao et~al.(2021)Yao, Sun, Ho, Sun, and Zhang]{yao2021learning}
W.~Yao, Y.~Sun, A.~Ho, C.~Sun, and K.~Zhang.
\newblock Learning temporally causal latent processes from general temporal data.
\newblock \emph{arXiv preprint arXiv:2110.05428}, 2021.

\bibitem[Yao et~al.(2022)Yao, Chen, and Zhang]{yao2022temporally}
W.~Yao, G.~Chen, and K.~Zhang.
\newblock Temporally disentangled representation learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Zhang(2010)]{Zhang2010nearly}
C.-H. Zhang.
\newblock Nearly unbiased variable selection under minimax concave penalty.
\newblock \emph{The Annals of Statistics}, 38\penalty0 (2):\penalty0 894--942, 2010.

\bibitem[Zheng et~al.(2022)Zheng, Ng, and Zhang]{zhengidentifiability}
Y.~Zheng, I.~Ng, and K.~Zhang.
\newblock On the identifiability of nonlinear {ICA}: Sparsity and beyond.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\end{thebibliography}
