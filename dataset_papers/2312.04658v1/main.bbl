\begin{thebibliography}{48}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahsan et~al.(2022)Ahsan, Luna, and Siddique]{ahsan2022machine}
Md~Manjurul Ahsan, Shahana~Akter Luna, and Zahed Siddique.
\newblock Machine-learning-based disease diagnosis: A comprehensive review.
\newblock \emph{{Healthcare}}, 10\penalty0 (3):\penalty0 541, 2022.

\bibitem[Angelopoulos and Bates(2021)]{angelopoulos2021gentle}
Anastasios~N Angelopoulos and Stephen Bates.
\newblock A gentle introduction to conformal prediction and distribution-free
  uncertainty quantification.
\newblock \emph{arXiv:2107.07511}, 2021.

\bibitem[Arora et~al.(2018)Arora, Ge, Neyshabur, and Zhang]{arora2018stronger}
Sanjeev Arora, Rong Ge, Behnam Neyshabur, and Yi~Zhang.
\newblock Stronger generalization bounds for deep nets via a compression
  approach.
\newblock In \emph{{Int.\ Conf.\ on Machine Learning}}, pages 254--263, 2018.

\bibitem[Bai et~al.(2022)Bai, Mei, Wang, Zhou, and Xiong]{bai2022efficient}
Yu~Bai, Song Mei, Huan Wang, Yingbo Zhou, and Caiming Xiong.
\newblock Efficient and differentiable conformal prediction with general
  function classes.
\newblock In \emph{{Int.\ Conf.\ on Learning Representations}}, 2022.

\bibitem[Bartlett et~al.(2017)Bartlett, Foster, and
  Telgarsky]{bartlett17spectrally}
Peter~L. Bartlett, Dylan~J. Foster, and Matus~J Telgarsky.
\newblock {Spectrally-Normalized Margin Bounds for Neural Networks}.
\newblock In \emph{{Conf.\ on Neural Information Processing Systems}},
  volume~30, 2017.

\bibitem[Blumer et~al.(1987)Blumer, Ehrenfeucht, Haussler, and
  Warmuth]{blumer87occams}
Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred~K Warmuth.
\newblock Occam's razor.
\newblock \emph{{Information Processing Letters}}, 24\penalty0 (6):\penalty0
  377--380, 1987.

\bibitem[Cleaveland et~al.(2023)Cleaveland, Lee, Pappas, and
  Lindemann]{cleaveland2023conformal}
Matthew Cleaveland, Insup Lee, George~J Pappas, and Lars Lindemann.
\newblock Conformal prediction regions for time series using linear
  complementarity programming.
\newblock \emph{arXiv:2304.01075}, 2023.

\bibitem[Cuturi et~al.(2019)Cuturi, Teboul, and Vert]{cuturi2019differentiable}
Marco Cuturi, Olivier Teboul, and Jean-Philippe Vert.
\newblock Differentiable ranking and sorting using optimal transport.
\newblock In \emph{{Conf.\ on Neural Information Processing Systems}},
  volume~32, 2019.

\bibitem[Donsker and Varadhan(1983)]{donsker1983asymptotic}
Monroe~D Donsker and SR~Srinivasa Varadhan.
\newblock Asymptotic evaluation of certain markov process expectations for
  large time. iv.
\newblock \emph{{Communications on Pure and Applied Mathematics}}, 36\penalty0
  (2):\penalty0 183--212, 1983.

\bibitem[Dziugaite and Roy(2017)]{dziugiate17computing}
Gintare~Karolina Dziugaite and Daniel~M. Roy.
\newblock {Computing Nonvacuous Generalization Bounds for Deep (Stochastic)
  Neural Networks with Many More Parameters than Training Data}.
\newblock In \emph{{Proc.\ Conf.\ on Uncertainty in Artificial Intelligence}},
  2017.

\bibitem[Dziugaite and Roy(2018)]{dziugaite2018data}
Gintare~Karolina Dziugaite and Daniel~M Roy.
\newblock Data-dependent pac-bayes priors via differential privacy.
\newblock In \emph{{Conf.\ on Neural Information Processing Systems}},
  volume~31, 2018.

\bibitem[Einbinder et~al.(2022)Einbinder, Romano, Sesia, and
  Zhou]{einbinder2022training}
Bat-Sheva Einbinder, Yaniv Romano, Matteo Sesia, and Yanfei Zhou.
\newblock Training uncertainty-aware classifiers with conformalized deep
  learning.
\newblock In \emph{{Conf.\ on Neural Information Processing Systems}},
  volume~35, 2022.

\bibitem[Fard et~al.(2012)Fard, Pineau, and Szepesv{\'a}ri]{fard2012pac}
Mahdi~Milani Fard, Joelle Pineau, and Csaba Szepesv{\'a}ri.
\newblock Pac-bayesian policy evaluation for reinforcement learning.
\newblock \emph{arXiv:1202.3717}, 2012.

\bibitem[Grover et~al.(2019)Grover, Wang, Zweig, and
  Ermon]{grover2018stochastic}
Aditya Grover, Eric Wang, Aaron Zweig, and Stefano Ermon.
\newblock Stochastic optimization of sorting networks via continuous
  relaxations.
\newblock In \emph{{Int.\ Conf.\ on Learning Representations}}, 2019.

\bibitem[Jiang et~al.(2020)Jiang, Neyshabur, Mobahi, Krishnan, and
  Bengio]{jiang2020fantastic}
Yiding Jiang, Behnam Neyshabur, Hossein Mobahi, Dilip Krishnan, and Samy
  Bengio.
\newblock {Fantastic Generalization Measures and Where to Find Them}.
\newblock In \emph{{Int.\ Conf.\ on Learning Representations}}, 2020.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and
  Haffner]{lecun1998gradient}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Lindemann et~al.(2023)Lindemann, Cleaveland, Shim, and
  Pappas]{lindemann2023safe}
Lars Lindemann, Matthew Cleaveland, Gihyun Shim, and George~J Pappas.
\newblock Safe planning in dynamic environments using conformal prediction.
\newblock \emph{{IEEE Robotics and Automation Letters}}, 8, 2023.

\bibitem[Lotfi et~al.(2022)Lotfi, Finzi, Kapoor, Potapczynski, Goldblum, and
  Wilson]{lotfi2022pac}
Sanae Lotfi, Marc Finzi, Sanyam Kapoor, Andres Potapczynski, Micah Goldblum,
  and Andrew~G Wilson.
\newblock {PAC-Bayes} compression bounds so tight that they can explain
  generalization.
\newblock In \emph{{Conf.\ on Neural Information Processing Systems}},
  volume~35, 2022.

\bibitem[Majumdar et~al.(2021)Majumdar, Farid, and Sonar]{majumdar2021pac}
Anirudha Majumdar, Alec Farid, and Anoopkumar Sonar.
\newblock {PAC-Bayes} control: learning policies that provably generalize to
  novel environments.
\newblock \emph{{Int.\ Journal of Robotics Research}}, 40\penalty0
  (2-3):\penalty0 574--593, 2021.

\bibitem[Maurer(2004)]{maurer2004note}
Andreas Maurer.
\newblock A note on the pac bayesian theorem.
\newblock \emph{arXiv:cs/0411099}, 2004.

\bibitem[McAllester(1998)]{mcallester1998some}
David~A McAllester.
\newblock Some {PAC}-{B}ayesian theorems.
\newblock In \emph{{Proc.\ Computational Learning Theory}}, pages 230--234,
  1998.

\bibitem[Neyshabur et~al.(2017{\natexlab{a}})Neyshabur, Bhojanapalli,
  McAllester, and Srebro]{neyshabur2017pac}
Behnam Neyshabur, Srinadh Bhojanapalli, David McAllester, and Nathan Srebro.
\newblock {A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for
  Neural Networks}.
\newblock \emph{arXiv:1707.09564}, 2017{\natexlab{a}}.

\bibitem[Neyshabur et~al.(2017{\natexlab{b}})Neyshabur, Bhojanapalli,
  McAllester, and Srebro]{neyshabur2017exploring}
Behnam Neyshabur, Srinadh Bhojanapalli, David McAllester, and Nati Srebro.
\newblock {Exploring Generalization in Deep Learning}.
\newblock In \emph{{Conf.\ on Neural Information Processing Systems}},
  volume~30, 2017{\natexlab{b}}.

\bibitem[Ovadia et~al.(2019)Ovadia, Fertig, Ren, Nado, Sculley, Nowozin,
  Dillon, Lakshminarayanan, and Snoek]{ovadia2019can}
Yaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, David Sculley, Sebastian
  Nowozin, Joshua Dillon, Balaji Lakshminarayanan, and Jasper Snoek.
\newblock Can you trust your model's uncertainty? evaluating predictive
  uncertainty under dataset shift.
\newblock \emph{{Conf.\ on Neural Information Processing Systems}}, 32, 2019.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In \emph{{Conf.\ on Neural Information Processing Systems}},
  volume~32, 2019.

\bibitem[Perez-Ortiz et~al.(2021)Perez-Ortiz, Rivasplata, Guedj, Gleeson,
  Zhang, Shawe-Taylor, Bober, and Kittler]{perez2021learning}
Maria Perez-Ortiz, Omar Rivasplata, Benjamin Guedj, Matthew Gleeson, Jingyu
  Zhang, John Shawe-Taylor, Miroslaw Bober, and Josef Kittler.
\newblock Learning pac-bayes priors for probabilistic neural networks.
\newblock \emph{arXiv:2109.10304}, 2021.

\bibitem[P{\'e}rez-Ortiz et~al.(2021)P{\'e}rez-Ortiz, Rivasplata, Shawe-Taylor,
  and Szepesv{\'a}ri]{perez2021tighter}
Mar{\'\i}a P{\'e}rez-Ortiz, Omar Rivasplata, John Shawe-Taylor, and Csaba
  Szepesv{\'a}ri.
\newblock Tighter risk certificates for neural networks.
\newblock \emph{{Journal of Machine Learning Research}}, 22:\penalty0
  10326--10365, 2021.

\bibitem[Ren et~al.(2021)Ren, Veer, and Majumdar]{ren2021generalization}
Allen Ren, Sushant Veer, and Anirudha Majumdar.
\newblock Generalization guarantees for imitation learning.
\newblock In \emph{{Conf.\ on Robot Learning}}, pages 1426--1442, 2021.

\bibitem[Rissanen(1989)]{rissanen1989stochastic}
Jorma Rissanen.
\newblock \emph{Stochastic Complexity in Statistical Inquiry}.
\newblock {World Scientific Publishing}, 1989.

\bibitem[Rivasplata et~al.(2019)Rivasplata, Tankasali, and
  Szepesvari]{rivasplata2019pac}
Omar Rivasplata, Vikram~M Tankasali, and Csaba Szepesvari.
\newblock Pac-bayes with backprop.
\newblock \emph{arXiv:1908.07380}, 2019.

\bibitem[Romano et~al.(2019)Romano, Patterson, and
  Candes]{romano2019conformalized}
Yaniv Romano, Evan Patterson, and Emmanuel Candes.
\newblock Conformalized quantile regression.
\newblock In \emph{{Conf.\ on Neural Information Processing Systems}},
  volume~32, 2019.

\bibitem[Romano et~al.(2020)Romano, Sesia, and
  Candes]{romano2020classification}
Yaniv Romano, Matteo Sesia, and Emmanuel Candes.
\newblock Classification with valid and adaptive coverage.
\newblock In \emph{{Conf.\ on Neural Information Processing Systems}},
  volume~33, 2020.

\bibitem[Sadinle et~al.(2019)Sadinle, Lei, and Wasserman]{sadinle2019least}
Mauricio Sadinle, Jing Lei, and Larry Wasserman.
\newblock Least ambiguous set-valued classifiers with bounded error levels.
\newblock \emph{Journal of the American Statistical Association}, 114\penalty0
  (525):\penalty0 223--234, 2019.

\bibitem[Schwarting et~al.(2018)Schwarting, Alonso-Mora, and
  Rus]{schwarting2018planning}
Wilko Schwarting, Javier Alonso-Mora, and Daniela Rus.
\newblock Planning and decision-making for autonomous vehicles.
\newblock \emph{Annual Review of Control, Robotics, and Autonomous Systems},
  1\penalty0 (1):\penalty0 187--210, 2018.

\bibitem[Seeger et~al.(2001)Seeger, Langford, and Megiddo]{seeger2001improved}
Matthias Seeger, John Langford, and Nimrod Megiddo.
\newblock An improved predictive accuracy bound for averaging classifiers.
\newblock In \emph{{Int.\ Conf.\ on Machine Learning}}, pages 290--297, 2001.

\bibitem[Shalev-Shwartz and Ben-David(2014)]{shalev2014understanding}
Shai Shalev-Shwartz and Shai Ben-David.
\newblock \emph{Understanding Machine Learning: From Theory to Algorithms}.
\newblock {Cambridge Univ.\ Press}, 2014.

\bibitem[Sharma et~al.(2021)Sharma, Azizan, and Pavone]{sharma2021sketching}
Apoorva Sharma, Navid Azizan, and Marco Pavone.
\newblock Sketching curvature for efficient out-of-distribution detection for
  deep neural networks.
\newblock In \emph{{Proc.\ Conf.\ on Uncertainty in Artificial Intelligence}},
  pages 1958--1967, 2021.

\bibitem[Stutz et~al.(2021)Stutz, Cemgil, Doucet, et~al.]{stutz2021learning}
David Stutz, Ali~Taylan Cemgil, Arnaud Doucet, et~al.
\newblock Learning optimal conformal classifiers.
\newblock In \emph{{Int.\ Conf.\ on Learning Representations}}, 2021.

\bibitem[Vamathevan et~al.(2019)Vamathevan, Clark, Czodrowski, Dunham, Ferran,
  Lee, Li, Madabhushi, Shah, Spitzer, et~al.]{vamathevan2019applications}
Jessica Vamathevan, Dominic Clark, Paul Czodrowski, Ian Dunham, Edgardo Ferran,
  George Lee, Bin Li, Anant Madabhushi, Parantu Shah, Michaela Spitzer, et~al.
\newblock Applications of machine learning in drug discovery and development.
\newblock \emph{Nature Reviews Drug Discovery}, 18\penalty0 (6):\penalty0
  463--477, 2019.

\bibitem[Vapnik and Chervonenkis(1968)]{vapnik1968uniform}
Vladimir~N Vapnik and A~Ya Chervonenkis.
\newblock On the uniform convergence of relative frequencies of events to their
  probabilities.
\newblock \emph{Dokl. Akad. Nauk}, 181\penalty0 (4), 1968.

\bibitem[Veer and Majumdar(2020)]{veer2020probably}
Sushant Veer and Anirudha Majumdar.
\newblock Probably approximately correct vision-based planning using motion
  primitives.
\newblock In \emph{{Conf.\ on Robot Learning}}, pages 1001--1014, 2020.

\bibitem[Viallard et~al.(2023)Viallard, Germain, Habrard, and
  Morvant]{viallard2023general}
Paul Viallard, Pascal Germain, Amaury Habrard, and Emilie Morvant.
\newblock A general framework for the practical disintegration of pac-bayesian
  bounds.
\newblock \emph{{Machine Learning}}, 2023.

\bibitem[Vovk(2012)]{vovk2012conditional}
Vladimir Vovk.
\newblock Conditional validity of inductive conformal predictors.
\newblock In \emph{{Asian Conf.\ on Machine Learning}}, pages 475--490, 2012.

\bibitem[Vovk et~al.(2005)Vovk, Gammerman, and Shafer]{vovk2005algorithmic}
Vladimir Vovk, Alexander Gammerman, and Glenn Shafer.
\newblock \emph{Algorithmic learning in a random world}.
\newblock {Springer}, 2005.

\bibitem[Waymo(2021)]{WaymoAVHandbook}
Waymo.
\newblock {The Waymo Driver Handbook: Teaching an autonomous vehicle how to
  perceive and understand the world around it}, 2021.
\newblock {Available at
  }\url{https://blog.waymo.com/2021/10/the-waymo-driver-handbook-perception.html}.

\bibitem[Yadan(2019)]{Yadan2019Hydra}
Omry Yadan.
\newblock Hydra - a framework for elegantly configuring complex applications.
\newblock Github, 2019.
\newblock URL \url{https://github.com/facebookresearch/hydra}.

\bibitem[Yang and Pavone(2023)]{yang2023object}
Heng Yang and Marco Pavone.
\newblock Object pose estimation with statistical guarantees: Conformal
  keypoint detection and geometric uncertainty propagation.
\newblock In \emph{{IEEE Conf.\ on Computer Vision and Pattern Recognition}},
  2023.

\bibitem[Yang and Kuchibhotla(2021)]{yang2021finite}
Yachong Yang and Arun~Kumar Kuchibhotla.
\newblock Finite-sample efficient conformal prediction.
\newblock \emph{arXiv:2104.13871}, 2021.

\end{thebibliography}
