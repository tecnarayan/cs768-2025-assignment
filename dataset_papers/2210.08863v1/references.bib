@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@article{sharma2021autonomous,
  title={Autonomous Reinforcement Learning: Formalism and Benchmarking},
  author={Sharma, Archit and Xu, Kelvin and Sardana, Nikhil and Gupta, Abhishek and Hausman, Karol and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2112.09605},
  year={2021}
}

@article{balloch2022novgrid,
  title={NovGrid: A Flexible Grid World for Evaluating Agent Response to Novelty},
  author={Balloch, Jonathan and Lin, Zhiyu and Hussain, Mustafa and Srinivas, Aarun and Wright, Robert and Peng, Xiangyu and Kim, Julia and Riedl, Mark},
  journal={arXiv preprint arXiv:2203.12117},
  year={2022}
}

@article{xie2020deep,
  title={Deep reinforcement learning amidst lifelong non-stationarity},
  author={Xie, Annie and Harrison, James and Finn, Chelsea},
  journal={arXiv preprint arXiv:2006.10701},
  year={2020}
}

@article{ho2016generative,
  title={Generative adversarial imitation learning},
  author={Ho, Jonathan and Ermon, Stefano},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{fu2017learning,
  title={Learning robust rewards with adversarial inverse reinforcement learning},
  author={Fu, Justin and Luo, Katie and Levine, Sergey},
  journal={arXiv preprint arXiv:1710.11248},
  year={2017}
}

@inproceedings{finn2016guided,
  title={Guided cost learning: Deep inverse optimal control via policy optimization},
  author={Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={49--58},
  year={2016},
  organization={PMLR}
}

@article{rudner2021outcome,
  title={Outcome-driven reinforcement learning via variational inference},
  author={Rudner, Tim GJ and Pong, Vitchyr and McAllister, Rowan and Gal, Yarin and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{eysenbach2017leave,
  title={Leave no trace: Learning to reset for safe and autonomous reinforcement learning},
  author={Eysenbach, Benjamin and Gu, Shixiang and Ibarz, Julian and Levine, Sergey},
  journal={arXiv preprint arXiv:1711.06782},
  year={2017}
}

@inproceedings{gupta2021reset,
  title={Reset-free reinforcement learning via multi-task learning: Learning dexterous manipulation behaviors without human intervention},
  author={Gupta, Abhishek and Yu, Justin and Zhao, Tony Z and Kumar, Vikash and Rovinsky, Aaron and Xu, Kelvin and Devlin, Thomas and Levine, Sergey},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={6664--6671},
  year={2021},
  organization={IEEE}
}

@inproceedings{sharma2021subgoal,
 author = {Sharma, Archit and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {18474--18486},
 publisher = {Curran Associates, Inc.},
 title = {Autonomous Reinforcement Learning via Subgoal Curricula},
 url = {https://proceedings.neurips.cc/paper/2021/file/99c83c904d0d64fbef50d919a5c66a80-Paper.pdf},
 volume = {34},
 year = {2021}
}

@article{zhu2020ingredients,
  title={The ingredients of real-world robotic reinforcement learning},
  author={Zhu, Henry and Yu, Justin and Gupta, Abhishek and Shah, Dhruv and Hartikainen, Kristian and Singh, Avi and Kumar, Vikash and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.12570},
  year={2020}
}

@inproceedings{julian2020never,
title	= {Never Stop Learning: The Effectiveness of Fine-Tuning in Robotic Reinforcement Learning},
author	= {Ryan Julian and Benjamin Swanson and Gaurav Sukhatme and Sergey Levine and Chelsea Finn and Karol Hausman},
year	= {2020},
URL	= {https://arxiv.org/abs/2004.10190}
}

@article{xie2021lifelong,
  title={Lifelong Robotic Reinforcement Learning by Retaining Experiences},
  author={Xie, Annie and Finn, Chelsea},
  journal={arXiv preprint arXiv:2109.09180},
  year={2021}
}

@article{gupta2019relay,
  title={Relay policy learning: Solving long-horizon tasks via imitation and reinforcement learning},
  author={Gupta, Abhishek and Kumar, Vikash and Lynch, Corey and Levine, Sergey and Hausman, Karol},
  journal={arXiv preprint arXiv:1910.11956},
  year={2019}
}

@inproceedings{ng2000algorithms,
  title={Algorithms for inverse reinforcement learning.},
  author={Ng, Andrew Y and Russell, Stuart J and others},
  booktitle={Icml},
  volume={1},
  pages={2},
  year={2000}
}

@article{fu2018variational,
  title={Variational inverse control with events: A general framework for data-driven reward definition},
  author={Fu, Justin and Singh, Avi and Ghosh, Dibya and Yang, Larry and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{nair2020awac,
  title={Awac: Accelerating online reinforcement learning with offline datasets},
  author={Nair, Ashvin and Gupta, Abhishek and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.09359},
  year={2020}
}

@inproceedings{
sasaki2021behavioral,
title={Behavioral Cloning from Noisy Demonstrations},
author={Fumihiro Sasaki and Ryota Yamashina},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=zrT3HcsWSAt}
}

@article{burda2018exploration,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}

@article{khetarpal2020towards,
  title={Towards continual reinforcement learning: A review and perspectives},
  author={Khetarpal, Khimya and Riemer, Matthew and Rish, Irina and Precup, Doina},
  journal={arXiv preprint arXiv:2012.13490},
  year={2020}
}

@inproceedings{fu2019diagnosing,
  title={Diagnosing bottlenecks in deep q-learning algorithms},
  author={Fu, Justin and Kumar, Aviral and Soh, Matthew and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={2021--2030},
  year={2019},
  organization={PMLR}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{mahadevan1996average,
  title={Average reward reinforcement learning: Foundations, algorithms, and empirical results},
  author={Mahadevan, Sridhar},
  journal={Machine learning},
  volume={22},
  number={1},
  pages={159--195},
  year={1996},
  publisher={Springer}
}

@inproceedings{schwartz1993reinforcement,
  title={A reinforcement learning method for maximizing undiscounted rewards},
  author={Schwartz, Anton},
  booktitle={Proceedings of the tenth international conference on machine learning},
  volume={298},
  pages={298--305},
  year={1993}
}

@article{sharma2022state,
  title={A State-Distribution Matching Approach to Non-Episodic Reinforcement Learning},
  author={Sharma, Archit and Ahmad, Rehaan and Finn, Chelsea},
  journal={arXiv preprint arXiv:2205.05212},
  year={2022}
}

@inproceedings{han2015learning,
  title={Learning compound multi-step controllers under unknown dynamics},
  author={Han, Weiqiao and Levine, Sergey and Abbeel, Pieter},
  booktitle={2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={6435--6442},
  year={2015},
  organization={IEEE}
}

@article{kim2022automating,
  title={Automating Reinforcement Learning with Example-based Resets},
  author={Kim, Jigang and hyeon Park, J and Cho, Daesol and Kim, H Jin},
  journal={IEEE Robotics and Automation Letters},
  year={2022},
  publisher={IEEE}
}

@article{gupta2022bootstrapped,
  title={Bootstrapped Autonomous Practicing via Multi-Task Reinforcement Learning},
  author={Gupta, Abhishek and Lynch, Corey and Kinman, Brandon and Peake, Garrett and Levine, Sergey and Hausman, Karol},
  journal={arXiv preprint arXiv:2203.15755},
  year={2022}
}

@inproceedings{ziebart2008maximum,
  title={Maximum entropy inverse reinforcement learning.},
  author={Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K and others},
  booktitle={AAAI},
  volume={8},
  pages={1433--1438},
  year={2008},
  organization={Chicago, IL, USA}
}

@inproceedings{ziebart2010modeling,
  title={Modeling interaction via the principle of maximum causal entropy},
  author={Ziebart, Brian D and Bagnell, J Andrew and Dey, Anind K},
  booktitle={ICML},
  year={2010}
}

@article{argall2009survey,
  title={A survey of robot learning from demonstration},
  author={Argall, Brenna D and Chernova, Sonia and Veloso, Manuela and Browning, Brett},
  journal={Robotics and autonomous systems},
  volume={57},
  number={5},
  pages={469--483},
  year={2009},
  publisher={Elsevier}
}

@inproceedings{ghasemipour2020divergence,
  title={A divergence minimization perspective on imitation learning methods},
  author={Ghasemipour, Seyed Kamyar Seyed and Zemel, Richard and Gu, Shixiang},
  booktitle={Conference on Robot Learning},
  pages={1259--1277},
  year={2020},
  organization={PMLR}
}

@article{kostrikov2018discriminator,
  title={Discriminator-actor-critic: Addressing sample inefficiency and reward bias in adversarial imitation learning},
  author={Kostrikov, Ilya and Agrawal, Kumar Krishna and Dwibedi, Debidatta and Levine, Sergey and Tompson, Jonathan},
  journal={arXiv preprint arXiv:1809.02925},
  year={2018}
}

@inproceedings{zhu2020off,
  title={Off-policy imitation learning from observations},
  author={Zhu, Zhuangdi and Lin, Kaixiang and Dai, Bo and Zhou, Jiayu},
  booktitle={the Thirty-fourth Annual Conference on Neural Information Processing Systems (NeurIPS 2020)},
  year={2020}
}

@inproceedings{torabi2019adversarial,
  title={Adversarial imitation learning from state-only demonstrations},
  author={Torabi, Faraz and Warnell, Garrett and Stone, Peter},
  booktitle={Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems},
  pages={2229--2231},
  year={2019}
}

@article{rafailov2021visual,
  title={Visual adversarial imitation learning using variational models},
  author={Rafailov, Rafael and Yu, Tianhe and Rajeswaran, Aravind and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{baram2017end,
  title={End-to-end differentiable adversarial imitation learning},
  author={Baram, Nir and Anschel, Oron and Caspi, Itai and Mannor, Shie},
  booktitle={International Conference on Machine Learning},
  pages={390--399},
  year={2017},
  organization={PMLR}
}

@inproceedings{brys2015reinforcement,
  title={Reinforcement learning from demonstration through shaping},
  author={Brys, Tim and Harutyunyan, Anna and Suay, Halit Bener and Chernova, Sonia and Taylor, Matthew E and Now{\'e}, Ann},
  booktitle={Twenty-fourth international joint conference on artificial intelligence},
  year={2015}
}

@inproceedings{nair2018overcoming,
  title={Overcoming exploration in reinforcement learning with demonstrations},
  author={Nair, Ashvin and McGrew, Bob and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={6292--6299},
  year={2018},
  organization={IEEE}
}

@article{rajeswaran2017learning,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.10087},
  year={2017}
}

@article{vecerik2017leveraging,
  title={Leveraging demonstrations for deep reinforcement learning on robotics problems with sparse rewards},
  author={Vecerik, Mel and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1707.08817},
  year={2017}
}

@inproceedings{hester2018deep,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  year={2018}
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@article{singh2019end,
  title={End-to-end robotic reinforcement learning without reward engineering},
  author={Singh, Avi and Yang, Larry and Hartikainen, Kristian and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:1904.07854},
  year={2019}
}

@article{kumar2020conservative,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{kidambi2020morel,
  title={Morel: Model-based offline reinforcement learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={21810--21823},
  year={2020}
}

@article{nair2020awac,
  title={Awac: Accelerating online reinforcement learning with offline datasets},
  author={Nair, Ashvin and Gupta, Abhishek and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.09359},
  year={2020}
}

@article{wu2019behavior,
  title={Behavior regularized offline reinforcement learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@article{yoneda2021invariance,
  title={Invariance Through Inference},
  author={Yoneda, Takuma and Yang, Ge and Walter, Matthew R and Stadie, Bradly},
  journal={arXiv preprint arXiv:2112.08526},
  year={2021}
}

@article{hansen2020self,
  title={Self-supervised policy adaptation during deployment},
  author={Hansen, Nicklas and Jangir, Rishabh and Sun, Yu and Aleny{\`a}, Guillem and Abbeel, Pieter and Efros, Alexei A and Pinto, Lerrel and Wang, Xiaolong},
  journal={arXiv preprint arXiv:2007.04309},
  year={2020}
}

@article{garg2021iq,
  title={IQ-Learn: Inverse soft-Q Learning for Imitation},
  author={Garg, Divyansh and Chakraborty, Shuvam and Cundy, Chris and Song, Jiaming and Ermon, Stefano},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{eysenbach2020off,
  title={Off-dynamics reinforcement learning: Training for transfer with domain classifiers},
  author={Eysenbach, Benjamin and Asawa, Swapnil and Chaudhari, Shreyas and Levine, Sergey and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2006.13916},
  year={2020}
}

@article{rusu2016progressive,
  title={Progressive neural networks},
  author={Rusu, Andrei A and Rabinowitz, Neil C and Desjardins, Guillaume and Soyer, Hubert and Kirkpatrick, James and Kavukcuoglu, Koray and Pascanu, Razvan and Hadsell, Raia},
  journal={arXiv preprint arXiv:1606.04671},
  year={2016}
}

@article{wang2020support,
  title={Support-weighted Adversarial Imitation Learning},
  author={Wang, Ruohan and Ciliberto, Carlo and Amadori, Pierluigi and Demiris, Yiannis},
  journal={arXiv preprint arXiv:2002.08803},
  year={2020}
}

@inproceedings{wang2021learning,
  title={Learning to Weight Imperfect Demonstrations},
  author={Wang, Yunke and Xu, Chang and Du, Bo and Lee, Honglak},
  booktitle={International Conference on Machine Learning},
  pages={10961--10970},
  year={2021},
  organization={PMLR}
}

@inproceedings{wang2021robust,
  title     = {Robust Adversarial Imitation Learning via Adaptively-Selected Demonstrations},
  author    = {Wang, Yunke and Xu, Chang and Du, Bo},
  booktitle = {Proceedings of the Thirtieth International Joint Conference on
               Artificial Intelligence, {IJCAI-21}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  editor    = {Zhi-Hua Zhou},
  pages     = {3155--3161},
  year      = {2021}
}

@article{cao2022learning,
  title={Learning from Imperfect Demonstrations via Adversarial Confidence Transfer},
  author={Cao, Zhangjie and Wang, Zihan and Sadigh, Dorsa},
  journal={arXiv preprint arXiv:2202.02967},
  year={2022}
}

@article{beliaev2022imitation,
  title={Imitation Learning by Estimating Expertise of Demonstrators},
  author={Beliaev, Mark and Shih, Andy and Ermon, Stefano and Sadigh, Dorsa and Pedarsani, Ramtin},
  journal={arXiv preprint arXiv:2202.01288},
  year={2022}
}

@article{wang2018exponentially,
  title={Exponentially weighted imitation learning for batched historical data},
  author={Wang, Qing and Xiong, Jiechao and Han, Lei and Liu, Han and Zhang, Tong and others},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{sun2019adversarial,
  title={Adversarial imitation learning from incomplete demonstrations},
  author={Sun, Mingfei and Ma, Xiaojuan},
  journal={arXiv preprint arXiv:1905.12310},
  year={2019}
}

@inproceedings{wu2019imitation,
  title={Imitation learning from imperfect demonstration},
  author={Wu, Yueh-Hua and Charoenphakdee, Nontawat and Bao, Han and Tangkaratt, Voot and Sugiyama, Masashi},
  booktitle={International Conference on Machine Learning},
  pages={6818--6827},
  year={2019},
  organization={PMLR}
}

@article{sadeghi2016cad2rl,
  title={Cad2rl: Real single-image flight without a single real image},
  author={Sadeghi, Fereshteh and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.04201},
  year={2016}
}

@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1126--1135},
  year={2017},
  organization={PMLR}
}

@article{nagabandi2018learning,
  title={Learning to adapt in dynamic, real-world environments through meta-reinforcement learning},
  author={Nagabandi, Anusha and Clavera, Ignasi and Liu, Simin and Fearing, Ronald S and Abbeel, Pieter and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:1803.11347},
  year={2018}
}

@article{zintgraf2019varibad,
  title={Varibad: A very good method for bayes-adaptive deep rl via meta-learning},
  author={Zintgraf, Luisa and Shiarlis, Kyriacos and Igl, Maximilian and Schulze, Sebastian and Gal, Yarin and Hofmann, Katja and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1910.08348},
  year={2019}
}

@inproceedings{finn2019online,
  title={Online meta-learning},
  author={Finn, Chelsea and Rajeswaran, Aravind and Kakade, Sham and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1920--1930},
  year={2019},
  organization={PMLR}
}

@inproceedings{tobin2017domain,
  title={Domain randomization for transferring deep neural networks from simulation to the real world},
  author={Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={2017 IEEE/RSJ international conference on intelligent robots and systems (IROS)},
  pages={23--30},
  year={2017},
  organization={IEEE}
}

@inproceedings{mehta2020active,
  title={Active domain randomization},
  author={Mehta, Bhairav and Diaz, Manfred and Golemo, Florian and Pal, Christopher J and Paull, Liam},
  booktitle={Conference on Robot Learning},
  pages={1162--1176},
  year={2020},
  organization={PMLR}
}

@inproceedings{peng2018sim,
  title={Sim-to-real transfer of robotic control with dynamics randomization},
  author={Peng, Xue Bin and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={3803--3810},
  year={2018},
  organization={IEEE}
}

@article{nichol2018first,
  title={On first-order meta-learning algorithms},
  author={Nichol, Alex and Achiam, Joshua and Schulman, John},
  journal={arXiv preprint arXiv:1803.02999},
  year={2018}
}

@article{qian2019exploration,
  title={Exploration bonus for regret minimization in discrete and continuous average reward mdps},
  author={Qian, Jian and Fruit, Ronan and Pirotta, Matteo and Lazaric, Alessandro},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{xu2018reinforced,
 author = {Xu, Ju and Zhu, Zhanxing},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Reinforced Continual Learning},
 url = {https://proceedings.neurips.cc/paper/2018/file/cee631121c2ec9232f3a2f028ad5c89b-Paper.pdf},
 volume = {31},
 year = {2018}
}

@InProceedings{Lomonaco_2020_CVPR_Workshops,
author = {Lomonaco, Vincenzo and Desai, Karan and Culurciello, Eugenio and Maltoni, Davide},
title = {Continual Reinforcement Learning in 3D Non-Stationary Environments},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
month = {June},
year = {2020}
}

@inproceedings{NEURIPS2019_fa7cdfad,
 author = {Rolnick, David and Ahuja, Arun and Schwarz, Jonathan and Lillicrap, Timothy and Wayne, Gregory},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Experience Replay for Continual Learning},
 url = {https://proceedings.neurips.cc/paper/2019/file/fa7cdfad1a5aaf8370ebeda47a1ff1c3-Paper.pdf},
 volume = {32},
 year = {2019}
}

@InProceedings{pmlr-v119-wei20c,
  title = 	 {Model-free Reinforcement Learning in Infinite-horizon Average-reward {M}arkov Decision Processes},
  author =       {Wei, Chen-Yu and Jahromi, Mehdi Jafarnia and Luo, Haipeng and Sharma, Hiteshi and Jain, Rahul},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {10170--10180},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR}
}

@article{zhang2017mixup,
  title={mixup: Beyond empirical risk minimization},
  author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1710.09412},
  year={2017}
}


@article{wang2020critic,
  title={Critic regularized regression},
  author={Wang, Ziyu and Novikov, Alexander and Zolna, Konrad and Merel, Josh S and Springenberg, Jost Tobias and Reed, Scott E and Shahriari, Bobak and Siegel, Noah and Gulcehre, Caglar and Heess, Nicolas and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7768--7778},
  year={2020}
}


@inproceedings{peters2010relative,
  title={Relative entropy policy search},
  author={Peters, Jan and Mulling, Katharina and Altun, Yasemin},
  booktitle={Twenty-Fourth AAAI Conference on Artificial Intelligence},
  year={2010}
}

@inproceedings{syed2008apprenticeship,
  title={Apprenticeship learning using linear programming},
  author={Syed, Umar and Bowling, Michael and Schapire, Robert E},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={1032--1039},
  year={2008}
}

@article{abdolmaleki2018maximum,
  title={Maximum a posteriori policy optimisation},
  author={Abdolmaleki, Abbas and Springenberg, Jost Tobias and Tassa, Yuval and Munos, Remi and Heess, Nicolas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1806.06920},
  year={2018}
}