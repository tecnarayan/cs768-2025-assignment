\begin{thebibliography}{10}

\bibitem{agarwal2011distributed}
Alekh Agarwal and John~C. Duchi.
\newblock Distributed delayed stochastic optimization.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  873--881, 2011.

\bibitem{arjevani2015communication}
Yossi Arjevani and Ohad Shamir.
\newblock Communication complexity of distributed convex learning and
  optimization.
\newblock In {\em Advances in neural information processing systems}, pages
  1756--1764, 2015.

\bibitem{assran2018stochastic}
Mahmoud Assran, Nicolas Loizou, Nicolas Ballas, and Michael Rabbat.
\newblock Stochastic gradient push for distributed deep learning.
\newblock {\em arXiv preprint arXiv:1811.10792}, 2018.

\bibitem{benezit2010order}
Florence B{\'e}n{\'e}zit, Alexandros~G Dimakis, Patrick Thiran, and Martin
  Vetterli.
\newblock Order-optimal consensus through randomized path averaging.
\newblock {\em IEEE Transactions on Information Theory}, 56(10):5150--5167,
  2010.

\bibitem{berthier2018gossip}
Rapha{\"e}l {Berthier}, Francis {Bach}, and Pierre {Gaillard}.
\newblock {Accelerated Gossip in Networks of Given Dimension using Jacobi
  Polynomial Iterations}.
\newblock {\em arXiv preprint arXiv:1805.08531}, May 2018.

\bibitem{bijral2017data}
Avleen~S Bijral, Anand~D Sarwate, and Nathan Srebro.
\newblock Data-dependent convergence for consensus stochastic optimization.
\newblock {\em IEEE Transactions on Automatic Control}, 62(9):4483--4498, 2017.

\bibitem{blanchard2018optimal}
Gilles Blanchard and Nicole M{\"u}cke.
\newblock Optimal rates for regularization of statistical inverse learning
  problems.
\newblock {\em Foundations of Computational Mathematics}, 18(4):971--1013,
  2018.

\bibitem{bousquet2008tradeoffs}
Olivier Bousquet and L{\'e}on Bottou.
\newblock The tradeoffs of large scale learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  161--168, 2008.

\bibitem{boyd2006randomized}
Stephen Boyd, Arpita Ghosh, Balaji Prabhakar, and Devavrat Shah.
\newblock Randomized gossip algorithms.
\newblock {\em IEEE transactions on information theory}, 52(6):2508--2530,
  2006.

\bibitem{Boyd:2011:DOS:2185815.2185816}
Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, and Jonathan Eckstein.
\newblock Distributed optimization and statistical learning via the alternating
  direction method of multipliers.
\newblock {\em Found. Trends Mach. Learn.}, 3(1):1--122, January 2011.

\bibitem{cao2006accelerated}
Ming Cao, Daniel~A Spielman, and Edmund~M Yeh.
\newblock Accelerated gossip algorithms for distributed computation.
\newblock In {\em Proc. of the 44th Annual Allerton Conference on
  Communication, Control, and Computation}, pages 952--959. Citeseer, 2006.

\bibitem{caponnetto2007optimal}
Andrea Caponnetto and Ernesto De~Vito.
\newblock Optimal rates for the regularized least-squares algorithm.
\newblock {\em Foundations of Computational Mathematics}, 7(3):331--368, 2007.

\bibitem{carratino2018learning}
Luigi Carratino, Alessandro Rudi, and Lorenzo Rosasco.
\newblock Learning with sgd and random features.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  10192--10203, 2018.

\bibitem{chung1997spectral}
Fan~R.K. Chung and Fan~Chung Graham.
\newblock {\em Spectral graph theory}.
\newblock Number~92. American Mathematical Soc., 1997.

\bibitem{cucker2007learning}
Felipe Cucker and Ding~Xuan Zhou.
\newblock {\em Learning theory: an approximation theory viewpoint}, volume~24.
\newblock Cambridge University Press, 2007.

\bibitem{dieuleveut2017harder}
Aymeric Dieuleveut, Nicolas Flammarion, and Francis Bach.
\newblock Harder, better, faster, stronger convergence rates for least-squares
  regression.
\newblock {\em The Journal of Machine Learning Research}, 18(1):3520--3570,
  2017.

\bibitem{dimakis2008geographic}
Alexandros~DG Dimakis, Anand~D Sarwate, and Martin~J Wainwright.
\newblock Geographic gossip: Efficient averaging for sensor networks.
\newblock {\em IEEE Transactions on Signal Processing}, 56(3):1205--1216, 2008.

\bibitem{DAW12}
John~C. Duchi, Alekh Agarwal, and Martin~J. Wainwright.
\newblock Dual averaging for distributed optimization: Convergence analysis and
  network scaling.
\newblock {\em IEEE Transactions on Automatic Control}, 57(3):592--606, 2012.

\bibitem{ghadimi2013stochastic}
Saeed Ghadimi and Guanghui Lan.
\newblock Stochastic first-and zeroth-order methods for nonconvex stochastic
  programming.
\newblock {\em SIAM Journal on Optimization}, 23(4):2341--2368, 2013.

\bibitem{guo2017learning}
Zheng-Chu Guo, Shao-Bo Lin, and Ding-Xuan Zhou.
\newblock Learning theory of distributed spectral algorithms.
\newblock {\em Inverse Problems}, 33(7):074009, 2017.

\bibitem{gyorfi2006distribution}
L{\'a}szl{\'o} Gy{\"o}rfi, Michael Kohler, Adam Krzyzak, and Harro Walk.
\newblock {\em A distribution-free theory of nonparametric regression}.
\newblock Springer Science \& Business Media, 2006.

\bibitem{johansson2007simple}
Bjorn Johansson, Maben Rabi, and Mikael Johansson.
\newblock A simple peer-to-peer algorithm for distributed optimization in
  sensor networks.
\newblock In {\em Decision and Control, 2007 46th IEEE Conference on}, pages
  4705--4710. IEEE, 2007.

\bibitem{johansson2009randomized}
Bj{\"o}rn Johansson, Maben Rabi, and Mikael Johansson.
\newblock A randomized incremental subgradient method for distributed
  optimization in networked systems.
\newblock {\em SIAM Journal on Optimization}, 20(3):1157--1170, 2009.

\bibitem{levin2017markov}
David~A Levin and Yuval Peres.
\newblock {\em Markov chains and mixing times}, volume 107.
\newblock American Mathematical Soc., 2017.

\bibitem{lian2017can}
Xiangru Lian, Ce~Zhang, Huan Zhang, Cho-Jui Hsieh, Wei Zhang, and Ji~Liu.
\newblock Can decentralized algorithms outperform centralized algorithms? a
  case study for decentralized parallel stochastic gradient descent.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  5330--5340, 2017.

\bibitem{lin2018optimal}
Junhong Lin and Volkan Cevher.
\newblock Optimal convergence for distributed learning with stochastic gradient
  methods and spectral-regularization algorithms.
\newblock {\em arXiv preprint arXiv:1801.07226}, 2018.

\bibitem{lin2017optimal}
Junhong Lin and Lorenzo Rosasco.
\newblock Optimal rates for multi-pass stochastic gradient methods.
\newblock {\em Journal of Machine Learning Research}, 18(97):1--47, 2017.

\bibitem{lin2017distributed}
Shao-Bo Lin, Xin Guo, and Ding-Xuan Zhou.
\newblock Distributed learning with regularized least squares.
\newblock {\em The Journal of Machine Learning Research}, 18(1):3202--3232,
  2017.

\bibitem{lobel2011distributed}
Ilan Lobel and Asuman Ozdaglar.
\newblock Distributed subgradient methods for convex optimization over random
  networks.
\newblock {\em IEEE Transactions on Automatic Control}, 56(6):1291--1306, 2011.

\bibitem{matei2011performance}
Ion Matei and John~S Baras.
\newblock Performance evaluation of the consensus-based distributed subgradient
  method under random communication topologies.
\newblock {\em IEEE Journal of Selected Topics in Signal Processing},
  5(4):754--771, 2011.

\bibitem{mokhtari2016dsa}
Aryan Mokhtari and Alejandro Ribeiro.
\newblock Dsa: Decentralized double stochastic averaging gradient algorithm.
\newblock {\em Journal of Machine Learning Research}, 17(61):1--35, 2016.

\bibitem{mucke2018parallelizing}
Nicole M{\"u}cke and Gilles Blanchard.
\newblock Parallelizing spectrally regularized kernel algorithms.
\newblock {\em The Journal of Machine Learning Research}, 19(1):1069--1097,
  2018.

\bibitem{Nedic2009}
Angelia Nedi{\'{c}}, Alex Olshevsky, Asuman Ozdaglar, and John~N. Tsitsiklis.
\newblock {On distributed averaging algorithms and quantization effects}.
\newblock {\em IEEE Transactions on Automatic Control}, 54(11):2506--2517,
  2009.

\bibitem{nedic2009distributed}
Angelia Nedic and Asuman Ozdaglar.
\newblock Distributed subgradient methods for multi-agent optimization.
\newblock {\em IEEE Transactions on Automatic Control}, 54(1):48--61, 2009.

\bibitem{pillaud2018statistical}
Loucas Pillaud-Vivien, Alessandro Rudi, and Francis Bach.
\newblock Statistical optimality of stochastic gradient descent on hard
  learning problems through multiple passes.
\newblock In {\em Advances in Neural Information Processing Systems 31}, pages
  8125--8135. 2018.

\bibitem{pinelis1986remarks}
IF~Pinelis and AI~Sakhanenko.
\newblock Remarks on inequalities for large deviation probabilities.
\newblock {\em Theory of Probability \& Its Applications}, 30(1):143--148,
  1986.

\bibitem{Rabbat15}
M.~{Rabbat}.
\newblock Multi-agent mirror descent for decentralized stochastic optimization.
\newblock In {\em 2015 IEEE 6th International Workshop on Computational
  Advances in Multi-Sensor Adaptive Processing (CAMSAP)}, pages 517--520, Dec
  2015.

\bibitem{2018arXiv180906958R}
D.~{Richards} and P.~{Rebeschini}.
\newblock {Graph-Dependent Implicit Regularisation for Distributed Stochastic
  Subgradient Descent}.
\newblock {\em ArXiv e-prints}, sep 2018.

\bibitem{robbins1985stochastic}
Herbert Robbins and Sutton Monro.
\newblock A stochastic approximation method.
\newblock In {\em Herbert Robbins Selected Papers}, pages 102--109. Springer,
  1985.

\bibitem{rosasco2015learning}
Lorenzo Rosasco and Silvia Villa.
\newblock Learning with incremental iterative regularization.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1630--1638, 2015.

\bibitem{sayed2014adaptive}
Ali~H. Sayed.
\newblock Adaptive networks.
\newblock {\em Proceedings of the IEEE}, 102(4):460--497, 2014.

\bibitem{scaman2017optimal}
Kevin Scaman, Francis Bach, S{\'e}bastien Bubeck, Yin~Tat Lee, and Laurent
  Massouli{\'e}.
\newblock Optimal algorithms for smooth and strongly convex distributed
  optimization in networks.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 3027--3036. JMLR. org, 2017.

\bibitem{scaman2018optimal}
Kevin Scaman, Francis Bach, S{\'e}bastien Bubeck, Laurent Massouli{\'e}, and
  Yin~Tat Lee.
\newblock Optimal algorithms for non-smooth distributed optimization in
  networks.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  2745--2754, 2018.

\bibitem{NET-014}
Devavrat Shah.
\newblock Gossip algorithms.
\newblock {\em Foundations and Trends{\textregistered} in Networking},
  3(1):1--125, 2009.

\bibitem{shamir2014fundamental}
Ohad Shamir.
\newblock Fundamental limits of online and distributed algorithms for
  statistical learning and estimation.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  163--171, 2014.

\bibitem{shamir2014distributed}
Ohad Shamir and Nathan Srebro.
\newblock Distributed stochastic optimization and learning.
\newblock In {\em Communication, Control, and Computing (Allerton), 2014 52nd
  Annual Allerton Conference on}, pages 850--857. IEEE, 2014.

\bibitem{shi2015extra}
Wei Shi, Qing Ling, Gang Wu, and Wotao Yin.
\newblock Extra: An exact first-order algorithm for decentralized consensus
  optimization.
\newblock {\em SIAM Journal on Optimization}, 25(2):944--966, 2015.

\bibitem{steinwart2008support}
Ingo Steinwart and Andreas Christmann.
\newblock {\em Support vector machines}.
\newblock Springer Science \& Business Media, 2008.

\bibitem{tarres2014online}
Pierre Tarres and Yuan Yao.
\newblock Online learning as stochastic approximation of regularization paths:
  Optimality and almost-sure convergence.
\newblock {\em IEEE Trans. Information Theory}, 60(9):5716--5735, 2014.

\bibitem{tsianos2012communication}
Konstantinos Tsianos, Sean Lawlor, and Michael~G Rabbat.
\newblock Communication/computation tradeoffs in consensus-based distributed
  optimization.
\newblock In {\em Advances in neural information processing systems}, pages
  1943--1951, 2012.

\bibitem{tsianos2016efficient}
Konstantinos~I Tsianos and Michael~G Rabbat.
\newblock Efficient distributed online prediction and stochastic optimization
  with approximate distributed averaging.
\newblock {\em IEEE Transactions on Signal and Information Processing over
  Networks}, 2(4):489--506, 2016.

\bibitem{tsitsiklis1986distributed}
John Tsitsiklis, Dimitri Bertsekas, and Michael Athans.
\newblock Distributed asynchronous deterministic and stochastic gradient
  optimization algorithms.
\newblock {\em IEEE transactions on automatic control}, 31(9):803--812, 1986.

\bibitem{tsitsiklis1984problems}
John~Nikolas Tsitsiklis.
\newblock Problems in decentralized decision making and computation.
\newblock Technical report, Massachusetts Inst Of Tech Cambridge Lab For
  Information And Decision Systems, 1984.

\bibitem{tsybakov2003optimal}
Alexandre~B Tsybakov.
\newblock Optimal rates of aggregation.
\newblock In {\em Learning Theory and Kernel Machines}, pages 303--313.
  Springer, 2003.

\bibitem{xiao2010dual}
Lin Xiao.
\newblock Dual averaging methods for regularized stochastic learning and online
  optimization.
\newblock {\em Journal of Machine Learning Research}, 11(Oct):2543--2596, 2010.

\bibitem{Xiao2004}
Lin Xiao and Stephen Boyd.
\newblock {Fast linear iterations for distributed averaging}.
\newblock {\em Systems and Control Letters}, 53(1):65--78, 2004.

\bibitem{yao2007early}
Yuan Yao, Lorenzo Rosasco, and Andrea Caponnetto.
\newblock On early stopping in gradient descent learning.
\newblock {\em Constructive Approximation}, 26(2):289--315, 2007.

\bibitem{ying2008online}
Yiming Ying and Massimiliano Pontil.
\newblock Online gradient descent learning algorithms.
\newblock {\em Foundations of Computational Mathematics}, 8(5):561--596, 2008.

\bibitem{zhang2005learning}
Tong Zhang.
\newblock Learning bounds for kernel regression using effective data
  dimensionality.
\newblock {\em Neural Computation}, 17(9):2077--2098, 2005.

\bibitem{zhang2015divide}
Yuchen Zhang, John Duchi, and Martin Wainwright.
\newblock Divide and conquer kernel ridge regression: A distributed algorithm
  with minimax optimal rates.
\newblock {\em The Journal of Machine Learning Research}, 16(1):3299--3340,
  2015.

\bibitem{zhang2015disco}
Yuchen Zhang and Xiao Lin.
\newblock Disco: Distributed optimization for self-concordant empirical loss.
\newblock In {\em International conference on machine learning}, pages
  362--370, 2015.

\bibitem{zhang2012communication}
Yuchen Zhang, Martin~J. Wainwright, and John~C. Duchi.
\newblock Communication-efficient algorithms for statistical optimization.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1502--1510, 2012.

\end{thebibliography}
