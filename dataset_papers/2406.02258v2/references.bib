@article{boshuizen1992moment,
  title={Moment-based minimax stopping functions for sequences of random variables},
  author={Boshuizen, Frans A and Hill, Theodore P},
  journal={Stochastic processes and their applications},
  volume={43},
  number={2},
  pages={303--316},
  year={1992},
  publisher={Elsevier}
}
@inproceedings{correa2017posted,
  title={Posted price mechanisms for a random stream of customers},
  author={Correa, Jos{\'e} and Foncea, Patricio and Hoeksma, Ruben and Oosterwijk, Tim and Vredeveld, Tjark},
  booktitle={Proceedings of the 2017 ACM Conference on Economics and Computation},
  pages={169--186},
  year={2017}
}

@inproceedings{correa2019prophet,
  title={Prophet inequalities for iid random variables from an unknown distribution},
  author={Correa, Jos{\'e} and D{\"u}tting, Paul and Fischer, Felix and Schewior, Kevin},
  booktitle={Proceedings of the 2019 ACM Conference on Economics and Computation},
  pages={3--17},
  year={2019}
}

@article{goldenshluger2022optimal,
  title={Optimal stopping of a random sequence with unknown distribution},
  author={Goldenshluger, Alexander and Zeevi, Assaf},
  journal={Mathematics of Operations Research},
  volume={47},
  number={1},
  pages={29--49},
  year={2022},
  publisher={INFORMS}
}

@article{qin2023minimization,
  title={Minimization Fractional Prophet Inequalities for Sequential Procurement},
  author={Qin, Junjie and Vardi, Shai and Wierman, Adam},
  journal={Mathematics of Operations Research},
  year={2023},
  publisher={INFORMS}
}

@article{ezra2022prophet,
  title={Prophet inequalities via the expected competitive ratio},
  author={Ezra, Tomer and Leonardi, Stefano and Reiffenhauser, Rebecca and Russo, Matteo and Tsigonias-Dimitriadis, Alexandros},
  journal={arXiv preprint arXiv:2207.03361},
  year={2022}
}

@article{jin2018q,
  title={Is Q-learning provably efficient?},
  author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@inproceedings{jia2023online,
  title={Online resource allocation in Markov Chains},
  author={Jia, Jianhao and Li, Hao and Liu, Kai and Liu, Ziqi and Zhou, Jun and Gravin, Nikolai and Tang, Zhihao Gavin},
  booktitle={Proceedings of the ACM Web Conference 2023},
  pages={3498--3507},
  year={2023}
}

@article{sabag2022optimal,
  title={Optimal competitive-ratio control},
  author={Sabag, Oron and Lale, Sahin and Hassibi, Babak},
  journal={arXiv preprint arXiv:2206.01782},
  year={2022}
}

@article{abdolhosseinzadeh2022lower,
  title={A lower bound competitive ratio for the online stochastic shortest path problem},
  author={Abdolhosseinzadeh, Mohsen},
  journal={International Journal of Operational Research},
  volume={43},
  number={1-2},
  pages={119--130},
  year={2022},
  publisher={Inderscience Publishers (IEL)}
}

@inproceedings{garg2013online,
  title={Online optimization with dynamic temporal uncertainty: Incorporating short term predictions for renewable integration in intelligent energy systems},
  author={Garg, Vikas and Jayram, TS and Narayanaswamy, Balakrishnan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={27},
  pages={1291--1297},
  year={2013}
}

@InProceedings{al2023active,
  title = 	 {Active Coverage for PAC Reinforcement Learning},
  author =       {Al-Marjani, Aymen and Tirinzoni, Andrea and Kaufmann, Emilie},
  booktitle = 	 {Proceedings of Thirty Sixth Conference on Learning Theory},
  pages = 	 {5044--5109},
  year = 	 {2023},
  volume = 	 {195},
  publisher =    {PMLR}
}


@article{tirinzoni2022near,
  title={Near instance-optimal pac reinforcement learning for deterministic mdps},
  author={Tirinzoni, Andrea and Al Marjani, Aymen and Kaufmann, Emilie},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={8785--8798},
  year={2022}
}

@article{dann2021beyond,
  title={Beyond value-function gaps: Improved instance-dependent regret bounds for episodic reinforcement learning},
  author={Dann, Christoph and Marinov, Teodor Vanislavov and Mohri, Mehryar and Zimmert, Julian},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={1--12},
  year={2021}
}

@inproceedings{xie2022role,
  title={The Role of Coverage in Online Reinforcement Learning},
  author={Xie, Tengyang and Foster, Dylan J and Bai, Yu and Jiang, Nan and Kakade, Sham M},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@book{altman2021constrained,
  title={Constrained Markov decision processes},
  author={Altman, Eitan},
  year={2021},
  publisher={Routledge}
}

@article{rashidinejad2021bridging,
  title={Bridging offline reinforcement learning and imitation learning: A tale of pessimism},
  author={Rashidinejad, Paria and Zhu, Banghua and Ma, Cong and Jiao, Jiantao and Russell, Stuart},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={11702--11716},
  year={2021}
}

@inproceedings{domingues2021episodic,
  title={Episodic reinforcement learning in finite mdps: Minimax lower bounds revisited},
  author={Domingues, Omar Darwiche and M{\'e}nard, Pierre and Kaufmann, Emilie and Valko, Michal},
  booktitle={Algorithmic Learning Theory},
  pages={578--598},
  year={2021},
  organization={PMLR}
}

@book{camacho2007model,
  title={Model predictive control},
  author={Camacho, Eduardo F and Bordons, Carlos and Camacho, Eduardo F and Bordons, Carlos},
  year={2007},
  publisher={Springer}
}

@article{efroni2020online,
  title={Online planning with lookahead policies},
  author={Efroni, Yonathan and Ghavamzadeh, Mohammad and Mannor, Shie},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={14024--14033},
  year={2020}
}

@inproceedings{efroni2019combine,
  title={How to combine tree-search methods in reinforcement learning},
  author={Efroni, Yonathan and Dalal, Gal and Scherrer, Bruno and Mannor, Shie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={3494--3501},
  year={2019}
}

@inproceedings{tamar2017learning,
  title={Learning from the hindsight planâ€”episodic mpc improvement},
  author={Tamar, Aviv and Thomas, Garrett and Zhang, Tianhao and Levine, Sergey and Abbeel, Pieter},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={336--343},
  year={2017},
  organization={IEEE}
}

@article{correa2019recent,
  title={Recent developments in prophet inequalities},
  author={Correa, Jose and Foncea, Patricio and Hoeksma, Ruben and Oosterwijk, Tim and Vredeveld, Tjark},
  journal={ACM SIGecom Exchanges},
  volume={17},
  number={1},
  pages={61--70},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@inproceedings{azar2017minimax,
  title={Minimax regret bounds for reinforcement learning},
  author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={263--272},
  year={2017},
  organization={PMLR}
}

@inproceedings{zanette2019tighter,
  title={Tighter problem-dependent regret bounds in reinforcement learning without domain knowledge using value function bounds},
  author={Zanette, Andrea and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={7304--7312},
  year={2019},
  organization={PMLR}
}

@inproceedings{efroni2019tight,
  title={Tight regret bounds for model-based reinforcement learning with greedy policies},
  author={Efroni, Yonathan and Merlis, Nadav and Ghavamzadeh, Mohammad and Mannor, Shie},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12224--12234},
  year={2019}
}

@inproceedings{simchowitz2019non,
  title={Non-asymptotic gap-dependent regret bounds for tabular mdps},
  author={Simchowitz, Max and Jamieson, Kevin G},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1153--1162},
  year={2019}
}

@inproceedings{zhang2021reinforcement,
  title={Is reinforcement learning more difficult than bandits? a near-optimal algorithm escaping the curse of horizon},
  author={Zhang, Zihan and Ji, Xiangyang and Du, Simon},
  booktitle={Conference on Learning Theory},
  pages={4528--4531},
  year={2021},
  organization={PMLR}
}

@inproceedings{dann2019policy,
  title={Policy certificates: Towards accountable reinforcement learning},
  author={Dann, Christoph and Li, Lihong and Wei, Wei and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={1507--1516},
  year={2019}
}

@article{jaksch2010near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Apr},
  pages={1563--1600},
  year={2010}
}

@article{hill1981ratio,
  title={Ratio comparisons of supremum and stop rule expectations},
  author={Hill, Theodore P and Kertz, Robert P},
  journal={Zeitschrift f{\"u}r Wahrscheinlichkeitstheorie und Verwandte Gebiete},
  volume={56},
  pages={283--285},
  year={1981},
  publisher={Springer}
}

@inproceedings{efroni2021reinforcement,
  title={Reinforcement learning with trajectory feedback},
  author={Efroni, Yonathan and Merlis, Nadav and Mannor, Shie},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  number={8},
  pages={7288--7295},
  year={2021}
}

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@inproceedings{efroni2021confidence,
  title={Confidence-budget matching for sequential budgeted learning},
  author={Efroni, Yonathan and Merlis, Nadav and Saha, Aadirupa and Mannor, Shie},
  booktitle={International Conference on Machine Learning},
  pages={2937--2947},
  year={2021},
  organization={PMLR}
}

@article{zhang2023settling,
  title={Settling the sample complexity of online reinforcement learning},
  author={Zhang, Zihan and Chen, Yuxin and Lee, Jason D and Du, Simon S},
  journal={arXiv preprint arXiv:2307.13586},
  year={2023}
}

@article{merlis2024value,
  title={The Value of Reward Lookahead in Reinforcement Learning},
  author={Merlis, Nadav and Baudry, Dorian and Perchet, Vianney},
  journal={arXiv preprint arXiv:2403.11637},
  year={2024}
}

@inproceedings{maurer2009empirical,
  title={Empirical bernstein bounds and sample variance penalization},
  author={Maurer, Andreas and Pontil, Massimiliano},
    booktitle={Conference on learning theory},
  year={2009}
}

@inproceedings{gatmiry2024bandit,
  title={Bandit Algorithms for Prophet Inequality and Pandora's Box},
  author={Gatmiry, Khashayar and Kesselheim, Thomas and Singla, Sahil and Wang, Yifan},
  booktitle={Proceedings of the 2024 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)},
  pages={462--500},
  year={2024},
  organization={SIAM}
}

@article{agarwal2023semi,
  title={Semi-Bandit Learning for Monotone Stochastic Optimization},
  author={Agarwal, Arpit and Ghuge, Rohan and Nagarajan, Viswanath},
  journal={arXiv preprint arXiv:2312.15427},
  year={2023}
}

@article{fournier2015rate,
  title={On the rate of convergence in Wasserstein distance of the empirical measure},
  author={Fournier, Nicolas and Guillin, Arnaud},
  journal={Probability theory and related fields},
  volume={162},
  number={3},
  pages={707--738},
  year={2015},
  publisher={Springer}
}

@inproceedings{boutilier2018planning,
  title={Planning and learning with stochastic action sets},
  author={Boutilier, Craig and Cohen, Alon and Hassidim, Avinatan and Mansour, Yishay and Meshi, Ofer and Mladenov, Martin and Schuurmans, Dale},
  booktitle={Proceedings of the 27th International Joint Conference on Artificial Intelligence},
  pages={4674--4682},
  year={2018}
}

@inproceedings{nikolova2008route,
  title={Route planning under uncertainty: The Canadian traveller problem.},
  author={Nikolova, Evdokia and Karger, David R},
  booktitle={AAAI},
  pages={969--974},
  year={2008}
}

@inproceedings{el2020lookahead,
  title={Lookahead-bounded q-learning},
  author={El Shar, Ibrahim and Jiang, Daniel},
  booktitle={International Conference on Machine Learning},
  pages={8665--8675},
  year={2020},
  organization={PMLR}
}

@article{yu2020power,
  title={The power of predictions in online control},
  author={Yu, Chenkai and Shi, Guanya and Chung, Soon-Jo and Yue, Yisong and Wierman, Adam},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1994--2004},
  year={2020}
}

@article{lin2021perturbation,
  title={Perturbation-based regret analysis of predictive control in linear time varying systems},
  author={Lin, Yiheng and Hu, Yang and Shi, Guanya and Sun, Haoyuan and Qu, Guannan and Wierman, Adam},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={5174--5185},
  year={2021}
}

@inproceedings{zhang2021regret,
  title={On the regret analysis of online LQR control with predictions},
  author={Zhang, Runyu and Li, Yingying and Li, Na},
  booktitle={2021 American Control Conference (ACC)},
  pages={697--703},
  year={2021},
  organization={IEEE}
}

@article{lin2022bounded,
  title={Bounded-regret mpc via perturbation analysis: Prediction error, constraints, and nonlinearity},
  author={Lin, Yiheng and Hu, Yang and Qu, Guannan and Li, Tongxin and Wierman, Adam},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={36174--36187},
  year={2022}
}

@article{li2019online,
  title={Online optimal control with linear dynamics and predictions: Algorithms and regret analysis},
  author={Li, Yingying and Chen, Xin and Li, Na},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{rosenberg2023planning,
  title={Planning and learning with adaptive lookahead},
  author={Rosenberg, Aviv and Hallak, Assaf and Mannor, Shie and Chechik, Gal and Dalal, Gal},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  pages={9606--9613},
  year={2023}
}

@inproceedings{moerland2020think,
  title={Think Neither Too Fast Nor Too Slow: The Computational Trade-off Between Planning And Reinforcement Learning},
  author={Moerland, Thomas M and Deichler, Anna and Baldi, Simone and Broekens, Joost and Jonker, Catholijn M},
  booktitle={Proceedings of the International Conference on Automated Planning and Scheduling (ICAPS), Nancy, France},
  pages={16--20},
  year={2020}
}

@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on learning theory},
  pages={2137--2143},
  year={2020},
  organization={PMLR}
}

@article{bubeck2012regret,
  title={Regret analysis of stochastic and nonstochastic multi-armed bandit problems},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={5},
  number={1},
  pages={1--122},
  year={2012},
  publisher={Now Publishers, Inc.}
}

@article{auer2002nonstochastic,
  title={The nonstochastic multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Freund, Yoav and Schapire, Robert E},
  journal={SIAM journal on computing},
  volume={32},
  number={1},
  pages={48--77},
  year={2002},
  publisher={SIAM}
}

@book{bertsekas2023course,
  title={A course in reinforcement learning},
  author={Bertsekas, Dimitri},
  year={2023},
  publisher={Athena Scientific}
}

@inproceedings{biedenkapp2021temporl,
  title={TempoRL: Learning when to act},
  author={Biedenkapp, Andr{\'e} and Rajan, Raghu and Hutter, Frank and Lindauer, Marius},
  booktitle={International Conference on Machine Learning},
  pages={914--924},
  year={2021},
  organization={PMLR}
}

@inproceedings{huang2019continuous,
  title={Continuous-time markov decision processes with controlled observations},
  author={Huang, Yunhan and Kavitha, Veeraruna and Zhu, Quanyan},
  booktitle={2019 57th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  pages={32--39},
  year={2019},
  organization={IEEE}
}


@article{chung2024thinker,
  title={Thinker: learning to plan and act},
  author={Chung, Stephen and Anokhin, Ivan and Krueger, David},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{schrittwieser2020mastering,
  title={Mastering atari, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={Nature},
  volume={588},
  number={7839},
  pages={604--609},
  year={2020},
  publisher={Nature Publishing Group}
}