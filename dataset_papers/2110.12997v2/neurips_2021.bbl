\begin{thebibliography}{55}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Allevato et~al.(2019)Allevato, Short, Pryor, and
  Thomaz]{allevato2019tunenet}
Adam Allevato, Elaine~Schaertl Short, Mitch Pryor, and Andrea Thomaz.
\newblock Tunenet: One-shot residual tuning for system identification and
  sim-to-real robot task transfer.
\newblock In Leslie~Pack Kaelbling, Danica Kragic, and Komei Sugiura, editors,
  \emph{3rd Annual Conference on Robot Learning, CoRL 2019, Osaka, Japan,
  October 30 - November 1, 2019, Proceedings}, volume 100 of \emph{Proceedings
  of Machine Learning Research}, pages 445--455. {PMLR}, 2019.
\newblock URL \url{http://proceedings.mlr.press/v100/allevato20a.html}.

\bibitem[Anand et~al.(2019)Anand, Racah, Ozair, Bengio, C{\^o}t{\'e}, and
  Hjelm]{anand2019unsupervised}
Ankesh Anand, Evan Racah, Sherjil Ozair, Yoshua Bengio, Marc-Alexandre
  C{\^o}t{\'e}, and R~Devon Hjelm.
\newblock Unsupervised state representation learning in atari.
\newblock \emph{arXiv preprint arXiv:1906.08226}, 2019.

\bibitem[Beaudry and Renner(2012)]{beaudry2012intuitive}
Normand~J. Beaudry and Renato Renner.
\newblock An intuitive proof of the data processing inequality, 2012.

\bibitem[Berseth et~al.(2019)Berseth, Geng, Devin, Finn, Jayaraman, and
  Levine]{berseth2019smirl}
Glen Berseth, Daniel Geng, Coline Devin, Chelsea Finn, Dinesh Jayaraman, and
  Sergey Levine.
\newblock Smirl: Surprise minimizing {RL} in dynamic environments.
\newblock \emph{CoRR}, abs/1912.05510, 2019.
\newblock URL \url{http://arxiv.org/abs/1912.05510}.

\bibitem[Brockman et~al.(2016)Brockman, Cheung, Pettersson, Schneider,
  Schulman, Tang, and Zaremba]{brockman2016openai}
Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman,
  Jie Tang, and Wojciech Zaremba.
\newblock Openai gym, 2016.

\bibitem[Campos et~al.(2020)Campos, Trott, Xiong, Socher,
  Gir{\'{o}}{-}i{-}Nieto, and Torres]{campos2020explore}
Victor Campos, Alexander Trott, Caiming Xiong, Richard Socher, Xavier
  Gir{\'{o}}{-}i{-}Nieto, and Jordi Torres.
\newblock Explore, discover and learn: Unsupervised discovery of state-covering
  skills.
\newblock 119:\penalty0 1317--1327, 2020.
\newblock URL \url{http://proceedings.mlr.press/v119/campos20a.html}.

\bibitem[Chebotar et~al.(2019)Chebotar, Handa, Makoviychuk, Macklin, Issac,
  Ratliff, and Fox]{chebotar2019closing}
Yevgen Chebotar, Ankur Handa, Viktor Makoviychuk, Miles Macklin, Jan Issac,
  Nathan~D. Ratliff, and Dieter Fox.
\newblock Closing the sim-to-real loop: Adapting simulation randomization with
  real world experience.
\newblock In \emph{International Conference on Robotics and Automation, {ICRA}
  2019, Montreal, QC, Canada, May 20-24, 2019}, pages 8973--8979. {IEEE}, 2019.
\newblock \doi{10.1109/ICRA.2019.8793789}.
\newblock URL \url{https://doi.org/10.1109/ICRA.2019.8793789}.

\bibitem[Colas et~al.(2020)Colas, Karch, Sigaud, and
  Oudeyer]{colas2020intrinsically}
C{\'{e}}dric Colas, Tristan Karch, Olivier Sigaud, and Pierre{-}Yves Oudeyer.
\newblock Intrinsically motivated goal-conditioned reinforcement learning: a
  short survey.
\newblock \emph{CoRR}, abs/2012.09830, 2020.
\newblock URL \url{https://arxiv.org/abs/2012.09830}.

\bibitem[Desai et~al.(2020)Desai, Durugkar, Karnan, Warnell, Hanna, and
  Stone]{desai2020imitation}
Siddharth Desai, Ishan Durugkar, Haresh Karnan, Garrett Warnell, Josiah Hanna,
  and Peter Stone.
\newblock An imitation from observation approach to transfer learning with
  dynamics mismatch.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Eysenbach et~al.(2018)Eysenbach, Gupta, Ibarz, and
  Levine]{eysenbach2018diversity}
Benjamin Eysenbach, Abhishek Gupta, Julian Ibarz, and Sergey Levine.
\newblock Diversity is all you need: Learning skills without a reward function.
\newblock \emph{arXiv preprint arXiv:1802.06070}, 2018.

\bibitem[Eysenbach et~al.(2020)Eysenbach, Asawa, Chaudhari, Salakhutdinov, and
  Levine]{eysenbach2020off}
Benjamin Eysenbach, Swapnil Asawa, Shreyas Chaudhari, Ruslan Salakhutdinov, and
  Sergey Levine.
\newblock Off-dynamics reinforcement learning: Training for transfer with
  domain classifiers.
\newblock \emph{arXiv preprint arXiv:2006.13916}, 2020.

\bibitem[Farchy et~al.(2013)Farchy, Barrett, MacAlpine, and
  Stone]{farchy2013humanoid}
Alon Farchy, Samuel Barrett, Patrick MacAlpine, and Peter Stone.
\newblock Humanoid robots learning to walk faster: From the real world to
  simulation and back.
\newblock In \emph{Proceedings of the 2013 international conference on
  Autonomous agents and multi-agent systems}, pages 39--46, 2013.

\bibitem[Galashov et~al.(2019)Galashov, Jayakumar, Hasenclever, Tirumala,
  Schwarz, Desjardins, Czarnecki, Teh, Pascanu, and
  Heess]{galashov2019information}
Alexandre Galashov, Siddhant~M. Jayakumar, Leonard Hasenclever, Dhruva
  Tirumala, Jonathan Schwarz, Guillaume Desjardins, Wojciech~M. Czarnecki,
  Yee~Whye Teh, Razvan Pascanu, and Nicolas Heess.
\newblock Information asymmetry in kl-regularized rl, 2019.

\bibitem[Gangwani and Peng(2020)]{Gangwani2020StateonlyIW}
Tanmay Gangwani and J.~Peng.
\newblock State-only imitation with transition dynamics mismatch.
\newblock \emph{ArXiv}, abs/2002.11879, 2020.

\bibitem[Ghosh et~al.(2018)Ghosh, Singh, Rajeswaran, Kumar, and
  Levine]{ghosh2018divideandconquer}
Dibya Ghosh, Avi Singh, Aravind Rajeswaran, Vikash Kumar, and Sergey Levine.
\newblock Divide-and-conquer reinforcement learning, 2018.

\bibitem[Goyal et~al.(2019)Goyal, Islam, Strouse, Ahmed, Botvinick, Larochelle,
  Bengio, and Levine]{goyal2019infobot}
Anirudh Goyal, Riashat Islam, Daniel Strouse, Zafarali Ahmed, Matthew
  Botvinick, Hugo Larochelle, Yoshua Bengio, and Sergey Levine.
\newblock Infobot: Transfer and exploration via the information bottleneck,
  2019.

\bibitem[Goyal et~al.(2020)Goyal, Sodhani, Binas, Peng, Levine, and
  Bengio]{Goyal2020Reinforcement}
Anirudh Goyal, Shagun Sodhani, Jonathan Binas, Xue~Bin Peng, Sergey Levine, and
  Yoshua Bengio.
\newblock Reinforcement learning with competitive ensembles of
  information-constrained primitives.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=ryxgJTEYDr}.

\bibitem[Guo et~al.(2020)Guo, Pires, Piot, Grill, Altch{\'{e}}, Munos, and
  Azar]{guo2020bootstrap}
Zhaohan~Daniel Guo, Bernardo~{\'{A}}vila Pires, Bilal Piot, Jean{-}Bastien
  Grill, Florent Altch{\'{e}}, R{\'{e}}mi Munos, and Mohammad~Gheshlaghi Azar.
\newblock Bootstrap latent-predictive representations for multitask
  reinforcement learning.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning, {ICML} 2020, 13-18 July 2020, Virtual Event}, volume 119 of
  \emph{Proceedings of Machine Learning Research}, pages 3875--3886. {PMLR},
  2020.
\newblock URL \url{http://proceedings.mlr.press/v119/guo20g.html}.

\bibitem[Haarnoja et~al.(2018)Haarnoja, Zhou, Abbeel, and
  Levine]{haarnoja2018soft}
Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock \emph{arXiv preprint arXiv:1801.01290}, 2018.

\bibitem[Hafner et~al.(2020)Hafner, Ortega, Ba, Parr, Friston, and
  Heess]{hafner2020action}
Danijar Hafner, Pedro~A. Ortega, Jimmy Ba, Thomas Parr, Karl~J. Friston, and
  Nicolas Heess.
\newblock Action and perception as divergence minimization.
\newblock \emph{CoRR}, abs/2009.01791, 2020.
\newblock URL \url{https://arxiv.org/abs/2009.01791}.

\bibitem[Hartikainen et~al.(2019)Hartikainen, Geng, Haarnoja, and
  Levine]{hartikainen2019dynamical}
Kristian Hartikainen, Xinyang Geng, Tuomas Haarnoja, and Sergey Levine.
\newblock Dynamical distance learning for semi-supervised and unsupervised
  skill discovery.
\newblock \emph{arXiv preprint arXiv:1907.08225}, 2019.

\bibitem[Hasenclever et~al.(2020)Hasenclever, Pardo, Hadsell, Heess, and
  Merel]{DBLP:conf/icml/HasencleverPHHM20}
Leonard Hasenclever, Fabio Pardo, Raia Hadsell, Nicolas Heess, and Josh Merel.
\newblock Comic: Complementary task learning {\&} mimicry for reusable skills.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning, {ICML} 2020, 13-18 July 2020, Virtual Event}, volume 119 of
  \emph{Proceedings of Machine Learning Research}, pages 4105--4115. {PMLR},
  2020.
\newblock URL \url{http://proceedings.mlr.press/v119/hasenclever20a.html}.

\bibitem[Higgins et~al.(2017)Higgins, Pal, Rusu, Matthey, Burgess, Pritzel,
  Botvinick, Blundell, and Lerchner]{higgins2017darla}
Irina Higgins, Arka Pal, Andrei Rusu, Loic Matthey, Christopher Burgess,
  Alexander Pritzel, Matthew Botvinick, Charles Blundell, and Alexander
  Lerchner.
\newblock Darla: Improving zero-shot transfer in reinforcement learning.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 1480--1490. JMLR. org, 2017.

\bibitem[Jabri et~al.(2019)Jabri, Hsu, Gupta, Eysenbach, Levine, and
  Finn]{jabri2019unsupervised}
Allan Jabri, Kyle Hsu, Abhishek Gupta, Ben Eysenbach, Sergey Levine, and
  Chelsea Finn.
\newblock Unsupervised curricula for visual meta-reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  10519--10531, 2019.

\bibitem[Kim et~al.(2020)Kim, Gu, Song, Zhao, and Ermon]{Kim2020DomainAI}
Kuno Kim, Yihong Gu, Jiaming Song, Shengjia Zhao, and S.~Ermon.
\newblock Domain adaptive imitation learning.
\newblock In \emph{ICML}, 2020.

\bibitem[Kingma and Welling(2013)]{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Kovač et~al.(2020)Kovač, Laversanne-Finot, and
  Oudeyer]{Kova2020GRIMGEPLP}
G.~Kovač, A.~Laversanne-Finot, and Pierre-Yves Oudeyer.
\newblock Grimgep: Learning progress for robust goal sampling in visual deep
  reinforcement learning.
\newblock \emph{arXiv: Learning}, 2020.

\bibitem[Lee et~al.(2020)Lee, Eysenbach, Parisotto, Xing, Levine, and
  Salakhutdinov]{lee2020efficient}
Lisa Lee, Benjamin Eysenbach, Emilio Parisotto, Eric Xing, Sergey Levine, and
  Ruslan Salakhutdinov.
\newblock Efficient exploration via state marginal matching, 2020.

\bibitem[Levine(2018)]{levine2018reinforcement}
Sergey Levine.
\newblock Reinforcement learning and control as probabilistic inference:
  Tutorial and review, 2018.
\newblock URL \url{http://arxiv.org/abs/1805.00909}.

\bibitem[Liu et~al.(2019)Liu, Ling, Mu, and Su]{liu2019state}
Fangchen Liu, Zhan Ling, Tongzhou Mu, and Hao Su.
\newblock State alignment-based imitation learning.
\newblock \emph{arXiv preprint arXiv:1911.10947}, 2019.

\bibitem[Liu et~al.(2021)Liu, Wang, Tian, and Chen]{liu2021learn}
Jinxin Liu, Donglin Wang, Qiangxing Tian, and Zhengyu Chen.
\newblock Learn goal-conditioned policy with intrinsic motivation for deep
  reinforcement learning, 2021.
\newblock URL \url{https://openreview.net/forum?id=MmcywoW7PbJ}.

\bibitem[Nair et~al.(2020)Nair, Bahl, Khazatsky, Pong, Berseth, and
  Levine]{nair2020contextual}
Ashvin Nair, Shikhar Bahl, Alexander Khazatsky, Vitchyr Pong, Glen Berseth, and
  Sergey Levine.
\newblock Contextual imagined goals for self-supervised robotic learning.
\newblock In \emph{Conference on Robot Learning}, pages 530--539. PMLR, 2020.

\bibitem[Nair et~al.(2018)Nair, Pong, Dalal, Bahl, Lin, and
  Levine]{nair2018visual}
Ashvin~V Nair, Vitchyr Pong, Murtaza Dalal, Shikhar Bahl, Steven Lin, and
  Sergey Levine.
\newblock Visual reinforcement learning with imagined goals.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  9191--9200, 2018.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Peng et~al.(2018)Peng, Andrychowicz, Zaremba, and Abbeel]{Peng_2018}
Xue~Bin Peng, Marcin Andrychowicz, Wojciech Zaremba, and Pieter Abbeel.
\newblock Sim-to-real transfer of robotic control with dynamics randomization.
\newblock \emph{2018 IEEE International Conference on Robotics and Automation
  (ICRA)}, May 2018.
\newblock \doi{10.1109/icra.2018.8460528}.
\newblock URL \url{http://dx.doi.org/10.1109/ICRA.2018.8460528}.

\bibitem[Petangoda et~al.(2019)Petangoda, Pascual{-}Diaz, Adam, Vrancx, and
  Grau{-}Moya]{petangoda2019disentangled}
Janith~C. Petangoda, Sergio Pascual{-}Diaz, Vincent Adam, Peter Vrancx, and
  Jordi Grau{-}Moya.
\newblock Disentangled skill embeddings for reinforcement learning.
\newblock \emph{CoRR}, abs/1906.09223, 2019.
\newblock URL \url{http://arxiv.org/abs/1906.09223}.

\bibitem[Pong et~al.(2020)Pong, Dalal, Lin, Nair, Bahl, and
  Levine]{pong2020skewfit}
Vitchyr~H. Pong, Murtaza Dalal, Steven Lin, Ashvin Nair, Shikhar Bahl, and
  Sergey Levine.
\newblock Skew-fit: State-covering self-supervised reinforcement learning,
  2020.

\bibitem[Schaul et~al.(2015)Schaul, Horgan, Gregor, and
  Silver]{schaul2015universal}
Tom Schaul, Daniel Horgan, Karol Gregor, and David Silver.
\newblock Universal value function approximators.
\newblock In \emph{International conference on machine learning}, pages
  1312--1320, 2015.

\bibitem[Schroff et~al.(2015)Schroff, Kalenichenko, and
  Philbin]{schroff2015facenet}
Florian Schroff, Dmitry Kalenichenko, and James Philbin.
\newblock Facenet: A unified embedding for face recognition and clustering.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 815--823, 2015.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{schulman2017proximal}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Schwarzer et~al.(2021)Schwarzer, Anand, Goel, Hjelm, Courville, and
  Bachman]{Schwarzer2021DATAEFFICIENTRL}
Max Schwarzer, Ankesh Anand, Rishab Goel, R.~Devon Hjelm, Aaron~C. Courville,
  and Philip Bachman.
\newblock Data-efficient reinforcement learning with self-predictive
  representations.
\newblock 2021.

\bibitem[Sermanet et~al.(2018)Sermanet, Lynch, Chebotar, Hsu, Jang, Schaal,
  Levine, and Brain]{sermanet2018time}
Pierre Sermanet, Corey Lynch, Yevgen Chebotar, Jasmine Hsu, Eric Jang, Stefan
  Schaal, Sergey Levine, and Google Brain.
\newblock Time-contrastive networks: Self-supervised learning from video.
\newblock In \emph{2018 IEEE International Conference on Robotics and
  Automation (ICRA)}, pages 1134--1141. IEEE, 2018.

\bibitem[Sharma et~al.(2020)Sharma, Gu, Levine, Kumar, and
  Hausman]{sharma2019dynamics}
Archit Sharma, Shixiang Gu, Sergey Levine, Vikash Kumar, and Karol Hausman.
\newblock Dynamics-aware unsupervised discovery of skills.
\newblock 2020.
\newblock URL \url{https://openreview.net/forum?id=HJgLZR4KvH}.

\bibitem[Singh et~al.(2019)Singh, Yang, Finn, and Levine]{singh2019end}
Avi Singh, Larry Yang, Chelsea Finn, and Sergey Levine.
\newblock End-to-end robotic reinforcement learning without reward engineering.
\newblock In Antonio Bicchi, Hadas Kress{-}Gazit, and Seth Hutchinson, editors,
  \emph{Robotics: Science and Systems XV, University of Freiburg, Freiburg im
  Breisgau, Germany, June 22-26, 2019}, 2019.
\newblock \doi{10.15607/RSS.2019.XV.073}.
\newblock URL \url{https://doi.org/10.15607/RSS.2019.XV.073}.

\bibitem[Strouse et~al.(2018)Strouse, Kleiman{-}Weiner, Tenenbaum, Botvinick,
  and Schwab]{strouse2019learning}
Daniel Strouse, Max Kleiman{-}Weiner, Josh Tenenbaum, Matthew Botvinick, and
  David~J. Schwab.
\newblock Learning to share and hide intentions using information
  regularization, 2018.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2018/hash/1ef03ed0cd5863c550128836b28ec3e9-Abstract.html}.

\bibitem[Teh et~al.(2017)Teh, Bapst, Czarnecki, Quan, Kirkpatrick, Hadsell,
  Heess, and Pascanu]{teh2017distral}
Yee~Whye Teh, Victor Bapst, Wojciech~M. Czarnecki, John Quan, James
  Kirkpatrick, Raia Hadsell, Nicolas Heess, and Razvan Pascanu.
\newblock Distral: Robust multitask reinforcement learning, 2017.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2017/hash/0abdc563a06105aee3c6136871c9f4d1-Abstract.html}.

\bibitem[Tian et~al.(2020{\natexlab{a}})Tian, Wang, Liu, Wang, and
  Kang]{tian2020independent}
Qiangxing Tian, Guanchu Wang, Jinxin Liu, Donglin Wang, and Yachen Kang.
\newblock Independent skill transfer for deep reinforcement learning.
\newblock In \emph{IJCAI}, pages 2901--2907, 2020{\natexlab{a}}.

\bibitem[Tian et~al.(2021)Tian, Liu, Wang, and Wang]{tian2021unsupervised}
Qiangxing Tian, Jinxin Liu, Guanchu Wang, and Donglin Wang.
\newblock Unsupervised discovery of transitional skills for deep reinforcement
  learning.
\newblock In \emph{2021 International Joint Conference on Neural Networks
  (IJCNN)}, pages 1--8. IEEE, 2021.

\bibitem[Tian et~al.(2020{\natexlab{b}})Tian, Nair, Ebert, Dasari, Eysenbach,
  Finn, and Levine]{tian2020model}
Stephen Tian, Suraj Nair, Frederik Ebert, Sudeep Dasari, Benjamin Eysenbach,
  Chelsea Finn, and Sergey Levine.
\newblock Model-based visual planning with self-supervised functional
  distances.
\newblock \emph{CoRR}, abs/2012.15373, 2020{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2012.15373}.

\bibitem[Tobin et~al.(2017)Tobin, Fong, Ray, Schneider, Zaremba, and
  Abbeel]{tobin2017domain}
Josh Tobin, Rachel Fong, Alex Ray, Jonas Schneider, Wojciech Zaremba, and
  Pieter Abbeel.
\newblock Domain randomization for transferring deep neural networks from
  simulation to the real world, 2017.

\bibitem[Venkattaramanujam et~al.(2019)Venkattaramanujam, Crawford, Doan, and
  Precup]{venkattaramanujam2019self}
Srinivas Venkattaramanujam, Eric Crawford, Thang Doan, and Doina Precup.
\newblock Self-supervised learning of distance functions for goal-conditioned
  reinforcement learning.
\newblock \emph{CoRR}, abs/1907.02998, 2019.
\newblock URL \url{http://arxiv.org/abs/1907.02998}.

\bibitem[Viano et~al.(2020)Viano, Huang, Kamalaruban, and
  Cevher]{Viano2020RobustIR}
Luca Viano, Y.~Huang, P.~Kamalaruban, and V.~Cevher.
\newblock Robust inverse reinforcement learning under transition dynamics
  mismatch.
\newblock \emph{ArXiv}, abs/2007.01174, 2020.

\bibitem[Warde-Farley et~al.(2018)Warde-Farley, de~Wiele, Kulkarni, Ionescu,
  Hansen, and Mnih]{wardefarley2018unsupervised}
David Warde-Farley, Tom~Van de~Wiele, Tejas Kulkarni, Catalin Ionescu, Steven
  Hansen, and Volodymyr Mnih.
\newblock Unsupervised control through non-parametric discriminative rewards,
  2018.

\bibitem[Wulfmeier et~al.(2017)Wulfmeier, Posner, and
  Abbeel]{wulfmeier2017mutual}
Markus Wulfmeier, Ingmar Posner, and Pieter Abbeel.
\newblock Mutual alignment transfer learning.
\newblock In \emph{Conference on Robot Learning}, pages 281--290. PMLR, 2017.

\bibitem[Zhao et~al.(2020)Zhao, Queralta, and Westerlund]{zhao2020transfer}
Wenshuai Zhao, Jorge~Pe{\~{n}}a Queralta, and Tomi Westerlund.
\newblock Sim-to-real transfer in deep reinforcement learning for robotics: a
  survey.
\newblock In \emph{2020 {IEEE} Symposium Series on Computational Intelligence,
  {SSCI} 2020, Canberra, Australia, December 1-4, 2020}, pages 737--744.
  {IEEE}, 2020.
\newblock \doi{10.1109/SSCI47803.2020.9308468}.
\newblock URL \url{https://doi.org/10.1109/SSCI47803.2020.9308468}.

\end{thebibliography}
