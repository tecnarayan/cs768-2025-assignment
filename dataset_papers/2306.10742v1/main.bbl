\begin{thebibliography}{36}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Benussi et~al.(2022)Benussi, Patanè, Wicker, Laurenti, and
  Kwiatkowska]{benussi2022individual}
Benussi, E., Patanè, A., Wicker, M., Laurenti, L., and Kwiatkowska, M.
\newblock Individual fairness guarantees for neural networks.
\newblock In \emph{Proceedings of the Thirty-First International Joint
  Conference on Artificial Intelligence, {IJCAI-22}}, pp.\  651--658.
  International Joint Conferences on Artificial Intelligence Organization,
  2022.
\newblock \doi{10.24963/ijcai.2022/92}.

\bibitem[Berrada et~al.(2021)Berrada, Dathathri, Dvijotham, Stanforth, Bunel,
  Uesato, Gowal, and Kumar]{berrada2021make}
Berrada, L., Dathathri, S., Dvijotham, K., Stanforth, R., Bunel, R.~R., Uesato,
  J., Gowal, S., and Kumar, M.~P.
\newblock Make sure you're unsure: A framework for verifying probabilistic
  specifications.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 11136--11147, 2021.

\bibitem[Biggio \& Roli(2018)Biggio and Roli]{biggio2018wild}
Biggio, B. and Roli, F.
\newblock Wild patterns: Ten years after the rise of adversarial machine
  learning.
\newblock \emph{Pattern Recognition}, 84:\penalty0 317--331, 2018.

\bibitem[Blundell et~al.(2015)Blundell, Cornebise, Kavukcuoglu, and
  Wierstra]{blundell2015weight}
Blundell, C., Cornebise, J., Kavukcuoglu, K., and Wierstra, D.
\newblock Weight uncertainty in neural network.
\newblock pp.\  1613--1622, 2015.

\bibitem[Bunel et~al.(2020)Bunel, De~Palma, Desmaison, Dvijotham, Kohli, Torr,
  and Kumar]{bunel2020lagrangian}
Bunel, R., De~Palma, A., Desmaison, A., Dvijotham, K., Kohli, P., Torr, P., and
  Kumar, M.~P.
\newblock Lagrangian decomposition for neural network verification.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence}, pp.\
  370--379. PMLR, 2020.

\bibitem[Carbone et~al.(2020)Carbone, Wicker, Laurenti, Patanè, Bortolussi,
  and Sanguinetti]{carbone2020robustness}
Carbone, G., Wicker, M., Laurenti, L., Patanè, A., Bortolussi, L., and
  Sanguinetti, G.
\newblock Robustness of bayesian neural networks to gradient-based attacks.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 15602--15613, 2020.

\bibitem[Cardelli et~al.(2019{\natexlab{a}})Cardelli, Kwiatkowska, Laurenti,
  Paoletti, Patanè, and Wicker]{cardelli2019statistical}
Cardelli, L., Kwiatkowska, M., Laurenti, L., Paoletti, N., Patanè, A., and
  Wicker, M.
\newblock Statistical guarantees for the robustness of {B}ayesian neural
  networks.
\newblock In \emph{Proceedings of the 28th International Joint Conference on
  Artificial Intelligence}, pp.\  5693--5700. AAAI Press, 2019{\natexlab{a}}.

\bibitem[Cardelli et~al.(2019{\natexlab{b}})Cardelli, Kwiatkowska, Laurenti,
  and Patanè]{cardelli2018robustness}
Cardelli, L., Kwiatkowska, M., Laurenti, L., and Patanè, A.
\newblock Robustness guarantees for {B}ayesian inference with {G}aussian
  processes.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pp.\  7759--7768, 2019{\natexlab{b}}.

\bibitem[Frankle \& Carbin(2018)Frankle and Carbin]{frankle2018lottery}
Frankle, J. and Carbin, M.
\newblock The lottery ticket hypothesis: Finding sparse, trainable neural
  networks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Gal \& Ghahramani(2016)Gal and Ghahramani]{gal2016dropout}
Gal, Y. and Ghahramani, Z.
\newblock Dropout as a bayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In \emph{international conference on machine learning}, pp.\
  1050--1059. PMLR, 2016.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{International Conference on Learning Representations (ICLR)},
  2015.

\bibitem[Harva et~al.(2004)]{harva2004hierarchical}
Harva, M. et~al.
\newblock \emph{Hierarchical variance models of image sequences}.
\newblock PhD thesis, Master’s thesis, Helsinki University of Technology,
  Espoo, 2004.

\bibitem[Hern{\'a}ndez-Lobato \& Adams(2015)Hern{\'a}ndez-Lobato and
  Adams]{hernandez2015probabilistic}
Hern{\'a}ndez-Lobato, J.~M. and Adams, R.
\newblock Probabilistic backpropagation for scalable learning of bayesian
  neural networks.
\newblock In \emph{International conference on machine learning}, pp.\
  1861--1869. PMLR, 2015.

\bibitem[Kahn et~al.(2017)Kahn, Villaflor, Pong, Abbeel, and Levine]{kahn17}
Kahn, G., Villaflor, A., Pong, V., Abbeel, P., and Levine, S.
\newblock Uncertainty-aware reinforcement learning for collision avoidance.
\newblock \emph{arXiv preprint arXiv:1702.01182}, 2017.

\bibitem[Katz et~al.(2017)Katz, Barrett, Dill, Julian, and
  Kochenderfer]{katz2017reluplex}
Katz, G., Barrett, C., Dill, D.~L., Julian, K., and Kochenderfer, M.~J.
\newblock Reluplex: An efficient {SMT} solver for verifying deep neural
  networks.
\newblock In \emph{International Conference on Computer Aided Verification},
  pp.\  97--117. Springer, 2017.

\bibitem[Khan et~al.(2018)Khan, Nielsen, Tangkaratt, Lin, Gal, and
  Srivastava]{khan2018fast}
Khan, M., Nielsen, D., Tangkaratt, V., Lin, W., Gal, Y., and Srivastava, A.
\newblock Fast and scalable bayesian deep learning by weight-perturbation in
  adam.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2611--2620. PMLR, 2018.

\bibitem[Lechner et~al.(2021)Lechner, Zikelic, Chatterjee, and
  Henzinger]{lechner2021infinite}
Lechner, M., Zikelic, D., Chatterjee, K., and Henzinger, T.
\newblock Infinite time horizon safety of bayesian neural networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Liu et~al.(2021)Liu, Arnon, Lazarus, Strong, Barrett, Kochenderfer,
  et~al.]{liu2021algorithms}
Liu, C., Arnon, T., Lazarus, C., Strong, C., Barrett, C., Kochenderfer, M.~J.,
  et~al.
\newblock Algorithms for verifying deep neural networks.
\newblock \emph{Foundations and Trends{\textregistered} in Optimization},
  4\penalty0 (3-4):\penalty0 244--404, 2021.

\bibitem[MacKay(1992)]{mackay1992practical}
MacKay, D.~J.
\newblock A practical bayesian framework for backpropagation networks.
\newblock \emph{Neural computation}, 4\penalty0 (3):\penalty0 448--472, 1992.

\bibitem[Madry et~al.(2017)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2017towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock \emph{arXiv preprint arXiv:1706.06083}, 2017.

\bibitem[Marchi et~al.(2021)Marchi, Gharesifard, and
  Tabuada]{marchi2021training}
Marchi, M., Gharesifard, B., and Tabuada, P.
\newblock Training deep residual networks for uniform approximation guarantees.
\newblock In \emph{Learning for Dynamics and Control}, pp.\  677--688. PMLR,
  2021.

\bibitem[McAllister et~al.(2017)McAllister, Gal, Kendall, Van Der~Wilk, Shah,
  Cipolla, and Weller]{mcallister2017concrete}
McAllister, R., Gal, Y., Kendall, A., Van Der~Wilk, M., Shah, A., Cipolla, R.,
  and Weller, A.
\newblock Concrete problems for autonomous vehicle safety: Advantages of
  bayesian deep learning.
\newblock International Joint Conferences on Artificial Intelligence, Inc.,
  2017.

\bibitem[Neal(2012)]{neal2012bayesian}
Neal, R.~M.
\newblock \emph{{B}ayesian learning for neural networks}, volume 118.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Osawa et~al.(2019)Osawa, Swaroop, Khan, Jain, Eschenhagen, Turner, and
  Yokota]{osawa2019practical}
Osawa, K., Swaroop, S., Khan, M. E.~E., Jain, A., Eschenhagen, R., Turner,
  R.~E., and Yokota, R.
\newblock Practical deep learning with bayesian principles.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Patanè et~al.(2022)Patanè, Blaas, Laurenti, Cardelli, Roberts, and
  Kwiatkowska]{patane2022adversarial}
Patanè, A., Blaas, A., Laurenti, L., Cardelli, L., Roberts, S., and
  Kwiatkowska, M.
\newblock Adversarial robustness guarantees for gaussian processes.
\newblock \emph{Journal of Machine Learning Research}, 23:\penalty0 1--55,
  2022.

\bibitem[Rawat et~al.(2017)Rawat, Wistuba, and Nicolae]{rawat2017adversarial}
Rawat, A., Wistuba, M., and Nicolae, M.-I.
\newblock Adversarial phenomenon in the eyes of bayesian deep learning.
\newblock \emph{arXiv preprint arXiv:1711.08244}, 2017.

\bibitem[Smith \& Gal(2018)Smith and Gal]{smith2018understanding}
Smith, L. and Gal, Y.
\newblock Understanding measures of uncertainty for adversarial example
  detection.
\newblock \emph{arXiv preprint arXiv:1803.08533}, 2018.

\bibitem[Smith et~al.(2022)Smith, Grosse, Backes, and
  Alvarez]{smith2022adversarial}
Smith, M.~T., Grosse, K., Backes, M., and Alvarez, M.~A.
\newblock Adversarial vulnerability bounds for gaussian process classification.
\newblock \emph{Machine Learning}, pp.\  1--39, 2022.

\bibitem[Socci et~al.(1997)Socci, Lee, and Seung]{socci1997rectified}
Socci, N., Lee, D., and Seung, H.~S.
\newblock The rectified gaussian distribution.
\newblock \emph{Advances in neural information processing systems}, 10, 1997.

\bibitem[Weng et~al.(2018)Weng, Zhang, Chen, Song, Hsieh, Daniel, and
  Dhillon]{weng2018towards}
Weng, T.-W., Zhang, H., Chen, H., Song, Z., Hsieh, C.-J., Daniel, L., and
  Dhillon, I.
\newblock Towards fast computation of certified robustness for {ReLU} networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2018.

\bibitem[Wicker et~al.(2020)Wicker, Laurenti, Patanè, and
  Kwiatkowska]{wicker2020probabilistic}
Wicker, M., Laurenti, L., Patanè, A., and Kwiatkowska, M.
\newblock Probabilistic safety for {B}ayesian neural networks.
\newblock \emph{Uncertainty in Artificial Intelligence (UAI)}, 2020.

\bibitem[Wicker et~al.(2021)Wicker, Laurenti, Patanè, Chen, Zhang, and
  Kwiatkowska]{wicker2021bayesian}
Wicker, M., Laurenti, L., Patanè, A., Chen, Z., Zhang, Z., and Kwiatkowska, M.
\newblock Bayesian inference with certifiable adversarial robustness.
\newblock \emph{AISTATS}, 2021.

\bibitem[Winn et~al.(2005)Winn, Bishop, and Jaakkola]{winn2005variational}
Winn, J., Bishop, C.~M., and Jaakkola, T.
\newblock Variational message passing.
\newblock \emph{Journal of Machine Learning Research}, 6\penalty0 (4), 2005.

\bibitem[Wong \& Kolter(2018)Wong and Kolter]{wong2018provable}
Wong, E. and Kolter, Z.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5286--5295. PMLR, 2018.

\bibitem[Zhang et~al.(2018{\natexlab{a}})Zhang, Sun, Duvenaud, and
  Grosse]{zhang2018noisy}
Zhang, G., Sun, S., Duvenaud, D., and Grosse, R.
\newblock Noisy natural gradient as variational inference.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5852--5861. PMLR, 2018{\natexlab{a}}.

\bibitem[Zhang et~al.(2018{\natexlab{b}})Zhang, Weng, Chen, Hsieh, and
  Daniel]{zhang2018efficient}
Zhang, H., Weng, T.-W., Chen, P.-Y., Hsieh, C.-J., and Daniel, L.
\newblock Efficient neural network robustness certification with general
  activation functions.
\newblock \emph{arXiv preprint arXiv:1811.00866}, 2018{\natexlab{b}}.

\end{thebibliography}
