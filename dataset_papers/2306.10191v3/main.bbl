\begin{thebibliography}{55}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Barbu et~al.(2019)Barbu, Mayo, Alverio, Luo, Wang, Gutfreund,
  Tenenbaum, and Katz]{barbu2019objectnet}
A.~Barbu, D.~Mayo, J.~Alverio, W.~Luo, C.~Wang, D.~Gutfreund, J.~Tenenbaum, and
  B.~Katz.
\newblock Objectnet: A large-scale bias-controlled dataset for pushing the
  limits of object recognition models.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Beaumont(2021)]{Github:clip_retrieval}
R.~Beaumont.
\newblock \emph{Clip Retrieval}, 2021.
\newblock URL \url{https://github.com/rom1504/clip-retrieval}.

\bibitem[Borgeaud et~al.(2022)Borgeaud, Mensch, Hoffmann, Cai, Rutherford,
  Millican, Van Den~Driessche, Lespiau, Damoc, Clark,
  et~al.]{borgeaud2022improving}
S.~Borgeaud, A.~Mensch, J.~Hoffmann, T.~Cai, E.~Rutherford, K.~Millican, G.~B.
  Van Den~Driessche, J.-B. Lespiau, B.~Damoc, A.~Clark, et~al.
\newblock Improving language models by retrieving from trillions of tokens.
\newblock In \emph{International conference on machine learning}, pages
  2206--2240. PMLR, 2022.

\bibitem[Brod et~al.(2013)Brod, Werkle-Bergner, and Shing]{brod2013influence}
G.~Brod, M.~Werkle-Bergner, and Y.~L. Shing.
\newblock The influence of prior knowledge on memory: a developmental cognitive
  neuroscience perspective.
\newblock \emph{Frontiers in behavioral neuroscience}, 7:\penalty0 139, 2013.

\bibitem[Brown and Kane(1988)]{brown1988preschool}
A.~L. Brown and M.~J. Kane.
\newblock Preschool children can learn to transfer: Learning to learn and
  learning from example.
\newblock \emph{Cognitive psychology}, 20\penalty0 (4):\penalty0 493--523,
  1988.

\bibitem[Chapelle et~al.(2006)Chapelle, Sch{\"o}lkopf, and
  Zien]{chapelle2006discussion}
O.~Chapelle, B.~Sch{\"o}lkopf, and A.~Zien.
\newblock A discussion of semi-supervised learning and transduction.
\newblock In \emph{Semi-supervised learning}, pages 473--478. MIT Press, 2006.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
J.~Deng, W.~Dong, R.~Socher, L.-J. Li, K.~Li, and L.~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee, 2009.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly,
  et~al.]{dosovitskiy2020image}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai,
  T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Fang et~al.(2022)Fang, Ilharco, Wortsman, Wan, Shankar, Dave, and
  Schmidt]{FangIWWSDS22}
A.~Fang, G.~Ilharco, M.~Wortsman, Y.~Wan, V.~Shankar, A.~Dave, and L.~Schmidt.
\newblock Data determines distributional robustness in contrastive language
  image pre-training {(CLIP)}.
\newblock In K.~Chaudhuri, S.~Jegelka, L.~Song, C.~Szepesv{\'{a}}ri, G.~Niu,
  and S.~Sabato, editors, \emph{International Conference on Machine Learning,
  {ICML} 2022, 17-23 July 2022, Baltimore, Maryland, {USA}}, volume 162 of
  \emph{Proceedings of Machine Learning Research}, pages 6216--6234. {PMLR},
  2022.
\newblock URL \url{https://proceedings.mlr.press/v162/fang22a.html}.

\bibitem[Fang et~al.(2021)Fang, Xiong, Xu, and Chen]{fang2021clip2video}
H.~Fang, P.~Xiong, L.~Xu, and Y.~Chen.
\newblock Clip2video: Mastering video-text retrieval via image clip.
\newblock \emph{arXiv preprint arXiv:2106.11097}, 2021.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{finn2017model}
C.~Finn, P.~Abbeel, and S.~Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{International conference on machine learning}, pages
  1126--1135. PMLR, 2017.

\bibitem[Franklin and Frank(2020)]{franklin2020generalizing}
N.~T. Franklin and M.~J. Frank.
\newblock Generalizing to generalize: Humans flexibly switch between
  compositional and conjunctive structures during reinforcement learning.
\newblock \emph{PLoS computational biology}, 16\penalty0 (4):\penalty0
  e1007720, 2020.

\bibitem[Gammerman et~al.(2013)Gammerman, Vovk, and
  Vapnik]{gammerman2013learning}
A.~Gammerman, V.~Vovk, and V.~Vapnik.
\newblock Learning by transduction.
\newblock \emph{arXiv preprint arXiv:1301.7375}, 2013.

\bibitem[Gandelsman et~al.(2022)Gandelsman, Sun, Chen, and
  Efros]{gandelsman2022test}
Y.~Gandelsman, Y.~Sun, X.~Chen, and A.~Efros.
\newblock Test-time training with masked autoencoders.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 29374--29385, 2022.

\bibitem[Goyal et~al.(2022)Goyal, Kumar, Garg, Kolter, and
  Raghunathan]{goyal2022finetune}
S.~Goyal, A.~Kumar, S.~Garg, Z.~Kolter, and A.~Raghunathan.
\newblock Finetune like you pretrain: Improved finetuning of zero-shot vision
  models.
\newblock \emph{arXiv preprint arXiv:2212.00638}, 2022.

\bibitem[Guu et~al.(2020)Guu, Lee, Tung, Pasupat, and Chang]{guu2020retrieval}
K.~Guu, K.~Lee, Z.~Tung, P.~Pasupat, and M.~Chang.
\newblock Retrieval augmented language model pre-training.
\newblock In \emph{International conference on machine learning}, pages
  3929--3938. PMLR, 2020.

\bibitem[He et~al.(2019)He, Girshick, and Doll{\'a}r]{he2019rethinking}
K.~He, R.~Girshick, and P.~Doll{\'a}r.
\newblock Rethinking imagenet pre-training.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 4918--4927, 2019.

\bibitem[Hendrycks et~al.(2021{\natexlab{a}})Hendrycks, Basart, Mu, Kadavath,
  Wang, Dorundo, Desai, Zhu, Parajuli, Guo, Song, Steinhardt, and
  Gilmer]{HendrycksBMKWDD21}
D.~Hendrycks, S.~Basart, N.~Mu, S.~Kadavath, F.~Wang, E.~Dorundo, R.~Desai,
  T.~Zhu, S.~Parajuli, M.~Guo, D.~Song, J.~Steinhardt, and J.~Gilmer.
\newblock The many faces of robustness: {A} critical analysis of
  out-of-distribution generalization.
\newblock In \emph{ICCV}, 2021{\natexlab{a}}.

\bibitem[Hendrycks et~al.(2021{\natexlab{b}})Hendrycks, Zhao, Basart,
  Steinhardt, and Song]{hendrycks2021natural}
D.~Hendrycks, K.~Zhao, S.~Basart, J.~Steinhardt, and D.~Song.
\newblock Natural adversarial examples.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 15262--15271, 2021{\natexlab{b}}.

\bibitem[Hermer-Vazquez et~al.(2001)Hermer-Vazquez, Moffet, and
  Munkholm]{hermer2001language}
L.~Hermer-Vazquez, A.~Moffet, and P.~Munkholm.
\newblock Language, space, and the development of cognitive flexibility in
  humans: The case of two spatial memory tasks.
\newblock \emph{Cognition}, 79\penalty0 (3):\penalty0 263--299, 2001.

\bibitem[Ilharco et~al.(2021)Ilharco, Wortsman, Wightman, Gordon, Carlini,
  Taori, Dave, Shankar, Namkoong, Miller, Hajishirzi, Farhadi, and
  Schmidt]{ilharco_gabriel_2021_5143773}
G.~Ilharco, M.~Wortsman, R.~Wightman, C.~Gordon, N.~Carlini, R.~Taori, A.~Dave,
  V.~Shankar, H.~Namkoong, J.~Miller, H.~Hajishirzi, A.~Farhadi, and
  L.~Schmidt.
\newblock Openclip, July 2021.
\newblock URL \url{https://doi.org/10.5281/zenodo.5143773}.

\bibitem[Jamal and Qi(2019)]{jamal2019task}
M.~A. Jamal and G.-J. Qi.
\newblock Task agnostic meta-learning for few-shot learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 11719--11727, 2019.

\bibitem[Jia et~al.(2021)Jia, Yang, Xia, Chen, Parekh, Pham, Le, Sung, Li, and
  Duerig]{jia2021scaling}
C.~Jia, Y.~Yang, Y.~Xia, Y.-T. Chen, Z.~Parekh, H.~Pham, Q.~V. Le, Y.~Sung,
  Z.~Li, and T.~Duerig.
\newblock Scaling up visual and vision-language representation learning with
  noisy text supervision.
\newblock \emph{arXiv preprint arXiv:2102.05918}, 2021.

\bibitem[Johnson et~al.(2019)Johnson, Douze, and J{\'e}gou]{johnson2019billion}
J.~Johnson, M.~Douze, and H.~J{\'e}gou.
\newblock Billion-scale similarity search with {GPUs}.
\newblock \emph{IEEE Transactions on Big Data}, 7\penalty0 (3):\penalty0
  535--547, 2019.

\bibitem[Khandelwal et~al.(2019)Khandelwal, Levy, Jurafsky, Zettlemoyer, and
  Lewis]{khandelwal2019generalization}
U.~Khandelwal, O.~Levy, D.~Jurafsky, L.~Zettlemoyer, and M.~Lewis.
\newblock Generalization through memorization: Nearest neighbor language
  models.
\newblock \emph{arXiv preprint arXiv:1911.00172}, 2019.

\bibitem[Knuth(1997)]{knuth1997retrieval}
D.~E. Knuth.
\newblock Retrieval on secondary keys.
\newblock \emph{The art of computer programming: Sorting and Searching},
  3:\penalty0 550--567, 1997.

\bibitem[Krause et~al.(2013)Krause, Stark, Deng, and Fei-Fei]{krause20133d}
J.~Krause, M.~Stark, J.~Deng, and L.~Fei-Fei.
\newblock 3d object representations for fine-grained categorization.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision workshops}, pages 554--561, 2013.

\bibitem[Kumar et~al.(2022)Kumar, Raghunathan, Jones, Ma, and
  Liang]{KumarRJ0L22}
A.~Kumar, A.~Raghunathan, R.~M. Jones, T.~Ma, and P.~Liang.
\newblock Fine-tuning can distort pretrained features and underperform
  out-of-distribution.
\newblock In \emph{The Tenth International Conference on Learning
  Representations, {ICLR} 2022, Virtual Event, April 25-29, 2022}.
  OpenReview.net, 2022.
\newblock URL \url{https://openreview.net/forum?id=UYneFzXSJWh}.

\bibitem[Lee et~al.(2022)Lee, Chen, Tajwar, Kumar, Yao, Liang, and
  Finn]{lee22surgical}
Y.~Lee, A.~S. Chen, F.~Tajwar, A.~Kumar, H.~Yao, P.~Liang, and C.~Finn.
\newblock Surgical fine-tuning improves adaptation to distribution shifts.
\newblock \emph{CoRR}, abs/2210.11466, 2022.
\newblock \doi{10.48550/arXiv.2210.11466}.
\newblock URL \url{https://doi.org/10.48550/arXiv.2210.11466}.

\bibitem[Liu et~al.(2023)Liu, Son, Yang, Liu, Gao, Lee, and
  Li]{liu2023learning}
H.~Liu, K.~Son, J.~Yang, C.~Liu, J.~Gao, Y.~J. Lee, and C.~Li.
\newblock Learning customized visual models with retrieval-augmented knowledge.
\newblock \emph{arXiv preprint arXiv:2301.07094}, 2023.

\bibitem[Maji et~al.(2013)Maji, Rahtu, Kannala, Blaschko, and
  Vedaldi]{maji2013fine}
S.~Maji, E.~Rahtu, J.~Kannala, M.~Blaschko, and A.~Vedaldi.
\newblock Fine-grained visual classification of aircraft.
\newblock \emph{arXiv preprint arXiv:1306.5151}, 2013.

\bibitem[Manning et~al.(2008)Manning, Raghavan, and
  Sch{\"u}tze]{manning2008vector}
C.~Manning, P.~Raghavan, and H.~Sch{\"u}tze.
\newblock Vector space classification.
\newblock \emph{Introduction to Information Retrieval}, pages 289--317, 2008.

\bibitem[Menon and Vondrick(2022)]{menon2022visual}
S.~Menon and C.~Vondrick.
\newblock Visual classification via description from large language models.
\newblock \emph{arXiv preprint arXiv:2210.07183}, 2022.

\bibitem[Meyer and Schvaneveldt(1971)]{meyer1971facilitation}
D.~E. Meyer and R.~W. Schvaneveldt.
\newblock Facilitation in recognizing pairs of words: evidence of a dependence
  between retrieval operations.
\newblock \emph{Journal of experimental psychology}, 90\penalty0 (2):\penalty0
  227, 1971.

\bibitem[Miller et~al.(2021)Miller, Taori, Raghunathan, Sagawa, Koh, Shankar,
  Liang, Carmon, and Schmidt]{MillerTRSKSLCS21}
J.~Miller, R.~Taori, A.~Raghunathan, S.~Sagawa, P.~W. Koh, V.~Shankar,
  P.~Liang, Y.~Carmon, and L.~Schmidt.
\newblock Accuracy on the line: on the strong correlation between
  out-of-distribution and in-distribution generalization.
\newblock In M.~Meila and T.~Zhang, editors, \emph{Proceedings of the 38th
  International Conference on Machine Learning, {ICML} 2021, 18-24 July 2021,
  Virtual Event}, volume 139 of \emph{Proceedings of Machine Learning
  Research}, pages 7721--7735. {PMLR}, 2021.
\newblock URL \url{http://proceedings.mlr.press/v139/miller21b.html}.

\bibitem[Nilsback and Zisserman(2008)]{nilsback2008automated}
M.-E. Nilsback and A.~Zisserman.
\newblock Automated flower classification over a large number of classes.
\newblock In \emph{2008 Sixth Indian Conference on Computer Vision, Graphics \&
  Image Processing}, pages 722--729. IEEE, 2008.

\bibitem[Oreshkin et~al.(2018)Oreshkin, Rodr{\'\i}guez~L{\'o}pez, and
  Lacoste]{oreshkin2018tadam}
B.~Oreshkin, P.~Rodr{\'\i}guez~L{\'o}pez, and A.~Lacoste.
\newblock Tadam: Task dependent adaptive metric for improved few-shot learning.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Parkhi et~al.(2012)Parkhi, Vedaldi, Zisserman, and
  Jawahar]{parkhi2012cats}
O.~M. Parkhi, A.~Vedaldi, A.~Zisserman, and C.~Jawahar.
\newblock Cats and dogs.
\newblock In \emph{2012 IEEE conference on computer vision and pattern
  recognition}, pages 3498--3505. IEEE, 2012.

\bibitem[Pratt et~al.(2022)Pratt, Liu, and Farhadi]{pratt2022does}
S.~Pratt, R.~Liu, and A.~Farhadi.
\newblock What does a platypus look like? generating customized prompts for
  zero-shot image classification.
\newblock \emph{arXiv preprint arXiv:2209.03320}, 2022.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
A.~Radford, J.~W. Kim, C.~Hallacy, A.~Ramesh, G.~Goh, S.~Agarwal, G.~Sastry,
  A.~Askell, P.~Mishkin, J.~Clark, et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{International conference on machine learning}, pages
  8748--8763. PMLR, 2021.

\bibitem[Recht et~al.(2019)Recht, Roelofs, Schmidt, and
  Shankar]{recht2019imagenet}
B.~Recht, R.~Roelofs, L.~Schmidt, and V.~Shankar.
\newblock Do imagenet classifiers generalize to imagenet?
\newblock In \emph{International conference on machine learning}, pages
  5389--5400. PMLR, 2019.

\bibitem[Rege et~al.(2023)Rege, Kusupati, Fan, Cao, Kakade, Jain, Farhadi,
  et~al.]{rege2023adanns}
A.~Rege, A.~Kusupati, A.~Fan, Q.~Cao, S.~Kakade, P.~Jain, A.~Farhadi, et~al.
\newblock Adanns: A framework for adaptive semantic search.
\newblock \emph{arXiv preprint arXiv:2305.19435}, 2023.

\bibitem[Roediger and McDermott(1995)]{roediger1995creating}
H.~L. Roediger and K.~B. McDermott.
\newblock Creating false memories: Remembering words not presented in lists.
\newblock \emph{Journal of experimental psychology: Learning, Memory, and
  Cognition}, 21\penalty0 (4):\penalty0 803, 1995.

\bibitem[Schuhmann et~al.(2022)Schuhmann, Beaumont, Vencu, Gordon, Wightman,
  Cherti, Coombes, Katta, Mullis, Wortsman, et~al.]{schuhmann2022laion}
C.~Schuhmann, R.~Beaumont, R.~Vencu, C.~Gordon, R.~Wightman, M.~Cherti,
  T.~Coombes, A.~Katta, C.~Mullis, M.~Wortsman, et~al.
\newblock Laion-5b: An open large-scale dataset for training next generation
  image-text models.
\newblock \emph{arXiv preprint arXiv:2210.08402}, 2022.

\bibitem[Shu et~al.(2022)Shu, Nie, Huang, Yu, Goldstein, Anandkumar, and
  Xiao]{shu2022test}
M.~Shu, W.~Nie, D.-A. Huang, Z.~Yu, T.~Goldstein, A.~Anandkumar, and C.~Xiao.
\newblock Test-time prompt tuning for zero-shot generalization in
  vision-language models.
\newblock \emph{arXiv preprint arXiv:2209.07511}, 2022.

\bibitem[Sivic and Zisserman(2003)]{sivic2003video}
J.~Sivic and A.~Zisserman.
\newblock Video google: A text retrieval approach to object matching in videos.
\newblock In \emph{Computer Vision, IEEE International Conference on},
  volume~3, pages 1470--1470. IEEE Computer Society, 2003.

\bibitem[Snell et~al.(2017)Snell, Swersky, and Zemel]{snell2017prototypical}
J.~Snell, K.~Swersky, and R.~Zemel.
\newblock Prototypical networks for few-shot learning.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Sun et~al.(2020)Sun, Wang, Liu, Miller, Efros, and Hardt]{sun2020test}
Y.~Sun, X.~Wang, Z.~Liu, J.~Miller, A.~Efros, and M.~Hardt.
\newblock Test-time training with self-supervision for generalization under
  distribution shifts.
\newblock In \emph{International conference on machine learning}, pages
  9229--9248. PMLR, 2020.

\bibitem[Taori et~al.(2020)Taori, Dave, Shankar, Carlini, Recht, and
  Schmidt]{TaoriDSCRS20}
R.~Taori, A.~Dave, V.~Shankar, N.~Carlini, B.~Recht, and L.~Schmidt.
\newblock Measuring robustness to natural distribution shifts in image
  classification.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~Balcan, and H.~Lin,
  editors, \emph{Advances in Neural Information Processing Systems 33: Annual
  Conference on Neural Information Processing Systems 2020, NeurIPS 2020,
  December 6-12, 2020, virtual}, 2020.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2020/hash/d8330f857a17c53d217014ee776bfd50-Abstract.html}.

\bibitem[Udandarao et~al.(2022)Udandarao, Gupta, and Albanie]{udandarao2022sus}
V.~Udandarao, A.~Gupta, and S.~Albanie.
\newblock Sus-x: Training-free name-only transfer of vision-language models.
\newblock \emph{arXiv preprint arXiv:2211.16198}, 2022.

\bibitem[Wang et~al.(2019)Wang, Ge, Lipton, and Xing]{WangGLX19}
H.~Wang, S.~Ge, Z.~C. Lipton, and E.~P. Xing.
\newblock Learning robust global representations by penalizing local predictive
  power.
\newblock In H.~M. Wallach, H.~Larochelle, A.~Beygelzimer,
  F.~d'Alch{\'{e}}{-}Buc, E.~B. Fox, and R.~Garnett, editors, \emph{Advances in
  Neural Information Processing Systems 32: Annual Conference on Neural
  Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019,
  Vancouver, BC, Canada}, pages 10506--10518, 2019.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2019/hash/3eefceb8087e964f89c2d59e8a249915-Abstract.html}.

\bibitem[Wortsman et~al.(2022)Wortsman, Ilharco, Kim, Li, Kornblith, Roelofs,
  Lopes, Hajishirzi, Farhadi, Namkoong, et~al.]{wortsman2022robust}
M.~Wortsman, G.~Ilharco, J.~W. Kim, M.~Li, S.~Kornblith, R.~Roelofs, R.~G.
  Lopes, H.~Hajishirzi, A.~Farhadi, H.~Namkoong, et~al.
\newblock Robust fine-tuning of zero-shot models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 7959--7971, 2022.

\bibitem[Xiao et~al.(2010)Xiao, Hays, Ehinger, Oliva, and
  Torralba]{xiao2010sun}
J.~Xiao, J.~Hays, K.~A. Ehinger, A.~Oliva, and A.~Torralba.
\newblock Sun database: Large-scale scene recognition from abbey to zoo.
\newblock In \emph{2010 IEEE computer society conference on computer vision and
  pattern recognition}, pages 3485--3492. IEEE, 2010.

\bibitem[Zhang et~al.(2022)Zhang, Zhang, Fang, Gao, Li, Dai, Qiao, and
  Li]{zhang2022tip}
R.~Zhang, W.~Zhang, R.~Fang, P.~Gao, K.~Li, J.~Dai, Y.~Qiao, and H.~Li.
\newblock Tip-adapter: Training-free adaption of clip for few-shot
  classification.
\newblock In \emph{Computer Vision--ECCV 2022: 17th European Conference, Tel
  Aviv, Israel, October 23--27, 2022, Proceedings, Part XXXV}, pages 493--510.
  Springer, 2022.

\bibitem[Zhou et~al.(2022)Zhou, Yang, Loy, and Liu]{zhou2022learning}
K.~Zhou, J.~Yang, C.~C. Loy, and Z.~Liu.
\newblock Learning to prompt for vision-language models.
\newblock \emph{International Journal of Computer Vision}, 130\penalty0
  (9):\penalty0 2337--2348, 2022.

\end{thebibliography}
