\begin{thebibliography}{10}

\bibitem{arazo2020pseudo}
Eric Arazo, Diego Ortego, Paul Albert, Noel~E Oâ€™Connor, and Kevin McGuinness.
\newblock Pseudo-labeling and confirmation bias in deep semi-supervised
  learning.
\newblock In {\em International Joint Conference on Neural Networks}, 2020.

\bibitem{ben2010theory}
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and
  Jennifer~Wortman Vaughan.
\newblock A theory of learning from different domains.
\newblock {\em Machine learning}, 2010.

\bibitem{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In {\em International conference on machine learning}, 2020.

\bibitem{dosovitskiy2020vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em ICLR}, 2021.

\bibitem{eastwood2022sourcefree}
Cian Eastwood, Ian Mason, Chris Williams, and Bernhard Sch{\"o}lkopf.
\newblock Source-free adaptation to measurement shift via bottom-up feature
  restoration.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{ganin2015unsupervised}
Yaroslav Ganin and Victor Lempitsky.
\newblock Unsupervised domain adaptation by backpropagation.
\newblock In {\em International conference on machine learning}, 2015.

\bibitem{gretton2012kernel}
Arthur Gretton, Karsten~M Borgwardt, Malte~J Rasch, Bernhard Sch{\"o}lkopf, and
  Alexander Smola.
\newblock A kernel two-sample test.
\newblock {\em The Journal of Machine Learning Research}, 2012.

\bibitem{han2018co}
Bo~Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and
  Masashi Sugiyama.
\newblock Co-teaching: Robust training of deep neural networks with extremely
  noisy labels.
\newblock In {\em Advances in neural information processing systems}, 2018.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, 2016.

\bibitem{hendrycks2018benchmarking}
Dan Hendrycks and Thomas Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{hershey2007approximating}
John~R Hershey and Peder~A Olsen.
\newblock Approximating the kullback leibler divergence between gaussian
  mixture models.
\newblock In {\em IEEE International Conference on Acoustics, Speech and Signal
  Processing}, 2007.

\bibitem{hoffman2018cycada}
Judy Hoffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu, Phillip Isola, Kate
  Saenko, Alexei Efros, and Trevor Darrell.
\newblock Cycada: Cycle-consistent adversarial domain adaptation.
\newblock In {\em International conference on machine learning}, 2018.

\bibitem{ioffe2015batch}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In {\em International conference on machine learning}, 2015.

\bibitem{iwasawa2021test}
Yusuke Iwasawa and Yutaka Matsuo.
\newblock Test-time classifier adjustment module for model-agnostic domain
  generalization.
\newblock In {\em Advances in Neural Information Processing Systems}, 2021.

\bibitem{jiang2007instance}
Jing Jiang and ChengXiang Zhai.
\newblock Instance weighting for domain adaptation in nlp.
\newblock In {\em ACL}, 2007.

\bibitem{krizhevsky2012imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In {\em Advances in neural information processing systems}, 2012.

\bibitem{kundu2020universal}
Jogendra~Nath Kundu, Naveen Venkat, R~Venkatesh Babu, et~al.
\newblock Universal source-free domain adaptation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, 2020.

\bibitem{7528140}
Gerhard Kurz, Florian Pfaff, and Uwe~D. Hanebeck.
\newblock Kullback-leibler divergence and moment matching for hyperspherical
  probability distributions.
\newblock In {\em 2016 19th International Conference on Information Fusion
  (FUSION)}, 2016.

\bibitem{lee2013pseudo}
Dong-Hyun Lee et~al.
\newblock Pseudo-label: The simple and efficient semi-supervised learning
  method for deep neural networks.
\newblock In {\em Workshop on challenges in representation learning, ICML},
  2013.

\bibitem{li2019learning}
Junnan Li, Yongkang Wong, Qi~Zhao, and Mohan~S Kankanhalli.
\newblock Learning to learn from noisy labeled data.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, 2019.

\bibitem{pmlr-v119-liang20a}
Jian Liang, Dapeng Hu, and Jiashi Feng.
\newblock Do we really need to access the source data? {S}ource hypothesis
  transfer for unsupervised domain adaptation.
\newblock In {\em International Conference on Machine Learning}, 2020.

\bibitem{liu2021ttt++}
Yuejiang Liu, Parth Kothari, Bastien van Delft, Baptiste Bellot-Gurlet, Taylor
  Mordan, and Alexandre Alahi.
\newblock Ttt++: When does self-supervised test-time training fail or thrive?
\newblock In {\em Advances in Neural Information Processing Systems}, 2021.

\bibitem{VisDA}
Xingchao Peng, Ben Usman, Neela Kaushik, Judy Hoffman, Dequan Wang, and Kate
  Saenko.
\newblock Visda: The visual domain adaptation challenge.
\newblock {\em arXiv preprint arXiv:1710.06924}, 2017.

\bibitem{quinonero2008dataset}
Joaquin Qui{\~n}onero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil~D
  Lawrence.
\newblock {\em Dataset shift in machine learning}.
\newblock Mit Press, 2008.

\bibitem{pmlr-v97-recht19a}
Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar.
\newblock Do imagenet classifiers generalize to imagenet?
\newblock In {\em International Conference on Machine Learning}, 2019.

\bibitem{sohn2020fixmatch}
Kihyuk Sohn, David Berthelot, Nicholas Carlini, Zizhao Zhang, Han Zhang,
  Colin~A Raffel, Ekin~Dogus Cubuk, Alexey Kurakin, and Chun-Liang Li.
\newblock Fixmatch: Simplifying semi-supervised learning with consistency and
  confidence.
\newblock {\em Advances in Neural Information Processing Systems}, 2020.

\bibitem{sun2016deep}
Baochen Sun and Kate Saenko.
\newblock Deep coral: Correlation alignment for deep domain adaptation.
\newblock In {\em European conference on computer vision}, 2016.

\bibitem{ModelNet40-C}
Jiachen Sun, Qingzhao Zhang, Bhavya Kailkhura, Zhiding Yu, Chaowei Xiao, and
  Z~Morley Mao.
\newblock Benchmarking robustness of 3d point cloud recognition against common
  corruptions.
\newblock {\em arXiv preprint arXiv:2201.12296}, 2022.

\bibitem{sun2020test}
Yu~Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt.
\newblock Test-time training with self-supervision for generalization under
  distribution shifts.
\newblock In {\em International Conference on Machine Learning}, 2020.

\bibitem{tang2020unsupervised}
Hui Tang, Ke~Chen, and Kui Jia.
\newblock Unsupervised domain adaptation via structurally regularized deep
  clustering.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, 2020.

\bibitem{tzeng2014deep}
Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, and Trevor Darrell.
\newblock Deep domain confusion: Maximizing for domain invariance.
\newblock {\em arXiv preprint arXiv:1412.3474}, 2014.

\bibitem{van2008visualizing}
Laurens Van~der Maaten and Geoffrey Hinton.
\newblock Visualizing data using t-sne.
\newblock {\em Journal of machine learning research}, 2008.

\bibitem{wang2020tent}
Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell.
\newblock Tent: Fully test-time adaptation by entropy minimization.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{wang2018deep}
Mei Wang and Weihong Deng.
\newblock Deep visual domain adaptation: A survey.
\newblock {\em Neurocomputing}, 2018.

\bibitem{wang2022continual}
Qin Wang, Olga Fink, Luc Van~Gool, and Dengxin Dai.
\newblock Continual test-time domain adaptation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, 2022.

\bibitem{wang2019dynamic}
Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay~E Sarma, Michael~M Bronstein, and
  Justin~M Solomon.
\newblock Dynamic graph cnn for learning on point clouds.
\newblock {\em Acm Transactions On Graphics (tog)}, 2019.

\bibitem{xia2021adaptive}
Haifeng Xia, Handong Zhao, and Zhengming Ding.
\newblock Adaptive adversarial network for source-free domain adaptation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, 2021.

\bibitem{yan2017mind}
Hongliang Yan, Yukang Ding, Peihua Li, Qilong Wang, Yong Xu, and Wangmeng Zuo.
\newblock Mind the class weight bias: Weighted maximum mean discrepancy for
  unsupervised domain adaptation.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, 2017.

\bibitem{yang2021generalized}
Shiqi Yang, Yaxing Wang, Joost van~de Weijer, Luis Herranz, and Shangling Jui.
\newblock Generalized source-free domain adaptation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, 2021.

\bibitem{zellinger2017central}
Werner Zellinger, Thomas Grubinger, Edwin Lughofer, Thomas Natschl{\"a}ger, and
  Susanne Saminger-Platz.
\newblock Central moment discrepancy (cmd) for domain-invariant representation
  learning.
\newblock In {\em International Conference on Learning Representations}, 2016.

\bibitem{ZELLINGER2019174}
Werner Zellinger, Bernhard~A. Moser, Thomas Grubinger, Edwin Lughofer, Thomas
  NatschlÃ¤ger, and Susanne Saminger-Platz.
\newblock Robust unsupervised domain adaptation for neural networks via moment
  alignment.
\newblock {\em Information Sciences}, 2019.

\bibitem{zhou2021domain}
Kaiyang Zhou, Ziwei Liu, Yu~Qiao, Tao Xiang, and Chen Change~Loy.
\newblock Domain generalization: A survey.
\newblock {\em arXiv e-prints}, pages arXiv--2103, 2021.

\bibitem{zhou2018brief}
Zhi-Hua Zhou.
\newblock A brief introduction to weakly supervised learning.
\newblock {\em National science review}, 2018.

\end{thebibliography}
