\begin{thebibliography}{46}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Achiam et~al.(2023)Achiam, Adler, Agarwal, Ahmad, Akkaya, Aleman,
  Almeida, Altenschmidt, Altman, Anadkat, et~al.]{achiam2023gpt}
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya,
  Florencia~Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman,
  Shyamal Anadkat, et~al.
\newblock Gpt-4 technical report.
\newblock \emph{arXiv preprint arXiv:2303.08774}, 2023.

\bibitem[Ahn et~al.(2023)Ahn, Beirami, Sun, and Suresh]{ahn2023spectr++}
Kwangjun Ahn, Ahmad Beirami, Ziteng Sun, and Ananda~Theertha Suresh.
\newblock Spectr++: Improved transport plans for speculative decoding of large
  language models.
\newblock In \emph{NeurIPS 2023 Workshop Optimal Transport and Machine
  Learning}, 2023.

\bibitem[Arnab et~al.(2021)Arnab, Dehghani, Heigold, Sun, Lu{\v{c}}i{\'c}, and
  Schmid]{arnab2021vivit}
Anurag Arnab, Mostafa Dehghani, Georg Heigold, Chen Sun, Mario Lu{\v{c}}i{\'c},
  and Cordelia Schmid.
\newblock Vivit: A video vision transformer.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 6836--6846, 2021.

\bibitem[Bae et~al.(2023)Bae, Ko, Song, and Yun]{bae2023fast}
Sangmin Bae, Jongwoo Ko, Hwanjun Song, and Se-Young Yun.
\newblock Fast and robust early-exiting framework for autoregressive language
  models with synchronized parallel decoding.
\newblock \emph{arXiv preprint arXiv:2310.05424}, 2023.

\bibitem[Bergner et~al.(2024)Bergner, Skliar, Royer, Blankevoort, Asano, and
  Bejnordi]{bergner2024think}
Benjamin Bergner, Andrii Skliar, Amelie Royer, Tijmen Blankevoort, Yuki Asano,
  and Babak~Ehteshami Bejnordi.
\newblock Think big, generate quick: Llm-to-slm for fast autoregressive
  decoding.
\newblock \emph{arXiv preprint arXiv:2402.16844}, 2024.

\bibitem[Bhendawade et~al.(2024)Bhendawade, Belousova, Fu, Mason, Rastegari,
  and Najibi]{bhendawade2024speculative}
Nikhil Bhendawade, Irina Belousova, Qichen Fu, Henry Mason, Mohammad Rastegari,
  and Mahyar Najibi.
\newblock Speculative streaming: Fast llm inference without auxiliary models.
\newblock \emph{arXiv preprint arXiv:2402.11131}, 2024.

\bibitem[Biderman et~al.(2023)Biderman, Schoelkopf, Anthony, Bradley,
  O’Brien, Hallahan, Khan, Purohit, Prashanth, Raff,
  et~al.]{biderman2023pythia}
Stella Biderman, Hailey Schoelkopf, Quentin~Gregory Anthony, Herbie Bradley,
  Kyle O’Brien, Eric Hallahan, Mohammad~Aflah Khan, Shivanshu Purohit,
  USVSN~Sai Prashanth, Edward Raff, et~al.
\newblock Pythia: A suite for analyzing large language models across training
  and scaling.
\newblock In \emph{International Conference on Machine Learning}, pages
  2397--2430. PMLR, 2023.

\bibitem[Brohan et~al.(2022)Brohan, Brown, Carbajal, Chebotar, Dabis, Finn,
  Gopalakrishnan, Hausman, Herzog, Hsu, et~al.]{brohan2022rt}
Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Joseph Dabis,
  Chelsea Finn, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, Jasmine
  Hsu, et~al.
\newblock Rt-1: Robotics transformer for real-world control at scale.
\newblock \emph{arXiv preprint arXiv:2212.06817}, 2022.

\bibitem[Burton(1985)]{burton1985speculative}
F~Warren Burton.
\newblock Speculative computation, parallelism, and functional programming.
\newblock \emph{IEEE Transactions on Computers}, 100\penalty0 (12):\penalty0
  1190--1193, 1985.

\bibitem[Chen et~al.(2023{\natexlab{a}})Chen, Borgeaud, Irving, Lespiau, Sifre,
  and Jumper]{chen2023accelerating}
Charlie Chen, Sebastian Borgeaud, Geoffrey Irving, Jean-Baptiste Lespiau,
  Laurent Sifre, and John Jumper.
\newblock Accelerating large language model decoding with speculative sampling.
\newblock \emph{arXiv preprint arXiv:2302.01318}, 2023{\natexlab{a}}.

\bibitem[Chen et~al.(2023{\natexlab{b}})Chen, Yang, Lin, Sun, Huang, and
  Chang]{chen2023cascade}
Ziyi Chen, Xiaocong Yang, Jiacheng Lin, Chenkai Sun, Jie Huang, and Kevin
  Chen-Chuan Chang.
\newblock Cascade speculative drafting for even faster llm inference.
\newblock \emph{arXiv preprint arXiv:2312.11462}, 2023{\natexlab{b}}.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly,
  et~al.]{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Dubois et~al.(2023)Dubois, Li, Taori, Zhang, Gulrajani, Ba, Guestrin,
  Liang, and Hashimoto]{dubois2023alpacafarm}
Yann Dubois, Chen~Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani,
  Jimmy Ba, Carlos Guestrin, Percy~S Liang, and Tatsunori~B Hashimoto.
\newblock Alpacafarm: A simulation framework for methods that learn from human
  feedback.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2023.

\bibitem[Fu et~al.(2024)Fu, Bailis, Stoica, and Zhang]{fu2024break}
Yichao Fu, Peter Bailis, Ion Stoica, and Hao Zhang.
\newblock Break the sequential dependency of llm inference using lookahead
  decoding.
\newblock \emph{arXiv preprint arXiv:2402.02057}, 2024.

\bibitem[Gabbay and Mendelson(1996)]{gabbay1996speculative}
Freddy Gabbay and Avi Mendelson.
\newblock \emph{Speculative execution based on value prediction}.
\newblock Technion-IIT, Department of Electrical Engineering, 1996.

\bibitem[Gagrani et~al.(2024)Gagrani, Goel, Jeon, Park, Lee, and
  Lott]{gagrani2024speculative}
Mukul Gagrani, Raghavv Goel, Wonseok Jeon, Junyoung Park, Mingu Lee, and
  Christopher Lott.
\newblock On speculative decoding for multimodal large language models.
\newblock \emph{arXiv preprint arXiv:2404.08856}, 2024.

\bibitem[Han et~al.(2022)Han, Wang, Chen, Chen, Guo, Liu, Tang, Xiao, Xu, Xu,
  et~al.]{han2022survey}
Kai Han, Yunhe Wang, Hanting Chen, Xinghao Chen, Jianyuan Guo, Zhenhua Liu,
  Yehui Tang, An~Xiao, Chunjing Xu, Yixing Xu, et~al.
\newblock A survey on vision transformer.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 45\penalty0 (1):\penalty0 87--110, 2022.

\bibitem[He et~al.(2023)He, Zhong, Cai, Lee, and He]{he2023rest}
Zhenyu He, Zexuan Zhong, Tianle Cai, Jason~D Lee, and Di~He.
\newblock Rest: Retrieval-based speculative decoding.
\newblock \emph{arXiv preprint arXiv:2311.08252}, 2023.

\bibitem[Ho et~al.(2022)Ho, Chan, Saharia, Whang, Gao, Gritsenko, Kingma,
  Poole, Norouzi, Fleet, et~al.]{ho2022imagen}
Jonathan Ho, William Chan, Chitwan Saharia, Jay Whang, Ruiqi Gao, Alexey
  Gritsenko, Diederik~P Kingma, Ben Poole, Mohammad Norouzi, David~J Fleet,
  et~al.
\newblock Imagen video: High definition video generation with diffusion models.
\newblock \emph{arXiv preprint arXiv:2210.02303}, 2022.

\bibitem[Huang et~al.(2024)Huang, Guo, and Wang]{huang2024specdec++}
Kaixuan Huang, Xudong Guo, and Mengdi Wang.
\newblock Specdec++: Boosting speculative decoding via adaptive candidate
  lengths.
\newblock \emph{arXiv preprint arXiv:2405.19715}, 2024.

\bibitem[Jeon et~al.(2024)Jeon, Gagrani, Goel, Park, Lee, and
  Lott]{jeon2024recursive}
Wonseok Jeon, Mukul Gagrani, Raghavv Goel, Junyoung Park, Mingu Lee, and
  Christopher Lott.
\newblock Recursive speculative decoding: Accelerating llm inference via
  sampling without replacement.
\newblock \emph{arXiv preprint arXiv:2402.14160}, 2024.

\bibitem[Kaplan et~al.(2020)Kaplan, McCandlish, Henighan, Brown, Chess, Child,
  Gray, Radford, Wu, and Amodei]{kaplan2020scaling}
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom~B Brown, Benjamin Chess, Rewon
  Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.
\newblock Scaling laws for neural language models.
\newblock \emph{arXiv preprint arXiv:2001.08361}, 2020.

\bibitem[Kim et~al.(2023)Kim, Mangalam, Moon, Malik, Mahoney, Gholami, and
  Keutzer]{kim2023speculative}
Sehoon Kim, Karttikeya Mangalam, Suhong Moon, Jitendra Malik, Michael~W
  Mahoney, Amir Gholami, and Kurt Keutzer.
\newblock Speculative decoding with big little decoder.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing
  Systems}, 2023.

\bibitem[Leviathan et~al.(2023)Leviathan, Kalman, and
  Matias]{leviathan2023fast}
Yaniv Leviathan, Matan Kalman, and Yossi Matias.
\newblock Fast inference from transformers via speculative decoding.
\newblock In \emph{International Conference on Machine Learning}, pages
  19274--19286. PMLR, 2023.

\bibitem[Liu et~al.(2023)Liu, Hu, Bailis, Stoica, Deng, Cheung, and
  Zhang]{liu2023online}
Xiaoxuan Liu, Lanxiang Hu, Peter Bailis, Ion Stoica, Zhijie Deng, Alvin Cheung,
  and Hao Zhang.
\newblock Online speculative decoding.
\newblock \emph{arXiv preprint arXiv:2310.07177}, 2023.

\bibitem[Miao et~al.(2023)Miao, Oliaro, Zhang, Cheng, Wang, Wong, Chen, Arfeen,
  Abhyankar, and Jia]{miao2023specinfer}
Xupeng Miao, Gabriele Oliaro, Zhihao Zhang, Xinhao Cheng, Zeyu Wang, Rae
  Ying~Yee Wong, Zhuoming Chen, Daiyaan Arfeen, Reyna Abhyankar, and Zhihao
  Jia.
\newblock Specinfer: Accelerating generative llm serving with speculative
  inference and token tree verification.
\newblock \emph{arXiv preprint arXiv:2305.09781}, 2023.

\bibitem[Mitchell et~al.(2023)Mitchell, Rafailov, Sharma, Finn, and
  Manning]{mitchell2023emulator}
Eric Mitchell, Rafael Rafailov, Archit Sharma, Chelsea Finn, and Christopher~D
  Manning.
\newblock An emulator for fine-tuning large language models using small
  language models.
\newblock \emph{arXiv preprint arXiv:2310.12962}, 2023.

\bibitem[Ou et~al.(2024)Ou, Chen, and Tian]{ou2024lossless}
Jie Ou, Yueming Chen, and Wenhong Tian.
\newblock Lossless acceleration of large language model via adaptive n-gram
  parallel decoding.
\newblock \emph{arXiv preprint arXiv:2404.08698}, 2024.

\bibitem[Qian et~al.(2024)Qian, Gonugondla, Ha, Shang, Gouda, Nallapati,
  Sengupta, Ma, and Deoras]{qian2024bass}
Haifeng Qian, Sujan~Kumar Gonugondla, Sungsoo Ha, Mingyue Shang, Sanjay~Krishna
  Gouda, Ramesh Nallapati, Sudipta Sengupta, Xiaofei Ma, and Anoop Deoras.
\newblock Bass: Batched attention-optimized speculative sampling.
\newblock \emph{arXiv preprint arXiv:2404.15778}, 2024.

\bibitem[Santilli et~al.(2023)Santilli, Severino, Postolache, Maiorca, Mancusi,
  Marin, and Rodol{\`a}]{santilli2023accelerating}
Andrea Santilli, Silvio Severino, Emilian Postolache, Valentino Maiorca,
  Michele Mancusi, Riccardo Marin, and Emanuele Rodol{\`a}.
\newblock Accelerating transformer inference for translation via parallel
  decoding.
\newblock \emph{arXiv preprint arXiv:2305.10427}, 2023.

\bibitem[Shridhar et~al.(2023)Shridhar, Manuelli, and
  Fox]{shridhar2023perceiver}
Mohit Shridhar, Lucas Manuelli, and Dieter Fox.
\newblock Perceiver-actor: A multi-task transformer for robotic manipulation.
\newblock In \emph{Conference on Robot Learning}, pages 785--799. PMLR, 2023.

\bibitem[Spector and Re(2023)]{spector2023accelerating}
Benjamin Spector and Chris Re.
\newblock Accelerating llm inference with staged speculative decoding.
\newblock \emph{arXiv preprint arXiv:2308.04623}, 2023.

\bibitem[Stern et~al.(2018)Stern, Shazeer, and Uszkoreit]{stern2018blockwise}
Mitchell Stern, Noam Shazeer, and Jakob Uszkoreit.
\newblock Blockwise parallel decoding for deep autoregressive models.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Su et~al.(2023)Su, Giannoula, and Pekhimenko]{su2023synergy}
Qidong Su, Christina Giannoula, and Gennady Pekhimenko.
\newblock The synergy of speculative decoding and batching in serving large
  language models.
\newblock \emph{arXiv preprint arXiv:2310.18813}, 2023.

\bibitem[Sun et~al.(2024{\natexlab{a}})Sun, Chen, Yang, Tian, and
  Chen]{sun2024triforce}
Hanshi Sun, Zhuoming Chen, Xinyu Yang, Yuandong Tian, and Beidi Chen.
\newblock Triforce: Lossless acceleration of long sequence generation with
  hierarchical speculative decoding.
\newblock \emph{arXiv preprint arXiv:2404.11912}, 2024{\natexlab{a}}.

\bibitem[Sun et~al.(2023)Sun, Suresh, Ro, Beirami, Jain, and Yu]{sun2023spectr}
Ziteng Sun, Ananda~Theertha Suresh, Jae~Hun Ro, Ahmad Beirami, Himanshu Jain,
  and Felix Yu.
\newblock Spectr: Fast speculative decoding via optimal transport.
\newblock \emph{arXiv preprint arXiv:2310.15141}, 2023.

\bibitem[Sun et~al.(2024{\natexlab{b}})Sun, Ro, Beirami, and
  Suresh]{sun2024optimal}
Ziteng Sun, Jae~Hun Ro, Ahmad Beirami, and Ananda~Theertha Suresh.
\newblock Optimal block-level draft verification for accelerating speculative
  decoding.
\newblock \emph{arXiv preprint arXiv:2403.10444}, 2024{\natexlab{b}}.

\bibitem[Team et~al.(2023)Team, Anil, Borgeaud, Wu, Alayrac, Yu, Soricut,
  Schalkwyk, Dai, Hauth, et~al.]{team2023gemini}
Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac,
  Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew~M Dai, Anja Hauth, et~al.
\newblock Gemini: a family of highly capable multimodal models.
\newblock \emph{arXiv preprint arXiv:2312.11805}, 2023.

\bibitem[Touvron et~al.(2023)Touvron, Lavril, Izacard, Martinet, Lachaux,
  Lacroix, Rozi{\`e}re, Goyal, Hambro, Azhar, et~al.]{touvron2023llama}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
  Lachaux, Timoth{\'e}e Lacroix, Baptiste Rozi{\`e}re, Naman Goyal, Eric
  Hambro, Faisal Azhar, et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock \emph{arXiv preprint arXiv:2302.13971}, 2023.

\bibitem[Wang et~al.(2024)Wang, Yang, Wang, Liu, Wang, Liang, Ma, Feng, You,
  Bao, et~al.]{wang2024minions}
Siqi Wang, Hailong Yang, Xuezhu Wang, Tongxuan Liu, Pengbo Wang, Xuning Liang,
  Kejie Ma, Tianyu Feng, Xin You, Yongjun Bao, et~al.
\newblock Minions: Accelerating large language model inference with adaptive
  and collective speculative decoding.
\newblock \emph{arXiv preprint arXiv:2402.15678}, 2024.

\bibitem[Xia et~al.(2023)Xia, Ge, Wang, Chen, Wei, and Sui]{xia2023speculative}
Heming Xia, Tao Ge, Peiyi Wang, Si-Qing Chen, Furu Wei, and Zhifang Sui.
\newblock Speculative decoding: Exploiting speculative execution for
  accelerating seq2seq generation.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP 2023}, pages 3909--3925, 2023.

\bibitem[Xia et~al.(2024)Xia, Yang, Dong, Wang, Li, Ge, Liu, Li, and
  Sui]{xia2024unlocking}
Heming Xia, Zhe Yang, Qingxiu Dong, Peiyi Wang, Yongqi Li, Tao Ge, Tianyu Liu,
  Wenjie Li, and Zhifang Sui.
\newblock Unlocking efficiency in large language model inference: A
  comprehensive survey of speculative decoding.
\newblock \emph{arXiv preprint arXiv:2401.07851}, 2024.

\bibitem[Xu et~al.(2023)Xu, Yin, Jin, Zhang, Wei, Xu, and Liu]{xu2023llmcad}
Daliang Xu, Wangsong Yin, Xin Jin, Ying Zhang, Shiyun Wei, Mengwei Xu, and
  Xuanzhe Liu.
\newblock Llmcad: Fast and scalable on-device large language model inference.
\newblock \emph{arXiv preprint arXiv:2309.04255}, 2023.

\bibitem[Yan et~al.(2024)Yan, Agarwal, and Venkataraman]{yan2024decoding}
Minghao Yan, Saurabh Agarwal, and Shivaram Venkataraman.
\newblock Decoding speculative decoding.
\newblock \emph{arXiv preprint arXiv:2402.01528}, 2024.

\bibitem[Yang et~al.(2024)Yang, Huang, Dai, and Chen]{yang2024multi}
Sen Yang, Shujian Huang, Xinyu Dai, and Jiajun Chen.
\newblock Multi-candidate speculative decoding.
\newblock \emph{arXiv preprint arXiv:2401.06706}, 2024.

\bibitem[Zhou et~al.(2023)Zhou, Lyu, Rawat, Menon, Rostamizadeh, Kumar, Kagy,
  and Agarwal]{zhou2023distillspec}
Yongchao Zhou, Kaifeng Lyu, Ankit~Singh Rawat, Aditya~Krishna Menon, Afshin
  Rostamizadeh, Sanjiv Kumar, Jean-Fran{\c{c}}ois Kagy, and Rishabh Agarwal.
\newblock Distillspec: Improving speculative decoding via knowledge
  distillation.
\newblock \emph{arXiv preprint arXiv:2310.08461}, 2023.

\end{thebibliography}
