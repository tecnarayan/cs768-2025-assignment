\begin{thebibliography}{}

\bibitem[Agarwal et~al., 2014]{agarwal2014taming}
Agarwal, A., Hsu, D., Kale, S., Langford, J., Li, L., and Schapire, R. (2014).
\newblock Taming the monster: A fast and simple algorithm for contextual
  bandits.
\newblock In {\em International Conference on Machine Learning}, pages
  1638--1646. PMLR.

\bibitem[Agrawal, 1995]{agrawal_1995}
Agrawal, R. (1995).
\newblock Sample mean based index policies by o(log n) regret for the
  multi-armed bandit problem.
\newblock {\em Advances in Applied Probability}, 27(4):1054â€“1078.

\bibitem[Agrawal et~al., 2017]{agrawal2017thompson}
Agrawal, S., Avadhanula, V., Goyal, V., and Zeevi, A. (2017).
\newblock Thompson sampling for the mnl-bandit.
\newblock {\em arXiv preprint arXiv:1706.00977}.

\bibitem[Agrawal and Goyal, 2012]{agrawal2012analysis}
Agrawal, S. and Goyal, N. (2012).
\newblock Analysis of thompson sampling for the multi-armed bandit problem.
\newblock In {\em Conference on learning theory}, pages 39--1. JMLR Workshop
  and Conference Proceedings.

\bibitem[Agrawal and Goyal, 2013a]{agrawal2013further}
Agrawal, S. and Goyal, N. (2013a).
\newblock Further optimal regret bounds for thompson sampling.
\newblock In {\em Artificial intelligence and statistics}, pages 99--107. PMLR.

\bibitem[Agrawal and Goyal, 2013b]{AG2013a}
Agrawal, S. and Goyal, N. (2013b).
\newblock Further optimal regret bounds for thompson sampling.
\newblock In {\em Artificial intelligence and statistics}, pages 99--107.

\bibitem[Agrawal and Goyal, 2013c]{AG2013b}
Agrawal, S. and Goyal, N. (2013c).
\newblock Thompson sampling for contextual bandits with linear payoffs.
\newblock In {\em International Conference on Machine Learning}, pages
  127--135.

\bibitem[Agrawal and Goyal, 2017]{agrawal2017near}
Agrawal, S. and Goyal, N. (2017).
\newblock Near-optimal regret bounds for thompson sampling.
\newblock {\em Journal of the ACM (JACM)}, 64(5):1--24.

\bibitem[Audibert et~al., 2009]{audibert2009minimax}
Audibert, J.-Y., Bubeck, S., et~al. (2009).
\newblock Minimax policies for adversarial and stochastic bandits.
\newblock In {\em COLT}, volume~7, pages 1--122.

\bibitem[Auer, 2002]{auer2002using}
Auer, P. (2002).
\newblock Using confidence bounds for exploitation-exploration trade-offs.
\newblock {\em Journal of Machine Learning Research}, 3(Nov):397--422.

\bibitem[Auer et~al., 2002]{auer2002finite}
Auer, P., Cesa-Bianchi, N., and Fischer, P. (2002).
\newblock Finite-time analysis of the multiarmed bandit problem.
\newblock {\em Machine learning}, 47(2-3):235--256.

\bibitem[Bercu et~al., 2015]{bercu2015concentration}
Bercu, B., Delyon, B., and Rio, E. (2015).
\newblock {\em Concentration inequalities for sums and martingales}.
\newblock Springer.

\bibitem[Berry and Fristedt, 1985]{berry1985bandit}
Berry, D.~A. and Fristedt, B. (1985).
\newblock Bandit problems: sequential allocation of experiments (monographs on
  statistics and applied probability).

\bibitem[Bietti et~al., 2018]{bietti2018contextual}
Bietti, A., Agarwal, A., and Langford, J. (2018).
\newblock A contextual bandit bake-off.
\newblock {\em arXiv preprint arXiv:1802.04064}.

\bibitem[Bowden and Trippa, 2017]{bowden2017unbiased}
Bowden, J. and Trippa, L. (2017).
\newblock Unbiased estimation for response adaptive clinical trials.
\newblock {\em Statistical methods in medical research}, 26(5):2376--2388.

\bibitem[Bubeck and Cesa-Bianchi, 2012]{bubeck2012regret}
Bubeck, S. and Cesa-Bianchi, N. (2012).
\newblock Regret analysis of stochastic and nonstochastic multi-armed bandit
  problems.
\newblock {\em arXiv preprint arXiv:1204.5721}.

\bibitem[Carpentier et~al., 2011]{carpentier2011upper}
Carpentier, A., Lazaric, A., Ghavamzadeh, M., Munos, R., and Auer, P. (2011).
\newblock Upper-confidence-bound algorithms for active learning in multi-armed
  bandits.
\newblock In {\em International Conference on Algorithmic Learning Theory},
  pages 189--203. Springer.

\bibitem[Chapelle and Li, 2011]{chapelle2011empirical}
Chapelle, O. and Li, L. (2011).
\newblock An empirical evaluation of thompson sampling.
\newblock {\em Advances in neural information processing systems},
  24:2249--2257.

\bibitem[Chu et~al., 2011]{chu2011contextual}
Chu, W., Li, L., Reyzin, L., and Schapire, R. (2011).
\newblock Contextual bandits with linear payoff functions.
\newblock In {\em Proceedings of the Fourteenth International Conference on
  Artificial Intelligence and Statistics}, pages 208--214.

\bibitem[Crump et~al., 2009]{crump2009dealing}
Crump, R.~K., Hotz, V.~J., Imbens, G.~W., and Mitnik, O.~A. (2009).
\newblock Dealing with limited overlap in estimation of average treatment
  effects.
\newblock {\em Biometrika}, 96(1):187--199.

\bibitem[Dimakopoulou et~al., 2017]{dimakopoulou2017estimation}
Dimakopoulou, M., Zhou, Z., Athey, S., and Imbens, G. (2017).
\newblock Estimation considerations in contextual bandits.
\newblock {\em arXiv preprint arXiv:1711.07077}.

\bibitem[Dimakopoulou et~al., 2019]{dimakopoulou2019balanced}
Dimakopoulou, M., Zhou, Z., Athey, S., and Imbens, G. (2019).
\newblock Balanced linear contextual bandits.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 3445--3453.

\bibitem[Filippi et~al., 2010]{FCGS2010}
Filippi, S., Cappe, O., Garivier, A., and Szepesv{\'a}ri, C. (2010).
\newblock Parametric bandits: The generalized linear case.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  586--594.

\bibitem[Garivier and Capp{\'e}, 2011]{garivier2011kl}
Garivier, A. and Capp{\'e}, O. (2011).
\newblock The kl-ucb algorithm for bounded stochastic bandits and beyond.
\newblock In {\em Proceedings of the 24th annual conference on learning
  theory}, pages 359--376. JMLR Workshop and Conference Proceedings.

\bibitem[Garivier and Moulines, 2011]{garivier2011upper}
Garivier, A. and Moulines, E. (2011).
\newblock On upper-confidence bound policies for switching bandit problems.
\newblock In {\em International Conference on Algorithmic Learning Theory},
  pages 174--188. Springer.

\bibitem[Ghavamzadeh et~al., 2015]{ghavamzadeh2015bayesian}
Ghavamzadeh, M., Mannor, S., Pineau, J., Tamar, A., et~al. (2015).
\newblock Bayesian reinforcement learning: A survey.
\newblock {\em Foundations and Trends{\textregistered} in Machine Learning},
  8(5-6):359--483.

\bibitem[Graepel et~al., 2010]{graepel2010web}
Graepel, T., Candela, J.~Q., Borchert, T., and Herbrich, R. (2010).
\newblock Web-scale bayesian click-through rate prediction for sponsored search
  advertising in microsoft's bing search engine.
\newblock In {\em ICML}.

\bibitem[Hadad et~al., 2019]{hadad2019confidence}
Hadad, V., Hirshberg, D.~A., Zhan, R., Wager, S., and Athey, S. (2019).
\newblock Confidence intervals for policy evaluation in adaptive experiments.
\newblock {\em arXiv preprint arXiv:1911.02768}.

\bibitem[Hall and Heyde, 2014]{hall2014martingale}
Hall, P. and Heyde, C.~C. (2014).
\newblock {\em Martingale limit theory and its application}.
\newblock Academic press.

\bibitem[Imbens and Rubin, 2015]{imbens2015causal}
Imbens, G.~W. and Rubin, D.~B. (2015).
\newblock {\em Causal inference in statistics, social, and biomedical
  sciences}.
\newblock Cambridge University Press.

\bibitem[Jun et~al., 2017]{JBNW2017}
Jun, K.-S., Bhargava, A., Nowak, R., and Willett, R. (2017).
\newblock Scalable generalized linear bandits: Online computation and hashing.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  99--109.

\bibitem[Kaufmann et~al., 2012]{kaufmann2012thompson}
Kaufmann, E., Korda, N., and Munos, R. (2012).
\newblock Thompson sampling: An asymptotically optimal finite-time analysis.
\newblock In {\em International conference on algorithmic learning theory},
  pages 199--213. Springer.

\bibitem[Lai and Robbins, 1985]{lai1985asymptotically}
Lai, T.~L. and Robbins, H. (1985).
\newblock Asymptotically efficient adaptive allocation rules.
\newblock {\em Advances in applied mathematics}, 6(1):4--22.

\bibitem[Lattimore and Szepesv{\'a}ri, 2020]{lattimore2020bandit}
Lattimore, T. and Szepesv{\'a}ri, C. (2020).
\newblock {\em Bandit algorithms}.
\newblock Cambridge University Press.

\bibitem[Li and Chapelle, 2012]{li2012open}
Li, L. and Chapelle, O. (2012).
\newblock Open problem: Regret bounds for thompson sampling.
\newblock In {\em Conference on Learning Theory}, pages 43--1. JMLR Workshop
  and Conference Proceedings.

\bibitem[Li et~al., 2010]{LCLS2010}
Li, L., Chu, W., Langford, J., and Schapire, R.~E. (2010).
\newblock A contextual-bandit approach to personalized news article
  recommendation.
\newblock In {\em Proceedings of the 19th international conference on World
  wide web}, pages 661--670. ACM.

\bibitem[Li et~al., 2017]{LLZ2017}
Li, L., Lu, Y., and Zhou, D. (2017).
\newblock Provably optimal algorithms for generalized linear contextual
  bandits.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 2071--2080. JMLR. org.

\bibitem[Luedtke and Van Der~Laan, 2016]{luedtke2016statistical}
Luedtke, A.~R. and Van Der~Laan, M.~J. (2016).
\newblock Statistical inference for the mean outcome under a possibly
  non-unique optimal treatment strategy.
\newblock {\em Annals of statistics}, 44(2):713.

\bibitem[May and Leslie, 2011]{may2011simulation}
May, B.~C. and Leslie, D.~S. (2011).
\newblock Simulation studies in optimistic bayesian sampling in
  contextual-bandit problems.
\newblock {\em Statistics Group, Department of Mathematics, University of
  Bristol}, 11(02).

\bibitem[Neel and Roth, 2018]{neel2018mitigating}
Neel, S. and Roth, A. (2018).
\newblock Mitigating bias in adaptive data gathering via differential privacy.
\newblock In {\em International Conference on Machine Learning}, pages
  3720--3729. PMLR.

\bibitem[Nie et~al., 2018]{nie2018adaptively}
Nie, X., Tian, X., Taylor, J., and Zou, J. (2018).
\newblock Why adaptively collected data have negative bias and how to correct
  for it.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 1261--1269. PMLR.

\bibitem[Robbins, 1952]{robbins1952some}
Robbins, H. (1952).
\newblock Some aspects of the sequential design of experiments.
\newblock {\em Bulletin of the American Mathematical Society}, 58(5):527--535.

\bibitem[Russo, 2016]{russo2016simple}
Russo, D. (2016).
\newblock Simple bayesian algorithms for best arm identification.
\newblock In {\em Conference on Learning Theory}, pages 1417--1418. PMLR.

\bibitem[Russo and Van~Roy, 2014]{RV2014}
Russo, D. and Van~Roy, B. (2014).
\newblock Learning to optimize via posterior sampling.
\newblock {\em Mathematics of Operations Research}, 39(4):1221--1243.

\bibitem[Russo and Van~Roy, 2016]{russo2016information}
Russo, D. and Van~Roy, B. (2016).
\newblock An information-theoretic analysis of thompson sampling.
\newblock {\em The Journal of Machine Learning Research}, 17(1):2442--2471.

\bibitem[Russo et~al., 2017]{russo2017tutorial}
Russo, D., Van~Roy, B., Kazerouni, A., Osband, I., and Wen, Z. (2017).
\newblock A tutorial on thompson sampling.
\newblock {\em arXiv preprint arXiv:1707.02038}.

\bibitem[Scott, 2010]{scott2010modern}
Scott, S.~L. (2010).
\newblock A modern bayesian look at the multi-armed bandit.
\newblock {\em Applied Stochastic Models in Business and Industry},
  26(6):639--658.

\bibitem[Shin et~al., 2019]{shin2019bias}
Shin, J., Ramdas, A., and Rinaldo, A. (2019).
\newblock On the bias, risk and consistency of sample means in multi-armed
  bandits.
\newblock {\em arXiv preprint arXiv:1902.00746}.

\bibitem[Sutton and Barto, 2018]{sutton2018reinforcement}
Sutton, R.~S. and Barto, A.~G. (2018).
\newblock {\em Reinforcement learning: An introduction}.
\newblock MIT press.

\bibitem[Thompson, 1933]{thompson1933likelihood}
Thompson, W.~R. (1933).
\newblock On the likelihood that one unknown probability exceeds another in
  view of the evidence of two samples.
\newblock {\em Biometrika}, 25(3/4):285--294.

\bibitem[Xu et~al., 2013]{xu2013estimation}
Xu, M., Qin, T., and Liu, T.-Y. (2013).
\newblock Estimation bias in multi-armed bandit algorithms for search
  advertising.
\newblock {\em Advances in Neural Information Processing Systems},
  26:2400--2408.

\bibitem[Zhang et~al., 2020]{zhang2020inference}
Zhang, K.~W., Janson, L., and Murphy, S.~A. (2020).
\newblock Inference for batched bandits.
\newblock {\em arXiv preprint arXiv:2002.03217}.

\end{thebibliography}
