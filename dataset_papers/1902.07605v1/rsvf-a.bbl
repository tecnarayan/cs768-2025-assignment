\begin{thebibliography}{43}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Auer et~al.(2010)Auer, Jaksch, and Ortner]{Auer2010a}
Auer, P., Jaksch, T., and Ortner, R.
\newblock {Near-optimal regret bounds for reinforcement learning}.
\newblock \emph{Journal of Machine Learning Research}, 11\penalty0
  (1):\penalty0 1563--1600, 2010.

\bibitem[Bagnell et~al.(2001)Bagnell, Ng, and Schneider]{Bagnell2001b}
Bagnell, J.~A., Ng, A.~Y., and Schneider, J.~G.
\newblock {Solving Uncertain Markov Decision Processes}.
\newblock \emph{Carnegie Mellon Research Showcase}, pp.\  948--957, 2001.

\bibitem[Ben-Tal et~al.(2009)Ben-Tal, {El Ghaoui}, and Nemirovski]{Ben-Tal2009}
Ben-Tal, A., {El Ghaoui}, L., and Nemirovski, A.
\newblock \emph{{Robust Optimization}}.
\newblock Princeton University Press, 2009.

\bibitem[Bertsekas \& Tsitsiklis(1996)Bertsekas and Tsitsiklis]{Bertsekas1996}
Bertsekas, D.~P. and Tsitsiklis, J.~N.
\newblock \emph{{Neuro-dynamic programming}}.
\newblock 1996.

\bibitem[Bertsimas et~al.(2017)Bertsimas, Kallus, and Gupta]{Bertsimas2017}
Bertsimas, D., Kallus, N., and Gupta, V.
\newblock \emph{{Data-driven robust optimization}}.
\newblock Springer Berlin Heidelberg, 2017.

\bibitem[Delgado et~al.(2016)Delgado, {De Barros}, Dias, and
  Sanner]{Delgado2016}
Delgado, K.~V., {De Barros}, L.~N., Dias, D.~B., and Sanner, S.
\newblock {Real-time dynamic programming for Markov decision processes with
  imprecise probabilities}.
\newblock \emph{Artificial Intelligence}, 230:\penalty0 192--223, 2016.

\bibitem[Dietterich et~al.(2013)Dietterich, Taleghan, and
  Crowley]{Dietterich2013}
Dietterich, T., Taleghan, M., and Crowley, M.
\newblock {PAC optimal planning for invasive species management: Improved
  exploration for reinforcement learning from simulator-defined MDPs.}
\newblock \emph{AAAI}, 2013.

\bibitem[Gelman et~al.(2014)Gelman, Carlin, Stern, and Rubin]{Gelman2014}
Gelman, A., Carlin, J.~B., Stern, H.~S., and Rubin, D.~B.
\newblock \emph{{Bayesian Data Analysis}}.
\newblock Chapman and Hall/CRC, 3rd edition, 2014.

\bibitem[Goyal \& Grand-Clement(2018)Goyal and Grand-Clement]{Goyal2018}
Goyal, V. and Grand-Clement, J.
\newblock {Robust Markov Decision Process: Beyond Rectangularity}.
\newblock Technical report, 2018.

\bibitem[Gupta(2015)]{Gupta2015}
Gupta, V.
\newblock {Near-Optimal Bayesian Ambiguity Sets for Distributionally Robust
  Optimization}.
\newblock 2015.

\bibitem[Hanasusanto \& Kuhn(2013)Hanasusanto and Kuhn]{Hanasusanto2013}
Hanasusanto, G. and Kuhn, D.
\newblock {Robust Data-Driven Dynamic Programming}.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2013.

\bibitem[Ho et~al.(2018)Ho, Petrik, and Wiesemann]{Ho2018}
Ho, C.~P., Petrik, M., and Wiesemann, W.
\newblock {Fast Bellman Updates for Robust MDPs}.
\newblock In \emph{International Conference on Machine Learning (ICML)},
  volume~80, pp.\  1979--1988, 2018.

\bibitem[Iyengar(2005)]{Iyengar2005}
Iyengar, G.~N.
\newblock {Robust dynamic programming}.
\newblock \emph{Mathematics of Operations Research}, 30\penalty0 (2):\penalty0
  257--280, 2005.

\bibitem[Jaksch et~al.(2010)Jaksch, Ortner, and Auer]{Auer2010}
Jaksch, T., Ortner, R., and Auer, P.
\newblock {Near-optimal Regret Bounds for Reinforcement Learning}.
\newblock \emph{Journal of Machine Learning Research}, 11\penalty0
  (1):\penalty0 1563--1600, 2010.

\bibitem[Jiang \& Li(2015)Jiang and Li]{Jiang2015b}
Jiang, N. and Li, L.
\newblock {Doubly Robust Off-policy Value Evaluation for Reinforcement
  Learning}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2015.

\bibitem[Kalyanasundaram et~al.(2002)Kalyanasundaram, Chong, and
  Shroff]{Kalyanasundaram2002}
Kalyanasundaram, S., Chong, E. K.~P., and Shroff, N.~B.
\newblock {Markov decision processes with uncertain transition rates:
  Sensitivity and robust control}.
\newblock In \emph{IEEE Conference on Decision and Control}, pp.\  3799--3804,
  2002.

\bibitem[Lange et~al.(2012)Lange, Gabel, and Riedmiller]{Lange2012}
Lange, S., Gabel, T., and Riedmiller, M.
\newblock {Batch Reinforcement Learning}.
\newblock In \emph{Reinforcement Learning}, pp.\  45--73. 2012.

\bibitem[Laroche \& Trichelair(2018)Laroche and Trichelair]{Laroche2017}
Laroche, R. and Trichelair, P.
\newblock {Safe Policy Improvement with Baseline Bootstrapping}, 2018.

\bibitem[{Le Tallec}(2007)]{LeTallec2007}
{Le Tallec}, Y.
\newblock \emph{{Robust, Risk-Sensitive, and Data-driven Control of Markov
  Decision Processes}}.
\newblock PhD thesis, MIT, 2007.

\bibitem[Li et~al.(2015)Li, Munos, and Szepesv{\'{a}}ri]{Li2015}
Li, L., Munos, R., and Szepesv{\'{a}}ri, C.
\newblock {Toward Minimax Off-policy Value Estimation}.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics (AISTATS)}, 2015.

\bibitem[Lim et~al.(2013)Lim, Xu, and Mannor]{Lim2013}
Lim, S.~H., Xu, H., and Mannor, S.
\newblock {Reinforcement Learning in Robust Markov Decision Processes}.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2013.

\bibitem[Mannor et~al.(2012)Mannor, Mebel, and Xu]{Mannor2012}
Mannor, S., Mebel, O., and Xu, H.
\newblock {Lightning does not strike twice: Robust MDPs with coupled
  uncertainty}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2012.

\bibitem[Mannor et~al.(2016)Mannor, Mebel, and Xu]{Mannor2016}
Mannor, S., Mebel, O., and Xu, H.
\newblock {Robust MDPs with k-rectangular uncertainty}.
\newblock \emph{Mathematics of Operations Research}, 41\penalty0 (4):\penalty0
  1484--1509, 2016.

\bibitem[Munos et~al.(2016)Munos, Stepleton, Harutyunyan, and
  Bellemare]{Munos2016}
Munos, R., Stepleton, T., Harutyunyan, A., and Bellemare, M.~G.
\newblock {Safe and Efficient Off-Policy Reinforcement Learning}.
\newblock In \emph{Conference on Neural Information Processing Systems (NIPS)},
  2016.

\bibitem[Murphy(2012)]{Murphy2012}
Murphy, K.
\newblock \emph{{Machine Learning: A Probabilistic Perspective}}.
\newblock 2012.

\bibitem[Nilim \& {El Ghaoui}(2005)Nilim and {El Ghaoui}]{Nilim2005}
Nilim, A. and {El Ghaoui}, L.
\newblock {Robust control of Markov decision processes with uncertain
  transition matrices}.
\newblock \emph{Operations Research}, 53\penalty0 (5):\penalty0 780--798, 2005.

\bibitem[Petrik(2012)]{Petrik2012}
Petrik, M.
\newblock {Approximate dynamic programming by minimizing distributionally
  robust bounds}.
\newblock In \emph{International Conference of Machine Learning (ICML)}, 2012.

\bibitem[Petrik \& Subramanian(2014)Petrik and Subramanian]{Petrik2014}
Petrik, M. and Subramanian, D.
\newblock {RAAM : The benefits of robustness in approximating aggregated MDPs
  in reinforcement learning}.
\newblock In \emph{Neural Information Processing Systems (NIPS)}, 2014.

\bibitem[Petrik et~al.(2016)Petrik, {Mohammad Ghavamzadeh}, and
  Chow]{Petrik2016a}
Petrik, M., {Mohammad Ghavamzadeh}, and Chow, Y.
\newblock {Safe Policy Improvement by Minimizing Robust Baseline Regret}.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2016.

\bibitem[Puterman(2005)]{Puterman2005}
Puterman, M.~L.
\newblock \emph{{Markov decision processes: Discrete stochastic dynamic
  programming}}.
\newblock 2005.

\bibitem[Shapiro et~al.(2014)Shapiro, Dentcheva, and Ruszczynski]{Shapiro2014}
Shapiro, A., Dentcheva, D., and Ruszczynski, A.
\newblock \emph{{Lectures on stochastic programming: Modeling and theory}}.
\newblock 2014.

\bibitem[Strehl \& Littman(2008)Strehl and Littman]{Strehl2008}
Strehl, A. and Littman, M.
\newblock {An analysis of model-based Interval Estimation for Markov Decision
  Processes}.
\newblock \emph{Journal of Computer and System Sciences}, 74:\penalty0
  1309--1331, 2008.

\bibitem[Strehl(2007)]{Strehl2008a}
Strehl, A.~L.
\newblock \emph{{Probably Approximately Correct (PAC) Exploration in
  Reinforcement Learning}}.
\newblock PhD thesis, Rutgers University, 2007.

\bibitem[Sutton \& Barto(1998)Sutton and Barto]{Sutton1998}
Sutton, R.~S. and Barto, A.
\newblock \emph{{Reinforcement learning}}.
\newblock 1998.

\bibitem[Taleghan et~al.(2015)Taleghan, Dietterich, Crowley, Hall, and
  Albers]{Taleghan2015}
Taleghan, M.~A., Dietterich, T.~G., Crowley, M., Hall, K., and Albers, H.~J.
\newblock {PAC Optimal MDP Planning with Application to Invasive Species
  Management}.
\newblock \emph{Journal of Machine Learning Research}, 16:\penalty0 3877--3903,
  2015.

\bibitem[Tamar et~al.(2014)Tamar, Mannor, and Xu]{Tamar2014a}
Tamar, A., Mannor, S., and Xu, H.
\newblock {Scaling up Robust MDPs Using Function Approximation}.
\newblock In \emph{International Conference of Machine Learning (ICML)}, 2014.

\bibitem[Thomas \& Brunskill(2016)Thomas and Brunskill]{Thomas2016}
Thomas, P.~S. and Brunskill, E.
\newblock {Data-efficient off-policy policy evaluation for reinforcement
  learning}.
\newblock In \emph{International Conference of Machine Learning (ICML)}, 2016.

\bibitem[Thomas et~al.(2015)Thomas, Teocharous, and Ghavamzadeh]{Thomas2015}
Thomas, P.~S., Teocharous, G., and Ghavamzadeh, M.
\newblock {High Confidence Off-Policy Evaluation}.
\newblock In \emph{Annual Conference of the AAAI}, 2015.

\bibitem[Tirinzoni et~al.(2018)Tirinzoni, Milano, Chen, and
  Ziebart]{Tirinzoni2018}
Tirinzoni, A., Milano, P., Chen, X., and Ziebart, B.~D.
\newblock {Policy-Conditioned Uncertainty Sets for Robust Markov Decision
  Processes}.
\newblock In \emph{Neural Information Processing Systems (NIPS)}, 2018.

\bibitem[Weissman et~al.(2003)Weissman, Ordentlich, Seroussi, Verdu, and
  Weinberger]{Weissman2003xx}
Weissman, T., Ordentlich, E., Seroussi, G., Verdu, S., and Weinberger, M.~J.
\newblock {Inequalities for the L1 deviation of the empirical distribution}.
\newblock 2003.

\bibitem[Wiesemann et~al.(2013)Wiesemann, Kuhn, and Rustem]{Wiesemann2013}
Wiesemann, W., Kuhn, D., and Rustem, B.
\newblock {Robust Markov decision processes}.
\newblock \emph{Mathematics of Operations Research}, 38\penalty0 (1):\penalty0
  153--183, 2013.

\bibitem[Xu \& Mannor(2006)Xu and Mannor]{Xu2006}
Xu, H. and Mannor, S.
\newblock {The robustness-performance tradeoff in Markov decision processes}.
\newblock \emph{Advances in Neural Information Processing Systems (NIPS)},
  2006.

\bibitem[Xu \& Mannor(2009)Xu and Mannor]{Xu2009}
Xu, H. and Mannor, S.
\newblock {Parametric regret in uncertain Markov decision processes}.
\newblock In \emph{IEEE Conference on Decision and Control (CDC)}, pp.\
  3606--3613, 2009.

\end{thebibliography}
