\begin{thebibliography}{}

\bibitem[Abadi et~al., 2015]{tensorflow2015-whitepaper}
Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado,
  G.~S., Davis, A., Dean, J., Devin, M., Ghemawat, S., Goodfellow, I., Harp,
  A., Irving, G., Isard, M., Jia, Y., Jozefowicz, R., Kaiser, L., Kudlur, M.,
  Levenberg, J., Man\'{e}, D., Monga, R., Moore, S., Murray, D., Olah, C.,
  Schuster, M., Shlens, J., Steiner, B., Sutskever, I., Talwar, K., Tucker, P.,
  Vanhoucke, V., Vasudevan, V., Vi\'{e}gas, F., Vinyals, O., Warden, P.,
  Wattenberg, M., Wicke, M., Yu, Y., and Zheng, X. (2015).
\newblock {TensorFlow}: Large-scale machine learning on heterogeneous systems.
\newblock Software available from tensorflow.org.

\bibitem[{Aboleth Developers}, 2017]{aboleth2017aboleth}
{Aboleth Developers} (2017).
\newblock Aboleth.
\newblock \url{https://github.com/data61/aboleth}.

\bibitem[Al-Rfou et~al., 2016]{alrfou2016theano}
Al-Rfou, R., Alain, G., Almahairi, A., Angermueller, C., Bahdanau, D., Ballas,
  N., Bastien, F., Bayer, J., Belikov, A., Belopolsky, A., Bengio, Y.,
  Bergeron, A., Bergstra, J., Bisson, V., {Bleecher Snyder}, J., Bouchard, N.,
  Boulanger-Lewandowski, N., Bouthillier, X., de~Br\'ebisson, A., Breuleux, O.,
  Carrier, P.-L., Cho, K., Chorowski, J., Christiano, P., Cooijmans, T.,
  C\^ot\'e, M.-A., C\^ot\'e, M., Courville, A., Dauphin, Y.~N., Delalleau, O.,
  Demouth, J., Desjardins, G., Dieleman, S., Dinh, L., Ducoffe, M., Dumoulin,
  V., {Ebrahimi Kahou}, S., Erhan, D., Fan, Z., Firat, O., Germain, M., Glorot,
  X., Goodfellow, I., Graham, M., Gulcehre, C., Hamel, P., Harlouchet, I.,
  Heng, J.-P., Hidasi, B., Honari, S., Jain, A., Jean, S., Jia, K., Korobov,
  M., Kulkarni, V., Lamb, A., Lamblin, P., Larsen, E., Laurent, C., Lee, S.,
  Lefrancois, S., Lemieux, S., L\'eonard, N., Lin, Z., Livezey, J.~A., Lorenz,
  C., Lowin, J., Ma, Q., Manzagol, P.-A., Mastropietro, O., McGibbon, R.~T.,
  Memisevic, R., van Merri\"enboer, B., Michalski, V., Mirza, M., Orlandi, A.,
  Pal, C., Pascanu, R., Pezeshki, M., Raffel, C., Renshaw, D., Rocklin, M.,
  Romero, A., Roth, M., Sadowski, P., Salvatier, J., Savard, F., Schl\"uter,
  J., Schulman, J., Schwartz, G., Serban, I.~V., Serdyuk, D., Shabanian, S.,
  Simon, E., Spieckermann, S., Subramanyam, S.~R., Sygnowski, J., Tanguay, J.,
  van Tulder, G., Turian, J., Urban, S., Vincent, P., Visin, F., de~Vries, H.,
  Warde-Farley, D., Webb, D.~J., Willson, M., Xu, K., Xue, L., Yao, L., Zhang,
  S., and Zhang, Y. (2016).
\newblock {Theano: A {Python} framework for fast computation of mathematical
  expressions}.
\newblock {\em arXiv preprint arXiv:1605.02688}.

\bibitem[Al-Shedivat et~al., 2017]{al2017learning}
Al-Shedivat, M., Wilson, A.~G., Saatchi, Y., Hu, Z., and Xing, E.~P. (2017).
\newblock Learning scalable deep kernels with recurrent structure.
\newblock {\em Journal of Machine Learning Research}, 18(1).

\bibitem[Azizzadenesheli et~al., 2018]{azizzadenesheli2018bdqn}
Azizzadenesheli, K., Brunskill, E., and Anandkumar, A. (2018).
\newblock Efficient exploration through bayesian deep q-networks.
\newblock {\em arXiv preprint arXiv:1802.04412}.

\bibitem[Bingham et~al., 2018]{bingham2018pyro}
Bingham, E., Chen, J.~P., Jankowiak, M., Obermeyer, F., Pradhan, N.,
  Karaletsos, T., Singh, R., Szerlip, P., Horsfall, P., and Goodman, N.~D.
  (2018).
\newblock {Pyro: Deep Universal Probabilistic Programming}.
\newblock {\em arXiv preprint arXiv:1810.09538}.

\bibitem[Blundell et~al., 2015]{blundell2015weight}
Blundell, C., Cornebise, J., Kavukcuoglu, K., and Wierstra, D. (2015).
\newblock Weight uncertainty in neural networks.
\newblock In {\em International Conference on Machine Learning}.

\bibitem[Bui et~al., 2016]{bui2016deepgpep}
Bui, T., Hernandez-Lobato, D., Hernandez-Lobato, J., Li, Y., and Turner, R.
  (2016).
\newblock Deep gaussian processes for regression using approximate expectation
  propagation.
\newblock In Balcan, M.~F. and Weinberger, K.~Q., editors, {\em Proceedings of
  The 33rd International Conference on Machine Learning}, volume~48 of {\em
  Proceedings of Machine Learning Research}, pages 1472--1481, New York, New
  York, USA. PMLR.

\bibitem[Carpenter et~al., 2016]{carpenter2016stan}
Carpenter, B., Gelman, A., Hoffman, M.~D., Lee, D., Goodrich, B., Betancourt,
  M., Brubaker, M., Guo, J., Li, P., and Riddell, A. (2016).
\newblock Stan: {A} probabilistic programming language.
\newblock {\em Journal of Statistical Software}.

\bibitem[Chelba et~al., 2013]{chelba2013one}
Chelba, C., Mikolov, T., Schuster, M., Ge, Q., Brants, T., and Koehn, P.
  (2013).
\newblock One billion word benchmark for measuring progress in statistical
  language modeling.
\newblock {\em CoRR}, abs/1312.3005.

\bibitem[Chen et~al., 2015]{chen2015mxnet}
Chen, T., Li, M., Li, Y., Lin, M., Wang, N., Wang, M., Xiao, T., Xu, B., Zhang,
  C., and Zhang, Z. (2015).
\newblock {MXNet}: A flexible and efficient machine learning library for
  heterogeneous distributed systems.
\newblock {\em arXiv preprint arXiv:1512.01274}.

\bibitem[Chollet, 2016]{chollet2015keras}
Chollet, F. (2016).
\newblock Keras.
\newblock \url{https://github.com/fchollet/keras}.

\bibitem[Collobert et~al., 2011]{collobert2011torch}
Collobert, R., Kavukcuoglu, K., and Farabet, C. (2011).
\newblock Torch7: A matlab-like environment for machine learning.
\newblock In {\em BigLearn, NIPS Workshop}.

\bibitem[Damianou and Lawrence, 2013]{damianou2013deep}
Damianou, A. and Lawrence, N. (2013).
\newblock Deep gaussian processes.
\newblock In {\em Artificial Intelligence and Statistics}, pages 207--215.

\bibitem[Dillon et~al., 2017]{dillon2017tensorflow}
Dillon, J.~V., Langmore, I., Tran, D., Brevdo, E., Vasudevan, S., Moore, D.,
  Patton, B., Alemi, A., Hoffman, M., and Saurous, R.~A. (2017).
\newblock {TensorFlow Distributions}.
\newblock {\em arXiv preprint arXiv:1711.10604}.

\bibitem[Dinh et~al., 2017]{dinh2017density}
Dinh, L., Sohl-Dickstein, J., and Bengio, S. (2017).
\newblock Density estimation using real nvp.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Fortunato et~al., 2017]{fortunato2017bayesian}
Fortunato, M., Blundell, C., and Vinyals, O. (2017).
\newblock Bayesian recurrent neural networks.
\newblock {\em arXiv preprint arXiv:1704.02798}.

\bibitem[Gal and Ghahramani, 2016]{gal2016dropout}
Gal, Y. and Ghahramani, Z. (2016).
\newblock Dropout as a bayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In {\em international conference on machine learning}, pages
  1050--1059.

\bibitem[Gal et~al., 2016]{gal2016deeppilco}
Gal, Y., McAllister, R., and Rasmussen, C.~E. (2016).
\newblock Improving pilco with bayesian neural network dynamics models.
\newblock In {\em Data-Efficient Machine Learning workshop, ICML}, volume~4.

\bibitem[Gardner et~al., 2018]{gardner2018gpytorch}
Gardner, J.~R., Pleiss, G., Bindel, D., Weinberger, K.~Q., and Wilson, A.~G.
  (2018).
\newblock Gpytorch: Blackbox matrix-matrix gaussian process inference with gpu
  acceleration.
\newblock In {\em NeurIPS}.

\bibitem[Germain et~al., 2015]{germain2015made}
Germain, M., Gregor, K., Murray, I., and Larochelle, H. (2015).
\newblock Made: Masked autoencoder for distribution estimation.
\newblock In {\em International Conference on Machine Learning}, pages
  881--889.

\bibitem[Gomez et~al., 2017]{gomez2017reversible}
Gomez, A.~N., Ren, M., Urtasun, R., and Grosse, R.~B. (2017).
\newblock The reversible residual network: Backpropagation without storing
  activations.
\newblock In {\em Neural Information Processing Systems}.

\bibitem[Goodman et~al., 2012]{goodman2012church}
Goodman, N., Mansinghka, V., Roy, D.~M., Bonawitz, K., and Tenenbaum, J.~B.
  (2012).
\newblock Church: a language for generative models.
\newblock {\em arXiv preprint arXiv:1206.3255}.

\bibitem[{GPy}, 2012]{gpy2014}
{GPy} (since 2012).
\newblock {GPy}: A gaussian process framework in python.
\newblock \url{http://github.com/SheffieldML/GPy}.

\bibitem[Hafner et~al., 2018a]{hafner2018planet}
Hafner, D., Lillicrap, T., Fischer, I., Villegas, R., Ha, D., Lee, H., and
  Davidson, J. (2018a).
\newblock Learning latent dynamics for planning from pixels.
\newblock {\em arXiv preprint arXiv:1811.04551}.

\bibitem[Hafner et~al., 2018b]{hafner2018reliable}
Hafner, D., Tran, D., Irpan, A., Lillicrap, T., and Davidson, J. (2018b).
\newblock Reliable uncertainty estimates in deep neural networks using noise
  contrastive priors.
\newblock {\em arXiv preprint}.

\bibitem[Hensman et~al., 2013]{hensman2013svi}
Hensman, J., Fusi, N., and Lawrence, N.~D. (2013).
\newblock Gaussian processes for big data.
\newblock In {\em Conference on Uncertainty in Artificial Intelligence}.

\bibitem[Hern\'{a}ndez-Lobato and Adams, 2015]{miguel2015pbp}
Hern\'{a}ndez-Lobato, J.~M. and Adams, R.~P. (2015).
\newblock Probabilistic backpropagation for scalable learning of bayesian
  neural networks.
\newblock In {\em Proceedings of the 32Nd International Conference on
  International Conference on Machine Learning - Volume 37}, ICML'15, pages
  1861--1869. JMLR.org.

\bibitem[Jia et~al., 2014]{jia2014caffe}
Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R.,
  Guadarrama, S., and Darrell, T. (2014).
\newblock Caffe: Convolutional architecture for fast feature embedding.
\newblock In {\em Proceedings of the 22nd ACM international conference on
  Multimedia}, pages 675--678. ACM.

\bibitem[John and Hensman, 2018]{john2018large}
John, S.~T. and Hensman, J. (2018).
\newblock Large-scale cox process inference using variational fourier features.
\newblock {\em arXiv preprint arXiv:1804.01016}.

\bibitem[Jouppi et~al., 2017]{jouppi2017datacenter}
Jouppi, N.~P., Young, C., Patil, N., Patterson, D., Agrawal, G., Bajwa, R.,
  Bates, S., Bhatia, S., Boden, N., Borchers, A., et~al. (2017).
\newblock In-datacenter performance analysis of a tensor processing unit.
\newblock In {\em Proceedings of the 44th Annual International Symposium on
  Computer Architecture}.

\bibitem[Kingma and Welling, 2014]{kingma2014auto}
Kingma, D.~P. and Welling, M. (2014).
\newblock Auto-encoding variational {B}ayes.
\newblock In {\em International Conference on Learning Representations}.

\bibitem[Kiselyov and Shan, 2009]{kiselyov2009embedded}
Kiselyov, O. and Shan, C.-C. (2009).
\newblock Embedded probabilistic programming.
\newblock In {\em DSL}, volume 5658, pages 360--384. Springer.

\bibitem[Laumann and Shridhar, 2018]{laumann2018bayesian}
Laumann, F. and Shridhar, K. (2018).
\newblock Bayesian convolutional neural networks.
\newblock {\em arXiv preprint arXiv:1806.05978}.

\bibitem[Louizos and Welling, 2017]{louizos2017multiplicative}
Louizos, C. and Welling, M. (2017).
\newblock Multiplicative normalizing flows for variational bayesian neural
  networks.
\newblock {\em arXiv preprint arXiv:1703.01961}.

\bibitem[Matthews et~al., 2017]{GPflow2017}
Matthews, A. G. d.~G., {van der Wilk}, M., Nickson, T., Fujii, K.,
  {Boukouvalas}, A., {Le{\'o}n-Villagr{\'a}}, P., Ghahramani, Z., and Hensman,
  J. (2017).
\newblock {{GP}flow: A {G}aussian process library using {T}ensor{F}low}.
\newblock {\em Journal of Machine Learning Research}, 18(40):1--6.

\bibitem[Narayanan et~al., 2016]{narayanan2016probabilistic}
Narayanan, P., Carette, J., Romano, W., Shan, C.-c., and Zinkov, R. (2016).
\newblock {Probabilistic Inference by Program Transformation in Hakaru (System
  Description)}.
\newblock In {\em International Symposium on Functional and Logic Programming},
  pages 62--79, Cham. Springer, Cham.

\bibitem[Neal, 1995]{neal1995software}
Neal, R. (1995).
\newblock Software for flexible bayesian modeling and markov chain sampling.
\newblock \url{https://www.cs.toronto.edu/~radford/fbm.software.html}.

\bibitem[Parmar et~al., 2018]{parmar2018image}
Parmar, N., Vaswani, A., Uszkoreit, J., Kaiser, {\L}., Shazeer, N., Ku, A., and
  Tran, D. (2018).
\newblock Image transformer.
\newblock In {\em International Conference on Machine Learning}.

\bibitem[{Probtorch Developers}, 2017]{probtorch2017probtorch}
{Probtorch Developers} (2017).
\newblock Probtorch.
\newblock \url{https://github.com/probtorch/probtorch}.

\bibitem[Rasmussen and Nickisch, 2010]{rasmussen2010gaussian}
Rasmussen, C.~E. and Nickisch, H. (2010).
\newblock Gaussian processes for machine learning (gpml) toolbox.
\newblock {\em Journal of machine learning research}, 11(Nov):3011--3015.

\bibitem[Rezende and Mohamed, 2015]{rezende2015variational}
Rezende, D.~J. and Mohamed, S. (2015).
\newblock Variational inference with normalizing flows.
\newblock In {\em International Conference on Machine Learning}.

\bibitem[S. and N., 2016]{guadarrama2016slim}
S., G. and N., S. (2016).
\newblock {TensorFlow-Slim}: A lightweight library for defining, training and
  evaluating complex models in {TensorFlow}.

\bibitem[Salimans et~al., 2017]{salimans2017pixelcnnpp}
Salimans, T., Karpathy, A., Chen, X., and Kingma, D.~P. (2017).
\newblock {PixelCNN++}: Improving the pixelcnn with discretized logistic
  mixture likelihood and other modifications.
\newblock {\em arXiv preprint arXiv:1701.05517}.

\bibitem[Salimbeni and Deisenroth, 2017]{salimbeni2017doubly}
Salimbeni, H. and Deisenroth, M. (2017).
\newblock Doubly stochastic variational inference for deep gaussian processes.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4588--4599.

\bibitem[Shazeer et~al., 2018]{shazeer2018mesh}
Shazeer, N., Cheng, Y., Parmar, N., Tran, D., Vaswani, A., Koanantakool, P.,
  Hawkins, P., Lee, H., Hong, M., Young, C., Sepassi, R., and Hechtman, B.
  (2018).
\newblock {Mesh-TensorFlow}: Deep learning for supercomputers.
\newblock In {\em Neural Information Processing Systems}.

\bibitem[Tran et~al., 2018]{tran2018simple}
Tran, D., Hoffman, M.~D., Moore, D., Suter, C., Vasudevan, S., Radul, A.,
  Johnson, M., and Saurous, R.~A. (2018).
\newblock Simple, distributed, and accelerated probabilistic programming.
\newblock In {\em Neural Information Processing Systems}.

\bibitem[Tran et~al., 2016]{tran2016edward}
Tran, D., Kucukelbir, A., Dieng, A.~B., Rudolph, M., Liang, D., and Blei, D.~M.
  (2016).
\newblock {Edward: A library for probabilistic modeling, inference, and
  criticism}.
\newblock {\em arXiv preprint arXiv:1610.09787}.

\bibitem[Vanhatalo et~al., 2013]{vanhatalo2013gpstuff}
Vanhatalo, J., Riihim{\"a}ki, J., Hartikainen, J., Jyl{\"a}nki, P., Tolvanen,
  V., and Vehtari, A. (2013).
\newblock Gpstuff: Bayesian modeling with gaussian processes.
\newblock {\em Journal of Machine Learning Research}, 14(Apr):1175--1179.

\bibitem[Vaswani et~al., 2018]{vaswani2018tensor2tensor}
Vaswani, A., Bengio, S., Brevdo, E., Chollet, F., Gomez, A.~N., Gouws, S.,
  Jones, L., Kaiser, L., Kalchbrenner, N., Parmar, N., Sepassi, R., Shazeer,
  N., and Uszkoreit, J. (2018).
\newblock Tensor2tensor for neural machine translation.
\newblock {\em CoRR}, abs/1803.07416.

\bibitem[Wen et~al., 2018]{wen2018flipout}
Wen, Y., Vicol, P., Ba, J., Tran, D., and Grosse, R. (2018).
\newblock Flipout: Efficient pseudo-independent weight perturbations on
  mini-batches.
\newblock In {\em International Conference on Learning Representations}.

\end{thebibliography}
