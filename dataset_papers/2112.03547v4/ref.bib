% CG
@inproceedings{guestrin2002coordinated,
  title={Coordinated reinforcement learning},
  author={Guestrin, Carlos and Lagoudakis, Michail and Parr, Ronald},
  booktitle={ICML},
  volume={2},
  pages={227--234},
  year={2002},
  organization={Citeseer}
}

@article{kok2006collaborative,
  title={Collaborative multiagent reinforcement learning by payoff propagation},
  author={Kok, Jelle R and Vlassis, Nikos},
  journal={Journal of Machine Learning Research},
  volume={7},
  pages={1789--1828},
  year={2006}
}

@inproceedings{guestrin2002context,
  title={Context-specific multiagent coordination and planning with factored MDPs},
  author={Guestrin, Carlos and Venkataraman, Shobha and Koller, Daphne},
  booktitle={AAAI/IAAI},
  pages={253--259},
  year={2002}
}

@inproceedings{guestrin2001multiagent,
  title={Multiagent Planning with Factored MDPs.},
  author={Guestrin, Carlos and Koller, Daphne and Parr, Ronald},
  booktitle={NIPS},
  volume={1},
  pages={1523--1530},
  year={2001}
}

% Relative Overgeneralization
@article{panait2006biasing,
  title={Biasing coevolutionary search for optimal multiagent behaviors},
  author={Panait, Liviu and Luke, Sean and Wiegand, R Paul},
  journal={IEEE Transactions on Evolutionary Computation},
  volume={10},
  number={6},
  pages={629--645},
  year={2006},
  publisher={IEEE}
}

@article{wei2016lenient,
  title={Lenient learning in independent-learner stochastic cooperative games},
  author={Wei, Ermo and Luke, Sean},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2914--2955},
  year={2016},
  publisher={JMLR. org}
}

% DCG
@inproceedings{bohmer2020deep,
	title={Deep coordination graphs},
	author={B{\"o}hmer, Wendelin and Kurin, Vitaly and Whiteson, Shimon},
	booktitle={International Conference on Machine Learning},
	pages={980--991},
	year={2020},
	organization={PMLR}
}

@article{wang2021context,
	title={Context-Aware Sparse Deep Coordination Graphs},
	author={Wang, Tonghan and Zeng, Liang and Dong, Weijun and Yang, Qianlan and Yu, Yang and Zhang, Chongjie},
	journal={arXiv preprint arXiv:2106.02886},
	year={2021}
}

@inproceedings{castellini2019representational,
	title={The Representational Capacity of Action-Value Networks for Multi-Agent Reinforcement Learning},
	author={Castellini, Jacopo and Oliehoek, Frans A and Savani, Rahul and Whiteson, Shimon},
	booktitle={AAMAS 2019: The 18th International Conference on Autonomous Agents and MultiAgent Systems},
	pages={1862--1864},
	year={2019},
	organization={International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)}
}

% VDN
@inproceedings{sunehag2018value,
	title={Value-Decomposition Networks For Cooperative Multi-Agent Learning Based On Team Reward},
	author={Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others},
	booktitle={Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
	pages={2085--2087},
	year={2018}
}

% Morphologies
@inproceedings{pathak2019learning,
	title={Learning to Control Self-Assembling Morphologies: A Study of Generalization via Modularity},
	author={Pathak, Deepak and Lu, Christopher and Darrell, Trevor and Isola, Phillip and Efros, Alexei A},
	booktitle={Advances in Neural Information Processing Systems},
	volume={32},
	pages={2295--2305},
	year={2019}
}

% Implementation Details
@article{edmonds1965paths,
  title={Paths, trees, and flowers},
  author={Edmonds, Jack},
  journal={Canadian Journal of mathematics},
  volume={17},
  pages={449--467},
  year={1965},
  publisher={Cambridge University Press}
}

%DCOP
@article{fioretto2018distributed,
  title={Distributed constraint optimization problems and applications: A survey},
  author={Fioretto, Ferdinando and Pontelli, Enrico and Yeoh, William},
  journal={Journal of Artificial Intelligence Research},
  volume={61},
  pages={623--698},
  year={2018}
}

%maxsum
@book{pearl1988probabilistic,
  title={Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference},
  author={Pearl, Judea},
  year={1988},
  publisher={Morgan Kaufmann}
}

@inproceedings{stranders2009decentralised,
  title={Decentralised coordination of mobile sensors using the max-sum algorithm},
  author={Stranders, Ruben and Farinelli, Alessandro and Rogers, Alex and Jennings, Nicholas R},
  booktitle={Twenty-First International Joint Conference on Artificial Intelligence},
  year={2009}
}

@inproceedings{zhang2013coordinating,
  title={Coordinating multi-agent reinforcement learning with limited communication},
  author={Zhang, Chongjie and Lesser, Victor},
  booktitle={Proceedings of the 2013 international conference on Autonomous agents and multi-agent systems},
  pages={1101--1108},
  year={2013}
}

% Dec-POMDPs
@book{oliehoek2016concise,
  title={A concise introduction to decentralized POMDPs},
  author={Oliehoek, Frans A and Amato, Christopher and others},
  volume={1},
  year={2016},
  publisher={Springer}
}

% sensor
@book{lesser2003distributed,
  title={Distributed sensor networks: A multiagent perspective},
  author={Lesser, Victor and Ortiz Jr, Charles L and Tambe, Milind},
  volume={9},
  year={2003},
  publisher={Springer Science \& Business Media}
}

@inproceedings{zhang2011coordinated,
  title={Coordinated multi-agent reinforcement learning in networked distributed POMDPs},
  author={Zhang, Chongjie and Lesser, Victor},
  booktitle={Twenty-Fifth AAAI Conference on Artificial Intelligence},
  year={2011}
}

% applications
@article{van2016coordinated,
	title={Coordinated deep reinforcement learners for traffic light control},
	author={Van der Pol, Elise and Oliehoek, Frans A},
	journal={Proceedings of Learning, Inference and Control of Multi-Agent Systems (at NIPS 2016)},
	year={2016}
}

@article{ye2015multi,
	title={A multi-agent framework for packet routing in wireless sensor networks},
	author={Ye, Dayong and Zhang, Minjie and Yang, Yun},
	journal={Sensors},
	volume={15},
	number={5},
	pages={10026--10047},
	year={2015},
	publisher={Multidisciplinary Digital Publishing Institute}
}

@article{alonso2017multi,
	title={Multi-robot formation control and object transport in dynamic environments via constrained optimization},
	author={Alonso-Mora, Javier and Baker, Stuart and Rus, Daniela},
	journal={The International Journal of Robotics Research},
	volume={36},
	number={9},
	pages={1000--1021},
	year={2017},
	publisher={SAGE Publications Sage UK: London, England}
}

%NDQ
@inproceedings{wang2019learning,
	title={Learning Nearly Decomposable Value Functions Via Communication Minimization},
	author={Wang, Tonghan and Wang, Jianhao and Zheng, Chongyi and Zhang, Chongjie},
	booktitle={International Conference on Learning Representations},
	year={2020}
}

%QMIX
@article{rashid2020monotonic,
	title={Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning},
	author={Rashid, Tabish and Samvelyan, Mikayel and De Witt, Christian Schroeder and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
	journal={arXiv preprint arXiv:2003.08839},
	year={2020}
}

%maddpg
@article{lowe2017multi,
  title={Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments},
  author={Lowe, Ryan and Wu, Yi and Tamar, Aviv and Harb, Jean and Abbeel, Pieter and Mordatch, Igor},
  journal={Neural Information Processing Systems (NIPS)},
  year={2017}
}

% inductive bias
@article{battaglia2018relational,
	title={Relational inductive biases, deep learning, and graph networks},
	author={Battaglia, Peter W and Hamrick, Jessica B and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and others},
	journal={arXiv preprint arXiv:1806.01261},
	year={2018}
}

%DCOP hardness
@article{dagum1993approximating,
  title={Approximating probabilistic inference in Bayesian belief networks is NP-hard},
  author={Dagum, Paul and Luby, Michael},
  journal={Artificial intelligence},
  volume={60},
  number={1},
  pages={141--153},
  year={1993},
  publisher={Elsevier}
}

@article{park2004complexity,
  title={Complexity results and approximation strategies for MAP explanations},
  author={Park, James D and Darwiche, Adnan},
  journal={Journal of Artificial Intelligence Research},
  volume={21},
  pages={101--133},
  year={2004}
}


@article{hasselt2010double,
  title={Double Q-learning},
  author={Hasselt, Hado},
  journal={Advances in neural information processing systems},
  volume={23},
  pages={2613--2621},
  year={2010}
}

@inproceedings{son2019qtran,
	title={QTRAN: Learning to Factorize with Transformation for Cooperative Multi-Agent Reinforcement Learning},
	author={Son, Kyunghwan and Kim, Daewoo and Kang, Wan Ju and Hostallero, David Earl and Yi, Yung},
	booktitle={International Conference on Machine Learning},
	pages={5887--5896},
	year={2019}
}

%QPLEX
@inproceedings{wang2020QPLEX,
	title={QPLEX: Duplex Dueling Multi-Agent Q-Learning},
	author={Wang, Jianhao and Ren, Zhizhou and Liu, Terry and Yang, Yu and Zhang, Chongjie},
	booktitle={International Conference on Learning Representations},
	year={2021}
}

@article{samvelyan19smac,
  title = {{The} {StarCraft} {Multi}-{Agent} {Challenge}},
  author = {Mikayel Samvelyan and Tabish Rashid and Christian Schroeder de Witt and Gregory Farquhar and Nantas Nardelli and Tim G. J. Rudner and Chia-Man Hung and Philiph H. S. Torr and Jakob Foerster and Shimon Whiteson},
  journal = {CoRR},
  volume = {abs/1902.04043},
  year = {2019},
}

%wqmix
@article{rashid2020weighted,
  title={Weighted QMIX: Expanding monotonic value function factorisation for deep multi- agent reinforcement learning},
  author={Rashid, T and Farquhar, G and Peng, B and Whiteson, S},
  journal={NeurIPS Proceedings 2020},
  year={2020},
  publisher={NeurIPS}
}


%-----related works-----
@article{kraemer2016multi,
  title={Multi-agent reinforcement learning as a rehearsal for decentralized planning},
  author={Kraemer, Landon and Banerjee, Bikramjit},
  journal={Neurocomputing},
  volume={190},
  pages={82--94},
  year={2016},
  publisher={Elsevier}
}

@article{oroojlooyjadid2019review,
  title={A review of cooperative multi-agent deep reinforcement learning},
  author={OroojlooyJadid, Afshin and Hajinezhad, Davood},
  journal={arXiv preprint arXiv:1908.03963},
  year={2019}
}

@inproceedings{tan1993multi,
  title={Multi-agent reinforcement learning: Independent vs. cooperative agents},
  author={Tan, Ming},
  booktitle={Proceedings of the tenth international conference on machine learning},
  pages={330--337},
  year={1993}
}

@inproceedings{foerster2017stabilising,
  title={Stabilising experience replay for deep multi-agent reinforcement learning},
  author={Foerster, Jakob and Nardelli, Nantas and Farquhar, Gregory and Afouras, Triantafyllos and Torr, Philip HS and Kohli, Pushmeet and Whiteson, Shimon},
  booktitle={International conference on machine learning},
  pages={1146--1155},
  year={2017},
  organization={PMLR}
}

@article{wen2019probabilistic,
  title={Probabilistic recursive reasoning for multi-agent reinforcement learning},
  author={Wen, Ying and Yang, Yaodong and Luo, Rui and Wang, Jun and Pan, Wei},
  journal={arXiv preprint arXiv:1901.09207},
  year={2019}
}

@inproceedings{foerster2018counterfactual,
	title={Counterfactual multi-agent policy gradients},
	author={Foerster, Jakob N and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
	booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
	year={2018}
}

@article{wang2020off,
	title={Off-Policy Multi-Agent Decomposed Policy Gradients},
	author={Wang, Yihan and Han, Beining and Wang, Tonghan and Dong, Heng and Zhang, Chongjie},
	journal={arXiv preprint arXiv:2007.12322},
	year={2020}
}


@inproceedings{wang2020multi,
	title={Multi-Agent Reinforcement Learning with Emergent Roles},
	author={Wang, Tonghan and Dong, Heng and Lesser, Victor and Zhang, Chongjie},
	booktitle={International Conference on Machine Learning},
	year={2020}
}

@inproceedings{jiang2021emergence,
  title={The Emergence of Individuality},
  author={Jiang, Jiechuan and Lu, Zongqing},
  booktitle={International Conference on Machine Learning},
  pages={4992--5001},
  year={2021},
  organization={PMLR}
}

@article{wang2020rode,
  title={Rode: Learning roles to decompose multi-agent tasks},
  author={Wang, Tonghan and Gupta, Tarun and Mahajan, Anuj and Peng, Bei and Whiteson, Shimon and Zhang, Chongjie},
  journal={arXiv preprint arXiv:2010.01523},
  year={2020}
}

@article{singh2018learning,
  title={Learning when to communicate at scale in multiagent cooperative and competitive tasks},
  author={Singh, Amanpreet and Jain, Tushar and Sukhbaatar, Sainbayar},
  journal={arXiv preprint arXiv:1812.09755},
  year={2018}
}

%Communication
@inproceedings{das2019tarmac,
	title={Tarmac: Targeted multi-agent communication},
	author={Das, Abhishek and Gervet, Th{\'e}ophile and Romoff, Joshua and Batra, Dhruv and Parikh, Devi and Rabbat, Mike and Pineau, Joelle},
	booktitle={International Conference on Machine Learning},
	pages={1538--1546},
	year={2019}
}

@article{li2020deep,
  title={Deep implicit coordination graphs for multi-agent reinforcement learning},
  author={Li, Sheng and Gupta, Jayesh K and Morales, Peter and Allen, Ross and Kochenderfer, Mykel J},
  journal={arXiv preprint arXiv:2006.11438},
  year={2020}
}

@article{cho2014learning,
  title={Learning phrase representations using RNN encoder-decoder for statistical machine translation},
  author={Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1406.1078},
  year={2014}
}

@inproceedings{yoon2020much,
  title={How Much and When Do We Need Higher-order Information in Hypergraphs? A Case Study on Hyperedge Prediction},
  author={Yoon, Se-eun and Song, Hyungseok and Shin, Kijung and Yi, Yung},
  booktitle={Proceedings of The Web Conference 2020},
  pages={2627--2633},
  year={2020}
}

@inproceedings{mahajan2019maven,
	title={MAVEN: Multi-Agent Variational Exploration},
	author={Mahajan, Anuj and Rashid, Tabish and Samvelyan, Mikayel and Whiteson, Shimon},
	booktitle={Advances in Neural Information Processing Systems},
	pages={7611--7622},
	year={2019}
}

@book{sutton2018reinforcement,
	title={Reinforcement learning: An introduction},
	author={Sutton, Richard S and Barto, Andrew G},
	year={2018},
	publisher={MIT press}
}

%sparse
@inproceedings{kok2004sparse,
  title={Sparse cooperative Q-learning},
  author={Kok, Jelle R and Vlassis, Nikos},
  booktitle={Proceedings of the twenty-first international conference on Machine learning},
  pages={61},
  year={2004}
}

%CSP
@inproceedings{kindler2016approximation,
  title={Approximation of non-boolean 2CSP},
  author={Kindler, Guy and Kolla, Alexandra and Trevisan, Luca},
  booktitle={Proceedings of the Twenty-Seventh Annual ACM-SIAM Symposium on Discrete Algorithms},
  pages={1705--1714},
  year={2016},
  organization={SIAM}
}

@article{manurangsi2015near,
  title={Near-Optimal UGC-hardness of Approximating Max k-CSP\_R},
  author={Manurangsi, Pasin and Nakkiran, Preetum and Trevisan, Luca},
  journal={arXiv preprint arXiv:1511.06558},
  year={2015}
}

@article{chan2016approximation,
  title={Approximation resistance from pairwise-independent subgroups},
  author={Chan, Siu On},
  journal={Journal of the ACM (JACM)},
  volume={63},
  number={3},
  pages={1--32},
  year={2016},
  publisher={ACM New York, NY, USA}
}

%lvd
@article{wang2021towards,
  title={Towards understanding cooperative multi-agent q-learning with value factorization},
  author={Wang, Jianhao and Ren, Zhizhou and Han, Beining and Ye, Jianing and Zhang, Chongjie},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={29142--29155},
  year={2021}
}