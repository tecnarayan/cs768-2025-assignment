@article{wang2022self,
  title   = {Self-Instruct: Aligning Language Model with Self Generated Instructions},
  author  = {Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A and Khashabi, Daniel and Hajishirzi, Hannaneh},
  journal = {arXiv preprint arXiv:2212.10560},
  year    = {2022}
}

@article{longpre2023flan,
  title   = {The flan collection: Designing data and methods for effective instruction tuning},
  author  = {Longpre, Shayne and Hou, Le and Vu, Tu and Webson, Albert and Chung, Hyung Won and Tay, Yi and Zhou, Denny and Le, Quoc V and Zoph, Barret and Wei, Jason and others},
  journal = {arXiv preprint arXiv:2301.13688},
  year    = {2023}
}

@article{bai2022training,
  title   = {Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author  = {Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal = {arXiv preprint arXiv:2204.05862},
  year    = {2022}
}

@article{christiano2017deep,
  title   = {Deep reinforcement learning from human preferences},
  author  = {Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal = {Advances in neural information processing systems},
  volume  = {30},
  year    = {2017}
}

@article{schulman2017proximal,
  title   = {Proximal policy optimization algorithms},
  author  = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal = {arXiv preprint arXiv:1707.06347},
  year    = {2017}
}

@article{stiennon2020learning,
  title   = {Learning to summarize with human feedback},
  author  = {Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {33},
  pages   = {3008--3021},
  year    = {2020}
}

@article{gao2022scaling,
  title   = {Scaling Laws for Reward Model Overoptimization},
  author  = {Gao, Leo and Schulman, John and Hilton, Jacob},
  journal = {arXiv preprint arXiv:2210.10760},
  year    = {2022}
}

@inproceedings{kakade2002approximately,
  title     = {Approximately optimal approximate reinforcement learning},
  author    = {Kakade, Sham and Langford, John},
  booktitle = {Proceedings of the Nineteenth International Conference on Machine Learning},
  pages     = {267--274},
  year      = {2002}
}

@article{chatgpt,
  title  = {Introducing ChatGPT},
  author = {OpenAI},
  url    = {https://openai.com/blog/chatgpt}
}

@article{ziegler2019fine,
  title   = {Fine-tuning language models from human preferences},
  author  = {Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal = {arXiv preprint arXiv:1909.08593},
  year    = {2019}
}

@article{anthony2017thinking,
  title   = {Thinking fast and slow with deep learning and tree search},
  author  = {Anthony, Thomas and Tian, Zheng and Barber, David},
  journal = {Advances in neural information processing systems},
  volume  = {30},
  year    = {2017}
}

@article{silver2017mastering,
  title     = {Mastering the game of go without human knowledge},
  author    = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal   = {nature},
  volume    = {550},
  number    = {7676},
  pages     = {354--359},
  year      = {2017},
  publisher = {Nature Publishing Group}
}

@article{uesato2022solving,
  title   = {Solving math word problems with process-and outcome-based feedback},
  author  = {Uesato, Jonathan and Kushman, Nate and Kumar, Ramana and Song, Francis and Siegel, Noah and Wang, Lisa and Creswell, Antonia and Irving, Geoffrey and Higgins, Irina},
  journal = {arXiv preprint arXiv:2211.14275},
  year    = {2022}
}

@article{lu2022quark,
  title   = {Quark: Controllable text generation with reinforced unlearning},
  author  = {Lu, Ximing and Welleck, Sean and Hessel, Jack and Jiang, Liwei and Qin, Lianhui and West, Peter and Ammanabrolu, Prithviraj and Choi, Yejin},
  journal = {Advances in neural information processing systems},
  volume  = {35},
  pages   = {27591--27609},
  year    = {2022}
}

@article{touvron2023llama,
  title   = {Llama: Open and efficient foundation language models},
  author  = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal = {arXiv preprint arXiv:2302.13971},
  year    = {2023}
}

@article{bradley1952rank,
  title     = {Rank analysis of incomplete block designs: I. The method of paired comparisons},
  author    = {Bradley, Ralph Allan and Terry, Milton E},
  journal   = {Biometrika},
  volume    = {39},
  number    = {3/4},
  pages     = {324--345},
  year      = {1952},
  publisher = {JSTOR}
}

@article{bakker2022fine,
  title   = {Fine-tuning language models to find agreement among humans with diverse preferences},
  author  = {Bakker, Michiel and Chadwick, Martin and Sheahan, Hannah and Tessler, Michael and Campbell-Gillingham, Lucy and Balaguer, Jan and McAleese, Nat and Glaese, Amelia and Aslanides, John and Botvinick, Matt and others},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {35},
  pages   = {38176--38189},
  year    = {2022}
}

@article{glaese2022improving,
  title   = {Improving alignment of dialogue agents via targeted human judgements},
  author  = {Glaese, Amelia and McAleese, Nat and Tr{\k{e}}bacz, Maja and Aslanides, John and Firoiu, Vlad and Ewalds, Timo and Rauh, Maribeth and Weidinger, Laura and Chadwick, Martin and Thacker, Phoebe and others},
  journal = {arXiv preprint arXiv:2209.14375},
  year    = {2022}
}

@article{korbak2023pretraining,
  title   = {Pretraining language models with human preferences},
  author  = {Korbak, Tomasz and Shi, Kejian and Chen, Angelica and Bhalerao, Rasika and Buckley, Christopher L and Phang, Jason and Bowman, Samuel R and Perez, Ethan},
  journal = {arXiv preprint arXiv:2302.08582},
  year    = {2023}
}

@article{keskar2019ctrl,
  title   = {Ctrl: A conditional transformer language model for controllable generation},
  author  = {Keskar, Nitish Shirish and McCann, Bryan and Varshney, Lav R and Xiong, Caiming and Socher, Richard},
  journal = {arXiv preprint arXiv:1909.05858},
  year    = {2019}
}

@article{liu2023chain,
  title   = {Chain of hindsight aligns language models with feedback},
  author  = {Liu, H and Sferrazza, C and Abbeel, P},
  journal = {arXiv preprint arXiv:2302.02676},
  year    = {2023}
}

@misc{koala_blogpost_2023,
  author       = {Xinyang Geng and Arnav Gudibande and Hao Liu and Eric Wallace and Pieter Abbeel and Sergey Levine and Dawn Song},
  title        = {Koala: A Dialogue Model for Academic Research},
  howpublished = {Blog post},
  month        = {April},
  year         = {2023},
  url          = {https://bair.berkeley.edu/blog/2023/04/03/koala/},
  urldate      = {2023-04-03}
}

@misc{oai_model_index,
  author = {OpenAI},
  title  = {Model index for researchers}
}


@article{wei2021finetuned,
  title   = {Finetuned language models are zero-shot learners},
  author  = {Wei, Jason and Bosma, Maarten and Zhao, Vincent Y and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  journal = {arXiv preprint arXiv:2109.01652},
  year    = {2021}
}

@article{goyal2022news,
  title   = {News summarization and evaluation in the era of gpt-3},
  author  = {Goyal, Tanya and Li, Junyi Jessy and Durrett, Greg},
  journal = {arXiv preprint arXiv:2209.12356},
  year    = {2022}
}

@article{zhang2023benchmarking,
  title   = {Benchmarking large language models for news summarization},
  author  = {Zhang, Tianyi and Ladhak, Faisal and Durmus, Esin and Liang, Percy and McKeown, Kathleen and Hashimoto, Tatsunori B},
  journal = {arXiv preprint arXiv:2301.13848},
  year    = {2023}
}

@inproceedings{freitag2021results,
  title     = {Results of the WMT21 metrics shared task: Evaluating metrics with expert-based human evaluations on TED and news domain},
  author    = {Freitag, Markus and Rei, Ricardo and Mathur, Nitika and Lo, Chi-kiu and Stewart, Craig and Foster, George and Lavie, Alon and Bojar, Ond{\v{r}}ej},
  booktitle = {Proceedings of the Sixth Conference on Machine Translation},
  pages     = {733--774},
  year      = {2021}
}

@article{mishra2021cross,
  title   = {Cross-task generalization via natural language crowdsourcing instructions},
  author  = {Mishra, Swaroop and Khashabi, Daniel and Baral, Chitta and Hajishirzi, Hannaneh},
  journal = {arXiv preprint arXiv:2104.08773},
  year    = {2021}
}

@article{sanh2021multitask,
  title   = {Multitask prompted training enables zero-shot task generalization},
  author  = {Sanh, Victor and Webson, Albert and Raffel, Colin and Bach, Stephen H and Sutawika, Lintang and Alyafeai, Zaid and Chaffin, Antoine and Stiegler, Arnaud and Scao, Teven Le and Raja, Arun and others},
  journal = {arXiv preprint arXiv:2110.08207},
  year    = {2021}
}

@article{aribandi2021ext5,
  title   = {Ext5: Towards extreme multi-task scaling for transfer learning},
  author  = {Aribandi, Vamsi and Tay, Yi and Schuster, Tal and Rao, Jinfeng and Zheng, Huaixiu Steven and Mehta, Sanket Vaibhav and Zhuang, Honglei and Tran, Vinh Q and Bahri, Dara and Ni, Jianmo and others},
  journal = {arXiv preprint arXiv:2111.10952},
  year    = {2021}
}

@inproceedings{wang2022super,
  title     = {Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks},
  author    = {Wang, Yizhong and Mishra, Swaroop and Alipoormolabashi, Pegah and Kordi, Yeganeh and Mirzaei, Amirreza and Naik, Atharva and Ashok, Arjun and Dhanasekaran, Arut Selvan and Arunkumar, Anjana and Stap, David and others},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages     = {5085--5109},
  year      = {2022}
}

@article{bai2022constitutional,
  title   = {Constitutional AI: Harmlessness from AI Feedback},
  author  = {Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal = {arXiv preprint arXiv:2212.08073},
  year    = {2022}
}

@article{aher2022using,
  title   = {Using Large Language Models to Simulate Multiple Humans},
  author  = {Aher, Gati and Arriaga, Rosa I and Kalai, Adam Tauman},
  journal = {arXiv preprint arXiv:2208.10264},
  year    = {2022}
}

@article{argyle2022out,
  title   = {Out of One, Many: Using Language Models to Simulate Human Samples},
  author  = {Argyle, Lisa P and Busby, Ethan C and Fulda, Nancy and Gubler, Joshua and Rytting, Christopher and Wingate, David},
  journal = {arXiv preprint arXiv:2209.06899},
  year    = {2022}
}

@inproceedings{park2022social,
  title     = {Social Simulacra: Creating Populated Prototypes for Social Computing Systems},
  author    = {Park, Joon Sung and Popowski, Lindsay and Cai, Carrie and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle = {Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology},
  pages     = {1--18},
  year      = {2022}
}

@article{park2023generative,
  title   = {Generative agents: Interactive simulacra of human behavior},
  author  = {Park, Joon Sung and O'Brien, Joseph C and Cai, Carrie J and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  journal = {arXiv preprint arXiv:2304.03442},
  year    = {2023}
}

@article{uchendu2021turingbench,
  title   = {TURINGBENCH: A benchmark environment for Turing test in the age of neural text generation},
  author  = {Uchendu, Adaku and Ma, Zeyu and Le, Thai and Zhang, Rui and Lee, Dongwon},
  journal = {arXiv preprint arXiv:2109.13296},
  year    = {2021}
}

@article{karra2022ai,
  title   = {AI Personification: Estimating the Personality of Language Models},
  author  = {Karra, Saketh Reddy and Nguyen, Son and Tulabandhula, Theja},
  journal = {arXiv preprint arXiv:2204.12000},
  year    = {2022}
}

@article{santurkar2023whose,
  title   = {Whose opinions do language models reflect?},
  author  = {Santurkar, Shibani and Durmus, Esin and Ladhak, Faisal and Lee, Cinoo and Liang, Percy and Hashimoto, Tatsunori},
  journal = {arXiv preprint arXiv:2303.17548},
  year    = {2023}
}

@article{brockman2016openai,
  title   = {Openai gym},
  author  = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal = {arXiv preprint arXiv:1606.01540},
  year    = {2016}
}

@inproceedings{todorov2012mujoco,
  title        = {Mujoco: A physics engine for model-based control},
  author       = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle    = {2012 IEEE/RSJ international conference on intelligent robots and systems},
  pages        = {5026--5033},
  year         = {2012},
  organization = {IEEE}
}

@article{tassa2018deepmind,
  title   = {Deepmind control suite},
  author  = {Tassa, Yuval and Doron, Yotam and Muldal, Alistair and Erez, Tom and Li, Yazhe and Casas, Diego de Las and Budden, David and Abdolmaleki, Abbas and Merel, Josh and Lefrancq, Andrew and others},
  journal = {arXiv preprint arXiv:1801.00690},
  year    = {2018}
}

@inproceedings{summers2020lyceum,
  title        = {Lyceum: An efficient and scalable ecosystem for robot learning},
  author       = {Summers, Colin and Lowrey, Kendall and Rajeswaran, Aravind and Srinivasa, Siddhartha and Todorov, Emanuel},
  booktitle    = {Learning for Dynamics and Control},
  pages        = {793--803},
  year         = {2020},
  organization = {PMLR}
}

@inproceedings{fan2018surreal,
  title        = {Surreal: Open-source reinforcement learning framework and robot manipulation benchmark},
  author       = {Fan, Linxi and Zhu, Yuke and Zhu, Jiren and Liu, Zihua and Zeng, Orien and Gupta, Anchit and Creus-Costa, Joan and Savarese, Silvio and Fei-Fei, Li},
  booktitle    = {Conference on Robot Learning},
  pages        = {767--782},
  year         = {2018},
  organization = {PMLR}
}

@article{juliani2018unity,
  title   = {Unity: A general platform for intelligent agents},
  author  = {Juliani, Arthur and Berges, Vincent-Pierre and Teng, Ervin and Cohen, Andrew and Harper, Jonathan and Elion, Chris and Goy, Chris and Gao, Yuan and Henry, Hunter and Mattar, Marwan and others},
  journal = {arXiv preprint arXiv:1809.02627},
  year    = {2018}
}

@article{freeman2021brax,
  title   = {Brax--A Differentiable Physics Engine for Large Scale Rigid Body Simulation},
  author  = {Freeman, C Daniel and Frey, Erik and Raichuk, Anton and Girgin, Sertan and Mordatch, Igor and Bachem, Olivier},
  journal = {arXiv preprint arXiv:2106.13281},
  year    = {2021}
}

@article{shi2022life,
  title   = {When Life Gives You Lemons, Make Cherryade: Converting Feedback from Bad Responses into Good Labels},
  author  = {Shi, Weiyan and Dinan, Emily and Shuster, Kurt and Weston, Jason and Xu, Jing},
  journal = {arXiv preprint arXiv:2210.15893},
  year    = {2022}
}

@article{saunders2022self,
  title   = {Self-critiquing models for assisting human evaluators},
  author  = {Saunders, William and Yeh, Catherine and Wu, Jeff and Bills, Steven and Ouyang, Long and Ward, Jonathan and Leike, Jan},
  journal = {arXiv preprint arXiv:2206.05802},
  year    = {2022}
}

@article{chen2023improving,
  title   = {Improving Code Generation by Training with Natural Language Feedback},
  author  = {Chen, Angelica and Scheurer, J{\'e}r{\'e}my and Korbak, Tomasz and Campos, Jon Ander and Chan, Jun Shern and Bowman, Samuel R and Cho, Kyunghyun and Perez, Ethan},
  journal = {arXiv preprint arXiv:2303.16749},
  year    = {2023}
}

@article{scheurer2023training,
  title   = {Training language models with language feedback at scale},
  author  = {Scheurer, J{\'e}r{\'e}my and Campos, Jon Ander and Korbak, Tomasz and Chan, Jun Shern and Chen, Angelica and Cho, Kyunghyun and Perez, Ethan},
  journal = {arXiv preprint arXiv:2303.16755},
  year    = {2023}
}

@article{chiang2023can,
  title   = {Can Large Language Models Be an Alternative to Human Evaluations?},
  author  = {Chiang, Cheng-Han and Lee, Hung-yi},
  journal = {arXiv preprint arXiv:2305.01937},
  year    = {2023}
}

@article{perez2022discovering,
  title   = {Discovering Language Model Behaviors with Model-Written Evaluations},
  author  = {Perez, Ethan and Ringer, Sam and Luko{\v{s}}i{\=u}t{\.e}, Kamil{\.e} and Nguyen, Karina and Chen, Edwin and Heiner, Scott and Pettit, Craig and Olsson, Catherine and Kundu, Sandipan and Kadavath, Saurav and others},
  journal = {arXiv preprint arXiv:2212.09251},
  year    = {2022}
}

@article{madaan2023self,
  title   = {Self-refine: Iterative refinement with self-feedback},
  author  = {Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal = {arXiv preprint arXiv:2303.17651},
  year    = {2023}
}

@article{lee2023aligning,
  title   = {Aligning text-to-image models using human feedback},
  author  = {Lee, Kimin and Liu, Hao and Ryu, Moonkyung and Watkins, Olivia and Du, Yuqing and Boutilier, Craig and Abbeel, Pieter and Ghavamzadeh, Mohammad and Gu, Shixiang Shane},
  journal = {arXiv preprint arXiv:2302.12192},
  year    = {2023}
}

@article{chen2023teaching,
  title   = {Teaching large language models to self-debug},
  author  = {Chen, Xinyun and Lin, Maxwell and Sch{\"a}rli, Nathanael and Zhou, Denny},
  journal = {arXiv preprint arXiv:2304.05128},
  year    = {2023}
}

@article{weston2016dialog,
  title   = {Dialog-based language learning},
  author  = {Weston, Jason E},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {29},
  year    = {2016}
}

@article{li2016dialogue,
  title   = {Dialogue learning with human-in-the-loop},
  author  = {Li, Jiwei and Miller, Alexander H and Chopra, Sumit and Ranzato, Marc'Aurelio and Weston, Jason},
  journal = {arXiv preprint arXiv:1611.09823},
  year    = {2016}
}

@article{hancock2019learning,
  title   = {Learning from dialogue after deployment: Feed yourself, chatbot!},
  author  = {Hancock, Braden and Bordes, Antoine and Mazare, Pierre-Emmanuel and Weston, Jason},
  journal = {arXiv preprint arXiv:1901.05415},
  year    = {2019}
}

@article{nguyen2017reinforcement,
  title   = {Reinforcement learning for bandit neural machine translation with simulated human feedback},
  author  = {Nguyen, Khanh and Daum{\'e} III, Hal and Boyd-Graber, Jordan},
  journal = {arXiv preprint arXiv:1707.07402},
  year    = {2017}
}

@article{lam2018reinforcement,
  title   = {A reinforcement learning approach to interactive-predictive neural machine translation},
  author  = {Lam, Tsz Kin and Kreutzer, Julia and Riezler, Stefan},
  journal = {arXiv preprint arXiv:1805.01553},
  year    = {2018}
}

@article{kreutzer2018can,
  title   = {Can neural machine translation be improved with user feedback?},
  author  = {Kreutzer, Julia and Khadivi, Shahram and Matusov, Evgeny and Riezler, Stefan},
  journal = {arXiv preprint arXiv:1804.05958},
  year    = {2018}
}

@article{sokolov2016bandit,
  title   = {Bandit structured prediction for learning from partial feedback in statistical machine translation},
  author  = {Sokolov, Artem and Riezler, Stefan and Urvoy, Tanguy},
  journal = {arXiv preprint arXiv:1601.04468},
  year    = {2016}
}

@article{ramamurthy2022reinforcement,
  title   = {Is Reinforcement Learning (Not) for Natural Language Processing?: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization},
  author  = {Ramamurthy, Rajkumar and Ammanabrolu, Prithviraj and Brantley, Kiant{\'e} and Hessel, Jack and Sifa, Rafet and Bauckhage, Christian and Hajishirzi, Hannaneh and Choi, Yejin},
  journal = {arXiv preprint arXiv:2210.01241},
  year    = {2022}
}

@article{wu2016google,
  title   = {Google's neural machine translation system: Bridging the gap between human and machine translation},
  author  = {Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and others},
  journal = {arXiv preprint arXiv:1609.08144},
  year    = {2016}
}

@article{kiegeland2021revisiting,
  title   = {Revisiting the weaknesses of reinforcement learning for neural machine translation},
  author  = {Kiegeland, Samuel and Kreutzer, Julia},
  journal = {arXiv preprint arXiv:2106.08942},
  year    = {2021}
}

@article{paulus2017deep,
  title   = {A deep reinforced model for abstractive summarization},
  author  = {Paulus, Romain and Xiong, Caiming and Socher, Richard},
  journal = {arXiv preprint arXiv:1705.04304},
  year    = {2017}
}

@article{snell2022offline,
  title   = {Offline rl for natural language generation with implicit language q learning},
  author  = {Snell, Charlie and Kostrikov, Ilya and Su, Yi and Yang, Mengjiao and Levine, Sergey},
  journal = {arXiv preprint arXiv:2206.11871},
  year    = {2022}
}

@article{peng2023instruction,
  title   = {Instruction tuning with gpt-4},
  author  = {Peng, Baolin and Li, Chunyuan and He, Pengcheng and Galley, Michel and Gao, Jianfeng},
  journal = {arXiv preprint arXiv:2304.03277},
  year    = {2023}
}

@article{liu2023visual,
  title   = {Visual instruction tuning},
  author  = {Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal = {arXiv preprint arXiv:2304.08485},
  year    = {2023}
}

@article{liu2023nlg,
  title   = {G-Eval: NLG Evaluation using GPT-4 with Better Human Alignmentg},
  author  = {Liu, Yang and Iter, Dan and Xu, Yichong  and  Wang, Shuohang and Xu, Ruochen and Zhu, Chenguang},
  journal = {arXiv preprint arXiv:2303.16634},
  year    = {2023}
}

@misc{alpaca_eval,
  author       = {Xuechen Li and Tianyi Zhang and Yann Dubois and Rohan Taori and Ishaan Gulrajani and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title        = {AlpacaEval: An Automatic Evaluator of Instruction-following Models},
  year         = {2023},
  publisher    = {GitHub},
  journal      = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/alpaca_eval}}
}

@article{zheng2023judging,
  title   = {Judging LLM-as-a-judge with MT-Bench and Chatbot Arena},
  author  = {Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal = {arXiv preprint arXiv:2306.05685},
  year    = {2023}
}

@article{rafailov2023direct,
  title   = {Direct preference optimization: Your language model is secretly a reward model},
  author  = {Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D and Finn, Chelsea},
  journal = {arXiv preprint arXiv:2305.18290},
  year    = {2023}
}

