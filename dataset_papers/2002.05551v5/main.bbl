\begin{thebibliography}{50}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alquier et~al.(2016)Alquier, Ridgway, Chopin, and Teh]{Alquier2016a}
Alquier, P., Ridgway, J., Chopin, N., and Teh, Y.~W.
\newblock {On the properties of variational approximations of Gibbs
  posteriors}.
\newblock \emph{Journal of Machine Learning Research}, 2016.

\bibitem[Amit \& Meir(2018)Amit and Meir]{amit2017meta}
Amit, R. and Meir, R.
\newblock {Meta-learning by adjusting priors based on extended PAC-Bayes
  theory}.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Andrychowicz et~al.(2016)Andrychowicz, Denil, Colmenarejo, Hoffman,
  Pfau, Schaul, Shillingford, and De~Freitas]{Andrychowicz2016}
Andrychowicz, M., Denil, M., Colmenarejo, S.~G., Hoffman, M.~W., Pfau, D.,
  Schaul, T., Shillingford, B., and De~Freitas, N.
\newblock {Learning to learn by gradient descent by gradient descent}.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Auer(2002)]{auer2002using}
Auer, P.
\newblock Using confidence bounds for exploitation-exploration trade-offs.
\newblock \emph{Journal of Machine Learning Research}, 3\penalty0
  (Nov):\penalty0 397--422, 2002.

\bibitem[Baxter(2000)]{baxter2000model}
Baxter, J.
\newblock A model of inductive bias learning.
\newblock \emph{Journal of Artificial Intelligence Research}, 2000.

\bibitem[Bergstra et~al.(2013)Bergstra, Yamins, and Cox]{bergstra13}
Bergstra, J., Yamins, D., and Cox, D.
\newblock Making a science of model search: Hyperparameter optimization in
  hundreds of dimensions for vision architectures.
\newblock In \emph{International Conference on Machine Learning}, 2013.

\bibitem[Blei et~al.(2016)Blei, Kucukelbir, and McAuliffe]{Blei2016}
Blei, D.~M., Kucukelbir, A., and McAuliffe, J.~D.
\newblock {Variational Inference: {A} Review for Statisticians}.
\newblock \emph{arXiv preprint arXiv:1601.00670}, 2016.

\bibitem[Boucheron et~al.(2013)Boucheron, Lugosi, and Massart]{Boucheron2013}
Boucheron, S., Lugosi, G., and Massart, P.
\newblock {Concentration inequalities : a nonasymptotic theory of
  independence}.
\newblock chapter 2.4, pp.\  27--30. Oxford University Press, 2013.

\bibitem[Catoni(2007)]{catoni2007pac}
Catoni, O.
\newblock {PAC-Bayesian supervised classification: the thermodynamics of
  statistical learning}.
\newblock \emph{arXiv}, 2007.

\bibitem[Chen et~al.(2017)Chen, Hoffman, Colmenarejo, Denil, Lillicrap,
  Botvinick, and De~Freitas]{Chen2017a}
Chen, Y., Hoffman, M.~W., Colmenarejo, S.~G., Denil, M., Lillicrap, T.~P.,
  Botvinick, M., and De~Freitas, N.
\newblock {Learning to Learn without Gradient Descent by Gradient Descent}.
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Dziugaite \& Roy(2016)Dziugaite and Roy]{dziugaite2017computing}
Dziugaite, G.~K. and Roy, D.~M.
\newblock Computing nonvacuous generalization bounds for deep (stochastic)
  neural networks with many more parameters than training data.
\newblock In \emph{Uncertainty in Artificial Intelligence}, 2016.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{finn2017model}
Finn, C., Abbeel, P., and Levine, S.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Finn et~al.(2018)Finn, Xu, and Levine]{finn2018probabilistic}
Finn, C., Xu, K., and Levine, S.
\newblock Probabilistic model-agnostic meta-learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Fortuin \& R{\"a}tsch(2019)Fortuin and R{\"a}tsch]{fortuin2019deep}
Fortuin, V. and R{\"a}tsch, G.
\newblock {Deep Mean Functions for Meta-Learning in Gaussian Processes}.
\newblock \emph{arXiv preprint: arXiv:1901.08098}, 2019.

\bibitem[Fortuin et~al.(2019)Fortuin, R{\"a}tsch, and
  Mandt]{fortuin2019multivariate}
Fortuin, V., R{\"a}tsch, G., and Mandt, S.
\newblock Multivariate time series imputation with variational autoencoders.
\newblock \emph{arXiv preprint arXiv:1907.04155}, 2019.

\bibitem[Garnelo et~al.(2018)Garnelo, Schwarz, Rosenbaum, Viola, Rezende,
  Eslami, and Teh]{garnelo2018neural}
Garnelo, M., Schwarz, J., Rosenbaum, D., Viola, F., Rezende, D.~J., Eslami, S.,
  and Teh, Y.~W.
\newblock Neural processes.
\newblock \emph{arXiv preprint arXiv:1807.01622}, 2018.

\bibitem[Germain et~al.(2016)Germain, Bach, Lacoste, and
  Lacoste-Julien]{germain2016pac}
Germain, P., Bach, F., Lacoste, A., and Lacoste-Julien, S.
\newblock Pac-bayesian theory meets bayesian inference.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Guedj(2019)]{guedj2019primer}
Guedj, B.
\newblock {A primer on PAC-Bayesian learning}.
\newblock In \emph{2nd Congress of the French Mathematical Society}, 2019.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017calibration}
Guo, C., Pleiss, G., Sun, Y., and Weinberger, K.~Q.
\newblock On calibration of modern neural networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1321--1330, 2017.

\bibitem[Hochreiter et~al.(2001)Hochreiter, Younger, and
  Conwell]{Hochreiter2001}
Hochreiter, S., Younger, A.~S., and Conwell, P.~R.
\newblock {Learning To Learn Using Gradient Descent}.
\newblock In \emph{International Conference on Artificial Neural Networks},
  2001.

\bibitem[Kim et~al.(2018)Kim, Yoon, Dia, Kim, Bengio, and Ahn]{kim2018bayesian}
Kim, T., Yoon, J., Dia, O., Kim, S., Bengio, Y., and Ahn, S.
\newblock Bayesian model-agnostic meta-learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Kingma \& Welling(2014)Kingma and Welling]{kingma2014auto}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational bayes.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Kirschner et~al.(2019{\natexlab{a}})Kirschner, Mutn\'y, Hiller,
  Ischebeck, and Krause]{kirschner2019linebo}
Kirschner, J., Mutn\'y, M., Hiller, N., Ischebeck, R., and Krause, A.
\newblock {Adaptive and Safe Bayesian Optimization in High Dimensions via
  One-Dimensional Subspaces}.
\newblock In \emph{International Conference on Machine Learning},
  2019{\natexlab{a}}.

\bibitem[Kirschner et~al.(2019{\natexlab{b}})Kirschner, Nonnenmacher, Mutn\'y,
  Hiller, Adelmann, Ischebeck, and Krause]{kirschner2019swissfel}
Kirschner, J., Nonnenmacher, M., Mutn\'y, M., Hiller, N., Adelmann, A.,
  Ischebeck, R., and Krause, A.
\newblock {Bayesian Optimization for Fast and Safe Parameter Tuning of
  SwissFEL}.
\newblock In \emph{International Free-Electron Laser Conference (FEL2019)},
  2019{\natexlab{b}}.

\bibitem[Krause \& Ong(2011)Krause and Ong]{krause2011contextual}
Krause, A. and Ong, C.~S.
\newblock Contextual gaussian process bandit optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2011.

\bibitem[Kuleshov et~al.(2018)Kuleshov, Fenner, and Ermon]{Kuleshov2018}
Kuleshov, V., Fenner, N., and Ermon, S.
\newblock Accurate uncertainties for deep learning using calibrated regression.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Lake et~al.(2015)Lake, Salakhutdinov, and Tenenbaum]{lake2015human}
Lake, B.~M., Salakhutdinov, R., and Tenenbaum, J.~B.
\newblock Human-level concept learning through probabilistic program induction.
\newblock \emph{Science}, 2015.

\bibitem[Lever et~al.(2013)Lever, Laviolette, and Shawe-Taylor]{Lever2013}
Lever, G., Laviolette, F., and Shawe-Taylor, J.
\newblock {Tighter PAC-Bayes bounds through distribution-dependent priors}.
\newblock \emph{Theoretical Computer Science}, 473:\penalty0 4--28, feb 2013.
\newblock ISSN 0304-3975.
\newblock \doi{10.1016/J.TCS.2012.10.013}.

\bibitem[Liu \& Wang(2016)Liu and Wang]{Liu2016}
Liu, Q. and Wang, D.
\newblock {Stein Variational Gradient Descent: A General Purpose Bayesian
  Inference Algorithm}.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Madden(2004)]{intel_sensor_data}
Madden, S.
\newblock Intel lab data.
\newblock \url{http://db.csail.mit.edu/labdata/labdata.html}, 2004.
\newblock Accessed: Sep 8, 2020.

\bibitem[McAllester(1999)]{mcallester1999some}
McAllester, D.~A.
\newblock {Some PAC-Bayesian theorems}.
\newblock \emph{Machine Learning}, 1999.

\bibitem[Milne et~al.(2017)Milne, Schietinger, Aiba, Alarcon, Alex, Anghel,
  Arsov, Beard, Beaud, Bettoni, et~al.]{milne2017swissfel}
Milne, C.~J., Schietinger, T., Aiba, M., Alarcon, A., Alex, J., Anghel, A.,
  Arsov, V., Beard, C., Beaud, P., Bettoni, S., et~al.
\newblock Swissfel: the swiss x-ray free electron laser.
\newblock \emph{Applied Sciences}, 2017.

\bibitem[Nichol et~al.(2018)Nichol, Achiam, and Schulman]{nichol2018firstorder}
Nichol, A., Achiam, J., and Schulman, J.
\newblock {On First-Order Meta-Learning Algorithms}.
\newblock \emph{arXiv preprint arXiv:1803.02999}, 2018.

\bibitem[Parrado-Hernandez et~al.(2012)Parrado-Hernandez, Ambroladze,
  Shawe-Taylor, and Sun]{parrado12pac}
Parrado-Hernandez, E., Ambroladze, A., Shawe-Taylor, J., and Sun, S.
\newblock {PAC-Bayes Bounds with Data Dependent Priors}.
\newblock \emph{Journal of Machine Learning Research}, 2012.

\bibitem[Pentina \& Lampert(2014)Pentina and Lampert]{pentina2014pac}
Pentina, A. and Lampert, C.
\newblock {A PAC-Bayesian bound for lifelong learning}.
\newblock In \emph{International Conference on Machine Learning}, 2014.

\bibitem[Qin et~al.(2018)Qin, Zhang, Zhao, Wang, Shi, Qi, Shi, and
  Lei]{qin2018rethink}
Qin, Y., Zhang, W., Zhao, C., Wang, Z., Shi, H., Qi, G., Shi, J., and Lei, Z.
\newblock Rethink and redesign meta learning.
\newblock \emph{arXiv preprint arXiv:1812.04955}, 2018.

\bibitem[Rasmussen \& Ghahramani(2001)Rasmussen and Ghahramani]{Rasmussen2001}
Rasmussen, C.~E. and Ghahramani, Z.
\newblock {Occam's Razor}.
\newblock In \emph{NIPS}, volume~13, pp.\  294----300, 2001.

\bibitem[Rasmussen \& Williams(2006)Rasmussen and
  Williams]{rasmussen2003gaussian}
Rasmussen, C.~E. and Williams, C. K.~I.
\newblock \emph{Gaussian processes in machine learning}.
\newblock 2006.

\bibitem[Rezende \& Mohamed(2015)Rezende and Mohamed]{rezende2015variational}
Rezende, D.~J. and Mohamed, S.
\newblock Variational inference with normalizing flows.
\newblock \emph{International Conference on Machine Learning}, 2015.

\bibitem[Rothfuss et~al.(2019{\natexlab{a}})Rothfuss, Ferreira, Boehm, Walther,
  Ulrich, Asfour, and Krause]{rothfuss2019noise}
Rothfuss, J., Ferreira, F., Boehm, S., Walther, S., Ulrich, M., Asfour, T., and
  Krause, A.
\newblock {Noise Regularization for Conditional Density Estimation}.
\newblock \emph{arXiv preprint arXiv:1907.08982}, 2019{\natexlab{a}}.

\bibitem[Rothfuss et~al.(2019{\natexlab{b}})Rothfuss, Lee, Clavera, Asfour, and
  Abbeel]{rothfuss2019promp}
Rothfuss, J., Lee, D., Clavera, I., Asfour, T., and Abbeel, P.
\newblock {ProMP: Proximal Meta-Policy Search}.
\newblock In \emph{International Conference on Learning Representations},
  2019{\natexlab{b}}.

\bibitem[Silva et~al.(2012)Silva, Moody, Scott, Celi, and
  Mark]{silva2012predicting}
Silva, I., Moody, G., Scott, D.~J., Celi, L.~A., and Mark, R.~G.
\newblock Predicting in-hospital mortality of icu patients: The
  physionet/computing in cardiology challenge 2012.
\newblock In \emph{Computing in Cardiology}, 2012.

\bibitem[Snell et~al.(2017)Snell, Swersky, and Zemel]{snell2017prototypical}
Snell, J., Swersky, K., and Zemel, R.
\newblock Prototypical networks for few-shot learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Srinivas et~al.(2009)Srinivas, Krause, Kakade, and
  Seeger]{srinivas2009gaussian}
Srinivas, N., Krause, A., Kakade, S.~M., and Seeger, M.
\newblock Gaussian process optimization in the bandit setting: No regret and
  experimental design.
\newblock In \emph{International Conference on Machine Learning}, 2009.

\bibitem[Thompson(1933)]{thompson1933likelihood}
Thompson, W.~R.
\newblock On the likelihood that one unknown probability exceeds another in
  view of the evidence of two samples.
\newblock \emph{Biometrika}, 1933.

\bibitem[Thrun \& Pratt(1998)Thrun and Pratt]{thrun1998}
Thrun, S. and Pratt, L. (eds.).
\newblock \emph{Learning to Learn}.
\newblock Kluwer Academic Publishers, 1998.

\bibitem[Vinyals et~al.(2016)Vinyals, Blundell, Lillicrap, Wierstra,
  et~al.]{vinyals2016matching}
Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et~al.
\newblock Matching networks for one shot learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Widmer et~al.(2010)Widmer, Toussaint, Altun, and
  R{\"a}tsch]{widmer2010inferring}
Widmer, C., Toussaint, N.~C., Altun, Y., and R{\"a}tsch, G.
\newblock Inferring latent task structure for multitask learning by multiple
  kernel learning.
\newblock \emph{BMC bioinformatics}, 2010.

\bibitem[Wilson et~al.(2016)Wilson, Hu, Salakhutdinov, and
  Xing]{wilson2016deep}
Wilson, A.~G., Hu, Z., Salakhutdinov, R., and Xing, E.~P.
\newblock Deep kernel learning.
\newblock In \emph{Artificial Intelligence and Statistics}, pp.\  370--378,
  2016.

\bibitem[Yin et~al.(2020)Yin, Tucker, Zhou, Levine, and Finn]{yin2020meta}
Yin, M., Tucker, G., Zhou, M., Levine, S., and Finn, C.
\newblock Meta-learning without memorization.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\end{thebibliography}
