\begin{thebibliography}{53}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alon and Halman(2021)]{StochDP-auto-FPTAS}
T.~Alon and N.~Halman.
\newblock Automatic generation of fptases for stochastic monotone dynamic
  programs made easier.
\newblock \emph{SIAM Journal on Discrete Mathematics}, 35\penalty0
  (4):\penalty0 2679--2722, 2021.
\newblock \doi{10.1137/19M1308633}.
\newblock URL \url{https://doi.org/10.1137/19M1308633}.

\bibitem[Alshiekh et~al.(2018)Alshiekh, Bloem, Ehlers, Könighofer, Niekum, and
  Topcu]{SafeShielding}
M.~Alshiekh, R.~Bloem, R.~Ehlers, B.~Könighofer, S.~Niekum, and U.~Topcu.
\newblock Safe reinforcement learning via shielding.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  32\penalty0 (1), Apr. 2018.
\newblock \doi{10.1609/aaai.v32i1.11797}.
\newblock URL \url{https://ojs.aaai.org/index.php/AAAI/article/view/11797}.

\bibitem[Altman(1999)]{cMDP-book}
E.~Altman.
\newblock \emph{Constrained Markov Decision Processes}.
\newblock Chapman and Hall/CRC, 1999.
\newblock \doi{10.1201/9781315140223}.

\bibitem[Bai et~al.(2023)Bai, Singh~Bedi, and
  Aggarwal]{NoViolationPolicyGradient}
Q.~Bai, A.~Singh~Bedi, and V.~Aggarwal.
\newblock Achieving zero constraint violation for constrained reinforcement
  learning via conservative natural policy gradient primal-dual algorithm.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  37\penalty0 (6):\penalty0 6737--6744, 6 2023.
\newblock \doi{10.1609/aaai.v37i6.25826}.
\newblock URL \url{https://ojs.aaai.org/index.php/AAAI/article/view/25826}.

\bibitem[Berkenkamp et~al.(2017)Berkenkamp, Turchetta, Schoellig, and
  Krause]{SafeStable}
F.~Berkenkamp, M.~Turchetta, A.~Schoellig, and A.~Krause.
\newblock Safe model-based reinforcement learning with stability guarantees.
\newblock In I.~Guyon, U.~V. Luxburg, S.~Bengio, H.~Wallach, R.~Fergus,
  S.~Vishwanathan, and R.~Garnett, editors, \emph{Advances in Neural
  Information Processing Systems}, volume~30. Curran Associates, Inc., 2017.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2017/file/766ebcd59621e305170616ba3d3dac32-Paper.pdf}.

\bibitem[Bhalgat et~al.(2011)Bhalgat, Goel, and Khanna]{StochKP-bicriteria}
A.~Bhalgat, A.~Goel, and S.~Khanna.
\newblock Improved approximation results for stochastic knapsack problems.
\newblock In \emph{Proceedings of the Twenty-Second Annual ACM-SIAM Symposium
  on Discrete Algorithms}, SODA '11, page 1647–1665, USA, 2011. Society for
  Industrial and Applied Mathematics.

\bibitem[Bhatia et~al.(2021)Bhatia, Varakantham, and Kumar]{ResourceMatching}
A.~Bhatia, P.~Varakantham, and A.~Kumar.
\newblock Resource constrained deep reinforcement learning.
\newblock \emph{Proceedings of the International Conference on Automated
  Planning and Scheduling}, 29\penalty0 (1):\penalty0 610--620, 5 2021.
\newblock \doi{10.1609/icaps.v29i1.3528}.
\newblock URL \url{https://ojs.aaai.org/index.php/ICAPS/article/view/3528}.

\bibitem[Borkar(2005)]{cMDP-Actor-Critic}
V.~Borkar.
\newblock An actor-critic algorithm for constrained markov decision processes.
\newblock \emph{Systems \& Control Letters}, 54\penalty0 (3):\penalty0
  207--213, 2005.
\newblock ISSN 0167-6911.
\newblock \doi{https://doi.org/10.1016/j.sysconle.2004.08.007}.
\newblock URL
  \url{https://www.sciencedirect.com/science/article/pii/S0167691104001276}.

\bibitem[Bossens and Bishop(2022)]{SafeE4}
D.~M. Bossens and N.~Bishop.
\newblock Explicit explore, exploit, or escape (e4): Near-optimal
  safety-constrained reinforcement learning in polynomial time.
\newblock \emph{Mach. Learn.}, 112\penalty0 (3):\penalty0 817–858, 6 2022.
\newblock ISSN 0885-6125.
\newblock \doi{10.1007/s10994-022-06201-z}.
\newblock URL \url{https://doi.org/10.1007/s10994-022-06201-z}.

\bibitem[Brantley et~al.(2020)Brantley, Dudík, Lykouris, Miryoosefi,
  Simchowitz, Slivkins, and Sun]{Knap-Brantley}
K.~Brantley, M.~Dudík, T.~Lykouris, S.~Miryoosefi, M.~Simchowitz, A.~Slivkins,
  and W.~Sun.
\newblock Constrained episodic reinforcement learning in concave-convex and
  knapsack settings.
\newblock In \emph{NeurIPS}, 2020.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2020/hash/bc6d753857fe3dd4275dff707dedf329-Abstract.html}.

\bibitem[Castellano et~al.(2022)Castellano, Min, Mallada, and
  Bazerque]{AlmostSure}
A.~Castellano, H.~Min, E.~Mallada, and J.~A. Bazerque.
\newblock Reinforcement learning with almost sure constraints.
\newblock In R.~Firoozi, N.~Mehr, E.~Yel, R.~Antonova, J.~Bohg, M.~Schwager,
  and M.~Kochenderfer, editors, \emph{Proceedings of The 4th Annual Learning
  for Dynamics and Control Conference}, volume 168 of \emph{Proceedings of
  Machine Learning Research}, pages 559--570. PMLR, 6 2022.
\newblock URL \url{https://proceedings.mlr.press/v168/castellano22a.html}.

\bibitem[Cheng et~al.(2019)Cheng, Orosz, Murray, and Burdick]{SafeBarrier}
R.~Cheng, G.~Orosz, R.~M. Murray, and J.~W. Burdick.
\newblock End-to-end safe reinforcement learning through barrier functions for
  safety-critical continuous control tasks.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  33\penalty0 (01):\penalty0 3387--3395, Jul. 2019.
\newblock \doi{10.1609/aaai.v33i01.33013387}.
\newblock URL \url{https://ojs.aaai.org/index.php/AAAI/article/view/4213}.

\bibitem[Cheung(2019)]{Knap-PreBrantley}
W.~C. Cheung.
\newblock Regret minimization for reinforcement learning with vectorial
  feedback and complex objectives.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32, 2019.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2019/file/a02ffd91ece5e7efeb46db8f10a74059-Paper.pdf}.

\bibitem[Chow et~al.(2018)Chow, Nachum, Duenez-Guzman, and
  Ghavamzadeh]{SafeLyapunov}
Y.~Chow, O.~Nachum, E.~Duenez-Guzman, and M.~Ghavamzadeh.
\newblock A lyapunov-based approach to safe reinforcement learning.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, \emph{Advances in Neural Information Processing
  Systems}, volume~31. Curran Associates, Inc., 2018.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2018/file/4fe5149039b52765bde64beb9f674940-Paper.pdf}.

\bibitem[Coronato et~al.(2020)Coronato, Naeem, {De Pietro}, and
  Paragliola]{MedSurvery}
A.~Coronato, M.~Naeem, G.~{De Pietro}, and G.~Paragliola.
\newblock Reinforcement learning for intelligent healthcare applications: A
  survey.
\newblock \emph{Artificial Intelligence in Medicine}, 109:\penalty0 101964,
  2020.
\newblock ISSN 0933-3657.
\newblock \doi{https://doi.org/10.1016/j.artmed.2020.101964}.
\newblock URL
  \url{https://www.sciencedirect.com/science/article/pii/S093336572031229X}.

\bibitem[Dean et~al.(2005)Dean, Goemans, and Vondr\'{a}k]{PIP-Stochastic}
B.~C. Dean, M.~X. Goemans, and J.~Vondr\'{a}k.
\newblock Adaptivity and approximation for stochastic packing problems.
\newblock In \emph{Proceedings of the Sixteenth Annual ACM-SIAM Symposium on
  Discrete Algorithms}, SODA '05, page 395–404, USA, 2005. Society for
  Industrial and Applied Mathematics.
\newblock ISBN 0898715857.

\bibitem[Dolgov and Durfee(2005)]{cMDP-MILP}
D.~A. Dolgov and E.~H. Durfee.
\newblock Stationary deterministic policies for constrained mdps with multiple
  rewards, costs, and discount factors.
\newblock In \emph{IJCAI}, volume~19, pages 1326--1331, 2005.

\bibitem[Fan et~al.(2021)Fan, Zhang, Yahja, and Mostafavi]{DisasterDigitalTwin}
C.~Fan, C.~Zhang, A.~Yahja, and A.~Mostafavi.
\newblock Disaster city digital twin: A vision for integrating artificial and
  human intelligence for disaster management.
\newblock \emph{International Journal of Information Management}, 56:\penalty0
  102049, 2021.
\newblock ISSN 0268-4012.
\newblock \doi{https://doi.org/10.1016/j.ijinfomgt.2019.102049}.
\newblock URL
  \url{https://www.sciencedirect.com/science/article/pii/S0268401219302956}.

\bibitem[Feinberg(2000)]{cMDP-hardness-OG}
E.~A. Feinberg.
\newblock Constrained discounted markov decision processes and hamiltonian
  cycles.
\newblock \emph{Mathematics of Operations Research}, 25\penalty0 (1):\penalty0
  130--140, 2000.
\newblock \doi{10.1287/moor.25.1.130.15210}.
\newblock URL \url{https://doi.org/10.1287/moor.25.1.130.15210}.

\bibitem[Fisac et~al.(2019)Fisac, Lugovoy, Rubies-Royo, Ghosh, and
  Tomlin]{PreInstantaneous1}
J.~F. Fisac, N.~F. Lugovoy, V.~Rubies-Royo, S.~Ghosh, and C.~J. Tomlin.
\newblock Bridging hamilton-jacobi safety analysis and reinforcement learning.
\newblock In \emph{2019 International Conference on Robotics and Automation
  (ICRA)}, page 8550–8556. IEEE Press, 2019.
\newblock \doi{10.1109/ICRA.2019.8794107}.
\newblock URL \url{https://doi.org/10.1109/ICRA.2019.8794107}.

\bibitem[Frieze and Clarke(1984)]{PIP-PTAS}
A.~Frieze and M.~Clarke.
\newblock Approximation algorithms for the m-dimensional 0--1 knapsack problem:
  Worst-case and probabilistic analyses.
\newblock \emph{European Journal of Operational Research}, 15\penalty0
  (1):\penalty0 100--109, 1984.
\newblock ISSN 0377-2217.
\newblock \doi{https://doi.org/10.1016/0377-2217(84)90053-5}.
\newblock URL
  \url{https://www.sciencedirect.com/science/article/pii/0377221784900535}.

\bibitem[Garc{{\'i}}a et~al.(2015)Garc{{\'i}}a, Fern, and
  o~Fern{{\'a}}ndez]{SafeComprSurvey}
J.~Garc{{\'i}}a, Fern, and o~Fern{{\'a}}ndez.
\newblock A comprehensive survey on safe reinforcement learning.
\newblock \emph{Journal of Machine Learning Research}, 16\penalty0
  (42):\penalty0 1437--1480, 2015.
\newblock URL \url{http://jmlr.org/papers/v16/garcia15a.html}.

\bibitem[Geißer et~al.(2020)Geißer, Povéda, Trevizan, Bondouy,
  Teichteil-Königsbuch, and Thiébaux]{AircraftWeatherDet}
F.~Geißer, G.~Povéda, F.~Trevizan, M.~Bondouy, F.~Teichteil-Königsbuch, and
  S.~Thiébaux.
\newblock Optimal and heuristic approaches for constrained flight planning
  under weather uncertainty.
\newblock \emph{Proceedings of the International Conference on Automated
  Planning and Scheduling}, 30\penalty0 (1):\penalty0 384--393, Jun. 2020.
\newblock \doi{10.1609/icaps.v30i1.6684}.
\newblock URL \url{https://ojs.aaai.org/index.php/ICAPS/article/view/6684}.

\bibitem[Gros et~al.(2020)Gros, Zanon, and Bemporad]{PreInstantaneous2}
S.~Gros, M.~Zanon, and A.~Bemporad.
\newblock Safe reinforcement learning via projection on a safe set: How to
  achieve optimality?
\newblock \emph{IFAC-PapersOnLine}, 53\penalty0 (2):\penalty0 8076--8081, 2020.
\newblock ISSN 2405-8963.
\newblock \doi{https://doi.org/10.1016/j.ifacol.2020.12.2276}.
\newblock URL
  \url{https://www.sciencedirect.com/science/article/pii/S2405896320329360}.
\newblock 21st IFAC World Congress.

\bibitem[Gu et~al.(2024)Gu, Yang, Du, Chen, Walter, Wang, and
  Knoll]{SafeReview}
S.~Gu, L.~Yang, Y.~Du, G.~Chen, F.~Walter, J.~Wang, and A.~Knoll.
\newblock A review of safe reinforcement learning: Methods, theory and
  applications, 2024.
\newblock URL \url{https://arxiv.org/abs/2205.10330}.

\bibitem[Halman and Nannicini(2019)]{StochDP-breaking-curse}
N.~Halman and G.~Nannicini.
\newblock Toward breaking the curse of dimensionality: An fptas for stochastic
  dynamic programs with multidimensional actions and scalar states.
\newblock \emph{SIAM Journal on Optimization}, 29\penalty0 (2):\penalty0
  1131--1163, 2019.
\newblock \doi{10.1137/18M1208423}.
\newblock URL \url{https://doi.org/10.1137/18M1208423}.

\bibitem[Halman et~al.(2014)Halman, Klabjan, Li, Orlin, and
  Simchi-Levi]{StochDP-FPTAS-genframework}
N.~Halman, D.~Klabjan, C.-L. Li, J.~Orlin, and D.~Simchi-Levi.
\newblock Fully polynomial time approximation schemes for stochastic dynamic
  programs.
\newblock \emph{SIAM Journal on Discrete Mathematics}, 28\penalty0
  (4):\penalty0 1725--1796, 2014.
\newblock \doi{10.1137/130925153}.
\newblock URL \url{https://doi.org/10.1137/130925153}.

\bibitem[HasanzadeZonuzy et~al.(2021)HasanzadeZonuzy, Bura, Kalathil, and
  Shakkottai]{cMDP-sample-complexity-safe}
A.~HasanzadeZonuzy, A.~Bura, D.~Kalathil, and S.~Shakkottai.
\newblock Learning with safety constraints: Sample complexity of reinforcement
  learning for constrained mdps.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence},
  35\penalty0 (9):\penalty0 7667--7674, 5 2021.
\newblock \doi{10.1609/aaai.v35i9.16937}.
\newblock URL \url{https://ojs.aaai.org/index.php/AAAI/article/view/16937}.

\bibitem[Hong and Williams(2023)]{cMDP-dual-search}
S.~Hong and B.~C. Williams.
\newblock An anytime algorithm for constrained stochastic shortest path
  problems with deterministic policies.
\newblock \emph{Artificial Intelligence}, 316:\penalty0 103846, 2023.
\newblock ISSN 0004-3702.
\newblock \doi{https://doi.org/10.1016/j.artint.2022.103846}.
\newblock URL
  \url{https://www.sciencedirect.com/science/article/pii/S0004370222001862}.

\bibitem[Hong et~al.(2021)Hong, Lee, Huang, Khonji, Alyassi, and
  Williams]{AircraftRoutingDet}
S.~Hong, S.~U. Lee, X.~Huang, M.~Khonji, R.~Alyassi, and B.~C. Williams.
\newblock An anytime algorithm for chance constrained stochastic shortest path
  problems and its application to aircraft routing.
\newblock In \emph{2021 IEEE International Conference on Robotics and
  Automation (ICRA)}, pages 475--481, 2021.
\newblock \doi{10.1109/ICRA48506.2021.9561229}.

\bibitem[Khonji et~al.(2019)Khonji, Jasour, and
  Williams]{cMDP-deterministic-constH}
M.~Khonji, A.~Jasour, and B.~Williams.
\newblock Approximability of constant-horizon constrained pomdp.
\newblock In \emph{Proceedings of the Twenty-Eighth International Joint
  Conference on Artificial Intelligence, {IJCAI-19}}, pages 5583--5590.
  International Joint Conferences on Artificial Intelligence Organization, 7
  2019.
\newblock \doi{10.24963/ijcai.2019/775}.
\newblock URL \url{https://doi.org/10.24963/ijcai.2019/775}.

\bibitem[Kolesar(1970)]{MedScheduling}
P.~Kolesar.
\newblock A markovian model for hospital admission scheduling.
\newblock \emph{Management Science}, 16\penalty0 (6):\penalty0 B384--B396,
  1970.
\newblock ISSN 00251909, 15265501.
\newblock URL \url{http://www.jstor.org/stable/2628725}.

\bibitem[Li et~al.(2021)Li, Fridovich-Keil, Sojoudi, and
  Tomlin]{InstantaneousSafeRL}
J.~Li, D.~Fridovich-Keil, S.~Sojoudi, and C.~J. Tomlin.
\newblock Augmented lagrangian method for instantaneously constrained
  reinforcement learning problems.
\newblock In \emph{2021 60th IEEE Conference on Decision and Control (CDC)},
  page 2982–2989. IEEE Press, 2021.
\newblock \doi{10.1109/CDC45484.2021.9683088}.
\newblock URL \url{https://doi.org/10.1109/CDC45484.2021.9683088}.

\bibitem[Li et~al.(2018)Li, Zhao, Sun, I, Yang, Chen, Zhao, and
  Zhang]{ResourceNetworkSlicing}
R.~Li, Z.~Zhao, Q.~Sun, C.-L. I, C.~Yang, X.~Chen, M.~Zhao, and H.~Zhang.
\newblock Deep reinforcement learning for resource management in network
  slicing.
\newblock \emph{IEEE Access}, 6:\penalty0 74429--74441, 2018.
\newblock \doi{10.1109/ACCESS.2018.2881964}.

\bibitem[Mao et~al.(2016)Mao, Alizadeh, Menache, and Kandula]{ResourceGeneral}
H.~Mao, M.~Alizadeh, I.~Menache, and S.~Kandula.
\newblock Resource management with deep reinforcement learning.
\newblock In \emph{Proceedings of the 15th ACM Workshop on Hot Topics in
  Networks}, HotNets '16, page 50–56, New York, NY, USA, 2016. Association
  for Computing Machinery.
\newblock ISBN 9781450346610.
\newblock \doi{10.1145/3005745.3005750}.
\newblock URL \url{https://doi.org/10.1145/3005745.3005750}.

\bibitem[McMahan and Zhu(2024)]{cMDP-Anytime}
J.~McMahan and X.~Zhu.
\newblock Anytime-constrained reinforcement learning.
\newblock In S.~Dasgupta, S.~Mandt, and Y.~Li, editors, \emph{Proceedings of
  The 27th International Conference on Artificial Intelligence and Statistics},
  volume 238 of \emph{Proceedings of Machine Learning Research}, pages
  4321--4329. PMLR, 02--04 May 2024.
\newblock URL \url{https://proceedings.mlr.press/v238/mcmahan24a.html}.

\bibitem[Paragliola et~al.(2018)Paragliola, Coronato, Naeem, and
  De~Pietro]{MedRisk}
G.~Paragliola, A.~Coronato, M.~Naeem, and G.~De~Pietro.
\newblock A reinforcement learning-based approach for the risk management of
  e-health environments: A case study.
\newblock In \emph{2018 14th International Conference on Signal-Image
  Technology \& Internet-Based Systems (SITIS)}, pages 711--716, 2018.
\newblock \doi{10.1109/SITIS.2018.00114}.

\bibitem[Paruchuri et~al.(2004)Paruchuri, Tambe, Ordonez, and
  Kraus]{TeamworkDet}
P.~Paruchuri, M.~Tambe, F.~Ordonez, and S.~Kraus.
\newblock Towards a formalization of teamwork with resource constraints.
\newblock In \emph{Third International Joint Conference on Autonomous Agents
  and Multiagent Systems}, United States, 2004. IEEE Computer Society.
\newblock Place of conference:USA.

\bibitem[Paternain et~al.(2019)Paternain, Chamon, Calvo-Fullana, and
  Ribeiro]{cMDP-ZeroDualityGap}
S.~Paternain, L.~Chamon, M.~Calvo-Fullana, and A.~Ribeiro.
\newblock Constrained reinforcement learning has zero duality gap.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32, 2019.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2019/file/c1aeb6517a1c7f33514f7ff69047e74e-Paper.pdf}.

\bibitem[Peng and Shen(2021)]{ResourceUAV}
H.~Peng and X.~Shen.
\newblock Multi-agent reinforcement learning based resource management in mec-
  and uav-assisted vehicular networks.
\newblock \emph{IEEE Journal on Selected Areas in Communications}, 39\penalty0
  (1):\penalty0 131--141, 2021.
\newblock \doi{10.1109/JSAC.2020.3036962}.

\bibitem[Puterman(1994)]{MDP-book}
M.~L. Puterman.
\newblock \emph{Markov Decision Processes: Discrete Stochastic Dynamic
  Programming}.
\newblock John Wiley \& Sons, Inc., USA, 1st edition, 1994.
\newblock ISBN 0471619779.

\bibitem[Roderick et~al.(2021)Roderick, Nagarajan, and Kolter]{SafeStatePAC}
M.~Roderick, V.~Nagarajan, and Z.~Kolter.
\newblock Provably safe pac-mdp exploration using analogies.
\newblock In A.~Banerjee and K.~Fukumizu, editors, \emph{Proceedings of The
  24th International Conference on Artificial Intelligence and Statistics},
  volume 130 of \emph{Proceedings of Machine Learning Research}, pages
  1216--1224. PMLR, 4 2021.
\newblock URL \url{https://proceedings.mlr.press/v130/roderick21a.html}.

\bibitem[Taleghan and Dietterich(2018)]{cMDP-efficient-exploration-violates}
M.~A. Taleghan and T.~G. Dietterich.
\newblock Efficient exploration for constrained mdps.
\newblock In \emph{2018 AAAI Spring Symposium Series}, 2018.

\bibitem[Thomas et~al.(2021)Thomas, Luo, and Ma]{Safe-RL-Imagining}
G.~Thomas, Y.~Luo, and T.~Ma.
\newblock Safe reinforcement learning by imagining the near future.
\newblock In M.~Ranzato, A.~Beygelzimer, Y.~Dauphin, P.~Liang, and J.~W.
  Vaughan, editors, \emph{Advances in Neural Information Processing Systems},
  volume~34, pages 13859--13869. Curran Associates, Inc., 2021.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2021/file/73b277c11266681122132d024f53a75b-Paper.pdf}.

\bibitem[{Tsai} et~al.(2019){Tsai}, {Phatak}, {Kitanidis}, and
  {Field}]{DisasterFlooding}
Y.~L. {Tsai}, A.~{Phatak}, P.~K. {Kitanidis}, and C.~B. {Field}.
\newblock {Deep Reinforcement Learning for Disaster Response: Navigating the
  Dynamic Emergency Vehicle and Rescue Team Dispatch during a Flood}.
\newblock In \emph{AGU Fall Meeting Abstracts}, volume 2019, pages NH33B--14,
  Dec. 2019.

\bibitem[Vaswani et~al.(2022)Vaswani, Yang, and Szepesvari]{cMDP-Pac}
S.~Vaswani, L.~Yang, and C.~Szepesvari.
\newblock Near-optimal sample complexity bounds for constrained mdps.
\newblock In S.~Koyejo, S.~Mohamed, A.~Agarwal, D.~Belgrave, K.~Cho, and A.~Oh,
  editors, \emph{Advances in Neural Information Processing Systems}, volume~35,
  pages 3110--3122. Curran Associates, Inc., 2022.
\newblock URL
  \url{https://proceedings.neurips.cc/paper_files/paper/2022/file/14a5ebc9cd2e507cd811df78c15bf5d7-Paper-Conference.pdf}.

\bibitem[Wang et~al.(2023)Wang, Zhan, Jiao, Wang, Jin, Yang, Wang, Huang, and
  Zhu]{SafeHardBarrier}
Y.~Wang, S.~S. Zhan, R.~Jiao, Z.~Wang, W.~Jin, Z.~Yang, Z.~Wang, C.~Huang, and
  Q.~Zhu.
\newblock Enforcing hard constraints with soft barriers: Safe reinforcement
  learning in unknown stochastic environments.
\newblock In A.~Krause, E.~Brunskill, K.~Cho, B.~Engelhardt, S.~Sabato, and
  J.~Scarlett, editors, \emph{Proceedings of the 40th International Conference
  on Machine Learning}, volume 202 of \emph{Proceedings of Machine Learning
  Research}, pages 36593--36604. PMLR, 7 2023.
\newblock URL \url{https://proceedings.mlr.press/v202/wang23as.html}.

\bibitem[Wei et~al.(2022)Wei, Liu, and Ying]{cMDP-Model-Violation-Free}
H.~Wei, X.~Liu, and L.~Ying.
\newblock Triple-q: A model-free algorithm for constrained reinforcement
  learning with sublinear regret and zero constraint violation.
\newblock In G.~Camps-Valls, F.~J.~R. Ruiz, and I.~Valera, editors,
  \emph{Proceedings of The 25th International Conference on Artificial
  Intelligence and Statistics}, volume 151 of \emph{Proceedings of Machine
  Learning Research}, pages 3274--3307. PMLR, 3 2022.
\newblock URL \url{https://proceedings.mlr.press/v151/wei22a.html}.

\bibitem[Williamson and Shmoys(2011)]{approx-book}
D.~P. Williamson and D.~B. Shmoys.
\newblock \emph{The Design of Approximation Algorithms}.
\newblock Cambridge University Press, USA, 1st edition, 2011.
\newblock ISBN 0521195276.

\bibitem[Wu et~al.(2019)Wu, Ju, Wu, Lin, Xiong, Xu, Li, and Liang]{DisasterUAV}
C.~Wu, B.~Ju, Y.~Wu, X.~Lin, N.~Xiong, G.~Xu, H.~Li, and X.~Liang.
\newblock Uav autonomous target search based on deep reinforcement learning in
  complex disaster scene.
\newblock \emph{IEEE Access}, 7:\penalty0 117227--117245, 2019.
\newblock \doi{10.1109/ACCESS.2019.2933002}.

\bibitem[Xu and Mannor(2011)]{CCMDP-GoalComplexity}
H.~Xu and S.~Mannor.
\newblock Probabilistic goal markov decision processes.
\newblock In \emph{Proceedings of the Twenty-Second International Joint
  Conference on Artificial Intelligence - Volume Volume Three}, IJCAI'11, page
  2046–2052. AAAI Press, 2011.
\newblock ISBN 9781577355151.

\bibitem[Yang et~al.(2022)Yang, Khuller, Choudhary, Mitra, and
  Mahadik]{CorrStocKnap}
S.~Yang, S.~Khuller, S.~Choudhary, S.~Mitra, and K.~Mahadik.
\newblock {Correlated Stochastic Knapsack with a Submodular Objective}.
\newblock In S.~Chechik, G.~Navarro, E.~Rotenberg, and G.~Herman, editors,
  \emph{30th Annual European Symposium on Algorithms (ESA 2022)}, volume 244 of
  \emph{Leibniz International Proceedings in Informatics (LIPIcs)}, pages
  91:1--91:14, Dagstuhl, Germany, 2022. Schloss Dagstuhl -- Leibniz-Zentrum
  f{\"u}r Informatik.
\newblock ISBN 978-3-95977-247-1.
\newblock \doi{10.4230/LIPIcs.ESA.2022.91}.
\newblock URL \url{https://drops.dagstuhl.de/opus/volltexte/2022/17029}.

\bibitem[Zhao et~al.(2023)Zhao, He, Chen, Wei, and Liu]{SafeStateSurvey}
W.~Zhao, T.~He, R.~Chen, T.~Wei, and C.~Liu.
\newblock State-wise safe reinforcement learning: a survey.
\newblock In \emph{Proceedings of the Thirty-Second International Joint
  Conference on Artificial Intelligence}, IJCAI '23, 2023.
\newblock ISBN 978-1-956792-03-4.
\newblock \doi{10.24963/ijcai.2023/763}.
\newblock URL \url{https://doi.org/10.24963/ijcai.2023/763}.

\end{thebibliography}
