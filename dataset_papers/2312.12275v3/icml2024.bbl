\begin{thebibliography}{46}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2023)Agarwal, Rahman, St-Charles, Prince, and Kahou]{agarwal2023transformers}
Agarwal, P., Rahman, A.~A., St-Charles, P.-L., Prince, S. J.~D., and Kahou, S.~E.
\newblock Transformers in reinforcement learning: A survey.
\newblock \emph{arXiv preprint arXiv: 2307.05979}, 2023.

\bibitem[Beattie et~al.(2016)Beattie, Leibo, Teplyashin, Ward, Wainwright, Küttler, Lefrancq, Green, Valdés, Sadik, Schrittwieser, Anderson, York, Cant, Cain, Bolton, Gaffney, King, Hassabis, Legg, and Petersen]{beattie2016deepmind}
Beattie, C., Leibo, J.~Z., Teplyashin, D., Ward, T., Wainwright, M., Küttler, H., Lefrancq, A., Green, S., Valdés, V., Sadik, A., Schrittwieser, J., Anderson, K., York, S., Cant, M., Cain, A., Bolton, A., Gaffney, S., King, H., Hassabis, D., Legg, S., and Petersen, S.
\newblock Deepmind lab.
\newblock \emph{arXiv preprint arXiv: 1612.03801}, 2016.

\bibitem[Brohan et~al.(2022)Brohan, Brown, Carbajal, Chebotar, Dabis, Finn, Gopalakrishnan, Hausman, Herzog, Hsu, Ibarz, Ichter, Irpan, Jackson, Jesmonth, Joshi, Julian, Kalashnikov, Kuang, Leal, Lee, Levine, Lu, Malla, Manjunath, Mordatch, Nachum, Parada, Peralta, Perez, Pertsch, Quiambao, Rao, Ryoo, Salazar, Sanketi, Sayed, Singh, Sontakke, Stone, Tan, Tran, Vanhoucke, Vega, Vuong, Xia, Xiao, Xu, Xu, Yu, and Zitkovich]{brohan2022rt1}
Brohan, A., Brown, N., Carbajal, J., Chebotar, Y., Dabis, J., Finn, C., Gopalakrishnan, K., Hausman, K., Herzog, A., Hsu, J., Ibarz, J., Ichter, B., Irpan, A., Jackson, T., Jesmonth, S., Joshi, N.~J., Julian, R.~C., Kalashnikov, D., Kuang, Y., Leal, I., Lee, K.-H., Levine, S., Lu, Y., Malla, U., Manjunath, D., Mordatch, I., Nachum, O., Parada, C., Peralta, J., Perez, E., Pertsch, K., Quiambao, J., Rao, K., Ryoo, M., Salazar, G., Sanketi, P., Sayed, K., Singh, J., Sontakke, S., Stone, A., Tan, C., Tran, H., Vanhoucke, V., Vega, S., Vuong, Q., Xia, F., Xiao, T., Xu, P., Xu, S., Yu, T., and Zitkovich, B.
\newblock Rt-1: Robotics transformer for real-world control at scale.
\newblock \emph{Robotics: Science and Systems}, 2022.
\newblock \doi{10.48550/arXiv.2212.06817}.

\bibitem[Brown et~al.(2020)Brown, Goo, and Niekum]{brown2020better}
Brown, D.~S., Goo, W., and Niekum, S.
\newblock Better-than-demonstrator imitation learning via automatically-ranked demonstrations.
\newblock In \emph{Conference on robot learning}, pp.\  330--359. PMLR, 2020.

\bibitem[Chen et~al.(2021)Chen, Lu, Rajeswaran, Lee, Grover, Laskin, Abbeel, Srinivas, and Mordatch]{chen2021decision}
Chen, L., Lu, K., Rajeswaran, A., Lee, K., Grover, A., Laskin, M., Abbeel, P., Srinivas, A., and Mordatch, I.
\newblock Decision transformer: Reinforcement learning via sequence modeling.
\newblock \emph{Neural Information Processing Systems}, 2021.

\bibitem[Dai et~al.(2022)Dai, Sun, Dong, Hao, Sui, and Wei]{dai2022can}
Dai, D., Sun, Y., Dong, L., Hao, Y., Sui, Z., and Wei, F.
\newblock Why can gpt learn in-context? language models secretly perform gradient descent as meta optimizers.
\newblock \emph{arXiv preprint arXiv:2212.10559}, 2022.

\bibitem[Duan et~al.(2016)Duan, Schulman, Chen, Bartlett, Sutskever, and Abbeel]{duan2016rl}
Duan, Y., Schulman, J., Chen, X., Bartlett, P.~L., Sutskever, I., and Abbeel, P.
\newblock Rl$^2$: Fast reinforcement learning via slow reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1611.02779}, 2016.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{finn2017model}
Finn, C., Abbeel, P., and Levine, S.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{International conference on machine learning}, pp.\  1126--1135. PMLR, 2017.

\bibitem[Fuchs et~al.(2021)Fuchs, Song, Kaufmann, Scaramuzza, and D{\"u}rr]{fuchs2021super}
Fuchs, F., Song, Y., Kaufmann, E., Scaramuzza, D., and D{\"u}rr, P.
\newblock Super-human performance in gran turismo sport using deep reinforcement learning.
\newblock \emph{IEEE Robotics and Automation Letters}, 6\penalty0 (3):\penalty0 4257--4264, 2021.

\bibitem[Hafner(2021)]{hafner2021benchmarking}
Hafner, D.
\newblock Benchmarking the spectrum of agent capabilities.
\newblock \emph{arXiv preprint arXiv: 2109.06780}, 2021.
\newblock URL \url{https://arxiv.org/abs/2109.06780v2}.

\bibitem[Hambro et~al.(2022)Hambro, Raileanu, Rothermel, Mella, Rocktäschel, Küttler, and Murray]{hambro2022dungeons}
Hambro, E., Raileanu, R., Rothermel, D., Mella, V., Rocktäschel, T., Küttler, H., and Murray, N.
\newblock Dungeons and data: A large-scale nethack dataset.
\newblock \emph{arXiv preprint arXiv: 2211.00539}, 2022.

\bibitem[Herzog et~al.(2023)Herzog, Rao, Hausman, Lu, Wohlhart, Yan, Lin, Arenas, Xiao, Kappler, Ho, Rettinghouse, Chebotar, Lee, Gopalakrishnan, Julian, Li, Fu, Wei, Ramesh, Holden, Kleiven, Rendleman, Kirmani, Bingham, Weisz, Xu, Lu, Bennice, Fong, Do, Lam, Bai, Holson, Quinlan, Brown, Kalakrishnan, Ibarz, Pastor, and Levine]{herzog2023deep}
Herzog, A., Rao, K., Hausman, K., Lu, Y., Wohlhart, P., Yan, M., Lin, J., Arenas, M.~G., Xiao, T., Kappler, D., Ho, D., Rettinghouse, J., Chebotar, Y., Lee, K.-H., Gopalakrishnan, K., Julian, R., Li, A., Fu, C.~K., Wei, B., Ramesh, S., Holden, K., Kleiven, K., Rendleman, D., Kirmani, S., Bingham, J., Weisz, J., Xu, Y., Lu, W., Bennice, M., Fong, C., Do, D., Lam, J., Bai, Y., Holson, B., Quinlan, M., Brown, N., Kalakrishnan, M., Ibarz, J., Pastor, P., and Levine, S.
\newblock Deep rl at scale: Sorting waste in office buildings with a fleet of mobile manipulators.
\newblock \emph{arXiv preprint arXiv: 2305.03270}, 2023.

\bibitem[Hochreiter et~al.(2001)Hochreiter, Younger, and Conwell]{hochreiter2001learning}
Hochreiter, S., Younger, A.~S., and Conwell, P.~R.
\newblock Learning to learn using gradient descent.
\newblock In \emph{Artificial Neural Networks—ICANN 2001: International Conference Vienna, Austria, August 21--25, 2001 Proceedings 11}, pp.\  87--94. Springer, 2001.

\bibitem[Janner et~al.(2021)Janner, Li, and Levine]{janner2021sequence}
Janner, M., Li, Q., and Levine, S.
\newblock Offline reinforcement learning as one big sequence modeling problem.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2021.

\bibitem[Jeon et~al.(2024)Jeon, Lee, Lei, and Roy]{jeon2024informationtheoretic}
Jeon, H.~J., Lee, J.~D., Lei, Q., and Roy, B.~V.
\newblock An information-theoretic analysis of in-context learning.
\newblock \emph{arXiv preprint arXiv: 2401.15530}, 2024.

\bibitem[Kirsch et~al.(2022)Kirsch, Harrison, Sohl-Dickstein, and Metz]{kirsch2022generalpurpose}
Kirsch, L., Harrison, J., Sohl-Dickstein, J., and Metz, L.
\newblock General-purpose in-context learning by meta-learning transformers.
\newblock \emph{arXiv preprint arXiv: 2212.04458}, 2022.
\newblock URL \url{https://arxiv.org/abs/2212.04458v2}.

\bibitem[Kirsch et~al.(2023)Kirsch, Harrison, Freeman, Sohl-Dickstein, and Schmidhuber]{kirsch2023towards}
Kirsch, L., Harrison, J., Freeman, C.~D., Sohl-Dickstein, J., and Schmidhuber, J.
\newblock Towards general-purpose in-context learning agents.
\newblock In \emph{NeurIPS 2023 Workshop on Distribution Shifts: New Frontiers with Foundation Models}, 2023.

\bibitem[Kurenkov et~al.(2023)Kurenkov, Nikulin, Tarasov, and Kolesnikov]{kurenkov2023katakomba}
Kurenkov, V., Nikulin, A., Tarasov, D., and Kolesnikov, S.
\newblock Katakomba: Tools and benchmarks for data-driven nethack.
\newblock \emph{NEURIPS}, 2023.

\bibitem[Küttler et~al.(2020)Küttler, Nardelli, Miller, Raileanu, Selvatici, Grefenstette, and Rocktäschel]{kuttler2020nethack}
Küttler, H., Nardelli, N., Miller, A.~H., Raileanu, R., Selvatici, M., Grefenstette, E., and Rocktäschel, T.
\newblock The nethack learning environment.
\newblock \emph{arXiv preprint arXiv: 2006.13760}, 2020.

\bibitem[Laskin et~al.(2022)Laskin, Wang, Oh, Parisotto, Spencer, Steigerwald, Strouse, Hansen, Filos, Brooks, et~al.]{laskin2022context}
Laskin, M., Wang, L., Oh, J., Parisotto, E., Spencer, S., Steigerwald, R., Strouse, D., Hansen, S., Filos, A., Brooks, E., et~al.
\newblock In-context reinforcement learning with algorithm distillation.
\newblock \emph{arXiv preprint arXiv:2210.14215}, 2022.

\bibitem[Lee et~al.(2023)Lee, Xie, Pacchiano, Chandak, Finn, Nachum, and Brunskill]{lee2023supervised}
Lee, J.~N., Xie, A., Pacchiano, A., Chandak, Y., Finn, C., Nachum, O., and Brunskill, E.
\newblock Supervised pretraining can learn in-context reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2306.14892}, 2023.

\bibitem[Lee et~al.(2022)Lee, Nachum, Yang, Lee, Freeman, Guadarrama, Fischer, Xu, Jang, Michalewski, et~al.]{lee2022multi}
Lee, K.-H., Nachum, O., Yang, M.~S., Lee, L., Freeman, D., Guadarrama, S., Fischer, I., Xu, W., Jang, E., Michalewski, H., et~al.
\newblock Multi-game decision transformers.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 27921--27936, 2022.

\bibitem[Lin et~al.(2022)Lin, Liu, and Sengupta]{lin2022switch}
Lin, Q., Liu, H., and Sengupta, B.
\newblock Switch trajectory transformer with distributional value approximation for multi-task reinforcement learning.
\newblock \emph{arXiv preprint arXiv: 2203.07413}, 2022.

\bibitem[Liu \& Abbeel(2023)Liu and Abbeel]{liu2023emergent}
Liu, H. and Abbeel, P.
\newblock Emergent agentic transformer from chain of hindsight experience.
\newblock \emph{International Conference On Machine Learning}, 2023.
\newblock \doi{10.48550/arXiv.2305.16554}.

\bibitem[Micheli et~al.(2023)Micheli, Alonso, and Fleuret]{iris2023}
Micheli, V., Alonso, E., and Fleuret, F.
\newblock Transformers are sample-efficient world models.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=vhFu1Acb0xb}.

\bibitem[Morris(1981)]{morris1981spatial}
Morris, R.~G.
\newblock Spatial localization does not require the presence of local cues.
\newblock \emph{Learning and motivation}, 12\penalty0 (2):\penalty0 239--260, 1981.

\bibitem[Muller et~al.(2021)Muller, Hollmann, Arango, Grabocka, and Hutter]{muller2021transformers}
Muller, S., Hollmann, N., Arango, S.~P., Grabocka, J., and Hutter, F.
\newblock Transformers can do bayesian inference.
\newblock \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://arxiv.org/abs/2112.10510v6}.

\bibitem[Nikulin et~al.(2023)Nikulin, Kurenkov, Zisman, Agarkov, Sinii, and Kolesnikov]{nikulin2023xlandminigrid}
Nikulin, A., Kurenkov, V., Zisman, I., Agarkov, A., Sinii, V., and Kolesnikov, S.
\newblock Xland-minigrid: Scalable meta-reinforcement learning environments in jax.
\newblock \emph{arXiv preprint arXiv: 2312.12044}, 2023.

\bibitem[Osband et~al.(2013)Osband, Russo, and Van~Roy]{osband2013more}
Osband, I., Russo, D., and Van~Roy, B.
\newblock (more) efficient reinforcement learning via posterior sampling.
\newblock \emph{Advances in Neural Information Processing Systems}, 26, 2013.
\newblock URL \url{https://arxiv.org/abs/1306.0940v5}.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, and Sutskever]{radford2019language}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I.
\newblock Language models are unsupervised multitask learners.
\newblock 2019.

\bibitem[Raffin et~al.(2021)Raffin, Hill, Gleave, Kanervisto, Ernestus, and Dormann]{stable-baselines3}
Raffin, A., Hill, A., Gleave, A., Kanervisto, A., Ernestus, M., and Dormann, N.
\newblock Stable-baselines3: Reliable reinforcement learning implementations.
\newblock \emph{Journal of Machine Learning Research}, 22\penalty0 (268):\penalty0 1--8, 2021.
\newblock URL \url{http://jmlr.org/papers/v22/20-1364.html}.

\bibitem[Reed et~al.(2022)Reed, Zolna, Parisotto, Colmenarejo, Novikov, Barth-Maron, Gimenez, Sulsky, Kay, Springenberg, Eccles, Bruce, Razavi, Edwards, Heess, Chen, Hadsell, Vinyals, Bordbar, and de~Freitas]{reed2022generalist}
Reed, S., Zolna, K., Parisotto, E., Colmenarejo, S.~G., Novikov, A., Barth-Maron, G., Gimenez, M., Sulsky, Y., Kay, J., Springenberg, J.~T., Eccles, T., Bruce, J., Razavi, A., Edwards, A., Heess, N., Chen, Y., Hadsell, R., Vinyals, O., Bordbar, M., and de~Freitas, N.
\newblock A generalist agent.
\newblock \emph{arXiv preprint arXiv: 2205.06175}, 2022.

\bibitem[Schrittwieser et~al.(2020)Schrittwieser, Antonoglou, Hubert, Simonyan, Sifre, Schmitt, Guez, Lockhart, Hassabis, Graepel, et~al.]{schrittwieser2020mastering}
Schrittwieser, J., Antonoglou, I., Hubert, T., Simonyan, K., Sifre, L., Schmitt, S., Guez, A., Lockhart, E., Hassabis, D., Graepel, T., et~al.
\newblock Mastering atari, go, chess and shogi by planning with a learned model.
\newblock \emph{Nature}, 588\penalty0 (7839):\penalty0 604--609, 2020.

\bibitem[Shi et~al.(2023)Shi, Jiang, Grigsby, Fan, and Zhu]{shi2023crossepisodic}
Shi, L.~X., Jiang, Y., Grigsby, J., Fan, L.~J., and Zhu, Y.
\newblock Cross-episodic curriculum for transformer agents.
\newblock \emph{NEURIPS}, 2023.

\bibitem[Sinii et~al.(2023)Sinii, Nikulin, Kurenkov, Zisman, and Kolesnikov]{sinii2023context}
Sinii, V., Nikulin, A., Kurenkov, V., Zisman, I., and Kolesnikov, S.
\newblock In-context reinforcement learning for variable action spaces.
\newblock \emph{arXiv preprint arXiv:2312.13327}, 2023.

\bibitem[Tai et~al.(2023)Tai, Towers, and Tower]{jun_jet_tai_2023_8140744}
Tai, J.~J., Towers, M., and Tower, E.
\newblock {Shimmy: Gymnasium and PettingZoo Wrappers for Commonly Used Environments}, June 2023.
\newblock URL \url{https://doi.org/10.5281/zenodo.8140744}.

\bibitem[Tarasov et~al.(2022)Tarasov, Nikulin, Akimov, Kurenkov, and Kolesnikov]{tarasov2022corl}
Tarasov, D., Nikulin, A., Akimov, D., Kurenkov, V., and Kolesnikov, S.
\newblock Corl: Research-oriented deep offline reinforcement learning library.
\newblock In \emph{3rd Offline RL Workshop: Offline RL as a ''Launchpad''}, 2022.
\newblock URL \url{https://openreview.net/forum?id=SyAS49bBcv}.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N., Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Vinyals et~al.(2019)Vinyals, Babuschkin, Czarnecki, Mathieu, Dudzik, Chung, Choi, Powell, Ewalds, Georgiev, et~al.]{vinyals2019grandmaster}
Vinyals, O., Babuschkin, I., Czarnecki, W.~M., Mathieu, M., Dudzik, A., Chung, J., Choi, D.~H., Powell, R., Ewalds, T., Georgiev, P., et~al.
\newblock Grandmaster level in starcraft ii using multi-agent reinforcement learning.
\newblock \emph{Nature}, 575\penalty0 (7782):\penalty0 350--354, 2019.

\bibitem[Von~Oswald et~al.(2023)Von~Oswald, Niklasson, Randazzo, Sacramento, Mordvintsev, Zhmoginov, and Vladymyrov]{von2023transformers}
Von~Oswald, J., Niklasson, E., Randazzo, E., Sacramento, J., Mordvintsev, A., Zhmoginov, A., and Vladymyrov, M.
\newblock Transformers learn in-context by gradient descent.
\newblock In \emph{International Conference on Machine Learning}, pp.\  35151--35174. PMLR, 2023.

\bibitem[Wang et~al.(2024)Wang, Blaser, Daneshmand, and Zhang]{wang2024transformers}
Wang, J., Blaser, E., Daneshmand, H., and Zhang, S.
\newblock Transformers learn temporal difference methods for in-context reinforcement learning, 2024.

\bibitem[Wang et~al.(2016)Wang, Kurth-Nelson, Tirumala, Soyer, Leibo, Munos, Blundell, Kumaran, and Botvinick]{wang2016learning}
Wang, J.~X., Kurth-Nelson, Z., Tirumala, D., Soyer, H., Leibo, J.~Z., Munos, R., Blundell, C., Kumaran, D., and Botvinick, M.
\newblock Learning to reinforcement learn.
\newblock \emph{arXiv preprint arXiv:1611.05763}, 2016.

\bibitem[Wei et~al.(2022)Wei, Tay, Bommasani, Raffel, Zoph, Borgeaud, Yogatama, Bosma, Zhou, Metzler, et~al.]{wei2022emergent}
Wei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Metzler, D., et~al.
\newblock Emergent abilities of large language models.
\newblock \emph{arXiv preprint arXiv:2206.07682}, 2022.

\bibitem[Xie et~al.(2021)Xie, Raghunathan, Liang, and Ma]{xie2021explanation}
Xie, S.~M., Raghunathan, A., Liang, P., and Ma, T.
\newblock An explanation of in-context learning as implicit bayesian inference.
\newblock \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://arxiv.org/abs/2111.02080v6}.

\bibitem[Yamagata et~al.(2022)Yamagata, Khalil, and Santos-Rodríguez]{yamagata2022qlearning}
Yamagata, T., Khalil, A., and Santos-Rodríguez, R.
\newblock Q-learning decision transformer: Leveraging dynamic programming for conditional sequence modelling in offline rl.
\newblock \emph{International Conference on Machine Learning}, 2022.
\newblock \doi{10.48550/arXiv.2209.03993}.

\bibitem[Zisman(2024)]{zisman2023agentic}
Zisman, I.
\newblock suessmann/agentic-transformer-pytorch: v1.0, 2024.
\newblock URL \url{https://zenodo.org/doi/10.5281/zenodo.10577992}.

\end{thebibliography}
