\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bar-Tal et~al.(2024)Bar-Tal, Chefer, Tov, Herrmann, Paiss, Zada, Ephrat, Hur, Li, Michaeli, et~al.]{bar2024lumiere}
Omer Bar-Tal, Hila Chefer, Omer Tov, Charles Herrmann, Roni Paiss, Shiran Zada, Ariel Ephrat, Junhwa Hur, Yuanzhen Li, Tomer Michaeli, et~al.
\newblock Lumiere: A space-time diffusion model for video generation.
\newblock \emph{arXiv preprint arXiv:2401.12945}, 2024.

\bibitem[Behrmann et~al.(2019)Behrmann, Grathwohl, Chen, Duvenaud, and Jacobsen]{behrmann2019invertible}
Jens Behrmann, Will Grathwohl, Ricky~TQ Chen, David Duvenaud, and J{\"o}rn-Henrik Jacobsen.
\newblock Invertible residual networks.
\newblock In \emph{International conference on machine learning}, pages 573--582. PMLR, 2019.

\bibitem[Brooks et~al.(2023)Brooks, Holynski, and Efros]{brooks2022instructpix2pix}
Tim Brooks, Aleksander Holynski, and Alexei~A. Efros.
\newblock Instruct{Pix2Pix}: Learning to follow image editing instructions.
\newblock In \emph{CVPR}, 2023.

\bibitem[Ceylan and Gutmann(2018)]{ceylan2018conditional}
Ciwan Ceylan and Michael~U Gutmann.
\newblock Conditional noise-contrastive estimation of unnormalised models.
\newblock In \emph{International Conference on Machine Learning}, pages 726--734. PMLR, 2018.

\bibitem[Chen et~al.(2021)Chen, Zhang, Zen, Weiss, Norouzi, Dehak, and Chan]{chen2021wavegrad}
Nanxin Chen, Yu~Zhang, Heiga Zen, Ron~J Weiss, Mohammad Norouzi, Najim Dehak, and William Chan.
\newblock Wave{G}rad 2: Iterative refinement for text-to-speech synthesis.
\newblock \emph{arXiv preprint arXiv:2106.09660}, 2021.

\bibitem[Chen et~al.(2019)Chen, Behrmann, Duvenaud, and Jacobsen]{chen2019residual}
Ricky~TQ Chen, Jens Behrmann, David~K Duvenaud, and J{\"o}rn-Henrik Jacobsen.
\newblock Residual flows for invertible generative modeling.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Choi et~al.(2022)Choi, Meng, Song, and Ermon]{choi2022density}
Kristy Choi, Chenlin Meng, Yang Song, and Stefano Ermon.
\newblock Density ratio estimation via infinitesimal classification.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pages 2552--2573. PMLR, 2022.

\bibitem[Chung and Ye(2022)]{chung2022score}
Hyungjin Chung and Jong~Chul Ye.
\newblock Score-based diffusion models for accelerated {MRI}.
\newblock \emph{Medical Image Analysis}, 80:\penalty0 102479, 2022.

\bibitem[Dhariwal and Nichol(2021)]{dhariwal2021diffusion}
Prafulla Dhariwal and Alexander Nichol.
\newblock Diffusion models beat {GAN}s on image synthesis.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 8780--8794, 2021.

\bibitem[Dinh et~al.(2016)Dinh, Sohl-Dickstein, and Bengio]{dinh2016density}
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
\newblock Density estimation using real {NVP}.
\newblock \emph{arXiv preprint arXiv:1605.08803}, 2016.

\bibitem[Efron(2011)]{efron2011tweedie}
Bradley Efron.
\newblock Tweedieâ€™s formula and selection bias.
\newblock \emph{Journal of the American Statistical Association}, 106\penalty0 (496):\penalty0 1602, 2011.

\bibitem[Girdhar et~al.(2023)Girdhar, Singh, Brown, Duval, Azadi, Rambhatla, Shah, Yin, Parikh, and Misra]{girdhar2023emu}
Rohit Girdhar, Mannat Singh, Andrew Brown, Quentin Duval, Samaneh Azadi, Sai~Saketh Rambhatla, Akbar Shah, Xi~Yin, Devi Parikh, and Ishan Misra.
\newblock Emu {V}ideo: Factorizing text-to-video generation by explicit image conditioning.
\newblock \emph{arXiv preprint arXiv:2311.10709}, 2023.

\bibitem[Grathwohl et~al.(2018)Grathwohl, Chen, Bettencourt, Sutskever, and Duvenaud]{grathwohl2018ffjord}
Will Grathwohl, Ricky~TQ Chen, Jesse Bettencourt, Ilya Sutskever, and David Duvenaud.
\newblock {FFJORD}: Free-form continuous dynamics for scalable reversible generative models.
\newblock \emph{arXiv preprint arXiv:1810.01367}, 2018.

\bibitem[Grover and Ermon(2018)]{grover2018boosted}
Aditya Grover and Stefano Ermon.
\newblock Boosted generative models.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~32, 2018.

\bibitem[Gutmann and Hyv{\"a}rinen(2012)]{gutmann2012noise}
Michael~U Gutmann and Aapo Hyv{\"a}rinen.
\newblock Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics.
\newblock \emph{Journal of machine learning research}, 13\penalty0 (2), 2012.

\bibitem[Hertz et~al.(2022)Hertz, Mokady, Tenenbaum, Aberman, Pritch, and Cohen-Or]{hertz2022prompt}
Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, and Daniel Cohen-Or.
\newblock Prompt-to-prompt image editing with cross attention control.
\newblock \emph{arXiv preprint arXiv:2208.01626}, 2022.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and Hochreiter]{fid}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
\newblock {GAN}s trained by a two time-scale update rule converge to a local nash equilibrium.
\newblock In \emph{Advances in Neural Information Processing Systems}, volume~30, 2017.

\bibitem[Ho and Salimans(2022)]{ho2022classifier}
Jonathan Ho and Tim Salimans.
\newblock Classifier-free diffusion guidance.
\newblock \emph{arXiv preprint arXiv:2207.12598}, 2022.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 6840--6851, 2020.

\bibitem[Huberman-Spiegelglas et~al.(2023)Huberman-Spiegelglas, Kulikov, and Michaeli]{HubermanSpiegelglas2023}
Inbar Huberman-Spiegelglas, Vladimir Kulikov, and Tomer Michaeli.
\newblock An edit friendly {DDPM} noise space: Inversion and manipulations.
\newblock \emph{arXiv preprint arXiv:2304.06140}, 2023.

\bibitem[Kawar et~al.(2022)Kawar, Elad, Ermon, and Song]{kawar2022denoising}
Bahjat Kawar, Michael Elad, Stefano Ermon, and Jiaming Song.
\newblock Denoising diffusion restoration models.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 23593--23606, 2022.

\bibitem[Kingma et~al.(2021)Kingma, Salimans, Poole, and Ho]{kingma2021variational}
Diederik Kingma, Tim Salimans, Ben Poole, and Jonathan Ho.
\newblock Variational diffusion models.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 21696--21707, 2021.

\bibitem[Kingma and Cun(2010)]{kingma2010regularized}
Durk~P Kingma and Yann Cun.
\newblock Regularized estimation of image statistics by score matching.
\newblock \emph{Advances in neural information processing systems}, 23, 2010.

\bibitem[Kingma and Dhariwal(2018)]{kingma2018glow}
Durk~P Kingma and Prafulla Dhariwal.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Kong et~al.(2021)Kong, Ping, Huang, Zhao, and Catanzaro]{kong2021diffwave}
Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, and Bryan Catanzaro.
\newblock Diff{W}ave: A versatile diffusion model for audio synthesis.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton, et~al.]{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock \emph{University of Toronto}, 2009.

\bibitem[Lazarow et~al.(2017)Lazarow, Jin, and Tu]{lazarow2017introspective}
Justin Lazarow, Long Jin, and Zhuowen Tu.
\newblock Introspective neural networks for generative modeling.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer Vision}, pages 2774--2783, 2017.

\bibitem[LeCun(1998)]{lecun1998mnist}
Yan LeCun.
\newblock The {MNIST} database of handwritten digits.
\newblock 1998.
\newblock URL \url{http://yann. lecun. com/exdb/mnist/}.

\bibitem[Lipman et~al.(2022)Lipman, Chen, Ben-Hamu, Nickel, and Le]{lipman2022flow}
Yaron Lipman, Ricky~TQ Chen, Heli Ben-Hamu, Maximilian Nickel, and Matt Le.
\newblock Flow matching for generative modeling.
\newblock \emph{arXiv preprint arXiv:2210.02747}, 2022.

\bibitem[Liu et~al.(2022)Liu, Gong, and Liu]{liu2022flow}
Xingchao Liu, Chengyue Gong, and Qiang Liu.
\newblock Flow straight and fast: Learning to generate and transfer data with rectified flow.
\newblock \emph{arXiv preprint arXiv:2209.03003}, 2022.

\bibitem[Liu et~al.(2015)Liu, Luo, Wang, and Tang]{liu2015CelebA}
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.
\newblock Deep learning face attributes in the wild.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer Vision}, pages 3730--3738, 2015.

\bibitem[Lu et~al.(2022)Lu, Zhou, Bao, Chen, Li, and Zhu]{lu2022dpm}
Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu.
\newblock Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 5775--5787, 2022.

\bibitem[Meng et~al.(2021)Meng, He, Song, Song, Wu, Zhu, and Ermon]{meng2021sdedit}
Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and Stefano Ermon.
\newblock {SDE}dit: Guided image synthesis and editing with stochastic differential equations.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Miyasawa et~al.(1961)]{miyasawa1961empirical}
Koichi Miyasawa et~al.
\newblock An empirical bayes estimator of the mean of a normal population.
\newblock \emph{Bull. Inst. Internat. Statist}, 38\penalty0 (181-188):\penalty0 1--2, 1961.

\bibitem[Rhodes et~al.(2020)Rhodes, Xu, and Gutmann]{rhodes2020telescoping}
Benjamin Rhodes, Kai Xu, and Michael~U Gutmann.
\newblock Telescoping density-ratio estimation.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 4905--4916, 2020.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 10684--10695, 2022.

\bibitem[Saharia et~al.(2022)Saharia, Chan, Chang, Lee, Ho, Salimans, Fleet, and Norouzi]{saharia2022palette}
Chitwan Saharia, William Chan, Huiwen Chang, Chris Lee, Jonathan Ho, Tim Salimans, David Fleet, and Mohammad Norouzi.
\newblock Palette: Image-to-image diffusion models.
\newblock In \emph{ACM SIGGRAPH 2022 Conference Proceedings}, pages 1--10, 2022.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and Ganguli]{sohl2015deep}
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In \emph{International conference on machine learning}, pages 2256--2265. PMLR, 2015.

\bibitem[Song et~al.(2020{\natexlab{a}})Song, Meng, and Ermon]{song2020denoising}
Jiaming Song, Chenlin Meng, and Stefano Ermon.
\newblock Denoising diffusion implicit models.
\newblock \emph{arXiv preprint arXiv:2010.02502}, 2020{\natexlab{a}}.

\bibitem[Song and Ermon(2019)]{song2019generative}
Yang Song and Stefano Ermon.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Song et~al.(2019)Song, Meng, and Ermon]{song2019mintnet}
Yang Song, Chenlin Meng, and Stefano Ermon.
\newblock Mint{N}et: Building invertible neural networks with masked convolutions.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Song et~al.(2020{\natexlab{b}})Song, Garg, Shi, and Ermon]{song2020sliced}
Yang Song, Sahaj Garg, Jiaxin Shi, and Stefano Ermon.
\newblock Sliced score matching: A scalable approach to density and score estimation.
\newblock In \emph{Uncertainty in Artificial Intelligence}, pages 574--584. PMLR, 2020{\natexlab{b}}.

\bibitem[Song et~al.(2020{\natexlab{c}})Song, Sohl-Dickstein, Kingma, Kumar, Ermon, and Poole]{song2020score}
Yang Song, Jascha Sohl-Dickstein, Diederik~P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole.
\newblock Score-based generative modeling through stochastic differential equations.
\newblock \emph{arXiv preprint arXiv:2011.13456}, 2020{\natexlab{c}}.

\bibitem[Song et~al.(2023)Song, Shen, Xing, and Ermon]{song2023solving}
Yang Song, Liyue Shen, Lei Xing, and Stefano Ermon.
\newblock Solving inverse problems in medical imaging with score-based generative models.
\newblock In \emph{International Conference on Learning Representations}, 2023.

\bibitem[Stein(1981)]{stein1981estimation}
Charles~M Stein.
\newblock Estimation of the mean of a multivariate normal distribution.
\newblock \emph{The annals of Statistics}, pages 1135--1151, 1981.

\bibitem[Sugiyama et~al.(2012)Sugiyama, Suzuki, and Kanamori]{sugiyama2012density}
Masashi Sugiyama, Taiji Suzuki, and Takafumi Kanamori.
\newblock \emph{Density ratio estimation in machine learning}.
\newblock Cambridge University Press, 2012.

\bibitem[Yair and Michaeli(2022)]{yair2022thinking}
Omer Yair and Tomer Michaeli.
\newblock Thinking fourth dimensionally: Treating time as a random variable in ebms.
\newblock \emph{https://openreview.net/forum?id=m0fEJ2bvwpw}, 2022.

\end{thebibliography}
