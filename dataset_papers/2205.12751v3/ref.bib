@article{kakade2009duality,
  title={On the duality of strong convexity and strong smoothness: Learning applications and matrix regularization},
  author={Kakade, Sham and Shalev-Shwartz, Shai and Tewari, Ambuj and others},
  journal={Unpublished Manuscript, http://ttic. uchicago. edu/shai/papers/KakadeShalevTewari09. pdf},
  volume={2},
  number={1},
  year={2009}
}

@inproceedings{berthet2020learning,
 author = {Berthet, Quentin and Blondel, Mathieu and Teboul, Olivier and Cuturi, Marco and Vert, Jean-Philippe and Bach, Francis},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 title = {Learning with Differentiable Pertubed Optimizers},
 year = {2020}
}


@article{lu2018relatively,
  title={Relatively smooth convex optimization by first-order methods, and applications},
  author={Lu, Haihao and Freund, Robert M. and Nesterov, Yurii},
  journal={SIAM Journal on Optimization},
  volume={28},
  number={1},
  pages={333--354},
  year={2018},
  publisher={SIAM}
}


@article{radhakrishnan2020linear,
  title={Linear Convergence of Generalized Mirror Descent with Time-Dependent Mirrors},
  author={Radhakrishnan, Adityanarayanan and Belkin, Mikhail and Uhler, Caroline},
  journal={arXiv preprint 2009.08574},
  year={2020}
}

@article{bubeck2014convex,
  title={Convex optimization: Algorithms and complexity},
  author={Bubeck, S{\'e}bastien},
  journal={arXiv preprint 1405.4980},
  year={2014}
}


@phdthesis{dragomir2021bregman,
  title={Bregman Gradient Methods for Relatively-Smooth Optimization},
  author={Dragomir, Radu-Alexandru},
  year={2021},
  school={UT1 Capitole}
}

@article{hanzely2021fastest,
  title={Fastest rates for stochastic mirror descent methods},
  author={Hanzely, Filip and Richt{\'a}rik, Peter},
  journal={Computational Optimization and Applications},
  pages={1--50},
  year={2021},
  publisher={Springer}
}

@article{d2021acceleration,
  title={Acceleration Methods},
  author={d’Aspremont, Alexandre and Scieur, Damien and Taylor, Adrien},
  journal={Foundations and Trends{\textregistered} in Optimization},
  volume={5},
  number={1-2},
  pages={1--245},
  year={2021}
}


@article{lacoste2015global,
  title={On the global linear convergence of Frank-Wolfe optimization variants},
  author={Lacoste-Julien, Simon and Jaggi, Martin},
  journal={Advances in Neural Information Processing Systems (NIPS)},
  year={2015}
}



@article{diakonikolas2021complementary,
  title={Complementary composite minimization, small gradients in general norms, and applications to regression problems},
  author={Diakonikolas, Jelena and Guzm{\'a}n, Crist{\'o}bal},
  journal={arXiv preprint 2101.11041},
  year={2021}
}


@book{nesterov2003introductory,
  title={Introductory Lectures on Convex Optimization: A Basic Course},
  author={Nesterov, Yurii},
  year={2003},
  publisher={Springer Science \& Business Media}
}


@book{rockafellar2015convex,
  title={Convex Analysis},
  author={Rockafellar, Ralph T.},
  year={2015},
  publisher={Princeton University Press}
}


@inproceedings{nesterov1983method,
  title={A method for unconstrained convex minimization problem with the rate of convergence ${O}(1/k^2)$},
  author={Nesterov, Yurii},
  booktitle={Doklady an USSR},
  volume={269},
  pages={543--547},
  year={1983}
}


@article{frank1956algorithm,
  title={An algorithm for quadratic programming},
  author={Frank, Marguerite and Wolfe, Philip},
  journal={Naval research logistics quarterly},
  volume={3},
  number={1-2},
  pages={95--110},
  year={1956},
  publisher={Wiley Online Library}
}


@article{lan2013complexity,
  title={The complexity of large-scale convex programming under a linear optimization oracle},
  author={Lan, Guanghui},
  journal={arXiv preprint 1309.5550},
  year={2013}
}

@inproceedings{jaggi2013revisiting,
  title={Revisiting Frank-Wolfe: Projection-free sparse convex optimization},
  author={Jaggi, Martin},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2013}
}

@book{demianov1970approximate,
  title={Approximate methods in optimization problems},
  author={Demyanov, Vladimir Fedorovich and Rubinov, Aleksandr Moiseevich},
  year={1970},
  publisher={Elsevier Publishing Company}
}

@article{levitin1966constrained,
  title={Constrained minimization methods},
  author={Levitin, Evgeny S. and Polyak, Boris T.},
  journal={USSR Computational mathematics and mathematical physics},
  volume={6},
  number={5},
  pages={1--50},
  year={1966},
  publisher={No longer published by Elsevier}
}

@article{guelat1986some,
  title={Some comments on {W}olfe's ‘away step’},
  author={Gu{\'e}lat, Jacques and Marcotte, Patrice},
  journal={Mathematical Programming},
  volume={35},
  number={1},
  pages={110--119},
  year={1986},
  publisher={Springer}
}

@phdthesis{jaggi2011sparse,
  title={Sparse Convex Optimization Methods for Machine Learning},
  author={Jaggi, Martin},
  year={2011},
  school={ETH Zurich}
}

@article{bach2020effectiveness,
author = {Bach, Francis},
title = {On the Effectiveness of {R}ichardson Extrapolation in Data Science},
journal = {SIAM Journal on Mathematics of Data Science},
volume = {3},
number = {4},
pages = {1251-1277},
year = {2021}
}



@article{li2020does,
  title={How does momentum help {F}rank {W}olfe?},
  author={Li, Bingcong and Coutino, Mario and Giannakis, Georgios B. and Leus, Geert},
  journal={arXiv preprint 2006.11116},
  year={2020}
}


@inproceedings{aybat2019universally,
  title={A universally optimal multistage accelerated stochastic gradient method},
  author={Aybat, Necdet S. and Fallah, Alireza and Gurbuzbalaban, Mert and Ozdaglar, Asuman},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2019}
}


@article{gasnikov2018universal,
  title={Universal method for stochastic composite optimization problems},
  author={Gasnikov, Alexander V. and Nesterov, Yurii},
  journal={Computational Mathematics and Mathematical Physics},
  volume={58},
  number={1},
  pages={48--64},
  year={2018},
  publisher={Springer}
}


@article{beck2009fast,
  title={A fast iterative shrinkage-thresholding algorithm for linear inverse problems},
  author={Beck, Amir and Teboulle, Marc},
  journal={SIAM journal on imaging sciences},
  volume={2},
  number={1},
  pages={183--202},
  year={2009},
  publisher={SIAM}
}

@article{freund2017extended,
  title={An Extended {F}rank--{W}olfe Method with “In-Face” Directions, and Its Application to Low-Rank Matrix Completion},
  author={Freund, Robert M. and Grigas, Paul and Mazumder, Rahul},
  journal={SIAM Journal on optimization},
  volume={27},
  number={1},
  pages={319--346},
  year={2017},
  publisher={SIAM}
}

@article{harchaoui2015conditional,
  title={Conditional gradient algorithms for norm-regularized smooth convex optimization},
  author={Harchaoui, Zaid and Juditsky, Anatoli and Nemirovski, Arkadi},
  journal={Mathematical Programming},
  volume={152},
  number={1},
  pages={75--112},
  year={2015},
  publisher={Springer}
}


@article{lan2012optimal,
  title={An optimal method for stochastic composite optimization},
  author={Lan, Guanghui},
  journal={Mathematical Programming},
  volume={133},
  number={1},
  pages={365--397},
  year={2012},
  publisher={Springer}
}


@article{nesterov2013gradient,
  title={Gradient methods for minimizing composite functions},
  author={Nesterov, Yurii},
  journal={Mathematical Programming},
  volume={140},
  number={1},
  pages={125--161},
  year={2013},
  publisher={Springer}
}

@phdthesis{devolder2013exactness,
  title={Exactness, inexactness and stochasticity in first-order methods for large-scale convex optimization},
  author={Devolder, Olivier},
  year={2013},
  school={PhD thesis, ICTEAM and CORE, Universit{\'e} Catholique de Louvain}
}

@article{bach2015duality,
  title={Duality between subgradient and conditional gradient methods},
  author={Bach, Francis},
  journal={SIAM Journal on Optimization},
  volume={25},
  number={1},
  pages={115--129},
  year={2015},
  publisher={SIAM}
}


@book{rockafellar2009variational,
  title={Variational Analysis},
  author={Rockafellar, Ralph T. and Wets, Roger J.-B.},
  year={2009},
  publisher={Springer Science \& Business Media}
}

@inproceedings{abernethy2014online,
  title={Online linear optimization via smoothing},
  author={Abernethy, Jacob and Lee, Chansoo and Sinha, Abhinav and Tewari, Ambuj},
  booktitle={Conference on Learning Theory (COLT)},
  year={2014}
}


@article{abernethy2016perturbation,
  title={Perturbation techniques in online learning and optimization},
  author={Abernethy, Jacob and Lee, Chansoo and Tewari, Ambuj},
  journal={Perturbations, Optimization, and Statistics},
  pages={223},
  year={2016},
  publisher={MIT Press}
}


@article{duchi2012randomized,
  title={Randomized smoothing for stochastic optimization},
  author={Duchi, John C. and Bartlett, Peter L. and Wainwright, Martin J.},
  journal={SIAM Journal on Optimization},
  volume={22},
  number={2},
  pages={674--701},
  year={2012},
  publisher={SIAM}
}


@article{nesterov2017random,
  title={Random gradient-free minimization of convex functions},
  author={Nesterov, Yurii and Spokoiny, Vladimir},
  journal={Foundations of Computational Mathematics},
  volume={17},
  number={2},
  pages={527--566},
  year={2017},
  publisher={Springer}
}


@article{hendrikx2020dual,
  title={Dual-free stochastic decentralized optimization with variance reduction},
  author={Hendrikx, Hadrien and Bach, Francis and Massouli{\'e}, Laurent},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2020}
}


@article{lan2018optimal,
  title={An optimal randomized incremental gradient method},
  author={Lan, Guanghui and Zhou, Yi},
  journal={Mathematical programming},
  volume={171},
  number={1},
  pages={167--215},
  year={2018},
  publisher={Springer}
}

@inproceedings{wang2017exploiting,
  title={Exploiting strong convexity from data with primal-dual first-order algorithms},
  author={Wang, Jialei and Xiao, Lin},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017}
}


@book{gumbel1954statistical,
  title={Statistical theory of extreme values and some practical applications: a series of lectures},
  author={Gumbel, Emil J.},
  volume={33},
  year={1954},
  publisher={US Government Printing Office}
}


@inproceedings{hazan2016variance,
  title={Variance-reduced and projection-free stochastic optimization},
  author={Hazan, Elad and Luo, Haipeng},
  booktitle={International Conference on Machine Learning},
  pages={1263--1271},
  year={2016},
  organization={PMLR}
}

@inproceedings{negiar2020stochastic,
  title={Stochastic Frank-Wolfe for constrained finite-sum minimization},
  author={N{\'e}giar, Geoffrey and Dresdner, Gideon and Tsai, Alicia and El Ghaoui, Laurent and Locatello, Francesco and Freund, Robert and Pedregosa, Fabian},
  booktitle={International Conference on Machine Learning},
  pages={7253--7262},
  year={2020},
  organization={PMLR}
}


@article{ball1994sharp,
  title={Sharp uniform convexity and smoothness inequalities for trace norms},
  author={Ball, Keith and Carlen, Eric A and Lieb, Elliott H},
  journal={Inventiones mathematicae},
  volume={115},
  number={1},
  pages={463--482},
  year={1994},
  publisher={Springer}
}



@article{kakade2008complexity,
  title={On the complexity of linear prediction: Risk bounds, margin bounds, and regularization},
  author={Kakade, Sham M and Sridharan, Karthik and Tewari, Ambuj},
  journal={Advances in neural information processing systems},
  volume={21},
  year={2008}
}


@article{jaxopt_implicit_diff,
  title={Efficient and Modular Implicit Differentiation},
  author={Blondel, Mathieu and Berthet, Quentin and Cuturi, Marco and Frostig, Roy 
    and Hoyer, Stephan and Llinares-L{\'o}pez, Felipe and Pedregosa, Fabian 
    and Vert, Jean-Philippe},
  journal={arXiv preprint arXiv:2105.15183},
  year={2021}
}


@inproceedings{garber2015faster,
  title={Faster rates for the frank-wolfe method over strongly-convex sets},
  author={Garber, Dan and Hazan, Elad},
  booktitle={International Conference on Machine Learning},
  pages={541--549},
  year={2015},
  organization={PMLR}
}


@inproceedings{cohen2021relative,
  title={Relative Lipschitzness in Extragradient Methods and a Direct Recipe for Acceleration},
  author={Cohen, Michael B and Sidford, Aaron and Tian, Kevin},
  booktitle={12th Innovations in Theoretical Computer Science Conference (ITCS 2021)},
  volume={185},
  year={2021}
}

@article{jin2022sharper,
  title={Sharper rates for separable minimax and finite sum optimization via primal-dual extragradient methods},
  author={Jin, Yujia and Sidford, Aaron and Tian, Kevin},
  journal={arXiv preprint arXiv:2202.04640},
  year={2022}
}


@article{lan2016conditional,
  title={Conditional gradient sliding for convex optimization},
  author={Lan, Guanghui and Zhou, Yi},
  journal={SIAM Journal on Optimization},
  volume={26},
  number={2},
  pages={1379--1409},
  year={2016},
  publisher={SIAM}
}


@article{ghadimi2019conditional,
  title={Conditional gradient type methods for composite nonlinear and stochastic optimization},
  author={Ghadimi, Saeed},
  journal={Mathematical Programming},
  volume={173},
  number={1},
  pages={431--464},
  year={2019},
  publisher={Springer}
}

@article{bottou2018optimization,
  title={Optimization methods for large-scale machine learning},
  author={Bottou, L{\'e}on and Curtis, Frank E and Nocedal, Jorge},
  journal={Siam Review},
  volume={60},
  number={2},
  pages={223--311},
  year={2018},
  publisher={SIAM}
}

@inproceedings{vaswani2022towards,
  title={Towards Noise-adaptive, Problem-adaptive (Accelerated) Stochastic Gradient Descent},
  author={Vaswani, Sharan and Dubois-Taine, Benjamin and Babanezhad, Reza},
  booktitle={International Conference on Machine Learning},
  pages={22015--22059},
  year={2022},
  organization={PMLR}
}


@article{vaswani2019painless,
  title={Painless stochastic gradient: Interpolation, line-search, and convergence rates},
  author={Vaswani, Sharan and Mishkin, Aaron and Laradji, Issam and Schmidt, Mark and Gidel, Gauthier and Lacoste-Julien, Simon},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}