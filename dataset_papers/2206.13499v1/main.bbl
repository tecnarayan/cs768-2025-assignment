\begin{thebibliography}{42}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Altae-Tran et~al.(2017)Altae-Tran, Ramsundar, Pappu, and
  Pande]{altae2017low}
Altae-Tran, H., Ramsundar, B., Pappu, A.~S., and Pande, V.
\newblock Low data drug discovery with one-shot learning.
\newblock \emph{ACS central science}, 3\penalty0 (4):\penalty0 283--293, 2017.

\bibitem[Bertinetto et~al.(2016)Bertinetto, Henriques, Valmadre, Torr, and
  Vedaldi]{bertinetto2016learning}
Bertinetto, L., Henriques, J.~F., Valmadre, J., Torr, P., and Vedaldi, A.
\newblock Learning feed-forward one-shot learners.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  523--531, 2016.

\bibitem[Brock et~al.(2017)Brock, Lim, Ritchie, and Weston]{brock2017smash}
Brock, A., Lim, T., Ritchie, J.~M., and Weston, N.
\newblock Smash: one-shot model architecture search through hypernetworks.
\newblock \emph{arXiv preprint arXiv:1708.05344}, 2017.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Brown, T.~B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock \emph{arXiv preprint arXiv:2005.14165}, 2020.

\bibitem[Carion et~al.(2020)Carion, Massa, Synnaeve, Usunier, Kirillov, and
  Zagoruyko]{carion2020end}
Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov, A., and Zagoruyko,
  S.
\newblock End-to-end object detection with transformers.
\newblock In \emph{European Conference on Computer Vision}, pp.\  213--229.
  Springer, 2020.

\bibitem[Chen et~al.(2021)Chen, Lu, Rajeswaran, Lee, Grover, Laskin, Abbeel,
  Srinivas, and Mordatch]{chen2021decision}
Chen, L., Lu, K., Rajeswaran, A., Lee, K., Grover, A., Laskin, M., Abbeel, P.,
  Srinivas, A., and Mordatch, I.
\newblock Decision transformer: Reinforcement learning via sequence modeling.
\newblock \emph{arXiv preprint arXiv:2106.01345}, 2021.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Dong et~al.(2018)Dong, Zhu, Zhang, Yang, and Wu]{dong2018fast}
Dong, X., Zhu, L., Zhang, D., Yang, Y., and Wu, F.
\newblock Fast parameter adaptation for few-shot image captioning and visual
  question answering.
\newblock In \emph{Proceedings of the 26th ACM international conference on
  Multimedia}, pp.\  54--62, 2018.

\bibitem[Duan et~al.(2017)Duan, Andrychowicz, Stadie, Ho, Schneider, Sutskever,
  Abbeel, and Zaremba]{duan2017one}
Duan, Y., Andrychowicz, M., Stadie, B.~C., Ho, J., Schneider, J., Sutskever,
  I., Abbeel, P., and Zaremba, W.
\newblock One-shot imitation learning.
\newblock \emph{arXiv preprint arXiv:1703.07326}, 2017.

\bibitem[Ebert et~al.(2018)Ebert, Finn, Dasari, Xie, Lee, and
  Levine]{ebert2018visual}
Ebert, F., Finn, C., Dasari, S., Xie, A., Lee, A., and Levine, S.
\newblock Visual foresight: Model-based deep reinforcement learning for
  vision-based robotic control.
\newblock \emph{arXiv preprint arXiv:1812.00568}, 2018.

\bibitem[Finn et~al.(2017{\natexlab{a}})Finn, Abbeel, and
  Levine]{finn2017model}
Finn, C., Abbeel, P., and Levine, S.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1126--1135. PMLR, 2017{\natexlab{a}}.

\bibitem[Finn et~al.(2017{\natexlab{b}})Finn, Yu, Zhang, Abbeel, and
  Levine]{finn2017one}
Finn, C., Yu, T., Zhang, T., Abbeel, P., and Levine, S.
\newblock One-shot visual imitation learning via meta-learning.
\newblock In \emph{Conference on Robot Learning}, pp.\  357--368. PMLR,
  2017{\natexlab{b}}.

\bibitem[Fujimoto et~al.(2018)Fujimoto, Hoof, and
  Meger]{fujimoto2018addressing}
Fujimoto, S., Hoof, H., and Meger, D.
\newblock Addressing function approximation error in actor-critic methods.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1587--1596. PMLR, 2018.

\bibitem[Furuta et~al.(2021)Furuta, Matsuo, and Gu]{furuta2021generalized}
Furuta, H., Matsuo, Y., and Gu, S.~S.
\newblock Generalized decision transformer for offline hindsight information
  matching.
\newblock \emph{arXiv preprint arXiv:2111.10364}, 2021.

\bibitem[Gao et~al.(2020)Gao, Fisch, and Chen]{gao2020making}
Gao, T., Fisch, A., and Chen, D.
\newblock Making pre-trained language models better few-shot learners.
\newblock \emph{arXiv preprint arXiv:2012.15723}, 2020.

\bibitem[Haarnoja et~al.(2018)Haarnoja, Zhou, Abbeel, and
  Levine]{haarnoja2018soft}
Haarnoja, T., Zhou, A., Abbeel, P., and Levine, S.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement
  learning with a stochastic actor.
\newblock In \emph{International conference on machine learning}, pp.\
  1861--1870. PMLR, 2018.

\bibitem[Islam et~al.(2019)Islam, Teru, Sharma, and
  Pineau]{islam_off-policy_2019}
Islam, R., Teru, K.~K., Sharma, D., and Pineau, J.
\newblock Off-{{Policy Policy Gradient Algorithms}} by {{Constraining}} the
  {{State Distribution Shift}}.
\newblock \emph{arXiv:1911.06970 [cs, stat]}, 2019.

\bibitem[Janner et~al.(2021)Janner, Li, and Levine]{janner2021reinforcement}
Janner, M., Li, Q., and Levine, S.
\newblock Reinforcement learning as one big sequence modeling problem.
\newblock \emph{arXiv preprint arXiv:2106.02039}, 2021.

\bibitem[Kahn et~al.(2021)Kahn, Abbeel, and Levine]{kahn2021badgr}
Kahn, G., Abbeel, P., and Levine, S.
\newblock Badgr: An autonomous self-supervised learning-based navigation
  system.
\newblock \emph{IEEE Robotics and Automation Letters}, 6\penalty0 (2):\penalty0
  1312--1319, 2021.

\bibitem[Kalashnikov et~al.(2018)Kalashnikov, Irpan, Pastor, Ibarz, Herzog,
  Jang, Quillen, Holly, Kalakrishnan, Vanhoucke,
  et~al.]{kalashnikov2018scalable}
Kalashnikov, D., Irpan, A., Pastor, P., Ibarz, J., Herzog, A., Jang, E.,
  Quillen, D., Holly, E., Kalakrishnan, M., Vanhoucke, V., et~al.
\newblock Scalable deep reinforcement learning for vision-based robotic
  manipulation.
\newblock In \emph{Conference on Robot Learning}, pp.\  651--673. PMLR, 2018.

\bibitem[Kidambi et~al.(2021)Kidambi, Rajeswaran, Netrapalli, and
  Joachims]{kidambi_morel_2021}
Kidambi, R., Rajeswaran, A., Netrapalli, P., and Joachims, T.
\newblock {{MOReL}} : {{Model-Based Offline Reinforcement Learning}}.
\newblock In \emph{{{arXiv}}:2005.05951 [Cs, Stat]}, 2021.

\bibitem[Kumar et~al.(2020)Kumar, Zhou, Tucker, and
  Levine]{kumar_conservative_2020}
Kumar, A., Zhou, A., Tucker, G., and Levine, S.
\newblock Conservative {{Q-Learning}} for {{Offline Reinforcement Learning}}.
\newblock \emph{Neural Information Processing Systems}, 2020.

\bibitem[Levine et~al.(2020)Levine, Kumar, Tucker, and Fu]{levine2020offline}
Levine, S., Kumar, A., Tucker, G., and Fu, J.
\newblock Offline reinforcement learning: Tutorial, review, and perspectives on
  open problems.
\newblock \emph{arXiv preprint arXiv:2005.01643}, 2020.

\bibitem[Liu et~al.(2021)Liu, Yuan, Fu, Jiang, Hayashi, and Neubig]{liu2021pre}
Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., and Neubig, G.
\newblock Pre-train, prompt, and predict: A systematic survey of prompting
  methods in natural language processing.
\newblock \emph{arXiv preprint arXiv:2107.13586}, 2021.

\bibitem[Mitchell et~al.(2021)Mitchell, Rafailov, Peng, Levine, and
  Finn]{mitchell2021offline}
Mitchell, E., Rafailov, R., Peng, X.~B., Levine, S., and Finn, C.
\newblock Offline meta-reinforcement learning with advantage weighting.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  7780--7791. PMLR, 2021.

\bibitem[Nichol et~al.(2018)Nichol, Achiam, and
  Schulman]{nichol_first-order_2018}
Nichol, A., Achiam, J., and Schulman, J.
\newblock On {{First-Order Meta-Learning Algorithms}}.
\newblock \emph{arXiv:1803.02999 [cs]}, 2018.

\bibitem[Peng et~al.(2019)Peng, Kumar, Zhang, and Levine]{peng2019advantage}
Peng, X.~B., Kumar, A., Zhang, G., and Levine, S.
\newblock Advantage-weighted regression: Simple and scalable off-policy
  reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1910.00177}, 2019.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, Sutskever,
  et~al.]{radford2019language}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et~al.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI blog}, 1\penalty0 (8):\penalty0 9, 2019.

\bibitem[Rajeswaran et~al.(2019)Rajeswaran, Finn, Kakade, and
  Levine]{rajeswaran_meta-learning_2019}
Rajeswaran, A., Finn, C., Kakade, S.~M., and Levine, S.
\newblock Meta-{{Learning}} with {{Implicit Gradients}}.
\newblock In Wallach, H., Larochelle, H., Beygelzimer, A.,
  d{\textbackslash}textquotesingle {Alch{\'e}-Buc}, F., Fox, E., and Garnett,
  R. (eds.), \emph{Advances in {{Neural Information Processing Systems}} 32},
  pp.\  113--124. {Curran Associates, Inc.}, 2019.

\bibitem[Rothfuss et~al.(2018)Rothfuss, Lee, Clavera, Asfour, and
  Abbeel]{rothfuss2018promp}
Rothfuss, J., Lee, D., Clavera, I., Asfour, T., and Abbeel, P.
\newblock Promp: Proximal meta-policy search.
\newblock \emph{arXiv preprint arXiv:1810.06784}, 2018.

\bibitem[Shiarlis et~al.(2018)Shiarlis, Wulfmeier, Salter, Whiteson, and
  Posner]{shiarlis2018taco}
Shiarlis, K., Wulfmeier, M., Salter, S., Whiteson, S., and Posner, I.
\newblock Taco: Learning task decomposition via temporal alignment for control.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  4654--4663. PMLR, 2018.

\bibitem[Shridhar et~al.(2020)Shridhar, Thomason, Gordon, Bisk, Han, Mottaghi,
  Zettlemoyer, and Fox]{shridhar2020alfred}
Shridhar, M., Thomason, J., Gordon, D., Bisk, Y., Han, W., Mottaghi, R.,
  Zettlemoyer, L., and Fox, D.
\newblock Alfred: A benchmark for interpreting grounded instructions for
  everyday tasks.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  10740--10749, 2020.

\bibitem[Sutton \& Barto(2018)Sutton and Barto]{sutton_reinforcement_2018}
Sutton, R.~S. and Barto, A.~G.
\newblock \emph{Reinforcement {{Learning}}: {{An Introduction}}}.
\newblock {MIT Press}, 2018.
\newblock ISBN 978-0-262-35270-3.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{todorov2012MuJoCo}
Todorov, E., Erez, T., and Tassa, Y.
\newblock Mujoco: A physics engine for model-based control.
\newblock In \emph{2012 IEEE/RSJ International Conference on Intelligent Robots
  and Systems}, pp.\  5026--5033. IEEE, 2012.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  5998--6008, 2017.

\bibitem[Vinyals et~al.(2016)Vinyals, Blundell, Lillicrap, Wierstra,
  et~al.]{vinyals2016matching}
Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et~al.
\newblock Matching networks for one shot learning.
\newblock \emph{Advances in neural information processing systems},
  29:\penalty0 3630--3638, 2016.

\bibitem[Wang et~al.(2020)Wang, Yao, Kwok, and Ni]{wang2020generalizing}
Wang, Y., Yao, Q., Kwok, J.~T., and Ni, L.~M.
\newblock Generalizing from a few examples: A survey on few-shot learning.
\newblock \emph{ACM Computing Surveys (CSUR)}, 53\penalty0 (3):\penalty0 1--34,
  2020.

\bibitem[Wu \& Demiris(2010)Wu and Demiris]{wu2010towards}
Wu, Y. and Demiris, Y.
\newblock Towards one shot learning by imitation for humanoid robots.
\newblock In \emph{2010 IEEE International Conference on Robotics and
  Automation}, pp.\  2889--2894. IEEE, 2010.

\bibitem[Yoon et~al.(2018)Yoon, Kim, Dia, Kim, Bengio, and
  Ahn]{yoon2018bayesian}
Yoon, J., Kim, T., Dia, O., Kim, S., Bengio, Y., and Ahn, S.
\newblock Bayesian model-agnostic meta-learning.
\newblock In \emph{Proceedings of the 32nd International Conference on Neural
  Information Processing Systems}, pp.\  7343--7353, 2018.

\bibitem[Yu et~al.(2020{\natexlab{a}})Yu, Quillen, He, Julian, Hausman, Finn,
  and Levine]{yu2020meta}
Yu, T., Quillen, D., He, Z., Julian, R., Hausman, K., Finn, C., and Levine, S.
\newblock Meta-world: A benchmark and evaluation for multi-task and meta
  reinforcement learning.
\newblock In \emph{Conference on Robot Learning}, pp.\  1094--1100. PMLR,
  2020{\natexlab{a}}.

\bibitem[Yu et~al.(2020{\natexlab{b}})Yu, Thomas, Yu, Ermon, Zou, Levine, Finn,
  and Ma]{yu_mopo_2020}
Yu, T., Thomas, G., Yu, L., Ermon, S., Zou, J., Levine, S., Finn, C., and Ma,
  T.
\newblock {{MOPO}}: {{Model-based Offline Policy Optimization}}.
\newblock \emph{Neural Information Processing Systems}, 2020{\natexlab{b}}.

\bibitem[Yu et~al.(2021)Yu, Kumar, Rafailov, Rajeswaran, Levine, and
  Finn]{yu_combo_2021}
Yu, T., Kumar, A., Rafailov, R., Rajeswaran, A., Levine, S., and Finn, C.
\newblock {{COMBO}}: {{Conservative Offline Model-Based Policy Optimization}}.
\newblock \emph{arXiv:2102.08363 [cs]}, 2021.

\end{thebibliography}
