@article{hajek1982hitting,
  title={Hitting-time and occupation-time bounds implied by drift analysis with applications},
  author={Hajek, Bruce},
  journal={Advances in Applied probability},
  volume={14},
  number={3},
  pages={502--525},
  year={1982},
  publisher={Cambridge University Press}
}
@inproceedings{yang2019sample,
  title={Sample-optimal parametric Q-learning using linearly additive features},
  author={Yang, Lin and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={6995--7004},
  year={2019},
  organization={PMLR}
}
@article{azar2012sample,
  title={On the sample complexity of reinforcement learning with a generative model},
  author={Azar, Mohammad Gheshlaghi and Munos, R{\'e}mi and Kappen, Bert},
  journal={arXiv preprint arXiv:1206.6461},
  year={2012}
}
@inproceedings{koenig1993complexity,
  title={Complexity analysis of real-time reinforcement learning},
  author={Koenig, Sven and Simmons, Reid G},
  booktitle={AAAI},
  pages={99--107},
  year={1993}
}
@article{gao2017properties,
  title={On the properties of the softmax function with application in game theory and reinforcement learning},
  author={Gao, Bolin and Pavel, Lacra},
  journal={arXiv preprint arXiv:1704.00805},
  year={2017}
}

@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2137--2143},
  year={2020},
  organization={PMLR}
}

@article{pan2019reinforcement,
  title={Reinforcement learning with dynamic boltzmann softmax updates},
  author={Pan, Ling and Cai, Qingpeng and Meng, Qi and Chen, Wei and Huang, Longbo and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:1903.05926},
  year={2019}
}

@article{efroni2020exploration,
  title={Exploration-exploitation in constrained mdps},
  author={Efroni, Yonathan and Mannor, Shie and Pirotta, Matteo},
  journal={arXiv preprint arXiv:2003.02189},
  year={2020}
}

@article{epasto2020optimal,
  title={Optimal Approximation--Smoothness Tradeoffs for Soft-Max Functions},
  author={Epasto, Alessandro and Mahdian, Mohammad and Mirrokni, Vahab and Zampetakis, Manolis},
  journal={arXiv preprint arXiv:2010.11450},
  year={2020}
}

@inproceedings{ding2021provably,
  title={Provably efficient safe exploration via primal-dual policy optimization},
  author={Ding, Dongsheng and Wei, Xiaohan and Yang, Zhuoran and Wang, Zhaoran and Jovanovic, Mihailo},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3304--3312},
  year={2021},
  organization={PMLR}
}

@article{liu2021learning,
  title={Learning Policies with Zero or Bounded Constraint Violation for Constrained MDPs},
  author={Liu, Tao and Zhou, Ruida and Kalathil, Dileep and Kumar, PR and Tian, Chao},
  journal={arXiv preprint arXiv:2106.02684},
  year={2021}
}

@article{wei2021provably,
  title={A Provably-Efficient Model-Free Algorithm for Constrained Markov Decision Processes},
  author={Wei, Honghao and Liu, Xin and Ying, Lei},
  journal={arXiv preprint arXiv:2106.01577},
  year={2021}
}

@inproceedings{xu2021crpo,
  title={Crpo: A new approach for safe reinforcement learning with convergence guarantee},
  author={Xu, Tengyu and Liang, Yingbin and Lan, Guanghui},
  booktitle={International Conference on Machine Learning},
  pages={11480--11491},
  year={2021},
  organization={PMLR}
}

@inproceedings{ding2020natural,
  title={Natural Policy Gradient Primal-Dual Method for Constrained Markov Decision Processes.},
  author={Ding, Dongsheng and Zhang, Kaiqing and Basar, Tamer and Jovanovic, Mihailo R},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{ayoub2020model,
  title={Model-based reinforcement learning with value-targeted regression},
  author={Ayoub, Alex and Jia, Zeyu and Szepesvari, Csaba and Wang, Mengdi and Yang, Lin},
  booktitle={International Conference on Machine Learning},
  pages={463--474},
  year={2020},
  organization={PMLR}
}

@inproceedings{cai2020provably,
  title={Provably efficient exploration in policy optimization},
  author={Cai, Qi and Yang, Zhuoran and Jin, Chi and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={1283--1294},
  year={2020},
  organization={PMLR}
}

@inproceedings{yang2020reinforcement,
  title={Reinforcement learning in feature space: Matrix bandit, kernels, and regret bound},
  author={Yang, Lin and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={10746--10756},
  year={2020},
  organization={PMLR}
}

@article{qiu2020upper,
  title={Upper confidence primal-dual optimization: Stochastically constrained Markov decision processes with adversarial losses and unknown transitions},
  author={Qiu, Shuang and Wei, Xiaohan and Yang, Zhuoran and Ye, Jieping and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2003.00660},
  year={2020}
}

@inproceedings{modi2020sample,
  title={Sample complexity of reinforcement learning using linearly combined model ensembles},
  author={Modi, Aditya and Jiang, Nan and Tewari, Ambuj and Singh, Satinder},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2010--2020},
  year={2020},
  organization={PMLR}
}

@article{agarwal2021theory,
  title={On the theory of policy gradient methods: Optimality, approximation, and distribution shift},
  author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={98},
  pages={1--76},
  year={2021}
}

@article{paternain2019safe,
  title={Safe policies for reinforcement learning via primal-dual methods},
  author={Paternain, Santiago and Calvo-Fullana, Miguel and Chamon, Luiz FO and Ribeiro, Alejandro},
  journal={arXiv preprint arXiv:1911.09101},
  year={2019}
}

@article{jin2018q,
  title={Is Q-learning provably efficient?},
  author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
  journal={arXiv preprint arXiv:1807.03765},
  year={2018}
}

@article{besson2018doubling,
  title={What doubling tricks can and can't do for multi-armed bandits},
  author={Besson, Lilian and Kaufmann, Emilie},
  journal={arXiv preprint arXiv:1803.06971},
  year={2018}
}

@article{abbasi2011improved,
  title={Improved algorithms for linear stochastic bandits},
  author={Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
  journal={Advances in neural information processing systems},
  volume={24},
  pages={2312--2320},
  year={2011}
}

@article{singh2020learning,
  title={Learning in Markov decision processes under constraints},
  author={Singh, Rahul and Gupta, Abhishek and Shroff, Ness B},
  journal={arXiv preprint arXiv:2002.12435},
  year={2020}
}

@article{brantley2020constrained,
  title={Constrained episodic reinforcement learning in concave-convex and knapsack settings},
  author={Brantley, Kiant{\'e} and Dudik, Miroslav and Lykouris, Thodoris and Miryoosefi, Sobhan and Simchowitz, Max and Slivkins, Aleksandrs and Sun, Wen},
  journal={arXiv preprint arXiv:2006.05051},
  year={2020}
}

@article{kalagarla2020sample,
  title={A sample-efficient algorithm for episodic finite-horizon mdp with constraints},
  author={Kalagarla, Krishna C and Jain, Rahul and Nuzzo, Pierluigi},
  journal={arXiv preprint arXiv:2009.11348},
  year={2020}
} 

@article{bai2021achieving,
  title={Achieving Zero Constraint Violation for Constrained Reinforcement Learning via Primal-Dual Approach},
  author={Bai, Qinbo and Bedi, Amrit Singh and Agarwal, Mridul and Koppel, Alec and Aggarwal, Vaneet},
  journal={arXiv preprint arXiv:2109.06332},
  year={2021}
}

@article{chen2021primal,
  title={A primal-dual approach to constrained Markov decision processes},
  author={Chen, Yi and Dong, Jing and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2101.10895},
  year={2021}
}



@inproceedings{zhou2021provably,
  title={Provably efficient reinforcement learning for discounted mdps with feature mapping},
  author={Zhou, Dongruo and He, Jiafan and Gu, Quanquan},
  booktitle={International Conference on Machine Learning},
  pages={12793--12802},
  year={2021},
  organization={PMLR}
}

@inproceedings{uchibe2007constrained,
  title={Constrained reinforcement learning from intrinsic and extrinsic rewards},
  author={Uchibe, Eiji and Doya, Kenji},
  booktitle={2007 IEEE 6th International Conference on Development and Learning},
  pages={163--168},
  year={2007},
  organization={IEEE}
}

@article{bhatnagar2012online,
  title={An online actor--critic algorithm with function approximation for constrained markov decision processes},
  author={Bhatnagar, Shalabh and Lakshmanan, K},
  journal={Journal of Optimization Theory and Applications},
  volume={153},
  number={3},
  pages={688--708},
  year={2012},
  publisher={Springer}
}

@article{yang2020projection,
  title={Projection-based constrained policy optimization},
  author={Yang, Tsung-Yen and Rosca, Justinian and Narasimhan, Karthik and Ramadge, Peter J},
  journal={arXiv preprint arXiv:2010.03152},
  year={2020}
}

@article{tessler2018reward,
  title={Reward constrained policy optimization},
  author={Tessler, Chen and Mankowitz, Daniel J and Mannor, Shie},
  journal={arXiv preprint arXiv:1805.11074},
  year={2018}
}

@article{amani2021safe,
  title={Safe Reinforcement Learning with Linear Function Approximation},
  author={Amani, Sanae and Thrampoulidis, Christos and Yang, Lin F},
  journal={arXiv preprint arXiv:2106.06239},
  year={2021}
}

@article{amani2019linear,
  title={Linear stochastic bandits under safety constraints},
  author={Amani, Sanae and Alizadeh, Mahnoosh and Thrampoulidis, Christos},
  journal={arXiv preprint arXiv:1908.05814},
  year={2019}
}

@inproceedings{pacchiano2021stochastic,
  title={Stochastic bandits with linear constraints},
  author={Pacchiano, Aldo and Ghavamzadeh, Mohammad and Bartlett, Peter and Jiang, Heinrich},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2827--2835},
  year={2021},
  organization={PMLR}
}

@article{moradipari2021safe,
  title={Safe linear thompson sampling with side information},
  author={Moradipari, Ahmadreza and Amani, Sanae and Alizadeh, Mahnoosh and Thrampoulidis, Christos},
  journal={IEEE Transactions on Signal Processing},
  year={2021},
  publisher={IEEE}
}

@inproceedings{zheng2020constrained,
  title={Constrained upper confidence reinforcement learning},
  author={Zheng, Liyuan and Ratliff, Lillian},
  booktitle={Learning for Dynamics and Control},
  pages={620--629},
  year={2020},
  organization={PMLR}
}

@INPROCEEDINGS{8793611,
  author={Lütjens, Björn and Everett, Michael and How, Jonathan P.},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  title={Safe Reinforcement Learning With Model Uncertainty Estimates}, 
  year={2019},
  volume={},
  number={},
  pages={8662-8668},
  doi={10.1109/ICRA.2019.8793611}}
  
  @inproceedings{zhao2021model,
  title={Model-free safe control for zero-violation reinforcement learning},
  author={Zhao, Weiye and He, Tairan and Liu, Changliu},
  booktitle={5th Annual Conference on Robot Learning},
  year={2021}
}

@article{vershynin2010introduction,
  title={Introduction to the non-asymptotic analysis of random matrices},
  author={Vershynin, Roman},
  journal={arXiv preprint arXiv:1011.3027},
  year={2010}
}

@article{liu2021efficient,
  title={An efficient pessimistic-optimistic algorithm for stochastic linear bandits with general constraints},
  author={Liu, Xin and Li, Bin and Shi, Pengyi and Ying, Lei},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{ding2022provably,
  title={Provably Efficient Primal-Dual Reinforcement Learning for CMDPs with Non-stationary Objectives and Constraints},
  author={Ding, Yuhao and Lavaei, Javad},
  journal={arXiv preprint arXiv:2201.11965},
  year={2022}
}

@inproceedings{wei2021learning,
  title={Learning infinite-horizon average-reward mdps with linear function approximation},
  author={Wei, Chen-Yu and Jahromi, Mehdi Jafarnia and Luo, Haipeng and Jain, Rahul},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3007--3015},
  year={2021},
  organization={PMLR}
}


@article{xie2020learning,
  title={Learning Zero-Sum Simultaneous-Move Markov Games Using Function Approximation and Correlated Equilibrium},
  author={Xie, Qiaomin and Chen, Yudong and Wang, Zhaoran and Yang, Zhuoran},
  journal={arXiv preprint arXiv:2002.07066},
  year={2020}
}
