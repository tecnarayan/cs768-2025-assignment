\begin{thebibliography}{55}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Babaeizadeh et~al.(2021)Babaeizadeh, Saffar, Nair, Levine, Finn, and Erhan]{babaeizadeh2021fitvid}
Babaeizadeh, M., Saffar, M.~T., Nair, S., Levine, S., Finn, C., and Erhan, D.
\newblock Fitvid: Overfitting in pixel-level video prediction.
\newblock \emph{arXiv preprint arXiv:2106.13195}, 2021.

\bibitem[Blattmann et~al.(2023)Blattmann, Rombach, Ling, Dockhorn, Kim, Fidler, and Kreis]{blattmann2023align}
Blattmann, A., Rombach, R., Ling, H., Dockhorn, T., Kim, S.~W., Fidler, S., and Kreis, K.
\newblock Align your latents: High-resolution video synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  22563--22575, 2023.

\bibitem[Cachay et~al.(2023)Cachay, Zhao, James, and Yu]{cachay2023dyffusion}
Cachay, S.~R., Zhao, B., James, H., and Yu, R.
\newblock Dyffusion: A dynamics-informed diffusion model for spatiotemporal forecasting.
\newblock \emph{arXiv preprint arXiv:2306.01984}, 2023.

\bibitem[Carreira \& Zisserman(2017)Carreira and Zisserman]{carreira2017quo}
Carreira, J. and Zisserman, A.
\newblock Quo vadis, action recognition? a new model and the kinetics dataset.
\newblock In \emph{proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pp.\  6299--6308, 2017.

\bibitem[Carreira et~al.(2018)Carreira, Noland, Banki-Horvath, Hillier, and Zisserman]{carreira2018short}
Carreira, J., Noland, E., Banki-Horvath, A., Hillier, C., and Zisserman, A.
\newblock A short note about kinetics-600.
\newblock \emph{arXiv preprint arXiv:1808.01340}, 2018.

\bibitem[Clark et~al.(2019)Clark, Donahue, and Simonyan]{clark2019adversarial}
Clark, A., Donahue, J., and Simonyan, K.
\newblock Adversarial video generation on complex datasets.
\newblock \emph{arXiv preprint arXiv:1907.06571}, 2019.

\bibitem[Dresdner et~al.(2022)Dresdner, Kochkov, Norgaard, Zepeda-Núñez, Smith, Brenner, and Hoyer]{Dresdner2022-Spectral-ML}
Dresdner, G., Kochkov, D., Norgaard, P., Zepeda-Núñez, L., Smith, J.~A., Brenner, M.~P., and Hoyer, S.
\newblock Learning to correct spectral methods for simulating turbulent flows.
\newblock In \emph{arXiv}, 2022.
\newblock \doi{10.48550/ARXIV.2207.00556}.
\newblock URL \url{https://arxiv.org/abs/2207.00556}.

\bibitem[Ebert et~al.(2017)Ebert, Finn, Lee, and Levine]{ebert2017self}
Ebert, F., Finn, C., Lee, A.~X., and Levine, S.
\newblock Self-supervised visual planning with temporal skip connections.
\newblock \emph{CoRL}, 12:\penalty0 16, 2017.

\bibitem[Gao et~al.(2023)Gao, Morioka, Zhang, and Chen]{gao2023e3}
Gao, Y., Morioka, N., Zhang, Y., and Chen, N.
\newblock E3 tts: Easy end-to-end diffusion-based text to speech.
\newblock In \emph{2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)}, pp.\  1--8. IEEE, 2023.

\bibitem[Ge et~al.(2023)Ge, Nah, Liu, Poon, Tao, Catanzaro, Jacobs, Huang, Liu, and Balaji]{ge2023preserve}
Ge, S., Nah, S., Liu, G., Poon, T., Tao, A., Catanzaro, B., Jacobs, D., Huang, J.-B., Liu, M.-Y., and Balaji, Y.
\newblock Preserve your own correlation: A noise prior for video diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  22930--22941, 2023.

\bibitem[Gupta et~al.(2023)Gupta, Yu, Sohn, Gu, Hahn, Fei-Fei, Essa, Jiang, and Lezama]{gupta2023photorealistic}
Gupta, A., Yu, L., Sohn, K., Gu, X., Hahn, M., Fei-Fei, L., Essa, I., Jiang, L., and Lezama, J.
\newblock Photorealistic video generation with diffusion models.
\newblock \emph{arXiv preprint arXiv:2312.06662}, 2023.

\bibitem[Harvey et~al.(2022)Harvey, Naderiparizi, Masrani, Weilbach, and Wood]{harvey2022flexible}
Harvey, W., Naderiparizi, S., Masrani, V., Weilbach, C., and Wood, F.
\newblock Flexible diffusion modeling of long videos.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 27953--27965, 2022.

\bibitem[He et~al.(2022)He, Yang, Zhang, Shan, and Chen]{he2022latent}
He, Y., Yang, T., Zhang, Y., Shan, Y., and Chen, Q.
\newblock Latent video diffusion models for high-fidelity video generation with arbitrary lengths.
\newblock \emph{arXiv preprint arXiv:2211.13221}, 2022.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Ho, J., Jain, A., and Abbeel, P.
\newblock Denoising diffusion probabilistic models.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H. (eds.), \emph{Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS}, 2020.

\bibitem[Ho et~al.(2022{\natexlab{a}})Ho, Chan, Saharia, Whang, Gao, Gritsenko, Kingma, Poole, Norouzi, Fleet, et~al.]{ho2022imagen}
Ho, J., Chan, W., Saharia, C., Whang, J., Gao, R., Gritsenko, A., Kingma, D.~P., Poole, B., Norouzi, M., Fleet, D.~J., et~al.
\newblock Imagen video: High definition video generation with diffusion models.
\newblock \emph{arXiv preprint arXiv:2210.02303}, 2022{\natexlab{a}}.

\bibitem[Ho et~al.(2022{\natexlab{b}})Ho, Salimans, Gritsenko, Chan, Norouzi, and Fleet]{ho2022video}
Ho, J., Salimans, T., Gritsenko, A., Chan, W., Norouzi, M., and Fleet, D.~J.
\newblock Video diffusion models.
\newblock \emph{arXiv:2204.03458}, 2022{\natexlab{b}}.

\bibitem[Hoogeboom et~al.(2023)Hoogeboom, Heek, and Salimans]{hoogeboom2023simple}
Hoogeboom, E., Heek, J., and Salimans, T.
\newblock simple diffusion: End-to-end diffusion for high resolution images.
\newblock \emph{arXiv preprint arXiv:2301.11093}, 2023.

\bibitem[Jabri et~al.(2022)Jabri, Fleet, and Chen]{jabri2022scalable}
Jabri, A., Fleet, D.~J., and Chen, T.
\newblock Scalable adaptive computation for iterative generation.
\newblock \emph{CoRR}, abs/2212.11972, 2022.

\bibitem[Kawar et~al.(2023)Kawar, Zada, Lang, Tov, Chang, Dekel, Mosseri, and Irani]{kawar2023imagic}
Kawar, B., Zada, S., Lang, O., Tov, O., Chang, H., Dekel, T., Mosseri, I., and Irani, M.
\newblock Imagic: Text-based real image editing with diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  6007--6017, 2023.

\bibitem[Kay et~al.(2017)Kay, Carreira, Simonyan, Zhang, Hillier, Vijayanarasimhan, Viola, Green, Back, Natsev, et~al.]{kay2017kinetics}
Kay, W., Carreira, J., Simonyan, K., Zhang, B., Hillier, C., Vijayanarasimhan, S., Viola, F., Green, T., Back, T., Natsev, P., et~al.
\newblock The kinetics human action video dataset.
\newblock \emph{arXiv preprint arXiv:1705.06950}, 2017.

\bibitem[Kingma \& Gao(2023)Kingma and Gao]{kingma2023understanding}
Kingma, D.~P. and Gao, R.
\newblock Understanding diffusion objectives as the elbo with simple data augmentation.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.

\bibitem[Kingma et~al.(2021)Kingma, Salimans, Poole, and Ho]{kingma2021vdm}
Kingma, D.~P., Salimans, T., Poole, B., and Ho, J.
\newblock Variational diffusion models.
\newblock \emph{CoRR}, abs/2107.00630, 2021.

\bibitem[Kochkov et~al.(2021)Kochkov, Smith, Alieva, Wang, Brenner, and Hoyer]{Kochkov2021-ML-CFD}
Kochkov, D., Smith, J.~A., Alieva, A., Wang, Q., Brenner, M.~P., and Hoyer, S.
\newblock Machine learning{\textendash}accelerated computational fluid dynamics.
\newblock \emph{Proceedings of the National Academy of Sciences}, 118\penalty0 (21), 2021.
\newblock ISSN 0027-8424.
\newblock \doi{10.1073/pnas.2101784118}.
\newblock URL \url{https://www.pnas.org/content/118/21/e2101784118}.

\bibitem[Kohl et~al.(2023)Kohl, Chen, and Thuerey]{kohl2023turbulent}
Kohl, G., Chen, L.-W., and Thuerey, N.
\newblock Turbulent flow simulation using autoregressive conditional diffusion models.
\newblock \emph{arXiv preprint arXiv:2309.01745}, 2023.

\bibitem[Kong et~al.(2021)Kong, Ping, Huang, Zhao, and Catanzaro]{kong2021diffwave}
Kong, Z., Ping, W., Huang, J., Zhao, K., and Catanzaro, B.
\newblock {DiffWave}: {A} versatile diffusion model for audio synthesis.
\newblock In \emph{9th International Conference on Learning Representations, {ICLR}}, 2021.

\bibitem[Le~Moing et~al.(2021)Le~Moing, Ponce, and Schmid]{le2021ccvs}
Le~Moing, G., Ponce, J., and Schmid, C.
\newblock Ccvs: context-aware controllable video synthesis.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 14042--14055, 2021.

\bibitem[Li et~al.(2022)Li, Thickstun, Gulrajani, Liang, and Hashimoto]{li2022diffusion}
Li, X., Thickstun, J., Gulrajani, I., Liang, P.~S., and Hashimoto, T.~B.
\newblock Diffusion-lm improves controllable text generation.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 4328--4343, 2022.

\bibitem[Li et~al.(2020)Li, Kovachki, Azizzadenesheli, Liu, Bhattacharya, Stuart, and Anandkumar]{li2020fourier}
Li, Z., Kovachki, N., Azizzadenesheli, K., Liu, B., Bhattacharya, K., Stuart, A., and Anandkumar, A.
\newblock Fourier neural operator for parametric partial differential equations.
\newblock \emph{arXiv preprint arXiv:2010.08895}, 2020.

\bibitem[Lippe et~al.(2023)Lippe, Veeling, Perdikaris, Turner, and Brandstetter]{lippe2023pde}
Lippe, P., Veeling, B.~S., Perdikaris, P., Turner, R.~E., and Brandstetter, J.
\newblock Pde-refiner: Achieving accurate long rollouts with neural pde solvers.
\newblock \emph{arXiv preprint arXiv:2308.05732}, 2023.

\bibitem[Luc et~al.(2020)Luc, Clark, Dieleman, Casas, Doron, Cassirer, and Simonyan]{luc2020transformation}
Luc, P., Clark, A., Dieleman, S., Casas, D. d.~L., Doron, Y., Cassirer, A., and Simonyan, K.
\newblock Transformation-based adversarial video prediction on large-scale data.
\newblock \emph{arXiv preprint arXiv:2003.04035}, 2020.

\bibitem[Meng et~al.(2022)Meng, Gao, Kingma, Ermon, Ho, and Salimans]{meng2022ondistillation}
Meng, C., Gao, R., Kingma, D.~P., Ermon, S., Ho, J., and Salimans, T.
\newblock On distillation of guided diffusion models.
\newblock \emph{CoRR}, abs/2210.03142, 2022.

\bibitem[Nash et~al.(2022)Nash, Carreira, Walker, Barr, Jaegle, Malinowski, and Battaglia]{nash2022transframer}
Nash, C., Carreira, J., Walker, J., Barr, I., Jaegle, A., Malinowski, M., and Battaglia, P.
\newblock Transframer: Arbitrary frame prediction with generative models.
\newblock \emph{arXiv preprint arXiv:2203.09494}, 2022.

\bibitem[Price et~al.(2023)Price, Sanchez-Gonzalez, Alet, Ewalds, El-Kadi, Stott, Mohamed, Battaglia, Lam, and Willson]{price2023gencast}
Price, I., Sanchez-Gonzalez, A., Alet, F., Ewalds, T., El-Kadi, A., Stott, J., Mohamed, S., Battaglia, P., Lam, R., and Willson, M.
\newblock Gencast: Diffusion-based ensemble forecasting for medium-range weather.
\newblock \emph{arXiv preprint arXiv:2312.15796}, 2023.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and Chen]{ramesh2022hierarchicaltextconditional}
Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., and Chen, M.
\newblock Hierarchical text-conditional image generation with {CLIP} latents.
\newblock \emph{CoRR}, abs/2204.06125, 2022.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022highresolution}
Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{{IEEE/CVF} Conference on Computer Vision and Pattern Recognition, {CVPR} 2022, New Orleans, LA, USA, June 18-24, 2022}, pp.\  10674--10685. {IEEE}, 2022.

\bibitem[Saharia et~al.(2022)Saharia, Chan, Saxena, Li, Whang, Denton, Ghasemipour, Ayan, Mahdavi, Lopes, Salimans, Ho, Fleet, and Norouzi]{saharia2022imagen}
Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E., Ghasemipour, S. K.~S., Ayan, B.~K., Mahdavi, S.~S., Lopes, R.~G., Salimans, T., Ho, J., Fleet, D.~J., and Norouzi, M.
\newblock Photorealistic text-to-image diffusion models with deep language understanding.
\newblock \emph{CoRR}, abs/2205.11487, 2022.

\bibitem[Singer et~al.(2022)Singer, Polyak, Hayes, Yin, An, Zhang, Hu, Yang, Ashual, Gafni, Parikh, Gupta, and Taigman]{singer2022makeavideo}
Singer, U., Polyak, A., Hayes, T., Yin, X., An, J., Zhang, S., Hu, Q., Yang, H., Ashual, O., Gafni, O., Parikh, D., Gupta, S., and Taigman, Y.
\newblock Make-a-video: Text-to-video generation without text-video data.
\newblock \emph{CoRR}, abs/2209.14792, 2022.

\bibitem[Sohl{-}Dickstein et~al.(2015)Sohl{-}Dickstein, Weiss, Maheswaranathan, and Ganguli]{sohldickstein2015diffusion}
Sohl{-}Dickstein, J., Weiss, E.~A., Maheswaranathan, N., and Ganguli, S.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In Bach, F.~R. and Blei, D.~M. (eds.), \emph{Proceedings of the 32nd International Conference on Machine Learning, {ICML}}, 2015.

\bibitem[Song \& Ermon(2019)Song and Ermon]{song2019generativemodellingestimatinggradient}
Song, Y. and Ermon, S.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock In \emph{Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS}, 2019.

\bibitem[StabilityAI(2023)]{StabilityAI2023StableVideo}
StabilityAI.
\newblock Introducing stable video diffusion.
\newblock In \emph{Stability AI}, Nov 2023.
\newblock Accessed: 2024-01-25.

\bibitem[Sun et~al.(2023)Sun, Yang, and Yoo]{sun2023neural}
Sun, Z., Yang, Y., and Yoo, S.
\newblock A neural pde solver with temporal stencil modeling.
\newblock \emph{arXiv preprint arXiv:2302.08105}, 2023.

\bibitem[Tashiro et~al.(2021)Tashiro, Song, Song, and Ermon]{tashiro2021csdi}
Tashiro, Y., Song, J., Song, Y., and Ermon, S.
\newblock Csdi: Conditional score-based diffusion models for probabilistic time series imputation.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 24804--24816, 2021.

\bibitem[Unterthiner et~al.(2019)Unterthiner, van Steenkiste, Kurach, Marinier, Michalski, and Gelly]{unterthiner2019fvd}
Unterthiner, T., van Steenkiste, S., Kurach, K., Marinier, R., Michalski, M., and Gelly, S.
\newblock Fvd: A new metric for video generation.
\newblock In \emph{arXiv}, 2019.

\bibitem[Villegas et~al.(2022)Villegas, Babaeizadeh, Kindermans, Moraldo, Zhang, Saffar, Castro, Kunze, and Erhan]{villegas2022phenaki}
Villegas, R., Babaeizadeh, M., Kindermans, P.-J., Moraldo, H., Zhang, H., Saffar, M.~T., Castro, S., Kunze, J., and Erhan, D.
\newblock Phenaki: Variable length video generation from open domain textual description.
\newblock \emph{arXiv preprint arXiv:2210.02399}, 2022.

\bibitem[Weissenborn et~al.(2019)Weissenborn, T{\"a}ckstr{\"o}m, and Uszkoreit]{weissenborn2019scaling}
Weissenborn, D., T{\"a}ckstr{\"o}m, O., and Uszkoreit, J.
\newblock Scaling autoregressive video models.
\newblock \emph{arXiv preprint arXiv:1906.02634}, 2019.

\bibitem[Wu et~al.(2022)Wu, Liang, Ji, Yang, Fang, Jiang, and Duan]{wu2022nuwa}
Wu, C., Liang, J., Ji, L., Yang, F., Fang, Y., Jiang, D., and Duan, N.
\newblock N{\"u}wa: Visual synthesis pre-training for neural visual world creation.
\newblock In \emph{European conference on computer vision}, pp.\  720--736. Springer, 2022.

\bibitem[Wu et~al.(2023)Wu, Fan, Liu, Gong, Shen, Jiao, Zheng, Li, Wei, Guo, et~al.]{wu2023ar}
Wu, T., Fan, Z., Liu, X., Gong, Y., Shen, Y., Jiao, J., Zheng, H.-T., Li, J., Wei, Z., Guo, J., et~al.
\newblock Ar-diffusion: Auto-regressive diffusion model for text generation.
\newblock \emph{arXiv preprint arXiv:2305.09515}, 2023.

\bibitem[Yan et~al.(2021)Yan, Zhang, Abbeel, and Srinivas]{yan2021videogpt}
Yan, W., Zhang, Y., Abbeel, P., and Srinivas, A.
\newblock Videogpt: Video generation using vq-vae and transformers.
\newblock \emph{arXiv preprint arXiv:2104.10157}, 2021.

\bibitem[Yan et~al.(2023)Yan, Hafner, James, and Abbeel]{yan2023teco}
Yan, W., Hafner, D., James, S., and Abbeel, P.
\newblock Temporally consistent transformers for video generation.
\newblock In Krause, A., Brunskill, E., Cho, K., Engelhardt, B., Sabato, S., and Scarlett, J. (eds.), \emph{International Conference on Machine Learning, {ICML}}, 2023.

\bibitem[Yang et~al.(2023)Yang, Srivastava, and Mandt]{yang2023diffusion}
Yang, R., Srivastava, P., and Mandt, S.
\newblock Diffusion probabilistic modeling for video generation.
\newblock \emph{Entropy}, 25\penalty0 (10):\penalty0 1469, 2023.

\bibitem[Yu et~al.(2022)Yu, Xu, Koh, Luong, Baid, Wang, Vasudevan, Ku, Yang, Ayan, Hutchinson, Han, Parekh, Li, Zhang, Baldridge, and Wu]{yu2022scalingautoregressive}
Yu, J., Xu, Y., Koh, J.~Y., Luong, T., Baid, G., Wang, Z., Vasudevan, V., Ku, A., Yang, Y., Ayan, B.~K., Hutchinson, B., Han, W., Parekh, Z., Li, X., Zhang, H., Baldridge, J., and Wu, Y.
\newblock Scaling autoregressive models for content-rich text-to-image generation.
\newblock \emph{CoRR}, abs/2206.10789, 2022.

\bibitem[Yu et~al.(2023{\natexlab{a}})Yu, Cheng, Sohn, Lezama, Zhang, Chang, Hauptmann, Yang, Hao, Essa, et~al.]{yu2023magvit}
Yu, L., Cheng, Y., Sohn, K., Lezama, J., Zhang, H., Chang, H., Hauptmann, A.~G., Yang, M.-H., Hao, Y., Essa, I., et~al.
\newblock Magvit: Masked generative video transformer.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  10459--10469, 2023{\natexlab{a}}.

\bibitem[Yu et~al.(2023{\natexlab{b}})Yu, Lezama, Gundavarapu, Versari, Sohn, Minnen, Cheng, Gupta, Gu, Hauptmann, et~al.]{yu2023language}
Yu, L., Lezama, J., Gundavarapu, N.~B., Versari, L., Sohn, K., Minnen, D., Cheng, Y., Gupta, A., Gu, X., Hauptmann, A.~G., et~al.
\newblock Language model beats diffusion--tokenizer is key to visual generation.
\newblock \emph{arXiv preprint arXiv:2310.05737}, 2023{\natexlab{b}}.

\bibitem[Yu et~al.(2023{\natexlab{c}})Yu, Sohn, Kim, and Shin]{yu2023video}
Yu, S., Sohn, K., Kim, S., and Shin, J.
\newblock Video probabilistic diffusion models in projected latent space.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  18456--18466, 2023{\natexlab{c}}.

\bibitem[Zhang et~al.(2023)Zhang, Liu, Aberman, and Hanocka]{zhang2023tedi}
Zhang, Z., Liu, R., Aberman, K., and Hanocka, R.
\newblock Tedi: Temporally-entangled diffusion for long-term motion synthesis.
\newblock \emph{arXiv preprint arXiv:2307.15042}, 2023.

\end{thebibliography}
