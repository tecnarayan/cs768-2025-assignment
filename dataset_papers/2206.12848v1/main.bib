%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% General RL Sources
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={R. S. Sutton and A. G. Barto},
  year={2018},
  publisher={MIT press}
}

@book{bertsekas2005dynamic,
  title={Dynamic programming and optimal control},
  author={D. Bertsekas},
  year={2005},
  publisher={Athena scientific Belmont, MA}
}

@book{puterman1994markov,
  title={Markov Decision Processes},
  author={Puterman, Martin L},
  publisher={Wiley and Sons},
  year={1994}
}
%%%%%%%%%%%%%%%%%%%%%%%% Replay buffer analysis %%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Replay Buffer/Experience Replay sources
@techreport{lin1993reinforcement,
  title={Reinforcement learning for robots using neural networks},
  author={Lin, Long-Ji},
  year={1993},
  institution={Carnegie-Mellon Univ Pittsburgh PA School of Computer Science}
}

% Original DQN paper from the workshop
@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

%%%% % PER - Prioritized sampling

@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}


@inproceedings{fedus2020revisiting,
  title={Revisiting fundamentals of experience replay},
  author={Fedus, William and Ramachandran, Prajit and Agarwal, Rishabh and Bengio, Yoshua and Larochelle, Hugo and Rowland, Mark and Dabney, Will},
  booktitle={International Conference on Machine Learning},
  pages={3061--3071},
  year={2020},
  organization={PMLR}
}

@article{zhang2017deeper,
  title={A deeper look at experience replay},
  author={Zhang, Shangtong and Sutton, Richard S},
  journal={arXiv preprint arXiv:1712.01275},
  year={2017}
}

@inproceedings{liu2018effects,
  title={The effects of memory replay in reinforcement learning},
  author={Liu, Ruishan and Zou, James},
  booktitle={2018 56th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  pages={478--485},
  year={2018},
  organization={IEEE}
}

@article{pan2018organizing,
  title={Organizing experience: a deeper look at replay mechanisms for sample-based planning in continuous state domains},
  author={Pan, Yangchen and Zaheer, Muhammad and White, Adam and Patterson, Andrew and White, Martha},
  journal={arXiv preprint arXiv:1806.04624},
  year={2018}
}

@article{horgan2018distributed,
  title={Distributed prioritized experience replay},
  author={Horgan, Dan and Quan, John and Budden, David and Barth-Maron, Gabriel and Hessel, Matteo and Van Hasselt, Hado and Silver, David},
  journal={arXiv preprint arXiv:1803.00933},
  year={2018}
}

@article{zha2019experience,
  title={Experience replay optimization},
  author={Zha, Daochen and Lai, Kwei-Herng and Zhou, Kaixiong and Hu, Xia},
  journal={arXiv preprint arXiv:1906.08387},
  year={2019}
}

@inproceedings{novati2019remember,
  title={Remember and forget for experience replay},
  author={Novati, Guido and Koumoutsakos, Petros},
  booktitle={International Conference on Machine Learning},
  pages={4851--4860},
  year={2019},
  organization={PMLR}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%% high order markov chains 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{adke1988limit,
  title={Limit distribution of a high order Markov chain},
  author={Adke, SR and Deshmukh, SR},
  journal={Journal of the Royal Statistical Society: Series B (Methodological)},
  volume={50},
  number={1},
  pages={105--108},
  year={1988},
  publisher={Wiley Online Library}
}

@article{li1990some,
  title={Some results on the estimation of a higher order Markov chain},
  author={Li, Wai Keung and Kwok, Michael CO},
  journal={Communications in Statistics-Simulation and Computation},
  volume={19},
  number={1},
  pages={363--380},
  year={1990},
  publisher={Taylor \& Francis}
}

@article{logan1981structural,
  title={A structural model of the higher-order Markov process incorporating reversion effects},
  author={Logan, John Allen},
  journal={Journal of Mathematical Sociology},
  volume={8},
  number={1},
  pages={75--89},
  year={1981},
  publisher={Taylor \& Francis}
}

@article{raftery1985model,
  title={A model for high-order Markov chains},
  author={Raftery, Adrian E},
  journal={Journal of the Royal Statistical Society: Series B (Methodological)},
  volume={47},
  number={3},
  pages={528--539},
  year={1985},
  publisher={Wiley Online Library}
}

@article{ching2004higher,
  title={Higher-order Markov chain models for categorical data sequences},
  author={Ching, Wai Ki and Fung, Eric S and Ng, Michael K},
  journal={Naval Research Logistics (NRL)},
  volume={51},
  number={4},
  pages={557--574},
  year={2004},
  publisher={Wiley Online Library}
}

@article{fasino2020ergodicity,
  title={Ergodicity coefficients for higher-order stochastic processes},
  author={Fasino, Dario and Tudisco, Francesco},
  journal={SIAM Journal on Mathematics of Data Science},
  volume={2},
  number={3},
  pages={740--769},
  year={2020},
  publisher={SIAM}
}

@article{li2015stationary,
  title={Stationary probability vectors of higher-order Markov chains},
  author={Li, Chi-Kwong and Zhang, Shixiao},
  journal={Linear Algebra and Its Applications},
  volume={473},
  pages={114--125},
  year={2015},
  publisher={Elsevier}
}

@article{ng2010finding,
  title={Finding the largest eigenvalue of a nonnegative tensor},
  author={Ng, Michael and Qi, Liqun and Zhou, Guanglu},
  journal={SIAM Journal on Matrix Analysis and Applications},
  volume={31},
  number={3},
  pages={1090--1099},
  year={2010},
  publisher={SIAM}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% Faddeevâ€“LeVerrier algorithm %%%%%%%%%%%%%%%%%%%%

@article{leverrier1840variations,
  title={Sur les variations s{\'e}culaire des {\'e}lements des orbites pour les sept plan{\'e}tes principales},
  author={Leverrier, UJJ},
  journal={J. de Math},
  number={s 1},
  pages={5},
  year={1840}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%% Decorrelation in RL %%%%%%%%%%%%%%%%%%%%%

@article{mavrin2019deep,
  title={Deep reinforcement learning with decorrelation},
  author={Mavrin, Borislav and Yao, Hengshuai and Kong, Linglong},
  journal={arXiv preprint arXiv:1903.07765},
  year={2019}
}

@article{gomrokchi2021did,
  title={Where Did You Learn That From? Surprising Effectiveness of Membership Inference Attacks Against Temporally Correlated Data in Deep Reinforcement Learning},
  author={Gomrokchi, Maziar and Amin, Susan and Aboutalebi, Hossein and Wong, Alexander and Precup, Doina},
  journal={arXiv preprint arXiv:2109.03975},
  year={2021}
}

@article{ramicic2020correlation,
  title={Correlation minimizing replay memory in temporal-difference reinforcement learning},
  author={Ramicic, Mirza and Bonarini, Andrea},
  journal={Neurocomputing},
  volume={393},
  pages={91--100},
  year={2020},
  publisher={Elsevier}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%% Correlation in Deep neural networks %%%%%%%%%%%%%%%%%%%%%

@article{benton2017deep,
  title={Deep generalized canonical correlation analysis},
  author={Benton, Adrian and Khayrallah, Huda and Gujral, Biman and Reisinger, Dee Ann and Zhang, Sheng and Arora, Raman},
  journal={arXiv preprint arXiv:1702.02519},
  year={2017}
}

@article{chandar2016correlational,
  title={Correlational neural networks},
  author={Chandar, Sarath and Khapra, Mitesh M and Larochelle, Hugo and Ravindran, Balaraman},
  journal={Neural computation},
  volume={28},
  number={2},
  pages={257--285},
  year={2016},
  publisher={MIT Press}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%% Autocorrelation in Actions  %%%%%%%%%%%%%%%%%%%%%
@inproceedings{szulc2020framework,
  title={A framework for reinforcement learning with autocorrelated actions},
  author={Szulc, Marcin and {\L}yskawa, Jakub and Wawrzy{\'n}ski, Pawe{\l}},
  booktitle={International Conference on Neural Information Processing},
  pages={90--101},
  year={2020},
  organization={Springer}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%% Prioritized replay buffer extensions %%%%%%%%%%%%%%%%%%%%%
@article{brittain2019prioritized,
  title={Prioritized sequence experience replay},
  author={Brittain, Marc and Bertram, Josh and Yang, Xuxi and Wei, Peng},
  journal={arXiv preprint arXiv:1905.12726},
  year={2019}
}

@article{li2021revisiting,
  title={Revisiting Prioritized Experience Replay: A Value Perspective},
  author={Li, Ang A and Lu, Zongqing and Miao, Chenglin},
  journal={arXiv preprint arXiv:2102.03261},
  year={2021}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%% Sim and real better together %%%%%%%%%%%%%%%%%%

@article{di2021sim,
  title={Sim and Real: Better Together},
  author={Di-Castro Shashua, Shirli and Di Castro, Dotan and Mannor, Shie},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%% Convergence %%%%%%%%%%%%%%%

@inproceedings{konda2000actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  booktitle={Advances in neural information processing systems},
  pages={1008--1014},
  year={2000},
  organization={Citeseer}
}

% Stochastic Approximation sources
@book{kushner2003stochastic,
  title={Stochastic approximation and recursive algorithms and applications},
  author={Kushner, Harold and Yin, G George},
  volume={35},
  year={2003},
  publisher={Springer Science \& Business Media}
}

@book{kushner2012stochastic,
  title={Stochastic approximation methods for constrained and unconstrained systems},
  author={Kushner, Harold Joseph and Clark, Dean S},
  volume={26},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@book{borkar2009stochastic,
  title={Stochastic approximation: a dynamical systems viewpoint},
  author={Borkar, Vivek S},
  volume={48},
  year={2009},
  publisher={Springer}
}

@book{bertsekas1996neuro,
  title={Neuro-dynamic programming},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  year={1996},
  publisher={Athena Scientific}
}

@article{borkar2000ode,
  title={The ODE method for convergence of stochastic approximation and reinforcement learning},
  author={Borkar, Vivek S and Meyn, Sean P},
  journal={SIAM Journal on Control and Optimization},
  volume={38},
  number={2},
  pages={447--469},
  year={2000},
  publisher={SIAM}
}

% finite analysis for average reward actor critic:
@inproceedings{dalal2018finite,
  title={Finite sample analyses for TD (0) with function approximation},
  author={Dalal, Gal and Sz{\"o}r{\'e}nyi, Bal{\'a}zs and Thoppe, Gugan and Mannor, Shie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{wu2020finite,
  title={A finite time analysis of two time-scale actor critic methods},
  author={Wu, Yue and Zhang, Weitong and Xu, Pan and Gu, Quanquan},
  journal={arXiv preprint arXiv:2005.01350},
  year={2020}
}

@article{zou2019finite,
  title={Finite-sample analysis for sarsa with linear function approximation},
  author={Zou, Shaofeng and Xu, Tengyu and Liang, Yingbin},
  journal={arXiv preprint arXiv:1902.02234},
  year={2019}
}

%convergance of actor critic
@article{bhatnagar2009natural,
  title={Natural actor--critic algorithms},
  author={Bhatnagar, Shalabh and Sutton, Richard S and Ghavamzadeh, Mohammad and Lee, Mark},
  journal={Automatica},
  volume={45},
  number={11},
  pages={2471--2482},
  year={2009},
  publisher={Elsevier}
}

@article{bhatnagar2004simultaneous,
  title={A simultaneous perturbation stochastic approximation-based actor-critic algorithm for Markov decision processes},
  author={Bhatnagar, Shalabh and Kumar, Shishir},
  journal={IEEE Transactions on Automatic Control},
  volume={49},
  number={4},
  pages={592--598},
  year={2004},
  publisher={IEEE}
}

@article{dicastro2010convergent,
  title={A convergent online single time scale actor critic algorithm},
  author={Di~Castro, Dotan and Meir, Ron},
  journal={The Journal of Machine Learning Research},
  volume={11},
  pages={367--410},
  year={2010},
  publisher={JMLR. org}
}

% DDPG
@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

% SAC
@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

%%%%%%%%%%% analysis of regret bounds in replay buffers  %%%%%%%%%%%%%%%%%%%%
@article{lazic2021improved,
  title={Improved Regret Bound and Experience Replay in Regularized Policy Iteration},
  author={Lazic, Nevena and Yin, Dong and Abbasi-Yadkori, Yasin and Szepesvari, Csaba},
  journal={arXiv preprint arXiv:2102.12611},
  year={2021}
}

@book{laguna2013business,
  title={Business process modeling, simulation, and design},
  author={Laguna, Manuel and Marklund, Johan},
  year={2013},
  publisher={Taylor \& Francis}
}

%%%%%%%%%%%%%%% Actor critic convergance analysis %%%%%%%%%%%%%%%
@inproceedings{bhatnagar2008incremental,
  title={Incremental natural actor-critic algorithms},
  author={Bhatnagar, Shalabh and Ghavamzadeh, Mohammad and Lee, Mark and Sutton, Richard S},
  booktitle={Advances in neural information processing systems},
  pages={105--112},
  year={2008}
}



%%%%%%%%%%%%%%%% Replay buffer related:

@article{lahire2021large,
  title={Large Batch Experience Replay},
  author={Lahire, Thibault and Geist, Matthieu and Rachelson, Emmanuel},
  journal={arXiv preprint arXiv:2110.01528},
  year={2021}
}



% Deep Q learning asymptotic convergence analysis
@article{ramaswamy2021deep,
  title={Deep Q-Learning: Theoretical Insights from an Asymptotic Analysis},
  author={Ramaswamy, Arunselvan and Hullermeier, Eyke},
  journal={IEEE Transactions on Artificial Intelligence},
  year={2021},
  publisher={IEEE}
}

% DDPG asymptotic convergence analysis
@article{redder2022asymptotic,
  title={Asymptotic Convergence of Deep Multi-Agent Actor-Critic Algorithms},
  author={Redder, Adrian and Ramaswamy, Arunselvan and Karl, Holger},
  journal={arXiv preprint arXiv:2201.00570},
  year={2022}
}

% Finite sample analysis of Deep Q-Learning
@inproceedings{fan2020theoretical,
  title={A theoretical analysis of deep Q-learning},
  author={Fan, Jianqing and Wang, Zhaoran and Xie, Yuchen and Yang, Zhuoran},
  booktitle={Learning for Dynamics and Control},
  pages={486--489},
  year={2020},
  organization={PMLR}
}

% FQI algorithm - a version of DQN with independece assumption
@inproceedings{riedmiller2005neural,
  title={Neural fitted Q iteration--first experiences with a data efficient neural reinforcement learning method},
  author={Riedmiller, Martin},
  booktitle={European conference on machine learning},
  pages={317--328},
  year={2005},
  organization={Springer}
}

@article{ernst2005tree,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  pages={503--556},
  year={2005},
  publisher={Microtome Publishing}
}

%%% Sample efficient actor-critic with experience replay
@article{wang2016sample,
  title={Sample efficient actor-critic with experience replay},
  author={Wang, Ziyu and Bapst, Victor and Heess, Nicolas and Mnih, Volodymyr and Munos, Remi and Kavukcuoglu, Koray and de Freitas, Nando},
  journal={arXiv preprint arXiv:1611.01224},
  year={2016}
}

@book{oppenheim1997signals,
  title={Signals \& systems},
  author={Oppenheim, Alan V and Willsky, Alan S and Nawab, Syed Hamid and Hern{\'a}ndez, Gloria Mata and others},
  year={1997},
  publisher={Pearson Educaci{\'o}n}
}

@book{porat2008digital,
  title={Digital processing of random signals: theory and methods},
  author={Porat, Boaz},
  year={2008},
  publisher={Courier Dover Publications}
}

@book{norris1998markov,
  title={Markov chains},
  author={Norris, James Robert},
  number={2},
  year={1998},
  series={1},
  publisher={Cambridge university press}
}



%%%%%%%%% TD3 algorithm 
@inproceedings{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International Conference on Machine Learning},
  pages={1587--1596},
  year={2018},
  organization={PMLR}
}