\begin{thebibliography}{38}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abernethy et~al.(2015)Abernethy, Lee, and
  Tewari]{abernethy2015fighting}
Abernethy, J.~D., Lee, C., and Tewari, A.
\newblock Fighting bandits with a new kind of smoothness.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2015.

\bibitem[Anantharam et~al.(1987)Anantharam, Varaiya, and
  Walrand]{anantharam1987asymptotically}
Anantharam, V., Varaiya, P., and Walrand, J.
\newblock Asymptotically efficient allocation rules for the multiarmed bandit
  problem with multiple plays-part i: Iid rewards.
\newblock \emph{IEEE Transactions on Automatic Control}, 32\penalty0 (11),
  1987.

\bibitem[Audibert \& Bubeck(2009)Audibert and Bubeck]{audibert2009minimax}
Audibert, J.-Y. and Bubeck, S.
\newblock Minimax policies for adversarial and stochastic bandits.
\newblock In \emph{Conference on Learning Theory}, 2009.

\bibitem[Audibert et~al.(2013)Audibert, Bubeck, and Lugosi]{audibert2013regret}
Audibert, J.-Y., Bubeck, S., and Lugosi, G.
\newblock Regret in online combinatorial optimization.
\newblock \emph{Mathematics of Operations Research}, 39\penalty0 (1), 2013.

\bibitem[Auer \& Chiang(2016)Auer and Chiang]{auer2016algorithm}
Auer, P. and Chiang, C.-K.
\newblock An algorithm with nearly optimal pseudo-regret for both stochastic
  and adversarial bandits.
\newblock In \emph{Conference on Learning Theory}, 2016.

\bibitem[Auer et~al.(2002)Auer, Cesa-Bianchi, Freund, and
  Schapire]{auer2002nonstochastic}
Auer, P., Cesa-Bianchi, N., Freund, Y., and Schapire, R.~E.
\newblock The nonstochastic multiarmed bandit problem.
\newblock \emph{SIAM Journal on Computing}, 32\penalty0 (1), 2002.

\bibitem[Bertsekas et~al.(2003)Bertsekas, Nedi, Ozdaglar,
  et~al.]{bertsekas2003convex}
Bertsekas, D.~P., Nedi, A., Ozdaglar, A.~E., et~al.
\newblock \emph{Convex analysis and optimization}.
\newblock Athena Scientific, 2003.

\bibitem[Bubeck \& Slivkins(2012)Bubeck and Slivkins]{bubeck2012best}
Bubeck, S. and Slivkins, A.
\newblock The best of both worlds: stochastic and adversarial bandits.
\newblock In \emph{Conference on Learning Theory}, 2012.

\bibitem[Bubeck et~al.(2013)Bubeck, Perchet, and Rigollet]{bubeck2013bounded}
Bubeck, S., Perchet, V., and Rigollet, P.
\newblock Bounded regret in stochastic multi-armed bandits.
\newblock In \emph{Conference on Learning Theory}, 2013.

\bibitem[Bubeck et~al.(2018)Bubeck, Cohen, and Li]{bubeck2018sparsity}
Bubeck, S., Cohen, M.~B., and Li, Y.
\newblock Sparsity, variance and curvature in multi-armed bandits.
\newblock In \emph{International Conference on Algorithmic Learning Theory},
  2018.

\bibitem[Cesa-Bianchi \& Lugosi(2012)Cesa-Bianchi and
  Lugosi]{cesa2012combinatorial}
Cesa-Bianchi, N. and Lugosi, G.
\newblock Combinatorial bandits.
\newblock \emph{Journal of Computer and System Sciences}, 78\penalty0 (5),
  2012.

\bibitem[Chen et~al.(2013)Chen, Wang, and Yuan]{chen2013combinatorial}
Chen, W., Wang, Y., and Yuan, Y.
\newblock Combinatorial multi-armed bandit: General framework and applications.
\newblock In \emph{International Conference on Machine Learning}, 2013.

\bibitem[Combes et~al.(2015)Combes, Shahi, Proutiere,
  et~al.]{combes2015combinatorial}
Combes, R., Shahi, M. S. T.~M., Proutiere, A., et~al.
\newblock Combinatorial bandits revisited.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2015.

\bibitem[Combes et~al.(2017)Combes, Magureanu, and
  Proutiere]{combes2017minimal}
Combes, R., Magureanu, S., and Proutiere, A.
\newblock Minimal exploration in structured stochastic bandits.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Dani et~al.(2008)Dani, Kakade, and Hayes]{dani2008price}
Dani, V., Kakade, S.~M., and Hayes, T.~P.
\newblock The price of bandit information for online optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  345--352, 2008.

\bibitem[Freund \& Schapire(1997)Freund and Schapire]{freund1997decision}
Freund, Y. and Schapire, R.~E.
\newblock A decision-theoretic generalization of on-line learning and an
  application to boosting.
\newblock \emph{Journal of Computer and System Sciences}, 55\penalty0 (1),
  1997.

\bibitem[Gai et~al.(2012)Gai, Krishnamachari, and Jain]{gai2012combinatorial}
Gai, Y., Krishnamachari, B., and Jain, R.
\newblock Combinatorial network optimization with unknown variables:
  Multi-armed bandits with linear rewards and individual observations.
\newblock \emph{IEEE/ACM Transactions on Networking}, 20\penalty0 (5), 2012.

\bibitem[Gaillard et~al.(2014)Gaillard, Stoltz, and
  Van~Erven]{gaillard2014second}
Gaillard, P., Stoltz, G., and Van~Erven, T.
\newblock A second-order bound with excess losses.
\newblock In \emph{Conference on Learning Theory}, 2014.

\bibitem[Gopalan et~al.(2014)Gopalan, Mannor, and Mansour]{gopalan2014thompson}
Gopalan, A., Mannor, S., and Mansour, Y.
\newblock Thompson sampling for complex online problems.
\newblock In \emph{International Conference on Machine Learning}, 2014.

\bibitem[Hazan et~al.(2016)]{hazan2016introduction}
Hazan, E. et~al.
\newblock Introduction to online convex optimization.
\newblock \emph{Foundations and Trends{\textregistered} in Optimization},
  2\penalty0 (3-4), 2016.

\bibitem[Koolen et~al.(2010)Koolen, Warmuth, and Kivinen]{koolen2010hedging}
Koolen, W.~M., Warmuth, M.~K., and Kivinen, J.
\newblock Hedging structured concepts.
\newblock In \emph{Conference on Learning Theory}, 2010.

\bibitem[Koolen et~al.(2016)Koolen, Gr{\"u}nwald, and van
  Erven]{koolen2016combining}
Koolen, W.~M., Gr{\"u}nwald, P., and van Erven, T.
\newblock Combining adversarial guarantees and stochastic fast rates in online
  learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Kveton et~al.(2015)Kveton, Wen, Ashkan, and
  Szepesvari]{kveton2015tight}
Kveton, B., Wen, Z., Ashkan, A., and Szepesvari, C.
\newblock Tight regret bounds for stochastic combinatorial semi-bandits.
\newblock In \emph{Artificial Intelligence and Statistics}, 2015.

\bibitem[Lai \& Robbins(1985)Lai and Robbins]{lai1985asymptotically}
Lai, T.~L. and Robbins, H.
\newblock Asymptotically efficient adaptive allocation rules.
\newblock \emph{Advances in Applied Mathematics}, 6\penalty0 (1), 1985.

\bibitem[Lattimore \& Szepesvari(2017)Lattimore and
  Szepesvari]{lattimore2016end}
Lattimore, T. and Szepesvari, C.
\newblock The end of optimism? an asymptotic analysis of finite-armed linear
  bandits.
\newblock 2017.

\bibitem[Lattimore et~al.(2018)Lattimore, Kveton, Li, and
  Szepesvari]{lattimore2018toprank}
Lattimore, T., Kveton, B., Li, S., and Szepesvari, C.
\newblock Toprank: A practical algorithm for online stochastic ranking.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Luo \& Schapire(2015)Luo and Schapire]{luo2015achieving}
Luo, H. and Schapire, R.~E.
\newblock Achieving all with no parameters: Adanormalhedge.
\newblock In \emph{Conference on Learning Theory}, 2015.

\bibitem[Luo et~al.(2018)Luo, Wei, and Zheng]{luo2018efficient}
Luo, H., Wei, C.-Y., and Zheng, K.
\newblock Efficient online portfolio with logarithmic regret.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Neu(2015)]{neu2015first}
Neu, G.
\newblock First-order regret bounds for combinatorial semi-bandits.
\newblock In \emph{Conference on Learning Theory}, 2015.

\bibitem[Neu \& Bart{\'o}k(2013)Neu and Bart{\'o}k]{neu2013efficient}
Neu, G. and Bart{\'o}k, G.
\newblock An efficient algorithm for learning with semi-bandit feedback.
\newblock In \emph{International Conference on Algorithmic Learning Theory},
  2013.

\bibitem[Orabona et~al.(2015)Orabona, Crammer, and
  Cesa-Bianchi]{orabona2015generalized}
Orabona, F., Crammer, K., and Cesa-Bianchi, N.
\newblock A generalized online mirror descent with applications to
  classification and regression.
\newblock \emph{Machine Learning}, 99\penalty0 (3), 2015.

\bibitem[Seldin \& Lugosi(2017)Seldin and Lugosi]{seldin2017improved}
Seldin, Y. and Lugosi, G.
\newblock An improved parametrization and analysis of the exp3++ algorithm for
  stochastic and adversarial bandits.
\newblock In \emph{Conference on Learning Theory}, 2017.

\bibitem[Seldin \& Slivkins(2014)Seldin and Slivkins]{seldin2014one}
Seldin, Y. and Slivkins, A.
\newblock One practical algorithm for both stochastic and adversarial bandits.
\newblock In \emph{International Conference on Machine Learning}, 2014.

\bibitem[Suehiro et~al.(2012)Suehiro, Hatano, Kijima, Takimoto, and
  Nagano]{suehiro2012online}
Suehiro, D., Hatano, K., Kijima, S., Takimoto, E., and Nagano, K.
\newblock Online prediction under submodular constraints.
\newblock In \emph{International Conference on Algorithmic Learning Theory},
  pp.\  260--274. Springer, 2012.

\bibitem[Thune \& Seldin(2018)Thune and Seldin]{thune2018adaptation}
Thune, T. and Seldin, Y.
\newblock Adaptation to easy data in prediction with limited advice.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2909--2918, 2018.

\bibitem[Warmuth \& Kuzmin(2008)Warmuth and Kuzmin]{warmuth2008randomized}
Warmuth, M.~K. and Kuzmin, D.
\newblock Randomized online pca algorithms with regret bounds that are
  logarithmic in the dimension.
\newblock \emph{Journal of Machine Learning Research}, 9\penalty0
  (Oct):\penalty0 2287--2320, 2008.

\bibitem[Wei \& Luo(2018)Wei and Luo]{wei2018more}
Wei, C.-Y. and Luo, H.
\newblock More adaptive algorithms for adversarial bandits.
\newblock In \emph{Computational Learning Theory}, 2018.

\bibitem[Zimmert \& Seldin(2019)Zimmert and Seldin]{zimmert2018optimal}
Zimmert, J. and Seldin, Y.
\newblock An optimal algorithm for stochastic and adversarial bandits.
\newblock In \emph{Artificial Intelligence and Statistics}, 2019.

\end{thebibliography}
