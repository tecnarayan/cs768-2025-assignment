\begin{thebibliography}{58}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amodei et~al.(2016)Amodei, Olah, Steinhardt, Christiano, Schulman, and
  Man{\'{e}}]{concreteAIsafety}
Dario Amodei, Chris Olah, Jacob Steinhardt, Paul~F Christiano, John Schulman,
  and Dan Man{\'{e}}.
\newblock Concrete problems in {AI} safety.
\newblock \emph{CoRR}, abs/1606.06565, 2016.
\newblock URL \url{http://arxiv.org/abs/1606.06565}.

\bibitem[Balakrishnan et~al.(2013)Balakrishnan, Narayanan, Rinaldo, Singh, and
  Wasserman]{balakrishnan2013cluster}
Sivaraman Balakrishnan, Srivatsan Narayanan, Alessandro Rinaldo, Aarti Singh,
  and Larry Wasserman.
\newblock Cluster trees on manifolds.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2679--2687, 2013.

\bibitem[Bartlett and Wegkamp(2008)]{bartlett2008classification}
Peter~L Bartlett and Marten~H Wegkamp.
\newblock Classification with a reject option using a hinge loss.
\newblock \emph{Journal of Machine Learning Research}, 9\penalty0
  (Aug):\penalty0 1823--1840, 2008.

\bibitem[Chaudhuri and Dasgupta(2010)]{chaudhuri2010rates}
Kamalika Chaudhuri and Sanjoy Dasgupta.
\newblock Rates of convergence for the cluster tree.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  343--351, 2010.

\bibitem[Chazal(2013)]{chazal2013upper}
Fr{\'e}d{\'e}ric Chazal.
\newblock An upper bound for the volume of geodesic balls in submanifolds of
  {Euclidean} spaces.
\newblock
  \emph{https://geometrica.saclay.inria.fr/team/Fred.Chazal/BallVolumeJan2013.pdf},
  2013.

\bibitem[Chollet et~al.(2015)]{chollet2015keras}
Fran\c{c}ois Chollet et~al.
\newblock Keras.
\newblock 2015.

\bibitem[Chow(1970)]{chow1970optimum}
C~Chow.
\newblock On optimum recognition error and reject tradeoff.
\newblock \emph{IEEE Transactions on Information Theory}, 16\penalty0
  (1):\penalty0 41--46, 1970.

\bibitem[Cortes et~al.(2016{\natexlab{a}})Cortes, DeSalvo, and
  Mohri]{cortes2016boosting}
Corinna Cortes, Giulia DeSalvo, and Mehryar Mohri.
\newblock Boosting with abstention.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1660--1668, 2016{\natexlab{a}}.

\bibitem[Cortes et~al.(2016{\natexlab{b}})Cortes, DeSalvo, and
  Mohri]{cortes2016learning}
Corinna Cortes, Giulia DeSalvo, and Mehryar Mohri.
\newblock Learning with rejection.
\newblock In \emph{International Conference on Algorithmic Learning Theory},
  pages 67--82. Springer, 2016{\natexlab{b}}.

\bibitem[Cortes et~al.(2017)Cortes, DeSalvo, Gentile, Mohri, and
  Yang]{cortes2017online}
Corinna Cortes, Giulia DeSalvo, Claudio Gentile, Mehryar Mohri, and Scott Yang.
\newblock Online learning with abstention.
\newblock \emph{arXiv preprint arXiv:1703.03478}, 2017.

\bibitem[Dasgupta and Kpotufe(2014)]{dasgupta2014optimal}
Sanjoy Dasgupta and Samory Kpotufe.
\newblock Optimal rates for {k-NN} density and mode estimation.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2555--2563, 2014.

\bibitem[Devroye et~al.(1994)Devroye, Gyorfi, Krzyzak, and
  Lugosi]{devroye1994strong}
Luc Devroye, Laszlo Gyorfi, Adam Krzyzak, and G{\'a}bor Lugosi.
\newblock On the strong universal consistency of nearest neighbor regression
  function estimates.
\newblock \emph{The Annals of Statistics}, pages 1371--1385, 1994.

\bibitem[Dubuisson and Masson(1993)]{dubuisson1993statistical}
Bernard Dubuisson and Mylene Masson.
\newblock A statistical decision rule with incomplete knowledge about classes.
\newblock \emph{Pattern Recognition}, 26\penalty0 (1):\penalty0 155--165, 1993.

\bibitem[El-Yaniv and Wiener(2010)]{el2010foundations}
Ran El-Yaniv and Yair Wiener.
\newblock On the foundations of noise-free selective classification.
\newblock \emph{Journal of Machine Learning Research}, 11\penalty0
  (May):\penalty0 1605--1641, 2010.

\bibitem[Ester et~al.(1996)Ester, Kriegel, Sander, Xu,
  et~al.]{ester1996density}
Martin Ester, Hans-Peter Kriegel, J{\"o}rg Sander, Xiaowei Xu, et~al.
\newblock A density-based algorithm for discovering clusters in large spatial
  databases with noise.
\newblock In \emph{Kdd}, pages 226--231, 1996.

\bibitem[Fan et~al.(2002)Fan, Chu, Wang, and Yu]{Fan:2002}
Wei Fan, Fang Chu, Haixun Wang, and Philip~S. Yu.
\newblock Pruning and dynamic scheduling of cost-sensitive ensembles.
\newblock \emph{AAAI}, 2002.

\bibitem[Friedman et~al.(2001)Friedman, Hastie, and
  Tibshirani]{friedman2001elements}
Jerome Friedman, Trevor Hastie, and Robert Tibshirani.
\newblock \emph{The Elements of Statistical Learning}.
\newblock Springer, 2001.

\bibitem[Fumera and Roli(2002)]{fumera2002support}
Giorgio Fumera and Fabio Roli.
\newblock Support vector machines with embedded reject option.
\newblock In \emph{Pattern Recognition with Support Vector Machines}, pages
  68--82. Springer, 2002.

\bibitem[Fumera et~al.(2000)Fumera, Roli, and Giacinto]{fumera2000multiple}
Giorgio Fumera, Fabio Roli, and Giorgio Giacinto.
\newblock Multiple reject thresholds for improving classification reliability.
\newblock In \emph{Joint IAPR International Workshops on Statistical Techniques
  in Pattern Recognition (SPR) and Structural and Syntactic Pattern Recognition
  (SSPR)}, pages 863--871. Springer, 2000.

\bibitem[Gal and Ghahramani(2016)]{gal2016dropout}
Yarin Gal and Zoubin Ghahramani.
\newblock Dropout as a {Bayesian} approximation: Representing model uncertainty
  in deep learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  1050--1059, 2016.

\bibitem[Genovese et~al.(2012)Genovese, Perone-Pacifico, Verdinelli, and
  Wasserman]{genovese2012minimax}
Christopher Genovese, Marco Perone-Pacifico, Isabella Verdinelli, and Larry
  Wasserman.
\newblock Minimax manifold estimation.
\newblock \emph{Journal of Machine Learning Research}, 13\penalty0
  (May):\penalty0 1263--1291, 2012.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock \emph{arXiv preprint arXiv:1412.6572}, 2014.

\bibitem[Grandvalet et~al.(2009)Grandvalet, Rakotomamonjy, Keshet, and
  Canu]{grandvalet2009support}
Yves Grandvalet, Alain Rakotomamonjy, Joseph Keshet, and St{\'e}phane Canu.
\newblock Support vector machines with a reject option.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  537--544, 2009.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017calibration}
Chuan Guo, Geoff Pleiss, Yu~Sun, and Kilian~Q Weinberger.
\newblock On calibration of modern neural networks.
\newblock \emph{arXiv preprint arXiv:1706.04599}, 2017.

\bibitem[Hartigan(1975)]{hartigan1975clustering}
John~A Hartigan.
\newblock Clustering algorithms.
\newblock 1975.

\bibitem[Hendrycks and Gimpel(2016)]{hendrycks2016baseline}
Dan Hendrycks and Kevin Gimpel.
\newblock A baseline for detecting misclassified and out-of-distribution
  examples in neural networks.
\newblock \emph{arXiv preprint arXiv:1610.02136}, 2016.

\bibitem[Herbei and Wegkamp(2006)]{herbei2006classification}
Radu Herbei and Marten~H Wegkamp.
\newblock Classification with reject option.
\newblock \emph{Canadian Journal of Statistics}, 34\penalty0 (4):\penalty0
  709--721, 2006.

\bibitem[Jiang(2017{\natexlab{a}})]{jiang2017density}
Heinrich Jiang.
\newblock Density level set estimation on manifolds with {DBSCAN}.
\newblock In \emph{International Conference on Machine Learning}, pages
  1684--1693, 2017{\natexlab{a}}.

\bibitem[Jiang(2017{\natexlab{b}})]{jiang2017uniform}
Heinrich Jiang.
\newblock Uniform convergence rates for kernel density estimation.
\newblock In \emph{International Conference on Machine Learning}, pages
  1694--1703, 2017{\natexlab{b}}.

\bibitem[Kendall and Gal(2017)]{kendall2017uncertainties}
Alex Kendall and Yarin Gal.
\newblock What uncertainties do we need in {Bayesian} deep learning for
  computer vision?
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  5580--5590, 2017.

\bibitem[Krizhevsky(2009)]{krizhevsky2009learning}
Alex Krizhevsky.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Kuleshov and Liang(2015)]{kuleshov2015calibrated}
Volodymyr Kuleshov and Percy~S Liang.
\newblock Calibrated structured prediction.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3474--3482, 2015.

\bibitem[Lakshminarayanan et~al.(2017)Lakshminarayanan, Pritzel, and
  Blundell]{lakshminarayanan2017simple}
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell.
\newblock Simple and scalable predictive uncertainty estimation using deep
  ensembles.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  6405--6416, 2017.

\bibitem[Landgrebe et~al.(2006)Landgrebe, Tax, Pacl{\'\i}k, and
  Duin]{landgrebe2006interaction}
Thomas~CW Landgrebe, David~MJ Tax, Pavel Pacl{\'\i}k, and Robert~PW Duin.
\newblock The interaction between classification and reject performance for
  distance-based reject-option classifiers.
\newblock \emph{Pattern Recognition Letters}, 27\penalty0 (8):\penalty0
  908--917, 2006.

\bibitem[LeCun(1998)]{lecun1998mnist}
Yann LeCun.
\newblock The {MNIST} database of handwritten digits.
\newblock \emph{http://yann. lecun. com/exdb/mnist/}, 1998.

\bibitem[Lee and See(2004)]{lee2004trust}
John~D Lee and Katrina~A See.
\newblock Trust in automation: Designing for appropriate reliance.
\newblock \emph{Human factors}, 46\penalty0 (1):\penalty0 50--80, 2004.

\bibitem[Liu and Deng(2015)]{Liu2015VeryDC}
Shuying Liu and Weihong Deng.
\newblock Very deep convolutional neural network based image classification
  using small training sample size.
\newblock \emph{2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR)},
  pages 730--734, 2015.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and
  Ng]{netzer2011reading}
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo~Wu, and Andrew~Y
  Ng.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock 2011.

\bibitem[Nguyen et~al.(2015)Nguyen, Yosinski, and Clune]{nguyen2015deep}
Anh Nguyen, Jason Yosinski, and Jeff Clune.
\newblock Deep neural networks are easily fooled: High confidence predictions
  for unrecognizable images.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 427--436, 2015.

\bibitem[Niculescu-Mizil and Caruana(2005)]{niculescu2005predicting}
Alexandru Niculescu-Mizil and Rich Caruana.
\newblock Predicting good probabilities with supervised learning.
\newblock In \emph{Proceedings of the 22nd International Conference on Machine
  Learning}, pages 625--632. ACM, 2005.

\bibitem[Niyogi et~al.(2008)Niyogi, Smale, and Weinberger]{niyogi2008finding}
Partha Niyogi, Stephen Smale, and Shmuel Weinberger.
\newblock Finding the homology of submanifolds with high confidence from random
  samples.
\newblock \emph{Discrete \& Computational Geometry}, 39\penalty0
  (1-3):\penalty0 419--441, 2008.

\bibitem[Papernot and McDaniel(2018)]{papernot2018deep}
Nicolas Papernot and Patrick McDaniel.
\newblock Deep k-nearest neighbors: Towards confident, interpretable and robust
  deep learning.
\newblock \emph{arXiv preprint arXiv:1803.04765}, 2018.

\bibitem[Parrish et~al.(2013)Parrish, Anderson, Gupta, and Hsaio]{Parrish:2013}
Nathan Parrish, Hyrum~S. Anderson, Maya~R. Gupta, and Dun~Yu Hsaio.
\newblock Classifying with confidence from incomplete information.
\newblock \emph{Journal of Machine Learning Research}, 14\penalty0
  (December):\penalty0 3561--3589, 2013.

\bibitem[Platt(1999)]{platt1999probabilistic}
John Platt.
\newblock Probabilistic outputs for support vector machines and comparisons to
  regularized likelihood methods.
\newblock \emph{Advances in Large Margin Classifiers}, 10\penalty0
  (3):\penalty0 61--74, 1999.

\bibitem[Provost et~al.(1998)Provost, Fawcett, and Kohavi]{provost1998case}
Foster~J Provost, Tom Fawcett, and Ron Kohavi.
\newblock The case against accuracy estimation for comparing induction
  algorithms.
\newblock In \emph{ICML}, volume~98, pages 445--453, 1998.

\bibitem[Rigollet et~al.(2009)Rigollet, Vert, et~al.]{rigollet2009optimal}
Philippe Rigollet, R{\'e}gis Vert, et~al.
\newblock Optimal rates for plug-in estimators of density level sets.
\newblock \emph{Bernoulli}, 15\penalty0 (4):\penalty0 1154--1178, 2009.

\bibitem[Rinaldo and Wasserman(2010)]{rinaldo2010generalized}
Alessandro Rinaldo and Larry Wasserman.
\newblock Generalized density clustering.
\newblock \emph{The Annals of Statistics}, 38\penalty0 (5):\penalty0
  2678--2722, 2010.

\bibitem[Santos-Pereira and Pires(2005)]{santos2005optimal}
Carla~M Santos-Pereira and Ana~M Pires.
\newblock On optimal reject rules and {ROC} curves.
\newblock \emph{Pattern Recognition Letters}, 26\penalty0 (7):\penalty0
  943--952, 2005.

\bibitem[Simonyan and Zisserman(2014)]{simonyan2014very}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem[Singh et~al.(2009)Singh, Scott, Nowak, et~al.]{singh2009adaptive}
Aarti Singh, Clayton Scott, Robert Nowak, et~al.
\newblock Adaptive {Hausdorff} estimation of density level sets.
\newblock \emph{The Annals of Statistics}, 37\penalty0 (5B):\penalty0
  2760--2782, 2009.

\bibitem[Tax and Duin(2008)]{tax2008growing}
David~MJ Tax and Robert~PW Duin.
\newblock Growing a multi-class classifier with a reject option.
\newblock \emph{Pattern Recognition Letters}, 29\penalty0 (10):\penalty0
  1565--1570, 2008.

\bibitem[Tortorella(2000)]{tortorella2000optimal}
Francesco Tortorella.
\newblock An optimal reject rule for binary classifiers.
\newblock In \emph{Joint IAPR International Workshops on Statistical Techniques
  in Pattern Recognition (SPR) and Structural and Syntactic Pattern Recognition
  (SSPR)}, pages 611--620. Springer, 2000.

\bibitem[Tsybakov et~al.(1997)]{tsybakov1997nonparametric}
Alexandre~B Tsybakov et~al.
\newblock On nonparametric estimation of density level sets.
\newblock \emph{The Annals of Statistics}, 25\penalty0 (3):\penalty0 948--969,
  1997.

\bibitem[Varshney and Alemzadeh(2017)]{varshney2017safety}
Kush~R Varshney and Homa Alemzadeh.
\newblock On the safety of machine learning: Cyber-physical systems, decision
  sciences, and data products.
\newblock \emph{Big data}, 5\penalty0 (3):\penalty0 246--255, 2017.

\bibitem[Wang et~al.(2015)Wang, Trapeznikov, and Saligrama]{Wang:2015}
Joseph Wang, Kirill Trapeznikov, and Venkatesh Saligrama.
\newblock Efficient learning by directed acyclic graph for resource constrained
  prediction.
\newblock \emph{Advances in Neural Information Processing Systems {(NIPS)}},
  2015.

\bibitem[Wiener and El-Yaniv(2011)]{wiener2011agnostic}
Yair Wiener and Ran El-Yaniv.
\newblock Agnostic selective classification.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1665--1673, 2011.

\bibitem[Yuan and Wegkamp(2010)]{yuan2010classification}
Ming Yuan and Marten Wegkamp.
\newblock Classification methods with reject option based on convex risk
  minimization.
\newblock \emph{Journal of Machine Learning Research}, 11\penalty0
  (Jan):\penalty0 111--130, 2010.

\bibitem[Zadrozny and Elkan(2002)]{zadrozny2002transforming}
Bianca Zadrozny and Charles Elkan.
\newblock Transforming classifier scores into accurate multiclass probability
  estimates.
\newblock In \emph{Proceedings of the Eighth ACM SIGKDD International
  Conference on Knowledge Discovery and Data Mining}, pages 694--699. ACM,
  2002.

\end{thebibliography}
