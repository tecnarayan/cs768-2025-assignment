\begin{thebibliography}{10}

\bibitem{input_uncertainty_augmentation}
M.~S. Ayhan and P.~Berens.
\newblock {Test-time Data Augmentation for Estimation of Heteroscedastic
  Aleatoric Uncertainty in Deep Neural Networks}.
\newblock {\em MIDL}, Mar. 2018.

\bibitem{Bahdanau15}
D.~Bahdanau, K.~Cho, and Y.~Bengio.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock {\em ICLR}, 2015.

\bibitem{retain}
E.~Choi, M.~T. Bahadori, J.~Sun, J.~Kulas, A.~Schuetz, and W.~Stewart.
\newblock Retain: An interpretable predictive model for healthcare using
  reverse time attention mechanism.
\newblock In {\em NIPS}. 2016.

\bibitem{futoma17}
J.~Futoma, S.~Hariharan, and K.~A. Heller.
\newblock Learning to detect sepsis with a multitask gaussian process {RNN}
  classifier.
\newblock In {\em ICML}, 2017.

\bibitem{rnn_dropout}
Y.~{Gal} and Z.~{Ghahramani}.
\newblock {A Theoretically Grounded Application of Dropout in Recurrent Neural
  Networks}.
\newblock {\em ArXiv e-prints}, 2015.

\bibitem{cnn_dropout}
Y.~{Gal} and Z.~{Ghahramani}.
\newblock {Bayesian Convolutional Neural Networks with Bernoulli Approximate
  Variational Inference}.
\newblock {\em ArXiv e-prints}, June 2015.

\bibitem{dropout_as_bayesian}
Y.~Gal and Z.~Ghahramani.
\newblock Dropout as a bayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In {\em ICML}, 2016.

\bibitem{concrete_dropout}
Y.~Gal, J.~Hron, and A.~Kendall.
\newblock Concrete dropout.
\newblock In I.~Guyon, U.~V. Luxburg, S.~Bengio, H.~Wallach, R.~Fergus,
  S.~Vishwanathan, and R.~Garnett, editors, {\em NIPS}, 2017.

\bibitem{guo17}
C.~Guo, G.~Pleiss, Y.~Sun, and K.~Q. Weinberger.
\newblock On calibration of modern neural networks.
\newblock In {\em ICML}, 2017.

\bibitem{resnet}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock {Deep Residual Learning for Image Recognition}.
\newblock In {\em CVPR}, 2016.

\bibitem{physio2012}
D.~J. S. L. A.~C. Ivanovitch~Silva, Galan~Moody and R.~G. Mark.
\newblock Predicting in-hospital mortality of icu patients: The
  physionet/computing in cardiology challenge 2012.
\newblock In {\em In CinC}, 2012.

\bibitem{mimic3_ref}
A.~E. Johnson, T.~J. Pollard, L.~Shen, L.~wei H.~Lehman, M.~Feng, M.~Ghassemi,
  B.~Moody, P.~Szolovits, L.~A. Celi, and R.~G. Mark.
\newblock Mimic-iii, a freely accessible critical care database.

\bibitem{bayesian_segnet}
A.~{Kendall}, V.~{Badrinarayanan}, and R.~{Cipolla}.
\newblock {Bayesian SegNet: Model Uncertainty in Deep Convolutional
  Encoder-Decoder Architectures for Scene Understanding}.
\newblock {\em ArXiv e-prints}, Nov. 2015.

\bibitem{what_uncertainty}
A.~{Kendall} and Y.~{Gal}.
\newblock {What Uncertainties Do We Need in Bayesian Deep Learning for Computer
  Vision?}
\newblock In {\em NIPS}, 2017.

\bibitem{adam}
D.~P. Kingma and J.~Ba.
\newblock Adam: {A} method for stochastic optimization.
\newblock {\em CoRR}, abs/1412.6980, 2014.

\bibitem{variational_dropout}
D.~P. {Kingma}, T.~{Salimans}, and M.~{Welling}.
\newblock {Variational Dropout and the Local Reparameterization Trick}.
\newblock {\em ArXiv e-prints}, June 2015.

\bibitem{vae}
D.~P. Kingma and M.~Welling.
\newblock Auto encoding variational bayes.
\newblock In {\em ICLR}. 2014.

\bibitem{alexnet}
A.~Krizhevsky, I.~Sutskever, and G.~E. Hinton.
\newblock {ImageNet Classification with Deep Convolutional Neural Networks}.
\newblock In {\em NIPS}, 2012.

\bibitem{deep_ensembles}
B.~Lakshminarayanan, A.~Pritzel, and C.~Blundell.
\newblock Simple and scalable predictive uncertainty estimation using deep
  ensembles.
\newblock In {\em NIPS}, pages 6405--6416, 2017.

\bibitem{sepsis3}
S.~M, D.~CS, S.~C, and et~al.
\newblock The third international consensus definitions for sepsis and septic
  shock (sepsis-3).
\newblock In {\em JAMA}, 2016.

\bibitem{concrete_distribution}
C.~J. {Maddison}, A.~{Mnih}, and Y.~{Whye Teh}.
\newblock {The Concrete Distribution: A Continuous Relaxation of Discrete
  Random Variables}.
\newblock {\em ArXiv e-prints}, Nov. 2016.

\bibitem{ece}
M.~P. Naeini, G.~F. Cooper, and M.~Hauskrecht.
\newblock Obtaining well calibrated probabilities using bayesian binning.
\newblock In {\em AAAI}, 2015.

\bibitem{benchmark_mimic3}
S.~Purushotham, C.~Meng, Z.~Che, and Y.~Liu.
\newblock Benchmark of deep learning models on large healthcare {MIMIC}
  datasets.
\newblock In {\em CoRR}, 2017.

\bibitem{cvae}
K.~Sohn, H.~Lee, and X.~Yan.
\newblock Learning structured output representation using deep conditional
  generative models.
\newblock In {\em NIPS}. 2015.

\bibitem{dropout}
N.~Srivastava, G.~Hinton, A.~Krizhevsky, I.~Sutskever, and R.~Salakhutdinov.
\newblock Dropout: A simple way to prevent neural networks from overfitting.
\newblock {\em Journal of Machine Learning Research}, 15:1929--1958, 2014.

\bibitem{e2ememnet}
S.~Sukhbaatar, A.~Szlam, J.~Weston, and R.~Fergus.
\newblock End-to-end memory networks.
\newblock In {\em NIPS}, 2015.

\bibitem{bayesian_lstm}
J.~{van der Westhuizen} and J.~{Lasenby}.
\newblock {Bayesian LSTMs in medicine}.
\newblock {\em ArXiv e-prints}, June 2017.

\bibitem{show_attend_tell}
K.~Xu, J.~L. Ba, R.~Kiros, K.~Cho, A.~Courville, R.~Salakhutdinov, R.~S. Zemel,
  and Y.~Bengio.
\newblock Show, attend and tell: Neural image caption generation with visual
  attention.
\newblock In {\em ICML}, 2015.

\bibitem{timeseries_uncertainty_uber}
L.~{Zhu} and N.~{Laptev}.
\newblock {Deep and Confident Prediction for Time Series at Uber}.
\newblock {\em ArXiv e-prints}, Sept. 2017.

\end{thebibliography}
