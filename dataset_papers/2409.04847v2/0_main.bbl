\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{avrahami2023spatext}
Omri Avrahami, Thomas Hayes, Oran Gafni, Sonal Gupta, Yaniv Taigman, Devi Parikh, Dani Lischinski, Ohad Fried, and Xi Yin.
\newblock Spatext: Spatio-textual representation for controllable image generation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 18370--18380, 2023.

\bibitem{avrahami2022blended}
Omri Avrahami, Dani Lischinski, and Ohad Fried.
\newblock Blended diffusion for text-driven editing of natural images.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 18208--18218, 2022.

\bibitem{qwen}
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu.
\newblock Qwen technical report.
\newblock {\em arXiv preprint arXiv:2309.16609}, 2023.

\bibitem{balaji2022ediffi}
Yogesh Balaji, Seungjun Nah, Xun Huang, Arash Vahdat, Jiaming Song, Karsten Kreis, Miika Aittala, Timo Aila, Samuli Laine, Bryan Catanzaro, et~al.
\newblock ediffi: Text-to-image diffusion models with an ensemble of expert denoisers.
\newblock {\em arXiv preprint arXiv:2211.01324}, 2022.

\bibitem{dalle3}
James Betker, Gabriel Goh, Li Jing, Tim Brooks, Jianfeng Wang, Linjie Li, Long Ouyang, Juntang Zhuang, Joyce Lee, Yufei Guo, et~al.
\newblock Improving image generation with better captions.
\newblock {\em Computer Science. https://cdn. openai. com/papers/dall-e-3. pdf}, 2(3):8, 2023.

\bibitem{brooks2023instructpix2pix}
Tim Brooks, Aleksander Holynski, and Alexei~A Efros.
\newblock Instructpix2pix: Learning to follow image editing instructions.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 18392--18402, 2023.

\bibitem{coco}
Holger Caesar, Jasper Uijlings, and Vittorio Ferrari.
\newblock Coco-stuff: Thing and stuff classes in context.
\newblock In {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 1209--1218, 2018.

\bibitem{cc3m}
Soravit Changpinyo, Piyush Sharma, Nan Ding, and Radu Soricut.
\newblock Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 3558--3568, 2021.

\bibitem{pixart_sigma}
Junsong Chen, Chongjian Ge, Enze Xie, Yue Wu, Lewei Yao, Xiaozhe Ren, Zhongdao Wang, Ping Luo, Huchuan Lu, and Zhenguo Li.
\newblock Pixart-$sigma$: Weak-to-strong training of diffusion transformer for 4k text-to-image generation.
\newblock {\em arXiv preprint arXiv:2403.04692}, 2024.

\bibitem{pixart_alpha}
Junsong Chen, Jincheng Yu, Chongjian Ge, Lewei Yao, Enze Xie, Yue Wu, Zhongdao Wang, James Kwok, Ping Luo, Huchuan Lu, et~al.
\newblock Pixart-$alpha$: Fast training of diffusion transformer for photorealistic text-to-image synthesis.
\newblock {\em arXiv preprint arXiv:2310.00426}, 2023.

\bibitem{cheng2023layoutdiffuse}
Jiaxin Cheng, Xiao Liang, Xingjian Shi, Tong He, Tianjun Xiao, and Mu Li.
\newblock Layoutdiffuse: Adapting foundational diffusion models for layout-to-image generation.
\newblock {\em arXiv preprint arXiv:2302.08908}, 2023.

\bibitem{cheng2023consistent}
Jiaxin Cheng, Tianjun Xiao, and Tong He.
\newblock Consistent video-to-video transfer using synthetic dataset.
\newblock {\em arXiv preprint arXiv:2311.00213}, 2023.

\bibitem{yoloworld}
Tianheng Cheng, Lin Song, Yixiao Ge, Wenyu Liu, Xinggang Wang, and Ying Shan.
\newblock Yolo-world: Real-time open-vocabulary object detection.
\newblock {\em arXiv preprint arXiv:2401.17270}, 2024.

\bibitem{cheng2023sdfusion}
Yen-Chi Cheng, Hsin-Ying Lee, Sergey Tulyakov, Alexander~G Schwing, and Liang-Yan Gui.
\newblock Sdfusion: Multimodal 3d shape completion, reconstruction, and generation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 4456--4465, 2023.

\bibitem{dhariwal2021diffusion}
Prafulla Dhariwal and Alexander~Quinn Nichol.
\newblock Diffusion models beat gans on image synthesis.
\newblock In {\em Advances in Neural Information Processing Systems}, 2021.

\bibitem{textualinversion}
Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or Patashnik, Amit~Haim Bermano, Gal Chechik, and Daniel Cohen-or.
\newblock An image is worth one word: Personalizing text-to-image generation using textual inversion.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2022.

\bibitem{gan}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial networks.
\newblock {\em Communications of the ACM}, 63(11):139--144, 2020.

\bibitem{gupta2019lvis}
Agrim Gupta, Piotr Dollar, and Ross Girshick.
\newblock Lvis: A dataset for large vocabulary instance segmentation.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 5356--5364, 2019.

\bibitem{context_l2i}
Sen He, Wentong Liao, Michael~Ying Yang, Yongxin Yang, Yi-Zhe Song, Bodo Rosenhahn, and Tao Xiang.
\newblock Context-aware layout to image generation with enhanced object appearance.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 15049--15058, 2021.

\bibitem{fid}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash equilibrium.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{ddpm}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock {\em Advances in neural information processing systems}, 33:6840--6851, 2020.

\bibitem{cfg}
Jonathan Ho and Tim Salimans.
\newblock Classifier-free diffusion guidance.
\newblock {\em arXiv preprint arXiv:2207.12598}, 2022.

\bibitem{taming}
Manuel Jahn, Robin Rombach, and Bj{\"o}rn Ommer.
\newblock High-resolution complex scene synthesis with transformers.
\newblock {\em arXiv preprint arXiv:2105.06458}, 2021.

\bibitem{kawar2023imagic}
Bahjat Kawar, Shiran Zada, Oran Lang, Omer Tov, Huiwen Chang, Tali Dekel, Inbar Mosseri, and Michal Irani.
\newblock Imagic: Text-based real image editing with diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 6007--6017, 2023.

\bibitem{li2023gligen}
Yuheng Li, Haotian Liu, Qingyang Wu, Fangzhou Mu, Jianwei Yang, Jianfeng Gao, Chunyuan Li, and Yong~Jae Lee.
\newblock Gligen: Open-set grounded text-to-image generation.
\newblock {\em arXiv preprint arXiv:2301.07093}, 2023.

\bibitem{lama}
Zejian Li, Jingyu Wu, Immanuel Koh, Yongchuan Tang, and Lingyun Sun.
\newblock Image synthesis from layout with locality-aware mask adaption.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 13819--13828, 2021.

\bibitem{liu2023grounding}
Shilong Liu, Zhaoyang Zeng, Tianhe Ren, Feng Li, Hao Zhang, Jie Yang, Chunyuan Li, Jianwei Yang, Hang Su, Jun Zhu, et~al.
\newblock Grounding dino: Marrying dino with grounded pre-training for open-set object detection.
\newblock {\em arXiv preprint arXiv:2303.05499}, 2023.

\bibitem{adamw}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock {\em arXiv preprint arXiv:1711.05101}, 2017.

\bibitem{meng2021sdedit}
Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and Stefano Ermon.
\newblock Sdedit: Guided image synthesis and editing with stochastic differential equations.
\newblock {\em arXiv preprint arXiv:2108.01073}, 2021.

\bibitem{mou2023t2i}
Chong Mou, Xintao Wang, Liangbin Xie, Jian Zhang, Zhongang Qi, Ying Shan, and Xiaohu Qie.
\newblock T2i-adapter: Learning adapters to dig out more controllable ability for text-to-image diffusion models.
\newblock {\em arXiv preprint arXiv:2302.08453}, 2023.

\bibitem{nichol2021improved}
Alexander~Quinn Nichol and Prafulla Dhariwal.
\newblock Improved denoising diffusion probabilistic models.
\newblock In {\em International Conference on Machine Learning}, pages 8162--8171. PMLR, 2021.

\bibitem{glide}
Alexander~Quinn Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob Mcgrew, Ilya Sutskever, and Mark Chen.
\newblock Glide: Towards photorealistic image generation and editing with text-guided diffusion models.
\newblock In {\em International Conference on Machine Learning}, pages 16784--16804. PMLR, 2022.

\bibitem{spade}
Taesung Park, Ming-Yu Liu, Ting-Chun Wang, and Jun-Yan Zhu.
\newblock Semantic image synthesis with spatially-adaptive normalization.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 2337--2346, 2019.

\bibitem{pernias2024wrstchen}
Pablo Pernias, Dominic Rampas, Mats~Leon Richter, Christopher Pal, and Marc Aubreville.
\newblock W\"urstchen: An efficient architecture for large-scale text-to-image diffusion models.
\newblock In {\em The Twelfth International Conference on Learning Representations}, 2024.

\bibitem{podell2023sdxl}
Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas M{\"u}ller, Joe Penna, and Robin Rombach.
\newblock Sdxl: Improving latent diffusion models for high-resolution image synthesis.
\newblock {\em arXiv preprint arXiv:2307.01952}, 2023.

\bibitem{poole2022dreamfusion}
Ben Poole, Ajay Jain, Jonathan~T Barron, and Ben Mildenhall.
\newblock Dreamfusion: Text-to-3d using 2d diffusion.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2022.

\bibitem{dalle2}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock {\em arXiv preprint arXiv:2204.06125}, 2022.

\bibitem{pSp}
Elad Richardson, Yuval Alaluf, Or Patashnik, Yotam Nitzan, Yaniv Azar, Stav Shapiro, and Daniel Cohen-Or.
\newblock Encoding in style: a stylegan encoder for image-to-image translation.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 2287--2296, 2021.

\bibitem{ldm}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 10684--10695, 2022.

\bibitem{ruiz2023dreambooth}
Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and Kfir Aberman.
\newblock Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 22500--22510, 2023.

\bibitem{saharia2022palette}
Chitwan Saharia, William Chan, Huiwen Chang, Chris Lee, Jonathan Ho, Tim Salimans, David Fleet, and Mohammad Norouzi.
\newblock Palette: Image-to-image diffusion models.
\newblock In {\em ACM SIGGRAPH 2022 Conference Proceedings}, pages 1--10, 2022.

\bibitem{palette}
Chitwan Saharia, William Chan, Huiwen Chang, Chris Lee, Jonathan Ho, Tim Salimans, David Fleet, and Mohammad Norouzi.
\newblock Palette: Image-to-image diffusion models.
\newblock In {\em ACM SIGGRAPH 2022 Conference Proceedings}, pages 1--10, 2022.

\bibitem{imagen}
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily~L Denton, Kamyar Ghasemipour, Raphael Gontijo~Lopes, Burcu Karagol~Ayan, Tim Salimans, et~al.
\newblock Photorealistic text-to-image diffusion models with deep language understanding.
\newblock {\em Advances in Neural Information Processing Systems}, 35:36479--36494, 2022.

\bibitem{saharia2022image}
Chitwan Saharia, Jonathan Ho, William Chan, Tim Salimans, David~J Fleet, and Mohammad Norouzi.
\newblock Image super-resolution via iterative refinement.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}, 45(4):4713--4726, 2022.

\bibitem{singer2022make}
Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, et~al.
\newblock Make-a-video: Text-to-video generation without text-video data.
\newblock {\em arXiv preprint arXiv:2209.14792}, 2022.

\bibitem{sohl2015deep}
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In {\em International conference on machine learning}, pages 2256--2265. PMLR, 2015.

\bibitem{song2019generative}
Yang Song and Stefano Ermon.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{song2020score}
Yang Song, Jascha Sohl-Dickstein, Diederik~P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole.
\newblock Score-based generative modeling through stochastic differential equations.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{lostgan}
Wei Sun and Tianfu Wu.
\newblock Image synthesis from reconfigurable layout and style.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 10531--10540, 2019.

\bibitem{ocgan}
Tristan Sylvain, Pengchuan Zhang, Yoshua Bengio, R~Devon Hjelm, and Shikhar Sharma.
\newblock Object-centric image generation from layouts.
\newblock In {\em Proceedings of the AAAI Conference on Artificial Intelligence}, volume~35, pages 2647--2655, 2021.

\bibitem{tang2023make}
Junshu Tang, Tengfei Wang, Bo Zhang, Ting Zhang, Ran Yi, Lizhuang Ma, and Dong Chen.
\newblock Make-it-3d: High-fidelity 3d creation from a single image with diffusion prior.
\newblock {\em arXiv preprint arXiv:2303.14184}, 2023.

\bibitem{vqvae}
Aaron Van Den~Oord, Oriol Vinyals, et~al.
\newblock Neural discrete representation learning.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{allyouneed}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{instdiff}
Xudong Wang, Trevor Darrell, Sai~Saketh Rambhatla, Rohit Girdhar, and Ishan Misra.
\newblock Instancediffusion: Instance-level control for image generation.
\newblock 2024.

\bibitem{watson2022novel}
Daniel Watson, William Chan, Ricardo~Martin Brualla, Jonathan Ho, Andrea Tagliasacchi, and Mohammad Norouzi.
\newblock Novel view synthesis with diffusion models.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2022.

\bibitem{randb}
Jiayu Xiao, Liang Li, Henglei Lv, Shuhui Wang, and Qingming Huang.
\newblock R\&b: Region and boundary aware zero-shot grounded text-to-image generation.
\newblock {\em arXiv preprint arXiv:2310.08872}, 2023.

\bibitem{boxdiff}
Jinheng Xie, Yuexiang Li, Yawen Huang, Haozhe Liu, Wentian Zhang, Yefeng Zheng, and Mike~Zheng Shou.
\newblock Boxdiff: Text-to-image synthesis with training-free box-constrained diffusion.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 7452--7461, 2023.

\bibitem{xue2023freestyle}
Han Xue, Zhiwu Huang, Qianru Sun, Li Song, and Wenjun Zhang.
\newblock Freestyle layout-to-image synthesis.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 14256--14266, 2023.

\bibitem{yang2023paint}
Binxin Yang, Shuyang Gu, Bo Zhang, Ting Zhang, Xuejin Chen, Xiaoyan Sun, Dong Chen, and Fang Wen.
\newblock Paint by example: Exemplar-based image editing with diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 18381--18391, 2023.

\bibitem{twfa}
Zuopeng Yang, Daqing Liu, Chaoyue Wang, Jie Yang, and Dacheng Tao.
\newblock Modeling image composition for complex scene generation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 7764--7773, 2022.

\bibitem{yao2022detclip}
Lewei Yao, Jianhua Han, Youpeng Wen, Xiaodan Liang, Dan Xu, Wei Zhang, Zhenguo Li, Chunjing Xu, and Hang Xu.
\newblock Detclip: Dictionary-enriched visual-concept paralleled pre-training for open-world detection.
\newblock {\em Advances in Neural Information Processing Systems}, 35:9125--9138, 2022.

\bibitem{zareian2021open}
Alireza Zareian, Kevin~Dela Rosa, Derek~Hao Hu, and Shih-Fu Chang.
\newblock Open-vocabulary object detection using captions.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 14393--14402, 2021.

\bibitem{controlnet}
Lvmin Zhang and Maneesh Agrawala.
\newblock Adding conditional control to text-to-image diffusion models.
\newblock {\em arXiv preprint arXiv:2302.05543}, 2023.

\bibitem{ram}
Youcai Zhang, Xinyu Huang, Jinyu Ma, Zhaoyang Li, Zhaochuan Luo, Yanchun Xie, Yuzhuo Qin, Tong Luo, Yaqian Li, Shilong Liu, et~al.
\newblock Recognize anything: A strong image tagging model.
\newblock {\em arXiv preprint arXiv:2306.03514}, 2023.

\bibitem{zheng2023layoutdiffusion}
Guangcong Zheng, Xianpan Zhou, Xuewei Li, Zhongang Qi, Ying Shan, and Xi Li.
\newblock Layoutdiffusion: Controllable diffusion model for layout-to-image generation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 22490--22499, 2023.

\end{thebibliography}
