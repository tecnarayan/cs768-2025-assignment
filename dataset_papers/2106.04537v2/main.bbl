\begin{thebibliography}{30}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alom et~al.(2018)Alom, Hasan, Yakopcic, Taha, and
  Asari]{alom2018recurrent}
Md~Zahangir Alom, Mahmudul Hasan, Chris Yakopcic, Tarek~M Taha, and Vijayan~K
  Asari.
\newblock Recurrent residual convolutional neural network based on u-net
  (r2u-net) for medical image segmentation.
\newblock \emph{arXiv preprint arXiv:1802.06955}, 2018.

\bibitem[Arjovsky et~al.(2019)Arjovsky, Bottou, Gulrajani, and
  Lopez-Paz]{arjovsky2019invariant}
Martin Arjovsky, L{\'e}on Bottou, Ishaan Gulrajani, and David Lopez-Paz.
\newblock Invariant risk minimization.
\newblock \emph{arXiv preprint arXiv:1907.02893}, 2019.

\bibitem[Baddeley(2012)]{baddeley2012working}
Alan Baddeley.
\newblock Working memory: theories, models, and controversies.
\newblock \emph{Annual review of psychology}, 63:\penalty0 1--29, 2012.

\bibitem[Baddeley and Hitch(1974)]{baddeley1974working}
Alan~D Baddeley and Graham Hitch.
\newblock Working memory.
\newblock In \emph{Psychology of learning and motivation}, volume~8, pages
  47--89. Elsevier, 1974.

\bibitem[Bai et~al.(2018)Bai, Kolter, and Koltun]{bai2018trellis}
Shaojie Bai, J~Zico Kolter, and Vladlen Koltun.
\newblock Trellis networks for sequence modeling.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Bai et~al.(2019)Bai, Kolter, and Koltun]{bai2019deep}
Shaojie Bai, J~Zico Kolter, and Vladlen Koltun.
\newblock Deep equilibrium models.
\newblock \emph{Advances in Neural Information Processing Systems},
  32:\penalty0 690--701, 2019.

\bibitem[Biswas and Regan(2015)]{biswas2015measuring}
Tamal Biswas and Kenneth Regan.
\newblock Measuring level-k reasoning, satisficing, and human error in
  game-play data.
\newblock In \emph{2015 IEEE 14th International Conference on Machine Learning
  and Applications (ICMLA)}, pages 941--947. IEEE, 2015.

\bibitem[Elo(1978)]{elo1978rating}
Arpad~E Elo.
\newblock \emph{The rating of chessplayers, past and present}.
\newblock Arco Pub., 1978.

\bibitem[Eyzaguirre and Soto(2020)]{eyzaguirre2020differentiable}
Cristobal Eyzaguirre and Alvaro Soto.
\newblock Differentiable adaptive computation time for visual reasoning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 12817--12825, 2020.

\bibitem[Graves(2016)]{graves2016adaptive}
Alex Graves.
\newblock Adaptive computation time for recurrent neural networks.
\newblock \emph{arXiv preprint arXiv:1603.08983}, 2016.

\bibitem[Graves et~al.(2014)Graves, Wayne, and Danihelka]{graves2014neural}
Alex Graves, Greg Wayne, and Ivo Danihelka.
\newblock Neural turing machines.
\newblock \emph{arXiv preprint arXiv:1410.5401}, 2014.

\bibitem[{He} et~al.(2016){He}, {Zhang}, {Ren}, and {Sun}]{he2016deep}
K.~{He}, X.~{Zhang}, S.~{Ren}, and J.~{Sun}.
\newblock Deep residual learning for image recognition.
\newblock In \emph{2016 IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pages 770--778, 2016.

\bibitem[Hill(2017)]{hill2017making}
Christian Hill.
\newblock Making a maze, Apr 2017.
\newblock URL \url{https://scipython.com/blog/making-a-maze/}.

\bibitem[Huang et~al.(2016)Huang, Sun, Liu, Sedra, and
  Weinberger]{huang2016deep}
Gao Huang, Yu~Sun, Zhuang Liu, Daniel Sedra, and Kilian~Q Weinberger.
\newblock Deep networks with stochastic depth.
\newblock In \emph{European conference on computer vision}, pages 646--661.
  Springer, 2016.

\bibitem[Jaegle et~al.(2021)Jaegle, Gimeno, Brock, Zisserman, Vinyals, and
  Carreira]{jaegle2021perceiver}
Andrew Jaegle, Felix Gimeno, Andrew Brock, Andrew Zisserman, Oriol Vinyals, and
  Joao Carreira.
\newblock Perceiver: General perception with iterative attention.
\newblock \emph{arXiv preprint arXiv:2103.03206}, 2021.

\bibitem[Kaiser and Sutskever(2015)]{kaiser2015neural}
{\L}ukasz Kaiser and Ilya Sutskever.
\newblock Neural gpus learn algorithms.
\newblock \emph{arXiv preprint arXiv:1511.08228}, 2015.

\bibitem[Kar et~al.(2019)Kar, Kubilius, Schmidt, Issa, and
  DiCarlo]{kar2019evidence}
Kohitij Kar, Jonas Kubilius, Kailyn Schmidt, Elias~B Issa, and James~J DiCarlo.
\newblock Evidence that recurrent circuits are critical to the ventral
  streamâ€™s execution of core object recognition behavior.
\newblock \emph{Nature neuroscience}, 22\penalty0 (6):\penalty0 974--983, 2019.

\bibitem[Kaya et~al.(2019)Kaya, Hong, and Dumitras]{kaya2019shallow}
Yigitcan Kaya, Sanghyun Hong, and Tudor Dumitras.
\newblock Shallow-deep networks: Understanding and mitigating network
  overthinking.
\newblock In \emph{International Conference on Machine Learning}, pages
  3301--3310. PMLR, 2019.

\bibitem[Lan et~al.(2020)Lan, Chen, Goodman, Gimpel, Sharma, and
  Soricut]{lan2020albert}
Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and
  Radu Soricut.
\newblock Albert: A lite bert for self-supervised learning of language
  representations.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Liang and Hu(2015)]{liang2015recurrent}
Ming Liang and Xiaolin Hu.
\newblock Recurrent convolutional neural network for object recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 3367--3375, 2015.

\bibitem[Liao and Poggio(2016)]{liao2016bridging}
Qianli Liao and Tomaso Poggio.
\newblock Bridging the gaps between residual learning, recurrent neural
  networks and visual cortex.
\newblock \emph{arXiv preprint arXiv:1604.03640}, 2016.

\bibitem[Lichess(2021)]{lichess}
Lichess.
\newblock Lichess open puzzles database.
\newblock \url{https://database.lichess.org/#puzzles}, 2021.
\newblock Accessed: 2021-04-01.

\bibitem[McIlroy-Young et~al.(2020)McIlroy-Young, Sen, Kleinberg, and
  Anderson]{mcilroy2020aligning}
Reid McIlroy-Young, Siddhartha Sen, Jon Kleinberg, and Ashton Anderson.
\newblock Aligning superhuman ai with human behavior: Chess as a model system.
\newblock In \emph{Proceedings of the 26th ACM SIGKDD International Conference
  on Knowledge Discovery \& Data Mining}, pages 1677--1687, 2020.

\bibitem[Pinheiro and Collobert(2014)]{pinheiro2014recurrent}
Pedro Pinheiro and Ronan Collobert.
\newblock Recurrent convolutional neural networks for scene labeling.
\newblock In \emph{International conference on machine learning}, pages 82--90.
  PMLR, 2014.

\bibitem[Romstad et~al.()Romstad, Costalba, and Kiiski]{stockfish}
Tord Romstad, Marco Costalba, and et~al. Kiiski, Joona.
\newblock Stockfish: A strong open source chess engine.
\newblock URL \url{https://stockfishchess.org/}.

\bibitem[Schwarzschild et~al.(2021)Schwarzschild, Borgnia, Gupta, Bansal, Emam,
  Huang, Goldblum, and Goldstein]{schwarzschild2021datasets}
Avi Schwarzschild, Eitan Borgnia, Arjun Gupta, Arpit Bansal, Zeyad Emam, Furong
  Huang, Micah Goldblum, and Tom Goldstein.
\newblock Datasets for studying generalization from easy to hard examples.
\newblock \emph{arXiv preprint arXiv:2108.06011}, 2021.

\bibitem[Selsam et~al.(2018)Selsam, Lamm, B{\"u}nz, Liang, de~Moura, and
  Dill]{selsam2018learning}
Daniel Selsam, Matthew Lamm, Benedikt B{\"u}nz, Percy Liang, Leonardo de~Moura,
  and David~L Dill.
\newblock Learning a sat solver from single-bit supervision.
\newblock \emph{arXiv preprint arXiv:1802.03685}, 2018.

\bibitem[Shu et~al.(2020)Shu, Wu, Goldblum, and Goldstein]{shu2020preparing}
Manli Shu, Zuxuan Wu, Micah Goldblum, and Tom Goldstein.
\newblock Preparing for the worst: Making networks less brittle with
  adversarial batch normalization.
\newblock \emph{arXiv preprint arXiv:2009.08965}, 2020.

\bibitem[Silver et~al.(2017)Silver, Hubert, Schrittwieser, Antonoglou, Lai,
  Guez, Lanctot, Sifre, Kumaran, Graepel, et~al.]{silver2017mastering}
David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew
  Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore
  Graepel, et~al.
\newblock Mastering chess and shogi by self-play with a general reinforcement
  learning algorithm.
\newblock \emph{arXiv preprint arXiv:1712.01815}, 2017.

\bibitem[Tamar et~al.(2016)Tamar, Wu, Thomas, Levine, and
  Abbeel]{tamar2016value}
Aviv Tamar, Yi~Wu, Garrett Thomas, Sergey Levine, and Pieter Abbeel.
\newblock Value iteration networks.
\newblock \emph{arXiv preprint arXiv:1602.02867}, 2016.

\end{thebibliography}
