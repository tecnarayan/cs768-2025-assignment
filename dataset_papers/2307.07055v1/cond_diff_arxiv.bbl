\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ajay et~al.(2023)Ajay, Du, Gupta, Tenenbaum, Jaakkola, and
  Agrawal]{ajay2023is}
Anurag Ajay, Yilun Du, Abhi Gupta, Joshua~B. Tenenbaum, Tommi~S. Jaakkola, and
  Pulkit Agrawal.
\newblock Is conditional generative modeling all you need for decision making?
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=sP1fo2K9DFG}.

\bibitem[Anderson(1982)]{anderson1982reverse}
Brian~DO Anderson.
\newblock Reverse-time diffusion equation models.
\newblock \emph{Stochastic Processes and their Applications}, 12\penalty0
  (3):\penalty0 313--326, 1982.

\bibitem[Austin et~al.(2021)Austin, Johnson, Ho, Tarlow, and van~den
  Berg]{austin2021structured}
Jacob Austin, Daniel~D Johnson, Jonathan Ho, Daniel Tarlow, and Rianne van~den
  Berg.
\newblock Structured denoising diffusion models in discrete state-spaces.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 17981--17993, 2021.

\bibitem[Balaji et~al.(2022)Balaji, Nah, Huang, Vahdat, Song, Kreis, Aittala,
  Aila, Laine, Catanzaro, et~al.]{balaji2022ediffi}
Yogesh Balaji, Seungjun Nah, Xun Huang, Arash Vahdat, Jiaming Song, Karsten
  Kreis, Miika Aittala, Timo Aila, Samuli Laine, Bryan Catanzaro, et~al.
\newblock ediffi: Text-to-image diffusion models with an ensemble of expert
  denoisers.
\newblock \emph{arXiv preprint arXiv:2211.01324}, 2022.

\bibitem[Brandfonbrener et~al.(2021)Brandfonbrener, Whitney, Ranganath, and
  Bruna]{brandfonbrener2021offline}
David Brandfonbrener, William Whitney, Rajesh Ranganath, and Joan Bruna.
\newblock Offline contextual bandits with overparameterized models.
\newblock In \emph{International Conference on Machine Learning}, pages
  1049--1058. PMLR, 2021.

\bibitem[Chen and Jiang(2019)]{chen2019information}
Jinglin Chen and Nan Jiang.
\newblock Information-theoretic considerations in batch reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  1042--1051. PMLR, 2019.

\bibitem[Chen et~al.(2020)Chen, Bai, Lee, Zhao, Wang, Xiong, and
  Socher]{chen2020towards}
Minshuo Chen, Yu~Bai, Jason~D Lee, Tuo Zhao, Huan Wang, Caiming Xiong, and
  Richard Socher.
\newblock Towards understanding hierarchical learning: Benefits of neural
  representations.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 22134--22145, 2020.

\bibitem[Chen et~al.(2023)Chen, Huang, Zhao, and Wang]{chen2023score}
Minshuo Chen, Kaixuan Huang, Tuo Zhao, and Mengdi Wang.
\newblock Score approximation, estimation and distribution recovery of
  diffusion models on low-dimensional data.
\newblock \emph{arXiv preprint arXiv:2302.07194}, 2023.

\bibitem[Chen et~al.(2022)Chen, Chewi, Li, Li, Salim, and
  Zhang]{chen2022sampling}
Sitan Chen, Sinho Chewi, Jerry Li, Yuanzhi Li, Adil Salim, and Anru~R Zhang.
\newblock Sampling is as easy as learning the score: theory for diffusion
  models with minimal data assumptions.
\newblock \emph{arXiv preprint arXiv:2209.11215}, 2022.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee, 2009.

\bibitem[Dhariwal and Nichol(2021)]{dhariwal2021diffusion}
Prafulla Dhariwal and Alexander Nichol.
\newblock Diffusion models beat gans on image synthesis.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 8780--8794, 2021.

\bibitem[Fan et~al.(2020)Fan, Wang, Xie, and Yang]{fan2020theoretical}
Jianqing Fan, Zhaoran Wang, Yuchen Xie, and Zhuoran Yang.
\newblock A theoretical analysis of deep q-learning.
\newblock In \emph{Learning for Dynamics and Control}, pages 486--489. PMLR,
  2020.

\bibitem[Gong et~al.(2019)Gong, Boddeti, and Jain]{gong2019intrinsic}
Sixue Gong, Vishnu~Naresh Boddeti, and Anil~K Jain.
\newblock On the intrinsic dimensionality of image representations.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 3987--3996, 2019.

\bibitem[Graikos et~al.(2022)Graikos, Malkin, Jojic, and
  Samaras]{graikos2022diffusion}
Alexandros Graikos, Nikolay Malkin, Nebojsa Jojic, and Dimitris Samaras.
\newblock Diffusion models as plug-and-play priors.
\newblock \emph{arXiv preprint arXiv:2206.09012}, 2022.

\bibitem[Gy{\"o}rfi et~al.(2002)Gy{\"o}rfi, K{\"o}hler, Krzy{\.z}ak, and
  Walk]{gyorfi2002distribution}
L{\'a}szl{\'o} Gy{\"o}rfi, Michael K{\"o}hler, Adam Krzy{\.z}ak, and Harro
  Walk.
\newblock \emph{A distribution-free theory of nonparametric regression},
  volume~1.
\newblock Springer, 2002.

\bibitem[Haussmann and Pardoux(1986)]{haussmann1986time}
Ulrich~G Haussmann and Etienne Pardoux.
\newblock Time reversal of diffusions.
\newblock \emph{The Annals of Probability}, pages 1188--1205, 1986.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem[Ho and Salimans(2022)]{ho2022classifier}
Jonathan Ho and Tim Salimans.
\newblock Classifier-free diffusion guidance.
\newblock \emph{arXiv preprint arXiv:2207.12598}, 2022.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 6840--6851, 2020.

\bibitem[Hyv{\"a}rinen and Dayan(2005)]{hyvarinen2005estimation}
Aapo Hyv{\"a}rinen and Peter Dayan.
\newblock Estimation of non-normalized statistical models by score matching.
\newblock \emph{Journal of Machine Learning Research}, 6\penalty0 (4), 2005.

\bibitem[Janner et~al.(2022)Janner, Du, Tenenbaum, and
  Levine]{janner2022diffuser}
Michael Janner, Yilun Du, Joshua Tenenbaum, and Sergey Levine.
\newblock Planning with diffusion for flexible behavior synthesis.
\newblock In \emph{International Conference on Machine Learning}, 2022.

\bibitem[Jin et~al.(2021)Jin, Yang, and Wang]{jin2021pessimism}
Ying Jin, Zhuoran Yang, and Zhaoran Wang.
\newblock Is pessimism provably efficient for offline rl?
\newblock In \emph{International Conference on Machine Learning}, pages
  5084--5096. PMLR, 2021.

\bibitem[Kingma and Dhariwal(2018)]{kingma2018glow}
Durk~P Kingma and Prafulla Dhariwal.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Lee et~al.(2023{\natexlab{a}})Lee, Lu, and Tan]{lee2023convergence}
Holden Lee, Jianfeng Lu, and Yixin Tan.
\newblock Convergence of score-based generative modeling for general data
  distributions.
\newblock In \emph{International Conference on Algorithmic Learning Theory},
  pages 946--985. PMLR, 2023{\natexlab{a}}.

\bibitem[Lee et~al.(2023{\natexlab{b}})Lee, Kim, and Kim]{LeeProtein}
Jin~Sub Lee, Jisun Kim, and Philip~M. Kim.
\newblock Proteinsgm: Score-based generative modeling for de novo protein
  design.
\newblock \emph{bioRxiv}, 2023{\natexlab{b}}.
\newblock \doi{10.1101/2022.07.13.499967}.
\newblock URL
  \url{https://www.biorxiv.org/content/early/2023/02/04/2022.07.13.499967}.

\bibitem[Li et~al.(2022)Li, Thickstun, Gulrajani, Liang, and
  Hashimoto]{li2022diffusion}
Xiang Li, John Thickstun, Ishaan Gulrajani, Percy~S Liang, and Tatsunori~B
  Hashimoto.
\newblock Diffusion-lm improves controllable text generation.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 4328--4343, 2022.

\bibitem[Liang et~al.(2023)Liang, Mu, Ding, Ni, Tomizuka, and
  Luo]{liang2023adaptdiffuser}
Zhixuan Liang, Yao Mu, Mingyu Ding, Fei Ni, Masayoshi Tomizuka, and Ping Luo.
\newblock Adaptdiffuser: Diffusion models as adaptive self-evolving planners.
\newblock \emph{arXiv preprint arXiv:2302.01877}, 2023.

\bibitem[Liu et~al.(2018)Liu, Li, Tang, and Zhou]{liu2018breaking}
Qiang Liu, Lihong Li, Ziyang Tang, and Dengyong Zhou.
\newblock Breaking the curse of horizon: Infinite-horizon off-policy
  estimation.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Munos and Szepesv{\'a}ri(2008)]{munos2008finite}
R{\'e}mi Munos and Csaba Szepesv{\'a}ri.
\newblock Finite-time bounds for fitted value iteration.
\newblock \emph{Journal of Machine Learning Research}, 9\penalty0 (5), 2008.

\bibitem[Nakada and Imaizumi(2020)]{nakada2020adaptive}
Ryumei Nakada and Masaaki Imaizumi.
\newblock Adaptive approximation and generalization of deep neural network with
  intrinsic dimensionality.
\newblock \emph{The Journal of Machine Learning Research}, 21\penalty0
  (1):\penalty0 7018--7055, 2020.

\bibitem[Nguyen-Tang et~al.(2021)Nguyen-Tang, Gupta, Nguyen, and
  Venkatesh]{nguyen2021offline}
Thanh Nguyen-Tang, Sunil Gupta, A~Tuan Nguyen, and Svetha Venkatesh.
\newblock Offline neural contextual bandits: Pessimism, optimization and
  generalization.
\newblock \emph{arXiv preprint arXiv:2111.13807}, 2021.

\bibitem[Nichol et~al.(2021)Nichol, Dhariwal, Ramesh, Shyam, Mishkin, McGrew,
  Sutskever, and Chen]{nichol2021glide}
Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin,
  Bob McGrew, Ilya Sutskever, and Mark Chen.
\newblock Glide: Towards photorealistic image generation and editing with
  text-guided diffusion models.
\newblock \emph{arXiv preprint arXiv:2112.10741}, 2021.

\bibitem[Oko et~al.(2023)Oko, Akiyama, and Suzuki]{oko2023diffusion}
Kazusato Oko, Shunta Akiyama, and Taiji Suzuki.
\newblock Diffusion models are minimax optimal distribution estimators.
\newblock In \emph{ICLR 2023 Workshop on Mathematical and Empirical
  Understanding of Foundation Models}, 2023.
\newblock URL \url{https://openreview.net/forum?id=6961CeTSFA}.

\bibitem[Ouyang et~al.(2022)Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin,
  Zhang, Agarwal, Slama, Ray, et~al.]{ouyang2022training}
Long Ouyang, Jeffrey Wu, Xu~Jiang, Diogo Almeida, Carroll Wainwright, Pamela
  Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et~al.
\newblock Training language models to follow instructions with human feedback.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 27730--27744, 2022.

\bibitem[Pearce et~al.(2023)Pearce, Rashid, Kanervisto, Bignell, Sun,
  Georgescu, Macua, Tan, Momennejad, Hofmann, and Devlin]{pearce2023imitating}
Tim Pearce, Tabish Rashid, Anssi Kanervisto, Dave Bignell, Mingfei Sun, Raluca
  Georgescu, Sergio~Valcarcel Macua, Shan~Zheng Tan, Ida Momennejad, Katja
  Hofmann, and Sam Devlin.
\newblock Imitating human behaviour with diffusion models.
\newblock In \emph{The Eleventh International Conference on Learning
  Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=Pv1GPQzRrC8}.

\bibitem[Pope et~al.(2021)Pope, Zhu, Abdelkader, Goldblum, and
  Goldstein]{pope2021intrinsic}
Phillip Pope, Chen Zhu, Ahmed Abdelkader, Micah Goldblum, and Tom Goldstein.
\newblock The intrinsic dimension of images and its impact on learning.
\newblock \emph{arXiv preprint arXiv:2104.08894}, 2021.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and
  Chen]{ramesh2022hierarchical}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock \emph{arXiv preprint arXiv:2204.06125}, 2022.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and
  Ommer]{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn
  Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 10684--10695, 2022.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and
  Brox]{ronneberger2015u}
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In \emph{Medical Image Computing and Computer-Assisted
  Intervention--MICCAI 2015: 18th International Conference, Munich, Germany,
  October 5-9, 2015, Proceedings, Part III 18}, pages 234--241. Springer, 2015.

\bibitem[Schick et~al.(2021)Schick, Udupa, and Schütze]{schick2020self}
Timo Schick, Sahana Udupa, and Hinrich Schütze.
\newblock Self-diagnosis and self-debiasing: A proposal for reducing
  corpus-based bias in nlp.
\newblock \emph{Computing Research Repository}, arXiv:2103.00453, 2021.
\newblock URL \url{http://arxiv.org/abs/2103.00453}.

\bibitem[Schuhmann et~al.(2022)Schuhmann, Beaumont, Vencu, Gordon, Wightman,
  Cherti, Coombes, Katta, Mullis, Wortsman, et~al.]{schuhmann2022laion}
Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross
  Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell
  Wortsman, et~al.
\newblock Laion-5b: An open large-scale dataset for training next generation
  image-text models.
\newblock \emph{arXiv preprint arXiv:2210.08402}, 2022.

\bibitem[Song et~al.(2021)Song, Meng, and Ermon]{song2020denoising}
Jiaming Song, Chenlin Meng, and Stefano Ermon.
\newblock Denoising diffusion implicit models.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=St1giarCHLP}.

\bibitem[Song and Ermon(2020)]{song2020improved}
Yang Song and Stefano Ermon.
\newblock Improved techniques for training score-based generative models.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 12438--12448, 2020.

\bibitem[Song et~al.(2020{\natexlab{a}})Song, Garg, Shi, and
  Ermon]{song2020sliced}
Yang Song, Sahaj Garg, Jiaxin Shi, and Stefano Ermon.
\newblock Sliced score matching: A scalable approach to density and score
  estimation.
\newblock In \emph{Uncertainty in Artificial Intelligence}, pages 574--584.
  PMLR, 2020{\natexlab{a}}.

\bibitem[Song et~al.(2020{\natexlab{b}})Song, Sohl-Dickstein, Kingma, Kumar,
  Ermon, and Poole]{song2020score}
Yang Song, Jascha Sohl-Dickstein, Diederik~P Kingma, Abhishek Kumar, Stefano
  Ermon, and Ben Poole.
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock \emph{arXiv preprint arXiv:2011.13456}, 2020{\natexlab{b}}.

\bibitem[Song et~al.(2023)Song, Dhariwal, Chen, and
  Sutskever]{song2023consistency}
Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya Sutskever.
\newblock Consistency models.
\newblock \emph{arXiv preprint arXiv:2303.01469}, 2023.

\bibitem[Tenenbaum et~al.(2000)Tenenbaum, Silva, and
  Langford]{tenenbaum2000global}
Joshua~B Tenenbaum, Vin~de Silva, and John~C Langford.
\newblock A global geometric framework for nonlinear dimensionality reduction.
\newblock \emph{science}, 290\penalty0 (5500):\penalty0 2319--2323, 2000.

\bibitem[Tsybakov(2008)]{tsybakov2008intro}
Alexandre~B. Tsybakov.
\newblock \emph{Introduction to Nonparametric Estimation}.
\newblock Springer Publishing Company, Incorporated, 1st edition, 2008.
\newblock ISBN 0387790519.

\bibitem[Vahdat et~al.(2021)Vahdat, Kreis, and Kautz]{vahdat2021score}
Arash Vahdat, Karsten Kreis, and Jan Kautz.
\newblock Score-based generative modeling in latent space.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 11287--11302, 2021.

\bibitem[Vershynin(2018)]{vershynin2018high}
Roman Vershynin.
\newblock \emph{High-dimensional probability: An introduction with applications
  in data science}, volume~47.
\newblock Cambridge university press, 2018.

\bibitem[Vincent(2011)]{vincent2011connection}
Pascal Vincent.
\newblock A connection between score matching and denoising autoencoders.
\newblock \emph{Neural computation}, 23\penalty0 (7):\penalty0 1661--1674,
  2011.

\bibitem[Wainwright(2019)]{wainwright2019high}
Martin~J Wainwright.
\newblock \emph{High-dimensional statistics: A non-asymptotic viewpoint},
  volume~48.
\newblock Cambridge university press, 2019.

\bibitem[Zhang and Agrawala(2023)]{zhang2023adding}
Lvmin Zhang and Maneesh Agrawala.
\newblock Adding conditional control to text-to-image diffusion models.
\newblock \emph{arXiv preprint arXiv:2302.05543}, 2023.

\end{thebibliography}
