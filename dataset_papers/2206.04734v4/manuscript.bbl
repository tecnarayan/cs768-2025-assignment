\begin{thebibliography}{10}

\bibitem{acerbi2018variational}
Luigi Acerbi.
\newblock Variational bayesian monte carlo.
\newblock {\em Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem{acerbi2020variational}
Luigi Acerbi.
\newblock Variational bayesian monte carlo with noisy likelihoods.
\newblock {\em Advances in Neural Information Processing Systems},
  33:8211--8222, 2020.

\bibitem{aitio2021predicting}
A.~Aitio and D.~A. Howey.
\newblock Predicting battery end of life from solar off-grid system field data
  using machine learning.
\newblock {\em Joule}, 5(12):3204--3220, 2021.

\bibitem{aitio2020bayesian}
A.~Aitio, S.~G. Marquis, P.~Ascencio, and D.~A. Howey.
\newblock Bayesian parameter estimation applied to the {L}i-ion battery single
  particle model with electrolyte dynamics.
\newblock {\em IFAC-PapersOnLine}, 53(2):12497--12504, 2020.

\bibitem{bach2017on}
F.~Bach.
\newblock On the equivalence between kernel quadrature rules and random feature
  expansions.
\newblock {\em Journal of Machine Learning Research}, 18:714, 2017.

\bibitem{bach2012on}
F.~Bach, S.~Lacoste-Julien, and G.~Obozinski.
\newblock On the equivalence between herding and conditional gradient
  algorithms.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2012.

\bibitem{balandat2020botorch}
M.~Balandat, B.~Karrer, D.~Jiang, S.~Daulton, B.~Letham, A.~G. Wilson, and
  E.~Bakshy.
\newblock Bo{T}orch: a framework for efficient {M}onte-{C}arlo {B}ayesian
  optimization.
\newblock {\em International Conference on Neural Information Processing
  Systems (NeurIPS)}, 33:21524--21538, 2020.

\bibitem{belhadji2019kernel}
A.~Belhadji, R.~Bardenet, and P.~Chainais.
\newblock Kernel quadrature with {DPP}s.
\newblock In {\em International Conference on Neural Information Processing
  Systems (NeurIPS)}, 2019.
\newblock URL:
  \url{https://proceedings.neurips.cc/paper/2019/file/7012ef0335aa2adbab58bd6d0702ba41-Paper.pdf}.

\bibitem{bennett1976efficient}
C.~H. Bennett.
\newblock {Efficient estimation of free energy differences from {M}onte {C}arlo
  data}.
\newblock {\em Journal of Computational Physics}, 22:245 -- 268, 1976.

\bibitem{berahas2016multi}
A.~S. Berahas, J.~Nocedal, and M.~Tak{\'a}c.
\newblock A multi-batch l-bfgs method for machine learning.
\newblock {\em International Conference on Neural Information Processing
  Systems (NeurIPS)}, 29, 2016.

\bibitem{bizeray2019identifiability}
A.~M. Bizeray, J.~H. Kim, S.~R. Duncan, and D.~A. Howey.
\newblock Identifiability and parameter estimation of the single particle
  lithium-ion battery model.
\newblock {\em IEEE Transactions on Control Systems Technology},
  27(5):1862--1877, 2019.
\newblock URL: \url{https://doi.org/10.1109/TCST.2018.2838097}.

\bibitem{bizeray2016spectral}
A.~M. Bizeray, J.~Reniers, and D.~A. Howey.
\newblock Spectral {L}i-ion {SPM}.
\newblock \url{"https://doi.org/10.5281/zenodo.212178"}, 2016.

\bibitem{bizeray2015lithium}
A.~M. Bizeray, S.~Zhao, S.~R. Duncan, and D.~A. Howey.
\newblock Lithium-ion battery thermal-electrochemical model-based state
  estimation using orthogonal collocation and a modified extended {K}alman
  filter.
\newblock {\em Journal of Power Sources}, 296:400--412, 2015.

\bibitem{briol2015frank}
F.-X. Briol, C.~J. Oates, M.~Girolami, and M.~A. Osborne.
\newblock Frank-{W}olfe {B}ayesian quadrature: Probabilistic integration with
  theoretical guarantees.
\newblock In {\em International Conference on Neural Information Processing
  Systems (NeurIPS)}, 2015.
\newblock URL:
  \url{https://proceedings.neurips.cc/paper/2015/file/ba3866600c3540f67c1e9575e213be0a-Paper.pdf}.

\bibitem{briol2019probabilistic}
F.-X. Briol, C.~J. Oates, M.~Girolami, M.~A. Osborne, and D.~Sejdinovic.
\newblock Probabilistic integration: a role in statistical computation?
\newblock {\em Statistical Science}, 34(1):1--22, 2019.

\bibitem{buchner2016statistical}
J.~Buchner.
\newblock A statistical test for nested sampling algorithms.
\newblock {\em Statistics and Computing}, 26(1):383--392, 2016.

\bibitem{buchner2019collaborative}
J.~Buchner.
\newblock Collaborative nested sampling: Big data versus complex physical
  models.
\newblock {\em Publications of the Astronomical Society of the Pacific},
  131(1004):108005, 2019.

\bibitem{buchner2021nested}
J.~Buchner.
\newblock Nested sampling methods.
\newblock {\em arXiv preprint arXiv:2101.09675}, 2021.

\bibitem{buchner2021ultranest}
J.~Buchner.
\newblock Ultra{N}est--a robust, general purpose {B}ayesian inference engine.
\newblock {\em arXiv preprint arXiv:2101.09604}, 2021.

\bibitem{byrd1995limited}
R.~H. Byrd, P.~Lu, J.~Nocedal, and C.~Zhu.
\newblock A limited memory algorithm for bound constrained optimization.
\newblock {\em SIAM Journal on scientific computing}, 16(5):1190--1208, 1995.

\bibitem{campbell2019sparse}
T.~Campbell and B.~Beronov.
\newblock Sparse variational inference: {B}ayesian coresets from scratch.
\newblock {\em International Conference on Neural Information Processing
  Systems (NeurIPS)}, 32, 2019.

\bibitem{campbell2019automated}
T.~Campbell and T.~Broderick.
\newblock Automated scalable {B}ayesian inference via {H}ilbert coresets.
\newblock {\em The Journal of Machine Learning Research}, 20(1):551--588, 2019.

\bibitem{chai2019automated}
H.~Chai, J.~F. Ton, M.~A. Osborne, and R.~Garnett.
\newblock Automated model selection with {B}ayesian quadrature.
\newblock In {\em International Conference on Machine Learning (ICML)},
  volume~97, pages 931--940, 2019.
\newblock URL: \url{https://proceedings.mlr.press/v97/chai19a.html}.

\bibitem{Chai2016improving}
H.~R. Chai and R.~Garnett.
\newblock Improving quadrature for constrained integrands.
\newblock In {\em In IEEE 16th International Conference on Data Mining (ICDM)},
  page 1107, 2016.
\newblock URL: \url{https://doi.org/10.1109/ICDM.2016.0144}.

\bibitem{chen2010super}
Y.~Chen, M.~Welling, and A.~Smola.
\newblock Super-samples from kernel herding.
\newblock In {\em International Conference on Uncertainty in Artificial
  Intelligence (UAI)}, 2010.

\bibitem{cosentino2020randomized}
F.~Cosentino, H.~Oberhauser, and A.~Abate.
\newblock A randomized algorithm to reduce the support of discrete measures.
\newblock {\em International Conference on Neural Information Processing
  Systems (NeurIPS)}, 33:15100--15110, 2020.

\bibitem{cranmer2020frontier}
K.~Cranmer, J.~Brehmer, and G.~Louppe.
\newblock The frontier of simulation-based inference.
\newblock {\em Proceedings of the National Academy of Sciences},
  117(48):30055--30062, 2020.

\bibitem{deisenroth2009gaussian}
M.~P. Deisenroth, C.~E. Rasmussen, and J.~Peters.
\newblock Gaussian process dynamic programming.
\newblock {\em Neurocomputing}, 72(7-9):1508--1524, 2009.

\bibitem{didelot2011likelihood}
X.~Didelot, R.~G. Everitt, A.~M. Johansen, and D.~J. Lawson.
\newblock Likelihood-free estimation of model evidence.
\newblock {\em Bayesian analysis}, 6(1):49--76, 2011.

\bibitem{evensen1994sequential}
G.~Evensen.
\newblock Sequential data assimilation with a nonlinear quasi-geostrophic model
  using {M}onte {C}arlo methods to forecast error statistics.
\newblock {\em Journal of Geophysical Research: Oceans}, 99(C5):10143--10162,
  1994.

\bibitem{fas12}
Gregory~E. Fasshauer and Michael~J. McCourt.
\newblock Stable evaluation of {G}aussian radial basis function interpolants.
\newblock {\em SIAM Journal on Scientific Computing}, 34(2):A737--A762, 2012.
\newblock URL: \url{https://doi.org/10.1137/110824784}.

\bibitem{feroz2009multinest}
F.~Feroz, M.~P. Hobson, and M.~Bridges.
\newblock Multi{N}est: an efficient and robust {B}ayesian inference tool for
  cosmology and particle physics.
\newblock {\em Monthly Notices of the Royal Astronomical Society},
  398(4):1601--1614, 2009.

\bibitem{frohlich2021bayesian}
C.~Fröhlich, A.~Gessner, P.~Hennig, B.~Schölkopf, and G.~Arvanitidis.
\newblock Bayesian quadrature on {R}iemannian data manifolds.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2021.
\newblock URL: \url{https://icml.cc/virtual/2021/poster/9655}.

\bibitem{gardner2018gpytorch}
J.~Gardner, G.~Pleiss, K.~Q. Weinberger, D.~Bindel, and A.~G. Wilson.
\newblock G{P}y{T}orch: {B}lackbox matrix-matrix {G}aussian process inference
  with {GPU} acceleration.
\newblock {\em International Conference on Neural Information Processing
  Systems (NeurIPS)}, 31, 2018.

\bibitem{Genz1984testing}
A.~Genz.
\newblock Testing multidimensional integration routines.
\newblock In {\em In Proc. of international conference on Tools, methods and
  languages for scientific and engineering computation}, pages 81--94, 1984.

\bibitem{gsbert2003weighted}
F.~J.~G. Gisbert.
\newblock {Weighted samples, kernel density estimators and convergence}.
\newblock {\em Empirical Economics}, 28:335–351, 2003.
\newblock URL: \url{https://doi.org/10.1007/s001810200134}.

\bibitem{gpy2012gpy}
{GPy}.
\newblock {GPy}: A gaussian process framework in python.
\newblock \url{http://github.com/SheffieldML/GPy}, since 2012.

\bibitem{graf2013efficient}
D.M. Gr{\"a}f.
\newblock {\em Efficient algorithms for the computation of optimal quadrature
  points on {R}iemannian manifolds}.
\newblock PhD thesis, Chemnitz University of Technology, 2013.

\bibitem{greenberg2019automatic}
D.~Greenberg, M.~Nonnenmacher, and J.~Macke.
\newblock Automatic posterior transformation for likelihood-free inference.
\newblock In {\em International Conference on Machine Learning (ICML)}, pages
  2404--2414, 2019.

\bibitem{gretton2006kernel}
Arthur Gretton, Karsten Borgwardt, Malte Rasch, Bernhard Sch{\"o}lkopf, and
  Alex Smola.
\newblock A kernel method for the two-sample-problem.
\newblock {\em Advances in neural information processing systems}, 19, 2006.

\bibitem{gunter2014sampling}
T.~Gunter, M.~A. Osborne, R.~Garnett, P.~Hennig, and S.~J. Roberts.
\newblock Sampling for inference in probabilistic models with fast {B}ayesian
  quadrature.
\newblock In {\em International Conference on Neural Information Processing
  Systems (NeurIPS)}, 2014.
\newblock URL:
  \url{https://proceedings.neurips.cc/paper/2014/file/e94f63f579e05cb49c05c2d050ead9c0-Paper.pdf}.

\bibitem{gurobi2022gurobi}
{Gurobi Optimization, LLC}.
\newblock {Gurobi Optimizer Reference Manual}, 2022.
\newblock URL: \url{https://www.gurobi.com}.

\bibitem{gutmann2016bayesian}
M.~U. Gutmann, J.~Corander, et~al.
\newblock Bayesian optimization for likelihood-free inference of
  simulator-based statistical models.
\newblock {\em Journal of Machine Learning Research}, 2016.

\bibitem{hal11}
N.~Halko, P.~G. Martinsson, and J.~A. Tropp.
\newblock Finding structure with randomness: {P}robabilistic algorithms for
  constructing approximate matrix decompositions.
\newblock {\em SIAM review}, 53(2):217--288, 2011.

\bibitem{hamid2021marginalising}
S.~Hamid, S.~Schulze, M.~A. Osborne, and S.~J. Roberts.
\newblock Marginalising over stationary kernels with {B}ayesian quadrature.
\newblock {\em International Conference on Artificial Intelligence and
  Statistics (AISTATS)}, 2021.
\newblock URL: \url{https://proceedings.mlr.press/v151/hamid22a/hamid22a.pdf}.

\bibitem{harris2020array}
C.~R. Harris, K.~J. Millman, S.~J. {van der Walt}, R.~Gommers, P.~Virtanen,
  D.~Cournapeau, E.~Wieser, J.~Taylor, S.~Berg, N.~J. Smith, R.~Kern, M.~Picus,
  S.~Hoyer, M.~H. Kerkwijk, M.~Brett, A.~Haldane, J.~F. R{\'{i}}o, M.~Wiebe,
  P.~Peterson, P.~G{\'{e}}rard-Marchant, K.~Sheppard, T.~Reddy, W.~Weckesser,
  H.~Abbasi, C.~Gohlke, and T.~E. Oliphant.
\newblock Array programming with {NumPy}.
\newblock {\em Nature}, 585(7825):357--362, 2020.
\newblock \href {https://doi.org/10.1038/s41586-020-2649-2}
  {\path{doi:10.1038/s41586-020-2649-2}}.

\bibitem{hasting1970monte}
W.~K. Hastings.
\newblock {Monte {C}arlo sampling methods using {M}arkov chains and their
  applications}.
\newblock {\em Biometrika}, 57(1):97–109, 1970.
\newblock URL: \url{https://doi:10.1093/ biomet/57.1.97}.

\bibitem{hayakawa2021positively}
S.~Hayakawa, H.~Oberhauser, and T.~Lyons.
\newblock Positively weighted kernel quadrature via subsampling.
\newblock arXiv preprint, 2021.
\newblock URL: \url{https://doi.org/10.48550/arXiv.2107.09597}.

\bibitem{hennig2015probabilistic}
P.~Hennig, M.~A. Osborne, and M.~Girolami.
\newblock Probabilistic numerics and uncertainty in computations.
\newblock {\em Proceedings of the Royal Society A: Mathematical, Physical and
  Engineering Sciences}, 471(2179):20150142, 2015.

\bibitem{higson2019dynamic}
E.~Higson, W.~Handley, M.~Hobson, and A.~Lasenby.
\newblock Dynamic nested sampling: an improved algorithm for parameter
  estimation and evidence calculation.
\newblock {\em Stat. Comput.}, 29:891–913, 2019.
\newblock URL: \url{https://doi.org/10.1007/s11222-018-9844-0}.

\bibitem{hoffman2014the}
M.~D. Hoffman and A.~Gelman.
\newblock {The {N}o-{U}-{T}urn sampler: adaptively setting path lengths in
  {H}amiltonian {M}onte {C}arlo}.
\newblock {\em Journal of Machine Learning Research}, 15(1):1593–1623, 2014.

\bibitem{huszar2012optimally}
F.~Husz\'{a}r and D.~Duvenaud.
\newblock Optimally-weighted herding is {B}ayesian quadrature.
\newblock In {\em International Conference on Uncertainty in Artificial
  Intelligence (UAI)}, 2012.

\bibitem{hutter2014efficient}
F.~Hutter, H.~Hoos, and K.~Leyton-Brown.
\newblock An efficient approach for assessing hyperparameter importance.
\newblock In {\em International Conference on Machine Learning (ICML)}, pages
  754--762, 2014.

\bibitem{jones2001taxonomy}
D.~R. Jones.
\newblock {A taxonomy of global optimization methods based on response
  surfaces}.
\newblock {\em Journal of global optimization}, 21:345–383, 2001.

\bibitem{kan19}
M.~Kanagawa and P.~Hennig.
\newblock Convergence guarantees for adaptive {B}ayesian quadrature methods.
\newblock {\em Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem{karvonen2021integration}
T.~Karvonen, C.~Oates, and M.~Girolami.
\newblock Integration in reproducing kernel hilbert spaces of gaussian kernels.
\newblock {\em Mathematics of Computation}, 90(331):2209--2233, 2021.

\bibitem{kathuria2016batched}
T.~Kathuria, A.~Deshpande, and P.~Kohli.
\newblock Batched {G}aussian process bandit optimization via determinantal
  point processes.
\newblock {\em Advances in Neural Information Processing Systems}, 29, 2016.

\bibitem{kim1999phase}
S.~G. Kim, W.~T. Kim, and T.~Suzuki.
\newblock Phase-field model for binary alloys.
\newblock {\em Physical review e}, 60(6):7186, 1999.

\bibitem{kitagawa1993monte}
G.~Kitagawa.
\newblock A {M}onte {C}arlo filtering and smoothing method for non-{G}aussian
  nonlinear state space models.
\newblock In {\em Proceedings of the 2nd U.S.-Japan Joint Seminar on
  Statistical Time Series Analysis}, page 110, 1993.
\newblock URL: \url{https://www.ism.ac.jp/~kitagawa/1993_US-Japan.pdf}.

\bibitem{koyama2019computational}
T.~Koyama.
\newblock {\em Computational Engineering for Materials Design, Computational
  Microstructures, New and Expanded Edition: Microstructure Formation Analysis
  by the Phase-Field Method}.
\newblock Uchida Rokakuho, Tokyo, Japan, 2019.

\bibitem{kum12}
S.~Kumar, M.~Mohri, and A.~Talwalkar.
\newblock Sampling methods for the {N}ystr{\"o}m method.
\newblock {\em The Journal of Machine Learning Research}, 13(1):981--1006,
  2012.

\bibitem{Kuo2017multivariate}
F.~Kuo, I.~Sloan, and H.~Wo{\'z}niakowski.
\newblock Multivariate integration for analytic functions with gaussian
  kernels.
\newblock {\em Mathematics of Computation}, 86(304):829--853, 2017.

\bibitem{kuo2012gauss}
F.~Y. Kuo and H.~Wo{\'z}niakowski.
\newblock Gauss-{H}ermite quadratures for functions from {H}ilbert spaces with
  {G}aussian reproducing kernels.
\newblock {\em BIT Numerical Mathematics}, 52(2):425--436, 2012.

\bibitem{lawrence2003gaussian}
N.~Lawrence.
\newblock Gaussian process latent variable models for visualisation of high
  dimensional data.
\newblock {\em Advances in neural information processing systems}, 16, 2003.

\bibitem{lit12}
C.~Litterer and T.~Lyons.
\newblock High order recombination and an application to cubature on {W}iener
  space.
\newblock {\em The Annals of Applied Probability}, 22(4):1301--1327, 2012.

\bibitem{manousakas2020bayesian}
D.~Manousakas, Z.~Xu, C.~Mascolo, and T.~Campbell.
\newblock Bayesian pseudocoresets.
\newblock {\em International Conference on Neural Information Processing
  Systems (NeurIPS)}, 33:14950--14960, 2020.

\bibitem{marquis2019asymptotic}
S.~G. Marquis, V.~Sulzer, R.~Timms, C.~P. Please, and S.~J. Chapman.
\newblock An asymptotic derivation of a single particle model with electrolyte.
\newblock {\em Journal of the Electrochemical Society}, 166(15):A3693–A3706,
  2019.
\newblock URL: \url{https://doi.org/10.1149/2.0341915jes}.

\bibitem{matsuura2021adjoint}
Y.~Matsuura, Y.~Tsukada, and T.~Koyama.
\newblock Adjoint model for estimating material parameters based on
  microstructure evolution during spinodal decomposition.
\newblock {\em Physical Review Materials}, 5(11):113801, 2021.

\bibitem{metropolis1953equation}
N.~Metropolis, A.~W. Rosenbluth, M.~N. Rosenbluth, A.~H. Teller, and E.~Teller.
\newblock {Equation of state calculations by fast computing machines}.
\newblock {\em The journal of chemical physics}, 21(6):1087–1092, 1953.

\bibitem{mukherjee2006nested}
P.~Mukherjee, D.~Parkinson, and A.~R. Liddle.
\newblock A nested sampling algorithm for cosmological model selection.
\newblock {\em The Astrophysical Journal}, 638(2):L51, 2006.

\bibitem{neal2001annealed}
R.M. Neal.
\newblock {Annealed importance sampling}.
\newblock {\em Statistics and Computing}, 11(2):125–139, 2001.

\bibitem{oates2017control}
C.~J. Oates, M.~Girolami, and N.~Chopin.
\newblock Control functionals for {M}onte {C}arlo integration.
\newblock {\em Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 79(3):695--718, 2017.

\bibitem{oates2016controlled}
C.~J. Oates, T.~Papamarkou, and M.~Girolami.
\newblock The controlled thermodynamic integral for bayesian model evidence
  evaluation.
\newblock {\em Journal of the American Statistical Association},
  111(514):634--645, 2016.

\bibitem{ohagan1991bayes}
A.~O'Hagan.
\newblock Bayes-{H}ermite quadrature.
\newblock {\em Journal of Statistical Planning and Inference}, 29:245, 1991.
\newblock URL: \url{https://doi.org/10.1016/0378-3758(91)90002-V}.

\bibitem{ohagan1998bayesian}
A.~O'Hagan.
\newblock Bayesian quadrature with non-normal approximating functions.
\newblock {\em Statistics and Computing}, 8:365, 1998.
\newblock URL: \url{https://doi.org/10.1023/A:1008832824006}.

\bibitem{osborne2012active}
M.~A. Osborne, D.~Duvenaud, R.~Garnett, C.~Rasmussen, S.~Roberts, and
  Z.~Ghahramani.
\newblock Active learning of model evidence using {B}ayesian quadrature.
\newblock In {\em International Conference on Neural Information Processing
  Systems (NeurIPS)}, 2012.
\newblock URL:
  \url{https://proceedings.neurips.cc/paper/2012/file/6364d3f0f495b6ab9dcf8d3b5c6e0b01-Paper.pdf}.

\bibitem{pinsler2019bayesian}
R.~Pinsler, J.~Gordon, E.~Nalisnick, and J.~M. Hern{\'a}ndez-Lobato.
\newblock Bayesian batch active learning as sparse subset approximation.
\newblock {\em International Conference on Neural Information Processing
  Systems (NeurIPS)}, 32, 2019.

\bibitem{rasmussen2003bayesian}
C.~E. Rasmussen and Z.~Ghahramani.
\newblock Bayesian {M}onte {C}arlo.
\newblock In {\em International Conference on Neural Information Processing
  Systems (NeurIPS)}, 2003.
\newblock URL: \url{https://mlg.eng.cam.ac.uk/zoubin/papers/RasGha03.pdf}.

\bibitem{roberts2013gaussian}
S.~Roberts, M.~Osborne, M.~Ebden, S.~Reece, N.~Gibson, and S.~Aigrain.
\newblock Gaussian processes for time-series modelling.
\newblock {\em Phil. Trans. R. Soc. A.}, 371:20110550, 2013.

\bibitem{skilling2006nested}
J.~Skilling.
\newblock Nested sampling for general {B}ayesian computation.
\newblock {\em Bayesian Analysis}, 1(4):833 -- 859, 2006.
\newblock URL: \url{https://doi.org/10.1214/06-BA127}.

\bibitem{speagle2020dynesty}
J.~S. Speagle.
\newblock {dynesty: a dynamic nested sampling package for estimating {B}ayesian
  posteriors and evidences}.
\newblock {\em Monthly Notices of the Royal Astronomical Society},
  493(3):3132--3158, 2020.
\newblock URL: \url{https://doi.org/10.1093/mnras/staa278}.

\bibitem{sriperumbudur2010hilbert}
Bharath~K Sriperumbudur, Arthur Gretton, Kenji Fukumizu, Bernhard
  Sch{\"o}lkopf, and Gert~RG Lanckriet.
\newblock Hilbert space embeddings and metrics on probability measures.
\newblock {\em The Journal of Machine Learning Research}, 11:1517--1561, 2010.

\bibitem{surjanovic2022virtual}
S.~Surjanovic and D.~Bingham.
\newblock Virtual library of simulation experiments: Test functions and
  datasets.
\newblock Retrieved May 12, 2022, from \url{http://www.sfu.ca/~ssurjano}.

\bibitem{sarkka2012infinite}
S.~Särkkä and J.~Hartikainen.
\newblock Infinite-dimensional {K}alman filtering approach to spatio-temporal
  {G}aussian process regression.
\newblock In {\em Artificial Intelligence and Statistics}, pages 993--1001,
  2012.

\bibitem{tch15}
M.~Tchernychova.
\newblock {\em Carath{\'e}odory cubature measures}.
\newblock PhD thesis, University of Oxford, 2015.

\bibitem{virtanen2020scipy}
P.~Virtanen, R.~Gommers, T.~E. Oliphant, M.~Haberland, T.~Reddy, D.~Cournapeau,
  E.~Burovski, P.~Peterson, W.~Weckesser, J.~Bright, S.~J. {van der Walt},
  M.~Brett, J.~Wilson, K.~J. Millman, N.~Mayorov, A.~R.~J. Nelson, E.~Jones,
  R.~Kern, E.~Larson, C.~J. Carey, {\.I}.~Polat, Y.~Feng, E.~W. Moore,
  J.~{VanderPlas}, D.~Laxalde, J.~Perktold, R.~Cimrman, I.~Henriksen, E.~A.
  Quintero, C.~R. Harris, A.~M. Archibald, A.~H. Ribeiro, F.~Pedregosa, P.~{van
  Mulbregt}, and {SciPy 1.0 Contributors}.
\newblock {{SciPy} 1.0: Fundamental Algorithms for Scientific Computing in
  Python}.
\newblock {\em Nature Methods}, 17:261--272, 2020.
\newblock \href {https://doi.org/10.1038/s41592-019-0686-2}
  {\path{doi:10.1038/s41592-019-0686-2}}.

\bibitem{wagstaff2019bayesian}
E.~Wagstaff.
\newblock {B}ayesian quadrature library.
\newblock \url{https://github.com/OxfordML/bayesquad}, since 2019.

\bibitem{wagstaff2018batch}
E.~Wagstaff, S.~Hamid, and M.~A. Osborne.
\newblock Batch selection for parallelisation of {B}ayesian quadrature.
\newblock arXiv preprint, 2018.
\newblock URL: \url{https://doi.org/10.48550/arXiv.1812.01553}.

\bibitem{wahba1990spline}
G.~Wahba.
\newblock {\em Spline models for observational data}.
\newblock SIAM, 1990.

\bibitem{wilson2018maximizing}
J.~Wilson, F.~Hutter, and M.~Deisenroth.
\newblock Maximizing acquisition functions for {B}ayesian optimization.
\newblock {\em International Conference on Neural Information Processing
  Systems (NeurIPS)}, 31, 2018.

\end{thebibliography}
