@book{bebendorf2008hierarchical,
  title={Hierarchical matrices},
  author={Bebendorf, Mario},
  year={2008},
  publisher={Springer}
}

@article{chen2005condition,
  title={Condition numbers of {G}aussian random matrices},
  author={Chen, Zizhong and Dongarra, Jack J},
  journal={SIAM Journal on Matrix Analysis and Applications},
  volume={27},
  number={3},
  pages={603--620},
  year={2005},
  publisher={SIAM}
}

@inproceedings{cutajar2016preconditioning,
  title={Preconditioning kernel matrices},
  author={Cutajar, Kurt and Osborne, Michael and Cunningham, John and Filippone, Maurizio},
  booktitle={International conference on machine learning},
  pages={2529--2538},
  year={2016},
  organization={PMLR}
}


@InProceedings{pmlr-v139-kapoor21a,
  title = 	 {SKIing on Simplices: Kernel Interpolation on the Permutohedral Lattice for Scalable Gaussian Processes},
  author =       {Kapoor, Sanyam and Finzi, Marc and Wang, Ke Alexander and Wilson, Andrew Gordon Gordon},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {5279--5289},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/kapoor21a/kapoor21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/kapoor21a.html},
  abstract = 	 {State-of-the-art methods for scalable Gaussian processes use iterative algorithms, requiring fast matrix vector multiplies (MVMs) with the co-variance kernel. The Structured Kernel Interpolation (SKI) framework accelerates these MVMs by performing efficient MVMs on a grid and interpolating back to the original space. In this work, we develop a connection between SKI and the permutohedral lattice used for high-dimensional fast bilateral filtering. Using a sparse simplicial grid instead of a dense rectangular one, we can perform GP inference exponentially faster in the dimension than SKI. Our approach, Simplex-GP, enables scaling SKI to high dimensions, while maintaining strong predictive performance. We additionally provide a CUDA implementation of Simplex-GP, which enables significant GPU acceleration of MVM based inference.}
}


@article{boltz,
author = {Duchon, Philippe and Flajolet, Philippe and Louchard, Guy and Schaeffer, Gilles},
title = {Boltzmann Samplers for the Random Generation of Combinatorial Structures},
year = {2004},
issue_date = {July 2004},
publisher = {Cambridge University Press},
address = {USA},
volume = {13},
number = {4–5},
issn = {0963-5483},
doi = {10.1017/S0963548304006315},
journal = {Comb. Probab. Comput.},
month = {jul},
pages = {577–625},
numpages = {49}
}

@article{dai2020random,
  author    = {Dai Feng and
               Richard Baumgartner},
  title     = {Random Forest {(RF)} Kernel for Regression, Classification and Survival},
  journal   = {CoRR},
  volume    = {abs/2009.00089},
  year      = {2020},
  url       = {https://arxiv.org/abs/2009.00089},
  eprinttype = {arXiv},
  eprint    = {2009.00089},
  timestamp = {Fri, 18 Sep 2020 15:17:35 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2009-00089.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{Dua2019,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

@inproceedings{dutordoir2020sparse,
  title={Sparse {G}aussian processes with spherical harmonic features},
  author={Dutordoir, Vincent and Durrande, Nicolas and Hensman, James},
  booktitle={International Conference on Machine Learning},
  pages={2793--2802},
  year={2020},
  organization={PMLR}
}

@InProceedings{titsias09,
  title = 	 {Variational Learning of Inducing Variables in Sparse {G}aussian Processes},
  author = 	 {Titsias, Michalis},
  booktitle = 	 {Proceedings of the Twelth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {567--574},
  year = 	 {2009},
  editor = 	 {van Dyk, David and Welling, Max},
  volume = 	 {5},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Hilton Clearwater Beach Resort, Clearwater Beach, Florida USA},
  month = 	 {16--18 Apr},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v5/titsias09a/titsias09a.pdf},
  url = 	 {https://proceedings.mlr.press/v5/titsias09a.html},
}


@inproceedings{hensman13,
author = {Hensman, James and Fusi, Nicol\`{o} and Lawrence, Neil D.},
title = {{G}aussian Processes for Big Data},
year = {2013},
publisher = {AUAI Press},
address = {Arlington, Virginia, USA},
booktitle = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence},
pages = {282–290},
numpages = {9},
location = {Bellevue, WA},
series = {UAI'13}
}

@book{fletcher2013practical,
  title={Practical methods of optimization},
  author={Fletcher, Roger},
  year={2013},
  edition = {2nd},
  address = {New York},
  publisher={John Wiley \& Sons}
}

@article{hackbusch2004hierarchical,
  title={Hierarchical matrices based on a weak admissibility criterion},
  author={Hackbusch, Wolfgang and Khoromskij, Boris N and Kriemann, Ronald},
  journal={Computing},
  volume={73},
  number={3},
  pages={207--243},
  year={2004},
  publisher={Springer}
}

@article{hackbusch1999sparse,
  title={A sparse matrix arithmetic based on $\mathcal{H}$-matrices. {P}art {I}: Introduction to $\mathcal{H}$-matrices},
  author={Hackbusch, Wolfgang},
  journal={Computing},
  volume={62},
  number={2},
  pages={89--108},
  year={1999},
  publisher={Springer}
}

@inproceedings{hartikainen2010kalman,
  title={Kalman filtering and smoothing solutions to temporal {G}aussian process regression models},
  author={Hartikainen, Jouni and S{\"a}rkk{\"a}, Simo},
  booktitle={2010 IEEE international workshop on machine learning for signal processing},
  pages={379--384},
  year={2010},
  organization={IEEE}
}

@article{kalman1960new,
  title={A New Approach to Linear Filtering and Prediction Problems},
  author={Kalman, RE},
  journal={Journal of Basic Engineering},
  volume={83},
  number={1},
  pages={95--108},
  year={1960}
}

@article{lazaro2010sparse,
  title={Sparse spectrum {G}aussian process regression},
  author={L{\'a}zaro-Gredilla, Miguel and Quinonero-Candela, Joaquin and Rasmussen, Carl Edward and Figueiras-Vidal, An{\'\i}bal R},
  journal={The Journal of Machine Learning Research},
  volume={11},
  pages={1865--1881},
  year={2010},
  publisher={JMLR. org}
}

@InProceedings{ma2020,
  title = 	 {Additive Tree-Structured Covariance Function for Conditional Parameter Spaces in {B}ayesian Optimization},
  author =       {Ma, Xingchen and Blaschko, Matthew},
  booktitle = 	 {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  pages = 	 {1015--1025},
  year = 	 {2020},
  editor = 	 {Chiappa, Silvia and Calandra, Roberto},
  volume = 	 {108},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {26--28 Aug},
  publisher =    {PMLR},
}

@INPROCEEDINGS{levesque2017,  author={Lévesque, Julien-Charles and Durand, Audrey and Gagné, Christian and Sabourin, Robert},  booktitle={2017 International Joint Conference on Neural Networks (IJCNN)},   title={{B}ayesian optimization for conditional hyperparameter spaces},   year={2017},  volume={},  number={},  pages={286-293}}

@article{poggio2019double,
  title={Double descent in the condition number},
  author={Poggio, Tomaso and Kur, Gil and Banburski, Andrzej},
  journal={arXiv preprint arXiv:1912.06190},
  year={2019}
}

@article{quinonero2005unifying,
  title={A unifying view of sparse approximate {G}aussian process regression},
  author={Quinonero-Candela, Joaquin and Rasmussen, Carl Edward},
  journal={The Journal of Machine Learning Research},
  volume={6},
  pages={1939--1959},
  year={2005},
  publisher={JMLR.org}
}

@inproceedings{titsias2009variational,
  title={Variational learning of inducing variables in sparse {G}aussian processes},
  author={Titsias, Michalis},
  booktitle={Artificial intelligence and statistics},
  pages={567--574},
  year={2009},
  organization={PMLR}
}

@incollection{pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@inproceedings{snelson2005,
 author = {Snelson, Edward and Ghahramani, Zoubin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Y. Weiss and B. Sch\"{o}lkopf and J. Platt},
 pages = {},
 publisher = {MIT Press},
 title = {Sparse {G}aussian Processes using Pseudo-inputs},
 volume = {18},
 year = {2005}
}



@article{wang2019exact,
  title={Exact {G}aussian processes on a million data points},
  author={Wang, Ke and Pleiss, Geoff and Gardner, Jacob and Tyree, Stephen and Weinberger, Kilian Q and Wilson, Andrew Gordon},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{gardner2018gpytorch,
  title={Gpytorch: Blackbox matrix-matrix {G}aussian process inference with gpu acceleration},
  author={Gardner, Jacob and Pleiss, Geoff and Weinberger, Kilian Q and Bindel, David and Wilson, Andrew G},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@incollection{venables1999tree,
  title={Tree-based methods},
  author={Venables, William N and Ripley, Brian D},
  booktitle={Modern applied statistics with S-Plus},
  pages={303--327},
  year={1999},
  publisher={Springer}
}

@article{wild2021connections,
  title={Connections and Equivalences between the {N}ystr\"{o}m Method and Sparse Variational {G}aussian Processes},
  author={Wild, Veit and Kanagawa, Motonobu and Sejdinovic, Dino},
  journal={arXiv preprint arXiv:2106.01121},
  year={2021}
}

@book{williams2006gaussian,
  title={{G}aussian processes for machine learning},
  author={Williams, Christopher K and Rasmussen, Carl Edward},
  volume={2},
  number={3},
  year={2006},
  publisher={MIT press Cambridge, MA}
}

@inproceedings{williams2000using,
 author = {Williams, Christopher and Seeger, Matthias},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {T. Leen and T. Dietterich and V. Tresp},
 pages = {},
 publisher = {MIT Press},
 title = {Using the {N}ystr\"{o}m Method to Speed Up Kernel Machines},
 url = {https://proceedings.neurips.cc/paper/2000/file/19de10adbaa1b2ee13f77f679fa1483a-Paper.pdf},
 volume = {13},
 year = {2000}
}

@inproceedings{wilson2015kernel,
  title={Kernel interpolation for scalable structured Gaussian processes (KISS-GP)},
  author={Wilson, Andrew and Nickisch, Hannes},
  booktitle={International conference on machine learning},
  pages={1775--1784},
  year={2015},
  organization={PMLR}
}

@inproceedings{zhang2005time,
  title={Time-series {G}aussian process regression based on {T}oeplitz computation of ${O}(N^2)$ operations and ${O}(N)$-level storage},
  author={Zhang, Yunong and Leithead, William E and Leith, Douglas J},
  booktitle={Proceedings of the 44th IEEE Conference on Decision and Control},
  pages={3711--3716},
  year={2005},
  organization={IEEE}
}
