\begin{thebibliography}{35}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ajalloeian \& Stich(2020)Ajalloeian and Stich]{ajalloeian2020analysis}
Ahmad Ajalloeian and Sebastian~U Stich.
\newblock Analysis of sgd with biased gradient estimators.
\newblock \emph{arXiv preprint arXiv:2008.00051}, 2020.

\bibitem[Al-Shedivat et~al.(2017)Al-Shedivat, Bansal, Burda, Sutskever,
  Mordatch, and Abbeel]{al2017continuous}
Maruan Al-Shedivat, Trapit Bansal, Yuri Burda, Ilya Sutskever, Igor Mordatch,
  and Pieter Abbeel.
\newblock Continuous adaptation via meta-learning in nonstationary and
  competitive environments.
\newblock \emph{arXiv preprint arXiv:1710.03641}, 2017.

\bibitem[Blei et~al.(2017)Blei, Kucukelbir, and McAuliffe]{blei2017}
David~M Blei, Alp Kucukelbir, and Jon~D McAuliffe.
\newblock Variational inference: A review for statisticians.
\newblock \emph{Journal of the American Statistical Association}, 112\penalty0
  (518):\penalty0 859--877, 2017.

\bibitem[Duan et~al.(2016)Duan, Schulman, Chen, Bartlett, Sutskever, and
  Abbeel]{duan2016rl}
Yan Duan, John Schulman, Xi~Chen, Peter~L Bartlett, Ilya Sutskever, and Pieter
  Abbeel.
\newblock Rl2: Fast reinforcement learning via slow reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1611.02779}, 2016.

\bibitem[Fakoor et~al.(2019)Fakoor, Chaudhari, Soatto, and
  Smola]{fakoor2019meta}
Rasool Fakoor, Pratik Chaudhari, Stefano Soatto, and Alexander~J Smola.
\newblock Meta-q-learning.
\newblock \emph{arXiv preprint arXiv:1910.00125}, 2019.

\bibitem[Fallah et~al.(2020{\natexlab{a}})Fallah, Georgiev, Mokhtari, and
  Ozdaglar]{fallah2020provably}
Alireza Fallah, Kristian Georgiev, Aryan Mokhtari, and Asuman Ozdaglar.
\newblock Provably convergent policy gradient methods for model-agnostic
  meta-reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2002.05135}, 2020{\natexlab{a}}.

\bibitem[Fallah et~al.(2020{\natexlab{b}})Fallah, Mokhtari, and
  Ozdaglar]{fallah2020convergence}
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar.
\newblock On the convergence theory of gradient-based model-agnostic
  meta-learning algorithms.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pp.\  1082--1092. PMLR, 2020{\natexlab{b}}.

\bibitem[Farquhar et~al.(2019)Farquhar, Whiteson, and
  Foerster]{farquhar2019loaded}
Gregory Farquhar, Shimon Whiteson, and Jakob Foerster.
\newblock Loaded dice: Trading off bias and variance in any-order score
  function gradient estimators for reinforcement learning.
\newblock 2019.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{finn2017model}
Chelsea Finn, Pieter Abbeel, and Sergey Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1126--1135. PMLR, 2017.

\bibitem[Foerster et~al.(2018)Foerster, Farquhar, Al-Shedivat, Rockt{\"a}schel,
  Xing, and Whiteson]{foerster2018dice}
Jakob Foerster, Gregory Farquhar, Maruan Al-Shedivat, Tim Rockt{\"a}schel, Eric
  Xing, and Shimon Whiteson.
\newblock Dice: The infinitely differentiable monte carlo estimator.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1529--1538. PMLR, 2018.

\bibitem[Houthooft et~al.(2018)Houthooft, Chen, Isola, Stadie, Wolski, Ho, and
  Abbeel]{houthooft2018evolved}
Rein Houthooft, Richard~Y Chen, Phillip Isola, Bradly~C Stadie, Filip Wolski,
  Jonathan Ho, and Pieter Abbeel.
\newblock Evolved policy gradients.
\newblock \emph{arXiv preprint arXiv:1802.04821}, 2018.

\bibitem[Ji et~al.(2020)Ji, Yang, and Liang]{ji2020multi}
Kaiyi Ji, Junjie Yang, and Yingbin Liang.
\newblock Multi-step model-agnostic meta-learning: Convergence and improved
  algorithms.
\newblock \emph{arXiv preprint arXiv:2002.07836}, 2020.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kingma \& Welling(2013)Kingma and Welling]{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Levine et~al.(2016)Levine, Finn, Darrell, and Abbeel]{levine2016}
Sergey Levine, Chelsea Finn, Trevor Darrell, and Pieter Abbeel.
\newblock End-to-end training of deep visuomotor policies.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 1334--1373, 2016.

\bibitem[Liu et~al.(2019)Liu, Socher, and Xiong]{liu2019taming}
Hao Liu, Richard Socher, and Caiming Xiong.
\newblock Taming maml: Efficient unbiased meta-reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  4061--4071. PMLR, 2019.

\bibitem[Mao et~al.(2019)Mao, Foerster, Rockt{\"a}schel, Al-Shedivat, Farquhar,
  and Whiteson]{mao2019baseline}
Jingkai Mao, Jakob Foerster, Tim Rockt{\"a}schel, Maruan Al-Shedivat, Gregory
  Farquhar, and Shimon Whiteson.
\newblock A baseline for any order gradient estimation in stochastic
  computation graphs.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  4343--4351. PMLR, 2019.

\bibitem[Mnih et~al.(2013)Mnih, Kavukcuoglu, Silver, Graves, Antonoglou,
  Wierstra, and Riedmiller]{mnih2013}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis
  Antonoglou, Daan Wierstra, and Martin Riedmiller.
\newblock Playing atari with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1312.5602}, 2013.

\bibitem[Mohamed et~al.(2020)Mohamed, Rosca, Figurnov, and
  Mnih]{mohamed2020monte}
Shakir Mohamed, Mihaela Rosca, Michael Figurnov, and Andriy Mnih.
\newblock Monte carlo gradient estimation in machine learning.
\newblock \emph{J. Mach. Learn. Res.}, 21\penalty0 (132):\penalty0 1--62, 2020.

\bibitem[Oh et~al.(2020)Oh, Hessel, Czarnecki, Xu, van Hasselt, Singh, and
  Silver]{oh2020discovering}
Junhyuk Oh, Matteo Hessel, Wojciech~M Czarnecki, Zhongwen Xu, Hado van Hasselt,
  Satinder Singh, and David Silver.
\newblock Discovering reinforcement learning algorithms.
\newblock \emph{arXiv preprint arXiv:2007.08794}, 2020.

\bibitem[Ortega et~al.(2019)Ortega, Wang, Rowland, Genewein, Kurth-Nelson,
  Pascanu, Heess, Veness, Pritzel, Sprechmann, et~al.]{ortega2019meta}
Pedro~A Ortega, Jane~X Wang, Mark Rowland, Tim Genewein, Zeb Kurth-Nelson,
  Razvan Pascanu, Nicolas Heess, Joel Veness, Alex Pritzel, Pablo Sprechmann,
  et~al.
\newblock Meta-learning of sequential strategies.
\newblock \emph{arXiv preprint arXiv:1905.03030}, 2019.

\bibitem[Popoviciu(1965)]{popoviciu1965certaines}
Tiberiu Popoviciu.
\newblock Sur certaines in{\'e}galit{\'e}s qui caract{\'e}risent les fonctions
  convexes.
\newblock \emph{Analele Stiintifice Univ.“Al. I. Cuza”, Iasi, Sectia Mat},
  11:\penalty0 155--164, 1965.

\bibitem[Rakelly et~al.(2019)Rakelly, Zhou, Finn, Levine, and
  Quillen]{rakelly2019efficient}
Kate Rakelly, Aurick Zhou, Chelsea Finn, Sergey Levine, and Deirdre Quillen.
\newblock Efficient off-policy meta-reinforcement learning via probabilistic
  context variables.
\newblock In \emph{International conference on machine learning}, pp.\
  5331--5340. PMLR, 2019.

\bibitem[Ross(2002)]{ross6277simulation}
SM~Ross.
\newblock Simulation, 2002, 2002.

\bibitem[Rothfuss et~al.(2018)Rothfuss, Lee, Clavera, Asfour, and
  Abbeel]{rothfuss2018promp}
Jonas Rothfuss, Dennis Lee, Ignasi Clavera, Tamim Asfour, and Pieter Abbeel.
\newblock Promp: Proximal meta-policy search.
\newblock \emph{arXiv preprint arXiv:1810.06784}, 2018.

\bibitem[Schulman et~al.(2015)Schulman, Levine, Abbeel, Jordan, and
  Moritz]{schulman2015}
John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp
  Moritz.
\newblock Trust region policy optimization.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1889--1897, 2015.

\bibitem[Silver et~al.(2016)Silver, Huang, Maddison, Guez, Sifre, Van
  Den~Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot,
  et~al.]{silver2016}
David Silver, Aja Huang, Chris~J Maddison, Arthur Guez, Laurent Sifre, George
  Van Den~Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda
  Panneershelvam, Marc Lanctot, et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock \emph{nature}, 529\penalty0 (7587):\penalty0 484--489, 2016.

\bibitem[Sutton et~al.(2000)Sutton, McAllester, Singh, and Mansour]{sutton1999}
Richard~S Sutton, David~A McAllester, Satinder~P Singh, and Yishay Mansour.
\newblock Policy gradient methods for reinforcement learning with function
  approximation.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1057--1063, 2000.

\bibitem[Tang et~al.(2020)Tang, Valko, and Munos]{tang2020taylor}
Yunhao Tang, Michal Valko, and R{\'e}mi Munos.
\newblock Taylor expansion policy optimization.
\newblock \emph{arXiv preprint arXiv:2003.06259}, 2020.

\bibitem[Tang et~al.(2021)Tang, Kozuno, Rowland, Munos, and
  Valko]{tang2021unifying}
Yunhao Tang, Tadashi Kozuno, Mark Rowland, R{\'e}mi Munos, and Michal Valko.
\newblock Unifying gradient estimators for meta-reinforcement learning via
  off-policy evaluation.
\newblock \emph{arXiv preprint arXiv:2106.13125}, 2021.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{todorov2012}
Emanuel Todorov, Tom Erez, and Yuval Tassa.
\newblock Mujoco: A physics engine for model-based control.
\newblock In \emph{Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ
  International Conference on}, pp.\  5026--5033. IEEE, 2012.

\bibitem[Wang et~al.(2016)Wang, Kurth-Nelson, Tirumala, Soyer, Leibo, Munos,
  Blundell, Kumaran, and Botvinick]{wang2016learning}
Jane~X Wang, Zeb Kurth-Nelson, Dhruva Tirumala, Hubert Soyer, Joel~Z Leibo,
  Remi Munos, Charles Blundell, Dharshan Kumaran, and Matt Botvinick.
\newblock Learning to reinforcement learn.
\newblock \emph{arXiv preprint arXiv:1611.05763}, 2016.

\bibitem[Wang et~al.(2015)Wang, Schaul, Hessel, Van~Hasselt, Lanctot, and
  De~Freitas]{wang2016}
Ziyu Wang, Tom Schaul, Matteo Hessel, Hado Van~Hasselt, Marc Lanctot, and Nando
  De~Freitas.
\newblock Dueling network architectures for deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1511.06581}, 2015.

\bibitem[Xu et~al.(2020)Xu, van Hasselt, Hessel, Oh, Singh, and
  Silver]{xu2020meta}
Zhongwen Xu, Hado van Hasselt, Matteo Hessel, Junhyuk Oh, Satinder Singh, and
  David Silver.
\newblock Meta-gradient reinforcement learning with an objective discovered
  online.
\newblock \emph{arXiv preprint arXiv:2007.08433}, 2020.

\bibitem[Zintgraf et~al.(2019)Zintgraf, Shiarlis, Igl, Schulze, Gal, Hofmann,
  and Whiteson]{zintgraf2019varibad}
Luisa Zintgraf, Kyriacos Shiarlis, Maximilian Igl, Sebastian Schulze, Yarin
  Gal, Katja Hofmann, and Shimon Whiteson.
\newblock Varibad: A very good method for bayes-adaptive deep rl via
  meta-learning.
\newblock \emph{arXiv preprint arXiv:1910.08348}, 2019.

\end{thebibliography}
