@article{crossgnn,
  title={Crossgnn: Confronting noisy multivariate time series via cross interaction refinement},
  author={Huang, Qihe and Shen, Lei and Zhang, Ruixin and Ding, Shouhong and Wang, Binwu and Zhou, Zhengyang and Wang, Yang},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{Transformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{TransformerforTS,
  title={Transformers in time series: A survey},
  author={Wen, Qingsong and Zhou, Tian and Zhang, Chaoli and Chen, Weiqi and Ma, Ziqing and Yan, Junchi and Sun, Liang},
  journal={arXiv preprint arXiv:2202.07125},
  year={2022}
}

@article{LogTrans,
  title={Enhancing the locality and breaking the memory bottleneck of transformer on time series forecasting},
  author={Li, Shiyang and Jin, Xiaoyong and Xuan, Yao and Zhou, Xiyou and Chen, Wenhu and Wang, Yu-Xiang and Yan, Xifeng},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{TFT,
  title={Temporal fusion transformers for interpretable multi-horizon time series forecasting},
  author={Lim, Bryan and Ar{\i}k, Sercan {\"O} and Loeff, Nicolas and Pfister, Tomas},
  journal={International Journal of Forecasting},
  volume={37},
  number={4},
  pages={1748--1764},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{Informer,
  title={Informer: Beyond efficient transformer for long sequence time-series forecasting},
  author={Zhou, Haoyi and Zhang, Shanghang and Peng, Jieqi and Zhang, Shuai and Li, Jianxin and Xiong, Hui and Zhang, Wancai},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  number={12},
  pages={11106--11115},
  year={2021}
}

@article{Autoformer,
  title={Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting},
  author={Wu, Haixu and Xu, Jiehui and Wang, Jianmin and Long, Mingsheng},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={22419--22430},
  year={2021}
}

@inproceedings{Pyraformer,
  title={Pyraformer: Low-complexity pyramidal attention for long-range time series modeling and forecasting},
  author={Liu, Shizhan and Yu, Hang and Liao, Cong and Li, Jianguo and Lin, Weiyao and Liu, Alex X and Dustdar, Schahram},
  booktitle={International conference on learning representations},
  year={2021}
}

@inproceedings{Fedformer,
  title={Fedformer: Frequency enhanced decomposed transformer for long-term series forecasting},
  author={Zhou, Tian and Ma, Ziqing and Wen, Qingsong and Wang, Xue and Sun, Liang and Jin, Rong},
  booktitle={International conference on machine learning},
  pages={27268--27286},
  year={2022},
  organization={PMLR}
}

@article{ETSformer,
  title={Etsformer: Exponential smoothing transformers for time-series forecasting},
  author={Woo, Gerald and Liu, Chenghao and Sahoo, Doyen and Kumar, Akshat and Hoi, Steven},
  journal={arXiv preprint arXiv:2202.01381},
  year={2022}
}

@article{NSTransformers,
  title={Non-stationary transformers: Exploring the stationarity in time series forecasting},
  author={Liu, Yong and Wu, Haixu and Wang, Jianmin and Long, Mingsheng},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={9881--9893},
  year={2022}
}

@article{Vit,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{MAE,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16000--16009},
  year={2022}
}


@inproceedings{
    Crossformer,
    title={Crossformer: Transformer Utilizing Cross-Dimension Dependency for Multivariate Time Series Forecasting},
    author={Yunhao Zhang and Junchi Yan},
    booktitle={International Conference on Learning Representations},
    year={2023}
}


@inproceedings{PatchTST,
  title     = {A Time Series is Worth 64 Words: Long-term Forecasting with Transformers},
  author    = {Nie, Yuqi and
               H. Nguyen, Nam and
               Sinthong, Phanwadee and 
               Kalagnanam, Jayant},
  booktitle = {International Conference on Learning Representations},
  year      = {2023}
}


@inproceedings{liu2024itransformer,
  title={iTransformer: Inverted Transformers Are Effective for Time Series Forecasting}, 
  author={Yong Liu and Tengge Hu and Haoran Zhang and Haixu Wu and Shiyu Wang and Lintao Ma and Mingsheng Long},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@inproceedings{Nhit,
  title={Nhits: Neural hierarchical interpolation for time series forecasting},
  author={Challu, Cristian and Olivares, Kin G and Oreshkin, Boris N and Ramirez, Federico Garza and Canseco, Max Mergenthaler and Dubrawski, Artur},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={6},
  pages={6989--6997},
  year={2023}
}

@inproceedings{DLinear,
  title={Are transformers effective for time series forecasting?},
  author={Zeng, Ailing and Chen, Muxi and Zhang, Lei and Xu, Qiang},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={37},
  number={9},
  pages={11121--11128},
  year={2023}
}

@article{LightTS,
  title={Less is more: Fast multivariate time series forecasting with light sampling-oriented mlp structures},
  author={Zhang, Tianping and Zhang, Yizhuo and Cao, Wei and Bian, Jiang and Yi, Xiaohan and Zheng, Shun and Li, Jian},
  journal={arXiv preprint arXiv:2207.01186},
  year={2022}
}

@article{MTS-Mixers,
  title={Mts-mixers: Multivariate time series forecasting via factorized temporal and channel mixing},
  author={Li, Zhe and Rao, Zhongwen and Pan, Lujia and Xu, Zenglin},
  journal={arXiv preprint arXiv:2302.04501},
  year={2023}
}

@article{Tsmixer,
  title={Tsmixer: An all-mlp architecture for time series forecasting},
  author={Chen, Si-An and Li, Chun-Liang and Yoder, Nate and Arik, Sercan O and Pfister, Tomas},
  journal={arXiv preprint arXiv:2303.06053},
  year={2023}
}

@article{TiDE,
  title={Long-term forecasting with tide: Time-series dense encoder},
  author={Das, Abhimanyu and Kong, Weihao and Leach, Andrew and Mathur, Shaan and Sen, Rajat and Yu, Rose},
  journal={arXiv preprint arXiv:2304.08424},
  year={2023}
}


@inproceedings{fits,
  title={FITS: Modeling Time Series with $10 k $ Parameters},
  author={Xu, Zhijian and Zeng, Ailing and Xu, Qiang},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@inproceedings{timemixer,
  title={TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting},
  author={Wang, Shiyu and Wu, Haixu and Shi, Xiaoming and Hu, Tengge and Luo, Huakun and Ma, Lintao and Zhang, James Y and ZHOU, JUN},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@inproceedings{hdmixer,
  title={Hdmixer: Hierarchical dependency with extendable patch for multivariate time series forecasting},
  author={Huang, Qihe and Shen, Lei and Zhang, Ruixin and Cheng, Jiahuan and Ding, Shouhong and Zhou, Zhengyang and Wang, Yang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={11},
  pages={12608--12616},
  year={2024}
}

@article{softs,
  title={SOFTS: Efficient Multivariate Time Series Forecasting with Series-Core Fusion},
  author={Han, Lu and Chen, Xu-Yang and Ye, Han-Jia and Zhan, De-Chuan},
  journal={arXiv preprint arXiv:2404.14197},
  year={2024}
}


@inproceedings{sparsetsf,
  title={SparseTSF: Modeling Long-term Time Series Forecasting with 1k Parameters},
  author={Lin, Shengsheng and Lin, Weiwei and Wu, Wentai and Chen, Haojun and Yang, Junjie},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{scinet,
  title={Scinet: Time series modeling and forecasting with sample convolution and interaction},
  author={Liu, Minhao and Zeng, Ailing and Chen, Muxi and Xu, Zhijian and Lai, Qiuxia and Ma, Lingna and Xu, Qiang},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={5816--5828},
  year={2022}
}

@inproceedings{LSTNet,
  title={Modeling long-and short-term temporal patterns with deep neural networks},
  author={Lai, Guokun and Chang, Wei-Cheng and Yang, Yiming and Liu, Hanxiao},
  booktitle={The 41st international ACM SIGIR conference on research \& development in information retrieval},
  pages={95--104},
  year={2018}
}

@article{DeepAR,
  title={DeepAR: Probabilistic forecasting with autoregressive recurrent networks},
  author={Salinas, David and Flunkert, Valentin and Gasthaus, Jan and Januschowski, Tim},
  journal={International journal of forecasting},
  volume={36},
  number={3},
  pages={1181--1191},
  year={2020},
  publisher={Elsevier}
}

@article{segrnn,
  title={Segrnn: Segment recurrent neural network for long-term time series forecasting},
  author={Lin, Shengsheng and Lin, Weiwei and Wu, Wentai and Zhao, Feiyu and Mo, Ruichao and Zhang, Haotong},
  journal={arXiv preprint arXiv:2308.11200},
  year={2023}
}

@article{witran,
  title={Witran: Water-wave information transmission and recurrent acceleration network for long-range time series forecasting},
  author={Jia, Yuxin and Lin, Youfang and Hao, Xinyan and Lin, Yan and Guo, Shengnan and Wan, Huaiyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{sutranets,
  title={SutraNets: Sub-series Autoregressive Networks for Long-Sequence, Probabilistic Forecasting},
  author={Bergsma, Shane and Zeyl, Tim and Guo, Lei},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={30518--30533},
  year={2023}
}

@article{RWKV-TS,
  title={RWKV-TS: Beyond Traditional Recurrent Neural Network for Time Series Tasks},
  author={Hou, Haowen and Yu, F Richard},
  journal={arXiv preprint arXiv:2401.09093},
  year={2024}
}

@article{TCN1,
  title={An empirical evaluation of generic convolutional and recurrent networks for sequence modeling},
  author={Bai, Shaojie and Kolter, J Zico and Koltun, Vladlen},
  journal={arXiv preprint arXiv:1803.01271},
  year={2018}
}

@inproceedings{TCN2,
 author = {Franceschi, Jean-Yves and Dieuleveut, Aymeric and Jaggi, Martin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Unsupervised Scalable Representation Learning for Multivariate Time Series},
 url = {https://proceedings.neurips.cc/paper_files/paper/2019/file/53c6de78244e9f528eb3e1cda69699bb-Paper.pdf},
 volume = {32},
 year = {2019}
}


@inproceedings{micn,
  title={Micn: Multi-scale local and global context modeling for long-term series forecasting},
  author={Wang, Huiqiang and Peng, Jian and Huang, Feihu and Wang, Jince and Chen, Junhui and Xiao, Yifei},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}


@inproceedings{timesnet,
  title={Timesnet: Temporal 2d-variation modeling for general time series analysis},
  author={Wu, Haixu and Hu, Tengge and Liu, Yong and Zhou, Hang and Wang, Jianmin and Long, Mingsheng},
  booktitle={International Conference on Learning Representations},
  year={2023}
}

@article{patchmixer,
  title={Patchmixer: A patch-mixing architecture for long-term time series forecasting},
  author={Gong, Zeying and Tang, Yujin and Liang, Junwei},
  journal={arXiv preprint arXiv:2310.00655},
  year={2023}
}

@inproceedings{moderntcn,
  title={ModernTCN: A modern pure convolution structure for general time series analysis},
  author={Luo, Donghao and Wang, Xue},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}


@article{OFA,
  title={One fits all: Power general time series analysis by pretrained lm},
  author={Zhou, Tian and Niu, Peisong and Sun, Liang and Jin, Rong and others},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@article{Time-llm,
  title={Time-llm: Time series forecasting by reprogramming large language models},
  author={Jin, Ming and Wang, Shiyu and Ma, Lintao and Chu, Zhixuan and Zhang, James Y and Shi, Xiaoming and Chen, Pin-Yu and Liang, Yuxuan and Li, Yuan-Fang and Pan, Shirui and others},
  journal={arXiv preprint arXiv:2310.01728},
  year={2023}
}

@article{promptcast,
  title={Promptcast: A new prompt-based learning paradigm for time series forecasting},
  author={Xue, Hao and Salim, Flora D},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2023},
  publisher={IEEE}
}

@article{LLMTime,
  title={Large language models are zero-shot time series forecasters},
  author={Gruver, Nate and Finzi, Marc and Qiu, Shikai and Wilson, Andrew G},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{tempo,
  title={Tempo: Prompt-based generative pre-trained transformer for time series forecasting},
  author={Cao, Defu and Jia, Furong and Arik, Sercan O and Pfister, Tomas and Zheng, Yixiang and Ye, Wen and Liu, Yan},
  journal={arXiv preprint arXiv:2310.04948},
  year={2023}
}

@article{LSTPrompt,
  title={LSTPrompt: Large Language Models as Zero-Shot Time Series Forecasters by Long-Short-Term Prompting},
  author={Liu, Haoxin and Zhao, Zhiyuan and Wang, Jindong and Kamarthi, Harshavardhan and Prakash, B Aditya},
  journal={arXiv preprint arXiv:2402.16132},
  year={2024}
}

@article{depts,
  title={DEPTS: Deep expansion learning for periodic time series forecasting},
  author={Fan, Wei and Zheng, Shun and Yi, Xiaohan and Cao, Wei and Fu, Yanjie and Bian, Jiang and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:2203.07681},
  year={2022}
}

@article{instance,
  title={Instance normalization: The missing ingredient for fast stylization},
  author={Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
  journal={arXiv preprint arXiv:1607.08022},
  year={2016}
}

@inproceedings{revin,
  title={Reversible instance normalization for accurate time-series forecasting against distribution shift},
  author={Kim, Taesung and Kim, Jinhee and Tae, Yunwon and Park, Cheonbok and Choi, Jang-Ho and Choo, Jaegul},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{RLinear,
  title={Revisiting long-term time series forecasting: An investigation on linear mapping},
  author={Li, Zhe and Qi, Shiyi and Li, Yiduo and Xu, Zenglin},
  journal={arXiv preprint arXiv:2305.10721},
  year={2023}
}

@article{adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}


@book{acf,
  title={Time series analysis},
  author={Madsen, Henrik},
  year={2007},
  publisher={CRC Press}
}

@article{pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{petformer,
  title={Petformer: Long-term time series forecasting via placeholder-enhanced transformer},
  author={Lin, Shengsheng and Lin, Weiwei and Wu, Wentai and Wang, Songbo and Wang, Yongxiang},
  journal={arXiv preprint arXiv:2308.04791},
  year={2023}
}

@article{tfb,
  title   = {TFB: Towards Comprehensive and Fair Benchmarking of Time Series Forecasting Methods},
  author  = {Xiangfei Qiu and Jilin Hu and Lekui Zhou and Xingjian Wu and Junyang Du and Buang Zhang and Chenjuan Guo and Aoying Zhou and Christian S. Jensen and Zhenli Sheng and Bin Yang},
  journal = {Proc. {VLDB} Endow.},
  volume  = {17},
  number  = {9},
  pages   = {2363--2377},
  year    = {2024}
}


@inproceedings{lenet,
  title     = {LeRet: Language-Empowered Retentive Network for Time Series Forecasting},
  author    = {Huang, Qihe and Zhou, Zhengyang and Yang, Kuo and Lin, Gengyu and Yi, Zhongchao and Wang, Yang},
  booktitle = {Proceedings of the Thirty-Third International Joint Conference on
               Artificial Intelligence, {IJCAI-24}},
  year      = {2024}
}


@article{CI,
  title={The capacity and robustness trade-off: Revisiting the channel independent strategy for multivariate time series forecasting},
  author={Han, Lu and Ye, Han-Jia and Zhan, De-Chuan},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2024},
  publisher={IEEE}
}

@inproceedings{LD,
  title={Revitalizing Multivariate Time Series Forecasting: Learnable Decomposition with Inter-Series Dependencies and Intra-Series Variations Modeling},
  author={Yu, Guoqi and Zou, Jing and Hu, Xiaowei and Aviles-Rivero, Angelica I and Qin, Jing and Wang, Shujun},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{Ti-mae,
  title={Ti-mae: Self-supervised masked time series autoencoders},
  author={Li, Zhe and Rao, Zhongwen and Pan, Lujia and Wang, Pengyun and Xu, Zenglin},
  journal={arXiv preprint arXiv:2301.08871},
  year={2023}
}

@inproceedings{linear-analysis,
  title={An Analysis of Linear Time Series Forecasting Models},
  author={Toner, William and Darlow, Luke Nicholas},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@inproceedings{sscnn,
  title={Parsimony or Capability? Decomposition Delivers Both in Long-term Time Series Forecasting},
  author={Jinliang Deng and Feiyang Ye and Du Yin and Xuan Song and Ivor Wai-Hung Tsang and Hui Xiong},
  year={2024},
  url={https://api.semanticscholar.org/CorpusID:267068391}
}


@inproceedings{jin2024position,
  title={Position: What Can Large Language Models Tell Us about Time Series Analysis},
  author={Jin, Ming and Zhang, Yifan and Chen, Wei and Zhang, Kexin and Liang, Yuxuan and Yang, Bin and Wang, Jindong and Pan, Shirui and Wen, Qingsong},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}