\begin{thebibliography}{38}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Babes et~al.(2011)Babes, Marivate, Littman, and Subramanian]{babes11}
Babes, Monica, Marivate, Vukosi~N., Littman, Michael~L., and Subramanian,
  Kaushik.
\newblock Apprenticeship learning about multiple intentions.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  897--904, 2011.

\bibitem[Baird \& Moore(1999)Baird and Moore]{baird1999gradient}
Baird, Leemon and Moore, Andrew~W.
\newblock Gradient descent for general reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  968--974, 1999.

\bibitem[Baker et~al.(2007)Baker, Tenenbaum, and Saxe]{baker2007goal}
Baker, Chris~L, Tenenbaum, Joshua~B, and Saxe, Rebecca~R.
\newblock Goal inference as inverse planning.
\newblock In \emph{Proceedings of the 29th Annual Meeting of the Cognitive
  Science Society}, 2007.

\bibitem[Beliakov et~al.(2016)Beliakov, Sola, and S{\'a}nchez]{beliakov16}
Beliakov, Gleb, Sola, Humberto~Bustince, and S{\'a}nchez, Tomasa~Calvo.
\newblock \emph{A Practical Guide to Averaging Functions}.
\newblock Springer, 2016.

\bibitem[Bellman(1957)]{VI}
Bellman, Richard.
\newblock A {M}arkovian decision process.
\newblock \emph{Journal of Mathematics and Mechanics}, 6\penalty0 (5):\penalty0
  679--684, 1957.

\bibitem[Boyd \& Vandenberghe(2004)Boyd and Vandenberghe]{boyd2004convex}
Boyd, S.P. and Vandenberghe, L.
\newblock \emph{Convex optimization}.
\newblock Cambridge University Press, 2004.

\bibitem[Brent(2013)]{brent2013algorithms}
Brent, Richard~P.
\newblock \emph{Algorithms for minimization without derivatives}.
\newblock Courier Corporation, 2013.

\bibitem[Brockman et~al.(2016)Brockman, Cheung, Pettersson, Schneider,
  Schulman, Tang, and Zaremba]{open_AI}
Brockman, Greg, Cheung, Vicki, Pettersson, Ludwig, Schneider, Jonas, Schulman,
  John, Tang, Jie, and Zaremba, Wojciech.
\newblock Openai gym, 2016.

\bibitem[Chollet(2015)]{chollet2015keras}
Chollet, Fran\c{c}ois.
\newblock Keras.
\newblock \url{https://github.com/fchollet/keras}, 2015.

\bibitem[Cover \& Thomas(2006)Cover and Thomas]{cover2006}
Cover, T.M. and Thomas, J.A.
\newblock \emph{{Elements of Information Theory}}.
\newblock John Wiley and Sons, 2006.

\bibitem[Dearden et~al.(1998)Dearden, Friedman, and Russell]{dearden98}
Dearden, Richard, Friedman, Nir, and Russell, Stuart.
\newblock Bayesian {Q}-learning.
\newblock In \emph{Fifteenth National Conference on Artificial Intelligence
  (AAAI)}, pp.\  761--768, 1998.

\bibitem[Fox et~al.(2016)Fox, Pakman, and Tishby]{fox2015taming}
Fox, Roy, Pakman, Ari, and Tishby, Naftali.
\newblock Taming the noise in reinforcement learning via soft updates.
\newblock In \emph{Proceedings of the Thirty-Second Conference on Uncertainty
  in Artificial Intelligence}, pp.\  202--211. AUAI Press, 2016.

\bibitem[Gordon(1995)]{gordon1995stable}
Gordon, Geoffrey~J.
\newblock Stable function approximation in dynamic programming.
\newblock In \emph{Proceedings of the twelfth international conference on
  machine learning}, pp.\  261--268, 1995.

\bibitem[Gordon(2001)]{gordon2001reinforcement}
Gordon, Geoffrey~J.
\newblock Reinforcement learning with function approximation converges to a
  region, 2001.
\newblock Unpublished.

\bibitem[John(1994)]{john94}
John, George~H.
\newblock When the best move isn't optimal: {Q}-learning with exploration.
\newblock In \emph{Proceedings of the Twelfth National Conference on Artificial
  Intelligence}, pp.\  1464, Seattle, WA, 1994.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, Diederik and Ba, Jimmy.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kuleshov \& Precup(2014)Kuleshov and Precup]{kuleshov14}
Kuleshov, Volodymyr and Precup, Doina.
\newblock Algorithms for multi-armed bandit problems.
\newblock arXiv preprint arXiv:1402.6028, 2014.

\bibitem[Littman \& Szepesv\'ari(1996)Littman and Szepesv\'ari]{littman96}
Littman, Michael~L. and Szepesv\'ari, Csaba.
\newblock A generalized reinforcement-learning model: {C}onvergence and
  applications.
\newblock In Saitta, Lorenza (ed.), \emph{Proceedings of the Thirteenth
  International Conference on Machine Learning}, pp.\  310--318, 1996.

\bibitem[Littman(1996)]{littman96c}
Littman, Michael~Lederman.
\newblock \emph{Algorithms for Sequential Decision Making}.
\newblock PhD thesis, Department of Computer Science, Brown University,
  February 1996.
\newblock Also Technical Report CS-96-09.

\bibitem[Neu \& Szepesv\'ari(2007)Neu and Szepesv\'ari]{neu07}
Neu, Gergely and Szepesv\'ari, Csaba.
\newblock Apprenticeship learning using inverse reinforcement learning and
  gradient methods.
\newblock In \emph{UAI}, 2007.

\bibitem[Ng \& Russell(2000)Ng and Russell]{ng00}
Ng, Andrew~Y. and Russell, Stuart.
\newblock Algorithms for inverse reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  663--670, 2000.

\bibitem[Perkins \& Precup(2002)Perkins and Precup]{perkins2002convergent}
Perkins, Theodore~J and Precup, Doina.
\newblock A convergent form of approximate policy iteration.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1595--1602, 2002.

\bibitem[Peters et~al.(2010)Peters, M{\"u}lling, and Altun]{peters2010relative}
Peters, Jan, M{\"u}lling, Katharina, and Altun, Yasemin.
\newblock Relative entropy policy search.
\newblock In \emph{AAAI}. Atlanta, 2010.

\bibitem[Puterman(1994)]{Puterman94}
Puterman, Martin~L.
\newblock \emph{Markov Decision Processes---Discrete Stochastic Dynamic
  Programming}.
\newblock John Wiley \& Sons, Inc., New York, NY, 1994.

\bibitem[Ramachandran \& Amir(2007)Ramachandran and Amir]{ramachandran07}
Ramachandran, Deepak and Amir, Eyal.
\newblock Bayesian inverse reinforcement learning.
\newblock In \emph{IJCAI}, 2007.

\bibitem[Rubin et~al.(2012)Rubin, Shamir, and Tishby]{rubin2012trading}
Rubin, Jonathan, Shamir, Ohad, and Tishby, Naftali.
\newblock Trading value and information in mdps.
\newblock In \emph{Decision Making with Imperfect Decision Makers}, pp.\
  57--74. Springer, 2012.

\bibitem[Rummery \& Niranjan(1994)Rummery and Niranjan]{rummery94b}
Rummery, G.~A. and Niranjan, M.
\newblock On-line {Q}-learning using connectionist systems.
\newblock Technical Report CUED/F-INFENG/TR 166, Cambridge University
  Engineering Department, 1994.

\bibitem[Safak(1993)]{logSumExpEE}
Safak, Aysel.
\newblock Statistical analysis of the power sum of multiple correlated
  log-normal components.
\newblock \emph{IEEE Transactions on Vehicular Technology}, 42\penalty0
  (1):\penalty0 58--61, 1993.

\bibitem[Singh et~al.(2000)Singh, Jaakkola, Littman, and
  {Sz}epesv{\'a}ri]{singh00}
Singh, Satinder, Jaakkola, Tommi, Littman, Michael~L., and {Sz}epesv{\'a}ri,
  Csaba.
\newblock Convergence results for single-step on-policy reinforcement-learning
  algorithms.
\newblock \emph{Machine Learning}, 39:\penalty0 287--308, 2000.

\bibitem[Stahl \& Wilson(1994)Stahl and Wilson]{stahl94}
Stahl, Dale~O. and Wilson, Paul~W.
\newblock Experimental evidence on players' models of other players.
\newblock \emph{Journal of Economic Behavior and Organization}, 25\penalty0
  (3):\penalty0 309--â€“327, 1994.

\bibitem[Sutton(1990)]{sutton90}
Sutton, Richard~S.
\newblock Integrated architectures for learning, planning, and reacting based
  on approximating dynamic programming.
\newblock In \emph{Proceedings of the Seventh International Conference on
  Machine Learning}, pp.\  216--224, Austin, TX, 1990. Morgan Kaufmann.

\bibitem[Sutton \& Barto(1998)Sutton and Barto]{sutton98}
Sutton, Richard~S. and Barto, Andrew~G.
\newblock \emph{Reinforcement Learning: {A}n Introduction}.
\newblock The MIT Press, 1998.

\bibitem[Team et~al.(2016)Team, Al-Rfou, Alain, Almahairi, Angermueller,
  Bahdanau, Ballas, Bastien, Bayer, Belikov, et~al.]{team2016theano}
Team, The Theano~Development, Al-Rfou, Rami, Alain, Guillaume, Almahairi,
  Amjad, Angermueller, Christof, Bahdanau, Dzmitry, Ballas, Nicolas, Bastien,
  Fr{\'e}d{\'e}ric, Bayer, Justin, Belikov, Anatoly, et~al.
\newblock Theano: A python framework for fast computation of mathematical
  expressions.
\newblock \emph{arXiv preprint arXiv:1605.02688}, 2016.

\bibitem[Thrun(1992)]{Thrun92}
Thrun, Sebastian~B.
\newblock The role of exploration in learning control.
\newblock In White, David~A. and Sofge, Donald~A. (eds.), \emph{Handbook of
  Intelligent Control: {N}eural, Fuzzy, and Adaptive Approaches}, pp.\
  527--559. Van Nostrand Reinhold, New York, NY, 1992.

\bibitem[Todorov(2006)]{todorov2006linearly}
Todorov, Emanuel.
\newblock Linearly-solvable markov decision problems.
\newblock In \emph{NIPS}, pp.\  1369--1376, 2006.

\bibitem[Van~Seijen et~al.(2009)Van~Seijen, Van~Hasselt, Whiteson, and
  Wiering]{van2009theoretical}
Van~Seijen, Harm, Van~Hasselt, Hado, Whiteson, Shimon, and Wiering, Marco.
\newblock A theoretical and empirical analysis of {E}xpected {S}arsa.
\newblock In \emph{2009 IEEE Symposium on Adaptive Dynamic Programming and
  Reinforcement Learning}, pp.\  177--184. IEEE, 2009.

\bibitem[Williams(1992)]{Williams92}
Williams, Ronald~J.
\newblock Simple statistical gradient-following algorithms for connectionist
  reinforcement learning.
\newblock \emph{Machine Learning}, 8\penalty0 (3):\penalty0 229--256, 1992.

\bibitem[Wright \& Leyton-Brown(2010)Wright and Leyton-Brown]{wright10}
Wright, James~R. and Leyton-Brown, Kevin.
\newblock Beyond equilibrium: Predicting human behavior in normal-form games.
\newblock In \emph{AAAI}, 2010.

\end{thebibliography}
