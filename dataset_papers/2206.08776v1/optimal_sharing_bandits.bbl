\begin{thebibliography}{28}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Anandkumar et~al.(2011)Anandkumar, Michael, Tang, and
  Swami]{anandkumar2011distributed}
Anandkumar, A., Michael, N., Tang, A.~K., and Swami, A.
\newblock Distributed algorithms for learning and cognitive medium access with
  logarithmic regret.
\newblock \emph{IEEE Journal on Selected Areas in Communications}, 29\penalty0
  (4):\penalty0 731--745, 2011.

\bibitem[Anantharam et~al.(1987)Anantharam, Varaiya, and
  Walrand]{anantharam1987asymptotically}
Anantharam, V., Varaiya, P., and Walrand, J.
\newblock Asymptotically efficient allocation rules for the multiarmed bandit
  problem with multiple plays-part i: Iid rewards.
\newblock \emph{IEEE Transactions on Automatic Control}, 32\penalty0
  (11):\penalty0 968--976, 1987.

\bibitem[Bistritz \& Leshem(2018)Bistritz and Leshem]{bistritz2018distributed}
Bistritz, I. and Leshem, A.
\newblock Distributed multi-player bandits-a game of thrones approach.
\newblock \emph{Advances in Neural Information Processing Systems (NeurIPS)},
  2018.

\bibitem[Bourel et~al.(2020)Bourel, Maillard, and Talebi]{bourel2020tightening}
Bourel, H., Maillard, O.-A., and Talebi, M.~S.
\newblock Tightening exploration in upper confidence reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Bubeck et~al.(2012)Bubeck, Cesa-Bianchi, et~al.]{bubeck2012regret}
Bubeck, S., Cesa-Bianchi, N., et~al.
\newblock Regret analysis of stochastic and nonstochastic multi-armed bandit
  problems.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  5\penalty0 (1):\penalty0 1--122, 2012.

\bibitem[Cai et~al.(2018)Cai, Liu, Chen, and Lui]{cai2018online}
Cai, K., Liu, X., Chen, Y.-Z.~J., and Lui, J. C.~S.
\newblock An online learning approach to network application optimization with
  guarantee.
\newblock In \emph{IEEE INFOCOM 2018-IEEE Conference on Computer
  Communications}, pp.\  2006--2014. IEEE, 2018.

\bibitem[Capp{\'e} et~al.(2013)Capp{\'e}, Garivier, Maillard, Munos, Stoltz,
  et~al.]{cappe_kullback-leibler_2013}
Capp{\'e}, O., Garivier, A., Maillard, O.-A., Munos, R., Stoltz, G., et~al.
\newblock {K}ullback--{L}eibler upper confidence bounds for optimal sequential
  allocation.
\newblock \emph{Annals of Statistics}, 41\penalty0 (3):\penalty0 1516--1541,
  2013.

\bibitem[Cesa-Bianchi \& Lugosi(2012)Cesa-Bianchi and
  Lugosi]{cesa2012combinatorial}
Cesa-Bianchi, N. and Lugosi, G.
\newblock Combinatorial bandits.
\newblock \emph{Journal of Computer and System Sciences}, 78\penalty0
  (5):\penalty0 1404--1422, 2012.

\bibitem[Chen et~al.(2013)Chen, Wang, and Yuan]{chen2013combinatorial}
Chen, W., Wang, Y., and Yuan, Y.
\newblock Combinatorial multi-armed bandit: General framework and applications.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  151--159. PMLR, 2013.

\bibitem[Chen et~al.(2016)Chen, Wang, Yuan, and Wang]{chen2016combinatorial}
Chen, W., Wang, Y., Yuan, Y., and Wang, Q.
\newblock Combinatorial multi-armed bandit and its extension to
  probabilistically triggered arms.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 1746--1778, 2016.

\bibitem[Combes et~al.(2015)Combes, Magureanu, Proutiere, and
  Laroche]{combes2015learning}
Combes, R., Magureanu, S., Proutiere, A., and Laroche, C.
\newblock Learning to rank: Regret lower bounds and efficient algorithms.
\newblock In \emph{Proceedings of the 2015 ACM SIGMETRICS International
  Conference on Measurement and Modeling of Computer Systems}, pp.\  231--244,
  2015.

\bibitem[{Gai} et~al.(2012){Gai}, {Krishnamachari}, and
  {Jain}]{gai2012combinatorial}
{Gai}, Y., {Krishnamachari}, B., and {Jain}, R.
\newblock Combinatorial network optimization with unknown variables:
  Multi-armed bandits with linear rewards and individual observations.
\newblock \emph{IEEE/ACM Transactions on Networking}, 20\penalty0 (5):\penalty0
  1466--1478, 2012.
\newblock \doi{10.1109/TNET.2011.2181864}.

\bibitem[Komiyama et~al.(2015)Komiyama, Honda, and
  Nakagawa]{komiyama_optimal_2015}
Komiyama, J., Honda, J., and Nakagawa, H.
\newblock Optimal regret analysis of {T}hompson sampling in stochastic
  multi-armed bandit problem with multiple plays.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1152--1161. PMLR, 2015.

\bibitem[Komiyama et~al.(2017)Komiyama, Honda, and
  Takeda]{komiyama2017position}
Komiyama, J., Honda, J., and Takeda, A.
\newblock Position-based multiple-play bandit problem with unknown position
  bias.
\newblock In \emph{Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, pp.\  5005--5015, 2017.

\bibitem[Kveton et~al.(2014)Kveton, Wen, Ashkan, Eydgahi, and
  Eriksson]{kveton2014matroid}
Kveton, B., Wen, Z., Ashkan, A., Eydgahi, H., and Eriksson, B.
\newblock Matroid bandits: fast combinatorial optimization with learning.
\newblock In \emph{Proceedings of the Thirtieth Conference on Uncertainty in
  Artificial Intelligence}, pp.\  420--429, 2014.

\bibitem[Kveton et~al.(2015)Kveton, Wen, Ashkan, and
  Szepesv{\'a}ri]{kveton2015combinatorial}
Kveton, B., Wen, Z., Ashkan, A., and Szepesv{\'a}ri, C.
\newblock Combinatorial cascading bandits.
\newblock In \emph{Proceedings of the 28th International Conference on Neural
  Information Processing Systems-Volume 1}, pp.\  1450--1458, 2015.

\bibitem[Lagr{\'e}e et~al.(2016)Lagr{\'e}e, Vernade, and
  Capp{\'e}]{lagree2016multiple}
Lagr{\'e}e, P., Vernade, C., and Capp{\'e}, O.
\newblock Multiple-play bandits in the position-based model.
\newblock In \emph{Proceedings of the 30th International Conference on Neural
  Information Processing Systems}, pp.\  1605--1613, 2016.

\bibitem[Lai \& Robbins(1985)Lai and Robbins]{lai1985asymptotically}
Lai, T.~L. and Robbins, H.
\newblock Asymptotically efficient adaptive allocation rules.
\newblock \emph{Advances in applied mathematics}, 6\penalty0 (1):\penalty0
  4--22, 1985.

\bibitem[Lattimore \& Szepesv{\'a}ri(2020)Lattimore and
  Szepesv{\'a}ri]{lattimore2020bandit}
Lattimore, T. and Szepesv{\'a}ri, C.
\newblock \emph{Bandit algorithms}.
\newblock Cambridge University Press, 2020.

\bibitem[Magesh \& Veeravalli(2021)Magesh and
  Veeravalli]{magesh2021decentralized}
Magesh, A. and Veeravalli, V.~V.
\newblock Decentralized heterogeneous multi-player multi-armed bandits with
  non-zero rewards on collisions.
\newblock \emph{IEEE Transactions on Information Theory}, 2021.

\bibitem[Narayanan et~al.(2020)Narayanan, Ramadan, Carpenter, Liu, Liu, Qian,
  and Zhang]{narayanan2020first}
Narayanan, A., Ramadan, E., Carpenter, J., Liu, Q., Liu, Y., Qian, F., and
  Zhang, Z.-L.
\newblock A first look at commercial 5g performance on smartphones.
\newblock In \emph{Proceedings of The Web Conference 2020}, pp.\  894--905,
  2020.

\bibitem[Perchet et~al.(2013)Perchet, Rigollet,
  et~al.]{perchet_multi-armed_2013}
Perchet, V., Rigollet, P., et~al.
\newblock The multi-armed bandit problem with covariates.
\newblock \emph{Annals of statistics}, 41\penalty0 (2):\penalty0 693--721,
  2013.

\bibitem[Rosenski et~al.(2016)Rosenski, Shamir, and Szlak]{rosenski2016multi}
Rosenski, J., Shamir, O., and Szlak, L.
\newblock Multi-player bandits--a musical chairs approach.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  155--163. PMLR, 2016.

\bibitem[Slivkins et~al.(2019)]{slivkins2019introduction}
Slivkins, A. et~al.
\newblock Introduction to multi-armed bandits.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  12\penalty0 (1-2):\penalty0 1--286, 2019.

\bibitem[Tsybakov(2008)]{tsybakov_introduction_2008}
Tsybakov, A.~B.
\newblock \emph{Introduction to Nonparametric Estimation}.
\newblock Springer Publishing Company, Incorporated, 1st edition, 2008.
\newblock ISBN 0387790519.

\bibitem[Wang et~al.(2020)Wang, Proutiere, Ariu, Jedra, and
  Russo]{wang2020optimal}
Wang, P.-A., Proutiere, A., Ariu, K., Jedra, Y., and Russo, A.
\newblock Optimal algorithms for multiplayer multi-armed bandits.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pp.\  4120--4129. PMLR, 2020.

\bibitem[Wang et~al.(2022)Wang, Xie, and Lui]{wang2022multi}
Wang, X., Xie, H., and Lui, J.~C.
\newblock Multi-player multi-armed bandits with finite shareable resources
  arms: Learning algorithms \& applications.
\newblock In \emph{Proceedings of IJCAI}, 2022.

\bibitem[Wen et~al.(2017)Wen, Kveton, Valko, and Vaswani]{wen2017online}
Wen, Z., Kveton, B., Valko, M., and Vaswani, S.
\newblock Online influence maximization under independent cascade model with
  semi-bandit feedback.
\newblock In \emph{Neural Information Processing Systems}, pp.\  1--24, 2017.

\end{thebibliography}
