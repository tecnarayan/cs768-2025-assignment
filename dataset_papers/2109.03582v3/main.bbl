\begin{thebibliography}{10}

\bibitem{gretton2012kernel}
Arthur Gretton, Karsten~M Borgwardt, Malte~J Rasch, Bernhard Sch{\"o}lkopf, and
  Alexander Smola.
\newblock A kernel two-sample test.
\newblock {\em The Journal of Machine Learning Research}, 13(1):723--773, 2012.

\bibitem{zhang2012kernel}
Kun Zhang, Jonas Peters, Dominik Janzing, and Bernhard Sch{\"o}lkopf.
\newblock Kernel-based conditional independence test and application in causal
  discovery.
\newblock {\em arXiv preprint arXiv:1202.3775}, 2012.

\bibitem{scholkopf2002learning}
Bernhard Sch{\"o}lkopf, Alexander~J Smola, Francis Bach, et~al.
\newblock {\em Learning with kernels: support vector machines, regularization,
  optimization, and beyond}.
\newblock MIT press, 2002.

\bibitem{hofmann2008kernel}
Thomas Hofmann, Bernhard Sch{\"o}lkopf, and Alexander~J Smola.
\newblock Kernel methods in machine learning.
\newblock {\em The annals of statistics}, pages 1171--1220, 2008.

\bibitem{szabo2016learning}
Zolt{\'a}n Szab{\'o}, Bharath~K Sriperumbudur, Barnab{\'a}s P{\'o}czos, and
  Arthur Gretton.
\newblock Learning theory for distribution regression.
\newblock {\em The Journal of Machine Learning Research}, 17(1):5272--5311,
  2016.

\bibitem{lemercier2021distribution}
Maud Lemercier, Cristopher Salvi, Theodoros Damoulas, Edwin Bonilla, and Terry
  Lyons.
\newblock Distribution regression for sequential data.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 3754--3762. PMLR, 2021.

\bibitem{song2013kernel}
Le~Song, Kenji Fukumizu, and Arthur Gretton.
\newblock Kernel embeddings of conditional distributions: A unified kernel
  framework for nonparametric inference in graphical models.
\newblock {\em IEEE Signal Processing Magazine}, 30(4):98--111, 2013.

\bibitem{song2010nonparametric}
Le~Song, Arthur Gretton, and Carlos Guestrin.
\newblock Nonparametric tree graphical models.
\newblock In {\em Proceedings of the Thirteenth International Conference on
  Artificial Intelligence and Statistics}, pages 765--772. JMLR Workshop and
  Conference Proceedings, 2010.

\bibitem{fukumizu2013kernel}
Kenji Fukumizu, Le~Song, and Arthur Gretton.
\newblock Kernel bayes' rule: Bayesian inference with positive definite
  kernels.
\newblock {\em The Journal of Machine Learning Research}, 14(1):3753--3783,
  2013.

\bibitem{song2009hilbert}
Le~Song, Jonathan Huang, Alex Smola, and Kenji Fukumizu.
\newblock Hilbert space embeddings of conditional distributions with
  applications to dynamical systems.
\newblock In {\em Proceedings of the 26th Annual International Conference on
  Machine Learning}, pages 961--968, 2009.

\bibitem{mitrovic2018causal}
Jovana Mitrovic, Dino Sejdinovic, and Yee~Whye Teh.
\newblock Causal inference via kernel deviance measures.
\newblock {\em arXiv preprint arXiv:1804.04622}, 2018.

\bibitem{tillman2009nonlinear}
Robert~E Tillman, Arthur Gretton, and Peter Spirtes.
\newblock Nonlinear directed acyclic structure learning with weakly additive
  noise models.
\newblock In {\em NIPS}, pages 1847--1855, 2009.

\bibitem{sun2007kernel}
Xiaohai Sun, Dominik Janzing, Bernhard Sch{\"o}lkopf, and Kenji Fukumizu.
\newblock A kernel-based causal learning algorithm.
\newblock In {\em Proceedings of the 24th international conference on Machine
  learning}, pages 855--862, 2007.

\bibitem{fukumizu2007kernel}
Kenji Fukumizu, Arthur Gretton, Xiaohai Sun, and Bernhard Sch{\"o}lkopf.
\newblock Kernel measures of conditional dependence.
\newblock In {\em NIPS}, volume~20, pages 489--496, 2007.

\bibitem{park2020measure}
Junhyung Park and Krikamol Muandet.
\newblock A measure-theoretic approach to kernel conditional mean embeddings.
\newblock {\em Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem{law2018bayesian}
Ho~Chung~Leon Law, Dougal Sutherland, Dino Sejdinovic, and Seth Flaxman.
\newblock Bayesian approaches to distribution regression.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 1167--1176. PMLR, 2018.

\bibitem{muandet2012learning}
Krikamol Muandet, Kenji Fukumizu, Francesco Dinuzzo, and Bernhard
  Sch{\"o}lkopf.
\newblock Learning from distributions via support measure machines.
\newblock In {\em Advances in neural information processing systems}, pages
  10--18, 2012.

\bibitem{smola2007hilbert}
Alex Smola, Arthur Gretton, Le~Song, and Bernhard Sch{\"o}lkopf.
\newblock A hilbert space embedding for distributions.
\newblock In {\em International Conference on Algorithmic Learning Theory},
  pages 13--31. Springer, 2007.

\bibitem{lyons2014rough}
Terry Lyons.
\newblock Rough paths, signatures and the modelling of functions on streams.
\newblock {\em Proceedings of the International Congress of Mathematicians,
  Korea}, 2014.

\bibitem{bonnier2019deep}
Patric Bonnier, Patrick Kidger, I~Perez~Arribas, Cristopher Salvi, and Terry
  Lyons.
\newblock Deep signature transforms.
\newblock {\em Advances in Neural Information Processing Systems}, 2019.

\bibitem{kiraly2019kernels}
Franz~J Kir{\'a}ly and Harald Oberhauser.
\newblock Kernels for sequentially ordered data.
\newblock {\em Journal of Machine Learning Research}, 20(31):1--45, 2019.

\bibitem{cass2020computing}
Thomas Cass, Terry Lyons, Cristopher Salvi, and Weixin Yang.
\newblock The signature kernel is the solution of a goursat pde.
\newblock {\em arXiv preprint arXiv:2006.14794}, 2020.

\bibitem{Aldous81adapt}
D.~J. Aldous.
\newblock Weak convergence and general theory of processes.
\newblock {\em Unpublished draft of monograph}, 1981.

\bibitem{Pflug2012multi}
G.~C. Pflug and A.~Pichler.
\newblock A distance for multistage stochastic optimization models.
\newblock {\em SIAM J. Optim.}, 22(1):1--23, 2012.

\bibitem{Backhoff2021adapted}
J~Backhoff-Veraguas, D~Bartl, M~Beiglb\"ock, and J~Wiesel.
\newblock Estimating processes in adapted wasserstein distance.
\newblock {\em Annals of applied probability}, 2021.

\bibitem{Hoover84adapt}
D.~Hoover and J.~Keisler.
\newblock Adapted probability distributions.
\newblock {\em Trans. Amer. Math. Soc.}, 1984.

\bibitem{Backhoff2019adapted}
J~Backhoff-Veraguas, D~Bartl, M~Beiglb\"ock, and M~Eder.
\newblock Adapted wasserstein distances and stability in mathematical finance.
\newblock {\em Finance and Stochastics}, 2019.

\bibitem{backhoff2020all}
Julio Backhoff-Veraguas, Daniel Bartl, Mathias Beiglb{\"o}ck, and Manu Eder.
\newblock All adapted topologies are equal.
\newblock {\em Probability Theory and Related Fields}, 178(3):1125--1172, 2020.

\bibitem{bonnier2020adapted}
Patric Bonnier, Chong Liu, and Harald Oberhauser.
\newblock Adapted topologies and higher rank signatures.
\newblock {\em arXiv preprint arXiv:2005.08897}, 2020.

\bibitem{lyons1998differential}
Terry~J Lyons.
\newblock Differential equations driven by rough signals.
\newblock {\em Revista Matem{\'a}tica Iberoamericana}, 14(2):215--310, 1998.

\bibitem{chevyrev2018signature}
Ilya Chevyrev and Harald Oberhauser.
\newblock Signature moments to characterize laws of stochastic processes.
\newblock {\em arXiv preprint arXiv:1810.10971}, 2018.

\bibitem{sriperumbudur2010hilbert}
Bharath~K Sriperumbudur, Arthur Gretton, Kenji Fukumizu, Bernhard
  Sch{\"o}lkopf, and Gert~RG Lanckriet.
\newblock Hilbert space embeddings and metrics on probability measures.
\newblock {\em The Journal of Machine Learning Research}, 11:1517--1561, 2010.

\bibitem{sejdinovic2013equivalence}
Dino Sejdinovic, Bharath Sriperumbudur, Arthur Gretton, and Kenji Fukumizu.
\newblock Equivalence of distance-based and rkhs-based statistics in hypothesis
  testing.
\newblock {\em The Annals of Statistics}, pages 2263--2291, 2013.

\bibitem{muandet2016kernel}
Krikamol Muandet, Kenji Fukumizu, Bharath Sriperumbudur, and Bernhard
  Sch{\"o}lkopf.
\newblock Kernel mean embedding of distributions: A review and beyond.
\newblock {\em arXiv preprint arXiv:1605.09522}, 2016.

\bibitem{Christmann2008SVM}
Andreas Christmann and Ingo Steinwart.
\newblock {\em Support Vector Machines}.
\newblock Springer verlag, 2008.

\bibitem{bayer2016pricing}
Christian Bayer, Peter Friz, and Jim Gatheral.
\newblock Pricing under rough volatility.
\newblock {\em Quantitative Finance}, 16(6):887--904, 2016.

\bibitem{buehler2019deep}
H~Buehler, L~Gonon, J~Teichmann, and B~Wood.
\newblock Deep hedging.
\newblock {\em Quantitative Finance}, 19(8):1271--1291, 2019.

\bibitem{gatheral2018volatility}
Jim Gatheral, Thibault Jaisson, and Mathieu Rosenbaum.
\newblock Volatility is rough.
\newblock {\em Quantitative Finance}, 18(6):933--949, 2018.

\bibitem{gassiat2019martingale}
Paul Gassiat et~al.
\newblock On the martingale property in the rough bergomi model.
\newblock {\em Electronic Communications in Probability}, 24, 2019.

\bibitem{duncan2000stochastic}
Tyrone~E Duncan, Yaozhong Hu, and Bozenna Pasik-Duncan.
\newblock Stochastic calculus for fractional brownian motion i. theory.
\newblock {\em SIAM Journal on Control and Optimization}, 38(2):582--612, 2000.

\bibitem{longstaff2001valuing}
Francis~A Longstaff and Eduardo~S Schwartz.
\newblock Valuing american options by simulation: a simple least-squares
  approach.
\newblock {\em The review of financial studies}, 14(1):113--147, 2001.

\bibitem{li2020causal}
Yunzhu Li, Antonio Torralba, Anima Anandkumar, Dieter Fox, and Animesh Garg.
\newblock Causal discovery in physical systems from videos.
\newblock {\em Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem{shah2020hardness}
Rajen~D Shah and Jonas Peters.
\newblock The hardness of conditional independence testing and the generalised
  covariance measure.
\newblock {\em The Annals of Statistics}, 48(3):1514--1538, 2020.

\bibitem{lundborg2021conditional}
Anton~Rask Lundborg, Rajen~D Shah, and Jonas Peters.
\newblock Conditional independence testing in hilbert spaces with applications
  to functional data analysis.
\newblock {\em arXiv preprint arXiv:2101.07108}, 2021.

\bibitem{gretton2012optimal}
Arthur Gretton, Dino Sejdinovic, Heiko Strathmann, Sivaraman Balakrishnan,
  Massimiliano Pontil, Kenji Fukumizu, and Bharath~K Sriperumbudur.
\newblock Optimal kernel choice for large-scale two-sample tests.
\newblock In {\em Advances in neural information processing systems}, pages
  1205--1213. Citeseer, 2012.

\bibitem{sutherland2017}
Danica~J. Sutherland, Hsiao{-}Yu Tung, Heiko Strathmann, Soumyajit De, Aaditya
  Ramdas, Alexander~J. Smola, and Arthur Gretton.
\newblock Generative models and model criticism via optimized maximum mean
  discrepancy.
\newblock In {\em 5th International Conference on Learning Representations,
  {ICLR}}, 2017.

\bibitem{liu2020learning}
Feng Liu, Wenkai Xu, Jie Lu, Guangquan Zhang, Arthur Gretton, and Danica~J
  Sutherland.
\newblock Learning deep kernels for non-parametric two-sample tests.
\newblock In {\em International Conference on Machine Learning}, pages
  6316--6326. PMLR, 2020.

\bibitem{flaxman2016bayesian}
Seth Flaxman, Dino Sejdinovic, John~P Cunningham, and Sarah Filippi.
\newblock Bayesian learning of kernel embeddings.
\newblock In {\em Proceedings of the Thirty-Second Conference on Uncertainty in
  Artificial Intelligence}, pages 182--191, 2016.

\bibitem{hsu2018hyperparameter}
Kelvin Hsu, Richard Nock, and Fabio Ramos.
\newblock Hyperparameter learning for conditional kernel mean embeddings with
  rademacher complexity bounds.
\newblock In {\em Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pages 227--242. Springer, 2018.

\bibitem{fukumizu2004dimensionality}
Kenji Fukumizu, Francis~R Bach, and Michael~I Jordan.
\newblock Dimensionality reduction for supervised learning with reproducing
  kernel hilbert spaces.
\newblock {\em Journal of Machine Learning Research}, 5(Jan):73--99, 2004.

\bibitem{herrera2021optimal}
Calypso Herrera, Florian Krach, Pierre Ruyssen, and Josef Teichmann.
\newblock Optimal stopping via randomized neural networks.
\newblock {\em arXiv preprint arXiv:2104.13669}, 2021.

\bibitem{becker2019deep}
Sebastian Becker, Patrick Cheridito, and Arnulf Jentzen.
\newblock Deep optimal stopping.
\newblock {\em Journal of Machine Learning Research}, 20:74, 2019.

\bibitem{spirtes2000causation}
Peter Spirtes, Clark~N Glymour, Richard Scheines, and David Heckerman.
\newblock {\em Causation, prediction, and search}.
\newblock MIT press, 2000.

\bibitem{park2021LS}
J~Park and K~Muandet.
\newblock Regularised least--squares regression with infinite--dimensional
  output space.
\newblock {\em arXiv preprint arXiv:2010.10973}, 2021.

\bibitem{christmann2010universal}
Andreas Christmann and Ingo Steinwart.
\newblock Universal kernels on non-standard input spaces.
\newblock In {\em Advances in neural information processing systems}, pages
  406--414, 2010.

\bibitem{walkden2014ergodic}
Charles Walkden.
\newblock Ergodic theory.
\newblock {\em Lecture Notes University of Manchester}, 2014.

\end{thebibliography}
