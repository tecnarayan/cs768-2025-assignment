\begin{thebibliography}{31}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbasi-Yadkori et~al.(2011)Abbasi-Yadkori, P{\'a}l, and
  Szepesv{\'a}ri]{abbasi2011improved}
Y.~Abbasi-Yadkori, D.~P{\'a}l, and C.~Szepesv{\'a}ri.
\newblock Improved algorithms for linear stochastic bandits.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2312--2320, 2011.

\bibitem[Agrawal(1995)]{agrawal1995sample}
R.~Agrawal.
\newblock Sample mean based index policies by ${O}(\log n)$ regret for the
  multi-armed bandit problem.
\newblock \emph{Advances in Applied Probability}, 27\penalty0 (4):\penalty0
  1054--1078, 1995.

\bibitem[Agrawal and Goyal(2012)]{agrawal2012analysis}
S.~Agrawal and N.~Goyal.
\newblock Analysis of {T}hompson sampling for the multi-armed bandit problem.
\newblock In \emph{Conference on Learning Theory}, pages 39--1, 2012.

\bibitem[Audibert et~al.(2011)Audibert, Catoni, et~al.]{audibert2011robust}
J.-Y. Audibert, O.~Catoni, et~al.
\newblock Robust linear least squares regression.
\newblock \emph{The Annals of Statistics}, 39\penalty0 (5):\penalty0
  2766--2794, 2011.

\bibitem[Auer(2002)]{auer2002using}
P.~Auer.
\newblock Using confidence bounds for exploitation-exploration trade-offs.
\newblock \emph{Journal of Machine Learning Research}, 3\penalty0
  (Nov):\penalty0 397--422, 2002.

\bibitem[Bubeck(2010)]{bubeck2010bandits}
S.~Bubeck.
\newblock \emph{Bandits games and clustering foundations}.
\newblock PhD thesis, Universit{\'e} des Sciences et Technologie de Lille-Lille
  I, 2010.

\bibitem[Bubeck et~al.(2012)Bubeck, Cesa-Bianchi, et~al.]{bubeck2012regret}
S.~Bubeck, N.~Cesa-Bianchi, et~al.
\newblock Regret analysis of stochastic and nonstochastic multi-armed bandit
  problems.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  5\penalty0 (1):\penalty0 1--122, 2012.

\bibitem[Bubeck et~al.(2013)Bubeck, Cesa-Bianchi, and
  Lugosi]{bubeck2013bandits}
S.~Bubeck, N.~Cesa-Bianchi, and G.~Lugosi.
\newblock Bandits with heavy tail.
\newblock \emph{IEEE Transactions on Information Theory}, 59\penalty0
  (11):\penalty0 7711--7717, 2013.

\bibitem[Carpentier and Valko(2014)]{carpentier2014extreme}
A.~Carpentier and M.~Valko.
\newblock Extreme bandits.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1089--1097, 2014.

\bibitem[Chapelle and Li(2011)]{chapelle2011empirical}
O.~Chapelle and L.~Li.
\newblock An empirical evaluation of {T}hompson sampling.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2249--2257, 2011.

\bibitem[Chu et~al.(2011)Chu, Li, Reyzin, and Schapire]{chu2011contextual}
W.~Chu, L.~Li, L.~Reyzin, and R.~Schapire.
\newblock Contextual bandits with linear payoff functions.
\newblock In \emph{Proceedings of the Fourteenth International Conference on
  Artificial Intelligence and Statistics}, pages 208--214, 2011.

\bibitem[Cont and Bouchaud(2000)]{cont2000herd}
R.~Cont and J.-P. Bouchaud.
\newblock Herd behavior and aggregate fluctuations in financial markets.
\newblock \emph{Macroeconomic Dynamics}, 4\penalty0 (2):\penalty0 170--196,
  2000.

\bibitem[Dani et~al.(2008{\natexlab{a}})Dani, Hayes, and
  Kakade]{dani2008stochastic}
V.~Dani, T.~P. Hayes, and S.~M. Kakade.
\newblock Stochastic linear optimization under bandit feedback.
\newblock In \emph{Conference on Learning Theory}, pages 355--366,
  2008{\natexlab{a}}.

\bibitem[Dani et~al.(2008{\natexlab{b}})Dani, Kakade, and Hayes]{dani2008price}
V.~Dani, S.~M. Kakade, and T.~P. Hayes.
\newblock The price of bandit information for online optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  345--352, 2008{\natexlab{b}}.

\bibitem[Gittins et~al.(2011)Gittins, Glazebrook, and Weber]{gittins2011multi}
J.~Gittins, K.~Glazebrook, and R.~Weber.
\newblock \emph{Multi-armed bandit allocation indices}.
\newblock John Wiley \& Sons, 2011.

\bibitem[Hsu and Sabato(2014)]{hsu2014heavy}
D.~Hsu and S.~Sabato.
\newblock Heavy-tailed regression with a generalized median-of-means.
\newblock In \emph{International Conference on Machine Learning}, pages 37--45,
  2014.

\bibitem[Hsu and Sabato(2016)]{hsu2016loss}
D.~Hsu and S.~Sabato.
\newblock Loss minimization and parameter estimation with heavy tails.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 543--582, 2016.

\bibitem[Lai and Robbins(1985)]{lai1985asymptotically}
T.~L. Lai and H.~Robbins.
\newblock Asymptotically efficient adaptive allocation rules.
\newblock \emph{Advances in Applied Mathematics}, 6\penalty0 (1):\penalty0
  4--22, 1985.

\bibitem[Lattimore(2017)]{lattimore2017scale}
T.~Lattimore.
\newblock A scale free algorithm for stochastic bandits with bounded kurtosis.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1583--1592, 2017.

\bibitem[Lattimore et~al.(2014)Lattimore, Crammer, and
  Szepesv{\'a}ri]{lattimore2014optimal}
T.~Lattimore, K.~Crammer, and C.~Szepesv{\'a}ri.
\newblock Optimal resource allocation with semi-bandit feedback.
\newblock In \emph{Proceedings of the Thirtieth Conference on Uncertainty in
  Artificial Intelligence}, pages 477--486. AUAI Press, 2014.

\bibitem[Li et~al.(2010)Li, Chu, Langford, and Schapire]{li2010contextual}
L.~Li, W.~Chu, J.~Langford, and R.~E. Schapire.
\newblock A contextual-bandit approach to personalized news article
  recommendation.
\newblock In \emph{Proceedings of the Nineteenth International Conference on
  World Wide Web}, pages 661--670. ACM, 2010.

\bibitem[Liebeherr et~al.(2012)Liebeherr, Burchard, and
  Ciucu]{liebeherr2012delay}
J.~Liebeherr, A.~Burchard, and F.~Ciucu.
\newblock Delay bounds in communication networks with heavy-tailed and
  self-similar traffic.
\newblock \emph{IEEE Transactions on Information Theory}, 58\penalty0
  (2):\penalty0 1010--1024, 2012.

\bibitem[Medina and Yang(2016)]{medina2016no}
A.~M. Medina and S.~Yang.
\newblock No-regret algorithms for heavy-tailed linear bandits.
\newblock In \emph{International Conference on Machine Learning}, pages
  1642--1650, 2016.

\bibitem[Munos et~al.(2014)]{munos2014bandits}
R.~Munos et~al.
\newblock From bandits to monte-carlo tree search: The optimistic principle
  applied to optimization and planning.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  7\penalty0 (1):\penalty0 1--129, 2014.

\bibitem[Robbins et~al.(1952)]{robbins1952some}
H.~Robbins et~al.
\newblock Some aspects of the sequential design of experiments.
\newblock \emph{Bulletin of the American Mathematical Society}, 58\penalty0
  (5):\penalty0 527--535, 1952.

\bibitem[Roberts et~al.(2015)Roberts, Boonstra, and
  Breakspear]{roberts2015heavy}
J.~A. Roberts, T.~W. Boonstra, and M.~Breakspear.
\newblock The heavy tail of the human brain.
\newblock \emph{Current Opinion in Neurobiology}, 31:\penalty0 164--172, 2015.

\bibitem[Seldin et~al.(2012)Seldin, Laviolette, Cesa-Bianchi, Shawe-Taylor, and
  Auer]{seldin2012pac}
Y.~Seldin, F.~Laviolette, N.~Cesa-Bianchi, J.~Shawe-Taylor, and P.~Auer.
\newblock {PAC-B}ayesian inequalities for martingales.
\newblock \emph{IEEE Transactions on Information Theory}, 58\penalty0
  (12):\penalty0 7086--7093, 2012.

\bibitem[Shao and Nikias(1993)]{shao1993signal}
M.~Shao and C.~L. Nikias.
\newblock Signal processing with fractional lower order moments: stable
  processes and their applications.
\newblock \emph{Proceedings of the IEEE}, 81\penalty0 (7):\penalty0 986--1010,
  1993.

\bibitem[Thompson(1933)]{thompson1933likelihood}
W.~R. Thompson.
\newblock On the likelihood that one unknown probability exceeds another in
  view of the evidence of two samples.
\newblock \emph{Biometrika}, 25\penalty0 (3/4):\penalty0 285--294, 1933.

\bibitem[Vakili et~al.(2013)Vakili, Liu, and Zhao]{vakili2013deterministic}
S.~Vakili, K.~Liu, and Q.~Zhao.
\newblock Deterministic sequencing of exploration and exploitation for
  multi-armed bandit problems.
\newblock \emph{IEEE Journal of Selected Topics in Signal Processing},
  7\penalty0 (5):\penalty0 759--767, 2013.

\bibitem[Yu et~al.(2018)Yu, Shao, Lyu, and King]{yupure}
X.~Yu, H.~Shao, M.~R. Lyu, and I.~King.
\newblock Pure exploration of multi-armed bandits with heavy-tailed payoffs.
\newblock In \emph{Proceedings of the Thirty-Fourth Conference on Uncertainty
  in Artificial Intelligence}, pages 937--946. AUAI Press, 2018.

\end{thebibliography}
