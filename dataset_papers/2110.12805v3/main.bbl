\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agustsson \& Theis(2020)Agustsson and Theis]{agustsson2020uq}
Agustsson, E. and Theis, L.
\newblock {Universally Quantized Neural Compression}.
\newblock In \emph{Advances in Neural Information Processing Systems 33}, 2020.

\bibitem[Ball{\'e} et~al.(2017)Ball{\'e}, Laparra, and
  Simoncelli]{balle2017end}
Ball{\'e}, J., Laparra, V., and Simoncelli, E.~P.
\newblock {End-to-end Optimized Image Compression}.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Bennett \& Shor(2002)Bennett and Shor]{bennett2002reverse}
Bennett, C.~H. and Shor, P.~W.
\newblock {Entanglement-Assisted Capacity of a Quantum Channel and the Reverse
  Shannon Theorem}.
\newblock \emph{IEEE Trans. Info. Theory}, 48\penalty0 (10), 2002.

\bibitem[Braverman \& Garg(2014)Braverman and Garg]{braverman2014}
Braverman, M. and Garg, A.
\newblock Public vs private coin in bounded-round information.
\newblock In Esparza, J., Fraigniaud, P., Husfeldt, T., and Koutsoupias, E.
  (eds.), \emph{Automata, Languages, and Programming}, pp.\  502--513.
  Springer, 2014.

\bibitem[Chatterjee \& Diaconis(2018)Chatterjee and Diaconis]{chatterjee2018is}
Chatterjee, S. and Diaconis, P.
\newblock The sample size required in importance sampling.
\newblock \emph{The Annals of Applied Probability}, 28\penalty0 (2):\penalty0
  1099--1135, 2018.

\bibitem[Chen et~al.(2020)Chen, Kairouz, and Ozgur]{chen2020trilemma}
Chen, W.-N., Kairouz, P., and Ozgur, A.
\newblock Breaking the communication-privacy-accuracy trilemma.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M.~F., and Lin,
  H. (eds.), \emph{Advances in Neural Information Processing Systems},
  volume~33, pp.\  3312--3324. Curran Associates, Inc., 2020.

\bibitem[Choi et~al.(2019)Choi, El-Khamy, and Lee]{choi2019uq}
Choi, Y., El-Khamy, M., and Lee, J.
\newblock Variable rate deep image compression with a conditional autoencoder.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, 2019.

\bibitem[Cover \& Permuter(2007)Cover and Permuter]{cover2007capacity}
Cover, T.~M. and Permuter, H.~H.
\newblock Capacity of coordinated actions.
\newblock In \emph{2007 IEEE International Symposium on Information Theory},
  pp.\  2701--2705, 2007.
\newblock \doi{10.1109/ISIT.2007.4557184}.

\bibitem[Cuff(2008)]{cuff2008}
Cuff, P.
\newblock Communication requirements for generating correlated random
  variables.
\newblock In \emph{2008 IEEE International Symposium on Information Theory},
  pp.\  1393--1397, 2008.

\bibitem[Dwork et~al.(2006)Dwork, McSherry, Nissim, and Smith]{dwork2006dp}
Dwork, C., McSherry, F., Nissim, K., and Smith, A.
\newblock Calibrating noise to sensitivity in private data analysis.
\newblock In Halevi, S. and Rabin, T. (eds.), \emph{Theory of Cryptography},
  pp.\  265--284. Springer Berlin Heidelberg, 2006.

\bibitem[Flamich et~al.(2020)Flamich, Havasi, and
  Hern{\'a}ndez-Lobato]{flamich2020cwq}
Flamich, G., Havasi, M., and Hern{\'a}ndez-Lobato, J.~M.
\newblock {Compressing Images by Encoding Their Latent Representations with
  Relative Entropy Coding}, 2020.
\newblock Advances in Neural Information Processing Systems 34.

\bibitem[Gumbel(1954)]{gumbel1954}
Gumbel, E.~J.
\newblock {Statistical Theory of Extreme Values and Some Practical
  Applications}.
\newblock \emph{U.S. Department of Commerce, National Bureau of Standards}, 33,
  1954.

\bibitem[{Harsha} et~al.(2007){Harsha}, {Jain}, {McAllester}, and
  {Radhakrishnan}]{harsha2007}
{Harsha}, P., {Jain}, R., {McAllester}, D., and {Radhakrishnan}, J.
\newblock {The Communication Complexity of Correlation}.
\newblock In \emph{Twenty-Second Annual IEEE Conference on Computational
  Complexity}, pp.\  10--23, 2007.

\bibitem[Havasi et~al.(2019)Havasi, Peharz, and
  Hernández-Lobato]{havasi2018miracle}
Havasi, M., Peharz, R., and Hernández-Lobato, J.~M.
\newblock {Minimal Random Code Learning: Getting Bits Back from Compressed
  Model Parameters}.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Hinton \& Van~Camp(1993)Hinton and Van~Camp]{hinton1993bb}
Hinton, G.~E. and Van~Camp, D.
\newblock Keeping the neural networks simple by minimizing the description
  length of the weights.
\newblock In \emph{Proceedings of the sixth annual conference on Computational
  learning theory}, pp.\  5--13, 1993.

\bibitem[Kingma \& Welling(2014)Kingma and Welling]{kingma2014vae}
Kingma, D. and Welling, M.
\newblock {Auto-encoding variational Bayes}.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Leech(1967)]{leech1967}
Leech, J.
\newblock Notes on sphere packings.
\newblock \emph{Canadian Journal of Mathematics}, 19:\penalty0 251–267, 1967.

\bibitem[Li \& Anantharam(2021)Li and Anantharam]{li2021lemma}
Li, C.~T. and Anantharam, V.
\newblock A unified framework for one-shot achievability via the poisson
  matching lemma.
\newblock \emph{IEEE Transactions on Information Theory}, 67\penalty0
  (5):\penalty0 2624--2651, 2021.
\newblock \doi{10.1109/TIT.2021.3058842}.

\bibitem[Li \& El~Gamal(2017)Li and El~Gamal]{li2017dyadic}
Li, C.~T. and El~Gamal, A.
\newblock Distributed simulation of continuous random variables.
\newblock \emph{IEEE Transactions on Information Theory}, 63\penalty0
  (10):\penalty0 6329--6343, 2017.
\newblock \doi{10.1109/TIT.2017.2735438}.

\bibitem[{Li} \& {El Gamal}(2018){Li} and {El Gamal}]{li2018pfr}
{Li}, C.~T. and {El Gamal}, A.
\newblock {Strong Functional Representation Lemma and Applications to Coding
  Theorems}.
\newblock \emph{IEEE Transactions on Information Theory}, 64\penalty0
  (11):\penalty0 6967--6978, 2018.
\newblock \doi{10.1109/TIT.2018.2865570}.

\bibitem[Maddison(2016)]{maddison2016ppmc}
Maddison, C.~J.
\newblock {A Poisson process model for Monte Carlo}.
\newblock In Hazan, T., Papandreou, G., and Tarlow, D. (eds.),
  \emph{Perturbation, Optimization, and Statistics}. MIT Press, 2016.

\bibitem[Maddison et~al.(2014)Maddison, Tarlow, and Minka]{maddison2014astar}
Maddison, C.~J., Tarlow, D., and Minka, T.
\newblock {$A\ast$ Sampling}.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~27, 2014.

\bibitem[Rissanen \& Langdon(1979)Rissanen and Langdon]{rissanen1979arithmetic}
Rissanen, J. and Langdon, G.~G.
\newblock Arithmetic coding.
\newblock \emph{IBM Journal of research and development}, 23\penalty0
  (2):\penalty0 149--162, 1979.

\bibitem[Roberts(1962)]{roberts1962noise}
Roberts, L.~G.
\newblock {Picture Coding Using Pseudo-Random Noise}.
\newblock \emph{IRE Transactions on Information Theory}, 1962.

\bibitem[Rényi(1953)]{renyi1953os}
Rényi, A.
\newblock On the theory of order statistics.
\newblock \emph{Acta Mathematica Hungarica}, 4:\penalty0 191--–231, 1953.

\bibitem[Schuchman(1964)]{schuchman1964dither}
Schuchman, L.
\newblock Dither signals and their effect on quantization noise.
\newblock \emph{IEEE Transactions on Communication Technology}, 12\penalty0
  (4):\penalty0 162--165, 1964.

\bibitem[Shah et~al.(2022)Shah, Chen, Balle, Kairouz, and Theis]{shah2021dp}
Shah, A., Chen, W.-N., Balle, J., Kairouz, P., and Theis, L.
\newblock Optimal compression of locally differentially private mechanisms.
\newblock In \emph{Artificial Intelligence and Statistics}, 2022.
\newblock URL \url{https://arxiv.org/abs/2111.00092}.

\bibitem[Song et~al.(2016)Song, Cuff, and Poor]{song2016ld}
Song, E.~C., Cuff, P., and Poor, H.~V.
\newblock The likelihood encoder for lossy compression.
\newblock \emph{IEEE Transactions on Information Theory}, 62\penalty0
  (4):\penalty0 1836--1849, 2016.
\newblock \doi{10.1109/TIT.2016.2529657}.

\bibitem[Sriperumbudur et~al.(2009)Sriperumbudur, Fukumizu, Gretton,
  Schölkopf, and Lanckriet]{sriperumbudur2009integral}
Sriperumbudur, B.~K., Fukumizu, K., Gretton, A., Schölkopf, B., and Lanckriet,
  G. R.~G.
\newblock On integral probability metrics, $\phi$-divergences and binary
  classification, 2009.

\bibitem[Theis \& Agustsson(2021)Theis and Agustsson]{theis2021stochastic}
Theis, L. and Agustsson, E.
\newblock On the advantages of stochastic encoders.
\newblock In \emph{Neural Compression Workshop at ICLR 2021}, 2021.

\bibitem[Townsend et~al.(2019)Townsend, Bird, and Barber]{townsend2019bb}
Townsend, J., Bird, T., and Barber, D.
\newblock Practical lossless compression with latent variables using bits back
  coding.
\newblock \emph{arXiv preprint arXiv:1901.04866}, 2019.

\bibitem[Wallace(1990)]{wallace1990bb}
Wallace, C.~S.
\newblock Classification by minimum-message-length inference.
\newblock In \emph{International Conference on Computing and Information}, pp.\
   72--81. Springer, 1990.

\bibitem[Wyner(1975)]{wyner1975ci}
Wyner, A.
\newblock The common information of two dependent random variables.
\newblock \emph{IEEE Transactions on Information Theory}, 21\penalty0
  (2):\penalty0 163--179, 1975.
\newblock \doi{10.1109/TIT.1975.1055346}.

\bibitem[Xu et~al.(2011)Xu, Liu, and Chen]{xu2011wyner}
Xu, G., Liu, W., and Chen, B.
\newblock Wyners common information for continuous random variables - a lossy
  source coding interpretation.
\newblock In \emph{45th Annual Conference on Information Sciences and Systems},
  pp.\  1--6, 2011.
\newblock \doi{10.1109/CISS.2011.5766249}.

\bibitem[Zamir(2014)]{zamir2014book}
Zamir, R.
\newblock \emph{{Lattice Coding for Signals and Networks}}.
\newblock Cambridge University Press, 2014.

\bibitem[Zamir \& Feder(1992)Zamir and Feder]{zamir1992universal}
Zamir, R. and Feder, M.
\newblock On universal quantization by randomized uniform/lattice quantizers.
\newblock \emph{IEEE Transactions on Information Theory}, 38\penalty0
  (2):\penalty0 428--436, 1992.

\bibitem[Ziv(1985)]{ziv1985universal}
Ziv, J.
\newblock On universal quantization.
\newblock \emph{IEEE Transactions on Information Theory}, 31\penalty0
  (3):\penalty0 344--347, 1985.

\end{thebibliography}
