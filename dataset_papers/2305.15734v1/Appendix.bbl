\begin{thebibliography}{16}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Eshed(2020)]{ap_eshed_novelty_detection}
Eshed, N.
\newblock Novelty detection and analysis in convolutional neural networks.
\newblock Master's thesis, Cornell University, 2020.

\bibitem[Furlanello et~al.(2018)Furlanello, Lipton, Tschannen, Itti, and
  Anandkumar]{ap_furlanello2018born}
Furlanello, T., Lipton, Z., Tschannen, M., Itti, L., and Anandkumar, A.
\newblock Born again neural networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1607--1616. PMLR, 2018.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{ap_he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[Howard et~al.(2017)Howard, Zhu, Chen, Kalenichenko, Wang, Weyand,
  Andreetto, and Adam]{ap_howard2017mobilenets}
Howard, A.~G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T.,
  Andreetto, M., and Adam, H.
\newblock Mobilenets: Efficient convolutional neural networks for mobile vision
  applications.
\newblock \emph{arXiv preprint arXiv:1704.04861}, 2017.

\bibitem[Kim et~al.(2018)Kim, Park, and Kwak]{ap_kim2018paraphrasing}
Kim, J., Park, S., and Kwak, N.
\newblock Paraphrasing complex network: Network compression via factor
  transfer.
\newblock \emph{arXiv preprint arXiv:1802.04977}, 2018.

\bibitem[Kokhlikyan et~al.(2020{\natexlab{a}})Kokhlikyan, Miglani, Martin,
  Wang, Alsallakh, Reynolds, Melnikov, Kliushkina, Araya, Yan,
  et~al.]{ap_kokhlikyan2020captum}
Kokhlikyan, N., Miglani, V., Martin, M., Wang, E., Alsallakh, B., Reynolds, J.,
  Melnikov, A., Kliushkina, N., Araya, C., Yan, S., et~al.
\newblock Captum: A unified and generic model interpretability library for
  pytorch.
\newblock \emph{arXiv preprint arXiv:2009.07896}, 2020{\natexlab{a}}.

\bibitem[Kokhlikyan et~al.(2020{\natexlab{b}})Kokhlikyan, Miglani, Martin,
  Wang, Alsallakh, Reynolds, Melnikov, Kliushkina, Araya, Yan,
  et~al.]{kokhlikyan2020captum}
Kokhlikyan, N., Miglani, V., Martin, M., Wang, E., Alsallakh, B., Reynolds, J.,
  Melnikov, A., Kliushkina, N., Araya, C., Yan, S., et~al.
\newblock Captum: A unified and generic model interpretability library for
  pytorch.
\newblock \emph{arXiv preprint arXiv:2009.07896}, 2020{\natexlab{b}}.

\bibitem[Matsubara(2021)]{ap_matsubara2021torchdistill}
Matsubara, Y.
\newblock torchdistill: A modular, configuration-driven framework for knowledge
  distillation.
\newblock In \emph{International Workshop on Reproducible Research in Pattern
  Recognition}, pp.\  24--44. Springer, 2021.

\bibitem[Paszke et~al.(2017)Paszke, Gross, Chintala, Chanan, Yang, DeVito, Lin,
  Desmaison, Antiga, and Lerer]{ap_paszke2017automatic}
Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z.,
  Desmaison, A., Antiga, L., and Lerer, A.
\newblock Automatic differentiation in pytorch.
\newblock In \emph{NIPS-W}, 2017.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, et~al.]{ap_paszke2019pytorch}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, et~al.]{ap_russakovsky2015imagenet}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
  Karpathy, A., Khosla, A., Bernstein, M., et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{International journal of computer vision}, 115\penalty0
  (3):\penalty0 211--252, 2015.

\bibitem[Tan \& Le(2019)Tan and Le]{ap_tan2019efficientnet}
Tan, M. and Le, Q.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock In \emph{International conference on machine learning}, pp.\
  6105--6114. PMLR, 2019.

\bibitem[Tian et~al.(2019)Tian, Krishnan, and Isola]{ap_tian2019contrastive}
Tian, Y., Krishnan, D., and Isola, P.
\newblock Contrastive representation distillation.
\newblock \emph{arXiv preprint arXiv:1910.10699}, 2019.

\bibitem[Tjoa \& Guan(2020)Tjoa and Guan]{ap_tjoa2020quantifying}
Tjoa, E. and Guan, C.
\newblock Quantifying explainability of saliency methods in deep neural
  networks.
\newblock \emph{arXiv preprint arXiv:2009.02899}, 2020.

\bibitem[Xu et~al.(2020)Xu, Liu, Li, and Loy]{ap_xu2020knowledge}
Xu, G., Liu, Z., Li, X., and Loy, C.~C.
\newblock Knowledge distillation meets self-supervision.
\newblock In \emph{European Conference on Computer Vision}, pp.\  588--604.
  Springer, 2020.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and
  Komodakis]{ap_zagoruyko2016paying}
Zagoruyko, S. and Komodakis, N.
\newblock Paying more attention to attention: Improving the performance of
  convolutional neural networks via attention transfer.
\newblock \emph{arXiv preprint arXiv:1612.03928}, 2016.

\end{thebibliography}
