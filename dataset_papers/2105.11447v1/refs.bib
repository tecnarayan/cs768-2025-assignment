@ARTICLE{akaike1974new,
  author={Akaike, H.},
  journal={TACON},
  title={A new look at the statistical model identification}, 
  year={1974},
  volume={19},
  number={6},
  pages={716-723},
  doi={10.1109/TAC.1974.1100705}}
@misc{alain2018understanding,
      title={Understanding intermediate layers using linear classifier probes}, 
      author={Guillaume Alain and Yoshua Bengio},
      year={2018},
      eprint={1610.01644},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1610.01644}
}
@article{allend1974relationship,
author = { David M.   Allen },
title = {The Relationship Between Variable Selection and Data Agumentation and a Method for Prediction},
journal = {Technometrics},
volume = {16},
number = {1},
pages = {125-127},
year  = {1974},
publisher = {Taylor & Francis},
doi = {10.1080/00401706.1974.10489157},
URL = { 
        https://www.tandfonline.com/doi/abs/10.1080/00401706.1974.10489157
},
eprint = { 
        https://www.tandfonline.com/doi/pdf/10.1080/00401706.1974.10489157
}
}
@article{amodei2016concrete,
  author    = {Dario Amodei and
               Chris Olah and
               Jacob Steinhardt and
               Paul F. Christiano and
               John Schulman and
               Dan Man{\'{e}}},
  title     = {Concrete Problems in {AI} Safety},
  journal   = {CoRR},
  volume    = {abs/1606.06565},
  year      = {2016},
  url       = {http://arxiv.org/abs/1606.06565},
  archivePrefix = {arXiv},
  eprint    = {1606.06565},
  timestamp = {Mon, 13 Aug 2018 16:48:59 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/AmodeiOSCSM16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@InProceedings{antol2015vqa,
author = {Stanislaw Antol and Aishwarya Agrawal and Jiasen Lu and Margaret Mitchell and Dhruv Batra and C. Lawrence Zitnick and Devi Parikh},
title = {{VQA}: {V}isual {Q}uestion {A}nswering},
booktitle = {ICCV},
year = {2015},
}
@inproceedings{artetxe2018unsupervised-neural,
    title={Unsupervised Neural Machine Translation},
    author={Mikel Artetxe and Gorka Labaka and Eneko Agirre and Kyunghyun Cho},
    booktitle={ICLR},
    year={2018},
    url={https://openreview.net/forum?id=Sy2ogebAW},
}
@inproceedings{ba2014do,
 author = {Ba, Jimmy and Caruana, Rich},
 booktitle = {NeuRIPS},
 editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K. Q. Weinberger},
 pages = {2654--2662},
 publisher = {Curran Associates, Inc.},
 title = {Do Deep Nets Really Need to be Deep?},
 url = {https://proceedings.neurips.cc/paper/2014/file/ea8fcd92d59581717e06eb187f10666d-Paper.pdf},
 volume = {27},
 year = {2014}
}
@inproceedings{bahdanau2015jointly,
  author    = {Dzmitry Bahdanau and
               Kyunghyun Cho and
               Yoshua Bengio},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Neural Machine Translation by Jointly Learning to Align and Translate},
  booktitle = {ICLR},
  year      = {2015},
  url       = {http://arxiv.org/abs/1409.0473},
  timestamp = {Wed, 17 Jul 2019 10:40:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/BahdanauCB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@book{baker2004item,
  title={Item response theory: Parameter estimation techniques},
  author={Baker, Frank B and Kim, Seock-Ho},
  year={2004},
  publisher={CRC Press}
}
@inproceedings{bar2006second,
  title={The second {PASCAL} recognising textual entailment challenge},
  author={Bar Haim, Roy and Dagan, Ido and Dolan, Bill and Ferro, Lisa and Giampiccolo, Danilo and Magnini, Bernardo and Szpektor, Idan},
  booktitle={Second {PASCAL} Challenges Workshop on Recognising Textual Entailment},
  year={2006},
  url={https://u.cs.biu.ac.il/~szpekti/papers/RTE2-organizers.pdf}
}
@article{beltagy2020longformer,
  title={Longformer: The Long-Document Transformer},
  author={Iz Beltagy and Matthew E. Peters and Arman Cohan},
  journal={arXiv:2004.05150},
  year={2020},
  url={https://arxiv.org/abs/2004.05150}
}
@article{bengio2000gradient,
    author = {Bengio, Yoshua},
    title = "{Gradient-Based Optimization of Hyperparameters}",
    journal = {Neural Computation},
    volume = {12},
    number = {8},
    pages = {1889-1900},
    year = {2000},
    month = {08},
    abstract = "{Many machine learning algorithms can be formulated as the minimization of a training criterion that involves a hyperparameter. This hyperparameter is usually chosen by trial and error with a model selection criterion. In this article we present a methodology to optimize several hyper-parameters, based on the computation of the gradient of a model selection criterion with respect to the hyperparameters. In the case of a quadratic training criterion, the gradient of the selection criterion with respect to the hyperparameters is efficiently computed by backpropagating through a Cholesky decomposition. In the more general case, we show that the implicit function theorem can be used to derive a formula for the hyper-parameter gradient involving second derivatives of the training criterion.}",
    issn = {0899-7667},
    doi = {10.1162/089976600300015187},
    url = {https://doi.org/10.1162/089976600300015187},
    eprint = {https://direct.mit.edu/neco/article-pdf/12/8/1889/814581/089976600300015187.pdf},
}
@INPROCEEDINGS{bentivogli2009fifth,
    author = {Luisa Bentivogli and Ido Dagan and Hoa Trang Dang and Danilo Giampiccolo and Bernardo Magnini},
    title = {The Fifth PASCAL Recognizing Textual Entailment Challenge},
    booktitle = {TAC},
    year = {2009},
    url={http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.232.1231}
}
@inproceedings{bergstra2011algorithms,
 author = {Bergstra, James and Bardenet, R\'{e}mi and Bengio, Yoshua and K\'{e}gl, Bal\'{a}zs},
 booktitle = {NeuRIPS},
 editor = {J. Shawe-Taylor and R. Zemel and P. Bartlett and F. Pereira and K. Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Algorithms for Hyper-Parameter Optimization},
 url = {https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf},
 volume = {24},
 year = {2011}
}
@inproceedings{blier2018description,
 author = {Blier, L\'{e}onard and Ollivier, Yann},
 booktitle = {NeuRIPS},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {2216--2226},
 publisher = {Curran Associates, Inc.},
 title = {The Description Length of Deep Learning models},
 url = {https://proceedings.neurips.cc/paper/2018/file/3b712de48137572f3849aabd5666a4e3-Paper.pdf},
 volume = {31},
 year = {2018}
}
@article{blumer1987occam,
author = {Blumer, Alselm and Ehrenfeucht, Andrzej and Haussler, David and Warmuth, Manfred K.},
title = {Occam's Razor},
year = {1987},
issue_date = {6 April 1987},
publisher = {Elsevier North-Holland, Inc.},
address = {USA},
volume = {24},
number = {6},
issn = {0020-0190},
url = {https://doi.org/10.1016/0020-0190(87)90114-1},
doi = {10.1016/0020-0190(87)90114-1},
journal = {Inf. Process. Lett.},
month = apr,
pages = {377–380},
numpages = {4}
}
@InProceedings{brunet2019understanding, title = {Understanding the Origins of Bias in Word Embeddings}, author = {Brunet, Marc-Etienne and Alkalay-Houlihan, Colleen and Anderson, Ashton and Zemel, Richard}, booktitle = {ICML}, pages = {803--811}, year = {2019}, editor = {Kamalika Chaudhuri and Ruslan Salakhutdinov}, volume = {97}, series = {PMLR}, month = {09--15 Jun}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v97/brunet19a/brunet19a.pdf}, url = { http://proceedings.mlr.press/v97/brunet19a.html }, abstract = {Popular word embedding algorithms exhibit stereotypical biases, such as gender bias. The widespread use of these algorithms in machine learning systems can amplify stereotypes in important contexts. Although some methods have been developed to mitigate this problem, how word embedding biases arise during training is poorly understood. In this work we develop a technique to address this question. Given a word embedding, our method reveals how perturbing the training corpus would affect the resulting embedding bias. By tracing the origins of word embedding bias back to the original training documents, one can identify subsets of documents whose removal would most reduce bias. We demonstrate our methodology on Wikipedia and New York Times corpora, and find it to be very accurate.} }
@inproceedings{bolukbasi2016man,
 author = {Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James Y and Saligrama, Venkatesh and Kalai, Adam T},
 booktitle = {NeuRIPS},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {4349--4357},
 publisher = {Curran Associates, Inc.},
 title = {Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings},
 url = {https://proceedings.neurips.cc/paper/2016/file/a486cd07e4ac3d270571622f4f316ec5-Paper.pdf},
 volume = {29},
 year = {2016}
}
@misc{brown2020language,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.14165}
}
@InProceedings{buolamwini2018gender,
title = {Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification}, author = {Joy Buolamwini and Timnit Gebru}, booktitle = {Fairness, Accountability and Transparency}, pages = {77--91}, year = {2018}, editor = {Sorelle A. Friedler and Christo Wilson}, volume = {81}, series = {PMLR}, address = {New York, NY, USA}, month = {23--24 Feb}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf}, url = {http://proceedings.mlr.press/v81/buolamwini18a.html}, abstract = {Recent studies demonstrate that machine learning algorithms can discriminate based on classes like race and gender. In this work, we present an approach to evaluate bias present in automated facial analysis algorithms and datasets with respect to phenotypic subgroups. Using the dermatologist approved Fitzpatrick Skin Type classification system, we characterize the gender and skin type distribution of two facial analysis benchmarks, IJB-A and Adience. We find that these datasets are overwhelmingly composed of lighter-skinned subjects (79.6\% for IJB-A and 86.2\% for Adience) and introduce a new facial analysis dataset which is balanced by gender and skin type. We evaluate 3 commercial gender classification systems using our dataset and show that darker-skinned females are the most misclassified group (with error rates of up to 34.7\%). The maximum error rate for lighter-skinned males is 0.8\%. The substantial disparities in the accuracy of classifying darker females, lighter females, darker males, and lighter males in gender classification systems require urgent attention if commercial companies are to build genuinely fair, transparent and accountable facial analysis algorithms.} }
@article{caliskan2017semantics,
title = "Semantics derived automatically from language corpora contain human-like biases",
abstract = "Machine learning is a means to derive artificial intelligence by discovering patterns in existing data. Here, we show that applying machine learning to ordinary human language results in human-like semantic biases. We replicated a spectrum of known biases, as measured by the Implicit Association Test, using a widely used, purely statistical machine-learning model trained on a standard corpus of text from the World Wide Web. Our results indicate that text corpora contain recoverable and accurate imprints of our historic biases, whether morally neutral as toward insects or flowers, problematic as toward race or gender, or even simply veridical, reflecting the status quo distribution of gender with respect to careers or first names. Our methods hold promise for identifying and addressing sources of bias in culture, including technology.",
keywords = "cs.AI, cs.CL, cs.CY, cs.LG",
author = "Aylin Caliskan and Bryson, {Joanna J} and Arvind Narayanan",
year = "2017",
month = apr,
day = "14",
doi = "10.1126/science.aal4230",
language = "English",
volume = "356",
pages = "183--186",
journal = "Science",
issn = "0036-8075",
publisher = "American Association for the Advancement of Science",
number = "6334",
}
@inproceedings{camburu2018esnli,
 author = {Camburu, Oana-Maria and Rockt\"{a}schel, Tim and Lukasiewicz, Thomas and Blunsom, Phil},
 booktitle = {NeuRIPS},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {9539--9549},
 publisher = {Curran Associates, Inc.},
 title = {e-SNLI: Natural Language Inference with Natural Language Explanations},
 url = {https://proceedings.neurips.cc/paper/2018/file/4c7a167bb329bd92580a99ce422d6fa6-Paper.pdf},
 volume = {31},
 year = {2018}
}
@inproceedings{caruana1995learning,
 author = {Caruana, Rich},
 booktitle = {NeuRIPS},
 editor = {G. Tesauro and D. Touretzky and T. Leen},
 pages = {},
 publisher = {MIT Press},
 title = {Learning Many Related Tasks at the Same Time with Backpropagation},
 url = {https://proceedings.neurips.cc/paper/1994/file/0f840be9b8db4d3fbd5ba2ce59211f55-Paper.pdf},
 volume = {7},
 year = {1995}
}
@article{caruana1997multitask,
author = {Caruana, Rich},
title = {Multitask Learning},
year = {1997},
issue_date = {July 1997},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {28},
number = {1},
issn = {0885-6125},
url = {https://doi.org/10.1023/A:1007379606734},
doi = {10.1023/A:1007379606734},
abstract = {Multitask Learning is an approach to inductive transfer that improves
generalization by using the domain information contained in the
training signals of related tasks as an inductive bias. It
does this by learning tasks in parallel while using a shared
representation; what is learned for each task can help other tasks be
learned better. This paper reviews prior work on MTL, presents new
evidence that MTL in backprop nets discovers task relatedness without
the need of supervisory signals, and presents new results for MTL
with k-nearest neighbor and kernel regression. In this paper we
demonstrate multitask learning in three domains. We explain how
multitask learning works, and show that there are many opportunities
for multitask learning in real domains. We present an algorithm and
results for multitask learning with case-based methods like k-nearest
neighbor and kernel regression, and sketch an algorithm for multitask
learning in decision trees. Because multitask learning works, can be
applied to many different kinds of domains, and can be used with
different learning algorithms, we conjecture there will be many
opportunities for its use on real-world problems.},
journal = {Machine Learning},
month = jul,
pages = {41–75},
numpages = {35},
keywords = {multitask learning, backpropagation, k-nearest neighbor, kernel regression, generalization, supervised learning, parallel transfer, inductive transfer}
}
@article{chapelle2004choosing,
  title={Choosing Multiple Parameters for Support Vector Machines},
  author={O. Chapelle and V. Vapnik and O. Bousquet and S. Mukherjee},
  journal={Machine Learning},
  year={2004},
  volume={46},
  pages={131-159}
}
@inproceedings{chen-etal-2020-mixtext,
    title = "{M}ix{T}ext: Linguistically-Informed Interpolation of Hidden Space for Semi-Supervised Text Classification",
    author = "Chen, Jiaao  and
      Yang, Zichao  and
      Yang, Diyi",
    booktitle = "ACL",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/2020.acl-main.194",
    doi = "10.18653/v1/2020.acl-main.194",
    pages = "2147--2157",
    abstract = "This paper presents MixText, a semi-supervised learning method for text classification, which uses our newly designed data augmentation method called TMix. TMix creates a large amount of augmented training samples by interpolating text in hidden space. Moreover, we leverage recent advances in data augmentation to guess low-entropy labels for unlabeled data, hence making them as easy to use as labeled data. By mixing labeled, unlabeled and augmented data, MixText significantly outperformed current pre-trained and fined-tuned models and other state-of-the-art semi-supervised learning methods on several text classification benchmarks. The improvement is especially prominent when supervision is extremely limited. We have publicly released our code at https://github.com/GT-SALT/MixText.",
}
@inproceedings{clark-etal-2019-boolq,
    title = "{B}ool{Q}: Exploring the Surprising Difficulty of Natural Yes/No Questions",
    author = "Clark, Christopher  and
      Lee, Kenton  and
      Chang, Ming-Wei  and
      Kwiatkowski, Tom  and
      Collins, Michael  and
      Toutanova, Kristina",
    booktitle = "NAACL",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/N19-1300",
    doi = "10.18653/v1/N19-1300",
    pages = "2924--2936",
    abstract = "In this paper we study yes/no questions that are naturally occurring {---} meaning that they are generated in unprompted and unconstrained settings. We build a reading comprehension dataset, BoolQ, of such questions, and show that they are unexpectedly challenging. They often query for complex, non-factoid information, and require difficult entailment-like inference to solve. We also explore the effectiveness of a range of transfer learning baselines. We find that transferring from entailment data is more effective than transferring from paraphrase or extractive QA data, and that it, surprisingly, continues to be very beneficial even when starting from massive pre-trained language models such as BERT. Our best method trains BERT on MultiNLI and then re-trains it on our train set. It achieves 80.4{\%} accuracy compared to 90{\%} accuracy of human annotators (and 62{\%} majority-baseline), leaving a significant gap for future work.",
}
@book{cover2006elements,
author = {Cover, Thomas M. and Thomas, Joy A.},
title = {Elements of Information Theory (Wiley Series in Telecommunications and Signal Processing)},
year = {2006},
isbn = {0471241954},
publisher = {Wiley-Interscience},
address = {USA},
url={http://staff.ustc.edu.cn/~cgong821/Wiley.Interscience.Elements.of.Information.Theory.Jul.2006.eBook-DDU.pdf}
}
@InProceedings{dagan2006pascal,
author="Dagan, Ido
and Glickman, Oren
and Magnini, Bernardo",
editor="Qui{\~{n}}onero-Candela, Joaquin
and Dagan, Ido
and Magnini, Bernardo
and d'Alch{\'e}-Buc, Florence",
title="The PASCAL Recognising Textual Entailment Challenge",
booktitle="Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="177--190",
abstract="This paper describes the PASCAL Network of Excellence first Recognising Textual Entailment (RTE-1) Challenge benchmark. The RTE task is defined as recognizing, given two text fragments, whether the meaning of one text can be inferred (entailed) from the other. This application-independent task is suggested as capturing major inferences about the variability of semantic expression which are commonly needed across multiple applications. The Challenge has raised noticeable attention in the research community, attracting 17 submissions from diverse groups, suggesting the generic relevance of the task.",
isbn="978-3-540-33428-6"
}
@article{dawid1984present,
 ISSN = {00359238},
 URL = {http://www.jstor.org/stable/2981683},
 abstract = {The prequential approach is founded on the premises that the purpose of statistical inference is to make sequential probability forecasts for future observations, rather than to express information about parameters. Many traditional parametric concepts, such as consistency and efficiency, prove to have natural counterparts in this formulation, which sheds new light on these and suggests fruitful extensions.},
 author = {A. P. Dawid},
 journal = {Journal of the Royal Statistical Society. Series A (General)},
 number = {2},
 pages = {278--292},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Present Position and Potential Developments: Some Personal Views: Statistical Theory: The Prequential Approach},
 volume = {147},
 year = {1984}
}
@article{de2019commitment, title={The CommitmentBank: Investigating projection in naturally occurring discourse}, volume={23}, url={https://ojs.ub.uni-konstanz.de/sub/index.php/sub/article/view/601}, DOI={10.18148/sub/2019.v23i2.601}, abstractNote={&lt;p&gt;This paper describes a new resource, the CommitmentBank, developed for the empirical investigation of the projection of finite clausal complements. A clausal complement is said to project when its content is understood as a commitment of the speaker even though the clause occurs under the scope of an entailment canceling operator such as negation or a question. The study of projection is therefore part of the study of commitments expressed by speakers to non-asserted sentence content. The content of clausal complements has been a central case for the study of projection, as there is a long-standing claim that clause-taking predicates fall into two classes—factives and nonfactives—distinguished on the basis of whether the contents of their complements project. This claim identifies the embedding predicate as the primary determinant of the projection behavior of these contents. The CommitmentBank is a corpus of naturally occurring discourses whose final sentence contains a clause-embedding predicate under an entailment canceling operator. In this paper, we describe the CommitmentBank and present initial results of analyses designed to evaluate the factive/nonfactive distinction and to investigate additional factors which affect the projectivity of clausal complements.&lt;/p&#38;gt;}, number={2}, journal={Sinn und Bedeutung}, author={de Marneffe, Marie-Catherine and Simons, Mandy and Tonhauser, Judith}, year={2019}, month={July}, pages={107-124} }
@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "NAACL",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}
@inproceedings{dixon2018measuring,
title	= {Measuring and Mitigating Unintended Bias in Text Classification},
author	= {Lucas Dixon and John Li and Jeffrey Sorensen and Nithum Thain and Lucy Vasserman},
year	= {2018},
booktitle = {AIES},
}
@inproceedings{dodge-etal-2019-show,
    title = "Show Your Work: Improved Reporting of Experimental Results",
    author = "Dodge, Jesse  and
      Gururangan, Suchin  and
      Card, Dallas  and
      Schwartz, Roy  and
      Smith, Noah A.",
    booktitle = "EMNLP",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/D19-1224",
    doi = "10.18653/v1/D19-1224",
    pages = "2185--2194",
    abstract = "Research in natural language processing proceeds, in part, by demonstrating that new models achieve superior performance (e.g., accuracy) on held-out test data, compared to previous results. In this paper, we demonstrate that test-set performance scores alone are insufficient for drawing accurate conclusions about which model performs best. We argue for reporting additional details, especially performance on validation data obtained during model development. We present a novel technique for doing so: expected validation performance of the best-found model as a function of computation budget (i.e., the number of hyperparameter search trials or the overall training time). Using our approach, we find multiple recent model comparisons where authors would have reached a different conclusion if they had used more (or less) computation. Our approach also allows us to estimate the amount of computation required to obtain a given accuracy; applying it to several recently published results yields massive variation across papers, from hours to weeks. We conclude with a set of best practices for reporting experimental results which allow for robust future comparisons, and provide code to allow researchers to use our technique.",
}
@article{dodge2020finetuning,
  author    = {Jesse Dodge and
               Gabriel Ilharco and
               Roy Schwartz and
               Ali Farhadi and
               Hannaneh Hajishirzi and
               Noah A. Smith},
  title     = {Fine-Tuning Pretrained Language Models: Weight Initializations, Data
               Orders, and Early Stopping},
  journal   = {CoRR},
  volume    = {abs/2002.06305},
  year      = {2020},
  url       = {https://arxiv.org/abs/2002.06305},
  archivePrefix = {arXiv},
  eprint    = {2002.06305},
  timestamp = {Wed, 23 Dec 2020 10:13:20 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2002-06305.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@incollection{dubois2020learning,
      title={Learning Optimal Representations with the Decodable Information Bottleneck}, 
      author={Yann Dubois and Douwe Kiela and David J. Schwab and Ramakrishna Vedantam},
      booktitle = {NeurIPS},
      year={2020},
      url={https://arxiv.org/abs/2009.12789}
}
@article{erven2012catching,
  abstract = {Summary.  Prediction and estimation based on Bayesian model selection and model averaging, and derived methods such as the Bayesian information criterion BIC, do not always converge at the fastest possible rate. We identify the catch-up phenomenon as a novel explanation for the slow convergence of Bayesian methods, which inspires a modification of the Bayesian predictive distribution, called the switch distribution. When used as an adaptive estimator, the switch distribution does achieve optimal cumulative risk convergence rates in non-parametric density estimation and Gaussian regression problems. We show that the minimax cumulative risk is obtained under very weak conditions and without knowledge of the underlying degree of smoothness. Unlike other adaptive model selection procedures such as the Akaike information criterion AIC and leave-one-out cross-validation, BIC and Bayes factor model selection are typically statistically consistent. We show that this property is retained by the switch distribution, which thus solves the AIC–BIC dilemma for cumulative risk. The switch distribution has an efficient implementation. We compare its performance with AIC, BIC and Bayesian model selection and averaging on a regression problem with simulated data.},
  added-at = {2017-01-09T13:57:26.000+0100},
  author = {Erven, Tim van and Grünwald, Peter and de Rooij, Steven},
  biburl = {https://www.bibsonomy.org/bibtex/218dec7a8b998803fe98881cb162bf013/yourwelcome},
  doi = {10.1111/j.1467-9868.2011.01025.x},
  interhash = {720cba6f22782ab2a507f012f4b33cf4},
  intrahash = {18dec7a8b998803fe98881cb162bf013},
  issn = {1467-9868},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  keywords = {AIC, BIC, averaging, bayesian consistency, efficiency model},
  language = {en},
  month = jun,
  number = 3,
  pages = {361--417},
  shorttitle = {Catching up faster by switching sooner},
  timestamp = {2017-01-09T14:01:11.000+0100},
  title = {Catching up faster by switching sooner: a predictive approach to adaptive estimation with an application to the {AIC}–{BIC} dilemma},
  url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9868.2011.01025.x/abstract},
  urldate = {2016-12-22},
  volume = 74,
  year = 2012
}
@article{ettinger-2020-bert,
    title = "What {BERT} Is Not: Lessons from a New Suite of Psycholinguistic Diagnostics for Language Models",
    author = "Ettinger, Allyson",
    journal = "TACL",
    volume = "8",
    year = "2020",
    url = "https://www.aclweb.org/anthology/2020.tacl-1.3",
    doi = "10.1162/tacl_a_00298",
    pages = "34--48",
    abstract = "Pre-training by language modeling has become a popular and successful approach to NLP tasks, but we have yet to understand exactly what linguistic capacities these pre-training processes confer upon models. In this paper we introduce a suite of diagnostics drawn from human language experiments, which allow us to ask targeted questions about information used by language models for generating predictions in context. As a case study, we apply these diagnostics to the popular BERT model, finding that it can generally distinguish good from bad completions involving shared category or role reversal, albeit with less sensitivity than humans, and it robustly retrieves noun hypernyms, but it struggles with challenging inference and role-based event prediction{---} and, in particular, it shows clear insensitivity to the contextual impacts of negation.",
}
@article{falcon2019pytorch,
  title={PyTorch Lightning},
  author={William {Falcon et al.}},
  journal={GitHub. Note: https://github.com/PyTorchLightning/pytorch-lightning},
  volume={3},
  year={2019}
}
@article{feifei2006one,
author = {Fei-Fei, Li and Fergus, Rob and Perona, Pietro},
title = {One-Shot Learning of Object Categories},
year = {2006},
issue_date = {April 2006},
publisher = {IEEE Computer Society},
address = {USA},
volume = {28},
number = {4},
issn = {0162-8828},
url = {https://doi.org/10.1109/TPAMI.2006.79},
doi = {10.1109/TPAMI.2006.79},
abstract = {Learning visual models of object categories notoriously requires hundreds or thousands of training examples. We show that it is possible to learn much information about a category from just one, or a handful, of images. The key insight is that, rather than learning from scratch, one can take advantage of knowledge coming from previously learned categories, no matter how different these categories might be. We explore a Bayesian implementation of this idea. Object categories are represented by probabilistic models. Prior knowledge is represented as a probability density function on the parameters of these models. The posterior model for an object category is obtained by updating the prior in the light of one or more observations. We test a simple implementation of our algorithm on a database of 101 diverse object categories. We compare category models learned by an implementation of our Bayesian approach to models learned from by Maximum Likelihood (ML) and Maximum A Posteriori (MAP) methods. We find that on a database of more than 100 categories, the Bayesian approach produces informative models when the number of training examples is too small for other methods to operate successfully.},
journal = {TPAMI},
month = apr,
pages = {594–611},
numpages = {18},
keywords = {unsupervised, priors., learning, few images, object categories, Recognition, variational inference}
}
@article{ferrucci2010building,
    title={Building Watson: An Overview of the DeepQA Project}, volume={31}, url={https://www.aaai.org/ojs/index.php/aimagazine/article/view/2303}, DOI={10.1609/aimag.v31i3.2303}, abstractNote={IBM Research undertook a challenge to build a computer system that could compete at the human champion level in real time on the American TV Quiz show, Jeopardy! The extent of the challenge includes fielding a real-time automatic contestant on the show, not merely a laboratory exercise. The Jeopardy! Challenge helped us address requirements that led to the design of the DeepQA architecture and the implementation of Watson. After 3 years of intense research and development by a core team of about 20 researches, Watson is performing at human expert-levels in terms of precision, confidence and speed at the Jeopardy! Quiz show. Our results strongly suggest that DeepQA is an effective and extensible architecture that may be used as a foundation for combining, deploying, evaluating and advancing a wide range of algorithmic techniques to rapidly advance the field of QA.}, number={3}, journal={AI Magazine}, author={Ferrucci, David and Brown, Eric and Chu-Carroll, Jennifer and Fan, James and Gondek, David and Kalyanpur, Aditya A. and Lally, Adam and Murdock, J. William and Nyberg, Eric and Prager, John and Schlaefer, Nico and Welty, Chris}, year={2010}, month={Jul.}, pages={59-79}
}
@inproceedings{finn2017model,
  abstract = {We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.},
  added-at = {2020-06-08T20:19:25.000+0200},
  author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  biburl = {https://www.bibsonomy.org/bibtex/2bfcc4bf2d65068f80a55bd06a34c9126/jaeschke},
  booktitle = {ICML},
  interhash = {52c1ed07488c96d0a0d4f19d1c4d635f},
  intrahash = {bfcc4bf2d65068f80a55bd06a34c9126},
  keywords = {few-shot learning machine ml},
  location = {Sydney, NSW, Australia},
  numpages = {10},
  pages = {1126--1135},
  publisher = {JMLR.org},
  series = {ICML’17},
  timestamp = {2020-06-08T20:19:25.000+0200},
  title = {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
  url = {https://dl.acm.org/doi/10.5555/3305381.3305498},
  volume = 70,
  year = 2017
}
@inproceedings{foo2008efficient,
 author = {Foo, Chuan-sheng and B., Chuong and Ng, Andrew},
 booktitle = {NeuRIPS},
 editor = {J. Platt and D. Koller and Y. Singer and S. Roweis},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Efficient multiple hyperparameter learning for log-linear models},
 url = {https://proceedings.neurips.cc/paper/2007/file/851ddf5058cf22df63d3344ad89919cf-Paper.pdf},
 volume = {20},
 year = {2008}
}
@article{gao2020making,
  title={Making Pre-trained Language Models Better Few-shot Learners},
  author={Gao, Tianyu and Fisch, Adam and Chen, Danqi},
  journal={arXiv preprint arXiv:2012.15723},
  year={2020}
}
@article{garcia2015comprehensive,
  author  = {Javier Garc{{\'i}}a and Fern and o Fern{{\'a}}ndez},
  title   = {A Comprehensive Survey on Safe Reinforcement Learning},
  journal = {JMLR},
  year    = {2015},
  volume  = {16},
  number  = {42},
  pages   = {1437-1480},
  url     = {http://jmlr.org/papers/v16/garcia15a.html}
}
@article{gebru2018datasheets,
  author    = {Timnit Gebru and
               Jamie Morgenstern and
               Briana Vecchione and
               Jennifer Wortman Vaughan and
               Hanna M. Wallach and
               Hal Daum{\'{e}} III and
               Kate Crawford},
  title     = {Datasheets for Datasets},
  journal   = {CoRR},
  volume    = {abs/1803.09010},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.09010},
  archivePrefix = {arXiv},
  eprint    = {1803.09010},
  timestamp = {Mon, 20 Aug 2018 15:16:09 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1803-09010.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{geisser1975predictive,
 ISSN = {01621459},
 URL = {http://www.jstor.org/stable/2285815},
 abstract = {An account is given of a recently devised method of prediction based on sample reuse techniques. It is most useful in low structure data paradigms that involve minimal assumptions. A series of applications demonstrating the technique is presented.},
 author = {Seymour Geisser},
 journal = {Journal of the American Statistical Association},
 number = {350},
 pages = {320--328},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {The Predictive Sample Reuse Method with Applications},
 volume = {70},
 year = {1975}
}
@inproceedings{giampiccolo2007pascal,
author = {Giampiccolo, Danilo and Magnini, Bernardo and Dagan, Ido and Dolan, Bill},
title = {The Third PASCAL Recognizing Textual Entailment Challenge},
year = {2007},
publisher = {ACL},
address = {USA},
abstract = {This paper presents the Third PASCAL Recognising Textual Entailment Challenge (RTE-3), providing an overview of the dataset creating methodology and the submitted systems. In creating this year's dataset, a number of longer texts were introduced to make the challenge more oriented to realistic scenarios. Additionally, a pool of resources was offered so that the participants could share common tools. A pilot task was also set up, aimed at differentiating unknown entailments from identified contradictions and providing justifications for overall system decisions. 26 participants submitted 44 runs, using different approaches and generally presenting new entailment models and achieving higher scores than in the previous challenges.},
booktitle = {ACL-PASCAL Workshop on Textual Entailment and Paraphrasing},
pages = {1–9},
numpages = {9},
location = {Prague, Czech Republic},
series = {RTE '07}
}
@article{goh2021multimodal,
  author = {Goh, Gabriel and †, Nick Cammarata and †, Chelsea Voss and Carter, Shan and Petrov, Michael and Schubert, Ludwig and Radford, Alec and Olah, Chris},
  title = {Multimodal Neurons in Artificial Neural Networks},
  journal = {Distill},
  year = {2021},
  note = {https://distill.pub/2021/multimodal-neurons},
  doi = {10.23915/distill.00030}
}
@article{grunwald2004tutorial,
author = {Grünwald, Peter},
year = {2004},
month = {06},
pages = {},
title = {A Tutorial Introduction to the Minimum Description Length Principle},
volume = {math.ST/0406077},
journal = {CoRR},
url={https://arxiv.org/abs/math/0406077}
}
@inproceedings{guo2017calibration,
author = {Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q.},
title = {On Calibration of Modern Neural Networks},
year = {2017},
publisher = {JMLR.org},
abstract = {Confidence calibration - the problem of predicting probability estimates representative of the true correctness likelihood - is important for classification models in many applications. We discover that modern neural networks, unlike those from a decade ago, are poorly calibrated. Through extensive experiments, we observe that depth, width, weight decay, and Batch Normalization are important factors influencing calibration. We evaluate the performance of various post-processing calibration methods on state-of-the-art architectures with image and document classification datasets. Our analysis and experiments not only offer insights into neural network learning, but also provide a simple and straightforward recipe for practical settings: on most datasets, temperature scaling - a single-parameter variant of Platt Scaling - is surprisingly effective at calibrating predictions.},
booktitle = {ICML},
pages = {1321–1330},
numpages = {10},
location = {Sydney, NSW, Australia},
series = {ICML'17},
url={http://proceedings.mlr.press/v70/guo17a.html}
}
@misc{gupta2021bert,
      title={BERT \& Family Eat Word Salad: Experiments with Text Understanding}, 
      author={Ashim Gupta and Giorgi Kvernadze and Vivek Srikumar},
      year={2021},
      eprint={2101.03453},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2101.03453}
}
@article{han2015deep,
  title={Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding},
  author={Han, Song and Mao, Huizi and Dally, William J},
  journal={ICLR},
  year={2016}
}
@inproceedings{henderson2018ethical,
author = {Henderson, Peter and Sinha, Koustuv and Angelard-Gontier, Nicolas and Ke, Nan Rosemary and Fried, Genevieve and Lowe, Ryan and Pineau, Joelle},
title = {Ethical Challenges in Data-Driven Dialogue Systems},
year = {2018},
isbn = {9781450360128},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278721.3278777},
doi = {10.1145/3278721.3278777},
abstract = {The use of dialogue systems as a medium for human-machine interaction is an increasingly prevalent paradigm. A growing number of dialogue systems use conversation strategies that are learned from large datasets. There are well documented instances where interactions with these system have resulted in biased or even offensive conversations due to the data-driven training process. Here, we highlight potential ethical issues that arise in dialogue systems research, including: implicit biases in data-driven systems, the rise of adversarial examples, potential sources of privacy violations, safety concerns, special considerations for reinforcement learning systems, and reproducibility concerns. We also suggest areas stemming from these issues that deserve further investigation. Through this initial survey, we hope to spur research leading to robust, safe, and ethically sound dialogue systems.},
booktitle = {AAAI/ACM Conference on AI, Ethics, and Society},
pages = {123–129},
numpages = {7},
keywords = {security, bias, machine learning, adversarial examples, reproducibility, ethics and safety, reinforcement learning, dialogue systems, privacy, computers and society, natural language processing},
location = {New Orleans, LA, USA},
series = {AIES '18}
}
@article{hendrycks2021natural,
  title={Natural Adversarial Examples},
  author={Dan Hendrycks and Kevin Zhao and Steven Basart and Jacob Steinhardt and Dawn Song},
  journal={CVPR},
  year={2021}
}
@inproceedings{hinton1993keeping,
author = {Hinton, Geoffrey E. and van Camp, Drew},
title = {Keeping the Neural Networks Simple by Minimizing the Description Length of the Weights},
year = {1993},
isbn = {0897916115},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/168304.168306},
doi = {10.1145/168304.168306},
booktitle = {COLT},
pages = {5–13},
numpages = {9},
location = {Santa Cruz, California, USA},
series = {COLT '93}
}
@inproceedings{holtzman2020curious,
title={The Curious Case of Neural Text Degeneration},
author={Ari Holtzman and Jan Buys and Li Du and Maxwell Forbes and Yejin Choi},
booktitle={ICLR},
year={2020},
url={https://openreview.net/forum?id=rygGQyrFvH}
}
@unpublished{honnibal2017spacy,
    AUTHOR = {Honnibal, Matthew and Montani, Ines},
    TITLE  = {{spaCy 2}: Natural language understanding with {B}loom embeddings, convolutional neural networks and incremental parsing},
    YEAR   = {2017},
    Note   = {To appear},
    url    = {https://github.com/explosion/spaCy}
}
@InProceedings{hutter2011sequential,
author="Hutter, Frank
and Hoos, Holger H.
and Leyton-Brown, Kevin",
editor="Coello, Carlos A. Coello",
title="Sequential Model-Based Optimization for General Algorithm Configuration",
booktitle="Learning and Intelligent Optimization",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="507--523",
abstract="State-of-the-art algorithms for hard computational problems often expose many parameters that can be modified to improve empirical performance. However, manually exploring the resulting combinatorial space of parameter settings is tedious and tends to lead to unsatisfactory outcomes. Recently, automated approaches for solving this algorithm configuration problem have led to substantial improvements in the state of the art for solving various problems. One promising approach constructs explicit regression models to describe the dependence of target algorithm performance on parameter settings; however, this approach has so far been limited to the optimization of few numerical algorithm parameters on single instances. In this paper, we extend this paradigm for the first time to general algorithm configuration problems, allowing many categorical parameters and optimization for sets of instances. We experimentally validate our new algorithm configuration procedure by optimizing a local search and a tree search solver for the propositional satisfiability problem (SAT), as well as the commercial mixed integer programming (MIP) solver CPLEX. In these experiments, our procedure yielded state-of-the-art performance, and in many cases outperformed the previous best configuration approach.",
isbn="978-3-642-25566-3"
}
@article{jiang-etal-2020-know,
    title = "How Can We Know What Language Models Know?",
    author = "Jiang, Zhengbao  and
      Xu, Frank F.  and
      Araki, Jun  and
      Neubig, Graham",
    journal = "TACL",
    volume = "8",
    year = "2020",
    url = "https://www.aclweb.org/anthology/2020.tacl-1.28",
    doi = "10.1162/tacl_a_00324",
    pages = "423--438",
    abstract = "Recent work has presented intriguing results examining the knowledge contained in language models (LMs) by having the LM fill in the blanks of prompts such as {``}Obama is a {\_}{\_} by profession{''}. These prompts are usually manually created, and quite possibly sub-optimal; another prompt such as {``}Obama worked as a {\_}{\_} {''} may result in more accurately predicting the correct profession. Because of this, given an inappropriate prompt, we might fail to retrieve facts that the LM does know, and thus any given prompt only provides a lower bound estimate of the knowledge contained in an LM. In this paper, we attempt to more accurately estimate the knowledge contained in LMs by automatically discovering better prompts to use in this querying process. Specifically, we propose mining-based and paraphrasing-based methods to automatically generate high-quality and diverse prompts, as well as ensemble methods to combine answers from different prompts. Extensive experiments on the LAMA benchmark for extracting relational knowledge from LMs demonstrate that our methods can improve accuracy from 31.1{\%} to 39.6{\%}, providing a tighter lower bound on what LMs know. We have released the code and the resulting LM Prompt And Query Archive (LPAQA) at https://github.com/jzbjyb/LPAQA.",
}
@article{johnson2017clevr,
  title={CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning},
  author={J. Johnson and B. Hariharan and Laurens van der Maaten and Li Fei-Fei and C. L. Zitnick and Ross B. Girshick},
  journal={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017},
  pages={1988-1997},
  url={https://arxiv.org/abs/1612.06890}
}
@InProceedings{joulin2017bag,
  title={Bag of Tricks for Efficient Text Classification},
  author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Mikolov, Tomas},
  booktitle={EACL: Short Papers},
  month={April},
  year={2017},
  publisher={ACL},
  pages={427--431},
  url={https://arxiv.org/abs/1607.01759}
}
@inproceedings{khashabi2018looking,
  title={Looking beyond the surface: A challenge set for reading comprehension over multiple sentences},
  author={Khashabi, Daniel and Chaturvedi, Snigdha and Roth, Michael and Upadhyay, Shyam and Roth, Dan},
  booktitle={NAACL},
  year={2018},
  publisher = {ACL},
  url={https://www.aclweb.org/anthology/papers/N/N18/N18-1023/}
}
@article{khatri2018advancing,
  author    = {Chandra Khatri and
               Behnam Hedayatnia and
               Anu Venkatesh and
               Jeff Nunn and
               Yi Pan and
               Qing Liu and
               Han Song and
               Anna Gottardi and
               Sanjeev Kwatra and
               Sanju Pancholi and
               Ming Cheng and
               Qinglang Chen and
               Lauren Stubel and
               Karthik Gopalakrishnan and
               Kate Bland and
               Raefer Gabriel and
               Arindam Mandal and
               Dilek Hakkani{-}T{\"{u}}r and
               Gene Hwang and
               Nate Michel and
               Eric King and
               Rohit Prasad},
  title     = {Advancing the State of the Art in Open Domain Dialog Systems through
               the Alexa Prize},
  journal   = {CoRR},
  volume    = {abs/1812.10757},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.10757},
  archivePrefix = {arXiv},
  eprint    = {1812.10757},
  timestamp = {Tue, 29 Sep 2020 17:29:53 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1812-10757.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{kingma2015adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {ICLR},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6980},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{kocijan-etal-2019-surprisingly,
    title = "A Surprisingly Robust Trick for the {W}inograd Schema Challenge",
    author = "Kocijan, Vid  and
      Cretu, Ana-Maria  and
      Camburu, Oana-Maria  and
      Yordanov, Yordan  and
      Lukasiewicz, Thomas",
    booktitle = "ACL",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/P19-1478",
    doi = "10.18653/v1/P19-1478",
    pages = "4837--4842",
    abstract = "The Winograd Schema Challenge (WSC) dataset WSC273 and its inference counterpart WNLI are popular benchmarks for natural language understanding and commonsense reasoning. In this paper, we show that the performance of three language models on WSC273 consistently and robustly improves when fine-tuned on a similar pronoun disambiguation problem dataset (denoted WSCR). We additionally generate a large unsupervised WSC-like dataset. By fine-tuning the BERT language model both on the introduced and on the WSCR dataset, we achieve overall accuracies of 72.5{\%} and 74.7{\%} on WSC273 and WNLI, improving the previous state-of-the-art solutions by 8.8{\%} and 9.6{\%}, respectively. Furthermore, our fine-tuned models are also consistently more accurate on the {``}complex{''} subsets of WSC273, introduced by Trichelair et al. (2018).",
}
@InProceedings{koh2017understanding, title = {Understanding Black-box Predictions via Influence Functions}, author = {Pang Wei Koh and Percy Liang}, booktitle = {ICML}, pages = {1885--1894}, year = {2017}, editor = {Doina Precup and Yee Whye Teh}, volume = {70}, series = {PMLR}, address = {International Convention Centre, Sydney, Australia}, month = {06--11 Aug}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v70/koh17a/koh17a.pdf}, url = {http://proceedings.mlr.press/v70/koh17a.html}, abstract = {How can we explain the predictions of a black-box model? In this paper, we use influence functions — a classic technique from robust statistics — to trace a model’s prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction. To scale up influence functions to modern machine learning settings, we develop a simple, efficient implementation that requires only oracle access to gradients and Hessian-vector products. We show that even on non-convex and non-differentiable models where the theory breaks down, approximations to influence functions can still provide valuable information. On linear models and convolutional neural networks, we demonstrate that influence functions are useful for multiple purposes: understanding model behavior, debugging models, detecting dataset errors, and even creating visually-indistinguishable training-set attacks.} }
@article{kolmogorov1963tables,
 ISSN = {0581572X},
 URL = {http://www.jstor.org/stable/25049284},
 author = {A. N. Kolmogorov},
 journal = {Sankhyā: The Indian Journal of Statistics, Series A (1961-2002)},
 number = {4},
 pages = {369--376},
 publisher = {Springer},
 title = {On Tables of Random Numbers},
 volume = {25},
 year = {1963}
}
@article{kolmogorov1968three,
  title={Three approaches to the quantitative definition of information},
  author={Kolmogorov, Andrei Nikolaevic},
  journal={International journal of computer mathematics},
  volume={2},
  number={1-4},
  pages={157--168},
  year={1968},
  publisher={Taylor \& Francis},
  url={https://www.tandfonline.com/doi/abs/10.1080/00207166808803030}
}
@article{lake2011one,
  title={One shot learning of simple visual concepts},
  author={B. Lake and R. Salakhutdinov and J. Gross and J. Tenenbaum},
  journal={Cognitive Science},
  year={2011},
  volume={33}
}
@article{lake2017building,
    title={Building machines that learn and think like people}, volume={40}, DOI={10.1017/S0140525X16001837}, journal={Behavioral and Brain Sciences}, publisher={Cambridge University Press}, author={Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.}, year={2017}, pages={e253},
    url={https://arxiv.org/abs/1604.00289}
}
@inproceedings{lample2018unsupervised,
    title={Unsupervised Machine Translation Using Monolingual Corpora Only},
    author={Guillaume Lample and Alexis Conneau and Ludovic Denoyer and Marc'Aurelio Ranzato},
    booktitle={ICLR},
    year={2018},
    url={https://openreview.net/forum?id=rkYTTf-AZ},
}
@inproceedings{lample2019cross,
  title={Cross-lingual Language Model Pretraining},
  author={Lample, Guillaume and Conneau, Alexis},
  booktitle={NeurIPS},
  year={2019},
  url= {https://arxiv.org/abs/1901.07291}
}
@inproceedings{lan2020albert,
title={ALBERT: A Lite BERT for Self-supervised Learning of Language Representations},
author={Zhenzhong Lan and Mingda Chen and Sebastian Goodman and Kevin Gimpel and Piyush Sharma and Radu Soricut},
booktitle={ICLR},
year={2020},
url={https://openreview.net/forum?id=H1eA7AEtvS}
}
@inproceedings{larochelle2008zero,
author = {Larochelle, Hugo and Erhan, Dumitru and Bengio, Y.},
year = {2008},
month = {01},
pages = {646-651},
title = {Zero-data Learning of New Tasks.},
volume = {2},
journal = {National Conference on Artificial Intelligence}
}
@INPROCEEDINGS{larsen1996design,
  author={Larsen, J. and Hansen, L.K. and Svarer, C. and Ohlsson, M.},
  booktitle={Neural Networks for Signal Processing VI. IEEE Signal Processing Society Workshop}, 
  title={Design and regularization of neural networks: the optimal use of a validation set}, 
  year={1996},
  volume={},
  number={},
  pages={62-71},
  doi={10.1109/NNSP.1996.548336}}
@inproceedings{levesque2012winograd,
author = {Levesque, Hector J. and Davis, Ernest and Morgenstern, Leora},
title = {The Winograd Schema Challenge},
year = {2012},
isbn = {9781577355601},
publisher = {AAAI Press},
abstract = {In this paper, we present an alternative to the Turing Test that has some conceptual and practical advantages. A Wino-grad schema is a pair of sentences that differ only in one or two words and that contain a referential ambiguity that is resolved in opposite directions in the two sentences. We have compiled a collection of Winograd schemas, designed so that the correct answer is obvious to the human reader, but cannot easily be found using selectional restrictions or statistical techniques over text corpora. A contestant in the Winograd Schema Challenge is presented with a collection of one sentence from each pair, and required to achieve human-level accuracy in choosing the correct disambiguation.},
booktitle = {KR},
pages = {552–561},
numpages = {10},
location = {Rome, Italy},
series = {KR'12},
url={https://cs.nyu.edu/faculty/davise/papers/WSKR2012.pdf}
}
@book{li1997introduction,
author = {Li, Ming and Vit\'{a}nyi, Paul},
title = {An Introduction to Kolmogorov Complexity and Its Applications (2nd Ed.)},
year = {1997},
isbn = {0387948686},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg}
}
@article{li2017learning,
  title={Learning to Optimize},
  author={Ke Li and Jitendra Malik},
  journal={arXiv},
  year={2017},
  volume={abs/1606.01885}
}
@inproceedings{li2018measuring,
  title={Measuring the Intrinsic Dimension of Objective Landscapes},
  author={Li, Chunyuan and Farkhoor, Heerad and Liu, Rosanne and Yosinski, Jason},
  booktitle={ICLR},
  year={2018}
}
@misc{li2021prefixtuning,
      title={Prefix-Tuning: Optimizing Continuous Prompts for Generation}, 
      author={Xiang Lisa Li and Percy Liang},
      year={2021},
      eprint={2101.00190},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{liu2019roberta,
  author    = {Yinhan Liu and
               Myle Ott and
               Naman Goyal and
               Jingfei Du and
               Mandar Joshi and
               Danqi Chen and
               Omer Levy and
               Mike Lewis and
               Luke Zettlemoyer and
               Veselin Stoyanov},
  title     = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
  journal   = {CoRR},
  volume    = {abs/1907.11692},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.11692},
  archivePrefix = {arXiv},
  eprint    = {1907.11692},
  timestamp = {Thu, 01 Aug 2019 08:59:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-11692.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{liu2018darts,
title={{DARTS}: Differentiable Architecture Search},
author={Hanxiao Liu and Karen Simonyan and Yiming Yang},
booktitle={ICLR},
year={2019},
url={https://openreview.net/forum?id=S1eYHoC5FX},
}
@inproceedings{liu-etal-2019-multi,
    title = "Multi-Task Deep Neural Networks for Natural Language Understanding",
    author = "Liu, Xiaodong  and
      He, Pengcheng  and
      Chen, Weizhu  and
      Gao, Jianfeng",
    booktitle = "ACL",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/P19-1441",
    doi = "10.18653/v1/P19-1441",
    pages = "4487--4496",
    abstract = "In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks. MT-DNN not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations to help adapt to new tasks and domains. MT-DNN extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as BERT (Devlin et al., 2018). MT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI, SciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.7{\%} (2.2{\%} absolute improvement) as of February 25, 2019 on the latest GLUE test set. We also demonstrate using the SNLI and SciTail datasets that the representations learned by MT-DNN allow domain adaptation with substantially fewer in-domain labels than the pre-trained BERT representations. Our code and pre-trained models will be made publicly available.",
}
@misc{liu2021makes,
      title={What Makes Good In-Context Examples for GPT-$3$?}, 
      author={Jiachang Liu and Dinghan Shen and Yizhe Zhang and Bill Dolan and Lawrence Carin and Weizhu Chen},
      year={2021},
      eprint={2101.06804},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{liu2021gpt,
      title={GPT Understands, Too}, 
      author={Xiao Liu and Yanan Zheng and Zhengxiao Du and Ming Ding and Yujie Qian and Zhilin Yang and Jie Tang},
      year={2021},
      eprint={2103.10385},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{liu2021what,
  title={What Makes Good In-Context Examples for GPT-3?},
  author={Jiachang Liu and Dinghan Shen and Yizhe Zhang and Bill Dolan and L. Carin and W. Chen},
  journal={arXiv},
  year={2021},
  volume={abs/2101.06804}
}
@inproceedings{lovering2021predicting,
title={Predicting Inductive Biases of Pre-Trained Models},
author={Charles Lovering and Rohan Jha and Tal Linzen and Ellie Pavlick},
booktitle={ICLR},
year={2021},
url={https://openreview.net/forum?id=mNtmhaDkAr}
}
@misc{lu2021fantastically,
      title={Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity}, 
      author={Yao Lu and Max Bartolo and Alastair Moore and Sebastian Riedel and Pontus Stenetorp},
      year={2021},
      eprint={2104.08786},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{mallows1973some,
 ISSN = {00401706},
 URL = {http://www.jstor.org/stable/1267380},
 abstract = {We discuss the interpretation of CP-plots and show how they can be calibrated in several ways. We comment on the practice of using the display as a basis for formal selection of a subset-regression model, and extend the range of application of the device to encompass arbitrary linear estimates of the regression coefficients, for example Ridge estimates.},
 author = {C. L. Mallows},
 journal = {Technometrics},
 number = {4},
 pages = {661--675},
 publisher = {[Taylor & Francis, Ltd., American Statistical Association, American Society for Quality]},
 title = {Some Comments on CP},
 volume = {15},
 year = {1973}
}
@article{martinez2019item,
title = "Item response theory in AI: Analysing machine learning classifiers at the instance level",
journal = "Artificial Intelligence",
volume = "271",
pages = "18 - 42",
year = "2019",
issn = "0004-3702",
doi = "https://doi.org/10.1016/j.artint.2018.09.004",
url = "http://www.sciencedirect.com/science/article/pii/S0004370219300220",
author = "Fernando Martínez-Plumed and Ricardo B.C. Prudêncio and Adolfo Martínez-Usó and José Hernández-Orallo",
keywords = "Artificial intelligence evaluation, Item response theory, Machine learning, Instance hardness, Classifier metrics",
abstract = "AI systems are usually evaluated on a range of problem instances and compared to other AI systems that use different strategies. These instances are rarely independent. Machine learning, and supervised learning in particular, is a very good example of this. Given a machine learning model, its behaviour for a single instance cannot be understood in isolation but rather in relation to the rest of the data distribution or dataset. In a dual way, the results of one machine learning model for an instance can be analysed in comparison to other models. While this analysis is relative to a population or distribution of models, it can give much more insight than an isolated analysis. Item response theory (IRT) combines this duality between items and respondents to extract latent variables of the items (such as discrimination or difficulty) and the respondents (such as ability). IRT can be adapted to the analysis of machine learning experiments (and by extension to any other artificial intelligence experiments). In this paper, we see that IRT suits classification tasks perfectly, where instances correspond to items and classifiers correspond to respondents. We perform a series of experiments with a range of datasets and classification methods to fully understand what the IRT parameters such as discrimination, difficulty and guessing mean for classification instances (and their relation to instance hardness measures) and how the estimated classifier ability can be used to compare classifier performance in a different way through classifier characteristic curves."
}
@article{mccann2018decanlp,
  title={The Natural Language Decathlon: Multitask Learning as Question Answering},
  author={Bryan McCann and Nitish Shirish Keskar and Caiming Xiong and Richard Socher},
  journal={arXiv preprint arXiv:1806.08730},
  year={2018}
}
@inproceedings{micikevicius2018mixed,
    title={Mixed Precision Training},
    author={Paulius Micikevicius and Sharan Narang and Jonah Alben and Gregory Diamos and Erich Elsen and David Garcia and Boris Ginsburg and Michael Houston and Oleksii Kuchaiev and Ganesh Venkatesh and Hao Wu},
    booktitle={ICLR},
    year={2018},
    url={https://openreview.net/forum?id=r1gs9JgRZ},
}
@incollection{miikkulainen2019evolving,
title = {Chapter 15 - Evolving Deep Neural Networks},
editor = {Robert Kozma and Cesare Alippi and Yoonsuck Choe and Francesco Carlo Morabito},
booktitle = {Artificial Intelligence in the Age of Neural Networks and Brain Computing},
publisher = {Academic Press},
pages = {293-312},
year = {2019},
isbn = {978-0-12-815480-9},
doi = {https://doi.org/10.1016/B978-0-12-815480-9.00015-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128154809000153},
author = {Risto Miikkulainen and Jason Liang and Elliot Meyerson and Aditya Rawal and Daniel Fink and Olivier Francon and Bala Raju and Hormoz Shahrzad and Arshak Navruzyan and Nigel Duffy and Babak Hodjat},
keywords = {Deep Learning, Evolutionary Computation, Gated Recurrent Networks, Image Captioning, Language Modeling, Neural Architecture Search, Neural Networks, Neuroevolution, Object Recognition},
abstract = {The success of deep learning depends on finding an architecture to fit the task. As deep learning has scaled up to more challenging tasks, the architectures have become difficult to design by hand. This paper proposes an automated method, CoDeepNEAT, for optimizing deep learning architectures through evolution. By extending existing neuroevolution methods to topology, components, and hyperparameters, this method achieves results comparable to best human designs in standard benchmarks in object recognition and language modeling. It also supports building a real-world application of automated image captioning on a magazine website. Given the anticipated increases in available computing power, evolution of deep networks is promising approach to constructing deep learning applications in the future.}
}
@article{oliver2018realistic,
  author    = {Avital Oliver and
               Augustus Odena and
               Colin Raffel and
               Ekin D. Cubuk and
               Ian J. Goodfellow},
  title     = {Realistic Evaluation of Deep Semi-Supervised Learning Algorithms},
  journal   = {CoRR},
  volume    = {abs/1804.09170},
  year      = {2018},
  url       = {http://arxiv.org/abs/1804.09170},
  archivePrefix = {arXiv},
  eprint    = {1804.09170},
  timestamp = {Mon, 13 Aug 2018 16:46:38 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1804-09170.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@incollection{paszke2019pytorch,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {NeuRIPS},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}
@article{perez2018film,
title={FiLM: Visual Reasoning with a General Conditioning Layer},
volume={32}, url={https://ojs.aaai.org/index.php/AAAI/article/view/11671},
abstractNote={ &lt;p&gt; We introduce a general-purpose conditioning method for neural networks called FiLM: Feature-wise Linear Modulation. FiLM layers influence neural network computation via a simple, feature-wise affine transformation based on conditioning information. We show that FiLM layers are highly effective for visual reasoning - answering image-related questions which require a multi-step, high-level process - a task which has proven difficult for standard deep learning methods that do not explicitly model reasoning. Specifically, we show on visual reasoning tasks that FiLM layers 1) halve state-of-the-art error for the CLEVR benchmark, 2) modulate features in a coherent manner, 3) are robust to ablations and architectural modifications, and 4) generalize well to challenging, new data from few examples or even zero-shot. &lt;/p&gt; },
number={1},
journal={AAAI},
author={Perez, Ethan and Strub, Florian and de Vries, Harm and Dumoulin, Vincent and Courville, Aaron},
year={2018},
month={Apr.}
}
@inproceedings{perez-etal-2020-unsupervised,
    title = "Unsupervised Question Decomposition for Question Answering",
    author = "Perez, Ethan  and
      Lewis, Patrick  and
      Yih, Wen-tau  and
      Cho, Kyunghyun  and
      Kiela, Douwe",
    booktitle = "EMNLP",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.713",
    doi = "10.18653/v1/2020.emnlp-main.713",
    pages = "8864--8880",
    abstract = "We aim to improve question answering (QA) by decomposing hard questions into simpler sub-questions that existing QA systems are capable of answering. Since labeling questions with decompositions is cumbersome, we take an unsupervised approach to produce sub-questions, also enabling us to leverage millions of questions from the internet. Specifically, we propose an algorithm for One-to-N Unsupervised Sequence transduction (ONUS) that learns to map one hard, multi-hop question to many simpler, single-hop sub-questions. We answer sub-questions with an off-the-shelf QA model and give the resulting answers to a recomposition model that combines them into a final answer. We show large QA improvements on HotpotQA over a strong baseline on the original, out-of-domain, and multi-hop dev sets. ONUS automatically learns to decompose different kinds of questions, while matching the utility of supervised and heuristic decomposition methods for QA and exceeding those methods in fluency. Qualitatively, we find that using sub-questions is promising for shedding light on why a QA system makes a prediction.",
}
@inproceedings{perez2021rissanen,
  author = {Ethan Perez and Douwe Kiela and Kyunghyun Cho},
  title = {Rissanen Data Analysis: Examining Dataset Characteristics via Description Length},
  booktitle={ICML},
  year = {2021},
  url = {https://arxiv.org/abs/2103.03872}
}
@inproceedings{petroni-etal-2019-language,
    title = "Language Models as Knowledge Bases?",
    author = {Petroni, Fabio  and
      Rockt{\"a}schel, Tim  and
      Riedel, Sebastian  and
      Lewis, Patrick  and
      Bakhtin, Anton  and
      Wu, Yuxiang  and
      Miller, Alexander},
    booktitle = "EMNLP",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/D19-1250",
    doi = "10.18653/v1/D19-1250",
    pages = "2463--2473",
    abstract = "Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as {``}fill-in-the-blank{''} cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.",
}
@ARTICLE{phillips2000feret,
  author={P. J. {Phillips} and  {Hyeonjoon Moon} and S. A. {Rizvi} and P. J. {Rauss}},
  journal={TPAMI}, 
  title={The FERET evaluation methodology for face-recognition algorithms}, 
  year={2000},
  volume={22},
  number={10},
  pages={1090-1104},
  doi={10.1109/34.879790}
  }
@misc{pham2020order,
      title={Out of Order: How important is the sequential order of words in a sentence in Natural Language Understanding tasks?}, 
      author={Thang M. Pham and Trung Bui and Long Mai and Anh Nguyen},
      year={2020},
      eprint={2012.15180},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2012.15180}
}
@article{phang2018stilts,
  title={Sentence Encoders on STILTs: Supplementary Training on Intermediate Labeled-data Tasks},
  author={Phang, Jason and F\'evry,, Thibault and Bowman, Samuel R.},
  journal   = {CoRR},
  volume    = {abs/1811.01088},
  year={2018}
}
@inproceedings{pilehvar2018wic,
  title = {{WiC}: The Word-in-Context Dataset for Evaluating Context-Sensitive Meaning Representations},
  author = {Pilehvar, Mohammad Taher and Camacho-Collados, Jose},
  booktitle = {NAACL},
  publisher = {ACL},
  year = {2019},
  url = {https://arxiv.org/abs/1808.09121}
}
@inproceedings{poerner-etal-2020-e,
    title = "{E}-{BERT}: Efficient-Yet-Effective Entity Embeddings for {BERT}",
    author = {Poerner, Nina  and
      Waltinger, Ulli  and
      Sch{\"u}tze, Hinrich},
    booktitle = "Findings of EMNLP",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/2020.findings-emnlp.71",
    doi = "10.18653/v1/2020.findings-emnlp.71",
    pages = "803--818",
    abstract = "We present a novel way of injecting factual knowledge about entities into the pretrained BERT model (Devlin et al., 2019): We align Wikipedia2Vec entity vectors (Yamada et al., 2016) with BERT{'}s native wordpiece vector space and use the aligned entity vectors as if they were wordpiece vectors. The resulting entity-enhanced version of BERT (called E-BERT) is similar in spirit to ERNIE (Zhang et al., 2019) and KnowBert (Peters et al., 2019), but it requires no expensive further pre-training of the BERT encoder. We evaluate E-BERT on unsupervised question answering (QA), supervised relation classification (RC) and entity linking (EL). On all three tasks, E-BERT outperforms BERT and other baselines. We also show quantitatively that the original BERT model is overly reliant on the surface form of entity names (e.g., guessing that someone with an Italian-sounding name speaks Italian), and that E-BERT mitigates this problem.",
}
@misc{radford2018improving,
    title={Improving Language Understanding by Generative Pre-Training},
    author={Alec Radford and Karthik Narasimhan and Tim Salimans and Ilya Sutskever},
    year={2018},
    url={https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf},
}
@misc{radford2019language,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year={2019}
}
@misc{radford2021learning,
      title={Learning Transferable Visual Models From Natural Language Supervision}, 
      author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
      year={2021},
      eprint={2103.00020},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{raffel2020exploring,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {JMLR},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1-67},
  url     = {http://jmlr.org/papers/v21/20-074.html}
}
@inproceedings{rajeswaran2019meta,
 author = {Rajeswaran, Aravind and Finn, Chelsea and Kakade, Sham M and Levine, Sergey},
 booktitle = {NeurIPS},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Meta-Learning with Implicit Gradients},
 url = {https://proceedings.neurips.cc/paper/2019/file/072b030ba126b2f4b2374f342be9ed44-Paper.pdf},
 volume = {32},
 year = {2019}
}
@inproceedings{ravi2017optimization,
  title={Optimization as a Model for Few-Shot Learning},
  author={S. Ravi and H. Larochelle},
  booktitle={ICLR},
  year={2017}
}
@article{real2019regularized, title={Regularized Evolution for Image Classifier Architecture Search}, volume={33}, url={https://ojs.aaai.org/index.php/AAAI/article/view/4405}, DOI={10.1609/aaai.v33i01.33014780}, abstractNote={&lt;p&gt;The effort devoted to hand-crafting neural network image classifiers has motivated the use of architecture search to discover them automatically. Although evolutionary algorithms have been repeatedly applied to neural network topologies, the image classifiers thus discovered have remained inferior to human-crafted ones. Here, we evolve an image classifier— &lt;em&gt;AmoebaNet-A&lt;/em&gt;—that surpasses hand-designs for the first time. To do this, we modify the tournament selection evolutionary algorithm by introducing an age property to favor the younger genotypes. Matching size, AmoebaNet-A has comparable accuracy to current state-of-the-art ImageNet models discovered with more complex architecture-search methods. Scaled to larger size, AmoebaNet-A sets a new state-of-the-art 83.9\% top-1 / 96.6\% top-5 ImageNet accuracy. In a controlled comparison against a well known reinforcement learning algorithm, we give evidence that evolution can obtain results faster with the same hardware, especially at the earlier stages of the search. This is relevant when fewer compute resources are available. Evolution is, thus, a simple method to effectively discover high-quality architectures.&lt;/p&gt;}, number={01}, journal={AAAI}, author={Real, Esteban and Aggarwal, Alok and Huang, Yanping and Le, Quoc V.}, year={2019}, month={Jul.}, pages={4780-4789} }
@article{rissanen1978modeling,
title = "Modeling by shortest data description",
journal = "Automatica",
volume = "14",
number = "5",
pages = "465 - 471",
year = "1978",
issn = "0005-1098",
doi = "https://doi.org/10.1016/0005-1098(78)90005-5",
url = "http://www.sciencedirect.com/science/article/pii/0005109878900055",
author = "J. Rissanen",
keywords = "Modeling, parameter estimation, identification, statistics, stochastic systems",
abstract = "The number of digits it takes to write down an observed sequence x1, …, xN of a time series depends on the model with its parameters that one assumes to have generated the observed data. Accordingly, by finding the model which minimizes the description length one obtains estimates of both the integer-valued structure parameters and the real-valued system parameters."
}
@article{rissanen1984universal,
  author={J. {Rissanen}},
  journal={IEEE Transactions on Information Theory}, 
  title={Universal coding, information, prediction, and estimation}, 
  year={1984},
  volume={30},
  number={4},
  pages={629-636},
  doi={10.1109/TIT.1984.1056936}}
@article{rissanen1985stochastic,
author = {Rissanen, Jorma},
year = {1986},
month = {09},
pages = {},
title = {Stochastic Complexity and Modeling},
volume = {14},
journal = {The Annals of Statistics},
doi = {10.1214/aos/1176350051}
}
@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
  journal={arXiv},
  year={2019},
  volume={abs/1910.01108}
}
@InProceedings{santoro2016metalearning, title = {Meta-Learning with Memory-Augmented Neural Networks}, author = {Santoro, Adam and Bartunov, Sergey and Botvinick, Matthew and Wierstra, Daan and Lillicrap, Timothy}, booktitle = {ICML}, pages = {1842--1850}, year = {2016}, editor = {Balcan, Maria Florina and Weinberger, Kilian Q.}, volume = {48}, series = {PMLR}, address = {New York, New York, USA}, month = {20--22 Jun}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v48/santoro16.pdf}, url = { http://proceedings.mlr.press/v48/santoro16.html }, abstract = {Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of "one-shot learning." Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory location-based focusing mechanisms.} }
@misc{scao2021data,
      title={How Many Data Points is a Prompt Worth?}, 
      author={Teven Le Scao and Alexander M. Rush},
      year={2021},
      eprint={2103.08493},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{schick2020exploiting,
  title={Exploiting Cloze Questions for Few-Shot Text Classification and Natural Language Inference},
  author={Timo Schick and Hinrich Schütze},
  journal={Computing Research Repository},
  volume={arXiv:2001.07676},
  url={http://arxiv.org/abs/2001.07676},
  year={2020}
}
@article{schick2020small,
  title={It's Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners},
  author={Timo Schick and Hinrich Schütze},
  journal={Computing Research Repository},
  volume={arXiv:2009.07118},
  url={http://arxiv.org/abs/2009.07118},
  year={2020}
}
@article{schick2020few,
  title={Few-Shot Text Generation with Pattern-Exploiting Training},
  author={Timo Schick and H. Schutze},
  journal={arXiv},
  year={2020},
  volume={abs/2012.11926}
}
@MastersThesis{schmidhuber1987evolutionary,
author = "Jurgen Schmidhuber",
title = "Evolutionary Principles in Self-Referential Learning. On Learning now to Learn: The Meta-Meta-Meta...-Hook",
school = "Technische Universitat Munchen, Germany",
year = "1987",
type = "Diploma Thesis",
month = "14 " # may,
keywords = "genetic algorithms, genetic programming, self-reference, introsepection, learning, meta, evolution, associative nets, neuronal nets, genetical algorithm, bucket brigade, SALM, PSALM, EURISKO, fractals",
URL = "http://www.idsia.ch/~juergen/diploma.html",
size = "62 pages",
}
@article{shannon1948mathematical,
  author={C. E. {Shannon}},
  journal={The Bell System Technical Journal}, 
  title={A mathematical theory of communication}, 
  year={1948},
  volume={27},
  number={3},
  pages={379-423},
  doi={10.1002/j.1538-7305.1948.tb01338.x}
}
@inproceedings{shin-etal-2020-autoprompt,
    title = "{A}uto{P}rompt: {E}liciting {K}nowledge from {L}anguage {M}odels with {A}utomatically {G}enerated {P}rompts",
    author = "Shin, Taylor  and
      Razeghi, Yasaman  and
      Logan IV, Robert L.  and
      Wallace, Eric  and
      Singh, Sameer",
    booktitle = "EMNLP",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.346",
    doi = "10.18653/v1/2020.emnlp-main.346",
    pages = "4222--4235",
    abstract = "The remarkable success of pretrained language models has motivated the study of what kinds of knowledge these models learn during pretraining. Reformulating tasks as fill-in-the-blanks problems (e.g., cloze tests) is a natural approach for gauging such knowledge, however, its usage is limited by the manual effort and guesswork required to write suitable prompts. To address this, we develop AutoPrompt, an automated method to create prompts for a diverse set of tasks, based on a gradient-guided search. Using AutoPrompt, we show that masked language models (MLMs) have an inherent capability to perform sentiment analysis and natural language inference without additional parameters or finetuning, sometimes achieving performance on par with recent state-of-the-art supervised models. We also show that our prompts elicit more accurate factual knowledge from MLMs than the manually created prompts on the LAMA benchmark, and that MLMs can be used as relation extractors more effectively than supervised relation extraction models. These results demonstrate that automatically generated prompts are a viable parameter-free alternative to existing probing methods, and as pretrained LMs become more sophisticated and capable, potentially a replacement for finetuning.",
}
@article{sinha2021masked,
  author    = {Koustuv Sinha and
               Robin Jia and
               Dieuwke Hupkes and
               Joelle Pineau and
               Adina Williams and
               Douwe Kiela},
  title     = {Masked Language Modeling and the Distributional Hypothesis: Order
               Word Matters Pre-training for Little},
  journal   = {CoRR},
  volume    = {abs/2104.06644},
  year      = {2021},
  url       = {https://arxiv.org/abs/2104.06644},
  archivePrefix = {arXiv},
  eprint    = {2104.06644},
  timestamp = {Mon, 19 Apr 2021 16:45:47 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2104-06644.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@misc{sinha2020unnatural,
      title={Unnatural Language Inference}, 
      author={Koustuv Sinha and Prasanna Parthasarathi and Joelle Pineau and Adina Williams},
      year={2020},
      eprint={2101.00010},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{snell2017prototypical,
 author = {Snell, Jake and Swersky, Kevin and Zemel, Richard},
 booktitle = {NeuRIPS},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Prototypical Networks for Few-shot Learning},
 url = {https://proceedings.neurips.cc/paper/2017/file/cb8da6767461f2812ae4290eac7cbc42-Paper.pdf},
 volume = {30},
 year = {2017}
}
@inproceedings{snoek2012practical,
 author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P},
 booktitle = {NeuRIPS},
 editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Practical Bayesian Optimization of Machine Learning Algorithms},
 url = {https://proceedings.neurips.cc/paper/2012/file/05311655a15b75fab86956663e1819cd-Paper.pdf},
 volume = {25},
 year = {2012}
}
@article{stone1974cross,
  title={Cross‐Validatory Choice and Assessment of Statistical Predictions},
  author={M. Stone},
  journal={Journal of the Royal Statistical Society. Series A (Methodological)},
  year={1974},
  volume={36},
  pages={111-133}
}
@article{sugawara2020assessing, title={Assessing the Benchmarking Capacity of Machine Reading Comprehension Datasets}, volume={34}, url={https://ojs.aaai.org/index.php/AAAI/article/view/6422}, DOI={10.1609/aaai.v34i05.6422}, number={05}, journal={AAAI}, author={Sugawara, Saku and Stenetorp, Pontus and Inui, Kentaro and Aizawa, Akiko}, year={2020}, month={Apr.}, pages={8918-8927} }
@inproceedings{swayamdipta2020dataset,
    title={Dataset Cartography: Mapping and Diagnosing Datasets with Training Dynamics},
    author={Swabha Swayamdipta and Roy Schwartz and Nicholas Lourie and Yizhong Wang and Hannaneh Hajishirzi and Noah A. Smith and Yejin Choi},
    booktitle={EMNLP},
    url={https://arxiv.org/abs/2009.10795},
    year={2020}
}
@article{talmor2020olmpics,
  author    = {Alon Talmor and
               Yanai Elazar and
               Yoav Goldberg and
               Jonathan Berant},
  title     = {oLMpics - On what Language Model Pre-training Captures},
  journal   = {Trans. Assoc. Comput. Linguistics},
  volume    = {8},
  pages     = {743--758},
  year      = {2020},
  url       = {https://transacl.org/ojs/index.php/tacl/article/view/2041},
  timestamp = {Wed, 17 Feb 2021 21:55:25 +0100},
  biburl    = {https://dblp.org/rec/journals/tacl/TalmorEGB20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{tam2021improving,
          title={Improving and Simplifying Pattern Exploiting Training},
          author={Tam, Derek and Menon, Rakesh R and Bansal, Mohit and Srivastava, Shashank and Raffel, Colin},
          journal={arxiv preprint arXiv:2103.11955},
          year={2021}
}
@inproceedings{thornton2013autoweka,
author = {Thornton, Chris and Hutter, Frank and Hoos, Holger H. and Leyton-Brown, Kevin},
title = {Auto-WEKA: Combined Selection and Hyperparameter Optimization of Classification Algorithms},
year = {2013},
isbn = {9781450321747},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2487575.2487629},
doi = {10.1145/2487575.2487629},
abstract = {Many different machine learning algorithms exist; taking into account each algorithm's hyperparameters, there is a staggeringly large number of possible alternatives overall. We consider the problem of simultaneously selecting a learning algorithm and setting its hyperparameters, going beyond previous work that attacks these issues separately. We show that this problem can be addressed by a fully automated approach, leveraging recent innovations in Bayesian optimization. Specifically, we consider a wide range of feature selection techniques (combining 3 search and 8 evaluator methods) and all classification approaches implemented in WEKA's standard distribution, spanning 2 ensemble methods, 10 meta-methods, 27 base classifiers, and hyperparameter settings for each classifier. On each of 21 popular datasets from the UCI repository, the KDD Cup 09, variants of the MNIST dataset and CIFAR-10, we show classification performance often much better than using standard selection and hyperparameter optimization methods. We hope that our approach will help non-expert users to more effectively identify machine learning algorithms and hyperparameter settings appropriate to their applications, and hence to achieve improved performance.},
booktitle = {SIGKDD},
pages = {847–855},
numpages = {9},
keywords = {weka, model selection, hyperparameter optimization},
location = {Chicago, Illinois, USA},
series = {KDD '13}
}
@book{hastie2001statistical,
  added-at = {2008-05-16T16:17:42.000+0200},
  address = {New York, NY, USA},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  biburl = {https://www.bibsonomy.org/bibtex/2f58afc5c9793fcc8ad8389824e57984c/sb3000},
  interhash = {d585aea274f2b9b228fc1629bc273644},
  intrahash = {f58afc5c9793fcc8ad8389824e57984c},
  keywords = {ml statistics},
  publisher = {Springer New York Inc.},
  series = {Springer Series in Statistics},
  timestamp = {2008-05-16T16:17:43.000+0200},
  title = {The Elements of Statistical Learning},
  year = 2001
}
@inproceedings{triantafillou2020metadataset,
title={Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples},
author={Eleni Triantafillou and Tyler Zhu and Vincent Dumoulin and Pascal Lamblin and Utku Evci and Kelvin Xu and Ross Goroshin and Carles Gelada and Kevin Swersky and Pierre-Antoine Manzagol and Hugo Larochelle},
booktitle={ICLR},
year={2020},
url={https://openreview.net/forum?id=rkgAGAVKPr}
}
@article{trinh2018simple,
  author    = {Trieu H. Trinh and
               Quoc V. Le},
  title     = {A Simple Method for Commonsense Reasoning},
  journal   = {CoRR},
  volume    = {abs/1806.02847},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.02847},
  archivePrefix = {arXiv},
  eprint    = {1806.02847},
  timestamp = {Mon, 13 Aug 2018 16:46:22 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1806-02847.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{vaswani2017attention,
  author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
  title     = {Attention Is All You Need},
  journal   = {CoRR},
  volume    = {abs/1706.03762},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.03762},
  archivePrefix = {arXiv},
  eprint    = {1706.03762},
  timestamp = {Mon, 13 Aug 2018 16:48:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{vinyals2016matching,
 author = {Vinyals, Oriol and Blundell, Charles and Lillicrap, Timothy and kavukcuoglu, koray and Wierstra, Daan},
 booktitle = {NeuRIPS},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Matching Networks for One Shot Learning},
 url = {https://proceedings.neurips.cc/paper/2016/file/90e1357833654983612fb05e3ec9148c-Paper.pdf},
 volume = {29},
 year = {2016}
}
@article{vehtari2017practical,
author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
title = {Practical Bayesian Model Evaluation Using Leave-One-out Cross-Validation and WAIC},
year = {2017},
issue_date = {September 2017},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {27},
number = {5},
issn = {0960-3174},
url = {https://doi.org/10.1007/s11222-016-9696-4},
doi = {10.1007/s11222-016-9696-4},
abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
journal = {Statistics and Computing},
month = sep,
pages = {1413–1432},
numpages = {20},
keywords = {Pareto smoothed importance sampling (PSIS), Widely applicable information criterion (WAIC), Leave-one-out cross-validation (LOO), Stan, K-fold cross-validation, Bayesian computation}
}
@article{virtanen2020scipy,
  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
            Haberland, Matt and Reddy, Tyler and Cournapeau, David and
            Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
            Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
            Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
            Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
            Kern, Robert and Larson, Eric and Carey, C J and
            Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and
            {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
            Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
            Harris, Charles R. and Archibald, Anne M. and
            Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and
            {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
            Computing in Python}},
  journal = {Nature Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272},
  adsurl  = {https://rdcu.be/b08Wh},
  doi     = {10.1038/s41592-019-0686-2},
}
@inproceedings{voita-titov-2020-information,
    title = "Information-Theoretic Probing with Minimum Description Length",
    author = "Voita, Elena  and
      Titov, Ivan",
    booktitle = "EMNLP",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.14",
    doi = "10.18653/v1/2020.emnlp-main.14",
    pages = "183--196",
    abstract = "To measure how well pretrained representations encode some linguistic property, it is common to use accuracy of a probe, i.e. a classifier trained to predict the property from the representations. Despite widespread adoption of probes, differences in their accuracy fail to adequately reflect differences in representations. For example, they do not substantially favour pretrained representations over randomly initialized ones. Analogously, their accuracy can be similar when probing for genuine linguistic labels and probing for random synthetic tasks. To see reasonable differences in accuracy with respect to these random baselines, previous work had to constrain either the amount of probe training data or its model size. Instead, we propose an alternative to the standard probes, information-theoretic probing with minimum description length (MDL). With MDL probing, training a probe to predict labels is recast as teaching it to effectively transmit the data. Therefore, the measure of interest changes from probe accuracy to the description length of labels given representations. In addition to probe quality, the description length evaluates {``}the amount of effort{''} needed to achieve the quality. This amount of effort characterizes either (i) size of a probing model, or (ii) the amount of data needed to achieve the high quality. We consider two methods for estimating MDL which can be easily implemented on top of the standard probing pipelines: variational coding and online coding. We show that these methods agree in results and are more informative and stable than the standard probes.",
}
@inproceedings{wang2018glue,
    title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
    author={Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},
    booktitle={ICLR},
    year={2019},
    url={https://openreview.net/forum?id=rJ4km2R5t7},
}
@inproceedings{wang2019superglue,
    author = {Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
    booktitle = {NeuRIPS},
    editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
    pages = {},
    publisher = {Curran Associates, Inc.},
    title = {SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems},
    url = {https://proceedings.neurips.cc/paper/2019/file/4496bf24afe7fab6f046bf4923da8de6-Paper.pdf},
    volume = {32},
    year = {2019}
}
@misc{wang2021entailment,
      title={Entailment as Few-Shot Learner}, 
      author={Sinong Wang and Han Fang and Madian Khabsa and Hanzi Mao and Hao Ma},
      year={2021},
      eprint={2104.14690},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{warstadt2018neural,
    title={Neural Network Acceptability Judgments},
    author={Warstadt, Alex and Singh, Amanpreet and Bowman, Samuel R},
    journal={arXiv preprint arXiv:1805.12471},
    year={2018}
}
@article{watanabe2010asymptotic,
  author  = {Sumio Watanabe},
  title   = {Asymptotic Equivalence of Bayes Cross Validation and Widely Applicable Information Criterion in Singular Learning Theory},
  journal = {JMLR},
  year    = {2010},
  volume  = {11},
  number  = {116},
  pages   = {3571-3594},
  url     = {http://jmlr.org/papers/v11/watanabe10a.html}
}
@misc{whitney2020evaluating,
    title={Evaluating representations by the complexity of learning low-loss predictors},
    author={William F. Whitney and Min Jae Song and David Brandfonbrener and Jaan Altosaar and Kyunghyun Cho},
    year={2020},
    eprint={2009.07368},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@misc{wiegreffe2020measuring,
      title={Measuring Association Between Labels and Free-Text Rationales}, 
      author={Sarah Wiegreffe and Ana Marasovic and Noah A. Smith},
      year={2020},
      eprint={2010.12762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "EMNLP: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}
@inproceedings{xie2020unsupervised,
 author = {Xie, Qizhe and Dai, Zihang and Hovy, Eduard and Luong, Thang and Le, Quoc},
 booktitle = {NeuRIPS},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {6256--6268},
 publisher = {Curran Associates, Inc.},
 title = {Unsupervised Data Augmentation for Consistency Training},
 url = {https://proceedings.neurips.cc/paper/2020/file/44feb0096faa8326192570788b38c1d1-Paper.pdf},
 volume = {33},
 year = {2020}
}
@inproceedings{yang2018hotpotqa,
  title={{HotpotQA}: A Dataset for Diverse, Explainable Multi-hop Question Answering},
  author={Yang, Zhilin and Qi, Peng and Zhang, Saizheng and Bengio, Yoshua and Cohen, William W. and Salakhutdinov, Ruslan and Manning, Christopher D.},
  booktitle={EMNLP},
  year={2018}
}
@inproceedings{yang-etal-2020-generative,
    title = "Generative Data Augmentation for Commonsense Reasoning",
    author = "Yang, Yiben  and
      Malaviya, Chaitanya  and
      Fernandez, Jared  and
      Swayamdipta, Swabha  and
      Le Bras, Ronan  and
      Wang, Ji-Ping  and
      Bhagavatula, Chandra  and
      Choi, Yejin  and
      Downey, Doug",
    booktitle = "Findings of EMNLP",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/2020.findings-emnlp.90",
    doi = "10.18653/v1/2020.findings-emnlp.90",
    pages = "1008--1025",
    abstract = "Recent advances in commonsense reasoning depend on large-scale human-annotated training sets to achieve peak performance. However, manual curation of training sets is expensive and has been shown to introduce annotation artifacts that neural models can readily exploit and overfit to. We propose a novel generative data augmentation technique, G-DAUG{\^{}}C, that aims to achieve more accurate and robust learning in a low-resource setting. Our approach generates synthetic examples using pretrained language models and selects the most informative and diverse set of examples for data augmentation. On experiments with multiple commonsense reasoning benchmarks, G-DAUG{\^{}}C consistently outperforms existing data augmentation methods based on back-translation, establishing a new state-of-the-art on WinoGrande, CODAH, and CommonsenseQA, as well as enhances out-of-distribution generalization, proving to be robust against adversaries or perturbations. Our analysis demonstrates that G-DAUG{\^{}}C produces a diverse set of fluent training examples, and that its selection and training approaches are important for performance.",
}
@article{ye2021crossfit,
  author    = {Qinyuan Ye and
               Bill Yuchen Lin and
               Xiang Ren},
  title     = {CrossFit: {A} Few-shot Learning Challenge for Cross-task Generalization
               in {NLP}},
  journal   = {CoRR},
  volume    = {abs/2104.08835},
  year      = {2021},
  url       = {https://arxiv.org/abs/2104.08835},
  archivePrefix = {arXiv},
  eprint    = {2104.08835},
  timestamp = {Mon, 26 Apr 2021 17:25:10 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2104-08835.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{yogatama2019learning,
  author    = {Dani Yogatama and
               Cyprien de Masson d'Autume and
               Jerome Connor and
               Tom{\'{a}}s Kocisk{\'{y}} and
               Mike Chrzanowski and
               Lingpeng Kong and
               Angeliki Lazaridou and
               Wang Ling and
               Lei Yu and
               Chris Dyer and
               Phil Blunsom},
  title     = {Learning and Evaluating General Linguistic Intelligence},
  journal   = {CoRR},
  volume    = {abs/1901.11373},
  year      = {2019},
  url       = {http://arxiv.org/abs/1901.11373},
  archivePrefix = {arXiv},
  eprint    = {1901.11373},
  timestamp = {Mon, 04 Feb 2019 08:11:03 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1901-11373.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{zhang-etal-2019-paws,
    title = "{PAWS}: Paraphrase Adversaries from Word Scrambling",
    author = "Zhang, Yuan  and
      Baldridge, Jason  and
      He, Luheng",
    booktitle = "NAACL",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "ACL",
    url = "https://www.aclweb.org/anthology/N19-1131",
    doi = "10.18653/v1/N19-1131",
    pages = "1298--1308",
    abstract = "Existing paraphrase identification datasets lack sentence pairs that have high lexical overlap without being paraphrases. Models trained on such data fail to distinguish pairs like flights from New York to Florida and flights from Florida to New York. This paper introduces PAWS (Paraphrase Adversaries from Word Scrambling), a new dataset with 108,463 well-formed paraphrase and non-paraphrase pairs with high lexical overlap. Challenging pairs are generated by controlled word swapping and back translation, followed by fluency and paraphrase judgments by human raters. State-of-the-art models trained on existing datasets have dismal performance on PAWS ({\textless}40{\%} accuracy); however, including PAWS training data for these models improves their accuracy to 85{\%} while maintaining performance on existing tasks. In contrast, models that do not capture non-local contextual information fail even with PAWS training examples. As such, PAWS provides an effective instrument for driving further progress on models that better exploit structure, context, and pairwise comparisons.",
}
@InProceedings{zhang2016yin,
author = {Peng Zhang and Yash Goyal and Douglas Summers{-}Stay and Dhruv Batra and Devi Parikh},
title = {{Y}in and {Y}ang: Balancing and Answering Binary Visual Questions},
booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2016},
}
@article{zhang2018record,
  title={{R}e{C}o{RD}: Bridging the Gap between Human and Machine Commonsense Reading Comprehension},
  author={Zhang, Sheng and Liu, Xiaodong and Liu, Jingjing and Gao, Jianfeng and Duh, Kevin and Van Durme, Benjamin},
  journal={arXiv preprint 1810.12885},
  year={2018}
}
@misc{zhao2021calibrate,
      title={Calibrate Before Use: Improving Few-Shot Performance of Language Models}, 
      author={Tony Z. Zhao and Eric Wallace and Shi Feng and Dan Klein and Sameer Singh},
      year={2021},
      eprint={2102.09690},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{zoph2017neural,
  author    = {Barret Zoph and
               Quoc V. Le},
  title     = {Neural Architecture Search with Reinforcement Learning},
  booktitle = {ICLR},
  publisher = {OpenReview.net},
  year      = {2017},
  url       = {https://openreview.net/forum?id=r1Ue8Hcxg},
  timestamp = {Thu, 04 Apr 2019 13:20:08 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/ZophL17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{zhong2021factual,
  author    = {Zexuan Zhong and
               Dan Friedman and
               Danqi Chen},
  title     = {Factual Probing Is {[MASK]:} Learning vs. Learning to Recall},
  journal   = {CoRR},
  volume    = {abs/2104.05240},
  year      = {2021},
  url       = {https://arxiv.org/abs/2104.05240},
  archivePrefix = {arXiv},
  eprint    = {2104.05240},
  timestamp = {Mon, 19 Apr 2021 16:45:47 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2104-05240.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}