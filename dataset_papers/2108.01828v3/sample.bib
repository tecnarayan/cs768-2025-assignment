
@inproceedings{lowe2020interaction,
  added-at = {2020-05-07T00:00:00.000+0200},
  author = {Lowe, Ryan and Gupta, Abhinav and Foerster, Jakob N. and Kiela, Douwe and Pineau, Joelle},
  biburl = {https://www.bibsonomy.org/bibtex/27870c6e93594969e7bd24bbed6dcafe8/dblp},
  booktitle = {ICLR},
  ee = {https://openreview.net/forum?id=rJxGLlBtwH},
  interhash = {dcc102ad1c8da9a1fd35504e4003e960},
  intrahash = {7870c6e93594969e7bd24bbed6dcafe8},
  keywords = {dblp},
  publisher = {OpenReview.net},
  timestamp = {2020-05-08T11:42:22.000+0200},
  title = {On the interaction between supervision and self-play in emergent communication.},
  url = {http://dblp.uni-trier.de/db/conf/iclr/iclr2020.html#Lowe0FKP20},
  year = 2020
}




@inproceedings{havrylov2017emergence,
 author = {Havrylov, Serhii and Titov, Ivan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Emergence of Language with Multi-agent Games: Learning to Communicate with Sequences of Symbols},
 url = {https://proceedings.neurips.cc/paper/2017/file/70222949cc0db89ab32c9969754d4758-Paper.pdf},
 volume = {30},
 year = {2017}
}



@article{bullard2021quasi,
  title={Quasi-Equivalence Discovery for Zero-Shot Emergent Communication},
  author={Bullard, Kalesha and Kiela, Douwe and Pineau, Joelle and Foerster, Jakob},
  journal={arXiv preprint arXiv:2103.08067},
  year={2021}
}

@article{bullard2020exploring,
  title={Exploring Zero-Shot Emergent Communication in Embodied Multi-Agent Populations},
  author={Bullard, Kalesha and Meier, Franziska and Kiela, Douwe and Pineau, Joelle and Foerster, Jakob},
  journal={arXiv preprint arXiv:2010.15896},
  year={2020}
}

@article{lowe2017multi,
  title={Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments},
  author={Lowe, Ryan and Wu, Yi and Tamar, Aviv and Harb, Jean and Abbeel, Pieter and Mordatch, Igor},
  journal={Neural Information Processing Systems (NIPS)},
  year={2017}
}

@article{mordatch2017emergence, title={Emergence of Grounded Compositional Language in Multi-Agent Populations}, volume={32}, url={https://ojs.aaai.org/index.php/AAAI/article/view/11492}, abstractNote={ &lt;p&gt; By capturing statistical patterns in large corpora, machine learning has enabled significant advances in natural language processing, including in machine translation, question answering, and sentiment analysis. However, for agents to intelligently interact with humans, simply capturing the statistical patterns is insufficient. In this paper we investigate if, and how, grounded compositional language can emerge as a means to achieve goals in multi-agent populations. Towards this end, we propose a multi-agent learning environment and learning methods that bring about emergence of a basic compositional language. This language is represented as streams of abstract discrete symbols uttered by agents over time, but nonetheless has a coherent structure that possesses a defined vocabulary and syntax. We also observe emergence of non-verbal communication such as pointing and guiding when language communication is unavailable. &lt;/p&gt; }, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Mordatch, Igor and Abbeel, Pieter}, year={2018}, month={Apr.} }

@inproceedings{lerer2019learning,
  title={Learning existing social conventions via observationally augmented self-play. AAAI},
  author={Lerer, Adam and Peysakhovich, Alexander},
  booktitle={ACM conference on Artificial Intelligence, Ethics, and Society},
  year={2019}
}

@article{tucker2020adversarially,
  title={Adversarially Guided Self-Play for Adopting Social Conventions},
  author={Tucker, Mycal and Zhou, Yilun and Shah, Julie},
  journal={arXiv preprint arXiv:2001.05994},
  year={2020}
}
@inproceedings{kottur2017natural,
    title = "Natural Language Does Not Emerge {`}Naturally{'} in Multi-Agent Dialog",
    author = "Kottur, Satwik  and
      Moura, Jos{\'e}  and
      Lee, Stefan  and
      Batra, Dhruv",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D17-1321",
    doi = "10.18653/v1/D17-1321",
    pages = "2962--2967",
    abstract = "A number of recent works have proposed techniques for end-to-end learning of communication protocols among cooperative multi-agent populations, and have simultaneously found the emergence of grounded human-interpretable language in the protocols developed by the agents, learned without any human supervision! In this paper, using a Task {\&} Talk reference game between two agents as a testbed, we present a sequence of {`}negative{'} results culminating in a {`}positive{'} one {--} showing that while most agent-invented languages are effective (i.e. achieve near-perfect task rewards), they are decidedly not interpretable or compositional. In essence, we find that natural language does not emerge {`}naturally{'},despite the semblance of ease of natural-language-emergence that one may gather from recent literature. We discuss how it is possible to coax the invented languages to become more and more human-like and compositional by increasing restrictions on how two agents may communicate.",
}
@inproceedings{glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}

@inproceedings{word2vec,
 author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Distributed Representations of Words and Phrases and their Compositionality},
 url = {https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf},
 volume = {26},
 year = {2013}
}

@article{lazaridou2020emergent,
  title={Emergent Multi-Agent Communication in the Deep Learning Era},
  author={Lazaridou, Angeliki and Baroni, Marco},
  journal={arXiv preprint arXiv:2006.02419},
  year={2020}
}



@inproceedings{lazaridou2016multi,
  author    = {Angeliki Lazaridou and
               Alexander Peysakhovich and
               Marco Baroni},
  title     = {Multi-Agent Cooperation and the Emergence of (Natural) Language},
  booktitle = {5th International Conference on Learning Representations, {ICLR} 2017,
               Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2017},
  url       = {https://openreview.net/forum?id=Hk8N3Sclg},
  timestamp = {Thu, 04 Apr 2019 13:20:09 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/LazaridouPB17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{lazaridou2018emergence,
  author    = {Angeliki Lazaridou and
               Karl Moritz Hermann and
               Karl Tuyls and
               Stephen Clark},
  title     = {Emergence of Linguistic Communication from Referential Games with
               Symbolic and Pixel Input},
  booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
               Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2018},
  url       = {https://openreview.net/forum?id=HJGv1Z-AW},
  timestamp = {Thu, 04 Apr 2019 13:20:09 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/LazaridouHTC18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{foerster2016learning,
 author = {Foerster, Jakob and Assael, Ioannis Alexandros and de Freitas, Nando and Whiteson, Shimon},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Learning to Communicate with Deep Multi-Agent Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper/2016/file/c7635bfd99248a2cdef8249ef7bfbef4-Paper.pdf},
 volume = {29},
 year = {2016}
}


@inproceedings{sukhbaatar2016learning,
 author = {Sukhbaatar, Sainbayar and szlam, arthur and Fergus, Rob},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Learning Multiagent Communication with Backpropagation},
 url = {https://proceedings.neurips.cc/paper/2016/file/55b1927fdafef39c48e5b73b5d61ea60-Paper.pdf},
 volume = {29},
 year = {2016}
}



@inproceedings{NEURIPS2019_fe5e7cb6,
 author = {Eccles, Tom and Bachrach, Yoram and Lever, Guy and Lazaridou, Angeliki and Graepel, Thore},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Biases for Emergent Communication in Multi-agent Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper/2019/file/fe5e7cb609bdbe6d62449d61849c38b0-Paper.pdf},
 volume = {32},
 year = {2019}
}

@phdthesis{hausknecht2016cooperation,
  title={Cooperation and communication in multiagent deep reinforcement learning},
  author={Hausknecht, Matthew John},
  year={2016}
}


@inproceedings{chaabouni2019antiefficient,
 author = {Chaabouni, Rahma and Kharitonov, Eugene and Dupoux, Emmanuel and Baroni, Marco},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Anti-efficient encoding in emergent communication},
 url = {https://proceedings.neurips.cc/paper/2019/file/31ca0ca71184bbdb3de7b20a51e88e90-Paper.pdf},
 volume = {32},
 year = {2019}
}


@conference{lee2017emergent,
title = "Emergent translation in multi-agent communication",
abstract = "While most machine translation systems to date are trained on large parallel corpora, humans learn language in a different way: by being grounded in an environment and interacting with other humans. In this work, we propose a communication game where two agents, native speakers of their own respective languages, jointly learn to solve a visual referential task. We find that the ability to understand and translate a foreign language emerges as a means to achieve shared goals. The emergent translation is interactive and multimodal, and crucially does not require parallel corpora, but only monolingual, independent text and corresponding images. Our proposed translation model achieves this by grounding the source and target languages into a shared visual modality, and outperforms several baselines on both word-level and sentence-level translation tasks. Furthermore, we show that agents in a multilingual community learn to translate better and faster than in a bilingual communication setting.",
author = "Jason Lee and Kyunghyun Cho and Jason Weston and Douwe Kiela",
year = "2018",
month = jan,
day = "1",
language = "English (US)",
note = "6th International Conference on Learning Representations, ICLR 2018 ; Conference date: 30-04-2018 Through 03-05-2018",
}

@inproceedings{jaques2019social,
  title={Social influence as intrinsic motivation for multi-agent deep reinforcement learning},
  author={Jaques, Natasha and Lazaridou, Angeliki and Hughes, Edward and Gulcehre, Caglar and Ortega, Pedro and Strouse, DJ and Leibo, Joel Z and De Freitas, Nando},
  booktitle={International Conference on Machine Learning},
  pages={3040--3049},
  year={2019},
  organization={PMLR}
}

@inproceedings{lazaridou-etal-2020-multi,
    title = "Multi-agent Communication meets Natural Language: Synergies between Functional and Structural Language Learning",
    author = "Lazaridou, Angeliki  and
      Potapenko, Anna  and
      Tieleman, Olivier",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.acl-main.685",
    doi = "10.18653/v1/2020.acl-main.685",
    pages = "7663--7674",
    abstract = "We present a method for combining multi-agent communication and traditional data-driven approaches to natural language learning, with an end goal of teaching agents to communicate with humans in natural language. Our starting point is a language model that has been trained on generic, not task-specific language data. We then place this model in a multi-agent self-play environment that generates task-specific rewards used to adapt or modulate the model, turning it into a task-conditional language model. We introduce a new way for combining the two types of learning based on the idea of reranking language model samples, and show that this method outperforms others in communicating with humans in a visual referential communication task. Finally, we present a taxonomy of different types of language drift that can occur alongside a set of measures to detect them.",
}

@article{bernstein2002complexity,
  title={The complexity of decentralized control of Markov decision processes},
  author={Bernstein, Daniel S and Givan, Robert and Immerman, Neil and Zilberstein, Shlomo},
  journal={Mathematics of operations research},
  volume={27},
  number={4},
  pages={819--840},
  year={2002},
  publisher={INFORMS}
}


@article{schulman2017proximal,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.06347},
  archivePrefix = {arXiv},
  eprint    = {1707.06347},
  timestamp = {Mon, 13 Aug 2018 16:47:34 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SchulmanWDRK17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016},
  organization={PMLR}
}

@misc{jang2017categorical,
      title={Categorical Reparameterization with Gumbel-Softmax}, 
      author={Eric Jang and Shixiang Gu and Ben Poole},
      year={2017},
      eprint={1611.01144},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}



@inproceedings{hu2020other,
  title={``{O}ther-Play” for Zero-Shot Coordination},
  author={Hu, Hengyuan and Lerer, Adam and Peysakhovich, Alex and Foerster, Jakob},
  booktitle={International Conference on Machine Learning},
  pages={4399--4410},
  year={2020},
  organization={PMLR}
}

@inproceedings{reimers-2019-sentence-bert,
    title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
    author = "Reimers, Nils and Gurevych, Iryna",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
    month = "11",
    year = "2019",
    publisher = "Association for Computational Linguistics",
    url = "http://arxiv.org/abs/1908.10084",
}

@incollection{mw,
  author    = {Merriam-Webster},
  title     = {Abulia},
  booktitle = {Merriam-Webster.com dictionary},
  url       = {https://www.merriam-webster.com/dictionary/abulia},
  urldate   = {2021-05-08},
}

@inproceedings{yu2018deep,
  title={Deep layer aggregation},
  author={Yu, Fisher and Wang, Dequan and Shelhamer, Evan and Darrell, Trevor},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2403--2412},
  year={2018}
}

@article{xian2018zero,
  title={Zero-shot learning—a comprehensive evaluation of the good, the bad and the ugly},
  author={Xian, Yongqin and Lampert, Christoph H and Schiele, Bernt and Akata, Zeynep},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={9},
  pages={2251--2265},
  year={2018},
  publisher={IEEE}
}

@incollection{meng2020unsupervised,
  title={Unsupervised Cross-domain Image Classification by Distance Metric Guided Feature Alignment},
  author={Meng, Qingjie and Rueckert, Daniel and Kainz, Bernhard},
  booktitle={Medical Ultrasound, and Preterm, Perinatal and Paediatric Image Analysis},
  pages={146--157},
  year={2020},
  publisher={Springer}
}

@inproceedings{chen2018zero,
  title={Zero-shot visual recognition using semantics-preserving adversarial embedding networks},
  author={Chen, Long and Zhang, Hanwang and Xiao, Jun and Liu, Wei and Chang, Shih-Fu},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={1043--1052},
  year={2018}
}

@inproceedings{socher2013zero,
author = {Socher, Richard and Ganjoo, Milind and Manning, Christopher D. and Ng, Andrew Y.},
title = {Zero-Shot Learning through Cross-Modal Transfer},
year = {2013},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {This work introduces a model that can recognize objects in images even if no training data is available for the object class. The only necessary knowledge about unseen visual categories comes from unsupervised text corpora. Unlike previous zero-shot learning models, which can only differentiate between unseen classes, our model can operate on a mixture of seen and unseen classes, simultaneously obtaining state of the art performance on classes with thousands of training images and reasonable performance on unseen classes. This is achieved by seeing the distributions of words in texts as a semantic space for understanding what objects look like. Our deep learning model does not require any manually defined semantic or visual features for either words or images. Images are mapped to be close to semantic word vectors corresponding to their classes, and the resulting image embeddings can be used to distinguish whether an image is of a seen or unseen class. We then use novelty detection methods to differentiate unseen classes from seen classes. We demonstrate two novelty detection strategies; the first gives high accuracy on unseen classes, while the second is conservative in its prediction of novelty and keeps the seen classes' accuracy high.},
booktitle = {Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 1},
pages = {935–943},
numpages = {9},
location = {Lake Tahoe, Nevada},
series = {NIPS'13}
}

@book{lewis2008convention,
  title={Convention: A philosophical study},
  author={Lewis, David},
  year={2008},
  publisher={John Wiley \& Sons}
}

@article{bengio2003neural,
  title={A neural probabilistic language model},
  author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal and Janvin, Christian},
  journal={The journal of machine learning research},
  volume={3},
  pages={1137--1155},
  year={2003},
  publisher={JMLR. org}
}


@article{almeida2019word,
  title={Word embeddings: A survey},
  author={Almeida, Felipe and Xex{\'e}o, Geraldo},
  journal={arXiv preprint arXiv:1901.09069},
  year={2019}
}

@misc{shariqbal,
  author = {Shariq Iqbal},
  title = {MADDPG-Pytorch},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/shariqiqbal2810/maddpg-pytorch}}
}

@inproceedings{lee2019countering,
title = "Countering language drift via visual grounding",
abstract = "Emergent multi-agent communication protocols are very different from natural language and not easily interpretable by humans. We find that agents that were initially pretrained to produce natural language can also experience detrimental language drift: when a non-linguistic reward is used in a goal-based task, e.g. some scalar success metric, the communication protocol may easily and radically diverge from natural language. We recast translation as a multi-agent communication game and examine auxiliary training constraints for their effectiveness in mitigating language drift. We show that a combination of syntactic (language model likelihood) and semantic (visual grounding) constraints gives the best communication performance, allowing pre-trained agents to retain English syntax while learning to accurately convey the intended meaning.",
author = "Jason Lee and Kyunghyun Cho and Douwe Kiela",
year = "2020",
language = "English (US)",
series = "EMNLP-IJCNLP 2019 - 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, Proceedings of the Conference",
publisher = "Association for Computational Linguistics",
pages = "4385--4395",
booktitle = "EMNLP-IJCNLP 2019 - 2019 Conference on Empirical Methods in Natural Language Processing and 9th International Joint Conference on Natural Language Processing, Proceedings of the Conference",
}

@article{cifar10,
title= {CIFAR-10 (Canadian Institute for Advanced Research)},
journal= {},
author= {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
year= {2010},
url= {http://www.cs.toronto.edu/~kriz/cifar.html},
abstract= {The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. 

The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. },
keywords= {Dataset},
terms= {}
}


@inproceedings{kuhn1951proceedings,
  added-at = {2013-06-17T14:15:18.000+0200},
  address = {Berkeley and Los Angeles},
  author = {Kuhn, H. W. and Tucker, A. W.},
  biburl = {https://www.bibsonomy.org/bibtex/2d009df996edeb353842306e3e70d9c86/thoni},
  booktitle = {Proceedings of the {S}econd {B}erkeley {S}ymposium on              {M}athematical {S}tatistics and {P}robability, 1950},
  description = {MR: Publications results for "MR Number=(47303)"},
  interhash = {7fb836ca2faa555996a5eae04e99cce2},
  intrahash = {d009df996edeb353842306e3e70d9c86},
  keywords = {conditions karush kkt kuhn svm tucker},
  mrclass = {90.0X},
  mrnumber = {0047303 (13,855f)},
  mrreviewer = {D. Gale},
  pages = {481--492},
  publisher = {University of California Press},
  timestamp = {2016-09-06T08:23:07.000+0200},
  title = {Nonlinear programming},
  year = 1951
}


