\begin{thebibliography}{}

\bibitem[Aas et~al., 2019]{aas2019explaining}
Aas, K., Jullum, M., and L{\o}land, A. (2019).
\newblock Explaining individual predictions when features are dependent: More
  accurate approximations to shapley values.
\newblock {\em arXiv preprint arXiv:1903.10464}.

\bibitem[Alvarez-Melis and Jaakkola, 2018]{alvarez2018robustness}
Alvarez-Melis, D. and Jaakkola, T.~S. (2018).
\newblock On the robustness of interpretability methods.
\newblock {\em arXiv preprint arXiv:1806.08049}.

\bibitem[Angwin et~al., 2016]{angwin2016machine}
Angwin, J., Larson, J., Mattu, S., and Kirchner, L. (2016).
\newblock Machine bias.
\newblock {\em ProPublica, May}, 23(2016):139--159.

\bibitem[Asuncion and Newman, 2007]{asuncion2007uci}
Asuncion, A. and Newman, D. (2007).
\newblock Uci machine learning repository.

\bibitem[Bhargava et~al., 2020]{bhargava2020limeout}
Bhargava, V., Couceiro, M., and Napoli, A. (2020).
\newblock Limeout: An ensemble approach to improve process fairness.
\newblock {\em arXiv preprint arXiv:2006.10531}.

\bibitem[Bloniarz et~al., 2016]{bloniarz2016supervised}
Bloniarz, A., Talwalkar, A., Yu, B., and Wu, C. (2016).
\newblock Supervised neighborhoods for distributed nonparametric regression.
\newblock In {\em Artificial Intelligence and Statistics}, pages 1450--1459.
  PMLR.

\bibitem[Botari et~al., 2020]{botari2020melime}
Botari, T., Hvilsh{\o}j, F., Izbicki, R., and de~Carvalho, A.~C. (2020).
\newblock Melime: Meaningful local explanation for machine learning models.
\newblock {\em arXiv preprint arXiv:2009.05818}.

\bibitem[Botari et~al., 2019]{botari2019local}
Botari, T., Izbicki, R., and de~Carvalho, A.~C. (2019).
\newblock Local interpretation methods to machine learning using the domain of
  the feature space.
\newblock In {\em Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pages 241--252. Springer.

\bibitem[Chen et~al., 2020]{chen2020true}
Chen, H., Janizek, J.~D., Lundberg, S., and Lee, S.-I. (2020).
\newblock True to the model or true to the data?
\newblock {\em arXiv preprint arXiv:2006.16234}.

\bibitem[Covert et~al., 2020]{covert2020understanding}
Covert, I., Lundberg, S., and Lee, S.-I. (2020).
\newblock Understanding global feature contributions with additive importance
  measures.
\newblock {\em Advances in Neural Information Processing Systems}, 33.

\bibitem[Domingos, 2012]{domingos2012few}
Domingos, P. (2012).
\newblock A few useful things to know about machine learning.
\newblock {\em Communications of the ACM}, 55(10):78--87.

\bibitem[Doucet et~al., 2001]{doucet2001introduction}
Doucet, A., De~Freitas, N., and Gordon, N. (2001).
\newblock An introduction to sequential monte carlo methods.
\newblock In {\em Sequential Monte Carlo methods in practice}, pages 3--14.
  Springer.

\bibitem[Fong and Vedaldi, 2017]{fong2017interpretable}
Fong, R.~C. and Vedaldi, A. (2017).
\newblock Interpretable explanations of black boxes by meaningful perturbation.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision}, pages 3429--3437.

\bibitem[Frye et~al., 2020]{frye2020shapley}
Frye, C., de~Mijolla, D., Cowton, L., Stanley, M., and Feige, I. (2020).
\newblock Shapley-based explainability on the data manifold.
\newblock {\em arXiv preprint arXiv:2006.01272}.

\bibitem[Frye et~al., 2019]{frye2019asymmetric}
Frye, C., Feige, I., and Rowat, C. (2019).
\newblock Asymmetric shapley values: incorporating causal knowledge into
  model-agnostic explainability.
\newblock {\em arXiv preprint arXiv:1910.06358}.

\bibitem[Gade et~al., 2020]{gade2020explainable}
Gade, K., Geyik, S., Kenthapadi, K., Mithal, V., and Taly, A. (2020).
\newblock Explainable ai in industry: Practical challenges and lessons learned.
\newblock In {\em Companion Proceedings of the Web Conference 2020}, pages
  303--304.

\bibitem[Garreau and von Luxburg, 2020]{garreau2020looking}
Garreau, D. and von Luxburg, U. (2020).
\newblock Looking deeper into lime.
\newblock {\em arXiv preprint arXiv:2008.11092}.

\bibitem[Ghorbani et~al., 2019]{ghorbani2019interpretation}
Ghorbani, A., Abid, A., and Zou, J. (2019).
\newblock Interpretation of neural networks is fragile.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 3681--3688.

\bibitem[Guidotti et~al., 2018]{guidotti2018local}
Guidotti, R., Monreale, A., Ruggieri, S., Pedreschi, D., Turini, F., and
  Giannotti, F. (2018).
\newblock Local rule-based explanations of black box decision systems.
\newblock {\em arXiv preprint arXiv:1805.10820}.

\bibitem[Hancox-Li, 2020]{hancox2020robustness}
Hancox-Li, L. (2020).
\newblock Robustness in machine learning explanations: does it matter?
\newblock In {\em Proceedings of the 2020 conference on fairness,
  accountability, and transparency}, pages 640--647.

\bibitem[Holzinger et~al., 2017]{holzinger2017we}
Holzinger, A., Biemann, C., Pattichis, C.~S., and Kell, D.~B. (2017).
\newblock What do we need to build explainable ai systems for the medical
  domain?
\newblock {\em arXiv preprint arXiv:1712.09923}.

\bibitem[Janzing et~al., 2020]{janzing2020feature}
Janzing, D., Minorics, L., and Bl{\"o}baum, P. (2020).
\newblock Feature relevance quantification in explainable ai: A causal problem.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 2907--2916. PMLR.

\bibitem[Lundberg and Lee, 2017]{lundberg2017unified}
Lundberg, S. and Lee, S.-I. (2017).
\newblock A unified approach to interpreting model predictions.
\newblock {\em arXiv preprint arXiv:1705.07874}.

\bibitem[Merrick and Taly, 2020]{merrick2020explanation}
Merrick, L. and Taly, A. (2020).
\newblock The explanation game: Explaining machine learning models using
  shapley values.
\newblock In {\em International Cross-Domain Conference for Machine Learning
  and Knowledge Extraction}, pages 17--38. Springer.

\bibitem[Nadaraya, 1964]{nadaraya1964estimating}
Nadaraya, E.~A. (1964).
\newblock On estimating regression.
\newblock {\em Theory of Probability \& Its Applications}, 9(1):141--142.

\bibitem[Rajapaksha et~al., 2020]{rajapaksha2020lormika}
Rajapaksha, D., Bergmeir, C., and Buntine, W. (2020).
\newblock Lormika: Local rule-based model interpretability with k-optimal
  associations.
\newblock {\em Information Sciences}, 540:221--241.

\bibitem[Rasouli and Yu, 2019]{rasouli2019meaningful}
Rasouli, P. and Yu, I.~C. (2019).
\newblock Meaningful data sampling for a faithful local explanation method.
\newblock In {\em International Conference on Intelligent Data Engineering and
  Automated Learning}, pages 28--38. Springer.

\bibitem[Rasouli and Yu, 2020]{rasouli2020explan}
Rasouli, P. and Yu, I.~C. (2020).
\newblock Explan: Explaining black-box classifiers using adaptive neighborhood
  generation.
\newblock In {\em 2020 International Joint Conference on Neural Networks
  (IJCNN)}, pages 1--9. IEEE.

\bibitem[Ribeiro et~al., 2016]{ribeiro2016should}
Ribeiro, M.~T., Singh, S., and Guestrin, C. (2016).
\newblock " why should i trust you?" explaining the predictions of any
  classifier.
\newblock In {\em Proceedings of the 22nd ACM SIGKDD international conference
  on knowledge discovery and data mining}, pages 1135--1144.

\bibitem[Robnik-{\v{S}}ikonja and Bohanec, 2018]{robnik2018perturbation}
Robnik-{\v{S}}ikonja, M. and Bohanec, M. (2018).
\newblock Perturbation-based explanations of prediction models.
\newblock In {\em Human and machine learning}, pages 159--175. Springer.

\bibitem[Roscher et~al., 2020]{roscher2020explainable}
Roscher, R., Bohn, B., Duarte, M.~F., and Garcke, J. (2020).
\newblock Explainable machine learning for scientific insights and discoveries.
\newblock {\em IEEE Access}, 8:42200--42216.

\bibitem[Ruppert and Wand, 1994]{ruppert1994multivariate}
Ruppert, D. and Wand, M.~P. (1994).
\newblock Multivariate locally weighted least squares regression.
\newblock {\em The annals of statistics}, pages 1346--1370.

\bibitem[Saito et~al., 2020]{saito2020improving}
Saito, S., Chua, E., Capel, N., and Hu, R. (2020).
\newblock Improving lime robustness with smarter locality sampling.
\newblock {\em arXiv preprint arXiv:2006.12302}.

\bibitem[Slack et~al., 2020]{slack2020fooling}
Slack, D., Hilgard, S., Jia, E., Singh, S., and Lakkaraju, H. (2020).
\newblock Fooling lime and shap: Adversarial attacks on post hoc explanation
  methods.
\newblock In {\em Proceedings of the AAAI/ACM Conference on AI, Ethics, and
  Society}, pages 180--186.

\bibitem[Smilkov et~al., 2017]{smilkov2017smoothgrad}
Smilkov, D., Thorat, N., Kim, B., Vi{\'e}gas, F., and Wattenberg, M. (2017).
\newblock Smoothgrad: removing noise by adding noise.
\newblock {\em arXiv preprint arXiv:1706.03825}.

\bibitem[Sundararajan and Najmi, 2020]{sundararajan2020many}
Sundararajan, M. and Najmi, A. (2020).
\newblock The many shapley values for model explanation.
\newblock In {\em International Conference on Machine Learning}, pages
  9269--9278. PMLR.

\bibitem[Visani et~al., 2020]{visani2020optilime}
Visani, G., Bagli, E., and Chesani, F. (2020).
\newblock Optilime: Optimized lime explanations for diagnostic computer
  algorithms.
\newblock {\em arXiv preprint arXiv:2006.05714}.

\bibitem[Watson, 1964]{watson1964smooth}
Watson, G.~S. (1964).
\newblock Smooth regression analysis.
\newblock {\em Sankhy{\=a}: The Indian Journal of Statistics, Series A}, pages
  359--372.

\bibitem[White and Garcez, 2019]{white2019measurable}
White, A. and Garcez, A.~d. (2019).
\newblock Measurable counterfactual local explanations for any classifier.
\newblock {\em arXiv preprint arXiv:1908.03020}.

\bibitem[Yeh et~al., 2019]{yeh2019fidelity}
Yeh, C.-K., Hsieh, C.-Y., Suggala, A.~S., Inouye, D.~I., and Ravikumar, P.
  (2019).
\newblock On the (in) fidelity and sensitivity for explanations.
\newblock {\em arXiv preprint arXiv:1901.09392}.

\end{thebibliography}
