
@article{shalev2016safe,
  title={Safe, multi-agent, reinforcement learning for autonomous driving},
  author={Shalev-Shwartz, Shai and Shammah, Shaked and Shashua, Amnon},
  journal={arXiv preprint arXiv:1610.03295},
  year={2016}
}

@article{brambilla2013swarm,
  title={Swarm robotics: a review from the swarm engineering perspective},
  author={Brambilla, Manuele and Ferrante, Eliseo and Birattari, Mauro and Dorigo, Marco},
  journal={Swarm Intelligence},
  volume={7},
  number={1},
  pages={1--41},
  year={2013},
  publisher={Springer}
}

@inproceedings{baker2020emergent,
title={Emergent Tool Use From Multi-Agent Autocurricula},
author={Bowen Baker and Ingmar Kanitscheider and Todor Markov and Yi Wu and Glenn Powell and Bob McGrew and Igor Mordatch},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=SkxpxJBKwS}
}

@misc{openaidota,
  author = {OpenAI},
  title = {OpenAI Five},
  howpublished = {\url{https://blog.openai.com/openai-five/}},
  year = {2018},
}


@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{krishnamurthy2016pac,
  title={PAC reinforcement learning with rich observations},
  author={Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John},
  journal={arXiv preprint arXiv:1602.02722},
  year={2016}
}

@book{wainwright2019high,
  title={High-dimensional statistics: A non-asymptotic viewpoint},
  author={Wainwright, Martin J},
  volume={48},
  year={2019},
  publisher={Cambridge University Press}
}

@book{filar2012competitive,
  title={Competitive Markov decision processes},
  author={Filar, Jerzy and Vrieze, Koos},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@article{jin2021bellman,
  title={Bellman Eluder Dimension: New Rich Classes of RL Problems, and Sample-Efficient Algorithms},
  author={Jin, Chi and Liu, Qinghua and Miryoosefi, Sobhan},
  journal={arXiv preprint arXiv:2102.00815},
  year={2021}
}

@article{yang2020bridging,
  title={Bridging exploration and general function approximation in reinforcement learning: Provably efficient kernel and neural value iterations},
  author={Yang, Zhuoran and Jin, Chi and Wang, Zhaoran and Wang, Mengdi and Jordan, Michael I},
  journal={arXiv preprint arXiv:2011.04622},
  year={2020}
}

@article{vinyals2019grandmaster,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Michael and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group}
}


@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@book{anderson2007optimal,
  title={Optimal control: linear quadratic methods},
  author={Anderson, Brian DO and Moore, John B},
  year={2007},
  publisher={Courier Corporation}
}


@book{lattimore2020bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}


@inproceedings{agarwal2014taming,
  title={Taming the monster: A fast and simple algorithm for contextual bandits},
  author={Agarwal, Alekh and Hsu, Daniel and Kale, Satyen and Langford, John and Li, Lihong and Schapire, Robert},
  booktitle={International Conference on Machine Learning},
  pages={1638--1646},
  year={2014}
}

@article{dean2019sample,
  title={On the sample complexity of the linear quadratic regulator},
  author={Dean, Sarah and Mania, Horia and Matni, Nikolai and Recht, Benjamin and Tu, Stephen},
  journal={Foundations of Computational Mathematics},
  pages={1--47},
  year={2019},
  publisher={Springer}
}

@article{singh2012predictive,
  title={Predictive state representations: A new theory for modeling dynamical systems},
  author={Singh, Satinder and James, Michael and Rudary, Matthew},
  journal={arXiv preprint arXiv:1207.4167},
  year={2012}
}

@article{bartlett2008high,
  title={High-probability regret bounds for bandit online linear optimization},
  author={Bartlett, Peter L and Dani, Varsha and Hayes, Thomas and Kakade, Sham and Rakhlin, Alexander and Tewari, Ambuj},
  year={2008}
}
@inproceedings{fazel2018global,
  title={Global convergence of policy gradient methods for the linear quadratic regulator},
  author={Fazel, Maryam and Ge, Rong and Kakade, Sham and Mesbahi, Mehran},
  booktitle={International Conference on Machine Learning},
  pages={1467--1476},
  year={2018},
  organization={PMLR}
}
@inproceedings{simchowitz2018learning,
  title={Learning without mixing: Towards a sharp analysis of linear system identification},
  author={Simchowitz, Max and Mania, Horia and Tu, Stephen and Jordan, Michael I and Recht, Benjamin},
  booktitle={Conference On Learning Theory},
  pages={439--473},
  year={2018},
  organization={PMLR}
}


@article{wang2020provably,
  title={Provably Efficient Reinforcement Learning with General Value Function Approximation},
  author={Wang, Ruosong and Salakhutdinov, Ruslan and Yang, Lin F},
  journal={arXiv preprint arXiv:2005.10804},
  year={2020}
}
@phdthesis{li2009unifying,
  title={A unifying framework for computational reinforcement learning theory},
  author={Li, Lihong},
  year={2009},
  school={Rutgers University-Graduate School-New Brunswick}
}

@inproceedings{jiang2017contextual,
  title={Contextual decision processes with low bellman rank are pac-learnable},
  author={Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John and Schapire, Robert E},
  booktitle={International Conference on Machine Learning},
  pages={1704--1713},
  year={2017},
  organization={PMLR}
}
@inproceedings{zanette2020frequentist,
  title={Frequentist regret bounds for randomized least-squares value iteration},
  author={Zanette, Andrea and Brandfonbrener, David and Brunskill, Emma and Pirotta, Matteo and Lazaric, Alessandro},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1954--1964},
  year={2020},
  organization={PMLR}
}

@inproceedings{dong2020root,
  title={Root-n-Regret for Learning in Markov Decision Processes with Function Approximation and Low Bellman Rank},
  author={Dong, Kefan and Peng, Jian and Wang, Yining and Zhou, Yuan},
  booktitle={Conference on Learning Theory},
  pages={1554--1557},
  year={2020},
  organization={PMLR}
}

@article{sutton1988learning,
  title={Learning to predict by the methods of temporal differences},
  author={Sutton, Richard S},
  journal={Machine learning},
  volume={3},
  number={1},
  pages={9--44},
  year={1988},
  publisher={Springer}
}
@book{vapnik2013nature,
  title={The nature of statistical learning theory},
  author={Vapnik, Vladimir},
  year={2013},
  publisher={Springer science \& business media}
}


@article{brafman2002r,
  title={R-max-a general polynomial time algorithm for near-optimal reinforcement learning},
  author={Brafman, Ronen I and Tennenholtz, Moshe},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Oct},
  pages={213--231},
  year={2002}
}
@article{bradtke1996linear,
  title={Linear least-squares algorithms for temporal difference learning},
  author={Bradtke, Steven J and Barto, Andrew G},
  journal={Machine learning},
  volume={22},
  number={1-3},
  pages={33--57},
  year={1996},
  publisher={Springer}
}
@article{bartlett2002rademacher,
  title={Rademacher and Gaussian complexities: Risk bounds and structural results},
  author={Bartlett, Peter L and Mendelson, Shahar},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Nov},
  pages={463--482},
  year={2002}
}

@article{littlestone1988learning,
  title={Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm},
  author={Littlestone, Nick},
  journal={Machine learning},
  volume={2},
  number={4},
  pages={285--318},
  year={1988},
  publisher={Springer}
}

@article{jaksch2010near,
  title={Near-optimal Regret Bounds for Reinforcement Learning.},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={4},
  year={2010}
}
@inproceedings{dann2015sample,
  title={Sample complexity of episodic fixed-horizon reinforcement learning},
  author={Dann, Christoph and Brunskill, Emma},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2818--2826},
  year={2015}
}
@article{rakhlin2010online,
  title={Online learning: Random averages, combinatorial parameters, and learnability},
  author={Rakhlin, Alexander and Sridharan, Karthik and Tewari, Ambuj},
  year={2010}
}

@inproceedings{agrawal2017optimistic,
  title={Optimistic posterior sampling for reinforcement learning: worst-case regret bounds},
  author={Agrawal, Shipra and Jia, Randy},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1184--1194},
  year={2017}
}
@article{tsitsiklis1997analysis,
  title={An analysis of temporal-difference learning with function approximation},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  journal={IEEE transactions on automatic control},
  volume={42},
  number={5},
  pages={674--690},
  year={1997},
  publisher={IEEE}
}
@inproceedings{lattimore2020learning,
  title={Learning with good feature representations in bandits and in rl with a generative model},
  author={Lattimore, Tor and Szepesvari, Csaba and Weisz, Gellert},
  booktitle={International Conference on Machine Learning},
  pages={5662--5670},
  year={2020},
  organization={PMLR}
}

@article{azar2017minimax,
  title={Minimax regret bounds for reinforcement learning},
  author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:1703.05449},
  year={2017}
}

@inproceedings{jin2018q,
  title={Is Q-learning provably efficient?},
  author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4863--4873},
  year={2018}
}
@article{zanette2019tighter,
  title={Tighter problem-dependent regret bounds in reinforcement learning without domain knowledge using value function bounds},
  author={Zanette, Andrea and Brunskill, Emma},
  journal={arXiv preprint arXiv:1901.00210},
  year={2019}
}
@article{zhang2020almost,
  title={Almost Optimal Model-Free Reinforcement Learning via Reference-Advantage Decomposition},
  author={Zhang, Zihan and Zhou, Yuan and Ji, Xiangyang},
  journal={arXiv preprint arXiv:2004.10019},
  year={2020}
}



@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2137--2143},
  year={2020}
}
@article{wang2019optimism,
  title={Optimism in reinforcement learning with generalized linear function approximation},
  author={Wang, Yining and Wang, Ruosong and Du, Simon S and Krishnamurthy, Akshay},
  journal={arXiv preprint arXiv:1912.04136},
  year={2019}
}
@article{cai2019provably,
  title={Provably efficient exploration in policy optimization},
  author={Cai, Qi and Yang, Zhuoran and Jin, Chi and Wang, Zhaoran},
  journal={arXiv preprint arXiv:1912.05830},
  year={2019}
}
@article{zanette2020learning,
  title={Learning Near Optimal Policies with Low Inherent Bellman Error},
  author={Zanette, Andrea and Lazaric, Alessandro and Kochenderfer, Mykel and Brunskill, Emma},
  journal={arXiv preprint arXiv:2003.00153},
  year={2020}
}
@article{zanette2020provably,
  title={Provably efficient reward-agnostic navigation with linear value iteration},
  author={Zanette, Andrea and Lazaric, Alessandro and Kochenderfer, Mykel J and Brunskill, Emma},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}


@inproceedings{osband2014model,
  title={Model-based reinforcement learning and the eluder dimension},
  author={Osband, Ian and Van Roy, Benjamin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1466--1474},
  year={2014}
}
@article{ayoub2020model,
  title={Model-Based Reinforcement Learning with Value-Targeted Regression},
  author={Ayoub, Alex and Jia, Zeyu and Szepesvari, Csaba and Wang, Mengdi and Yang, Lin F},
  journal={arXiv preprint arXiv:2006.01107},
  year={2020}
}
@article{foster2020instance,
  title={Instance-dependent complexity of contextual bandits and reinforcement learning: A disagreement-based perspective},
  author={Foster, Dylan J and Rakhlin, Alexander and Simchi-Levi, David and Xu, Yunzong},
  journal={arXiv preprint arXiv:2010.03104},
  year={2020}
}


@inproceedings{sun2019model,
  title={Model-based rl in contextual decision processes: Pac bounds and exponential improvements over model-free approaches},
  author={Sun, Wen and Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John},
  booktitle={Conference on Learning Theory},
  pages={2898--2933},
  year={2019}
}


@inproceedings{szepesvari2005finite,
  title={Finite time bounds for sampling based fitted value iteration},
  author={Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  booktitle={Proceedings of the 22nd international conference on Machine learning},
  pages={880--887},
  year={2005}
}
@article{munos2008finite,
  title={Finite-time bounds for fitted value iteration},
  author={Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={May},
  pages={815--857},
  year={2008}
}

@article{xie2020batch,
  title={Batch Value-function Approximation with Only Realizability},
  author={Xie, Tengyang and Jiang, Nan},
  journal={arXiv preprint arXiv:2008.04990},
  year={2020}
}
@inproceedings{russo2013eluder,
  title={Eluder dimension and the sample complexity of optimistic exploration},
  author={Russo, Daniel and Van Roy, Benjamin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2256--2264},
  year={2013}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}
@article{weisz2020exponential,
  title={Exponential Lower Bounds for Planning in MDPs With Linearly-Realizable Optimal Action-Value Functions},
  author={Weisz, Gellert and Amortila, Philip and Szepesv{\'a}ri, Csaba},
  journal={arXiv preprint arXiv:2010.01374},
  year={2020}
}

@article{li2016deep,
  title={Deep reinforcement learning for dialogue generation},
  author={Li, Jiwei and Monroe, Will and Ritter, Alan and Galley, Michel and Gao, Jianfeng and Jurafsky, Dan},
  journal={arXiv preprint arXiv:1606.01541},
  year={2016}
}
@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{neu2020unifying,
  title={A unifying view of optimism in episodic reinforcement learning},
  author={Neu, Gergely and Pike-Burke, Ciara},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}
@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015}
}

@inproceedings{dann2018oracle,
  title={On oracle-efficient PAC RL with rich observations},
  author={Dann, Christoph and Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John and Schapire, Robert E},
  booktitle={Advances in neural information processing systems},
  pages={1422--1432},
  year={2018}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}

@article{zhou2020provably,
  title={Provably efficient reinforcement learning for discounted mdps with feature mapping},
  author={Zhou, Dongruo and He, Jiafan and Gu, Quanquan},
  journal={arXiv preprint arXiv:2006.13165},
  year={2020}
}
@article{agarwal2020flambe,
  title={Flambe: Structural complexity and representation learning of low rank mdps},
  author={Agarwal, Alekh and Kakade, Sham and Krishnamurthy, Akshay and Sun, Wen},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{dudik2011efficient,
  title={Efficient optimal learning for contextual bandits},
  author={Dudik, Miroslav and Hsu, Daniel and Kale, Satyen and Karampatziakis, Nikos and Langford, John and Reyzin, Lev and Zhang, Tong},
  journal={arXiv preprint arXiv:1106.2369},
  year={2011}
}

@article{chen2019information,
  title={Information-theoretic considerations in batch reinforcement learning},
  author={Chen, Jinglin and Jiang, Nan},
  journal={arXiv preprint arXiv:1905.00360},
  year={2019}
}
@article{szepesvari2010algorithms,
  title={Algorithms for reinforcement learning},
  author={Szepesv{\'a}ri, Csaba},
  journal={Synthesis lectures on artificial intelligence and machine learning},
  volume={4},
  number={1},
  pages={1--103},
  year={2010},
  publisher={Morgan \& Claypool Publishers}
}
@inproceedings{xie2020learning,
  title={Learning zero-sum simultaneous-move markov games using function approximation and correlated equilibrium},
  author={Xie, Qiaomin and Chen, Yudong and Wang, Zhaoran and Yang, Zhuoran},
  booktitle={Conference on Learning Theory},
  pages={3674--3682},
  year={2020},
  organization={PMLR}
}
@article{pachter2010discrete,
  title={Discrete-time linear-quadratic dynamic games},
  author={Pachter, M and Pham, KD},
  journal={Journal of Optimization Theory and Applications},
  volume={146},
  number={1},
  pages={151--179},
  year={2010},
  publisher={Springer}
}
@article{bu2019global,
  title={Global convergence of policy gradient for sequential zero-sum linear quadratic dynamic games},
  author={Bu, Jingjing and Ratliff, Lillian J and Mesbahi, Mehran},
  journal={arXiv preprint arXiv:1911.04672},
  year={2019}
}
@inproceedings{bai2020provable,
  title={Provable self-play algorithms for competitive reinforcement learning},
  author={Bai, Yu and Jin, Chi},
  booktitle={International Conference on Machine Learning},
  pages={551--560},
  year={2020},
  organization={PMLR}
}

@article{tian2020provably,
  title={Online Learning in Unknown Markov Games},
  author={Tian, Yi and Wang, Yuanhao and Yu, Tiancheng and Sra, Suvrit},
  journal={arXiv preprint arXiv:2010.15020},
  year={2021}
}

@article{bai2020near,
  title={Near-Optimal Reinforcement Learning with Self-Play},
  author={Bai, Yu and Jin, Chi and Yu, Tiancheng},
  journal={arXiv preprint arXiv:2006.12007},
  year={2020}
}

@article{shapley1953stochastic,
  title={Stochastic games},
  author={Shapley, Lloyd S},
  journal={Proceedings of the national academy of sciences},
  volume={39},
  number={10},
  pages={1095--1100},
  year={1953},
  publisher={National Acad Sciences}
}

@incollection{littman1994markov,
  title={Markov games as a framework for multi-agent reinforcement learning},
  author={Littman, Michael L},
  booktitle={Machine learning proceedings 1994},
  pages={157--163},
  year={1994},
  publisher={Elsevier}
}

@inproceedings{littman2001friend,
  title={Friend-or-foe Q-learning in general-sum games},
  author={Littman, Michael L},
  booktitle={ICML},
  volume={1},
  pages={322--328},
  year={2001}
}

@article{hu2003nash,
  title={Nash Q-learning for general-sum stochastic games},
  author={Hu, Junling and Wellman, Michael P},
  journal={Journal of machine learning research},
  volume={4},
  number={Nov},
  pages={1039--1069},
  year={2003}
}

@article{hansen2013strategy,
  title={Strategy iteration is strongly polynomial for 2-player turn-based stochastic games with a constant discount factor},
  author={Hansen, Thomas Dueholm and Miltersen, Peter Bro and Zwick, Uri},
  journal={Journal of the ACM (JACM)},
  volume={60},
  number={1},
  pages={1--16},
  year={2013},
  publisher={ACM New York, NY, USA}
}

@article{wei2020linear,
  title={Linear Last-iterate Convergence in Constrained Saddle-point Optimization},
  author={Wei, Chen-Yu and Lee, Chung-Wei and Zhang, Mengxiao and Luo, Haipeng},
  journal={arXiv e-prints},
  pages={arXiv--2006},
  year={2020}
}

@article{jia2019feature,
  title={Feature-based q-learning for two-player stochastic games},
  author={Jia, Zeyu and Yang, Lin F and Wang, Mengdi},
  journal={arXiv preprint arXiv:1906.00423},
  year={2019}
}

@inproceedings{sidford2020solving,
  title={Solving discounted stochastic two-player games with near-optimal time and sample complexity},
  author={Sidford, Aaron and Wang, Mengdi and Yang, Lin and Ye, Yinyu},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2992--3002},
  year={2020},
  organization={PMLR}
}

@article{zhang2020model,
  title={Model-based multi-agent rl in zero-sum markov games with near-optimal sample complexity},
  author={Zhang, Kaiqing and Kakade, Sham M and Ba{\c{s}}ar, Tamer and Yang, Lin F},
  journal={arXiv preprint arXiv:2007.07461},
  year={2020}
}

@article{wei2017online,
  title={Online reinforcement learning in stochastic games},
  author={Wei, Chen-Yu and Hong, Yi-Te and Lu, Chi-Jen},
  journal={arXiv preprint arXiv:1712.00579},
  year={2017}
}

@article{wei2021last,
  title={Last-iterate Convergence of Decentralized Optimistic Gradient Descent/Ascent in Infinite-horizon Competitive Markov Games},
  author={Wei, Chen-Yu and Lee, Chung-Wei and Zhang, Mengxiao and Luo, Haipeng},
  journal={arXiv preprint arXiv:2102.04540},
  year={2021}
}

@article{liu2020sharp,
  title={A Sharp Analysis of Model-based Reinforcement Learning with Self-Play},
  author={Liu, Qinghua and Yu, Tiancheng and Bai, Yu and Jin, Chi},
  journal={arXiv preprint arXiv:2010.01604},
  year={2020}
}

@article{yu2021provably,
  title={Provably Efficient Algorithms for Multi-Objective Competitive RL},
  author={Yu, Tiancheng and Tian, Yi and Zhang, Jingzhao and Sra, Suvrit},
  journal={arXiv preprint arXiv:2102.03192},
  year={2021}
}

@article{chen2021almost,
  title={Almost Optimal Algorithms for Two-player Markov Games with Linear Function Approximation},
  author={Chen, Zixiang and Zhou, Dongruo and Gu, Quanquan},
  journal={arXiv preprint arXiv:2102.07404},
  year={2021}
}

@article{du2021bilinear,
  title={Bilinear classes: A structural framework for provable generalization in rl},
  author={Du, Simon S and Kakade, Sham M and Lee, Jason D and Lovett, Shachar and Mahajan, Gaurav and Sun, Wen and Wang, Ruosong},
  journal={arXiv preprint arXiv:2103.10897},
  year={2021}
}

@article{berner2019dota,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and Debiak, Przemyslaw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}

@article{li2020multi,
  title={Multi-Agent Trust Region Policy Optimization},
  author={Li, Hepeng and He, Haibo},
  journal={arXiv preprint arXiv:2010.07916},
  year={2020}
}

@article{yu2021surprising,
  title={The Surprising Effectiveness of MAPPO in Cooperative, Multi-Agent Games},
  author={Yu, Chao and Velu, Akash and Vinitsky, Eugene and Wang, Yu and Bayen, Alexandre and Wu, Yi},
  journal={arXiv preprint arXiv:2103.01955},
  year={2021}
}

@inproceedings{rashid2018qmix,
  title={Qmix: Monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and Schroeder, Christian and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  booktitle={International Conference on Machine Learning},
  pages={4295--4304},
  year={2018},
  organization={PMLR}
}

@article{lowe2017multi,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and Wu, Yi and Tamar, Aviv and Harb, Jean and Abbeel, Pieter and Mordatch, Igor},
  journal={arXiv preprint arXiv:1706.02275},
  year={2017}
}

@article{zinkevich2007regret,
  title={Regret minimization in games with incomplete information},
  author={Zinkevich, Martin and Johanson, Michael and Bowling, Michael and Piccione, Carmelo},
  journal={Advances in neural information processing systems},
  volume={20},
  pages={1729--1736},
  year={2007}
}

@article{celli2020no,
  title={No-regret learning dynamics for extensive-form correlated equilibrium},
  author={Celli, Andrea and Marchesi, Alberto and Farina, Gabriele and Gatti, Nicola},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@article{koller1992complexity,
  title={The complexity of two-person zero-sum games in extensive form},
  author={Koller, Daphne and Megiddo, Nimrod},
  journal={Games and economic behavior},
  volume={4},
  number={4},
  pages={528--552},
  year={1992},
  publisher={Elsevier}
}

@inproceedings{gilpin2006finding,
  title={Finding equilibria in large sequential games of imperfect information},
  author={Gilpin, Andrew and Sandholm, Tuomas},
  booktitle={Proceedings of the 7th ACM conference on Electronic commerce},
  pages={160--169},
  year={2006}
}

@article{brown2019superhuman,
  title={Superhuman AI for multiplayer poker},
  author={Brown, Noam and Sandholm, Tuomas},
  journal={Science},
  volume={365},
  number={6456},
  pages={885--890},
  year={2019},
  publisher={American Association for the Advancement of Science}
}

@article{brown2018superhuman,
  title={Superhuman AI for heads-up no-limit poker: Libratus beats top professionals},
  author={Brown, Noam and Sandholm, Tuomas},
  journal={Science},
  volume={359},
  number={6374},
  pages={418--424},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

@article{vial2021improved,
  title={Improved Algorithms for Misspecified Linear Markov Decision Processes},
  author={Vial, Daniel and Parulekar, Advait and Shakkottai, Sanjay and Srikant, R},
  journal={arXiv preprint arXiv:2109.05546},
  year={2021}
}