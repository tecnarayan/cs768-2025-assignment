\begin{thebibliography}{10}

\bibitem{ahmadi2014dsos}
Amir~Ali Ahmadi and Anirudha Majumdar.
\newblock Dsos and sdsos optimization: Lp and socp-based alternatives to sum of
  squares optimization.
\newblock In {\em 2014 48th annual conference on information sciences and
  systems (CISS)}, pages 1--5. IEEE, 2014.

\bibitem{pmlr-v97-anil19a}
Cem Anil, James Lucas, and Roger Grosse.
\newblock Sorting out {L}ipschitz function approximation.
\newblock In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, {\em
  Proceedings of the 36th International Conference on Machine Learning},
  volume~97 of {\em Proceedings of Machine Learning Research}, pages 291--301,
  Long Beach, California, USA, 09--15 Jun 2019. PMLR.

\bibitem{arjovsky2017wasserstein}
Martin Arjovsky, Soumith Chintala, and L{\'e}on Bottou.
\newblock Wasserstein generative adversarial networks.
\newblock In {\em International conference on machine learning}, pages
  214--223, 2017.

\bibitem{bezanson2017julia}
Jeff Bezanson, Alan Edelman, Stefan Karpinski, and Viral~B Shah.
\newblock Julia: A fresh approach to numerical computing.
\newblock {\em SIAM review}, 59(1):65--98, 2017.

\bibitem{bolte2019conservative}
J{\'e}r{\^o}me Bolte and Edouard Pauwels.
\newblock Conservative set valued fields, automatic differentiation, stochastic
  gradient method and deep learning.
\newblock {\em arXiv preprint arXiv:1909.10300}, 2019.

\bibitem{boopathy2019cnn}
Akhilan Boopathy, Tsui-Wei Weng, Pin-Yu Chen, Sijia Liu, and Luca Daniel.
\newblock Cnn-cert: An efficient framework for certifying robustness of
  convolutional neural networks.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 3240--3247, 2019.

\bibitem{combettes2019lipschitz}
Patrick~L Combettes and Jean-Christophe Pesquet.
\newblock Lipschitz certificates for neural network structures driven by
  averaged activation operators.
\newblock {\em arXiv preprint arXiv:1903.01014}, 2019.

\bibitem{dvijotham2018dual}
Krishnamurthy Dvijotham, Robert Stanforth, Sven Gowal, Timothy~A Mann, and
  Pushmeet Kohli.
\newblock A dual approach to scalable verification of deep networks.
\newblock In {\em UAI}, pages 550--559, 2018.

\bibitem{fazlyab2019safety}
Mahyar Fazlyab, Manfred Morari, and George~J Pappas.
\newblock Safety verification and robustness analysis of neural networks via
  quadratic constraints and semidefinite programming.
\newblock {\em arXiv preprint arXiv:1903.01287}, 2019.

\bibitem{fazlyab2019efficient}
Mahyar Fazlyab, Alexander Robey, Hamed Hassani, Manfred Morari, and George~J.
  Pappas.
\newblock Efficient and accurate estimation of lipschitz constants for deep
  neural networks, 2019.

\bibitem{gulrajani2017improved}
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron~C
  Courville.
\newblock Improved training of wasserstein gans.
\newblock In {\em Advances in neural information processing systems}, pages
  5767--5777, 2017.

\bibitem{henrion2009gloptipoly}
Didier Henrion, Jean-Bernard Lasserre, and Johan L{\"o}fberg.
\newblock Gloptipoly 3: moments, optimization and semidefinite programming.
\newblock {\em Optimization Methods \& Software}, 24(4-5):761--779, 2009.

\bibitem{huster2018limitations}
Todd Huster, Cho-Yu~Jason Chiang, and Ritu Chadha.
\newblock Limitations of the lipschitz constant as a defense against
  adversarial examples.
\newblock In {\em Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pages 16--29. Springer, 2018.

\bibitem{kakade2018provably}
Sham~M Kakade and Jason~D Lee.
\newblock Provably correct automatic sub-differentiation for qualified
  programs.
\newblock In {\em Advances in neural information processing systems}, pages
  7125--7135, 2018.

\bibitem{krivine1964anneaux}
Jean-Louis Krivine.
\newblock Anneaux pr{\'e}ordonn{\'e}s.
\newblock {\em Journal d’Analyse Math\'{e}matique}, 12(1):307--326, 1964.

\bibitem{lasserreicm2018}
J.~B. Lasserre.
\newblock The {M}oment-{SOS} {H}ierarchy.
\newblock In B.~Sirakov, P.~Ney de~Souza, and M.~Viana, editors, {\em
  Proceedings of the International Congress of Mathematicians (ICM 2018)},
  volume~4, pages 3773--3794, Rio de Janeiro, 2019. World Scientific,
  Singapore.

\bibitem{lasserre2001global}
Jean~B Lasserre.
\newblock Global optimization with polynomials and the problem of moments.
\newblock {\em SIAM Journal on optimization}, 11(3):796--817, 2001.

\bibitem{lasserre2006convergent}
Jean~B Lasserre.
\newblock Convergent sdp-relaxations in polynomial optimization with sparsity.
\newblock {\em SIAM Journal on Optimization}, 17(3):822--843, 2006.

\bibitem{lasserre2017bounded}
Jean~B Lasserre, Kim-Chuan Toh, and Shouguang Yang.
\newblock A bounded degree sos hierarchy for polynomial optimization.
\newblock {\em EURO Journal on Computational Optimization}, 5(1-2):87--117,
  2017.

\bibitem{lasserre2015introduction}
Jean~Bernard Lasserre.
\newblock {\em An introduction to polynomial and semi-algebraic optimization},
  volume~52.
\newblock Cambridge University Press, 2015.

\bibitem{latorre2020lipschitz}
Fabian Latorre, Paul Rolland, and Volkan Cevher.
\newblock Lipschitz constant estimation of neural networks via sparse
  polynomial optimization.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{laurent2003comparison}
Monique Laurent.
\newblock A comparison of the sherali-adams, lov{\'a}sz-schrijver, and lasserre
  relaxations for 0--1 programming.
\newblock {\em Mathematics of Operations Research}, 28(3):470--496, 2003.

\bibitem{lofberg2004yalmip}
Johan L{\"o}fberg.
\newblock Yalmip: A toolbox for modeling and optimization in matlab.
\newblock In {\em Proceedings of the CACSD Conference}, volume~3. Taipei,
  Taiwan, 2004.

\bibitem{magron1}
V.~Magron, G.~Constantinides, and A.~Donaldson.
\newblock Certified roundoff error bounds using semidefinite programming.
\newblock {\em ACM Trans. Math. Softw.}, 43(4):1--34, 2017.

\bibitem{miyato2018spectral}
Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida.
\newblock Spectral normalization for generative adversarial networks.
\newblock {\em arXiv preprint arXiv:1802.05957}, 2018.

\bibitem{opf1}
D.~K. Molzahn and I.~A. Hiskens.
\newblock A survey of relaxations and approximations of the power flow
  equations.
\newblock {\em Foundations and Trends® in Electric Energy Systems},
  4(1-2):1--221, 2019.

\bibitem{opf3}
D.~K. Molzahn, I.~A. Hiskens, C.~Josz, and P.~Panciatici.
\newblock Computational analysis of sparsity-exploiting moment relaxations of
  the opf problem.
\newblock In {\em Proceedings of the PSCC Conference}. Genoa, Italy, IEEE,
  2016.

\bibitem{nie2014optimality}
Jiawang Nie.
\newblock Optimality conditions and finite convergence of lasserre’s
  hierarchy.
\newblock {\em Mathematical programming}, 146(1-2):97--121, 2014.

\bibitem{putinar1993positive}
Mihai Putinar.
\newblock Positive polynomials on compact semi-algebraic sets.
\newblock {\em Indiana University Mathematics Journal}, 42(3):969--984, 1993.

\bibitem{raghunathan2018certified}
Aditi Raghunathan, Jacob Steinhardt, and Percy Liang.
\newblock Certified defenses against adversarial examples.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{Raghuathan18}
Aditi Raghunathan, Jacob Steinhardt, and Percy Liang.
\newblock Semidefinite relaxations for certifying robustness to adversarial
  examples.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  10877--10887, 2018.

\bibitem{shor1987quadratic}
Naum~Z Shor.
\newblock Quadratic optimization problems.
\newblock {\em Soviet Journal of Computer and Systems Sciences}, 25:1--11,
  1987.

\bibitem{stengle1974nullstellensatz}
Gilbert Stengle.
\newblock A nullstellensatz and a positivstellensatz in semialgebraic geometry.
\newblock {\em Mathematische Annalen}, 207(2):87--97, 1974.

\bibitem{tjeng2017evaluating}
Vincent Tjeng, Kai Xiao, and Russ Tedrake.
\newblock Evaluating robustness of neural networks with mixed integer
  programming.
\newblock {\em arXiv preprint arXiv:1711.07356}, 2017.

\bibitem{tsuzuku2018lipschitz}
Yusuke Tsuzuku, Issei Sato, and Masashi Sugiyama.
\newblock Lipschitz-margin training: Scalable certification of perturbation
  invariance for deep neural networks.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6541--6550, 2018.

\bibitem{virmaux2018lipschitz}
Aladin Virmaux and Kevin Scaman.
\newblock Lipschitz regularity of deep neural networks: Analysis and efficient
  estimation.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  3835--3844, 2018.

\bibitem{waki2006sums}
Hayato Waki, Sunyoung Kim, Masakazu Kojima, and Masakazu Muramatsu.
\newblock Sums of squares and semidefinite program relaxations for polynomial
  optimization problems with structured sparsity.
\newblock {\em SIAM Journal on Optimization}, 17(1):218--242, 2006.

\bibitem{weng2018towards}
Tsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Duane Boning,
  Inderjit~S Dhillon, and Luca Daniel.
\newblock Towards fast computation of certified robustness for relu networks.
\newblock {\em arXiv preprint arXiv:1804.09699}, 2018.

\bibitem{weng2018evaluating}
Tsui-Wei Weng, Huan Zhang, Pin-Yu Chen, Jinfeng Yi, Dong Su, Yupeng Gao,
  Cho-Jui Hsieh, and Luca Daniel.
\newblock Evaluating the robustness of neural networks: An extreme value theory
  approach.
\newblock {\em arXiv preprint arXiv:1801.10578}, 2018.

\bibitem{wong2017provable}
Eric Wong and J~Zico Kolter.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope.
\newblock {\em arXiv preprint arXiv:1711.00851}, 2017.

\bibitem{zhang2018efficient}
Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel.
\newblock Efficient neural network robustness certification with general
  activation functions.
\newblock In {\em Advances in neural information processing systems}, pages
  4939--4948, 2018.

\end{thebibliography}
