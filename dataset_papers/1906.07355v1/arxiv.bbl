\begin{thebibliography}{39}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Absil et~al.(2009)Absil, Mahony, and Sepulchre]{OptMan}
Absil, P.-A., Mahony, R., and Sepulchre, R.
\newblock \emph{Optimization Algorithms on Matrix Manifolds}.
\newblock Princeton University Press, 2009.

\bibitem[Agarwal et~al.(2018)Agarwal, Boumal, Bullins, and
  Cartis]{agarwal2018adaptive}
Agarwal, N., Boumal, N., Bullins, B., and Cartis, C.
\newblock Adaptive regularization with cubics on manifolds with a first-order
  analysis.
\newblock \emph{arXiv preprint arXiv:1806.00065}, 2018.

\bibitem[Ambrose \& Singer(1953)Ambrose and Singer]{ambrosesinger}
Ambrose, W. and Singer, I.~M.
\newblock A theorem on holonomy.
\newblock \emph{Transactions of the American Mathematical Society}, 75\penalty0
  (3):\penalty0 428--443, 1953.

\bibitem[Bonnabel(2013)]{bonnabel2013stochastic}
Bonnabel, S.
\newblock Stochastic gradient descent on riemannian manifolds.
\newblock \emph{IEEE Transactions on Automatic Control}, 58\penalty0
  (9):\penalty0 2217--2229, 2013.

\bibitem[Boumal \& Absil(2011)Boumal and Absil]{boumal2011rtrmc}
Boumal, N. and Absil, P.-a.
\newblock Rtrmc: A riemannian trust-region method for low-rank matrix
  completion.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  406--414, 2011.

\bibitem[Boumal et~al.(2016{\natexlab{a}})Boumal, Absil, and
  Cartis]{Rie_trust_region}
Boumal, N., Absil, P.-A., and Cartis, C.
\newblock Global rates of convergence for nonconvex optimization on manifolds.
\newblock \emph{IMA Journal of Numerical Analysis}, 2016{\natexlab{a}}.

\bibitem[Boumal et~al.(2016{\natexlab{b}})Boumal, Voroninski, and Bandeira]{BM}
Boumal, N., Voroninski, V., and Bandeira, A.
\newblock The non-convex burer-monteiro approach works on smooth semidefinite
  programs.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2757--2765, 2016{\natexlab{b}}.

\bibitem[Boumal et~al.(2018)Boumal, Absil, and Cartis]{manifold_second}
Boumal, N., Absil, P.-A., and Cartis, C.
\newblock Global rates of convergence for nonconvex optimization on manifolds.
\newblock \emph{IMA Journal of Numerical Analysis}, pp.\  drx080, 2018.
\newblock \doi{10.1093/imanum/drx080}.
\newblock URL \url{http://dx.doi.org/10.1093/imanum/drx080}.

\bibitem[Carmon \& Duchi(2017)Carmon and Duchi]{CubicR}
Carmon, Y. and Duchi, J.~C.
\newblock Gradient descent efficiently finds the cubic-regularized non-convex
  newton step.
\newblock \emph{arXiv preprint arXiv:1612.00547}, 2017.

\bibitem[Cheeger \& Ebin(2008)Cheeger and Ebin]{MR2394158}
Cheeger, J. and Ebin, D.~G.
\newblock \emph{Comparison Theorems in {R}iemannian Geometry}.
\newblock AMS Chelsea Publishing, Providence, RI, 2008.

\bibitem[Criscitiello \& Boumal(2019)Criscitiello and
  Boumal]{Criscitiello2019Efficiently}
Criscitiello, C. and Boumal, N.
\newblock Efficiently escaping saddle points on manifolds.
\newblock \emph{arXiv preprint arXiv:1906.04321}, 2019.

\bibitem[Do~Carmo(2016)]{do2016differential}
Do~Carmo, M.~P.
\newblock \emph{Differential Geometry of Curves and Surfaces}.
\newblock Courier Dover Publications, 2016.

\bibitem[Du et~al.(2017)Du, Jin, Lee, Jordan, Singh, and Poczos]{ExpTime}
Du, S.~S., Jin, C., Lee, J.~D., Jordan, M.~I., Singh, A., and Poczos, B.
\newblock Gradient descent can take exponential time to escape saddle points.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1067--1077, 2017.

\bibitem[Edelman et~al.(1998)Edelman, Arias, and Smith]{edelman1998geometry}
Edelman, A., Arias, T.~A., and Smith, S.~T.
\newblock The geometry of algorithms with orthogonality constraints.
\newblock \emph{SIAM journal on Matrix Analysis and Applications}, 20\penalty0
  (2):\penalty0 303--353, 1998.

\bibitem[Ge et~al.(2015)Ge, Huang, Jin, and Yuan]{Ge}
Ge, R., Huang, F., Jin, C., and Yuan, Y.
\newblock Escaping from saddle points -- online stochastic gradient for tensor
  decomposition.
\newblock In \emph{Conference on Learning Theory}, pp.\  797--842, 2015.

\bibitem[Hu et~al.(2018)Hu, Milzarek, Wen, and Yuan]{MR3826674}
Hu, J., Milzarek, A., Wen, Z., and Yuan, Y.
\newblock Adaptive quadratically regularized {N}ewton method for {R}iemannian
  optimization.
\newblock \emph{SIAM J. Matrix Anal. Appl.}, 39\penalty0 (3):\penalty0
  1181--1207, 2018.

\bibitem[Ishteva et~al.(2011)Ishteva, Absil, Van~Huffel, and
  De~Lathauwer]{ishteva2011best}
Ishteva, M., Absil, P.-A., Van~Huffel, S., and De~Lathauwer, L.
\newblock Best low multilinear rank approximation of higher-order tensors,
  based on the riemannian trust-region scheme.
\newblock \emph{SIAM Journal on Matrix Analysis and Applications}, 32\penalty0
  (1):\penalty0 115--135, 2011.

\bibitem[Jin et~al.(2017{\natexlab{a}})Jin, Ge, Netrapalli, Kakade, and
  Jordan]{GeSham}
Jin, C., Ge, R., Netrapalli, P., Kakade, S.~M., and Jordan, M.~I.
\newblock How to escape saddle points efficiently.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1724--1732, 2017{\natexlab{a}}.

\bibitem[Jin et~al.(2017{\natexlab{b}})Jin, Netrapalli, and Jordan]{HeavyBall}
Jin, C., Netrapalli, P., and Jordan, M.~I.
\newblock Accelerated gradient descent escapes saddle points faster than
  gradient descent.
\newblock \emph{arXiv preprint arXiv:1711.10456}, 2017{\natexlab{b}}.

\bibitem[Karcher(1977)]{karcher}
Karcher, H.
\newblock Riemannian center of mass and mollifier smoothing.
\newblock \emph{Communications on pure and applied mathematics}, 30\penalty0
  (5):\penalty0 509--541, 1977.

\bibitem[Kasai \& Mishra(2018)Kasai and Mishra]{NIPS2018_7679}
Kasai, H. and Mishra, B.
\newblock Inexact trust-region algorithms on riemannian manifolds.
\newblock In \emph{Advances in Neural Information Processing Systems 31}, pp.\
  4254--4265. 2018.

\bibitem[Khuzani \& Li(2017)Khuzani and Li]{khuzani2017stochastic}
Khuzani, M.~B. and Li, N.
\newblock Stochastic primal-dual method on riemannian manifolds with bounded
  sectional curvature.
\newblock \emph{arXiv preprint arXiv:1703.08167}, 2017.

\bibitem[Lee et~al.(2016)Lee, Simchowitz, Jordan, and Recht]{OnlyMin}
Lee, J.~D., Simchowitz, M., Jordan, M.~I., and Recht, B.
\newblock Gradient descent only converges to minimizers.
\newblock \emph{Conference on Learning Theory}, pp.\  1246--1257, 2016.

\bibitem[Lee et~al.(2017)Lee, Panageas, Piliouras, Simchowitz, Jordan, and
  Recht]{lee2017first}
Lee, J.~D., Panageas, I., Piliouras, G., Simchowitz, M., Jordan, M.~I., and
  Recht, B.
\newblock First-order methods almost always avoid saddle points.
\newblock \emph{arXiv preprint arXiv:1710.07406}, 2017.

\bibitem[Lee(1997)]{LeeJohn97}
Lee, J.~M.
\newblock \emph{Riemannian manifolds : an introduction to curvature}.
\newblock Graduate texts in mathematics ; 176. Springer, New York, 1997.
\newblock ISBN 9780387227269.

\bibitem[Mangoubi et~al.(2018)Mangoubi, Smith, et~al.]{rapidmix}
Mangoubi, O., Smith, A., et~al.
\newblock Rapid mixing of geodesic walks on manifolds with positive curvature.
\newblock \emph{The Annals of Applied Probability}, 28\penalty0 (4):\penalty0
  2501--2543, 2018.

\bibitem[Mokhtari et~al.(2018)Mokhtari, Ozdaglar, and
  Jadbabaie]{mokhtari_constrained}
Mokhtari, A., Ozdaglar, A., and Jadbabaie, A.
\newblock Escaping saddle points in constrained optimization.
\newblock \emph{arXiv preprint arXiv:1809.02162}, 2018.

\bibitem[Nouiehed et~al.(2018)Nouiehed, Lee, and Razaviyayn]{Lee_constrained}
Nouiehed, M., Lee, J.~D., and Razaviyayn, M.
\newblock Convergence to second-order stationarity for constrained non-convex
  optimization.
\newblock \emph{arXiv preprint arXiv:1810.02024}, 2018.

\bibitem[Pemantle(1990)]{nonconvergence}
Pemantle, R.
\newblock Nonconvergence to unstable points in urn models and stochastic
  approximations.
\newblock \emph{The Annals of Probability}, pp.\  698--712, 1990.

\bibitem[Rapcs{\'a}k(2008)]{rapcsak2008sectional}
Rapcs{\'a}k, T.
\newblock Sectional curvatures in nonlinear optimization.
\newblock \emph{Journal of Global Optimization}, 40\penalty0 (1-3):\penalty0
  375--388, 2008.

\bibitem[Sakai(1996)]{Sak96}
Sakai, T.
\newblock \emph{Riemannian Geometry}, volume 149 of \emph{Translations of
  Mathematical Monographs}.
\newblock American Mathematical Society, 1996.

\bibitem[Sun et~al.(2017)Sun, Qu, and Wright]{sun2017complete}
Sun, J., Qu, Q., and Wright, J.
\newblock Complete dictionary recovery over the sphere ii: Recovery by
  riemannian trust-region method.
\newblock \emph{IEEE Transactions on Information Theory}, 63\penalty0
  (2):\penalty0 885--914, 2017.

\bibitem[Sun \& Fazel(2018)Sun and Fazel]{Yue_projected}
Sun, Y. and Fazel, M.
\newblock Escaping saddle points efficiently in equality-constrained
  optimization problems.
\newblock In \emph{Workshop on Modern Trends in Nonconvex Optimization for
  Machine Learning, International Conference on Machine Learning}, 2018.

\bibitem[Tripuraneni et~al.(2018)Tripuraneni, Flammarion, Bach, and
  Jordan]{manifold_first}
Tripuraneni, N., Flammarion, N., Bach, F., and Jordan, M.~I.
\newblock {Averaging Stochastic Gradient Descent on Riemannian Manifolds}.
\newblock \emph{arXiv preprint arXiv:1802.09128}, 2018.

\bibitem[Tu(2017)]{DiffGeo}
Tu, L.~W.
\newblock \emph{Differential geometry : connections, curvature, and
  characteristic classes}.
\newblock Graduate texts in mathematics ; 275. Springer, Cham, Switzerland,
  2017.
\newblock ISBN 9783319550848.

\bibitem[Wong(1968)]{MR0229173}
Wong, Y.-c.
\newblock Sectional curvatures of {G}rassmann manifolds.
\newblock \emph{Proc. Nat. Acad. Sci. U.S.A.}, 60:\penalty0 75--79, 1968.

\bibitem[Zhang \& Sra(2016)Zhang and Sra]{Sra_geo_convex}
Zhang, H. and Sra, S.
\newblock First-order methods for geodesically convex optimization.
\newblock \emph{arXiv:1602.06053}, 2016.
\newblock {\it Preprint}.

\bibitem[Zhang et~al.(2016)Zhang, Reddi, and Sra]{svrg_manifold}
Zhang, H., Reddi, S.~J., and Sra, S.
\newblock Riemannian svrg: fast stochastic optimization on riemannian
  manifolds.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  4592--4600, 2016.

\bibitem[Zhang \& Zhang(2018)Zhang and Zhang]{zhang2018cubic}
Zhang, J. and Zhang, S.
\newblock A cubic regularized newton's method over riemannian manifolds.
\newblock \emph{arXiv preprint arXiv:1805.05565}, 2018.

\end{thebibliography}
