\begin{thebibliography}{10}

\bibitem{kirkpatrick2017overcoming}
James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei~A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et~al.
\newblock Overcoming catastrophic forgetting in neural networks.
\newblock {\em National Academy of Sciences}, 114(13):3521--3526, 2017.

\bibitem{zenke2017continual}
Friedemann Zenke, Ben Poole, and Surya Ganguli.
\newblock Continual learning through synaptic intelligence.
\newblock In {\em Proc. International Conference on Machine Learning (ICML)}, pages 3987--3995, 2017.

\bibitem{masana2020class}
Marc Masana, Xialei Liu, Bartlomiej Twardowski, Mikel Menta, Andrew~D Bagdanov, and Joost van~de Weijer.
\newblock Class-incremental learning: {S}urvey and performance evaluation on image classification.
\newblock {\em arXiv:2010.15277}, 2020.

\bibitem{van_de_Ven_2021_CVPR}
Gido~M Ven, Zhe Li, and Andreas~S Tolias.
\newblock Class-incremental learning with generative classifiers.
\newblock In {\em Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops}, pages 3611--3620, 2021.

\bibitem{ven_three}
Gido~M Ven and Andreas~S Tolias.
\newblock Three scenarios for continual learning.
\newblock In {\em Proc. International Conference on Neural Information Processing Systems (NeurIPS) Workshop}, pages 3611--3620, 2019.

\bibitem{shin}
Hanul Shin, Jung~Kwon Lee, Jaehong Kim, and Jiwon Kim.
\newblock Continual learning with deep generative replay.
\newblock In {\em Proc. International Conference on Neural Information Processing Systems (NeurIPS) Workshop}, pages 2994--3003, 2017.

\bibitem{icarl}
Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and Christoph~H. Lampert.
\newblock {i}carl: Incremental classifier and representation learning.
\newblock In {\em Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, page 2001â€“2010, 2017.

\bibitem{aljundi2019online}
Rahaf Aljundi, Lucas Caccia, Eugene Belilovsky, Massimo Caccia, Min Lin, Laurent Charlin, and Tinne Tuytelaars.
\newblock Online continual learning with maximally interfered retrieval.
\newblock {\em arXiv:1908.04742}, 2019.

\bibitem{aljundi2019task}
Rahaf Aljundi, Klaas Kelchtermans, and Tinne Tuytelaars.
\newblock Task-free continual learning.
\newblock In {\em Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 11254--11263, 2019.

\bibitem{hayes2020lifelong}
Tyler~L. Hayes and Christopher Kanan.
\newblock Lifelong machine learning with deep streaming linear discriminant analysis.
\newblock In {\em Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops}, pages 220--221, 2020.

\bibitem{zeno2021task}
Chen Zeno, Itay Golan, Elad Hoffer, and Daniel Soudry.
\newblock Task-agnostic continual learning using online variational bayes with fixed-point updates.
\newblock {\em Neural Computation}, 33(11):3139--3177, 2021.

\bibitem{belouadah2021comprehensive}
Eden Belouadah, Adrian Popescu, and Ioannis Kanellos.
\newblock A comprehensive study of class-incremental learning algorithms for visual tasks.
\newblock {\em Neural Networks}, 135(1):38--54, 2021.

\bibitem{liu2020generative}
Xialei Liu, Chenshen Wu, Mikel Menta, Luis Herranz, Bogdan Raducanu, Andrew~D Bagdanov, Shangling Jui, and Joost~van de~Weijer.
\newblock Generative feature replay for class-incremental learning.
\newblock In {\em Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops}, pages 226--227, 2020.

\bibitem{yu2020semantic}
Lu~Yu, Bartlomiej Twardowski, Xialei Liu, Luis Herranz, Kai Wang, Yongmei Cheng, Shangling Jui, and Joost van~de Weijer.
\newblock Semantic drift compensation for class-incremental learning.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops}, pages 6982--6991, 2020.

\bibitem{zhang2020class}
Junting Zhang, Jie Zhang, Shalini Ghosh, Dawei Li, Serafettin Tasci, Larry Heck, Heming Zhang, and C-C~Jay Kuo.
\newblock Class-incremental learning via deep model consolidation.
\newblock In {\em Proc. of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, pages 1131--1140, 2020.

\bibitem{crosstask}
Albin~Soutif Cormerais, Marc Masana, Joost Van~de Weijer, and Bartlomiej Twardowski.
\newblock On the importance of cross-task features for class-incremental learning.
\newblock In {\em Proc. of International Conference on Machine Learning (ICML) Workshops}, pages 3611--3620, 2021.

\bibitem{kim2022theoretical}
Gyuhak Kim, Changnan Xiao, Tatsuya Konishi, Zixuan Ke, and Bing Liu.
\newblock A theoretical study on solving continual learning.
\newblock {\em Advances in Neural Information Processing Systems}, 35:5065--5079, 2022.

\bibitem{ven2020brain}
Gido~M Ven, Hava~T Siegelmann, and Andreas~S Tolias.
\newblock Brain-inspired replay for continual learning with artificial neural networks.
\newblock {\em Nature Communications}, 11(1):1--14, 2020.

\bibitem{li2022learning}
Jin Li, Zhong Ji, Gang Wang, Qiang Wang, and Feng Gao.
\newblock Learning from students: Online contrastive distillation network for general continual learning.
\newblock In {\em Proc. International Joint Conference on Artificial Intelligence (IJCAI)}, pages 3215--3221, 2022.

\bibitem{lomonaco2017core50}
Vincenzo Lomonaco and Davide Maltoni.
\newblock Core50: {A} new dataset and benchmark for continuous object recognition.
\newblock In {\em Proc. of International Conference on Robot Learning (ICRL)}, pages 17--26, 2017.

\bibitem{maltoni2019continuous}
Davide Maltoni and Vincenzo Lomonaco.
\newblock Continuous learning in single-incremental-task scenarios.
\newblock {\em Neural Networks}, 116(3):56--73, 2019.

\bibitem{krizhevsky2012imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock {\em Advances in neural information processing systems}, 25, 2012.

\bibitem{ramezanian2022generative}
Mahta Ramezanian-Panahi, Germ{\'a}n Abrevaya, Jean-Christophe Gagnon-Audet, Vikram Voleti, Irina Rish, and Guillaume Dumas.
\newblock Generative models of brain dynamics.
\newblock {\em Frontiers in artificial intelligence}, 5:807406, 2022.

\bibitem{geirhos2020shortcut}
Robert Geirhos, J{\"o}rn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, and Felix~A Wichmann.
\newblock Shortcut learning in deep neural networks.
\newblock {\em Nature Machine Intelligence}, 2(11):665--673, 2020.

\bibitem{yang2022chroma}
Wanqian Yang, Polina Kirichenko, Micah Goldblum, and Andrew~G Wilson.
\newblock Chroma-vae: Mitigating shortcut learning with generative classifiers.
\newblock {\em Advances in Neural Information Processing Systems}, 35:20351--20365, 2022.

\bibitem{krizhevsky2009learning}
Alex Krizhevsky.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, University of Toronto, 2009.

\bibitem{recentreg}
Ta-Chu Kao, Kristopher~T Jensen, Gido~M. Ven, Alberto Bernacchia, and Guillaume Hennequin.
\newblock Natural continual learning: success is a journey, not (just) a destination.
\newblock In {\em Proc. International Conference on Neural Information Processing Systems (NeurIPS)}, pages 1266--1275, 2020.

\bibitem{varcl}
Cuong~V Nguyen, Yingzhen Li, Thang~D Bui, and Richard~E Turner.
\newblock Variational continual learning.
\newblock In {\em Proc. International Conference on Learning Representations (ICLR)}, pages 3987--3995, 2018.

\bibitem{unif}
Sebastian Farquhar and Yarin Gal.
\newblock A unifying bayesian view of continual learning.
\newblock In {\em Proc. International Conference on Neural Information Processing Systems (NeurIPS) Workshop}, pages 3987--3995, 2018.

\bibitem{Castro}
Francisco~M. Castro, Manuel~J. Marin-Jimenez, Nicolas Guil, Cordelia Schmid, and Karteek Alahari.
\newblock End-to-end incremental learning.
\newblock In {\em Proc. of the European Conference on Computer Vision (ECCV)}, pages 233--248, 2018.

\bibitem{dhar2019learning}
Prithviraj Dhar, Rajat~Vikram Singh, Kuan-Chuan Peng, Ziyan Wu, and Rama Chellappa.
\newblock Learning without memorizing.
\newblock In {\em Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 5138--5146, 2019.

\bibitem{JoanSerra}
Joan Serra, Didac Suris, Marius Miron, and Alexandros Karatzoglou.
\newblock Overcoming catastrophic forgetting with hard attention to the task.
\newblock In {\em Proc. of International Conference on Machine Learning (ICML)}, pages 4548--4557, 2018.

\bibitem{farquhar2018towards}
Sebastian Farquhar and Yarin Gal.
\newblock Towards robust evaluations of continual learning.
\newblock {\em arXiv:1805.09733}, 2018.

\bibitem{YenChang}
Yen-Chang Hsu, Yen-Cheng Liu, Anita Ramasamy, and Zsolt Kira.
\newblock Re-evaluating continual learning scenarios: {A} categorization and case for strong baselines.
\newblock In {\em Proc. International Conference on Neural Information Processing Systems (NeurIPS) Workshop}, pages 3987--3995, 2018.

\bibitem{gener}
Gido~M Ven and Andreas~S Tolias.
\newblock Generative replay with feedback connections as a general strategy for continual learning.
\newblock {\em arXiv:1805.09733}, 2018.

\bibitem{li2020energy}
Shuang Li, Yilun Du, Gido~M. Ven, and Igor Mordatch.
\newblock Energy-based models for continual learning.
\newblock {\em arXiv:2011.12216}, 2020.

\bibitem{wu2019large}
Yue Wu, Yinpeng Chen, Lijuan Wang, Yuancheng Ye, Zicheng Liu, Yandong Guo, and Yun Fu.
\newblock Large scale incremental learning.
\newblock In {\em Proc. of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pages 374--382, 2019.

\bibitem{belouadah2020scail}
Eden Belouadah and Adrian Popescu.
\newblock Scail: Classifier weights scaling for class incremental learning.
\newblock In {\em Proc. of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, pages 1266--1275, 2020.

\bibitem{SaihuiHou}
Saihui Hou, Xinyu Pan, Chen~Change Loy, Zilei Wang, and Dahua Lin.
\newblock Learning a unified classifier incrementally via rebalancing.
\newblock In {\em Proc. International Conference on Neural Information Processing Systems (NeurIPS) Workshop}, pages 831--839, 2019.

\bibitem{TylerHayes}
Tyler~L Hayes, Kushal Kafle, Robik Shrestha, Manoj Acharya, and Christopher Kanan.
\newblock Remind your neural network to prevent catastrophic forgetting.
\newblock In {\em Proc. of European Conference on Computer Vision (ECCV)}, pages 466--483, 2020.

\bibitem{YulaiCong}
Yulai Cong, Miaoyun Zhao, Jianqiao Li, Sijia Wang, and Lawrence Carin.
\newblock {GAN} memory with no forgetting.
\newblock In {\em Proc. International Conference on Neural Information Processing Systems}, page 2994â€“3003, 2020.

\bibitem{MatthiasDe}
Matthias De~Lange and Tinne Tuytelaars.
\newblock Continual prototype evolution: {L}earning online from non-stationary data streams.
\newblock {\em arXiv:2009.00919}, 2020.

\bibitem{arslanch}
Arslan Chaudhry, Marcus Rohrbach, Mohamed Elhoseiny, Thalaiyasingam Ajanthan, Puneet~K. Dokania, Philip~HS Torr, and Marc~Aurelio Ranzato.
\newblock On tiny episodic memories in continual learning.
\newblock {\em arXiv:1902.10486}, 2019.

\bibitem{davidrolnick}
David Rolnick, Arun Ahuja, Jonathan Schwarz, Timothy~P. Lillicrap, and Greg Wayne.
\newblock Experience replay for continual learning.
\newblock In {\em Proc. International Conference on Neural Information Processing Systems}, pages 3611--3620, 2019.

\bibitem{MartinMundt}
Martin Mundt, Yong~Won Hong, Iuliia Pliushch, and Visvanathan Ramesh.
\newblock A wholistic view of continual learning with deep neural networks: Forgotten lessons and the bridge to active and open world learning.
\newblock {\em arXiv:2009.01797}, 2020.

\bibitem{LucasCaccia}
Lucas Caccia, Eugene Belilovsky, Massimo Caccia, and Joelle Pineau.
\newblock Online learned continual compression with adaptive quantization modules.
\newblock In {\em Proc. of International Conference on Machine Learning (ICML)}, pages 1240--1250, 2020.

\bibitem{Anthony}
Anthony Robins.
\newblock Catastrophic forgetting, rehearsal and pseudorehearsal.
\newblock {\em Connection Science}, 7(2):123--146, 1995.

\bibitem{TimotheLesort}
Timothe Lesort, Hugo Caselles-Dupre, Michael Garcia-Ortiz, Andrei Stoian, and David Filliat.
\newblock Generative models from the perspective of continual learning.
\newblock In {\em Proc. of International Joint Conference on Neural Networks (IJCNN)}, pages 11254--11263, 2019.

\bibitem{DiederikPKingma}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock {\em arXiv:1312.6114}, 2013.

\bibitem{YuriBurda}
Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov.
\newblock Importance weighted autoencoders.
\newblock In {\em Proc. of International Conference on Learning Representations (ICLR)}, pages 17--26, 2016.

\bibitem{TaeKyunKim}
Tae-Kyun Kim, Bjorn Stenger, Josef Kittler, and Roberto Cipolla.
\newblock Incremental linear discriminant analysis using sufficient spanning sets and its applications.
\newblock In {\em Proc. of International Journal of Computer Vision (IJCV)}, page 216â€“232, 2011.

\bibitem{ShaoningPang}
Shaoning Pang, Seiichi Ozawa, and Nikola Kasabov.
\newblock Incremental linear discriminant analysis for classification of data streams.
\newblock {\em IEEE Trans. on Systems, Man, and Cybernetics (TSMC)}, 35(5):905--914, 2005.

\end{thebibliography}
