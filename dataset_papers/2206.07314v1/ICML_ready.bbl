\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Andor et~al.(2016)Andor, Alberti, Weiss, Severyn, Presta, Ganchev,
  Petrov, and Collins]{andor2016globally}
Andor, D., Alberti, C., Weiss, D., Severyn, A., Presta, A., Ganchev, K.,
  Petrov, S., and Collins, M.
\newblock Globally normalized transition-based neural networks.
\newblock \emph{arXiv preprint arXiv:1603.06042}, 2016.

\bibitem[Andriushchenko \& Flammarion(2020)Andriushchenko and
  Flammarion]{andriushchenko2020understanding}
Andriushchenko, M. and Flammarion, N.
\newblock Understanding and improving fast adversarial training.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Augustin et~al.(2020)Augustin, Meinke, and
  Hein]{augustin2020adversarial}
Augustin, M., Meinke, A., and Hein, M.
\newblock Adversarial robustness on in-and out-distribution improves
  explainability.
\newblock In \emph{ECCV}, 2020.

\bibitem[Carlini \& Wagner(2017{\natexlab{a}})Carlini and
  Wagner]{carlini2017adversarial}
Carlini, N. and Wagner, D.
\newblock Adversarial examples are not easily detected: Bypassing ten detection
  methods.
\newblock In \emph{Proceedings of the 10th ACM Workshop on Artificial
  Intelligence and Security}, 2017{\natexlab{a}}.

\bibitem[Carlini \& Wagner(2017{\natexlab{b}})Carlini and
  Wagner]{carlini2017towards}
Carlini, N. and Wagner, D.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{CVPR}, 2017{\natexlab{b}}.

\bibitem[Carmon et~al.(2019)Carmon, Raghunathan, Schmidt, Liang, and
  Duchi]{carmon2019unlabeled}
Carmon, Y., Raghunathan, A., Schmidt, L., Liang, P., and Duchi, J.~C.
\newblock Unlabeled data improves adversarial robustness.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Castelvecchi(2016)]{castelvecchi2016deep}
Castelvecchi, D.
\newblock Deep learning boosts google translate tool.
\newblock \emph{Nature News}, 2016.

\bibitem[Croce \& Hein(2020)Croce and Hein]{croce2020reliable}
Croce, F. and Hein, M.
\newblock Reliable evaluation of adversarial robustness with an ensemble of
  diverse parameter-free attacks.
\newblock In \emph{ICML}, 2020.

\bibitem[Deng \& Yu(2014)Deng and Yu]{deng2014deep}
Deng, L. and Yu, D.
\newblock Deep learning: methods and applications.
\newblock \emph{Foundations and trends in signal processing}, 2014.

\bibitem[DeVries et~al.(2018)DeVries, Vi{\'e}gas, Wattenberg, and
  Meade]{devries2018deep}
DeVries, P.~M., Vi{\'e}gas, F., Wattenberg, M., and Meade, B.~J.
\newblock Deep learning of aftershock patterns following large earthquakes.
\newblock \emph{Nature}, 2018.

\bibitem[Engstrom et~al.(2019)Engstrom, Ilyas, Salman, Santurkar, and
  Tsipras]{robustness}
Engstrom, L., Ilyas, A., Salman, H., Santurkar, S., and Tsipras, D.
\newblock Robustness (python library), 2019.
\newblock URL \url{https://github.com/MadryLab/robustness}.

\bibitem[Esteva et~al.(2017)Esteva, Kuprel, Novoa, Ko, Swetter, Blau, and
  Thrun]{esteva2017dermatologist}
Esteva, A., Kuprel, B., Novoa, R.~A., Ko, J., Swetter, S.~M., Blau, H.~M., and
  Thrun, S.
\newblock Dermatologist-level classification of skin cancer with deep neural
  networks.
\newblock \emph{Nature}, 2017.

\bibitem[Finlayson et~al.(2019)Finlayson, Bowers, Ito, Zittrain, Beam, and
  Kohane]{finlayson2019adversarial}
Finlayson, S.~G., Bowers, J.~D., Ito, J., Zittrain, J.~L., Beam, A.~L., and
  Kohane, I.~S.
\newblock Adversarial attacks on medical machine learning.
\newblock \emph{Science}, 2019.

\bibitem[Gao et~al.(2021)Gao, Liu, Zhang, Han, Liu, Niu, and
  Sugiyama]{gao2020maximum}
Gao, R., Liu, F., Zhang, J., Han, B., Liu, T., Niu, G., and Sugiyama, M.
\newblock Maximum mean discrepancy test is aware of adversarial attacks.
\newblock In \emph{ICML}, 2021.

\bibitem[Goodfellow et~al.(2016)Goodfellow, Bengio, and
  Courville]{goodfellow2016deep}
Goodfellow, I., Bengio, Y., and Courville, A.
\newblock \emph{Deep learning}.
\newblock MIT press, 2016.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014explaining}
Goodfellow, I.~J., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{ICLR}, 2015.

\bibitem[Gowal et~al.(2019)Gowal, Uesato, Qin, Huang, Mann, and
  Kohli]{gowal2019alternative}
Gowal, S., Uesato, J., Qin, C., Huang, P.-S., Mann, T., and Kohli, P.
\newblock An alternative surrogate loss for pgd-based adversarial testing.
\newblock \emph{arXiv preprint arXiv:1910.09338}, 2019.

\bibitem[Gowal et~al.(2020)Gowal, Qin, Uesato, Mann, and
  Kohli]{gowal2020uncovering}
Gowal, S., Qin, C., Uesato, J., Mann, T., and Kohli, P.
\newblock Uncovering the limits of adversarial training against norm-bounded
  adversarial examples.
\newblock \emph{arXiv preprint arXiv:2010.03593}, 2020.

\bibitem[Grippo et~al.(1986)Grippo, Lampariello, and
  Lucidi]{grippo1986nonmonotone}
Grippo, L., Lampariello, F., and Lucidi, S.
\newblock A nonmonotone line search technique for newtonâ€™s method.
\newblock \emph{SIAM journal on Numerical Analysis}, 1986.

\bibitem[Hao et~al.(2015)Hao, Tang, Wu, Ure, Sun, Tao, Gao, Patel, Curry,
  Samaco, et~al.]{hao2015forniceal}
Hao, S., Tang, B., Wu, Z., Ure, K., Sun, Y., Tao, H., Gao, Y., Patel, A.~J.,
  Curry, D.~J., Samaco, R.~C., et~al.
\newblock Forniceal deep brain stimulation rescues hippocampal memory in rett
  syndrome mice.
\newblock \emph{Nature}, 2015.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{CVPR}, 2016.

\bibitem[Hinton et~al.(2012)Hinton, Deng, Yu, Dahl, Mohamed, Jaitly, Senior,
  Vanhoucke, Nguyen, Sainath, et~al.]{hinton2012deep}
Hinton, G., Deng, L., Yu, D., Dahl, G.~E., Mohamed, A.-r., Jaitly, N., Senior,
  A., Vanhoucke, V., Nguyen, P., Sainath, T.~N., et~al.
\newblock Deep neural networks for acoustic modeling in speech recognition: The
  shared views of four research groups.
\newblock \emph{IEEE Signal processing magazine}, 2012.

\bibitem[Huang et~al.(2019)Huang, Xiao, Xiong, Wu, Mu, and
  Song]{huang2019applications}
Huang, H., Xiao, B., Xiong, H., Wu, Z., Mu, Y., and Song, H.
\newblock Applications of deep learning to relativistic hydrodynamics.
\newblock \emph{Nuclear Physics A}, 2019.

\bibitem[Huang et~al.(2011)Huang, Joseph, Nelson, Rubinstein, and
  Tygar]{huang2011adversarial}
Huang, L., Joseph, A.~D., Nelson, B., Rubinstein, B.~I., and Tygar, J.~D.
\newblock Adversarial machine learning.
\newblock In \emph{Proceedings of the 4th ACM workshop on Security and
  artificial intelligence}, 2011.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2012imagenet}
Krizhevsky, A., Sutskever, I., and Hinton, G.~E.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In \emph{NeurIPS}, 2012.

\bibitem[Kurakin et~al.(2017)Kurakin, Goodfellow, Bengio,
  et~al.]{kurakin2016adversarial}
Kurakin, A., Goodfellow, I., Bengio, S., et~al.
\newblock Adversarial examples in the physical world.
\newblock In \emph{ICLR}, 2017.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and
  Haffner]{lecun1998gradient}
LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 1998.

\bibitem[LeCun et~al.(2015)LeCun, Bengio, and Hinton]{lecun2015deep}
LeCun, Y., Bengio, Y., and Hinton, G.
\newblock Deep learning.
\newblock \emph{Nature}, 2015.

\bibitem[Levine et~al.(2019)Levine, Sharir, Cohen, and
  Shashua]{levine2019quantum}
Levine, Y., Sharir, O., Cohen, N., and Shashua, A.
\newblock Quantum entanglement in deep learning architectures.
\newblock \emph{Physical review letters}, 2019.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{Madry18PGD}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{ICLR}, 2018.

\bibitem[Maxmen(2018{\natexlab{a}})]{maxmen2018deep}
Maxmen, A.
\newblock Deep learning sharpens views of cells and genes.
\newblock \emph{Nature}, 2018{\natexlab{a}}.

\bibitem[Maxmen(2018{\natexlab{b}})]{maxmen2018machine}
Maxmen, A.
\newblock Machine learning spots natural selection at work in human genome.
\newblock \emph{Nature}, 2018{\natexlab{b}}.

\bibitem[Mnih et~al.(2013)Mnih, Kavukcuoglu, Silver, Graves, Antonoglou,
  Wierstra, and Riedmiller]{mnih2013playing}
Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra,
  D., and Riedmiller, M.
\newblock Playing atari with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1312.5602}, 2013.

\bibitem[Nguyen et~al.(2015)Nguyen, Yosinski, and Clune]{nguyen2015deep}
Nguyen, A., Yosinski, J., and Clune, J.
\newblock Deep neural networks are easily fooled: High confidence predictions
  for unrecognizable images.
\newblock In \emph{CVPR}, 2015.

\bibitem[Rade \& Moosavi-Dezfooli(2021)Rade and
  Moosavi-Dezfooli]{rade2021helper}
Rade, R. and Moosavi-Dezfooli, S.-M.
\newblock Helper-based adversarial training: Reducing excessive margin to
  achieve a better accuracy vs. robustness trade-off.
\newblock In \emph{ICML 2021 Workshop on Adversarial Machine Learning}, 2021.

\bibitem[Rebuffi et~al.(2021)Rebuffi, Gowal, Calian, Stimberg, Wiles, and
  Mann]{rebuffi2021fixing}
Rebuffi, S.-A., Gowal, S., Calian, D.~A., Stimberg, F., Wiles, O., and Mann, T.
\newblock Fixing data augmentation to improve adversarial robustness.
\newblock \emph{arXiv preprint arXiv:2103.01946}, 2021.

\bibitem[Rice et~al.(2020)Rice, Wong, and Kolter]{rice2020overfitting}
Rice, L., Wong, E., and Kolter, Z.
\newblock Overfitting in adversarially robust deep learning.
\newblock In \emph{ICML}, 2020.

\bibitem[Sehwag et~al.(2021)Sehwag, Mahloujifar, Handina, Dai, Xiang, Chiang,
  and Mittal]{sehwag2021improving}
Sehwag, V., Mahloujifar, S., Handina, T., Dai, S., Xiang, C., Chiang, M., and
  Mittal, P.
\newblock Improving adversarial robustness using proxy distributions.
\newblock \emph{arXiv preprint arXiv:2104.09425}, 2021.

\bibitem[Silver et~al.(2016)Silver, Huang, Maddison, Guez, Sifre, Van
  Den~Driessche, Schrittwieser, Antonoglou, Panneershelvam, Lanctot,
  et~al.]{silver2016mastering}
Silver, D., Huang, A., Maddison, C.~J., Guez, A., Sifre, L., Van Den~Driessche,
  G., Schrittwieser, J., Antonoglou, I., Panneershelvam, V., Lanctot, M.,
  et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock \emph{Nature}, 2016.

\bibitem[Sridhar et~al.(2021)Sridhar, Sokolsky, Lee, and
  Weimer]{sridhar2021robust}
Sridhar, K., Sokolsky, O., Lee, I., and Weimer, J.
\newblock Robust learning via persistency of excitation.
\newblock \emph{arXiv preprint arXiv:2106.02078}, 2021.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock In \emph{ICLR}, 2014.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In \emph{NeurIPS}, 2017.

\bibitem[Wang et~al.(2019)Wang, Ma, Bailey, Yi, Zhou, and
  Gu]{wang2019convergence}
Wang, Y., Ma, X., Bailey, J., Yi, J., Zhou, B., and Gu, Q.
\newblock On the convergence and robustness of adversarial training.
\newblock In \emph{ICML}, 2019.

\bibitem[Wang et~al.(2020)Wang, Zou, Yi, Bailey, Ma, and Gu]{wang2019improving}
Wang, Y., Zou, D., Yi, J., Bailey, J., Ma, X., and Gu, Q.
\newblock Improving adversarial robustness requires revisiting misclassified
  examples.
\newblock In \emph{ICLR}, 2020.

\bibitem[Webb(2018)]{webb2018deep}
Webb, S.
\newblock Deep learning for biology.
\newblock \emph{Nature}, 2018.

\bibitem[Wong et~al.(2020)Wong, Rice, and Kolter]{wong2020fast}
Wong, E., Rice, L., and Kolter, J.~Z.
\newblock Fast is better than free: Revisiting adversarial training.
\newblock In \emph{ICLR}, 2020.

\bibitem[Wu et~al.(2020)Wu, Xia, and Wang]{wu2020adversarial}
Wu, D., Xia, S.-T., and Wang, Y.
\newblock Adversarial weight perturbation helps robust generalization.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and
  Komodakis]{zagoruyko2016wide}
Zagoruyko, S. and Komodakis, N.
\newblock Wide residual networks.
\newblock In \emph{BMVC}, 2016.

\bibitem[Zhang et~al.(2019)Zhang, Yu, Jiao, Xing, Ghaoui, and
  Jordan]{ZhangYJXGJ19TRADES}
Zhang, H., Yu, Y., Jiao, J., Xing, E.~P., Ghaoui, L.~E., and Jordan, M.~I.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In \emph{ICML}, 2019.

\bibitem[Zhang et~al.(2020{\natexlab{a}})Zhang, Xu, Han, Niu, Cui, Sugiyama,
  and Kankanhalli]{zhang2020attacks}
Zhang, J., Xu, X., Han, B., Niu, G., Cui, L., Sugiyama, M., and Kankanhalli, M.
\newblock Attacks which do not kill training make adversarial learning
  stronger.
\newblock In \emph{ICML}, 2020{\natexlab{a}}.

\bibitem[Zhang et~al.(2021{\natexlab{a}})Zhang, Zhu, Niu, Han, Sugiyama, and
  Kankanhalli]{zhang2020geometry}
Zhang, J., Zhu, J., Niu, G., Han, B., Sugiyama, M., and Kankanhalli, M.
\newblock Geometry-aware instance-reweighted adversarial training.
\newblock In \emph{ICLR}, 2021{\natexlab{a}}.

\bibitem[Zhang et~al.(2020{\natexlab{b}})Zhang, Li, Liu, and
  Tian]{zhang2020dual}
Zhang, Y., Li, Y., Liu, T., and Tian, X.
\newblock Dual-path distillation: A unified framework to improve black-box
  attacks.
\newblock In \emph{ICML}, 2020{\natexlab{b}}.

\bibitem[Zhang et~al.(2020{\natexlab{c}})Zhang, Tian, Li, Wang, and
  Tao]{zhang2020principal}
Zhang, Y., Tian, X., Li, Y., Wang, X., and Tao, D.
\newblock Principal component adversarial example.
\newblock \emph{IEEE Transactions on Image Processing}, 29:\penalty0
  4804--4815, 2020{\natexlab{c}}.

\bibitem[Zhang et~al.(2021{\natexlab{b}})Zhang, Gong, Liu, Niu, Tian, Han,
  Sch{\"o}lkopf, and Zhang]{zhang2021adversarial}
Zhang, Y., Gong, M., Liu, T., Niu, G., Tian, X., Han, B., Sch{\"o}lkopf, B.,
  and Zhang, K.
\newblock Adversarial robustness through the lens of causality.
\newblock \emph{arXiv preprint arXiv:2106.06196}, 2021{\natexlab{b}}.

\end{thebibliography}
