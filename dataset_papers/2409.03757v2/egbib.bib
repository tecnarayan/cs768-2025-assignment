@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})

@article{dinov2,
  title={{DINOv2: Learning robust visual features without supervision}},
  author={Maxime Oquab and Timothée Darcet and Théo Moutakanni and Huy Vo and Marc Szafraniec and Vasil Khalidov and Pierre Fernandez and Daniel Haziza and Francisco Massa and Alaaeldin El-Nouby and Mahmoud Assran and Nicolas Ballas and Wojciech Galuba and Russell Howes and Po-Yao Huang and Shang-Wen Li and Ishan Misra and Michael Rabbat and Vasu Sharma and Gabriel Synnaeve and Hu Xu and Hervé Jegou and Julien Mairal and Patrick Labatut and Armand Joulin and Piotr Bojanowski},
journal={Transactions on Machine Learning Research},
year={2024},
}

@inproceedings{segmentanything,
  title={{Segment Anything}},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{uni3d,
  title={{Uni3D: Exploring unified 3D representation at scale}},
  author={Zhou, Junsheng and Wang, Jinsheng and Ma, Baorui and Liu, Yu-Shen and Huang, Tiejun and Wang, Xinlong},
  booktitle={ICLR},
  year={2024}
}

@inproceedings{dino,
  title={{Emerging properties in self-supervised vision transformers}},
  author={Caron, Mathilde and Touvron, Hugo and Misra, Ishan and J{\'e}gou, Herv{\'e} and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{lseg,
  title={{Language-driven semantic segmentation}},
  author={Li, Boyi and Weinberger, Kilian Q and Belongie, Serge and Koltun, Vladlen and Ranftl, Ren{\'e}},
  booktitle={ICLR},
  year={2022}
}

@inproceedings{blip2,
  title={{BLIP-2: Bootstrapping language-image pre-training with frozen image encoders and large language models}},
  author={Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle={ICML},
  year={2023},
}

@inproceedings{blip,
  title={{BLIP: Bootstrapping language-image pre-training for unified vision-language understanding and generation}},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={ICML},
  year={2022},
}

@inproceedings{stablediffusion,
  title={{High-resolution image synthesis with latent diffusion models}},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={CVPR},
  year={2022}
}

@article{stablevideodiffusion,
  title={{Stable Video Diffusion: Scaling latent video diffusion models to large datasets}},
  author={Andreas Blattmann and Tim Dockhorn and Sumith Kulal and Daniel Mendelevitch and Maciej Kilian and Dominik Lorenz and Yam Levi and Zion English and Vikram Voleti and Adam Letts and Varun Jampani and Robin Rombach},
  journal={arXiv preprint arXiv:2311.15127},
  year={2023}
}

@article{vjepa,
    title={{V-JEPA: Latent video prediction for visual representation learning}},
  author={Bardes, Adrien and Garrido, Quentin and Ponce, Jean and Chen, Xinlei and Rabbat, Michael and LeCun, Yann and Assran, Mahmoud and Ballas, Nicolas},
  journal={arXiv preprint arXiv:2404.08471},
  year={2024}
}

@article{swin3d,
  title={{Swin3D: A pretrained transformer backbone for 3D indoor scene understanding}},
  author={Yang, Yu-Qi and Guo, Yu-Xiao and Xiong, Jian-Yu and Liu, Yang and Pan, Hao and Wang, Peng-Shuai and Tong, Xin and Guo, Baining},
  journal={arXiv preprint arXiv:2304.06906},
  year={2023}
}

@article{opt,
  title={{OPT: Open pre-trained transformer language models}},
  author={Susan Zhang and Stephen Roller and Naman Goyal and Mikel Artetxe and Moya Chen and Shuohui Chen and Christopher Dewan and Mona Diab and Xian Li and Xi Victoria Lin and Todor Mihaylov and Myle Ott and Sam Shleifer and Kurt Shuster and Daniel Simig and Punit Singh Koura and Anjali Sridhar and Tianlu Wang and Luke Zettlemoyer},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}

@inproceedings{gpt3,
  title={Language models are few-shot learners},
  author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  booktitle={NeurIPS},
  year={2020}
}

@article{googlet5,
  title={{Exploring the limits of transfer learning with a unified text-to-text transformer}},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={JMLR},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}


@inproceedings{llama,
  title={{LLaMA-Adapter: Efficient fine-tuning of language models with zero-init attention}},
  author={Zhang, Renrui and Han, Jiaming and Zhou, Aojun and Hu, Xiangfei and Yan, Shilin and Lu, Pan and Li, Hongsheng and Gao, Peng and Qiao, Yu},
  booktitle={ICLR},
  year={2024}
}

@inproceedings{clip,
  title={{Learning transferable visual models from natural language supervision}},
  author={Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
  booktitle={ICML},
  year={2021},
}

@inproceedings{joulin2016learning,
  title={Learning visual features from large weakly supervised data},
  author={Joulin, Armand and Van Der Maaten, Laurens and Jabri, Allan and Vasilache, Nicolas},
  booktitle={ECCV},
  year={2016},
}

@inproceedings{mahajan2018exploring,
  title={Exploring the limits of weakly supervised pretraining},
  author={Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and Van Der Maaten, Laurens},
  booktitle={ECCV},
  year={2018}
}

@inproceedings{vit,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
  booktitle={ICLR},
  year={2021}
}

@inproceedings{colorization,
  title={Colorful image colorization},
  author={Zhang, Richard and Isola, Phillip and Efros, Alexei A},
  booktitle={ECCV},
  year={2016},
}

@inproceedings{rotation,
  title={Unsupervised representation learning by predicting image rotations},
  author={Gidaris, Spyros and Singh, Praveer and Komodakis, Nikos},
  booktitle={ICLR},
  year={2018}
}

@inproceedings{inpainting,
  title={{Context encoders: Feature learning by inpainting}},
  author={Pathak, Deepak and Krahenbuhl, Philipp and Donahue, Jeff and Darrell, Trevor and Efros, Alexei A},
  booktitle={CVPR},
  year={2016}
}

@inproceedings{moco,
  title={Momentum contrast for unsupervised visual representation learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={CVPR},
  year={2020}
}

@inproceedings{simsiam,
  title={Exploring simple siamese representation learning},
  author={Chen, Xinlei and He, Kaiming},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{simclr,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={ICML},
  year={2020},
}

@inproceedings{byol,
  title={Bootstrap your own latent-a new approach to self-supervised learning},
  author={Jean-Bastien Grill and Florian Strub and Florent Altché and Corentin Tallec and Pierre H. Richemond and Elena Buchatskaya and Carl Doersch and Bernardo Avila Pires and Zhaohan Daniel Guo and Mohammad Gheshlaghi Azar and Bilal Piot and Koray Kavukcuoglu and Rémi Munos and Michal Valko},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{mae,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{beit,
  title={{BeiT: Bert pre-training of image transformers}},
  author={Bao, Hangbo and Dong, Li and Piao, Songhao and Wei, Furu},
  booktitle={ICLR},
  year={2022}
}

@inproceedings{ibot,
  title={{iBOT: Image bert pre-training with online tokenizer}},
  author={Zhou, Jinghao and Wei, Chen and Wang, Huiyu and Shen, Wei and Xie, Cihang and Yuille, Alan and Kong, Tao},
  booktitle={ICLR},
  year={2022}
}

@inproceedings{structured3d,
  title={{Structured3D: A large photo-realistic dataset for structured 3D modeling}},
  author={Zheng, Jia and Zhang, Junfei and Li, Jing and Tang, Rui and Gao, Shenghua and Zhou, Zihan},
  booktitle={ECCV},
  year={2020},
}

@inproceedings{ijepa,
  title={Self-supervised learning from images with a joint-embedding predictive architecture},
  author={Assran, Mahmoud and Duval, Quentin and Misra, Ishan and Bojanowski, Piotr and Vincent, Pascal and Rabbat, Michael and LeCun, Yann and Ballas, Nicolas},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{omnimae,
  title={{OmniMAE: Single model masked pretraining on images and videos}},
  author={Girdhar, Rohit and El-Nouby, Alaaeldin and Singh, Mannat and Alwala, Kalyan Vasudev and Joulin, Armand and Misra, Ishan},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{contrastivescenecontexts,
  title={{Exploring data-efficient 3D scene understanding with contrastive scene contexts}},
  author={Hou, Ji and Graham, Benjamin and Nie{\ss}ner, Matthias and Xie, Saining},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{pointcontrast,
  title={{PointContrast: Unsupervised pre-training for 3D point cloud understanding}},
  author={Xie, Saining and Gu, Jiatao and Guo, Demi and Qi, Charles R and Guibas, Leonidas and Litany, Or},
  booktitle={ECCV},
  year={2020},
}

@inproceedings{depthcontrast,
  title={{Self-supervised pretraining of 3D features on any point-cloud}},
  author={Zhang, Zaiwei and Girdhar, Rohit and Joulin, Armand and Misra, Ishan},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{maskpoint,
  title={Masked discrimination for self-supervised learning on point clouds},
  author={Liu, Haotian and Cai, Mu and Lee, Yong Jae},
  booktitle={ECCV},
  year={2022},
}

@inproceedings{pointmae,
  title={Masked autoencoders for point cloud self-supervised learning},
  author={Pang, Yatian and Wang, Wenxiao and Tay, Francis EH and Liu, Wei and Tian, Yonghong and Yuan, Li},
  booktitle={ECCV},
  year={2022},
}

@inproceedings{maskscene,
  title={{Masked scene contrast: A scalable framework for unsupervised 3D representation learning}},
  author={Wu, Xiaoyang and Wen, Xin and Liu, Xihui and Zhao, Hengshuang},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{pointmask,
  title={{3D feature prediction for masked-autoencoder-based point cloud pretraining}},
  author={Yan, Siming and Yang, Yuqi and Guo, Yuxiao and Pan, Hao and Wang, Peng-shuai and Tong, Xin and Liu, Yang and Huang, Qixing},
  booktitle={ICLR},
  year={2024}
}

@inproceedings{pointbert,
  title={{Point-BERT: Pre-training 3D point cloud transformers with masked point modeling}},
  author={Yu, Xumin and Tang, Lulu and Rao, Yongming and Huang, Tiejun and Zhou, Jie and Lu, Jiwen},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{pointm2ae,
  title={{Point-M2AE: multi-scale masked autoencoders for hierarchical point cloud pre-training}},
  author={Zhang, Renrui and Guo, Ziyu and Gao, Peng and Fang, Rongyao and Zhao, Bin and Wang, Dong and Qiao, Yu and Li, Hongsheng},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{videomae,
  title={{VideoMAE: Masked autoencoders are data-efficient learners for self-supervised video pre-training}},
  author={Tong, Zhan and Song, Yibing and Wang, Jue and Wang, Limin},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{videomaev2,
  title={{VideoMAEv2: Scaling video masked autoencoders with dual masking}},
  author={Wang, Limin and Huang, Bingkun and Zhao, Zhiyu and Tong, Zhan and He, Yinan and Wang, Yi and Wang, Yali and Qiao, Yu},
  booktitle={CVPR},
  year={2023}
}

@article{lecunpath,
  title={A path towards autonomous machine intelligence version 0.9. 2, 2022-06-27},
  author={LeCun, Yann},
  journal={Open Review},
  volume={62},
  number={1},
  year={2022}
}

@article{mcjepa,
  title={{MC-JEPA: A joint-embedding predictive architecture for self-supervised learning of motion and content features}},
  author={Bardes, Adrien and Ponce, Jean and LeCun, Yann},
  journal={arXiv preprint arXiv:2307.12698},
  year={2023}
}

@inproceedings{videoclip,
  title={{VideoCLIP: Contrastive pre-training for zero-shot video-text understanding}},
  author={Xu, Hu and Ghosh, Gargi and Huang, Po-Yao and Okhonko, Dmytro and Aghajanyan, Armen and Metze, Florian and Zettlemoyer, Luke and Feichtenhofer, Christoph},
  booktitle={EMNLP},
  year={2021}
}

@inproceedings{merlot,
  title={{Merlot reserve: Neural script knowledge through vision and language and sound}},
  author={Zellers, Rowan and Lu, Jiasen and Lu, Ximing and Yu, Youngjae and Zhao, Yanpeng and Salehi, Mohammadreza and Kusupati, Aditya and Hessel, Jack and Farhadi, Ali and Choi, Yejin},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{vatt,
  title={{VATT: Transformers for multimodal self-supervised learning from raw video, audio and text}},
  author={Akbari, Hassan and Yuan, Liangzhe and Qian, Rui and Chuang, Wei-Hong and Chang, Shih-Fu and Cui, Yin and Gong, Boqing},
  booktitle={NeurIPS},
  year={2021}
}

@article{internvideo,
  title={{InternVideo: General video foundation models via generative and discriminative learning}},
  author={Yi Wang and Kunchang Li and Yizhuo Li and Yinan He and Bingkun Huang and Zhiyu Zhao and Hongjie Zhang and Jilan Xu and Yi Liu and Zun Wang and Sen Xing and Guo Chen and Junting Pan and Jiashuo Yu and Yali Wang and Limin Wang and Yu Qiao},
  journal={arXiv preprint arXiv:2212.03191},
  year={2022}
}

@inproceedings{diffusion2015,
  title={Deep unsupervised learning using nonequilibrium thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={ICML},
  year={2015},
}

@inproceedings{diffusion2020,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{liu2024openshape,
  title={{OpenShape: Scaling up 3D shape representation towards open-world understanding}},
  author={Liu, Minghua and Shi, Ruoxi and Kuang, Kaiming and Zhu, Yinhao and Li, Xuanlin and Han, Shizhong and Cai, Hong and Porikli, Fatih and Su, Hao},
  booktitle={NeurIPS},
  year={2024}
}

@inproceedings{labelefficientdiffusion,
  title={Label-efficient semantic segmentation with diffusion models},
  author={Baranchuk, Dmitry and Rubachev, Ivan and Voynov, Andrey and Khrulkov, Valentin and Babenko, Artem},
  booktitle={ICLR},
  year={2022}
}

@inproceedings{deitke2023objaverse,
  title={{Objaverse: A universe of annotated 3D objects}},
  author={Deitke, Matt and Schwenk, Dustin and Salvador, Jordi and Weihs, Luca and Michel, Oscar and VanderBilt, Eli and Schmidt, Ludwig and Ehsani, Kiana and Kembhavi, Aniruddha and Farhadi, Ali},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{odise,
  title={Open-vocabulary panoptic segmentation with text-to-image diffusion models},
  author={Xu, Jiarui and Liu, Sifei and Vahdat, Arash and Byeon, Wonmin and Wang, Xiaolong and De Mello, Shalini},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{emerdiff,
  title={{EmerDiff: Emerging pixel-level semantic knowledge in diffusion models}},
  author={Namekata, Koichi and Sabour, Amirmojtaba and Fidler, Sanja and Kim, Seung Wook},
  booktitle={ICLR},
  year={2024}
}

@inproceedings{diffumask,
  title={{DiffuMNask: Synthesizing images with pixel-level annotations for semantic segmentation using diffusion models}},
  author={Wu, Weijia and Zhao, Yuzhong and Shou, Mike Zheng and Zhou, Hong and Shen, Chunhua},
  booktitle={ICCV},
  year={2023}
}

@article{diffusionseg,
  title={{DiffusionSeg: Adapting diffusion towards unsupervised object discovery}},
  author={Ma, Chaofan and Yang, Yuhuan and Ju, Chen and Zhang, Fei and Liu, Jinxiang and Wang, Yu and Zhang, Ya and Wang, Yanfeng},
  journal={arXiv preprint arXiv:2303.09813},
  year={2023}
}

@inproceedings{ataleoftwofeatures,
  title={A tale of two features: Stable diffusion complements dino for zero-shot semantic correspondence},
  author={Zhang, Junyi and Herrmann, Charles and Hur, Junhwa and Polania Cabrera, Luisa and Jampani, Varun and Sun, Deqing and Yang, Ming-Hsuan},
  booktitle={NeurIPS},
  year={2023}
}

@inproceedings{probing3d,
  title={{Probing the 3D awareness of visual foundation models}},
  author={Banani, Mohamed El and Raj, Amit and Maninis, Kevis-Kokitsi and Kar, Abhishek and Li, Yuanzhen and Rubinstein, Michael and Sun, Deqing and Guibas, Leonidas and Johnson, Justin and Jampani, Varun},
  booktitle={CVPR},
  year={2024}
}

@inproceedings{unleashingdiffusiondepth,
  title={Unleashing text-to-image diffusion models for visual perception},
  author={Zhao, Wenliang and Rao, Yongming and Liu, Zuyan and Liu, Benlin and Zhou, Jie and Lu, Jiwen},
  booktitle={ICCV},
  year={2023}
}

@article{whatdoesdiffusionknow,
  title={What does stable diffusion know about the 3D scene?},
  author={Zhan, Guanqi and Zheng, Chuanxia and Xie, Weidi and Zisserman, Andrew},
  journal={arXiv preprint arXiv:2310.06836},
  year={2023}
}

@inproceedings{segpointfoundation,
  title={Segment any point cloud sequences by distilling vision foundation models},
  author={Liu, Youquan and Kong, Lingdong and Cen, Jun and Chen, Runnan and Zhang, Wenwei and Pan, Liang and Chen, Kai and Liu, Ziwei},
  booktitle={NeurIPS},
  year={2024}
}

@inproceedings{sqa3d,
  title={{SQA3D: Situated question answering in 3D scenes}},
  author={Ma, Xiaojian and Yong, Silong and Zheng, Zilong and Li, Qing and Liang, Yitao and Zhu, Song-Chun and Huang, Siyuan},
  booktitle={ICLR},
  year={2023}
}

@inproceedings{scanqa,
  title={{ScanQA: 3D question answering for spatial scene understanding}},
  author={Azuma, Daichi and Miyanishi, Taiki and Kurita, Shuhei and Kawanabe, Motoaki},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{sig3d,
  title={Situational awareness matters in {3D} vision language reasoning},
  author={Man, Yunze and Gui, Liang-Yan and Wang, Yu-Xiong},
  booktitle={CVPR},
  year={2024}
}

@inproceedings{3dllm,
  title={{3D-LLM: Injecting the 3D world into large language models}},
  author={Hong, Yining and Zhen, Haoyu and Chen, Peihao and Zheng, Shuhong and Du, Yilun and Chen, Zhenfang and Gan, Chuang},
  booktitle={NeurIPS},
  year={2023}
}

@inproceedings{openscene,
  title={{OpenScene: 3D scene understanding with open vocabularies}},
  author={Songyou Peng and Kyle Genova and Chiyu "Max" Jiang and Andrea Tagliasacchi and Marc Pollefeys and Thomas Funkhouser},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{bevguide,
author = {Man, Yunze and Gui, Liang-Yan and Wang, Yu-Xiong},
booktitle={CVPR},
title = {{BEV-guided} multi-modality fusion for driving perception},
year = {2023}
}

@inproceedings{pla3d,
  title={{PLA: Language-driven open-Vocabulary 3D scene understanding}},
  author={Ding, Runyu and Yang, Jihan and Xue, Chuhui and Zhang, Wenqing and Bai, Song and Qi, Xiaojuan},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{lerf,
  title={{LERF: Language embedded radiance fields}},
  author={Kerr, Justin and Kim, Chung Min and Goldberg, Ken and Kanazawa, Angjoo and Tancik, Matthew},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{3dconcept,
  title={{3D concept learning and reasoning from multi-view images}},
  author={Hong, Yining and Lin, Chunru and Du, Yilun and Chen, Zhenfang and Tenenbaum, Joshua B and Gan, Chuang},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{3dvista,
  title={{3D-VisTA: Pre-trained transformer for 3D vision and text alignment}},
  author={Zhu, Ziyu and Ma, Xiaojian and Chen, Yixin and Deng, Zhidong and Huang, Siyuan and Li, Qing},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{frozenlm4vision,
  title={Frozen transformers in language models are effective visual encoder layers},
  author={Pang, Ziqi and Xie, Ziyang and Man, Yunze and Wang, Yu-Xiong},
  booktitle={ICLR},
  year={2024}
}

@article{diffusiondepth,
  title={{DiffusionDepth}: Diffusion denoising approach for monocular depth estimation},
  author={Duan, Yiqun and Guo, Xianda and Zhu, Zheng},
  journal={arXiv preprint arXiv:2303.05021},
  year={2023}
}

@article{monoculardepthdiffusion,
  title={Monocular depth estimation using diffusion models},
  author={Saxena, Saurabh and Kar, Abhishek and Norouzi, Mohammad and Fleet, David J},
  journal={arXiv preprint arXiv:2302.14816},
  year={2023}
}

@inproceedings{diffusiondet,
  title={{DiffusionDet}: Diffusion model for object detection},
  author={Chen, Shoufa and Sun, Peize and Song, Yibing and Luo, Ping},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{amradio,
  title={{AM-RADIO: Agglomerative model--reduce all domains into one}},
  author={Ranzinger, Mike and Heinrich, Greg and Kautz, Jan and Molchanov, Pavlo},
  booktitle={CVPR},
  year={2024}
}

@inproceedings{scannet,
    title={{ScanNet: Richly-annotated 3D reconstructions of indoor scenes}},
    author={Dai, Angela and Chang, Angel X. and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\ss}ner, Matthias},
    booktitle = {CVPR},
    year = {2017}
}

@inproceedings{scanrefer,
  title={{ScanRefer: 3D object localization in {RGB-D} scans using natural language}},
  author={Chen, Dave Zhenyu and Chang, Angel X and Nie{\ss}ner, Matthias},
  booktitle={ECCV},
  year={2020},
}


@inproceedings{controlroom3d,
  title={{ControlRoom3D: Room generation using semantic proxy rooms}},
  author={Jonas Schult and Sam Tsai and Lukas Höllein and Bichen Wu and Jialiang Wang and Chih-Yao Ma and Kunpeng Li and Xiaofang Wang and Felix Wimbauer and Zijian He and Peizhao Zhang and Bastian Leibe and Peter Vajda and Ji Hou},
  booktitle={CVPR},
  year={2024}
}

@inproceedings{scenecraft,
  title={{SceneCraft}: Layout-Guided {3D} Scene Generation},
  author={Yang, Xiuyu and Man, Yunze and Chen, Jun-Kun and Wang, Yu-Xiong},
  booktitle={NeurIPS},
  year={2024}
}


@inproceedings{multiply,
  title={{MultiPLY: A multisensory object-centric embodied large language model in 3D world}},
  author={Hong, Yining and Zheng, Zishuo and Chen, Peihao and Wang, Yian and Li, Junyan and Gan, Chuang},
  booktitle={CVPR},
  year={2024}
}

@inproceedings{3dvla,
  title={{3D-VLA: A 3D vision-language-action generative world model}},
  author={Zhen, Haoyu and Qiu, Xiaowen and Chen, Peihao and Yang, Jincheng and Yan, Xin and Du, Yilun and Hong, Yining and Gan, Chuang},
  booktitle={ICML},
  year={2024}
}

@inproceedings{adam,
      title={{Adam: A method for stochastic optimization}}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2015},
      booktitle={ICLR},
}

@inproceedings{regtr,
      title={{REGTR: End-to-end point cloud correspondences with transformers}}, 
      author={Zi Jian Yew and Gim Hee Lee},
      year={2022},
      booktitle={CVPR},
}

@InProceedings{regformer,
    author    = {Liu, Jiuming and Wang, Guangming and Liu, Zhe and Jiang, Chaokang and Pollefeys, Marc and Wang, Hesheng},
    title     = {{RegFormer}: An Efficient Projection-Aware Transformer Network for Large-Scale Point Cloud Registration},
    booktitle = {ICCV},
    year      = {2023},
}

@inproceedings{scannet++,
  title={{ScanNet++: A high-fidelity dataset of 3D indoor scenes}},
  author={Yeshwanth, Chandan and Liu, Yueh-Cheng and Nie{\ss}ner, Matthias and Dai, Angela},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{matterport3d,
  title={{Matterport3D: Learning from {RGB-D} data in indoor environments}},
  author={Chang, Angel and Dai, Angela and Funkhouser, Thomas and Halber, Maciej and Niessner, Matthias and Savva, Manolis and Song, Shuran and Zeng, Andy and Zhang, Yinda},
  booktitle={3DV},
  year={2017}
}

@inproceedings{colmap,
  title={Structure-from-motion revisited},
  author={Schonberger, Johannes L and Frahm, Jan-Michael},
  booktitle={CVPR},
  year={2016}
}

@inproceedings{hypersim,
  title={{HyperSim: A photorealistic synthetic dataset for holistic indoor scene understanding}},
  author={Roberts, Mike and Ramapuram, Jason and Ranjan, Anurag and Kumar, Atulit and Bautista, Miguel Angel and Paczan, Nathan and Webb, Russ and Susskind, Joshua M},
  booktitle={ICCV},
  year={2021}
}

@article{adamw,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@inproceedings{bleu,
  title={{BLEU: a method for automatic evaluation of machine translation}},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={ACL},
  year={2002}
}

@inproceedings{rouge,
  title={{ROUGE: A package for automatic evaluation of summaries}},
  author={Lin, Chin-Yew},
  booktitle={ACL},
  year={2004}
}

@inproceedings{meteor,
  title={{METEOR: An automatic metric for MT evaluation with improved correlation with human judgments}},
  author={Banerjee, Satanjeev and Lavie, Alon},
  booktitle={ACL Workshop},
  year={2005}
}

@inproceedings{cider,
  title={{CIDER: Consensus-based image description evaluation}},
  author={Vedantam, Ramakrishna and Lawrence Zitnick, C and Parikh, Devi},
  booktitle={CVPR},
  year={2015}
}

@inproceedings{multi3drefer,
  title={{Multi3DRefer: Grounding text description to multiple 3D objects}},
  author={Zhang, Yiming and Gong, ZeMing and Chang, Angel X},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{referit3d,
  title={{ReferIt3D: Neural listeners for fine-grained 3D object identification in real-world scenes}},
  author={Achlioptas, Panos and Abdelreheem, Ahmed and Xia, Fei and Elhoseiny, Mohamed and Guibas, Leonidas},
  booktitle={ECCV},
  year={2020},
}

@article{Kabsch,
  title={A solution for the best rotation to relate two sets of vectors},
  author={Wolfgang Kabsch},
  journal={Acta Crystallographica Section A: Crystal Physics, Diffraction, Theoretical and General Crystallography},
  volume={32},
  number={5},
  pages={922--923},
  year={1976},
  publisher={International Union of Crystallography}
}


@article{Umeyama,
  title={Least-squares estimation of transformation parameters between two point patterns},
  author={Shinji Umeyama},
  journal={TPAMI},
  volume={13},
  number={04},
  pages={376--380},
  year={1991},
  publisher={IEEE Computer Society}
}


@inproceedings{tang2023emergent,
  title={Emergent correspondence from image diffusion},
  author={Tang, Luming and Jia, Menglin and Wang, Qianqian and Phoo, Cheng Perng and Hariharan, Bharath},
  booktitle={NeurIPS},
  year={2023}
}

@inproceedings{schuhmann2022laion,
  title={{Laion-5B: An open large-scale dataset for training next generation image-text models}},
  author={Christoph Schuhmann and Romain Beaumont and Richard Vencu and Cade Gordon and Ross Wightman and Mehdi Cherti and Theo Coombes and Aarush Katta and Clayton Mullis and Mitchell Wortsman and Patrick Schramowski and Srivatsa Kundurthy and Katherine Crowson and Ludwig Schmidt and Robert Kaczmarczyk and Jenia Jitsev},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{growsp,
      title={{GrowSP}: Unsupervised Semantic Segmentation of {3D} Point Clouds}, 
      author={Zihui Zhang and Bo Yang and Bing Wang and Bo Li},
      booktitle={CVPR},
      year={2023}
}

@inproceedings{zhou2017scene,
  title={{Scene parsing through ADE20k dataset}},
  author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
  booktitle={CVPR},
  year={2017}
}

@inproceedings{text2room,
  title={{Text2Room: Extracting textured 3D meshes from 2D text-to-image models}},
  author={H{\"o}llein, Lukas and Cao, Ang and Owens, Andrew and Johnson, Justin and Nie{\ss}ner, Matthias},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{scenescape,
  title={{SceneScape: Text-driven consistent scene generation}},
  author={Fridman, Rafail and Abecasis, Amit and Kasten, Yoni and Dekel, Tali},
  booktitle={NeurIPS},
  year={2023}
}

@article{ctrlroom,
  title={{Ctrl-Room: Controllable text-to-3D room meshes generation with layout constraints}},
  author={Fang, Chuan and Hu, Xiaotao and Luo, Kunming and Tan, Ping},
  journal={arXiv preprint arXiv:2310.03602},
  year={2023}
}

@inproceedings{graphdreamer,
  title={{GraphDreamer: Compositional 3D scene synthesis from scene graphs}},
  author={Gao, Gege and Liu, Weiyang and Chen, Anpei and Geiger, Andreas and Sch{\"o}lkopf, Bernhard},
  booktitle={CVPR},
  year={2024}
}

@inproceedings{glamm,
  title={{GLaMM}: Pixel grounding large multimodal model},
  author={Rasheed, Hanoona and Maaz, Muhammad and Shaji, Sahal and Shaker, Abdelrahman and Khan, Salman and Cholakkal, Hisham and Anwer, Rao M. and Xing, Eric and Yang, Ming-Hsuan and Khan, Fahad S.},
  booktitle={CVPR},
  year={2024}
}

@inproceedings{kosmos2,
  title={{Kosmos-2: Grounding multimodal large language models to the world}},
  author={Peng, Zhiliang and Wang, Wenhui and Dong, Li and Hao, Yaru and Huang, Shaohan and Ma, Shuming and Ye, Qixiang and Wei, Furu},
  booktitle={ICLR},
  year={2024}
}

@inproceedings{visionllm,
  title={{VisionLLM: Large language model is also an open-ended decoder for vision-centric tasks}},
  author={Wang, Wenhai and Chen, Zhe and Chen, Xiaokang and Wu, Jiannan and Zhu, Xizhou and Zeng, Gang and Luo, Ping and Lu, Tong and Zhou, Jie and Qiao, Yu and Dai, Jifeng},
  booktitle={NeurIPS},
  year={2023}
}

@inproceedings{pixelllm,
  title={Pixel aligned language models},
  author={Xu, Jiarui and Zhou, Xingyi and Yan, Shen and Gu, Xiuye and Arnab, Anurag and Sun, Chen and Wang, Xiaolong and Schmid, Cordelia},
  booktitle={CVPR},
  year={2024}
}

@article{lisa,
  title={{LISA: Reasoning segmentation via large language model}},
  author={Lai, Xin and Tian, Zhuotao and Chen, Yukang and Li, Yanwei and Yuan, Yuhui and Liu, Shu and Jia, Jiaya},
  journal={arXiv preprint arXiv:2308.00692},
  year={2023}
}

@article{drivelm,
  title={{DriveLM: Driving with graph visual question answering}},
  author={Sima, Chonghao and Renz, Katrin and Chitta, Kashyap and Chen, Li and Zhang, Hanxue and Xie, Chengen and Luo, Ping and Geiger, Andreas and Li, Hongyang},
  journal={arXiv preprint arXiv:2312.14150},
  year={2023}
}

@article{drivevlm,
  title={{DriveVLM}: {The} Convergence of Autonomous Driving and Large Vision-Language Models},
  author={Tian, Xiaoyu and Gu, Junru and Li, Bailin and Liu, Yicheng and Hu, Chenxu and Wang, Yang and Zhan, Kun and Jia, Peng and Lang, Xianpeng and Zhao, Hang},
  journal={arXiv preprint arXiv:2402.12289},
  year={2024}
}

@article{embodieddrive,
  title={Embodied Understanding of Driving Scenarios},
  author={Zhou, Yunsong and Huang, Linyan and Bu, Qingwen and Zeng, Jia and Li, Tianyu and Qiu, Hang and Zhu, Hongzi and Guo, Minyi and Qiao, Yu and Li, Hongyang},
  journal={arXiv preprint arXiv:2403.04593},
  year={2024}
}

@article{pivot,
  title={{PIVOT: Iterative visual prompting elicits actionable knowledge for VLMs}},
  author={Soroush Nasiriany and Fei Xia and Wenhao Yu and Ted Xiao and Jacky Liang and Ishita Dasgupta and Annie Xie and Danny Driess and Ayzaan Wahid and Zhuo Xu and Quan Vuong and Tingnan Zhang and Tsang-Wei Edward Lee and Kuang-Huei Lee and Peng Xu and Sean Kirmani and Yuke Zhu and Andy Zeng and Karol Hausman and Nicolas Heess and Chelsea Finn and Sergey Levine and Brian Ichter},
  journal={arXiv preprint arXiv:2402.07872},
  year={2024}
}

@article{gemini,
  title={{Gemini: A family of highly capable multimodal models}},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{gpt4,
  title={{GPT-4 technical report}},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@inproceedings{zheng2020structured3d,
  title={{Structured3D: A large photo-realistic dataset for structured 3D modeling}},
  author={Zheng, Jia and Zhang, Junfei and Li, Jing and Tang, Rui and Gao, Shenghua and Zhou, Zihan},
  booktitle={ECCV},
  year={2020},
}