\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{CTW{\etalchar{+}}21}

\bibitem[AFKT21]{AsiFeKoTa21}
Hilal Asi, Vitaly Feldman, Tomer Koren, and Kunal Talwar.
\newblock Private stochastic convex optimization: Optimal rates in {$\ell_1$} geometry.
\newblock In {\em ICML}, 2021.

\bibitem[AL24]{asi2023user}
Hilal Asi and Daogao Liu.
\newblock User-level differentially private stochastic convex optimization: Efficient algorithms with optimal rates.
\newblock In {\em International Conference on Artificial Intelligence and Statistics}, pages 4240--4248. PMLR, 2024.

\bibitem[ALT24]{asi2024private}
Hilal Asi, Daogao Liu, and Kevin Tian.
\newblock Private stochastic convex optimization with heavy tails: Near-optimality from simple reductions.
\newblock {\em arXiv preprint arXiv:2406.02789}, 2024.

\bibitem[BBG18]{balle18}
Borja Balle, Gilles Barthe, and Marco Gaboardi.
\newblock Privacy amplification by subsampling: Tight analyses via couplings and divergences.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi, and R.~Garnett, editors, {\em Advances in Neural Information Processing Systems}, volume~31. Curran Associates, Inc., 2018.

\bibitem[BFTT19]{bft19}
Raef Bassily, Vitaly Feldman, Kunal Talwar, and Abhradeep Thakurta.
\newblock Private stochastic convex optimization with optimal rates.
\newblock In {\em Advances in Neural Information Processing Systems}, volume~32, 2019.

\bibitem[BS23]{bassily2023user}
Raef Bassily and Ziteng Sun.
\newblock User-level private stochastic convex optimization with optimal rates.
\newblock In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, {\em Proceedings of the 40th International Conference on Machine Learning}, volume 202 of {\em Proceedings of Machine Learning Research}, pages 1838--1851. PMLR, 23--29 Jul 2023.

\bibitem[CTW{\etalchar{+}}21]{carlini2021extracting}
Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom~B Brown, Dawn Song, Ulfar Erlingsson, et~al.
\newblock Extracting training data from large language models.
\newblock In {\em USENIX Security Symposium}, volume~6, pages 2633--2650, 2021.

\bibitem[DBW12]{dbw12}
John~C Duchi, Peter~L Bartlett, and Martin~J Wainwright.
\newblock Randomized smoothing for stochastic optimization.
\newblock {\em SIAM Journal on Optimization}, 22(2):674--701, 2012.

\bibitem[DMNS06]{dwork2006calibrating}
Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith.
\newblock Calibrating noise to sensitivity in private data analysis.
\newblock In {\em Theory of cryptography conference}, pages 265--284. Springer, 2006.

\bibitem[DR14]{dwork2014}
Cynthia Dwork and Aaron Roth.
\newblock {\em The Algorithmic Foundations of Differential Privacy}, volume~9.
\newblock Now Publishers, Inc., 2014.

\bibitem[FKT20]{fkt20}
Vitaly Feldman, Tomer Koren, and Kunal Talwar.
\newblock Private stochastic convex optimization: optimal rates in linear time.
\newblock In {\em Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing}, pages 439--449, 2020.

\bibitem[GKK{\etalchar{+}}23]{ghazi2023user}
Badih Ghazi, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Raghu Meka, and Chiyuan Zhang.
\newblock On user-level private convex optimization.
\newblock In {\em International Conference on Machine Learning}, pages 11283--11299. PMLR, 2023.

\bibitem[GL12]{ghadimilan1}
Saeed Ghadimi and Guanghui Lan.
\newblock Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization i: A generic algorithmic framework.
\newblock {\em SIAM Journal on Optimization}, 22(4):1469--1492, 2012.

\bibitem[GL13]{ghadimilan2}
Saeed Ghadimi and Guanghui Lan.
\newblock Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization, ii: Shrinking procedures and optimal algorithms.
\newblock {\em SIAM Journal on Optimization}, 23(4):2061--2089, 2013.

\bibitem[GLZW24]{gao2024private}
Changyu Gao, Andrew Lowy, Xingyu Zhou, and Stephen~J Wright.
\newblock Private heterogeneous federated learning without a trusted server revisited: Error-optimal and communication-efficient algorithms for convex losses.
\newblock {\em arXiv preprint arXiv:2407.09690}, 2024.

\bibitem[HRS16]{hardt16}
Moritz Hardt, Ben Recht, and Yoram Singer.
\newblock Train faster, generalize better: Stability of stochastic gradient descent.
\newblock In Maria~Florina Balcan and Kilian~Q. Weinberger, editors, {\em Proceedings of The 33rd International Conference on Machine Learning}, volume~48 of {\em Proceedings of Machine Learning Research}, pages 1225--1234, New York, New York, USA, 20--22 Jun 2016. PMLR.

\bibitem[JNG{\etalchar{+}}19]{jin2019short}
Chi Jin, Praneeth Netrapalli, Rong Ge, Sham~M Kakade, and Michael~I Jordan.
\newblock A short note on concentration inequalities for random vectors with subgaussian norm.
\newblock {\em arXiv preprint arXiv:1902.03736}, 2019.

\bibitem[KLL21]{kll21}
Janardhan Kulkarni, Yin~Tat Lee, and Daogao Liu.
\newblock Private non-smooth erm and sco in subquadratic steps.
\newblock {\em Advances in Neural Information Processing Systems}, 34:4053--4064, 2021.

\bibitem[KOV15]{kairouz15}
Peter Kairouz, Sewoong Oh, and Pramod Viswanath.
\newblock The composition theorem for differential privacy, 2015.

\bibitem[LJCJ17]{lei17}
Lihua Lei, Cheng Ju, Jianbo Chen, and Michael~I Jordan.
\newblock Non-convex finite-sum optimization via scsg methods.
\newblock In {\em Proceedings of the 31st International Conference on Neural Information Processing Systems}, pages 2345--2355, 2017.

\bibitem[LLL{\etalchar{+}}24a]{li2024analyzing}
Zhuohang Li, Andrew Lowy, Jing Liu, Toshiaki Koike-Akino, Kieran Parsons, Bradley Malin, and Ye~Wang.
\newblock Analyzing inference privacy risks through gradients in machine learning.
\newblock {\em arXiv preprint arXiv:2408.16913}, 2024.

\bibitem[LLL{\etalchar{+}}24b]{lowy2024does}
Andrew Lowy, Zhuohang Li, Jing Liu, Toshiaki Koike-Akino, Kieran Parsons, and Ye~Wang.
\newblock Why does differential privacy with large epsilon defend against practical membership inference attacks?
\newblock {\em arXiv preprint arXiv:2402.09540}, 2024.

\bibitem[LR22]{lowy2023largelip}
Andrew Lowy and Meisam Razaviyayn.
\newblock Private stochastic optimization with large worst-case lipschitz parameter, 2022.

\bibitem[LSA{\etalchar{+}}21]{levy2021learning}
Daniel Levy, Ziteng Sun, Kareem Amin, Satyen Kale, Alex Kulesza, Mehryar Mohri, and Ananda~Theertha Suresh.
\newblock Learning with user-level privacy.
\newblock {\em Advances in Neural Information Processing Systems}, 34:12466--12479, 2021.

\bibitem[LUW24]{lowymake}
Andrew Lowy, Jonathan Ullman, and Stephen Wright.
\newblock How to make the gradients small privately: Improved rates for differentially private non-convex optimization.
\newblock In {\em Forty-first International Conference on Machine Learning}, 2024.

\bibitem[McS09]{mcsherry2009privacy}
Frank~D McSherry.
\newblock Privacy integrated queries: an extensible platform for privacy-preserving data analysis.
\newblock In {\em Proceedings of the 2009 ACM SIGMOD International Conference on Management of data}, pages 19--30, 2009.

\bibitem[MRTZ18]{mcmahan17}
Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li~Zhang.
\newblock Learning differentially private recurrent language models.
\newblock In {\em International Conference on Learning Representations (ICLR)}, 2018.

\bibitem[SSSS17]{shokri2017membership}
Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov.
\newblock Membership inference attacks against machine learning models.
\newblock In {\em 2017 IEEE symposium on security and privacy (SP)}, pages 3--18. IEEE, 2017.

\bibitem[SSSSS09]{shalev2009stochastic}
Shai Shalev-Shwartz, Ohad Shamir, Nathan Srebro, and Karthik Sridharan.
\newblock Stochastic convex optimization.
\newblock In {\em COLT}, volume~2, page~5, 2009.

\bibitem[TCK{\etalchar{+}}22]{tsfadia2022friendlycore}
Eliad Tsfadia, Edith Cohen, Haim Kaplan, Yishay Mansour, and Uri Stemmer.
\newblock Friendlycore: Practical differentially private aggregation.
\newblock In {\em International Conference on Machine Learning}, pages 21828--21863. PMLR, 2022.

\bibitem[Ull17]{ullman2017}
Jonathan Ullman.
\newblock {CS7880:} rigorous approaches to data privacy, 2017.

\bibitem[XZ24]{Xu2024}
Zheng Xu and Yanxiang Zhang.
\newblock Advances in private training for production on-device language models.
\newblock \url{https://research.google/blog/advances-in-private-training-for-production-on-device-language-models/}, 2024.
\newblock Google Research Blog.

\bibitem[YNS12]{yns11}
Farzad Yousefian, Angelia Nedi{\'c}, and Uday~V Shanbhag.
\newblock On stochastic gradient and subgradient methods with adaptive steplength sequences.
\newblock {\em Automatica}, 48(1):56--67, 2012.

\bibitem[ZTOH22]{zhang2022bring}
Liang Zhang, Kiran~K Thekumparampil, Sewoong Oh, and Niao He.
\newblock Bring your own algorithm for optimal differentially private stochastic minimax optimization.
\newblock {\em Advances in Neural Information Processing Systems}, 35:35174--35187, 2022.

\end{thebibliography}
