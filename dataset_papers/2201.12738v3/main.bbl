\begin{thebibliography}{64}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amir et~al.(2017)Amir, Taba, Berg, Melano, McKinstry, Di~Nolfo, Nayak,
  Andreopoulos, Garreau, Mendoza, et~al.]{amir2017dvs128gesture}
Amir, A., Taba, B., Berg, D., Melano, T., McKinstry, J., Di~Nolfo, C., Nayak,
  T., Andreopoulos, A., Garreau, G., Mendoza, M., et~al.
\newblock A low power, fully event-based gesture recognition system.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2017.

\bibitem[Bender et~al.(2018)Bender, Kindermans, Zoph, Vasudevan, and
  Le]{bender2018understanding}
Bender, G., Kindermans, P.-J., Zoph, B., Vasudevan, V., and Le, Q.
\newblock Understanding and simplifying one-shot architecture search.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning}, 2018.

\bibitem[Bohte et~al.(2002)Bohte, Kok, and La~Poutre]{bohte2002error}
Bohte, S.~M., Kok, J.~N., and La~Poutre, H.
\newblock Error-backpropagation in temporally encoded networks of spiking
  neurons.
\newblock \emph{Neurocomputing}, 48\penalty0 (1-4):\penalty0 17--37, 2002.

\bibitem[Cai et~al.(2019)Cai, Zhu, and Han]{cai2019proxylessnas}
Cai, H., Zhu, L., and Han, S.
\newblock Proxylessnas: Direct neural architecture search on target task and
  hardware.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Cai et~al.(2020)Cai, Gan, Wang, Zhang, and Han]{cai2020ofanet}
Cai, H., Gan, C., Wang, T., Zhang, Z., and Han, S.
\newblock Once for all: Train one network and specialize it for efficient
  deployment.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Chen et~al.(2019)Chen, Yang, Zhang, Meng, Xiao, and
  Sun]{chen2019detnas}
Chen, Y., Yang, T., Zhang, X., Meng, G., Xiao, X., and Sun, J.
\newblock Detnas: Backbone search for object detection.
\newblock \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Davies et~al.(2018)Davies, Srinivasa, Lin, Chinya, Cao, Choday, Dimou,
  Joshi, Imam, Jain, et~al.]{davies2018loihi}
Davies, M., Srinivasa, N., Lin, T.-H., Chinya, G., Cao, Y., Choday, S.~H.,
  Dimou, G., Joshi, P., Imam, N., Jain, S., et~al.
\newblock Loihi: A neuromorphic manycore processor with on-chip learning.
\newblock \emph{IEEE Micro}, 38\penalty0 (1):\penalty0 82--99, 2018.

\bibitem[Davies et~al.(2021)Davies, Wild, Orchard, Sandamirskaya, Guerra,
  Joshi, Plank, and Risbud]{davies2021advancing}
Davies, M., Wild, A., Orchard, G., Sandamirskaya, Y., Guerra, G. A.~F., Joshi,
  P., Plank, P., and Risbud, S.~R.
\newblock Advancing neuromorphic computing with loihi: A survey of results and
  outlook.
\newblock \emph{Proceedings of the IEEE}, 109\penalty0 (5):\penalty0 911--934,
  2021.

\bibitem[DeVries \& Taylor(2017)DeVries and Taylor]{devries2017cutout}
DeVries, T. and Taylor, G.~W.
\newblock Improved regularization of convolutional neural networks with cutout.
\newblock \emph{arXiv preprint arXiv:1708.04552}, 2017.

\bibitem[Diehl \& Cook(2015)Diehl and Cook]{diehl2015unsupervised}
Diehl, P.~U. and Cook, M.
\newblock Unsupervised learning of digit recognition using
  spike-timing-dependent plasticity.
\newblock \emph{Frontiers in Computational Neuroscience}, 9:\penalty0 99, 2015.

\bibitem[Diehl et~al.(2015)Diehl, Neil, Binas, Cook, Liu, and
  Pfeiffer]{diehl2015fast}
Diehl, P.~U., Neil, D., Binas, J., Cook, M., Liu, S.-C., and Pfeiffer, M.
\newblock Fast-classifying, high-accuracy spiking deep networks through weight
  and threshold balancing.
\newblock In \emph{International Joint Conference on Neural Networks}, 2015.

\bibitem[Ding et~al.(2021)Ding, Lian, Yang, Wang, Jin, Lu, and
  Luo]{ding2021hrnas}
Ding, M., Lian, X., Yang, L., Wang, P., Jin, X., Lu, Z., and Luo, P.
\newblock Hr-nas: Searching efficient high-resolution neural architectures with
  lightweight transformers.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2021.

\bibitem[Dong \& Yang(2019)Dong and Yang]{dong2019gdas}
Dong, X. and Yang, Y.
\newblock Searching for a robust neural architecture in four gpu hours.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2019.

\bibitem[Fang et~al.(2021{\natexlab{a}})Fang, Yu, Chen, Huang, Masquelier, and
  Tian]{fang2021SEW}
Fang, W., Yu, Z., Chen, Y., Huang, T., Masquelier, T., and Tian, Y.
\newblock Deep residual learning in spiking neural networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 34,
  2021{\natexlab{a}}.

\bibitem[Fang et~al.(2021{\natexlab{b}})Fang, Yu, Chen, Masquelier, Huang, and
  Tian]{fang2021incorporating}
Fang, W., Yu, Z., Chen, Y., Masquelier, T., Huang, T., and Tian, Y.
\newblock Incorporating learnable membrane time constant to enhance learning of
  spiking neural networks.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  2661--2671, 2021{\natexlab{b}}.

\bibitem[Gerstner \& Kistler(2002)Gerstner and Kistler]{gerstner2002spiking}
Gerstner, W. and Kistler, W.~M.
\newblock \emph{Spiking neuron models: Single neurons, populations,
  plasticity}.
\newblock Cambridge university press, 2002.

\bibitem[Guo et~al.(2020{\natexlab{a}})Guo, Han, Wang, Zhang, Yang, Wu, Chen,
  and Xu]{guo2020hitdetector}
Guo, J., Han, K., Wang, Y., Zhang, C., Yang, Z., Wu, H., Chen, X., and Xu, C.
\newblock Hit-detector: Hierarchical trinity architecture search for object
  detection.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2020{\natexlab{a}}.

\bibitem[Guo et~al.(2020{\natexlab{b}})Guo, Zhang, Mu, Heng, Liu, Wei, and
  Sun]{guo2020spos}
Guo, Z., Zhang, X., Mu, H., Heng, W., Liu, Z., Wei, Y., and Sun, J.
\newblock Single path one-shot neural architecture search with uniform
  sampling.
\newblock In \emph{European Conference on Computer Vision}, 2020{\natexlab{b}}.

\bibitem[Han et~al.(2020)Han, Srinivasan, and Roy]{han2020rmpsnn}
Han, B., Srinivasan, G., and Roy, K.
\newblock Rmp-snn: Residual membrane potential neuron for enabling deeper
  high-accuracy and low-latency spiking neural network.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, June 2020.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016resnet}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2016.

\bibitem[He et~al.(2020)He, Wu, Deng, Li, Wang, Tian, Ding, Wang, and
  Xie]{he2020comparing}
He, W., Wu, Y., Deng, L., Li, G., Wang, H., Tian, Y., Ding, W., Wang, W., and
  Xie, Y.
\newblock Comparing snns and rnns on neuromorphic vision datasets: similarities
  and differences.
\newblock \emph{Neural Networks}, 132:\penalty0 108--120, 2020.

\bibitem[Jiang et~al.(2020)Jiang, Xu, Zhang, Liang, and Li]{jiang2020spnas}
Jiang, C., Xu, H., Zhang, W., Liang, X., and Li, Z.
\newblock Sp-nas: Serial-to-parallel backbone search for object detection.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2020.

\bibitem[Kaiser et~al.(2020)Kaiser, Mostafa, and Neftci]{kaiser2020synaptic}
Kaiser, J., Mostafa, H., and Neftci, E.
\newblock Synaptic plasticity dynamics for deep continuous local learning
  (decolle).
\newblock \emph{Frontiers in Neuroscience}, 14:\penalty0 424, 2020.

\bibitem[Kim et~al.(2020{\natexlab{a}})Kim, Wang, Kim, and Lee]{kim2020est}
Kim, J., Wang, J., Kim, S., and Lee, Y.
\newblock Evolved speech-transformer: Applying neural architecture search to
  end-to-end automatic speech recognition.
\newblock In \emph{INTERSPEECH}, 2020{\natexlab{a}}.

\bibitem[Kim et~al.(2020{\natexlab{b}})Kim, Park, Na, and Yoon]{kim2020spiking}
Kim, S., Park, S., Na, B., and Yoon, S.
\newblock Spiking-yolo: Spiking neural network for energy-efficient object
  detection.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2020{\natexlab{b}}.

\bibitem[Kim \& Panda(2020)Kim and Panda]{kim2020BNTT}
Kim, Y. and Panda, P.
\newblock Revisiting batch normalization for training low-latency deep spiking
  neural networks from scratch.
\newblock \emph{Frontiers in Neuroscience}, pp.\  1638, 2020.

\bibitem[Kim \& Panda(2021)Kim and Panda]{kim2021SALT}
Kim, Y. and Panda, P.
\newblock Optimizing deeper spiking neural networks for dynamic vision sensing.
\newblock \emph{Neural Networks}, 144:\penalty0 686--698, 2021.

\bibitem[Kim et~al.(2022)Kim, Li, Park, Venkatesha, and Panda]{kim2022SNASNet}
Kim, Y., Li, Y., Park, H., Venkatesha, Y., and Panda, P.
\newblock Neural architecture search for spiking neural networks.
\newblock \emph{arXiv preprint arXiv:2201.10355}, 2022.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{kingma2015adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009cifar10}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Lee et~al.(2020)Lee, Sarwar, Panda, Srinivasan, and
  Roy]{lee2020enabling}
Lee, C., Sarwar, S.~S., Panda, P., Srinivasan, G., and Roy, K.
\newblock Enabling spike-based backpropagation for training deep neural network
  architectures.
\newblock \emph{Frontiers in Neuroscience}, 14:\penalty0 119, 2020.

\bibitem[Li et~al.(2017)Li, Liu, Ji, Li, and Shi]{li2017cifar10dvs}
Li, H., Liu, H., Ji, X., Li, G., and Shi, L.
\newblock Cifar10-dvs: an event-stream dataset for object classification.
\newblock \emph{Frontiers in Neuroscience}, 11:\penalty0 309, 2017.

\bibitem[Li \& Talwalkar(2020)Li and Talwalkar]{li2020random}
Li, L. and Talwalkar, A.
\newblock Random search and reproducibility for neural architecture search.
\newblock In \emph{Uncertainty in Artificial Intelligence}, 2020.

\bibitem[Lin et~al.(2014)Lin, Chen, and Yan]{lin2013nin_gap}
Lin, M., Chen, Q., and Yan, S.
\newblock Network in network.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Liu et~al.(2019)Liu, Simonyan, and Yang]{yang2019darts}
Liu, H., Simonyan, K., and Yang, Y.
\newblock Darts: Differentiable architecture search.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Maass(1997)]{maass1997networks}
Maass, W.
\newblock Networks of spiking neurons: the third generation of neural network
  models.
\newblock \emph{Neural networks}, 10\penalty0 (9):\penalty0 1659--1671, 1997.

\bibitem[Merolla et~al.(2014)Merolla, Arthur, Alvarez-Icaza, Cassidy, Sawada,
  Akopyan, Jackson, Imam, Guo, Nakamura, et~al.]{merolla2014million}
Merolla, P., Arthur, J.~V., Alvarez-Icaza, R., Cassidy, A.~S., Sawada, J.,
  Akopyan, F., Jackson, B.~L., Imam, N., Guo, C., Nakamura, Y., et~al.
\newblock A million spiking-neuron integrated circuit with a scalable
  communication network and interface.
\newblock \emph{Science}, 345\penalty0 (6197):\penalty0 668--673, 2014.

\bibitem[Neftci et~al.(2019)Neftci, Mostafa, and Zenke]{neftci2019surrogate}
Neftci, E.~O., Mostafa, H., and Zenke, F.
\newblock Surrogate gradient learning in spiking neural networks: Bringing the
  power of gradient-based optimization to spiking neural networks.
\newblock \emph{IEEE Signal Processing Magazine}, 36\penalty0 (6):\penalty0
  51--63, 2019.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and
  Ng]{netzer2011svhn}
Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., and Ng, A.~Y.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock In \emph{NeurIPS Workshop on Deep Learning and Unsupervised Feature
  Learning}, 2011.

\bibitem[Park et~al.(2019)Park, Kim, Choe, and Yoon]{park2019burst}
Park, S., Kim, S., Choe, H., and Yoon, S.
\newblock Fast and efficient information transmission with burst spikes in deep
  spiking neural networks.
\newblock In \emph{ACM/IEEE Design Automation Conference (DAC)}, 2019.

\bibitem[Park et~al.(2020)Park, Kim, Na, and Yoon]{park2020t2fsnn}
Park, S., Kim, S., Na, B., and Yoon, S.
\newblock T2fsnn: deep spiking neural networks with time-to-first-spike coding.
\newblock In \emph{ACM/IEEE Design Automation Conference (DAC)}, 2020.

\bibitem[Pellegrini et~al.(2021)Pellegrini, Zimmer, and
  Masquelier]{pellegrini2021spike_regularization}
Pellegrini, T., Zimmer, R., and Masquelier, T.
\newblock Low-activity supervised convolutional spiking neural networks applied
  to speech commands recognition.
\newblock In \emph{IEEE Spoken Language Technology Workshop (SLT)}, pp.\
  97--103. IEEE, 2021.

\bibitem[Peng et~al.(2020)Peng, Du, Yu, Li, Liao, and Fu]{peng2020cream}
Peng, H., Du, H., Yu, H., Li, Q., Liao, J., and Fu, J.
\newblock Cream of the crop: Distilling prioritized paths for one-shot neural
  architecture search.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Pham et~al.(2018)Pham, Guan, Zoph, Le, and Dean]{dean2018enas}
Pham, H., Guan, M.~Y., Zoph, B., Le, Q.~V., and Dean, J.
\newblock Efficient neural architecture search via parameter sharing.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning}, 2018.

\bibitem[Real et~al.(2017)Real, Moore, Selle, Saxena, Suematsu, Tan, Le, and
  Kurakin]{real2017large}
Real, E., Moore, S., Selle, A., Saxena, S., Suematsu, Y.~L., Tan, J., Le,
  Q.~V., and Kurakin, A.
\newblock Large-scale evolution of image classifiers.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning}, 2017.

\bibitem[Real et~al.(2019)Real, Aggarwal, Huang, and Le]{real2019regularized}
Real, E., Aggarwal, A., Huang, Y., and Le, Q.~V.
\newblock Regularized evolution for image classifier architecture search.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2019.

\bibitem[Rueckauer et~al.(2017)Rueckauer, Lungu, Hu, Pfeiffer, and
  Liu]{rueckauer2017conversion}
Rueckauer, B., Lungu, I.-A., Hu, Y., Pfeiffer, M., and Liu, S.-C.
\newblock Conversion of continuous-valued deep networks to efficient
  event-driven networks for image classification.
\newblock \emph{Frontiers in Neuroscience}, 11:\penalty0 682, 2017.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, et~al.]{russakovsky2015imagenet}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
  Karpathy, A., Khosla, A., Bernstein, M., et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{International Journal of Computer Vision}, 115\penalty0
  (3):\penalty0 211--252, 2015.

\bibitem[Sandler et~al.(2018)Sandler, Howard, Zhu, Zhmoginov, and
  Chen]{sandler2018mobilenetv2}
Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., and Chen, L.-C.
\newblock Mobilenetv2: Inverted residuals and linear bottlenecks.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2018.

\bibitem[Sengupta et~al.(2019)Sengupta, Ye, Wang, Liu, and
  Roy]{sengupta2019going}
Sengupta, A., Ye, Y., Wang, R., Liu, C., and Roy, K.
\newblock Going deeper in spiking neural networks: Vgg and residual
  architectures.
\newblock \emph{Frontiers in Neuroscience}, 13:\penalty0 95, 2019.

\bibitem[Simonyan \& Zisserman(2015)Simonyan and Zisserman]{Simonyan15vggnet}
Simonyan, K. and Zisserman, A.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Szegedy et~al.(2015)Szegedy, Liu, Jia, Sermanet, Reed, Anguelov,
  Erhan, Vanhoucke, and Rabinovich]{szegedy2015inception}
Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D.,
  Vanhoucke, V., and Rabinovich, A.
\newblock Going deeper with convolutions.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2015.

\bibitem[Tan et~al.(2019)Tan, Chen, Pang, Vasudevan, Sandler, Howard, and
  Le]{tan2019mnasnet}
Tan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., and Le,
  Q.~V.
\newblock Mnasnet: Platform-aware neural architecture search for mobile.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2019.

\bibitem[Wu et~al.(2019{\natexlab{a}})Wu, Dai, Zhang, Wang, Sun, Wu, Tian,
  Vajda, Jia, and Keutzer]{wu2019fbnet}
Wu, B., Dai, X., Zhang, P., Wang, Y., Sun, F., Wu, Y., Tian, Y., Vajda, P.,
  Jia, Y., and Keutzer, K.
\newblock Fbnet: Hardware-aware efficient convnet design via differentiable
  neural architecture search.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2019{\natexlab{a}}.

\bibitem[Wu et~al.(2019{\natexlab{b}})Wu, Deng, Li, Zhu, Xie, and
  Shi]{wu2019direct}
Wu, Y., Deng, L., Li, G., Zhu, J., Xie, Y., and Shi, L.
\newblock Direct training for spiking neural networks: Faster, larger, better.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2019{\natexlab{b}}.

\bibitem[Xie et~al.(2020)Xie, Chen, Bi, Wei, Xu, Chen, Wang, Xiao, Chang,
  Zhang, and Tian]{xie2020survey}
Xie, L., Chen, X., Bi, K., Wei, L., Xu, Y., Chen, Z., Wang, L., Xiao, A.,
  Chang, J., Zhang, X., and Tian, Q.
\newblock Weight-sharing neural architecture search: A battle to shrink the
  optimization gap, 2020.

\bibitem[Yan et~al.(2021)Yan, Peng, Wu, Wang, Fu, and Lu]{yan2021lighttrack}
Yan, B., Peng, H., Wu, K., Wang, D., Fu, J., and Lu, H.
\newblock Lighttrack: Finding lightweight neural networks for object tracking
  via one-shot architecture search.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2021.

\bibitem[You et~al.(2020)You, Huang, Yang, Wang, Qian, and
  Zhang]{you2020greedynas}
You, S., Huang, T., Yang, M., Wang, F., Qian, C., and Zhang, C.
\newblock Greedynas: Towards fast one-shot nas with greedy supernet.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2020.

\bibitem[Zhang et~al.(2020)Zhang, Li, Pan, Liu, and
  Su]{zhang2020oneshot_novelty}
Zhang, M., Li, H., Pan, S., Liu, T., and Su, S.~W.
\newblock One-shot neural architecture search via novelty driven sampling.
\newblock In \emph{International Joint Conference on Artificial Intelligence},
  2020.

\bibitem[Zhang et~al.(2021{\natexlab{a}})Zhang, Hou, Zhang, and
  Sun]{zhang2021rlnas}
Zhang, X., Hou, P., Zhang, X., and Sun, J.
\newblock Neural architecture search with random labels.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2021{\natexlab{a}}.

\bibitem[Zhang et~al.(2021{\natexlab{b}})Zhang, Xu, Mo, Tan, Yang, Wang, and
  Ren]{zhang2021dcnas}
Zhang, X., Xu, H., Mo, H., Tan, J., Yang, C., Wang, L., and Ren, W.
\newblock Dcnas: Densely connected neural architecture search for semantic
  image segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2021{\natexlab{b}}.

\bibitem[Zheng et~al.(2021)Zheng, Wu, Deng, Hu, and Li]{zheng2021going}
Zheng, H., Wu, Y., Deng, L., Hu, Y., and Li, G.
\newblock Going deeper with directly-trained larger spiking neural networks.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2021.

\bibitem[Zoph \& Le(2017)Zoph and Le]{le2017naswithRL}
Zoph, B. and Le, Q.~V.
\newblock Neural architecture search with reinforcement learning.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Zoph et~al.(2018)Zoph, Vasudevan, Shlens, and Le]{zoph2018nasnet}
Zoph, B., Vasudevan, V., Shlens, J., and Le, Q.~V.
\newblock Learning transferable architectures for scalable image recognition.
\newblock In \emph{Proceedings of the IEEE conference on Computer Vision and
  Pattern Recognition}, 2018.

\end{thebibliography}
