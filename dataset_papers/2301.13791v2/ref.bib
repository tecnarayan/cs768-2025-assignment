@article{bastani2021mostly,
  title={Mostly exploration-free algorithms for contextual bandits},
  author={Bastani, Hamsa and Bayati, Mohsen and Khosravi, Khashayar},
  journal={Management Science},
  volume={67},
  number={3},
  pages={1329--1349},
  year={2021},
  publisher={INFORMS}
}

@article{sankararaman2021bandits,
  title={Bandits with knapsacks beyond the worst case},
  author={Sankararaman, Karthik Abinav and Slivkins, Aleksandrs},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={23191--23204},
  year={2021}
}

@article{besbes2009dynamic,
  title={Dynamic pricing without knowing the demand function: Risk bounds and near-optimal algorithms},
  author={Besbes, Omar and Zeevi, Assaf},
  journal={Operations Research},
  volume={57},
  number={6},
  pages={1407--1420},
  year={2009},
  publisher={INFORMS}
}

@article{besson2018doubling,
  title={What doubling tricks can and can't do for multi-armed bandits},
  author={Besson, Lilian and Kaufmann, Emilie},
  journal={arXiv preprint arXiv:1803.06971},
  year={2018}
}

@ARTICLE{moradipari21safethompson,
  author={Moradipari, Ahmadreza and Amani, Sanae and Alizadeh, Mahnoosh and Thrampoulidis, Christos},
  journal={IEEE Transactions on Signal Processing}, 
  title={Safe Linear Thompson Sampling With Side Information}, 
  year={2021},
  volume={69},
  number={},
  pages={3755-3767},
  doi={10.1109/TSP.2021.3089822}}

@book{good2006resampling,
  title={Resampling methods},
  author={Good, Phillip I},
  year={2006},
  publisher={Springer}
}

@book{efron1994introduction,
  title={An introduction to the bootstrap},
  author={Efron, Bradley and Tibshirani, Robert J},
  year={1994},
  publisher={CRC press}
}

@InProceedings{pacchiano21linear,
  title = 	 { Stochastic Bandits with Linear Constraints },
  author =       {Pacchiano, Aldo and Ghavamzadeh, Mohammad and Bartlett, Peter and Jiang, Heinrich},
  booktitle = 	 {Proceedings of The 24th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {2827--2835},
  year = 	 {2021},
  editor = 	 {Banerjee, Arindam and Fukumizu, Kenji},
  volume = 	 {130},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--15 Apr},
  publisher =    {PMLR},
  abstract = 	 { We study a constrained contextual linear bandit setting, where the goal of the agent is to produce a sequence of policies, whose expected cumulative reward over the course of multiple rounds is maximum, and each one of them has an expected cost below a certain threshold. We propose an upper-confidence bound algorithm for this problem, called optimistic pessimistic linear bandit (OPLB), and prove a sublinear bound on its regret that is inversely proportional to the difference between the constraint threshold and the cost of a known feasible action. Our algorithm balances exploration and constraint satisfaction using a novel idea that scales the radii of the reward and cost confidence sets with different scaling factors. We further specialize our results to multi-armed bandits and propose a computationally efficient algorithm for this setting and prove a a regret bound that is better than simply casting multi-armed bandits as an instance of linear bandits and using the regret bound of OPLB. We also prove a lower-bound for the problem studied in the paper and provide simulations to validate our theoretical results. Finally, we show how our algorithm and analysis can be extended to multiple constraints and to the case when the cost of the feasible action is unknown. }
}


@article{gallego1994optimal,
  title={Optimal dynamic pricing of inventories with stochastic demand over finite horizons},
  author={Gallego, Guillermo and Van Ryzin, Garrett},
  journal={Management science},
  volume={40},
  number={8},
  pages={999--1020},
  year={1994},
  publisher={INFORMS}
}

@article{besbes2012blind,
  title={Blind network revenue management},
  author={Besbes, Omar and Zeevi, Assaf},
  journal={Operations research},
  volume={60},
  number={6},
  pages={1537--1550},
  year={2012},
  publisher={INFORMS}
}

@inproceedings{agrawal2014fast,
  title={Fast algorithms for online stochastic convex programming},
  author={Agrawal, Shipra and Devanur, Nikhil R},
  booktitle={Proceedings of the twenty-sixth annual ACM-SIAM symposium on Discrete algorithms},
  pages={1405--1424},
  year={2014},
  organization={SIAM}
}

@inproceedings{feldman2010online,
  title={Online stochastic packing applied to display ad allocation},
  author={Feldman, Jon and Henzinger, Monika and Korula, Nitish and Mirrokni, Vahab S and Stein, Cliff},
  booktitle={European Symposium on Algorithms},
  pages={182--194},
  year={2010},
  organization={Springer}
}

@article{liu2021efficient,
  title={An efficient pessimistic-optimistic algorithm for stochastic linear bandits with general constraints},
  author={Liu, Xin and Li, Bin and Shi, Pengyi and Ying, Lei},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={24075--24086},
  year={2021}
}

@article{agrawal2014dynamic,
  title={A dynamic near-optimal algorithm for online linear programming},
  author={Agrawal, Shipra and Wang, Zizhuo and Ye, Yinyu},
  journal={Operations Research},
  volume={62},
  number={4},
  pages={876--890},
  year={2014},
  publisher={INFORMS}
}

@inproceedings{devanur2011near,
  title={Near optimal online algorithms and fast approximation algorithms for resource allocation problems},
  author={Devanur, Nikhil R and Jain, Kamal and Sivan, Balasubramanian and Wilkens, Christopher A},
  booktitle={Proceedings of the 12th ACM conference on Electronic commerce},
  pages={29--38},
  year={2011}
}

@InProceedings{li21symmetry,
  title = 	 {The Symmetry between Arms and Knapsacks: A Primal-Dual Approach for Bandits with Knapsacks},
  author =       {Li, Xiaocheng and Sun, Chunlin and Ye, Yinyu},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {6483--6492},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  abstract = 	 {In this paper, we study the bandits with knapsacks (BwK) problem and develop a primal-dual based algorithm that achieves a problem-dependent logarithmic regret bound. The BwK problem extends the multi-arm bandit (MAB) problem to model the resource consumption, and the existing BwK literature has been mainly focused on deriving asymptotically optimal distribution-free regret bounds. We first study the primal and dual linear programs underlying the BwK problem. From this primal-dual perspective, we discover symmetry between arms and knapsacks, and then propose a new notion of suboptimality measure for the BwK problem. The suboptimality measure highlights the important role of knapsacks in determining algorithm regret and inspires the design of our two-phase algorithm. In the first phase, the algorithm identifies the optimal arms and the binding knapsacks, and in the second phase, it exhausts the binding knapsacks via playing the optimal arms through an adaptive procedure. Our regret upper bound involves the proposed suboptimality measure and it has a logarithmic dependence on length of horizon $T$ and a polynomial dependence on $m$ (the numbers of arms) and $d$ (the number of knapsacks). To the best of our knowledge, this is the first problem-dependent logarithmic regret bound for solving the general BwK problem.}
}


@inproceedings{immorlica2019adversarial,
  title={Adversarial bandits with knapsacks},
  author={Immorlica, Nicole and Sankararaman, Karthik Abinav and Schapire, Robert and Slivkins, Aleksandrs},
  booktitle={2019 IEEE 60th Annual Symposium on Foundations of Computer Science (FOCS)},
  pages={202--219},
  year={2019},
  organization={IEEE}
}

@inproceedings{agrawal2014bandits,
  title={Bandits with concave rewards and convex knapsacks},
  author={Agrawal, Shipra and Devanur, Nikhil R},
  booktitle={Proceedings of the fifteenth ACM conference on Economics and computation},
  pages={989--1006},
  year={2014}
}

@inproceedings{garivier2011kl,
  title={The KL-UCB algorithm for bounded stochastic bandits and beyond},
  author={Garivier, Aur{\'e}lien and Capp{\'e}, Olivier},
  booktitle={Proceedings of the 24th annual conference on learning theory},
  pages={359--376},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@book{boyd2004convex,
  title={Convex optimization},
  author={Boyd, Stephen and Boyd, Stephen P and Vandenberghe, Lieven},
  year={2004},
  publisher={Cambridge university press}
}

@article{ferreira2018online,
  title={Online network revenue management using thompson sampling},
  author={Ferreira, Kris Johnson and Simchi-Levi, David and Wang, He},
  journal={Operations research},
  volume={66},
  number={6},
  pages={1586--1602},
  year={2018},
  publisher={INFORMS}
}

@inproceedings{sivakumar2022smoothed,
  title={Smoothed adversarial linear contextual bandits with knapsacks},
  author={Sivakumar, Vidyashankar and Zuo, Shiliang and Banerjee, Arindam},
  booktitle={International Conference on Machine Learning},
  pages={20253--20277},
  year={2022},
  organization={PMLR}
}

@inproceedings{sivakumar2020structured,
  title={Structured linear contextual bandits: A sharp and geometric smoothed analysis},
  author={Sivakumar, Vidyashankar and Wu, Steven and Banerjee, Arindam},
  booktitle={International Conference on Machine Learning},
  pages={9026--9035},
  year={2020},
  organization={PMLR}
}

@article{kannan2018smoothed,
  title={A smoothed analysis of the greedy algorithm for the linear contextual bandit problem},
  author={Kannan, Sampath and Morgenstern, Jamie H and Roth, Aaron and Waggoner, Bo and Wu, Zhiwei Steven},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{murphy2005experimental,
  title={An experimental design for the development of adaptive treatment strategies},
  author={Murphy, Susan A},
  journal={Statistics in medicine},
  volume={24},
  number={10},
  pages={1455--1481},
  year={2005},
  publisher={Wiley Online Library}
}

@article{offer2021adaptive,
  title={Adaptive experimental design: Prospects and applications in political science},
  author={Offer-Westort, Molly and Coppock, Alexander and Green, Donald P},
  journal={American Journal of Political Science},
  volume={65},
  number={4},
  pages={826--844},
  year={2021},
  publisher={Wiley Online Library}
}

@article{collins2007multiphase,
  title={The multiphase optimization strategy (MOST) and the sequential multiple assignment randomized trial (SMART): new methods for more potent eHealth interventions},
  author={Collins, Linda M and Murphy, Susan A and Strecher, Victor},
  journal={American journal of preventive medicine},
  volume={32},
  number={5},
  pages={S112--S118},
  year={2007},
  publisher={Elsevier}
}

@inproceedings{kim2021doubly,
	author = {Wonyoung Kim and Gi-Soo Kim and Myunghee Cho Paik},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
	title = {Doubly Robust Thompson Sampling with Linear Payoffs},
	year = {2021}}

@inproceedings{li2019nearly,
	author = {Li, Yingkai and Wang, Yining and Zhou, Yuan},
	booktitle = {Conference on Learning Theory},
	organization = {PMLR},
	pages = {2173--2174},
	title = {Nearly minimax-optimal regret for linearly parameterized bandits},
	year = {2019}}

@article{tropp2012user,
	author = {Tropp, Joel A},
	journal = {Foundations of computational mathematics},
	number = {4},
	pages = {389--434},
	publisher = {Springer},
	title = {User-friendly tail bounds for sums of random matrices},
	volume = {12},
	year = {2012}}

@article{gao2016distributionally,
	author = {Gao, Rui and Kleywegt, Anton J},
	journal = {arXiv preprint arXiv:1604.02199},
	title = {Distributionally robust stochastic optimization with Wasserstein distance},
	year = {2016}}

@article{rusmevichientong2010linearly,
	author = {Rusmevichientong, Paat and Tsitsiklis, John N},
	journal = {Mathematics of Operations Research},
	number = {2},
	pages = {395--411},
	publisher = {INFORMS},
	title = {Linearly parameterized bandits},
	volume = {35},
	year = {2010}}

@article{kontorovich2008concentration,
	author = {Kontorovich, Leonid Aryeh and Ramanan, Kavita},
	journal = {The Annals of Probability},
	number = {6},
	pages = {2126--2158},
	publisher = {Institute of Mathematical Statistics},
	title = {Concentration inequalities for dependent random variables via the martingale method},
	volume = {36},
	year = {2008}}

@article{auer2002nonstochastic,
	author = {Auer, Peter and Cesa-Bianchi, Nicolo and Freund, Yoav and Schapire, Robert E},
	journal = {SIAM journal on computing},
	number = {1},
	pages = {48--77},
	publisher = {SIAM},
	title = {The nonstochastic multiarmed bandit problem},
	volume = {32},
	year = {2002b}}

@book{lattimore2020bandit,
	author = {Lattimore, Tor and Szepesv{\'a}ri, Csaba},
	publisher = {Cambridge University Press},
	title = {Bandit algorithms},
	year = {2020}}

@inbook{vanderVaart1996,
	abstract = {One of the two main approaches toward deriving Glivenko-Cantelli and Donsker theorems is based on the principle of comparing the empirical process to a ``symmetrized'' empirical process. In this chapter we derive the main symmetrization theorem, as well as a number of technical complements, which may be skipped at first reading.},
	address = {New York, NY},
	author = {van der Vaart, Aad W. and Wellner, Jon A.},
	booktitle = {Weak Convergence and Empirical Processes: With Applications to Statistics},
	doi = {10.1007/978-1-4757-2545-2_15},
	isbn = {978-1-4757-2545-2},
	pages = {107--121},
	publisher = {Springer New York},
	title = {Symmetrization and Measurability},
	year = {1996},
	bdsk-url-1 = {https://doi.org/10.1007/978-1-4757-2545-2_15}}

@article{lasserre1995trace,
	author = {Lasserre, Jean B},
	journal = {IEEE Transactions on Automatic Control},
	number = {8},
	pages = {1500--1501},
	publisher = {IEEE},
	title = {A trace inequality for matrix product},
	volume = {40},
	year = {1995}}

@article{chung2006concentration,
	author = {Chung, Fan and Lu, Linyuan},
	journal = {Internet Mathematics},
	number = {1},
	pages = {79--127},
	publisher = {Taylor \& Francis},
	title = {Concentration inequalities and martingale inequalities: a survey},
	volume = {3},
	year = {2006}}

@article{dubhashi1996balls,
	author = {Dubhashi, Devdatt P and Ranjan, Desh},
	journal = {BRICS Report Series},
	number = {25},
	title = {Balls and bins: A study in negative dependence},
	volume = {3},
	year = {1996}}

@article{auer2002using,
	author = {Auer, Peter},
	journal = {Journal of Machine Learning Research},
	number = {Nov},
	pages = {397--422},
	title = {Using confidence bounds for exploitation-exploration trade-offs},
	volume = {3},
	year = {2002a}}

@inproceedings{abbasi2012online,
	author = {Abbasi-Yadkori, Yasin and Pal, David and Szepesvari, Csaba},
	booktitle = {Artificial Intelligence and Statistics},
	pages = {1--9},
	title = {Online-to-confidence-set conversions and application to sparse stochastic bandits},
	year = {2012}}

@inproceedings{gopalan2014thompson,
	author = {Gopalan, Aditya and Mannor, Shie and Mansour, Yishay},
	booktitle = {International Conference on Machine Learning},
	pages = {100--108},
	title = {Thompson sampling for complex online problems},
	year = {2014}}

@article{abeille2017linear,
	author = {Abeille, Marc and Lazaric, Alessandro and others},
	journal = {Electronic Journal of Statistics},
	number = {2},
	pages = {5165--5197},
	publisher = {The Institute of Mathematical Statistics and the Bernoulli Society},
	title = {Linear thompson sampling revisited},
	volume = {11},
	year = {2017}}

@book{vershynin2018high,
	author = {Vershynin, Roman},
	publisher = {Cambridge university press},
	title = {High-dimensional probability: An introduction with applications in data science},
	volume = {47},
	year = {2018}}

@book{bickel1993efficient,
	author = {Bickel, Peter J and Klaassen, Chris AJ and Bickel, Peter J and Ritov, Ya'acov and Klaassen, J and Wellner, Jon A and Ritov, YA'Acov},
	publisher = {Johns Hopkins University Press Baltimore},
	title = {Efficient and adaptive estimation for semiparametric models},
	volume = {4},
	year = {1993}}

@inproceedings{li2017provably,
	author = {Li, Lihong and Lu, Yu and Zhou, Dengyong},
	booktitle = {Proceedings of the 34th International Conference on Machine Learning-Volume 70},
	organization = {JMLR. org},
	pages = {2071--2080},
	title = {Provably optimal algorithms for generalized linear contextual bandits},
	year = {2017}}

@book{asmussen2007stochastic,
	author = {Asmussen, S{\o}ren and Glynn, Peter W},
	publisher = {Springer Science \& Business Media},
	title = {Stochastic simulation: algorithms and analysis},
	volume = {57},
	year = {2007}}

@inproceedings{dimakopoulou2019balanced,
	author = {Dimakopoulou, Maria and Zhou, Zhengyuan and Athey, Susan and Imbens, Guido},
	booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
	pages = {3445--3453},
	title = {Balanced linear contextual bandits},
	volume = {33},
	year = {2019}}

@article{1933Thompson,
	author = {William R. Thompson},
	issn = {00063444},
	journal = {Biometrika},
	number = {3/4},
	pages = {285--294},
	publisher = {[Oxford University Press, Biometrika Trust]},
	title = {On the Likelihood that One Unknown Probability Exceeds Another in View of the Evidence of Two Samples},
	volume = {25},
	year = {1933}}

@book{tong2012multivariate,
	author = {Tong, Yung Liang},
	publisher = {Springer Science \& Business Media},
	title = {The multivariate normal distribution},
	year = {2012}}

@article{lee2016,
	author = {Lee, James R. and Peres, Yuval and Smart, Charles K.},
	doi = {10.1214/15-AOP1073},
	fjournal = {The Annals of Probability},
	journal = {Ann. Probab.},
	month = {11},
	number = {6},
	pages = {4184--4197},
	publisher = {The Institute of Mathematical Statistics},
	title = {A Gaussian upper bound for martingale small-ball probabilities},
	volume = {44},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1214/15-AOP1073}}

@article{goldenshluger2013linear,
	author = {Goldenshluger, Alexander and Zeevi, Assaf},
	journal = {Stochastic Systems},
	number = {1},
	pages = {230--261},
	publisher = {INFORMS},
	title = {A linear response bandit problem},
	volume = {3},
	year = {2013}}


@InProceedings{kim2022squeeze,
  title = 	 {Squeeze All: Novel Estimator and Self-Normalized Bound for Linear Contextual Bandits},
  author =       {Kim, Wonyoung and Paik, Myunghee Cho and Oh, Min-Hwan},
  booktitle = 	 {Proceedings of The 26th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {3098--3124},
  year = 	 {2023},
  editor = 	 {Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem},
  volume = 	 {206},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {25--27 Apr},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v206/kim23d/kim23d.pdf},
  url = 	 {https://proceedings.mlr.press/v206/kim23d.html},
  abstract = 	 {We propose a linear contextual bandit algorithm for linear contextual bandits with $O(\sqrt{dT \log T})$ regret bound, where $d$ is the dimension of contexts and $T$ is the time horizon. Our proposed algorithm is equipped with a novel estimator in which exploration is embedded through explicit randomization. Depending on the randomization, our proposed estimator takes contribution either from contexts of all arms or from selected contexts. We establish a self-normalized bound for our estimator, which allows a novel decomposition of the cumulative regret into additive dimension-dependent terms instead of multiplicative terms. We also prove a novel lower bound of $\Omega(\sqrt{dT})$ under our problem setting. Hence, the regret of our proposed algorithm matches the lower bound up to logarithmic factors. The numerical experiments support the theoretical guarantees and show that our proposed method outperforms the existing linear bandit algorithms.}
}

@article{kim2022double,
  title={Double Doubly Robust Thompson Sampling for Generalized Linear Contextual Bandits},
  author={Kim, Wonyoung and Lee, Kyungbok and Paik, Myunghee Cho},
  journal={arXiv preprint arXiv:2209.06983},
  year={2022}
}

@article{bastani2020online,
	author = {Bastani, Hamsa and Bayati, Mohsen},
	journal = {Operations Research},
	number = {1},
	pages = {276--294},
	publisher = {INFORMS},
	title = {Online decision making with high-dimensional covariates},
	volume = {68},
	year = {2020}}

@inproceedings{kim2019doubly,
	author = {Kim, Gisoo and Paik, Myunghee Cho},
	booktitle = {Advances in Neural Information Processing Systems},
	pages = {5869--5879},
	title = {Doubly-Robust Lasso Bandit},
	year = {2019}}

@inproceedings{perturb20akveton,
	author = {Kveton, Branislav and Szepesv{\'{a}}ri, Csaba and Ghavamzadeh, Mohammad and Boutilier, Craig},
	booktitle = {Proceedings of The 35th Uncertainty in Artificial Intelligence Conference},
	editor = {Adams, Ryan P. and Gogate, Vibhav},
	month = {22--25 Jul},
	pages = {530--540},
	publisher = {PMLR},
	series = {Proceedings of Machine Learning Research},
	title = {Perturbed-History Exploration in Stochastic Linear Bandits},
	volume = {115},
	year = {2020}}

@inproceedings{dani2008stochastic,
	author = {Dani, Varsha and Hayes, Thomas and Kakade, Sham},
	booktitle = {21st Annual Conference on Learning Theory},
	month = {01},
	pages = {355-366},
	title = {Stochastic linear optimization under bandit feedback},
	year = {2008}}

@inproceedings{agrawal2013thompson,
	author = {Agrawal, Shipra and Goyal, Navin},
	booktitle = {International Conference on Machine Learning},
	pages = {127--135},
	title = {Thompson sampling for contextual bandits with linear payoffs},
	year = {2013}}

@inproceedings{abbasi2011improved,
	author = {Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
	booktitle = {Advances in Neural Information Processing Systems},
	pages = {2312--2320},
	title = {Improved algorithms for linear stochastic bandits},
	year = {2011}}

@book{abramowitz1948handbook,
	author = {Abramowitz, Milton and Stegun, Irene A},
	publisher = {US Government printing office},
	title = {Handbook of mathematical functions with formulas, graphs, and mathematical tables},
	volume = {55},
	year = {1948}}

@inproceedings{amani2019linear,
	author = {Amani, Sanae and Alizadeh, Mahnoosh and Thrampoulidis, Christos},
	booktitle = {Advances in Neural Information Processing Systems},
	pages = {9252--9262},
	title = {Linear stochastic bandits under safety constraints},
	year = {2019}}

@article{tropp2015introduction,
	author = {Tropp, Joel A},
	journal = {Foundations and Trends{\textregistered} in Machine Learning},
	number = {1-2},
	pages = {1--230},
	publisher = {Now Publishers Inc. Hanover, MA, USA},
	title = {An Introduction to Matrix Concentration Inequalities},
	volume = {8},
	year = {2015}}

@techreport{tropp2011user,
	author = {Tropp, Joel A},
	institution = {CALIFORNIA INST OF TECH PASADENA},
	title = {User-friendly tail bounds for matrix martingales},
	year = {2011}}

@article{robins1994,
	abstract = {In applied problems it is common to specify a model for the conditional mean of a response given a set of regressors. A subset of the regressors may be missing for some study subjects either by design or happenstance. In this article we propose a new class of semiparametric estimators, based on inverse probability weighted estimating equations, that are consistent for parameter vector ?0 of the conditional mean model when the data are missing at random in the sense of Rubin and the missingness probabilities are either known or can be parametrically modeled. We show that the asymptotic variance of the optimal estimator in our class attains the semiparametric variance bound for the model by first showing that our estimation problem is a special case of the general problem of parameter estimation in an arbitrary semiparametric model in which the data are missing at random and the probability of observing complete data is bounded away from 0, and then deriving a representation for the efficient score, the semiparametric variance bound, and the influence function of any regular, asymptotically linear estimator in this more general estimation problem. Because the optimal estimator depends on the unknown probability law generating the data, we propose locally and globally adaptive semiparametric efficient estimators. We compare estimators in our class with previously proposed estimators. We show that each previous estimator is asymptotically equivalent to some, usually inefficient, estimator in our class. This equivalence is a consequence of a proposition stating that every regular asymptotic linear estimator of ?0 is asymptotically equivalent to some estimator in our class. We compare various estimators in a small simulation study and offer some practical recommendations.},
	author = {James M. Robins and Andrea Rotnitzky and Lue Ping Zhao},
	issn = {01621459},
	journal = {Journal of the American Statistical Association},
	number = {427},
	pages = {846--866},
	publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
	title = {Estimation of Regression Coefficients When Some Regressors Are Not Always Observed},
	volume = {89},
	year = {1994}}

@article{bang2005doubly,
	author = {Bang, Heejung and Robins, James M},
	journal = {Biometrics},
	number = {4},
	pages = {962--973},
	publisher = {Wiley Online Library},
	title = {Doubly robust estimation in missing data and causal inference models},
	volume = {61},
	year = {2005}}

@inproceedings{chu2011contextual,
	author = {Chu, Wei and Li, Lihong and Reyzin, Lev and Schapire, Robert},
	booktitle = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics}, 
	pages = {208--214},
	title = {Contextual bandits with linear payoff functions},
	year = {2011}}

@article{azuma1967weighted,
	author = {Azuma, Kazuoki},
	journal = {Tohoku Mathematical Journal, Second Series},
	number = {3},
	pages = {357--367},
	publisher = {Mathematical Institute, Tohoku University},
	title = {Weighted sums of certain dependent random variables},
	volume = {19},
	year = {1967}}

@incollection{chapelle2011,
	author = {Olivier Chapelle and Li, Lihong},
	booktitle = {Advances in Neural Information Processing Systems 24},
	editor = {J. Shawe-Taylor and R. S. Zemel and P. L. Bartlett and F. Pereira and K. Q. Weinberger},
	pages = {2249--2257},
	publisher = {Curran Associates, Inc.},
	title = {An Empirical Evaluation of Thompson Sampling},
	year = {2011}}

@book{pena2008self,
	author = {Pe{\~n}a, Victor H and Lai, Tze Leung and Shao, Qi-Man},
	publisher = {Springer Science \& Business Media},
	title = {Self-normalized processes: Limit theory and Statistical Applications},
	year = {2008}}

@inproceedings{abe1999associative,
	author = {Abe, Naoki and Long, Philip M},
	booktitle = {ICML},
	title = {Associative Reinforcement Learning using Linear Probabilistic Concepts},
	year = {1999}}

@article{lai1985asymptotically,
	author = {Lai, Tze Leung and Robbins, Herbert},
	journal = {Advances in applied mathematics},
	number = {1},
	pages = {4--22},
	publisher = {Academic Press},
	title = {Asymptotically efficient adaptive allocation rules},
	volume = {6},
	year = {1985}}

@inproceedings{li2010contextual,
	author = {Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E},
	booktitle = {Proceedings of the 19th international conference on World wide web},
	pages = {661--670},
	title = {A contextual-bandit approach to personalized news article recommendation},
	year = {2010}}

@inproceedings{oh2021sparsity,
	author = {Oh, Min-hwan and Iyengar, Garud and Zeevi, Assaf},
	booktitle = {International Conference on Machine Learning},
	organization = {PMLR},
	pages = {8271--8280},
	title = {Sparsity-agnostic lasso bandit},
	year = {2021}}

@article{agrawal2016linear,
  title={Linear contextual bandits with knapsacks},
  author={Agrawal, Shipra and Devanur, Nikhil},
  journal={Advances in Neural Information Processing Systems},
  volume={29},
  year={2016}
}

@article{badanidiyuru2018bandits,
  title={Bandits with knapsacks},
  author={Badanidiyuru, Ashwinkumar and Kleinberg, Robert and Slivkins, Aleksandrs},
  journal={Journal of the ACM (JACM)},
  volume={65},
  number={3},
  pages={1--55},
  year={2018},
  publisher={ACM New York, NY, USA}
}