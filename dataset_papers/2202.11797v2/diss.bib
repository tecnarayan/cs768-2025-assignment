% Introduction

@article{vinyals2019grandmaster,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{possati2020algorithmic,
  title={Algorithmic unconscious: Why psychoanalysis helps in understanding AI},
  author={Possati, Luca M},
  journal={Palgrave Communications},
  volume={6},
  number={1},
  pages={1--13},
  year={2020},
  publisher={Palgrave}
}

@article{woolgar1985not,
  title={Why not a sociology of machines? The case of sociology and artificial intelligence},
  author={Woolgar, Steve},
  journal={Sociology},
  volume={19},
  number={4},
  pages={557--572},
  year={1985},
  publisher={British Sociological Association}
}
@incollection{potter2007can,
  title={What can AI get from neuroscience?},
  author={Potter, Steve M},
  booktitle={50 years of artificial intelligence},
  pages={174--185},
  year={2007},
  publisher={Springer}
}

% Supernormal stimuli
@book{barrett2010supernormal,
  title={Supernormal stimuli: How primal urges overran their evolutionary purpose},
  author={Barrett, Deirdre},
  year={2010},
  publisher={WW Norton \& Company}
}

% Followup
@article{izza2021efficient,
  title={Efficient Explanations With Relevant Sets},
  author={Izza, Yacine and Ignatiev, Alexey and Narodytska, Nina and Cooper, Martin C and Marques-Silva, Joao},
  journal={arXiv preprint arXiv:2106.00546},
  year={2021}
}

% Hierarchical Shap
@article{teneggi2021fast,
  title={Fast Hierarchical Games for Image Explanations},
  author={Teneggi, Jacopo and Luster, Alexandre and Sulam, Jeremias},
  journal={arXiv preprint arXiv:2104.06164},
  year={2021}
}

% Tricks of the Trade
@book{montavon2012neural,
  title={Neural networks: tricks of the trade},
  author={Montavon, Gr{\'e}goire and Orr, Genevi{\`e}ve and M{\"u}ller, Klaus-Robert},
  volume={7700},
  year={2012},
  publisher={springer}
}

%Saliency
@article{tuckey2019saliency,
  title={Saliency Maps Generation for Automatic Text Summarization},
  author={Tuckey, David and Broda, Krysia and Russo, Alessandra},
  journal={arXiv preprint arXiv:1907.05664},
  year={2019}
}
% Criticism
@incollection{kindermans2019reliability,
  title={The (un) reliability of saliency methods},
  author={Kindermans, Pieter-Jan and Hooker, Sara and Adebayo, Julius and Alber, Maximilian and Sch{\"u}tt, Kristof T and D{\"a}hne, Sven and Erhan, Dumitru and Kim, Been},
  booktitle={Explainable AI: Interpreting, Explaining and Visualizing Deep Learning},
  pages={267--280},
  year={2019},
  publisher={Springer}
}

%OG Shapley
@book{shapley201617,
  title={17. A value for n-person games},
  author={Shapley, Lloyd S},
  year={2016},
  publisher={Princeton University Press}
}
%More about LRP
@article{montavon2019layer,
  title={Layer-wise relevance propagation: an overview},
  author={Montavon, Gr{\'e}goire and Binder, Alexander and Lapuschkin, Sebastian and Samek, Wojciech and M{\"u}ller, Klaus-Robert},
  journal={Explainable AI: interpreting, explaining and visualizing deep learning},
  pages={193--209},
  year={2019},
  publisher={Springer}
}

% EU regulations
@article{goodman2017european,
  title={European Union regulations on algorithmic decision-making and a “right to explanation”},
  author={Goodman, Bryce and Flaxman, Seth},
  journal={AI magazine},
  volume={38},
  number={3},
  pages={50--57},
  year={2017}
}

%% Leute, die uns zitieren
@article{roscher2020explainable,
  title={Explainable machine learning for scientific insights and discoveries},
  author={Roscher, Ribana and Bohn, Bastian and Duarte, Marco F and Garcke, Jochen},
  journal={Ieee Access},
  volume={8},
  pages={42200--42216},
  year={2020},
  publisher={IEEE}
}

@article{macdonald2019rate,
  title={A rate-distortion framework for explaining neural network decisions},
  author={Macdonald, Jan and W{\"a}ldchen, Stephan and Hauch, Sascha and Kutyniok, Gitta},
  journal={arXiv preprint arXiv:1905.11092},
  year={2019}
}


@inproceedings{ribeiro2016should,
  title={" Why should i trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}

@article{rudin2019stop,
  title={Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
  author={Rudin, Cynthia},
  journal={Nature Machine Intelligence},
  volume={1},
  number={5},
  pages={206--215},
  year={2019},
  publisher={Nature Publishing Group}
}

@inproceedings{shrikumar2017learning,
  title={Learning important features through propagating activation differences},
  author={Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
  booktitle={International Conference on Machine Learning},
  pages={3145--3153},
  year={2017},
  organization={PMLR}
}

% Off-Distribution Problems

@article{frye2020shapley,
  title={Shapley explainability on the data manifold},
  author={Frye, Christopher and de Mijolla, Damien and Begley, Tom and Cowton, Laurence and Stanley, Megan and Feige, Ilya},
  journal={arXiv preprint arXiv:2006.01272},
  year={2020}
}
@inproceedings{anders2020fairwashing,
  title={Fairwashing explanations with off-manifold detergent},
  author={Anders, Christopher and Pasliev, Plamen and Dombrowski, Ann-Kathrin and M{\"u}ller, Klaus-Robert and Kessel, Pan},
  booktitle={International Conference on Machine Learning},
  pages={314--323},
  year={2020},
  organization={PMLR}
}


@article{aas2019explaining,
  title={Explaining individual predictions when features are dependent: More accurate approximations to Shapley values},
  author={Aas, Kjersti and Jullum, Martin and L{\o}land, Anders},
  journal={arXiv preprint arXiv:1903.10464},
  year={2019}
}

% Distribution-approximation

%% Pimps different methods, cool pictures
@inproceedings{agarwal2020explaining,
  title={Explaining image classifiers by removing input features using generative models},
  author={Agarwal, Chirag and Nguyen, Anh},
  booktitle={Proceedings of the Asian Conference on Computer Vision},
  year={2020}
}


@article{ivanov2018variational,
  title={Variational autoencoder with arbitrary conditioning},
  author={Ivanov, Oleg and Figurnov, Michael and Vetrov, Dmitry},
  journal={arXiv preprint arXiv:1806.02382},
  year={2018}
}

@article{yang2021generative,
  title={Generative Counterfactuals for Neural Networks via Attribute-Informed Perturbation},
  author={Yang, Fan and Liu, Ninghao and Du, Mengnan and Hu, Xia},
  journal={ACM SIGKDD Explorations Newsletter},
  volume={23},
  number={1},
  pages={59--68},
  year={2021},
  publisher={ACM New York, NY, USA}
}


@article{o2020generative,
  title={Generative causal explanations of black-box classifiers},
  author={O'Shaughnessy, Matthew and Canal, Gregory and Connor, Marissa and Davenport, Mark and Rozell, Christopher},
  journal={arXiv preprint arXiv:2006.13913},
  year={2020}
}


%Self-Explaining:
@article{alvarez2018towards,
  title={Towards robust interpretability with self-explaining neural networks},
  author={Alvarez-Melis, David and Jaakkola, Tommi S},
  journal={arXiv preprint arXiv:1806.07538},
  year={2018}
}

% Bottleneck methods
@article{bang2019explaining,
  title={Explaining a black-box using deep variational information bottleneck approach},
  author={Bang, Seojin and Xie, Pengtao and Lee, Heewook and Wu, Wei and Xing, Eric},
  journal={arXiv preprint arXiv:1902.06918},
  year={2019}
}

@article{achille2018information,
  title={Information dropout: Learning optimal representations through noisy computation},
  author={Achille, Alessandro and Soatto, Stefano},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={40},
  number={12},
  pages={2897--2905},
  year={2018},
  publisher={IEEE}
}


% Overviews:
@article{arrieta2020explainable,
  title={Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI},
  author={Arrieta, Alejandro Barredo and D{\'\i}az-Rodr{\'\i}guez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and Garc{\'\i}a, Salvador and Gil-L{\'o}pez, Sergio and Molina, Daniel and Benjamins, Richard and others},
  journal={Information Fusion},
  volume={58},
  pages={82--115},
  year={2020},
  publisher={Elsevier}
}

@article{adadi2018peeking,
  title={Peeking inside the black-box: a survey on explainable artificial intelligence (XAI)},
  author={Adadi, Amina and Berrada, Mohammed},
  journal={IEEE access},
  volume={6},
  pages={52138--52160},
  year={2018},
  publisher={IEEE}
}
% Manipulation of counterfactuals
@article{slack2021counterfactual,
  title={Counterfactual Explanations Can Be Manipulated},
  author={Slack, Dylan and Hilgard, Sophie and Lakkaraju, Himabindu and Singh, Sameer},
  journal={arXiv preprint arXiv:2106.02666},
  year={2021}
}
@inproceedings{dimanov2020you,
  title={You Shouldn't Trust Me: Learning Models Which Conceal Unfairness From Multiple Explanation Methods.},
  author={Dimanov, Botty and Bhatt, Umang and Jamnik, Mateja and Weller, Adrian},
  booktitle={SafeAI@ AAAI},
  year={2020}
}
@inproceedings{slack2020fooling,
  title={Fooling lime and shap: Adversarial attacks on post hoc explanation methods},
  author={Slack, Dylan and Hilgard, Sophie and Jia, Emily and Singh, Sameer and Lakkaraju, Himabindu},
  booktitle={Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
  pages={180--186},
  year={2020}
}

@article{zhang2021survey,
  title={A survey on neural network interpretability},
  author={Zhang, Yu and Ti{\v{n}}o, Peter and Leonardis, Ale{\v{s}} and Tang, Ke},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence},
  year={2021},
  publisher={IEEE}
}


@inproceedings{lundberg2017unified,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  booktitle={Proceedings of the 31st international conference on neural information processing systems},
  pages={4768--4777},
  year={2017}
}