
@preamble{ "\newcommand{\noopsort}[1]{} "
	# "\newcommand{\printfirst}[2]{#1} "
	# "\newcommand{\singleletter}[1]{#1} "
	# "\newcommand{\switchargs}[2]{#2#1} " }

@string{mprog   = "Mathematical Programming"}
@string{mprogb   = "Mathematical Programming, Series B"}
@string{mprogstudy   = "Mathematical Programming Study"}
@string{siopt   = "SIAM Journal on Optimization"}
@string{coa   = "Computational Optimization and Applications"}
@string{orl   = "Operations Research Letters"}
@string{oms   = "Optimization Methods and Software"}

@article{bhandari2020note,
  title={A note on the linear convergence of policy gradient methods},
  author={Bhandari, Jalaj and Russo, Daniel},
  journal={arXiv preprint arXiv:2007.11120},
  year={2020}
}

@inproceedings{khodadadian2021finite,
  title={Finite-sample analysis of off-policy natural actor-critic algorithm},
  author={Khodadadian, Sajad and Chen, Zaiwei and Maguluri, Siva Theja},
  booktitle={International Conference on Machine Learning},
  pages={5420--5431},
  year={2021},
  organization={PMLR}
}

@book{FacPang03,
 author = "F. Facchinei and J. Pang",
 title = "Finite-Dimensional Variational Inequalities and Complementarity Problems, Volumes I and II",
 series = "Comprehensive Study in Mathematics",
 year = "2003",
 publisher = "Springer-Verlag",
 address = "New York"
 }
 @article{zhang2021finite,
  title={Finite Sample Analysis of Average-Reward TD Learning and $ Q $-Learning},
  author={Zhang, Sheng and Zhang, Zhe and Maguluri, Siva Theja},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={1230--1242},
  year={2021}
}

 @article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

 @article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@misc{1606.01540,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@article{sezenerobtaining,
  title={Obtaining Reward Functions of Rats Using Inverse Reinforcement Learning},
  booktitle={Turkish Autonomous Robots Conference},
  author={Sezener, Can Eren and Uchibe, Eiji and Doya, Kenji},
  Year = {2014},
}

@article{borkar1997actor,
  title={The actor-critic algorithm as multi-time-scale stochastic approximation},
  author={Borkar, Vivek S and Konda, Vijaymohan R},
  journal={Sadhana},
  volume={22},
  pages={525--543},
  year={1997},
  publisher={Springer}
}

@article{yamaguchi2018identification,
  title={Identification of animal behavioral strategies by inverse reinforcement learning},
  author={Yamaguchi, Shoichiro and Naoki, Honda and Ikeda, Muneki and Tsukada, Yuki and Nakano, Shunji and Mori, Ikue and Ishii, Shin},
  journal={PLoS computational biology},
  volume={14},
  number={5},
  pages={e1006122},
  year={2018},
  publisher={Public Library of Science San Francisco, CA USA}
}

@inproceedings{pinsler2018inverse,
  title={Inverse reinforcement learning of bird flocking behavior},
  author={Pinsler, Robert and Maag, Max and Arenz, Oleg and Neumann, Gerhard},
  booktitle={ICRA Swarms Workshop},
  year={2018}
}


@article{hirakawa2018can,
  title={Can AI predict animal movements? Filling gaps in animal trajectories using inverse reinforcement learning},
  author={Hirakawa, Tsubasa and Yamashita, Takayoshi and Tamaki, Toru and Fujiyoshi, Hironobu and Umezu, Yuta and Takeuchi, Ichiro and Matsumoto, Sakiko and Yoda, Ken},
  journal={Ecosphere},
  volume={9},
  number={10},
  pages={e02447},
  year={2018},
  publisher={Wiley Online Library}
}
@article{beck2003mirror,
  title={Mirror descent and nonlinear projected subgradient methods for convex optimization},
  author={Beck, Amir and Teboulle, Marc},
  journal={Operations Research Letters},
  volume={31},
  number={3},
  pages={167--175},
  year={2003},
  publisher={Elsevier}
}

@article{nemirovskij1983problem,
  title={Problem complexity and method efficiency in optimization},
  author={Nemirovskij, Arkadij Semenovi{\v{c}} and Yudin, David Borisovich},
  year={1983},
  publisher={Wiley-Interscience}
}

@article{GGT_20a,
	title={Simple and optimal methods for stochastic variational inequalities, {I}: operator extrapolation},
	author={Kotsalis, Georgios and Lan, Guanghui and Li, Tianjiao},
	journal={SIAM Journal on Optimization},
	volume={32},
	number={3},
	pages={2041--2073},
	year={2022},
	publisher={SIAM}
}

@article{khamaru2020temporal,
  title={Is temporal difference learning optimal? an instance-dependent analysis},
  author={Khamaru, Koulik and Pananjady, Ashwin and Ruan, Feng and Wainwright, Martin J and Jordan, Michael I},
  journal={SIAM Journal on Mathematics of Data Science},
  volume={3},
  number={4},
  pages={1013--1040},
  year={2021},
  publisher={SIAM}
}

@article{khamaru2020temporal_arxiv,
	title={Is temporal difference learning optimal? An instance-dependent analysis},
	author={Khamaru, Koulik and Pananjady, Ashwin and Ruan, Feng and Wainwright, Martin J and Jordan, Michael I},
	journal={arXiv preprint arXiv:2003.07337},
	year={2020}
}

@article{mou2020optimal,
	title={Optimal oracle inequalities for solving projected fixed-point equations},
	author={Mou, Wenlong and Pananjady, Ashwin and Wainwright, Martin J},
	journal={arXiv preprint arXiv:2012.05299},
	year={2020}
}

@article{kotsalis2020simple,
  title={Simple and Optimal Methods for Stochastic Variational Inequalities, {II}: Markovian Noise and Policy Evaluation in Reinforcement Learning},
  author={Kotsalis, Georgios and Lan, Guanghui and Li, Tianjiao},
  journal={SIAM Journal on Optimization},
  volume={32},
  number={2},
  pages={1120--1155},
  year={2022},
  publisher={SIAM}
}


@article{sutton1988learning,
  title={Learning to predict by the methods of temporal differences},
  author={Sutton, Richard S},
  journal={Machine learning},
  volume={3},
  number={1},
  pages={9--44},
  year={1988},
  publisher={Springer}
}

@article{tsitsiklis_vanroy_97,
  title={An analysis of temporal-difference learning with function approximation},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  journal={IEEE transactions on automatic control},
  volume={42},
  number={5},
  pages={674--690},
  year={1997},
  publisher={IEEE}
}


@inproceedings{sutton2009fast,
  title={Fast gradient-descent methods for temporal-difference learning with linear function approximation},
  author={Sutton, Richard S and Maei, Hamid Reza and Precup, Doina and Bhatnagar, Shalabh and Silver, David and Szepesv{\'a}ri, Csaba and Wiewiora, Eric},
  booktitle={International Conference on Machine Learning},
  pages={993--1000},
  year={2009}
}

@inproceedings{lakshminarayanan2018linear,
  title={Linear stochastic approximation: {H}ow far does constant step-size and iterate averaging go?},
  author={Lakshminarayanan, Chandrashekar and Szepesv{\'a}ri, Csaba},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1347--1355},
  year={2018},
  organization={PMLR}
}


@inproceedings{russo_18,
  title={A finite time analysis of temporal difference learning with linear function approximation},
  author={Bhandari, Jalaj and Russo, Daniel and Singal, Raghav},
  booktitle={Conference on learning theory},
  pages={1691--1692},
  year={2018},
  organization={PMLR}
}

@article{hsu2019mixing,
	title={Mixing time estimation in reversible {M}arkov chains from a single sample path},
	author={Hsu, Daniel and Kontorovich, Aryeh and Levin, David A and Peres, Yuval and Szepesv{\'a}ri, Csaba and Wolfer, Geoffrey},
	journal={The Annals of Applied Probability},
	volume={29},
	number={4},
	pages={2439--2480},
	year={2019},
	publisher={Institute of Mathematical Statistics}
}

@inproceedings{wolfer2019estimating,
	title={Estimating the mixing time of ergodic {M}arkov chains},
	author={Wolfer, Geoffrey and Kontorovich, Aryeh},
	booktitle={Conference on Learning Theory},
	pages={3120--3159},
	year={2019},
	organization={PMLR}
}


@article{dann2014policy,
	title={Policy evaluation with temporal differences: A survey and comparison},
	author={Dann, Christoph and Neumann, Gerhard and Peters, Jan},
	journal={Journal of Machine Learning Research},
	volume={15},
	pages={809--883},
	year={2014},
	publisher={Massachusetts Institute of Technology Press (MIT Press)/Microtome Publishing}
}

@book{borkar2009stochastic,
	title={Stochastic approximation: A dynamical systems viewpoint},
	author={Borkar, Vivek S},
	volume={48},
	year={2009},
	publisher={Springer}
}

@article{borkar2000ode,
	title={The {ODE} method for convergence of stochastic approximation and reinforcement learning},
	author={Borkar, Vivek S and Meyn, Sean P},
	journal={SIAM Journal on Control and Optimization},
	volume={38},
	number={2},
	pages={447--469},
	year={2000},
	publisher={SIAM}
}

@article{polyak1990new,
	title={New stochastic approximation type procedures},
	author={Polyak, Boris T},
	journal={Automat. i Telemekh},
	volume={7},
	number={98-107},
	pages={2},
	year={1990}
}

@article{ruppert1988efficient,
	title={Efficient estimators from a slowly convergent Robbins-Monro procedure},
	author={Ruppert, David},
	journal={School of Oper. Res. and Ind. Eng., Cornell Univ., Ithaca, NY, Tech. Rep},
	volume={781},
	year={1988}
}

@article{polyak1992acceleration,
	title={Acceleration of stochastic approximation by averaging},
	author={Polyak, Boris T and Juditsky, Anatoli B},
	journal={SIAM journal on control and optimization},
	volume={30},
	number={4},
	pages={838--855},
	year={1992},
	publisher={SIAM}
}

@article{tadic2004almost,
	title={On the almost sure rate of convergence of linear stochastic approximation algorithms},
	author={Tadic, Vladislav B},
	journal={IEEE Transactions on Information Theory},
	volume={50},
	number={2},
	pages={401--409},
	year={2004},
	publisher={IEEE}
}

@inproceedings{korda2015td,
	title={On {TD} (0) with function approximation: Concentration bounds and a centered variant with exponential convergence},
	author={Korda, Nathaniel and La, Prashanth},
	booktitle={International conference on machine learning},
	pages={626--634},
	year={2015},
	organization={PMLR}
}

@inproceedings{wai2019variance,
	title={Variance reduced policy evaluation with smooth function approximation},
	author={Wai, Hoi To and Hong, Mingyi and Yang, Zhuoran and Wang, Zhaoran and Tang, Kexin},
	booktitle={Advances in Neural Information Processing Systems},
	volume={32},
	pages={5784--5795},
	year={2019}
}


@article{xu2020reanalysis,
  title={Reanalysis of variance reduced temporal difference learning},
  author={Xu, Tengyu and Wang, Zhe and Zhou, Yi and Liang, Yingbin},
  journal={arXiv preprint arXiv:2001.01898},
  year={2020}
}

@article{nemirovsky1992information,
	title={Information-based complexity of linear operator equations},
	author={Nemirovsky, Arkadi S},
	journal={Journal of Complexity},
	volume={8},
	number={2},
	pages={153--175},
	year={1992},
	publisher={Academic Press}
}

@article{nemirovsky1991optimality,
	title={On optimality of {K}rylov's information when solving linear operator equations},
	author={Nemirovsky, Arkadi S},
	journal={Journal of Complexity},
	volume={7},
	number={2},
	pages={121--130},
	year={1991},
	publisher={Academic Press}
}

@incollection{hajek1972local,
	title={Local asymptotic minimax and admissibility in estimation},
	author={H{\'a}jek, Jaroslav},
	booktitle={Proceedings of the Sixth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Theory of Statistics},
	pages={175--194},
	year={1972},
	publisher={University of California Press}
}


@incollection{le1972limits,
	title={Limits of experiments},
	author={Le Cam, L},
	booktitle={Proceedings of the Sixth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Theory of Statistics},
	pages={245--282},
	year={1972},
	publisher={University of California Press}
}

@book{le2000asymptotics,
	title={Asymptotics in statistics: Some basic concepts},
	author={Le Cam, Lucien and Yang, Grace Lo},
	year={2000},
	publisher={Springer Science \& Business Media}
}

@inproceedings{johnson2013accelerating,
	title={Accelerating stochastic gradient descent using predictive variance reduction},
	author={Johnson, Rie and Zhang, Tong},
	booktitle={Advances in Neural Information Processing Systems},
	volume={26},
	pages={315--323},
	year={2013}
}


@article{kaelbling1996reinforcement,
  title={Reinforcement learning: A survey},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W},
  journal={Journal of artificial intelligence research},
  volume={4},
  pages={237--285},
  year={1996}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{singh2021reinforcement,
  title={Reinforcement learning in robotic applications: A comprehensive survey},
  author={Singh, Bharat and Kumar, Rajesh and Singh, Vinay Pratap},
  journal={Artificial Intelligence Review},
  pages={1--46},
  year={2021},
  publisher={Springer}
}

@article{ouyang2021lower,
  title={Lower complexity bounds of first-order methods for convex-concave bilinear saddle-point problems},
  author={Ouyang, Yuyuan and Xu, Yangyang},
  journal={Mathematical Programming},
  volume={185},
  number={1},
  pages={1--35},
  year={2021},
  publisher={Springer}
}

@article{schmidt2017minimizing,
  title={Minimizing finite sums with the stochastic average gradient},
  author={Schmidt, Mark and Le Roux, Nicolas and Bach, Francis},
  journal={Mathematical Programming},
  volume={162},
  number={1-2},
  pages={83--112},
  year={2017},
  publisher={Springer}
}

@article{xiao2014proximal,
  title={A proximal stochastic gradient method with progressive variance reduction},
  author={Xiao, Lin and Zhang, Tong},
  journal={SIAM Journal on Optimization},
  volume={24},
  number={4},
  pages={2057--2075},
  year={2014},
  publisher={SIAM}
}

@inproceedings{defazio2014saga,
  title={SAGA: A fast incremental gradient method with support for non-strongly convex composite objectives},
  author={Defazio, Aaron and Bach, Francis and Lacoste-Julien, Simon},
  booktitle={Advances in neural information processing systems},
  pages={1646--1654},
  year={2014}
}

@article{blatt2007convergent,
  title={A convergent incremental gradient method with a constant step size},
  author={Blatt, Doron and Hero, Alfred O and Gauchman, Hillel},
  journal={SIAM Journal on Optimization},
  volume={18},
  number={1},
  pages={29--51},
  year={2007},
  publisher={SIAM}
}

@article{duan2021optimal,
  title={Optimal policy evaluation using kernel-based temporal difference methods},
  author={Duan, Yaqi and Wang, Mengdi and Wainwright, Martin J},
  journal={arXiv preprint arXiv:2109.12002},
  year={2021}
}

@book{nesterov2003introductory,
  title={Introductory lectures on convex optimization: A basic course},
  author={Nesterov, Yurii},
  volume={87},
  year={2003},
  publisher={Springer Science \& Business Media}
}

@incollection{davis2016convergence,
	title={Convergence rate analysis of several splitting schemes},
	author={Davis, Damek and Yin, Wotao},
	booktitle={Splitting methods in communication, imaging, science, and engineering},
	pages={115--163},
	year={2016},
	publisher={Springer}
}

@book{abramowitz+stegun,
	added-at = {2008-06-25T06:25:58.000+0200},
	address = {New York},
	author = {Abramowitz, Milton and Stegun, Irene A.},
	biburl = {https://www.bibsonomy.org/bibtex/223ec744709b3a776a1af0a3fd65cd09f/a_olympia},
	description = {BibTeX - Wikipedia, the free encyclopedia},
	edition = {ninth Dover printing, tenth GPO printing},
	interhash = {d4914a420f489f7c5129ed01ec3cf80c},
	intrahash = {23ec744709b3a776a1af0a3fd65cd09f},
	keywords = {Handbook},
	publisher = {Dover},
	timestamp = {2008-06-25T06:25:58.000+0200},
	title = {Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables},
	year = 1964
}

@article{hoeffding1956distribution,
	title={On the distribution of the number of successes in independent trials},
	author={Hoeffding, Wassily},
	journal={The Annals of Mathematical Statistics},
	pages={713--721},
	year={1956},
	publisher={JSTOR}
}

@book{feller1966introduction,
	title={An Introduction to Probability Theory and Its Application: Vol. 1-2},
	author={Feller, William},
	year={1966}
}

@book{bauschke2011convex,
	title={Convex analysis and monotone operator theory in Hilbert spaces},
	author={Bauschke, Heinz H and Combettes, Patrick L and others},
	volume={408},
	year={2011},
	publisher={Springer}
}

@article{cominetti2014rate,
	title={On the rate of convergence of Krasnosel’skii-Mann iterations and their connection with sums of Bernoullis},
	author={Cominetti, Roberto and Soto, Jos{\'e} A and Vaisman, Jos{\'e}},
	journal={Israel Journal of Mathematics},
	volume={199},
	number={2},
	pages={757--772},
	year={2014},
	publisher={Springer}
}

@article{baillion1996rate,
	title={The Rate of Asymptotic Regularity Is O (1/  n)},
	author={Baillion, J and Bruck, RONALD E},
	journal={Lecture Notes in Pure and Applied Mathematics},
	pages={51--82},
	year={1996},
	publisher={MARCEL DEKKER AG}
}

@misc{bravo2021universal,
	title={Universal bounds for fixed point iterations via optimal transport metrics}, 
	author={Mario Bravo and Thierry Champion and Roberto Cominetti},
	year={2021},
	eprint={2108.00300},
	archivePrefix={arXiv},
	primaryClass={math.OC}
}

@article{alber2012stochastic,
	title={Stochastic approximation method for fixed point problems},
	author={Alber, Ya I and Chidume, CE and Li, Jinlu},
	journal={Applied Mathematics},
	volume={3},
	number={12},
	pages={2123--2132},
	year={2012},
	publisher={Scientific Research Publishing}
}

@article{zhang2021policy,
	title={On-Policy Deep Reinforcement Learning for the Average-Reward Criterion},
	author={Zhang, Yiming and Ross, Keith W},
	journal={arXiv preprint arXiv:2106.07329},
	year={2021}
}
@article{dewanto2020average,
	title={Average-reward model-free reinforcement learning: a systematic review and literature mapping},
	author={Dewanto, Vektor and Dunn, George and Eshragh, Ali and Gallagher, Marcus and Roosta, Fred},
	journal={arXiv preprint arXiv:2010.08920},
	year={2020}
}

@book{sutton2018reinforcement,
	title={Reinforcement learning: An introduction},
	author={Sutton, Richard S and Barto, Andrew G},
	year={2018},
	publisher={MIT press}
}

@article{blackwell1962discrete,
	title={Discrete dynamic programming},
	author={Blackwell, David},
	journal={The Annals of Mathematical Statistics},
	pages={719--726},
	year={1962},
	publisher={JSTOR}
}

@article{ma2021average,
	title={Average-Reward Reinforcement Learning with Trust Region Methods},
	author={Ma, Xiaoteng and Tang, Xiaohang and Xia, Li and Yang, Jun and Zhao, Qianchuan},
	journal={arXiv preprint arXiv:2106.03442},
	year={2021}
}

@article{cao2008stochastic,
	title={Stochastic learning and optimization-a sensitivity-based approach},
	author={Cao, Xi-Ren},
	journal={IFAC Proceedings Volumes},
	volume={41},
	number={2},
	pages={3480--3492},
	year={2008},
	publisher={Elsevier}
}

@article{dewanto2020average,
	title={Average-reward model-free reinforcement learning: a systematic review and literature mapping},
	author={Dewanto, Vektor and Dunn, George and Eshragh, Ali and Gallagher, Marcus and Roosta, Fred},
	journal={arXiv preprint arXiv:2010.08920},
	year={2020}
}

@article{mahadevan1996average,
	title={Average reward reinforcement learning: Foundations, algorithms, and empirical results},
	author={Mahadevan, Sridhar},
	journal={Machine learning},
	volume={22},
	number={1},
	pages={159--195},
	year={1996},
	publisher={Springer}
}

@article{abounadi2001learning,
	title={Learning algorithms for {M}arkov decision processes with average cost},
	author={Abounadi, Jinane and Bertsekas, Dimitri P and Borkar, Vivek S},
	journal={SIAM Journal on Control and Optimization},
	volume={40},
	number={3},
	pages={681--698},
	year={2001},
	publisher={SIAM}
}

@inproceedings{kakade2001optimizing,
	title={Optimizing average reward using discounted rewards},
	author={Kakade, Sham},
	booktitle={International Conference on Computational Learning Theory},
	pages={605--615},
	year={2001},
	organization={Springer}
}

@inproceedings{wei2021learning,
	title={Learning infinite-horizon average-reward {MDPs} with linear function approximation},
	author={Wei, Chen-Yu and Jahromi, Mehdi Jafarnia and Luo, Haipeng and Jain, Rahul},
	booktitle={International Conference on Artificial Intelligence and Statistics},
	pages={3007--3015},
	year={2021},
	organization={PMLR}
}


@inproceedings{schulman2015trust,
	title={Trust region policy optimization},
	author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
	booktitle={International conference on machine learning},
	pages={1889--1897},
	year={2015},
	organization={PMLR}
}

@INPROCEEDINGS{Kakade02approximatelyoptimal,
	author = {Sham Kakade and John Langford},
	title = {Approximately Optimal Approximate Reinforcement Learning},
	booktitle = {IN PROC. 19TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING},
	year = {2002},
	pages = {267--274},
	publisher = {}
}

@article{lan2022policy,
  title={Policy optimization over general state and action spaces},
  author={Lan, Guanghui},
  journal={arXiv preprint arXiv:2211.16715},
  year={2022}
}

@inproceedings{mahadevan1996average,
	title={An average-reward reinforcement learning algorithm for computing bias-optimal policies},
	author={Mahadevan, Sridhar},
	booktitle={AAAI/IAAI, Vol. 1},
	pages={875--880},
	year={1996},
	organization={Citeseer}
}

@article{li2021accelerated,
  title={Accelerated and instance-optimal policy evaluation with linear function approximation},
  author={Li, Tianjiao and Lan, Guanghui and Pananjady, Ashwin},
  journal={arXiv preprint arXiv:2112.13109},
  year={2021}
}

@article{kotsalis2020simple2,
  title={Simple and Optimal Methods for Stochastic Variational Inequalities, {II}: Markovian Noise and Policy Evaluation in Reinforcement Learning},
  author={Kotsalis, Georgios and Lan, Guanghui and Li, Tianjiao},
  journal={SIAM Journal on Optimization},
  volume={32},
  number={2},
  pages={1120--1155},
  year={2022},
  publisher={SIAM}
}

@article{li2022homotopic,
  title={Homotopic policy mirror descent: Policy convergence, implicit regularization, and improved sample complexity},
  author={Li, Yan and Zhao, Tuo and Lan, Guanghui},
  journal={arXiv preprint arXiv:2201.09457},
  year={2022}
}


@article{kotsalis2020simple1,
	title={Simple and optimal methods for stochastic variational inequalities, {I}: operator extrapolation},
	author={Kotsalis, Georgios and Lan, Guanghui and Li, Tianjiao},
	journal={SIAM Journal on Optimization},
	volume={32},
	number={3},
	pages={2041--2073},
	year={2022},
	publisher={SIAM}
}

@article{zhang2021finite,
  title={Finite Sample Analysis of Average-Reward {TD} Learning and {$ Q $}-Learning},
  author={Zhang, Sheng and Zhang, Zhe and Maguluri, Siva Theja},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{zhan2021policy,
  title={Policy mirror descent for regularized reinforcement learning: A generalized framework with linear convergence},
  author={Zhan, Wenhao and Cen, Shicong and Huang, Baihe and Chen, Yuxin and Lee, Jason D and Chi, Yuejie},
  journal={arXiv preprint arXiv:2105.11066},
  year={2021}
}

@book{lan2020first,
  title={First-order and stochastic optimization methods for machine learning},
  author={Lan, Guanghui},
  year={2020},
  publisher={Springer}
}

@book{puterman2014markov,
  title={{M}arkov decision processes: Discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@inproceedings{bertsekas1995neuro,
  title={Neuro-dynamic programming: an overview},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  booktitle={Proceedings of 1995 34th IEEE conference on decision and control},
  volume={1},
  pages={560--564},
  year={1995},
  organization={IEEE}
}

@inproceedings{jin2021towards,
  title={Towards tight bounds on the sample complexity of average-reward {MDPs}},
  author={Jin, Yujia and Sidford, Aaron},
  booktitle={International Conference on Machine Learning},
  pages={5055--5064},
  year={2021},
  organization={PMLR}
}

@article{montenegro2006mathematical,
  title={Mathematical aspects of mixing times in {M}arkov chains},
  author={Montenegro, Ravi and Tetali, Prasad and others},
  journal={Foundations and Trends in Theoretical Computer Science},
  volume={1},
  number={3},
  pages={237--354},
  year={2006},
  publisher={Now Publishers, Inc.}
}


@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{abbasi2019politex,
  title={Politex: Regret bounds for policy iteration using expert prediction},
  author={Abbasi-Yadkori, Yasin and Bartlett, Peter and Bhatia, Kush and Lazic, Nevena and Szepesvari, Csaba and Weisz, Gell{\'e}rt},
  booktitle={International Conference on Machine Learning},
  pages={3692--3702},
  year={2019},
  organization={PMLR}
}

@article{bertsekas1996temporal,
  title={Temporal differences-based policy iteration and applications in neuro-dynamic programming},
  author={Bertsekas, Dimitri P and Ioffe, Sergey},
  journal={Lab. for Info. and Decision Systems Report LIDS-P-2349, MIT, Cambridge, MA},
  volume={14},
  year={1996},
  publisher={Citeseer}
}

@article{brockman2016openai, 
  title={Openai gym}, 
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech}, 
  journal={arXiv preprint arXiv:1606.01540}, 
  year={2016} 
}

@article{stable-baselines3,
  author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},
  title   = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {268},
  pages   = {1-8}
}

@article{wang2017primal,
  title={Primal-Dual $\pi$ Learning: Sample Complexity and Sublinear Run Time for Ergodic {M}arkov Decision Problems},
  author={Wang, Mengdi},
  journal={arXiv preprint arXiv:1710.06100},
  year={2017}
}

@inproceedings{jin2020efficiently,
  title={Efficiently solving {MDPs} with stochastic mirror descent},
  author={Jin, Yujia and Sidford, Aaron},
  booktitle={International Conference on Machine Learning},
  pages={4890--4900},
  year={2020},
  organization={PMLR}
}

@article{kaelbling1996reinforcement,
  title={Reinforcement learning: A survey},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W},
  journal={Journal of artificial intelligence research},
  volume={4},
  pages={237--285},
  year={1996}
}



@inproceedings{lazic2021improved,
  title={Improved regret bound and experience replay in regularized policy iteration},
  author={Lazic, Nevena and Yin, Dong and Abbasi-Yadkori, Yasin and Szepesvari, Csaba},
  booktitle={International Conference on Machine Learning},
  pages={6032--6042},
  year={2021},
  organization={PMLR}
}


@article{wainwright2019variance,
  title={Variance-reduced {Q}-learning is minimax optimal},
  author={Wainwright, Martin J},
  journal={arXiv preprint arXiv:1906.04697},
  year={2019}
}

a

@article{chen2021finite,
  title={Finite-Sample Analysis of Off-Policy Natural Actor-Critic with Linear Function Approximation},
  author={Chen, Zaiwei and Khodadadian, Sajad and Maguluri, Siva Theja},
  journal={arXiv preprint arXiv:2105.12540},
  year={2021}
}

@inproceedings{cohen2016faster,
  title={Faster algorithms for computing the stationary distribution, simulating random walks, and more},
  author={Cohen, Michael B and Kelner, Jonathan and Peebles, John and Peng, Richard and Sidford, Aaron and Vladu, Adrian},
  booktitle={2016 IEEE 57th Annual Symposium on Foundations of Computer Science (FOCS)},
  pages={583--592},
  year={2016},
  organization={IEEE}
}

@article{tsitsiklis1999average,
  title={Average cost temporal-difference learning},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  journal={Automatica},
  volume={35},
  number={11},
  pages={1799--1808},
  year={1999},
  publisher={Elsevier}
}

@article{yu1994rates,
  title={Rates of convergence for empirical processes of stationary mixing sequences},
  author={Yu, Bin},
  journal={The Annals of Probability},
  pages={94--116},
  year={1994},
  publisher={JSTOR}
}

@article{mou2022optimal,
  title={Optimal variance-reduced stochastic approximation in Banach spaces},
  author={Mou, Wenlong and Khamaru, Koulik and Wainwright, Martin J and Bartlett, Peter L and Jordan, Michael I},
  journal={arXiv preprint arXiv:2201.08518},
  year={2022}
}

@article{bartlett2012regal,
  title={REGAL: A regularization based algorithm for reinforcement learning in weakly communicating {MDPs}},
  author={Bartlett, Peter L and Tewari, Ambuj},
  journal={arXiv preprint arXiv:1205.2661},
  year={2012}
}

@article{auer2008near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Auer, Peter and Jaksch, Thomas and Ortner, Ronald},
  journal={Advances in neural information processing systems},
  volume={21},
  year={2008}
}

@article{ouyang2017learning,
  title={Learning unknown {M}arkov decision processes: A thompson sampling approach},
  author={Ouyang, Yi and Gagrani, Mukul and Nayyar, Ashutosh and Jain, Rahul},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{brown1965iterative,
  title={On the iterative method of dynamic programming on a finite space discrete time {M}arkov process},
  author={Brown, Barry W},
  journal={The annals of mathematical statistics},
  pages={1279--1285},
  year={1965},
  publisher={JSTOR}
}

@article{howard1960dynamic,
  title={Dynamic programming and {M}arkov processes.},
  author={Howard, Ronald A},
  year={1960},
  publisher={John Wiley}
}

@inproceedings{zhang2021average,
  title={Average-reward off-policy policy evaluation with function approximation},
  author={Zhang, Shangtong and Wan, Yi and Sutton, Richard S and Whiteson, Shimon},
  booktitle={International Conference on Machine Learning},
  pages={12578--12588},
  year={2021},
  organization={PMLR}
}

@inproceedings{wan2021learning,
  title={Learning and planning in average-reward {M}arkov decision processes},
  author={Wan, Yi and Naik, Abhishek and Sutton, Richard S},
  booktitle={International Conference on Machine Learning},
  pages={10653--10662},
  year={2021},
  organization={PMLR}
}

@article{yu2009convergence,
  title={Convergence results for some temporal difference methods based on least squares},
  author={Yu, Huizhen and Bertsekas, Dimitri P},
  journal={IEEE Transactions on Automatic Control},
  volume={54},
  number={7},
  pages={1515--1531},
  year={2009},
  publisher={IEEE}
}



@article{barto1983neuronlike,
  title={Neuronlike adaptive elements that can solve difficult learning control problems},
  author={Barto, Andrew G and Sutton, Richard S and Anderson, Charles W},
  journal={IEEE transactions on systems, man, and cybernetics},
  number={5},
  pages={834--846},
  year={1983},
  publisher={IEEE}
}


@article{morimura2009generalized,
  title={A generalized natural actor-critic algorithm},
  author={Morimura, Tetsuro and Uchibe, Eiji and Yoshimoto, Junichiro and Doya, Kenji},
  journal={Advances in neural information processing systems},
  volume={22},
  year={2009}
}

@article{peters2008natural,
  title={Natural actor-critic},
  author={Peters, Jan and Schaal, Stefan},
  journal={Neurocomputing},
  volume={71},
  number={7-9},
  pages={1180--1190},
  year={2008},
  publisher={Elsevier}
}

@article{konda1999actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay and Tsitsiklis, John},
  journal={Advances in neural information processing systems},
  volume={12},
  year={1999}
}

@article{bhatnagar2009natural,
  title={Natural actor--critic algorithms},
  author={Bhatnagar, Shalabh and Sutton, Richard S and Ghavamzadeh, Mohammad and Lee, Mark},
  journal={Automatica},
  volume={45},
  number={11},
  pages={2471--2482},
  year={2009},
  publisher={Elsevier}
}

@book{borkar2009stochastic,
  title={Stochastic approximation: a dynamical systems viewpoint},
  author={Borkar, Vivek S},
  volume={48},
  year={2009},
  publisher={Springer}
}

@article{even2009online,
  title={Online {M}arkov decision processes},
  author={Even-Dar, Eyal and Kakade, Sham M and Mansour, Yishay},
  journal={Mathematics of Operations Research},
  volume={34},
  number={3},
  pages={726--736},
  year={2009},
  publisher={INFORMS}
}

@inproceedings{shani2020adaptive,
  title={Adaptive trust region policy optimization: Global convergence and faster rates for regularized {MDPs}},
  author={Shani, Lior and Efroni, Yonathan and Mannor, Shie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={5668--5675},
  year={2020}
}


@article{qiu2021finite,
  title={On finite-time convergence of actor-critic algorithm},
  author={Qiu, Shuang and Yang, Zhuoran and Ye, Jieping and Wang, Zhaoran},
  journal={IEEE Journal on Selected Areas in Information Theory},
  volume={2},
  number={2},
  pages={652--664},
  year={2021},
  publisher={IEEE}
}

@article{xu2020non,
  title={Non-asymptotic convergence analysis of two time-scale (natural) actor-critic algorithms},
  author={Xu, Tengyu and Wang, Zhe and Liang, Yingbin},
  journal={arXiv preprint arXiv:2005.03557},
  year={2020}
}

@article{xu2020improving,
  title={Improving sample complexity bounds for (natural) actor-critic algorithms},
  author={Xu, Tengyu and Wang, Zhe and Liang, Yingbin},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={4358--4369},
  year={2020}
}

@article{cen2021fast,
  title={Fast global convergence of natural policy gradient methods with entropy regularization},
  author={Cen, Shicong and Cheng, Chen and Chen, Yuxin and Wei, Yuting and Chi, Yuejie},
  journal={Operations Research},
  year={2021},
  publisher={INFORMS}
}

@article{agarwal2021theory,
  title={On the theory of policy gradient methods: Optimality, approximation, and distribution shift},
  author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={98},
  pages={1--76},
  year={2021},
  publisher={Microtome Publishing}
}

@article{degris2012off,
  title={Off-policy actor-critic},
  author={Degris, Thomas and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1205.4839},
  year={2012}
}

@article{li2020sample,
  title={Sample complexity of asynchronous {Q}-learning: Sharper analysis and variance reduction},
  author={Li, Gen and Wei, Yuting and Chi, Yuejie and Gu, Yuantao and Chen, Yuxin},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={7031--7043},
  year={2020}
}

@article{gosavi2004reinforcement,
  title={Reinforcement learning for long-run average cost},
  author={Gosavi, Abhijit},
  journal={European journal of operational research},
  volume={155},
  number={3},
  pages={654--674},
  year={2004},
  publisher={Elsevier}
}

@article{lan2022block,
  title={Block Policy Mirror Descent},
  author={Lan, Guanghui and Li, Yan and Zhao, Tuo},
  journal={arXiv preprint arXiv:2201.05756},
  year={2022}
}

@article{khodadadian2021linear,
  title={On the linear convergence of natural policy gradient algorithm},
  author={Khodadadian, Sajad and Jhunjhunwala, Prakirt Raj and Varma, Sushil Mahavir and Maguluri, Siva Theja},
  journal={arXiv preprint arXiv:2105.01424},
  year={2021}
}

@article{xiao2022convergence,
  title={On the Convergence Rates of Policy Gradient Methods},
  author={Xiao, Lin},
  journal={arXiv preprint arXiv:2201.07443},
  year={2022}
}

@article{dang2015convergence,
  title={On the convergence properties of non-euclidean extragradient methods for variational inequalities with generalized monotone operators},
  author={Dang, Cong D and Lan, Guanghui},
  journal={Computational Optimization and applications},
  volume={60},
  number={2},
  pages={277--310},
  year={2015},
  publisher={Springer}
}

@article{nian2020review,
  title={A review on reinforcement learning: Introduction and applications in industrial process control},
  author={Nian, Rui and Liu, Jinfeng and Huang, Biao},
  journal={Computers \& Chemical Engineering},
  volume={139},
  pages={106886},
  year={2020},
  publisher={Elsevier}
}

@article{xu2014reinforcement,
  title={Reinforcement learning algorithms with function approximation: Recent advances and applications},
  author={Xu, Xin and Zuo, Lei and Huang, Zhenhua},
  journal={Information Sciences},
  volume={261},
  pages={1--31},
  year={2014},
  publisher={Elsevier}
}

@inproceedings{bhandari2018finite,
  title={A finite time analysis of temporal difference learning with linear function approximation},
  author={Bhandari, Jalaj and Russo, Daniel and Singal, Raghav},
  booktitle={Conference on learning theory},
  pages={1691--1692},
  year={2018},
  organization={PMLR}
}


@inproceedings{ziebart2008maximum,
  title={Maximum entropy inverse reinforcement learning.},
  author={Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K and others},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2008}
}

@article{li2022stochastic,
  title={Stochastic first-order methods for average-reward Markov decision processes},
  author={Li, Tianjiao and Wu, Feiyang and Lan, Guanghui},
  journal={arXiv preprint arXiv:2205.05800},
  year={2022}
}

@article{lan2023policy,
  title={Policy mirror descent for reinforcement learning: Linear convergence, new sampling complexity, and generalized problem classes},
  author={Lan, Guanghui},
  journal={Mathematical programming},
  volume={198},
  number={1},
  pages={1059--1106},
  year={2023},
  publisher={Springer}
}

@inproceedings{ziebart2010modeling,
  title={Modeling interaction via the principle of maximum causal entropy},
  author={Ziebart, Brian D and Bagnell, J Andrew and Dey, Anind K},
  booktitle={ICML},
  year={2010}
}



@article{zeng2022maximum,
  title={Maximum-Likelihood Inverse Reinforcement Learning with Finite-Time Guarantees},
  author={Zeng, Siliang and Li, Chenliang and Garcia, Alfredo and Hong, Mingyi},
  journal={arXiv preprint arXiv:2210.01808},
  year={2022}
}
@inproceedings{todorov2012mujoco,
  title={MuJoCo: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE},
  doi={10.1109/IROS.2012.6386109}
}

@article{garg2021iq,
  title={IQ-Learn: Inverse soft-Q Learning for Imitation},
  author={Garg, Divyansh and Chakraborty, Shuvam and Cundy, Chris and Song, Jiaming and Ermon, Stefano},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={4028--4039},
  year={2021}
}

@inproceedings{ni2021f,
  title={f-irl: Inverse reinforcement learning via state marginal matching},
  author={Ni, Tianwei and Sikchi, Harshit and Wang, Yufei and Gupta, Tejus and Lee, Lisa and Eysenbach, Ben},
  booktitle={Conference on Robot Learning},
  pages={529--551},
  year={2021},
  organization={PMLR}
}


@article{haarnoja2018soft,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@book{meyn2012markov,
  title={Markov chains and stochastic stability},
  author={Meyn, Sean P and Tweedie, Richard L},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@article{pflug1990line,
  title={On-line optimization of simulated Markovian processes},
  author={Pflug, G Ch},
  journal={Mathematics of Operations Research},
  volume={15},
  number={3},
  pages={381--395},
  year={1990},
  publisher={INFORMS}
}

@book{bertsekas1996stochastic,
  title={Stochastic optimal control: the discrete-time case},
  author={Bertsekas, Dimitri and Shreve, Steven E},
  volume={5},
  year={1996},
  publisher={Athena Scientific}
}
@inproceedings{pflug2006derivatives,
  title={Derivatives of probability measures-concepts and applications to the optimization of stochastic systems},
  author={Pflug, Georg Ch},
  booktitle={Discrete Event Systems: Models and Applications: IIASA Conference Sopron, Hungary, August 3--7, 1987},
  pages={252--274},
  year={2006},
  organization={Springer}
}

@article{zhang2021convergence,
  title={On the convergence and sample efficiency of variance-reduced policy gradient method},
  author={Zhang, Junyu and Ni, Chengzhuo and Szepesvari, Csaba and Wang, Mengdi and others},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={2228--2240},
  year={2021}
}

@article{ho2016generative,
  title={Generative adversarial imitation learning},
  author={Ho, Jonathan and Ermon, Stefano},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}


@article{choi2012nonparametric,
  title={Nonparametric Bayesian inverse reinforcement learning for multiple reward functions},
  author={Choi, Jaedeug and Kim, Kee-Eung},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}

@article{choi2014hierarchical,
  title={Hierarchical bayesian inverse reinforcement learning},
  author={Choi, Jaedeug and Kim, Kee-Eung},
  journal={IEEE transactions on cybernetics},
  volume={45},
  number={4},
  pages={793--805},
  year={2014},
  publisher={IEEE}
}

@article{chan2021scalable,
  title={Scalable bayesian inverse reinforcement learning},
  author={Chan, Alex J and van der Schaar, Mihaela},
  journal={arXiv preprint arXiv:2102.06483},
  year={2021}
}

@article{schaal1999imitation,
  title={Is imitation learning the route to humanoid robots?},
  author={Schaal, Stefan},
  journal={Trends in cognitive sciences},
  volume={3},
  number={6},
  pages={233--242},
  year={1999},
  publisher={Elsevier}
}

@article{duan2017one,
  title={One-shot imitation learning},
  author={Duan, Yan and Andrychowicz, Marcin and Stadie, Bradly and Jonathan Ho, OpenAI and Schneider, Jonas and Sutskever, Ilya and Abbeel, Pieter and Zaremba, Wojciech},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{zolna2021task,
  title={Task-relevant adversarial imitation learning},
  author={Zolna, Konrad and Reed, Scott and Novikov, Alexander and Colmenarejo, Sergio Gomez and Budden, David and Cabi, Serkan and Denil, Misha and de Freitas, Nando and Wang, Ziyu},
  booktitle={Conference on Robot Learning},
  pages={247--263},
  year={2021},
  organization={PMLR}
}

@article{wang2017robust,
  title={Robust imitation of diverse behaviors},
  author={Wang, Ziyu and Merel, Josh S and Reed, Scott E and de Freitas, Nando and Wayne, Gregory and Heess, Nicolas},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{metelli2023towards,
  title={Towards Theoretical Understanding of Inverse Reinforcement Learning},
  author={Metelli, Alberto Maria and Lazzati, Filippo and Restelli, Marcello},
  journal={arXiv preprint arXiv:2304.12966},
  year={2023}
}

@article{zeng2023understanding,
  title={Understanding Expertise through Demonstrations: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning},
  author={Zeng, Siliang and Li, Chenliang and Garcia, Alfredo and Hong, Mingyi},
  journal={arXiv preprint arXiv:2302.07457},
  year={2023}
}