\begin{thebibliography}{57}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahmed et~al.(2021)Ahmed, Bengio, van Seijen, and
  Courville]{Ahmed2021SystematicGW}
Faruk Ahmed, Yoshua Bengio, Harm van Seijen, and Aaron~C. Courville.
\newblock Systematic generalisation with group invariant predictions.
\newblock In \emph{ICLR}, 2021.

\bibitem[Ahuja et~al.(2020)Ahuja, Shanmugam, Varshney, and
  Dhurandhar]{ahuja2020invariant}
Kartik Ahuja, Karthikeyan Shanmugam, Kush Varshney, and Amit Dhurandhar.
\newblock Invariant risk minimization games.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Ahuja et~al.(2021)Ahuja, Wang, Dhurandhar, Shanmugam, and
  Varshney]{Ahuja2020IRMsamplecomplexity}
Kartik Ahuja, Jun Wang, Amit Dhurandhar, Karthikeyan Shanmugam, and Kush~R.
  Varshney.
\newblock Empirical or invariant risk minimization? {A} sample complexity
  perspective.
\newblock \emph{International Conference on Learning Representations}, 2021.

\bibitem[Arjovsky et~al.(2019)Arjovsky, Bottou, Gulrajani, and
  Lopez-Paz]{Arjovsky2019Invariant}
Martin Arjovsky, LÃ©on Bottou, Ishaan Gulrajani, and David Lopez-Paz.
\newblock Invariant risk minimization.
\newblock \emph{arXiv preprint arXiv:1907.02893}, 2019.

\bibitem[Ben-Tal et~al.(2013)Ben-Tal, Den~Hertog, De~Waegenaere, Melenberg, and
  Rennen]{ben2013robust}
Aharon Ben-Tal, Dick Den~Hertog, Anja De~Waegenaere, Bertrand Melenberg, and
  Gijs Rennen.
\newblock Robust solutions of optimization problems affected by uncertain
  probabilities.
\newblock \emph{Management Science}, 59\penalty0 (2):\penalty0 341--357, 2013.

\bibitem[B{\"o}se et~al.(2017)B{\"o}se, Flunkert, Gasthaus, Januschowski,
  Lange, Salinas, Schelter, Seeger, and Wang]{bose2017probabilistic}
Joos-Hendrik B{\"o}se, Valentin Flunkert, Jan Gasthaus, Tim Januschowski,
  Dustin Lange, David Salinas, Sebastian Schelter, Matthias Seeger, and Yuyang
  Wang.
\newblock Probabilistic demand forecasting at scale.
\newblock \emph{Proceedings of the VLDB Endowment}, 10\penalty0 (12):\penalty0
  1694--1705, 2017.

\bibitem[Chang et~al.(2020)Chang, Zhang, Yu, and Jaakkola]{chang2020invariant}
Shiyu Chang, Yang Zhang, Mo~Yu, and Tommi Jaakkola.
\newblock Invariant rationalization.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Chen et~al.(2022{\natexlab{a}})Chen, Zhang, Yang, Ma, Xie, Liu, Han,
  and Cheng]{chen2022invariance}
Yongqiang Chen, Yonggang Zhang, Han Yang, Kaili Ma, Binghui Xie, Tongliang Liu,
  Bo~Han, and James Cheng.
\newblock Invariance principle meets out-of-distribution generalization on
  graphs.
\newblock \emph{arXiv preprint arXiv:2202.05441}, 2022{\natexlab{a}}.

\bibitem[Chen et~al.(2022{\natexlab{b}})Chen, Zhou, Bian, Xie, Ma, Zhang, Yang,
  Han, and Cheng]{chen2022pareto}
Yongqiang Chen, Kaiwen Zhou, Yatao Bian, Binghui Xie, Kaili Ma, Yonggang Zhang,
  Han Yang, Bo~Han, and James Cheng.
\newblock Pareto invariant risk minimization.
\newblock \emph{arXiv preprint arXiv:2206.07766}, 2022{\natexlab{b}}.

\bibitem[Creager et~al.(2021)Creager, Jacobsen, and
  Zemel]{creager2021environment}
Elliot Creager, J{\"o}rn-Henrik Jacobsen, and Richard Zemel.
\newblock Environment inference for invariant learning.
\newblock In \emph{International Conference on Machine Learning}, 2021.

\bibitem[Danks et~al.(2009)Danks, Glymour, and Tillman]{NIPS2008_37bc2f75}
David Danks, Clark Glymour, and Robert Tillman.
\newblock Integrating locally learned causal structures with overlapping
  variables.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2009.

\bibitem[Duchi and Namkoong(2021)]{duchi2021learning}
John~C Duchi and Hongseok Namkoong.
\newblock Learning models with uniform performance via distributionally robust
  optimization.
\newblock \emph{The Annals of Statistics}, 49\penalty0 (3):\penalty0
  1378--1406, 2021.

\bibitem[Gao et~al.(2020)Gao, Chen, and Kleywegt]{gao2020wasserstein}
Rui Gao, Xi~Chen, and Anton~J Kleywegt.
\newblock Wasserstein distributionally robust optimization and variation
  regularization.
\newblock \emph{arXiv preprint arXiv:1712.06050}, 2020.

\bibitem[Gislason et~al.(2006)Gislason, Benediktsson, and
  Sveinsson]{GISLASON2006294}
Pall~Oskar Gislason, Jon~Atli Benediktsson, and Johannes~R. Sveinsson.
\newblock Random forests for land cover classification.
\newblock \emph{Pattern Recognition Letters}, 27\penalty0 (4):\penalty0
  294--300, 2006.

\bibitem[Gulrajani and Lopez-Paz(2020)]{gulrajani2020search}
Ishaan Gulrajani and David Lopez-Paz.
\newblock In search of lost domain generalization.
\newblock \emph{arXiv preprint arXiv:2007.01434}, 2020.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{He2016CVPR}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{the IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 2016.

\bibitem[Hendrycks and Dietterich(2019)]{Hendrycks2019Bench}
Dan Hendrycks and Thomas~G. Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Huang et~al.(2020{\natexlab{a}})Huang, Zhang, Gong, and
  Glymour]{Huang_Zhang_Gong_Glymour_2020}
Biwei Huang, Kun Zhang, Mingming Gong, and Clark Glymour.
\newblock Causal discovery from multiple data sets with non-identical variable
  sets.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, 2020{\natexlab{a}}.

\bibitem[Huang et~al.(2020{\natexlab{b}})Huang, Zhang, Zhang, Ramsey, Glymour,
  and Sch{\"o}lopf]{Huang2020heterogeneous}
Biwei Huang, Kun Zhang, Jiji Zhang, Joseph Ramsey, Clark Glymour, and Bernhard
  Sch{\"o}lopf.
\newblock Causal discovery from heterogeneous/nonstationary data.
\newblock \emph{Journal of Machine Learning Research}, 21, May
  2020{\natexlab{b}}.

\bibitem[Hyvarinen et~al.(2019)Hyvarinen, Sasaki, and
  Turner]{Hyvarinen2019nonliearICA}
Aapo Hyvarinen, Hiroaki Sasaki, and Richard Turner.
\newblock Nonlinear {ICA} using auxiliary variables and generalized contrastive
  learning.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2019.

\bibitem[Jin et~al.(2020)Jin, Barzilay, and Jaakkola]{jin2020domain}
Wengong Jin, Regina Barzilay, and Tommi Jaakkola.
\newblock Domain extrapolation via regret minimization.
\newblock \emph{arXiv preprint arXiv:2006.03908}, 2020.

\bibitem[Khemakhem et~al.(2020)Khemakhem, Kingma, Monti, and
  Hyvarinen]{Khemakhem2020ICAVAE}
Ilyes Khemakhem, Diederik Kingma, Ricardo Monti, and Aapo Hyvarinen.
\newblock Variational autoencoders and nonlinear {ICA}: A unifying framework.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2020.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Krueger et~al.(2021)Krueger, Caballero, Jacobsen, Zhang, Binas, Zhang,
  Le~Priol, and Courville]{krueger2021out}
David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan
  Binas, Dinghuai Zhang, Remi Le~Priol, and Aaron Courville.
\newblock Out-of-distribution generalization via risk extrapolation (rex).
\newblock In \emph{International Conference on Machine Learning}, 2021.

\bibitem[Lee and Raginsky(2018)]{lee2017minimax}
Jaeho Lee and Maxim Raginsky.
\newblock Minimax statistical learning with wasserstein distances.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Lin et~al.(2021)Lin, Qing, and Zhang]{linempirical}
Yong Lin, Lian Qing, and Tong Zhang.
\newblock An empirical study of invariant risk minimization on deep models.
\newblock 2021.

\bibitem[Lin et~al.(2022)Lin, Dong, Wang, and Zhang]{Lin2020BIRM}
Yong Lin, Hanze Dong, Hao Wang, and Tong Zhang.
\newblock Bayesian invariant risk minimization.
\newblock In \emph{IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, 2022.

\bibitem[Liu et~al.(2021{\natexlab{a}})Liu, Haghgoo, Chen, Raghunathan, Koh,
  Sagawa, Liang, and Finn]{Liu2021JustTT}
Evan~Zheran Liu, Behzad Haghgoo, Annie~S. Chen, Aditi Raghunathan, Pang~Wei
  Koh, Shiori Sagawa, Percy Liang, and Chelsea Finn.
\newblock Just train twice: Improving group robustness without training group
  information.
\newblock In \emph{ICML}, 2021{\natexlab{a}}.

\bibitem[Liu et~al.(2021{\natexlab{b}})Liu, Hu, Cui, Li, and
  Shen]{liu2021heterogeneous}
Jiashuo Liu, Zheyuan Hu, Peng Cui, Bo~Li, and Zheyan Shen.
\newblock Heterogeneous risk minimization.
\newblock In \emph{International Conference on Machine Learning},
  2021{\natexlab{b}}.

\bibitem[Liu et~al.(2021{\natexlab{c}})Liu, Hu, Cui, Li, and
  Shen]{liu2021kernelheterogeneous}
Jiashuo Liu, Zheyuan Hu, Peng Cui, Bo~Li, and Zheyan Shen.
\newblock Kernalized heterogeneous risk minimization.
\newblock In \emph{NeurIPS}, 2021{\natexlab{c}}.

\bibitem[Liu et~al.(2015)Liu, Luo, Wang, and Tang]{liu2015faceattributes}
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.
\newblock Deep learning face attributes in the wild.
\newblock In \emph{Proceedings of International Conference on Computer Vision
  (ICCV)}, 2015.

\bibitem[Locatello et~al.(2019)Locatello, Bauer, Lucic, Raetsch, Gelly,
  Sch{\"o}lkopf, and Bachem]{Locatelloc2019}
Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly,
  Bernhard Sch{\"o}lkopf, and Olivier Bachem.
\newblock Challenging common assumptions in the unsupervised learning of
  disentangled representations.
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Mudelsee(2019)]{MUDELSEE2019310}
Manfred Mudelsee.
\newblock Trend analysis of climate time series: A review of methods.
\newblock \emph{Earth-Science Reviews}, 190:\penalty0 310--322, 2019.

\bibitem[Nam et~al.(2020)Nam, Cha, Ahn, Lee, and Shin]{Nam2020LearningFF}
Jun~Hyun Nam, Hyuntak Cha, Sungsoo Ahn, Jaeho Lee, and Jinwoo Shin.
\newblock Learning from failure: Training debiased classifier from biased
  classifier.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Pearl(2009)]{PearlCausality}
Judea Pearl.
\newblock \emph{Causality: Models, Reasoning and Inference}.
\newblock Cambridge University Press, USA, 2nd edition, 2009.

\bibitem[Peters et~al.(2016)Peters, B{\"u}hlmann, and
  Meinshausen]{peters2016causal}
Jonas Peters, Peter B{\"u}hlmann, and Nicolai Meinshausen.
\newblock Causal inference by using invariant prediction: Identification and
  confidence intervals.
\newblock \emph{Journal of the Royal Statistical Society. Series B (Statistical
  Methodology)}, pages 947--1012, 2016.

\bibitem[Peters et~al.(2017)Peters, Janzing, and Sch{\"o}lkopf]{Peters2017book}
Jonas Peters, Dominik Janzing, and Bernhard Sch{\"o}lkopf.
\newblock \emph{Elements of Causal Inference - Foundations and Learning
  Algorithms}.
\newblock MIT Press, Cambridge, MA, USA, 2017.

\bibitem[Recht et~al.(2019)Recht, Roelofs, Schmidt, and
  Shankar]{Recht2019transfer}
Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar.
\newblock Do {I}mage{N}et classifiers generalize to {I}mage{N}et?
\newblock In \emph{International Conference on Machine Learning}, 2019.

\bibitem[Rosenfeld et~al.(2021)Rosenfeld, Ravikumar, and
  Risteski]{rosenfeld2020risks}
Elan Rosenfeld, Pradeep Ravikumar, and Andrej Risteski.
\newblock The risks of invariant risk minimization.
\newblock \emph{International Conference on Learning Representations}, 2021.

\bibitem[Russwurm et~al.(2020)Russwurm, Wang, Korner, and
  Lobell]{Russwurm_2020_CVPR_Workshops}
Marc Russwurm, Sherrie Wang, Marco Korner, and David Lobell.
\newblock Meta-learning for few-shot land cover classification.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR) Workshops}, June 2020.

\bibitem[Sagawa et~al.(2020)Sagawa, Koh, Hashimoto, and
  Liang]{sagawa2020distributionally}
Shiori Sagawa, Pang~Wei Koh, Tatsunori~B Hashimoto, and Percy Liang.
\newblock Distributionally robust neural networks for group shifts: On the
  importance of regularization for worst-case generalization.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Sanh et~al.(2021)Sanh, Wolf, Belinkov, and Rush]{Sanh2021LearningFO}
Victor Sanh, Thomas Wolf, Yonatan Belinkov, and Alexander~M. Rush.
\newblock Learning from others' mistakes: Avoiding dataset biases without
  modeling them.
\newblock In \emph{ICML}, 2021.

\bibitem[Shapiro(2017)]{shapiro2017distributionally}
Alexander Shapiro.
\newblock Distributionally robust stochastic programming.
\newblock \emph{SIAM Journal on Optimization}, 27\penalty0 (4):\penalty0
  2258--2275, 2017.

\bibitem[Sohoni et~al.(2020)Sohoni, Dunnmon, Angus, Gu, and
  R{\'e}]{Sohoni2020NoSL}
Nimit~Sharad Sohoni, Jared~A. Dunnmon, Geoffrey Angus, Albert Gu, and
  Christopher R{\'e}.
\newblock No subclass left behind: Fine-grained robustness in coarse-grained
  classification problems.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Spirtes et~al.(2000)Spirtes, Glymour, and
  Scheines]{spirtes2000causation}
Peter Spirtes, Clark~N Glymour, and Richard Scheines.
\newblock \emph{Causation, Prediction, and Search}.
\newblock MIT Press, second edition, 2000.

\bibitem[Srivastava et~al.(2020)Srivastava, Hashimoto, and
  Liang]{srivastava20a}
Megha Srivastava, Tatsunori Hashimoto, and Percy Liang.
\newblock Robustness to spurious correlations via human annotations.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2014intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Tillman and Spirtes(2011)]{pmlr-v15-tillman11a}
Robert Tillman and Peter Spirtes.
\newblock Learning equivalence classes of acyclic models with latent and
  selection variables from multiple datasets with overlapping variables.
\newblock In \emph{Proceedings of the Fourteenth International Conference on
  Artificial Intelligence and Statistics}, 2011.

\bibitem[Vergara and Estevez(2014)]{Vergara2014FeatureSelectionMI}
Jorge Vergara and Pablo Estevez.
\newblock A review of feature selection methods based on mutual information.
\newblock \emph{Neural Computing and Applications}, 24, 01 2014.

\bibitem[Wang et~al.(2022)Wang, Yi, Chen, and Zhu]{Wang2022OODCIT}
Ruoyu Wang, Mingyang Yi, Zhitang Chen, and Shengyu Zhu.
\newblock Out-of-distribution generalization with causal invariant
  transformations.
\newblock In \emph{{IEEE/CVF} Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 2022.

\bibitem[Wang et~al.(2020)Wang, Chen, Xie, Azzari, and Lobell]{rs12020207}
Sherrie Wang, William Chen, Sang~Michael Xie, George Azzari, and David~B.
  Lobell.
\newblock Weakly supervised deep learning for segmentation of remote sensing
  imagery.
\newblock \emph{Remote Sensing}, 12\penalty0 (2), 2020.

\bibitem[Xie et~al.(2020)Xie, Chen, Liu, and Li]{xie2020risk}
Chuanlong Xie, Fei Chen, Yue Liu, and Zhenguo Li.
\newblock Risk variance penalization: From distributional robustness to
  causality.
\newblock \emph{arXiv preprint arXiv:2006.07544}, 2020.

\bibitem[Xie et~al.(2021)Xie, Kumar, Jones, Khani, Ma, and
  Liang]{xie2021innout}
Sang~Michael Xie, Ananya Kumar, Robbie Jones, Fereshte Khani, Tengyu Ma, and
  Percy Liang.
\newblock {In-N-Out}: Pre-training and self-training using auxiliary
  information for out-of-distribution robustness.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Xu and Jaakkola(2021)]{xu2021learning}
Yilun Xu and Tommi Jaakkola.
\newblock Learning representations that support robust transfer of predictors.
\newblock \emph{arXiv preprint arXiv:2110.09940}, 2021.

\bibitem[Yi et~al.(2021)Yi, Hou, Sun, Shang, Jiang, Liu, and
  Ma]{yi2021improved}
Mingyang Yi, Lu~Hou, Jiacheng Sun, Lifeng Shang, Xin Jiang, Qun Liu, and
  Zhi-Ming Ma.
\newblock Improved {OOD} generalization via adversarial training and
  pre-training.
\newblock In \emph{International Conference on Machine Learning}, 2021.

\bibitem[Zhou et~al.(2022{\natexlab{a}})Zhou, Lin, Pi, Zhang, Xu, Cui, and
  Zhang]{zhou2022model}
Xiao Zhou, Yong Lin, Renjie Pi, Weizhong Zhang, Renzhe Xu, Peng Cui, and Tong
  Zhang.
\newblock Model agnostic sample reweighting for out-of-distribution learning.
\newblock In \emph{International Conference on Machine Learning},
  2022{\natexlab{a}}.

\bibitem[Zhou et~al.(2022{\natexlab{b}})Zhou, Lin, Zhang, and
  Zhang]{Zhou2022SparseIRM}
Xiao Zhou, Yong Lin, Weizhong Zhang, and Tong Zhang.
\newblock Sparse invariant risk minimization.
\newblock In \emph{International Conference on Machine Learning},
  2022{\natexlab{b}}.

\end{thebibliography}
