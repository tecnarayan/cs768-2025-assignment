@article{pann,
author = {Kong, Qiuqiang and Cao, Yin and Iqbal, Turab and Wang, Yuxuan and others},
title = {PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition},
year = {2020},
issue_date = {2020},
publisher = {IEEE Press},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2020.3030497},
doi = {10.1109/TASLP.2020.3030497},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.}
}

@inproceedings{UrbanSound,
  title={A dataset and taxonomy for urban sound research},
  author={Salamon, Justin and Jacoby, Christopher and others},
  booktitle={22nd ACM international conference on Multimedia},
  year={2014}
}

@article{chen2021wavlm,
  title={Wavlm: Large-scale self-supervised pre-training for full stack speech processing},
  author={Chen, Sanyuan and Wang, Chengyi and Chen, Zhengyang and Wu, Yu and others},
  journal={IEEE Journal of Selected Topics in Signal Proc.},
  year={2022},
}

@article{xie2021zero,
  title={Zero-shot audio classification via semantic embeddings},
  author={Xie, Huang and Virtanen, Tuomas},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Proc.},
  year={2021},
  publisher={IEEE}
}

@article{zhang2021bigssl,
  title={Bigssl: Exploring the frontier of large-scale semi-supervised learning for automatic speech recognition},
  author={Zhang, Yu and Park, Daniel S and Han, Wei and Qin, James  and others},
  journal={IEEE Journal of Selected Topics in Signal Proc},
  year={2022}
}

@article{mesaros2019sound,
  title={Sound event detection in the DCASE 2017 challenge},
  author={Mesaros, Annamaria and Diment, Aleksandr and Elizalde, Benjamin and Heittola, Toni and others},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2019},
  publisher={IEEE}
}

@article{lyon2010machine,
  title={Machine hearing: An emerging field},
  author={Lyon, Richard F},
  journal={IEEE signal processing magazine},
  year={2010},
  publisher={IEEE}
}

@inproceedings{gong21b_interspeech,
  author={Yuan Gong and Yu-An Chung and James Glass},
  title={{AST: Audio Spectrogram Transformer}},
  year=2021,
  booktitle={Proc. Interspeech 2021},
  pages={571--575},
  doi={10.21437/Interspeech.2021-698}
}

@inproceedings{niizumi2021byol-a,
      title={BYOL for Audio: Self-Supervised Learning for General-Purpose Audio Representation}, 
      author={Daisuke Niizumi and Daiki Takeuchi and Yasunori Ohishi and Noboru Harada and Kunio Kashino},
      booktitle = {2021 International Joint Conference on Neural Networks, {IJCNN} 2021},
      year={2021},
      eprint={2103.06695},
      archivePrefix={arXiv},
      primaryClass={eess.AS}
}

@article{gong2021ast,
  title={Ast: Audio spectrogram transformer},
  author={Gong, Yuan and Chung, Yu-An and Glass, James},
  journal={arXiv preprint arXiv:2104.01778},
  year={2021}
}

@inproceedings{gong2022ssast,
  title={Ssast: Self-supervised audio spectrogram transformer},
  author={Gong, Yuan and Lai, Cheng-I and Chung, Yu-An and Glass, James},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  number={10},
  pages={10699--10709},
  year={2022}
}

@inproceedings{chen2022hts,
  title={HTS-AT: A hierarchical token-semantic audio transformer for sound classification and detection},
  author={Chen, Ke and Du, Xingjian and Zhu, Bilei and Ma, Zejun and Berg-Kirkpatrick, Taylor and Dubnov, Shlomo},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year={2022}
}

@INPROCEEDINGS{cola,
  author={Saeed, Aaqib and Grangier, David and Zeghidour, Neil},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Contrastive Learning of General-Purpose Audio Representations}, 
  year={2021}
}

@article{trill,
  title={Towards Learning a Universal Non-Semantic Representation of Speech},
  author={Shor, Joel and Jansen, Aren and Maor, Ronnie and Lang, Oran and Tuval, Omry and de Chaumont Quitry, F{\'e}lix and Tagliasacchi, Marco and Shavitt, Ira and Emanuel, Dotan and Haviv, Yinnon},
  journal={Proc. Interspeech 2020},
  pages={140--144},
  year={2020}
}
  
@INPROCEEDINGS{9415009,
  author={Fonseca, Eduardo and Ortego, Diego and McGuinness, Kevin and O’Connor, Noel E. and Serra, Xavier},
  booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Unsupervised Contrastive Learning of Sound Event Representations}, 
  year={2021},
  doi={10.1109/ICASSP39728.2021.9415009}}

@article{wav2vec2,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in neural information processing systems},
  year={2020}
}

@article{wav2vec,
  title={wav2vec: Unsupervised Pre-Training for Speech Recognition},
  author={Schneider, Steffen and Baevski, Alexei and Collobert, Ronan and Auli, Michael},
  journal={Proc. Interspeech 2019},
  pages={3465--3469},
  year={2019}
}

@article{hubert,
  title={Hubert: Self-supervised speech representation learning by masked prediction of hidden units},
  author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={29},
  pages={3451--3460},
  year={2021},
  publisher={IEEE}
}
  
@INPROCEEDINGS{audioset,
  author={Gemmeke, Jort F. and Ellis, Daniel P. W. and Freedman, Dylan and Jansen, Aren and Lawrence, Wade and Moore, R. Channing and Plakal, Manoj and Ritter, Marvin},
  booktitle={2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Audio Set: An ontology and human-labeled dataset for audio events}, 
  year={2017},
  volume={},
  number={},
  pages={776-780},
  doi={10.1109/ICASSP.2017.7952261}}
  
  @article{han2017convolutional,
  title={Convolutional neural networks with binaural representations and background subtraction for acoustic scene classification},
  author={Han, Yoonchang and Park, Jeongsoo and Lee, Kyogu},
  journal={the Detection and Classification of Acoustic Scenes and Events (DCASE)},
  year={2017}
}
  
@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and others},
  booktitle={International Conference on Machine Learning},
  year={2021},
  organization={PMLR}
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International Conference on Machine Learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}

@article{yuan2021florence,
  title={Florence: A New Foundation Model for Computer Vision},
  author={Yuan, Lu and Chen, Dongdong and Chen, Yi-Ling and Codella, Noel and others},
  journal={arXiv preprint arXiv:2111.11432},
  year={2021}
}

@INPROCEEDINGS{wav2clip,
  author={Wu, Ho-Hsiang and Seetharaman, Prem and Kumar, Kundan and others},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Wav2CLIP: Learning Robust Audio Representations from Clip}, 
  year={2022},
  doi={10.1109/ICASSP43922.2022.9747669}}
  
@INPROCEEDINGS{audioclip,
  author={Guzhov, Andrey and Raue, Federico and Hees, Jörn and Dengel, Andreas},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Audioclip: Extending Clip to Image, Text and Audio}, 
  year={2022},
  doi={10.1109/ICASSP43922.2022.9747631}}
  
@inproceedings{esc50,
  title = {{ESC}: {Dataset} for {Environmental Sound Classification}},
  author = {Piczak, Karol J.},
  booktitle = {Proceedings of the 23rd {Annual ACM Conference} on {Multimedia}},
  date = {2015-10-13},
  year = {2015},
  doi = {10.1145/2733373.2806390},
  location = {{Brisbane, Australia}},
  isbn = {978-1-4503-3459-4},
  publisher = {{ACM Press}},
  pages = {1015--1018}
}

@inproceedings{koutini2021efficient,
  author       = {Khaled Koutini and
                  Jan Schl{\"{u}}ter and
                  Hamid Eghbal{-}zadeh and
                  Gerhard Widmer},
  title        = {Efficient Training of Audio Transformers with Patchout},
  booktitle    = {Interspeech 2022, 23rd Annual Conference of the International Speech
                  Communication Association, Incheon, Korea, 18-22 September 2022},
  pages        = {2753--2757},
  publisher    = {{ISCA}},
  year         = {2022},
  url          = {https://doi.org/10.21437/Interspeech.2022-227},
  doi          = {10.21437/Interspeech.2022-227},
}

@ARTICLE{fsd50k,
  author={Fonseca, Eduardo and Favory, Xavier and Pons, Jordi and Font, Frederic and Serra, Xavier},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={FSD50K: An Open Dataset of Human-Labeled Sound Events}, 
  year={2022},
  doi={10.1109/TASLP.2021.3133208}}
  
@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186"
}

@INPROCEEDINGS{clotho,
  author={Drossos, Konstantinos and Lipping, Samuel and Virtanen, Tuomas},
  booktitle={ IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Clotho: an Audio Captioning Dataset}, 
  year={2020},
  doi={10.1109/ICASSP40776.2020.9052990}}
  
@inproceedings{macs,
  title={What is the ground truth? reliability of multi-annotator data for audio tagging},
  author={Mart{\'\i}n-Morat{\'o}, Irene and Mesaros, Annamaria},
  booktitle={2021 29th European Signal Processing Conference (EUSIPCO)},
  year={2021},
}

@inproceedings{audiocaps,
    author    = {Chris Dongjoo Kim and Byeongchang Kim and Hyunmin Lee and Gunhee Kim},
    title     = "{AudioCaps: Generating Captions for Audios in The Wild}",
    booktitle = {NAACL-HLT},
    year      = 2019
}

@inbook{pytorch,
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and K\"{o}pf, Andreas and Yang, Edward and DeVito, Zach and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
year = {2019},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 33rd International Conference on Neural Information Processing Systems},
articleno = {721},
numpages = {12}
}

@inproceedings{adam,
  author={Diederik P. Kingma and Jimmy Ba},
  title={Adam: A Method for Stochastic Optimization},
  year={2015},
  cdate={1420070400000},
  url={http://arxiv.org/abs/1412.6980},
  booktitle={ICLR (Poster)}
}

@inproceedings{wang2022towards,
  title={Towards learning universal audio representations},
  author={Wang, Luyu and Luc, Pauline and Wu, Yan and Recasens, Adria and Smaira, Lucas and Brock, Andrew and Jaegle, Andrew and Alayrac, Jean-Baptiste and Dieleman, Sander and Carreira, Joao and others},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={4593--4597},
  year={2022},
  organization={IEEE}
}

@INPROCEEDINGS{openl3,
  author={Cramer, Jason and Wu, Ho-Hsiang and Salamon, Justin and Bello, Juan Pablo},
  booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title={Look, Listen, and Learn More: Design Choices for Deep Audio Embeddings}, 
  year={2019},
  volume={},
  number={},
  pages={3852-3856},
  doi={10.1109/ICASSP.2019.8682475}}
  
@article{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@INPROCEEDINGS{esc50_daniels,
  author={Tompkins, Daniel and Kumar, Kshitiz and Wu, Jian},
  booktitle={ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Maximizing Audio Event Detection Model Performance on Small Datasets Through Knowledge Transfer, Data Augmentation, and Pretraining: an Ablation Study}, 
  year={2022},
  volume={},
  number={},
  pages={1016-1020},
  doi={10.1109/ICASSP43922.2022.9747250}}
  
@ARTICLE{us8k_best,
  author={Song, Hongwei and Deng, Shiwen and Han, Jiqing},
  journal={IEEE Signal Processing Letters}, 
  title={Exploring Inter-Node Relations in CNNs for Environmental Sound Classification}, 
  year={2022},
  volume={29},
  number={},
  pages={154-158},
  doi={10.1109/LSP.2021.3130502}}
  

@Article{ravdess_best,
AUTHOR = {Luna-Jiménez, Cristina and Kleinlein, Ricardo and Griol, David and Callejas, Zoraida and Montero and others},
TITLE = {A Proposal for Multimodal Emotion Recognition Using Aural Transformers and Action Units on RAVDESS Dataset},
JOURNAL = {Applied Sciences},
YEAR = {2022},
ARTICLE-NUMBER = {327},
URL = {https://www.mdpi.com/2076-3417/12/1/327},
ISSN = {2076-3417},
DOI = {10.3390/app12010327}
}

@article{speechcommands_best,
  title={Broadcasted residual learning for efficient keyword spotting},
  author={Kim, Byeonggeun and Chang, Simyung and Lee, Jinkyu and others},
  journal={arXiv preprint arXiv:2106.04140},
  year={2021}
}

@INPROCEEDINGS{vocalsound,
  author={Gong, Yuan and Yu, Jin and Glass, James},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Vocalsound: A Dataset for Improving Human Vocal Sounds Recognition}, 
  year={2022},
  doi={10.1109/ICASSP43922.2022.9746828}}
  
@article{kong2020sound,
  title={Sound event detection of weakly labelled data with CNN-transformer and automatic threshold optimization},
  author={Kong, Qiuqiang and Xu, Yong and others},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Proc.},
  year={2020},
}

@inproceedings{zhai2022lit,
  title={Lit: Zero-shot transfer with locked-image text tuning},
  author={Zhai, Xiaohua and Wang, Xiao and others},
  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recog.},
  year={2022}
}

@misc{nsynth2017,
    Author = {Jesse Engel and Cinjon Resnick and Adam Roberts and
              Sander Dieleman and Douglas Eck and Karen Simonyan and
              Mohammad Norouzi},
    Title = {Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders},
    Year = {2017},
    Eprint = {arXiv:1704.01279},
}

@article{mei2022metric,
  title={On Metric Learning for Audio-Text Cross-Modal Retrieval},
  author={Mei, Xinhao and Liu, Xubo and Sun, Jianyuan and Plumbley, Mark D and Wang, Wenwu},
  journal={arXiv preprint arXiv:2203.15537},
  year={2022}
}

@INPROCEEDINGS{crossmodal,
  author={Elizalde, Benjamin and Zarar, Shuayb and Raj, Bhiksha},
  booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Cross Modal Audio Search and Retrieval with Joint Embeddings Based on Text and Audio}, 
  year={2019}
}

@book{elizalde2020never,
  title={Never-ending learning of sounds},
  author={Elizalde, Benjamin Martinez},
  year={2020},
  publisher={Carnegie Mellon University}
}

@inproceedings{deshmukh2021improving,
author = {Deshmukh, Soham and Raj, Bhiksha and Singh, Rita},
year = {2021},
month = {08},
pages = {596-600},
title = {Improving Weakly Supervised Sound Event Detection with Self-Supervised Auxiliary Tasks},
doi = {10.21437/Interspeech.2021-2079}
}

@article{wu2022large,
  title={Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation},
  author={Wu, Yusong and Chen, Ke and Zhang, Tianyu and Hui, Yuchen and Berg-Kirkpatrick, Taylor and Dubnov, Shlomo},
  journal={arXiv preprint arXiv:2211.06687},
  year={2022}
}

@InProceedings{turian2022hear,
  title = 	 {{HEAR: Holistic Evaluation of Audio Representations}},
  author={Turian, Joseph and Shier, Jordie and others},
  booktitle = 	 {NeurIPS 2021 Competitions and Demonstrations Track},
  year = 	 {2022}
}

@inproceedings{wolf2019huggingface,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Wolf, Thomas and Debut, Lysandre and others",
    booktitle = "Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    year= 2020
}

@inproceedings{deshmukh2022audio,
  author={Soham Deshmukh and Benjamin Elizalde and Huaming Wang},
  title={{Audio Retrieval with WavText5K and CLAP Training}},
  year=2023,
  booktitle={Proc. INTERSPEECH 2023},
  pages={2948--2952},
  doi={10.21437/Interspeech.2023-1136}
}

@ARTICLE{sounddescs,
  author={Koepke, A. Sophia and Oncescu, Andreea-Maria and Henriques, Joao and Akata, Zeynep and Albanie, Samuel},
  journal={IEEE Transactions on Multimedia}, 
  title={Audio Retrieval with Natural Language Queries: A Benchmark Study}, 
  year={2022},
  doi={10.1109/TMM.2022.3149712}}

@inproceedings{tompkins2022maximizing,
  title={Maximizing audio event detection model performance on small datasets through knowledge transfer, data augmentation, and pretraining: an ablation study},
  author={Tompkins, Daniel and Kumar, Kshitiz and Wu, Jian},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1016--1020},
  year={2022},
  organization={IEEE}
}

@incollection{cnn_architectures_audioset,
title	= {CNN Architectures for Large-Scale Audio Classification},
author	= {Shawn Hershey and Sourish Chaudhuri and Daniel P. W. Ellis and Jort F. Gemmeke and Aren Jansen and Channing Moore and Manoj Plakal and Devin Platt and Rif A. Saurous and Bryan Seybold and Malcolm Slaney and Ron Weiss and Kevin Wilson},
year	= {2017},
URL	= {https://arxiv.org/abs/1609.09430},
booktitle	= {International Conference on Acoustics, Speech and Signal Processing (ICASSP)}
}

@article{chen2022beats,
  title={BEATs: Audio Pre-Training with Acoustic Tokenizers},
  author={Chen, Sanyuan and Wu, Yu and Wang, Chengyi and Liu, Shujie and Tompkins, Daniel and Chen, Zhuo and Wei, Furu},
  journal={arXiv preprint arXiv:2212.09058},
  year={2022}
}

@article{elizalde2022clap,
  title={Clap: Learning audio concepts from natural language supervision},
  author={Elizalde, Benjamin and Deshmukh, Soham and Ismail, Mahmoud Al and Wang, Huaming},
  journal={arXiv preprint arXiv:2206.04769},
  year={2022}
}

@article{mei2023wavcaps,
  title={WavCaps: A ChatGPT-Assisted Weakly-Labelled Audio Captioning Dataset for Audio-Language Multimodal Research},
  author={Mei, Xinhao and Meng, Chutong and Liu, Haohe and Kong, Qiuqiang and Ko, Tom and Zhao, Chengqi and Plumbley, Mark D and Zou, Yuexian and Wang, Wenwu},
  journal={arXiv preprint arXiv:2303.17395},
  year={2023}
}

@inproceedings{huang2022mulan,
  title={MuLan: A Joint Embedding of Music Audio and Natural Language},
  author={Qingqing Huang and Aren Jansen and Joonseok Lee and Ravi Ganti and Judith Yue Li and Daniel P. W. Ellis},
  booktitle={International Society for Music Information Retrieval Conference},
  year={2022}
}

@inproceedings{zhao_naacl,
author = {Y. Zhao and J. Hessel and Y. Yu and X. Lu and R. Zellers and Y. Choi},
title = {Connecting the Dots between Audio and Text without Parallel Data through Visual Knowledge Transfer},
booktitle = {2022 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)},
month = {Jul.},
year = {2022}}

@inproceedings{vit,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  booktitle={International Conference on Learning Representations}
}

@article{huang2022masked,
  title={Masked autoencoders that listen},
  author={Huang, Po-Yao and Xu, Hu and Li, Juncheng and Baevski, Alexei and Auli, Michael and Galuba, Wojciech and Metze, Florian and Feichtenhofer, Christoph},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={28708--28720},
  year={2022}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{weifinetuned,
  title={Finetuned Language Models are Zero-Shot Learners},
  author={Wei, Jason and Bosma, Maarten and Zhao, Vincent and Guu, Kelvin and Yu, Adams Wei and Lester, Brian and Du, Nan and Dai, Andrew M and Le, Quoc V},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{li2019visualbert,
  title={VISUALBERT: ASimple AND PERFORMANT BASELINE FOR VISION AND LANGUAGE},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1908.03557},
  year={2019}
}

@inproceedings{wangsimvlm,
  title={SimVLM: Simple Visual Language Model Pretraining with Weak Supervision},
  author={Wang, Zirui and Yu, Jiahui and Yu, Adams Wei and Dai, Zihang and Tsvetkov, Yulia and Cao, Yuan},
  booktitle={International Conference on Learning Representations}
}

@article{mokady2021clipcap,
  title={Clipcap: Clip prefix for image captioning},
  author={Mokady, Ron and Hertz, Amir and Bermano, Amit H},
  journal={arXiv preprint arXiv:2111.09734},
  year={2021}
}

@article{tsimpoukelli2021multimodal,
  title={Multimodal few-shot learning with frozen language models},
  author={Tsimpoukelli, Maria and Menick, Jacob L and Cabi, Serkan and Eslami, SM and Vinyals, Oriol and Hill, Felix},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={200--212},
  year={2021}
}

@inproceedings{lester2021power,
  title={The Power of Scale for Parameter-Efficient Prompt Tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={3045--3059},
  year={2021}
}

@inproceedings{li2021prefix,
  title={Prefix-Tuning: Optimizing Continuous Prompts for Generation},
  author={Li, Xiang Lisa and Liang, Percy},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={4582--4597},
  year={2021}
}

@article{alayrac2022flamingo,
  title={Flamingo: a visual language model for few-shot learning},
  author={Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katherine and Reynolds, Malcolm and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={23716--23736},
  year={2022}
}

@incollection{mccloskey1989catastrophic,
  title={Catastrophic interference in connectionist networks: The sequential learning problem},
  author={McCloskey, Michael and Cohen, Neal J},
  booktitle={Psychology of learning and motivation},
  volume={24},
  pages={109--165},
  year={1989},
  publisher={Elsevier}
}

@inproceedings{jeong2022cochlscene,
  title={CochlScene: Acquisition of acoustic scene data using crowdsourcing},
  author={Jeong, Il-Young and Park, Jeongsoo},
  booktitle={2022 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)},
  pages={17--21},
  year={2022},
  organization={IEEE}
}

@article{kim2023prefix,
  title={Prefix tuning for automated audio captioning},
  author={Kim, Minkyu and Sung-Bin, Kim and Oh, Tae-Hyun},
  journal={arXiv preprint arXiv:2303.17489},
  year={2023}
}

@inproceedings{lipping2022clotho,
  title={Clotho-AQA: A Crowdsourced Dataset for Audio Question Answering},
  author={Lipping, Samuel and Sudarsanam, Parthasaarathy and Drossos, Konstantinos and Virtanen, Tuomas},
  booktitle={2022 30th European Signal Processing Conference (EUSIPCO)},
  pages={1140--1144},
  year={2022},
  organization={IEEE}
}

@inproceedings{mosei,
  title={Multimodal language analysis in the wild: Cmu-mosei dataset and interpretable dynamic fusion graph},
  author={Zadeh, AmirAli Bagher and Liang, Paul Pu and Poria, Soujanya and Cambria, Erik and Morency, Louis-Philippe},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2236--2246},
  year={2018}
}

@article{zadeh2016mosi,
  title={Mosi: multimodal corpus of sentiment intensity and subjectivity analysis in online opinion videos},
  author={Zadeh, Amir and Zellers, Rowan and Pincus, Eli and Morency, Louis-Philippe},
  journal={arXiv preprint arXiv:1606.06259},
  year={2016}
}

@inproceedings{fma_dataset,
  title = {{FMA}: A Dataset for Music Analysis},
  author = {Defferrard, Micha\"el and Benzi, Kirell and Vandergheynst, Pierre and Bresson, Xavier},
  booktitle = {18th International Society for Music Information Retrieval Conference (ISMIR)},
  year = {2017},
  archiveprefix = {arXiv},
  eprint = {1612.01840}
}

@article{chung2022scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Eric and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={arXiv preprint arXiv:2210.11416},
  year={2022}
}

@inproceedings{poria2019meld,
  title={MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations},
  author={Poria, Soujanya and Hazarika, Devamanyu and Majumder, Navonil and Naik, Gautam and Cambria, Erik and Mihalcea, Rada},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={527--536},
  year={2019}
}

@article{msp_podcast,
  title={Building naturalistic emotionally balanced speech corpus by retrieving emotional speech from existing podcast recordings},
  author={Lotfian, Reza and Busso, Carlos},
  journal={IEEE Transactions on Affective Computing},
  volume={10},
  number={4},
  pages={471--483},
  year={2017},
  publisher={IEEE}
}

@article{dhamyal2022describing,
  title={Describing emotions with acoustic property prompts for speech emotion recognition},
  author={Dhamyal, Hira and Elizalde, Benjamin and Deshmukh, Soham and Wang, Huaming and Raj, Bhiksha and Singh, Rita},
  journal={arXiv preprint arXiv:2211.07737},
  year={2022}
}

@article{ji2023survey,
  title={Survey of hallucination in natural language generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  journal={ACM Computing Surveys},
  year={2023},
  publisher={ACM New York, NY}
}

@article{weidinger2021ethical,
  title={Ethical and social risks of harm from language models},
  author={Weidinger, Laura and Mellor, John and Rauh, Maribeth and Griffin, Conor and Uesato, Jonathan and Huang, Po-Sen and Cheng, Myra and Glaese, Mia and Balle, Borja and Kasirzadeh, Atoosa and others},
  journal={arXiv preprint arXiv:2112.04359},
  year={2021}
}

@article{rae2021scaling,
  title={Scaling language models: Methods, analysis \& insights from training gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
  journal={arXiv preprint arXiv:2112.11446},
  year={2021}
}

@article{borsos2022audiolm,
  title={Audiolm: a language modeling approach to audio generation},
  author={Borsos, Zal{\'a}n and Marinier, Rapha{\"e}l and Vincent, Damien and Kharitonov, Eugene and Pietquin, Olivier and Sharifi, Matt and Teboul, Olivier and Grangier, David and Tagliasacchi, Marco and Zeghidour, Neil},
  journal={arXiv preprint arXiv:2209.03143},
  year={2022}
}

@article{agostinelli2023musiclm,
  title={Musiclm: Generating music from text},
  author={Agostinelli, Andrea and Denk, Timo I and Borsos, Zal{\'a}n and Engel, Jesse and Verzetti, Mauro and Caillon, Antoine and Huang, Qingqing and Jansen, Aren and Roberts, Adam and Tagliasacchi, Marco and others},
  journal={arXiv preprint arXiv:2301.11325},
  year={2023}
}

@inproceedings{manas2022mapl,
    title = "{MAPL}: Parameter-Efficient Adaptation of Unimodal Pre-Trained Models for Vision-Language Few-Shot Prompting",
    author = "Ma{\~n}as, Oscar  and
      Rodriguez Lopez, Pau  and
      Ahmadi, Saba  and
      Nematzadeh, Aida  and
      Goyal, Yash  and
      Agrawal, Aishwarya",
    booktitle = "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",
    year = "2023",
    publisher = "Association for Computational Linguistics"
}

@inproceedings{fonseca2017freesound,
  title={Freesound datasets: a platform for the creation of open audio datasets},
  author={Fonseca, Eduardo and Pons Puig, Jordi and Favory, Xavier and Font Corbera, Frederic and Bogdanov, Dmitry and Ferraro, Andres and Oramas, Sergio and Porter, Alastair and Serra, Xavier},
  booktitle={Hu X, Cunningham SJ, Turnbull D, Duan Z, editors. Proceedings of the 18th ISMIR Conference; 2017 oct 23-27; Suzhou, China.[Canada]: International Society for Music Information Retrieval},
  year={2017},
  organization={International Society for Music Information Retrieval (ISMIR)}
}

@inproceedings{engel2017neural,
  title={Neural audio synthesis of musical notes with wavenet autoencoders},
  author={Engel, Jesse and Resnick, Cinjon and Roberts, Adam and Dieleman, Sander and Norouzi, Mohammad and Eck, Douglas and Simonyan, Karen},
  booktitle={International Conference on Machine Learning},
  pages={1068--1077},
  year={2017},
  organization={PMLR}
}

@ARTICLE{mtl_survey,
  author={Zhang, Yu and Yang, Qiang},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={A Survey on Multi-Task Learning}, 
  year={2022},
  volume={34},
  number={12},
  pages={5586-5609},
  doi={10.1109/TKDE.2021.3070203}}


@inproceedings{wang2022towards,
  title={Towards learning universal audio representations},
  author={Wang, Luyu and Luc, Pauline and Wu, Yan and Recasens, Adria and Smaira, Lucas and Brock, Andrew and Jaegle, Andrew and Alayrac, Jean-Baptiste and Dieleman, Sander and Carreira, Joao and others},
  booktitle={ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={4593--4597},
  year={2022},
  organization={IEEE}
}

@article{gong2021ssast, title={SSAST: Self-Supervised Audio Spectrogram Transformer}, volume={36}, url={https://ojs.aaai.org/index.php/AAAI/article/view/21315}, DOI={10.1609/aaai.v36i10.21315}, author={Gong, Yuan and Lai, Cheng-I and Chung, Yu-An and Glass, James}, year={2022}, month={Jun.}, pages={10699-10709} }

@INPROCEEDINGS{niizumi2021byola,
  author={Niizumi, Daisuke and Takeuchi, Daiki and Ohishi, Yasunori and Harada, Noboru and Kashino, Kunio},
  booktitle={2021 International Joint Conference on Neural Networks (IJCNN)}, 
  title={BYOL for Audio: Self-Supervised Learning for General-Purpose Audio Representation}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  doi={10.1109/IJCNN52387.2021.9534474}}

@article{zhou2021narle,
      title={NaRLE: Natural Language Models using Reinforcement Learning with Emotion Feedback}, 
      author={Ruijie Zhou and Soham Deshmukh and Jeremiah Greer and Charles Lee},
      year={2021},
      journal={arXiv preprintarXiv:2110.02148},
}

@inproceedings{toxic,
  author={Deshmukh, Soham and Rade, Rahul},
  booktitle={2018 Conference on Information and Communication Technology (CICT)}, 
  title={Tackling Toxic Online Communication with Recurrent Capsule Networks}, 
  year={2018},
  volume={},
  number={},
  pages={1-7},
  doi={10.1109/INFOCOMTECH.2018.8722433}}

@article{dhamyal2023prompting,
      title={Prompting Audios Using Acoustic Properties For Emotion Representation}, 
      author={Hira Dhamyal and Benjamin Elizalde and Soham Deshmukh and Huaming Wang and Bhiksha Raj and Rita Singh},
      year={2023},
      journal={arXiv preprint arXiv:2310.02298},
}