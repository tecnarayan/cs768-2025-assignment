@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{pixart,
      title={PixArt-$\alpha$: Fast Training of Diffusion Transformer for Photorealistic Text-to-Image Synthesis}, 
      author={Junsong Chen and Jincheng Yu and Chongjian Ge and Lewei Yao and Enze Xie and Yue Wu and Zhongdao Wang and James Kwok and Ping Luo and Huchuan Lu and Zhenguo Li},
      year={2023},
      eprint={2310.00426},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{wrstchen,
  title={W{\"u}rstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models},
  author={Pernias, Pablo and Rampas, Dominic and Richter, Mats Leon and Pal, Christopher and Aubreville, Marc},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{ho2020denoising,
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6840--6851},
  year={2020}
}

@article{song2020score,
  title={Score-based generative modeling through stochastic differential equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  journal={arXiv preprint arXiv:2011.13456},
  year={2020}
}

@article{dhariwal2021diffusion,
  title={Diffusion models beat gans on image synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8780--8794},
  year={2021}
}

@inproceedings{ldm,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10684--10695},
  year={2022}
}

@article{liu2023hyperhuman,
  title={HyperHuman: Hyper-Realistic Human Generation with Latent Structural Diffusion},
  author={Liu, Xian and Ren, Jian and Siarohin, Aliaksandr and Skorokhodov, Ivan and Li, Yanyu and Lin, Dahua and Liu, Xihui and Liu, Ziwei and Tulyakov, Sergey},
  journal={arXiv preprint arXiv:2310.08579},
  year={2023}
}

@article{li2023snapfusion,
  title={SnapFusion: Text-to-Image Diffusion Model on Mobile Devices within Two Seconds},
  author={Li, Yanyu and Wang, Huan and Jin, Qing and Hu, Ju and Chemerys, Pavlo and Fu, Yun and Wang, Yanzhi and Tulyakov, Sergey and Ren, Jian},
  journal={arXiv preprint arXiv:2306.00980},
  year={2023}
}

@article{karras2022elucidating,
  title={Elucidating the design space of diffusion-based generative models},
  author={Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={26565--26577},
  year={2022}
}

@article{menapace2024snap,
  title={Snap Video: Scaled Spatiotemporal Transformers for Text-to-Video Synthesis},
  author={Menapace, Willi and Siarohin, Aliaksandr and Skorokhodov, Ivan and Deyneka, Ekaterina and Chen, Tsai-Shien and Kag, Anil and Fang, Yuwei and Stoliar, Aleksei and Ricci, Elisa and Ren, Jian and others},
  journal={arXiv preprint arXiv:2402.14797},
  year={2024}
}

@article{ho2022imagen,
  title={Imagen video: High definition video generation with diffusion models},
  author={Ho, Jonathan and Chan, William and Saharia, Chitwan and Whang, Jay and Gao, Ruiqi and Gritsenko, Alexey and Kingma, Diederik P and Poole, Ben and Norouzi, Mohammad and Fleet, David J and others},
  journal={arXiv preprint arXiv:2210.02303},
  year={2022}
}

@article{gupta2023photorealistic,
  title={Photorealistic video generation with diffusion models},
  author={Gupta, Agrim and Yu, Lijun and Sohn, Kihyuk and Gu, Xiuye and Hahn, Meera and Fei-Fei, Li and Essa, Irfan and Jiang, Lu and Lezama, Jos{\'e}},
  journal={arXiv preprint arXiv:2312.06662},
  year={2023}
}

@inproceedings{saharia2022palette,
  title={Palette: Image-to-image diffusion models},
  author={Saharia, Chitwan and Chan, William and Chang, Huiwen and Lee, Chris and Ho, Jonathan and Salimans, Tim and Fleet, David and Norouzi, Mohammad},
  booktitle={ACM SIGGRAPH 2022 Conference Proceedings},
  pages={1--10},
  year={2022}
}
@inproceedings{zhang2023sine,
  title={Sine: Single image editing with text-to-image diffusion models},
  author={Zhang, Zhixing and Han, Ligong and Ghosh, Arnab and Metaxas, Dimitris N and Ren, Jian},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6027--6037},
  year={2023}
}

@article{ruiz2022dreambooth,
  title={DreamBooth: Fine Tuning Text-to-image Diffusion Models for Subject-Driven Generation},
  author={Ruiz, Nataniel and Li, Yuanzhen and Jampani, Varun and Pritch, Yael and Rubinstein, Michael and Aberman, Kfir},
  booktitle={arXiv preprint arxiv:2208.12242},
  year={2022}
}

@article{glide,
  title={Glide: Towards photorealistic image generation and editing with text-guided diffusion models},
  author={Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
  journal={arXiv preprint arXiv:2112.10741},
  year={2021}
}
@article{chang2023muse,
  title={Muse: Text-To-Image Generation via Masked Generative Transformers},
  author={Chang, Huiwen and Zhang, Han and Barber, Jarred and Maschinot, AJ and Lezama, Jose and Jiang, Lu and Yang, Ming-Hsuan and Murphy, Kevin and Freeman, William T and Rubinstein, Michael and others},
  journal={arXiv preprint arXiv:2301.00704},
  year={2023}
}


@article{ediffi,
  title={ediffi: Text-to-image diffusion models with an ensemble of expert denoisers},
  author={Balaji, Yogesh and Nah, Seungjun and Huang, Xun and Vahdat, Arash and Song, Jiaming and Kreis, Karsten and Aittala, Miika and Aila, Timo and Laine, Samuli and Catanzaro, Bryan and others},
  journal={arXiv preprint arXiv:2211.01324},
  year={2022}
}

@article{imagen,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={36479--36494},
  year={2022}
}

@inproceedings{gafni2022make,
  title={Make-a-scene: Scene-based text-to-image generation with human priors},
  author={Gafni, Oran and Polyak, Adam and Ashual, Oron and Sheynin, Shelly and Parikh, Devi and Taigman, Yaniv},
  booktitle={European Conference on Computer Vision},
  pages={89--106},
  year={2022},
  organization={Springer}
}

@article{gokaslan2023commoncanvas,
  title={CommonCanvas: An Open Diffusion Model Trained with Creative-Commons Images},
  author={Gokaslan, Aaron and Cooper, A Feder and Collins, Jasmine and Seguin, Landan and Jacobson, Austin and Patel, Mihir and Frankle, Jonathan and Stephenson, Cory and Kuleshov, Volodymyr},
  journal={arXiv preprint arXiv:2310.16825},
  year={2023}
}
@article{webster2023duplication,
  title={On the De-duplication of LAION-2B},
  author={Webster, Ryan and Rabin, Julien and Simon, Loic and Jurie, Frederic},
  journal={arXiv preprint arXiv:2303.12733},
  year={2023}
}


@article{dalle2,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

@inproceedings{gigagan,
  title={Scaling up gans for text-to-image synthesis},
  author={Kang, Minguk and Zhu, Jun-Yan and Zhang, Richard and Park, Jaesik and Shechtman, Eli and Paris, Sylvain and Park, Taesung},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10124--10134},
  year={2023}
}

@article{girdhar2023emu,
  title={Emu video: Factorizing text-to-video generation by explicit image conditioning},
  author={Girdhar, Rohit and Singh, Mannat and Brown, Andrew and Duval, Quentin and Azadi, Samaneh and Rambhatla, Sai Saketh and Shah, Akbar and Yin, Xi and Parikh, Devi and Misra, Ishan},
  journal={arXiv preprint arXiv:2311.10709},
  year={2023}
}


@inproceedings{hong2023improving,
  title={Improving sample quality of diffusion models using self-attention guidance},
  author={Hong, Susung and Lee, Gyuseong and Jang, Wooseok and Kim, Seungryong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={7462--7471},
  year={2023}
}
@inproceedings{gu2023matryoshka,
  title={Matryoshka diffusion models},
  author={Gu, Jiatao and Zhai, Shuangfei and Zhang, Yizhe and Susskind, Joshua M and Jaitly, Navdeep},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}
@article{chen2023gentron,
  title={GenTron: Delving Deep into Diffusion Transformers for Image and Video Generation},
  author={Chen, Shoufa and Xu, Mengmeng and Ren, Jiawei and Cong, Yuren and He, Sen and Xie, Yanping and Sinha, Animesh and Luo, Ping and Xiang, Tao and Perez-Rua, Juan-Manuel},
  journal={arXiv preprint arXiv:2312.04557},
  year={2023}
}
@inproceedings{peebles2023scalable,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}

@article{sdxl,
  title={Sdxl: Improving latent diffusion models for high-resolution image synthesis},
  author={Podell, Dustin and English, Zion and Lacey, Kyle and Blattmann, Andreas and Dockhorn, Tim and M{\"u}ller, Jonas and Penna, Joe and Rombach, Robin},
  journal={arXiv preprint arXiv:2307.01952},
  year={2023}
}


@article{dai2023emu,
  title={Emu: Enhancing image generation models using photogenic needles in a haystack},
  author={Dai, Xiaoliang and Hou, Ji and Ma, Chih-Yao and Tsai, Sam and Wang, Jialiang and Wang, Rui and Zhang, Peizhao and Vandenhende, Simon and Wang, Xiaofang and Dubey, Abhimanyu and others},
  journal={arXiv preprint arXiv:2309.15807},
  year={2023}
}

@article{sauer2023stylegan,
  title={Stylegan-t: Unlocking the power of gans for fast large-scale text-to-image synthesis},
  author={Sauer, Axel and Karras, Tero and Laine, Samuli and Geiger, Andreas and Aila, Timo},
  journal={arXiv preprint arXiv:2301.09515},
  year={2023}
}
@article{yu2022scaling,
  title={Scaling autoregressive models for content-rich text-to-image generation},
  author={Yu, Jiahui and Xu, Yuanzhong and Koh, Jing Yu and Luong, Thang and Baid, Gunjan and Wang, Zirui and Vasudevan, Vijay and Ku, Alexander and Yang, Yinfei and Ayan, Burcu Karagol and others},
  journal={arXiv preprint arXiv:2206.10789},
  year={2022}
}

@article{ma2023deepcache,
  title={Deepcache: Accelerating diffusion models for free},
  author={Ma, Xinyin and Fang, Gongfan and Wang, Xinchao},
  journal={arXiv preprint arXiv:2312.00858},
  year={2023}
}

@inproceedings{li2023distrifusion,
  title={DistriFusion: Distributed Parallel Inference for High-Resolution Diffusion Models},
  author={Li, Muyang and Cai, Tianle and Cao, Jiaxin and Zhang, Qinsheng and Cai, Han and Bai, Junjie and Jia, Yangqing and Liu, Ming-Yu and Li, Kai and Han, Song},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2024}
}

@article{wimbauer2023cache,
  title={Cache Me if You Can: Accelerating Diffusion Models through Block Caching},
  author={Wimbauer, Felix and Wu, Bichen and Schoenfeld, Edgar and Dai, Xiaoliang and Hou, Ji and He, Zijian and Sanakoyeu, Artsiom and Zhang, Peizhao and Tsai, Sam and Kohler, Jonas and others},
  journal={arXiv preprint arXiv:2312.03209},
  year={2023}
}
@inproceedings{sohl2015deep,
  title={Deep unsupervised learning using nonequilibrium thermodynamics},
  author={Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle={International Conference on Machine Learning},
  pages={2256--2265},
  year={2015},
  organization={PMLR}
}
@article{song2019generative,
  title={Generative modeling by estimating gradients of the data distribution},
  author={Song, Yang and Ermon, Stefano},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{karras2023analyzing,
  title={Analyzing and improving the training dynamics of diffusion models},
  author={Karras, Tero and Aittala, Miika and Lehtinen, Jaakko and Hellsten, Janne and Aila, Timo and Laine, Samuli},
  journal={arXiv preprint arXiv:2312.02696},
  year={2023}
}

@inproceedings{EfficientNetV2,
  title={Efficientnetv2: Smaller models and faster training},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International conference on machine learning},
  pages={10096--10106},
  year={2021},
  organization={PMLR}
}




@inproceedings{EfficientNet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International conference on machine learning},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}




@InProceedings{Liu_2022_CVPR,
    author    = {Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
    title     = {A ConvNet for the 2020s},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {11976-11986}
}


@inproceedings{MobilenetV3,
  title={Searching for mobilenetv3},
  author={Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and others},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={1314--1324},
  year={2019}
}



@article{tu2022maxvit,
  title={MaxViT: Multi-Axis Vision Transformer},
  author={Tu, Zhengzhong and Talebi, Hossein and Zhang, Han and Yang, Feng and Milanfar, Peyman and Bovik, Alan and Li, Yinxiao},
  journal={ECCV},
  year={2022},
}


@article{hendrycks2016gelu,
  title={Gaussian error linear units (gelus)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@inproceedings{SE_Nets_CVPR_2018,
  title={Squeeze-and-excitation networks},
  author={Hu, Jie and Shen, Li and Sun, Gang},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={7132--7141},
  year={2018}
}
@inproceedings{kag2022condensing,
  title={Condensing CNNs with Partial Differential Equations},
  author={Kag, Anil and Saligrama, Venkatesh},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={610--619},
  year={2022}
}
@inproceedings{sun2020neupde,
  title={NeuPDE: Neural network based ordinary and partial differential equations for modeling time-dependent data},
  author={Sun, Yifan and Zhang, Linan and Schaeffer, Hayden},
  booktitle={Mathematical and Scientific Machine Learning},
  pages={352--372},
  year={2020},
  organization={PMLR}
}
@article{chen2018neural,
  title={Neural ordinary differential equations},
  author={Chen, Ricky TQ and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@inproceedings{ding2022scaling,
  title={Scaling up your kernels to 31x31: Revisiting large kernel design in cnns},
  author={Ding, Xiaohan and Zhang, Xiangyu and Han, Jungong and Ding, Guiguang},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11963--11975},
  year={2022}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}
@article{hatamizadeh2023fastervit,
  title={FasterViT: Fast Vision Transformers with Hierarchical Attention},
  author={Hatamizadeh, Ali and Heinrich, Greg and Yin, Hongxu and Tao, Andrew and Alvarez, Jose M and Kautz, Jan and Molchanov, Pavlo},
  journal={arXiv preprint arXiv:2306.06189},
  year={2023}
}

@inproceedings{vit22b-dehghani23a,
  title={Scaling vision transformers to 22 billion parameters},
  author={Dehghani, Mostafa and Djolonga, Josip and Mustafa, Basil and Padlewski, Piotr and Heek, Jonathan and Gilmer, Justin and Steiner, Andreas Peter and Caron, Mathilde and Geirhos, Robert and Alabdulmohsin, Ibrahim and others},
  booktitle={International Conference on Machine Learning},
  pages={7480--7512},
  year={2023},
  organization={PMLR}
}




@misc{touvron2022things,
      title={Three things everyone should know about Vision Transformers}, 
      author={Hugo Touvron and Matthieu Cord and Alaaeldin El-Nouby and Jakob Verbeek and Hervé Jégou},
      year={2022},
      eprint={2203.09795},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{dai2021coatnet,
title={CoAtNet: Marrying Convolution and Attention for All Data Sizes},
author={Zihang Dai and Hanxiao Liu and Quoc V Le and Mingxing Tan},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
}
@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}
@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}
@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@article{minaee2021image,
  title={Image segmentation using deep learning: A survey},
  author={Minaee, Shervin and Boykov, Yuri and Porikli, Fatih and Plaza, Antonio and Kehtarnavaz, Nasser and Terzopoulos, Demetri},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={44},
  number={7},
  pages={3523--3542},
  year={2021},
  publisher={IEEE}
}
@article{jiao2019survey,
  title={A survey of deep learning-based object detection},
  author={Jiao, Licheng and Zhang, Fan and Liu, Fang and Yang, Shuyuan and Li, Lingling and Feng, Zhixi and Qu, Rong},
  journal={IEEE access},
  volume={7},
  pages={128837--128868},
  year={2019},
  publisher={IEEE}
}
@inproceedings{li2023rethinking,
  title={Rethinking vision transformers for mobilenet size and speed},
  author={Li, Yanyu and Hu, Ju and Wen, Yang and Evangelidis, Georgios and Salahi, Kamyar and Wang, Yanzhi and Tulyakov, Sergey and Ren, Jian},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={16889--16900},
  year={2023}
}
@article{li2022efficientformer,
  title={Efficientformer: Vision transformers at mobilenet speed},
  author={Li, Yanyu and Yuan, Geng and Wen, Yang and Hu, Ju and Evangelidis, Georgios and Tulyakov, Sergey and Wang, Yanzhi and Ren, Jian},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={12934--12949},
  year={2022}
}

@article{hatamizadeh2023diffit,
  title={Diffit: Diffusion vision transformers for image generation},
  author={Hatamizadeh, Ali and Song, Jiaming and Liu, Guilin and Kautz, Jan and Vahdat, Arash},
  journal={arXiv preprint arXiv:2312.02139},
  year={2023}
}
@article{wang2020linformer,
  title={Linformer: Self-attention with linear complexity},
  author={Wang, Sinong and Li, Belinda Z and Khabsa, Madian and Fang, Han and Ma, Hao},
  journal={arXiv preprint arXiv:2006.04768},
  year={2020}
}
@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10012--10022},
  year={2021}
}
@inproceedings{dong2022cswin,
  title={Cswin transformer: A general vision transformer backbone with cross-shaped windows},
  author={Dong, Xiaoyi and Bao, Jianmin and Chen, Dongdong and Zhang, Weiming and Yu, Nenghai and Yuan, Lu and Chen, Dong and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12124--12134},
  year={2022}
}
@inproceedings{pan2022edgevits,
  title={Edgevits: Competing light-weight cnns on mobile devices with vision transformers},
  author={Pan, Junting and Bulat, Adrian and Tan, Fuwen and Zhu, Xiatian and Dudziak, Lukasz and Li, Hongsheng and Tzimiropoulos, Georgios and Martinez, Brais},
  booktitle={European Conference on Computer Vision},
  pages={294--311},
  year={2022},
  organization={Springer}
}
@inproceedings{hatamizadeh2023global,
  title={Global context vision transformers},
  author={Hatamizadeh, Ali and Yin, Hongxu and Heinrich, Greg and Kautz, Jan and Molchanov, Pavlo},
  booktitle={International Conference on Machine Learning},
  pages={12633--12646},
  year={2023},
  organization={PMLR}
}
@article{ImageNetILSVRC15,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  pages={211--252},
  year={2015},
  publisher={Springer}
}
@article{xue2024raphael,
  title={Raphael: Text-to-image generation via large mixture of diffusion paths},
  author={Xue, Zeyue and Song, Guanglu and Guo, Qiushan and Liu, Boxiao and Zong, Zhuofan and Liu, Yu and Luo, Ping},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@inproceedings{feng2023ernie,
  title={ERNIE-ViLG 2.0: Improving text-to-image diffusion model with knowledge-enhanced mixture-of-denoising-experts},
  author={Feng, Zhida and Zhang, Zhenyu and Yu, Xintong and Fang, Yewei and Li, Lanxin and Chen, Xuyi and Lu, Yuxiang and Liu, Jiaxiang and Yin, Weichong and Feng, Shikun and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10135--10145},
  year={2023}
}



@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@article{objectDetectionSurvey,
  title={A survey of deep learning-based object detection},
  author={Jiao, Licheng and Zhang, Fan and Liu, Fang and Yang, Shuyuan and Li, Lingling and Feng, Zhixi and Qu, Rong},
  journal={IEEE access},
  volume={7},
  pages={128837--128868},
  year={2019},
  publisher={IEEE}
}

@article{semanticSegmentationSurvey,
  title={Image segmentation using deep learning: A survey},
  author={Minaee, Shervin and Boykov, Yuri and Porikli, Fatih and Plaza, Antonio and Kehtarnavaz, Nasser and Terzopoulos, Demetri},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={44},
  number={7},
  pages={3523--3542},
  year={2021},
  publisher={IEEE}
}

@inproceedings{dit,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}
@inproceedings{kondor2018generalization,
  title={On the generalization of equivariance and convolution in neural networks to the action of compact groups},
  author={Kondor, Risi and Trivedi, Shubhendu},
  booktitle={International Conference on Machine Learning},
  pages={2747--2755},
  year={2018},
  organization={PMLR}
}
@inproceedings{ViT2021dosovitskiy,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
  booktitle={International Conference on Learning Representations},
  year={2021},
}


@article{li2024scalability,
  title={On the Scalability of Diffusion-based Text-to-Image Generation},
  author={Li, Hao and Zou, Yang and Wang, Ying and Majumder, Orchid and Xie, Yusheng and Manmatha, R and Swaminathan, Ashwin and Tu, Zhuowen and Ermon, Stefano and Soatto, Stefano},
  journal={arXiv preprint arXiv:2404.02883},
  year={2024}
}

@inproceedings{hoogeboom2023simple,
  title={simple diffusion: End-to-end diffusion for high resolution images},
  author={Hoogeboom, Emiel and Heek, Jonathan and Salimans, Tim},
  booktitle={International Conference on Machine Learning},
  pages={13213--13232},
  year={2023},
  organization={PMLR}
}

@article{sheynin2023emu,
  title={Emu edit: Precise image editing via recognition and generation tasks},
  author={Sheynin, Shelly and Polyak, Adam and Singer, Uriel and Kirstain, Yuval and Zohar, Amit and Ashual, Oron and Parikh, Devi and Taigman, Yaniv},
  journal={arXiv preprint arXiv:2311.10089},
  year={2023}
}


@article{pixartsigma,
  title={PixArt-$\backslash$Sigma: Weak-to-Strong Training of Diffusion Transformer for 4K Text-to-Image Generation},
  author={Chen, Junsong and Ge, Chongjian and Xie, Enze and Wu, Yue and Yao, Lewei and Ren, Xiaozhe and Wang, Zhongdao and Luo, Ping and Lu, Huchuan and Li, Zhenguo},
  journal={arXiv preprint arXiv:2403.04692},
  year={2024}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}
@inproceedings{rezende2014stochastic,
  title={Stochastic backpropagation and approximate inference in deep generative models},
  author={Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
  booktitle={International conference on machine learning},
  pages={1278--1286},
  year={2014},
  organization={PMLR}
}
@article{chung2024scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Yunxuan and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={70},
  pages={1--53},
  year={2024}
}

@article{esser2024scaling,
  title={Scaling rectified flow transformers for high-resolution image synthesis},
  author={Esser, Patrick and Kulal, Sumith and Blattmann, Andreas and Entezari, Rahim and M{\"u}ller, Jonas and Saini, Harry and Levi, Yam and Lorenz, Dominik and Sauer, Axel and Boesel, Frederic and others},
  journal={arXiv preprint arXiv:2403.03206},
  year={2024}
}

@article{rope,
  title={Roformer: Enhanced transformer with rotary position embedding},
  author={Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal={Neurocomputing},
  volume={568},
  pages={127063},
  year={2024},
  publisher={Elsevier}
}

@article{rmsnorm,
  title={Root mean square layer normalization},
  author={Zhang, Biao and Sennrich, Rico},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}


@inproceedings{uvit,
  title={All are worth words: A vit backbone for diffusion models},
  author={Bao, Fan and Nie, Shen and Xue, Kaiwen and Cao, Yue and Li, Chongxuan and Su, Hang and Zhu, Jun},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22669--22679},
  year={2023}
}

@misc{ghosh2023geneval,
      title={GenEval: An Object-Focused Framework for Evaluating Text-to-Image Alignment}, 
      author={Dhruba Ghosh and Hanna Hajishirzi and Ludwig Schmidt},
      year={2023},
      eprint={2310.11513},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{RandAugment,
 author = {Cubuk, Ekin Dogus and Zoph, Barret and Shlens, Jon and Le, Quoc},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {18613--18624},
 publisher = {Curran Associates, Inc.},
 title = {RandAugment: Practical Automated Data Augmentation with a Reduced Search Space},
 volume = {33},
 year = {2020}
}

@inproceedings{
zhang2018mixup,
title={mixup: Beyond Empirical Risk Minimization},
author={Hongyi Zhang and Moustapha Cisse and Yann N. Dauphin and David Lopez-Paz},
booktitle={International Conference on Learning Representations},
year={2018},
}

@misc{rw2019timm,
  author = {Ross Wightman},
  title = {PyTorch Image Models},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  doi = {10.5281/zenodo.4414861},
  howpublished = {\url{https://github.com/rwightman/pytorch-image-models}}
}

@misc{ridnik2021imagenet21k,
      title={ImageNet-21K Pretraining for the Masses}, 
      author={Tal Ridnik and Emanuel Ben-Baruch and Asaf Noy and Lihi Zelnik-Manor},
      year={2021},
      eprint={2104.10972},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{xiao2018unifiedUperNet,
  title={Unified Perceptual Parsing for Scene Understanding},
  author={Xiao, Tete and Liu, Yingcheng and Zhou, Bolei and Jiang, Yuning and Sun, Jian},
  booktitle={European Conference on Computer Vision},
  year={2018},
  organization={Springer}
}

@misc{mmseg2020,
    title={{MMSegmentation}: OpenMMLab Semantic Segmentation Toolbox and Benchmark},
    author={MMSegmentation Contributors},
    howpublished = {\url{https://github.com/open-mmlab/mmsegmentation}},
    year={2020}
}


@INPROCEEDINGS{ade20k,
  author={Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Scene Parsing through ADE20K Dataset}, 
  year={2017},
  volume={},
  number={},
  pages={5122-5130},
  doi={10.1109/CVPR.2017.544}
}


@inproceedings{
loshchilov2018decoupled,
title={Decoupled Weight Decay Regularization},
author={Ilya Loshchilov and Frank Hutter},
booktitle={International Conference on Learning Representations},
year={2019},
}


@inproceedings{deitPaper,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={International conference on machine learning},
  pages={10347--10357},
  year={2021},
  organization={PMLR}
}

@inproceedings{brock2021high,
  title={High-performance large-scale image recognition without normalization},
  author={Brock, Andy and De, Soham and Smith, Samuel L and Simonyan, Karen},
  booktitle={International Conference on Machine Learning},
  pages={1059--1071},
  year={2021},
  organization={PMLR}
}

@inproceedings{
yang2023moat,
title={{MOAT}: Alternating Mobile Convolution and Attention Brings Strong Vision Models},
author={Chenglin Yang and Siyuan Qiao and Qihang Yu and Xiaoding Yuan and Yukun Zhu and Alan Yuille and Hartwig Adam and Liang-Chieh Chen},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=H0HGljkxQFN}
}

@misc{lin2023scaleaware,
      title={Scale-Aware Modulation Meet Transformer}, 
      author={Weifeng Lin and Ziheng Wu and Jiayu Chen and Jun Huang and Lianwen Jin},
      year={2023},
      eprint={2307.08579},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{cai2022efficientvit,
  title={Efficientvit: Enhanced linear attention for high-resolution low-computation visual recognition},
  author={Cai, Han and Gan, Chuang and Han, Song},
  journal={arXiv preprint arXiv:2205.14756},
  year={2022}
}

@misc{kim2024densenets,
    title={DenseNets Reloaded: Paradigm Shift Beyond ResNets and ViTs}, 
    author={Donghyun Kim and Byeongho Heo and Dongyoon Han},
    year={2024},
    eprint={2403.19588},
    archivePrefix={arXiv},
}

@inproceedings{iclr2024MogaNet,
  title={MogaNet: Multi-order Gated Aggregation Network},
  author={Siyuan Li and Zedong Wang and Zicheng Liu and Cheng Tan and Haitao Lin and Di Wu and Zhiyuan Chen and Jiangbin Zheng and Stan Z. Li},
  booktitle={International Conference on Learning Representations},
  year={2024}
}

@inproceedings{fan2023rmt,
  title={RMT: Retentive Networks Meet Vision Transformers},
  author={Qihang Fan and Huaibo Huang and Mingrui Chen and Hongmin Liu and Ran He},
  booktitle={CVPR},
  year={2024}
}

@Article{zhu2023biformer,
  author  = {Lei Zhu and Xinjiang Wang and Zhanghan Ke and Wayne Zhang and Rynson Lau},
  title   = {BiFormer: Vision Transformer with Bi-Level Routing Attention},
  journal = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year    = {2023},
}

@InProceedings{blip2_paper,
  title = 	 {{BLIP}-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models},
  author =       {Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {19730--19742},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/li23q/li23q.pdf},
  url = 	 {https://proceedings.mlr.press/v202/li23q.html},
  abstract = 	 {The cost of vision-and-language pre-training has become increasingly prohibitive due to end-to-end training of large-scale models. This paper proposes BLIP-2, a generic and efficient pre-training strategy that bootstraps vision-language pre-training from off-the-shelf frozen pre-trained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pre-trained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various vision-language tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model’s emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions.}
}


@article{pvt_v2_Wang_2022,
   title={PVT v2: Improved baselines with Pyramid Vision Transformer},
   volume={8},
   ISSN={2096-0662},
   DOI={10.1007/s41095-022-0274-8},
   number={3},
   journal={Computational Visual Media},
   publisher={Springer Science and Business Media LLC},
   author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
   year={2022},
   month=mar, pages={415–424} }


@article{heusel2017gans,
  title={Gans trained by a two time-scale update rule converge to a local nash equilibrium},
  author={Heusel, Martin and Ramsauer, Hubert and Unterthiner, Thomas and Nessler, Bernhard and Hochreiter, Sepp},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{cfg,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint arXiv:2207.12598},
  year={2022}
}