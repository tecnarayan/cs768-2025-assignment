@inproceedings{radford2015unsupervised,
  title={Unsupervised representation learning with deep convolutional generative adversarial networks},
  author={Radford, A. and Metz, L. and Chintala, S.},
  year={2016},
  booktitle = {ICLR}
}

@article{thrampoulidis2018precise,
  title={Precise Error Analysis of Regularized $ M $-Estimators in High Dimensions},
  author={Thrampoulidis, Christos and Abbasi, Ehsan and Hassibi, Babak},
  journal={IEEE Transactions on Information Theory},
  volume={64},
  number={8},
  pages={5592--5628},
  year={2018},
  publisher={IEEE}
}

@article{deng2019model,
  title={A model of double descent for high-dimensional binary linear classification},
  author={Deng, Zeyu and Kammoun, Abla and Thrampoulidis, Christos},
  journal={arXiv preprint arXiv:1911.05822},
  year={2019}
}

@article{mitra2019understanding,
  title={Understanding overfitting peaks in generalization error: Analytical risk curves for $ l\_2 $ and $ l\_1 $ penalized interpolation},
  author={Mitra, Partha P},
  journal={arXiv preprint arXiv:1906.03667},
  year={2019}
}

@article{kini2020analytic,
  title={Analytic study of double descent in binary classification: The impact of loss},
  author={Kini, Ganesh and Thrampoulidis, Christos},
  journal={arXiv preprint arXiv:2001.11572},
  year={2020}
}

@article{montanari2019generalization,
  title={The generalization error of max-margin linear classifiers: High-dimensional asymptotics in the overparametrized regime},
  author={Montanari, Andrea and Ruan, Feng and Sohn, Youngtak and Yan, Jun},
  journal={arXiv preprint arXiv:1911.01544},
  year={2019}
}

@book{mezard2009information,
  title={Information, physics, and computation},
  author={M\'ezard, Marc and Montanari, Andrea},
  year={2009},
  publisher={Oxford University Press}
}

@incollection{opper1996statistical,
  title={Statistical mechanics of generalization},
  author={Opper, Manfred and Kinzel, Wolfgang},
  booktitle={Models of neural networks III},
  pages={151--209},
  year={1996},
  publisher={Springer}
}


@article{donoho2016high,
  title={High dimensional robust m-estimation: Asymptotic variance via approximate message passing},
  author={Donoho, David and Montanari, Andrea},
  journal={Probability Theory and Related Fields},
  volume={166},
  number={3-4},
  pages={935--969},
  year={2016},
  publisher={Springer}
}
@article{el2013robust,
  title={On robust regression with high-dimensional predictors},
  author={El Karoui, Noureddine and Bean, Derek and Bickel, Peter J and Lim, Chinghway and Yu, Bin},
  journal={Proceedings of the National Academy of Sciences},
  volume={110},
  number={36},
  pages={14557--14562},
  year={2013},
  publisher={National Acad Sciences}
}

@article{bayati2011dynamics,
  title={The dynamics of message passing on dense graphs, with applications to compressed sensing},
  author={Bayati, Mohsen and Montanari, Andrea},
  journal={IEEE Transactions on Information Theory},
  volume={57},
  number={2},
  pages={764--785},
  year={2011},
  publisher={IEEE}
}

@article{gardner1989three,
  title={Three unfinished works on the optimal storage capacity of networks},
  author={Gardner, Elizabeth and Derrida, Bernard},
  journal={Journal of Physics A: Mathematical and General},
  volume={22},
  number={12},
  pages={1983},
  year={1989},
  publisher={IOP Publishing}
}

@article{zdeborova2020understanding,
  title={Understanding deep learning is also a job for physicists},
  author={Zdeborov{\'a}, Lenka},
  journal={Nature Physics},
  pages={1--3},
  year={2020},
  publisher={Nature Publishing Group}
}

@book{engel2001statistical,
  title={Statistical mechanics of learning},
  author={Engel, Andreas and Van den Broeck, Christian},
  year={2001},
  publisher={Cambridge University Press}
}

@article{creswell2018generative,
  title={Generative adversarial networks: An overview},
  author={Creswell, Antonia and White, Tom and Dumoulin, Vincent and Arulkumaran, Kai and Sengupta, Biswa and Bharath, Anil A},
  journal={IEEE Signal Processing Magazine},
  volume={35},
  number={1},
  pages={53--65},
  year={2018},
  publisher={IEEE}
}
@inproceedings{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  booktitle={Advances in neural information processing systems},
  pages={8571--8580},
  year={2018}
}
@article{andreux2020kymatio,
  title={Kymatio: Scattering Transforms in Python.},
  author={Andreux, Mathieu and Angles, Tom{\'a}s and Exarchakis, Georgios and Leonarduzzi, Roberto and Rochette, Gaspar and Thiry, Louis and Zarka, John and Mallat, St{\'e}phane and And{\'e}n, Joakim and Belilovsky, Eugene and others},
  journal={Journal of Machine Learning Research},
  volume={21},
  number={60},
  pages={1--6},
  year={2020}
}
@inproceedings{rahimi2008random,
  title={Random features for large-scale kernel machines},
  author={Rahimi, Ali and Recht, Benjamin},
  booktitle={Advances in neural information processing systems},
  pages={1177--1184},
  year={2008}
}

@article{watkin1993statistical,
  title={The statistical mechanics of learning a rule},
  author={Watkin, Timothy LH and Rau, Albrecht and Biehl, Michael},
  journal={Reviews of Modern Physics},
  volume={65},
  number={2},
  pages={499},
  year={1993},
  publisher={APS}
}

@article{seung1992statistical,
  title={Statistical mechanics of learning from examples},
  author={Seung, Hyunjune Sebastian and Sompolinsky, Haim and Tishby, Naftali},
  journal={Physical review A},
  volume={45},
  number={8},
  pages={6056},
  year={1992},
  publisher={APS}
}

@article{celentano2020lasso,
  title={The Lasso with general Gaussian designs with applications to hypothesis testing},
  author={Celentano, Michael and Montanari, Andrea and Wei, Yuting},
  journal={arXiv preprint arXiv:2007.13716},
  year={2020}
}
@inproceedings{salehi2020performance,
  title={The Performance Analysis of Generalized Margin Maximizers on Separable Data},
  author={Salehi, Fariborz and Abbasi, Ehsan and Hassibi, Babak},
  booktitle={International Conference on Machine Learning},
  pages={8417--8426},
  year={2020},
  organization={PMLR}
}

@inproceedings{pennington2017nonlinear,
 author = {Pennington, Jeffrey and Worah, Pratik},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {2637--2646},
 title = {Nonlinear random matrix theory for deep learning},
  volume = {30},
 year = {2017}
}

@article{fan2019spectral,
  title={The spectral norm of random inner-product kernel matrices},
  author={Fan, Zhou and Montanari, Andrea},
  journal={Probability Theory and Related Fields},
  volume={173},
  number={1},
  pages={27--85},
  year={2019},
  publisher={Springer}
}

@article{cheng2013spectrum,
  title={The spectrum of random inner-product kernel matrices},
  author={Cheng, Xiuyuan and Singer, Amit},
  journal={Random Matrices: Theory and Applications},
  volume={2},
  number={04},
  pages={1350010},
  year={2013},
  publisher={World Scientific}
}


@inproceedings{aubin2020generalization,
  title={Generalization error in high-dimensional perceptrons: Approaching Bayes error with convex optimization},
  author={Aubin, Benjamin and Krzakala, Florent and Lu, Yue M and Zdeborov{\'a}, Lenka},
 booktitle = {Advances in Neural Information Processing Systems},
 volume={33},
  year={2020}
}

@book{bauschke2011convex,
  title={Convex analysis and monotone operator theory in Hilbert spaces},
  author={Bauschke, Heinz H and Combettes, Patrick L and others},
  volume={408},
  year={2011},
  publisher={Springer}
}

@article{louart2018concentration,
  title={Concentration of measure and large random matrices with an application to sample covariance matrices},
  author={Louart, Cosme and Couillet, Romain},
  journal={arXiv preprint arXiv:1805.08295},
  year={2018}
}

@inproceedings{liao2020random,
  title={A random matrix analysis of random Fourier features: beyond the Gaussian kernel, a precise phase transition, and the corresponding double descent},
  author={Liao, Zhenyu and Couillet, Romain and Mahoney, Michael W},
 booktitle = {Advances in Neural Information Processing Systems},
 volume={33},
  year={2020}
}

@article{el2009concentration,
  title={Concentration of measure and spectra of random matrices: Applications to correlation matrices, elliptical distributions and beyond},
  author={El Karoui, Noureddine and others},
  journal={Annals of Applied Probability},
  volume={19},
  number={6},
  pages={2362--2405},
  year={2009},
  publisher={Institute of Mathematical Statistics}
}

@article{el2010spectrum,
  title={The spectrum of kernel random matrices},
  author={El Karoui, Noureddine and others},
  journal={Annals of statistics},
  volume={38},
  number={1},
  pages={1--50},
  year={2010},
  publisher={Institute of Mathematical Statistics}
}

@article{chafai2018convergence,
  title={On the convergence of the extremal eigenvalues of empirical covariance matrices with dependence},
  author={Chafa{\"\i}, Djalil and Tikhomirov, Konstantin},
  journal={Probability Theory and Related Fields},
  volume={170},
  number={3},
  pages={847--889},
  year={2018},
  publisher={Springer}
}

@article{bai2008large,
  title={Large sample covariance matrices without independence structures in columns},
  author={Bai, Zhidong and Zhou, Wang},
  journal={Statistica Sinica},
  pages={425--442},
  year={2008},
  publisher={JSTOR}
}

@article{cover1965geometrical,
  title={Geometrical and statistical properties of systems of linear inequalities with applications in pattern recognition},
  author={Cover, Thomas M},
  journal={IEEE transactions on electronic computers},
  volume = {EC-14},
  number={3},
  pages={326--334},
  year={1965},
  publisher={IEEE}
}

@inproceedings{gerace2020generalisation,
  author={Gerace, F. and Loureiro, B. and Krzakala, F. and M{\'e}zard, M. and Zdeborov{\'a}, L.},
  booktitle = "37th International Conference on Machine Learning",
 title={Generalisation error in learning with random features and the hidden manifold model},
  year={2020}
}

@article{zdeborova2016statistical,
  title={Statistical physics of inference: Thresholds and algorithms},
  author={Zdeborov{\'a}, Lenka and Krzakala, Florent},
  journal={Advances in Physics},
  volume={65},
  number={5},
  pages={453--552},
  year={2016},
  publisher={Taylor \& Francis}
}

@inproceedings{oymak2013squared,
  title={The squared-error of generalized lasso: A precise analysis},
  author={Oymak, Samet and Thrampoulidis, Christos and Hassibi, Babak},
  booktitle={2013 51st Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  pages={1002--1009},
  year={2013},
  organization={IEEE}
}

@inproceedings{williams96,
author = {Williams, Christopher K. I.},
title = {Computing with Infinite Networks},
year = {1996},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
booktitle = {Proceedings of the 9th International Conference on Neural Information Processing Systems},
pages = {295–301},
numpages = {7},
location = {Denver, Colorado},
series = {NIPS'96}
}

@article{miolane2018distribution,
  title={The distribution of the lasso: Uniform control over sparse balls and adaptive parameter tuning},
  author={Miolane, L{\'e}o and Montanari, Andrea},
  journal={arXiv preprint arXiv:1811.01212},
  year={2018}
}

@article{stojnic2013framework,
  title={A framework to characterize performance of lasso algorithms},
  author={Stojnic, Mihailo},
  journal={arXiv preprint arXiv:1303.7291},
  year={2013}
}

@article{goldt2020modelling,
  title={Modeling the influence of data structure on learning in neural networks: The hidden manifold model},
  author={Goldt, S. and M{\'e}zard, M. and Krzakala, F. and Zdeborov{\'a}, L.},
  journal = {Phys. Rev. X},
  volume={10},
  number={4},
  pages={041044},
  year={2020}
}

@article{liu2020kernel,
  title={Kernel regression in high dimension: Refined analysis beyond double descent},
  author={Liu, Fanghui and Liao, Zhenyu and Suykens, Johan AK},
  journal={arXiv preprint arXiv:2010.02681},
  year={2020}
}

@article{hachem2007deterministic,
  title={Deterministic equivalents for certain functionals of large random matrices},
  author={Hachem, Walid and Loubaton, Philippe and Najim, Jamal and others},
  journal={The Annals of Applied Probability},
  volume={17},
  number={3},
  pages={875--930},
  year={2007},
  publisher={Institute of Mathematical Statistics}
}

@inproceedings{goldt2020gaussian,
  title={The Gaussian equivalence of generative models for learning with two-layer neural networks},
  author={Goldt, Sebastian and Loureiro, Bruno and Reeves, Galen and M{\'e}zard, Marc and Krzakala, Florent and Zdeborov{\'a}, Lenka},
  booktitle={Mathematical and Scientific Machine Learning},
  year={2021}
}

@book{durrett2019probability,
  title={Probability: theory and examples},
  author={Durrett, Rick},
  volume={49},
  year={2019},
  publisher={Cambridge university press}
}

@ARTICLE{bruna2012,  author={J. {Bruna} and S. {Mallat}},  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},   title={Invariant Scattering Convolution Networks},   year={2013},  volume={35},  number={8},  pages={1872-1886},  doi={10.1109/TPAMI.2012.230}}

@book{scholkopf2018learning,
  title={Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond},
  author={Scholkopf, B. and Smola, A.J.},
  series={Adaptive Computation and Machine Learning},
  year={2018},
  publisher={MIT Press}
}

@article{hu2020universality,
  title={Universality laws for high-dimensional learning with random features},
  author={Hu, Hong and Lu, Yue M},
  journal={arXiv preprint arXiv:2009.07669},
  year={2020}
} 

@article{dhifallah2020precise,
  title={A precise performance analysis of learning with random features},
  author={Dhifallah, Oussama and Lu, Yue M},
  journal={arXiv preprint arXiv:2008.11904},
  year={2020}
}


@book{boucheron2013concentration,
  title={Concentration inequalities: A nonasymptotic theory of independence},
  author={Boucheron, St{\'e}phane and Lugosi, G{\'a}bor and Massart, Pascal},
  year={2013},
  publisher={Oxford university press}
}

@article{gordon1985some,
  title={Some inequalities for Gaussian processes and applications},
  author={Gordon, Yehoram},
  journal={Israel Journal of Mathematics},
  volume={50},
  number={4},
  pages={265--289},
  year={1985},
  publisher={Springer}
}

@book{vershynin2018high,
  title={High-dimensional probability: An introduction with applications in data science},
  author={Vershynin, Roman},
  volume={47},
  year={2018},
  publisher={Cambridge university press}
}

@incollection{vershynin2010introduction,
author = {Vershynin, Roman},
booktitle = {Compressed Sensing, Theory and Applications},
editor = {Eldar, Y. and Kutyniok., G.},
mendeley-groups = {Neuroscience/Continual Learning},
publisher = {Cambridge University Press},
title = {{Introduction to the non-asymptotic analysis of random matrices}},
year = {2012}
}

@book{mezard1987spin,
  title={Spin glass theory and beyond: An Introduction to the Replica Method and Its Applications},
  author={M{\'e}zard, Marc and Parisi, Giorgio and Virasoro, Miguel},
  volume={9},
  year={1987},
  publisher={World Scientific Publishing Company}
}

@online{xiao2017,
  author       = {Han Xiao and Kashif Rasul and Roland Vollgraf},
  title        = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},
  date         = {2017-08-28},
  year         = {2017},
  eprintclass  = {cs.LG},
  eprinttype   = {arXiv},
  eprint       = {cs.LG/1708.07747},
}

@article{dobriban2018high,
  title={High-dimensional asymptotics of prediction: Ridge regression and classification},
  author={Dobriban, Edgar and Wager, Stefan and others},
  journal={The Annals of Statistics},
  volume={46},
  number={1},
  pages={247--279},
  year={2018},
  publisher={Institute of Mathematical Statistics}
}
@article{spigler2019asymptotic,
	year = 2020,
	volume = {2020},
	number = {12},
	pages = {124001},
	author = {Stefano Spigler and Mario Geiger and Matthieu Wyart},
	title = {Asymptotic learning curves of kernel methods: empirical data versus teacher{\textendash}student paradigm},
	journal = {Journal of Statistical Mechanics: Theory and Experiment},
}

@article{spigler2019jamming,
  title={A jamming transition from under-to over-parametrization affects generalization in deep learning},
  author={Spigler, Stefano and Geiger, Mario and d’Ascoli, St{\'e}phane and Sagun, Levent and Biroli, Giulio and Wyart, Matthieu},
  journal={Journal of Physics A: Mathematical and Theoretical},
  volume={52},
  number={47},
  pages={474001},
  year={2019},
  publisher={IOP Publishing}
}

@inproceedings{seddik2020random,
  title={Random matrix theory proves that deep learning representations of gan-data behave as gaussian mixtures},
  author={Seddik, Mohamed El Amine and Louart, Cosme and Tamaazousti, Mohamed and Couillet, Romain},
  booktitle={International Conference on Machine Learning},
  pages={8573--8582},
  year={2020},
  organization={PMLR}
}

@article{huang2020large,
  title={Large scale analysis of generalization error in learning using margin based classification methods},
  author={Huang, Hanwen and Yang, Qinglong},
  journal={Journal of Statistical Mechanics: Theory and Experiment},
  volume={2020},
  number={10},
  pages={103407},
  year={2020},
  publisher={IOP Publishing}
}

@inproceedings{bordelon2020,
  title={Spectrum dependent learning curves in kernel regression and wide neural networks},
  author={Bordelon, Blake and Canatar, Abdulkadir and Pehlevan, Cengiz},
  booktitle={International Conference on Machine Learning},
  pages={1024--1034},
  year={2020},
  organization={PMLR}
}

@article{donoho2009message,
  title={Message-passing algorithms for compressed sensing},
  author={Donoho, David L and Maleki, Arian and Montanari, Andrea},
  journal={Proceedings of the National Academy of Sciences},
  volume={106},
  number={45},
  pages={18914--18919},
  year={2009},
  publisher={National Acad Sciences}
}

@inproceedings{wu2020optimal,
  title={On the Optimal Weighted $\ell_2$ Regularization in Overparameterized Linear Regression},
  author={Wu, Denny and Xu, Ji},
  year={2020},
  volume={33},
  booktitle = {Advances in Neural Information Processing Systems}
}

@article{marchenko1967distribution,
  title={Distribution of eigenvalues for some sets of random matrices},
  author={Marchenko, Vladimir Alexandrovich and Pastur, Leonid Andreevich},
  journal={Matematicheskii Sbornik},
  volume={114},
  number={4},
  pages={507--536},
  year={1967},
  publisher={Russian Academy of Sciences, Steklov Mathematical Institute of Russian~…}
}

@book{anderson2010introduction,
  title={An introduction to random matrices},
  author={Anderson, Greg W and Guionnet, Alice and Zeitouni, Ofer},
  number={118},
  year={2010},
  publisher={Cambridge university press}
}
@article{ledoit2011eigenvectors,
  title={Eigenvectors of some large sample covariance matrix ensembles},
  author={Ledoit, Olivier and P{\'e}ch{\'e}, Sandrine},
  journal={Probability Theory and Related Fields},
  volume={151},
  number={1},
  pages={233--264},
  year={2011},
  publisher={Springer}
}

@article{belkin2020two,
  title={Two models of double descent for weak features},
  author={Belkin, Mikhail and Hsu, Daniel and Xu, Ji},
  journal={SIAM Journal on Mathematics of Data Science},
  volume={2},
  number={4},
  pages={1167--1180},
  year={2020},
  publisher={SIAM}
}


@inproceedings{ghorbani2019limitations,
 author = {Ghorbani, Behrooz and Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {9111--9121},
 title = {Limitations of Lazy Training of Two-layers Neural Network},
 volume = {32},
 year = {2019}
}

@inproceedings{ghorbani2020neural,
 booktitle = {Advances in Neural Information Processing Systems},
  title={When do neural networks outperform kernel methods?},
  author={Ghorbani, Behrooz and Mei, Song and Misiakiewicz, Theodor and Montanari, Andrea},
  volume = {33},
  year = {2020}
}

@article{hastie2019surprises,
  title={Surprises in high-dimensional ridgeless least squares interpolation},
  author={Hastie, Trevor and Montanari, Andrea and Rosset, Saharon and Tibshirani, Ryan J},
  journal={arXiv preprint arXiv:1903.08560},
  year={2019}
}
@article{belkin2019reconciling,
  title={Reconciling modern machine-learning practice and the classical bias--variance trade-off},
  author={Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={32},
  pages={15849--15854},
  year={2019},
  publisher={National Acad Sciences}
}
@inproceedings{zhang2016understanding,
  author = {Zhang, C. and Bengio, S. and Hardt, M. and Recht, B. and Vinyals, O.},
  booktitle = {ICLR},
  title = {{Understanding deep learning requires rethinking generalization}},
  year = {2017}
}

@article{mei2019generalization,
  title={The generalization error of random features regression: Precise asymptotics and double descent curve},
  author={Mei, Song and Montanari, Andrea},
  journal={arXiv preprint arXiv:1908.05355},
  year={2019}
}

@article{candes2020phase,
  title={The phase transition for the existence of the maximum likelihood estimate in high-dimensional logistic regression},
  author={Cand{\`e}s, Emmanuel J and Sur, Pragya and others},
  journal={The Annals of Statistics},
  volume={48},
  number={1},
  pages={27--42},
  year={2020},
  publisher={Institute of Mathematical Statistics}
}

@article{andersen1982cox,
  title={Cox's regression model for counting processes: a large sample study},
  author={Andersen, Per Kragh and Gill, Richard D},
  journal={The annals of statistics},
  pages={1100--1120},
  year={1982},
  publisher={JSTOR}
}
@inproceedings{gerbelot2020colt,
  title={Asymptotic Errors for High-Dimensional Convex Penalized Linear Regression beyond Gaussian Matrices},
  author={Gerbelot, C{\'e}dric and Abbara, Alia and Krzakala, Florent},
  booktitle={Conference on Learning Theory},
  pages={1682--1713},
  year={2020},
  organization={PMLR}
}
@article{jacot2020kernel,
  title={Kernel Alignment Risk Estimator: Risk Prediction from Training Data},
  author={Jacot, Arthur and {\c{S}}im{\c{s}}ek, Berfin and Spadaro, Francesco and Hongler, Cl{\'e}ment and Gabriel, Franck},
  journal={arXiv preprint arXiv:2006.09796},
  year={2020}
}

@article {Bartlett30063,
	author = {Bartlett, Peter L. and Long, Philip M. and Lugosi, G{\'a}bor and Tsigler, Alexander},
	title = {Benign overfitting in linear regression},
	volume = {117},
	number = {48},
	pages = {30063--30070},
	year = {2020},
	doi = {10.1073/pnas.1907378117},
	publisher = {National Academy of Sciences},
	abstract = {The phenomenon of benign overfitting is one of the key mysteries uncovered by deep learning methodology: deep neural networks seem to predict well, even with a perfect fit to noisy training data. Motivated by this phenomenon, we consider when a perfect fit to training data in linear regression is compatible with accurate prediction. We give a characterization of linear regression problems for which the minimum norm interpolating prediction rule has near-optimal prediction accuracy. The characterization is in terms of two notions of the effective rank of the data covariance. It shows that overparameterization is essential for benign overfitting in this setting: the number of directions in parameter space that are unimportant for prediction must significantly exceed the sample size. By studying examples of data covariance properties that this characterization shows are required for benign overfitting, we find an important role for finite-dimensional data: the accuracy of the minimum norm interpolating prediction rule approaches the best possible accuracy for a much narrower range of properties of the data distribution when the data lie in an infinite-dimensional space vs. when the data lie in a finite-dimensional space with dimension that grows faster than the sample size.},
	issn = {0027-8424},
	URL = {https://www.pnas.org/content/117/48/30063},
	eprint = {https://www.pnas.org/content/117/48/30063.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}


@article{gerbelot2020asymptotic,
  title={Asymptotic Errors for Teacher-Student Convex Generalized Linear Models (or: How to Prove Kabashima's Replica Formula)},
  author={Gerbelot, Cedric and Abbara, Alia and Krzakala, Florent},
  journal={arXiv preprint arXiv:2006.06581},
  year={2020}
}

@article{kaiminginit,
  title={Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification},
  author={He,Kaiming  and Zhang,Xiangyu and Ren,Shaoqing  and Sun,Jian },
  journal={2015 IEEE International Conference on Computer Vision (ICCV)},
  year={2015},
  pages={1026-1034}
}

@inproceedings{Adam,
  title={Adam: A Method for Stochastic Optimization},
  author={Kingma,Diederik P. and Ba,Jimmy },
  booktitle = {Proceedings of the 3rd International Conference for Learning Representations},
  year={2015},
  volume={3}
}


@inproceedings{rosset2003margin,
  title={Margin Maximizing Loss Functions.},
  author={Rosset, Saharon and Zhu, Ji and Hastie, Trevor},
  booktitle={NIPS},
  pages={1237--1244},
  year={2003}
}

@inproceedings{pillaud2018statistical,
 author = {Pillaud-Vivien, Loucas and Rudi, Alessandro and Bach, Francis},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {8114--8124},
 title = {Statistical Optimality of Stochastic Gradient Descent on Hard Learning Problems through Multiple Passes},
  volume = {31},
 year = {2018}
}

@article{caponnetto2007optimal,
  title={Optimal rates for the regularized least-squares algorithm},
  author={Caponnetto, Andrea and De Vito, Ernesto},
  journal={Foundations of Computational Mathematics},
  volume={7},
  number={3},
  pages={331--368},
  year={2007},
  publisher={Springer}
}

@inproceedings{steinwart2009optimal,
  title={Optimal Rates for Regularized Least Squares Regression.},
  author={Steinwart, Ingo and Hush, Don R and Scovel, Clint and others},
  booktitle={COLT},
  pages={79--93},
  year={2009}
}

 @InProceedings{bottou2017, 
 title = {{W}asserstein Generative Adversarial Networks}, 
 author = {Martin Arjovsky and Soumith Chintala and L{\'e}on Bottou}, booktitle = {Proceedings of the 34th International Conference on Machine Learning}, 
 pages = {214--223}, 
 year = {2017}, 
 editor = {Doina Precup and Yee Whye Teh}, 
 volume = {70}, series = {Proceedings of Machine Learning Research}, 
 address = {International Convention Centre, Sydney, Australia}, 
 month = {06--11 Aug}, 
 publisher = {PMLR}
 } 

@inproceedings{arora2018,
  author    = {Sanjeev Arora and
               Andrej Risteski and
               Yi Zhang},
  title     = {Do GANs learn the distribution? Some Theory and Empirics},
  booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
               Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings},
  year      = {2018}
}

@misc{goodfellow2014generative,
      title={Generative Adversarial Networks}, 
      author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
      year={2014},
      eprint={1406.2661},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@inproceedings{ma2017analysis,
  title={Analysis of approximate message passing with a class of non-separable denoisers},
  author={Ma, Yanting and Rush, Cynthia and Baron, Dror},
  booktitle={2017 IEEE International Symposium on Information Theory (ISIT)},
  pages={231--235},
  year={2017},
  organization={IEEE}
}

}

@article{opper99,
  title = {Statistical Mechanics of Support Vector Networks},
  author = {Dietrich, Rainer and Opper, Manfred and Sompolinsky, Haim},
  journal = {Phys. Rev. Lett.},
  volume = {82},
  issue = {14},
  pages = {2975--2978},
  numpages = {0},
  year = {1999},
  month = {Apr},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.82.2975},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.82.2975}
}

@article{opper01,
  title = {Universal Learning Curves of Support Vector Machines},
  author = {Opper, M. and Urbanczik, R.},
  journal = {Phys. Rev. Lett.},
  volume = {86},
  issue = {19},
  pages = {4410--4413},
  numpages = {0},
  year = {2001},
  month = {May},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.86.4410},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.86.4410}
}
