\begin{thebibliography}{69}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Lillicrap and Kording(2019)]{lillicrap2019does}
T.~P. Lillicrap and K.~P. Kording.
\newblock What does it mean to understand a neural network?
\newblock \emph{arXiv preprint arXiv:1907.06374}, 2019.

\bibitem[Szegedy et~al.(2013)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
C.~Szegedy, W.~Zaremba, I.~Sutskever, J.~Bruna, D.~Erhan, I.~Goodfellow, and
  R.~Fergus.
\newblock Intriguing properties of neural networks.
\newblock \emph{arXiv preprint arXiv:1312.6199}, 2013.

\bibitem[Ilyas et~al.(2019)Ilyas, Santurkar, Tsipras, Engstrom, Tran, and
  Madry]{ilyas2019adversarial}
A.~Ilyas, S.~Santurkar, D.~Tsipras, L.~Engstrom, B.~Tran, and A.~Madry.
\newblock Adversarial examples are not bugs, they are features.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  125--136, 2019.

\bibitem[Geirhos et~al.(2020{\natexlab{a}})Geirhos, Jacobsen, Michaelis, Zemel,
  Brendel, Bethge, and Wichmann]{geirhos2020shortcut}
R.~Geirhos, J.-H. Jacobsen, C.~Michaelis, R.~Zemel, W.~Brendel, M.~Bethge, and
  F.~A. Wichmann.
\newblock Shortcut learning in deep neural networks.
\newblock \emph{{Nature Machine Intelligence}}, in press, 2020{\natexlab{a}}.

\bibitem[Mausfeld(2003)]{Mausfeld_2003a}
R.~Mausfeld.
\newblock No {Psychology} {In} - {No} {Psychology} {Out}.
\newblock \emph{Psychologische Rundschau}, 54\penalty0 (3):\penalty0 185--191,
  2003.

\bibitem[Zeiler and Fergus(2014)]{zeiler2014visualizing}
M.~D. Zeiler and R.~Fergus.
\newblock Visualizing and understanding convolutional networks.
\newblock In \emph{European conference on computer vision}, pages 818--833.
  Springer, 2014.

\bibitem[Zintgraf et~al.(2017)Zintgraf, Cohen, Adel, and
  Welling]{zintgraf2017visualizing}
L.~M. Zintgraf, T.~S. Cohen, T.~Adel, and M.~Welling.
\newblock Visualizing deep neural network decisions: Prediction difference
  analysis.
\newblock \emph{arXiv preprint arXiv:1702.04595}, 2017.

\bibitem[Olah et~al.(2020)Olah, Cammarata, Schubert, Goh, Petrov, and
  Carter]{olah2020zoom}
C.~Olah, N.~Cammarata, L.~Schubert, G.~Goh, M.~Petrov, and S.~Carter.
\newblock Zoom in: An introduction to circuits.
\newblock \emph{Distill}, 5\penalty0 (3):\penalty0 e00024--001, 2020.

\bibitem[Nie et~al.(2018)Nie, Zhang, and Patel]{nie2018theoretical}
W.~Nie, Y.~Zhang, and A.~Patel.
\newblock A theoretical explanation for perplexing behaviors of
  backpropagation-based visualizations.
\newblock \emph{arXiv preprint arXiv:1805.07039}, 2018.

\bibitem[Adebayo et~al.(2018)Adebayo, Gilmer, Muelly, Goodfellow, Hardt, and
  Kim]{adebayo2018sanity}
J.~Adebayo, J.~Gilmer, M.~Muelly, I.~Goodfellow, M.~Hardt, and B.~Kim.
\newblock Sanity checks for saliency maps.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  9505--9515, 2018.

\bibitem[Geirhos et~al.(2019)Geirhos, Rubisch, Michaelis, Bethge, Wichmann, and
  Brendel]{geirhos2019imagenettrained}
R.~Geirhos, P.~Rubisch, C.~Michaelis, M.~Bethge, Felix~A. Wichmann, and
  W.~Brendel.
\newblock {ImageNet}-trained {CNN}s are biased towards texture; increasing
  shape bias improves accuracy and robustness.
\newblock In \emph{{International Conference on Learning Representations}},
  2019.

\bibitem[Marr(1982)]{marr1982vision}
D.~Marr.
\newblock \emph{Vision: A computational investigation into the human
  representation and processing of visual information}.
\newblock W.H.Freeman \& Co Ltd, San Francisco, 1982.

\bibitem[Reichenbach(1956)]{reichenbach1956direction}
Hans Reichenbach.
\newblock \emph{The direction of time}.
\newblock Univ of California Press, 1956.

\bibitem[Castelvecchi(2016)]{castelvecchi2016can}
D.~Castelvecchi.
\newblock Can we open the black box of {AI}?
\newblock \emph{Nature News}, 538:\penalty0 20--23, 2016.

\bibitem[Shwartz-Ziv and Tishby(2017)]{shwartz2017opening}
R.~Shwartz-Ziv and N.~Tishby.
\newblock Opening the black box of deep neural networks via information.
\newblock \emph{arXiv preprint arXiv:1703.00810}, 2017.

\bibitem[Kietzmann et~al.(2018)Kietzmann, McClure, and
  Kriegeskorte]{kietzmann2018deep}
T.~C. Kietzmann, P.~McClure, and N.~Kriegeskorte.
\newblock Deep neural networks in computational neuroscience.
\newblock \emph{BioRxiv}, 2018.

\bibitem[Geirhos et~al.(2020{\natexlab{b}})Geirhos, Narayanappa, Mitzkus,
  Bethge, Wichmann, and Brendel]{geirhos2020on}
Robert Geirhos, Kantharaju Narayanappa, Benjamin Mitzkus, Matthias Bethge,
  Felix~A. Wichmann, and Wieland Brendel.
\newblock On the surprising similarities between supervised and self-supervised
  models.
\newblock \emph{arXiv preprint arXiv:2010.08377}, 2020{\natexlab{b}}.

\bibitem[Green(1964)]{Green_1964}
D.~M. Green.
\newblock Consistency of auditory detection judgments.
\newblock \emph{Psychological Review}, 71\penalty0 (5):\penalty0 392--407,
  1964.

\bibitem[Ghodrati et~al.(2014)Ghodrati, Farzmahdi, Rajaei, Ebrahimpour, and
  Khaligh-Razavi]{ghodrati2014feedforward}
M.~Ghodrati, A.~Farzmahdi, K.~Rajaei, R.~Ebrahimpour, and S.-M. Khaligh-Razavi.
\newblock Feedforward object-vision models only tolerate small image variations
  compared to human.
\newblock \emph{Frontiers in Computational Neuroscience}, 8:\penalty0 74, 2014.

\bibitem[Rajalingham et~al.(2015)Rajalingham, Schmidt, and
  DiCarlo]{rajalingham2015comparison}
R.~Rajalingham, K.~Schmidt, and J.~J. DiCarlo.
\newblock Comparison of object recognition behavior in human and monkey.
\newblock \emph{Journal of Neuroscience}, 35\penalty0 (35):\penalty0
  12127--12136, 2015.

\bibitem[Kheradpisheh et~al.(2016{\natexlab{a}})Kheradpisheh, Ghodrati,
  Ganjtabesh, and Masquelier]{kheradpisheh2016deep}
S.~R. Kheradpisheh, M.~Ghodrati, M.~Ganjtabesh, and T.~Masquelier.
\newblock Deep networks can resemble human feed-forward vision in invariant
  object recognition.
\newblock \emph{Scientific Reports}, 6:\penalty0 32672, 2016{\natexlab{a}}.

\bibitem[Kheradpisheh et~al.(2016{\natexlab{b}})Kheradpisheh, Ghodrati,
  Ganjtabesh, and Masquelier]{kheradpisheh2016humans}
S.~R. Kheradpisheh, M.~Ghodrati, M.~Ganjtabesh, and T.~Masquelier.
\newblock Humans and deep networks largely agree on which kinds of variation
  make object recognition harder.
\newblock \emph{Frontiers in Computational Neuroscience}, 10:\penalty0 92,
  2016{\natexlab{b}}.

\bibitem[Geirhos et~al.(2017)Geirhos, Janssen, Sch{\"u}tt, Rauber, Bethge, and
  Wichmann]{geirhos2017comparing}
R.~Geirhos, D.~H.J. Janssen, H.~H. Sch{\"u}tt, J.~Rauber, M.~Bethge, and F.~A
  Wichmann.
\newblock Comparing deep neural networks against humans: object recognition
  when the signal gets weaker.
\newblock \emph{arXiv preprint arXiv:1706.06969}, 2017.

\bibitem[Ma and Peters(2020)]{ma2020a}
W.~J. Ma and B.~Peters.
\newblock A neural network walks into a lab: towards using deep nets as models
  for human behavior.
\newblock \emph{arXiv preprint arXiv:2005.02181}, 2020.

\bibitem[Kubilius et~al.(2016)Kubilius, Bracci, and Op~de
  Beeck]{kubilius2016deep}
J.~Kubilius, S.~Bracci, and H.~P. Op~de Beeck.
\newblock Deep neural networks as a computational model for human shape
  sensitivity.
\newblock \emph{PLoS Computational Biology}, 12\penalty0 (4):\penalty0
  e1004896, 2016.

\bibitem[Rajalingham et~al.(2018)Rajalingham, Issa, Bashivan, Kar, Schmidt, and
  DiCarlo]{rajalingham2018large}
R.~Rajalingham, E.~B. Issa, P.~Bashivan, K.~Kar, K.~Schmidt, and J.~J. DiCarlo.
\newblock Large-scale, high-resolution comparison of the core visual object
  recognition behavior of humans, monkeys, and state-of-the-art deep artificial
  neural networks.
\newblock \emph{Journal of Neuroscience}, 38\penalty0 (33):\penalty0
  7255--7269, 2018.

\bibitem[Mania et~al.(2019)Mania, Miller, Schmidt, Hardt, and
  Recht]{mania2019model}
Horia Mania, John Miller, Ludwig Schmidt, Moritz Hardt, and Benjamin Recht.
\newblock Model similarity mitigates test set overuse.
\newblock In \emph{{Advances in Neural Information Processing Systems}}, pages
  9993--10002, 2019.

\bibitem[Meding et~al.(2019)Meding, Janzing, Sch{\"o}lkopf, and
  Wichmann]{Meding2019}
K.~Meding, D.~Janzing, B.~Sch{\"o}lkopf, and F.~A. Wichmann.
\newblock Perceiving the arrow of time in autoregressive motion.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2303--2314, 2019.

\bibitem[Cohen(1960)]{Cohen1960}
J.~Cohen.
\newblock A coefficient of agreement for nominal scales.
\newblock \emph{Educational and psychological measurement}, 20\penalty0
  (1):\penalty0 37--46, 1960.

\bibitem[Fründ et~al.(2014)Fründ, Wichmann, and Macke]{Frund_2014}
I.~Fründ, F.~A. Wichmann, and J.~H. Macke.
\newblock Quantifying the effect of intertrial dependence on perceptual
  decisions.
\newblock \emph{Journal of Vision}, 14\penalty0 (7), 2014.

\bibitem[Wichmann and Hill(2001)]{wichmann_psychometric_2001a}
F.~A. Wichmann and N.~J. Hill.
\newblock The psychometric function: {I}. {Fitting}, sampling, and goodness of
  fit.
\newblock \emph{Perception \& Psychophysics}, 63\penalty0 (8):\penalty0
  1293--1313, 2001.

\bibitem[Hunt(1986)]{Hunt1986}
R.J. Hunt.
\newblock Percent agreement, pearson's correlation, and kappa as measures of
  inter-examiner reliability.
\newblock \emph{Journal of Dental Research}, 65\penalty0 (2):\penalty0
  128--130, 1986.

\bibitem[Watson and Petrie(2010)]{watson2010method}
PF~Watson and A~Petrie.
\newblock Method agreement analysis: a review of correct methodology.
\newblock \emph{Theriogenology}, 73\penalty0 (9):\penalty0 1167--1179, 2010.

\bibitem[Fleiss et~al.(1969)Fleiss, Cohen, and Everitt]{Fleiss1969}
J.~L. Fleiss, J.~Cohen, and B.~S. Everitt.
\newblock Large sample standard errors of kappa and weighted kappa.
\newblock \emph{Psychological Bulletin}, 72\penalty0 (5):\penalty0 323--327,
  1969.

\bibitem[Hudson and Ramm(1987)]{Hudson1987}
W.~D. Hudson and C.~W. Ramm.
\newblock Correct formulation of the kappa coefficient of agreement.
\newblock \emph{Photogrammetric engineering and remote sensing}, 53\penalty0
  (4):\penalty0 421--422, 1987.

\bibitem[McHugh(2012)]{Mchugh2012}
M.~L. McHugh.
\newblock Interrater reliability: the kappa statistic.
\newblock \emph{Biochemia medica: Biochemia medica}, 22\penalty0 (3):\penalty0
  276--282, 2012.

\bibitem[Bland(2015)]{Bland2015}
M.~Bland.
\newblock \emph{An introduction to medical statistics}.
\newblock Oxford University Press (UK), 2015.

\bibitem[Fleiss et~al.(2003)Fleiss, Levin, and Paik]{fleiss2003}
J.~L. Fleiss, B.~Levin, and M.~C. Paik.
\newblock \emph{Statistical methods for rates and proportions}.
\newblock J. Wiley, Hoboken, N.J, 3rd ed edition, 2003.
\newblock ISBN 978-0-471-52629-2.

\bibitem[Umesh et~al.(1989)Umesh, Peterson, and Sauber]{Umesh1989}
U.~N. Umesh, R.~A. Peterson, and M.~H. Sauber.
\newblock Interjudge agreement and the maximum value of kappa.
\newblock \emph{Educational and Psychological Measurement}, 49\penalty0
  (4):\penalty0 835--850, 1989.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, et~al.]{russakovsky2015imagenet}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et~al.
\newblock {ImageNet} large scale visual recognition challenge.
\newblock \emph{{International Journal of Computer Vision}}, 115\penalty0
  (3):\penalty0 211--252, 2015.

\bibitem[Rust and Movshon(2005)]{rust2005praise}
Nicole~C Rust and J~Anthony Movshon.
\newblock In praise of artifice.
\newblock \emph{{Nature Neuroscience}}, 8\penalty0 (12):\penalty0 1647--1650,
  2005.

\bibitem[Martinez-Garcia et~al.(2019)Martinez-Garcia, Bertalm{\'\i}o, and
  Malo]{martinez2019praise}
Marina Martinez-Garcia, Marcelo Bertalm{\'\i}o, and Jes{\'u}s Malo.
\newblock In praise of artifice reloaded: caution with natural image databases
  in modeling vision.
\newblock \emph{{Frontiers in Neuroscience}}, 13:\penalty0 8, 2019.

\bibitem[Gatys et~al.(2016)Gatys, Ecker, and Bethge]{Gatys2016}
L.~A. Gatys, A.~S. Ecker, and M.~Bethge.
\newblock Image style transfer using convolutional neural networks.
\newblock In \emph{{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}}, pages 2414--2423, 2016.

\bibitem[Geirhos et~al.(2018)Geirhos, Temme, Rauber, Sch{\"u}tt, Bethge, and
  Wichmann]{geirhos2018generalisation}
R.~Geirhos, C.~R.~M. Temme, J.~Rauber, H.~H. Sch{\"u}tt, M.~Bethge, and F.~A.
  Wichmann.
\newblock Generalisation in humans and deep neural networks.
\newblock In \emph{{Advances in Neural Information Processing Systems}}, pages
  7538--7550, 2018.

\bibitem[Miller(1995)]{Miller1995}
G.~A. Miller.
\newblock {WordNet}: a lexical database for {E}nglish.
\newblock \emph{Communications of the ACM}, 38\penalty0 (11):\penalty0 39--41,
  1995.

\bibitem[Kubilius et~al.(2019)Kubilius, Schrimpf, Kar, Rajalingham, Hong,
  Majaj, Issa, Bashivan, Prescott-Roy, Schmidt, et~al.]{kubilius2019brain}
J.~Kubilius, M.~Schrimpf, K.~Kar, R.~Rajalingham, H.~Hong, N.~Majaj, E.~Issa,
  P.~Bashivan, J.~Prescott-Roy, K.~Schmidt, et~al.
\newblock Brain-like object recognition with high-performing shallow recurrent
  {ANNs}.
\newblock In \emph{{Advances in Neural Information Processing Systems}}, pages
  12785--12796, 2019.

\bibitem[Kornblith et~al.(2019)Kornblith, Shlens, and Le]{kornblith2019better}
S.~Kornblith, J.~Shlens, and Q.~V. Le.
\newblock Do better imagenet models transfer better?
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2661--2671, 2019.

\bibitem[Yamins et~al.(2014)Yamins, Hong, Cadieu, Solomon, Seibert, and
  DiCarlo]{yamins2014performance}
D.~L.~K. Yamins, H.~Hong, C.~F. Cadieu, E.~A. Solomon, D.~Seibert, and J.~J.
  DiCarlo.
\newblock Performance-optimized hierarchical models predict neural responses in
  higher visual cortex.
\newblock \emph{Proceedings of the National Academy of Sciences}, 111\penalty0
  (23):\penalty0 8619--8624, 2014.

\bibitem[Storrs et~al.(2020)Storrs, Kietzmann, Walther, Mehrer, and
  Kriegeskorte]{storrs2020diverse}
Katherine~R Storrs, Tim~C Kietzmann, Alexander Walther, Johannes Mehrer, and
  Nikolaus Kriegeskorte.
\newblock Diverse deep neural networks all predict human it well, after
  training and fitting.
\newblock \emph{bioRxiv}, 2020.

\bibitem[Akbarinia and Gegenfurtner(2019)]{akbarinia2019paradox}
Arash Akbarinia and Karl~R Gegenfurtner.
\newblock Paradox in deep neural networks: Similar yet different while
  different yet similar.
\newblock \emph{arXiv preprint arXiv:1903.04772}, 2019.

\bibitem[Mehrer et~al.(2020)Mehrer, Spoerer, Kriegeskorte, and
  Kietzmann]{mehrer2020individual}
Johannes Mehrer, Courtney~J Spoerer, Nikolaus Kriegeskorte, and Tim~C
  Kietzmann.
\newblock Individual differences among deep neural network models.
\newblock \emph{bioRxiv}, 2020.

\bibitem[Kriegeskorte(2015)]{kriegeskorte2015deep}
N.~Kriegeskorte.
\newblock Deep neural networks: a new framework for modeling biological vision
  and brain information processing.
\newblock \emph{Annual review of vision science}, 1:\penalty0 417--446, 2015.

\bibitem[Spoerer et~al.(2017)Spoerer, McClure, and
  Kriegeskorte]{spoerer2017recurrent}
C.~J. Spoerer, P.~McClure, and N.~Kriegeskorte.
\newblock Recurrent convolutional neural networks: a better model of biological
  object recognition.
\newblock \emph{Frontiers in psychology}, 8:\penalty0 1551, 2017.

\bibitem[Kietzmann et~al.(2019)Kietzmann, Spoerer, S{\"o}rensen, Cichy, Hauk,
  and Kriegeskorte]{kietzmann2019recurrence}
T.~C. Kietzmann, C.~J. Spoerer, L.~K.~A. S{\"o}rensen, R.~M. Cichy, O.~Hauk,
  and N.~Kriegeskorte.
\newblock Recurrence is required to capture the representational dynamics of
  the human visual system.
\newblock \emph{Proceedings of the National Academy of Sciences}, 116\penalty0
  (43):\penalty0 21854--21863, 2019.

\bibitem[Serre(2019)]{serre2019deep}
T.~Serre.
\newblock Deep learning: the good, the bad, and the ugly.
\newblock \emph{Annual Review of Vision Science}, 5:\penalty0 399--426, 2019.

\bibitem[van Bergen and Kriegeskorte(2020)]{van2020going}
R.~S. van Bergen and N.~Kriegeskorte.
\newblock Going in circles is the way forward: the role of recurrence in visual
  inference.
\newblock \emph{arXiv preprint arXiv:2003.12128}, 2020.

\bibitem[Linsley et~al.(2018)Linsley, Kim, Veerabadran, Windolf, and
  Serre]{linsley2018learning}
D.~Linsley, J.~Kim, V.~Veerabadran, C.~Windolf, and T.~Serre.
\newblock Learning long-range spatial dependencies with horizontal gated
  recurrent units.
\newblock In \emph{{Advances in Neural Information Processing Systems}}, pages
  152--164, 2018.

\bibitem[Tang et~al.(2018)Tang, Schrimpf, Lotter, Moerman, Paredes, Caro,
  Hardesty, Cox, and Kreiman]{tang2018recurrent}
H.~Tang, M.~Schrimpf, W.~Lotter, C.~Moerman, A.~Paredes, J.~O. Caro,
  W.~Hardesty, D.~Cox, and G.~Kreiman.
\newblock Recurrent computations for visual pattern completion.
\newblock \emph{{Proceedings of the National Academy of Sciences}},
  115\penalty0 (35):\penalty0 8835--8840, 2018.

\bibitem[Kar et~al.(2019)Kar, Kubilius, Schmidt, Issa, and
  DiCarlo]{kar2019evidence}
K.~Kar, J.~Kubilius, K.~Schmidt, E.~B. Issa, and J.~J. DiCarlo.
\newblock Evidence that recurrent circuits are critical to the ventral
  stream’s execution of core object recognition behavior.
\newblock \emph{{Nature Neuroscience}}, 22\penalty0 (6):\penalty0 974--983,
  2019.

\bibitem[Lake et~al.(2017)Lake, Ullman, Tenenbaum, and
  Gershman]{lake_building_2017}
B.~M. Lake, T.~D. Ullman, J.~B. Tenenbaum, and S.~J. Gershman.
\newblock Building machines that learn and think like people.
\newblock \emph{Behavioral and Brain Sciences}, 40, 2017.

\bibitem[Hagedorn et~al.(2019{\natexlab{a}})Hagedorn, Kalmus, Mann, Vicca,
  Van~den Berge, van Ypersele, Bourg, Rotmans, Kaaronen, Rahmstorf,
  et~al.]{hagedorn2019a}
G.~Hagedorn, P.~Kalmus, M.~Mann, S.~Vicca, J.~Van~den Berge, J.-P. van
  Ypersele, D.~Bourg, J.~Rotmans, R.~Kaaronen, S.~Rahmstorf, et~al.
\newblock Concerns of young protesters are justified.
\newblock \emph{Science}, 364:\penalty0 139--140, 2019{\natexlab{a}}.

\bibitem[Hagedorn et~al.(2019{\natexlab{b}})Hagedorn, Loew, Seneviratne, Lucht,
  Beck, Hesse, Knutti, Quaschning, Schleimer, Mattauch, et~al.]{hagedorn2019b}
G.~Hagedorn, T.~Loew, S.~I. Seneviratne, W.~Lucht, M.-L. Beck, J.~Hesse,
  R.~Knutti, V.~Quaschning, J.-H. Schleimer, L.~Mattauch, et~al.
\newblock The concerns of the young protesters are justified: A statement by
  scientists for future concerning the protests for more climate protection.
\newblock \emph{GAIA-Ecological Perspectives for Science and Society},
  28\penalty0 (2):\penalty0 79--87, 2019{\natexlab{b}}.

\bibitem[Creemers(2018)]{creemers2018china}
R.~Creemers.
\newblock China's social credit system: an evolving practice of control.
\newblock \emph{Available at SSRN 3175792}, 2018.

\bibitem[Selbst and Powles(2017)]{selbst2017meaningful}
A.~D. Selbst and J.~Powles.
\newblock Meaningful information and the right to explanation.
\newblock \emph{International Data Privacy Law}, 7\penalty0 (4):\penalty0
  233--242, 2017.

\bibitem[Schönfelder and Wichmann(2013)]{schonfelder2013}
Vinzenz~H. Schönfelder and Felix~A. Wichmann.
\newblock Identification of stimulus cues in narrow-band tone-in-noise
  detection using sparse observer models.
\newblock \emph{The Journal of the Acoustical Society of America}, 134\penalty0
  (1):\penalty0 447--463, 2013.

\bibitem[Hyndman and Fan(1996)]{Hyndman1996}
R.~J. Hyndman and Y.~Fan.
\newblock Sample quantiles in statistical packages.
\newblock \emph{The American Statistician}, 50\penalty0 (4):\penalty0 361--365,
  1996.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{pytorch}
A.~Paszke, S.~Gross, F.~Massa, A.~Lerer, J.~Bradbury, G.~Chanan, T.~Killeen,
  Z.~Lin, N.~Gimelshein, L.~Antiga, A.~Desmaison, A.~Kopf, E.~Yang, Z.~DeVito,
  M.~Raison, A.~Tejani, S.~Chilamkurthy, B.~Steiner, L.~Fang, J.~Bai, and
  S.~Chintala.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pages
  8024--8035. Curran Associates, Inc., 2019.

\bibitem[Simonyan and Zisserman(2015)]{simonyan2015very}
K.~Simonyan and A.~Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock arXiv preprint arXiv:1409.1556, 2015.

\bibitem[Hermann and Kornblith(2019)]{hermann2019exploring}
Katherine~L Hermann and Simon Kornblith.
\newblock Exploring the origins and prevalence of texture bias in convolutional
  neural networks.
\newblock \emph{arXiv preprint arXiv:1911.09071}, 2019.

\end{thebibliography}
