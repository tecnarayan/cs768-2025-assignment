\begin{thebibliography}{114}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abercrombie et~al.(2023)Abercrombie, Cercas~Curry, Dinkar, Rieser, and Talat]{abercrombie-etal-2023-mirages}
Gavin Abercrombie, Amanda Cercas~Curry, Tanvi Dinkar, Verena Rieser, and Zeerak Talat.
\newblock Mirages. on anthropomorphism in dialogue systems.
\newblock In Houda Bouamor, Juan Pino, and Kalika Bali (eds.), \emph{Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing}, pp.\  4776--4790, Singapore, December 2023. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2023.emnlp-main.290}.
\newblock URL \url{https://aclanthology.org/2023.emnlp-main.290}.

\bibitem[Ahdritz et~al.(2024)Ahdritz, Qin, Vyas, Barak, and Edelman]{ahdritz2024distinguishing}
Gustaf Ahdritz, Tian Qin, Nikhil Vyas, Boaz Barak, and Benjamin~L. Edelman.
\newblock Distinguishing the knowable from the unknowable with language models, 2024.
\newblock URL \url{https://arxiv.org/abs/2402.03563}.

\bibitem[Amayuelas et~al.(2023)Amayuelas, Pan, Chen, and Wang]{amayuelas2023knowledge}
Alfonso Amayuelas, Liangming Pan, Wenhu Chen, and William Wang.
\newblock Knowledge of knowledge: Exploring known-unknowns uncertainty with large language models.
\newblock arXiv preprint arXiv:2305.13712, 2023.
\newblock URL \url{https://arxiv.org/abs/2305.13712}.

\bibitem[Anthropic(2024)]{claude3}
Anthropic.
\newblock Introducing the next generation of claude.
\newblock 2024.
\newblock URL \url{https://www.anthropic.com/news/claude-3-family}.

\bibitem[Anwar et~al.(2024)Anwar, Saparov, Rando, Paleka, Turpin, Hase, Lubana, Jenner, Casper, Sourbut, Edelman, Zhang, Günther, Korinek, Hernandez-Orallo, Hammond, Bigelow, Pan, Langosco, Korbak, Zhang, Zhong, hÉigeartaigh, Recchia, Corsi, Chan, Anderljung, Edwards, Petrov, de~Witt, Motwan, Bengio, Chen, Torr, Albanie, Maharaj, Foerster, Tramer, He, Kasirzadeh, Choi, and Krueger]{anwar2024safetychallenges}
Usman Anwar, Abulhair Saparov, Javier Rando, Daniel Paleka, Miles Turpin, Peter Hase, Ekdeep~Singh Lubana, Erik Jenner, Stephen Casper, Oliver Sourbut, Benjamin~L. Edelman, Zhaowei Zhang, Mario Günther, Anton Korinek, Jose Hernandez-Orallo, Lewis Hammond, Eric Bigelow, Alexander Pan, Lauro Langosco, Tomasz Korbak, Heidi Zhang, Ruiqi Zhong, Seán~Ó hÉigeartaigh, Gabriel Recchia, Giulio Corsi, Alan Chan, Markus Anderljung, Lilian Edwards, Aleksandar Petrov, Christian~Schroeder de~Witt, Sumeet~Ramesh Motwan, Yoshua Bengio, Danqi Chen, Philip H.~S. Torr, Samuel Albanie, Tegan Maharaj, Jakob Foerster, Florian Tramer, He~He, Atoosa Kasirzadeh, Yejin Choi, and David Krueger.
\newblock Foundational challenges in assuring alignment and safety of large language models, 2024.
\newblock URL \url{https://arxiv.org/abs/2404.09932}.

\bibitem[Asai \& Choi(2021)Asai and Choi]{asai-choi-2021-challenges}
Akari Asai and Eunsol Choi.
\newblock Challenges in information-seeking {QA}: Unanswerable questions and paragraph retrieval.
\newblock In Chengqing Zong, Fei Xia, Wenjie Li, and Roberto Navigli (eds.), \emph{Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)}, pp.\  1492--1504, Online, August 2021. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2021.acl-long.118}.
\newblock URL \url{https://aclanthology.org/2021.acl-long.118}.

\bibitem[Baan et~al.(2023)Baan, Daheim, Ilia, Ulmer, Li, Fern{\'a}ndez, Plank, Sennrich, Zerva, and Aziz]{baan2023uncertainty}
Joris Baan, Nico Daheim, Evgenia Ilia, Dennis Ulmer, Haau-Sing Li, Raquel Fern{\'a}ndez, Barbara Plank, Rico Sennrich, Chrysoula Zerva, and Wilker Aziz.
\newblock Uncertainty in natural language generation: From theory to applications.
\newblock 2023.
\newblock URL \url{https://arxiv.org/abs/2307.15703}.

\bibitem[Bai et~al.(2022)Bai, Jones, Ndousse, Askell, Chen, Dassarma, Drain, Fort, Ganguli, Henighan, Joseph, Kadavath, Kernion, Conerly, El-Showk, Elhage, Hatfield-Dodds, Hernandez, Hume, Johnston, Kravec, Lovitt, Nanda, Olsson, Amodei, Brown, Clark, McCandlish, Olah, Mann, and Kaplan]{Bai2022TrainingAH}
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova Dassarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Kadavath, John Kernion, Tom Conerly, Sheer El-Showk, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson, Dario Amodei, Tom~B. Brown, Jack Clark, Sam McCandlish, Christopher Olah, Benjamin Mann, and Jared Kaplan.
\newblock Training a helpful and harmless assistant with reinforcement learning from human feedback.
\newblock \emph{ArXiv}, abs/2204.05862, 2022.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:248118878}.

\bibitem[Banko et~al.(2020)Banko, MacKeen, and Ray]{banko-etal-2020-unified}
Michele Banko, Brendon MacKeen, and Laurie Ray.
\newblock A unified taxonomy of harmful content.
\newblock In Seyi Akiwowo, Bertie Vidgen, Vinodkumar Prabhakaran, and Zeerak Waseem (eds.), \emph{Proceedings of the Fourth Workshop on Online Abuse and Harms}, pp.\  125--137, Online, November 2020. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.alw-1.16}.
\newblock URL \url{https://aclanthology.org/2020.alw-1.16}.

\bibitem[Bianchi et~al.(2024)Bianchi, Suzgun, Attanasio, Rottger, Jurafsky, Hashimoto, and Zou]{bianchi2023safety}
Federico Bianchi, Mirac Suzgun, Giuseppe Attanasio, Paul Rottger, Dan Jurafsky, Tatsunori Hashimoto, and James Zou.
\newblock Safety-tuned {LL}a{MA}s: Lessons from improving the safety of large language models that follow instructions.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=gT5hALch9z}.

\bibitem[Biderman et~al.(2024)Biderman, Portes, Ortiz, Paul, Greengard, Jennings, King, Havens, Chiley, Frankle, Blakeney, and Cunningham]{biderman2024lora}
Dan Biderman, Jacob Portes, Jose Javier~Gonzalez Ortiz, Mansheej Paul, Philip Greengard, Connor Jennings, Daniel King, Sam Havens, Vitaliy Chiley, Jonathan Frankle, Cody Blakeney, and John~Patrick Cunningham.
\newblock Lo{RA} learns less and forgets less.
\newblock \emph{Transactions on Machine Learning Research}, 2024.
\newblock ISSN 2835-8856.
\newblock URL \url{https://openreview.net/forum?id=aloEru2qCG}.
\newblock Featured Certification.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan, Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess, Clark, Berner, McCandlish, Radford, Sutskever, and Amodei]{Brown2020LanguageMA}
Tom~B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel~M. Ziegler, Jeff Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei.
\newblock Language models are few-shot learners.
\newblock \emph{ArXiv}, abs/2005.14165, 2020.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:218971783}.

\bibitem[Carlini et~al.(2021)Carlini, Tramer, Wallace, Jagielski, Herbert-Voss, Lee, Roberts, Brown, Song, Erlingsson, et~al.]{carlini2021extracting}
Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom~B Brown, Dawn Song, Ulfar Erlingsson, et~al.
\newblock Extracting training data from large language models.
\newblock In \emph{USENIX Security Symposium}, volume~6, 2021.

\bibitem[Carlini et~al.(2023)Carlini, Ippolito, Jagielski, Lee, Tramer, and Zhang]{carlini2023quantifying}
Nicholas Carlini, Daphne Ippolito, Matthew Jagielski, Katherine Lee, Florian Tramer, and Chiyuan Zhang.
\newblock Quantifying memorization across neural language models.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=TatRHT_1cK}.

\bibitem[Chao et~al.(2023)Chao, Robey, Dobriban, Hassani, Pappas, and Wong]{pair}
Patrick Chao, Alexander Robey, Edgar Dobriban, Hamed Hassani, George~J. Pappas, and Eric Wong.
\newblock Jailbreaking black box large language models in twenty queries, 2023.

\bibitem[Chen et~al.(2021)Chen, Tworek, Jun, Yuan, Ponde~de Oliveira~Pinto, Kaplan, Edwards, Burda, Joseph, Brockman, et~al.]{chen2021evaluating}
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde~de Oliveira~Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et~al.
\newblock Evaluating large language models trained on code.
\newblock \emph{arXiv e-prints}, pp.\  arXiv--2107, 2021.

\bibitem[Cheng et~al.(2024)Cheng, Marone, Weller, Lawrie, Khashabi, and Durme]{cheng2024dated}
Jeffrey Cheng, Marc Marone, Orion Weller, Dawn Lawrie, Daniel Khashabi, and Benjamin~Van Durme.
\newblock Dated data: Tracing knowledge cutoffs in large language models, 2024.

\bibitem[Chiang et~al.(2023)Chiang, Li, Lin, Sheng, Wu, Zhang, Zheng, Zhuang, Zhuang, Gonzalez, Stoica, and Xing]{vicuna2023}
Wei-Lin Chiang, Zhuohan Li, Zi~Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph~E. Gonzalez, Ion Stoica, and Eric~P. Xing.
\newblock Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality, March 2023.
\newblock URL \url{https://lmsys.org/blog/2023-03-30-vicuna/}.

\bibitem[Clark \& Gardner(2018)Clark and Gardner]{clark-gardner-2018-simple}
Christopher Clark and Matt Gardner.
\newblock Simple and effective multi-paragraph reading comprehension.
\newblock In Iryna Gurevych and Yusuke Miyao (eds.), \emph{Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pp.\  845--855, Melbourne, Australia, July 2018. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/P18-1078}.
\newblock URL \url{https://aclanthology.org/P18-1078}.

\bibitem[Clark et~al.(2020)Clark, Choi, Collins, Garrette, Kwiatkowski, Nikolaev, and Palomaki]{clark2020tydi}
Jonathan~H. Clark, Eunsol Choi, Michael Collins, Dan Garrette, Tom Kwiatkowski, Vitaly Nikolaev, and Jennimaria Palomaki.
\newblock {T}y{D}i {QA}: A benchmark for information-seeking question answering in typologically diverse languages.
\newblock \emph{Transactions of the Association for Computational Linguistics}, 8:\penalty0 454--470, 2020.
\newblock \doi{10.1162/tacl_a_00317}.
\newblock URL \url{https://aclanthology.org/2020.tacl-1.30}.

\bibitem[Cobbe et~al.(2021)Cobbe, Kosaraju, Bavarian, Chen, Jun, Kaiser, Plappert, Tworek, Hilton, Nakano, Hesse, and Schulman]{cobbe2021training}
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman.
\newblock Training verifiers to solve math word problems, 2021.
\newblock URL \url{https://arxiv.org/abs/2110.14168}.

\bibitem[Code(1987)]{code2020epistemic}
Lorraine Code.
\newblock \emph{Epistemic Responsibility}.
\newblock Published for Brown University Press by University Press of New England, Hanover, N.H., 1987.

\bibitem[Dai et~al.(2024)Dai, Pan, Sun, Ji, Xu, Liu, Wang, and Yang]{dai2023saferlhf}
Josef Dai, Xuehai Pan, Ruiyang Sun, Jiaming Ji, Xinbo Xu, Mickel Liu, Yizhou Wang, and Yaodong Yang.
\newblock Safe {RLHF}: Safe reinforcement learning from human feedback.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=TyFrPOKYXw}.

\bibitem[Derczynski et~al.(2023)Derczynski, Kirk, Balachandran, Kumar, Tsvetkov, Leiser, and Mohammad]{derczynski2023assessing}
Leon Derczynski, Hannah~Rose Kirk, Vidhisha Balachandran, Sachin Kumar, Yulia Tsvetkov, M.~R. Leiser, and Saif Mohammad.
\newblock Assessing language model deployment with risk cards, 2023.
\newblock URL \url{https://arxiv.org/abs/2303.18190}.

\bibitem[Derner \& Batistič(2023)Derner and Batistič]{derner2023beyond}
Erik Derner and Kristina Batistič.
\newblock Beyond the safeguards: Exploring the security risks of chatgpt, 2023.
\newblock URL \url{https://arxiv.org/abs/2305.08005}.

\bibitem[Desai \& Durrett(2020)Desai and Durrett]{desai2020calibration}
Shrey Desai and Greg Durrett.
\newblock Calibration of pre-trained transformers.
\newblock In Bonnie Webber, Trevor Cohn, Yulan He, and Yang Liu (eds.), \emph{Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)}, pp.\  295--302, Online, November 2020. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.emnlp-main.21}.
\newblock URL \url{https://aclanthology.org/2020.emnlp-main.21}.

\bibitem[Feng et~al.(2024{\natexlab{a}})Feng, Shi, Wang, Ding, Ahia, Li, Balachandran, Sitaram, and Tsvetkov]{feng2024teaching}
Shangbin Feng, Weijia Shi, Yike Wang, Wenxuan Ding, Orevaoghene Ahia, Shuyue~Stella Li, Vidhisha Balachandran, Sunayana Sitaram, and Yulia Tsvetkov.
\newblock Teaching {LLMs} to abstain across languages via multilingual feedback.
\newblock In \emph{Empirical Methods in Natural Language Processing (EMNLP)}, 2024{\natexlab{a}}.

\bibitem[Feng et~al.(2024{\natexlab{b}})Feng, Shi, Wang, Ding, Balachandran, and Tsvetkov]{feng2024don}
Shangbin Feng, Weijia Shi, Yike Wang, Wenxuan Ding, Vidhisha Balachandran, and Yulia Tsvetkov.
\newblock Don{'}t hallucinate, abstain: Identifying {LLM} knowledge gaps via multi-{LLM} collaboration.
\newblock In Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), \emph{Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pp.\  14664--14690, Bangkok, Thailand, August 2024{\natexlab{b}}. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2024.acl-long.786}.
\newblock URL \url{https://aclanthology.org/2024.acl-long.786}.

\bibitem[Ganguli et~al.(2022)Ganguli, Lovitt, Kernion, Askell, Bai, Kadavath, Mann, Perez, Schiefer, Ndousse, Jones, Bowman, Chen, Conerly, DasSarma, Drain, Elhage, El-Showk, Fort, Hatfield-Dodds, Henighan, Hernandez, Hume, Jacobson, Johnston, Kravec, Olsson, Ringer, Tran-Johnson, Amodei, Brown, Joseph, McCandlish, Olah, Kaplan, and Clark]{hh-rlhf}
Deep Ganguli, Liane Lovitt, Jackson Kernion, Amanda Askell, Yuntao Bai, Saurav Kadavath, Ben Mann, Ethan Perez, Nicholas Schiefer, Kamal Ndousse, Andy Jones, Sam Bowman, Anna Chen, Tom Conerly, Nova DasSarma, Dawn Drain, Nelson Elhage, Sheer El-Showk, Stanislav Fort, Zac Hatfield-Dodds, Tom Henighan, Danny Hernandez, Tristan Hume, Josh Jacobson, Scott Johnston, Shauna Kravec, Catherine Olsson, Sam Ringer, Eli Tran-Johnson, Dario Amodei, Tom Brown, Nicholas Joseph, Sam McCandlish, Chris Olah, Jared Kaplan, and Jack Clark.
\newblock Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned, 2022.

\bibitem[Gardner et~al.(2020)Gardner, Artzi, Basmov, Berant, Bogin, Chen, Dasigi, Dua, Elazar, Gottumukkala, Gupta, Hajishirzi, Ilharco, Khashabi, Lin, Liu, Liu, Mulcaire, Ning, Singh, Smith, Subramanian, Tsarfaty, Wallace, Zhang, and Zhou]{gardner-etal-2020-evaluating}
Matt Gardner, Yoav Artzi, Victoria Basmov, Jonathan Berant, Ben Bogin, Sihao Chen, Pradeep Dasigi, Dheeru Dua, Yanai Elazar, Ananth Gottumukkala, Nitish Gupta, Hannaneh Hajishirzi, Gabriel Ilharco, Daniel Khashabi, Kevin Lin, Jiangming Liu, Nelson~F. Liu, Phoebe Mulcaire, Qiang Ning, Sameer Singh, Noah~A. Smith, Sanjay Subramanian, Reut Tsarfaty, Eric Wallace, Ally Zhang, and Ben Zhou.
\newblock Evaluating models{'} local decision boundaries via contrast sets.
\newblock In Trevor Cohn, Yulan He, and Yang Liu (eds.), \emph{Findings of the Association for Computational Linguistics: EMNLP 2020}, pp.\  1307--1323, Online, November 2020. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.findings-emnlp.117}.
\newblock URL \url{https://aclanthology.org/2020.findings-emnlp.117}.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Mirza, Xiao, Courville, and Bengio]{goodfellow2015empirical}
Ian~J. Goodfellow, Mehdi Mirza, Da~Xiao, Aaron Courville, and Yoshua Bengio.
\newblock An empirical investigation of catastrophic forgetting in gradient-based neural networks, 2015.

\bibitem[Hartvigsen et~al.(2022)Hartvigsen, Gabriel, Palangi, Sap, Ray, and Kamar]{hartvigsen2022toxigen}
Thomas Hartvigsen, Saadia Gabriel, Hamid Palangi, Maarten Sap, Dipankar Ray, and Ece Kamar.
\newblock Toxigen: Controlling language models to generate implied and adversarial toxicity.
\newblock In \emph{Annual Meeting of the Association for Computational Linguistics}, volume~1, 2022.

\bibitem[Heersmink et~al.()Heersmink, de~Rooij, V{\'a}zquez, and Colombo]{heersminkphenomenology}
Richard Heersmink, Barend de~Rooij, Mar{\'\i}a Jimena~Clavel V{\'a}zquez, and Matteo Colombo.
\newblock A phenomenology and epistemology of large language models: Transparency, trust, and trustworthiness.

\bibitem[Hendrycks et~al.(2020)Hendrycks, Burns, Basart, Zou, Mazeika, Song, and Steinhardt]{hendrycks2020measuring}
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.
\newblock Measuring massive multitask language understanding.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Hestness et~al.(2017)Hestness, Narang, Ardalani, Diamos, Jun, Kianinejad, Patwary, Yang, and Zhou]{hestness2017deep}
Joel Hestness, Sharan Narang, Newsha Ardalani, Gregory Diamos, Heewoo Jun, Hassan Kianinejad, Md~Mostofa~Ali Patwary, Yang Yang, and Yanqi Zhou.
\newblock Deep learning scaling is predictable, empirically.
\newblock \emph{arXiv preprint arXiv:1712.00409}, 2017.

\bibitem[Hoffmann et~al.(2022)Hoffmann, Borgeaud, Mensch, Buchatskaya, Cai, Rutherford, Casas, Hendricks, Welbl, Clark, et~al.]{hoffmann2022training}
Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de~Las Casas, Lisa~Anne Hendricks, Johannes Welbl, Aidan Clark, et~al.
\newblock Training compute-optimal large language models.
\newblock \emph{arXiv preprint arXiv:2203.15556}, 2022.

\bibitem[Hu et~al.(2022)Hu, yelong shen, Wallis, Allen-Zhu, Li, Wang, Wang, and Chen]{hu2022lora}
Edward~J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu~Wang, and Weizhu Chen.
\newblock Lo{RA}: Low-rank adaptation of large language models.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=nZeVKeeFYf9}.

\bibitem[Huang et~al.(2023)Huang, Liu, Lin, Pang, Du, and Lin]{huang2023lorahub}
Chengsong Huang, Qian Liu, Bill~Yuchen Lin, Tianyu Pang, Chao Du, and Min Lin.
\newblock Lorahub: Efficient cross-task generalization via dynamic lora composition.
\newblock \emph{arXiv preprint arXiv:2307.13269}, 2023.

\bibitem[Huang et~al.(2022)Huang, Shao, and Chang]{huang2022large}
Jie Huang, Hanyin Shao, and Kevin Chen-Chuan Chang.
\newblock Are large pre-trained language models leaking your personal information?
\newblock \emph{EMNLP Findings}, 2022.

\bibitem[Ivison et~al.(2023)Ivison, Wang, Pyatkin, Lambert, Peters, Dasigi, Jang, Wadden, Smith, Beltagy, and Hajishirzi]{ivison2023camels}
Hamish Ivison, Yizhong Wang, Valentina Pyatkin, Nathan Lambert, Matthew Peters, Pradeep Dasigi, Joel Jang, David Wadden, Noah~A. Smith, Iz~Beltagy, and Hannaneh Hajishirzi.
\newblock Camels in a changing climate: Enhancing lm adaptation with tulu 2, 2023.

\bibitem[Jacovi et~al.(2021)Jacovi, Marasovi\'{c}, Miller, and Goldberg]{jacovi2021trust}
Alon Jacovi, Ana Marasovi\'{c}, Tim Miller, and Yoav Goldberg.
\newblock Formalizing trust in artificial intelligence: Prerequisites, causes and goals of human trust in ai.
\newblock In \emph{Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency}, FAccT '21, pp.\  624–635, New York, NY, USA, 2021. Association for Computing Machinery.
\newblock ISBN 9781450383097.
\newblock \doi{10.1145/3442188.3445923}.
\newblock URL \url{https://doi.org/10.1145/3442188.3445923}.

\bibitem[Jia \& Liang(2017)Jia and Liang]{jia-liang-2017-adversarial}
Robin Jia and Percy Liang.
\newblock Adversarial examples for evaluating reading comprehension systems.
\newblock In Martha Palmer, Rebecca Hwa, and Sebastian Riedel (eds.), \emph{Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing}, pp.\  2021--2031, Copenhagen, Denmark, September 2017. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/D17-1215}.
\newblock URL \url{https://aclanthology.org/D17-1215}.

\bibitem[Jiang et~al.(2023)Jiang, Sablayrolles, Mensch, Bamford, Chaplot, de~las Casas, Bressand, Lengyel, Lample, Saulnier, Lavaud, Lachaux, Stock, Scao, Lavril, Wang, Lacroix, and Sayed]{jiang2023mistral}
Albert~Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra~Singh Chaplot, Diego de~las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio~Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven~Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William~El Sayed.
\newblock Mistral 7b, 2023.

\bibitem[Jiang et~al.(2024{\natexlab{a}})Jiang, Sablayrolles, Roux, Mensch, Savary, Bamford, Chaplot, de~las Casas, Hanna, Bressand, Lengyel, Bour, Lample, Lavaud, Saulnier, Lachaux, Stock, Subramanian, Yang, Antoniak, Scao, Gervet, Lavril, Wang, Lacroix, and Sayed]{jiang2024mixtral}
Albert~Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra~Singh Chaplot, Diego de~las Casas, Emma~Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample, Lélio~Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven~Le Scao, Théophile Gervet, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William~El Sayed.
\newblock Mixtral of experts, 2024{\natexlab{a}}.

\bibitem[Jiang et~al.(2024{\natexlab{b}})Jiang, Rao, Han, Ettinger, Brahman, Kumar, Mireshghallah, Lu, Sap, Choi, and Dziri]{jiang2024wildteamingscaleinthewildjailbreaks}
Liwei Jiang, Kavel Rao, Seungju Han, Allyson Ettinger, Faeze Brahman, Sachin Kumar, Niloofar Mireshghallah, Ximing Lu, Maarten Sap, Yejin Choi, and Nouha Dziri.
\newblock Wildteaming at scale: From in-the-wild jailbreaks to (adversarially) safer language models.
\newblock In \emph{Proceedings of the Neural Information Processing Systems}, 2024{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2406.18510}.

\bibitem[Jiang et~al.(2021)Jiang, Araki, Ding, and Neubig]{jiang2021can}
Zhengbao Jiang, Jun Araki, Haibo Ding, and Graham Neubig.
\newblock How can we know when language models know? on the calibration of language models for question answering.
\newblock \emph{Transactions of the Association for Computational Linguistics}, 9:\penalty0 962--977, 2021.

\bibitem[Kadavath et~al.(2022)Kadavath, Conerly, Askell, Henighan, Drain, Perez, Schiefer, Hatfield-Dodds, DasSarma, Tran-Johnson, et~al.]{kadavath2022language}
Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, et~al.
\newblock Language models (mostly) know what they know.
\newblock \emph{arXiv preprint arXiv:2207.05221}, 2022.

\bibitem[Kamath et~al.(2020)Kamath, Jia, and Liang]{kamath-etal-2020-selective}
Amita Kamath, Robin Jia, and Percy Liang.
\newblock Selective question answering under domain shift.
\newblock In Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel Tetreault (eds.), \emph{Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics}, pp.\  5684--5696, Online, July 2020. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.acl-main.503}.
\newblock URL \url{https://aclanthology.org/2020.acl-main.503}.

\bibitem[Kaplan et~al.(2020)Kaplan, McCandlish, Henighan, Brown, Chess, Child, Gray, Radford, Wu, and Amodei]{kaplan2020scaling}
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom~B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.
\newblock Scaling laws for neural language models.
\newblock \emph{arXiv preprint arXiv:2001.08361}, 2020.

\bibitem[Karamolegkou et~al.(2023)Karamolegkou, Li, Zhou, and S{\o}gaard]{karamolegkou-etal-2023-copyright}
Antonia Karamolegkou, Jiaang Li, Li~Zhou, and Anders S{\o}gaard.
\newblock Copyright violations and large language models.
\newblock In Houda Bouamor, Juan Pino, and Kalika Bali (eds.), \emph{Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing}, pp.\  7403--7412, Singapore, December 2023. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2023.emnlp-main.458}.
\newblock URL \url{https://aclanthology.org/2023.emnlp-main.458}.

\bibitem[Keyvan \& Huang(2022)Keyvan and Huang]{10.1145/3534965}
Kimiya Keyvan and Jimmy~Xiangji Huang.
\newblock How to approach ambiguous queries in conversational search: A survey of techniques, approaches, tools, and challenges.
\newblock \emph{ACM Comput. Surv.}, 55\penalty0 (6), dec 2022.
\newblock ISSN 0360-0300.
\newblock \doi{10.1145/3534965}.
\newblock URL \url{https://doi.org/10.1145/3534965}.

\bibitem[Kim \& Thorne(2024)Kim and Thorne]{kim2024epistemology}
Minsu Kim and James Thorne.
\newblock Epistemology of language models: Do language models have holistic knowledge?
\newblock \emph{arXiv preprint arXiv:2403.12862}, 2024.

\bibitem[Kim et~al.(2022)Kim, Htut, Bowman, and Petty]{kim20222}
Najoung Kim, Phu~Mon Htut, Samuel~R Bowman, and Jackson Petty.
\newblock Qa$^2$: Question answering with questionable assumptions.
\newblock \emph{arXiv preprint arXiv:2212.10003}, 2022.

\bibitem[Kirk et~al.(2023)Kirk, Vidgen, R{\"o}ttger, and Hale]{kirk2023personalisation}
Hannah~Rose Kirk, Bertie Vidgen, Paul R{\"o}ttger, and Scott~A Hale.
\newblock Personalisation within bounds: A risk taxonomy and policy framework for the alignment of large language models with personalised feedback.
\newblock \emph{arXiv preprint arXiv:2303.05453}, 2023.

\bibitem[Kirkpatrick et~al.(2017)Kirkpatrick, Pascanu, Rabinowitz, Veness, Desjardins, Rusu, Milan, Quan, Ramalho, Grabska-Barwinska, Hassabis, Clopath, Kumaran, and Hadsell]{Kirkpatrick_2017}
James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei~A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, and Raia Hadsell.
\newblock Overcoming catastrophic forgetting in neural networks.
\newblock \emph{Proceedings of the National Academy of Sciences}, 114\penalty0 (13):\penalty0 3521–3526, March 2017.
\newblock ISSN 1091-6490.
\newblock \doi{10.1073/pnas.1611835114}.
\newblock URL \url{http://dx.doi.org/10.1073/pnas.1611835114}.

\bibitem[Kuhn et~al.(2023)Kuhn, Gal, and Farquhar]{kuhn2022clam}
Lorenz Kuhn, Yarin Gal, and Sebastian Farquhar.
\newblock Clam: Selective clarification for ambiguous questions with generative language models.
\newblock In \emph{ICML Workshop on Deployable Generative AI}, 2023.
\newblock URL \url{https://openreview.net/forum?id=VQWuqgSoVN#all}.

\bibitem[Kumar et~al.(2023)Kumar, Balachandran, Njoo, Anastasopoulos, and Tsvetkov]{kumar-etal-2023-language}
Sachin Kumar, Vidhisha Balachandran, Lucille Njoo, Antonios Anastasopoulos, and Yulia Tsvetkov.
\newblock Language generation models can cause harm: So what can we do about it? an actionable survey.
\newblock In Andreas Vlachos and Isabelle Augenstein (eds.), \emph{Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics}, pp.\  3299--3321, Dubrovnik, Croatia, May 2023. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2023.eacl-main.241}.
\newblock URL \url{https://aclanthology.org/2023.eacl-main.241}.

\bibitem[Lee et~al.(2024)Lee, Kim, Cherif, Dobre, Lee, Hwang, Kawaguchi, Gidel, Bengio, Malkin, et~al.]{lee2024learning}
Seanie Lee, Minsu Kim, Lynn Cherif, David Dobre, Juho Lee, Sung~Ju Hwang, Kenji Kawaguchi, Gauthier Gidel, Yoshua Bengio, Nikolay Malkin, et~al.
\newblock Learning diverse attacks on large language models for robust red-teaming and safety tuning.
\newblock \emph{arXiv preprint arXiv:2405.18540}, 2024.

\bibitem[Legislature()]{california_legislature_sb1001}
California Legislature.
\newblock Senate bill no. 1001.
\newblock \url{https://digitaldemocracy.calmatters.org/bills/ca_201720180sb1001}.
\newblock Accessed: 2024-06-05.

\bibitem[Levy et~al.(2017)Levy, Seo, Choi, and Zettlemoyer]{levy-etal-2017-zero}
Omer Levy, Minjoon Seo, Eunsol Choi, and Luke Zettlemoyer.
\newblock Zero-shot relation extraction via reading comprehension.
\newblock In Roger Levy and Lucia Specia (eds.), \emph{Proceedings of the 21st Conference on Computational Natural Language Learning ({C}o{NLL} 2017)}, pp.\  333--342, Vancouver, Canada, August 2017. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/K17-1034}.
\newblock URL \url{https://aclanthology.org/K17-1034}.

\bibitem[Li et~al.(2023{\natexlab{a}})Li, Guo, Fan, Xu, and Song]{li2023multi}
Haoran Li, Dadi Guo, Wei Fan, Mingshi Xu, and Yangqiu Song.
\newblock Multi-step jailbreaking privacy attacks on chatgpt.
\newblock \emph{arXiv preprint arXiv:2304.05197}, 2023{\natexlab{a}}.

\bibitem[Li et~al.(2024{\natexlab{a}})Li, Balachandran, Feng, Ilgen, Pierson, Koh, and Tsvetkov]{li2024mediq}
Shuyue~Stella Li, Vidhisha Balachandran, Shangbin Feng, Jonathan Ilgen, Emma Pierson, Pang~Wei Koh, and Yulia Tsvetkov.
\newblock {MediQ}: Question-asking {LLMs} for adaptive and reliable clinical reasoning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2024{\natexlab{a}}.

\bibitem[Li et~al.(2020)Li, Khashabi, Khot, Sabharwal, and Srikumar]{li-etal-2020-unqovering}
Tao Li, Daniel Khashabi, Tushar Khot, Ashish Sabharwal, and Vivek Srikumar.
\newblock {UNQOVER}ing stereotyping biases via underspecified questions.
\newblock In \emph{Findings of the Association for Computational Linguistics: EMNLP 2020}, pp.\  3475--3489, Online, November 2020. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.findings-emnlp.311}.
\newblock URL \url{https://aclanthology.org/2020.findings-emnlp.311}.

\bibitem[Li et~al.(2024{\natexlab{b}})Li, Zhou, Zhu, Yao, Liu, and Han]{li2024deepinception}
Xuan Li, Zhanke Zhou, Jianing Zhu, Jiangchao Yao, Tongliang Liu, and Bo~Han.
\newblock Deepinception: Hypnotize large language model to be jailbreaker, 2024{\natexlab{b}}.

\bibitem[Li et~al.(2023{\natexlab{b}})Li, Zhang, Dubois, Taori, Gulrajani, Guestrin, Liang, and Hashimoto]{alpaca_eval}
Xuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori, Ishaan Gulrajani, Carlos Guestrin, Percy Liang, and Tatsunori~B. Hashimoto.
\newblock Alpacaeval: An automatic evaluator of instruction-following models.
\newblock \url{https://github.com/tatsu-lab/alpaca_eval}, 2023{\natexlab{b}}.

\bibitem[Lin et~al.(2022)Lin, Hilton, and Evans]{lin2022truthfulqa}
Stephanie Lin, Jacob Hilton, and Owain Evans.
\newblock Truthfulqa: Measuring how models mimic human falsehoods.
\newblock In \emph{Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pp.\  3214--3252, 2022.

\bibitem[Liu et~al.(2023{\natexlab{a}})Liu, Xu, Chen, and Xiao]{liu2023autodan}
Xiaogeng Liu, Nan Xu, Muhao Chen, and Chaowei Xiao.
\newblock Autodan: Generating stealthy jailbreak prompts on aligned large language models, 2023{\natexlab{a}}.

\bibitem[Liu et~al.(2023{\natexlab{b}})Liu, Yao, Ton, Zhang, Cheng, Klochkov, Taufiq, and Li]{liu2023trustworthy}
Yang Liu, Yuanshun Yao, Jean-Francois Ton, Xiaoying Zhang, Ruocheng Guo~Hao Cheng, Yegor Klochkov, Muhammad~Faaiz Taufiq, and Hang Li.
\newblock Trustworthy llms: a survey and guideline for evaluating large language models' alignment.
\newblock \emph{arXiv preprint arXiv:2308.05374}, 2023{\natexlab{b}}.

\bibitem[Lukas et~al.(2023)Lukas, Salem, Sim, Tople, Wutschitz, and Zanella-B{\'e}guelin]{lukas2023analyzing}
Nils Lukas, Ahmed Salem, Robert Sim, Shruti Tople, Lukas Wutschitz, and Santiago Zanella-B{\'e}guelin.
\newblock Analyzing leakage of personally identifiable information in language models.
\newblock \emph{arXiv preprint arXiv:2302.00539}, 2023.

\bibitem[Majumder et~al.(2021)Majumder, Rao, Galley, and McAuley]{majumder2021ask}
Bodhisattwa~Prasad Majumder, Sudha Rao, Michel Galley, and Julian McAuley.
\newblock Ask what’s missing and what’s useful: Improving clarification question generation using global knowledge.
\newblock In \emph{Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies}, pp.\  4300--4312, 2021.

\bibitem[Markov et~al.(2023{\natexlab{a}})Markov, Zhang, Agarwal, Eloundou~Nekoul, Lee, Adler, Jiang, and Weng]{Markov_Zhang_Agarwal_EloundouNekoul_Lee_Adler_Jiang_Weng_2023}
Todor Markov, Chong Zhang, Sandhini Agarwal, Florentine Eloundou~Nekoul, Theodore Lee, Steven Adler, Angela Jiang, and Lilian Weng.
\newblock A holistic approach to undesired content detection in the real world.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, 37\penalty0 (12):\penalty0 15009--15018, Jun. 2023{\natexlab{a}}.
\newblock \doi{10.1609/aaai.v37i12.26752}.
\newblock URL \url{https://ojs.aaai.org/index.php/AAAI/article/view/26752}.

\bibitem[Markov et~al.(2023{\natexlab{b}})Markov, Zhang, Agarwal, Eloundou~Nekoul, Lee, Adler, Jiang, and Weng]{Markov_Zhang_Agarwal_Eloundou_Nekoul_Lee_Adler_Jiang_Weng_2023}
Todor Markov, Chong Zhang, Sandhini Agarwal, Florentine Eloundou~Nekoul, Theodore Lee, Steven Adler, Angela Jiang, and Lilian Weng.
\newblock A holistic approach to undesired content detection in the real world.
\newblock \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, 37\penalty0 (12):\penalty0 15009--15018, Jun. 2023{\natexlab{b}}.
\newblock \doi{10.1609/aaai.v37i12.26752}.
\newblock URL \url{https://ojs.aaai.org/index.php/AAAI/article/view/26752}.

\bibitem[Mazeika et~al.(2024)Mazeika, Phan, Yin, Zou, Wang, Mu, Sakhaee, Li, Basart, Li, Forsyth, and Hendrycks]{mazeika2024harmbench}
Mantas Mazeika, Long Phan, Xuwang Yin, Andy Zou, Zifan Wang, Norman Mu, Elham Sakhaee, Nathaniel Li, Steven Basart, Bo~Li, David Forsyth, and Dan Hendrycks.
\newblock Harmbench: A standardized evaluation framework for automated red teaming and robust refusal, 2024.

\bibitem[Mielke et~al.(2022)Mielke, Szlam, Dinan, and Boureau]{mielke2022reducing}
Sabrina~J Mielke, Arthur Szlam, Emily Dinan, and Y-Lan Boureau.
\newblock Reducing conversational agents’ overconfidence through linguistic calibration.
\newblock \emph{Transactions of the Association for Computational Linguistics}, 10:\penalty0 857--872, 2022.

\bibitem[Min et~al.(2020)Min, Michael, Hajishirzi, and Zettlemoyer]{min2020ambigqa}
Sewon Min, Julian Michael, Hannaneh Hajishirzi, and Luke Zettlemoyer.
\newblock Ambigqa: Answering ambiguous open-domain questions.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)}, pp.\  5783--5797, 2020.

\bibitem[Onoe et~al.(2021)Onoe, Zhang, Choi, and Durrett]{onoe2021creak}
Yasumasa Onoe, Michael~J.Q. Zhang, Eunsol Choi, and Greg Durrett.
\newblock Creak: A dataset for commonsense reasoning over entity knowledge.
\newblock \emph{OpenReview}, 2021.

\bibitem[OpenAI(2022)]{chatgpt2022}
OpenAI.
\newblock Introducing chatgpt.
\newblock 2022.
\newblock URL \url{https://openai.com/blog/chatgpt}.

\bibitem[OpenAI(2023)]{openai2023gpt4}
OpenAI.
\newblock Gpt-4 technical report, 2023.

\bibitem[Pyatkin et~al.(2023)Pyatkin, Hwang, Srikumar, Lu, Jiang, Choi, and Bhagavatula]{pyatkin2023clarifydelphi}
Valentina Pyatkin, Jena~D Hwang, Vivek Srikumar, Ximing Lu, Liwei Jiang, Yejin Choi, and Chandra Bhagavatula.
\newblock Clarifydelphi: Reinforced clarification questions with defeasibility rewards for social and moral situations.
\newblock In \emph{Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pp.\  11253--11271, 2023.

\bibitem[Rafailov et~al.(2023)Rafailov, Sharma, Mitchell, Manning, Ermon, and Finn]{NEURIPS2023_a85b405e}
Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher~D Manning, Stefano Ermon, and Chelsea Finn.
\newblock Direct preference optimization: Your language model is secretly a reward model.
\newblock In A.~Oh, T.~Naumann, A.~Globerson, K.~Saenko, M.~Hardt, and S.~Levine (eds.), \emph{Advances in Neural Information Processing Systems}, volume~36, pp.\  53728--53741. Curran Associates, Inc., 2023.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2023/file/a85b405ed65c6477a4fe8302b5e06ce7-Paper-Conference.pdf}.

\bibitem[Rajpurkar et~al.(2018)Rajpurkar, Jia, and Liang]{rajpurkar-etal-2018-know}
Pranav Rajpurkar, Robin Jia, and Percy Liang.
\newblock Know what you don{'}t know: Unanswerable questions for {SQ}u{AD}.
\newblock In Iryna Gurevych and Yusuke Miyao (eds.), \emph{Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)}, pp.\  784--789, Melbourne, Australia, July 2018. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/P18-2124}.
\newblock URL \url{https://aclanthology.org/P18-2124}.

\bibitem[Rao \& Daum{\'e}~III(2018)Rao and Daum{\'e}~III]{rao2018learning}
Sudha Rao and Hal Daum{\'e}~III.
\newblock Learning to ask good questions: Ranking clarification questions using neural expected value of perfect information.
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pp.\  2737--2746, 2018.

\bibitem[Ravichander(2019)]{ravichander2019question}
Abhilasha Ravichander.
\newblock Question answering for privacy policies: Combining computational and legal.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in Natural}, pp.\  4947--4958. Association for Computational Linguistics, 2019.

\bibitem[Reimers \& Gurevych(2020)Reimers and Gurevych]{reimers-2020-multilingual-sentence-bert}
Nils Reimers and Iryna Gurevych.
\newblock Making monolingual sentence embeddings multilingual using knowledge distillation.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing}. Association for Computational Linguistics, 11 2020.
\newblock URL \url{https://arxiv.org/abs/2004.09813}.

\bibitem[Ribeiro et~al.(2018)Ribeiro, Singh, and Guestrin]{ribeiro-etal-2018-semantically}
Marco~Tulio Ribeiro, Sameer Singh, and Carlos Guestrin.
\newblock Semantically equivalent adversarial rules for debugging {NLP} models.
\newblock In Iryna Gurevych and Yusuke Miyao (eds.), \emph{Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pp.\  856--865, Melbourne, Australia, July 2018. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/P18-1079}.
\newblock URL \url{https://aclanthology.org/P18-1079}.

\bibitem[R{\"o}ttger et~al.(2024{\natexlab{a}})R{\"o}ttger, Kirk, Vidgen, Attanasio, Bianchi, and Hovy]{röttger2024xstest}
Paul R{\"o}ttger, Hannah Kirk, Bertie Vidgen, Giuseppe Attanasio, Federico Bianchi, and Dirk Hovy.
\newblock {XST}est: A test suite for identifying exaggerated safety behaviours in large language models.
\newblock In Kevin Duh, Helena Gomez, and Steven Bethard (eds.), \emph{Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)}, pp.\  5377--5400, Mexico City, Mexico, June 2024{\natexlab{a}}. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2024.naacl-long.301}.
\newblock URL \url{https://aclanthology.org/2024.naacl-long.301}.

\bibitem[R{\"o}ttger et~al.(2024{\natexlab{b}})R{\"o}ttger, Pernisi, Vidgen, and Hovy]{rottger2024safetyprompts}
Paul R{\"o}ttger, Fabio Pernisi, Bertie Vidgen, and Dirk Hovy.
\newblock Safetyprompts: a systematic review of open datasets for evaluating and improving large language model safety.
\newblock \emph{arXiv preprint arXiv:2404.05399}, 2024{\natexlab{b}}.

\bibitem[Röttger et~al.(2024)Röttger, Pernisi, Vidgen, and Hovy]{röttger2024safetyprompts}
Paul Röttger, Fabio Pernisi, Bertie Vidgen, and Dirk Hovy.
\newblock Safetyprompts: a systematic review of open datasets for evaluating and improving large language model safety.
\newblock 2024.
\newblock URL \url{https://safetyprompts.com/}.

\bibitem[Salminen et~al.(2018)Salminen, Almerekhi, Milenković, Jung, An, Kwak, and Jansen]{Salminen_Almerekhi_Milenković_Jung_An_Kwak_Jansen_2018}
Joni Salminen, Hind Almerekhi, Milica Milenković, Soon-gyo Jung, Jisun An, Haewoon Kwak, and Bernard Jansen.
\newblock Anatomy of online hate: Developing a taxonomy and machine learning models for identifying and classifying hate in online news media.
\newblock \emph{Proceedings of the International AAAI Conference on Web and Social Media}, 12\penalty0 (1), Jun. 2018.
\newblock \doi{10.1609/icwsm.v12i1.15028}.
\newblock URL \url{https://ojs.aaai.org/index.php/ICWSM/article/view/15028}.

\bibitem[Srivastava et~al.(2022)Srivastava, Rastogi, Rao, Shoeb, Abid, Fisch, Brown, Santoro, Gupta, Garriga-Alonso, et~al.]{srivastava2022beyond}
Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal~Md Shoeb, Abubakar Abid, Adam Fisch, Adam~R Brown, Adam Santoro, Aditya Gupta, Adri{\`a} Garriga-Alonso, et~al.
\newblock Beyond the imitation game: Quantifying and extrapolating the capabilities of language models.
\newblock arXiv preprint arXiv:2206.04615, 2022.
\newblock URL \url{https://arxiv.org/abs/2206.04615}.

\bibitem[Srivastava et~al.(2023)Srivastava, Rastogi, Rao, Shoeb, Abid, Fisch, Brown, Santoro, Gupta, Garriga-Alonso, et~al.]{srivastava2023beyond}
Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal~Md Shoeb, Abubakar Abid, Adam Fisch, Adam~R Brown, Adam Santoro, Aditya Gupta, Adri{\`a} Garriga-Alonso, et~al.
\newblock Beyond the imitation game: Quantifying and extrapolating the capabilities of language models.
\newblock \emph{Transactions on Machine Learning Research}, 2023.

\bibitem[Sun et~al.(2024)Sun, Huang, Wang, Wu, Zhang, Li, Gao, Huang, Lyu, Zhang, Li, Liu, Liu, Wang, Zhang, Vidgen, Kailkhura, Xiong, Xiao, Li, Xing, Huang, Liu, Ji, Wang, Zhang, Yao, Kellis, Zitnik, Jiang, Bansal, Zou, Pei, Liu, Gao, Han, Zhao, Tang, Wang, Vanschoren, Mitchell, Shu, Xu, Chang, He, Huang, Backes, Gong, Yu, Chen, Gu, Xu, Ying, Ji, Jana, Chen, Liu, Zhou, Wang, Li, Zhang, Wang, Xie, Chen, Wang, Liu, Ye, Cao, Chen, and Zhao]{sun2024trustllm}
Lichao Sun, Yue Huang, Haoran Wang, Siyuan Wu, Qihui Zhang, Yuan Li, Chujie Gao, Yixin Huang, Wenhan Lyu, Yixuan Zhang, Xiner Li, Zhengliang Liu, Yixin Liu, Yijue Wang, Zhikun Zhang, Bertie Vidgen, Bhavya Kailkhura, Caiming Xiong, Chaowei Xiao, Chunyuan Li, Eric Xing, Furong Huang, Hao Liu, Heng Ji, Hongyi Wang, Huan Zhang, Huaxiu Yao, Manolis Kellis, Marinka Zitnik, Meng Jiang, Mohit Bansal, James Zou, Jian Pei, Jian Liu, Jianfeng Gao, Jiawei Han, Jieyu Zhao, Jiliang Tang, Jindong Wang, Joaquin Vanschoren, John Mitchell, Kai Shu, Kaidi Xu, Kai-Wei Chang, Lifang He, Lifu Huang, Michael Backes, Neil~Zhenqiang Gong, Philip~S. Yu, Pin-Yu Chen, Quanquan Gu, Ran Xu, Rex Ying, Shuiwang Ji, Suman Jana, Tianlong Chen, Tianming Liu, Tianyi Zhou, William Wang, Xiang Li, Xiangliang Zhang, Xiao Wang, Xing Xie, Xun Chen, Xuyu Wang, Yan Liu, Yanfang Ye, Yinzhi Cao, Yong Chen, and Yue Zhao.
\newblock Trustllm: Trustworthiness in large language models, 2024.

\bibitem[Suzgun et~al.(2023)Suzgun, Scales, Sch{\"a}rli, Gehrmann, Tay, Chung, Chowdhery, Le, Chi, Zhou, et~al.]{suzgun2023challenging}
Mirac Suzgun, Nathan Scales, Nathanael Sch{\"a}rli, Sebastian Gehrmann, Yi~Tay, Hyung~Won Chung, Aakanksha Chowdhery, Quoc Le, Ed~Chi, Denny Zhou, et~al.
\newblock Challenging big-bench tasks and whether chain-of-thought can solve them.
\newblock In \emph{Findings of the Association for Computational Linguistics: ACL 2023}, pp.\  13003--13051, 2023.

\bibitem[Team et~al.(2024)Team, Mesnard, Hardin, Dadashi, Bhupatiraju, Pathak, Sifre, Rivière, Kale, Love, Tafti, Hussenot, Sessa, Chowdhery, Roberts, Barua, Botev, Castro-Ros, Slone, Héliou, Tacchetti, Bulanova, Paterson, Tsai, Shahriari, Lan, Choquette-Choo, Crepy, Cer, Ippolito, Reid, Buchatskaya, Ni, Noland, Yan, Tucker, Muraru, Rozhdestvenskiy, Michalewski, Tenney, Grishchenko, Austin, Keeling, Labanowski, Lespiau, Stanway, Brennan, Chen, Ferret, Chiu, Mao-Jones, Lee, Yu, Millican, Sjoesund, Lee, Dixon, Reid, Mikuła, Wirth, Sharman, Chinaev, Thain, Bachem, Chang, Wahltinez, Bailey, Michel, Yotov, Chaabouni, Comanescu, Jana, Anil, McIlroy, Liu, Mullins, Smith, Borgeaud, Girgin, Douglas, Pandya, Shakeri, De, Klimenko, Hennigan, Feinberg, Stokowiec, hui Chen, Ahmed, Gong, Warkentin, Peran, Giang, Farabet, Vinyals, Dean, Kavukcuoglu, Hassabis, Ghahramani, Eck, Barral, Pereira, Collins, Joulin, Fiedel, Senter, Andreev, and Kenealy]{gemmateam2024gemma}
Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivière, Mihir~Sanjay Kale, Juliette Love, Pouya Tafti, Léonard Hussenot, Pier~Giuseppe Sessa, Aakanksha Chowdhery, Adam Roberts, Aditya Barua, Alex Botev, Alex Castro-Ros, Ambrose Slone, Amélie Héliou, Andrea Tacchetti, Anna Bulanova, Antonia Paterson, Beth Tsai, Bobak Shahriari, Charline~Le Lan, Christopher~A. Choquette-Choo, Clément Crepy, Daniel Cer, Daphne Ippolito, David Reid, Elena Buchatskaya, Eric Ni, Eric Noland, Geng Yan, George Tucker, George-Christian Muraru, Grigory Rozhdestvenskiy, Henryk Michalewski, Ian Tenney, Ivan Grishchenko, Jacob Austin, James Keeling, Jane Labanowski, Jean-Baptiste Lespiau, Jeff Stanway, Jenny Brennan, Jeremy Chen, Johan Ferret, Justin Chiu, Justin Mao-Jones, Katherine Lee, Kathy Yu, Katie Millican, Lars~Lowe Sjoesund, Lisa Lee, Lucas Dixon, Machel Reid, Maciej Mikuła, Mateo Wirth, Michael Sharman, Nikolai Chinaev, Nithum Thain, Olivier Bachem,
  Oscar Chang, Oscar Wahltinez, Paige Bailey, Paul Michel, Petko Yotov, Rahma Chaabouni, Ramona Comanescu, Reena Jana, Rohan Anil, Ross McIlroy, Ruibo Liu, Ryan Mullins, Samuel~L Smith, Sebastian Borgeaud, Sertan Girgin, Sholto Douglas, Shree Pandya, Siamak Shakeri, Soham De, Ted Klimenko, Tom Hennigan, Vlad Feinberg, Wojciech Stokowiec, Yu~hui Chen, Zafarali Ahmed, Zhitao Gong, Tris Warkentin, Ludovic Peran, Minh Giang, Clément Farabet, Oriol Vinyals, Jeff Dean, Koray Kavukcuoglu, Demis Hassabis, Zoubin Ghahramani, Douglas Eck, Joelle Barral, Fernando Pereira, Eli Collins, Armand Joulin, Noah Fiedel, Evan Senter, Alek Andreev, and Kathleen Kenealy.
\newblock Gemma: Open models based on gemini research and technology, 2024.

\bibitem[Touvron et~al.(2023{\natexlab{a}})Touvron, Lavril, Izacard, Martinet, Lachaux, Lacroix, Rozi{\`e}re, Goyal, Hambro, Azhar, Rodriguez, Joulin, Grave, and Lample]{Touvron2023LLaMAOA}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth{\'e}e Lacroix, Baptiste Rozi{\`e}re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample.
\newblock Llama: Open and efficient foundation language models.
\newblock \emph{ArXiv}, abs/2302.13971, 2023{\natexlab{a}}.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:257219404}.

\bibitem[Touvron et~al.(2023{\natexlab{b}})Touvron, Lavril, Izacard, Martinet, Lachaux, Lacroix, Rozi{\`e}re, Goyal, Hambro, Azhar, et~al.]{touvron2023llama}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth{\'e}e Lacroix, Baptiste Rozi{\`e}re, Naman Goyal, Eric Hambro, Faisal Azhar, et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock \emph{arXiv preprint arXiv:2302.13971}, 2023{\natexlab{b}}.

\bibitem[Touvron et~al.(2023{\natexlab{c}})Touvron, Martin, Stone, Albert, Almahairi, Babaei, Bashlykov, Batra, Bhargava, Bhosale, Bikel, Blecher, Ferrer, Chen, Cucurull, Esiobu, Fernandes, Fu, Fu, Fuller, Gao, Goswami, Goyal, Hartshorn, Hosseini, Hou, Inan, Kardas, Kerkez, Khabsa, Kloumann, Korenev, Koura, Lachaux, Lavril, Lee, Liskovich, Lu, Mao, Martinet, Mihaylov, Mishra, Molybog, Nie, Poulton, Reizenstein, Rungta, Saladi, Schelten, Silva, Smith, Subramanian, Tan, Tang, Taylor, Williams, Kuan, Xu, Yan, Zarov, Zhang, Fan, Kambadur, Narang, Rodriguez, Stojnic, Edunov, and Scialom]{touvron2023llama2}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian~Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit~Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric~Michael Smith, Ranjan Subramanian, Xiaoqing~Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian~Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas
  Scialom.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock \emph{arXiv preprint arXiv: 2307.09288}, 2023{\natexlab{c}}.

\bibitem[Varshney et~al.(2022)Varshney, Mishra, and Baral]{varshney2022investigating}
Neeraj Varshney, Swaroop Mishra, and Chitta Baral.
\newblock Investigating selective prediction approaches across several tasks in {IID}, {OOD}, and adversarial settings.
\newblock In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio (eds.), \emph{Findings of the Association for Computational Linguistics: ACL 2022}, pp.\  1995--2002, Dublin, Ireland, May 2022. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2022.findings-acl.158}.
\newblock URL \url{https://aclanthology.org/2022.findings-acl.158}.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Chen, Pei, Xie, Kang, Zhang, Xu, Xiong, Dutta, Schaeffer, Truong, Arora, Mazeika, Hendrycks, Lin, Cheng, Koyejo, Song, and Li]{NEURIPS2023_63cb9921}
Boxin Wang, Weixin Chen, Hengzhi Pei, Chulin Xie, Mintong Kang, Chenhui Zhang, Chejian Xu, Zidi Xiong, Ritik Dutta, Rylan Schaeffer, Sang Truong, Simran Arora, Mantas Mazeika, Dan Hendrycks, Zinan Lin, Yu~Cheng, Sanmi Koyejo, Dawn Song, and Bo~Li.
\newblock Decodingtrust: A comprehensive assessment of trustworthiness in gpt models.
\newblock In A.~Oh, T.~Naumann, A.~Globerson, K.~Saenko, M.~Hardt, and S.~Levine (eds.), \emph{Advances in Neural Information Processing Systems}, volume~36, pp.\  31232--31339. Curran Associates, Inc., 2023{\natexlab{a}}.
\newblock URL \url{https://proceedings.neurips.cc/paper_files/paper/2023/file/63cb9921eecf51bfad27a99b2c53dd6d-Paper-Datasets_and_Benchmarks.pdf}.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, Ivison, Dasigi, Hessel, Khot, Chandu, Wadden, MacMillan, Smith, Beltagy, and Hajishirzi]{wang2023far}
Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack Hessel, Tushar Khot, Khyathi~Raghavi Chandu, David Wadden, Kelsey MacMillan, Noah~A. Smith, Iz~Beltagy, and Hannaneh Hajishirzi.
\newblock How far can camels go? exploring the state of instruction tuning on open resources, 2023{\natexlab{b}}.
\newblock URL \url{https://arxiv.org/abs/2306.04751}.

\bibitem[Wang et~al.(2023{\natexlab{c}})Wang, Kordi, Mishra, Liu, Smith, Khashabi, and Hajishirzi]{wang-etal-2023-self-instruct}
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah~A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi.
\newblock Self-instruct: Aligning language models with self-generated instructions.
\newblock In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (eds.), \emph{Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pp.\  13484--13508, Toronto, Canada, July 2023{\natexlab{c}}. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2023.acl-long.754}.
\newblock URL \url{https://aclanthology.org/2023.acl-long.754}.

\bibitem[Wang et~al.(2024)Wang, Li, Han, Nakov, and Baldwin]{wang-etal-2024-answer}
Yuxia Wang, Haonan Li, Xudong Han, Preslav Nakov, and Timothy Baldwin.
\newblock Do-not-answer: Evaluating safeguards in {LLM}s.
\newblock In Yvette Graham and Matthew Purver (eds.), \emph{Findings of the Association for Computational Linguistics: EACL 2024}, pp.\  896--911, St. Julian{'}s, Malta, March 2024. Association for Computational Linguistics.
\newblock URL \url{https://aclanthology.org/2024.findings-eacl.61}.

\bibitem[Weidinger et~al.(2022)Weidinger, Uesato, Rauh, Griffin, Huang, Mellor, Glaese, Cheng, Balle, Kasirzadeh, Biles, Brown, Kenton, Hawkins, Stepleton, Birhane, Hendricks, Rimell, Isaac, Haas, Legassick, Irving, and Gabriel]{weidingertaxonomy}
Laura Weidinger, Jonathan Uesato, Maribeth Rauh, Conor Griffin, Po-Sen Huang, John Mellor, Amelia Glaese, Myra Cheng, Borja Balle, Atoosa Kasirzadeh, Courtney Biles, Sasha Brown, Zac Kenton, Will Hawkins, Tom Stepleton, Abeba Birhane, Lisa~Anne Hendricks, Laura Rimell, William Isaac, Julia Haas, Sean Legassick, Geoffrey Irving, and Iason Gabriel.
\newblock Taxonomy of risks posed by language models.
\newblock In \emph{Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency}, FAccT '22, pp.\  214–229, New York, NY, USA, 2022. Association for Computing Machinery.
\newblock ISBN 9781450393522.
\newblock \doi{10.1145/3531146.3533088}.
\newblock URL \url{https://doi.org/10.1145/3531146.3533088}.

\bibitem[Whitehead et~al.(2022)Whitehead, Petryk, Shakib, Gonzalez, Darrell, Rohrbach, and Rohrbach]{Whitehead2022ReliableVQ}
Spencer Whitehead, Suzanne Petryk, Vedaad Shakib, Joseph~E. Gonzalez, Trevor Darrell, Anna Rohrbach, and Marcus Rohrbach.
\newblock Reliable visual question answering: Abstain rather than answer incorrectly.
\newblock \emph{ArXiv}, abs/2204.13631, 2022.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:248426953}.

\bibitem[Xu et~al.(2019)Xu, Wang, Tang, Duan, Yang, Zeng, Zhou, and Sun]{xu-etal-2019-asking}
Jingjing Xu, Yuechen Wang, Duyu Tang, Nan Duan, Pengcheng Yang, Qi~Zeng, Ming Zhou, and Xu~Sun.
\newblock Asking clarification questions in knowledge-based question answering.
\newblock In Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wan (eds.), \emph{Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)}, pp.\  1618--1629, Hong Kong, China, November 2019. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/D19-1172}.
\newblock URL \url{https://aclanthology.org/D19-1172}.

\bibitem[Yang et~al.(2024)Yang, Chern, Qiu, Neubig, and Liu]{yang2023alignment}
Yuqing Yang, Ethan Chern, Xipeng Qiu, Graham Neubig, and Pengfei Liu.
\newblock Alignment for honesty, 2024.
\newblock URL \url{https://arxiv.org/abs/2312.07000}.

\bibitem[Yu et~al.(2023)Yu, Min, Zettlemoyer, and Hajishirzi]{yu2023crepe}
Xinyan Yu, Sewon Min, Luke Zettlemoyer, and Hannaneh Hajishirzi.
\newblock {CREPE}: Open-domain question answering with false presuppositions.
\newblock In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (eds.), \emph{Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pp.\  10457--10480, Toronto, Canada, July 2023. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2023.acl-long.583}.
\newblock URL \url{https://aclanthology.org/2023.acl-long.583}.

\bibitem[Zhang \& Choi(2021)Zhang and Choi]{zhang2021situatedqa}
Michael Zhang and Eunsol Choi.
\newblock {S}ituated{QA}: Incorporating extra-linguistic contexts into {QA}.
\newblock In Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih (eds.), \emph{Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing}, pp.\  7371--7387, Online and Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2021.emnlp-main.586}.
\newblock URL \url{https://aclanthology.org/2021.emnlp-main.586}.

\bibitem[Zhang \& Choi(2023)Zhang and Choi]{zhang2023clarify}
Michael~JQ Zhang and Eunsol Choi.
\newblock Clarify when necessary: Resolving ambiguity through interaction with lms.
\newblock \emph{arXiv preprint arXiv:2311.09469}, 2023.
\newblock URL \url{https://arxiv.org/abs/2311.09469}.

\bibitem[Zhang et~al.(2024)Zhang, Lei, Wu, Sun, Huang, Long, Liu, Lei, Tang, and Huang]{zhang2023safetybench}
Zhexin Zhang, Leqi Lei, Lindong Wu, Rui Sun, Yongkang Huang, Chong Long, Xiao Liu, Xuanyu Lei, Jie Tang, and Minlie Huang.
\newblock {S}afety{B}ench: Evaluating the safety of large language models.
\newblock In Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), \emph{Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pp.\  15537--15553, Bangkok, Thailand, August 2024. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2024.acl-long.830}.
\newblock URL \url{https://aclanthology.org/2024.acl-long.830}.

\bibitem[Zhao et~al.(2024)Zhao, Ren, Hessel, Cardie, Choi, and Deng]{zhao2024wildchat}
Wenting Zhao, Xiang Ren, Jack Hessel, Claire Cardie, Yejin Choi, and Yuntian Deng.
\newblock Wildchat: 1m chat{GPT} interaction logs in the wild.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=Bl8u7ZRlbM}.

\bibitem[Zhong et~al.(2024)Zhong, Ding, Liu, Du, and Tao]{zhong2024rose}
Qihuang Zhong, Liang Ding, Juhua Liu, Bo~Du, and Dacheng Tao.
\newblock {ROSE} doesn{'}t do that: Boosting the safety of instruction-tuned large language models with reverse prompt contrastive decoding.
\newblock In Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), \emph{Findings of the Association for Computational Linguistics ACL 2024}, pp.\  13721--13736, Bangkok, Thailand and virtual meeting, August 2024. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2024.findings-acl.814}.
\newblock URL \url{https://aclanthology.org/2024.findings-acl.814}.

\bibitem[Zhou et~al.(2024)Zhou, Kim, Brahman, Jiang, Zhu, Lu, Xu, Lin, Choi, Mireshghallah, Le~Bras, and Sap]{zhou2024haicosystem}
Xuhui Zhou, Hyunwoo Kim, Faeze Brahman, Liwei Jiang, Hao Zhu, Ximing Lu, Frank Xu, Bill~Yuchen Lin, Yejin Choi, Niloofar Mireshghallah, Ronan Le~Bras, and Maarten Sap.
\newblock Haicosystem: An ecosystem for sandboxing safety risks in human-ai interactions.
\newblock \emph{arXiv}, 2024.
\newblock URL \url{http://arxiv.org/abs/2409.16427}.

\bibitem[Zhuo et~al.(2023)Zhuo, Huang, Chen, and Xing]{Zhuo2023ExploringAE}
Terry~Yue Zhuo, Yujin Huang, Chunyang Chen, and Zhenchang Xing.
\newblock Exploring ai ethics of chatgpt: A diagnostic analysis.
\newblock \emph{ArXiv}, abs/2301.12867, 2023.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:256390238}.

\end{thebibliography}
