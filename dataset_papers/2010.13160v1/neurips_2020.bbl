\begin{thebibliography}{29}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Denil et~al.(2013)Denil, Shakibi, Dinh, Ranzato, and
  De~Freitas]{denil2013predicting}
Misha Denil, Babak Shakibi, Laurent Dinh, Marc'Aurelio Ranzato, and Nando
  De~Freitas.
\newblock Predicting parameters in deep learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2013.

\bibitem[Han et~al.(2015)Han, Pool, Tran, and Dally]{han2015learning}
Song Han, Jeff Pool, John Tran, and William Dally.
\newblock Learning both weights and connections for efficient neural network.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2015.

\bibitem[Han et~al.(2016)Han, Liu, Mao, Pu, Pedram, Horowitz, and
  Dally]{han2016eie}
Song Han, Xingyu Liu, Huizi Mao, Jing Pu, Ardavan Pedram, Mark~A Horowitz, and
  William~J Dally.
\newblock Eie: efficient inference engine on compressed deep neural network.
\newblock \emph{ACM SIGARCH Computer Architecture News}, 44\penalty0
  (3):\penalty0 243--254, 2016.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2016.

\bibitem[He et~al.(2018)He, Kang, Dong, Fu, and Yang]{he2018soft}
Yang He, Guoliang Kang, Xuanyi Dong, Yanwei Fu, and Yi~Yang.
\newblock Soft filter pruning for accelerating deep convolutional neural
  networks.
\newblock In \emph{International Joint Conference on Artificial Intelligence},
  2018.

\bibitem[He et~al.(2019)He, Liu, Wang, Hu, and Yang]{he2019filter}
Yang He, Ping Liu, Ziwei Wang, Zhilan Hu, and Yi~Yang.
\newblock Filter pruning via geometric median for deep convolutional neural
  networks acceleration.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2019.

\bibitem[He et~al.(2017)He, Zhang, and Sun]{he2017channel}
Yihui He, Xiangyu Zhang, and Jian Sun.
\newblock Channel pruning for accelerating very deep neural networks.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, 2017.

\bibitem[Hinton(2007)]{hinton2007learning}
Geoffrey~E Hinton.
\newblock Learning multiple layers of representation.
\newblock \emph{Trends in cognitive sciences}, 11\penalty0 (10):\penalty0
  428--434, 2007.

\bibitem[Ioffe and Szegedy(2015)]{ioffe2015batch}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock \emph{arXiv preprint arXiv:1502.03167}, 2015.

\bibitem[Kim et~al.(2016)Kim, Park, Yoo, Choi, Yang, and
  Shin]{kim2015compression}
Yong{-}Deok Kim, Eunhyeok Park, Sungjoo Yoo, Taelim Choi, Lu~Yang, and Dongjun
  Shin.
\newblock Compression of deep convolutional neural networks for fast and low
  power mobile applications.
\newblock In \emph{4th International Conference on Learning Representations},
  2016.

\bibitem[Kolda and Bader(2009)]{kolda2009tensor}
Tamara~G Kolda and Brett~W Bader.
\newblock Tensor decompositions and applications.
\newblock \emph{SIAM review}, 51\penalty0 (3):\penalty0 455--500, 2009.

\bibitem[Lebedev et~al.(2015)Lebedev, Ganin, Rakhuba, Oseledets, and
  Lempitsky]{lebedev2014speeding}
Vadim Lebedev, Yaroslav Ganin, Maksim Rakhuba, Ivan~V. Oseledets, and Victor~S.
  Lempitsky.
\newblock Speeding-up convolutional neural networks using fine-tuned
  cp-decomposition.
\newblock In \emph{3rd International Conference on Learning Representations},
  2015.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and
  Haffner]{lecun1998gradient}
Yann LeCun, L{\'e}on Bottou, Yoshua Bengio, and Patrick Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Lee et~al.(2019)Lee, Ajanthan, and Torr]{lee2018snip}
Namhoon Lee, Thalaiyasingam Ajanthan, and Philip~HS Torr.
\newblock Snip: Single-shot network pruning based on connection sensitivity.
\newblock In \emph{7th International Conference on Learning Representations},
  2019.

\bibitem[Li et~al.(2017)Li, Kadav, Durdanovic, Samet, and Graf]{li2016pruning}
Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans~Peter Graf.
\newblock Pruning filters for efficient convnets.
\newblock In \emph{5th International Conference on Learning Representations},
  2017.

\bibitem[Liu et~al.(2017)Liu, Li, Shen, Huang, Yan, and Zhang]{liu2017learning}
Zhuang Liu, Jianguo Li, Zhiqiang Shen, Gao Huang, Shoumeng Yan, and Changshui
  Zhang.
\newblock Learning efficient convolutional networks through network slimming.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, 2017.

\bibitem[Luo et~al.(2017)Luo, Wu, and Lin]{luo2017thinet}
Jian-Hao Luo, Jianxin Wu, and Weiyao Lin.
\newblock Thinet: A filter level pruning method for deep neural network
  compression.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, 2017.

\bibitem[Molchanov et~al.(2017)Molchanov, Tyree, Karras, Aila, and
  Kautz]{molchanov2016pruning}
Pavlo Molchanov, Stephen Tyree, Tero Karras, Timo Aila, and Jan Kautz.
\newblock Pruning convolutional neural networks for resource efficient
  inference.
\newblock In \emph{5th International Conference on Learning Representations},
  2017.

\bibitem[Mussay et~al.(2020)Mussay, Osadchy, Braverman, Zhou, and
  Feldman]{myssay2020coreset}
Ben Mussay, Margarita Osadchy, Vladimir Braverman, Samson Zhou, and Dan
  Feldman.
\newblock Data-independent neural pruning via coresets.
\newblock In \emph{8th International Conference on Learning Representations},
  2020.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, Berg, and Fei-Fei]{ILSVRC15}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein,
  Alexander~C. Berg, and Li~Fei-Fei.
\newblock {ImageNet Large Scale Visual Recognition Challenge}.
\newblock \emph{International Journal of Computer Vision}, 115\penalty0
  (3):\penalty0 211--252, 2015.

\bibitem[Simonyan and Zisserman(2015)]{SimonyanZ14a}
Karen Simonyan and Andrew Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock In \emph{3rd International Conference on Learning Representations},
  2015.

\bibitem[Srinivas and Babu(2015)]{BMVC2015_31}
Suraj Srinivas and R.~Venkatesh Babu.
\newblock Data-free parameter pruning for deep neural networks.
\newblock In \emph{Proceedings of the British Machine Vision Conference}, 2015.

\bibitem[Wang et~al.(2020)Wang, Zhang, and Grosse]{wang2020picking}
Chaoqi Wang, Guodong Zhang, and Roger Grosse.
\newblock Picking winning tickets before training by preserving gradient flow.
\newblock In \emph{8th International Conference on Learning Representations},
  2020.

\bibitem[Xiao et~al.(2017)Xiao, Rasul, and Vollgraf]{xiao2017fashion}
Han Xiao, Kashif Rasul, and Roland Vollgraf.
\newblock Fashion-mnist: a novel image dataset for benchmarking machine
  learning algorithms.
\newblock \emph{arXiv preprint arXiv:1708.07747}, 2017.

\bibitem[Ye and Xin~Lu(2018)]{ye2018rethinking}
Jianbo Ye and James Z.~Wang Xin~Lu, Zhe~Lin.
\newblock Rethinking the smaller-norm-less-informative assumption in channel
  pruning of convolution layers.
\newblock In \emph{6th International Conference on Learning Representations},
  2018.

\bibitem[You et~al.(2019)You, Yan, Ye, Ma, and Wang]{you2019gate}
Zhonghui You, Kun Yan, Jinmian Ye, Meng Ma, and Ping Wang.
\newblock Gate decorator: Global filter pruning method for accelerating deep
  convolutional neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Yu et~al.(2018)Yu, Li, Chen, Lai, Morariu, Han, Gao, Lin, and
  Davis]{yu2018nisp}
Ruichi Yu, Ang Li, Chun-Fu Chen, Jui-Hsin Lai, Vlad~I Morariu, Xintong Han,
  Mingfei Gao, Ching-Yung Lin, and Larry~S Davis.
\newblock Nisp: Pruning networks using neuron importance score propagation.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2018.

\bibitem[Zagoruyko and Komodakis(2016)]{BMVC2016_87}
Sergey Zagoruyko and Nikos Komodakis.
\newblock Wide residual networks.
\newblock In \emph{Proceedings of the British Machine Vision Conference}, 2016.

\bibitem[Zhou et~al.(2016)Zhou, Khosla, Lapedriza, Oliva, and
  Torralba]{zhou2016learning}
Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba.
\newblock Learning deep features for discriminative localization.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2016.

\end{thebibliography}
