\begin{thebibliography}{}

\bibitem[Abbasi-Yadkori and Szepesv{\'a}ri, 2011]{abbasi2011regret}
Abbasi-Yadkori, Y. and Szepesv{\'a}ri, C. (2011).
\newblock Regret bounds for the adaptive control of linear quadratic systems.
\newblock In {\em Proceedings of the 24th Annual Conference on Learning
  Theory}, pages 1--26. JMLR Workshop and Conference Proceedings.

\bibitem[Anta and Tabuada, 2010]{anta2010sample}
Anta, A. and Tabuada, P. (2010).
\newblock To sample or not to sample: Self-triggered control for nonlinear
  systems.
\newblock {\em IEEE Transactions on automatic control}, 55(9):2030--2042.

\bibitem[Astrom and Bernhardsson, 2002]{astrom2002comparison}
Astrom, K.~J. and Bernhardsson, B.~M. (2002).
\newblock Comparison of riemann and lebesgue sampling for first order
  stochastic systems.
\newblock In {\em Proceedings of the 41st IEEE Conference on Decision and
  Control, 2002.}, volume~2, pages 2011--2016. IEEE.

\bibitem[Auer et~al., 2008]{auer2008near}
Auer, P., Jaksch, T., and Ortner, R. (2008).
\newblock Near-optimal regret bounds for reinforcement learning.
\newblock {\em Advances in neural information processing systems}, 21.

\bibitem[Basei et~al., 2022]{basei2022logarithmic}
Basei, M., Guo, X., Hu, A., and Zhang, Y. (2022).
\newblock Logarithmic regret for episodic continuous-time linear-quadratic
  reinforcement learning over a finite-time horizon.
\newblock {\em Journal of Machine Learning Research}, 23(178):1--34.

\bibitem[Bradbury et~al., 2018]{jax2018github}
Bradbury, J., Frostig, R., Hawkins, P., Johnson, M.~J., Leary, C., Maclaurin,
  D., Necula, G., Paszke, A., Vander{P}las, J., Wanderman-{M}ilne, S., and
  Zhang, Q. (2018).
\newblock {JAX}: composable transformations of {P}ython+{N}um{P}y programs.

\bibitem[Brockman et~al., 2016]{brockman2016openai}
Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang,
  J., and Zaremba, W. (2016).
\newblock Openai gym.
\newblock {\em arXiv preprint arXiv:1606.01540}.

\bibitem[Chartrand, 2011]{chartrand2011numerical}
Chartrand, R. (2011).
\newblock Numerical differentiation of noisy, nonsmooth data.
\newblock {\em International Scholarly Research Notices}, 2011.

\bibitem[Chen et~al., 2018]{chen2018neural}
Chen, R. T.~Q., Rubanova, Y., Bettencourt, J., and Duvenaud, D.~K. (2018).
\newblock Neural ordinary differential equations.
\newblock In Bengio, S., Wallach, H., Larochelle, H., Grauman, K.,
  Cesa-Bianchi, N., and Garnett, R., editors, {\em Advances in Neural
  Information Processing Systems}, volume~31. Curran Associates, Inc.

\bibitem[Chowdhury and Gopalan, 2017]{chowdhury2017kernelized}
Chowdhury, S.~R. and Gopalan, A. (2017).
\newblock On kernelized multi-armed bandits.
\newblock In {\em International Conference on Machine Learning}, pages
  844--853. PMLR.

\bibitem[Chowdhury and Gopalan, 2019]{chowdhury2019online}
Chowdhury, S.~R. and Gopalan, A. (2019).
\newblock Online learning in kernelized markov decision processes.
\newblock In {\em The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 3197--3205. PMLR.

\bibitem[Chua et~al., 2018]{chua2018deep}
Chua, K., Calandra, R., McAllister, R., and Levine, S. (2018).
\newblock Deep reinforcement learning in a handful of trials using
  probabilistic dynamics models.
\newblock {\em Advances in neural information processing systems}, 31.

\bibitem[Cover, 1999]{cover1999elements}
Cover, T.~M. (1999).
\newblock {\em Elements of information theory}.
\newblock John Wiley \& Sons.

\bibitem[Cranmer et~al., 2020]{cranmer2020lagrangian}
Cranmer, M., Greydanus, S., Hoyer, S., Battaglia, P., Spergel, D., and Ho, S.
  (2020).
\newblock Lagrangian neural networks.
\newblock {\em arXiv preprint arXiv:2003.04630}.

\bibitem[Cullum, 1971]{cullum1971numerical}
Cullum, J. (1971).
\newblock Numerical differentiation and regularization.
\newblock {\em SIAM Journal on numerical analysis}, 8(2):254--265.

\bibitem[Curi et~al., 2020]{curi2020efficient}
Curi, S., Berkenkamp, F., and Krause, A. (2020).
\newblock Efficient model-based reinforcement learning through optimistic
  policy search and planning.
\newblock {\em Advances in Neural Information Processing Systems},
  33:14156--14170.

\bibitem[Dearden et~al., 2013]{dearden2013model}
Dearden, R., Friedman, N., and Andre, D. (2013).
\newblock Model-based bayesian exploration.
\newblock {\em arXiv preprint arXiv:1301.6690}.

\bibitem[Deisenroth and Rasmussen, 2011]{deisenroth2011pilco}
Deisenroth, M. and Rasmussen, C.~E. (2011).
\newblock Pilco: A model-based and data-efficient approach to policy search.
\newblock In {\em Proceedings of the 28th International Conference on machine
  learning (ICML-11)}, pages 465--472.

\bibitem[Doya, 2000]{doya2000reinforcement}
Doya, K. (2000).
\newblock Reinforcement learning in continuous time and space.
\newblock {\em Neural computation}, 12(1):219--245.

\bibitem[Du et~al., 2020]{du2020model}
Du, J., Futoma, J., and Doshi-Velez, F. (2020).
\newblock Model-based reinforcement learning for semi-markov decision processes
  with neural odes.
\newblock {\em Advances in Neural Information Processing Systems},
  33:19805--19816.

\bibitem[Engquist et~al., 2007]{engquist2007heterogeneous}
Engquist, B., Li, X., Ren, W., Vanden-Eijnden, E., et~al. (2007).
\newblock Heterogeneous multiscale methods: a review.
\newblock {\em Communications in Computational Physics}, 2(3):367--450.

\bibitem[G{\"a}fvert, 2016]{gafvert2016modelling}
G{\"a}fvert, M. (2016).
\newblock {\em Modelling the furuta pendulum}.
\newblock Department of Automatic Control, Lund Institute of Technology (LTH).

\bibitem[Ghysels et~al., 2006]{ghysels2006predicting}
Ghysels, E., Santa-Clara, P., and Valkanov, R. (2006).
\newblock Predicting volatility: getting the most out of return data sampled at
  different frequencies.
\newblock {\em Journal of Econometrics}, 131(1-2):59--95.

\bibitem[Greydanus et~al., 2019]{greydanus2019hamiltonian}
Greydanus, S., Dzamba, M., and Yosinski, J. (2019).
\newblock Hamiltonian neural networks.
\newblock {\em Advances in neural information processing systems}, 32.

\bibitem[Haarnoja et~al., 2018]{haarnoja2018soft}
Haarnoja, T., Zhou, A., Hartikainen, K., Tucker, G., Ha, S., Tan, J., Kumar,
  V., Zhu, H., Gupta, A., Abbeel, P., et~al. (2018).
\newblock Soft actor-critic algorithms and applications.
\newblock {\em arXiv preprint arXiv:1812.05905}.

\bibitem[Hartman, 2002]{hartman2002ordinary}
Hartman, P. (2002).
\newblock {\em Ordinary differential equations}.
\newblock SIAM.

\bibitem[Heemels et~al., 2021]{heemels2021event}
Heemels, W., Johansson, K.~H., and Tabuada, P. (2021).
\newblock Event-triggered and self-triggered control.
\newblock In {\em Encyclopedia of Systems and Control}, pages 724--730.
  Springer.

\bibitem[Heemels et~al., 2012]{heemels2012introduction}
Heemels, W.~P., Johansson, K.~H., and Tabuada, P. (2012).
\newblock An introduction to event-triggered and self-triggered control.
\newblock In {\em 2012 ieee 51st ieee conference on decision and control
  (cdc)}, pages 3270--3285. IEEE.

\bibitem[Holzm{\"u}ller et~al., 2022]{holzmuller2022framework}
Holzm{\"u}ller, D., Zaverkin, V., K{\"a}stner, J., and Steinwart, I. (2022).
\newblock A framework and benchmark for deep batch active learning for
  regression.
\newblock {\em arXiv preprint arXiv:2203.09410}.

\bibitem[Howe et~al., 2022]{howe2022myriad}
Howe, N., Dufort-Labb{\'e}, S., Rajkumar, N., and Bacon, P.-L. (2022).
\newblock Myriad: a real-world testbed to bridge trajectory optimization and
  deep learning.
\newblock {\em Advances in Neural Information Processing Systems},
  35:29801--29815.

\bibitem[Jacobson and Mayne, 1970]{jacobson1970differential}
Jacobson, D.~H. and Mayne, D.~Q. (1970).
\newblock {\em Differential dynamic programming}.
\newblock Number~24. Elsevier Publishing Company.

\bibitem[Jones et~al., 2009]{jones2009differential}
Jones, D.~S., Plank, M., and Sleeman, B.~D. (2009).
\newblock {\em Differential equations and mathematical biology}.
\newblock CRC press.

\bibitem[Kaandorp and Koole, 2007]{kaandorp2007optimal}
Kaandorp, G.~C. and Koole, G. (2007).
\newblock Optimal outpatient appointment scheduling.
\newblock {\em Health care management science}, 10:217--229.

\bibitem[Kakade et~al., 2020]{kakade2020information}
Kakade, S., Krishnamurthy, A., Lowrey, K., Ohnishi, M., and Sun, W. (2020).
\newblock Information theoretic regret bounds for online nonlinear control.
\newblock {\em Advances in Neural Information Processing Systems},
  33:15312--15325.

\bibitem[Kelly, 2017]{kelly2017introduction}
Kelly, M. (2017).
\newblock An introduction to trajectory optimization: How to do your own direct
  collocation.
\newblock {\em SIAM Review}, 59(4):849--904.

\bibitem[Khalil, 2015]{khalil2015nonlinear}
Khalil, H.~K. (2015).
\newblock {\em Nonlinear control}, volume 406.
\newblock Pearson New York.

\bibitem[Kirschner and Krause, 2018]{kirschner2018information}
Kirschner, J. and Krause, A. (2018).
\newblock Information directed sampling and bandits with heteroscedastic noise.
\newblock In {\em Conference On Learning Theory}, pages 358--384. PMLR.

\bibitem[Knowles and Renka, 2014]{knowles2014methods}
Knowles, I. and Renka, R.~J. (2014).
\newblock Methods for numerical differentiation of noisy data.
\newblock {\em Electron. J. Differ. Equ}, 21:235--246.

\bibitem[Knowles and Wallace, 1995]{knowles1995variational}
Knowles, I. and Wallace, R. (1995).
\newblock A variational method for numerical differentiation.
\newblock {\em Numerische Mathematik}, 70:91--110.

\bibitem[Kuleshov et~al., 2018]{kuleshov2018accurate}
Kuleshov, V., Fenner, N., and Ermon, S. (2018).
\newblock Accurate uncertainties for deep learning using calibrated regression.
\newblock In {\em International conference on machine learning}, pages
  2796--2804. PMLR.

\bibitem[Lederer et~al., 2021]{lederer2021gaussian}
Lederer, A., Conejo, A. J.~O., Maier, K.~A., Xiao, W., Umlauft, J., and Hirche,
  S. (2021).
\newblock Gaussian process-based real-time learning for safety critical
  applications.
\newblock In {\em International Conference on Machine Learning}, pages
  6055--6064. PMLR.

\bibitem[Lenhart and Workman, 2007]{lenhart2007optimal}
Lenhart, S. and Workman, J.~T. (2007).
\newblock {\em Optimal control applied to biological models}.
\newblock CRC press.

\bibitem[Li and Todorov, 2004]{li2004iterative}
Li, W. and Todorov, E. (2004).
\newblock Iterative linear quadratic regulator design for nonlinear biological
  movement systems.
\newblock In {\em ICINCO (1)}, pages 222--229. Citeseer.

\bibitem[Lillicrap et~al., 2015]{lillicrap2015continuous}
Lillicrap, T.~P., Hunt, J.~J., Pritzel, A., Heess, N., Erez, T., Tassa, Y.,
  Silver, D., and Wierstra, D. (2015).
\newblock Continuous control with deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1509.02971}.

\bibitem[Luo et~al., 2018]{luo2018algorithmic}
Luo, Y., Xu, H., Li, Y., Tian, Y., Darrell, T., and Ma, T. (2018).
\newblock Algorithmic framework for model-based deep reinforcement learning
  with theoretical guarantees.
\newblock {\em arXiv preprint arXiv:1807.03858}.

\bibitem[Lutter et~al., 2021]{lutter2021value}
Lutter, M., Mannor, S., Peters, J., Fox, D., and Garg, A. (2021).
\newblock Value iteration in continuous actions, states and time.
\newblock {\em arXiv preprint arXiv:2105.04682}.

\bibitem[Modares and Lewis, 2014]{modares2014linear}
Modares, H. and Lewis, F.~L. (2014).
\newblock Linear quadratic tracking control of partially-unknown
  continuous-time systems using reinforcement learning.
\newblock {\em IEEE Transactions on Automatic control}, 59(11):3051--3056.

\bibitem[Mohammadi et~al., 2021]{mohammadi2021convergence}
Mohammadi, H., Zare, A., Soltanolkotabi, M., and Jovanovi{\'c}, M.~R. (2021).
\newblock Convergence and sample complexity of gradient methods for the
  model-free linear--quadratic regulator problem.
\newblock {\em IEEE Transactions on Automatic Control}, 67(5):2435--2450.

\bibitem[Morari and Lee, 1999]{morari1999model}
Morari, M. and Lee, J.~H. (1999).
\newblock Model predictive control: past, present and future.
\newblock {\em Computers \& Chemical Engineering}, 23(4-5):667--682.

\bibitem[Mordatch et~al., 2012]{mordatch2012discovery}
Mordatch, I., Todorov, E., and Popovi{\'c}, Z. (2012).
\newblock Discovery of complex behaviors through contact-invariant
  optimization.
\newblock {\em ACM Transactions on Graphics (ToG)}, 31(4):1--8.

\bibitem[Nesic and Postoyan, 2021]{nesic2021nonlinear}
Nesic, D. and Postoyan, R. (2021).
\newblock Nonlinear sampled-data systems.
\newblock In {\em Encyclopedia of Systems and Control}, pages 1477--1483.
  Springer.

\bibitem[Nonami et~al., 2010]{nonami2010autonomous}
Nonami, K., Kendoul, F., Suzuki, S., Wang, W., and Nakazawa, D. (2010).
\newblock {\em Autonomous flying robots: unmanned aerial vehicles and micro
  aerial vehicles}.
\newblock Springer Science \& Business Media.

\bibitem[Osband et~al., 2013]{osband2013more}
Osband, I., Russo, D., and Van~Roy, B. (2013).
\newblock (more) efficient reinforcement learning via posterior sampling.
\newblock {\em Advances in Neural Information Processing Systems}, 26.

\bibitem[Osband and Van~Roy, 2014]{osband2014model}
Osband, I. and Van~Roy, B. (2014).
\newblock Model-based reinforcement learning and the eluder dimension.
\newblock {\em Advances in Neural Information Processing Systems}, 27.

\bibitem[Paing et~al., 2020]{paing2020new}
Paing, H.~S., Schagin, A.~V., Win, K.~S., and Linn, Y.~H. (2020).
\newblock New designing approaches for quadcopter using 2d model modelling a
  cascaded pid controller.
\newblock In {\em 2020 IEEE Conference of Russian Young Researchers in
  Electrical and Electronic Engineering (EIConRus)}, pages 2370--2373. IEEE.

\bibitem[Panetta and Fister, 2003]{panetta2003optimal}
Panetta, J.~C. and Fister, K.~R. (2003).
\newblock Optimal control applied to competing chemotherapeutic cell-kill
  strategies.
\newblock {\em SIAM Journal on Applied Mathematics}, 63(6):1954--1971.

\bibitem[Pasztor et~al., 2021]{pasztor2021efficient}
Pasztor, B., Bogunovic, I., and Krause, A. (2021).
\newblock Efficient model-based multi-agent mean-field reinforcement learning.
\newblock {\em arXiv preprint arXiv:2107.04050}.

\bibitem[Polack et~al., 2017]{polack2017kinematic}
Polack, P., Altch{\'e}, F., d'Andr{\'e}a Novel, B., and de~La~Fortelle, A.
  (2017).
\newblock The kinematic bicycle model: A consistent model for planning feasible
  trajectories for autonomous vehicles?
\newblock In {\em 2017 IEEE intelligent vehicles symposium (IV)}, pages
  812--818. IEEE.

\bibitem[Rothfuss et~al., 2023]{rothfuss2023hallucinated}
Rothfuss, J., Sukhija, B., Birchler, T., Kassraie, P., and Krause, A. (2023).
\newblock Hallucinated adversarial control for conservative offline policy
  evaluation.
\newblock {\em arXiv preprint arXiv:2303.01076}.

\bibitem[Russo and Van~Roy, 2014]{russo2014learning}
Russo, D. and Van~Roy, B. (2014).
\newblock Learning to optimize via posterior sampling.
\newblock {\em Mathematics of Operations Research}, 39(4):1221--1243.

\bibitem[Russo and Van~Roy, 2016]{russo2016information}
Russo, D. and Van~Roy, B. (2016).
\newblock An information-theoretic analysis of thompson sampling.
\newblock {\em The Journal of Machine Learning Research}, 17(1):2442--2471.

\bibitem[Schulman et~al., 2017]{schulman2017proximal}
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O. (2017).
\newblock Proximal policy optimization algorithms.
\newblock {\em arXiv preprint arXiv:1707.06347}.

\bibitem[Simchowitz and Foster, 2020]{simchowitz2020naive}
Simchowitz, M. and Foster, D. (2020).
\newblock Naive exploration is optimal for online lqr.
\newblock In {\em International Conference on Machine Learning}, pages
  8937--8948. PMLR.

\bibitem[Singh and Theers, 2021]{bicycle}
Singh, M. and Theers, M. (2021).
\newblock Kinematic bicycle model.
\newblock
  \url{https://thomasfermi.github.io/Algorithms-for-Automated-Driving/Control/BicycleModel.html}.
\newblock Accessed: 2023-10-09.

\bibitem[Spong et~al., 2006]{spong2006robot}
Spong, M.~W., Hutchinson, S., Vidyasagar, M., et~al. (2006).
\newblock {\em Robot modeling and control}, volume~3.
\newblock Wiley New York.

\bibitem[Srinivas et~al., 2009]{srinivas2009gaussian}
Srinivas, N., Krause, A., Kakade, S.~M., and Seeger, M. (2009).
\newblock Gaussian process optimization in the bandit setting: No regret and
  experimental design.
\newblock {\em arXiv preprint arXiv:0912.3995}.

\bibitem[Sussex et~al., 2023]{sussex2022model}
Sussex, S., Makarova, A., and Krause, A. (2023).
\newblock Model-based causal bayesian optimization.
\newblock In {\em International Conference on Learning Representations (ICLR)}.

\bibitem[Sutton and Barto, 2018]{sutton2018reinforcement}
Sutton, R.~S. and Barto, A.~G. (2018).
\newblock {\em Reinforcement learning: An introduction}.
\newblock MIT press.

\bibitem[Tallec et~al., 2019]{tallec2019making}
Tallec, C., Blier, L., and Ollivier, Y. (2019).
\newblock Making deep q-learning methods robust to time discretization.
\newblock In {\em International Conference on Machine Learning}, pages
  6096--6104. PMLR.

\bibitem[Thomas et~al., 2017]{thomas2017autonomous}
Thomas, J., Welde, J., Loianno, G., Daniilidis, K., and Kumar, V. (2017).
\newblock Autonomous flight for detection, localization, and tracking of moving
  targets with a small quadrotor.
\newblock {\em IEEE Robotics and Automation Letters}, 2(3):1762--1769.

\bibitem[Thompson, 1933]{thompson1933likelihood}
Thompson, W.~R. (1933).
\newblock On the likelihood that one unknown probability exceeds another in
  view of the evidence of two samples.
\newblock {\em Biometrika}, 25(3-4):285--294.

\bibitem[Todorov and Li, 2005]{todorov2005generalized}
Todorov, E. and Li, W. (2005).
\newblock A generalized iterative lqg method for locally-optimal feedback
  control of constrained nonlinear stochastic systems.
\newblock In {\em Proceedings of the 2005, American Control Conference, 2005.},
  pages 300--306. IEEE.

\bibitem[Treven et~al., 2021]{treven2021distributional}
Treven, L., Wenk, P., Dorfler, F., and Krause, A. (2021).
\newblock Distributional gradient matching for learning uncertain neural
  dynamics models.
\newblock {\em Advances in Neural Information Processing Systems},
  34:29780--29793.

\bibitem[Umlauft and Hirche, 2019]{umlauft2019feedback}
Umlauft, J. and Hirche, S. (2019).
\newblock Feedback linearization based on gaussian processes with
  event-triggered online learning.
\newblock {\em IEEE Transactions on Automatic Control}, 65(10):4154--4169.

\bibitem[Vakili et~al., 2021]{vakili2021information}
Vakili, S., Khezeli, K., and Picheny, V. (2021).
\newblock On information gain and regret bounds in gaussian process bandits.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 82--90. PMLR.

\bibitem[Vamvoudakis et~al., 2009]{vamvoudakis2009online}
Vamvoudakis, K., Vrabie, D., and Lewis, F. (2009).
\newblock Online policy iteration based algorithms to solve the continuous-time
  infinite horizon optimal control problem.
\newblock In {\em 2009 IEEE Symposium on Adaptive Dynamic Programming and
  Reinforcement Learning}, pages 36--41. IEEE.

\bibitem[Vrabie and Lewis, 2009]{vrabie2009neural}
Vrabie, D. and Lewis, F. (2009).
\newblock Neural network approach to continuous-time direct adaptive optimal
  control for partially unknown nonlinear systems.
\newblock {\em Neural Networks}, 22(3):237--246.

\bibitem[Vrabie and Lewis, 2008]{vrabie2008adaptive}
Vrabie, D. and Lewis, F.~L. (2008).
\newblock Adaptive optimal control algorithm for continuous-time nonlinear
  systems based on policy iteration.
\newblock In {\em 2008 47th IEEE Conference on Decision and Control}, pages
  73--79. IEEE.

\bibitem[Wagener et~al., 2019]{wagener2019online}
Wagener, N., Cheng, C.-A., Sacks, J., and Boots, B. (2019).
\newblock An online learning approach to model predictive control.
\newblock {\em arXiv preprint arXiv:1902.08967}.

\bibitem[Wagner et~al., 2018]{wagner2018regularised}
Wagner, J., Mazurek, P., Mi{\k{e}}kina, A., and Morawski, R.~Z. (2018).
\newblock Regularised differentiation of measurement data in systems for
  monitoring of human movements.
\newblock {\em Biomedical Signal Processing and Control}, 43:265--277.

\bibitem[Wang et~al., 2020]{wang2020reinforcement}
Wang, H., Zariphopoulou, T., and Zhou, X.~Y. (2020).
\newblock Reinforcement learning in continuous time and space: A stochastic
  control approach.
\newblock {\em The Journal of Machine Learning Research}, 21(1):8145--8178.

\bibitem[Williams and Rasmussen, 2006]{williams2006gaussian}
Williams, C.~K. and Rasmussen, C.~E. (2006).
\newblock {\em Gaussian processes for machine learning}, volume~2.
\newblock MIT press Cambridge, MA.

\bibitem[Williams et~al., 2017]{williams2017model}
Williams, G., Aldrich, A., and Theodorou, E.~A. (2017).
\newblock Model predictive path integral control: From theory to parallel
  computation.
\newblock {\em Journal of Guidance, Control, and Dynamics}, 40(2):344--357.

\bibitem[Yildiz et~al., 2021]{yildiz2021continuous}
Yildiz, C., Heinonen, M., and L{\"a}hdesm{\"a}ki, H. (2021).
\newblock Continuous-time model-based reinforcement learning.
\newblock In {\em International Conference on Machine Learning}, pages
  12009--12018. PMLR.

\end{thebibliography}
