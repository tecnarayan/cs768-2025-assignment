\begin{thebibliography}{39}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ali \& Silvey(1966)Ali and Silvey]{ali_general_1966}
Ali, S.~M. and Silvey, S.~D.
\newblock A general class of coefficients of divergence of one distribution from another.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Methodological)}, 1966.

\bibitem[Bagdasaryan et~al.(2019)Bagdasaryan, Poursaeed, and Shmatikov]{bagdasaryan2019differential}
Bagdasaryan, E., Poursaeed, O., and Shmatikov, V.
\newblock Differential privacy has disparate impact on model accuracy.
\newblock \emph{Advances in neural information processing systems}, 2019.

\bibitem[Berk et~al.(2017)Berk, Heidari, Jabbari, Joseph, Kearns, Morgenstern, Neel, and Roth]{berk_convex_2017}
Berk, R., Heidari, H., Jabbari, S., Joseph, M., Kearns, M., Morgenstern, J., Neel, S., and Roth, A.
\newblock A convex framework for fair regression.
\newblock \emph{arXiv:1706.02409}, 2017.

\bibitem[Burrell et~al.(2019)Burrell, Kahn, Jonas, and Griffin]{burrell_when_2019}
Burrell, J., Kahn, Z., Jonas, A., and Griffin, D.
\newblock When users control the algorithms: Values expressed in practices on twitter.
\newblock In \emph{Proceedings of the ACM on Human-Computer Interaction}, 2019.

\bibitem[Chen(2018)]{chen_thrown_2018}
Chen, J.~Y.
\newblock Thrown under the bus and outrunning it! the logic of didi and taxi drivers’ labour and activism in the on-demand economy.
\newblock \emph{New Media \& Society}, 2018.

\bibitem[Christiano et~al.(2017)Christiano, Leike, Brown, Martic, Legg, and Amodei]{christiano2017deep}
Christiano, P.~F., Leike, J., Brown, T., Martic, M., Legg, S., and Amodei, D.
\newblock Deep reinforcement learning from human preferences.
\newblock \emph{Advances in neural information processing systems}, 2017.

\bibitem[Csiszár(1967)]{csiszar_information-type_1967}
Csiszár, I.
\newblock On information-type measure of difference of probability distributions and indirect observations.
\newblock \emph{Studia Sci. Math. Hungar.}, 1967.

\bibitem[Delage \& Ye(2010)Delage and Ye]{delage_distributionally_2010}
Delage, E. and Ye, Y.
\newblock Distributionally robust optimization under moment uncertainty with application to data-drivenproblems.
\newblock \emph{Operations Research}, 2010.

\bibitem[Duchi \& Namkoong(2019)Duchi and Namkoong]{duchi_variance-based_2019}
Duchi, J. and Namkoong, H.
\newblock Variance-based regularization with convex objectives.
\newblock \emph{Journal of Machine Learning Research}, 2019.

\bibitem[Duchi \& Namkoong(2021)Duchi and Namkoong]{duchi_learning_2021}
Duchi, J.~C. and Namkoong, H.
\newblock Learning models with uniform performance via distributionally robust optimization.
\newblock \emph{The Annals of Statistics}, 2021.

\bibitem[Gerlitz \& Helmond(2013)Gerlitz and Helmond]{gerlitz_like_2013}
Gerlitz, C. and Helmond, A.
\newblock The like economy: Social buttons and the data-intensive web.
\newblock \emph{New media \& society}, 2013.

\bibitem[Hardt et~al.(2023)Hardt, Mazumdar, Mendler-Dünner, and Zrnic]{hardt_algorithmic_2023}
Hardt, M., Mazumdar, E., Mendler-Dünner, C., and Zrnic, T.
\newblock Algorithmic collective action in machine learning.
\newblock In \emph{International Conference on Machine Learning}, volume 2022, 2023.

\bibitem[Hashimoto et~al.(2018)Hashimoto, Srivastava, Namkoong, and Liang]{hashimoto_fairness_2018}
Hashimoto, T., Srivastava, M., Namkoong, H., and Liang, P.
\newblock Fairness without demographics in repeated loss minimization.
\newblock In \emph{Proceedings of the 35th International Conference on Machine Learning}, Proceedings of Machine Learning Research, 2018.

\bibitem[Hendrycks \& Dietterich(2019)Hendrycks and Dietterich]{hendrycks_benchmarking_2019}
Hendrycks, D. and Dietterich, T.
\newblock Benchmarking {Neural} {Network} {Robustness} to {Common} {Corruptions} and {Perturbations}.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Hermann et~al.(2020)Hermann, Chen, and Kornblith]{hermann_origins_2020}
Hermann, K., Chen, T., and Kornblith, S.
\newblock The origins and prevalence of texture bias in convolutional neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Kalimeris et~al.(2019)Kalimeris, Kaplun, Nakkiran, Edelman, Yang, Barak, and Zhang]{kalimeris_sgd_2019}
Kalimeris, D., Kaplun, G., Nakkiran, P., Edelman, B., Yang, T., Barak, B., and Zhang, H.
\newblock Sgd on neural networks learns functions of increasing complexity.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{kingma_adam_2015}
Kingma, D.~P. and Ba, J.
\newblock Adam: {A} {Method} for {Stochastic} {Optimization}.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Koh et~al.(2021)Koh, Sagawa, Marklund, Xie, Zhang, Balsubramani, Hu, Yasunaga, Phillips, Gao, et~al.]{koh_wilds_2021}
Koh, P.~W., Sagawa, S., Marklund, H., Xie, S.~M., Zhang, M., Balsubramani, A., Hu, W., Yasunaga, M., Phillips, R.~L., Gao, I., et~al.
\newblock Wilds: A benchmark of in-the-wild distribution shifts.
\newblock In \emph{International Conference on Machine Learning}, 2021.

\bibitem[Krizhevsky(2009)]{krizhevsky_learning_2009}
Krizhevsky, A.
\newblock Learning multiple layers of features from tiny images, 2009.

\bibitem[Levine et~al.(2022)Levine, Wies, Jannai, Navon, Hoshen, and Shashua]{levine_inductive_2022}
Levine, Y., Wies, N., Jannai, D., Navon, D., Hoshen, Y., and Shashua, A.
\newblock The inductive bias of in-context learning: Rethinking pretraining example design.
\newblock In \emph{International Conference on Learning Representations}, 2022.

\bibitem[Levy et~al.(2020)Levy, Carmon, Duchi, and Sidford]{levy_large-scale_2020}
Levy, D., Carmon, Y., Duchi, J.~C., and Sidford, A.
\newblock Large-scale methods for distributionally robust optimization.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Liu et~al.(2021)Liu, Haghgoo, Chen, Raghunathan, Koh, Sagawa, Liang, and Finn]{liu_just_2021}
Liu, E.~Z., Haghgoo, B., Chen, A.~S., Raghunathan, A., Koh, P.~W., Sagawa, S., Liang, P., and Finn, C.
\newblock Just train twice: Improving group robustness without training group information.
\newblock In \emph{Proceedings of the 38th {International} {Conference} on {Machine} {Learning}}, 2021.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and Vladu]{madry2018towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Meinshausen \& Bühlmann(2015)Meinshausen and Bühlmann]{meinshausen_maximin_2015}
Meinshausen, N. and Bühlmann, P.
\newblock Maximin effects in inhomogeneous large-scale data.
\newblock \emph{The Annals of Statistics}, 2015.

\bibitem[Nam et~al.(2020)Nam, Cha, Ahn, Lee, and Shin]{nam_learning_2020}
Nam, J., Cha, H., Ahn, S., Lee, J., and Shin, J.
\newblock Learning from failure: De-biasing classifier from biased classifier.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Namkoong \& Duchi(2016)Namkoong and Duchi]{namkoong_stochastic_2016}
Namkoong, H. and Duchi, J.~C.
\newblock Stochastic gradient methods for distributionally robust optimization with f-divergences.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Olson(1965)]{olson_logic_1965}
Olson, M.
\newblock The logic of collective action.
\newblock \emph{Contemporary Sociological Theory}, 1965.

\bibitem[Paleka \& Sanyal(2023)Paleka and Sanyal]{paleka2023a}
Paleka, D. and Sanyal, A.
\newblock A law of adversarial risk, interpolation, and label noise.
\newblock In \emph{International Conference on Learning Representations}, 2023.

\bibitem[Prost et~al.(2019)Prost, Qian, Chen, Chi, Chen, and Beutel]{prost2019toward}
Prost, F., Qian, H., Chen, Q., Chi, E.~H., Chen, J., and Beutel, A.
\newblock Toward a better trade-off between performance and fairness with kernel-based distribution matching.
\newblock \emph{arXiv:1910.11779}, 2019.

\bibitem[Rafailov et~al.(2024)Rafailov, Sharma, Mitchell, Manning, Ermon, and Finn]{rafailov2024direct}
Rafailov, R., Sharma, A., Mitchell, E., Manning, C.~D., Ermon, S., and Finn, C.
\newblock Direct preference optimization: Your language model is secretly a reward model.
\newblock \emph{Advances in Neural Information Processing Systems}, 2024.

\bibitem[Rahman(2021)]{rahman_invisible_2021}
Rahman, H.~A.
\newblock The invisible cage: Workers’ reactivity to opaque algorithmic evaluations.
\newblock \emph{Administrative Science Quarterly}, 2021.

\bibitem[Sagawa et~al.(2020)Sagawa, Koh, Hashimoto, and Liang]{sagawa_distributionally_2020}
Sagawa, S., Koh, P.~W., Hashimoto, T.~B., and Liang, P.
\newblock Distributionally {Robust} {Neural} {Networks}.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Sanyal et~al.(2022)Sanyal, Hu, and Yang]{sanyal2022unfair}
Sanyal, A., Hu, Y., and Yang, F.
\newblock How unfair is private learning?
\newblock In \emph{Uncertainty in Artificial Intelligence}, 2022.

\bibitem[Shah et~al.(2020)Shah, Tamuly, Raghunathan, Jain, and Netrapalli]{shah_pitfalls_2020}
Shah, H., Tamuly, K., Raghunathan, A., Jain, P., and Netrapalli, P.
\newblock The pitfalls of simplicity bias in neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Shi et~al.(2023)Shi, Daunhawer, Vogt, Torr, and Sanyal]{shi2023how}
Shi, Y., Daunhawer, I., Vogt, J.~E., Torr, P., and Sanyal, A.
\newblock How robust is unsupervised representation learning to distribution shift?
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.

\bibitem[{\c{T}}ifrea et~al.(2024){\c{T}}ifrea, Lahoti, Packer, Halpern, Beirami, and Prost]{ctifrea2023frapp}
{\c{T}}ifrea, A., Lahoti, P., Packer, B., Halpern, Y., Beirami, A., and Prost, F.
\newblock Frapp$\backslash$'e: A post-processing framework for group fairness regularization.
\newblock In \emph{International Conference on Machine Learning}, 2024.

\bibitem[Wang et~al.(2020)Wang, Guo, Narasimhan, Cotter, Gupta, and Jordan]{wang_robust_2020}
Wang, S., Guo, W., Narasimhan, H., Cotter, A., Gupta, M., and Jordan, M.
\newblock Robust optimization for fairness with noisy protected groups.
\newblock In \emph{Advances in {Neural} {Information} {Processing} {Systems}}, 2020.

\bibitem[White \& Cotterell(2021)White and Cotterell]{white_examining_2021}
White, J.~C. and Cotterell, R.
\newblock Examining the inductive bias of neural language models with artificial languages.
\newblock In \emph{Annual Meeting of the Association for Computational Linguistics}, 2021.

\bibitem[Ziegler et~al.(2022)Ziegler, Nix, Chan, Bauman, Schmidt-Nielsen, Lin, Scherlis, Nabeshima, Weinstein-Raun, de~Haas, et~al.]{ziegler2022adversarial}
Ziegler, D., Nix, S., Chan, L., Bauman, T., Schmidt-Nielsen, P., Lin, T., Scherlis, A., Nabeshima, N., Weinstein-Raun, B., de~Haas, D., et~al.
\newblock Adversarial training for high-stakes reliability.
\newblock \emph{Advances in Neural Information Processing Systems}, 2022.

\end{thebibliography}
