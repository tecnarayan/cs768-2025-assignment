\begin{thebibliography}{70}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2020)Agarwal, Schuurmans, and
  Norouzi]{agarwal2020optimistic}
Agarwal, R., Schuurmans, D., and Norouzi, M.
\newblock An optimistic perspective on offline reinforcement learning.
\newblock In \emph{ICML}, 2020.

\bibitem[Anand et~al.(2019)Anand, Racah, Ozair, Bengio, C{\^o}t{\'e}, and
  Hjelm]{stdim}
Anand, A., Racah, E., Ozair, S., Bengio, Y., C{\^o}t{\'e}, M.-A., and Hjelm,
  R.~D.
\newblock Unsupervised state representation learning in atari.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Andrychowicz et~al.(2017)Andrychowicz, Wolski, Ray, Schneider, Fong,
  Welinder, McGrew, Tobin, Abbeel, and Zaremba]{andrychowicz2017hindsight}
Andrychowicz, M., Wolski, F., Ray, A., Schneider, J., Fong, R., Welinder, P.,
  McGrew, B., Tobin, J., Abbeel, O.~P., and Zaremba, W.
\newblock Hindsight experience replay.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  5048--5058, 2017.

\bibitem[Anonymous(2021)]{rl_precipice}
Anonymous.
\newblock Deep reinforcement learning at the edge of the statistical precipice,
  2021.
\newblock See supplemental materials.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016layer}
Ba, J.~L., Kiros, J.~R., and Hinton, G.~E.
\newblock Layer normalization.
\newblock \emph{arXiv preprint arXiv:1607.06450}, 2016.

\bibitem[Bachman et~al.(2019)Bachman, Hjelm, and Buchwalter]{amdim}
Bachman, P., Hjelm, R.~D., and Buchwalter, W.
\newblock Learning representations by maximizing mutual information across
  views.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Bellemare et~al.(2017)Bellemare, Dabney, and
  Munos]{bellemare2017distributional}
Bellemare, M.~G., Dabney, W., and Munos, R.
\newblock A distributional perspective on reinforcement learning.
\newblock \emph{ICML}, 2017.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{gpt3}
Brown, T.~B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et~al.
\newblock Language models are few-shot learners.
\newblock \emph{arXiv preprint arXiv:2005.14165}, 2020.

\bibitem[Burda et~al.(2018)Burda, Edwards, Pathak, Storkey, Darrell, and
  Efros]{burda2018largescale}
Burda, Y., Edwards, H., Pathak, D., Storkey, A., Darrell, T., and Efros, A.~A.
\newblock Large-scale study of curiosity-driven learning, 2018.

\bibitem[Campos et~al.(2021)Campos, Sprechmann, Hansen, Barreto, Blundell,
  Vitvitskyi, Kapturowski, and Badia]{campos2021coverage}
Campos, V., Sprechmann, P., Hansen, S.~S., Barreto, A., Blundell, C.,
  Vitvitskyi, A., Kapturowski, S., and Badia, A.~P.
\newblock Coverage as a principle for discovering transferable behavior in
  reinforcement learning, 2021.
\newblock URL \url{https://openreview.net/forum?id=INhwJdJtxn6}.

\bibitem[Castro et~al.(2018)Castro, Moitra, Gelada, Kumar, and
  Bellemare]{castro18dopamine}
Castro, P.~S., Moitra, S., Gelada, C., Kumar, S., and Bellemare, M.~G.
\newblock Dopamine: {A} {R}esearch {F}ramework for {D}eep {R}einforcement
  {L}earning.
\newblock 2018.
\newblock URL \url{http://arxiv.org/abs/1812.06110}.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Kornblith, Norouzi, and
  Hinton]{simCLR}
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock \emph{ICML}, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Kornblith, Swersky, Norouzi, and
  Hinton]{simCLRv2}
Chen, T., Kornblith, S., Swersky, K., Norouzi, M., and Hinton, G.
\newblock Big self-supervised models are strong semi-supervised learners.
\newblock In \emph{NeurIPS}, 2020{\natexlab{b}}.

\bibitem[Chu et~al.(2016)Chu, Madhavan, Beijbom, Hoffman, and
  Darrell]{chu2016best}
Chu, B., Madhavan, V., Beijbom, O., Hoffman, J., and Darrell, T.
\newblock \emph{Best Practices for Fine-Tuning Visual Classifiers to New
  Domains}, pp.\  435--442.
\newblock 11 2016.
\newblock ISBN 978-3-319-49408-1.
\newblock \doi{10.1007/978-3-319-49409-8_34}.

\bibitem[Dabney et~al.(2021)Dabney, Barreto, Rowland, Dadashi, Quan, Bellemare,
  and Silver]{dabney2020value}
Dabney, W., Barreto, A., Rowland, M., Dadashi, R., Quan, J., Bellemare, M.~G.,
  and Silver, D.
\newblock The value-improvement path: Towards better representations for
  reinforcement learning.
\newblock 2021.

\bibitem[Degris \& Modayil(2012)Degris and Modayil]{degris2012scaling}
Degris, T. and Modayil, J.
\newblock Scaling-up knowledge for a cognizant robot.
\newblock In \emph{AAAI Spring Symposium on Designing Intelligent Robots:
  Reintegrating AI.}, 2012.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{devlin2019-bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{ACL}, 2019.

\bibitem[Dubey et~al.(2018)Dubey, Agrawal, Pathak, Griffiths, and
  Efros]{dubey2018investigating}
Dubey, R., Agrawal, P., Pathak, D., Griffiths, T., and Efros, A.
\newblock Investigating human priors for playing video games.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Dulac-Arnold et~al.(2020)Dulac-Arnold, Levine, Mankowitz, Li,
  Paduraru, Gowal, and Hester]{dulacarnold2020realworldrlempirical}
Dulac-Arnold, G., Levine, N., Mankowitz, D.~J., Li, J., Paduraru, C., Gowal,
  S., and Hester, T.
\newblock An empirical investigation of the challenges of real-world
  reinforcement learning.
\newblock 2020.

\bibitem[Espeholt et~al.(2018)Espeholt, Soyer, Munos, Simonyan, Mnih, Ward,
  Doron, Firoiu, Harley, Dunning, Legg, and Kavukcuoglu]{impala}
Espeholt, L., Soyer, H., Munos, R., Simonyan, K., Mnih, V., Ward, T., Doron,
  Y., Firoiu, V., Harley, T., Dunning, I., Legg, S., and Kavukcuoglu, K.
\newblock {IMPALA:} scalable distributed deep-rl with importance weighted
  actor-learner architectures.
\newblock \emph{CoRR}, abs/1802.01561, 2018.
\newblock URL \url{http://arxiv.org/abs/1802.01561}.

\bibitem[Eysenbach et~al.(2018)Eysenbach, Gupta, Ibarz, and
  Levine]{eysenbach2018diversity}
Eysenbach, B., Gupta, A., Ibarz, J., and Levine, S.
\newblock Diversity is all you need: Learning skills without a reward function.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Gelada et~al.(2019)Gelada, Kumar, Buckman, Nachum, and
  Bellemare]{deepMDP}
Gelada, C., Kumar, S., Buckman, J., Nachum, O., and Bellemare, M.~G.
\newblock Deepmdp: Learning continuous latent space models for representation
  learning.
\newblock \emph{ICML}, 2019.

\bibitem[Grill et~al.(2020)Grill, Strub, Altch{\'e}, Tallec, Richemond,
  Buchatskaya, Doersch, Pires, Guo, Azar, et~al.]{BYOL}
Grill, J.-B., Strub, F., Altch{\'e}, F., Tallec, C., Richemond, P.~H.,
  Buchatskaya, E., Doersch, C., Pires, B.~A., Guo, Z.~D., Azar, M.~G., et~al.
\newblock Bootstrap your own latent: A new approach to self-supervised
  learning.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Guo et~al.(2020)Guo, Pires, Piot, Grill, Altch{\'e}, Munos, and
  Azar]{pbl}
Guo, D., Pires, B.~A., Piot, B., Grill, J.-b., Altch{\'e}, F., Munos, R., and
  Azar, M.~G.
\newblock Bootstrap latent-predictive representations for multitask
  reinforcement learning.
\newblock In \emph{ICML}, 2020.

\bibitem[Guo et~al.(2018)Guo, Azar, Piot, Pires, and Munos]{guo2018neural}
Guo, Z.~D., Azar, M.~G., Piot, B., Pires, B.~A., and Munos, R.
\newblock Neural predictive belief representations.
\newblock \emph{ICML}, 2018.

\bibitem[Hadsell et~al.(2020)Hadsell, Rao, Rusu, and
  Pascanu]{hadsell2020embracing}
Hadsell, R., Rao, D., Rusu, A.~A., and Pascanu, R.
\newblock Embracing change: Continual learning in deep neural networks.
\newblock \emph{Trends in Cognitive Sciences}, 2020.
\newblock \doi{https://doi.org/10.1016/j.tics.2020.09.004}.
\newblock URL
  \url{http://www.sciencedirect.com/science/article/pii/S1364661320302199}.

\bibitem[Hansen et~al.(2020)Hansen, Dabney, Barreto, Warde-Farley, de~Wiele,
  and Mnih]{Hansen2020Fast}
Hansen, S., Dabney, W., Barreto, A., Warde-Farley, D., de~Wiele, T.~V., and
  Mnih, V.
\newblock Fast task inference with variational intrinsic successor features.
\newblock In \emph{ICLR}, 2020.

\bibitem[Harris et~al.(2020)Harris, Millman, van~der Walt, Gommers, Virtanen,
  Cournapeau, Wieser, Taylor, Berg, Smith, Kern, Picus, Hoyer, van Kerkwijk,
  Brett, Haldane, del R{'{\i}}o, Wiebe, Peterson, G{'{e}}rard-Marchant,
  Sheppard, Reddy, Weckesser, Abbasi, Gohlke, and Oliphant]{harris2020array}
Harris, C.~R., Millman, K.~J., van~der Walt, S.~J., Gommers, R., Virtanen, P.,
  Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N.~J., Kern, R.,
  Picus, M., Hoyer, S., van Kerkwijk, M.~H., Brett, M., Haldane, A., del
  R{'{\i}}o, J.~F., Wiebe, M., Peterson, P., G{'{e}}rard-Marchant, P.,
  Sheppard, K., Reddy, T., Weckesser, W., Abbasi, H., Gohlke, C., and Oliphant,
  T.~E.
\newblock Array programming with {NumPy}.
\newblock \emph{Nature}, 585\penalty0 (7825):\penalty0 357--362, September
  2020.
\newblock \doi{10.1038/s41586-020-2649-2}.
\newblock URL \url{https://doi.org/10.1038/s41586-020-2649-2}.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{resnet}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{CVPR}, 2016.

\bibitem[He et~al.(2020)He, Fan, Wu, Xie, and Girshick]{moco}
He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{CVPR}, 2020.

\bibitem[H{\'e}naff et~al.(2019)H{\'e}naff, Srinivas, De~Fauw, Razavi, Doersch,
  Eslami, and Oord]{cpcv2}
H{\'e}naff, O.~J., Srinivas, A., De~Fauw, J., Razavi, A., Doersch, C., Eslami,
  S., and Oord, A. v.~d.
\newblock Data-efficient image recognition with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1905.09272}, 2019.

\bibitem[Hernandez et~al.(2021)Hernandez, Kaplan, Henighan, and
  McCandlish]{hernandez2021scaling}
Hernandez, D., Kaplan, J., Henighan, T., and McCandlish, S.
\newblock Scaling laws for transfer, 2021.

\bibitem[Hessel et~al.(2018)Hessel, Modayil, van Hasselt, Schaul, Ostrovski,
  Dabney, Horgan, Piot, Azar, and Silver]{hessel2018rainbow}
Hessel, M., Modayil, J., van Hasselt, H., Schaul, T., Ostrovski, G., Dabney,
  W., Horgan, D., Piot, B., Azar, M.~G., and Silver, D.
\newblock Rainbow: Combining improvements in deep reinforcement learning.
\newblock In \emph{AAAI}, 2018.

\bibitem[Hessel et~al.(2021)Hessel, Danihelka, Viola, Guez, Schmitt, Sifre,
  Weber, Silver, and van Hasselt]{hessel2021muesli}
Hessel, M., Danihelka, I., Viola, F., Guez, A., Schmitt, S., Sifre, L., Weber,
  T., Silver, D., and van Hasselt, H.
\newblock Muesli: Combining improvements in policy optimization.
\newblock \emph{arXiv preprint arXiv:2104.06159}, 2021.

\bibitem[Hjelm et~al.(2019)Hjelm, Fedorov, Lavoie-Marchildon, Grewal, Bachman,
  Trischler, and Bengio]{dim}
Hjelm, R.~D., Fedorov, A., Lavoie-Marchildon, S., Grewal, K., Bachman, P.,
  Trischler, A., and Bengio, Y.
\newblock Learning deep representations by mutual information estimation and
  maximization.
\newblock \emph{ICLR}, 2019.

\bibitem[Ioffe \& Szegedy(2015)Ioffe and Szegedy]{ioffe2015batch}
Ioffe, S. and Szegedy, C.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In \emph{ICML}, 2015.

\bibitem[Kaiser et~al.(2019)Kaiser, Babaeizadeh, Mi{\l}os, Osi{\'n}ski,
  Campbell, Czechowski, Erhan, Finn, Kozakowski, Levine, et~al.]{simple}
Kaiser, {\L}., Babaeizadeh, M., Mi{\l}os, P., Osi{\'n}ski, B., Campbell, R.~H.,
  Czechowski, K., Erhan, D., Finn, C., Kozakowski, P., Levine, S., et~al.
\newblock Model based reinforcement learning for atari.
\newblock In \emph{ICLR}, 2019.

\bibitem[Kaplan et~al.(2020)Kaplan, McCandlish, Henighan, Brown, Chess, Child,
  Gray, Radford, Wu, and Amodei]{kaplan2020scaling}
Kaplan, J., McCandlish, S., Henighan, T., Brown, T.~B., Chess, B., Child, R.,
  Gray, S., Radford, A., Wu, J., and Amodei, D.
\newblock Scaling laws for neural language models.
\newblock \emph{arXiv preprint arXiv:2001.08361}, 2020.

\bibitem[Kielak(2020)]{kielak2020do}
Kielak, K.~P.
\newblock Do recent advancements in model-based deep reinforcement learning
  really improve data efficiency?, 2020.
\newblock URL \url{https://openreview.net/forum?id=Bke9u1HFwB}.

\bibitem[Kostrikov et~al.(2021)Kostrikov, Yarats, and Fergus]{drq}
Kostrikov, I., Yarats, D., and Fergus, R.
\newblock Image augmentation is all you need: Regularizing deep reinforcement
  learning from pixels.
\newblock In \emph{ICLR}, 2021.

\bibitem[Lake et~al.(2017)Lake, Ullman, Tenenbaum, and
  Gershman]{lake2017building}
Lake, B.~M., Ullman, T.~D., Tenenbaum, J.~B., and Gershman, S.~J.
\newblock Building machines that learn and think like people.
\newblock \emph{Behavioral and brain sciences}, 40, 2017.

\bibitem[Lesort et~al.(2018)Lesort, D{\'\i}az-Rodr{\'\i}guez, Goudou, and
  Filliat]{lesort2018state}
Lesort, T., D{\'\i}az-Rodr{\'\i}guez, N., Goudou, J.-F., and Filliat, D.
\newblock State representation learning for control: An overview.
\newblock \emph{Neural Networks}, 108, 2018.

\bibitem[Li et~al.(2020)Li, Chaudhari, Yang, Lam, Ravichandran, Bhotika, and
  Soatto]{Li2020Rethinking}
Li, H., Chaudhari, P., Yang, H., Lam, M., Ravichandran, A., Bhotika, R., and
  Soatto, S.
\newblock Rethinking the hyperparameters for fine-tuning.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=B1g8VkHFPH}.

\bibitem[Liu \& Abbeel(2021)Liu and Abbeel]{liu2021unsupervised}
Liu, H. and Abbeel, P.
\newblock Unsupervised active pre-training for reinforcement learning, 2021.
\newblock URL \url{https://openreview.net/forum?id=cvNYovr16SB}.

\bibitem[Mazoure et~al.(2020)Mazoure, Combes, Doan, Bachman, and
  Hjelm]{mazoure2020deep}
Mazoure, B., Combes, R. T.~d., Doan, T., Bachman, P., and Hjelm, R.~D.
\newblock Deep reinforcement and infomax learning.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{dqn}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M., Fidjeland, A.~K., Ostrovski, G., et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540), 2015.

\bibitem[Ng et~al.(1999)Ng, Harada, and Russell]{ng1999policy}
Ng, A.~Y., Harada, D., and Russell, S.~J.
\newblock Policy invariance under reward transformations: Theory and
  application to reward shaping.
\newblock In \emph{ICML}, 1999.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{cpc}
Oord, A. v.~d., Li, Y., and Vinyals, O.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, et~al.]{pytorch}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Pathak et~al.(2017)Pathak, Agrawal, Efros, and
  Darrell]{pathak2017curiosity}
Pathak, D., Agrawal, P., Efros, A.~A., and Darrell, T.
\newblock Curiosity-driven exploration by self-supervised prediction.
\newblock In \emph{ICML}. PMLR, 2017.

\bibitem[Perez et~al.(2018)Perez, Strub, de~Vries, Dumoulin, and
  Courville]{perez2018film}
Perez, E., Strub, F., de~Vries, H., Dumoulin, V., and Courville, A.~C.
\newblock Film: Visual reasoning with a general conditioning layer.
\newblock In \emph{AAAI}, 2018.

\bibitem[Sandler et~al.(2018)Sandler, Howard, Zhu, Zhmoginov, and
  Chen]{sandler2018mobilenetv2}
Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., and Chen, L.-C.
\newblock Mobilenetv2: Inverted residuals and linear bottlenecks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  4510--4520, 2018.

\bibitem[Schrittwieser et~al.(2021)Schrittwieser, Antonoglou, Hubert, Simonyan,
  Sifre, Schmitt, Guez, Lockhart, Hassabis, Graepel, et~al.]{muzero}
Schrittwieser, J., Antonoglou, I., Hubert, T., Simonyan, K., Sifre, L.,
  Schmitt, S., Guez, A., Lockhart, E., Hassabis, D., Graepel, T., et~al.
\newblock Mastering atari, go, chess and shogi by planning with a learned
  model.
\newblock \emph{Nature}, 2021.

\bibitem[Schwarzer et~al.(2021)Schwarzer, Anand, Goel, Hjelm, Courville, and
  Bachman]{schwarzer2020dataefficient}
Schwarzer, M., Anand, A., Goel, R., Hjelm, R.~D., Courville, A., and Bachman,
  P.
\newblock Data-efficient reinforcement learning with self-predictive
  representations.
\newblock In \emph{ICLR}, 2021.

\bibitem[Sekar et~al.(2020)Sekar, Rybkin, Daniilidis, Abbeel, Hafner, and
  Pathak]{sekar2020planning}
Sekar, R., Rybkin, O., Daniilidis, K., Abbeel, P., Hafner, D., and Pathak, D.
\newblock Planning to explore via self-supervised world models.
\newblock In \emph{ICML}, 2020.

\bibitem[Sharma et~al.(2019)Sharma, Gu, Levine, Kumar, and
  Hausman]{sharma2019dynamics}
Sharma, A., Gu, S., Levine, S., Kumar, V., and Hausman, K.
\newblock Dynamics-aware unsupervised discovery of skills.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Sohn et~al.(2020)Sohn, Berthelot, Li, Zhang, Carlini, Cubuk, Kurakin,
  Zhang, and Raffel]{sohn2020fixmatch}
Sohn, K., Berthelot, D., Li, C.-L., Zhang, Z., Carlini, N., Cubuk, E.~D.,
  Kurakin, A., Zhang, H., and Raffel, C.
\newblock Fixmatch: Simplifying semi-supervised learning with consistency and
  confidence.
\newblock \emph{arXiv preprint arXiv:2001.07685}, 2020.

\bibitem[Stooke \& Abbeel(2019)Stooke and Abbeel]{rlpyt}
Stooke, A. and Abbeel, P.
\newblock rlpyt: A research code base for deep reinforcement learning in
  pytorch.
\newblock \emph{arXiv preprint arXiv:1909.01500}, 2019.

\bibitem[Stooke et~al.(2021)Stooke, Lee, Abbeel, and
  Laskin]{stooke2020decoupling}
Stooke, A., Lee, K., Abbeel, P., and Laskin, M.
\newblock Decoupling representation learning from reinforcement learning, 2021.

\bibitem[Sutton \& Barto(2018)Sutton and Barto]{Sutton1998}
Sutton, R.~S. and Barto, A.~G.
\newblock \emph{Reinforcement Learning: An Introduction}.
\newblock The MIT Press, second edition, 2018.
\newblock URL \url{http://incompleteideas.net/book/the-book-2nd.html}.

\bibitem[Tan \& Le(2019)Tan and Le]{efficientnet}
Tan, M. and Le, Q.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  6105--6114, 2019.

\bibitem[Tarvainen \& Valpola(2017)Tarvainen and Valpola]{tarvainen2017mean}
Tarvainen, A. and Valpola, H.
\newblock Mean teachers are better role models: Weight-averaged consistency
  targets improve semi-supervised deep learning results.
\newblock In \emph{NeurIPS}, 2017.

\bibitem[Tsividis et~al.(2017)Tsividis, Pouncy, Xu, Tenenbaum, and
  Gershman]{tsividis2017-learning91}
Tsividis, P., Pouncy, T., Xu, J.~L., Tenenbaum, J.~B., and Gershman, S.~J.
\newblock Human learning in atari.
\newblock In \emph{AAAI Spring Symposia}, 2017.

\bibitem[Van~Hasselt et~al.(2016)Van~Hasselt, Guez, and Silver]{doubledqn}
Van~Hasselt, H., Guez, A., and Silver, D.
\newblock Deep reinforcement learning with double q-learning.
\newblock In \emph{AAAI}, 2016.

\bibitem[van Hasselt et~al.(2019)van Hasselt, Hessel, and Aslanides]{der}
van Hasselt, H.~P., Hessel, M., and Aslanides, J.
\newblock When to use parametric models in reinforcement learning?
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Wang \& Isola(2020)Wang and Isola]{wang2020understanding}
Wang, T. and Isola, P.
\newblock Understanding contrastive representation learning through alignment
  and uniformity on the hypersphere, 2020.

\bibitem[Wang et~al.(2016)Wang, Schaul, Hessel, Hasselt, Lanctot, and
  Freitas]{wang2016dueling}
Wang, Z., Schaul, T., Hessel, M., Hasselt, H., Lanctot, M., and Freitas, N.
\newblock Dueling network architectures for deep reinforcement learning.
\newblock In \emph{ICML}, 2016.

\bibitem[Zenke et~al.(2017)Zenke, Poole, and Ganguli]{zenke2017continual}
Zenke, F., Poole, B., and Ganguli, S.
\newblock Continual learning through synaptic intelligence.
\newblock In \emph{ICML}, 2017.

\bibitem[Zhan et~al.(2020)Zhan, Zhao, Pinto, Abbeel, and
  Laskin]{zhan2020framework}
Zhan, A., Zhao, P., Pinto, L., Abbeel, P., and Laskin, M.
\newblock A framework for efficient robotic manipulation, 2020.

\bibitem[Zhang et~al.(2018)Zhang, Vinyals, Munos, and Bengio]{zhang2018study}
Zhang, C., Vinyals, O., Munos, R., and Bengio, S.
\newblock A study on overfitting in deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1804.06893}, 2018.

\end{thebibliography}
