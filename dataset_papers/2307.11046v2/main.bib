@online{suttonwebRLhypothesis,
  author = {Richard S Sutton},
  title = {The reward hypothesis},
  year ={2004},
  url = {http://incompleteideas.net/rlai.cs.ualberta.ca/RLAI/rewardhypothesis.html},
}

@online{littmanRH,
  author = {Michael L. Littman},
  title = {The reward hypothesis},
  year ={2017},
  url = {https://www.coursera.org/lecture/fundamentals-of-reinforcement-learning/michael-littman-the-reward-hypothesis-q6x0e},
}
@book{puterman2014markov,
  title={Markov Decision Processes: Discrete Stochastic Dynamic Programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@inproceedings{cassandra1994acting,
  title={Acting optimally in partially observable stochastic domains},
  author={Cassandra, Anthony R. and Kaelbling, Leslie Pack and Littman, Michael L.},
  booktitle={Proceedings of the AAAI Conference on Artificiall Intelligence},
  year={1994}
}

@article{robinson1949definability,
  title={Definability and decision problems in arithmetic},
  author={Robinson, Julia},
  journal={The Journal of Symbolic Logic},
  volume={14},
  number={2},
  pages={98--114},
  year={1949},
  publisher={Cambridge University Press}
}

@inproceedings{ng1999policy,
  title={Policy invariance under reward transformations: Theory and application to reward shaping},
  author={Ng, Andrew Y. and Harada, Daishi and Russell, Stuart},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={1999}
}

@article{kaelbling1998planning,
  author = "Leslie Pack Kaelbling and Michael L. Littman and
                  Anthony R. Cassandra",
  title = "Planning and acting in partially observable
                  stochastic domains", 
  journal = "Artificial Intelligence",
  volume = "101",
  number = "1--2",
  year = "1998",
  pages = "99--134",
  myurl = "http://www.elsevier.nl/cas/tree/store/artint/sub/1998/101/1-2/1532.pdf",
  type = "bib2html"
}

@article{wirth2017survey,
  title={A survey of preference-based reinforcement learning methods},
  author={Wirth, Christian and Akrour, Riad and Neumann, Gerhard and F{\"u}rnkranz, Johannes},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={4945--4990},
  year={2017},
  publisher={JMLR.org}
}

@inproceedings{amin2017repeated,
  title={Repeated inverse reinforcement learning},
  author={Amin, Kareem and Jiang, Nan and Singh, Satinder},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{bellemare2017distributional,
  title={A distributional perspective on reinforcement learning},
  author={Bellemare, Marc G. and Dabney, Will and Munos, R{\'e}mi},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2017},
}

@inproceedings{rowland2018analysis,
  title={An analysis of categorical distributional reinforcement learning},
  author={Rowland, Mark and Bellemare, Marc G. and Dabney, Will and Munos, R{\'e}mi and Teh, Yee Whye},
  booktitle={Proceedings of the International Conference on Artificial Intelligence and Statistics},
  year={2018}
}

@inproceedings{dabney2018implicit,
  title={Implicit quantile networks for distributional reinforcement learning},
  author={Dabney, Will and Ostrovski, Georg and Silver, David and Munos, R{\'e}mi},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2018}
}

@article{cook1986,
  title={An axiomatic approach to distance on partial orderings},
  author={Cook, Wade D and Kress, Moshe and Seiford, Lawrence M},
  journal={RAIRO-Operations Research},
  volume={20},
  number={2},
  pages={115--122},
  year={1986},
  publisher={EDP Sciences}
}

@article{mezHo2014periodicity,
  title={Periodicity of the last digits of some combinatorial sequences},
  author={Mez{\H{o}}, Istv{\'a}n},
  journal={J. Integer Seq},
  volume={17},
  pages={1--18},
  year={2014}
}

@inproceedings{fagin2004comparing,
  title={Comparing and aggregating rankings with ties},
  author={Fagin, Ronald and Kumar, Ravi and Mahdian, Mohammad and Sivakumar, D and Vee, Erik},
  booktitle={ACM Symposium on Principles of Database Systems},
  year={2004}
}

@article{fagin2006comparing,
  title={Comparing partial rankings},
  author={Fagin, Ronald and Kumar, Ravi and Mahdian, Mohammad and Sivakumar, D and Vee, Erik},
  journal={SIAM Journal on Discrete Mathematics},
  volume={20},
  number={3},
  pages={628--648},
  year={2006},
  publisher={SIAM}
}

@inproceedings{jiang2015dependence,
  title={The dependence of effective planning horizon on model accuracy},
  author={Jiang, Nan and Kulesza, Alex and Singh, Satinder and Lewis, Richard},
  booktitle={Proceedings of the International Conference on Autonomous Agents and Multiagent Systems},
  year={2015},
}

@article{semal1991iterative,
  title={Iterative algorithms for large stochastic matrices},
  author={Semal, Pierre},
  journal={Linear algebra and its applications},
  volume={154},
  pages={65--103},
  year={1991},
  publisher={Elsevier}
}
@article{xu2020preference,
  title={Preference-based Reinforcement Learning with Finite-Time Guarantees},
  author={Xu, Yichong and Wang, Ruosong and Yang, Lin and Singh, Aarti and Dubrawski, Artur},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}
@book{kreps1988notes,
  title={Notes on the Theory of Choice},
  author={Kreps, David},
  year={1988},
  publisher={Westview Press}
}

@inproceedings{duchi2010consistency,
  title={On the consistency of ranking algorithms},
  author={Duchi, John C and Mackey, Lester W and Jordan, Michael I},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2010}
}
@phdthesis{sorg2011optimal,
  title={The Optimal Reward Problem: Designing Effective Reward for Bounded Agents},
  author={Sorg, Jonathan},
  school={University of Michigan},
  year={2011}
}
@article{littman2017environment,
  title={Environment-independent task specifications via {GLTL}},
  author={Littman, Michael L. and Topcu, Ufuk and Fu, Jie and Isbell, Charles and Wen, Min and MacGlashan, James},
  journal={arXiv preprint arXiv:1704.04341},
  year={2017}
}
@article{bertsekas1991analysis,
  title={An analysis of stochastic shortest path problems},
  author={Bertsekas, Dimitri P. and Tsitsiklis, John N.},
  journal={Mathematics of Operations Research},
  volume={16},
  number={3},
  pages={580--595},
  year={1991},
  publisher={INFORMS}
}
@article{friston2010free,
  title={The free-energy principle: a unified brain theory?},
  author={Friston, Karl J.},
  journal={Nature reviews neuroscience},
  volume={11},
  number={2},
  pages={127--138},
  year={2010},
  publisher={Nature publishing group}
}
@article{hafner2020action,
  title={Action and perception as divergence minimization},
  author={Hafner, Danijar and Ortega, Pedro A. and Ba, Jimmy and Parr, Thomas and Friston, Karl J. and Heess, Nicolas},
  journal={arXiv preprint arXiv:2009.01791},
  year={2020}
}
@article{clark2020beyond,
  title={Beyond desire? Agency, choice, and the predictive mind},
  author={Clark, Andy},
  journal={Australasian Journal of Philosophy},
  volume={98},
  number={1},
  pages={1--15},
  year={2020},
  publisher={Taylor \& Francis}
}

@incollection{tishby2011information,
  title={Information theory of decisions and actions},
  author={Tishby, Naftali and Polani, Daniel},
  booktitle={Perception-action cycle},
  pages={601--636},
  year={2011},
  publisher={Springer}
}
@inproceedings{akshay2013steady,
  title={The steady-state control problem for {M}arkov decision processes},
  author={Akshay, Sundararaman and Bertrand, Nathalie and Haddad, Serge and Helouet, Loic},
  booktitle={Proceedings of the International Conference on Quantitative Evaluation of Systems},
  year={2013},
}

@inproceedings{singh2009rewards,
  title={Where do rewards come from?},
  author={Singh, Satinder and Lewis, Richard L and Barto, Andrew G},
  booktitle={Proceedings of the Annual Conference of the Cognitive Science Society},
  year={2009},
}

@inproceedings{christiano2017deep,
  title={Deep Reinforcement Learning from Human Preferences},
  author={Christiano, Paul F. and Leike, Jan and Brown, Tom B. and Martic, Miljan and Legg, Shane and Amodei, Dario},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}
@inproceedings{krishna2020maximum,
  title={Maximum Reward Formulation In Reinforcement Learning},
  author={Krishna Gottipati, Sai and Pathak, Yashaswi and Nuttall, Rohan and Chunduru, Raviteja and Touati, Ahmed and Ganapathi Subramanian, Sriram and Taylor, Matthew E. and Chandar, Sarath},
  booktitle={NeurIPS Workshop on Deep Reinforcement Learning},
  year={2020}
}
@inproceedings{macglashan2016convergent,
  title={Convergent actor critic by humans},
  author={MacGlashan, James and Littman, Michael L. and Roberts, David L. and Loftin, Robert and Peng, Bei and Taylor, Matthew E.},
  booktitle={Proceedings of the International Conference on Intelligent Robots and Systems},
  year={2016}
}

@inproceedings{novoseller2020dueling,
  title={Dueling posterior sampling for preference-based reinforcement learning},
  author={Novoseller, Ellen and Wei, Yibing and Sui, Yanan and Yue, Yisong and Burdick, Joel},
  booktitle={Proceedings of the Conference on Uncertainty in Artificial Intelligence},
  year={2020},
}
@inproceedings{hadfield2017inverse,
  title={Inverse reward design},
  author={Hadfield-Menell, Dylan and Milli, Smitha and Abbeel, Pieter and Russell, Stuart and Dragan, Anca},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}
@online{yann_cake,
  title = {Yann LeCun's Cake Analogy},
  url = {https://medium.com/syncedreview/yann-lecun-cake-analogy-2-0-a361da560dae}
}

@inproceedings{arumugam2017accurately,
  title={Accurately and efficiently interpreting human-robot instructions of varying granularities},
  author={Arumugam, Dilip and Karamcheti, Siddharth and Gopalan, Nakul and Wong, Lawson LS and Tellex, Stefanie},
  booktitle={Proceedings of the Robotics: Science and Systems Conference},
  year={2017}
}
@inproceedings{agarwal2019learning,
  title={Learning to generalize from sparse and underspecified rewards},
  author={Agarwal, Rishabh and Liang, Chen and Schuurmans, Dale and Norouzi, Mohammad},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2019},
}

@book{russell94,
  author = "Stuart J. Russell and Peter Norvig",
  title = "Artificial Intelligence: {A} Modern Approach",
  publisher = "Prentice-Hall",
  isbn = "0-13-103805-2",
  address = "Englewood Cliffs, NJ",
  year = 1994
}


@article{ackley1992interactions,
  title={Interactions between learning and evolution},
  author={Ackley, David and Littman, Michael L.},
  journal={Artificial Life II},
  year={1992},
  publisher={Addison-Wesley}
}

@book{sutton2018reinforcement,
  title={Reinforcement Learning: An Introduction},
  author={Sutton, Richard S and Barto, Andrew G.},
  year={2018},
  publisher={MIT Press}
}

@inproceedings{auer2009near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Auer, Peter and Jaksch, Thomas and Ortner, Ronald},
  booktitle={Advances in Neural Information Processing Systems},
  year={2009}
}

@article{Strehl2009,
    author = {Strehl, Alexander L. and Li, Lihong and Littman, Michael L.},
    journal = {Journal of Machine Learning Research},
    pages = {2413--2444},
    title = {Reinforcement Learning in Finite {MDP}s: {PAC} Analysis},
    volume = {10},
    year = {2009}
}

@inproceedings{williams2018learning,
  title={Learning to parse natural language to grounded reward functions with weak supervision},
  author={Williams, Edward C. and Gopalan, Nakul and Rhee, Mine and Tellex, Stefanie},
  booktitle={Proceedings of the International Conference on Robotics and Automation},
  year={2018},
}

@misc{singh2010separating,
  title={On Separating Agent Designer Goals from Agent Goals: Breaking the Preferences--Parameters Confound},
  author={Singh, Satinder and Lewis, Richard L. and Sorg, Jonathan and Barto, Andrew G. and Helou, Akram},
  year={2010},
  publisher={Citeseer}
}

@inproceedings{zheng2020can,
  title={What Can Learned Intrinsic Rewards Capture?},
  author={Zheng, Zeyu and Oh, Junhyuk and Hessel, Matteo and Xu, Zhongwen and Kroiss, Manuel and van Hasselt, Hado and Silver, David and Singh, Satinder},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2020},
}
@techreport{singh2005intrinsically,
  title={Intrinsically motivated reinforcement learning},
  author={Singh, Satinder and Barto, Andrew G. and Chentanez, Nuttapong},
  year={2005},
  institution={University of Massachusetts at Amherst Department of Computer Science}
}

@article{haydencase2020,
  title={The case against economic values in the orbitofrontal cortex (or anywhere else in the brain)},
  author={Hayden, Benjamin Y. and Niv, Yael},
  journal={PsyArXiv},
  year={2020}
}

@article{dayan2002reward,
  title={Reward, motivation, and reinforcement learning},
  author={Dayan, Peter and Balleine, Bernard W},
  journal={Neuron},
  volume={36},
  number={2},
  pages={285--298},
  year={2002},
  publisher={Elsevier}
}

@article{bayer2005midbrain,
  title={Midbrain dopamine neurons encode a quantitative reward prediction error signal},
  author={Bayer, Hannah M and Glimcher, Paul W},
  journal={Neuron},
  volume={47},
  number={1},
  pages={129--141},
  year={2005},
  publisher={Elsevier}
}

@article{schultz1997neural,
  title={A neural substrate of prediction and reward},
  author={Schultz, Wolfram and Dayan, Peter and Montague, P Read},
  journal={Science},
  volume={275},
  number={5306},
  pages={1593--1599},
  year={1997},
  publisher={American Association for the Advancement of Science}
}

@article{fedus2019hyperbolic,
  title={Hyperbolic discounting and learning over multiple horizons},
  author={Fedus, William and Gelada, Carles and Bengio, Yoshua and Bellemare, Marc G. and Larochelle, Hugo},
  journal={arXiv preprint arXiv:1902.06865},
  year={2019}
}

@inproceedings{pitis2019rethinking,
  title={Rethinking the discount factor in reinforcement learning: A decision theoretic approach},
  author={Pitis, Silviu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2019}
}


@inproceedings{hadfield2016off,
  title={The off-switch game},
  author={Hadfield-Menell, Dylan and Dragan, Anca and Abbeel, Pieter and Russell, Stuart},
  booktitle={Proceedings of the International Joint Conference on Artificial Intelligence},
  year={2017}
}

@article{kumar2020realab,
  title={{REALab}: An Embedded Perspective on Tampering},
  author={Kumar, Ramana and Uesato, Jonathan and Ngo, Richard and Everitt, Tom and Krakovna, Victoria and Legg, Shane},
  journal={arXiv preprint arXiv:2011.08820},
  year={2020}
}

@inproceedings{koenig93,
  author={Sven Koenig and Reid G. Simmons},
  title={Complexity Analysis of Real-time Reinforcement Learning},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence}, 
  year={1993},
  mynote = "I think this is the n-cubed Q-learning paper"
}

@article{ho2019people,
  title={People teach with rewards and punishments as communication, not reinforcements},
  author={Ho, Mark K. and Cushman, Fiery and Littman, Michael L. and Austerweil, Joseph L.},
  journal={Journal of Experimental Psychology: General},
  volume={148},
  number={3},
  pages={520},
  year={2019},
  publisher={American Psychological Association}
}

@article{ho2016showing,
  title={Showing versus doing: Teaching by demonstration},
  author={Ho, Mark K. and Littman, Michael L. and MacGlashan, James and Cushman, Fiery and Austerweil, Joseph L},
  journal={Advances in Neural Information Processing Systems},
  year={2016}
}

@inproceedings{macglashan2017interactive,
  title={Interactive learning from policy-dependent human feedback},
  author={MacGlashan, James and Ho, Mark K. and Loftin, Robert and Peng, Bei and Wang, Guan and Roberts, David L. and Taylor, Matthew E. and Littman, Michael L.},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2017},
  organization={PMLR}
}

@inproceedings{hadfield2016cooperative,
  title={Cooperative inverse reinforcement learning},
  author={Hadfield-Menell, Dylan and Dragan, Anca and Abbeel, Pieter and Russell, Stuart},
  booktitle={Advances in Neural Information Processing Systems}, 
  year={2016}
}

@article{michaud2020understanding,
  title={Understanding Learned Reward Functions},
  author={Michaud, Eric J. and Gleave, Adam and Russell, Stuart},
  journal={arXiv preprint arXiv:2012.05862},
  year={2020}
}

@misc{shah2021benefits,
title={Benefits of Assistance over Reward Learning},
author={Rohin Shah and Pedro Freire and Neel Alex and Rachel Freedman and Dmitrii Krasheninnikov and Lawrence Chan and Michael D. Dennis and Pieter Abbeel and Anca Dragan and Stuart Russell},
year={2021},
url={https://openreview.net/forum?id=DFIoGDZejIB}
}

@article{friston2009reinforcement,
  title={Reinforcement learning or active inference?},
  author={Friston, Karl J. and Daunizeau, Jean and Kiebel, Stefan J.},
  journal={PloS One},
  volume={4},
  number={7},
  pages={e6421},
  year={2009},
  publisher={Public Library of Science}
}

@inproceedings{li2006towards,
  title={Towards a Unified Theory of State Abstraction for {MDP}s},
  author={Li, Lihong and Walsh, Thomas J. and Littman, Michael L.},
  booktitle={Proceedings of the International Symposium on Artificial Intelligence and Mathematics},
  year={2006}
}

@inproceedings{macglashan15,
  title = {Grounding {E}nglish commands to reward functions},
    author={MacGlashan, James and Babes-Vroman, Monica and Marie desJardins and Littman, Michael L. and Muresan, Smaranda and Squire, Shawn and Tellex, Stefanie and Arumugam, Dilip and Yang, Lei},
  year = {2015},
  booktitle = {Proceedings of Robotics: Science and Systems}
}

@article{debreu1954representation,
  title={Representation of a preference ordering by a numerical function},
  author={Debreu, Gerard},
  journal={Decision Processes},
  volume={3},
  pages={159--165},
  year={1954},
  publisher={New York}
}

@article{koopmans1960stationary,
  title={Stationary ordinal utility and impatience},
  author={Koopmans, Tjalling C.},
  journal={Econometrica: Journal of the Econometric Society},
  pages={287--309},
  year={1960},
  publisher={JSTOR}
}

@article{koopmans1966structure,
  title={Structure of preference over time},
  author={Koopmans, Tjalling C.},
  journal = "Cowles Foundation Discussion Paper",
  number = 206,
  year={1966}
}

@article{arrow1950difficulty,
  title={A difficulty in the concept of social welfare},
  author={Arrow, Kenneth J.},
  journal={Journal of political economy},
  volume={58},
  number={4},
  pages={328--346},
  year={1950},
  publisher={The University of Chicago Press}
}
@article{eckersley2018impossibility,
  title={Impossibility and Uncertainty Theorems in {AI} Value Alignment (or why your {AGI} should not have a utility function)},
  author={Eckersley, Peter},
  journal={arXiv preprint arXiv:1901.00064},
  year={2018}
}

@book{parfit1984reasons,
  title={Reasons and persons},
  author={Parfit, Derek},
  year={1984},
  publisher={Oxford University Press}
}
@book{vonneumann1953theory,
  title={Theory of Games and Economic Behavior},
  author={von Neumann, John and Morgenstern, Oskar},
  year={1953},
  publisher={Princeton University Press}
}

@inproceedings{wilson2012bayesian,
  title={A {B}ayesian approach for policy learning from trajectory preference queries},
  author={Wilson, Aaron and Fern, Alan and Tadepalli, Prasad},
  booktitle={Advances in Neural Information Processing Systems},
  year={2012}
}

@inproceedings{tasse2020boolean,
  title={A {B}oolean Task Algebra for Reinforcement Learning},
  author={Tasse, Geraud Nangue and James, Steven and Rosman, Benjamin},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}

@inproceedings{white2017unifying,
  title={Unifying task specification in reinforcement learning},
  author={White, Martha},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2017},
}

@online{ortega2018,
author = {Ortega, Pedro A. and Maini, Vishal and the DeepMind Safety Team},
  title = {Building safe artificial intelligence: specification, robustness, and assurance},
  year ={2018},
  url = {https://medium.com/@deepmindsafetyresearch/building-safe-artificial-intelligence-52f5f75058f1},
}

@inproceedings{everitt2017reinforcement,
  title={Reinforcement learning with a corrupted reward channel},
  author={Everitt, Tom and Krakovna, Victoria and Orseau, Laurent and Hutter, Marcus and Legg, Shane},
  booktitle={Proceedings of the International Joint Conference on Artificial Intelligence},
  year={2017}
}

@inproceedings{jeon2020reward,
  title={Reward-rational (implicit) choice: A unifying formalism for reward learning},
  author={Jeon, Hong Jun and Milli, Smitha and Dragan, Anca},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}

@inproceedings{ng2000algorithms,
  title={Algorithms for inverse reinforcement learning.},
  author={Ng, Andrew Y. and Russell, Stuart J. and others},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2000}
}

@inproceedings{abbeel2004apprenticeship,
  title={Apprenticeship learning via inverse reinforcement learning},
  author={Abbeel, Pieter and Ng., Andrew Y.},
  booktitle={Proceedings of the International Conference on Machine learning},
  year={2004}
}

@inproceedings{syed2008apprenticeship,
  title={Apprenticeship learning using linear programming},
  author={Syed, Umar and Bowling, Michael and Schapire, Robert E.},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2008}
}

@inproceedings{karmarkar1984new,
  title={A new polynomial-time algorithm for linear programming},
  author={Karmarkar, Narendra},
  booktitle={Proceedings of the Annual ACM Symposium on Theory of Computing},
  year={1984}
}

@inproceedings{icarte2018using,
  title={Using reward machines for high-level task specification and decomposition in reinforcement learning},
  author={Icarte, Rodrigo Toro and Klassen, Toryn and Valenzano, Richard and McIlraith, Sheila},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2018},
}

@inproceedings{toro2018teaching,
  title={Teaching multiple tasks to an {RL} agent using {LTL}},
  author={Toro Icarte, Rodrigo and Klassen, Toryn Q. and Valenzano, Richard and McIlraith, Sheila A.},
  booktitle={Proceedings of the International Conference on Autonomous Agents and Multiagent Systems},
  year={2018}
}

@article{mitten1974preference,
  title={Preference order dynamic programming},
  author={Mitten, L. G.},
  journal={Management Science},
  volume={21},
  number={1},
  pages={43--46},
  year={1974},
  publisher={INFORMS}
}

@article{sobel1975ordinal,
  title={Ordinal dynamic programming},
  author={Sobel, Matthew J.},
  journal={Management science},
  volume={21},
  number={9},
  pages={967--975},
  year={1975},
  publisher={INFORMS}
}

@incollection{heger1994consideration,
  title={Consideration of risk in reinforcement learning},
  author={Heger, Matthias},
  booktitle={Machine Learning Proceedings 1994},
  pages={105--111},
  year={1994},
  publisher={Elsevier}
}

@inproceedings{jothimurugan2020composable,
  title={A composable specification language for reinforcement learning tasks},
  author={Jothimurugan, Kishor and Alur, Rajeev and Bastani, Osbert},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}

@inproceedings{hammond2021multi,
  title={Multi-Agent Reinforcement Learning with Temporal Logic Specifications},
  author={Hammond, Lewis and Abate, Alessandro and Gutierrez, Julian and Wooldridge, Michael},
  booktitle={Proceedings of the International Conference on Autonomous Agents and Multiagent Systems},
  year={2021}
}

@inproceedings{li2017reinforcement,
  title={Reinforcement learning with temporal logic rewards},
  author={Li, Xiao and Vasile, Cristian-Ioan and Belta, Calin},
  booktitle={Proceedings of the International Conference on Intelligent Robots and Systems},
  year={2017},
}
@online{csabaRLhypothesis,
  author = {Csaba Szepesvári},
  title = {Constrained {MDP}s and the reward hypothesis},
  year ={2020},
  url = {http://readingsml.blogspot.com/2020/03/constrained-mdps-and-reward-hypothesis.html},
}

@inproceedings{sunehag2011axioms,
  title={Axioms for rational reinforcement learning},
  author={Sunehag, Peter and Hutter, Marcus},
  booktitle={Proceedings of the International Conference on Algorithmic Learning Theory},
  year={2011},
}

@inproceedings{weng2011markov,
  title={Markov decision processes with ordinal rewards: Reference point-based preferences},
  author={Weng, Paul},
  booktitle={Proceedings of the International Conference on Automated Planning and Scheduling},
  year={2011}
}
@article{sobel2013discounting,
  title={Discounting axioms imply risk neutrality},
  author={Sobel, Matthew J.},
  journal={Annals of Operations Research},
  volume={208},
  number={1},
  pages={417--432},
  year={2013},
  publisher={Springer}
}
@inproceedings{knox2009interactively,
  title={Interactively shaping agents via human reinforcement: The {TAMER} framework},
  author={Knox, W. Bradley and Stone, Peter},
  booktitle={Proceedings of the International Conference on Knowledge Capture},
  year={2009}
}

@inproceedings{dewey2014reinforcement,
  title={Reinforcement learning and the reward engineering principle},
  author={Dewey, Daniel},
  booktitle={Proceedings of the AAAI Spring Symposium Series},
  year={2014}
}

@inproceedings{mataric1994reward,
  title={Reward functions for accelerated learning},
  author={Mataric, Maja J.},
    booktitle={Proceedings of the International Conference on Machine Learning},
  year={1994},
}
@article{sorg2010reward,
  title={Reward design via online gradient ascent},
  author={Sorg, Jonathan and Lewis, Richard L. and Singh, Satinder},
  journal={Advances in Neural Information Processing Systems},
  year={2010},
}

@article{friston2012dopamine,
  title={Dopamine, affordance and active inference},
  author={Friston, Karl J. and Shiner, Tamara and FitzGerald, Thomas and Galea, Joseph M and Adams, Rick and Brown, Harriet and Dolan, Raymond J. and Moran, Rosalyn and Stephan, Klaas Enno and Bestmann, Sven},
  journal={PLoS Comput Biol},
  volume={8},
  number={1},
  pages={e1002327},
  year={2012},
  publisher={Public Library of Science}
}

@article{silver2021reward,
  title={Reward Is Enough},
  author={Silver, David and Singh, Satinder and Precup, Doina and Sutton, Richard S.},
  journal={Artificial Intelligence},
  pages={103535},
  year={2021},
  publisher={Elsevier}
}

@article{skyum1985complexity,
  title={A complexity theory based on Boolean algebra},
  author={Skyum, Sven and Valiant, Leslie G.},
  journal={Journal of the ACM (JACM)},
  volume={32},
  number={2},
  pages={484--502},
  year={1985},
  publisher={ACM New York, NY, USA}
}
@article{paterson1976circuit,
  title={Circuit size is nonlinear in depth},
  author={Paterson, MS and Valiant, Leslie G.},
  journal={Theoretical Computer Science},
  volume={2},
  number={3},
  pages={397--400},
  year={1976},
  publisher={Elsevier}
}

@book{wegener1987complexity,
  title={The complexity of Boolean functions},
  author={Wegener, Ingo},
  year={1987},
  publisher={John Wiley \& Sons, Inc.}
}

@article{quine1952problem,
  title={The problem of simplifying truth functions},
  author={Quine, Willard V.},
  journal={The American mathematical monthly},
  volume={59},
  number={8},
  pages={521--531},
  year={1952},
  publisher={Taylor \& Francis}
}

@incollection{mccloskey1989catastrophic,
  title={Catastrophic interference in connectionist networks: The sequential learning problem},
  author={McCloskey, Michael and Cohen, Neal J},
  booktitle={Psychology of learning and motivation},
  volume={24},
  pages={109--165},
  year={1989},
  publisher={Elsevier}
}

@article{mccluskey1956minimization,
  title={Minimization of Boolean functions},
  author={McCluskey, Edward J.},
  journal={The Bell System Technical Journal},
  volume={35},
  number={6},
  pages={1417--1444},
  year={1956},
  publisher={Nokia Bell Labs}
}

@article{mileto1964average,
  title={Average values of quantities appearing in Boolean function minimization},
  author={Mileto, Franco and Putzolu, G},
  journal={IEEE Transactions on Electronic Computers},
  number={2},
  pages={87--92},
  year={1964},
  publisher={IEEE}
}

@article{mileto1965statistical,
  title={Statistical complexity of algorithms for Boolean function minimization},
  author={Mileto, Franco and Putzolu, Gianfranco},
  journal={Journal of the ACM (JACM)},
  volume={12},
  number={3},
  pages={364--375},
  year={1965},
  publisher={ACM New York, NY, USA}
}
@inbook{christian2021alignment,
  title={The Alignment Problem: Machine Learning and Human Values},
  author={Christian, Brian},
  year={2021},
  publisher={Atlantic Books},
  pages={130--131}
}

@inproceedings{lattimore2013sample,
  title={The sample-complexity of general reinforcement learning},
  author={Lattimore, Tor and Hutter, Marcus and Sunehag, Peter},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2013},
}
@phdthesis{leike2016nonparametric,
  title={Nonparametric general reinforcement learning},
  author={Leike, Jan},
  year={2016},
  school={The Australian National University}
}

@article{dong2022simple,
  title={Simple agent, complex environment: Efficient reinforcement learning with agent states},
  author={Dong, Shi and Van Roy, Benjamin and Zhou, Zhengyuan},
  journal={Journal of Machine Learning Research},
  volume={23},
  number={255},
  pages={1--54},
  year={2022}
}

@article{platanios2020jelly,
  title={Jelly bean world: A testbed for never-ending learning},
  author={Platanios, Emmanouil Antonios and Saparov, Abulhair and Mitchell, Tom},
  journal={arXiv preprint arXiv:2002.06306},
  year={2020}
}

@inproceedings{brunskill2014pac,
  title={{PAC}-inspired Option Discovery in Lifelong Reinforcement Learning.},
  author={Brunskill, Emma and Li, Lihong},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2014}
}
@inproceedings{isele2016using,
  title={Using Task Features for Zero-Shot Knowledge Transfer in Lifelong Learning.},
  author={Isele, David and Rostami, Mohammad and Eaton, Eric},
  booktitle={Proceedings of the International Joint Conference on Artificial Intelligence},
  year={2016}
}
@inproceedings{tanaka2003multitask,
  title={Multitask reinforcement learning on the distribution of {MDP}s},
  author={Tanaka, Fumihide and Yamamura, Masayuki},
  booktitle={Proceedings of the IEEE International Symposium on Computational Intelligence in Robotics and Automation},
  year={2003},
}
@article{brunskill2013sample,
  title={Sample complexity of multi-task reinforcement learning},
  author={Brunskill, Emma and Li, Lihong},
  journal={arXiv preprint arXiv:1309.6821},
  year={2013}
}
@inproceedings{wilson2007multi,
  title={Multi-task reinforcement learning: a hierarchical {B}ayesian approach},
  author={Wilson, Aaron and Fern, Alan and Ray, Soumya and Tadepalli, Prasad},
  booktitle={Proceedings of the International Conference on Machine learning},
  year={2007}
}

@article{taylor2009transfer,
  title={Transfer learning for reinforcement learning domains: A survey},
  author={Matthew E. Taylor and Peter Stone},
  journal={Journal of Machine Learning Research},
  volume={10},
  number={Jul},
  pages={1633--1685},
  year={2009}
}
@inproceedings{szita2011agnostic,
  title={Agnostic KWIK learning and efficient approximate reinforcement learning},
  author={Szita, Istv{\'a}n and Szepesv{\'a}ri, Csaba},
  booktitle={Proceedings of the Annual Conference on Learning Theory},
}
@article{li2011knows,
  title={Knows what it knows: a framework for self-aware learning},
  author={Li, Lihong and Littman, Michael L. and Walsh, Thomas J. and Strehl, Alexander L.},
  journal={Machine learning},
  volume={82},
  number={3},
  pages={399--443},
  year={2011},
  publisher={Springer}
}

@article{kearns1994toward,
  title={Toward efficient agnostic learning},
  author={Kearns, Michael J. and Schapire, Robert E. and Sellie, Linda M.},
  journal={Machine Learning},
  volume={17},
  number={2},
  pages={115--141},
  year={1994},
  publisher={Springer}
}
@inproceedings{carlson2010toward,
  title={Toward an architecture for never-ending language learning},
  author={Carlson, Andrew and Betteridge, Justin and Kisiel, Bryan and Settles, Burr and Hruschka, Estevam R and Mitchell, Tom},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2010}
}

@article{mitchell2018never,
  title={Never-ending learning},
  author={Mitchell, Tom and Cohen, William and Hruschka, Estevam and Talukdar, Partha and Yang, Bishan and Betteridge, Justin and Carlson, Andrew and Dalvi, Bhavana and Gardner, Matt and Kisiel, Bryan and others},
  journal={Communications of the ACM},
  volume={61},
  number={5},
  pages={103--115},
  year={2018},
  publisher={ACM New York, NY, USA}
}
@article{lecarpentier2019non,
  title={Non-stationary {M}arkov decision processes, a worst-case approach using model-based reinforcement learning},
  author={Lecarpentier, Erwan and Rachelson, Emmanuel},
  journal={Advances in Neural Information Processing Systems},
  year={2019}
}
@phdthesis{lecarpentier2020reinforcement,
  title={Reinforcement learning in non-stationary environments},
  author={Lecarpentier, Erwan},
  year={2020},
  school={Toulouse, ISAE}
}

@inproceedings{cheung2020reinforcement,
  title={Reinforcement learning for non-stationary {M}arkov decision processes: The blessing of (more) optimism},
  author={Cheung, Wang Chi and Simchi-Levi, David and Zhu, Ruihao},
  booktitle={Proceedings of the International Conference on Machine Learning},
}

@article{besbes2014stochastic,
  title={Stochastic multi-armed-bandit problem with non-stationary rewards},
  author={Besbes, Omar and Gur, Yonatan and Zeevi, Assaf},
  journal={Advances in Neural Information Processing Systems},
  year={2014}
}

@article{rivera2019large,
  title={Large scale {M}arkov decision processes with changing rewards},
  author={Rivera Cardoso, Adrian and Wang, He and Xu, Huan},
  journal={Advances in Neural Information Processing Systems},
  year={2019}
}

@inproceedings{chen2019new,
  title={A new algorithm for non-stationary contextual bandits: Efficient, optimal and parameter-free},
  author={Chen, Yifang and Lee, Chung-Wei and Luo, Haipeng and Wei, Chen-Yu},
  booktitle={Proceedings of the Conference on Learning Theory},
  year={2019},
}

@inproceedings{dick2014online,
  title={Online learning in {M}arkov decision processes with changing cost sequences},
  author={Dick, Travis and Gy{\"o}rgy, Andr{\'a}s and Szepesvari, Csaba},
  booktitle={Procedings of the International Conference on Machine Learning},
  year={2014},
}

@article{gajane2018sliding,
  title={A sliding-window algorithm for {M}arkov decision processes with arbitrarily changing rewards and transitions},
  author={Gajane, Pratik and Ortner, Ronald and Auer, Peter},
  journal={arXiv preprint arXiv:1805.10066},
  year={2018}
}

@inproceedings{sutton2007role,
  title={On the role of tracking in stationary environments},
  author={Sutton, Richard S and Koop, Anna and Silver, David},
  booktitle={Proceedings of the International Conference on Machine learning},
  year={2007}
}

@article{watkins1992q,
  title={{$Q$}-learning},
  author={Watkins, Christopher J.C.H. and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@article{singh2000convergence,
  title={Convergence results for single-step on-policy reinforcement-learning algorithms},
  author={Singh, Satinder and Jaakkola, Tommi and Littman, Michael L. and Szepesv{\'a}ri, Csaba},
  journal={Machine learning},
  volume={38},
  number={3},
  pages={287--308},
  year={2000},
  publisher={Springer}
}

@article{bellman1957markovian,
  title={A {M}arkovian decision process},
  author={Bellman, Richard},
  journal={Journal of Mathematics and Mechanics},
  pages={679--684},
  year={1957},
  publisher={JSTOR}
}


@article{puterman1979convergence,
  title={On the convergence of policy iteration in stationary dynamic programming},
  author={Puterman, Martin L. and Brumelle, Shelby L.},
  journal={Mathematics of Operations Research},
  volume={4},
  number={1},
  pages={60--69},
  year={1979},
  publisher={INFORMS}
}

@article{kearns1998finite,
  title={Finite-sample convergence rates for {Q}-learning and indirect algorithms},
  author={Kearns, Michael and Singh, Satinder},
  journal={Advances in Neural Information Processing Systems},
  year={1998}
}

@article{szepesvari1997asymptotic,
  title={The asymptotic convergence-rate of {Q}-learning},
  author={Szepesv{\'a}ri, Csaba},
  journal={Advances in Neural Information Processing Systems},
  year={1997}
}

@book{mitchell1997machine,
  title={Machine Learning},
  author={Mitchell, Tom},
  year={1997},
  publisher={McGraw-Hill}
}


@article{hutter2000theory,
  title={A theory of universal artificial intelligence based on algorithmic complexity},
  author={Hutter, Marcus},
  journal={arXiv preprint cs/0004001},
  year={2000}
}
@inproceedings{hutter2002self,
  title={Self-optimizing and {P}areto-optimal policies in general environments based on {B}ayes-mixtures},
  author={Hutter, Marcus},
  booktitle={Proceedings of the International Conference on Computational Learning Theory},
  year={2002},
}
@book{hutter2004universal,
  title={Universal artificial intelligence: Sequential decisions based on algorithmic probability},
  author={Hutter, Marcus},
  year={2004},
  publisher={Springer Science \& Business Media}
}
@article{cohen2019strongly,
  title={A strongly asymptotically optimal agent in general environments},
  author={Cohen, Michael K and Catt, Elliot and Hutter, Marcus},
  journal={arXiv preprint arXiv:1903.01021},
  year={2019}
}

@article{lu2023bitbybit,
year = {2023},
volume = {16},
journal = {Foundations and Trends in Machine Learning},
title = {Reinforcement Learning, Bit by Bit},
issn = {1935-8237},
number = {6},
pages = {733-865},
author = {Xiuyuan Lu and Benjamin Van Roy and Vikranth Dwaracherla and Morteza Ibrahimi and Ian Osband and Zheng Wen}
}
@article{lu2021reinforcement,
  title={Reinforcement learning, bit by bit},
  author={Lu, Xiuyuan and Van Roy, Benjamin and Dwaracherla, Vikranth and Ibrahimi, Morteza and Osband, Ian and Wen, Zheng},
  journal={arXiv preprint arXiv:2103.04047},
  year={2021}
}

@article{oh2020discovering,
  title={Discovering reinforcement learning algorithms},
  author={Oh, Junhyuk and Hessel, Matteo and Czarnecki, Wojciech M and Xu, Zhongwen and van Hasselt, Hado P and Singh, Satinder and Silver, David},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@inproceedings{azar2017minimax,
  title={Minimax regret bounds for reinforcement learning},
  author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2017}
}

@article{jaksch2010near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Apr},
  pages={1563--1600},
  year={2010}
}

@article{kearns2002near,
  title={Near-optimal reinforcement learning in polynomial time},
  author={Kearns, Michael and Singh, Satinder},
  journal={Machine learning},
  volume={49},
  number={2-3},
  pages={209--232},
  year={2002},
  publisher={Springer}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@book{abbott2001understanding,
  title={Understanding Analysis},
  author={Abbott, Stephen},
  volume={2},
  year={2001},
  chapter={2},
  publisher={Springer}
}

@article{even2003learning,
  title={Learning Rates for Q-learning.},
  author={Even-Dar, Eyal and Mansour, Yishay and Bartlett, Peter},
  journal={Journal of machine learning Research},
  volume={5},
  number={1},
  year={2003}
}
@inproceedings{beck2013improved,
  title={Improved upper bounds on the expected error in constant step-size Q-learning},
  author={Beck, Carolyn L and Srikant, Rayadurgam},
  booktitle={2013 American Control Conference},
  pages={1926--1931},
  year={2013},
  organization={IEEE}
}

@article{beck2012error,
  title={Error bounds for constant step-size Q-learning},
  author={Beck, Carolyn L and Srikant, Rayadurgam},
  journal={Systems \& control letters},
  volume={61},
  number={12},
  pages={1203--1208},
  year={2012},
  publisher={Elsevier}
}

@article{even2009online,
  title={Online {M}arkov decision processes},
  author={Even-Dar, Eyal and Kakade, Sham M and Mansour, Yishay},
  journal={Mathematics of Operations Research},
  volume={34},
  number={3},
  pages={726--736},
  year={2009},
  publisher={INFORMS}
}

@article{kaelbling1996reinforcement,
  title={Reinforcement learning: A survey},
  author={Kaelbling, Leslie Pack and Littman, Michael L. and Moore, Andrew W.},
  journal={Journal of Artificial Intelligence Research},
  pages={237--285},
  year={1996}
}

@book{lattimore2020bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}

@article{schrittwieser2020mastering,
  title={Mastering atari, {G}o, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={Nature},
  volume={588},
  number={7839},
  pages={604--609},
  year={2020},
  publisher={Nature Publishing Group}
}

@phdthesis{lattimore2014theory,
  title={Theory of general reinforcement learning},
  author={Lattimore, Tor},
  year={2014},
  school={The Australian National University}
}

@phdthesis{majeed2021abstractions,
  title={Abstractions of general reinforcement Learning},
  author={Majeed, Sultan J},
  school={The Australian National University},
  year={2021},
}

@inproceedings{shi2020does,
  title={Does the {M}arkov decision process fit the data: Testing for the {M}arkov property in sequential decision making},
  author={Shi, Chengchun and Wan, Runzhe and Song, Rui and Lu, Wenbin and Leng, Ling},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2020},
}

@article{mnih2015human,
  Author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  Journal = {Nature},
  Number = {7540},
  Pages = {529--533},
  Title = {Human-level control through deep reinforcement learning},
  Volume = {518},
  Year = {2015}
}

@incollection{sutton1992introduction,
  title={Introduction: The challenge of reinforcement learning},
  author={Sutton, Richard S},
  booktitle={Reinforcement Learning},
  pages={1--3},
  year={1992},
  publisher={Springer}
}

@article{robbins1951stochastic,
  title={A stochastic approximation method},
  author={Robbins, Herbert and Monro, Sutton},
  journal={The annals of mathematical statistics},
  pages={400--407},
  year={1951},
  publisher={JSTOR}
}

@article{brafman2002r,
  title={R-max-a general polynomial time algorithm for near-optimal reinforcement learning},
  author={Brafman, Ronen I and Tennenholtz, Moshe},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Oct},
  pages={213--231},
  year={2002}
}
@article{khetarpal2022towards,
  title={Towards continual reinforcement learning: A review and perspectives},
  author={Khetarpal, Khimya and Riemer, Matthew and Rish, Irina and Precup, Doina},
  journal={Journal of Artificial Intelligence Research},
  volume={75},
  pages={1401--1476},
  year={2022}
}



@article{littman2015reinforcement,
  title={Reinforcement learning improves behaviour from evaluative feedback},
  author={Littman, Michael L.},
  journal={Nature},
  volume={521},
  number={7553},
  pages={445--451},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{murphy2005generalization,
  author  = {Susan A. Murphy},
  title   = {A Generalization Error for Q-Learning},
  journal = {Journal of Machine Learning Research},
  year    = {2005},
  volume  = {6},
  number  = {37},
  pages   = {1073--1097},
}
}

@article{minsky1961steps,
  title={Steps toward artificial intelligence},
  author={Minsky, Marvin},
  journal={Proceedings of the IRE},
  volume={49},
  number={1},
  pages={8--30},
  year={1961},
  publisher={IEEE}
}

@article{moerland2020model,
  title={Model-based reinforcement learning: A survey},
  author={Moerland, Thomas M and Broekens, Joost and Jonker, Catholijn M},
  journal={arXiv preprint arXiv:2006.16712},
  year={2020}
}

@article{simon1955behavioral,
  title={A behavioral model of rational choice},
  author={Simon, Herbert A},
  journal={The quarterly journal of economics},
  volume={69},
  number={1},
  pages={99--118},
  year={1955},
  publisher={MIT Press}
}

@book{cherniak1990minimal,
  title={Minimal rationality},
  author={Cherniak, Christopher},
  year={1990},
  publisher={MIT Press}
}

@book{todd2012ecological,
  title={Ecological rationality: Intelligence in the world.},
  author={Todd, Peter M and Gigerenzer, Gerd Ed},
  year={2012},
  publisher={Oxford University Press}
}

@article{gershman2015computational,
  title={Computational rationality: A converging paradigm for intelligence in brains, minds, and machines},
  author={Gershman, Samuel J and Horvitz, Eric J and Tenenbaum, Joshua B},
  journal={Science},
  volume={349},
  number={6245},
  pages={273--278},
  year={2015},
  publisher={American Association for the Advancement of Science}
}

@article{lewis2014computational,
  title={Computational rationality: Linking mechanism and behavior through bounded utility maximization},
  author={Lewis, Richard L and Howes, Andrew and Singh, Satinder},
  journal={Topics in cognitive science},
  volume={6},
  number={2},
  pages={279--311},
  year={2014},
  publisher={Wiley Online Library}
}

@article{russell1994provably,
  title={Provably bounded-optimal agents},
  author={Russell, Stuart J and Subramanian, Devika},
  journal={Journal of Artificial Intelligence Research},
  volume={2},
  pages={575--609},
  year={1994}
}

@inproceedings{fazel2018global,
  title={Global convergence of policy gradient methods for the linear quadratic regulator},
  author={Fazel, Maryam and Ge, Rong and Kakade, Sham and Mesbahi, Mehran},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2018},
}

@article{sutton1999policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
  journal={Advances in neural information processing systems},
  year={1999}
}

@inproceedings{russo2016simple,
  title={Simple {B}ayesian algorithms for best arm identification},
  author={Russo, Daniel},
  booktitle={Proceedings of the Conference on Learning Theory},
  year={2016},
}

@book{pollard2012convergence,
  title={Convergence of stochastic processes},
  author={Pollard, David},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@inproceedings{gordon2000reinforcement,
  title={Reinforcement learning with function approximation converges to a region},
  author={Gordon, Geoffrey J},
  booktitle={Advances in Neural Information Processing Systems},
  year={2000}
}

@inproceedings{leike2016thompson,
  title={Thompson sampling is asymptotically optimal in general environments},
  author={Leike, Jan and Lattimore, Tor and Orseau, Laurent and Hutter, Marcus},
  booktitle={Proceedings of the Conference on Uncertainty in Artificial Intelligence},
  year={2016}
}

@inproceedings{lattimore2011asymptotically,
  title={Asymptotically optimal agents},
  author={Lattimore, Tor and Hutter, Marcus},
  booktitle={Proceedings of the International Conference on Algorithmic Learning Theory},
  year={2011},
}

@inproceedings{majeed2018q,
  title={On {Q}-learning Convergence for Non-{M}arkov Decision Processes.},
  author={Majeed, Sultan J. and Hutter, Marcus},
  booktitle={Proceedings of the International Joint Conference on Artificial Intelligence},
  year={2018}
}

@phdthesis{mccallum1996reinforcement,
  title={Reinforcement learning with selective perception and hidden state},
  author={McCallum, Andrew Kachites},
  year={1996},
  publisher={University of Rochester}
}

@inproceedings{fiechter1994efficient,
  title={Efficient reinforcement learning},
  author={Fiechter, Claude-Nicolas},
  booktitle={Proceedings of the Conference on Computational Learning Theory},
  year={1994}
}
@article{sallans2004reinforcement,
  title={Reinforcement learning with factored states and actions},
  author={Sallans, Brian and Hinton, Geoffrey E},
  journal={The Journal of Machine Learning Research},
  volume={5},
  pages={1063--1088},
  year={2004},
  publisher={JMLR.org}
}

@article{calandriello2014sparse,
  title={Sparse multi-task reinforcement learning},
  author={Calandriello, Daniele and Lazaric, Alessandro and Restelli, Marcello},
  journal={Advances in neural information processing systems},
  year={2014}
}

@article{mahadevan1996average,
  title={Average reward reinforcement learning: Foundations, algorithms, and empirical results},
  author={Mahadevan, Sridhar},
  journal={Machine learning},
  volume={22},
  number={1},
  pages={159--195},
  year={1996},
  publisher={Springer}
}


@article{griffiths2015rational,
  title={Rational use of cognitive resources: Levels of analysis between the computational and the algorithmic},
  author={Griffiths, Thomas L and Lieder, Falk and Goodman, Noah D},
  journal={Topics in cognitive science},
  volume={7},
  number={2},
  pages={217--229},
  year={2015},
  publisher={Wiley Online Library}
}


@article{auer2008near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Auer, Peter and Jaksch, Thomas and Ortner, Ronald},
  journal={Advances in Neural Information Processing Systems},
  year={2008}
}

@inproceedings{konidaris2007building,
  title={Building Portable Options: Skill Transfer in Reinforcement Learning.},
  author={Konidaris, George and Barto, Andrew},
  booktitle={Proceedings of the International Joint Conference on Artificial Intelligence},
  year={2007}
}

@inproceedings{konidaris2006autonomous,
  title={Autonomous shaping: Knowledge transfer in reinforcement learning},
  author={Konidaris, George and Barto, Andrew},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2006}
}

@inproceedings{konidaris2006framework,
  title={A framework for transfer in reinforcement learning},
  author={Konidaris, George},
  booktitle={ICML Workshop on Structural Knowledge Transfer for Machine Learning},
  year={2006}
}

@inproceedings{diuk2008object,
  title={An object-oriented representation for efficient reinforcement learning},
  author={Diuk, Carlos and Cohen, Andre and Littman, Michael L},
  booktitle={Proceedings of the International conference on Machine learning},
  year={2008}
}

@inproceedings{kearns1999efficient,
  title={Efficient reinforcement learning in factored {MDP}s},
  author={Kearns, Michael and Koller, Daphne},
  booktitle={Proceedings of the International Joint Conference on Artificial Intelligence},
  year={1999}
}

@article{icarte2022reward,
  title={Reward machines: Exploiting reward function structure in reinforcement learning},
  author={Icarte, Rodrigo Toro and Klassen, Toryn Q and Valenzano, Richard and McIlraith, Sheila A},
  journal={Journal of Artificial Intelligence Research},
  volume={73},
  pages={173--208},
  year={2022}
}
@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Proceedings of the Conference on Learning Theory},
  year={2020},
}

@article{bradtke1996linear,
  title={Linear least-squares algorithms for temporal difference learning},
  author={Bradtke, Steven J and Barto, Andrew G},
  journal={Machine learning},
  volume={22},
  number={1},
  pages={33--57},
  year={1996},
  publisher={Springer}
}

@inproceedings{majeed2019performance,
  title={Performance guarantees for homomorphisms beyond {M}arkov decision processes},
  author={Majeed, Sultan Javed and Hutter, Marcus},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2019}
}

@article{van2006performance,
  title={Performance loss bounds for approximate value iteration with state aggregation},
  author={Van Roy, Benjamin},
  journal={Mathematics of Operations Research},
  volume={31},
  number={2},
  pages={234--244},
  year={2006},
  publisher={INFORMS}
}

@article{chen2021lyapunov,
  title={A {L}yapunov theory for finite-sample guarantees of asynchronous {Q}-learning and {TD}-learning variants},
  author={Chen, Zaiwei and Maguluri, Siva Theja and Shakkottai, Sanjay and Shanmugam, Karthikeyan},
  journal={arXiv preprint arXiv:2102.01567},
  year={2021}
}
@misc{harutyunyan2020what,
    title = {What is an agent?},
    author = {Anna Harutyunyan},
    year ={2020},
    howpublished= {\url{http://anna.harutyunyan.net/wp-content/uploads/2020/09/What_is_an_agent.pdf}},
}

@phdthesis{ortega2011unified,
  title={A unified framework for resource-bounded autonomous agents interacting with unknown environments},
  author={Ortega, Pedro Alejandro},
  year={2011},
  school={University of Cambridge}
}

@phdthesis{ring1994continual,
  title={Continual learning in reinforcement environments},
  author={Ring, Mark B},
  year={1994},
  school={The University of Texas at Austin}
}

@article{abel2023convergence,
    title={On the Convergence of Bounded Agents},
    author={Abel, David and Barreto, Andr{\'e}, and van Hasselt, Hado and Precup, Doina and Van Roy, Benjamin and Singh, Satinder},
    year={2023},
}

@inproceedings{bowling2023settling,
title={Settling the Reward Hypothesis},
author={Bowling, Michael and Martin, John D. and Abel, David and Dabney, Will},
booktitle={Proceedings of the International Conference on Machine Learning},
year={2023}
}

@article{sutton2022quest,
  title={The quest for a common model of the intelligent decision maker},
  author={Sutton, Richard S},
  journal={arXiv preprint arXiv:2202.13252},
  year={2022}
}

@article{Valiant1984,
    author = {Valiant, Leslie G.},
    journal = {Communications of the ACM},
    number = {11},
    pages = {1134--1142},
    pmid = {12929239},
    title = {{A theory of the learnable}},
    volume = {27},
    year = {1984}
}

@article{vapnik1971uniform,
  title={On the Uniform Convergence of Relative Frequencies of Events to Their Probabilities},
  author={Vapnik, Vladimir N. and Chervonenkis, Aleksei Y.},
  journal={Theory of Probability \& Its Applications},
  volume={16},
  number={2},
  pages={264--280},
  year={1971},
  publisher={SIAM}
}

@book{shalev2014understanding,
  title={Understanding Machine Learning: From Theory to Algorithms},
  author={Shalev-Shwartz, Shai and Ben-David, Shai},
  year={2014},
  publisher={Cambridge University Press}
}

@article{silver2016mastering,
  title={Mastering the game of {G}o with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}
@inproceedings{schwarz2018progress,
  title={Progress \& compress: A scalable framework for continual learning},
  author={Schwarz, Jonathan and Czarnecki, Wojciech and Luketina, Jelena and Grabska-Barwinska, Agnieszka and Teh, Yee Whye and Pascanu, Razvan and Hadsell, Raia},
    booktitle={Proceedings of the International Conference on Machine Learning},
  year={2018},
}

@article{rolnick2019experience,
  title={Experience replay for continual learning},
  author={Rolnick, David and Ahuja, Arun and Schwarz, Jonathan and Lillicrap, Timothy and Wayne, Gregory},
  journal={Advances in Neural Information Processing Systems},
  year={2019}
}

@article{ring1997child,
  title={CHILD: A first step towards continual learning},
  author={Ring, Mark B},
  journal={Machine Learning},
  volume={28},
  number={1},
  pages={77--104},
  year={1997},
  publisher={Springer}
}

@article{parisi2019continual,
  title={Continual lifelong learning with neural networks: A review},
  author={Parisi, German I and Kemker, Ronald and Part, Jose L and Kanan, Christopher and Wermter, Stefan},
  journal={Neural networks},
  volume={113},
  pages={54--71},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{luketina2022,
author = {Jelena Luketina and Sebastian Flennerhag and Yannick Schroecker and David Abel and Tom Zahavy and Satinder Singh},
title = {Meta-Gradients in Non-Stationary Environments},
booktitle = {Proceedings of the Conference on Lifelong Learning Agents},
year = {2022}
}
@article{baker2023domain,
  title={A domain-agnostic approach for characterization of lifelong learning systems},
  author={Baker, Megan M and New, Alexander and Aguilar-Simon, Mario and Al-Halah, Ziad and Arnold, S{\'e}bastien MR and Ben-Iwhiwhu, Ese and Brna, Andrew P and Brooks, Ethan and Brown, Ryan C and Daniels, Zachary and others},
  journal={Neural Networks},
  volume={160},
  pages={274--296},
  year={2023},
  publisher={Elsevier}
}

@article{mai2022online,
  title={Online continual learning in image classification: An empirical survey},
  author={Mai, Zheda and Li, Ruiwen and Jeong, Jihwan and Quispe, David and Kim, Hyunwoo and Sanner, Scott},
  journal={Neurocomputing},
  volume={469},
  pages={28--51},
  year={2022},
  publisher={Elsevier}
}
@article{lesort2020continual,
  title={Continual learning for robotics: Definition, framework, learning strategies, opportunities and challenges},
  author={Lesort, Timoth{\'e}e and Lomonaco, Vincenzo and Stoian, Andrei and Maltoni, Davide and Filliat, David and D{\'\i}az-Rodr{\'\i}guez, Natalia},
  journal={Information fusion},
  volume={58},
  pages={52--68},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{ring2005toward,
  title={Toward a formal framework for continual learning},
  author={Ring, Mark B},
  booktitle={NeurIPS Workshop on Inductive Transfer},
  year={2005}
}

@article{hadsell2020embracing,
  title={Embracing change: Continual learning in deep neural networks},
  author={Hadsell, Raia and Rao, Dushyant and Rusu, Andrei A and Pascanu, Razvan},
  journal={Trends in cognitive sciences},
  volume={24},
  number={12},
  pages={1028--1040},
  year={2020},
  publisher={Elsevier}
}

@book{friedman1953essays,
  title={Essays in positive economics},
  author={Friedman, Milton},
  year={1953},
  publisher={University of Chicago press}
}

@article{riemer2022continual,
  title={Continual learning in environments with polynomial mixing times},
  author={Riemer, Matthew and Raparthy, Sharath Chandra and Cases, Ignacio and Subbaraj, Gopeshh and Puelma Touzel, Maximilian and Rish, Irina},
  journal={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{bartlett2002rademacher,
  title={Rademacher and Gaussian complexities: Risk bounds and structural results},
  author={Bartlett, Peter L and Mendelson, Shahar},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Nov},
  year={2002}
}



@inproceedings{abel2018transfer,
title={Policy and Value Transfer in Lifelong Reinforcement Learning},
author={David Abel and Yuu Jinnai and Yue Guo and George Konidaris and Michael L. Littman},
booktitle={Proceedings of the International Conference on Machine Learning},
year={2018}
}

@article{abbas2023loss,
  title={Loss of Plasticity in Continual Deep Reinforcement Learning},
  author={Abbas, Zaheer and Zhao, Rosie and Modayil, Joseph and White, Adam and Machado, Marlos C},
  journal={arXiv preprint arXiv:2303.07507},
  year={2023}
}

@inproceedings{lyle2023understanding,
  title={Understanding plasticity in neural networks},
  author={Lyle, Clare and Zheng, Zeyu and Nikishin, Evgenii and Pires, Bernardo Avila and Pascanu, Razvan and Dabney, Will},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2023}
}

@article{french1999catastrophic,
  title={Catastrophic forgetting in connectionist networks},
  author={French, Robert M},
  journal={Trends in cognitive sciences},
  volume={3},
  number={4},
  pages={128--135},
  year={1999},
  publisher={Elsevier}
}

@article{dohare2023loss,
  title={Loss of Plasticity in Deep Continual Learning},
  author={Dohare, Shibhansh and Hernandez-Garcia, Juan and Rahman, Parash and Sutton, Richard and Mahmood, A Rupam},
  journal={arXiv preprint arXiv:2306.13812},
  year={2023}
}
@article{dohare2021continual,
  title={Continual backprop: Stochastic gradient descent with persistent randomness},
  author={Dohare, Shibhansh and Sutton, Richard S and Mahmood, A Rupam},
  journal={arXiv preprint arXiv:2108.06325},
  year={2021}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@article{thrun1995lifelong,
  title={Lifelong robot learning},
  author={Thrun, Sebastian and Mitchell, Tom M},
  journal={Robotics and autonomous systems},
  volume={15},
  number={1-2},
  pages={25--46},
  year={1995},
  publisher={Elsevier}
}

@article{thrun1998lifelong,
  title={Lifelong Learning Algorithms.},
  author={Thrun, Sebastian},
  journal={Learning to Learn},
  volume={8},
  pages={181--209},
  year={1998}
}

@article{schaul2018barbados,
  title={The {B}arbados 2018 list of open issues in continual learning},
  author={Schaul, Tom and van Hasselt, Hado and Modayil, Joseph and White, Martha and White, Adam and Bacon, Pierre-Luc and Harb, Jean and Mourad, Shibl and Bellemare, Marc and Precup, Doina},
  journal={arXiv preprint arXiv:1811.07004},
  year={2018}
}

@article{de2013learning,
  title={What is learning? On the nature and merits of a functional definition of learning},
  author={De Houwer, Jan and Barnes-Holmes, Dermot and Moors, Agnes},
  journal={Psychonomic bulletin \& review},
  volume={20},
  pages={631--642},
  year={2013},
  publisher={Springer}
}

@article{thrun1995thenth,
  title={Is learning the n-th thing any easier than learning the first?},
  author={Thrun, Sebastian},
  journal={Advances in Neural Information Processing Systems},
  year={1995}
}

@article{sutton2022alberta,
  title={The Alberta plan for {AI} research},
  author={Sutton, Richard S and Bowling, Michael and Pilarski, Patrick M},
  journal={arXiv preprint arXiv:2208.11173},
  year={2022}
}

@article{goodfellow2013empirical,
  title={An empirical investigation of catastrophic forgetting in gradient-based neural networks},
  author={Goodfellow, Ian J and Mirza, Mehdi and Xiao, Da and Courville, Aaron and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1312.6211},
  year={2013}
}

@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the National Academy of Sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
}

@article{teh2017distral,
  title={Distral: Robust multitask reinforcement learning},
  author={Teh, Yee and Bapst, Victor and Czarnecki, Wojciech M and Quan, John and Kirkpatrick, James and Hadsell, Raia and Heess, Nicolas and Pascanu, Razvan},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{nguyen2018variational,
  title={Variational continual learning},
  author={Nguyen, Cuong V and Li, Yingzhen and Bui, Thang D and Turner, Richard E},
  journal={Proceedings of the International Conference on Learning Representations},
  year={2018}
}

@article{liu2023definition,
  title={A Definition of Non-Stationary Bandits},
  author={Liu, Yueyang and Van Roy, Benjamin and Xu, Kuang},
  journal={arXiv preprint arXiv:2302.12202},
  year={2023}
}


@article{monteleoni2003online,
  title={Online learning of non-stationary sequences},
  author={Monteleoni, Claire and Jaakkola, Tommi},
  journal={Advances in Neural Information Processing Systems},
  volume={16},
  year={2003}
}


@inproceedings{bartlett1992learning,
  title={Learning with a slowly changing distribution},
  author={Bartlett, Peter L},
  booktitle={Proceedings of the Annual Workshop on Computational Learning Theory},
  year={1992}
}


@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2017},
}

@article{schaul2010metalearning,
  title={Metalearning},
  author={Schaul, Tom and Schmidhuber, J{\"u}rgen},
  journal={Scholarpedia},
  volume={5},
  number={6},
  pages={4650},
  year={2010}
}

@article{kumar2023continual,
  title={Continual learning as computationally constrained reinforcement learning},
  author={Kumar, Saurabh and Marklund, Henrik and Rao, Ashish and Zhu, Yifan and Jeon, Hong Jun and Liu, Yueyang and Van Roy, Benjamin},
  journal={arXiv preprint arXiv:2307.04345},
  year={2023}
}

@inproceedings{silver2011machine,
  title={Machine lifelong learning: Challenges and benefits for artificial general intelligence},
  author={Silver, Daniel L},
  booktitle={Proceedings of the Conference on Artificial General Intelligence},
  year={2011},
}

@incollection{schmidhuber1998reinforcement,
  title={Reinforcement learning with self-modifying policies},
  author={Schmidhuber, J{\"u}rgen and Zhao, Jieyu and Schraudolph, Nicol N},
  booktitle={Learning to Learn},
  pages={293--309},
  year={1998},
  publisher={Springer}
}

@inproceedings{ruvolo2013ella,
  title={{ELLA}: An efficient lifelong learning algorithm},
  author={Ruvolo, Paul and Eaton, Eric},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2013},
}

@inproceedings{ammar2015safe,
  title={Safe policy search for lifelong reinforcement learning with sublinear regret},
  author={Ammar, Haitham Bou and Tutunov, Rasul and Eaton, Eric},
  booktitle={Proceedings of the International Conference on Machine Learning},
  year={2015},
}

@article{fu2022model,
  title={Model-based Lifelong Reinforcement Learning with {B}ayesian Exploration},
  author={Fu, Haotian and Yu, Shangqun and Littman, Michael and Konidaris, George},
  journal={Advances in Neural Information Processing Systems},
  year={2022}
}