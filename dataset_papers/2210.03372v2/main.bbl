\begin{thebibliography}{64}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bossard et~al.(2014)Bossard, Guillaumin, and Gool]{bossard2014food}
Lukas Bossard, Matthieu Guillaumin, and Luc~Van Gool.
\newblock Food-101--mining discriminative components with random forests.
\newblock In \emph{European Conference on Computer Vision (ECCV)}, pages
  446--461, 2014.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  et~al.
\newblock Language models are few-shot learners.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pages 1877--1901, 2020.

\bibitem[Chen et~al.(2020{\natexlab{a}})Chen, Liu, Chang, Cheng, Amini, and
  Wang]{chen2020adversarial}
Tianlong Chen, Sijia Liu, Shiyu Chang, Yu~Cheng, Lisa Amini, and Zhangyang
  Wang.
\newblock Adversarial robustness: From self-supervised pre-training to
  fine-tuning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 699--708, 2020{\natexlab{a}}.

\bibitem[Chen et~al.(2020{\natexlab{b}})Chen, Kornblith, Norouzi, and
  Hinton]{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pages
  1597--1607, 2020{\natexlab{b}}.

\bibitem[Chen et~al.(2020{\natexlab{c}})Chen, Kornblith, Swersky, Norouzi, and
  Hinton]{chen2020big}
Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey~E
  Hinton.
\newblock Big self-supervised models are strong semi-supervised learners.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pages 22243--22255, 2020{\natexlab{c}}.

\bibitem[Chen and Ma(2021)]{chen2021towards}
Tong Chen and Zhan Ma.
\newblock Towards robust neural image compression: Adversarial attack and model
  finetuning.
\newblock \emph{arXiv preprint arXiv:2112.08691}, 2021.

\bibitem[Cimpoi et~al.(2014)Cimpoi, Maji, Kokkinos, Mohamed, and
  Vedaldi]{cimpoi2014DTD}
Mircea Cimpoi, Subhransu Maji, Iasonas Kokkinos, Sammy Mohamed, and Andrea
  Vedaldi.
\newblock Describing textures in the wild.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 3606--3613, 2014.

\bibitem[Coates et~al.(2011)Coates, Ng, and Lee]{coates2011stl10}
Adam Coates, Andrew Ng, and Honglak Lee.
\newblock An analysis of single-layer networks in unsupervised feature
  learning.
\newblock In \emph{Proceedings of the Fourteenth International Conference on
  Artificial Intelligence and Statistics (AISTATS)}, pages 215--223, 2011.

\bibitem[Deng and Karam(2020)]{deng2020uapepgd}
Yingpeng Deng and Lina~J Karam.
\newblock Universal adversarial attack via enhanced projected gradient descent.
\newblock In \emph{IEEE International Conference on Image Processing (ICIP)},
  pages 1241--1245, 2020.

\bibitem[Dong et~al.(2021)Dong, Luu, Lin, Yan, and Zhang]{dong2021should}
Xinshuai Dong, Anh~Tuan Luu, Min Lin, Shuicheng Yan, and Hanwang Zhang.
\newblock How should pre-trained language models be fine-tuned towards
  adversarial robustness?
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pages 4356--4369, 2021.

\bibitem[Dong et~al.(2018)Dong, Liao, Pang, Su, Zhu, Hu, and
  Li]{dong2018boosting}
Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu, and
  Jianguo Li.
\newblock Boosting adversarial attacks with momentum.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 9185--9193, 2018.

\bibitem[Dong et~al.(2019)Dong, Pang, Su, and Zhu]{dong2019evading}
Yinpeng Dong, Tianyu Pang, Hang Su, and Jun Zhu.
\newblock Evading defenses to transferable adversarial examples by
  translation-invariant attacks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 4312--4321, 2019.

\bibitem[Fan et~al.(2021)Fan, Liu, Chen, Zhang, and Gan]{fan2021does}
Lijie Fan, Sijia Liu, Pin-Yu Chen, Gaoyuan Zhang, and Chuang Gan.
\newblock When does contrastive learning preserve adversarial robustness from
  pretraining to finetuning?
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pages 21480--21492, 2021.

\bibitem[Gidaris et~al.(2018)Gidaris, Singh, and
  Komodakis]{gidaris2018unsupervisedrotation}
Spyros Gidaris, Praveer Singh, and Nikos Komodakis.
\newblock Unsupervised representation learning by predicting image rotations.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow2014adver}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2015.

\bibitem[Guo et~al.(2019)Guo, Shi, Kumar, Grauman, Rosing, and
  Feris]{guo2019spottune}
Yunhui Guo, Honghui Shi, Abhishek Kumar, Kristen Grauman, Tajana Rosing, and
  Rogerio Feris.
\newblock Spottune: transfer learning through adaptive fine-tuning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 4805--4814, 2019.

\bibitem[Han et~al.(2021)Han, Zhang, Ding, Gu, Liu, Huo, Qiu, Yao, Zhang,
  Zhang, et~al.]{han2021pre}
Xu~Han, Zhengyan Zhang, Ning Ding, Yuxian Gu, Xiao Liu, Yuqi Huo, Jiezhong Qiu,
  Yuan Yao, Ao~Zhang, Liang Zhang, et~al.
\newblock Pre-trained models: Past, present and future.
\newblock \emph{AI Open}, pages 225--250, 2021.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 770--778, 2016.

\bibitem[He et~al.(2020{\natexlab{a}})He, Fan, Wu, Xie, and
  Girshick]{he2020moco}
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 9729--9738, 2020{\natexlab{a}}.

\bibitem[He et~al.(2020{\natexlab{b}})He, Fan, Wu, Xie, and
  Girshick]{he2020momentum}
Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 9729--9738, 2020{\natexlab{b}}.

\bibitem[He et~al.(2022)He, Chen, Xie, Li, Doll\'ar, and
  Girshick]{he2021masked}
Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\'ar, and Ross
  Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 16000--16009, 2022.

\bibitem[Inoue(2018)]{inoue2018data}
Hiroshi Inoue.
\newblock Data augmentation by pairing samples for images classification.
\newblock \emph{arXiv preprint arXiv:1801.02929}, 2018.

\bibitem[Ioffe and Szegedy(2015)]{ioffe2015batch}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pages
  448--456, 2015.

\bibitem[Jiang et~al.(2020)Jiang, Chen, Chen, and Wang]{jiang2020robust}
Ziyu Jiang, Tianlong Chen, Ting Chen, and Zhangyang Wang.
\newblock Robust pre-training by adversarial contrastive learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pages 16199--16210, 2020.

\bibitem[Kenton and Toutanova(2019)]{devlin2018bert}
Jacob Devlin Ming-Wei~Chang Kenton and Lee~Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{Annual Conference of the North American Chapter of the
  Association for Computational Linguistics (NAACL)}, pages 4171--4186, 2019.

\bibitem[Khosla et~al.(2020)Khosla, Teterwak, Wang, Sarna, Tian, Isola,
  Maschinot, Liu, and Krishnan]{khosla2020supervised}
Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip
  Isola, Aaron Maschinot, Ce~Liu, and Dilip Krishnan.
\newblock Supervised contrastive learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pages 18661--18673, 2020.

\bibitem[Khrulkov and Oseledets(2018)]{khrulkov2018asv}
Valentin Khrulkov and Ivan Oseledets.
\newblock Art of singular vectors and universal adversarial perturbations.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 8562--8570, 2018.

\bibitem[Krause et~al.(2013)Krause, Deng, Stark, and Fei-Fei]{krause2013cars}
Jonathan Krause, Jia Deng, Michael Stark, and Li~Fei-Fei.
\newblock Collecting a large-scale dataset of fine-grained cars.
\newblock 2013.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009cifar100}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Kumar et~al.(2022)Kumar, Raghunathan, Jones, Ma, and
  Liang]{kumar2022fine}
Ananya Kumar, Aditi Raghunathan, Robbie Jones, Tengyu Ma, and Percy Liang.
\newblock Fine-tuning can distort pretrained features and underperform
  out-of-distribution.
\newblock \emph{The International Conference on Learning Representations
  (ICLR)}, 2022.

\bibitem[Kurakin et~al.(2018)Kurakin, Goodfellow, and
  Bengio]{kurakin2018physical}
Alexey Kurakin, Ian~J Goodfellow, and Samy Bengio.
\newblock Adversarial examples in the physical world.
\newblock In \emph{Artificial Intelligence Safety and Security}, pages 99--112.
  2018.

\bibitem[Le-Khac et~al.(2020)Le-Khac, Healy, and Smeaton]{le2020contrastive}
Phuc~H Le-Khac, Graham Healy, and Alan~F Smeaton.
\newblock Contrastive representation learning: A framework and review.
\newblock \emph{IEEE Access}, pages 193907--193934, 2020.

\bibitem[Liu et~al.(2017)Liu, Chen, Liu, and Song]{liu2016blackbox}
Yanpei Liu, Xinyun Chen, Chang Liu, and Dawn Song.
\newblock Delving into transferable adversarial examples and black-box attacks.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2017.

\bibitem[Liu et~al.(2019)Liu, Ott, Goyal, Du, Joshi, Chen, Levy, Lewis,
  Zettlemoyer, and Stoyanov]{liu2019roberta}
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer
  Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.
\newblock Roberta: A robustly optimized bert pretraining approach.
\newblock \emph{arXiv preprint arXiv:1907.11692}, 2019.

\bibitem[Lu et~al.(2020{\natexlab{a}})Lu, Jia, Wang, Li, Chai, Carin, and
  Velipasalar]{lu2020DR}
Yantao Lu, Yunhan Jia, Jianyu Wang, Bai Li, Weiheng Chai, Lawrence Carin, and
  Senem Velipasalar.
\newblock Enhancing cross-task black-box transferability of adversarial
  examples with dispersion reduction.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 940--949, 2020{\natexlab{a}}.

\bibitem[Lu et~al.(2020{\natexlab{b}})Lu, Jia, Wang, Li, Chai, Carin, and
  Velipasalar]{lu2020std}
Yantao Lu, Yunhan Jia, Jianyu Wang, Bai Li, Weiheng Chai, Lawrence Carin, and
  Senem Velipasalar.
\newblock Enhancing cross-task black-box transferability of adversarial
  examples with dispersion reduction.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 940--949, 2020{\natexlab{b}}.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2017PGD}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Maji et~al.(2013)Maji, Rahtu, Kannala, Blaschko, and
  Vedaldi]{maji2013fgvc}
Subhransu Maji, Esa Rahtu, Juho Kannala, Matthew Blaschko, and Andrea Vedaldi.
\newblock Fine-grained visual classification of aircraft.
\newblock \emph{arXiv preprint arXiv:1306.5151}, 2013.

\bibitem[Moosavi-Dezfooli et~al.(2016)Moosavi-Dezfooli, Fawzi, and
  Frossard]{moosavi2016deepfool}
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard.
\newblock Deepfool: a simple and accurate method to fool deep neural networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition (CVPR)}, pages 2574--2582, 2016.

\bibitem[Moosavi-Dezfooli et~al.(2017)Moosavi-Dezfooli, Fawzi, Fawzi, and
  Frossard]{moosavi2017universal}
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, and Pascal
  Frossard.
\newblock Universal adversarial perturbations.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 1765--1773, 2017.

\bibitem[Mopuri et~al.(2017)Mopuri, Garg, and Babu]{mopuri2017fff}
Konda~Reddy Mopuri, Utsav Garg, and R~Venkatesh Babu.
\newblock Fast feature fool: A data independent approach to universal
  adversarial perturbations.
\newblock In \emph{British Machine Vision Conference (BMVC)}, 2017.

\bibitem[Naseer et~al.(2019)Naseer, Khan, Khan, Shahbaz~Khan, and
  Porikli]{naseer2019cross}
Muhammad~Muzammal Naseer, Salman~H Khan, Muhammad~Haris Khan, Fahad
  Shahbaz~Khan, and Fatih Porikli.
\newblock Cross-domain transferability of adversarial perturbations.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pages 12905--12915, 2019.

\bibitem[Naseer et~al.(2020)Naseer, Khan, Hayat, Khan, and
  Porikli]{naseer2020ssp}
Muzammal Naseer, Salman Khan, Munawar Hayat, Fahad~Shahbaz Khan, and Fatih
  Porikli.
\newblock A self-supervised approach for adversarial robustness.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 262--271, 2020.

\bibitem[Netzer et~al.(2011)Netzer, Wang, Coates, Bissacco, Wu, and
  Ng]{netzer2011svhn}
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo~Wu, and Andrew~Y
  Ng.
\newblock Reading digits in natural images with unsupervised feature learning.
\newblock 2011.

\bibitem[Noroozi and Favaro(2016)]{noroozi2016jig}
Mehdi Noroozi and Paolo Favaro.
\newblock Unsupervised learning of visual representations by solving jigsaw
  puzzles.
\newblock In \emph{European Conference on Computer Vision (ECCV)}, pages
  69--84, 2016.

\bibitem[Oquab et~al.(2014)Oquab, Bottou, Laptev, and Sivic]{oquab2014transfer}
Maxime Oquab, Leon Bottou, Ivan Laptev, and Josef Sivic.
\newblock Learning and transferring mid-level image representations using
  convolutional neural networks.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 1717--1724, 2014.

\bibitem[Papernot et~al.(2016)Papernot, McDaniel, Jha, Fredrikson, Celik, and
  Swami]{papernot2016lJMSA}
Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z~Berkay
  Celik, and Ananthram Swami.
\newblock The limitations of deep learning in adversarial settings.
\newblock In \emph{2016 IEEE European Symposium on Security and Privacy
  (EuroS\&P)}, pages 372--387, 2016.

\bibitem[Park et~al.(2020)Park, Efros, Zhang, and Zhu]{park2020contrastive}
Taesung Park, Alexei~A Efros, Richard Zhang, and Jun-Yan Zhu.
\newblock Contrastive learning for unpaired image-to-image translation.
\newblock In \emph{European Conference on Computer Vision (ECCV)}, pages
  319--345, 2020.

\bibitem[Parkhi et~al.(2012)Parkhi, Vedaldi, Zisserman, and
  Jawahar]{parkhi2012pets}
Omkar~M Parkhi, Andrea Vedaldi, Andrew Zisserman, and CV~Jawahar.
\newblock Cats and dogs.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 3498--3505, 2012.

\bibitem[Qiu et~al.(2020)Qiu, Sun, Xu, Shao, Dai, and Huang]{qiu2020pre}
Xipeng Qiu, Tianxiang Sun, Yige Xu, Yunfan Shao, Ning Dai, and Xuanjing Huang.
\newblock Pre-trained models for natural language processing: A survey.
\newblock \emph{Science China Technological Sciences}, pages 1872--1897, 2020.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark, et~al.]{radford2021clip}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pages
  8748--8763, 2021.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, et~al.]{russakovsky2015imagenet}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{International journal of computer vision (IJCV)}, pages
  211--252, 2015.

\bibitem[Sai et~al.(2020)Sai, Mohankumar, Arora, and Khapra]{sai2020improving}
Ananya~B Sai, Akash~Kumar Mohankumar, Siddhartha Arora, and Mitesh~M Khapra.
\newblock Improving dialog evaluation with a multi-reference adversarial
  dataset and large scale pretraining.
\newblock \emph{Transactions of the Association for Computational Linguistics
  (TACL)}, pages 810--827, 2020.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013FGSM}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2014.

\bibitem[Trinh et~al.(2019)Trinh, Luong, and Le]{trinh2019selfie}
Trieu~H Trinh, Minh-Thang Luong, and Quoc~V Le.
\newblock Selfie: Self-supervised pretraining for image embedding.
\newblock \emph{arXiv preprint arXiv:1906.02940}, 2019.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017transformer}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{Advances in neural information processing systems
  (NeurIPS)}, pages 6000--6010, 2017.

\bibitem[Wah et~al.(2011)Wah, Branson, Welinder, Perona, and
  Belongie]{wah2011cub}
Catherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge
  Belongie.
\newblock The caltech-ucsd birds-200-2011 dataset.
\newblock 2011.

\bibitem[Xie et~al.(2019)Xie, Zhang, Zhou, Bai, Wang, Ren, and
  Yuille]{xie2019improving}
Cihang Xie, Zhishuai Zhang, Yuyin Zhou, Song Bai, Jianyu Wang, Zhou Ren, and
  Alan~L Yuille.
\newblock Improving transferability of adversarial examples with input
  diversity.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 2730--2739, 2019.

\bibitem[Yan et~al.(2020)Yan, Misra, Gupta, Ghadiyaram, and
  Mahajan]{yan2020clusterfit}
Xueting Yan, Ishan Misra, Abhinav Gupta, Deepti Ghadiyaram, and Dhruv Mahajan.
\newblock Clusterfit: Improving generalization of visual representations.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 6509--6518, 2020.

\bibitem[Yang and Liu(2022)]{yang2022robust}
Zonghan Yang and Yang Liu.
\newblock On robust prefix-tuning for text classification.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2022.

\bibitem[Yosinski et~al.(2014)Yosinski, Clune, Bengio, and
  Lipson]{yosinski2014transferable}
Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson.
\newblock How transferable are features in deep neural networks?
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pages 3320--3328, 2014.

\bibitem[Yun et~al.(2019)Yun, Han, Oh, Chun, Choe, and Yoo]{yun2019cutmix}
Sangdoo Yun, Dongyoon Han, Seong~Joon Oh, Sanghyuk Chun, Junsuk Choe, and
  Youngjoon Yoo.
\newblock Cutmix: Regularization strategy to train strong classifiers with
  localizable features.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 6023--6032, 2019.

\bibitem[Zhang et~al.(2021)Zhang, Li, Chen, Song, Gao, He, and
  Xue]{zhang2022beyond}
Qilong Zhang, Xiaodan Li, Yuefeng Chen, Jingkuan Song, Lianli Gao, Yuan He, and
  Hui Xue.
\newblock Beyond imagenet attack: Towards crafting adversarial examples for
  black-box domains.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2021.

\bibitem[Zhang et~al.(2016)Zhang, Isola, and Efros]{2016Colorful}
Richard Zhang, Phillip Isola, and Alexei~A Efros.
\newblock Colorful image colorization.
\newblock In \emph{European Conference on Computer Vision (ECCV)}, pages
  649--666, 2016.

\end{thebibliography}
