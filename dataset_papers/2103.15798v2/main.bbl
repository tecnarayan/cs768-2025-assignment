\begin{thebibliography}{50}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Adhikari(2020)]{adhikari2020}
Badri Adhikari.
\newblock A fully open-source framework for deep learning protein real-valued
  distances.
\newblock \emph{Scientific Reports}, 10\penalty0 (1):\penalty0 13374, 2020.
\newblock \doi{10.1038/s41598-020-70181-0}.
\newblock URL \url{https://doi.org/10.1038/s41598-020-70181-0}.

\bibitem[Ailon et~al.(2020)Ailon, Leibovich, and Nair]{ailon2020butterfly}
Nir Ailon, Omer Leibovich, and Vineet Nair.
\newblock Sparse linear networks with a fixed butterfly structure: Theory and
  practice.
\newblock arXiv, 2020.

\bibitem[{Alizadeh vahid} et~al.(2020){Alizadeh vahid}, Prabhu, Farhadi, and
  Rastegari]{alizadeh2020butterfly}
Keivan {Alizadeh vahid}, Anish Prabhu, Ali Farhadi, and Mohammad Rastegari.
\newblock Butterfly transform: An efficient {FFT} based neural architecture
  design.
\newblock In \emph{Proceedings of the IEEE Conference on Conference on Computer
  Vision and Pattern Recognition}, 2020.

\bibitem[Allan and Williams(2005)]{allan2005chorales}
Moray Allan and Christopher Williams.
\newblock Harmonising chorales by probabilistic inference.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2005.

\bibitem[Bai et~al.(2018)Bai, Kolter, and Koltun]{bai2018tcn}
Shaojie Bai, J.~Zico Kolter, and Vladlen Koltun.
\newblock An empirical evaluation of generic convolutional and recurrent
  networks for sequence modeling.
\newblock arXiv, 2018.

\bibitem[Bai et~al.(2019)Bai, Kolter, and Koltun]{bai2019trellis}
Shaojie Bai, J.~Zico Kolter, and Vladlen Koltun.
\newblock Trellis networks for sequence modeling.
\newblock In \emph{Proceedings of the 7th International Conference on Learning
  Representations}, 2019.

\bibitem[Bergstra and Bengio(2012)]{bergstra2012rs}
James Bergstra and Yoshua Bengio.
\newblock Random search for hyper-parameter optimization.
\newblock \emph{Journal of Machine Learning Research}, 13:\penalty0 281--305,
  2012.

\bibitem[Cai et~al.(2020)Cai, Gan, Wang, Zhang, and Han]{cai2020ofa}
Han Cai, Chuang Gan, Tianzhe Wang, Zhekai Zhang, and Song Han.
\newblock Once-for-all: Train one network and specialize it for efficient
  deployment.
\newblock In \emph{Proceedings of the 8th International Conference on Learning
  Representations}, 2020.

\bibitem[Dao et~al.(2019)Dao, Gu, Eichhorn, Rudra, and
  R\'{e}]{dao2019butterfly}
Tri Dao, Albert Gu, Matthew Eichhorn, Atri Rudra, and Christopher R\'{e}.
\newblock Learning fast algorithms for linear transforms using butterfly
  factorizations.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning}, 2019.

\bibitem[Dao et~al.(2020)Dao, Sohoni, Gu, Eichhorn, Blonder, Leszczynski,
  Rudra, and R\'{e}]{dao2020kaleidoscope}
Tri Dao, Nimit Sohoni, Albert Gu, Matthew Eichhorn, Amit Blonder, Megan
  Leszczynski, Atri Rudra, and Christopher R\'{e}.
\newblock Kaleidoscope: An efficient, learnable representation for all
  structured linear maps.
\newblock In \emph{Proceedings of the 8th International Conference on Learning
  Representations}, 2020.

\bibitem[Dong and Yang(2020)]{dong2020nasbench201}
Xuanyi Dong and Yi~Yang.
\newblock {NAS-Bench-201}: Extending the scope of reproducible neural
  architecture search.
\newblock In \emph{Proceedings of the 8th International Conference on Learning
  Representations}, 2020.

\bibitem[Elsken et~al.(2019)Elsken, Metzen, and Hutter]{elsken2019nas}
Thomas Elsken, Jan~Hendrik Metzen, and Frank Hutter.
\newblock Neural architecture search: A survey.
\newblock \emph{Journal of Machine Learning Research}, 20\penalty0
  (55):\penalty0 1--21, 2019.

\bibitem[Fang et~al.(2020)Fang, Sun, Zhang, Li, Liu, and
  Wang]{fang2020densenas}
Jiemin Fang, Yuzhu Sun, Qian Zhang, Yuan Li, Wenyu Liu, and Xinggang Wang.
\newblock Densely connected search space for more flexible neural architecture
  search.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2020.

\bibitem[Gu et~al.(2020)Gu, Dao, Ermon, Rudra, and R\'{e}]{gu2020hippo}
Albert Gu, Tri Dao, Stefano Ermon, Atri Rudra, and Christopher R\'{e}.
\newblock {HiPPO}: Recurrent memory with optimal polynomial projections.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2016.

\bibitem[Hochreiter and Schmidhuber(1997)]{hochreiter1997lstm}
Sepp Hochreiter and J\"{u}rgen Schmidhuber.
\newblock Long short-term memory.
\newblock \emph{Neural Computation}, 9:\penalty0 1735--1780, 1997.

\bibitem[Ioffe and Szegedy(2015)]{ioffe2015batchnorm}
Sergey Ioffe and Christian Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In \emph{Proceedings of the 32nd International Conference on Machine
  Learning}, 2015.

\bibitem[Jones et~al.(2011)Jones, Buchan, Cozzetto, and Pontil]{psicov}
David~T. Jones, Daniel W.~A. Buchan, Domenico Cozzetto, and Massimiliano
  Pontil.
\newblock {PSICOV: precise structural contact prediction using sparse inverse
  covariance estimation on large multiple sequence alignments}.
\newblock \emph{Bioinformatics}, 28\penalty0 (2):\penalty0 184--190, 11 2011.
\newblock ISSN 1367-4803.
\newblock \doi{10.1093/bioinformatics/btr638}.
\newblock URL \url{https://doi.org/10.1093/bioinformatics/btr638}.

\bibitem[Jumper et~al.(2021)Jumper, Evans, Pritzel, Green, Figurnov,
  Ronneberger, Tunyasuvunakool, Bates, {\v Z}{\'\i}dek, Potapenko, Bridgland,
  Meyer, Kohl, Ballard, Cowie, Romera-Paredes, Nikolov, Jain, Adler, Back,
  Petersen, Reiman, Clancy, Zielinski, Steinegger, Pacholska, Berghammer,
  Bodenstein, Silver, Vinyals, Senior, Kavukcuoglu, Kohli, and
  Hassabis]{alphafold2}
John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov,
  Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin {\v
  Z}{\'\i}dek, Anna Potapenko, Alex Bridgland, Clemens Meyer, Simon A.~A. Kohl,
  Andrew~J. Ballard, Andrew Cowie, Bernardino Romera-Paredes, Stanislav
  Nikolov, Rishub Jain, Jonas Adler, Trevor Back, Stig Petersen, David Reiman,
  Ellen Clancy, Michal Zielinski, Martin Steinegger, Michalina Pacholska, Tamas
  Berghammer, Sebastian Bodenstein, David Silver, Oriol Vinyals, Andrew~W.
  Senior, Koray Kavukcuoglu, Pushmeet Kohli, and Demis Hassabis.
\newblock Highly accurate protein structure prediction with alphafold.
\newblock \emph{Nature}, 596\penalty0 (7873):\penalty0 583--589, 2021.
\newblock \doi{10.1038/s41586-021-03819-2}.
\newblock URL \url{https://doi.org/10.1038/s41586-021-03819-2}.

\bibitem[Kingma and Ba(2015)]{kingma2015adam}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{Proceedings of the 3rd International Conference on Learning
  Representations}, 2015.

\bibitem[Kipf and Welling(2017)]{kipf2017gcn}
Thomas~N. Kipf and Max Welling.
\newblock Semi-supervised classification with graph convolutional networks.
\newblock In \emph{Proceedings of the 5th International Conference on Learning
  Representations}, 2017.

\bibitem[Krizhevksy(2009)]{krizhevsky2009cifar}
Alex Krizhevksy.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, 2009.

\bibitem[LeCun et~al.(1999)LeCun, Haffner, Bottou, and Bengio]{lecun1999lenet}
Yann LeCun, Patrick Haffner, L\'{e}on Bottou, and Yoshua Bengio.
\newblock Object recognition with gradient-based learning.
\newblock In \emph{Shape, Contour and Grouping in Computer Vision}. 1999.

\bibitem[Li and Talwalkar(2019)]{li2019rsws}
Liam Li and Ameet Talwalkar.
\newblock Random search and reproducibility for neural architecture search.
\newblock In \emph{Proceedings of the Conference on Uncertainty in Artificial
  Intelligence}, 2019.

\bibitem[Li et~al.(2018{\natexlab{a}})Li, Jamieson, DeSalvo, Rostamizadeh, and
  Talwalkar]{li2018hyperband}
Liam Li, Kevin Jamieson, Giulia DeSalvo, Afshin Rostamizadeh, and Ameet
  Talwalkar.
\newblock Hyperband: A novel bandit-based approach to hyperparameter
  optimization.
\newblock \emph{Journal of Machine Learning Research}, 18\penalty0
  (185):\penalty0 1--52, 2018{\natexlab{a}}.

\bibitem[Li et~al.(2021{\natexlab{a}})Li, Khodak, Balcan, and
  Talwalkar]{li2021gaea}
Liam Li, Mikhail Khodak, Maria-Florina Balcan, and Ameet Talwalkar.
\newblock Geometry-aware gradient algorithms for neural architecture search.
\newblock In \emph{Proceedings of the 9th International Conference on Learning
  Representations}, 2021{\natexlab{a}}.
\newblock To Appear.

\bibitem[Li et~al.(2018{\natexlab{b}})Li, Yu, Shahabi, and Liu]{li2018dcrnn}
Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu.
\newblock Diffusion convolutional recurrent neural network: Data-driven traffic
  forecasting.
\newblock In \emph{Proceedings of the 6th International Conference on Learning
  Representations}, 2018{\natexlab{b}}.

\bibitem[Li et~al.(2015)Li, Yang, Martin, Ho, and Ying]{li2015butterfly}
Yingzhou Li, Haizhao Yang, Eileen~R. Martin, Kenneth~L. Ho, and Lexing Ying.
\newblock Butterfly factorization.
\newblock \emph{Multiscale Modeling \& Simulation}, 13\penalty0 (2):\penalty0
  714--732, 2015.

\bibitem[Li et~al.(2018{\natexlab{c}})Li, Yang, and
  Ying]{li2018multidimensional}
Yingzhou Li, Haizhao Yang, and Lexing Ying.
\newblock Multidimensional butterfly factorization.
\newblock \emph{Applied and Computational Harmonic Analysis}, 44\penalty0
  (3):\penalty0 737--758, 2018{\natexlab{c}}.

\bibitem[Li et~al.(2021{\natexlab{b}})Li, Kovachki, Azizzadenesheli, Liu,
  Bhattacharya, Stuart, and Anandkumar]{li2021fno}
Zongyi Li, Nikola~Borislavov Kovachki, Kamyar Azizzadenesheli, Burigede Liu,
  Kaushik Bhattacharya, Andrew Stuart, and Anima Anandkumar.
\newblock Fourier neural operator for parametric partial differential
  equations.
\newblock In \emph{Proceedings of the 9th International Conference on Learning
  Representations}, 2021{\natexlab{b}}.
\newblock To Appear.

\bibitem[Liu et~al.(2019{\natexlab{a}})Liu, Chen, Schroff, Adam, Hua, Yuille,
  and Fei-Fei]{liu2019autodl}
Chenxi Liu, Liang-Chieh Chen, Florian Schroff, Hartwig Adam, Wei Hua, Alan
  Yuille, and Li~Fei-Fei.
\newblock Auto-{D}eep{L}ab: Hierarchical neural architecture search for
  semantic image segmentation.
\newblock In \emph{Proceedings of the IEEE Conference on Conference on Computer
  Vision and Pattern Recognition}, 2019{\natexlab{a}}.

\bibitem[Liu et~al.(2019{\natexlab{b}})Liu, Simonyan, and Yang]{liu2019darts}
Hanxiao Liu, Karen Simonyan, and Yiming Yang.
\newblock {DARTS}: Differentiable architecture search.
\newblock In \emph{Proceedings of the 7th International Conference on Learning
  Representations}, 2019{\natexlab{b}}.

\bibitem[Mei et~al.(2020)Mei, Li, Lian, Jin, Yang, Yuille, and
  Yang]{mei2020atomnas}
Jieru Mei, Yingwei Li, Xiaochen Lian, Xiaojie Jin, Linjie Yang, Alan Yuille,
  and Jianchao Yang.
\newblock Atom{NAS}: Fine-grained end-to-end neural architecture search.
\newblock In \emph{Proceedings of the 8th International Conference on Learning
  Representations}, 2020.

\bibitem[Moczulski et~al.(2015)Moczulski, Denil, Appleyard, and
  de~Freitas]{moczulski2015acdc}
Marcin Moczulski, Misha Denil, Jeremy Appleyard, and Nando de~Freitas.
\newblock {ACDC}: A structured efficient linear layer.
\newblock arXiv, 2015.

\bibitem[Nekrasov et~al.(2019)Nekrasov, Chen, Shen, and Reid]{nekrasov2019nas}
Vladimir Nekrasov, Hao Chen, Chunhua Shen, and Ian Reid.
\newblock Fast neural architecture search of compact semantic segmentation
  models via auxiliary cells.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2019.

\bibitem[Pham et~al.(2018)Pham, Guan, Zoph, Le, and Dean]{pham2018enas}
Hieu Pham, Melody~Y. Guan, Barret Zoph, Quoc~V. Le, and Jeff Dean.
\newblock Efficient neural architecture search via parameter sharing.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning}, 2018.

\bibitem[Real et~al.(2020)Real, Liang, So, and Le]{real2020automlzero}
Esteban Real, Chen Liang, David~R. So, and Quoc~V. Le.
\newblock Auto{ML}-{Z}ero: Evolving machine learning algorithms from scratch.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, 2020.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and
  Brox]{ronneberger2015unet}
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
\newblock U-{N}et: Convolutional networks for biomedical image segmentation.
\newblock In \emph{Medical Image Computing and Computer-Assisted Intervention},
  2015.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, Berg, and
  Fei-Fei]{russakovsky2015imagenet}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein,
  Alexander~C. Berg, and Li~Fei-Fei.
\newblock {ImageNet} large scale visual recognition challenge.
\newblock \emph{International Journal of Computer Vision}, 115\penalty0
  (3):\penalty0 211--252, 2015.

\bibitem[Senior et~al.(2020)Senior, Evans, Jumper, Kirkpatrick, Sifre, Green,
  Qin, {\v Z}{\'\i}dek, Nelson, Bridgland, Penedones, Petersen, Simonyan,
  Crossan, Kohli, Jones, Silver, Kavukcuoglu, and Hassabis]{alphafold}
Andrew~W. Senior, Richard Evans, John Jumper, James Kirkpatrick, Laurent Sifre,
  Tim Green, Chongli Qin, Augustin {\v Z}{\'\i}dek, Alexander W.~R. Nelson,
  Alex Bridgland, Hugo Penedones, Stig Petersen, Karen Simonyan, Steve Crossan,
  Pushmeet Kohli, David~T. Jones, David Silver, Koray Kavukcuoglu, and Demis
  Hassabis.
\newblock Improved protein structure prediction using potentials from deep
  learning.
\newblock \emph{Nature}, 577\penalty0 (7792):\penalty0 706--710, 2020.
\newblock \doi{10.1038/s41586-019-1923-7}.
\newblock URL \url{https://doi.org/10.1038/s41586-019-1923-7}.

\bibitem[Sirignano and Spiliopoulos(2018)]{sirignano2018dgm}
Justin Sirignano and Konstantinos Spiliopoulos.
\newblock {DGM}: A deep learning algorithm for solving partial differential
  equations.
\newblock \emph{Journal of Computational Physics}, 375:\penalty0 1339--1364,
  2018.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N. Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Wang et~al.(2020{\natexlab{a}})Wang, Yang, Chen, Bai, Zhang, Su, Kou,
  Tong, Yang, and Zhou]{wang2020textnas}
Yujing Wang, Yaming Yang, Yiren Chen, Jing Bai, Ce~Zhang, Guinan Su, Xiaoyu
  Kou, Yunhai Tong, Mao Yang, and Lidong Zhou.
\newblock Textnas: A neural architecture search space tailored for text
  representation.
\newblock In \emph{Proceedings of the 34th AAAI Conference on Artificial
  Intelligence}, 2020{\natexlab{a}}.

\bibitem[Wang et~al.(2020{\natexlab{b}})Wang, Ma, Liu, and
  Tang]{wang2020rtransformer}
Zhiwei Wang, Yao Ma, Zitao Liu, and Jiliang Tang.
\newblock {R-T}ransformer: Recurrent neural network enhanced transformer.
\newblock In \emph{Proceedings of the 8th International Conference on Learning
  Representations}, 2020{\natexlab{b}}.

\bibitem[Xu et~al.(2020)Xu, Xie, Zhang, Chen, Qi, Tian, and
  Xiong]{xu2020pcdarts}
Yuhui Xu, Lingxi Xie, Xiaopeng Zhang, Xin Chen, Guo-Jun Qi, Qi~Tian, and
  Hongkai Xiong.
\newblock {PC-DARTS}: Partial channel connections for memory-efficient
  architecture search.
\newblock In \emph{Proceedings of the 8th International Conference on Learning
  Representations}, 2020.

\bibitem[Yang et~al.(2020)Yang, Esperan\c{c}a, and Carlucci]{yang2020nas}
Antoine Yang, Pedro~M. Esperan\c{c}a, and Fabio~M. Carlucci.
\newblock {NAS} evaluation is frustratingly hard.
\newblock In \emph{Proceedings of the 8th International Conference on Learning
  Representations}, 2020.

\bibitem[Ying et~al.(2019)Ying, Klein, Christiansen, Real, Murphy, and
  Hutter]{ying2019nasbench101}
Chris Ying, Aaron Klein, Eric Christiansen, Esteban Real, Kevin Murphy, and
  Frank Hutter.
\newblock {NAS-Bench-101}: Towards reproducible neural architecture search.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning}, 2019.

\bibitem[Zagoruyko and Komodakis(2016)]{zagoruyko2016wideresnet}
Sergey Zagoruyko and Nikos Komodakis.
\newblock Wide residual networks.
\newblock In \emph{Proceedings of the British Machine Vision Conference}, 2016.

\bibitem[Zela et~al.(2020)Zela, Siems, and Hutter]{zela2020nasbench1shot1}
Arber Zela, Julien Siems, and Frank Hutter.
\newblock {NAS-Bench-1Shot1}: Benchmarking and dissecting one-shot neural
  architecture search.
\newblock In \emph{Proceedings of the 8th International Conference on Learning
  Representations}, 2020.

\bibitem[Zoph et~al.(2018)Zoph, Vasudevan, Shlens, and Le]{zoph2018nas}
Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc~V. Le.
\newblock Learning transferable architectures for scalable image recognition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2018.

\end{thebibliography}
