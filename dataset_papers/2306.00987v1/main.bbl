\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{abdal2021styleflow}
Rameen Abdal, Peihao Zhu, Niloy~J Mitra, and Peter Wonka.
\newblock Styleflow: Attribute-conditioned exploration of stylegan-generated
  images using conditional continuous normalizing flows.
\newblock {\em ACM Transactions on Graphics (ToG)}, 40(3):1--21, 2021.

\bibitem{alaluf2022hyperstyle}
Yuval Alaluf, Omer Tov, Ron Mokady, Rinon Gal, and Amit Bermano.
\newblock Hyperstyle: {Stylegan} inversion with hypernetworks for real image
  editing.
\newblock In {\em CVPR}, pages 18511--18521, 2022.

\bibitem{bao2022generative}
Zhipeng Bao, Martial Hebert, and Yu-Xiong Wang.
\newblock Generative modeling for multi-task visual learning.
\newblock In {\em International Conference on Machine Learning}, pages
  1537--1554. PMLR, 2022.

\bibitem{bar2022visual}
Amir Bar, Yossi Gandelsman, Trevor Darrell, Amir Globerson, and Alexei Efros.
\newblock Visual prompting via image inpainting.
\newblock {\em Advances in Neural Information Processing Systems},
  35:25005--25017, 2022.

\bibitem{barrow1978recovering}
H Barrow and J Tenenbaum.
\newblock Recovering intrinsic scene characteristics.
\newblock {\em Comput. vis. syst}, 2(3-26):2, 1978.

\bibitem{bau2020understanding}
David Bau, Jun-Yan Zhu, Hendrik Strobelt, Agata Lapedriza, Bolei Zhou, and
  Antonio Torralba.
\newblock Understanding the role of individual units in a deep neural network.
\newblock {\em Proceedings of the National Academy of Sciences},
  117(48):30071--30078, 2020.

\bibitem{bau2018gan}
David Bau, Jun-Yan Zhu, Hendrik Strobelt, Bolei Zhou, Joshua~B Tenenbaum,
  William~T Freeman, and Antonio Torralba.
\newblock Gan dissection: Visualizing and understanding generative adversarial
  networks.
\newblock {\em arXiv preprint arXiv:1811.10597}, 2018.

\bibitem{bell2014intrinsic}
Sean Bell, Kavita Bala, and Noah Snavely.
\newblock Intrinsic images in the wild.
\newblock {\em ACM Transactions on Graphics}, 2014.

\bibitem{bhat2023zoedepth}
Shariq~Farooq Bhat, Reiner Birkl, Diana Wofk, Peter Wonka, and Matthias
  M{\"u}ller.
\newblock Zoedepth: Zero-shot transfer by combining relative and metric depth.
\newblock {\em arXiv preprint arXiv:2302.12288}, 2023.

\bibitem{bhattad2023StylitGAN}
Anand Bhattad and D.A. Forsyth.
\newblock Stylitgan: Prompting stylegan to generate new illumination
  conditions.
\newblock In {\em arXiv}, 2023.

\bibitem{bhattad2023make}
Anand Bhattad, Viraj Shah, Derek Hoiem, and DA Forsyth.
\newblock Make it so: Steering stylegan for any image inversion and editing.
\newblock {\em arXiv preprint arXiv:2304.14403}, 2023.

\bibitem{chang2022maskgit}
Huiwen Chang, Han Zhang, Lu Jiang, Ce Liu, and William~T. Freeman.
\newblock Maskgit: Masked generative image transformer.
\newblock In {\em The IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2022.

\bibitem{chong2021jojogan}
Min~Jin Chong and David Forsyth.
\newblock Jojogan: One shot face stylization.
\newblock {\em arXiv preprint arXiv:2112.11641}, 2021.

\bibitem{chong2021stylegan}
Min~Jin Chong, Hsin-Ying Lee, and David Forsyth.
\newblock Stylegan of all trades: Image manipulation with only pretrained
  stylegan.
\newblock {\em arXiv preprint arXiv:2111.01619}, 2021.

\bibitem{dhariwal2021diffusion}
Prafulla Dhariwal and Alexander Nichol.
\newblock Diffusion models beat gans on image synthesis.
\newblock {\em Advances in Neural Information Processing Systems},
  34:8780--8794, 2021.

\bibitem{eftekhar2021omnidata}
Ainaz Eftekhar, Alexander Sax, Jitendra Malik, and Amir Zamir.
\newblock Omnidata: A scalable pipeline for making multi-task mid-level vision
  datasets from 3d scans.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, 2021.

\bibitem{EVA02}
Yuxin Fang, Quan Sun, Xinggang Wang, Tiejun Huang, Xinlong Wang, and Yue Cao.
\newblock Eva-02: A visual representation for neon genesis.
\newblock {\em arXiv preprint arXiv:2303.11331}, 2023.

\bibitem{fang2023eva}
Yuxin Fang, Wen Wang, Binhui Xie, Quan Sun, Ledell Wu, Xinggang Wang, Tiejun
  Huang, Xinlong Wang, and Yue Cao.
\newblock Eva: Exploring the limits of masked visual representation learning at
  scale.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, 2023.

\bibitem{forsyth2020intrinsic}
David Forsyth and Jason~J Rock.
\newblock Intrinsic image decomposition using paradigms.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  44(11):7624--7637, 2021.

\bibitem{goodfellow2014generative}
Ian~J Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial networks.
\newblock {\em arXiv preprint arXiv:1406.2661}, 2014.

\bibitem{huang2017arbitrary}
Xun Huang and Serge Belongie.
\newblock Arbitrary style transfer in real-time with adaptive instance
  normalization.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision}, 2017.

\bibitem{issenhuth2021edibert}
Thibaut Issenhuth, Ugo Tanielian, J{\'e}r{\'e}mie Mary, and David Picard.
\newblock Edibert, a generative model for image editing.
\newblock {\em arXiv preprint arXiv:2111.15264}, 2021.

\bibitem{jahanian2021generative}
Ali Jahanian, Xavier Puig, Yonglong Tian, and Phillip Isola.
\newblock Generative models as a data source for multiview representation
  learning.
\newblock {\em arXiv preprint arXiv:2106.05258}, 2021.

\bibitem{janner2017self}
Michael Janner, Jiajun Wu, Tejas~D Kulkarni, Ilker Yildirim, and Josh
  Tenenbaum.
\newblock Self-supervised intrinsic image decomposition.
\newblock In {\em Advances in Neural Information Processing Systems}, 2017.

\bibitem{kafri2021stylefusion}
Omer Kafri, Or Patashnik, Yuval Alaluf, and Daniel Cohen-Or.
\newblock Stylefusion: A generative model for disentangling spatial segments.
\newblock {\em arXiv preprint arXiv:2107.07437}, 2021.

\bibitem{kang2023scaling}
Minguk Kang, Jun-Yan Zhu, Richard Zhang, Jaesik Park, Eli Shechtman, Sylvain
  Paris, and Taesung Park.
\newblock Scaling up gans for text-to-image synthesis.
\newblock {\em arXiv preprint arXiv:2303.05511}, 2023.

\bibitem{kar20223d}
O{\u{g}}uzhan~Fatih Kar, Teresa Yeo, Andrei Atanov, and Amir Zamir.
\newblock 3d common corruptions and data augmentation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 18963--18974, 2022.

\bibitem{karras2021alias}
Tero Karras, Miika Aittala, Samuli Laine, Erik H{\"a}rk{\"o}nen, Janne
  Hellsten, Jaakko Lehtinen, and Timo Aila.
\newblock Alias-free generative adversarial networks.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{karras2019style}
Tero Karras, Samuli Laine, and Timo Aila.
\newblock A style-based generator architecture for generative adversarial
  networks.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, 2019.

\bibitem{karras2020analyzing}
Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and
  Timo Aila.
\newblock Analyzing and improving the image quality of stylegan.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, 2020.

\bibitem{kawar2023imagic}
Bahjat Kawar, Shiran Zada, Oran Lang, Omer Tov, Huiwen Chang, Tali Dekel, Inbar
  Mosseri, and Michal Irani.
\newblock Imagic: Text-based real image editing with diffusion models.
\newblock In {\em Conference on Computer Vision and Pattern Recognition 2023},
  2023.

\bibitem{kingma2019introduction}
Diederik~P Kingma, Max Welling, et~al.
\newblock An introduction to variational autoencoders.
\newblock {\em Foundations and Trends{\textregistered} in Machine Learning},
  12(4):307--392, 2019.

\bibitem{li2021semantic}
Daiqing Li, Junlin Yang, Karsten Kreis, Antonio Torralba, and Sanja Fidler.
\newblock Semantic segmentation with generative models: Semi-supervised
  learning and strong out-of-domain generalization.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 8300--8311, 2021.

\bibitem{ling2021editgan}
Huan Ling, Karsten Kreis, Daiqing Li, Seung~Wook Kim, Antonio Torralba, and
  Sanja Fidler.
\newblock Editgan: High-precision semantic image editing.
\newblock {\em Advances in Neural Information Processing Systems},
  34:16331--16345, 2021.

\bibitem{liu2020unsupervised}
Yunfei Liu, Yu Li, Shaodi You, and Feng Lu.
\newblock Unsupervised learning for intrinsic image decomposition from a single
  image.
\newblock 2020.

\bibitem{mou2023t2i}
Chong Mou, Xintao Wang, Liangbin Xie, Jian Zhang, Zhongang Qi, Ying Shan, and
  Xiaohu Qie.
\newblock T2i-adapter: Learning adapters to dig out more controllable ability
  for text-to-image diffusion models.
\newblock {\em arXiv preprint arXiv:2302.08453}, 2023.

\bibitem{RGBDGAN}
Atsuhiro Noguchi and Tatsuya Harada.
\newblock Rgbd-gan: Unsupervised 3d representation learning from natural image
  datasets via rgbd image synthesis.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{pan20202d}
Xingang Pan, Bo Dai, Ziwei Liu, Chen~Change Loy, and Ping Luo.
\newblock Do 2d gans know 3d shape? unsupervised 3d shape reconstruction from
  2d image gans.
\newblock {\em arXiv preprint arXiv:2011.00844}, 2020.

\bibitem{pan2022gan2x}
Xingang Pan, Ayush Tewari, Lingjie Liu, and Christian Theobalt.
\newblock Gan2x: Non-lambertian inverse rendering of image gans.
\newblock {\em arXiv preprint arXiv:2206.09244}, 2022.

\bibitem{pan2021shadegan}
Xingang Pan, Xudong Xu, Chen~Change Loy, Christian Theobalt, and Bo Dai.
\newblock A shading-guided generative implicit model for shape-accurate
  3d-aware image synthesis.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)},
  2021.

\bibitem{ranftl2021vision}
Ren{\'e} Ranftl, Alexey Bochkovskiy, and Vladlen Koltun.
\newblock Vision transformers for dense prediction.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, 2021.

\bibitem{razavi2019generating}
Ali Razavi, Aaron Van~den Oord, and Oriol Vinyals.
\newblock Generating diverse high-fidelity images with vq-vae-2.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{richardson2021encoding}
Elad Richardson, Yuval Alaluf, Or Patashnik, Yotam Nitzan, Yaniv Azar, Stav
  Shapiro, and Daniel Cohen-Or.
\newblock Encoding in style: a stylegan encoder for image-to-image translation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 2287--2296, 2021.

\bibitem{roich2021pivotal}
Daniel Roich, Ron Mokady, Amit~H Bermano, and Daniel Cohen-Or.
\newblock Pivotal tuning for latent-based editing of real images.
\newblock {\em arXiv preprint arXiv:2106.05744}, 2021.

\bibitem{rombach2022high}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn
  Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10684--10695, 2022.

\bibitem{salimans2016improved}
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and
  Xi Chen.
\newblock Improved techniques for training gans.
\newblock {\em Advances in neural information processing systems}, 29, 2016.

\bibitem{sariyildiz2023fake}
Mert~Bulent Sariyildiz, Karteek Alahari, Diane Larlus, and Yannis Kalantidis.
\newblock Fake it till you make it: Learning transferable representations from
  synthetic imagenet clones.
\newblock In {\em CVPR 2023--IEEE/CVF Conference on Computer Vision and Pattern
  Recognition}, 2023.

\bibitem{shen2020interfacegan}
Yujun Shen, Ceyuan Yang, Xiaoou Tang, and Bolei Zhou.
\newblock Interfacegan: Interpreting the disentangled face representation
  learned by gans.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  2020.

\bibitem{shen2021closed}
Yujun Shen and Bolei Zhou.
\newblock Closed-form factorization of latent semantics in gans.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 1532--1540, 2021.

\bibitem{shi20223daware}
Zifan Shi, Yujun Shen, Jiapeng Zhu, Dit-Yan Yeung, and Qifeng Chen.
\newblock 3d-aware indoor scene synthesis with depth priors.
\newblock 2022.

\bibitem{shoshan2021gan}
Alon Shoshan, Nadav Bhonker, Igor Kviatkovsky, and Gerard Medioni.
\newblock Gan-control: Explicitly controllable gans.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 14083--14093, 2021.

\bibitem{tan2022volux}
Feitong Tan, Sean Fanello, Abhimitra Meka, Sergio Orts-Escolano, Danhang Tang,
  Rohit Pandey, Jonathan Taylor, Ping Tan, and Yinda Zhang.
\newblock Volux-gan: A generative model for 3d face synthesis with hdri
  relighting.
\newblock {\em arXiv preprint arXiv:2201.04873}, 2022.

\bibitem{tzelepis2021warpedganspace}
Christos Tzelepis, Georgios Tzimiropoulos, and Ioannis Patras.
\newblock Warpedganspace: Finding non-linear rbf paths in gan latent space.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 6393--6402, 2021.

\bibitem{van2017neural}
Aaron Van Den~Oord, Oriol Vinyals, et~al.
\newblock Neural discrete representation learning.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{voynov2020unsupervised}
Andrey Voynov and Artem Babenko.
\newblock Unsupervised discovery of interpretable directions in the gan latent
  space.
\newblock In {\em International conference on machine learning}, pages
  9786--9796. PMLR, 2020.

\bibitem{wang2021TengFei}
Tengfei Wang, Yong Zhang, Yanbo Fan, Jue Wang, and Qifeng Chen.
\newblock High-fidelity {GAN} inversion for image attribute editing.
\newblock In {\em CVPR}, 2022.

\bibitem{wu2021stylespace}
Zongze Wu, Dani Lischinski, and Eli Shechtman.
\newblock Stylespace analysis: Disentangled controls for stylegan image
  generation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 12863--12872, 2021.

\bibitem{xu2023odise}
Jiarui Xu, Sifei Liu, Arash Vahdat, Wonmin Byeon, Xiaolong Wang, and Shalini
  De~Mello.
\newblock {Open-Vocabulary Panoptic Segmentation with Text-to-Image Diffusion
  Models}.
\newblock {\em arXiv preprint arXiv:2303.04803}, 2023.

\bibitem{yang2019semantic}
Ceyuan Yang, Yujun Shen, and Bolei Zhou.
\newblock Semantic hierarchy emerges in deep generative representations for
  scene synthesis.
\newblock {\em International Journal of Computer Vision}, 2020.

\bibitem{yang2021discovering}
Huiting Yang, Liangyu Chai, Qiang Wen, Shuang Zhao, Zixun Sun, and Shengfeng
  He.
\newblock Discovering interpretable latent space directions of gans beyond
  binary attributes.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 12177--12185, 2021.

\bibitem{yu2021dual}
Ning Yu, Guilin Liu, Aysegul Dundar, Andrew Tao, Bryan Catanzaro, Larry~S
  Davis, and Mario Fritz.
\newblock Dual contrastive loss and attention for gans.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 6731--6742, 2021.

\bibitem{yu2019inverserendernet}
Ye Yu and William~AP Smith.
\newblock Inverserendernet: Learning single image inverse rendering.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2019.

\bibitem{zamir2020robust}
Amir~R Zamir, Alexander Sax, Nikhil Cheerla, Rohan Suri, Zhangjie Cao, Jitendra
  Malik, and Leonidas~J Guibas.
\newblock Robust learning through cross-task consistency.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, 2020.

\bibitem{zhang2023adding}
Lvmin Zhang and Maneesh Agrawala.
\newblock Adding conditional control to text-to-image diffusion models, 2023.

\bibitem{zhang2020image}
Yuxuan Zhang, Wenzheng Chen, Huan Ling, Jun Gao, Yinan Zhang, Antonio Torralba,
  and Sanja Fidler.
\newblock Image gans meet differentiable rendering for inverse graphics and
  interpretable 3d neural rendering.
\newblock {\em arXiv preprint arXiv:2010.09125}, 2020.

\bibitem{zhang2021datasetgan}
Yuxuan Zhang, Huan Ling, Jun Gao, Kangxue Yin, Jean-Francois Lafleche, Adela
  Barriuso, Antonio Torralba, and Sanja Fidler.
\newblock Datasetgan: Efficient labeled data factory with minimal human effort.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10145--10155, 2021.

\bibitem{zhao2023unleashing}
Wenliang Zhao, Yongming Rao, Zuyan Liu, Benlin Liu, Jie Zhou, and Jiwen Lu.
\newblock Unleashing text-to-image diffusion models for visual perception.
\newblock {\em arXiv preprint arXiv:2303.02153}, 2023.

\bibitem{zhou2016semantic}
Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Barriuso, and Antonio
  Torralba.
\newblock Semantic understanding of scenes through the ade20k dataset.
\newblock {\em arXiv preprint arXiv:1608.05442}, 2016.

\bibitem{zhu2020indomain}
Jiapeng Zhu, Yujun Shen, Deli Zhao, and Bolei Zhou.
\newblock In-domain gan inversion for real image editing.
\newblock In {\em Proceedings of European Conference on Computer Vision
  (ECCV)}, 2020.

\bibitem{zhuang2021enjoy}
Peiye Zhuang, Oluwasanmi Koyejo, and Alexander~G Schwing.
\newblock Enjoy your editing: Controllable gans for image editing via latent
  space navigation.
\newblock {\em arXiv preprint arXiv:2102.01187}, 2021.

\end{thebibliography}
