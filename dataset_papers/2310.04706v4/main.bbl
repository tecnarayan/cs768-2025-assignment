\begin{thebibliography}{40}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2021)Agarwal, Jiang, Kakade, and Sun]{alek2019reinforce}
Alekh Agarwal, Nan Jiang, Sham~M. Kakade, and Wen Sun.
\newblock Reinforcement learning: Theory and algorithms, 2021.

\bibitem[Ahmed et~al.(2020)Ahmed, Tr{\"a}uble, Goyal, Neitz, Bengio, Sch{\"o}lkopf, W{\"u}thrich, and Bauer]{ahmed2020causalworld}
Ossama Ahmed, Frederik Tr{\"a}uble, Anirudh Goyal, Alexander Neitz, Yoshua Bengio, Bernhard Sch{\"o}lkopf, Manuel W{\"u}thrich, and Stefan Bauer.
\newblock Causalworld: A robotic manipulation benchmark for causal structure and transfer learning.
\newblock \emph{arXiv preprint arXiv:2010.04296}, 2020.

\bibitem[Antotsiou et~al.(2021)Antotsiou, Ciliberto, and Kim]{antotsiou2021adversarial}
Dafni Antotsiou, Carlo Ciliberto, and Tae-Kyun Kim.
\newblock Adversarial imitation learning with trajectorial augmentation and correction.
\newblock In \emph{2021 IEEE International Conference on Robotics and Automation (ICRA)}, pages 4724--4730. IEEE, 2021.

\bibitem[Bottou et~al.(2013)Bottou, Peters, Qui{\~n}onero-Candela, Charles, Chickering, Portugaly, Ray, Simard, and Snelson]{bottou2013counterfactual}
L{\'e}on Bottou, Jonas Peters, Joaquin Qui{\~n}onero-Candela, Denis~X Charles, D~Max Chickering, Elon Portugaly, Dipankar Ray, Patrice Simard, and Ed~Snelson.
\newblock Counterfactual reasoning and learning systems: The example of computational advertising.
\newblock \emph{Journal of Machine Learning Research}, 14\penalty0 (11), 2013.

\bibitem[Bratko et~al.(1995)Bratko, Urban{\v{c}}i{\v{c}}, and Sammut]{bratko1995behavioural}
Ivan Bratko, Tanja Urban{\v{c}}i{\v{c}}, and Claude Sammut.
\newblock Behavioural cloning: phenomena, results and problems.
\newblock \emph{IFAC Proceedings Volumes}, 28\penalty0 (21):\penalty0 143--149, 1995.

\bibitem[Buesing et~al.(2018)Buesing, Weber, Zwols, Racaniere, Guez, Lespiau, and Heess]{buesing2018woulda}
Lars Buesing, Theophane Weber, Yori Zwols, Sebastien Racaniere, Arthur Guez, Jean-Baptiste Lespiau, and Nicolas Heess.
\newblock Woulda, coulda, shoulda: Counterfactually-guided policy search.
\newblock \emph{arXiv preprint arXiv:1811.06272}, 2018.

\bibitem[Hoshino et~al.(2021)Hoshino, Hisada, and Oikawa]{hoshino2021imitation}
Satoshi Hoshino, Tomoki Hisada, and Ryota Oikawa.
\newblock Imitation learning based on data augmentation for robotic reaching.
\newblock In \emph{2021 60th Annual Conference of the Society of Instrument and Control Engineers of Japan (SICE)}, pages 417--424. IEEE, 2021.

\bibitem[Kaushik et~al.(2020)Kaushik, Setlur, Hovy, and Lipton]{kaushik2020explaining}
Divyansh Kaushik, Amrith Setlur, Eduard Hovy, and Zachary~C Lipton.
\newblock Explaining the efficacy of counterfactually augmented data.
\newblock \emph{arXiv preprint arXiv:2010.02114}, 2020.

\bibitem[Khemakhem et~al.(2020)Khemakhem, Kingma, Monti, and Hyvarinen]{khemakhem2020variational}
Ilyes Khemakhem, Diederik Kingma, Ricardo Monti, and Aapo Hyvarinen.
\newblock Variational autoencoders and nonlinear ica: A unifying framework.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pages 2207--2217. PMLR, 2020.

\bibitem[Killian et~al.(2022)Killian, Ghassemi, and Joshi]{killian2022counterfactually}
Taylor~W Killian, Marzyeh Ghassemi, and Shalmali Joshi.
\newblock Counterfactually guided policy transfer in clinical settings.
\newblock In \emph{Conference on Health, Inference, and Learning}, pages 5--31. PMLR, 2022.

\bibitem[Kim and Pineau(2016)]{kim2016socially}
Beomjoon Kim and Joelle Pineau.
\newblock Socially adaptive path planning in human environments using inverse reinforcement learning.
\newblock \emph{International Journal of Social Robotics}, 8:\penalty0 51--66, 2016.

\bibitem[Kim et~al.(2022)Kim, Lee, Jang, Yang, and Kim]{kim2022lobsdice}
Geon-Hyeong Kim, Jongmin Lee, Youngsoo Jang, Hongseok Yang, and Kee-Eung Kim.
\newblock Lobsdice: offline imitation learning from observation via stationary distribution correction estimation.
\newblock \emph{arXiv preprint arXiv:2202.13536}, 2022.

\bibitem[Kingma and Welling(2013)]{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Kumar et~al.(2019)Kumar, Fu, Soh, Tucker, and Levine]{kumar2019stabilizing}
Aviral Kumar, Justin Fu, Matthew Soh, George Tucker, and Sergey Levine.
\newblock Stabilizing off-policy q-learning via bootstrapping error reduction.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Lai et~al.(2023)Lai, Liu, Tang, Wang, Hao, and Luo]{lai2023chipformer}
Yao Lai, Jinxin Liu, Zhentao Tang, Bin Wang, Jianye Hao, and Ping Luo.
\newblock Chipformer: Transferable chip placement via offline decision transformer.
\newblock \emph{arXiv preprint arXiv:2306.14744}, 2023.

\bibitem[Liu et~al.(2023{\natexlab{a}})Liu, He, Kang, Zhuang, Wang, and Xu]{liu2023ceil}
Jinxin Liu, Li~He, Yachen Kang, Zifeng Zhuang, Donglin Wang, and Huazhe Xu.
\newblock Ceil: Generalized contextual imitation learning.
\newblock \emph{arXiv preprint arXiv:2306.14534}, 2023{\natexlab{a}}.

\bibitem[Liu et~al.(2023{\natexlab{b}})Liu, Zu, He, and Wang]{liu2023clue}
Jinxin Liu, Lipeng Zu, Li~He, and Donglin Wang.
\newblock Clue: Calibrated latent guidance for offline reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2306.13412}, 2023{\natexlab{b}}.

\bibitem[Locatello et~al.(2019)Locatello, Bauer, Lucic, Raetsch, Gelly, Sch{\"o}lkopf, and Bachem]{locatello2019challenging}
Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly, Bernhard Sch{\"o}lkopf, and Olivier Bachem.
\newblock Challenging common assumptions in the unsupervised learning of disentangled representations.
\newblock In \emph{international conference on machine learning}, pages 4114--4124. PMLR, 2019.

\bibitem[Lu et~al.(2020)Lu, Huang, Wang, Hern{\'a}ndez-Lobato, Zhang, and Sch{\"o}lkopf]{lu2020sample}
Chaochao Lu, Biwei Huang, Ke~Wang, Jos{\'e}~Miguel Hern{\'a}ndez-Lobato, Kun Zhang, and Bernhard Sch{\"o}lkopf.
\newblock Sample-efficient reinforcement learning via counterfactual-based data augmentation.
\newblock \emph{arXiv preprint arXiv:2012.09092}, 2020.

\bibitem[Mesnard et~al.(2020)Mesnard, Weber, Viola, Thakoor, Saade, Harutyunyan, Dabney, Stepleton, Heess, Guez, et~al.]{mesnard2020counterfactual}
Thomas Mesnard, Th{\'e}ophane Weber, Fabio Viola, Shantanu Thakoor, Alaa Saade, Anna Harutyunyan, Will Dabney, Tom Stepleton, Nicolas Heess, Arthur Guez, et~al.
\newblock Counterfactual credit assignment in model-free reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2011.09464}, 2020.

\bibitem[Mita et~al.(2021)Mita, Filippone, and Michiardi]{mita2021identifiable}
Graziano Mita, Maurizio Filippone, and Pietro Michiardi.
\newblock An identifiable double vae for disentangled representations.
\newblock In \emph{International Conference on Machine Learning}, pages 7769--7779. PMLR, 2021.

\bibitem[Oberst and Sontag(2019)]{oberst2019counterfactual}
Michael Oberst and David Sontag.
\newblock Counterfactual off-policy evaluation with gumbel-max structural causal models.
\newblock In \emph{International Conference on Machine Learning}, pages 4881--4890. PMLR, 2019.

\bibitem[Pearl(2000)]{pearl2000models}
Judea Pearl.
\newblock Models, reasoning and inference.
\newblock \emph{Cambridge, UK: CambridgeUniversityPress}, 19\penalty0 (2), 2000.

\bibitem[Pitis et~al.(2022)Pitis, Creager, Mandlekar, and Garg]{pitis2022mocoda}
Silviu Pitis, Elliot Creager, Ajay Mandlekar, and Animesh Garg.
\newblock Mocoda: Model-based counterfactual data augmentation.
\newblock \emph{arXiv preprint arXiv:2210.11287}, 2022.

\bibitem[Ross et~al.(2011)Ross, Gordon, and Bagnell]{ross2011reduction}
St{\'e}phane Ross, Geoffrey Gordon, and Drew Bagnell.
\newblock A reduction of imitation learning and structured prediction to no-regret online learning.
\newblock In \emph{Proceedings of the fourteenth international conference on artificial intelligence and statistics}, pages 627--635. JMLR Workshop and Conference Proceedings, 2011.

\bibitem[Sasaki and Yamashina(2021)]{sasaki2021behavioral}
Fumihiro Sasaki and Ryota Yamashina.
\newblock Behavioral cloning from noisy demonstrations.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Shalev-Shwartz and Ben-David(2014)]{shalev2014understanding}
Shai Shalev-Shwartz and Shai Ben-David.
\newblock \emph{Understanding machine learning: From theory to algorithms}.
\newblock Cambridge university press, 2014.

\bibitem[Sohn et~al.(2015)Sohn, Lee, and Yan]{sohn2015learning}
Kihyuk Sohn, Honglak Lee, and Xinchen Yan.
\newblock Learning structured output representation using deep conditional generative models.
\newblock \emph{Advances in neural information processing systems}, 28, 2015.

\bibitem[Spencer et~al.(2021)Spencer, Choudhury, Venkatraman, Ziebart, and Bagnell]{spencer2021feedback}
Jonathan Spencer, Sanjiban Choudhury, Arun Venkatraman, Brian Ziebart, and J~Andrew Bagnell.
\newblock Feedback in imitation learning: The three regimes of covariate shift.
\newblock \emph{arXiv preprint arXiv:2102.02872}, 2021.

\bibitem[Sun et~al.(2019)Sun, Vemula, Boots, and Bagnell]{sun2019provably}
Wen Sun, Anirudh Vemula, Byron Boots, and Drew Bagnell.
\newblock Provably efficient imitation learning from observation alone.
\newblock In \emph{International conference on machine learning}, pages 6036--6045. PMLR, 2019.

\bibitem[Swamy et~al.(2021)Swamy, Choudhury, Bagnell, and Wu]{swamy2021moments}
Gokul Swamy, Sanjiban Choudhury, J~Andrew Bagnell, and Steven Wu.
\newblock Of moments and matching: A game-theoretic framework for closing the imitation gap.
\newblock In \emph{International Conference on Machine Learning}, pages 10022--10032. PMLR, 2021.

\bibitem[Tassa et~al.(2018)Tassa, Doron, Muldal, Erez, Li, Casas, Budden, Abdolmaleki, Merel, Lefrancq, et~al.]{tassa2018deepmind}
Yuval Tassa, Yotam Doron, Alistair Muldal, Tom Erez, Yazhe Li, Diego de~Las Casas, David Budden, Abbas Abdolmaleki, Josh Merel, Andrew Lefrancq, et~al.
\newblock Deepmind control suite.
\newblock \emph{arXiv preprint arXiv:1801.00690}, 2018.

\bibitem[Wu et~al.(2019)Wu, Tucker, and Nachum]{wu2019behavior}
Yifan Wu, George Tucker, and Ofir Nachum.
\newblock Behavior regularized offline reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1911.11361}, 2019.

\bibitem[Wu et~al.(2020)Wu, Sun, Zhan, Yang, and Tomizuka]{wu2020efficient}
Zheng Wu, Liting Sun, Wei Zhan, Chenyu Yang, and Masayoshi Tomizuka.
\newblock Efficient sampling-based maximum entropy inverse reinforcement learning with application to autonomous driving.
\newblock \emph{IEEE Robotics and Automation Letters}, 5\penalty0 (4):\penalty0 5355--5362, 2020.

\bibitem[Xu and Denil(2021)]{xu2021positive}
Danfei Xu and Misha Denil.
\newblock Positive-unlabeled reward learning.
\newblock In \emph{Conference on Robot Learning}, pages 205--219. PMLR, 2021.

\bibitem[Xu et~al.(2022)Xu, Zhan, Yin, and Qin]{xu2022discriminator}
Haoran Xu, Xianyuan Zhan, Honglei Yin, and Huiling Qin.
\newblock Discriminator-weighted offline imitation learning from suboptimal demonstrations.
\newblock In \emph{International Conference on Machine Learning}, pages 24725--24742. PMLR, 2022.

\bibitem[Zhao et~al.(2022)Zhao, He, Luo, and Liu]{zhao2022collective}
Zhenting Zhao, Bowei He, Wenhao Luo, and Rui Liu.
\newblock Collective conditioned reflex: A bio-inspired fast emergency reaction mechanism for designing safe multi-robot systems.
\newblock \emph{IEEE Robotics and Automation Letters}, 7\penalty0 (4):\penalty0 10985--10990, 2022.

\bibitem[Zhu et~al.(2022)Zhu, Chen, Tian, Zhang, and Yu]{zhu2022offline}
Zheng-Mao Zhu, Xiong-Hui Chen, Hong-Long Tian, Kun Zhang, and Yang Yu.
\newblock Offline reinforcement learning with causal structured world models.
\newblock \emph{arXiv preprint arXiv:2206.01474}, 2022.

\bibitem[Zolna et~al.(2020)Zolna, Novikov, Konyushkova, Gulcehre, Wang, Aytar, Denil, de~Freitas, and Reed]{zolna2020offline}
Konrad Zolna, Alexander Novikov, Ksenia Konyushkova, Caglar Gulcehre, Ziyu Wang, Yusuf Aytar, Misha Denil, Nando de~Freitas, and Scott Reed.
\newblock Offline learning from demonstrations and unlabeled experience.
\newblock \emph{arXiv preprint arXiv:2011.13885}, 2020.

\bibitem[Zolna et~al.(2021)Zolna, Reed, Novikov, Colmenarejo, Budden, Cabi, Denil, de~Freitas, and Wang]{zolna2021task}
Konrad Zolna, Scott Reed, Alexander Novikov, Sergio~Gomez Colmenarejo, David Budden, Serkan Cabi, Misha Denil, Nando de~Freitas, and Ziyu Wang.
\newblock Task-relevant adversarial imitation learning.
\newblock In \emph{Conference on Robot Learning}, pages 247--263. PMLR, 2021.

\end{thebibliography}
