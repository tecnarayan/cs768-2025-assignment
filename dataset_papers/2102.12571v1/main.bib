@inproceedings{abel2019expected,
  title={The expected-length model of options},
  author={Abel, David and Winder, John},
  booktitle={IJCAI},
  year={2019}
}

@article{alpern1987recognizing,
  title={Recognizing safety and liveness},
  author={Alpern, Bowen and Schneider, Fred B},
  journal={Distributed computing},
  volume={2},
  number={3},
  pages={117--126},
  year={1987},
  publisher={Springer}
}

@inproceedings{andreas2017modular,
  title={Modular multitask reinforcement learning with policy sketches},
  author={Andreas, Jacob and Klein, Dan and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={166--175},
  year={2017}
}

@inproceedings{araki2020deep,
  title={Deep Bayesian Nonparametric Learning of Rules and Plans from Demonstrations with a Learned Automaton Prior.},
  author={Araki, Brandon and Vodrahalli, Kiran and Leech, Thomas and Vasile, Cristian Ioan and Donahue, Mark and Rus, Daniela},
  booktitle={AAAI},
  pages={10026--10034},
  year={2020}
}
  
@INPROCEEDINGS{araki2019learning, 
    AUTHOR    = {Brandon Araki AND Kiran Vodrahalli AND Thomas Leech AND Cristian Ioan Vasile AND Mark  Donahue AND Daniela Rus}, 
    TITLE     = {Learning to Plan with Logical Automata}, 
    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, 
    YEAR      = {2019}, 
    ADDRESS   = {FreiburgimBreisgau, Germany}, 
    MONTH     = {June}, 
    DOI       = {10.15607/RSS.2019.XV.064} 
} 

@book{Baier08,
    author    = {C. Baier and J. Katoen},
    title     = {{Principles of model checking}},
    publisher = {MIT Press},
    year      = {2008},
    isbn      = {978-0-262-02649-9}
}

@inproceedings{bhatia2010sampling,
  title={Sampling-based motion planning with temporal goals},
  author={Bhatia, Amit and Kavraki, Lydia E and Vardi, Moshe Y},
  booktitle={2010 IEEE International Conference on Robotics and Automation},
  pages={2689--2696},
  year={2010},
  organization={IEEE}
}

@inproceedings{camacho2019ltl,
  title={LTL and Beyond: Formal Languages for Reward Function Specification in Reinforcement Learning.},
  author={Camacho, Alberto and Icarte, Rodrigo Toro and Klassen, Toryn Q and Valenzano, Richard Anthony and McIlraith, Sheila A},
  booktitle={IJCAI},
  volume={19},
  pages={6065--6073},
  year={2019}
}

@book{Clark01,
title = {Model Checking},
author = {Clarke, Edmund M. and Grumberg, Orna and Peled, Doron},
year = {2001},
publisher = {MIT Press},
isbn = {978-0-262-03270-4}
}

@inproceedings{dayan1993feudal,
  title={Feudal reinforcement learning},
  author={Dayan, Peter and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={271--278},
  year={1993}
}

@article{dietterich2000hierarchical,
  title={Hierarchical reinforcement learning with the MAXQ value function decomposition},
  author={Dietterich, Thomas G},
  journal={Journal of artificial intelligence research},
  volume={13},
  pages={227--303},
  year={2000}
}

@inproceedings{dietterich2000state,
  title={State abstraction in MAXQ hierarchical reinforcement learning},
  author={Dietterich, Thomas G},
  booktitle={Advances in Neural Information Processing Systems},
  pages={994--1000},
  year={2000}
}

@inproceedings{diuk2008object,
  title={An object-oriented representation for efficient reinforcement learning},
  author={Diuk, Carlos and Cohen, Andre and Littman, Michael L},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={240--247},
  year={2008}
}

@inproceedings{Duret16,
  author = {Alexandre Duret-Lutz and Alexandre Lewkowicz and Amaury
      Fauchille and Thibaud Michaud and Etienne Renault and
      Laurent Xu},
  title = {Spot 2.0 --- a framework for {LTL} and $\omega$-automata
      manipulation},
  booktitle = {Proceedings of the 14th International Symposium on
      Automated Technology for Verification and Analysis
      (ATVA'16)},
  series = {Lecture Notes in Computer Science},
  publisher = {Springer},
  volume = {9938},
  pages = {122--129},
  year = {2016},
  month = oct,
  doi = {10.1007/978-3-319-46520-3_8}
}

@article{ecoffet2019go,
  title={Go-explore: a new approach for hard-exploration problems},
  author={Ecoffet, Adrien and Huizinga, Joost and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff},
  journal={arXiv preprint arXiv:1901.10995},
  year={2019}
}

@inproceedings{eysenbach2019search,
  title={Search on the replay buffer: Bridging planning and reinforcement learning},
  author={Eysenbach, Ben and Salakhutdinov, Russ R and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={15220--15231},
  year={2019}
}

@inproceedings{fainekos2005temporal,
  title={Temporal logic motion planning for mobile robots},
  author={Fainekos, Georgios E and Kress-Gazit, Hadas and Pappas, George J},
  booktitle={Proceedings of the 2005 IEEE International Conference on Robotics and Automation},
  pages={2020--2025},
  year={2005},
  organization={IEEE}
}

@inproceedings{faust2018prm,
  title={PRM-RL: Long-range robotic navigation tasks by combining reinforcement learning and sampling-based planning},
  author={Faust, Aleksandra and Oslund, Kenneth and Ramirez, Oscar and Francis, Anthony and Tapia, Lydia and Fiser, Marek and Davidson, James},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={5113--5120},
  year={2018},
  organization={IEEE}
}

@inproceedings{fu2017sampling,
  title={Sampling-based approximate optimal control under temporal logic constraints},
  author={Fu, Jie and Papusha, Ivan and Topcu, Ufuk},
  booktitle={Proceedings of the 20th International Conference on Hybrid Systems: Computation and Control},
  pages={227--235},
  year={2017}
}

@article{fu2014probably,
  title={Probably approximately correct MDP learning and control with temporal logic constraints},
  author={Fu, Jie and Topcu, Ufuk},
  journal={arXiv preprint arXiv:1404.7073},
  year={2014}
}

@article{ghosh2018learning,
  title={Learning actionable representations with goal-conditioned policies},
  author={Ghosh, Dibya and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:1811.07819},
  year={2018}
}

@inproceedings{gopalan2017planning,
  title={Planning with abstract markov decision processes},
  author={Gopalan, Nakul and Littman, Michael L and MacGlashan, James and Squire, Shawn and Tellex, Stefanie and Winder, John and Wong, Lawson LS and others},
  booktitle={Twenty-Seventh International Conference on Automated Planning and Scheduling},
  year={2017}
}

@article{gordon2019should,
  title={What should I do now? marrying reinforcement learning and symbolic planning},
  author={Gordon, Daniel and Fox, Dieter and Farhadi, Ali},
  journal={arXiv preprint arXiv:1901.01492},
  year={2019}
}

@article{hasanbeig2018logically,
  title={Logically-constrained reinforcement learning},
  author={Hasanbeig, Mohammadhosein and Abate, Alessandro and Kroening, Daniel},
  journal={arXiv preprint arXiv:1801.08099},
  year={2018}
}

@inproceedings{icarte2018using,
  title={Using reward machines for high-level task specification and decomposition in reinforcement learning},
  author={Icarte, Rodrigo Toro and Klassen, Toryn and Valenzano, Richard and McIlraith, Sheila},
  booktitle={International Conference on Machine Learning},
  pages={2107--2116},
  year={2018}
}

@inproceedings{icarte2019learning,
  title={Learning reward machines for partially observable reinforcement learning},
  author={Icarte, Rodrigo Toro and Waldie, Ethan and Klassen, Toryn and Valenzano, Rick and Castro, Margarita and McIlraith, Sheila},
  booktitle={Advances in Neural Information Processing Systems},
  pages={15523--15534},
  year={2019}
}

@inproceedings{illanes2020symbolic,
  title={Symbolic Plans as High-Level Instructions for Reinforcement Learning},
  author={Illanes, Le{\'o}n and Yan, Xi and Icarte, Rodrigo Toro and McIlraith, Sheila A},
  booktitle={Proceedings of the International Conference on Automated Planning and Scheduling},
  volume={30},
  pages={540--550},
  year={2020}
}

@article{james2019pyrep,
  title={PyRep: Bringing V-REP to Deep Robot Learning},
  author={James, Stephen and Freese, Marc and Davison, Andrew J.},
  journal={arXiv preprint arXiv:1906.11176},
  year={2019}
}

@inproceedings{jothimurugan2019composable,
  title={A Composable Specification Language for Reinforcement Learning Tasks},
  author={Jothimurugan, Kishor and Alur, Rajeev and Bastani, Osbert},
  booktitle={Advances in Neural Information Processing Systems},
  pages={13041--13051},
  year={2019}
}

@inproceedings{kaelbling2011hierarchical,
  title={Hierarchical task and motion planning in the now},
  author={Kaelbling, Leslie Pack and Lozano-P{\'e}rez, Tom{\'a}s},
  booktitle={2011 IEEE International Conference on Robotics and Automation},
  pages={1470--1477},
  year={2011},
  organization={IEEE}
}

@article{kansou2019converting,
  title={CONVERTING ASubset OF LTL FORMULA TO BUCHI AUTOMATA},
  author={Kansou, Bilal Kansoand Ali},
  journal={International Journal of Software Engineering \& Applications (IJSEA)},
  volume={10},
  number={2},
  year={2019}
}

@article{kress2009temporal,
  title={Temporal-logic-based reactive mission and motion planning},
  author={Kress-Gazit, Hadas and Fainekos, Georgios E and Pappas, George J},
  journal={IEEE transactions on robotics},
  volume={25},
  number={6},
  pages={1370--1381},
  year={2009},
  publisher={IEEE}
}

@article{kuo2020encoding,
  title={Encoding formulas as deep networks: Reinforcement learning for zero-shot execution of LTL formulas},
  author={Kuo, Yen-Ling and Katz, Boris and Barbu, Andrei},
  journal={arXiv preprint arXiv:2006.01110},
  year={2020}
}

@inproceedings{kulkarni2016hierarchical,
  title={Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation},
  author={Kulkarni, Tejas D and Narasimhan, Karthik and Saeedi, Ardavan and Tenenbaum, Josh},
  booktitle={Advances in neural information processing systems},
  pages={3675--3683},
  year={2016}
}

@article{li2019formal,
  title={A formal methods approach to interpretable reinforcement learning for robotic planning},
  author={Li, Xiao and Serlin, Zachary and Yang, Guang and Belta, Calin},
  journal={Science Robotics},
  volume={4},
  number={37},
  year={2019},
  publisher={Science Robotics}
}

@inproceedings{li2017reinforcement,
  title={Reinforcement learning with temporal logic rewards},
  author={Li, Xiao and Vasile, Cristian-Ioan and Belta, Calin},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={3834--3839},
  year={2017},
  organization={IEEE}
}

@inproceedings{li2006towards,
  title={Towards a Unified Theory of State Abstraction for MDPs.},
  author={Li, Lihong and Walsh, Thomas J and Littman, Michael L},
  booktitle={ISAIM},
  year={2006}
}

@article{liu2013synthesis,
  title={Synthesis of reactive switching protocols from temporal logic specifications},
  author={Liu, Jun and Ozay, Necmiye and Topcu, Ufuk and Murray, Richard M},
  journal={IEEE Transactions on Automatic Control},
  volume={58},
  number={7},
  pages={1771--1785},
  year={2013},
  publisher={IEEE}
}

@inproceedings{lyu2019sdrl,
  title={SDRL: interpretable and data-efficient deep reinforcement learning leveraging symbolic planning},
  author={Lyu, Daoming and Yang, Fangkai and Liu, Bo and Gustafson, Steven},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={2970--2977},
  year={2019}
}

@article{marcus2020next,
  title={The next decade in ai: four steps towards robust artificial intelligence},
  author={Marcus, Gary},
  journal={arXiv preprint arXiv:2002.06177},
  year={2020}
}

@inproceedings{mason2017assured,
  title={Assured reinforcement learning with formally verified abstract policies},
  author={Mason, George Rupert and Calinescu, Radu Constantin and Kudenko, Daniel and Banks, Alec},
  booktitle={9th International Conference on Agents and Artificial Intelligence (ICAART)},
  year={2017},
  organization={York}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{oh2019planning,
  title={Planning with state abstractions for non-Markovian task specifications},
  author={Oh, Yoonseon and Patel, Roma and Nguyen, Thao and Huang, Baichuan and Pavlick, Ellie and Tellex, Stefanie},
  journal={arXiv preprint arXiv:1905.12096},
  year={2019}
}

@inproceedings{papusha2016automata,
  title={Automata theory meets approximate dynamic programming: Optimal control with temporal logic constraints},
  author={Papusha, Ivan and Fu, Jie and Topcu, Ufuk and Murray, Richard M},
  booktitle={2016 IEEE 55th Conference on Decision and Control (CDC)},
  pages={434--440},
  year={2016},
  organization={IEEE}
}

@inproceedings{parr1998reinforcement,
  title={Reinforcement learning with hierarchies of machines},
  author={Parr, Ronald and Russell, Stuart J},
  booktitle={Advances in neural information processing systems},
  pages={1043--1049},
  year={1998}
}

@inproceedings{paxton2017combining,
  title={Combining neural networks and tree search for task and motion planning in challenging environments},
  author={Paxton, Chris and Raman, Vasumathi and Hager, Gregory D and Kobilarov, Marin},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={6059--6066},
  year={2017},
  organization={IEEE}
}

@article{plaku2016motion,
  title={Motion planning with temporal-logic specifications: Progress and challenges},
  author={Plaku, Erion and Karaman, Sertac},
  journal={AI communications},
  volume={29},
  number={1},
  pages={151--162},
  year={2016},
  publisher={IOS Press}
}

@inproceedings{precup1998multi,
  title={Multi-time models for temporally abstract planning},
  author={Precup, Doina and Sutton, Richard S},
  booktitle={Advances in neural information processing systems},
  pages={1050--1056},
  year={1998}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{shah2020planning,
  title={Planning with uncertain specifications (puns)},
  author={Shah, Ankit and Li, Shen and Shah, Julie},
  journal={IEEE Robotics and Automation Letters},
  volume={5},
  number={2},
  pages={3414--3421},
  year={2020},
  publisher={IEEE}
}

@article{silverfew,
  title={Few-Shot Bayesian Imitation Learning with Logical Program Policies},
  author={Silver, Tom and Allen, Kelsey R and Lew, Alex K and Kaelbling, Leslie and Tenenbaum, Josh}
}

@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@article{yuan2019modular,
  title={Modular deep reinforcement learning with temporal logic specifications},
  author={Yuan, Lim Zun and Hasanbeig, Mohammadhosein and Abate, Alessandro and Kroening, Daniel},
  journal={arXiv preprint arXiv:1909.11591},
  year={2019}
}

@article{zhang2020survey,
  title={A Survey of Knowledge-based Sequential Decision Making under Uncertainty},
  author={Zhang, Shiqi and Sridharan, Mohan},
  journal={arXiv preprint arXiv:2008.08548},
  year={2020}
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}
