\begin{thebibliography}{10}

\bibitem{bertinetto2018meta}
Luca Bertinetto, Joao~F Henriques, Philip~HS Torr, and Andrea Vedaldi.
\newblock Meta-learning with differentiable closed-form solvers.
\newblock {\em arXiv preprint arXiv:1805.08136}, 2018.

\bibitem{carlini2017towards}
Nicholas Carlini and David Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In {\em 2017 ieee symposium on security and privacy (sp)}, pages
  39--57. IEEE, 2017.

\bibitem{cohen2019certified}
Jeremy Cohen, Elan Rosenfeld, and Zico Kolter.
\newblock Certified adversarial robustness via randomized smoothing.
\newblock In {\em International Conference on Machine Learning}, pages
  1310--1320. PMLR, 2019.

\bibitem{dhillon2018stochastic}
Guneet~S. Dhillon, Kamyar Azizzadenesheli, Zachary~C. Lipton, Jeremy Bernstein,
  Jean Kossaifi, Aran Khanna, and Anima Anandkumar.
\newblock Stochastic activation pruning for robust adversarial defense, 2018.

\bibitem{dong2019efficient}
Yinpeng Dong, Hang Su, Baoyuan Wu, Zhifeng Li, Wei Liu, Tong Zhang, and Jun
  Zhu.
\newblock Efficient decision-based black-box adversarial attacks on face
  recognition.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 7714--7722, 2019.

\bibitem{ehlers2017formal}
Ruediger Ehlers.
\newblock Formal verification of piece-wise linear feed-forward neural
  networks.
\newblock In {\em International Symposium on Automated Technology for
  Verification and Analysis}, pages 269--286. Springer, 2017.

\bibitem{fischer2017adversarial}
Volker Fischer, Mummadi~Chaithanya Kumar, Jan~Hendrik Metzen, and Thomas Brox.
\newblock Adversarial examples for semantic image segmentation.
\newblock {\em arXiv preprint arXiv:1703.01101}, 2017.

\bibitem{fischetti2017deep}
Matteo Fischetti and Jason Jo.
\newblock Deep neural networks as 0-1 mixed integer linear programs: A
  feasibility study.
\newblock {\em arXiv preprint arXiv:1712.06174}, 2017.

\bibitem{goldblum2020adversarially}
Micah Goldblum, Liam Fowl, and Tom Goldstein.
\newblock Adversarially robust few-shot learning: A meta-learning approach.
\newblock {\em Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock {\em arXiv preprint arXiv:1412.6572}, 2014.

\bibitem{gowal2018effectiveness}
Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel, Chongli Qin,
  Jonathan Uesato, Relja Arandjelovic, Timothy Mann, and Pushmeet Kohli.
\newblock On the effectiveness of interval bound propagation for training
  verifiably robust models.
\newblock {\em arXiv preprint arXiv:1810.12715}, 2018.

\bibitem{hendrik2017universal}
Jan Hendrik~Metzen, Mummadi Chaithanya~Kumar, Thomas Brox, and Volker Fischer.
\newblock Universal adversarial perturbations against semantic image
  segmentation.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 2755--2764, 2017.

\bibitem{hoeffding1994probability}
Wassily Hoeffding.
\newblock Probability inequalities for sums of bounded random variables.
\newblock In {\em The collected works of Wassily Hoeffding}, pages 409--426.
  Springer, 1994.

\bibitem{jang2019adversarial}
Yunseok Jang, Tianchen Zhao, Seunghoon Hong, and Honglak Lee.
\newblock Adversarial defense via learning to generate diverse attacks.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 2740--2749, 2019.

\bibitem{jia2019certified}
Jinyuan Jia, Xiaoyu Cao, Binghui Wang, and Neil~Zhenqiang Gong.
\newblock Certified robustness for top-k predictions against adversarial
  perturbations via randomized smoothing.
\newblock {\em arXiv preprint arXiv:1912.09899}, 2019.

\bibitem{katz2017reluplex}
Guy Katz, Clark Barrett, David~L Dill, Kyle Julian, and Mykel~J Kochenderfer.
\newblock Reluplex: An efficient smt solver for verifying deep neural networks.
\newblock In {\em International Conference on Computer Aided Verification},
  pages 97--117. Springer, 2017.

\bibitem{kaziakhmedov2019real}
Edgar Kaziakhmedov, Klim Kireev, Grigorii Melnikov, Mikhail Pautov, and
  Aleksandr Petiushko.
\newblock Real-world attack on mtcnn face detection system.
\newblock In {\em 2019 International Multi-Conference on Engineering, Computer
  and Information Sciences (SIBIRCON)}, pages 0422--0427. IEEE, 2019.

\bibitem{komkov2021advhat}
Stepan Komkov and Aleksandr Petiushko.
\newblock Advhat: Real-world adversarial attack on arcface face id system.
\newblock In {\em 2020 25th International Conference on Pattern Recognition
  (ICPR)}, pages 819--826. IEEE, 2021.

\bibitem{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem{kumar2021center}
Aounon Kumar and Tom Goldstein.
\newblock Center smoothing: Certified robustness for networks with structured
  outputs.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{lecuyer2019certified}
Mathias Lecuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, and Suman
  Jana.
\newblock Certified robustness to adversarial examples with differential
  privacy.
\newblock In {\em 2019 IEEE Symposium on Security and Privacy (SP)}, pages
  656--672. IEEE, 2019.

\bibitem{lee2019tight}
Guang-He Lee, Yang Yuan, Shiyu Chang, and Tommi~S Jaakkola.
\newblock Tight certificates of adversarial robustness for randomly smoothed
  classifiers.
\newblock {\em arXiv preprint arXiv:1906.04948}, 2019.

\bibitem{levine2020robustness}
Alexander Levine and Soheil Feizi.
\newblock Robustness certificates for sparse adversarial attacks by randomized
  ablation.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pages 4585--4593, 2020.

\bibitem{levine2020wasserstein}
Alexander Levine and Soheil Feizi.
\newblock Wasserstein smoothing: Certified robustness against wasserstein
  adversarial attacks.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 3938--3947. PMLR, 2020.

\bibitem{li2018certified}
Bai Li, Changyou Chen, Wenlin Wang, and Lawrence Carin.
\newblock Certified adversarial robustness with additive noise.
\newblock {\em arXiv preprint arXiv:1809.03113}, 2018.

\bibitem{li2021universal}
Debang Li, Junge Zhang, and Kaiqi Huang.
\newblock Universal adversarial perturbations against object detection.
\newblock {\em Pattern Recognition}, 110:107584, 2021.

\bibitem{li2021tss}
Linyi Li, Maurice Weber, Xiaojun Xu, Luka Rimanic, Bhavya Kailkhura, Tao Xie,
  Ce~Zhang, and Bo~Li.
\newblock Tss: Transformation-specific smoothing for robustness certification,
  2021.

\bibitem{liu2021long}
Fan Liu, Shuyu Zhao, Xuelong Dai, and Bin Xiao.
\newblock Long-term cross adversarial training: A robust meta-learning method
  for few-shot classification tasks.
\newblock {\em arXiv preprint arXiv:2106.12900}, 2021.

\bibitem{liu2018towards}
Xuanqing Liu, Minhao Cheng, Huan Zhang, and Cho-Jui Hsieh.
\newblock Towards robust neural networks via random self-ensemble.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 369--385, 2018.

\bibitem{lomuscio2017approach}
Alessio Lomuscio and Lalit Maganti.
\newblock An approach to reachability analysis for feed-forward relu neural
  networks.
\newblock {\em arXiv preprint arXiv:1706.07351}, 2017.

\bibitem{madry2017towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock {\em arXiv preprint arXiv:1706.06083}, 2017.

\bibitem{mohapatra2020higher}
Jeet Mohapatra, Ching-Yun Ko, Tsui-Wei Weng, Pin-Yu Chen, Sijia Liu, and Luca
  Daniel.
\newblock Higher-order certification for randomized smoothing.
\newblock {\em arXiv preprint arXiv:2010.06651}, 2020.

\bibitem{moosavi2017universal}
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, and Pascal
  Frossard.
\newblock Universal adversarial perturbations.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1765--1773, 2017.

\bibitem{moosavi2016deepfool}
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard.
\newblock Deepfool: a simple and accurate method to fool deep neural networks.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2574--2582, 2016.

\bibitem{pautov2021cc}
Mikhail Pautov, Nurislam Tursynbek, Marina Munkhoeva, Nikita Muravev, Aleksandr
  Petiushko, and Ivan Oseledets.
\newblock {CC-Cert}: A probabilistic approach to certify general robustness of
  neural networks.
\newblock {\em arXiv preprint arXiv:2109.10696}, 2021.

\bibitem{raghunathan2018certified}
Aditi Raghunathan, Jacob Steinhardt, and Percy Liang.
\newblock Certified defenses against adversarial examples.
\newblock {\em arXiv preprint arXiv:1801.09344}, 2018.

\bibitem{russakovsky2015imagenet}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock {\em International journal of computer vision}, 115(3):211--252,
  2015.

\bibitem{salman2019provably}
Hadi Salman, Greg Yang, Jerry Li, Pengchuan Zhang, Huan Zhang, Ilya
  Razenshteyn, and Sebastien Bubeck.
\newblock Provably robust deep learning via adversarially trained smoothed
  classifiers.
\newblock {\em arXiv preprint arXiv:1906.04584}, 2019.

\bibitem{snell2017prototypical}
Jake Snell, Kevin Swersky, and Richard~S Zemel.
\newblock Prototypical networks for few-shot learning.
\newblock {\em arXiv preprint arXiv:1703.05175}, 2017.

\bibitem{su2019one}
Jiawei Su, Danilo~Vasconcellos Vargas, and Kouichi Sakurai.
\newblock One pixel attack for fooling deep neural networks.
\newblock {\em IEEE Transactions on Evolutionary Computation}, 23(5):828--841,
  2019.

\bibitem{szegedy2013intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock {\em arXiv preprint arXiv:1312.6199}, 2013.

\bibitem{teng2019ell_1}
Jiaye Teng, Guang-He Lee, and Yang Yuan.
\newblock $\ell\_1 $ adversarial robustness certificates: a randomized
  smoothing approach.
\newblock 2019.

\bibitem{triantafillou2019meta}
Eleni Triantafillou, Tyler Zhu, Vincent Dumoulin, Pascal Lamblin, Utku Evci,
  Kelvin Xu, Ross Goroshin, Carles Gelada, Kevin Swersky, Pierre-Antoine
  Manzagol, et~al.
\newblock Meta-dataset: A dataset of datasets for learning to learn from few
  examples.
\newblock {\em arXiv preprint arXiv:1903.03096}, 2019.

\bibitem{vinyals2016matching}
Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et~al.
\newblock Matching networks for one shot learning.
\newblock {\em Advances in neural information processing systems},
  29:3630--3638, 2016.

\bibitem{wah2011caltech}
Catherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge
  Belongie.
\newblock The caltech-ucsd birds-200-2011 dataset.
\newblock 2011.

\bibitem{weng2019proven}
Lily Weng, Pin-Yu Chen, Lam Nguyen, Mark Squillante, Akhilan Boopathy, Ivan
  Oseledets, and Luca Daniel.
\newblock Proven: Verifying robustness of neural networks with a probabilistic
  approach.
\newblock In {\em International Conference on Machine Learning}, pages
  6727--6736. PMLR, 2019.

\bibitem{wong2018provable}
Eric Wong and Zico Kolter.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope.
\newblock In {\em International Conference on Machine Learning}, pages
  5286--5295. PMLR, 2018.

\bibitem{wu2020making}
Zuxuan Wu, Ser-Nam Lim, Larry~S Davis, and Tom Goldstein.
\newblock Making an invisibility cloak: Real world adversarial attacks on
  object detectors.
\newblock In {\em European Conference on Computer Vision}, pages 1--17.
  Springer, 2020.

\bibitem{xie2017mitigating}
Cihang Xie, Jianyu Wang, Zhishuai Zhang, Zhou Ren, and Alan Yuille.
\newblock Mitigating adversarial effects through randomization.
\newblock {\em arXiv preprint arXiv:1711.01991}, 2017.

\bibitem{xie2017adversarial}
Cihang Xie, Jianyu Wang, Zhishuai Zhang, Yuyin Zhou, Lingxi Xie, and Alan
  Yuille.
\newblock Adversarial examples for semantic segmentation and object detection.
\newblock In {\em Proceedings of the IEEE International Conference on Computer
  Vision}, pages 1369--1378, 2017.

\bibitem{yang2020randomized}
Greg Yang, Tony Duan, J~Edward Hu, Hadi Salman, Ilya Razenshteyn, and Jerry Li.
\newblock Randomized smoothing of all shapes and sizes.
\newblock In {\em International Conference on Machine Learning}, pages
  10693--10705. PMLR, 2020.

\bibitem{zhang2020black}
Dinghuai Zhang, Mao Ye, Chengyue Gong, Zhanxing Zhu, and Qiang Liu.
\newblock Black-box certification with randomized smoothing: A functional
  optimization based framework.
\newblock {\em arXiv preprint arXiv:2002.09169}, 2020.

\bibitem{zhang2019theoretically}
Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El~Ghaoui, and
  Michael Jordan.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In {\em International Conference on Machine Learning}, pages
  7472--7482. PMLR, 2019.

\bibitem{zhong2020towards}
Yaoyao Zhong and Weihong Deng.
\newblock Towards transferable adversarial attack against deep face
  recognition.
\newblock {\em IEEE Transactions on Information Forensics and Security},
  16:1452--1466, 2020.

\bibitem{zhou2020manifold}
Jianli Zhou, Chao Liang, and Jun Chen.
\newblock Manifold projection for adversarial defense on face recognition.
\newblock In {\em European Conference on Computer Vision}, pages 288--305.
  Springer, 2020.

\end{thebibliography}
