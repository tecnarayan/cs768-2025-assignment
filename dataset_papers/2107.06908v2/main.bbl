\begin{thebibliography}{30}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amodei et~al.(2016)Amodei, Olah, Steinhardt, Christiano, Schulman, and
  Man{\'e}]{Amodei2016ConcretePI}
Amodei, D., Olah, C., Steinhardt, J., Christiano, P.~F., Schulman, J., and
  Man{\'e}, D.
\newblock Concrete problems in ai safety.
\newblock \emph{ArXiv}, 2016.

\bibitem[Bishop(1994)]{Bishop}
Bishop, C.~M.
\newblock Novelty detection and neural network validation.
\newblock \emph{IEE Proceedings-Vision, Image and Signal processing},
  141\penalty0 (4):\penalty0 217--222, 1994.

\bibitem[Chen et~al.(2018)Chen, Mishra, Rohaninejad, and
  Abbeel]{Chen2018PixelSNAILAI}
Chen, X., Mishra, N., Rohaninejad, M., and Abbeel, P.
\newblock Pixelsnail: An improved autoregressive generative model.
\newblock In \emph{ICML}, volume abs/1712.09763, 2018.

\bibitem[Choi et~al.(2018)Choi, Jang, and Alemi]{Choi2018WAICBW}
Choi, H., Jang, E., and Alemi, A.~A.
\newblock Waic, but why? generative ensembles for robust anomaly detection.
\newblock \emph{ArXiv}, 2018.

\bibitem[Cover \& Thomas(1991)Cover and Thomas]{Cover1991ElementsOI}
Cover, T. and Thomas, J.
\newblock \emph{Elements of Information Theory}.
\newblock 1991.

\bibitem[Dinh et~al.(2015)Dinh, Krueger, and Bengio]{Dinh2015NICENI}
Dinh, L., Krueger, D., and Bengio, Y.
\newblock Nice: Non-linear independent components estimation.
\newblock \emph{ArXiv}, 2015.

\bibitem[Dinh et~al.(2017)Dinh, Sohl-Dickstein, and Bengio]{Dinh2017DensityEU}
Dinh, L., Sohl-Dickstein, J., and Bengio, S.
\newblock Density estimation using real nvp.
\newblock \emph{ArXiv}, abs/1605.08803, 2017.

\bibitem[Hendrycks \& Gimpel(2017)Hendrycks and Gimpel]{Hendrycks2017ABF}
Hendrycks, D. and Gimpel, K.
\newblock A baseline for detecting misclassified and out-of-distribution
  examples in neural networks.
\newblock In \emph{ICLR}, 2017.

\bibitem[Hendrycks et~al.(2019)Hendrycks, Mazeika, and
  Dietterich]{Hendrycks2019DeepAD}
Hendrycks, D., Mazeika, M., and Dietterich, T.~G.
\newblock Deep anomaly detection with outlier exposure.
\newblock In \emph{ICLR}, 2019.

\bibitem[Jerfel et~al.(2021)Jerfel, Wang, Fannjiang, Heller, Ma, and
  Jordan]{jerfel2021variational}
Jerfel, G., Wang, S.~L., Fannjiang, C., Heller, K.~A., Ma, Y., and Jordan, M.
\newblock Variational refinement for importance sampling using the forward
  kullback-leibler divergence.
\newblock In \emph{Third Symposium on Advances in Approximate Bayesian
  Inference}, 2021.

\bibitem[Kingma \& Dhariwal(2018)Kingma and Dhariwal]{Kingma2018GlowGF}
Kingma, D.~P. and Dhariwal, P.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Kirichenko et~al.(2020)Kirichenko, Izmailov, and
  Wilson]{Kirichenko2020WhyNF}
Kirichenko, P., Izmailov, P., and Wilson, A.
\newblock Why normalizing flows fail to detect out-of-distribution data.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Le Lan \& Dinh(2020)Lan and Dinh]{Lan2020PerfectDM}
Le Lan, C. and Dinh, L.
\newblock Perfect density models cannot guarantee anomaly detection.
\newblock In \emph{NeurIPS I Can’t Believe It’s Not Better Workshop}, 2020.

\bibitem[Liang et~al.(2018)Liang, Li, and Srikant]{Liang2018EnhancingTR}
Liang, S., Li, Y., and Srikant, R.
\newblock Enhancing the reliability of out-of-distribution image detection in
  neural networks.
\newblock In \emph{ICLR}, 2018.

\bibitem[Liu et~al.(2015)Liu, Luo, Wang, and Tang]{liu2015faceattributes}
Liu, Z., Luo, P., Wang, X., and Tang, X.
\newblock Deep learning face attributes in the wild.
\newblock In \emph{Proceedings of International Conference on Computer Vision
  (ICCV)}, December 2015.

\bibitem[Maal{\o}e et~al.(2019)Maal{\o}e, Fraccaro, Li{\'e}vin, and
  Winther]{BIVA}
Maal{\o}e, L., Fraccaro, M., Li{\'e}vin, V., and Winther, O.
\newblock Biva: A very deep hierarchy of latent variables for generative
  modeling.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Morningstar et~al.(2021)Morningstar, Ham, Gallagher, Lakshminarayanan,
  Alemi, and Dillon]{Morningstar2020DensityOS}
Morningstar, W., Ham, C., Gallagher, A.~G., Lakshminarayanan, B., Alemi, A.~A.,
  and Dillon, J.~V.
\newblock Density of states estimation for out-of-distribution detection.
\newblock 2021.

\bibitem[Nalisnick et~al.(2019{\natexlab{a}})Nalisnick, Matsukawa, Teh,
  G{\"o}r{\"u}r, and Lakshminarayanan]{Nalisnick2019DoDG}
Nalisnick, E., Matsukawa, A., Teh, Y., G{\"o}r{\"u}r, D., and Lakshminarayanan,
  B.
\newblock Do deep generative models know what they don't know?
\newblock In \emph{ICLR}, 2019{\natexlab{a}}.

\bibitem[Nalisnick et~al.(2019{\natexlab{b}})Nalisnick, Matsukawa, Teh, and
  Lakshminarayanan]{DeepMind2019DetectingOI}
Nalisnick, E., Matsukawa, A., Teh, Y.~W., and Lakshminarayanan, B.
\newblock Detecting out-of-distribution inputs to deep generative models using
  typicality.
\newblock In \emph{NeurIPS Workshop on Bayesian Deep Learning},
  2019{\natexlab{b}}.

\bibitem[Neyman \& Pearson(1933)Neyman and Pearson]{Neyman1933OnTP}
Neyman, J. and Pearson, E.
\newblock On the problem of the most efficient tests of statistical hypotheses.
\newblock \emph{Philosophical Transactions of the Royal Society A},
  231:\penalty0 289--337, 1933.

\bibitem[Oord et~al.(2016{\natexlab{a}})Oord, Kalchbrenner, Espeholt,
  Kavukcuoglu, Vinyals, and Graves]{Oord2016ConditionalIG}
Oord, A., Kalchbrenner, N., Espeholt, L., Kavukcuoglu, K., Vinyals, O., and
  Graves, A.
\newblock Conditional image generation with pixelcnn decoders.
\newblock In \emph{NeurIPS}, 2016{\natexlab{a}}.

\bibitem[Oord et~al.(2016{\natexlab{b}})Oord, Kalchbrenner, and
  Kavukcuoglu]{Oord2016PixelRN}
Oord, A., Kalchbrenner, N., and Kavukcuoglu, K.
\newblock Pixel recurrent neural networks.
\newblock In \emph{ICML}, 2016{\natexlab{b}}.

\bibitem[Ren et~al.(2019)Ren, Liu, Fertig, Snoek, Poplin, DePristo, Dillon, and
  Lakshminarayanan]{Ren2019LikelihoodRF}
Ren, J., Liu, P.~J., Fertig, E., Snoek, J., Poplin, R., DePristo, M.~A.,
  Dillon, J.~V., and Lakshminarayanan, B.
\newblock Likelihood ratios for out-of-distribution detection.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Ruff et~al.(2018)Ruff, G{\"o}rnitz, Deecke, Siddiqui, Vandermeulen,
  Binder, M{\"u}ller, and Kloft]{Ruff2018DeepOC}
Ruff, L., G{\"o}rnitz, N., Deecke, L., Siddiqui, S., Vandermeulen, R.~A.,
  Binder, A., M{\"u}ller, E., and Kloft, M.
\newblock Deep one-class classification.
\newblock In \emph{ICML}, 2018.

\bibitem[Salimans et~al.(2017)Salimans, Karpathy, Chen, and
  Kingma]{Salimans2017PixelCNNIT}
Salimans, T., Karpathy, A., Chen, X., and Kingma, D.~P.
\newblock Pixelcnn++: Improving the pixelcnn with discretized logistic mixture
  likelihood and other modifications.
\newblock 2017.

\bibitem[Schirrmeister et~al.(2020)Schirrmeister, Zhou, Ball, and
  Zhang]{Schirrmeister2020UnderstandingAD}
Schirrmeister, R.~T., Zhou, Y., Ball, T., and Zhang, D.
\newblock Understanding anomaly detection with deep invertible networks through
  hierarchies of distributions and features.
\newblock In \emph{NeurIPS}, 2020.

\bibitem[Sch{\"o}lkopf et~al.(1999)Sch{\"o}lkopf, Williamson, Smola,
  Shawe-Taylor, and Platt]{Schlkopf1999SupportVM}
Sch{\"o}lkopf, B., Williamson, R.~C., Smola, A., Shawe-Taylor, J., and Platt,
  J.~C.
\newblock Support vector method for novelty detection.
\newblock In \emph{NeurIPS}, 1999.

\bibitem[Serr{\`a} et~al.(2020)Serr{\`a}, {\'A}lvarez, G{\'o}mez, Slizovskaia,
  N{\'u}{\~n}ez, and Luque]{Serr2020InputCA}
Serr{\`a}, J., {\'A}lvarez, D., G{\'o}mez, V., Slizovskaia, O., N{\'u}{\~n}ez,
  J.~F., and Luque, J.
\newblock Input complexity and out-of-distribution detection with
  likelihood-based generative models.
\newblock In \emph{ICLR}, 2020.

\bibitem[Tax \& Duin(2004)Tax and Duin]{Tax2004SupportVD}
Tax, D. and Duin, R.
\newblock Support vector data description.
\newblock \emph{Machine Learning}, 54:\penalty0 45--66, 2004.

\bibitem[Wang et~al.(2020)Wang, Dai, Wipf, and Zhu]{Wang2020FurtherAO}
Wang, Z., Dai, B., Wipf, D., and Zhu, J.
\newblock Further analysis of outlier detection with deep generative models.
\newblock In \emph{NeurIPS}, 2020.

\end{thebibliography}
