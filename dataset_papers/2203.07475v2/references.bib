
@Article{	  ab2020,
  title		= {From Inverse Optimal Control to Inverse Reinforcement
		  Learning: A Historical Review},
  author	= {Ab Azar, Nematollah and Shahmansoorian, Aref and Davoudi,
		  Mohsen},
  journal	= {Annual Reviews in Control},
  volume	= {50},
  pages		= {119--138},
  year		= {2020},
  publisher	= {Elsevier},
  doi		= {10.1016/j.arcontrol.2020.06.001}
}

@InProceedings{	  abbeel2004,
  author	= {Abbeel, Pieter and Ng, Andrew Y.},
  title		= {Apprenticeship Learning via Inverse Reinforcement
		  Learning},
  year		= {2004},
  month		= jul,
  address	= {Banff, Alberta, Canada},
  booktitle	= {Proceedings of the Twenty-First International Conference
		  on Machine Learning},
  publisher	= {Association for Computing Machinery},
  doi		= {10.1145/1015330.1015430},
  pages		= {1--8}
}

@Article{	  abbeel2010,
  author	= {Abbeel, Pieter and Coates, Adam and Ng, Andrew Y},
  title		= {Autonomous Helicopter Aerobatics Through Apprenticeship
		  Learning},
  journal	= {The International Journal of Robotics Research},
  volume	= {29},
  number	= {13},
  pages		= {1608--1639},
  year		= {2010},
  publisher	= {SAGE Publications Sage UK},
  address	= {London, England},
  doi		= {10.1177/0278364910371999}
}

@Article{	  aguirregabiria2005,
  title		= {Nonparametric Identification of Behavioral Responses to
		  Counterfactual Policy Interventions in Dynamic Discrete
		  Decision Processes},
  author	= {Aguirregabiria, Victor},
  journal	= {Economics Letters},
  volume	= {87},
  number	= {3},
  pages		= {393--398},
  year		= {2005},
  publisher	= {Elsevier},
  doi		= {10.1016/j.econlet.2004.12.014}
}

@Article{	  aguirregabiria2010,
  title		= {Dynamic Discrete Choice Structural Models: A Survey},
  author	= {Aguirregabiria, Victor and Mira, Pedro},
  journal	= {Journal of Econometrics},
  volume	= {156},
  number	= {1},
  pages		= {38--67},
  year		= {2010},
  publisher	= {Elsevier},
  doi		= {10.1016/j.jeconom.2009.09.007}
}

@Book{		  aigner1979,
  author	= {Aigner, Martin},
  title		= {Combinatorial Theory},
  edition	= {Reprint of the 1979},
  isbn		= {3540617876},
  lccn		= {96051833},
  series	= {Classics in Mathematics},
  year		= {1996},
  publisher	= {Springer Berlin Heidelberg}
}

@Book{		  aima3e,
  title		= {Artificial Intelligence: A Modern Approach},
  author	= {Russell, Stuart and Norvig, Peter},
  year		= {2009},
  edition	= {third},
  publisher	= {Prentice Hall},
  address	= {Upper Saddle River, NJ},
  isbn		= {9780136042594}
}

@InProceedings{	  akrour2012,
  title		= {{APRIL}: Active Preference Learning-Based Reinforcement
		  Learning},
  author	= {Akrour, Riad and Schoenauer, Marc and Sebag, Mich{\`e}le},
  pages		= {116--131},
  booktitle	= {Machine Learning and Knowledge Discovery in Databases:
		  ECML PKDD 2012, Proceedings, Part II},
  series	= {Lecture Notes in Computer Science},
  volume	= {7524},
  address	= {Bristol, UK},
  year		= {2012},
  publisher	= {Springer},
  doi		= {10.1007/978-3-642-33486-3_8}
}

@InProceedings{	  amin2017,
  author	= {Amin, Kareem and Jiang, Nan and Singh, Satinder P.},
  title		= {Repeated Inverse Reinforcement Learning},
  booktitle	= {Proceedings of the 31st Conference on Neural
		  Information Processing Systems},
  address	= {Long Beach, California, USA},
  pages		= {1813-1822},
  volume	= {30},
  year		= {2017},
  publisher	= {Curran Associates, Inc., Red Hook, NY, USA}
}

@Article{	  amodei2016,
  author	= {Amodei, Dario and Olah, Chris and Steinhardt, Jacob and
		  Christiano, Paul F and Schulman, John and Man{\'e}, Dan},
  title		= {Concrete Problems in {AI} Safety},
  journal	= {arXiv preprint},
  volume	= {arXiv:1606.06565 [cs.AI]},
  year		= {2016}
}

@Article{	  arcidiacono2020,
  title		= {Identifying Dynamic Discrete Choice Models Off Short
		  Panels},
  author	= {Arcidiacono, Peter and Miller, Robert A},
  journal	= {Journal of Econometrics},
  volume	= {215},
  number	= {2},
  pages		= {473--485},
  year		= {2020},
  publisher	= {Elsevier},
  doi		= {10.1016/j.jeconom.2018.12.025}
}

@InProceedings{	  armstrong2017,
  author	= {Armstrong, Stuart and Mindermann, S{\"o}ren},
  title		= {Occam's Razor is Insufficient to Infer the Preferences of
		  Irrational Agents},
  pages		= {5603-5614},
  booktitle	= {Proceedings of the 32nd Conference on Neural
		  Information Processing Systems},
  volume	= {31},
  address	= {Montr\'{e}al, Canada},
  year		= {2018},
  publisher	= {Curran Associates, Inc., Red Hook, NY, USA}
}

@Article{	  baker2006,
  title		= {Bayesian models of human action understanding},
  author	= {Baker, Chris L and Tenenbaum, Joshua B and Saxe, Rebecca},
  journal	= {Advances in Neural Information Processing Systems},
  volume	= {18},
  pages		= {99},
  year		= {2006},
  publisher	= {Citeseer}
}

@InProceedings{	  baker2007,
  title		= {Goal inference as inverse planning},
  author	= {Baker, Chris L and Tenenbaum, Joshua B and Saxe, Rebecca
		  R},
  booktitle	= {Proceedings of the Annual Meeting of the Cognitive Science
		  Society},
  volume	= {29},
  number	= {29},
  year		= {2007}
}

@Book{		  birkhoff1967,
  author	= {Birkhoff, Garrett},
  title		= {Lattice Theory},
  edition	= {third},
  publisher	= {American Mathematical Society},
  date		= {1967}
}

@Article{	  biyik2020,
  author	= {B{\i}y{\i}k, Erdem and Losey, Dylan P and Palan, Malayandi
		  and Landolfi, Nicholas C and Shevchuk, Gleb and Sadigh,
		  Dorsa},
  title		= {Learning Reward Functions From Diverse Sources of Human
		  Feedback: Optimally Integrating Demonstrations and
		  Preferences},
  journal	= {The International Journal of Robotics Research},
  volume	= {41},
  number	= {1},
  pages		= {45-67},
  year		= {2022},
  doi		= {10.1177/02783649211041652}
}

@Book{		  bostrom2014,
  author	= {Nick Bostrom},
  title		= {Superintelligence: Paths, Dangers, Strategies},
  isbn		= {9780199678112},
  lccn		= {2013955152},
  year		= {2014},
  publisher	= {Oxford University Press},
  address	= {Oxford}
}

@Article{	  brown2019brex,
  title		= {Deep {B}ayesian Reward Learning from Preferences},
  author	= {Brown, Daniel S and Niekum, Scott},
  journal	= {arXiv preprint arXiv:1912.04472},
  year		= {2019}
}

@InProceedings{	  brown2019trex,
  title		= {Extrapolating beyond suboptimal demonstrations via inverse
		  reinforcement learning from observations},
  author	= {Brown, Daniel and Goo, Wonjoon and Nagarajan, Prabhat and
		  Niekum, Scott},
  booktitle	= {International Conference on Machine Learning},
  pages		= {783--792},
  year		= {2019},
  organization	= {PMLR}
}

@InProceedings{	  brown2020drex,
  title		= {Better-than-demonstrator imitation learning via
		  automatically-ranked demonstrations},
  author	= {Brown, Daniel S and Goo, Wonjoon and Niekum, Scott},
  booktitle	= {Conference on Robot Learning},
  pages		= {330--359},
  year		= {2020},
  organization	= {PMLR}
}

@Article{	  camerer1995,
  title		= {Individual Decision Making},
  author	= {Camerer, Colin},
  journal	= {Handbook of Experimental Economics},
  year		= {1995},
  publisher	= {Princeton University Press}
}

@InProceedings{ cao2021,
  author	= {Haoyang Cao and Samuel N. Cohen and Lukasz Szpruch},
  title		= {Identifiability in Inverse Reinforcement Learning},
  pages     = {12362--12373},
  volume    = {34},
  booktitle	= {Proceedings of the 35th Conference on Neural Information Processing Systems},
  year      = {2021},
  address	= {Virtual},
  publisher	= {Curran Associates, Inc., Red Hook, NY, USA}
}
%
%
%
%
%
%

@InProceedings{	  christiano2017,
  author	= {Christiano, Paul F. and Leike, Jan and Brown, Tom B. and
		  Martic, Miljan and Legg, Shane and Amodei, Dario},
  title		= {Deep Reinforcement Learning from Human Preferences},
  year		= {2017},
  publisher	= {Curran Associates, Inc., Red Hook, NY, USA},
  booktitle	= {Proceedings of the 31st Conference on Neural
		  Information Processing Systems},
  pages		= {4302â€“4310},
  address	= {Long Beach, California, USA},
  volume	= {30}
}

@InProceedings{	  codevilla2018,
  title		= {End-to-end driving via conditional imitation learning},
  author	= {Codevilla, Felipe and M{\"u}ller, Matthias and L{\'o}pez,
		  Antonio and Koltun, Vladlen and Dosovitskiy, Alexey},
  booktitle	= {2018 IEEE International Conference on Robotics and
		  Automation (ICRA)},
  pages		= {4693--4700},
  year		= {2018},
  organization	= {IEEE}
}

@Article{	  collins2021,
  title		= {Advances in Modeling Learning and Decision-Making in
		  Neuroscience},
  author	= {Collins, Anne G E and Shenhav, Amitai},
  journal	= {Neuropsychopharmacology},
  pages		= {104--118},
  volume	= {47},
  year		= {2022},
  publisher	= {Nature Publishing Group},
  doi		= {10.1038/s41386-021-01126-y}
}

@InProceedings{	  dabney2018,
  title		= {Distributional Reinforcement Learning with Quantile
		  Regression},
  author	= {Dabney, Will and Rowland, Mark and Bellemare, Marc G and
		  Munos, R{\'e}mi},
  booktitle	= {Proceedings of the AAAI Conference on Artificial
		  Intelligence},
  volume	= {32(1)},
  pages		= {2892--2901},
  address	= {New Orleans, Lousiana, USA},
  month		= apr,
  year		= {2018},
  publisher	= {AAAI Press}
}

@Article{	  dafoe2020,
  title		= {Open Problems in Cooperative {AI}},
  author	= {Allan Dafoe and Edward Hughes and Yoram Bachrach and
		  Tantum Collins and Kevin R. McKee and Joel Z. Leibo and
		  Kate Larson and Thore Graepel},
  year		= {2020},
  journal	= {arXiv preprint},
  volume	= {arXiv:2012.08630 [cs.AI]}
}

@Book{		  dennett1989,
  title		= {The Intentional Stance},
  author	= {Dennett, Daniel C},
  year		= {1987},
  isbn		= {026204093X},
  lccn		= {87003018},
  publisher	= {MIT Press}
}

@InProceedings{	  dulac2019,
  title		= {Challenges of Real-World Reinforcement Learning},
  author	= {Dulac-Arnold, Gabriel and Mankowitz, Daniel and Hester,
		  Todd},
  year      = {2019},
  booktitle	= {Reinforcement Learning for Real Life,
		  International Conference on Machine Learning Workshop},
  address	= {Long Beach, California, USA},
  month		= jun,
  doi       = {10.48550/arXiv.1904.12901}
}
%
%

@InProceedings{     jenner2021,
    title   = {Preprocessing Reward Functions for Interpretability},
    author  = {Jenner, Erik and Gleave, Adam},
    year    = {2021},
    booktitle = {Cooperative AI Workshop, NeurIPS 2021},
    address = {Virtual},
    month   = dec,
    doi     = {10.48550/arXiv.2203.13553}
}
@InProceedings{     michaud2020,
    title   = {Understanding learned reward functions},
    author  = {Michaud, Eric J and Gleave, Adam and Russell, Stuart},
    year    = {2020},
    booktitle = {Deep Reinforcement Learning Workshop, NeurIPS 2020},
    address = {Virtual},
    month   = dec,
    doi     = {10.48550/arXiv.2012.05862}
}


@InProceedings{	  dvijotham2010,
  title		= {Inverse Optimal Control with Linearly-Solvable {MDPs}},
  author	= {Dvijotham, Krishnamurthy and Todorov, Emanuel},
  pages		= {335--342},
  month		= jun,
  year		= {2010},
  booktitle	= {Proceedings of the 27th International Conference on
		  Machine Learning},
  address	= {Haifa, Israel},
  publisher	= {Omnipress, Madison, Wisconsin, USA}
}

@Book{		  fishburn1970,
  title		= {Utility Theory for Decision Making},
  author	= {Fishburn, Peter C},
  year		= {1970},
  publisher	= {John Wiley \& Sons, Inc.},
  lccn		= {74-107587},
  isbn		= {0471260606}
}

@Article{	  gabriel2020,
  title		= {Artificial Intelligence, Values, and Alignment},
  author	= {Gabriel, Iason},
  journal	= {Minds and Machines},
  volume	= {30},
  number	= {3},
  pages		= {411--437},
  year		= {2020},
  publisher	= {Springer},
  doi		= {10.1007/s11023-020-09539-2}
}

@InProceedings{	  haarnoja2017,
  title		= {Reinforcement Learning with Deep Energy-Based Policies},
  author	= {Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and
		  Levine, Sergey},
  booktitle	= {Proceedings of the 34th International Conference on
		  Machine Learning},
  pages		= {1352--1361},
  volume	= {70},
  series	= {Proceedings of Machine Learning Research},
  year		= {2017},
  address	= {Sydney, Australia},
  month		= aug,
  publisher	= {PMLR}
}

@Article{	  howes2014,
  title		= {Utility Maximization and Bounds on Human Information
		  Processing},
  author	= {Howes, Andrew and Lewis, Richard L and Singh, Satinder},
  journal	= {Topics in Cognitive Science},
  volume	= {6},
  number	= {2},
  pages		= {198--203},
  year		= {2014},
  publisher	= {John Wiley \& Sons, Inc.},
  doi		= {10.1111/tops.12089}
}

@InProceedings{	  ibarz2018,
  author	= {Ibarz, Borja and Leike, Jan and Pohlen, Tobias and Irving,
		  Geoffrey and Legg, Shane and Amodei, Dario},
  title		= {Reward Learning from Human Preferences and Demonstrations
		  in {A}tari},
  pages		= {8022â€“8034},
  booktitle	= {Proceedings of the 32nd Conference on Neural
		  Information Processing Systems},
  volume	= {31},
  address	= {Montr\'{e}al, Canada},
  year		= {2018},
  publisher	= {Curran Associates, Inc., Red Hook, NY, USA}
}

@InProceedings{	  jeon2020,
  author	= {Jeon, Hong Jun and Milli, Smitha and Dragan, Anca},
  title		= {Reward-Rational (Implicit) Choice: A Unifying Formalism
		  for Reward Learning},
  pages		= {4415--4426},
  booktitle	= {Proceedings of the 34th Conference on Neural
		  Information Processing Systems},
  address	= {Virtual},
  volume	= {33},
  year		= {2020},
  publisher	= {Curran Associates, Inc., Red Hook, NY, USA}
}

@InProceedings{	  kim2021,
  author	= {Kim, Kuno and Garg, Shivam and Shiragur, Kirankumar and
		  Ermon, Stefano},
  title		= {Reward Identification in Inverse Reinforcement Learning},
  pages		= {5496--5505},
  booktitle	= {Proceedings of the 38th International Conference on
		  Machine Learning},
  volume	= {139},
  series	= {Proceedings of Machine Learning Research},
  address	= {Virtual},
  month		= jul,
  year		= {2021},
  publisher	= {PMLR}
}

@InProceedings{	  koppol2020,
  title		= {Iterative Interactive Reward Learning},
  author	= {Koppol, Pallavi and Admoni, Henny and Simmons, Reid},
  booktitle	= {Participatory Approaches to Machine Learning,
		  International Conference on Machine Learning Workshop},
  address	= {Virtual},
  year		= {2020},
  month		= jul
}

@InProceedings{        krasheninnikov2021combining,
      title={Combining Reward Information from Multiple Sources}, 
      author={Dmitrii Krasheninnikov and Rohin Shah and Herke van Hoof},
      month = dec,
      year={2019},
      booktitle={Workshop on Learning with Rich Experience (LIRE), NeurIPS 2019},
      address={Vancouver, Canada},
      note	= {\textit{arXiv preprint,} arXiv:2103.12142 [cs.LG]},
      eprint={2103.12142},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
}



@Article{	  leike2018,
  title		= {Scalable Agent Alignment via Reward Modeling: A Research
		  Direction},
  author	= {Leike, Jan and Krueger, David and Everitt, Tom and Martic,
		  Miljan and Maini, Vishal and Legg, Shane},
  journal	= {arXiv preprint},
  volume	= {arXiv:1811.07871 [cs.LG]},
  year		= {2018}
}

@Article{	  lewbel2019,
  title		= {The Identification Zoo: Meanings of Identification in
		  Econometrics},
  author	= {Lewbel, Arthur},
  journal	= {Journal of Economic Literature},
  volume	= {57},
  number	= {4},
  pages		= {835--903},
  year		= {2019},
  publisher	= {American Economic Association},
  doi		= {10.1257/jel.20181361}
}

@Article{     koopmans1949,
    author  = {Tjalling C. Koopmans},
    journal = {Econometrica},
    number  = {2},
    pages   = {125--144},
    title   = {Identification Problems in Economic Model Construction},
    volume  = {17},
    year    = {1949},
}

@Book{		  manski1995,
  title		= {Identification Problems in the Social Sciences},
  author	= {Manski, Charles F},
  year		= {1995},
  publisher	= {Harvard University Press},
  isbn		= {9780674442849}
}

@Book{		  manski2003,
  title		= {Partial Identification of Probability Distributions},
  author	= {Manski, Charles F},
  year		= {2003},
  publisher	= {Springer},
  isbn		= {0387004548}
}

@InProceedings{	  morimura2010nonpara,
  title		= {Nonparametric Return Distribution Approximation for
		  Reinforcement Learning},
  author	= {Morimura, Tetsuro and Sugiyama, Masashi and Kashima,
		  Hisashi and Hachiya, Hirotaka and Tanaka, Toshiyuki},
  pages		= {799--806},
  booktitle	= {Proceedings of the 27th International Conference on
		  Machine Learning},
  address	= {Haifa, Israel},
  month		= jun,
  year		= {2010},
  publisher	= {Omnipress, Madison, Wisconsin, USA}
}

@InProceedings{	  morimura2010para,
  title		= {Parametric Return Density Estimation for Reinforcement
		  Learning},
  author	= {Morimura, Tetsuro and Sugiyama, Masashi and Kashima,
		  Hisashi and Hachiya, Hirotaka and Tanaka, Toshiyuki},
  year		= {2010},
  publisher	= {AUAI Press, Arlington, Virginia, USA},
  booktitle	= {Proceedings of the Twenty-Sixth Conference on Uncertainty
		  in Artificial Intelligence},
  pages		= {368--375},
  address	= {Catalina Island, California, USA}
}

@InProceedings{	  ng1999,
  title		= {Policy Invariance Under Reward Transformations: Theory and
		  Application to Reward Shaping},
  author	= {Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  pages		= {278--287},
  booktitle	= {Proceedings of the Sixteenth International Conference on
		  Machine Learning},
  address	= {Bled, Slovenia},
  year		= {1999},
  publisher	= {Morgan Kaufmann Publishers Inc., San Francisco, CA, USA}
}

@InProceedings{	  ng2000,
  title		= {Algorithms for Inverse Reinforcement Learning},
  author	= {Ng, Andrew Y and Russell, Stuart},
  pages		= {663--670},
  booktitle	= {Proceedings of the Seventeenth International Conference on
		  Machine Learning},
  address	= {Stanford, California, USA},
  volume	= {1},
  year		= {2000},
  publisher	= {Morgan Kaufmann Publishers Inc., San Francisco,
		  California, USA}
}

@Article{	  odonoghue2016,
  title		= {Combining policy gradient and {Q}-learning},
  author	= {O'Donoghue, Brendan and Munos, Remi and Kavukcuoglu, Koray
		  and Mnih, Volodymyr},
  journal	= {arXiv preprint arXiv:1611.01626},
  year		= {2016}
}

@InProceedings{	  orsini2021,
  title		= {What Matters for Adversarial Imitation Learning?},
  author	= {Manu Orsini and Anton Raichuk and L{\'e}onard Hussenot and
		  Damien Vincent and Robert Dadashi and Sertan Girgin and
		  Matthieu Geist and Olivier Bachem and Olivier Pietquin and
		  Marcin Andrychowicz},
  pages = {14656--14668},  
  year		= {2021},
  volume    = {34},
  booktitle	= {Proceedings of the 35th Conference on Neural Information Processing Systems},
  address	= {Virtual},
  publisher	= {Curran Associates, Inc., Red Hook, NY, USA}
}
%
%
%

@InProceedings{	  palan2019,
  title		= {Learning Reward Functions by Integrating Human
		  Demonstrations and Preferences},
  author	= {Palan, Malayandi and Landolfi, Nicholas Charles and
		  Shevchuk, Gleb and Sadigh, Dorsa},
  booktitle	= {Proceedings of Robotics: Science and Systems},
  address	= {Freiburg im Breisgau, Germany},
  month		= jun,
  year		= {2019},
  doi		= {10.15607/RSS.2019.XV.023}
}

@InProceedings{	  peng2020,
  author	= {Peng, Xue Bin and Coumans, Erwin and Zhang, Tingnan and
		  Lee, Tsang-Wei Edward and Tan, Jie and Levine, Sergey},
  booktitle	= {Robotics: Science and Systems},
  year		= {2020},
  month		= {07},
  title		= {Learning Agile Robotic Locomotion Skills by Imitating
		  Animals},
  doi		= {10.15607/RSS.2020.XVI.064}
}

@Article{	  peterson2021,
  title		= {Using Large-Scale Experiments and Machine Learning to
		  Discover Theories of Human Decision-Making},
  author	= {Peterson, Joshua C and Bourgin, David D and Agrawal,
		  Mayank and Reichman, Daniel and Griffiths, Thomas L},
  journal	= {Science},
  volume	= {372},
  number	= {6547},
  pages		= {1209--1214},
  year		= {2021},
  publisher	= {American Association for the Advancement of Science},
  doi		= {10.1126/science.abe2629}
}

@InProceedings{	  ramachandran2007,
  title		= {Bayesian Inverse Reinforcement Learning},
  author	= {Ramachandran, Deepak and Amir, Eyal},
  pages		= {2586--2591},
  booktitle	= {Proceedings of the 20th International Joint Conference on
		  Artifical Intelligence},
  address	= {Hyderabad, India},
  year		= {2007},
  publisher	= {Morgan Kaufmann Publishers Inc., San Francisco,
		  California, USA}
}

@InProceedings{	  rothkopf2011,
  title		= {Preference Elicitation and Inverse Reinforcement
		  Learning},
  author	= {Rothkopf, Constantin A and Dimitrakakis, Christos},
  booktitle	= {Machine Learning and Knowledge Discovery in Databases:
		  ECML PKDD 2011, Proceedings, Part III},
  series	= {Lecture Notes in Computer Science},
  volume	= {6913},
  pages		= {34--48},
  year		= {2011},
  organization	= {Springer},
  doi		= {10.1007/978-3-642-23808-6_3},
  address	= {Athens, Greece}
}

@InProceedings{	  russell1998,
  title		= {Learning Agents for Uncertain Environments (Extended
		  Abstract)},
  author	= {Russell, Stuart},
  booktitle	= {Proceedings of the Eleventh Annual Conference on
		  Computational Learning Theory},
  pages		= {101--103},
  year		= {1998},
  publisher	= {Association for Computing Machinery},
  doi		= {10.1145/279943.279964},
  address	= {Madison, Wisconsin, USA}
}

@InCollection{	  rust1994,
  title		= {Structural estimation of {Markov} decision processes},
  author	= {Rust, John},
  booktitle	= {Handbook of Econometrics},
  editor	= {Engle, Robert F. and McFadden, Daniel L.},
  volume	= {4},
  pages		= {3081--3143},
  year		= {1994},
  publisher	= {Elsevier},
  doi		= {10.1016/S1573-4412(05)80020-0}
}

@Article{	  schoemaker1982,
  title		= {The Expected Utility Model: Its Variants, Purposes,
		  Evidence and Limitations},
  author	= {Schoemaker, Paul J. H.},
  journal	= {Journal of Economic Literature},
  volume	= {20},
  number	= {2},
  pages		= {529--563},
  year		= {1982},
  publisher	= {American Economic Association}
}

@InProceedings{	  shah2019,
  author	= {Shah, Rohin and Gundotra, Noah and Abbeel, Pieter and
		  Dragan, Anca},
  title		= {On the Feasibility of Learning, Rather than Assuming,
		  Human Biases for Reward Inference},
  pages		= {5670--5679},
  booktitle	= {Proceedings of the 36th International Conference on
		  Machine Learning},
  volume	= {97},
  series	= {Proceedings of Machine Learning Research},
  address	= {Long Beach, California, USA},
  year		= {2019},
  month		= jun,
  publisher	= {PMLR}
}

@InProceedings{	  singh2019,
  title		= {End-to-End Robotic Reinforcement Learning Without Reward
		  Engineering},
  author	= {Singh, Avi and Yang, Larry and Hartikainen, Kristian and
		  Finn, Chelsea and Levine, Sergey},
  booktitle	= {Proceedings of Robotics: Science and Systems},
  address	= {Freiburg im Breisgau, Germany},
  month		= jun,
  year		= {2019},
  doi		= {10.15607/RSS.2019.XV.073}
}

@Article{	  srisuma2015,
  title		= {Identification in Discrete {M}arkov Decision Models},
  author	= {Srisuma, Sorawoot},
  journal	= {Econometric Theory},
  volume	= {31},
  number	= {3},
  pages		= {521--538},
  year		= {2015},
  publisher	= {Cambridge University Press},
  doi		= {10.1017/S0266466614000437}
}

@InProceedings{	  stiennon2020,
  title		= {Learning to Summarize from Human Feedback},
  author	= {Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and
		  Ziegler, Daniel M and Lowe, Ryan and Voss, Chelsea and
		  Radford, Alec and Amodei, Dario and Christiano, Paul F},
  pages		= {3008--3021},
  booktitle	= {Proceedings of the 34th Conference on Neural
		  Information Processing Systems},
  volume	= {33},
  address	= {Virtual},
  year		= {2020},
  publisher	= {Curran Associates, Inc., Red Hook, NY, USA}
}

@Book{		  sutton2018,
  title		= {Reinforcement Learning: An Introduction},
  author	= {Sutton, Richard S and Barto, Andrew G},
  year		= {2018},
  edition	= {second},
  publisher	= {MIT Press},
  isbn		= {9780262352703}
}

@Article{	  tamer2010,
  title		= {Partial Identification in Econometrics},
  author	= {Tamer, Elie},
  journal	= {Annual Review of Economics},
  volume	= {2},
  pages		= {167--195},
  year		= {2010},
  publisher	= {Annual Reviews},
  doi		= {10.1146/annurev.economics.050708.143401}
}

@InProceedings{	  tung2018,
  title		= {Reward Learning from Narrated Demonstrations},
  author	= {Tung, Hsiao-Yu and Harley, Adam W and Huang, Liang-Kang
		  and Fragkiadaki, Katerina},
  pages		= {7004--7013},
  booktitle	= {Proceedings: 2018 IEEE/CVF Conference on Computer Vision
		  and Pattern Recognition (CVPR)},
  month		= jun,
  year		= {2018},
  address	= {Salt Lake City, Utah, USA},
  publisher	= {IEEE Computer Society, Los Alamitos, CA, USA},
  doi		= {10.1109/CVPR.2018.00732}
}

@Book{		  vnm2,
  title		= {Theory of Games and Economic Behavior},
  author	= {von Neumann, John and Morgenstern, Oskar},
  edition	= {second revised},
  year		= {1947},
  publisher	= {Princeton University Press}
}

@InProceedings{	  wiewiora2003,
  title		= {Principled Methods for Advising Reinforcement Learning
		  Agents},
  author	= {Wiewiora, Eric and Cottrell, Garrison W and Elkan,
		  Charles},
  pages		= {792--799},
  booktitle	= {Proceedings of the Twentieth International Conference on
		  Machine Learning},
  address	= {Washington, D.C., USA},
  month		= aug,
  year		= {2003},
  publisher	= {AAAI Press}
}

@Article{	  wirth2017,
  title		= {A Survey of Preference-Based Reinforcement Learning
		  Methods},
  author	= {Wirth, Christian and Akrour, Riad and Neumann, Gerhard and
		  F{\"u}rnkranz, Johannes},
  journal	= {Journal of Machine Learning Research},
  volume	= {18},
  number	= {1},
  pages		= {4945--4990},
  month		= jan,
  year		= {2017},
  publisher	= {JMLR}
}

@Article{	  yang2019,
  title		= {Imitation learning from observations by minimizing inverse
		  dynamics disagreement},
  author	= {Yang, Chao and Ma, Xiaojian and Huang, Wenbing and Sun,
		  Fuchun and Liu, Huaping and Huang, Junzhou and Gan,
		  Chuang},
  journal	= {arXiv preprint arXiv:1910.04417},
  year		= {2019}
}

@Article{	  zhang2019,
  title		= {Leveraging human guidance for deep reinforcement learning
		  tasks},
  author	= {Zhang, Ruohan and Torabi, Faraz and Guan, Lin and Ballard,
		  Dana H and Stone, Peter},
  journal	= {arXiv preprint arXiv:1909.09906},
  year		= {2019}
}

@InProceedings{	  ziebart2008,
  title		= {Maximum entropy inverse reinforcement learning},
  author	= {Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew
		  and Dey, Anind K},
  booktitle	= {23rd AAAI Conference on Artificial Intelligence},
  volume	= {8},
  pages		= {1433--1438},
  year		= {2008}
}

@InProceedings{	  ziebart2010paper,
  author	= {Ziebart, Brian D and Bagnell, J Andrew and Dey, Anind K},
  title		= {Modeling Interaction via the Principle of Maximum Causal
		  Entropy},
  pages		= {1255--1262},
  month		= jun,
  year		= {2010},
  booktitle	= {Proceedings of the 27th International Conference on
		  Machine Learning},
  address	= {Haifa, Israel},
  publisher	= {Omnipress, Madison, Wisconsin, USA}
}

@PhDThesis{	  ziebart2010thesis,
  author	= {Ziebart, Brian D},
  title		= {Modeling Purposeful Adaptive Behavior with the Principle
		  of Maximum Causal Entropy},
  school	= {Carnegie Mellon University},
  year		= {2010}
}

