\begin{thebibliography}{36}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Achille \& Soatto(2018)Achille and Soatto]{achille2018information}
Achille, A. and Soatto, S.
\newblock Information dropout: Learning optimal representations through noisy
  computation.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2018.

\bibitem[Alemi et~al.(2017)Alemi, Fischer, Dillon, and
  Murphy]{alemi2016bottleneck}
Alemi, A.~A., Fischer, I., Dillon, J.~V., and Murphy, K.
\newblock Deep variational information bottleneck.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and Bottou]{wgan}
Arjovsky, M., Chintala, S., and Bottou, L.
\newblock Wasserstein generative adversarial networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  214--223, 2017.

\bibitem[Athalye et~al.(2018)Athalye, Carlini, and
  Wagner]{athalye2018obfuscate}
Athalye, A., Carlini, N., and Wagner, D.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In Dy, J. and Krause, A. (eds.), \emph{Proceedings of the 35th
  International Conference on Machine Learning}, volume~80 of \emph{Proceedings
  of Machine Learning Research}, pp.\  274--283, Stockholmsm√§ssan, Stockholm
  Sweden, 10--15 Jul 2018. PMLR.
\newblock URL \url{http://proceedings.mlr.press/v80/athalye18a.html}.

\bibitem[Bartlett \& Shawe-taylor(1998)Bartlett and
  Shawe-taylor]{bartlett1998generalization}
Bartlett, P. and Shawe-taylor, J.
\newblock Generalization performance of support vector machines and other
  pattern classifiers, 1998.

\bibitem[Bartunov et~al.(2018)Bartunov, Santoro, Richards, Hinton, and
  Lillicrap]{Bartunov-et-al-2018}
Bartunov, S., Santoro, A., Richards, B.~A., Hinton, G.~E., and Lillicrap, T.
\newblock Assessing the scalability of biologically-motivated deep learning
  algorithms and architectures.
\newblock \emph{submitted to ICLR'2018}, 2018.

\bibitem[Belghazi et~al.(2018)Belghazi, Rajeswar, Baratin, Hjelm, and
  Courville]{belghazi2018mine}
Belghazi, I., Rajeswar, S., Baratin, A., Hjelm, R.~D., and Courville, A.~C.
\newblock {MINE:} mutual information neural estimation.
\newblock \emph{CoRR}, abs/1801.04062, 2018.
\newblock URL \url{http://arxiv.org/abs/1801.04062}.

\bibitem[Ben-David et~al.(2010)Ben-David, Blitzer, Crammer, Kulesza, Pereira,
  and Vaughan]{ben2010theory}
Ben-David, S., Blitzer, J., Crammer, K., Kulesza, A., Pereira, F., and Vaughan,
  J.~W.
\newblock A theory of learning from different domains.
\newblock \emph{Machine learning}, 79\penalty0 (1-2):\penalty0 151--175, 2010.

\bibitem[Cybenko(1989)]{cybenko1989approximation}
Cybenko, G.
\newblock Approximation by superpositions of a sigmoidal function.
\newblock \emph{Mathematics of control, signals and systems}, 2\penalty0
  (4):\penalty0 303--314, 1989.

\bibitem[Devries \& Taylor(2017)Devries and Taylor]{cutout}
Devries, T. and Taylor, G.~W.
\newblock Improved regularization of convolutional neural networks with cutout.
\newblock \emph{CoRR}, abs/1708.04552, 2017.
\newblock URL \url{http://arxiv.org/abs/1708.04552}.

\bibitem[{Goodfellow} et~al.(2015){Goodfellow}, {Shlens}, and
  {Szegedy}]{goodfellow2014adv}
{Goodfellow}, I.~J., {Shlens}, J., and {Szegedy}, C.
\newblock {Explaining and Harnessing Adversarial Examples}.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Goyal et~al.(2018)Goyal, Islam, Strouse, Ahmed, Larochelle, Botvinick,
  Levine, and Bengio]{goyal2018transfer}
Goyal, A., Islam, R., Strouse, D., Ahmed, Z., Larochelle, H., Botvinick, M.,
  Levine, S., and Bengio, Y.
\newblock Transfer and exploration via the information bottleneck.
\newblock 2018.

\bibitem[Gulrajani et~al.(2017)Gulrajani, Ahmed, Arjovsky, Dumoulin, and
  Courville]{wgan_gp}
Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., and Courville, A.~C.
\newblock Improved training of wasserstein gans.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  5769--5779, 2017.

\bibitem[Guo et~al.(2016)Guo, Mao, and Zhang]{adamix}
Guo, H., Mao, Y., and Zhang, R.
\newblock {MixUp as Locally Linear Out-Of-Manifold Regularization}.
\newblock \emph{ArXiv e-prints}, 2016.
\newblock URL \url{https://arxiv.org/abs/1809.02499}.

\bibitem[{Guo} et~al.(2018{\natexlab{a}}){Guo}, {Mao}, and
  {Zhang}]{guo2018adamix}
{Guo}, H., {Mao}, Y., and {Zhang}, R.
\newblock {MixUp as Locally Linear Out-Of-Manifold Regularization}.
\newblock \emph{ArXiv e-prints}, September 2018{\natexlab{a}}.

\bibitem[{Guo} et~al.(2018{\natexlab{b}}){Guo}, {Mao}, and
  {Zhang}]{guo2018agrlearn}
{Guo}, H., {Mao}, Y., and {Zhang}, R.
\newblock {Aggregated Learning: A Vector Quantization Approach to Learning with
  Neural Networks}.
\newblock \emph{ArXiv e-prints}, July 2018{\natexlab{b}}.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016identity}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Identity mappings in deep residual networks.
\newblock In \emph{ECCV}, 2016.

\bibitem[Hinton et~al.(2012)Hinton, Srivastava, Krizhevsky, Sutskever, and
  Salakhutdinov]{hinton2012dropout}
Hinton, G.~E., Srivastava, N., Krizhevsky, A., Sutskever, I., and
  Salakhutdinov, R.
\newblock Improving neural networks by preventing co-adaptation of feature
  detectors.
\newblock \emph{CoRR}, abs/1207.0580, 2012.
\newblock URL \url{http://arxiv.org/abs/1207.0580}.

\bibitem[Ioffe \& Szegedy(2015)Ioffe and Szegedy]{ioffe2015bn}
Ioffe, S. and Szegedy, C.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In \emph{ICML}, 2015.

\bibitem[LeCun et~al.(2015)LeCun, Bengio, and Hinton]{lecun2015deep}
LeCun, Y., Bengio, Y., and Hinton, G.
\newblock Deep learning.
\newblock \emph{nature}, 521\penalty0 (7553):\penalty0 436, 2015.

\bibitem[Lee et~al.(2015)Lee, Zhang, Fischer, and
  Bengio]{Lee-et-al-MLKDB2015-small}
Lee, D.-H., Zhang, S., Fischer, A., and Bengio, Y.
\newblock Difference target propagation.
\newblock In \emph{Machine Learning and Knowledge Discovery in Databases
  (ECML/PKDD)}. 2015.

\bibitem[Lee et~al.(1995)Lee, Bartlett, and Williamson]{lee1995vcsmooth}
Lee, W.~S., Bartlett, P.~L., and Williamson, R.~C.
\newblock Lower bounds on the vc dimension of smoothly parameterized function
  classes.
\newblock \emph{Neural Computation}, 7\penalty0 (5):\penalty0 1040--1053, Sep.
  1995.
\newblock ISSN 0899-7667.
\newblock \doi{10.1162/neco.1995.7.5.1040}.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2017adv}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=rJzIBfZAb}.

\bibitem[Mikolov et~al.(2013)Mikolov, Chen, Corrado, and
  Dean]{mikolov2013wordembed}
Mikolov, T., Chen, K., Corrado, G., and Dean, J.
\newblock Efficient estimation of word representations in vector space.
\newblock In \emph{International Conference on Learning Representations}, 2013.

\bibitem[Miyato et~al.(2018)Miyato, Kataoka, Koyama, and Yoshida]{spec_norm}
Miyato, T., Kataoka, T., Koyama, M., and Yoshida, Y.
\newblock Spectral normalization for generative adversarial networks.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=B1QRgziT-}.

\bibitem[Salimans et~al.(2016)Salimans, Goodfellow, Zaremba, Cheung, Radford,
  and Chen]{improved_techniques}
Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., and Chen,
  X.
\newblock Improved techniques for training gans.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  2234--2242, 2016.

\bibitem[Scellier \& Bengio(2017)Scellier and
  Bengio]{Scellier+Bengio-frontiers2017}
Scellier, B. and Bengio, Y.
\newblock Equilibrium propagation: Bridging the gap between energy-based models
  and backpropagation.
\newblock \emph{Frontiers in computational neuroscience}, 11, 2017.

\bibitem[Shwartz{-}Ziv \& Tishby(2017)Shwartz{-}Ziv and
  Tishby]{shwartz2017info}
Shwartz{-}Ziv, R. and Tishby, N.
\newblock Opening the black box of deep neural networks via information.
\newblock \emph{CoRR}, abs/1703.00810, 2017.
\newblock URL \url{http://arxiv.org/abs/1703.00810}.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013adv}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Tishby \& Zaslavsky(2015)Tishby and Zaslavsky]{tishby2015info}
Tishby, N. and Zaslavsky, N.
\newblock Deep learning and the information bottleneck principle.
\newblock \emph{CoRR}, abs/1503.02406, 2015.
\newblock URL \url{http://arxiv.org/abs/1503.02406}.

\bibitem[Tokozume et~al.(2018)Tokozume, Ushiku, and
  Harada]{tokozume2017betweenclass}
Tokozume, Y., Ushiku, Y., and Harada, T.
\newblock Between-class learning for image classification.
\newblock In \emph{The IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, June 2018.

\bibitem[Wang et~al.(2018)Wang, Luo, Li, Zhu, Shi, and
  Osher]{wang2018interpolate}
Wang, B., Luo, X., Li, Z., Zhu, W., Shi, Z., and Osher, S.~J.
\newblock Deep learning with data dependent implicit activation function.
\newblock \emph{CoRR}, abs/1802.00168, 2018.
\newblock URL \url{http://arxiv.org/abs/1802.00168}.

\bibitem[Whittington \& Bogacz(2017)Whittington and
  Bogacz]{Whittington+Bogacz-2018}
Whittington, J.~C. and Bogacz, R.
\newblock An approximation of the error backpropagation algorithm in a
  predictive coding network with local hebbian synaptic plasticity.
\newblock \emph{Neural computation}, 2017.

\bibitem[Zeiler \& Fergus(2013)Zeiler and Fergus]{zeiler2013visual}
Zeiler, M.~D. and Fergus, R.
\newblock Visualizing and understanding convolutional networks.
\newblock \emph{CoRR}, abs/1311.2901, 2013.
\newblock URL \url{http://arxiv.org/abs/1311.2901}.

\bibitem[Zhang et~al.(2018)Zhang, Cisse, Dauphin, and
  Lopez-Paz]{zhang2017mixup}
Zhang, H., Cisse, M., Dauphin, Y.~N., and Lopez-Paz, D.
\newblock mixup: Beyond empirical risk minimization.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=r1Ddp1-Rb}.

\bibitem[Zhao \& Cho(2018)Zhao and Cho]{zhao2018retrieve}
Zhao, J. and Cho, K.
\newblock Retrieval-augmented convolutional neural networks for improved
  robustness against adversarial examples.
\newblock \emph{CoRR}, abs/1802.09502, 2018.
\newblock URL \url{http://arxiv.org/abs/1802.09502}.

\end{thebibliography}
