\begin{thebibliography}{10}

\bibitem{bertoin2022sgqn}
David Bertoin, Adil Zouitine, Mehdi Zouitine, and Emmanuel Rachelson.
\newblock Look where you look! saliency-guided q-networks for generalization in
  visual reinforcement learning.
\newblock {\em NeurIPS}, 2022.

\bibitem{chen2021unsupervised}
Boyuan Chen, Pieter Abbeel, and Deepak Pathak.
\newblock Unsupervised learning of visual 3d keypoints for control.
\newblock In {\em ICML}, 2021.

\bibitem{dasari2019robonet}
Sudeep Dasari, Frederik Ebert, Stephen Tian, Suraj Nair, Bernadette Bucher,
  Karl Schmeckpeper, Siddharth Singh, Sergey Levine, and Chelsea Finn.
\newblock Robonet: Large-scale multi-robot learning.
\newblock {\em CoRL}, 2019.

\bibitem{driess2022nerfrl}
Danny Driess, Ingmar Schubert, Pete Florence, Yunzhu Li, and Marc Toussaint.
\newblock Reinforcement learning with neural radiance fields.
\newblock {\em arXiv}, 2022.

\bibitem{gandelsman2022tttmae}
Yossi Gandelsman, Yu~Sun, Xinlei Chen, and Alexei Efros.
\newblock Test-time training with masked autoencoders.
\newblock {\em NeurIPS}, 2022.

\bibitem{hafner2020dreamer}
Danijar Hafner, Timothy Lillicrap, Mohammad Norouzi, and Jimmy Ba.
\newblock Mastering atari with discrete world models.
\newblock {\em arXiv}, 2020.

\bibitem{hansen2021pad}
Nicklas Hansen, Rishabh Jangir, Yu~Sun, Guillem Aleny{\`a}, Pieter Abbeel,
  Alexei~A Efros, Lerrel Pinto, and Xiaolong Wang.
\newblock Self-supervised policy adaptation during deployment.
\newblock {\em ICLR}, 2021.

\bibitem{hansen2022modem}
Nicklas Hansen, Yixin Lin, Hao Su, Xiaolong Wang, Vikash Kumar, and Aravind
  Rajeswaran.
\newblock Modem: Accelerating visual model-based reinforcement learning with
  demonstrations.
\newblock {\em ICLR}, 2023.

\bibitem{hansen2021svea}
Nicklas Hansen, Hao Su, and Xiaolong Wang.
\newblock Stabilizing deep q-learning with convnets and vision transformers
  under data augmentation.
\newblock {\em NeurIPS}, 2021.

\bibitem{hansen2021soda}
Nicklas Hansen and Xiaolong Wang.
\newblock Generalization in reinforcement learning by soft data augmentation.
\newblock In {\em International Conference on Robotics and Automation}, 2021.

\bibitem{hansen2022tdmpc}
Nicklas Hansen, Xiaolong Wang, and Hao Su.
\newblock Temporal difference learning for model predictive control.
\newblock {\em ICML}, 2022.

\bibitem{hansen2022lfs}
Nicklas Hansen, Zhecheng Yuan, Yanjie Ze, Tongzhou Mu, Aravind Rajeswaran, Hao
  Su, Huazhe Xu, and Xiaolong Wang.
\newblock On pre-training for visuo-motor control: Revisiting a
  learning-from-scratch baseline.
\newblock {\em ICML}, 2023.

\bibitem{jaderberg2015stn}
Max Jaderberg, Karen Simonyan, Andrew Zisserman, et~al.
\newblock Spatial transformer networks.
\newblock {\em NeurIPS}, 2015.

\bibitem{laskin2020rad}
Misha Laskin, Kimin Lee, Adam Stooke, Lerrel Pinto, Pieter Abbeel, and Aravind
  Srinivas.
\newblock Reinforcement learning with augmented data.
\newblock {\em NeurIPS}, 2020.

\bibitem{lee2019network}
Kimin Lee, Kibok Lee, Jinwoo Shin, and Honglak Lee.
\newblock Network randomization: A simple technique for generalization in deep
  reinforcement learning.
\newblock {\em arXiv preprint arXiv:1910.05396}, 2019.

\bibitem{li20223d}
Yunzhu Li, Shuang Li, Vincent Sitzmann, Pulkit Agrawal, and Antonio Torralba.
\newblock 3d neural scene representations for visuomotor control.
\newblock In {\em CoRL}, 2022.

\bibitem{mnih2013playing}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis
  Antonoglou, Daan Wierstra, and Martin Riedmiller.
\newblock Playing atari with deep reinforcement learning.
\newblock {\em arXiv}, 2013.

\bibitem{mnih2015human}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei~A Rusu, Joel Veness,
  Marc~G Bellemare, Alex Graves, Martin Riedmiller, Andreas~K Fidjeland, Georg
  Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock {\em Nature}, 2015.

\bibitem{peng2018sim}
Xue~Bin Peng, Marcin Andrychowicz, Wojciech Zaremba, and Pieter Abbeel.
\newblock Sim-to-real transfer of robotic control with dynamics randomization.
\newblock In {\em ICRA}, 2018.

\bibitem{rajeswaran2017dapg}
Aravind Rajeswaran, Vikash Kumar, Abhishek Gupta, Giulia Vezzani, John
  Schulman, Emanuel Todorov, and Sergey Levine.
\newblock Learning complex dexterous manipulation with deep reinforcement
  learning and demonstrations.
\newblock {\em RSS}, 2018.

\bibitem{ramos2019bayessim}
Fabio Ramos, Rafael~Carvalhaes Possas, and Dieter Fox.
\newblock Bayessim: adaptive domain randomization via probabilistic inference
  for robotics simulators.
\newblock {\em arXiv}, 2019.

\bibitem{shah2021rrl}
Rutav Shah and Vikash Kumar.
\newblock Rrl: Resnet as representation for reinforcement learning.
\newblock {\em ICML}, 2021.

\bibitem{shang2021self}
Jinghuan Shang and Michael~S Ryoo.
\newblock Self-supervised disentangled representation learning for third-person
  imitation learning.
\newblock In {\em IROS}, 2021.

\bibitem{sharma2019third}
Pratyusha Sharma, Deepak Pathak, and Abhinav Gupta.
\newblock Third-person visual imitation learning via decoupled hierarchical
  controller.
\newblock {\em NeurIPS}, 2019.

\bibitem{stadie2017third}
Bradly~C Stadie, Pieter Abbeel, and Ilya Sutskever.
\newblock Third-person imitation learning.
\newblock {\em ICLR}, 2017.

\bibitem{stone2021distracting}
Austin Stone, Oscar Ramirez, Kurt Konolige, and Rico Jonschkowski.
\newblock The distracting control suite--a challenging benchmark for
  reinforcement learning from pixels.
\newblock {\em arXiv}, 2021.

\bibitem{sun2021online}
Yu~Sun, Wyatt~L Ubellacker, Wen-Loong Ma, Xiang Zhang, Changhao Wang, Noel~V
  Csomay-Shanklin, Masayoshi Tomizuka, Koushil Sreenath, and Aaron~D Ames.
\newblock Online learning of unknown dynamics for model-based controllers in
  legged locomotion.
\newblock {\em RA-L}, 2021.

\bibitem{sun2020ttt}
Yu~Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt.
\newblock Test-time training with self-supervision for generalization under
  distribution shifts.
\newblock In {\em ICML}, 2020.

\bibitem{sun2019test}
Yu~Sun, Xiaolong Wang, Liu Zhuang, John Miller, Moritz Hardt, and Alexei~A.
  Efros.
\newblock Test-time training with self-supervision for generalization under
  distribution shifts.
\newblock In {\em ICML}, 2020.

\bibitem{tassa2018dmc}
Yuval Tassa, Yotam Doron, Alistair Muldal, Tom Erez, Yazhe Li, Diego de~Las
  Casas, David Budden, Abbas Abdolmaleki, Josh Merel, Andrew Lefrancq, et~al.
\newblock Deepmind control suite.
\newblock {\em arXiv}, 2018.

\bibitem{tobin2017domain}
Josh Tobin, Rachel Fong, Alex Ray, Jonas Schneider, Wojciech Zaremba, and
  Pieter Abbeel.
\newblock Domain randomization for transferring deep neural networks from
  simulation to the real world.
\newblock In {\em IROS}, 2017.

\bibitem{tung20203d}
Hsiao-Yu~Fish Tung, Zhou Xian, Mihir Prabhudesai, Shamit Lal, and Katerina
  Fragkiadaki.
\newblock 3d-oes: Viewpoint-invariant object-factorized environment simulators.
\newblock {\em arXiv}, 2020.

\bibitem{wang2020improving}
Kaixin Wang, Bingyi Kang, Jie Shao, and Jiashi Feng.
\newblock Improving generalization in reinforcement learning with mixture
  regularization.
\newblock {\em NeurIPS}, 2020.

\bibitem{yang2021learning}
Ruihan Yang, Minghao Zhang, Nicklas Hansen, Huazhe Xu, and Xiaolong Wang.
\newblock Learning vision-guided quadrupedal locomotion end-to-end with
  cross-modal transformers.
\newblock {\em ICLR}, 2021.

\bibitem{yarats2021drqv2}
Denis Yarats, Rob Fergus, Alessandro Lazaric, and Lerrel Pinto.
\newblock Mastering visual continuous control: Improved data-augmented
  reinforcement learning.
\newblock {\em arXiv}, 2021.

\bibitem{yuan2022pieg}
Zhecheng Yuan, Zhengrong Xue, Bo~Yuan, Xueqian Wang, Yi~Wu, Yang Gao, and
  Huazhe Xu.
\newblock Pre-trained image encoder for generalizable visual reinforcement
  learning.
\newblock {\em NeurIPS}, 2022.

\bibitem{ze2023rl3d}
Yanjie Ze, Nicklas Hansen, Yinbo Chen, Mohit Jain, and Xiaolong Wang.
\newblock Visual reinforcement learning with self-supervised 3d
  representations.
\newblock {\em RA-L}, 2023.

\end{thebibliography}
