\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aberdam et~al.(2020)Aberdam, Simon, and Elad]{aberdam2020and}
Aviad Aberdam, Dror Simon, and Michael Elad.
\newblock When and how can deep generative models be inverted?
\newblock \emph{arXiv preprint arXiv:2006.15555}, 2020.

\bibitem[Ambrosio and Gigli(2013)]{Ambrosio1}
Luigi Ambrosio and Nicola Gigli.
\newblock A user's guide to optimal transport.
\newblock In \emph{Modelling and optimisation of flows on networks}, volume
  2062 of \emph{Lecture Notes in Math.}, pages 1--155. Springer, Heidelberg,
  2013.
\newblock \doi{10.1007/978-3-642-32160-3\_1}.
\newblock URL \url{https://doi.org/10.1007/978-3-642-32160-3_1}.

\bibitem[Ambrosio et~al.(2008)Ambrosio, Gigli, and
  Savar{\'e}]{ambrosio2008gradient}
Luigi Ambrosio, Nicola Gigli, and Giuseppe Savar{\'e}.
\newblock \emph{Gradient flows: in metric spaces and in the space of
  probability measures}.
\newblock Springer Science \& Business Media, 2008.

\bibitem[Ardizzone et~al.(2018)Ardizzone, Kruse, Wirkert, Rahner, Pellegrini,
  Klessen, Maier-Hein, Rother, and K{\"o}the]{ardizzone2018analyzing}
Lynton Ardizzone, Jakob Kruse, Sebastian Wirkert, Daniel Rahner, Eric~W
  Pellegrini, Ralf~S Klessen, Lena Maier-Hein, Carsten Rother, and Ullrich
  K{\"o}the.
\newblock Analyzing inverse problems with invertible neural networks.
\newblock \emph{arXiv preprint arXiv:1808.04730}, 2018.

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and
  Bottou]{arjovsky2017wasserstein}
Martin Arjovsky, Soumith Chintala, and L{\'e}on Bottou.
\newblock Wasserstein gan.
\newblock \emph{arXiv preprint arXiv:1701.07875}, 2017.

\bibitem[Arridge et~al.(2019)Arridge, Maass, {\"O}ktem, and
  Sch{\"o}nlieb]{arridge2019solving}
Simon Arridge, Peter Maass, Ozan {\"O}ktem, and Carola-Bibiane Sch{\"o}nlieb.
\newblock Solving inverse problems using data-driven models.
\newblock \emph{Acta Numerica}, 28:\penalty0 1--174, 2019.

\bibitem[Billingsley(1999)]{Billingsley}
Patrick Billingsley.
\newblock \emph{Convergence of probability measures}.
\newblock Wiley Series in Probability and Statistics: Probability and
  Statistics. John Wiley \& Sons, Inc., New York, second edition, 1999.
\newblock ISBN 0-471-19745-9.
\newblock \doi{10.1002/9780470316962}.
\newblock URL \url{https://doi.org/10.1002/9780470316962}.
\newblock A Wiley-Interscience Publication.

\bibitem[Bora et~al.(2017)Bora, Jalal, Price, and Dimakis]{bora2017compressed}
Ashish Bora, Ajil Jalal, Eric Price, and Alexandros~G Dimakis.
\newblock Compressed sensing using generative models.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 537--546. JMLR. org, 2017.

\bibitem[Brehmer and Cranmer(2020)]{brehmer2020flows}
Johann Brehmer and Kyle Cranmer.
\newblock Flows for simultaneous manifold learning and density estimation.
\newblock \emph{arXiv preprint arXiv:2003.13913}, 2020.

\bibitem[Bui Thi~Mai and Lampert(2020)]{bui2020functional}
Phuong Bui Thi~Mai and Christoph Lampert.
\newblock Functional vs. parametric equivalence of relu networks.
\newblock In \emph{8th International Conference on Learning Representations},
  2020.

\bibitem[Cunningham et~al.(2020)Cunningham, Zabounidis, Agrawal, Fiterau, and
  Sheldon]{cunningham2020normalizing}
Edmond Cunningham, Renos Zabounidis, Abhinav Agrawal, Ina Fiterau, and Daniel
  Sheldon.
\newblock Normalizing flows across dimensions.
\newblock \emph{arXiv preprint arXiv:2006.13070}, 2020.

\bibitem[Dinh et~al.(2014)Dinh, Krueger, and Bengio]{dinh2014nice}
Laurent Dinh, David Krueger, and Yoshua Bengio.
\newblock Nice: Non-linear independent components estimation.
\newblock \emph{arXiv preprint arXiv:1410.8516}, 2014.

\bibitem[Dinh et~al.(2016)Dinh, Sohl-Dickstein, and Bengio]{dinh2016density}
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
\newblock Density estimation using real nvp.
\newblock \emph{arXiv preprint arXiv:1605.08803}, 2016.

\bibitem[Durkan et~al.(2019{\natexlab{a}})Durkan, Bekasov, Murray, and
  Papamakarios]{durkan2019cubic}
Conor Durkan, Artur Bekasov, Iain Murray, and George Papamakarios.
\newblock Cubic-spline flows.
\newblock \emph{arXiv preprint arXiv:1906.02145}, 2019{\natexlab{a}}.

\bibitem[Durkan et~al.(2019{\natexlab{b}})Durkan, Bekasov, Murray, and
  Papamakarios]{durkan2019neural}
Conor Durkan, Artur Bekasov, Iain Murray, and George Papamakarios.
\newblock Neural spline flows.
\newblock \emph{Advances in Neural Information Processing Systems},
  32:\penalty0 7511--7522, 2019{\natexlab{b}}.

\bibitem[Golub(1996)]{golub1996matrix}
Gene~H Golub.
\newblock \emph{Matrix computations}.
\newblock Johns Hopkins University Press, 1996.

\bibitem[Gomez et~al.(2017)Gomez, Ren, Urtasun, and
  Grosse]{gomez2017reversible}
Aidan~N Gomez, Mengye Ren, Raquel Urtasun, and Roger~B Grosse.
\newblock The reversible residual network: Backpropagation without storing
  activations.
\newblock In \emph{Advances in neural information processing systems}, pages
  2214--2224, 2017.

\bibitem[Grathwohl et~al.(2018)Grathwohl, Chen, Bettencourt, Sutskever, and
  Duvenaud]{grathwohl2018ffjord}
Will Grathwohl, Ricky~TQ Chen, Jesse Bettencourt, Ilya Sutskever, and David
  Duvenaud.
\newblock Ffjord: Free-form continuous dynamics for scalable reversible
  generative models.
\newblock \emph{arXiv preprint arXiv:1810.01367}, 2018.

\bibitem[Hirsch(2012)]{hirsch2012differential}
Morris~W Hirsch.
\newblock \emph{Differential topology}, volume~33.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Huang et~al.(2018)Huang, Krueger, Lacoste, and
  Courville]{huang2018neural}
Chin-Wei Huang, David Krueger, Alexandre Lacoste, and Aaron Courville.
\newblock Neural autoregressive flows.
\newblock In \emph{International Conference on Machine Learning}, pages
  2078--2087. PMLR, 2018.

\bibitem[Jacobsen et~al.(2018)Jacobsen, Smeulders, and
  Oyallon]{jacobsen2018revnet}
J{\"o}rn-Henrik Jacobsen, Arnold Smeulders, and Edouard Oyallon.
\newblock i-revnet: Deep invertible networks.
\newblock \emph{arXiv preprint arXiv:1802.07088}, 2018.

\bibitem[Jaini et~al.(2019)Jaini, Selby, and Yu]{jaini2019sum}
Priyank Jaini, Kira~A Selby, and Yaoliang Yu.
\newblock Sum-of-squares polynomial flow.
\newblock In \emph{International Conference on Machine Learning}, pages
  3009--3018. PMLR, 2019.

\bibitem[Kingma et~al.(2016)Kingma, Salimans, Jozefowicz, Chen, Sutskever, and
  Welling]{kingma2016improving}
Diederik~P Kingma, Tim Salimans, Rafal Jozefowicz, Xi~Chen, Ilya Sutskever, and
  Max Welling.
\newblock Improving variational inference with inverse autoregressive flow.
\newblock \emph{arXiv preprint arXiv:1606.04934}, 2016.

\bibitem[Kingma and Dhariwal(2018)]{kingma2018glow}
Durk~P Kingma and Prafulla Dhariwal.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  10215--10224, 2018.

\bibitem[Kobyzev et~al.(2020)Kobyzev, Prince, and
  Brubaker]{kobyzev2020normalizing}
Ivan Kobyzev, Simon Prince, and Marcus Brubaker.
\newblock Normalizing flows: An introduction and review of current methods.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 2020.

\bibitem[Kothari et~al.(2021)Kothari, Khorashadizadeh, de~Hoop, and
  Dokmani{\'c}]{kothari2021trumpets}
Konik Kothari, AmirEhsan Khorashadizadeh, Maarten de~Hoop, and Ivan
  Dokmani{\'c}.
\newblock Trumpets: Injective flows for inference and inverse problems.
\newblock \emph{arXiv preprint arXiv:2102.10461}, 2021.

\bibitem[Kruse et~al.(2019)Kruse, Detommaso, Scheichl, and
  K{\"o}the]{kruse2019hint}
Jakob Kruse, Gianluca Detommaso, Robert Scheichl, and Ullrich K{\"o}the.
\newblock Hint: Hierarchical invertible neural transport for density estimation
  and bayesian inference.
\newblock \emph{arXiv preprint arXiv:1905.10687}, 2019.

\bibitem[Kruse et~al.(2021)Kruse, Ardizzone, Rother, and
  K{\"o}the]{kruse2021benchmarking}
Jakob Kruse, Lynton Ardizzone, Carsten Rother, and Ullrich K{\"o}the.
\newblock Benchmarking invertible architectures on inverse problems.
\newblock \emph{arXiv preprint arXiv:2101.10763}, 2021.

\bibitem[Lee et~al.(2017)Lee, Ge, Ma, Risteski, and Arora]{lee2017ability}
Holden Lee, Rong Ge, Tengyu Ma, Andrej Risteski, and Sanjeev Arora.
\newblock On the ability of neural nets to express distributions.
\newblock In \emph{Conference on Learning Theory}, pages 1271--1296. PMLR,
  2017.

\bibitem[Lei et~al.(2019)Lei, Jalal, Dhillon, and Dimakis]{lei2019inverting}
Qi~Lei, Ajil Jalal, Inderjit~S Dhillon, and Alexandros~G Dimakis.
\newblock Inverting deep generative models, one layer at a time.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  13910--13919, 2019.

\bibitem[Lu and Lu(2020)]{lu2020universal}
Yulong Lu and Jianfeng Lu.
\newblock A universal approximation theorem of deep neural networks for
  expressing distributions.
\newblock \emph{arXiv preprint arXiv:2004.08867}, 2020.

\bibitem[Madsen et~al.(1997)Madsen, Tornehave, et~al.]{madsen1997calculus}
Ib~H Madsen, Jxrgen Tornehave, et~al.
\newblock \emph{From calculus to cohomology: de Rham cohomology and
  characteristic classes}.
\newblock Cambridge university press, 1997.

\bibitem[Milnor(1956)]{milnor1956manifolds}
John Milnor.
\newblock On manifolds homeomorphic to the 7-sphere.
\newblock \emph{Annals of Mathematics}, pages 399--405, 1956.

\bibitem[Mukherjee(2015)]{Mukherjee}
Amiya Mukherjee.
\newblock \emph{Differential topology}.
\newblock Hindustan Book Agency, New Delhi; Birkh\"{a}user/Springer, Cham,
  second edition, 2015.
\newblock ISBN 978-3-319-19044-0; 978-3-319-19045-7.
\newblock \doi{10.1007/978-3-319-19045-7}.
\newblock URL \url{https://doi.org/10.1007/978-3-319-19045-7}.

\bibitem[M{\"u}ller(2014)]{muller2014uniform}
Stefan M{\"u}ller.
\newblock Uniform approximation of homeomorphisms by diffeomorphisms.
\newblock \emph{Topology and its Applications}, 178:\penalty0 315--319, 2014.

\bibitem[Murasugi(2008)]{Murasugi}
Kunio Murasugi.
\newblock \emph{Knot theory \& its applications}.
\newblock Modern Birkh\"{a}user Classics. Birkh\"{a}user Boston, Inc., Boston,
  MA, 2008.
\newblock ISBN 978-0-8176-4718-6.
\newblock \doi{10.1007/978-0-8176-4719-3}.
\newblock URL \url{https://doi.org/10.1007/978-0-8176-4719-3}.
\newblock Translated from the 1993 Japanese original by Bohdan Kurpita, Reprint
  of the 1996 translation [MR1391727].

\bibitem[Papamakarios et~al.(2019)Papamakarios, Nalisnick, Rezende, Mohamed,
  and Lakshminarayanan]{papamakarios2019normalizing}
George Papamakarios, Eric Nalisnick, Danilo~Jimenez Rezende, Shakir Mohamed,
  and Balaji Lakshminarayanan.
\newblock Normalizing flows for probabilistic modeling and inference.
\newblock \emph{arXiv preprint arXiv:1912.02762}, 2019.

\bibitem[Puthawala et~al.(2020)Puthawala, Kothari, Lassas, Dokmani{\'c}, and
  de~Hoop]{puthawala2020globally}
Michael Puthawala, Konik Kothari, Matti Lassas, Ivan Dokmani{\'c}, and Maarten
  de~Hoop.
\newblock Globally injective relu networks.
\newblock \emph{arXiv preprint arXiv:2006.08464}, 2020.

\bibitem[Rolnick and K\"{o}rding(2020)]{rolnick2020reverse}
David Rolnick and Konrad K\"{o}rding.
\newblock Reverse-engineering deep relu networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  8178--8187. PMLR, 2020.

\bibitem[S\'{e}quin(2011)]{Sequin}
Carlo~H. S\'{e}quin.
\newblock Tori story.
\newblock In Reza Sarhangi and Carlo~H. S\'{e}quin, editors, \emph{Proceedings
  of Bridges 2011: Mathematics, Music, Art, Architecture, Culture}, pages
  121--130. Tessellations Publishing, 2011.
\newblock ISBN 978-0-9846042-6-5.

\bibitem[Sun and Bouman(2020)]{sun2020deep}
He~Sun and Katherine~L Bouman.
\newblock Deep probabilistic imaging: Uncertainty quantification and
  multi-modal solution characterization for computational imaging.
\newblock \emph{arXiv preprint arXiv:2010.14462}, 2020.

\bibitem[Sutherland(2009)]{MR2548039}
Wilson~A. Sutherland.
\newblock \emph{Introduction to metric and topological spaces}.
\newblock Oxford University Press, Oxford, 2009.
\newblock ISBN 978-0-19-956308-1.
\newblock Second edition [of MR0442869], Companion web site:
  www.oup.com/uk/companion/metric.

\bibitem[Tao(2009)]{tao2009analysis}
Terence Tao.
\newblock \emph{Analysis}, volume 185.
\newblock Springer, 2009.

\bibitem[Teshima et~al.(2020)Teshima, Ishikawa, Tojo, Oono, Ikeda, and
  Sugiyama]{teshima2020coupling}
Takeshi Teshima, Isao Ishikawa, Koichi Tojo, Kenta Oono, Masahiro Ikeda, and
  Masashi Sugiyama.
\newblock Coupling-based invertible neural networks are universal
  diffeomorphism approximators.
\newblock \emph{arXiv preprint arXiv:2006.11469}, 2020.

\bibitem[Villani(2008)]{villani2008optimal}
C{\'e}dric Villani.
\newblock \emph{Optimal transport: old and new}, volume 338.
\newblock Springer Science \& Business Media, 2008.

\bibitem[Yarotsky(2017)]{yarotsky2017error}
Dmitry Yarotsky.
\newblock Error bounds for approximations with deep relu networks.
\newblock \emph{Neural Networks}, 94:\penalty0 103--114, 2017.

\bibitem[Yarotsky(2018)]{yarotsky2018optimal}
Dmitry Yarotsky.
\newblock Optimal approximation of continuous functions by very deep relu
  networks.
\newblock In \emph{Conference on Learning Theory}, pages 639--649. PMLR, 2018.

\end{thebibliography}
