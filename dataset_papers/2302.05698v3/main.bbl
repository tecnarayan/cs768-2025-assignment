\begin{thebibliography}{68}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agrawal et~al.(2022)Agrawal, Zhou, Lewis, Zettlemoyer, and
  Ghazvininejad]{agrawal2022context}
Agrawal, S., Zhou, C., Lewis, M., Zettlemoyer, L., and Ghazvininejad, M.
\newblock In-context examples selection for machine translation.
\newblock \emph{arXiv preprint arXiv:2212.02437}, 2022.

\bibitem[An et~al.(2022)An, Feng, Lv, Kong, Qiu, and Huang]{an2022cont}
An, C., Feng, J., Lv, K., Kong, L., Qiu, X., and Huang, X.
\newblock Cont: Contrastive neural text generation.
\newblock \emph{NeurIPS}, 2022.

\bibitem[Andreas et~al.(2020)Andreas, Bufe, Burkett, Chen~Jr, Clausman,
  Crawford, Crim, DeLoach, Dorner, Eisner, et~al.]{andreas2020task}
Andreas, J., Bufe, J., Burkett, D., Chen~Jr, C., Clausman, J., Crawford, J.,
  Crim, K., DeLoach, J., Dorner, L., Eisner, J., et~al.
\newblock Task-oriented dialogue as dataflow synthesis.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  8:\penalty0 556--571, 2020.

\bibitem[Azadi et~al.(2017)Azadi, Feng, and Darrell]{azadi2017learning}
Azadi, S., Feng, J., and Darrell, T.
\newblock Learning detection with diverse proposals.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  7149--7157, 2017.

\bibitem[Berant et~al.(2013)Berant, Chou, Frostig, and
  Liang]{berant-etal-2013-semantic}
Berant, J., Chou, A., Frostig, R., and Liang, P.
\newblock Semantic parsing on {F}reebase from question-answer pairs.
\newblock In \emph{Proceedings of the 2013 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  1533--1544, Seattle, Washington, USA,
  October 2013. Association for Computational Linguistics.
\newblock URL \url{https://www.aclweb.org/anthology/D13-1160}.

\bibitem[Black et~al.(2021)Black, Gao, Wang, Leahy, and Biderman]{gpt-neo}
Black, S., Gao, L., Wang, P., Leahy, C., and Biderman, S.
\newblock {GPT-Neo: Large Scale Autoregressive Language Modeling with
  Mesh-Tensorflow}, March 2021.
\newblock URL \url{https://doi.org/10.5281/zenodo.5297715}.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert{-}Voss, Krueger,
  Henighan, Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin,
  Gray, Chess, Clark, Berner, McCandlish, Radford, Sutskever, and
  Amodei]{DBLP:conf/nips/BrownMRSKDNSSAA20}
Brown, T.~B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
  Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S.,
  Herbert{-}Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A.,
  Ziegler, D.~M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin,
  M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A.,
  Sutskever, I., and Amodei, D.
\newblock Language models are few-shot learners.
\newblock In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H.
  (eds.), \emph{Advances in Neural Information Processing Systems 33: Annual
  Conference on Neural Information Processing Systems 2020, NeurIPS 2020,
  December 6-12, 2020, virtual}, 2020.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html}.

\bibitem[Chen et~al.(2018)Chen, Zhang, and Zhou]{chen2018fast}
Chen, L., Zhang, G., and Zhou, E.
\newblock Fast greedy map inference for determinantal point process to improve
  recommendation diversity.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Chen et~al.(2021{\natexlab{a}})Chen, Tworek, Jun, Yuan,
  de~Oliveira~Pinto, Kaplan, Edwards, Burda, Joseph, Brockman,
  et~al.]{chen2021codex}
Chen, M., Tworek, J., Jun, H., Yuan, Q., de~Oliveira~Pinto, H.~P., Kaplan, J.,
  Edwards, H., Burda, Y., Joseph, N., Brockman, G., et~al.
\newblock Evaluating large language models trained on code.
\newblock \emph{arXiv preprint arXiv:2107.03374}, 2021{\natexlab{a}}.

\bibitem[Chen et~al.(2021{\natexlab{b}})Chen, Tworek, Jun, Yuan, Pinto, Kaplan,
  Edwards, Burda, Joseph, Brockman, et~al.]{chen2021evaluating}
Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d.~O., Kaplan, J.,
  Edwards, H., Burda, Y., Joseph, N., Brockman, G., et~al.
\newblock Evaluating large language models trained on code.
\newblock \emph{arXiv preprint arXiv:2107.03374}, 2021{\natexlab{b}}.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and
  Toutanova]{devlin-etal-2019-bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pp.\  4171--4186,
  Minneapolis, Minnesota, 2019. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/N19-1423}.
\newblock URL \url{https://aclanthology.org/N19-1423}.

\bibitem[Dolan et~al.(2004)Dolan, Quirk, and Brockett]{dolan2004unsupervised}
Dolan, W.~B., Quirk, C., and Brockett, C.
\newblock Unsupervised construction of large paraphrase corpora: Exploiting
  massively parallel news sources.
\newblock In \emph{COLING 2004: Proceedings of the 20th International
  Conference on Computational Linguistics}, pp.\  350--356, 2004.

\bibitem[FAIR et~al.(2022)FAIR, Bakhtin, Brown, Dinan, Farina, Flaherty, Fried,
  Goff, Gray, Hu, et~al.]{meta2022human}
FAIR, Bakhtin, A., Brown, N., Dinan, E., Farina, G., Flaherty, C., Fried, D.,
  Goff, A., Gray, J., Hu, H., et~al.
\newblock Human-level play in the game of diplomacy by combining language
  models with strategic reasoning.
\newblock \emph{Science (New York, NY)}, 378\penalty0 (6624):\penalty0
  1067--1074, 2022.

\bibitem[Finegan-Dollak et~al.(2018)Finegan-Dollak, Kummerfeld, Zhang,
  Ramanathan, Sadasivam, Zhang, and Radev]{finegan-dollak-etal-2018-improving}
Finegan-Dollak, C., Kummerfeld, J.~K., Zhang, L., Ramanathan, K., Sadasivam,
  S., Zhang, R., and Radev, D.
\newblock Improving text-to-{SQL} evaluation methodology.
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pp.\  351--360,
  Melbourne, Australia, July 2018. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/P18-1033}.
\newblock URL \url{https://aclanthology.org/P18-1033}.

\bibitem[Gao et~al.(2021{\natexlab{a}})Gao, Biderman, Black, Golding, Hoppe,
  Foster, Phang, He, Thite, Nabeshima, et~al.]{gao2020pile}
Gao, L., Biderman, S., Black, S., Golding, L., Hoppe, T., Foster, C., Phang,
  J., He, H., Thite, A., Nabeshima, N., et~al.
\newblock The pile: An 800gb dataset of diverse text for language modeling.
\newblock \emph{ArXiv preprint}, abs/2101.00027, 2021{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/2101.00027}.

\bibitem[Gao et~al.(2021{\natexlab{b}})Gao, Yao, and Chen]{gao2021simcse}
Gao, T., Yao, X., and Chen, D.
\newblock Simcse: Simple contrastive learning of sentence embeddings.
\newblock In \emph{Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  6894--6910, 2021{\natexlab{b}}.

\bibitem[Gillenwater et~al.(2012)Gillenwater, Kulesza, and
  Taskar]{gillenwater2012near}
Gillenwater, J., Kulesza, A., and Taskar, B.
\newblock Near-optimal map inference for determinantal point processes.
\newblock \emph{Advances in Neural Information Processing Systems}, 25, 2012.

\bibitem[Gong et~al.(2014)Gong, Chao, Grauman, and Sha]{gong2014diverse}
Gong, B., Chao, W.-L., Grauman, K., and Sha, F.
\newblock Diverse sequential subset selection for supervised video
  summarization.
\newblock \emph{Advances in neural information processing systems}, 27, 2014.

\bibitem[Han et~al.(2017)Han, Kambadur, Park, and Shin]{han2017faster}
Han, I., Kambadur, P., Park, K., and Shin, J.
\newblock Faster greedy map inference for determinantal point processes.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1384--1393. PMLR, 2017.

\bibitem[Hasson \& Berant(2021)Hasson and Berant]{hasson2021question}
Hasson, M. and Berant, J.
\newblock Question decomposition with dependency graphs.
\newblock In \emph{3rd Conference on Automated Knowledge Base Construction},
  2021.

\bibitem[He et~al.(2020)He, Fan, Wu, Xie, and Girshick]{he2020momentum}
He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pp.\  9729--9738, 2020.

\bibitem[Heilbron et~al.(2015)Heilbron, Escorcia, Ghanem, and
  Niebles]{heilbron2015activitynet}
Heilbron, F.~C., Escorcia, V., Ghanem, B., and Niebles, J.~C.
\newblock Activitynet: A large-scale video benchmark for human activity
  understanding.
\newblock In \emph{2015 IEEE conference on computer vision and pattern
  recognition (CVPR)}, pp.\  961--970. IEEE, 2015.

\bibitem[Holtzman et~al.(2019)Holtzman, Buys, Du, Forbes, and
  Choi]{holtzman2019curious}
Holtzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y.
\newblock The curious case of neural text degeneration.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Izacard et~al.(2021)Izacard, Caron, Hosseini, Riedel, Bojanowski,
  Joulin, and Grave]{izacard2021towards}
Izacard, G., Caron, M., Hosseini, L., Riedel, S., Bojanowski, P., Joulin, A.,
  and Grave, E.
\newblock Towards unsupervised dense information retrieval with contrastive
  learning.
\newblock \emph{arXiv preprint arXiv:2112.09118}, 2021.

\bibitem[Karpukhin et~al.(2020)Karpukhin, Oguz, Min, Lewis, Wu, Edunov, Chen,
  and Yih]{karpukhin2020dense}
Karpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., and
  Yih, W.-t.
\newblock Dense passage retrieval for open-domain question answering.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pp.\  6769--6781, 2020.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{Proceedings of ICLR}, 2015.

\bibitem[Ko et~al.(1995)Ko, Lee, and Queyranne]{ko1995exact}
Ko, C.-W., Lee, J., and Queyranne, M.
\newblock An exact algorithm for maximum entropy sampling.
\newblock \emph{Operations Research}, 43\penalty0 (4):\penalty0 684--691, 1995.

\bibitem[Kulesza \& Taskar(2011)Kulesza and Taskar]{kulesza2011k}
Kulesza, A. and Taskar, B.
\newblock k-dpps: Fixed-size determinantal point processes.
\newblock In \emph{ICML}, 2011.

\bibitem[Kulesza et~al.(2012)Kulesza, Taskar, et~al.]{kulesza2012determinantal}
Kulesza, A., Taskar, B., et~al.
\newblock Determinantal point processes for machine learning.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  5\penalty0 (2--3):\penalty0 123--286, 2012.

\bibitem[Kulis et~al.(2013)]{kulis2013metric}
Kulis, B. et~al.
\newblock Metric learning: A survey.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  5\penalty0 (4):\penalty0 287--364, 2013.

\bibitem[Levy et~al.(2022)Levy, Bogin, and Berant]{levy2022diverse}
Levy, I., Bogin, B., and Berant, J.
\newblock Diverse demonstrations improve in-context compositional
  generalization.
\newblock \emph{arXiv preprint arXiv:2212.06800}, 2022.

\bibitem[Li et~al.(2021)Li, Arora, Chen, Gupta, Gupta, and Mehdad]{li2021mtop}
Li, H., Arora, A., Chen, S., Gupta, A., Gupta, S., and Mehdad, Y.
\newblock Mtop: A comprehensive multilingual task-oriented semantic parsing
  benchmark.
\newblock In \emph{Proceedings of the 16th Conference of the European Chapter
  of the Association for Computational Linguistics: Main Volume}, pp.\
  2950--2962, 2021.

\bibitem[Li et~al.(2022)Li, Lin, Zhang, Fu, Chen, Lou, and Chen]{li2022advance}
Li, Y., Lin, Z., Zhang, S., Fu, Q., Chen, B., Lou, J.-G., and Chen, W.
\newblock On the advance of making language models better reasoners.
\newblock \emph{arXiv preprint arXiv:2206.02336}, 2022.

\bibitem[Lin et~al.(2018)Lin, Wang, Zettlemoyer, and Ernst]{LinWZE2018:NL2Bash}
Lin, X.~V., Wang, C., Zettlemoyer, L., and Ernst, M.~D.
\newblock Nl2bash: A corpus and semantic parser for natural language interface
  to the linux operating system.
\newblock In \emph{Proceedings of the Eleventh International Conference on
  Language Resources and Evaluation {LREC} 2018, Miyazaki (Japan), 7-12 May,
  2018.}, 2018.

\bibitem[Liu et~al.(2022)Liu, Shen, Zhang, Dolan, Carin, and
  Chen]{liu2022makes}
Liu, J., Shen, D., Zhang, Y., Dolan, W.~B., Carin, L., and Chen, W.
\newblock What makes good in-context examples for gpt-3?
\newblock In \emph{Proceedings of Deep Learning Inside Out (DeeLIO 2022): The
  3rd Workshop on Knowledge Extraction and Integration for Deep Learning
  Architectures}, pp.\  100--114, 2022.

\bibitem[Liu et~al.(2009)]{liu2009learning}
Liu, T.-Y. et~al.
\newblock Learning to rank for information retrieval.
\newblock \emph{Foundations and Trends{\textregistered} in Information
  Retrieval}, 3\penalty0 (3):\penalty0 225--331, 2009.

\bibitem[Lu et~al.(2022)Lu, Bartolo, Moore, Riedel, and
  Stenetorp]{lu2022fantastically}
Lu, Y., Bartolo, M., Moore, A., Riedel, S., and Stenetorp, P.
\newblock Fantastically ordered prompts and where to find them: Overcoming
  few-shot prompt order sensitivity.
\newblock In \emph{Proceedings of the 60th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pp.\  8086--8098,
  2022.

\bibitem[Nakano et~al.(2021)Nakano, Hilton, Balaji, Wu, Ouyang, Kim, Hesse,
  Jain, Kosaraju, Saunders, et~al.]{nakano2021webgpt}
Nakano, R., Hilton, J., Balaji, S., Wu, J., Ouyang, L., Kim, C., Hesse, C.,
  Jain, S., Kosaraju, V., Saunders, W., et~al.
\newblock Webgpt: Browser-assisted question-answering with human feedback.
\newblock \emph{arXiv preprint arXiv:2112.09332}, 2021.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
Oord, A. v.~d., Li, Y., and Vinyals, O.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[OpenAI(2022)]{openai2022chatgpt}
OpenAI, T.
\newblock Chatgpt: Optimizing language models for dialogue.
\newblock \emph{OpenAI}, 2022.

\bibitem[Qiu et~al.(2022{\natexlab{a}})Qiu, Shaw, Pasupat, Nowak, Linzen, Sha,
  and Toutanova]{qiu-etal-2022-improving}
Qiu, L., Shaw, P., Pasupat, P., Nowak, P., Linzen, T., Sha, F., and Toutanova,
  K.
\newblock Improving compositional generalization with latent structure and data
  augmentation.
\newblock In \emph{Proceedings of the 2022 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pp.\  4341--4362, Seattle, United States, July
  2022{\natexlab{a}}. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2022.naacl-main.323}.
\newblock URL \url{https://aclanthology.org/2022.naacl-main.323}.

\bibitem[Qiu et~al.(2022{\natexlab{b}})Qiu, Shaw, Pasupat, Shi, Herzig, Pitler,
  Sha, and Toutanova]{qiu2022evaluating}
Qiu, L., Shaw, P., Pasupat, P., Shi, T., Herzig, J., Pitler, E., Sha, F., and
  Toutanova, K.
\newblock Evaluating the impact of model scale for compositional generalization
  in semantic parsing.
\newblock \emph{arXiv preprint arXiv:2205.12253}, 2022{\natexlab{b}}.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, and
  Sutskever]{Radford2019LanguageMA}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I.
\newblock Language models are unsupervised multitask learners.
\newblock 2019.

\bibitem[Robertson \& Zaragoza(2009)Robertson and Zaragoza]{stephen2009bm25}
Robertson, S. and Zaragoza, H.
\newblock The probabilistic relevance framework: Bm25 and beyond.
\newblock \emph{Foundations and Trends in Information Retrieval}, 3:\penalty0
  333--389, 01 2009.
\newblock \doi{10.1561/1500000019}.

\bibitem[Rohrbach et~al.(2017)Rohrbach, Torabi, Rohrbach, Tandon, Pal,
  Larochelle, Courville, and Schiele]{rohrbach2017movie}
Rohrbach, A., Torabi, A., Rohrbach, M., Tandon, N., Pal, C., Larochelle, H.,
  Courville, A., and Schiele, B.
\newblock Movie description.
\newblock \emph{International Journal of Computer Vision}, 123:\penalty0
  94--120, 2017.

\bibitem[Rubin et~al.(2022)Rubin, Herzig, and Berant]{rubin-etal-2022-learning}
Rubin, O., Herzig, J., and Berant, J.
\newblock Learning to retrieve prompts for in-context learning.
\newblock In \emph{Proceedings of the 2022 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pp.\  2655--2671, Seattle, United States, July 2022.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2022.naacl-main.191}.
\newblock URL \url{https://aclanthology.org/2022.naacl-main.191}.

\bibitem[Sch{\"o}lkopf et~al.(2002)Sch{\"o}lkopf, Smola, Bach,
  et~al.]{scholkopf2002learning}
Sch{\"o}lkopf, B., Smola, A.~J., Bach, F., et~al.
\newblock \emph{Learning with kernels: support vector machines, regularization,
  optimization, and beyond}.
\newblock MIT press, 2002.

\bibitem[Shaw et~al.(2021)Shaw, Chang, Pasupat, and
  Toutanova]{shaw-etal-2021-compositional}
Shaw, P., Chang, M.-W., Pasupat, P., and Toutanova, K.
\newblock Compositional generalization and natural language variation: Can a
  semantic parsing approach handle both?
\newblock In \emph{Proceedings of the 59th Annual Meeting of the Association
  for Computational Linguistics and the 11th International Joint Conference on
  Natural Language Processing (Volume 1: Long Papers)}, pp.\  922--938, Online,
  August 2021. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2021.acl-long.75}.
\newblock URL \url{https://aclanthology.org/2021.acl-long.75}.

\bibitem[Shi et~al.(2022)Shi, Fried, Ghazvininejad, Zettlemoyer, and
  Wang]{shi2022natural}
Shi, F., Fried, D., Ghazvininejad, M., Zettlemoyer, L., and Wang, S.~I.
\newblock Natural language to code translation with execution.
\newblock \emph{arXiv preprint arXiv:2204.11454}, 2022.

\bibitem[Socher et~al.(2013)Socher, Perelygin, Wu, Chuang, Manning, Ng, and
  Potts]{socher2013recursive}
Socher, R., Perelygin, A., Wu, J., Chuang, J., Manning, C.~D., Ng, A.~Y., and
  Potts, C.
\newblock Recursive deep models for semantic compositionality over a sentiment
  treebank.
\newblock In \emph{Proceedings of the 2013 conference on empirical methods in
  natural language processing}, pp.\  1631--1642, 2013.

\bibitem[Su et~al.(2022)Su, Kasai, Wu, Shi, Wang, Xin, Zhang, Ostendorf,
  Zettlemoyer, Smith, et~al.]{su2022selective}
Su, H., Kasai, J., Wu, C.~H., Shi, W., Wang, T., Xin, J., Zhang, R., Ostendorf,
  M., Zettlemoyer, L., Smith, N.~A., et~al.
\newblock Selective annotation makes language models better few-shot learners.
\newblock \emph{arXiv preprint arXiv:2209.01975}, 2022.

\bibitem[Talmor et~al.(2019)Talmor, Herzig, Lourie, and
  Berant]{talmor-etal-2019-commonsenseqa}
Talmor, A., Herzig, J., Lourie, N., and Berant, J.
\newblock {C}ommonsense{QA}: A question answering challenge targeting
  commonsense knowledge.
\newblock In \emph{Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pp.\  4149--4158,
  Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.
\newblock \doi{10.18653/v1/N19-1421}.
\newblock URL \url{https://aclanthology.org/N19-1421}.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Wang et~al.(2018)Wang, Singh, Michael, Hill, Levy, and
  Bowman]{wang2018glue}
Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., and Bowman, S.
\newblock Glue: A multi-task benchmark and analysis platform for natural
  language understanding.
\newblock In \emph{Proceedings of the 2018 EMNLP Workshop BlackboxNLP:
  Analyzing and Interpreting Neural Networks for NLP}, pp.\  353--355, 2018.

\bibitem[Wang et~al.(2022)Wang, Wei, Schuurmans, Le, Chi, and
  Zhou]{wang2022self}
Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., and Zhou, D.
\newblock Self-consistency improves chain of thought reasoning in language
  models.
\newblock \emph{arXiv preprint arXiv:2203.11171}, 2022.

\bibitem[Wei et~al.(2022)Wei, Tay, Bommasani, Raffel, Zoph, Borgeaud, Yogatama,
  Bosma, Zhou, Metzler, et~al.]{wei2022emergent}
Wei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama,
  D., Bosma, M., Zhou, D., Metzler, D., et~al.
\newblock Emergent abilities of large language models.
\newblock \emph{Transactions on Machine Learning Research}, 2022.

\bibitem[Williams et~al.(2018)Williams, Nangia, and Bowman]{williams2018broad}
Williams, A., Nangia, N., and Bowman, S.
\newblock A broad-coverage challenge corpus for sentence understanding through
  inference.
\newblock In \emph{Proceedings of the 2018 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long Papers)}, pp.\  1112--1122, 2018.

\bibitem[Wolf et~al.(2020)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac,
  Rault, Louf, Funtowicz, Davison, Shleifer, von Platen, Ma, Jernite, Plu, Xu,
  Scao, Gugger, Drame, Lhoest, and Rush]{wolf-etal-2020-transformers}
Wolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P.,
  Rault, T., Louf, R., Funtowicz, M., Davison, J., Shleifer, S., von Platen,
  P., Ma, C., Jernite, Y., Plu, J., Xu, C., Scao, T.~L., Gugger, S., Drame, M.,
  Lhoest, Q., and Rush, A.~M.
\newblock Transformers: State-of-the-art natural language processing.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing: System Demonstrations}, pp.\  38--45, Online,
  October 2020. Association for Computational Linguistics.
\newblock URL \url{https://www.aclweb.org/anthology/2020.emnlp-demos.6}.

\bibitem[Wolfson et~al.(2020)Wolfson, Geva, Gupta, Gardner, Goldberg, Deutch,
  and Berant]{wolfson2020break}
Wolfson, T., Geva, M., Gupta, A., Gardner, M., Goldberg, Y., Deutch, D., and
  Berant, J.
\newblock Break it down: A question understanding benchmark.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  8:\penalty0 183--198, 2020.

\bibitem[Wu et~al.(2022)Wu, Wang, Ye, and Kong]{wu2022self}
Wu, Z., Wang, Y., Ye, J., and Kong, L.
\newblock Self-adaptive in-context learning.
\newblock \emph{arXiv preprint arXiv:2212.10375}, 2022.

\bibitem[Xie et~al.(2017)Xie, Salakhutdinov, Mou, and Xing]{xie2017deep}
Xie, P., Salakhutdinov, R., Mou, L., and Xing, E.~P.
\newblock Deep determinantal point process for large-scale multi-label
  classification.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision (ICCV)}, Oct 2017.

\bibitem[Ye et~al.(2022{\natexlab{a}})Ye, Gao, Wu, Feng, Yu, and
  Kong]{ye-etal-2022-progen}
Ye, J., Gao, J., Wu, Z., Feng, J., Yu, T., and Kong, L.
\newblock {P}ro{G}en: Progressive zero-shot dataset generation via in-context
  feedback.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP 2022}, pp.\  3671--3683, Abu Dhabi, United Arab Emirates, December
  2022{\natexlab{a}}. Association for Computational Linguistics.
\newblock URL \url{https://aclanthology.org/2022.findings-emnlp.269}.

\bibitem[Ye et~al.(2023)Ye, Li, Kong, and Yu]{Ye2023GeneratingDF}
Ye, J., Li, C., Kong, L., and Yu, T.
\newblock Generating data for symbolic language with large language models.
\newblock 2023.

\bibitem[Ye et~al.(2022{\natexlab{b}})Ye, Iyer, Celikyilmaz, Stoyanov, Durrett,
  and Pasunuru]{ye2022complementary}
Ye, X., Iyer, S., Celikyilmaz, A., Stoyanov, V., Durrett, G., and Pasunuru, R.
\newblock Complementary explanations for effective in-context learning.
\newblock \emph{arXiv preprint arXiv:2211.13892}, 2022{\natexlab{b}}.

\bibitem[Yin et~al.(2021)Yin, Fang, Neubig, Pauls, Platanios, Su, Thomson, and
  Andreas]{yin2021compositional}
Yin, P., Fang, H., Neubig, G., Pauls, A., Platanios, E.~A., Su, Y., Thomson,
  S., and Andreas, J.
\newblock Compositional generalization for neural semantic parsing via
  span-level supervised attention.
\newblock In \emph{Proceedings of the 2021 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pp.\  2810--2823, 2021.

\bibitem[Zelle \& Mooney(1996)Zelle and Mooney]{zelle:aaai96}
Zelle, J.~M. and Mooney, R.~J.
\newblock Learning to parse database queries using inductive logic programming.
\newblock In \emph{AAAI/IAAI}, pp.\  1050--1055, Portland, OR, August 1996.
  AAAI Press/MIT Press.
\newblock URL \url{http://www.cs.utexas.edu/users/ai-lab?zelle:aaai96}.

\bibitem[Zellers et~al.(2019)Zellers, Holtzman, Bisk, Farhadi, and
  Choi]{zellers2019hellaswag}
Zellers, R., Holtzman, A., Bisk, Y., Farhadi, A., and Choi, Y.
\newblock Hellaswag: Can a machine really finish your sentence?
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, 2019.

\bibitem[Zhong et~al.(2020)Zhong, Liu, Chen, Wang, Qiu, and
  Huang]{zhong-etal-2020-extractive}
Zhong, M., Liu, P., Chen, Y., Wang, D., Qiu, X., and Huang, X.
\newblock Extractive summarization as text matching.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pp.\  6197--6208, Online, July 2020.
  Association for Computational Linguistics.
\newblock \doi{10.18653/v1/2020.acl-main.552}.
\newblock URL \url{https://aclanthology.org/2020.acl-main.552}.

\end{thebibliography}
