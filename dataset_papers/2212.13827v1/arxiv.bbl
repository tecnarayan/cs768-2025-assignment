\begin{thebibliography}{62}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbas et~al.(2022)Abbas, Xiao, Chen, Chen, and Chen]{abbas2022sharp}
Momin Abbas, Quan Xiao, Lisha Chen, Pin-Yu Chen, and Tianyi Chen.
\newblock Sharp-maml: Sharpness-aware model-agnostic meta learning.
\newblock \emph{arXiv preprint arXiv:2206.03996}, 2022.

\bibitem[Alain et~al.(2019)Alain, Roux, and Manzagol]{alain2019negative}
Guillaume Alain, Nicolas~Le Roux, and Pierre-Antoine Manzagol.
\newblock Negative eigenvalues of the hessian in deep neural networks.
\newblock \emph{arXiv preprint arXiv:1902.02366}, 2019.

\bibitem[Andriushchenko and Flammarion(2022)]{andriushchenko2022understanding}
Maksym Andriushchenko and Nicolas Flammarion.
\newblock Understanding sharpness-aware minimization, 2022.
\newblock URL \url{https://openreview.net/forum?id=qXa0nhTRZGV}.

\bibitem[Arora et~al.(2020)Arora, Arora, Bruna, Cohen, DU, GE, GUNASEKAR, Jin,
  LEE, MA, et~al.]{arora2020theory}
Raman Arora, SANJEEV Arora, Joan Bruna, NADAV Cohen, SIMON DU, RONG GE, SURIYA
  GUNASEKAR, C~Jin, JASON LEE, TENGYU MA, et~al.
\newblock Theory of deep learning, 2020.

\bibitem[Bahri et~al.(2021)Bahri, Mobahi, and Tay]{bahri2021sharpness}
Dara Bahri, Hossein Mobahi, and Yi~Tay.
\newblock Sharpness-aware minimization improves language model generalization.
\newblock \emph{arXiv preprint arXiv:2110.08529}, 2021.

\bibitem[Biewald(2020)]{wandb}
Lukas Biewald.
\newblock Experiment tracking with weights and biases, 2020.
\newblock URL \url{https://www.wandb.com/}.
\newblock Software available from wandb.com.

\bibitem[Bisla et~al.(2022)Bisla, Wang, and Choromanska]{bisla2022low}
Devansh Bisla, Jing Wang, and Anna Choromanska.
\newblock Low-pass filtering sgd for recovering flat optima in the deep
  learning optimization landscape.
\newblock \emph{arXiv preprint arXiv:2201.08025}, 2022.

\bibitem[Buda et~al.(2018)Buda, Maki, and Mazurowski]{buda2018systematic}
Mateusz Buda, Atsuto Maki, and Maciej~A Mazurowski.
\newblock A systematic study of the class imbalance problem in convolutional
  neural networks.
\newblock \emph{Neural Networks}, 106:\penalty0 249--259, 2018.

\bibitem[Byrd and Lipton(2019)]{byrd2019effect}
Jonathon Byrd and Zachary Lipton.
\newblock What is the effect of importance weighting in deep learning?
\newblock In \emph{International Conference on Machine Learning}, pages
  872--881. PMLR, 2019.

\bibitem[Cao et~al.(2019)Cao, Wei, Gaidon, Arechiga, and Ma]{cao2019learning}
Kaidi Cao, Colin Wei, Adrien Gaidon, Nikos Arechiga, and Tengyu Ma.
\newblock Learning imbalanced datasets with label-distribution-aware margin
  loss.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Chaudhari et~al.(2019)Chaudhari, Choromanska, Soatto, LeCun, Baldassi,
  Borgs, Chayes, Sagun, and Zecchina]{chaudhari2019entropy}
Pratik Chaudhari, Anna Choromanska, Stefano Soatto, Yann LeCun, Carlo Baldassi,
  Christian Borgs, Jennifer Chayes, Levent Sagun, and Riccardo Zecchina.
\newblock Entropy-sgd: Biasing gradient descent into wide valleys.
\newblock \emph{Journal of Statistical Mechanics: Theory and Experiment},
  2019\penalty0 (12):\penalty0 124018, 2019.

\bibitem[Chawla et~al.(2002)Chawla, Bowyer, Hall, and
  Kegelmeyer]{chawla2002smote}
Nitesh~V Chawla, Kevin~W Bowyer, Lawrence~O Hall, and W~Philip Kegelmeyer.
\newblock Smote: synthetic minority over-sampling technique.
\newblock \emph{Journal of artificial intelligence research}, 16:\penalty0
  321--357, 2002.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock \emph{arXiv preprint arXiv:2002.05709}, 2020.

\bibitem[Cotter et~al.(2019)Cotter, Gupta, Jiang, Srebro, Sridharan, Wang,
  Woodworth, and You]{cotter2019training}
Andrew Cotter, Maya Gupta, Heinrich Jiang, Nathan Srebro, Karthik Sridharan,
  Serena Wang, Blake Woodworth, and Seungil You.
\newblock Training well-generalizing classifiers for fairness metrics and other
  data-dependent constraints.
\newblock In \emph{International Conference on Machine Learning}, pages
  1397--1405. PMLR, 2019.

\bibitem[Cui et~al.(2021)Cui, Zhong, Liu, Yu, and Jia]{cui2021parametric}
Jiequan Cui, Zhisheng Zhong, Shu Liu, Bei Yu, and Jiaya Jia.
\newblock Parametric contrastive learning.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 715--724, 2021.

\bibitem[Cui et~al.(2019)Cui, Jia, Lin, Song, and Belongie]{cui2019class}
Yin Cui, Menglin Jia, Tsung-Yi Lin, Yang Song, and Serge Belongie.
\newblock Class-balanced loss based on effective number of samples.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 9268--9277, 2019.

\bibitem[Daneshmand et~al.(2018)Daneshmand, Kohler, Lucchi, and
  Hofmann]{daneshmand2018escaping}
Hadi Daneshmand, Jonas Kohler, Aurelien Lucchi, and Thomas Hofmann.
\newblock Escaping saddles with stochastic gradients.
\newblock In \emph{International Conference on Machine Learning}, pages
  1155--1164. PMLR, 2018.

\bibitem[Dauphin et~al.(2014)Dauphin, Pascanu, Gulcehre, Cho, Ganguli, and
  Bengio]{dauphin2014identifying}
Yann~N Dauphin, Razvan Pascanu, Caglar Gulcehre, Kyunghyun Cho, Surya Ganguli,
  and Yoshua Bengio.
\newblock Identifying and attacking the saddle point problem in
  high-dimensional non-convex optimization.
\newblock \emph{Advances in neural information processing systems}, 27, 2014.

\bibitem[Foret et~al.(2021)Foret, Kleiner, Mobahi, and
  Neyshabur]{foret2021sharpnessaware}
Pierre Foret, Ariel Kleiner, Hossein Mobahi, and Behnam Neyshabur.
\newblock Sharpness-aware minimization for efficiently improving
  generalization.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=6Tm1mposlrM}.

\bibitem[Ge et~al.(2015)Ge, Huang, Jin, and Yuan]{ge2015escaping}
Rong Ge, Furong Huang, Chi Jin, and Yang Yuan.
\newblock Escaping from saddle pointsâ€”online stochastic gradient for tensor
  decomposition.
\newblock In \emph{Conference on learning theory}, pages 797--842. PMLR, 2015.

\bibitem[Ghorbani et~al.(2019)Ghorbani, Krishnan, and
  Xiao]{pmlr-v97-ghorbani19b}
Behrooz Ghorbani, Shankar Krishnan, and Ying Xiao.
\newblock An investigation into neural net optimization via hessian eigenvalue
  density.
\newblock In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors,
  \emph{Proceedings of the 36th International Conference on Machine Learning},
  volume~97 of \emph{Proceedings of Machine Learning Research}, pages
  2232--2241. PMLR, 09--15 Jun 2019.
\newblock URL \url{https://proceedings.mlr.press/v97/ghorbani19b.html}.

\bibitem[Gilmer et~al.(2021)Gilmer, Ghorbani, Garg, Kudugunta, Neyshabur,
  Cardoze, Dahl, Nado, and Firat]{gilmer2021loss}
Justin Gilmer, Behrooz Ghorbani, Ankush Garg, Sneha Kudugunta, Behnam
  Neyshabur, David Cardoze, George Dahl, Zachary Nado, and Orhan Firat.
\newblock A loss curvature perspective on training instability in deep
  learning.
\newblock \emph{arXiv preprint arXiv:2110.04369}, 2021.

\bibitem[He and Garcia(2009)]{5128907}
Haibo He and Edwardo~A. Garcia.
\newblock Learning from imbalanced data.
\newblock \emph{IEEE Transactions on Knowledge and Data Engineering},
  21\penalty0 (9):\penalty0 1263--1284, 2009.
\newblock \doi{10.1109/TKDE.2008.239}.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{He_2016_CVPR}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2016.

\bibitem[He et~al.(2021)He, Wu, and Wei]{He_2021_ICCV}
Yin-Yin He, Jianxin Wu, and Xiu-Shen Wei.
\newblock Distilling virtual examples for long-tailed recognition.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 235--244, October 2021.

\bibitem[Hochreiter and Schmidhuber(1997)]{hochreiter1997flat}
Sepp Hochreiter and J{\"u}rgen Schmidhuber.
\newblock Flat minima.
\newblock \emph{Neural computation}, 9\penalty0 (1):\penalty0 1--42, 1997.

\bibitem[Jin et~al.(2017)Jin, Ge, Netrapalli, Kakade, and
  Jordan]{jin2017escape}
Chi Jin, Rong Ge, Praneeth Netrapalli, Sham~M Kakade, and Michael~I Jordan.
\newblock How to escape saddle points efficiently.
\newblock In \emph{International Conference on Machine Learning}, pages
  1724--1732. PMLR, 2017.

\bibitem[Jin et~al.(2019)Jin, Netrapalli, Ge, Kakade, and
  Jordan]{Jin2019StochasticGD}
Chi Jin, Praneeth Netrapalli, Rong Ge, Sham~M. Kakade, and Michael~I. Jordan.
\newblock Stochastic gradient descent escapes saddle points efficiently.
\newblock \emph{ArXiv}, abs/1902.04811, 2019.

\bibitem[Kang et~al.(2020)Kang, Xie, Rohrbach, Yan, Gordo, Feng, and
  Kalantidis]{Kang2020Decoupling}
Bingyi Kang, Saining Xie, Marcus Rohrbach, Zhicheng Yan, Albert Gordo, Jiashi
  Feng, and Yannis Kalantidis.
\newblock Decoupling representation and classifier for long-tailed recognition.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=r1gRTCVFvB}.

\bibitem[Keskar et~al.(2016)Keskar, Mudigere, Nocedal, Smelyanskiy, and
  Tang]{keskar2016large}
Nitish~Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy,
  and Ping Tak~Peter Tang.
\newblock On large-batch training for deep learning: Generalization gap and
  sharp minima.
\newblock \emph{arXiv preprint arXiv:1609.04836}, 2016.

\bibitem[Khosla et~al.(2020)Khosla, Teterwak, Wang, Sarna, Tian, Isola,
  Maschinot, Liu, and Krishnan]{khosla2020supervised}
Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip
  Isola, Aaron Maschinot, Ce~Liu, and Dilip Krishnan.
\newblock Supervised contrastive learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 18661--18673, 2020.

\bibitem[Kini et~al.(2021)Kini, Paraskevas, Oymak, and
  Thrampoulidis]{kini2021label}
Ganesh~Ramachandra Kini, Orestis Paraskevas, Samet Oymak, and Christos
  Thrampoulidis.
\newblock Label-imbalanced and group-sensitive classification under
  overparameterization.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Krishna et~al.(2017)Krishna, Zhu, Groth, Johnson, Hata, Kravitz, Chen,
  Kalantidis, Li, Shamma, et~al.]{krishna2017visual}
Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua
  Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David~A Shamma, et~al.
\newblock Visual genome: Connecting language and vision using crowdsourced
  dense image annotations.
\newblock \emph{International journal of computer vision}, 123\penalty0
  (1):\penalty0 32--73, 2017.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Li et~al.(2018)Li, Xu, Taylor, Studer, and
  Goldstein]{li2018visualizing}
Hao Li, Zheng Xu, Gavin Taylor, Christoph Studer, and Tom Goldstein.
\newblock Visualizing the loss landscape of neural nets.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Li et~al.(2021)Li, Wang, and Wu]{li2021self}
Tianhao Li, Limin Wang, and Gangshan Wu.
\newblock Self supervision to distillation for long-tailed visual recognition.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 630--639, 2021.

\bibitem[Li et~al.(2020)Li, Gu, Zhou, Chen, and Banerjee]{li2020hessian}
Xinyan Li, Qilong Gu, Yingxue Zhou, Tiancong Chen, and Arindam Banerjee.
\newblock Hessian based analysis of sgd for deep nets: Dynamics and
  generalization.
\newblock In \emph{Proceedings of the 2020 SIAM International Conference on
  Data Mining}, pages 190--198. SIAM, 2020.

\bibitem[Liu et~al.(2022)Liu, Mai, Chen, Hsieh, and You]{liu2022towards}
Yong Liu, Siqi Mai, Xiangning Chen, Cho-Jui Hsieh, and Yang You.
\newblock Towards efficient and scalable sharpness-aware minimization.
\newblock \emph{arXiv preprint arXiv:2203.02714}, 2022.

\bibitem[Liu et~al.(2019)Liu, Miao, Zhan, Wang, Gong, and Yu]{liu2019large}
Ziwei Liu, Zhongqi Miao, Xiaohang Zhan, Jiayun Wang, Boqing Gong, and Stella~X
  Yu.
\newblock Large-scale long-tailed recognition in an open world.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 2537--2546, 2019.

\bibitem[Menon et~al.(2020)Menon, Jayasumana, Rawat, Jain, Veit, and
  Kumar]{menon2020long}
Aditya~Krishna Menon, Sadeep Jayasumana, Ankit~Singh Rawat, Himanshu Jain,
  Andreas Veit, and Sanjiv Kumar.
\newblock Long-tail learning via logit adjustment.
\newblock \emph{arXiv preprint arXiv:2007.07314}, 2020.

\bibitem[Merkulov and Oseledets(2019)]{merkulov2019empirical}
DM~Merkulov and Ivan~V Oseledets.
\newblock Empirical study of extreme overfitting points of neural networks.
\newblock \emph{Journal of Communications Technology and Electronics},
  64\penalty0 (12):\penalty0 1527--1534, 2019.

\bibitem[Park et~al.(2021)Park, Lim, Jeon, and Choi]{Park_2021_ICCV}
Seulki Park, Jongin Lim, Younghan Jeon, and Jin~Young Choi.
\newblock Influence-balanced loss for imbalanced visual classification.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 735--744, October 2021.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{NEURIPS2019_9015}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith
  Chintala.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, \emph{Advances in Neural
  Information Processing Systems 32}, pages 8024--8035. Curran Associates,
  Inc., 2019.
\newblock URL
  \url{http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}.

\bibitem[Rangwani et~al.(2022)Rangwani, Aithal, Mishra, Jain, and
  Babu]{rangwani2022closer}
Harsh Rangwani, Sumukh~K Aithal, Mayank Mishra, Arihant Jain, and R.~Venkatesh
  Babu.
\newblock A closer look at smoothness in domain adversarial training.
\newblock In \emph{Proceedings of the 39th International Conference on Machine
  Learning}, 2022.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, et~al.]{russakovsky2015imagenet}
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma,
  Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{International journal of computer vision}, 115\penalty0
  (3):\penalty0 211--252, 2015.

\bibitem[Sagun et~al.(2017)Sagun, Evci, Guney, Dauphin, and
  Bottou]{sagun2017empirical}
Levent Sagun, Utku Evci, V~Ugur Guney, Yann Dauphin, and Leon Bottou.
\newblock Empirical analysis of the hessian of over-parametrized neural
  networks.
\newblock \emph{arXiv preprint arXiv:1706.04454}, 2017.

\bibitem[Samuel and Chechik(2021)]{Samuel_2021_ICCV}
Dvir Samuel and Gal Chechik.
\newblock Distributional robustness loss for long-tail learning.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 9495--9504, October 2021.

\bibitem[Tan et~al.(2020)Tan, Wang, Li, Li, Ouyang, Yin, and
  Yan]{tan2020equalization}
Jingru Tan, Changbao Wang, Buyu Li, Quanquan Li, Wanli Ouyang, Changqing Yin,
  and Junjie Yan.
\newblock Equalization loss for long-tailed object recognition.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 11662--11671, 2020.

\bibitem[Thomee et~al.(2016)Thomee, Shamma, Friedland, Elizalde, Ni, Poland,
  Borth, and Li]{thomee2016yfcc100m}
Bart Thomee, David~A Shamma, Gerald Friedland, Benjamin Elizalde, Karl Ni,
  Douglas Poland, Damian Borth, and Li-Jia Li.
\newblock Yfcc100m: The new data in multimedia research.
\newblock \emph{Communications of the ACM}, 59\penalty0 (2):\penalty0 64--73,
  2016.

\bibitem[Van~Horn and Perona(2017)]{van2017devil}
Grant Van~Horn and Pietro Perona.
\newblock The devil is in the tails: Fine-grained classification in the wild.
\newblock \emph{arXiv preprint arXiv:1709.01450}, 2017.

\bibitem[Van~Horn et~al.(2018)Van~Horn, Mac~Aodha, Song, Cui, Sun, Shepard,
  Adam, Perona, and Belongie]{van2018inaturalist}
Grant Van~Horn, Oisin Mac~Aodha, Yang Song, Yin Cui, Chen Sun, Alex Shepard,
  Hartwig Adam, Pietro Perona, and Serge Belongie.
\newblock The inaturalist species classification and detection dataset.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 8769--8778, 2018.

\bibitem[Wang et~al.(2021)Wang, Lian, Miao, Liu, and Yu]{wang2021longtailed}
Xudong Wang, Long Lian, Zhongqi Miao, Ziwei Liu, and Stella Yu.
\newblock Long-tailed recognition by routing diverse distribution-aware
  experts.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=D9I3drBz4UC}.

\bibitem[Yang and Xu(2020{\natexlab{a}})]{NEURIPS2020_e025b627}
Yuzhe Yang and Zhi Xu.
\newblock Rethinking the value of labels for improving class-imbalanced
  learning.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.F. Balcan, and H.~Lin,
  editors, \emph{Advances in Neural Information Processing Systems}, volume~33,
  pages 19290--19301. Curran Associates, Inc., 2020{\natexlab{a}}.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2020/file/e025b6279c1b88d3ec0eca6fcb6e6280-Paper.pdf}.

\bibitem[Yang and Xu(2020{\natexlab{b}})]{yang2020rethinking}
Yuzhe Yang and Zhi Xu.
\newblock Rethinking the value of labels for improving class-imbalanced
  learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 19290--19301, 2020{\natexlab{b}}.

\bibitem[Yao et~al.(2020)Yao, Gholami, Keutzer, and Mahoney]{yao2020pyhessian}
Zhewei Yao, Amir Gholami, Kurt Keutzer, and Michael~W Mahoney.
\newblock Pyhessian: Neural networks through the lens of the hessian.
\newblock In \emph{2020 IEEE international conference on big data (Big data)},
  pages 581--590. IEEE, 2020.

\bibitem[Ye et~al.(2020)Ye, Chen, Zhan, and Chao]{ye2020identifying}
Han-Jia Ye, Hong-You Chen, De-Chuan Zhan, and Wei-Lun Chao.
\newblock Identifying and compensating for feature deviation in imbalanced deep
  learning.
\newblock \emph{arXiv preprint arXiv:2001.01385}, 2020.

\bibitem[Zhang(2019)]{zhang2019medical}
Chuanhai Zhang.
\newblock \emph{Medical image classification under class imbalance}.
\newblock PhD thesis, Iowa State University, 2019.

\bibitem[Zhang et~al.(2021{\natexlab{a}})Zhang, Li, Yan, He, and
  Sun]{zhang2021distribution}
Songyang Zhang, Zeming Li, Shipeng Yan, Xuming He, and Jian Sun.
\newblock Distribution alignment: A unified framework for long-tail visual
  recognition.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 2361--2370, 2021{\natexlab{a}}.

\bibitem[Zhang et~al.(2021{\natexlab{b}})Zhang, Hooi, Hong, and
  Feng]{zhang2021test}
Yifan Zhang, Bryan Hooi, Lanqing Hong, and Jiashi Feng.
\newblock Test-agnostic long-tailed recognition by test-time aggregating
  diverse experts with self-supervision.
\newblock \emph{arXiv preprint arXiv:2107.09249}, 2021{\natexlab{b}}.

\bibitem[Zhong et~al.(2021)Zhong, Cui, Liu, and Jia]{zhong2021improving}
Zhisheng Zhong, Jiequan Cui, Shu Liu, and Jiaya Jia.
\newblock Improving calibration for long-tailed recognition.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 16489--16498, 2021.

\bibitem[Zhu et~al.(2022)Zhu, Wang, Chen, Chen, and Jiang]{Zhu_2022_CVPR}
Jianggang Zhu, Zheng Wang, Jingjing Chen, Yi-Ping~Phoebe Chen, and Yu-Gang
  Jiang.
\newblock Balanced contrastive learning for long-tailed visual recognition.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, pages 6908--6917, June 2022.

\bibitem[Zhuang et~al.(2022)Zhuang, Gong, Yuan, Cui, Adam, Dvornek, sekhar
  tatikonda, s~Duncan, and Liu]{zhuang2022surrogate}
Juntang Zhuang, Boqing Gong, Liangzhe Yuan, Yin Cui, Hartwig Adam, Nicha~C
  Dvornek, sekhar tatikonda, James s~Duncan, and Ting Liu.
\newblock Surrogate gap minimization improves sharpness-aware training.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=edONMAnhLu-}.

\end{thebibliography}
