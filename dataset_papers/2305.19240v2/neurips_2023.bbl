\begin{thebibliography}{62}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abramson et~al.(2020)Abramson, Ahuja, Brussee, Carnevale, Cassin, Clark, Dudzik, Georgiev, Guy, Harley, Hill, Hung, Kenton, Landon, Lillicrap, Mathewson, Muldal, Santoro, Savinov, Varma, Wayne, Wong, Yan, and Zhu]{Abramson20}
J.~Abramson, A.~Ahuja, A.~Brussee, F.~Carnevale, M.~Cassin, S.~Clark, A.~Dudzik, P.~Georgiev, A.~Guy, T.~Harley, F.~Hill, A.~Hung, Z.~Kenton, J.~Landon, T.~P. Lillicrap, K.~W. Mathewson, A.~Muldal, A.~Santoro, N.~Savinov, V.~Varma, G.~Wayne, N.~Wong, C.~Yan, and R.~Zhu.
\newblock Imitating interactive intelligence.
\newblock \emph{arXiv}, abs/2012.05672, 2020.

\bibitem[Andreas et~al.(2016)Andreas, Klein, and Levine]{sketches}
J.~Andreas, D.~Klein, and S.~Levine.
\newblock Modular multitask reinforcement learning with policy sketches, 2016.

\bibitem[Argall et~al.(2009)Argall, Chernova, Veloso, and Browning]{argall2009survey}
B.~D. Argall, S.~Chernova, M.~Veloso, and B.~Browning.
\newblock A survey of robot learning from demonstration.
\newblock \emph{Robotics and autonomous systems}, 57\penalty0 (5):\penalty0 469--483, 2009.

\bibitem[Bacon et~al.(2017)Bacon, Harb, and Precup]{bacon2017option}
P.-L. Bacon, J.~Harb, and D.~Precup.
\newblock The option-critic architecture.
\newblock In \emph{Thirty-First AAAI Conference on Artificial Intelligence}, 2017.

\bibitem[Barto and Mahadevan(2003)]{barto2003recent}
A.~G. Barto and S.~Mahadevan.
\newblock Recent advances in hierarchical reinforcement learning.
\newblock \emph{Discrete event dynamic systems}, 13\penalty0 (1-2):\penalty0 41--77, 2003.

\bibitem[Billard et~al.(2008)Billard, Calinon, Dillmann, and Schaal]{billard2008survey}
A.~Billard, S.~Calinon, R.~Dillmann, and S.~Schaal.
\newblock Survey: Robot programming by demonstration.
\newblock \emph{Handbook of robotics}, 59\penalty0 (BOOK\_CHAP), 2008.

\bibitem[Brockman et~al.(2016)Brockman, Cheung, Pettersson, Schneider, Schulman, Sidor, Sutskever, and Zemel]{brockman2016openai}
G.~Brockman, V.~Cheung, L.~Pettersson, J.~Schneider, J.~Schulman, S.~Sidor, I.~Sutskever, and R.~S. Zemel.
\newblock Openai gym.
\newblock \emph{arXiv preprint arXiv:1606.01540}, 2016.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.]{brown2020language}
T.~B. Brown, B.~Mann, N.~Ryder, M.~Subbiah, J.~Kaplan, P.~Dhariwal, A.~Neelakantan, P.~Shyam, G.~Sastry, A.~Askell, et~al.
\newblock Language models are few-shot learners.
\newblock \emph{arXiv preprint arXiv:2005.14165}, 2020.

\bibitem[Bruce et~al.(2023)Bruce, Hambro, Azar, and Bellemare]{bruce2023learning}
D.~Bruce, E.~Hambro, M.~Azar, and M.~G. Bellemare.
\newblock Learning about progress from experts.
\newblock In \emph{International Conference on Learning Representations}, 2023.

\bibitem[Bulatov et~al.(2022)Bulatov, Kuratov, and Burtsev]{bulatov2022recurrent}
A.~Bulatov, Y.~Kuratov, and M.~Burtsev.
\newblock Recurrent memory transformer.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 11079--11091, 2022.

\bibitem[Chen et~al.(2021)Chen, Lu, Rajeswaran, Lee, Grover, Laskin, Abbeel, Srinivas, and Mordatch]{chen2021dt}
L.~Chen, K.~Lu, A.~Rajeswaran, K.~Lee, A.~Grover, M.~Laskin, P.~Abbeel, A.~Srinivas, and I.~Mordatch.
\newblock Decision transformer: Reinforcement learning via sequence modeling.
\newblock \emph{CoRR}, abs/2106.01345, 2021.
\newblock URL \url{https://arxiv.org/abs/2106.01345}.

\bibitem[Clever et~al.(2021)Clever, Handa, Mazhar, Parker, Shapira, Wan, Narang, Akinola, Cakmak, and Fox]{clever2021assistive}
H.~M. Clever, A.~Handa, H.~Mazhar, K.~Parker, O.~Shapira, Q.~Wan, Y.~Narang, I.~Akinola, M.~Cakmak, and D.~Fox.
\newblock Assistive tele-op: Leveraging transformers to collect robotic task demonstrations.
\newblock \emph{arXiv preprint arXiv:2112.05129}, 2021.

\bibitem[Dai et~al.(2019)Dai, Yang, Yang, Carbonell, Le, and Salakhutdinov]{dai2019transformer}
Z.~Dai, Z.~Yang, Y.~Yang, J.~Carbonell, Q.~V. Le, and R.~Salakhutdinov.
\newblock Transformer-xl: Attentive language models beyond a fixed-length context.
\newblock \emph{arXiv preprint arXiv:1901.02860}, 2019.

\bibitem[Dasari and Gupta(2020)]{dasari2020transformers}
S.~Dasari and A.~Gupta.
\newblock Transformers for one-shot visual imitation.
\newblock \emph{arXiv preprint arXiv:2011.05970}, 2020.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, pages 4171--4186, 2018.
\newblock \doi{10.18653/v1/N19-1423}.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, et~al.]{dosovitskiy2020image}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai, T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Eysenbach et~al.(2018)Eysenbach, Gupta, Ibarz, and Levine]{diversity}
B.~Eysenbach, A.~Gupta, J.~Ibarz, and S.~Levine.
\newblock Diversity is all you need: Learning skills without a reward function.
\newblock \emph{CoRR}, abs/1802.06070, 2018.
\newblock URL \url{http://arxiv.org/abs/1802.06070}.

\bibitem[Florence et~al.(2019)Florence, Manuelli, and Tedrake]{florence2019self}
P.~Florence, L.~Manuelli, and R.~Tedrake.
\newblock Self-supervised correspondence in visuomotor policy learning.
\newblock \emph{IEEE Robotics and Automation Letters}, 5\penalty0 (2):\penalty0 492--499, 2019.

\bibitem[Florensa et~al.(2017)Florensa, Duan, and Abbeel]{snn}
C.~Florensa, Y.~Duan, and P.~Abbeel.
\newblock Stochastic neural networks for hierarchical reinforcement learning, 2017.

\bibitem[Fu et~al.(2020)Fu, Kumar, Nachum, Tucker, and Levine]{fu2020d4rl}
J.~Fu, A.~Kumar, O.~Nachum, G.~Tucker, and S.~Levine.
\newblock D4rl: Datasets for deep data-driven reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2004.07219}, 2020.

\bibitem[Fujimoto et~al.(2018)Fujimoto, Hoof, and Meger]{fujimoto2018addressing}
S.~Fujimoto, H.~Hoof, and D.~Meger.
\newblock Addressing function approximation error in actor-critic methods.
\newblock In \emph{International Conference on Machine Learning}, volume~80 of \emph{Proceedings of Machine Learning Research}, pages 1587--1596. PMLR, {PMLR}, 2018.

\bibitem[Gulcehre et~al.(2020)Gulcehre, Wang, Novikov, Le~Paine, Gomez~Colmenarejo, Zolna, Agarwal, Merel, Mankowitz, Paduraru, et~al.]{gulcehre2020rl}
C.~Gulcehre, Z.~Wang, A.~Novikov, T.~Le~Paine, S.~Gomez~Colmenarejo, K.~Zolna, R.~Agarwal, J.~Merel, D.~Mankowitz, C.~Paduraru, et~al.
\newblock Rl unplugged: Benchmarks for offline reinforcement learning.
\newblock \emph{arXiv e-prints}, pages arXiv--2006, 2020.

\bibitem[Hambro et~al.(2022{\natexlab{a}})Hambro, Mohanty, Babaev, Byeon, Chakraborty, Grefenstette, Jiang, Daejin, Kanervisto, Kim, Kim, Kirk, Kurin, K{\"u}ttler, Kwon, Lee, Mella, Nardelli, Nazarov, Ovsov, Holder, Raileanu, Ramanauskas, Rockt{\"a}schel, Rothermel, Samvelyan, Sorokin, Sypetkowski, and Sypetkowski]{hambro2021insights}
E.~Hambro, S.~Mohanty, D.~Babaev, M.~Byeon, D.~Chakraborty, E.~Grefenstette, M.~Jiang, J.~Daejin, A.~Kanervisto, J.~Kim, S.~Kim, R.~Kirk, V.~Kurin, H.~K{\"u}ttler, T.~Kwon, D.~Lee, V.~Mella, N.~Nardelli, I.~Nazarov, N.~Ovsov, J.~Holder, R.~Raileanu, K.~Ramanauskas, T.~Rockt{\"a}schel, D.~Rothermel, M.~Samvelyan, D.~Sorokin, M.~Sypetkowski, and M.~Sypetkowski.
\newblock Insights from the neurips 2021 nethack challenge.
\newblock In \emph{Proceedings of the NeurIPS 2021 Competitions and Demonstrations Track}, pages 41--52, 2022{\natexlab{a}}.

\bibitem[Hambro et~al.(2022{\natexlab{b}})Hambro, Raileanu, Rothermel, Mella, Rockt{\"a}schel, K{\"u}ttler, and Murray]{hambro2022dungeons}
E.~Hambro, R.~Raileanu, D.~Rothermel, V.~Mella, T.~Rockt{\"a}schel, H.~K{\"u}ttler, and N.~Murray.
\newblock Dungeons and data: A large-scale nethack dataset.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022{\natexlab{b}}.

\bibitem[Hendrycks and Gimpel(2016)]{hendrycks2016gaussian}
D.~Hendrycks and K.~Gimpel.
\newblock Gaussian error linear units (gelus).
\newblock \emph{arXiv preprint arXiv:1606.08415}, 2016.

\bibitem[Ho and Ermon(2016)]{ho2016generative}
J.~Ho and S.~Ermon.
\newblock Generative adversarial imitation learning.
\newblock In \emph{Advances in neural information processing systems}, volume~29, pages 4565--4573, 2016.

\bibitem[Jaegle et~al.(2021)Jaegle, Gimeno, Brock, Vinyals, Zisserman, and Carreira]{jaegle2021perceiver}
A.~Jaegle, F.~Gimeno, A.~Brock, O.~Vinyals, A.~Zisserman, and J.~Carreira.
\newblock Perceiver: General perception with iterative attention.
\newblock In \emph{International conference on machine learning}, pages 4651--4664. PMLR, 2021.

\bibitem[Jang et~al.(2017)Jang, Gu, and Poole]{jang2017categorical}
E.~Jang, S.~Gu, and B.~Poole.
\newblock Categorical reparameterization with gumbel-softmax.
\newblock In \emph{5th International Conference on Learning Representations, {ICLR} 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings}. OpenReview.net, 2017.

\bibitem[Janner et~al.(2021)Janner, Li, and Levine]{janner2021offline}
M.~Janner, Q.~Li, and S.~Levine.
\newblock Offline reinforcement learning as one big sequence modeling problem.
\newblock \emph{Advances in neural information processing systems}, 34, 2021.

\bibitem[Kaplan et~al.(2020)Kaplan, McCandlish, Henighan, Brown, Chess, Child, Gray, Radford, Wu, and Amodei]{Kaplan01}
J.~Kaplan, S.~McCandlish, T.~Henighan, T.~B. Brown, B.~Chess, R.~Child, S.~Gray, A.~Radford, J.~Wu, and D.~Amodei.
\newblock Scaling laws for neural language models.
\newblock \emph{arXiv}, abs/2001.08361, 2020.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
D.~Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kumar et~al.(2019)Kumar, Fu, Soh, Tucker, and Levine]{kumar2019stabilizing}
A.~Kumar, J.~Fu, M.~Soh, G.~Tucker, and S.~Levine.
\newblock Stabilizing off-policy q-learning via bootstrapping error reduction.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Kumar et~al.(2020)Kumar, Zhou, Tucker, and Levine]{kumar2020conservative}
A.~Kumar, A.~Zhou, G.~Tucker, and S.~Levine.
\newblock Conservative q-learning for offline reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 1179--1191, 2020.

\bibitem[Kuttler et~al.(2020)Kuttler, Nardelli, Lavril, Selvatici, Sivakumar, Bellemare, Munos, Graves, and Bellemare]{kuettler2020nethack}
H.~Kuttler, N.~Nardelli, T.~Lavril, M.~Selvatici, V.~Sivakumar, M.~G. Bellemare, R.~Munos, A.~Graves, and M.~G. Bellemare.
\newblock The nethack learning environment.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Le et~al.(2018)Le, Jiang, Agarwal, Dud{\'\i}k, Yue, and Daum{\'e}~III]{le2018hierarchical}
H.~Le, N.~Jiang, A.~Agarwal, M.~Dud{\'\i}k, Y.~Yue, and H.~Daum{\'e}~III.
\newblock Hierarchical imitation and reinforcement learning.
\newblock In \emph{International conference on machine learning}, pages 2917--2926. PMLR, 2018.

\bibitem[Levine et~al.(2020)Levine, Kumar, Tucker, and Fu]{levine2020offline}
S.~Levine, A.~Kumar, G.~Tucker, and J.~Fu.
\newblock Offline reinforcement learning: Tutorial, review, and perspectives on open problems.
\newblock \emph{arXiv preprint arXiv:2005.01643}, 2020.

\bibitem[Levy et~al.(2017)Levy, Konidaris, Platt, and Saenko]{hac}
A.~Levy, G.~Konidaris, R.~Platt, and K.~Saenko.
\newblock Learning multi-level hierarchies with hindsight, 2017.

\bibitem[Mandi et~al.(2021)Mandi, Liu, Lee, and Abbeel]{mandi2021towards}
Z.~Mandi, F.~Liu, K.~Lee, and P.~Abbeel.
\newblock Towards more generalizable one-shot visual imitation learning.
\newblock \emph{arXiv preprint arXiv:2110.13423}, 2021.

\bibitem[Mella et~al.(2022)Mella, Hambro, Rothermel, and K{\"{u}}ttler]{moolib2022}
V.~Mella, E.~Hambro, D.~Rothermel, and H.~K{\"{u}}ttler.
\newblock {moolib: A Platform for Distributed RL}.
\newblock 2022.
\newblock URL \url{https://github.com/facebookresearch/moolib}.

\bibitem[Nachum et~al.(2018)Nachum, Gu, Lee, and Levine]{hiro}
O.~Nachum, S.~Gu, H.~Lee, and S.~Levine.
\newblock Data-efficient hierarchical reinforcement learning.
\newblock \emph{CoRR}, abs/1805.08296, 2018.
\newblock URL \url{http://arxiv.org/abs/1805.08296}.

\bibitem[Nachum et~al.(2019)Nachum, Gu, Lee, and Levine]{nachum2019near-optimal}
O.~Nachum, S.~Gu, H.~Lee, and S.~Levine.
\newblock Near-optimal representation learning for hierarchical reinforcement learning.
\newblock In \emph{7th International Conference on Learning Representations, {ICLR} 2019, New Orleans, LA, USA, May 6-9, 2019}. OpenReview.net, 2019.

\bibitem[Osa et~al.(2018)Osa, Pajarinen, Neumann, Bagnell, Abbeel, and Peters]{osa2018algorithmic}
T.~Osa, J.~Pajarinen, G.~Neumann, J.~A. Bagnell, P.~Abbeel, and J.~Peters.
\newblock An algorithmic perspective on imitation learning.
\newblock \emph{arXiv preprint arXiv:1811.06711}, 2018.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan, Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
A.~Paszke, S.~Gross, F.~Massa, A.~Lerer, J.~Bradbury, G.~Chanan, T.~Killeen, Z.~Lin, N.~Gimelshein, L.~Antiga, et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock \emph{Advances in neural information processing systems}, 32:\penalty0 8026--8037, 2019.

\bibitem[Peng et~al.(2018)Peng, Abbeel, Levine, and van~de Panne]{peng2018deepmimic}
X.~B. Peng, P.~Abbeel, S.~Levine, and M.~van~de Panne.
\newblock Deepmimic: Example-guided deep reinforcement learning of physics-based character skills.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 37\penalty0 (4):\penalty0 1--14, 2018.

\bibitem[Peng et~al.(2021)Peng, Ma, Abbeel, Levine, and Kanazawa]{peng2021amp}
X.~B. Peng, Z.~Ma, P.~Abbeel, S.~Levine, and A.~Kanazawa.
\newblock Amp: Adversarial motion priors for stylized physics-based character control.
\newblock \emph{ACM Transactions on Graphics (TOG)}, 40\penalty0 (4):\penalty0 1--20, 2021.

\bibitem[Petrenko et~al.(2020)Petrenko, Huang, Kumar, Sukhatme, and Koltun]{petrenko2020sample}
A.~Petrenko, Z.~Huang, T.~Kumar, G.~Sukhatme, and V.~Koltun.
\newblock Sample factory: Egocentric 3d control from pixels at 100000 fps with asynchronous reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pages 7652--7662. PMLR, 2020.

\bibitem[Pomerleau(1988)]{pomerleau1988alvinn}
D.~A. Pomerleau.
\newblock Alvinn: An autonomous land vehicle in a neural network.
\newblock \emph{Advances in neural information processing systems}, 1, 1988.

\bibitem[Rahmatizadeh et~al.(2018)Rahmatizadeh, Abolghasemi, B{\"o}l{\"o}ni, and Levine]{rahmatizadeh2018vision}
R.~Rahmatizadeh, P.~Abolghasemi, L.~B{\"o}l{\"o}ni, and S.~Levine.
\newblock Vision-based multi-task manipulation for inexpensive robots using end-to-end learning from demonstration.
\newblock In \emph{2018 IEEE international conference on robotics and automation (ICRA)}, pages 3758--3765. IEEE, 2018.

\bibitem[Reed et~al.(2022)Reed, Zolna, Parisotto, Colmenarejo, Novikov, Barth-Maron, Gimenez, Sulsky, Kay, Springenberg, et~al.]{reed2022generalist}
S.~Reed, K.~Zolna, E.~Parisotto, S.~G. Colmenarejo, A.~Novikov, G.~Barth-Maron, M.~Gimenez, Y.~Sulsky, J.~Kay, J.~T. Springenberg, et~al.
\newblock A generalist agent.
\newblock \emph{arXiv preprint arXiv:2205.06175}, 2022.

\bibitem[Schaal(1999)]{schaal1999imitation}
S.~Schaal.
\newblock Is imitation learning the route to humanoid robots?
\newblock \emph{Trends in cognitive sciences}, 3\penalty0 (6):\penalty0 233--242, 1999.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and Klimov]{schulman2017proximal}
J.~Schulman, F.~Wolski, P.~Dhariwal, A.~Radford, and O.~Klimov.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Shafiullah et~al.(2022)Shafiullah, Cui, Altanzaya, and Pinto]{shafiullah2022behavior}
N.~M. Shafiullah, Z.~Cui, A.~A. Altanzaya, and L.~Pinto.
\newblock Behavior transformers: Cloning $ k $ modes with one stone.
\newblock \emph{Advances in neural information processing systems}, 35:\penalty0 22955--22968, 2022.

\bibitem[Shankar et~al.(2020)Shankar, Tulsiani, Pinto, and Gupta]{shankar2020discovering}
T.~Shankar, S.~Tulsiani, L.~Pinto, and A.~Gupta.
\newblock Discovering motor programs by recomposing demonstrations.
\newblock In \emph{International Conference on Learning Representations}, 2020.
\newblock URL \url{https://openreview.net/forum?id=rkgHY0NYwr}.

\bibitem[Sharma et~al.(2019)Sharma, Gu, Levine, Kumar, and Hausman]{DADS}
A.~Sharma, S.~Gu, S.~Levine, V.~Kumar, and K.~Hausman.
\newblock Dynamics-aware unsupervised discovery of skills.
\newblock \emph{CoRR}, abs/1907.01657, 2019.
\newblock URL \url{http://arxiv.org/abs/1907.01657}.

\bibitem[Tassa et~al.(2018)Tassa, Silver, Schrittwieser, Guez, Sifre, Driessche, Dieleman, Greff, Erez, and Petersen]{tassa2018deepmind}
Y.~Tassa, D.~Silver, J.~Schrittwieser, A.~Guez, L.~Sifre, G.~v.~d. Driessche, S.~Dieleman, K.~Greff, T.~Erez, and S.~Petersen.
\newblock Deepmind control suite.
\newblock \emph{arXiv preprint arXiv:1801.01294}, 2018.

\bibitem[Team et~al.(2023)Team, Bauer, Baumli, Baveja, Behbahani, Bhoopchand, Bradley-Schmieg, Chang, Clay, Collister, et~al.]{team2023human}
A.~A. Team, J.~Bauer, K.~Baumli, S.~Baveja, F.~Behbahani, A.~Bhoopchand, N.~Bradley-Schmieg, M.~Chang, N.~Clay, A.~Collister, et~al.
\newblock Human-timescale adaptation in an open-ended task space.
\newblock \emph{arXiv preprint arXiv:2301.07608}, 2023.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{vaswani2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez, L.~Kaiser, and I.~Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, {USA}}, pages 5998--6008, 2017.

\bibitem[Wu et~al.(2019)Wu, Tucker, and Nachum]{wu2019behavior}
Y.~Wu, G.~Tucker, and O.~Nachum.
\newblock Behavior regularized offline reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1911.11361}, 2019.

\bibitem[Zeng et~al.(2020)Zeng, Florence, Tompson, Welker, Chien, Attarian, Armstrong, Krasin, Duong, Sindhwani, et~al.]{zeng2020transporter}
A.~Zeng, P.~Florence, J.~Tompson, S.~Welker, J.~Chien, M.~Attarian, T.~Armstrong, I.~Krasin, D.~Duong, V.~Sindhwani, et~al.
\newblock Transporter networks: Rearranging the visual world for robotic manipulation.
\newblock In \emph{Conference on Robot Learning}, 2020.

\bibitem[Zhang et~al.(2018)Zhang, McCarthy, Jow, Lee, Chen, Goldberg, and Abbeel]{zhang2018deep}
T.~Zhang, Z.~McCarthy, O.~Jow, D.~Lee, X.~Chen, K.~Goldberg, and P.~Abbeel.
\newblock Deep imitation learning for complex manipulation tasks from virtual reality teleoperation.
\newblock In \emph{ICRA}, pages 5628--5635. IEEE, 2018.

\bibitem[Zhong et~al.(2022)Zhong, Hambro, Grefenstette, Park, Azar, and Bellemare]{zhong2022improving}
Y.~Zhong, E.~Hambro, E.~Grefenstette, T.~Park, M.~Azar, and M.~G. Bellemare.
\newblock Improving policy learning via language dynamics distillation.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2022.

\bibitem[Zhu et~al.(2018)Zhu, Wang, Merel, Rusu, Erez, Cabi, Tunyasuvunakool, Kram{\'a}r, Hadsell, de~Freitas, et~al.]{zhu2018reinforcement}
Y.~Zhu, Z.~Wang, J.~Merel, A.~Rusu, T.~Erez, S.~Cabi, S.~Tunyasuvunakool, J.~Kram{\'a}r, R.~Hadsell, N.~de~Freitas, et~al.
\newblock Reinforcement and imitation learning for diverse visuomotor skills.
\newblock \emph{arXiv preprint arXiv:1802.09564}, 2018.

\end{thebibliography}
