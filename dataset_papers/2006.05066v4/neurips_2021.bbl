\begin{thebibliography}{37}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bhalgat et~al.(2020)Bhalgat, Zhang, Lin, and
  Porikli]{bhalgat2020structured}
Bhalgat, Y., Zhang, Y., Lin, J.~M., and Porikli, F.
\newblock Structured convolutions for efficient neural network design.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 5553--5564, 2020.

\bibitem[Chen et~al.(2019)Chen, Wang, Pang, Cao, Xiong, Li, Sun, Feng, Liu, Xu,
  Zhang, Cheng, Zhu, Cheng, Zhao, Li, Lu, Zhu, Wu, Dai, Wang, Shi, Ouyang, Loy,
  and Lin]{mmdetection}
Chen, K., Wang, J., Pang, J., Cao, Y., Xiong, Y., Li, X., Sun, S., Feng, W.,
  Liu, Z., Xu, J., Zhang, Z., Cheng, D., Zhu, C., Cheng, T., Zhao, Q., Li, B.,
  Lu, X., Zhu, R., Wu, Y., Dai, J., Wang, J., Shi, J., Ouyang, W., Loy, C.~C.,
  and Lin, D.
\newblock {MMDetection}: Open mmlab detection toolbox and benchmark.
\newblock \emph{arXiv preprint arXiv:1906.07155}, 2019.

\bibitem[Denton et~al.(2014)Denton, Zaremba, Bruna, LeCun, and
  Fergus]{denton2014exploiting}
Denton, E.~L., Zaremba, W., Bruna, J., LeCun, Y., and Fergus, R.
\newblock Exploiting linear structure within convolutional networks for
  efficient evaluation.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1269--1277, 2014.

\bibitem[Eigen et~al.(2014)Eigen, Rolfe, Fergus, and
  LeCun]{eigen2014understanding}
Eigen, D., Rolfe, J.~T., Fergus, R., and LeCun, Y.
\newblock Understanding deep architectures using a recursive convolutional
  network.
\newblock In \emph{2nd International Conference on Learning Representations,
  {ICLR} 2014}, 2014.

\bibitem[{Graves} et~al.(2013){Graves}, {Mohamed}, and
  {Hinton}]{graves2013speech}
{Graves}, A., {Mohamed}, A., and {Hinton}, G.
\newblock Speech recognition with deep recurrent neural networks.
\newblock In \emph{2013 IEEE International Conference on Acoustics, Speech and
  Signal Processing}, pp.\  6645--6649, 2013.

\bibitem[{Guo} et~al.(2019){Guo}, {Yu}, {Wu}, {Liang}, {Qin}, and
  {Yan}]{guo2019dynamic}
{Guo}, Q., {Yu}, Z., {Wu}, Y., {Liang}, D., {Qin}, H., and {Yan}, J.
\newblock Dynamic recursive neural network.
\newblock In \emph{2019 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pp.\  5142--5151, 2019.

\bibitem[Han et~al.(2016)Han, Mao, and Dally]{han2016deep}
Han, S., Mao, H., and Dally, W.~J.
\newblock Deep compression: Compressing deep neural network with pruning,
  trained quantization and huffman coding.
\newblock In Bengio, Y. and LeCun, Y. (eds.), \emph{4th International
  Conference on Learning Representations, {ICLR} 2016, San Juan, Puerto Rico,
  May 2-4, 2016, Conference Track Proceedings}, 2016.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[He et~al.(2017{\natexlab{a}})He, Gkioxari, Dollar, and
  Girshick]{he207mask}
He, K., Gkioxari, G., Dollar, P., and Girshick, R.
\newblock Mask r-cnn.
\newblock \emph{2017 IEEE International Conference on Computer Vision (ICCV)},
  Oct 2017{\natexlab{a}}.

\bibitem[He et~al.(2017{\natexlab{b}})He, Zhang, and Sun]{he2017channel}
He, Y., Zhang, X., and Sun, J.
\newblock Channel pruning for accelerating very deep neural networks.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  1389--1397, 2017{\natexlab{b}}.

\bibitem[Howard et~al.(2017)Howard, Zhu, Chen, Kalenichenko, Wang, Weyand,
  Andreetto, and Adam]{howard2017mobilenets}
Howard, A.~G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T.,
  Andreetto, M., and Adam, H.
\newblock Mobilenets: Efficient convolutional neural networks for mobile vision
  applications.
\newblock \emph{arXiv preprint arXiv:1704.04861}, 2017.

\bibitem[Huang et~al.(2017)Huang, Liu, Van Der~Maaten, and
  Weinberger]{huang2017densely}
Huang, G., Liu, Z., Van Der~Maaten, L., and Weinberger, K.~Q.
\newblock Densely connected convolutional networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  4700--4708, 2017.

\bibitem[Ioffe \& Szegedy(2015)Ioffe and Szegedy]{ioffe2015batch}
Ioffe, S. and Szegedy, C.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  448--456, 2015.

\bibitem[Jaderberg et~al.(2014)Jaderberg, Vedaldi, and
  Zisserman]{jaderberg2014speeding}
Jaderberg, M., Vedaldi, A., and Zisserman, A.
\newblock Speeding up convolutional neural networks with low rank expansions.
\newblock \emph{arXiv preprint arXiv:1405.3866}, 2014.

\bibitem[Jastrzebski et~al.(2018)Jastrzebski, Arpit, Ballas, Verma, Che, and
  Bengio]{jastrzebski2018residual}
Jastrzebski, S., Arpit, D., Ballas, N., Verma, V., Che, T., and Bengio, Y.
\newblock Residual connections encourage iterative inference.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Kim et~al.(2016)Kim, Kwon~Lee, and Mu~Lee]{kim2016deeply}
Kim, J., Kwon~Lee, J., and Mu~Lee, K.
\newblock Deeply-recursive convolutional network for image super-resolution.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  1637--1645, 2016.

\bibitem[LeCun et~al.(1990)LeCun, Denker, and Solla]{lecun1990optimal}
LeCun, Y., Denker, J.~S., and Solla, S.~A.
\newblock Optimal brain damage.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  598--605, 1990.

\bibitem[Li et~al.(2017)Li, Kadav, Durdanovic, Samet, and Graf]{li2017pruning}
Li, H., Kadav, A., Durdanovic, I., Samet, H., and Graf, H.~P.
\newblock Pruning filters for efficient convnets.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Li et~al.(2019{\natexlab{a}})Li, Gu, Van~Gool, and
  Timofte]{li2019learning}
Li, Y., Gu, S., Van~Gool, L., and Timofte, R.
\newblock Learning filter basis for convolutional neural network compression.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, 2019{\natexlab{a}}.

\bibitem[Li et~al.(2019{\natexlab{b}})Li, Lin, Zhang, Liu, Doermann, Wu, Huang,
  and Ji]{li2019exploiting}
Li, Y., Lin, S., Zhang, B., Liu, J., Doermann, D., Wu, Y., Huang, F., and Ji,
  R.
\newblock Exploiting kernel sparsity and entropy for interpretable cnn
  compression.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  2800--2809, 2019{\natexlab{b}}.

\bibitem[Liang \& Hu(2015)Liang and Hu]{liang2015recurrent}
Liang, M. and Hu, X.
\newblock Recurrent convolutional neural network for object recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  3367--3375, 2015.

\bibitem[Lin et~al.(2017)Lin, Goyal, Girshick, He, and
  Doll{\'a}r]{lin2017focal}
Lin, T.-Y., Goyal, P., Girshick, R., He, K., and Doll{\'a}r, P.
\newblock Focal loss for dense object detection.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, 2017.

\bibitem[Pascanu et~al.(2013)Pascanu, Mikolov, and
  Bengio]{pascanu2013difficulty}
Pascanu, R., Mikolov, T., and Bengio, Y.
\newblock On the difficulty of training recurrent neural networks.
\newblock In \emph{International conference on machine learning}, pp.\
  1310--1318, 2013.

\bibitem[Polyak \& Wolf(2015)Polyak and Wolf]{polyak2015channel}
Polyak, A. and Wolf, L.
\newblock Channel-level acceleration of deep face representations.
\newblock \emph{IEEE Access}, 3:\penalty0 2163--2175, 2015.

\bibitem[Qiu et~al.(2018)Qiu, Cheng, Sapiro, et~al.]{qiu2018dcfnet}
Qiu, Q., Cheng, X., Sapiro, G., et~al.
\newblock Dcfnet: Deep neural network with decomposed convolutional filters.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  4198--4207. PMLR, 2018.

\bibitem[Ren et~al.(2017)Ren, He, Girshick, and Sun]{ren2017faster}
Ren, S., He, K., Girshick, R., and Sun, J.
\newblock Faster r-cnn: Towards real-time object detection with region proposal
  networks.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, Jun 2017.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, et~al.]{russakovsky2015imagenet}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
  Karpathy, A., Khosla, A., Bernstein, M., et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{International journal of computer vision}, 115\penalty0
  (3):\penalty0 211--252, 2015.

\bibitem[Savarese \& Maire(2019)Savarese and Maire]{savarese2019learning}
Savarese, P. and Maire, M.
\newblock Learning implicitly recurrent {CNN}s through parameter sharing.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Socher et~al.(2011)Socher, Lin, Manning, and Ng]{socher2011parsing}
Socher, R., Lin, C.~C., Manning, C., and Ng, A.~Y.
\newblock Parsing natural scenes and natural language with recursive neural
  networks.
\newblock In \emph{Proceedings of the 28th international conference on machine
  learning (ICML-11)}, pp.\  129--136, 2011.

\bibitem[Vorontsov et~al.(2017)Vorontsov, Trabelsi, Kadoury, and
  Pal]{pmlr-v70-vorontsov17a}
Vorontsov, E., Trabelsi, C., Kadoury, S., and Pal, C.
\newblock On orthogonality and learning recurrent networks with long term
  dependencies.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning}, pp.\  3570--3578, 2017.

\bibitem[Wang et~al.(2018)Wang, Xu, Chunjing, Xu, and Tao]{wang2018learning}
Wang, Y., Xu, C., Chunjing, X., Xu, C., and Tao, D.
\newblock Learning versatile filters for efficient convolutional neural
  networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1608--1618, 2018.

\bibitem[Xie et~al.(2017)Xie, Girshick, Doll{\'a}r, Tu, and
  He]{xie2017aggregated}
Xie, S., Girshick, R., Doll{\'a}r, P., Tu, Z., and He, K.
\newblock Aggregated residual transformations for deep neural networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  1492--1500, 2017.

\bibitem[Xingjian et~al.(2015)Xingjian, Chen, Wang, Yeung, Wong, and
  Woo]{xingjian2015convolutional}
Xingjian, S., Chen, Z., Wang, H., Yeung, D.-Y., Wong, W.-K., and Woo, W.-c.
\newblock Convolutional lstm network: A machine learning approach for
  precipitation nowcasting.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  802--810, 2015.

\bibitem[Yang et~al.(2020)Yang, Yu, Jojic, Huan, and Huang]{yang2020fsnet}
Yang, Y., Yu, J., Jojic, N., Huan, J., and Huang, T.~S.
\newblock Fsnet: Compression of deep convolutional neural networks by filter
  summary.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Yang et~al.(2019)Yang, Wang, Liu, Chen, Xu, Shi, Xu, and
  Xu]{yang2019legonet}
Yang, Z., Wang, Y., Liu, C., Chen, H., Xu, C., Shi, B., Xu, C., and Xu, C.
\newblock {L}ego{N}et: Efficient convolutional neural networks with lego
  filters.
\newblock In Chaudhuri, K. and Salakhutdinov, R. (eds.), \emph{Proceedings of
  the 36th International Conference on Machine Learning}, volume~97 of
  \emph{Proceedings of Machine Learning Research}, pp.\  7005--7014. PMLR,
  09--15 Jun 2019.

\bibitem[Zamir et~al.(2017)Zamir, Wu, Sun, Shen, Shi, Malik, and
  Savarese]{zamir2017feedback}
Zamir, A.~R., Wu, T.-L., Sun, L., Shen, W.~B., Shi, B.~E., Malik, J., and
  Savarese, S.
\newblock Feedback networks.
\newblock In \emph{2017 IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pp.\  1808--1817. IEEE, 2017.

\bibitem[Zhang et~al.(2015)Zhang, Zou, He, and Sun]{zhang2015accelerating}
Zhang, X., Zou, J., He, K., and Sun, J.
\newblock Accelerating very deep convolutional networks for classification and
  detection.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 38\penalty0 (10):\penalty0 1943--1955, 2015.

\end{thebibliography}
