
@article{serviansky2020set2graph,
  title={Set2Graph: Learning Graphs From Sets},
  author={Serviansky, Hadar and Segol, Nimrod and Shlomi, Jonathan and Cranmer, Kyle and Gross, Eilam and Maron, Haggai and Lipman, Yaron},
  journal={arXiv preprint arXiv:2002.08772},
  year={2020}
}
@inproceedings{weinberger2006distance,
  title={Distance metric learning for large margin nearest neighbor classification},
  author={Weinberger, Kilian Q and Blitzer, John and Saul, Lawrence K},
  booktitle={Advances in neural information processing systems},
  pages={1473--1480},
  year={2006}
}

@article{aljalbout2018clustering,
  title={Clustering with deep learning: Taxonomy and new methods},
  author={Aljalbout, Elie and Golkov, Vladimir and Siddiqui, Yawar and Strobel, Maximilian and Cremers, Daniel},
  journal={arXiv preprint arXiv:1801.07648},
  year={2018}
}

@incollection{de1997computational,
  title={Computational geometry},
  author={De Berg, Mark and Van Kreveld, Marc and Overmars, Mark and Schwarzkopf, Otfried},
  booktitle={Computational geometry},
  pages={1--17},
  year={1997},
  publisher={Springer}
}

@article{stewart1990matrix,
  title={Matrix perturbation theory},
  author={Stewart, Gilbert W},
  year={1990},
  publisher={Citeseer}
}

@article{o2005critical,
  title={Critical points of the singular value decomposition},
  author={O'Neil, Kevin A},
  journal={SIAM journal on matrix analysis and applications},
  volume={27},
  number={2},
  pages={459--473},
  year={2005},
  publisher={SIAM}
}

@article{kulis2013metric,
  title={Metric learning: A survey},
  author={Kulis, Brian and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={5},
  number={4},
  pages={287--364},
  year={2013},
  publisher={Now Publishers, Inc.}
}

@article{Guest_2016,
   title={Jet flavor classification in high-energy physics with deep neural networks},
   volume={94},
   ISSN={2470-0029},
   url={http://dx.doi.org/10.1103/PhysRevD.94.112002},
   DOI={10.1103/physrevd.94.112002},
   number={11},
   journal={Physical Review D},
   publisher={American Physical Society (APS)},
   author={Guest, Daniel and Collado, Julian and Baldi, Pierre and Hsu, Shih-Chieh and Urban, Gregor and Whiteson, Daniel},
   year={2016},
   month={Dec}
}

@article{Carleo_2019,
   title={Machine learning and the physical sciences},
   volume={91},
   ISSN={1539-0756},
   url={http://dx.doi.org/10.1103/RevModPhys.91.045002},
   DOI={10.1103/revmodphys.91.045002},
   number={4},
   journal={Reviews of Modern Physics},
   publisher={American Physical Society (APS)},
   author={Carleo, Giuseppe and Cirac, Ignacio and Cranmer, Kyle and Daudet, Laurent and Schuld, Maria and Tishby, Naftali and Vogt-Maranto, Leslie and Zdeborová, Lenka},
   year={2019},
   month={Dec}
}

@article{Waltenberger:2011zz,
      author         = "Waltenberger, Wolfgang",
      title          = "{RAVE: A detector-independent toolkit to reconstruct
                        vertices}",
      journal        = "IEEE Trans. Nucl. Sci.",
      volume         = "58",
      year           = "2011",
      pages          = "434-444",
      doi            = "10.1109/TNS.2011.2119492",
      SLACcitation   = "%%CITATION = IETNA,58,434;%%"
}


@article{de_Favereau_2014,
   title={DELPHES 3: a modular framework for fast simulation of a generic collider experiment},
   volume={2014},
   ISSN={1029-8479},
   url={http://dx.doi.org/10.1007/JHEP02(2014)057},
   DOI={10.1007/jhep02(2014)057},
   number={2},
   journal={Journal of High Energy Physics},
   publisher={Springer Science and Business Media LLC},
   author={de Favereau, J. and Delaere, C. and Demin, P. and Giammanco, A. and Lemaître, V. and Mertens, A. and Selvaggi, M.},
   year={2014},
   month={Feb}
}

@article{Sj_strand_2015,
   title={An introduction to PYTHIA 8.2},
   volume={191},
   ISSN={0010-4655},
   url={http://dx.doi.org/10.1016/j.cpc.2015.01.024},
   DOI={10.1016/j.cpc.2015.01.024},
   journal={Computer Physics Communications},
   publisher={Elsevier BV},
   author={Sjöstrand, Torbjörn and Ask, Stefan and Christiansen, Jesper R. and Corke, Richard and Desai, Nishita and Ilten, Philip and Mrenna, Stephen and Prestel, Stefan and Rasmussen, Christine O. and Skands, Peter Z.},
   year={2015},
   month={Jun},
   pages={159–177}
}


@article{maron2019universality,
  title={On the universality of invariant networks},
  author={Maron, Haggai and Fetaya, Ethan and Segol, Nimrod and Lipman, Yaron},
  journal={arXiv preprint arXiv:1901.09342},
  year={2019}
}
@article{maron2020learning,
    title={On Learning Sets of Symmetric Elements},
    author={Haggai Maron and Or Litany and Gal Chechik and Ethan Fetaya},
    year={2020},
    journal={arXiv preprint arXiv:2002.08599}
}



@inproceedings{
maron2018invariant,
title={Invariant and Equivariant Graph Networks},
author={Haggai Maron and Heli Ben-Hamu and Nadav Shamir and Yaron Lipman},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=Syx72jC9tm},
}

@inproceedings{zaheer2017deep,
  title={Deep sets},
  author={Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Ruslan R and Smola, Alexander J},
  booktitle={Advances in neural information processing systems},
  pages={3391--3401},
  year={2017}
}

@article{kipf2016variational,
  title={Variational graph auto-encoders},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1611.07308},
  year={2016}
}
@inproceedings{garg2018supervising,
  title={Supervising unsupervised learning},
  author={Garg, Vikas},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4991--5001},
  year={2018}
}
@article{ferrari2015clustering,
  title={Clustering algorithm selection by meta-learning systems: A new distance-based problem characterization and ranking combination methods},
  author={Ferrari, Daniel Gomes and De Castro, Leandro Nunes},
  journal={Information Sciences},
  volume={301},
  pages={181--194},
  year={2015},
  publisher={Elsevier}
}
@inproceedings{ferrari2012clustering,
  title={Clustering algorithm recommendation: a meta-learning approach},
  author={Ferrari, Daniel G and de Castro, Leandro Nunes},
  booktitle={International Conference on Swarm, Evolutionary, and Memetic Computing},
  pages={143--150},
  year={2012},
  organization={Springer}
}
@article{hsu2019multi,
  title={Multi-class classification without multi-class labels},
  author={Hsu, Yen-Chang and Lv, Zhaoyang and Schlosser, Joel and Odom, Phillip and Kira, Zsolt},
  journal={arXiv preprint arXiv:1901.00544},
  year={2019}
}

@article{hsu2017learning,
  title={Learning to cluster in order to transfer across domains and tasks},
  author={Hsu, Yen-Chang and Lv, Zhaoyang and Kira, Zsolt},
  journal={arXiv preprint arXiv:1711.10125},
  year={2017}
}

@article{jiang2019meta,
  title={Meta-Learning to Cluster},
  author={Jiang, Yibo and Verma, Nakul},
  journal={arXiv preprint arXiv:1910.14134},
  year={2019}
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2019}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

@book{methodequivar,
author = {Chossat, Pascal and Lauterbach, Reiner},
year = {2000},
month = {02},
pages = {},
title = {Methods in Equivariant Bifurcations and Dynamical Systems},
isbn = {978-981-02-3828-5}
}

@inproceedings{rydh2007minimal,
  title={A minimal set of generators for the ring of multisymmetric functions},
  author={Rydh, David},
  booktitle={Annales de l'institut Fourier},
  volume={57},
  number={6},
  pages={1741--1769},
  year={2007}
}

@inproceedings{
segol2020on,
title={On Universal Equivariant Set Networks},
author={Nimrod Segol and Yaron Lipman},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HkxTwkrKDB}
}

@inproceedings{2019-Keriven-GNN,
  url = { http://arxiv.org/abs/1905.04943 },
  year = { 2019 },
  booktitle = { Proc. NIPS'19 },
  author = { N. Keriven and G. Peyr{\'e} },
  title = { Universal Invariant and Equivariant Graph Neural Networks },
}



@article{pont20172017,
  title={The 2017 davis challenge on video object segmentation},
  author={Pont-Tuset, Jordi and Perazzi, Federico and Caelles, Sergi and Arbel{\'a}ez, Pablo and Sorkine-Hornung, Alex and Van Gool, Luc},
  journal={arXiv preprint arXiv:1704.00675},
  year={2017}
}
@article{ravanbakhsh2016deep,
  title={Deep learning with sets and point clouds},
  author={Ravanbakhsh, Siamak and Schneider, Jeff and Poczos, Barnabas},
  journal={arXiv preprint arXiv:1611.04500},
  year={2016}
}
@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick and others},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Taipei, Taiwan}
}
@article{edwards2016towards,
  title={Towards a neural statistician},
  author={Edwards, Harrison and Storkey, Amos},
  journal={arXiv preprint arXiv:1606.02185},
  year={2016}
}

@inproceedings{su2015multi,
  title={Multi-view convolutional neural networks for 3d shape recognition},
  author={Su, Hang and Maji, Subhransu and Kalogerakis, Evangelos and Learned-Miller, Erik},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={945--953},
  year={2015}
}
@inproceedings{kalogerakis20173d,
  title={3D shape segmentation with projective convolutional networks},
  author={Kalogerakis, Evangelos and Averkiou, Melinos and Maji, Subhransu and Chaudhuri, Siddhartha},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3779--3788},
  year={2017}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{zhang2018learning,
  title={Learning Representations of Sets through Optimized Permutations},
  author={Zhang, Yan and Hare, Jonathon and Pr{\"u}gel-Bennett, Adam},
  journal={arXiv preprint arXiv:1812.03928},
  year={2018}
}
@article{murphy2018janossy,
  title={Janossy pooling: Learning deep permutation-invariant functions for variable-size inputs},
  author={Murphy, Ryan L and Srinivasan, Balasubramaniam and Rao, Vinayak and Ribeiro, Bruno},
  journal={arXiv preprint arXiv:1811.01900},
  year={2018}
}
@article{wagstaff2019limitations,
  title={On the limitations of representing functions on sets},
  author={Wagstaff, Edward and Fuchs, Fabian B and Engelcke, Martin and Posner, Ingmar and Osborne, Michael},
  journal={arXiv preprint arXiv:1901.09006},
  year={2019}
}

@article{bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@inproceedings{dfaust:CVPR:2017,
        title = {Dynamic {FAUST}: {R}egistering Human Bodies in Motion},
        author = {Bogo, Federica and Romero, Javier and Pons-Moll, Gerard and Black, Michael J.},
        booktitle = {IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
        month = jul,
        year = {2017},
        month_numeric = {7}
      }
      
@misc{vaswani2017attention,
    title={Attention Is All You Need},
    author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
    year={2017},
    eprint={1706.03762},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{ilse2018attention,
  title={Attention-based deep multiple instance learning},
  author={Ilse, Maximilian and Tomczak, Jakub M and Welling, Max},
  journal={arXiv preprint arXiv:1802.04712},
  year={2018}
}

@article{vinyals2015order,
  title={Order matters: Sequence to sequence for sets},
  author={Vinyals, Oriol and Bengio, Samy and Kudlur, Manjunath},
  journal={arXiv preprint arXiv:1511.06391},
  year={2015}
}

@misc{vinyals2015pointer,
    title={Pointer Networks},
    author={Oriol Vinyals and Meire Fortunato and Navdeep Jaitly},
    year={2015},
    eprint={1506.03134},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@article{yang2018attentional,
  title={Attentional Aggregation of Deep Feature Sets for Multi-view 3D Reconstruction},
  author={Yang, Bo and Wang, Sen and Markham, Andrew and Trigoni, Niki},
  journal={arXiv preprint arXiv:1808.00758},
  year={2018}
}

@article{liu2019permutation,
  title={Permutation-invariant Feature Restructuring for Correlation-aware Image Set-based Recognition},
  author={Liu, Xiaofeng and Guo, Zhenhua and Li, Site and Kong, Lingsheng and Jia, Ping and You, Jane and Kumar, BVK},
  journal={arXiv preprint arXiv:1908.01174},
  year={2019}
}
@inproceedings{lee2019set,
  title={Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks},
  author={Lee, Juho and Lee, Yoonho and Kim, Jungtaek and Kosiorek, Adam and Choi, Seungjin and Teh, Yee Whye},
  booktitle={International Conference on Machine Learning},
  pages={3744--3753},
  year={2019}
}

@book{simmons1963introduction,
  title={Introduction to topology and modern analysis},
  author={Simmons, George F},
  year={1963},
  publisher={Tokyo}
}

@article{yarotsky2018universal,
  title={Universal approximations of invariant maps by neural networks},
  author={Yarotsky, Dmitry},
  journal={arXiv preprint arXiv:1804.10306},
  year={2018}
}

@inproceedings{herzig2018mapping,
  title={Mapping images to scene graphs with permutation-invariant structured prediction},
  author={Herzig, Roei and Raboh, Moshiko and Chechik, Gal and Berant, Jonathan and Globerson, Amir},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7211--7221},
  year={2018}
}


@inproceedings{aittala2018burst,
  title={Burst image deblurring using permutation invariant convolutional neural networks},
  author={Aittala, Miika and Durand, Fr{\'e}do},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={731--747},
  year={2018}
}

@article{sridhar2019multiview,
  title={Multiview Aggregation for Learning Category-Specific Shape Reconstruction},
  author={Sridhar, Srinath and Rempe, Davis and Valentin, Julien and Bouaziz, Sofien and Guibas, Leonidas J},
  journal={arXiv preprint arXiv:1907.01085},
  year={2019}
}

@article{sannai2019universal,
  title={Universal approximations of permutation invariant/equivariant functions by deep neural networks},
  author={Sannai, Akiyoshi and Takai, Yuuki and Cordonnier, Matthieu},
  journal={arXiv preprint arXiv:1903.01939},
  year={2019}
}


@article{albooyeh2019incidence,
  title={Incidence Networks for Geometric Deep Learning},
  author={Albooyeh, Marjan and Bertolini, Daniele and Ravanbakhsh, Siamak},
  journal={arXiv preprint arXiv:1905.11460},
  year={2019}
}

@article{chen2019equivalence,
  title={On the equivalence between graph isomorphism testing and function approximation with GNNs},
  author={Chen, Zhengdao and Villar, Soledad and Chen, Lei and Bruna, Joan},
  journal={arXiv preprint arXiv:1905.12560},
  year={2019}
}


@article{maron2019provably,
  title={Provably Powerful Graph Networks},
  author={Maron, Haggai and Ben-Hamu, Heli and Serviansky, Hadar and Lipman, Yaron},
  journal={arXiv preprint arXiv:1905.11136},
  year={2019}
}

@article{murphy2019relational,
  title={Relational Pooling for Graph Representations},
  author={Murphy, Ryan L and Srinivasan, Balasubramaniam and Rao, Vinayak and Ribeiro, Bruno},
  journal={arXiv preprint arXiv:1903.02541},
  year={2019}
}

@article{keriven2019universal,
  author    = {Nicolas Keriven and
               Gabriel Peyr{\'{e}}},
  title     = {Universal Invariant and Equivariant Graph Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1905.04943},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.04943},
  archivePrefix = {arXiv},
  eprint    = {1905.04943},
  timestamp = {Tue, 28 May 2019 12:48:08 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1905-04943},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{cybenko1989approximation,
  title={Approximation by superpositions of a sigmoidal function},
  author={Cybenko, George},
  journal={Mathematics of control, signals and systems},
  volume={2},
  number={4},
  pages={303--314},
  year={1989},
  publisher={Springer}
}
@article{hornik1989multilayer,
  title={Multilayer feedforward networks are universal approximators},
  author={Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  journal={Neural networks},
  volume={2},
  number={5},
  pages={359--366},
  year={1989},
  publisher={Elsevier}
}
@inproceedings{lei2017deriving,
  title={Deriving neural architectures from sequence and graph kernels},
  author={Lei, Tao and Jin, Wengong and Barzilay, Regina and Jaakkola, Tommi},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2024--2033},
  year={2017},
  organization={JMLR. org}
}
@article{morris2019towards,
  title={Towards a practical $ k $-dimensional Weisfeiler-Leman algorithm},
  author={Morris, Christopher and Mutzel, Petra},
  journal={arXiv preprint arXiv:1904.01543},
  year={2019}
}
@inproceedings{zhang2017weisfeiler,
  title={Weisfeiler-Lehman neural machine for link prediction},
  author={Zhang, Muhan and Chen, Yixin},
  booktitle={Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={575--583},
  year={2017},
  organization={ACM}
}

@article{fey2019fast,
  title={Fast Graph Representation Learning with PyTorch Geometric},
  author={Fey, Matthias and Lenssen, Jan Eric},
  journal={arXiv preprint arXiv:1903.02428},
  year={2019}
}
@article{wu2018moleculenet,
  title={MoleculeNet: a benchmark for molecular machine learning},
  author={Wu, Zhenqin and Ramsundar, Bharath and Feinberg, Evan N and Gomes, Joseph and Geniesse, Caleb and Pappu, Aneesh S and Leswing, Karl and Pande, Vijay},
  journal={Chemical science},
  volume={9},
  number={2},
  pages={513--530},
  year={2018},
  publisher={Royal Society of Chemistry}
}

@article{ramakrishnan2014quantum,
  title={Quantum chemistry structures and properties of 134 kilo molecules},
  author={Ramakrishnan, Raghunathan and Dral, Pavlo O and Rupp, Matthias and Von Lilienfeld, O Anatole},
  journal={Scientific data},
  volume={1},
  pages={140022},
  year={2014},
  publisher={Nature Publishing Group}
}

@incollection{NIPS2018_7951,
title = {Mapping Images to Scene Graphs with Permutation-Invariant Structured Prediction},
author = {Herzig, Roei and Raboh, Moshiko and Chechik, Gal and Berant, Jonathan and Globerson, Amir},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
pages = {7211--7221},
year = {2018},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/7951-mapping-images-to-scene-graphs-with-permutation-invariant-structured-prediction.pdf}
}

@misc{kriege2019survey,
    title={A Survey on Graph Kernels},
    author={Nils M. Kriege and Fredrik D. Johansson and Christopher Morris},
    year={2019},
    eprint={1903.11835},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{hamilton2017representation,
  title={Representation learning on graphs: Methods and applications},
  author={Hamilton, William L and Ying, Rex and Leskovec, Jure},
  journal={arXiv preprint arXiv:1709.05584},
  year={2017}
}
@article{zhou2018graph,
  title={Graph neural networks: A review of methods and applications},
  author={Zhou, Jie and Cui, Ganqu and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Sun, Maosong},
  journal={arXiv preprint arXiv:1812.08434},
  year={2018}
}

@article{DBLP:journals/corr/abs-1812-04202,
  author    = {Ziwei Zhang and
               Peng Cui and
               Wenwu Zhu},
  title     = {Deep Learning on Graphs: {A} Survey},
  journal   = {CoRR},
  volume    = {abs/1812.04202},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.04202},
  archivePrefix = {arXiv},
  eprint    = {1812.04202},
  timestamp = {Tue, 01 Jan 2019 15:01:25 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1812-04202},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{wu2019comprehensive,
  title={A comprehensive survey on graph neural networks},
  author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S},
  journal={arXiv preprint arXiv:1901.00596},
  year={2019}
}

@inproceedings{babai2016graph,
  title={Graph isomorphism in quasipolynomial time},
  author={Babai, L{\'a}szl{\'o}},
  booktitle={Proceedings of the forty-eighth annual ACM symposium on Theory of Computing},
  pages={684--697},
  year={2016},
  organization={ACM}
}

@article{vishwanathan2010graph,
  title={Graph kernels},
  author={Vishwanathan, S Vichy N and Schraudolph, Nicol N and Kondor, Risi and Borgwardt, Karsten M},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Apr},
  pages={1201--1242},
  year={2010}
}

@inproceedings{
xu2018how,
title={How Powerful are Graph Neural Networks?},
author={Keyulu Xu and Weihua Hu and Jure Leskovec and Stefanie Jegelka},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=ryGs6iA5Km},
}


@article{morris2018weisfeiler,
  title={Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks},
  author={Morris, Christopher and Ritzert, Martin and Fey, Matthias and Hamilton, William L and Lenssen, Jan Eric and Rattan, Gaurav and Grohe, Martin},
  journal={arXiv preprint arXiv:1810.02244},
  year={2018}
}

@inproceedings{morris2017glocalized,
  title={Glocalized Weisfeiler-Lehman graph kernels: Global-local feature maps of graphs},
  author={Morris, Christopher and Kersting, Kristian and Mutzel, Petra},
  booktitle={2017 IEEE International Conference on Data Mining (ICDM)},
  pages={327--336},
  year={2017},
  organization={IEEE}
}

@article{briand2004algebra,
  title={When is the algebra of multisymmetric polynomials generated by the elementary multisymmetric polynomials},
  author={Briand, Emmanuel},
  journal={Contributions to Algebra and Geometry},
  volume={45},
  number={2},
  pages={353--368},
  year={2004}
}

@article{ivanov2018anonymous,
	title={Anonymous Walk Embeddings},
	author={Ivanov, Sergey and Burnaev, Evgeny},
	journal={arXiv preprint arXiv:1805.11921},
	year={2018}
}
@inproceedings{verma2017hunt,
	title={Hunt For The Unique, Stable, Sparse And Fast Feature Learning On Graphs},
	author={Verma, Saurabh and Zhang, Zhi-Li},
	booktitle={Advances in Neural Information Processing Systems},
	pages={88--98},
	year={2017}
}



@article{hornik1991approximation,
  title={Approximation capabilities of multilayer feedforward networks},
  author={Hornik, Kurt},
  journal={Neural networks},
  volume={4},
  number={2},
  pages={251--257},
  year={1991},
  publisher={Elsevier}
}


@book{fulton2013representation,
	title={Representation theory: a first course},
	author={Fulton, William and Harris, Joe},
	volume={129},
	year={2013},
	publisher={Springer Science \& Business Media}
}
@article{qi2017pointnet,
  title={Pointnet: Deep learning on point sets for 3d classification and segmentation},
  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
  journal={Proc. Computer Vision and Pattern Recognition (CVPR), IEEE},
  volume={1},
  number={2},
  pages={4},
  year={2017}
}

@article{kipf2018neural,
  title={Neural relational inference for interacting systems},
  author={Kipf, Thomas and Fetaya, Ethan and Wang, Kuan-Chieh and Welling, Max and Zemel, Richard},
  journal={arXiv preprint arXiv:1802.04687},
  year={2018}
}

@inproceedings{schroff2015facenet,
  title={Facenet: A unified embedding for face recognition and clustering},
  author={Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={815--823},
  year={2015}
}
@inproceedings{cohen2016group,
	title={Group equivariant convolutional networks},
	author={Cohen, Taco and Welling, Max},
	booktitle={International conference on machine learning},
	pages={2990--2999},
	year={2016}
}



@inproceedings{Simonovsky2017,
	abstract = {A number of problems can be formulated as prediction on graph-structured data. In this work, we generalize the convolution operator from regular grids to arbitrary graphs while avoiding the spectral domain, which allows us to handle graphs of varying size and connectivity. To move beyond a simple diffusion, filter weights are conditioned on the specific edge labels in the neighborhood of a vertex. Together with the proper choice of graph coarsening, we explore constructing deep neural networks for graph classification. In particular, we demonstrate the generality of our formulation in point cloud classification, where we set the new state of the art, and on a graph classification dataset, where we outperform other deep learning approaches. The source code is available at https://github.com/mys007/ecc},
	archivePrefix = {arXiv},
	arxivId = {1704.02901},
	author = {Simonovsky, Martin and Komodakis, Nikos},
	booktitle = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
	doi = {10.1109/CVPR.2017.11},
	eprint = {1704.02901},
	file = {::},
	isbn = {9781538604571},
	issn = {1063-6919},
	mendeley-groups = {equivariant},
	title = {{Dynamic edge-conditioned filters in convolutional neural networks on graphs}},
	year = {2017}
}
@techreport{Orbanz,
	abstract = {The natural habitat of most Bayesian methods is data represented by exchangeable sequences of observations, for which de Finetti's theorem provides the theoretical foundation. Dirichlet process clustering, Gaussian process regression, and many other parametric and nonparametric Bayesian models fall within the remit of this framework; many problems arising in modern data analysis do not. This article provides an introduction to Bayesian models of graphs, matrices, and other data that can be modeled by random structures. We describe results in probability theory that generalize de Finetti's theorem to such data and discuss their relevance to nonparametric Bayesian modeling. With the basic ideas in place, we survey example models available in the literature; applications of such models include collaborative filtering, link prediction, and graph and network analysis. We also highlight connections to recent developments in graph theory and probability, and sketch the more general mathematical foundation of Bayesian methods for other types of data beyond sequences and arrays.},
	archivePrefix = {arXiv},
	arxivId = {arXiv:1312.7857v2},
	author = {Orbanz, Peter and Roy, Daniel M},
	eprint = {arXiv:1312.7857v2},
	file = {::},
	mendeley-groups = {equivariant},
	title = {{Bayesian Models of Graphs, Arrays and Other Exchangeable Random Structures}}
}
@inproceedings{Hartford2018,
	title={Deep Models of Interactions Across Sets},
	author={Jason S. Hartford and Devon R. Graham and Kevin Leyton-Brown and Siamak Ravanbakhsh},
	booktitle={ICML},
	year={2018}
}
@article{Ravanbakhsh2017,
	title={Equivariance through parameter-sharing},
	author={Ravanbakhsh, Siamak and Schneider, Jeff and Poczos, Barnabas},
	journal={arXiv preprint arXiv:1702.08389},
	year={2017}
}
@article{Lei2017,
	abstract = {The design of neural architectures for structured objects is typically guided by experimental insights rather than a formal process. In this work, we appeal to kernels over combinatorial structures, such as sequences and graphs, to derive appropriate neural operations. We introduce a class of deep recurrent neural operations and formally characterize their associated kernel spaces. Our recurrent modules compare the input to virtual reference objects (cf. filters in CNN) via the kernels. Similar to traditional neural operations, these reference objects are parameterized and directly optimized in end-to-end training. We empirically evaluate the proposed class of neural architectures on standard applications such as language modeling and molecular graph regression, achieving state-of-the-art results across these applications.},
	archivePrefix = {arXiv},
	arxivId = {1705.09037},
	author = {Lei, Tao and Jin, Wengong and Barzilay, Regina and Jaakkola, Tommi},
	eprint = {1705.09037},
	file = {::},
	isbn = {9781510855144},
	mendeley-groups = {equivariant},
	title = {{Deriving Neural Architectures from Sequence and Graph Kernels}},
	year = {2017}
}

@article{graham2019deep,
  title={Deep Models for Relational Databases},
  author={Graham, Devon and Ravanbakhsh, Siamak},
  journal={arXiv preprint arXiv:1903.09033},
  year={2019}
}
@inproceedings{Zhang,
	title={An end-to-end deep learning architecture for graph classification},
	author={Zhang, Muhan and Cui, Zhicheng and Neumann, Marion and Chen, Yixin},
	booktitle={Proceedings of AAAI Conference on Artificial Inteligence},
	year={2018}
}
@article{kipf,
	title={Semi-supervised classification with graph convolutional networks},
	author={Kipf, Thomas N and Welling, Max},
	journal={arXiv preprint arXiv:1609.02907},
	year={2016}
}
@inproceedings{Atwood2015,
	title={Diffusion-convolutional neural networks},
	author={Atwood, James and Towsley, Don},
	booktitle={Advances in Neural Information Processing Systems},
	pages={1993--2001},
	year={2016}
}
@article{Niepert2016,
	abstract = {Numerous important problems can be framed as learning from graph data. We propose a framework for learning convolutional neural networks for arbitrary graphs. These graphs may be undirected, directed, and with both discrete and continuous node and edge attributes. Analogous to image-based convolutional networks that operate on locally connected regions of the input, we present a general approach to extracting locally connected regions from graphs. Using established benchmark data sets, we demonstrate that the learned feature representations are competitive with state of the art graph kernels and that their computation is highly efficient.},
	archivePrefix = {arXiv},
	arxivId = {1605.05273},
	author = {Niepert, Mathias and Ahmed, Mohamed and Kutzkov, Konstantin},
	eprint = {1605.05273},
	file = {::},
	isbn = {9781510829008},
	issn = {1938-7228},
	mendeley-groups = {equivariant},
	title = {{Learning Convolutional Neural Networks for Graphs}},
	year = {2016}
}
@techreport{Axler,
	author = {Axler, S and Gehring, E W and Ribet, K A},
	file = {::},
	mendeley-groups = {equivariant},
	title = {{Graduate Texts in Mathematics 129 Readings in Mathematics Editorial Board}}
}
@inproceedings{Yanardag2015,
	abstract = {In this paper, we present Deep Graph Kernels, a unified frame-work to learn latent representations of sub-structures for graphs, inspired by latest advancements in language modeling and deep learning. Our framework leverages the dependency information be-tween sub-structures by learning their latent representations. We demonstrate instances of our framework on three popular graph kernels, namely Graphlet kernels, Weisfeiler-Lehman subtree ker-nels, and Shortest-Path graph kernels. Our experiments on several benchmark datasets show that Deep Graph Kernels achieve signif-icant improvements in classification accuracy over state-of-the-art graph kernels.},
	author = {Yanardag, Pinar and Vishwanathan, S.V.N.},
	booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '15},
	doi = {10.1145/2783258.2783417},
	file = {:Users/haggaim/Library/Application Support/Mendeley Desktop/Downloaded/Yanardag, Vishwanathan - 2015 - Deep Graph Kernels.pdf:pdf},
	isbn = {9781450336642},
	issn = {9781450336642},
	mendeley-groups = {equivariant},
	title = {{Deep Graph Kernels}},
	year = {2015}
}
@inproceedings{Agarwal2006,
	abstract = {citation 66},
	author = {Agarwal, Sameer and Branson, Kristin and Belongie, Serge},
	booktitle = {Proceedings of the 23rd international conference on Machine learning  - ICML '06},
	doi = {10.1145/1143844.1143847},
	file = {:Users/haggaim/Library/Application Support/Mendeley Desktop/Downloaded/Agarwal, Branson, Belongie - 2006 - Higher order learning with graphs.pdf:pdf},
	isbn = {1595933832},
	issn = {1595933832},
	mendeley-groups = {equivariant},
	title = {{Higher order learning with graphs}},
	year = {2006}
}

@article{Kondor2018,
	title={Covariant compositional networks for learning graphs},
	author={Kondor, Risi and Son, Hy Truong and Pan, Horace and Anderson, Brandon and Trivedi, Shubhendu},
	journal={arXiv preprint arXiv:1801.02144},
	year={2018}
}
@article{Kondor2018a,
	title={On the generalization of equivariance and convolution in neural networks to the action of compact groups},
	author={Kondor, Risi and Trivedi, Shubhendu},
	journal={arXiv preprint arXiv:1802.03690},
	year={2018}
}
@techreport{,
	file = {:Users/haggaim/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - Pure and Appllad MathamatlcH.pdf:pdf},
	mendeley-groups = {equivariant},
	title = {{Pure and Appllad MathamatlcH}}
}
@article{Yarotsky2018,
	abstract = {We describe generalizations of the universal approximation theorem for neural networks to maps invariant or equivariant with respect to linear representations of groups. Our goal is to establish network-like computational models that are both invariant/equivariant and provably complete in the sense of their ability to approximate any continuous invariant/equivariant map. Our contribution is three-fold. First, in the general case of compact groups we propose a construction of a complete invariant/equivariant network using an intermediate polynomial layer. We invoke classical theorems of Hilbert and Weyl to justify and simplify this construction; in particular, we describe an explicit complete ansatz for approximation of permutation-invariant maps. Second, we consider groups of translations and prove several versions of the universal approximation theorem for convolutional networks in the limit of continuous signals on euclidean spaces. Finally, we consider 2D signal transformations equivariant with respect to the group SE(2) of rigid euclidean motions. In this case we introduce the "charge--conserving convnet" -- a convnet-like computational model based on the decomposition of the feature space into isotypic representations of SO(2). We prove this model to be a universal approximator for continuous SE(2)--equivariant signal transformations.},
	archivePrefix = {arXiv},
	arxivId = {1804.10306},
	author = {Yarotsky, Dmitry},
	eprint = {1804.10306},
	file = {:Users/haggaim/Library/Application Support/Mendeley Desktop/Downloaded/Yarotsky - 2018 - Universal approximations of invariant maps by neural networks.pdf:pdf},
	mendeley-groups = {equivariant},
	title = {{Universal approximations of invariant maps by neural networks}},
	year = {2018}
}
@inproceedings{Qi2017,
	abstract = {Point cloud is an important type of geometric data structure. Due to its irregular format, most researchers transform such data to regular 3D voxel grids or collections of images. This, however, renders data unnecessarily voluminous and causes issues. In this paper, we design a novel type of neural network that directly consumes point clouds and well respects the permutation invariance of points in the input. Our network, named PointNet, provides a unified architecture for applications ranging from object classification, part segmentation, to scene semantic parsing. Though simple, PointNet is highly efficient and effective. Empirically, it shows strong performance on par or even better than state of the art. Theoretically, we provide analysis towards understanding of what the network has learnt and why the network is robust with respect to input perturbation and corruption.},
	archivePrefix = {arXiv},
	arxivId = {1612.00593},
	author = {Qi, Charles R. and Su, Hao and Mo, Kaichun and Guibas, Leonidas J.},
	booktitle = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
	doi = {10.1109/CVPR.2017.16},
	eprint = {1612.00593},
	file = {:Users/haggaim/Library/Application Support/Mendeley Desktop/Downloaded/Qi et al. - 2017 - PointNet Deep learning on point sets for 3D classification and segmentation.pdf:pdf},
	isbn = {9781538604571},
	issn = {1063-6919},
	mendeley-groups = {equivariant},
	title = {{PointNet: Deep learning on point sets for 3D classification and segmentation}},
	year = {2017}
}


@article{Monti2018,
	abstract = {In recent years, there has been a surge of interest in developing deep learning methods for non-Euclidean structured data such as graphs. In this paper, we propose Dual-Primal Graph CNN, a graph convolutional architecture that alternates convolution-like operations on the graph and its dual. Our approach allows to learn both vertex- and edge features and generalizes the previous graph attention (GAT) model. We provide extensive experimental validation showing state-of-the-art results on a variety of tasks tested on established graph benchmarks, including CORA and Citeseer citation networks as well as MovieLens, Flixter, Douban and Yahoo Music graph-guided recommender systems.},
	archivePrefix = {arXiv},
	arxivId = {1806.00770},
	author = {Monti, Federico and Shchur, Oleksandr and Bojchevski, Aleksandar and Litany, Or and G{\"{u}}nnemann, Stephan and Bronstein, Michael M.},
	eprint = {1806.00770},
	file = {:Users/haggaim/Dropbox/PhD/learning{\_}on{\_}graphs{\_}via{\_}pairwise{\_}permutation{\_}invariant{\_}layers/refs/Dual-Primal Graph Convolutional Networks.pdf:pdf},
	mendeley-groups = {equivariant},
	pages = {1--11},
	title = {{Dual-Primal Graph Convolutional Networks}},
	url = {http://arxiv.org/abs/1806.00770},
	year = {2018}
}
@article{Velickovic2017,
	abstract = {We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training).},
	archivePrefix = {arXiv},
	arxivId = {1710.10903},
	author = {Veli{\v{c}}kovi{\'{c}}, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Li{\`{o}}, Pietro and Bengio, Yoshua},
	eprint = {1710.10903},
	file = {:Users/haggaim/Dropbox/PhD/learning{\_}on{\_}graphs{\_}via{\_}pairwise{\_}permutation{\_}invariant{\_}layers/refs/GRAPH ATTENTION NETWORKS.pdf:pdf},
	mendeley-groups = {equivariant},
	pages = {1--12},
	title = {{Graph Attention Networks}},
	url = {http://arxiv.org/abs/1710.10903},
	year = {2017}
}
@inproceedings{Hamilton2017,
	title={Inductive representation learning on large graphs},
	author={Hamilton, Will and Ying, Zhitao and Leskovec, Jure},
	booktitle={Advances in Neural Information Processing Systems},
	pages={1024--1034},
	year={2017}
}


@inproceedings{Defferrard2016,
	title={Convolutional neural networks on graphs with fast localized spectral filtering},
	author={Defferrard, Micha{\"e}l and Bresson, Xavier and Vandergheynst, Pierre},
	booktitle={Advances in Neural Information Processing Systems},
	pages={3844--3852},
	year={2016}
}
@article{Levie2017,
	abstract = {The rise of graph-structured data such as social networks, regulatory networks, citation graphs, and functional brain networks, in combination with resounding success of deep learning in various applications, has brought the interest in generalizing deep learning models to non-Euclidean domains. In this paper, we introduce a new spectral domain convolutional architecture for deep learning on graphs. The core ingredient of our model is a new class of parametric rational complex functions (Cayley polynomials) allowing to efficiently compute localized regular filters on graphs that specialize on frequency bands of interest. Our model scales linearly with the size of the input data for sparsely-connected graphs, can handle different constructions of Laplacian operators, and typically requires less parameters than previous models. Extensive experimental results show the superior performance of our approach on various graph learning problems.},
	archivePrefix = {arXiv},
	arxivId = {1705.07664},
	author = {Levie, Ron and Monti, Federico and Bresson, Xavier and Bronstein, Michael M.},
	doi = {10.1109/CVPR.2017.576},
	eprint = {1705.07664},
	file = {:Users/haggaim/Dropbox/PhD/learning{\_}on{\_}graphs{\_}via{\_}pairwise{\_}permutation{\_}invariant{\_}layers/refs/Cayleynets- Graph convolutional neural networks with complex rational spectral filters.pdf:pdf},
	isbn = {978-1-5386-0457-1},
	issn = {1063-6919},
	mendeley-groups = {garph NN},
	pages = {1--12},
	title = {{CayleyNets: Graph Convolutional Neural Networks with Complex Rational Spectral Filters}},
	url = {http://arxiv.org/abs/1705.07664},
	year = {2017}
}
@article{Battaglia2016,
	abstract = {Reasoning about objects, relations, and physics is central to human intelligence, and a key goal of artificial intelligence. Here we introduce the interaction network, a model which can reason about how objects in complex systems interact, supporting dynamical predictions, as well as inferences about the abstract properties of the system. Our model takes graphs as input, performs object- and relation-centric reasoning in a way that is analogous to a simulation, and is implemented using deep neural networks. We evaluate its ability to reason about several challenging physical domains: n-body problems, rigid-body collision, and non-rigid dynamics. Our results show it can be trained to accurately simulate the physical trajectories of dozens of objects over thousands of time steps, estimate abstract quantities such as energy, and generalize automatically to systems with different numbers and configurations of objects and relations. Our interaction network implementation is the first general-purpose, learnable physics engine, and a powerful general framework for reasoning about object and relations in a wide variety of complex real-world domains.},
	archivePrefix = {arXiv},
	arxivId = {1612.00222},
	author = {Battaglia, Peter W. and Pascanu, Razvan and Lai, Matthew and Rezende, Danilo and Kavukcuoglu, Koray},
	eprint = {1612.00222},
	file = {:Users/haggaim/Dropbox/PhD/learning{\_}on{\_}graphs{\_}via{\_}pairwise{\_}permutation{\_}invariant{\_}layers/refs/Interaction networks for learning about objects, relations and physics..pdf:pdf},
	issn = {10495258},
	mendeley-groups = {garph NN},
	title = {{Interaction Networks for Learning about Objects, Relations and Physics}},
	url = {http://arxiv.org/abs/1612.00222},
	year = {2016}
}
@inproceedings{Duvenaud2015,
	title={Convolutional networks on graphs for learning molecular fingerprints},
	author={Duvenaud, David K and Maclaurin, Dougal and Iparraguirre, Jorge and Bombarell, Rafael and Hirzel, Timothy and Aspuru-Guzik, Al{\'a}n and Adams, Ryan P},
	booktitle={Advances in neural information processing systems},
	pages={2224--2232},
	year={2015}
}
@article{Gori2005,
	abstract = {In several applications the information is naturally represented by graphs. Traditional approaches cope with graphi-cal data structures using a preprocessing phase which transforms the graphs into a set of flat vectors. However, in this way, important topological information may be lost and the achieved results may heavily depend on the preprocessing stage. This paper presents a new neural model, called graph neural network (GNN), capable of directly processing graphs. GNNs extends recursive neural networks and can be applied on most of the practically useful kinds of graphs, including directed, undirected, labelled and cyclic graphs. A learning algorithm for GNNs is proposed and some experiments are discussed which assess the properties of the model.},
	author = {Gori, Marco and Monfardini, Gabriele and Scarselli, Franco},
	doi = {10.1109/IJCNN.2005.1555942},
	file = {:Users/haggaim/Dropbox/PhD/learning{\_}on{\_}graphs{\_}via{\_}pairwise{\_}permutation{\_}invariant{\_}layers/refs/A{\_}new{\_}Model{\_}for{\_}Learning{\_}in{\_}Graph{\_}Domains.pdf:pdf},
	isbn = {0780390482},
	journal = {Proceedings of the International Joint Conference on Neural Networks},
	mendeley-groups = {garph NN},
	number = {January},
	pages = {729--734},
	title = {{A new model for earning in raph domains}},
	volume = {2},
	year = {2005}
}
@inproceedings{Gilmer2017,
	title={Neural Message Passing for Quantum Chemistry},
	author={Gilmer, Justin and Schoenholz, Samuel S and Riley, Patrick F and Vinyals, Oriol and Dahl, George E},
	booktitle={International Conference on Machine Learning},
	pages={1263--1272},
	year={2017}
}
@article{Bruna2013,
	abstract = {Convolutional Neural Networks are extremely efficient architectures in image and audio recognition tasks, thanks to their ability to exploit the local translational invariance of signal classes over their domain. In this paper we consider possible generalizations of CNNs to signals defined on more general domains without the action of a translation group. In particular, we propose two constructions, one based upon a hierarchical clustering of the domain, and another based on the spectrum of the graph Laplacian. We show through experiments that for low-dimensional graphs it is possible to learn convolutional layers with a number of parameters independent of the input size, resulting in efficient deep architectures.},
	archivePrefix = {arXiv},
	arxivId = {1312.6203},
	author = {Bruna, Joan and Zaremba, Wojciech and Szlam, Arthur and LeCun, Yann},
	eprint = {1312.6203},
	mendeley-groups = {garph NN},
	pages = {1--14},
	title = {{Spectral Networks and Locally Connected Networks on Graphs}},
	url = {http://arxiv.org/abs/1312.6203},
	year = {2013}
}
@article{Henaff2015,
	abstract = {Deep Learning's recent successes have mostly relied on Convolutional Networks, which exploit fundamental statistical properties of images, sounds and video data: the local stationarity and multi-scale compositional structure, that allows expressing long range interactions in terms of shorter, localized interactions. However, there exist other important examples, such as text documents or bioinformatic data, that may lack some or all of these strong statistical regularities. In this paper we consider the general question of how to construct deep architectures with small learning complexity on general non-Euclidean domains, which are typically unknown and need to be estimated from the data. In particular, we develop an extension of Spectral Networks which incorporates a Graph Estimation procedure, that we test on large-scale classification problems, matching or improving over Dropout Networks with far less parameters to estimate.},
	archivePrefix = {arXiv},
	arxivId = {1506.05163},
	author = {Henaff, Mikael and Bruna, Joan and LeCun, Yann},
	eprint = {1506.05163},
	file = {:Users/haggaim/Dropbox/PhD/learning{\_}on{\_}graphs{\_}via{\_}pairwise{\_}permutation{\_}invariant{\_}layers/refs/Deep{\_}Convolutional{\_}Networks{\_}on{\_}Graph-Structured{\_}Da.pdf:pdf},
	issn = {1506.05163},
	mendeley-groups = {garph NN},
	number = {June},
	title = {{Deep Convolutional Networks on Graph-Structured Data}},
	url = {http://arxiv.org/abs/1506.05163},
	year = {2015}
}
@article{Li2015,
	abstract = {Graph-structured data appears frequently in domains including chemistry, natural language semantics, social networks, and knowledge bases. In this work, we study feature learning techniques for graph-structured inputs. Our starting point is previous work on Graph Neural Networks (Scarselli et al., 2009), which we modify to use gated recurrent units and modern optimization techniques and then extend to output sequences. The result is a flexible and broadly useful class of neural network models that has favorable inductive biases relative to purely sequence-based models (e.g., LSTMs) when the problem is graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and graph algorithm learning tasks. We then show it achieves state-of-the-art performance on a problem from program verification, in which subgraphs need to be matched to abstract data structures.},
	archivePrefix = {arXiv},
	arxivId = {1511.05493},
	author = {Li, Yujia and Tarlow, Daniel and Brockschmidt, Marc and Zemel, Richard},
	doi = {10.1103/PhysRevLett.116.082003},
	eprint = {1511.05493},
	file = {:Users/haggaim/Dropbox/PhD/learning{\_}on{\_}graphs{\_}via{\_}pairwise{\_}permutation{\_}invariant{\_}layers/refs/GATED GRAPH SEQUENCE NEURAL NETWORKS.pdf:pdf},
	issn = {10797114},
	mendeley-groups = {garph NN},
	number = {1},
	pages = {1--20},
	title = {{Gated Graph Sequence Neural Networks}},
	url = {http://arxiv.org/abs/1511.05493},
	year = {2015}
}
@article{Scarselli2009,
	author = {Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
	doi = {10.1109/TNN.2008.2005605},
	file = {:Users/haggaim/Dropbox/PhD/learning{\_}on{\_}graphs{\_}via{\_}pairwise{\_}permutation{\_}invariant{\_}layers/refs/The graph neural network model.pdf:pdf},
	isbn = {1045-9227},
	issn = {1045-9227},
	journal = {Neural Networks, IEEE Transactions on},
	mendeley-groups = {garph NN},
	number = {1},
	pages = {61--80},
	title = {{The graph neural network model}},
	volume = {20},
	year = {2009}
}



@article{Ying2018,
	abstract = {Recently, graph neural networks (GNNs) have revolutionized the field of graph representation learning through effectively learned node embeddings, and achieved state-of-the-art results in tasks such as node classification and link prediction. However, current GNN methods are inherently flat and do not learn hierarchical representations of graphs---a limitation that is especially problematic for the task of graph classification, where the goal is to predict the label associated with an entire graph. Here we propose DiffPool, a differentiable graph pooling module that can generate hierarchical representations of graphs and can be combined with various graph neural network architectures in an end-to-end fashion. DiffPool learns a differentiable soft cluster assignment for nodes at each layer of a deep GNN, mapping nodes to a set of clusters, which then form the coarsened input for the next GNN layer. Our experimental results show that combining existing GNN methods with DiffPool yields an average improvement of 5-10{\%} accuracy on graph classification benchmarks, compared to all existing pooling approaches, achieving a new state-of-the-art on four out of five benchmark data sets.},
	archivePrefix = {arXiv},
	arxivId = {1806.08804},
	author = {Ying, Rex and You, Jiaxuan and Morris, Christopher and Ren, Xiang and , William L. and Leskovec, Jure},
	doi = {10.1145/nnnnnnn.nnnnnnn},
	eprint = {1806.08804},
	file = {:Users/haggaim/Dropbox/PhD/learning{\_}on{\_}graphs{\_}via{\_}pairwise{\_}permutation{\_}invariant{\_}layers/refs/Hierarchical Graph Representation Learning with Differentiable Pooling.pdf:pdf},
	mendeley-groups = {garph NN},
	title = {{Hierarchical Graph Representation Learning with Differentiable Pooling}},
	url = {http://arxiv.org/abs/1806.08804},
	year = {2018}
}
@inproceedings{monti2017geometric,
	title={Geometric deep learning on graphs and manifolds using mixture model CNNs},
	author={Monti, Federico and Boscaini, Davide and Masci, Jonathan and Rodola, Emanuele and Svoboda, Jan and Bronstein, Michael M},
	booktitle={Proc. CVPR},
	volume={1},
	number={2},
	pages={3},
	year={2017}
}

@inproceedings{krizhevsky2012imagenet,
	title={Imagenet classification with deep convolutional neural networks},
	author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	booktitle={Advances in neural information processing systems},
	pages={1097--1105},
	year={2012}
}

@article{Welling2018,
	title={Spherical CNNs},
	author={Cohen, Taco S and Geiger, Mario and K{\"o}hler, Jonas and Welling, Max},
	journal={arXiv preprint arXiv:1801.10130},
	year={2018}
}
@article{Weiler2018,
	abstract = {We present a convolutional network that is equivariant to rigid body motions. The model uses scalar-, vector-, and tensor fields over 3D Euclidean space to represent data, and equivariant convolutions to map between such representations. These SE(3)-equivariant convolutions utilize kernels which are parameterized as a linear combination of a complete steerable kernel basis, which is derived in this paper. We prove that equivariant convolutions are the most general equivariant linear maps between fields over R{\^{}}3. Our experimental results confirm the effectiveness of 3D Steerable CNNs for the problem of amino acid propensity prediction and protein structure classification, both of which have inherent SE(3) symmetry.},
	archivePrefix = {arXiv},
	arxivId = {1807.02547},
	author = {Weiler, Maurice and Geiger, Mario and Welling, Max and Boomsma, Wouter and Cohen, Taco},
	eprint = {1807.02547},
	file = {:Users/haggaim/Dropbox/PhD/learning{\_}on{\_}graphs{\_}via{\_}pairwise{\_}permutation{\_}invariant{\_}layers/refs/3D Steerable CNNs- Learning Rotationally Equivariant Features in Volumetric Data.pdf:pdf},
	mendeley-groups = {equivariant NN},
	title = {{3D Steerable CNNs: Learning Rotationally Equivariant Features in Volumetric Data}},
	url = {http://arxiv.org/abs/1807.02547},
	year = {2018}
}
@article{Cohen2016,
	abstract = {It has long been recognized that the invariance and equivariance properties of a representation are critically important for success in many vision tasks. In this paper we present Steerable Convolutional Neural Networks, an efficient and flexible class of equivariant convolutional networks. We show that steerable CNNs achieve state of the art results on the CIFAR image classification benchmark. The mathematical theory of steerable representations reveals a type system in which any steerable representation is a composition of elementary feature types, each one associated with a particular kind of symmetry. We show how the parameter cost of a steerable filter bank depends on the types of the input and output features, and show how to use this knowledge to construct CNNs that utilize parameters effectively.},
	archivePrefix = {arXiv},
	arxivId = {1612.08498},
	author = {Cohen, Taco S. and Welling, Max},
	eprint = {1612.08498},
	file = {:Users/haggaim/Dropbox/PhD/learning{\_}on{\_}graphs{\_}via{\_}pairwise{\_}permutation{\_}invariant{\_}layers/refs/STEERABLE CNNS.pdf:pdf},
	mendeley-groups = {equivariant NN},
	number = {1990},
	pages = {1--14},
	title = {{Steerable CNNs}},
	url = {http://arxiv.org/abs/1612.08498},
	year = {2016}
}

@incollection{tsuda2010graph,
	title={Graph classification},
	author={Tsuda, Koji and Saigo, Hiroto},
	booktitle={Managing and mining graph data},
	pages={337--363},
	year={2010},
	publisher={Springer}
}
@book{chung1997spectral,
	title={Spectral graph theory},
	author={Chung, Fan RK and Graham, Fan Chung},
	number={92},
	year={1997},
	publisher={American Mathematical Soc.}
}
@inproceedings{shervashidze2009efficient,
	title={Efficient graphlet kernels for large graph comparison},
	author={Shervashidze, Nino and Vishwanathan, SVN and Petri, Tobias and Mehlhorn, Kurt and Borgwardt, Karsten},
	booktitle={Artificial Intelligence and Statistics},
	pages={488--495},
	year={2009}
}


@article{neumann2016propagation,
	title={Propagation kernels: efficient graph kernels from propagated information},
	author={Neumann, Marion and Garnett, Roman and Bauckhage, Christian and Kersting, Kristian},
	journal={Machine Learning},
	volume={102},
	number={2},
	pages={209--245},
	year={2016},
	publisher={Springer}
}
@article{shervashidze2011weisfeiler,
	title={Weisfeiler-lehman graph kernels},
	author={Shervashidze, Nino and Schweitzer, Pascal and Leeuwen, Erik Jan van and Mehlhorn, Kurt and Borgwardt, Karsten M},
	journal={Journal of Machine Learning Research},
	volume={12},
	number={Sep},
	pages={2539--2561},
	year={2011}
}


@inproceedings{tensorflow,
	title={Tensorflow: a system for large-scale machine learning.},
	author={Abadi, Mart{\'\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others},
	booktitle={OSDI},
	volume={16},
	pages={265--283},
	year={2016}
}
@article{lecun1989backpropagation,
	title={Backpropagation applied to handwritten zip code recognition},
	author={LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},
	journal={Neural computation},
	volume={1},
	number={4},
	pages={541--551},
	year={1989},
	publisher={MIT Press}
}

@book{grohe2017descriptive,
  title={Descriptive complexity, canonisation, and definable graph structure theory},
  author={Grohe, Martin},
  volume={47},
  year={2017},
  publisher={Cambridge University Press}
}

@article{cai1992optimal,
  title={An optimal lower bound on the number of variables for graph identification},
  author={Cai, Jin-Yi and F{\"u}rer, Martin and Immerman, Neil},
  journal={Combinatorica},
  volume={12},
  number={4},
  pages={389--410},
  year={1992},
  publisher={Springer}
}



@article{douglas2011weisfeiler,
  title={The Weisfeiler-Lehman method and graph isomorphism testing},
  author={Douglas, Brendan L},
  journal={arXiv preprint arXiv:1101.5211},
  year={2011}
}

@article{grohe2015pebble,
  title={Pebble games and linear equations},
  author={Grohe, Martin and Otto, Martin},
  journal={The Journal of Symbolic Logic},
  volume={80},
  number={3},
  pages={797--844},
  year={2015},
  publisher={Cambridge University Press}
}

@inproceedings{abadi2016tensorflow,
  title={Tensorflow: A system for large-scale machine learning},
  author={Abadi, Mart{\'\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others},
  booktitle={12th $\{$USENIX$\}$ Symposium on Operating Systems Design and Implementation ($\{$OSDI$\}$ 16)},
  pages={265--283},
  year={2016}
}

@article{cohen2019gauge,
  title={Gauge equivariant convolutional networks and the icosahedral cnn},
  author={Cohen, Taco S and Weiler, Maurice and Kicanaoglu, Berkay and Welling, Max},
  journal={arXiv preprint arXiv:1902.04615},
  year={2019}
}

@inproceedings{cohen2019general,
  title={A general theory of equivariant cnns on homogeneous spaces},
  author={Cohen, Taco S and Geiger, Mario and Weiler, Maurice},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9142--9153},
  year={2019}
}

@article{winkels20183d,
  title={3d g-cnns for pulmonary nodule detection},
  author={Winkels, Marysia and Cohen, Taco S},
  journal={arXiv preprint arXiv:1804.04656},
  year={2018}
}

@inproceedings{worrall2018cubenet,
  title={Cubenet: Equivariance to 3d rotation and translation},
  author={Worrall, Daniel and Brostow, Gabriel},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={567--584},
  year={2018}
}

@inproceedings{worrall2017harmonic,
  title={Harmonic networks: Deep translation and rotation equivariance},
  author={Worrall, Daniel E and Garbin, Stephan J and Turmukhambetov, Daniyar and Brostow, Gabriel J},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={5028--5037},
  year={2017}
}
@inproceedings{weiler2018learning,
  title={Learning steerable filters for rotation equivariant CNNs},
  author={Weiler, Maurice and Hamprecht, Fred A and Storath, Martin},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={849--858},
  year={2018}
}

@article{thomas2018tensor,
  title={Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds},
  author={Thomas, Nathaniel and Smidt, Tess and Kearnes, Steven and Yang, Lusann and Li, Li and Kohlhoff, Kai and Riley, Patrick},
  journal={arXiv preprint arXiv:1802.08219},
  year={2018}
}

@article{kondor2018n,
  title={N-body networks: a covariant hierarchical neural network architecture for learning atomic potentials},
  author={Kondor, Risi},
  journal={arXiv preprint arXiv:1803.01588},
  year={2018}
}

@article{dieleman2016exploiting,
  title={Exploiting cyclic symmetry in convolutional neural networks},
  author={Dieleman, Sander and De Fauw, Jeffrey and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1602.02660},
  year={2016}
}

@article{esteves20173d,
  title={3D object classification and retrieval with Spherical CNNs},
  author={Esteves, Carlos and Allen-Blanchette, Christine and Makadia, Ameesh and Daniilidis, Kostas},
  journal={arXiv preprint arXiv:1711.06721},
  year={2017}
}

@article{wood1996representation,
  title={Representation theory and invariant neural networks},
  author={Wood, Jeffrey and Shawe-Taylor, John},
  journal={Discrete applied mathematics},
  volume={69},
  number={1-2},
  pages={33--60},
  year={1996},
  publisher={Elsevier}
}

@misc{maehara2019simple,
    title={A Simple Proof of the Universality of Invariant/Equivariant Graph Neural Networks},
    author={Takanori Maehara and Hoang NT},
    year={2019},
    eprint={1910.03802},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{sutskever2014sequence,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, I and Vinyals, O and Le, QV},
  journal={Advances in NIPS},
  year={2014}
}

@article{paszke2017automatic,
  title={Automatic differentiation in pytorch},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  year={2017}
}

@article{zhou2017places,
  title={Places: A 10 million Image Database for Scene Recognition},
  author={Zhou, Bolei and Lapedriza, Agata and Khosla, Aditya and Oliva, Aude and Torralba, Antonio},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2017},
  publisher={IEEE}
}
@article{soomro2012ucf101,
  title={UCF101: A dataset of 101 human actions classes from videos in the wild},
  author={Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
  journal={arXiv preprint arXiv:1212.0402},
  year={2012}
}

@article{puschel2008algebraic,
  title={Algebraic signal processing theory: Foundation and 1-D time},
  author={Puschel, Markus and Moura, Jos{\'e} MF},
  journal={IEEE Transactions on Signal Processing},
  volume={56},
  number={8},
  pages={3572--3585},
  year={2008},
  publisher={IEEE}
}

@article{kraft2000classical,
  title={Classical invariant theory, a primer},
  author={Kraft, Hanspeter and Procesi, Claudio},
  journal={Lecture Notes, Version},
  year={2000}
}

@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={International Conference on Medical image computing and computer-assisted intervention},
  pages={234--241},
  year={2015},
  organization={Springer}
}


@inproceedings{bromley1994signature,
  title={Signature verification using a" siamese" time delay neural network},
  author={Bromley, Jane and Guyon, Isabelle and LeCun, Yann and S{\"a}ckinger, Eduard and Shah, Roopak},
  booktitle={Advances in neural information processing systems},
  pages={737--744},
  year={1994}
}

@inproceedings{simo2015discriminative,
  title={Discriminative learning of deep convolutional feature point descriptors},
  author={Simo-Serra, Edgar and Trulls, Eduard and Ferraz, Luis and Kokkinos, Iasonas and Fua, Pascal and Moreno-Noguer, Francesc},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={118--126},
  year={2015}
}

@inproceedings{zagoruyko2015learning,
  title={Learning to compare image patches via convolutional neural networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4353--4361},
  year={2015}
}

@inproceedings{chopra2005learning,
  title={Learning a similarity metric discriminatively, with application to face verification},
  author={Chopra, Sumit and Hadsell, Raia and LeCun, Yann and others},
  booktitle={CVPR (1)},
  pages={539--546},
  year={2005}
}

@article{bell2015learning,
  title={Learning visual similarity for product design with convolutional neural networks},
  author={Bell, Sean and Bala, Kavita},
  journal={ACM Transactions on Graphics (TOG)},
  volume={34},
  number={4},
  pages={98},
  year={2015},
  publisher={ACM}
}

@inproceedings{vo2016localizing,
  title={Localizing and orienting street views using overhead imagery},
  author={Vo, Nam N and Hays, James},
  booktitle={European conference on computer vision},
  pages={494--509},
  year={2016},
  organization={Springer}
}

@inproceedings{ahmed2015improved,
  title={An improved deep learning architecture for person re-identification},
  author={Ahmed, Ejaz and Jones, Michael and Marks, Tim K},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3908--3916},
  year={2015}
}
@article{Aad:2012tfa,
      author         = "Aad, Georges and others",
      title          = "{Observation of a new particle in the search for the
                        Standard Model Higgs boson with the ATLAS detector at the
                        LHC}",
      collaboration  = "ATLAS",
      journal        = "Phys. Lett.",
      volume         = "B716",
      year           = "2012",
      pages          = "1-29",
      doi            = "10.1016/j.physletb.2012.08.020",
      eprint         = "1207.7214",
      archivePrefix  = "arXiv",
      primaryClass   = "hep-ex",
      reportNumber   = "CERN-PH-EP-2012-218",
      SLACcitation   = "%%CITATION = ARXIV:1207.7214;%%"
}
@article{Chatrchyan:2012xdj,
      author         = "Chatrchyan, Serguei and others",
      title          = "{Observation of a new boson at a mass of 125 GeV with the
                        CMS experiment at the LHC}",
      collaboration  = "CMS",
      journal        = "Phys. Lett.",
      volume         = "B716",
      year           = "2012",
      pages          = "30-61",
      doi            = "10.1016/j.physletb.2012.08.021",
      eprint         = "1207.7235",
      archivePrefix  = "arXiv",
      primaryClass   = "hep-ex",
      reportNumber   = "CMS-HIG-12-028, CERN-PH-EP-2012-220",
      SLACcitation   = "%%CITATION = ARXIV:1207.7235;%%"
}
%H to bb
@article{Aaboud:2018zhk,
      author         = "Aaboud, Morad and others",
      title          = "{Observation of $H \rightarrow b\bar{b}$ decays and $VH$
                        production with the ATLAS detector}",
      collaboration  = "ATLAS",
      year           = "2018",
      eprint         = "1808.08238",
      archivePrefix  = "arXiv",
      primaryClass   = "hep-ex",
      reportNumber   = "CERN-EP-2018-215",
      SLACcitation   = "%%CITATION = ARXIV:1808.08238;%%"
}
@article{Aaboud:2018fhh,
      author         = "Aaboud, M. and others",
      title          = "{Search for the Decay of the Higgs Boson to Charm Quarks
                        with the ATLAS Experiment}",
      collaboration  = "ATLAS",
      journal        = "Phys. Rev. Lett.",
      volume         = "120",
      year           = "2018",
      number         = "21",
      pages          = "211802",
      doi            = "10.1103/PhysRevLett.120.211802",
      eprint         = "1802.04329",
      archivePrefix  = "arXiv",
      primaryClass   = "hep-ex",
      reportNumber   = "CERN-EP-2017-334",
      SLACcitation   = "%%CITATION = ARXIV:1802.04329;%%"
}
@article{Salam_2010,
   title={Towards jetography},
   volume={67},
   ISSN={1434-6052},
   url={http://dx.doi.org/10.1140/epjc/s10052-010-1314-6},
   DOI={10.1140/epjc/s10052-010-1314-6},
   number={3-4},
   journal={The European Physical Journal C},
   publisher={Springer Science and Business Media LLC},
   author={Salam, Gavin P.},
   year={2010},
   month={May},
   pages={637–686}
}

@misc{OGB2019,
  title = {Open Graph Benchmark},
  howpublished = {\url{https://ogb.stanford.edu/}},
     year={2019},
}



@inproceedings{raboh2020differentiable,
  title={Differentiable scene graphs},
  author={Raboh, Moshiko and Herzig, Roei and Berant, Jonathan and Chechik, Gal and Globerson, Amir},
  booktitle={The IEEE Winter Conference on Applications of Computer Vision},
  pages={1488--1497},
  year={2020}
}