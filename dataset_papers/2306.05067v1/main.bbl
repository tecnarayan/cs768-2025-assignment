\begin{thebibliography}{44}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{layernorm}
Ba, J.~L., Kiros, J.~R., and Hinton, G.~E.
\newblock Layer normalization.
\newblock \emph{arXiv preprint arXiv:1607.06450}, 2016.

\bibitem[Bahng et~al.(2022)Bahng, Jahanian, Sankaranarayanan, and
  Isola]{bahng2022visual}
Bahng, H., Jahanian, A., Sankaranarayanan, S., and Isola, P.
\newblock Visual prompting: Modifying pixel space to adapt pre-trained models.
\newblock \emph{arXiv preprint arXiv:2203.17274}, 2022.

\bibitem[Bao et~al.(2021)Bao, Dong, and Wei]{bao2021beit}
Bao, H., Dong, L., and Wei, F.
\newblock Beit: Bert pre-training of image transformers.
\newblock \emph{arXiv preprint arXiv:2106.08254}, 2021.

\bibitem[Bordes et~al.(2021)Bordes, Balestriero, and Vincent]{bordes2021high}
Bordes, F., Balestriero, R., and Vincent, P.
\newblock High fidelity visualization of what your self-supervised
  representation knows about.
\newblock \emph{arXiv preprint arXiv:2112.09164}, 2021.

\bibitem[Cai et~al.(2020)Cai, Gan, Zhu, and Han]{cai2020tinytl}
Cai, H., Gan, C., Zhu, L., and Han, S.
\newblock Tinytl: Reduce memory, not parameters for efficient on-device
  learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Caron et~al.(2021)Caron, Touvron, Misra, J{\'e}gou, Mairal,
  Bojanowski, and Joulin]{caron2021emerging}
Caron, M., Touvron, H., Misra, I., J{\'e}gou, H., Mairal, J., Bojanowski, P.,
  and Joulin, A.
\newblock Emerging properties in self-supervised vision transformers.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, 2021.

\bibitem[Chen et~al.(2022)Chen, Ge, Tong, Wang, Song, Wang, and
  Luo]{chen2022adaptformer}
Chen, S., Ge, C., Tong, Z., Wang, J., Song, Y., Wang, J., and Luo, P.
\newblock Adaptformer: Adapting vision transformers for scalable visual
  recognition.
\newblock \emph{arXiv preprint arXiv:2205.13535}, 2022.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{chen2020simple}
Chen, T., Kornblith, S., Norouzi, M., and Hinton, G.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2020.

\bibitem[Chen et~al.(2021)Chen, Xie, and He]{chen2021empirical}
Chen, X., Xie, S., and He, K.
\newblock An empirical study of training self-supervised vision transformers.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, 2021.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE Conference on Computer Vision and Pattern
  Recognition}. IEEE, 2009.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly,
  et~al.]{dosovitskiy2020image}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Gebru et~al.(2017)Gebru, Krause, Wang, Chen, Deng, and
  Fei-Fei]{gebru2017fine}
Gebru, T., Krause, J., Wang, Y., Chen, D., Deng, J., and Fei-Fei, L.
\newblock Fine-grained car detection for visual census estimation.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~31, 2017.

\bibitem[Geiger et~al.(2013)Geiger, Lenz, Stiller, and
  Urtasun]{geiger2013vision}
Geiger, A., Lenz, P., Stiller, C., and Urtasun, R.
\newblock Vision meets robotics: The kitti dataset.
\newblock \emph{The International Journal of Robotics Research}, 32\penalty0
  (11), 2013.

\bibitem[Geng et~al.(2020)Geng, Wang, Wang, Qin, Liu, and Tu]{geng2020does}
Geng, X., Wang, L., Wang, X., Qin, B., Liu, T., and Tu, Z.
\newblock How does selective mechanism improve self-attention networks?
\newblock \emph{arXiv preprint arXiv:2005.00979}, 2020.

\bibitem[Grill et~al.(2020)Grill, Strub, Altch{\'e}, Tallec, Richemond,
  Buchatskaya, Doersch, Avila~Pires, Guo, Gheshlaghi~Azar,
  et~al.]{grill2020bootstrap}
Grill, J.-B., Strub, F., Altch{\'e}, F., Tallec, C., Richemond, P.,
  Buchatskaya, E., Doersch, C., Avila~Pires, B., Guo, Z., Gheshlaghi~Azar, M.,
  et~al.
\newblock Bootstrap your own latent-a new approach to self-supervised learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Hambardzumyan et~al.(2021)Hambardzumyan, Khachatrian, and
  May]{hambardzumyan2021warp}
Hambardzumyan, K., Khachatrian, H., and May, J.
\newblock Warp: Word-level adversarial reprogramming.
\newblock \emph{arXiv preprint arXiv:2101.00121}, 2021.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{resnet}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{CVPR}, 2016.

\bibitem[He et~al.(2020)He, Fan, Wu, Xie, and Girshick]{he2020momentum}
He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2020.

\bibitem[He et~al.(2022)He, Chen, Xie, Li, Doll{\'a}r, and
  Girshick]{he2022masked}
He, K., Chen, X., Xie, S., Li, Y., Doll{\'a}r, P., and Girshick, R.
\newblock Masked autoencoders are scalable vision learners.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2022.

\bibitem[Houlsby et~al.(2019)Houlsby, Giurgiu, Jastrzebski, Morrone,
  De~Laroussilhe, Gesmundo, Attariyan, and Gelly]{houlsby2019parameter}
Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., De~Laroussilhe, Q.,
  Gesmundo, A., Attariyan, M., and Gelly, S.
\newblock Parameter-efficient transfer learning for nlp.
\newblock In \emph{International Conference on Machine Learning}. PMLR, 2019.

\bibitem[Huang et~al.(2023)Huang, Liu, Li, Li, Sun, and
  Liu]{huang2023extensibleacl}
Huang, X., Liu, Z., Li, P., Li, T., Sun, M., and Liu, Y.
\newblock An extensible plug-and-play method for multi-aspect controllable text
  generation.
\newblock In \emph{Proceedings of the 61st Annual Meeting of the Association
  for Computational Linguistics}, 2023.

\bibitem[Jang et~al.(2016)Jang, Gu, and Poole]{jang2016categorical}
Jang, E., Gu, S., and Poole, B.
\newblock Categorical reparameterization with gumbel-softmax.
\newblock \emph{arXiv preprint arXiv:1611.01144}, 2016.

\bibitem[Jia et~al.(2022)Jia, Tang, Chen, Cardie, Belongie, Hariharan, and
  Lim]{jia2022visual}
Jia, M., Tang, L., Chen, B.-C., Cardie, C., Belongie, S., Hariharan, B., and
  Lim, S.-N.
\newblock Visual prompt tuning.
\newblock \emph{arXiv preprint arXiv:2203.12119}, 2022.

\bibitem[Khosla et~al.(2011)Khosla, Jayadevaprakash, Yao, and
  Li]{khosla2011novel}
Khosla, A., Jayadevaprakash, N., Yao, B., and Li, F.-F.
\newblock Novel dataset for fine-grained image categorization: Stanford dogs.
\newblock In \emph{Proc. CVPR workshop on fine-grained visual categorization
  (FGVC)}, volume~2. Citeseer, 2011.

\bibitem[Kriegeskorte(2015)]{kriegeskorte2015deep}
Kriegeskorte, N.
\newblock Deep neural networks: a new framework for modelling biological vision
  and brain information processing.
\newblock \emph{biorxiv}, 2015.

\bibitem[LeCun et~al.(2015)LeCun, Bengio, and Hinton]{lecun2015deep}
LeCun, Y., Bengio, Y., and Hinton, G.
\newblock Deep learning.
\newblock \emph{nature}, 521\penalty0 (7553), 2015.

\bibitem[Lester et~al.(2021)Lester, Al-Rfou, and Constant]{lester2021power}
Lester, B., Al-Rfou, R., and Constant, N.
\newblock The power of scale for parameter-efficient prompt tuning.
\newblock \emph{arXiv preprint arXiv:2104.08691}, 2021.

\bibitem[Li \& Liang(2021)Li and Liang]{li2021prefix}
Li, X.~L. and Liang, P.
\newblock Prefix-tuning: Optimizing continuous prompts for generation.
\newblock \emph{arXiv preprint arXiv:2101.00190}, 2021.

\bibitem[Lin et~al.(2017)Lin, Doll{\'a}r, Girshick, He, Hariharan, and
  Belongie]{lin2017feature}
Lin, T.-Y., Doll{\'a}r, P., Girshick, R., He, K., Hariharan, B., and Belongie,
  S.
\newblock Feature pyramid networks for object detection.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2017.

\bibitem[Liu et~al.(2019)Liu, Ott, Goyal, Du, Joshi, Chen, Levy, Lewis,
  Zettlemoyer, and Stoyanov]{liu2019roberta}
Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M.,
  Zettlemoyer, L., and Stoyanov, V.
\newblock Roberta: A robustly optimized bert pretraining approach.
\newblock \emph{arXiv preprint arXiv:1907.11692}, 2019.

\bibitem[Nilsback \& Zisserman(2008)Nilsback and
  Zisserman]{nilsback2008automated}
Nilsback, M.-E. and Zisserman, A.
\newblock Automated flower classification over a large number of classes.
\newblock In \emph{2008 Sixth Indian Conference on Computer Vision, Graphics \&
  Image Processing}. IEEE, 2008.

\bibitem[Qin \& Eisner(2021)Qin and Eisner]{qin2021learning}
Qin, G. and Eisner, J.
\newblock Learning how to ask: Querying lms with mixtures of soft prompts.
\newblock \emph{arXiv preprint arXiv:2104.06599}, 2021.

\bibitem[Schmidhuber(2015)]{schmidhuber2015deep}
Schmidhuber, J.
\newblock Deep learning in neural networks: An overview.
\newblock \emph{Neural networks}, 61, 2015.

\bibitem[Ulyanov et~al.(2018)Ulyanov, Vedaldi, and Lempitsky]{ulyanov2018deep}
Ulyanov, D., Vedaldi, A., and Lempitsky, V.
\newblock Deep image prior.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2018.

\bibitem[Van~Horn et~al.(2015)Van~Horn, Branson, Farrell, Haber, Barry,
  Ipeirotis, Perona, and Belongie]{van2015building}
Van~Horn, G., Branson, S., Farrell, R., Haber, S., Barry, J., Ipeirotis, P.,
  Perona, P., and Belongie, S.
\newblock Building a bird recognition app and large scale dataset with citizen
  scientists: The fine print in fine-grained dataset collection.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2015.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock \emph{Advances in Neural Information Processing Systems}, 30, 2017.

\bibitem[Wah et~al.(2011)Wah, Branson, Welinder, Perona, and
  Belongie]{wah2011caltech}
Wah, C., Branson, S., Welinder, P., Perona, P., and Belongie, S.
\newblock The caltech-ucsd birds-200-2011 dataset.
\newblock 2011.

\bibitem[Xie et~al.(2022)Xie, Zhang, Cao, Lin, Bao, Yao, Dai, and
  Hu]{xie2022simmim}
Xie, Z., Zhang, Z., Cao, Y., Lin, Y., Bao, J., Yao, Z., Dai, Q., and Hu, H.
\newblock Simmim: A simple framework for masked image modeling.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2022.

\bibitem[Zhai et~al.(2019)Zhai, Puigcerver, Kolesnikov, Ruyssen, Riquelme,
  Lucic, Djolonga, Pinto, Neumann, Dosovitskiy, et~al.]{zhai2019large}
Zhai, X., Puigcerver, J., Kolesnikov, A., Ruyssen, P., Riquelme, C., Lucic, M.,
  Djolonga, J., Pinto, A.~S., Neumann, M., Dosovitskiy, A., et~al.
\newblock A large-scale study of representation learning with the visual task
  adaptation benchmark.
\newblock \emph{arXiv preprint arXiv:1910.04867}, 2019.

\bibitem[Zhao et~al.(2020)Zhao, Wu, Lau, and Lin]{zhao2020makes}
Zhao, N., Wu, Z., Lau, R.~W., and Lin, S.
\newblock What makes instance discrimination good for transfer learning?
\newblock \emph{arXiv preprint arXiv:2006.06606}, 2020.

\bibitem[Zheng et~al.(2021)Zheng, Lu, Zhao, Zhu, Luo, Wang, Fu, Feng, Xiang,
  Torr, et~al.]{zheng2021rethinking}
Zheng, S., Lu, J., Zhao, H., Zhu, X., Luo, Z., Wang, Y., Fu, Y., Feng, J.,
  Xiang, T., Torr, P.~H., et~al.
\newblock Rethinking semantic segmentation from a sequence-to-sequence
  perspective with transformers.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2021.

\bibitem[Zhou et~al.(2017)Zhou, Zhao, Puig, Fidler, Barriuso, and
  Torralba]{zhou2017scene}
Zhou, B., Zhao, H., Puig, X., Fidler, S., Barriuso, A., and Torralba, A.
\newblock Scene parsing through ade20k dataset.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, 2017.

\bibitem[Zhou et~al.(2021)Zhou, Wei, Wang, Shen, Xie, Yuille, and
  Kong]{zhou2021ibot}
Zhou, J., Wei, C., Wang, H., Shen, W., Xie, C., Yuille, A., and Kong, T.
\newblock ibot: Image bert pre-training with online tokenizer.
\newblock \emph{arXiv preprint arXiv:2111.07832}, 2021.

\end{thebibliography}
