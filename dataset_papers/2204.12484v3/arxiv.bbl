\begin{thebibliography}{10}\itemsep=-1pt

\bibitem{agarap2018deep}
A.~F. Agarap.
\newblock Deep learning using rectified linear units (relu).
\newblock {\em arXiv preprint arXiv:1803.08375}, 2018.

\bibitem{alayrac2022flamingo}
J.-B. Alayrac, J.~Donahue, P.~Luc, A.~Miech, I.~Barr, Y.~Hasson, K.~Lenc,
  A.~Mensch, K.~Millican, M.~Reynolds, et~al.
\newblock Flamingo: a visual language model for few-shot learning.
\newblock {\em arXiv preprint arXiv:2204.14198}, 2022.

\bibitem{andriluka20142d}
M.~Andriluka, L.~Pishchulin, P.~Gehler, and B.~Schiele.
\newblock 2d human pose estimation: New benchmark and state of the art
  analysis.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 3686--3693, 2014.

\bibitem{bao2022beit}
H.~Bao, L.~Dong, S.~Piao, and F.~Wei.
\newblock {BE}it: {BERT} pre-training of image transformers.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{ASDA}
Y.~Bin, X.~Cao, X.~Chen, Y.~Ge, Y.~Tai, C.~Wang, J.~Li, F.~Huang, C.~Gao, and
  N.~Sang.
\newblock Adversarial semantic data augmentation for human pose estimation.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 606--622. Springer, 2020.

\bibitem{burgos2013robust}
X.~P. Burgos-Artizzu, P.~Perona, and P.~Doll{\'a}r.
\newblock Robust face landmark estimation under occlusion.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 1513--1520, 2013.

\bibitem{bigdetection2022}
L.~Cai, Z.~Zhang, Y.~Zhu, L.~Zhang, M.~Li, and X.~Xue.
\newblock Bigdetection: A large-scale benchmark for improved object detector
  pre-training.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 4777--4787, 2022.

\bibitem{cai2020learning}
Y.~Cai, Z.~Wang, Z.~Luo, B.~Yin, A.~Du, H.~Wang, X.~Zhou, E.~Zhou, X.~Zhang,
  and J.~Sun.
\newblock Learning delicate local representations for multi-person pose
  estimation.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, 2020.

\bibitem{Cao_2019_ICCV}
J.~Cao, H.~Tang, H.-S. Fang, X.~Shen, C.~Lu, and Y.-W. Tai.
\newblock Cross-domain adaptation for animal pose estimation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, October 2019.

\bibitem{carion2020end}
N.~Carion, F.~Massa, G.~Synnaeve, N.~Usunier, A.~Kirillov, and S.~Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, 2020.

\bibitem{mmpose2020}
M.~Contributors.
\newblock Openmmlab pose estimation toolbox and benchmark.
\newblock \url{https://github.com/open-mmlab/mmpose}, 2020.

\bibitem{deng2009imagenet}
J.~Deng, W.~Dong, R.~Socher, L.-J. Li, K.~Li, and L.~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 248--255, 2009.

\bibitem{dosovitskiy2020image}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai,
  T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{gou2021knowledge}
J.~Gou, B.~Yu, S.~J. Maybank, and D.~Tao.
\newblock Knowledge distillation: A survey.
\newblock {\em International Journal of Computer Vision}, 129(6):1789--1819,
  2021.

\bibitem{MaskedAutoencoders2021}
K.~He, X.~Chen, S.~Xie, Y.~Li, P.~Doll{\'a}r, and R.~Girshick.
\newblock Masked autoencoders are scalable vision learners.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 16000--16009, 2022.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 770--778, 2016.

\bibitem{hinton2015distilling}
G.~Hinton, O.~Vinyals, J.~Dean, et~al.
\newblock Distilling the knowledge in a neural network.
\newblock {\em arXiv preprint arXiv:1503.02531}, 2(7), 2015.

\bibitem{Huang_2020_CVPR}
J.~Huang, Z.~Zhu, F.~Guo, and G.~Huang.
\newblock The devil is in the details: Delving into unbiased data processing
  for human pose estimation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2020.

\bibitem{ioffe2015batch}
S.~Ioffe and C.~Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In {\em International conference on machine learning}, pages
  448--456. PMLR, 2015.

\bibitem{mipnet}
R.~Khirodkar, V.~Chari, A.~Agrawal, and A.~Tyagi.
\newblock Multi-instance pose networks: Rethinking top-down pose estimation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 3122--3131, 2021.

\bibitem{koestinger2011annotated}
M.~Koestinger, P.~Wohlhart, P.~M. Roth, and H.~Bischof.
\newblock Annotated facial landmarks in the wild: A large-scale, real-world
  database for facial landmark localization.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision Workshops (ICCV)}, pages 2144--2151, 2011.

\bibitem{li2019crowdpose}
J.~Li, C.~Wang, H.~Zhu, Y.~Mao, H.-S. Fang, and C.~Lu.
\newblock Crowdpose: Efficient crowded scenes pose estimation and a new
  benchmark.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 10863--10872, 2019.

\bibitem{Li_2021_CVPR}
K.~Li, S.~Wang, X.~Zhang, Y.~Xu, W.~Xu, and Z.~Tu.
\newblock Pose recognition with cascade transformers.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 1944--1953, June 2021.

\bibitem{li2019rethinking}
W.~Li, Z.~Wang, B.~Yin, Q.~Peng, Y.~Du, T.~Xiao, G.~Yu, H.~Lu, Y.~Wei, and
  J.~Sun.
\newblock Rethinking on multi-stage networks for human pose estimation.
\newblock {\em arXiv preprint arXiv:1901.00148}, 2019.

\bibitem{li2022exploring}
Y.~Li, H.~Mao, R.~Girshick, and K.~He.
\newblock Exploring plain vision transformer backbones for object detection.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, 2022.

\bibitem{li2021improved}
Y.~Li, C.-Y. Wu, H.~Fan, K.~Mangalam, B.~Xiong, J.~Malik, and C.~Feichtenhofer.
\newblock Mvitv2: Improved multiscale vision transformers for classification
  and detection.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, 2022.

\bibitem{li2021tokenpose}
Y.~Li, S.~Zhang, Z.~Wang, S.~Yang, W.~Yang, S.-T. Xia, and E.~Zhou.
\newblock Tokenpose: Learning keypoint tokens for human pose estimation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, 2021.

\bibitem{lin2014microsoft}
T.-Y. Lin, M.~Maire, S.~Belongie, J.~Hays, P.~Perona, D.~Ramanan,
  P.~Doll{\'a}r, and C.~L. Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, 2014.

\bibitem{lin2020human}
W.~Lin, H.~Liu, S.~Liu, Y.~Li, R.~Qian, T.~Wang, N.~Xu, H.~Xiong, G.-J. Qi, and
  N.~Sebe.
\newblock Human in events: A large-scale benchmark for human-centric video
  analysis in complex events.
\newblock {\em arXiv preprint arXiv:2005.04490}, 2020.

\bibitem{liu2021pre}
P.~Liu, W.~Yuan, J.~Fu, Z.~Jiang, H.~Hayashi, and G.~Neubig.
\newblock Pre-train, prompt, and predict: A systematic survey of prompting
  methods in natural language processing.
\newblock {\em arXiv preprint arXiv:2107.13586}, 2021.

\bibitem{liu2021swin}
Z.~Liu, Y.~Lin, Y.~Cao, H.~Hu, Y.~Wei, Z.~Zhang, S.~Lin, and B.~Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 10012--10022, 2021.

\bibitem{pan2021scalable}
Z.~Pan, B.~Zhuang, J.~Liu, H.~He, and J.~Cai.
\newblock Scalable vision transformers with hierarchical pooling.
\newblock In {\em Proceedings of the IEEE/cvf international conference on
  computer vision}, pages 377--386, 2021.

\bibitem{reddi2018convergence}
S.~J. Reddi, S.~Kale, and S.~Kumar.
\newblock On the convergence of adam and beyond.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{strudel2021segmenter}
R.~Strudel, R.~Garcia, I.~Laptev, and C.~Schmid.
\newblock Segmenter: Transformer for semantic segmentation.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 7262--7272, 2021.

\bibitem{CFA}
Z.~Su, M.~Ye, G.~Zhang, L.~Dai, and J.~Sheng.
\newblock Cascade feature aggregation for human pose estimation.
\newblock {\em arXiv preprint arXiv:1902.07837}, 2019.

\bibitem{sun2019deep}
K.~Sun, B.~Xiao, D.~Liu, and J.~Wang.
\newblock Deep high-resolution representation learning for human pose
  estimation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 5693--5703, 2019.

\bibitem{toshev2014deeppose}
A.~Toshev and C.~Szegedy.
\newblock Deeppose: Human pose estimation via deep neural networks.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 1653--1660, 2014.

\bibitem{wang2021scaled}
P.~Wang, X.~Wang, H.~Luo, J.~Zhou, Z.~Zhou, F.~Wang, H.~Li, and R.~Jin.
\newblock Scaled relu matters for training vision transformers.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~36, pages 2495--2503, 2022.

\bibitem{wang2021pyramid}
W.~Wang, E.~Xie, X.~Li, D.-P. Fan, K.~Song, D.~Liang, T.~Lu, P.~Luo, and
  L.~Shao.
\newblock Pyramid vision transformer: A versatile backbone for dense prediction
  without convolutions.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 568--578, 2021.

\bibitem{wang2022crossformer}
W.~Wang, L.~Yao, L.~Chen, B.~Lin, D.~Cai, X.~He, and W.~Liu.
\newblock Crossformer: A versatile vision transformer hinging on cross-scale
  attention.
\newblock In {\em International Conference on Learning Representations}, 2022.

\bibitem{wu2017ai}
J.~Wu, H.~Zheng, B.~Zhao, Y.~Li, B.~Yan, R.~Liang, W.~Wang, S.~Zhou, G.~Lin,
  Y.~Fu, et~al.
\newblock Ai challenger: A large-scale dataset for going deeper in image
  understanding.
\newblock {\em arXiv preprint arXiv:1711.06475}, 2017.

\bibitem{xiao2018simple}
B.~Xiao, H.~Wu, and Y.~Wei.
\newblock Simple baselines for human pose estimation and tracking.
\newblock In {\em Proceedings of the European conference on computer vision
  (ECCV)}, 2018.

\bibitem{xu2021vitae}
Y.~Xu, Q.~Zhang, J.~Zhang, and D.~Tao.
\newblock Vitae: Vision transformer advanced by exploring intrinsic inductive
  bias.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{yang2021transpose}
S.~Yang, Z.~Quan, M.~Nie, and W.~Yang.
\newblock Transpose: Keypoint localization via transformer.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, 2021.

\bibitem{yang2022apt}
Y.~Yang, J.~Yang, Y.~Xu, J.~Zhang, L.~Lan, and D.~Tao.
\newblock Apt-36k: A large-scale benchmark for animal pose estimation and
  tracking.
\newblock In {\em Advances in neural information processing systems Datasets
  and Benchmarks Track}, 2022.

\bibitem{yang2019xlnet}
Z.~Yang, Z.~Dai, Y.~Yang, J.~Carbonell, R.~R. Salakhutdinov, and Q.~V. Le.
\newblock Xlnet: Generalized autoregressive pretraining for language
  understanding.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{yu2021ap10k}
H.~Yu, Y.~Xu, J.~Zhang, W.~Zhao, Z.~Guan, and D.~Tao.
\newblock Ap-10k: A benchmark for animal pose estimation in the wild.
\newblock In {\em Thirty-fifth Conference on Neural Information Processing
  Systems Datasets and Benchmarks Track (Round 2)}, 2021.

\bibitem{YuanFHLZCW21}
Y.~Yuan, R.~Fu, L.~Huang, W.~Lin, C.~Zhang, X.~Chen, and J.~Wang.
\newblock Hrformer: High-resolution transformer for dense prediction.
\newblock In {\em Advances in Neural Information Processing Systems}, 2021.

\bibitem{zhang2020distribution}
F.~Zhang, X.~Zhu, H.~Dai, M.~Ye, and C.~Zhu.
\newblock Distribution-aware coordinate representation for human pose
  estimation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 7093--7102, 2020.

\bibitem{zhang2021towards}
J.~Zhang, Z.~Chen, and D.~Tao.
\newblock Towards high performance human keypoint detection.
\newblock {\em International Journal of Computer Vision}, 129(9):2639--2662,
  2021.

\bibitem{zhang2020empowering}
J.~Zhang and D.~Tao.
\newblock Empowering things with intelligence: a survey of the progress,
  challenges, and opportunities in artificial intelligence of things.
\newblock {\em IEEE Internet of Things Journal}, 8(10):7789--7817, 2020.

\bibitem{zhang2022vitaev2}
Q.~Zhang, Y.~Xu, J.~Zhang, and D.~Tao.
\newblock Vitaev2: Vision transformer advanced by exploring inductive bias for
  image recognition and beyond.
\newblock {\em arXiv preprint arXiv:2202.10108}, 2022.

\bibitem{zhang2022vsa}
Q.~Zhang, Y.~Xu, J.~Zhang, and D.~Tao.
\newblock Vsa: Learning varied-size window attention in vision transformers.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, 2022.

\bibitem{zhang2019pose2seg}
S.-H. Zhang, R.~Li, X.~Dong, P.~Rosin, Z.~Cai, X.~Han, D.~Yang, H.~Huang, and
  S.-M. Hu.
\newblock Pose2seg: Detection free human instance segmentation.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 889--898, 2019.

\bibitem{zhou2021elsa}
J.~Zhou, P.~Wang, F.~Wang, Q.~Liu, H.~Li, and R.~Jin.
\newblock Elsa: Enhanced local self-attention for vision transformer.
\newblock {\em arXiv preprint arXiv:2112.12786}, 2021.

\end{thebibliography}
