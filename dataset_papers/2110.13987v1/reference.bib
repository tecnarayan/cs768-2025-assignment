@article{Fu,
  author    = {Zhang{-}Hua Fu and
               Kai{-}Bin Qiu and
               Hongyuan Zha},
  title     = {Generalize a Small Pre-trained Model to Arbitrarily Large {TSP} Instances},
  journal   = {CoRR},
  volume    = {abs/2012.10658},
  year      = {2020},
  url       = {https://arxiv.org/abs/2012.10658},
  archivePrefix = {arXiv},
  eprint    = {2012.10658},
  timestamp = {Mon, 04 Jan 2021 16:33:46 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2012-10658.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@MISC{LNS,
    author = {Paul Shaw},
    title = {A New Local Search Algorithm Providing High Quality Solutions to Vehicle Routing Problems},
    year = {1997}
}

@inproceedings{POMO,
 author = {Kwon, Yeong-Dae and Choo, Jinho and Kim, Byoungjip and Yoon, Iljoo and Gwon, Youngjune and Min, Seungjai},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {21188--21198},
 publisher = {Curran Associates, Inc.},
 title = {POMO: Policy Optimization with Multiple Optima for Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper/2020/file/f231f2107df69eab0a3862d50018a9b2-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{MDAM,
  title={Multi-decoder attention model with embedding glimpse for solving vehicle routing problems},
  author={Xin, Liang and Song, Wen and Cao, Zhiguang and Zhang, Jie},
  booktitle={Proceedings of 35th AAAI Conference on Artificial Intelligence},
  year={2021}
}

@inbook{matai,
author = {Matai, Rajesh and Singh, Surya and Mittal, M.L.},
year = {2010},
month = {11},
pages = {},
title = {Traveling Salesman Problem: an Overview of Applications, Formulations, and Solution Approaches},
isbn = {978-953-307-426-9},
doi = {10.5772/12909}
}
@misc{gurobi,  author = "Gurobi Optimization, LLC",  title = "Gurobi Optimizer Reference Manual",  year = 2021,  url = "http://www.gurobi.com"}

@article{NLNS,
  author    = {Andr{\'{e}} Hottung and
               Kevin Tierney},
  title     = {Neural Large Neighborhood Search for the Capacitated Vehicle Routing
               Problem},
  journal   = {CoRR},
  volume    = {abs/1911.09539},
  year      = {2019},
  url       = {http://arxiv.org/abs/1911.09539},
  archivePrefix = {arXiv},
  eprint    = {1911.09539},
  timestamp = {Tue, 03 Dec 2019 14:15:54 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1911-09539.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@ARTICLE{robot,
  author={B. {Yuan} and M. {Orlowska} and S. {Sadiq}},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={On the Optimal Robot Routing Problem in Wireless Sensor Networks}, 
  year={2007},
  volume={19},
  number={9},
  pages={1252-1261},
  doi={10.1109/TKDE.2007.1062}}


@article{bio,
author = {Johnson, Olin and Liu, Jing},
year = {2006},
month = {02},
pages = {3},
title = {A traveling salesman approach for predicting protein functions},
volume = {1},
journal = {Source code for biology and medicine},
doi = {10.1186/1751-0473-1-3}
}


@article{Croes58,
  added-at = {2008-08-12T13:46:30.000+0200},
  author = {Croes, A.},
  biburl = {https://www.bibsonomy.org/bibtex/2ba6ebabb44a999c285348b9e9ebd89ba/apo},
  interhash = {9d73f125dd4309fa85191cdb925a885f},
  intrahash = {ba6ebabb44a999c285348b9e9ebd89ba},
  journal = {Operations Research},
  keywords = {da2 tsp vrp},
  pages = {791â€“-812},
  timestamp = {2008-08-12T13:46:31.000+0200},
  title = {A method for solving traveling salesman problems},
  volume = 5,
  year = 1958
}

@article{smith,
title = "Neural Networks for Combinatorial Optimization: A Review of More Than a Decade of Research",
author = "Smith, {Kate A}",
year = "1999",
language = "English",
pages = "15 -- 34",
journal = "INFORMS Journal on Computing",
issn = "1091-9856",
publisher = "Institute for Operations Research and the Management Sciences (INFORMS)",
}


@software{ortools,
  title = {OR-Tools},
  version = {7.2},
  author = {Laurent Perron and Vincent Furnon},
  year = {2019},
  organization = {Google},
  url = {https://developers.google.com/optimization/},
  date = {2019-7-19}
}


@inproceedings{Nazari,
 author = {Nazari, MohammadReza and Oroojlooy, Afshin and Snyder, Lawrence and Takac, Martin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {9839--9849},
 publisher = {Curran Associates, Inc.},
 title = {Reinforcement Learning for Solving the Vehicle Routing Problem},
 url = {https://proceedings.neurips.cc/paper/2018/file/9fb4651c05b2ed70fba5afe0b039a550-Paper.pdf},
 volume = {31},
 year = {2018}
}


@article{dantzig,
 ISSN = {00963984},
 URL = {http://www.jstor.org/stable/166695},
 abstract = {It is shown that a certain tour of 49 cities, one in each of the 48 states and Washington, D. C., has the shortest road distance.},
 author = {G. Dantzig and R. Fulkerson and S. Johnson},
 journal = {Journal of the Operations Research Society of America},
 number = {4},
 pages = {393--410},
 publisher = {INFORMS},
 title = {Solution of a Large-Scale Traveling-Salesman Problem},
 volume = {2},
 year = {1954}
}

@inproceedings{chen2019learning,
  title={Learning to Perform Local Rewriting for Combinatorial Optimization},
  author={Chen, Xinyun and Tian, Yuandong},
  booktitle={Advances in Neural Information Processing Systems},
  year={2019}
}

@InProceedings{drl-2opt,
  title = 	 {Learning 2-opt Heuristics for the Traveling Salesman Problem via Deep Reinforcement Learning},
  author =       {da Costa, Paulo R d O and Rhuggenaath, Jason and Zhang, Yingqian and Akcay, Alp},
  booktitle = 	 {Proceedings of The 12th Asian Conference on Machine Learning},
  pages = 	 {465--480},
  year = 	 {2020},
  editor = 	 {Sinno Jialin Pan and Masashi Sugiyama},
  volume = 	 {129},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Bangkok, Thailand},
  month = 	 {18--20 Nov},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v129/costa20a/costa20a.pdf},
  url = 	 {http://proceedings.mlr.press/v129/costa20a.html},
  abstract = 	 {Recent works using deep learning to solve the Traveling Salesman Problem (TSP) have focused on learning construction heuristics. Such approaches find TSP solutions of good quality but require additional procedures such as beam search and sampling to improve solutions and achieve state-of-the-art performance. However, few studies have focused on improvement heuristics, where a given solution is improved until reaching a near-optimal one. In this work, we propose to learn a local search heuristic based on 2-opt operators via deep reinforcement learning. We propose a policy gradient algorithm to learn a stochastic policy that selects 2-opt operations given a current solution. Moreover, we introduce a policy neural network that leverages a pointing attention mechanism, which unlike previous works, can be easily extended to more general $k$-opt moves. Our results show that the learned policies can improve even over random initial solutions and approach near-optimal solutions at a faster rate than previous state-of-the-art deep learning methods.}
}


@article{helsgaun,
author = {Helsgaun, Keld},
year = {2000},
month = {10},
pages = {106-130},
title = {An Effective Implementation of the Lin-Kernighan Traveling Salesman Heuristic},
volume = {126},
journal = {European Journal of Operational Research},
doi = {10.1016/S0377-2217(99)00284-2}
}

@article{PAPADIMITRIOU1977237,
title = "The Euclidean travelling salesman problem is NP-complete",
journal = "Theoretical Computer Science",
volume = "4",
number = "3",
pages = "237 - 244",
year = "1977",
issn = "0304-3975",
doi = "https://doi.org/10.1016/0304-3975(77)90012-3",
url = "http://www.sciencedirect.com/science/article/pii/0304397577900123",
author = "Christos H. Papadimitriou",
abstract = "The Travelling Salesman Problem is shown to be NP-Complete even if its instances are restricted to be realizable by sets of points on the Euclidean plane."
}

@article{LeCun,
author = {LeCun, Yann and Bengio, Y. and Hinton, Geoffrey},
year = {2015},
month = {05},
pages = {436-44},
title = {Deep Learning},
volume = {521},
journal = {Nature},
doi = {10.1038/nature14539}
}


% @inproceedings{
%     concorde1,
%      title = {Concorde TSP solver},
%      author = {David Applegate, Robert Bixby, Vasek Chvatal, and William Cook},
%      booktitle={International Conference on Learning Representations},
%      year = {2006},
%      url = {http://www.math.uwaterloo.ca/tsp/concorde/m},
% }

@inproceedings{
    concorde,
    title={Concorde TSP solver},
    author={David Applegate and Robert Bixby and Vasek Chvatal and William Cook},
    year={2006},
    url={http://www.math.uwaterloo.ca/tsp/concorde/m},
}


@inproceedings{
    kool2018attention,
    title={Attention, Learn to Solve Routing Problems!},
    author={Wouter Kool and Herke van Hoof and Max Welling},
    booktitle={International Conference on Learning Representations},
    year={2019},
    url={https://openreview.net/forum?id=ByxBFsRqYm},
}

@article{orienteering,
author = {Golden, Bruce L. and Levy, Larry and Vohra, Rakesh},
title = {The orienteering problem},
journal = {Naval Research Logistics (NRL)},
volume = {34},
number = {3},
pages = {307-318},
doi = {https://doi.org/10.1002/1520-6750(198706)34:3<307::AID-NAV3220340302>3.0.CO;2-D},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/1520-6750%28198706%2934%3A3%3C307%3A%3AAID-NAV3220340302%3E3.0.CO%3B2-D},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/1520-6750%28198706%2934%3A3%3C307%3A%3AAID-NAV3220340302%3E3.0.CO%3B2-D},
abstract = {Abstract Orienteering is a sport in which start and end points are specified along with other locations. These other locations have associated scores. Competitors seek to visit, in a fixed amount of time, a subset of these locations on the way from the start point to the end point in order to maximize the total score. An effective center-of-gravity heuristic is presented that outperforms heuristics from the literature.},
year = {1987}
}


@misc{bello2017neural,
      title={Neural Combinatorial Optimization with Reinforcement Learning}, 
      author={Irwan Bello and Hieu Pham and Quoc V. Le and Mohammad Norouzi and Samy Bengio},
      year={2017},
      eprint={1611.09940},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@INPROCEEDINGS{kim,
  author={M. {Kim} and H. {Park} and S. {Kim} and K. {Son} and S. {Kim} and K. {Son} and S. {Choi} and G. {Park} and J. {Kim}},
  booktitle={2020 IEEE 29th Conference on Electrical Performance of Electronic Packaging and Systems (EPEPS)}, 
  title={Reinforcement Learning-based Auto-router considering Signal Integrity}, 
  year={2020},
  volume={},
  number={},
  pages={1-3},
  doi={10.1109/EPEPS48591.2020.9231473}}
  
@article{Liao2019ADR,
  title={A Deep Reinforcement Learning Approach for Global Routing},
  author={Haiguang Liao and Wentai Zhang and Xuliang Dong and B. P{\'o}czos and K. Shimada and L. Kara},
  journal={ArXiv},
  year={2019},
  volume={abs/1906.08809}
}

@ARTICLE{8985416,
  author={H. {Park} and J. {Park} and S. {Kim} and K. {Cho} and D. {Lho} and S. {Jeong} and S. {Park} and G. {Park} and B. {Sim} and S. {Kim} and Y. {Kim} and J. {Kim}},
  journal={IEEE Transactions on Components, Packaging and Manufacturing Technology}, 
  title={Deep Reinforcement Learning-Based Optimal Decoupling Capacitor Design Method for Silicon Interposer-Based 2.5-D/3-D ICs}, 
  year={2020},
  volume={10},
  number={3},
  pages={467-478},
  doi={10.1109/TCPMT.2020.2972019}}
  
@misc{liao2020attention,
      title={Attention Routing: track-assignment detailed routing using attention-based reinforcement learning}, 
      author={Haiguang Liao and Qingyi Dong and Xuliang Dong and Wentai Zhang and Wangyang Zhang and Weiyi Qi and Elias Fallon and Levent Burak Kara},
      year={2020},
      eprint={2004.09473},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{ma2019combinatorial,
      title={Combinatorial Optimization by Graph Pointer Networks and Hierarchical Reinforcement Learning}, 
      author={Qiang Ma and Suwen Ge and Danyang He and Darshan Thaker and Iddo Drori},
      year={2019},
      eprint={1911.04936},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}






@misc{fu2020generalize,
      title={Generalize a Small Pre-trained Model to Arbitrarily Large TSP Instances}, 
      author={Zhang-Hua Fu and Kai-Bin Qiu and Hongyuan Zha},
      year={2020},
      eprint={2012.10658},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{dacosta2020learning,
      title={Learning 2-opt Heuristics for the Traveling Salesman Problem via Deep Reinforcement Learning}, 
      author={Paulo R. de O. da Costa and Jason Rhuggenaath and Yingqian Zhang and Alp Akcay},
      year={2020},
      eprint={2004.01608},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{wu2020learning,
      title={Learning Improvement Heuristics for Solving Routing Problems}, 
      author={Yaoxin Wu and Wen Song and Zhiguang Cao and Jie Zhang and Andrew Lim},
      year={2020},
      eprint={1912.05784},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{hopfield,
author = {Hopfield, John and Tank, D},
year = {1985},
month = {02},
pages = {141-52},
title = {Neural Computation of Decisions in Optimization Problems},
volume = {52},
journal = {Biological cybernetics},
doi = {10.1007/BF00339943}
}

@inproceedings{pointer,
 author = {Vinyals, Oriol and Fortunato, Meire and Jaitly, Navdeep},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
 pages = {2692--2700},
 publisher = {Curran Associates, Inc.},
 title = {Pointer Networks},
 url = {https://proceedings.neurips.cc/paper/2015/file/29921001f2f04bd3baee84a12e98098f-Paper.pdf},
 volume = {28},
 year = {2015}
}


@InProceedings{duedon,
author="Deudon, Michel
and Cournut, Pierre
and Lacoste, Alexandre
and Adulyasak, Yossiri
and Rousseau, Louis-Martin",
editor="van Hoeve, Willem-Jan",
title="Learning Heuristics for the TSP by Policy Gradient",
booktitle="Integration of Constraint Programming, Artificial Intelligence, and Operations Research",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="170--181",
abstract="The aim of the study is to provide interesting insights on how efficient machine learning algorithms could be adapted to solve combinatorial optimization problems in conjunction with existing heuristic procedures. More specifically, we extend the neural combinatorial optimization framework to solve the traveling salesman problem (TSP). In this framework, the city coordinates are used as inputs and the neural network is trained using reinforcement learning to predict a distribution over city permutations. Our proposed framework differs from the one in [1] since we do not make use of the Long Short-Term Memory (LSTM) architecture and we opted to design our own critic to compute a baseline for the tour length which results in more efficient learning. More importantly, we further enhance the solution approach with the well-known 2-opt heuristic. The results show that the performance of the proposed framework alone is generally as good as high performance heuristics (OR-Tools). When the framework is equipped with a simple 2-opt procedure, it could outperform such heuristics and achieve close to optimal results on 2D Euclidean graphs. This demonstrates that our approach based on machine learning techniques could learn good heuristics which, once being enhanced with a simple local search, yield promising results.",
isbn="978-3-319-93031-2"
}
@inproceedings{adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6980},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/KingmaB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{lstm,
author = {Hochreiter, Sepp and Schmidhuber, JÃ¼rgen},
year = {1997},
month = {12},
pages = {1735-80},
title = {Long Short-term Memory},
volume = {9},
journal = {Neural computation},
doi = {10.1162/neco.1997.9.8.1735}
}

@inproceedings{attention,
  author    = {Dzmitry Bahdanau and
               Kyunghyun Cho and
               Yoshua Bengio},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Neural Machine Translation by Jointly Learning to Align and Translate},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1409.0473},
  timestamp = {Wed, 17 Jul 2019 10:40:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/BahdanauCB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{khalil,
 author = {Khalil, Elias and Dai, Hanjun and Zhang, Yuyu and Dilkina, Bistra and Song, Le},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {6348--6358},
 publisher = {Curran Associates, Inc.},
 title = {Learning Combinatorial Optimization Algorithms over Graphs},
 url = {https://proceedings.neurips.cc/paper/2017/file/d9896106ca98d3d05b8cbdf4fd8b13a1-Paper.pdf},
 volume = {30},
 year = {2017}
}
@InProceedings{ma2019combinatorial,
  author    = {Ma, Qiang and Ge, Suwen and He, Danyang and Thaker, Darshan and Drori, Iddo},
  title     = {Combinatorial Optimization by Graph Pointer Networks and Hierarchical Reinforcement Learning},
  booktitle = {AAAI Workshop on Deep Learning on Graphs: Methodologies and Applications},
  year      = {2020},
}
@misc{rennie2017selfcritical,
      title={Self-critical Sequence Training for Image Captioning}, 
      author={Steven J. Rennie and Etienne Marcheret and Youssef Mroueh and Jarret Ross and Vaibhava Goel},
      year={2017},
      eprint={1612.00563},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@book{toth,
author = {Toth, Paolo and Vigo, Daniele},editor = {Daniele Vigo and Paolo Toth},
title = {Vehicle Routing},
publisher = {Society for Industrial and Applied Mathematics},
year = {2014},
doi = {10.1137/1.9781611973594},
address = {Philadelphia, PA},
edition   = {},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611973594}
}

@article{lkh2017,
author = {Helsgaun, Keld},
year = {2017},
month = {12},
pages = {},
title = {An Extension of the Lin-Kernighan-Helsgaun TSP Solver for Constrained Traveling Salesman and Vehicle Routing Problems},
doi = {10.13140/RG.2.2.25569.40807}
}

@inbook{cvrp,
author = {Stefan Irnich and Paolo Toth and Daniele Vigo},
title = {Chapter 1: The Family of Vehicle Routing Problems},
booktitle = {Vehicle Routing},
chapter = {},
pages = {1-33},
doi = {10.1137/1.9781611973594.ch1},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611973594.ch1},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611973594.ch1}
}


@InProceedings{placement1,
  title = 	 {Device Placement Optimization with Reinforcement Learning},
  author =       {Azalia Mirhoseini and Hieu Pham and Quoc V. Le and Benoit Steiner and Rasmus Larsen and Yuefeng Zhou and Naveen Kumar and Mohammad Norouzi and Samy Bengio and Jeff Dean},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {2430--2439},
  year = 	 {2017},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/mirhoseini17a/mirhoseini17a.pdf},
  url = 	 {
http://proceedings.mlr.press/v70/mirhoseini17a.html
},
  abstract = 	 {The past few years have witnessed a growth in size and computational requirements for training and inference with neural networks. Currently, a common approach to address these requirements is to use a heterogeneous distributed environment with a mixture of hardware devices such as CPUs and GPUs. Importantly, the decision of placing parts of the neural models on devices is often made by human experts based on simple heuristics and intuitions. In this paper, we propose a method which learns to optimize device placement for TensorFlow computational graphs. Key to our method is the use of a sequence-to-sequence model to predict which subsets of operations in a TensorFlow graph should run on which of the available devices. The execution time of the predicted placements is then used as the reward signal to optimize the parameters of the sequence-to-sequence model. Our main result is that on Inception-V3 for ImageNet classification, and on RNN LSTM, for language modeling and neural machine translation, our model finds non-trivial device placements that outperform hand-crafted heuristics and traditional algo-rithmic methods.}
}

@article{placement2,
  author    = {Azalia Mirhoseini and
               Anna Goldie and
               Mustafa Yazgan and
               Joe Jiang and
               Ebrahim M. Songhori and
               Shen Wang and
               Young{-}Joon Lee and
               Eric Johnson and
               Omkar Pathak and
               Sungmin Bae and
               Azade Nazi and
               Jiwoo Pak and
               Andy Tong and
               Kavya Srinivasa and
               William Hang and
               Emre Tuncer and
               Anand Babu and
               Quoc V. Le and
               James Laudon and
               Richard C. Ho and
               Roger Carpenter and
               Jeff Dean},
  title     = {Chip Placement with Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/2004.10746},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.10746},
  archivePrefix = {arXiv},
  eprint    = {2004.10746},
  timestamp = {Tue, 28 Apr 2020 16:10:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-10746.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{track,
  author    = {Haiguang Liao and
               Qingyi Dong and
               Xuliang Dong and
               Wentai Zhang and
               Wangyang Zhang and
               Weiyi Qi and
               Elias Fallon and
               Levent Burak Kara},
  title     = {Attention Routing: track-assignment detailed routing using attention-based
               reinforcement learning},
  journal   = {CoRR},
  volume    = {abs/2004.09473},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.09473},
  archivePrefix = {arXiv},
  eprint    = {2004.09473},
  timestamp = {Tue, 13 Oct 2020 08:36:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-09473.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{lu_cvrp,
  author    = {Hao Lu and
               Xingwen Zhang and
               Shuang Yang},
  title     = {A Learning-based Iterative Method for Solving Vehicle Routing Problems},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher = {OpenReview.net},
  year      = {2020},
  url       = {https://openreview.net/forum?id=BJe1334YDH},
  timestamp = {Thu, 07 May 2020 17:11:47 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/LuZY20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{bio1,
title	= {Model-Based Reinforcement Learning for Biological Sequence Design},
author	= {Christof Angermueller and David Dohan and David Belanger and Ramya Deshpande and Kevin Murphy and Lucy Colwell},
booktitle={International Conference on Learning Representations},
year	= {2020}
}


@article{joshi,
  author    = {Chaitanya K. Joshi and
               Thomas Laurent and
               Xavier Bresson},
  title     = {An Efficient Graph Convolutional Network Technique for the Travelling
               Salesman Problem},
  journal   = {CoRR},
  volume    = {abs/1906.01227},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.01227},
  archivePrefix = {arXiv},
  eprint    = {1906.01227},
  timestamp = {Sat, 23 Jan 2021 01:20:18 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1906-01227.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Article{Rein91,
  author      = {Gerhard Reinelt},
  journal     = {ORSA Journal on Computing},
  title       = {{TSPLIB}--A Traveling Salesman Problem Library},
  year        = {1991},
  number      = {4},
  pages       = {376--384},
  volume      = {3},
  optabstract = {This paper contains the description of a traveling salesman problem library (TSPLIB) which is meant to provide researchers with a broad set of test problems from various sources and with various properties. For every problem a short description is given along with known lower and upper bounds. Several references to computational tests on some of the problems are given. INFORMS Journal on Computing, ISSN 1091-9856, was published as ORSA Journal on Computing from 1989 to 1995 under ISSN 0899-1499.},
  optdoi      = {10.1287/ijoc.3.4.376},
  opteprint   = {https://doi.org/10.1287/ijoc.3.4.376},
  opturl      = {https://doi.org/10.1287/ijoc.3.4.376},
}

@article{kool_dp,
  author    = {Wouter Kool and
               Herke van Hoof and
               Joaquim A. S. Gromicho and
               Max Welling},
  title     = {Deep Policy Dynamic Programming for Vehicle Routing Problems},
  journal   = {CoRR},
  volume    = {abs/2102.11756},
  year      = {2021},
  url       = {https://arxiv.org/abs/2102.11756},
  archivePrefix = {arXiv},
  eprint    = {2102.11756},
  timestamp = {Wed, 24 Feb 2021 15:42:45 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2102-11756.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{transportation,
  author={Veres, Matthew and Moussa, Medhat},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Deep Learning for Intelligent Transportation Systems: A Survey of Emerging Trends}, 
  year={2020},
  volume={21},
  number={8},
  pages={3152-3168},
  doi={10.1109/TITS.2019.2929020}}

@article{pctsp,
author = {Balas, Egon},
title = {The prize collecting traveling salesman problem},
journal = {Networks},
volume = {19},
number = {6},
pages = {621-636},
doi = {https://doi.org/10.1002/net.3230190602},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/net.3230190602},
abstract = {Abstract The following is a valid model for an important class of scheduling and routing problems. A salesman who travels between pairs of cities at a cost depending only on the pair, gets a prize in every city that he vitis and pays a penalty to every city that he fails to visit, wishes to minimize his travel costs and net penalties, while visiting enough cities to collect a prescribed amount of prize money. We call this problem the Prize Collecting Traveling Salesman Problem (PCTSP). This paper discusses structural properties of the PCTS polytope, the convex hull of solutions to the PCTSP. In particular, it identifies several families of facet defining inequalities for this polytope. Some of these inequalities are related to facets of the ordinary TS polytope, others to facets of the knapsack polytope. They can be used in algorithms for the PCTSP either as cutting planes or as ingredients of a Lagrangean optimand.},
year = {1989}
}


@InProceedings{sac,
  title = 	 {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author =       {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1861--1870},
  year = 	 {2018},
  editor = 	 {Jennifer Dy and Andreas Krause},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {StockholmsmÃ¤ssan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/haarnoja18b/haarnoja18b.pdf},
  url = 	 {http://proceedings.mlr.press/v80/haarnoja18b.html},
  abstract = 	 {Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.}
}

@InProceedings{mis,
  title = 	 {Learning What to Defer for Maximum Independent Sets},
  author =       {Ahn, Sungsoo and Seo, Younggyo and Shin, Jinwoo},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {134--144},
  year = 	 {2020},
  editor = 	 {Hal DaumÃ© III and Aarti Singh},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/ahn20a/ahn20a.pdf},
  url = 	 {
http://proceedings.mlr.press/v119/ahn20a.html
},
  abstract = 	 {Designing efficient algorithms for combinatorial optimization appears ubiquitously in various scientific fields. Recently, deep reinforcement learning (DRL) frameworks have gained considerable attention as a new approach: they can automate the design of a solver while relying less on sophisticated domain knowledge of the target problem. However, the existing DRL solvers determine the solution using a number of stages proportional to the number of elements in the solution, which severely limits their applicability to large-scale graphs. In this paper, we seek to resolve this issue by proposing a novel DRL scheme, coined learning what to defer (LwD), where the agent adaptively shrinks or stretch the number of stages by learning to distribute the element-wise decisions of the solution at each stage. We apply the proposed framework to the maximum independent set (MIS) problem, and demonstrate its significant improvement over the current state-of-the-art DRL scheme. We also show that LwD can outperform the conventional MIS solvers on large-scale graphs having millions of vertices, under a limited time budget.}
}


@inproceedings{gurobi,
  author    = {Gurobi Optimization, LLC},
  title     = {Gurobi optimizer reference manual},
  year      = {2018},
  url       = {http://www.gurobi.com}
}

@article{entropy,
author = {Williams, Ronald and Peng, Jing},
year = {1991},
month = {09},
pages = {241-},
title = {Function Optimization Using Connectionist Reinforcement Learning Algorithms},
volume = {3},
journal = {Connection Science},
doi = {10.1080/09540099108946587}
}

@inproceedings{transformer,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {5998--6008},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@article{Williams:92,
  added-at = {2008-03-11T14:52:34.000+0100},
  author = {Williams, R. J.},
  biburl = {https://www.bibsonomy.org/bibtex/294224c3e53bfe80ade7218b3a0283465/idsia},
  citeulike-article-id = {2374762},
  interhash = {b90d65a735ae02a940f5075b0fd7ebe7},
  intrahash = {94224c3e53bfe80ade7218b3a0283465},
  journal = {Machine Learning},
  keywords = {daanbib},
  pages = {229--256},
  priority = {2},
  timestamp = {2008-03-11T15:05:47.000+0100},
  title = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  volume = 8,
  year = 1992
}


@inproceedings{actor,
 author = {Konda, Vijay and Tsitsiklis, John},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Solla and T. Leen and K. M\"{u}ller},
 pages = {1008--1014},
 publisher = {MIT Press},
 title = {Actor-Critic Algorithms},
 url = {https://proceedings.neurips.cc/paper/1999/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf},
 volume = {12},
 year = {2000}
}

@misc{joshi2020learning,
      title={Learning TSP Requires Rethinking Generalization}, 
      author={Chaitanya K. Joshi and Quentin Cappart and Louis-Martin Rousseau and Thomas Laurent and Xavier Bresson},
      year={2020},
      eprint={2006.07054},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@INPROCEEDINGS{ga1,
  author={Y. {Tsujimura} and M. {Gen}},
  booktitle={1998 Second International Conference. Knowledge-Based Intelligent Electronic Systems. Proceedings KES'98 (Cat. No.98EX111)}, 
  title={Entropy-based genetic algorithm for solving TSP}, 
  year={1998},
  volume={2},
  number={},
  pages={285-290 vol.2},
  doi={10.1109/KES.1998.725924}}
  
  @inproceedings{Singh2008HavrdaAC,
  title={Havrda and Charvat Entropy Based Genetic Algorithm for Traveling Salesman Problem},
  author={B. Singh},
  year={2008}
}

@article{smith1999neural,
	title={Neural Networks for Combinatorial Optimization: A Review of More Than a Decade of Research},
	author={Smith, A. Kate},
	journal={INFORMS Journal on Computing},
	pages={15--34},
	year={1999}
}
