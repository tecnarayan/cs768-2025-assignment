\begin{thebibliography}{10}

\bibitem{asanovic1991experimental}
Krste Asanovic and Nelson Morgan.
\newblock {\em Experimental determination of precision requirements for
  back-propagation training of artificial neural networks}.
\newblock International Computer Science Institute, 1991.

\bibitem{avron2011randomized}
Haim Avron and Sivan Toledo.
\newblock Randomized algorithms for estimating the trace of an implicit
  symmetric positive semi-definite matrix.
\newblock {\em Journal of the ACM (JACM)}, 58(2):8, 2011.

\bibitem{bai1996some}
Zhaojun Bai, Gark Fahey, and Gene Golub.
\newblock Some large-scale matrix computation problems.
\newblock {\em Journal of Computational and Applied Mathematics},
  74(1-2):71--89, 1996.

\bibitem{bengio2013estimating}
Yoshua Bengio, Nicholas L{\'e}onard, and Aaron Courville.
\newblock Estimating or propagating gradients through stochastic neurons for
  conditional computation.
\newblock {\em arXiv preprint arXiv:1308.3432}, 2013.

\bibitem{choi2018pact}
Jungwook Choi, Zhuo Wang, Swagath Venkataramani, Pierce I-Jen Chuang,
  Vijayalakshmi Srinivasan, and Kailash Gopalakrishnan.
\newblock {PACT}: Parameterized clipping activation for quantized neural
  networks.
\newblock {\em arXiv preprint arXiv:1805.06085}, 2018.

\bibitem{courbariaux2015binaryconnect}
Matthieu Courbariaux, Yoshua Bengio, and Jean-Pierre David.
\newblock {BinaryConnect}: Training deep neural networks with binary weights
  during propagations.
\newblock In {\em Advances in neural information processing systems}, pages
  3123--3131, 2015.

\bibitem{dong2019hawq}
Zhen Dong, Zhewei Yao, Amir Gholami, Michael~W. Mahoney, and Kurt Keutzer.
\newblock {HAWQ}: Hessian aware quantization of neural networks with
  mixed-precision.
\newblock In {\em The IEEE International Conference on Computer Vision (ICCV)},
  October 2019.

\bibitem{gholami2018squeezenext}
Amir Gholami, Kiseok Kwon, Bichen Wu, Zizheng Tai, Xiangyu Yue, Peter Jin,
  Sicheng Zhao, and Kurt Keutzer.
\newblock {SqueezeNext}: Hardware-aware neural network design.
\newblock {\em Workshop paper in CVPR}, 2018.

\bibitem{han2015deep}
Song Han, Huizi Mao, and William~J Dally.
\newblock Deep compression: Compressing deep neural networks with pruning,
  trained quantization and huffman coding.
\newblock {\em International Conference on Learning Representations}, 2016.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem{jacob2018quantization}
Benoit Jacob, Skirmantas Kligys, Bo~Chen, Menglong Zhu, Matthew Tang, Andrew
  Howard, Hartwig Adam, and Dmitry Kalenichenko.
\newblock Quantization and training of neural networks for efficient
  integer-arithmetic-only inference.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 2704--2713, 2018.

\bibitem{krishnamoorthi2018whitepaper}
Raghuraman Krishnamoorthi.
\newblock Quantizing deep convolutional networks for efficient inference: A
  whitepaper.
\newblock {\em arXiv preprint arXiv:1806.08342}, 2018.

\bibitem{li2019fully}
Rundong Li, Yan Wang, Feng Liang, Hongwei Qin, Junjie Yan, and Rui Fan.
\newblock Fully quantized network for object detection.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 2810--2819, 2019.

\bibitem{lin2017focal}
Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll{\'a}r.
\newblock Focal loss for dense object detection.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 2980--2988, 2017.

\bibitem{lin2014coco}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em European conference on computer vision}, pages 740--755.
  Springer, 2014.

\bibitem{Mah-mat-rev_BOOK}
M.~W. Mahoney.
\newblock {\em Randomized algorithms for matrices and data}.
\newblock Foundations and Trends in Machine Learning. NOW Publishers, Boston,
  2011.

\bibitem{PCMI_math_of_data_BOOK}
M.~W. Mahoney, J.~C. Duchi, and A.~C. Gilbert, editors.
\newblock {\em The Mathematics of Data}.
\newblock IAS/Park City Mathematics Series. AMS, IAS/PCMI, and SIAM, 2018.

\bibitem{park2018value}
Eunhyeok Park, Sungjoo Yoo, and Peter Vajda.
\newblock Value-aware quantization for training and inference of neural
  networks.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 580--595, 2018.

\bibitem{rastegari2016xnor}
Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, and Ali Farhadi.
\newblock {Xnor-net}: Imagenet classification using binary convolutional neural
  networks.
\newblock In {\em European Conference on Computer Vision}, pages 525--542.
  Springer, 2016.

\bibitem{shen2019Q-BERT}
Sheng Shen, Zhen Dong, Jiayu Ye, Linjian Ma, Zhewei Yao, Amir Gholami,
  Michael~W. Mahoney, and Kurt Keutzer.
\newblock {Q-BERT}: Hessian based ultra low precision quantization of bert.
\newblock {\em arXiv preprint arXiv:1909.05840}, 2019.

\bibitem{szegedy2016rethinking}
Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew
  Wojna.
\newblock Rethinking the inception architecture for computer vision.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2818--2826, 2016.

\bibitem{wang2018haq}
Kuan Wang, Zhijian Liu, Yujun Lin, Ji~Lin, and Song Han.
\newblock {HAQ}: Hardware-aware automated quantization.
\newblock {\em In Proceedings of the IEEE conference on computer vision and
  pattern recognition}, 2019.

\bibitem{wu2018mixed}
Bichen Wu, Yanghan Wang, Peizhao Zhang, Yuandong Tian, Peter Vajda, and Kurt
  Keutzer.
\newblock Mixed precision quantization of convnets via differentiable neural
  architecture search.
\newblock {\em arXiv preprint arXiv:1812.00090}, 2018.

\bibitem{wu2016quantized}
Jiaxiang Wu, Cong Leng, Yuhang Wang, Qinghao Hu, and Jian Cheng.
\newblock Quantized convolutional neural networks for mobile devices.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 4820--4828, 2016.

\bibitem{yao2018large}
Zhewei Yao, Amir Gholami, Kurt Keutzer, and Michael~W. Mahoney.
\newblock Large batch size training of neural networks with adversarial
  training and second-order information.
\newblock {\em arXiv preprint arXiv:1810.01021}, 2018.

\bibitem{yao2018hessian}
Zhewei Yao, Amir Gholami, Qi~Lei, Kurt Keutzer, and Michael~W. Mahoney.
\newblock Hessian-based analysis of large batch training and robustness to
  adversaries.
\newblock {\em Advances in Neural Information Processing Systems}, 2018.

\bibitem{yao2019trust}
Zhewei Yao, Amir Gholami, Peng Xu, Kurt Keutzer, and Michael~W. Mahoney.
\newblock Trust region based adversarial attack on neural networks.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 11350--11359, 2019.

\bibitem{zhang_2018_lqnets}
Dongqing Zhang, Jiaolong Yang, Dongqiangzi Ye, and Gang Hua.
\newblock {LQ-Nets}: Learned quantization for highly accurate and compact deep
  neural networks.
\newblock In {\em The European Conference on Computer Vision (ECCV)}, September
  2018.

\bibitem{zhou2017incremental}
Aojun Zhou, Anbang Yao, Yiwen Guo, Lin Xu, and Yurong Chen.
\newblock Incremental network quantization: Towards lossless {CNNs} with
  low-precision weights.
\newblock {\em International Conference on Learning Representations}, 2017.

\bibitem{zhou2016dorefa}
Shuchang Zhou, Yuxin Wu, Zekun Ni, Xinyu Zhou, He~Wen, and Yuheng Zou.
\newblock {DoReFa-Net}: Training low bitwidth convolutional neural networks
  with low bitwidth gradients.
\newblock {\em arXiv preprint arXiv:1606.06160}, 2016.

\end{thebibliography}
