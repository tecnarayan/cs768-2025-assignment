\begin{thebibliography}{70}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and
  Bottou]{arjovsky2017wasserstein}
M.~Arjovsky, S.~Chintala, and L.~Bottou.
\newblock Wasserstein generative adversarial networks.
\newblock In \emph{International conference on machine learning}, pages
  214--223. PMLR, 2017.

\bibitem[Arora et~al.(2017)Arora, Ge, Liang, Ma, and
  Zhang]{arora2017generalization}
S.~Arora, R.~Ge, Y.~Liang, T.~Ma, and Y.~Zhang.
\newblock Generalization and equilibrium in generative adversarial nets
  ({GAN}s).
\newblock In D.~Precup and Y.~W. Teh, editors, \emph{Proceedings of the 34th
  International Conference on Machine Learning}, volume~70 of \emph{Proceedings
  of Machine Learning Research}, pages 224--232. PMLR, 06--11 Aug 2017.
\newblock URL \url{https://proceedings.mlr.press/v70/arora17a.html}.

\bibitem[Balunovi\'{c} et~al.(2021)Balunovi\'{c}, Ruoss, and
  Vechev]{balunovic2021fair}
M.~Balunovi\'{c}, A.~Ruoss, and M.~Vechev.
\newblock Fair normalizing flows.
\newblock \emph{arXiv:2106.05937}, 2021.

\bibitem[Bansal et~al.(2018)Bansal, Chen, and Wang]{bansal2018}
N.~Bansal, X.~Chen, and Z.~Wang.
\newblock {Can We Gain More from Orthogonality Regularizations in Training Deep
  Networks?}
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~31, 2018.

\bibitem[Behrmann et~al.(2021)Behrmann, Vicol, Wang, Grosse, and
  Jacobsen]{behrmann2020}
J.~Behrmann, P.~Vicol, K.-C. Wang, R.~Grosse, and J.-H. Jacobsen.
\newblock Understanding and mitigating exploding inverses in invertible neural
  networks.
\newblock In \emph{Proceedings of The 24th International Conference on
  Artificial Intelligence and Statistics}, volume 130, pages 1792--1800. PMLR,
  13--15 Apr 2021.

\bibitem[Brehmer and Cranmer(2020)]{brehmer2020}
J.~Brehmer and K.~Cranmer.
\newblock {Flows for simultaneous manifold learning and density estimation}.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~33, 2020.

\bibitem[Brock et~al.(2019)Brock, Donahue, and Simonyan]{brock2018}
A.~Brock, J.~Donahue, and K.~Simonyan.
\newblock Large scale {GAN} training for high fidelity natural image synthesis.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Brundage et~al.(2018)Brundage, Avin, Clark, Toner, Eckersley,
  Garfinkel, Dafoe, Scharre, Zeitzoff, Filar, Anderson, Roff, Allen,
  Steinhardt, Flynn, h\'{E}igeartaigh, Beard, Belfield, Farquhar, Lyle,
  Crootof, Evans, Page, Bryson, Yampolskiy, and Amodei]{brundage2021malicious}
M.~Brundage, S.~Avin, J.~Clark, H.~Toner, P.~Eckersley, B.~Garfinkel, A.~Dafoe,
  P.~Scharre, T.~Zeitzoff, B.~Filar, H.~Anderson, H.~Roff, G.~C. Allen,
  J.~Steinhardt, C.~Flynn, S.~O. h\'{E}igeartaigh, S.~Beard, H.~Belfield,
  S.~Farquhar, C.~Lyle, R.~Crootof, O.~Evans, M.~Page, J.~Bryson,
  R.~Yampolskiy, and D.~Amodei.
\newblock The malicious use of artificial intelligence: Forecasting,
  prevention, and mitigation.
\newblock \emph{arXiv:1802.07228}, 2018.

\bibitem[Caterini et~al.(2021)Caterini, Loaiza-Ganem, Pleiss, and
  Cunningham]{caterini2021}
A.~L. Caterini, G.~Loaiza-Ganem, G.~Pleiss, and J.~P. Cunningham.
\newblock Rectangular flows for manifold learning.
\newblock \emph{arXiv:2106.01413}, 2021.

\bibitem[Child(2021)]{child2021}
R.~Child.
\newblock Very deep {VAE}s generalize autoregressive models and can outperform
  them on images.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Cornish et~al.(2020)Cornish, Caterini, Deligiannidis, and
  Doucet]{cornish2020}
R.~Cornish, A.~Caterini, G.~Deligiannidis, and A.~Doucet.
\newblock Relaxing bijectivity constraints with continuously indexed
  normalising flows.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, volume 119, pages 2133--2143, 2020.

\bibitem[Cunningham and Fiterau(2021)]{cunningham2021}
E.~Cunningham and M.~Fiterau.
\newblock A change of variables method for rectangular matrix-vector products.
\newblock In \emph{Proceedings of The 24th International Conference on
  Artificial Intelligence and Statistics}, volume 130. PMLR, 2021.

\bibitem[{Cunningham} et~al.(2020){Cunningham}, {Zabounidis}, {Agrawal},
  {Fiterau}, and {Sheldon}]{cunningham2020}
E.~{Cunningham}, R.~{Zabounidis}, A.~{Agrawal}, I.~{Fiterau}, and D.~{Sheldon}.
\newblock {Normalizing Flows Across Dimensions}.
\newblock \emph{arXiv:2006.13070}, 2020.

\bibitem[Dai and Wipf(2019)]{dai2019}
B.~Dai and D.~Wipf.
\newblock {Diagnosing and Enhancing {VAE} Models}.
\newblock In \emph{International Conference on Learning Representations, {ICLR}
  2019}, 2019.

\bibitem[Di~Francesco et~al.(2012)Di~Francesco, Mathieu, and
  S{\'e}n{\'e}chal]{francesco2012}
P.~Di~Francesco, P.~Mathieu, and D.~S{\'e}n{\'e}chal.
\newblock \emph{{Conformal field theory}}.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Dinh et~al.(2014)Dinh, Krueger, and Bengio]{dinh2014}
L.~Dinh, D.~Krueger, and Y.~Bengio.
\newblock Nice: Non-linear independent components estimation.
\newblock \emph{arXiv:1410.8516}, 2014.

\bibitem[Dinh et~al.(2017)Dinh, Sohl{-}Dickstein, and Bengio]{dinh2017}
L.~Dinh, J.~Sohl{-}Dickstein, and S.~Bengio.
\newblock {Density estimation using Real {NVP}}.
\newblock In \emph{International Conference on Learning Representations, {ICLR}
  2017}, 2017.

\bibitem[Du and Mordatch(2019)]{du2019}
Y.~Du and I.~Mordatch.
\newblock Implicit generation and modeling with energy based models.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32, 2019.

\bibitem[Durkan et~al.(2019)Durkan, Bekasov, Murray, and
  Papamakarios]{durkan2019neural}
C.~Durkan, A.~Bekasov, I.~Murray, and G.~Papamakarios.
\newblock Neural spline flows.
\newblock \emph{Advances in Neural Information Processing Systems},
  32:\penalty0 7511--7522, 2019.

\bibitem[Durkan et~al.(2020)Durkan, Bekasov, Murray, and Papamakarios]{nflows}
C.~Durkan, A.~Bekasov, I.~Murray, and G.~Papamakarios.
\newblock {nflows}: normalizing flows in {PyTorch}, Nov. 2020.
\newblock URL \url{https://doi.org/10.5281/zenodo.4296287}.

\bibitem[Fefferman et~al.(2016)Fefferman, Mitter, and Narayanan]{fefferman2016}
C.~Fefferman, S.~Mitter, and H.~Narayanan.
\newblock {Testing the manifold hypothesis}.
\newblock \emph{Journal of the American Mathematical Society}, 29\penalty0
  (4):\penalty0 983--1049, 2016.

\bibitem[Gemici et~al.(2016)Gemici, Rezende, and Mohamed]{gemici2016}
M.~C. Gemici, D.~Rezende, and S.~Mohamed.
\newblock {Normalizing Flows on Riemannian Manifolds}, 2016.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014}
I.~J. Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair,
  A.~Courville, and Y.~Bengio.
\newblock Generative adversarial networks.
\newblock \emph{arXiv:1406.2661}, 2014.

\bibitem[Grover et~al.(2018)Grover, Dhar, and Ermon]{grover2018flowgan}
A.~Grover, M.~Dhar, and S.~Ermon.
\newblock Flow-gan: Combining maximum likelihood and adversarial learning in
  generative models.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2018.

\bibitem[Gulrajani et~al.(2017)Gulrajani, Ahmed, Arjovsky, Dumoulin, and
  Courville]{gulrajani2017improved}
I.~Gulrajani, F.~Ahmed, M.~Arjovsky, V.~Dumoulin, and A.~C. Courville.
\newblock Improved training of wasserstein gans.
\newblock In \emph{NIPS}, 2017.

\bibitem[{Harandi} and {Fernando}(2016)]{harandi2016}
M.~{Harandi} and B.~{Fernando}.
\newblock {Generalized BackPropagation, {\'E}tude De Cas: Orthogonality}.
\newblock \emph{arXiv:1611.05927}, 2016.

\bibitem[Hartman(1958)]{hartman1958}
P.~Hartman.
\newblock On isometries and on a theorem of {L}iouville.
\newblock \emph{Mathematische Zeitschrift}, 69:\penalty0 202--210, 1958.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and
  Hochreiter]{heusel2017}
M.~Heusel, H.~Ramsauer, T.~Unterthiner, B.~Nessler, and S.~Hochreiter.
\newblock {GANs Trained by a Two Time-Scale Update Rule Converge to a Local
  Nash Equilibrium}.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~30, 2017.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020}
J.~Ho, A.~Jain, and P.~Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~33, pages 6840--6851, 2020.

\bibitem[Huang et~al.(2018)Huang, Liu, Lang, Yu, and Li]{huang2018}
L.~Huang, X.~Liu, B.~Lang, A.~W. Yu, and B.~Li.
\newblock Orthogonal weight normalization: Solution to optimization over
  multiple dependent stiefel manifolds in deep neural networks.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2018.

\bibitem[Jia et~al.(2017)Jia, Tao, Gao, and Xu]{jia2016}
K.~Jia, D.~Tao, S.~Gao, and X.~Xu.
\newblock Improving training of deep neural networks via singular value
  bounding.
\newblock In \emph{2017 IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pages 3994--4002, 2017.

\bibitem[Karras et~al.(2019)Karras, Laine, and Aila]{karras2019}
T.~Karras, S.~Laine, and T.~Aila.
\newblock A style-based generator architecture for generative adversarial
  networks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, June 2019.

\bibitem[Karras et~al.(2020)Karras, Aittala, Hellsten, Laine, Lehtinen, and
  Aila]{karras2020}
T.~Karras, M.~Aittala, J.~Hellsten, S.~Laine, J.~Lehtinen, and T.~Aila.
\newblock Training generative adversarial networks with limited data.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~33, pages 12104--12114, 2020.

\bibitem[Kingma and Ba(2015)]{kingma2015}
D.~P. Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{3rd International Conference on Learning Representations,
  {ICLR} 2015}, 2015.
\newblock URL \url{http://arxiv.org/abs/1412.6980}.

\bibitem[Kingma and Dhariwal(2018)]{kingma2018}
D.~P. Kingma and P.~Dhariwal.
\newblock {Glow: Generative Flow with Invertible 1x1 Convolutions}.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~31, 2018.

\bibitem[Kingma and Welling(2013)]{kingma2013}
D.~P. Kingma and M.~Welling.
\newblock {Auto-encoding Variational Bayes}.
\newblock \emph{arXiv:1312.6114}, 2013.

\bibitem[Kingma et~al.(2016)Kingma, Salimans, Jozefowicz, Chen, Sutskever, and
  Welling]{kingma2016}
D.~P. Kingma, T.~Salimans, R.~Jozefowicz, X.~Chen, I.~Sutskever, and
  M.~Welling.
\newblock Improved variational inference with inverse autoregressive flow.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~29, 2016.

\bibitem[Koenen et~al.(2021)Koenen, Wright, Maass, and
  Behrmann]{koenen2021generalization}
N.~Koenen, M.~N. Wright, P.~Maass, and J.~Behrmann.
\newblock Generalization of the change of variables formula with applications
  to residual flows.
\newblock In \emph{ICML Workshop on Invertible Neural Networks, Normalizing
  Flows, and Explicit Likelihood Models}, 2021.

\bibitem[{Kothari} et~al.(2021){Kothari}, {Khorashadizadeh}, {de Hoop}, and
  {Dokmani{\'c}}]{kothari2021}
K.~{Kothari}, A.~{Khorashadizadeh}, M.~{de Hoop}, and I.~{Dokmani{\'c}}.
\newblock {Trumpets: Injective Flows for Inference and Inverse Problems}.
\newblock \emph{arxiv:2102.10461}, 2021.

\bibitem[Krizhevsky(2009)]{krizhevsky2009learning}
A.~Krizhevsky.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, University of Toronto, 2009.
\newblock URL
  \url{https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf}.

\bibitem[Kumar et~al.(2020)Kumar, Poole, and Murphy]{kumar2020}
A.~Kumar, B.~Poole, and K.~Murphy.
\newblock {Regularized Autoencoders via Relaxed Injective Probability Flow}.
\newblock In \emph{Proceedings of the Twenty Third International Conference on
  Artificial Intelligence and Statistics}, volume 108, pages 4292--4301, 2020.

\bibitem[LeCun et~al.(1998)LeCun, Bottou, Bengio, and
  Haffner]{lecun1998gradient}
Y.~LeCun, L.~Bottou, Y.~Bengio, and P.~Haffner.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, 1998.

\bibitem[Lee(2018)]{lee2018}
J.~M. Lee.
\newblock \emph{{Introduction to Riemannian manifolds}}.
\newblock Springer, 2018.

\bibitem[Lezcano-Casado(2019)]{lezcano2019b}
M.~Lezcano-Casado.
\newblock Trivializations for gradient-based optimization on manifolds.
\newblock In \emph{Advances in Neural Information Processing Systems, NeurIPS},
  pages 9154--9164, 2019.

\bibitem[Lezcano-Casado and Mart\'{\i}nez-Rubio(2019)]{lezcano2019a}
M.~Lezcano-Casado and D.~Mart\'{\i}nez-Rubio.
\newblock {Cheap Orthogonal Constraints in Neural Networks: A Simple
  Parametrization of the Orthogonal and Unitary Group}.
\newblock In \emph{Proceedings of the 36th International Conference on Machine
  Learning}, volume~97, pages 3794--3803, 2019.

\bibitem[Liu et~al.(2015)Liu, Luo, Wang, and Tang]{liu2015}
Z.~Liu, P.~Luo, X.~Wang, and X.~Tang.
\newblock Deep learning face attributes in the wild.
\newblock In \emph{Proceedings of International Conference on Computer Vision
  (ICCV)}, December 2015.

\bibitem[Loshchilov and Hutter(2017)]{loschilov2017warm}
I.~Loshchilov and F.~Hutter.
\newblock {SGDR:} stochastic gradient descent with warm restarts.
\newblock In \emph{5th International Conference on Learning Representations,
  {ICLR} 2017}, 2017.
\newblock URL \url{https://openreview.net/forum?id=Skq89Scxx}.

\bibitem[Mathieu and Nickel(2020)]{mathieu2020}
E.~Mathieu and M.~Nickel.
\newblock {Riemannian Continuous Normalizing Flows}.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~33, pages 2503--2515, 2020.

\bibitem[Naeem et~al.(2020)Naeem, Oh, Uh, Choi, and Yoo]{naeem2020}
M.~F. Naeem, S.~J. Oh, Y.~Uh, Y.~Choi, and J.~Yoo.
\newblock Reliable fidelity and diversity metrics for generative models.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, volume 119 of \emph{Proceedings of Machine Learning Research},
  pages 7176--7185. PMLR, 13--18 Jul 2020.

\bibitem[Nair and Hinton(2010)]{nair2010}
V.~Nair and G.~E. Hinton.
\newblock Rectified linear units improve restricted boltzmann machines.
\newblock In \emph{Proceedings of the 27th International Conference on
  International Conference on Machine Learning}, ICML'10, page 807–814, 2010.

\bibitem[Nalisnick et~al.(2019)Nalisnick, Matsukawa, Teh, Gorur, and
  Lakshminarayanan]{nalisnick2018deep}
E.~Nalisnick, A.~Matsukawa, Y.~W. Teh, D.~Gorur, and B.~Lakshminarayanan.
\newblock Do deep generative models know what they don't know?
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=H1xwNhCcYm}.

\bibitem[Oord et~al.(2016)Oord, Kalchbrenner, and Kavukcuoglu]{vanoord2016}
A.~V. Oord, N.~Kalchbrenner, and K.~Kavukcuoglu.
\newblock Pixel recurrent neural networks.
\newblock In \emph{Proceedings of The 33rd International Conference on Machine
  Learning}, volume~48 of \emph{Proceedings of Machine Learning Research},
  pages 1747--1756. PMLR, 2016.

\bibitem[{Ozay} and {Okatani}(2016)]{ozay2016}
M.~{Ozay} and T.~{Okatani}.
\newblock {Optimization on Submanifolds of Convolution Kernels in CNNs}.
\newblock \emph{arXiv:1610.07008}, 2016.

\bibitem[Papamakarios et~al.(2021)Papamakarios, Nalisnick, Rezende, Mohamed,
  and Lakshminarayanan]{papamakarios2021}
G.~Papamakarios, E.~Nalisnick, D.~J. Rezende, S.~Mohamed, and
  B.~Lakshminarayanan.
\newblock {Normalizing Flows for Probabilistic Modeling and Inference}.
\newblock \emph{Journal of Machine Learning Research}, 22\penalty0
  (57):\penalty0 1--64, 2021.

\bibitem[Pennec(2006)]{pennec2006intrinsic}
X.~Pennec.
\newblock Intrinsic statistics on riemannian manifolds: Basic tools for
  geometric measurements.
\newblock \emph{Journal of Mathematical Imaging and Vision}, 25\penalty0
  (1):\penalty0 127--154, 2006.

\bibitem[Peterfreund et~al.(2020)Peterfreund, Lindenbaum, Dietrich, Bertalan,
  Gavish, Kevrekidis, and Coifman]{peterfreund2020}
E.~Peterfreund, O.~Lindenbaum, F.~Dietrich, T.~Bertalan, M.~Gavish, I.~G.
  Kevrekidis, and R.~R. Coifman.
\newblock Local conformal autoencoder for standardized data coordinates.
\newblock \emph{Proceedings of the National Academy of Sciences}, 117\penalty0
  (49):\penalty0 30918--30927, 2020.

\bibitem[Qi et~al.(2020)Qi, You, Wang, Ma, and Malik]{qi2020}
H.~Qi, C.~You, X.~Wang, Y.~Ma, and J.~Malik.
\newblock Deep isometric learning for visual recognition.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, volume 119, pages 7824--7835, 2020.

\bibitem[Radford et~al.(2016)Radford, Metz, and Chintala]{radford2015}
A.~Radford, L.~Metz, and S.~Chintala.
\newblock {Unsupervised Representation Learning with Deep Convolutional
  Generative Adversarial Networks}.
\newblock In \emph{International Conference on Learning Representations}, 2016.

\bibitem[Rezende and Mohamed(2015)]{rezende2015}
D.~Rezende and S.~Mohamed.
\newblock {Variational Inference with Normalizing Flows}.
\newblock In \emph{Proceedings of the 32nd International Conference on Machine
  Learning}, volume~37, pages 1530--1538, 2015.

\bibitem[Rezende et~al.(2020)Rezende, Papamakarios, Racaniere, Albergo, Kanwar,
  Shanahan, and Cranmer]{rezende2020}
D.~J. Rezende, G.~Papamakarios, S.~Racaniere, M.~Albergo, G.~Kanwar,
  P.~Shanahan, and K.~Cranmer.
\newblock {Normalizing Flows on Tori and Spheres}.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, volume 119, pages 8083--8092, 2020.

\bibitem[Sajjadi et~al.(2018)Sajjadi, Bachem, Lucic, Bousquet, and
  Gelly]{sajjadi2018}
M.~S.~M. Sajjadi, O.~Bachem, M.~Lucic, O.~Bousquet, and S.~Gelly.
\newblock Assessing generative models via precision and recall.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, \emph{Advances in Neural Information Processing
  Systems}, volume~31. Curran Associates, Inc., 2018.

\bibitem[Seitzer(2020)]{seitzer2020}
M.~Seitzer.
\newblock {pytorch-fid: FID Score for PyTorch}.
\newblock \url{https://github.com/mseitzer/pytorch-fid}, August 2020.
\newblock Version 0.1.1.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and
  Ganguli]{sohldickenstein2015deep}
J.~Sohl-Dickstein, E.~Weiss, N.~Maheswaranathan, and S.~Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In F.~Bach and D.~Blei, editors, \emph{Proceedings of the 32nd
  International Conference on Machine Learning}, volume~37, pages 2256--2265,
  2015.

\bibitem[Song and Ermon(2019)]{yang2019}
Y.~Song and S.~Ermon.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32. Curran Associates, Inc., 2019.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2019/file/3001ef257407d5a371a96dcd947c7d93-Paper.pdf}.

\bibitem[Steed and Caliskan(2021)]{steed2021image}
R.~Steed and A.~Caliskan.
\newblock Image representations learned with unsupervised pre-training contain
  human-like biases.
\newblock In \emph{Proceedings of the 2021 ACM Conference on Fairness,
  Accountability, and Transparency}, pages 701--713, 2021.

\bibitem[Tolstikhin et~al.(2018)Tolstikhin, Bousquet, Gelly, and
  Schoelkopf]{tolstikhin2018wasserstein}
I.~Tolstikhin, O.~Bousquet, S.~Gelly, and B.~Schoelkopf.
\newblock Wasserstein auto-encoders.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=HkL7n1-0b}.

\bibitem[{Tomczak} and {Welling}(2016)]{tomczak2016}
J.~M. {Tomczak} and M.~{Welling}.
\newblock {Improving Variational Auto-Encoders using Householder Flow}.
\newblock \emph{arXiv:1611.09630}, 2016.

\bibitem[Vahdat and Kautz(2020)]{vahdat2020}
A.~Vahdat and J.~Kautz.
\newblock {NVAE: A Deep Hierarchical Variational Autoencoder}.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~33, pages 19667--19679, 2020.

\bibitem[Westerlund(2019)]{westerlund2019emergence}
M.~Westerlund.
\newblock The emergence of deepfake technology: A review.
\newblock \emph{Technology Innovation Management Review}, 9\penalty0 (11),
  2019.

\bibitem[Xiao et~al.(2018)Xiao, Bahri, Sohl-Dickstein, Schoenholz, and
  Pennington]{xiao2018}
L.~Xiao, Y.~Bahri, J.~Sohl-Dickstein, S.~Schoenholz, and J.~Pennington.
\newblock Dynamical isometry and a mean field theory of {CNN}s: How to train
  10,000-layer vanilla convolutional neural networks.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning}, volume~80, pages 5393--5402, 2018.

\end{thebibliography}
