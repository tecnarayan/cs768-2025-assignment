@article{zhao2020learning,
author = {Zhao, Zhibing and Xia, Lirong},
journal = {arXiv preprint arXiv:2006.03869},
title = {{Learning Mixtures of Plackett-Luce Models with Features from Top-{\$} l {\$} Orders}},
year = {2020}
}
@inproceedings{zhao2019learning,
author = {Zhao, Zhibing and Xia, Lirong},
booktitle = {Advances in Neural Information Processing Systems},
pages = {10143--10153},
title = {{Learning Mixtures of Plackett-Luce Models from Structured Partial Orders}},
year = {2019}
}
@inproceedings{Qin2017,
abstract = {The Nonlinear autoregressive exogenous (NARX) model, which predicts the current value of a time series based upon its previous values as well as the current and past values of multiple driving (exogenous) series, has been studied for decades. Despite the fact that various NARX models have been developed, few of them can capture the long-term temporal dependencies appropriately and select the relevant driving series to make predictions. In this paper, we propose a dual-stage attention-based recurrent neural network (DA-RNN) to address these two issues. In the first stage, we introduce an input attention mechanism to adaptively extract relevant driving series (a.k.a., input features) at each time step by referring to the previous encoder hidden state. In the second stage, we use a temporal attention mechanism to select relevant encoder hidden states across all time steps. With this dual-stage attention scheme, our model can not only make predictions effectively, but can also be easily interpreted. Thorough empirical studies based upon the SML 2010 dataset and the NASDAQ 100 Stock dataset demonstrate that the DA-RNN can outperform state-of-the-art methods for time series prediction.},
author = {Qin, Yao and Song, Dongjin and Cheng, Haifeng and Cheng, Wei and Jiang, Guofei and Cottrell, Garrison W.},
booktitle = {IJCAI International Joint Conference on Artificial Intelligence},
isbn = {9780999241103},
issn = {10450823},
title = {{A dual-stage attention-based recurrent neural network for time series prediction}},
year = {2017}
}
@inproceedings{Bahdanau2015,
abstract = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder–decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder–decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},
archivePrefix = {arXiv},
arxivId = {1409.0473},
author = {Bahdanau, Dzmitry and Cho, Kyung Hyun and Bengio, Yoshua},
booktitle = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
eprint = {1409.0473},
title = {{Neural machine translation by jointly learning to align and translate}},
year = {2015}
}
@article{busa2019optimal,
author = {Busa-Fekete, R{\'{o}}bert and Fotakis, Dimitris and Sz{\"{o}}r{\'{e}}nyi, Bal{\'{a}}zs and Zampetakis, Manolis},
journal = {arXiv preprint arXiv:1906.01009},
title = {{Optimal Learning of Mallows Block Model}},
year = {2019}
}
@inproceedings{Mathieu2020,
abstract = {A top-list is a possibly incomplete ranking of elements: only a subset of the elements are ranked, with all unranked elements tied for last. Top-list aggregation, a generalization of the well-known rank aggregation problem, takes as input a collection of top-lists and aggregates them into a single complete ranking, aiming to minimize the number of upsets (pairs ranked in opposite order in the input and in the output). In this paper, we give simple approximation algorithms for top-list aggregation. • We generalize the footrule algorithm for rank aggregation (which minimizes Spearman's footrule distance), yielding a simple 2-approximation algorithm for top-list aggregation. • Ailon's RepeatChoice algorithm for bucket-orders aggregation yields a 2-approximation algorithm for top-list aggregation. Using inspiration from approval voting, we define the score of an element as the frequency with which it is ranked, i.e. appears in an input top-list. We reinterpret RepeatChoice for top-list aggregation as a randomized algorithm using variables whose expectations correspond to score and to the average rank of an element given that it is ranked. • Using average ranks, we generalize and analyze Borda's algorithm for rank aggregation. We observe that the natural generalization is not a constant approximation. • We design a simple 2-phase variant of the Generalized Borda's algorithm, roughly sorting by scores and breaking ties by average ranks, yielding another simple constant-approximation algorithm for top-list aggregation. • We then design another 2-phase variant in which in order to break ties we use, as a black box, the Mathieu-Schudy PTAS for rank aggregation, yielding a PTAS for top-list aggregation. This solves an open problem posed by Ailon. • Finally, in the special case in which all input lists have length at most k, we design another simple 2-phase algorithm based on sorting by scores, and prove that it is an EPTAS - the complexity is O(n log n) when k = o(log n).},
author = {Mathieu, Claire and Mauras, Simon},
booktitle = {Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms},
doi = {10.1137/1.9781611975994.171},
isbn = {9781611975994},
title = {{How to aggregate Top-lists: Approximation algorithms via scores and average ranks}},
year = {2020}
}
@inproceedings{Snoek2012,
abstract = {The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a "black art" requiring expert experience, rules of thumb, or sometimes bruteforce search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.},
archivePrefix = {arXiv},
arxivId = {1206.2944},
author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P.},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1206.2944},
isbn = {9781627480031},
issn = {10495258},
title = {{Practical Bayesian optimization of machine learning algorithms}},
year = {2012}
}
@article{Moraglio2013,
abstract = {Geometric differential evolution (GDE) is a recently introduced formal generalization of traditional differential evolution (DE) that can be used to derive specific differential evolution algorithms for both continuous and combinatorial spaces retaining the same geometric interpretation of the dynamics of the DE search across representations. In this article, we first review the theory behind the GDE algorithm, then, we use this framework to formally derive specific GDE for search spaces associated with binary strings, permutations, vectors of permutations and genetic programs. The resulting algorithms are representation-specific differential evolution algorithms searching the target spaces by acting directly on their underlying representations.We present experimental results for each of the new algorithms on a number of well-known problems comprising NK-landscapes, TSP, and Sudoku, for binary strings, permutations, and vectors of permutations.We also present results for the regression, artificial ant, parity, and multiplexer problems within the genetic programming domain. Experiments show that overall the new DE algorithms are competitive with well-tuned standard search algorithms. {\textcopyright} 2013 by the Massachusetts Institute of Technology.},
author = {Moraglio, A. and Togelius, J. and Silva, S.},
doi = {10.1162/EVCO_a_00099},
issn = {10636560},
journal = {Evolutionary Computation},
keywords = {Combinatorial spaces,Differential evolution,Genetic programming,Principled design of search operators,Representations,Theory},
pmid = {23270388},
title = {{Geometric differential evolution for combinatorial and programs spaces}},
year = {2013}
}
@inproceedings{Brinker2007,
abstract = {We present a case-based approach to multilabel ranking, a recent extension of the well-known problem of multilabel classification. Roughly speaking, a multilabel ranking refines a multilabel classification in the sense that, while the latter only splits a predefined label set into relevant and irrelevant labels, the former furthermore puts the labels within both parts of this bipartition in a total order. We introduce a conceptually novel framework, essentially viewing multilabel ranking as a special case of aggregating rankings which are supplemented with an additional virtual label and in which ties are permitted. Even though this framework is amenable to a variety of aggregation procedures, we focus on a particular technique which is computationally efficient and prove that it computes optimal aggregations with respect to the (generalized) Spearman rank correlation as an underlying loss (utility) function. Moreover, we propose an elegant generalization of this loss function and empirically show that it increases accuracy for the subtask of multilabel classification.},
author = {Brinker, Klaus and H{\"{u}}llermeier, Eyke},
booktitle = {IJCAI International Joint Conference on Artificial Intelligence},
doi = {10.1007/11871842_53},
issn = {10450823},
title = {{Case-based multilabel ranking}},
year = {2007}
}
@inproceedings{Oh2015,
abstract = {In personalized recommendation systems, it is important to predict preferences of a user on items that have not been seen by that user yet. Similarly, in revenue management, it is important to predict outcomes of comparisons among those items that have never been compared so far. The MultiNomial Logit model, a popular discrete choice model, captures the structure of the hidden preferences with a low-rank matrix. In order to predict the preferences, we want to learn the underlying model from noisy observations of the low-rank matrix, collected as revealed preferences in various forms of ordinal data. A natural approach to learn such a model is to solve a convex relaxation of nuclear norm minimization. We present the convex relaxation approach in two contexts of interest: collaborative ranking and bundled choice modeling. In both cases, we show that the convex relaxation is minimax optimal. We prove an upper bound on the resulting error with finite samples, and provide a matching information-theoretic lower bound.},
archivePrefix = {arXiv},
arxivId = {1506.07947},
author = {Oh, Sewoong and Thekumparampil, Kiran K. and Xu, Jiaming},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1506.07947},
issn = {10495258},
keywords = {low rank matrix,multinomial logit,nuclear norm,pl,plackett luce},
mendeley-tags = {nuclear norm,pl,plackett luce,multinomial logit,low rank matrix},
title = {{Collaboratively learning preferences from ordinal data}},
year = {2015}
}
@inproceedings{Malalanirainy2019,
abstract = {The Convex Search Algorithm (CSA) is a generalization across representations of Evolutionary Algorithms (EAs) with crossover and no mutation. The Standard Evolutionary Search Algorithm (SESA) is a more accurate generalization of EAs with crossover and no mutation, using a standard two-parents crossover. This work extends the runtime analysis of the CSA on quasi-concave landscapes [4] to the SESA. We instantiate the analysis to binary strings and integer vectors endowed with the Hamming distance and the Manhattan distance. We find that the SESA requires a larger population size to converge to a global optimum; resulting in a larger runtime upper bound than the CSA. Empirical studies on LeadingOnes confirmed the existence of a smallest population size above which both algorithms are guaranteed to find the global optimum. Below this threshold, the SESA is less successful than the CSA.},
author = {Malalanirainy, Tina and Moraglio, Alberto},
booktitle = {GECCO 2019 Companion - Proceedings of the 2019 Genetic and Evolutionary Computation Conference Companion},
doi = {10.1145/3319619.3321959},
isbn = {9781450367486},
keywords = {Crossover,Population size lower bound,Runtime analysis},
title = {{Runtime analysis of abstract evolutionary search with standard crossover}},
year = {2019}
}
@article{cuturi2019differentiable,
author = {Cuturi, Marco and Teboul, Olivier and Vert, Jean-Philippe},
journal = {Advances in Neural Information Processing Systems (NIPS)},
title = {{Differentiable Sorting using Optimal Transport: The Sinkhorn CDF and Quantile Operator}},
year = {2019}
}
@inproceedings{singh2019policy,
abstract = {Conventional Learning-to-Rank (LTR) methods optimize the utility of the rankings to the users, but they are oblivious to their impact on the ranked items. However, there has been a growing understanding that the latter is important to consider for a wide range of ranking applications (e.g. online marketplaces, job placement, admissions). To address this need, we propose a general LTR framework that can optimize a wide range of utility metrics (e.g. NDCG) while satisfying fairness of exposure constraints with respect to the items. This framework expands the class of learnable ranking functions to stochastic ranking policies, which provides a language for rigorously expressing fairness specifications. Furthermore, we provide a new LTR algorithm called FAIR-PG-RANK for directly searching the space of fair ranking policies via a policy-gradient approach. Beyond the theoretical evidence in deriving the framework and the algorithm, we provide empirical results on simulated and real-world datasets verifying the effectiveness of the approach in individual and group-fairness settings.},
author = {Singh, Ashudeep and Joachims, Thorsten},
booktitle = {Advances in Neural Information Processing Systems},
keywords = {learning to rank},
mendeley-tags = {learning to rank},
pages = {5427--5437},
title = {{Policy learning for fairness in ranking}},
year = {2019}
}
@inproceedings{Snoek2014,
abstract = {Bayesian optimization has proven to be a highly effective methodology for the global optimization of unknown, expensive and multimodal functions. The ability to accurately model distributions over functions is critical to the effectiveness of Bayesian optimization. Although Gaussian processes provide a flexible prior over functions, there are various classes of functions that remain difficult to model. One of the most frequently occurring of these is the class of non-stationary functions. The optimization of the hyperparameters of machine learning algorithms is a problem domain in which parameters are often manually transformed a priori, for example by optimizing in "log-space," to mitigate the effects of spatially-varying length scale. We develop a methodology for automatically learning a wide family of bijective transformations or warpings of the input space using the Beta cumulative distribution function. We further extend the warping framework to multi-task Bayesian optimization so that multiple tasks can be warped into a jointly stationary space. On a set of challenging benchmark optimization tasks, we observe that the inclusion of warping greatly improves on the state-of-the-art, producing better results faster and more reliably.},
archivePrefix = {arXiv},
arxivId = {1402.0929},
author = {Snoek, Jasper and Swersky, Kevin and Zemel, Richard and Adams, Ryan P.},
booktitle = {31st International Conference on Machine Learning, ICML 2014},
eprint = {1402.0929},
isbn = {9781634393973},
issn = {1533-7928},
title = {{Input warping for Bayesian optimization of non-stationary functions}},
year = {2014}
}
@article{Oliveto2007,
abstract = {Computational time complexity analyzes of evolutionary algorithms (EAs) have been performed since the mid-nineties. The first results were related to very simple algorithms, such as the (1+1)-EA, on toy problems. These efforts produced a deeper understanding of how EAs perform on different kinds of fitness landscapes and general mathematical tools that may be extended to the analysis of more complicated EAs on more realistic problems. In fact, in recent years, it has been possible to analyze the (1+1)-EA on combinatorial optimization problems with practical applications and more realistic population-based EAs on structured toy problems. This paper presents a survey of the results obtained in the last decade along these two research lines. The most common mathematical techniques are introduced, the basic ideas behind them are discussed and their elective applications are highlighted. Solred problems that were still open are enumerated as are those still awaiting for a solution. New questions and problems arisen in the meantime are also considered. {\textcopyright} 2007 Institute of Automation, Chinese Academy of Sciences.},
author = {Oliveto, Pietro S. and He, Jun and Yao, Xin},
doi = {10.1007/s11633-007-0281-3},
issn = {14768186},
journal = {International Journal of Automation and Computing},
keywords = {Combinatorial optimization,Computational complexity,Evolutionary algorithms,Evolutionary computation theory},
title = {{Time complexity of evolutionary algorithms for combinatorial optimization: A decade of results}},
year = {2007}
}
@article{PerLopStu2015si,
author = {{P{\'{e}}rez C{\'{a}}ceres}, Leslie and L{\'{o}}pez-Ib{\'{a}}{\~{n}}ez, Manuel and St{\"{u}}tzle, Thomas},
doi = {10.1007/s11721-015-0106-x},
journal = {Swarm Intelligence},
number = {2-3},
pages = {103--124},
title = {{Ant colony optimization on a limited budget of evaluations}},
volume = {9},
year = {2015}
}
@inproceedings{pmlr-v98-achab19a,
abstract = {Whereas most dimensionality reduction techniques ($\backslash$textit{\{}e.g.{\}} PCA, ICA, NMF) for multivariate data essentially rely on linear algebra to a certain extent, summarizing ranking data, viewed as realizations of a random permutation {\$}\Sigma{\$} on a set of items indexed by {\$}i\backslashin {\{}1,{\ldots},;{\{}n{\}}{\}}{\$}, is a great statistical challenge, due to the absence of vector space structure for the set of permutations {\$}\backslashmathfrak{\{}S{\}}{\_}n{\$}. It is the goal of this article to develop an original framework for possibly reducing the number of parameters required to describe the distribution of a statistical population composed of rankings/permutations, on the premise that the collection of items under study can be partitioned into subsets/buckets, such that, with high probability, items in a certain bucket are either all ranked higher or else all ranked lower than items in another bucket. In this context, {\$}\Sigma{\$}'s distribution can be hopefully represented in a sparse manner by a $\backslash$textit{\{}bucket distribution{\}}, $\backslash$textit{\{}i.e.{\}} a bucket ordering plus the ranking distributions within each bucket. More precisely, we introduce a dedicated distortion measure, based on a mass transportation metric, in order to quantify the accuracy of such representations. The performance of buckets minimizing an empirical version of the distortion is investigated through a rate bound analysis. Complexity penalization techniques are also considered to select the shape of a bucket order with minimum expected distortion. Beyond theoretical concepts and results, numerical experiments on real ranking data are displayed in order to provide empirical evidence of the relevance of the approach promoted.},
address = {Chicago, Illinois},
author = {Achab, Mastane and Korba, Anna and Cl{\'{e}}men{\c{c}}on, Stephan},
booktitle = {Proceedings of the 30th International Conference on Algorithmic Learning Theory},
editor = {Garivier, Aur{\'{e}}lien and Kale, Satyen},
pages = {64--93},
publisher = {PMLR},
series = {Proceedings of Machine Learning Research},
title = {{Dimensionality Reduction and (Bucket) Ranking: a Mass Transportation Approach}},
url = {http://proceedings.mlr.press/v98/achab19a.html},
volume = {98},
year = {2019}
}
@inproceedings{ZaeStoFriFisNauBar2014,
abstract = {Real-world optimization problems may require time consuming and expensive measurements or simulations. Recently, the application of surrogate model-based approaches was extended from continuous to combinatorial spaces. This extension is based on the utilization of suitable distance measures such as Hamming or Swap Distance. In this work, such an extension is implemented for Kriging (Gaussian Process) models. Kriging provides a measure of uncertainty when determining predictions. This can be harnessed to calculate the Expected Improvement (EI) of a candidate solution. In continuous optimization, EI is used in the Efficient Global Optimization (EGO) approach to balance exploitation and exploration for expensive optimization problems. Employing the extended Kriging model, we show for the first time that EGO can successfully be applied to combinatorial optimization problems. We describe necessary adaptations and arising issues as well as experimental results on several test problems. All surrogate models are optimized with a Genetic Algorithm (GA). To yield a comprehensive comparison, EGO and Kriging are compared to an earlier suggested Radial Basis Function Network, a linear modeling approach, as well as model-free optimization with random search and GA. EGO clearly outperforms the competing approaches on most of the tested problem instances. {\textcopyright} 2014 is held by the owner/author(s).},
author = {Zaefferer, Martin and Stork, J{\"{o}}rg and Friese, Martina and Fischbach, Andreas and Naujoks, Boris and Bartz-Beielstein, Thomas},
booktitle = {GECCO 2014 - Proceedings of the 2014 Genetic and Evolutionary Computation Conference},
doi = {10.1145/2576768.2598282},
isbn = {9781450326629},
keywords = {Distance measure,Efficient global optimization,Gaussian processes,Genetic algorithm,Kriging,Surrogate model-based optimization},
title = {{Efficient global optimization for combinatorial problems}},
year = {2014}
}
@inproceedings{Korba2017,
abstract = {Originally formulated in Social Choice theory, Ranking Aggregation, also referred to as Consensus Ranking, has motivated the development of numerous statistical models since the middle of the 20th century. Recently, the analysis of ranking/preference data has been the subject of a renewed interest in machine-learning, boosted by modern applications such as meta-search engines, giving rise to the design of various scalable algorithmic approaches for approximately computing ranking medians, viewed as solutions of a discrete (generally NP-hard) minimization problem. This paper develops a statistical learning theory for ranking aggregation in a general probabilistic setting (avoiding any rigid ranking model assumptions), assessing the generalization ability of empirical ranking medians. Universal rate bounds are established and the situations where convergence occurs at an exponential rate are fully characterized. Minimax lower bounds are also proved, showing that the rate bounds we obtain are optimal.},
author = {Korba, Anna and Cl{\'{e}}men{\c{c}}on, Stephan and Sibony, Eric},
booktitle = {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics, AISTATS 2017},
title = {{A learning theory of ranking aggregation}},
year = {2017}
}
@inproceedings{Clemencon2015,
abstract = {Decision tree induction algorithms, possibly combined with a consensus technique, have been recently successfully extended to multipartite ranking. It is the goal of this paper to address certain aspects of their weakness, instability and lack of smoothness namely, by proposing dedicated ensemble learning strategies. A shown by numerical experiments, bootstrap aggregation combined with a certain amount of feature randomization dramatically improve performance of such ranking methods, in terms of accuracy and robustness both at the same time.},
author = {Cl{\'{e}}men{\c{c}}on, St{\'{e}}phan and Robbiano, Sylvain},
booktitle = {23rd European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2015 - Proceedings},
isbn = {9782875870148},
title = {{An ensemble learning technique for multipartite ranking}},
year = {2015}
}
@inproceedings{Clemencon2018,
abstract = {In the present era of personalized customer services and rec-ommender systems, predicting the preferences of an individual over a set of items indexed by [n] = {\{}1, ⋯, n{\}}, n ≥ 1, based on its characteristics, modelled as a r.v. X say, is an ubiquitous issue. Though easy to state, this predictive problem referered to as ranking median regression (RMR in short) is very difficult to solve in practice. The major challenge lies in the fact that, here, the (discrete) output space is the symmetric group Sn, composed of all permutations of [n], of explosive cardinality n!, and which is not a subset of a vector space. It is thus far from straightforward to build (non parametric) predictive rules taking their values in Sn, except by means of ranking aggregation techniques implemented at a local level, as proposed in [1] or [2]. However, such local learning techniques exhibit high instability and it is the main goal of this paper to investigate to which extent Kemeny ranking aggregation of randomized RMR rules may remedy this drawback. Beyond a theoretical analysis establishing its validity, the relevance of this novel ensemble learning technique is supported by experimental results.},
author = {Cl{\'{e}}men{\c{c}}on, Stephan and Korba, Anna},
booktitle = {ESANN 2018 - Proceedings, European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning},
isbn = {9782875870476},
title = {{On aggregation in ranking median regression}},
year = {2018}
}
@inproceedings{Sibony2014,
abstract = {Data representing preferences of users are at the core of many Big Data modern applications, such as recommender systems or search engines. While most of the introduced machine learning approaches are designed to handle preference data under the form of cardinal scores, such as ratings given by the users to the items, many situations require to deal with ordinal preferences, coming from implicit feedback data for instance. Methods relying on the analysis of ranking data are best suited for these situations, but they face a great computational challenge insofar as the number of ways to express ordinal preferences on a catalog of n items explodes with n. It is the main purpose of this paper to promote a new representation of preference data when they come under the form of incomplete rankings, that is to say ordinal preferences on small subsets of items. The representation exploits the 'multiscale' structure of incomplete rankings and though it relies on recent results in algebraic topology, it is used and interpreted similar to classic wavelet multiresolution analysis on a Euclidean space. We apply it to the problem of incomplete rankings prediction and show at the same time that it is statistically consistent and that it can be computed at a reasonable cost given the complexity of the original data. It is illustrated by very encouraging empirical work based on real datasets.},
author = {Sibony, Eric and Clemencon, Stephan and Jakubowicz, Jeremie},
booktitle = {Proceedings - 2014 IEEE International Conference on Big Data, IEEE Big Data 2014},
doi = {10.1109/BigData.2014.7004361},
isbn = {9781479956654},
keywords = {incomplete rankings,multiresolution analysis,preference data},
title = {{Multiresolution analysis of incomplete rankings with applications to prediction}},
year = {2014}
}
@inproceedings{Clemencon2008,
abstract = {We consider the extension of standard decision tree methods to the bipartite ranking problem. In ranking, the goal pursued is global: define an order on the whole input space in order to have positive instances on top with maximum probability. The most natural way of ordering all instances consists in projecting the input data x onto the real line using a real-valued scoring function s and the accuracy of the ordering induced by a candidate s is classically measured in terms of the AUC. In the paper, we discuss the design of tree-structured scoring functions obtained by maximizing the AUC criterion. In particular, the connection with recursive piecewise linear approximation of the optimal ROC curve both in the L 1-sense and in the L ∈∞∈-sense is discussed. {\textcopyright} 2008 Springer-Verlag Berlin Heidelberg.},
author = {Cl{\'{e}}men{\c{c}}on, St{\'{e}}phan and Vayatis, Nicolas},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-540-87987-9_7},
issn = {03029743},
title = {{Approximation of the optimal ROC curve and a tree-based ranking algorithm}},
year = {2008}
}
@inproceedings{Laforgue2019,
abstract = {Tournament procedures, recently introduced in Lugosi {\&} Mendelson (2016), offer an appealing alternative, from a theoretical perspective at least, to the principle of Empirical Risk Minimization in machine learning. Statistical learning by Median-of-Means (MoM) basically consists in segmenting the training data into blocks of equal size and comparing the statistical performance of every pair of candidate decision rules on each data block: that with highest performance on the majority of the blocks is declared as the winner. In the context of nonparametric regression, functions having won all their duels have been shown to outperform empirical risk minimizers w.r.t. the mean squared error under minimal assumptions, while exhibiting robustness properties. It is the purpose of this paper to extend this approach, in order to address other learning problems in particular, for which the performance criterion takes the form of an expectation over pairs of observations rather than over one single observation, as may be the case in pairwise ranking, clustering or metric learning. Precisely, it is proved here that the bounds achieved by MoM are essentially conserved when the blocks are built by means of independent sampling without replacement schemes instead of a simple segmentation. These results are next extended to situations where the risk is related to a pairwise loss function and its empirical counterpart is of the form of a U-statistic. Beyond theoretical results guaranteeing the performance of the learning/estimation methods proposed, some numerical experiments provide empirical evidence of their relevance in practice.},
author = {Laforgue, Pierre and Cl{\'{e}}men{\c{c}}on, Stephan and Bertail, Patrice},
booktitle = {36th International Conference on Machine Learning, ICML 2019},
isbn = {9781510886988},
title = {{On medians of (Randomized) pairwise means}},
year = {2019}
}
@inproceedings{Clemencon2010,
abstract = {The goal of this paper is threefold. It first describes a novel way of measuring disagreement between rankings of a finite set of n≥1 elements, that can be viewed as a (mass transportation) Kantorovich metric, once the collection rankings of is embedded in the set of n×n doubly-stochastic matrices. It also shows that such an embedding makes it possible to define a natural notion of median, that can be interpreted in a probabilistic fashion. In addition, from a computational perspective, the convexification induced by this approach makes median computation more tractable, in contrast to the standard metric-based method that generally yields NP-hard optimization problems. As an illustration, this novel methodology is applied to the issue of ranking aggregation, and is shown to compete with state of the art techniques. {\textcopyright} 2010 Springer-Verlag Berlin Heidelberg.},
author = {Cl{\'{e}}men{\c{c}}on, St{\'{e}}phan and Jakubowicz, J{\'{e}}r{\'{e}}mie},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-15880-3_22},
isbn = {364215879X},
issn = {03029743},
title = {{Kantorovich distances between rankings with applications to rank aggregation}},
year = {2010}
}
@inproceedings{Clemencon2009,
abstract = {In this paper, we propose an adaptive algorithm for bipartite ranking and prove its statistical performance in a stronger sense than the AUC criterion. Our procedure builds on and significantly improves the RankOver algorithm proposed in [1]. The algorithm outputs a piecewise constant scoring rule which is obtained by overlaying a finite collection of classifiers. Here, each of these classifiers is the empirical solution of a specific minimum-volume set (MV-set) estimation problem. The major novelty arises from the fact that the levels of the MV-sets to recover are chosen adaptively from the data to adjust to the variability of the target curve. The ROC curve of the estimated scoring rule may be interpreted as an adaptive spline approximant of the optimal ROC curve. Error bounds for the estimate of the optimal ROC curve in terms of the L∞-distance are also provided. {\textcopyright} 2009 Springer.},
author = {Cl{\'{e}}men{\c{c}}on, St{\'{e}}phan and Vayatis, Nicolas},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-04414-4_20},
isbn = {3642044131},
issn = {03029743},
title = {{Adaptive estimation of the optimal ROC curve and a bipartite ranking algorithm}},
year = {2009}
}
@misc{irurozki2019online,
archivePrefix = {arXiv},
arxivId = {stat.ML/1910.08795},
author = {Irurozki, Ekhine and Lobo, Jesus and Perez, Aritz and Ser, Javier Del},
eprint = {1910.08795},
primaryClass = {stat.ML},
title = {{Online Ranking with Concept Drifts in Streaming Data}},
year = {2019}
}
@article{Toledo2015,
abstract = {Recommender systems help users to find information that best fits their preferences and needs in an overloaded search space. Most recommender systems research has been focused on the accuracy improvement of recommendation algorithms. Despite this, recently new trends in recommender systems have become important research topics such as, cold start, group recommendations, context-aware recommendations, and natural noise. The concept of natural noise is related to the study and management of inconsistencies in datasets of users' preferences used in recommender systems. In this paper a novel approach is proposed to detect and correct those inconsistent ratings that might bias recommendations, whose main advantage regarding previous proposals is that it uses only the current ratings in the dataset without needing any additional information. To do so, this proposal detects noisy ratings by characterizing items and users by their profiles, and then a strategy to fix these noisy ratings is carried out to increase the accuracy of such recommender systems. Finally a case study is developed to show the advantage of this proposal to deal with natural noise regarding previous methodologies.},
author = {Toledo, Raciel Yera and Mota, Yail{\'{e}} Caballero and Mart{\'{i}}nez, Luis},
doi = {10.1016/j.knosys.2014.12.011},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Collaborative filtering,Matrix factorization,Natural noise,Nearest neighbor-based recommendation,Recommender systems},
title = {{Correcting noisy ratings in collaborative recommender systems}},
year = {2015}
}
@article{Butler2017,
author = {Butler, James and Smalley, Christopher},
doi = {10.1016/b978-0-7506-7531-4.x5000-3},
issn = {02738139},
journal = {Pharmaceutical Engineering},
title = {{An introduction to predictive maintenance}},
year = {2017}
}
@inproceedings{Kurakin2019,
abstract = {Adversarial examples are malicious inputs designed to fool machine learning models. They often transfer from one model to another, allowing attackers to mount black box attacks without knowledge of the target model's parameters. Adversarial training is the process of explicitly training a model on adversarial examples, in order to make it more robust to attack or to reduce its test error on clean inputs. So far, adversarial training has primarily been applied to small problems. In this research, we apply adversarial training to ImageNet (Russakovsky et al., 2014). Our contributions include: (1) recommendations for how to succes-fully scale adversarial training to large models and datasets, (2) the observation that adversarial training confers robustness to single-step attack methods, (3) the finding that multi-step attack methods are somewhat less transferable than single-step attack methods, so single-step attacks are the best for mounting black-box attacks, and (4) resolution of a “label leaking” effect that causes adversarially trained models to perform better on adversarial examples than on clean examples, because the adversarial example construction process uses the true label and the model can learn to exploit regularities in the construction process.},
archivePrefix = {arXiv},
arxivId = {1611.01236},
author = {Kurakin, Alexey and Goodfellow, Ian J. and Bengio, Samy},
booktitle = {5th International Conference on Learning Representations, ICLR 2017 - Conference Track Proceedings},
eprint = {1611.01236},
title = {{Adversarial machine learning at scale}},
year = {2019}
}
@article{Shah2017,
abstract = {There are various parametric models for analyzing pairwise comparison data, including the Bradley-Terry-Luce (BTL) and Thurstone models, but their reliance on strong parametric assumptions is limiting. In this paper, we study a flexible model for pairwise comparisons, under which the probabilities of outcomes are required only to satisfy a natural form of stochastic transitivity. This class includes parametric models, including the BTL and Thurstone models as special cases, but is considerably more general. We provide various examples of models in this broader stochastically transitive class for which classical parametric models provide poor fits. Despite this greater flexibility, we show that the matrix of probabilities can be estimated at the same rate as in standard parametric models up to logarithmic terms. On the other hand, unlike in the BTL and Thurstone models, computing the minimax-optimal estimator in the stochastically transitive model is non-trivial, and we explore various computationally tractable alternatives. We show that a simple singular value thresholding algorithm is statistically consistent but does not achieve the minimax rate. We then propose and study algorithms that achieve the minimax rate over interesting sub-classes of the full stochastically transitive class. We complement our theoretical results with thorough numerical simulations.},
archivePrefix = {arXiv},
arxivId = {1510.05610},
author = {Shah, Nihar B. and Balakrishnan, Sivaraman and Guntuboyina, Adityanand and Wainwright, Martin J.},
doi = {10.1109/TIT.2016.2634418},
eprint = {1510.05610},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
keywords = {Minimax techniques,pairwise comparisons,ranking,singular value thresholding,statistics},
title = {{Stochastically Transitive Models for Pairwise Comparisons: Statistical and Computational Issues}},
year = {2017}
}
@incollection{Garcia-Martinez2018,
abstract = {This chapter presents the fundamental concepts of genetic algorithms (GAs) that have become an essential tool for solving optimization problems in a wide variety of fields. The first part of this chapter is devoted to the revision of the basic components for the design of GAs. We illustrate this construction process through its application for solving three widely known optimization problems as knapsack problem, traveling salesman problem, and real-parameter optimization. The second part of the chapter focuses on the study of diversification techniques that represent a fundamental issue in order to achieve an effective search in GAs. In fact, analyzing its diversity has led to the presentation of numerous GA models in the literature. Similarly, the hybridization with other metaheuristics and optimization methods has become a very fruitful research area. The third part of the chapter is dedicated to the study of these hybrid methods. In closing, in the fourth part, we outline the wide spectrum of application areas that shows the level of maturity and the wide research community of the GA field.},
author = {Garc{\'{i}}a-Mart{\'{i}}nez, Carlos and Rodriguez, Francisco J. and Lozano, Manuel},
booktitle = {Handbook of Heuristics},
doi = {10.1007/978-3-319-07124-4_28},
isbn = {9783319071244},
issn = {0454-1405},
keywords = {GA design,Genetic Algorithms,basic components,diversity generation,diversity maintenance,hybrid genetic algorithms,population diversity},
title = {{Genetic algorithms}},
year = {2018}
}
@inproceedings{ElMesaoudi-Paul2018a,
abstract = {We propose a new statistical model for ranking data, i.e., a new family of probability distributions on permutations. Our model is inspired by the idea of a data-generating process in the form of a noisy sorting procedure, in which deterministic comparisons between pairs of items are replaced by Bernoulli trials. The probability of producing a certain ranking as a result then essentially depends on the Bernoulli parameters, which can be interpreted as pairwise preferences. We show that our model can be written in closed form if insertion sort is used as sorting algorithm and can be characterized recursively if quick sort is used, and propose a maximum likelihood approach for parameter estimation. We also introduce a generalization of the model, in which the constraints on pairwise preferences are relaxed, and for which maximum likelihood estimation can be carried out based on a variation of the generalized iterative scaling algorithm. Experimentally, we show that the models perform very well in terms of goodness of fit, compared to existing models for ranking data.},
author = {{El Mesaoudi-Paul}, Adil and Hiillermeier, Eyke and Busa-Fekete, Robert},
booktitle = {35th International Conference on Machine Learning, ICML 2018},
isbn = {9781510867963},
title = {{Ranking distributions based on noisy sorting}},
year = {2018}
}
@incollection{Bhunia2019,
abstract = {After studying this chapter, the readers are able to learn:The limitations of the simplex method in deriving integer solutions to LPPsGomory's all-integer and mixed-integer programming techniquesThe branch and bound method to solve integer programming problems.},
author = {Bhunia, Asoke Kumar and Sahoo, Laxminarayan and Shaikh, Ali Akbar},
booktitle = {Springer Optimization and Its Applications},
doi = {10.1007/978-981-32-9967-2_8},
issn = {19316836},
title = {{Integer Programming}},
year = {2019}
}
@misc{Vansteenwegen2011,
abstract = {During the last decade, a number of challenging applications in logistics, tourism and other fields were modelled as orienteering problems (OP). In the orienteering problem, a set of vertices is given, each with a score. The goal is to determine a path, limited in length, that visits some vertices and maximises the sum of the collected scores. In this paper, the literature about the orienteering problem and its applications is reviewed. The OP is formally described and many relevant variants are presented. All published exact solution approaches and (meta) heuristics are discussed and compared. Interesting open research questions concerning the OP conclude this paper. {\textcopyright} 2010 Elsevier B.V. All rights reserved.},
author = {Vansteenwegen, Pieter and Souffriau, Wouter and Oudheusden, Dirk Van},
booktitle = {European Journal of Operational Research},
doi = {10.1016/j.ejor.2010.03.045},
issn = {03772217},
keywords = {Combinatorial optimisation,Orienteering problem,Survey},
title = {{The orienteering problem: A survey}},
year = {2011}
}
@book{Larranaga2002,
abstract = {Estimation of Distribution Algorithms: A New Tool for Evolutionary Computation is devoted to a new paradigm for evolutionary computation, named estimation of distribution algorithms (EDAs). This new class of algorithms generalizes genetic algorithms by replacing the crossover and mutation operators with learning and sampling from the probability distribution of the best individuals of the population at each iteration of the algorithm. Working in such a way, the relationships between the variables involved in the problem domain are explicitly and effectively captured and exploited. This text constitutes the first compilation and review of the techniques and applications of this new tool for performing evolutionary computation. Estimation of Distribution Algorithms: A New Tool for Evolutionary Computation is clearly divided into three parts. Part I is dedicated to the foundations of EDAs. In this part, after introducing some probabilistic graphical models - Bayesian and Gaussian networks - a review of existing EDA approaches is presented, as well as some new methods based on more flexible probabilistic graphical models. A mathematical modeling of discrete EDAs is also presented. Part II covers several applications of EDAs in some classical optimization problems: the travelling salesman problem, the job scheduling problem, and the knapsack problem. EDAs are also applied to the optimization of some well-known combinatorial and continuous functions. Part III presents the application of EDAs to solve some problems that arise in the machine learning field: feature subset selection, feature weighting in K-NN classifiers, rule induction, partial abductive inference in Bayesian networks, partitional clustering, and the search for optimal weights in artificial neural networks. Estimation of Distribution Algorithms: A New Tool for Evolutionary Computation is a useful and interesting tool for researchers working in the field of evolutionary computation and for engineers who face real-world optimization problems. This book may also be used by graduate students and researchers in computer science. `... I urge those who are interested in EDAs to study this well-crafted book today.' David E. Goldberg, University of Illinois Champaign-Urbana.},
author = {Larra{\~{n}}aga, P and Lozano, J A},
booktitle = {Estimation of Distribution Algorithms A New Tool for Evolutionary Computation},
isbn = {0792374665},
title = {{Estimation of Distribution Algorithms: A New Tool for Evolutionary Computation}},
year = {2002}
}
@inproceedings{Hernando2011,
abstract = {This work is related to the search of complexity measures for instances of combinatorial optimization problems. Particularly, we have carried out a study about the complexity of random instances of the Traveling Salesman Problem under the 2-exchange neighbor system. We have proposed two descriptors of complexity: the proportion of the size of the basin of attraction of the global optimum over the size of the search space and the proportion of the number of different local optima over the size of the search space. We have analyzed the evolution of these descriptors as the size of the problem grows. After that, and using our complexity measures, we find a phase transition phenomenon in the complexity of the instances. {\textcopyright} 2011 IEEE.},
author = {Hernando, Leticia and Pascual, Jose A. and Mendiburu, Alexander and Lozano, Jose A.},
booktitle = {IEEE SSCI 2011 - Symposium Series on Computational Intelligence - FOCI 2011: 2011 IEEE Symposium on Foundations of Computational Intelligence},
doi = {10.1109/FOCI.2011.5949471},
isbn = {9781424499823},
title = {{A study on the complexity of TSP instances under the 2-exchange neighbor system}},
year = {2011}
}
@article{Fukasawa2006,
abstract = {The best exact algorithms for the Capacitated Vehicle Routing Problem (CVRP) have been based on either branch-and-cut or Lagrangean relaxation/column generation. This paper presents an algorithm that combines both approaches: it works over the intersection of two polytopes, one associated with a traditional Lagrangean relaxation over q-routes, the other defined by bound, degree and capacity constraints. This is equivalent to a linear program with exponentially many variables and constraints that can lead to lower bounds that are superior to those given by previous methods. The resulting branch-and-cut-and-price algorithm can solve to optimality all instances from the literature with up to 135 vertices. This more than doubles the size of the instances that can be consistently solved.},
author = {Fukasawa, Ricardo and Longo, Humberto and Lysgaard, Jens and {De Arag{\~{a}}o}, Marcus Poggi and Reis, Marcelo and Uchoa, Eduardo and Werneck, Renato F.},
doi = {10.1007/s10107-005-0644-x},
issn = {00255610},
journal = {Mathematical Programming},
title = {{Robust branch-and-cut-and-price for the capacitated vehicle routing problem}},
year = {2006}
}
@article{Reinelt1991,
abstract = {This paper contains the description of a traveling salesman problem library (TSPLIB) which is meant to provide researchers with a broad set of test problems from various sources and with various properties. For every problem a short description is given along with known lower and upper bounds. Several references to computational tests on some of the problems are given.},
author = {Reinelt, Gerhard},
doi = {10.1287/ijoc.3.4.376},
issn = {08991499},
journal = {ORSA journal on computing},
title = {{TSPLIB. A traveling salesman problem library}},
year = {1991}
}
@article{Marta2003,
abstract = {This work shows how a preliminary aircraft design can be achieved by means of genetic algorithms (GA). The aircraft major parameters are mapped into a chromosome like string. These include the wing, tail and fuselage geometry, thrust requirements and operating parameters. GA operators are performed on a population of such strings and natural selection is expected to occur. The design performance is obtained by using the aircraft range as the fitness function. Different GA parameters and selection methods – fitness and ranking – are tested and their impact on the algorithm efficiency is analyzed. The constraints implementation is also studied.},
author = {Marta, Andre C.},
journal = {Genetic Algorithms and Genetic Programming at Stanford 2003},
keywords = {genetic algorithms},
title = {{Parametric Study of a Genetic Algorithm using a Aircraft Design Optimization Problem}},
year = {2003}
}
@article{Goodfellow2018,
abstract = {overview},
author = {Goodfellow, Ian and McDaniel, Patrick and Papernot, Nicolas},
doi = {10.1145/3134599},
issn = {00010782},
journal = {Communications of the ACM},
title = {{Making machine learning robust against adversarial inputs}},
year = {2018}
}
@misc{Yokoo2000,
abstract = {When multiple agents are in a shared environment, there usually exist constraints among the possible actions of these agents. A distributed constraint satisfaction problem (distributed CSP) is a problem to find a consistent combination of actions that satisfies these inter-agent constraints. Various application problems in multi-agent systems can be formalized as distributed CSPs. This paper gives an overview of the existing research on distributed CSPs. First, we briefly describe the problem formalization and algorithms of normal, centralized CSPs. Then, we show the problem formalization and several MAS application problems of distributed CSPs. Furthermore, we describe a series of algorithms for solving distributed CSPs, i.e., the asynchronous backtracking, the asynchronous weak-commitment search, the distributed breakout, and distributed consistency algorithms. Finally, we show two extensions of the basic problem formalization of distributed CSPs, i.e., handling multiple local variables, and dealing with over-constrained problems.},
author = {Yokoo, Makoto and Hirayama, Katsutoshi},
booktitle = {Autonomous Agents and Multi-Agent Systems},
doi = {10.1023/A:1010078712316},
issn = {13872532},
keywords = {Constraint satisfaction,Distributed AI,Search},
title = {{Algorithms for Distributed Constraint Satisfaction: A Review}},
year = {2000}
}
@inproceedings{Kondor2010,
abstract = {The quadratic assignment problem (QAP) is a central problem in combinatorial optimization. Several famous computationally hard tasks, such as graph matching, partitioning, and the traveling salesman all reduce to special cases of the QAP. In this paper we propose a new approach to the QAP based on the theory of non-commutative Fourier analysis on the symmetric group. Specifically, we present a branch-and-bound algorithm that performs both the branching and the bounding steps in Fourier space. By exploiting the band-limited nature of the QAP objective function and using FFT techniques, the algorithm runs in O(n3) time per branch-and-bound node. The techniques underlying the algorithm generalize to a range of other combinatorial optimization problems. Copyright {\textcopyright} by SIAM.},
author = {Kondor, Risi},
booktitle = {Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms},
doi = {10.1137/1.9781611973075.82},
isbn = {9780898717013},
title = {{A Fourier space algorithm for solving quadratic assignment problems}},
year = {2010}
}
@misc{Reinelt2014,
abstract = {TSPLIB is a library of sample instances for the TSP (and related problems) from various sources and of various types.},
author = {Reinelt, Gerhard},
booktitle = {Library for sample instances for TSP problems},
title = {{TSPLIB}},
year = {2014}
}
@article{narayanan2006break,
author = {Narayanan, Arvind and Shmatikov, Vitaly},
journal = {arXiv preprint cs/0610105},
title = {{How to break anonymity of the netflix prize dataset}},
year = {2006}
}
@inproceedings{Ghosh2018,
abstract = {Recent successes in reinforcement learning have lead to the development of complex controllers for realworld robots. As these robots are deployed in safety-critical applications and interact with humans, it becomes critical to ensure safety in order to avoid causing harm. A first step in this direction is to test the controllers in simulation. To be able to do this, we need to capture what we mean by safety and then efficiently search the space of all behaviors to see if they are safe. In this paper, we present an active-testing framework based on Bayesian Optimization. We specify safety constraints using logic and exploit structure in the problem in order to test the system for adversarial counter examples that violate the safety specifications. These specifications are defined as complex boolean combinations of smooth functions on the trajectories and, unlike reward functions in reinforcement learning, are expressive and impose hard constraints on the system. In our framework, we exploit regularity assumptions on individual functions in form of a Gaussian Process (GP) prior. We combine these into a coherent optimization framework using problem structure. The resulting algorithm is able to provably verify complex safety specifications or alternatively find counter examples. Experimental results show that the proposed method is able to find adversarial examples quickly.},
archivePrefix = {arXiv},
arxivId = {1802.08678},
author = {Ghosh, Shromona and Berkenkamp, Felix and Ranade, Gireeja and Qadeer, Shaz and Kapoor, Ashish},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2018.8460635},
eprint = {1802.08678},
isbn = {9781538630815},
issn = {10504729},
title = {{Verifying Controllers Against Adversarial Examples with Bayesian Optimization}},
year = {2018}
}
@article{ZaeStoBar2014:ppsn,
abstract = {For expensive black-box optimization problems, surrogatemodel based approaches like Efficient Global Optimization are frequently used in continuous optimization. Their main advantage is the reduction of function evaluations by exploiting cheaper, data-driven models of the actual target function. The utilization of such methods in combinatorial or mixed search spaces is less common. Efficient Global Optimization and related methods were recently extended to such spaces, by replacing continuous distance (or similarity) measures with measures suited for the respective problem representations. This article investigates a large set of distance measures for their applicability to various permutation problems. The main purpose is to identify, how a distance measure can be chosen, either a-priori or online. In detail, we show that the choice of distance measure can be integrated into the Maximum Likelihood Estimation process of the underlying Kriging model. This approach has robust, good performance, thus providing a very nice tool towards selection of a distance measure.},
annote = {They want to know wich is the best distance for bayesian optimization with Krigling optim. They DO NOT consider the problem as parameter an conclude that the best is Hamming},
author = {Zaefferer, Martin and Stork, J{\"{o}}rg and Beielstein, Thomas Bartz},
doi = {10.1007/978-3-319-10762-2_37},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {bayseian optimization},
mendeley-tags = {bayseian optimization},
title = {{Distance measures for permutations in combinatorial efficient global optimization}},
year = {2014}
}
@article{Nagata2013,
abstract = {This paper presents a genetic algorithm (GA) for solving the traveling salesman problem (TSP). To construct a powerful GA, we use edge assembly crossover (EAX) and make substantial enhancements to it: (i) localization of EAX together with its efficient implementation and (ii) the use of a local search procedure in EAX to determine good combinations of building blocks of parent solutions for generating even better offspring solutions from very high-quality parent solutions. In addition, we develop (iii) an innovative selection model for maintaining population diversity at a negligible computational cost. Experimental results on well-studied TSP benchmarks demonstrate that the proposed GA outperforms state-of-the-art heuristic algorithms in finding very high-quality solutions on instances with up to 200,000 cities. In contrast to the state-of-the-art TSP heuristics, which are all based on the Lin-Kernighan (LK) algorithm, our GA achieves top performance without using an LK-based algorithm. {\textcopyright} 2013 INFORMS.},
author = {Nagata, Yuichi and Kobayashi, Shigenobu},
doi = {10.1287/ijoc.1120.0506},
issn = {10919856},
journal = {INFORMS Journal on Computing},
keywords = {Crossover,Genetic algorithm,Population diversity,Traveling salesman},
title = {{A powerful genetic algorithm using edge assembly crossover for the traveling salesman problem}},
year = {2013}
}
@inproceedings{Xiao2018,
abstract = {Deep neural networks (DNNs) have been found to be vulnerable to adversarial examples resulting from adding small-magnitude perturbations to inputs. Such adversarial examples can mislead DNNs to produce adversary-selected results. Different attack strategies have been proposed to generate adversarial examples, but how to produce them with high perceptual quality and more efficiently requires more research efforts. In this paper, we propose AdvGAN to generate adversarial examples with generative adversarial networks (GANs), which can learn and approximate the distribution of original instances. For AdvGAN, once the generator is trained, it can generate perturbations efficiently for any instance, so as to potentially accelerate adversarial training as defenses. We apply Adv-GAN in both semi-whitebox and black-box attack settings. In semi-whitebox attacks, there is no need to access the original target model after the generator is trained, in contrast to traditional white-box attacks. In black-box attacks, we dynamically train a distilled model for the black-box model and optimize the generator accordingly. Adversarial examples generated by AdvGAN on different target models have high attack success rate under stateof-the-art defenses compared to other attacks. Our attack has placed the first with 92.76{\%} accuracy on a public MNIST black-box attack challenge.1.},
archivePrefix = {arXiv},
arxivId = {1801.02610},
author = {Xiao, Chaowei and Li, Bo and Zhu, Jun Yan and He, Warren and Liu, Mingyan and Song, Dawn},
booktitle = {IJCAI International Joint Conference on Artificial Intelligence},
doi = {10.24963/ijcai.2018/543},
eprint = {1801.02610},
isbn = {9780999241127},
issn = {10450823},
title = {{Generating adversarial examples with adversarial networks}},
year = {2018}
}
@inproceedings{Ye2018,
abstract = {Deep neural networks have been known to be vulnerable to adversarial attacks, raising lots of security concerns in the practical deployment. Popular defensive approaches can be formulated as a (distributionally) robust optimization problem, which minimizes a "point estimate" of worst-case loss derived from either per-datum perturbation or adversary data-generating distribution within certain predefined constraints. This point estimate ignores potential test adversaries that are beyond the pre-defined constraints. The model robustness might deteriorate sharply in the scenario of stronger test adversarial data, fn this work, a novel robust training framework is proposed to alleviate this issue, Bayesian Robust Learning, in which a distribution is put on the adversarial data-generating distribution to account for the uncertainty of the adversarial data-generating process. The uncertainty directly helps to consider the potential adversaries that are stronger than the point estimate in the cases of distributionally robust optimization. The uncertainty of model parameters is also incorporated to accommodate the full Bayesian framework. We design a scalable Markov Chain Monte Carlo sampling strategy to obtain the posterior distribution over model parameters. Various experiments are conducted to verify the superiority of BAL over existing adversarial training methods. The code for BAL is available at h t t p s: / / t i n y u r l . com/yexsaewr.},
author = {Ye, Nanyang and Zhu, Zhanxing},
booktitle = {Advances in Neural Information Processing Systems},
issn = {10495258},
title = {{Bayesian adversarial learning}},
year = {2018}
}
@inproceedings{Abadi2016,
abstract = {Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.},
archivePrefix = {arXiv},
arxivId = {1607.00133},
author = {Abadi, Mart{\'{i}}n and McMahan, H. Brendan and Chu, Andy and Mironov, Ilya and Zhang, Li and Goodfellow, Ian and Talwar, Kunal},
booktitle = {Proceedings of the ACM Conference on Computer and Communications Security},
doi = {10.1145/2976749.2978318},
eprint = {1607.00133},
isbn = {9781450341394},
issn = {15437221},
title = {{Deep learning with differential privacy}},
year = {2016}
}
@inproceedings{He2018,
abstract = {Item recommendation is a personalized ranking task. To this end, many recommender systems optimize models with pairwise ranking objectives, such as the Bayesian Personalized Ranking (BPR). Using matrix Factorization (MF) - the most widely used model in recommendation - as a demonstration, we show that optimizing it with BPR leads to a recommender model that is not robust. In particular, we find that the resultant model is highly vulnerable to adversarial perturbations on its model parameters, which implies the possibly large error in generalization. To enhance the robustness of a recommender model and thus improve its generalization performance, we propose a new optimization framework, namely Adversarial Personalized Ranking (APR). In short, our APR enhances the pairwise ranking method BPR by performing adversarial training. It can be interpreted as playing a minimax game, where the minimization of the BPR objective function meanwhile defends an adversary, which adds adversarial perturbations on model parameters to maximize the BPR objective function. To illustrate how it works, we implement APR on MF by adding adversarial perturbations on the embedding vectors of users and items. Extensive experiments on three public real-world datasets demonstrate the effectiveness of APR - by optimizing MF with APR, it outperforms BPR with a relative improvement of 11.2{\%} on average and achieves state-of-the-art performance for item recommendation. Our implementation is available at: $\backslash$urlhttps://github.com/hexiangnan/adversarial-personalized-ranking.},
archivePrefix = {arXiv},
arxivId = {1808.03908},
author = {He, Xiangnan and He, Zhankui and Du, Xiaoyu and Chua, Tat Seng},
booktitle = {41st International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2018},
doi = {10.1145/3209978.3209981},
eprint = {1808.03908},
isbn = {9781450356572},
keywords = {Adversarial training,Item recommendation,Matrix factorization,Pairwise learning,Personalized ranking},
title = {{Adversarial personalized ranking for recommendation}},
year = {2018}
}
@article{Dwork2013,
abstract = {The problem of privacy-preserving data analysis has a long history spanning multiple disciplines. As electronic data about individuals becomes increasingly detailed, and as technology enables ever more powerful collection and curation of these data, the need increases for a robust, meaningful, and mathematically rigorous definition of privacy, together with a computationally rich class of algorithms that satisfy this definition. Differential Privacy is such a definition. After motivating and discussing the meaning of differential privacy, the preponderance of this monograph is devoted to fundamental techniques for achieving differential privacy, and application of these techniques in creative combinations, using the query-release problem as an ongoing example. A key point is that, by rethinking the computational goal, one can often obtain far better results than would be achieved by methodically replacing each step of a non-private computation with a differentially private implementation. Despite some astonishingly powerful computational results, there are still fundamental limitations - not just on what can be achieved with differential privacy but on what can be achieved with any method that protects against a complete breakdown in privacy. Virtually all the algorithms discussed herein maintain differential privacy against adversaries of arbitrary computational power. Certain algorithms are computationally intensive, others are efficient. Computational complexity for the adversary and the algorithm are both discussed. We then turn from fundamentals to applications other than queryrelease, discussing differentially private methods for mechanism design and machine learning. The vast majority of the literature on differentially private algorithms considers a single, static, database that is subject to many analyses. Differential privacy in other models, including distributed databases and computations on data streams is discussed. Finally, we note that this work is meant as a thorough introduction to the problems and techniques of differential privacy, but is not intended to be an exhaustive survey- there is by now a vast amount of work in differential privacy, and we can cover only a small portion of it. {\textcopyright} 2014 C. Dwork and A. Roth.},
author = {Dwork, Cynthia and Roth, Aaron},
doi = {10.1561/0400000042},
issn = {15513068},
journal = {Foundations and Trends in Theoretical Computer Science},
title = {{The algorithmic foundations of differential privacy}},
year = {2013}
}
@inproceedings{Papernot2017,
abstract = {Machine learning (ML) models, e.g., deep neural networks (DNNs), are vulnerable to adversarial examples: malicious inputs modified to yield erroneous model outputs, while appearing unmodified to human observers. Potential attacks include having malicious content like malware identified as legitimate or controlling vehicle behavior. Yet, all existing adversarial example attacks require knowledge of either the model internals or its training data. We introduce the first practical demonstration of an attacker controlling a remotely hosted DNN with no such knowledge. Indeed, the only capability of our black-box adversary is to observe labels given by the DNN to chosen inputs. Our attack strategy consists in training a local model to substitute for the target DNN, using inputs synthetically generated by an adversary and labeled by the target DNN. We use the local substitute to craft adversarial examples, and find that they are misclassi fied by the targeted DNN. To perform a real-world and properly-blinded evaluation, we attack a DNN hosted by MetaMind, an online deep learning API. We find that their DNN misclassifies 84.24{\%} of the adversarial examples crafted with our substitute. We demonstrate the general applicability of our strategy to many ML techniques by conducting the same attack against models hosted by Amazon and Google, using logistic regression substitutes. They yield adversarial examples misclassified by Amazon and Google at rates of 96.19{\%} and 88.94{\%}. We also find that this black-box attack strategy is capable of evading defense strategies previously found to make adversarial example crafting harder.},
archivePrefix = {arXiv},
arxivId = {1602.02697},
author = {Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z. Berkay and Swami, Ananthram},
booktitle = {ASIA CCS 2017 - Proceedings of the 2017 ACM Asia Conference on Computer and Communications Security},
doi = {10.1145/3052973.3053009},
eprint = {1602.02697},
isbn = {9781450349444},
title = {{Practical black-box attacks against machine learning}},
year = {2017}
}
@inproceedings{Ilyas2019,
abstract = {We study the problem of generating adversarial examples in a black-box setting in which only loss-oracle access to a model is available. We introduce a framework that conceptually unifies much of the existing work on black-box attacks, and we demonstrate that the current state-of-the-art methods are optimal in a natural sense. Despite this optimality, we show how to improve black-box attacks by bringing a new element into the problem: gradient priors. We give a bandit optimization-based algorithm that allows us to seamlessly integrate any such priors, and we explicitly identify and incorporate two examples. The resulting methods use two to four times fewer queries and fail two to five times less than the current state-of-the-art.},
archivePrefix = {arXiv},
arxivId = {1807.07978},
author = {Ilyas, Andrew and Engstrom, Logan and Madry, Aleksander},
booktitle = {7th International Conference on Learning Representations, ICLR 2019},
eprint = {1807.07978},
title = {{Prior convictions: Black-box adversarial attacks with bandits and priors}},
year = {2019}
}
@article{Sabbeh2018,
abstract = {Nowadays, customers have become more interested in the quality of service (QoS) that organizations can provide them. Services provided by different vendors are not highly distinguished which increases competition between organizations to maintain and increase their QoS. Customer Relationship Management systems are used to enable organizations to acquire new customers, establish a continuous relationship with them and increase customer retention for more profitability. CRM systems use machine-learning models to analyze customers' personal and behavioral data to give organization a competitive advantage by increasing customer retention rate. Those models can predict customers who are expected to churn and reasons of churn. Predictions are used to design targeted marketing plans and service offers. This paper tries to compare and analyze the performance of different machine-learning techniques that are used for churn prediction problem. Ten analytical techniques that belong to different categories of learning are chosen for this study. The chosen techniques include Discriminant Analysis, Decision Trees (CART), instance-based learning (k-nearest neighbors), Support Vector Machines, Logistic Regression, ensemble-based learning techniques (Random Forest, Ada Boosting trees and Stochastic Gradient Boosting), Na{\"{i}}ve Bayesian, and Multi-layer perceptron. Models were applied on a dataset of telecommunication that contains 3333 records. Results show that both random forest and ADA boost outperform all other techniques with almost the same accuracy 96{\%}. Both Multi-layer perceptron and Support vector machine can be recommended as well with 94{\%} accuracy. Decision tree achieved 90{\%}, na{\"{i}}ve Bayesian 88{\%} and finally logistic regression and Linear Discriminant Analysis (LDA) with accuracy 86.7{\%}.},
author = {Sabbeh, Sahar F.},
doi = {10.14569/IJACSA.2018.090238},
issn = {21565570},
journal = {International Journal of Advanced Computer Science and Applications},
keywords = {Analytical CRM,Business intelligence,Customer churn,Customer relationship management (CRM),Customer retention,Data mining,Machine-learning,Predictive analytics},
title = {{Machine-learning techniques for customer retention: A comparative study}},
year = {2018}
}
@inproceedings{Audibert2007,
abstract = {Algorithms based on upper-confidence bounds for balancing exploration and exploitation are gaining popularity since they are easy to implement, efficient and effective. In this paper we consider a variant of the basic algorithm for the stochastic, multi-armed bandit problem that takes into account the empirical variance of the different arms. In earlier experimental works, such algorithms were found to outperform the competing algorithms. The purpose of this paper is to provide a theoretical explanation of these findings and provide theoretical guidelines for the tuning of the parameters of these algorithms. For this we analyze the expected regret and for the first time the concentration of the regret. The analysis of the expected regret shows that variance estimates can be especially advantageous when the payoffs of suboptimal arms have low variance. The risk analysis, rather unexpectedly, reveals that except for some very special bandit problems, the regret, for upper confidence bounds based algorithms with standard bias sequences, concentrates only at a polynomial rate. Hence, although these algorithms achieve logarithmic expected regret rates, they seem less attractive when the risk of suffering much worse than logarithmic regret is also taken into account. {\textcopyright} Springer-Verlag Berlin Heidelberg 2007.},
author = {Audibert, Jean Yves and Munos, R{\'{e}}mi and Szepesv{\'{a}}ri, Csaba},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-540-75225-7_15},
isbn = {9783540752240},
issn = {03029743},
title = {{Tuning bandit algorithms in stochastic environments}},
year = {2007}
}
@article{irurozki20a,
author = {Irurozki, E. and Perez, A. and Lobo, J and del Ser, J.},
title = {{Online Ranking with Concept Drifts in Streaming Data}},
year = {2020}
}
@inproceedings{Karger2011,
abstract = {Crowdsourcing systems, in which tasks are electronically distributed to numerous "information piece-workers", have emerged as an effective paradigm for humanpowered solving of large scale problems in domains such as image classification, data entry, optical character recognition, recommendation, and proofreading. Because these low-paid workers can be unreliable, nearly all crowdsourcers must devise schemes to increase confidence in their answers, typically by assigning each task multiple times and combining the answers in some way such as majority voting. In this paper, we consider a general model of such crowdsourcing tasks, and pose the problem of minimizing the total price (i.e., number of task assignments) that must be paid to achieve a target overall reliability. We give a new algorithm for deciding which tasks to assign to which workers and for inferring correct answers from the workers' answers. We show that our algorithm significantly outperforms majority voting and, in fact, is asymptotically optimal through comparison to an oracle that knows the reliability of every worker.},
author = {Karger, David R. and Oh, Sewoong and Shah, Devavrat},
booktitle = {Advances in Neural Information Processing Systems 24: 25th Annual Conference on Neural Information Processing Systems 2011, NIPS 2011},
isbn = {9781618395993},
title = {{Iterative learning for reliable crowdsourcing systems}},
year = {2011}
}
@article{Vitelli2018,
abstract = {Ranking and comparing items is crucial for collecting information about preferences in many areas, from marketing to politics. The Mallows rank model is among the most successful approaches to analyse rank data, but its computational complexity has limited its use to a particular form based on Kendall distance. We develop new computationally tractable methods for Bayesian inference in Mallows models that work with any right-invariant distance. Our method performs inference on the consensus ranking of the items, also when based on partial rankings, such as top-k items or pairwise comparisons. We prove that items that none of the assessors has ranked do not influence the maximum a posteriori consensus ranking, and can therefore be ignored. When assessors are many or heterogeneous, we propose a mixture model for clustering them in homogeneous subgroups, with cluster-specific consensus rankings. We develop approximate stochastic algorithms that allow a fully probabilistic analysis, leading to coherent quantifications of uncertainties. We make probabilistic predictions on the class membership of assessors based on their ranking of just some items, and predict missing individual preferences, as needed in recommendation systems. We test our approach using several experimental and benchmark datasets.},
archivePrefix = {arXiv},
arxivId = {1405.7945},
author = {Vitelli, Valeria and S{\o}rensen, {\O}ystein and Crispino, Marta and Frigessi, Arnoldo and Arjas, Elja},
eprint = {1405.7945},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {Incomplete Rankings,Markov Chain Monte Carlo,Pairwise Comparisons,Preference Learning with uncertainty,Recommendation Systems},
number = {1},
title = {{Probabilistic preference learning with the Mallows rank model}},
volume = {18},
year = {2018}
}
@inproceedings{hosseini2015matching,
author = {Hosseini, Hadi and Larson, Kate and Cohen, Robin},
booktitle = {Twenty-Ninth AAAI Conference on Artificial Intelligence},
title = {{Matching with dynamic ordinal preferences}},
year = {2015}
}
@inproceedings{freeman2017fair,
author = {Freeman, Rupert and Zahedi, Seyed Majid and Conitzer, Vincent},
booktitle = {Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI). Forthcoming},
title = {{Fair social choice in dynamic settings}},
year = {2017}
}
@article{McClellan1974,
abstract = {"The bible of all fundamental algorithms and the work that taught many of today's software developers most of what they know about computer programming."--"Byte," September 1995"I can't begin to tell you how many pleasurable hours of study and recreation they have afforded me! I have pored over them in cars, restaurants, at work, at home... and even at a Little League game when my son wasn't in the line-up."--Charles Long"If you think you're a really good programmer... read [Knuth's]" Art of Computer Programming... "You should definitely send me a resume if you can read the whole thing."--Bill Gates"It's always a pleasure when a problem is hard enough that you have to get the Knuths off the shelf. I find that merely opening one has a very useful terrorizing effect on computers."--Jonathan LaventholThe first revision of this third volume is the most comprehensive survey of classical computer techniques for sorting and searching. It extends the treatment of data structures in Volume 1 to consider both large and small databases and internal and external memories. The book contains a selection of carefully checked computer methods, with a quantitative analysis of their efficiency. Outstanding features of the second edition include a revised section on optimum sorting and new discussions of the theory of permutations and of universal hashing.},
author = {McClellan, Michael T. and Minker, Jack and Knuth, Donald E.},
doi = {10.2307/2005383},
issn = {00255718},
journal = {Mathematics of Computation},
title = {{The Art of Computer Programming, Vol. 3: Sorting and Searching}},
year = {1974}
}
@inproceedings{Martin1990,
abstract = {Associated with each permutation P = [x(1),x(2), ... ,x(N)] of N (ordered) objects is its inversion table I(P) = {\{}y(1), y(2), ... ,y(N){\}}, a sequence of non-negative integers such that y(1) = 0 and, for i {\textgreater} 1, y(i) is the number of terms in {\{}x(1), x(2), ... ,x(i-1){\}} which are greater than or follow the term x(i). A tree permutation is a permutation whose inversion table {\{}y(1), ... ,y(N){\}} has the property that y(i+1) - y(i) is less than 2 for i = 1, 2, ... , N-1; such an inversion table is called a 2-inversion table. Tree permutations of {\{}1, 2, ... , N{\}} are used to represent binary trees having N nodes. O(N) time algorithms are given for converting tree permutations into their associated 2-inversion tables and vice-versa.},
author = {Martin, Harold W.},
booktitle = {ACM Eighteenth Annual Computer Science Conference (CSC90)},
doi = {10.1145/100348.100370},
isbn = {0897913485},
title = {{Transformations between tree permutations and inversion tables}},
year = {1990}
}
@article{Tideman1987,
abstract = {"Independence of clones" is a generalization of the condition of not being subject to the perverse consequences of vote splitting that arise under plurality voting. A new voting rule that is at least "almost always" independent of clones is obtained by the following algorithm: Require the collective ranking of the candidates to be consistent with the paired comparisons decided by the largest and second largest margins, and then, if possible, with the paired comparison decided by the third largest margin, and so on. The advantages of this "ranked pairs" rule over previously proposed voting rules that are independent of clones is that it possesses Condorcet consistency, non-negative responsiveness, and "resolvability" (the property that every tie be within one vote of being broken). {\textcopyright} 1987 Springer-Verlag.},
author = {Tideman, T. N.},
doi = {10.1007/BF00433944},
issn = {01761714},
journal = {Social Choice and Welfare},
title = {{Independence of clones as a criterion for voting rules}},
year = {1987}
}
@article{ailon2008aggregating,
author = {Ailon, Nir and Charikar, Moses and Newman, Alantha},
journal = {Journal of the ACM (JACM)},
number = {5},
pages = {23},
publisher = {ACM},
title = {{Aggregating inconsistent information: ranking and clustering}},
volume = {55},
year = {2008}
}
@inproceedings{parkes2013dynamic,
author = {Parkes, David C and Procaccia, Ariel D},
booktitle = {Twenty-Seventh AAAI Conference on Artificial Intelligence},
title = {{Dynamic social choice with evolving preferences}},
year = {2013}
}
@inproceedings{tal2015study,
author = {Tal, Maor and Meir, Reshef and Gal, Ya'akov},
booktitle = {Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems},
pages = {665--673},
title = {{A study of human behavior in online voting}},
year = {2015}
}
@article{Ailon2008,
abstract = {We address optimization problems in which we are given contradictory pieces of input information and the goal is to find a globally consistent solution that minimizes the extent of disagreement with the respective inputs. Specifically, the problems we address are rank aggregation, the feedback arc set problem on tournaments, and correlation and consensus clustering. We show that for all these problems (and various weighted versions of them), we can obtain improved approximation factors using essentially the same remarkably simple algorithm. Additionally, we almost settle a long-standing conjecture of Bang-Jensen and Thomassen and show that unless NPBPP, there is no polynomial time algorithm for the problem of minimum feedback arc set in tournaments.},
author = {Ailon, Nir and Charikar, Moses and Newman, Alantha},
doi = {10.1145/1411509.1411513},
issn = {00045411},
journal = {Journal of the ACM},
keywords = {Consensus clustering,Correlation clustering,Minimum feedback arc-set,Rank aggregation,Tournaments},
title = {{Aggregating inconsistent information: Ranking and clustering}},
year = {2008}
}
@article{arza2019approaching,
abstract = {{\textcopyright} 2015, Springer Science+Business Media New York. The Mallows (MM) and the Generalized Mallows (GMM) probability models have demonstrated their validity in the framework of Estimation of distribution algorithms (EDAs) for solving permutation-based combinatorial optimisation problems. Recent works, however, have suggested that the performance of these algorithms strongly relies on the distance used under the model. The goal of this paper is to review three common distances for permutations, Kendall's-{\$}{\$}$\backslash$tau {\$}{\$}$\tau$, Cayley and Ulam, and compare their performance under MM and GMM EDAs. Moreover, with the aim of predicting the most suitable distance for solving any given permutation problem, we focus our attention on the relation between these distances and the neighbourhood systems in the field of local search optimisation. In this sense, we demonstrate that the performance of the MM and GMM EDAs is strongly correlated with that of multistart local search algorithms when using related neighbourhoods. Furthermore, by means of fitness landscape analysis techniques, we show that the suitability of a distance to solve a problem is clearly characterised by the generation of high smoothness fitness landscapes.},
annote = {From Duplicate 1 (Sampling and Learning Mallows and Generalized Mallows Models Under the Cayley Distance - Irurozki, E; Calvo, B; Lozano, J A)

cited By 7

From Duplicate 5 (Mallows and generalized Mallows model for matchings - Irurozki, E; Calvo, B; Lozano, J A)

cited By 2},
author = {Irurozki, Ekhi{\~{n}}e Ekhine and Lozano, J.A. Jose A. and Ceberio, Josu and Irurozki, Ekhi{\~{n}}e Ekhine and Mendiburu, Alexander and Lozano, J.A. Jose A. and Calvo, Borja and Lozano, J.A. Jose A. and Arza, Etor and Ceberio, Josu and P{\'{e}}rez, Aritz and Irurozki, Ekhi{\~{n}}e Ekhine and Mendiburu, Alexander and Lozano, J.A. Jose A. and Calvo, Borja and Lozano, J.A. Jose A. and Ceberio, Josu and Irurozki, Ekhi{\~{n}}e Ekhine and Mendiburu, Alexander and Lozano, J.A. Jose A. and Ceberio, Josu and Santamaria, Josean and Santana, Roberto and Mendiburu, Alexander and Irurozki, Ekhi{\~{n}}e Ekhine and Mendiburu, Alexander and Lozano, J.A. Jose A. and Calvo, Borja and Lozano, J.A. Jose A.},
doi = {10.1007/s11009-016-9506-7},
isbn = {1374801100},
issn = {15487660},
journal = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
keywords = {Cayley,Distances,Estimation of distribution algorithms,Generalized Mallows,Generalized Mallows model,Hamming,Kendall's $\tau$,Landscape,Learning,Mallows,Mallows and Generalized Mallows models,Neighbourhood,Permutation,Permutation flowshop scheduling problem,Permutations-based Problems,Permutations-based optimization problems,R,Ranking,Sampling,Ulam,dblp},
number = {2},
pages = {141--142},
publisher = {ACM},
series = {Lecture Notes in Computer Science},
title = {{Approaching the quadratic assignment problem with kernels of mallows models under the hamming distance}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975256345{\&}doi=10.1007{\%}2Fs11009-016-9506-7{\&}partnerID=40{\&}md5=4df4d6c91333e01716ff28f5ccb5a7cd https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064047539{\&}doi=10.3150{\%}2F17-BEJ1017{\&}partnerID=40{\&}md5=589},
volume = {44},
year = {2019}
}
@inproceedings{arza2019approaching,
author = {Arza, Etor and Ceberio, Josu and P{\'{e}}rez, Aritz and Irurozki, Ekhi{\~{n}}e},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {141--142},
title = {{Approaching the quadratic assignment problem with kernels of mallows models under the hamming distance}},
year = {2019}
}
@article{irurozki2018algorithm,
author = {Irurozki, Ekhine and Ceberio, Josu and Santamaria, Josean and Santana, Roberto and Mendiburu, Alexander},
journal = {ACM Transactions on Mathematical Software (TOMS)},
number = {4},
pages = {47},
publisher = {ACM},
title = {{Algorithm 989: perm{\_}mateda: A Matlab Toolbox of Estimation of Distribution Algorithms for Permutation-based Combinatorial Optimization Problems}},
volume = {44},
year = {2018}
}
@inproceedings{Fagin2004,
abstract = {Rank aggregation has recently been proposed as a useful abstraction that has several applications, including meta-search, synthesizing rank functions from multiple indices, similarity search, and classification. In database applications (catalog searches, fielded searches, parametric searches, etc.), the rankings are produced by sorting an underlying database according to various fields. Typically, there are a number of fields that each have very few distinct values, and hence the corresponding rankings have many ties in them. Known methods for rank aggregation are poorly suited to this context, and the difficulties can be traced back to the fact that we do not have sound mathematical principles to compare two partial rankings, that is, rankings that allow ties. In this work, we provide a comprehensive picture of how to compare partial rankings. We propose several metrics to compare partial rankings, present algorithms that efficiently compute them, and prove that they are within constant multiples of each other. Based on these concepts, we formulate aggregation problems for partial rankings, and develop a highly efficient algorithm to compute the top few elements of a near-optimal aggregation of multiple partial rankings. In a model of access that is suitable for databases, our algorithm reads essentially as few elements of each partial ranking as are necessary to determine the winner(s).},
author = {Fagin, Ronald and Kumar, Ravi and Mahdian, Mohammad and Sivakumar, D. and Vee, Erik},
booktitle = {Proceedings of the ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems},
doi = {10.1145/1055558.1055568},
title = {{Comparing and aggregating rankings with ties}},
year = {2004}
}
@article{Ailon2010,
abstract = {We study the problem of aggregating partial rankings. This problem is motivated by applications such as meta-searching and information retrieval, search engine spam fighting, e-commerce, learning from experts, analysis of population preference sampling, committee decision making and more. We improve recent constant factor approximation algorithms for aggregation of full rankings and generalize them to partial rankings. Our algorithms improve constant factor approximation with respect to a family of metrics recently proposed in the context of comparing partial rankings. We pay special attention to two important types of partial rankings: the well-known top-m lists and the more general p-ratings which we define. We provide first evidence for hardness of aggregating them for constant m, p. {\textcopyright} 2008 Springer Science+Business Media, LLC.},
author = {Ailon, Nir},
doi = {10.1007/s00453-008-9211-1},
issn = {01784617},
journal = {Algorithmica (New York)},
keywords = {Approximation algorithms,Rank aggregation,Ranking with ties},
title = {{Aggregation of partial rankings, p-ratings and top-m lists}},
year = {2010}
}
@article{Stump2013,
abstract = {In this paper, we construct bijections between Dyck paths, noncrossing partitions, and 231-avoiding permutations, which send the area statistic on Dyck paths to the inversion number on noncrossing partitions and on 231-avoiding permutations. This bijection has the additional property that it simultaneously sends the major index on Dyck paths to the sum of the major index and the inverse major index on noncrossing partitions and on 231-avoiding permutations, respectively. Moreover, we provide generalizations of these constructions to the group of signed permutations.},
archivePrefix = {arXiv},
arxivId = {0808.2822},
author = {Stump, Christian},
doi = {10.4310/joc.2013.v4.n4.a3},
eprint = {0808.2822},
issn = {21563527},
journal = {Journal of Combinatorics},
title = {{More bijective Catalan combinatorics on permutations and on signed permutations}},
year = {2013}
}
@inproceedings{Lu2011,
abstract = {Learning preference distributions is a key problem in many areas (e.g., recommender systems, IR, social choice). However, many existing methods require restrictive data models for evidence about user preferences. We relax these restrictions by considering as data arbitrary pairwise comparisons - the fundamental building blocks of ordinal rankings. We develop the first algorithms for learning Mallows models (and mixtures) with pairwise comparisons. At the heart is a new algorithm, the generalized repeated insertion model (GRIM), for sampling from arbitrary ranking distributions. We develop approximate samplers that are exact for many important special cases - and have provable bounds with pairwise evidence - and derive algorithms for evaluating log-likelihood, learning Mallows mixtures, and non-parametric estimation. Experiments on large, real-world datasets show the effectiveness of our approach. Copyright 2011 by the author(s)/owner(s).},
author = {Lu, Tyler and Boutilier, Craig},
booktitle = {Proceedings of the 28th International Conference on Machine Learning, ICML 2011},
isbn = {9781450306195},
title = {{Learning Mallows models with pairwise preferences}},
year = {2011}
}
@article{Krempl2014,
abstract = {Every day, huge volumes of sensory, transactional, and web data are continuously generated as streams, which need to be analyzed online as they arrive. Streaming data can be considered as one of the main sources of what is called big data. While predictive modeling for data streams and big data have received a lot of at-tention over the last decade, many research approaches are typi-cally designed for well-behaved controlled problem settings, over-looking important challenges imposed by real-world applications. This article presents a discussion on eight open challenges for data stream mining. Our goal is to identify gaps between current re-search and meaningful applications, highlight open problems, and define new application-relevant research directions for data stream mining. The identified challenges cover the full cycle of knowledge discovery and involve such problems as: protecting data privacy, dealing with legacy systems, handling incomplete and delayed in-formation, analysis of complex data, and evaluation of stream min-ing algorithms. The resulting analysis is illustrated by practical applications and provides general suggestions concerning lines of future research in data stream mining.},
author = {Krempl, Georg and Spiliopoulou, Myra and Stefanowski, Jerzy and {\v{Z}}liobaite, Indre and Brzezi{\'{n}}ski, Dariusz and H{\"{u}}llermeier, Eyke and Last, Mark and Lemaire, Vincent and Noack, Tino and Shaker, Ammar and Sievi, Sonja},
doi = {10.1145/2674026.2674028},
issn = {19310145},
journal = {ACM SIGKDD Explorations Newsletter},
title = {{Open challenges for data stream mining research}},
year = {2014}
}
@book{Gam2010,
abstract = {In the last two decades, machine learning research and practice has fo- cused on batch learning, usually with small datasets. Nowadays there are appli- cations in which the data are modeled best not as persistent tables, but rather as transient data streams. Learning from data streams is an increasing research area with challenging applications and contributions from fields like data bases, learn- ing theory, machine learning, and data mining. In this work we identify the main characteristics of stream mining algorithms, and present two illustrative examples of such algorithms.},
author = {Gam, Jo{\~{a}}o},
booktitle = {Knowledge Discovery from Data Streams},
doi = {10.1201/EBK1439826119},
isbn = {9781439826126},
title = {{Knowledge discovery from data streams}},
year = {2010}
}
@inproceedings{Lu2011,
abstract = {Learning preference distributions is a key problem in many areas (e.g., recommender systems, IR, social choice). However, many existing methods require restrictive data models for evidence about user preferences. We relax these restrictions by considering as data arbitrary pairwise comparisons - the fundamental building blocks of ordinal rankings. We develop the first algorithms for learning Mallows models (and mixtures) with pairwise comparisons. At the heart is a new algorithm, the generalized repeated insertion model (GRIM), for sampling from arbitrary ranking distributions. We develop approximate samplers that are exact for many important special cases - and have provable bounds with pairwise evidence - and derive algorithms for evaluating log-likelihood, learning Mallows mixtures, and non-parametric estimation. Experiments on large, real-world datasets show the effectiveness of our approach. Copyright 2011 by the author(s)/owner(s).},
author = {Lu, Tyler and Boutilier, Craig},
booktitle = {Proceedings of the 28th International Conference on Machine Learning, ICML 2011},
isbn = {9781450306195},
title = {{Learning Mallows models with pairwise preferences}},
year = {2011}
}
@article{Irurozki2018,
annote = {cited By 7},
author = {Irurozki, E and Calvo, B and Lozano, J A},
doi = {10.1007/s11009-016-9506-7},
journal = {Methodology and Computing in Applied Probability},
number = {1},
title = {{Sampling and Learning Mallows and Generalized Mallows Models Under the Cayley Distance}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975256345{\&}doi=10.1007{\%}2Fs11009-016-9506-7{\&}partnerID=40{\&}md5=4df4d6c91333e01716ff28f5ccb5a7cd},
volume = {20},
year = {2018}
}
@article{Irurozki2014a,
annote = {cited By 2},
author = {Irurozki, E and Calvo, B and Lozano, J A},
doi = {10.3150/17-BEJ1017},
journal = {Bernoulli},
number = {2},
pages = {1160--1188},
title = {{Mallows and generalized Mallows model for matchings}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064047539{\&}doi=10.3150{\%}2F17-BEJ1017{\&}partnerID=40{\&}md5=589e0ca1ce0fb5575c4a568b96a6cac8},
volume = {25},
year = {2019}
}
@article{gama2014survey,
author = {Gama, Jo{\~{a}}o and {\v{Z}}liobait$\backslash$.e, Indr$\backslash$.e and Bifet, Albert and Pechenizkiy, Mykola and Bouchachia, Abdelhamid},
journal = {ACM computing surveys (CSUR)},
number = {4},
pages = {44},
publisher = {ACM},
title = {{A survey on concept drift adaptation}},
volume = {46},
year = {2014}
}
@inproceedings{qu2009mining,
author = {Qu, Wei and Zhang, Yang and Zhu, Junping and Qiu, Qiang},
booktitle = {Asian Conference on Machine Learning},
organization = {Springer},
pages = {308--321},
title = {{Mining multi-label concept-drifting data streams using dynamic classifier ensemble}},
year = {2009}
}
@inproceedings{matuszyk2015forgetting,
author = {Matuszyk, Pawel and Vinagre, Jo{\~{a}}o and Spiliopoulou, Myra and Jorge, Al$\backslash$'$\backslash$ipio M{\'{a}}rio and Gama, Jo{\~{a}}o},
booktitle = {Proceedings of the 30th Annual ACM Symposium on Applied Computing},
organization = {ACM},
pages = {947--953},
title = {{Forgetting methods for incremental matrix factorization in recommender systems}},
year = {2015}
}
@article{bifet2009adaptive,
author = {{Bifet Figuerol}, Albert Carles and {Gavald{\`{a}} Mestre}, Ricard},
title = {{Adaptive parameter-free learning from evolving data streams}},
year = {2009}
}
@book{alippi2014intelligence,
author = {Alippi, Cesare},
publisher = {Springer},
title = {{Intelligence for embedded systems}},
year = {2014}
}
@incollection{Chung2011,
author = {Chung, Lyinn and Marden, John I},
doi = {10.1007/978-1-4612-2738-0_7},
title = {{Extensions of Mallows' ϕ Model}},
year = {2011}
}
@inproceedings{crammer2005loss,
author = {Crammer, Koby and Singer, Yoram},
booktitle = {International Conference on Computational Learning Theory},
organization = {Springer},
pages = {48--62},
title = {{Loss bounds for online category ranking}},
year = {2005}
}
@inproceedings{al2018dynamic,
author = {Al-Ghossein, Marie and Abdessalem, Talel and Barr{\'{e}}, Anthony},
booktitle = {Companion of the The Web Conference 2018 on The Web Conference 2018},
organization = {International World Wide Web Conferences Steering Committee},
pages = {1419--1423},
title = {{Dynamic Local Models for Online Recommendation}},
year = {2018}
}
@inproceedings{furnkranz2003pairwise,
author = {F{\"{u}}rnkranz, Johannes and H{\"{u}}llermeier, Eyke},
booktitle = {European conference on machine learning},
organization = {Springer},
pages = {145--156},
title = {{Pairwise preference learning and ranking}},
year = {2003}
}
@article{silva13,
author = {Silva, J A and Faria, E R and Barros, R C and {Hruschka E. R.}, De Carvalho amd A C and Gama, J},
journal = {ACM Computing Surveys},
number = {1},
pages = {13},
publisher = {ACM},
title = {{Data stream clustering: A survey}},
volume = {46},
year = {2013}
}
@book{furnkranz2010preference,
author = {F{\"{u}}rnkranz, Johannes and H{\"{u}}llermeier, Eyke},
publisher = {Springer},
title = {{Preference learning}},
year = {2010}
}
@article{zhou2014big,
author = {Zhou, Zhi-Hua and Chawla, Nitesh V and Jin, Yaochu and Williams, Graham J},
journal = {IEEE Computational Intelligence Magazine},
number = {4},
pages = {62--74},
publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
title = {{Big data opportunities and challenges: Discussions from data analytics perspectives}},
volume = {9},
year = {2014}
}
@inproceedings{yan2007model,
author = {Yan, Rong and Tesic, Jelena and Smith, John R},
booktitle = {Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining},
organization = {ACM},
pages = {834--843},
title = {{Model-shared subspace boosting for multi-label classification}},
year = {2007}
}
@inproceedings{brinker2007label,
author = {Brinker, Klaus and H{\"{u}}llermeier, Eyke},
booktitle = {International Conference on Case-Based Reasoning},
organization = {Springer},
pages = {77--91},
title = {{Label ranking in case-based reasoning}},
year = {2007}
}
@article{crammer2006online,
author = {Crammer, Koby and Dekel, Ofer and Keshet, Joseph and Shalev-Shwartz, Shai and Singer, Yoram},
journal = {Journal of Machine Learning Research},
number = {Mar},
pages = {551--585},
title = {{Online passive-aggressive algorithms}},
volume = {7},
year = {2006}
}
@inproceedings{shalev2007unified,
author = {Shalev-Shwartz, Shai and Singer, Yoram},
booktitle = {Artificial Intelligence and Statistics},
pages = {452--459},
title = {{A unified algorithmic approach for efficient online label ranking}},
year = {2007}
}
@article{shalev2007primal,
author = {Shalev-Shwartz, Shai and Singer, Yoram},
journal = {Machine Learning},
number = {2-3},
pages = {115--142},
publisher = {Springer},
title = {{A primal-dual perspective of online learning algorithms}},
volume = {69},
year = {2007}
}
@article{Meek2014,
abstract = {We develop a new exponential family probabilistic model for permutations that can capture hierarchical structure, and that has the well known Mallows and generalized Mallows models as subclasses. We describe how one can do parameter estimation and propose an approach to structure search for this class of models. We provide experimental evidence that this added flexibility both improves predictive performance and enables a deeper understanding of collections of permutations.},
author = {Meek, Christopher and Meil, Marina},
journal = {NIPS},
title = {{Recursive Inversion Models for Permutations}},
year = {2014}
}
@inproceedings{read2009generating,
author = {Read, Jesse and Pfahringer, Bernhard and Holmes, Geoff},
booktitle = {ECML/PKKD 2009 Workshop on Learning from Multi-label Data (MLD'09)},
pages = {69--84},
title = {{Generating synthetic multi-label data streams}},
year = {2009}
}
@inproceedings{spyromitros2011dealing,
author = {Spyromitros-Xioufis, Eleftherios and Spiliopoulou, Myra and Tsoumakas, Grigorios and Vlahavas, Ioannis},
booktitle = {Twenty-Second International Joint Conference on Artificial Intelligence},
title = {{Dealing with concept drift and class imbalance in multi-label stream classification}},
year = {2011}
}
@article{rodrigues08,
author = {Rodrigues, P.{\~{}}P. and Gama, J and Pedroso, J},
journal = {IEEE Transactions on Knowledge and Data Engineering},
number = {5},
pages = {615--627},
publisher = {IEEE},
title = {{Hierarchical clustering of time-series data streams}},
volume = {20},
year = {2008}
}
@inproceedings{cheng2009decision,
author = {Cheng, Weiwei and H{\"{u}}hn, Jens and H{\"{u}}llermeier, Eyke},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
organization = {ACM},
pages = {161--168},
title = {{Decision tree and instance-based learning for label ranking}},
year = {2009}
}
@article{frigo2017online,
author = {Frig{\'{o}}, Erzs{\'{e}}bet and P{\'{a}}lovics, R{\'{o}}bert and Kelen, Domokos and Kocsis, Levente and Bencz{\'{u}}r, Andr{\'{a}}s},
publisher = {CEUR-WS. org},
title = {{Online ranking prediction in non-stationary environments}},
year = {2017}
}
@incollection{vembu2010label,
author = {Vembu, Shankar and G{\"{a}}rtner, Thomas},
booktitle = {Preference learning},
pages = {45--64},
publisher = {Springer},
title = {{Label ranking algorithms: A survey}},
year = {2010}
}
@article{kendall1938new,
author = {Kendall, Maurice G},
journal = {Biometrika},
number = {1/2},
pages = {81--93},
publisher = {JSTOR},
title = {{A new measure of rank correlation}},
volume = {30},
year = {1938}
}
@article{gnedin2010q,
author = {Gnedin, Alexander and Olshanski, Grigori and Others},
journal = {The Annals of Probability},
number = {6},
pages = {2103--2135},
publisher = {Institute of Mathematical Statistics},
title = {{q-Exchangeability via quasi-invariance}},
volume = {38},
year = {2010}
}
@article{gama14,
author = {Gama, J and Zliobaite, I and Bifet, A and Pechenizkiy, M and Bouchachia, A},
journal = {ACM Computing Surveys},
number = {4},
pages = {44},
publisher = {ACM},
title = {{Survey on concept drift adaptation}},
volume = {46},
year = {2014}
}
@article{bifet2010moa,
author = {Bifet, Albert and Holmes, Geoff and Kirkby, Richard and Pfahringer, Bernhard},
journal = {Journal of Machine Learning Research},
number = {May},
pages = {1601--1604},
title = {{Moa: Massive online analysis}},
volume = {11},
year = {2010}
}
@article{asfaw2017time,
author = {Asfaw, Derbachew and Vitelli, Valeria and S{\o}rensen, {\O}ystein and Arjas, Elja and Frigessi, Arnoldo},
journal = {Stat},
number = {1},
pages = {14--30},
publisher = {Wiley Online Library},
title = {{Time-varying rankings with the Bayesian Mallows model}},
volume = {6},
year = {2017}
}
@article{grossberg1988nonlinear,
author = {Grossberg, Stephen},
journal = {Neural networks},
number = {1},
pages = {17--61},
publisher = {Elsevier},
title = {{Nonlinear neural networks: Principles, mechanisms, and architectures}},
volume = {1},
year = {1988}
}
@inproceedings{kong2011ensemble,
author = {Kong, Xiangnan and Philip, S Yu},
booktitle = {7th International Conference on Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom)},
organization = {IEEE},
pages = {95--104},
title = {{An ensemble-based approach to fast classification of multi-label data streams}},
year = {2011}
}
@inproceedings{park2008multi,
author = {Park, Sang-Hyeun and F{\"{u}}rnkranz, Johannes},
booktitle = {ECML PKDD 2008 Workshop on Preference Learning},
pages = {157--171},
title = {{Multi-label classification with label constraints}},
year = {2008}
}
@article{ditzler2015learning,
author = {Ditzler, Gregory and Roveri, Manuel and Alippi, Cesare and Polikar, Robi},
journal = {IEEE Computational Intelligence Magazine},
number = {4},
pages = {12--25},
publisher = {IEEE},
title = {{Learning in nonstationary environments: A survey}},
volume = {10},
year = {2015}
}
@article{minku2010impact,
author = {Minku, Leandro L and White, Allan P and Yao, Xin},
journal = {IEEE Transactions on knowledge and Data Engineering},
number = {5},
pages = {730--742},
publisher = {IEEE},
title = {{The impact of diversity on online ensemble learning in the presence of concept drift}},
volume = {22},
year = {2010}
}
@inproceedings{Caragiannis2017,
abstract = {We consider a voting scenario where agents have opinions that are estimates of an underlying common ground truth ranking of the available alternatives, and each agent is asked to approve a set with her most preferred alternatives. We assume that estimates are implicitly formed using the well-known Mallows model for generating random rankings. We show that k-approval voting --- where all agents are asked to approve the same number k of alternatives and the outcome is obtained by sorting the alternatives in terms of their number of approvals --- has exponential sample complexity for all values of k. This negative result suggests that an exponential (in terms of the number of alternatives m) number of agents is always necessary in order to recover the ground truth ranking with high probability. In contrast, by just asking each agent to approve a random number of alternatives, the sample complexity improves dramatically: it now depends only polynomially on m. Our results may have implications on the effectiveness of crowdsourcing applications that ask workers to provide their input by approving sets of available alternatives.},
annote = {We show that k-approval voting — where all agents are asked to approve the same number k of alternatives and the outcome is obtained by sorting the alternatives in terms of their number of approvals — has exponential sample complexity for all values of k. This negative result suggests that an exponential (in terms of the number of alternatives m) number of agents is always necessary in order to recover the ground truth ranking with high probability. In contrast, by just asking each agent to approve a random number of alternatives, the sample complexity improves dramatically: it now depends only polynomially on m.},
author = {Caragiannis, Ioannis and Micha, Evi},
booktitle = {IJCAI International Joint Conference on Artificial Intelligence},
isbn = {9780999241103},
issn = {10450823},
title = {{Learning a ground truth ranking using noisy approval votes}},
year = {2017}
}
@inproceedings{ailon2014improved,
author = {Ailon, Nir},
booktitle = {Artificial Intelligence and Statistics},
pages = {29--37},
title = {{Improved bounds for online learning over the permutahedron and other ranking polytopes}},
year = {2014}
}
@techreport{Yasutake2012,
abstract = {We consider an online learning framework where the task is to predict a permutation which represents a ranking of n fixed objects. At each trial, the learner incurs a loss defined as Kendall tau distance between the predicted permutation and the true permutation given by the adversary. This setting is quite natural in many situations such as information retrieval and recommendation tasks. We prove a lower bound of the cumulative loss and hardness results. Then, we propose an algorithm for this problem and prove its relative loss bound which shows our algorithm is close to optimal. {\textcopyright} 2012 S. Yasutake, K. Hatano, E. Takimoto  {\&}  M. Takeda.},
author = {Yasutake, Shota and Hatano, Kohei and Takimoto, Eiji and Takeda, Masayuki and Hoi, Steven C H and Buntine, Wray},
booktitle = {Asian Conference on Machine Learning},
keywords = {online learning,permutation,rank aggregation,ranking},
title = {{Online Rank Aggregation}},
year = {2012}
}
@article{hullermeier2008label,
author = {H{\"{u}}llermeier, Eyke and F{\"{u}}rnkranz, Johannes and Cheng, Weiwei and Brinker, Klaus},
journal = {Artificial Intelligence},
number = {16-17},
pages = {1897--1916},
publisher = {Elsevier},
title = {{Label ranking by learning pairwise preferences}},
volume = {172},
year = {2008}
}
@article{snell1962mathematical,
author = {Snell, J L and Kemeny, J G},
journal = {Introduction to Higher Mathematics. Ginn, Boston},
title = {{Mathematical Models in the Social Sciences}},
year = {1962}
}
@article{zagier1992realizability,
author = {Zagier, Don},
journal = {Communications in mathematical physics},
number = {1},
pages = {199--210},
publisher = {Springer},
title = {{Realizability of a model in infinite statistics}},
volume = {147},
year = {1992}
}
@article{Lu2014,
abstract = {Learning preference distributions is a critical problem in many areas (e.g., recommender systems, IR, social choice). However, many existing learning and inference methods im-pose restrictive assumptions on the form of user preferences that can be admitted as ev-idence. We relax these restrictions by considering as data arbitrary pairwise comparisons of alternatives, which represent the fundamental building blocks of ordinal rankings. We develop the first algorithms for learning Mallows models (and mixtures thereof) from pair-wise comparison data. At the heart of our technique is a new algorithm, the generalized repeated insertion model (GRIM), which allows sampling from arbitrary ranking distribu-tions, and conditional Mallows models in particular. While we show that sampling from a Mallows model with pairwise evidence is computationally difficult in general, we develop approximate samplers that are exact for many important special cases—and have provable bounds with pairwise evidence—and derive algorithms for evaluating log-likelihood, learn-ing Mallows mixtures, and non-parametric estimation. Experiments on real-world data sets demonstrate the effectiveness of our approach.},
author = {Lu, Tyler and Boutilier, Craig},
journal = {Journal of Machine Learning Research},
keywords = {Mallows models,incomplete data,mixture models,preference learning,ranking},
title = {{Effective Sampling and Learning for Mallows Models with Pairwise-Preference Data}},
year = {2014}
}
@article{lu2012bayesian,
author = {Lu, Tyler and Tang, Pingzhong and Procaccia, Ariel D and Boutilier, Craig},
journal = {arXiv preprint arXiv:1210.4895},
title = {{Bayesian vote manipulation: Optimal strategies and impact on welfare}},
year = {2012}
}
@inproceedings{dey2015detecting,
author = {Dey, Palash and Misra, Neeldhara and Narahari, Y},
booktitle = {Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems},
organization = {International Foundation for Autonomous Agents and Multiagent Systems},
pages = {1441--1450},
title = {{Detecting possible manipulators in elections}},
year = {2015}
}
@article{Mossel2013,
abstract = {We study the phase transition of the coalitional manipulation problem for generalized scoring rules. Previously it has been shown that, under some conditions on the distribution of votes, if the number of manipulators is o(sqrt{\{}n{\}}), where n is the number of voters, then the probability that a random profile is manipulable by the coalition goes to zero as the number of voters goes to infinity, whereas if the number of manipulators is omega(sqrt{\{}n{\}}), then the probability that a random profile is manipulable goes to one. Here we consider the critical window, where a coalition has size c*sqrt{\{}n{\}}, and we show that as c goes from zero to infinity, the limiting probability that a random profile is manipulable goes from zero to one in a smooth fashion, i.e., there is a smooth phase transition between the two regimes. This result analytically validates recent empirical results, and suggests that deciding the coalitional manipulation problem may be of limited computational hardness in practice.},
author = {Mossel, Elchanan and Procaccia, Ariel D. and Racz, Miklos Z.},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
title = {{A smooth transition from powerlessness to absolute power}},
year = {2013}
}
@article{gibbard1973manipulation,
author = {Gibbard, Allan and Others},
journal = {Econometrica},
number = {4},
pages = {587--601},
title = {{Manipulation of voting schemes: a general result}},
volume = {41},
year = {1973}
}
@article{mossel2012election,
author = {Mossel, Elchanan and R{\'{a}}cz, Mikl{\'{o}}s Z},
journal = {SIGecom Exchanges},
number = {2},
pages = {22--24},
title = {{Election manipulation: the average case.}},
volume = {11},
year = {2012}
}
@inproceedings{ElMesaoudi-Paul2018,
abstract = {We propose a new statistical model for ranking data, i.e., a new family of probability distributions on permutations. Our model is inspired by the idea of a data-generating process in the form of a noisy sorting procedure, in which deterministic comparisons between pairs of items are replaced by Bernoulli trials. The probability of producing a certain ranking as a result then essentially depends on the Bernoulli parameters, which can be interpreted as pairwise preferences. We show that our model can be written in closed form if insertion or quick sort are used as sorting algorithms, and propose a maximum likelihood approach for parameter estimation. We also introduce a generalization of the model, in which the constraints on pairwise preferences are relaxed, and for which maximum likelihood estimation can be carried out based on a variation of the generalized iterative scaling algorithm. Experimentally, we show that the models perform very well in terms of goodness of fit, compared to existing models for ranking data.},
author = {{El Mesaoudi-Paul}, Adil and Busa-Fekete, R{\'{o}}bert},
booktitle = {Proceedings of the 35th International Conference on Machine Learning},
title = {{Ranking Distributions based on Noisy Sorting}},
year = {2018}
}
@inproceedings{Agarwal2016,
abstract = {In today's big data era, huge amounts of ranking and choice data are generated on a daily basis, and consequently, many powerful new computational tools for dealing with ranking and choice data have emerged in recent years. This paper highlights recent developments in two areas of ranking and choice modeling that cross traditional boundaries and are of multidisciplinary interest: ranking from pairwise comparisons, and automatic discovery of latent categories from choice survey data.},
author = {Agarwal, Shivani},
booktitle = {IJCAI International Joint Conference on Artificial Intelligence},
issn = {10450823},
title = {{On ranking and choice models}},
year = {2016}
}
@article{Procaccia2007,
abstract = {Encouraging voters to truthfully reveal their preferences in an election has long been an important issue. Recently, computational complexity has been suggested as a means of precluding strategic behavior. Previous studies have shown that some voting protocols are hard to manipulate, but used NP-hardness as the complexity measure. Such a worst-case analysis may be an insufficient guarantee of resistance to manipulation. Indeed, we demonstrate that NP-hard manipulations may be tractable in the average case. For this purpose, we augment the existing theory of average-case complexity with some new concepts. In particular, we consider elections distributed with respect to junta distributions, which concentrate on hard instances. We use our techniques to prove that scoring protocols are susceptible to manipulation by coalitions, when the number of candidates is constant.},
author = {Procaccia, Ariel D. and Rosenschein, Jeffrey S.},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
title = {{Junta distributions and the average-case complexity of manipulating elections}},
year = {2007}
}
@article{satterthwaite1975strategy,
author = {Satterthwaite, Mark Allen},
journal = {Journal of economic theory},
number = {2},
pages = {187--217},
publisher = {Elsevier},
title = {{Strategy-proofness and Arrow's conditions: Existence and correspondence theorems for voting procedures and social welfare functions}},
volume = {10},
year = {1975}
}
@article{Hameed2017,
abstract = {Genetic algorithms (GAs) represent a method that mimics the process of natural evolution in effort to find good solutions. In that process, crossover operator plays an important role. To comprehend the genetic algorithms as a whole, it is necessary to understand the role of a crossover operator. Today, there are a number of different crossover operators that can be used , one of the problems in using genetic algorithms is the choice of crossover operator Many crossover operators have been proposed in literature on evolutionary algorithms, however, it is still unclear which crossover operator works best for a given optimization problem. This paper aims at studying the behavior of different types of crossover operators in the performance of genetic algorithm. These types of crossover are implemented on Traveling Salesman Problem (TSP); Whitley used the order crossover (OX) depending on specific parameters to solve the traveling salesman problem, the aim of this paper is to make a comparative study between order crossover (OX) and other types of crossover using the same parameters which was Whitley used.},
author = {Hameed, Wafaa Mustafa and {Baker Kanbar}, Asan and Lecturer, Assistant},
doi = {10.5281/zenodo.345734},
isbn = {1110.51760.2},
journal = {International Journal of Research-Granthaalayah},
keywords = {Crossover Operator,Evolutionary Algor,Genetic Algorithms,Natural Evaluation,Order Crossover,Parameters,Traveling Salesman Problem},
title = {{A Comparative Study of Crossover Operators for Genetic Algorithms to Solve Travelling Salesman Problem}},
year = {2017}
}
@inproceedings{10.1007/978-3-319-10762-2_16,
abstract = {In this paper a new discrete Differential Evolution algorithm for the Permutation Flowshop Scheduling Problem with the total flowtime criterion is proposed. The core of the algorithm is the distance-based differential mutation operator defined by means of a new randomized bubble sort algorithm. This mutation scheme allows the Differential Evolution to directly navigate the permutations search space. Experiments were held on a well known benchmark suite and the results show that our proposal outperforms state-of-the-art algorithms on the majority of the problems.},
address = {Cham},
author = {Santucci, Valentino and Baioletti, Marco and Milani, Alfredo},
booktitle = {Parallel Problem Solving from Nature -- PPSN XIII},
editor = {Bartz-Beielstein, Thomas and Branke, J{\"{u}}rgen and Filipi{\v{c}}, Bogdan and Smith, Jim},
isbn = {978-3-319-10762-2},
pages = {161--170},
publisher = {Springer International Publishing},
title = {{A Differential Evolution Algorithm for the Permutation Flowshop Scheduling Problem with Total Flow Time Criterion}},
year = {2014}
}
@article{Magalhaes-Mendes2013,
abstract = {Genetic algorithms (GA) are wide class of global optimization methods. Many genetic algorithms have been applied to solve combinatorial optimization problems. One of the problems in using genetic algorithms is the choice of crossover operator. The aim of this paper is to show the influence of genetic crossover operators on the performance of a genetic algorithm. The GA is applied to the job shop scheduling problem (JSSP). To achieve this aim an experimental study of a set of crossover operators is presented. The experimental study is based on a decision support system (DSS). To compare the abilities of different crossover operators, the DSS was designed giving all the operators the same opportunities. The genetic crossover operators are tested on a set of standard instances taken from the literature. The makespan is the measure used to evaluate the genetic crossover operators. The main conclusion is that there is a crossover operator having the best average performance on a specific set of solved instances.},
author = {Magalh{\~{a}}es-Mendes, Jorge},
issn = {11092750},
journal = {WSEAS Transactions on Computers},
keywords = {Crossover Operators,Genetic Algorithms,JSSP,Operations Research,Optimization,Scheduling},
title = {{A comparative study of crossover operators for genetic algorithms to solve the job shop scheduling problem}},
year = {2013}
}
@misc{sloane_catalan,
abstract = {number of permutations at each hamming distance},
author = {Sloane, Neil James Alexander},
booktitle = {https://oeis.org/A000108},
title = {{Catalan numbers, https://oeis.org/A000108}},
url = {https://oeis.org/A000108},
year = {2009}
}
@book{Stanley2015,
abstract = {We begin with a set of problems that will be shown to be completely equivalent. The solution to each problem is the same sequence of numbers called the Catalan numbers. Later in the document we will derive relationships and explicit formulas for the Catalan numbers in many different ways. 1 Problems 1.1 Balanced Parentheses Suppose you have n pairs of parentheses and you would like to form valid groupings of them, where " valid " means that each open parenthesis has a matching closed parenthesis. For example, " (()()) " is valid, but " ())()(" is not. How many groupings are there for each value of n? Perhaps a more precise definition of the problem would be this: A string of parentheses is valid if there are an equal number of open and closed parentheses and if you begin at the left as you move to the right, add 1 each time you pass an open and subtract 1 each time you pass a closed parenthesis, then the sum is always non-negative. Table 1 shows the possible groupings for 0 ≤ n ≤ 5. n = 0: * 1 way n = 1: () 1 way n = 2: ()(), (()) 2 ways n = 3:},
author = {Stanley, Richard P.},
booktitle = {Catalan Numbers},
doi = {10.1017/CBO9781139871495},
isbn = {9781139871495},
title = {{Catalan numbers}},
year = {2015}
}
@inproceedings{baioletti2018algebraic,
author = {Baioletti, Marco and Milani, Alfredo and Santucci, Valentino},
booktitle = {2018 IEEE Congress on Evolutionary Computation (CEC)},
organization = {IEEE},
pages = {1--8},
title = {{Algebraic Crossover Operators for Permutations}},
year = {2018}
}
@incollection{petersen2015eulerian,
author = {Petersen, T Kyle},
booktitle = {Eulerian Numbers},
pages = {3--18},
publisher = {Springer},
title = {{Eulerian numbers}},
year = {2015}
}
@article{xia2019learning,
author = {Xia, Lirong},
journal = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
number = {1},
pages = {1--159},
publisher = {Morgan {\&} Claypool Publishers},
title = {{Learning and Decision-Making from Rank Data}},
volume = {13},
year = {2019}
}
@inproceedings{liu2018efficiently,
author = {Liu, Allen and Moitra, Ankur},
booktitle = {2018 IEEE 59th Annual Symposium on Foundations of Computer Science (FOCS)},
organization = {IEEE},
pages = {627--638},
title = {{Efficiently learning mixtures of Mallows models}},
year = {2018}
}
@inproceedings{NIPS2018_7691,
author = {Chierichetti, Flavio and Dasgupta, Anirban and Haddadan, Shahrzad and Kumar, Ravi and Lattanzi, Silvio},
booktitle = {Advances in Neural Information Processing Systems 31},
editor = {Bengio, S and Wallach, H and Larochelle, H and Grauman, K and Cesa-Bianchi, N and Garnett, R},
pages = {4382--4392},
publisher = {Curran Associates, Inc.},
title = {{Mallows Models for Top-k Lists}},
url = {http://papers.nips.cc/paper/7691-mallows-models-for-top-k-lists.pdf},
year = {2018}
}
@article{Meila2010a,
abstract = {This paper presents a statistical model for expressing preferences through rankings, when the number of alternatives (items to rank) is large. A human ranker will then typically rank only the most preferred items, and may not even examine the whole set of items, or know how many they are. Similarly, a user presented with the ranked output of a search engine, will only consider the highest ranked items. We model such situations by introducing a stagewise ranking model that operates with finite ordered lists called top-t orderings over an infinite space of items. We give algorithms to estimate this model from data, and demonstrate that it has sufficient statistics, being thus an exponential family model with continuous and discrete parameters. We describe its conjugate prior and other statistical properties. Then, we extend the estimation problem to multimodal data by introducing an Exponential-Blurring-Mean-Shift nonparametric clustering algorithm. The experiments highlight the properties of our model and demonstrate that infinite models over permutations can be simple, elegant and practical.},
author = {Meila, Marina and Bao, Le},
isbn = {1532-4435},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {branch-and-bound,distance based ranking model,expo-,mallows model,nential family,non-parametric clustering,partial orderings,permutations},
title = {{An Exponential Model for Infinite Rankings}},
year = {2010}
}
@incollection{Heckelman2016,
abstract = {The computability of social choice functions by majority voting.},
author = {Heckelman, Jac and Miller, Nicholas and Ragan, Robi},
booktitle = {Handbook of Social Choice and Voting},
doi = {10.4337/9781783470730.00010},
title = {{Computational social choice}},
year = {2016}
}
@book{Brandt2016,
abstract = {The Handbook of Computational Statistics - Concepts and Methods is divided into 4 parts. It begins with an overview of the field of Computational Statistics, how it emerged as a seperate discipline, how it developed along the development of hard- and software, including a discussion of current active research. The second part presents several topics in the supporting field of statistical computing. Emphasis is placed on the need for fast and accurate numerical algorithms, and it discusses some of the basic methodologies for transformation, data base handling and graphics treatment. The third part focuses on statistical methodology. Special attention is given to smoothing, iterative procedures, simulation and visualization of multivariate data. Finally a set of selected applications like Bioinformatics, Medical Imaging, Finance and Network Intrusion Detection highlight the usefulness of computational statistics.},
author = {Brandt, Felix and Conitzer, Vincent and Endriss, Ulle and Lang, J{\'{e}}r{\^{o}}me and Procaccia, Ariel D.},
booktitle = {Handbook of Computational Social Choice},
doi = {10.1017/CBO9781107446984},
isbn = {9781107446984},
title = {{Handbook of computational social choice}},
year = {2016}
}
@book{Condorcet1785,
abstract = {Essai sur l'application de l'analyse {\`{a}} la probabilit{\'{e}} des d{\'{e}}cisions rendues {\`{a}} la pluralit{\'{e}} des voix ([Reprod.]) / par M. le marquis de Condorcet,... -- 1785 -- livre},
author = {Condorcet, J De A},
booktitle = {Condorcet Selected Writings},
title = {{Essai sur l'application de l'analyse a la probabilite des decisions rendues a la pluralite des voix}},
year = {1785}
}
@article{Fagin2003,
abstract = {Systems that produce ranked lists of results are abundant. For instance, Web search engines return ranked lists of Web pages. There has been work on distance measure for list permutations, like Kendall tau and Spearman's footrule, as well as extensions to handle top-k lists, which are more common in practice. In addition to ranking whole objects (e.g., Web pages), there is an increasing number of systems that provide keyword search on XML or other semistructured data, and produce ranked lists of XML sub-trees. Unfortunately, previous distance measures are not suitable for ranked lists of sub-trees since they do not account for the possible overlap between the returned sub-trees. That is, two sub-trees differing by a single node would be considered separate objects. In this paper, we present the first distance measures for ranked lists of sub-trees, and show under what conditions these measures are metrics. Furthermore, we present algorithms to efficiently compute these distance measures. Finally, we evaluate and compare the proposed measures on real data using three popular XML keyword proximity search systems. ?? 2013 Elsevier Ltd. Allrightsreserved.},
author = {Fagin, Ronald and Kumar, Ravi and Sivakumar, D.},
doi = {10.1137/s0895480102412856},
issn = {0895-4801},
journal = {SIAM Journal on Discrete Mathematics},
title = {{ Comparing Top k Lists }},
year = {2003}
}
@inproceedings{Braverman2008,
abstract = {In this paper we study noisy sorting without re-sampling. In this problem there is an unknown order api(1) pi(j) for all pairs i neq j, where ga {\textgreater} 0 is a constant and q(ai,aj) = -q(aj,ai) for all i and j. It is assumed that the errors are independent. Given the status of the queries the goal is to find the maximum likelihood order. In other words, the goal is find a permutation sigma that minimizes the number of pairs sigma(i) {\textgreater} sigma(j) where q(sigma(i),sigma(j)) = -. The problem so defined is the feedback arc set problem on distributions of inputs, each of which is a tournament obtained as a noisy perturbations of a linear order. Note that when ga {\textless} 1/2 and n is large, it is impossible to recover the original order pi. It is known that the weighted feedback are set problem on tournaments is NP-hard in general. Here we present an algorithm of running time n O(gamma -4) and sampling complexity Ogamma(n log n) that with high probability solves the noisy sorting without re-sampling problem. We also show that if is an optimal solution of the problem then it is ``close'' to the original order. More formally, with high probability it holds that sumi sigma(i) - pi(i) = Theta(n) and maxi sigma(i) - pi(i) = Theta(log n). Our results are of interest in applications to ranking, such as ranking in sports, or ranking of search items based on comparisons by experts.},
archivePrefix = {arXiv},
arxivId = {0707.1051},
author = {Braverman, Mark and Mossel, Elchanan},
booktitle = {Proceedings of the 19th Annual Symposium on Discrete Algorithms},
eprint = {0707.1051},
isbn = {9780898716474},
issn = {9780898716474},
title = {{Noisy Sorting Without Resampling}},
year = {2008}
}
@article{Moraglio2005,
abstract = {Evolutionary Algorithms (EAs) are successful and$\backslash$n$\backslash$nwidespread general problem solving methods that mimic$\backslash$n$\backslash$nin a simplified manner biological evolution. Whereas all$\backslash$n$\backslash$nEAs share the same basic algorithmic structure, they differ$\backslash$n$\backslash$nin the solution representation ? the genotype ? and in the$\backslash$n$\backslash$nsearch operators employed ? mutation and crossover ?$\backslash$n$\backslash$nthat are representation-specific. Is this difference only$\backslash$n$\backslash$nsuperficial? Is there a deeper unity encompassing all$\backslash$n$\backslash$nmutation and crossover operators beyond the specific$\backslash$n$\backslash$nrepresentation, hence all EAs?$\backslash$n$\backslash$nTopological crossover and topological mutation are$\backslash$n$\backslash$nrepresentation-independent operators that are welldefined$\backslash$n$\backslash$nonce a notion of distance over the solution$\backslash$n$\backslash$nspace is defined. These operators generalise traditional$\backslash$n$\backslash$ncrossover and mutation operators for binary strings and$\backslash$n$\backslash$nreal vectors. In this paper we explore how the topological$\backslash$n$\backslash$nframework applies to the permutation representation and$\backslash$n$\backslash$nin particular analyse the consequences of having more$\backslash$n$\backslash$nthan one notion of distance available. Also, we study the$\backslash$n$\backslash$ninteractions among distances and build a rational picture$\backslash$n$\backslash$nin which pre-existing recombination/crossover operators$\backslash$n$\backslash$nfor permutation fit naturally. Lastly, we also analyse the$\backslash$n$\backslash$napplication of topological crossover to TSP.},
author = {Moraglio, Alberto and Poli, Riccardo},
doi = {10.1145/1102256.1102330},
isbn = {1595930973},
journal = {Proceedings of the 2005 workshops on Genetic and Evolutionary Computation},
keywords = {7,crossover,for an introduction,is one of the,most-frequently used,permutations,see,the permutation representation,theory,to the topic},
title = {{Topological Crossover for the Permutation Representation}},
year = {2005}
}
@inproceedings{awasthi2014learning,
abstract = {This work concerns learning probabilistic models for ranking data in a heterogeneous population. The specific problem we study is learning the parameters of a {\{}$\backslash$em Mallows Mixture Model{\}}. Despite being widely studied, current heuristics for this problem do not have theoretical guarantees and can get stuck in bad local optima. We present the first polynomial time algorithm which provably learns the parameters of a mixture of two Mallows models. A key component of our algorithm is a novel use of tensor decomposition techniques to learn the top-k prefix in both the rankings. Before this work, even the question of {\{}$\backslash$em identifiability{\}} in the case of a mixture of two Mallows models was unresolved.},
author = {Awasthi, Pranjal and Blum, Avrim and Sheffet, Or and Vijayaraghavan, Aravindan},
booktitle = {Advances in Neural Information Processing Systems},
pages = {2609--2617},
title = {{Learning mixtures of ranking models}},
year = {2014}
}
@article{MoraglioAlbertoandPoli2004,
abstract = {A swarm algorithm framework (SWAF), realized by agent-based modeling, is presented to solve numerical optimization problems. Each agent is a bare bones cognitive architecture, which learns knowledge by appropriately deploying a set of simple rules in fast and frugal heuristics. Two essential categories of rules, the generate-and-test and the problem-formulation rules, are implemented, and both of the macro rules by simple combination and subsymbolic deploying of multiple rules among them are also studied. Experimental results on benchmark problems are presented, and performance comparison between SWAF and other existing algorithms indicates that it is efficiently.},
author = {Moraglio, Alberto and Poli, Riccardo},
doi = {doi:10.1007/b98643},
isbn = {3-540-22344-4},
issn = {0302-9743},
journal = {Genetic and Evolutionary Computation -- GECCO 2004},
pmid = {18595440},
title = {{Topological Interpretation of Crossover}},
year = {2004}
}
@article{Bartholdi1989a,
abstract = {We show how computational complexity might protect the integrity of social choice. We exhibit a voting rule that efficiently computes winners but is computationally resistant to strategic manipulation. It is NP-complete for a manipulative voter to determine how to exploit knowledge of the preferences of others. In contrast, many standard voting schemes can be manipulated with only polynomial computational effort. },
author = {Bartholdi, J. J. and Tovey, C. A. and Trick, M. A.},
doi = {10.1007/BF00295861},
issn = {01761714},
journal = {Social Choice and Welfare},
title = {{The computational difficulty of manipulating an election}},
year = {1989}
}
@article{Davies2011,
abstract = {We prove that it is NP-hard for a coalition of two manipulators to compute how to manipulate the Borda voting rule. This resolves one of the last open problems in the computational complexity of manipulating common voting rules. Because of this NP-hardness, we treat computing a manipulation as an approximation problem where we try to minimize the number of manipulators. Based on ideas from bin packing and multiprocessor scheduling, we propose two new approximation methods to compute manipulations of the Borda rule. Experiments show that these methods significantly outperform the previous best known {\%}existing approximation method. We are able to find optimal manipulations in almost all the randomly generated elections tested. Our results suggest that, whilst computing a manipulation of the Borda rule by a coalition is NP-hard, computational complexity may provide only a weak barrier against manipulation in practice.},
archivePrefix = {arXiv},
arxivId = {1105.5667},
author = {Davies, J and Katsirelos, G and Narodytska, N and Walsh, T},
eprint = {1105.5667},
isbn = {9781577355083},
journal = {AAAI},
keywords = {Combinatorial algorithms,Feasible flow,Maximum flow,Network flow,Strongly connected network},
title = {{Complexity of and Algorithms for Borda Manipulation.}},
year = {2011}
}
@article{Zuckerman2009,
abstract = {We investigate the problem of coalitional manipulation in elections, which is known to be hard in a variety of voting rules. We put forward efficient algorithms for the problem in Borda, Maximin and Plurality with Runoff, and analyze their windows of error. Specifically, given an instance on which an algorithm fails, we bound the additional power the manipulators need in order to succeed. We finally discuss the implications of our results with respect to the popular approach of employing computational hardness to preclude manipulation. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
author = {Zuckerman, Michael and Procaccia, Ariel D. and Rosenschein, Jeffrey S.},
doi = {10.1016/j.artint.2008.11.005},
isbn = {9780898716474},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Computational complexity,Computational social choice,Manipulation,Voting},
pmid = {11932877},
title = {{Algorithms for the coalitional manipulation problem}},
year = {2009}
}
@article{Faliszewski2010,
abstract = {{\textless}p{\textgreater}We provide an overview of more than two decades of work, mostly in AI, that studies computational complexity as a barrier against manipulation in elections.{\textless}/p{\textgreater}},
author = {Faliszewski, Piotr and Procaccia, Ariel D.},
doi = {10.1609/aimag.v31i4.2314},
issn = {0738-4602},
journal = {AI Magazine},
title = {{AI's War on Manipulation: Are We Winning?}},
year = {2010}
}
@article{Rajkumar2015,
abstract = {We consider the problem of ranking n items from stochastically sampled pairwise preferences. It was shown recently that when the underlying pairwise preferences are acyclic, several algo-rithms including the Rank Centrality algorithm, the Matrix Borda algorithm, and the SVM-RankAggregation algorithm succeed in recov-ering a ranking that minimizes a global pair-wise disagreement error (Rajkumar and Agarwal, 2014). In this paper, we consider settings where pairwise preferences can contain cycles. In such settings, one may still like to be able to recover 'good' items at the top of the ranking. For exam-ple, if a Condorcet winner exists that beats ev-ery other item, it is natural to ask that this be ranked at the top. More generally, several tour-nament solution concepts such as the top cycle, Copeland set, Markov set and others have been proposed in the social choice literature for choos-ing a set of winners in the presence of cycles. We show that existing algorithms can fail to per-form well in terms of ranking Condorcet winners and various natural tournament solution sets at the top. We then give alternative ranking algo-rithms that provably rank Condorcet winners, top cycles, and other tournament solution sets of in-terest at the top. In all cases, we give finite sam-ple complexity bounds for our algorithms to re-cover such winners. As a by-product of our anal-ysis, we also obtain an improved sample com-plexity bound for the Rank Centrality algorithm to recover an optimal ranking under a Bradley-Terry-Luce (BTL) condition, which answers an open question of Rajkumar and Agarwal (2014). Proceedings of the 32 nd International Conference on Machine Learning, Lille, France, 2015. JMLR: W{\&}CP volume 37. Copy-right 2015 by the author(s).},
author = {Rajkumar, Arun and Ghoshal, Suprovat and Lim, Lek-Heng and Agarwal, Shivani},
isbn = {9781510810587},
journal = {International Conference on Machine Learning},
title = {{Ranking from Stochastic Pairwise Preferences: Recovering Condorcet Winners and Tournament Solution Sets at the Top}},
year = {2015}
}
@book{Brockwell2002,
abstract = {Some of the key mathematical results are stated without proof in order to make the underlying theory accessible to a wider audience. The book assumes a knowledge only of basic calculus, matrix algebra, and elementary statistics. The emphasis is on methods and the analysis of data sets. The logic and tools of model-building for stationary and nonstationary time series are developed in detail and numerous exercises, many of which make use of the included computer package, provide the reader with ample opportunity to develop skills in this area. The core of the book covers stationary processes, ARMA and ARIMA processes, multivariate time series and state-space models, with an optional chapter on spectral analysis. Additional topics include harmonic regression, the Burg and Hannan-Rissanen algorithms, unit roots, regression with ARMA errors, structural models, the EM algorithm, generalized state-space models with applications to time series of count data, exponential smoothing, the Holt-Winters and ARAR forecasting algorithms, transfer function models and intervention analysis. Brief introductions are also given to cointegration and to nonlinear, continuous-time and long-memory models. The time series package included in the back of the book is a slightly modified version of the package ITSM, published separately as ITSM for Windows, by Springer-Verlag, 1994. It does not handle such large data sets as ITSM for Windows, but like the latter, runs on IBM-PC compatible computers under either DOS or Windows (version 3.1 or later). The programs are all menu-driven so that the reader can immediately apply the techniques in the book to time series data, with a minimal investment of time in the computational and algorithmic aspects of the analysis.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Brockwell, Peter and Davis, Richard},
booktitle = {Technometrics},
doi = {10.2307/1271510},
eprint = {arXiv:1011.1669v3},
isbn = {0387953515},
issn = {00401706},
pmid = {708181},
title = {{Introduction to Time Series and Forecasting}},
year = {2002}
}
@article{Ogata1981,
author = {Ogata, Yosihiko and Tanemura, Masaharu},
doi = {10.1007/BF02480944},
issn = {00203157},
journal = {Annals of the Institute of Statistical Mathematics},
title = {{Estimation of interaction potentials of spatial point patterns through the maximum likelihood procedure}},
year = {1981}
}
@article{Potamianos1997,
abstract = {We present an analysis of previously proposed Monte Carlo$\backslash$nalgorithms for estimating the partition function of a Gibbs random$\backslash$nfield. We show that this problem reduces to estimating one or more$\backslash$nexpectations of suitable functionals of the Gibbs states with respect to$\backslash$nproperly chosen Gibbs distributions. As expected, the resulting$\backslash$nestimators are consistent. Certain generalizations are also provided. We$\backslash$nstudy computational complexity with respect to grid size and show that$\backslash$nMonte Carlo partition function estimation algorithms can be classified$\backslash$ninto two categories: E-type algorithms that are of exponential$\backslash$ncomplexity and P-type algorithms that are of polynomial complexity,$\backslash$nTuring reducible to the problem of sampling from the Gibbs distribution.$\backslash$nE-type algorithms require estimating a single expectation, whereas,$\backslash$nP-type algorithms require estimating a number of expectations with$\backslash$nrespect to Gibbs distributions which are chosen to be sufficiently$\backslash$n{\&}ldquo;close{\&}rdquo; to each other. In the latter case, the required$\backslash$nnumber of expectations is of polynomial order with respect to grid size.$\backslash$nWe compare computational complexity by using both theoretical results$\backslash$nand simulation experiments. We determine the most efficient E-type and$\backslash$nP-type algorithms and conclude that P-type algorithms are more$\backslash$nappropriate for partition function estimation. We finally suggest a$\backslash$npractical and efficient P-type algorithm for this task},
author = {Potamianos, Gerasimos and Goutsias, John},
doi = {10.1109/18.641558},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
keywords = {Gibbs random fields,Index Terms—Computational complexity,Monte Carlo simulations,importance sampling,partition func-tion estimation,stochastic approximation},
title = {{Stochastic approximation algorithms for partition function$\backslash$nestimation of Gibbs random fields}},
year = {1997}
}
@article{Soufiani2014a,
abstract = {Rank breaking is a methodology introduced by Azari Soufiani et al. (2013a) for applying a Generalized Method of Moments (GMM) algorithm to the estimation of parametric ranking models. Breaking takes full rankings and breaks, or splits them up, into counts for pairs of alternatives that occur in particular positions (e.g., first place and second place, second place and third place). GMMs are of interest because they can achieve significant speed-up relative to maximum likelihood approaches and comparable statistical efficiency. We characterize the breakings for which the estimator is consistent for random utility models (RUMs) including Plackett-Luce and Normal-RUM, develop a general sufficient condition for a full breaking to be the only consistent breaking, and provide a trichotomy theorem in regard to single-edge breakings. Experimental results are presented to show the computational efficiency along with statistical performance of the proposed method.},
author = {Soufiani, Hossein Azari and Parkes, David C. and Xia, Lirong},
isbn = {9781634393973},
journal = {31st International Conference on Machine learning},
keywords = {generalized method of moments,random utility models},
title = {{Computing Parametric Ranking Models via Rank-Breaking}},
year = {2014}
}
@article{Soufiani2014,
abstract = {In this paper we propose a class of efficient Generalized Method-of-Moments (GMM) algorithms for computing parameters of the Plackett-Luce model, where the data consists of full rankings over alternatives. Our technique is based on breaking the full rankings into pairwise comparisons, and then computing param- eters that satisfy a set of generalized moment conditions. We identify conditions for the output of GMM to be unique, and identify a general class of consistent and inconsistent breakings. We then show by theory and experiments that our al- gorithms run significantly faster than the classical Minorize-Maximization (MM) algorithm, while achieving competitive statistical efficienc},
author = {Soufiani, Hossein Azari and Chen, William Z. and Parkes, David C. and Xia, Lirong},
doi = {no DOI, URL correct},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems 2013},
title = {{Generalized Method-Of-Moments For Rank Aggregation}},
year = {2014}
}
@article{Medsker2001,
abstract = {Recurrent neural networks have been an interesting and important part of neural network research during the 1990's. They have already been applied to a wide variety of problems involving time sequences of events and ordered data such as characters in words. Novel current uses range from motion detection and music synthesis to financial forecasting. This book is a summary of work on recurrent neural networks and is exemplary of current research ideas and challenges in this subfield of artificial neural network research and development. By sharing these perspectives, we hope to illuminate opportunities and encourage further work in this promising area},
author = {Medsker, L R and Jain, L C},
isbn = {9780849371813},
journal = {New York},
keywords = {lista{\_}filtrada},
title = {{RECURRENT NEURAL Design and Applications}},
url = {http://higherintellect.info/texts/science{\_}and{\_}technology/artificial{\_}intelligence/Recurrent{\%}5CnNeural{\%}5CnNetworks{\%}5CnDesign{\%}5CnAnd{\%}5CnApplications{\%}5Cn-{\%}5CnL.R.{\%}5CnMedsker.pdf},
year = {2001}
}
@article{AllinGeo2017,
abstract = {This paper discusses speech recognition and how it can be made utilizing machine learning. This paper also discusses how errors can be figured out to execute the program decreasing the possibility of errors. Additionally examined in the paper is the means by which the program translates the information and predicts the speech. The paper additionally talks about the utilization of Nyquisttheorem and Fourier Transformation to make speech recognition conceivable.},
author = {{Allin Geo}, A.V. and Kaliyamurthie, K.P.},
issn = {13143395},
journal = {International Journal of Pure and Applied Mathematics},
keywords = {Algorithms,Classification,Deep Learning,Error,Fourier Transformation,Neural Networks,Nyquist theorem,Representation,Speech Recognition},
number = {10 Special Issue},
title = {{Discourse recognition with deep learning}},
volume = {116},
year = {2017}
}
@article{Short1996,
abstract = {"Recurrent backprop" for learning to store information over extended time periods takes too long. The main reason is insufficient, decaying error back flow. We describe a novel, efficient "Long Short Term Memory" (LSTM) that overcomes this and related problems. Unlike previous approaches, LSTM can learn to bridge arbitrary time lags by enforcing constant error flow. Using gradient descent, LSTM explicitly learns when to store information and when to access it. In experimental comparisons with "Real-Time Recurrent Learning", "Recurrent Cascade-Correlation", "Elman nets", and "Neural Sequence Chunking", LSTM leads to many more successful runs, and learns much faster. Unlike its competitors, LSTM can solve tasks involving minimal time lags of more than 1000 time steps, even in noisy environments.},
author = {Short, Long and Memory, Term},
journal = {Memory},
number = {1993},
pages = {1--28},
title = {{Long Short Term Memory}},
year = {1996}
}
@misc{pycma2017,
author = {Nikohansen},
booktitle = {GitHub repository},
howpublished = {$\backslash$url{\{}https://github.com/CMA-ES/pycma{\}}},
publisher = {GitHub},
title = {pycma},
year = {2017}
}
@article{GoodfellowIanBengioYoshuaCourville2016,
abstract = {The Deep Learning textbook is a resource intended to help students and practitioners enter the field of machine learning in general and deep learning in particular. The online version of the book is now complete and will remain available online for free.},
author = {{Goodfellow, Ian, Bengio, Yoshua, Courville}, Aaron},
journal = {MIT Press},
title = {{Deep Learning (Chinese Translation)}},
url = {http://www.deeplearningbook.org/},
year = {2016}
}
@article{Zheng2016,
abstract = {High accuracy scanned sunspot drawings handwritten characters recognition is an issue of critical importance to analyze sunspots movement and store them in the database. This paper presents a robust deep learning method for scanned sunspot drawings handwritten characters recognition. The convolution neural network (CNN) is one algorithm of deep learning which is truly successful in training of multi-layer network structure. CNN is used to train recognition model of handwritten character images which are extracted from the original sunspot drawings. We demonstrate the advantages of the proposed method on sunspot drawings provided by Chinese Academy Yunnan Observatory and obtain the daily full-disc sunspot numbers and sunspot areas from the sunspot drawings. The experimental results show that the proposed method achieves a high recognition accurate rate.},
author = {Zheng, Sheng and Zeng, Xiangyun and Lin, Ganghua and Zhao, Cui and Feng, Yongli and Tao, Jinping and Zhu, Daoyuan and Xiong, Li},
doi = {10.1016/j.newast.2015.11.001},
isbn = {1451185553},
issn = {13841076},
journal = {New Astronomy},
keywords = {Convolution neural network,Handwriting character,Recognition,Sunspot drawings},
pages = {54--59},
title = {{Sunspot drawings handwritten character recognition method based on deep learning}},
volume = {45},
year = {2016}
}
@article{Li2014,
abstract = {Long short-term memory (LSTM) based acoustic modeling methods have recently been shown to give state-of-the-art performance on some speech recognition tasks. To achieve a further performance improvement, in this research, deep extensions on LSTM are investigated considering that deep hierarchical model has turned out to be more efficient than a shallow one. Motivated by previous research on constructing deep recurrent neural networks (RNNs), alternative deep LSTM architectures are proposed and empirically evaluated on a large vocabulary conversational telephone speech recognition task. Meanwhile, regarding to multi-GPU devices, the training process for LSTM networks is introduced and discussed. Experimental results demonstrate that the deep LSTM networks benefit from the depth and yield the state-of-the-art performance on this task.},
archivePrefix = {arXiv},
arxivId = {1410.4281},
author = {Li, Xiangang and Wu, Xihong},
doi = {10.1109/ICASSP.2015.7178826},
eprint = {1410.4281},
isbn = {978-1-4673-6997-8},
issn = {15206149},
journal = {2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
pages = {4520--4524},
title = {{Constructing Long Short-Term Memory based Deep Recurrent Neural Networks for Large Vocabulary Speech Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7178826{\%}5Cnhttp://arxiv.org/abs/1410.4281},
year = {2014}
}
@inproceedings{Ermon2011,
abstract = {We propose a novel Adaptive Markov Chain Monte Carlo algorithm to compute the partition function. In particular, we show how to accelerate a flat histogram sampling technique by significantly reducing the number of " null moves " in the chain, while maintaining asymptotic convergence properties. Our experiments show that our method converges quickly to highly accurate solutions on a range of benchmark instances, outperforming other state-of-the-art methods such as IJGP, TRW, and Gibbs sampling both in run-time and accuracy. We also show how ob-taining a so-called density of states distribution allows for efficient weight learning in Markov Logic theories.},
author = {Ermon, Stefano and Gomes, C and Sabharwal, B and Selman, Bart},
booktitle = {Proc. 25th Annual Conf. on Neural Information Processing System (NIPS-11)},
isbn = {9781618395993},
title = {{Accelerated adaptive markov chain for partition function computation}},
year = {2011}
}
@article{Jerrum2004,
abstract = {We present a polynomial-time randomized algorithm for estimating the permanent of an arbitrary n x n matrix with nonnegative entries. This algorithm--technically a "fully-polynomial randomized approximation scheme"--computes an approximation that is, with high probability, within arbitrarily small specified relative error of the true value of the permanent.ABSTRACT FROM AUTHOR},
archivePrefix = {arXiv},
arxivId = {arXiv:1210.6463},
author = {Jerrum, Mark and Sinclair, Alistair and Vigoda, Eric},
doi = {10.1145/1008731.1008738},
eprint = {arXiv:1210.6463},
isbn = {0219477507},
issn = {00045411},
journal = {Journal of the ACM},
number = {4},
pages = {671--697},
title = {{A polynomial-time approximation algorithm for the permanent of a matrix with nonnegative entries}},
url = {http://portal.acm.org/citation.cfm?doid=1008731.1008738},
volume = {51},
year = {2004}
}
@article{Barvinok2016,
abstract = {We present a deterministic algorithm, which, for any given 0{\textless} epsilon {\textless} 1 and an nxn real or complex matrix A=(a{\_}{\{}ij{\}}) such that | a{\_}{\{}ij{\}}-1| {\textless} 0.19 computes the permanent of A within a relative error epsilon in n{\^{}}{\{}O(log n -log epsilon){\}} time. The method can be extended to compute other partition functions associated with subgraph counting and graph homomorphisms.},
archivePrefix = {arXiv},
arxivId = {arXiv:1405.1303v1},
author = {Barvinok, Alexander},
doi = {10.1007/s10208-014-9243-7},
eprint = {arXiv:1405.1303v1},
issn = {16153383},
journal = {Foundations of Computational Mathematics},
keywords = {Algorithm,Hafnian,Permanent},
number = {2},
pages = {329--342},
title = {{Computing the Permanent of (Some) Complex Matrices}},
volume = {16},
year = {2016}
}
@book{Irurozki2011a,
abstract = {An increasing number of data mining domains consider data that can be represented as permutations. Therefore, it is important to devise new methods to learn predictive models over datasets of permutations. However, maintaining probability distributions over the space of permutations is a hard task since there are n! permutations of n elements. The Fourier transform has been successfully generalized to functions over permutations. One of its main advantages in the context of probability distributions is that it compactly summarizes approximations to functions by discarding high order marginals information. In this paper, we present a method to learn a probability distribution that approximates the generating distribution of a given sample of permutations. In particular, this method learns the Fourier domain information representing this probability distribution. {\textcopyright} 2011 Springer-Verlag.},
author = {Irurozki, E. and Calvo, B. and Lozano, J.A.},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-642-21043-3-22},
isbn = {9783642210426},
issn = {03029743},
keywords = {Probabilistic modeling,learning,permutation,ranking},
title = {{Learning probability distributions over permutations by means of Fourier coefficients}},
volume = {6657 LNAI},
year = {2011}
}
@article{Irurozki2011b,
abstract = {Haplotype data are especially important in the study of complex diseases since it contains more information than genotype data. However, obtaining haplotype data is technically difficult and costly. Computational methods have proved to be an effective way of inferring haplotype data from genotype data. One of these methods, the haplotype inference by pure parsimony approach (HIPP), casts the problem as an optimization problem and as such has been proved to be NP-hard. We have designed and developed a new preprocessing procedure for this problem. Our proposed algorithm works with groups of haplotypes rather than individual haplotypes. It iterates searching and deleting haplotypes that are not helpful in order to find the optimal solution. This preprocess can be coupled with any of the current solvers for the HIPP that need to preprocess the genotype data. In order to test it, we have used two state-of-the-art solvers, RTIP and GAHAP, and simulated and real HapMap data. Due to the computational time and memory reduction caused by our preprocess, problem instances that were previously unaffordable can be now efficiently solved. {\textcopyright} 2006 IEEE.},
author = {Irurozki, E. and Calvo, B. and Lozano, J.A.},
doi = {10.1109/TCBB.2010.125},
issn = {15455963},
journal = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
keywords = {Biology and genetics,haplotype inference,optimization},
number = {5},
title = {{A preprocessing procedure for haplotype inference by pure parsimony}},
volume = {8},
year = {2011}
}
@article{Ceberio2014a,
abstract = {The aim of this paper is two-fold. First, we introduce a novel general estimation of distribution algorithm to deal with permutation-based optimization problems. The algorithm is based on the use of a probabilistic model for permutations called the generalized Mallows model. In order to prove the potential of the proposed algorithm, our second aim is to solve the permutation flowshop scheduling problem. A hybrid approach consisting of the new estimation of distribution algorithm and a variable neighborhood search is proposed. Conducted experiments demonstrate that the proposed algorithm is able to outperform the state-of-the-art approaches. Moreover, from the 220 benchmark instances tested, the proposed hybrid approach obtains new best known results in 152 cases. An in-depth study of the results suggests that the successful performance of the introduced approach is due to the ability of the generalized Mallows estimation of distribution algorithm to discover promising regions in the search space. {\textcopyright} 1997-2012 IEEE.},
author = {Ceberio, J. and Irurozki, E. and Mendiburu, A. and Lozano, J.A.},
doi = {10.1109/TEVC.2013.2260548},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Estimation of distribution algorithms,Generalized Mallows model,Permutation flowshop scheduling problem,Permutations-based optimization problems},
number = {2},
title = {{A distance-based ranking model estimation of distribution algorithm for the flowshop scheduling problem}},
volume = {18},
year = {2014}
}
@article{Ceberio2015a,
abstract = {{\textcopyright} 2015, Springer Science+Business Media New York. The Mallows (MM) and the Generalized Mallows (GMM) probability models have demonstrated their validity in the framework of Estimation of distribution algorithms (EDAs) for solving permutation-based combinatorial optimisation problems. Recent works, however, have suggested that the performance of these algorithms strongly relies on the distance used under the model. The goal of this paper is to review three common distances for permutations, Kendall's-{\$}{\$}$\backslash$tau {\$}{\$}$\tau$, Cayley and Ulam, and compare their performance under MM and GMM EDAs. Moreover, with the aim of predicting the most suitable distance for solving any given permutation problem, we focus our attention on the relation between these distances and the neighbourhood systems in the field of local search optimisation. In this sense, we demonstrate that the performance of the MM and GMM EDAs is strongly correlated with that of multistart local search algorithms when using related neighbourhoods. Furthermore, by means of fitness landscape analysis techniques, we show that the suitability of a distance to solve a problem is clearly characterised by the generation of high smoothness fitness landscapes.},
author = {Ceberio, J. and Irurozki, E. and Mendiburu, A. and Lozano, J.A.},
doi = {10.1007/s10589-015-9740-x},
issn = {15732894},
journal = {Computational Optimization and Applications},
keywords = {Distances,Estimation of distribution algorithms,Landscape,Mallows and Generalized Mallows models,Neighbourhood,Permutations-based Problems},
number = {2},
title = {{A review of distances for the Mallows and Generalized Mallows estimation of distribution algorithms}},
volume = {62},
year = {2015}
}
@article{Irurozki2016b,
abstract = {In this paper we present the R package PerMallows, which is a complete toolbox to work with permutations, distances and some of the most popular probability models for permutations: Mallows and the Generalized Mallows models. The Mallows model is an exponential location model, considered as analogous to the Gaussian distribution. It is based on the definition of a distance between permutations. The Generalized Mallows model is its best-known extension. The package includes functions for making inference, sampling and learning such distributions. The distances considered in PerMallows are Kendall's $\tau$, Cayley, Hamming and Ulam.},
author = {Irurozki, Ekhine and Calvo, Borja and Lozano, Jose A.},
doi = {10.18637/jss.v071.i12},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {Cayley,Generalized Mallows,Hamming,Kendall's $\tau$,Learning,Mallows,Permutation,R,Ranking,Sampling,Ulam},
title = {{PerMallows: An R package for mallows and generalized mallows models}},
volume = {71},
year = {2019}
}
@inproceedings{Irurozki2009a,
abstract = {A haplotype is a DNA sequence that is inherited from one parent. They are especially important in the study of complex diseases since they contain more information than genotype data, so the next high priority phase in human genomics involves the development of a full Haplotype Map of human genome [1]. However, obtaining haplotype data is technically difficult and expensive. One of the computational methods for obtaining haplotype data from genotype data is the pure parsimony criterion, an approach known as Haplotype Inference by Pure Parsimony (HIPP). It has been proved to be an NP-hard problem. We present a new preprocessing method which drastically decreases the number of relevant haplotypes. Several algorithms need to preprocess data; for big problem instances this key procedure is even more important than the process. This preprocessing was eventually tested on real and simulated data applying a tabu search, and the performance of the resulting algorithm showed it to be competitive with thebest actual solvers. {\textcopyright} 2009 IEEE.},
author = {Irurozki, E. and Lozano, J.A.},
booktitle = {2009 IEEE Congress on Evolutionary Computation, CEC 2009},
doi = {10.1109/CEC.2009.4983097},
isbn = {9781424429592},
title = {{A new preprocessing procedure for the haplotype inference problem}},
year = {2009}
}
@article{Vembu2009,
abstract = {We consider MAP estimators for structured prediction with exponential family models. In particular, we concentrate on the case that efficient algorithms for uniformsampling from the output space exist. We show that under this assumption (i) exact computation of the partition function remains a hard prob- lem, and (ii) the partition function and the gradient of the log partition function can be approximated efficiently. Our main result is an approximation scheme for the parti- tion function based on Markov Chain Monte Carlo theory. We also show that the efficient uniform sampling assumption holds in several application settings that are of importance in machine learning.},
author = {Vembu, Shankar and G{\"{a}}rtner, Thomas and Boley, Mario},
journal = {UAI 2009},
pages = {557--564},
title = {{Probabilistic Structured Predictors}},
year = {2009}
}
@article{Desir2016,
abstract = {We consider the assortment optimization problem when customer preferences follow a mixture of Mallows distributions. The assortment optimization problem focuses on determining the revenue/profit maximizing subset of products from a large universe of products; it is an important decision that is commonly faced by retailers in determining what to offer their customers. There are two key challenges: (a) the Mallows distribution lacks a closed-form expression (and requires summing an exponential number of terms) to compute the choice probability and, hence, the expected revenue/profit per customer; and (b) finding the best subset may require an exhaustive search. Our key contributions are an efficiently computable closed-form expression for the choice probability under the Mallows model and a compact mixed integer linear program (MIP) formulation for the assortment problem.},
author = {D{\'{e}}sir, Antoine and Segev, Danny},
issn = {10495258},
journal = {29th Conference on Neural Information Processing Systems (NIPS 2016)},
number = {Nips},
pages = {1--9},
title = {{Assortment Optimization Under the Mallows model}},
year = {2016}
}
@article{Maystre2017,
abstract = {We address the problem of learning a ranking by using adaptively chosen pairwise comparisons. Our goal is to recover the ranking accurately but to sample the comparisons sparingly. If all comparison outcomes are consistent with the ranking, the optimal solution is to use an efficient sorting algorithm, such as Quicksort. But how do sorting algorithms behave if some comparison outcomes are inconsistent with the ranking? We give favorable guarantees for Quicksort for the popular Bradley-Terry model, under natural assumptions on the parameters. Furthermore, we empirically demonstrate that sorting algorithms lead to a very simple and effective active learning strategy: repeatedly sort the items. This strategy performs as well as state-of-the-art methods (and much better than random sampling) at a minuscule fraction of the computational cost.},
archivePrefix = {arXiv},
arxivId = {arXiv:1502.05556v2},
author = {Maystre, Lucas and Grossglauser, Matthias},
eprint = {arXiv:1502.05556v2},
journal = {Proceedings of the 34th International Conference on Machine Learning},
keywords = {Bradley-Terry,active learning,ranking,sorting},
pages = {2344--2353},
title = {{Just Sort It! A Simple and Effective Approach to Active Preference Learning}},
url = {http://proceedings.mlr.press/v70/maystre17a.html},
volume = {70},
year = {2017}
}
@article{Cheon2009,
abstract = {A Bayesian network is a powerful graphical model. It is advantageous for real-world data analysis and finding relations among variables. Knowledge presentation and rule generation, based on a Bayesian approach, have been studied and reported in many research papers across various fields. Since a Bayesian network has both causal and probabilistic semantics, it is regarded as an ideal representation to combine background knowledge and real data. Rare event predictions have been performed using several methods, but remain a challenge. We design and implement a Bayesian network model to forecast daily ozone states. We evaluate the proposed Bayesian network model, comparing it to traditional decision tree models, to examine its utility.},
author = {Cheon, Seong-Pyo and Kim, Sungshin and Lee, So-Young and Lee, Chong-Bum},
doi = {10.1016/j.knosys.2009.02.004},
isbn = {0950-7051},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Bayesian network,Ozone forecasting,Rare event prediction},
number = {5},
pages = {336--343},
title = {{Bayesian networks based rare event prediction with sensor data}},
url = {http://www.sciencedirect.com/science/article/pii/S0950705109000392{\%}5Cnhttp://linkinghub.elsevier.com/retrieve/pii/S0950705109000392},
volume = {22},
year = {2009}
}
@article{Trotman2005,
abstract = {New general purpose ranking functions are discovered using genetic programming. The TREC WSJ collection was chosen as a training set. A baseline comparison function was chosen as the best of inner product, probability, cosine, and Okapi BM25. An elitist genetic algorithm with a population size 100 was run 13 times for 100 generations and the best performing algorithms chosen from these. The best learned functions, when evaluated against the best baseline function (BM25), demonstrate some significant performance differences, with improvements in mean average precision as high as 32{\%} observed on one TREC collection not used in training. In no test is BM25 shown to significantly outperform the best learned function.},
author = {Trotman, Andrew},
doi = {10.1007/s10791-005-6991-7},
isbn = {1386-4564},
issn = {13864564},
journal = {Information Retrieval},
keywords = {Genetic programming,Machine learning,Searching,Socument ranking},
number = {3},
pages = {359--381},
title = {{Learning to rank}},
volume = {8},
year = {2005}
}
@article{Vapnik2015,
abstract = {V. Vapnik and R. Izmailov. Learning using privileged information: Similarity control and knowledge transfer. Journal of Machine Learning Research, 16:2023–2049, 2015.},
author = {Vapnik, Vladimir},
doi = {10.1007/978-3-319-17091-6_1},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {classification,frames,intelligent teacher,kernel functions,knowledge,knowledge representation,learning theory,privileged information,regression,similarity control,similarity functions,support vector machines,svm,transfer},
pages = {2023--2049},
title = {{Learning Using Privileged Information : Similarity Control and Knowledge Transfer}},
volume = {16},
year = {2015}
}
@article{Calvo2009,
abstract = {The feature subset selection problem has a growing importance in many machine learning applications where the amount of variables is very high. There is a great number of algorithms that can approach this problem in supervised databases but, when examples from one or more classes are not available, supervised feature subset selection algorithms cannot be directly applied. One of these algorithms is the correlation based filter selection (CFS). In this work we propose an adaptation of this algorithm that can be applied when only positive and unlabelled examples are available. As far as we know, this is the first time the feature subset selection problem is studied in the positive unlabelled learning context. We have tested this adaptation on synthetic datasets obtained by sampling Bayesian network models where we know which variables are (in)dependent of the class. We have also tested our adaptations on real-life databases where the absence of negative examples has been simulated. The results show that, having enough positive examples, it is possible to obtain good solutions to the feature subset selection problem when only positive and unlabelled instances are available. ?? 2009 Elsevier B.V. All rights reserved.},
author = {Calvo, Borja and Larra{\~{n}}aga, Pedro and Lozano, Jose A.},
doi = {10.1016/j.patrec.2009.04.015},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Feature subset selection,Filter methods,Partially supervised classification,Positive unlabelled learning},
number = {11},
pages = {1027--1036},
title = {{Feature subset selection from positive and unlabelled examples}},
volume = {30},
year = {2009}
}
@inproceedings{Theofilatos2016,
abstract = {Modeling road accident occurrence has gained increasing attention over the years. So far, considerable efforts have been made from researchers and policy makers in order to explain road accidents and improve road safety performance of highways. In reality, road accidents are rare events. In such cases, the binary dependent variable is characterized by dozens to thousands of times fewer events (accidents) than non-events (non-accidents). Instead of using traditional logistic regression methods, this paper considers accidents as rare events and proposes a series of rare-events logit models which are applied in order to model road accident occurrence by utilizing real-time traffic data. This statistical procedure was initially proposed by King and Zeng (2001) when scholars study rare events such as wars, massive economic crises and so on. Rare-events logit models basically estimate the same models as traditional logistic regression, but the estimates as well as the probabilities are corrected for the bias that occurs when the sample is small or the observed events are very rare. Consequently, the basic problem of underestimating the event probabilities is avoided as stated by King and Zeng (2001). To the best of our knowledge, this is the first time that this approach is followed when road accident data are analyzed. Instead of applying a traditional case-control study, the complete dataset of hourly aggregated traffic data such as flow, occupancy, mean time speed and percentage of trucks, were collected from three random loop detectors in the Attica Tollway ("Attiki Odos") located in Greater Athens Area in Greece for the 2008-2011 period. The modeling results showed an adequate statistical fit and reveal a negative relationship between accident occurrence and the natural logarithm of speed in the accident location. This study attempts to contribute to the understanding of accident occurrence in motorways by developing novel models such as the rare-events logit for the first time in safety evaluation of motorways.},
author = {Theofilatos, Athanasios and Yannis, George and Kopelias, Pantelis and Papadimitriou, Fanis},
booktitle = {Transportation Research Procedia},
doi = {10.1016/j.trpro.2016.05.293},
issn = {23521465},
keywords = {accident occurrence,logistic regression,rare events,traffic parameters},
pages = {3399--3405},
title = {{Predicting Road Accidents: A Rare-events Modeling Approach}},
volume = {14},
year = {2016}
}
@article{Kumar2010,
abstract = {Spearman's footrule and Kendall's tau are two well estab- lished distances between rankings. They, however, fail to take into account concepts crucial to evaluating a result set in information retrieval: element relevance and positional information. That is, changing the rank of a highly-relevant document should result in a higher penalty than changing the rank of an irrelevant document; a similar logic holds for the top versus the bottom of the result ordering. In this work, we extend both of these metrics to those with posi- tion and element weights, and show that a variant of the Diaconis–Graham inequality still holds — the generalized two measures remain within a constant factor of each other for all permutations. We continue by extending the element weights into a dis- tance metric between elements. For example, in search eval- uation, swapping the order of two nearly duplicate results should result in little penalty, even if these two are highly relevant and appear at the top of the list. We extend the distance measures to this more general case and show that they remain within a constant factor of each other. We conclude by conducting simple experiments on web search data with the proposed measures. Our experiments show that the weighted generalizations are more robust and consistent with each other than their unweighted counter- parts.},
author = {Kumar, Ravi and Vassilvitskii, Sergei},
doi = {10.1145/1772690.1772749},
isbn = {9781605587998},
journal = {Proceedings of the 19th international conference on World wide web - WWW '10},
keywords = {footrule,kendall tau,metrics,permutation distances,retrieval measures,spearman},
number = {3},
pages = {571},
title = {{Generalized distances between rankings}},
url = {http://portal.acm.org/citation.cfm?doid=1772690.1772749},
year = {2010}
}
@misc{Contributors,
author = {{OpenStreetMap$\backslash$ Contributors}},
title = {{Planet dump}},
url = {www.openstreetmap.org},
year = {2015}
}
@article{Hastie2009,
abstract = {During the past decade there has been an explosion in computation and information technology. With it has come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It should be a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting-the first comprehensive treatment of this topic in any book. Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie wrote much of the statistical modeling software in S-PLUS and invented principal curves and surfaces. Tibshirani proposed the Lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, and projection pursuit. FROM THE REVIEWS: TECHNOMETRICS "This is a vast and complex book. Generally, it concentrates on explaining why and how the methods work, rather than how to use them. Examples and especially the visualizations are principle features...As a source for the methods of statistical learning...it will probably be a long time before there is a competitor to this book."},
archivePrefix = {arXiv},
arxivId = {1010.3003},
author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
doi = {10.1007/b94608},
eprint = {1010.3003},
isbn = {9780387848570},
issn = {03436993},
journal = {Elements},
pages = {337--387},
pmid = {15512507},
title = {{The Elements of Statistical Learning}},
url = {http://www.springerlink.com/index/10.1007/b94608},
volume = {1},
year = {2009}
}
@article{Park2016,
abstract = {In modern society, accidents on the roads are one of the most life-threatening dangers to humans. Traffic accidents that cause a lot of damages are occurring all over the places. The most effective solution to these types of accidents can be to predict future accidents in advance, giving drivers chances to avoid the dangers or reduce the damage by responding quickly. Predicting accidents on the road can be achieved using classification analysis, a datamining procedure requiring enough data to build a learning model.However, building such a predicting system involves several problems. It requires many hardware resources to collect and analyze traffic data for predicting traffic accidents since the data are extremely large. Furthermore, the size of data related to traffic accidents is less than that not related to traffic accidents; the amounts of the two classes (classes to be predicted and other classes) of data differ and are thus imbalanced. The purpose of this paper is to build a predicting model that can resolve all these problems. This paper suggests using the Hadoop framework to process and analyze big traffic data efficiently and a sampling method to resolve the problem of data imbalance. Based on this, the predicting system first preprocesses the big traffic data and analyzes it to create data for the learning system. The imbalance of created data is corrected using a sampling method. To improve the predicting accuracy, corrected data are classified into several groups, to which classification analysis is applied.},
author = {Park, Seong-hun and Kim, Sung-min and Ha, Young-guk},
doi = {10.1007/s11227-016-1624-z},
isbn = {1122701616},
issn = {0920-8542},
journal = {The Journal of Supercomputing},
number = {7},
pages = {2815--2831},
title = {{Highway traffic accident prediction using VDS big data analysis}},
url = {http://link.springer.com/10.1007/s11227-016-1624-z},
volume = {72},
year = {2016}
}
@article{JulienJacquesQuentinGrimonprez,
author = {{Julien Jacques, Quentin Grimonprez}, Christophe Biernacki},
title = {{Rankcluster: An R package for clustering multivariate partial rankings}}
}
@article{Yu2013b,
abstract = {Freeway crash occurrences are highly influenced by geometric characteristics, traffic status, weather conditions and drivers' behavior. For a mountainous freeway which suffers from adverse weather conditions, it is critical to incorporate real-time weather information and traffic data in the crash frequency study. In this paper, a Bayesian inference method was employed to model one year's crash data on I-70 in the state of Colorado. Real-time weather and traffic variables, along with geometric characteristics variables were evaluated in the models. Two scenarios were considered in this study, one seasonal and one crash type based case. For the methodology part, the Poisson model and two random effect models with a Bayesian inference method were employed and compared in this study. Deviance Information Criterion (DIC) was utilized as a comparison factor. The correlated random effect models outperformed the others. The results indicate that the weather condition variables, especially precipitation, play a key role in the crash occurrence models. The conclusions imply that different active traffic management strategies should be designed based on seasons, and single-vehicle crashes have different crash mechanism compared to multi-vehicle crashes. ?? 2012 Elsevier Ltd.},
author = {Yu, Rongjie and Abdel-Aty, Mohamed and Ahmed, Mohamed},
doi = {10.1016/j.aap.2012.05.011},
issn = {00014575},
journal = {Accident Analysis and Prevention},
keywords = {Bayesian inference,Mountainous freeway safety,Real-time weather data and random effect model},
pages = {371--376},
pmid = {22658460},
title = {{Bayesian random effect models incorporating real-time weather and traffic data to investigate mountainous freeway hazardous factors}},
volume = {50},
year = {2013}
}
@article{Xu2013,
abstract = {Real-time crash risk prediction using traffic data collected from loop detector stations is useful in dynamic safety management systems aimed at improving traffic safety through application of proactive safety countermeasures. The major drawback of most of the existing studies is that they focus on the crash risk without consideration of crash severity. This paper presents an effort to develop a model that predicts the crash likelihood at different levels of severity with a particular focus on severe crashes. The crash data and traffic data used in this study were collected on the I-880 freeway in California, United States. This study considers three levels of crash severity: fatal/incapacitating injury crashes (KA), non-incapacitating/possible injury crashes (BC), and property-damage-only crashes (PDO). The sequential logit model was used to link the likelihood of crash occurrences at different severity levels to various traffic flow characteristics derived from detector data. The elasticity analysis was conducted to evaluate the effect of the traffic flow variables on the likelihood of crash and its severity.The results show that the traffic flow characteristics contributing to crash likelihood were quite different at different levels of severity. The PDO crashes were more likely to occur under congested traffic flow conditions with highly variable speed and frequent lane changes, while the KA and BC crashes were more likely to occur under less congested traffic flow conditions. High speed, coupled with a large speed difference between adjacent lanes under uncongested traffic conditions, was found to increase the likelihood of severe crashes (KA). This study applied the 20-fold cross-validation method to estimate the prediction performance of the developed models. The validation results show that the model's crash prediction performance at each severity level was satisfactory. The findings of this study can be used to predict the probabilities of crash at different severity levels, which is valuable knowledge in the pursuit of reducing the risk of severe crashes through the use of dynamic safety management systems on freeways. ?? 2013 Elsevier Ltd. All rights reserved.},
author = {Xu, Chengcheng and Tarko, Andrew P. and Wang, Wei and Liu, Pan},
doi = {10.1016/j.aap.2013.03.035},
isbn = {0001-4575},
issn = {00014575},
journal = {Accident Analysis and Prevention},
keywords = {Crash risk prediction,Crash severity,Freeway,Real-time safety management,Sequential logit model},
pages = {30--39},
pmid = {23628940},
title = {{Predicting crash likelihood and severity on freeways with real-time loop detector data}},
volume = {57},
year = {2013}
}
@article{Horvitz2012,
abstract = {We present research on developing models that forecast traffic flow and congestion in the Greater Seattle area. The research has led to the deployment of a service named JamBayes, that is being actively used by over 2,500 users via smartphones and desktop versions of the system. We review the modeling effort and describe experiments probing the predictive accuracy of the models. Finally, we present research on building models that can identify current and future surprises, via efforts on modeling and forecasting unexpected situations.},
archivePrefix = {arXiv},
arxivId = {1207.1352},
author = {Horvitz, Eric J. and Apacible, Johnson and Sarin, Raman and Liao, Lin},
eprint = {1207.1352},
isbn = {0-9749039-1-4},
journal = {Conference on Uncertainty in Artificial Intelligence},
pages = {1--10},
title = {{Prediction, Expectation, and Surprise: Methods, Designs, and Study of a Deployed Traffic Forecasting Service}},
url = {http://arxiv.org/abs/1207.1352},
year = {2012}
}
@article{Li2013,
abstract = {Pavement condition has been known as a key factor related to ride quality, but it is less clear how exactly pavement conditions are related to traffic crashes. The researchers used Geographic Information System (GIS) to link Texas Department of Transportation (TxDOT) Crash Record Information System (CRIS) data and Pavement Management Information System (PMIS) data, which provided an opportunity to examine the impact of pavement conditions on traffic crashes in depth. The study analyzed the correlation between several key pavement condition ratings or scores and crash severity based on a large number of crashes in Texas between 2008 and 2009. The results in general suggested that poor pavement condition scores and ratings were associated with proportionally more severe crashes, but very poor pavement conditions were actually associated with less severe crashes. Very good pavement conditions might induce speeding behaviors and therefore could have caused more severe crashes, especially on non-freeway arterials and during favorable driving conditions. In addition, the results showed that the effects of pavement conditions on crash severity were more evident for passenger vehicles than for commercial vehicles. These results provide insights on how pavement conditions may have contributed to crashes, which may be valuable for safety improvement during pavement design and maintenance. Readers should notice that, although the study found statistically significant effects of pavement variables on crash severity, the effects were rather minor in reality as suggested by frequency analyses. ?? 2013 Elsevier Ltd. All rights reserved.},
author = {Li, Yingfeng and Liu, Chunxiao and Ding, Liang},
doi = {10.1016/j.aap.2013.06.028},
isbn = {0001-4575},
issn = {00014575},
journal = {Accident Analysis and Prevention},
keywords = {Condition score,Crash severity,Distress score,International roughness index,Multiple comparison procedures,Pavement condition,Pavement type},
pages = {399--406},
pmid = {23892046},
title = {{Impact of pavement conditions on crash severity}},
volume = {59},
year = {2013}
}
@article{Yu2013a,
abstract = {Introduction This study provides a systematic approach to investigate the different characteristics of weekday and weekend crashes. Method Weekend crashes were defined as crashes occurring between Friday 9 p.m. and Sunday 9 p.m., while the other crashes were labeled as weekday crashes. In order to reveal the various features for weekday and weekend crashes, multi-level traffic safety analyses have been conducted. For the aggregate analysis, crash frequency models have been developed through Bayesian inference technique; correlation effects of weekday and weekend crash frequencies have been accounted. A multivariate Poisson model and correlated random effects Poisson model were estimated; model goodness-of-fits have been compared through DIC values. In addition to the safety performance functions, a disaggregate crash time propensity model was calibrated with Bayesian logistic regression model. Moreover, in order to account for the cross-section unobserved heterogeneity, random effects Bayesian logistic regression model was employed. Results It was concluded that weekday crashes are more probable to happen during congested sections, while the weekend crashes mostly occur under free flow conditions. Finally, for the purpose of confirming the aforementioned conclusions, real-time crash prediction models have been developed. Random effects Bayesian logistic regression models incorporating the microscopic traffic data were developed. Results of the real-time crash prediction models are consistent with the crash time propensity analysis. Furthermore, results from these models would shed some lights on future geometric improvements and traffic management strategies to improve traffic safety. Impact on Industry Utilizing safety performance to identify potential geometric improvements to reduce crash occurrence and monitoring real-time crash risks to pro-actively improve traffic safety. ?? 2013 Elsevier Ltd.},
author = {Yu, Rongjie and Abdel-Aty, Mohamed},
doi = {10.1016/j.jsr.2013.05.002},
issn = {00224375},
journal = {Journal of Safety Research},
keywords = {Bayesian logistic regression,Mountainous freeway traffic safety,Multivariate,Poisson model,Random effects,Weekend crash},
pages = {91--97},
pmid = {23932690},
title = {{Investigating the different characteristics of weekday and weekend crashes}},
volume = {46},
year = {2013}
}
@article{Wang2015a,
abstract = {Weaving segments are potential recurrent bottlenecks which affect the efficiency and safety of expressways during peak hours. Meanwhile, they are one of the most complicated segments, since on- and off-ramp traffic merges, diverges and weaves in the limited space. One effective way to improve the safety of weaving segments is to study crash likelihood using real-time crash data with the objective of, identifying hazardous conditions and reducing the risk of crashes by Intelligent Transportation Systems (ITS) traffic control. This study presents a multilevel Bayesian logistic regression model for crashes at expressway weaving segments using crash, geometric, Microwave Vehicle Detection System (MVDS) and weather data. The results show that the mainline speed at the beginning of the weaving segments, the speed difference between the beginning and the end of weaving segment, logarithm of volume have significant impacts on the crash risk of the following 5-10. min for weaving segments. The configuration is also an important factor. Weaving segment, in which there is no need for on- or off-ramp traffic to change lane, is with high crash risk because it has more traffic interactions and higher speed differences between weaving and non-weaving traffic. Meanwhile, maximum length, which measures the distance at which weaving turbulence no longer has impact, is found to be positively related to the crash risk at the 95{\%} confidence interval. In addition to traffic and geometric factors, wet pavement surface condition significantly increases the crash ratio by 77{\%}. The proposed model along with ITS, e.g., ramp metering, Dynamic Message Sign (DMS), and high friction surface treatment can be used to enhance the safety of weaving segments in real-time.},
author = {Wang, Ling and Abdel-Aty, Mohamed and Shi, Qi and Park, Juneyoung},
doi = {10.1016/j.trc.2015.10.008},
issn = {0968090X},
journal = {Transportation Research Part C: Emerging Technologies},
keywords = {Expressway weaving segments,Maximum length,Multilevel Bayesian logistic regression model,Real-time crash analysis},
pages = {1--10},
title = {{Real-time crash prediction for expressway weaving segments}},
volume = {61},
year = {2015}
}
@article{Wang2013,
abstract = {The analysis of road network designs can provide useful information to transportation planners as they seek to improve the safety of road networks. The objectives of this study were to compare and define the effective road network indices and to analyze the relationship between road network structure and traffic safety at the level of the Traffic Analysis Zone (TAZ). One problem in comparing different road networks is establishing criteria that can be used to scale networks in terms of their structures. Based on data from Orange and Hillsborough Counties in Florida, road network structural properties within TAZs were scaled using 3 indices: Closeness Centrality, Betweenness Centrality, and Meshedness Coefficient. The Meshedness Coefficient performed best in capturing the structural features of the road network. Bayesian Conditional Autoregressive (CAR) models were developed to assess the safety of various network configurations as measured by total crashes, crashes on state roads, and crashes on local roads. The models' results showed that crash frequencies on local roads were closely related to factors within the TAZs (e.g., zonal network structure, TAZ population), while crash frequencies on state roads were closely related to the road and traffic features of state roads. For the safety effects of different networks, the Grid type was associated with the highest frequency of crashes, followed by the Mixed type, the Loops {\&} Lollipops type, and the Sparse type. This study shows that it is possible to develop a quantitative scale for structural properties of a road network, and to use that scale to calculate the relationships between network structural properties and safety. ?? 2013 Elsevier Ltd. All rights reserved.},
author = {Wang, Xuesong and Wu, Xingwei and Abdel-Aty, Mohamed and Tremont, Paul J.},
doi = {10.1016/j.aap.2013.02.026},
isbn = {0001-4575},
issn = {00014575},
journal = {Accident Analysis and Prevention},
keywords = {Bayesian Conditional Autoregressive model,Betweenness Centrality,Closeness Centrality,Meshedness Coefficient,Road network structures,Safety performance,Traffic analysis zone},
pages = {22--31},
pmid = {23584537},
title = {{Investigation of road network features and safety performance}},
volume = {56},
year = {2013}
}
@article{Montella2010,
abstract = {The identification of crash hotspots is the first step of the highway safety management process. Errors in hotspot identification may result in the inefficient use of resources for safety improvements and may reduce the global effectiveness of the safety management process. Despite the importance of using effective hotspot identification (HSID) methods, only a few researchers have compared the performance of various methods. In this research, seven commonly applied HSID methods were compared against four robust and informative quantitative evaluation criteria. The following HSID methods were compared: crash frequency (CF), equivalent property damage only (EPDO) crash frequency, crash rate (CR), proportion method (P), empirical Bayes estimate of total-crash frequency (EB), empirical Bayes estimate of severe-crash frequency (EBs), and potential for improvement (PFI). The HSID methods were compared using the site consistency test, the method consistency test, the total rank differences test, and the total score test. These tests evaluate each HSID method's performance in a variety of areas, such as efficiency in identifying sites that show consistently poor safety performance, reliability in identifying the same hotspots in subsequent time periods, and ranking consistency. To evaluate the HSID methods, five years of crash data from the Italian motorway A16 were used. The quantitative evaluation tests showed that the EB method performs better than the other HSID methods. Test results highlight that the EB method is the most consistent and reliable method for identifying priority investigation locations. The EB expected frequency of total-crashes (EB) performed better than the EB expected frequency of severe-crashes (EBs), although the results differed only slightly when the number of identified hotspots increased. The CF method performed better than other HSID methods with more appealing theoretical arguments. In particular, the CF method performed better than the CR method. This result is quite alarming, since many agencies use the CR method. The PFI and EPDO methods were largely inconsistent. The proportion method performed worst in all of the tests. Overall, these results are consistent with the results of previous studies. The identification of engineering countermeasures that may reduce crashes was successful in all of the hotspots identified with the EB method; this finding shows that the identified hotspots can also be corrected. The advantages associated with the EB method were based on crash data from one Italian motorway, and the relative performances of HSID methods may change when using other crash data. However, the study results are very significant and are consistent with earlier findings. To further clarify the benefits of the EB method, this study should be replicated in other countries. Nevertheless, the study results, combined with previous research results, strongly suggest that the EB method should be the standard in the identification of hotspots. ?? 2009 Elsevier Ltd. All rights reserved.},
author = {Montella, Alfonso},
doi = {10.1016/j.aap.2009.09.025},
isbn = {0817683941},
issn = {00014575},
journal = {Accident Analysis and Prevention},
keywords = {Crash prediction models,Empirical Bayes method,Engineering countermeasures,Hotspots,Quantitative evaluation criteria,Ranking criteria},
number = {2},
pages = {571--581},
pmid = {20159081},
title = {{A comparative analysis of hotspot identification methods}},
volume = {42},
year = {2010}
}
@article{Yu2015,
abstract = {Freeway crashes are highly influenced by weather conditions, especially for a mountainous freeway affected by adverse weather conditions. In order to reduce crash occurrence, a variety of weather monitoring systems and Intelligent Transportation Systems (ITS) have been introduced to address the weather impact. However, the effects of weather conditions on crash occurrence have not been fully investigated and understood. With detailed weather information from weather monitoring stations, this study seeks to investigate the complex effects of weather factors, such as visibility and precipitation, on crash occurrence based on safety performance functions. Unlike conventional traffic safety studies which deal with crash frequency, crash rates per 100. million vehicle miles travelled were adopted as the dependent variable in this study. Three years of weather related crash data from a 15. mile mountainous freeway on I-70 in Colorado were utilized. First, a fixed parameter Tobit model was estimated to unveil the effects of explanatory variables on crash rates. Then, in order to characterize the heterogeneous effects of weather conditions across the homogeneous segments, a traditional random parameter Tobit model was developed. Furthermore, for the purpose of monitoring the intricate interactions between weather conditions and geometric characteristics, a multivariate structure for the distribution of random parameters was introduced; which result in a correlated random parameter Tobit model. Likelihood ratio test results demonstrated that the correlated random parameter Tobit model was superior to the uncorrelated random parameter and fixed parameter Tobit models. Moreover, visibility and precipitation variables were found to have substantial correlations with geometric characteristics like steep downgrade slopes and curve segments. Results from the models will shed lights on future applications of weather warning systems to improve traffic safety.},
author = {Yu, Rongjie and Xiong, Yingge and Abdel-Aty, Mohamed},
doi = {10.1016/j.trc.2014.09.016},
isbn = {0968-090X},
issn = {0968090X},
journal = {Transportation Research Part C: Emerging Technologies},
keywords = {Aggregate traffic safety,Correlated random parameter model,Tobit model,Weather warning system},
pages = {68--77},
title = {{A correlated random parameter approach to investigate the effects of weather conditions on crash risk for a mountainous freeway}},
volume = {50},
year = {2015}
}
@article{Deublein2013,
abstract = {In this paper a novel methodology for the prediction of the occurrence of road accidents is presented. The methodology utilizes a combination of three statistical methods: (1) gamma-updating of the occurrence rates of injury accidents and injured road users, (2) hierarchical multivariate Poisson-lognormal regression analysis taking into account correlations amongst multiple dependent model response variables and effects of discrete accident count data e.g. over-dispersion, and (3) Bayesian inference algorithms, which are applied by means of data mining techniques supported by Bayesian Probabilistic Networks in order to represent non-linearity between risk indicating and model response variables, as well as different types of uncertainties which might be present in the development of the specific models. Prior Bayesian Probabilistic Networks are first established by means of multivariate regression analysis of the observed frequencies of the model response variables, e.g. the occurrence of an accident, and observed values of the risk indicating variables, e.g. degree of road curvature. Subsequently, parameter learning is done using updating algorithms, to determine the posterior predictive probability distributions of the model response variables, conditional on the values of the risk indicating variables. The methodology is illustrated through a case study using data of the Austrian rural motorway network. In the case study, on randomly selected road segments the methodology is used to produce a model to predict the expected number of accidents in which an injury has occurred and the expected number of light, severe and fatally injured road users. Additionally, the methodology is used for geo-referenced identification of road sections with increased occurrence probabilities of injury accident events on a road link between two Austrian cities. It is shown that the proposed methodology can be used to develop models to estimate the occurrence of road accidents for any road network provided that the required data are available. ?? 2012 Elsevier Ltd.},
author = {Deublein, Markus and Schubert, Matthias and Adey, Bryan T. and Kohler, Jochen and Faber, Michael H.},
doi = {10.1016/j.aap.2012.11.019},
isbn = {00014575 (ISSN)},
issn = {00014575},
journal = {Accident Analysis and Prevention},
keywords = {Accident prediction,Accident risk modelling,Bayesian Probabilistic Networks,Hierarchical Bayes,Injury accidents,Multivariate regression analysis,Road safety assessment},
pages = {274--291},
pmid = {23277309},
title = {{Prediction of road accidents: A Bayesian hierarchical approach}},
volume = {51},
year = {2013}
}
@article{Shi2016,
abstract = {With the rapid growth of traffic in urban areas, concerns about congestion and traffic safety have been heightened. This study leveraged both Automatic Vehicle Identification (AVI) system and Microwave Vehicle Detection System (MVDS) installed on an expressway in Central Florida to explore how congestion impacts the crash occurrence in urban areas. Multiple congestion measures from the two systems were developed. To ensure more precise estimates of the congestion's effects, the traffic data were aggregated into peak and non-peak hours. Multicollinearity among traffic parameters was examined. The results showed the presence of multicollinearity especially during peak hours. As a response, ridge regression was introduced to cope with this issue. Poisson models with uncorrelated random effects, correlated random effects, and both correlated random effects and random parameters were constructed within the Bayesian framework. It was proven that correlated random effects could significantly enhance model performance. The random parameters model has similar goodness-of-fit compared with the model with only correlated random effects. However, by accounting for the unobserved heterogeneity, more variables were found to be significantly related to crash frequency. The models indicated that congestion increased crash frequency during peak hours while during non-peak hours it was not a major crash contributing factor. Using the random parameter model, the three congestion measures were compared. It was found that all congestion indicators had similar effects while Congestion Index (CI) derived from MVDS data was a better congestion indicator for safety analysis. Also, analyses showed that the segments with higher congestion intensity could not only increase property damage only (PDO) crashes, but also more severe crashes. In addition, the issues regarding the necessity to incorporate specific congestion indicator for congestion's effects on safety and to take care of the multicollinearity between explanatory variables were also discussed. By including a specific congestion indicator, the model performance significantly improved. When comparing models with and without ridge regression, the magnitude of the coefficients was altered in the existence of multicollinearity. These conclusions suggest that the use of appropriate congestion measure and consideration of multicolilnearity among the variables would improve the models and our understanding about the effects of congestion on traffic safety.},
author = {Shi, Qi and Abdel-Aty, Mohamed and Lee, Jaeyoung},
doi = {10.1016/j.aap.2015.12.001},
isbn = {0001-4575},
issn = {00014575},
journal = {Accident Analysis and Prevention},
keywords = {Bayesian inference,Congestion,Ridge regression,Urban expressway safety},
pages = {124--137},
pmid = {26760688},
title = {{A Bayesian ridge regression analysis of congestion's impact on urban expressway safety}},
volume = {88},
year = {2016}
}
@article{Golob2008,
abstract = {In this paper we lay the groundwork for gauging the level of safety of any type of traffic flow on a freeway, based on data from single loop detectors; the procedure can be implemented wherever such data are monitored or simulated. Our analyses are based on loop detector data for each of the freeway lanes for a short period of time preceding teach of over 1700 accidents in our case study. This case study covers the six major freeways in Orange County, California, for a six-month period in 2001. Recognizing that loop detector data at a specific time and place cannot be converted to speed, because it is not possible to know effective vehicle length at such a detailed level (that is, the mix of long and short vehicles is unknown at a specific place for a short period of time), we avoid using any direct speed or density measures among the parameters. Rather, we employ explanatory parameters that include not only central tendencies (means and medians), but variations, and measures of systematic and synchronized traits that capture patterns in short period of loop detector data. Such patterns include breakdown from free flow to congested operations or recovery back to free flow, and differences in traffic conditions across lanes. In the analysis, we uncover an extensive set of statistical parameters that capture those aspects of traffic flow that are strongly related to accident potential. We demonstrate that the parameters can account for speed and density, even though these are not used directly. Moreover, the parameters account for important differences among the types of accidents that occur under different types of traffic flow. ?? 2007.},
author = {Golob, Thomas F. and Recker, Will and Pavlis, Yannis},
doi = {10.1016/j.ssci.2007.08.007},
issn = {09257535},
journal = {Safety Science},
keywords = {Accidents,Factor analysis,Freeway safety,Loop detector data,Multinomial logit,Statistical analysis,Traffic flow},
number = {9},
pages = {1306--1333},
title = {{Probabilistic models of freeway safety performance using traffic flow data as predictors}},
volume = {46},
year = {2008}
}
@article{Chiou2006,
abstract = {This paper employs artificial neural network (ANN) to develop an accident appraisal expert system. Two ANN models - party-based and case-based - with different hidden neurons are trained and validated by k-fold (k = 3) cross validation method. A total of 537 two-car crash accidents (1074 parties involved) are randomly and equally divided into three subsets. For the comparison, a discrimination analysis (DA) model is also calibrated. The results show that the ANN model can achieve a high correctness rate of 85.72{\%} in training and 77.91{\%} in validation and a low Schwarz's Bayesian information criterion (SBC) of -0.82 in training and 0.13 in validation, which indicates that the ANN model is suitable for accident appraisal. Furthermore, in order to measure the importance of each explanatory variable, a general influence (GI) index is computed based on the trained weights of ANN. It is found that the most influential variable is right-of-way, followed by location and alcoholic use. This finding concurs with the prior knowledge in accident appraisal. Thus, for the fair assessment of accident liabilities the correctness of these three key variables is of critical importance to police investigation reports. ?? 2006 Elsevier Ltd. All rights reserved.},
author = {Chiou, Yu Chiun},
doi = {10.1016/j.aap.2006.02.006},
isbn = {0001-4575},
issn = {00014575},
journal = {Accident Analysis and Prevention},
keywords = {Accident appraisal,Artificial neural network,Discrimination analysis,Expert system},
number = {4},
pages = {777--785},
pmid = {16556433},
title = {{An artificial neural network-based expert system for the appraisal of two-car crash accidents}},
volume = {38},
year = {2006}
}
@misc{Golob2004,
abstract = {In this paper, we present evidence of strong relationships between traffic flow conditions and the likelihood of traffic accidents (crashes), by type of crash. Traffic flow variables are measured using standard monitoring devices such as single inductive loop detectors. The key traffic flow elements that affect safety are found to be mean volume and median speed, and temporal variations in volume and speed, where variations need to be distinguished by freeway lane. We demonstrate how these relationships can form the basis for a tool that monitors the real-time safety level of traffic flow on an urban freeway. Such a safety performance monitoring tool can also be used in cost-benefit evaluations of projects aimed at mitigating congestion, by comparing the levels of safety of traffic flows patterns before and after project implementation. ?? 2003 Elsevier Ltd. All rights reserved.},
author = {Golob, Thomas F. and Recker, Wilfred W. and Alvarez, Veronica M.},
booktitle = {Accident Analysis and Prevention},
doi = {10.1016/j.aap.2003.09.006},
isbn = {0001-4575},
issn = {00014575},
keywords = {Accident rates,Congested flow,Fundamental diagram,Loop detectors,Speed,Traffic density,Traffic flow,Traffic safety},
number = {6},
pages = {933--946},
pmid = {15350870},
title = {{Freeway safety as a function of traffic flow}},
volume = {36},
year = {2004}
}
@article{Wang2015,
abstract = {Limited research has been conducted on real-time crash analysis of expressway ramps, although there have been many studies in recent years on estimating real-time crash prediction models for main lines. This study presents Bayesian logistic regression models for single-vehicle (SV) and multivehicle (MV) crashes on expressway ramps by using real-time microwave vehicle detection system data, real-time weather data, and ramp geometric information. The results find that the logarithm of the vehicle count, average speed in a 5-min interval, and visibility are significant factors for the occurrence of SV and MV crashes. The Bayesian logistic regression models show that curved ramps and wet road surfaces would increase the possibility of an SV crash, and off-ramps would result in high risk of MV crashes. The high standard deviation of speed in a 5-min interval would significantly increase MV crash likelihood. Random Forests software was applied in variable importance analysis, and the results revealed that the m...},
author = {Wang, Ling and Shi, Qi and Abdel-Aty, Mohamed},
doi = {10.3141/2514-04},
isbn = {10.3141/2514-04},
issn = {0361-1981},
journal = {Transportation Research Record: Journal of the Transportation Research Board},
number = {2514},
pages = {32--38},
title = {{Predicting Crashes on Expressway Ramps with Real-Time Traffic and Weather Data}},
url = {http://trrjournalonline.trb.org/doi/abs/10.3141/2514-04},
year = {2015}
}
@article{Yu2014,
abstract = {This paper investigates the effects of microscopic traffic, weather, and roadway geometric factors on the occurrence of specific crash types for a freeway. The I-70 Freeway was chosen for this paper since automatic vehicle identification (AVI) and weather detection systems are implemented along this corridor. A main objective of this paper is to expand the purpose of the existing intelligent transportation system to incorporate traffic safety improvement and suggest active traffic management (ATM) strategies by identifying the real-time crash patterns. Crashes have been categorized as rear-end, sideswipe, and single-vehicle crashes. AVI segment average speed, real-time weather data, and roadway geometric characteristic data were utilized as explanatory variables in this paper. First, binary logistic regression models were estimated to compare single- with multivehicle crashes and sideswipe with rear-end crashes. Then, a hierarchical logistic regression model that simultaneously fits two conditional logistic regression models for the three crash types has been developed. Results from the models indicate that single-vehicle crashes are more likely to occur in snowy seasons, at moderate slopes, three-lane segments, and under free-flow conditions, whereas the sideswipe crash occurrence differs from rear-end crashes with the visibility situation, segment number of lanes, grades, and their directions (up or down). Furthermore, the innovative way of estimating two conditional logistic regression models simultaneously in the Bayesian framework fits the correlated data structure well. Conclusions from this paper imply that different ATM strategies should be designed for three- and two-lane roadway sections and are also considering the seasonal effects.},
author = {Yu, Rongjie and Abdel-Aty, Mohamed A. and Ahmed, Mohamed M. and Wang, Xuesong},
doi = {10.1109/TITS.2013.2276089},
issn = {15249050},
journal = {IEEE Transactions on Intelligent Transportation Systems},
keywords = {Active traffic management (ATM),crash-type analysis,intelligent transportation system (ITS),microscopic crash analysis,random effect logistic regression,real-time data},
number = {1},
pages = {205--213},
title = {{Utilizing microscopic traffic and weather data to analyze real-time crash patterns in the context of active traffic management}},
volume = {15},
year = {2014}
}
@article{Yu2013,
abstract = {Real-time crash risk evaluation models will likely play a key role in Active Traffic Management (ATM). Models have been developed to predict crash occurrence in order to proactively improve traffic safety. Previous real-time crash risk evaluation studies mainly employed logistic regression and neural network models which have a linear functional form and over-fitting drawbacks, respectively. Moreover, these studies mostly focused on estimating the models but barely investigated the models' predictive abilities. In this study, support vector machine (SVM), a recently proposed statistical learning model was introduced to evaluate real-time crash risk. The data has been split into a training dataset (used for developing the models) and scoring datasets (meant for assessing the models' predictive power). Classification and regression tree (CART) model has been developed to select the most important explanatory variables and based on the results, three candidates Bayesian logistic regression models have been estimated with accounting for different levels unobserved heterogeneity. Then SVM models with different kernel functions have been developed and compared to the Bayesian logistic regression model. Model comparisons based on areas under the ROC curve (AUC) demonstrated that the SVM model with Radial-basis kernel function outperformed the others. Moreover, several extension analyses have been conducted to evaluate the effect of sample size on SVM models' predictive capability; the importance of variable selection before developing SVM models; and the effect of the explanatory variables in the SVM models. Results indicate that (1) smaller sample size would enhance the SVM model's classification accuracy, (2) variable selection procedure is needed prior to the SVM model estimation, and (3) explanatory variables have identical effects on crash occurrence for the SVM models and logistic regression models. ?? 2012 Elsevier Ltd.},
author = {Yu, Rongjie and Abdel-Aty, Mohamed},
doi = {10.1016/j.aap.2012.11.027},
issn = {00014575},
journal = {Accident Analysis and Prevention},
keywords = {Bayesian logistic regression,Mountainous freeway safety,Real-time crash risk evaluation,Support vector machine model},
pages = {252--259},
pmid = {23287112},
title = {{Utilizing support vector machine in real-time crash risk evaluation}},
volume = {51},
year = {2013}
}
@book{UNWTO2016,
author = {UNWTO},
title = {{UNWTO Tourism Highlights, 2016 Edition}},
url = {http://www.e-unwto.org/doi/pdf/10.18111/9789284418145},
year = {2016}
}
@misc{R,
address = {Vienna, Austria},
annote = {{\{}ISBN{\}} 3-900051-07-0},
author = {{R Development Core Team}},
institution = {R Foundation for Statistical Computing},
title = {{R: A Language and Environment for Statistical Computing}},
url = {http://www.r-project.org},
year = {2008}
}
@inproceedings{Ceberio2016,
author = {Ceberio, Josu and Mendiburu, Alexander and Lozano, Jose A.},
booktitle = {XI Congreso Espa{\~{n}}ol de Metaheuristicas, Algoritmos Evolutivos y Bioinspirados (MAEB-2016) (Accepted)},
title = {{A Note on the Boltzmann Distribution and the Linear Ordering Problem}},
year = {2016}
}
@inproceedings{Ceberio2015,
address = {Madrid},
author = {Ceberio, Josu and Mendiburu, Alexander and Lozano, Jose A.},
booktitle = {Genetic and Evolutionary Computation Conference (GECCO-2015)},
pages = {505----512},
title = {{Kernels of Mallows Models for Solving Permutation-based Problems}},
year = {2015}
}
@article{fligner1990,
abstract = {In the situation where subjects independently rank order a fixed set of items, the idea of a consensus ordering of the items is defined and employed as a parameter in a class of probability models for rankings. In the context of such models, which generalize those of Mallows, posterior probabilities may be easily formed about the population consensus ordering. An example of rankings obtained by the Graduate Record Examination Board is presented to demonstrate the adequacy of these generalized Mallows' models for describing actual data sets of rankings and to illustrate convenient summaries of the posterior probabilities for the consensus ordering.},
author = {Fligner, Michael A and Verducci, Joseph S},
doi = {10.1007/BF02294743},
issn = {1860-0980},
journal = {Psychometrika},
number = {1},
pages = {53--63},
title = {{Posterior probabilities for a consensus ordering}},
url = {http://dx.doi.org/10.1007/BF02294743},
volume = {55},
year = {1990}
}
@article{meila2016,
author = {Meila, Marina and Chen, Harr},
doi = {10.1109/TPAMI.2016.2515599},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
title = {{Bayesian non-parametric clustering of ranking data}},
year = {2016}
}
@inproceedings{wang2004bipartite,
author = {Wang, Yuhang and Makedon, Fillia and Ford, James and Huang, Heng},
booktitle = {Engineering in Medicine and Biology Society, 2004. IEMBS'04. 26th Annual International Conference of the IEEE},
organization = {IEEE},
pages = {2972--2975},
title = {{A bipartite graph matching framework for finding correspondences between structural elements in two proteins}},
volume = {2},
year = {2004}
}
@inproceedings{lecun1998,
author = {LeCun, Yann and Bottou, L{\'{e}}on and Bengio, Yoshua and Haffner, Patrick},
booktitle = {Proceedings of the IEEE},
keywords = {MSc character{\_}recognition checked mnist network ne},
number = {11},
pages = {2278--2324},
title = {{Gradient-Based Learning Applied to Document Recognition}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.42.7665},
volume = {86},
year = {1998}
}
@article{Belongie:2002:SMO:628328.628792,
address = {Washington, DC, USA},
author = {Belongie, S and Malik, J and Puzicha, J},
doi = {10.1109/34.993558},
issn = {0162-8828},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
keywords = {MPEG7,correspondence problem,deformable templates,digit recognition,image registration,object recognition,shape},
number = {4},
pages = {509--522},
publisher = {IEEE Computer Society},
title = {{Shape Matching and Object Recognition Using Shape Contexts}},
url = {http://dx.doi.org/10.1109/34.993558},
volume = {24},
year = {2002}
}
@article{Apellido,
author = {Apellido, Primer and Nacimiento, Fecha De and Apellido, Segundo},
title = {{Ii. norberen datuak / ii. datos personales}}
}
@incollection{Schwartz2005,
author = {Schwartz, Justus and Steger, Angelika and Wei{\ss}l, Andreas},
booktitle = {Experimental and Efficient Algorithms},
doi = {10.1007/11427186_41},
editor = {Nikoletseas, SotirisE.},
isbn = {978-3-540-25920-6},
pages = {476--487},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Fast Algorithms for Weighted Bipartite Matching}},
url = {http://dx.doi.org/10.1007/11427186{\_}41},
volume = {3503},
year = {2005}
}
@article{KunchevaIJMLC10,
author = {Kuncheva, L I},
doi = {DOI 10.1007/s13042-010-0002-z},
journal = {International Journal of Machine Learning and Cybernetics},
number = {1},
pages = {53--61},
title = {{Full-class Set classification using the Hungarian algorithm}},
volume = {1},
year = {2010}
}
@article{Flajolet1994,
abstract = {A systematic approach to the random generation of labelled combinatorial objects is presented. It applies to structures that are decomposable, i.e., formally specifiable by grammars involving set, sequence, and cycle constructions. A general strategy is developed for solving the random generation problem with two closely related types of methods: for structures of size n, the boustrophedonic algorithms exhibit a worst-case behaviour of the form O(n log n); the sequential algorithms have worst case O(n2), while offering good potential for optimizations in the average case. The complexity model is in terms of arithmetic operations and both methods appeal to precomputed numerical table of linear size that can be computed in time O(n2). A companion calculus permits systematically to compute the average case cost of the sequential generation algorithm associated to a given specification. Using optimizations dictated by the cost calculus, several random generation algorithms of the sequential type are developed; most of them have expected complexity 1/2n log n, and are thus only slightly superlinear. The approach is exemplified by the random generation of a number of classical combinatorial structures including Cayley trees, hierarchies, the cycle decomposition of permutations, binary trees, functional graphs, surjections, and set partitions.},
author = {Flajolet, Philippe and Zimmermann, Paul and {Van Cutsem}, Bernard},
doi = {10.1016/0304-3975(94)90226-7},
file = {:Users/ekhi/Library/Application Support/Mendeley Desktop/Downloaded/Flajolet, Zimmermann, Van Cutsem - 1994 - A calculus for the random generation of labelled combinatorial structures.pdf:pdf},
issn = {03043975},
journal = {Theoretical Computer Science},
month = {sep},
number = {1-2},
pages = {1--35},
title = {{A calculus for the random generation of labelled combinatorial structures}},
url = {http://www.sciencedirect.com/science/article/pii/0304397594902267},
volume = {132},
year = {1994}
}
@inproceedings{chierichetti_et_al:LIPIcs:2014:4725,
abstract = {The Mallows model is a classical model for generating noisy perturbations of a hidden permuta- tion, where the magnitude of the perturbations is determined by a single parameter. In this work we consider the following reconstruction problem: given several perturbations of a hidden permutation that are generated according to the Mallows model, each with its own parameter, how to recover the hidden permutation? When the parameters are approximately known and sat- isfy certain conditions, we obtain a simple algorithm for reconstructing the hidden permutation; we also show that these conditions are nearly inevitable for reconstruction. We then provide an algorithm to estimate the parameters themselves. En route we obtain a precise characterization of the swapping probability in the Mallows model.},
address = {Dagstuhl, Germany},
annote = {Keywords: Mallows model; Rank aggregation; Reconstruction},
author = {Chierichetti, Flavio and Dasgupta, Anirban and Kumar, Ravi and Lattanzi, Silvio},
booktitle = {Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques (APPROX/RANDOM 2014)},
doi = {http://dx.doi.org/10.4230/LIPIcs.APPROX-RANDOM.2014.604},
editor = {Jansen, Klaus and Rolim, Jos{\'{e}} D P and Devanur, Nikhil R and Moore, Cristopher},
isbn = {978-3-939897-74-3},
issn = {1868-8969},
pages = {604--617},
publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
series = {Leibniz International Proceedings in Informatics (LIPIcs)},
title = {{On Reconstructing a Hidden Permutation}},
url = {http://drops.dagstuhl.de/opus/volltexte/2014/4725},
volume = {28},
year = {2014}
}
@inproceedings{Chierichetti2015,
address = {New York, NY, USA},
author = {Chierichetti, Flavio and Dasgupta, Anirban and Kumar, Ravi and Lattanzi, Silvio},
booktitle = {Proceedings of the 2015 Conference on Innovations in Theoretical Computer Science},
doi = {10.1145/2688073.2688111},
isbn = {978-1-4503-3333-7},
keywords = {mallows models,mixture models,permutations,ranking aggregation},
pages = {85--92},
publisher = {ACM},
series = {ITCS '15},
title = {{On Learning Mixture Models for Permutations}},
url = {http://doi.acm.org/10.1145/2688073.2688111},
year = {2015}
}
@inproceedings{Kumar:2013:RQ:2433396.2433416,
address = {New York, NY, USA},
author = {Kumar, Ravi and Lempel, Ronny and Schwartz, Roy and Vassilvitskii, Sergei},
booktitle = {Proceedings of the Sixth ACM International Conference on Web Search and Data Mining},
doi = {10.1145/2433396.2433416},
isbn = {978-1-4503-1869-3},
keywords = {bucketization of static ranks,rank linearization},
pages = {153--162},
publisher = {ACM},
series = {WSDM '13},
title = {{Rank Quantization}},
url = {http://doi.acm.org/10.1145/2433396.2433416},
year = {2013}
}
@article{DBLP:journals/siamcomp/ChierichettiK14,
abstract = {study rules that output a single winner.They study a setting with a single correct alternative and noisy signals about its identity. Focusing on a single voting rule — the plurality rule — they give an upper bound on the number of votes that are required to pinpoint the correct winner. They also prove a lower bound that applies to any voting rule and suggests that plurality is not far from optimal.},
author = {Chierichetti, Flavio and Kleinberg, Jon M},
doi = {10.1137/130936592},
journal = {{\{}SIAM{\}} J. Comput.},
keywords = {They study a setting with a single correct alterna},
number = {5},
pages = {1615--1653},
title = {{Voting with Limited Information and Many Alternatives}},
url = {http://dx.doi.org/10.1137/130936592},
volume = {43},
year = {2014}
}
@incollection{Afshani:QC:2013,
author = {Afshani, Peyman and Agrawal, Manindra and Doerr, Benjamin and Doerr, Carola and Larsen, KasperGreen and Mehlhorn, Kurt},
booktitle = {Space-Efficient Data Structures, Streams, and Algorithms},
doi = {10.1007/978-3-642-40273-9_1},
editor = {Brodnik, Andrej and L{\'{o}}pez-Ortiz, Alejandro and Raman, Venkatesh and Viola, Alfredo},
isbn = {978-3-642-40272-2},
pages = {1--11},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{The Query Complexity of Finding a Hidden Permutation}},
url = {http://dx.doi.org/10.1007/978-3-642-40273-9{\_}1},
volume = {8066},
year = {2013}
}
@inproceedings{Dalvi:2013:ACB:2488388.2488414,
address = {Republic and Canton of Geneva, Switzerland},
author = {Dalvi, Nilesh and Dasgupta, Anirban and Kumar, Ravi and Rastogi, Vibhor},
booktitle = {Proceedings of the 22Nd International Conference on World Wide Web},
isbn = {978-1-4503-2035-1},
keywords = {crowdsourcing,mechanical turk,spectral methods},
pages = {285--294},
publisher = {International World Wide Web Conferences Steering Committee},
series = {WWW '13},
title = {{Aggregating Crowdsourced Binary Ratings}},
url = {http://dl.acm.org/citation.cfm?id=2488388.2488414},
year = {2013}
}
@book{marden1996analyzing,
author = {Marden, John I},
isbn = {9780412995217},
publisher = {Taylor {\&} Francis},
series = {Chapman {\&} Hall/CRC Monographs on Statistics {\&} Applied Probability},
title = {{Analyzing and Modeling Rank Data}},
url = {https://books.google.es/books?id=Dp24H21QHNoC},
year = {1996}
}
@inproceedings{DBLP:conf/aldt/LuB11,
author = {Lu, Tyler and Boutilier, Craig},
booktitle = {Algorithmic Decision Theory},
doi = {10.1007/978-3-642-24873-3_11},
editor = {Brafman, Ronen I and Roberts, Fred S and Tsouki{\`{a}}s, Alexis},
pages = {135--149},
publisher = {Springer},
series = {Lecture Notes in Computer Science},
title = {{Vote Elicitation with Probabilistic Preference Models: Empirical Estimation and Cost Tradeoffs}},
url = {http://dx.doi.org/10.1007/978-3-642-24873-3{\_}11},
volume = {6992},
year = {2011}
}
@inproceedings{DBLP:conf/icml/Busa-FeketeHS14,
author = {Busa-Fekete, R{\'{o}}bert and H{\"{u}}llermeier, Eyke and Sz{\"{o}}r{\'{e}}nyi, Bal{\'{a}}zs},
booktitle = {Proceedings of the 31th International Conference on Machine Learning, (ICML)},
pages = {1071--1079},
title = {{Preference-Based Rank Elicitation using Statistical Models: The Case of Mallows}},
url = {http://jmlr.org/proceedings/papers/v32/busa-fekete14.html},
year = {2014}
}
@inproceedings{burges2005learning,
author = {Burges, Chris and Shaked, Tal and Renshaw, Erin and Lazier, Ari and Deeds, Matt and Hamilton, Nicole and Hullender, Greg},
booktitle = {Proceedings of the 22nd international conference on Machine learning},
organization = {ACM},
pages = {89--96},
title = {{Learning to rank using gradient descent}},
year = {2005}
}
@article{Coppersmith:2010,
author = {Coppersmith, Don and Fleischer, Lisa K and Rurda, Atri},
doi = {10.1145/1798596.1798608},
issn = {1549-6325},
journal = {ACM Trans. Algorithms},
keywords = {Approximation algorithms,Borda's method,feedback arc set problem,rank aggregation,tournaments},
month = {jul},
number = {3},
pages = {1--13},
publisher = {ACM},
title = {{Ordering by Weighted Number of Wins Gives a Good Ranking for Weighted Tournaments}},
volume = {6},
year = {2010}
}
@techreport{REAL12467,
abstract = {Nagym{\{}{\'{e}}{\}}ret{\{}$\backslash$Hu{\}} gr{\{}{\'{a}}{\}}fok strukt{\{}{\'{u}}{\}}r{\{}{\'{a}}{\}}j{\{}{\'{a}}{\}}nak felt{\{}{\'{a}}{\}}r{\{}{\'{a}}{\}}s{\{}{\'{a}}{\}}ra alkalmaztunk {\{}{\'{e}}{\}}s fejlesztett{\{}{\"{u}}{\}}nk ki param{\{}{\'{e}}{\}}teres {\{}{\'{e}}{\}}s nemparam{\{}{\'{e}}{\}}teres statisztikai m{\{}{\'{o}}{\}}dszereket. Param{\{}{\'{e}}{\}}teres vizsg{\{}{\'{a}}{\}}latok: az {\{}{\'{u}}{\}}n. {\{}{\'{a}}{\}}ltal{\{}{\'{a}}{\}}nos{\{}$\backslash$'i{\}}tott v{\{}{\'{e}}{\}}letlen gr{\{}{\'{a}}{\}}f modellben {\{}{\'{e}}{\}}s az alpha-beta-modellekben a param{\{}{\'{e}}{\}}terek maximum likelihood becsl{\{}{\'{e}}{\}}s{\{}{\'{e}}{\}}re EM-algoritmust haszn{\{}{\'{a}}{\}}ltunk. A modellt a Rasch-modell p{\{}{\'{a}}{\}}ros gr{\{}{\'{a}}{\}}fokra t{\{}{\"{o}}{\}}rt{\{}{\'{e}}{\}}n{\{}$\backslash$Ho{\}} alkalmaz{\{}{\'{a}}{\}}s{\{}{\'{a}}{\}}val kiterjesztett{\{}{\"{u}}{\}}k a t{\{}{\"{o}}{\}}bbklaszteres szitu{\{}{\'{a}}{\}}ci{\{}{\'{o}}{\}}ra. Nemparam{\{}{\'{e}}{\}}teres vizsg{\{}{\'{a}}{\}}latok: minim{\{}{\'{a}}{\}}lis, maxim{\{}{\'{a}}{\}}lis {\{}{\'{e}}{\}}s regul{\{}{\'{a}}{\}}ris v{\{}{\'{a}}{\}}g{\{}{\'{a}}{\}}sok. A klaszterek sz{\{}{\'{a}}{\}}m{\{}{\'{a}}{\}}ra a norm{\{}{\'{a}}{\}}lt Laplace ill. modularit{\{}{\'{a}}{\}}s m{\{}{\'{a}}{\}}trix saj{\{}{\'{a}}{\}}t{\{}{\'{e}}{\}}rt{\{}{\'{e}}{\}}keib{\{}$\backslash$Ho{\}}l k{\{}{\"{o}}{\}}vetkeztett{\{}{\"{u}}{\}}nk, m{\{}$\backslash$'i{\}}g maguknak a klasztereknek a megkeres{\{}{\'{e}}{\}}s{\{}{\'{e}}{\}}re a k-k{\{}{\"{o}}{\}}z{\{}{\'{e}}{\}}p elj{\{}{\'{a}}{\}}r{\{}{\'{a}}{\}}st alkalmaztuk a cs{\{}{\'{u}}{\}}csreprezent{\{}{\'{a}}{\}}nsok seg{\{}$\backslash$'i{\}}ts{\{}{\'{e}}{\}}g{\{}{\'{e}}{\}}vel. T{\{}{\'{e}}{\}}teleket bizony{\{}$\backslash$'i{\}}tottunk a v{\{}{\'{a}}{\}}g{\{}{\'{a}}{\}}sok, a t{\{}{\'{e}}{\}}rfogatregularit{\{}{\'{a}}{\}}s m{\{}{\'{e}}{\}}r{\{}$\backslash$Ho{\}}sz{\{}{\'{a}}{\}}ma, a spektr{\{}{\'{a}}{\}}lis r{\{}{\'{e}}{\}}s {\{}{\'{e}}{\}}s a klaszterek k-varianci{\{}{\'{a}}{\}}ja k{\{}{\"{o}}{\}}zti {\{}{\"{o}}{\}}sszef{\{}{\"{u}}{\}}gg{\{}{\'{e}}{\}}sekre, ha cs{\{}{\'{u}}{\}}csok sz{\{}{\'{a}}{\}}ma tart a v{\{}{\'{e}}{\}}gtelenbe {\{}{\'{u}}{\}}gy, hogy nincsen domin{\{}{\'{a}}{\}}ns cs{\{}{\'{u}}{\}}cs. {\{}{\'{A}}{\}}ltal{\{}{\'{a}}{\}}nos{\{}$\backslash$'i{\}}tottuk az {\{}{\'{u}}{\}}n. Newman-Girvan modularit{\{}{\'{a}}{\}}st, {\{}{\'{e}}{\}}s a norm{\{}{\'{a}}{\}}lt modularit{\{}{\'{a}}{\}}s m{\{}{\'{a}}{\}}trix nagy abszol{\{}{\'{u}}{\}}t {\{}{\'{e}}{\}}rt{\{}{\'{e}}{\}}k{\{}$\backslash$Hu{\}} saj{\{}{\'{a}}{\}}t{\{}{\'{e}}{\}}rt{\{}{\'{e}}{\}}keit {\{}{\'{e}}{\}}s azok el{\{}$\backslash$Ho{\}}jel{\{}{\'{e}}{\}}t haszn{\{}{\'{a}}{\}}ltuk a klaszterek jelleg{\{}{\'{e}}{\}}nek meg{\{}{\'{a}}{\}}llap{\{}$\backslash$'i{\}}t{\{}{\'{a}}{\}}s{\{}{\'{a}}{\}}ra. Az {\{}{\'{a}}{\}}ltal{\{}{\'{a}}{\}}nos{\{}$\backslash$'i{\}}tott v{\{}{\'{e}}{\}}letlen gr{\{}{\'{a}}{\}}fok spektr{\{}{\'{a}}{\}}lis karakteriz{\{}{\'{a}}{\}}ci{\{}{\'{o}}{\}}j{\{}{\'{a}}{\}}t adtuk a struktur{\{}{\'{a}}{\}}lis saj{\{}{\'{a}}{\}}t{\{}{\'{e}}{\}}rt{\{}{\'{e}}{\}}kek {\{}{\'{e}}{\}}s saj{\{}{\'{a}}{\}}talterek seg{\{}$\backslash$'i{\}}ts{\{}{\'{e}}{\}}g{\{}{\'{e}}{\}}vel. Vizsg{\{}{\'{a}}{\}}latainkat kiterjesztett{\{}{\"{u}}{\}}k s{\{}{\'{u}}{\}}lyozott, ir{\{}{\'{a}}{\}}ny{\{}$\backslash$'i{\}}tott gr{\{}{\'{a}}{\}}fokra {\{}{\'{e}}{\}}s kontingenciat{\{}{\'{a}}{\}}bl{\{}{\'{a}}{\}}kra is. Foglalkoztunk tov{\{}{\'{a}}{\}}bb{\{}{\'{a}}{\}} minim{\{}{\'{a}}{\}}lis t{\{}{\"{o}}{\}}bbszempont{\{}{\'{u}}{\}} v{\{}{\'{a}}{\}}g{\{}{\'{a}}{\}}ss{\{}$\backslash$Hu{\}}r{\{}$\backslash$Hu{\}}s{\{}{\'{e}}{\}}gek tesztelhet{\{}$\backslash$Ho{\}}s{\{}{\'{e}}{\}}g{\{}{\'{e}}{\}}vel a Lov{\{}{\'{a}}{\}}sz L. {\{}{\'{e}}{\}}s t{\{}{\'{a}}{\}}rsszerz{\{}$\backslash$Ho{\}}i {\{}{\'{a}}{\}}ltal konvergens gr{\{}{\'{a}}{\}}fsorozatokn{\{}{\'{a}}{\}}l haszn{\{}{\'{a}}{\}}lt {\{}{\'{e}}{\}}rtelemben. {\{}$\backslash$ensuremath{\{}|{\}}{\}} We applied and developed parametric and nonparametric statistical methods to recover the structure of large graphs. Parametric inference: in the so-called generalized random graph model and alpha- beta-models we applied EM-algorithm for the maximum likelihood estimation of the parameters. We extended the model to the several clusters case via the Rasch-model applied to the bipartite graphs formed by the pairs of the clusters. Nonparametric inference: minimal, maximal, and regular cuts. For the number of clusters, we concluded from the spectra of the Laplacian and modularity matrices, whereas we found the clusters by the k-means algorithm applied for the vertex representatives. We proved theorems for the relations between the multiway cuts, the constant of the volume-regularity, and the spectral gap together with the k-variance of the clusters, when the number of the vertices tends to infinity in such a way that there are no dominant vertices. We generalized the notion of the so-called Newman-Girvan modularity and gave the spectral characterization of the generalized random graphs. We extended our findings to weighted and directed graphs, further, to contingency tables. We also investigated the testability of balanced multiway cut densities, where for the testability we used the definitions of Lov{\{}{\'{a}}{\}}sz L. and coauthors in the context of convergent graph sequences.},
author = {Tusn{\'{a}}dy, G{\'{a}}bor and Bolla, Marianna and Csisz{\'{a}}r, Villo and Kr{\'{a}}mli, Andr{\'{a}}s and Mikl{\'{o}}s, Dezs$\backslash$Ho},
booktitle = {OTKA Kutat{\{}{\'{a}}{\}}si Jelent{\{}{\'{e}}{\}}sek {\{}$\backslash$ensuremath{\{}|{\}}{\}} OTKA Research Reports},
keywords = {Matematika},
publisher = {OTKA},
title = {{Nagym{\{}{\'{e}}{\}}ret{\{}$\backslash$Hu{\}} v{\{}{\'{e}}{\}}letlen gr{\{}{\'{a}}{\}}fok statisztikai vizsg{\{}{\'{a}}{\}}lata = Statistical inference on large random graphs}},
type = {Project Report},
url = {http://real.mtak.hu/12467/},
year = {2013}
}
@article{bttree,
author = {Strobl, C and Wickelmaier, F and Zeileis, A},
journal = {Journal of Educational and Behavioral Statistics},
number = {2},
pages = {135--153},
title = {{Accounting for Individual Differences in Bradley-Terry Models by Means of Recursive Partitioning}},
volume = {36},
year = {2011}
}
@article{BradleyTerry2,
author = {Turner, Heather and Firth, David},
journal = {Journal of Statistical Software},
number = {9},
pages = {1--21},
title = {{Bradley-Terry Models in {\{}$\backslash$proglang{\{}R{\}}{\}}: The {\{}$\backslash$pkg{\{}BradleyTerry2{\}}{\}} Package}},
url = {http://www.jstatsoft.org/v48/i09/},
volume = {48},
year = {2012}
}
@article{Lee1013,
author = {Lee, Paul H and Yu, Philip L H},
doi = {10.1186/1471-2288-13-65},
journal = {BMC Medical Research Methodology},
keywords = {Distance-based model,Luce model,Multidimensional},
number = {1},
publisher = {BioMed Central},
title = {{An {\{}$\backslash$proglang{\{}R{\}}{\}} package for analyzing and modeling ranking data}},
url = {http://dx.doi.org/10.1186/1471-2288-13-65},
volume = {13},
year = {2013}
}
@misc{OEIS,
author = {Sloane, Neil James Alexander},
booktitle = {http://oeis.org/},
title = {{On-Line Encyclopedia of Integer Sequences, http://oeis.org/}},
url = {http://oeis.org/},
year = {2009}
}
@misc{sloane_ulam,
abstract = {count of permutations at each ulam distance},
author = {Sloane, Neil James Alexander},
booktitle = {https://oeis.org/A126065},
title = {{Triangle of numbers by length of the longest increasing subsequence, https://oeis.org/A126065}},
url = {https://oeis.org/A126065},
year = {2009}
}
@misc{sloane_hamming,
abstract = {number of permutations at each hamming distance},
author = {Sloane, Neil James Alexander},
booktitle = {https://oeis.org/A000166},
title = {{Subfactorial or rencontres numbers, or derangements, https://oeis.org/A000166}},
url = {https://oeis.org/A000166},
year = {2009}
}
@misc{Sloane_cayley,
abstract = {Number of permutations at each Cayley distance},
author = {Sloane, Neil James Alexander},
booktitle = {https://oeis.org/A008275},
title = {{Triangle read by rows of Stirling numbers of first kind, https://oeis.org/A008275}},
url = {https://oeis.org/A008275},
year = {2009}
}
@misc{Sloane_kendall,
abstract = {count of permutations at each kendall distance},
author = {Sloane, Neil James Alexander},
booktitle = {https://oeis.org/A008302},
title = {{Triangle of Mahonian numbers, https://oeis.org/A008302}},
url = {https://oeis.org/A008302},
year = {2009}
}
@inproceedings{DBLP:conf/isnn/2009-1,
booktitle = {ISNN (1)},
editor = {Yu, Wen and He, Haibo and Zhang, Nian},
isbn = {978-3-642-01506-9},
publisher = {Springer-Verlag},
series = {Lecture Notes in Computer Science},
title = {{Advances in Neural Networks - ISNN 2009, 6th International Symposium on Neural Networks, ISNN 2009, Wuhan, China, May 26-29, 2009, Proceedings, Part I}},
volume = {5551},
year = {2009}
}
@article{journals/corr/BuzagloYEB13,
abstract = {The goal of this paper is to construct systematic error-correcting codes for permutations and multi-permutations in the Kendall's {\$}\backslashtau{\$}-metric. These codes are important in new applications such as rank modulation for flash memories. The construction is based on error-correcting codes for multi-permutations and a partition of the set of permutations into error-correcting codes. For a given large enough number of information symbols {\$}k{\$}, and for any integer {\$}t{\$}, we present a construction for {\$}{\{}(k+r,k){\}}{\$} systematic {\$}t{\$}-error-correcting codes, for permutations from {\$}S{\_}{\{}k+r{\}}{\$}, with less redundancy symbols than the number of redundancy symbols in the codes of the known constructions. In particular, for a given {\$}t{\$} and for sufficiently large {\$}k{\$} we can obtain {\$}r=t+1{\$}. The same construction is also applied to obtain related systematic error-correcting codes for multi-permutations.},
archivePrefix = {arXiv},
arxivId = {1311.7113},
author = {Buzaglo, Sarit and Yaakobi, Eitan and Etzion, Tuvi and Bruck, Jehoshua},
eprint = {1311.7113},
journal = {Computing Research Repository},
month = {nov},
title = {{Systematic Codes for Rank Modulation}},
url = {http://arxiv.org/abs/1311.7113},
year = {2013}
}
@inproceedings{GenerateLandscapes,
address = {Catania, Italy},
author = {Hernando, Leticia and Mendiburu, Alexander and Lozano, Jose A.},
booktitle = {Learning and Intelligent OptimizatioN Conference (LION 7)},
title = {{Generating Customized Landscapes in Permutation-based Combinatorial Optimization Problems}},
year = {2013}
}
@inproceedings{conf/wads/BaderMY01,
author = {Bader, David A and Moret, Bernard M E and Yan, Mi},
booktitle = {Algorithms and Data Structures Symposium (WADS)},
isbn = {3-540-42423-7},
keywords = {dblp},
pages = {365--376},
publisher = {Springer-Verlag},
series = {Lecture Notes in Computer Science},
title = {{A Linear-Time Algorithm for Computing Inversion Distance between Signed Permutations with an Experimental Study.}},
url = {http://dblp.uni-trier.de/db/conf/wads/wads2001.html{\#}BaderMY01},
volume = {2125},
year = {2001}
}
@incollection{Vaudenay95,
author = {Vaudenay, Serge},
booktitle = {Fast Software Encryption},
doi = {10.1007/3-540-60590-8_22},
isbn = {978-3-540-60590-4},
pages = {286--297},
publisher = {Springer-Verlag},
series = {Lecture Notes in Computer Science},
title = {{On the need for multipermutations: Cryptanalysis of MD4 and SAFER}},
url = {http://dx.doi.org/10.1007/3-540-60590-8{\_}22},
volume = {1008},
year = {1995}
}
@article{diaconis1976spearmans,
author = {Diaconis, Persi and Graham, R L},
journal = {Journal of the Royal Statistical Society B},
keywords = {DA paper rankings},
number = {2},
title = {{Spearman's Footrule as a Measure of Disarray}},
volume = {39},
year = {1977}
}
@article{DBLP:journals/tit/FarnoudSM13,
author = {Farnoud, Farzad and Skachek, Vitaly and Milenkovic, Olgica},
journal = {IEEE Transactions on Information Theory},
number = {5},
pages = {3003--3020},
title = {{Error-Correction in Flash Memories via Codes in the Ulam Metric}},
volume = {59},
year = {2013}
}
@article{DBLP:journals/jsac/HassanzadehM14,
author = {Hassanzadeh, Farzad Farnoud and Milenkovic, Olgica},
journal = {IEEE Journal on Selected Areas in Communications},
number = {5},
pages = {919--932},
title = {{Multipermutation Codes in the Ulam Metric for Nonvolatile Memories}},
volume = {32},
year = {2014}
}
@inproceedings{conf/icml/BleiF10,
author = {Blei, David M and Frazier, Peter},
booktitle = {International Conference on Machine Learning (ICML)},
isbn = {978-1-60558-907-7},
keywords = {dblp},
pages = {87--94},
publisher = {Omnipress},
title = {{Distance dependent Chinese restaurant processes.}},
url = {http://dblp.uni-trier.de/db/conf/icml/icml2010.html{\#}BleiF10},
year = {2010}
}
@article{arratia1992,
author = {Arratia, Richard and Tavare, Simon},
doi = {10.1214/aop/1176989707},
journal = {The Annals of Probability},
number = {3},
pages = {1567--1591},
publisher = {The Institute of Mathematical Statistics},
title = {{The Cycle Structure of Random Permutations}},
url = {http://dx.doi.org/10.1214/aop/1176989707},
volume = {20},
year = {1992}
}
@book{Deza.Deza2009EncyclopediaofDistances,
author = {Deza, Michel Marie and Deza, Elena},
doi = {10.1007/978-3-642-00234-2_1},
publisher = {Springer-Verlag},
title = {{Encyclopedia of Distances}},
year = {2009}
}
@article{journals/toc/CharikarK06,
author = {Charikar, Moses and Krauthgamer, Robert},
journal = {Theory of Computing},
keywords = {dblp},
number = {1},
pages = {207--224},
title = {{Embedding the Ulam metric into l1.}},
url = {http://dblp.uni-trier.de/db/journals/toc/toc2.html{\#}CharikarK06},
volume = {2},
year = {2006}
}
@article{Gessel1993189,
abstract = {The number of permutations with given cycle structure and descent set is shown to be equal to the scalar product of two special characters of the symmetric group. Enumerative applications are given to cycles, involutions and derangements. },
author = {Gessel, Ira M and Reutenauer, Christophe},
doi = {http://dx.doi.org/10.1016/0097-3165(93)90095-P},
issn = {0097-3165},
journal = {Journal of Combinatorial Theory, Series A},
number = {2},
pages = {189--215},
title = {{Counting permutations with given cycle structure and descent set}},
url = {http://www.sciencedirect.com/science/article/pii/009731659390095P},
volume = {64},
year = {1993}
}
@techreport{Beame2009,
abstract = {The sequence a{\_}1,...,a{\_}m is a common subsequence in the set of permutations S = {\{}p{\_}1,...,p{\_}k{\}} on [n] if it is a subsequence of p{\_}i(1),...,p{\_}i(n) and p{\_}j(1),...,p{\_}j(n) for some distinct p{\_}i, p{\_}j in S. Recently, Beame and Huynh-Ngoc (2008) showed that when k{\textgreater}=3, every set of k permutations on [n] has a common subsequence of length at least n{\^{}}{\{}1/3{\}}. We show that, surprisingly, this lower bound is asymptotically optimal for all constant values of k. Specifically, we show that for any k{\textgreater}=3 and n{\textgreater}=k{\^{}}2 there exists a set of k permutations on [n] in which the longest common subsequence has length at most 32(kn){\^{}}{\{}1/3{\}}. The proof of the upper bound is constructive, and uses elementary algebraic techniques.},
archivePrefix = {arXiv},
arxivId = {0904.1615},
author = {Beame, Paul and Blais, Eric and Huynh-Ngoc, Dang-Trinh},
eprint = {0904.1615},
month = {apr},
title = {{Longest Common Subsequences in Sets of Permutations}},
url = {http://arxiv.org/abs/0904.1615},
year = {2009}
}
@inproceedings{conf/nips/FioriSVMS13,
author = {Fiori, Marcelo and Sprechmann, Pablo and Vogelstein, Joshua T and Mus{\'{e}}, Pablo and Sapiro, Guillermo},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
keywords = {dblp},
pages = {127--135},
title = {{Robust Multimodal Graph Matching: Sparse Coding Meets Graph Matching.}},
url = {http://dblp.uni-trier.de/db/conf/nips/nips2013.html{\#}FioriSVMS13},
year = {2013}
}
@inproceedings{conf/nips/PachauriKS13,
author = {Pachauri, Deepti and Kondor, Risi and Singh, Vikas},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
keywords = {dblp},
pages = {1860--1868},
title = {{Solving the multi-way matching problem by permutation synchronization.}},
url = {http://dblp.uni-trier.de/db/conf/nips/nips2013.html{\#}PachauriKS13},
year = {2013}
}
@article{Beckman1957,
author = {Beckman, M and Koopmans, T C},
journal = {Econometrica},
keywords = {imported},
pages = {53--76},
title = {{Assignment problems and the location of economic activities}},
volume = {25},
year = {1957}
}
@incollection{journals/corr/abs-0904-2623,
author = {Petterson, James and Caetano, Tib{\'{e}}rio S and McAuley, Julian John and Yu, Jin},
booktitle = {Advances in Neural Information Processing Systems 22},
keywords = {dblp},
pages = {1455----1463},
title = {{Exponential Family Graph Matching and Ranking}},
url = {http://dblp.uni-trier.de/db/journals/corr/corr0904.html{\#}abs-0904-2623},
volume = {abs/0904.2},
year = {2009}
}
@inproceedings{conf/nips/VolkovsZ12,
author = {Volkovs, Maksims and Zemel, Richard S},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
keywords = {dblp},
pages = {1322--1330},
title = {{Efficient Sampling for Bipartite Matching Problems.}},
url = {http://dblp.uni-trier.de/db/conf/nips/nips2012.html{\#}VolkovsZ12},
year = {2012}
}
@article{Hardy:427613,
author = {Hardy, Godfrey Harold and Ramanujan, Srinivasa Aiyangar},
journal = {Journal London Mathematical Society},
pages = {75--115},
title = {{Asymptotic formulae in combinatory analysis}},
volume = {17},
year = {1918}
}
@book{rademacher1937partition,
author = {Rademacher, H},
publisher = {Hodgson},
title = {{On the Partition Function P(n)}},
url = {http://books.google.es/books?id=8{\_}gwygAACAAJ},
year = {1937}
}
@article{baik1999distribution,
author = {Baik, Jinho and Deift, Percy and Johansson, Kurt},
journal = {Journal of the American Mathematical Society},
number = {4},
pages = {1119--1178},
title = {{On the distribution of the length of the longest increasing subsequence of random permutations}},
volume = {12},
year = {1999}
}
@inproceedings{conf/focs/SaksS10,
author = {Saks, Michael and Seshadhri, C},
booktitle = {Foundations of Computer Science, FOCS},
isbn = {978-0-7695-4244-7},
keywords = {dblp},
pages = {458--467},
publisher = {IEEE Computer Society},
title = {{Estimating the Longest Increasing Sequence in Polylogarithmic Time.}},
url = {http://dblp.uni-trier.de/db/conf/focs/focs2010.html{\#}SaksS10},
year = {2010}
}
@inproceedings{conf/soda/AndoniN10,
author = {Andoni, Alexandr and Nguyen, Huy L},
booktitle = {Symposium on Discrete Algorithms, SODA},
keywords = {dblp},
pages = {76--86},
title = {{Near-Optimal Sublinear Time Algorithms for Ulam Distance.}},
url = {http://dblp.uni-trier.de/db/conf/soda/soda2010.html{\#}AndoniN10},
year = {2010}
}
@article{JonkerLAP,
address = {New York, NY, USA},
author = {Jonker, R and Volgenant, A},
doi = {10.1007/BF02278710},
issn = {0010-485X},
journal = {The Netherlands Computing},
number = {4},
pages = {325--340},
publisher = {Springer-Verlag},
title = {{A Shortest Augmenting Path Algorithm for Dense and Sparse Linear Assignment Problems}},
url = {http://dx.doi.org/10.1007/BF02278710},
volume = {38},
year = {1987}
}
@book{numerical_recipes_c,
address = {New York, NY, USA},
author = {Press, William H and Teukolsky, Saul A and Vetterling, William T and Flannery, Brian P},
isbn = {0-521-43108-5},
publisher = {Cambridge University Press},
title = {{Numerical Recipes in C (2Nd Ed.): The Art of Scientific Computing}},
year = {1992}
}
@article{Lee20122486,
author = {Lee, Paul H and Yu, Philip L H},
doi = {http://dx.doi.org/10.1016/j.csda.2012.02.002},
issn = {0167-9473},
journal = {Computational Statistics {\&} Data Analysis},
keywords = {Distance-based models,Mixtures models,Ranking data},
number = {8},
pages = {2486--2500},
title = {{Mixtures of weighted distance-based models for ranking data with applications in political studies}},
url = {http://www.sciencedirect.com/science/article/pii/S0167947312000679},
volume = {56},
year = {2012}
}
@book{Larranaga:2001:EDA,
address = {Norwell, MA, USA},
author = {Larra{\~{n}}aga, Pedro and Lozano, Jose A.},
isbn = {0792374665},
publisher = {Kluwer Academic Publishers},
title = {{Estimation of Distribution Algorithms: A New Tool for Evolutionary Computation}},
year = {2001}
}
@article{babington,
author = {{Babington Smith}, B},
journal = {Journal of the Royal Statistical Society},
pages = {153--162},
title = {{Discussion on professor Ross's paper}},
volume = {12},
year = {1950}
}
@article{feray2012,
abstract = {The purpose of this article is to present a general method to find limiting laws for some renormalized statistics on random permutations. The model of random permutations considered here is Ewens sampling model, which generalizes uniform random permutations. Under this model, we describe the asymptotic behavior of some statistics, including the number of occurrences of any dashed pattern. Our approach is based on the method of moments and relies on the following intuition: two events involving the images of different integers are almost independent.},
author = {F{\'{e}}ray, Valentin},
journal = {Electronic Journal of Probability},
number = {76},
pages = {1--32},
title = {{Asymptotics of some statistics in Ewens random permutations}},
volume = {18},
year = {2013}
}
@article{Hullermeier201049,
annote = {Special Issue on Intelligent Data Analysis},
author = {H{\"{u}}llermeier, Eyke and F{\"{u}}rnkranz, Johannes},
doi = {http://dx.doi.org/10.1016/j.jcss.2009.05.005},
issn = {0022-0000},
journal = {Journal of Computer and System Sciences},
keywords = {Label ranking,Machine learning,Pairwise classification,Preference learning,Rank correlation,Ranking error,Risk minimization},
number = {1},
pages = {49--62},
title = {{On predictive accuracy and risk minimization in pairwise label ranking}},
url = {http://www.sciencedirect.com/science/article/pii/S0022000009000440},
volume = {76},
year = {2010}
}
@article{Knuth,
author = {Knuth, Donald E},
journal = {Pacific Journal of Mathematics},
keywords = {imported},
pages = {709--727},
title = {{Permutations, matrices and generalized Young tableaux}},
volume = {34},
year = {1970}
}
@article{Schensted1961,
author = {Schensted, Craige},
doi = {10.4153/CJM-1961-015-3},
journal = {Canadian Journal of Mathematics},
pages = {179--191},
title = {{Longest increasing and decreasing subsequences}},
volume = {13},
year = {1961}
}
@article{robinson1938,
author = {Robinson, Gilbert de Beauregard},
doi = {10.2307/2371609},
journal = {American Journal of Mathematics},
number = {3},
pages = {745--760},
title = {{On the representation of the symmetric group}},
volume = {60},
year = {1938}
}
@article{journals/jal/FranzblauZ82,
author = {Franzblau, Deborah S and Zeilberger, Doron},
journal = {Journal of Algorithms},
keywords = {dblp},
number = {4},
pages = {317--343},
title = {{A Bijective Proof of the Hook-Length Formula.}},
url = {http://dblp.uni-trier.de/db/journals/jal/jal3.html{\#}FranzblauZ82},
volume = {3},
year = {1982}
}
@article{journals/dmtcs/NovelliPS97,
author = {Novelli, Jean-Christophe and Pak, Igor and Stoyanovskii, Alexander V},
journal = {Discrete Mathematics {\&} Theoretical Computer Science},
keywords = {dblp},
number = {1},
pages = {53--67},
title = {{A direct bijective proof of the hook-length formula.}},
url = {http://dblp.uni-trier.de/db/journals/dmtcs/dmtcs1.html{\#}NovelliPS97},
volume = {1},
year = {1997}
}
@article{journals/combinatorics/Bandlow08,
author = {Bandlow, Jason},
journal = {The Electronic Journal of Combinatorics},
keywords = {dblp},
number = {1},
title = {{An Elementary Proof of the Hook Formula.}},
url = {http://dblp.uni-trier.de/db/journals/combinatorics/combinatorics15.html{\#}Bandlow08},
volume = {15},
year = {2008}
}
@article{journals/tamm/GlassN04,
author = {Glass, Kenneth and Ng, Chi-Keung},
journal = {The American Mathematical Monthly},
keywords = {dblp},
number = {8},
pages = {700--704},
title = {{A Simple Proof of the Hook Length Formula.}},
url = {http://dblp.uni-trier.de/db/journals/tamm/tamm111.html{\#}GlassN04},
volume = {111},
year = {2004}
}
@article{Yao1999,
author = {Yao, Grace and B{\"{o}}ckenholt, Ulf},
doi = {10.1348/000711099158973},
issn = {2044-8317},
journal = {British Journal of Mathematical and Statistical Psychology},
number = {1},
pages = {79--92},
publisher = {Blackwell Publishing Ltd},
title = {{Bayesian estimation of Thurstonian ranking models based on the Gibbs sampler}},
url = {http://dx.doi.org/10.1348/000711099158973},
volume = {52},
year = {1999}
}
@article{Maydeu_Olivares01paired,
abstract = {We relate Thurstonian models for paired comparisons data to Thurstonian models for ranking data, which assign zero probabilities to all intransitive patterns. We also propose an intermediate model for paired comparisons data that assigns nonzero probabilities to all transitive patterns and to some but not all intransitive patterns.There is a close correspondence between the multidimensional normal ogive model employed in educational testing and Thurstone's model for paired comparisons data under multiple judgment sampling with minimal identification restrictions. Alike the normal ogive model, Thurstonian models have two formulations, a factor analytic and an IRT formulation. We use the factor analytic formulation to estimate this model from the first and second order marginals of the contingency table using estimators proposed by Muth{\'{e}}n. We also propose a statistic to assess the fit of these models to the first and second order marginals of the contingency table. This is important, as a model may reproduce well the estimated thresholds and tetrachoric correlations, yet fail to reproduce the marginals of the contingency table if the assumption of multivariate normality is incorrect.A simulation study is performed to investigate the performance of three alternative limited information estimators which differ in the procedure used in their final stage: unweighted least squares (ULS), diagonally weighted least squares (DWLS), and full weighted least squares (WLS). Both the ULS and DWLS show a good performance with medium size problems and small samples, with a slight better performance of the ULS estimator.},
author = {Maydeu-Olivares, Albert},
doi = {10.1007/bf02294836},
issn = {0033-3123},
journal = {Psychometrika},
keywords = {gt{\_}quevirco,gts{\_}paired,gts{\_}sensory},
number = {2},
pages = {209--227},
publisher = {Springer-Verlag},
title = {{Limited information estimation and testing of Thurstonian models for paired comparison data under multiple judgment sampling}},
url = {http://dx.doi.org/10.1007/bf02294836},
volume = {66},
year = {2001}
}
@article{journals/mss/Maydeu-Olivares02,
author = {Maydeu-Olivares, Alberto},
journal = {Mathematical Social Sciences},
keywords = {dblp},
number = {3},
pages = {467--483},
title = {{Limited information estimation and testing of Thurstonian models for preference data.}},
url = {http://dblp.uni-trier.de/db/journals/mss/mss43.html{\#}Maydeu-Olivares02},
volume = {43},
year = {2002}
}
@article{Maydeu-Olivares1999,
author = {Maydeu-Olivares, Alberto},
journal = {Psychometrika},
keywords = {GMM; GLS; WLS estimation; UMD; ULS; EWMD estimatio},
number = {3},
pages = {325--340},
title = {{Thurstonian modeling of ranking data via mean and covariance structure analysis}},
url = {http://econpapers.repec.org/RePEc:spr:psycho:v:64:y:1999:i:3:p:325-340},
volume = {64},
year = {1999}
}
@techreport{Chen04,
abstract = {As people increasingly rely on interactive decision support systems to choose products and make decisions, building effective interfaces for these systems becomes more and more challenging due to the explosion of on-line information, the initial incomplete user preference and user's cognitive and emotional limitations of information processing. How to accurately elicit user's preference accompanyingly becomes the main concern of current decision support systems. This paper is a survey of the...},
author = {Chen, Li and Pu, Pearl},
booktitle = {Ecole Politechnique Federale de Lausanne, Tech. Rep. IC/2004/67},
keywords = {elicitation,hci,preference,preference-elicitation,recommendation,survey},
title = {{Survey of Preference Elicitation Methods}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.58.5265},
year = {2004}
}
@inproceedings{Irurozki2009,
author = {Irurozki, Ekhine and Lozano, Jose A.},
booktitle = {IEEE Congress on Evolutionary Computation},
keywords = {dblp},
pages = {1320--1327},
publisher = {IEEE},
title = {{A new preprocessing procedure for the haplotype inference problem.}},
url = {http://dblp.uni-trier.de/db/conf/cec/cec2009.html{\#}IrurozkiL09},
year = {2009}
}
@inproceedings{conf/ai/IrurozkiCL11,
author = {Irurozki, Ekhine and Calvo, Borja and Lozano, Jose A.},
booktitle = {Canadian Conference on AI},
isbn = {978-3-642-21042-6},
keywords = {dblp},
pages = {186--191},
publisher = {Springer-Verlag},
series = {Lecture Notes in Computer Science},
title = {{Learning Probability Distributions over Permutations by Means of Fourier Coefficients.}},
url = {http://dblp.uni-trier.de/db/conf/ai/ai2011.html{\#}IrurozkiCL11},
volume = {6657},
year = {2011}
}
@article{Ceberio2012,
author = {Ceberio, Josu and Irurozki, Ekhine and Mendiburu, Alexander and Lozano, Jose A.},
doi = {10.1007/s13748-011-0005-3},
isbn = {1374801100},
issn = {2192-6352},
journal = {Progress in Artificial Intelligence},
number = {1},
pages = {103--117},
title = {{A review on estimation of distribution algorithms in permutation-based combinatorial optimization problems}},
volume = {1},
year = {2012}
}
@article{Ceberio2013,
abstract = {The aim of this paper is two-fold. First, we introduce a novel general estimation of distribution algorithm to deal with permutation-based optimization problems. The algorithm is based on the use of a probabilistic model for permutations called the generalized Mallows model. In order to prove the potential of the proposed algorithm, our second aim is to solve the permutation flowshop scheduling problem. A hybrid approach consisting of the new estimation of distribution algorithm and a variable neighborhood search is proposed. Conducted experiments demonstrate that the proposed algorithm is able to outperform the state-of-the-art approaches. Moreover, from the 220 benchmark instances tested, the proposed hybrid approach obtains new best known results in 152 cases. An in-depth study of the results suggests that the successful performance of the introduced approach is due to the ability of the generalized Mallows estimation of distribution algorithm to discover promising regions in the search space.},
author = {Ceberio, Josu and Irurozki, Ekhine and Mendiburu, Alexander and Lozano, Jose A.},
doi = {10.1109/TEVC.2013.2260548},
isbn = {2009029143},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
keywords = {Estimation of distribution algorithms,Generalized Mallows model,Permutation flowshop scheduling problem,Permutations-based optimization problems},
number = {2},
pages = {286--300},
title = {{A distance-based ranking model estimation of distribution algorithm for the flowshop scheduling problem}},
volume = {18},
year = {2014}
}
@inproceedings{Ceberio2014,
author = {Ceberio, Josu and Irurozki, Ekhine and Mendiburu, Alexander and Lozano, Jose A.},
booktitle = {IEEE Congress on Evolutionary Computation},
doi = {10.1109/CEC.2014.6900435},
isbn = {9781479914883},
pages = {2459--2466},
title = {{Extending Distance-based Ranking Models in Estimation of Distribution Algorithms}},
year = {2014}
}
@article{Mueller2013,
author = {Mueller, Carl and Starr, Shannon},
doi = {10.1007/s10959-011-0364-5},
issn = {0894-9840},
journal = {Journal of Theoretical Probability},
keywords = {60B15,82B05,Random permutations},
number = {2},
pages = {514--540},
publisher = {Springer-Verlag},
title = {{The Length of the Longest Increasing Subsequence of a Random Mallows Permutation}},
url = {http://dx.doi.org/10.1007/s10959-011-0364-5},
volume = {26},
year = {2013}
}
@book{Stanley1986,
address = {Belmont, CA, USA},
author = {Stanley, R P},
isbn = {0-534-06546-5},
publisher = {Wadsworth Publishing Company},
title = {{Enumerative Combinatorics}},
year = {1986}
}
@misc{pmr,
annote = {R package version 1.2.3},
author = {Lee, Paul H and Yu, Philip L H},
title = {{$\backslash$pkg{\{}pmr{\}}: Probability Models for Ranking Data}},
url = {http://cran.r-project.org/package=pmr},
year = {2013}
}
@article{prefmod,
author = {Hatzinger, Reinhold and Dittrich, Regina},
issn = {1548-7660},
journal = {Journal of Statistical Software},
number = {10},
pages = {1--31},
title = {{{\{}$\backslash$pkg{\{}prefmod{\}}{\}}: An {\{}$\backslash$proglang{\{}R{\}}{\}} Package for Modeling Preferences Based on Paired Comparisons, Rankings, or Ratings}},
url = {http://www.jstatsoft.org/v48/i10},
volume = {48},
year = {2012}
}
@misc{rmallow,
annote = {R package version 1.0},
author = {Gregory, Erik},
title = {{RMallow: Fit Multi-Modal Mallows' Models to ranking data}},
url = {http://cran.r-project.org/package=RMallow},
year = {2012}
}
@book{bona2004,
address = {Boca Raton, FL, London},
author = {B{\'{o}}na, Mikl{\'{o}}s},
isbn = {1-584-88434-7},
publisher = {Chapman {\&} Hall/CRC Press},
series = {Discrete mathematics and its applications},
title = {{Combinatorics of permutations}},
url = {http://opac.inria.fr/record=b1101002},
year = {2004}
}
@article{Ali2011,
annote = {Computational Foundations of Social Choice},
author = {Ali, Alnur and Meila, Marina},
doi = {http://dx.doi.org/10.1016/j.mathsocsci.2011.08.008},
issn = {0165-4896},
journal = {Mathematical Social Sciences},
number = {1},
pages = {28--40},
title = {{Experiments with Kemeny ranking: What works when?}},
url = {http://www.sciencedirect.com/science/article/pii/S0165489611000989},
volume = {64},
year = {2012}
}
@article{diaconis1989,
author = {Diaconis, Persi},
doi = {10.1214/aos/1176347251},
journal = {The Annals of Statistics},
number = {3},
pages = {949--979},
publisher = {The Institute of Mathematical Statistics},
title = {{A Generalization of Spectral Analysis with Application to Ranked Data}},
url = {http://dx.doi.org/10.1214/aos/1176347251},
volume = {17},
year = {1989}
}
@article{regen98,
author = {Regenwetter, Michel and Doignon, Jean-Paul},
issn = {0022-2496},
journal = {Journal of Mathematical Psychology},
number = {1},
pages = {102--106},
title = {{The Choice Probabilities of the Latent-Scale Model Satisfy the Size-Independent Model When n Is Small.}},
volume = {42},
year = {1998}
}
@article{Regenwetter1998,
author = {Regenwetter, Michel and Marley, A.A.J. and Joe, H.},
journal = {Australian Journal of Psychology},
number = {3},
pages = {175--185},
title = {{Random Utility threshold models for subset choice}},
volume = {50},
year = {1998}
}
@article{akl02,
author = {Akl, Selim G},
journal = {BIT Numerical Mathematics},
keywords = {dblp},
number = {1},
pages = {2--7},
title = {{A New Algorithm for Generating Derangements}},
url = {http://dblp.uni-trier.de/db/journals/bit/bit20.html{\#}Akl80},
volume = {20},
year = {1980}
}
@article{greene79,
author = {Greene, Curtis and Nijenhuis, Albert and Wilf, Herbert S.},
journal = {Advances in Mathematics},
pages = {104--109},
title = {{A Probabilistic Proof of a Formula for the Number of Young Tableaux of a Given Shape}},
volume = {31},
year = {1979}
}
@article{BleiGJ10,
author = {Blei, David M and Griffiths, Thomas L and Jordan, Michael I},
journal = {J. ACM},
number = {2},
title = {{The nested chinese restaurant process and bayesian nonparametric inference of topic hierarchies}},
volume = {57},
year = {2010}
}
@article{diaconis2002bayesian,
abstract = {We develop Bayesian versions of three classic probability problems: the birthday problem, the coupon collector's problem and the matching problem. In each case, the Bayesian component involves a prior on the underlying probability mechanism. Sometimes this appreciably changes the answer, sometimes not.},
author = {Diaconis, Persi and Holmes, Susan},
journal = {Sankhya: The Indian Journal of Statistics, Series A (1961-2002)},
keywords = {coupon{\_}collector},
number = {3},
publisher = {Springer-Verlag on behalf of the Indian Statistical Institute},
title = {{A Bayesian Peek into Feller Volume I}},
url = {http://www.jstor.org/stable/25051431},
volume = {64},
year = {2002}
}
@article{Hanlon1992,
author = {Hanlon, Phil and Diaconis, Persi},
journal = {Contemporary Mathematics},
pages = {99.117},
title = {{Eigenanalysis for some examples of the Metropolis algorithm}},
volume = {138},
year = {1992}
}
@incollection{partitions2011,
author = {McCullagh, Peter},
booktitle = {International Encyclopedia of Statistical Science},
doi = {10.1007/978-3-642-04898-2_473},
isbn = {978-3-642-04897-5},
pages = {1170--1177},
publisher = {Springer-Verlag},
title = {{Random Permutations and Partition Models}},
url = {http://dx.doi.org/10.1007/978-3-642-04898-2{\_}473},
year = {2011}
}
@incollection{Tavare1997,
author = {Tavar{\'{e}}, Simon and Ewens, Warren J},
booktitle = {Discrete Multivariate Distributions},
chapter = {41},
isbn = {0-471-12844-9},
keywords = {chinese-restaurent-process,dirichlet-process,discrete-distribution,evolution,ewens-distribution,ewens-sampling,latent-dirichlet-allocation},
pages = {232--246},
publisher = {John Wiley {\&} Sons},
title = {{Multivariate Ewens distribution}},
year = {1997}
}
@book{arratia2003,
author = {Arratia, Richard and Barbour, A D and Tavar{\'{e}}, Simon},
isbn = {3-03719-000-0},
keywords = {combinatorial{\_}stochastic{\_}process},
pages = {xii+363},
publisher = {European Mathematical Society (EMS), Z{\"{u}}rich},
series = {EMS Monographs in Mathematics},
title = {{Logarithmic combinatorial structures: a probabilistic approach}},
year = {2003}
}
@article{donnelly1986partition,
abstract = {It has recently been shown that the Ewens sampling formula may be generated by a Polya-like urn model. A genealogical proof of this result equates the labelling of balls in the urn to the partition by age of alleles in the sample. This urn construction is shown to be equivalent to the construction of Kingman (Proc. Roy. Soc. London Ser. A 361 (1978), 1–20) using a Poisson-Dirichlet “paintbox” and as a consequence, the partition by ages is seen to be equivalent to the size biased permutation of the Poisson-Dirichlet distribution. This approach unifies and extends many results on ages of alleles, the Polya urn, and the Poisson-Dirichlet distribution. Furthermore the Ewens sampling formula is characterized as being the only partition structure which may be generated by an urn-like mechanism.},
author = {Donnelly, Peter},
doi = {10.1016/0040-5809(86)90037-7},
issn = {0040-5809},
journal = {Theoretical Population Biology},
keywords = {age{\_}of{\_}allele coalescent{\_}theory ewens{\_}sampling{\_}for},
number = {2},
pages = {271--288},
title = {{Partition structures, Polya urns, the Ewens sampling formula, and the ages of alleles}},
url = {http://www.sciencedirect.com/science/article/pii/0040580986900377},
volume = {30},
year = {1986}
}
@inproceedings{DBLP:conf/aistats/2013,
booktitle = {AISTATS},
publisher = {JMLR.org},
series = {JMLR Proceedings},
title = {{Proceedings of the Sixteenth International Conference on Artificial Intelligence and Statistics, AISTATS 2013, Scottsdale, AZ, USA, April 29 - May 1, 2013}},
volume = {31},
year = {2013}
}
@inproceedings{DBLP:conf/aistats/AroraM13,
author = {Arora, Raman and Meila, Marina},
booktitle = {Artificial Intelligence and Statistics (AISTATS)},
pages = {117--125},
series = {JMLR Proceedings},
title = {{Consensus Ranking with Signed Permutations}},
volume = {31},
year = {2013}
}
@article{bourque2002,
address = {Essex, UK},
author = {Bourque, Guillaume and Pevzner, Pavel A},
journal = {Genome Research},
number = {12},
pages = {26--36},
title = {{Genome-scale evolution: Reconstructing gene orders in the ancestral species}},
volume = {1},
year = {2002}
}
@article{diaconis88Finetti,
author = {Diaconis, Persi},
editor = {Bernardo},
journal = {Bayesian statistics},
keywords = {de,finettis},
pages = {111--125},
publisher = {Oxford University Press},
title = {{Recent progress on de Finetti's notions of exchangeability}},
volume = {3},
year = {1988}
}
@article{ewens72,
abstract = {In this paper a beginning is made on the sampling theory of neutral alleles. That is, we consider deductive and subsequently inductive questions relating to a sample of genes from a selectively neutral locus. The inductions concern estimation, confidence intervals and hypothesis testing. In particular the test of the hypothesis that the alleles being sampled are indeed selectively neutral will be considered. In view of the large amount of data currently being obtained by electrophoretic methods on allele frequencies and numbers, and the current interest in the possibility of extensive ” non-Darwinian” evolution, such a sampling theory seems necessary. However, a large number of unsolved problems in this area remain, a partial listing being given towards the end of this paper.},
author = {Ewens, Warren J},
doi = {10.1016/0040-5809(72)90035-4},
issn = {00405809},
journal = {Theoretical Population Biology},
number = {1},
pages = {87--112},
title = {{The sampling theory of selectively neutral alleles}},
url = {http://dx.doi.org/10.1016/0040-5809(72)90035-4},
volume = {3},
year = {1972}
}
@inproceedings{Caragiannis2013,
abstract = {A well-studied approach to the design of voting rules views them as maximum likelihood estimators; given votes that are seen as noisy estimates of a true ranking of the alternatives, the rule must reconstruct the most likely true ranking. We argue that this is too stringent a requirement, and instead ask: How many votes does a voting rule need to reconstruct the true ranking? We define the family of pairwise-majority consistent rules, and show that for all rules in this family the number of samples required from the Mallows noise model is logarithmic in the number of alternatives, and that no rule can do asymptotically better (while some rules like plurality do much worse). Taking a more normative point of view, we consider voting rules that surely return the true ranking as the number of samples tends to infinity (we call this property accuracy in the limit); this allows us to move to a higher level of abstraction. We study families of noise models that are parametrized by distance functions, and find voting rules that are accurate in the limit for all noise models in such general families. We characterize the distance functions that induce noise models for which pairwise-majority consistent rules are accurate in the limit, and provide a similar result for another novel family of position-dominance consistent rules. These characterizations capture three well-known distance functions.},
address = {New York, NY, USA},
author = {Caragiannis, Ioannis and Procaccia, Ariel D and Shah, Nisarg},
booktitle = {Proceedings of the Fourteenth ACM Conference on Electronic Commerce},
doi = {10.1145/2482540.2482570},
isbn = {978-1-4503-1962-1},
keywords = {computer social choice,mallows' model,sample complexity},
pages = {143--160},
publisher = {ACM},
series = {EC '13},
title = {{When Do Noisy Votes Reveal the Truth?}},
url = {http://doi.acm.org/10.1145/2482540.2482570},
year = {2013}
}
@article{csiszar09,
abstract = {Summary: The L-decomposable and the bi-decomposable models are two families of distributions on the set S{\_}{\{}n{\}} of all permutations of the first n positive integers. Both of these models are characterized by collections of conditional independence relations. We first compute a Markov basis for the L-decomposable model, and then give partial results about the Markov basis of the bi-decomposable model. Using these Markov bases, we show that not all bi-decomposable distributions can be approximated arbitrarily well by strictly positive bi-decomposable distributions.},
author = {Csisz{\'{a}}r, Villo},
issn = {0023-5954},
journal = {Kybernetika},
number = {2},
pages = {249--260},
publisher = {Institute of Information Theory and Automation, Academy of Sciences of the Czech Republic, Prague},
title = {{Markov bases of conditional independence models for permutations.}},
volume = {45},
year = {2009}
}
@article{diaconis86markov,
abstract = {We construct Markov chain algorithms for sampling from discrete exponential families conditional on a sufficient statistic. Examples include contingency tables, logistic regression, and spectral analysis of permutation data. The algorithms involve computations in polynomial rings using Grobner bases.},
annote = {* Markov Bases * Algorithm to sample from exponential distribution conditioned on a statistic value},
author = {Diaconis, Persi and Sturmfels, Bernd},
doi = {10.2307/119991},
issn = {00905364},
journal = {The Annals of Statistics},
keywords = {exponential-families,geometry},
number = {1},
publisher = {Institute of Mathematical Statistics},
title = {{Algebraic Algorithms for Sampling from Conditional Distributions}},
url = {http://dx.doi.org/10.2307/119991},
volume = {26},
year = {1998}
}
@article{Preferences,
author = {Furnkranz, Johannes and Hullermeier, Eyke},
editor = {H{\"{u}}llermeier, Eyke and F{\"{u}}rnkranz, Johannes},
journal = {Machine Learning},
number = {2-3},
title = {{Preference Learning and Ranking [Special Issue]}},
volume = {93},
year = {2013}
}
@article{Higuera2000,
address = {Essex, UK},
author = {de la Higuera, C and Casacuberta, F},
doi = {http://dx.doi.org/10.1016/S0304-3975(97)00240-5},
issn = {0304-3975},
journal = {Theoretical Computer Science},
keywords = {B{\_}scanpathsimilarity informationtheory theoretical},
number = {1-2},
pages = {39--48},
publisher = {Elsevier Science Publishers Ltd.},
title = {{Topology of strings: median string is NP-complete}},
url = {http://portal.acm.org/citation.cfm?id=323488},
volume = {230},
year = {2000}
}
@article{olivares08,
author = {{Olivares-Rodr{\'{i}}guez C.; Oncina}, J},
journal = {Lecture Notes in Computer Science},
pages = {431--440},
title = {{A Stochastic Approach to Median String Computation}},
volume = {5342},
year = {2008}
}
@article{zoghbi98,
author = {Zoghbi, Antoine and Stojmenovi{\'{c}}, Ivan},
journal = {International Journal of Computer Mathematics},
keywords = {combinatorics,computerscience,partitions},
number = {2},
pages = {319--332},
title = {{Fast algorithms for generating integer partitions}},
url = {http://www.ams.org/mathscinet-getitem?mr=1712501},
volume = {70},
year = {1998}
}
@article{Bader11,
abstract = {During the last years, the genomes of more and more species have been sequenced,
providing data for phylogenetic reconstruction based on genome
rearrangement measures, where the most important distance measures are
the reversal distance and the transposition distance. The two main tasks in
all phylogenetic reconstruction algorithms is to calculate pairwise distances
and to solve the median of three problem. While the reversal distance problem
can be solved in linear time, the reversal median problem has been proven
to be NP-complete. The status of the transposition distance problem is still
open, but it is conjectured to be more dicult than the reversal problem.
Therefore, it suggests itself that also the transposition median problem is
NP-complete. However, this conjecture could not be proven yet. We now
succeeded in giving a non-trivial proof for the NP-completeness of the transposition
median problem.},
author = {Bader, Martin},
doi = {http://dx.doi.org/10.1016/j.tcs.2010.12.009},
journal = {Theoretical Computer Science},
keywords = {Complexity,Median problem,NP-complete,Transposition},
number = {12-14},
pages = {1099--1110},
title = {{The transposition median problem is NP-complete.}},
url = {http://dblp.uni-trier.de/db/journals/tcs/tcs412.html{\#}Bader11},
volume = {412},
year = {2011}
}
@article{Caprara03RMP,
address = {Institute for Operations Research and the Management Sciences (INFORMS), Linthicum, Maryland, USA},
author = {Caprara, A},
doi = {http://dx.doi.org/10.1287/ijoc.15.1.93.15155},
issn = {1526-5528},
journal = {INFORMS Journal on Computing},
number = {1},
pages = {93--113},
publisher = {INFORMS},
title = {{The Reversal Median Problem}},
volume = {15},
year = {2003}
}
@book{Borda1781,
author = {Borda, J.},
publisher = {Histoire de l'Academie Royal des Sciences.},
title = {{Memoire sur les Elections au Scrutin.}},
year = {1781}
}
@article{A.D.Gordon1979,
author = {{A. D. Gordon}},
journal = {Biometrika},
number = {1},
pages = {7--15},
title = {{A measure of agreement between rankings}},
volume = {66},
year = {1979}
}
@article{Kammerdiner2009,
author = {Kammerdiner, Alla and Krokhmal, Pavlo A and Pardalos, Panos M},
journal = {Optimization Letters},
keywords = {combinatorial optimization,hamming distance,hypergraph matchings,lem,multidimensional assignment prob-},
pages = {609--617},
title = {{On the Hamming distance in combinatorial optimization problems on hypergraph matchings}},
volume = {4},
year = {2009}
}
@article{Wellner2002,
author = {Wellner, Jon A},
keywords = {and phrases,limiting distributions,longest increasing subsequence,mean,monte-carlo method,random matrices,random permutation,random young tableaux,s metric,ulam,variance},
number = {2000},
pages = {1--19},
title = {{On Longest Increasing Subsequences and Random Young Tableaux: Experimental Results and Recent Theorems}},
year = {2002}
}
@article{Fiorio2005,
author = {Fiorio, Christophe and Montpellier, Lirm and Report, France},
number = {c},
pages = {1996--2005},
title = {algorithm2e.sty — package for algorithms},
volume = {9},
year = {2005}
}
@article{Fiorio2013,
author = {Fiorio, Christophe},
number = {c},
pages = {1998--2013},
title = {algorithm2e.sty — package for algorithms},
volume = {0},
year = {2013}
}
@misc{TheMendeleySupportTeam2011c,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@article{Mladenovic:1997:VNS,
address = {Oxford, UK, UK},
author = {Mladenovi{\'{c}}, N and Hansen, P},
doi = {10.1016/S0305-0548(97)00031-2},
issn = {0305-0548},
journal = {Computers {\&} Operations Research},
number = {11},
pages = {1097--1100},
publisher = {Elsevier Science Ltd.},
title = {{Variable neighborhood search}},
url = {http://dx.doi.org/10.1016/S0305-0548(97)00031-2},
volume = {24},
year = {1997}
}
@article{esp96,
abstract = {The computation of elementary symmetric functions and their derivatives is an integral part of conditional maximum likelihood estimation of item parameters un der the Rasch model. The conditional approach has the advantages of parameter estimates that are consistent (assuming the model is correct) and statistically rigorous goodness-of-fit tests. Despite these characteristics, the conditional approach has been limited by problems in computing the elementary symmetric functions. The in troduction of recursive formulas for computing these functions and the availability of modem computers has largely mediated these problems; however, detailed documentation of how these formulas work is lacking. This paper describes how various recursion formulas work and how they are used to compute elementary symmetric functions and their derivatives. The availabil ity of this information should promote a more thorough understanding of item parameter estimation in the Rasch model among both measurement specialists and practitioners.},
author = {Baker, Frank B and Harwell, Michael R},
doi = {10.1177/014662169602000206},
journal = {Applied Psychological Measurement},
keywords = {newtons{\_}identity},
number = {2},
pages = {169--192},
title = {{Computing Elementary Symmetric Functions and Their Derivatives: A Didactic}},
url = {http://dx.doi.org/10.1177/014662169602000206},
volume = {20},
year = {1996}
}
@article{Kuhn1955,
author = {Kuhn, Harold W},
journal = {Naval Research Logistics Quarterly},
pages = {83----97},
title = {{The Hungarian Method for the assignment problem}},
volume = {2},
year = {1955}
}
@inproceedings{NIPS2012_0012,
author = {Ziegler, Andrew and Christiansen, Eric and Kriegman, David and Belongie, Serge},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
pages = {1--9},
title = {{Locally Uniform Comparison Image Descriptor}},
url = {http://books.nips.cc/papers/files/nips25/NIPS2012{\_}0012.pdf},
year = {2012}
}
@article{DBLP:journals/jmlr/SunLK11,
author = {Sun, Mingxuan and Lebanon, Guy and Kidwell, Paul},
journal = {Journal of the Royal Statistical Society C},
number = {3},
pages = {471--492},
title = {{Estimating Probabilities in Recommendation Systems}},
volume = {61},
year = {2012}
}
@misc{TheMendeleySupportTeam2011a,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@misc{TheMendeleySupportTeam2011b,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@inproceedings{DBLP:conf/wine/2008,
booktitle = {WINE},
editor = {Papadimitriou, Christos H and Zhang, Shuzhong},
isbn = {978-3-540-92184-4},
publisher = {Springer-Verlag},
series = {Lecture Notes in Computer Science},
title = {{Internet and Network Economics, 4th International Workshop, WINE 2008, Shanghai, China, December 17-20, 2008. Proceedings}},
volume = {5385},
year = {2008}
}
@article{critchlow:1988:ulam,
author = {Critchlow, Douglas Edward},
journal = {In Encyclopedia of Statistical Sciences},
keywords = {disorder,distance,permutation},
pages = {379--380},
title = {{Ulam's metric}},
volume = {9},
year = {1988}
}
@article{permMetricsDeza98,
abstract = {his is a survey on distances on the symmetric groups Sn together with their applications in many contexts; for example: statistics, coding theory, computing, bell-ringing and so on, which were originally seen unrelated. This paper initializes a step of research toward this direction in the hope that it will stimulate more researchs and eventually lead to a systematic study on this subject. Distances on Sn were used in many papers in different contexts; for example, in statistics (see [Cr] and its references), coding theory (see [BCD] and its references), in computing (see, for example [Kn]), bell-ringing and so on. Here we attempt to give a brief bird's view of distances on Sn according to types of problems considered:},
author = {Deza, Michael and Huang, Tayuan},
journal = {Journal of Combinatorics, Information and System Sciences},
keywords = {distance,measure,permutation},
pages = {173--185},
title = {{Metrics on permutations, a survey}},
volume = {23},
year = {1998}
}
@book{AnalyzingRankData,
author = {Schader, M (Ed ).},
keywords = {Clasificaci{\'{o}}n,Estad{\'{i}}stica,Modelo,Multivariable,T{\'{e}}cnicas},
pages = {346},
publisher = {Chapman {\&} Hall},
title = {{Analyzing and modeling data and knowledge}},
year = {1991}
}
@phdthesis{Rinker2011,
abstract = {Rank data is comprised of a set of complete and partial rankings which reflect preference or standing (examples of such data can be generated by voters, search engines, market survey responses, etc.). Complete rankings (viewed as bijective maps from a set of n items to n ranks) can be identified with the symmetric group Sn, and this identification gives rise to a variety of analytic techniques. One such method is a probabilistic soft clustering technique based on the Mallows probability distribution for the symmetric group. This distribution relies on Kendall's tau (a distance on Sn) and is normalized by a sum over the entire space of n! rankings. It can be extended to partial rankings (which differ from complete rankings by allowing multi-way ties at varying ranks), theoretically facilitating the extension of this probabilistic method. Unfortunately, the generalization of the Mallows distribution requires the evaluation of even more complex sums, which quickly become prohibitively large. In this thesis, we present a closed form of Mallows distribution for partial rankings which allows us to extend the clustering method to accommodate arbitrary sets of rank data. In addition, our combinatorial proof of this closed form allows Mallows model and its accompanying closed forms to be generalized to several natural extensions of the symmetric group, namely the flag variety of the finite general linear group and all finite Coxeter groups.},
author = {Rinker, Paige E. and Rockmore, Daniel N},
pages = {61},
school = {Datmouth college, Hanover, New Hampshire},
title = {{A Mallows model for Coxeter groups and buildings}},
year = {2011}
}
@article{starr2009,
archivePrefix = {arXiv},
arxivId = {math-ph/0904.0696},
author = {Starr, Shannon},
doi = {10.1063/1.3156746},
eprint = {0904.0696},
journal = {Journal of Mathematical Physics},
keywords = {Integral and integrodifferential equations,Liouville equation,Ordinary and partial differential equations; boun,Probability theory,hyperbolic equations,partial differential equations,probability,thermodynamics},
number = {9},
pages = {95208},
primaryClass = {math-ph},
title = {{Thermodynamic limit for the Mallows model on S{\_}{\{}n{\}}}},
volume = {50},
year = {2009}
}
@article{Evans2012,
author = {Evans, Steven Neil and Grubel, Rudolf and Wakolbinger, Anton},
doi = {10.1214/EJP.v17-1698},
issn = {1083-6489},
journal = {Electronic Journal of Probability},
month = {jan},
title = {{Trickle-down processes and their boundaries}},
url = {http://ejp.ejpecp.org/article/view/1698},
volume = {17},
year = {2012}
}
@article{Diaconis2000,
author = {Diaconis, Persi and Ram, Arun},
doi = {10.1307/mmj/1030132713},
journal = {The Michigan Mathematical Journal},
number = {1},
pages = {157--190},
title = {{Analysis of systematic scan Metropolis algorithms using Iwahori-Hecke algebra techniques.}},
url = {http://projecteuclid.org:80/Dienst/getRecord?id=euclid.mmj/1030132713/},
volume = {48},
year = {2000}
}
@article{Farnoud2012,
abstract = {We consider the problem of rank aggregation based on new distance measures derived through axiomatic approaches and based on score-based methods. In the first scenario, we derive novel distance measures that allow for discriminating between the ranking process of highest and lowest ranked elements in the list. These distance functions represent weighted versions of Kendall's tau measure and may be computed efficiently in polynomial time. Furthermore, we describe how such axiomatic approaches may be extended to the study of score-based aggregation and present the first analysis of distributed vote aggregation over networks.},
author = {Farnoud, Farzad and Touri, Behrouz and Milenkovic, Olgica},
month = {mar},
title = {{Novel Distance Measures for Vote Aggregation}},
url = {http://arxiv.org/abs/1203.6371},
year = {2012}
}
@inproceedings{LebanonL02,
abstract = {A distance-based conditional model on the ranking poset is presented for use in classification and ranking. The model is an extension of the Mallows model, and generalizes the classifier combination methods used by several ensemble learning algorithms, including error correcting output codes, discrete AdaBoost, logistic regression and cranking. The algebraic structure of the ranking poset leads to a simple Bayesian inter- pretation of the conditional model and its special cases. In addition to a unifying view, the framework suggests a probabilistic interpretation for error correcting output codes and an extension beyond the binary coding scheme.},
author = {Lebanon, Guy and Lafferty, John D},
booktitle = {Advances in Neural Information Processing Systems},
pages = {415--422},
title = {{Conditional Models on the Ranking Poset}},
year = {2002}
}
@inproceedings{QinGL10,
abstract = {In this paper, we propose a new probabilistic model on permutations, which inherits the advantages of both the Luce model and the Mallows model and avoids their limitations. We refer to the model as coset-permutation distance based stagewise (CPS) model. Different from the Mallows model, the CPS model is a stagewise model. It decomposes the generative process of a permutation $\pi$ into sequential stages, which makes the efficient computation possible. At the k-th stage, an object is selected and assigned to position k with a certain probability. Different from the Luce model, the CPS model defines the selection probability based on the distance between a location permutation $\sigma$ and the right coset of $\pi$ (referred to as coset-permutation distance) at each stage. In this sense, it is also a distance-based model. Because many different permutation distances can be used to induce the coset-permutation distance, the CPS model also has rich expressiveness. Furthermore, the coset-permutation distances induced by many popular permutation distances can be computed with polynomial time complexity, which further ensures the efficiency of the CPS model.},
author = {Qin, Tao and Geng, Xiubo and Liu, Tie-Yan},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
editor = {Lafferty, John D and Williams, Christopher K I and Shawe-Taylor, John and Zemel, Richard S and Culotta, Aron},
keywords = {dblp},
pages = {1948--1956},
publisher = {Curran Associates, Inc.},
title = {{A New Probabilistic Model for Rank Aggregation.}},
url = {http://dblp.uni-trier.de/db/conf/nips/nips2010.html{\#}QinGL10},
year = {2010}
}
@inproceedings{conf/isnn/ChengH09,
author = {Cheng, Weiwei and H{\"{u}}llermeier, Eyke},
booktitle = {Advances in Neural Networks (ISNN)},
isbn = {978-3-642-01506-9},
keywords = {2009 kNN multi-label multilabel-ranking ranking we},
pages = {707--716},
publisher = {Springer-Verlag},
series = {Lecture Notes in Computer Science},
title = {{A New Instance-Based Label Ranking Approach Using the Mallows Model}},
url = {http://dblp.uni-trier.de/db/conf/isnn/isnn2009-1.html{\#}ChengH09},
volume = {5551},
year = {2009}
}
@article{Murphy2003645,
abstract = {Ranking data arises when judges are asked to rank some or all of a group of objects. Examples of ranking data arise in many areas, including the Irish electoral system and the Irish college admission system. Mixture models can be used to study heterogeneous populations. The study of these populations is achieved by thinking of the population as being composed of a finite number of homogeneous sub-populations. Mixtures of distance-based models are used to analyze ranking data from heterogeneous populations. Results from simulations are included, as well as an application to the well-known American Psychological Association election data set.},
annote = {Recent Developments in Mixture Model},
author = {Murphy, Thomas Brendan and Martin, Donal},
doi = {10.1016/S0167-9473(02)00165-2},
issn = {0167-9473},
journal = {Computational Statistics {\&} Data Analysis},
keywords = {Maximum likelihood,Mixture models,Ranking data},
number = {3-4},
pages = {645--655},
title = {{Mixtures of distance-based models for ranking data}},
url = {http://www.sciencedirect.com/science/article/pii/S0167947302001652},
volume = {41},
year = {2003}
}
@article{D'Elia2005917,
abstract = {A mixture model for preferences data, which adequately represents the composite nature of the elicitation mechanism in ranking processes, is proposed. Both probabilistic features of the mixture distribution and inferential and computational issues arising from the maximum likelihood parameters estimation are addressed. Moreover, empirical evidence from different data sets confirming the goodness of fit of the proposed model to many real preferences data is shown.},
author = {D'Elia, Angela and Piccolo, Domenico},
doi = {10.1016/j.csda.2004.06.012},
issn = {0167-9473},
journal = {Computational Statistics {\&} Data Analysis},
keywords = {Mixture model,Preferences data,Rankings},
number = {3},
pages = {917--934},
title = {{A mixture model for preferences data analysis}},
url = {http://www.sciencedirect.com/science/article/pii/S0167947304001987},
volume = {49},
year = {2005}
}
@article{Gnedin2012615,
abstract = {We introduce a probability distribution Q on the infinite group S Z of permutations of the set of integers Z . The distribution Q is a natural extension of the Mallows distribution on the finite symmetric group. A one-sided infinite counterpart of Q , supported by the group of permutations of N , was studied previously in our paper [A. Gnedin, G. Olshanski, q-Exchangeability via quasi-invariance, Ann. Probab. 38 (2010) 2103–2135, arXiv:0907.3275]. We analyze various features of Q such as its symmetries, the support, and the marginal distributions.},
author = {Gnedin, Alexander and Olshanski, Grigori},
doi = {10.1016/j.aam.2012.01.001},
issn = {0196-8858},
journal = {Advances in Applied Mathematics},
keywords = {{\textless}span style='font-style: italic'{\textgreater}q{\textless}/span{\textgreater}-Exchange,Infinite symmetric group,Mallows model,Random permutations},
number = {5},
pages = {615--639},
title = {{The two-sided infinite extension of the Mallows model for random permutations}},
url = {http://www.sciencedirect.com/science/article/pii/S0196885812000115},
volume = {48},
year = {2012}
}
@article{citeulike:8461510,
abstract = { A new psychological law, called the law of comparative judgment, is presented with some of its special applications in the measurement of psychological values. This law is applicable not only to the comparison of physical stimulus intensities but also to qualitative comparative judgments, such as those of excellence of specimens in an educational scale. It should be possible also to verify it on comparative judgments which involve simultaneous and successive contrast. The law is stated as follows:[Equation omitted]in which S-sub(1) and S-sub(2) are the psychological scale values of the two compared stimuli; x-sub(12) is the sigma value corresponding to the proportion of judgments p-sub(1) {\textgreater} p-sub(2). ς-sub(1) is the discriminal dispersion of stimulus R-sub(1) and ς-sub(2) is the dispersion of stimulus R-sub(2). r is the correlation between the discriminal deviations of R-sub(1) and R-sub(2) in the same judgment. This law is basic for work on Weber's and Fechner's laws, applies to the judgments of a single observer who compares a series of stimuli by the method of paired comparisons when no "equal" judgments are allowed, and is a rational equation for the method of constant stimuli. The law is then applied to five cases each of which involves different assumptions and different degrees of simplification of the law for practical use. The weighting of the observation equations is discussed because the observation equations obtained with the five cases are not of the same reliability and hence should not be equally weighted. (PsycINFO Database Record (c) 2006 APA, all rights reserved) },
author = {Thurstone, L L},
doi = {10.1037/h0070288},
issn = {0033-295X},
journal = {Psychological Review},
keywords = {judgment,measurement},
number = {4},
pages = {273--286},
title = {{A law of comparative judgment.}},
url = {http://dx.doi.org/10.1037/h0070288},
volume = {34},
year = {1927}
}
@article{Bayer.Diaconis-1992,
author = {Bayer, D and Diaconis, P},
journal = {The Annals of Applied Probability},
keywords = {bibtex-import},
number = {2},
pages = {294--313},
title = {{Trailing the dovetail shuffle to its lair}},
url = {http://www.jstor.org/view/10505164/di983988/98p0059i/0},
volume = {2},
year = {1992}
}
@article{citeulike:6744178,
abstract = {The use of simulation for high-dimensional intractable computations has revolutionized applied mathematics. Designing, improving and understanding
the new tools leads to (and leans on) fascinating mathematics, from representation theory through micro-local analysis.},
author = {Diaconis, Persi},
doi = {10.1090/S0273-0979-08-01238-X},
issn = {0273-0979},
journal = {Bulletin of the American Mathematical Society},
keywords = {markov{\_}chain{\_}monte{\_}carlo},
month = {nov},
number = {2},
pages = {179--205},
title = {{The Markov chain Monte Carlo revolution}},
url = {http://dx.doi.org/10.1090/S0273-0979-08-01238-X},
volume = {46},
year = {2008}
}
@book{Wilf1999,
author = {Wilf, Herbert S.},
title = {{East Side, West Side . . . - an introduction to combinatorial families-with Maple programming}},
year = {1999}
}
@misc{TheMendeleySupportTeam2011,
abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
address = {London},
author = {{The Mendeley Support Team}},
booktitle = {Mendeley Desktop},
keywords = {Mendeley,how-to,user manual},
pages = {1--16},
publisher = {Mendeley Ltd.},
title = {{Getting Started with Mendeley}},
url = {http://www.mendeley.com},
year = {2011}
}
@inproceedings{Fagin:2003:ESS:872757.872795,
address = {New York, NY, USA},
author = {Fagin, Ronald and Kumar, Ravi and Sivakumar, D},
booktitle = {International conference on Management of data (ACM SIGMOD)},
doi = {10.1145/872757.872795},
isbn = {1-58113-634-X},
pages = {301--312},
publisher = {ACM},
series = {SIGMOD '03},
title = {{Efficient similarity search and classification via rank aggregation}},
url = {http://doi.acm.org/10.1145/872757.872795},
year = {2003}
}
@inproceedings{Dwork:2001:RAM:371920.372165,
address = {New York, NY, USA},
author = {Dwork, Cynthia and Kumar, Ravi and Naor, Moni and Sivakumar, D},
booktitle = {International conference on World Wide Web},
doi = {10.1145/371920.372165},
isbn = {1-58113-348-0},
keywords = {metasearch,multi-word queries,rank aggregation,ranking functions,spam},
pages = {613--622},
publisher = {ACM},
series = {WWW '01},
title = {{Rank aggregation methods for the Web}},
url = {http://doi.acm.org/10.1145/371920.372165},
year = {2001}
}
@inproceedings{farah,
address = {New York, NY, USA},
author = {Farah, Mohamed and Vanderpooten, Daniel},
booktitle = {Conference on Research and development in information retrieval (ACM SIGIR)},
doi = {10.1145/1277741.1277843},
isbn = {978-1-59593-597-7},
keywords = {data fusion,metasearch engine,multiple criteria approach,outranking methods,rank aggregation},
pages = {591--598},
publisher = {ACM},
series = {SIGIR '07},
title = {{An outranking approach for rank aggregation in information retrieval}},
url = {http://doi.acm.org/10.1145/1277741.1277843},
year = {2007}
}
@article{pinch,
author = {Pinch, Richard G E},
journal = {Combinatorics, probability and computing},
pages = {473--479},
title = {{The distance of a permutation from a subgroup of S{\_}n}},
year = {2007}
}
@inproceedings{sdp2,
author = {de Lima, Thaynara Arielly and Ayala-Rincon, Mauricio},
booktitle = {Congreso colombiano de computacion (7CCC) - To appear},
title = {{Algorithmic Problems for Metrics on Permutation Groups}},
year = {2012}
}
@inproceedings{DBLP:conf/sofsem/ArvindJ08,
author = {Arvind, Vikraman and Joglekar, Pushkar S},
booktitle = {Conference on Current Trends in Theory and Practice of Computer Science (SOFSEM)},
isbn = {978-3-540-77565-2},
pages = {136--147},
publisher = {Springer-Verlag},
series = {Lecture Notes in Computer Science},
title = {{Algorithmic Problems for Metrics on Permutation Groups}},
volume = {4910},
year = {2008}
}
@article{DBLP:journals/dm/BuchheimCW09,
author = {Buchheim, Christoph and Cameron, Peter J and Wu, Taoyang},
journal = {Discrete Mathematics},
number = {4},
pages = {962--968},
title = {{On the subgroup distance problem}},
volume = {309},
year = {2009}
}
@inproceedings{Schaefer1978,
address = {New York, New York, USA},
author = {Schaefer, Thomas J.},
booktitle = {Proceedings of the tenth annual ACM symposium on Theory of computing - STOC '78},
doi = {10.1145/800133.804350},
pages = {216--226},
publisher = {ACM Press},
title = {{The complexity of satisfiability problems}},
url = {http://portal.acm.org/citation.cfm?doid=800133.804350},
year = {1978}
}
@article{Levin1973,
author = {Levin, Leonid A.},
issn = {1058-6180},
journal = {Problems of Information Transmission (Проблемы передачи информации)},
month = {oct},
number = {3},
pages = {265--266},
title = {{{\{}Universal search problems (Универсальные задачи перебора){\}}}},
volume = {9},
year = {1973}
}
@inproceedings{Cook1971,
address = {New York, USA},
author = {Cook, Stephen A.},
booktitle = {The complexity of theorem-proving procedures},
doi = {10.1145/800157.805047},
pages = {151--158},
publisher = {ACM},
title = {{ACM symposium on theory of computing}},
year = {1971}
}
@article{Betzler2011,
author = {Betzler, Nadja and Guo, Jiong and Komusiewicz, Christian and Niedermeier, Rolf},
doi = {dx.doi.org/10.1016/j.jcss.2010.07.005},
journal = {Journal of computer and system science},
number = {4},
pages = {774--789},
title = {{Average parameterization and partial kernelization for computing medians}},
volume = {77},
year = {2011}
}
@article{Popov2007,
author = {Popov, Vladimir},
doi = {http://dx.doi.org/10.1016/j.tcs.2007.05.029},
journal = {Theoretical computer science},
number = {1-3},
pages = {115--126},
title = {{Multiple genome rearrangement by swaps and by element duplications}},
volume = {385},
year = {2007}
}
@article{Lau2005,
author = {Lau, K. K. and Yuen, Pong C. and Tang, Yuan Y.},
doi = {10.1016/j.patcog.2004.07.006},
journal = {Pattern Recognition},
number = {3},
pages = {323--339},
title = {{Directed connection measurement for evaluating reconstructed stroke sequence in handwriting images}},
volume = {38},
year = {2005}
}
@inproceedings{Cheng2009,
address = {Bled, Slovenia},
author = {Cheng, Weiwei and Hullermeier, Eyke},
booktitle = {Workshop Proceedings of Learning from Multi-Label Data},
pages = {28--38},
title = {{A Simple Instance-Based Approach to Multilabel Classification Using the Mallows Model}},
year = {2009}
}
@inproceedings{Meila2010,
abstract = {We present a Dirichlet process mixture model over discrete incomplete rankings and study two Gibbs sampling inference techniques for estimating posterior clusterings. The first ap- proach uses a slice sampling subcomponent for estimating cluster parameters. The sec- ond approach marginalizes out several cluster parameters by taking advantage of approx- imations to the conditional posteriors. We empirically demonstrate (1) the effectiveness of this approximation for improving conver- gence, (2) the benefits of the Dirichlet pro- cess model over alternative clustering tech- niques for ranked data, and (3) the applica- bility of the approach to exploring large real- world ranking datasets.},
author = {Meila, Marina and Chen, Harr},
booktitle = {Uncertainty in Artificial Intelligence (UAI)},
pages = {285--294},
title = {{Dirichlet Process Mixtures of Generalized Mallows Models}},
year = {2010}
}
@book{10.1137/1.9780898718546,
address = {Philadephia, PA},
author = {Creignou, Nadia and Khanna, Sanjeev and Sudan, Madhu},
doi = {DOI:10.1137/1.9780898718546},
isbn = {9780898718546},
keywords = {computational complexity; constraints; artificial},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Complexity Classifications of Boolean Constraint Satisfaction Problems}},
url = {http://dx.doi.org/10.1137/1.9780898718546},
year = {2001}
}
@article{Gandolfo,
abstract = {We consider a model of random permutations of the sites of the cubic lattice. Permutations are weighted so that sites are preferably sent onto neighbors. We present numerical evidence for the occurrence of a transition to a phase with infinite, macroscopic cycles.},
archivePrefix = {arXiv},
arxivId = {arXiv:cond-mat/0703315v3},
author = {Gandolfo, Daniel and Ruiz, Jean and Ueltschi, Daniel},
eprint = {0703315v3},
keywords = {bose-einstein con-,cycle percolation,random cycles,random permutations},
pages = {1--13},
primaryClass = {arXiv:cond-mat},
title = {{On a model of random cycles}}
}
@article{Fulman,
abstract = {This paper studies biased riffle shuffles, first defined by Diaconis, Fill, and Pitman. These shuffles generalize the well-studied Gilbert-Shannon-Reeds shuffle and convolve nicely. An upper bound is given for the time for these shuffles to converge to the uniform distribution; this matches lower bounds of Lalley. A careful version of a bijection of Gessel leads to a generating function for cycle structure after one of these shuffles and gives new results about descents in random permutations. Results are also obtained about the inversion and descent structure of a permutation after one of these shuffle},
archivePrefix = {arXiv},
arxivId = {arXiv:math/9712240v1},
author = {Fulman, Jason},
eprint = {9712240v1},
pages = {1--11},
primaryClass = {arXiv:math},
title = {{The Combinatorics of Biased Riffle Shuffles}}
}
@article{Wilson2000,
archivePrefix = {arXiv},
arxivId = {arXiv:math/0702753v1},
author = {Wilson, Mark C},
eprint = {0702753v1},
pages = {1--10},
primaryClass = {arXiv:math},
title = {{Random and exhaustive generation of permutations and cycles}},
year = {2000}
}
@article{Tsaban2010,
archivePrefix = {arXiv},
arxivId = {arXiv:cs/0207027v6},
author = {Tsaban, Boaz},
eprint = {0207027v6},
keywords = {1 for the sake,and leave the pseudorandom,and phrases,case for part 3,cycle structure,fast,forward permutations,of clarity,permutation graphs,pseudorandom permutations,purely,random case,the beginning in the,we will concentrate in},
pages = {1--20},
primaryClass = {arXiv:cs},
title = {{Permutation graphs, fast forward permutations, and sampling the cycle structure of a permutation}},
year = {2010}
}
@article{Ercolani2011,
abstract = {We investigate the typical cycle lengths, the total number of cycles, and the number of finite cycles in random permutations whose probability involves cycle weights. Typical cycle lengths and total number of cycles depend strongly on the parameters, while the distributions of finite cycles are usually independent Poisson random variables.},
archivePrefix = {arXiv},
arxivId = {arXiv:1102.4796v1},
author = {Ercolani, Nicholas M and Ueltschi, Daniel},
eprint = {arXiv:1102.4796v1},
journal = {Random Structures {\&} Algorithms},
keywords = {2010 math,60k35,class,cycle structure,cycle weights,ewens distribution,random permutations,subj},
number = {1},
title = {{Cycle structure of random permutations with cycle weights}},
volume = {44},
year = {2014}
}
@article{Fulman2001,
archivePrefix = {arXiv},
arxivId = {arXiv:math/0102176v3},
author = {Fulman, Jason},
eprint = {0102176v3},
keywords = {card shuffling,cycle index,increasing subsequence,rsk correspondence},
pages = {1--34},
primaryClass = {arXiv:math},
title = {{Applications of Symmetric Functions to Cycle and Increasing Subsequence Structure after Shuffl}},
year = {2001}
}
@article{Lugo2009,
archivePrefix = {arXiv},
arxivId = {arXiv:0909.2909v1},
author = {Lugo, Michael},
eprint = {arXiv:0909.2909v1},
journal = {ReCALL},
pages = {1--15},
title = {{The number of cycles of specified normalized length in permutations}},
year = {2009}
}
@article{Betz2011,
archivePrefix = {arXiv},
arxivId = {arXiv:0908.2217v3},
author = {Betz, Volker and Ueltschi, Daniel and Velenik, Yvan},
doi = {10.1214/10-AAP697},
eprint = {arXiv:0908.2217v3},
issn = {1050-5164},
journal = {The Annals of Applied Probability},
keywords = {60K35, Random permutations, cycle weights, cycle l},
month = {feb},
number = {1},
pages = {312--331},
title = {{Random permutations with cycle weights}},
url = {http://projecteuclid.org/euclid.aoap/1292598036},
volume = {21},
year = {2011}
}
@article{Benaych-georges2009,
archivePrefix = {arXiv},
arxivId = {arXiv:0712.1903v6},
author = {Benaych-georges, Florent},
eprint = {arXiv:0712.1903v6},
journal = {Main},
keywords = {a-permutations,cycle,cycles of random permutations,lengths,random permutations,random permutations with restricted},
pages = {1--11},
title = {{Cycles of random permutations with restricted cycle lengths}},
year = {2009}
}
@article{Goldschmidt2007,
archivePrefix = {arXiv},
arxivId = {arXiv:0712.0556v1},
author = {Goldschmidt, Christina and Martin, James B},
eprint = {arXiv:0712.0556v1},
journal = {Bernoulli},
pages = {1--13},
title = {{Fragmenting random permutations}},
year = {2007}
}
@phdthesis{Arndt2010,
author = {Arndt, J{\"{o}}rg},
school = {Australian National University},
title = {{Generating Random Permutations}},
year = {2010}
}
@book{feller1,
author = {Feller, William},
howpublished = {Hardcover},
isbn = {0471257087},
keywords = {book combinatorics d4.1 discrete feller probabilit},
publisher = {John Wiley {\&} Sons},
title = {{An Introduction to Probability Theory and Its Applications}},
volume = {1},
year = {1968}
}
@article{Bartholdi1989,
author = {Bartholdi, J. and Tovey, C. A. and Trick, M. A.},
doi = {10.1007/BF00303169},
issn = {0176-1714},
journal = {Social Choice and Welfare},
month = {apr},
number = {2},
pages = {157--165},
title = {{Voting schemes for which it can be difficult to tell who won the election}},
url = {http://www.springerlink.com/index/10.1007/BF00303169},
volume = {6},
year = {1989}
}
@book{diaconis88,
author = {Diaconis, Persi},
publisher = {Institute of Mathematical Statistics},
title = {{Group representations in probability and statistics}},
year = {1988}
}
@book{fligner93,
author = {Fligner, Michael A and Verducci, Joseph S},
isbn = {9780387979205},
publisher = {Springer-Verlag},
title = {{Probability Models and Statistical Analyses for Ranking Data}},
year = {1993}
}
@book{luce59,
address = {New York},
author = {{Luce R.}, Duncan},
keywords = {discrete{\_}choice},
publisher = {John Wiley {\&} Sons},
title = {{Individual Choice Behavior}},
year = {1959}
}
@article{helmbold2009,
author = {Helmbold, D P and Warmuth, M K},
journal = {Journal of Machine Learning Research},
pages = {1705--1736},
title = {{Learning Permutations with Exponential Weights}},
volume = {10},
year = {2009}
}
@inproceedings{icml2010_043,
address = {Haifa, Israel},
author = {Duchi, John C and Mackey, Lester W and Jordan, Michael I},
booktitle = {International Conference on Machine Learning (ICML)},
editor = {F{\"{u}}rnkranz, Johannes and Joachims, Thorsten},
pages = {327--334},
title = {{On the Consistency of Ranking Algorithms}},
year = {2010}
}
@inproceedings{shachter-peot1992,
author = {Shachter, R D and Peot, M A},
booktitle = {8th Conferece on Uncertainty in Artificial Intelligence},
pages = {276--283},
title = {{Decision Making Using Probabilistic Inference Methods}},
year = {1992}
}
@inproceedings{DBLP:conf/pakdd/2010-1,
booktitle = {Advances in Knowledge Discovery and Data Mining (PAKDD)},
editor = {Zaki, Mohammed Javeed and Yu, Jeffrey Xu and Ravindran, B and Pudi, Vikram},
isbn = {978-3-642-13656-6},
publisher = {Springer-Verlag},
series = {Lecture Notes in Computer Science},
title = {{Advances in Knowledge Discovery and Data Mining, 14th Pacific-Asia Conference, PAKDD 2010, Hyderabad, India, June 21-24, 2010. Proceedings. Part I}},
volume = {6118},
year = {2010}
}
@techreport{maslen,
address = {Hanover, NH, USA},
author = {Maslen, David K Rockmore Daniel N},
keywords = {dartmouth-cs},
publisher = {Dartmouth College},
title = {{Generalized FFTS - A Survey of Some Recent Results}},
url = {http://portal.acm.org/citation.cfm?id=867740},
year = {1996}
}
@misc{snob,
annote = {{\{}A{\}}vailable at $\backslash$texttt{\{}http://www.cs.columbia.edu/$\backslash${\~{}}{\{} {\}}risi/Snob/{\}}},
author = {Kondor, R},
title = {{$\backslash$mathbb{\{}S{\}}{\_}n$\backslash$texttt{\{}ob{\}}: a {\{}C++{\}} library for fast {\{}F{\}}ourier transforms on the symmetric group}},
year = {2006}
}
@article{graphkernels,
author = {{S. V. N. Vishwanathan}, N N Schraudolf R Kondor and Borgwardt, K M},
journal = {Journal of Machine Learning Research},
pages = {1705--1736},
title = {{Graph kernels}},
volume = {10},
year = {2010}
}
@inproceedings{meila08,
address = {Corvallis, Oregon},
author = {Meila, Marina and Bao, Le},
booktitle = {Uncertainty in Artificial Intelligence (UAI)},
pages = {393--402},
publisher = {AUAI Press},
title = {{Estimation and Clustering with Infinite Rankings}},
year = {2008}
}
@article{buntine1996,
author = {Buntine, W},
journal = {IEEE Trans. on Knowledge and Data Engineering},
number = {2},
pages = {195--210},
title = {{A guide to the literature on learning probabilistic networks from data}},
volume = {8},
year = {1996}
}
@inproceedings{pakdd10,
author = {Gwadera, Robert and Crestani, Fabio},
booktitle = {PAKDD (1)},
pages = {286--299},
title = {{Ranking Sequential Patterns with Respect to Significance}},
year = {2010}
}
@article{plackett,
author = {Plackett, R L},
journal = {Journal of the Royal Statistical Society},
number = {10},
pages = {193--202},
title = {{The Analysis of Permutations}},
volume = {24},
year = {1975}
}
@book{serre77,
author = {Serre, J P},
publisher = {Springer-Verlag},
title = {{Linear Representations in Finite Groups}},
year = {1977}
}
@article{indepLarge,
author = {Huang, J and Guestrin, Carlos},
journal = {Electronic Journal of Statistics},
pages = {199--230},
title = {{Uncovering the Riffled Independence Structure of Rankings}},
volume = {6},
year = {2012}
}
@inproceedings{Kondor2008a,
address = {Haifa/Israel},
author = {Kondor, R and Barbosa, M},
booktitle = {Conference on Learning Theory},
title = {{Ranking with kernels in Fourier space}},
year = {2010}
}
@inproceedings{meila07,
address = {Corvallis, Oregon},
author = {Meila, Marina and Phadnis, Kapil and Patterson, Arthur and Bilmes, Julian},
booktitle = {Uncertainty in Artificial Intelligence (UAI)},
pages = {285--294},
title = {{Consensus ranking under the exponential model}},
year = {2007}
}
@inproceedings{cohen10,
address = {Cambridge, MA, USA},
author = {Cohen, William W and Schapire, Robert E and Singer, Yoram},
booktitle = {Advances in Neural Information Processing Systems (NIPS)},
isbn = {0-262-10076-2},
pages = {451--457},
publisher = {MIT Press},
series = {NIPS '97},
title = {{Learning to order things}},
year = {1998}
}
@inproceedings{learnriffle,
address = {Haifa, Israel},
author = {Huang, J and Guestrin, C},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Learning Hierarchical Riffle Independent Groupings from Rankings}},
year = {2010}
}
@book{jensen-book2001,
author = {V.{\~{}}Jensen, F},
publisher = {Springer Verlag},
title = {{Bayesian Networks and Decision Graphs}},
year = {2001}
}
@article{critchlow91,
author = {Critchlow, Douglas Edward and Fligner, Michael A and Verducci, Joseph S},
journal = {Journal of Mathematical Psychology},
pages = {294--318},
title = {{Probability Models on Rankings}},
volume = {35},
year = {1991}
}
@article{hunter04,
author = {Hunter, David R},
journal = {The Annals of Statistics},
keywords = {2004,ranking,statistical{\_}model},
number = {1},
pages = {384--406},
title = {{MM Algorithms for Generalized Bradley-Terry Models}},
volume = {32},
year = {2004}
}
@article{Irurozki2014,
author = {Irurozki, Ekhine},
pages = {42--44},
mendeley-groups = {Mallows{\_}Model},
title = {{Sampling and learning distance-based probability models for permutation spaces}},
year = {2014}
}
@article{gMallows,
author = {Fligner, Michael A and Verducci, Joseph S},
journal = {Journal of the Royal Statistical Society},
number = {3},
pages = {359--369},
title = {{Distance based ranking models}},
volume = {48},
year = {1986}
}
@article{mallows,
author = {Mallows, C L},
journal = {Biometrika},
number = {1-2},
pages = {114--130},
title = {{Non-null ranking models}},
volume = {44},
year = {1957}
}
@inproceedings{guiver09,
author = {Guiver, John and Snelson, Edward},
booktitle = {International Conference on Machine Learning (ICML)},
pages = {377--384},
publisher = {ACM},
series = {ICML '09},
title = {{Bayesian inference for Plackett-Luce ranking models}},
year = {2009}
}
@book{critchlow95,
address = {Berlin [u.a.]},
author = {Critchlow, Douglas Edward},
isbn = {3540962883},
keywords = {imported},
number = {34},
publisher = {Springer-Verlag},
series = {Lecture notes in statistics},
title = {{Metric methods for analyzing partially ranked data}},
year = {1985}
}
@inproceedings{cebe2011b,
address = {Shanghai},
author = {Ceberio, Josu and Mendiburu, Alexander and Lozano, Jose A.},
booktitle = {International Conference on Neural Information Processing (ICONIP)},
number = {23-25},
title = {{Introducing The Mallows Model on Estimation of Distribution Algorithms}},
year = {2011}
}
@article{Fligner1988,
author = {Fligner, Michael A and Verducci, Joseph S},
doi = {10.2307/2289322},
issn = {01621459},
journal = {Journal of the American Statistical Association},
number = {403},
pages = {892--901},
publisher = {JSTOR},
title = {{Multistage Ranking Models}},
url = {http://www.jstor.org/stable/2289322?origin=crossref},
volume = {83},
year = {1988}
}
@article{Xu2000,
abstract = {Abstract In this paper, we propose a (n–1)2 parameter, multistage ranking model, which represents a generalization of Luce's model. We propose then×n item-rank relative frequency matrix (p-matrix) as a device for summarizing a set of rankings. As an alternative to the traditional maximum likelihood estimation, for the proposed model we suggest a method which estimates the parameters from thep-matrix. An illustrative numerical example is given. The proposed model and its differences from Luce's model are briefly discussed. We also show some specialp-matrix patterns possessed by the Thurstonian models and distance-based models.},
author = {Xu, Liqun},
journal = {Psychometrika},
keywords = {c-matrix,collective ranking,matrix,p-,permutation,preference,random ranking generation,random ranking model},
number = {2},
pages = {217--231},
title = {{A multistage ranking model}},
volume = {65},
year = {2000}
}
@article{Regenwetter2004,
author = {Doignon, Jean-Paul},
journal = {Psychometrika},
keywords = {approval voting,foundation for grants ses98-18756,models,probabilistic choice models,probabilistic ranking,subset choice,the authors are grateful,to regenwetter,to the national science},
number = {1},
pages = {33--54},
title = {{The repeated insertion model for rankings: Missing link between two subset choice models}},
volume = {69},
year = {2004}
}
@article{Kidwell2008,
abstract = {Ranking data, which result from m raters ranking n items, are difficult to visualize due to their discrete algebraic structure, and the computational difficulties associated with them when n is large. This problem becomes worse when raters provide tied rankings or not all items are ranked. We develop an approach for the visualization of ranking data for large n which is intuitive, easy to use, and computationally efficient. The approach overcomes the structural and computational difficulties by utilizing a natural measure of dissimilarity for raters, and projecting the raters into a low dimensional vector space where they are viewed. The visualization techniques are demonstrated using voting data, jokes, and movie preferences.},
author = {Kidwell, Paul and Lebanon, Guy and Cleveland, William S},
doi = {10.1109/TVCG.2008.181},
issn = {1077-2626},
journal = {IEEE transactions on visualization and computer graphics},
number = {6},
pages = {1356--63},
pmid = {18988984},
title = {{Visualizing incomplete and partially ranked data.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18988984},
volume = {14},
year = {2008}
}
@inproceedings{Klementiev2008,
abstract = {The need to meaningfully combine sets of rankings often comes up when one deals with ranked data. Although a number of heuristic and supervised learning approaches to rank aggregation exist, they require domain knowledge or supervised ranked data, both of which are expensive to acquire. In order to address these limitations, we propose a mathematical and algorithmic framework for learning to aggregate (partial) rankings without supervision. We instantiate the framework for the cases of combining permutations and combining top-k lists, and propose a novel metric for the latter. Experiments in both scenarios demonstrate the effectiveness of the proposed formalism.},
author = {Klementiev, Alexandre and Roth, Dan and Small, Kevin},
booktitle = {International Conference on Machine Learning (ICML)},
pages = {472--479},
title = {{Unsupervised Rank Aggregation with Distance-Based Models}},
year = {2008}
}
@article{Unibertsitatea2007,
author = {Unibertsitatea, Euskal Herriko},
title = {{Memoria de investigaci´ on presentada para optar al t´ ıtulo de doctor por}},
year = {2007}
}
@article{Taylor2008,
author = {Taylor, Michael and Guiver, John and Robertson, Stephen and Minka, Tom},
keywords = {gradient descent,learning,metrics,optimization,ranking},
pages = {77--85},
title = {{SoftRank : Optimizing Non-Smooth Rank Metrics}},
year = {2008}
}
@article{Kondor2008,
author = {Kondor, Risi},
journal = {Spectrum},
title = {{The Skew Spectrum of Graphs}},
year = {2008}
}
@article{Kondor1992,
archivePrefix = {arXiv},
arxivId = {arXiv:0712.4259v1},
author = {Kondor, Risi},
eprint = {arXiv:0712.4259v1},
journal = {Neuroscience},
number = {x},
pages = {1--10},
title = {{The skew spectrum of functions on finite groups and their homogeneous spaces}},
year = {1992}
}
@article{Kondor2009,
author = {Kondor, Risi},
journal = {ReCALL},
title = {{The Graphlet Spectrum}},
year = {2009}
}
@article{Kondor2008b,
author = {Kondor, Risi},
number = {May},
title = {{Group theoretical methods in machine learning Risi Kondor}},
year = {2008}
}
@article{Borgwardt2007,
abstract = {It is widely believed that comparing discrepancies in the protein-protein interaction (PPI) networks of individuals will become an important tool in understanding and preventing diseases. Currently PPI networks for individuals are not available, but gene expression data is becoming easier to obtain and allows us to represent individuals by a co-integrated gene expression/protein interaction network. Two major problems hamper the application of graph kernels - state-of-the-art methods for whole-graph comparison - to compare PPI networks. First, these methods do not scale to graphs of the size of a PPI network. Second, missing edges in these interaction networks are biologically relevant for detecting discrepancies, yet, these methods do not take this into account. In this article we present graph kernels for biological network comparison that are fast to compute and take into account missing interactions. We evaluate their practical performance on two datasets of co-integrated gene expression/PPI networks.},
author = {Borgwardt, Karsten M and Kriegel, Hans-Peter and Vishwanathan, S V N and Schraudolph, Nicol N},
issn = {1793-5091},
journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
keywords = {Computational Biology,Databases, Genetic,Disease Progression,Gene Expression Profiling,Gene Expression Profiling: statistics {\&} numerical,Humans,Prognosis,Protein Array Analysis,Protein Array Analysis: statistics {\&} numerical dat,Protein Interaction Mapping,Protein Interaction Mapping: statistics {\&} numerica},
month = {jan},
pages = {4--15},
pmid = {17992741},
title = {{Graph kernels for disease outcome prediction from protein-protein interaction networks.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17992741},
volume = {11},
year = {2007}
}
@article{Millen2001,
author = {Millen, Brian a. and Bunge, John and Handley, John C.},
doi = {10.1117/1.1350560},
issn = {10179909},
journal = {Journal of Electronic Imaging},
number = {2},
pages = {399},
title = {{Ranked data analysis of a gamut-mapping experiment}},
url = {http://link.aip.org/link/JEIME5/v10/i2/p399/s1{\&}Agg=doi},
volume = {10},
year = {2001}
}
@article{Buchheim2006,
author = {Buchheim, Christoph and Cameron, Peter J and Wu, Taoyang},
journal = {Science},
keywords = {1991 msc,20b40,68q25,permutation groups,subgroup distance},
number = {September},
pages = {1--10},
title = {{On the Subgroup Distance Problem}},
year = {2006}
}
@article{Tapiador2008,
author = {Tapiador, Juan M Estevez and Hernandez-castro, Julio C and Alcaide, Almudena and Ribagorda, Arturo},
journal = {Communication},
number = {2},
pages = {166--172},
title = {{On the Distinguishability of Distance-Bounded Permutations in Ordered Channels}},
volume = {3},
year = {2008}
}
@article{Mao2008,
author = {Mao, Yi and Lebanon, Guy},
journal = {Journal of Machine Learning Research},
keywords = {kernel smoothing,partially ordered sets,ranked data},
pages = {2401--2429},
title = {{Non-Parametric Modeling of Partially Ranked Data}},
volume = {9},
year = {2008}
}
@article{Csiszar2009,
author = {Csisz{\'{a}}r, Villo},
doi = {10.1016/j.jmp.2009.04.011},
issn = {0022-2496},
journal = {Journal of Mathematical Psychology},
number = {4},
pages = {294--297},
publisher = {Elsevier Inc.},
title = {{On L-decomposability of random orderings}},
url = {http://dx.doi.org/10.1016/j.jmp.2009.04.011},
volume = {53},
year = {2009}
}
@inproceedings{Kondor,
author = {Kondor, Risi and Howard, Andrew and Jebara, Tony},
booktitle = {International Conference on Artificial Intelligence and Statistics},
pages = {211----218},
title = {{Multi-object tracking with representations of the symmetric group}},
year = {2007}
}
@inproceedings{Agrawal,
address = {Shanghai, China, December 17-20, 2008},
author = {Agrawal, Shipra and Wang, Zizhuo and Ye, Yinyu},
booktitle = {Internet and Network Economics},
doi = {http://dx.doi.org/10.1007/978-3-540-92185-1},
pages = {126--137},
title = {{Parimutuel betting on permutations}},
url = {http://www.springerlink.com/index/r773425g00314427.pdf},
volume = {5385},
year = {2008}
}
@inproceedings{Busse2007,
abstract = {Cluster analysis of ranking data, which occurs in consumer questionnaires, voting forms or other inquiries of preferences, attempts to identify typical groups of rank choices. Empirically measured rankings are often incomplete, i.e. different numbers of filled rank positions cause heterogeneity in the data. We propose a mixture approach for clustering of heterogeneous rank data. Rankings of different lengths can be described and compared by means of a single probabilistic model. A maximum entropy approach avoids hidden assumptions about missing rank positions. Parameter estimators and an efficient EM algorithm for unsupervised inference are derived for the ranking mixture model. Experiments on both synthetic data and real-world data demonstrate significantly improved parameter estimates on heterogeneous data when the incomplete rankings are included in the inference process.},
author = {Busse, Ludwig M and Buhmann, Joachim M},
booktitle = {International Conference on Machine Learning},
pages = {113----120},
title = {{Cluster Analysis of Heterogeneous Rank Data}},
year = {2007}
}
@article{Diaconis1998,
author = {Diaconis, Persi},
pages = {20--36},
title = {{What Do We Know about the Metropolis Algorithm ?*}},
volume = {36},
year = {1998}
}
@article{Aldous1999,
author = {Aldous, David and Diaconis, Persi},
journal = {Society},
number = {4},
pages = {413--432},
title = {{Longest increasing subsequences: from patience sorting to the Baik-Deift-Johansson Theorem}},
volume = {36},
year = {1999}
}
@article{Duh2009,
author = {Duh, Kevin K},
title = {{Learning to Rank with Partially-Labeled Data}},
year = {2009}
}
@article{Kondor2008a,
author = {Kondor, Risi},
journal = {Technology},
number = {1},
title = {{Ranking with kernels in Fourier space}},
year = {2008}
}
@article{Myrvold2000,
author = {Myrvold, Wendy},
journal = {Computer},
keywords = {1,1 g,1 historical background,2,a permutation of order,algorithms for combinatorial problems,applying modular arithmetic,for convenience when,n,n is an arrangement,of f 0,of n symbols,permutation,ranking,this paper considers permutations,unranking},
pages = {1--6},
title = {{Ranking and Unranking Permutations in Linear Time}},
year = {2000}
}
@inproceedings{Lafferty1996,
author = {Lebanon, Guy and Lafferty, John},
booktitle = {International Conference on Machine Learning (ICML)},
pages = {363--370},
title = {{Cranking: Combining rankings using conditional probability models on permutations}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.16.8754{\&}rep=rep1{\&}type=pdf},
year = {2002}
}
@article{Statistics2010,
archivePrefix = {arXiv},
arxivId = {arXiv:1006.1328v1},
author = {Statistics, Applied},
eprint = {arXiv:1006.1328v1},
journal = {Statistics},
pages = {1--65},
title = {{UNCOVERING THE RIFFLED INDEPENDENCE STRUCTURE OF RANKINGS By Jonathan Huang and Carlos Guestrin Carnegie Mellon University}},
year = {2010}
}
@article{Huangb,
author = {Huang, Jonathan},
pages = {1--5},
title = {{Structure Discovery from Partial Rankings}}
}
@article{Guestrin,
author = {Guestrin, Carlos},
journal = {Fruits},
pages = {2},
title = {{Riffled Independence for Ranked}}
}
@article{Guestrin2010,
author = {Guestrin, Carlos},
journal = {Intelligence},
title = {{Learning Hierarchical Ri e Independent Groupings from Rankings Learning Hierarchical Ri e Independent Groupings from Rankings}},
year = {2010}
}
@article{Huangc,
author = {Huang, Jonathan and Guestrin, Carlos},
journal = {Fruits},
title = {{Learning Hierarchical Ri e Independent Groupings from Rankings : Supplemental Material Ri ed independence criterion}}
}
@article{Smola2009,
author = {Smola, Alex},
title = {{Hilbert Space Embeddings of Conditional Distributions with Applications to Dynamical Systems}},
year = {2009}
}
@article{Huang2009,
abstract = {Permutations are ubiquitous in many real-world problems, such as voting, ranking, and data asso- ciation. Representing uncertainty over permutations is challenging, since there are n! possibilities, and typical compact and factorized probability distribution representations, such as graphical mod- els, cannot capture the mutual exclusivity constraints associated with permutations. In this paper, we use the “low-frequency” terms of a Fourier decomposition to represent distributions over per- mutations compactly. We present Kronecker conditioning, a novel approach for maintaining and updating these distributions directly in the Fourier domain, allowing for polynomial time bandlim- ited approximations. Low order Fourier-based approximations, however, may lead to functions that do not correspond to valid distributions. To address this problem, we present a quadratic program defined directly in the Fourier domain for projecting the approximation onto a relaxation of the polytope of legal marginal distributions. We demonstrate the effectiveness of our approach on a real camera-based multi-person tracking scenario.},
author = {Huang, Jonathan},
journal = {Journal of Machine Learning Research},
keywords = {approximate inference,group theoretical meth-,identity management,ods,permutations,sensor networks},
pages = {997--1070},
title = {{Fourier Theoretic Probabilistic Inference over Permutations}},
volume = {10},
year = {2009}
}
@inproceedings{Huang2009a,
author = {Huang, Jonathan and Guestrin, Carlos and Jiang, Xiaoye and Guibas, Leonidas},
booktitle = {Artificial Intelligence and Statistics (AISTATS)},
title = {{Exploiting Probabilistic Independence for Permutations}},
year = {2009}
}
@article{Huang,
author = {Huang, Jonathan and Guestrin, Carlos and Guibas, Leonidas},
journal = {Representations},
pages = {1--8},
title = {{Efficient Inference for Distributions on Permutations}}
}
@article{Jagabathula,
author = {Jagabathula, Srikanth},
journal = {Transform},
pages = {1--11},
title = {{Inferring rankings under constrained sensing}}
}
@article{Down,
author = {Down, Handed},
journal = {Transform},
title = {{EE 261 The Fourier Transform Integration by parts : The Fourier Transform : Convolution :}}
}
@article{Rockmore,
author = {Rockmore, Dan and Kostelec, Peter and Hordijk, Wim and Peter, F},
journal = {Transform},
keywords = {assignment problems,cayley graphs,fast fourier transform,fitness landscapes,graphs,rna folding,spectral analysis,walsh functions},
title = {{Fast Fourier Transform for Fitness Landscapes}}
}
@article{Mandhani2009,
author = {Mandhani, Bhushan and Meila, Marina},
journal = {Journal of Machine Learning Research},
pages = {392--399},
title = {{Tractable Search for Learning Exponential Models of Rankings}},
volume = {5},
year = {2009}
}
@article{Bespamyatnikh2000,
author = {Bespamyatnikh, Sergei and Segal, Michael},
journal = {Information Processing Letters},
keywords = {algorithms,longest increasing subsequence,van emde boas tree},
pages = {7--11},
title = {{Enumerating longest increasing subsequences and patience sorting}},
volume = {76},
year = {2000}
}
@article{Malm2005,
author = {Malm, Eric},
number = {May},
title = {{Decimation-in-frequency Fast Fourier Transforms for the Symmetric Group}},
year = {2005}
}
@article{Gupta2002,
abstract = {A new class of prior distributions for metric-based models in the analysis of fully and partially ranked data is developed. This class is attractive because it provides a meaningful way to encapsulate prior information about the parameters of the model. Three examples illustrate the ideas developed in the paper. Copyright 2002 Royal Statistical Society.},
author = {Gupta, Jayanti and Damien, Paul},
journal = {Journal of the Royal Statistical Society B},
keywords = {equivalence class,mallows model,symmetric group},
number = {3},
pages = {433--445},
title = {{Conjugacy class prior distributions on metric-based ranking models}},
volume = {64},
year = {2002}
}
@article{Csiszar2008,
author = {Csisz{\'{a}}r, Villo},
doi = {10.1007/s10474-008-7240-5},
issn = {0236-5294},
journal = {Acta Mathematica Hungarica},
keywords = {and phrases,conditional inde-,log-linear models,matching,random permutations},
month = {jul},
number = {1-2},
pages = {131--152},
title = {{Conditional independence relations and log-linear models for random matchings}},
url = {http://www.springerlink.com/index/10.1007/s10474-008-7240-5},
volume = {122},
year = {2008}
}
@article{Andreas2004,
author = {Andreas, W},
keywords = {barrier method,filter method,interior-point method,line search,nonconvex constrained optimization,nonlinear programming},
title = {{On the Implementation of an Interior-Point Filter Line-Search Algorithm for Large-Scale Nonlinear Programming}},
year = {2004}
}
@article{Virus2008,
abstract = {A new doping control screening method has been developed, for the analysis of doping agents in human urine, using HPLC/orbitrap with in-source collision-induced dissociation and atmospheric pressure chemical ionization. The developed method allows the detection of 29 compounds, including agents with antiestrogenic activity, beta(2) agonists, exogenous anabolic steroids, and other anabolic agents. The mass accuracy of this method is better at 2 ppm using an external reference. The detection limit for all compounds tested was better than 100 pg/ml. The recoveries of most analytes were above 70{\%}. The measured median repeatability values for doping agents included in the method at concentrations of 1 and 10 ng/ml were 21 and 17{\%}, respectively. The relative standard deviation (RSD) of the intraday precision (n = 6) ranged from RSD = 16-22{\%}, whereas the interday precision (n = 18), ranged from RSD = 17-26{\%}, depending on the solute concentration investigated.},
author = {Virus, E D and Sobolevsky, T G and Rodchenkov, G M},
doi = {10.1002/jms.1447},
issn = {1076-5174},
journal = {Journal of mass spectrometry : JMS},
keywords = {Adrenergic beta-Agonists,Adrenergic beta-Agonists: urine,Anabolic Agents,Anabolic Agents: urine,Chromatography, High Pressure Liquid,Doping in Sports,Estrogen Receptor Modulators,Estrogen Receptor Modulators: urine,Humans,Mass Screening,Spectrometry, Mass, Electrospray Ionization,Spectrometry, Mass, Electrospray Ionization: metho,Substance Abuse Detection,Substance Abuse Detection: methods},
month = {jul},
number = {7},
pages = {949--57},
pmid = {18563856},
title = {{Introduction of HPLC/orbitrap mass spectrometry as screening method for doping control.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20645174},
volume = {43},
year = {2008}
}
@book{Forsgren2002,
author = {Forsgren, Anders and Gill, Philip E and Wright, Margaret H},
booktitle = {Society},
isbn = {0036144502414},
keywords = {49d37,49j15,49j20,49m37,65f05,65k05,90c30,ams subject classifications,barrier methods,constrained minimization,interior methods,methods,nonlinear constraints,nonlinear programming,penalty methods,pii,primal-dual,s0036144502414942},
number = {4},
pages = {525--597},
title = {{Interior Methods for Nonlinear}},
volume = {44},
year = {2002}
}
@article{Volkovs2009,
author = {Volkovs, Maksims N and Zemel, Richard S},
journal = {Learning},
title = {{BoltzRank : Learning to Maximize Expected Ranking Gain}},
year = {2009}
}
@article{Jiang2011,
archivePrefix = {arXiv},
arxivId = {arXiv:1110.0807v1},
author = {Jiang, Yunjiang},
eprint = {arXiv:1110.0807v1},
journal = {October},
pages = {1--21},
title = {{Asymptotic independence of Spearman ' s uniform metric with other metrics arXiv : 1110 . 0807v1 [ math . ST ] 4 Oct 2011}},
year = {2011}
}
@article{Schiavinotto,
author = {Schiavinotto, Tommaso and St{\"{u}}tzle, Thomas},
journal = {Computers {\&} OR},
keywords = {distance,metrics,permutations,search landscape analysis},
pages = {3143--3153},
title = {{A Review of Metrics on Permutations for Search Landscape Analysis}},
volume = {34},
year = {2007}
}
@article{Morales-luna2009,
archivePrefix = {arXiv},
arxivId = {arXiv:0904.4518v1},
author = {Morales-luna, Guillermo},
eprint = {arXiv:0904.4518v1},
pages = {1--3},
title = {{arXiv : 0904 . 4518v1 [ math . OC ] 29 Apr 2009 A straightforward local-search optimization algorithm on the symmetric group}},
year = {2009}
}
@article{Wiese2003,
author = {Wiese, K},
doi = {10.1016/S0303-2647(03)00133-3},
isbn = {1604268743},
issn = {03032647},
journal = {Biosystems},
keywords = {genetic algorithms,genetic operators,representation,rna secondary structure prediction,selection},
month = {nov},
number = {1-2},
pages = {29--41},
title = {{A permutation-based genetic algorithm for the RNA folding problem: a critical look at selection strategies, crossover operators, and representation issues}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0303264703001333},
volume = {72},
year = {2003}
}
@article{Xie2005,
abstract = {MOTIVATION: False discovery rate (FDR) is defined as the expected percentage of false positives among all the claimed positives. In practice, with the true FDR unknown, an estimated FDR can serve as a criterion to evaluate the performance of various statistical methods under the condition that the estimated FDR approximates the true FDR well, or at least, it does not improperly favor or disfavor any particular method. Permutation methods have become popular to estimate FDR in genomic studies. The purpose of this paper is 2-fold. First, we investigate theoretically and empirically whether the standard permutation-based FDR estimator is biased, and if so, whether the bias inappropriately favors or disfavors any method. Second, we propose a simple modification of the standard permutation to yield a better FDR estimator, which can in turn serve as a more fair criterion to evaluate various statistical methods. RESULTS: Both simulated and real data examples are used for illustration and comparison. Three commonly used test statistics, the sample mean, SAM statistic and Student's t-statistic, are considered. The results show that the standard permutation method overestimates FDR. The overestimation is the most severe for the sample mean statistic while the least for the t-statistic with the SAM-statistic lying between the two extremes, suggesting that one has to be cautious when using the standard permutation-based FDR estimates to evaluate various statistical methods. In addition, our proposed FDR estimation method is simple and outperforms the standard method.},
author = {Xie, Yang and Pan, Wei and Khodursky, Arkady B},
doi = {10.1093/bioinformatics/bti685},
issn = {1367-4803},
journal = {Bioinformatics (Oxford, England)},
keywords = {Algorithms,Chromosome Mapping,Cluster Analysis,Computational Biology,Computational Biology: methods,Computer Simulation,DNA, Complementary,DNA, Complementary: metabolism,Data Interpretation, Statistical,False Positive Reactions,Gene Expression Profiling,Gene Expression Profiling: methods,Models, Genetic,Models, Statistical,Oligonucleotide Array Sequence Analysis,Oligonucleotide Array Sequence Analysis: methods,Pattern Recognition, Automated,Reproducibility of Results,Sensitivity and Specificity,Software},
month = {dec},
number = {23},
pages = {4280--8},
pmid = {16188930},
title = {{A note on using permutation-based false discovery rate estimates to compare different analysis methods for microarray data.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16188930},
volume = {21},
year = {2005}
}
@article{Klementiev,
author = {Klementiev, Alexandre and Roth, Dan and Small, Kevin},
journal = {Learning},
keywords = {distance-based models,rank aggregation,ranking},
title = {{A Framework for Unsupervised Rank Aggregation}}
}
@article{Maslen2003,
author = {Maslen, David K and Rockmore, Daniel N},
journal = {Signal Processing},
keywords = {bratteli diagram,cooley,fand,gel,generalized fourier transform,tsetlin basis},
number = {January 2000},
pages = {1151--1160},
title = {{The Cooley – Tukey FFT and Group Theory}},
volume = {46},
year = {2003}
}
@article{Bertolazzi2006,
author = {Bertolazzi, Paola and Godi, Alessandra and Tininini, Leonardo},
journal = {Informatica},
keywords = {haplotyping,integer linear programming,polynomial formulations},
pages = {1--17},
title = {{Solving haplotyping inference parsimony problem using a new basic polynomial formulation}},
volume = {1},
year = {2006}
}
@article{Liu2019,
abstract = {We propose an EM-based framework for learning Plackett-Luce model and its mixtures from partial orders. The core of our framework is the efficient sampling of linear extensions of partial orders under Plackett-Luce model. We propose two Markov Chain Monte Carlo (MCMC) samplers: Gibbs sampler and the generalized repeated insertion method tuned by MCMC (GRIM-MCMC), and prove the efficiency of GRIM-MCMC for a large class of preferences.Experiments on synthetic data show that the algorithm with Gibbs sampler outperforms that with GRIM-MCMC. Experiments on real-world data show that the likelihood of test dataset increases when (i) partial orders provide more information; or (ii) the number of components in mixtures of PlackettLuce model increases.},
author = {Liu, Ao and Zhao, Zhibing and Liao, Chao and Lu, Pinyan and Xia, Lirong},
doi = {10.1609/aaai.v33i01.33014328},
issn = {2159-5399},
journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
title = {{Learning Plackett-Luce Mixtures from Partial Preferences}},
year = {2019}
}
@article{Mollica2017,
abstract = {The elicitation of an ordinal judgment on multiple alternatives is often required in many psychological and behavioral experiments to investigate preference/choice orientation of a specific population. The Plackett–Luce model is one of the most popular and frequently applied parametric distributions to analyze rankings of a finite set of items. The present work introduces a Bayesian finite mixture of Plackett–Luce models to account for unobserved sample heterogeneity of partially ranked data. We describe an efficient way to incorporate the latent group structure in the data augmentation approach and the derivation of existing maximum likelihood procedures as special instances of the proposed Bayesian method. Inference can be conducted with the combination of the Expectation-Maximization algorithm for maximum a posteriori estimation and the Gibbs sampling iterative procedure. We additionally investigate several Bayesian criteria for selecting the optimal mixture configuration and describe diagnostic tools for assessing the fitness of ranking distributions conditionally and unconditionally on the number of ranked items. The utility of the novel Bayesian parametric Plackett–Luce mixture for characterizing sample heterogeneity is illustrated with several applications to simulated and real preference ranked data. We compare our method with the frequentist approach and a Bayesian nonparametric mixture model both assuming the Plackett–Luce model as a mixture component. Our analysis on real datasets reveals the importance of an accurate diagnostic check for an appropriate in-depth understanding of the heterogenous nature of the partial ranking data.},
author = {Mollica, Cristina and Tardella, Luca},
doi = {10.1007/s11336-016-9530-0},
issn = {00333123},
journal = {Psychometrika},
keywords = {Gibbs sampling,MAP estimation,Plackett–Luce model,data augmentation,goodness-of-fit,label switching,mixture models,ranking data},
pmid = {27734294},
title = {{Bayesian Plackett–Luce Mixture Models for Partially Ranked Data}},
year = {2017}
}
