\begin{thebibliography}{86}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi

\bibitem[{Anil et~al.(2018)Anil, Pereyra, Passos, Ormandi, Dahl, and
  Hinton}]{anil2018large}
Rohan Anil, Gabriel Pereyra, Alexandre Passos, Robert Ormandi, George~E Dahl,
  and Geoffrey~E Hinton. 2018.
\newblock Large scale distributed neural network training through online
  distillation.
\newblock \emph{arXiv preprint arXiv:1804.03235}.

\bibitem[{Antol et~al.(2015)Antol, Agrawal, Lu, Mitchell, Batra,
  Lawrence~Zitnick, and Parikh}]{antol2015vqa}
Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra,
  C~Lawrence~Zitnick, and Devi Parikh. 2015.
\newblock Vqa: Visual question answering.
\newblock In \emph{ICCV}.

\bibitem[{Ba and Caruana(2014)}]{ba2013do}
Lei~Jimmy Ba and Rich Caruana. 2014.
\newblock Do deep nets really need to be deep?
\newblock In \emph{NeurIPS}.

\bibitem[{Bender and Koller(2020)}]{bender-koller-2020-climbing}
Emily~M. Bender and Alexander Koller. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.acl-main.463} {Climbing
  towards {NLU}: {On} meaning, form, and understanding in the age of data}.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pages 5185--5198, Online. Association for
  Computational Linguistics.

\bibitem[{Bisk et~al.(2020{\natexlab{a}})Bisk, Holtzman, Thomason, Andreas,
  Bengio, Chai, Lapata, Lazaridou, May, Nisnevich et~al.}]{bisk2020experience}
Yonatan Bisk, Ari Holtzman, Jesse Thomason, Jacob Andreas, Yoshua Bengio, Joyce
  Chai, Mirella Lapata, Angeliki Lazaridou, Jonathan May, Aleksandr Nisnevich,
  et~al. 2020{\natexlab{a}}.
\newblock Experience grounds language.
\newblock In \emph{EMNLP}.

\bibitem[{Bisk et~al.(2020{\natexlab{b}})Bisk, Zellers, Gao, Choi
  et~al.}]{bisk2020piqa}
Yonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi, et~al.
  2020{\natexlab{b}}.
\newblock Piqa: Reasoning about physical commonsense in natural language.
\newblock In \emph{AAAI}, pages 7432--7439.

\bibitem[{Bordes et~al.(2019)Bordes, Zablocki, Soulier, Piwowarski, and
  Gallinari}]{bordes2020incorporating}
Patrick Bordes, Eloi Zablocki, Laure Soulier, Benjamin Piwowarski, and Patrick
  Gallinari. 2019.
\newblock Incorporating visual semantics into sentence representations within a
  grounded space.
\newblock In \emph{EMNLP-IJCNLP}.

\bibitem[{Caba~Heilbron et~al.(2015)Caba~Heilbron, Escorcia, Ghanem, and
  Carlos~Niebles}]{caba2015activitynet}
Fabian Caba~Heilbron, Victor Escorcia, Bernard Ghanem, and Juan Carlos~Niebles.
  2015.
\newblock Activitynet: A large-scale video benchmark for human activity
  understanding.
\newblock In \emph{CVPR}, pages 961--970.

\bibitem[{Carlini et~al.(2020)Carlini, Tram{\`{e}}r, Wallace, Jagielski,
  Herbert{-}Voss, Lee, Roberts, Brown, Song, Erlingsson, Oprea, and
  Raffel}]{extractionattack}
Nicholas Carlini, Florian Tram{\`{e}}r, Eric Wallace, Matthew Jagielski, Ariel
  Herbert{-}Voss, Katherine Lee, Adam Roberts, Tom~B. Brown, Dawn Song,
  {\'{U}}lfar Erlingsson, Alina Oprea, and Colin Raffel. 2020.
\newblock Extracting training data from large language models.
\newblock \emph{arXiv preprint arXiv:2012.07805}.

\bibitem[{Cer et~al.(2017)Cer, Diab, Agirre, Lopez-Gazpio, and
  Specia}]{cer2017semeval}
Daniel Cer, Mona Diab, Eneko Agirre, Inigo Lopez-Gazpio, and Lucia Specia.
  2017.
\newblock Semeval-2017 task 1: Semantic textual similarity-multilingual and
  cross-lingual focused evaluation.
\newblock In \emph{SemEval}.

\bibitem[{Chebotar and Waters(2016)}]{chebotar2016distilling}
Yevgen Chebotar and Austin Waters. 2016.
\newblock Distilling knowledge from ensembles of neural networks for speech
  recognition.
\newblock In \emph{Interspeech}, pages 3439--3443.

\bibitem[{Chen et~al.(2020{\natexlab{a}})Chen, Kornblith, Norouzi, and
  Hinton}]{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
  2020{\natexlab{a}}.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{ICML}, pages 1597--1607. PMLR.

\bibitem[{Chen et~al.(2015)Chen, Fang, Lin, Vedantam, Gupta, Doll{\'a}r, and
  Zitnick}]{chen2015microsoft}
Xinlei Chen, Hao Fang, Tsung-Yi Lin, Ramakrishna Vedantam, Saurabh Gupta, Piotr
  Doll{\'a}r, and C~Lawrence Zitnick. 2015.
\newblock Microsoft coco captions: Data collection and evaluation server.
\newblock \emph{arXiv preprint arXiv:1504.00325}.

\bibitem[{Chen et~al.(2020{\natexlab{b}})Chen, Li, Yu, Kholy, Ahmed, Gan,
  Cheng, and Liu}]{chen2019uniter}
Yen-Chun Chen, Linjie Li, Licheng Yu, Ahmed~El Kholy, Faisal Ahmed, Zhe Gan,
  Yu~Cheng, and Jingjing Liu. 2020{\natexlab{b}}.
\newblock Uniter: Learning universal image-text representations.
\newblock In \emph{ECCV}.

\bibitem[{Chen et~al.(2018)Chen, Wang, and Zhang}]{chen2018darkrank}
Yuntao Chen, Naiyan Wang, and Zhaoxiang Zhang. 2018.
\newblock Darkrank: Accelerating deep metric learning via cross sample
  similarities transfer.
\newblock In \emph{AAAI}.

\bibitem[{Christie et~al.(2016)Christie, Laddha, Agrawal, Antol, Goyal,
  Kochersberger, and Batra}]{christie2016resolving}
Gordon Christie, Ankit Laddha, Aishwarya Agrawal, Stanislaw Antol, Yash Goyal,
  Kevin Kochersberger, and Dhruv Batra. 2016.
\newblock Resolving language and vision ambiguities together: Joint
  segmentation \& prepositional attachment resolution in captioned scenes.
\newblock In \emph{EMNLP}.

\bibitem[{Clark et~al.(2020)Clark, Luong, Le, and Manning}]{clark2020electra}
Kevin Clark, Minh-Thang Luong, Quoc~V Le, and Christopher~D Manning. 2020.
\newblock Electra: Pre-training text encoders as discriminators rather than
  generators.
\newblock In \emph{ICLR}.

\bibitem[{Conneau et~al.(2020)Conneau, Khandelwal, Goyal, Chaudhary, Wenzek,
  Guzm{\'a}n, Grave, Ott, Zettlemoyer, and Stoyanov}]{conneau2019unsupervised}
Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume
  Wenzek, Francisco Guzm{\'a}n, Edouard Grave, Myle Ott, Luke Zettlemoyer, and
  Veselin Stoyanov. 2020.
\newblock Unsupervised cross-lingual representation learning at scale.
\newblock In \emph{ACL}.

\bibitem[{Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei}]{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei. 2009.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{CVPR}.

\bibitem[{Devlin et~al.(2018)Devlin, Chang, Lee, and
  Toutanova}]{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{NAACL}.

\bibitem[{Do et~al.(2019)Do, Do, Tran, Tjiputra, and Tran}]{do2019compact}
Tuong Do, Thanh-Toan Do, Huy Tran, Erman Tjiputra, and Quang~D Tran. 2019.
\newblock Compact trilinear interaction for visual question answering.
\newblock In \emph{ICCV}, pages 392--401.

\bibitem[{Dodge et~al.(2020)Dodge, Ilharco, Schwartz, Farhadi, Hajishirzi, and
  Smith}]{dodge2020fine}
Jesse Dodge, Gabriel Ilharco, Roy Schwartz, Ali Farhadi, Hannaneh Hajishirzi,
  and Noah Smith. 2020.
\newblock Fine-tuning pretrained language models: Weight initializations, data
  orders, and early stopping.
\newblock \emph{arXiv preprint arXiv:2002.06305}.

\bibitem[{Dong et~al.(2019)Dong, Yang, Wang, Wei, Liu, Wang, Gao, Zhou, and
  Hon}]{dong2019unified}
Li~Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu~Wang, Jianfeng Gao,
  Ming Zhou, and Hsiao-Wuen Hon. 2019.
\newblock Unified language model pre-training for natural language
  understanding and generation.
\newblock In \emph{NeurIPS}.

\bibitem[{Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly
  et~al.}]{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al. 2021.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In \emph{ICLR}.

\bibitem[{Graff et~al.(2003)Graff, Kong, Chen, and Maeda}]{graff2003english}
David Graff, Junbo Kong, Ke~Chen, and Kazuaki Maeda. 2003.
\newblock English gigaword.
\newblock \emph{Linguistic Data Consortium, Philadelphia}, 4(1):34.

\bibitem[{Gretton et~al.(2012)Gretton, Borgwardt, Rasch, Sch{{\"o}}lkopf, and
  Smola}]{JMLR:v13:gretton12a}
Arthur Gretton, Karsten~M. Borgwardt, Malte~J. Rasch, Bernhard Sch{{\"o}}lkopf,
  and Alexander Smola. 2012.
\newblock \href {http://jmlr.org/papers/v13/gretton12a.html} {A kernel
  two-sample test}.
\newblock \emph{JMLR}, 13(25):723--773.

\bibitem[{Grill et~al.(2020)Grill, Strub, Altch{\'e}, Tallec, Richemond,
  Buchatskaya, Doersch, Pires, Guo, Azar et~al.}]{grill2020bootstrap}
Jean-Bastien Grill, Florian Strub, Florent Altch{\'e}, Corentin Tallec,
  Pierre~H Richemond, Elena Buchatskaya, Carl Doersch, Bernardo~Avila Pires,
  Zhaohan~Daniel Guo, Mohammad~Gheshlaghi Azar, et~al. 2020.
\newblock Bootstrap your own latent: A new approach to self-supervised
  learning.
\newblock In \emph{NeurIPS}.

\bibitem[{Gupta et~al.(2016)Gupta, Hoffman, and Malik}]{gupta2016cross}
Saurabh Gupta, Judy Hoffman, and Jitendra Malik. 2016.
\newblock Cross modal distillation for supervision transfer.
\newblock In \emph{CVPR}, pages 2827--2836.

\bibitem[{Hara et~al.(2018)Hara, Kataoka, and Satoh}]{hara3dcnns}
Kensho Hara, Hirokatsu Kataoka, and Yutaka Satoh. 2018.
\newblock Can spatiotemporal 3d cnns retrace the history of 2d cnns and
  imagenet?
\newblock In \emph{CVPR}.

\bibitem[{Harnad(1990)}]{HARNAD1990335}
Stevan Harnad. 1990.
\newblock \href {https://doi.org/https://doi.org/10.1016/0167-2789(90)90087-6}
  {The symbol grounding problem}.
\newblock \emph{Physica D: Nonlinear Phenomena}, 42(1):335--346.

\bibitem[{He et~al.(2016)He, Zhang, Ren, and Sun}]{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016.
\newblock Deep residual learning for image recognition.
\newblock In \emph{CVPR}, pages 770--778.

\bibitem[{He et~al.(2019)He, Zhang, Zhang, Zhang, Xie, and Li}]{he2019bag}
Tong He, Zhi Zhang, Hang Zhang, Zhongyue Zhang, Junyuan Xie, and Mu~Li. 2019.
\newblock Bag of tricks for image classification with convolutional neural
  networks.
\newblock In \emph{CVPR}, pages 558--567.

\bibitem[{Hessel et~al.(2019)Hessel, Lee, and Mimno}]{hessel2019unsupervised}
Jack Hessel, Lillian Lee, and David Mimno. 2019.
\newblock Unsupervised discovery of multimodal links in multi-image,
  multi-sentence documents.
\newblock In \emph{EMNLP-IJCNLP}, pages 2034--2045.

\bibitem[{Hinton et~al.(2014)Hinton, Vinyals, and Dean}]{hinton2015distilling}
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2014.
\newblock Distilling the knowledge in a neural network.
\newblock In \emph{NeurIPS Deep Learning Workshop}.

\bibitem[{Huang and Wang(2017)}]{huang2017like}
Zehao Huang and Naiyan Wang. 2017.
\newblock Like what you like: Knowledge distill via neuron selectivity
  transfer.
\newblock \emph{arXiv preprint arXiv:1707.01219}.

\bibitem[{Iyer et~al.(2017)Iyer, Dandekar, and Csernai}]{iyer2017qqp}
Shankar Iyer, Nikhil Dandekar, and Kornel Csernai. 2017.
\newblock \href
  {https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs} {First
  quora dataset release: Question pairs}.

\bibitem[{Kataoka et~al.(2020)Kataoka, Wakamiya, Hara, and
  Satoh}]{kataoka2020would}
Hirokatsu Kataoka, Tenga Wakamiya, Kensho Hara, and Yutaka Satoh. 2020.
\newblock Would mega-scale datasets further enhance spatiotemporal 3d cnns?
\newblock \emph{arXiv preprint arXiv:2004.04968}.

\bibitem[{Kay et~al.(2017)Kay, Carreira, Simonyan, Zhang, Hillier,
  Vijayanarasimhan, Viola, Green, Back, Natsev et~al.}]{kay2017kinetics}
Will Kay, Joao Carreira, Karen Simonyan, Brian Zhang, Chloe Hillier, Sudheendra
  Vijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, Paul Natsev, et~al.
  2017.
\newblock The kinetics human action video dataset.
\newblock \emph{arXiv preprint arXiv:1705.06950}.

\bibitem[{Kiela et~al.(2018)Kiela, Conneau, Jabri, and
  Nickel}]{kiela2017learning}
Douwe Kiela, Alexis Conneau, Allan Jabri, and Maximilian Nickel. 2018.
\newblock Learning visually grounded sentence representations.
\newblock In \emph{NAACL}.

\bibitem[{Kiela et~al.(2015)Kiela, Vulic, and Clark}]{kiela2015visual}
Douwe Kiela, Ivan Vulic, and Stephen Clark. 2015.
\newblock Visual bilingual lexicon induction with transferred convnet features.
\newblock In \emph{EMNLP}. ACL; East Stroudsburg, PA.

\bibitem[{Kim and Rush(2016)}]{kim2016sequence}
Yoon Kim and Alexander~M Rush. 2016.
\newblock Sequence-level knowledge distillation.
\newblock In \emph{ACL}.

\bibitem[{Kingma and Ba(2014)}]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba. 2014.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{ICLR}.

\bibitem[{Kong et~al.(2014)Kong, Lin, Bansal, Urtasun, and
  Fidler}]{kong2014you}
Chen Kong, Dahua Lin, Mohit Bansal, Raquel Urtasun, and Sanja Fidler. 2014.
\newblock What are you talking about? text-to-image coreference.
\newblock In \emph{CVPR}, pages 3558--3565.

\bibitem[{Kuehne et~al.(2011)Kuehne, Jhuang, Garrote, Poggio, and
  Serre}]{kuehne2011hmdb}
Hildegard Kuehne, Hueihan Jhuang, Est{\'\i}baliz Garrote, Tomaso Poggio, and
  Thomas Serre. 2011.
\newblock Hmdb: a large video database for human motion recognition.
\newblock In \emph{ICCV}, pages 2556--2563. IEEE.

\bibitem[{Lan et~al.(2020)Lan, Chen, Goodman, Gimpel, Sharma, and
  Soricut}]{lan2019albert}
Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and
  Radu Soricut. 2020.
\newblock Albert: A lite bert for self-supervised learning of language
  representations.
\newblock In \emph{ICLR}.

\bibitem[{Li et~al.(2020{\natexlab{a}})Li, Duan, Fang, Gong, Jiang, and
  Zhou}]{li2020unicoder}
Gen Li, Nan Duan, Yuejian Fang, Ming Gong, Daxin Jiang, and Ming Zhou.
  2020{\natexlab{a}}.
\newblock Unicoder-vl: A universal encoder for vision and language by
  cross-modal pre-training.
\newblock In \emph{AAAI}, pages 11336--11344.

\bibitem[{Li et~al.(2020{\natexlab{b}})Li, Chen, Cheng, Gan, Yu, and
  Liu}]{li2020hero}
Linjie Li, Yen-Chun Chen, Yu~Cheng, Zhe Gan, Licheng Yu, and Jingjing Liu.
  2020{\natexlab{b}}.
\newblock Hero: Hierarchical encoder for video+ language omni-representation
  pre-training.
\newblock In \emph{EMNLP}.

\bibitem[{Li et~al.(2020{\natexlab{c}})Li, Gao, Niu, Xiao, Liu, Liu, Wu, and
  Wang}]{li2020unimo}
Wei Li, Can Gao, Guocheng Niu, Xinyan Xiao, Hao Liu, Jiachen Liu, Hua Wu, and
  Haifeng Wang. 2020{\natexlab{c}}.
\newblock Unimo: Towards unified-modal understanding and generation via
  cross-modal contrastive learning.
\newblock \emph{arXiv preprint arXiv:2012.15409}.

\bibitem[{Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan,
  Doll{\'a}r, and Zitnick}]{lin2014microsoft}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick. 2014.
\newblock Microsoft coco: Common objects in context.
\newblock In \emph{ECCV}, pages 740--755. Springer.

\bibitem[{Liu et~al.(2019)Liu, Ott, Goyal, Du, Joshi, Chen, Levy, Lewis,
  Zettlemoyer, and Stoyanov}]{liu2019roberta}
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer
  Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019.
\newblock Roberta: A robustly optimized bert pretraining approach.
\newblock \emph{arXiv preprint arXiv:1907.11692}.

\bibitem[{Loshchilov and Hutter(2019)}]{loshchilov2017decoupled}
Ilya Loshchilov and Frank Hutter. 2019.
\newblock Decoupled weight decay regularization.
\newblock In \emph{ICLR}.

\bibitem[{Lu et~al.(2019)Lu, Batra, Parikh, and Lee}]{lu2019vilbert}
Jiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee. 2019.
\newblock Vilbert: Pretraining task-agnostic visiolinguistic representations
  for vision-and-language tasks.
\newblock In \emph{NeurIPS}.

\bibitem[{Merity et~al.(2017)Merity, Xiong, Bradbury, and
  Socher}]{merity2016pointer}
Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. 2017.
\newblock Pointer sentinel mixture models.
\newblock In \emph{ICLR}.

\bibitem[{Miech et~al.(2020)Miech, Alayrac, Smaira, Laptev, Sivic, and
  Zisserman}]{miech2020end}
Antoine Miech, Jean-Baptiste Alayrac, Lucas Smaira, Ivan Laptev, Josef Sivic,
  and Andrew Zisserman. 2020.
\newblock End-to-end learning of visual representations from uncurated
  instructional videos.
\newblock In \emph{CVPR}.

\bibitem[{Miech et~al.(2019)Miech, Zhukov, Alayrac, Tapaswi, Laptev, and
  Sivic}]{miech2019howto100m}
Antoine Miech, Dimitri Zhukov, Jean-Baptiste Alayrac, Makarand Tapaswi, Ivan
  Laptev, and Josef Sivic. 2019.
\newblock Howto100m: Learning a text-video embedding by watching hundred
  million narrated video clips.
\newblock In \emph{ICCV}, pages 2630--2640.

\bibitem[{Mirzadeh et~al.(2020)Mirzadeh, Farajtabar, Li, Levine, Matsukawa, and
  Ghasemzadeh}]{mirzadeh2020improved}
Seyed~Iman Mirzadeh, Mehrdad Farajtabar, Ang Li, Nir Levine, Akihiro Matsukawa,
  and Hassan Ghasemzadeh. 2020.
\newblock Improved knowledge distillation via teacher assistant.
\newblock In \emph{AAAI}.

\bibitem[{Paszke et~al.(2017)Paszke, Gross, Chintala, Chanan, Yang, DeVito,
  Lin, Desmaison, Antiga, and Lerer}]{paszke2017automatic}
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary
  DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. 2017.
\newblock Automatic differentiation in {PyTorch}.
\newblock In \emph{NIPS Autodiff Workshop}.

\bibitem[{Peters et~al.(2018)Peters, Neumann, Iyyer, Gardner, Clark, Lee, and
  Zettlemoyer}]{peters2018deep}
Matthew~E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark,
  Kenton Lee, and Luke Zettlemoyer. 2018.
\newblock Deep contextualized word representations.
\newblock In \emph{NAACL}.

\bibitem[{Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal,
  Sastry, Askell, Mishkin, Clark et~al.}]{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al. 2021.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock \emph{arXiv preprint arXiv:2103.00020}.

\bibitem[{Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena,
  Zhou, Li, and Liu}]{raffel2020exploring}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
  Matena, Yanqi Zhou, Wei Li, and Peter~J Liu. 2020.
\newblock Exploring the limits of transfer learning with a unified text-to-text
  transformer.
\newblock \emph{JMLR}.

\bibitem[{Rajpurkar et~al.(2018)Rajpurkar, Jia, and Liang}]{rajpurkar2018know}
Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018.
\newblock Know what you don't know: Unanswerable questions for squad.
\newblock In \emph{ACL}.

\bibitem[{Rajpurkar et~al.(2016)Rajpurkar, Zhang, Lopyrev, and
  Liang}]{rajpurkar2016squad}
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016.
\newblock Squad: 100,000+ questions for machine comprehension of text.
\newblock In \emph{EMNLP}.

\bibitem[{Rush et~al.(2015)Rush, Chopra, and Weston}]{Rush_2015}
Alexander~M. Rush, Sumit Chopra, and Jason Weston. 2015.
\newblock \href {https://doi.org/10.18653/v1/d15-1044} {A neural attention
  model for abstractive sentence summarization}.
\newblock In \emph{EMNLP}.

\bibitem[{See et~al.(2017)See, Liu, and Manning}]{see2017get}
Abigail See, Peter~J Liu, and Christopher~D Manning. 2017.
\newblock Get to the point: Summarization with pointer-generator networks.
\newblock In \emph{ACL}.

\bibitem[{Song et~al.(2019)Song, Tan, Qin, Lu, and Liu}]{song2019mass}
Kaitao Song, Xu~Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. 2019.
\newblock Mass: Masked sequence to sequence pre-training for language
  generation.
\newblock In \emph{ICML}.

\bibitem[{Soomro et~al.(2012)Soomro, Zamir, and Shah}]{soomro2012ucf101}
Khurram Soomro, Amir~Roshan Zamir, and Mubarak Shah. 2012.
\newblock Ucf101: A dataset of 101 human actions classes from videos in the
  wild.
\newblock \emph{CoRR}.

\bibitem[{Sun et~al.(2019)Sun, Myers, Vondrick, Murphy, and
  Schmid}]{sun2019videobert}
Chen Sun, Austin Myers, Carl Vondrick, Kevin Murphy, and Cordelia Schmid. 2019.
\newblock Videobert: A joint model for video and language representation
  learning.
\newblock In \emph{ICCV}.

\bibitem[{Tan and Bansal(2019)}]{tan2019lxmert}
Hao Tan and Mohit Bansal. 2019.
\newblock Lxmert: Learning cross-modality encoder representations from
  transformers.
\newblock In \emph{EMNLP}.

\bibitem[{Tan and Bansal(2020)}]{tan2020vokenization}
Hao Tan and Mohit Bansal. 2020.
\newblock Vokenization: improving language understanding with contextualized,
  visual-grounded supervision.
\newblock In \emph{EMNLP}.

\bibitem[{Tang and Wang(2018)}]{tang2018ranking}
Jiaxi Tang and Ke~Wang. 2018.
\newblock Ranking distillation: Learning compact ranking models with high
  performance for recommender system.
\newblock In \emph{SIGKDD}, pages 2289--2298.

\bibitem[{Tang et~al.(2021)Tang, Lei, and Bansal}]{tang2021decembert}
Zineng Tang, Jie Lei, and Mohit Bansal. 2021.
\newblock Decembert: Learning from noisy instructional videos via dense
  captions and entropy minimization.
\newblock In \emph{NAACL-HLT}, pages 2415--2426.

\bibitem[{Tian et~al.(2020)Tian, Krishnan, and Isola}]{tian2019contrastive}
Yonglong Tian, Dilip Krishnan, and Phillip Isola. 2020.
\newblock Contrastive representation distillation.
\newblock In \emph{ICLR}.

\bibitem[{Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones,
  Gomez, Kaiser, and Polosukhin}]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin. 2017.
\newblock Attention is all you need.
\newblock In \emph{NeurIPS}.

\bibitem[{Wang et~al.(2018)Wang, Singh, Michael, Hill, Levy, and
  Bowman}]{wang2018glue}
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel~R
  Bowman. 2018.
\newblock Glue: A multi-task benchmark and analysis platform for natural
  language understanding.
\newblock In \emph{ICLR}.

\bibitem[{Williams et~al.(2018)Williams, Nangia, and
  Bowman}]{williams2017broad}
Adina Williams, Nikita Nangia, and Samuel~R Bowman. 2018.
\newblock A broad-coverage challenge corpus for sentence understanding through
  inference.
\newblock In \emph{NAACL}.

\bibitem[{Xie et~al.(2018)Xie, Sun, Huang, Tu, and Murphy}]{Xie_2018_ECCV}
Saining Xie, Chen Sun, Jonathan Huang, Zhuowen Tu, and Kevin Murphy. 2018.
\newblock Rethinking spatiotemporal feature learning: Speed-accuracy trade-offs
  in video classification.
\newblock In \emph{ECCV}.

\bibitem[{Xu et~al.(2016)Xu, Mei, Yao, and Rui}]{xu2016msr}
Jun Xu, Tao Mei, Ting Yao, and Yong Rui. 2016.
\newblock Msr-vtt: A large video description dataset for bridging video and
  language.
\newblock In \emph{CVPR}.

\bibitem[{Xu et~al.(2018)Xu, Hsu, and Huang}]{xu2017training}
Zheng Xu, Yen-Chang Hsu, and Jiawei Huang. 2018.
\newblock Training shallow and thin networks for acceleration via knowledge
  distillation with conditional adversarial networks.
\newblock In \emph{ICLR Workshop}.

\bibitem[{Yang et~al.(2019)Yang, Dai, Yang, Carbonell, Salakhutdinov, and
  Le}]{yang2019xlnet}
Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ~R Salakhutdinov,
  and Quoc~V Le. 2019.
\newblock Xlnet: Generalized autoregressive pretraining for language
  understanding.
\newblock In \emph{NeurIPS}.

\bibitem[{Zellers et~al.(2018)Zellers, Bisk, Schwartz, and
  Choi}]{zellers2018swag}
Rowan Zellers, Yonatan Bisk, Roy Schwartz, and Yejin Choi. 2018.
\newblock Swag: A large-scale adversarial dataset for grounded commonsense
  inference.
\newblock In \emph{EMNLP}.

\bibitem[{Zhang et~al.(2018)Zhang, Xiang, Hospedales, and Lu}]{zhang2018deep}
Ying Zhang, Tao Xiang, Timothy~M Hospedales, and Huchuan Lu. 2018.
\newblock Deep mutual learning.
\newblock In \emph{CVPR}, pages 4320--4328.

\bibitem[{Zhang et~al.(2019)Zhang, Chen, Wang, Utiyama, Sumita, Li, and
  Zhao}]{zhang2019neural}
Zhuosheng Zhang, Kehai Chen, Rui Wang, Masao Utiyama, Eiichiro Sumita, Zuchao
  Li, and Hai Zhao. 2019.
\newblock Neural machine translation with universal visual representation.
\newblock In \emph{ICLR}.

\bibitem[{Zhou et~al.(2021)Zhou, Richardson, Ning, Khot, Sabharwal, and
  Roth}]{zhou-etal-2021-temporal}
Ben Zhou, Kyle Richardson, Qiang Ning, Tushar Khot, Ashish Sabharwal, and Dan
  Roth. 2021.
\newblock \href {https://www.aclweb.org/anthology/2021.naacl-main.107}
  {Temporal reasoning on implicit events from distant supervision}.
\newblock In \emph{Proceedings of the 2021 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 1361--1371, Online. Association for Computational
  Linguistics.

\bibitem[{Zhou et~al.(2020)Zhou, Palangi, Zhang, Hu, Corso, and
  Gao}]{zhou2020unified}
Luowei Zhou, Hamid Palangi, Lei Zhang, Houdong Hu, Jason~J Corso, and Jianfeng
  Gao. 2020.
\newblock Unified vision-language pre-training for image captioning and vqa.
\newblock In \emph{AAAI}.

\bibitem[{Zhou et~al.(2017)Zhou, Xu, and Corso}]{zhou2017towards}
Luowei Zhou, Chenliang Xu, and Jason~J Corso. 2017.
\newblock Towards automatic learning of procedures from web instructional
  videos.
\newblock In \emph{AAAI}.

\bibitem[{Zhu and Yang(2020)}]{zhu2020actbert}
Linchao Zhu and Yi~Yang. 2020.
\newblock Actbert: Learning global-local video-text representations.
\newblock In \emph{CVPR}.

\end{thebibliography}
