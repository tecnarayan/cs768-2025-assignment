\begin{thebibliography}{35}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Akrout et~al.(2019)Akrout, Wilson, Humphreys, Lillicrap, and
  Tweed]{akrout_deep_2019}
Akrout, M., Wilson, C., Humphreys, P.~C., Lillicrap, T., and Tweed, D.
\newblock Deep {Learning} without {Weight} {Transport}.
\newblock \emph{arXiv:1904.05391 [cs, stat]}, April 2019.
\newblock URL \url{http://arxiv.org/abs/1904.05391}.
\newblock arXiv: 1904.05391.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{ba2016layer}
Ba, J.~L., Kiros, J.~R., and Hinton, G.~E.
\newblock Layer normalization.
\newblock \emph{arXiv preprint arXiv:1607.06450}, 2016.

\bibitem[Baldi et~al.(2018)Baldi, Sadowski, and Lu]{baldi_learning_2018}
Baldi, P., Sadowski, P., and Lu, Z.
\newblock Learning in the machine: {R}andom backpropagation and the deep
  learning channel.
\newblock \emph{Artificial Intelligence}, 260:\penalty0 1--35, 2018.
\newblock \doi{10.1016/j.artint.2018.03.003}.

\bibitem[Bartunov et~al.(2018)Bartunov, Santoro, Richards, Marris, Hinton, and
  Lillicrap]{bartunov_assessing_2018}
Bartunov, S., Santoro, A., Richards, B., Marris, L., Hinton, G.~E., and
  Lillicrap, T.
\newblock Assessing the {S}calability of {B}iologically-{M}otivated {D}eep
  {L}earning {A}lgorithms and {A}rchitectures.
\newblock In Bengio, S., Wallach, H., Larochelle, H., Grauman, K.,
  Cesa-Bianchi, N., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems 31}, pp.\  9368--9378. Curran Associates,
  Inc., 2018.
\newblock URL
  \url{http://papers.nips.cc/paper/8148-assessing-the-scalability-of-biologically-motivated-deep-learning-algorithms-and-architectures.pdf}.

\bibitem[Bengio(2014)]{bengio_how_2014}
Bengio, Y.
\newblock How {A}uto-{E}ncoders {C}ould {P}rovide {C}redit {A}ssignment in
  {D}eep {N}etworks via {T}arget {P}ropagation.
\newblock \emph{ArXiv}, abs/1407.7906, 2014.

\bibitem[Bengio et~al.(2017)Bengio, Mesnard, Fischer, Zhang, and
  Wu]{bengio2017STDP}
Bengio, Y., Mesnard, T., Fischer, A., Zhang, S., and Wu, Y.
\newblock {STDP}-{C}ompatible {A}pproximation of {B}ackpropagation in an
  {E}nergy-{B}ased {M}odel.
\newblock \emph{Neural Computation}, 29\penalty0 (3):\penalty0 555--577, 2017.
\newblock \doi{10.1162/NECO\_a\_00934}.
\newblock URL \url{https://doi.org/10.1162/NECO_a_00934}.
\newblock PMID: 28095200.

\bibitem[Bergstra et~al.(2011)Bergstra, Bardenet, Bengio, and
  K{\'e}gl]{bergstra_tpe_2011}
Bergstra, J.~S., Bardenet, R., Bengio, Y., and K{\'e}gl, B.
\newblock Algorithms for hyper-parameter optimization.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  2546--2554, 2011.

\bibitem[Buchlovsky et~al.(2019)Buchlovsky, Budden, Grewe, Jones, Aslanides,
  Besse, Brock, Clark, Colmenarejo, Pope, et~al.]{buchlovsky2019tf}
Buchlovsky, P., Budden, D., Grewe, D., Jones, C., Aslanides, J., Besse, F.,
  Brock, A., Clark, A., Colmenarejo, S.~G., Pope, A., et~al.
\newblock Tf-replicator: {D}istributed machine learning for researchers.
\newblock \emph{arXiv preprint arXiv:1902.00465}, 2019.

\bibitem[Cadena et~al.(2019)Cadena, Denfield, Walker, Gatys, Tolias, Bethge,
  and Ecker]{cadena2019deep}
Cadena, S.~A., Denfield, G.~H., Walker, E.~Y., Gatys, L.~A., Tolias, A.~S.,
  Bethge, M., and Ecker, A.~S.
\newblock Deep convolutional models improve predictions of macaque v1 responses
  to natural images.
\newblock \emph{PLoS computational biology}, 15\penalty0 (4):\penalty0
  e1006897, 2019.

\bibitem[Crick(1989)]{crick_recent_1989}
Crick, F.
\newblock The recent excitement about neural networks.
\newblock \emph{Nature}, 337:\penalty0 129–132, 1989.
\newblock \doi{10.1038/337129a0}.

\bibitem[Grossberg(1987)]{grossberg_competitive_1987}
Grossberg, S.
\newblock Competitive {L}earning: {F}rom {I}nteractive {A}ctivation to
  {A}daptive {R}esonance.
\newblock \emph{Cognitive Science}, 11:\penalty0 23--63, 1987.

\bibitem[Guerguiev et~al.(2017)Guerguiev, Lillicrap, and
  Richards]{guerguiev_towards_2017}
Guerguiev, J., Lillicrap, T.~P., and Richards, B.~A.
\newblock Towards deep learning with segregated dendrites.
\newblock \emph{eLife}, 6, 2017.
\newblock \doi{10.7554/eLife.22901}.

\bibitem[Guerguiev et~al.(2019)Guerguiev, Kording, and
  Richards]{guerguiev_spike-based_2019}
Guerguiev, J., Kording, K.~P., and Richards, B.~A.
\newblock Spike-based causal inference for weight alignment.
\newblock \emph{arXiv:1910.01689 [cs, q-bio]}, October 2019.
\newblock URL \url{http://arxiv.org/abs/1910.01689}.
\newblock arXiv: 1910.01689.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he_deep_2016}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep {Residual} {Learning} for {Image} {Recognition}.
\newblock In \emph{2016 {IEEE} {Conference} on {Computer} {Vision} and
  {Pattern} {Recognition} ({CVPR})}, pp.\  770--778, June 2016.
\newblock \doi{10.1109/CVPR.2016.90}.
\newblock ISSN: 1063-6919.

\bibitem[Imbens \& Lemieux(2008)Imbens and Lemieux]{imbens2008regression}
Imbens, G.~W. and Lemieux, T.
\newblock Regression discontinuity designs: A guide to practice.
\newblock \emph{Journal of econometrics}, 142\penalty0 (2):\penalty0 615--635,
  2008.

\bibitem[Ioffe \& Szegedy(2015)Ioffe and Szegedy]{ioffe2015batch}
Ioffe, S. and Szegedy, C.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock \emph{arXiv preprint arXiv:1502.03167}, 2015.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kolen \& Pollack(1994)Kolen and Pollack]{Kolen1994backpropagation}
Kolen, J. and Pollack, J.
\newblock Backpropagation without weight transport.
\newblock In \emph{Proceedings of 1994 IEEE International Conference on Neural
  Networks (ICNN'94)}, volume~3, pp.\  1375 -- 1380 vol.3, 07 1994.
\newblock ISBN 0-7803-1901-X.
\newblock \doi{10.1109/ICNN.1994.374486}.

\bibitem[Kunin et~al.(2019)Kunin, Bloom, Goeva, and Seed]{kunin_loss_2019}
Kunin, D., Bloom, J., Goeva, A., and Seed, C.
\newblock Loss {L}andscapes of {R}egularized {L}inear {A}utoencoders.
\newblock In Chaudhuri, K. and Salakhutdinov, R. (eds.), \emph{Proceedings of
  the 36th International Conference on Machine Learning}, volume~97 of
  \emph{Proceedings of Machine Learning Research}, pp.\  3560--3569, Long
  Beach, California, USA, 09--15 Jun 2019. PMLR.
\newblock URL \url{http://proceedings.mlr.press/v97/kunin19a.html}.

\bibitem[Lansdell \& Kording(2019)Lansdell and Kording]{lansdell2019spiking}
Lansdell, B.~J. and Kording, K.~P.
\newblock Spiking allows neurons to estimate their causal effect.
\newblock \emph{bioRxiv}, pp.\  253351, 2019.

\bibitem[Lee et~al.(2015)Lee, Zhang, Fischer, and Bengio]{lee_difference_2015}
Lee, D.-H., Zhang, S., Fischer, A., and Bengio, Y.
\newblock Difference target propagation.
\newblock In \emph{Joint european conference on machine learning and knowledge
  discovery in databases}, pp.\  498--515. Springer, 2015.

\bibitem[Liao et~al.(2016)Liao, Leibo, and Poggio]{liao_how_2016}
Liao, Q., Leibo, J.~Z., and Poggio, T.
\newblock How {I}mportant is {W}eight {S}ymmetry in {B}ackpropagation?
\newblock In \emph{Proceedings of the Thirtieth AAAI Conference on Artificial
  Intelligence}, AAAI'16, pp.\  1837--1844. AAAI Press, 2016.
\newblock URL \url{http://dl.acm.org/citation.cfm?id=3016100.3016156}.

\bibitem[Lillicrap et~al.(2016)Lillicrap, Cownden, Tweed, and
  Akerman]{lillicrap_random_2016}
Lillicrap, T.~P., Cownden, D., Tweed, D.~B., and Akerman, C.~J.
\newblock Random synaptic feedback weights support error backpropagation for
  deep learning.
\newblock \emph{Nature Communications}, 7:\penalty0 13276, November 2016.
\newblock ISSN 2041-1723.
\newblock \doi{10.1038/ncomms13276}.
\newblock URL \url{https://www.nature.com/articles/ncomms13276}.

\bibitem[Majaj et~al.(2015)Majaj, Hong, Solomon, and
  {DiCarlo}]{majaj2015simple}
Majaj, N.~J., Hong, H., Solomon, E.~A., and {DiCarlo}, J.~J.
\newblock Simple {L}earned {W}eighted {S}ums of {I}nferior {T}emporal
  {N}euronal {F}iring {R}ates {A}ccurately {P}redict {H}uman {C}ore {O}bject
  {R}ecognition {P}erformance.
\newblock \emph{The Journal of neuroscience : the official journal of the
  Society for Neuroscience}, 35:\penalty0 13402--18, 2015 Sep 30 2015.
\newblock ISSN 1529-2401.
\newblock \doi{10.1523/JNEUROSCI.5181-14.2015}.

\bibitem[Moskovitz et~al.(2018)Moskovitz, Litwin{-}Kumar, and
  Abbott]{moskovitz_feedback_2018}
Moskovitz, T.~H., Litwin{-}Kumar, A., and Abbott, L.~F.
\newblock Feedback alignment in deep convolutional networks.
\newblock \emph{CoRR}, abs/1812.06488, 2018.
\newblock URL \url{http://arxiv.org/abs/1812.06488}.

\bibitem[N{\o}kland(2016)]{nokland_direct_2016}
N{\o}kland, A.
\newblock Direct {F}eedback {A}lignment {P}rovides {L}earning in {D}eep
  {N}eural {N}etworks.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1037--1045, 2016.

\bibitem[Oja(1982)]{oja_neuron}
Oja, E.
\newblock A simplified neuron model as a principal component analyzer.
\newblock \emph{E. J. Math. Biology}, 15\penalty0 (3):\penalty0 267 -- 273,
  1982.
\newblock \doi{10.1007/BF00275687}.

\bibitem[Rumelhart et~al.(1986)Rumelhart, Hinton, and
  Williams]{rumelhart_learning_1986}
Rumelhart, D.~E., Hinton, G.~E., and Williams, R.~J.
\newblock Learning representations by back-propagating errors.
\newblock \emph{Nature}, 323:\penalty0 533–536, October 1986.
\newblock \doi{10.1038/323533a0}.

\bibitem[Sacramento et~al.(2018)Sacramento, Ponte~Costa, Bengio, and
  Senn]{Sacramento2018Dendritic}
Sacramento, J.~a., Ponte~Costa, R., Bengio, Y., and Senn, W.
\newblock Dendritic cortical microcircuits approximate the backpropagation
  algorithm.
\newblock In Bengio, S., Wallach, H., Larochelle, H., Grauman, K.,
  Cesa-Bianchi, N., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems 31}, pp.\  8721--8732. Curran Associates,
  Inc., 2018.
\newblock URL
  \url{http://papers.nips.cc/paper/8089-dendritic-cortical-microcircuits-approximate-the-backpropagation-algorithm.pdf}.

\bibitem[Saxe et~al.(2013)Saxe, Mcclelland, and Ganguli]{saxe_exact_2013}
Saxe, A., Mcclelland, J., and Ganguli, S.
\newblock Exact solutions to the nonlinear dynamics of learning in deep linear
  neural networks.
\newblock \emph{arXiv preprint arXiv:1312.6120}, 12 2013.

\bibitem[Scellier \& Bengio(2017)Scellier and Bengio]{Scellier2017Equilibrium}
Scellier, B. and Bengio, Y.
\newblock Equilibrium {P}ropagation: {B}ridging the {G}ap between
  {E}nergy-{B}ased {M}odels and {B}ackpropagation.
\newblock \emph{Frontiers in Computational Neuroscience}, 11:\penalty0 24,
  2017.
\newblock ISSN 1662-5188.
\newblock \doi{10.3389/fncom.2017.00024}.
\newblock URL
  \url{https://www.frontiersin.org/article/10.3389/fncom.2017.00024}.

\bibitem[Whittington \& Bogacz(2017)Whittington and
  Bogacz]{whittington2017approximation}
Whittington, J. C.~R. and Bogacz, R.
\newblock An {A}pproximation of the {E}rror {B}ackpropagation {A}lgorithm in a
  {P}redictive {C}oding {N}etwork with {L}ocal {H}ebbian {S}ynaptic
  {P}lasticity.
\newblock \emph{Neural computation}, 29\penalty0 (5):\penalty0 1229--1262,
  2017.

\bibitem[Xiao et~al.(2019)Xiao, Chen, Liao, and
  Poggio]{xiao_biologically-plausible_2019}
Xiao, W., Chen, H., Liao, Q., and Poggio, T.
\newblock Biologically-{P}lausible {L}earning {A}lgorithms {C}an {S}cale to
  {L}arge {D}atasets.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=SygvZ209F7}.

\bibitem[Xie \& Seung(2003)Xie and Seung]{Xie2003Equivalence}
Xie, X. and Seung, H.
\newblock Equivalence of {B}ackpropagation and {C}ontrastive {H}ebbian
  {L}earning in a {L}ayered {N}etwork.
\newblock \emph{Neural computation}, 15:\penalty0 441--54, 03 2003.
\newblock \doi{10.1162/089976603762552988}.

\bibitem[Yamins et~al.(2014)Yamins, Hong, Cadieu, Solomon, Seibert, and
  DiCarlo]{yamins2014performance}
Yamins, D.~L., Hong, H., Cadieu, C.~F., Solomon, E.~A., Seibert, D., and
  DiCarlo, J.~J.
\newblock Performance-optimized hierarchical models predict neural responses in
  higher visual cortex.
\newblock \emph{Proceedings of the National Academy of Sciences}, 111\penalty0
  (23):\penalty0 8619--8624, 2014.

\end{thebibliography}
