\begin{thebibliography}{65}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alemi et~al.(2017)Alemi, Fischer, Dillon, and Murphy]{alemi2016deep}
Alemi, A.~A., Fischer, I., Dillon, J.~V., and Murphy, K.
\newblock Deep variational information bottleneck.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Alemi et~al.(2018)Alemi, Fischer, and Dillon]{alemi2018uncertainty}
Alemi, A.~A., Fischer, I., and Dillon, J.~V.
\newblock Uncertainty in the variational information bottleneck.
\newblock \emph{arXiv preprint arXiv:1807.00906}, 2018.

\bibitem[Azoury \& Warmuth(2001)Azoury and Warmuth]{azoury2001relative}
Azoury, K.~S. and Warmuth, M.~K.
\newblock Relative loss bounds for online density estimation with the exponential family of distributions.
\newblock \emph{Machine Learning}, 2001.

\bibitem[Banerjee et~al.(2004)Banerjee, Dhillon, Ghosh, and Merugu]{banerjee2004information}
Banerjee, A., Dhillon, I., Ghosh, J., and Merugu, S.
\newblock An information theoretic analysis of maximum likelihood mixture estimation for exponential families.
\newblock In \emph{International Conference on Machine Learning}, 2004.

\bibitem[Banerjee et~al.(2005)Banerjee, Merugu, Dhillon, Ghosh, and Lafferty]{banerjee2005clustering}
Banerjee, A., Merugu, S., Dhillon, I.~S., Ghosh, J., and Lafferty, J.
\newblock {Clustering with Bregman divergences}.
\newblock \emph{Journal of Machine Learning Research}, 2005.

\bibitem[Barndorff-Nielsen(2014)]{barndorff2014information}
Barndorff-Nielsen, O.
\newblock \emph{Information and exponential families: in statistical theory}.
\newblock John Wiley \& Sons, 2014.

\bibitem[Berger(1971)]{berger1971}
Berger, T.
\newblock Rate distortion theory; a mathematical basis for data compression.
\newblock \emph{Prentice-Hall}, 1971.

\bibitem[Berger \& Gibson(1998)Berger and Gibson]{berger1998lossy}
Berger, T. and Gibson, J.~D.
\newblock Lossy source coding.
\newblock \emph{IEEE Transactions on Information Theory}, 1998.

\bibitem[Blahut(1972)]{blahut1972computation}
Blahut, R.
\newblock Computation of channel capacity and rate-distortion functions.
\newblock \emph{IEEE Transactions on Information Theory}, 1972.

\bibitem[Blundell et~al.(2015)Blundell, Cornebise, Kavukcuoglu, and Wierstra]{blundell2015weight}
Blundell, C., Cornebise, J., Kavukcuoglu, K., and Wierstra, D.
\newblock Weight uncertainty in neural network.
\newblock In \emph{International Conference on Machine Learning}, 2015.

\bibitem[Bregman(1967)]{bregman1967relaxation}
Bregman, L.~M.
\newblock The relaxation method of finding the common point of convex sets and its application to the solution of problems in convex programming.
\newblock \emph{USSR computational mathematics and mathematical physics}, 1967.

\bibitem[Brekelmans \& Nielsen(2022)Brekelmans and Nielsen]{brekelmans2022rhotau}
Brekelmans, R. and Nielsen, F.
\newblock Rho-tau bregman information and the geometry of annealing paths.
\newblock \emph{arXiv preprint arXiv:2209.07481}, 2022.

\bibitem[Charpentier et~al.(2023)Charpentier, Zhang, and G{\"u}nnemann]{charpentier2023training}
Charpentier, B., Zhang, C., and G{\"u}nnemann, S.
\newblock Training, architecture, and prior for deterministic uncertainty methods.
\newblock In \emph{ICLR 2023 Workshop on Pitfalls of limited data and computation for Trustworthy ML}, 2023.
\newblock URL \url{https://openreview.net/forum?id=iYA80086YH}.

\bibitem[Corbi{\`e}re et~al.(2019)Corbi{\`e}re, Thome, Bar-Hen, Cord, and P{\'e}rez]{corbiere2019addressing}
Corbi{\`e}re, C., Thome, N., Bar-Hen, A., Cord, M., and P{\'e}rez, P.
\newblock Addressing failure prediction by learning model confidence.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Cover(1999)]{cover1999elements}
Cover, T.~M.
\newblock \emph{Elements of information theory}.
\newblock John Wiley \& Sons, 1999.

\bibitem[Csisz{\'a}r(1984)]{csiszar1984information}
Csisz{\'a}r, I.
\newblock Information geometry and alternating minimization procedures.
\newblock \emph{Statistics and Decisions}, 1984.

\bibitem[Csisz{\'a}r(1995)]{csiszar1995generalized}
Csisz{\'a}r, I.
\newblock Generalized projections for non-negative functions.
\newblock In \emph{IEEE International Symposium on Information Theory}, 1995.

\bibitem[Davis \& Dhillon(2006)Davis and Dhillon]{davis2006differential}
Davis, J. and Dhillon, I.
\newblock {Differential entropic clustering of multivariate Gaussians}.
\newblock \emph{Advances in Neural Information Processing Systems}, 2006.

\bibitem[Foong et~al.(2019)Foong, Li, Hern{\'a}ndez-Lobato, and Turner]{foong2019between}
Foong, A.~Y., Li, Y., Hern{\'a}ndez-Lobato, J.~M., and Turner, R.~E.
\newblock 'in-between'uncertainty in bayesian neural networks.
\newblock \emph{arXiv preprint arXiv:1906.11537}, 2019.

\bibitem[Frigyik et~al.(2008)Frigyik, Srivastava, and Gupta]{frigyik2008functional}
Frigyik, B.~A., Srivastava, S., and Gupta, M.~R.
\newblock {Functional Bregman divergence and Bayesian estimation of distributions}.
\newblock \emph{IEEE Transactions on Information Theory}, 2008.

\bibitem[Fujimoto et~al.(2018)Fujimoto, Meger, and Precup]{fujimoto2019off}
Fujimoto, S., Meger, D., and Precup, D.
\newblock Off-policy deep reinforcement learning without exploration.
\newblock In \emph{International Conference on Machine Learning}, 2018.

\bibitem[Gal \& Ghahramani(2016)Gal and Ghahramani]{gal2016dropout}
Gal, Y. and Ghahramani, Z.
\newblock {Dropout as a Bayesian approximation: Representing model uncertainty in deep learning}.
\newblock In \emph{International Conference on Machine Learning}, 2016.

\bibitem[Gulrajani et~al.(2017)Gulrajani, Ahmed, Arjovsky, Dumoulin, and Courville]{gulrajani2017improved}
Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., and Courville, A.~C.
\newblock Improved training of wasserstein gans.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017calibration}
Guo, C., Pleiss, G., Sun, Y., and Weinberger, K.~Q.
\newblock On calibration of modern neural networks.
\newblock In \emph{International Conference on Machine Learning}, 2017.

\bibitem[Hendrycks \& Dietterich(2019)Hendrycks and Dietterich]{hendrycks2018benchmarking}
Hendrycks, D. and Dietterich, T.
\newblock Benchmarking neural network robustness to common corruptions and perturbations.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=HJz6tiCqYm}.

\bibitem[Hendrycks et~al.(2019)Hendrycks, Mazeika, and Dietterich]{hendrycks2019oe}
Hendrycks, D., Mazeika, M., and Dietterich, T.
\newblock Deep anomaly detection with outlier exposure.
\newblock \emph{Proceedings of the International Conference on Learning Representations}, 2019.

\bibitem[Hendrycks et~al.(2020)Hendrycks, Mu, Cubuk, Zoph, Gilmer, and Lakshminarayanan]{hendrycks2020augmix}
Hendrycks, D., Mu, N., Cubuk, E.~D., Zoph, B., Gilmer, J., and Lakshminarayanan, B.
\newblock {AugMix}: A simple data processing method to improve robustness and uncertainty.
\newblock \emph{Proceedings of the International Conference on Learning Representations (ICLR)}, 2020.

\bibitem[Hendrycks et~al.(2021)Hendrycks, Zhao, Basart, Steinhardt, and Song]{hendrycks2021nae}
Hendrycks, D., Zhao, K., Basart, S., Steinhardt, J., and Song, D.
\newblock Natural adversarial examples.
\newblock \emph{CVPR}, 2021.

\bibitem[Hern{\'a}ndez-Lobato \& Adams(2015)Hern{\'a}ndez-Lobato and Adams]{hernandez2015probabilistic}
Hern{\'a}ndez-Lobato, J.~M. and Adams, R.
\newblock {Probabilistic backpropagation for scalable learning of Bayesian neural networks}.
\newblock In \emph{International Conference on Machine Learning}, 2015.

\bibitem[Hoffman et~al.(2017)Hoffman, Riquelme, and Johnson]{hoffman2017beta}
Hoffman, M.~D., Riquelme, C., and Johnson, M.~J.
\newblock {The $\beta$-VAEâ€™s implicit prior}.
\newblock In \emph{Workshop on Bayesian Deep Learning, Advances in Neural Information Processing Systems}, 2017.

\bibitem[Jaeger et~al.(2023)Jaeger, L{\"u}th, Klein, and Bungert]{jaeger2023a}
Jaeger, P.~F., L{\"u}th, C.~T., Klein, L., and Bungert, T.~J.
\newblock A call to reflect on evaluation practices for failure detection in image classification.
\newblock In \emph{The Eleventh International Conference on Learning Representations}, 2023.
\newblock URL \url{https://openreview.net/forum?id=YnkGMIh0gvX}.

\bibitem[Jiang et~al.(2012)Jiang, Kulis, and Jordan]{jiang2012small}
Jiang, K., Kulis, B., and Jordan, M.
\newblock {Small-variance asymptotics for exponential family Dirichlet process mixture models}.
\newblock \emph{Advances in Neural Information Processing Systems}, 2012.

\bibitem[Kivlichan et~al.(2021)Kivlichan, Liu, Vasserman, and Lin]{50669}
Kivlichan, I., Liu, J., Vasserman, L.~H., and Lin, Z.
\newblock Measuring and improving model-moderator collaboration using uncertainty estimation.
\newblock In \emph{Workshop on Online Abuse and Harms}, 2021.

\bibitem[Lakshminarayanan et~al.(2017)Lakshminarayanan, Pritzel, and Blundell]{lakshminarayanan2017simple}
Lakshminarayanan, B., Pritzel, A., and Blundell, C.
\newblock Simple and scalable predictive uncertainty estimation using deep ensembles.
\newblock \emph{Advances in Neural Information Processing Systems}, 2017.

\bibitem[Lee et~al.(2021)Lee, Laskin, Srinivas, and Abbeel]{lee2021sunrise}
Lee, K., Laskin, M., Srinivas, A., and Abbeel, P.
\newblock Sunrise: A simple unified framework for ensemble learning in deep reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, 2021.

\bibitem[Liu et~al.(2020)Liu, Lin, Padhy, Tran, Bedrax~Weiss, and Lakshminarayanan]{liu2020simple}
Liu, J., Lin, Z., Padhy, S., Tran, D., Bedrax~Weiss, T., and Lakshminarayanan, B.
\newblock Simple and principled uncertainty estimation with deterministic deep learning via distance awareness.
\newblock \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Liu et~al.(2023)Liu, Padhy, Ren, Lin, Wen, Jerfel, Nado, Snoek, Tran, and Lakshminarayanan]{JMLR:v24:22-0479}
Liu, J.~Z., Padhy, S., Ren, J., Lin, Z., Wen, Y., Jerfel, G., Nado, Z., Snoek, J., Tran, D., and Lakshminarayanan, B.
\newblock A simple approach to improve single-model deep uncertainty via distance-awareness.
\newblock \emph{Journal of Machine Learning Research}, 24\penalty0 (42):\penalty0 1--63, 2023.

\bibitem[Markelle~Kelly(1998)]{uci_datasets}
Markelle~Kelly, Rachel~Longjohn, K.~N.
\newblock Uci repository of machine learning databases.
\newblock In \emph{http://www.ics.uci.edu/~mlearn/MLRepository.html}, 1998.

\bibitem[Matz \& Duhamel(2004)Matz and Duhamel]{matz2004information}
Matz, G. and Duhamel, P.
\newblock {Information geometric formulation and interpretation of accelerated Blahut-Arimoto-type algorithms}.
\newblock In \emph{Information theory workshop}. IEEE, 2004.

\bibitem[Minka(2005)]{minka2005divergence}
Minka, T.
\newblock Divergence measures and message passing.
\newblock Technical Report MSR-TR-2005-173, Microsoft Research, 2005.

\bibitem[Miyato et~al.(2018)Miyato, Kataoka, Koyama, and Yoshida]{miyato2018spectral}
Miyato, T., Kataoka, T., Koyama, M., and Yoshida, Y.
\newblock Spectral normalization for generative adversarial networks.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Mukhoti et~al.(2023)Mukhoti, Kirsch, van Amersfoort, Torr, and Gal]{Mukhoti_2023_CVPR}
Mukhoti, J., Kirsch, A., van Amersfoort, J., Torr, P.~H., and Gal, Y.
\newblock Deep deterministic uncertainty: A new simple baseline.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pp.\  24384--24394, June 2023.

\bibitem[Netzer et~al.(2019)Netzer, Wang, Coates, Bissacco, Wu, and Ng]{svhn}
Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., and Ng, A.~Y.
\newblock {The Street View House Numbers (SVHN) dataset}.
\newblock \emph{http://ufldl.stanford.edu/housenumbers}, 2019.

\bibitem[Nielsen(2023)]{nielsen2023fisher}
Nielsen, F.
\newblock {Fisher-Rao and pullback Hilbert cone distances on the multivariate Gaussian manifold with applications to simplification and quantization of mixtures}.
\newblock In \emph{Annual Workshop on Topology, Algebra, and Geometry in Machine Learning}, 2023.

\bibitem[Nielsen et~al.(2007)Nielsen, Boissonnat, and Nock]{nielsen2007bregman}
Nielsen, F., Boissonnat, J.-D., and Nock, R.
\newblock {Bregman Voronoi diagrams: Properties, algorithms and applications}.
\newblock \emph{Extended abstract appeared in ACM-SIAM Symposium on Discrete Algorithms 2007. INRIA Technical Report RR-6154, arXiv preprint arXiv:0709.2196}, 2007.

\bibitem[Northcutt et~al.(2021)Northcutt, Jiang, and Chuang]{northcutt2021confident}
Northcutt, C., Jiang, L., and Chuang, I.
\newblock Confident learning: Estimating uncertainty in dataset labels.
\newblock \emph{Journal of Artificial Intelligence Research}, 70:\penalty0 1373--1411, 2021.

\bibitem[Osawa et~al.(2019)Osawa, Swaroop, Khan, Jain, Eschenhagen, Turner, and Yokota]{osawa2019practical}
Osawa, K., Swaroop, S., Khan, M. E.~E., Jain, A., Eschenhagen, R., Turner, R.~E., and Yokota, R.
\newblock {Practical deep learning with Bayesian principles}.
\newblock \emph{Advances in Neural Information Processing Systems}, 2019.

\bibitem[Osband et~al.(2016)Osband, Blundell, Pritzel, and Van~Roy]{osband2016deep}
Osband, I., Blundell, C., Pritzel, A., and Van~Roy, B.
\newblock {Deep exploration via bootstrapped DQN}.
\newblock \emph{Advances in Neural Information Processing Systems}, 2016.

\bibitem[Osband et~al.(2021)Osband, Wen, Asghari, Dwaracherla, Ibrahimi, Lu, and Van~Roy]{osband2021epistemic}
Osband, I., Wen, Z., Asghari, S.~M., Dwaracherla, V., Ibrahimi, M., Lu, X., and Van~Roy, B.
\newblock Epistemic neural networks.
\newblock \emph{arXiv preprint arXiv:2107.08924}, 2021.

\bibitem[Pinto et~al.(2022{\natexlab{a}})Pinto, Torr, and K.~Dokania]{pinto2022impartial}
Pinto, F., Torr, P.~H., and K.~Dokania, P.
\newblock An impartial take to the cnn vs transformer robustness contest.
\newblock In \emph{European Conference on Computer Vision}, pp.\  466--480. Springer, 2022{\natexlab{a}}.

\bibitem[Pinto et~al.(2022{\natexlab{b}})Pinto, Yang, Lim, Torr, and Dokania]{pinto2022using}
Pinto, F., Yang, H., Lim, S.~N., Torr, P., and Dokania, P.
\newblock Using mixup as a regularizer can surprisingly improve accuracy \& out-of-distribution robustness.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 14608--14622, 2022{\natexlab{b}}.

\bibitem[Platanios et~al.(2020)Platanios, Al-Shedivat, Xing, and Mitchell]{platanios2020learning}
Platanios, E.~A., Al-Shedivat, M., Xing, E., and Mitchell, T.
\newblock Learning from imperfect annotations.
\newblock \emph{arXiv preprint arXiv:2004.03473}, 2020.

\bibitem[Postels et~al.(2022)Postels, Seg{\`u}, Sun, Sieber, Van~Gool, Yu, and Tombari]{pmlr-v162-postels22a}
Postels, J., Seg{\`u}, M., Sun, T., Sieber, L.~D., Van~Gool, L., Yu, F., and Tombari, F.
\newblock On the practicality of deterministic epistemic uncertainty.
\newblock In \emph{International Conference on Machine Learning}, 2022.

\bibitem[Rahimi \& Recht(2007)Rahimi and Recht]{rahimi2007random}
Rahimi, A. and Recht, B.
\newblock Random features for large-scale kernel machines.
\newblock \emph{Advances in Neural Information Processing Systems}, 2007.

\bibitem[Rose(1994)]{rose1994mapping}
Rose, K.
\newblock A mapping approach to rate-distortion computation and analysis.
\newblock \emph{IEEE Transactions on Information Theory}, 1994.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma, Huang, Karpathy, Khosla, Bernstein, et~al.]{russakovsky2015imagenet}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{International journal of computer vision}, 115:\penalty0 211--252, 2015.

\bibitem[Tishby et~al.(2000)Tishby, Pereira, and Bialek]{tishby2000information}
Tishby, N., Pereira, F.~C., and Bialek, W.
\newblock The information bottleneck method.
\newblock \emph{arXiv preprint physics/0004057}, 2000.

\bibitem[Titsias(2009)]{titsias2009variational}
Titsias, M.
\newblock {Variational learning of inducing variables in sparse Gaussian processes}.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, 2009.

\bibitem[Van~Amersfoort et~al.(2020)Van~Amersfoort, Smith, Teh, and Gal]{van2020uncertainty}
Van~Amersfoort, J., Smith, L., Teh, Y.~W., and Gal, Y.
\newblock Uncertainty estimation using a single deep deterministic neural network.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Van~Amersfoort et~al.(2021)Van~Amersfoort, Smith, Jesson, Key, and Gal]{van2021feature}
Van~Amersfoort, J., Smith, L., Jesson, A., Key, O., and Gal, Y.
\newblock On feature collapse and deep kernel learning for single forward pass uncertainty.
\newblock \emph{arXiv preprint arXiv:2102.11409}, 2021.

\bibitem[Wilson \& Izmailov(2020)Wilson and Izmailov]{wilson2020bayesian}
Wilson, A.~G. and Izmailov, P.
\newblock {Bayesian deep learning and a probabilistic perspective of generalization}.
\newblock \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Wu et~al.(2021)Wu, Zhai, Srivastava, Susskind, Zhang, Salakhutdinov, and Goh]{wu2021uncertainty}
Wu, Y., Zhai, S., Srivastava, N., Susskind, J.~M., Zhang, J., Salakhutdinov, R., and Goh, H.
\newblock Uncertainty weighted actor-critic for offline reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, 2021.

\bibitem[Xiao et~al.(2022)Xiao, Liang, Bhatt, Neiswanger, Salakhutdinov, and Morency]{xiao-etal-2022-uncertainty}
Xiao, Y., Liang, P.~P., Bhatt, U., Neiswanger, W., Salakhutdinov, R., and Morency, L.-P.
\newblock Uncertainty quantification with pre-trained language models: A large-scale empirical analysis.
\newblock In Goldberg, Y., Kozareva, Z., and Zhang, Y. (eds.), \emph{Findings of the Association for Computational Linguistics: EMNLP 2022}, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and Komodakis]{zagoruyko2016wide}
Zagoruyko, S. and Komodakis, N.
\newblock Wide residual networks.
\newblock In \emph{British Machine Vision Conference}, 2016.

\bibitem[Zhu et~al.(2022)Zhu, Cheng, Zhang, and Liu]{zhu2022rethinking}
Zhu, F., Cheng, Z., Zhang, X.-Y., and Liu, C.-L.
\newblock Rethinking confidence calibration for failure prediction.
\newblock In \emph{European Conference on Computer Vision}, pp.\  518--536. Springer, 2022.

\end{thebibliography}
