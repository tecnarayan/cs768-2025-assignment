\begin{thebibliography}{51}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bauer et~al.(2016)Bauer, van~der Wilk, and
  Rasmussen]{bauer2016understanding}
Matthias Bauer, Mark van~der Wilk, and Carl~Edward Rasmussen.
\newblock Understanding probabilistic sparse gaussian process approximations.
\newblock In \emph{Advances in neural information processing systems}, pages
  1533--1541, 2016.

\bibitem[Bonilla et~al.(2007)Bonilla, Agakov, and Williams]{bonilla2007kernel}
Edwin~V Bonilla, Felix~V Agakov, and Christopher~KI Williams.
\newblock Kernel multi-task learning using task-specific features.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 43--50, 2007.

\bibitem[Casale et~al.(2015)Casale, Rakitsch, Lippert, and
  Stegle]{casale2015efficient}
Francesco~Paolo Casale, Barbara Rakitsch, Christoph Lippert, and Oliver Stegle.
\newblock Efficient set tests for the genetic analysis of correlated traits.
\newblock \emph{Nature methods}, 12\penalty0 (8):\penalty0 755, 2015.

\bibitem[Casale et~al.(2017)Casale, Horta, Rakitsch, and
  Stegle]{casale2017joint}
Francesco~Paolo Casale, Danilo Horta, Barbara Rakitsch, and Oliver Stegle.
\newblock Joint genetic analysis using variant sets reveals polygenic
  gene-context interactions.
\newblock \emph{PLoS genetics}, 13\penalty0 (4):\penalty0 e1006693, 2017.

\bibitem[Chen et~al.(2016)Chen, Kingma, Salimans, Duan, Dhariwal, Schulman,
  Sutskever, and Abbeel]{chen2016variational}
Xi~Chen, Diederik~P Kingma, Tim Salimans, Yan Duan, Prafulla Dhariwal, John
  Schulman, Ilya Sutskever, and Pieter Abbeel.
\newblock Variational lossy autoencoder.
\newblock \emph{arXiv preprint arXiv:1611.02731}, 2016.

\bibitem[Csat{\'o} and Opper(2002)]{csato2002sparse}
Lehel Csat{\'o} and Manfred Opper.
\newblock Sparse on-line gaussian processes.
\newblock \emph{Neural computation}, 14\penalty0 (3):\penalty0 641--668, 2002.

\bibitem[Dalca et~al.(2015)Dalca, Sridharan, Sabuncu, and
  Golland]{dalca2015predictive}
Adrian~V Dalca, Ramesh Sridharan, Mert~R Sabuncu, and Polina Golland.
\newblock Predictive modeling of anatomy with genetic and clinical data.
\newblock In \emph{International Conference on Medical Image Computing and
  Computer-Assisted Intervention}, pages 519--526. Springer, 2015.

\bibitem[Durrande et~al.(2011)Durrande, Ginsbourger, Roustant, and
  Carraro]{durrande2011additive}
Nicolas Durrande, David Ginsbourger, Olivier Roustant, and Laurent Carraro.
\newblock Additive covariance kernels for high-dimensional gaussian process
  modeling.
\newblock \emph{arXiv preprint arXiv:1111.6233}, 2011.

\bibitem[Gal et~al.(2014)Gal, Van Der~Wilk, and Rasmussen]{gal2014distributed}
Yarin Gal, Mark Van Der~Wilk, and Carl~Edward Rasmussen.
\newblock Distributed variational inference in sparse gaussian process
  regression and latent variable models.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3257--3265, 2014.

\bibitem[G{\"o}nen and Alpayd{\i}n(2011)]{gonen2011multiple}
Mehmet G{\"o}nen and Ethem Alpayd{\i}n.
\newblock Multiple kernel learning algorithms.
\newblock \emph{Journal of machine learning research}, 12\penalty0
  (Jul):\penalty0 2211--2268, 2011.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in neural information processing systems}, pages
  2672--2680, 2014.

\bibitem[Harville(1997)]{harville1997matrix}
David~A Harville.
\newblock \emph{Matrix algebra from a statistician's perspective}, volume~1.
\newblock Springer, 1997.

\bibitem[Henderson and Searle(1981)]{henderson1981deriving}
Harold~V Henderson and Shayle~R Searle.
\newblock On deriving the inverse of a sum of matrices.
\newblock \emph{Siam Review}, 23\penalty0 (1):\penalty0 53--60, 1981.

\bibitem[Hensman et~al.(2013)Hensman, Fusi, and Lawrence]{hensman2013gaussian}
James Hensman, Nicolo Fusi, and Neil~D Lawrence.
\newblock Gaussian processes for big data.
\newblock In \emph{Uncertainty in Artificial Intelligence}, page 282. Citeseer,
  2013.

\bibitem[Hoffman and Johnson(2016)]{hoffman2016elbo}
Matthew~D Hoffman and Matthew~J Johnson.
\newblock Elbo surgery: yet another way to carve up the variational evidence
  lower bound.
\newblock In \emph{Workshop in Advances in Approximate Bayesian Inference,
  NIPS}, 2016.

\bibitem[Hou et~al.(2017)Hou, Shen, Sun, and Qiu]{hou2017deep}
Xianxu Hou, Linlin Shen, Ke~Sun, and Guoping Qiu.
\newblock Deep feature consistent variational autoencoder.
\newblock In \emph{Applications of Computer Vision (WACV), 2017 IEEE Winter
  Conference on}, pages 1133--1141. IEEE, 2017.

\bibitem[Jiang et~al.(2016)Jiang, Zheng, Tan, Tang, and
  Zhou]{jiang2016variational}
Zhuxi Jiang, Yin Zheng, Huachun Tan, Bangsheng Tang, and Hanning Zhou.
\newblock Variational deep embedding: An unsupervised and generative approach
  to clustering.
\newblock \emph{arXiv preprint arXiv:1611.05148}, 2016.

\bibitem[Johnson et~al.(2016)Johnson, Duvenaud, Wiltschko, Adams, and
  Datta]{johnson2016composing}
Matthew Johnson, David~K Duvenaud, Alex Wiltschko, Ryan~P Adams, and Sandeep~R
  Datta.
\newblock Composing graphical models with neural networks for structured
  representations and fast inference.
\newblock In \emph{Advances in neural information processing systems}, pages
  2946--2954, 2016.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kingma and Welling(2013)]{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114}, 2013.

\bibitem[Kingma et~al.(2014)Kingma, Mohamed, Rezende, and
  Welling]{kingma2014semi}
Diederik~P Kingma, Shakir Mohamed, Danilo~Jimenez Rezende, and Max Welling.
\newblock Semi-supervised learning with deep generative models.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3581--3589, 2014.

\bibitem[Kingma et~al.(2016)Kingma, Salimans, Jozefowicz, Chen, Sutskever, and
  Welling]{kingma2016improved}
Diederik~P Kingma, Tim Salimans, Rafal Jozefowicz, Xi~Chen, Ilya Sutskever, and
  Max Welling.
\newblock Improved variational inference with inverse autoregressive flow.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  4743--4751, 2016.

\bibitem[Kulkarni et~al.(2015)Kulkarni, Whitney, Kohli, and
  Tenenbaum]{kulkarni2015deep}
Tejas~D Kulkarni, William~F Whitney, Pushmeet Kohli, and Josh Tenenbaum.
\newblock Deep convolutional inverse graphics network.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2539--2547, 2015.

\bibitem[Lawrence(2005)]{lawrence2005probabilistic}
Neil Lawrence.
\newblock Probabilistic non-linear principal component analysis with gaussian
  process latent variable models.
\newblock \emph{Journal of machine learning research}, 6\penalty0
  (Nov):\penalty0 1783--1816, 2005.

\bibitem[LeCun et~al.(1995)LeCun, Bengio, et~al.]{lecun1995convolutional}
Yann LeCun, Yoshua Bengio, et~al.
\newblock Convolutional networks for images, speech, and time series.
\newblock \emph{The handbook of brain theory and neural networks},
  3361\penalty0 (10):\penalty0 1995, 1995.

\bibitem[Lonsdale et~al.(2013)Lonsdale, Thomas, Salvatore, Phillips, Lo, Shad,
  Hasz, Walters, Garcia, Young, et~al.]{lonsdale2013genotype}
John Lonsdale, Jeffrey Thomas, Mike Salvatore, Rebecca Phillips, Edmund Lo,
  Saboor Shad, Richard Hasz, Gary Walters, Fernando Garcia, Nancy Young, et~al.
\newblock The genotype-tissue expression (gtex) project.
\newblock \emph{Nature genetics}, 45\penalty0 (6):\penalty0 580, 2013.

\bibitem[Maal{\o}e et~al.(2016)Maal{\o}e, S{\o}nderby, S{\o}nderby, and
  Winther]{maaloe2016auxiliary}
Lars Maal{\o}e, Casper~Kaae S{\o}nderby, S{\o}ren~Kaae S{\o}nderby, and Ole
  Winther.
\newblock Auxiliary deep generative models.
\newblock \emph{arXiv preprint arXiv:1602.05473}, 2016.

\bibitem[Nalisnick et~al.(2016)Nalisnick, Hertel, and
  Smyth]{nalisnick2016approximate}
Eric Nalisnick, Lars Hertel, and Padhraic Smyth.
\newblock Approximate inference for deep latent gaussian mixtures.
\newblock In \emph{NIPS Workshop on Bayesian Deep Learning}, volume~2, 2016.

\bibitem[Pandey and Dukkipati(2017)]{pandey2017variational}
Gaurav Pandey and Ambedkar Dukkipati.
\newblock Variational methods for conditional multimodal deep learning.
\newblock In \emph{Neural Networks (IJCNN), 2017 International Joint Conference
  on}, pages 308--315. IEEE, 2017.

\bibitem[Qui{\~n}onero-Candela and Rasmussen(2005)]{quinonero2005unifying}
Joaquin Qui{\~n}onero-Candela and Carl~Edward Rasmussen.
\newblock A unifying view of sparse approximate gaussian process regression.
\newblock \emph{Journal of Machine Learning Research}, 6\penalty0
  (Dec):\penalty0 1939--1959, 2005.

\bibitem[Rakitsch et~al.(2013)Rakitsch, Lippert, Borgwardt, and
  Stegle]{rakitsch2013all}
Barbara Rakitsch, Christoph Lippert, Karsten Borgwardt, and Oliver Stegle.
\newblock It is all in the noise: Efficient multi-task gaussian process
  inference with structured residuals.
\newblock In \emph{Advances in neural information processing systems}, pages
  1466--1474, 2013.

\bibitem[Ranganath et~al.(2016)Ranganath, Tran, and
  Blei]{ranganath2016hierarchical}
Rajesh Ranganath, Dustin Tran, and David Blei.
\newblock Hierarchical variational models.
\newblock In \emph{International Conference on Machine Learning}, pages
  324--333, 2016.

\bibitem[Rasmussen(2004)]{rasmussen2004gaussian}
Carl~Edward Rasmussen.
\newblock Gaussian processes in machine learning.
\newblock In \emph{Advanced lectures on machine learning}, pages 63--71.
  Springer, 2004.

\bibitem[Rezende and Mohamed(2015)]{rezende2015variational}
Danilo~Jimenez Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock \emph{arXiv preprint arXiv:1505.05770}, 2015.

\bibitem[Rezende et~al.(2014)Rezende, Mohamed, and
  Wierstra]{rezende2014stochastic}
Danilo~Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock \emph{arXiv preprint arXiv:1401.4082}, 2014.

\bibitem[Righi et~al.(2012)Righi, Peissig, and Tarr]{righi2012recognizing}
Giulia Righi, Jessie~J Peissig, and Michael~J Tarr.
\newblock Recognizing disguised faces.
\newblock \emph{Visual Cognition}, 20\penalty0 (2):\penalty0 143--169, 2012.

\bibitem[Shu et~al.(2016)Shu, Brofos, Zhang, Bui, Ghavamzadeh, and
  Kochenderfer]{shu2016stochastic}
Rui Shu, James Brofos, Frank Zhang, Hung~Hai Bui, Mohammad Ghavamzadeh, and
  Mykel Kochenderfer.
\newblock Stochastic video prediction with conditional density estimation.
\newblock In \emph{ECCV Workshop on Action and Anticipation for Visual
  Learning}, volume~2, 2016.

\bibitem[Siddharth et~al.(2016)Siddharth, Paige, Desmaison, de~Meent, Wood,
  Goodman, Kohli, Torr, et~al.]{siddharth2016inducing}
N~Siddharth, Brooks Paige, Alban Desmaison, Van de~Meent, Frank Wood, Noah~D
  Goodman, Pushmeet Kohli, Philip~HS Torr, et~al.
\newblock Inducing interpretable representations with variational autoencoders.
\newblock \emph{arXiv preprint arXiv:1611.07492}, 2016.

\bibitem[Siddharth et~al.(2017)Siddharth, Paige, Van~de Meent, Desmaison, Wood,
  Goodman, Kohli, and Torr]{siddharth2017learning}
N~Siddharth, Brooks Paige, Jan-Willem Van~de Meent, Alban Desmaison, Frank
  Wood, Noah~D Goodman, Pushmeet Kohli, and Philip~HS Torr.
\newblock Learning disentangled representations with semi-supervised deep
  generative models.
\newblock \emph{ArXiv e-prints (Jun 2017)}, 2017.

\bibitem[Snelson and Ghahramani(2006)]{snelson2006sparse}
Edward Snelson and Zoubin Ghahramani.
\newblock Sparse gaussian processes using pseudo-inputs.
\newblock In \emph{Advances in neural information processing systems}, pages
  1257--1264, 2006.

\bibitem[Sohn et~al.(2015)Sohn, Lee, and Yan]{sohn2015learning}
Kihyuk Sohn, Honglak Lee, and Xinchen Yan.
\newblock Learning structured output representation using deep conditional
  generative models.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3483--3491, 2015.

\bibitem[Stegle et~al.(2011)Stegle, Lippert, Mooij, Lawrence, and
  Borgwardt]{stegle2011efficient}
Oliver Stegle, Christoph Lippert, Joris~M Mooij, Neil~D Lawrence, and Karsten~M
  Borgwardt.
\newblock Efficient inference in matrix-variate gaussian models
  with$\backslash$iid observation noise.
\newblock In \emph{Advances in neural information processing systems}, pages
  630--638, 2011.

\bibitem[Suzuki et~al.(2016)Suzuki, Nakayama, and Matsuo]{suzuki2016joint}
Masahiro Suzuki, Kotaro Nakayama, and Yutaka Matsuo.
\newblock Joint multimodal learning with deep generative models.
\newblock \emph{arXiv preprint arXiv:1611.01891}, 2016.

\bibitem[Titsias(2009)]{titsias2009variational}
Michalis Titsias.
\newblock Variational learning of inducing variables in sparse gaussian
  processes.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 567--574,
  2009.

\bibitem[Tomczak and Welling(2017)]{tomczak2017vae}
Jakub~M Tomczak and Max Welling.
\newblock Vae with a vampprior.
\newblock \emph{arXiv preprint arXiv:1705.07120}, 2017.

\bibitem[Tran et~al.(2015)Tran, Ranganath, and Blei]{tran2015variational}
Dustin Tran, Rajesh Ranganath, and David~M Blei.
\newblock The variational gaussian process.
\newblock \emph{arXiv preprint arXiv:1511.06499}, 2015.

\bibitem[Vedantam et~al.(2017)Vedantam, Fischer, Huang, and
  Murphy]{vedantam2017generative}
Ramakrishna Vedantam, Ian Fischer, Jonathan Huang, and Kevin Murphy.
\newblock Generative models of visually grounded imagination.
\newblock \emph{arXiv preprint arXiv:1705.10762}, 2017.

\bibitem[Wang et~al.(2016)Wang, Yan, Lee, and Livescu]{wang2016deep}
Weiran Wang, Xinchen Yan, Honglak Lee, and Karen Livescu.
\newblock Deep variational canonical correlation analysis.
\newblock \emph{arXiv preprint arXiv:1610.03454}, 2016.

\bibitem[Wilson and Adams(2013)]{wilson2013gaussian}
Andrew Wilson and Ryan Adams.
\newblock Gaussian process kernels for pattern discovery and extrapolation.
\newblock In \emph{International Conference on Machine Learning}, pages
  1067--1075, 2013.

\bibitem[Wilson et~al.(2016)Wilson, Hu, Salakhutdinov, and
  Xing]{wilson2016deep}
Andrew~Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, and Eric~P Xing.
\newblock Deep kernel learning.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 370--378,
  2016.

\bibitem[Wu and Goodman(2018)]{wu2018multimodal}
Mike Wu and Noah Goodman.
\newblock Multimodal generative models for scalable weakly-supervised learning.
\newblock \emph{arXiv preprint arXiv:1802.05335}, 2018.

\end{thebibliography}
