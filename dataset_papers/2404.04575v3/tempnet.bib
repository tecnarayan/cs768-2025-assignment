@inproceedings{joy2023sample,
  title={Sample-dependent adaptive temperature scaling for improved calibration},
  author={Joy, Tom and Pinto, Francesco and Lim, Ser-Nam and Torr, Philip HS and Dokania, Puneet K},
  booktitle={Proceedings of the 37th AAAI Conference on Artificial Intelligence},
  pages={14919--14926},
  year={2023}
}

@article{DBLP:journals/corr/abs-2005-14165,
  author       = {Tom B. Brown and
                  Benjamin Mann and
                  Nick Ryder and
                  Melanie Subbiah and
                  Jared Kaplan and
                  Prafulla Dhariwal and
                  Arvind Neelakantan and
                  Pranav Shyam and
                  Girish Sastry and
                  Amanda Askell and
                  Sandhini Agarwal and
                  Ariel Herbert{-}Voss and
                  Gretchen Krueger and
                  Tom Henighan and
                  Rewon Child and
                  Aditya Ramesh and
                  Daniel M. Ziegler and
                  Jeffrey Wu and
                  Clemens Winter and
                  Christopher Hesse and
                  Mark Chen and
                  Eric Sigler and
                  Mateusz Litwin and
                  Scott Gray and
                  Benjamin Chess and
                  Jack Clark and
                  Christopher Berner and
                  Sam McCandlish and
                  Alec Radford and
                  Ilya Sutskever and
                  Dario Amodei},
  title        = {Language Models are Few-Shot Learners},
  journal      = {CoRR},
  volume       = {abs/2005.14165},
  year         = {2020},
  url          = {https://arxiv.org/abs/2005.14165},
  eprinttype    = {arXiv},
  eprint       = {2005.14165},
  timestamp    = {Thu, 25 May 2023 10:38:31 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2005-14165.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{HornikEtAl89,
  added-at = {2012-08-18T21:01:01.000+0200},
  author = {Hornik, K. and Stinchcombe, M. and White, H.},
  biburl = {https://www.bibsonomy.org/bibtex/2093b3edd165afb94d52365daefa7e4db/dalbem},
  date-added = {2008-03-06 20:17:54 -0300},
  date-modified = {2008-03-06 20:17:54 -0300},
  groups = {public},
  interhash = {9948713640c726f50c4c5a57e121f7ac},
  intrahash = {093b3edd165afb94d52365daefa7e4db},
  journal = {Neural Networks},
  keywords = {},
  number = 5,
  pages = {359-366},
  timestamp = {2012-08-18T21:01:01.000+0200},
  title = {Multilayer feedforward networks are universal approximators},
  username = {dalbem},
  volume = 2,
  year = 1989
}

@article{qi2023stochastic,
      title={Stochastic Constrained DRO with a Complexity Independent of Sample Size}, 
      author={Qi Qi and Jiameng Lyu and Kung sik Chan and Er Wei Bai and Tianbao Yang},
      year={2023},
      journal={Transcations of Machine Learning and Research},
}

@inproceedings{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={1026--1034},
  year={2015}
}

@article{sion1958general,
  title={On general minimax theorems.},
  author={Sion, Maurice},
  journal={Pacific Journal of mathematics},
  volume={8},
  number={1},
  pages={171--176},
  year={1958},
}

@inproceedings{Kim2019AdaptiveTT,
  title={Adaptive Temperature Tuning for Mellowmax in Deep Reinforcement Learning},
  author={Seungchan Kim},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:208980169}
}
@article{zhang2021temperature,
  title={Temperature as Uncertainty in Contrastive Learning},
  author={Zhang, Oliver and Wu, Mike and Bayrooti, Jasmine and Goodman, Noah},
  journal={arXiv preprint arXiv:2110.04403},
  year={2021}
}
@misc{wu2023bsl,
      title={BSL: Understanding and Improving Softmax Loss for Recommendation}, 
      author={Junkang Wu and Jiawei Chen and Jiancan Wu and Wentao Shi and Jizhi Zhang and Xiang Wang},
      year={2023},
      eprint={2312.12882},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{cherti2023reproducible,
  title={Reproducible scaling laws for contrastive language-image learning},
  author={Cherti, Mehdi and Beaumont, Romain and Wightman, Ross and Wortsman, Mitchell and Ilharco, Gabriel and Gordon, Cade and Schuhmann, Christoph and Schmidt, Ludwig and Jitsev, Jenia},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2818--2829},
  year={2023}
}

@article{DBLP:journals/corr/abs-1809-04157,
  author       = {Xu Zhang and
                  Felix X. Yu and
                  Svebor Karaman and
                  Wei Zhang and
                  Shih{-}Fu Chang},
  title        = {Heated-Up Softmax Embedding},
  journal      = {CoRR},
  volume       = {abs/1809.04157},
  year         = {2018},
  url          = {http://arxiv.org/abs/1809.04157},
  eprinttype    = {arXiv},
  eprint       = {1809.04157},
  timestamp    = {Tue, 26 Mar 2019 17:00:53 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1809-04157.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{zhu2023label,
  title={Label distributionally robust losses for multi-class classification: Consistency, robustness and adaptivity},
  author={Zhu, Dixian and Ying, Yiming and Yang, Tianbao},
  booktitle={Proceedings of the 40th International Conference on Machine Learning},
  pages={43289--43325},
  year={2023},
}

@article{sanh2019distilbert,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@article{balanya2022adaptive,
  title={Adaptive Temperature Scaling for Robust Calibration of Deep Neural Networks},
  author={Balanya, Sergio A and Maro{\~n}as, Juan and Ramos, Daniel},
  journal={arXiv preprint arXiv:2208.00461},
  year={2022}
}

@inproceedings{lewis2023improving,
  title={Improving Domain Generalization in Contrastive Learning using Domain-Aware Temperature Control},
  author={Lewis, Robert A and Matton, Katie and Picard, Rosalind and Guttag, John},
  booktitle={NeurIPS 2023 Workshop on Distribution Shifts: New Frontiers with Foundation Models},
  year={2023}
}

@article{manna2023dystress,
  title={DySTreSS: Dynamically Scaled Temperature in Self-Supervised Contrastive Learning},
  author={Manna, Siladittya and Chattopadhyay, Soumitri and Dey, Rakesh and Bhattacharya, Saumik and Pal, Umapada},
  journal={arXiv preprint arXiv:2308.01140},
  year={2023}
}

@inproceedings{qiu2023not,
  title={Not All Semantics are Created Equal: Contrastive Self-supervised Learning with Automatic Temperature Individualization},
  author={Qiu, Zi-Hao and Hu, Quanqi and Yuan, Zhuoning and Zhou, Denny and Zhang, Lijun and Yang, Tianbao},
  booktitle={Proceedings of the 40th International Conference on Machine Learning},
  pages={28389--28421},
  year={2023}
}

@article{tao2024supervised,
  title={Supervised contrastive representation learning with tree-structured parzen estimator Bayesian optimization for imbalanced tabular data},
  author={Tao, Shuting and Peng, Peng and Li, Yunfei and Sun, Haiyue and Li, Qi and Wang, Hongwei},
  journal={Expert Systems with Applications},
  volume={237},
  pages={121294},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{katageri2024synergizing,
  title={Synergizing Contrastive Learning and Optimal Transport for 3D Point Cloud Domain Adaptation},
  author={Katageri, Siddharth and De, Arkadipta and Devaguptapu, Chaitanya and Prasad, VSSV and Sharma, Charu and Kaul, Manohar},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={2942--2951},
  year={2024}
}

@inproceedings{luo2023contrastive,
  title={Contrastive Latent Space Reconstruction Learning for Audio-Text Retrieval},
  author={Luo, Kaiyi and Zhang, Xulong and Wang, Jianzong and Li, Huaxiong and Cheng, Ning and Xiao, Jing},
  booktitle={Proceedings of the 35th IEEE International Conference on Tools with Artificial Intelligence},
  pages={913--917},
  year={2023},
  organization={IEEE}
}

@inproceedings{kukleva2023temperature,
  title={Temperature schedules for self-supervised contrastive methods on long-tail data},
  author={Kukleva, Anna and B{\"o}hle, Moritz and Schiele, Bernt and Kuehne, Hilde and Rupprecht, Christian},
  booktitle={the 11th International Conference on Learning Representations},
  year={2023}
}

@inproceedings{wang2021understanding,
  title={Understanding the behaviour of contrastive loss},
  author={Wang, Feng and Liu, Huaping},
  booktitle={Proceedings of the 34th IEEE/CVF conference on computer vision and pattern recognition},
  pages={2495--2504},
  year={2021}
}

@inproceedings{zhang2022dual,
  title={Dual temperature helps contrastive learning without many negative samples: Towards understanding and simplifying moco},
  author={Zhang, Chaoning and Zhang, Kang and Pham, Trung X and Niu, Axi and Qiao, Zhinan and Yoo, Chang D and Kweon, In So},
  booktitle={Proceedings of the 35th IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14441--14450},
  year={2022}
}

@inproceedings{khaertdinov2021contrastive,
  title={Contrastive self-supervised learning for sensor-based human activity recognition},
  author={Khaertdinov, Bulat and Ghaleb, Esam and Asteriadis, Stylianos},
  booktitle={2021 IEEE International Joint Conference on Biometrics},
  pages={1--8},
  year={2021},
  organization={IEEE}
}

@article{wu2023understanding,
  title={Understanding contrastive learning via distributionally robust optimization},
  author={Wu, Junkang and Chen, Jiawei and Wu, Jiancan and Shi, Wentao and Wang, Xiang and He, Xiangnan},
  journal={arXiv preprint arXiv:2310.11048},
  year={2023}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={Proceedings of the 38th International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
}

@inproceedings{chen2020simple,
  title={A simple framework for contrastive learning of visual representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={Proceedings of the 37th International conference on machine learning},
  pages={1597--1607},
  year={2020}
}

@inproceedings{li2021align,
  title={Align before fuse: Vision and language representation learning with momentum distillation},
  author={Li, Junnan and Selvaraju, Ramprasaath and Gotmare, Akhilesh and Joty, Shafiq and Xiong, Caiming and Hoi, Steven Chu Hong},
  booktitle={Advances in Neural Information Processing Systems},
  volume={34},
  pages={9694--9705},
  year={2021}
}

@inproceedings{goel2022cyclip,
  title={Cyclip: Cyclic contrastive language-image pretraining},
  author={Goel, Shashank and Bansal, Hritik and Bhatia, Sumit and Rossi, Ryan and Vinay, Vishwa and Grover, Aditya},
  booktitle={Advances in Neural Information Processing Systems},
  volume={35},
  pages={6704--6719},
  year={2022}
}

@article{jaynes1957information,
  title={Information theory and statistical mechanics},
  author={Jaynes, Edwin T},
  journal={Physical review},
  volume={106},
  number={4},
  pages={620},
  year={1957},
  publisher={APS}
}

@article{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@inproceedings{guo2017calibration,
  title={On calibration of modern neural networks},
  author={Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q},
  booktitle={Proceedings of the 34th International Conference on Machine Learning},
  pages={1321--1330},
  year={2017},
}

@inproceedings{xu2022systematic,
  title={A systematic evaluation of large language models of code},
  author={Xu, Frank F and Alon, Uri and Neubig, Graham and Hellendoorn, Vincent Josua},
  booktitle={Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming},
  pages={1--10},
  year={2022}
}

@article{wang2020contextual,
  title={Contextual temperature for language modeling},
  author={Wang, Pei-Hsin and Hsieh, Sheng-Iou and Chang, Shih-Chieh and Chen, Yu-Ting and Pan, Jia-Yu and Wei, Wei and Juan, Da-Chang},
  journal={arXiv preprint arXiv:2012.13575},
  year={2020}
}

@inproceedings{gloeckle2023temperature,
  title={Temperature-scaled large language models for Lean proofstep prediction},
  author={Gloeckle, Fabian and Roziere, Baptiste and Hayat, Amaury and Synnaeve, Gabriel},
  booktitle={The 3rd Workshop on Mathematical Reasoning and AI at NeurIPS'23},
  year={2023}
}

@article{austin2021program,
  title={Program synthesis with large language models},
  author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
  journal={arXiv preprint arXiv:2108.07732},
  year={2021}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{zhu2021temperature,
  title={Temperature network for few-shot learning with distribution-aware large-margin metric},
  author={Zhu, Wei and Li, Wenbin and Liao, Haofu and Luo, Jiebo},
  journal={Pattern Recognition},
  volume={112},
  pages={107797},
  year={2021}
}

@inproceedings{li2023curriculum,
  title={Curriculum temperature for knowledge distillation},
  author={Li, Zheng and Li, Xiang and Yang, Lingfeng and Zhao, Borui and Song, Renjie and Luo, Lei and Li, Jun and Yang, Jian},
  booktitle={Proceedings of the 37th AAAI Conference on Artificial Intelligence},
  volume={37},
  number={2},
  pages={1504--1512},
  year={2023}
}

@article{liu2022meta,
  title={Meta knowledge distillation},
  author={Liu, Jihao and Liu, Boxiao and Li, Hongsheng and Liu, Yu},
  journal={arXiv preprint arXiv:2202.07940},
  year={2022}
}

@article{ma2017softmax,
  title={Softmax q-distribution estimation for structured prediction: A theoretical interpretation for raml},
  author={Ma, Xuezhe and Yin, Pengcheng and Liu, Jingzhou and Neubig, Graham and Hovy, Eduard},
  journal={arXiv preprint arXiv:1705.07136},
  year={2017}
}

@article{he2018determining,
  title={Determining the optimal temperature parameter for Softmax function in reinforcement learning},
  author={He, Yu-Lin and Zhang, Xiao-Liang and Ao, Wei and Huang, Joshua Zhexue},
  journal={Applied Soft Computing},
  volume={70},
  pages={80--85},
  year={2018},
}

@inproceedings{hu2017toward,
  title={Toward controlled generation of text},
  author={Hu, Zhiting and Yang, Zichao and Liang, Xiaodan and Salakhutdinov, Ruslan and Xing, Eric P},
  booktitle={Proceedings of the 34th International Conference on Machine Learning},
  pages={1587--1596},
  year={2017},
}

@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@inproceedings{yuan2022provable,
  title={Provable stochastic optimization for global contrastive learning: Small batch does not harm performance},
  author={Yuan, Zhuoning and Wu, Yuexin and Qiu, Zi-Hao and Du, Xianzhi and Zhang, Lijun and Zhou, Denny and Yang, Tianbao},
  booktitle={Proceedings of the 39th International Conference on Machine Learning},
  pages={25760--25782},
  year={2022},
}

@article{mitchell1980need,
  title={The need for biases in learning generalizations},
  author={Mitchell, Tom M},
  year={1980},
  publisher={Department of Computer Science, Laboratory for Computer Science Research~…}
}

@book{rockafellar2009variational,
  title={Variational analysis},
  author={Rockafellar, R Tyrrell and Wets, Roger J-B},
  volume={317},
  year={2009},
  publisher={Springer Science \& Business Media}
}

@inproceedings{sharma2018conceptual,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics},
  pages={2556--2565},
  year={2018}
}

@inproceedings{changpinyo2021conceptual,
  title={Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts},
  author={Changpinyo, Soravit and Sharma, Piyush and Ding, Nan and Soricut, Radu},
  booktitle={Proceedings of the 34th IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3558--3568},
  year={2021}
}

@inproceedings{plummer2015flickr30k,
  title={Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models},
  author={Plummer, Bryan A and Wang, Liwei and Cervantes, Chris M and Caicedo, Juan C and Hockenmaier, Julia and Lazebnik, Svetlana},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2641--2649},
  year={2015}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Proceedings of the 11th European Conference on Computer Vision},
  pages={740--755},
  year={2014}
}

@inproceedings{mu2022slip,
  title={Slip: Self-supervision meets language-image pre-training},
  author={Mu, Norman and Kirillov, Alexander and Wagner, David and Xie, Saining},
  booktitle={Proceedings of the 19th European Conference on Computer Vision},
  pages={529--544},
  year={2022}
}

@article{li2021supervision,
  title={Supervision exists everywhere: A data efficient contrastive language-image pre-training paradigm},
  author={Li, Yangguang and Liang, Feng and Zhao, Lichen and Cui, Yufeng and Ouyang, Wanli and Shao, Jing and Yu, Fengwei and Yan, Junjie},
  journal={arXiv preprint arXiv:2110.05208},
  year={2021}
}


@inproceedings{dou2022coarse,
  title={Coarse-to-fine vision-language pre-training with fusion in the backbone},
  author={Dou, Zi-Yi and Kamath, Aishwarya and Gan, Zhe and Zhang, Pengchuan and Wang, Jianfeng and Li, Linjie and Liu, Zicheng and Liu, Ce and LeCun, Yann and Peng, Nanyun and others},
  journal={arXiv preprint arXiv:2206.07643},
  booktitle={Advances in Neural Information Processing Systems},
  volume={35},
  pages={9694--9705},
  year={2022}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@article{gao2020pile,
  title={The pile: An 800gb dataset of diverse text for language modeling},
  author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and others},
  journal={arXiv preprint arXiv:2101.00027},
  year={2020}
}

@article{touvron2023llama1,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{touvron2023llama2,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{bjerva2020subjqa,
  title={SubjQA: a dataset for subjectivity and review comprehension},
  author={Bjerva, Johannes and Bhutani, Nikita and Golshan, Behzad and Tan, Wang-Chiew and Augenstein, Isabelle},
  journal={arXiv preprint arXiv:2004.14283},
  year={2020}
}

@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}

@inproceedings{biderman2023pythia,
  title={Pythia: A suite for analyzing large language models across training and scaling},
  author={Biderman, Stella and Schoelkopf, Hailey and Anthony, Quentin Gregory and Bradley, Herbie and O’Brien, Kyle and Hallahan, Eric and Khan, Mohammad Aflah and Purohit, Shivanshu and Prashanth, USVSN Sai and Raff, Edward and others},
  booktitle={Proceedings of the 40th International Conference on Machine Learning},
  pages={2397--2430},
  year={2023}
}

@inproceedings{rasley2020deepspeed,
  title={Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters},
  author={Rasley, Jeff and Rajbhandari, Samyam and Ruwase, Olatunji and He, Yuxiong},
  booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={3505--3506},
  year={2020}
}

@inproceedings{karpathy2015deep,
  title={Deep visual-semantic alignments for generating image descriptions},
  author={Karpathy, Andrej and Fei-Fei, Li},
  booktitle={Proceedings of the 28th IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3128--3137},
  year={2015}
}

@article{shoeybi2019megatron,
  title={Megatron-lm: Training multi-billion parameter language models using model parallelism},
  author={Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1909.08053},
  year={2019}
}

@software{gpt-neox-library,
  title = {{GPT-NeoX: Large Scale Autoregressive Language Modeling in PyTorch}},
  author = {Andonian, Alex and Anthony, Quentin and Biderman, Stella and Black, Sid and Gali, Preetham and Gao, Leo and Hallahan, Eric and Levy-Kramer, Josh and Leahy, Connor and Nestler, Lucas and Parker, Kip and Pieler, Michael and Phang, Jason and Purohit, Shivanshu and Schoelkopf, Hailey and Stander, Dashiell and Songz, Tri and Tigges, Curt and Thérien, Benjamin and Wang, Phil and Weinbach, Samuel},
  url = {https://www.github.com/eleutherai/gpt-neox},
  doi = {10.5281/zenodo.5879544},
  month = {9},
  year = {2023},
  version = {2.0.0},
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{huang2023survey,
  title={A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions},
  author={Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and others},
  journal={arXiv preprint arXiv:2311.05232},
  year={2023}
}

@misc{eval-harness,
  author       = {Gao, Leo and Tow, Jonathan and Abbasi, Baber and Biderman, Stella and Black, Sid and DiPofi, Anthony and Foster, Charles and Golding, Laurence and Hsu, Jeffrey and Le Noac'h, Alain and Li, Haonan and McDonell, Kyle and Muennighoff, Niklas and Ociepa, Chris and Phang, Jason and Reynolds, Laria and Schoelkopf, Hailey and Skowron, Aviya and Sutawika, Lintang and Tang, Eric and Thite, Anish and Wang, Ben and Wang, Kevin and Zou, Andy},
  title        = {A framework for few-shot language model evaluation},
  month        = 12,
  year         = 2023,
  publisher    = {Zenodo},
  version      = {v0.4.0},
  doi          = {10.5281/zenodo.10256836},
  url          = {https://zenodo.org/records/10256836}
}


@inproceedings{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  booktitle={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6704--6719},
  year={2022}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@inproceedings{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  booktile={the 10th International Conference on Learning Representations},
  year={2022}
}

@misc{selfinstruct,
  title={Self-Instruct: Aligning Language Model with Self Generated Instructions},
  author={Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A. and Khashabi, Daniel and Hajishirzi, Hannaneh},
  journal={arXiv preprint arXiv:2212.10560},
  year={2022}
}

@misc{alpaca_eval,
  author = {Xuechen Li and Tianyi Zhang and Yann Dubois and Rohan Taori and Ishaan Gulrajani and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {AlpacaEval: An Automatic Evaluator of Instruction-following Models},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/alpaca_eval}}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}



@article{young2024yi,
  title={Yi: Open foundation models by 01. ai},
  author={Young, Alex and Chen, Bei and Li, Chao and Huang, Chengen and Zhang, Ge and Zhang, Guanwei and Li, Heng and Zhu, Jiangcheng and Chen, Jianqun and Chang, Jing and others},
  journal={arXiv preprint arXiv:2403.04652},
  year={2024}
}

@article{cobbe2021gsm8k,
  title={Training Verifiers to Solve Math Word Problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and Hesse, Christopher and Schulman, John},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@inproceedings{zheng2024judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}