%% Alphabetical order please!
@article{brantley2020constrained,
  title={Constrained episodic reinforcement learning in concave-convex and knapsack settings},
  author={Brantley, Kiant{\'e} and Dudik, Miroslav and Lykouris, Thodoris and Miryoosefi, Sobhan and Simchowitz, Max and Slivkins, Aleksandrs and Sun, Wen},
  journal={arXiv preprint arXiv:2006.05051},
  year={2020}
}

@article{abels2018dynamic,
  title={Dynamic weights in multi-objective deep reinforcement learning},
  author={Abels, Axel and Roijers, Diederik M and Lenaerts, Tom and Now{\'e}, Ann and Steckelmacher, Denis},
  journal={arXiv preprint arXiv:1809.07803},
  year={2018}
}
@inproceedings{achiam2017constrained,
  title={Constrained policy optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  booktitle={International Conference on Machine Learning},
  pages={22--31},
  year={2017},
  organization={PMLR}
}

@inproceedings{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, OpenAI Pieter and Zaremba, Wojciech},
  booktitle={Advances in neural information processing systems},
  pages={5048--5058},
  year={2017}
}

@article{azar2013minimax,
  title={Minimax PAC bounds on the sample complexity of reinforcement learning with a generative model},
  author={Azar, Mohammad Gheshlaghi and Munos, R{\'e}mi and Kappen, Hilbert J},
  journal={Machine learning},
  volume={91},
  number={3},
  pages={325--349},
  year={2013},
  publisher={Springer}
}

@inproceedings{azar2017minimax,
  title={Minimax regret bounds for reinforcement learning},
  author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={263--272},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{barrett2008learning,
  title={Learning all optimal policies with multiple criteria},
  author={Barrett, Leon and Narayanan, Srini},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={41--47},
  year={2008}
}

@article{brafman2002r,
  title={R-max-a general polynomial time algorithm for near-optimal reinforcement learning},
  author={Brafman, Ronen I and Tennenholtz, Moshe},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Oct},
  pages={213--231},
  year={2002}
}

@article{brown2018superhuman,
  title={Superhuman AI for heads-up no-limit poker: Libratus beats top professionals},
  author={Brown, Noam and Sandholm, Tuomas},
  journal={Science},
  volume={359},
  number={6374},
  pages={418--424},
  year={2018},
  publisher={American Association for the Advancement of Science}
}
@article{cai2019provably,
  title={Provably Efficient Exploration in Policy Optimization},
  author={Cai, Qi and Yang, Zhuoran and Jin, Chi and Wang, Zhaoran},
  journal={arXiv preprint arXiv:1912.05830},
  year={2019}
}

@article{cheung2019regret,
  title={Regret minimization for reinforcement learning with vectorial feedback and complex objectives},
  author={Cheung, Wang Chi},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={726--736},
  year={2019}
}

@article{dong2019q,
  title={Q-learning with ucb exploration is sample efficient for infinite-horizon mdp},
  author={Dong, Kefan and Wang, Yuanhao and Chen, Xiaoyu and Wang, Liwei},
  journal={arXiv preprint arXiv:1901.09311},
  year={2019}
}

@inproceedings{du2019provably,
  title={Provably efficient Q-learning with function approximation via distribution shift error checking oracle},
  author={Du, Simon S and Luo, Yuping and Wang, Ruosong and Zhang, Hanrui},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8058--8068},
  year={2019}
}
@article{du2020agnostic,
  title={Agnostic Q-learning with Function Approximation in Deterministic Systems: Tight Bounds on Approximation Error and Sample Complexity},
  author={Du, Simon S and Lee, Jason D and Mahajan, Gaurav and Wang, Ruosong},
  journal={arXiv preprint arXiv:2002.07125},
  year={2020}
}

@article{efroni2020exploration,
  title={Exploration-exploitation in constrained mdps},
  author={Efroni, Yonathan and Mannor, Shie and Pirotta, Matteo},
  journal={arXiv preprint arXiv:2003.02189},
  year={2020}
}
@article{el2018controlled,
  title={Controlled Markov processes with safety state constraints},
  author={El Chamie, Mahmoud and Yu, Yue and A{\c{c}}{\i}kme{\c{s}}e, Beh{\c{c}}et and Ono, Masahiro},
  journal={IEEE Transactions on Automatic Control},
  volume={64},
  number={3},
  pages={1003--1018},
  year={2018},
  publisher={IEEE}
}

@article{fisac2018general,
  title={A general safety framework for learning-based control in uncertain robotic systems},
  author={Fisac, Jaime F and Akametalu, Anayo K and Zeilinger, Melanie N and Kaynama, Shahab and Gillula, Jeremy and Tomlin, Claire J},
  journal={IEEE Transactions on Automatic Control},
  volume={64},
  number={7},
  pages={2737--2752},
  year={2018},
  publisher={IEEE}
}
@article{garcia2015comprehensive,
  title={A comprehensive survey on safe reinforcement learning},
  author={Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
  journal={Journal of Machine Learning Research},
  volume={16},
  number={1},
  pages={1437--1480},
  year={2015}
}
@article{hazan2018provably,
  title={Provably efficient maximum entropy exploration},
  author={Hazan, Elad and Kakade, Sham M and Singh, Karan and Van Soest, Abby},
  journal={arXiv preprint arXiv:1812.02690},
  year={2018}
}
@article{jaksch2010near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Apr},
  pages={1563--1600},
  year={2010}
}
@article{jia2019feature,
  title={Feature-Based Q-Learning for Two-Player Stochastic Games},
  author={Jia, Zeyu and Yang, Lin F and Wang, Mengdi},
  journal={arXiv preprint arXiv:1906.00423},
  year={2019}
}
@inproceedings{jin2018q,
  title={Is q-learning provably efficient?},
  author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4863--4873},
  year={2018}
}

@article{jin2019provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  journal={arXiv preprint arXiv:1907.05388},
  year={2019}
}

@misc{jin2019learning,
    title={Learning Adversarial MDPs with Bandit Feedback and Unknown Transition},
    author={Chi Jin and Tiancheng Jin and Haipeng Luo and Suvrit Sra and Tiancheng Yu},
    year={2019},
    eprint={1912.01192},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{jin2020reward,
  title={Reward-Free Exploration for Reinforcement Learning},
  author={Jin, Chi and Krishnamurthy, Akshay and Simchowitz, Max and Yu, Tiancheng},
  journal={arXiv preprint arXiv:2002.02794},
  year={2020}
}

@article{johnson1984extensions,
  title={Extensions of Lipschitz mappings into a Hilbert space},
  author={Johnson, William B and Lindenstrauss, Joram},
  journal={Contemporary mathematics},
  volume={26},
  number={189-206},
  pages={1},
  year={1984}
}


@phdthesis{kakade2003sample,
  title={On the sample complexity of reinforcement learning},
  author={Kakade, Sham Machandranath and others},
  year={2003},
  school={University of London London, England}
}

@article{kaufmann2020adaptive,
  title={Adaptive Reward-Free Exploration},
  author={Kaufmann, Emilie and M{\'e}nard, Pierre and Domingues, Omar Darwiche and Jonsson, Anders and Leurent, Edouard and Valko, Michal},
  journal={arXiv preprint arXiv:2006.06294},
  year={2020}
}

@article{maurer2009empirical,
  title={Empirical Bernstein bounds and sample variance penalization},
  author={Maurer, Andreas and Pontil, Massimiliano},
  journal={arXiv preprint arXiv:0907.3740},
  year={2009}
}

@article{menard2020fast,
  title={Fast active learning for pure exploration in reinforcement learning},
  author={M{\'e}nard, Pierre and Domingues, Omar Darwiche and Jonsson, Anders and Kaufmann, Emilie and Leurent, Edouard and Valko, Michal},
  journal={arXiv preprint arXiv:2007.13442},
  year={2020}
}

@article{modi2019sample,
  title={Sample complexity of reinforcement learning using linearly combined model ensembles},
  author={Modi, Aditya and Jiang, Nan and Tewari, Ambuj and Singh, Satinder},
  journal={arXiv preprint arXiv:1910.10597},
  year={2019}
}
@article{mossalam2016multi,
  title={Multi-objective deep reinforcement learning},
  author={Mossalam, Hossam and Assael, Yannis M and Roijers, Diederik M and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1610.02707},
  year={2016}
}

@inproceedings{natarajan2005dynamic,
  title={Dynamic preferences in multi-criteria reinforcement learning},
  author={Natarajan, Sriraam and Tadepalli, Prasad},
  booktitle={Proceedings of the 22nd international conference on Machine learning},
  pages={601--608},
  year={2005}
}

@inproceedings{neu2012adversarial,
  title={The adversarial stochastic shortest path problem with unknown transition probabilities},
  author={Neu, Gergely and Gyorgy, Andras and Szepesv{\'a}ri, Csaba},
  booktitle={Artificial Intelligence and Statistics},
  pages={805--813},
  year={2012}
}

@article{roijers2013survey,
  title={A survey of multi-objective sequential decision-making},
  author={Roijers, Diederik M and Vamplew, Peter and Whiteson, Shimon and Dazeley, Richard},
  journal={Journal of Artificial Intelligence Research},
  volume={48},
  pages={67--113},
  year={2013}
}

@article{rosenberg2019online,
  title={Online convex optimization in adversarial markov decision processes},
  author={Rosenberg, Aviv and Mansour, Yishay},
  journal={arXiv preprint arXiv:1905.07773},
  year={2019}
}

@inproceedings{sidford2018near,
  title={Near-optimal time and sample complexities for solving Markov decision processes with a generative model},
  author={Sidford, Aaron and Wang, Mengdi and Wu, Xian and Yang, Lin and Ye, Yinyu},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5186--5196},
  year={2018}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484},
  year={2016},
  publisher={Nature Publishing Group}
}

@inproceedings{schaul2015universal,
  title={Universal value function approximators},
  author={Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle={International conference on machine learning},
  pages={1312--1320},
  year={2015}
}

@article{van2014multi,
  title={Multi-objective reinforcement learning using sets of pareto dominating policies},
  author={Van Moffaert, Kristof and Now{\'e}, Ann},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={3483--3512},
  year={2014},
  publisher={JMLR. org}
}

@article{vinyals2019alphastar,
  title={Alphastar: Mastering the real-time strategy game starcraft ii},
  author={Vinyals, Oriol and Babuschkin, Igor and Chung, Junyoung and Mathieu, Michael and Jaderberg, Max and Czarnecki, Wojciech M and Dudzik, Andrew and Huang, Aja and Georgiev, Petko and Powell, Richard and others},
  journal={DeepMind blog},
  pages={2},
  year={2019}
}
@article{wang2019optimism,
  title={Optimism in Reinforcement Learning with Generalized Linear Function Approximation},
  author={Wang, Yining and Wang, Ruosong and Du, Simon S and Krishnamurthy, Akshay},
  journal={arXiv preprint arXiv:1912.04136},
  year={2019}

}@article{wang2020provably,
  title={Provably Efficient Reinforcement Learning with General Value Function Approximation},
  author={Wang, Ruosong and Salakhutdinov, Ruslan and Yang, Lin F},
  journal={arXiv preprint arXiv:2005.10804},
  year={2020}
}

@article{weissman2003inequalities,
  title={Inequalities for the L1 deviation of the empirical distribution},
  author={Weissman, Tsachy and Ordentlich, Erik and Seroussi, Gadiel and Verdu, Sergio and Weinberger, Marcelo J},
  journal={Hewlett-Packard Labs, Tech. Rep},
  year={2003}
}
@inproceedings{wachi2020safe,
  title={Safe reinforcement learning in constrained markov decision processes},
  author={Wachi, Akifumi and Sui, Yanan},
  booktitle={International Conference on Machine Learning},
  pages={9797--9806},
  year={2020},
  organization={PMLR}
}


@inproceedings{yang2019generalized,
  title={A Generalized Algorithm for Multi-Objective Reinforcement Learning and Policy Adaptation},
  author={Yang, Runzhe and Sun, Xingyuan and Narasimhan, Karthik},
  booktitle={Advances in Neural Information Processing Systems},
  pages={14610--14621},
  year={2019}
}

@article{yang2019reinforcement,
  title={Reinforcement leaning in feature space: Matrix bandit, kernels, and regret bound},
  author={Yang, Lin F and Wang, Mengdi},
  journal={arXiv preprint arXiv:1905.10389},
  year={2019}
}

@inproceedings{yang2019sample,
  title={Sample-optimal parametric q-learning using linearly additive features},
  author={Yang, Lin and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={6995--7004},
  year={2019}
}

@inproceedings{zanette2019limiting,
  title={Limiting Extrapolation in Linear Approximate Value Iteration},
  author={Zanette, Andrea and Lazaric, Alessandro and Kochenderfer, Mykel J and Brunskill, Emma},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5616--5625},
  year={2019}
}

@article{zanette2020learning,
  title={Learning Near Optimal Policies with Low Inherent Bellman Error},
  author={Zanette, Andrea and Lazaric, Alessandro and Kochenderfer, Mykel and Brunskill, Emma},
  journal={arXiv preprint arXiv:2003.00153},
  year={2020}
}
@inproceedings{zanette2019tighter,
  title={Tighter problem-dependent regret bounds in reinforcement learning without domain knowledge using value function bounds},
  author={Zanette, Andrea and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={7304--7312},
  year={2019},
  organization={PMLR}
}
@article{zhang2020almost,
  title={Almost Optimal Model-Free Reinforcement Learning via Reference-Advantage Decomposition},
  author={Zhang, Zihan and Zhou, Yuan and Ji, Xiangyang},
  journal={arXiv preprint arXiv:2004.10019},
  year={2020}
}

@article{zhang2020nearly,
  title={Nearly Minimax Optimal Reward-free Reinforcement Learning},
  author={Zhang, Zihan and Du, Simon S and Ji, Xiangyang},
  journal={arXiv preprint arXiv:2010.05901},
  year={2020}
}


@misc{zhang2020task,
      title={Task-agnostic Exploration in Reinforcement Learning}, 
      author={Xuezhou Zhang and Yuzhe Ma and Adish Singla},
      year={2020},
      eprint={2006.09497},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{zhao2019maximum,
  title={Maximum entropy-regularized multi-goal reinforcement learning},
  author={Zhao, Rui and Sun, Xudong and Tresp, Volker},
  journal={arXiv preprint arXiv:1905.08786},
  year={2019}
}

@article{wang2020reward,
  title={On reward-free reinforcement learning with linear function approximation},
  author={Wang, Ruosong and Du, Simon S and Yang, Lin F and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2006.11274},
  year={2020}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{cheung2019exploration,
  title={Exploration-exploitation trade-off in reinforcement learning on online markov decision processes with global concave rewards},
  author={Cheung, Wang Chi},
  journal={arXiv preprint arXiv:1905.06466},
  year={2019}
}
@article{dann2017unifying,
    title   = {Unifying PAC and regret: Uniform PAC bounds for episodic reinforcement learning},
    author  = {Dann, Christoph and Lattimore, Tor and Brunskill, Emma},
    journal = {arXiv preprint arXiv:1703.07710},
    year    = {2017}
}