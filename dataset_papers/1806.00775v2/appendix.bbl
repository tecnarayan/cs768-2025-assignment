\begin{thebibliography}{6}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Burnetas and Katehakis(1997)]{burnetas1997optimal}
Apostolos~N. Burnetas and Michael~N. Katehakis.
\newblock Optimal adaptive policies for {Markov} decision processes.
\newblock \emph{Mathematics of Operations Research}, 22\penalty0 (1):\penalty0
  222--255, 1997.

\bibitem[Combes and Proutiere(2014)]{Combes2014}
Richard Combes and Alexandre Proutiere.
\newblock Unimodal bandits: Regret lower bounds and optimal algorithms.
\newblock In \emph{Proceedings of the 31st International Conference on Machine
  Learning}, 2014.

\bibitem[Garivier et~al.(Jun. 2018)Garivier, Ménard, and Stoltz]{garivier193}
Aurélien Garivier, Pierre Ménard, and Gilles Stoltz.
\newblock Explore first, exploit next: The true shape of regret in bandit
  problems.
\newblock \emph{Mathematics of Operations Research}, Jun. 2018.

\bibitem[Kaufmann et~al.(2016)Kaufmann, Capp{\'e}, and
  Garivier]{kaufmann2016complexity}
Emilie Kaufmann, Olivier Capp{\'e}, and Aurélien Garivier.
\newblock On the complexity of best-arm identification in multi-armed bandit
  models.
\newblock \emph{The Journal of Machine Learning Research}, 17\penalty0
  (1):\penalty0 1--42, 2016.

\bibitem[Magureanu et~al.(2014)Magureanu, Combes, and Proutiere]{magureanu2014}
Stefan Magureanu, Richard Combes, and Alexandre Proutiere.
\newblock Lipschitz bandits: Regret lower bounds and optimal algorithms.
\newblock In \emph{Conference on Learning Theory}, 2014.

\bibitem[Puterman(1994)]{puterman1994markov}
M.~L. Puterman.
\newblock \emph{Markov decision processes: discrete stochastic dynamic
  programming}.
\newblock John Wiley \& Sons, 1994.

\end{thebibliography}
