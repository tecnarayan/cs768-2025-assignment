\begin{thebibliography}{43}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Barnett(2018)]{barnett2018convergence}
Barnett, S.~A.
\newblock Convergence problems with generative adversarial networks (gans).
\newblock \emph{arXiv preprint arXiv:1806.11382}, 2018.

\bibitem[Ba{\c{s}}ar \& Bernhard(2008)Ba{\c{s}}ar and Bernhard]{bacsar2008h}
Ba{\c{s}}ar, T. and Bernhard, P.
\newblock \emph{H-infinity optimal control and related minimax design problems:
  a dynamic game approach}.
\newblock Springer Science \& Business Media, 2008.

\bibitem[Baydin et~al.(2018)Baydin, Pearlmutter, Radul, and
  Siskind]{baydin2018automatic}
Baydin, A.~G., Pearlmutter, B.~A., Radul, A.~A., and Siskind, J.~M.
\newblock Automatic differentiation in machine learning: a survey.
\newblock \emph{Journal of Marchine Learning Research}, 18:\penalty0 1--43,
  2018.

\bibitem[Bemporad et~al.(2003)Bemporad, Borrelli, and Morari]{bemporad2003min}
Bemporad, A., Borrelli, F., and Morari, M.
\newblock Min-max control of constrained uncertain discrete-time linear
  systems.
\newblock \emph{IEEE Transactions on automatic control}, 48\penalty0
  (9):\penalty0 1600--1606, 2003.

\bibitem[de~la Pena et~al.(2006)de~la Pena, Alamo, Bemporad, and
  Camacho]{de2006feedback}
de~la Pena, D.~M., Alamo, T., Bemporad, A., and Camacho, E.~F.
\newblock Feedback min-max model predictive control based on a quadratic cost
  function.
\newblock In \emph{American Control Conference, 2006}, pp.\  6--pp. IEEE, 2006.

\bibitem[Epstein \& Schneider(2003)Epstein and Schneider]{epstein2003recursive}
Epstein, L.~G. and Schneider, M.
\newblock Recursive multiple-priors.
\newblock \emph{Journal of Economic Theory}, 113\penalty0 (1):\penalty0 1--31,
  2003.

\bibitem[Frank \& Wolfe(1956)Frank and Wolfe]{frank1956algorithm}
Frank, M. and Wolfe, P.
\newblock An algorithm for quadratic programming.
\newblock \emph{Naval research logistics quarterly}, 3\penalty0 (1-2):\penalty0
  95--110, 1956.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
  S., Courville, A., and Bengio, Y.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  2672--2680, 2014.

\bibitem[Hansen et~al.(2013)Hansen, Miltersen, and Zwick]{hansen2013strategy}
Hansen, T.~D., Miltersen, P.~B., and Zwick, U.
\newblock Strategy iteration is strongly polynomial for 2-player turn-based
  stochastic games with a constant discount factor.
\newblock \emph{Journal of the ACM (JACM)}, 60\penalty0 (1):\penalty0 1, 2013.

\bibitem[Hoffman \& Karp(1966)Hoffman and Karp]{hoffman1966nonterminating}
Hoffman, A.~J. and Karp, R.~M.
\newblock On nonterminating stochastic games.
\newblock \emph{Management Science}, 12\penalty0 (5):\penalty0 359--370, 1966.

\bibitem[Iyengar(2005)]{iyengar2005robust}
Iyengar, G.~N.
\newblock Robust dynamic programming.
\newblock \emph{Mathematics of Operations Research}, 30\penalty0 (2):\penalty0
  257--280, 2005.

\bibitem[Kakade \& Langford(2002)Kakade and Langford]{kakade2002approximately}
Kakade, S. and Langford, J.
\newblock Approximately optimal approximate reinforcement learning.
\newblock In \emph{ICML}, volume~2, pp.\  267--274, 2002.

\bibitem[Kerrigan \& Maciejowski(2004)Kerrigan and
  Maciejowski]{kerrigan2004feedback}
Kerrigan, E.~C. and Maciejowski, J.~M.
\newblock Feedback min-max model predictive control using a single linear
  program: robust stability and the explicit solution.
\newblock \emph{International Journal of Robust and Nonlinear Control:
  IFAC-Affiliated Journal}, 14\penalty0 (4):\penalty0 395--413, 2004.

\bibitem[Kurakin et~al.(2018)Kurakin, Goodfellow, Bengio, Dong, Liao, Liang,
  Pang, Zhu, Hu, Xie, et~al.]{kurakin2018adversarial}
Kurakin, A., Goodfellow, I., Bengio, S., Dong, Y., Liao, F., Liang, M., Pang,
  T., Zhu, J., Hu, X., Xie, C., et~al.
\newblock Adversarial attacks and defences competition.
\newblock \emph{arXiv preprint arXiv:1804.00097}, 2018.

\bibitem[Lillicrap et~al.(2015)Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa,
  Silver, and Wierstra]{lillicrap2015continuous}
Lillicrap, T.~P., Hunt, J.~J., Pritzel, A., Heess, N., Erez, T., Tassa, Y.,
  Silver, D., and Wierstra, D.
\newblock Continuous control with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1509.02971}, 2015.

\bibitem[Maitra \& Parthasarathy(1970)Maitra and
  Parthasarathy]{maitra1970stochastic}
Maitra, A. and Parthasarathy, T.
\newblock On stochastic games.
\newblock \emph{Journal of Optimization Theory and Applications}, 5\penalty0
  (4):\penalty0 289--300, 1970.

\bibitem[Mannor et~al.(2012)Mannor, Mebel, and Xu]{mannor2012lightning}
Mannor, S., Mebel, O., and Xu, H.
\newblock Lightning does not strike twice: Robust mdps with coupled
  uncertainty.
\newblock \emph{arXiv preprint arXiv:1206.4643}, 2012.

\bibitem[Nash(1951)]{nash1951non}
Nash, J.
\newblock Non-cooperative games.
\newblock \emph{Annals of mathematics}, pp.\  286--295, 1951.

\bibitem[Nilim \& El~Ghaoui(2005)Nilim and El~Ghaoui]{nilim2005robust}
Nilim, A. and El~Ghaoui, L.
\newblock Robust control of markov decision processes with uncertain transition
  matrices.
\newblock \emph{Operations Research}, 53\penalty0 (5):\penalty0 780--798, 2005.

\bibitem[Patek(1997)]{patek1997stochastic}
Patek, S.~D.
\newblock \emph{Stochastic and shortest path games: theory and algorithms}.
\newblock PhD thesis, Massachusetts Institute of Technology, 1997.

\bibitem[Peng et~al.(2018)Peng, Andrychowicz, Zaremba, and Abbeel]{peng2018sim}
Peng, X.~B., Andrychowicz, M., Zaremba, W., and Abbeel, P.
\newblock Sim-to-real transfer of robotic control with dynamics randomization.
\newblock In \emph{2018 IEEE International Conference on Robotics and
  Automation (ICRA)}, pp.\  1--8. IEEE, 2018.

\bibitem[Pinto et~al.(2017)Pinto, Davidson, Sukthankar, and
  Gupta]{pinto2017robust}
Pinto, L., Davidson, J., Sukthankar, R., and Gupta, A.
\newblock Robust adversarial reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2817--2826, 2017.

\bibitem[Plappert et~al.(2017)Plappert, Houthooft, Dhariwal, Sidor, Chen, Chen,
  Asfour, Abbeel, and Andrychowicz]{plappert2017parameter}
Plappert, M., Houthooft, R., Dhariwal, P., Sidor, S., Chen, R.~Y., Chen, X.,
  Asfour, T., Abbeel, P., and Andrychowicz, M.
\newblock Parameter space noise for exploration.
\newblock \emph{arXiv preprint arXiv:1706.01905}, 2017.

\bibitem[Puterman(1994)]{puterman1994markov}
Puterman, M.~L.
\newblock \emph{Markov decision processes: discrete stochastic dynamic
  programming}.
\newblock John Wiley \& Sons, 1994.

\bibitem[Rao et~al.(1973)Rao, Chandrasekaran, and Nair]{rao1973algorithms}
Rao, S., Chandrasekaran, R., and Nair, K.
\newblock Algorithms for discounted stochastic games.
\newblock \emph{Journal of Optimization Theory and Applications}, 11\penalty0
  (6):\penalty0 627--637, 1973.

\bibitem[Samangouei et~al.(2018)Samangouei, Kabkab, and
  Chellappa]{samangouei2018defense}
Samangouei, P., Kabkab, M., and Chellappa, R.
\newblock Defense-gan: Protecting classifiers against adversarial attacks using
  generative models.
\newblock \emph{arXiv preprint arXiv:1805.06605}, 2018.

\bibitem[Scherrer(2014)]{scherrer2014approximate}
Scherrer, B.
\newblock Approximate policy iteration schemes: a comparison.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1314--1322, 2014.

\bibitem[Scherrer \& Geist(2014)Scherrer and Geist]{scherrer2014local}
Scherrer, B. and Geist, M.
\newblock Local policy search in a convex space and conservative policy
  iteration as boosted policy search.
\newblock In \emph{Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pp.\  35--50. Springer, 2014.

\bibitem[Shani et~al.(2018)Shani, Efroni, and Mannor]{shani2018revisiting}
Shani, L., Efroni, Y., and Mannor, S.
\newblock Revisiting exploration-conscious reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1812.05551}, 2018.

\bibitem[Shapley(1953)]{shapley1953stochastic}
Shapley, L.~S.
\newblock Stochastic games.
\newblock \emph{Proceedings of the national academy of sciences}, 39\penalty0
  (10):\penalty0 1095--1100, 1953.

\bibitem[Silver et~al.(2014)Silver, Lever, Heess, Degris, Wierstra, and
  Riedmiller]{silver2014deterministic}
Silver, D., Lever, G., Heess, N., Degris, T., Wierstra, D., and Riedmiller, M.
\newblock Deterministic policy gradient algorithms.
\newblock In \emph{ICML}, 2014.

\bibitem[Sion et~al.(1958)]{sion1958general}
Sion, M. et~al.
\newblock On general minimax theorems.
\newblock \emph{Pacific Journal of mathematics}, 8\penalty0 (1):\penalty0
  171--176, 1958.

\bibitem[Straffin(1993)]{straffin1993game}
Straffin, P.~D.
\newblock \emph{Game theory and strategy}, volume~36.
\newblock MAA, 1993.

\bibitem[Sutton et~al.(2000)Sutton, McAllester, Singh, and
  Mansour]{sutton2000policy}
Sutton, R.~S., McAllester, D.~A., Singh, S.~P., and Mansour, Y.
\newblock Policy gradient methods for reinforcement learning with function
  approximation.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1057--1063, 2000.

\bibitem[Szegedy et~al.(2013)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2013intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock \emph{arXiv preprint arXiv:1312.6199}, 2013.

\bibitem[Tamar et~al.(2013)Tamar, Xu, and Mannor]{tamar2013scaling}
Tamar, A., Xu, H., and Mannor, S.
\newblock Scaling up robust mdps by reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1306.6189}, 2013.

\bibitem[Todorov et~al.(2012)Todorov, Erez, and Tassa]{todorov2012mujoco}
Todorov, E., Erez, T., and Tassa, Y.
\newblock Mujoco: A physics engine for model-based control.
\newblock In \emph{Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ
  International Conference on}, pp.\  5026--5033. IEEE, 2012.

\bibitem[Uhlenbeck \& Ornstein(1930)Uhlenbeck and
  Ornstein]{uhlenbeck1930theory}
Uhlenbeck, G.~E. and Ornstein, L.~S.
\newblock On the theory of the brownian motion.
\newblock \emph{Physical review}, 36\penalty0 (5):\penalty0 823, 1930.

\bibitem[Wiesemann et~al.(2013)Wiesemann, Kuhn, and
  Rustem]{wiesemann2013robust}
Wiesemann, W., Kuhn, D., and Rustem, B.
\newblock Robust markov decision processes.
\newblock \emph{Mathematics of Operations Research}, 38\penalty0 (1):\penalty0
  153--183, 2013.

\bibitem[Xiao et~al.(2018)Xiao, Li, Zhu, He, Liu, and Song]{xiao2018generating}
Xiao, C., Li, B., Zhu, J.-Y., He, W., Liu, M., and Song, D.
\newblock Generating adversarial examples with adversarial networks.
\newblock \emph{arXiv preprint arXiv:1801.02610}, 2018.

\bibitem[Xu \& Mannor(2007)Xu and Mannor]{xu2007robustness}
Xu, H. and Mannor, S.
\newblock The robustness-performance tradeoff in markov decision processes.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1537--1544, 2007.

\bibitem[Xu \& Mannor(2012)Xu and Mannor]{xu2012robustness}
Xu, H. and Mannor, S.
\newblock Robustness and generalization.
\newblock \emph{Machine learning}, 86\penalty0 (3):\penalty0 391--423, 2012.

\bibitem[Xu et~al.(2009)Xu, Caramanis, and Mannor]{xu2009robustness}
Xu, H., Caramanis, C., and Mannor, S.
\newblock Robustness and regularization of support vector machines.
\newblock \emph{Journal of Machine Learning Research}, 10\penalty0
  (Jul):\penalty0 1485--1510, 2009.

\end{thebibliography}
