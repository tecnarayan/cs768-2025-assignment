@inproceedings{taori2020measuring,
    title={Measuring Robustness to Natural Distribution Shifts in Image Classification},
    author={Rohan Taori and Achal Dave and Vaishaal Shankar and Nicholas Carlini and Benjamin Recht and Ludwig Schmidt},
    booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
    year={2020},
    note={\url{https://arxiv.org/abs/2007.00644}},
}

@article{scao2022bloom,
  title={Bloom: A 176b-parameter open-access multilingual language model},
  author={Scao, Teven Le and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c{c}}ois and Gall{\'e}, Matthias and others},
  journal={arXiv preprint arXiv:2211.05100},
  year={2022}
}

@inproceedings{fixaug,
 author = {Touvron, Hugo and Vedaldi, Andrea and Douze, Matthijs and Jegou, Herve},
 booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
 title = {Fixing the train-test resolution discrepancy},
 note = {\url{https://proceedings.neurips.cc/paper/2019/file/d03a857a23b5285736c4d55e0bb067c8-Paper.pdf}},
 year = {2019}
}

@inproceedings{press2017using,
    title = "Using the Output Embedding to Improve Language Models",
    author = "Press, Ofir  and
      Wolf, Lior",
    booktitle = "Proceedings of the 15th Conference of the {E}uropean Chapter of the Association for Computational Linguistics: Volume 2, Short Papers",
    month = apr,
    year = "2017",
    address = "Valencia, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/E17-2025",
    pages = "157--163",
    abstract = "We study the topmost weight matrix of neural network language models. We show that this matrix constitutes a valid word embedding. When training language models, we recommend tying the input embedding and this output embedding. We analyze the resulting update rules and show that the tied embedding evolves in a more similar way to the output embedding than to the input embedding in the untied model. We also offer a new method of regularizing the output embedding. Our methods lead to a significant reduction in perplexity, as we are able to show on a variety of neural network language models. Finally, we show that weight tying can reduce the size of neural translation models to less than half of their original size without harming their performance.",
}

@article{wang2018glue,
  title={GLUE: A multi-task benchmark and analysis platform for natural language understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
  journal={arXiv preprint arXiv:1804.07461},
  year={2018}
}

@inproceedings{dagan2005pascal,
  title={The PASCAL recognising textual entailment challenge},
  author={Dagan, Ido and Glickman, Oren and Magnini, Bernardo},
  booktitle={Machine Learning Challenges Workshop},
  year={2005},
}

@inproceedings{
kumar2021finetuning,
title={Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution},
author={Ananya Kumar and Aditi Raghunathan and Robbie Matthew Jones and Tengyu Ma and Percy Liang},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=UYneFzXSJWh}
}

@misc{ma2019nlpaug,
  title={NLP Augmentation},
  author={Edward Ma},
  howpublished={https://github.com/makcedward/nlpaug},
  year={2019}
}

@article{wei2019eda,
  title={Eda: Easy data augmentation techniques for boosting performance on text classification tasks},
  author={Wei, Jason and Zou, Kai},
  journal={arXiv preprint arXiv:1901.11196},
  year={2019}
}

@inproceedings{wolf2020transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and RÃ©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}

@article{warstadt2018neural,
author = {Warstadt, Alex and Singh, Amanpreet and Bowman, Samuel R.},
title = {Neural Network Acceptability Judgments},
journal = {TACL},
volume = {7},
pages = {625-641},
year = {2019},
}

@article{dodge2020fine,
  title={Fine-tuning pretrained language models: Weight initializations, data orders, and early stopping},
  author={Dodge, Jesse and Ilharco, Gabriel and Schwartz, Roy and Farhadi, Ali and Hajishirzi, Hannaneh and Smith, Noah},
  journal={arXiv preprint arXiv:2002.06305},
  year={2020}
}

@inproceedings{socher2013recursive,
  title={Recursive deep models for semantic compositionality over a sentiment treebank},
  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew and Potts, Christopher},
  booktitle={Proceedings of EMNLP},
  year={2013}
}

@inproceedings{bar2006second,
  title={The second pascal recognising textual entailment challenge},
  author={Bar-Haim, Roy and Dagan, Ido and Dolan, Bill and Ferro, Lisa and Giampiccolo, Danilo and Magnini, Bernardo and Szpektor, Idan},
  booktitle={Proc. of the II PASCAL challenge},
  year={2006},
}

@inproceedings{giampiccolo2007third,
  title={The third pascal recognizing textual entailment challenge},
  author={Giampiccolo, Danilo and Magnini, Bernardo and Dagan, Ido and Dolan, Bill},
  booktitle={Proc. of the ACL-PASCAL workshop on textual entailment and paraphrasing},
  year={2007},
}

@inproceedings{bentivogli2009fifth,
  title={The Fifth PASCAL Recognizing Textual Entailment Challenge.},
  author={Bentivogli, Luisa and Clark, Peter and Dagan, Ido and Giampiccolo, Danilo},
  booktitle={TAC},
  year={2009}
}

@article{matthews1975comparison,
  title={Comparison of the predicted and observed secondary structure of T4 phage lysozyme},
  author={Matthews, Brian W},
  journal={Biochimica et Biophysica Acta (BBA)-Protein Structure},
  year={1975},
}

@InProceedings{dolan2005automatically,
author = {Dolan, Bill and Brockett, Chris},
title = {Automatically Constructing a Corpus of Sentential Paraphrases},
booktitle = {Proc. of IWP},
year = {2005},
}

@article{raffel2020t5,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1-67},
  url     = {http://jmlr.org/papers/v21/20-074.html}
}

@inproceedings{devlin2019bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}



@inproceedings{yosinski2014transferable,
  title={How transferable are features in deep neural networks?},
  author={Yosinski, Jason and Clune, Jeff and Bengio, Yoshua and Lipson, Hod},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2014},
  note={\url{https://arxiv.org/abs/1411.1792}},
}

@inproceedings{alexnet,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 note = {\url{https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf}},
 year = {2012}
}



@inproceedings{radford2021learning,
Author = {Alec Radford and Jong Wook Kim and Chris Hallacy and Aditya Ramesh and Gabriel Goh and Sandhini Agarwal and Girish Sastry and Amanda Askell and Pamela Mishkin and Jack Clark and Gretchen Krueger and Ilya Sutskever},
Title = {Learning Transferable Visual Models From Natural Language Supervision},
Year = {2021},
note={\url{https://arxiv.org/abs/2103.00020}},
booktitle={International Conference on Machine Learning (ICML)}
}

@misc{rw2019timm,
  author = {Ross Wightman},
  title = {PyTorch Image Models},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  doi = {10.5281/zenodo.4414861},
  howpublished = {\url{https://github.com/rwightman/pytorch-image-models}}
}

@inproceedings{tan2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2019},
  note={\url{https://proceedings.mlr.press/v97/tan19a/tan19a.pdf}}
}

@article{mchugh2012interrater,
  title={Interrater reliability: the kappa statistic},
  author={McHugh, Mary L},
  journal={Biochemia medica},
  year={2012},
  publisher={Medicinska naklada}
}

@article{colin2020exploring,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  note={\url{http://jmlr.org/papers/v21/20-074.html}}
}

@inproceedings{mocov1,
  title={Momentum Contrast for Unsupervised Visual Representation Learning},
  author={He, Kaiming and Fan, Haoqi and Wu, Yuxin and Xie, Saining and Girshick, Ross},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020},
  note={\url{https://arxiv.org/abs/1911.05722}}
}

@inproceedings{cubuk2020randaugment,
  title={{RandAugment}: Practical automated data augmentation with a reduced search space},
  author={Cubuk, Ekin D and Zoph, Barret and Shlens, Jonathon and Le, Quoc V},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020},
  note={\url{https://arxiv.org/abs/1909.13719}},
}

@misc{mocov2,
  title={Improved Baselines with Momentum Contrastive Learning},
  author={Chen, Xinlei and Fan, Haoqi and Girshick, Ross and He, Kaiming},
  note={\url{https://arxiv.org/abs/2003.04297}},
  year={2020}
}

@inproceedings{pirl,
  title={Self-supervised Learning of Pretext-Invariant Representations},
  author={Misra, Ishan and Maaten, Laurens van der},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020},
  note={\url{https://arxiv.org/abs/1912.01991}}
}

@inproceedings{simclr,
  title={A Simple Framework for Contrastive Learning of Visual Representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020},
  note={\url{http://proceedings.mlr.press/v119/chen20j.html}}
}

@inproceedings{simclrv2,
 author = {Chen, Ting and Kornblith, Simon and Swersky, Kevin and Norouzi, Mohammad and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 title = {Big Self-Supervised Models are Strong Semi-Supervised Learners},
 note={\url{https://arxiv.org/abs/2006.10029}},
 year = {2020}
}

@inproceedings{swav,
  title={Unsupervised Learning of Visual Features by Contrasting Cluster Assignments},
  author={Caron, Mathilde and Misra, Ishan and Mairal, Julien and Goyal, Priya and Bojanowski, Piotr and Joulin, Armand},
  booktitle={Proceedings of Advances in Neural Information Processing Systems (NeurIPS)},
  note={\url{https://arxiv.org/abs/2006.09882}},
  year={2020}
}

@inproceedings{sohn2020fixmatch,
  title={Fixmatch: Simplifying semi-supervised learning with consistency and confidence},
  author={Sohn, Kihyuk and Berthelot, David and Li, Chun-Liang and Zhang, Zizhao and Carlini, Nicholas and Cubuk, Ekin D and Kurakin, Alex and Zhang, Han and Raffel, Colin},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  note={\url{https://arxiv.org/abs/2001.07685}},
  year={2020}
}

@inproceedings{mahajan2018exploring,
  title={Exploring the limits of weakly supervised pretraining},
  author={Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and Van Der Maaten, Laurens},
  booktitle={European Conference on Computer Vision (ECCV)},
  note={\url{https://arxiv.org/abs/1805.00932}},
  year={2018}
}

@inproceedings{xie2020self,
  title={Self-training with noisy student improves imagenet classification},
  author={Xie, Qizhe and Luong, Minh-Thang and Hovy, Eduard and Le, Quoc V},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  note={\url{https://arxiv.org/abs/1911.04252}},
  year={2020}
}

@inproceedings{sun2017revisiting,
  title={Revisiting unreasonable effectiveness of data in deep learning era},
  author={Sun, Chen and Shrivastava, Abhinav and Singh, Saurabh and Gupta, Abhinav},
  booktitle={International Conference on Computer Vision (ICCV)},
  note={\url{https://arxiv.org/abs/1707.02968}},
  year={2017}
}

@inproceedings{li2017learning,
  title={Learning visual n-grams from web data},
  author={Li, Ang and Jabri, Allan and Joulin, Armand and van der Maaten, Laurens},
  booktitle={International Conference on Computer Vision (ICCV)},
  note={\url{https://arxiv.org/abs/1612.09161}},
  year={2017}
}

@inproceedings{joulin2016learning,
  title={Learning visual features from large weakly supervised data},
  author={Joulin, Armand and Van Der Maaten, Laurens and Jabri, Allan and Vasilache, Nicolas},
  booktitle={European Conference on Computer Vision (ECCV)},
  note={\url{https://arxiv.org/abs/1511.02251}},
  year={2016}
}

@misc{fort2019deep,
  title={Deep ensembles: A loss landscape perspective},
  author={Fort, Stanislav and Hu, Huiyi and Lakshminarayanan, Balaji},
  note={\url{https://arxiv.org/abs/1912.02757}},
  year={2019}
}

@article{gao2021clip,
  title={Clip-adapter: Better vision-language models with feature adapters},
  author={Gao, Peng and Geng, Shijie and Zhang, Renrui and Ma, Teli and Fang, Rongyao and Zhang, Yongfeng and Li, Hongsheng and Qiao, Yu},
  journal={arXiv preprint arXiv:2110.04544},
  year={2021}
}

@article{zhang2021tip,
  title={Tip-Adapter: Training-free CLIP-Adapter for Better Vision-Language Modeling},
  author={Zhang, Renrui and Fang, Rongyao and Gao, Peng and Zhang, Wei and Li, Kunchang and Dai, Jifeng and Qiao, Yu and Li, Hongsheng},
  journal={arXiv preprint arXiv:2111.03930},
  year={2021}
}

@misc{coop,
  title={Learning to Prompt for Vision-Language Models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  note={\url{https://arxiv.org/abs/2109.01134}},
  year={2021}
}


@Article{mu2021slip,
  author  = {Norman Mu and Alexander Kirillov and David Wagner and Saining Xie},
  title   = {SLIP: Self-supervision meets Language-Image Pre-training},
  journal = {arXiv preprint arXiv:2112.12750},
  year    = {2021},
}

@inproceedings{fort2020deep,
  title={Deep learning versus kernel learning: an empirical study of loss landscape geometry and the time evolution of the neural tangent kernel},
  author={Fort, Stanislav and Dziugaite, Gintare Karolina and Paul, Mansheej and Kharaghani, Sepideh and Roy, Daniel M and Ganguli, Surya},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year={2020},
  note={\url{https://arxiv.org/abs/2010.15110}},
}

@inproceedings{kornblith2019similarity,
  title={Similarity of neural network representations revisited},
  author={Kornblith, Simon and Norouzi, Mohammad and Lee, Honglak and Hinton, Geoffrey},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2019},
  note={\url{https://arxiv.org/abs/1905.00414}}
}

@inproceedings{skalak1996sources,
  title={The sources of increased accuracy for two proposed boosting algorithms},
  author={Skalak, David B and others},
  booktitle={American Association for Artificial Intelligence (AAAI), Integrating Multiple Learned Models Workshop},
  year={1996},
  note={\url{https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.40.2269&rep=rep1&type=pdf}}
}

@book{kuncheva2014combining,
  title={Combining pattern classifiers: methods and algorithms},
  author={Kuncheva, Ludmila I},
  year={2014},
  publisher={John Wiley \& Sons}
}

@book{friedman2001elements,
  title={The elements of statistical learning},
  author={Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert and others},
  year={2001},
  publisher={Springer series in statistics New York}
}

@book{quinonero2009dataset,
  title={Dataset shift in machine learning},
  author={Qui{\~n}onero-Candela, Joaquin and Sugiyama, Masashi and Lawrence, Neil D and Schwaighofer, Anton},
  year={2009},
  publisher={Mit Press}
}

@article{ho1998random,
  title={The random subspace method for constructing decision forests},
  author={Ho, Tin Kam},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  note={\url{https://ieeexplore.ieee.org/document/709601}},
  year={1998}
}

@article{kuncheva2003measures,
  title={Measures of diversity in classifier ensembles and their relationship with the ensemble accuracy},
  author={Kuncheva, Ludmila I and Whitaker, Christopher J},
  journal={Machine learning},
  year={2003},
  note={\url{https://doi.org/10.1023/A:1022859003006}}
}

@inproceedings{sariyildiz2020learning,
  title={Learning visual representations with caption annotations},
  author={Sariyildiz, Mert Bulent and Perez, Julien and Larlus, Diane},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2020},
  note={\url{https://arxiv.org/abs/2008.01392}}
}

@inproceedings{desai2021virtex,
  title={Virtex: Learning visual representations from textual annotations},
  author={Desai, Karan and Johnson, Justin},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2021},
  note={\url{https://arxiv.org/abs/2006.06666}}
}

@inproceedings{sharif2014cnn,
  title={CNN features off-the-shelf: an astounding baseline for recognition},
  author={Sharif Razavian, Ali and Azizpour, Hossein and Sullivan, Josephine and Carlsson, Stefan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition workshops},
  year={2014},
  note={\url{https://arxiv.org/abs/1403.6382}}
}

@inproceedings{torralba2011unbiased,
  title={Unbiased look at dataset bias},
  author={Torralba, Antonio and Efros, Alexei A},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2011},
  note={\url{https://people.csail.mit.edu/torralba/publications/datasets_cvpr11.pdf}}
}

@misc{zhang2020contrastive,
  title={Contrastive learning of medical visual representations from paired images and text},
  author={Zhang, Yuhao and Jiang, Hang and Miura, Yasuhide and Manning, Christopher D and Langlotz, Curtis P},
  note={\url{https://arxiv.org/abs/2010.00747}},
  year={2020}
}

@inproceedings{kolesnikov2020big,
  title={Big transfer (bit): General visual representation learning},
  author={Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Puigcerver, Joan and Yung, Jessica and Gelly, Sylvain and Houlsby, Neil},
  booktitle={European Conference on Computer Vision (ECCV)},
  note={\url{https://arxiv.org/abs/1912.11370}},
  year={2020}
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc V and Sung, Yunhsuan and Li, Zhen and Duerig, Tom},
  booktitle={International Conference on Machine Learning (ICML)},
  note={\url{https://arxiv.org/abs/2102.05918}},
  year={2021}
}

@inproceedings{goyal2019scaling,
  title={Scaling and benchmarking self-supervised visual representation learning},
  author={Goyal, Priya and Mahajan, Dhruv and Gupta, Abhinav and Misra, Ishan},
  booktitle={International Conference on Computer Vision (ICCV)},
  note={\url{https://arxiv.org/abs/1905.01235}},
  year={2019}
}

@inproceedings{gidaris2018unsupervised,
  title={Unsupervised Representation Learning by Predicting Image Rotations},
  author={Gidaris, Spyros and Singh, Praveer and Komodakis, Nikos},
  booktitle={International Conference on Learning Representations (ICLR)},
  note={\url{https://arxiv.org/abs/1803.07728}},
  year={2018}
}

@inproceedings{
foret2021sharpnessaware,
title={Sharpness-aware Minimization for Efficiently Improving Generalization},
author={Pierre Foret and Ariel Kleiner and Hossein Mobahi and Behnam Neyshabur},
booktitle={International Conference on Learning Representations},
year={2021},
note={\url{https://openreview.net/forum?id=6Tm1mposlrM}},
}

@inproceedings{Noroozi2017RepresentationLB,
  title={Representation Learning by Learning to Count},
  author={Mehdi Noroozi and Hamed Pirsiavash and Paolo Favaro},
  booktitle={International Conference on Computer Vision (ICCV)},
  note={\url{https://arxiv.org/abs/1708.06734}},
  year={2017},
}

@inproceedings{noroozi2016unsupervised,
  title={Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles},
  author={Noroozi, Mehdi and Favaro, Paolo},
  booktitle={European Conference on Computer Vision (ECCV)},
  note={\url{https://arxiv.org/abs/1603.09246}},
  year={2016},
}

@inproceedings{doersch2015unsupervised,
  title = {Unsupervised Visual Representation Learning by Context Prediction},
  author = {Doersch, Carl and Gupta, Abhinav and Efros, Alexei A.},
  booktitle = {International Conference on Computer Vision (ICCV)},
  note={\url{https://arxiv.org/abs/1505.05192}},
  year = {2015}
}

@misc{bommasani2021opportunities,
  title={On the Opportunities and Risks of Foundation Models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  note={\url{https://arxiv.org/abs/2108.07258}},
  year={2021}
}

@misc{hinton2014dark,
  title={Dark knowledge},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  year={2014},
  note={\url{https://www.ttic.edu/dl/dark14.pdf}},
}

@misc{zhai2021scaling,
  title={Scaling vision transformers},
  author={Zhai, Xiaohua and Kolesnikov, Alexander and Houlsby, Neil and Beyer, Lucas},
  note={\url{https://arxiv.org/abs/2106.04560}},
  year={2021}
}

@inproceedings{
dosovitskiy2021an,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations (ICLR)},
year={2021},
note={\url{https://arxiv.org/abs/2010.11929}}
}

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "North {A}merican Chapter of the Association for Computational Linguistics (NAACL)",
    year = "2019",
    url = "https://aclanthology.org/N19-1423",
}

@inproceedings{peters-etal-2018-deep,
    title = "Deep Contextualized Word Representations",
    author = "Peters, Matthew E.  and
      Neumann, Mark  and
      Iyyer, Mohit  and
      Gardner, Matt  and
      Clark, Christopher  and
      Lee, Kenton  and
      Zettlemoyer, Luke",
    booktitle = "North {A}merican Chapter of the Association for Computational Linguistics (NAACL)",
    year = "2018",
    url = "https://aclanthology.org/N18-1202",
}

@inproceedings{sun2020scalability,
  title={Scalability in perception for autonomous driving: Waymo open dataset},
  author={Sun, Pei and Kretzschmar, Henrik and Dotiwalla, Xerxes and Chouard, Aurelien and Patnaik, Vijaysai and Tsui, Paul and Guo, James and Zhou, Yin and Chai, Yuning and Caine, Benjamin and others},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  note={\url{https://arxiv.org/abs/1912.04838}},
  year={2020}
}

@inproceedings{miller2020effect,
  title={The effect of natural distribution shift on question answering models},
  author={Miller, John and Krauth, Karl and Recht, Benjamin and Schmidt, Ludwig},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020},
  note={\url{https://arxiv.org/abs/2004.14444}},
}

@misc{yalniz2019billion,
  title={Billion-scale semi-supervised learning for image classification},
  author={Yalniz, I Zeki and J{\'e}gou, Herv{\'e} and Chen, Kan and Paluri, Manohar and Mahajan, Dhruv},
  note={\url{https://arxiv.org/abs/1905.00546}},
  year={2019}
}

@misc{steiner2021train,
  title={How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers},
  author={Steiner, Andreas and Kolesnikov, Alexander and Zhai, Xiaohua and Wightman, Ross and Uszkoreit, Jakob and Beyer, Lucas},
  year={2021},
  note={\url{https://arxiv.org/abs/2106.10270}}
}

@misc{roelofs2020mitigating,
  title={Mitigating bias in calibration error estimation},
  author={Roelofs, Rebecca and Cain, Nicholas and Shlens, Jonathon and Mozer, Michael C},
  note={\url{https://arxiv.org/abs/2012.08668}},
  year={2020}
}

@inproceedings{alcorn2019strike,
  title={Strike (with) a pose: Neural networks are easily fooled by strange poses of familiar objects},
  author={Alcorn, Michael A and Li, Qi and Gong, Zhitao and Wang, Chengfei and Mai, Long and Ku, Wei-Shinn and Nguyen, Anh},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  note={\url{https://arxiv.org/abs/1811.11553}},
  year={2019}
}

@misc{radford2019language,
author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
title = {{Language Models are Unsupervised Multitask Learners}},
note={\url{https://openai.com/blog/better-language-models/}},
year = {2019}
}

@misc{henighan2020scaling,
  title={Scaling laws for autoregressive generative modeling},
  author={Henighan, Tom and Kaplan, Jared and Katz, Mor and Chen, Mark and Hesse, Christopher and Jackson, Jacob and Jun, Heewoo and Brown, Tom B and Dhariwal, Prafulla and Gray, Scott and others},
  note={\url{https://arxiv.org/abs/2010.14701}},
  year={2020}
}

@misc{hernandez2021scaling,
  title={Scaling laws for transfer},
  author={Hernandez, Danny and Kaplan, Jared and Henighan, Tom and McCandlish, Sam},
  note={\url{https://arxiv.org/abs/2102.01293}},
  year={2021}
}

@inproceedings{brown2020language,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and others},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 title = {Language Models are Few-Shot Learners},
 note={\url{https://arxiv.org/abs/2005.14165}},
 year = {2020}
}



@InProceedings{pmlr-v97-recht19a, 
title = {Do {I}mage{N}et Classifiers Generalize to {I}mage{N}et?}, 
author = {Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal}, 
booktitle = {International Conference on Machine Learning (ICML)}, 
year = {2019},
note={\url{https://arxiv.org/abs/1902.10811}}
}

@article{imageneta,
  title={Natural Adversarial Examples},
  author={Dan Hendrycks and Kevin Zhao and Steven Basart and Jacob Steinhardt and Dawn Song},
  journal={Conference on Computer Vision and Pattern Recognition (CVPR)},
  note={\url{https://arxiv.org/abs/1907.07174}},
  year={2021}
}

@article{imagenetc,
  title={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},
  author={Dan Hendrycks and Thomas Dietterich},
  journal={International Conference on Learning Representations (ICLR)},
  note={\url{https://arxiv.org/abs/1903.12261}},
  year={2019}
}

@article{imagenetr,
  title={The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization},
  author={Dan Hendrycks and Steven Basart and Norman Mu and Saurav Kadavath and Frank Wang and Evan Dorundo and Rahul Desai and Tyler Zhu and Samyak Parajuli and Mike Guo and Dawn Song and Jacob Steinhardt and Justin Gilmer},
  journal={International Conference on Computer Vision (ICCV)},
  note={\url{https://arxiv.org/abs/2006.16241}},
  year={2021}
}

@inproceedings{imagenetsketch,
    title={Learning Robust Global Representations by Penalizing Local Predictive Power},
    author={Wang, Haohan and Ge, Songwei and Lipton, Zachary and Xing, Eric P},
    booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
    note={\url{https://arxiv.org/abs/1905.13549}},
    year={2019}
}

@inproceedings{objectnet,
 author = {Barbu, Andrei and Mayo, David and Alverio, Julian and Luo, William and Wang, Christopher and Gutfreund, Dan and Tenenbaum, Josh and Katz, Boris},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 title = {ObjectNet: A large-scale bias-controlled dataset for pushing the limits of object recognition models},
 url = {https://proceedings.neurips.cc/paper/2019/file/97af07a14cacba681feacf3012730892-Paper.pdf},
 year = {2019}
}

@misc{vidrobust,
  title={Do Image Classifiers Generalize Across Time?},
  author={Shankar, Vaishaal and Dave, Achal and Roelofs, Rebecca and Ramanan, Deva and Recht, Benjamin and Schmidt, Ludwig},
  note={\url{https://arxiv.org/abs/1906.02168}},
  year={2019}
}

@inproceedings{wilds2021,
  title = {{WILDS}: A Benchmark of in-the-Wild Distribution Shifts},
  author = {Pang Wei Koh and Shiori Sagawa and Henrik Marklund and Sang Michael Xie and Marvin Zhang and Akshay Balsubramani and Weihua Hu and Michihiro Yasunaga and Richard Lanas Phillips and Irena Gao and Tony Lee and Etienne David and Ian Stavness and Wei Guo and Berton A. Earnshaw and Imran S. Haque and Sara Beery and Jure Leskovec and Anshul Kundaje and Emma Pierson and Sergey Levine and Chelsea Finn and Percy Liang},
  booktitle = {International Conference on Machine Learning (ICML)},
  year = {2021},
  note={\url{https://arxiv.org/abs/2012.07421}}
}


@InProceedings{miller21b,
  title = 	 {Accuracy on the Line: on the Strong Correlation Between Out-of-Distribution and In-Distribution Generalization},
  author =       {Miller, John P and Taori, Rohan and Raghunathan, Aditi and Sagawa, Shiori and Koh, Pang Wei and Shankar, Vaishaal and Liang, Percy and Carmon, Yair and Schmidt, Ludwig},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2021},
  note={\url{https://arxiv.org/abs/2107.04649}},
}


@inproceedings{dietterich2000ensemble,
  title={Ensemble methods in machine learning},
  author={Dietterich, Thomas G},
  booktitle={International workshop on multiple classifier systems},
  year={2000},
  note={\url{https://link.springer.com/chapter/10.1007/3-540-45014-9_1}}
}

@inproceedings{deepensembles,
 author = {Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 title = {Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles},
 note={\url{https://arxiv.org/abs/1612.01474}},
 year = {2017}
}

@article{bauer1999empirical,
  title={An empirical comparison of voting classification algorithms: Bagging, boosting, and variants},
  author={Bauer, Eric and Kohavi, Ron},
  journal={Machine learning},
  year={1999},
  note={\url{https://link.springer.com/article/10.1023/A:1007515423169}}
}

@article{breiman1996bagging,
  title={Bagging predictors},
  author={Breiman, Leo},
  journal={Machine learning},
  year={1996},
  note={\url{https://link.springer.com/article/10.1007/BF00058655}}
}

@article{FREUND1997119,
title = {A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting},
author={Freund, Yoav and Schapire, Robert E},
journal = {Journal of Computer and System Sciences},
year = {1997},
note={\url{https://www.sciencedirect.com/science/article/pii/S002200009791504X}}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  note={\url{https://arxiv.org/abs/1512.03385}},
  year={2016}
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2012},
  note={\url{https://dl.acm.org/doi/10.1145/3065386}}
}
@inproceedings{geirhos2018generalisation,
  title={Generalisation in humans and deep neural networks},
  author={Geirhos, Robert and Temme, Carlos R Medina and Rauber, Jonas and Sch{\"u}tt, Heiko H and Bethge, Matthias and Wichmann, Felix A},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  note={\url{https://arxiv.org/abs/1808.08750}},
  year={2018}
}

@inproceedings{cubuk2018autoaugment,
  title={Autoaugment: Learning augmentation policies from data},
  author={Cubuk, Ekin D and Zoph, Barret and Mane, Dandelion and Vasudevan, Vijay and Le, Quoc V},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  note={\url{https://arxiv.org/abs/1805.09501}},
  year={2018}
}

@article{bian2021does,
  title={When does diversity help generalization in classification ensembles?},
  author={Bian, Yijun and Chen, Huanhuan},
  journal={IEEE Transactions on Cybernetics},
  year={2021},
  note={\url{https://arxiv.org/abs/1910.13631}}
}

@inproceedings{hendrycks2019augmix,
  title={{AugMix}: A Simple Data Processing Method to Improve Robustness and Uncertainty},
  author={Hendrycks, Dan and Mu, Norman and Cubuk, Ekin D. and Zoph, Barret and Gilmer, Justin and Lakshminarayanan, Balaji},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020},
  note={\url{https://arxiv.org/abs/1912.02781}}
}

@inproceedings{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2017},
  note={\url{https://arxiv.org/abs/1706.06083}}
}

@inproceedings{eykholt2018robust,
  title={Robust physical-world attacks on deep learning visual classification},
  author={Eykholt, Kevin and Evtimov, Ivan and Fernandes, Earlence and Li, Bo and Rahmati, Amir and Xiao, Chaowei and Prakash, Atul and Kohno, Tadayoshi and Song, Dawn},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  note={\url{https://arxiv.org/abs/1707.08945}},
  year={2018}
}

@inproceedings{geirhos2018imagenet,
  title={ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness},
  author={Geirhos, Robert and Rubisch, Patricia and Michaelis, Claudio and Bethge, Matthias and Wichmann, Felix A and Brendel, Wieland},
  booktitle={International Conference on Learning Representations (ICLR)},
  note={\url{https://arxiv.org/abs/1811.12231}},
  year={2018}
}

@inproceedings{engstrom2019exploring,
  title={Exploring the landscape of spatial robustness},
  author={Engstrom, Logan and Tran, Brandon and Tsipras, Dimitris and Schmidt, Ludwig and Madry, Aleksander},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2019},
  note={\url{https://arxiv.org/abs/1712.02779}}
}

@misc{devries2017improved,
  title={Improved regularization of convolutional neural networks with cutout},
  author={DeVries, Terrance and Taylor, Graham W},
  note={\url{https://arxiv.org/abs/1708.04552}},
  year={2017}
}

@inproceedings{salman2019provably,
  title={Provably robust deep learning via adversarially trained smoothed classifiers},
  author={Salman, Hadi and Yang, Greg and Li, Jerry and Zhang, Pengchuan and Zhang, Huan and Razenshteyn, Ilya and Bubeck, Sebastien},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  note={\url{https://arxiv.org/abs/1906.04584}},
  year={2019}
}

@inproceedings{shafahi2019adversarial,
  title={Adversarial training for free!},
  author={Shafahi, Ali and Najibi, Mahyar and Ghiasi, Amin and Xu, Zheng and Dickerson, John and Studer, Christoph and Davis, Larry S and Taylor, Gavin and Goldstein, Tom},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2019},
  note={\url{https://arxiv.org/abs/1904.12843}}
}

@inproceedings{cohen2019certified,
  title={Certified adversarial robustness via randomized smoothing},
  author={Cohen, Jeremy and Rosenfeld, Elan and Kolter, Zico},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2019},
  note={\url{https://arxiv.org/abs/1902.02918}}
}


@inproceedings{hinton2015distilling,
  title={Distilling the knowledge in a neural network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  note={\url{https://arxiv.org/abs/1503.02531}},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS) Deep Learning Workshop},
  year={2015}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={Conference on Computer Vision and Pattern Recognition},
  year={2009},
  note={\url{https://ieeexplore.ieee.org/document/5206848}}
}

@inproceedings{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2019},
  note={\url{https://arxiv.org/abs/1912.01703}}
}

@inproceedings{
loshchilov2018decoupled,
title={Decoupled Weight Decay Regularization},
author={Ilya Loshchilov and Frank Hutter},
booktitle={International Conference on Learning Representations (ICLR)},
year={2019},
note={\url{https://openreview.net/forum?id=Bkg6RiCqY7}},
}

@misc{choi2019empirical,
  title={On empirical comparisons of optimizers for deep learning},
  author={Choi, Dami and Shallue, Christopher J and Nado, Zachary and Lee, Jaehoon and Maddison, Chris J and Dahl, George E},
  note={\url{https://arxiv.org/abs/1910.05446}},
  year={2019}
}

@misc{beyer2021knowledge,
  title={Knowledge distillation: A good teacher is patient and consistent},
  author={Beyer, Lucas and Zhai, Xiaohua and Royer, Am{\'e}lie and Markeeva, Larisa and Anil, Rohan and Kolesnikov, Alexander},
  year={2021},
  url={https://arxiv.org/abs/2106.05237},
}

@inproceedings{loshchilov2016sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  booktitle={International Conference on Learning Representations (ICLR)},
  note={\url{https://arxiv.org/abs/1608.03983}},
  year={2016}
}

@inproceedings{muller2019does,
  title={When does label smoothing help?},
  author={M{\"u}ller, Rafael and Kornblith, Simon and Hinton, Geoffrey},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  note={\url{https://arxiv.org/abs/1906.02629}},
  year={2019}
}

@article{zhu1997algorithm,
  title={Algorithm 778: L-BFGS-B: Fortran subroutines for large-scale bound-constrained optimization},
  author={Zhu, Ciyou and Byrd, Richard H and Lu, Peihuang and Nocedal, Jorge},
  journal={ACM Transactions on mathematical software (TOMS)},
  year={1997},
}

@inproceedings{yadav2019cold,
  title={Cold case: The lost mnist digits},
  author={Yadav, Chhavi and Bottou, L{\'e}on},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  note={\url{https://arxiv.org/abs/1905.10498}},
  year={2019}
}

@inproceedings{kornblith2019better,
  title={Do better imagenet models transfer better?},
  author={Kornblith, Simon and Shlens, Jonathon and Le, Quoc V},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  note={\url{https://arxiv.org/abs/1805.08974}},
  year={2019}
}

@misc{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  note={\url{https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf}}
}

@inproceedings{lu2020harder,
  title={Harder or different? a closer look at distribution shift in dataset reproduction},
  author={Lu, Shangyun and Nott, Bradley and Olson, Aaron and Todeschini, Alberto and Vahabi, Hossein and Carmon, Yair and Schmidt, Ludwig},
  booktitle={International Conference on Machine Learning (ICML) Workshop on Uncertainty and Robustness in Deep Learning},
  note={\url{http://www.gatsby.ucl.ac.uk/~balaji/udl2020/accepted-papers/UDL2020-paper-101.pdf}},
  year={2020}
}

@inproceedings{christie2018functional,
  title={Functional map of the world},
  author={Christie, Gordon and Fendley, Neil and Wilson, James and Mukherjee, Ryan},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  note={\url{https://arxiv.org/abs/1711.07846}},
  year={2018}
}

@inproceedings{beery2021iwildcam,
  title={The iWildCam 2021 Competition Dataset},
  author={Beery, Sara and Agarwal, Arushi and Cole, Elijah and Birodkar, Vighnesh},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR) FGVC8 Workshop},
  note={\url{https://arxiv.org/abs/2105.03494}},
  year={2021}
}


@InProceedings{pmlr-v80-dziugaite18a,
title = {Entropy-{SGD} optimizes the prior of a {PAC}-{B}ayes bound: Generalization properties of Entropy-{SGD} and data-dependent priors},
author = {Dziugaite, Gintare Karolina and Roy, Daniel},
booktitle = {International Conference on Machine Learning (ICML)},
year = {2018},
note={\url{https://arxiv.org/abs/1712.09376}}
}

@article{hochreiter1997flat,
  title={Flat minima},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  year={1997},
  note={\url{https://direct.mit.edu/neco/article/9/1/1/6027/Flat-Minima}}
}

@inproceedings{li2017visualizing,
  title={Visualizing the loss landscape of neural nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  note={\url{https://arxiv.org/abs/1712.09913}},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2017}
}

@inproceedings{dtd,
  title={Describing textures in the wild},
  author={Cimpoi, Mircea and Maji, Subhransu and Kokkinos, Iasonas and Mohamed, Sammy and Vedaldi, Andrea},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  note={\url{https://arxiv.org/abs/1311.3618}},
  year={2014}
}

@inproceedings{food101,
  title={Food-101--mining discriminative components with random forests},
  author={Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2014},
  note={\url{https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/}}
}

@article{sun397,
  title={Sun database: Exploring a large collection of scene categories},
  author={Xiao, Jianxiong and Ehinger, Krista A and Hays, James and Torralba, Antonio and Oliva, Aude},
  journal={International Journal of Computer Vision},
  year={2016},
  note={\url{https://link.springer.com/article/10.1007/s11263-014-0748-y}}
}

@inproceedings{cars,
  title={3d object representations for fine-grained categorization},
  author={Krause, Jonathan and Stark, Michael and Deng, Jia and Fei-Fei, Li},
  booktitle={International Conference on Computer Vision (ICCV) Workshops},
  year={2013},
  note={\url{https://ieeexplore.ieee.org/document/6755945}}
}

@misc{andreassen2021evolution,
  title={The Evolution of Out-of-Distribution Robustness Throughout Fine-Tuning},
  author={Andreassen, Anders and Bahri, Yasaman and Neyshabur, Behnam and Roelofs, Rebecca},
  note={\url{https://arxiv.org/abs/2106.15831}},
  year={2021}
}

@inproceedings{guo2017calibration,
  title={On calibration of modern neural networks},
  author={Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q},
  note={\url{https://arxiv.org/abs/1706.04599}},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017}
}



@inproceedings{pmlr-v139-wortsman21a,
  title = {Learning Neural Network Subspaces},
  author = {Wortsman, Mitchell and Horton, Maxwell C and Guestrin, Carlos and Farhadi, Ali and Rastegari, Mohammad},
  booktitle = {International Conference on Machine Learning (ICML)},
  year = {2021},
  note={\url{https://arxiv.org/abs/2102.10472}}
}


@inproceedings{malinin2019ensemble,
  title={Ensemble distribution distillation},
  author={Malinin, Andrey and Mlodozeniec, Bruno and Gales, Mark},
  note={\url{https://arxiv.org/abs/1905.00076}},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2019}
}

@inproceedings{tran2020hydra,
  title={Hydra: Preserving ensemble diversity for model distillation},
  author={Tran, Linh and Veeling, Bastiaan S and Roth, Kevin and Swiatkowski, Jakub and Dillon, Joshua V and Snoek, Jasper and Mandt, Stephan and Salimans, Tim and Nowozin, Sebastian and Jenatton, Rodolphe},
  note={\url{https://arxiv.org/abs/2001.04694}},
  booktitle={International Conference on Machine Learning (ICML) Workshop on Uncertainty and Robustness in Deep Learning},
  year={2020}
}

@inproceedings{neyshabur2020being,
  title={What is being transferred in transfer learning?},
  author={Neyshabur, Behnam and Sedghi, Hanie and Zhang, Chiyuan},
  note={\url{https://arxiv.org/abs/2008.11687}},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@inproceedings{izmailov2018averaging,
  title={Averaging weights leads to wider optima and better generalization},
  author={Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},
  booktitle={Conference on Uncertainty in Artificial Intelligence (UAI)},
  note={\url{https://arxiv.org/abs/1803.05407}},
  year={2018}
}

@inproceedings{frankle2020linear,
  title={Linear mode connectivity and the lottery ticket hypothesis},
  author={Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel and Carbin, Michael},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020},
  note={\url{https://arxiv.org/abs/1912.05671}}
}

@inproceedings{garipov2018loss,
  title={Loss surfaces, mode connectivity, and fast ensembling of dnns},
  author={Garipov, Timur and Izmailov, Pavel and Podoprikhin, Dmitrii and Vetrov, Dmitry and Wilson, Andrew Gordon},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  note={\url{https://arxiv.org/abs/1802.10026}},
  year={2018}
}

@inproceedings{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  note={\url{https://arxiv.org/abs/1806.07572}},
  year={2018}
}


@inproceedings{li2018measuring,
  title={Measuring the intrinsic dimension of objective landscapes},
  author={Li, Chunyuan and Farkhoor, Heerad and Liu, Rosanne and Yosinski, Jason},
  booktitle={International Conference on Learning Representations (ICLR)},
  note={\url{https://arxiv.org/abs/1804.08838}},
  year={2018}
}

@misc{d2020underspecification,
  title={Underspecification presents challenges for credibility in modern machine learning},
  author={D'Amour, Alexander and Heller, Katherine and Moldovan, Dan and Adlam, Ben and Alipanahi, Babak and Beutel, Alex and Chen, Christina and Deaton, Jonathan and Eisenstein, Jacob and Hoffman, Matthew D and others},
  note={\url{https://arxiv.org/abs/2011.03395}},
  year={2020}
}


@inproceedings{tramer2017ensemble,
  title={Ensemble adversarial training: Attacks and defenses},
  author={Tram{\`e}r, Florian and Kurakin, Alexey and Papernot, Nicolas and Goodfellow, Ian and Boneh, Dan and McDaniel, Patrick},
  booktitle={International Conference on Learning Representations (ICLR)},
  note={\url{https://arxiv.org/abs/1705.07204}},
  year={2017}
}

@inproceedings{stickland2020diverse,
  title={Diverse ensembles improve calibration},
  author={Stickland, Asa Cooper and Murray, Iain},
  booktitle={International Conference on Machine Learning (ICML) Workshop on Uncertainty and Robustness in Deep Learning},
  note={\url{https://arxiv.org/abs/2007.04206}},
  year={2020}
}

@misc{mustafa2020deep,
  title={Deep Ensembles for Low-Data Transfer Learning},
  author={Mustafa, Basil and Riquelme, Carlos and Puigcerver, Joan and Pinto, Andr{\'e} Susano and Keysers, Daniel and Houlsby, Neil},
  note={\url{https://arxiv.org/abs/2010.06866}},
  year={2020}
}

@inproceedings{ovadia2019can,
  title={Can you trust your model's uncertainty? Evaluating predictive uncertainty under dataset shift},
  author={Ovadia, Yaniv and Fertig, Emily and Ren, Jie and Nado, Zachary and Sculley, David and Nowozin, Sebastian and Dillon, Joshua V and Lakshminarayanan, Balaji and Snoek, Jasper},
  note={\url{https://arxiv.org/abs/1906.02530}},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2019}
}

@inproceedings{lucas2021analyzing,
  title={Analyzing Monotonic Linear Interpolation in Neural Network Loss Landscapes},
  author={Lucas, James and Bae, Juhan and Zhang, Michael R and Fort, Stanislav and Zemel, Richard and Grosse, Roger},
  booktitle={International Conference on Machine Learning (ICML)},
  note={\url{https://arxiv.org/abs/2104.11044}},
  year={2021}
}

@inproceedings{goodfellow2014qualitatively,
  title={Qualitatively characterizing neural network optimization problems},
  author={Goodfellow, Ian J and Vinyals, Oriol and Saxe, Andrew M},
  note={\url{https://arxiv.org/abs/1412.6544}},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2014}
}

@misc{amodei2016concrete,
  title={Concrete problems in AI safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  note={\url{https://arxiv.org/abs/1606.06565}},
  year={2016}
}

@inproceedings{zhang2019lookahead,
  title={Lookahead optimizer: k steps forward, 1 step back},
  author={Zhang, Michael R and Lucas, James and Hinton, Geoffrey and Ba, Jimmy},
  note={\url{https://arxiv.org/abs/1907.08610}},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2019}
}

@inproceedings{utama2021avoiding,
  title={Avoiding Inference Heuristics in Few-shot Prompt-based Finetuning},
  author={Utama, Prasetya Ajie and Moosavi, Nafise Sadat and Sanh, Victor and Gurevych, Iryna},
  note={\url{https://arxiv.org/abs/2109.04144}},
  booktitle={Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2021}
}

@inproceedings{jiang2019smart,
  title={Smart: Robust and efficient fine-tuning for pre-trained natural language models through principled regularized optimization},
  author={Jiang, Haoming and He, Pengcheng and Chen, Weizhu and Liu, Xiaodong and Gao, Jianfeng and Zhao, Tuo},
  note={\url{https://arxiv.org/abs/1911.03437}},
  booktitle={Association for Computational Linguistics (ACL)},
  year={2019}
}

@inproceedings{zhu2019freelb,
  title={Freelb: Enhanced adversarial training for natural language understanding},
  author={Zhu, Chen and Cheng, Yu and Gan, Zhe and Sun, Siqi and Goldstein, Tom and Liu, Jingjing},
  note={\url{https://arxiv.org/abs/1909.11764}},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020}
}
@article{polyak1992acceleration,
  title={Acceleration of stochastic approximation by averaging},
  author={Polyak, Boris T and Juditsky, Anatoli B},
  journal={SIAM journal on control and optimization},
  year={1992},
  note={\url{https://epubs.siam.org/doi/abs/10.1137/0330046?journalCode=sjcodc}}
}

@article{polyak1990new,
  title={New method of stochastic approximation type},
  author={Polyak, Boris Teodorovich},
  journal={Automation and remote control},
  year={1990},
}
@misc{ruppert1988efficient,
  title={Efficient estimations from a slowly convergent Robbins-Monro process},
  author={Ruppert, David},
  year={1988},
  note={\url{https://ecommons.cornell.edu/bitstream/handle/1813/8664/TR000781.pdf}}
}

@article{wortsman2021robust,
  title={Robust fine-tuning of zero-shot models},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Kim, Jong Wook and Li, Mike and Kornblith, Simon and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Hajishirzi, Hannaneh and Farhadi, Ali and Namkoong, Hongseok and Schmidt, Ludwig},
  note={\url{https://arxiv.org/abs/2109.01903}},
  year={2021}
}


@misc{nichol2018first,
  title={On first-order meta-learning algorithms},
  author={Nichol, Alex and Achiam, Joshua and Schulman, John},
  note={\url{https://arxiv.org/abs/1803.02999}},
  year={2018}
}


@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences (PNAS)},
  year={2017},
  note={\url{https://arxiv.org/abs/1612.00796}}
}
@inproceedings{zenke2017continual,
  title={Continual learning through synaptic intelligence},
  author={Zenke, Friedemann and Poole, Ben and Ganguli, Surya},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017},
  note={\url{https://arxiv.org/abs/1703.04200}}
}

@misc{lubana2021quadratic,
      title={How do Quadratic Regularizers Prevent Catastrophic Forgetting: The Role of Interpolation}, 
      author={Ekdeep Singh Lubana and Puja Trivedi and Danai Koutra and Robert P. Dick},
      year={2021},
      note={\url{https://arxiv.org/abs/2102.02805}},
}

@inproceedings{yeo2021robustness,
  title={Robustness via Cross-Domain Ensembles},
  author={Yeo, Teresa and Kar, O\u{g}uzhan Fatih and Zamir, Amir},
  booktitle={International Conference on Computer Vision (ICCV)},
  note={\url{https://arxiv.org/abs/2103.10919}},
  year={2021}
}

@inproceedings{
    aghajanyan2021better,
    title={Better Fine-Tuning by Reducing Representational Collapse},
    author={Armen Aghajanyan and Akshat Shrivastava and Anchit Gupta and Naman Goyal and Luke Zettlemoyer and Sonal Gupta},
    booktitle={International Conference on Learning Representations (ICLR)},
    year={2021},
    note={\url{https://openreview.net/forum?id=OQ08SN70M1V}},
}

@article{MCCLOSKEY1989109,
    title = {Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem},
    journal = {Psychology of Learning and Motivation},
    year = {1989},
    note = {\url{https://www.sciencedirect.com/science/article/pii/S0079742108605368}},
    author = {Michael McCloskey and Neal J. Cohen},
}

@inproceedings{biggio2013evasion,
  title={Evasion attacks against machine learning at test time},
  author={Biggio, Battista and Corona, Igino and Maiorca, Davide and Nelson, Blaine and {\v{S}}rndi{\'c}, Nedim and Laskov, Pavel and Giacinto, Giorgio and Roli, Fabio},
  booktitle={Joint European conference on machine learning and knowledge discovery in databases},
  year={2013},
  note = {\url{https://arxiv.org/abs/1708.06131}}
}

@article{biggio2018wild,
  title={Wild patterns: Ten years after the rise of adversarial machine learning},
  author={Biggio, Battista and Roli, Fabio},
  journal={Pattern Recognition},
  year={2018},
  note = {\url{https://arxiv.org/abs/1712.03141}}
}

@inproceedings{shankar2020evaluating,
  title={Evaluating machine accuracy on imagenet},
  author={Shankar, Vaishaal and Roelofs, Rebecca and Mania, Horia and Fang, Alex and Recht, Benjamin and Schmidt, Ludwig},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020},
  note={\url{http://proceedings.mlr.press/v119/shankar20c/shankar20c.pdf}},
}

@misc{gontijo2021no,
  title={No One Representation to Rule Them All: Overlapping Features of Training Methods},
  author={Gontijo-Lopes, Raphael and Dauphin, Yann and Cubuk, Ekin D},
  journal={arXiv preprint arXiv:2110.12899},
  note={\url{https://arxiv.org/abs/2007.01434}},
  year={2021}
}


@inproceedings{li2020rethinking,
  title={Rethinking the hyperparameters for fine-tuning},
  author={Li, Hao and Chaudhari, Pratik and Yang, Hao and Lam, Michael and Ravichandran, Avinash and Bhotika, Rahul and Soatto, Stefano},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020},
  note={\url{https://arxiv.org/abs/2002.11770}},
}


@inproceedings{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2014},
  note={\url{https://arxiv.org/abs/1412.6980}},
}

@article{rmsprop,
  title={Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude},
  author={Tieleman, Tijmen and Hinton, Geoffrey},
  journal={COURSERA: Neural networks for machine learning},
  volume={4},
  number={2},
  pages={26--31},
  year={2012}
}


@article{zhang2017mixup,
  title={mixup: Beyond empirical risk minimization},
  author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2017},
  note={\url{https://arxiv.org/abs/1710.09412}},
}

@inproceedings{
hewitt2021ensembles,
title={Ensembles and Cocktails: Robust Finetuning for Natural Language Generation},
author={John Hewitt and Xiang Lisa Li and Sang Michael Xie and Benjamin Newman and Percy Liang},
booktitle={NeurIPS 2021 Workshop on Distribution Shifts},
year={2021},
note={\url{https://openreview.net/forum?id=qXucB21w1C3}}
}

@article{saikia2020optimized,
  title={Optimized generic feature learning for few-shot classification across domains},
  author={Saikia, Tonmoy and Brox, Thomas and Schmid, Cordelia},
  journal={arXiv preprint arXiv:2001.07926},
  year={2020}
}

@inproceedings{mendoza2016towards,
  title={Towards automatically-tuned neural networks},
  author={Mendoza, Hector and Klein, Aaron and Feurer, Matthias and Springenberg, Jost Tobias and Hutter, Frank},
  booktitle={Workshop on Automatic Machine Learning},
  pages={58--65},
  year={2016},
  organization={PMLR}
}

@inproceedings{snoek2015scalable,
  title={Scalable bayesian optimization using deep neural networks},
  author={Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Mostofa and Prabhat, Mr and Adams, Ryan},
  booktitle={International conference on machine learning},
  pages={2171--2180},
  year={2015},
  organization={PMLR}
}

@article{wenzel2020hyperparameter,
  title={Hyperparameter ensembles for robustness and uncertainty quantification},
  author={Wenzel, Florian and Snoek, Jasper and Tran, Dustin and Jenatton, Rodolphe},
  journal={arXiv preprint arXiv:2006.13570},
  year={2020}
}

@article{levesque2016bayesian,
  title={Bayesian hyperparameter optimization for ensemble learning},
  author={L{\'e}vesque, Julien-Charles and Gagn{\'e}, Christian and Sabourin, Robert},
  journal={arXiv preprint arXiv:1605.06394},
  year={2016}
}

@inproceedings{caruana2006getting,
  title={Getting the most out of ensemble selection},
  author={Caruana, Rich and Munson, Art and Niculescu-Mizil, Alexandru},
  booktitle={Sixth International Conference on Data Mining (ICDM'06)},
  pages={828--833},
  year={2006},
  organization={IEEE}
}

@misc{matena2021merging,
  title={Merging Models with Fisher-Weighted Averaging},
  author={Michael Matena and Colin Raffel},
  note={\url{https://arxiv.org/abs/2111.09832}},
  year={2021}
}

@inproceedings{caruana2004ensemble,
  title={Ensemble selection from libraries of models},
  author={Caruana, Rich and Niculescu-Mizil, Alexandru and Crew, Geoff and Ksikes, Alex},
  booktitle={Proceedings of the twenty-first international conference on Machine learning},
  pages={18},
  year={2004}
}


@misc{pham2021scaling,
  title={Combined Scaling for Zero-shot Transfer Learning},
  author={Hieu Pham and Zihang Dai and Golnaz Ghiasi and Hanxiao Liu and Adams Wei Yu and Minh-Thang Luong and Mingxing Tan and Quoc V. Le},
  note={\url{https://arxiv.org/abs/2111.10050}},
  year={2021}
}


@inproceedings{
kumar2021calibrated,
title={Calibrated Ensembles: A Simple Way to Mitigate {ID}-{OOD} Accuracy Tradeoffs},
author={Ananya Kumar and Aditi Raghunathan and Tengyu Ma and Percy Liang},
booktitle={NeurIPS 2021 Workshop on Distribution Shifts},
year={2021},
note={\url{https://openreview.net/forum?id=dmDE-9e9F_x}}
}


@misc{lopes2021no,
  title={No one representation to rule them all: overlapping features of training methods},
  author={Raphael Gontijo-Lopes and Yann Dauphin and Ekin D. Cubuk},
  note={\url{https://arxiv.org/abs/2110.12899}},
  year={2021}
}


@misc{zhai21lit,
  title={LiT: Zero-Shot Transfer with Locked-image Text Tuning},
  author={Xiaohua Zhai and Xiao Wang and Basil Mustafa and Andreas Steiner and Daniel Keysers and Alexander Kolesnikov and Lucas Beyer},
  note={\url{https://arxiv.org/abs/2111.07991}},
  year={2021}
}

@inproceedings{szegedy2016rethinking,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2818--2826},
  year={2016}
}

@inproceedings{donahue2014decaf,
  title={Decaf: A deep convolutional activation feature for generic visual recognition},
  author={Donahue, Jeff and Jia, Yangqing and Vinyals, Oriol and Hoffman, Judy and Zhang, Ning and Tzeng, Eric and Darrell, Trevor},
  booktitle={International conference on machine learning},
  pages={647--655},
  year={2014},
  organization={PMLR}
}

@inproceedings{girshick2014rich,
  title={Rich feature hierarchies for accurate object detection and semantic segmentation},
  author={Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={580--587},
  year={2014}
}

@inproceedings{azizpour2015generic,
  title={From generic to specific deep representations for visual recognition},
  author={Azizpour, Hossein and Sharif Razavian, Ali and Sullivan, Josephine and Maki, Atsuto and Carlsson, Stefan},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition workshops},
  pages={36--45},
  year={2015}
}

@inproceedings{chatfield2014return,
  title={Return of the devil in the details: Delving deep into convolutional nets},
  author={Chatfield, Ken and Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  booktitle={British Machine Vision Conference},
  year={2014}
}

@inproceedings{agrawal2014analyzing,
  title={Analyzing the performance of multilayer neural networks for object recognition},
  author={Agrawal, Pulkit and Girshick, Ross and Malik, Jitendra},
  booktitle={European conference on computer vision},
  pages={329--344},
  year={2014},
  organization={Springer}
}

@inproceedings{guo2019spottune,
  title={Spottune: transfer learning through adaptive fine-tuning},
  author={Guo, Yunhui and Shi, Honghui and Kumar, Abhishek and Grauman, Kristen and Rosing, Tajana and Feris, Rogerio},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4805--4814},
  year={2019}
}

@inproceedings{xuhong2018explicit,
  title={Explicit inductive bias for transfer learning with convolutional networks},
  author={Xuhong, LI and Grandvalet, Yves and Davoine, Franck},
  booktitle={International Conference on Machine Learning},
  pages={2825--2834},
  year={2018},
  organization={PMLR}
}

@inproceedings{li2020rifle,
  title={RIFLE: Backpropagation in Depth for Deep Transfer Learning through Re-Initializing the Fully-connected LayEr},
  author={Li, Xingjian and Xiong, Haoyi and An, Haozhe and Xu, Cheng-Zhong and Dou, Dejing},
  booktitle={International Conference on Machine Learning},
  pages={6010--6019},
  year={2020},
  organization={PMLR}
}

@inproceedings{shu2021zoo,
  title={Zoo-tuning: Adaptive transfer from a zoo of models},
  author={Shu, Yang and Kou, Zhi and Cao, Zhangjie and Wang, Jianmin and Long, Mingsheng},
  booktitle={International Conference on Machine Learning},
  pages={9626--9637},
  year={2021},
  organization={PMLR}
}

@article{dai2021coatnet,
  title={{CoAtNet}: Marrying convolution and attention for all data sizes},
  author={Dai, Zihang and Liu, Hanxiao and Le, Quoc and Tan, Mingxing},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{beyer2020we,
  title={Are we done with imagenet?},
  author={Beyer, Lucas and H{\'e}naff, Olivier J and Kolesnikov, Alexander and Zhai, Xiaohua and Oord, A{\"a}ron van den},
  journal={arXiv preprint arXiv:2006.07159},
  year={2020}
}

@inproceedings{shazeer2018adafactor,
  title={Adafactor: Adaptive learning rates with sublinear memory cost},
  author={Shazeer, Noam and Stern, Mitchell},
  booktitle={International Conference on Machine Learning},
  pages={4596--4604},
  year={2018},
  organization={PMLR}
}

@article{bagherinezhad2018label,
  title={Label refinery: Improving imagenet classification through label progression},
  author={Bagherinezhad, Hessam and Horton, Maxwell and Rastegari, Mohammad and Farhadi, Ali},
  journal={arXiv preprint arXiv:1805.02641},
  year={2018}
}


@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@software{djolonga2020robustness,
  author = {Josip Djolonga and Frances Hubis and Matthias Minderer and Zachary Nado and Jeremy Nixon and Rob Romijnders and Dustin Tran and Mario Lucic},
  title = {{R}obustness {M}etrics},
  url = {https://github.com/google-research/robustness_metrics},
  version = {0.0.1},
  year = {2020},
}

@inproceedings{yun2019cutmix,
  title={Cutmix: Regularization strategy to train strong classifiers with localizable features},
  author={Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={6023--6032},
  year={2019}
}

@article{kaddour2022questions,
  title={Questions for Flat-Minima Optimization of Modern Neural Networks},
  author={Kaddour, Jean and Liu, Linqing and Silva, Ricardo and Kusner, Matt J},
  journal={arXiv preprint arXiv:2202.00661},
  year={2022}
}

@article{von2020neural,
  title={Neural networks with late-phase weights},
  author={Von Oswald, Johannes and Kobayashi, Seijin and Sacramento, Joao and Meulemans, Alexander and Henning, Christian and Grewe, Benjamin F},
  journal={arXiv preprint arXiv:2007.12927},
  year={2020}
}

@article{dettmers2022llm,
  title={Llm. int8 (): 8-bit matrix multiplication for transformers at scale},
  author={Dettmers, Tim and Lewis, Mike and Belkada, Younes and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2208.07339},
  year={2022}
}

@article{micikevicius2017mixed,
  title={Mixed precision training},
  author={Micikevicius, Paulius and Narang, Sharan and Alben, Jonah and Diamos, Gregory and Elsen, Erich and Garcia, David and Ginsburg, Boris and Houston, Michael and Kuchaiev, Oleksii and Venkatesh, Ganesh and others},
  journal={arXiv preprint arXiv:1710.03740},
  year={2017}
}

@article{blake2023unit,
  title={Unit Scaling: Out-of-the-Box Low-Precision Training},
  author={Blake, Charlie and Orr, Douglas and Luschi, Carlo},
  journal={arXiv preprint arXiv:2303.11257},
  year={2023}
}


@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{cherti2022reproducible,
  title={Reproducible scaling laws for contrastive language-image learning},
  author={Cherti, Mehdi and Beaumont, Romain and Wightman, Ross and Wortsman, Mitchell and Ilharco, Gabriel and Gordon, Cade and Schuhmann, Christoph and Schmidt, Ludwig and Jitsev, Jenia},
  journal={arXiv preprint arXiv:2212.07143},
  year={2022}
}

@article{micikevicius2022fp8,
  title={FP8 formats for deep learning},
  author={Micikevicius, Paulius and Stosic, Dusan and Burgess, Neil and Cornea, Marius and Dubey, Pradeep and Grisenthwaite, Richard and Ha, Sangwon and Heinecke, Alexander and Judd, Patrick and Kamalu, John and others},
  journal={arXiv preprint arXiv:2209.05433},
  year={2022}
}

@inproceedings{tillet2019triton,
  title={Triton: an intermediate language and compiler for tiled neural network computations},
  author={Tillet, Philippe and Kung, Hsiang-Tsung and Cox, David},
  booktitle={Proceedings of the 3rd ACM SIGPLAN International Workshop on Machine Learning and Programming Languages},
  pages={10--19},
  year={2019}
}

@article{schuhmann2022laion,
  title={Laion-5b: An open large-scale dataset for training next generation image-text models},
  author={Schuhmann, Christoph and Beaumont, Romain and Vencu, Richard and Gordon, Cade and Wightman, Ross and Cherti, Mehdi and Coombes, Theo and Katta, Aarush and Mullis, Clayton and Wortsman, Mitchell and others},
  journal={arXiv preprint arXiv:2210.08402},
  year={2022}
}

@inproceedings{gupta2015deep,
  title={Deep learning with limited numerical precision},
  author={Gupta, Suyog and Agrawal, Ankur and Gopalakrishnan, Kailash and Narayanan, Pritish},
  booktitle={International conference on machine learning},
  pages={1737--1746},
  year={2015},
  organization={PMLR}
}

@article{courbariaux2014training,
  title={Training deep neural networks with low precision multiplications},
  author={Courbariaux, Matthieu and Bengio, Yoshua and David, Jean-Pierre},
  journal={arXiv preprint arXiv:1412.7024},
  year={2014}
}


@article{wang2019bfloat16,
  title={BFloat16: The secret to high performance on Cloud TPUs},
  author={Wang, Shibo and Kanwar, Pankaj},
  year={2019},
  note={\url{https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus}}
}


@article{zhang2022opt,
  title={Opt: Open pre-trained transformer language models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}


@misc{optvideo,
  title={Open Pretrained Transformers lecture},
  author={Zhang, Susan},
  journal={Stanford MLSys Lectures},
  year={2023},
  note={\url{https://www.youtube.com/watch?v=p9IxoSkvZ-M}}
}

@inproceedings{zhu2020towards,
  title={Towards unified int8 training for convolutional neural network},
  author={Zhu, Feng and Gong, Ruihao and Yu, Fengwei and Liu, Xianglong and Wang, Yanfei and Li, Zhelong and Yang, Xiuqi and Yan, Junjie},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={1969--1979},
  year={2020}
}

@article{xiao2022smoothquant,
  title={Smoothquant: Accurate and efficient post-training quantization for large language models},
  author={Xiao, Guangxuan and Lin, Ji and Seznec, Mickael and Demouth, Julien and Han, Song},
  journal={arXiv preprint arXiv:2211.10438},
  year={2022}
}

@article{dettmers2022case,
  title={The case for 4-bit precision: k-bit Inference Scaling Laws},
  author={Dettmers, Tim and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2212.09720},
  year={2022}
}

@inproceedings{NEURIPS2018_335d3d1c,
 author = {Wang, Naigang and Choi, Jungwook and Brand, Daniel and Chen, Chia-Yu and Gopalakrishnan, Kailash},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Training Deep Neural Networks with 8-bit Floating Point Numbers},
 url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/335d3d1cd7ef05ec77714a215134914c-Paper.pdf},
 volume = {31},
 year = {2018}
}

@article{dettmers2022optimizers,
  title={8-bit Optimizers via Block-wise Quantization},
  author={Dettmers, Tim and Lewis, Mike and Shleifer, Sam and Zettlemoyer, Luke},
  journal={9th International Conference on Learning Representations, ICLR},
  year={2022}
}

@software{openclip,
  author       = {Ilharco, Gabriel and
                  Wortsman, Mitchell and
                  Wightman, Ross and
                  Gordon, Cade and
                  Carlini, Nicholas and
                  Taori, Rohan and
                  Dave, Achal and
                  Shankar, Vaishaal and
                  Namkoong, Hongseok and
                  Miller, John and
                  Hajishirzi, Hannaneh and
                  Farhadi, Ali and
                  Schmidt, Ludwig},
  title        = {OpenCLIP},
  month        = jul,
  year         = 2021,
  note         = {If you use this software, please cite it as below.},
  publisher    = {Zenodo},
  version      = {0.1},
  doi          = {10.5281/zenodo.5143773},
  url          = {https://doi.org/10.5281/zenodo.5143773}
}

@article{dehghani2023scaling,
  title={Scaling vision transformers to 22 billion parameters},
  author={Dehghani, Mostafa and Djolonga, Josip and Mustafa, Basil and Padlewski, Piotr and Heek, Jonathan and Gilmer, Justin and Steiner, Andreas and Caron, Mathilde and Geirhos, Robert and Alabdulmohsin, Ibrahim and others},
  journal={arXiv preprint arXiv:2302.05442},
  year={2023}
}

@inproceedings{touvron2021going,
  title={Going deeper with image transformers},
  author={Touvron, Hugo and Cord, Matthieu and Sablayrolles, Alexandre and Synnaeve, Gabriel and J{\'e}gou, Herv{\'e}},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={32--42},
  year={2021}
}

@inproceedings{bachlechner2021rezero,
  title={Rezero is all you need: Fast convergence at large depth},
  author={Bachlechner, Thomas and Majumder, Bodhisattwa Prasad and Mao, Henry and Cottrell, Gary and McAuley, Julian},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={1352--1361},
  year={2021},
  organization={PMLR}
}

@article{zhang2019fixup,
  title={Fixup initialization: Residual learning without normalization},
  author={Zhang, Hongyi and Dauphin, Yann N and Ma, Tengyu},
  journal={arXiv preprint arXiv:1901.09321},
  year={2019}
}

@inproceedings{brock2021high,
  title={High-performance large-scale image recognition without normalization},
  author={Brock, Andy and De, Soham and Smith, Samuel L and Simonyan, Karen},
  booktitle={International Conference on Machine Learning},
  pages={1059--1071},
  year={2021},
  organization={PMLR}
}

@article{dinan2023effective,
  title={Effective Theory of Transformers at Initialization},
  author={Dinan, Emily and Yaida, Sho and Zhang, Susan},
  journal={arXiv preprint arXiv:2304.02034},
  year={2023}
}

@inproceedings{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1026--1034},
  year={2015}
}

@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={249--256},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

@inproceedings{chen2021empirical,
  title={An empirical study of training self-supervised vision transformers},
  author={Chen, Xinlei and Xie, Saining and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9640--9649},
  year={2021}
}

@misc{gilmerspikes,
    title={Intriguing Properties of Transformer Training Instabilities},
    author={Gilmer, Justin and Schioppa, Andrea and Cohen, Jeremy},
    note={To appear.}
}

@article{zhai2023stabilizing,
  title={Stabilizing Transformer Training by Preventing Attention Entropy Collapse},
  author={Zhai, Shuangfei and Likhomanenko, Tatiana and Littwin, Etai and Busbridge, Dan and Ramapuram, Jason and Zhang, Yizhe and Gu, Jiatao and Susskind, Josh},
  journal={arXiv preprint arXiv:2303.06296},
  year={2023}
}

@article{zhai2023sigmoid,
  title={Sigmoid Loss for Language Image Pre-Training},
  author={Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},
  journal={arXiv preprint arXiv:2303.15343},
  year={2023}
}


@article{molybog2023theory,
  title={A theory on adam instability in large-scale machine learning},
  author={Molybog, Igor and Albert, Peter and Chen, Moya and DeVito, Zachary and Esiobu, David and Goyal, Naman and Koura, Punit Singh and Narang, Sharan and Poulton, Andrew and Silva, Ruan and others},
  journal={arXiv preprint arXiv:2304.09871},
  year={2023}
}

@article{cohen2022adaptive,
  title={Adaptive gradient methods at the edge of stability},
  author={Cohen, Jeremy M and Ghorbani, Behrooz and Krishnan, Shankar and Agarwal, Naman and Medapati, Sourabh and Badura, Michal and Suo, Daniel and Cardoze, David and Nado, Zachary and Dahl, George E and others},
  journal={arXiv preprint arXiv:2207.14484},
  year={2022}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{duchi2011adaptive,
  title={Adaptive subgradient methods for online learning and stochastic optimization.},
  author={Duchi, John and Hazan, Elad and Singer, Yoram},
  journal={Journal of machine learning research},
  volume={12},
  number={7},
  year={2011}
}

@article{reddi2019convergence,
  title={On the convergence of adam and beyond},
  author={Reddi, Sashank J and Kale, Satyen and Kumar, Sanjiv},
  journal={arXiv preprint arXiv:1904.09237},
  year={2019}
}


@misc{giantclip,
  title={Reaching 80\% Accuracy with OpenCLIP},
  author={Mitchell Wortsman},
  note={\url{https://laion.ai/blog/giant-openclip/}},
  year={2023}
}

@article{cho2021dkm,
  title={Dkm: Differentiable k-means clustering layer for neural network compression},
  author={Cho, Minsik and Vahid, Keivan A and Adya, Saurabh and Rastegari, Mohammad},
  journal={arXiv preprint arXiv:2108.12659},
  year={2021}
}

@article{kumar2023dual,
  title={Dual PatchNorm},
  author={Kumar, Manoj and Dehghani, Mostafa and Houlsby, Neil},
  journal={arXiv preprint arXiv:2302.01327},
  year={2023}
}

@article{li2022scaling,
  title={Scaling Language-Image Pre-training via Masking},
  author={Li, Yanghao and Fan, Haoqi and Hu, Ronghang and Feichtenhofer, Christoph and He, Kaiming},
  journal={arXiv preprint arXiv:2212.00794},
  year={2022}
}

@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10684--10695},
  year={2022}
}

@inproceedings{wortsman2022model,
  title={Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Gadre, Samir Ya and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Morcos, Ari S and Namkoong, Hongseok and Farhadi, Ali and Carmon, Yair and Kornblith, Simon and others},
  booktitle={International Conference on Machine Learning},
  pages={23965--23998},
  year={2022},
  organization={PMLR}
}

@article{chen2023symbolic,
  title={Symbolic discovery of optimization algorithms},
  author={Chen, Xiangning and Liang, Chen and Huang, Da and Real, Esteban and Wang, Kaiyuan and Liu, Yao and Pham, Hieu and Dong, Xuanyi and Luong, Thang and Hsieh, Cho-Jui and others},
  journal={arXiv preprint arXiv:2302.06675},
  year={2023}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}



@article{park2022nuqmm,
  title={nuQmm: Quantized MatMul for Efficient Inference of Large-Scale Generative Language Models},
  author={Park, Gunho and Park, Baeseong and Kwon, Se Jung and Kim, Byeongwook and Lee, Youngjoo and Lee, Dongsoo},
  journal={arXiv preprint arXiv:2206.09557},
  year={2022}
}

@article{yao2022zeroquant,
  title={ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers},
  author={Yao, Zhewei and Aminabadi, Reza Yazdani and Zhang, Minjia and Wu, Xiaoxia and Li, Conglong and He, Yuxiong},
  journal={arXiv preprint arXiv:2206.01861},
  year={2022}
}

@article{bondarenko2021understanding,
  title={Understanding and overcoming the challenges of efficient transformer quantization},
  author={Bondarenko, Yelysei and Nagel, Markus and Blankevoort, Tijmen},
  journal={arXiv preprint arXiv:2109.12948},
  year={2021}
}

@article{zhao2021automatic,
  title={Automatic Mixed-Precision Quantization Search of BERT},
  author={Zhao, Changsheng and Hua, Ting and Shen, Yilin and Lou, Qian and Jin, Hongxia},
  journal={arXiv preprint arXiv:2112.14938},
  year={2021}
}

@inproceedings{yao2021hawq,
  title={Hawq-v3: Dyadic neural network quantization},
  author={Yao, Zhewei and Dong, Zhen and Zheng, Zhangcheng and Gholami, Amir and Yu, Jiali and Tan, Eric and Wang, Leyuan and Huang, Qijing and Wang, Yida and Mahoney, Michael and others},
  booktitle={International Conference on Machine Learning},
  pages={11875--11886},
  year={2021},
  organization={PMLR}
}



@article{wu2020integer,
  title={Integer quantization for deep learning inference: Principles and empirical evaluation},
  author={Wu, Hao and Judd, Patrick and Zhang, Xiaojie and Isaev, Mikhail and Micikevicius, Paulius},
  journal={arXiv preprint arXiv:2004.09602},
  year={2020}
}


@inproceedings{dong2019hawq,
  title={Hawq: Hessian aware quantization of neural networks with mixed-precision},
  author={Dong, Zhen and Yao, Zhewei and Gholami, Amir and Mahoney, Michael W and Keutzer, Kurt},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={293--302},
  year={2019}
}

@inproceedings{cai2020zeroq,
  title={Zeroq: A novel zero shot quantization framework},
  author={Cai, Yaohui and Yao, Zhewei and Dong, Zhen and Gholami, Amir and Mahoney, Michael W and Keutzer, Kurt},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13169--13178},
  year={2020}
}

@inproceedings{gong2019differentiable,
  title={Differentiable soft quantization: Bridging full-precision and low-bit neural networks},
  author={Gong, Ruihao and Liu, Xianglong and Jiang, Shenghu and Li, Tianxiang and Hu, Peng and Lin, Jiazhen and Yu, Fengwei and Yan, Junjie},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4852--4861},
  year={2019}
}

@inproceedings{zhang2018lq,
  title={Lq-nets: Learned quantization for highly accurate and compact deep neural networks},
  author={Zhang, Dongqing and Yang, Jiaolong and Ye, Dongqiangzi and Hua, Gang},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={365--382},
  year={2018}
}

@inproceedings{shen2020q,
  title={Q-bert: Hessian based ultra low precision quantization of bert},
  author={Shen, Sheng and Dong, Zhen and Ye, Jiayu and Ma, Linjian and Yao, Zhewei and Gholami, Amir and Mahoney, Michael W and Keutzer, Kurt},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={05},
  pages={8815--8821},
  year={2020}
}

@article{jacob2017quantization,
  title={Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference. arXiv e-prints, art},
  author={Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
  journal={arXiv preprint arXiv:1712.05877},
  year={2017}
}

@inproceedings{zhao2021distribution,
  title={Distribution adaptive int8 quantization for training cnns},
  author={Zhao, Kang and Huang, Sida and Pan, Pan and Li, Yinghan and Zhang, Yingya and Gu, Zhenyu and Xu, Yinghui},
  booktitle={Proceedings of the Thirty-Fifth AAAI Conference on Artificial Intelligence},
  year={2021}
}


@inproceedings{gong2019softquant,
  author    = {Ruihao Gong and
               Xianglong Liu and
               Shenghu Jiang and
               Tianxiang Li and
               Peng Hu and
               Jiazhen Lin and
               Fengwei Yu and
               Junjie Yan},
  title     = {Differentiable Soft Quantization: Bridging Full-Precision and Low-Bit
               Neural Networks},
  booktitle = {2019 {IEEE/CVF} International Conference on Computer Vision, {ICCV}
               2019, Seoul, Korea (South), October 27 - November 2, 2019},
  pages     = {4851--4860},
  publisher = {{IEEE}},
  year      = {2019},
  url       = {https://doi.org/10.1109/ICCV.2019.00495},
  doi       = {10.1109/ICCV.2019.00495},
  timestamp = {Thu, 05 Mar 2020 13:43:22 +0100},
  biburl    = {https://dblp.org/rec/conf/iccv/GongLJLHLYY19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{choi2019bit2,
  author    = {Jungwook Choi and
               Swagath Venkataramani and
               Vijayalakshmi Srinivasan and
               Kailash Gopalakrishnan and
               Zhuo Wang and
               Pierce Chuang},
  editor    = {Ameet Talwalkar and
               Virginia Smith and
               Matei Zaharia},
  title     = {Accurate and Efficient 2-bit Quantized Neural Networks},
  booktitle = {Proceedings of Machine Learning and Systems 2019, MLSys 2019, Stanford,
               CA, USA, March 31 - April 2, 2019},
  publisher = {mlsys.org},
  year      = {2019},
  url       = {https://proceedings.mlsys.org/book/268.pdf},
  timestamp = {Thu, 18 Jun 2020 15:48:01 +0200},
  biburl    = {https://dblp.org/rec/conf/mlsys/ChoiVSGWC19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{mellempudi2019bit8,
  author    = {Naveen Mellempudi and
               Sudarshan Srinivasan and
               Dipankar Das and
               Bharat Kaul},
  title     = {Mixed Precision Training With 8-bit Floating Point},
  journal   = {CoRR},
  volume    = {abs/1905.12334},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.12334},
  eprinttype = {arXiv},
  eprint    = {1905.12334},
  timestamp = {Mon, 03 Jun 2019 13:42:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-12334.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}}

@article{qin2020survey1bit,
  author    = {Haotong Qin and
               Ruihao Gong and
               Xianglong Liu and
               Xiao Bai and
               Jingkuan Song and
               Nicu Sebe},
  title     = {Binary Neural Networks: {A} Survey},
  journal   = {CoRR},
  volume    = {abs/2004.03333},
  year      = {2020},
  url       = {https://arxiv.org/abs/2004.03333},
  eprinttype = {arXiv},
  eprint    = {2004.03333},
  timestamp = {Wed, 08 Apr 2020 17:08:25 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2004-03333.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{courbariaux2014training,
  title={Training deep neural networks with low precision multiplications},
  author={Courbariaux, Matthieu and Bengio, Yoshua and David, Jean-Pierre},
  journal={arXiv preprint arXiv:1412.7024},
  year={2014}
}

@article{fan2020training,
  title={Training with quantization noise for extreme model compression},
  author={Fan, Angela and Stock, Pierre and Graham, Benjamin and Grave, Edouard and Gribonval, R{\'e}mi and Jegou, Herve and Joulin, Armand},
  journal={arXiv preprint arXiv:2004.07320},
  year={2020}
}

@article{jin2022f8net,
  title={F8Net: Fixed-Point 8-bit Only Multiplication for Network Quantization},
  author={Jin, Qing and Ren, Jian and Zhuang, Richard and Hanumante, Sumant and Li, Zhengang and Chen, Zhiyu and Wang, Yanzhi and Yang, Kaiyuan and Tulyakov, Sergey},
  journal={arXiv preprint arXiv:2202.05239},
  year={2022}
}

@inproceedings{Zhang2020TernaryBERTDU,
  title={TernaryBERT: Distillation-aware Ultra-low Bit BERT},
  author={Wei Zhang and Lu Hou and Yichun Yin and Lifeng Shang and Xiao Chen and Xin Jiang and Qun Liu},
  booktitle={EMNLP},
  year={2020}
}


@article{Bai2021BinaryBERTPT,
  title={BinaryBERT: Pushing the Limit of BERT Quantization},
  author={Haoli Bai and Wei Zhang and Lu Hou and Lifeng Shang and Jing Jin and Xin Jiang and Qun Liu and Michael R. Lyu and Irwin King},
  journal={ArXiv},
  year={2021},
  volume={abs/2012.15701}
}


@inproceedings{Rastegari2016xnor,
  author    = {Mohammad Rastegari and
               Vicente Ordonez and
               Joseph Redmon and
               Ali Farhadi},
  editor    = {Bastian Leibe and
               Jiri Matas and
               Nicu Sebe and
               Max Welling},
  title     = {XNOR-Net: ImageNet Classification Using Binary Convolutional Neural
               Networks},
  booktitle = {Computer Vision - {ECCV} 2016 - 14th European Conference, Amsterdam,
               The Netherlands, October 11-14, 2016, Proceedings, Part {IV}},
  series    = {Lecture Notes in Computer Science},
  volume    = {9908},
  pages     = {525--542},
  publisher = {Springer},
  year      = {2016},
  url       = {https://doi.org/10.1007/978-3-319-46493-0\_32},
  doi       = {10.1007/978-3-319-46493-0\_32},
  timestamp = {Wed, 25 Sep 2019 18:11:12 +0200},
  biburl    = {https://dblp.org/rec/conf/eccv/RastegariORF16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{courbariaux2015binaryconnect,
  author    = {Matthieu Courbariaux and
               Yoshua Bengio and
               Jean{-}Pierre David},
  editor    = {Corinna Cortes and
               Neil D. Lawrence and
               Daniel D. Lee and
               Masashi Sugiyama and
               Roman Garnett},
  title     = {BinaryConnect: Training Deep Neural Networks with binary weights during
               propagations},
  booktitle = {Advances in Neural Information Processing Systems 28: Annual Conference
               on Neural Information Processing Systems 2015, December 7-12, 2015,
               Montreal, Quebec, Canada},
  pages     = {3123--3131},
  year      = {2015},
  url       = {https://proceedings.neurips.cc/paper/2015/hash/3e15cc11f979ed25912dff5b0669f2cd-Abstract.html},
  timestamp = {Thu, 21 Jan 2021 15:15:22 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/CourbariauxBD15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{courbariaux2016bit1,
  author    = {Matthieu Courbariaux and
               Yoshua Bengio},
  title     = {BinaryNet: Training Deep Neural Networks with Weights and Activations
               Constrained to +1 or -1},
  journal   = {CoRR},
  volume    = {abs/1602.02830},
  year      = {2016},
  url       = {http://arxiv.org/abs/1602.02830},
  eprinttype = {arXiv},
  eprint    = {1602.02830},
  timestamp = {Mon, 13 Aug 2018 16:46:57 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/CourbariauxB16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{wang2018training8bit,
  author    = {Naigang Wang and
               Jungwook Choi and
               Daniel Brand and
               Chia{-}Yu Chen and
               Kailash Gopalakrishnan},
  editor    = {Samy Bengio and
               Hanna M. Wallach and
               Hugo Larochelle and
               Kristen Grauman and
               Nicol{\`{o}} Cesa{-}Bianchi and
               Roman Garnett},
  title     = {Training Deep Neural Networks with 8-bit Floating Point Numbers},
  booktitle = {Advances in Neural Information Processing Systems 31: Annual Conference
               on Neural Information Processing Systems 2018, NeurIPS 2018, December
               3-8, 2018, Montr{\'{e}}al, Canada},
  pages     = {7686--7695},
  year      = {2018},
  url       = {https://proceedings.neurips.cc/paper/2018/hash/335d3d1cd7ef05ec77714a215134914c-Abstract.html},
  timestamp = {Thu, 21 Jan 2021 15:15:21 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/WangCBCG18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{sun2019hybrid8bit,
  author    = {Xiao Sun and
               Jungwook Choi and
               Chia{-}Yu Chen and
               Naigang Wang and
               Swagath Venkataramani and
               Vijayalakshmi Srinivasan and
               Xiaodong Cui and
               Wei Zhang and
               Kailash Gopalakrishnan},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {Hybrid 8-bit Floating Point {(HFP8)} Training and Inference for Deep
               Neural Networks},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, December
               8-14, 2019, Vancouver, BC, Canada},
  pages     = {4901--4910},
  year      = {2019},
  url       = {https://proceedings.neurips.cc/paper/2019/hash/65fc9fb4897a89789352e211ca2d398f-Abstract.html},
  timestamp = {Thu, 21 Jan 2021 15:15:19 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/SunCCWVSCZG19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{cambier2020shiftsqueeze,
  author    = {L{\'{e}}opold Cambier and
               Anahita Bhiwandiwalla and
               Ting Gong and
               Oguz H. Elibol and
               Mehran Nekuii and
               Hanlin Tang},
  title     = {Shifted and Squeezed 8-bit Floating Point format for Low-Precision
               Training of Deep Neural Networks},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher = {OpenReview.net},
  year      = {2020},
  url       = {https://openreview.net/forum?id=Bkxe2AVtPS},
  timestamp = {Thu, 07 May 2020 17:11:47 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/CambierBGENT20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{drumond2018hybridblock,
  author    = {Mario Drumond and
               Tao Lin and
               Martin Jaggi and
               Babak Falsafi},
  editor    = {Samy Bengio and
               Hanna M. Wallach and
               Hugo Larochelle and
               Kristen Grauman and
               Nicol{\`{o}} Cesa{-}Bianchi and
               Roman Garnett},
  title     = {Training DNNs with Hybrid Block Floating Point},
  booktitle = {Advances in Neural Information Processing Systems 31: Annual Conference
               on Neural Information Processing Systems 2018, NeurIPS 2018, December
               3-8, 2018, Montr{\'{e}}al, Canada},
  pages     = {451--461},
  year      = {2018},
  url       = {https://proceedings.neurips.cc/paper/2018/hash/6a9aeddfc689c1d0e3b9ccc3ab651bc5-Abstract.html},
  timestamp = {Tue, 01 Jun 2021 10:12:08 +0200},
  biburl    = {https://dblp.org/rec/conf/nips/DrumondLJF18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{zhu2017ternary,
  author    = {Chenzhuo Zhu and
               Song Han and
               Huizi Mao and
               William J. Dally},
  title     = {Trained Ternary Quantization},
  booktitle = {5th International Conference on Learning Representations, {ICLR} 2017,
               Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2017},
  url       = {https://openreview.net/forum?id=S1\_pAu9xl},
  timestamp = {Fri, 20 Nov 2020 16:16:07 +0100},
  biburl    = {https://dblp.org/rec/conf/iclr/ZhuHMD17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{li2019bit4,
  author    = {Rundong Li and
               Yan Wang and
               Feng Liang and
               Hongwei Qin and
               Junjie Yan and
               Rui Fan},
  title     = {Fully Quantized Network for Object Detection},
  booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR}
               2019, Long Beach, CA, USA, June 16-20, 2019},
  pages     = {2810--2819},
  publisher = {Computer Vision Foundation / {IEEE}},
  year      = {2019},
  url       = {http://openaccess.thecvf.com/content\_CVPR\_2019/html/Li\_Fully\_Quantized\_Network\_for\_Object\_Detection\_CVPR\_2019\_paper.html},
  doi       = {10.1109/CVPR.2019.00292},
  timestamp = {Mon, 30 Aug 2021 17:01:14 +0200},
  biburl    = {https://dblp.org/rec/conf/cvpr/LiWLQYF19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{kim2021bert,
  title={I-bert: Integer-only bert quantization},
  author={Kim, Sehoon and Gholami, Amir and Yao, Zhewei and Mahoney, Michael W and Keutzer, Kurt},
  booktitle={International conference on machine learning},
  pages={5506--5518},
  year={2021},
  organization={PMLR}
}

@article{frantar2022gptq,
  title={GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers},
  author={Frantar, Elias and Ashkboos, Saleh and Hoefler, Torsten and Alistarh, Dan},
  journal={arXiv preprint arXiv:2210.17323},
  year={2022}
}

@article{rae2021scaling,
  title={Scaling language models: Methods, analysis \& insights from training gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
  journal={arXiv preprint arXiv:2112.11446},
  year={2021}
}

@article{zeng2022glm,
  title={Glm-130b: An open bilingual pre-trained model},
  author={Zeng, Aohan and Liu, Xiao and Du, Zhengxiao and Wang, Zihan and Lai, Hanyu and Ding, Ming and Yang, Zhuoyi and Xu, Yifan and Zheng, Wendi and Xia, Xiao and others},
  journal={arXiv preprint arXiv:2210.02414},
  year={2022}
}


@article{fbgemm,
  title={FBGEMM: Enabling High-Performance Low-Precision Deep Learning Inference},
  author={Khudia, Daya and Huang, Jianyu and Basu, Protonu and Deng, Summer and Liu, Haixin and Park, Jongsoo and Smelyanskiy, Mikhail},
  journal={arXiv preprint arXiv:2101.05615},
  year={2021}
}