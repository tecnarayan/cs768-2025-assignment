\begin{thebibliography}{10}

\bibitem{ji2023ai}
Jiaming Ji, Tianyi Qiu, Boyuan Chen, Borong Zhang, Hantao Lou, Kaile Wang, Yawen Duan, Zhonghao He, Jiayi Zhou, Zhaowei Zhang, et~al.
\newblock Ai alignment: A comprehensive survey.
\newblock {\em arXiv preprint arXiv:2310.19852}, 2023.

\bibitem{ouyang2022training}
Long Ouyang, Jeffrey Wu, Xu~Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et~al.
\newblock Training language models to follow instructions with human feedback.
\newblock {\em Advances in Neural Information Processing Systems}, 35:27730--27744, 2022.

\bibitem{taori2023stanford}
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori~B Hashimoto.
\newblock Stanford alpaca: An instruction-following llama model, 2023.

\bibitem{schulman2017proximal}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock {\em arXiv preprint arXiv:1707.06347}, 2017.

\bibitem{bai2022training}
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et~al.
\newblock Training a helpful and harmless assistant with reinforcement learning from human feedback.
\newblock {\em arXiv preprint arXiv:2204.05862}, 2022.

\bibitem{rafailov2023direct}
Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher~D Manning, Stefano Ermon, and Chelsea Finn.
\newblock Direct preference optimization: Your language model is secretly a reward model.
\newblock In {\em Thirty-seventh Conference on Neural Information Processing Systems}, 2023.

\bibitem{lu2023inference}
Ximing Lu, Faeze Brahman, Peter West, Jaehun Jung, Khyathi Chandu, Abhilasha Ravichander, Prithviraj Ammanabrolu, Liwei Jiang, Sahana Ramnath, Nouha Dziri, et~al.
\newblock Inference-time policy adapters (ipa): Tailoring extreme-scale lms without fine-tuning.
\newblock In {\em Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing}, pages 6863--6883, 2023.

\bibitem{cheng2023black}
Jiale Cheng, Xiao Liu, Kehan Zheng, Pei Ke, Hongning Wang, Yuxiao Dong, Jie Tang, and Minlie Huang.
\newblock Black-box prompt optimization: Aligning large language models without model training.
\newblock {\em arXiv preprint arXiv:2311.04155}, 2023.

\bibitem{yang2024rlcd}
Kevin Yang, Dan Klein, Asli Celikyilmaz, Nanyun Peng, and Yuandong Tian.
\newblock {RLCD}: Reinforcement learning from contrastive distillation for {LM} alignment.
\newblock In {\em The Twelfth International Conference on Learning Representations}, 2024.

\bibitem{askell2021general}
Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, Nicholas Joseph, Ben Mann, Nova DasSarma, et~al.
\newblock A general language assistant as a laboratory for alignment.
\newblock {\em arXiv preprint arXiv:2112.00861}, 2021.

\bibitem{yao2023deepspeed}
Zhewei Yao, Reza~Yazdani Aminabadi, Olatunji Ruwase, Samyam Rajbhandari, Xiaoxia Wu, Ammar~Ahmad Awan, Jeff Rasley, Minjia Zhang, Conglong Li, Connor Holmes, et~al.
\newblock Deepspeed-chat: Easy, fast and affordable rlhf training of chatgpt-like models at all scales.
\newblock {\em arXiv preprint arXiv:2308.01320}, 2023.

\bibitem{anwar2024foundational}
Usman Anwar, Abulhair Saparov, Javier Rando, Daniel Paleka, Miles Turpin, Peter Hase, Ekdeep~Singh Lubana, Erik Jenner, Stephen Casper, Oliver Sourbut, et~al.
\newblock Foundational challenges in assuring alignment and safety of large language models.
\newblock {\em arXiv preprint arXiv:2404.09932}, 2024.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 770--778, 2016.

\bibitem{zou2023representation}
Andy Zou, Long Phan, Sarah Chen, James Campbell, Phillip Guo, Richard Ren, Alexander Pan, Xuwang Yin, Mantas Mazeika, Ann-Kathrin Dombrowski, et~al.
\newblock Representation engineering: A top-down approach to ai transparency.
\newblock {\em arXiv preprint arXiv:2310.01405}, 2023.

\bibitem{subramani2022extracting}
Nishant Subramani, Nivedita Suresh, and Matthew~E Peters.
\newblock Extracting latent steering vectors from pretrained language models.
\newblock {\em arXiv preprint arXiv:2205.05124}, 2022.

\bibitem{yin2022interpreting}
Kayo Yin and Graham Neubig.
\newblock Interpreting language models with contrastive explanations.
\newblock In {\em Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing}, pages 184--198, 2022.

\bibitem{ji2024beavertails}
Jiaming Ji, Mickel Liu, Josef Dai, Xuehai Pan, Chi Zhang, Ce~Bian, Boyuan Chen, Ruiyang Sun, Yizhou Wang, and Yaodong Yang.
\newblock Beavertails: Towards improved safety alignment of llm via a human-preference dataset.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{ji2024pku}
Jiaming Ji, Donghai Hong, Borong Zhang, Boyuan Chen, Josef Dai, Boren Zheng, Tianyi Qiu, Boxun Li, and Yaodong Yang.
\newblock Pku-saferlhf: Towards multi-level safety alignment for llms with human preference.
\newblock {\em arXiv preprint arXiv:2406.15513}, 2024.

\bibitem{chiang2023vicuna}
Wei-Lin Chiang, Zhuohan Li, Zi~Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph~E Gonzalez, et~al.
\newblock Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality.
\newblock {\em See https://vicuna. lmsys. org (accessed 14 April 2023)}, 2023.

\bibitem{touvron2023llama}
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock {\em arXiv preprint arXiv:2307.09288}, 2023.

\bibitem{team2024gemma}
Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivi{\`e}re, Mihir~Sanjay Kale, Juliette Love, et~al.
\newblock Gemma: Open models based on gemini research and technology.
\newblock {\em arXiv preprint arXiv:2403.08295}, 2024.

\bibitem{rashkin2019towards}
Hannah Rashkin, Eric~Michael Smith, Margaret Li, and Y-Lan Boureau.
\newblock Towards empathetic open-domain conversation models: A new benchmark and dataset.
\newblock In {\em Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics}, pages 5370--5381, 2019.

\bibitem{chen2021dialogsum}
Yulong Chen, Yang Liu, Liang Chen, and Yue Zhang.
\newblock Dialogsum: A real-life scenario dialogue summarization dataset.
\newblock In {\em Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021}, pages 5062--5074, 2021.

\bibitem{bhardwaj2023red}
Rishabh Bhardwaj and Soujanya Poria.
\newblock Red-teaming large language models using chain of utterances for safety-alignment.
\newblock {\em arXiv preprint arXiv:2308.09662}, 2023.

\bibitem{lin2022truthfulqa}
Stephanie Lin, Jacob Hilton, and Owain Evans.
\newblock Truthfulqa: Measuring how models mimic human falsehoods.
\newblock In {\em Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 3214--3252, 2022.

\bibitem{openai2023gpt4}
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia~Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et~al.
\newblock Gpt-4 technical report.
\newblock {\em arXiv preprint arXiv:2303.08774}, 2023.

\bibitem{anthropic2023claude2}
Anthropic.
\newblock {Claude 2}.
\newblock \url{https://www.anthropic.com/news/claude-2}, 2023.

\bibitem{dai2024safe}
Josef Dai, Xuehai Pan, Ruiyang Sun, Jiaming Ji, Xinbo Xu, Mickel Liu, Yizhou Wang, and Yaodong Yang.
\newblock Safe rlhf: Safe reinforcement learning from human feedback.
\newblock In {\em The Twelfth International Conference on Learning Representations}, 2024.

\bibitem{kaplan2020scaling}
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom~B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.
\newblock Scaling laws for neural language models.
\newblock {\em arXiv preprint arXiv:2001.08361}, 2020.

\bibitem{bai2022constitutional}
Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, et~al.
\newblock Constitutional ai: Harmlessness from ai feedback.
\newblock {\em arXiv preprint arXiv:2212.08073}, 2022.

\bibitem{saunders2022self}
William Saunders, Catherine Yeh, Jeff Wu, Steven Bills, Long Ouyang, Jonathan Ward, and Jan Leike.
\newblock Self-critiquing models for assisting human evaluators.
\newblock {\em arXiv preprint arXiv:2206.05802}, 2022.

\bibitem{madaan2024self}
Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et~al.
\newblock Self-refine: Iterative refinement with self-feedback.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{cui2023ultrafeedback}
Ganqu Cui, Lifan Yuan, Ning Ding, Guanming Yao, Wei Zhu, Yuan Ni, Guotong Xie, Zhiyuan Liu, and Maosong Sun.
\newblock Ultrafeedback: Boosting language models with high-quality feedback, 2023.

\bibitem{turner2023activation}
Alex Turner, Lisa Thiergart, David Udell, Gavin Leech, Ulisse Mini, and Monte MacDiarmid.
\newblock Activation addition: Steering language models without optimization.
\newblock {\em arXiv preprint arXiv:2308.10248}, 2023.

\bibitem{li2024inference}
Kenneth Li, Oam Patel, Fernanda Vi{\'e}gas, Hanspeter Pfister, and Martin Wattenberg.
\newblock Inference-time intervention: Eliciting truthful answers from a language model.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{casper2023open}
Stephen Casper, Xander Davies, Claudia Shi, Thomas~Krendl Gilbert, J{\'e}r{\'e}my Scheurer, Javier Rando, Rachel Freedman, Tomasz Korbak, David Lindner, Pedro Freire, Tony~Tong Wang, Samuel Marks, Charbel-Raphael Segerie, Micah Carroll, Andi Peng, Phillip Christoffersen, Mehul Damani, Stewart Slocum, Usman Anwar, Anand Siththaranjan, Max Nadeau, Eric~J Michaud, Jacob Pfau, Dmitrii Krasheninnikov, Xin Chen, Lauro Langosco, Peter Hase, Erdem Biyik, Anca Dragan, David Krueger, Dorsa Sadigh, and Dylan Hadfield-Menell.
\newblock Open problems and fundamental limitations of reinforcement learning from human feedback.
\newblock {\em Transactions on Machine Learning Research}, 2023.
\newblock Survey Certification.

\bibitem{ziegler2019fine}
Daniel~M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom~B Brown, Alec Radford, Dario Amodei, Paul Christiano, and Geoffrey Irving.
\newblock Fine-tuning language models from human preferences.
\newblock {\em arXiv preprint arXiv:1909.08593}, 2019.

\bibitem{yuan2024rrhf}
Hongyi Yuan, Zheng Yuan, Chuanqi Tan, Wei Wang, Songfang Huang, and Fei Huang.
\newblock Rrhf: Rank responses to align language models with human feedback.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{gulcehre2023reinforced}
Caglar Gulcehre, Tom~Le Paine, Srivatsan Srinivasan, Ksenia Konyushkova, Lotte Weerts, Abhishek Sharma, Aditya Siddhant, Alex Ahern, Miaosen Wang, Chenjie Gu, et~al.
\newblock Reinforced self-training (rest) for language modeling.
\newblock {\em arXiv preprint arXiv:2308.08998}, 2023.

\bibitem{lee2023rlaif}
Harrison Lee, Samrat Phatale, Hassan Mansoor, Kellie Lu, Thomas Mesnard, Colton Bishop, Victor Carbune, and Abhinav Rastogi.
\newblock Rlaif: Scaling reinforcement learning from human feedback with ai feedback.
\newblock {\em arXiv preprint arXiv:2309.00267}, 2023.

\bibitem{Dathathri2020Plug}
Sumanth Dathathri, Andrea Madotto, Janice Lan, Jane Hung, Eric Frank, Piero Molino, Jason Yosinski, and Rosanne Liu.
\newblock Plug and play language models: A simple approach to controlled text generation.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{yang2021fudge}
Kevin Yang and Dan Klein.
\newblock Fudge: Controlled text generation with future discriminators.
\newblock In {\em Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies}, pages 3511--3535, 2021.

\bibitem{dong2022survey}
Qingxiu Dong, Lei Li, Damai Dai, Ce~Zheng, Zhiyong Wu, Baobao Chang, Xu~Sun, Jingjing Xu, and Zhifang Sui.
\newblock A survey on in-context learning.
\newblock {\em arXiv preprint arXiv:2301.00234}, 2022.

\bibitem{min2022rethinking}
Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer.
\newblock Rethinking the role of demonstrations: What makes in-context learning work?
\newblock {\em arXiv preprint arXiv:2202.12837}, 2022.

\bibitem{vernikos2023small}
Giorgos Vernikos, Arthur Bra{\v{z}}inskas, Jakub Adamek, Jonathan Mallinson, Aliaksei Severyn, and Eric Malmi.
\newblock Small language models improve giants by rewriting their outputs.
\newblock {\em arXiv preprint arXiv:2305.13514}, 2023.

\bibitem{jiang2023llm}
Dongfu Jiang, Xiang Ren, and Bill~Yuchen Lin.
\newblock Llm-blender: Ensembling large language models with pairwise ranking and generative fusion.
\newblock {\em arXiv preprint arXiv:2306.02561}, 2023.

\bibitem{zheng2024large}
Chujie Zheng, Hao Zhou, Fandong Meng, Jie Zhou, and Minlie Huang.
\newblock Large language models are not robust multiple choice selectors.
\newblock In {\em The Twelfth International Conference on Learning Representations}, 2024.

\bibitem{mita2020self}
Masato Mita, Shun Kiyono, Masahiro Kaneko, Jun Suzuki, and Kentaro Inui.
\newblock A self-refinement strategy for noise reduction in grammatical error correction.
\newblock In {\em Findings of the Association for Computational Linguistics: EMNLP 2020}, pages 267--280, 2020.

\bibitem{reid2022learning}
Machel Reid and Graham Neubig.
\newblock Learning to model editing processes.
\newblock In {\em Findings of the Association for Computational Linguistics: EMNLP 2022}, pages 3822--3832, 2022.

\bibitem{yang2023idea2img}
Zhengyuan Yang, Jianfeng Wang, Linjie Li, Kevin Lin, Chung-Ching Lin, Zicheng Liu, and Lijuan Wang.
\newblock Idea2img: Iterative self-refinement with gpt-4v (ision) for automatic image design and generation.
\newblock {\em arXiv preprint arXiv:2310.08541}, 2023.

\bibitem{chen2024teaching}
Xinyun Chen, Maxwell Lin, Nathanael Sch{\"a}rli, and Denny Zhou.
\newblock Teaching large language models to self-debug.
\newblock In {\em The Twelfth International Conference on Learning Representations}, 2024.

\bibitem{burns2023weak}
Collin Burns, Pavel Izmailov, Jan~Hendrik Kirchner, Bowen Baker, Leo Gao, Leopold Aschenbrenner, Yining Chen, Adrien Ecoffet, Manas Joglekar, Jan Leike, Ilya Sutskever, and Jeff Wu.
\newblock Weak-to-strong generalization: Eliciting strong capabilities with weak supervision.
\newblock {\em arXiv preprint arXiv:2312.09390}, 2023.

\bibitem{dubois2024length}
Yann Dubois, Bal{\'a}zs Galambosi, Percy Liang, and Tatsunori~B Hashimoto.
\newblock Length-controlled alpacaeval: A simple way to debias automatic evaluators.
\newblock {\em arXiv preprint arXiv:2404.04475}, 2024.

\bibitem{superalignment}
OpenAI.
\newblock Introducing superalignment.
\newblock \url{https://openai.com/blog/introducing-superalignment}, 2023.
\newblock Accessed on July 5, 2023.

\bibitem{amodei2016concrete}
Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, and Dan Man{\'e}.
\newblock Concrete problems in ai safety.
\newblock {\em arXiv preprint arXiv:1606.06565}, 2016.

\bibitem{chen2021evaluating}
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De~Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et~al.
\newblock Evaluating large language models trained on code.
\newblock {\em arXiv preprint arXiv:2107.03374}, 2021.

\bibitem{hendrycks2020measuring}
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.
\newblock Measuring massive multitask language understanding.
\newblock {\em arXiv preprint arXiv:2009.03300}, 2020.

\bibitem{hendrycks2021measuring}
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt.
\newblock Measuring mathematical problem solving with the math dataset.
\newblock {\em arXiv preprint arXiv:2103.03874}, 2021.

\bibitem{zheng2023judging}
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi~Lin, Zhuohan Li, Dacheng Li, Eric Xing, et~al.
\newblock Judging llm-as-a-judge with mt-bench and chatbot arena.
\newblock {\em Advances in Neural Information Processing Systems}, 36:46595--46623, 2023.

\bibitem{noauthor_undated-nz}
China: hourly minimum wage by region 2024.
\newblock \url{https://www.statista.com/statistics/233886/minimum-wage-per-hour-in-china-by-city-and-province/}.
\newblock Accessed: 2024-5-21.

\bibitem{levenshtein1966binary}
Vladimir~I Levenshtein et~al.
\newblock Binary codes capable of correcting deletions, insertions, and reversals.
\newblock In {\em Soviet physics doklady}, volume~10, pages 707--710. Soviet Union, 1966.

\bibitem{kwon2023efficient}
Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody~Hao Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica.
\newblock Efficient memory management for large language model serving with pagedattention.
\newblock In {\em Proceedings of the 29th Symposium on Operating Systems Principles}, pages 611--626, 2023.

\bibitem{ganguli2022red}
Deep Ganguli, Liane Lovitt, Jackson Kernion, Amanda Askell, Yuntao Bai, Saurav Kadavath, Ben Mann, Ethan Perez, Nicholas Schiefer, Kamal Ndousse, et~al.
\newblock Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned.
\newblock {\em arXiv preprint arXiv:2209.07858}, 2022.

\end{thebibliography}
