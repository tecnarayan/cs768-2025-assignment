\begin{thebibliography}{61}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal and Arora(2023)]{pixelformer}
Ashutosh Agarwal and Chetan Arora.
\newblock Attention attention everywhere: Monocular depth prediction with skip
  attention.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on
  Applications of Computer Vision}, pages 5861--5870, 2023.

\bibitem[Ahmed et~al.(1974)Ahmed, Natarajan, and Rao]{dct}
N. Ahmed, T. Natarajan, and K.R. Rao.
\newblock Discrete cosine transform.
\newblock \emph{IEEE Transactions on Computers}, C-23\penalty0 (1):\penalty0
  90--93, 1974.

\bibitem[Bhat et~al.(2021)Bhat, Alhashim, and Wonka]{adabins}
Shariq~Farooq Bhat, Ibraheem Alhashim, and Peter Wonka.
\newblock Adabins: Depth estimation using adaptive bins.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 4009--4018, 2021.

\bibitem[Bhat et~al.(2022)Bhat, Alhashim, and Wonka]{localbins}
Shariq~Farooq Bhat, Ibraheem Alhashim, and Peter Wonka.
\newblock Localbins: Improving depth estimation by learning local
  distributions.
\newblock In \emph{European Conference on Computer Vision}, pages 480--496.
  Springer, 2022.

\bibitem[Cao et~al.(2017)Cao, Wu, and Shen]{cao2017estimating}
Yuanzhouhan Cao, Zifeng Wu, and Chunhua Shen.
\newblock Estimating depth from monocular images as classification using deep
  fully convolutional residual networks.
\newblock \emph{IEEE Transactions on Circuits and Systems for Video
  Technology}, 28\penalty0 (11):\penalty0 3174--3182, 2017.

\bibitem[Chen et~al.(1977)Chen, Smith, and Fralick]{fast_dct}
Wen-Hsiung Chen, C. Smith, and S. Fralick.
\newblock A fast computational algorithm for the discrete cosine transform.
\newblock \emph{IEEE Transactions on Communications}, 25\penalty0 (9):\penalty0
  1004--1009, 1977.

\bibitem[Cho et~al.(2014)Cho, van Merri{\"e}nboer, Gulcehre, Bahdanau,
  Bougares, Schwenk, and Bengio]{gru}
Kyunghyun Cho, Bart van Merri{\"e}nboer, Caglar Gulcehre, Dzmitry Bahdanau,
  Fethi Bougares, Holger Schwenk, and Yoshua Bengio.
\newblock Learning phrase representations using {RNN} encoder{--}decoder for
  statistical machine translation.
\newblock In \emph{Proceedings of the 2014 Conference on Empirical Methods in
  Natural Language Processing ({EMNLP})}, pages 1724--1734, Doha, Qatar, 2014.
  Association for Computational Linguistics.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei]{imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee, 2009.

\bibitem[Dong et~al.(2022)Dong, Garratt, Anavatti, and Abbass]{depth_robotics}
Xingshuai Dong, Matthew~A. Garratt, Sreenatha~G. Anavatti, and Hussein~A.
  Abbass.
\newblock Towards real-time monocular depth estimation for robotics: A survey.
\newblock \emph{IEEE Transactions on Intelligent Transportation Systems},
  23\penalty0 (10):\penalty0 16940--16961, 2022.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, et~al.]{vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Eigen et~al.(2014)Eigen, Puhrsch, and Fergus]{eigen_depth}
David Eigen, Christian Puhrsch, and Rob Fergus.
\newblock Depth map prediction from a single image using a multi-scale deep
  network.
\newblock In \emph{Advances in Neural Information Processing Systems}. Curran
  Associates, Inc., 2014.

\bibitem[Fu et~al.(2018)Fu, Gong, Wang, Batmanghelich, and Tao]{fu2018deep}
Huan Fu, Mingming Gong, Chaohui Wang, Kayhan Batmanghelich, and Dacheng Tao.
\newblock Deep ordinal regression network for monocular depth estimation.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2002--2011, 2018.

\bibitem[Geiger et~al.(2012)Geiger, Lenz, and Urtasun]{kitti}
Andreas Geiger, Philip Lenz, and Raquel Urtasun.
\newblock Are we ready for autonomous driving? the kitti vision benchmark
  suite.
\newblock In \emph{2012 IEEE conference on computer vision and pattern
  recognition}, pages 3354--3361. IEEE, 2012.

\bibitem[Hao et~al.(2018)Hao, Li, You, and Lu]{hao2018detail}
Zhixiang Hao, Yu Li, Shaodi You, and Feng Lu.
\newblock Detail preserving depth estimation from a single image using
  attention guided networks.
\newblock In \emph{2018 International Conference on 3D Vision (3DV)}, pages
  304--313. IEEE, 2018.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{resnet}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem[Kingma and Ba(2014)]{adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Lee et~al.(2019)Lee, Han, Ko, and Suh]{bts}
Jin~Han Lee, Myung-Kyu Han, Dong~Wook Ko, and Il~Hong Suh.
\newblock From big to small: Multi-scale local planar guidance for monocular
  depth estimation.
\newblock \emph{arXiv preprint arXiv:1907.10326}, 2019.

\bibitem[Li et~al.(2023)Li, Zhang, Sun, Zou, Liu, Yang, Li, Zhang, and
  Gao]{semantic_sam}
Feng Li, Hao Zhang, Peize Sun, Xueyan Zou, Shilong Liu, Jianwei Yang, Chunyuan
  Li, Lei Zhang, and Jianfeng Gao.
\newblock Semantic-sam: Segment and recognize anything at any granularity.
\newblock \emph{arXiv preprint arXiv:2307.04767}, 2023.

\bibitem[Li and Snavely(2018)]{megadepth}
Zhengqi Li and Noah Snavely.
\newblock Megadepth: Learning single-view depth prediction from internet
  photos.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2041--2050, 2018.

\bibitem[Li et~al.(2024)Li, Wang, Liu, and Jiang]{binsformer}
Zhenyu Li, Xuyang Wang, Xianming Liu, and Junjun Jiang.
\newblock Binsformer: Revisiting adaptive bins for monocular depth estimation.
\newblock \emph{IEEE Transactions on Image Processing}, 33:\penalty0
  3964--3976, 2024.

\bibitem[Liu et~al.(2023{\natexlab{a}})Liu, Kumar, Gu, Timofte, and
  Van~Gool]{mgdepth}
Ce Liu, Suryansh Kumar, Shuhang Gu, Radu Timofte, and Luc Van~Gool.
\newblock Single image depth prediction made better: A multivariate gaussian
  take.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 17346--17356, 2023{\natexlab{a}}.

\bibitem[Liu et~al.(2023{\natexlab{b}})Liu, Kumar, Gu, Timofte, and
  Van~Gool]{vadepth}
Ce Liu, Suryansh Kumar, Shuhang Gu, Radu Timofte, and Luc Van~Gool.
\newblock Va-depthnet: A variational approach to single image depth prediction.
\newblock \emph{arXiv preprint arXiv:2302.06556}, 2023{\natexlab{b}}.

\bibitem[Liu et~al.(2021)Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and Guo]{swin}
Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 10012--10022, 2021.

\bibitem[Long et~al.(2021)Long, Lin, Liu, Li, Theobalt, Yang, and
  Wang]{asndepth}
Xiaoxiao Long, Cheng Lin, Lingjie Liu, Wei Li, Christian Theobalt, Ruigang
  Yang, and Wenping Wang.
\newblock Adaptive surface normal constraint for depth estimation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 12849--12858, 2021.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith
  Chintala.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In \emph{Advances in Neural Information Processing Systems}. Curran
  Associates, Inc., 2019.

\bibitem[Patil et~al.(2022)Patil, Sakaridis, Liniger, and Van~Gool]{p3depth}
Vaishakh Patil, Christos Sakaridis, Alexander Liniger, and Luc Van~Gool.
\newblock P3depth: Monocular depth estimation with a piecewise planarity prior.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 1610--1621, 2022.

\bibitem[Piccinelli et~al.(2023)Piccinelli, Sakaridis, and Yu]{idisc}
Luigi Piccinelli, Christos Sakaridis, and Fisher Yu.
\newblock idisc: Internal discretization for monocular depth estimation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 21477--21487, 2023.

\bibitem[Qi et~al.(2018)Qi, Liao, Liu, Urtasun, and Jia]{geonet}
Xiaojuan Qi, Renjie Liao, Zhengzhe Liu, Raquel Urtasun, and Jiaya Jia.
\newblock Geonet: Geometric neural network for joint depth and surface normal
  estimation.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 283--291, 2018.

\bibitem[Ramachandran et~al.(2017)Ramachandran, Zoph, and Le]{swish}
Prajit Ramachandran, Barret Zoph, and Quoc~V Le.
\newblock Searching for activation functions.
\newblock \emph{arXiv preprint arXiv:1710.05941}, 2017.

\bibitem[Ranftl et~al.(2021)Ranftl, Bochkovskiy, and Koltun]{dpt}
Ren{\'e} Ranftl, Alexey Bochkovskiy, and Vladlen Koltun.
\newblock Vision transformers for dense prediction.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 12179--12188, 2021.

\bibitem[Saxena et~al.(2005)Saxena, Chung, and Ng]{depth_mrf}
Ashutosh Saxena, Sung Chung, and Andrew Ng.
\newblock Learning depth from single monocular images.
\newblock In \emph{Advances in Neural Information Processing Systems}. MIT
  Press, 2005.

\bibitem[Saxena et~al.(2007)Saxena, Schulte, Ng, et~al.]{saxena2007depth}
Ashutosh Saxena, Jamie Schulte, Andrew~Y Ng, et~al.
\newblock Depth estimation using monocular and stereo cues.
\newblock In \emph{IJCAI}, pages 2197--2203, 2007.

\bibitem[Shao et~al.(2023{\natexlab{a}})Shao, Pei, Chen, Wu, and Li]{nddepth}
Shuwei Shao, Zhongcai Pei, Weihai Chen, Xingming Wu, and Zhengguo Li.
\newblock Nddepth: Normal-distance assisted monocular depth estimation.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 7931--7940, 2023{\natexlab{a}}.

\bibitem[Shao et~al.(2023{\natexlab{b}})Shao, Pei, Wu, Liu, Chen, and
  Li]{iebins}
Shuwei Shao, Zhongcai Pei, Xingming Wu, Zhong Liu, Weihai Chen, and Zhengguo
  Li.
\newblock Iebins: Iterative elastic bins for monocular depth estimation.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  53025--53037. Curran Associates, Inc., 2023{\natexlab{b}}.

\bibitem[Shi et~al.(2016)Shi, Caballero, Husz{\'a}r, Totz, Aitken, Bishop,
  Rueckert, and Wang]{pixelshuffle}
Wenzhe Shi, Jose Caballero, Ferenc Husz{\'a}r, Johannes Totz, Andrew~P Aitken,
  Rob Bishop, Daniel Rueckert, and Zehan Wang.
\newblock Real-time single image and video super-resolution using an efficient
  sub-pixel convolutional neural network.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1874--1883, 2016.

\bibitem[Silberman et~al.(2012)Silberman, Hoiem, Kohli, and Fergus]{nyu}
Nathan Silberman, Derek Hoiem, Pushmeet Kohli, and Rob Fergus.
\newblock Indoor segmentation and support inference from rgbd images.
\newblock In \emph{Computer Vision--ECCV 2012: 12th European Conference on
  Computer Vision, Florence, Italy, October 7-13, 2012, Proceedings, Part V
  12}, pages 746--760. Springer, 2012.

\bibitem[Smith and Topin(2019)]{onecycle}
Leslie~N Smith and Nicholay Topin.
\newblock Super-convergence: Very fast training of neural networks using large
  learning rates.
\newblock In \emph{Artificial intelligence and machine learning for
  multi-domain operations applications}, pages 369--386. SPIE, 2019.

\bibitem[Tan and Le(2019)]{efficientnet}
Mingxing Tan and Quoc Le.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock In \emph{International conference on machine learning}, pages
  6105--6114. PMLR, 2019.

\bibitem[Teed and Deng(2020)]{raft}
Zachary Teed and Jia Deng.
\newblock Raft: Recurrent all-pairs field transforms for optical flow.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference,
  Glasgow, UK, August 23--28, 2020, Proceedings, Part II 16}, pages 402--419.
  Springer, 2020.

\bibitem[Tsai et~al.(2005)Tsai, Chang, and Chen]{depth_from_perspective}
Yi-Min Tsai, Yu-Lin Chang, and Liang-Gee Chen.
\newblock Block-based vanishing line and vanishing point detection for 3d scene
  reconstruction.
\newblock In \emph{2006 international symposium on intelligent signal
  processing and communications}, pages 586--589. IEEE, 2005.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{transformer}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Wang et~al.(2021)Wang, Zhang, Yan, Li, Xu, Li, and Yang]{rnw}
Kun Wang, Zhenyu Zhang, Zhiqiang Yan, Xiang Li, Baobei Xu, Jun Li, and Jian
  Yang.
\newblock Regularizing nighttime weirdness: Efficient self-supervised monocular
  depth estimation in the dark.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 16055--16064, 2021.

\bibitem[Wang et~al.(2024)Wang, Yan, Tian, Zhang, Li, Li, and Yang]{altnerf}
Kun Wang, Zhiqiang Yan, Huang Tian, Zhenyu Zhang, Xiang Li, Jun Li, and Jian
  Yang.
\newblock Altnerf: Learning robust neural radiance field via alternating
  depth-pose optimization.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, pages 5508--5516, 2024.

\bibitem[Wang et~al.(2020)Wang, Zhang, Wang, Lin, and Lu]{semantic_depth}
Lijun Wang, Jianming Zhang, Oliver Wang, Zhe Lin, and Huchuan Lu.
\newblock Sdc-depth: Semantic divide-and-conquer network for monocular depth
  estimation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR)}, 2020.

\bibitem[Wang et~al.(2019)Wang, Chao, Garg, Hariharan, Campbell, and
  Weinberger]{depth_driving}
Yan Wang, Wei-Lun Chao, Divyansh Garg, Bharath Hariharan, Mark Campbell, and
  Kilian~Q Weinberger.
\newblock Pseudo-lidar from visual depth estimation: Bridging the gap in 3d
  object detection for autonomous driving.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 8445--8453, 2019.

\bibitem[Xie et~al.(2023)Xie, Geng, Hu, Zhang, Hu, and Cao]{xie2023revealing}
Zhenda Xie, Zigang Geng, Jingcheng Hu, Zheng Zhang, Han Hu, and Yue Cao.
\newblock Revealing the dark secrets of masked image modeling.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 14475--14485, 2023.

\bibitem[Xu et~al.(2018)Xu, Wang, Tang, Liu, Sebe, and Ricci]{xu2018structured}
Dan Xu, Wei Wang, Hao Tang, Hong Liu, Nicu Sebe, and Elisa Ricci.
\newblock Structured attention guided convolutional neural fields for monocular
  depth estimation.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 3917--3925, 2018.

\bibitem[Yan et~al.(2022{\natexlab{a}})Yan, Li, Wang, Zhang, Li, and
  Yang]{yan2022multi}
Zhiqiang Yan, Xiang Li, Kun Wang, Zhenyu Zhang, Jun Li, and Jian Yang.
\newblock Multi-modal masked pre-training for monocular panoramic depth
  completion.
\newblock In \emph{European Conference on Computer Vision}, pages 378--395.
  Springer, 2022{\natexlab{a}}.

\bibitem[Yan et~al.(2022{\natexlab{b}})Yan, Wang, Li, Zhang, Li, and
  Yang]{rignet}
Zhiqiang Yan, Kun Wang, Xiang Li, Zhenyu Zhang, Jun Li, and Jian Yang.
\newblock Rignet: Repetitive image guided network forÂ depth completion.
\newblock In \emph{Computer Vision -- ECCV 2022}, pages 214--230, Cham,
  2022{\natexlab{b}}. Springer Nature Switzerland.

\bibitem[Yan et~al.(2023{\natexlab{a}})Yan, Li, Wang, Chen, Li, and
  Yang]{yan2023distortion}
Zhiqiang Yan, Xiang Li, Kun Wang, Shuo Chen, Jun Li, and Jian Yang.
\newblock Distortion and uncertainty aware loss for panoramic depth completion.
\newblock In \emph{International Conference on Machine Learning}, pages
  39099--39109. PMLR, 2023{\natexlab{a}}.

\bibitem[Yan et~al.(2023{\natexlab{b}})Yan, Wang, Li, Zhang, Li, and
  Yang]{desnet}
Zhiqiang Yan, Kun Wang, Xiang Li, Zhenyu Zhang, Jun Li, and Jian Yang.
\newblock Desnet: Decomposed scale-consistent network for unsupervised depth
  completion.
\newblock In \emph{Proceedings of the AAAI conference on artificial
  intelligence}, pages 3109--3117, 2023{\natexlab{b}}.

\bibitem[Yan et~al.(2024{\natexlab{a}})Yan, Lin, Wang, Zheng, Wang, Zhang, Li,
  and Yang]{tofdc}
Zhiqiang Yan, Yuankai Lin, Kun Wang, Yupeng Zheng, Yufei Wang, Zhenyu Zhang,
  Jun Li, and Jian Yang.
\newblock Tri-perspective view decomposition for geometry-aware depth
  completion.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 2024{\natexlab{a}}.

\bibitem[Yan et~al.(2024{\natexlab{b}})Yan, Zheng, Fan, Li, Li, and
  Yang]{yan2024learnable}
Zhiqiang Yan, Yupeng Zheng, Deng-Ping Fan, Xiang Li, Jun Li, and Jian Yang.
\newblock Learnable differencing center for nighttime depth perception.
\newblock \emph{Visual Intelligence}, 2\penalty0 (1):\penalty0 15,
  2024{\natexlab{b}}.

\bibitem[Yang et~al.(2021)Yang, Tang, Ding, Sebe, and Ricci]{transdepth}
Guanglei Yang, Hao Tang, Mingli Ding, Nicu Sebe, and Elisa Ricci.
\newblock Transformer-based attention networks for continuous pixel-wise
  prediction.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer vision}, pages 16269--16279, 2021.

\bibitem[Yin et~al.(2019)Yin, Liu, Shen, and Yan]{vnl}
Wei Yin, Yifan Liu, Chunhua Shen, and Youliang Yan.
\newblock Enforcing geometric constraints of virtual normal for depth
  prediction.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 5684--5693, 2019.

\bibitem[Yin et~al.(2021)Yin, Zhang, Wang, Niklaus, Mai, Chen, and
  Shen]{yin2021learning}
Wei Yin, Jianming Zhang, Oliver Wang, Simon Niklaus, Long Mai, Simon Chen, and
  Chunhua Shen.
\newblock Learning to recover 3d scene shape from a single image.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 204--213, 2021.

\bibitem[Yu et~al.(2023)Yu, Sheng, Zhou, Luo, Cao, Gu, Zhang, and
  Shen]{yu2023aggregating}
Zhu Yu, Zehua Sheng, Zili Zhou, Lun Luo, Si-Yuan Cao, Hong Gu, Huaqi Zhang, and
  Hui-Liang Shen.
\newblock Aggregating feature point cloud for depth completion.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 8732--8743, 2023.

\bibitem[Yuan et~al.(2022)Yuan, Gu, Dai, Zhu, and Tan]{newcrf}
Weihao Yuan, Xiaodong Gu, Zuozhuo Dai, Siyu Zhu, and Ping Tan.
\newblock Neural window fully-connected crfs for monocular depth estimation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 3916--3925, 2022.

\bibitem[Zhang et~al.(1999)Zhang, Tsai, Cryer, and Shah]{shape_from_shading}
Ruo Zhang, Ping-Sing Tsai, James~Edwin Cryer, and Mubarak Shah.
\newblock Shape-from-shading: a survey.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 21\penalty0 (8):\penalty0 690--706, 1999.

\bibitem[Zhang et~al.(2019)Zhang, Cui, Xu, Yan, Sebe, and Yang]{panet}
Zhenyu Zhang, Zhen Cui, Chunyan Xu, Yan Yan, Nicu Sebe, and Jian Yang.
\newblock Pattern-affinitive propagation across depth, surface normal and
  semantic segmentation.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 4106--4115, 2019.

\bibitem[Zhao et~al.(2017)Zhao, Shi, Qi, Wang, and Jia]{ppm}
Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia.
\newblock Pyramid scene parsing network.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2881--2890, 2017.

\end{thebibliography}
