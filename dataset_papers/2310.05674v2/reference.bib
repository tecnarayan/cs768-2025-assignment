@article{aghajanyan2023scaling,
  title={Scaling Laws for Generative Mixed-Modal Language Models},
  author={Aghajanyan, Armen and Yu, Lili and Conneau, Alexis and Hsu, Wei-Ning and Hambardzumyan, Karen and Zhang, Susan and Roller, Stephen and Goyal, Naman and Levy, Omer and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2301.03728},
  year={2023}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{hoffmann2022training,
  title={Training compute-optimal large language models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={arXiv preprint arXiv:2203.15556},
  year={2022}
}

@article{sorscher2022beyond,
  title={Beyond neural scaling laws: beating power law scaling via data pruning},
  author={Sorscher, Ben and Geirhos, Robert and Shekhar, Shashank and Ganguli, Surya and Morcos, Ari},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={19523--19536},
  year={2022}
}

@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{kirillov2023segment,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  journal={arXiv preprint arXiv:2304.02643},
  year={2023}
}

@inproceedings{radford2022robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

@article{shu2019meta,
  title={Meta-weight-net: Learning an explicit mapping for sample weighting},
  author={Shu, Jun and Xie, Qi and Yi, Lixuan and Zhao, Qian and Zhou, Sanping and Xu, Zongben and Meng, Deyu},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{zheng2021meta,
  title={Meta label correction for noisy label learning},
  author={Zheng, Guoqing and Awadallah, Ahmed Hassan and Dumais, Susan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  pages={11053--11061},
  year={2021}
}

@article{xie2023data,
  title={Data Selection for Language Models via Importance Resampling},
  author={Xie, Sang Michael and Santurkar, Shibani and Ma, Tengyu and Liang, Percy},
  journal={arXiv preprint arXiv:2302.03169},
  year={2023}
}

@inproceedings{ren2018learning,
  title={Learning to reweight examples for robust deep learning},
  author={Ren, Mengye and Zeng, Wenyuan and Yang, Bin and Urtasun, Raquel},
  booktitle={International conference on machine learning},
  pages={4334--4343},
  year={2018},
  organization={PMLR}
}

@article{yan2022forml,
  title={FORML: Learning to Reweight Data for Fairness},
  author={Yan, Bobby and Seto, Skyler and Apostoloff, Nicholas},
  journal={arXiv preprint arXiv:2202.01719},
  year={2022}
}

@article{gao2020pile,
  title={The pile: An 800gb dataset of diverse text for language modeling},
  author={Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and others},
  journal={arXiv preprint arXiv:2101.00027},
  year={2020}
}

@inproceedings{abbas2023semdedup,
  title={SemDeDup: Data-efficient learning at web-scale through semantic deduplication},
  author={Abbas, Amro Kamal Mohamed and Tirumala, Kushal and Simig, Daniel and Ganguli, Surya and Morcos, Ari S},
  booktitle={ICLR 2023 Workshop on Mathematical and Empirical Understanding of Foundation Models},
  year={2023}
}

@inproceedings{
choe2023betty,
title={Betty: An Automatic Differentiation Library for Multilevel Optimization},
author={Sang Keun Choe and Willie Neiswanger and Pengtao Xie and Eric Xing},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=LV_MeMS38Q9}
}

@inproceedings{lorraine2020optimizing,
  title={Optimizing millions of hyperparameters by implicit differentiation},
  author={Lorraine, Jonathan and Vicol, Paul and Duvenaud, David},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1540--1552},
  year={2020},
  organization={PMLR}
}

@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1126--1135},
  year={2017},
  organization={PMLR}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{
clarke2022scalable,
title={Scalable One-Pass Optimisation of High-Dimensional Weight-Update Hyperparameters by Implicit Differentiation},
author={Ross M Clarke and Elre Talea Oldewage and Jos{\'e} Miguel Hern{\'a}ndez-Lobato},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=hfU7Ka5cfrC}
}

@inproceedings{
liu2018darts,
title={{DARTS}: Differentiable Architecture Search},
author={Hanxiao Liu and Karen Simonyan and Yiming Yang},
booktitle={International Conference on Learning Representations},
year={2019}
}

@article{gretton2012kernel,
  title={A kernel two-sample test},
  author={Gretton, Arthur and Borgwardt, Karsten M and Rasch, Malte J and Sch{\"o}lkopf, Bernhard and Smola, Alexander},
  journal={The Journal of Machine Learning Research},
  volume={13},
  number={1},
  pages={723--773},
  year={2012},
  publisher={JMLR. org}
}

@article{jaakkola1998exploiting,
  title={Exploiting generative models in discriminative classifiers},
  author={Jaakkola, Tommi and Haussler, David},
  journal={Advances in neural information processing systems},
  volume={11},
  year={1998}
}

@inproceedings{gudovskiy2021autodo,
  title={Autodo: Robust autoaugment for biased data with label noise via scalable probabilistic implicit differentiation},
  author={Gudovskiy, Denis and Rigazio, Luca and Ishizaka, Shun and Kozuka, Kazuki and Tsukizawa, Sotaro},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16601--16610},
  year={2021}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@inproceedings{hataya2022meta,
  title={Meta approach to data augmentation optimization},
  author={Hataya, Ryuichiro and Zdenek, Jan and Yoshizoe, Kazuki and Nakayama, Hideki},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={2574--2583},
  year={2022}
}

@inproceedings{ghosh2021we,
  title={Do we really need gold samples for sample weighting under label noise?},
  author={Ghosh, Aritra and Lan, Andrew},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={3922--3931},
  year={2021}
}

@inproceedings{grazzi2020iteration,
  title={On the iteration complexity of hypergradient computation},
  author={Grazzi, Riccardo and Franceschi, Luca and Pontil, Massimiliano and Salzo, Saverio},
  booktitle={International Conference on Machine Learning},
  pages={3748--3758},
  year={2020},
  organization={PMLR}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{hataya2023nystrom,
  title={Nystr{\"o}m Method for Accurate and Scalable Implicit Differentiation},
  author={Hataya, Ryuichiro and Yamada, Makoto},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4643--4654},
  year={2023},
  organization={PMLR}
}

@inproceedings{maclaurin2015gradient,
  title={Gradient-based hyperparameter optimization through reversible learning},
  author={Maclaurin, Dougal and Duvenaud, David and Adams, Ryan},
  booktitle={International conference on machine learning},
  pages={2113--2122},
  year={2015},
  organization={PMLR}
}

@inproceedings{franceschi2017forward,
  title={Forward and reverse gradient-based hyperparameter optimization},
  author={Franceschi, Luca and Donini, Michele and Frasconi, Paolo and Pontil, Massimiliano},
  booktitle={International Conference on Machine Learning},
  pages={1165--1173},
  year={2017},
  organization={PMLR}
}

@inproceedings{franceschi2018bilevel,
  title={Bilevel programming for hyperparameter optimization and meta-learning},
  author={Franceschi, Luca and Frasconi, Paolo and Salzo, Saverio and Grazzi, Riccardo and Pontil, Massimiliano},
  booktitle={International Conference on Machine Learning},
  pages={1568--1577},
  year={2018},
  organization={PMLR}
}

@inproceedings{pedregosa2016hyperparameter,
  title={Hyperparameter optimization with approximate gradient},
  author={Pedregosa, Fabian},
  booktitle={International conference on machine learning},
  pages={737--746},
  year={2016},
  organization={PMLR}
}

@article{rajeswaran2019meta,
  title={Meta-learning with implicit gradients},
  author={Rajeswaran, Aravind and Finn, Chelsea and Kakade, Sham M and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@article{zucchet2022contrastive,
  title={A contrastive rule for meta-learning},
  author={Zucchet, Nicolas and Schug, Simon and Von Oswald, Johannes and Zhao, Dominic and Sacramento, Jo{\~a}o},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={25921--25936},
  year={2022}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{devlin2018bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina},
  booktitle={Proceedings of NAACL-HLT},
  pages={4171--4186},
  year={2019}
}

@inproceedings{luketina2016scalable,
  title={Scalable gradient-based tuning of continuous regularization hyperparameters},
  author={Luketina, Jelena and Berglund, Mathias and Greff, Klaus and Raiko, Tapani},
  booktitle={International conference on machine learning},
  pages={2952--2960},
  year={2016},
  organization={PMLR}
}

@article{lichtarge2022simple,
  title={Simple and Effective Gradient-Based Tuning of Sequence-to-Sequence Models},
  author={Lichtarge, Jared and Alberti, Chris and Kumar, Shankar},
  journal={arXiv preprint arXiv:2209.04683},
  year={2022}
}

@inproceedings{
antoniou2018how,
title={How to train your {MAML}},
author={Antreas Antoniou and Harrison Edwards and Amos Storkey},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=HJGven05Y7},
}

@inproceedings{
schuhmann2022laionb,
title={{LAION}-5B: An open large-scale dataset for training next generation image-text models},
author={Christoph Schuhmann and Romain Beaumont and Richard Vencu and Cade W Gordon and Ross Wightman and Mehdi Cherti and Theo Coombes and Aarush Katta and Clayton Mullis and Mitchell Wortsman and Patrick Schramowski and Srivatsa R Kundurthy and Katherine Crowson and Ludwig Schmidt and Robert Kaczmarczyk and Jenia Jitsev},
booktitle={Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2022},
url={https://openreview.net/forum?id=M3Y74vmsMcY}
}

@article{loshchilov2016sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1608.03983},
  year={2016}
}

@inproceedings{hosseini2021dsrna,
  title={Dsrna: Differentiable search of robust neural architectures},
  author={Hosseini, Ramtin and Yang, Xingyi and Xie, Pengtao},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6196--6205},
  year={2021}
}

@inproceedings{fung2022jfb,
  title={Jfb: Jacobian-free backpropagation for implicit networks},
  author={Fung, Samy Wu and Heaton, Howard and Li, Qiuwei and McKenzie, Daniel and Osher, Stanley and Yin, Wotao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  pages={6648--6656},
  year={2022}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{arnold2020learn2learn,
  title={learn2learn: A library for Meta-Learning research},
  author={Arnold, S{\'e}bastien MR and Mahajan, Praateek and Datta, Debajyoti and Bunner, Ian and Zarkias, Konstantinos Saitas},
  journal={arXiv preprint arXiv:2008.12284},
  year={2020}
}

@inproceedings{zhang2021idarts,
  title={idarts: Differentiable architecture search with stochastic implicit gradients},
  author={Zhang, Miao and Su, Steven W and Pan, Shirui and Chang, Xiaojun and Abbasnejad, Ehsan M and Haffari, Reza},
  booktitle={International Conference on Machine Learning},
  pages={12557--12566},
  year={2021},
  organization={PMLR}
}

@inproceedings{metz2019understanding,
  title={Understanding and correcting pathologies in the training of learned optimizers},
  author={Metz, Luke and Maheswaranathan, Niru and Nixon, Jeremy and Freeman, Daniel and Sohl-Dickstein, Jascha},
  booktitle={International Conference on Machine Learning},
  pages={4556--4565},
  year={2019},
  organization={PMLR}
}

@article{metz2022velo,
  title={VeLO: Training Versatile Learned Optimizers by Scaling Up},
  author={Metz, Luke and Harrison, James and Freeman, C Daniel and Merchant, Amil and Beyer, Lucas and Bradbury, James and Agrawal, Naman and Poole, Ben and Mordatch, Igor and Roberts, Adam and others},
  journal={arXiv preprint arXiv:2211.09760},
  year={2022}
}

@inproceedings{
wang2023dynams,
title={Dyna{MS}: Dyanmic Margin Selection for Efficient Deep Learning},
author={Jiaxing Wang and Yong Li and Jingwei Zhuo and Xupeng Shi and WEIZHONG ZHANG and Lixing Gong and Tong Tao and Pengzhang Liu and Yongjun Bao and Weipeng Yan},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=7oPAgqxNb20}
}

@article{paul2021deep,
  title={Deep learning on a data diet: Finding important examples early in training},
  author={Paul, Mansheej and Ganguli, Surya and Dziugaite, Gintare Karolina},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={20596--20607},
  year={2021}
}

@inproceedings{
toneva2018empirical,
title={An Empirical Study of Example Forgetting during Deep Neural Network Learning},
author={Mariya Toneva and Alessandro Sordoni and Remi Tachet des Combes and Adam Trischler and Yoshua Bengio and Geoffrey J. Gordon},
booktitle={International Conference on Learning Representations},
year={2019}
}

@article{ratner2016data,
  title={Data programming: Creating large training sets, quickly},
  author={Ratner, Alexander J and De Sa, Christopher M and Wu, Sen and Selsam, Daniel and R{\'e}, Christopher},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{
zhang2021wrench,
title={{WRENCH}: A Comprehensive Benchmark for Weak Supervision},
author={Jieyu Zhang and Yue Yu and Yinghao Li and Yujing Wang and Yaming Yang and Mao Yang and Alexander Ratner},
booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
year={2021},
url={https://openreview.net/forum?id=Q9SKS5k8io}
}

@article{grefenstette2019generalized,
  title={Generalized Inner Loop Meta-Learning},
  author={Grefenstette, Edward and Amos, Brandon and Yarats, Denis and Htut, Phu Mon and Molchanov, Artem and Meier, Franziska and Kiela, Douwe and Cho, Kyunghyun and Chintala, Soumith},
  journal={arXiv preprint arXiv:1910.01727},
  year={2019}
}

@misc{deleu2019torchmeta,
  title={{Torchmeta: A Meta-Learning library for PyTorch}},
  author={Deleu, Tristan and W\"urfl, Tobias and Samiei, Mandana and Cohen, Joseph Paul and Bengio, Yoshua},
  year={2019},
  url={https://arxiv.org/abs/1909.06576},
  note={Available at: https://github.com/tristandeleu/pytorch-meta}
}

@inproceedings{liao2018reviving,
  title={Reviving and improving recurrent back-propagation},
  author={Liao, Renjie and Xiong, Yuwen and Fetaya, Ethan and Zhang, Lisa and Yoon, KiJung and Pitkow, Xaq and Urtasun, Raquel and Zemel, Richard},
  booktitle={International Conference on Machine Learning},
  pages={3082--3091},
  year={2018},
  organization={PMLR}
}


@article{pearlmutter1994fast,
  title={Fast exact multiplication by the Hessian},
  author={Pearlmutter, Barak A},
  journal={Neural computation},
  volume={6},
  number={1},
  pages={147--160},
  year={1994},
  publisher={MIT Press}
}


@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}


@inproceedings{kwon2023fully,
  title={A fully first-order method for stochastic bilevel optimization},
  author={Kwon, Jeongyeol and Kwon, Dohyun and Wright, Stephen and Nowak, Robert D},
  booktitle={International Conference on Machine Learning},
  pages={18083--18113},
  year={2023},
  organization={PMLR}
}

@article{li2020pytorch,
author = {Li, Shen and Zhao, Yanli and Varma, Rohan and Salpekar, Omkar and Noordhuis, Pieter and Li, Teng and Paszke, Adam and Smith, Jeff and Vaughan, Brian and Damania, Pritam and Chintala, Soumith},
year = {2020},
month = {08},
pages = {3005-3018},
title = {PyTorch distributed: experiences on accelerating data parallel training},
volume = {13},
journal = {Proceedings of the VLDB Endowment},
doi = {10.14778/3415478.3415530}
}

@inproceedings{
Dhillon2020A,
title={A Baseline for Few-Shot Image Classification},
author={Guneet Singh Dhillon and Pratik Chaudhari and Avinash Ravichandran and Stefano Soatto},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rylXBkrYDS}
}

@inproceedings{dontstoppretraining2020,
 author = {Suchin Gururangan and Ana Marasović and Swabha Swayamdipta and Kyle Lo and Iz Beltagy and Doug Downey and Noah A. Smith},
 title = {Don't Stop Pretraining: Adapt Language Models to Domains and Tasks},
 year = {2020},
 booktitle = {Proceedings of ACL},
}

@inproceedings{wang2019characterizing,
  title={Characterizing and avoiding negative transfer},
  author={Wang, Zirui and Dai, Zihang and P{\'o}czos, Barnab{\'a}s and Carbonell, Jaime},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11293--11302},
  year={2019}
}


@inproceedings{
dery2022should,
title={Should We Be Pre-training? An Argument for End-task Aware Training as an Alternative},
author={Lucio M. Dery and Paul Michel and Ameet Talwalkar and Graham Neubig},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=2bO2x8NAIMB}
}

@inproceedings{guo2022deepcore,
  title={Deepcore: A comprehensive library for coreset selection in deep learning},
  author={Guo, Chengcheng and Zhao, Bo and Bai, Yanbing},
  booktitle={Database and Expert Systems Applications: 33rd International Conference, DEXA 2022, Vienna, Austria, August 22--24, 2022, Proceedings, Part I},
  pages={181--195},
  year={2022},
  organization={Springer}
}


@article{blondel2022efficient,
  title={Efficient and modular implicit differentiation},
  author={Blondel, Mathieu and Berthet, Quentin and Cuturi, Marco and Frostig, Roy and Hoyer, Stephan and Llinares-L{\'o}pez, Felipe and Pedregosa, Fabian and Vert, Jean-Philippe},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={5230--5242},
  year={2022}
}

@article{gupta2018meta,
  title={Meta-reinforcement learning of structured exploration strategies},
  author={Gupta, Abhishek and Mendonca, Russell and Liu, YuXuan and Abbeel, Pieter and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{rakelly2019efficient,
  title={Efficient off-policy meta-reinforcement learning via probabilistic context variables},
  author={Rakelly, Kate and Zhou, Aurick and Finn, Chelsea and Levine, Sergey and Quillen, Deirdre},
  booktitle={International conference on machine learning},
  pages={5331--5340},
  year={2019},
  organization={PMLR}
}

@article{humplik2019meta,
  title={Meta reinforcement learning as task inference},
  author={Humplik, Jan and Galashov, Alexandre and Hasenclever, Leonard and Ortega, Pedro A and Teh, Yee Whye and Heess, Nicolas},
  journal={arXiv preprint arXiv:1905.06424},
  year={2019}
}


@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}


@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@inproceedings{
dosovitskiy2021an,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=YicbFdNTTy}
}

@article{gadre2023datacomp,
  title={DataComp: In search of the next generation of multimodal datasets},
  author={Gadre, Samir Yitzhak and Ilharco, Gabriel and Fang, Alex and Hayase, Jonathan and Smyrnis, Georgios and Nguyen, Thao and Marten, Ryan and Wortsman, Mitchell and Ghosh, Dhruba and Zhang, Jieyu and others},
  journal={arXiv preprint arXiv:2304.14108},
  year={2023}
}


@inproceedings{yu2021fine,
  title={Fine-Tuning Pre-trained Language Model with Weak Supervision: A Contrastive-Regularized Self-Training Approach},
  author={Yu, Yue and Zuo, Simiao and Jiang, Haoming and Ren, Wendi and Zhao, Tuo and Zhang, Chao},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={1063--1077},
  year={2021}
}


@inproceedings{mikolov2010recurrent,
  title={Recurrent neural network based language model.},
  author={Mikolov, Tomas and Karafi{\'a}t, Martin and Burget, Lukas and Cernock{\`y}, Jan and Khudanpur, Sanjeev},
  booktitle={Interspeech},
  volume={2},
  number={3},
  pages={1045--1048},
  year={2010},
  organization={Makuhari}
}


@article{rumelhart1986learning,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={nature},
  volume={323},
  number={6088},
  pages={533--536},
  year={1986},
  publisher={Nature Publishing Group UK London}
}


@article{chen2016training,
  title={Training deep nets with sublinear memory cost},
  author={Chen, Tianqi and Xu, Bing and Zhang, Chiyuan and Guestrin, Carlos},
  journal={arXiv preprint arXiv:1604.06174},
  year={2016}
}


@inproceedings{bernstein2018signsgd,
  title={signSGD: Compressed optimisation for non-convex problems},
  author={Bernstein, Jeremy and Wang, Yu-Xiang and Azizzadenesheli, Kamyar and Anandkumar, Animashree},
  booktitle={International Conference on Machine Learning},
  pages={560--569},
  year={2018},
  organization={PMLR}
}


@inproceedings{liu2020generic,
  title={A generic first-order algorithmic framework for bi-level programming beyond lower-level singleton},
  author={Liu, Risheng and Mu, Pan and Yuan, Xiaoming and Zeng, Shangzhi and Zhang, Jin},
  booktitle={International Conference on Machine Learning},
  pages={6305--6315},
  year={2020},
  organization={PMLR}
}

@inproceedings{
liu2022bome,
title={{BOME}! Bilevel Optimization Made Easy: A Simple First-Order Approach},
author={Bo Liu and Mao Ye and Stephen Wright and Peter Stone and qiang liu},
booktitle={Advances in Neural Information Processing Systems},
editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
year={2022},
url={https://openreview.net/forum?id=DTsCy9Lyj5-}
}


@inproceedings{
Coleman2020Selection,
title={Selection via Proxy: Efficient Data Selection for Deep Learning},
author={Cody Coleman and Christopher Yeh and Stephen Mussmann and Baharan Mirzasoleiman and Peter Bailis and Percy Liang and Jure Leskovec and Matei Zaharia},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HJg2b0VYDr}
}


@article{chung2022scaling,
  title={Scaling instruction-finetuned language models},
  author={Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Eric and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and others},
  journal={arXiv preprint arXiv:2210.11416},
  year={2022}
}

@article{ramamurthy2022reinforcement,
  title={Is Reinforcement Learning (Not) for Natural Language Processing?: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization},
  author={Ramamurthy, Rajkumar and Ammanabrolu, Prithviraj and Brantley, Kiant{\'e} and Hessel, Jack and Sifa, Rafet and Bauckhage, Christian and Hajishirzi, Hannaneh and Choi, Yejin},
  journal={arXiv preprint arXiv:2210.01241},
  year={2022}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{zhang2020adaptive,
  title={Why are adaptive methods good for attention models?},
  author={Zhang, Jingzhao and Karimireddy, Sai Praneeth and Veit, Andreas and Kim, Seungyeon and Reddi, Sashank and Kumar, Sanjiv and Sra, Suvrit},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15383--15393},
  year={2020}
}


@article{sutton2019bitter,
  title={The bitter lesson},
  author={Sutton, Richard},
  journal={Incomplete Ideas (blog)},
  volume={13},
  number={1},
  year={2019}
}

@article{hooker2021hardware,
  title={The hardware lottery},
  author={Hooker, Sara},
  journal={Communications of the ACM},
  volume={64},
  number={12},
  pages={58--65},
  year={2021},
  publisher={ACM New York, NY, USA}
}


@inproceedings{
metz2016unrolled,
title={Unrolled Generative Adversarial Networks},
author={Luke Metz and Ben Poole and David Pfau and Jascha Sohl-Dickstein},
booktitle={International Conference on Learning Representations},
year={2017}
}


@article{shoeybi2019megatron,
  title={Megatron-lm: Training multi-billion parameter language models using model parallelism},
  author={Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1909.08053},
  year={2019}
}

@article{huang2019gpipe,
  title={Gpipe: Efficient training of giant neural networks using pipeline parallelism},
  author={Huang, Yanping and Cheng, Youlong and Bapna, Ankur and Firat, Orhan and Chen, Dehao and Chen, Mia and Lee, HyoukJoong and Ngiam, Jiquan and Le, Quoc V and Wu, Yonghui and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}