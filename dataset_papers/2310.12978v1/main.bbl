\begin{thebibliography}{79}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Aberman et~al.(2020)Aberman, Li, Lischinski, Sorkine-Hornung, Cohen-Or, and Chen]{aberman2020skeleton}
Kfir Aberman, Peizhuo Li, Dani Lischinski, Olga Sorkine-Hornung, Daniel Cohen-Or, and Baoquan Chen.
\newblock Skeleton-aware networks for deep motion retargeting.
\newblock \emph{TOG}, 39\penalty0 (4):\penalty0 62, 2020.

\bibitem[Ahn et~al.(2018)Ahn, Ha, Choi, Yoo, and Oh]{ahn2018text2action}
Hyemin Ahn, Timothy Ha, Yunho Choi, Hwiyeon Yoo, and Songhwai Oh.
\newblock Text2action: Generative adversarial synthesis from language to action.
\newblock In \emph{ICRA}, 2018.

\bibitem[Ahuja \& Morency(2019)Ahuja and Morency]{ahuja2019language2pose}
Chaitanya Ahuja and Louis-Philippe Morency.
\newblock Language2pose: Natural language grounded pose forecasting.
\newblock In \emph{3DV}, 2019.

\bibitem[Ao et~al.(2022)Ao, Gao, Lou, Chen, and Liu]{ao2022rhythmic_gesticulator}
Tenglong Ao, Qingzhe Gao, Yuke Lou, Baoquan Chen, and Libin Liu.
\newblock Rhythmic gesticulator: Rhythm-aware co-speech gesture synthesis with hierarchical neural embeddings.
\newblock \emph{ACM TOG}, 41\penalty0 (6):\penalty0 1--19, 2022.

\bibitem[Barnes et~al.(1996)Barnes, Rizvi, and Nasrabadi]{rvq}
C.F. Barnes, S.A. Rizvi, and N.M. Nasrabadi.
\newblock Advances in residual vector quantization: a review.
\newblock \emph{IEEE TIP}, 5\penalty0 (2):\penalty0 226--262, 1996.
\newblock \doi{10.1109/83.480761}.

\bibitem[Cai et~al.(2021)Cai, Wang, Zhu, Cham, Cai, Yuan, Liu, Zheng, Yan, Ding, et~al.]{cai2021unified}
Yujun Cai, Yiwei Wang, Yiheng Zhu, Tat-Jen Cham, Jianfei Cai, Junsong Yuan, Jun Liu, Chuanxia Zheng, Sijie Yan, Henghui Ding, et~al.
\newblock A unified 3d human motion synthesis model via conditional variational auto-encoder.
\newblock In \emph{ICCV}, 2021.

\bibitem[Chen et~al.(2023{\natexlab{a}})Chen, Zhang, Li, Pang, Xia, and Liu]{2023mac}
Ling-Hao Chen, Jiawei Zhang, Yewen Li, Yiren Pang, Xiaobo Xia, and Tongliang Liu.
\newblock Humanmac: Masked motion completion for human motion prediction.
\newblock \emph{ICCV}, 2023{\natexlab{a}}.

\bibitem[Chen et~al.(2023{\natexlab{b}})Chen, Jiang, Liu, Huang, Fu, Chen, Yu, and Yu]{mld}
Xin Chen, Biao Jiang, Wen Liu, Zilong Huang, Bin Fu, Tao Chen, Jingyi Yu, and Gang Yu.
\newblock Executing your commands via motion diffusion in latent space.
\newblock \emph{CVPR}, 2023{\natexlab{b}}.

\bibitem[Copet et~al.(2023)Copet, Kreuk, Gat, Remez, Kant, Synnaeve, Adi, and Défossez]{copet2023simple}
Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi, and Alexandre Défossez.
\newblock Simple and controllable music generation.
\newblock \emph{arXiv preprint arXiv:2306.05284}, 2023.

\bibitem[Dabral et~al.(2023)Dabral, Mughal, Golyanik, and Theobalt]{dabral2023mofusion}
Rishabh Dabral, Muhammad~Hamza Mughal, Vladislav Golyanik, and Christian Theobalt.
\newblock Mofusion: A framework for denoising-diffusion-based motion synthesis.
\newblock In \emph{CVPR}, pp.\  9760--9770, 2023.

\bibitem[Défossez et~al.(2022)Défossez, Copet, Synnaeve, and Adi]{defossez2022highfi}
Alexandre Défossez, Jade Copet, Gabriel Synnaeve, and Yossi Adi.
\newblock High fidelity neural audio compression.
\newblock \emph{arXiv preprint arXiv:2210.13438}, 2022.

\bibitem[Floridi \& Chiriatti(2020)Floridi and Chiriatti]{floridi2020gpt}
Luciano Floridi and Massimo Chiriatti.
\newblock Gpt-3: Its nature, scope, limits, and consequences.
\newblock \emph{Minds and Machines}, 2020.

\bibitem[Ghosh et~al.(2021)Ghosh, Cheema, Oguz, Theobalt, and Slusallek]{ghosh2021synthesis}
Anindita Ghosh, Noshaba Cheema, Cennet Oguz, Christian Theobalt, and Philipp Slusallek.
\newblock Synthesis of compositional animations from textual descriptions.
\newblock In \emph{ICCV}, 2021.

\bibitem[Gower(1975)]{gower1975generalized}
John~C Gower.
\newblock Generalized procrustes analysis.
\newblock \emph{Psychometrika}, 40:\penalty0 33--51, 1975.

\bibitem[Guo et~al.(2022)Guo, Zou, Zuo, Wang, Ji, Li, and Cheng]{guo2022generating}
Chuan Guo, Shihao Zou, Xinxin Zuo, Sen Wang, Wei Ji, Xingyu Li, and Li~Cheng.
\newblock Generating diverse and natural 3d human motions from text.
\newblock In \emph{CVPR}, 2022.

\bibitem[Habibie et~al.(2021)Habibie, Xu, Mehta, Liu, Seidel, Pons-Moll, Elgharib, and Theobalt]{habibie2021learning}
Ikhsanul Habibie, Weipeng Xu, Dushyant Mehta, Lingjie Liu, Hans-Peter Seidel, Gerard Pons-Moll, Mohamed Elgharib, and Christian Theobalt.
\newblock Learning speech-driven 3d conversational gestures from video.
\newblock In \emph{ACM IVA}, pp.\  101--108, 2021.

\bibitem[Hong et~al.(2022)Hong, Zhang, Pan, Cai, Yang, and Liu]{hong2022avatarclip}
Fangzhou Hong, Mingyuan Zhang, Liang Pan, Zhongang Cai, Lei Yang, and Ziwei Liu.
\newblock Avatarclip: Zero-shot text-driven generation and animation of 3d avatars.
\newblock \emph{ACM SIGGRAPH}, 2022.

\bibitem[Jiang et~al.(2023)Jiang, Chen, Liu, Yu, Yu, and Chen]{jiang2023motiongpt}
Biao Jiang, Xin Chen, Wen Liu, Jingyi Yu, Gang Yu, and Tao Chen.
\newblock Motiongpt: Human motion as a foreign language.
\newblock In \emph{NeurIPS}, 2023.

\bibitem[Kim et~al.(2023)Kim, Kim, and Choi]{kim2023flame}
Jihoon Kim, Jiseob Kim, and Sungjoon Choi.
\newblock Flame: Free-form language-based motion synthesis \& editing.
\newblock In \emph{AAAI}, volume~37, pp.\  8255--8263, 2023.

\bibitem[Kingma \& Welling(2013)Kingma and Welling]{vae}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational bayes.
\newblock In \emph{ICLR}, 2013.

\bibitem[Lee et~al.(2023)Lee, Moon, and Lee]{lee2023multiact}
Taeryung Lee, Gyeongsik Moon, and Kyoung~Mu Lee.
\newblock Multiact: Long-term 3d human motion generation from multiple action labels.
\newblock In \emph{AAAI}, volume~37, pp.\  1231--1239, 2023.

\bibitem[Li et~al.(2021{\natexlab{a}})Li, Zhang, Li, Su, Huang, Jin, Chen, Huang, and Yoo]{li2021detectornet}
He~Li, Shiyu Zhang, Xuejiao Li, Liangcai Su, Hongjie Huang, Duo Jin, Linghao Chen, Jianbin Huang, and Jaesoo Yoo.
\newblock Detectornet: Transformer-enhanced spatial temporal graph neural network for traffic prediction.
\newblock In \emph{ACM SIGSPATIAL}, pp.\  133--136, 2021{\natexlab{a}}.

\bibitem[Li et~al.(2021{\natexlab{b}})Li, Xu, Chen, Bian, Yang, and Lu]{li2021hybrik}
Jiefeng Li, Chao Xu, Zhicun Chen, Siyuan Bian, Lixin Yang, and Cewu Lu.
\newblock Hybrik: A hybrid analytical-neural inverse kinematics solution for 3d human pose and shape estimation.
\newblock In \emph{CVPR}, pp.\  3383--3393, 2021{\natexlab{b}}.

\bibitem[Li et~al.(2023{\natexlab{a}})Li, Zhao, Zhang, Su, Ren, Zhang, Tang, and Li]{li2023finedance}
Ronghui Li, Junfan Zhao, Yachao Zhang, Mingyang Su, Zeping Ren, Han Zhang, Yansong Tang, and Xiu Li.
\newblock Finedance: A fine-grained choreography dataset for 3d full body dance generation.
\newblock In \emph{ICCV}, pp.\  10234--10243, 2023{\natexlab{a}}.

\bibitem[Li et~al.(2022)Li, Xia, Ge, and Liu]{li2022selective}
Shikun Li, Xiaobo Xia, Shiming Ge, and Tongliang Liu.
\newblock Selective-supervised contrastive learning with noisy labels.
\newblock In \emph{CVPR}, pp.\  316--325, 2022.

\bibitem[Li et~al.(2023{\natexlab{b}})Li, Zhuang, Song, Zhang, Chen, and Hao]{Li_2023_ICCV}
Shuai Li, Sisi Zhuang, Wenfeng Song, Xinyu Zhang, Hejia Chen, and Aimin Hao.
\newblock Sequential texts driven cohesive motions synthesis with natural transitions.
\newblock In \emph{ICCV}, pp.\  9498--9508, October 2023{\natexlab{b}}.

\bibitem[Lin et~al.(2023{\natexlab{a}})Lin, Zeng, Lu, Cai, Zhang, Wang, and Zhang]{lin2023motion}
Jing Lin, Ailing Zeng, Shunlin Lu, Yuanhao Cai, Ruimao Zhang, Haoqian Wang, and Lei Zhang.
\newblock Motion-x: A large-scale 3d expressive whole-body human motion dataset.
\newblock \emph{NeurIPS}, 2023{\natexlab{a}}.

\bibitem[Lin et~al.(2023{\natexlab{b}})Lin, Zeng, Wang, Zhang, and Li]{osx}
Jing Lin, Ailing Zeng, Haoqian Wang, Lei Zhang, and Yu~Li.
\newblock One-stage 3d whole-body mesh recovery with component aware transformer.
\newblock In \emph{CVPR}, pp.\  21159--21168, 2023{\natexlab{b}}.

\bibitem[Lin et~al.(2023{\natexlab{c}})Lin, Chang, Liu, Li, Lin, Tian, and Chen]{lin2023being}
Junfan Lin, Jianlong Chang, Lingbo Liu, Guanbin Li, Liang Lin, Qi~Tian, and Chang-wen Chen.
\newblock Being comes from not-being: Open-vocabulary text-to-motion generation with wordless training.
\newblock In \emph{CVPR}, pp.\  23222--23231, 2023{\natexlab{c}}.

\bibitem[Liu et~al.(2022)Liu, Zhu, Iwamoto, Peng, Li, Zhou, Bozkurt, and Zheng]{liu2022beat}
Haiyang Liu, Zihao Zhu, Naoya Iwamoto, Yichen Peng, Zhengqing Li, You Zhou, Elif Bozkurt, and Bo~Zheng.
\newblock Beat: A large-scale semantic and emotional multi-modal dataset for conversational gestures synthesis.
\newblock In \emph{ECCV}, pp.\  612--630. Springer, 2022.

\bibitem[Liu et~al.(2019)Liu, Shahroudy, Perez, Wang, Duan, and Kot]{liu2019ntu}
Jun Liu, Amir Shahroudy, Mauricio Perez, Gang Wang, Ling-Yu Duan, and Alex~C Kot.
\newblock Ntu rgb+ d 120: A large-scale benchmark for 3d human activity understanding.
\newblock \emph{TPAMI}, 2019.

\bibitem[Loshchilov \& Hutter(2019)Loshchilov and Hutter]{loshchilov2017decoupled}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock \emph{ICLR}, 2019.

\bibitem[Lu et~al.(2022)Lu, Zhang, Lu, and Roychowdhury]{lu2022action}
Qiujing Lu, Yipeng Zhang, Mingjian Lu, and Vwani Roychowdhury.
\newblock Action-conditioned on-demand motion generation.
\newblock In \emph{ACM MM}, pp.\  2249--2257, 2022.

\bibitem[Lucas et~al.(2022)Lucas, Baradel, Weinzaepfel, and Rogez]{lucas2022posegpt}
Thomas Lucas, Fabien Baradel, Philippe Weinzaepfel, and Gr{\'e}gory Rogez.
\newblock Posegpt: Quantization-based 3d human motion generation and forecasting.
\newblock In \emph{ECCV}, pp.\  417--435. Springer, 2022.

\bibitem[Mahmood et~al.(2019)Mahmood, Ghorbani, Troje, Pons-Moll, and Black]{amass}
Naureen Mahmood, Nima Ghorbani, Nikolaus~F Troje, Gerard Pons-Moll, and Michael~J Black.
\newblock Amass: Archive of motion capture as surface shapes.
\newblock In \emph{ICCV}, 2019.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Pavlakos et~al.(2019)Pavlakos, Choutas, Ghorbani, Bolkart, Osman, Tzionas, and Black]{smpl-x}
Georgios Pavlakos, Vasileios Choutas, Nima Ghorbani, Timo Bolkart, Ahmed~AA Osman, Dimitrios Tzionas, and Michael~J Black.
\newblock Expressive body capture: 3d hands, face, and body from a single image.
\newblock In \emph{CVPR}, 2019.

\bibitem[Petrovich et~al.(2022)Petrovich, Black, and Varol]{temos}
Mathis Petrovich, Michael~J Black, and G{\"u}l Varol.
\newblock Temos: Generating diverse human motions from textual descriptions.
\newblock In \emph{ECCV}, 2022.

\bibitem[Petrovich et~al.(2023)Petrovich, Black, and Varol]{petrovich2023tmr}
Mathis Petrovich, Michael~J Black, and G{\"u}l Varol.
\newblock Tmr: Text-to-motion retrieval using contrastive 3d human motion synthesis.
\newblock \emph{ICCV}, 2023.

\bibitem[Plappert et~al.(2016)Plappert, Mandery, and Asfour]{plappert2016kit}
Matthias Plappert, Christian Mandery, and Tamim Asfour.
\newblock The kit motion-language dataset.
\newblock \emph{Big data}, 4\penalty0 (4):\penalty0 236--252, 2016.

\bibitem[Punnakkal et~al.(2021)Punnakkal, Chandrasekaran, Athanasiou, Quiros-Ramirez, and Black]{babel}
Abhinanda~R Punnakkal, Arjun Chandrasekaran, Nikos Athanasiou, Alejandra Quiros-Ramirez, and Michael~J Black.
\newblock Babel: bodies, action and behavior with english labels.
\newblock In \emph{CVPR}, 2021.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{clip}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{ICML}, 2021.

\bibitem[Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena, Zhou, Li, and Liu]{t5}
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter~J Liu.
\newblock Exploring the limits of transfer learning with a unified text-to-text transformer.
\newblock \emph{JMLR}, 21\penalty0 (1):\penalty0 5485--5551, 2020.

\bibitem[Razavi et~al.(2019)Razavi, Van~den Oord, and Vinyals]{vqvae2}
Ali Razavi, Aaron Van~den Oord, and Oriol Vinyals.
\newblock Generating diverse high-fidelity images with vq-vae-2.
\newblock \emph{NeurIPS}, 32, 2019.

\bibitem[Reimers \& Gurevych(2019)Reimers and Gurevych]{sbert}
Nils Reimers and Iryna Gurevych.
\newblock Sentence-bert: Sentence embeddings using siamese bert-networks.
\newblock In \emph{EMNLP-IJCNLP}, pp.\  3982--3992, 2019.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{ldm}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj{\"o}rn Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{CVPR}, pp.\  10684--10695, 2022.

\bibitem[Sanh et~al.(2019)Sanh, Debut, Chaumond, and Wolf]{sanh2019distilbert}
Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf.
\newblock Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter.
\newblock \emph{arXiv preprint arXiv:1910.01108}, 2019.

\bibitem[Siyao et~al.(2022)Siyao, Yu, Gu, Lin, Wang, Qian, Loy, and Liu]{siyao2022bailando}
Li~Siyao, Weijiang Yu, Tianpei Gu, Chunze Lin, Quan Wang, Chen Qian, Chen~Change Loy, and Ziwei Liu.
\newblock Bailando: 3d dance generation by actor-critic gpt with choreographic memory.
\newblock In \emph{CVPR}, pp.\  11050--11059, 2022.

\bibitem[Song et~al.(2020)Song, Tan, Qin, Lu, and Liu]{song2020mpnet}
Kaitao Song, Xu~Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu.
\newblock Mpnet: Masked and permuted pre-training for language understanding.
\newblock \emph{NeurIPS}, 33:\penalty0 16857--16867, 2020.

\bibitem[Taheri et~al.(2020)Taheri, Ghorbani, Black, and Tzionas]{taheri2020grab}
Omid Taheri, Nima Ghorbani, Michael~J Black, and Dimitrios Tzionas.
\newblock Grab: A dataset of whole-body human grasping of objects.
\newblock In \emph{ECCV}, 2020.

\bibitem[Tevet et~al.(2022)Tevet, Gordon, Hertz, Bermano, and Cohen-Or]{motionclip}
Guy Tevet, Brian Gordon, Amir Hertz, Amit~H Bermano, and Daniel Cohen-Or.
\newblock Motionclip: Exposing human motion generation to clip space.
\newblock In \emph{ECCV}, 2022.

\bibitem[Tevet et~al.(2023)Tevet, Raab, Gordon, Shafir, Bermano, and Cohen-Or]{mdm2022human}
Guy Tevet, Sigal Raab, Brian Gordon, Yonatan Shafir, Amit~H Bermano, and Daniel Cohen-Or.
\newblock Human motion diffusion model.
\newblock \emph{ICLR}, 2023.

\bibitem[Tseng et~al.(2023)Tseng, Castellon, and Liu]{tseng2023edge}
Jonathan Tseng, Rodrigo Castellon, and Karen Liu.
\newblock Edge: Editable dance generation from music.
\newblock In \emph{CVPR}, pp.\  448--458, 2023.

\bibitem[Van Den~Oord et~al.(2017)Van Den~Oord, Vinyals, et~al.]{van2017neural}
Aaron Van Den~Oord, Oriol Vinyals, et~al.
\newblock Neural discrete representation learning.
\newblock \emph{NeruIPS}, 30, 2017.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock \emph{NeurIPS}, 30, 2017.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Deng, Yin, Shum, and Wang]{wang2023progressive}
Duomin Wang, Yu~Deng, Zixin Yin, Heung-Yeung Shum, and Baoyuan Wang.
\newblock Progressive disentangled representation learning for fine-grained controllable talking head synthesis.
\newblock In \emph{CVPR}, pp.\  17979--17989, 2023{\natexlab{a}}.

\bibitem[Wang et~al.(2022{\natexlab{a}})Wang, Rong, Liu, Yan, Lin, and Dai]{wang2022towards}
Jingbo Wang, Yu~Rong, Jingyuan Liu, Sijie Yan, Dahua Lin, and Bo~Dai.
\newblock Towards diverse and natural scene-aware 3d human motion synthesis.
\newblock In \emph{CVPR}, pp.\  20460--20469, 2022{\natexlab{a}}.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, Yu, and Zhang]{wang2022zero}
Yinhuai Wang, Jiwen Yu, and Jian Zhang.
\newblock Zero-shot image restoration using denoising diffusion null-space model.
\newblock \emph{ICLR}, 2023{\natexlab{b}}.

\bibitem[Wang et~al.(2022{\natexlab{b}})Wang, Chen, Liu, Zhu, Liang, and Huang]{wang2022humanise}
Zan Wang, Yixin Chen, Tengyu Liu, Yixin Zhu, Wei Liang, and Siyuan Huang.
\newblock Humanise: Language-conditioned human motion generation in 3d scenes.
\newblock \emph{NuerIPS}, 35:\penalty0 14959--14971, 2022{\natexlab{b}}.

\bibitem[Wang et~al.(2020)Wang, Yu, Zhao, Zhang, Zhou, Yuan, and Chen]{wang2020learning}
Zhenyi Wang, Ping Yu, Yang Zhao, Ruiyi Zhang, Yufan Zhou, Junsong Yuan, and Changyou Chen.
\newblock Learning diverse stochastic human-action generators by learning smooth latent transitions.
\newblock In \emph{AAAI}, 2020.

\bibitem[Xia et~al.(2019)Xia, Liu, Wang, Han, Gong, Niu, and Sugiyama]{anchornoise}
Xiaobo Xia, Tongliang Liu, Nannan Wang, Bo~Han, Chen Gong, Gang Niu, and Masashi Sugiyama.
\newblock Are anchor points really indispensable in label-noise learning?
\newblock \emph{NeurIPS}, 32, 2019.

\bibitem[Xia et~al.(2020)Xia, Liu, Han, Wang, Gong, Liu, Niu, Tao, and Sugiyama]{partnoise}
Xiaobo Xia, Tongliang Liu, Bo~Han, Nannan Wang, Mingming Gong, Haifeng Liu, Gang Niu, Dacheng Tao, and Masashi Sugiyama.
\newblock Part-dependent label noise: Towards instance-dependent label noise.
\newblock \emph{NeurIPS}, 33:\penalty0 7597--7610, 2020.

\bibitem[Xu et~al.(2022)Xu, Wang, and Gui]{xu2022diverse}
Sirui Xu, Yu-Xiong Wang, and Liang-Yan Gui.
\newblock Diverse human motion prediction guided by multi-level spatial-temporal anchors.
\newblock In \emph{ECCV}, pp.\  251--269. Springer, 2022.

\bibitem[Xu et~al.(2023{\natexlab{a}})Xu, Li, Wang, and Gui]{xu2023interdiff}
Sirui Xu, Zhengyuan Li, Yu-Xiong Wang, and Liang-Yan Gui.
\newblock Interdiff: Generating 3d human-object interactions with physics-informed diffusion.
\newblock \emph{ICCV}, 2023{\natexlab{a}}.

\bibitem[Xu et~al.(2023{\natexlab{b}})Xu, Wang, and Gui]{2023stochastic}
Sirui Xu, Yu-Xiong Wang, and Liang-Yan Gui.
\newblock Stochastic multi-person 3d motion forecasting.
\newblock In \emph{ICLR}, 2023{\natexlab{b}}.

\bibitem[Yan et~al.(2019)Yan, Li, Xiong, Yan, and Lin]{yan2019convolutional}
Sijie Yan, Zhizhong Li, Yuanjun Xiong, Huahan Yan, and Dahua Lin.
\newblock Convolutional sequence generation for skeleton-based action synthesis.
\newblock In \emph{ICCV}, 2019.

\bibitem[Yang et~al.(2023)Yang, Zeng, Liu, Li, Zhang, and Zhang]{yang2023explicit}
Jie Yang, Ailing Zeng, Shilong Liu, Feng Li, Ruimao Zhang, and Lei Zhang.
\newblock Explicit box detection unifies end-to-end multi-person pose estimation.
\newblock In \emph{ICLR}, 2023.

\bibitem[Yao et~al.(2023)Yao, Song, Zhou, Ao, Chen, and Liu]{yao2023moconvq}
Heyuan Yao, Zhenhua Song, Yuyang Zhou, Tenglong Ao, Baoquan Chen, and Libin Liu.
\newblock Moconvq: Unified physics-based motion control via scalable discrete representations.
\newblock \emph{arXiv preprint arXiv:2310.10198}, 2023.

\bibitem[Yi et~al.(2023)Yi, Liang, Liu, Cao, Wen, Bolkart, Tao, and Black]{talkshow}
Hongwei Yi, Hualin Liang, Yifei Liu, Qiong Cao, Yandong Wen, Timo Bolkart, Dacheng Tao, and Michael~J Black.
\newblock Generating holistic 3d human motion from speech.
\newblock In \emph{CVPR}, 2023.

\bibitem[Yu et~al.(2020)Yu, Zhao, Li, Yuan, and Chen]{yu2020structure}
Ping Yu, Yang Zhao, Chunyuan Li, Junsong Yuan, and Changyou Chen.
\newblock Structure-aware human-action generation.
\newblock In \emph{ECCV}, 2020.

\bibitem[Yu et~al.(2023)Yu, Yin, Zhou, Wang, Wong, and Wang]{yu2023talking}
Zhentao Yu, Zixin Yin, Deyu Zhou, Duomin Wang, Finn Wong, and Baoyuan Wang.
\newblock Talking head generation with probabilistic audio-to-visual diffusion priors.
\newblock In \emph{ICCV}, pp.\  7645--7655, 2023.

\bibitem[Yuan et~al.(2023)Yuan, Song, Iqbal, Vahdat, and Kautz]{Yuan2022PhysDiffPH}
Ye~Yuan, Jiaming Song, Umar Iqbal, Arash Vahdat, and Jan Kautz.
\newblock Physdiff: Physics-guided human motion diffusion model.
\newblock \emph{ICCV}, 2023.

\bibitem[Zeghidour et~al.(2021)Zeghidour, Luebs, Omran, Skoglund, and Tagliasacchi]{zeghidour2021soundstream}
Neil Zeghidour, Alejandro Luebs, Ahmed Omran, Jan Skoglund, and Marco Tagliasacchi.
\newblock Soundstream: An end-to-end neural audio codec.
\newblock \emph{TASLP}, 30:\penalty0 495--507, 2021.

\bibitem[Zeng et~al.(2022)Zeng, Yang, Ju, Li, Wang, and Xu]{zeng2022smoothnet}
Ailing Zeng, Lei Yang, Xuan Ju, Jiefeng Li, Jianyi Wang, and Qiang Xu.
\newblock Smoothnet: A plug-and-play network for refining human poses in videos.
\newblock In \emph{ECCV}, pp.\  625--642. Springer, 2022.

\bibitem[Zhang et~al.(2023)Zhang, Zhang, Cun, Huang, Zhang, Zhao, Lu, and Shen]{t2m-gpt}
Jianrong Zhang, Yangsong Zhang, Xiaodong Cun, Shaoli Huang, Yong Zhang, Hongwei Zhao, Hongtao Lu, and Xi~Shen.
\newblock T2m-gpt: Generating human motion from textual descriptions with discrete representations.
\newblock \emph{CVPR}, 2023.

\bibitem[Zhang et~al.(2022)Zhang, Cai, Pan, Hong, Guo, Yang, and Liu]{motiondiffuse}
Mingyuan Zhang, Zhongang Cai, Liang Pan, Fangzhou Hong, Xinying Guo, Lei Yang, and Ziwei Liu.
\newblock Motiondiffuse: Text-driven human motion generation with diffusion model.
\newblock \emph{arXiv preprint arXiv:2208.15001}, 2022.

\bibitem[Zhang et~al.(2020)Zhang, Black, and Tang]{zhang2020perpetual}
Yan Zhang, Michael~J Black, and Siyu Tang.
\newblock Perpetual motion: Generating unbounded human motion.
\newblock \emph{arXiv preprint arXiv:2007.13886}, 2020.

\bibitem[Zhao et~al.(2020)Zhao, Su, and Ji]{zhao2020bayesian}
Rui Zhao, Hui Su, and Qiang Ji.
\newblock Bayesian adversarial human motion synthesis.
\newblock In \emph{CVPR}, 2020.

\bibitem[Zhou \& Wang(2023)Zhou and Wang]{zhou2023ude}
Zixiang Zhou and Baoyuan Wang.
\newblock Ude: A unified driving engine for human motion generation.
\newblock In \emph{CVPR}, pp.\  5632--5641, 2023.

\end{thebibliography}
