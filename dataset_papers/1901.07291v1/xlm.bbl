\begin{thebibliography}{45}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi

\bibitem[{Al-Rfou et~al.(2018)Al-Rfou, Choe, Constant, Guo, and
  Jones}]{al2018character}
Rami Al-Rfou, Dokook Choe, Noah Constant, Mandy Guo, and Llion Jones. 2018.
\newblock Character-level language modeling with deeper self-attention.
\newblock \emph{arXiv preprint arXiv:1808.04444}.

\bibitem[{Ammar et~al.(2016)Ammar, Mulcaire, Tsvetkov, Lample, Dyer, and
  Smith}]{ammar2016massively}
Waleed Ammar, George Mulcaire, Yulia Tsvetkov, Guillaume Lample, Chris Dyer,
  and Noah~A Smith. 2016.
\newblock Massively multilingual word embeddings.
\newblock \emph{arXiv preprint arXiv:1602.01925}.

\bibitem[{Anoop et~al.(2018)Anoop, Pratik, and Pushpak}]{kunchukuttan2018iit}
Kunchukuttan Anoop, Mehta Pratik, and Bhattacharyya Pushpak. 2018.
\newblock The iit bombay english-hindi parallel corpus.
\newblock In \emph{LREC}.

\bibitem[{Artetxe et~al.(2018)Artetxe, Labaka, Agirre, and
  Cho}]{unsupNMTartetxe}
Mikel Artetxe, Gorka Labaka, Eneko Agirre, and Kyunghyun Cho. 2018.
\newblock Unsupervised neural machine translation.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}.

\bibitem[{Artetxe and Schwenk(2018)}]{artetxe2018massively}
Mikel Artetxe and Holger Schwenk. 2018.
\newblock Massively multilingual sentence embeddings for zero-shot
  cross-lingual transfer and beyond.
\newblock \emph{arXiv preprint arXiv:1812.10464}.

\bibitem[{Bojanowski et~al.(2017)Bojanowski, Grave, Joulin, and
  Mikolov}]{bojanowski2017enriching}
Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2017.
\newblock Enriching word vectors with subword information.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  5:135--146.

\bibitem[{Bowman et~al.(2015)Bowman, Angeli, Potts, and
  Manning}]{bowman2015large}
Samuel~R. Bowman, Gabor Angeli, Christopher Potts, and Christopher~D. Manning.
  2015.
\newblock A large annotated corpus for learning natural language inference.
\newblock In \emph{EMNLP}.

\bibitem[{Camacho-Collados et~al.(2017)Camacho-Collados, Pilehvar, Collier, and
  Navigli}]{camacho2017semeval}
Jose Camacho-Collados, Mohammad~Taher Pilehvar, Nigel Collier, and Roberto
  Navigli. 2017.
\newblock Semeval-2017 task 2: Multilingual and cross-lingual semantic word
  similarity.
\newblock In \emph{Proceedings of the 11th International Workshop on Semantic
  Evaluation (SemEval-2017)}, pages 15--26.

\bibitem[{Chang et~al.(2008)Chang, Galley, and Manning}]{chang2008optimizing}
Pi-Chuan Chang, Michel Galley, and Christopher~D Manning. 2008.
\newblock Optimizing chinese word segmentation for machine translation
  performance.
\newblock In \emph{Proceedings of the third workshop on statistical machine
  translation}, pages 224--232.

\bibitem[{Conneau and Kiela(2018)}]{conneau2018senteval}
Alexis Conneau and Douwe Kiela. 2018.
\newblock Senteval: An evaluation toolkit for universal sentence
  representations.
\newblock \emph{LREC}.

\bibitem[{Conneau et~al.(2018{\natexlab{a}})Conneau, Lample, Ranzato, Denoyer,
  and Jegou}]{Conneau:2018:iclr_muse}
Alexis Conneau, Guillaume Lample, {Marc'Aurelio} Ranzato, Ludovic Denoyer, and
  Hervé Jegou. 2018{\natexlab{a}}.
\newblock Word translation without parallel data.
\newblock In \emph{ICLR}.

\bibitem[{Conneau et~al.(2018{\natexlab{b}})Conneau, Rinott, Lample, Williams,
  Bowman, Schwenk, and Stoyanov}]{conneau2018xnli}
Alexis Conneau, Ruty Rinott, Guillaume Lample, Adina Williams, Samuel~R.
  Bowman, Holger Schwenk, and Veselin Stoyanov. 2018{\natexlab{b}}.
\newblock Xnli: Evaluating cross-lingual sentence representations.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing}. Association for Computational Linguistics.

\bibitem[{Dai et~al.(2019)Dai, Yang, Yang, Cohen, Carbonell, Le, and
  Salakhutdinov}]{dai2019transformerxl}
Zihang Dai, Zhilin Yang, Yiming Yang, William~W. Cohen, Jaime Carbonell,
  Quoc~V. Le, and Ruslan Salakhutdinov. 2019.
\newblock \href {https://openreview.net/forum?id=HJePno0cYm} {Transformer-{XL}:
  Language modeling with longer-term dependency}.

\bibitem[{Devlin et~al.(2018)Devlin, Chang, Lee, and
  Toutanova}]{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}.

\bibitem[{Eriguchi et~al.(2018)Eriguchi, Johnson, Firat, Kazawa, and
  Macherey}]{eriguchi2018zero}
Akiko Eriguchi, Melvin Johnson, Orhan Firat, Hideto Kazawa, and Wolfgang
  Macherey. 2018.
\newblock Zero-shot cross-lingual classification using multilingual neural
  machine translation.
\newblock \emph{arXiv preprint arXiv:1809.04686}.

\bibitem[{Faruqui and Dyer(2014)}]{faruqui2014improving}
Manaal Faruqui and Chris Dyer. 2014.
\newblock Improving vector space word representations using multilingual
  correlation.
\newblock \emph{Proceedings of EACL}.

\bibitem[{Hendrycks and Gimpel(2016)}]{hendrycks2016bridging}
Dan Hendrycks and Kevin Gimpel. 2016.
\newblock Bridging nonlinearities and stochastic regularizers with gaussian
  error linear units.
\newblock \emph{arXiv preprint arXiv:1606.08415}.

\bibitem[{Hermann and Blunsom(2014)}]{hermann2014multilingual}
Karl~Moritz Hermann and Phil Blunsom. 2014.
\newblock Multilingual models for compositional distributed semantics.
\newblock \emph{arXiv preprint arXiv:1404.4641}.

\bibitem[{Hochreiter and Schmidhuber(1997)}]{hochreiter1997long}
Sepp Hochreiter and J{\"u}rgen Schmidhuber. 1997.
\newblock Long short-term memory.
\newblock \emph{Neural computation}, 9(8):1735--1780.

\bibitem[{Howard and Ruder(2018)}]{howard2018universal}
Jeremy Howard and Sebastian Ruder. 2018.
\newblock Universal language model fine-tuning for text classification.
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, volume~1, pages
  328--339.

\bibitem[{Johnson et~al.(2017)Johnson, Schuster, Le, Krikun, Wu, Chen, Thorat,
  Vi{\'e}gas, Wattenberg, Corrado et~al.}]{johnson2017google}
Melvin Johnson, Mike Schuster, Quoc~V Le, Maxim Krikun, Yonghui Wu, Zhifeng
  Chen, Nikhil Thorat, Fernanda Vi{\'e}gas, Martin Wattenberg, Greg Corrado,
  et~al. 2017.
\newblock Google’s multilingual neural machine translation system: Enabling
  zero-shot translation.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  5:339--351.

\bibitem[{Jozefowicz et~al.(2016)Jozefowicz, Vinyals, Schuster, Shazeer, and
  Wu}]{jozefowicz2016exploring}
Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu.
  2016.
\newblock Exploring the limits of language modeling.
\newblock \emph{arXiv preprint arXiv:1602.02410}.

\bibitem[{Kingma and Ba(2014)}]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba. 2014.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}.

\bibitem[{Koehn et~al.(2007)Koehn, Hoang, Birch, Callison-Burch, Federico,
  Bertoldi, Cowan, Shen, Moran, Zens et~al.}]{koehn2007moses}
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello
  Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard
  Zens, et~al. 2007.
\newblock Moses: Open source toolkit for statistical machine translation.
\newblock In \emph{Proceedings of the 45th annual meeting of the ACL on
  interactive poster and demonstration sessions}, pages 177--180. Association
  for Computational Linguistics.

\bibitem[{Lample et~al.(2018{\natexlab{a}})Lample, Conneau, Denoyer, and
  Ranzato}]{unsupNMTlample}
Guillaume Lample, Alexis Conneau, Ludovic Denoyer, and Marc'Aurelio Ranzato.
  2018{\natexlab{a}}.
\newblock Unsupervised machine translation using monolingual corpora only.
\newblock In \emph{ICLR}.

\bibitem[{Lample et~al.(2018{\natexlab{b}})Lample, Ott, Conneau, Denoyer, and
  Ranzato}]{lample2018phrase}
Guillaume Lample, Myle Ott, Alexis Conneau, Ludovic Denoyer, and Marc'Aurelio
  Ranzato. 2018{\natexlab{b}}.
\newblock Phrase-based \& neural unsupervised machine translation.
\newblock In \emph{EMNLP}.

\bibitem[{Mikolov et~al.(2010)Mikolov, Karafi{\'a}t, Burget,
  {\v{C}}ernock{\`y}, and Khudanpur}]{mikolov2010recurrent}
Tom{\'a}{\v{s}} Mikolov, Martin Karafi{\'a}t, Luk{\'a}{\v{s}} Burget, Jan
  {\v{C}}ernock{\`y}, and Sanjeev Khudanpur. 2010.
\newblock Recurrent neural network based language model.
\newblock In \emph{Eleventh Annual Conference of the International Speech
  Communication Association}.

\bibitem[{Mikolov et~al.(2013{\natexlab{a}})Mikolov, Le, and
  Sutskever}]{mikolov2013exploiting}
Tomas Mikolov, Quoc~V Le, and Ilya Sutskever. 2013{\natexlab{a}}.
\newblock Exploiting similarities among languages for machine translation.
\newblock \emph{arXiv preprint arXiv:1309.4168}.

\bibitem[{Mikolov et~al.(2013{\natexlab{b}})Mikolov, Sutskever, Chen, Corrado,
  and Dean}]{mikolov2013distributed}
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg~S Corrado, and Jeff Dean.
  2013{\natexlab{b}}.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In \emph{Advances in neural information processing systems}, pages
  3111--3119.

\bibitem[{Paszke et~al.(2017)Paszke, Gross, Chintala, Chanan, Yang, DeVito,
  Lin, Desmaison, Antiga, and Lerer}]{paszke2017automatic}
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary
  DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. 2017.
\newblock Automatic differentiation in pytorch.
\newblock \emph{NIPS 2017 Autodiff Workshop}.

\bibitem[{Radford et~al.(2018)Radford, Narasimhan, Salimans, and
  Sutskever}]{radford2018improving}
Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018.
\newblock \href
  {https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf}
  {Improving language understanding by generative pre-training}.
\newblock \emph{URL
  https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language\_understanding\_paper.pdf}.

\bibitem[{Ramachandran et~al.(2016)Ramachandran, Liu, and
  Le}]{ramachandran2016unsupervised}
Prajit Ramachandran, Peter~J Liu, and Quoc~V Le. 2016.
\newblock Unsupervised pretraining for sequence to sequence learning.
\newblock \emph{arXiv preprint arXiv:1611.02683}.

\bibitem[{Sennrich et~al.(2015)Sennrich, Haddow, and
  Birch}]{sennrich2015neural}
Rico Sennrich, Barry Haddow, and Alexandra Birch. 2015.
\newblock Neural machine translation of rare words with subword units.
\newblock In \emph{Proceedings of the 54th Annual Meeting of the Association
  for Computational Linguistics}, pages 1715--1725.

\bibitem[{Sennrich et~al.(2016)Sennrich, Haddow, and
  Birch}]{sennrich2016edinburgh}
Rico Sennrich, Barry Haddow, and Alexandra Birch. 2016.
\newblock Edinburgh neural machine translation systems for wmt 16.
\newblock \emph{arXiv preprint arXiv:1606.02891}.

\bibitem[{Smith et~al.(2017)Smith, Turban, Hamblin, and
  Hammerla}]{smith2017offline}
Samuel~L Smith, David~HP Turban, Steven Hamblin, and Nils~Y Hammerla. 2017.
\newblock Offline bilingual word vectors, orthogonal transformations and the
  inverted softmax.
\newblock \emph{International Conference on Learning Representations}.

\bibitem[{Socher et~al.(2013)Socher, Perelygin, Wu, Chuang, Manning, Ng, and
  Potts}]{socher2013recursive}
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher~D Manning,
  Andrew Ng, and Christopher Potts. 2013.
\newblock Recursive deep models for semantic compositionality over a sentiment
  treebank.
\newblock In \emph{Proceedings of the 2013 conference on empirical methods in
  natural language processing}, pages 1631--1642.

\bibitem[{Taylor(1953)}]{taylor1953cloze}
Wilson~L Taylor. 1953.
\newblock “cloze procedure”: A new tool for measuring readability.
\newblock \emph{Journalism Bulletin}, 30(4):415--433.

\bibitem[{Tiedemann(2012)}]{TIEDEMANN12.463}
Jörg Tiedemann. 2012.
\newblock Parallel data, tools and interfaces in opus.
\newblock In \emph{LREC}, Istanbul, Turkey. European Language Resources
  Association (ELRA).

\bibitem[{Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones,
  Gomez, Kaiser, and Polosukhin}]{transformer17}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  6000--6010.

\bibitem[{Wada and Iwata(2018)}]{wada2018unsupervised}
Takashi Wada and Tomoharu Iwata. 2018.
\newblock Unsupervised cross-lingual word embedding by multilingual neural
  language models.
\newblock \emph{arXiv preprint arXiv:1809.02306}.

\bibitem[{Wang et~al.(2018)Wang, Singh, Michael, Hill, Levy, and
  Bowman}]{wang2018glue}
Alex Wang, Amapreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel~R
  Bowman. 2018.
\newblock Glue: A multi-task benchmark and analysis platform for natural
  language understanding.
\newblock \emph{arXiv preprint arXiv:1804.07461}.

\bibitem[{Werbos(1990)}]{werbos1990backpropagation}
Paul~J Werbos. 1990.
\newblock Backpropagation through time: what it does and how to do it.
\newblock \emph{Proceedings of the IEEE}, 78(10):1550--1560.

\bibitem[{Williams et~al.(2017)Williams, Nangia, and Bowman}]{multinli:2017}
Adina Williams, Nikita Nangia, and Samuel~R. Bowman. 2017.
\newblock A broad-coverage challenge corpus for sentence understanding through
  inference.
\newblock In \emph{NAACL}.

\bibitem[{Xing et~al.(2015)Xing, Wang, Liu, and Lin}]{xing2015normalized}
Chao Xing, Dong Wang, Chao Liu, and Yiye Lin. 2015.
\newblock Normalized word embedding and orthogonal transform for bilingual word
  translation.
\newblock \emph{Proceedings of NAACL}.

\bibitem[{Ziemski et~al.(2016)Ziemski, Junczys-Dowmunt, and
  Pouliquen}]{ziemski2016united}
Michal Ziemski, Marcin Junczys-Dowmunt, and Bruno Pouliquen. 2016.
\newblock The united nations parallel corpus v1. 0.
\newblock In \emph{LREC}.

\end{thebibliography}
