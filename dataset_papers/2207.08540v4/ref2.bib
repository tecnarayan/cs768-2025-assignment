@article{zhang2020optimal,
  title={Optimal Algorithms for Convex Nested Stochastic Composite Optimization},
  author={Zhang, Zhe and Lan, Guanghui},
  journal={arXiv preprint arXiv:2011.10076},
  year={2020}
}

@article{bamber1975area,
	title={The area above the ordinal dominance graph and the area below the receiver operating characteristic graph},
	author={Bamber, Donald},
	journal={Journal of mathematical psychology},
	volume={12},
	number={4},
	pages={387--415},
	year={1975},
	publisher={Elsevier}
}
@inproceedings{eban2017scalable,
	title={Scalable learning of non-decomposable objectives},
	author={Eban, Elad and Schain, Mariano and Mackey, Alan and Gordon, Ariel and Rifkin, Ryan and Elidan, Gal},
	booktitle={Artificial intelligence and statistics},
	pages={832--840},
	year={2017},
	organization={PMLR}
}

@article{qin2010general,
	title={A general approximation framework for direct optimization of information retrieval measures},
	author={Qin, Tao and Liu, Tie-Yan and Li, Hang},
	journal={Information retrieval},
	volume={13},
	number={4},
	pages={375--397},
	year={2010},
	publisher={Springer}
}

@article{narasimhan2019optimizing,
	title={Optimizing Generalized Rate Metrics with Three Players},
	author={Narasimhan, Harikrishna and Cotter, Andrew and Gupta, Maya},
	journal={Advances in Neural Information Processing Systems},
	volume={32},
	pages={10747--10758},
	year={2019}
}

@article{goldberger2004neighbourhood,
	title={Neighbourhood components analysis},
	author={Goldberger, Jacob and Hinton, Geoffrey E and Roweis, Sam and Salakhutdinov, Russ R},
	journal={Advances in neural information processing systems},
	volume={17},
	year={2004},
	publisher={Citeseer}
}

@article{li2014top,
  title={Top rank optimization in linear time},
  author={Li, Nan and Jin, Rong and Zhou, Zhi-Hua},
  journal={arXiv preprint arXiv:1410.1462},
  year={2014}
}

@article{guo2021stochastic,
	title={On Stochastic Moving-Average Estimators for Non-Convex Optimization},
	author={Guo, Zhishuai and Xu, Yi and Yin, Wotao and Jin, Rong and Yang, Tianbao},
	journal={arXiv preprint arXiv:2104.14840},
	year={2021}
}

@article{boyd2012accuracy,
  title={Accuracy at the Top},
  author={Boyd, Stephen and Cortes, Corinna and Mohri, Mehryar and Radovanovic, Ana},
  journal={Advances in Neural Information Processing Systems},
  volume={25},
  pages={953--961},
  year={2012}
}

@inproceedings{agarwal2011infinite,
  title={The infinite push: A new support vector ranking algorithm that directly optimizes accuracy at the absolute top of the list},
  author={Agarwal, Shivani},
  booktitle={Proceedings of the 2011 SIAM International Conference on Data Mining},
  pages={839--850},
  year={2011},
  organization={SIAM}
}

@inproceedings{finn2017model,
	title={Model-agnostic meta-learning for fast adaptation of deep networks},
	author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
	booktitle={International Conference on Machine Learning},
	pages={1126--1135},
	year={2017},
	organization={PMLR}
}
@article{mokhtari2020stochastic,
	title={Stochastic conditional gradient methods: From convex minimization to submodular maximization},
	author={Mokhtari, Aryan and Hassani, Hamed and Karbasi, Amin},
	journal={Journal of machine learning research},
	year={2020}
}

@article{dang2015stochastic,
	title={Stochastic block mirror descent methods for nonsmooth and stochastic optimization},
	author={Dang, Cong D and Lan, Guanghui},
	journal={SIAM Journal on Optimization},
	volume={25},
	number={2},
	pages={856--881},
	year={2015},
	publisher={SIAM}
}

@inproceedings{gower2019sgd,
	title={SGD: General analysis and improved rates},
	author={Gower, Robert Mansel and Loizou, Nicolas and Qian, Xun and Sailanbayev, Alibek and Shulgin, Egor and Richt{\'a}rik, Peter},
	booktitle={International Conference on Machine Learning},
	pages={5200--5209},
	year={2019},
	organization={PMLR}
}

@article{wang2016accelerating,
	title={Accelerating stochastic composition optimization},
	author={Wang, Mengdi and Liu, Ji and Fang, Ethan},
	journal={Advances in Neural Information Processing Systems},
	volume={29},
	pages={1714--1722},
	year={2016}
}



@inproceedings{lian2017finite,
	title={Finite-sum composition optimization via variance reduced gradient descent},
	author={Lian, Xiangru and Wang, Mengdi and Liu, Ji},
	booktitle={Artificial Intelligence and Statistics},
	pages={1159--1167},
	year={2017},
	organization={PMLR}
}

@inproceedings{finn2019online,
	title={Online meta-learning},
	author={Finn, Chelsea and Rajeswaran, Aravind and Kakade, Sham and Levine, Sergey},
	booktitle={International Conference on Machine Learning},
	pages={1920--1930},
	year={2019},
	organization={PMLR}
}

@inproceedings{franceschi2018bilevel,
	title={Bilevel programming for hyperparameter optimization and meta-learning},
	author={Franceschi, Luca and Frasconi, Paolo and Salzo, Saverio and Grazzi, Riccardo and Pontil, Massimiliano},
	booktitle={International Conference on Machine Learning},
	pages={1568--1577},
	year={2018},
	organization={PMLR}
}

@article{rajeswaran2019meta,
	title={Meta-learning with implicit gradients},
	author={Rajeswaran, Aravind and Finn, Chelsea and Kakade, Sham and Levine, Sergey},
	journal={arXiv preprint arXiv:1909.04630},
	year={2019}
}

@inproceedings{wang2020global,
	title={On the global optimality of model-agnostic meta-learning},
	author={Wang, Lingxiao and Cai, Qi and Yang, Zhuoran and Wang, Zhaoran},
	booktitle={International Conference on Machine Learning},
	pages={9837--9846},
	year={2020},
	organization={PMLR}
}

@article{ji2020convergence,
	title={Convergence of Meta-Learning with Task-Specific Adaptation over Partial Parameters},
	author={Ji, Kaiyi and Lee, Jason D and Liang, Yingbin and Poor, H Vincent},
	journal={arXiv preprint arXiv:2006.09486},
	year={2020}
}

@article{lixiang2019convergence,
	title={On the convergence of fedavg on non-iid data},
	author={Li, Xiang and Huang, Kaixuan and Yang, Wenhao and Wang, Shusen and Zhang, Zhihua},
	journal={arXiv preprint arXiv:1907.02189},
	year={2019}
}

@inproceedings{Snell2017PrototypicalNF,
  title={Prototypical Networks for Few-shot Learning},
  author={J. Snell and Kevin Swersky and R. Zemel},
  booktitle={NIPS},
  year={2017}
}

@article{Chen2021ASS,
  title={A Single-Timescale Stochastic Bilevel Optimization Method},
  author={Tianyi Chen and Yuejiao Sun and W. Yin},
  journal={ArXiv},
  year={2021},
  volume={abs/2102.04671}
}

@article{Ji2020ProvablyFA,
  title={Provably Faster Algorithms for Bilevel Optimization and Applications to Meta-Learning},
  author={Kaiyi Ji and Junjie Yang and Yingbin Liang},
  journal={ArXiv},
  year={2020},
  volume={abs/2010.07962}
}

@inproceedings{Vinyals2016MatchingNF,
  title={Matching Networks for One Shot Learning},
  author={Oriol Vinyals and C. Blundell and T. Lillicrap and K. Kavukcuoglu and Daan Wierstra},
  booktitle={NIPS},
  year={2016}
}

@inproceedings{Ravi2017OptimizationAA,
  title={Optimization as a Model for Few-Shot Learning},
  author={S. Ravi and H. Larochelle},
  booktitle={ICLR},
  year={2017}
}

@article{ji2020multistep,
	title={Multi-Step Model-Agnostic Meta-Learning: Convergence and Improved
	Algorithms},
	author={Ji, Kaiyi and Yang, Junjie and Liang, Yingbin},
	journal={arXiv preprint arXiv:2002.07836},
	year={2020}
}

@article{Hanzely2020FederatedLO,
	title={Federated Learning of a Mixture of Global and Local Models},
	author={Filip Hanzely and Peter Richt{\'a}rik},
	journal={ArXiv},
	year={2020},
	volume={abs/2002.05516}
}

@article{Jiang2019ImprovingFL,
	title={Improving Federated Learning Personalization via Model Agnostic Meta Learning},
	author={Yihan Jiang and Jakub Konecn{\'y} and Keith Rush and S. Kannan},
	journal={ArXiv},
	year={2019},
	volume={abs/1909.12488}
}

@article{li2017meta,
	title={Meta-sgd: Learning to learn quickly for few-shot learning},
	author={Li, Zhenguo and Zhou, Fengwei and Chen, Fei and Li, Hang},
	journal={arXiv preprint arXiv:1707.09835},
	year={2017}
}

@article{nichol2018first,
	title={On first-order meta-learning algorithms},
	author={Nichol, Alex and Achiam, Joshua and Schulman, John},
	journal={arXiv preprint arXiv:1803.02999},
	year={2018}
}

@article{finn2018probabilistic,
	title={Probabilistic model-agnostic meta-learning},
	author={Finn, Chelsea and Xu, Kelvin and Levine, Sergey},
	journal={arXiv preprint arXiv:1806.02817},
	year={2018}
}



@inproceedings{karimireddy2020scaffold,
	title={SCAFFOLD: Stochastic controlled averaging for federated learning},
	author={Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
	booktitle={International Conference on Machine Learning},
	pages={5132--5143},
	year={2020},
	organization={PMLR}
}

@article{collins2020distribution,
	title={Distribution-agnostic model-agnostic meta-learning},
	author={Collins, Liam and Mokhtari, Aryan and Shakkottai, Sanjay},
	journal={arXiv preprint arXiv:2002.04766},
	year={2020}
}

@article{behl2019alpha,
	title={Alpha maml: Adaptive model-agnostic meta-learning},
	author={Behl, Harkirat Singh and Baydin, At{\i}l{\i}m G{\"u}nes and Torr, Philip HS},
	journal={arXiv preprint arXiv:1905.07435},
	year={2019}
}


@article{grant2018recasting,
	title={Recasting gradient-based meta-learning as hierarchical bayes},
	author={Grant, Erin and Finn, Chelsea and Levine, Sergey and Darrell, Trevor and Griffiths, Thomas},
	journal={arXiv preprint arXiv:1801.08930},
	year={2018}
}

@inproceedings{balcan2019provable,
	title={Provable guarantees for gradient-based meta-learning},
	author={Balcan, Maria-Florina and Khodak, Mikhail and Talwalkar, Ameet},
	booktitle={International Conference on Machine Learning},
	pages={424--433},
	year={2019},
	organization={PMLR}
}

@inproceedings{yoon2018bayesian,
	title={Bayesian model-agnostic meta-learning},
	author={Yoon, Jaesik and Kim, Taesup and Dia, Ousmane and Kim, Sungwoong and Bengio, Yoshua and Ahn, Sungjin},
	booktitle={Proceedings of the 32nd International Conference on Neural Information Processing Systems},
	pages={7343--7353},
	year={2018}
}

@article{raghu2019rapid,
	title={Rapid learning or feature reuse? towards understanding the effectiveness of maml},
	author={Raghu, Aniruddh and Raghu, Maithra and Bengio, Samy and Vinyals, Oriol},
	journal={arXiv preprint arXiv:1909.09157},
	year={2019}
}

@article{antoniou2018train,
	title={How to train your maml},
	author={Antoniou, Antreas and Edwards, Harrison and Storkey, Amos},
	journal={arXiv preprint arXiv:1810.09502},
	year={2018}
}

@inproceedings{fallah2020convergence,
	title={On the convergence theory of gradient-based model-agnostic meta-learning algorithms},
	author={Fallah, Alireza and Mokhtari, Aryan and Ozdaglar, Asuman},
	booktitle={International Conference on Artificial Intelligence and Statistics},
	pages={1082--1092},
	year={2020},
	organization={PMLR}
}

@article{fallah2020personalized,
	title={Personalized federated learning: A meta-learning approach},
	author={Fallah, Alireza and Mokhtari, Aryan and Ozdaglar, Asuman},
	journal={arXiv preprint arXiv:2002.07948},
	year={2020}
}

@article{richtarik2016parallel,
	title={Parallel coordinate descent methods for big data optimization},
	author={Richt{\'a}rik, Peter and Tak{\'a}c, Martin},
	journal={Mathematical Programming},
	volume={156},
	number={1-2},
	pages={433--484},
	year={2016},
	publisher={Springer}
}

@inproceedings{NEURIPS2020_f4f1f13c,
 author = {T. Dinh, Canh and Tran, Nguyen and Nguyen, Josh},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {21394--21405},
 publisher = {Curran Associates, Inc.},
 title = {Personalized Federated Learning with Moreau Envelopes},
 url = {https://proceedings.neurips.cc/paper/2020/file/f4f1f13c8289ac1b1ee0ff176b56fc60-Paper.pdf},
 volume = {33},
 year = {2020}
}


@article{DBLP:journals/corr/abs-2002-03755,
  author    = {Rasul Tutunov and
               Minne Li and
               Jun Wang and
               Haitham Bou{-}Ammar},
  title     = {Compositional {ADAM:} An Adaptive Compositional Solver},
  journal   = {CoRR},
  volume    = {abs/2002.03755},
  year      = {2020},
  url       = {https://arxiv.org/abs/2002.03755},
  archivePrefix = {arXiv},
  eprint    = {2002.03755},
  timestamp = {Wed, 12 Feb 2020 16:38:55 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2002-03755.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{journals/corr/abs-1801-00631,
  abstract = {Although deep learning has historical roots going back decades, neither the term “deep learning” nor the approach was popular just over five years ago, when the field was reignited by papers such as Krizhevsky, Sutskever and Hinton’s now classic 2012 (Krizhevsky, Sutskever, & Hinton, 2012)deep net model of Imagenet.
What has the field discovered in the five subsequent years? Against a background of considerable progress in areas such as speech recognition, image recognition, and game playing, and considerable enthusiasm in the popular press, I present ten concerns for deep learning, and suggest that deep learning must be supplemented by other techniques if we are to reach artificial general intelligence. },
  added-at = {2018-06-22T21:24:06.000+0200},
  author = {Marcus, Gary},
  biburl = {https://www.bibsonomy.org/bibtex/2576d50f9b2333772cd7bf2224e685485/huiyangsfsu},
  ee = {http://arxiv.org/abs/1801.00631},
  interhash = {a3e62c52ef8d1f7cc5091b739b218a94},
  intrahash = {576d50f9b2333772cd7bf2224e685485},
  journal = {CoRR},
  keywords = {criticism deep learning},
  timestamp = {2018-06-22T21:24:06.000+0200},
  title = {Deep Learning: A Critical Appraisal.},
  url = {https://arxiv.org/pdf/1801.00631.pdf},
  volume = {abs/1801.00631},
  year = 2018
}



@article{thompson1972principal,
	title={Principal submatrices IX: Interlacing inequalities for singular values of submatrices},
	author={Thompson, Robert C},
	journal={Linear Algebra and its Applications},
	volume={5},
	number={1},
	pages={1--12},
	year={1972},
	publisher={North-Holland}
}

@article{wang2021momentum,
	title={Momentum Accelerates the Convergence of Stochastic AUPRC Maximization},
	author={Wang, Guanghui and Yang, Ming and Zhang, Lijun and Yang, Tianbao},
	journal={arXiv preprint arXiv:2107.01173},
	year={2021}
}

@article{qi2021stochastic,
	title={Stochastic Optimization of Areas Under Precision-Recall Curves with Provable Convergence},
	author={Qi, Qi and Luo, Youzhi and Xu, Zhao and Ji, Shuiwang and Yang, Tianbao},
	journal={Advances in Neural Information Processing Systems},
	volume={35},
	year={2021}
}


@article{Ghadimi2020AST,
  title={A Single Timescale Stochastic Approximation Method for Nested Stochastic Optimization},
  author={S. Ghadimi and Andrzej Ruszczy'nski and Mengdi Wang},
  journal={SIAM J. Optim.},
  year={2020},
  volume={30},
  pages={960-979}
}

@article{Song2020ESMAMLSH,
  title={ES-MAML: Simple Hessian-Free Meta Learning},
  author={Xingyou Song and W. Gao and Yuxiang Yang and Krzysztof Choromanski and Aldo Pacchiano and Yunhao Tang},
  journal={ArXiv},
  year={2020},
  volume={abs/1910.01215}
}
@inproceedings{Zhou2019EfficientML,
  title={Efficient Meta Learning via Minibatch Proximal Update},
  author={Pan Zhou and X. Yuan and Huan Xu and S. Yan and Jiashi Feng},
  booktitle={NeurIPS},
  year={2019}
}

@Article{VR-Review2020,
  author  = {Gower, Robert M. and Schmidt, Mark and Bach, Francis and Richt\'{a}rik, Peter},
  journal = {Proceedings of the IEEE},
  title   = {Variance-reduced methods for machine learning},
  year    = {2020},
  number  = {11},
  pages   = {1968--1983},
  volume  = {108},
}

@article{wang2017stochastic,
	title={Stochastic compositional gradient descent: algorithms for minimizing compositions of expected-value functions},
	author={Wang, Mengdi and Fang, Ethan X and Liu, Han},
	journal={Mathematical Programming},
	volume={161},
	number={1-2},
	pages={419--449},
	year={2017},
	publisher={Springer}
}

@article{hu2020biased,
	title={Biased Stochastic First-Order Methods for Conditional Stochastic Optimization and Applications in Meta Learning},
	author={Hu, Yifan and Zhang, Siqi and Chen, Xin and He, Niao},
	journal={Advances in Neural Information Processing Systems},
	volume={33},
	year={2020}
}

@inproceedings{alistarh2017qsgd,
  title={{QSGD}: {C}ommunication-efficient {SGD} via gradient quantization and encoding},
  author={Alistarh, Dan and Grubic, Demjan and Li, Jerry and Tomioka, Ryota and Vojnovic, Milan},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1709--1720},
  year={2017}
}


@InProceedings{Allen-Zhu2016,
  author    = {Zeyuan Allen-Zhu and Elad Hazan},
  title     = {Variance reduction for faster non-convex optimization},
  booktitle = {The 33th International Conference on Machine Learning},
  year      = {2016},
  pages     = {699--707},
  journal   = {arXiv:1603.05643},
}



@Article{biased2020,
  author  = {Aleksandr Beznosikov and Samuel Horv\'{a}th and Peter Richt\'{a}rik and Mher Safaryan},
  title   = {On Biased Compression for Distributed Learning},
  journal = {arXiv:2002.12410},
  year    = {2020},
}


@Article{UP2020,
  author  = {Mher Safaryan and Egor Shulgin and Peter Richt\'{a}rik},
  title   = {Uncertainty Principle for Communication Compression in Distributed and Federated Learning and the Search for an Optimal Compressor},
  journal = {arXiv preprint arXiv:2002.08958},
  year    = {2020},
}



@article{johnson2013accelerating,
	title={Accelerating stochastic gradient descent using predictive variance reduction},
	author={Johnson, Rie and Zhang, Tong},
	journal={Advances in neural information processing systems},
	volume={26},
	pages={315--323},
	year={2013},
	publisher={Citeseer}
}

@techreport{xu2020compressed,
	title={Compressed communication for distributed deep learning: Survey and quantitative evaluation},
	author={Xu, Hang and Ho, Chen-Yu and Abdelmoniem, Ahmed M. and Dutta, Aritra and Bergou, El Houcine and Karatsenidis, Konstantinos and Canini, Marco and Kalnis, Panos},
	year={2020}
}

@inproceedings{huang2017densely,
	title={Densely connected convolutional networks},
	author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={4700--4708},
	year={2017}
}

@article{dalcin2005mpi,
	title={{MPI} for {P}ython},
	author={Dalc{\'\i}n, Lisandro and Paz, Rodrigo and Storti, Mario},
	journal={Journal of Parallel and Distributed Computing},
	volume={65},
	number={9},
	pages={1108--1115},
	year={2005},
	publisher={Elsevier}
}

@article{kingma2013auto,
	title={Auto-encoding variational bayes},
	author={Kingma, Diederik P. and Welling, Max},
	journal={arXiv preprint arXiv:1312.6114},
	year={2013}
}

@inproceedings{chen2018isolating,
  title={Isolating sources of disentanglement in {VAEs}},
  author={Chen, Ricky T. Q. and Li, Xuechen and Grosse, Roger and Duvenaud, David},
  booktitle={Proceedings of the 32nd International Conference on Neural Information Processing Systems},
  pages={2615--2625},
  year={2018}
}

@article{paszke2017automatic,
	title={Automatic differentiation in {PyTorch}},
	author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
	year={2017}
}

@inproceedings{he2016deep,
	title={Deep residual learning for image recognition},
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={770--778},
	year={2016}
}

@article{devlin2018bert,
	title={{BERT}: Pre-training of deep bidirectional transformers for language understanding},
	author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	journal={arXiv preprint arXiv:1810.04805},
	year={2018}
}

@article{hinton2015distilling,
	title={Distilling the knowledge in a neural network},
	author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
	journal={arXiv preprint arXiv:1503.02531},
	year={2015}
}

@article{horvath2019stochastic,
	title={Stochastic distributed learning with gradient quantization and variance reduction},
	author={Horv{\'a}th, Samuel and Kovalev, Dmitry and Mishchenko, Konstantin and Stich, Sebastian and Richt{\'a}rik, Peter},
	journal={arXiv preprint arXiv:1904.05115},
	year={2019}
}

@inproceedings{defazio2019ineffectiveness,
	title={On the ineffectiveness of variance reduced optimization for deep learning},
	author={Defazio, Aaron and Bottou, L{\'e}on},
	booktitle={Advances in Neural Information Processing Systems},
	pages={1755--1765},
	year={2019}
}

@InProceedings{bernstein2018signsgd,
  title = 	 {Sign{SGD}: Compressed Optimisation for Non-Convex Problems},
  author = 	 {Bernstein, Jeremy and Wang, Yu-Xiang and Azizzadenesheli, Kamyar and Anandkumar, Animashree},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {560--569},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR},
}

@article{mishchenko2019distributed,
  title={Distributed Learning with Compressed Gradient Differences},
  author={Mishchenko, Konstantin and Gorbunov, Eduard and Tak{\'a}{\v{c}}, Martin and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:1901.09269},
  year={2019}
}

@InProceedings{Gower2019,
  author    = {Gower, Robert Mansel and Loizou, Nicolas and Qian, Xun and Sailanbayev, Alibek and Shulgin, Egor and Richt\'{a}rik, Peter},
  title     = {{SGD}: General Analysis and Improved Rates},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  year      = {2019},
  editor    = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume    = {97},
  series    = {Proceedings of Machine Learning Research},
  pages     = {5200--5209},
  address   = {Long Beach, California, USA},
  month     = {09--15 Jun},
  publisher = {PMLR},
}

@book{nesterov2013introductory,
  title={Introductory lectures on convex optimization: A basic course},
  author={Nesterov, Yurii},
  volume={87},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@inproceedings{dutta2020discrepancy,
  title={On the Discrepancy between the Theoretical Analysis and Practical Implementations of Compressed Communication for Distributed Deep Learning},
  author={Dutta, Aritra and Bergou, El Houcine and Abdelmoniem, Ahmed M. and Ho, Chen-Yu and Sahu, Atal Narayan and Canini, Marco and Kalnis, Panos},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={3817--3824},
  year={2020}
}

@article{sapio2019scaling,
  title={Scaling distributed machine learning with in-network aggregation},
  author={Sapio, Amedeo and Canini, Marco and Ho, Chen-Yu and Nelson, Jacob and Kalnis, Panos and Kim, Changhoon and Krishnamurthy, Arvind and Moshref, Masoud and Ports, Dan RK and Richt{\'a}rik, Peter},
  journal={To appear in 18th USENIX Symposium on Networked Systems Design and Implementation},
  year={2020}
}

@inproceedings{karimireddy2019error,
  title={Error Feedback Fixes {SignSGD} and other Gradient Compression Schemes},
  author={Karimireddy, Sai Praneeth and Rebjock, Quentin and Stich, Sebastian and Jaggi, Martin},
  booktitle={International Conference on Machine Learning},
  pages={3252--3261},
  year={2019}
}

@inproceedings{stich2018sparsified,
  title={Sparsified {SGD} with memory},
  author={Stich, Sebastian U. and Cordonnier, Jean-Baptiste and Jaggi, Martin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4447--4458},
  year={2018}
}

@article{horvath2019natural,
  title={Natural compression for distributed deep learning},
  author={Horv\'{a}th, Samuel and Ho, Chen-Yu and Horv\'{a}th, \v{L}udov\'{i}t and Sahu, Atal Narayan and Canini, Marco and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:1905.10988},
  year={2019}
}

@inproceedings{kovalev2020don,
	title={Don’t jump through hoops and remove those loops: {SVRG} and {K}atyusha are better without the outer loop},
	author={Kovalev, Dmitry and Horv{\'a}th, Samuel and Richt{\'a}rik, Peter},
	booktitle={Algorithmic Learning Theory},
	pages={451--467},
	year={2020},
	organization={PMLR}
}

@article{mishchenko2020random,
  title={Random Reshuffling: Simple Analysis with Vast Improvements},
  author={Mishchenko, Konstantin and Khaled, Ahmed and Richt{\'a}rik, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@incollection{bottou2012stochastic,
  title={Stochastic gradient descent tricks},
  author={Bottou, L{\'e}on},
  booktitle={Neural networks: Tricks of the trade},
  pages={421--436},
  year={2012},
  publisher={Springer}
}

