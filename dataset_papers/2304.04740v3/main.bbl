\begin{thebibliography}{62}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Anderson(1982)]{Anderson1982ReversetimeDE}
Anderson, B. D.~O.
\newblock Reverse-time diffusion equation models.
\newblock \emph{Stochastic Processes and their Applications}, 12:\penalty0
  313--326, 1982.

\bibitem[Ba et~al.(2016)Ba, Kiros, and Hinton]{Ba2016LayerN}
Ba, J., Kiros, J.~R., and Hinton, G.~E.
\newblock Layer normalization.
\newblock \emph{ArXiv}, abs/1607.06450, 2016.

\bibitem[Bortoli et~al.(2022)Bortoli, Mathieu, Hutchinson, Thornton, Teh, and
  Doucet]{Bortoli2022RiemannianSG}
Bortoli, V.~D., Mathieu, E., Hutchinson, M., Thornton, J., Teh, Y.~W., and
  Doucet, A.
\newblock Riemannian score-based generative modeling.
\newblock \emph{ArXiv}, abs/2202.02763, 2022.

\bibitem[Bubeck et~al.(2015)Bubeck, Eldan, and Lehec]{Bubeck2015FiniteTimeAO}
Bubeck, S., Eldan, R., and Lehec, J.
\newblock Finite-time analysis of projected langevin monte carlo.
\newblock In \emph{NIPS}, 2015.

\bibitem[Cattiaux(1988)]{Cattiaux1988TimeRO}
Cattiaux, P.
\newblock Time reversal of diffusion processes with a boundary condition.
\newblock \emph{Stochastic Processes and their Applications}, 28:\penalty0
  275--292, 1988.

\bibitem[Chen et~al.(2018)Chen, Rubanova, Bettencourt, and
  Duvenaud]{Chen2018NeuralOD}
Chen, T.~Q., Rubanova, Y., Bettencourt, J., and Duvenaud, D.~K.
\newblock Neural ordinary differential equations.
\newblock In \emph{Neural Information Processing Systems}, 2018.

\bibitem[Child et~al.(2019)Child, Gray, Radford, and
  Sutskever]{Child2019GeneratingLS}
Child, R., Gray, S., Radford, A., and Sutskever, I.
\newblock Generating long sequences with sparse transformers.
\newblock \emph{ArXiv}, abs/1904.10509, 2019.

\bibitem[Chrabaszcz et~al.(2017)Chrabaszcz, Loshchilov, and
  Hutter]{Chrabaszcz2017ADV}
Chrabaszcz, P., Loshchilov, I., and Hutter, F.
\newblock A downsampled variant of imagenet as an alternative to the cifar
  datasets.
\newblock \emph{ArXiv}, abs/1707.08819, 2017.

\bibitem[Dhariwal \& Nichol(2021)Dhariwal and Nichol]{Dhariwal2021DiffusionMB}
Dhariwal, P. and Nichol, A.
\newblock Diffusion models beat gans on image synthesis.
\newblock \emph{ArXiv}, abs/2105.05233, 2021.

\bibitem[Dormand \& Prince(1980)Dormand and Prince]{Dormand1980AFO}
Dormand, J.~R. and Prince, P.~J.
\newblock A family of embedded runge-kutta formulae.
\newblock \emph{Journal of Computational and Applied Mathematics}, 6:\penalty0
  19--26, 1980.

\bibitem[Efron(2011)]{Efron2011TweediesFA}
Efron, B.
\newblock Tweedieâ€™s formula and selection bias.
\newblock \emph{Journal of the American Statistical Association}, 106:\penalty0
  1602 -- 1614, 2011.

\bibitem[Evans(2010)]{evans10}
Evans, L.~C.
\newblock \emph{Partial differential equations}.
\newblock American Mathematical Society, Providence, R.I., 2010.
\newblock ISBN 9780821849743 0821849743.

\bibitem[Harrison \& Reiman(1981)Harrison and Reiman]{Harrison1981ReflectedBM}
Harrison, J.~M. and Reiman, M.~I.
\newblock Reflected brownian motion on an orthant.
\newblock \emph{Annals of Probability}, 9:\penalty0 302--308, 1981.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and
  Hochreiter]{Heusel2017GANsTB}
Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., and Hochreiter, S.
\newblock Gans trained by a two time-scale update rule converge to a local nash
  equilibrium.
\newblock In \emph{NIPS}, 2017.

\bibitem[Ho \& Salimans(2022)Ho and Salimans]{Ho2022ClassifierFreeDG}
Ho, J. and Salimans, T.
\newblock Classifier-free diffusion guidance.
\newblock \emph{ArXiv}, abs/2207.12598, 2022.

\bibitem[Ho et~al.(2019)Ho, Chen, Srinivas, Duan, and Abbeel]{Ho2019FlowIF}
Ho, J., Chen, X., Srinivas, A., Duan, Y., and Abbeel, P.
\newblock Flow++: Improving flow-based generative models with variational
  dequantization and architecture design.
\newblock \emph{ArXiv}, abs/1902.00275, 2019.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{Ho2020DenoisingDP}
Ho, J., Jain, A., and Abbeel, P.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{ArXiv}, abs/2006.11239, 2020.

\bibitem[Hoogeboom et~al.(2021)Hoogeboom, Gritsenko, Bastings, Poole, van~den
  Berg, and Salimans]{Hoogeboom2021AutoregressiveDM}
Hoogeboom, E., Gritsenko, A.~A., Bastings, J., Poole, B., van~den Berg, R., and
  Salimans, T.
\newblock Autoregressive diffusion models.
\newblock \emph{ArXiv}, abs/2110.02037, 2021.

\bibitem[Huang et~al.(2021)Huang, Lim, and Courville]{Huang2021AVP}
Huang, C.-W., Lim, J.~H., and Courville, A.~C.
\newblock A variational perspective on diffusion-based generative models and
  score matching.
\newblock In \emph{Neural Information Processing Systems}, 2021.

\bibitem[Hutchinson(1989)]{Hutchinson1989ASE}
Hutchinson, M.~F.
\newblock A stochastic estimator of the trace of the influence matrix for
  laplacian smoothing splines.
\newblock \emph{Communications in Statistics - Simulation and Computation},
  18:\penalty0 1059--1076, 1989.

\bibitem[Hyv{\"a}rinen(2005)]{Hyvrinen2005EstimationON}
Hyv{\"a}rinen, A.
\newblock Estimation of non-normalized statistical models by score matching.
\newblock \emph{J. Mach. Learn. Res.}, 6:\penalty0 695--709, 2005.

\bibitem[Hyv{\"a}rinen(2007)]{Hyvrinen2007SomeEO}
Hyv{\"a}rinen, A.
\newblock Some extensions of score matching.
\newblock \emph{Comput. Stat. Data Anal.}, 51:\penalty0 2499--2512, 2007.

\bibitem[Jing et~al.(2022{\natexlab{a}})Jing, Corso, Berlinghieri, and
  Jaakkola]{Jing2022SubspaceDG}
Jing, B., Corso, G., Berlinghieri, R., and Jaakkola, T.
\newblock Subspace diffusion generative models.
\newblock In \emph{European Conference on Computer Vision}, 2022{\natexlab{a}}.

\bibitem[Jing et~al.(2022{\natexlab{b}})Jing, Corso, Chang, Barzilay, and
  Jaakkola]{Jing2022TorsionalDF}
Jing, B., Corso, G., Chang, J., Barzilay, R., and Jaakkola, T.
\newblock Torsional diffusion for molecular conformer generation.
\newblock \emph{ArXiv}, abs/2206.01729, 2022{\natexlab{b}}.

\bibitem[Jolicoeur-Martineau et~al.(2020)Jolicoeur-Martineau, Piche-Taillefer,
  des Combes, and Mitliagkas]{JolicoeurMartineau2020AdversarialSM}
Jolicoeur-Martineau, A., Piche-Taillefer, R., des Combes, R.~T., and
  Mitliagkas, I.
\newblock Adversarial score matching and improved sampling for image
  generation.
\newblock \emph{ArXiv}, abs/2009.05475, 2020.

\bibitem[Karras et~al.(2022)Karras, Aittala, Aila, and
  Laine]{Karras2022ElucidatingTD}
Karras, T., Aittala, M., Aila, T., and Laine, S.
\newblock Elucidating the design space of diffusion-based generative models.
\newblock \emph{ArXiv}, abs/2206.00364, 2022.

\bibitem[Kim et~al.(2021)Kim, Shin, Song, Kang, and Moon]{Kim2021SoftTA}
Kim, D., Shin, S.-J., Song, K., Kang, W., and Moon, I.-C.
\newblock Soft truncation: A universal training technique of score-based
  diffusion model for high precision score estimation.
\newblock In \emph{International Conference on Machine Learning}, 2021.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{Kingma2014AdamAM}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{CoRR}, abs/1412.6980, 2014.

\bibitem[Kingma et~al.(2021)Kingma, Salimans, Poole, and
  Ho]{Kingma2021VariationalDM}
Kingma, D.~P., Salimans, T., Poole, B., and Ho, J.
\newblock Variational diffusion models.
\newblock \emph{ArXiv}, abs/2107.00630, 2021.

\bibitem[Koehler et~al.(2022)Koehler, Heckett, and
  Risteski]{Koehler2022StatisticalEO}
Koehler, F., Heckett, A., and Risteski, A.
\newblock Statistical efficiency of score matching: The view from isoperimetry.
\newblock \emph{ArXiv}, abs/2210.00726, 2022.

\bibitem[Krizhevsky(2009)]{Krizhevsky2009LearningML}
Krizhevsky, A.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Lee et~al.(2021)Lee, Chang, Jiang, Zhang, Tu, and
  Liu]{Lee2021ViTGANTG}
Lee, K., Chang, H., Jiang, L., Zhang, H., Tu, Z., and Liu, C.
\newblock Vitgan: Training gans with vision transformers.
\newblock \emph{ArXiv}, abs/2107.04589, 2021.

\bibitem[Li et~al.(2022)Li, Thickstun, Gulrajani, Liang, and
  Hashimoto]{Li2022DiffusionLMIC}
Li, X.~L., Thickstun, J., Gulrajani, I., Liang, P., and Hashimoto, T.
\newblock Diffusion-lm improves controllable text generation.
\newblock \emph{ArXiv}, abs/2205.14217, 2022.

\bibitem[Liu(1993)]{Liu1993NumericalAT}
Liu, Y.
\newblock Numerical approaches to stochastic differential equations with
  boundary conditions.
\newblock 1993.

\bibitem[{\O}ksendal(1987)]{ksendal1987StochasticDE}
{\O}ksendal, B.
\newblock Stochastic differential equations : an introduction with
  applications.
\newblock \emph{Journal of the American Statistical Association}, 82:\penalty0
  948, 1987.

\bibitem[Park \& Kim(2021)Park and Kim]{Park2021StyleformerTB}
Park, J. and Kim, Y.
\newblock Styleformer: Transformer based generative adversarial networks with
  style vector.
\newblock \emph{2022 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pp.\  8973--8982, 2021.

\bibitem[Pilipenko(2014)]{Pilipenko2014AnIT}
Pilipenko, A.
\newblock An introduction to stochastic differential equations with reflection.
\newblock 2014.

\bibitem[Ramachandran et~al.(2017)Ramachandran, Zoph, and
  Le]{Ramachandran2017SwishAS}
Ramachandran, P., Zoph, B., and Le, Q.~V.
\newblock Swish: a self-gated activation function.
\newblock \emph{arXiv: Neural and Evolutionary Computing}, 2017.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and
  Chen]{Ramesh2022HierarchicalTI}
Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., and Chen, M.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock \emph{ArXiv}, abs/2204.06125, 2022.

\bibitem[Richemond et~al.(2022)Richemond, Dieleman, and
  Doucet]{Richemond2022CategoricalSW}
Richemond, P.~H., Dieleman, S., and Doucet, A.
\newblock Categorical sdes with simplex diffusion.
\newblock \emph{ArXiv}, abs/2210.14784, 2022.

\bibitem[Rombach et~al.(2021)Rombach, Blattmann, Lorenz, Esser, and
  Ommer]{Rombach2021HighResolutionIS}
Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock \emph{2022 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)}, pp.\  10674--10685, 2021.

\bibitem[Russakovsky et~al.(2014)Russakovsky, Deng, Su, Krause, Satheesh, Ma,
  Huang, Karpathy, Khosla, Bernstein, Berg, and
  Fei-Fei]{Russakovsky2014ImageNetLS}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
  Karpathy, A., Khosla, A., Bernstein, M.~S., Berg, A.~C., and Fei-Fei, L.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{International Journal of Computer Vision}, 115:\penalty0
  211--252, 2014.

\bibitem[Saharia et~al.(2022)Saharia, Chan, Saxena, Li, Whang, Denton,
  Ghasemipour, Ayan, Mahdavi, Lopes, Salimans, Ho, Fleet, and
  Norouzi]{Saharia2022PhotorealisticTD}
Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E.~L.,
  Ghasemipour, S. K.~S., Ayan, B.~K., Mahdavi, S.~S., Lopes, R.~G., Salimans,
  T., Ho, J., Fleet, D.~J., and Norouzi, M.
\newblock Photorealistic text-to-image diffusion models with deep language
  understanding.
\newblock \emph{ArXiv}, abs/2205.11487, 2022.

\bibitem[Salimans et~al.(2016)Salimans, Goodfellow, Zaremba, Cheung, Radford,
  and Chen]{Salimans2016ImprovedTF}
Salimans, T., Goodfellow, I.~J., Zaremba, W., Cheung, V., Radford, A., and
  Chen, X.
\newblock Improved techniques for training gans.
\newblock \emph{ArXiv}, abs/1606.03498, 2016.

\bibitem[Salimans et~al.(2017)Salimans, Karpathy, Chen, and
  Kingma]{Salimans2017PixelCNNIT}
Salimans, T., Karpathy, A., Chen, X., and Kingma, D.~P.
\newblock Pixelcnn++: Improving the pixelcnn with discretized logistic mixture
  likelihood and other modifications.
\newblock \emph{ArXiv}, abs/1701.05517, 2017.

\bibitem[Schuss(2013)]{Schuss2013BrownianDA}
Schuss, Z.
\newblock Brownian dynamics at boundaries and interfaces.
\newblock 2013.

\bibitem[Skorokhod(1961)]{Skorokhod1961StochasticEF}
Skorokhod, A.~V.
\newblock Stochastic equations for diffusion processes in a bounded region.
\newblock \emph{Theory of Probability and Its Applications}, 6:\penalty0
  264--274, 1961.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and
  Ganguli]{SohlDickstein2015DeepUL}
Sohl-Dickstein, J.~N., Weiss, E.~A., Maheswaranathan, N., and Ganguli, S.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock \emph{ArXiv}, abs/1503.03585, 2015.

\bibitem[Song et~al.(2020)Song, Meng, and Ermon]{Song2020DenoisingDI}
Song, J., Meng, C., and Ermon, S.
\newblock Denoising diffusion implicit models.
\newblock \emph{ArXiv}, abs/2010.02502, 2020.

\bibitem[Song \& Ermon(2019{\natexlab{a}})Song and Ermon]{Song2019GenerativeMB}
Song, Y. and Ermon, S.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock \emph{ArXiv}, abs/1907.05600, 2019{\natexlab{a}}.

\bibitem[Song \& Ermon(2019{\natexlab{b}})Song and Ermon]{song2019generative}
Song, Y. and Ermon, S.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock \emph{Advances in Neural Information Processing Systems}, 32,
  2019{\natexlab{b}}.

\bibitem[Song et~al.(2019)Song, Garg, Shi, and Ermon]{Song2019SlicedSM}
Song, Y., Garg, S., Shi, J., and Ermon, S.
\newblock Sliced score matching: A scalable approach to density and score
  estimation.
\newblock In \emph{Conference on Uncertainty in Artificial Intelligence}, 2019.

\bibitem[Song et~al.(2021{\natexlab{a}})Song, Durkan, Murray, and
  Ermon]{Song2021MaximumLT}
Song, Y., Durkan, C., Murray, I., and Ermon, S.
\newblock Maximum likelihood training of score-based diffusion models.
\newblock In \emph{Neural Information Processing Systems}, 2021{\natexlab{a}}.

\bibitem[Song et~al.(2021{\natexlab{b}})Song, Sohl-Dickstein, Kingma, Kumar,
  Ermon, and Poole]{Song2020ScoreBasedGM}
Song, Y., Sohl-Dickstein, J., Kingma, D.~P., Kumar, A., Ermon, S., and Poole,
  B.
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock In \emph{International Conference on Learning Representations},
  2021{\natexlab{b}}.
\newblock URL \url{https://openreview.net/forum?id=PxTIG12RRHS}.

\bibitem[Szegedy et~al.(2014)Szegedy, Liu, Jia, Sermanet, Reed, Anguelov,
  Erhan, Vanhoucke, and Rabinovich]{Szegedy2014GoingDW}
Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S.~E., Anguelov, D., Erhan,
  D., Vanhoucke, V., and Rabinovich, A.
\newblock Going deeper with convolutions.
\newblock \emph{2015 IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp.\  1--9, 2014.

\bibitem[Szegedy et~al.(2015)Szegedy, Vanhoucke, Ioffe, Shlens, and
  Wojna]{Szegedy2015RethinkingTI}
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z.
\newblock Rethinking the inception architecture for computer vision.
\newblock \emph{2016 IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, pp.\  2818--2826, 2015.

\bibitem[van~den Oord et~al.(2016)van~den Oord, Kalchbrenner, and
  Kavukcuoglu]{Oord2016PixelRN}
van~den Oord, A., Kalchbrenner, N., and Kavukcuoglu, K.
\newblock Pixel recurrent neural networks.
\newblock \emph{ArXiv}, abs/1601.06759, 2016.

\bibitem[Vincent(2011)]{Vincent2011ACB}
Vincent, P.
\newblock A connection between score matching and denoising autoencoders.
\newblock \emph{Neural Computation}, 23:\penalty0 1661--1674, 2011.

\bibitem[Vincent et~al.(2008)Vincent, Larochelle, Bengio, and
  Manzagol]{Vincent2008ExtractingAC}
Vincent, P., Larochelle, H., Bengio, Y., and Manzagol, P.-A.
\newblock Extracting and composing robust features with denoising autoencoders.
\newblock In \emph{International Conference on Machine Learning}, 2008.

\bibitem[Williams(1988)]{Williams1988OnTO}
Williams, R.~J.
\newblock On time-reversal of reflected brownian motions.
\newblock 1988.

\bibitem[Xu et~al.(2022)Xu, Yu, Song, Shi, Ermon, and Tang]{Xu2022GeoDiffAG}
Xu, M., Yu, L., Song, Y., Shi, C., Ermon, S., and Tang, J.
\newblock Geodiff: a geometric diffusion model for molecular conformation
  generation.
\newblock \emph{ArXiv}, abs/2203.02923, 2022.

\bibitem[Yu et~al.(2020)Yu, Drton, and Shojaie]{Yu2020GeneralizedSM}
Yu, S., Drton, M., and Shojaie, A.
\newblock Generalized score matching for general domains.
\newblock \emph{Information and inference : a journal of the IMA}, 11
  2:\penalty0 739--780, 2020.

\end{thebibliography}
