\begin{thebibliography}{10}

\bibitem{jaynes}
Edwin~T Jaynes.
\newblock {\em Probability theory: the logic of science}.
\newblock Cambridge university press, 2003.

\bibitem{dongarra2000guest}
Jack Dongarra and Francis Sullivan.
\newblock Guest editors' introduction: The top 10 algorithms.
\newblock {\em IEEE Annals of the History of Computing}, 2(01):22--23, 2000.

\bibitem{neal2011mcmc}
Radford~M Neal et~al.
\newblock Mcmc using hamiltonian dynamics.
\newblock {\em Handbook of markov chain monte carlo}, 2(11):2, 2011.

\bibitem{nuts}
Matthew~D Hoffman and Andrew Gelman.
\newblock The no-u-turn sampler: adaptively setting path lengths in hamiltonian
  monte carlo.
\newblock {\em J. Mach. Learn. Res.}, 15(1):1593--1623, 2014.

\bibitem{stan}
Bob Carpenter, Andrew Gelman, Matthew~D Hoffman, Daniel Lee, Ben Goodrich,
  Michael Betancourt, Marcus~A Brubaker, Jiqiang Guo, Peter Li, and Allen
  Riddell.
\newblock Stan: a probabilistic programming language.
\newblock {\em Grantee Submission}, 76(1):1--32, 2017.

\bibitem{sgld}
Max Welling and Yee~W Teh.
\newblock Bayesian learning via stochastic gradient langevin dynamics.
\newblock In {\em Proceedings of the 28th international conference on machine
  learning (ICML-11)}, pages 681--688. Citeseer, 2011.

\bibitem{neutra}
Matthew Hoffman, Pavel Sountsov, Joshua~V Dillon, Ian Langmore, Dustin Tran,
  and Srinivas Vasudevan.
\newblock Neutra-lizing bad geometry in hamiltonian monte carlo using neural
  transport.
\newblock {\em arXiv preprint arXiv:1903.03704}, 2019.

\bibitem{levy2017generalizing}
Daniel Levy, Matthew~D Hoffman, and Jascha Sohl-Dickstein.
\newblock Generalizing hamiltonian monte carlo with neural networks.
\newblock {\em arXiv preprint arXiv:1711.09268}, 2017.

\bibitem{coopnet}
Jianwen Xie, Yang Lu, Ruiqi Gao, Song-Chun Zhu, and Ying~Nian Wu.
\newblock Cooperative training of descriptor and generator networks.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  42(1):27--45, 2018.

\bibitem{proposal_entropy}
Zengyi Li, Yubei Chen, and Friedrich~T Sommer.
\newblock A neural network mcmc sampler that maximizes proposal entropy.
\newblock {\em Entropy}, 23(3):269, 2021.

\bibitem{song2018learning}
Yunfu Song and Zhijian Ou.
\newblock Learning neural random fields with inclusive auxiliary generators.
\newblock {\em arXiv preprint arXiv:1806.00271}, 2018.

\bibitem{salimans2015markov}
Tim Salimans, Diederik Kingma, and Max Welling.
\newblock Markov chain monte carlo and variational inference: Bridging the gap.
\newblock In {\em International Conference on Machine Learning}, pages
  1218--1226. PMLR, 2015.

\bibitem{grathwohl2020no}
Will Grathwohl, Jacob Kelly, Milad Hashemi, Mohammad Norouzi, Kevin Swersky,
  and David Duvenaud.
\newblock No mcmc for me: Amortized sampling for fast and stable training of
  energy-based models.
\newblock {\em arXiv preprint arXiv:2010.04230}, 2020.

\bibitem{kumar2019maximum}
Rithesh Kumar, Sherjil Ozair, Anirudh Goyal, Aaron Courville, and Yoshua
  Bengio.
\newblock Maximum entropy generators for energy-based models.
\newblock {\em arXiv preprint arXiv:1901.08508}, 2019.

\bibitem{nose1984molecular}
Sh{\=u}ichi Nos{\'e}.
\newblock A molecular dynamics method for simulations in the canonical
  ensemble.
\newblock {\em Molecular physics}, 52(2):255--268, 1984.

\bibitem{leimkuhler2016molecular}
Ben Leimkuhler and Charles Matthews.
\newblock {\em Molecular Dynamics.}
\newblock Springer, 2016.

\bibitem{hoover1985canonical}
William~G Hoover.
\newblock Canonical dynamics: Equilibrium phase-space distributions.
\newblock {\em Physical review A}, 31(3):1695, 1985.

\bibitem{yoshida1990construction}
Haruo Yoshida.
\newblock Construction of higher order symplectic integrators.
\newblock {\em Physics letters A}, 150(5-7):262--268, 1990.

\bibitem{martyna1992nose}
Glenn~J Martyna, Michael~L Klein, and Mark Tuckerman.
\newblock Nos{\'e}--hoover chains: The canonical ensemble via continuous
  dynamics.
\newblock {\em The Journal of chemical physics}, 97(4):2635--2643, 1992.

\bibitem{martyna1996explicit}
Glenn~J Martyna, Mark~E Tuckerman, Douglas~J Tobias, and Michael~L Klein.
\newblock Explicit reversible integrators for extended systems dynamics.
\newblock {\em Molecular Physics}, 87(5):1117--1157, 1996.

\bibitem{nijkamp1}
Erik Nijkamp, Mitch Hill, Song-Chun Zhu, and Ying~Nian Wu.
\newblock Learning non-convergent non-persistent short-run mcmc toward
  energy-based model.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  5233--5243, 2019.

\bibitem{nijkamp2}
Erik Nijkamp, Mitch Hill, Tian Han, Song-Chun Zhu, and Ying~Nian Wu.
\newblock On the anatomy of mcmc-based maximum likelihood learning of
  energy-based models.
\newblock {\em arXiv preprint arXiv:1903.12370}, 2019.

\bibitem{zanette1995thermodynamics}
Damian~H Zanette and Pablo~A Alemany.
\newblock Thermodynamics of anomalous diffusion.
\newblock {\em Physical review letters}, 75(3):366, 1995.

\bibitem{cuendet2006jarzynski}
Michel~A Cuendet.
\newblock The jarzynski identity derived from general hamiltonian or
  non-hamiltonian dynamics reproducing nvt or npt ensembles.
\newblock {\em The Journal of chemical physics}, 125(14):144109, 2006.

\bibitem{campisi2012logarithmic}
Michele Campisi, Fei Zhan, Peter Talkner, and Peter H{\"a}nggi.
\newblock Logarithmic oscillators: ideal hamiltonian thermostats.
\newblock {\em Physical review letters}, 108(25):250601, 2012.

\bibitem{patra2018zeroth}
Puneet~Kumar Patra and Baidurya Bhattacharya.
\newblock Zeroth law investigation on the logarithmic thermostat.
\newblock {\em Scientific reports}, 8(1):1--11, 2018.

\bibitem{walters2000introduction}
Peter Walters.
\newblock {\em An introduction to ergodic theory}, volume~79.
\newblock Springer Science \& Business Media, 2000.

\bibitem{birkhoff1931proof}
George~D Birkhoff.
\newblock Proof of the ergodic theorem.
\newblock {\em Proceedings of the National Academy of Sciences},
  17(12):656--660, 1931.

\bibitem{neumann1932proof}
J~v Neumann.
\newblock Proof of the quasi-ergodic hypothesis.
\newblock {\em Proceedings of the National Academy of Sciences}, 18(1):70--82,
  1932.

\bibitem{moore2015ergodic}
Calvin~C Moore.
\newblock Ergodic theorem, ergodic theory, and statistical mechanics.
\newblock {\em Proceedings of the National Academy of Sciences},
  112(7):1907--1911, 2015.

\bibitem{tupper2005ergodicity}
Paul~F Tupper.
\newblock Ergodicity and the numerical simulation of hamiltonian systems.
\newblock {\em SIAM Journal on Applied Dynamical Systems}, 4(3):563--587, 2005.

\bibitem{patra2015lyapunov}
Puneet~Kumar Patra, Julien~Clinton Sprott, William~Graham Hoover, and
  Carol~Griswold Hoover.
\newblock Deterministic time-reversible thermostats: chaos, ergodicity, and the
  zeroth law of thermodynamics.
\newblock {\em Molecular Physics}, 113(17-18):2863--2872, 2015.

\bibitem{verlet1967computer}
Loup Verlet.
\newblock Computer" experiments" on classical fluids. i. thermodynamical
  properties of lennard-jones molecules.
\newblock {\em Physical review}, 159(1):98, 1967.

\bibitem{vitter1985random}
Jeffrey~S Vitter.
\newblock Random sampling with a reservoir.
\newblock {\em ACM Transactions on Mathematical Software (TOMS)}, 11(1):37--57,
  1985.

\bibitem{neal2005hamiltonian}
Radford~M Neal.
\newblock Hamiltonian importance sampling.
\newblock In {\em talk presented at the Banff International Research Station
  (BIRS) workshop on Mathematical Issues in Molecular Dynamics}, 2005.

\bibitem{hamiltonianvae}
Anthony~L Caterini, Arnaud Doucet, and Dino Sejdinovic.
\newblock Hamiltonian variational auto-encoder.
\newblock {\em arXiv preprint arXiv:1805.11328}, 2018.

\bibitem{rezende2015variational}
Danilo Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock In {\em International Conference on Machine Learning}, pages
  1530--1538. PMLR, 2015.

\bibitem{jarzynski1997}
Christopher Jarzynski.
\newblock Nonequilibrium equality for free energy differences.
\newblock {\em Physical Review Letters}, 78(14):2690, 1997.

\bibitem{jarzynski2011}
Christopher Jarzynski.
\newblock Equalities and inequalities: Irreversibility and the second law of
  thermodynamics at the nanoscale.
\newblock {\em Annu. Rev. Condens. Matter Phys.}, 2(1):329--351, 2011.

\bibitem{habeck}
Michael Habeck.
\newblock Model evidence from nonequilibrium simulations.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1753--1762, 2017.

\bibitem{pcd}
Tijmen Tieleman.
\newblock Training restricted boltzmann machines using approximations to the
  likelihood gradient.
\newblock In {\em Proceedings of the 25th international conference on Machine
  learning}, pages 1064--1071, 2008.

\bibitem{stein}
Jackson Gorham and Lester Mackey.
\newblock Measuring sample quality with stein's method.
\newblock {\em arXiv preprint arXiv:1506.03039}, 2015.

\bibitem{gretton2012kernel}
Arthur Gretton, Karsten~M Borgwardt, Malte~J Rasch, Bernhard Sch{\"o}lkopf, and
  Alexander Smola.
\newblock A kernel two-sample test.
\newblock {\em The Journal of Machine Learning Research}, 13(1):723--773, 2012.

\bibitem{chen2018neural}
Ricky~TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David~K Duvenaud.
\newblock Neural ordinary differential equations.
\newblock In {\em Advances in neural information processing systems}, pages
  6571--6583, 2018.

\bibitem{dormand}
John~R Dormand and Peter~J Prince.
\newblock A family of embedded runge-kutta formulae.
\newblock {\em Journal of computational and applied mathematics}, 6(1):19--26,
  1980.

\bibitem{mala}
Peter~J Rossky, JD~Doll, and HL~Friedman.
\newblock Brownian dynamics as smart monte carlo simulation.
\newblock {\em The Journal of Chemical Physics}, 69(10):4628--4633, 1978.

\bibitem{kleinerman2008implementations}
Dana~S Kleinerman, Cezary Czaplewski, Adam Liwo, and Harold~A Scheraga.
\newblock Implementations of nos{\'e}--hoover and nos{\'e}--poincar{\'e}
  thermostats in mesoscopic dynamic simulations with the united-residue model
  of a polypeptide chain.
\newblock {\em The Journal of chemical physics}, 128(24):06B621, 2008.

\bibitem{secret_classifier}
Will Grathwohl, Kuan-Chieh Wang, J{\"o}rn-Henrik Jacobsen, David Duvenaud,
  Mohammad Norouzi, and Kevin Swersky.
\newblock Your classifier is secretly an energy based model and you should
  treat it like one.
\newblock {\em arXiv preprint arXiv:1912.03263}, 2019.

\bibitem{du}
Yilun Du and Igor Mordatch.
\newblock Implicit generation and generalization in energy-based models.
\newblock {\em arXiv preprint arXiv:1903.08689}, 2019.

\bibitem{xie2016theory}
Jianwen Xie, Yang Lu, Song-Chun Zhu, and Yingnian Wu.
\newblock A theory of generative convnet.
\newblock In {\em International Conference on Machine Learning}, pages
  2635--2644. PMLR, 2016.

\bibitem{song2021train}
Yang Song and Diederik~P Kingma.
\newblock How to train your energy-based models.
\newblock {\em arXiv preprint arXiv:2101.03288}, 2021.

\bibitem{du2020improved}
Yilun Du, Shuang Li, Joshua Tenenbaum, and Igor Mordatch.
\newblock Improved contrastive divergence training of energy based models.
\newblock {\em arXiv preprint arXiv:2012.01316}, 2020.

\bibitem{cd}
Miguel~A Carreira-Perpinan and Geoffrey~E Hinton.
\newblock On contrastive divergence learning.
\newblock In {\em Aistats}, volume~10, pages 33--40. Citeseer, 2005.

\bibitem{sngan}
Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida.
\newblock Spectral normalization for generative adversarial networks.
\newblock {\em arXiv preprint arXiv:1802.05957}, 2018.

\bibitem{md_review}
M~Sri~Harish and Puneet~Kumar Patra.
\newblock Temperature and its control in molecular dynamics simulations.
\newblock {\em Molecular Simulation}, pages 1--29, 2021.

\bibitem{morriss1998thermostats}
Gary~P Morriss and Carl~P Dettmann.
\newblock Thermostats: analysis and application.
\newblock {\em Chaos: An Interdisciplinary Journal of Nonlinear Science},
  8(2):321--336, 1998.

\bibitem{ais}
Radford~M Neal.
\newblock Annealed importance sampling.
\newblock {\em Statistics and computing}, 11(2):125--139, 2001.

\bibitem{jascha_db}
Jascha Sohl-Dickstein, Mayur Mudigonda, and Michael~R DeWeese.
\newblock Hamiltonian monte carlo without detailed balance.
\newblock {\em arXiv preprint arXiv:1409.5191}, 2014.

\bibitem{jaschaneq}
Jascha Sohl-Dickstein, Eric~A Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock {\em arXiv preprint arXiv:1503.03585}, 2015.

\bibitem{noe_snf}
Hao Wu, Jonas K{\"o}hler, and Frank No{\'e}.
\newblock Stochastic normalizing flows.
\newblock {\em arXiv preprint arXiv:2002.06707}, 2020.

\bibitem{rotskoff2019dynamical}
Grant~M Rotskoff and Eric Vanden-Eijnden.
\newblock Dynamical computation of the density of states and bayes factors
  using nonequilibrium importance sampling.
\newblock {\em Physical review letters}, 122(15):150602, 2019.

\bibitem{thin2021invertible}
Achille Thin, Yazid Janati, Sylvain~Le Corff, Charles Ollion, Arnaud Doucet,
  Alain Durmus, Eric Moulines, and Christian Robert.
\newblock Invertible flow non equilibrium sampling.
\newblock {\em arXiv preprint arXiv:2103.10943}, 2021.

\bibitem{rhmc}
Mark Girolami and Ben Calderhead.
\newblock Riemann manifold langevin and hamiltonian monte carlo methods.
\newblock {\em Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 73(2):123--214, 2011.

\bibitem{involutive}
Kirill Neklyudov, Max Welling, Evgenii Egorov, and Dmitry Vetrov.
\newblock Involutive mcmc: a unifying framework.
\newblock In {\em International Conference on Machine Learning}, pages
  7273--7282. PMLR, 2020.

\bibitem{orbital}
Kirill Neklyudov and Max Welling.
\newblock Orbital mcmc.
\newblock {\em arXiv preprint arXiv:2010.08047}, 2020.

\bibitem{neklyudov2021deterministic}
Kirill Neklyudov, Roberto Bondesan, and Max Welling.
\newblock Deterministic gibbs sampling via ordinary differential equations.
\newblock {\em arXiv preprint arXiv:2106.10188}, 2021.

\bibitem{song2020score}
Yang Song, Jascha Sohl-Dickstein, Diederik~P Kingma, Abhishek Kumar, Stefano
  Ermon, and Ben Poole.
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock {\em arXiv preprint arXiv:2011.13456}, 2020.

\bibitem{izmailov2021bayesian}
Pavel Izmailov, Sharad Vikram, Matthew~D Hoffman, and Andrew~Gordon Wilson.
\newblock What are bayesian neural network posteriors really like?
\newblock {\em arXiv preprint arXiv:2104.14421}, 2021.

\bibitem{brekelmans2020all}
Rob Brekelmans, Vaden Masrani, Frank Wood, Greg {Ver Steeg}, and Aram Galstyan.
\newblock All in the exponential family: Bregman duality in thermodynamic
  variational inference.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2020.

\end{thebibliography}
