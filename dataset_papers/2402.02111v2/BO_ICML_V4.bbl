\begin{thebibliography}{10}

\bibitem{ament2024unexpected}
Sebastian Ament, Samuel Daulton, David Eriksson, Maximilian Balandat, and Eytan
  Bakshy.
\newblock Unexpected improvements to expected improvement for {B}ayesian
  optimization.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{astudillo2021multi}
Raul Astudillo, Daniel Jiang, Maximilian Balandat, Eytan Bakshy, and Peter
  Frazier.
\newblock Multi-step budgeted {B}ayesian optimization with unknown evaluation
  costs.
\newblock {\em Advances in Neural Information Processing Systems},
  34:20197--20209, 2021.

\bibitem{auer2002using}
Peter Auer.
\newblock Using confidence bounds for exploitation-exploration trade-offs.
\newblock {\em Journal of Machine Learning Research}, 3(Nov):397--422, 2002.

\bibitem{auer2002finite}
Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer.
\newblock Finite-time analysis of the multiarmed bandit problem.
\newblock {\em Machine learning}, 47:235--256, 2002.

\bibitem{balandat2020botorch}
Maximilian Balandat, Brian Karrer, Daniel Jiang, Samuel Daulton, Ben Letham,
  Andrew~G Wilson, and Eytan Bakshy.
\newblock {BoTorch: {A} framework for efficient Monte-Carlo Bayesian
  optimization}.
\newblock {\em Advances in neural information processing systems},
  33:21524--21538, 2020.

\bibitem{beck2020multilevel}
Joakim Beck, Ben Mansour~Dia, Luis Espath, and Ra{\'u}l Tempone.
\newblock {Multilevel double loop Monte Carlo and stochastic collocation
  methods with importance sampling for Bayesian optimal experimental design}.
\newblock {\em International Journal for Numerical Methods in Engineering},
  121(15):3482--3503, 2020.

\bibitem{beskos2017multilevel}
Alexandros Beskos, Ajay Jasra, Kody Law, Raul Tempone, and Yan Zhou.
\newblock Multilevel sequential {Monte C}arlo samplers.
\newblock {\em Stochastic Processes and their Applications}, 127(5):1417--1440,
  2017.

\bibitem{blanchet}
Jose~H Blanchet, Nan Chen, and Peter~W Glynn.
\newblock {Unbiased Monte Carlo computation of smooth functions of expectations
  via Taylor expansions}.
\newblock In {\em 2015 Winter Simulation Conference (WSC)}, pages 360--367.
  IEEE, 2015.

\bibitem{bogunovic2016truncated}
Ilija Bogunovic, Jonathan Scarlett, Andreas Krause, and Volkan Cevher.
\newblock {Truncated variance reduction: A unified approach to Bayesian
  optimization and level-set estimation}.
\newblock {\em Advances in neural information processing systems}, 29, 2016.

\bibitem{borovkov1999probability}
Aleksandr~Alekseevich Borovkov.
\newblock {\em Probability theory}.
\newblock CRC Press, 1999.

\bibitem{bungartz2004sparse}
Hans-Joachim Bungartz and Michael Griebel.
\newblock Sparse grids.
\newblock {\em Acta numerica}, 13:147--269, 2004.

\bibitem{caflisch1998monte}
Russel~E Caflisch.
\newblock {Monte Carlo and quasi-Monte Carlo methods}.
\newblock {\em Acta numerica}, 7:1--49, 1998.

\bibitem{cai2022multi}
Diana Cai and Ryan~P Adams.
\newblock {Multi-fidelity Monte Carlo: A pseudo-marginal approach}.
\newblock {\em Advances in Neural Information Processing Systems},
  35:21654--21667, 2022.

\bibitem{chada2022multilevel}
Neil~K Chada, Ajay Jasra, Kody~JH Law, and Sumeetpal~S Singh.
\newblock {Multilevel Bayesian deep neural networks}.
\newblock {\em arXiv preprint arXiv:2203.12961}, 2022.

\bibitem{chatterjee2018sample}
Sourav Chatterjee and Persi Diaconis.
\newblock The sample size required in importance sampling.
\newblock {\em The Annals of Applied Probability}, 28(2):1099--1135, 2018.

\bibitem{chevalier2013fast}
Cl{\'e}ment Chevalier and David Ginsbourger.
\newblock Fast computation of the multi-points expected improvement with
  applications in batch selection.
\newblock In {\em International conference on learning and intelligent
  optimization}, pages 59--69. Springer, 2013.

\bibitem{frazier2018tutorial}
Peter~I Frazier.
\newblock {A tutorial on Bayesian optimization}.
\newblock {\em arXiv preprint arXiv:1807.02811}, 2018.

\bibitem{fujisawa2021multilevel}
Masahiro Fujisawa and Issei Sato.
\newblock {Multilevel Monte Carlo variational inference}.
\newblock {\em The Journal of Machine Learning Research}, 22(1):12741--12784,
  2021.

\bibitem{garnett2023bayesian}
Roman Garnett.
\newblock {\em Bayesian optimization}.
\newblock Cambridge University Press, 2023.

\bibitem{giles2008multilevel}
Michael~B Giles.
\newblock Multilevel {Monte C}arlo path simulation.
\newblock {\em Operations research}, 56(3):607--617, 2008.

\bibitem{giles2015multilevel}
Michael~B Giles.
\newblock {Multilevel Monte Carlo methods}.
\newblock {\em Acta numerica}, 24:259--328, 2015.

\bibitem{giles2018mlmc}
Michael~B Giles.
\newblock {MLMC} for nested expectations.
\newblock In {\em {Contemporary Computational Mathematics-A Celebration of the
  80th Birthday of Ian Sloan}}, pages 425--442. Springer, 2018.

\bibitem{giles2019decision}
Michael~B Giles and Takashi Goda.
\newblock {Decision-making under uncertainty: {U}sing MLMC for efficient
  estimation of EVPPI}.
\newblock {\em Statistics and Computing}, 29(4):739--751, 2019.

\bibitem{giles2019multilevel}
Michael~B Giles and Abdul-Lateef Haji-Ali.
\newblock Multilevel nested simulation for efficient risk estimation.
\newblock {\em SIAM/ASA Journal on Uncertainty Quantification}, 7(2):497--525,
  2019.

\bibitem{ginsbourger2010towards}
David Ginsbourger and Rodolphe Le~Riche.
\newblock Towards {G}aussian process-based optimization with finite time
  horizon.
\newblock In {\em mODa 9--Advances in Model-Oriented Design and Analysis:
  Proceedings of the 9th International Workshop in Model-Oriented Design and
  Analysis held in Bertinoro, Italy, June 14-18, 2010}, pages 89--96. Springer,
  2010.

\bibitem{goda2020multilevel}
Takashi Goda, Tomohiko Hironaka, and Takeru Iwamoto.
\newblock {Multilevel Monte Carlo estimation of expected information gains}.
\newblock {\em Stochastic Analysis and Applications}, 38(4):581--600, 2020.

\bibitem{goda2022unbiased}
Takashi Goda, Tomohiko Hironaka, Wataru Kitade, and Adam Foster.
\newblock {Unbiased MLMC stochastic gradient-based optimization of Bayesian
  experimental designs}.
\newblock {\em SIAM Journal on Scientific Computing}, 44(1):A286--A311, 2022.

\bibitem{gonzalez2016glasses}
Javier Gonz{\'a}lez, Michael Osborne, and Neil Lawrence.
\newblock {GLASSES: Relieving the myopia of Bayesian optimisation}.
\newblock In {\em Artificial Intelligence and Statistics}, pages 790--799.
  PMLR, 2016.

\bibitem{haji2016multi}
Abdul-Lateef Haji-Ali, Fabio Nobile, and Ra{\'u}l Tempone.
\newblock {Multi-index Monte Carlo: {W}hen sparsity meets sampling}.
\newblock {\em Numerische Mathematik}, 132:767--806, 2016.

\bibitem{heath2018scientific}
Michael~T Heath.
\newblock {\em Scientific computing: {A}n introductory survey, revised second
  edition}.
\newblock SIAM, 2018.

\bibitem{hennig2012entropy}
Philipp Hennig and Christian~J Schuler.
\newblock Entropy search for information-efficient global optimization.
\newblock {\em Journal of Machine Learning Research}, 13(6), 2012.

\bibitem{hernandez2014predictive}
Jos{\'e}~Miguel Hern{\'a}ndez-Lobato, Matthew~W Hoffman, and Zoubin Ghahramani.
\newblock Predictive entropy search for efficient global optimization of
  black-box functions.
\newblock {\em Advances in neural information processing systems}, 27, 2014.

\bibitem{hironaka2020multilevel}
Tomohiko Hironaka, Michael~B Giles, Takashi Goda, and Howard Thom.
\newblock {Multilevel Monte Carlo estimation of the expected value of sample
  information}.
\newblock {\em SIAM/ASA Journal on Uncertainty Quantification},
  8(3):1236--1259, 2020.

\bibitem{hu2021bias}
Yifan Hu, Xin Chen, and Niao He.
\newblock On the bias-variance-cost tradeoff of stochastic optimization.
\newblock {\em Advances in Neural Information Processing Systems},
  34:22119--22131, 2021.

\bibitem{james1980monte}
Frederick James.
\newblock {Monte Carlo theory and practice}.
\newblock {\em Reports on progress in Physics}, 43(9):1145, 1980.

\bibitem{ourmimc}
Ajay Jasra, Kengo Kamatani, Kody J.~H. Law, and Yan Zhou.
\newblock A multi-index {Markov chain Monte C}arlo method.
\newblock {\em International Journal for Uncertainty Quantification}, 8(1),
  2018.

\bibitem{jasra2023multi}
Ajay Jasra, Kody~JH Law, Neil Walton, and Shangda Yang.
\newblock Multi-index sequential {M}onte {C}arlo ratio estimators for
  {B}ayesian inverse problems.
\newblock {\em Foundations of Computational Mathematics}, pages 1--56, 2023.

\bibitem{jiang2020binoculars}
Shali Jiang, Henry Chai, Javier Gonzalez, and Roman Garnett.
\newblock {BINOCULARS for efficient, nonmyopic sequential experimental design}.
\newblock In {\em International Conference on Machine Learning}, pages
  4794--4803. PMLR, 2020.

\bibitem{jiang2020efficient}
Shali Jiang, Daniel Jiang, Maximilian Balandat, Brian Karrer, Jacob Gardner,
  and Roman Garnett.
\newblock {Efficient nonmyopic Bayesian optimization via one-shot multi-step
  trees}.
\newblock {\em Advances in Neural Information Processing Systems},
  33:18039--18049, 2020.

\bibitem{jones1998efficient}
Donald~R Jones, Matthias Schonlau, and William~J Welch.
\newblock Efficient global optimization of expensive black-box functions.
\newblock {\em Journal of Global optimization}, 13(4):455, 1998.

\bibitem{kim2015guide}
Sujin Kim, Raghu Pasupathy, and Shane~G Henderson.
\newblock A guide to sample average approximation.
\newblock {\em Handbook of simulation optimization}, pages 207--243, 2015.

\bibitem{kleywegt2002sampleaverage}
Anton~J. Kleywegt, Alexander. Shapiro, and Tito. Homem-de Mello.
\newblock The sample average approximation method for stochastic discrete
  optimization.
\newblock {\em SIAM Journal on Optimization}, 12(2):479--502, 2002.

\bibitem{lam2017lookahead}
Remi Lam and Karen Willcox.
\newblock Lookahead {B}ayesian optimization with inequality constraints.
\newblock {\em Advances in neural information processing systems}, 30, 2017.

\bibitem{lam2016bayesian}
Remi Lam, Karen Willcox, and David~H Wolpert.
\newblock Bayesian optimization with a finite budget: {A}n approximate dynamic
  programming approach.
\newblock {\em Advances in Neural Information Processing Systems}, 29, 2016.

\bibitem{l2009monte}
Pierre L'Ecuyer, Art~B Owen, et~al.
\newblock {\em {Monte Carlo and Quasi-Monte Carlo Methods 2008}}.
\newblock Springer, 2009.

\bibitem{lee2020efficient}
Eric Lee, David Eriksson, David Bindel, Bolong Cheng, and Mike Mccourt.
\newblock {Efficient rollout strategies for Bayesian optimization}.
\newblock In {\em Conference on Uncertainty in Artificial Intelligence}, pages
  260--269. PMLR, 2020.

\bibitem{liang2023randomized}
Xinzhu Liang, Shangda Yang, Simon~L Cotter, and Kody~JH Law.
\newblock {A randomized Multi-index sequential Monte Carlo method}.
\newblock {\em Statistics and Computing}, 33(5):97, 2023.

\bibitem{lyne2015russian}
Anne-Marie Lyne, Mark Girolami, Yves Atchad{\'e}, Heiko Strathmann, and Daniel
  Simpson.
\newblock {On Russian Roulette estimates for Bayesian inference with
  doubly-intractable likelihoods}.
\newblock {\em Statistical Science}, 30(4):443--467, 2015.

\bibitem{movckus1975bayesian}
Jonas Mo{\v{c}}kus.
\newblock {On Bayesian methods for seeking the extremum}.
\newblock In {\em Optimization Techniques IFIP Technical Conference:
  Novosibirsk, July 1--7, 1974}, pages 400--404. Springer, 1975.

\bibitem{nguyen2017predictive}
Vu~Nguyen, Sunil Gupta, Santu Rana, Cheng Li, and Svetha Venkatesh.
\newblock Predictive variance reduction search.
\newblock In {\em NIPS Workshop on Bayesian Optimization}, volume~12, 2017.

\bibitem{peherstorfer2018survey}
Benjamin Peherstorfer, Karen Willcox, and Max Gunzburger.
\newblock Survey of multifidelity methods in uncertainty propagation,
  inference, and optimization.
\newblock {\em Siam Review}, 60(3):550--591, 2018.

\bibitem{renganathan2020recursive}
S~Ashwin Renganathan, Jeffrey Larson, and Stefan Wild.
\newblock Recursive two-step lookahead expected payoff for time-dependent
  {B}ayesian optimization.
\newblock {\em arXiv preprint arXiv:2006.08037}, 2020.

\bibitem{rhee2012new}
Chang-han Rhee and Peter~W Glynn.
\newblock {A new approach to unbiased estimation for SDE's}.
\newblock In {\em Proceedings of the 2012 Winter Simulation Conference (WSC)},
  pages 1--7. IEEE, 2012.

\bibitem{rhee2015unbiased}
Chang-han Rhee and Peter~W Glynn.
\newblock {Unbiased estimation with square root convergence for SDE models}.
\newblock {\em Operations Research}, 63(5):1026--1043, 2015.

\bibitem{shahriari2015taking}
Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan~P Adams, and Nando De~Freitas.
\newblock {Taking the human out of the loop: A review of Bayesian
  optimization}.
\newblock {\em Proceedings of the IEEE}, 104(1):148--175, 2015.

\bibitem{shapiro2021lectures}
Alexander Shapiro, Darinka Dentcheva, and Andrzej Ruszczynski.
\newblock {\em Lectures on stochastic programming: {M}odeling and theory}.
\newblock SIAM, 2021.

\bibitem{srinivas2009gaussian}
Niranjan Srinivas, Andreas Krause, Sham~M Kakade, and Matthias Seeger.
\newblock {Gaussian process optimization in the bandit setting: No regret and
  experimental design}.
\newblock {\em arXiv preprint arXiv:0912.3995}, 2009.

\bibitem{strathmann2015unbiased}
Heiko Strathmann, Dino Sejdinovic, and Mark Girolami.
\newblock {Unbiased Bayes for big data: Paths of partial posteriors}.
\newblock {\em arXiv preprint arXiv:1501.03326}, 2015.

\bibitem{wang2020parallelBO}
Jialei Wang, Scott~C. Clark, Eric Liu, and Peter~I. Frazier.
\newblock Parallel bayesian global optimization of expensive functions.
\newblock {\em Operations Research}, 68(6):1850--1865, 2020.

\bibitem{wu2019practical}
Jian Wu and Peter Frazier.
\newblock {Practical two-step lookahead Bayesian optimization}.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{yue2020non}
Xubo Yue and Raed~AL Kontar.
\newblock {Why non-myopic Bayesian optimization is promising and how far should
  we look-ahead? A study via rollout}.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 2808--2818. PMLR, 2020.

\bibitem{frazier2021constraint}
Yunxiang Zhang, Xiangyu Zhang, and Peter~I. Frazier.
\newblock Two-step lookahead {B}ayesian optimization with inequality
  constraints.
\newblock In Marc'Aurelio Ranzato, Alina Beygelzimer, Yann~N. Dauphin, Percy
  Liang, and Jennifer~Wortman Vaughan, editors, {\em Advances in Neural
  Information Processing Systems 34: Annual Conference on Neural Information
  Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual}, pages
  12563--12575, 2021.

\end{thebibliography}
