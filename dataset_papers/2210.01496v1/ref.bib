@book{nesterov2018lectures,
  title={Lectures on convex optimization},
  author={Nesterov, Yurii and others},
  volume={137},
  year={2018},
  publisher={Springer}
}


@article{allen2018neon2,
  title={Neon2: Finding local minima via first-order oracles},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{ji2019improved,
  title={Improved zeroth-order variance reduced algorithms and analysis for nonconvex optimization},
  author={Ji, Kaiyi and Wang, Zhe and Zhou, Yi and Liang, Yingbin},
  booktitle={International Conference on Machine Learning},
  pages={3100--3109},
  year={2019},
  organization={PMLR}
}

@article{lei2017non,
  title={Non-convex finite-sum optimization via scsg methods},
  author={Lei, Lihua and Ju, Cheng and Chen, Jianbo and Jordan, Michael I},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{ye2018hessian,
  title={Hessian-aware zeroth-order optimization for black-box adversarial attack},
  author={Ye, Haishan and Huang, Zhichao and Fang, Cong and Li, Chris Junchi and Zhang, Tong},
  journal={arXiv preprint arXiv:1812.11377},
  year={2018}
}

@misc{MVT,
    author = "{Wikipedia contributors}",
    title = "Mean value theorem --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2022",
    url = "https://en.wikipedia.org/w/index.php?title=Mean_value_theorem&oldid=1070109266",
    note = "[Online; accessed 20-March-2022]"
 }
 
  @misc{azuma-hoeffding,
    author = "{Wikipedia contributors}",
    title = "Azuma's inequality --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2021",
    url = "https://en.wikipedia.org/w/index.php?title=Azuma%27s_inequality&oldid=1037843061",
    note = "[Online; accessed 22-March-2022]"
  }
  
  @article{gao2018information,
  title={On the information-adaptive variants of the ADMM: an iteration complexity perspective},
  author={Gao, Xiang and Jiang, Bo and Zhang, Shuzhong},
  journal={Journal of Scientific Computing},
  volume={76},
  number={1},
  pages={327--363},
  year={2018},
  publisher={Springer}
}

@article{fang2018spider,
  title={Spider: Near-optimal non-convex optimization via stochastic path-integrated differential estimator},
  author={Fang, Cong and Li, Chris Junchi and Lin, Zhouchen and Zhang, Tong},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% applications of ZO
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% reinforcement learning

@article{salimans2017evolution,
  title={Evolution strategies as a scalable alternative to reinforcement learning},
  author={Salimans, Tim and Ho, Jonathan and Chen, Xi and Sidor, Szymon and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1703.03864},
  year={2017}
}

@inproceedings{choromanski2018structured,
  title={Structured evolution with compact architectures for scalable policy optimization},
  author={Choromanski, Krzysztof and Rowland, Mark and Sindhwani, Vikas and Turner, Richard and Weller, Adrian},
  booktitle={International Conference on Machine Learning},
  pages={970--978},
  year={2018},
  organization={PMLR}
}

@article{jing2021asynchronous,
  title={Asynchronous Distributed Reinforcement Learning for LQR Control via Zeroth-Order Block Coordinate Descent},
  author={Jing, Gangshan and Bai, He and George, Jemin and Chakrabortty, Aranya and Sharma, Piyush K},
  journal={arXiv preprint arXiv:2107.12416},
  year={2021}
}

% adversarial attack

@inproceedings{papernot2017practical,
  title={Practical black-box attacks against machine learning},
  author={Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z Berkay and Swami, Ananthram},
  booktitle={Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security},
  pages={506--519},
  year={2017}
}

@inproceedings{
madry2018towards,
title={Towards Deep Learning Models Resistant to Adversarial Attacks},
author={Aleksander Madry and Aleksandar Makelov and Ludwig Schmidt and Dimitris Tsipras and Adrian Vladu},
booktitle={International Conference on Learning Representations},
year={2018}
}

@inproceedings{chen2017zoo,
  title={Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models},
  author={Chen, Pin-Yu and Zhang, Huan and Sharma, Yash and Yi, Jinfeng and Hsieh, Cho-Jui},
  booktitle={Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security},
  pages={15--26},
  year={2017}
}

@inproceedings{bhagoji2018practical,
  title={Practical black-box attacks on deep neural networks using efficient query mechanisms},
  author={Bhagoji, Arjun Nitin and He, Warren and Li, Bo and Song, Dawn},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={154--169},
  year={2018}
}

@article{tu2019autozoom,
author = {Tu, Chun-Chen and Ting, Paishun and Chen, Pin-Yu and Liu, Sijia and Zhang, Huan and Yi, Jinfeng and Hsieh, Cho-Jui and Cheng, Shin-Ming},
year = {2019},
month = {07},
pages = {742-749},
title = {AutoZOOM: Autoencoder-Based Zeroth Order Optimization Method for Attacking Black-Box Neural Networks},
volume = {33},
journal = {Proceedings of the AAAI Conference on Artificial Intelligence}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% local minima vs. global minima
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{ge2015escaping,
  title={Escaping from saddle points-online stochastic gradient for tensor decomposition},
  author={Ge, Rong and Huang, Furong and Jin, Chi and Yuan, Yang},
  booktitle={Conference on learning theory},
  pages={797--842},
  year={2015},
  organization={PMLR}
}

@article{ge2016matrix,
  title={Matrix completion has no spurious local minimum},
  author={Ge, Rong and Lee, Jason D and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={29},
  year={2016}
}

@article{kawaguchi2016deep,
  title={Deep learning without poor local minima},
  author={Kawaguchi, Kenji},
  journal={Advances in Neural Information Processing Systems},
  volume={29},
  year={2016}
}

@inproceedings{ge2018learning,
title={Learning One-hidden-layer Neural Networks with Landscape Design},
author={Rong Ge and Jason D. Lee and Tengyu Ma},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=BkwHObbRZ},
}

@article{ge2017optimization,
  title={On the optimization landscape of tensor decompositions},
  author={Ge, Rong and Ma, Tengyu},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{JMLR:v19:16-465,
  author  = {Moritz Hardt and Tengyu Ma and Benjamin Recht},
  title   = {Gradient Descent Learns Linear Dynamical Systems},
  journal = {Journal of Machine Learning Research},
  year    = {2018},
  volume  = {19},
  number  = {29},
  pages   = {1-44}
}

@article{kawaguchi2019every,
  title={Every local minimum value is the global minimum value of induced model in nonconvex machine learning},
  author={Kawaguchi, Kenji and Huang, Jiaoyang and Kaelbling, Leslie Pack},
  journal={Neural Computation},
  volume={31},
  number={12},
  pages={2293--2323},
  year={2019},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{laurent2018deep,
  title={Deep linear networks with arbitrary loss: All local minima are global},
  author={Laurent, Thomas and Brecht, James},
  booktitle={International conference on machine learning},
  pages={2902--2907},
  year={2018},
  organization={PMLR}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% FO Deterministic methods for FO stationary point

@book{nesterov2003introductory,
  title={Introductory lectures on convex optimization: A basic course},
  author={Nesterov, Yurii},
  volume={87},
  year={2003},
  publisher={Springer Science \& Business Media}
}

@article{ghadimi2016accelerated,
  title={Accelerated gradient methods for nonconvex nonlinear and stochastic programming},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={Mathematical Programming},
  volume={156},
  number={1},
  pages={59--99},
  year={2016},
  publisher={Springer}
}

@inproceedings{carmon2017convex,
  title={“Convex Until Proven Guilty”: Dimension-Free Acceleration of Gradient Descent on Non-Convex Functions},
  author={Carmon, Yair and Duchi, John C and Hinder, Oliver and Sidford, Aaron},
  booktitle={International Conference on Machine Learning},
  pages={654--663},
  year={2017},
  organization={PMLR}
}

@article{li2022restarted,
  title={Restarted Nonconvex Accelerated Gradient Descent: No More Polylogarithmic Factor in the {$ \mathcal{O} (\epsilon^{-7/4}) $} Complexity},
  author={Li, Huan and Lin, Zhouchen},
  journal={arXiv preprint arXiv:2201.11411},
  year={2022}
}

% FO online methods for FO stationary point

@inproceedings{reddi2016stochastic,
  title={Stochastic variance reduction for nonconvex optimization},
  author={Reddi, Sashank J and Hefny, Ahmed and Sra, Suvrit and Poczos, Barnabas and Smola, Alex},
  booktitle={International Conference on Machine Learning},
  pages={314--323},
  year={2016},
  organization={PMLR}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{jain2017global,
  title={Global convergence of non-convex gradient descent for computing matrix squareroot},
  author={Jain, Prateek and Jin, Chi and Kakade, Sham and Netrapalli, Praneeth},
  booktitle={Artificial Intelligence and Statistics},
  pages={479--488},
  year={2017},
  organization={PMLR}
}

@article{sun2018geometric,
  title={A geometric analysis of phase retrieval},
  author={Sun, Ju and Qu, Qing and Wright, John},
  journal={Foundations of Computational Mathematics},
  volume={18},
  number={5},
  pages={1131--1198},
  year={2018},
  publisher={Springer}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{nesterov2006cubic,
  title={Cubic regularization of Newton method and its global performance},
  author={Nesterov, Yurii and Polyak, Boris T},
  journal={Mathematical Programming},
  volume={108},
  number={1},
  pages={177--205},
  year={2006},
  publisher={Springer}
}



@article{carmon2018accelerated,
  title={Accelerated methods for nonconvex optimization},
  author={Carmon, Yair and Duchi, John C and Hinder, Oliver and Sidford, Aaron},
  journal={SIAM Journal on Optimization},
  volume={28},
  number={2},
  pages={1751--1772},
  year={2018},
  publisher={SIAM}
}

@inproceedings{agarwal2017finding,
  title={Finding approximate local minima faster than gradient descent},
  author={Agarwal, Naman and Allen-Zhu, Zeyuan and Bullins, Brian and Hazan, Elad and Ma, Tengyu},
  booktitle={Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing},
  pages={1195--1199},
  year={2017}
}

@article{xu2017neon+,
  title={NEON+: Accelerated gradient methods for extracting negative curvature for non-convex optimization},
  author={Xu, Yi and Jin, Rong and Yang, Tianbao},
  journal={arXiv preprint arXiv:1712.01033},
  year={2017}
}

@article{allen2018natasha,
  title={Natasha 2: Faster non-convex optimization than sgd},
  author={Allen-Zhu, Zeyuan},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}


@inproceedings{jin2017escape,
  title={How to escape saddle points efficiently},
  author={Jin, Chi and Ge, Rong and Netrapalli, Praneeth and Kakade, Sham M and Jordan, Michael I},
  booktitle={International Conference on Machine Learning},
  pages={1724--1732},
  year={2017},
  organization={PMLR}
}

@inproceedings{jin2018accelerated,
  title={Accelerated gradient descent escapes saddle points faster than gradient descent},
  author={Jin, Chi and Netrapalli, Praneeth and Jordan, Michael I},
  booktitle={Conference On Learning Theory},
  pages={1042--1085},
  year={2018},
  organization={PMLR}
}

@article{zhang2021escape,
  title={Escape saddle points by a simple gradient-descent based algorithm},
  author={Zhang, Chenyi and Li, Tongyang},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{jin2021nonconvex,
  title={On nonconvex optimization for machine learning: Gradients, stochasticity, and saddle points},
  author={Jin, Chi and Netrapalli, Praneeth and Ge, Rong and Kakade, Sham M and Jordan, Michael I},
  journal={Journal of the ACM (JACM)},
  volume={68},
  number={2},
  pages={1--29},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@inproceedings{fang2019sharp,
  title={Sharp analysis for nonconvex sgd escaping from saddle points},
  author={Fang, Cong and Lin, Zhouchen and Zhang, Tong},
  booktitle={Conference on Learning Theory},
  pages={1192--1234},
  year={2019},
  organization={PMLR}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% zeroth-order methods for finding SOSP

@article{jin2018local,
  title={On the local minima of the empirical risk},
  author={Jin, Chi and Liu, Lydia T and Ge, Rong and Jordan, Michael I},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{vlatakis2019efficiently,
  title={Efficiently avoiding saddle points with zero order methods: No gradients required},
  author={Vlatakis-Gkaragkounis, Emmanouil-Vasileios and Flokas, Lampros and Piliouras, Georgios},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{balasubramanian2022zeroth,
  title={Zeroth-order nonconvex stochastic optimization: Handling constraints, high dimensionality, and saddle points},
  author={Balasubramanian, Krishnakumar and Ghadimi, Saeed},
  journal={Foundations of Computational Mathematics},
  volume={22},
  number={1},
  pages={35--76},
  year={2022},
  publisher={Springer}
}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@article{nesterov2017random,
  title={Random gradient-free minimization of convex functions},
  author={Nesterov, Yurii and Spokoiny, Vladimir},
  journal={Foundations of Computational Mathematics},
  volume={17},
  number={2},
  pages={527--566},
  year={2017},
  publisher={Springer}
}

@article{ghadimi2013stochastic,
  title={Stochastic first-and zeroth-order methods for nonconvex stochastic programming},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={SIAM Journal on Optimization},
  volume={23},
  number={4},
  pages={2341--2368},
  year={2013},
  publisher={SIAM}
}

@article{oja1982simplified,
  title={Simplified neuron model as a principal component analyzer},
  author={Oja, Erkki},
  journal={Journal of Mathematical Biology},
  volume={15},
  number={3},
  pages={267--273},
  year={1982},
  publisher={Springer}
}

@inproceedings{allen2017faster,
  title={Faster principal component regression and stable matrix Chebyshev approximation},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi},
  booktitle={International Conference on Machine Learning},
  pages={107--115},
  year={2017},
  organization={PMLR}
}

@article{du2017gradient,
  title={Gradient descent can take exponential time to escape saddle points},
  author={Du, Simon S and Jin, Chi and Lee, Jason D and Jordan, Michael I and Singh, Aarti and Poczos, Barnabas},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{carmon2016gradient,
  title={Gradient descent efficiently finds the cubic-regularized non-convex Newton step},
  author={Carmon, Yair and Duchi, John C},
  journal={arXiv preprint arXiv:1612.00547},
  year={2016}
}

@article{lucchi2021second,
  title={On the Second-order Convergence Properties of Random Search Methods},
  author={Lucchi, Aurelien and Orvieto, Antonio and Solomou, Adamos},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{cartis2011adaptive1,
  title={Adaptive cubic regularisation methods for unconstrained optimization. Part I: motivation, convergence and numerical results},
  author={Cartis, Coralia and Gould, Nicholas IM and Toint, Philippe L},
  journal={Mathematical Programming},
  volume={127},
  number={2},
  pages={245--295},
  year={2011},
  publisher={Springer}
}

@article{cartis2011adaptive2,
  title={Adaptive cubic regularisation methods for unconstrained optimization. Part II: worst-case function-and derivative-evaluation complexity},
  author={Cartis, Coralia and Gould, Nicholas IM and Toint, Philippe L},
  journal={Mathematical programming},
  volume={130},
  number={2},
  pages={295--319},
  year={2011},
  publisher={Springer}
}

@article{liu2018adaptive,
  title={Adaptive negative curvature descent with applications in non-convex optimization},
  author={Liu, Mingrui and Li, Zhe and Wang, Xiaoyu and Yi, Jinfeng and Yang, Tianbao},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{CC01a,
 author = {Chang, Chih-Chung and Lin, Chih-Jen},
 title = {{LIBSVM}: A library for support vector machines},
 journal = {ACM Transactions on Intelligent Systems and Technology},
 volume = {2},
 issue = {3},
 year = {2011},
 pages = {27:1--27:27},
 note =	 {Software available at \url{http://www.csie.ntu.edu.tw/~cjlin/libsvm}}
}