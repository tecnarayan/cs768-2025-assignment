\begin{thebibliography}{48}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bakr et~al.(2023)Bakr, Sun, Shen, Khan, Li, and Elhoseiny]{bakr2023hrs}
Bakr, E.~M., Sun, P., Shen, X., Khan, F.~F., Li, L.~E., and Elhoseiny, M.
\newblock Hrs-bench: Holistic, reliable and scalable benchmark for text-to-image models.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  20041--20053, 2023.

\bibitem[Bellagente et~al.(2023)Bellagente, Brack, Teufel, Friedrich, Deiseroth, Eichenberg, Dai, Baldock, Nanda, Oostermeijer, et~al.]{bellagente2023multifusion}
Bellagente, M., Brack, M., Teufel, H., Friedrich, F., Deiseroth, B., Eichenberg, C., Dai, A., Baldock, R., Nanda, S., Oostermeijer, K., et~al.
\newblock Multifusion: Fusing pre-trained models for multi-lingual, multi-modal image generation.
\newblock \emph{arXiv preprint arXiv:2305.15296}, 2023.

\bibitem[Betker et~al.(2023)Betker, Goh, Jing, Brooks, Wang, Li, Ouyang, Zhuang, Lee, Guo, et~al.]{betker2023improving}
Betker, J., Goh, G., Jing, L., Brooks, T., Wang, J., Li, L., Ouyang, L., Zhuang, J., Lee, J., Guo, Y., et~al.
\newblock Improving image generation with better captions.
\newblock \emph{Computer Science. https://cdn. openai. com/papers/dall-e-3. pdf}, 2:\penalty0 3, 2023.

\bibitem[{Civitai}(2024)]{Civitai2024}
{Civitai}.
\newblock Civitai: The home of open-source generative ai, 2024.
\newblock URL \url{https://civitai.com}.
\newblock Accessed: 2024-01-20.

\bibitem[CompVis(2022)]{checkermerge}
CompVis.
\newblock {GitHub Merge: [Safety Checker] Add Safety Checker Module}.
\newblock \url{https://github.com/CompVis/stable-diffusion/commit/d0c714ae4afa1c011269a956d6f260f84f77025e}, 2022.
\newblock Accessed 29/09/2022.

\bibitem[Creswell et~al.(2018)Creswell, White, Dumoulin, Arulkumaran, Sengupta, and Bharath]{creswell2018generative}
Creswell, A., White, T., Dumoulin, V., Arulkumaran, K., Sengupta, B., and Bharath, A.~A.
\newblock Generative adversarial networks: An overview.
\newblock \emph{IEEE signal processing magazine}, 35\penalty0 (1):\penalty0 53--65, 2018.

\bibitem[Deng et~al.(2019)Deng, Guo, Xue, and Zafeiriou]{deng2019arcface}
Deng, J., Guo, J., Xue, N., and Zafeiriou, S.
\newblock Arcface: Additive angular margin loss for deep face recognition.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  4690--4699, 2019.

\bibitem[Ding et~al.(2022)Ding, Zheng, Hong, and Tang]{ding2022cogview2}
Ding, M., Zheng, W., Hong, W., and Tang, J.
\newblock Cogview2: Faster and better text-to-image generation via hierarchical transformers.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 16890--16902, 2022.

\bibitem[Gafni et~al.(2022)Gafni, Polyak, Ashual, Sheynin, Parikh, and Taigman]{gafni2022make}
Gafni, O., Polyak, A., Ashual, O., Sheynin, S., Parikh, D., and Taigman, Y.
\newblock Make-a-scene: Scene-based text-to-image generation with human priors.
\newblock In \emph{European Conference on Computer Vision}, pp.\  89--106. Springer, 2022.

\bibitem[Gal et~al.(2022)Gal, Alaluf, Atzmon, Patashnik, Bermano, Chechik, and Cohen-Or]{gal2022image}
Gal, R., Alaluf, Y., Atzmon, Y., Patashnik, O., Bermano, A.~H., Chechik, G., and Cohen-Or, D.
\newblock An image is worth one word: Personalizing text-to-image generation using textual inversion.
\newblock \emph{arXiv preprint arXiv:2208.01618}, 2022.

\bibitem[Google(2024)]{Bard}
Google.
\newblock Bard, 2024.
\newblock URL \url{https://blog.google/technology/ai/bard-google-ai-search-updates/}.

\bibitem[Hao et~al.(2024)Hao, Chi, Dong, and Wei]{hao2024optimizing}
Hao, Y., Chi, Z., Dong, L., and Wei, F.
\newblock Optimizing prompts for text-to-image generation.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Hessel et~al.(2021)Hessel, Holtzman, Forbes, Bras, and Choi]{hessel2021clipscore}
Hessel, J., Holtzman, A., Forbes, M., Bras, R.~L., and Choi, Y.
\newblock Clipscore: A reference-free evaluation metric for image captioning.
\newblock \emph{arXiv preprint arXiv:2104.08718}, 2021.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and Hochreiter]{heusel2017gans}
Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., and Hochreiter, S.
\newblock Gans trained by a two time-scale update rule converge to a local nash equilibrium.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Ho, J., Jain, A., and Abbeel, P.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 6840--6851, 2020.

\bibitem[Huang et~al.(2023)Huang, Sun, Xie, Li, and Liu]{huang2023t2i}
Huang, K., Sun, K., Xie, E., Li, Z., and Liu, X.
\newblock T2i-compbench: A comprehensive benchmark for open-world compositional text-to-image generation.
\newblock \emph{arXiv preprint arXiv:2307.06350}, 2023.

\bibitem[Lee et~al.(2023)Lee, Yasunaga, Meng, Mai, Park, Gupta, Zhang, Narayanan, Teufel, Bellagente, et~al.]{lee2023holistic}
Lee, T., Yasunaga, M., Meng, C., Mai, Y., Park, J.~S., Gupta, A., Zhang, Y., Narayanan, D., Teufel, H.~B., Bellagente, M., et~al.
\newblock Holistic evaluation of text-to-image models.
\newblock \emph{arXiv preprint arXiv:2311.04287}, 2023.

\bibitem[{Lexica}(2024)]{lexica}
{Lexica}.
\newblock Lexica, 2024.
\newblock URL \url{https://lexica.art}.
\newblock Accessed: 2024-01-20.

\bibitem[Lin et~al.(2014)Lin, Maire, Belongie, Hays, Perona, Ramanan, Doll{\'a}r, and Zitnick]{lin2014microsoft}
Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Doll{\'a}r, P., and Zitnick, C.~L.
\newblock Microsoft coco: Common objects in context.
\newblock In \emph{Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13}, pp.\  740--755. Springer, 2014.

\bibitem[Lin et~al.(2023)Lin, Liu, Zhang, Gao, Qiu, Xiao, Qiu, Lin, Shao, Chen, et~al.]{lin2023sphinx}
Lin, Z., Liu, C., Zhang, R., Gao, P., Qiu, L., Xiao, H., Qiu, H., Lin, C., Shao, W., Chen, K., et~al.
\newblock Sphinx: The joint mixing of weights, tasks, and visual embeddings for multi-modal large language models.
\newblock \emph{arXiv preprint arXiv:2311.07575}, 2023.

\bibitem[Liu et~al.(2023)Liu, Li, Wu, and Lee]{liu2023visual}
Liu, H., Li, C., Wu, Q., and Lee, Y.~J.
\newblock Visual instruction tuning.
\newblock \emph{arXiv preprint arXiv:2304.08485}, 2023.

\bibitem[Luccioni et~al.(2023)Luccioni, Akiki, Mitchell, and Jernite]{luccioni2023stable}
Luccioni, A.~S., Akiki, C., Mitchell, M., and Jernite, Y.
\newblock Stable bias: Analyzing societal representations in diffusion models.
\newblock \emph{arXiv preprint arXiv:2303.11408}, 2023.

\bibitem[{Machine Vision \& Learning Group LMU}(2022)]{safetychecker}
{Machine Vision \& Learning Group LMU}.
\newblock Safety checker model card.
\newblock \url{https://huggingface.co/CompVis/stable-diffusion-safety-checker}, 2022.
\newblock Accessed 20/01/2024.

\bibitem[Midjourney(2023)]{Midjourney}
Midjourney, I.
\newblock Midjourney, 2023.
\newblock URL \url{https://www.midjourney.com}.
\newblock Accessed: 2024-01-20.

\bibitem[OpenAI(2023)]{2023GPT4VisionSC}
OpenAI.
\newblock Gpt-4v(ision) system card.
\newblock \emph{OpenAI}, 2023.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:263218031}.

\bibitem[{OpenAI}(2023)]{dalle3}
{OpenAI}.
\newblock DallÂ·e 3 system card, 2023.
\newblock OpenAI (2023{\natexlab{a}}).

\bibitem[OpenAI(2024)]{policies}
OpenAI.
\newblock Openai content pilicy, 2024.
\newblock URL \url{https://openai.com/policies/usage-policies}.
\newblock Accessed: 2024-01-20.

\bibitem[Petsiuk et~al.(2022)Petsiuk, Siemenn, Surbehera, Chin, Tyser, Hunter, Raghavan, Hicke, Plummer, Kerret, et~al.]{petsiuk2022human}
Petsiuk, V., Siemenn, A.~E., Surbehera, S., Chin, Z., Tyser, K., Hunter, G., Raghavan, A., Hicke, Y., Plummer, B.~A., Kerret, O., et~al.
\newblock Human evaluation of text-to-image models on a multi-task benchmark.
\newblock \emph{arXiv preprint arXiv:2211.12112}, 2022.

\bibitem[Podell et~al.(2023)Podell, English, Lacey, Blattmann, Dockhorn, M{\"u}ller, Penna, and Rombach]{podell2023sdxl}
Podell, D., English, Z., Lacey, K., Blattmann, A., Dockhorn, T., M{\"u}ller, J., Penna, J., and Rombach, R.
\newblock Sdxl: Improving latent diffusion models for high-resolution image synthesis.
\newblock \emph{arXiv preprint arXiv:2307.01952}, 2023.

\bibitem[Qu et~al.(2023)Qu, Shen, He, Backes, Zannettou, and Zhang]{qu2023unsafe}
Qu, Y., Shen, X., He, X., Backes, M., Zannettou, S., and Zhang, Y.
\newblock Unsafe diffusion: On the generation of unsafe images and hateful memes from text-to-image models.
\newblock \emph{arXiv preprint arXiv:2305.13873}, 2023.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Radford, A., Kim, J.~W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{International Conference on Machine Learning}, pp.\  8748--8763. PMLR, 2021.

\bibitem[Ramesh et~al.(2021)Ramesh, Pavlov, Goh, Gray, Voss, Radford, Chen, and Sutskever]{ramesh2021zero}
Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., and Sutskever, I.
\newblock Zero-shot text-to-image generation.
\newblock In \emph{International Conference on Machine Learning}, pp.\  8821--8831. PMLR, 2021.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and Chen]{ramesh2022hierarchical}
Ramesh, A., Dhariwal, P., Nichol, A., Chu, C., and Chen, M.
\newblock Hierarchical text-conditional image generation with clip latents.
\newblock \emph{arXiv preprint arXiv:2204.06125}, 1\penalty0 (2):\penalty0 3, 2022.

\bibitem[Rando et~al.(2022)Rando, Paleka, Lindner, Heim, and Tram{\`e}r]{rando2022red}
Rando, J., Paleka, D., Lindner, D., Heim, L., and Tram{\`e}r, F.
\newblock Red-teaming the stable diffusion safety filter.
\newblock \emph{arXiv preprint arXiv:2210.04610}, 2022.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022high}
Rombach, R., Blattmann, A., Lorenz, D., Esser, P., and Ommer, B.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  10684--10695, 2022.

\bibitem[Saharia et~al.(2022)Saharia, Chan, Saxena, Li, Whang, Denton, Ghasemipour, Gontijo~Lopes, Karagol~Ayan, Salimans, et~al.]{saharia2022photorealistic}
Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E.~L., Ghasemipour, K., Gontijo~Lopes, R., Karagol~Ayan, B., Salimans, T., et~al.
\newblock Photorealistic text-to-image diffusion models with deep language understanding.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 36479--36494, 2022.

\bibitem[Salimans et~al.(2016)Salimans, Goodfellow, Zaremba, Cheung, Radford, and Chen]{salimans2016improved}
Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., and Chen, X.
\newblock Improved techniques for training gans.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Schramowski et~al.(2023)Schramowski, Brack, Deiseroth, and Kersting]{schramowski2023safe}
Schramowski, P., Brack, M., Deiseroth, B., and Kersting, K.
\newblock Safe latent diffusion: Mitigating inappropriate degeneration in diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  22522--22531, 2023.

\bibitem[Seshadri et~al.(2023)Seshadri, Singh, and Elazar]{seshadri2023bias}
Seshadri, P., Singh, S., and Elazar, Y.
\newblock The bias amplification paradox in text-to-image generation.
\newblock \emph{arXiv preprint arXiv:2308.00755}, 2023.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and Ganguli]{sohl2015deep}
Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., and Ganguli, S.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock In \emph{International conference on machine learning}, pp.\  2256--2265. PMLR, 2015.

\bibitem[Sun et~al.(2014)Sun, Chen, Wang, and Tang]{sun2014deep}
Sun, Y., Chen, Y., Wang, X., and Tang, X.
\newblock Deep learning face representation by joint identification-verification.
\newblock \emph{Advances in neural information processing systems}, 27, 2014.

\bibitem[Tao et~al.(2022)Tao, Tang, Wu, Jing, Bao, and Xu]{tao2022df}
Tao, M., Tang, H., Wu, F., Jing, X.-Y., Bao, B.-K., and Xu, C.
\newblock Df-gan: A simple and effective baseline for text-to-image synthesis.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  16515--16525, 2022.

\bibitem[Tong et~al.(2024)Tong, Liu, Zhai, Ma, LeCun, and Xie]{tong2024eyes}
Tong, S., Liu, Z., Zhai, Y., Ma, Y., LeCun, Y., and Xie, S.
\newblock Eyes wide shut? exploring the visual shortcomings of multimodal llms.
\newblock \emph{arXiv preprint arXiv:2401.06209}, 2024.

\bibitem[Wah et~al.(2011)Wah, Branson, Welinder, Perona, and Belongie]{wah2011caltech}
Wah, C., Branson, S., Welinder, P., Perona, P., and Belongie, S.
\newblock The caltech-ucsd birds-200-2011 dataset.
\newblock 2011.

\bibitem[Xu et~al.(2023)Xu, Liu, Wu, Tong, Li, Ding, Tang, and Dong]{xu2023imagereward}
Xu, J., Liu, X., Wu, Y., Tong, Y., Li, Q., Ding, M., Tang, J., and Dong, Y.
\newblock Imagereward: Learning and evaluating human preferences for text-to-image generation.
\newblock \emph{arXiv preprint arXiv:2304.05977}, 2023.

\bibitem[Xu et~al.(2018)Xu, Zhang, Huang, Zhang, Gan, Huang, and He]{xu2018attngan}
Xu, T., Zhang, P., Huang, Q., Zhang, H., Gan, Z., Huang, X., and He, X.
\newblock Attngan: Fine-grained text to image generation with attentional generative adversarial networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pp.\  1316--1324, 2018.

\bibitem[Zhang et~al.(2016)Zhang, Zhang, Li, and Qiao]{zhang2016joint}
Zhang, K., Zhang, Z., Li, Z., and Qiao, Y.
\newblock Joint face detection and alignment using multitask cascaded convolutional networks.
\newblock \emph{IEEE signal processing letters}, 23\penalty0 (10):\penalty0 1499--1503, 2016.

\bibitem[Zhang et~al.(2023)Zhang, Li, Cui, Cai, Liu, Fu, Huang, Zhao, Zhang, Chen, et~al.]{zhang2023siren}
Zhang, Y., Li, Y., Cui, L., Cai, D., Liu, L., Fu, T., Huang, X., Zhao, E., Zhang, Y., Chen, Y., et~al.
\newblock Siren's song in the ai ocean: A survey on hallucination in large language models.
\newblock \emph{arXiv preprint arXiv:2309.01219}, 2023.

\end{thebibliography}
