\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amari(1998)]{Amari1998}
Amari, Shun-Ichi.
\newblock {Natural Gradient Works Efficiently in Learning}.
\newblock \emph{Neural Computation}, 10\penalty0 (2):\penalty0 251--276, 1998.
\newblock ISSN 08997667.
\newblock \doi{10.1162/089976698300017746}.

\bibitem[Bach \& Moulines(2013)Bach and Moulines]{Bach2013}
Bach, F and Moulines, E.
\newblock {Non-strongly-convex smooth stochastic approximation with convergence
  rate O (1/n)}.
\newblock \emph{Neural Information Processing Systems}, 2013.

\bibitem[Bach \& Moulines(2011)Bach and Moulines]{Moulines2011}
Bach, FR and Moulines, E.
\newblock {Non-Asymptotic Analysis of Stochastic Approximation Algorithms for
  Machine Learning}.
\newblock \emph{Neural Information Processing Systems}, 2011.

\bibitem[Bell \& Sejnowski(1995)Bell and Sejnowski]{Bell1995}
Bell, AJ and Sejnowski, TJ.
\newblock {An information-maximization approach to blind separation and blind
  deconvolution}.
\newblock \emph{Neural computation}, 1995.

\bibitem[Bergstra \& Breuleux(2010)Bergstra and Breuleux]{Bergstra2010}
Bergstra, J and Breuleux, O.
\newblock {Theano: a CPU and GPU math expression compiler}.
\newblock \emph{Proceedings of the Python for Scientific Computing Conference
  (SciPy)}, 2010.

\bibitem[Blatt et~al.(2007)Blatt, Hero, and Gauchman]{Blatt2007}
Blatt, Doron, Hero, Alfred~O, and Gauchman, Hillel.
\newblock {A convergent incremental gradient method with a constant step size}.
\newblock \emph{SIAM Journal on Optimization}, 18\penalty0 (1):\penalty0
  29--51, 2007.

\bibitem[Bordes et~al.(2009)Bordes, Bottou, and Gallinari]{Bordes2009}
Bordes, Antoine, Bottou, L\'{e}on, and Gallinari, Patrick.
\newblock {SGD-QN: Careful quasi-Newton stochastic gradient descent}.
\newblock \emph{The Journal of Machine Learning Research}, 10:\penalty0
  1737--1754, 2009.

\bibitem[Bottou(1991)]{Bottou}
Bottou, L\'{e}on.
\newblock {Stochastic gradient learning in neural networks}.
\newblock \emph{Proceedings of Neuro-Nimes}, 91:\penalty0 8, 1991.

\bibitem[Boyd \& Vandenberghe(2004)Boyd and Vandenberghe]{boyd2004convex}
Boyd, S~P and Vandenberghe, L.
\newblock \emph{{Convex optimization}}.
\newblock Cambridge Univ Press, 2004.
\newblock ISBN 0521833787.

\bibitem[Broyden(1970)]{Broyden1970}
Broyden, CG.
\newblock {The convergence of a class of double-rank minimization algorithms 2.
  The new algorithm}.
\newblock \emph{IMA Journal of Applied Mathematics}, 1970.

\bibitem[Byrd et~al.(2014)Byrd, Hansen, Nocedal, and Singer]{Byrd2014}
Byrd, RH, Hansen, SL, Nocedal, J, and Singer, Y.
\newblock {A Stochastic Quasi-Newton Method for Large-Scale Optimization}.
\newblock \emph{arXiv preprint arXiv:1401.7020}, 2014.

\bibitem[Byrd et~al.(2011)Byrd, Chin, Neveitt, and Nocedal]{Byrd2011}
Byrd, RH Richard~H, Chin, GM Gillian~M, Neveitt, Will, and Nocedal, Jorge.
\newblock {On the use of stochastic hessian information in optimization methods
  for machine learning}.
\newblock \emph{SIAM Journal on Optimization}, 21\penalty0 (3):\penalty0
  977--995, 2011.

\bibitem[{Dennis Jr} \& Mor\'{e}(1977){Dennis Jr} and Mor\'{e}]{Dennis1977}
{Dennis Jr}, John~E and Mor\'{e}, Jorge~J.
\newblock {Quasi-Newton methods, motivation and theory}.
\newblock \emph{SIAM review}, 19\penalty0 (1):\penalty0 46--89, 1977.

\bibitem[Duchi et~al.(2010)Duchi, Hazan, and Singer]{Duchi2010}
Duchi, John, Hazan, Elad, and Singer, Yoram.
\newblock {Adaptive subgradient methods for online learning and stochastic
  optimization}.
\newblock \emph{Journal of Machine Learning Research}, 12:\penalty0 2121--2159,
  2010.

\bibitem[Fletcher(1970)]{Fletcher1970}
Fletcher, R.
\newblock {A new approach to variable metric algorithms}.
\newblock \emph{The computer journal}, 1970.

\bibitem[Goldfarb(1970)]{Goldfarb1970}
Goldfarb, D.
\newblock {A family of variable-metric methods derived by variational means}.
\newblock \emph{Mathematics of computation}, 1970.

\bibitem[Goodfellow \& Warde-Farley(2013{\natexlab{a}})Goodfellow and
  Warde-Farley]{Goodfellow2013}
Goodfellow, IJ and Warde-Farley, D.
\newblock {Maxout networks}.
\newblock \emph{arXiv:1302.4389}, 2013{\natexlab{a}}.

\bibitem[Goodfellow \& Warde-Farley(2013{\natexlab{b}})Goodfellow and
  Warde-Farley]{Goodfellow2013a}
Goodfellow, IJ and Warde-Farley, D.
\newblock {Pylearn2: a machine learning research library}.
\newblock \emph{arXiv:1308.4214}, 2013{\natexlab{b}}.

\bibitem[Hennig(2013)]{Hennig2013}
Hennig, P.
\newblock {Fast probabilistic optimization from noisy gradients}.
\newblock \emph{International Conference on Machine Learning}, 2013.

\bibitem[Hillar et~al.(2012)Hillar, Sohl-Dickstein, and Koepsell]{Hillar2012}
Hillar, Christopher, Sohl-Dickstein, Jascha, and Koepsell, Kilian.
\newblock {Efficient and optimal binary Hopfield associative memory storage
  using minimum probability flow}.
\newblock \emph{arXiv}, 1204.2916, April 2012.

\bibitem[Hinton et~al.(2012)Hinton, Srivastava, Krizhevsky, Sutskever, and
  Salakhutdinov]{Hinton:2012tv}
Hinton, Geoffrey~E., Srivastava, Nitish, Krizhevsky, Alex, Sutskever, Ilya, and
  Salakhutdinov, Ruslan~R.
\newblock {Improving neural networks by preventing co-adaptation of feature
  detectors}.
\newblock \emph{arXiv:1207.0580}, 2012.

\bibitem[Huber(1981)]{Huber81}
Huber, PJ.
\newblock {Robust statistics}.
\newblock \emph{Wiley, New York}, 1981.

\bibitem[Le et~al.(2011)Le, Ngiam, Coates, Lahiri, Prochnow, and Ng]{Ngiam2011}
Le, Quoc~V., Ngiam, Jiquan, Coates, Adam, Lahiri, Abhik, Prochnow, Bobby, and
  Ng, Andrew~Y.
\newblock {On optimization methods for deep learning}.
\newblock \emph{International Conference on Machine Learning}, 2011.

\bibitem[Lin et~al.(2008)Lin, Weng, and Keerthi]{Lin2008}
Lin, Chih-Jen, Weng, Ruby~C, and Keerthi, S~Sathiya.
\newblock {Trust region newton method for logistic regression}.
\newblock \emph{The Journal of Machine Learning Research}, 9:\penalty0
  627--650, 2008.

\bibitem[Liu \& Nocedal(1989)Liu and Nocedal]{Liu1989}
Liu, Dong C~DC and Nocedal, Jorge.
\newblock {On the limited memory BFGS method for large scale optimization}.
\newblock \emph{Mathematical programming}, 45\penalty0 (1-3):\penalty0
  503--528, 1989.

\bibitem[Mairal(2013)]{Mairal2013}
Mairal, J.
\newblock {Optimization with First-Order Surrogate Functions}.
\newblock \emph{International Conference on Machine Learning}, 2013.

\bibitem[Mairal(2014)]{Mairal2014}
Mairal, Julien.
\newblock {Incremental Majorization-Minimization Optimization with Application
  to Large-Scale Machine Learning}.
\newblock \emph{arXiv:1402.4419}, February 2014.

\bibitem[Martens(2010)]{Martens2010}
Martens, James.
\newblock {Deep learning via Hessian-free optimization}.
\newblock In \emph{Proceedings of the 27th International Conference on Machine
  Learning (ICML)}, volume 951, pp.\  2010, 2010.

\bibitem[Papakonstantinou(2009)]{BFGShistory}
Papakonstantinou, JM.
\newblock \emph{{Historical Development of the BFGS Secant Method and Its
  Characterization Properties}}.
\newblock 2009.

\bibitem[Pascanu et~al.(2012)Pascanu, Mikolov, and Bengio]{Pascanu2012}
Pascanu, Razvan, Mikolov, Tomas, and Bengio, Yoshua.
\newblock {On the difficulty of training Recurrent Neural Networks}.
\newblock \emph{arXiv preprint arXiv:1211.5063.}, November 2012.

\bibitem[Rifai et~al.(2011)Rifai, Vincent, Muller, Glorot, and
  Bengio]{Rifai2011}
Rifai, Salah, Vincent, Pascal, Muller, Xavier, Glorot, Xavier, and Bengio,
  Yoshua.
\newblock {Contractive auto-encoders: Explicit invariance during feature
  extraction}.
\newblock In \emph{Proceedings of the 28th International Conference on Machine
  Learning (ICML-11)}, pp.\  833--840, 2011.

\bibitem[Robbins \& Monro(1951)Robbins and Monro]{Robbins1951}
Robbins, Herbert and Monro, Sutton.
\newblock {A stochastic approximation method}.
\newblock \emph{The Annals of Mathematical Statistics}, pp.\  400--407, 1951.

\bibitem[Roux et~al.(2012)Roux, Schmidt, and Bach]{Roux2012}
Roux, N~Le, Schmidt, M, and Bach, F.
\newblock {A Stochastic Gradient Method with an Exponential Convergence Rate
  for Finite Training Sets}.
\newblock \emph{NIPS}, 2012.

\bibitem[Schraudolph et~al.(2007)Schraudolph, Yu, and
  G\"{u}nter]{Schraudolph2007}
Schraudolph, Nicol, Yu, Jin, and G\"{u}nter, Simon.
\newblock {A stochastic quasi-Newton method for online convex optimization}.
\newblock \emph{AIstats}, 2007.

\bibitem[Schraudolph(1999)]{Schraudolph1999}
Schraudolph, Nicol~N.
\newblock {Local gain adaptation in stochastic gradient descent}.
\newblock In \emph{Artificial Neural Networks, 1999. ICANN 99. Ninth
  International Conference on (Conf. Publ. No. 470)}, volume~2, pp.\  569--574.
  IET, 1999.

\bibitem[Shanno(1970)]{Shanno1970}
Shanno, DF.
\newblock {Conditioning of quasi-Newton methods for function minimization}.
\newblock \emph{Mathematics of computation}, 1970.

\bibitem[Sohl-Dickstein(2012)]{Sohl-Dickstein2012b}
Sohl-Dickstein, Jascha.
\newblock {The Natural Gradient by Analogy to Signal Whitening, and Recipes and
  Tricks for its Use}.
\newblock \emph{arXiv:1205.1828v1}, May 2012.

\bibitem[Sohl-Dickstein et~al.(2011{\natexlab{a}})Sohl-Dickstein, Battaglino,
  and DeWeese]{SohlDickstein2011a}
Sohl-Dickstein, Jascha, Battaglino, Peter, and DeWeese, Michael.
\newblock {New Method for Parameter Estimation in Probabilistic Models: Minimum
  Probability Flow}.
\newblock \emph{Physical Review Letters}, 107\penalty0 (22):\penalty0 11--14,
  November 2011{\natexlab{a}}.
\newblock ISSN 0031-9007.
\newblock \doi{10.1103/PhysRevLett.107.220601}.

\bibitem[Sohl-Dickstein et~al.(2011{\natexlab{b}})Sohl-Dickstein, Battaglino,
  and DeWeese]{MPF_ICML}
Sohl-Dickstein, Jascha, Battaglino, Peter~B., and DeWeese, Michael~R.
\newblock {Minimum Probability Flow Learning}.
\newblock \emph{International Conference on Machine Learning}, 107\penalty0
  (22):\penalty0 11--14, November 2011{\natexlab{b}}.
\newblock ISSN 0031-9007.
\newblock \doi{10.1103/PhysRevLett.107.220601}.

\bibitem[Sunehag et~al.(2009)Sunehag, Trumpf, Vishwanathan, and
  Schraudolph]{Sunehag2009}
Sunehag, Peter, Trumpf, Jochen, Vishwanathan, S V~N, and Schraudolph, Nicol.
\newblock {Variable metric stochastic approximation theory}.
\newblock \emph{arXiv preprint arXiv:0908.3529}, August 2009.

\bibitem[Vinyals \& Povey(2011)Vinyals and Povey]{Vinyals2011}
Vinyals, Oriol and Povey, Daniel.
\newblock {Krylov subspace descent for deep learning}.
\newblock \emph{arXiv preprint arXiv:1111.4259}, 2011.

\end{thebibliography}
