\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alt et~al.(2019)Alt, {\v{S}}o{\v{s}}i{\'c}, and
  Koeppl]{alt2019correlation}
B.~Alt, A.~{\v{S}}o{\v{s}}i{\'c}, and H.~Koeppl.
\newblock Correlation priors for reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  14155--14165, 2019.

\bibitem[Bain and Crisan(2008)]{bain2008fundamentals}
A.~Bain and D.~Crisan.
\newblock \emph{Fundamentals of stochastic filtering}, volume~60.
\newblock Springer Science \& Business Media, 2008.

\bibitem[Baird(1994)]{baird1994reinforcement}
L.~C. Baird.
\newblock Reinforcement learning in continuous time: Advantage updating.
\newblock In \emph{Proceedings of 1994 IEEE International Conference on Neural
  Networks (ICNN'94)}, volume~4, pages 2448--2453. IEEE, 1994.

\bibitem[Bertsekas(1995)]{bertsekas1995dynamic}
D.~P. Bertsekas.
\newblock \emph{Dynamic programming and optimal control}, volume~2.
\newblock Athena scientific Belmont, MA, 1995.

\bibitem[Bhasin et~al.(2013)Bhasin, Kamalapurkar, Johnson, Vamvoudakis, Lewis,
  and Dixon]{bhasin2013novel}
S.~Bhasin, R.~Kamalapurkar, M.~Johnson, K.~G. Vamvoudakis, F.~L. Lewis, and
  W.~E. Dixon.
\newblock A novel actor--critic--identifier architecture for approximate
  optimal control of uncertain nonlinear systems.
\newblock \emph{Automatica}, 49\penalty0 (1):\penalty0 82--92, 2013.

\bibitem[Bolch et~al.(2006)Bolch, Greiner, De~Meer, and
  Trivedi]{bolch2006queueing}
G.~Bolch, S.~Greiner, H.~De~Meer, and K.~S. Trivedi.
\newblock \emph{Queueing networks and {M}arkov chains: modeling and performance
  evaluation with computer science applications}.
\newblock John Wiley \& Sons, 2006.

\bibitem[Bradtke and Duff(1995)]{bradtke1995reinforcement}
S.~J. Bradtke and M.~O. Duff.
\newblock Reinforcement learning methods for continuous-time {M}arkov decision
  problems.
\newblock In \emph{Advances in neural information processing systems}, pages
  393--400, 1995.

\bibitem[Cassandra(1998)]{cassandra1998exact}
A.~R. Cassandra.
\newblock \emph{Exact and Approximate Algorithms for Partially Observable
  {M}arkov Decision Processes}.
\newblock PhD thesis, Department of Computer Science, Brown University,
  Providence, RI, 1998.

\bibitem[Cassandra et~al.(1994)Cassandra, Kaelbling, and
  Littman]{cassandra1994acting}
A.~R. Cassandra, L.~P. Kaelbling, and M.~L. Littman.
\newblock Acting optimally in partially observable stochastic domains.
\newblock In \emph{AAAI}, volume~94, pages 1023--1028, 1994.

\bibitem[Cassandras and Lafortune(2009)]{cassandras2009introduction}
C.~G. Cassandras and S.~Lafortune.
\newblock \emph{Introduction to discrete event systems}.
\newblock Springer Science \& Business Media, 2009.

\bibitem[Cassandras and Lygeros(2018)]{cassandras2018stochastic}
C.~G. Cassandras and J.~Lygeros.
\newblock \emph{Stochastic hybrid systems}.
\newblock CRC Press, 2018.

\bibitem[Chaudhari et~al.(2013)Chaudhari, Karaman, Hsu, and
  Frazzoli]{chaudhari2013sampling}
P.~Chaudhari, S.~Karaman, D.~Hsu, and E.~Frazzoli.
\newblock Sampling-based algorithms for continuous-time {POMDP}s.
\newblock In \emph{2013 American Control Conference}, pages 4604--4610. IEEE,
  2013.

\bibitem[Doya(2000)]{doya2000reinforcement}
K.~Doya.
\newblock Reinforcement learning in continuous time and space.
\newblock \emph{Neural computation}, 12\penalty0 (1):\penalty0 219--245, 2000.

\bibitem[Feldbaum(1960)]{feldbaum1960dual}
A.~Feldbaum.
\newblock Dual control theory. i.
\newblock \emph{Avtomatika i Telemekhanika}, 21\penalty0 (9):\penalty0
  1240--1249, 1960.

\bibitem[Han et~al.(2018)Han, Jentzen, and Weinan]{han2018solving}
J.~Han, A.~Jentzen, and E.~Weinan.
\newblock Solving high-dimensional partial differential equations using deep
  learning.
\newblock \emph{Proceedings of the National Academy of Sciences}, 115\penalty0
  (34):\penalty0 8505--8510, 2018.

\bibitem[Hanson(2007)]{hanson2007applied}
F.~B. Hanson.
\newblock \emph{Applied stochastic processes and control for jump-diffusions:
  modeling, analysis and computation}.
\newblock SIAM, 2007.

\bibitem[Harmon and Baird~III(1996)]{harmon1996multi}
M.~E. Harmon and L.~C. Baird~III.
\newblock Multi-player residual advantage learning with general function
  approximation.
\newblock \emph{Wright Laboratory, WL/AACF, Wright-Patterson Air Force Base,
  OH}, pages 45433--7308, 1996.

\bibitem[Huang et~al.(2016)Huang, Pauleve, Zechner, Unger, Hansen, and
  Koeppl]{huang2016reconstructing}
L.~Huang, L.~Pauleve, C.~Zechner, M.~Unger, A.~S. Hansen, and H.~Koeppl.
\newblock Reconstructing dynamic molecular states from single-cell time series.
\newblock \emph{Journal of The Royal Society Interface}, 13\penalty0
  (122):\penalty0 20160533, 2016.

\bibitem[Igl et~al.(2018)Igl, Zintgraf, Le, Wood, and Whiteson]{igl2018deep}
M.~Igl, L.~Zintgraf, T.~A. Le, F.~Wood, and S.~Whiteson.
\newblock Deep variational reinforcement learning for {POMDP}s.
\newblock In \emph{International Conference on Machine Learning}, pages
  2117--2126, 2018.

\bibitem[Jacobson(1968)]{jacobson1968new}
D.~H. Jacobson.
\newblock New second-order and first-order algorithms for determining optimal
  control: A differential dynamic programming approach.
\newblock \emph{Journal of Optimization Theory and Applications}, 2\penalty0
  (6):\penalty0 411--440, 1968.

\bibitem[Jain and Precup(2018)]{jain2018eligibility}
A.~Jain and D.~Precup.
\newblock Eligibility traces for options.
\newblock In \emph{Proceedings of the 17th International Conference on
  Autonomous Agents and MultiAgent Systems}, pages 1008--1016. International
  Foundation for Autonomous Agents and Multiagent Systems, 2018.

\bibitem[Kaelbling et~al.(1998)Kaelbling, Littman, and
  Cassandra]{kaelbling1998planning}
L.~P. Kaelbling, M.~L. Littman, and A.~R. Cassandra.
\newblock Planning and acting in partially observable stochastic domains.
\newblock \emph{Artificial intelligence}, 101\penalty0 (1-2):\penalty0 99--134,
  1998.

\bibitem[Kalman(1963)]{kalman1963theory}
R.~Kalman.
\newblock The theory of optimal control and the calculus of variations.
\newblock In \emph{Mathematical optimization techniques}, pages 309--331.
  University of California Press Los Angeles, CA, 1963.

\bibitem[Kappen(2005)]{kappen2005path}
H.~J. Kappen.
\newblock Path integrals and symmetry breaking for optimal control theory.
\newblock \emph{Journal of statistical mechanics: theory and experiment},
  2005\penalty0 (11):\penalty0 P11011, 2005.

\bibitem[Kushner(1964)]{kushner1964differential}
H.~J. Kushner.
\newblock On the differential equations satisfied by conditional probablitity
  densities of {M}arkov processes, with applications.
\newblock \emph{Journal of the Society for Industrial and Applied Mathematics,
  Series A: Control}, 2\penalty0 (1):\penalty0 106--119, 1964.

\bibitem[LeCun et~al.(2015)LeCun, Bengio, and Hinton]{lecun2015deep}
Y.~LeCun, Y.~Bengio, and G.~Hinton.
\newblock Deep learning.
\newblock \emph{nature}, 521\penalty0 (7553):\penalty0 436--444, 2015.

\bibitem[Lewis and Shedler(1979)]{lewis1979simulation}
P.~W. Lewis and G.~S. Shedler.
\newblock Simulation of nonhomogeneous {P}oisson processes by thinning.
\newblock \emph{Naval research logistics quarterly}, 26\penalty0 (3):\penalty0
  403--413, 1979.

\bibitem[Lutter et~al.(2019)Lutter, Ritter, and Peters]{lutter2019deep}
M.~Lutter, C.~Ritter, and J.~Peters.
\newblock Deep {L}agrangian networks: Using physics as model prior for deep
  learning.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Lutter et~al.(2020)Lutter, Belousov, Listmann, Clever, and
  Peters]{lutter2019hjb}
M.~Lutter, B.~Belousov, K.~Listmann, D.~Clever, and J.~Peters.
\newblock {HJB} optimal feedback control with deep differential value functions
  and action constraints.
\newblock In \emph{Proceedings of the Conference on Robot Learning}, pages
  640--650. PMLR, 30 Oct--01 Nov 2020.

\bibitem[Mahadevan(1998)]{mahadevan1998partially}
S.~Mahadevan.
\newblock Partially observable semi-{M}arkov decision processes: Theory and
  applications in engineering and cognitive science.
\newblock In \emph{AAAI Fall Symposium on Planning with Partially Observable
  {M}arkov Decision Processes, Orlando, FL, USA}, pages 113--120, 1998.

\bibitem[Mei and Eisner(2017)]{mei2017neural}
H.~Mei and J.~M. Eisner.
\newblock The neural hawkes process: A neurally self-modulating multivariate
  point process.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  6754--6764, 2017.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{mnih2015human}
V.~Mnih, K.~Kavukcuoglu, D.~Silver, A.~A. Rusu, J.~Veness, M.~G. Bellemare,
  A.~Graves, M.~Riedmiller, A.~K. Fidjeland, G.~Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529--533, 2015.

\bibitem[Norris(1998)]{norris1998markov}
J.~R. Norris.
\newblock \emph{{M}arkov chains}.
\newblock Number~2 in Cambridge Series in Statistical and Probabilistic
  Mathematics. Cambridge university press, 1998.

\bibitem[Omidshafiei et~al.(2016)Omidshafiei, Agha-Mohammadi, Amato, Liu, How,
  and Vian]{omidshafiei2016graph}
S.~Omidshafiei, A.-A. Agha-Mohammadi, C.~Amato, S.-Y. Liu, J.~P. How, and
  J.~Vian.
\newblock Graph-based cross entropy method for solving multi-robot
  decentralized {POMDP}s.
\newblock In \emph{2016 IEEE International Conference on Robotics and
  Automation (ICRA)}, pages 5395--5402. IEEE, 2016.

\bibitem[Pontryagin(1962)]{pontryagin1962mathematical}
L.~S. Pontryagin.
\newblock \emph{The mathematical theory of optimal processes}.
\newblock John Wiley, 1962.

\bibitem[S{\"a}rkk{\"a} and Solin(2019)]{sarkka2019applied}
S.~S{\"a}rkk{\"a} and A.~Solin.
\newblock \emph{Applied stochastic differential equations}, volume~10.
\newblock Cambridge University Press, 2019.

\bibitem[Silver and Veness(2010)]{silver2010monte}
D.~Silver and J.~Veness.
\newblock Monte-carlo planning in large {POMDP}s.
\newblock In \emph{Advances in neural information processing systems}, pages
  2164--2172, 2010.

\bibitem[Simpkins and Todorov(2009)]{simpkins2009practical}
A.~Simpkins and E.~Todorov.
\newblock Practical numerical methods for stochastic optimal control of
  biological systems in continuous time and space.
\newblock In \emph{2009 IEEE Symposium on Adaptive Dynamic Programming and
  Reinforcement Learning}, pages 212--218. IEEE, 2009.

\bibitem[Sirignano and Spiliopoulos(2018)]{sirignano2018dgm}
J.~Sirignano and K.~Spiliopoulos.
\newblock {DGM}: A deep learning algorithm for solving partial differential
  equations.
\newblock \emph{Journal of Computational Physics}, 375:\penalty0 1339--1364,
  2018.

\bibitem[Srinivasan and Parlikad(2014)]{srinivasan2014semi}
R.~Srinivasan and A.~K. Parlikad.
\newblock Semi-{M}arkov decision process with partial information for
  maintenance decisions.
\newblock \emph{IEEE Transactions on Reliability}, 63\penalty0 (4):\penalty0
  891--898, 2014.

\bibitem[Stengel(1994)]{stengel1994optimal}
R.~F. Stengel.
\newblock \emph{Optimal control and estimation}.
\newblock Courier Corporation, 1994.

\bibitem[Sutton and Barto(2018)]{sutton2018reinforcement}
R.~S. Sutton and A.~G. Barto.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT Press, 2018.

\bibitem[Sutton et~al.(1999)Sutton, Precup, and Singh]{sutton1999between}
R.~S. Sutton, D.~Precup, and S.~Singh.
\newblock Between {MDP}s and semi-{MDP}s: A framework for temporal abstraction
  in reinforcement learning.
\newblock \emph{Artificial intelligence}, 112\penalty0 (1-2):\penalty0
  181--211, 1999.

\bibitem[Tallec et~al.(2019)Tallec, Blier, and Ollivier]{tallec2019making}
C.~Tallec, L.~Blier, and Y.~Ollivier.
\newblock Making deep q-learning methods robust to time discretization.
\newblock In K.~Chaudhuri and R.~Salakhutdinov, editors, \emph{Proceedings of
  the 36th International Conference on Machine Learning}, volume~97, pages
  6096--6104, Long Beach, California, USA, 09--15 Jun 2019. PMLR.

\bibitem[Tassa and Erez(2007)]{tassa2007least}
Y.~Tassa and T.~Erez.
\newblock Least squares solutions of the {HJB} equation with neural network
  value-function approximators.
\newblock \emph{IEEE transactions on neural networks}, 18\penalty0
  (4):\penalty0 1031--1041, 2007.

\bibitem[Tassa et~al.(2008)Tassa, Erez, and Smart]{tassa2008receding}
Y.~Tassa, T.~Erez, and W.~D. Smart.
\newblock Receding horizon differential dynamic programming.
\newblock In \emph{Advances in neural information processing systems}, pages
  1465--1472, 2008.

\bibitem[Theodorou and Todorov(2012)]{theodorou2012stochastic}
E.~A. Theodorou and E.~Todorov.
\newblock Stochastic optimal control for nonlinear {M}arkov jump diffusion
  processes.
\newblock In \emph{2012 American Control Conference (ACC)}, pages 1633--1639.
  IEEE, 2012.

\bibitem[Vamvoudakis and Lewis(2010)]{vamvoudakis2010online}
K.~G. Vamvoudakis and F.~L. Lewis.
\newblock Online actor--critic algorithm to solve the continuous-time infinite
  horizon optimal control problem.
\newblock \emph{Automatica}, 46\penalty0 (5):\penalty0 878--888, 2010.

\bibitem[Wang et~al.(2008)Wang, Blei, and Heckerman]{wang2008continuous}
C.~Wang, D.~Blei, and D.~Heckerman.
\newblock Continuous time dynamic topic models.
\newblock In \emph{Proceedings of the Twenty-Fourth Conference on Uncertainty
  in Artificial Intelligence}, pages 579--586, 2008.

\bibitem[Wang et~al.(2016)Wang, Schaul, Hessel, Van~Hasselt, Lanctot, and
  De~Freitas]{wang2015dueling}
Z.~Wang, T.~Schaul, M.~Hessel, H.~Van~Hasselt, M.~Lanctot, and N.~De~Freitas.
\newblock Dueling network architectures for deep reinforcement learning.
\newblock In \emph{Proceedings of the 33rd International Conference on
  International Conference on Machine Learning-Volume 48}, pages 1995--2003,
  2016.

\bibitem[Wildner and Koeppl(2019)]{wildner2019moment}
C.~Wildner and H.~Koeppl.
\newblock Moment-based variational inference for {M}arkov jump processes.
\newblock In \emph{International Conference on Machine Learning}, pages
  6766--6775, 2019.

\bibitem[Wonham(1964)]{wonham1964some}
W.~M. Wonham.
\newblock Some applications of stochastic differential equations to optimal
  nonlinear filtering.
\newblock \emph{Journal of the Society for Industrial and Applied Mathematics,
  Series A: Control}, 2\penalty0 (3):\penalty0 347--369, 1964.

\bibitem[Xie et~al.(2019)Xie, Li, and Lui]{xie2019optimizing}
H.~Xie, Y.~Li, and J.~C. Lui.
\newblock Optimizing discount and reputation trade-offs in e-commerce systems:
  Characterization and online learning.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 7992--7999, 2019.

\bibitem[Ye et~al.(2017)Ye, Somani, Hsu, and Lee]{ye2017despot}
N.~Ye, A.~Somani, D.~Hsu, and W.~S. Lee.
\newblock Despot: Online {POMDP} planning with regularization.
\newblock \emph{Journal of Artificial Intelligence Research}, 58:\penalty0
  231--266, 2017.

\end{thebibliography}
