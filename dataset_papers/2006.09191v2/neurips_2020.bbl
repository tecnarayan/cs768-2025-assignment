\begin{thebibliography}{10}

\bibitem{abadi2016tensorflow}
M.~Abadi, P.~Barham, J.~Chen, Z.~Chen, A.~Davis, J.~Dean, M.~Devin,
  S.~Ghemawat, G.~Irving, M.~Isard, et~al.
\newblock Tensorflow: A system for large-scale machine learning.
\newblock In {\em 12th $\{$USENIX$\}$ symposium on operating systems design and
  implementation ($\{$OSDI$\}$ 16)}, pages 265--283, 2016.

\bibitem{antoran_getting_2020}
J.~Antor{\'a}n, U.~Bhatt, T.~Adel, A.~Weller, and J.~M. Hern{\'a}ndez-Lobato.
\newblock Getting a clue: A method for explaining uncertainty estimates.
\newblock {\em arXiv preprint arXiv:2006.06848}, 2020.

\bibitem{baptista2018bayesian}
R.~Baptista and M.~Poloczek.
\newblock Bayesian optimization of combinatorial structures.
\newblock In {\em International Conference on Machine Learning}, pages
  462--471, 2018.

\bibitem{blanchard_output_weighted_2020}
A.~Blanchard and T.~Sapsis.
\newblock Output-weighted importance sampling for {B}ayesian experimental
  design and uncertainty quantification.
\newblock {\em arXiv preprint arXiv:2006.12394}, 2020.

\bibitem{bowman_generating_2016}
S.~R. Bowman, L.~Vilnis, O.~Vinyals, A.~M. Dai, R.~Jozefowicz, and S.~Bengio.
\newblock Generating sentences from a continuous space.
\newblock {\em CoNLL 2016}, page~10, 2016.

\bibitem{brochu2010tutorial}
E.~Brochu, V.~M. Cora, and N.~De~Freitas.
\newblock A tutorial on {Bayesian} optimization of expensive cost functions,
  with application to active user modeling and hierarchical reinforcement
  learning.
\newblock {\em arXiv preprint arXiv:1012.2599}, 2010.

\bibitem{brookes2019conditioning}
D.~Brookes, H.~Park, and J.~Listgarten.
\newblock Conditioning by adaptive sampling for robust design.
\newblock In {\em International Conference on Machine Learning}, pages
  773--782, 2019.

\bibitem{Brookes_Listgarten_2020}
D.~H. Brookes and J.~Listgarten.
\newblock Design by adaptive sampling.
\newblock {\em arXiv preprint arXiv:1810.03714}, 2018.

\bibitem{dai_syntax-directed_2018}
H.~Dai, Y.~Tian, B.~Dai, S.~Skiena, and L.~Song.
\newblock Syntax-directed variational autoencoder for structured data.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{daxberger2019bayesian}
E.~Daxberger and J.~M. Hern{\'a}ndez-Lobato.
\newblock Bayesian variational autoencoders for unsupervised
  out-of-distribution detection.
\newblock {\em arXiv preprint arXiv:1912.05651}, 2019.

\bibitem{daxberger2019mixed}
E.~Daxberger, A.~Makarova, M.~Turchetta, and A.~Krause.
\newblock Mixed-variable {B}ayesian optimization.
\newblock In C.~Bessiere, editor, {\em Proceedings of the Twenty-Ninth
  International Joint Conference on Artificial Intelligence, {IJCAI-20}}, pages
  2633--2639. International Joint Conferences on Artificial Intelligence
  Organization, 7 2020.
\newblock Main track.

\bibitem{de2005tutorial}
P.-T. De~Boer, D.~P. Kroese, S.~Mannor, and R.~Y. Rubinstein.
\newblock A tutorial on the cross-entropy method.
\newblock {\em Annals of operations research}, 134(1):19--67, 2005.

\bibitem{de_cao_molgan_2018}
N.~De~Cao and T.~Kipf.
\newblock Molgan: An implicit generative model for small molecular graphs.
\newblock {\em arXiv preprint arXiv:1805.11973}, 2018.

\bibitem{de2017gpflow}
A.~G. De~G.~Matthews, M.~Van Der~Wilk, T.~Nickson, K.~Fujii, A.~Boukouvalas,
  P.~Le{\'o}n-Villagr{\'a}, Z.~Ghahramani, and J.~Hensman.
\newblock Gpflow: A {Gaussian} process library using tensorflow.
\newblock {\em The Journal of Machine Learning Research}, 18(1):1299--1304,
  2017.

\bibitem{eismann_bayesian_2018}
S.~Eissman, D.~Levy, R.~Shu, S.~Bartzsch, and S.~Ermon.
\newblock Bayesian optimization and attribute adjustment.
\newblock In {\em Proc. 34th Conference on Uncertainty in Artificial
  Intelligence}, 2018.

\bibitem{elsken_neural_2019}
T.~Elsken, J.~H. Metzen, and F.~Hutter.
\newblock Neural architecture search: A survey.
\newblock {\em Journal of Machine Learning Research}, 20:1--21, 2019.

\bibitem{elton_deep_2019}
D.~C. Elton, Z.~Boukouvalas, M.~D. Fuge, and P.~W. Chung.
\newblock Deep learning for molecular designâ€”a review of the state of the
  art.
\newblock {\em Molecular Systems Design \& Engineering}, 4(4):828--849, 2019.

\bibitem{falcon2019pytorch}
W.~Falcon.
\newblock Pytorch lightning.
\newblock {\em GitHub. Note:
  https://github.com/PyTorchLightning/pytorch-lightning}, 3, 2019.

\bibitem{garnett_active_2013}
R.~Garnett, B.~DE, M.~A. Osborne, O.~AC, P.~Hennig, and M.~DE.
\newblock Active learning of linear embeddings for {Gaussian} processes.
\newblock {\em stat}, 1050:24, 2013.

\bibitem{gomez2018}
R.~G{\'o}mez-Bombarelli, J.~N. Wei, D.~Duvenaud, J.~M. Hern{\'a}ndez-Lobato,
  B.~S{\'a}nchez-Lengeling, D.~Sheberla, J.~Aguilera-Iparraguirre, T.~D.
  Hirzel, R.~P. Adams, and A.~Aspuru-Guzik.
\newblock Automatic chemical design using a data-driven continuous
  representation of molecules.
\newblock {\em ACS central science}, 4(2):268--276, 2018.

\bibitem{goodfellow2014generative}
I.~Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair,
  A.~Courville, and Y.~Bengio.
\newblock Generative adversarial nets.
\newblock In {\em Advances in neural information processing systems}, pages
  2672--2680, 2014.

\bibitem{griffiths_constrained_2020}
R.-R. Griffiths and J.~M. Hern{\'a}ndez-Lobato.
\newblock Constrained {B}ayesian optimization for automatic chemical design
  using variational autoencoders.
\newblock {\em Chemical science}, 11(2):577--586, 2020.

\bibitem{guimaraes_objective-reinforced_2018}
G.~L. Guimaraes, B.~Sanchez-Lengeling, C.~Outeiral, P.~L.~C. Farias, and
  A.~Aspuru-Guzik.
\newblock Objective-reinforced generative adversarial networks (organ) for
  sequence generation models.
\newblock {\em arXiv preprint arXiv:1705.10843}, 2017.

\bibitem{gupta_feedback_2019}
A.~Gupta and J.~Zou.
\newblock Feedback gan for dna optimizes protein functions.
\newblock {\em Nature Machine Intelligence}, 1(2):105--111, 2019.

\bibitem{hoang2018decentralized}
T.~N. Hoang, Q.~M. Hoang, R.~Ouyang, and K.~H. Low.
\newblock Decentralized high-dimensional {B}ayesian optimization with factor
  graphs.
\newblock In {\em Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem{huang_scalable_2015}
W.~Huang, D.~Zhao, F.~Sun, H.~Liu, and E.~Chang.
\newblock Scalable {G}aussian process regression using deep neural networks.
\newblock In {\em Twenty-fourth international joint conference on artificial
  intelligence}. Citeseer, 2015.

\bibitem{irwin_zinc_2012}
J.~J. Irwin, T.~Sterling, M.~M. Mysinger, E.~S. Bolstad, and R.~G. Coleman.
\newblock Zinc: a free tool to discover chemistry for biology.
\newblock {\em Journal of chemical information and modeling}, 52(7):1757--1768,
  2012.

\bibitem{jin_junction_2019}
W.~Jin, R.~Barzilay, and T.~Jaakkola.
\newblock Junction tree variational autoencoder for molecular graph generation.
\newblock In {\em International Conference on Machine Learning}, pages
  2323--2332, 2018.

\bibitem{jin_learning_2019}
W.~Jin, K.~Yang, R.~Barzilay, and T.~Jaakkola.
\newblock Learning multimodal graph-to-graph translation for molecule
  optimization.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{jones1998efficient}
D.~R. Jones, M.~Schonlau, and W.~J. Welch.
\newblock Efficient global optimization of expensive black-box functions.
\newblock {\em Journal of Global optimization}, 13(4):455--492, 1998.

\bibitem{kajino_molecular_2019}
H.~Kajino.
\newblock Molecular hypergraph grammar with its application to molecular
  optimization.
\newblock In {\em International Conference on Machine Learning}, pages
  3183--3191. PMLR, 2019.

\bibitem{kandasamy2015high}
K.~Kandasamy, J.~Schneider, and B.~P{\'o}czos.
\newblock High dimensional {Bayesian} optimisation and bandits via additive
  models.
\newblock In {\em International Conference on Machine Learning}, pages
  295--304, 2015.

\bibitem{kang_conditional_2019}
S.~Kang and K.~Cho.
\newblock Conditional molecular design with deep generative models.
\newblock {\em Journal of chemical information and modeling}, 59(1):43--52,
  2018.

\bibitem{kim2019bayesian}
J.~Kim, M.~McCourt, T.~You, S.~Kim, and S.~Choi.
\newblock Bayesian optimization over sets.
\newblock {\em arXiv preprint arXiv:1905.09780}, 2019.

\bibitem{kingma2013auto}
D.~P. Kingma and M.~Welling.
\newblock Auto-encoding variational {B}ayes.
\newblock {\em arXiv preprint arXiv:1312.6114}, 2013.

\bibitem{korovina2020chembo}
K.~Korovina, S.~Xu, K.~Kandasamy, W.~Neiswanger, B.~Poczos, J.~Schneider, and
  E.~Xing.
\newblock Chembo: {Bayesian} optimization of small organic molecules with
  synthesizable recommendations.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 3393--3403. PMLR, 2020.

\bibitem{kusner_grammar_2017}
M.~J. Kusner, B.~Paige, and J.~M. Hern{\'a}ndez-Lobato.
\newblock Grammar variational autoencoder.
\newblock In {\em International Conference on Machine Learning}, pages
  1945--1954, 2017.

\bibitem{li_deep_2018}
Y.~Li.
\newblock Deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1810.06339}, 2018.

\bibitem{li_multi-objective_2018}
Y.~Li, L.~Zhang, and Z.~Liu.
\newblock Multi-objective de novo drug design with conditional graph generative
  model.
\newblock {\em Journal of cheminformatics}, 10(1):33, 2018.

\bibitem{lim_molecular_2018}
J.~Lim, S.~Ryu, J.~W. Kim, and W.~Y. Kim.
\newblock Molecular generative model based on conditional variational
  autoencoder for de novo molecular design.
\newblock {\em Journal of cheminformatics}, 10(1):1--9, 2018.

\bibitem{lu2018structured}
X.~Lu, J.~Gonzalez, Z.~Dai, and N.~Lawrence.
\newblock Structured variationally auto-encoded optimization.
\newblock In {\em International Conference on Machine Learning}, pages
  3267--3275, 2018.

\bibitem{luo2018neural}
R.~Luo, F.~Tian, T.~Qin, E.~Chen, and T.-Y. Liu.
\newblock Neural architecture optimization.
\newblock In {\em Advances in neural information processing systems}, pages
  7816--7827, 2018.

\bibitem{mahmood_cold_2019}
O.~Mahmood and J.~M. Hern{\'a}ndez-Lobato.
\newblock A cold approach to generating optimal samples.
\newblock {\em arXiv preprint arXiv:1905.09885}, 2019.

\bibitem{mccloskey_catastrophic_1989}
M.~McCloskey and N.~J. Cohen.
\newblock Catastrophic interference in connectionist networks: The sequential
  learning problem.
\newblock In {\em Psychology of learning and motivation}, volume~24, pages
  109--165. Elsevier, 1989.

\bibitem{mirza_conditional_2014}
M.~Mirza and S.~Osindero.
\newblock Conditional generative adversarial nets.
\newblock {\em arXiv preprint arXiv:1411.1784}, 2014.

\bibitem{mutny2018efficient}
M.~Mutny and A.~Krause.
\newblock Efficient high dimensional {B}ayesian optimization with additivity
  and quadrature fourier features.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  9005--9016, 2018.

\bibitem{nguyen_plug_2017}
A.~Nguyen, J.~Clune, Y.~Bengio, A.~Dosovitskiy, and J.~Yosinski.
\newblock Plug \& play generative networks: Conditional iterative generation of
  images in latent space.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 4467--4477, 2017.

\bibitem{nguyen_synthesizing_2016}
A.~Nguyen, A.~Dosovitskiy, J.~Yosinski, T.~Brox, and J.~Clune.
\newblock Synthesizing the preferred inputs for neurons in neural networks via
  deep generator networks.
\newblock In {\em Advances in neural information processing systems}, pages
  3387--3395, 2016.

\bibitem{oh2019combinatorial}
C.~Oh, J.~M. Tomczak, E.~Gavves, and M.~Welling.
\newblock Combinatorial {Bayesian} optimization using graph representations.
\newblock {\em arXiv preprint arXiv:1902.00448}, 2019.

\bibitem{olivecrona_molecular_2017}
M.~Olivecrona, T.~Blaschke, O.~Engkvist, and H.~Chen.
\newblock Molecular de-novo design through deep reinforcement learning.
\newblock {\em Journal of cheminformatics}, 9(1):48, 2017.

\bibitem{otter_survey_2020}
D.~W. Otter, J.~R. Medina, and J.~K. Kalita.
\newblock A survey of the usages of deep learning for natural language
  processing.
\newblock {\em IEEE Transactions on Neural Networks and Learning Systems},
  2020.

\bibitem{paszke2017automatic}
A.~Paszke, S.~Gross, S.~Chintala, G.~Chanan, E.~Yang, Z.~DeVito, Z.~Lin,
  A.~Desmaison, L.~Antiga, and A.~Lerer.
\newblock Automatic differentiation in pytorch.
\newblock 2017.

\bibitem{peters2007reinforcement}
J.~Peters and S.~Schaal.
\newblock Reinforcement learning by reward-weighted regression for operational
  space control.
\newblock In {\em Proceedings of the 24th international conference on Machine
  learning}, pages 745--750, 2007.

\bibitem{popova_deep_2018}
M.~Popova, O.~Isayev, and A.~Tropsha.
\newblock Deep reinforcement learning for de novo drug design.
\newblock {\em Science advances}, 4(7):eaap7885, 2018.

\bibitem{rezende2014stochastic}
D.~J. Rezende, S.~Mohamed, and D.~Wierstra.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock In {\em International Conference on Machine Learning}, pages
  1278--1286, 2014.

\bibitem{rubinstein_cross-entropy_1999}
R.~Rubinstein.
\newblock The cross-entropy method for combinatorial and continuous
  optimization.
\newblock {\em Methodology and computing in applied probability},
  1(2):127--190, 1999.

\bibitem{rubinstein_optimization_1997}
R.~Y. Rubinstein.
\newblock Optimization of computer simulation models with rare events.
\newblock {\em European Journal of Operational Research}, 99(1):89--112, 1997.

\bibitem{sanchez-lengeling_inverse_2018}
B.~Sanchez-Lengeling and A.~Aspuru-Guzik.
\newblock Inverse molecular design using machine learning: Generative models
  for matter engineering.
\newblock {\em Science}, 361(6400):360--365, 2018.

\bibitem{segler_generating_2018}
M.~H. Segler, T.~Kogej, C.~Tyrchan, and M.~P. Waller.
\newblock Generating focused molecule libraries for drug discovery with
  recurrent neural networks.
\newblock {\em ACS central science}, 4(1):120--131, 2018.

\bibitem{sener_active_2018}
O.~Sener and S.~Savarese.
\newblock Active learning for convolutional neural networks: A core-set
  approach.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{shahriari2015taking}
B.~Shahriari, K.~Swersky, Z.~Wang, R.~P. Adams, and N.~De~Freitas.
\newblock Taking the human out of the loop: A review of {Bayesian}
  optimization.
\newblock {\em Proceedings of the IEEE}, 104(1):148--175, 2015.

\bibitem{simm_reinforcement_2020}
G.~N. Simm, R.~Pinsler, and J.~M. Hern{\'a}ndez-Lobato.
\newblock Reinforcement learning for molecular design guided by quantum
  mechanics.
\newblock {\em arXiv preprint arXiv:2002.07717}, 2020.

\bibitem{simonovsky_graphvae_2018}
M.~Simonovsky and N.~Komodakis.
\newblock Graphvae: Towards generation of small graphs using variational
  autoencoders.
\newblock In {\em International Conference on Artificial Neural Networks},
  pages 412--422. Springer, 2018.

\bibitem{snoek2012practical}
J.~Snoek, H.~Larochelle, and R.~P. Adams.
\newblock Practical {Bayesian} optimization of machine learning algorithms.
\newblock In {\em Advances in neural information processing systems}, pages
  2951--2959, 2012.

\bibitem{sohn_learning_2015}
K.~Sohn, H.~Lee, and X.~Yan.
\newblock Learning structured output representation using deep conditional
  generative models.
\newblock In {\em Advances in neural information processing systems}, pages
  3483--3491, 2015.

\bibitem{sutton1998introduction}
R.~S. Sutton, A.~G. Barto, et~al.
\newblock {\em Introduction to reinforcement learning}, volume 135.
\newblock MIT press Cambridge, 1998.

\bibitem{titsias2009variational}
M.~Titsias.
\newblock Variational learning of inducing variables in sparse {Gaussian}
  processes.
\newblock In {\em Artificial Intelligence and Statistics}, pages 567--574,
  2009.

\bibitem{van_den_oord_conditional_2016}
A.~Van~den Oord, N.~Kalchbrenner, L.~Espeholt, O.~Vinyals, A.~Graves, et~al.
\newblock Conditional image generation with pixelcnn decoders.
\newblock In {\em Advances in neural information processing systems}, pages
  4790--4798, 2016.

\bibitem{van1987simulated}
P.~J. Van~Laarhoven and E.~H. Aarts.
\newblock Simulated annealing.
\newblock In {\em Simulated annealing: Theory and applications}, pages 7--15.
  Springer, 1987.

\bibitem{wang_graphgan_2018}
H.~Wang, J.~Wang, J.~Wang, M.~Zhao, W.~Zhang, F.~Zhang, X.~Xie, and M.~Guo.
\newblock {GraphGAN}: {Graph} {Representation} {Learning} {With} {Generative}
  {Adversarial} {Nets}.
\newblock In {\em Thirty-{Second} {AAAI} {Conference} on {Artificial}
  {Intelligence}}, Apr. 2018.

\bibitem{wang_bayesian_2013}
Z.~Wang, M.~Zoghi, F.~Hutter, D.~Matheson, and N.~De~Freitas.
\newblock Bayesian optimization in high dimensions via random embeddings.
\newblock In {\em Proceedings of the Twenty-Third international joint
  conference on Artificial Intelligence}, pages 1778--1784. AAAI Press, 2013.

\bibitem{white_sampling_2016}
T.~White.
\newblock Sampling generative networks.
\newblock {\em arXiv preprint arXiv:1609.04468}, 2016.

\bibitem{williams2006gaussian}
C.~K. Williams and C.~E. Rasmussen.
\newblock {\em Gaussian processes for machine learning}, volume~2.
\newblock MIT press Cambridge, MA, 2006.

\bibitem{wilson_deep_2016}
A.~G. Wilson, Z.~Hu, R.~Salakhutdinov, and E.~P. Xing.
\newblock Deep kernel learning.
\newblock In {\em Artificial intelligence and statistics}, pages 370--378,
  2016.

\bibitem{you_graph_2018}
J.~You, B.~Liu, Z.~Ying, V.~Pande, and J.~Leskovec.
\newblock Graph convolutional policy network for goal-directed molecular graph
  generation.
\newblock In {\em Advances in neural information processing systems}, pages
  6410--6421, 2018.

\bibitem{zhang_d_vae_2019}
M.~Zhang, S.~Jiang, Z.~Cui, R.~Garnett, and Y.~Chen.
\newblock D-vae: A variational autoencoder for directed acyclic graphs.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1588--1600, 2019.

\bibitem{zhou_optimization_2019}
Z.~Zhou, S.~Kearnes, L.~Li, R.~N. Zare, and P.~Riley.
\newblock Optimization of molecules via deep reinforcement learning.
\newblock {\em Scientific reports}, 9(1):1--10, 2019.

\end{thebibliography}
