\begin{thebibliography}{10}

\bibitem{importantData1}
Alon~Y. Halevy, Peter Norvig, and Fernando Pereira.
\newblock The unreasonable effectiveness of data.
\newblock {\em {IEEE} Intell. Syst.}, 24(2):8--12, 2009.

\bibitem{importantData2}
Chen Sun, Abhinav Shrivastava, Saurabh Singh, and Abhinav Gupta.
\newblock Revisiting unreasonable effectiveness of data in deep learning era.
\newblock In {\em {IEEE} International Conference on Computer Vision, {ICCV}
  2017, Venice, Italy, October 22-29, 2017}, pages 843--852. {IEEE} Computer
  Society, 2017.

\bibitem{importantDataBench}
Ravit Dotan and Smitha Milli.
\newblock Value-laden disciplinary shifts in machine learning.
\newblock In Mireille Hildebrandt, Carlos Castillo, L.~Elisa Celis, Salvatore
  Ruggieri, Linnet Taylor, and Gabriela Zanfir{-}Fortuna, editors, {\em FAT*
  '20: Conference on Fairness, Accountability, and Transparency, Barcelona,
  Spain, January 27-30, 2020}, page 294. {ACM}, 2020.

\bibitem{mlstory}
Moritz Hardt and Benjamin Recht.
\newblock {\em Patterns, predictions, and actions: Foundations of machine
  learning}, chapter~8.
\newblock Princeton University Press, 2022.

\bibitem{exacerbate-inequities-howard2018ugly}
Ayanna Howard and Jason Borenstein.
\newblock The ugly truth about ourselves and our robot creations: the problem
  of bias and social inequity.
\newblock {\em Science and engineering ethics}, 24(5):1521--1536, 2018.

\bibitem{angwin2016machine}
Julia Angwin, Jeff Larson, Lauren Kirchner, and Surya Mattu.
\newblock Machine bias: There’s software used across the country to predict
  future criminals. and it’s biased against blacks.
\newblock
  \url{https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing},
  May 2016.
\newblock Accessed: 2022-05-16.

\bibitem{exacerbate-inequities-o2016weapons}
Cathy O'Neil.
\newblock {\em Weapons of math destruction: How big data increases inequality
  and threatens democracy}.
\newblock Crown, 2016.

\bibitem{measure-barocas}
Solon Barocas, Moritz Hardt, and Arvind Narayanan.
\newblock Fairness in machine learning.
\newblock {\em {NIPS} tutorial}, 1:2017, 2017.

\bibitem{empirical-friedler2019comparative}
Sorelle~A Friedler, Carlos Scheidegger, Suresh Venkatasubramanian, Sonam
  Choudhary, Evan~P Hamilton, and Derek Roth.
\newblock A comparative study of fairness-enhancing interventions in machine
  learning.
\newblock In {\em Proceedings of the conference on fairness, accountability,
  and transparency}, pages 329--338, 2019.

\bibitem{empirical-lamba2021empirical}
Hemank Lamba, Kit~T Rodolfa, and Rayid Ghani.
\newblock An empirical comparison of bias reduction methods on real-world
  problems in high-stakes policy settings.
\newblock {\em ACM SIGKDD Explorations Newsletter}, 23(1):69--85, 2021.

\bibitem{fabris2022algorithmic}
Alessandro Fabris, Stefano Messina, Gianmaria Silvello, and Gian~Antonio Susto.
\newblock Algorithmic fairness datasets: the story so far.
\newblock {\em arXiv preprint arXiv:2202.01711}, 2022.

\bibitem{ding2021retiring}
Frances Ding, Moritz Hardt, John Miller, and Ludwig Schmidt.
\newblock Retiring adult: New datasets for fair machine learning.
\newblock In {\em Advances in Neural Information Processing Systems}, 2021.

\bibitem{bao2021compaslicated}
Michelle Bao, Angela Zhou, Samantha Zottola, Brian Brubach, Brian Brubach,
  Sarah Desmarais, Aaron Horowitz, Kristian Lum, and Suresh Venkatasubramanian.
\newblock It's compaslicated: The messy relationship between {RAI} datasets and
  algorithmic fairness benchmarks.
\newblock In Joaquin Vanschoren and Sai{-}Kit Yeung, editors, {\em Proceedings
  of the Neural Information Processing Systems Track on Datasets and Benchmarks
  1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual}, 2021.

\bibitem{shifts}
Andrey Malinin, Neil Band, Yarin Gal, Mark J.~F. Gales, Alexander Ganshin,
  German Chesnokov, Alexey Noskov, Andrey Ploskonosov, Liudmila Prokhorenkova,
  Ivan Provilkov, Vatsal Raina, Vyas Raina, Denis Roginskiy, Mariya Shmatova,
  Panagiotis Tigas, and Boris Yangel.
\newblock Shifts: {A} dataset of real distributional shift across multiple
  large-scale tasks.
\newblock In Joaquin Vanschoren and Sai{-}Kit Yeung, editors, {\em Proceedings
  of the Neural Information Processing Systems Track on Datasets and Benchmarks
  1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual}, 2021.

\bibitem{discontents}
Amandalynne Paullada, Inioluwa~Deborah Raji, Emily~M. Bender, Emily Denton, and
  Alex Hanna.
\newblock Data and its (dis)contents: {A} survey of dataset development and use
  in machine learning research.
\newblock {\em Patterns}, 2(11):100336, 2021.

\bibitem{koch2021reduced}
Bernard Koch, Emily Denton, Alex Hanna, and Jacob~G. Foster.
\newblock Reduced, reused and recycled: The life of a dataset in machine
  learning research.
\newblock In Joaquin Vanschoren and Sai{-}Kit Yeung, editors, {\em Proceedings
  of the Neural Information Processing Systems Track on Datasets and Benchmarks
  1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual}, 2021.

\bibitem{luccioni2022framework}
Alexandra~Sasha Luccioni, Frances Corry, Hamsini Sridharan, Mike Ananny, Jason
  Schultz, and Kate Crawford.
\newblock A framework for deprecating datasets: Standardizing documentation,
  identification, and communication.
\newblock 2022.

\bibitem{zhang2021index}
Daniel Zhang, Saurabh Mishra, Erik Brynjolfsson, John Etchemendy, Deep Ganguli,
  Barbara Grosz, Terah Lyons, James Manyika, Juan Niebles, Michael Sellitto,
  Yoav Shoham, Jack Clark, and Raymond Perrault.
\newblock The ai index 2021 annual report.
\newblock In {\em AI Index Steering Committee, Human-Centered AI Institute,
  Stanford University, Stanford, CA}, March 2021.

\bibitem{gebru2018datasheets}
Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman~Vaughan,
  Hanna Wallach, Hal Daumé~III, and Kate Crawford.
\newblock Datasheets for datasets, March 2018.

\bibitem{vadhanOpenDPOpenSourceSuite2019a}
S.~Vadhan, M.~Crosas, and James Honaker.
\newblock {{OpenDP}} : {{An Open-Source Suite}} of {{Differential Privacy
  Tools}}.
\newblock
  https://www.semanticscholar.org/paper/OpenDP-\%3A-An-Open-Source-Suite-of-Differential-Tools-Vadhan-Crosas/853f3d2673078c0fe7d16b04c7eae307905eb22b,
  2019.

\bibitem{NIPS2014_5ca3e9b1}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In Z.~Ghahramani, M.~Welling, C.~Cortes, N.~Lawrence, and K.Q.
  Weinberger, editors, {\em Advances in Neural Information Processing Systems},
  volume~27. Curran Associates, Inc., 2014.

\bibitem{GDPR}
{European Parliament and Council}.
\newblock {Regulation (EU) 2016/679 of the European Parliament and of the
  Council of 27 April 2016 on the protection of natural persons with regard to
  the processing of personal data and on the free movement of such data, and
  repealing Directive 95/46}.
\newblock {\em Official Journal of the European Union (OJ)}, 59:1, 2016.

\bibitem{dwork2006calibrating}
Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith.
\newblock Calibrating noise to sensitivity in private data analysis.
\newblock In {\em Theory of cryptography conference}, pages 265--284. Springer,
  2006.

\bibitem{fairmlbook}
Solon Barocas, Moritz Hardt, and Arvind Narayanan.
\newblock {\em Fairness and Machine Learning}.
\newblock fairmlbook.org, 2019.
\newblock \url{http://www.fairmlbook.org}.

\bibitem{dalpozzoloCalibratingProbabilityUndersampling2015}
Andrea Dal~Pozzolo, Olivier Caelen, Reid Johnson, and Gianluca Bontempi.
\newblock Calibrating {{Probability}} with {{Undersampling}} for {{Unbalanced
  Classification}}.
\newblock In {\em 2015 {{IEEE Symposium Series}} on {{Computational
  Intelligence}} ({{SSCI}})}, {Cape Town, South Africa}, December 2015.

\bibitem{lopez-rojasPAYSIMFINANCIALMOBILE2016}
Edgar~Alonso {Lopez-Rojas}, Ahmad Elmir, and Stefan Axelsson.
\newblock {{PAYSIM}}: {{A FINANCIAL MOBILE MONEY SIMULATOR FOR FRAUD
  DETECTION}}.
\newblock In {\em 28th {{European Modeling}} and {{Simulation Symposium}} 2016
  ({{EMSS}} 2016)}, {Larnaca, Cyprus}, September 2016.

\bibitem{basic_account_EU}
{European Parliament and Council}.
\newblock {Directive 2014/92/EU of the European Parliament and of the Council
  of 23 July 2014 on the comparability of fees related to payment accounts,
  payment account switching and access to payment accounts with basic
  features}.
\newblock {\em Official Journal of the European Union (OJ)}, 57:214, 2014.

\bibitem{kohavi1996scaling}
Ron Kohavi.
\newblock Scaling up the accuracy of naive-bayes classifiers: A decision-tree
  hybrid.
\newblock In {\em Proceedings of the Second International Conference on
  Knowledge Discovery and Data Mining}, KDD'96, page 202–207. AAAI Press,
  1996.

\bibitem{dua2017uci}
Dheeru Dua and Casey Graff.
\newblock {UCI} machine learning repository, 2017.

\bibitem{quy2022survey}
Tai Le~Quy, Arjun Roy, Vasileios Iosifidis, Wenbin Zhang, and Eirini Ntoutsi.
\newblock A survey on datasets for fairness‐aware machine learning.
\newblock In {\em Wiley Interdisciplinary Reviews: Data Mining and Knowledge
  Discovery}, 03 2022.

\bibitem{barenstein2019propublica}
Matias {Barenstein}.
\newblock {ProPublica's COMPAS Data Revisited}.
\newblock page arXiv:1906.04711, Jun 2019.

\bibitem{gromping2019south}
Ulrike Grömping.
\newblock South german credit data: Correcting a widely used data set.
\newblock In {\em Reports in Mathematics, Physics and Chemistry}, 2019.

\bibitem{lequySurveyDatasetsFairnessaware2022}
Tai Le~Quy, Arjun Roy, Vasileios Iosifidis, Wenbin Zhang, and Eirini Ntoutsi.
\newblock A survey on datasets for fairness-aware machine learning.
\newblock {\em WIREs Data Mining and Knowledge Discovery}, 12(3):e1452, 2022.

\bibitem{kroger2021how}
Jacob~Leon Kr{\"o}ger, Milagros Miceli, and Florian M{\"u}ller.
\newblock How data can be used against people: A classification of personal
  data misuses.
\newblock {\em SSRN Electronic Journal}, 2021.

\bibitem{dworkDifferentialPrivacySurvey2008}
Cynthia Dwork.
\newblock Differential {{Privacy}}: {{A Survey}} of {{Results}}.
\newblock In Manindra Agrawal, Dingzhu Du, Zhenhua Duan, and Angsheng Li,
  editors, {\em Theory and {{Applications}} of {{Models}} of {{Computation}}},
  Lecture {{Notes}} in {{Computer Science}}, pages 1--19, {Berlin, Heidelberg},
  2008. {Springer}.

\bibitem{jordon2018pate}
James Jordon, Jinsung Yoon, and Mihaela Van Der~Schaar.
\newblock Pate-gan: Generating synthetic data with differential privacy
  guarantees.
\newblock In {\em International conference on learning representations}, 2018.

\bibitem{chen2018differentially}
Qingrong Chen, Chong Xiang, Minhui Xue, Bo~Li, Nikita Borisov, Dali Kaafar, and
  Haojin Zhu.
\newblock Differentially private data generative models.
\newblock {\em CoRR}, abs/1812.02274, 2018.

\bibitem{xu2019modeling}
Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, and Kalyan Veeramachaneni.
\newblock Modeling tabular data using conditional gan.
\newblock In {\em Advances in Neural Information Processing Systems}, 2019.

\bibitem{rosenblattDifferentiallyPrivateSynthetic2020}
Lucas Rosenblatt, Xiaoyan Liu, Samira Pouyanfar, Eduardo {de Leon}, Anuj Desai,
  and Joshua Allen.
\newblock Differentially {{Private Synthetic Data}}: {{Applied Evaluations}}
  and {{Enhancements}}, November 2020.

\bibitem{taoBenchmarkingDifferentiallyPrivate2022}
Yuchao Tao, Ryan McKenna, Michael Hay, Ashwin Machanavajjhala, and Gerome
  Miklau.
\newblock Benchmarking {{Differentially Private Synthetic Data Generation
  Algorithms}}, February 2022.

\bibitem{kato2012}
Kato Mivule.
\newblock Utilizing noise addition for data privacy, an overview.
\newblock In {\em Proceedings of the International Conference on Information
  and Knowledge Engineering (IKE 2012)}, 07 2012.

\bibitem{borji2022evaluation}
Ali Borji.
\newblock Pros and cons of gan evaluation measures: New developments.
\newblock {\em Computer Vision and Image Understanding}, 215:103329, 2022.

\bibitem{zhao2021effective}
Zilong Zhao, Aditya Kunar, Robert Birke, and Lydia~Y. Chen.
\newblock Ctab-gan: Effective table data synthesizing.
\newblock In Vineeth~N. Balasubramanian and Ivor Tsang, editors, {\em
  Proceedings of The 13th Asian Conference on Machine Learning}, volume 157 of
  {\em Proceedings of Machine Learning Research}, pages 97--112. PMLR, 17--19
  Nov 2021.

\bibitem{ke2017lightgbm}
Guolin Ke, Qi~Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei
  Ye, and Tie-Yan Liu.
\newblock Lightgbm: A highly efficient gradient boosting decision tree.
\newblock In I.~Guyon, U.~Von Luxburg, S.~Bengio, H.~Wallach, R.~Fergus,
  S.~Vishwanathan, and R.~Garnett, editors, {\em Advances in Neural Information
  Processing Systems}, volume~30. Curran Associates, Inc., 2017.

\bibitem{corbett-daviesAlgorithmicDecisionMaking2017}
Sam {Corbett-Davies}, Emma Pierson, Avi Feller, Sharad Goel, and Aziz Huq.
\newblock Algorithmic {{Decision Making}} and the {{Cost}} of {{Fairness}}.
\newblock In {\em Proceedings of the 23rd {{ACM SIGKDD International
  Conference}} on {{Knowledge Discovery}} and {{Data Mining}}}, {{KDD}} '17,
  pages 797--806, {New York, NY, USA}, August 2017. {Association for Computing
  Machinery}.

\bibitem{pombalUnderstandingUnfairnessFraud2022}
Jos{\'e} Pombal, Andr{\'e}~F. Cruz, Jo{\~a}o Bravo, Pedro Saleiro, M{\'a}rio
  A.~T. Figueiredo, and Pedro Bizarro.
\newblock Understanding {{Unfairness}} in {{Fraud Detection}} through {{Model}}
  and {{Data Bias Interactions}}.
\newblock In {\em {{KDD}} 2022 {{Workshop}} on {{Machine Learning}} in
  {{Finance}}}, July 2022.

\bibitem{zafar2017fairness}
Muhammad~Bilal Zafar, Isabel Valera, Manuel Gomez-Rodriguez, and Krishna~P.
  Gummadi.
\newblock Fairness constraints: Mechanisms for fair classification.
\newblock In {\em AISTATS}, 2017.

\bibitem{strategic-classification}
Nilesh~N. Dalvi, Pedro~M. Domingos, Mausam, Sumit~K. Sanghai, and Deepak Verma.
\newblock Adversarial classification.
\newblock In Won Kim, Ron Kohavi, Johannes Gehrke, and William DuMouchel,
  editors, {\em Proceedings of the Tenth {ACM} {SIGKDD} International
  Conference on Knowledge Discovery and Data Mining, Seattle, Washington, USA,
  August 22-25, 2004}, pages 99--108. {ACM}, 2004.

\bibitem{performative-prediction}
Juan~C. Perdomo, Tijana Zrnic, Celestine Mendler{-}D{\"{u}}nner, and Moritz
  Hardt.
\newblock Performative prediction.
\newblock In {\em Proceedings of the 37th International Conference on Machine
  Learning, {ICML} 2020, 13-18 July 2020, Virtual Event}, volume 119 of {\em
  Proceedings of Machine Learning Research}, pages 7599--7609. {PMLR}, 2020.

\bibitem{pombalPrisonersTheirOwn2022}
Jos{\'e} Pombal, Pedro Saleiro, M{\'a}rio A.~T. Figueiredo, and Pedro Bizarro.
\newblock Prisoners of {{Their Own Devices}}: {{How Models Induce Data Bias}}
  in {{Performative Prediction}}.
\newblock In {\em {{ICML}} 2022 {{Workshop}} on {{Responsible Decision Making}}
  in {{Dynamic Environments}}}, August 2022.

\bibitem{xieDifferentiallyPrivateGenerative2018}
Liyang Xie, Kaixiang Lin, Shu Wang, Fei Wang, and Jiayu Zhou.
\newblock Differentially {{Private Generative Adversarial Network}}, February
  2018.

\end{thebibliography}
