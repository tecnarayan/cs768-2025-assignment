\begin{thebibliography}{102}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbe et~al.(2020)Abbe, Fan, Wang, and Zhong]{abbe2020entrywise}
Emmanuel Abbe, Jianqing Fan, Kaizheng Wang, and Yiqiao Zhong.
\newblock Entrywise eigenvector analysis of random matrices with low expected rank.
\newblock \emph{The Annals of Statistics}, 48\penalty0 (3):\penalty0 1452, 2020.

\bibitem[Abbe et~al.(2022)Abbe, Fan, and Wang]{abbe2022l}
Emmanuel Abbe, Jianqing Fan, and Kaizheng Wang.
\newblock An $\ell_p$ theory of pca and spectral clustering.
\newblock \emph{The Annals of Statistics}, 50\penalty0 (4):\penalty0 2359--2385, 2022.

\bibitem[Alon et~al.(2013)Alon, Lee, Shraibman, and Vempala]{alon2013approximate}
Noga Alon, Troy Lee, Adi Shraibman, and Santosh Vempala.
\newblock The approximate rank of a matrix and its algorithmic applications: approximate rank.
\newblock In \emph{Proceedings of the forty-fifth annual ACM Symposium on Theory of Computing}, pages 675--684, 2013.

\bibitem[Altschuler et~al.(2016)Altschuler, Bhaskara, Fu, Mirrokni, Rostamizadeh, and Zadimoghaddam]{altschuler2016greedy}
Jason Altschuler, Aditya Bhaskara, Gang Fu, Vahab Mirrokni, Afshin Rostamizadeh, and Morteza Zadimoghaddam.
\newblock Greedy column subset selection: New bounds and distributed algorithms.
\newblock In \emph{International Conference on Machine Learning}, pages 2539--2548. PMLR, 2016.

\bibitem[Balakrishnan et~al.(2011)Balakrishnan, Xu, Krishnamurthy, and Singh]{balakrishnan2011noise}
Sivaraman Balakrishnan, Min Xu, Akshay Krishnamurthy, and Aarti Singh.
\newblock Noise thresholds for spectral clustering.
\newblock \emph{Advances in Neural Information Processing Systems}, 24, 2011.

\bibitem[Barzilai and Shamir(2023)]{barzilai2023generalization}
Daniel Barzilai and Ohad Shamir.
\newblock Generalization in kernel regression under realistic assumptions.
\newblock \emph{arXiv preprint arXiv:2312.15995}, 2023.

\bibitem[Belabbas and Wolfe(2009)]{belabbas2009spectral}
Mohamed-Ali Belabbas and Patrick~J Wolfe.
\newblock Spectral methods in machine learning and new strategies for very large datasets.
\newblock \emph{Proceedings of the National Academy of Sciences}, 106\penalty0 (2):\penalty0 369--374, 2009.

\bibitem[Belkin(2018)]{belkin2018approximation}
Mikhail Belkin.
\newblock Approximation beats concentration? an approximation view on inference with smooth radial kernels.
\newblock In \emph{Conference On Learning Theory}, pages 1348--1361. PMLR, 2018.

\bibitem[Belkin and Niyogi(2001)]{belkin2001laplacian}
Mikhail Belkin and Partha Niyogi.
\newblock Laplacian eigenmaps and spectral techniques for embedding and clustering.
\newblock \emph{Advances in Neural Information Processing Systems}, 14, 2001.

\bibitem[Boutsidis et~al.(2009)Boutsidis, Mahoney, and Drineas]{boutsidis2009improved}
Christos Boutsidis, Michael~W Mahoney, and Petros Drineas.
\newblock An improved approximation algorithm for the column subset selection problem.
\newblock In \emph{Proceedings of the twentieth annual ACM-SIAM symposium on Discrete algorithms}, pages 968--977. SIAM, 2009.

\bibitem[Braun(2006)]{braun2006accurate}
Mikio~L Braun.
\newblock Accurate error bounds for the eigenvalues of the kernel matrix.
\newblock \emph{The Journal of Machine Learning Research}, 7:\penalty0 2303--2328, 2006.

\bibitem[Budzinskiy(2024{\natexlab{a}})]{budzinskiy2024distance}
Stanislav Budzinskiy.
\newblock On the distance to low-rank matrices in the maximum norm.
\newblock \emph{Linear Algebra and its Applications}, 688:\penalty0 44--58, 2024{\natexlab{a}}.

\bibitem[Budzinskiy(2024{\natexlab{b}})]{budzinskiy2024entrywise}
Stanislav Budzinskiy.
\newblock Entrywise tensor-train approximation of large tensors via random embeddings.
\newblock \emph{arXiv preprint arXiv:2403.11768}, 2024{\natexlab{b}}.

\bibitem[Candes and Recht(2012)]{candes2012exact}
Emmanuel Candes and Benjamin Recht.
\newblock Exact matrix completion via convex optimization.
\newblock \emph{Communications of the ACM}, 55\penalty0 (6):\penalty0 111--119, 2012.

\bibitem[Cand{\`e}s and Tao(2010)]{candes2010power}
Emmanuel~J Cand{\`e}s and Terence Tao.
\newblock The power of convex relaxation: Near-optimal matrix completion.
\newblock \emph{IEEE transactions on information theory}, 56\penalty0 (5):\penalty0 2053--2080, 2010.

\bibitem[Cape et~al.(2019)Cape, Tang, and Priebe]{cape2019two}
Joshua Cape, Minh Tang, and Carey~E Priebe.
\newblock The two-to-infinity norm and singular subspace geometry with applications to high-dimensional statistics.
\newblock \emph{The Annals of Statistics}, 2019.

\bibitem[Chen et~al.(2021)Chen, Chi, Fan, Ma, et~al.]{chen2021spectral}
Yuxin Chen, Yuejie Chi, Jianqing Fan, Cong Ma, et~al.
\newblock Spectral methods for data science: A statistical perspective.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning}, 14\penalty0 (5):\penalty0 566--806, 2021.

\bibitem[Chi et~al.(2019)Chi, Lu, and Chen]{chi2019nonconvex}
Yuejie Chi, Yue~M Lu, and Yuxin Chen.
\newblock Nonconvex optimization meets low-rank matrix factorization: An overview.
\newblock \emph{IEEE Transactions on Signal Processing}, 67\penalty0 (20):\penalty0 5239--5269, 2019.

\bibitem[Cobos and K{\"u}hn(1990)]{cobos1990eigenvalues}
Fernando Cobos and Thomas K{\"u}hn.
\newblock Eigenvalues of integral operators with positive definite kernels satisfying integrated h{\"o}lder conditions over metric compacta.
\newblock \emph{Journal of Approximation Theory}, 63\penalty0 (1):\penalty0 39--55, 1990.

\bibitem[Coifman and Lafon(2006)]{coifman2006diffusion}
Ronald~R Coifman and St{\'e}phane Lafon.
\newblock Diffusion maps.
\newblock \emph{Applied and computational harmonic analysis}, 21\penalty0 (1):\penalty0 5--30, 2006.

\bibitem[Cortes and Vapnik(1995)]{cortes1995support}
Corinna Cortes and Vladimir Vapnik.
\newblock Support-vector networks.
\newblock \emph{Machine learning}, 20:\penalty0 273--297, 1995.

\bibitem[Cortez et~al.(2009)Cortez, Cerdeira, Almeida, Matos, and Reis]{wine_quality}
Paulo Cortez, A.~Cerdeira, F.~Almeida, T.~Matos, and J.~Reis.
\newblock {Wine Quality}.
\newblock UCI Machine Learning Repository, 2009.
\newblock {DOI}: https://doi.org/10.24432/C56S3T.

\bibitem[De~Vito et~al.(2005)De~Vito, Rosasco, Caponnetto, De~Giovannini, Odone, and Bartlett]{de2005learning}
Ernesto De~Vito, Lorenzo Rosasco, Andrea Caponnetto, Umberto De~Giovannini, Francesca Odone, and Peter Bartlett.
\newblock Learning from examples as an inverse problem.
\newblock \emph{Journal of Machine Learning Research}, 6\penalty0 (5), 2005.

\bibitem[Deng(2012)]{deng2012mnist}
Li~Deng.
\newblock The mnist database of handwritten digit images for machine learning research.
\newblock \emph{IEEE Signal Processing Magazine}, 29\penalty0 (6):\penalty0 141--142, 2012.

\bibitem[Derezinski et~al.(2020)Derezinski, Khanna, and Mahoney]{derezinski2020improved}
Michal Derezinski, Rajiv Khanna, and Michael~W Mahoney.
\newblock Improved guarantees and a multiple-descent curve for column subset selection and the nystrom method.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 4953--4964, 2020.

\bibitem[Drineas et~al.(2005)Drineas, Mahoney, and Cristianini]{drineas2005nystrom}
Petros Drineas, Michael~W Mahoney, and Nello Cristianini.
\newblock On the nystr{\"o}m method for approximating a gram matrix for improved kernel-based learning.
\newblock \emph{Journal of Machine Learning Research}, 6\penalty0 (12), 2005.

\bibitem[Eckart and Young(1936)]{eckart1936approximation}
Carl Eckart and Gale Young.
\newblock The approximation of one matrix by another of lower rank.
\newblock \emph{Psychometrika}, 1\penalty0 (3):\penalty0 211--218, 1936.

\bibitem[Eldridge et~al.(2018)Eldridge, Belkin, and Wang]{eldridge2018unperturbed}
Justin Eldridge, Mikhail Belkin, and Yusu Wang.
\newblock Unperturbed: spectral analysis beyond davis-kahan.
\newblock In \emph{Algorithmic learning theory}, pages 321--358. PMLR, 2018.

\bibitem[Erd{\H{o}}s et~al.(2009{\natexlab{a}})Erd{\H{o}}s, Schlein, and Yau]{erdHos2009local}
L{\'a}szl{\'o} Erd{\H{o}}s, Benjamin Schlein, and Horng-Tzer Yau.
\newblock Local semicircle law and complete delocalization for wigner random matrices.
\newblock \emph{Communications in Mathematical Physics}, 287\penalty0 (2):\penalty0 641--655, 2009{\natexlab{a}}.

\bibitem[Erd{\H{o}}s et~al.(2009{\natexlab{b}})Erd{\H{o}}s, Schlein, and Yau]{erdHos2009semicircle}
L{\'a}szl{\'o} Erd{\H{o}}s, Benjamin Schlein, and Horng-Tzer Yau.
\newblock Semicircle law on short scales and delocalization of eigenvectors for wigner random matrices.
\newblock 2009{\natexlab{b}}.

\bibitem[Fan et~al.(2018)Fan, Wang, and Zhong]{fan2018ell_}
Jianqing Fan, Weichen Wang, and Yiqiao Zhong.
\newblock An $\ell_\infty$ eigenvector perturbation bound and its application.
\newblock \emph{Journal of Machine Learning Research}, 18\penalty0 (207):\penalty0 1--42, 2018.

\bibitem[Fasshauer and McCourt(2012)]{fasshauer2012stable}
Gregory~E Fasshauer and Michael~J McCourt.
\newblock Stable evaluation of gaussian radial basis function interpolants.
\newblock \emph{SIAM Journal on Scientific Computing}, 34\penalty0 (2):\penalty0 A737--A762, 2012.

\bibitem[Ferrari-Trecate et~al.(1998)Ferrari-Trecate, Williams, and Opper]{ferrari1998finite}
Giancarlo Ferrari-Trecate, Christopher Williams, and Manfred Opper.
\newblock Finite-dimensional approximation of gaussian processes.
\newblock \emph{Advances in Neural Information Processing Systems}, 11, 1998.

\bibitem[Ferreira and Menegatto(2013)]{ferreira2013eigenvalue}
JC~Ferreira and VA3128739 Menegatto.
\newblock Eigenvalue decay rates for positive integral operators.
\newblock \emph{Annali di Matematica Pura ed Applicata}, 192\penalty0 (6):\penalty0 1025--1041, 2013.

\bibitem[Fine and Scheinberg(2001)]{fine2001efficient}
Shai Fine and Katya Scheinberg.
\newblock Efficient svm training using low-rank kernel representations.
\newblock \emph{Journal of Machine Learning Research}, 2\penalty0 (Dec):\penalty0 243--264, 2001.

\bibitem[Flaxman et~al.(2016)Flaxman, Sejdinovic, Cunningham, and Filippi]{flaxman2016bayesian}
Seth Flaxman, Dino Sejdinovic, John~P Cunningham, and Sarah Filippi.
\newblock Bayesian learning of kernel embeddings.
\newblock \emph{arXiv preprint arXiv:1603.02160}, 2016.

\bibitem[Garreau et~al.(2017)Garreau, Jitkrittum, and Kanagawa]{garreau2017large}
Damien Garreau, Wittawat Jitkrittum, and Motonobu Kanagawa.
\newblock Large sample analysis of the median heuristic.
\newblock \emph{arXiv preprint arXiv:1707.07269}, 2017.

\bibitem[Gittens(2011)]{gittens2011spectral}
Alex Gittens.
\newblock The spectral norm error of the naive nystrom extension.
\newblock \emph{arXiv preprint arXiv:1110.5305}, 2011.

\bibitem[Gittens and Mahoney(2013)]{gittens2013revisiting}
Alex Gittens and Michael Mahoney.
\newblock Revisiting the nystrom method for improved large-scale machine learning.
\newblock In \emph{International Conference on Machine Learning}, pages 567--575. PMLR, 2013.

\bibitem[Gradshteyn and Ryzhik(2014)]{gradshteyn2014table}
I.S. Gradshteyn and I.M. Ryzhik.
\newblock \emph{Table of Integrals, Series, and Products}.
\newblock Academic Press, 8 edition, 2014.
\newblock ISBN 978-0123849335.

\bibitem[Halko et~al.(2011)Halko, Martinsson, and Tropp]{halko2011finding}
Nathan Halko, Per-Gunnar Martinsson, and Joel~A Tropp.
\newblock Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions.
\newblock \emph{SIAM review}, 53\penalty0 (2):\penalty0 217--288, 2011.

\bibitem[Hall and Horowitz(2007)]{hall2007methodology}
Peter Hall and Joel~L Horowitz.
\newblock Methodology and convergence rates for functional linear regression.
\newblock \emph{The Annals of Statistics}, 2007.

\bibitem[Hirsch and Lacombe(1999)]{hirsch1999elements}
Francis Hirsch and Gilles Lacombe.
\newblock \emph{Elements of Functional Analysis}.
\newblock Springer, 1999.

\bibitem[Indritz(1961)]{indritz1961inequality}
Jack Indritz.
\newblock An inequality for hermite polynomials.
\newblock \emph{Proceedings of the American Mathematical Society}, 12\penalty0 (6):\penalty0 981--983, 1961.

\bibitem[Johnson and Lindenstrauss(1982)]{johnson1982extensions}
William Johnson and J.~Lindenstrauss.
\newblock Extensions of lipschitz mappings into a hilbert space.
\newblock \emph{Conference in Modern Analysis and Probability}, 26:\penalty0 189--206, 01 1982.

\bibitem[Keshavan et~al.(2010)Keshavan, Montanari, and Oh]{keshavan2010matrix}
Raghunandan~H Keshavan, Andrea Montanari, and Sewoong Oh.
\newblock Matrix completion from a few entries.
\newblock \emph{IEEE transactions on information theory}, 56\penalty0 (6):\penalty0 2980--2998, 2010.

\bibitem[K{\"u}hn(1987)]{kuhn1987eigenvalues}
Thomas K{\"u}hn.
\newblock Eigenvalues of integral operators with smooth positive definite kernels.
\newblock \emph{Archiv der Mathematik}, 49:\penalty0 525--534, 1987.

\bibitem[Kumar et~al.(2009{\natexlab{a}})Kumar, Mohri, and Talwalkar]{kumar2009ensemble}
Sanjiv Kumar, Mehryar Mohri, and Ameet Talwalkar.
\newblock Ensemble nystrom method.
\newblock \emph{Advances in Neural Information Processing Systems}, 22, 2009{\natexlab{a}}.

\bibitem[Kumar et~al.(2009{\natexlab{b}})Kumar, Mohri, and Talwalkar]{kumar2009sampling}
Sanjiv Kumar, Mehryar Mohri, and Ameet Talwalkar.
\newblock On sampling-based approximate spectral decomposition.
\newblock In \emph{Proceedings of the 26th annual International Conference on Machine Learning}, pages 553--560, 2009{\natexlab{b}}.

\bibitem[Lafferty et~al.(2005)Lafferty, Lebanon, and Jaakkola]{lafferty2005diffusion}
John Lafferty, Guy Lebanon, and Tommi Jaakkola.
\newblock Diffusion kernels on statistical manifolds.
\newblock \emph{Journal of Machine Learning Research}, 6\penalty0 (1), 2005.

\bibitem[Lang(1995)]{lang1995newsweeder}
Ken Lang.
\newblock Newsweeder: Learning to filter netnews.
\newblock In \emph{Machine Learning Proceedings 1995}, pages 331--339. Elsevier, 1995.

\bibitem[Ledoux(2001)]{ledoux2001concentration}
Michel Ledoux.
\newblock \emph{The Concentration of Measure Phenomenon, Mathematical Surveys and Monographs}.
\newblock Number~89. American Mathematical Soc., 2001.

\bibitem[Lei(2014)]{lei2014adaptive}
Jing Lei.
\newblock Adaptive global testing for functional linear models.
\newblock \emph{Journal of the American Statistical Association}, 109\penalty0 (506):\penalty0 624--634, 2014.

\bibitem[Lei(2021)]{lei2021network}
Jing Lei.
\newblock Network representation using graph root distributions.
\newblock \emph{The Annals of Statistics}, 2021.

\bibitem[Lei(2019)]{lei2019unified}
Lihua Lei.
\newblock Unified $\ell_{2\rightarrow\infty}$ eigenspace perturbation theory for symmetric random matrices.
\newblock \emph{arXiv preprint arXiv:1909.04798}, 2019.

\bibitem[Li et~al.(2024)Li, Yu, Chen, and Lin]{li2024eigenvalue}
Yicheng Li, Zixiong Yu, Guhan Chen, and Qian Lin.
\newblock On the eigenvalue decay rates of a class of neural-network related kernel functions defined on general domains.
\newblock \emph{Journal of Machine Learning Research}, 25\penalty0 (82):\penalty0 1--47, 2024.

\bibitem[Lyzinski et~al.(2014)Lyzinski, Sussman, Tang, Athreya, and Priebe]{lyzinski2014perfect}
Vince Lyzinski, Daniel~L Sussman, Minh Tang, Avanti Athreya, and Carey~E Priebe.
\newblock Perfect clustering for stochastic blockmodel graphs via adjacency spectral embedding.
\newblock \emph{Electron. J. Statist.}, 2014.

\bibitem[Ma et~al.(2018)Ma, Wang, Chi, and Chen]{ma2018implicit}
Cong Ma, Kaizheng Wang, Yuejie Chi, and Yuxin Chen.
\newblock Implicit regularization in nonconvex statistical estimation: Gradient descent converges linearly for phase retrieval and matrix completion.
\newblock In \emph{International Conference on Machine Learning}, pages 3345--3354. PMLR, 2018.

\bibitem[Mao et~al.(2021)Mao, Sarkar, and Chakrabarti]{mao2021estimating}
Xueyu Mao, Purnamrita Sarkar, and Deepayan Chakrabarti.
\newblock Estimating mixed memberships with sharp eigenvector deviations.
\newblock \emph{Journal of the American Statistical Association}, 116\penalty0 (536):\penalty0 1928--1940, 2021.

\bibitem[Meister(2011)]{meister2011asymptotic}
Alexander Meister.
\newblock Asymptotic equivalence of functional linear regression and a white noise inverse problem.
\newblock \emph{The Annals of Statistics}, pages 1471--1495, 2011.

\bibitem[Mendelson and Neeman(2010)]{mendelson2010regularization}
Shahar Mendelson and Joseph Neeman.
\newblock Regularization in kernel learning.
\newblock \emph{The Annals of Statistics}, 2010.

\bibitem[Mercer(1909)]{mercer1909xvi}
James Mercer.
\newblock Xvi. functions of positive and negative type, and their connection the theory of integral equations.
\newblock \emph{Philosophical Transactions of the Royal Society of London. Series A}, 209\penalty0 (441-458):\penalty0 415--446, 1909.

\bibitem[Minh et~al.(2006)Minh, Niyogi, and Yao]{minh2006mercer}
Ha~Quang Minh, Partha Niyogi, and Yuan Yao.
\newblock Mercer’s theorem, feature maps, and smoothing.
\newblock In \emph{International Conference on Computational Learning Theory}, pages 154--168. Springer, 2006.

\bibitem[Mirsky(1960)]{mirsky1960symmetric}
Leon Mirsky.
\newblock Symmetric gauge functions and unitarily invariant norms.
\newblock \emph{The Quarterly Journal of Mathematics}, 11\penalty0 (1):\penalty0 50--59, 1960.

\bibitem[Mooij et~al.(2016)Mooij, Peters, Janzing, Zscheischler, and Sch{\"o}lkopf]{mooij2016distinguishing}
Joris~M Mooij, Jonas Peters, Dominik Janzing, Jakob Zscheischler, and Bernhard Sch{\"o}lkopf.
\newblock Distinguishing cause from effect using observational data: methods and benchmarks.
\newblock \emph{Journal of Machine Learning Research}, 17\penalty0 (32):\penalty0 1--102, 2016.

\bibitem[Mu et~al.(2016)Mu, Sriperumbudur, Fukumizu, Gretton, Sch{\"o}lkopf, et~al.]{mu2016kernel}
Krikamol Mu, Bharath Sriperumbudur, Kenji Fukumizu, Arthur Gretton, Bernhard Sch{\"o}lkopf, et~al.
\newblock Kernel mean shrinkage estimators.
\newblock \emph{Journal of Machine Learning Research}, 17\penalty0 (48):\penalty0 1--41, 2016.

\bibitem[Nash et~al.(1995)Nash, Sellers, Talbot, Cawthorn, and Ford]{abalone}
Warwick Nash, Tracy Sellers, Simon Talbot, Andrew Cawthorn, and Wes Ford.
\newblock {Abalone}.
\newblock UCI Machine Learning Repository, 1995.
\newblock {DOI}: https://doi.org/10.24432/C55C7W.

\bibitem[Ng et~al.(2001)Ng, Jordan, and Weiss]{ng2001spectral}
Andrew Ng, Michael Jordan, and Yair Weiss.
\newblock On spectral clustering: Analysis and an algorithm.
\newblock \emph{Advances in Neural Information Processing Systems}, 14, 2001.

\bibitem[Nicaise(2000)]{nicaise2000jacobi}
Serge Nicaise.
\newblock Jacobi polynomials, weighted sobolev spaces and approximation results of some singularities.
\newblock \emph{Mathematische Nachrichten}, 213\penalty0 (1):\penalty0 117--140, 2000.

\bibitem[Ong et~al.(2004)Ong, Mary, Canu, and Smola]{ong2004learning}
Cheng~Soon Ong, Xavier Mary, St{\'e}phane Canu, and Alexander~J Smola.
\newblock Learning with non-positive kernels.
\newblock In \emph{Proceedings of the twenty-first International Conference on Machine Learning}, page~81, 2004.

\bibitem[Ostrovskii and Rudi(2019)]{ostrovskii2019affine}
Dmitrii~M Ostrovskii and Alessandro Rudi.
\newblock Affine invariant covariance estimation for heavy-tailed distributions.
\newblock In \emph{Conference on Learning Theory}, pages 2531--2550. PMLR, 2019.

\bibitem[Pollard(1990)]{pollard1990empirical}
David Pollard.
\newblock Empirical processes: theory and applications.
\newblock IMS, 1990.

\bibitem[Rahimi and Recht(2007)]{rahimi2007random}
Ali Rahimi and Benjamin Recht.
\newblock Random features for large-scale kernel machines.
\newblock \emph{Advances in Neural Information Processing Systems}, 20, 2007.

\bibitem[Rahimi and Recht(2008)]{rahimi2008weighted}
Ali Rahimi and Benjamin Recht.
\newblock Weighted sums of random kitchen sinks: Replacing minimization with randomization in learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 21, 2008.

\bibitem[Rosasco et~al.(2010)Rosasco, Belkin, and De~Vito]{rosasco2010learning}
Lorenzo Rosasco, Mikhail Belkin, and Ernesto De~Vito.
\newblock On learning with integral operators.
\newblock \emph{Journal of Machine Learning Research}, 11\penalty0 (2), 2010.

\bibitem[Roweis and Saul(2000)]{roweis2000nonlinear}
Sam~T Roweis and Lawrence~K Saul.
\newblock Nonlinear dimensionality reduction by locally linear embedding.
\newblock \emph{Science}, 290\penalty0 (5500):\penalty0 2323--2326, 2000.

\bibitem[Rubin-Delanchy et~al.(2022)Rubin-Delanchy, Cape, Tang, and Priebe]{rubin2022statistical}
Patrick Rubin-Delanchy, Joshua Cape, Minh Tang, and Carey~E Priebe.
\newblock A statistical interpretation of spectral embedding: the generalised random dot product graph.
\newblock \emph{Journal of the Royal Statistical Society Series B: Statistical Methodology}, 84\penalty0 (4):\penalty0 1446--1473, 2022.

\bibitem[Rudelson and Vershynin(2015)]{rudelson2015delocalization}
Mark Rudelson and Roman Vershynin.
\newblock Delocalization of eigenvectors of random matrices with independent entries.
\newblock \emph{Duke Math. J.}, 2015.

\bibitem[Scetbon and Harchaoui(2021)]{scetbon2021spectral}
Meyer Scetbon and Zaid Harchaoui.
\newblock A spectral analysis of dot-product kernels.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pages 3394--3402. PMLR, 2021.

\bibitem[Sch{\"o}lkopf et~al.(1998)Sch{\"o}lkopf, Smola, and M{\"u}ller]{scholkopf1998nonlinear}
Bernhard Sch{\"o}lkopf, Alexander Smola, and Klaus-Robert M{\"u}ller.
\newblock Nonlinear component analysis as a kernel eigenvalue problem.
\newblock \emph{Neural Computation}, 10\penalty0 (5):\penalty0 1299--1319, 1998.

\bibitem[Shi et~al.(2008)Shi, Belkin, and Yu]{shi2008data}
Tao Shi, Mikhail Belkin, and Bin Yu.
\newblock Data spectroscopy: Learning mixture models using eigenspaces of convolution operators.
\newblock In \emph{Proceedings of the 25th International Conference on Machine Learning}, pages 936--943, 2008.

\bibitem[Shi et~al.(2009)Shi, Belkin, and Yu]{shi2009data}
Tao Shi, Mikhail Belkin, and Bin Yu.
\newblock Data spectroscopy: Eigenspaces of convolution operators and clustering.
\newblock \emph{The Annals of Statistics}, pages 3960--3984, 2009.

\bibitem[Smola et~al.(2000)Smola, Ov{\'a}ri, and Williamson]{smola2000regularization}
Alex Smola, Zolt{\'a}n Ov{\'a}ri, and Robert~C Williamson.
\newblock Regularization with dot-product kernels.
\newblock \emph{Advances in Neural Information Processing Systems}, 13, 2000.

\bibitem[Srebro and Shraibman(2005)]{srebro2005rank}
Nathan Srebro and Adi Shraibman.
\newblock Rank, trace-norm and max-norm.
\newblock In \emph{International Conference on Computational Learning Theory}, pages 545--560. Springer, 2005.

\bibitem[Steinwart and Scovel(2012)]{steinwart2012mercer}
Ingo Steinwart and Clint Scovel.
\newblock Mercer’s theorem on general domains: On the interaction between measures, kernels, and rkhss.
\newblock \emph{Constructive Approximation}, 35:\penalty0 363--417, 2012.

\bibitem[Stojanovic et~al.(2023)Stojanovic, Jedra, and Proutiere]{stojanovic2023spectral}
Stefan Stojanovic, Yassir Jedra, and Alexandre Proutiere.
\newblock Spectral entry-wise matrix estimation for low-rank reinforcement learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 36:\penalty0 77056--77070, 2023.

\bibitem[Talagrand(1996)]{talagrand1996new}
Michel Talagrand.
\newblock {A new look at independence}.
\newblock \emph{The Annals of Probability}, 24\penalty0 (1):\penalty0 1 -- 34, 1996.

\bibitem[Tang et~al.(2013)Tang, Sussman, and Priebe]{tang2013universally}
Minh Tang, Daniel~L. Sussman, and Carey~E. Priebe.
\newblock {Universally consistent vertex classification for latent positions graphs}.
\newblock \emph{The Annals of Statistics}, 41\penalty0 (3):\penalty0 1406 -- 1430, 2013.

\bibitem[Tao and Vu(2011)]{tao2011random}
Terence Tao and Van Vu.
\newblock {Random matrices: Universality of local eigenvalue statistics}.
\newblock \emph{Acta Mathematica}, 206\penalty0 (1):\penalty0 127 -- 204, 2011.
\newblock \doi{10.1007/s11511-011-0061-3}.

\bibitem[Udell and Townsend(2019)]{udell2019big}
Madeleine Udell and Alex Townsend.
\newblock Why are big data matrices approximately low rank?
\newblock \emph{SIAM Journal on Mathematics of Data Science}, 1\penalty0 (1):\penalty0 144--160, 2019.

\bibitem[Valdivia(2018)]{valdivia2018relative}
Ernesto~Araya Valdivia.
\newblock Relative concentration bounds for the spectrum of kernel matrices.
\newblock \emph{arXiv preprint arXiv:1812.02108}, 2018.

\bibitem[Virtanen et~al.(2020)Virtanen, Gommers, Oliphant, Haberland, Reddy, Cournapeau, Burovski, Peterson, Weckesser, Bright, {van der Walt}, Brett, Wilson, Millman, Mayorov, Nelson, Jones, Kern, Larson, Carey, Polat, Feng, Moore, {VanderPlas}, Laxalde, Perktold, Cimrman, Henriksen, Quintero, Harris, Archibald, Ribeiro, Pedregosa, {van Mulbregt}, and {SciPy 1.0 Contributors}]{scipy}
Pauli Virtanen, Ralf Gommers, Travis~E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, St{\'e}fan~J. {van der Walt}, Matthew Brett, Joshua Wilson, K.~Jarrod Millman, Nikolay Mayorov, Andrew R.~J. Nelson, Eric Jones, Robert Kern, Eric Larson, C~J Carey, {\.I}lhan Polat, Yu~Feng, Eric~W. Moore, Jake {VanderPlas}, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen, E.~A. Quintero, Charles~R. Harris, Anne~M. Archibald, Antonio~H. Ribeiro, Fabian Pedregosa, Paul {van Mulbregt}, and {SciPy 1.0 Contributors}.
\newblock {{SciPy} 1.0: Fundamental Algorithms for Scientific Computing in Python}.
\newblock \emph{Nature Methods}, 17:\penalty0 261--272, 2020.
\newblock \doi{10.1038/s41592-019-0686-2}.

\bibitem[Von~Luxburg(2007)]{von2007tutorial}
Ulrike Von~Luxburg.
\newblock A tutorial on spectral clustering.
\newblock \emph{Statistics and Computing}, 17:\penalty0 395--416, 2007.

\bibitem[Vu and Wang(2015)]{vu2015random}
Van Vu and Ke~Wang.
\newblock Random weighted projections, random quadratic forms and random eigenvectors.
\newblock \emph{Random Structures \& Algorithms}, 47\penalty0 (4):\penalty0 792--821, 2015.

\bibitem[Wagner et~al.(2018)Wagner, Weinreb, Collins, Briggs, Megason, and Klein]{wagner2018single}
Daniel~E Wagner, Caleb Weinreb, Zach~M Collins, James~A Briggs, Sean~G Megason, and Allon~M Klein.
\newblock Single-cell mapping of gene expression landscapes and lineage in the zebrafish embryo.
\newblock \emph{Science}, 360\penalty0 (6392):\penalty0 981--987, 2018.

\bibitem[Williams and Rasmussen(1995)]{williams1995gaussian}
Christopher Williams and Carl Rasmussen.
\newblock Gaussian processes for regression.
\newblock \emph{Advances in Neural Information Processing Systems}, 8, 1995.

\bibitem[Williams and Seeger(2000)]{williams2000using}
Christopher Williams and Matthias Seeger.
\newblock Using the nystr{\"o}m method to speed up kernel machines.
\newblock \emph{Advances in Neural Information Processing Systems}, 13, 2000.

\bibitem[Williamson et~al.(2001)Williamson, Smola, and Scholkopf]{williamson2001generalization}
Robert~C Williamson, Alexander~J Smola, and Bernhard Scholkopf.
\newblock Generalization performance of regularization networks and support vector machines via entropy numbers of compact operators.
\newblock \emph{IEEE transactions on Information Theory}, 47\penalty0 (6):\penalty0 2516--2532, 2001.

\bibitem[Xu(2018)]{xu2018rates}
Jiaming Xu.
\newblock Rates of convergence of spectral methods for graphon estimation.
\newblock In \emph{International Conference on Machine Learning}, pages 5433--5442. PMLR, 2018.

\bibitem[Zhong and Boumal(2018)]{zhong2018near}
Yiqiao Zhong and Nicolas Boumal.
\newblock Near-optimal bounds for phase synchronization.
\newblock \emph{SIAM Journal on Optimization}, 28\penalty0 (2):\penalty0 989--1016, 2018.

\bibitem[Zhou(2002)]{zhou2002covering}
Ding-Xuan Zhou.
\newblock The covering number in learning theory.
\newblock \emph{Journal of Complexity}, 18\penalty0 (3):\penalty0 739--767, 2002.

\bibitem[Zhu et~al.(1997)Zhu, Williams, Rohwer, and Morciniec]{zhu1997gaussian}
Huaiyu Zhu, Christopher~KI Williams, Richard Rohwer, and Michal Morciniec.
\newblock Gaussian regression and optimal finite dimensional linear models.
\newblock 1997.

\end{thebibliography}
