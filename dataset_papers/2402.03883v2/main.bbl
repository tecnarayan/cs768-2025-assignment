\begin{thebibliography}{10}

\bibitem{absil2008optimization}
P-A Absil, Robert Mahony, and Rodolphe Sepulchre.
\newblock {\em Optimization algorithms on matrix manifolds}.
\newblock Princeton University Press, 2008.

\bibitem{alcantara2024theoretical}
Jan~Harold Alcantara and Akiko Takeda.
\newblock Theoretical smoothing frameworks for general nonsmooth bilevel problems.
\newblock Technical report, arXiv preprint arXiv:2401.17852, 2024.

\bibitem{alimisis2020continuous}
Foivos Alimisis, Antonio Orvieto, Gary B{\'e}cigneul, and Aurelien Lucchi.
\newblock A continuous-time perspective for modeling acceleration in {R}iemannian optimization.
\newblock In {\em International Conference on Artificial Intelligence and Statistics (AISTATS)}, 2020.

\bibitem{arsigny2007geometric}
Vincent Arsigny, Pierre Fillard, Xavier Pennec, and Nicholas Ayache.
\newblock Geometric means in a novel vector space structure on symmetric positive-definite matrices.
\newblock {\em SIAM Journal on Matrix Analysis and Applications}, 29(1):328--347, 2007.

\bibitem{artetxe2018generalizing}
Mikel Artetxe, Gorka Labaka, and Eneko Agirre.
\newblock Generalizing and improving bilingual word embedding mappings with a multi-step framework of linear transformations.
\newblock In {\em the AAAI Conference on Artificial Intelligence (AAAI)}, 2018.

\bibitem{bhatia2009positive}
Rajendra Bhatia.
\newblock Positive definite matrices.
\newblock In {\em Positive Definite Matrices}. Princeton university press, 2009.

\bibitem{bonnel2015semivectorial}
Henri Bonnel, L{\'e}onard Todjihound{\'e}, and Constantin Udri{\c{s}}te.
\newblock Semivectorial bilevel optimization on {R}iemannian manifolds.
\newblock {\em Journal of Optimization Theory and Applications}, 167:464--486, 2015.

\bibitem{boumal2023introduction}
Nicolas Boumal.
\newblock {\em An introduction to optimization on smooth manifolds}.
\newblock Cambridge University Press, 2023.

\bibitem{chen2024finding}
Lesi Chen, Jing Xu, and Jingzhao Zhang.
\newblock On finding small hyper-gradients in bilevel optimization: Hardness results and improved analysis.
\newblock In {\em Annual Conference on Learning Theory (COLT)}, 2024.

\bibitem{chen2022single}
Tianyi Chen, Yuejiao Sun, Quan Xiao, and Wotao Yin.
\newblock A single-timescale method for stochastic bilevel optimization.
\newblock In {\em International Conference on Artificial Intelligence and Statistics (AISTATS)}, 2022.

\bibitem{chen2021closing}
Tianyi Chen, Yuejiao Sun, and Wotao Yin.
\newblock Closing the gap: Tighter analysis of alternating stochastic gradient methods for bilevel problems.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2021.

\bibitem{courty17a}
Nicolas Courty, Rémi Flamary, Devis Tuia, and Alain Rakotomamonjy.
\newblock Optimal transport for domain adaptation.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}, 39(9):1853--1865, 2017.

\bibitem{cuturi2013a}
Marco Cuturi.
\newblock Sinkhorn distances: Lightspeed computation of optimal transport.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2013.

\bibitem{dagreou2022framework}
Mathieu Dagr{\'e}ou, Pierre Ablin, Samuel Vaiter, and Thomas Moreau.
\newblock A framework for bilevel optimization that enables stochastic and global variance reduction algorithms.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2022.

\bibitem{douik2019manifold}
Ahmed Douik and Babak Hassibi.
\newblock Manifold optimization over the set of doubly stochastic matrices: A second-order geometry.
\newblock {\em IEEE Transactions on Signal Processing}, 67(22):5761--5774, 2019.

\bibitem{finn2017model}
Chelsea Finn, Pieter Abbeel, and Sergey Levine.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2017.

\bibitem{flamary2021pot}
R{\'e}mi Flamary, Nicolas Courty, Alexandre Gramfort, Mokhtar~Z Alaya, Aur{\'e}lie Boisbunon, Stanislas Chambon, Laetitia Chapel, Adrien Corenflos, Kilian Fatras, Nemo Fournier, et~al.
\newblock {POT}: Python optimal transport.
\newblock {\em Journal of Machine Learning Research}, 22(1):3571--3578, 2021.

\bibitem{franceschi2018bilevel}
Luca Franceschi, Paolo Frasconi, Saverio Salzo, Riccardo Grazzi, and Massimiliano Pontil.
\newblock Bilevel programming for hyperparameter optimization and meta-learning.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2018.

\bibitem{ghadimi2018approximation}
Saeed Ghadimi and Mengdi Wang.
\newblock Approximation methods for bilevel programming.
\newblock Technical report, arXiv preprint arXiv:1802.02246, 2018.

\bibitem{gong2012geodesic}
Boqing Gong, Yuan Shi, Fei Sha, and Kristen Grauman.
\newblock Geodesic flow kernel for unsupervised domain adaptation.
\newblock In {\em Conference on Computer Vision and Pattern Recognition (CVPR)}, 2012.

\bibitem{grazzi2020iteration}
Riccardo Grazzi, Luca Franceschi, Massimiliano Pontil, and Saverio Salzo.
\newblock On the iteration complexity of hypergradient computation.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2020.

\bibitem{ijcai2021p345}
Andi Han and Junbin Gao.
\newblock Riemannian stochastic recursive momentum method for non-convex optimization.
\newblock In {\em International Joint Conference on Artificial Intelligence (IJCAI)}, 2021.

\bibitem{9536452}
Andi Han and Junbin Gao.
\newblock Improved variance reduction methods for {R}iemannian non-convex optimization.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}, 44(11):7610--7623, 2022.

\bibitem{han2023learning}
Andi Han, Bamdev Mishra, Pratik Jawanpuria, and Junbin Gao.
\newblock Learning with symmetric positive definite matrices via generalized {Bures-Wasserstein} geometry.
\newblock In {\em International Conference on Geometric Science of Information (GSI)}, 2023.

\bibitem{han2023nonconvexnonconcave}
Andi Han, Bamdev Mishra, Pratik Jawanpuria, and Junbin Gao.
\newblock {Nonconvex-nonconcave min-max optimization on Riemannian manifolds}.
\newblock {\em Transactions on Machine Learning Research}, 2023.

\bibitem{han2023riemna}
Andi Han, Bamdev Mishra, Pratik Jawanpuria, and Junbin Gao.
\newblock Riemannian accelerated gradient methods via extrapolation.
\newblock In {\em International Conference on Artificial Intelligence and Statistics (AISTATS)}, 2023.

\bibitem{han2023riemannian}
Andi Han, Bamdev Mishra, Pratik Jawanpuria, Pawan Kumar, and Junbin Gao.
\newblock Riemannian {H}amiltonian methods for min-max optimization on manifolds.
\newblock {\em SIAM Journal on Optimization}, 33(3):1797--1827, 2023.

\bibitem{han2021riemannian}
Andi Han, Bamdev Mishra, Pratik~Kumar Jawanpuria, and Junbin Gao.
\newblock On {R}iemannian optimization over positive definite matrices with the {Bures-Wasserstein} geometry.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2021.

\bibitem{hansen1992new}
Pierre Hansen, Brigitte Jaumard, and Gilles Savard.
\newblock New branch-and-bound rules for linear bilevel programming.
\newblock {\em SIAM Journal on Scientific and Statistical Computing}, 13(5):1194--1217, 1992.

\bibitem{harandi2017dimensionality}
Mehrtash Harandi, Mathieu Salzmann, and Richard Hartley.
\newblock Dimensionality reduction on {SPD} manifolds: The emergence of geometry-aware methods.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}, 40(1):48--62, 2017.

\bibitem{hataya2023nystrom}
Ryuichiro Hataya and Makoto Yamada.
\newblock Nystr{\"o}m method for accurate and scalable implicit differentiation.
\newblock In {\em International Conference on Artificial Intelligence and Statistics (AISTATS)}, 2023.

\bibitem{hong2023two}
Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran Yang.
\newblock A two-timescale stochastic algorithm framework for bilevel optimization: Complexity analysis and application to actor-critic.
\newblock {\em SIAM Journal on Optimization}, 33(1):147--180, 2023.

\bibitem{horev2016geometry}
Inbal Horev, Florian Yger, and Masashi Sugiyama.
\newblock Geometry-aware principal component analysis for symmetric positive definite matrices.
\newblock In {\em Asian Conference on Machine Learning (ACML)}, 2016.

\bibitem{hospedales2021meta}
Timothy Hospedales, Antreas Antoniou, Paul Micaelli, and Amos Storkey.
\newblock Meta-learning in neural networks: A survey.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}, 44(9):5149--5169, 2021.

\bibitem{hu2023extragradient}
Zihao Hu, Guanghui Wang, Xi~Wang, Andre Wibisono, Jacob D~Abernethy, and Molei Tao.
\newblock Extragradient type methods for {R}iemannian variational inequality problems.
\newblock In {\em International Conference on Artificial Intelligence and Statistics (AISTATS)}, 2024.

\bibitem{huang2022riemannian}
Feihu Huang and Shangqian Gao.
\newblock Riemannian gradient methods for stochastic composition problems.
\newblock {\em Neural Networks}, 153:224--234, 2022.

\bibitem{huang2023gradient}
Feihu Huang and Shangqian Gao.
\newblock Gradient descent ascent for minimax problems on {R}iemannian manifolds.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}, 2023.

\bibitem{huang2017riemannian}
Zhiwu Huang and Luc Van~Gool.
\newblock A {R}iemannian network for spd matrix learning.
\newblock In {\em {AAAI Conference on Artificial Intelligence} (AAAI)}, 2017.

\bibitem{ji2020convergence}
Kaiyi Ji, Jason~D Lee, Yingbin Liang, and H~Vincent Poor.
\newblock Convergence of meta-learning with task-specific adaptation over partial parameters.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2020.

\bibitem{ji2021bilevel}
Kaiyi Ji, Junjie Yang, and Yingbin Liang.
\newblock Bilevel optimization: Convergence analysis and enhanced design.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2021.

\bibitem{jordan2022first}
Michael Jordan, Tianyi Lin, and Emmanouil-Vasileios Vlatakis-Gkaragkounis.
\newblock First-order algorithms for min-max optimization in geodesic metric spaces.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2022.

\bibitem{kasai2018riemannian}
Hiroyuki Kasai, Hiroyuki Sato, and Bamdev Mishra.
\newblock Riemannian stochastic recursive gradient algorithm.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2018.

\bibitem{knight2008sinkhorn}
Philip~A Knight.
\newblock The {Sinkhorn--Knopp} algorithm: convergence and applications.
\newblock {\em SIAM Journal on Matrix Analysis and Applications}, 30(1):261--275, 2008.

\bibitem{kochurov2020geoopt}
Max Kochurov, Rasul Karimov, and Serge Kozlukov.
\newblock Geoopt: {R}iemannian optimization in {PyTorch}.
\newblock Technical report, arXiv preprint arXiv:2005.02819, 2020.

\bibitem{kwon2023fully}
Jeongyeol Kwon, Dohyun Kwon, Stephen Wright, and Robert~D Nowak.
\newblock A fully first-order method for stochastic bilevel optimization.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2023.

\bibitem{leibe2003analyzing}
Bastian Leibe and Bernt Schiele.
\newblock Analyzing appearance and contour based methods for object categorization.
\newblock In {\em Conference on Computer Vision and Pattern Recognition (CVPR)}, 2003.

\bibitem{li2024riemannian}
Jiaxiang Li and Shiqian Ma.
\newblock Riemannian bilevel optimization.
\newblock Technical report, arXiv preprint arXiv:2402.02019, 2024.

\bibitem{li2019efficient}
Jun Li, Fuxin Li, and Sinisa Todorovic.
\newblock {Efficient Riemannian Optimization on the Stiefel Manifold via the Cayley Transform}.
\newblock In {\em International Conference on Learning Representations (ICLR)}, 2019.

\bibitem{liao2022inexact}
Jiagen Liao and Zhongping Wan.
\newblock {Inexact restoration methods for semivectorial bilevel programming problem on Riemannian manifolds}.
\newblock {\em Axioms}, 11(12):696, 2022.

\bibitem{liao2022karush}
Jiagen Liao and Zhongping Wan.
\newblock {On the Karush-Kuhn-Tucker reformulation of the bilevel optimization problems on Riemannian manifolds}.
\newblock {\em Filomat}, 36(11):3609--3624, 2022.

\bibitem{lin2019riemannian}
Zhenhua Lin.
\newblock Riemannian geometry of symmetric positive definite matrices via {C}holesky decomposition.
\newblock {\em SIAM Journal on Matrix Analysis and Applications}, 40(4):1353--1370, 2019.

\bibitem{liu2022bome}
Bo~Liu, Mao Ye, Stephen Wright, Peter Stone, and Qiang Liu.
\newblock Bome! bilevel optimization made easy: A simple first-order approach.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2022.

\bibitem{liu2018darts}
Hanxiao Liu, Karen Simonyan, and Yiming Yang.
\newblock {DARTS: Differentiable architecture search}.
\newblock In {\em International Conference on Learning Representations (ICLR)}, 2018.

\bibitem{lorraine2020optimizing}
Jonathan Lorraine, Paul Vicol, and David Duvenaud.
\newblock Optimizing millions of hyperparameters by implicit differentiation.
\newblock In {\em International Conference on Artificial Intelligence and Statistics (AISTATS)}, 2020.

\bibitem{malago2018wasserstein}
Luigi Malag{\`o}, Luigi Montrucchio, and Giovanni Pistone.
\newblock {Wasserstein Riemannian geometry of Gaussian densities}.
\newblock {\em Information Geometry}, 1:137--179, 2018.

\bibitem{martinez2023accelerated}
David Mart{\'\i}nez-Rubio, Christophe Roux, Christopher Criscitiello, and Sebastian Pokutta.
\newblock Accelerated methods for {R}iemannian min-max optimization ensuring bounded geometric penalties.
\newblock Technical report, arXiv preprint arXiv:2305.16186, 2023.

\bibitem{mishra2021manifold}
Bamdev Mishra, NTV Satyadev, Hiroyuki Kasai, and Pratik Jawanpuria.
\newblock Manifold optimization for non-linear optimal transport problems.
\newblock Technical report, arXiv preprint arXiv:2103.00902, 2021.

\bibitem{computationalOT}
Gabriel Peyre and Marco Cuturi.
\newblock Computational optimal transport: With applications to data science.
\newblock {\em Foundations and Trends in Machine Learning}, 11(5-6):355--607, 2019.

\bibitem{ren2018metalearning}
Mengye Ren, Sachin Ravi, Eleni Triantafillou, Jake Snell, Kevin Swersky, Josh~B. Tenenbaum, Hugo Larochelle, and Richard~S. Zemel.
\newblock Meta-learning for semi-supervised few-shot classification.
\newblock In {\em International Conference on Learning Representations (ICLR)}, 2018.

\bibitem{shi2005extended}
Chenggen Shi, Jie Lu, and Guangquan Zhang.
\newblock An extended {Kuhn--Tucker} approach for linear bilevel programming.
\newblock {\em Applied Mathematics and Computation}, 162(1):51--63, 2005.

\bibitem{sow2022convergence}
Daouda Sow, Kaiyi Ji, and Yingbin Liang.
\newblock On the convergence theory for {H}essian-free bilevel algorithms.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2022.

\bibitem{sukthanker2021neural}
Rhea Sukthanker, Zhiwu Huang, Suryansh Kumar, Erik Endsjo~Goron, Yan Wu, and Luc Van~Gool.
\newblock Neural architecture search of spd manifold networks.
\newblock In {\em International Joint Conference on Artificial Intelligence (IJCAI)}, 2021.

\bibitem{sun2019escaping}
Yue Sun, Nicolas Flammarion, and Maryam Fazel.
\newblock Escaping from saddle points on {R}iemannian manifolds.
\newblock {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2019.

\bibitem{tabealhojeh2023rmaml}
Hadi Tabealhojeh, Peyman Adibi, Hossein Karshenas, Soumava~Kumar Roy, and Mehrtash Harandi.
\newblock {RMAML: Riemannian meta-learning with orthogonality constraints}.
\newblock {\em Pattern Recognition}, 140:109563, 2023.

\bibitem{tsaknakis2022implicit}
Ioannis Tsaknakis, Prashant Khanduri, and Mingyi Hong.
\newblock An implicit gradient-type method for linearly constrained bilevel problems.
\newblock In {\em International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 2022.

\bibitem{wang2017stochastic}
Mengdi Wang, Ethan~X Fang, and Han Liu.
\newblock Stochastic compositional gradient descent: algorithms for minimizing compositions of expected-value functions.
\newblock {\em Mathematical Programming}, 161:419--449, 2017.

\bibitem{wang2023riemannian}
Xi~Wang, Deming Yuan, Yiguang Hong, Zihao Hu, Lei Wang, and Guodong Shi.
\newblock Riemannian optimistic algorithms.
\newblock Technical report, arXiv preprint arXiv:2308.16004, 2023.

\bibitem{xiao2023alternating}
Quan Xiao, Han Shen, Wotao Yin, and Tianyi Chen.
\newblock Alternating projected sgd for equality-constrained bilevel optimization.
\newblock In {\em International Conference on Artificial Intelligence and Statistics (AISTATS)}, 2023.

\bibitem{zadeh16}
Pourya Zadeh, Reshad Hosseini, and Suvrit Sra.
\newblock Geometric mean metric learning.
\newblock In {\em International Conference on Machine Learning (ICML)}, 2016.

\bibitem{zhang2022riemannian}
Dewei Zhang and Sam~Davanloo Tajbakhsh.
\newblock Riemannian stochastic gradient method for nested composition optimization.
\newblock Technical report, arXiv preprint arXiv:2207.09350, 2022.

\bibitem{zhang2016riemannian}
Hongyi Zhang, Sashank J~Reddi, and Suvrit Sra.
\newblock {Riemannian SVRG: Fast stochastic optimization on Riemannian manifolds}.
\newblock In {\em Advances in Neural Information Processing Systems (NeurIPS)}, 2016.

\bibitem{zhang2016first}
Hongyi Zhang and Suvrit Sra.
\newblock First-order methods for geodesically convex optimization.
\newblock In {\em Conference on Learning Theory (COLT)}, 2016.

\bibitem{sionminimaxgeode}
Peiyuan Zhang, Jingzhao Zhang, and Suvrit Sra.
\newblock Sion’s minimax theorem in geodesic metric spaces and a {Riemannian} extragradient algorithm.
\newblock {\em SIAM Journal on Optimization}, 33(4):2885--2908, 2023.

\end{thebibliography}
