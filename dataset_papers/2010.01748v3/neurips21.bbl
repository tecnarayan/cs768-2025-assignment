\begin{thebibliography}{10}

\bibitem{mnih2015human}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei~A Rusu, Joel Veness,
  Marc~G Bellemare, Alex Graves, Martin Riedmiller, Andreas~K Fidjeland, Georg
  Ostrovski, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock {\em Nature}, 518(7540):529, 2015.

\bibitem{cube_hand}
Ilge Akkaya, Marcin Andrychowicz, Maciek Chociej, Mateusz Litwin, Bob McGrew,
  Arthur Petron, Alex Paino, Matthias Plappert, Glenn Powell, Raphael Ribas,
  Jonas Schneider, Nikolas Tezak, Jerry Tworek, Peter Welinder, Lilian Weng,
  Qiming Yuan, Wojciech Zaremba, and Lei Zhang.
\newblock Solving rubik's cube with a robot hand.
\newblock {\em CoRR}, abs/1910.07113, 2019.

\bibitem{bojarski2016end}
Mariusz Bojarski, Davide Del~Testa, Daniel Dworakowski, Bernhard Firner, Beat
  Flepp, Prasoon Goyal, Lawrence~D Jackel, Mathew Monfort, Urs Muller, Jiakai
  Zhang, et~al.
\newblock End to end learning for self-driving cars.
\newblock {\em arXiv preprint arXiv:1604.07316}, 2016.

\bibitem{codevilla2018end}
Felipe Codevilla, Matthias Miiller, Antonio L{\'o}pez, Vladlen Koltun, and
  Alexey Dosovitskiy.
\newblock End-to-end driving via conditional behavior cloning.
\newblock In {\em 2018 IEEE International Conference on Robotics and Automation
  (ICRA)}, pages 1--9. IEEE, 2018.

\bibitem{agarwal2016learning}
Vibhu Agarwal, Tanya Podchiyska, Juan~M Banda, Veena Goel, Tiffany~I Leung,
  Evan~P Minty, Timothy~E Sweeney, Elsie Gyang, and Nigam~H Shah.
\newblock Learning statistical models of phenotypes using noisy labeled
  training data.
\newblock {\em Journal of the American Medical Informatics Association},
  23(6):1166--1173, 2016.

\bibitem{gao2018reinforcement}
Yang Gao, Huazhe Xu, Ji~Lin, Fisher Yu, Sergey Levine, and Trevor Darrell.
\newblock Reinforcement learning from imperfect demonstrations.
\newblock {\em arXiv preprint arXiv:1802.05313}, 2018.

\bibitem{wang2020rlnoisy}
Jingkang Wang, Yang Liu, and Bo~Li.
\newblock Reinforcement learning with perturbed rewards.
\newblock In {\em AAAI}, 2020.

\bibitem{EverittKOL17}
Tom Everitt, Victoria Krakovna, Laurent Orseau, and Shane Legg.
\newblock Reinforcement learning with a corrupted reward channel.
\newblock In {\em {IJCAI}}, pages 4705--4713, 2017.

\bibitem{RomoffP0FP18}
Joshua Romoff, Alexandre Pich{\'{e}}, Peter Henderson, Vincent
  Fran{\c{c}}ois{-}Lavet, and Joelle Pineau.
\newblock Reward estimation for variance reduction in deep reinforcement
  learning.
\newblock In {\em {ICLR} (Workshop)}. OpenReview.net, 2018.

\bibitem{loftin2014learning}
Robert Loftin, Bei Peng, James MacGlashan, Michael~L Littman, Matthew~E Taylor,
  Jeff Huang, and David~L Roberts.
\newblock Learning something from nothing: Leveraging implicit human feedback
  strategies.
\newblock In {\em The 23rd IEEE international symposium on robot and human
  interactive communication}, pages 607--612. IEEE, 2014.

\bibitem{LaskeyLFDG17}
Michael Laskey, Jonathan Lee, Roy Fox, Anca~D. Dragan, and Ken Goldberg.
\newblock {DART:} noise injection for robust behavior cloning.
\newblock In {\em CoRL}, volume~78 of {\em Proceedings of Machine Learning
  Research}, pages 143--156. {PMLR}, 2017.

\bibitem{wu2019imitation}
Yueh-Hua Wu, Nontawat Charoenphakdee, Han Bao, Voot Tangkaratt, and Masashi
  Sugiyama.
\newblock Imitation learning from imperfect demonstration.
\newblock In {\em International Conference on Machine Learning}, pages
  6818--6827. PMLR, 2019.

\bibitem{ReddyDL20}
Siddharth Reddy, Anca~D. Dragan, and Sergey Levine.
\newblock {SQIL:} behavior cloning via reinforcement learning with sparse
  rewards.
\newblock In {\em {ICLR}}. OpenReview.net, 2020.

\bibitem{sasaki2020behavioral}
Fumihiro Sasaki and Ryota Yamashina.
\newblock Behavioral cloning from noisy demonstrations.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{GuoCYTC19}
Xiaoxiao Guo, Shiyu Chang, Mo~Yu, Gerald Tesauro, and Murray Campbell.
\newblock Hybrid reinforcement learning with expert state sequences.
\newblock In {\em {AAAI}}, pages 3739--3746. {AAAI} Press, 2019.

\bibitem{lee2020weaklysupervised}
Lisa Lee, Benjamin Eysenbach, Ruslan Salakhutdinov, Shixiang, Gu, and Chelsea
  Finn.
\newblock Weakly-supervised reinforcement learning for controllable behavior,
  2020.

\bibitem{yang2020peerloss}
Yang Liu and Hongyi Guo.
\newblock Peer loss functions: Learning from noisy labels without knowing noise
  rates.
\newblock {\em ICML}, abs/1910.03231, 2020.

\bibitem{natarajan2013learning}
Nagarajan Natarajan, Inderjit~S Dhillon, Pradeep~K Ravikumar, and Ambuj Tewari.
\newblock Learning with noisy labels.
\newblock In {\em Advances in neural information processing systems}, pages
  1196--1204, 2013.

\bibitem{scott2013classification}
Clayton Scott, Gilles Blanchard, Gregory Handy, Sara Pozzi, and Marek Flaska.
\newblock Classification with asymmetric label noise: Consistency and maximal
  denoising.
\newblock In {\em COLT}, pages 489--511, 2013.

\bibitem{scott2015rate}
Clayton Scott.
\newblock A rate of convergence for mixture proportion estimation, with
  application to learning from noisy labels.
\newblock In {\em AISTATS}, 2015.

\bibitem{sukhbaatar2014learning}
Sainbayar Sukhbaatar and Rob Fergus.
\newblock Learning from noisy labels with deep neural networks.
\newblock {\em arXiv preprint arXiv:1406.2080}, 2(3):4, 2014.

\bibitem{van2015learning}
Brendan van Rooyen and Robert~C Williamson.
\newblock Learning in the presence of corruption.
\newblock {\em arXiv preprint arXiv:1504.00091}, 2015.

\bibitem{liu2015classification}
Tongliang Liu and Dacheng Tao.
\newblock Classification with noisy labels by importance reweighting.
\newblock {\em IEEE Transactions on pattern analysis and machine intelligence},
  38(3):447--461, 2015.

\bibitem{menon2015learning}
Aditya Menon, Brendan Van~Rooyen, Cheng~Soon Ong, and Bob Williamson.
\newblock Learning from corrupted binary labels via class-probability
  estimation.
\newblock In {\em ICML}, pages 125--134, 2015.

\bibitem{zhu2021second}
Zhaowei Zhu, Tongliang Liu, and Yang Liu.
\newblock A second-order approach to learning with instance-dependent label
  noise.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 10113--10123, 2021.

\bibitem{northcutt2021confident}
Curtis Northcutt, Lu~Jiang, and Isaac Chuang.
\newblock Confident learning: Estimating uncertainty in dataset labels.
\newblock {\em Journal of Artificial Intelligence Research}, 70:1373--1411,
  2021.

\bibitem{li2021provably}
Xuefeng Li, Tongliang Liu, Bo~Han, Gang Niu, and Masashi Sugiyama.
\newblock Provably end-to-end label-noise learning without anchor points.
\newblock {\em arXiv preprint arXiv:2102.02400}, 2021.

\bibitem{zhu2021clusterability}
Zhaowei Zhu, Yiwen Song, and Yang Liu.
\newblock Clusterability as an alternative to anchor points when learning with
  noisy labels.
\newblock {\em arXiv preprint arXiv:2102.05291}, 2021.

\bibitem{zhu2021federated}
Zhaowei Zhu, Jingxuan Zhu, Ji~Liu, and Yang Liu.
\newblock Federated bandit: A gossiping approach.
\newblock In {\em Abstract Proceedings of the 2021 ACM SIGMETRICS/International
  Conference on Measurement and Modeling of Computer Systems}, pages 3--4,
  2021.

\bibitem{wei2021when}
Jiaheng Wei and Yang Liu.
\newblock When optimizing {\$}f{\$}-divergence is robust with label noise.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{yang21understand}
Yang Liu.
\newblock Understanding instance-level label noise: Disparate impacts and
  treatments.
\newblock In {\em {ICML}}, volume 139 of {\em Proceedings of Machine Learning
  Research}, pages 6725--6735. {PMLR}, 2021.

\bibitem{pomerleau1991efficient}
Dean~A Pomerleau.
\newblock Efficient training of artificial neural networks for autonomous
  navigation.
\newblock {\em Neural computation}, 3(1):88--97, 1991.

\bibitem{ross2010efficient}
St{\'e}phane Ross and Drew Bagnell.
\newblock Efficient reductions for imitation learning.
\newblock In {\em Proceedings of the thirteenth international conference on
  artificial intelligence and statistics}, pages 661--668, 2010.

\bibitem{ross2011reduction}
St{\'e}phane Ross, Geoffrey Gordon, and Drew Bagnell.
\newblock A reduction of imitation learning and structured prediction to
  no-regret online learning.
\newblock In {\em Proceedings of the fourteenth international conference on
  artificial intelligence and statistics}, pages 627--635, 2011.

\bibitem{dart}
Michael Laskey, Jonathan Lee, Roy Fox, Anca~D. Dragan, and Ken Goldberg.
\newblock {DART:} noise injection for robust imitation learning.
\newblock In {\em CoRL}, volume~78 of {\em Proceedings of Machine Learning
  Research}, pages 143--156. {PMLR}, 2017.

\bibitem{end_bc_sdv}
Mariusz Bojarski, Davide~Del Testa, Daniel Dworakowski, Bernhard Firner, Beat
  Flepp, Prasoon Goyal, Lawrence~D. Jackel, Mathew Monfort, Urs Muller, Jiakai
  Zhang, Xin Zhang, Jake Zhao, and Karol Zieba.
\newblock End to end learning for self-driving cars.
\newblock {\em CoRR}, abs/1604.07316, 2016.

\bibitem{Reddy2019}
Siddharth Reddy, Anca~D. Dragan, and Sergey Levine.
\newblock {SQIL: Behavior Cloning via Reinforcement Learning with Sparse
  Rewards}.
\newblock 2019.

\bibitem{Torabi2018}
Faraz Torabi, Garrett Warnell, and Peter Stone.
\newblock Behavioral cloning from observation.
\newblock In {\em {IJCAI}}, pages 4950--4957. ijcai.org, 2018.

\bibitem{augmented_BCO}
Juarez Monteiro, Nathan Gavenski, Roger Granada, Felipe Meneguzzi, and
  Rodrigo~Coelho Barros.
\newblock Augmented behavioral cloning from observation.
\newblock {\em CoRR}, abs/2004.13529, 2020.

\bibitem{Giusti2016a}
Alessandro Giusti, Jerome Guzzi, Dan~C. Ciresan, Fang~Lin He, Juan~P.
  Rodriguez, Flavio Fontana, Matthias Faessler, Christian Forster, Jurgen
  Schmidhuber, Gianni~Di Caro, Davide Scaramuzza, and Luca~M. Gambardella.
\newblock {A Machine Learning Approach to Visual Perception of Forest Trails
  for Mobile Robots}.
\newblock {\em IEEE Robotics and Automation Letters}, 1(2):661--667, 2016.

\bibitem{justesen2017learning}
Niels Justesen and Sebastian Risi.
\newblock Learning macromanagement in starcraft from replays using deep
  learning.
\newblock In {\em 2017 IEEE Conference on Computational Intelligence and Games
  (CIG)}, pages 162--169. IEEE, 2017.

\bibitem{Farag2018}
Wael Farag and Zakaria Saleh.
\newblock {Behavior cloning for autonomous driving using convolutional neural
  networks}.
\newblock {\em 2018 International Conference on Innovation and Intelligence for
  Informatics, Computing, and Technologies, 3ICT 2018}, 2018.

\bibitem{SongLYO19}
Jialin Song, Ravi Lanka, Yisong Yue, and Masahiro Ono.
\newblock Co-training for policy learning.
\newblock In {\em {UAI}}, page 441. {AUAI} Press, 2019.

\bibitem{dasgupta2013crowdsourced}
Anirban Dasgupta and Arpita Ghosh.
\newblock Crowdsourced judgement elicitation with endogenous proficiency.
\newblock In {\em Proceedings of the 22nd international conference on World
  Wide Web}, pages 319--330, 2013.

\bibitem{ShnayderAFP16}
Victor Shnayder, Arpit Agarwal, Rafael~M. Frongillo, and David~C. Parkes.
\newblock Informed truthfulness in multi-task peer prediction.
\newblock In {\em {EC}}, pages 179--196. {ACM}, 2016.

\bibitem{BrysHSCTN15}
Tim Brys, Anna Harutyunyan, Halit~Bener Suay, Sonia Chernova, Matthew~E.
  Taylor, and Ann Now{\'{e}}.
\newblock Reinforcement learning from demonstration through shaping.
\newblock In {\em {IJCAI}}, pages 3352--3358. {AAAI} Press, 2015.

\bibitem{HesterVPLSPHQSO18}
Todd Hester, Matej Vecer{\'{\i}}k, Olivier Pietquin, Marc Lanctot, Tom Schaul,
  Bilal Piot, Dan Horgan, John Quan, Andrew Sendonaris, Ian Osband, Gabriel
  Dulac{-}Arnold, John Agapiou, Joel~Z. Leibo, and Audrunas Gruslys.
\newblock Deep q-learning from demonstrations.
\newblock In {\em {AAAI}}, pages 3223--3230. {AAAI} Press, 2018.

\bibitem{liu2021importance}
Yang Liu.
\newblock The importance of understanding instance-level noisy labels.
\newblock {\em arXiv preprint arXiv:2102.05336}, 2021.

\bibitem{dqn1}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis
  Antonoglou, Daan Wierstra, and Martin~A. Riedmiller.
\newblock Playing atari with deep reinforcement learning.
\newblock {\em CoRR}, abs/1312.5602, 2013.

\bibitem{dueling-dqn}
Ziyu Wang, Tom Schaul, Matteo Hessel, Hado van Hasselt, Marc Lanctot, and Nando
  de~Freitas.
\newblock Dueling network architectures for deep reinforcement learning.
\newblock In {\em {ICML}}, volume~48, pages 1995--2003, 2016.

\bibitem{SuttonMSM99}
Richard~S. Sutton, David~A. McAllester, Satinder~P. Singh, and Yishay Mansour.
\newblock Policy gradient methods for reinforcement learning with function
  approximation.
\newblock In {\em {NIPS}}, pages 1057--1063. The {MIT} Press, 1999.

\bibitem{Watkins92q-learning}
Christopher J. C.~H. Watkins and Peter Dayan.
\newblock Q-learning.
\newblock In {\em Machine Learning}, pages 279--292, 1992.

\bibitem{pathak2017curiosity}
Deepak Pathak, Pulkit Agrawal, Alexei~A Efros, and Trevor Darrell.
\newblock Curiosity-driven exploration by self-supervised prediction.
\newblock In {\em International conference on machine learning}, pages
  2778--2787. PMLR, 2017.

\bibitem{cheng2021learning}
Hao Cheng, Zhaowei Zhu, Xingyu Li, Yifei Gong, Xing Sun, and Yang Liu.
\newblock Learning with instance-dependent label noise: A sample sieve
  approach.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{prioritized_experience_replay}
Tom Schaul, John Quan, Ioannis Antonoglou, and David Silver.
\newblock Prioritized experience replay.
\newblock In {\em {ICLR} (Poster)}, 2016.

\bibitem{double-dqn}
Hado van Hasselt, Arthur Guez, and David Silver.
\newblock Deep reinforcement learning with double q-learning.
\newblock In {\em {AAAI}}, pages 2094--2100, 2016.

\bibitem{ddpg}
Timothy~P. Lillicrap, Jonathan~J. Hunt, Alexander Pritzel, Nicolas Heess, Tom
  Erez, Yuval Tassa, David Silver, and Daan Wierstra.
\newblock Continuous control with deep reinforcement learning.
\newblock {\em CoRR}, abs/1509.02971, 2015.

\bibitem{ppo}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock {\em CoRR}, abs/1707.06347, 2017.

\bibitem{Ho2016a}
Jonathan Ho and Stefano Ermon.
\newblock {Generative adversarial behavior cloning}.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4572--4580, 2016.

\bibitem{NgHR99}
Andrew~Y. Ng, Daishi Harada, and Stuart~J. Russell.
\newblock Policy invariance under reward transformations: Theory and
  application to reward shaping.
\newblock In {\em {ICML}}, pages 278--287. Morgan Kaufmann, 1999.

\bibitem{AsmuthLZ08}
John Asmuth, Michael~L. Littman, and Robert Zinkov.
\newblock Potential-based shaping in model-based reinforcement learning.
\newblock In {\em {AAAI}}, pages 604--609. {AAAI} Press, 2008.

\bibitem{von2007theory}
John Von~Neumann and Oskar Morgenstern.
\newblock {\em Theory of games and economic behavior (commemorative edition)}.
\newblock Princeton university press, 2007.

\bibitem{DBLP:conf/nips/JaakkolaJS93}
Tommi~S. Jaakkola, Michael~I. Jordan, and Satinder~P. Singh.
\newblock Convergence of stochastic iterative dynamic programming algorithms.
\newblock In {\em {NIPS}}, pages 703--710, 1993.

\bibitem{DBLP:journals/ml/Tsitsiklis94}
John~N. Tsitsiklis.
\newblock Asynchronous stochastic approximation and q-learning.
\newblock {\em Machine Learning}, 16(3):185--202, 1994.

\bibitem{KearnsS98a}
Michael~J. Kearns and Satinder~P. Singh.
\newblock Finite-sample convergence rates for q-learning and indirect
  algorithms.
\newblock In {\em {NIPS}}, pages 996--1002, 1998.

\bibitem{KearnsS00}
Michael~J. Kearns and Satinder~P. Singh.
\newblock Bias-variance error bounds for temporal difference updates.
\newblock In {\em {COLT}}, pages 142--147, 2000.

\bibitem{KearnsMN99}
Michael~J. Kearns, Yishay Mansour, and Andrew~Y. Ng.
\newblock A sparse sampling algorithm for near-optimal planning in large markov
  decision processes.
\newblock In {\em {IJCAI}}, pages 1324--1231, 1999.

\bibitem{Kakade2003OnTS}
Sham~Machandranath Kakade.
\newblock {\em On the Sample Complexity of Reinforcement Learning}.
\newblock PhD thesis, University of London, 2003.

\end{thebibliography}
