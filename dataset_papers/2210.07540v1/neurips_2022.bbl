\begin{thebibliography}{10}

\bibitem{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em ICLR}, 2021.

\bibitem{liu2021swin}
Ze~Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock In {\em ICCV}, 2021.

\bibitem{krizhevsky2012imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In {\em NeurIPS}, 2012.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em CVPR}, 2016.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em NeurIPS}, 2017.

\bibitem{zheng2021rethinking}
Sixiao Zheng, Jiachen Lu, Hengshuang Zhao, Xiatian Zhu, Zekun Luo, Yabiao Wang,
  Yanwei Fu, Jianfeng Feng, Tao Xiang, Philip~HS Torr, et~al.
\newblock Rethinking semantic segmentation from a sequence-to-sequence
  perspective with transformers.
\newblock In {\em CVPR}, 2021.

\bibitem{carion2020end}
Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander
  Kirillov, and Sergey Zagoruyko.
\newblock End-to-end object detection with transformers.
\newblock In {\em ECCV}, 2020.

\bibitem{jiang2021transgan}
Yifan Jiang, Shiyu Chang, and Zhangyang Wang.
\newblock Transgan: Two pure transformers can make one strong gan, and that can
  scale up.
\newblock In {\em NeurIPS}, 2021.

\bibitem{shao2021adversarial}
Rulin Shao, Zhouxing Shi, Jinfeng Yi, Pin-Yu Chen, and Cho-Jui Hsieh.
\newblock On the adversarial robustness of visual transformers.
\newblock In {\em arXiv}, 2021.

\bibitem{aldahdooh2021reveal}
Ahmed Aldahdooh, Wassim Hamidouche, and Olivier Deforges.
\newblock Reveal of vision transformers robustness against adversarial attacks.
\newblock In {\em arXiv}, 2021.

\bibitem{szegedy2013intriguing}
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
  Ian Goodfellow, and Rob Fergus.
\newblock Intriguing properties of neural networks.
\newblock In {\em ICLR}, 2014.

\bibitem{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In {\em ICLR}, 2015.

\bibitem{madry2017towards}
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
  Adrian Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In {\em ICLR}, 2018.

\bibitem{zhang2019theoretically}
Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric~P. Xing, Laurent~El Ghaoui, and
  Michael~I. Jordan.
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In {\em ICML}, 2019.

\bibitem{wang2019improving}
Yisen Wang, Difan Zou, Jinfeng Yi, James Bailey, Xingjun Ma, and Quanquan Gu.
\newblock Improving adversarial robustness requires revisiting misclassified
  examples.
\newblock In {\em ICLR}, 2020.

\bibitem{wu2020adversarial}
Dongxian Wu, Shu-Tao Xia, and Yisen Wang.
\newblock Adversarial weight perturbation helps robust generalization.
\newblock In {\em NeurIPS}, 2020.

\bibitem{pang2020bag}
Tianyu Pang, Xiao Yang, Yinpeng Dong, Hang Su, and Jun Zhu.
\newblock Bag of tricks for adversarial training.
\newblock In {\em ICLR}, 2021.

\bibitem{sun2017revisiting}
Chen Sun, Abhinav Shrivastava, Saurabh Singh, and Abhinav Gupta.
\newblock Revisiting unreasonable effectiveness of data in deep learning era.
\newblock In {\em ICCV}, 2017.

\bibitem{touvron2021training}
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre
  Sablayrolles, and Herv{\'e} J{\'e}gou.
\newblock Training data-efficient image transformers \& distillation through
  attention.
\newblock In {\em ICML}, 2021.

\bibitem{cubuk2019randaugment}
Ekin~Dogus Cubuk, Barret Zoph, Jon Shlens, and Quoc Le.
\newblock Randaugment: Practical automated data augmentation with a reduced
  search space.
\newblock In {\em NeurIPS}, 2020.

\bibitem{zhang2017mixup}
Hongyi Zhang, Moustapha Cisse, Yann~N Dauphin, and David Lopez-Paz.
\newblock mixup: Beyond empirical risk minimization.
\newblock In {\em ICLR}, 2018.

\bibitem{loshchilov2018decoupled}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock In {\em ICLR}, 2018.

\bibitem{robbins1951stochastic}
Herbert Robbins and Sutton Monro.
\newblock A stochastic approximation method.
\newblock {\em The Annals of Mathematical Statistics}, 1951.

\bibitem{qu2021rethinking}
Liangqiong Qu, Yuyin Zhou, Paul~Pu Liang, Yingda Xia, Feifei Wang, Li~Fei-Fei,
  Ehsan Adeli, and Daniel Rubin.
\newblock Rethinking architecture design for tackling data heterogeneity in
  federated learning.
\newblock In {\em CVPR}, 2022.

\bibitem{chen2021empirical}
Xinlei Chen, Saining Xie, and Kaiming He.
\newblock An empirical study of training self-supervised vision transformers.
\newblock In {\em ICCV}, 2021.

\bibitem{steiner2021train}
Andreas Steiner, Alexander Kolesnikov, Xiaohua Zhai, Ross Wightman, Jakob
  Uszkoreit, and Lucas Beyer.
\newblock How to train your vit? data, augmentation, and regularization in
  vision transformers.
\newblock In {\em Transactions on Machine Learning Research}, 2022.

\bibitem{carlini2017towards}
Nicholas Carlini and David Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In {\em S$\&$P}, 2017.

\bibitem{wang2019dynamic}
Yisen Wang, Xingjun Ma, James Bailey, Jinfeng Yi, Bowen Zhou, and Quanquan Gu.
\newblock On the convergence and robustness of adversarial training.
\newblock In {\em ICML}, 2019.

\bibitem{wang2022self}
Hongjun Wang and Yisen Wang.
\newblock Self-ensemble adversarial training for improved robustness.
\newblock In {\em ICLR}, 2022.

\bibitem{athalye2018obfuscated}
Anish Athalye, Nicholas Carlini, and David Wagner.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In {\em ICML}, 2018.

\bibitem{croce2020reliable}
Francesco Croce and Matthias Hein.
\newblock Reliable evaluation of adversarial robustness with an ensemble of
  diverse parameter-free attacks.
\newblock In {\em ICML}, 2020.

\bibitem{croce2021robustbench}
Francesco Croce, Maksym Andriushchenko, Vikash Sehwag, Edoardo Debenedetti,
  Nicolas Flammarion, Mung Chiang, Prateek Mittal, and Matthias Hein.
\newblock Robustbench: a standardized adversarial robustness benchmark.
\newblock In {\em NeurIPS Datasets and Benchmarks Track}, 2021.

\bibitem{mahmood2021robustness}
Kaleel Mahmood, Rigel Mahmood, and Marten Van~Dijk.
\newblock On the robustness of vision transformers to adversarial examples.
\newblock In {\em ICCV}, 2021.

\bibitem{benz2021adversarial}
Philipp Benz, Soomin Ham, Chaoning Zhang, Adil Karjauv, and In~So Kweon.
\newblock Adversarial robustness comparison of vision transformer and mlp-mixer
  to cnns.
\newblock In {\em arXiv}, 2021.

\bibitem{bai2021transformers}
Yutong Bai, Jieru Mei, Alan~L Yuille, and Cihang Xie.
\newblock Are transformers more robust than cnns?
\newblock In {\em NeurIPS}, 2021.

\bibitem{cifar}
Alex Krizhevsky, Geoffrey Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock {\em Tech Report}, 2009.

\bibitem{imagenette}
Jeremy Howard.
\newblock Imagenette.
\newblock \url{https://github.com/fastai/imagenette/}.

\bibitem{croce2020minimally}
Francesco Croce and Matthias Hein.
\newblock Minimally distorted adversarial examples with a fast adaptive
  boundary attack.
\newblock In {\em ICML}, 2020.

\bibitem{andriushchenko2020square}
Maksym Andriushchenko, Francesco Croce, Nicolas Flammarion, and Matthias Hein.
\newblock Square attack: a query-efficient black-box adversarial attack via
  random search.
\newblock In {\em ECCV}, 2020.

\bibitem{pascanu2012understanding}
Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio.
\newblock Understanding the exploding gradient problem.
\newblock In {\em arXiv}, 2012.

\bibitem{rice2020overfitting}
Leslie Rice, Eric Wong, and Zico Kolter.
\newblock Overfitting in adversarially robust deep learning.
\newblock In {\em ICML}, 2020.

\bibitem{gowal2020uncovering}
Sven Gowal, Chongli Qin, Jonathan Uesato, Timothy Mann, and Pushmeet Kohli.
\newblock Uncovering the limits of adversarial training against norm-bounded
  adversarial examples.
\newblock In {\em arXiv}, 2020.

\bibitem{yun2019cutmix}
Sangdoo Yun, Dongyoon Han, Seong~Joon Oh, Sanghyuk Chun, Junsuk Choe, and
  Youngjoon Yoo.
\newblock Cutmix: Regularization strategy to train strong classifiers with
  localizable features.
\newblock In {\em ICCV}, 2019.

\bibitem{d2021convit}
St{\'e}phane dâ€™Ascoli, Hugo Touvron, Matthew~L Leavitt, Ari~S Morcos, Giulio
  Biroli, and Levent Sagun.
\newblock Convit: Improving vision transformers with soft convolutional
  inductive biases.
\newblock In {\em ICML}, 2021.

\end{thebibliography}
