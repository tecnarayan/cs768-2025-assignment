\begin{thebibliography}{10}

\bibitem{kingma2014auto}
Kingma, D.~P. and Welling, M.
\newblock Auto-Encoding Variational {Bayes}.
\newblock In \emph{2nd International Conference on Learning Representations},
  edited by Y.~Bengio and Y.~LeCun, 2014.

\bibitem{rezende2014stochastic}
Rezende, D.~J., Mohamed, S., and Wierstra, D.
\newblock Stochastic Backpropagation and Approximate Inference in Deep
  Generative Models.
\newblock In \emph{Proceedings of the 31st International Conference on Machine
  Learning}, edited by E.~P. Xing and T.~Jebara, volume~32 of \emph{Proceedings
  of Machine Learning Research}, pp. 1278--1286. PMLR, Beijing, China, 2014.

\bibitem{goodfellow2014generative}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
  S., Courville, A., and Bengio, Y.
\newblock Generative Adversarial Nets.
\newblock In \emph{Advances in Neural Information Processing Systems}, edited
  by Z.~Ghahramani, M.~Welling, C.~Cortes, N.~Lawrence, and K.~Q. Weinberger,
  volume~27. Curran Associates, Inc., 2014.

\bibitem{tabak2013family}
Tabak, E.~G. and Turner, C.~V.
\newblock A Family of Nonparametric Density Estimation Algorithms.
\newblock \emph{Communications on Pure and Applied Mathematics},
  66(2):145--164, 2013.

\bibitem{rezende2015variational}
Rezende, D. and Mohamed, S.
\newblock Variational Inference with Normalizing Flows.
\newblock In \emph{Proceedings of the 32nd International Conference on Machine
  Learning}, edited by F.~R. Bach and D.~Blei, volume~37 of \emph{Proceedings
  of Machine Learning Research}, pp. 1530--1538. PMLR, Lille, France, 2015.

\bibitem{sohl2015deep}
Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N., and Ganguli, S.
\newblock Deep Unsupervised Learning using Nonequilibrium Thermodynamics.
\newblock In \emph{Proceedings of the 32nd International Conference on Machine
  Learning}, edited by F.~R. Bach and D.~Blei, volume~37 of \emph{Proceedings
  of Machine Learning Research}, pp. 2256--2265. PMLR, Lille, France, 2015.

\bibitem{ho2020denoising}
Ho, J., Jain, A., and Abbeel, P.
\newblock Denoising Diffusion Probabilistic Models.
\newblock In \emph{Advances in Neural Information Processing Systems}, edited
  by H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin,
  volume~33. Curran Associates, Inc., 2020.

\bibitem{theis2016note}
Theis, L., van~den Oord, A., and Bethge, M.
\newblock A Note on the Evaluation of Generative Models.
\newblock In \emph{4th International Conference on Learning Representations},
  edited by Y.~Bengio and Y.~LeCun, 2016.

\bibitem{karras2018progressive}
Karras, T., Aila, T., Laine, S., and Lehtinen, J.
\newblock Progressive Growing of {GAN}s for Improved Quality, Stability, and
  Variation.
\newblock In \emph{6th International Conference on Learning Representations},
  2018.

\bibitem{brock2018large}
Brock, A., Donahue, J., and Simonyan, K.
\newblock Large Scale {GAN} Training for High Fidelity Natural Image Synthesis.
\newblock In \emph{7th International Conference on Learning Representations},
  2019.

\bibitem{vahdat2020nvae}
Vahdat, A. and Kautz, J.
\newblock {NVAE}: A Deep Hierarchical Variational Autoencoder.
\newblock In \emph{Advances in Neural Information Processing Systems}, edited
  by H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin,
  volume~33, pp. 19667--19679. Curran Associates, Inc., 2020.

\bibitem{barz2020do}
Barz, B. and Denzler, J.
\newblock Do We Train on Test Data? {P}urging {CIFAR} of Near-Duplicates.
\newblock \emph{Journal of Imaging}, 6(6):41, 2020.

\bibitem{rosenblatt1956remarks}
Rosenblatt, M.
\newblock {Remarks on Some Nonparametric Estimates of a Density Function}.
\newblock \emph{The Annals of Mathematical Statistics}, 27(3):832 -- 837, 1956.

\bibitem{parzen1962estimation}
Parzen, E.
\newblock {On Estimation of a Probability Density Function and Mode}.
\newblock \emph{The Annals of Mathematical Statistics}, 33(3):1065 -- 1076,
  1962.

\bibitem{feldman2019does}
Feldman, V.
\newblock Does Learning Require Memorization? A Short Tale about a Long Tail.
\newblock \emph{arXiv preprint arXiv:1906.05271}, 2019.

\bibitem{feldman2020what}
Feldman, V. and Zhang, C.
\newblock What Neural Networks Memorize and Why: Discovering the Long Tail via
  Influence Estimation.
\newblock In \emph{Advances in Neural Information Processing Systems}, edited
  by H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin,
  volume~33, pp. 2881--2891. Curran Associates, Inc., 2020.

\bibitem{zhang2017understanding}
Zhang, C., Bengio, S., Hardt, M., Recht, B., and Vinyals, O.
\newblock Understanding Deep Learning Requires Rethinking Generalization.
\newblock In \emph{5th International Conference on Learning Representations},
  2017.

\bibitem{arpit2017closer}
Arpit, D., Jastrz{\k{e}}bski, S., Ballas, N., Krueger, D., Bengio, E., Kanwal,
  M.~S., Maharaj, T., Fischer, A., Courville, A., Bengio, Y., and
  Lacoste-Julien, S.
\newblock A Closer Look at Memorization in Deep Networks.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning}, edited by D.~Precup and Y.~W. Teh, volume~70, pp. 233--242, 2017.

\bibitem{stephenson2021on}
Stephenson, C., Padhy, S., Ganesh, A., Hui, Y., Tang, H., and Chung, S.
\newblock On the Geometry of Generalization and Memorization in Deep Neural
  Networks.
\newblock In \emph{9th International Conference on Learning Representations},
  2021.

\bibitem{carlini2019secret}
Carlini, N., Liu, C., Erlingsson, {\'U}., Kos, J., and Song, D.
\newblock The Secret Sharer: Evaluating and Testing Unintended Memorization in
  Neural Networks.
\newblock In \emph{28th {USENIX} Security Symposium}, pp. 267--284, 2019.

\bibitem{hochreiter1997long}
Hochreiter, S. and Schmidhuber, J.
\newblock Long Short-Term Memory.
\newblock \emph{Neural Computation}, 9(8):1735--1780, 1997.

\bibitem{jiang2021characterizing}
Jiang, Z., Zhang, C., Talwar, K., and Mozer, M.~C.
\newblock Characterizing Structural Regularities of Labeled Data in
  Overparameterized Models.
\newblock In \emph{Proceedings of the 38th International Conference on Machine
  Learning}, edited by M.~Meila and T.~Zhang, volume 139 of \emph{Proceedings
  of Machine Learning Research}, pp. 5034--5044. PMLR, 2021.

\bibitem{liu2020early}
Liu, S., Niles-Weed, J., Razavian, N., and Fernandez-Granda, C.
\newblock Early-Learning Regularization Prevents Memorization of Noisy Labels.
\newblock In \emph{Advances in Neural Information Processing Systems}, edited
  by H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin,
  volume~33, pp. 20331--20342. Curran Associates, Inc., 2020.

\bibitem{xia2021robust}
Xia, X., Liu, T., Han, B., Gong, C., Wang, N., Ge, Z., and Chang, Y.
\newblock Robust Early-Learning: Hindering the Memorization of Noisy Labels.
\newblock In \emph{9th International Conference on Learning Representations},
  2021.

\bibitem{lopez2016revisiting}
Lopez-Paz, D. and Oquab, M.
\newblock Revisiting Classifier Two-Sample Tests.
\newblock In \emph{5th International Conference on Learning Representations},
  2017.

\bibitem{xu2018empirical}
Xu, Q., Huang, G., Yuan, Y., Guo, C., Sun, Y., Wu, F., and Weinberger, K.~Q.
\newblock An Empirical Study on Evaluation Metrics of Generative Adversarial
  Networks.
\newblock \emph{arXiv preprint arXiv:1806.07755}, 2018.

\bibitem{meehan2020non}
Meehan, C., Chaudhuri, K., and Dasgupta, S.
\newblock A Non-Parametric Test to Detect Data-Copying in Generative Models.
\newblock In \emph{Proceedings of the 23rd International Conference on
  Artificial Intelligence and Statistics}, edited by S.~Chiappa and
  R.~Calandra, volume 108 of \emph{Proceedings of Machine Learning Research},
  pp. 3546--3556. PMLR, 2020.

\bibitem{fredrikson2015model}
Fredrikson, M., Jha, S., and Ristenpart, T.
\newblock Model Inversion Attacks that Exploit Confidence Information and Basic
  Countermeasures.
\newblock In \emph{Proceedings of the 22nd {ACM} {SIGSAC} Conference on
  Computer and Communications Security}, pp. 1322--1333, 2015.

\bibitem{shokri2017membership}
Shokri, R., Stronati, M., Song, C., and Shmatikov, V.
\newblock Membership Inference Attacks against Machine Learning Models.
\newblock In \emph{2017 IEEE Symposium on Security and Privacy}, pp. 3--18.
  IEEE, 2017.

\bibitem{hitaj2017deep}
Hitaj, B., Ateniese, G., and Perez-Cruz, F.
\newblock Deep Models Under the {GAN}: Information Leakage from Collaborative
  Deep Learning.
\newblock In \emph{Proceedings of the 2017 {ACM} {SIGSAC} Conference on
  Computer and Communications Security}, pp. 603--618, 2017.

\bibitem{hayes2019logan}
Hayes, J., Melis, L., Danezis, G., and De~Cristofaro, E.
\newblock {LOGAN}: Membership Inference Attacks Against Generative Models.
\newblock \emph{Proceedings on Privacy Enhancing Technologies},
  2019(1):133--152, 2019.

\bibitem{webster2019detecting}
Webster, R., Rabin, J., Simon, L., and Jurie, F.
\newblock Detecting Overfitting of Deep Generative Networks via Latent
  Recovery.
\newblock In \emph{Proceedings of the {IEEE/CVF} Conference on Computer Vision
  and Pattern Recognition}, pp. 11273--11282, 2019.

\bibitem{arora2018do}
Arora, S., Risteski, A., and Zhang, Y.
\newblock Do {GAN}s Learn the Distribution? Some Theory and Empirics.
\newblock In \emph{6th International Conference on Learning Representations},
  2018.

\bibitem{nalisnick2019deep}
Nalisnick, E., Matsukawa, A., Teh, Y.~W., Gorur, D., and Lakshminarayanan, B.
\newblock Do Deep Generative Models Know What They Don't Know?
\newblock In \emph{7th International Conference on Learning Representations},
  2019.

\bibitem{salimans2016improved}
Salimans, T., Goodfellow, I., Zaremba, W., Cheun, V., Radford, A., and Chen, X.
\newblock Improved Techniques for Training {GAN}s.
\newblock In \emph{Advances in Neural Information Processing Systems}, edited
  by D.~D. Lee, M.~Sugiyama, U.~V. Luxburg, I.~Guyon, and R.~Garnett,
  volume~29, pp. 2234--2242. Curran Associates, Inc., 2016.

\bibitem{heusel2017gans}
Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., and Hochreiter, S.
\newblock {GAN}s Trained by a Two Time-Scale Update Rule Converge to a Local
  {Nash} Equilibrium.
\newblock In \emph{Advances in Neural Information Processing Systems}, edited
  by I.~Guyon, U.~V. Luxburg, S.~Bengio, H.~Wallach, R.~Fergus,
  S.~Vishwanathan, and R.~Garnett, volume~30. Curran Associates, Inc., 2017.

\bibitem{gulrajani2018towards}
Gulrajani, I., Raffel, C., and Metz, L.
\newblock Towards {GAN} Benchmarks Which Require Generalization.
\newblock In \emph{7th International Conference on Learning Representations},
  2019.

\bibitem{hampel1974influence}
Hampel, F.~R.
\newblock The Influence Curve and Its Role in Robust Estimation.
\newblock \emph{Journal of the American Statistical Association},
  69(346):383--393, 1974.

\bibitem{cook1980characterizations}
Cook, R.~D. and Weisberg, S.
\newblock Characterizations of an Empirical Influence Function for Detecting
  Influential Cases in Regression.
\newblock \emph{Technometrics}, 22(4):495--508, 1980.

\bibitem{koh2017understanding}
Koh, P.~W. and Liang, P.
\newblock Understanding Black-box Predictions via Influence Functions.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning}, edited by D.~Precup and Y.~W. Teh, volume~70, pp. 1885--1894,
  2017.

\bibitem{terashita2021influence}
Terashita, N., Ohashi, H., Nonaka, Y., and Kanemaru, T.
\newblock Influence Estimation for Generative Adversarial Networks.
\newblock In \emph{9th International Conference on Learning Representations},
  2021.

\bibitem{basu2021influence}
Basu, S., Pope, P., and Feizi, S.
\newblock Influence Functions in Deep Learning Are Fragile.
\newblock In \emph{9th International Conference on Learning Representations},
  2021.

\bibitem{kong2021understanding}
Kong, Z. and Chaudhuri, K.
\newblock Understanding Instance-based Interpretability of Variational
  Auto-Encoders.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~34, 2021.

\bibitem{pruthi2020estimating}
Pruthi, G., Liu, F., Kale, S., and Sundararajan, M.
\newblock Estimating Training Data Influence by Tracing Gradient Descent.
\newblock In \emph{Advances in Neural Information Processing Systems}, edited
  by H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin,
  volume~33, pp. 19920--19930. Curran Associates, Inc., 2020.

\bibitem{bousquet2002stability}
Bousquet, O. and Elisseeff, A.
\newblock Stability and Generalization.
\newblock \emph{Journal of Machine Learning Research}, 2:499--526, 2002.

\bibitem{kullback1951information}
Kullback, S. and Leibler, R.~A.
\newblock On Information and Sufficiency.
\newblock \emph{The Annals of Mathematical Statistics}, 22(1):79--86, 1951.

\bibitem{burda2016importance}
Burda, Y., Grosse, R.~B., and Salakhutdinov, R.
\newblock Importance Weighted Autoencoders.
\newblock In \emph{4th International Conference on Learning Representations},
  edited by Y.~Bengio and Y.~LeCun, 2016.

\bibitem{lecun1998mnist}
LeCun, Y., Cortes, C., and Burges, C. J.~C.
\newblock The {MNIST} Database of Handwritten Digits, 1998.

\bibitem{krizhevsky2009learning}
Krizhevsky, A.
\newblock \emph{Learning Multiple Layers of Features from Tiny Images}.
\newblock Master's thesis, University of Toronto, 2009.

\bibitem{liu2015faceattributes}
Liu, Z., Luo, P., Wang, X., and Tang, X.
\newblock Deep Learning Face Attributes in the Wild.
\newblock In \emph{Proceedings of International Conference on Computer Vision},
  2015.

\bibitem{kingma2015adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: {A} Method for Stochastic Optimization.
\newblock In \emph{3rd International Conference on Learning Representations},
  edited by Y.~Bengio and Y.~LeCun, 2015.

\bibitem{paszke2019pytorch}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., K{\"{o}}pf, A., Yang,
  E., DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang,
  L., Bai, J., and Chintala, S.
\newblock {PyTorch}: An Imperative Style, High-Performance Deep Learning
  Library.
\newblock In \emph{Advances in Neural Information Processing Systems}, edited
  by H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d'Alch{\'e} Buc, E.~B. Fox,
  and R.~Garnett, volume~32. Curran Associates, Inc., 2019.

\bibitem{wu2016quantitative}
Wu, Y., Burda, Y., Salakhutdinov, R., and Grosse, R.~B.
\newblock On the Quantitative Analysis of Decoder-Based Generative Models.
\newblock In \emph{5th International Conference on Learning Representations},
  2017.

\bibitem{dwork2006calibrating}
Dwork, C., McSherry, F., Nissim, K., and Smith, A.
\newblock Calibrating Noise to Sensitivity in Private Data Analysis.
\newblock In \emph{Theory of Cryptography Conference}, pp. 265--284. Springer,
  2006.

\bibitem{dwork2014algorithmic}
Dwork, C. and Roth, A.
\newblock The Algorithmic Foundations of Differential Privacy.
\newblock \emph{Foundations and Trends in Theoretical Computer Science},
  9(3â€“4):211--407, 2014.

\bibitem{quinn2009factorial}
Quinn, J.~A., Williams, C. K.~I., and McIntosh, N.
\newblock Factorial Switching Linear Dynamical Systems Applied to Physiological
  Condition Monitoring.
\newblock \emph{{IEEE} Transactions on Pattern Analysis and Machine
  Intelligence}, 31(9):1537--1551, 2009.

\bibitem{eduardo2020robust}
Eduardo, S., Naz{\'a}bal, A., Williams, C. K.~I., and Sutton, C.
\newblock Robust Variational Autoencoders for Outlier Detection and Repair of
  Mixed-Type Data.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pp. 4056--4066. PMLR, 2020.

\bibitem{akrami2019robust}
Akrami, H., Joshi, A.~A., Li, J., Aydore, S., and Leahy, R.~M.
\newblock Robust Variational Autoencoder.
\newblock \emph{arXiv preprint arXiv:1905.09961}, 2019.

\bibitem{lee2011much}
Lee, J. and Clifton, C.
\newblock How Much is Enough? Choosing $\varepsilon$ for Differential Privacy.
\newblock In \emph{International Conference on Information Security}, pp.
  325--340. Springer, 2011.

\bibitem{hsu2014differential}
Hsu, J., Gaboardi, M., Haeberlen, A., Khanna, S., Narayan, A., Pierce, B.~C.,
  and Roth, A.
\newblock Differential Privacy: An Economic Method for Choosing Epsilon.
\newblock In \emph{2014 IEEE 27th Computer Security Foundations Symposium}, pp.
  398--410. IEEE, 2014.

\bibitem{belkin2019reconciling}
Belkin, M., Hsu, D., Ma, S., and Mandal, S.
\newblock Reconciling Modern Machine-Learning Practice and the Classical
  Bias--Variance Trade-off.
\newblock \emph{Proceedings of the National Academy of Sciences},
  116(32):15849--15854, 2019.

\bibitem{nakkiran2020deep}
Nakkiran, P., Kaplun, G., Bansal, Y., Yang, T., Barak, B., and Sutskever, I.
\newblock Deep Double Descent: Where Bigger Models and More Data Hurt.
\newblock In \emph{8th International Conference on Learning Representations},
  2020.

\bibitem{song2021scorebased}
Song, Y., Sohl-Dickstein, J., Kingma, D.~P., Kumar, A., Ermon, S., and Poole,
  B.
\newblock Score-Based Generative Modeling through Stochastic Differential
  Equations.
\newblock In \emph{9th International Conference on Learning Representations},
  2021.

\bibitem{salakhutdinov2008quantitative}
Salakhutdinov, R. and Murray, I.
\newblock On the Quantitative Analysis of Deep Belief Networks.
\newblock In \emph{Proceedings of the 25th International Conference on Machine
  Learning}, edited by A.~McCallum and S.~Roweis, pp. 872--879. Omnipress,
  2008.

\bibitem{nair2010rectified}
Nair, V. and Hinton, G.~E.
\newblock Rectified Linear Units Improve Restricted {Boltzmann} Machines.
\newblock In \emph{Proceedings of the 27th International Conference on Machine
  Learning}, edited by J.~F{\"u}rnkranz and T.~Joachims, pp. 807--814.
  Omnipress, 2010.

\bibitem{uria2013rnade}
Uria, B., Murray, I., and Larochelle, H.
\newblock {RNADE}: The Real-Valued Neural Autoregressive Density-Estimator.
\newblock In \emph{Advances in Neural Information Processing Systems}, edited
  by C.~J.~C. Burges, L.~Bottou, M.~Welling, Z.~Ghahramani, and K.~Q.
  Weinberger, volume~26, pp. 2175--2183. Curran Associates, Inc., 2013.

\bibitem{papamakarios2017masked}
Papamakarios, G., Pavlakou, T., and Murray, I.
\newblock Masked Autoregressive Flow for Density Estimation.
\newblock In \emph{Advances in Neural Information Processing Systems}, edited
  by I.~Guyon, U.~V. Luxburg, S.~Bengio, H.~Wallach, R.~Fergus,
  S.~Vishwanathan, and R.~Garnett, volume~30. Curran Associates, Inc., 2017.

\bibitem{radford2016unsupervised}
Radford, A., Metz, L., and Chintala, S.
\newblock Unsupervised Representation Learning with Deep Convolutional
  Generative Adversarial Networks.
\newblock In \emph{4th International Conference on Learning Representations},
  edited by Y.~Bengio and Y.~LeCun, 2016.

\bibitem{ioffe2015batch}
Ioffe, S. and Szegedy, C.
\newblock Batch Normalization: Accelerating Deep Network Training by Reducing
  Internal Covariate Shift.
\newblock In \emph{Proceedings of the 32nd International Conference on Machine
  Learning}, edited by F.~R. Bach and D.~Blei, volume~37 of \emph{Proceedings
  of Machine Learning Research}, pp. 448--456. PMLR, Lille, France, 2015.

\bibitem{maas2013rectifier}
Maas, A.~L., Hannun, A.~Y., and Ng, A.~Y.
\newblock Rectifier Nonlinearities Improve Neural Network Acoustic Models.
\newblock In \emph{Proceedings of the 30th International Conference on Machine
  Learning}, edited by S.~Dasgupta and D.~McAllester, volume~28 of
  \emph{Proceedings of Machine Learning Research}. PMLR, 2013.

\end{thebibliography}
