\begin{thebibliography}{10}

\bibitem{anthropic-2023}
Anthropic.
\newblock {Claude 2}, 7 2023.

\bibitem{anthropic-2024}
Anthropic.
\newblock {Introducing the next generation of Claude}, 3 2024.

\bibitem{bai2023qwen}
J.~Bai, S.~Bai, Y.~Chu, Z.~Cui, K.~Dang, X.~Deng, Y.~Fan, W.~Ge, Y.~Han, F.~Huang, et~al.
\newblock Qwen technical report.
\newblock {\em arXiv preprint arXiv:2309.16609}, 2023.

\bibitem{open-llm-leaderboard}
E.~Beeching, C.~Fourrier, N.~Habib, S.~Han, N.~Lambert, N.~Rajani, O.~Sanseviero, L.~Tunstall, and T.~Wolf.
\newblock Open llm leaderboard.
\newblock \url{https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard}, 2023.

\bibitem{brown2020language}
T.~Brown, B.~Mann, N.~Ryder, M.~Subbiah, J.~D. Kaplan, P.~Dhariwal, A.~Neelakantan, P.~Shyam, G.~Sastry, A.~Askell, et~al.
\newblock Language models are few-shot learners.
\newblock {\em Advances in neural information processing systems}, 33:1877--1901, 2020.

\bibitem{clark2018think}
P.~Clark, I.~Cowhey, O.~Etzioni, T.~Khot, A.~Sabharwal, C.~Schoenick, and O.~Tafjord.
\newblock Think you have solved question answering? try arc, the ai2 reasoning challenge, 2018.

\bibitem{gsm8k}
K.~Cobbe, V.~Kosaraju, M.~Bavarian, M.~Chen, H.~Jun, L.~Kaiser, M.~Plappert, J.~Tworek, J.~Hilton, R.~Nakano, C.~Hesse, and J.~Schulman.
\newblock Training verifiers to solve math word problems, 2021.

\bibitem{gao2022retrieval}
Y.~Gao, Q.~Yin, Z.~Li, R.~Meng, T.~Zhao, B.~Yin, I.~King, and M.~Lyu.
\newblock Retrieval-augmented multilingual keyphrase generation with retriever-generator iterative training.
\newblock In {\em Findings of the Association for Computational Linguistics: NAACL 2022}, pages 1233--1246, 2022.

\bibitem{gupta2019amazonqa}
M.~Gupta, N.~Kulkarni, R.~Chanda, A.~Rayasam, and Z.~C. Lipton.
\newblock Amazonqa: A review-based question answering task.
\newblock {\em arXiv preprint arXiv:1908.04364}, 2019.

\bibitem{hendrycks2021measuring}
D.~Hendrycks, C.~Burns, S.~Basart, A.~Zou, M.~Mazeika, D.~Song, and J.~Steinhardt.
\newblock Measuring massive multitask language understanding.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{hou2024bridging}
Y.~Hou, J.~Li, Z.~He, A.~Yan, X.~Chen, and J.~McAuley.
\newblock Bridging language and items for retrieval and recommendation.
\newblock {\em arXiv preprint arXiv:2403.03952}, 2024.

\bibitem{hou2024large}
Y.~Hou, J.~Zhang, Z.~Lin, H.~Lu, R.~Xie, J.~McAuley, and W.~X. Zhao.
\newblock Large language models are zero-shot rankers for recommender systems.
\newblock In {\em European Conference on Information Retrieval}, pages 364--381. Springer, 2024.

\bibitem{Javaheripi_Bubeck_2023}
M.~Javaheripi and S.~Bubeck.
\newblock Phi-2: The surprising power of small language models, Dec 2023.

\bibitem{jiang2023mistral}
A.~Q. Jiang, A.~Sablayrolles, A.~Mensch, C.~Bamford, D.~S. Chaplot, D.~d.~l. Casas, F.~Bressand, G.~Lengyel, G.~Lample, L.~Saulnier, et~al.
\newblock Mistral 7b.
\newblock {\em arXiv preprint arXiv:2310.06825}, 2023.

\bibitem{jiang2022short}
H.~Jiang, T.~Cao, Z.~Li, C.~Luo, X.~Tang, Q.~Yin, D.~Zhang, R.~Goutam, and B.~Yin.
\newblock Short text pre-training with extended token classification for e-commerce query understanding.
\newblock {\em arXiv preprint arXiv:2210.03915}, 2022.

\bibitem{jin2023amazon}
W.~Jin, H.~Mao, Z.~Li, H.~Jiang, C.~Luo, H.~Wen, H.~Han, H.~Lu, Z.~Wang, R.~Li, et~al.
\newblock Amazon-m2: A multilingual multi-locale shopping session dataset for recommendation and text generation.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2023.

\bibitem{kasneci2023chatgpt}
E.~Kasneci, K.~Se{\ss}ler, S.~K{\"u}chemann, M.~Bannert, D.~Dementieva, F.~Fischer, U.~Gasser, G.~Groh, S.~G{\"u}nnemann, E.~H{\"u}llermeier, et~al.
\newblock Chatgpt for good? on opportunities and challenges of large language models for education.
\newblock {\em Learning and individual differences}, 103:102274, 2023.

\bibitem{li2023text}
J.~Li, M.~Wang, J.~Li, J.~Fu, X.~Shen, J.~Shang, and J.~McAuley.
\newblock Text is all you need: Learning language representations for sequential recommendation.
\newblock In {\em Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining}, pages 1258--1267, 2023.

\bibitem{li2022query}
S.~Li, F.~Lv, T.~Jin, G.~Li, Y.~Zheng, T.~Zhuang, Q.~Liu, X.~Zeng, J.~Kwok, and Q.~Ma.
\newblock Query rewriting in taobao search.
\newblock In {\em Proceedings of the 31st ACM International Conference on Information \& Knowledge Management}, pages 3262--3271, 2022.

\bibitem{li2024ecomgpt}
Y.~Li, S.~Ma, X.~Wang, S.~Huang, C.~Jiang, H.-T. Zheng, P.~Xie, F.~Huang, and Y.~Jiang.
\newblock Ecomgpt: Instruction-tuning large language models with chain-of-task tasks for e-commerce.
\newblock In {\em Proceedings of the AAAI Conference on Artificial Intelligence}, volume~38, pages 18582--18590, 2024.

\bibitem{liang2023holistic}
P.~Liang, R.~Bommasani, T.~Lee, D.~Tsipras, D.~Soylu, M.~Yasunaga, Y.~Zhang, D.~Narayanan, Y.~Wu, A.~Kumar, et~al.
\newblock Holistic evaluation of language models.
\newblock {\em Transactions on Machine Learning Research}, 2023.

\bibitem{lin2004rouge}
C.-Y. Lin.
\newblock Rouge: A package for automatic evaluation of summaries.
\newblock In {\em Text summarization branches out}, pages 74--81, 2004.

\bibitem{lin2022truthfulqa}
S.~Lin, J.~Hilton, and O.~Evans.
\newblock Truthfulqa: Measuring how models mimic human falsehoods, 2022.

\bibitem{liu2023enhancing}
X.~Liu, Z.~Li, Y.~Gao, J.~Yang, T.~Cao, Z.~Wang, B.~Yin, and Y.~Song.
\newblock Enhancing user intent capture in session-based recommendation with attribute patterns.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2023.

\bibitem{luo2022query}
C.~Luo, W.~Headden, N.~Avudaiappan, H.~Jiang, T.~Cao, Q.~Yin, Y.~Gao, Z.~Li, R.~Goutam, H.~Zhang, et~al.
\newblock Query attribute recommendation at amazon search.
\newblock In {\em Proceedings of the 16th ACM Conference on Recommender Systems}, pages 506--508, 2022.

\bibitem{meta-ai-research-2024}
Meta-AI-Research.
\newblock {Introducing Meta Llama 3: The most capable openly available LLM to date}, 4 2024.

\bibitem{ni2019justifying}
J.~Ni, J.~Li, and J.~McAuley.
\newblock Justifying recommendations using distantly-labeled reviews and fine-grained aspects.
\newblock In {\em Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing (EMNLP-IJCNLP)}, pages 188--197, 2019.

\bibitem{ni2017estimating}
J.~Ni, Z.~C. Lipton, S.~Vikram, and J.~McAuley.
\newblock Estimating reactions and recommending products with generative models of reviews.
\newblock In {\em Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers)}, pages 783--791, 2017.

\bibitem{papineni2002bleu}
K.~Papineni, S.~Roukos, T.~Ward, and W.-J. Zhu.
\newblock Bleu: a method for automatic evaluation of machine translation.
\newblock In {\em Proceedings of the 40th annual meeting of the Association for Computational Linguistics}, pages 311--318, 2002.

\bibitem{peng2024ecellm}
B.~Peng, X.~Ling, Z.~Chen, H.~Sun, and X.~Ning.
\newblock ecellm: Generalizing large language models for e-commerce from large-scale, high-quality instruction data.
\newblock {\em arXiv preprint arXiv:2402.08831}, 2024.

\bibitem{post2018call}
M.~Post.
\newblock A call for clarity in reporting bleu scores.
\newblock {\em arXiv preprint arXiv:1804.08771}, 2018.

\bibitem{raffel2020exploring}
C.~Raffel, N.~Shazeer, A.~Roberts, K.~Lee, S.~Narang, M.~Matena, Y.~Zhou, W.~Li, and P.~J. Liu.
\newblock Exploring the limits of transfer learning with a unified text-to-text transformer.
\newblock {\em Journal of machine learning research}, 21(140):1--67, 2020.

\bibitem{reddy2022shopping}
C.~K. Reddy, L.~M{\`a}rquez, F.~Valero, N.~Rao, H.~Zaragoza, S.~Bandyopadhyay, A.~Biswas, A.~Xing, and K.~Subbian.
\newblock Shopping queries dataset: A large-scale esci benchmark for improving product search.
\newblock {\em arXiv preprint arXiv:2206.06588}, 2022.

\bibitem{reimers2019sentence}
N.~Reimers and I.~Gurevych.
\newblock Sentence-bert: Sentence embeddings using siamese bert-networks.
\newblock In {\em Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)}, pages 3982--3992, 2019.

\bibitem{roziere2023code}
B.~Roziere, J.~Gehring, F.~Gloeckle, S.~Sootla, I.~Gat, X.~E. Tan, Y.~Adi, J.~Liu, T.~Remez, J.~Rapin, et~al.
\newblock Code llama: Open foundation models for code.
\newblock {\em arXiv preprint arXiv:2308.12950}, 2023.

\bibitem{winogrande}
K.~Sakaguchi, R.~L. Bras, C.~Bhagavatula, and Y.~Choi.
\newblock {WINOGRANDE:} an adversarial winograd schema challenge at scale, 2019.

\bibitem{touvron2023llama}
H.~Touvron, L.~Martin, K.~Stone, P.~Albert, A.~Almahairi, Y.~Babaei, N.~Bashlykov, S.~Batra, P.~Bhargava, S.~Bhosale, et~al.
\newblock Llama 2: Open foundation and fine-tuned chat models.
\newblock {\em arXiv preprint arXiv:2307.09288}, 2023.

\bibitem{wang2020learning}
Q.~Wang, L.~Yang, B.~Kanagal, S.~Sanghai, D.~Sivakumar, B.~Shu, Z.~Yu, and J.~Elsas.
\newblock Learning to extract attribute value from product via question answering: A multi-task approach.
\newblock In {\em Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery \& data mining}, pages 47--55, 2020.

\bibitem{wang2023gpt}
S.~Wang, X.~Sun, X.~Li, R.~Ouyang, F.~Wu, T.~Zhang, J.~Li, and G.~Wang.
\newblock Gpt-ner: Named entity recognition via large language models.
\newblock {\em arXiv preprint arXiv:2304.10428}, 2023.

\bibitem{wei2021finetuned}
J.~Wei, M.~Bosma, V.~Y. Zhao, K.~Guu, A.~W. Yu, B.~Lester, N.~Du, A.~M. Dai, and Q.~V. Le.
\newblock Finetuned language models are zero-shot learners.
\newblock {\em arXiv preprint arXiv:2109.01652}, 2021.

\bibitem{wei2022chain}
J.~Wei, X.~Wang, D.~Schuurmans, M.~Bosma, F.~Xia, E.~Chi, Q.~V. Le, D.~Zhou, et~al.
\newblock Chain-of-thought prompting elicits reasoning in large language models.
\newblock {\em Advances in neural information processing systems}, 35:24824--24837, 2022.

\bibitem{wei2024llmrec}
W.~Wei, X.~Ren, J.~Tang, Q.~Wang, L.~Su, S.~Cheng, J.~Wang, D.~Yin, and C.~Huang.
\newblock Llmrec: Large language models with graph augmentation for recommendation.
\newblock In {\em Proceedings of the 17th ACM International Conference on Web Search and Data Mining}, pages 806--815, 2024.

\bibitem{west2022symbolic}
P.~West, C.~Bhagavatula, J.~Hessel, J.~Hwang, L.~Jiang, R.~Le~Bras, X.~Lu, S.~Welleck, and Y.~Choi.
\newblock Symbolic knowledge distillation: from general language models to commonsense models.
\newblock In {\em Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies}, pages 4602--4625, 2022.

\bibitem{wu2022some}
F.~Wu, Y.~Liu, R.~Gazo, B.~Bedrich, and X.~Qu.
\newblock Some practice for improving the search results of e-commerce.
\newblock {\em arXiv preprint arXiv:2208.00108}, 2022.

\bibitem{wu2019session}
S.~Wu, Y.~Tang, Y.~Zhu, L.~Wang, X.~Xie, and T.~Tan.
\newblock Session-based recommendation with graph neural networks.
\newblock In {\em Proceedings of the AAAI conference on artificial intelligence}, volume~33, pages 346--353, 2019.

\bibitem{xu2021tacc}
K.~Xu, X.~Wan, H.~Wang, Z.~Ren, X.~Liao, D.~Sun, C.~Zeng, and K.~Chen.
\newblock Tacc: A full-stack cloud computing infrastructure for machine learning tasks.
\newblock {\em arXiv preprint arXiv:2110.01556}, 2021.

\bibitem{YangL2022}
H.~Yang and K.~Li.
\newblock Pyabsa: Open framework for aspect-based sentiment analysis, 2022.

\bibitem{yang2022mave}
L.~Yang, Q.~Wang, Z.~Yu, A.~Kulkarni, S.~Sanghai, B.~Shu, J.~Elsas, and B.~Kanagal.
\newblock Mave: A product dataset for multi-source attribute value extraction.
\newblock In {\em Proceedings of the fifteenth ACM international conference on web search and data mining}, pages 1256--1265, 2022.

\bibitem{yao2022webshop}
S.~Yao, H.~Chen, J.~Yang, and K.~Narasimhan.
\newblock Webshop: Towards scalable real-world web interaction with grounded language agents.
\newblock {\em Advances in Neural Information Processing Systems}, 35:20744--20757, 2022.

\bibitem{zellers2019hellaswag}
R.~Zellers, A.~Holtzman, Y.~Bisk, A.~Farhadi, and Y.~Choi.
\newblock Hellaswag: Can a machine really finish your sentence?, 2019.

\bibitem{zhang2019bertscore}
T.~Zhang, V.~Kishore, F.~Wu, K.~Q. Weinberger, and Y.~Artzi.
\newblock Bertscore: Evaluating text generation with bert.
\newblock {\em arXiv preprint arXiv:1904.09675}, 2019.

\bibitem{zhang2021survey}
Y.~Zhang and Q.~Yang.
\newblock A survey on multi-task learning.
\newblock {\em IEEE Transactions on Knowledge and Data Engineering}, 34(12):5586--5609, 2021.

\bibitem{zheng2018opentag}
G.~Zheng, S.~Mukherjee, X.~L. Dong, and F.~Li.
\newblock Opentag: Open attribute value extraction from product profiles.
\newblock In {\em Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery \& data mining}, pages 1049--1058, 2018.

\bibitem{zhou2023webarena}
S.~Zhou, F.~F. Xu, H.~Zhu, X.~Zhou, R.~Lo, A.~Sridhar, X.~Cheng, T.~Ou, Y.~Bisk, D.~Fried, et~al.
\newblock Webarena: A realistic web environment for building autonomous agents.
\newblock {\em arXiv preprint arXiv:2307.13854}, 2023.

\bibitem{ziems2024can}
C.~Ziems, W.~Held, O.~Shaikh, J.~Chen, Z.~Zhang, and D.~Yang.
\newblock Can large language models transform computational social science?
\newblock {\em Computational Linguistics}, 50(1):237--291, 2024.

\end{thebibliography}
