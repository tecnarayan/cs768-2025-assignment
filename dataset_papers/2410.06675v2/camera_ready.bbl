\begin{thebibliography}{68}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Avila et~al.(2019)Avila, Gamper, Reddy, Cutler, Tashev, and Gehrke]{avila2019non}
Anderson~R Avila, Hannes Gamper, Chandan Reddy, Ross Cutler, Ivan Tashev, and Johannes Gehrke.
\newblock {Non-intrusive speech quality assessment using neural networks}.
\newblock In \emph{International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 631--635. IEEE, 2019.

\bibitem[Baevski et~al.(2020)Baevski, Zhou, Mohamed, and Auli]{baevski2020wav2vec}
Alexei Baevski, Yuhao Zhou, Abdelrahman Mohamed, and Michael Auli.
\newblock {wav2vec 2.0: A framework for self-supervised learning of speech representations}.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 12449--12460, 2020.

\bibitem[Becerra et~al.(2022)Becerra, Ragano, and Hines]{becerra22_interspeech}
Helard Becerra, Alessandro Ragano, and Andrew Hines.
\newblock {Exploring the influence of fine-tuning data on wav2vec 2.0 model for blind speech quality prediction}.
\newblock In \emph{Proc. Interspeech}, pages 4088--4092, 2022.
\newblock \doi{10.21437/Interspeech.2022-10766}.

\bibitem[Beerends et~al.(2013)Beerends, Schmidmer, Berger, Obermann, Ullmann, Pomy, and Keyhl]{beerends2013perceptual}
John~G Beerends, Christian Schmidmer, Jens Berger, Matthias Obermann, Raphael Ullmann, Joachim Pomy, and Michael Keyhl.
\newblock {Perceptual objective listening quality assessment (POLQA), the third generation ITU-T standard for end-to-end speech quality measurement part I — temporal alignment}.
\newblock \emph{Journal of the Audio Engineering Society}, 61\penalty0 (6):\penalty0 366--384, 2013.

\bibitem[Burnham et~al.(2011)Burnham, Estival, Fazio, Viethen, Cox, Dale, Cassidy, Epps, Togneri, Wagner, et~al.]{burnham2011building}
Denis Burnham, Dominique Estival, Steven Fazio, Jette Viethen, Felicity Cox, Robert Dale, Steve Cassidy, Julien Epps, Roberto Togneri, Michael Wagner, et~al.
\newblock {Building an audio-visual corpus of Australian English: large corpus collection with an economical portable and replicable Black Box}.
\newblock In \emph{Proc. Interspeech 2011}, 2011.

\bibitem[Catellier and Voran(2020)]{catellier2020wawenets}
Andrew~A Catellier and Stephen~D Voran.
\newblock {Wawenets: A no-reference convolutional waveform-based approach to estimating narrowband and wideband speech quality}.
\newblock In \emph{International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 331--335. IEEE, 2020.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{chen2020simple}
Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton.
\newblock A simple framework for contrastive learning of visual representations.
\newblock In \emph{International conference on machine learning}, pages 1597--1607. PMLR, 2020.

\bibitem[Chinen et~al.(2020)Chinen, Lim, Skoglund, Gureev, O'Gorman, and Hines]{chinen2020visqol}
Michael Chinen, Felicia~SC Lim, Jan Skoglund, Nikita Gureev, Feargus O'Gorman, and Andrew Hines.
\newblock {ViSQOL v3: An open source production ready objective speech and audio metric}.
\newblock In \emph{2020 Twelfth international conference on quality of multimedia experience (QoMEX)}. IEEE, 2020.

\bibitem[Chung et~al.(2021)Chung, Zhang, Han, Chiu, Qin, Pang, and Wu]{chung2021w2v}
Yu-An Chung, Yu~Zhang, Wei Han, Chung-Cheng Chiu, James Qin, Ruoming Pang, and Yonghui Wu.
\newblock {w2v-bert: Combining contrastive learning and masked language modeling for self-supervised speech pre-training}.
\newblock In \emph{2021 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)}, pages 244--250. IEEE, 2021.

\bibitem[Cooper and Yamagishi(2021)]{cooper21_ssw}
Erica Cooper and Junichi Yamagishi.
\newblock {How do Voices from Past Speech Synthesis Challenges Compare Today?}
\newblock In \emph{Proc. 11th ISCA Speech Synthesis Workshop (SSW 11)}, pages 183--188, 2021.
\newblock \doi{10.21437/SSW.2021-32}.

\bibitem[Demirsahin et~al.(2020)Demirsahin, Kjartansson, Gutkin, and Rivera]{demirsahin2020open}
Isin Demirsahin, Oddur Kjartansson, Alexander Gutkin, and Clara Rivera.
\newblock {Open-source multi-speaker corpora of the English accents in the British isles}.
\newblock In \emph{Proceedings of the Twelfth Language Resources and Evaluation Conference}, pages 6532--6541, 2020.

\bibitem[Dhaini et~al.(2024)Dhaini, Berar, Honeine, and Van~Exem]{dhaini2024contrastive}
Mohamad Dhaini, Maxime Berar, Paul Honeine, and Antonin Van~Exem.
\newblock Contrastive learning for regression on hyperspectral data.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 5080--5084. IEEE, 2024.

\bibitem[Ding et~al.(2015)Ding, Lin, Wang, and Chao]{ding2015deep}
Shengyong Ding, Liang Lin, Guangrun Wang, and Hongyang Chao.
\newblock Deep feature learning with relative distance comparison for person re-identification.
\newblock \emph{Pattern Recognition}, 48\penalty0 (10):\penalty0 2993--3003, 2015.

\bibitem[Fu et~al.(2018)Fu, Tsao, Hwang, and Wang]{Quality-Net}
Szu{-}Wei Fu, Yu~Tsao, Hsin{-}Te Hwang, and Hsin{-}Min Wang.
\newblock Quality-net: An end-to-end non-intrusive speech quality assessment model based on {BLSTM}.
\newblock In \emph{Proc. Interspeech}, pages 1873--1877, 2018.
\newblock \doi{10.21437/Interspeech.2018-1802}.
\newblock URL \url{https://doi.org/10.21437/Interspeech.2018-1802}.

\bibitem[Fu et~al.(2024)Fu, Hung, Tsao, and Wang]{fu2024selfsupervised}
Szu-Wei Fu, Kuo-Hsuan Hung, Yu~Tsao, and Yu-Chiang~Frank Wang.
\newblock Self-supervised speech quality estimation and enhancement using only clean speech.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=ale56Ya59q}.

\bibitem[Ha and Blanz(2021)]{ha2021deep}
Mai~Lan Ha and Volker Blanz.
\newblock Deep ranking with adaptive margin triplet loss.
\newblock \emph{arXiv preprint arXiv:2107.06187}, 2021.

\bibitem[Harte et~al.(2015)Harte, Gillen, and Hines]{harte2015tcd}
Naomi Harte, Eoin Gillen, and Andrew Hines.
\newblock {TCD-VoIP, a research database of degraded speech for assessing quality in VoIP applications}.
\newblock In \emph{2015 Seventh International Workshop on Quality of Multimedia Experience (QoMEX)}, pages 1--6. IEEE, 2015.

\bibitem[Hermans et~al.(2017)Hermans, Beyer, and Leibe]{hermans2017defense}
Alexander Hermans, Lucas Beyer, and Bastian Leibe.
\newblock In defense of the triplet loss for person re-identification.
\newblock \emph{arXiv preprint arXiv:1703.07737}, 2017.

\bibitem[Hines and Harte(2012)]{hines2012speech}
Andrew Hines and Naomi Harte.
\newblock Speech intelligibility prediction using a neurogram similarity index measure.
\newblock \emph{Speech Communication}, 54\penalty0 (2):\penalty0 306--320, 2012.

\bibitem[Hsu et~al.(2021)Hsu, Bolte, Tsai, Lakhotia, Salakhutdinov, and Mohamed]{hsu2021hubert}
Wei-Ning Hsu, Benjamin Bolte, Yao-Hung~Hubert Tsai, Kushal Lakhotia, Ruslan Salakhutdinov, and Abdelrahman Mohamed.
\newblock {HuBERT: Self-supervised speech representation learning by masked prediction of hidden units}.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 29:\penalty0 3451--3460, 2021.

\bibitem[Hu and Loizou(2006)]{hu2006subjective}
Yi~Hu and Philipos~C Loizou.
\newblock Subjective comparison of speech enhancement algorithms.
\newblock In \emph{2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings}, volume~1, pages I--I. IEEE, 2006.

\bibitem[Huang et~al.(2022)Huang, Cooper, Tsao, Wang, Toda, and Yamagishi]{huang22f_interspeech}
Wen~Chin Huang, Erica Cooper, Yu~Tsao, Hsin-Min Wang, Tomoki Toda, and Junichi Yamagishi.
\newblock {The VoiceMOS Challenge 2022}.
\newblock In \emph{Proc. Interspeech 2022}, pages 4536--4540, 2022.
\newblock \doi{10.21437/Interspeech.2022-970}.

\bibitem[ITU-TP(2016)]{pesqwb}
ITU-T~Recommendation ITU-TP.
\newblock P.862.2: Wideband extension to recommendation p.862 for the assessment of wideband telephone networks and speech codecs,.
\newblock Technical report, Tech. rep, 2016.

\bibitem[Jiang et~al.(2021)Jiang, Li, Cao, Zou, and Li]{jiang21_interspeech}
Dongwei Jiang, Wubo Li, Miao Cao, Wei Zou, and Xiangang Li.
\newblock {Speech SimCLR: Combining Contrastive and Reconstruction Objective for Self-Supervised Speech Representation Learning}.
\newblock In \emph{Proc. Interspeech 2021}, pages 1544--1548, 2021.
\newblock \doi{10.21437/Interspeech.2021-391}.

\bibitem[Kabal(2002)]{kabal2002tsp}
Peter Kabal.
\newblock Tsp speech database.
\newblock \emph{McGill University, Database Version}, 1\penalty0 (0):\penalty0 09--02, 2002.

\bibitem[Kang et~al.(2020)Kang, Li, Xie, Yuan, and Feng]{kang2020exploring}
Bingyi Kang, Yu~Li, Sa~Xie, Zehuan Yuan, and Jiashi Feng.
\newblock Exploring balanced feature spaces for representation learning.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Karthik et~al.(2021)Karthik, Wu, Goodman, and Tamkin]{karthik2021tradeoffs}
Ananya Karthik, Mike Wu, Noah Goodman, and Alex Tamkin.
\newblock {Tradeoffs between contrastive and supervised learning: An empirical study}.
\newblock \emph{arXiv preprint arXiv:2112.05340}, 2021.

\bibitem[Khosla et~al.(2020)Khosla, Teterwak, Wang, Sarna, Tian, Isola, Maschinot, Liu, and Krishnan]{khosla2020supervised}
Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip Isola, Aaron Maschinot, Ce~Liu, and Dilip Krishnan.
\newblock Supervised contrastive learning.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 18661--18673, 2020.

\bibitem[Kim and Tarraf(2007)]{kim2007anique+}
Doh-Suk Kim and Ahmed Tarraf.
\newblock {ANIQUE+: A new American national standard for non-intrusive estimation of narrowband speech quality}.
\newblock \emph{Bell Labs Technical Journal}, 12\penalty0 (1):\penalty0 221--236, 2007.

\bibitem[Kumar et~al.(2023)Kumar, Tan, Ni, Manocha, Zhang, Henderson, and Xu]{kumar2023torchaudio}
Anurag Kumar, Ke~Tan, Zhaoheng Ni, Pranay Manocha, Xiaohui Zhang, Ethan Henderson, and Buye Xu.
\newblock Torchaudio-squim: Reference-less speech quality and intelligibility measures in torchaudio.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 1--5. IEEE, 2023.

\bibitem[Lawless and Heymann(2010)]{lawless2010sensory}
Harry~T Lawless and Hildegarde Heymann.
\newblock \emph{{Sensory evaluation of food: principles and practices}}, volume~2.
\newblock Springer, 2010.

\bibitem[Le-Khac et~al.(2020)Le-Khac, Healy, and Smeaton]{le2020contrastive}
Phuc~H Le-Khac, Graham Healy, and Alan~F Smeaton.
\newblock Contrastive representation learning: A framework and review.
\newblock \emph{IEEE Access}, 8:\penalty0 193907--193934, 2020.

\bibitem[Le~Roux et~al.(2019)Le~Roux, Wisdom, Erdogan, and Hershey]{le2019sdr}
Jonathan Le~Roux, Scott Wisdom, Hakan Erdogan, and John~R Hershey.
\newblock Sdr--half-baked or well done?
\newblock In \emph{IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 626--630. IEEE, 2019.

\bibitem[Li et~al.(2021)Li, Zhou, Xiong, and Hoi]{PCL}
Junnan Li, Pan Zhou, Caiming Xiong, and Steven C.~H. Hoi.
\newblock Prototypical contrastive learning of unsupervised representations.
\newblock In \emph{9th International Conference on Learning Representations, {ICLR} 2021, Virtual Event, Austria, May 3-7, 2021}. OpenReview.net, 2021.
\newblock URL \url{https://openreview.net/forum?id=KmykpuSrjcq}.

\bibitem[Li et~al.(2022)Li, Xia, Ge, and Liu]{li2022selective}
Shikun Li, Xiaobo Xia, Shiming Ge, and Tongliang Liu.
\newblock Selective-supervised contrastive learning with noisy labels.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 316--325, 2022.

\bibitem[Lu et~al.(2022)Lu, Wang, Watanabe, Richard, Yu, and Tsao]{lu2022conditional}
Yen-Ju Lu, Zhong-Qiu Wang, Shinji Watanabe, Alexander Richard, Cheng Yu, and Yu~Tsao.
\newblock Conditional diffusion probabilistic model for speech enhancement.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 7402--7406. IEEE, 2022.

\bibitem[Maiti et~al.(2023)Maiti, Peng, Saeki, and Watanabe]{maiti}
Soumi Maiti, Yifan Peng, Takaaki Saeki, and Shinji Watanabe.
\newblock {SpeechLMScore: Evaluating Speech Generation Using Speech Language Model}.
\newblock In \emph{International Conference on Acoustics, Speech and Signal Processing (ICASSP), IEEE}, 2023.
\newblock \doi{10.1109/ICASSP49357.2023.10095710}.

\bibitem[Malfait et~al.(2006)Malfait, Berger, and Kastner]{malfait2006p}
Ludovic Malfait, Jens Berger, and Martin Kastner.
\newblock {P. 563—The ITU-T standard for single-ended speech quality assessment}.
\newblock \emph{IEEE Transactions on Audio, Speech, and Language Processing}, 14\penalty0 (6):\penalty0 1924--1934, 2006.

\bibitem[Manocha and Kumar(2022)]{manocha22c_interspeech}
Pranay Manocha and Anurag Kumar.
\newblock {Speech Quality Assessment through MOS using Non-Matching References}.
\newblock In \emph{Proc. Interspeech 2022}, pages 654--658, 2022.
\newblock \doi{10.21437/Interspeech.2022-407}.

\bibitem[Manocha et~al.(2021{\natexlab{a}})Manocha, Jin, Zhang, and Finkelstein]{manocha2021cdpam}
Pranay Manocha, Zeyu Jin, Richard Zhang, and Adam Finkelstein.
\newblock {CDPAM: Contrastive learning for perceptual audio similarity}.
\newblock In \emph{International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 196--200. IEEE, 2021{\natexlab{a}}.

\bibitem[Manocha et~al.(2021{\natexlab{b}})Manocha, Xu, and Kumar]{manocha2021noresqa}
Pranay Manocha, Buye Xu, and Anurag Kumar.
\newblock {NORESQA: A framework for speech quality assessment using non-matching references}.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 22363--22378, 2021{\natexlab{b}}.

\bibitem[Milde and Biemann(2018)]{milde18_interspeech}
Benjamin Milde and Chris Biemann.
\newblock {Unspeech: Unsupervised Speech Context Embeddings}.
\newblock In \emph{Proc. Interspeech 2018}, pages 2693--2697, 2018.
\newblock \doi{10.21437/Interspeech.2018-2194}.

\bibitem[Mittag et~al.(2021)Mittag, Naderi, Chehadi, and Möller]{mittag21_interspeech}
Gabriel Mittag, Babak Naderi, Assmaa Chehadi, and Sebastian Möller.
\newblock {NISQA: A Deep CNN-Self-Attention Model for Multidimensional Speech Quality Prediction with Crowdsourced Datasets}.
\newblock In \emph{Proc. Interspeech 2021}, pages 2127--2131, 2021.
\newblock \doi{10.21437/Interspeech.2021-299}.

\bibitem[Mohamed et~al.(2022)Mohamed, Lee, Borgholt, Havtorn, Edin, Igel, Kirchhoff, Li, Livescu, Maal{\o}e, et~al.]{mohamed2022self}
Abdelrahman Mohamed, Hung-yi Lee, Lasse Borgholt, Jakob~D Havtorn, Joakim Edin, Christian Igel, Katrin Kirchhoff, Shang-Wen Li, Karen Livescu, Lars Maal{\o}e, et~al.
\newblock Self-supervised speech representation learning: A review.
\newblock \emph{IEEE Journal of Selected Topics in Signal Processing}, 16\penalty0 (6):\penalty0 1179--1210, 2022.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{oord2018representation}
Aaron van~den Oord, Yazhe Li, and Oriol Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Ott(2019)]{ott2019fairseq}
M~Ott.
\newblock fairseq: A fast, extensible toolkit for sequence modeling.
\newblock \emph{arXiv preprint arXiv:1904.01038}, 2019.

\bibitem[Panayotov et~al.(2015)Panayotov, Chen, Povey, and Khudanpur]{panayotov2015librispeech}
Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur.
\newblock Librispeech: an asr corpus based on public domain audio books.
\newblock In \emph{2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 5206--5210. IEEE, 2015.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan, Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Popov et~al.(2021)Popov, Vovk, Gogoryan, Sadekova, and Kudinov]{popov2021grad}
Vadim Popov, Ivan Vovk, Vladimir Gogoryan, Tasnima Sadekova, and Mikhail Kudinov.
\newblock Grad-tts: A diffusion probabilistic model for text-to-speech.
\newblock In \emph{International Conference on Machine Learning}, pages 8599--8608. PMLR, 2021.

\bibitem[Ragano et~al.(2021)Ragano, Benetos, and Hines]{ragano2021more}
Alessandro Ragano, Emmanouil Benetos, and Andrew Hines.
\newblock {More for less: Non-intrusive speech quality assessment with limited annotations}.
\newblock In \emph{2021 13th International Conference on Quality of Multimedia Experience (QoMEX)}, pages 103--108. IEEE, 2021.

\bibitem[Ragano et~al.(2024)Ragano, Skoglund, and Hines]{ragano2024nomad}
Alessandro Ragano, Jan Skoglund, and Andrew Hines.
\newblock {NOMAD: Unsupervised Learning of Perceptual Embeddings For Speech Enhancement and Non-Matching Reference Audio Quality Assessment}.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 1011--1015. IEEE, 2024.

\bibitem[Reddy et~al.(2020)Reddy, Gopal, Cutler, Beyrami, Cheng, Dubey, Matusevych, Aichner, Aazami, Braun, Rana, Srinivasan, and Gehrke]{reddy20_interspeech}
Chandan~K.A. Reddy, Vishak Gopal, Ross Cutler, Ebrahim Beyrami, Roger Cheng, Harishchandra Dubey, Sergiy Matusevych, Robert Aichner, Ashkan Aazami, Sebastian Braun, Puneet Rana, Sriram Srinivasan, and Johannes Gehrke.
\newblock {The INTERSPEECH 2020 Deep Noise Suppression Challenge: Datasets, Subjective Testing Framework, and Challenge Results}.
\newblock In \emph{Proc. Interspeech 2020}, pages 2492--2496, 2020.
\newblock \doi{10.21437/Interspeech.2020-3038}.

\bibitem[Reddy et~al.(2021)Reddy, Gopal, and Cutler]{reddy2021dnsmos}
Chandan~KA Reddy, Vishak Gopal, and Ross Cutler.
\newblock {DNSMOS}: A non-intrusive perceptual objective speech quality metric to evaluate noise suppressors.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 6493--6497. IEEE, 2021.

\bibitem[Rix et~al.(2001)Rix, Beerends, Hollier, and Hekstra]{rix2001perceptual}
Antony~W Rix, John~G Beerends, Michael~P Hollier, and Andries~P Hekstra.
\newblock {Perceptual evaluation of speech quality (PESQ)-a new method for speech quality assessment of telephone networks and codecs}.
\newblock In \emph{IEEE international conference on acoustics, speech, and signal processing. Proceedings}, volume~2, pages 749--752. IEEE, 2001.

\bibitem[Schroff et~al.(2015)Schroff, Kalenichenko, and Philbin]{schroff2015facenet}
Florian Schroff, Dmitry Kalenichenko, and James Philbin.
\newblock Facenet: A unified embedding for face recognition and clustering.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 815--823, 2015.

\bibitem[Serr{\`a} et~al.(2021)Serr{\`a}, Pons, and Pascual]{serra2021sesqa}
Joan Serr{\`a}, Jordi Pons, and Santiago Pascual.
\newblock {SESQA: semi-supervised learning for speech quality assessment}.
\newblock In \emph{International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 381--385. IEEE, 2021.

\bibitem[Tan and Wang(2019)]{tan2019learning}
Ke~Tan and DeLiang Wang.
\newblock Learning complex spectral mapping with gated convolutional recurrent networks for monaural speech enhancement.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 28:\penalty0 380--390, 2019.

\bibitem[Tian et~al.(2020)Tian, Sun, Poole, Krishnan, Schmid, and Isola]{tian2020makes}
Yonglong Tian, Chen Sun, Ben Poole, Dilip Krishnan, Cordelia Schmid, and Phillip Isola.
\newblock What makes for good views for contrastive learning?
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 6827--6839, 2020.

\bibitem[Tseng et~al.(2021)Tseng, yu~Huang, Kao, Lin, and yi~Lee]{tseng21b_interspeech}
Wei-Cheng Tseng, Chien yu~Huang, Wei-Tsung Kao, Yist~Y. Lin, and Hung yi~Lee.
\newblock {Utilizing Self-Supervised Representations for MOS Prediction}.
\newblock In \emph{Proc. Interspeech 2021}, pages 2781--2785, 2021.
\newblock \doi{10.21437/Interspeech.2021-2013}.

\bibitem[Union(1998)]{ITUT1998}
International~Telecommunication Union.
\newblock {ITU-T P. Supplement 23 coded-speech database}, 1998.

\bibitem[Wang et~al.(2022)Wang, Jiang, Li, Ni, Dai, Li, Xiong, and Li]{wang2022contrastive}
Yaoming Wang, Yangzhou Jiang, Jin Li, Bingbing Ni, Wenrui Dai, Chenglin Li, Hongkai Xiong, and Teng Li.
\newblock Contrastive regression for domain adaptation on gaze estimation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 19376--19385, 2022.

\bibitem[Yang et~al.(2022)Yang, Hira, Ni, Astafurov, Chen, Puhrsch, Pollack, Genzel, Greenberg, Yang, et~al.]{yang2022torchaudio}
Yao-Yuan Yang, Moto Hira, Zhaoheng Ni, Artyom Astafurov, Caroline Chen, Christian Puhrsch, David Pollack, Dmitriy Genzel, Donny Greenberg, Edward~Z Yang, et~al.
\newblock Torchaudio: Building blocks for audio and speech processing.
\newblock In \emph{IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, pages 6982--6986. IEEE, 2022.

\bibitem[Yi et~al.(2022)Yi, Xiao, Xiao, Naderi, Möller, Wardah, Mittag, Culter, Zhang, Williamson, Chen, Yang, and Shang]{yi22b_interspeech}
Gaoxiong Yi, Wei Xiao, Yiming Xiao, Babak Naderi, Sebastian Möller, Wafaa Wardah, Gabriel Mittag, Ross Culter, Zhuohuang Zhang, Donald~S. Williamson, Fei Chen, Fuzheng Yang, and Shidong Shang.
\newblock {ConferencingSpeech 2022 Challenge: Non-intrusive Objective Speech Quality Assessment (NISQA) Challenge for Online Conferencing Applications}.
\newblock In \emph{Proc. Interspeech 2022}, pages 3308--3312, 2022.
\newblock \doi{10.21437/Interspeech.2022-10597}.

\bibitem[Zeghidour et~al.(2021)Zeghidour, Luebs, Omran, Skoglund, and Tagliasacchi]{zeghidour2021soundstream}
Neil Zeghidour, Alejandro Luebs, Ahmed Omran, Jan Skoglund, and Marco Tagliasacchi.
\newblock Soundstream: An end-to-end neural audio codec.
\newblock \emph{IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 30:\penalty0 495--507, 2021.

\bibitem[Zeng et~al.(2021)Zeng, He, Yan, Liu, Wu, Xu, Jiang, and Xu]{zeng2021modeling}
Zhiyuan Zeng, Keqing He, Yuanmeng Yan, Zijun Liu, Yanan Wu, Hong Xu, Huixing Jiang, and Weiran Xu.
\newblock Modeling discriminative representations for out-of-domain detection with supervised contrastive learning.
\newblock In \emph{Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)}, pages 870--878, 2021.

\bibitem[Zha et~al.(2024)Zha, Cao, Son, Yang, and Katabi]{zha2024rank}
Kaiwen Zha, Peng Cao, Jeany Son, Yuzhe Yang, and Dina Katabi.
\newblock {Rank-N-Contrast: Learning Continuous Representations for Regression}.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Zhang et~al.(2023)Zhang, Yang, Mi, Zheng, and Yao]{ordinalregression}
Shihao Zhang, Linlin Yang, Michael~Bi Mi, Xiaoxu Zheng, and Angela Yao.
\newblock Improving deep regression with ordinal entropy.
\newblock In \emph{The Eleventh International Conference on Learning Representations, {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023}. OpenReview.net, 2023.

\bibitem[Zhong et~al.(2022)Zhong, Tang, Chen, Peng, and Wang]{zhong2022self}
Y~Zhong, H~Tang, J~Chen, J~Peng, and Y-X Wang.
\newblock Is self-supervised learning more robust than supervised learning?
\newblock In \emph{Proc ICML Workshop on Pre-training}, 2022.

\end{thebibliography}
