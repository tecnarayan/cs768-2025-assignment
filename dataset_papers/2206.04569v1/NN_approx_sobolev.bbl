\begin{thebibliography}{62}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi
\expandafter\ifx\csname url\endcsname\relax
  \def\url#1{\texttt{#1}}\fi
\expandafter\ifx\csname urlprefix\endcsname\relax\def\urlprefix{}\fi

\bibitem[{Allard et~al.(2012)Allard, Chen and Maggioni}]{allard2012multi}
\textsc{Allard, W.~K.}, \textsc{Chen, G.} and \textsc{Maggioni, M.} (2012).
\newblock Multi-scale geometric methods for data sets ii: Geometric
  multi-resolution analysis.
\newblock \textit{Appl. Comput. Harmon. Anal.}, \textbf{32} 435--462.

\bibitem[{Barron(1993)}]{barron1993universal}
\textsc{Barron, A.~R.} (1993).
\newblock Universal approximation bounds for superpositions of a sigmoidal
  function.
\newblock \textit{IEEE Trans. Inform. Theory}, \textbf{39} 930--945.

\bibitem[{Brenner et~al.(2008)Brenner, Scott and
  Scott}]{brenner2008mathematical}
\textsc{Brenner, S.~C.}, \textsc{Scott, L.~R.} and \textsc{Scott, L.~R.}
  (2008).
\newblock \textit{The mathematical theory of finite element methods}, vol.~3.
\newblock Springer.

\bibitem[{Brezis and Br{\'e}zis(2011)}]{brezis2011functional}
\textsc{Brezis, H.} and \textsc{Br{\'e}zis, H.} (2011).
\newblock \textit{Functional analysis, Sobolev spaces and partial differential
  equations}, vol.~2.
\newblock Springer.

\bibitem[{Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell et~al.}]{brown2020language}
\textsc{Brown, T.~B.}, \textsc{Mann, B.}, \textsc{Ryder, N.}, \textsc{Subbiah,
  M.}, \textsc{Kaplan, J.}, \textsc{Dhariwal, P.}, \textsc{Neelakantan, A.},
  \textsc{Shyam, P.}, \textsc{Sastry, G.}, \textsc{Askell, A.} \textsc{et~al.}
  (2020).
\newblock Language models are few-shot learners.
\newblock \textit{arXiv preprint arXiv:2005.14165}.

\bibitem[{Bubeck and Sellke(2021)}]{bubeck2021universal}
\textsc{Bubeck, S.} and \textsc{Sellke, M.} (2021).
\newblock A universal law of robustness via isoperimetry.
\newblock \textit{arXiv preprint arXiv:2105.12806}.

\bibitem[{Cardaliaguet and Euvrard(1992)}]{cardaliaguet1992approximation}
\textsc{Cardaliaguet, P.} and \textsc{Euvrard, G.} (1992).
\newblock Approximation of a function and its derivative with a neural network.
\newblock \textit{Neural networks}, \textbf{5} 207--220.

\bibitem[{Chen et~al.(2019{\natexlab{a}})Chen, Jiang, Liao and
  Zhao}]{chen2019efficient}
\textsc{Chen, M.}, \textsc{Jiang, H.}, \textsc{Liao, W.} and \textsc{Zhao, T.}
  (2019{\natexlab{a}}).
\newblock Efficient approximation of deep relu networks for functions on low
  dimensional manifolds.
\newblock \textit{Advances in neural information processing systems},
  \textbf{32} 8174--8184.

\bibitem[{Chen et~al.(2019{\natexlab{b}})Chen, Jiang, Liao and
  Zhao}]{chen2019nonparametric}
\textsc{Chen, M.}, \textsc{Jiang, H.}, \textsc{Liao, W.} and \textsc{Zhao, T.}
  (2019{\natexlab{b}}).
\newblock Nonparametric regression on low-dimensional manifolds using deep relu
  networks.
\newblock \textit{arXiv preprint arXiv:1908.01842}.

\bibitem[{Chen et~al.(2020)Chen, Liu, Liao and Zhao}]{chen2020doubly}
\textsc{Chen, M.}, \textsc{Liu, H.}, \textsc{Liao, W.} and \textsc{Zhao, T.}
  (2020).
\newblock Doubly robust off-policy learning on low-dimensional manifolds by
  deep neural networks.
\newblock \textit{arXiv preprint arXiv:2011.01797}.

\bibitem[{Chui and Li(1992)}]{chui1992approximation}
\textsc{Chui, C.~K.} and \textsc{Li, X.} (1992).
\newblock Approximation by ridge functions and neural networks with one hidden
  layer.
\newblock \textit{J. Approx. Theory}, \textbf{70} 131--141.

\bibitem[{Chui and Mhaskar(2018)}]{chui2018deep}
\textsc{Chui, C.~K.} and \textsc{Mhaskar, H.~N.} (2018).
\newblock Deep nets for local manifold learning.
\newblock \textit{Frontiers in Applied Mathematics and Statistics}, \textbf{4}
  12.

\bibitem[{Cloninger and Klock(2020)}]{cloninger2020relu}
\textsc{Cloninger, A.} and \textsc{Klock, T.} (2020).
\newblock Relu nets adapt to intrinsic dimensionality beyond the target domain.
\newblock \textit{arXiv e-prints} arXiv--2008.

\bibitem[{Coifman et~al.(2005)Coifman, Lafon, Lee, Maggioni, Nadler, Warner and
  Zucker}]{coifman2005geometric}
\textsc{Coifman, R.~R.}, \textsc{Lafon, S.}, \textsc{Lee, A.~B.},
  \textsc{Maggioni, M.}, \textsc{Nadler, B.}, \textsc{Warner, F.} and
  \textsc{Zucker, S.~W.} (2005).
\newblock Geometric diffusions as a tool for harmonic analysis and structure
  definition of data: Diffusion maps.
\newblock \textit{Proc. Natl. Acad. Sci.}, \textbf{102} 7426--7431.

\bibitem[{Conway and Sloane(1988)}]{conwaysphere}
\textsc{Conway, J.} and \textsc{Sloane, N.} (1988).
\newblock Sphere packings, lattices and groups.

\bibitem[{Cybenko(1989)}]{cybenko1989approximation}
\textsc{Cybenko, G.} (1989).
\newblock Approximation by superpositions of a sigmoidal function.
\newblock \textit{Math. Control Signals Systems}, \textbf{2} 303--314.

\bibitem[{Devlin et~al.(2018)Devlin, Chang, Lee and Toutanova}]{devlin2018bert}
\textsc{Devlin, J.}, \textsc{Chang, M.-W.}, \textsc{Lee, K.} and
  \textsc{Toutanova, K.} (2018).
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \textit{arXiv preprint arXiv:1810.04805}.

\bibitem[{Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn,
  Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly
  et~al.}]{dosovitskiy2020image}
\textsc{Dosovitskiy, A.}, \textsc{Beyer, L.}, \textsc{Kolesnikov, A.},
  \textsc{Weissenborn, D.}, \textsc{Zhai, X.}, \textsc{Unterthiner, T.},
  \textsc{Dehghani, M.}, \textsc{Minderer, M.}, \textsc{Heigold, G.},
  \textsc{Gelly, S.} \textsc{et~al.} (2020).
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \textit{arXiv preprint arXiv:2010.11929}.

\bibitem[{Driver(2003)}]{driver2003analysis}
\textsc{Driver, B.~K.} (2003).
\newblock Analysis tools with applications.
\newblock \textit{Lecture notes}.

\bibitem[{Federer(1959)}]{federer1959curvature}
\textsc{Federer, H.} (1959).
\newblock Curvature measures.
\newblock \textit{Transactions of the American Mathematical Society},
  \textbf{93} 418--491.

\bibitem[{Funahashi(1989)}]{funahashi1989approximate}
\textsc{Funahashi, K.-I.} (1989).
\newblock On the approximate realization of continuous mappings by neural
  networks.
\newblock \textit{Neural networks}, \textbf{2} 183--192.

\bibitem[{Goodfellow et~al.(2014)Goodfellow, Shlens and
  Szegedy}]{goodfellow2014explaining}
\textsc{Goodfellow, I.~J.}, \textsc{Shlens, J.} and \textsc{Szegedy, C.}
  (2014).
\newblock Explaining and harnessing adversarial examples.
\newblock \textit{arXiv preprint arXiv:1412.6572}.

\bibitem[{Gu and Rigazio(2014)}]{gu2014towards}
\textsc{Gu, S.} and \textsc{Rigazio, L.} (2014).
\newblock Towards deep neural network architectures robust to adversarial
  examples.
\newblock \textit{arXiv preprint arXiv:1412.5068}.

\bibitem[{G{\"u}hring et~al.(2020)G{\"u}hring, Kutyniok and
  Petersen}]{guhring2020error}
\textsc{G{\"u}hring, I.}, \textsc{Kutyniok, G.} and \textsc{Petersen, P.}
  (2020).
\newblock Error bounds for approximations with deep relu neural networks in w
  s, p norms.
\newblock \textit{Analysis and Applications}, \textbf{18} 803--859.

\bibitem[{Hein and Andriushchenko(2017)}]{hein2017formal}
\textsc{Hein, M.} and \textsc{Andriushchenko, M.} (2017).
\newblock Formal guarantees on the robustness of a classifier against
  adversarial manipulation.
\newblock \textit{arXiv preprint arXiv:1705.08475}.

\bibitem[{Hon and Yang(2021)}]{hon2021simultaneous}
\textsc{Hon, S.} and \textsc{Yang, H.} (2021).
\newblock Simultaneous neural network approximations in sobolev spaces.
\newblock \textit{arXiv preprint arXiv:2109.00161}.

\bibitem[{Hornik(1991)}]{hornik1991approximation}
\textsc{Hornik, K.} (1991).
\newblock Approximation capabilities of multilayer feedforward networks.
\newblock \textit{Neural Networks}, \textbf{4} 251--257.

\bibitem[{Hornik et~al.(1990)Hornik, Stinchcombe and
  White}]{hornik1990universal}
\textsc{Hornik, K.}, \textsc{Stinchcombe, M.} and \textsc{White, H.} (1990).
\newblock Universal approximation of an unknown mapping and its derivatives
  using multilayer feedforward networks.
\newblock \textit{Neural networks}, \textbf{3} 551--560.

\bibitem[{Irie and Miyake(1988)}]{irie1988capabilities}
\textsc{Irie, B.} and \textsc{Miyake, S.} (1988).
\newblock Capabilities of three-layered perceptrons.
\newblock In \textit{IEEE International Conference on Neural Networks}, vol.~1.

\bibitem[{Lee(2006)}]{lee2006riemannian}
\textsc{Lee, J.~M.} (2006).
\newblock \textit{Riemannian manifolds: an introduction to curvature}, vol.
  176.
\newblock Springer Science \& Business Media.

\bibitem[{Leshno et~al.(1993)Leshno, Lin, Pinkus and
  Schocken}]{leshno1993multilayer}
\textsc{Leshno, M.}, \textsc{Lin, V.~Y.}, \textsc{Pinkus, A.} and
  \textsc{Schocken, S.} (1993).
\newblock Multilayer feedforward networks with a nonpolynomial activation
  function can approximate any function.
\newblock \textit{Neural Networks}, \textbf{6} 861--867.

\bibitem[{Liu et~al.(2021)Liu, Chen, Zhao and Liao}]{liu2021besov}
\textsc{Liu, H.}, \textsc{Chen, M.}, \textsc{Zhao, T.} and \textsc{Liao, W.}
  (2021).
\newblock Besov function approximation and binary classification on
  low-dimensional manifolds using convolutional residual networks.
\newblock In \textit{International Conference on Machine Learning}. PMLR.

\bibitem[{Liu et~al.(2022)Liu, Yang, Chen, Zhao and Liao}]{liu2022deep}
\textsc{Liu, H.}, \textsc{Yang, H.}, \textsc{Chen, M.}, \textsc{Zhao, T.} and
  \textsc{Liao, W.} (2022).
\newblock Deep nonparametric estimation of operators between infinite
  dimensional spaces.
\newblock \textit{arXiv preprint arXiv:2201.00217}.

\bibitem[{Madry et~al.(2017)Madry, Makelov, Schmidt, Tsipras and
  Vladu}]{madry2017towards}
\textsc{Madry, A.}, \textsc{Makelov, A.}, \textsc{Schmidt, L.},
  \textsc{Tsipras, D.} and \textsc{Vladu, A.} (2017).
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock \textit{arXiv preprint arXiv:1706.06083}.

\bibitem[{Mhaskar(1996)}]{mhaskar1996neural}
\textsc{Mhaskar, H.~N.} (1996).
\newblock Neural networks for optimal approximation of smooth and analytic
  functions.
\newblock \textit{Neural Comput.}, \textbf{8} 164--177.

\bibitem[{Miyato et~al.(2018)Miyato, Maeda, Koyama and
  Ishii}]{miyato2018virtual}
\textsc{Miyato, T.}, \textsc{Maeda, S.-i.}, \textsc{Koyama, M.} and
  \textsc{Ishii, S.} (2018).
\newblock Virtual adversarial training: a regularization method for supervised
  and semi-supervised learning.
\newblock \textit{IEEE transactions on pattern analysis and machine
  intelligence}, \textbf{41} 1979--1993.

\bibitem[{Montanelli and Yang(2020)}]{montanelli2020error}
\textsc{Montanelli, H.} and \textsc{Yang, H.} (2020).
\newblock Error bounds for deep relu networks using the kolmogorov--arnold
  superposition theorem.
\newblock \textit{Neural Networks}, \textbf{129} 1--6.

\bibitem[{Nakada and Imaizumi(2019)}]{nakada1907adaptive}
\textsc{Nakada, R.} and \textsc{Imaizumi, M.} (2019).
\newblock Adaptive approximation and estimation of deep neural network to
  intrinsic dimensionality.
\newblock \textit{arXiv preprint arXiv:1907.02177}.

\bibitem[{Niyogi et~al.(2008)Niyogi, Smale and Weinberger}]{niyogi2008finding}
\textsc{Niyogi, P.}, \textsc{Smale, S.} and \textsc{Weinberger, S.} (2008).
\newblock Finding the homology of submanifolds with high confidence from random
  samples.
\newblock \textit{Discrete \& Computational Geometry}, \textbf{39} 419--441.

\bibitem[{Oono and Suzuki(2019)}]{oono2019approximation}
\textsc{Oono, K.} and \textsc{Suzuki, T.} (2019).
\newblock Approximation and non-parametric estimation of resnet-type
  convolutional neural networks.
\newblock In \textit{International Conference on Machine Learning}. PMLR.

\bibitem[{Petersen and Voigtlaender(2020)}]{petersen2020equivalence}
\textsc{Petersen, P.} and \textsc{Voigtlaender, F.} (2020).
\newblock Equivalence of approximation by convolutional neural networks and
  fully-connected networks.
\newblock \textit{Proceedings of the American Mathematical Society},
  \textbf{148} 1567--1581.

\bibitem[{Pope et~al.(2021)Pope, Zhu, Abdelkader, Goldblum and
  Goldstein}]{pope2021intrinsic}
\textsc{Pope, P.}, \textsc{Zhu, C.}, \textsc{Abdelkader, A.}, \textsc{Goldblum,
  M.} and \textsc{Goldstein, T.} (2021).
\newblock The intrinsic dimension of images and its impact on learning.
\newblock \textit{arXiv preprint arXiv:2104.08894}.

\bibitem[{Roweis and Saul(2000)}]{roweis2000nonlinear}
\textsc{Roweis, S.~T.} and \textsc{Saul, L.~K.} (2000).
\newblock Nonlinear dimensionality reduction by locally linear embedding.
\newblock \textit{Science}, \textbf{290} 2323--2326.

\bibitem[{Schmidt-Hieber(2019)}]{schmidt2019deep}
\textsc{Schmidt-Hieber, J.} (2019).
\newblock Deep relu network approximation of functions on a manifold.
\newblock \textit{arXiv preprint arXiv:1908.00695}.

\bibitem[{Shaham et~al.(2018)Shaham, Cloninger and
  Coifman}]{shaham2018provable}
\textsc{Shaham, U.}, \textsc{Cloninger, A.} and \textsc{Coifman, R.~R.} (2018).
\newblock Provable approximation properties for deep neural networks.
\newblock \textit{Applied and Computational Harmonic Analysis}, \textbf{44}
  537--557.

\bibitem[{Shen et~al.(2019)Shen, Yang and Zhang}]{shen2019deep}
\textsc{Shen, Z.}, \textsc{Yang, H.} and \textsc{Zhang, S.} (2019).
\newblock Deep network approximation characterized by number of neurons.
\newblock \textit{arXiv preprint arXiv:1906.05497}.

\bibitem[{Slobodeckij(1958)}]{slobodeckij1958generalized}
\textsc{Slobodeckij, L.} (1958).
\newblock Generalized sobolev spaces and their applications to boundary value
  problems of partial differential equations, leningrad.
\newblock \textit{Gos. Ped. Inst. Ucep. Zap}, \textbf{197} 54--112.

\bibitem[{Spivak(1973)}]{spivak1973comprehensive}
\textsc{Spivak, M.} (1973).
\newblock A comprehensive introduction to differential geometry.
\newblock \textit{Bull. Amer. Math. Soc}, \textbf{79} 303--306.

\bibitem[{Stein(1970)}]{stein1970singular}
\textsc{Stein, E.~M.} (1970).
\newblock \textit{Singular Integrals and Differentiability Properties of
  Functions}, vol.~2.
\newblock Princeton University Press.

\bibitem[{Suzuki(2019)}]{suzuki2018adaptivity}
\textsc{Suzuki, T.} (2019).
\newblock Adaptivity of deep re{LU} network for learning in besov and mixed
  smooth besov spaces: optimal rate and curse of dimensionality.
\newblock In \textit{International Conference on Learning Representations}.

\bibitem[{Suzuki and Nitanda(2019)}]{suzuki2019deep}
\textsc{Suzuki, T.} and \textsc{Nitanda, A.} (2019).
\newblock Deep learning is adaptive to intrinsic dimensionality of model
  smoothness in anisotropic besov space.
\newblock \textit{arXiv preprint arXiv:1910.12799}.

\bibitem[{Tenenbaum et~al.(2000)Tenenbaum, De~Silva and
  Langford}]{tenenbaum2000global}
\textsc{Tenenbaum, J.~B.}, \textsc{De~Silva, V.} and \textsc{Langford, J.~C.}
  (2000).
\newblock A global geometric framework for nonlinear dimensionality reduction.
\newblock \textit{Science}, \textbf{290} 2319--2323.

\bibitem[{Tu(2010)}]{tu2010introduction}
\textsc{Tu, L.} (2010).
\newblock \textit{An Introduction to Manifolds}.
\newblock Universitext, Springer New York.

\bibitem[{Uesato et~al.(2018)Uesato, O’donoghue, Kohli and
  Oord}]{uesato2018adversarial}
\textsc{Uesato, J.}, \textsc{O’donoghue, B.}, \textsc{Kohli, P.} and
  \textsc{Oord, A.} (2018).
\newblock Adversarial risk and the dangers of evaluating against weak attacks.
\newblock In \textit{International Conference on Machine Learning}. PMLR.

\bibitem[{Weng et~al.(2018)Weng, Zhang, Chen, Yi, Su, Gao, Hsieh and
  Daniel}]{weng2018evaluating}
\textsc{Weng, T.-W.}, \textsc{Zhang, H.}, \textsc{Chen, P.-Y.}, \textsc{Yi,
  J.}, \textsc{Su, D.}, \textsc{Gao, Y.}, \textsc{Hsieh, C.-J.} and
  \textsc{Daniel, L.} (2018).
\newblock Evaluating the robustness of neural networks: An extreme value theory
  approach.
\newblock \textit{arXiv preprint arXiv:1801.10578}.

\bibitem[{Wu et~al.(2020)Wu, Chen, Cai, He and Gu}]{wu2020wider}
\textsc{Wu, B.}, \textsc{Chen, J.}, \textsc{Cai, D.}, \textsc{He, X.} and
  \textsc{Gu, Q.} (2020).
\newblock Do wider neural networks really help adversarial robustness?
\newblock \textit{arXiv preprint arXiv:2010.01279}.

\bibitem[{Yarotsky(2017)}]{yarotsky2017error}
\textsc{Yarotsky, D.} (2017).
\newblock Error bounds for approximations with deep relu networks.
\newblock \textit{Neural Networks}, \textbf{94} 103--114.

\bibitem[{Zagoruyko and Komodakis(2016)}]{zagoruyko2016wide}
\textsc{Zagoruyko, S.} and \textsc{Komodakis, N.} (2016).
\newblock Wide residual networks.
\newblock \textit{arXiv preprint arXiv:1605.07146}.

\bibitem[{Zhang et~al.(2019)Zhang, Yu, Jiao, Xing, Ghaoui and
  Jordan}]{zhang2019theoretically}
\textsc{Zhang, H.}, \textsc{Yu, Y.}, \textsc{Jiao, J.}, \textsc{Xing, E.~P.},
  \textsc{Ghaoui, L.~E.} and \textsc{Jordan, M.~I.} (2019).
\newblock Theoretically principled trade-off between robustness and accuracy.
\newblock In \textit{International Conference on Machine Learning}.

\bibitem[{Zhao et~al.(2021)Zhao, Zuo, Zhao and Zhao}]{zhao2021adversarially}
\textsc{Zhao, Z.}, \textsc{Zuo, S.}, \textsc{Zhao, T.} and \textsc{Zhao, Y.}
  (2021).
\newblock Adversarially regularized policy learning guided by trajectory
  optimization.
\newblock \textit{arXiv preprint arXiv:2109.07627}.

\bibitem[{Zhou(2020{\natexlab{a}})}]{zhou2020theory}
\textsc{Zhou, D.-X.} (2020{\natexlab{a}}).
\newblock Theory of deep convolutional neural networks: Downsampling.
\newblock \textit{Neural Networks}, \textbf{124} 319--327.

\bibitem[{Zhou(2020{\natexlab{b}})}]{zhou2020universality}
\textsc{Zhou, D.-X.} (2020{\natexlab{b}}).
\newblock Universality of deep convolutional neural networks.
\newblock \textit{Applied and computational harmonic analysis}, \textbf{48}
  787--794.

\end{thebibliography}
