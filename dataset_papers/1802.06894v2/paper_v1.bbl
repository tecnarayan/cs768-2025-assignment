\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Allman et~al.(2009)Allman, Matias, and Rhodes]{Allman2009}
Elizabeth~S. Allman, Catherine Matias, and John~A. Rhodes.
\newblock Identifiability of parameters in latent structure models with many
  observed variables.
\newblock \emph{Annals of Statistics}, 37\penalty0 (6 A):\penalty0 3099--3132,
  2009.

\bibitem[Anandkumar et~al.(2012)Anandkumar, Hsu, and Kakade]{Anandkumar2012}
Animashree Anandkumar, Daniel Hsu, and Sham~M. Kakade.
\newblock A method of moments for mixture models and hidden {Markov} models.
\newblock In \emph{Conference on Learning Theory (COLT)}, pages 33.1--33.34,
  2012.

\bibitem[Anandkumar et~al.(2014)Anandkumar, Ge, Hsu, Kakade, and
  Telgarsky]{Anandkumar2014}
Animashree Anandkumar, Rong Ge, Daniel Hsu, Sham~M. Kakade, and Matus
  Telgarsky.
\newblock Tensor decompositions for learning latent variable models.
\newblock \emph{Journal of Machine Learning Research}, 15:\penalty0 2773--2832,
  2014.

\bibitem[Arora et~al.(2013)Arora, Ge, Halpern, Mimno, Moitra, Sontag, Wu, and
  Zhu]{arora2013practical}
Sanjeev Arora, Rong Ge, Yonatan Halpern, David Mimno, Ankur Moitra, David
  Sontag, Yichen Wu, and Michael Zhu.
\newblock A practical algorithm for topic modeling with provable guarantees.
\newblock In \emph{International Conference on Machine Learning}, pages
  280--288, 2013.

\bibitem[Barlier et~al.(2015)Barlier, Laroche, and Pietquin]{Barlier2015}
Merwan Barlier, Romain Laroche, and Olivier Pietquin.
\newblock Learning dialogue dynamics with the method of moments.
\newblock In \emph{IEEE Spoken Language Technology Workshop (SLT)}, pages
  98--105, 2015.

\bibitem[Baum et~al.(1970)Baum, Petrie, Soules, and
  Weiss]{baum1970maximization}
Leonard~E Baum, Ted Petrie, George Soules, and Norman Weiss.
\newblock A maximization technique occurring in the statistical analysis of
  probabilistic functions of markov chains.
\newblock \emph{The Annals of Mathematical Statistics}, 41\penalty0
  (1):\penalty0 164--171, 1970.

\bibitem[Bhaskara et~al.(2014)Bhaskara, Charikar, and
  Vijayaraghavan]{bhaskara14a}
Aditya Bhaskara, Moses Charikar, and Aravindan Vijayaraghavan.
\newblock Uniqueness of tensor decompositions with applications to polynomial
  identifiability.
\newblock In \emph{Proceedings of The 27th Conference on Learning Theory},
  volume~35, pages 742--778, Jun 2014.

\bibitem[Blei et~al.(2003)Blei, Ng, and Jordan]{blei2003latent}
David~M Blei, Andrew~Y Ng, and Michael~I Jordan.
\newblock Latent {Dirichlet} allocation.
\newblock \emph{Journal of machine Learning research}, 3\penalty0
  (Jan):\penalty0 993--1022, 2003.

\bibitem[Boyd and Vandenberghe(2004)]{boyd2004convex}
Stephen Boyd and Lieven Vandenberghe.
\newblock \emph{Convex Optimization}.
\newblock Cambridge University Press, 2004.

\bibitem[Chiantini and Ottaviani(2012)]{chiantini2012generic}
Luca Chiantini and Giorgio Ottaviani.
\newblock On generic identifiability of 3-tensors of small rank.
\newblock \emph{SIAM Journal on Matrix Analysis and Applications}, 33\penalty0
  (3):\penalty0 1018--1037, 2012.

\bibitem[Cybenko and Crespi(2011)]{Cybenko2011}
George Cybenko and Valentino Crespi.
\newblock Learning hidden {Markov} models using nonnegative matrix
  factorization.
\newblock \emph{IEEE Transactions on Information Theory}, 57\penalty0
  (6):\penalty0 3963--3970, 2011.

\bibitem[{De Lathauwer} et~al.(2004){De Lathauwer}, {De Moor}, and
  Vandewalle]{DeLathauwer2004a}
Lieven {De Lathauwer}, Bart {De Moor}, and Joos Vandewalle.
\newblock Computation of the canonical decomposition by means of a simultaneous
  generalized {Schur} decomposition.
\newblock \emph{SIAM Journal on Matrix Analysis and Applications}, 26\penalty0
  (2):\penalty0 295--327, Jan 2004.

\bibitem[Donoho and Stodden(2004)]{donoho2004does}
David Donoho and Victoria Stodden.
\newblock When does non-negative matrix factorization give a correct
  decomposition into parts?
\newblock In \emph{Advances in neural information processing systems}, pages
  1141--1148, 2004.

\bibitem[Donoho and Elad(2003)]{Donoho2003}
David~L. Donoho and Michael Elad.
\newblock Optimally sparse representation in general (nonorthogonal)
  dictionaries via {ell-one} minimization.
\newblock In \emph{Proceedings of the National Academy of Sciences of the
  United States of America}, volume 100, pages 2197--202, 2003.

\bibitem[Fu et~al.(2018)Fu, Huang, and Sidiropoulos]{fu2017spl}
X.~Fu, K.~Huang, and N.~D. Sidiropoulos.
\newblock On identifiability of nonnegative matrix factorization.
\newblock \emph{IEEE Signal Processing Letters}, 25\penalty0 (3):\penalty0
  328--332, 2018.

\bibitem[Fu et~al.(2015)Fu, Ma, Huang, and Sidiropoulos]{fu2015bss}
Xiao Fu, Wing-Kin Ma, Kejun Huang, and Nicholas~D. Sidiropoulos.
\newblock Blind separation of quasi-stationary sources: Exploiting convex
  geometry in covariance domain.
\newblock \emph{IEEE Transactions on Signal Processing}, 63\penalty0
  (9):\penalty0 2306--2320, May 2015.

\bibitem[Ghahramani(2001)]{Ghahramani2001}
Zoubin Ghahramani.
\newblock An introduction to hidden {Markov} models and {Baysian} networks.
\newblock \emph{International Journal of Pattern Recognition and Artificial
  Intelligence}, 15\penalty0 (1):\penalty0 9--42, 2001.

\bibitem[Glaude et~al.(2015)Glaude, Enderli, and Pietquin]{Glaude2015}
Hadrien Glaude, Cyrille Enderli, and Olivier Pietquin.
\newblock Spectral learning with non negative probabilities for finite state
  automaton.
\newblock In \emph{IEEE Workshop on Automatic Speech Recognition and
  Understanding (ASRU)}, pages 71--77, 2015.

\bibitem[Gruber et~al.(2007)Gruber, Weiss, and Rosen-Zvi]{gruber2007hidden}
Amit Gruber, Yair Weiss, and Michal Rosen-Zvi.
\newblock Hidden topic {Markov} models.
\newblock In \emph{Artificial intelligence and statistics}, pages 163--170,
  2007.

\bibitem[Harshman(1970)]{harshman1970foundations}
Richard~A Harshman.
\newblock Foundations of the {PARAFAC} procedure: Models and conditions for an
  ``explanatory'' multimodal factor analysis.
\newblock Technical report, University of California at Los Angeles, 1970.

\bibitem[Hofmann(2001)]{hofmann2001unsupervised}
Thomas Hofmann.
\newblock Unsupervised learning by probabilistic latent semantic analysis.
\newblock \emph{Machine learning}, 42\penalty0 (1-2):\penalty0 177--196, 2001.

\bibitem[Hsu et~al.(2009)Hsu, Kakade, and Zhang]{Hsu2009}
Daniel~J Hsu, Sham~M Kakade, and Tong Zhang.
\newblock A spectral algorithm for learning hidden {Markov} models.
\newblock In \emph{Conference on Learning Theory (COLT)}, 2009.

\bibitem[Huang et~al.(2014)Huang, Sidiropoulos, and Swami]{huang2014tsp}
Kejun Huang, Nicholas~D. Sidiropoulos, and Ananthram Swami.
\newblock Non-negative matrix factorization revisited: Uniqueness and algorithm
  for symmetric decomposition.
\newblock \emph{IEEE Transactions on Signal Processing}, 62\penalty0
  (1):\penalty0 211--224, Jan. 2014.

\bibitem[Huang et~al.(2015)Huang, Sidiropoulos, Papalexakis, Christos,
  Talukdar, and Mitchell]{huang2015principled}
Kejun Huang, Nicholas~D. Sidiropoulos, Evangelos Papalexakis, Faloutsos
  Christos, Partha~P. Talukdar, and Tom Mitchell.
\newblock Principled neuro-functional connectivity discovery.
\newblock In \emph{SIAM International Conference on Data Mining (SDM)}, 2015.

\bibitem[Huang et~al.(2016{\natexlab{a}})Huang, Fu, and
  Sidiropoulos]{huang2016nips}
Kejun Huang, Xiao Fu, and Nicholas~D. Sidiropoulos.
\newblock Anchor-free correlated topic modeling: Identifiability and algorithm.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2016{\natexlab{a}}.

\bibitem[Huang et~al.(2016{\natexlab{b}})Huang, Ge, Kakade, and
  Dahleh]{Huang2016}
Qingqing Huang, Rong Ge, Sham Kakade, and Munther Dahleh.
\newblock Minimal realization problems for hidden {Markov} models.
\newblock \emph{IEEE Transactions on Signal Processing}, 64\penalty0
  (7):\penalty0 1896--1904, 2016{\natexlab{b}}.

\bibitem[Jensen(1906)]{jensen1906fonctions}
Johan Jensen.
\newblock Sur les fonctions convexes et les in{\'e}galit{\'e}s entre les
  valeurs moyennes.
\newblock \emph{Acta mathematica}, 30\penalty0 (1):\penalty0 175--193, 1906.

\bibitem[Kontorovich(2006)]{kontorovich2006measure}
Leonid Kontorovich.
\newblock Measure concentration of hidden {Markov} processes.
\newblock \emph{arXiv preprint math/0608064}, 2006.

\bibitem[Lakshminarayanan and Raich(2010)]{Lakshminarayanan2010}
Balaji Lakshminarayanan and Raviv Raich.
\newblock {Non-negative matrix factorization for parameter estimation in hidden
  Markov models}.
\newblock In \emph{IEEE International Workshop on Machine Learning for Signal
  Processing}, pages 89--94, 2010.

\bibitem[Leurgans et~al.(1993)Leurgans, Ross, and
  Abel]{leurgans1993decomposition}
SE~Leurgans, RT~Ross, and RB~Abel.
\newblock A decomposition for three-way arrays.
\newblock \emph{SIAM Journal on Matrix Analysis and Applications}, 14\penalty0
  (4):\penalty0 1064--1083, 1993.

\bibitem[Mimaroglu(2007)]{reuters21578}
Selim Mimaroglu.
\newblock Some text datasets, 2007.
\newblock \url{https://www.cs.umb.edu/~smimarog/textmining/datasets/}.

\bibitem[Rabiner and Juang(1986)]{rabiner1986introduction}
Lawrence Rabiner and B~Juang.
\newblock An introduction to hidden {Markov} models.
\newblock \emph{IEEE ASSP Magazine}, 3\penalty0 (1):\penalty0 4--16, 1986.

\bibitem[Razaviyayn et~al.(2013)Razaviyayn, Hong, and
  Luo]{razaviyayn2013unified}
Meisam Razaviyayn, Mingyi Hong, and Zhi-Quan Luo.
\newblock A unified convergence analysis of block successive minimization
  methods for nonsmooth optimization.
\newblock \emph{SIAM Journal on Optimization}, 23\penalty0 (2):\penalty0
  1126--1153, 2013.

\bibitem[Sanchez and Kowalski(1990)]{sanchez1990tensorial}
Eugenio Sanchez and Bruce~R Kowalski.
\newblock Tensorial resolution: a direct trilinear decomposition.
\newblock \emph{Journal of Chemometrics}, 4\penalty0 (1):\penalty0 29--45,
  1990.

\bibitem[Sharan et~al.(2017)Sharan, Kakade, Liang, and Valiant]{Sharan2017}
Vatsal Sharan, Sham Kakade, Percy Liang, and Gregory Valiant.
\newblock Learning overcomplete {HMMs}.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  2017.

\bibitem[Shashanka et~al.(2008)Shashanka, Raj, and
  Smaragdis]{shashanka2008probabilistic}
Madhusudana Shashanka, Bhiksha Raj, and Paris Smaragdis.
\newblock Probabilistic latent variable models as nonnegative factorizations.
\newblock \emph{Computational intelligence and neuroscience}, 2008, 2008.

\bibitem[Sidiropoulos et~al.()Sidiropoulos, De~Lathauwer, Fu, Huang,
  Papalexakis, and Faloutsos]{sidiropoulos2017tensor}
Nicholas~D Sidiropoulos, Lieven De~Lathauwer, Xiao Fu, Kejun Huang, Evangelos~E
  Papalexakis, and Christos Faloutsos.
\newblock Tensor decomposition for signal processing and machine learning.
\newblock \emph{IEEE Transactions on Signal Processing}, 65\penalty0
  (13):\penalty0 3551--3582.

\bibitem[Vanluyten et~al.(2008)Vanluyten, Willems, and {De
  Moor}]{Vanluyten2008}
Bart Vanluyten, Jan~C. Willems, and Bart {De Moor}.
\newblock Structured nonnegative matrix factorization with applications to
  hidden {Markov} realization and clustering.
\newblock \emph{Linear Algebra and Its Applications}, 429\penalty0
  (7):\penalty0 1409--1424, 2008.

\bibitem[Vervliet et~al.(2016)Vervliet, Debals, Sorber, Van~Barel, and
  De~Lathauwer]{tensorlab3.0}
N.~Vervliet, O.~Debals, L.~Sorber, M.~Van~Barel, and L.~De~Lathauwer.
\newblock Tensorlab 3.0, Mar. 2016.
\newblock URL \url{https://www.tensorlab.net}.
\newblock Available online.

\bibitem[Wallach(2006)]{wallach2006topic}
Hanna~M Wallach.
\newblock Topic modeling: Beyond bag-of-words.
\newblock In \emph{International Conference on Machine Learning}, pages
  977--984, 2006.

\bibitem[Wang et~al.(2007)Wang, McCallum, and Wei]{wang2007topical}
Xuerui Wang, Andrew McCallum, and Xing Wei.
\newblock Topical n-grams: Phrase and topic discovery, with an application to
  information retrieval.
\newblock In \emph{IEEE International Conference on Data Mining}, pages
  697--702. IEEE, 2007.

\end{thebibliography}
