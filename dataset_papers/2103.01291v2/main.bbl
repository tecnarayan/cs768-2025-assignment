\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bishop(2006)]{bishop2006pattern}
Bishop, C.~M.
\newblock \emph{Pattern recognition and machine learning}.
\newblock springer, 2006.

\bibitem[Blundell et~al.(2015)Blundell, Cornebise, Kavukcuoglu, and
  Wierstra]{blundell2015weight}
Blundell, C., Cornebise, J., Kavukcuoglu, K., and Wierstra, D.
\newblock Weight uncertainty in neural networks.
\newblock \emph{arXiv preprint arXiv:1505.05424}, 2015.

\bibitem[Buntine \& Weigend(1991)Buntine and Weigend]{buntine1991bayesian}
Buntine, W.~L. and Weigend, A.~S.
\newblock Bayesian back-propagation.
\newblock \emph{Complex systems}, 5\penalty0 (6):\penalty0 603--643, 1991.

\bibitem[Chen et~al.(2014)Chen, Fox, and Guestrin]{chen2014stochastic}
Chen, T., Fox, E., and Guestrin, C.
\newblock Stochastic gradient hamiltonian monte carlo.
\newblock In \emph{International conference on machine learning}, pp.\
  1683--1691, 2014.

\bibitem[Cheng \& Boots(2017)Cheng and Boots]{cheng2017variational}
Cheng, C.-A. and Boots, B.
\newblock Variational inference for gaussian process models with linear
  complexity.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  5184--5194, 2017.

\bibitem[Durmus et~al.(2017)Durmus, Moulines, and
  Saksman]{durmus2017convergence}
Durmus, A., Moulines, E., and Saksman, E.
\newblock On the convergence of hamiltonian monte carlo.
\newblock \emph{arXiv preprint arXiv:1705.00166}, 2017.

\bibitem[Fletcher(1976)]{fletcher1976conjugate}
Fletcher, R.
\newblock Conjugate gradient methods for indefinite systems.
\newblock In \emph{Numerical analysis}, pp.\  73--89. Springer, 1976.

\bibitem[Gal \& Ghahramani(2016)Gal and Ghahramani]{gal2016dropout}
Gal, Y. and Ghahramani, Z.
\newblock Dropout as a bayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In \emph{international conference on machine learning}, pp.\
  1050--1059, 2016.

\bibitem[Grathwohl et~al.(2020)Grathwohl, Wang, Jacobsen, Duvenaud, and
  Zemel]{grathwohl2020learning}
Grathwohl, W., Wang, K.-C., Jacobsen, J.-H., Duvenaud, D., and Zemel, R.
\newblock Learning the stein discrepancy for training and evaluating
  energy-based models without sampling.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  3732--3747. PMLR, 2020.

\bibitem[Graves(2011)]{graves2011practical}
Graves, A.
\newblock Practical variational inference for neural networks.
\newblock \emph{Advances in neural information processing systems},
  24:\penalty0 2348--2356, 2011.

\bibitem[Hensman et~al.(2013)Hensman, Fusi, and Lawrence]{hensman2013gaussian}
Hensman, J., Fusi, N., and Lawrence, N.~D.
\newblock Gaussian processes for big data.
\newblock \emph{arXiv preprint arXiv:1309.6835}, 2013.

\bibitem[Hensman et~al.(2015)Hensman, Matthews, and
  Ghahramani]{hensman2015scalable}
Hensman, J., Matthews, A., and Ghahramani, Z.
\newblock Scalable variational gaussian process classification.
\newblock 2015.

\bibitem[Hu et~al.(2018)Hu, Chen, Sun, Bai, Ye, and Cheng]{hu2018stein}
Hu, T., Chen, Z., Sun, H., Bai, J., Ye, M., and Cheng, G.
\newblock Stein neural sampler.
\newblock \emph{arXiv preprint arXiv:1810.03545}, 2018.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kingma et~al.(2015)Kingma, Salimans, and
  Welling]{kingma2015variational}
Kingma, D.~P., Salimans, T., and Welling, M.
\newblock Variational dropout and the local reparameterization trick.
\newblock \emph{Advances in neural information processing systems},
  28:\penalty0 2575--2583, 2015.

\bibitem[Korattikara~Balan et~al.(2015)Korattikara~Balan, Rathod, Murphy, and
  Welling]{korattikara2015bayesian}
Korattikara~Balan, A., Rathod, V., Murphy, K.~P., and Welling, M.
\newblock Bayesian dark knowledge.
\newblock \emph{Advances in Neural Information Processing Systems},
  28:\penalty0 3438--3446, 2015.

\bibitem[Krueger et~al.(2017)Krueger, Huang, Islam, Turner, Lacoste, and
  Courville]{krueger2017bayesian}
Krueger, D., Huang, C.-W., Islam, R., Turner, R., Lacoste, A., and Courville,
  A.
\newblock Bayesian hypernetworks.
\newblock \emph{arXiv preprint arXiv:1710.04759}, 2017.

\bibitem[Lakshminarayanan et~al.(2017)Lakshminarayanan, Pritzel, and
  Blundell]{lakshminarayanan2017simple}
Lakshminarayanan, B., Pritzel, A., and Blundell, C.
\newblock Simple and scalable predictive uncertainty estimation using deep
  ensembles.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  6402--6413, 2017.

\bibitem[Liu et~al.(2019)Liu, Zhuo, Cheng, Zhang, and
  Zhu]{liu2019understanding}
Liu, C., Zhuo, J., Cheng, P., Zhang, R., and Zhu, J.
\newblock Understanding and accelerating particle-based variational inference.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  4082--4092. PMLR, 2019.

\bibitem[Liu(2017)]{liu2017GF}
Liu, Q.
\newblock Stein variational gradient descent as gradient flow.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  3115--3123, 2017.

\bibitem[Liu \& Wang(2016)Liu and Wang]{liu2016stein}
Liu, Q. and Wang, D.
\newblock Stein variational gradient descent: A general purpose bayesian
  inference algorithm.
\newblock \emph{Advances in neural information processing systems},
  29:\penalty0 2378--2386, 2016.

\bibitem[Louizos \& Welling(2016)Louizos and Welling]{louizos2016structured}
Louizos, C. and Welling, M.
\newblock Structured and efficient variational deep learning with matrix
  gaussian posteriors.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1708--1716, 2016.

\bibitem[Louizos \& Welling(2017)Louizos and
  Welling]{louizos2017multiplicative}
Louizos, C. and Welling, M.
\newblock Multiplicative normalizing flows for variational bayesian neural
  networks.
\newblock \emph{arXiv preprint arXiv:1703.01961}, 2017.

\bibitem[MacKay(1992)]{mackay1992practical}
MacKay, D.~J.
\newblock A practical bayesian framework for backpropagation networks.
\newblock \emph{Neural computation}, 4\penalty0 (3):\penalty0 448--472, 1992.

\bibitem[Marzouk et~al.(2016)Marzouk, Moselhy, Parno, and
  Spantini]{marzouk2016introduction}
Marzouk, Y., Moselhy, T., Parno, M., and Spantini, A.
\newblock An introduction to sampling via measure transport.
\newblock \emph{arXiv preprint arXiv:1602.05023}, 2016.

\bibitem[Minka(2001)]{minka2001family}
Minka, T.~P.
\newblock \emph{A family of algorithms for approximate Bayesian inference}.
\newblock PhD thesis, Massachusetts Institute of Technology, 2001.

\bibitem[Neal et~al.(2018)Neal, Olson, Fern, Wong, and Li]{neal2018open}
Neal, L., Olson, M., Fern, X., Wong, W.-K., and Li, F.
\newblock Open set learning with counterfactual images.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pp.\  613--628, 2018.

\bibitem[Neal(2012)]{neal2012bayesian}
Neal, R.~M.
\newblock \emph{Bayesian learning for neural networks}, volume 118.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Neal et~al.(2011)]{neal2011mcmc}
Neal, R.~M. et~al.
\newblock Mcmc using hamiltonian dynamics.
\newblock \emph{Handbook of markov chain monte carlo}, 2\penalty0
  (11):\penalty0 2, 2011.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen,
  T., Lin, Z., Gimelshein, N., Antiga, L., et~al.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock \emph{arXiv preprint arXiv:1912.01703}, 2019.

\bibitem[Pawlowski et~al.(2017)Pawlowski, Brock, Lee, Rajchl, and
  Glocker]{pawlowski2017implicit}
Pawlowski, N., Brock, A., Lee, M.~C., Rajchl, M., and Glocker, B.
\newblock Implicit weight uncertainty in neural networks.
\newblock \emph{arXiv preprint arXiv:1711.01297}, 2017.

\bibitem[Rasmussen(2003)]{rasmussen2003gaussian}
Rasmussen, C.~E.
\newblock Gaussian processes in machine learning.
\newblock In \emph{Summer School on Machine Learning}, pp.\  63--71. Springer,
  2003.

\bibitem[Rezende \& Mohamed(2015)Rezende and Mohamed]{rezende2015variational}
Rezende, D. and Mohamed, S.
\newblock Variational inference with normalizing flows.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  1530--1538. PMLR, 2015.

\bibitem[Saad(2003)]{saad2003iterative}
Saad, Y.
\newblock \emph{Iterative methods for sparse linear systems}.
\newblock SIAM, 2003.

\bibitem[Strathmann et~al.(2015)Strathmann, Sejdinovic, Livingstone, Szabo, and
  Gretton]{strathmann2015gradient}
Strathmann, H., Sejdinovic, D., Livingstone, S., Szabo, Z., and Gretton, A.
\newblock Gradient-free hamiltonian monte carlo with efficient kernel
  exponential families.
\newblock \emph{Advances in Neural Information Processing Systems},
  28:\penalty0 955--963, 2015.

\bibitem[Wang \& Liu(2016)Wang and Liu]{wang2016learning}
Wang, D. and Liu, Q.
\newblock Learning to draw samples: With application to amortized mle for
  generative adversarial learning.
\newblock \emph{arXiv preprint arXiv:1611.01722}, 2016.

\bibitem[Wang et~al.(2019)Wang, Pleiss, Gardner, Tyree, Weinberger, and
  Wilson]{wang2019exact}
Wang, K., Pleiss, G., Gardner, J., Tyree, S., Weinberger, K.~Q., and Wilson,
  A.~G.
\newblock Exact gaussian processes on a million data points.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  14648--14659, 2019.

\bibitem[Welling \& Teh(2011)Welling and Teh]{welling2011bayesian}
Welling, M. and Teh, Y.~W.
\newblock Bayesian learning via stochastic gradient langevin dynamics.
\newblock In \emph{Proceedings of the 28th international conference on machine
  learning (ICML-11)}, pp.\  681--688, 2011.

\bibitem[Wilson et~al.(2016)Wilson, Hu, Salakhutdinov, and
  Xing]{wilson2016stochastic}
Wilson, A.~G., Hu, Z., Salakhutdinov, R.~R., and Xing, E.~P.
\newblock Stochastic variational deep kernel learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  29:\penalty0 2586--2594, 2016.

\bibitem[Yao et~al.(2019)Yao, Pan, Ghosh, and Doshi-Velez]{yao2019quality}
Yao, J., Pan, W., Ghosh, S., and Doshi-Velez, F.
\newblock Quality of uncertainty quantification for bayesian neural network
  inference.
\newblock \emph{arXiv preprint arXiv:1906.09686}, 2019.

\bibitem[Young(1954)]{young1954iterative}
Young, D.
\newblock Iterative methods for solving partial difference equations of
  elliptic type.
\newblock \emph{Transactions of the American Mathematical Society}, 76\penalty0
  (1):\penalty0 92--111, 1954.

\end{thebibliography}
