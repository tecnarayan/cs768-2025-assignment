\begin{thebibliography}{25}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Altschuler et~al.(2017)Altschuler, Weed, and
  Rigollet]{altschuler2017near}
Altschuler, J., Weed, J., and Rigollet, P.
\newblock Near-linear time approximation algorithms for optimal transport via
  sinkhorn iteration.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1964--1974, 2017.

\bibitem[Athalye et~al.(2018{\natexlab{a}})Athalye, Carlini, and
  Wagner]{obfuscated-gradients}
Athalye, A., Carlini, N., and Wagner, D.
\newblock Obfuscated gradients give a false sense of security: Circumventing
  defenses to adversarial examples.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning, {ICML} 2018}, July 2018{\natexlab{a}}.
\newblock URL \url{https://arxiv.org/abs/1802.00420}.

\bibitem[Athalye et~al.(2018{\natexlab{b}})Athalye, Engstrom, Ilyas, and
  Kwok]{pmlr-v80-athalye18b}
Athalye, A., Engstrom, L., Ilyas, A., and Kwok, K.
\newblock Synthesizing robust adversarial examples.
\newblock In Dy, J. and Krause, A. (eds.), \emph{Proceedings of the 35th
  International Conference on Machine Learning}, volume~80 of \emph{Proceedings
  of Machine Learning Research}, pp.\  284--293, Stockholmsm√§ssan, Stockholm
  Sweden, 10--15 Jul 2018{\natexlab{b}}. PMLR.
\newblock URL \url{http://proceedings.mlr.press/v80/athalye18b.html}.

\bibitem[Carlini \& Wagner(2017)Carlini and Wagner]{carlini2017towards}
Carlini, N. and Wagner, D.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{Security and Privacy (SP), 2017 IEEE Symposium on}, pp.\
  39--57. IEEE, 2017.

\bibitem[Croce et~al.(2018)Croce, Andriushchenko, and Hein]{croce2018provable}
Croce, F., Andriushchenko, M., and Hein, M.
\newblock Provable robustness of relu networks via maximization of linear
  regions.
\newblock \emph{CoRR}, abs/1810.07481, 2018.
\newblock URL \url{http://arxiv.org/abs/1810.07481}.

\bibitem[Cuturi(2013)]{cuturi2013sinkhorn}
Cuturi, M.
\newblock Sinkhorn distances: Lightspeed computation of optimal transport.
\newblock In Burges, C. J.~C., Bottou, L., Welling, M., Ghahramani, Z., and
  Weinberger, K.~Q. (eds.), \emph{Advances in Neural Information Processing
  Systems 26}, pp.\  2292--2300. Curran Associates, Inc., 2013.
\newblock URL
  \url{http://papers.nips.cc/paper/4927-sinkhorn-distances-lightspeed-computation-of-optimal-transport.pdf}.

\bibitem[Dvijotham et~al.(2018)Dvijotham, Stanforth, Gowal, Mann, and
  Kohli]{dvijotham18}
Dvijotham, K., Stanforth, R., Gowal, S., Mann, T., and Kohli, P.
\newblock A dual approach to scalable verification of deep networks.
\newblock In \emph{Proceedings of the Thirty-Fourth Conference Annual
  Conference on Uncertainty in Artificial Intelligence (UAI-18)}, pp.\
  162--171, Corvallis, Oregon, 2018. AUAI Press.

\bibitem[Engstrom et~al.(2017)Engstrom, Tran, Tsipras, Schmidt, and
  Madry]{engstrom2017rotation}
Engstrom, L., Tran, B., Tsipras, D., Schmidt, L., and Madry, A.
\newblock A rotation and a translation suffice: Fooling cnns with simple
  transformations.
\newblock \emph{arXiv preprint arXiv:1712.02779}, 2017.

\bibitem[Eykholt et~al.(2018)Eykholt, Evtimov, Fernandes, Li, Rahmati, Xiao,
  Prakash, Kohno, and Song]{eykholt2018robust}
Eykholt, K., Evtimov, I., Fernandes, E., Li, B., Rahmati, A., Xiao, C.,
  Prakash, A., Kohno, T., and Song, D.
\newblock Robust physical-world attacks on deep learning visual classification.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  1625--1634, 2018.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow2015explaining}
Goodfellow, I., Shlens, J., and Szegedy, C.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{International Conference on Learning Representations}, 2015.
\newblock URL \url{http://arxiv.org/abs/1412.6572}.

\bibitem[Gowal et~al.(2018)Gowal, Dvijotham, Stanforth, Bunel, Qin, Uesato,
  Arandjelovic, Mann, and Kohli]{gowal2018interval}
Gowal, S., Dvijotham, K., Stanforth, R., Bunel, R., Qin, C., Uesato, J.,
  Arandjelovic, R., Mann, T.~A., and Kohli, P.
\newblock On the effectiveness of interval bound propagation for training
  verifiably robust models.
\newblock \emph{CoRR}, abs/1810.12715, 2018.
\newblock URL \url{http://arxiv.org/abs/1810.12715}.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[Kurakin et~al.(2017)Kurakin, Goodfellow, and
  Bengio]{kurakin2017adversarial}
Kurakin, A., Goodfellow, I., and Bengio, S.
\newblock Adversarial examples in the physical world.
\newblock \emph{ICLR Workshop}, 2017.
\newblock URL \url{https://arxiv.org/abs/1607.02533}.

\bibitem[Lu et~al.(2017)Lu, Sibai, Fabry, and Forsyth]{lu2017no}
Lu, J., Sibai, H., Fabry, E., and Forsyth, D.
\newblock No need to worry about adversarial examples in object detection in
  autonomous vehicles.
\newblock \emph{arXiv preprint arXiv:1707.03501}, 2017.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and
  Vladu]{madry2018towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., and Vladu, A.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock In \emph{International Conference on Learning Representations}, 2018.
\newblock URL \url{https://openreview.net/forum?id=rJzIBfZAb}.

\bibitem[Mirman et~al.(2018)Mirman, Gehr, and Vechev]{mirman2018diff}
Mirman, M., Gehr, T., and Vechev, M.
\newblock Differentiable abstract interpretation for provably robust neural
  networks.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2018.
\newblock URL
  \url{https://www.icml.cc/Conferences/2018/Schedule?showEvent=2477}.

\bibitem[Papernot et~al.(2016)Papernot, McDaniel, Wu, Jha, and
  Swami]{papernot2016distillation}
Papernot, N., McDaniel, P., Wu, X., Jha, S., and Swami, A.
\newblock Distillation as a defense to adversarial perturbations against deep
  neural networks.
\newblock In \emph{Security and Privacy (SP), 2016 IEEE Symposium on}, pp.\
  582--597. IEEE, 2016.

\bibitem[Raghunathan et~al.(2018)Raghunathan, Steinhardt, and
  Liang]{raghunathan2018semi}
Raghunathan, A., Steinhardt, J., and Liang, P.~S.
\newblock Semidefinite relaxations for certifying robustness to adversarial
  examples.
\newblock In Bengio, S., Wallach, H., Larochelle, H., Grauman, K.,
  Cesa-Bianchi, N., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems 31}, pp.\  10900--10910. Curran Associates,
  Inc., 2018.
\newblock URL
  \url{http://papers.nips.cc/paper/8285-semidefinite-relaxations-for-certifying-robustness-to-adversarial-examples.pdf}.

\bibitem[Sharif et~al.(2017)Sharif, Bhagavatula, Bauer, and
  Reiter]{sharif2017adversarial}
Sharif, M., Bhagavatula, S., Bauer, L., and Reiter, M.~K.
\newblock Adversarial generative nets: Neural network attacks on
  state-of-the-art face recognition.
\newblock \emph{arXiv preprint arXiv:1801.00349}, 2017.

\bibitem[Sinha et~al.(2018)Sinha, Namkoong, and Duchi]{sinha2018certifying}
Sinha, A., Namkoong, H., and Duchi, J.
\newblock Certifying some distributional robustness with principled adversarial
  training.
\newblock 2018.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2014intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I.,
  and Fergus, R.
\newblock Intriguing properties of neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2014.
\newblock URL \url{http://arxiv.org/abs/1312.6199}.

\bibitem[Tjeng et~al.(2019)Tjeng, Xiao, and Tedrake]{tjeng2018evaluating}
Tjeng, V., Xiao, K.~Y., and Tedrake, R.
\newblock Evaluating robustness of neural networks with mixed integer
  programming.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=HyGIdiRqtm}.

\bibitem[Wong \& Kolter(2018)Wong and Kolter]{wong2018provable}
Wong, E. and Kolter, Z.
\newblock Provable defenses against adversarial examples via the convex outer
  adversarial polytope.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5283--5292, 2018.

\bibitem[Wong et~al.(2018)Wong, Schmidt, Metzen, and Kolter]{wong2018scaling}
Wong, E., Schmidt, F., Metzen, J.~H., and Kolter, J.~Z.
\newblock Scaling provable adversarial defenses.
\newblock In Bengio, S., Wallach, H., Larochelle, H., Grauman, K.,
  Cesa-Bianchi, N., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems 31}, pp.\  8410--8419. Curran Associates,
  Inc., 2018.
\newblock URL
  \url{http://papers.nips.cc/paper/8060-scaling-provable-adversarial-defenses.pdf}.

\bibitem[Xiao et~al.(2019)Xiao, Tjeng, Shafiullah, and Madry]{xiao2018training}
Xiao, K.~Y., Tjeng, V., Shafiullah, N. M.~M., and Madry, A.
\newblock Training for faster adversarial robustness verification via inducing
  re{LU} stability.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=BJfIVjAcKm}.

\end{thebibliography}
