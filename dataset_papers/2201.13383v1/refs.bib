@article{10.1214/08-AOS648,
author = {Noureddine El Karoui},
title = {{The spectrum of kernel random matrices}},
volume = {38},
journal = {The Annals of Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {1 -- 50},
year = {2010}
}

@article{Krogh1997,
  title = {Statistical mechanics of ensemble learning},
  author = {Krogh, Anders and Sollich, Peter},
  journal = {Phys. Rev. E},
  volume = {55},
  issue = {1},
  pages = {811--825},
  numpages = {0},
  year = {1997},
  month = {Jan},
  publisher = {American Physical Society}
}

@article{Opitz1999,
   author = {David Opitz and Richard Maclin},
   journal = {Journal of Artificial Intelligence Research},
   month = {8},
   pages = {169-198},
   publisher = {Morgan Kaufmann Publishers},
   title = {Popular Ensemble Methods: An Empirical Study},
   volume = {11},
   year = {1999},
}

@article{Breiman1996,
   author = {Leo Breiman},
   issue = {2},
   journal = {Machine Learning},
   keywords = {Aggregation,Averaging,Bootstrap,Combining},
   pages = {123-140},
   publisher = {Springer Netherlands},
   title = {Bagging predictors},
   volume = {24},
   year = {1996},
}



@article{gerbelot2021graph,
  title={Graph-based approximate message passing iterations},
  author={Gerbelot, C{\'e}dric and Berthier, Rapha{\"e}l},
  journal={arXiv preprint arXiv:2109.11905},
  year={2021}
}

@article{Loureiro2021,
      title={Capturing the learning curves of generic features maps for realistic data sets with a teacher-student model}, 
      author={Bruno Loureiro and C\'edric Gerbelot and Hugo Cui and Sebastian Goldt and Florent Krzakala and Marc M\'ezard and Lenka Zdeborov\'a},
      year={2021},
      eprint={2102.08127},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      journal = {arXiv:2102.08127}
}
@article{dhifallah2020precise,
  title={A precise performance analysis of learning with random features},
  author={Dhifallah, Oussama and Lu, Yue M},
  journal={arXiv:2008.11904},
  year={2020}
}
@inproceedings{rahimi2007random,
  author={Ali Rahimi and Benjamin Recht},
  title={{Random Features for Large-Scale Kernel Machines}},
  year={2007},
  cdate={1167609600000},
  pages={1177-1184},
  OPTurl={http://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines},
  booktitle={NIPS}
}

@article{aubin2019committee,
  title={The committee machine: Computational to statistical gaps in learning a two-layers neural network},
  author={Aubin, Benjamin and Maillard, Antoine and Barbier, Jean and Krzakala, Florent and Macris, Nicolas and Zdeborov{\'a}, Lenka},
  journal={Journal of Statistical Mechanics: Theory and Experiment},
  volume={2019},
  number={12},
  pages={124023},
  year={2019},
  publisher={IOP Publishing}
}

@article{javanmard2013state,
  title={State evolution for general approximate message passing algorithms, with applications to spatial coupling},
  author={Javanmard, Adel and Montanari, Andrea},
  journal={Information and Inference: A Journal of the IMA},
  volume={2},
  number={2},
  pages={115--144},
  year={2013},
  publisher={OUP}
}

@article{berthier2020state,
  title={State evolution for approximate message passing with non-separable functions},
  author={Berthier, Raphael and Montanari, Andrea and Nguyen, Phan-Minh},
  journal={Information and Inference: A Journal of the IMA},
  volume={9},
  number={1},
  pages={33--79},
  year={2020},
  publisher={Oxford University Press}
}

@article{bayati2011dynamics,
  title={The dynamics of message passing on dense graphs, with applications to compressed sensing},
  author={Bayati, Mohsen and Montanari, Andrea},
  journal={IEEE Transactions on Information Theory},
  volume={57},
  number={2},
  pages={764--785},
  year={2011},
  publisher={IEEE}
}

@article{bayati2011lasso,
  title={{The LASSO risk for Gaussian matrices}},
  author={Bayati, Mohsen and Montanari, Andrea},
  journal={IEEE Transactions on Information Theory},
  volume={58},
  number={4},
  pages={1997--2017},
  year={2011},
  publisher={IEEE}
}

@book{mezard1987spin,
  title={Spin glass theory and beyond: An Introduction to the Replica Method and Its Applications},
  author={M{\'e}zard, Marc and Parisi, Giorgio and Virasoro, Miguel},
  volume={9},
  year={1987},
  publisher={World Scientific Publishing Company}
}

@article{gerbelot2020asymptotic,
  title={{Asymptotic Errors for Teacher-Student Convex Generalized Linear Models (or: How to Prove Kabashima's Replica Formula)}},
  author={Gerbelot, Cedric and Abbara, Alia and Krzakala, Florent},
  journal={Preprint arXiv:2006.06581},
  year={2020}
}

@article{parikh2014proximal,
  title={Proximal algorithms},
  author={Parikh, Neal and Boyd, Stephen},
  journal={Foundations and Trends in optimization},
  volume={1},
  number={3},
  pages={127--239},
  year={2014},
  publisher={Now Publishers Inc. Hanover, MA, USA}
}
@book{bauschke2011convex,
  title={Convex analysis and monotone operator theory in Hilbert spaces},
  author={Bauschke, Heinz H and Combettes, Patrick L and others},
  volume={408},
  year={2011},
  publisher={Springer}
}

@article{zdeborova2016statistical,
  title={Statistical physics of inference: Thresholds and algorithms},
  author={Zdeborov{\'a}, Lenka and Krzakala, Florent},
  journal={Advances in Physics},
  volume={65},
  number={5},
  pages={453--552},
  year={2016},
  publisher={Taylor \& Francis}
}

@article{celentano2020lasso,
  title={{The Lasso with general Gaussian designs with applications to hypothesis testing}},
  author={Celentano, Michael and Montanari, Andrea and Wei, Yuting},
  journal={Preprint arXiv:2007.13716},
  year={2020}
}

@article{bauschke2003bregman,
  title={Bregman monotone optimization algorithms},
  author={Bauschke, Heinz H and Borwein, Jonathan M and Combettes, Patrick L},
  journal={SIAM Journal on control and optimization},
  volume={42},
  number={2},
  pages={596--636},
  year={2003},
  publisher={SIAM}
}
@article{bauschke2018regularizing,
  title={Regularizing with Bregman--Moreau Envelopes},
  author={Bauschke, Heinz H and Dao, Minh N and Lindstrom, Scott B},
  journal={SIAM Journal on Optimization},
  volume={28},
  number={4},
  pages={3208--3228},
  year={2018},
  publisher={SIAM}
}

@article{bolthausen2014iterative,
  title={{An iterative construction of solutions of the TAP equations for the Sherrington--Kirkpatrick model}},
  author={Bolthausen, Erwin},
  journal={Communications in Mathematical Physics},
  volume={325},
  number={1},
  pages={333--366},
  year={2014},
  publisher={Springer}
}

@article{thrampoulidis2018precise,
  title={Precise error analysis of regularized $ M $-estimators in high dimensions},
  author={Thrampoulidis, Christos and Abbasi, Ehsan and Hassibi, Babak},
  journal={IEEE Transactions on Information Theory},
  volume={64},
  number={8},
  pages={5592--5628},
  year={2018},
  publisher={IEEE}
}

@article{goldt2021gaussian,
  title={The Gaussian equivalence of generative models for learning with shallow neural networks},
  author={Goldt, Sebastian and Loureiro, Bruno and Reeves, Galen and Krzakala, Florent and M{\'e}zard, Marc and Zdeborov{\'a}, Lenka},
  journal={Proceedings of Machine Learning Research},
  volume={145},
  pages={1--46},
  year={2021}
}

@article{donoho2009message,
  title={Message-passing algorithms for compressed sensing},
  author={Donoho, David L and Maleki, Arian and Montanari, Andrea},
  journal={Proceedings of the National Academy of Sciences},
  volume={106},
  number={45},
  pages={18914--18919},
  year={2009},
  publisher={National Acad Sciences}
}

@article{donoho2016high,
  title={High dimensional robust m-estimation: Asymptotic variance via approximate message passing},
  author={Donoho, David and Montanari, Andrea},
  journal={Probability Theory and Related Fields},
  volume={166},
  number={3},
  pages={935--969},
  year={2016},
  publisher={Springer}
}


@inproceedings{rangan2011generalized,
  title={Generalized approximate message passing for estimation with random linear mixing},
  author={Rangan, Sundeep},
  booktitle={2011 IEEE International Symposium on Information Theory Proceedings},
  pages={2168--2172},
  year={2011},
  organization={IEEE}
}

@article{hu2020universality,
  title={Universality laws for high-dimensional learning with random features},
  author={Hu, Hong and Lu, Yue M},
  journal={arXiv:2009.07669},
  year={2020}
}

@inproceedings{NIPS2003_0fe47339,
 author = {Rosset, Saharon and Zhu, Ji and Hastie, Trevor},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Thrun and L. Saul and B. Sch\"{o}lkopf},
 pages = {},
 publisher = {MIT Press},
 title = {Margin Maximizing Loss Functions},
 volume = {16},
 year = {2004}
}

@inproceedings{jacot2020implicit,
  title={Implicit regularization of random feature models},
  author={Jacot, Arthur and Simsek, Berfin and Spadaro, Francesco and Hongler, Cl{\'e}ment and Gabriel, Franck},
  booktitle={International Conference on Machine Learning},
  pages={4631--4640},
  year={2020},
  organization={PMLR}
}

@article{Hansen1990,
  title={Neural network ensembles},
  author={Hansen, Lars Kai and Salamon, Peter},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={12},
  number={10},
  pages={993--1001},
  year={1990},
  publisher={IEEE}
}

  
@misc{lakshminarayanan_deep_ensembles_2017,
      title={Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles}, 
      author={Balaji Lakshminarayanan and Alexander Pritzel and Charles Blundell},
      year={2017},
      eprint={1612.01474},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{malinin_ensemble_distillation_2019,
      title={Ensemble Distribution Distillation}, 
      author={Andrey Malinin and Bruno Mlodozeniec and Mark Gales},
      year={2019},
      eprint={1905.00076},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{wen_batchensemble_2020,
      title={BatchEnsemble: An Alternative Approach to Efficient Ensemble and Lifelong Learning}, 
      author={Yeming Wen and Dustin Tran and Jimmy Ba},
      year={2020},
      eprint={2002.06715},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{Bartlett30063,
	author = {Bartlett, Peter L. and Long, Philip M. and Lugosi, G{\'a}bor and Tsigler, Alexander},
	title = {Benign overfitting in linear regression},
	volume = {117},
	number = {48},
	pages = {30063--30070},
	year = {2020},
	OPTOPTdoi = {10.1073/pnas.1907378117},
	publisher = {National Academy of Sciences},
	OPTissn = {0027-8424},
	OPTURL = {https://www.pnas.org/content/117/48/30063},
	OPTeprint = {https://www.pnas.org/content/117/48/30063.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}

@misc{tsigler2020benign,
      title={Benign overfitting in ridge regression}, 
      author={Alexander Tsigler and Peter L. Bartlett},
      year={2020},
      eprint={2009.14286},
      archivePrefix={arXiv},
      primaryClass={math.ST}
}

@article{loureiro2021learning,
  title={Learning Gaussian Mixtures with Generalised Linear Models: Precise Asymptotics in High-dimensions},
  author={Loureiro, Bruno and Sicuro, Gabriele and Gerbelot, C{\'e}dric and Pacco, Alessandro and Krzakala, Florent and Zdeborov{\'a}, Lenka},
  journal={arXiv:2106.03791},
  year={2021}
}

@misc{tripuraneni2021covariate,
      title={Covariate Shift in High-Dimensional Random Feature Regression}, 
      author={Nilesh Tripuraneni and Ben Adlam and Jeffrey Pennington},
      year={2021},
      eprint={2111.08234},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{hastie2020surprises,
      title={Surprises in High-Dimensional Ridgeless Least Squares Interpolation}, 
      author={Trevor Hastie and Andrea Montanari and Saharon Rosset and Ryan J. Tibshirani},
      year={2020},
      eprint={1903.08560},
      archivePrefix={arXiv},
      primaryClass={math.ST}
}


@inproceedings{rosset2004margin,
  title={Margin maximizing loss functions},
  author={Rosset, Saharon and Zhu, Ji and Hastie, Trevor J},
  booktitle={Advances in neural information processing systems},
  pages={1237--1244},
  year={2004}
}


@misc{nakkiran2019deep,
      title={Deep Double Descent: Where Bigger Models and More Data Hurt}, 
      author={Preetum Nakkiran and Gal Kaplun and Yamini Bansal and Tristan Yang and Boaz Barak and Ilya Sutskever},
      year={2019},
      eprint={1912.02292},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{advani2017highdimensional,
      title={High-dimensional dynamics of generalization error in neural networks}, 
      author={Madhu S. Advani and Andrew M. Saxe},
      year={2017},
      eprint={1710.03667},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{Belkin2020,
   title={Two Models of Double Descent for Weak Features},
   volume={2},
   OPTISSN={2577-0187},
   OPTurl={http://dx.OPTdoi.org/10.1137/20M1336072},
   OPTDOI={10.1137/20m1336072},
   number={4},
   journal={SIAM Journal on Mathematics of Data Science},
   publisher={Society for Industrial & Applied Mathematics (SIAM)},
   author={Belkin, Mikhail and Hsu, Daniel and Xu, Ji},
   year={2020},
   month={Jan},
   pages={1167–1180}
}

@article {Loog10625,
	author = {Loog, Marco and Viering, Tom and Mey, Alexander and Krijthe, Jesse H. and Tax, David M. J.},
	title = {A brief prehistory of double descent},
	volume = {117},
	number = {20},
	pages = {10625--10626},
	year = {2020},
	OPTdoi = {10.1073/pnas.2001875117},
	publisher = {National Academy of Sciences},
	OPTissn = {0027-8424},
	URL = {https://www.pnas.org/content/117/20/10625},
	eprint = {https://www.pnas.org/content/117/20/10625.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}

@article {Belkin10627,
	author = {Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
	title = {Reply to Loog et al.: Looking beyond the peaking phenomenon},
	volume = {117},
	number = {20},
	pages = {10627--10627},
	year = {2020},
	OPTdoi = {10.1073/pnas.2003206117},
	publisher = {National Academy of Sciences},
	OPTissn = {0027-8424},
	eprint = {https://www.pnas.org/content/117/20/10627.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}

@inproceedings{NIPS1996_25df35de,
 author = {B\"{o}s, Siegfried and Opper, Manfred},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. C. Mozer and M. Jordan and T. Petsche},
 pages = {},
 publisher = {MIT Press},
 title = {Dynamics of Training},
 OPTurl = {https://proceedings.neurips.cc/paper/1996/file/25df35de87aa441b88f22a6c2a830a17-Paper.pdf},
 volume = {9},
 year = {1997}
}

@article{Opper_1990,
	OPTdoi = {10.1088/0305-4470/23/11/012},
	OPTurl = {https://OPTdoi.org/10.1088/0305-4470/23/11/012},
	year = 1990,
	month = {jun},
	publisher = {{IOP} Publishing},
	volume = {23},
	number = {11},
	pages = {L581--L586},
	author = {M Opper and W Kinzel and J Kleinz and R Nehl},
	title = {On the ability of the optimal perceptron to generalise},
	journal = {Journal of Physics A: Mathematical and General},
	abstract = {A linearly separable Boolean function is derived from a set of examples by a perceptron with optimal stability. The probability to reconstruct a pattern which is not learnt is calculated analytically using the replica method.}
}

@misc{zhang2017understanding,
      title={Understanding deep learning requires rethinking generalization}, 
      author={Chiyuan Zhang and Samy Bengio and Moritz Hardt and Benjamin Recht and Oriol Vinyals},
      year={2017},
      eprint={1611.03530},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{Tallis1962,
 ISSN = {00359246},
 author = {G. M. Tallis},
 journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
 number = {2},
 pages = {530--534},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {The Use of a Generalized Multinomial Distribution in the Estimation of Correlation in Discrete Data},
 volume = {24},
 year = {1962}
}

@article{Diniz2010,
author = {Carlos A. R. Diniz and Marcelo H. Tutia and Jose G. Leite},
title = {{Bayesian analysis of a correlated binomial model}},
volume = {24},
journal = {Brazilian Journal of Probability and Statistics},
number = {1},
publisher = {Brazilian Statistical Association},
pages = {68 -- 77},
keywords = {Bayesian inference, Correlated binomial distribution, data augmentation method, MCMC methods},
year = {2010},
doi = {10.1214/08-BJPS014}
}
@article {Belkin15849,
	author = {Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
	title = {Reconciling modern machine-learning practice and the classical bias{\textendash}variance trade-off},
	volume = {116},
	number = {32},
	pages = {15849--15854},
	year = {2019},
	OPTdoi = {10.1073/pnas.1903070116},
	publisher = {National Academy of Sciences},
	OPTissn = {0027-8424},
	eprint = {https://www.pnas.org/content/116/32/15849.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}


@article{drucker1994boosting,
  title={Boosting and other ensemble methods},
  author={Drucker, Harris and Cortes, Corinna and Jackel, Lawrence D and LeCun, Yann and Vapnik, Vladimir},
  journal={Neural computation},
  volume={6},
  number={6},
  pages={1289--1301},
  year={1994},
  publisher={MIT Press}
}

@inproceedings{NEURIPS2019_ae614c55,
 author = {Chizat, L\'{e}na\"{\i}c and Oyallon, Edouard and Bach, Francis},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {On Lazy Training in Differentiable Programming},
 volume = {32},
 year = {2019}
}


@article{arora2019harnessing,
  title={Harnessing the Power of Infinitely Wide Deep Nets on Small-data Tasks},
  author={Arora, Sanjeev and Du, Simon S and Li, Zhiyuan and Salakhutdinov, Ruslan and Wang, Ruosong and Yu, Dingli},
  journal={arXiv preprint arXiv:1910.01663},
  year={2019}
}

@article{arora2019exact,
  title={On exact computation with an infinitely wide neural net},
  author={Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Ruslan and Wang, Ruosong},
  journal={arXiv preprint arXiv:1904.11955},
  year={2019}
}


@inproceedings{NEURIPS2018_5a4be1fa,
 author = {Jacot, Arthur and Gabriel, Franck and Hongler, Clement},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Neural Tangent Kernel: Convergence and Generalization in Neural Networks},
 volume = {31},
 year = {2018}
}

@article{mei2018mean,
  title={A mean field view of the landscape of two-layer neural networks},
  author={Mei, Song and Montanari, Andrea and Nguyen, Phan-Minh},
  journal={Proceedings of the National Academy of Sciences},
  volume={115},
  number={33},
  pages={E7665--E7671},
  year={2018},
  publisher={National Acad Sciences}
}
@article{mei2020generalization,
author = {Mei, Song and Montanari, Andrea},
title = {The Generalization Error of Random Features Regression: Precise Asymptotics and the Double Descent Curve},
journal = {Communications on Pure and Applied Mathematics},
pages = {},
year = {2021}
}

@InProceedings{pmlr-v119-gerace20a,
  title = 	 {Generalisation error in learning with random features and the hidden manifold model},
  author =       {Gerace, Federica and Loureiro, Bruno and Krzakala, Florent and Mezard, Marc and Zdeborova, Lenka},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {3452--3462},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/gerace20a/gerace20a.pdf}
}

@article{PhysRevX.10.041044,
  title = {Modeling the Influence of Data Structure on Learning in Neural Networks: The Hidden Manifold Model},
  author = {Goldt, Sebastian and M\'ezard, Marc and Krzakala, Florent and Zdeborov\'a, Lenka},
  journal = {Physical Review X},
  volume = {10},
  issue = {4},
  pages = {041044},
  numpages = {32},
  year = {2020},
  month = {Dec},
  publisher = {American Physical Society}
}

@article{geman1992neural,
  title={Neural networks and the bias/variance dilemma},
  author={Geman, Stuart and Bienenstock, Elie and Doursat, Ren{\'e}},
  journal={Neural computation},
  volume={4},
  number={1},
  pages={1--58},
  year={1992},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@inproceedings{NIPS2017_0f3d014e,
 author = {Pennington, Jeffrey and Worah, Pratik},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Nonlinear random matrix theory for deep learning},
 volume = {30},
 year = {2017}
}



@article{neal2018modern,
  title={A modern take on the bias-variance tradeoff in neural networks},
  author={Neal, Brady and Mittal, Sarthak and Baratin, Aristide and Tantia, Vinayak and Scicluna, Matthew and Lacoste-Julien, Simon and Mitliagkas, Ioannis},
  journal={arXiv preprint arXiv:1810.08591},
  year={2018}
}


@article{chen2020multiple,
  title={Multiple descent: Design your own generalization curve},
  author={Chen, Lin and Min, Yifei and Belkin, Mikhail and Karbasi, Amin},
  journal={arXiv preprint arXiv:2008.01036},
  year={2020}
}

@misc{lee2018deep,
      title={Deep Neural Networks as Gaussian Processes}, 
      author={Jaehoon Lee and Yasaman Bahri and Roman Novak and Samuel S. Schoenholz and Jeffrey Pennington and Jascha Sohl-Dickstein},
      year={2018},
      eprint={1711.00165},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@Inbook{Schapire2003,
author="Schapire, Robert E.",
editor="Denison, David D.
and Hansen, Mark H.
and Holmes, Christopher C.
and Mallick, Bani
and Yu, Bin",
title="The Boosting Approach to Machine Learning: An Overview",
bookTitle="Nonlinear Estimation and Classification",
year="2003",
publisher="Springer New York",
address="New York, NY",
pages="149--171",
isbn="978-0-387-21579-2",
doi="10.1007/978-0-387-21579-2_9",
}



@inproceedings{adlam2020neural,
  title={The neural tangent kernel in high dimensions: Triple descent and a multi-scale theory of generalization},
  author={Adlam, Ben and Pennington, Jeffrey},
  booktitle={International Conference on Machine Learning},
  pages={74--84},
  year={2020},
  organization={PMLR}
}

@article{PhysRevLett.75.2432,
  title = {Weight Space Structure and Internal Representations: A Direct Approach to Learning and Generalization in Multilayer Neural Networks},
  author = {Monasson, R\'emi and Zecchina, Riccardo},
  journal = {Phys. Rev. Lett.},
  volume = {75},
  issue = {12},
  pages = {2432--2435},
  numpages = {0},
  year = {1995},
  month = {Sep},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.75.2432},
}

@article{Schwarze1992,
	year = 1992,
	month = {oct},
	publisher = {{IOP} Publishing},
	volume = {20},
	number = {4},
	pages = {375--380},
	author = {H Schwarze and J Hertz},
	title = {Generalization in a Large Committee Machine},
	journal = {Europhysics Letters ({EPL})},
}

@article{Sompolinsky1990,
	doi = {10.1209/0295-5075/13/6/016},
	year = 1990,
	month = {nov},
	publisher = {{IOP} Publishing},
	volume = {13},
	number = {6},
	pages = {567--572},
	author = {H Sompolinsky and N Tishby},
	title = {Learning in a Two-Layer Neural Network of Edge Detectors},
	journal = {Europhysics Letters ({EPL})},
}


@article{PhysRevLett.72.2113,
  title = {Learning and generalization in a two-layer neural network: The role of the Vapnik-Chervonvenkis dimension},
  author = {Opper, Manfred},
  journal = {Phys. Rev. Lett.},
  volume = {72},
  issue = {13},
  pages = {2113--2116},
  numpages = {0},
  year = {1994},
  month = {Mar},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.72.2113},
}


@article{schapire1990strength,
  title={The strength of weak learnability},
  author={Schapire, Robert E},
  journal={Machine learning},
  volume={5},
  number={2},
  pages={197--227},
  year={1990},
  publisher={Springer}
}

@article{dAscoli_2021,
	year = 2021,
	month = {dec},
	publisher = {{IOP} Publishing},
	volume = {2021},
	number = {12},
	pages = {124002},
	author = {St{\'{e}}phane d'Ascoli and Levent Sagun and Giulio Biroli},
	title = {Triple descent and the two kinds of overfitting: where and why do they appear?},
	journal = {Journal of Statistical Mechanics: Theory and Experiment}
}

@article{Spigler_2019,
	year = 2019,
	month = {oct},
	publisher = {{IOP} Publishing},
	volume = {52},
	number = {47},
	pages = {474001},
	author = {Stefano Spigler and Mario Geiger and Stephane d'Ascoli and Levent Sagun and Giulio Biroli and Matthieu Wyart},
	title = {A jamming transition from under- to over-parametrization affects generalization in deep learning},
	journal = {Journal of Physics A: Mathematical and Theoretical}
}


@incollection{bottou2012stochastic,
  title={Stochastic gradient descent tricks},
  author={Bottou, L{\'e}on},
  booktitle={Neural networks: Tricks of the trade},
  pages={421--436},
  year={2012},
  publisher={Springer}
}

@article{narkhede2021review,
  title={A review on weight initialization strategies for neural networks},
  author={Narkhede, Meenal V and Bartakke, Prashant P and Sutaone, Mukul S},
  journal={Artificial intelligence review},
  pages={1--32},
  year={2021},
  publisher={Springer}
}

@article{geiger2020scaling,
  title={Scaling description of generalization with number of parameters in deep learning},
  author={Geiger, Mario and Jacot, Arthur and Spigler, Stefano and Gabriel, Franck and Sagun, Levent and d’Ascoli, St{\'e}phane and Biroli, Giulio and Hongler, Cl{\'e}ment and Wyart, Matthieu},
  journal={Journal of Statistical Mechanics: Theory and Experiment},
  volume={2020},
  number={2},
  pages={023401},
  year={2020},
  publisher={IOP Publishing}
}


@article{geiger2019disentangling,
  title={Disentangling feature and lazy learning in deep neural networks: an empirical study},
  author={Geiger, Mario and Spigler, Stefano and Jacot, Arthur and Wyart, Matthieu},
  journal={arXiv preprint arXiv:1906.08034},
  year={2019}
}


@inproceedings{NEURIPS2020_7d420e2b,
 author = {Adlam, Ben and Pennington, Jeffrey},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {11022--11032},
 publisher = {Curran Associates, Inc.},
 title = {Understanding Double Descent Requires A Fine-Grained Bias-Variance Decomposition},
 volume = {33},
 year = {2020}
}

@InProceedings{dascoli2020,
  title = 	 {Double Trouble in Double Descent: Bias and Variance(s) in the Lazy Regime},
  author =       {D'Ascoli, St{\'e}phane and Refinetti, Maria and Biroli, Giulio and Krzakala, Florent},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {2280--2290},
  year = 	 {2020},
  editor = 	 {Daum\'e III, Hal and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/d-ascoli20a/d-ascoli20a.pdf}
  }

@article{JMLR:v22:20-1211,
  author  = {Licong Lin and Edgar Dobriban},
  title   = {{What Causes the Test Error? Going Beyond Bias-Variance via ANOVA}},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {155},
  pages   = {1-82}
}

@article{bauschke2006joint,
  title={Joint minimization with alternating Bregman proximity operators},
  author={Bauschke, Heinz and Combettes, Patrick and Noll, Dominikus},
  journal={Pacific Journal of Optimization},
  year={2006}
}

@book{vershynin2018high,
  title={High-dimensional probability: An introduction with applications in data science},
  author={Vershynin, Roman},
  volume={47},
  year={2018},
  publisher={Cambridge university press}
}

@article{vershynin2010introduction,
  title={Introduction to the non-asymptotic analysis of random matrices},
  author={Vershynin, Roman},
  journal={arXiv:1011.3027},
  year={2010}
}

@inproceedings{NIPS1993_0537fb40,
 author = {Perrone, Michael},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Cowan and G. Tesauro and J. Alspector},
 pages = {},
 publisher = {Morgan-Kaufmann},
 title = {Putting It All Together: Methods for Combining Neural Networks},
 volume = {6},
 year = {1994}
}

@INPROCEEDINGS{Perrone93whennetworks,
    author = {Michael P. Perrone and Leaon N. Cooper},
    title = {When Networks Disagree: Ensemble Methods for Hybrid Neural Networks},
    booktitle = {},
    year = {1993},
    pages = {126--142},
    publisher = {Chapman and Hall}
}

@inproceedings{NIPS1994_b8c37e33,
 author = {Krogh, Anders and Vedelsby, Jesper},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {G. Tesauro and D. Touretzky and T. Leen},
 pages = {},
 publisher = {MIT Press},
 title = {Neural Network Ensembles, Cross Validation, and Active Learning},
 volume = {7},
 year = {1995}
}


