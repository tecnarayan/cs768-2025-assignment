\begin{thebibliography}{10}

\bibitem{andreas2019good}
J.~Andreas.
\newblock Good-enough compositional data augmentation.
\newblock In {\em Proceedings of the 58th Annual Meeting of the Association for
  Computational Linguistics}, 2020.

\bibitem{angluin1987learning}
D.~Angluin.
\newblock Learning regular sets from queries and counterexamples.
\newblock {\em Information and computation}, 75(2):87--106, 1987.

\bibitem{bahdanau2014neural}
D.~Bahdanau, K.~Cho, and Y.~Bengio.
\newblock Neural machine translation by jointly learning to align and
  translate.
\newblock In {\em International Conference on Learning Representations}, 2015.

\bibitem{bahdanau2019closure}
D.~Bahdanau, H.~de~Vries, T.~J. O'Donnell, S.~Murty, P.~Beaudoin, Y.~Bengio,
  and A.~Courville.
\newblock Closure: Assessing systematic generalization of clevr models.
\newblock {\em arXiv preprint arXiv:1912.05783}, 2019.

\bibitem{bod2006all}
R.~Bod.
\newblock An all-subtrees approach to unsupervised parsing.
\newblock In {\em Proceedings of the 21st International Conference on
  Computational Linguistics and the 44th annual meeting of the Association for
  Computational Linguistics}, pages 865--872. Association for Computational
  Linguistics, 2006.

\bibitem{cai2016making}
J.~Cai, R.~Shin, and D.~Song.
\newblock Making neural programming architectures generalize via recursion.
\newblock In {\em ICLR}, 2017.

\bibitem{chang2018automatically}
M.~B. Chang, A.~Gupta, S.~Levine, and T.~L. Griffiths.
\newblock Automatically composing representation transformations as a means for
  generalization.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{chen2017towards}
X.~Chen, C.~Liu, and D.~Song.
\newblock Towards synthesizing complex programs from input-output examples.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{chomsky2002syntactic}
N.~Chomsky and D.~W. Lightfoot.
\newblock {\em Syntactic structures}.
\newblock Walter de Gruyter, 2002.

\bibitem{cross2016span}
J.~Cross and L.~Huang.
\newblock Span-based constituency parsing with a structure-label system and
  provably optimal dynamic oracles.
\newblock In {\em Proceedings of the 2016 Conference on Empirical Methods in
  Natural Language Processing}, pages 1--11, 2016.

\bibitem{de2010grammatical}
C.~De~la Higuera.
\newblock {\em Grammatical inference: learning automata and grammars}.
\newblock Cambridge University Press, 2010.

\bibitem{dessi2019cnns}
R.~Dess{\`\i} and M.~Baroni.
\newblock Cnns found to jump around more skillfully than rnns: Compositional
  generalization in seq2seq convolutional networks.
\newblock In {\em Proceedings of the 57th Annual Meeting of the Association for
  Computational Linguistics}, pages 3919--3923, 2019.

\bibitem{devlin2018bert}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock {\em arXiv preprint arXiv:1810.04805}, 2018.

\bibitem{dong2019neural}
H.~Dong, J.~Mao, T.~Lin, C.~Wang, L.~Li, and D.~Zhou.
\newblock Neural logic machines.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{dong2016language}
L.~Dong and M.~Lapata.
\newblock Language to logical form with neural attention.
\newblock In {\em ACL}, 2016.

\bibitem{gordon2019permutation}
J.~Gordon, D.~Lopez-Paz, M.~Baroni, and D.~Bouchacourt.
\newblock Permutation equivariant models for compositional generalization in
  language.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{graves2014neural}
A.~Graves, G.~Wayne, and I.~Danihelka.
\newblock Neural turing machines.
\newblock {\em arXiv preprint arXiv:1410.5401}, 2014.

\bibitem{grefenstette2015learning}
E.~Grefenstette, K.~M. Hermann, M.~Suleyman, and P.~Blunsom.
\newblock Learning to transduce with unbounded memory.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1828--1836, 2015.

\bibitem{hochreiter1997long}
S.~Hochreiter and J.~Schmidhuber.
\newblock Long short-term memory.
\newblock {\em Neural computation}, 9(8):1735--1780, 1997.

\bibitem{hudson2018compositional}
D.~A. Hudson and C.~D. Manning.
\newblock Compositional attention networks for machine reasoning.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{johnson2017clevr}
J.~Johnson, B.~Hariharan, L.~van~der Maaten, L.~Fei-Fei, C.~Lawrence~Zitnick,
  and R.~Girshick.
\newblock Clevr: A diagnostic dataset for compositional language and elementary
  visual reasoning.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 2901--2910, 2017.

\bibitem{joulin2015inferring}
A.~Joulin and T.~Mikolov.
\newblock Inferring algorithmic patterns with stack-augmented recurrent nets.
\newblock In {\em Advances in Neural Information Processing Systems}, 2015.

\bibitem{kaiser2015neural}
{\L}.~Kaiser and I.~Sutskever.
\newblock Neural gpus learn algorithms.
\newblock {\em arXiv preprint arXiv:1511.08228}, 2015.

\bibitem{keysers2019measuring}
D.~Keysers, N.~Sch{\"a}rli, N.~Scales, H.~Buisman, D.~Furrer, S.~Kashubin,
  N.~Momchev, D.~Sinopalnikov, L.~Stafiniak, T.~Tihon, et~al.
\newblock Measuring compositional generalization: A comprehensive method on
  realistic data.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{kurach2015neural}
K.~Kurach, M.~Andrychowicz, and I.~Sutskever.
\newblock Neural random-access machines.
\newblock {\em arXiv preprint arXiv:1511.06392}, 2015.

\bibitem{lake2018generalization}
B.~Lake and M.~Baroni.
\newblock Generalization without systematicity: On the compositional skills of
  sequence-to-sequence recurrent networks.
\newblock In {\em International Conference on Machine Learning}, pages
  2873--2882, 2018.

\bibitem{lake2019compositional}
B.~M. Lake.
\newblock Compositional generalization through meta sequence-to-sequence
  learning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  9788--9798, 2019.

\bibitem{lake2019human}
B.~M. Lake, T.~Linzen, and M.~Baroni.
\newblock Human few-shot learning of compositional instructions.
\newblock {\em arXiv preprint arXiv:1901.04587}, 2019.

\bibitem{lake2017building}
B.~M. Lake, T.~D. Ullman, J.~B. Tenenbaum, and S.~J. Gershman.
\newblock Building machines that learn and think like people.
\newblock {\em Behavioral and brain sciences}, 40, 2017.

\bibitem{li2019compositional}
Y.~Li, L.~Zhao, J.~Wang, and J.~Hestness.
\newblock Compositional generalization for primitive substitutions.
\newblock In {\em Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, pages 4284--4293, 2019.

\bibitem{liu2017shift}
J.~Liu and Y.~Zhang.
\newblock Shift-reduce constituent parsing with neural lookahead features.
\newblock {\em Transactions of the Association for Computational Linguistics},
  5:45--58, 2017.

\bibitem{loula2018rearranging}
J.~Loula, M.~Baroni, and B.~M. Lake.
\newblock Rearranging the familiar: Testing compositional generalization in
  recurrent networks.
\newblock {\em arXiv preprint arXiv:1807.07545}, 2018.

\bibitem{lu2019neurally}
S.~Lu, J.~Mao, J.~B. Tenenbaum, and J.~Wu.
\newblock Neurally-guided structure inference.
\newblock In {\em International Conference on Machine Learning}, 2019.

\bibitem{mao2019neuro}
J.~Mao, C.~Gan, P.~Kohli, J.~B. Tenenbaum, and J.~Wu.
\newblock The neuro-symbolic concept learner: Interpreting scenes, words, and
  sentences from natural supervision.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{misra2016neural}
D.~Misra and Y.~Artzi.
\newblock Neural shift-reduce ccg semantic parsing.
\newblock In {\em Proceedings of the 2016 conference on empirical methods in
  natural language processing}, pages 1775--1786, 2016.

\bibitem{montague1970universal}
R.~Montague.
\newblock Universal grammar.
\newblock {\em Theoria}, 36(3):373--398, 1970.

\bibitem{nikolaus2019compositional}
M.~Nikolaus, M.~Abdou, M.~Lamm, R.~Aralikatte, and D.~Elliott.
\newblock Compositional generalization in image captioning.
\newblock In {\em Proceedings of the 23rd Conference on Computational Natural
  Language Learning (CoNLL)}, pages 87--98, 2019.

\bibitem{nye2020learning}
M.~I. Nye, A.~Solar-Lezama, J.~B. Tenenbaum, and B.~M. Lake.
\newblock Learning compositional rules via neural program synthesis.
\newblock {\em arXiv preprint arXiv:2003.05562}, 2020.

\bibitem{pierrot2019learning}
T.~Pierrot, G.~Ligner, S.~E. Reed, O.~Sigaud, N.~Perrin, A.~Laterre, D.~Kas,
  K.~Beguir, and N.~de~Freitas.
\newblock Learning compositional neural programs with recursive tree search and
  planning.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  14646--14656, 2019.

\bibitem{reed2015neural}
S.~Reed and N.~De~Freitas.
\newblock Neural programmer-interpreters.
\newblock In {\em ICLR}, 2016.

\bibitem{ruis2020benchmark}
L.~Ruis, J.~Andreas, M.~Baroni, D.~Bouchacourt, and B.~M. Lake.
\newblock A benchmark for systematic generalization in grounded language
  understanding.
\newblock {\em arXiv preprint arXiv:2003.05161}, 2020.

\bibitem{russin2019compositional}
J.~Russin, J.~Jo, R.~C. O'Reilly, and Y.~Bengio.
\newblock Compositional generalization in a deep seq2seq model by separating
  syntax and semantics.
\newblock {\em arXiv preprint arXiv:1904.09708}, 2019.

\bibitem{steedman2000syntactic}
M.~Steedman.
\newblock {\em The syntactic process}, volume~24.
\newblock MIT press Cambridge, MA, 2000.

\bibitem{vaswani2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  {\L}.~Kaiser, and I.~Polosukhin.
\newblock Attention is all you need.
\newblock In {\em Advances in neural information processing systems}, pages
  5998--6008, 2017.

\bibitem{vedantam2019probabilistic}
R.~Vedantam, K.~Desai, S.~Lee, M.~Rohrbach, D.~Batra, and D.~Parikh.
\newblock Probabilistic neural symbolic models for interpretable visual
  question answering.
\newblock In {\em International Conference on Machine Learning}, pages
  6428--6437, 2019.

\bibitem{vinyals2015pointer}
O.~Vinyals, M.~Fortunato, and N.~Jaitly.
\newblock Pointer networks.
\newblock In {\em Advances in neural information processing systems}, pages
  2692--2700, 2015.

\bibitem{vinyals2015grammar}
O.~Vinyals, {\L}.~Kaiser, T.~Koo, S.~Petrov, I.~Sutskever, and G.~Hinton.
\newblock Grammar as a foreign language.
\newblock In {\em Advances in Neural Information Processing Systems}, 2015.

\bibitem{wiseman2016sequence}
S.~Wiseman and A.~M. Rush.
\newblock Sequence-to-sequence learning as beam-search optimization.
\newblock In {\em EMNLP}, 2016.

\bibitem{xiao2018improving}
D.~Xiao, J.-Y. Liao, and X.~Yuan.
\newblock Improving the universality and learnability of neural
  programmer-interpreters with combinator abstraction.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{yi2018neural}
K.~Yi, J.~Wu, C.~Gan, A.~Torralba, P.~Kohli, and J.~Tenenbaum.
\newblock Neural-symbolic vqa: Disentangling reasoning from vision and language
  understanding.
\newblock In {\em Advances in neural information processing systems}, pages
  1031--1042, 2018.

\bibitem{zaremba2016learning}
W.~Zaremba, T.~Mikolov, A.~Joulin, and R.~Fergus.
\newblock Learning simple algorithms from examples.
\newblock In {\em Proceedings of The 33rd International Conference on Machine
  Learning}, pages 421--429, 2016.

\bibitem{zaremba2015reinforcement}
W.~Zaremba and I.~Sutskever.
\newblock Reinforcement learning neural turing machines-revised.
\newblock {\em arXiv preprint arXiv:1505.00521}, 2015.

\end{thebibliography}
