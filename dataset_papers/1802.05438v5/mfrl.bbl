\begin{thebibliography}{51}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bertsekas(2012)]{bertsekas2012weighted}
Bertsekas, D.~P.
\newblock Weighted sup-norm contractions in dynamic programming: A review and
  some new applications.
\newblock \emph{Dept. Elect. Eng. Comput. Sci., Massachusetts Inst. Technol.,
  Cambridge, MA, USA, Tech. Rep. LIDS-P-2884}, 2012.

\bibitem[Binder et~al.(1993)Binder, Heermann, Roelofs, Mallinckrodt, and
  McKay]{binder1993monte}
Binder, K., Heermann, D., Roelofs, L., Mallinckrodt, A.~J., and McKay, S.
\newblock Monte carlo simulation in statistical physics.
\newblock \emph{Computers in Physics}, 7\penalty0 (2):\penalty0 156--157, 1993.

\bibitem[Blume(1993)]{blume1993statistical}
Blume, L.~E.
\newblock The statistical mechanics of strategic interaction.
\newblock \emph{Games and economic behavior}, 5\penalty0 (3):\penalty0
  387--424, 1993.

\bibitem[Bowling \& Veloso(2001)Bowling and Veloso]{bowling2001rational}
Bowling, M. and Veloso, M.
\newblock Rational and convergent learning in stochastic games.
\newblock In \emph{International joint conference on artificial intelligence},
  volume~17, pp.\  1021--1026. Lawrence Erlbaum Associates Ltd, 2001.

\bibitem[Bowling \& Veloso(2002)Bowling and Veloso]{bowling2002multiagent}
Bowling, M. and Veloso, M.
\newblock Multiagent learning using a variable learning rate.
\newblock \emph{Artificial Intelligence}, 136\penalty0 (2):\penalty0 215--250,
  2002.

\bibitem[Busoniu et~al.(2008)Busoniu, Babuska, and
  De~Schutter]{busoniu2008comprehensive}
Busoniu, L., Babuska, R., and De~Schutter, B.
\newblock A comprehensive survey of multiagent reinforcement learning.
\newblock \emph{IEEE Trans. Systems, Man, and Cybernetics, Part C}, 38\penalty0
  (2):\penalty0 156--172, 2008.

\bibitem[Cao et~al.(2007)Cao, Qin, Liu, Tsai, and Li]{cao2007learning}
Cao, Z., Qin, T., Liu, T.-Y., Tsai, M.-F., and Li, H.
\newblock Learning to rank: from pairwise approach to listwise approach.
\newblock In \emph{Proceedings of the 24th international conference on Machine
  learning}, pp.\  129--136. ACM, 2007.

\bibitem[Colby et~al.(2015)Colby, Kharaghani, HolmesParker, and
  Tumer]{colby2015counterfactual}
Colby, M.~K., Kharaghani, S., HolmesParker, C., and Tumer, K.
\newblock Counterfactual exploration for improving multiagent learning.
\newblock In \emph{Proceedings of the 2015 International Conference on
  Autonomous Agents and Multiagent Systems}, pp.\  171--179. International
  Foundation for Autonomous Agents and Multiagent Systems, 2015.

\bibitem[de~Cote \& Littman(2008)de~Cote and Littman]{DBLP:conf/uai/CoteL08}
de~Cote, E.~M. and Littman, M.~L.
\newblock A polynomial-time nash equilibrium algorithm for repeated stochastic
  games.
\newblock In McAllester, D.~A. and Myllym{\"{a}}ki, P. (eds.), \emph{{UAI}
  2008}, pp.\  419--426. {AUAI} Press, 2008.
\newblock ISBN 0-9749039-4-9.

\bibitem[Fink et~al.(1964)]{fink1964equilibrium}
Fink, A.~M. et~al.
\newblock Equilibrium in a stochastic $ n $-person game.
\newblock \emph{Journal of science of the hiroshima university, series ai
  (mathematics)}, 28\penalty0 (1):\penalty0 89--93, 1964.

\bibitem[Foerster et~al.(2017)Foerster, Chen, Al{-}Shedivat, Whiteson, Abbeel,
  and Mordatch]{DBLP:journals/corr/abs-1709-04326}
Foerster, J.~N., Chen, R.~Y., Al{-}Shedivat, M., Whiteson, S., Abbeel, P., and
  Mordatch, I.
\newblock Learning with opponent-learning awareness.
\newblock \emph{CoRR}, abs/1709.04326, 2017.

\bibitem[Foerster et~al.(2018)Foerster, Farquhar, Afouras, Nardelli, and
  Whiteson]{comafoerster}
Foerster, J.~N., Farquhar, G., Afouras, T., Nardelli, N., and Whiteson, S.
\newblock Counterfactual multi-agent policy gradients.
\newblock In  \citet{DBLP:conf/aaai/2018}.

\bibitem[Galam \& Walliser(2010)Galam and
  Walliser]{RePEc:eee:phsmap:v:389:y:2010:i:3:p:481-489}
Galam, S. and Walliser, B.
\newblock Ising model versus normal form game.
\newblock \emph{Physica A: Statistical Mechanics and its Applications},
  389\penalty0 (3):\penalty0 481--489, 2010.

\bibitem[Gupta et~al.(2017)Gupta, Egorov, and
  Kochenderfer]{gupta2017cooperative}
Gupta, J.~K., Egorov, M., and Kochenderfer, M.
\newblock Cooperative multi-agent control using deep reinforcement learning.
\newblock In \emph{AAMAS}, pp.\  66--83. Springer, 2017.

\bibitem[Hasselt(2010)]{hasselt2010double}
Hasselt, H.~V.
\newblock Double q-learning.
\newblock In \emph{NIPS}, pp.\  2613--2621, 2010.

\bibitem[He \& Boyd{-}Graber(2016)He and Boyd{-}Graber]{DBLP:conf/icml/HeB16}
He, H. and Boyd{-}Graber, J.~L.
\newblock Opponent modeling in deep reinforcement learning.
\newblock In Balcan, M. and Weinberger, K.~Q. (eds.), \emph{ICML}, volume~48,
  pp.\  1804--1813. JMLR.org, 2016.

\bibitem[HolmesParker et~al.(2014)HolmesParker, Taylor, Zhan, and
  Tumer]{holmesparker2014exploiting}
HolmesParker, C., Taylor, M., Zhan, Y., and Tumer, K.
\newblock Exploiting structure and agent-centric rewards to promote
  coordination in large multiagent systems.
\newblock In \emph{Adaptive and Learning Agents Workshop}, 2014.

\bibitem[Hu \& Wellman(2003)Hu and Wellman]{hu2003nash}
Hu, J. and Wellman, M.~P.
\newblock Nash q-learning for general-sum stochastic games.
\newblock \emph{Journal of machine learning research}, 4\penalty0
  (Nov):\penalty0 1039--1069, 2003.

\bibitem[Huang et~al.(2006)Huang, Malham{\'e}, Caines, et~al.]{huang2006large}
Huang, M., Malham{\'e}, R.~P., Caines, P.~E., et~al.
\newblock Large population stochastic dynamic games: closed-loop mckean-vlasov
  systems and the nash certainty equivalence principle.
\newblock \emph{Communications in Information \& Systems}, 6\penalty0
  (3):\penalty0 221--252, 2006.

\bibitem[Ising(1925)]{ising1925beitrag}
Ising, E.
\newblock Beitrag zur theorie des ferromagnetismus.
\newblock \emph{Zeitschrift f{\"u}r Physik}, 31\penalty0 (1):\penalty0
  253--258, 1925.

\bibitem[Jaakkola et~al.(1994)Jaakkola, Jordan, and
  Singh]{jaakkola1994convergence}
Jaakkola, T., Jordan, M.~I., and Singh, S.~P.
\newblock Convergence of stochastic iterative dynamic programming algorithms.
\newblock In \emph{NIPS}, pp.\  703--710, 1994.

\bibitem[Jeong et~al.(2015)Jeong, Kang, and Kim]{jeong2015analysis}
Jeong, S.~H., Kang, A.~R., and Kim, H.~K.
\newblock Analysis of game bot's behavioral characteristics in social
  interaction networks of mmorpg.
\newblock In \emph{ACM SIGCOMM Computer Communication Review}, volume~45, pp.\
  99--100. ACM, 2015.

\bibitem[Kapetanakis \& Kudenko(2002)Kapetanakis and
  Kudenko]{Kapetanakis:2002:RLC:777092.777145}
Kapetanakis, S. and Kudenko, D.
\newblock Reinforcement learning of coordination in cooperative multi-agent
  systems.
\newblock In \emph{NCAI}, pp.\  326--331, Menlo Park, CA, USA, 2002.
\newblock ISBN 0-262-51129-0.

\bibitem[Konda \& Tsitsiklis(2000)Konda and Tsitsiklis]{NIPS1999_1786}
Konda, V.~R. and Tsitsiklis, J.~N.
\newblock Actor-critic algorithms.
\newblock In Solla, S.~A., Leen, T.~K., and M\"{u}ller, K. (eds.),
  \emph{Advances in Neural Information Processing Systems 12}, pp.\
  1008--1014. MIT Press, 2000.

\bibitem[Kreyszig(1978)]{kreyszig1978introductory}
Kreyszig, E.
\newblock \emph{Introductory functional analysis with applications}, volume~1.
\newblock wiley New York, 1978.

\bibitem[Lasry \& Lions(2007)Lasry and Lions]{lasry2007mean}
Lasry, J.-M. and Lions, P.-L.
\newblock Mean field games.
\newblock \emph{Japanese journal of mathematics}, 2\penalty0 (1):\penalty0
  229--260, 2007.

\bibitem[Lemke \& Howson(1964)Lemke and Howson]{lemke1964equilibrium}
Lemke, C.~E. and Howson, Jr, J.~T.
\newblock Equilibrium points of bimatrix games.
\newblock \emph{Journal of the Society for Industrial and Applied Mathematics},
  12\penalty0 (2):\penalty0 413--423, 1964.

\bibitem[Littman(1994)]{littman1994markov}
Littman, M.~L.
\newblock Markov games as a framework for multi-agent reinforcement learning.
\newblock In \emph{ICML}, volume 157, pp.\  157--163, 1994.

\bibitem[Littman(2001)]{littman2001friend}
Littman, M.~L.
\newblock Friend-or-foe q-learning in general-sum games.
\newblock In \emph{ICML}, volume~1, pp.\  322--328, 2001.

\bibitem[Littman \& Stone(2005)Littman and Stone]{littman2005polynomial}
Littman, M.~L. and Stone, P.
\newblock A polynomial-time nash equilibrium algorithm for repeated games.
\newblock \emph{Decision Support Systems}, 39\penalty0 (1):\penalty0 55--66,
  2005.

\bibitem[Lowe et~al.(2017{\natexlab{a}})Lowe, Wu, Tamar, Harb, Abbeel, and
  Mordatch]{lowe2017multi}
Lowe, R., Wu, Y., Tamar, A., Harb, J., Abbeel, O.~P., and Mordatch, I.
\newblock Multi-agent actor-critic for mixed cooperative-competitive
  environments.
\newblock In \emph{NIPS}, pp.\  6382--6393, 2017{\natexlab{a}}.

\bibitem[Lowe et~al.(2017{\natexlab{b}})Lowe, Wu, Tamar, Harb, Abbeel, and
  Mordatch]{DBLP:conf/nips/LoweWTHAM17}
Lowe, R., Wu, Y., Tamar, A., Harb, J., Abbeel, P., and Mordatch, I.
\newblock Multi-agent actor-critic for mixed cooperative-competitive
  environments.
\newblock In Guyon, I., von Luxburg, U., Bengio, S., Wallach, H.~M., Fergus,
  R., Vishwanathan, S. V.~N., and Garnett, R. (eds.), \emph{NIPS}, pp.\
  6382--6393, 2017{\natexlab{b}}.

\bibitem[Matignon et~al.(2012)Matignon, Laurent, and
  Le~Fort-Piat]{matignon2012independent}
Matignon, L., Laurent, G.~J., and Le~Fort-Piat, N.
\newblock Independent reinforcement learners in cooperative markov games: a
  survey regarding coordination problems.
\newblock \emph{The Knowledge Engineering Review}, 27\penalty0 (1):\penalty0
  1--31, 2012.

\bibitem[McIlraith \& Weinberger(2018)McIlraith and
  Weinberger]{DBLP:conf/aaai/2018}
McIlraith, S.~A. and Weinberger, K.~Q. (eds.).
\newblock \emph{Proceedings of the Thirty-Second {AAAI} Conference on
  Artificial Intelligence, New Orleans, Louisiana, USA, February 2-7, 2018},
  2018. {AAAI} Press.

\bibitem[Melo et~al.(2008)Melo, Meyn, and Ribeiro]{melo2008analysis}
Melo, F.~S., Meyn, S.~P., and Ribeiro, M.~I.
\newblock An analysis of reinforcement learning with function approximation.
\newblock In \emph{Proceedings of the 25th international conference on Machine
  learning}, pp.\  664--671. ACM, 2008.

\bibitem[Panait \& Luke(2005)Panait and Luke]{panait2005cooperative}
Panait, L. and Luke, S.
\newblock Cooperative multi-agent learning: The state of the art.
\newblock \emph{AAMAS}, 11\penalty0 (3):\penalty0 387--434, 2005.

\bibitem[Peng et~al.(2017)Peng, Yuan, Wen, Yang, Tang, Long, and
  Wang]{DBLP:journals/corr/PengYWYTLW17}
Peng, P., Yuan, Q., Wen, Y., Yang, Y., Tang, Z., Long, H., and Wang, J.
\newblock Multiagent bidirectionally-coordinated nets for learning to play
  starcraft combat games.
\newblock \emph{CoRR}, abs/1703.10069, 2017.

\bibitem[Rendle(2012)]{rendle2012factorization}
Rendle, S.
\newblock Factorization machines with libfm.
\newblock \emph{ACM Transactions on Intelligent Systems and Technology (TIST)},
  3\penalty0 (3):\penalty0 57, 2012.

\bibitem[Shapley(1953)]{shapley1953stochastic}
Shapley, L.~S.
\newblock Stochastic games.
\newblock \emph{Proceedings of the national academy of sciences}, 39\penalty0
  (10):\penalty0 1095--1100, 1953.

\bibitem[Silver et~al.(2014)Silver, Lever, Heess, Degris, Wierstra, and
  Riedmiller]{silver2014deterministic}
Silver, D., Lever, G., Heess, N., Degris, T., Wierstra, D., and Riedmiller, M.
\newblock Deterministic policy gradient algorithms.
\newblock In \emph{ICML}, pp.\  387--395, 2014.

\bibitem[Singh et~al.(2000)Singh, Jaakkola, Littman, and
  Szepesv{\'a}ri]{singh2000convergence}
Singh, S., Jaakkola, T., Littman, M.~L., and Szepesv{\'a}ri, C.
\newblock Convergence results for single-step on-policy reinforcement-learning
  algorithms.
\newblock \emph{Machine learning}, 38\penalty0 (3):\penalty0 287--308, 2000.

\bibitem[Stanley(1971)]{stanley1971phase}
Stanley, H.~E.
\newblock Phase transitions and critical phenomena.
\newblock \emph{Clarendon, Oxford}, 9, 1971.

\bibitem[Szepesv{\'a}ri \& Littman(1999)Szepesv{\'a}ri and
  Littman]{szepesvari1999unified}
Szepesv{\'a}ri, C. and Littman, M.~L.
\newblock A unified analysis of value-function-based reinforcement-learning
  algorithms.
\newblock \emph{Neural computation}, 11\penalty0 (8):\penalty0 2017--2060,
  1999.

\bibitem[Tan(1993)]{tan1993multi}
Tan, M.
\newblock Multi-agent reinforcement learning: Independent vs. cooperative
  agents.
\newblock In \emph{Proceedings of the tenth international conference on machine
  learning}, pp.\  330--337, 1993.

\bibitem[Troy(1997)]{troy1997envisioning}
Troy, C.~A.
\newblock Envisioning stock trading where the brokers are bots.
\newblock \emph{New York Times}, 16, 1997.

\bibitem[van~der Wal et~al.(1981)van~der Wal, van~der Wal, van~der Wal,
  Math{\'e}maticien, van~der Wal, and Mathematician]{van1981stochastic}
van~der Wal, J., van~der Wal, J., van~der Wal, J., Math{\'e}maticien, P.-B.,
  van~der Wal, J., and Mathematician, N.
\newblock \emph{Stochastic Dynamic Programming: successive approximations and
  nearly optimal strategies for Markov decision processes and Markov games}.
\newblock Mathematisch centrum, 1981.

\bibitem[Wang et~al.(2017)Wang, Zhang, Yuan, et~al.]{wang2017display}
Wang, J., Zhang, W., Yuan, S., et~al.
\newblock Display advertising with real-time bidding (rtb) and behavioural
  targeting.
\newblock \emph{Foundations and Trends{\textregistered} in Information
  Retrieval}, 11\penalty0 (4-5):\penalty0 297--435, 2017.

\bibitem[Watkins \& Dayan(1992)Watkins and Dayan]{watkins1992q}
Watkins, C.~J. and Dayan, P.
\newblock Q-learning.
\newblock \emph{Machine learning}, 8\penalty0 (3-4):\penalty0 279--292, 1992.

\bibitem[Weintraub et~al.(2006)Weintraub, Benkard, and
  Van~Roy]{weintraub2006oblivious}
Weintraub, G.~Y., Benkard, L., and Van~Roy, B.
\newblock Oblivious equilibrium: A mean field approximation for large-scale
  dynamic games.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1489--1496, 2006.

\bibitem[Yang et~al.(2017)Yang, Ye, Trivedi, Xu, and
  Zha]{DBLP:journals/corr/abs-1711-03156}
Yang, J., Ye, X., Trivedi, R., Xu, H., and Zha, H.
\newblock Deep mean field games for learning optimal behavior policy of large
  populations.
\newblock \emph{CoRR}, abs/1711.03156, 2017.

\bibitem[Zheng et~al.(2018)Zheng, Yang, Cai, Zhou, Zhang, Wang, and
  Yu]{DBLP:conf/aaai/ZhengYCZZWY18}
Zheng, L., Yang, J., Cai, H., Zhou, M., Zhang, W., Wang, J., and Yu, Y.
\newblock Magent: {A} many-agent reinforcement learning platform for artificial
  collective intelligence.
\newblock In  \citet{DBLP:conf/aaai/2018}.

\end{thebibliography}
