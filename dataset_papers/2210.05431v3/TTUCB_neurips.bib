p% This file was created with JabRef 2.10.
% Encoding: UTF-8

@inproceedings{menard2017minimax,
  title={A minimax and asymptotically optimal algorithm for stochastic bandits},
  author={M{\'e}nard, Pierre and Garivier, Aur{\'e}lien},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={223--237},
  year={2017},
  organization={PMLR}
}
@article{Sutton88,
  author    = {Richard S. Sutton},
  title     = {Learning to Predict by the Methods of Temporal Differences},
  journal   = {Machine Learning},
  volume    = {3},
  pages     = {9--44},
  year      = {1988}
}

@article{posner1975random,
  title={Random coding strategies for minimum entropy},
  author={Posner, Edward},
  journal={IEEE Transactions on Information Theory},
  volume={21},
  number={4},
  pages={388--391},
  year={1975},
  publisher={IEEE}
}

@book{sundaram1996first,
  title={A first course in optimization theory},
  author={Sundaram, Rangarajan K and others},
  year={1996},
  publisher={Cambridge university press}
}

@book{barbu2012convexity,
  title={Convexity and optimization in Banach spaces},
  author={Barbu, Viorel and Precupanu, Teodor},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@article{agrawal2021optimal,
  title={Optimal best-arm identification methods for tail-risk measures},
  author={Agrawal, Shubhada and Koolen, Wouter M and Juneja, Sandeep},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@book{berge1997topological,
  title={Topological Spaces: including a treatment of multi-valued functions, vector spaces, and convexity},
  author={Berge, Claude},
  year={1997},
  publisher={Courier Corporation}
}

@article{garivier2018kl,
  title={KL-UCB-switch: optimal regret bounds for stochastic bandits from both a distribution-dependent and a distribution-free viewpoints},
  author={Garivier, Aur{\'e}lien and Hadiji, H{\'e}di and Menard, Pierre and Stoltz, Gilles},
  journal={arXiv preprint arXiv:1805.05071},
  year={2018}
}

@article{honda2011asymptotically,
  title={An asymptotically optimal policy for finite support models in the multiarmed bandit problem},
  author={Honda, Junya and Takemura, Akimichi},
  journal={Machine Learning},
  volume={85},
  number={3},
  pages={361--391},
  year={2011},
  publisher={Springer}
}

@article{Alex19,
  author    = {Alexander Luedtke and
               Emilie Kaufmann and
               Antoine Chambaz},
  title     = {Asymptotically optimal algorithms for budgeted multiple play bandits},
  journal   = {Machine Learning},
  volume    = {108},
  number    = {11},
  pages     = {1919--1949},
  year      = {2019}
}

@inproceedings{Du21OptimalRFE,
  author    = {Zihan Zhang and
               Simon Du and
               Xiangyang Ji},
  title     = {Near Optimal Reward-Free Reinforcement Learning},
  booktitle = {International Conference on Machine Learning,
               (ICML)},
year      = {2021}
}


@inproceedings{Du21HorizonFreeRegret,
  author    = {Zihan Zhang and Xiangyang Ji and Simon Du},
  title     = {Is Reinforcement Learning More Difficult Than Bandits? A Near-optimal Algorithm Escaping the Curse of Horizon},
  booktitle = {International Conference on Learning Theory (COLT)},
  year      = {2021}
}

@inproceedings{Omar21LB,
  author    = {Omar Darwiche Domingues and
               Pierre M{\'{e}}nard and
               Emilie Kaufmann and
               Michal Valko},
  title     = {Episodic Reinforcement Learning in Finite MDPs: Minimax Lower Bounds
               Revisited},
  booktitle = {Algorithmic Learning Theory (ALT)},
  year      = {2021}
}

@inproceedings{Kaufmann21RFE,
  author    = {Emilie Kaufmann and
               Pierre M{\'{e}}nard and
               Omar Darwiche Domingues and
               Anders Jonsson and
               Edouard Leurent and
               Michal Valko},
  title     = {Adaptive Reward-Free Exploration},
  booktitle = {Algorithmic Learning Theory (ALT)},
  year      = {2021}
}

@inproceedings{Menard21RFE,
  author    = {Pierre M{\'{e}}nard and
               Omar Darwiche Domingues and
               Anders Jonsson and Emilie Kaufmann and
               Edouard Leurent and
               Michal Valko},
  title     = {Fast active learning for pure exploration in reinforcement learning},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2021}
}



@article{Lagoudakis03LSPI,
  author    = {Michail G. Lagoudakis and
               Ronald Parr},
  title     = {Least-Squares Policy Iteration},
  journal   = {Journal of  Machine Learning Research},
  volume    = {4},
  pages     = {1107--1149},
  year      = {2003}
}

@article{Reda20Survey,
title = {Machine learning applications in drug development},
author = {Clémence Réda and Emilie Kaufmann and Andrée Delahaye-Duriez},
journal = {Computational and Structural Biotechnology Journal},
volume = {18},
pages = {241--252},
year = {2020}}

@article{shafer2011test,
  title={Test martingales, {B}ayes factors and p-values},
  author={Shafer, Glenn and Shen, Alexander and Vereshchagin, Nikolai and Vovk, Vladimir},
  journal={Statistical Science},
  volume=26,
  number=1,
  pages={84--101},
  year=2011,
  publisher={Institute of Mathematical Statistics}
}




@ARTICLE{Centenaro16,
author={M. Centenaro and L. Vangelista and A. Zanella and M. Zorzi},
journal={IEEE Wireless Communications},
title={Long-range communications in unlicensed bands: the rising stars in the {IoT} and smart city scenarios},
year={2016},
volume={23},
number={5},
pages={60-67}
}


@inproceedings{Fiechter94,
  author    = {Claude{-}Nicolas Fiechter},
  title     = {Efficient Reinforcement Learning},
  booktitle = {Proceedings of the Seventh Conference on Computational
               Learning Theory (COLT)},
  year      = {1994}
}
@inproceedings{Fiechter97,
  author    = {Claude{-}Nicolas Fiechter},
  title     = {Expected Mistake Bound Model for On-Line Reinforcement Learning},
  booktitle = {Proceedings of the Fourteenth International Conference on Machine Learning (ICML)},
  year      = {1997}
}

@article{silver2017mastering,
  author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
  title = {Mastering the game of Go without human knowledge},
  journal = {Nature},
  pages = {354--},
  volume = 550,
  year = 2017
}

@article{Avner15,
    title =        {{Learning to Coordinate Without Communication in Multi-User Multi-Armed Bandit Problems}},
    author =       {O. Avner and S. Mannor},
    journal =      {{arXiv preprint arXiv:1504.08167}},
    year =         {2015}
}

@inproceedings{Gidel17SFW,
  author    = {Gauthier Gidel and
               Tony Jebara and
               Simon Lacoste{-}Julien},
  title     = {Frank-Wolfe Algorithms for Saddle Point Problems},
  booktitle = {Proceedings of the 20th International Conference on Artificial Intelligence
               and Statistics (AISTATS)},
  year      = {2017}
}

@inproceedings{Proutiere20MP,
  author    = {Po-An Wang, Alexandre Proutière, Kaito Ariu, Yassir Jedra, Alessio Russo},
  title     = {Optimal Algorithms for Multiplayer Multi-Armed Bandits},
  booktitle   = {AISTATS},
  year      = {2020}
}

@article{Robinson51,
title = {An Iterative Method of Solving a Game},
author = {Julia Robinson},
journal = {The Annals of Mathematics},
volume = {54},
number = {2},
year = {1951}
}


@Article{Teraoka14MCTS,
  Title                    = {Efficient Sampling Method for Monte Carlo Tree Search Problem},
  Author                   = {Teraoka, K. and Hatano, K. and Takimoto, E.},
  Journal                  = {IEICE Transactions on Infomation and Systems},
  Year                     = {2014},
  Pages                    = {392--398},
}


@article{Strehl09,
  author    = {Alexander L. Strehl and
               Lihong Li and
               Michael L. Littman},
  title     = {Reinforcement Learning in Finite MDPs: {PAC} Analysis},
  journal   = {Journal of Machine Learning Research},
  volume    = {10},
  pages     = {2413--2444},
  year      = {2009}
}

@article{Kearns02SparseSampling,
  author    = {Michael J. Kearns and
               Yishay Mansour and
               Andrew Y. Ng},
  title     = {A Sparse Sampling Algorithm for Near-Optimal Planning in Large Markov
               Decision Processes},
  journal   = {Machine Learning},
  volume    = {49},
  number    = {2-3},
  pages     = {193--208},
  year      = {2002}
}

@article{BrafmanT02,
  author    = {Ronen I. Brafman and
               Moshe Tennenholtz},
  title     = {{R-MAX} - {A} General Polynomial Time Algorithm for Near-Optimal Reinforcement
               Learning},
  journal   = {Journal of Machine Learning Research},
  volume    = {3},
  pages     = {213--231},
  year      = {2002}
}

@phdthesis{Kakade03PhD,
  author    = {Sham Kakade},
  title     = {On the Sample Complexity of Reinforcement Learning},
  school   = {University College London},
  year      = {2003}
}

@book{Ville39,
  author    = {Jean Ville},
  title     = {\'Etude critique de la notion de collectif},
  editor = { Gauthier-Villars},
  year      = {1939}
}

@phdthesis{Claire17PhD,
  author    = {Claire Vernade},
  title     = {Mod\`eles de bandits manchots pour des applications interactives},
  school   = {Telecom ParisTech},
  year      = {2017}
}

@Book{Csaba10Book,
  Title                    = {Algorithms for Reinforcement Learning},
  Author                   = {Csaba Szepesvari},
  Publisher                = {Morgan \& Claypool},
  Year                     = {2010}}

@phdthesis{Watkins89,
  author    = {C.J.C.H. Watkins},
  title     = {Learning from Delayed Rewards},
  school   = {University of Cambridge},
  year      = {1989}
}

@InProceedings{YadLinear11,
  Title                    = {{Improved Algorithms for Linear Stochastic Bandits}},
  Author                   = {Abbasi-Yadkori, Y. and D.P{\'a}l and C.Szepesv{\'a}ri},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2011},

  Abstract                 = {stochastic linear bandit, 'dual setting', action set that can vary in time, subgaussian assumption on the noise OFUL: regret bound slightly better than Rus-Tsi, interesting concentration arguments},
  Owner                    = {kaufmann},
  Timestamp                = {2011.11.16}
}

@article{Zhao10,
    title =        {{Distributed learning in Multi-Armed Bandit with multiple players}},
    author =       {K. Liu and Q. Zhao},
    journal =      {IEEE Transaction on Signal Processing},
    volume =       {58},
    number =       {11},
    pages =        {5667--5681},
    year =         {2010}
}

@article{Besson19GLRKLUCB,
  author    = {Lilian Besson and
               Emilie Kaufmann},
  title     = {The Generalized Likelihood Ratio Test meets klUCB: an Improved Algorithm
               for Piece-Wise Non-Stationary Bandits},
  journal   = {arXiv:1902.01575},
  year = {2019}
}

@article{LaiXing10GLRT,
  title={Sequential change-point detection when the pre-and post-change parameters are unknown},
  author={Lai, Tze Leung and Xing, Haipeng},
  journal={Sequential analysis},
  volume={29},
  number={2},
  pages={162--175},
  year={2010},
  publisher={Taylor \& Francis}
}


@article{SubhoOdalric19,
  author    = {Subhojyoti Mukherjee and
               Odalric{-}Ambrym Maillard},
  title     = {Distribution-dependent and Time-uniform Bounds for Piecewise i.i.d
               Bandits},
  year      = {2019},
  journal       = {arXiv:1905.13159}
}



@inproceedings{Luo19Context,
    title =        {A New Algorithm for Non-stationary Contextual Bandits: Efficient, Optimal, and Parameter-Free},
    author =       {Yifang Chen and Chung-Wei Lee and Haipeng Luo and Chen-Yu Wei},
    booktitle =    {Congerence on Learning Theory (COLT)},
    year =         {2019}
}

@inproceedings{Chen13Comb,
  author    = {Wei Chen and Yajun Wang and Yang Yuan},
  title     = {Combinatorial Multi-Armed Bandit: General Framework and Applications},
  booktitle = {International Conference on Machine Learning},
  year      = {2013},
}

@article{GaiKJ12,
  author    = {Yi Gai and
               Bhaskar Krishnamachari and
               Rahul Jain},
  title     = {Combinatorial Network Optimization With Unknown Variables: Multi-Armed
               Bandits With Linear Rewards and Individual Observations},
  journal   = {{IEEE/ACM} Trans. Netw.},
  volume    = {20},
  number    = {5},
  pages     = {1466--1478},
  year      = {2012}
}

@article{AudibertBL14,
  author    = {Jean{-}Yves Audibert and
               S{\'{e}}bastien Bubeck and
               G{\'{a}}bor Lugosi},
  title     = {Regret in Online Combinatorial Optimization},
  journal   = {Math. Oper. Res.},
  volume    = {39},
  number    = {1},
  pages     = {31--45},
  year      = {2014}
}

@inproceedings{KvetonWAS15,
  author    = {Branislav Kveton and
               Zheng Wen and
               Azin Ashkan and
               Csaba Szepesv{\'{a}}ri},
  title     = {Tight Regret Bounds for Stochastic Combinatorial Semi-Bandits},
  booktitle = {{AISTATS}},
  year      = {2015}
  }


@inproceedings{Luo18Context,
    title =        {Efficient Contextual Bandits in Non-stationary Worlds},
    author =       {Haipeng Luo and Chen-Yu Wei and Alekh Agarwal and John Langford},
    booktitle =    {Congerence on Learning Theory (COLT)},
    year =         {2018}
}

@inproceedings{Auer19NonStat,
    title =        {Adaptively Tracking the Best Bandit Arm with an Unknown Number of Distribution Changes},
    author =       {Peter Auer and Pratik Gajane and Ronald Ortner},
    booktitle =    {Congerence on Learning Theory (COLT)},
    year =         {2019}
}

@inproceedings{AuerLuo19,
  author    = {Peter Auer and
               Yifang Chen and
               Pratik Gajane and
               Chung{-}Wei Lee and
               Haipeng Luo and
               Ronald Ortner and
               Chen{-}Yu Wei},
  title     = {Achieving Optimal Dynamic Regret for Non-stationary Bandits without
               Prior Information},
  booktitle = {Conference on Learning Theory (COLT)},
  year = {2019}
}


@Article{Agrawal:95,
  Title                    = {{Sample mean based index policies with O(log n) regret for the multi-armed bandit problem}},
  Author                   = {Agrawal, R.},
  Journal                  = {Advances in Applied Probability},
  Year                     = {1995},
  Number                   = {4},
  Pages                    = {1054--1078},
  Volume                   = {27},

  Publisher                = {JSTOR}
}

@Article{Agrawaletal89LBGene,
  Title                    = {{Asymptotically Efficient Adaptive Allocation Schemes for Controlled i.i.d. Processes: Finite Parameter Space}},
  Author                   = {Agrawal, R. and Teneketzis, D. and aram, V.},
  Journal                  = {IEEE Transactions on Automatic Control},
  Year                     = {1989},
  Pages                    = {258--267},
  Volume                   = {34(3)},

  Abstract                 = {A rapprocher de Graves et Lai pour la generalisation de la borne de Lai et Robbins, dans un cas plus simple (avec une preuve plus claire que l'on peut adapter !)},
  Owner                    = {kaufmann},
  Timestamp                = {2014.03.12}
}

@InProceedings{AGAISTAT13,
  Title                    = {{Further Optimal Regret Bounds for Thompson Sampling}},
  Author                   = {Agrawal, S. and Goyal, N.},
  Booktitle                = {{Proceedings of the 16th Conference on Artificial Intelligence and Statistics}},
  Year                     = {2013},

  Owner                    = {Emilie},
  Timestamp                = {2013.05.07}
}

@INPROCEEDINGS{Dwork06,
    author = {Cynthia Dwork and Frank Mcsherry and Kobbi Nissim and Adam Smith},
    title = {Calibrating noise to sensitivity in private data analysis},
    booktitle = {In Proceedings of the 3rd Theory of Cryptography Conference},
    year = {2006},
    pages = {265--284},
    publisher = {Springer}
}

@inproceedings{Whang16DPRR,
  author    = {Yue Wang and
               Xintao Wu and
               Donghui Hu},
  title     = {Using Randomized Response for Differential Privacy Preserving Data
               Collection},
  booktitle = {Proceedings of the Workshops of the {EDBT/ICDT} 2016 Joint Conference},
  year      = {2016}
}

@InProceedings{Tossou2016Privacy,
  author =     {Aristide C. Y. Tossou and Christos Dimitrakakis},
  title =      {Algorithms for Differentially Private Multi-Armed Bandits},
  booktitle = {13th International Conference on Artificial Intelligence ({AAAI 2016})},
  year =   {2016},
  keywords = {differential privacy, bandits, regret, reinforcement learning, privacy, machine learning}
}

@InProceedings{AGContext13,
  Title                    = {{Thompson Sampling for Contextual Bandits with Linear Payoffs}},
  Author                   = {Agrawal, S. and Goyal, N.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2013},

  Owner                    = {Emilie},
  Timestamp                = {2013.05.07}
}

@inproceedings{Riquelme18DeepTS,
  author    = {Carlos Riquelme and
               George Tucker and
               Jasper Snoek},
  title     = {Deep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian
               Deep Networks for Thompson Sampling},
  booktitle = {6th International Conference on Learning Representations (ICLR)},
  year      = {2018}
}

@inproceedings{Zhao22SRSR,
  author  = {Yao Zhao and Connor James Stephens and Csaba Szepesvári and Kwang-Sung Jun},
  title   = {Revisiting Simple Regret: Fast Rates for Returning a Good Arm}, 
  booktitle       = {40th International Conference on Machine Learning (ICML)},
  year          = {2023}
}


@InProceedings{AGCOLT12,
  Title                    = {{Analysis of Thompson Sampling for the multi-armed bandit problem}},
  Author                   = {Agrawal, S. and Goyal, N.},
  Booktitle                = {{Proceedings of the 25th Conference On Learning Theory}},
  Year                     = {2012},

  Owner                    = {Emilie},
  Timestamp                = {2013.05.07}
}

@InProceedings{Alonal15GraphFeedback,
  Title                    = {Online Learning with Feedback Graph: Beyond Bandits},
  Author                   = {Alon, N. and Cesa-Bianchi, N. and Dekel, O. and Koren, T.},
  Booktitle                = {Conference On Learning Theory (COLT)},
  Year                     = {2015},

  Owner                    = {emilie},
  Timestamp                = {2016.01.29}
}

@Article{Anantharam87,
  Title                    = {Asymptotically Efficient Allocation Rules for the Multiarmed Bandit Problem with Multiple Plays-Part I: I.I.D. Rewards},
  Author                   = {Anantharam, V. and Varaya, P. and Walrand, J.},
  Journal                  = {IEEE Transactions on Automatic Control},
  Year                     = {1987},
  Number                   = {11},
  Pages                    = {968-976},
  Volume                   = {32},

  Owner                    = {emilie},
  Timestamp                = {2016.03.29}
}

@inproceedings{Komiyama15MPB,
  author    = {Junpei Komiyama and
               Junya Honda and
               Hiroshi Nakagawa},
  title     = {Optimal Regret Analysis of Thompson Sampling in Stochastic Multi-armed
               Bandit Problem with Multiple Plays},
  booktitle = {Proceedings of the 32nd International Conference on Machine Learning (ICML)},
  year      = {2015}
}


@article{Proutiere19OptimalMPMAB,
  author    = {Alexandre Prouti{\`{e}}re and
               Po{-}An Wang},
  title     = {An Optimal Algorithm in Multiplayer Multi-Armed Bandits},
  journal   = {arXiv:1909.13079},
  year      = {2019}
}

@InProceedings{CsabaTracking,
  Title                    = {Active Learning in Multi-Armed Bandits},
  Author                   = {Antos, A. and Grover, V. and Szepesv\'{a}ri, C.},
  Booktitle                = {Algorithmic Learning Theory},
  Year                     = {2008},

  Owner                    = {emilie},
  Timestamp                = {2016.01.28}
}

@article{Honda15IMED,
  author    = {Junya Honda and
               Akimichi Takemura},
  title     = {Non-asymptotic analysis of a new bandit algorithm for semi-bounded
               rewards},
  journal   = {Journal of Machine Learning Research},
  volume    = {16},
  pages     = {3721--3756},
  year      = {2015}
}

@article{Garivier18KLUCBSwitch,
  author    = {Aur{\'{e}}lien Garivier and
               H{\'{e}}di Hadiji and
               Pierre M{\'{e}}nard and
               Gilles Stoltz},
  title     = {KL-UCB-switch: optimal regret bounds for stochastic bandits from both
               a distribution-dependent and a distribution-free viewpoints},
  journal   = {arXiv:1805.05071},
  year      = {2018}
}



@InProceedings{Asmuthal09BOSS,
  Title                    = {{A Bayesian sampling approach to exploration in reinforcement learning}},
  Author                   = {Asmuth, J. and Li, L. and Littman, M.L. and Nouri, A. and Wingate, D.},
  Booktitle                = {{Uncertainty in Artificial Intelligence (UAI)}},
  Year                     = {2009},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.18}
}

@Article{Audibertal10MOSS,
  Title                    = {{Regret Bounds and Minimax Policies under Partial Monitoring}},
  Author                   = {Audibert, J-Y. and Bubeck, S.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@InProceedings{Audibertal11,
  Title                    = {{Minimax Policies for Combinatorial Prediction Games}},
  Author                   = {Audibert, J-Y. and Bubeck, S. and Lugosi, G.},
  Booktitle                = {{Conference On Learning Theory (COLT)}},
  Year                     = {2011},

  Abstract                 = {adversarial linear bandit when D={0,1}^d Lower bound in the dual setting : 0.005 d\sqrt(n) Lower bound in the setting where the loss of the adversary is simply bounded by 1 : 0.01d^{3/2}\sqrt{n} EXP2 algorithm as a generalization of COMBAND},
  Owner                    = {kaufmann},
  Timestamp                = {2013.01.16}
}

@InProceedings{Baudry20SDA,
  Title                    = {{Sub-sampling for Efficient Non-Parametric Bandit Exploration.}},
  Author                   = {Baudry, D. and Kaufmann, E. and Maillard, O-A.},
  Booktitle                = {Advances in Neural Information Processing Systems (NeurIPS)},
  Year                     = {2020}
}

@InProceedings{Bubeck10BestArm,
  Title                    = {{Best Arm Identification in Multi-armed Bandits}},
  Author                   = {Audibert, J-Y. and Bubeck, S. and Munos, R.},
  Booktitle                = {{Conference on Learning Theory}},
  Year                     = {2010},

  Abstract                 = {pure exploration : gives strategy minimizing the probability of advising a wrong arm at time n (slighlty different from the simple regret) two good strategies: - UCB-E is a UCB whose exploration rate is no longer log(n) but LINEAR in n (you have to explore more to ensure a good simple regret, to the detriment of a good cumulated regret) but the precise exploration function is distribution dependent - Successive Rejects Algorithm: draw uniformly the arms on each phase and at the end of each phase dismisses the arm with lowest empirical mean (size of phases chosen according to Hoeffding Inequality) - inspired by Hoeffding Races (more adapted to model selection or full information and a PAC setting)},
  Owner                    = {kaufmann},
  Timestamp                = {2012.06.15}
}

@Article{Audibertal09UCBV,
  Title                    = {{Exploration-exploitation trade-off using variance estimates in multi-armed bandits}},
  Author                   = {Audibert, J-Y. and Munos, R. and Szepesv{\'a}ri, {Cs.}},
  Journal                  = {Theoretical Computer Science},
  Year                     = {2009},
  Number                   = {19},
  Volume                   = {410},

  File                     = {TCS08.pdf:http\://imagine.enpc.fr/publications/papers/TCS08.pdf:PDF}
}

@Article{Auer02,
  Title                    = {{Using Confidence bounds for Exploration Exploitation trade-offs}},
  Author                   = {Auer},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2002},
  Pages                    = {397--422},
  Volume                   = {3},

  Abstract                 = {- a variant of EXP3 for shifting bandit in the adversarial case [previous work of Auer on the adversarial bandit seems large] - LinRel algorithm for stochastic linear bandit (not under this name), states the Stochastic Linear Bandit Problem (?)},
  Owner                    = {kaufmann},
  Timestamp                = {2013.01.15}
}

@Article{Aueral02,
  Title                    = {{Finite-time analysis of the multiarmed bandit problem}},
  Author                   = {Auer, P. and Cesa-Bianchi, N. and Fischer, P.},
  Journal                  = {Machine Learning},
  Year                     = {2002},
  Number                   = {2},
  Pages                    = {235--256},
  Volume                   = {47},

  Publisher                = {Springer}
}

@inproceedings{RiouHonda20,
  author    = {Charles Riou and
               Junya Honda},
  title     = {Bandit Algorithms Based on Thompson Sampling for Bounded Reward Distributions},
  booktitle = {Algorithmic Learning Theory (ALT)},
  year      = {2020}
}

@Article{Auer:al02EXP3,
  Title                    = {{The nonstochastic multiarmed bandit problem}},
  Author                   = {Auer, P. and Cesa-Bianchi, N. and Freund, Y. and Schapire, R.},
  Journal                  = {SIAM Journal of Computing},
  Year                     = {2002},
  Pages                    = {48--77},
  Volume                   = {32(1)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.06}
}

@article{AgrawalG17,
  author    = {Shipra Agrawal and
               Navin Goyal},
  title     = {Near-Optimal Regret Bounds for Thompson Sampling},
  journal   = {J. {ACM}},
  volume    = {64},
  number    = {5},
  pages     = {30:1--30:24},
  year      = {2017},
}

@inproceedings{Baudry21DS,
  author    = {Dorian Baudry and
               Patrick Saux and
               Odalric{-}Ambrym Maillard},
  title     = {From Optimality to Robustness: Dirichlet Sampling Strategies in Stochastic
               Bandits},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2021}
}


@inproceedings{Claire17RankOne,
  author    = {Sumeet Katariya and
               Branislav Kveton and
               Csaba Szepesv{\'{a}}ri and
               Claire Vernade and
               Zheng Wen},
  title     = {Stochastic Rank-1 Bandits},
  booktitle = {Proceedings of the 20th International Conference on Artificial Intelligence
               and Statistics},
  year      = {2017}
}


@inproceedings{Claire17BernoulliRankOne,
  Title                    = {Bernoulli Rank-1 Bandits for Click Feedback},
  Author                   = {Katariya, Sumeet and Kveton, Branislav and Szepesv\'{a}ri, Csaba and Vernade, Claire and Wen, Zheng},
  Booktitle                = {International Joint Conferences on Artificial Intelligence (IJCAI)},
  Year                     = {2017}
}

@inproceedings{Trinh20,
  author    = {Cindy Trinh and
               Emilie Kaufmann and
               Claire Vernade and
               Richard Combes},
  title     = {Solving Bernoulli Rank-One Bandits with Unimodal Thompson Sampling},
  booktitle = {Algorithmic Learning Theory (ALT)},
  year      = {2020}
}

@Article{Balcan10Active,
  Title                    = {{The true sample complexity of active learning}},
  Author                   = {Balcan, M-F. and Hanneke, S. and {Wortman Voghan}, J.},
  Journal                  = {Machine Learning},
  Year                     = {2010},
  Pages                    = {111--139},
  Volume                   = {80}
}

@Article{Balsubramani15,
  Title                    = {Sharp Finite-Time Iterated-Logarithm Martingale Concentration},
  Author                   = {Balsmubramani, A.},
  Journal                  = {arXiv:1405.2639},
  Year                     = {2015},
}

@Article{Bechofer:54,
  Title                    = {{A single-sample multiple decision procedure for ranking means of normal populations with known variances}},
  Author                   = {Bechhofer, R.},
  Journal                  = {Annals of Mathematical Statistics},
  Year                     = {1954},
  Pages                    = {16--39},
  Volume                   = {25},

  Abstract                 = {Static strategies for the gaussian case with known or unkown, similar or disimilar variances N=N\_1 + ... + N\_k samples. How to choose the N\_i (as small as possible) to achieve a given probability of error when the delta between the arms is known? (sufficient condition) Based on approximation of the probability of good ranking (a lower bound of the quantity is obtained in the least favorable 'slippage' configuration). The author provides a table that helps choosing N\_i in practise.},
  Owner                    = {Emilie},
  Timestamp                = {2013.05.19}
}

@article{Hong21Survey,
title = {Review on ranking and selection: A new perspective},
author = {Hong, L.J. and Fan, W. and Luo, J.},
journal = {Frontiers of Engineering Management},
volume= {8},
pages = {321–343},
year = {2021}
}
@Book{Bechofer:al68,
  Title                    = {{Sequential identification and ranking procedures}},
  Author                   = {Bechhofer, Robert and Kiefer, Jack and Sobel, Milton},
  Publisher                = {The University of Chicago Press},
  Year                     = {1968},

  Abstract                 = {State the ranking and identification procedures with 'PCS1' probability conditions. No 'optimal' procedure, rather efficient procedures, based on fully uniform sampling: - for the identification problem: 'maximum a posteriori' with an uniform prior (possible to express in terms of likelihood) - for the ranking problem (for exponential families): use the same procedure, expressed in terms of gaps, and replace gaps by what they are in the Least Favorable (Slippage) configuration (heavily dependent on the delta parameter) Achieve the same garantee in terms of sample complexity as what can be done for a sequential multiple hypothesis testing based on K samples (and procedures for this purpose are hard to design!)},
  Owner                    = {Emilie},
  Timestamp                = {2013.05.19}
}

@Article{Bellman:Bay56,
  Title                    = {{A problem in the sequential design of experiments}},
  Author                   = {Bellman, R.},
  Journal                  = {The indian journal of statistics},
  Year                     = {1956},
  Pages                    = {221--229},
  Volume                   = {16(3/4)},

  Abstract                 = {historical introduction general presentation of the bayesian bandit framework for two arms (discounted !) study the uncorelated case, 1/2 problem, in the discounted setting => discribe the stopping policy in terms of an index},
  Owner                    = {kaufmann},
  Timestamp                = {2012.07.06}
}

@Article{Bellman:54DP,
  Title                    = {{The theory of dynamic programming}},
  Author                   = {Bellman, R.},
  Journal                  = {Bulletin of the American Mathematical Society},
  Year                     = {1954},
  Pages                    = {503--515},
  Volume                   = {60(6)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.28}
}



@article{Bubeck13Heavy,
  author    = {S{\'{e}}bastien Bubeck and
               Nicol{\`{o}} Cesa{-}Bianchi and
               G{\'{a}}bor Lugosi},
  title     = {Bandits With Heavy Tail},
  journal   = {{IEEE} Transactions on Information Theory},
  volume    = {59},
  number    = {11},
  pages     = {7711--7717},
  year      = {2013}
}



@Book{Berry:Fristedt85,
  Title                    = {{Bandit Problems. Sequential allocation of experiments}},
  Author                   = {Berry, D.A. and Fristedt, B.},
  Publisher                = {Chapman and Hall},
  Year                     = {1985},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.21}
}

@Book{Bickel:Doksum,
  Title                    = {{Mathematical Statistics, Basic Ideas and Selected Topics}},
  Author                   = {Bickel, P. and Doksum, K.A.},
  Publisher                = {Prentice Hall},
  Year                     = {2001},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.23}
}

@Book{Bishop06Laplace,
  Title                    = {{Pattern Recognition and Machine Learning}},
  Author                   = {Bishop, C.M.},
  Publisher                = {Springer-Verlag New York},
  Year                     = {2006},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.18}
}

@InProceedings{OMS14,
  Title                    = {An analysis of optimistic, best-first search for minimax sequential decision making},
  Author                   = {Borsoniu, L. and Munos, R. and P{\'a}ll, E.},
  Booktitle                = {ADPRL14},
  Year                     = {2014},

  Owner                    = {emilie},
  Timestamp                = {2016.05.26}
}

@Book{Boucheronal13CI,
  Title                    = {{Concentration inequalities. A non asymptotic theory of independence.}},
  Author                   = {Boucheron, S., S. and Lugosi, G. and Massart, P},
  Publisher                = {Oxford University Press},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.26}
}

@Article{Bradt:al56,
  Title                    = {{On sequential designs for maximizing the sum of n observations}},
  Author                   = {Bradt, R.N and Johnson, S.M. and Karlin, S.},
  Journal                  = {Annals of Mathematical Statistics},
  Year                     = {1956},
  Pages                    = {1060--1074},
  Volume                   = {27(4)},

  Abstract                 = {contains the finite time Gittins indices ! bayesian finite-horizon framework - special case with a prior charging two values ('hypotheses' setting of Sonin) - product prior F(p)F(q) exactly solved for n=2 - solving the one-armed bandit with finite time exactly (approximation of Gittins indices) Link between the one-armed problem and the Gittins index : established by Gittins ! contient des relations entre indices finis},
  Owner                    = {kaufmann},
  Timestamp                = {2012.07.06}
}

@Article{Brezzi:Lai02,
  Title                    = {{Optimal learning and experimentation in bandit problems}},
  Author                   = {Brezzi, M. and Lai, T.},
  Journal                  = {Journal of Economics Dynamics and Control},
  Year                     = {2002},
  Pages                    = {87--108},
  Volume                   = {27},

  Owner                    = {kaufmann},
  Timestamp                = {2012.04.18}
}

@TechReport{Brezzi:LaiTech,
  Title                    = {{Incomplete learning fomr endogenous data in dynamic allocation}},
  Author                   = {Brezzi, M. and Lai, T.},
  Institution              = {Stanford University},
  Year                     = {1999},

  Owner                    = {kaufmann},
  Timestamp                = {2012.04.18}
}

@TechReport{Rummery94SARSA,
  Title                    = {On-line Q-learning using connectionist systems},
  Author                   = {Rummery, G. A. and Niranjan, M.},
  Institution              = {Cambridge University Engineering Department},
  Year                     = {1994}
}

@inproceedings{TsitsiklisVanRoy96,
  author    = {John N. Tsitsiklis and
               Benjamin {Van Roy}},
  title     = {Analysis of Temporal-Diffference Learning with Function Approximation},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {1996}
}

@article{LazaricGM12LSPI,
  author    = {Alessandro Lazaric and
               Mohammad Ghavamzadeh and
               R{\'{e}}mi Munos},
  title     = {Finite-sample analysis of least-squares policy iteration},
  journal   = {Journal of Machine Learning Research},
  volume    = {13},
  pages     = {3041--3074},
  year      = {2012}
}

@inproceedings{Lazaric10LSTD,
  author    = {Alessandro Lazaric and
               Mohammad Ghavamzadeh and
               R{\'{e}}mi Munos},
  title     = {Finite-Sample Analysis of {LSTD}},
  booktitle = {Proceedings of the 27th International Conference on Machine Learning
               (ICML)},
  year      = {2010}
}

@article{Lagoudakis03LSPI,
  author    = {Michail G. Lagoudakis and
               Ronald Parr},
  title     = {Least-Squares Policy Iteration},
  journal   = {Journal of Machine Learning Research},
  volume    = {4},
  pages     = {1107--1149},
  year      = {2003}
}

@inproceedings{Munos05,
  author    = {R{\'{e}}mi Munos},
  title     = {Error Bounds for Approximate Value Iteration},
  booktitle = {Proceedings, The Twentieth National Conference on Artificial Intelligence
               and the Seventeenth Innovative Applications of Artificial Intelligence
               Conference},
  pages     = {1006--1011},
  year      = {2005}
}

@article{MunosS08,
  author    = {R{\'{e}}mi Munos and
               Csaba Szepesv{\'{a}}ri},
  title     = {Finite-Time Bounds for Fitted Value Iteration},
  journal   = {Journal of Machine Learning Research},
  volume    = {9},
  pages     = {815--857},
  year      = {2008}
}

@TechReport{Brochu10Tuto,
  Title                    = {{A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning}},
  Author                   = {Brochu, E. and Cora, V.M. and {De Freitas}, N.},
  Institution              = {University of Bristish Columbia},
  Year                     = {2010},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.20}
}

@article{Cowan17Gaussian,
  author    = {Wesley Cowan and
               Junya Honda and
               Michael N. Katehakis},
  title     = {Normal Bandits of Unknown Means and Variances},
  journal   = {Journal of Machine Learning Research},
  volume    = {18},
  pages     = {154:1--154:28},
  year      = {2017}
}

@Article{SurveyMCTS12,
  Title                    = {A Survey of Monte Carlo Tree Search Methods},
  Author                   = {Browne, C. and Powley, E. and Whitehouse, D. and Lucas, S. and Cowling, P. and Rohlfshagen, P. and Tavener, S. and Perez, D. and Samothrakis, S. and Colton, S.},
  Journal                  = {IEEE Transactions on Computational Intelligence and AI in games,},
  Year                     = {2012},
  Number                   = {1},
  Pages                    = {1-49},
  Volume                   = {4},

  Owner                    = {emilie},
  Timestamp                = {2016.02.12}
}

@TechReport{Bubeck:LectOpt11,
  Title                    = {{Introduction to Online Optimization}},
  Author                   = {Bubeck, S.},
  Institution              = {Lecture Notes, Princeton University},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2013.01.28}
}

@PhdThesis{Bubeck:Thesis,
  Title                    = {{Jeux de bandits et fondation du clustering}},
  Author                   = {Bubeck, S.},
  School                   = {Universit{\'e} de Lille 1},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.26}
}

@Article{Bubeck:Survey12,
  Title                    = {{Regret analysis of stochastic and nonstochastic multi-armed bandit problems}},
  Author                   = {Bubeck, S. and Cesa-Bianchi, N.},
  Journal                  = {Fondations and Trends in Machine Learning},
  Year                     = {2012},
  Pages                    = {1--122},
  Volume                   = {5(1)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.13}
}

@InProceedings{Bubeck:al12,
  Title                    = {{Towards Minimax Policies for Online Linear Opimization with Bandit Feedback}},
  Author                   = {Bubeck, S. and Cesa-Bianchi, N. and Kakade, S.},
  Booktitle                = {{Proceedings of the 25th Conference On Learning Theory}},
  Year                     = {2012},

  Abstract                 = {adversarial linear bandit EXP2 with John distribution (intractable) minimax optimal when A is finite Efficient Miror-Descent based algorithm for two situation (combinatorial case and euclidian ball) For A and Z as the euclidian ball, we get a upper bound on the regret of sqrt(dn) -> There is no current lower bound for given A and Z!},
  Owner                    = {kaufmann},
  Timestamp                = {2013.01.16}
}

@InProceedings{BubeckLiu:13,
  Title                    = {{Prior-free and prior-dependent regret bounds for Thompson Sampling}},
  Author                   = {Bubeck, S. and Liu, C.-Y.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.24}
}

@Article{Bubeckal11,
  Title                    = {{Pure Exploration in Finitely Armed and Continuous Armed Bandits}},
  Author                   = {Bubeck, S. and Munos, R. and Stoltz, G.},
  Journal                  = {Theoretical Computer Science 412, 1832-1852},
  Year                     = {2011},
  Pages                    = {1832--1852},
  Volume                   = {412},

  Abstract                 = {algorithm minimizing the simple regret at round n correspond to a different set of application : you don't care making error in the exploration phase and just have to make a good recomandation for the arm in the end -> pure exploration, interesting applications (Marjorie?) forecaster : pair of an allocation (how to deal with exploration) and a recomandation (what you advice at a given stage if you have to stop exploring) -> (or try to) version of the pure exploration problem a strategy that has low cummulative regret (for its exploration phase) has a simple regret that is lower bounded ! lower bound for the simple regret (Bernoulli) : exponential decay, unlike what is achieved with an UCB exploration upper bound on the simple regret for strategy including UCB and the uniform exploration (which turns to be optimal coupled with an recommandation based on the empirical mean)},
  Owner                    = {kaufmann},
  Timestamp                = {2012.06.15}
}

@Article{Bubeck11Xarmed,
  Title                    = {X-armed bandits},
  Author                   = {Bubeck, S. and Munos, R. and Stoltz, G. and Szepesv\'{a}ri, C.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2011},
  Pages                    = {1587-1627},
  Volume                   = {12},

  Owner                    = {emilie},
  Timestamp                = {2016.01.28}
}

@InProceedings{BPR13,
  Title                    = {{Bounded regret in stochastic multi-armed bandits}},
  Author                   = {Bubeck, S. and Perchet, V. and Rigollet, P.},
  Booktitle                = {{Proceedings of the 26th Conference On Leaning Theory}},
  Year                     = {2013},

  Owner                    = {Emilie},
  Timestamp                = {2013.04.22}
}

@InProceedings{Perchet15Batched,
  Title                    = {Batched Bandit Problems},
  Author                   = {Perchet, Vianney and Rigollet, Philippe and Chassang, Sylvain and Snowberg, Eric},
  Booktitle                = {Proceedings of the 28th Conference On Learning Theory},
  Year                     = {2015},

  Owner                    = {emilie},
  Timestamp                = {2016.04.25}
}


@InProceedings{Bubeck:alMult13,
  Title                    = {{Multiple Identifications in multi-armed bandits}},
  Author                   = {Bubeck, S. and Wang, T. and Viswanathan, N.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2013},

  Abstract                 = {An algorithm for finding the m best arms in a pure-exploration setting with known horizon n upper bound the probability of error at time t (no matching lower bound) Successive Acepts and Rejects algorithms : suprinsingly enough, the Successive Reject does not work !},
  Owner                    = {kaufmann},
  Timestamp                = {2012.09.04}
}

@Article{Bull11EI,
  Title                    = {{Convergence Rates of Efficient Global Optimization Algorithms}},
  Author                   = {Bull, A.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2011},
  Pages                    = {2879--2904},
  Volume                   = {12},

  Owner                    = {kaufmann},
  Timestamp                = {2014.07.02}
}

@Article{BurnKat03OneArmed,
  Title                    = {{Asymptotic Bayes Analysis for the finite horizon one armed bandit problem}},
  Author                   = {Burnetas, A. and Katehakis, M.},
  Journal                  = {Probability in the Engineering and Informational Sciences},
  Year                     = {2003},
  Pages                    = {53--82},
  Volume                   = {17},

  Abstract                 = {contains an asymptotic resolution of the B\_lambda problem for two arms in the exponential family ! draws no parallel with Gittins index proposes an alternative exploration rate},
  Owner                    = {kaufmann},
  Timestamp                = {2012.06.21}
}

@Article{Burn:Kat:MDP97,
  Title                    = {{Optimal adaptive policies for {M}arkov decision processes}},
  Author                   = {Burnetas, A.N. and Katehakis, M.N.},
  Journal                  = {Mathematics of Operations Research},
  Year                     = {1997},
  Pages                    = {222--255},

  Publisher                = {Institute for Operations Research and the Management Sciences}
}

@Article{BurnKat96,
  Title                    = {{Optimal adaptive policies for sequential allocation problems}},
  Author                   = {Burnetas, A.N and Katehakis, M.},
  Journal                  = {Advances in Applied Mathematics},
  Year                     = {1996},
  Pages                    = {122--142},
  Volume                   = {17(2)},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@book{BanditBook,
author = {Lattimore, Tor and Szepesvari, Csaba},
publisher = {Cambridge University Press},
title = {{Bandit Algorithms}},
year = {2019}
}

@inproceedings{Degenne19BAI,
  author    = {R{\'{e}}my Degenne and
               Thomas Nedelec and
               Cl{\'{e}}ment Calauz{\`{e}}nes and
               Vianney Perchet},
  title     = {Bridging the gap between regret minimization and best arm identification, with application to {A/B} tests},
  booktitle = {The 22nd International Conference on Artificial Intelligence and Statistics (AISTATS)},
  year      = {2019}
}


@inproceedings{Azar17UBCVI,
  author    = {Mohammad Gheshlaghi Azar and
               Ian Osband and
               R{\'{e}}mi Munos},
  title     = {Minimax Regret Bounds for Reinforcement Learning},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning,
               (ICML)},
  year      = {2017}
}

@article{Ciara18,
  author    = {Ciara Pike{-}Burke and
               Shipra Agrawal and
               Csaba Szepesv{\'{a}}ri and
               Steffen Gr{\"{u}}new{\"{a}}lder},
  title     = {Bandits with Delayed Anonymous Feedback},
  journal   = {CoRR},
  volume    = {abs/1709.06853},
  year      = {2017},
  url       = {http://arxiv.org/abs/1709.06853},
  archivePrefix = {arXiv},
  eprint    = {1709.06853},
  timestamp = {Thu, 28 Dec 2017 16:02:42 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1709-06853},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{VernadeCP17,
  author    = {Claire Vernade and
               Olivier Capp{\'{e}} and
               Vianney Perchet},
  title     = {Stochastic Bandit Models for Delayed Conversions},
  booktitle = {Proceedings of the Thirty-Third Conference on Uncertainty in Artificial
               Intelligence (UAI)},
  year      = {2017}
}

@Article{KLUCBJournal,
  Title                    = {{{K}ullback-{L}eibler upper confidence bounds for optimal sequential allocation}},
  Author                   = {Capp{\'e}, O. and Garivier, A. and Maillard, O-A. and Munos, R. and Stoltz, G.},
  Journal                  = {Annals of Statistics},
  Year                     = {2013},
  Pages                    = {1516--1541},
  Volume                   = {41(3)},

  Owner                    = {kaufmann},
  Timestamp                = {2012.08.31}
}

@InProceedings{Marc12SideInfo,
  Title                    = {Levaraging Side Observations in Stochastic Bandits},
  Author                   = {Caron, S. and Kveton, B. and Lelarge, M. and Bhagat, S.},
  Booktitle                = {Conference on Uncertainty in Artificial Intelligence (UAI)},
  Year                     = {2012},

  Owner                    = {emilie},
  Timestamp                = {2016.01.29}
}

@InProceedings{carpentier2015simple,
  Title                    = {{Simple regret for infinitely many armed bandits}},
  Author                   = {Carpentier, Alexandra and Valko, Michal},
  Booktitle                = {International Conference on Machine Learning},
  Year                     = {2015},

  Abstract                 = {We consider a stochastic bandit problem with infinitely many arms. In this setting, the learner has no chance of trying all the arms even once and has to dedicate its limited number of samples only to a certain number of arms. All previous algorithms for this setting were designed for minimizing the cumulative regret of the learner. In this paper, we propose an algorithm aiming at minimizing the simple regret. As in the cumulative regret setting of infinitely many armed bandits, the rate of the simple regret will depend on a parameter {\$}\backslashbeta{\$} characterizing the distribution of the near-optimal arms. We prove that depending on {\$}\backslashbeta{\$}, our algorithm is minimax optimal either up to a multiplicative constant or up to a {\$}\backslashlog(n){\$} factor. We also provide extensions to several important cases: when {\$}\backslashbeta{\$} is unknown, in a natural setting where the near-optimal arms have a small variance, and in the case of unknown time horizon.},
  Owner                    = {emilie},
  Timestamp                = {2016.05.26}
}

@Article{Comband12,
  Title                    = {{Combinatorial Bandits}},
  Author                   = {Cesa-Bianchi, N. and Lugosi, G.},
  Journal                  = {Journal of Computer and System Sciences},
  Year                     = {2012},
  Pages                    = {1404--1422},
  Volume                   = {78},

  Abstract                 = {adversarial linear bandit with D={0,1}^d COMBAND algorithm (not always enjoying a good regret, depends on an exploration distribution) a lot of funny example},
  Owner                    = {kaufmann},
  Timestamp                = {2013.01.16}
}

@Book{PLG06,
  Title                    = {{Prediction, Learning and Games}},
  Author                   = {Cesa-Bianchi, N. and Lugosi, G.},
  Publisher                = {Cambridge University Press},
  Year                     = {2006},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.25}
}

@InProceedings{Chandra14COLT,
  Title                    = {{Finding a most biaised coin with fewest flips}},
  Author                   = {Chandrasekaran, K. and Karp, R.},
  Booktitle                = {{Proceeding of the 27th Conference on Learning Theory}},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.07.16}
}

@Article{ChangLai87,
  Title                    = {{Optimal stopping and dynamic allocation}},
  Author                   = {Chang, F. and Lai, T.},
  Journal                  = {Advances in Applied Probability},
  Year                     = {1987},
  Pages                    = {829--853},
  Volume                   = {19},

  Owner                    = {kaufmann},
  Timestamp                = {2012.04.18}
}

@article{RussoRKOW18,
  author    = {Daniel Russo and
               Benjamin Van Roy and
               Abbas Kazerouni and
               Ian Osband and
               Zheng Wen},
  title     = {A Tutorial on Thompson Sampling},
  journal   = {Foundations and Trends in Machine Learning},
  volume    = {11},
  number    = {1},
  pages     = {1--96},
  year      = {2018}
}

@Book{Rasmussen2005,
 author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
 title = {Gaussian Processes for Machine Learning},
 year = {2005},
 publisher = {The MIT Press},
}

@InProceedings{LiChapelle11,
  Title                    = {{An empirical evaluation of Thompson Sampling}},
  Author                   = {Chapelle, O. and Li, L.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2012.05.02}
}

@Article{Chapelleetal14Ad,
  Title                    = {{Simple and scalable response prediction for display advertising.}},
  Author                   = {Chapelle, O. and Manavoglu, E. and Rosales, R.},
  Journal                  = {Transactions on Intelligent Systems and Technology},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.17}
}

@Article{Chen16OptimalAlt,
  title={Towards instance optimal bounds for best arm identification},
  author={Chen, Lijie and Li, Jian and Qiao, Mingda},
  journal={Conference on Learning Theory},
  year={2017}
}

@InProceedings{Chen14ComBAI,
  Title                    = {{Combinatorial Pure Exploration of Multi-Armed Bandits}},
  Author                   = {Chen, S. and Lin, T. and King, I. and Lyu, M. and Chen, W.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2014}
}

@TechReport{Chernoff:Tech67,
  Title                    = {{Optimal stochastic control}},
  Author                   = {Chernoff, H.},
  Institution              = {Stanford, California},
  Year                     = {1967},

  Owner                    = {kaufmann},
  Timestamp                = {2012.07.05}
}

@InProceedings{Chernoff67,
  Title                    = {{Sequential models for clinical trials}},
  Author                   = {Chernoff, H.},
  Booktitle                = {{Fifth Berkeley Symposium on Mathematical Statistics and Probability}},
  Year                     = {1967},

  Owner                    = {kaufmann},
  Timestamp                = {2012.04.18}
}

@Article{Chernoff59,
  Title                    = {{Sequential design of Experiments}},
  Author                   = {Chernoff, H.},
  Journal                  = {The Annals of Mathematical Statistics},
  Year                     = {1959},
  Number                   = {3},
  Pages                    = {755--770},
  Volume                   = {30}
}

@Article{Chernoff:Ray65,
  Title                    = {{A Bayes sequential sampling inspection plan}},
  Author                   = {Chernoff, H. and Ray, S.N.},
  Journal                  = {Annals of Mathematical Statistics},
  Year                     = {1965},
  Pages                    = {1387--1407},
  Volume                   = {36},

  Owner                    = {kaufmann},
  Timestamp                = {2012.04.18}
}

@Book{Cheung11Book,
  Title                    = {Dose finding with the Continual Reassessment Method},
  Author                   = {Cheung, Y.K.},
  Publisher                = {Chapman and Hall},
  Year                     = {2011},

  Owner                    = {emilie},
  Timestamp                = {2016.11.03}
}

@InProceedings{LinUCB11,
  Title                    = {{Contextual Bandits with Linear Payoff Functions}},
  Author                   = {Chu, W. and Li, L. and Reyzin, L. and Schapire, R.},
  Booktitle                = {{Proceedings of the 14th Conference on Artificial Intelligence and Statistics}},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.06}
}

@Article{ClopperPearson34,
  Title                    = {{The use of confidence of fiducial limits illustration in the case of the binomial}},
  Author                   = {Clopper, C.J. and Pearson, E.S.},
  Journal                  = {Biometrika},
  Year                     = {1934},
  Pages                    = {404--413},
  Volume                   = {26}
}

@InProceedings{Combes17OSSB,
  Title                    = {Minimal Exploration in Structured Stochastic Bandits},
  Author                   = {Combes, R. and Magureanu, S. and Prouti{\`e}re, A.},
  Booktitle                = {Advances in Neural Information Processing Systems (NeurIPS)},
  Year                     = {2017},

  Owner                    = {emilie},
  Timestamp                = {2017.11.22}
}

@inproceedings{TorRemi14Structured,
  author    = {Tor Lattimore and R{\'{e}}mi Munos},
  title     = {Bounded Regret for Finite-Armed Structured Bandits},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2014}
}

@Article{Combes15JSAC,
  Title                    = {{Dynamic Rate and Channel Selection in Cognitive Radio Systems}},
  Author                   = {Combes, R. and Prouti{\`e}re, A.},
  Journal                  = {IEEE Journal on Selected Area in Communication},
  Year                     = {2015},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.24}
}

@inproceedings{Kocsis06,
    title =        {{Discounted UCB}},
    author =       {L. Kocsis and C. Szepesv{\'a}ri},
    booktitle =    {{2nd PASCAL Challenges Workshop}},
    year =         {2006}
}

@book{BertsekasTsi96,
  author    = {Dimitri P. Bertsekas and
               John N. Tsitsiklis},
  title     = {Neuro-dynamic programming},
  publisher = {Athena Scientific},
  year      = {1996}
}

@inproceedings{Garivier13ITW,
  author    = {Aur{\'{e}}lien Garivier},
  title     = {Informational confidence bounds for self-normalized averages and applications},
  booktitle = {2013 {IEEE} Information Theory Workshop, {ITW} 2013, Sevilla, Spain,
               September 9-13, 2013},
  pages     = {1--5},
  year      = {2013}
}


@inproceedings{Garivier11UCBDiscount,
    title =        {{On Upper-Confidence Bound Policies For Switching Bandit Problems}},
    author =       {A. Garivier and E. Moulines},
    booktitle =    {{Algorithmic Learning Theory (ALT)}},
    pages =        {174--188},
    year =         {2011},
    publisher =    {{PMLR}},
}


@inproceedings{YuMannor09,
    title =        {{Piecewise-Stationary Bandit Problems with Side Observations}},
    author =       {J. Y. Yu and S. Mannor},
    booktitle =    {{Proceedings of the International Conference on Machine Learning (ICML)}},
    pages =        {1177--1184},
    year =         {2009},
    organization = {ACM}
}

@inproceedings{LiuLeeShroff17,
    title =        {{A Change-Detection based Framework for Piecewise-stationary Multi-Armed Bandit Problem}},
    author =       {F. Liu and J. Lee and N. Shroff},
    booktitle =    {{The Thirty-Second AAAI Conference on Artificial Intelligence (AAAI 2018)}},
    year =         {2018}
}

@inproceedings{CaoZhenKvetonXie18,
    title =        {{Nearly Optimal Adaptive Procedure for Piecewise-Stationary Bandit: a Change-Point Detection Approach}},
    author =       {Y. Cao and W. Zheng and B. Kveton and Y. Xie},
    booktitle =    {AISTATS},
    address =      {Okinawa, Japan},
    year =         {2019}
}

@InProceedings{Combes14ICML,
  Title                    = {Unimodal bandits: Regret lower bounds and optimal algorithms},
  Author                   = {Combes, R. and Prouti{\`e}re, A.},
  Booktitle                = {International Conference on Machine Learning (ICML)},
  Year                     = {2014},

  Owner                    = {emilie},
  Timestamp                = {2015.12.26}
}

@inproceedings{KwonPV17,
  author    = {Joon Kwon and
               Vianney Perchet and
               Claire Vernade},
  title     = {Sparse Stochastic Bandits},
  booktitle = {Proceedings of the 30th Conference on Learning Theory (COLT)},
  year      = {2017}
}



@inproceedings{Paladino17UTS,
  author    = {Stefano Paladino and
               Francesco Trov{\`{o}} and
               Marcello Restelli and
               Nicola Gatti},
  title     = {Unimodal Thompson Sampling for Graph-Structured Arms},
  booktitle = {AAAI},
  year      = {2017}
}

@article{Kveton17LowRank,
  author    = {Branislav Kveton and
               Csaba Szepesv{\'{a}}ri and
               Anup Rao and
               Zheng Wen and
               Yasin Abbasi{-}Yadkori and
               S. Muthukrishnan},
  title     = {Stochastic Low-Rank Bandits},
  journal   = {Preprint arXiv:1712.04644},
  year      = {2017}
}

@TechReport{Combes14Unimodal,
  Title                    = {{Unimodal Bandits without Smoothness}},
  Author                   = {Combes, R. and Prouti{\`e}re, A.},
  Year                     = {2014},

  Booktitle                = {{arXiv:1406.7447}}
}

@Conference{Combes14802,
  Title                    = {{Optimal rate sampling in 802.11 systems}},
  Author                   = {Combes, R. and Prouti{\`e}re, A. and Yun, D. and Ok, J. and Yi, Y.},
  Booktitle                = {{IEEE INFOCOM}},
  Year                     = {2014},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.24}
}

@InProceedings{CombUCB15,
  Title                    = {Combinatorial bandits revisited},
  Author                   = {Combes, R. and Talebi, S. and Prouti{\`e}re, A. and Lelarge, M.},
  Booktitle                = {Advances in Neural Information Processing Systems (NeurIPS)},
  Year                     = {2015},

  Owner                    = {emilie},
  Timestamp                = {2015.11.30}
}

@InProceedings{Vayatis13GP,
  Title                    = {{Parallel Gaussian Process Optimization with Upper Confidence Bounds and Pure Exploration}},
  Author                   = {Contal, E. and Buffoni, D. and Vayatis, N.},
  Booktitle                = {{Proceedings of the European Conference on Machine Learning}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.07.17}
}

@InProceedings{Contal15Chaining,
  Title                    = {Optimization for Gaussian Processes via Chaining},
  Author                   = {Contal, E. and Malherbe, C. and Vayatis, N.},
  Booktitle                = {NeurIPS workshop on Bayesian Optimization},
  Year                     = {2015},

  Owner                    = {emilie},
  Timestamp                = {2016.10.17}
}

@Book{Cover:Thomas,
  Title                    = {{Elements of Information Theory (2nd Edition)}},
  Author                   = {Cover, T. and Thomas, J.},
  Editor                   = {Wiley},
  Publisher                = {Wiley},
  Year                     = {2006},

  Owner                    = {kaufmann},
  Timestamp                = {2012.11.29}
}

@InProceedings{Danial08,
  Title                    = {{Stochastic Linear Optimization under Bandit Feedback}},
  Author                   = {Dani, V. and Hayes, T.P. and Kakade, S.M.},
  Booktitle                = {{Advances in Neural Information and Signal Processing}},
  Year                     = {2008},
  Pages                    = {355--366},

  Abstract                 = {stochastic linear bandit, dual setting algo Confidence Ball (L1 and L2) Minimax Lower bound d*sqrt(n) (rather adversarial) on the hypercube Upper bound in high probability on the regret - problem dependant when Delta>0 - problem independant},
  Journal                  = {Conference On Learning Theory (COLT)},
  Owner                    = {kaufmann},
  Timestamp                = {2011.11.16}
}

@InProceedings{Danial07,
  Title                    = {{The Price of Bandit Information in Online Optimization}},
  Author                   = {Dani, V. and Hayes, T. and Kakade, S.},
  Booktitle                = {{Advances in Neural Information and Signal Processing}},
  Year                     = {2007},

  Abstract                 = {adversarial linear bandit (oblivious?) mention of a lower bound (not very clear, see their paper from 2008) (on the hypercube) Geometric Hedge algorithm},
  Owner                    = {kaufmann},
  Timestamp                = {2013.01.16}
}

@Article{DeLaPenaal04,
  Title                    = {{Self-Normalized Processes: Exponential inequalities, moment bounds and iterated logarithm laws}},
  Author                   = {{De La Pena}, V. and Klass, M. and Lai, T.L.},
  Journal                  = {The Annals of Probability},
  Year                     = {2004},
  Pages                    = {1902--1933},
  Volume                   = {32(3A)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.04}
}

@Book{DeLaPenaal09Book,
  Title                    = {{Self-normalized processes. Limit Theory and Statistical applications}},
  Author                   = {{De La Pena}, V.H. and Lai, T.L. and Q., Shao},
  Publisher                = {Springer},
  Year                     = {2009},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.04}
}

@Book{DemboZeitouni,
  Title                    = {{Large Deviations Techniques and Applications, 2nd Edition}},
  Author                   = {Dembo, Amir and Zeitouni, Ofer},
  Publisher                = {Springer},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2013.01.23}
}

@Article{Romaric14,
  Title                    = {{Efficient Eigen-updating for Spectral Graph Clustering}},
  Author                   = {Dhanjal, C. and Gaudel, R. and Cl{\'e}mencon, S.},
  Journal                  = {arXiv:1301.1318},
  Year                     = {2014},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.24}
}

@Conference{SpherCov06,
  Title                    = {{Covering spheres and balls with smaller balls}},
  Author                   = {Dumer, I.},
  Booktitle                = {{ISIT}},
  Year                     = {2006},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@inproceedings{Kveton19PHE,
  author    = {Branislav Kveton and
               Csaba Szepesv{\'{a}}ri and
               Mohammad Ghavamzadeh and
               Craig Boutilier},
  title     = {Perturbed-History Exploration in Stochastic Multi-Armed Bandits},
  booktitle = {Proceedings of the Twenty-Eighth International Joint Conference on
               Artificial Intelligence (IJCAI)},
  year      = {2019}
}

@InProceedings{Durand14AAAI,
  Title                    = {{Thompson Sampling for Combinatorial Bandits and Its Application to Online Feature Selection}},
  Author                   = {Durand, A. and Gagn{\'e}, C.},
  Booktitle                = {{AAAI-14 Workshop on Sequential Decision-Making with Big Data}},
  Year                     = {2014}
}

@Book{Durrett10,
  Title                    = {{Probability: Theory and Examples}},
  Author                   = {Durrett, R.},
  Publisher                = {Cambridge University Press},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.17}
}

@Article{Eckles14TSBootstrap,
  Title                    = {Thompson Sampling with the online bootstrap},
  Author                   = {Eckles, D. and Kaptein, M.},
  Journal                  = {arXiv:1410.4009},
  Year                     = {2014},

  Owner                    = {emilie},
  Timestamp                = {2015.10.13}
}

@Article{EvenDaral06,
  Title                    = {{Action Elimination and Stopping Conditions for the Multi-Armed Bandit and Reinforcement Learning Problems}},
  Author                   = {Even-Dar, E. and Mannor, S. and Mansour, Y.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2006},
  Pages                    = {1079--1105},
  Volume                   = {7},

  Abstract                 = {Pure exploration problem of finding the best arm in a PAC setting (with a level epsilon of tolerance) Several algorithms are proposed, with successive elimination sometimes},
  Owner                    = {kaufmann},
  Timestamp                = {2012.09.04}
}

@inproceedings{Baransi14BESA,
  author    = {Akram Baransi and
               Odalric{-}Ambrym Maillard and
               Shie Mannor},
  title     = {Sub-sampling for Multi-armed Bandits},
  booktitle = {Machine Learning and Knowledge Discovery in Databases - European Conference,
               {ECML} / {PKDD}},
  year      = {2014}
}

@article{FDA19,
author = {{Food and Drugs Administration (FDA)}},
title = {Adaptive Design Clinical Trials for Drugs and Biologics},
year = {2018}
}

@Book{Berry10Book,
  Title                    = {Bayesian adaptive methods for clinical trials},
  Author                   = {S.M. Berry and B.P. Carlin and J.J. Lee and P. Muller},
  Publisher                = {CRC Press},
  Year                     = {2010}
}

@article{Berrys16Alzheimer,
author = {Andrew Satlin and Jinping Wang and Veronika Logovinsky and Scott Berry and Chad Swanson and Shobha Dhadda and Donald A. Berry},
title = {Design of a Bayesian adaptive phase 2 proof-of-concept trial for BAN2401, a putative disease-modifying monoclonal antibody for the treatment of Alzheimer’s disease},
journal = {Alzheimer’s Dementia: Translational Research and Clinical Intervention},
volume = {2(1)},
year = {2016}
}

@Article{Feldman62,
  Title                    = {{Contributions to the ''two-armed bandit''}},
  Author                   = {Feldman, D.},
  Journal                  = {The Annals of Mathematical Statistics},
  Year                     = {1962},
  Pages                    = {947--956},
  Volume                   = {33(3)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.24}
}

@PhdThesis{filippi10,
  Title                    = {{Optimistic strategies in Reinforcement Learning \emph{(in French)}}},
  Author                   = {Filippi, S.},
  School                   = {Telecom ParisTech},
  Year                     = {2010},

  Url                      = {http://tel.archives-ouvertes.fr/tel-00551401}
}

@InProceedings{allerton10,
  Title                    = {{Optimism in Reinforcement Learning and {K}ullback-{L}eibler Divergence}},
  Author                   = {Filippi, S. and Capp{\'e}, O. and Garivier, A.},
  Booktitle                = {{Allerton Conference on Communication, Control, and Computing}},
  Year                     = {2010},

  Address                  = {Monticello, US},

  Eprint                   = {1004.5229}
}

@inproceedings{DumitrascuFE18,
  author    = {Bianca Dumitrascu and
               Karen Feng and
               Barbara E. Engelhardt},
  title     = {{PG-TS:} Improved Thompson Sampling for Logistic Contextual Bandits},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2018}
}


@InProceedings{Filippi:GLM10,
  Title                    = {{Parametric Bandits : The Generalized Linear case}},
  Author                   = {Filippi, S. and Capp{\'e}, O. and Garivier, A. and Szepesv{\'a}ri, C.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2012.05.02}
}

@InProceedings{Fonteneaual13,
  Title                    = {{An optimistic posterior sampling strategy for Bayesian reinforcement learning}},
  Author                   = {Fonteneau, R. and Korda, N. and Munos, R.},
  Booktitle                = {{Workshop on Bayesian Optimization, NeurIPS}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.18}
}

@TechReport{Frostig:Weiss99,
  Title                    = {{Four proofs of {G}ittins' multiarmed bandit theorem}},
  Author                   = {Frostig, E. and Weiss, G.},
  Year                     = {1999},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.01}
}

@InProceedings{Gabillon12UGapE,
  Title                    = {{Best Arm Identification: A Unified Approach to Fixed Budget and Fixed Confidence}},
  Author                   = {Gabillon, V. and Ghavamzadeh, M. and Lazaric, A.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2012},

  Owner                    = {kaufmann},
  Timestamp                = {2012.11.06}
}

@InProceedings{Aurelien13,
  Title                    = {{Informational Confidence Bounds for Self-Normalized Averages and Applications}},
  Author                   = {Garivier, A.},
  Booktitle                = {{IEEE Information Theory Workshop}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.20}
}

@InProceedings{AOKLUCB,
  Title                    = {{The {KL-UCB} algorithm for bounded stochastic bandits and beyond}},
  Author                   = {Garivier, A. and Capp{\'e}, O.},
  Booktitle                = {{Proceedings of the 24th Conference on Learning Theory}},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@article{GK19Epsilon,
  author    = {Aur\'elien Garivier and
               Emilie Kaufmann},
  title     = {Non-Asymptotic Sequential Tests for Overlapping Hypotheses and application to near optimal arm identification in bandit models},
  year      = {2021},
  journal   = {Sequential Analysis},
  volume = {40(1)},
  pages = {61-96}
}

@InProceedings{CsabaTracking,
  Title                    = {Active Learning in Multi-Armed Bandits},
  Author                   = {Antos, A. and Grover, V. and Szepesv\'{a}ri, C.},
  Booktitle                = {Algorithmic Learning Theory},
  Year                     = {2008},

  Owner                    = {emilie},
  Timestamp                = {2016.01.28}
}

@article{VaidhiyanS18,
  author    = {Nidhin Koshy Vaidhiyan and
               Rajesh Sundaresan},
  title     = {Learning to Detect an Oddball Target},
  journal   = {{IEEE} Transaction on Information Theory},
  volume    = {64},
  number    = {2},
  pages     = {831--852},
  year      = {2018}
}



@InProceedings{GK16,
  Title                    = {Optimal Best Arm Identification with Fixed Confidence},
  Author                   = {Garivier, Aur{\'e}lien and Kaufmann, Emilie},
  Booktitle                = {Proceedings of the 29th Conference On Learning Theory},
  Year                     = {2016}
}


@InProceedings{Jouini09,
  Title                    = {
Multi-Armed Bandit Based Policies for
Cognitive Radio’s Decision Making Issues},
  Author                   = {Jouini, W. and Ernst, D. and Moy, C. and Palicot, J.},
  Booktitle                = {International Conference Signals, Circuits
and Systems (IEEE)},
  Year                     = {2009}
}


@inproceedings{Garivier17DF,
author = {Garivier, A. and M\'enard, P. and Rossi, L.},
title = {Thresholding Bandit for Dose-ranging: The Impact of Monotonicity},
booktitle = {International Conference on Machine Learning, Artificial Intelligence and Applications},
year = {2019}}

@InProceedings{GKK16,
  Title                    = {Maximin Action Identification: A New Bandit Framework for Games},
  Author                   = {Garivier, A. and Kaufmann, E. and Koolen, W.M.},
  Booktitle                = {Proceedings of the 29th Conference On Learning Theory},
  Year                     = {2016},

  Owner                    = {emilie},
  Timestamp                = {2016.05.25}
}

@article{GMS16,
  author    = {Aur{\'{e}}lien Garivier and
               Pierre M{\'{e}}nard and
               Gilles Stoltz},
  title     = {Explore First, Exploit Next: The True Shape of Regret in Bandit Problems},
  journal   = {Mathemathics of Opereration Research},
  volume    = {44},
  number    = {2},
  pages     = {377--399},
  year      = {2019},
}

@InProceedings{GarivierMoulines11,
  Title                    = {{On Upper-Confidence Bound Policies for Switching Bandit Problems}},
  Author                   = {Garivier, A. and Moulines, E.},
  Booktitle                = {{Proceedings of the 22nd conference on Algorithmic Learning Theory}},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@Article{GinebraClayton99,
  Title                    = {{Small-sample performance of Bernoulli two-armed bandit Bayesian strategies}},
  Author                   = {Ginebra, J. and Clayton, M.K.},
  Journal                  = {Journal of Statistical Planning and Inference},
  Year                     = {1999},
  Pages                    = {107--122},
  Volume                   = {79(1)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.26}
}

@TechReport{GinebraClayton94TechReportFreq,
  Title                    = {{Small-sample frequentist properties of Bernoulli two-armed bandit Bayesian strategies}},
  Author                   = {Ginebra, J. and Clayton, M.K.},
  Institution              = {University of Wisconsin},
  Year                     = {1994},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.05.31}
}

@Article{Gittins79,
  Title                    = {{Bandit processes and dynamic allocation indices}},
  Author                   = {Gittins, J.C.},
  Journal                  = {Journal of the Royal Statistical Society, Series B},
  Year                     = {1979},
  Number                   = {2},
  Pages                    = {148--177},
  Volume                   = {41},

  Keywords                 = {bandit},
  Publisher                = {JSTOR}
}

@Book{GittinsBook11,
  Title                    = {{Multi-armed bandit allocation indices (2nd Edition)}},
  Author                   = {Gittins, J. and Glazebrook, K. and Weber, R.},
  Editor                   = {Wiley},
  Publisher                = {Wiley},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2012.07.06}
}

@Article{Gittins:Jones79,
  Title                    = {{A dynamic allocation index for the discounted multiarmed bandit problem}},
  Author                   = {Gittins, J.C. and Jones, D.M.},
  Journal                  = {Biometrika},
  Year                     = {1979},
  Number                   = {3},
  Pages                    = {561--565},
  Volume                   = {66},

  Keywords                 = {bandit},
  Publisher                = {Biometrika Trust}
}

@InProceedings{Gittins:Jones74,
  Title                    = {{A dynamic allocation index for the sequential design of experiments}},
  Author                   = {Gittins, J. and Jones, D.M.},
  Booktitle                = {{Progress in Statistics (proceedings of the 1972 European Meeting of Statisticians)}},
  Year                     = {1974},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.01}
}

@InProceedings{GlynnJuneja04,
  Title                    = {A large deviations perspective on ordinal optimization},
  Author                   = {Glynn, P. and Juneja, S.},
  Booktitle                = {Proceedings of the 2004 Winter Simulation Conference (IEEE)},
  Year                     = {2004},

  Owner                    = {emilie},
  Timestamp                = {2016.08.05}
}

@InProceedings{Gopalan14TSComplex,
  Title                    = {{Thompson Sampling for Complex Online Problems}},
  Author                   = {Gopalan, A. and Mannor, S. and Mansour, Y.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.17}
}

@Article{GranmoBLA,
  Title                    = {{Solving two-armed Bernoulli Bandit Problems using a Bayesian Learning Automaton}},
  Author                   = {Granmo, O.C.},
  Journal                  = {International Journal of Intelligent Computing and Cybernetics},
  Year                     = {2010},
  Pages                    = {207--234},
  Volume                   = {3(2)},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@Article{GravesLai97,
  Title                    = {{Asymptotically Efficient adaptive choice of control laws in controlled markov chains}},
  Author                   = {Graves, T.L. and Lai, T.L.},
  Journal                  = {SIAM Journal on Control and Optimization},
  Year                     = {1997},
  Pages                    = {715--743},
  Volume                   = {35(3)},

  Abstract                 = {generalisation de la borne de Lai et Robbins: - � des bandits om on a des informations pr�cise sur les param�tre des bras (e.g. bounded regret) - aux restless bandits (trop simple?) - aux switching bandits},
  Owner                    = {kaufmann},
  Timestamp                = {2013.07.15}
}

@InProceedings{Grill16TrailBlazer,
  Title                    = {Blazing the trails before beating the path: Sample-efficient Monte-Carlo planning},
  Author                   = {Grill, J.-B. and Valko, M. and Munos, R.},
  Booktitle                = {Neural Information Processing Systems (NeurIPS)},
  Year                     = {2016},

  Owner                    = {emilie},
  Timestamp                = {2016.10.17}
}

@inproceedings{Omar19Smoothcruiser,
  author    = {J.-B. Grill and
               Omar Darwiche Domingues and
               Pierre M{\'{e}}nard and
               R{\'{e}}mi Munos and
               Michal Valko},
  title     = {Planning in entropy-regularized Markov decision processes and games},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2019}
}


@inproceedings{NIPS17,
  author    = {Emilie Kaufmann and
               Wouter M. Koolen},
  title     = {{M}Onte-{C}Arlo Tree Search by Best Arm Identification},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2017},
}

@inproceedings{HuangASM17,
  author    = {Ruitong Huang and
               Mohammad M. Ajallooeian and
               Csaba Szepesv{\'{a}}ri and
               Martin M{\"{u}}ller},
  title     = {Structured Best Arm Identification with Fixed Confidence},
  booktitle = {International Conference on Algorithmic Learning Theory (ALT)},
  year      = {2017}
}

@inproceedings{Chen17CombBAI,
  author    = {Lijie Chen and
               Anupam Gupta and
               Jian Li and
               Mingda Qiao and
               Ruosong Wang},
  title     = {Nearly Optimal Sampling Algorithms for Combinatorial Pure Exploration},
  booktitle = {Proceedings of the 30th Conference on Learning Theory (COLT)},
  year      = {2017},
}

@inproceedings{chen2017nearly,
  title={Nearly instance optimal sample complexity bounds for top-k arm selection},
  author={Chen, Lijie and Li, Jian and Qiao, Mingda},
  booktitle={Artificial Intelligence and Statistics},
  year={2017}
}

@inproceedings{Jin18OptQL,
  author    = {Chi Jin and
               Zeyuan Allen{-}Zhu and
               S{\'{e}}bastien Bubeck and
               Michael I. Jordan},
  title     = {Is {Q}-Learning Provably Efficient?},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2018}
}

@InProceedings{grill2015black-box,
  Title                    = {{Black-box optimization of noisy functions with unknown smoothness}},
  Author                   = {Grill, Jean-Bastien and Valko, Michal and Munos, R{\'{e}}mi},
  Booktitle                = {Neural Information Processing Systems},
  Year                     = {2015},

  Abstract                 = {We study the problem of black-box optimization of a function f of any dimension, given function evaluations perturbed by noise. The function is assumed to be locally smooth around one of its global optima, but this smoothness is unknown. Our contribution is an adaptive optimization algorithm, POO or parallel optimistic optimization, that is able to deal with this setting. POO performs almost as well as the best known algorithms requiring the knowledge of the smoothness. Furthermore, POO works for a larger class of functions than what was previously considered, especially for functions that are difficult to optimize, in a very precise sense. We provide a finite-time analysis of POO's performance, which shows that its error after n evaluations is at most a factor of sqrt(ln n) away from the error of the best known optimization algorithms using the knowledge of the smoothness.},
  Owner                    = {emilie},
  Timestamp                = {2016.05.26}
}

@InProceedings{Guha14TSweird,
  Title                    = {{Stochastic Regret Minimization via Thompson Sampling}},
  Author                   = {Guha, S. and Munagala, K.},
  Booktitle                = {{Proceedings of the 27th Conference On Learning Theory}},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.17}
}

@InProceedings{HeidrichMeisneral09,
  Title                    = {{{H}oeffding and {B}ernstein Races for Selecting Policies in Evolutionary Direct Policy Search}},
  Author                   = {Heidrich-Meisner, V. and Igel, C.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2009},

  Owner                    = {kaufmann},
  Timestamp                = {2012.10.01}
}

@Article{Hoeffding63,
  Title                    = {{Probability inequalities for sums of bounded random variables}},
  Author                   = {Hoeffding, W.},
  Journal                  = {Journal of the American Statistical Association},
  Year                     = {1963},
  Pages                    = {13:30},
  Volume                   = {58},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.19}
}

@article{Shahriari16Survey,
  author    = {Bobak Shahriari and
               Kevin Swersky and
               Ziyu Wang and
               Ryan P. Adams and
               Nando de Freitas},
  title     = {Taking the Human Out of the Loop: {A} Review of Bayesian Optimization},
  journal   = {Proceedings of the {IEEE}},
  volume    = {104},
  number    = {1},
  pages     = {148--175},
  year      = {2016},
}


@InProceedings{Hoffmanal14,
  Title                    = {{On correlation and budget constraints in model-based bandit optimization with application to automatic machine learning}},
  Author                   = {Hoffman, M. and Shahriari, B. and de Freitas, N.},
  Booktitle                = {{Proceedings of the 17th International Conference on Artificial Intelligence and Statistics}},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.07.02}
}

@InProceedings{HondaTakemura10,
  Title                    = {{An Asymptotically Optimal Bandit Algorithm for Bounded Support Models}},
  Author                   = {Honda, J. and Takemura, A.},
  Booktitle                = {{Proceedings of the 23rd Conference on Learning Theory}},
  Year                     = {2010}
}

@InProceedings{HondaTakemura14TS,
  Title                    = {{Optimality of Thompson Sampling for Gaussian Bandits depends on priors}},
  Author                   = {Honda, J. and Takemura, A.},
  Booktitle                = {{Proceedings of the 17th conference on Artificial Intelligence and Statistics}},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.17}
}

@article{AlphaZero,
  author    = {David Silver and
               Thomas Hubert and
               Julian Schrittwieser and
               Ioannis Antonoglou and
               Matthew Lai and
               Arthur Guez and
               Marc Lanctot and
               Laurent Sifre and
               Dharshan Kumaran and
               Thore Graepel and
               Timothy P. Lillicrap and
               Karen Simonyan and
               Demis Hassabis},
  title     = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  journal   = {Science},
  volume    = {362},
  issue = {6419},
  page = {1140-1144},
  year      = {2018},
}

@inproceedings{Azar17UCBVI,
  author    = {Mohammad Gheshlaghi Azar and
               Ian Osband and
               R{\'{e}}mi Munos},
  title     = {Minimax Regret Bounds for Reinforcement Learning},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning (ICML)},
  pages     = {263--272},
  year      = {2017}
}

@inproceedings{Kveton19Giro,
  author    = {Branislav Kveton and
               Csaba Szepesv{\'{a}}ri and
               Sharan Vaswani and
               Zheng Wen and
               Tor Lattimore and
               Mohammad Ghavamzadeh},
  title     = {Garbage In, Reward Out: Bootstrapping Exploration in Multi-Armed Bandits},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning (ICML)},
  year      = {2019}
}

@article{Abbasi19Bootstrap,
  author    = {Botao Hao and
               Yasin Abbasi{-}Yadkori and
               Zheng Wen and
               Guang Cheng},
  title     = {Bootstrapping Upper Confidence Bound},
  booktitle = {Advances in Neural Processing Systems (NeurIPS)},
  year      = {2019}
}


@Article{AuerUCRL10,
  Title                    = {{Near-Optimal regret bounds for reinforcement learning}},
  Author                   = {Jaksch, T. and Ortner, R. and Auer, P.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2010},
  Pages                    = {1563--1600},
  Volume                   = {11},
  Owner                    = {kaufmann},
  Timestamp                = {2013.02.28}
}

@Article{Marjorie15,
  Title                    = {{Sequential design of computer experiments for the assessment of fetus exposure to electromagnetic fields}},
  Author                   = {Jala, M. and L{\'e}vy-Leduc, C. and Moulines, E. and Conil, E. and Wiart, J.},
  Journal                  = {Technometrics},
  Year                     = {2015},
  Volume                   = {},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.20}
}

@InProceedings{Jala:al12,
  Title                    = {{Sequential design of computer experiments for parameter estimation}},
  Author                   = {Jala, M. and L{\'e}vy-Leduc, C. and Moulines, E. and Conil, E. and Wiart, J.},
  Booktitle                = {{EUSIPCO}},
  Year                     = {2012},

  Owner                    = {kaufmann},
  Timestamp                = {2013.01.28}
}

@InProceedings{Jamieson15Duel,
  Title                    = {{Sparse Dueling Bandits}},
  Author                   = {Jamieson, K. and Katariya, S. and Deshpande, A. and Nowak, R.},
  Booktitle                = {{Proceedings of the 18th Conference on Artificial Intelligence and Statistics}},
  Year                     = {2015},

  Owner                    = {Utilisateur},
  Timestamp                = {2015.02.07}
}

@inproceedings{Komiyama16Duelling,
  author    = {Junpei Komiyama and
               Junya Honda and
               Hiroshi Nakagawa},
  title     = {Copeland Dueling Bandit Problem: Regret Lower Bound, Optimal Algorithm,
               and Computationally Efficient Algorithm},
  booktitle = {Proceedings of the 33nd International Conference on Machine Learning (ICML)},
  year      = {2016}
}

@inproceedings{Lattimore19PM,
  author    = {Tor Lattimore and
               Csaba Szepesv{\'{a}}ri},
  title     = {Cleaning up the neighborhood: {A} full classification for adversarial
               partial monitoring},
  booktitle = {Algorithmic Learning Theory (ALT)},
  year      = {2019}
}

@InProceedings{Jamiesonal14LILUCB,
  Title                    = {{lil'{UCB}: an Optimal Exploration Algorithm for Multi-Armed Bandits}},
  Author                   = {Jamieson, K. and Malloy, M. and Nowak, R. and Bubeck, S.},
  Booktitle                = {{Proceedings of the 27th Conference on Learning Theory}},
  Year                     = {2014}
}

@Article{Jeffreys46,
  Title                    = {{An invariant form for prior probability in estimation problems}},
  Author                   = {Jeffreys, H.},
  Journal                  = {Proceedings of the Royal Society of London, Serie A.},
  Year                     = {1946},
  Pages                    = {453--461},
  Volume                   = {286},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.23}
}

@Article{Jennisonal84,
  Title                    = {{Asymptotically optimal procedures for sequential adaptive selection of the best of several normal means}},
  Author                   = {Jennison, Christopher and Johnstone, Iain M. and Turnbull, Bruce W.},
  Journal                  = {Statistical Decision Theory and Related Topics III},
  Year                     = {1982},
  Pages                    = {55--86},
  Volume                   = {2},

  Owner                    = {Emilie},
  Timestamp                = {2013.04.24}
}




@article{Feldman14BRUE,
  author    = {Zohar Feldman and
               Carmel Domshlak},
  title     = {Simple Regret Optimization in Online Planning for Markov Decision
               Processes},
  journal   = {J. Artif. Intell. Res.},
  volume    = {51},
  pages     = {165--205},
  year      = {2014}
}

@article{Feldman12BRUE,
  author    = {Zohar Feldman and
               Carmel Domshlak},
  title     = {Simple Regret Optimization in Online Planning for Markov Decision
               Processes},
  journal   = {arXiv:1206.3382},
  year      = {2012}
}

@inproceedings{Tolpin12SRMCTS,
  author    = {David Tolpin and
               Solomon Eyal Shimony},
  title     = {{MCTS} Based on Simple Regret},
  booktitle = {Proceedings of the Twenty-Sixth {AAAI} Conference on Artificial Intelligence,
               July 22-26, 2012, Toronto, Ontario, Canada.},
  year      = {2012}
}

@inproceedings{Leurent19KLOLOP,
    title={Practical Open-Loop Optimistic Planning},
    author={Edouard Leurent and Odalric-Ambrym Maillard},
    year={2019},
    booktitle={Proceedings of ECML PKDD 2019}
}

@inproceedings{Hessel18Rainbow,
  author    = {Matteo Hessel and
               Joseph Modayil and
               Hado van Hasselt and
               Tom Schaul and
               Georg Ostrovski and
               Will Dabney and
               Dan Horgan and
               Bilal Piot and
               Mohammad Gheshlaghi Azar and
               David Silver},
  title     = {Rainbow: Combining Improvements in Deep Reinforcement Learning},
  booktitle = {Proceedings of the Thirty-Second {AAAI} Conference on Artificial Intelligence},
  year      = {2018}
}


@article{Mnih15DQN,
  author    = {Volodymyr Mnih and
               Koray Kavukcuoglu and
               David Silver and
               Andrei A. Rusu and
               Joel Veness and
               Marc G. Bellemare and
               Alex Graves and
               Martin A. Riedmiller and
               Andreas Fidjeland and
               Georg Ostrovski and
               Stig Petersen and
               Charles Beattie and
               Amir Sadik and
               Ioannis Antonoglou and
               Helen King and
               Dharshan Kumaran and
               Daan Wierstra and
               Shane Legg and
               Demis Hassabis},
  title     = {Human-level control through deep reinforcement learning},
  journal   = {Nature},
  volume    = {518},
  number    = {7540},
  pages     = {529--533},
  year      = {2015}
}

@inproceedings{Busoniu12OPMDP,
  author    = {Lucian Busoniu and
               R{\'{e}}mi Munos},
  title     = {Optimistic planning for Markov decision processes},
  booktitle = {Proceedings of the Fifteenth International Conference on Artificial
               Intelligence and Statistics,  (AISTATS)},
  year      = {2012}
}

@inproceedings{Bubeck10OLOP,
  author    = {S{\'{e}}bastien Bubeck and
               R{\'{e}}mi Munos},
  title     = {Open Loop Optimistic Planning},
  booktitle = {Conference on Learning Theory (COLT)},
  year      = {2010}
}

@Article{Jones:alEI98,
  Title                    = {{Efficient Global Optimization of Expensive Black-Box Functions}},
  Author                   = {Jones, Donal R. and Schonlau, Matthias and Welch, William},
  Journal                  = {Journal of Global Optimization},
  Year                     = {1998},
  Pages                    = {455--492},
  Volume                   = {13(4)},

  Owner                    = {kaufmann},
  Timestamp                = {2013.01.28}
}

@InProceedings{JunNowak16,
  Title                    = {Anytime exploration for Multi-armed Bandits using Confidence Information},
  Author                   = {Jun, K-W and Nowak, R.},
  Booktitle                = {International Conference on Machine Learning (ICML)},
  Year                     = {2016},

  Owner                    = {emilie},
  Timestamp                = {2016.08.05}
}

@PhdThesis{Shivaram:PHD,
  Title                    = {{Learning Methods for Sequential Decision Making with Imperfect Representations}},
  Author                   = {Kalyanakrishnan, S.},
  School                   = {Departement of Computer Science, The University of Texas at Austin},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2012.12.19}
}

@InProceedings{Shivaram:al10,
  Title                    = {{Efficient Selection in Multiple Bandit Arms: Theory and Practice}},
  Author                   = {Kalyanakrishnan, S. and Stone, P.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2012.09.05}
}

@InProceedings{Shivaramal12,
  Title                    = {{{PAC} subset selection in stochastic multi-armed bandits}},
  Author                   = {Kalyanakrishnan, S. and Tewari, A. and Auer, P. and Stone, P.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2012},

  Owner                    = {kaufmann},
  Timestamp                = {2012.08.22}
}

@InProceedings{Karnin:al13,
  Title                    = {{Almost optimal Exploration in multi-armed bandits}},
  Author                   = {Karnin, Z. and Koren, T. and Somekh, O.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2013},

  Owner                    = {Emilie},
  Timestamp                = {2013.06.21}
}

@InProceedings{Claire17AISTATS,
  Title                    = {Stochastic Rank 1 Bandit},
  Author                   = {Katariya, S. and Kveton, B. and Szepesv\'{a}ri, C. and Vernade, C. and Wen, Z.},
  Booktitle                = {AISTATS},
  Year                     = {2017},

  Owner                    = {emilie},
  Timestamp                = {2017.08.13}
}

@InProceedings{Claire17IJCAI,
  Title                    = {Bernoulli Rank-1 Bandits for Click Feedback},
  Author                   = {Katariya, S. and Kveton, B. and Szepesv\'{a}ri, C. and Vernade, C. and Wen, Z.},
  Booktitle                = {IJCAI},
  Year                     = {2017},

  Owner                    = {emilie},
  Timestamp                = {2017.08.13}
}

@Article{KatRob:95Gauss,
  Title                    = {{Sequential choice from several populations}},
  Author                   = {Katehakis, M. and Robbins, H.},
  Journal                  = {Proceedings of the National Academy of Science},
  Year                     = {1995},
  Pages                    = {8584--8585},
  Volume                   = {92},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.25}
}

@Article{AOS16,
  Title                    = {On Bayesian Index Policies for Sequential Resource Allocation},
  Author                   = {Kaufmann, E.},
  Journal                  = {Preprint arXiv:1601.01190},
  Year                     = {2016},

  Owner                    = {emilie},
  Timestamp                = {2016.02.01}
}

@PhdThesis{MaThese,
  Title                    = {{Analyse de strat{\'e}gies bay{\'e}siennes et fr{\'e}quentistes pour l'allocation s{\'e}quentielle de ressources}},
  Author                   = {Kaufmann, E.},
  Year                     = {2014},

  Organization             = {Telecom ParisTech}
}

@Article{JMLR15,
  Title                    = {{On the Complexity of Best Arm Identification in Multi-Armed Bandit Models}},
  Author                   = {Kaufmann, E. and Capp{\'e}, O. and Garivier, A.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2016},
  Number                   = {1},
  Pages                    = {1-42},
  Volume                   = {17}
}

@inproceedings{Russac21ABn,
  author    = {Yoan Russac and
               Christina Katsimerou and
               Dennis Bohle and
               Olivier Capp{\'{e}} and
               Aur{\'{e}}lien Garivier and
               Wouter M. Koolen},
  title     = {A/B/n Testing with Control in the Presence of Subpopulations},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2021}
}

@InProceedings{COLT14,
  Title                    = {{On the Complexity of A/B Testing}},
  Author                   = {Kaufmann, E. and Capp{\'e}, O. and Garivier, A.},
  Booktitle                = {{Proceedings of the 27th Conference On Learning Theory}},
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.23}
}

@InProceedings{AISTATS12,
  Title                    = {{On {B}ayesian {U}pper-{C}onfidence {B}ounds for Bandit Problems}},
  Author                   = {Kaufmann, E. and Capp{\'e}, O. and Garivier, A.},
  Booktitle                = {{Proceedings of the 15th conference on Artificial Intelligence and Statistics}},
  Year                     = {2012},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@Article{ESAIM17,
  Title                    = {Learning the distribution with largest mean: two bandit frameworks.},
  Author                   = {Kaufmann, E. and Garivier, A.},
  Journal                  = {ESAIM: Proceedings and Surveys},
  Year                     = {2017},
  Volume                   = {60},
  Pages = {114-131}
}

@ARTICLE{GMS18,
  TITLE = {Explore First, Exploit Next: The True Shape of Regret in Bandit Problems},
  AUTHOR = {Aurélien Garivier and Pierre Ménard and Gilles Stoltz},
  JOURNAL = {Mathematics of Operations Research},
  YEAR = {Jun. 2018},
  ARXIV = {1602.07182},
  HAL = {01276324},
}



@InProceedings{COLT13,
  Title                    = {{Information complexity in bandit subset selection}},
  Author                   = {Kaufmann, E. and Kalyanakrishnan, S.},
  Booktitle                = {{Proceeding of the 26th Conference On Learning Theory.}},
  Year                     = {2013},

  Owner                    = {Emilie},
  Timestamp                = {2013.04.22}
}

@InProceedings{ALT12,
  Title                    = {{Thompson Sampling : an Asymptotically Optimal Finite-Time Analysis}},
  Author                   = {Kaufmann, E. and Korda, N. and Munos, R.},
  Booktitle                = {{Proceedings of the 23rd conference on Algorithmic Learning Theory}},
  Year                     = {2012},

  Owner                    = {kaufmann},
  Timestamp                = {2012.08.22}
}

@Book{RPS,
  Title                    = {{Requiem pour {S}tanley}},
  Author                   = {Kaufmann, S.},
  Publisher                = {Editions Lulu},
  Year                     = {2014},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.08.24}
}

@Conference{Kocak14SpectralTS,
  Title                    = {{Spectral Thompson Sampling}},
  Author                   = {Koc{\'a}k, T. and Valko, M. and Munos, R. and Agrawal, S.},
  Booktitle                = {{International Conference on Machine Learning}},
  Year                     = {2014},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.24}
}

@InProceedings{Kocsis2006,
  Title                    = {Bandit Based Monte-carlo Planning},
  Author                   = {Kocsis, Levente and Szepesv\'{a}ri, Csaba},
  Booktitle                = {Proceedings of the 17th European Conference on Machine Learning},
  Year                     = {2006},

  Address                  = {Berlin, Heidelberg},
  Pages                    = {282--293},
  Publisher                = {Springer-Verlag},
  Series                   = {ECML'06},

  Acmid                    = {2091633},
  Doi                      = {10.1007/11871842_29},
  ISBN                     = {3-540-45375-X, 978-3-540-45375-8},
  Location                 = {Berlin, Germany},
  Numpages                 = {12},
  Url                      = {http://dx.doi.org/10.1007/11871842_29}
}

@InProceedings{KocsisBBMCP06,
  Title                    = {Bandit Based Monte-carlo Planning},
  Author                   = {Kocsis, L. and Szepesv\'{a}ri, C.},
  Booktitle                = {Proceedings of the 17th European Conference on Machine Learning},
  Year                     = {2006},

  Address                  = {Berlin, Heidelberg},
  Pages                    = {282--293},
  Publisher                = {Springer-Verlag},
  Series                   = {ECML'06},

  Acmid                    = {2091633},
  Comment-doi              = {10.1007/11871842_29},
  Comment-url              = {http://dx.doi.org/10.1007/11871842_29},
  ISBN                     = {3-540-45375-X, 978-3-540-45375-8},
  Location                 = {Berlin, Germany},
  Numpages                 = {12}
}

@InProceedings{NeurIPS13,
  Title                    = {{Thompson Sampling for 1-dimensional Exponential family bandits}},
  Author                   = {Korda, N. and Kaufmann, E. and Munos, R.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.22}
}

@InProceedings{Krause:11Context,
  Title                    = {{Contextual Gaussian Process Bandit Optimization}},
  Author                   = {Krause, A. and Ong, C.S.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2011},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.07}
}

@inproceedings{Anandkumar10,
    title =        {{Opportunistic Spectrum Access with multiple users: Learning under competition}},
    author =       {A. Anandkumar and N. Michael and A. K. Tang},
    booktitle =    {{IEEE INFOCOM}},
    year =         {2010}
}

@inproceedings{Besson18,
    title =        {{Multi-player Bandits Revisited}},
    author =       {Lilian Besson and Emilie Kaufmann},
    booktitle =    {{Algorithmic Learning Theory (ALT)}},
    year =         {2018}
}

@inproceedings{Bonnefoi17,
    title =        {{Multi-Armed Bandit Learning in IoT Networks: Learning helps even in non-stationary settings}},
    author =       {R. Bonnefoi and L. Besson and C. Moy and E. Kaufmann and J. Palicot},
    booktitle =    {{12th EAI Conference on Cognitive Radio Oriented Wireless Network and Communication}},
    series =       {CROWNCOM Proceedings},
    year =         {2017}
}

@inproceedings{Rosenski16,
    title =        {{Multi-Player Bandits -- A Musical Chairs Approach}},
    author =       {J. Rosenski and O. Shamir and L. Szlak},
    booktitle =    {{International Conference on Machine Learning}},
    pages =        {155--163},
    year =         {2016}
}

@Article{Lai:SeqTest88,
  Title                    = {{Nearly Optimal Sequential Tests for Composite Hypotheses}},
  Author                   = {Lai, T.L.},
  Journal                  = {Annals of Statistics},
  Year                     = {1988},
  Pages                    = {856--886},
  Volume                   = {16(2)},

  Owner                    = {kaufmann},
  Timestamp                = {2012.12.12}
}

@Article{Lai88,
  Title                    = {{Boundary Crossing problems for samples means}},
  Author                   = {Lai, T.L.},
  Journal                  = {Annals of Probability},
  Year                     = {1988},
  Pages                    = {375--396},
  Volume                   = {16(1)},

  Abstract                 = {present a general concentration inequality in terms of KL-divergence that is useful in a asymoptotic analysis for 'KL-UCB' provided in Lai87 and also for sequential hypothese testing},
  Owner                    = {kaufmann},
  Timestamp                = {2012.07.19}
}

@Article{Lai87,
  Title                    = {{Adaptive treatment allocation and the multi-armed bandit problem}},
  Author                   = {Lai, T.L.},
  Journal                  = {Annals of Statistics},
  Year                     = {1987},
  Pages                    = {1091--1114},
  Volume                   = {15(3)},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@Article{LaiRobbins85bandits,
  Title                    = {{Asymptotically efficient adaptive allocation rules}},
  Author                   = {Lai, T.L. and Robbins, H.},
  Journal                  = {Advances in Applied Mathematics},
  Year                     = {1985},
  Number                   = {1},
  Pages                    = {4--22},
  Volume                   = {6},

  Date-modified            = {2010-02-02 03:14:31 -0700},
  Publisher                = {Elsevier}
}

@Article{RobbinsSiegmund74,
  Title                    = {The expected sample size of some tests of power one},
  Author                   = {Robbins, H. and Siegmund, D.},
  Journal                  = {The Annals of Statistics},
  Year                     = {1974},
  Pages                    = {415--436},
  Volume                   = {2(3)},
}

@Article{Tor15Gittins,
  Title                    = {Regret Analysis of the Finite-Horizon Gittins Index Strategy for Multi-Armed Bandits},
  Author                   = {Lattimore, T.},
  Journal                  = {arXiv:1511.06014},
  Year                     = {2015},

  Owner                    = {emilie},
  Timestamp                = {2015.11.27}
}

@InProceedings{Tor17EndOptimism,
  Title                    = {The End of Optimism? An Asymptotic Analysis of Finite-Armed Linear Bandits},
  Author                   = {Lattimore, T. and Szepesv\'{a}ri, C.},
  Booktitle                = {AISTATS},
  Year                     = {2017},

  Owner                    = {emilie},
  Timestamp                = {2017.11.22}
}


@InProceedings{GKL16,
  Title                    = {On Explore-Then-Commit Strategies},
  Author                   = {Garivier, A. and Kaufmann, E. and Lattimore, T.},
  Booktitle                = {Advances in Neural Information Processing Systems (NeurIPS)},
  Year                     = {2016}
}

@InProceedings{GUK16,
  Title                    = {Corrupt Bandits},
  Author                   = {Gajane, P. and Urvoy, T. and Kaufmann, E.},
  Booktitle                = {European Workshop on Reinforcement Learning (EWRL)},
  Year                     = {2016}
}


@InProceedings{SKV18,
  Title                    = {Adaptive Black-Box Optimization Got Easier : HCT Only Needs Local Smoothness},
  Author                   = {Shang, X. and Kaufmann, E. and Valko, M. },
  Booktitle                = {European Workshop on Reinforcement Learning (EWRL)},
  Year                     = {2018}
}

@inproceedings{Bistritz18GOT,
  title = {Distributed Multi-Player Bandits - a Game of Thrones Approach},
  author = {Bistritz, Ilai and Leshem, Amir},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year = {2018},
}

@article{Bistritz19GOT,
  author    = {Ilai Bistritz and Amir Leshem},
  title     = {Game of Thrones: Fully Distributed Learning for
  Multi-Player Bandits},
  journal   = {arXiv.org:1810.11162v3},
  year = {2019}
}

@article{Tibrewal19,
  author    = {Harshvardhan Tibrewal and Sravan Patchala and Manjesh K.\ Hanawal and Sumit J.\ Darak},
  title     = {Multiplayer Multi-armed Bandits for Optimal Assignment in Heterogeneous Networks},
  journal   = {arXiv.org:1901.03868v4},
  year = {2019},
  notes = "Extended abstract appeared in proceedings of INFOCOM 2019"
}

@article{Warner1965,
  author = {Warner, Stanley L.},
  journal = {Journal of the American Statistical Association},
    number = {309},
    pages = {63+},
    title = {{Randomized Response: A Survey Technique for Eliminating Evasive Answer Bias}},
    volume = {60},
    year = {1965}
}

@InProceedings{GUK18,
  Title                    = {Corrupt Bandits for Preserving Local Privacy},
  Author                   = {Gajane, P. and Urvoy, T. and Kaufmann, E.},
  Booktitle                = {International Conference on Algorithmic Learning Theory (ALT)},
  Year                     = {2018}
}

@InProceedings{Aziz18,
  Title                    = {Pure Exploration in Infinite Bandit Models with Fixed Confidence},
  Author                   = {Aziz, M. and Anderton, J. and Kaufmann, E. and Aslam, J.},
  Booktitle                = {International Conference on Algorithmic Learning Theory (ALT)},
  Year                     = {2018}
}


@InProceedings{BK18,
  Title                    = {Multi-Player Bandits Revisited},
  Author                   = {Besson, L. and Kaufmann, E.},
  Booktitle                = {International Conference on Algorithmic Learning Theory (ALT)},
  Year                     = {2018}
}

@inproceedings{Bonnefoi17,
    title =        {{Multi-Armed Bandit Learning in IoT Networks: Learning helps even in non-stationary settings}},
    author =       {R. Bonnefoi and L. Besson and C. Moy and E. Kaufmann and J. Palicot},
    booktitle =    {{12th EAI Conference on Cognitive Radio Oriented Wireless Network and Communication}},
    series =       {CROWNCOM Proceedings},
    year =         {2017}
}

@inproceedings{BoursierPerchet18,
  author    = {Etienne Boursier and
               Vianney Perchet},
  title     = {{SIC-MMAB:} Synchronisation Involves Communication in Multiplayer
               Multi-Armed Bandits},
  booktitle   = {Advances in Neural Information Processing Systems (NeuRIPS)},
  year = {2019}
}

@article{Abbas18RewardOnly,
  author    = {G{\'{a}}bor Lugosi and
               Abbas Mehrabian},
  title     = {Multiplayer bandits without observing collision information},
  journal   = {arXiv:1808.08416},
  year      = {2018}
}

@inproceedings{BKMP20,
  author    = {Etienne Boursier and Emilie Kaufmann and
               Abbas Mehrabian and Vianney Perchet},
  title     = {A Practical Algorithm for Multiplayer Bandits when Arm Means Vary Among Players},
  booktitle = {The 23rd International Conference on Artificial Intelligence and Statistics,
               (AISTATS)},
  year      = {2020}
}

@article {hungarian,
    AUTHOR = {Munkres, James},
     TITLE = {Algorithms for the assignment and transportation problems},
   JOURNAL = {J. Soc. Indust. Appl. Math.},
    VOLUME = {5},
      YEAR = {1957},
     PAGES = {32--38},
   MRCLASS = {90.0X},
  MRNUMBER = {0093429},
MRREVIEWER = {P. Wolfe},
}


@article{massart1990,
  author = {Massart, P.},
  journal = {Annals of Probability},
  title = {The Tight Constant in the Dvoretzky-Kiefer-Wolfowitz Inequality},
  volume = {18},
  year = {1990}
}

@Article{LaurentMassart00,
  Title                    = {{Adaptive estimation of a quadratic functional by model selection}},
  Author                   = {Laurent, B. and Massart, P},
  Journal                  = {Annals of Statistics},
  Year                     = {2000},
  Pages                    = {1302--1338},
  Volume                   = {28(5)},

  Abstract                 = {gives an upper bound on the quantile of a chi square distribution},
  Owner                    = {kaufmann},
  Timestamp                = {2013.11.28}
}

@InProceedings{Lelarge13Spectrum,
  Title                    = {{Spectrum Bandit Optimization}},
  Author                   = {Lelarge, M. and Prouti{\`e}re, A. and Talebi, S.},
  Booktitle                = {{ITW}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.07.16}
}

@Article{LevinLeu:08AR,
  Title                    = {{On a Conjecture of Bechhofer, Kiefer, and Sobel for the Levin-Robbins-Leu Binomial Subset Selection Procedures}},
  Author                   = {Levin, B. and Leu, C.},
  Journal                  = {Sequential Analysis},
  Year                     = {2008},
  Pages                    = {106--125},
  Volume                   = {27},

  Owner                    = {Emilie},
  Timestamp                = {2013.06.20}
}


@Article{Robbins70LIL,
  Title                    = {{Statistical Methods Related to the law of the iterated logarithm}},
  Author                   = {Robbins, H.},
  Journal                  = {Annals of Mathematical Statistics},
  Year                     = {1970},
  Pages                    = {1397--1409},
  Volume                   = {41(5)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.01.21}
}

@InProceedings{LiChapelle:OpenPb,
  Title                    = {{Open Problem: Regret Bounds for Thompson Sampling}},
  Author                   = {Li, L. and Chapelle, O.},
  Booktitle                = {{Proceedings of the 25th Conference On Learning Theory}},
  Year                     = {2012},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.25}
}

@Article{Jamieson16JHyperOpt,
  Title                    = {Efficient Hyperparameter Optimization and Infinitely Many Armed Bandits},
  Author                   = {Li, L. and Jamieson, K. and DeSalvo G. and Rostamizadeh, A. and Talwalkar, A.},
  Journal                  = {arXiv:1603.06560v1},
  Year                     = {2016},

  Owner                    = {emilie},
  Timestamp                = {2016.10.17}
}

@Article{LiuLi15,
  Title                    = {On the prior sensitivity of Thompson Sampling},
  Author                   = {Liu, C.-Y. and Li, L.},
  Journal                  = {arXiv:1506.03378},
  Year                     = {2015},

  Owner                    = {emilie},
  Timestamp                = {2015.11.04}
}

@article{KK18Mixtures,
  title={Mixture martingales revisited with applications to sequential tests and confidence intervals},
  author={Kaufmann, Emilie and Koolen, Wouter M},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={246},
  pages={1--44},
  year={2021}
}

@InProceedings{LocatelliGC16,
  Title                    = {An optimal algorithm for the Thresholding Bandit Problem},
  Author                   = {Andrea Locatelli and
 Maurilio Gutzeit and
 Alexandra Carpentier},
  Booktitle                = {International Conference on Machine Learning (ICML)},
  Year                     = {2016}
}

@inproceedings{Carpentier16LBFB,
  author    = {Alexandra Carpentier and
               Andrea Locatelli},
  title     = {Tight (Lower) Bounds for the Fixed Budget Best Arm Identification
               Bandit Problem},
  booktitle = {Proceedings of the 29th Conference on Learning Theory (COLT)},
  year      = {2016}
}

@inproceedings{Sutton99PG,
  author    = {Richard S. Sutton and
               David A. McAllester and
               Satinder P. Singh and
               Yishay Mansour},
  title     = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {1999},
}

@inproceedings{Juneja19,
  author    = {Sandeep Juneja and
               Subhashini Krishnasamy},
  title     = {Sample complexity of partition identification using multi-armed bandits},
  booktitle = {Conference on Learning Theory {(COLT)}},
  year      = {2019}
}

@InProceedings{Combes14Lip,
  Title                    = {{Lipschitz Bandits: Regret lower bounds and optimal algorithms}},
  Author                   = {Magureanu, S. and Combes, R. and Prouti{\`e}re, A.},
  Booktitle                = {{Proceedings on the 27th Conference On Learning Theory}},
  Year                     = {2014}
}

@inproceedings{A2C,
  author    = {Volodymyr Mnih and
               Adri{\`{a}} Puigdom{\`{e}}nech Badia and
               Mehdi Mirza and
               Alex Graves and
               Timothy P. Lillicrap and
               Tim Harley and
               David Silver and
               Koray Kavukcuoglu},
  title     = {Asynchronous Methods for Deep Reinforcement Learning},
  booktitle = {Proceedings of the 33nd International Conference on Machine Learning,
               {(ICML)}},
  year = {2016}
}



@InProceedings{KKG18Murphy,
  Title                    = {Sequential Test for the Lowest Mean: From {T}hompson to {M}urphy {S}ampling},
  Author                   = {Kaufmann, E. and Koolen, W.M. and Garivier, A.},
  Booktitle                = {Advances in Neural Information Processing Systems (NeurIPS)},
  Year                     = {2018}
}

@inproceedings{Degenne19Multiple,
  author    = {R{\'{e}}my Degenne and
               Wouter M. Koolen},
  title     = {Pure Exploration with Multiple Correct Answers},
 Booktitle                = {Advances in Neural Information Processing Systems (NeurIPS)},
  Year                     = {2019}
}

@inproceedings{Degenne19GameBAI,
  author    = {R{\'{e}}my Degenne and
               Wouter M. Koolen and
               Pierre M{\'{e}}nard},
  title     = {Non-Asymptotic Pure Exploration by Solving Games},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS) },
  year      = {2019}
}


@article{Ararat21,
  author    = {Cagin Ararat and Cem Tekin},
  title     = {Vector Optimization with Stochastic Bandit Feedback},
  year      = {2021},
  journal = {arXiv 2110.12311}
}

@inproceedings{Auer16Pareto,
  author    = {Peter Auer and
               Chao{-}Kai Chiang and
               Ronald Ortner and
               Madalina M. Drugan},
  title     = {Pareto Front Identification from Stochastic Bandit Feedback},
  booktitle = {Proceedings of the 19th International Conference on Artificial Intelligence
               and Statistics (AISTATS)},
  year      = {2016}
}


@article{Menard19Gradient,
  author    = {Pierre M{\'{e}}nard},
  title     = {Gradient Ascent for Active Exploration in Bandit Problems},
  year      = {2019},
  journal = {arXiv 1905.08165}
}

@article{Richert14,
  author    = {Laura Richert and Adélaïde Doussau and Jean-Daniel Lelièvre and Vincent Arnold and Véronique Rieux and Amel Bouakane and Yves Lévy and Geneviève Chêne and Rodolphe Thiébaut},
  title     = {Accelerating clinical development of HIV vaccine strategies: methodological challenges and considerations in constructing an optimised multi-arm phase I/II trial design},
  year      = {2014},
  journal = {Trials},
  volume = {15(68)}
}

@InProceedings{Maillard:al11KLUCB,
  Title                    = {{A Finite-Time Analysis of Multi-armed Bandits Problems with {K}ullback-{L}eibler Divergences}},
  Author                   = {Maillard, O-A. and Munos, R. and Stoltz, G.},
  Booktitle                = {{Proceedings of the 24th Conference On Learning Theory}},
  Year                     = {2011}
}

@inproceedings{Maillard2018GLR,
    title =       {{Sequential change-point detection: Laplace concentration of scan statistics and non-asymptotic delay bounds}},
    author =      {O.-A. Maillard},
    year =        {2019},
    booktitle =   {Algorithmic Learning Theory (ALT)}
}

@Article{Mairal10OnlineNMF,
  Title                    = {{Online Learning for Matrix Factorization and Sparse Coding}},
  Author                   = {Mairal, J. and Bach, F. and Ponce, J. and Sapiro, G.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2010},
  Pages                    = {19--60},
  Volume                   = {11},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.24}
}

@Article{MannorTsi04,
  Title                    = {{The Sample Complexity of Exploration in the Multi-Armed Bandit Problem}},
  Author                   = {Mannor, S. and Tsitsiklis, J.},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2004},
  Pages                    = {623--648},

  Abstract                 = {Setting: Fixed Confidence with epsilon>0, find the best arm (non asymptotic) lower bounds for Bernoulli rewrads: - a worst case LB scaling in epsilon - a LB scaling in epsilon and gaps but for parameter smaller than 1/2 (that involves some abstract parameter p -> not a sum over all arms) Thm 5 - a more complicated LB for 'general' parameter Thm 8 - a 'worse-case' Bayesian bound (there exists a prior) - a worst-case Lai and Robbins version (based on a Bayesian LB) in the regret setting - some stuff when the distributions are known},
  Owner                    = {kaufmann},
  Timestamp                = {2013.03.25}
}

@Article{MaronMoore:97,
  Title                    = {{The Racing algorithm: Model selection for Lazy learners}},
  Author                   = {Maron, O. and Moore, A.},
  Journal                  = {Artificial Intelligence Review},
  Year                     = {1997},
  Pages                    = {113--131},
  Volume                   = {11(1-5)},

  Owner                    = {kaufmann},
  Timestamp                = {2013.01.30}
}

@Book{massart2007,
  Title                    = {{Concentration inequalities and model selection}},
  Author                   = {Massart, P.},
  Publisher                = {Springer},
  Year                     = {2007},

  Address                  = {Berlin},
  Note                     = {Lectures from the 33rd Summer School on Probability Theory held in Saint-Flour, July 6--23, 2003},
  Series                   = {{Lecture Notes in Mathematics}},
  Volume                   = {1896},

  Pages                    = {xiv+337}
}

@Article{May:al12OBS,
  Title                    = {{Optimistic {B}ayesian sampling in contextual bandit problems}},
  Author                   = {May, B. and Korda, N. and A., Lee and D., Leslie},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2012},
  Pages                    = {2069--2106},
  Volume                   = {13},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.22}
}

@article{Slivkins19Survey,
  author    = {Aleksandrs Slivkins},
  title     = {Introduction to Multi-Armed Bandits},
  journal   = {Foundations and Trends in Machine Learning},
  volume    = {12},
  number    = {1-2},
  pages     = {1--286},
  year      = {2019}
}

@InProceedings{MellorShapiro13TSwitch,
  Title                    = {{Thompson Sampling in Switching Environments with Bayesian Online Change Point Detection}},
  Author                   = {Mellor, J. and Shapiro, J.},
  Booktitle                = {{Proceeding of the 16th Conference on Artificial Intelligence and Statistics}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.17}
}

@inproceedings{Shao20Structure,
  author    = {R{\'{e}}my Degenne and
               Han Shao and
               Wouter M. Koolen},
  title     = {Structure Adaptive Algorithms for Stochastic Bandits},
  booktitle   = {International Conference on Machine Learning (ICML)},
  year      = {2020}
}

@article{AdaHedge,
  author    = {Steven de Rooij and
               Tim van Erven and
               Peter D. Gr{\"{u}}nwald and
               Wouter M. Koolen},
  title     = {Follow the leader if you can, hedge if you must},
  journal   = {Journal of Machine Learning Research},
  volume    = {15},
  number    = {1},
  pages     = {1281--1316},
  year      = {2014}
}

@inproceedings{Berthet17FW,
  author    = {Quentin Berthet and
               Vianney Perchet},
  title     = {Fast Rates for Bandit Optimization with Upper-Confidence Frank-Wolfe},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2017},
}

@InProceedings{Mnih:Bernstein08,
  Title                    = {{Empirical {B}ernstein stopping}},
  Author                   = {Mnih, V. and Szepesv{\'a}ri, C. and Audibert, J-Y.},
  Booktitle                = {{International Conference on Machine Learning (ICML)}},
  Year                     = {2008},

  Owner                    = {kaufmann},
  Timestamp                = {2012.11.08}
}

@InProceedings{MockusEI77,
  Title                    = {{On Bayesian methods for seeking the extremum and their application}},
  Author                   = {Mockus, Jonas},
  Booktitle                = {{Inf. Process. 77, Proc. IFIP Congr., Toronto 1977}},
  Year                     = {1977},

  Owner                    = {kaufmann},
  Timestamp                = {2013.01.28}
}

@inproceedings{Jonsson20MDPGapE,
  author    = {Anders Jonsson and
               Emilie Kaufmann and
               Pierre M{\'{e}}nard and
               Omar Darwiche Domingues and
               Edouard Leurent and
               Michal Valko},
  title     = {Planning in Markov Decision Processes with Gap-Dependent Sample Complexity},
  booktitle  = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2020}
}

@Book{SurveyRemiMCTS,
  Title                    = {From bandits to Monte-Carlo Tree Search: The optimistic principle applied to optimization and planning.},
  Author                   = {Munos, R.},
  Publisher                = {Foundations and Trends in Machine Learning},
  Year                     = {2014},
  Number                   = {1},
  Volume                   = {7},

  Owner                    = {emilie},
  Timestamp                = {2016.01.28}
}

@article{Feldman14BRUE,
  author    = {Zohar Feldman and
               Carmel Domshlak},
  title     = {Simple Regret Optimization in Online Planning for Markov Decision
               Processes},
  journal   = {Journal of Artifial Intelligence Research},
  volume    = {51},
  pages     = {165--205},
  year      = {2014}
}


@Article{Javidi13,
  Title                    = {{Active sequential hypothesis testing}},
  Author                   = {Naghshvar, M. and Javidi, T.},
  Journal                  = {Annals of Statistics},
  Year                     = {2013},
  Pages                    = {2703--2738},
  Volume                   = {41(6)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.07.16}
}

@Book{Neveu72,
  Title                    = {{Martingales {\`a} temps discret}},
  Author                   = {Neveu, Jacques},
  Publisher                = {Masson},
  Year                     = {1972},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.19}
}

@Article{NinoMora11Finite,
  Title                    = {{Computing a Classic Index for Finite-Horizon Bandits}},
  Author                   = {Nino-Mora, J.},
  Journal                  = {INFORMS Journal of Computing},
  Year                     = {2011},
  Pages                    = {254--267},
  Volume                   = {23(2)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.26}
}

@Article{Nino-Mora07,
  Title                    = {A (2/3)n3 Fast-Pivoting Algorithm for the Gittins Index and Optimal Stopping of a Markov Chain.},
  Author                   = {Niño-Mora, José},
  Journal                  = {INFORMS Journal on Computing},
  Year                     = {2007},
  Number                   = {4},
  Pages                    = {596-606},
  Volume                   = {19}
}

@Article{OQuigleyPF90CRM,
  Title                    = {Continual reassessment method: A practical design for Phase I clinical trials in cancer},
  Author                   = {O'Quigley, J. and Pepe, M. and Fisher, L.},
  Journal                  = {Biometrics},
  Year                     = {1990},
  Number                   = {46},
  Pages                    = {33-48},

  Owner                    = {emilie},
  Timestamp                = {2016.11.02}
}

@inproceedings{Jedor19Categorized,
  author    = {Matthieu Jedor and
               Vianney Perchet and
               Jonathan Lou{\"{e}}dec},
  title     = {Categorized Bandits},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2019}
}

@inproceedings{Pepels14SimpleMCTS,
  author    = {Tom Pepels and
               Tristan Cazenave and
               Mark H. M. Winands and
               Marc Lanctot},
  title     = {Minimizing Simple and Cumulative Regret in Monte-Carlo Tree Search},
  booktitle = {Third Workshop on Computer Games (CGW)},
  pages     = {1--15},
  year      = {2014}
}

@Article{OQuingley90CRM,
  Title                    = {Continual Reassessment Method: A Practical Design for Phase {I} Clinical Trials in Cancer},
  Author                   = {O'Quingley, J. and Pepe, M. and Fisher, L.},
  Journal                  = {Biometrics},
  Year                     = {1990},
  Number                   = {1},
  Pages                    = {33-48},
  Volume                   = {46},

  Owner                    = {emilie},
  Timestamp                = {2015.12.26}
}

@InProceedings{RussoVanRoy13RL,
  Title                    = {{(More) Efficient Reinforcement Learning Via Posterior Sampling}},
  Author                   = {Osband, I. and {Van Roy}, B. and Russo, D.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.06.18}
}



@article{Russo18TutoTS,
  author    = {Daniel Russo and
               Benjamin Van Roy and
               Abbas Kazerouni and
               Ian Osband and
               Zheng Wen},
  title     = {A Tutorial on Thompson Sampling},
  journal   = {Foundations and Trends in Machine Learning},
  volume    = {11},
  number    = {1},
  pages     = {1--96},
  year      = {2018}
}



@InProceedings{Shang19DTTTS,
  Title                    = {A simple dynamic bandit algorithm for hyper-parameter tuning},
  Author                   = {Shang, X. and Kaufmann, E. and Valko, M.},
  Booktitle                = {6th ICML Workshop on Automated Machine Learning (ICML 2019 - AutoML)},
  Year                     = {2019}
}

@inproceedings{Shang20TTTS,
  author    = {Xuedong Shang and
               Rianne de Heide and
               Emilie Kaufmann and
               Pierre M{\'{e}}nard and
               Michal Valko},
  title     = {Fixed-Confidence Guarantees for Bayesian Best-Arm Identification},
  booktitle   = {International Conference on Artificial Intelligence and Statistics (AISTATS)},
  year      = {2020}
}

@inproceedings{Shang20TTTS,
  author    = {Xuedong Shang and
               Rianne de Heide and
               Emilie Kaufmann and
               Pierre M{\'{e}}nard and
               Michal Valko},
  title     = {Fixed-Confidence Guarantees for Bayesian Best-Arm Identification},
  booktitle   = {International Conference on Artificial Intelligence and Statistics (AISTATS)},
  year      = {2020}
}

@inproceedings{Jamieson14Survey,
  author    = {Kevin G. Jamieson and
               Robert D. Nowak},
  title     = {Best-arm identification algorithms for multi-armed bandits in the
               fixed confidence setting},
  booktitle = {Conference on Information Sciences and Systems (CISS)},
  year      = {2014}
}

@inproceedings{Agrawal20GeneBAI,
  author    = {Shubhada Agrawal and
               Sandeep Juneja and
               Peter W. Glynn},
  title     = {Optimal {$\delta$}-Correct Best-Arm Selection
               for Heavy-Tailed Distributions},
  booktitle = {Algorithmic Learning Theory (ALT)},
  year      = {2020}
}

@inproceedings{Agrawal21Regret,
  title={Regret minimization in heavy-tailed bandits},
  author={Agrawal, Shubhada and Juneja, Sandeep K and Koolen, Wouter M},
  booktitle={Conference on Learning Theory},
  year={2021}
}

@article{Aziz19DoseFinding,
  author    = {Maryam Aziz and
               Emilie Kaufmann and
               Marie{-}Karelle Riviere},
  title     = {On Multi-Armed Bandit Designs for Dose-Finding Clinical Trials},
  journal = {Journal of Machine Learning Research},
  volume = {22(14)},
  pages = {1-38},
  year = {2021}
}

@Article{Paulson:94,
  Title                    = {{Sequential procedures for selecting the best one of k {K}oopman-{D}armois populations}},
  Author                   = {Paulson, E.},
  Journal                  = {Sequential Analysis: Design Methods and Applications},
  Year                     = {1994},
  Pages                    = {207--220},
  Volume                   = {13},

  Abstract                 = {to pay, not found},
  Owner                    = {Emilie},
  Timestamp                = {2013.06.20}
}

@Article{Paulson:64,
  Title                    = {{A sequential procedure for selecting the population with the largest mean from k normal populations}},
  Author                   = {Paulson, E.},
  Journal                  = {Annals of Mathematical Statistics},
  Year                     = {1964},
  Pages                    = {174--180},
  Volume                   = {35},

  Owner                    = {Emilie},
  Timestamp                = {2013.06.20}
}

@InProceedings{Pavlidis:al08IE,
  Title                    = {{Simulation studies of multi-armed bandits with covariates}},
  Author                   = {Pavlidis, N.G and Tasoulis, D.K. and Hand, D.J.},
  Booktitle                = {{10th Proceedings of the International Conference on Computer Modeling}},
  Year                     = {2008},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.04.16}
}

@Article{PenaSelf04,
  Title                    = {{Self-normalized Processes : Exponential inequalities, moment bounds and iterated logarithm laws}},
  Author                   = {de la Pena, V.H. and Klass, M.J. and Lai, T.L.},
  Journal                  = {Annals of Probability},
  Year                     = {2004},
  Pages                    = {1902--1933},
  Volume                   = {32(3A)},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@Conference{Preux14Opt,
  Title                    = {{Bandits attack function optimization}},
  Author                   = {Preux, P. and Munos, R. and Valko, M.},
  Booktitle                = {{IEEE Congress on Evolutionary Computation}},
  Year                     = {2014},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.24}
}

@Book{Puterman94MDP,
  Title                    = {{Markov Decision Processes. Discrete Stochastic. Dynamic Programming.}},
  Author                   = {Puterman, M.L.},
  Publisher                = {Wiley},
  Year                     = {1994},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.24}
}

@Article{Wilks38,
  Title                    = {{The Large-Sample Distribution of the Likelihood Ratio for Testing Composite Hypotheses}},
  Author                   = {Wilks, S.S.},
  Journal                  = {The Annals of Mathematical Statistics},
  Year                     = {1938},
  Pages                    = {60--62},
  Volume                   = {9(1)}
}

@article{Kearns02SS,
  author    = {Michael J. Kearns and
               Yishay Mansour and
               Andrew Y. Ng},
  title     = {A Sparse Sampling Algorithm for Near-Optimal Planning in Large Markov
               Decision Processes},
  journal   = {Machine Learning},
  volume    = {49},
  number    = {2-3},
  pages     = {193--208},
  year      = {2002}
}

@PhdThesis{TheseMKR14,
  Title                    = {Designs adaptatifs de recherche de dose en encologie dans le cadre de combinaisons de molécules et de molécules ciblées},
  Author                   = {Riviere, M-K.},
  School                   = {Université Paris-Diderot},
  Year                     = {2014},

  Owner                    = {emilie},
  Timestamp                = {2015.12.26}
}

@inproceedings{LiCLS10,
  author    = {Lihong Li and
               Wei Chu and
               John Langford and
               Robert E. Schapire},
  title     = {A contextual-bandit approach to personalized news article recommendation},
  booktitle = {WWW},
  year      = {2010}
}

@Article{MKR16,
  Title                    = {Phase I/II Dose-Finding Design for Molecularly Targeted Agent: Plateau Determination using Adaptive Randomization},
  Author                   = {Rivière, M-K. and Jourdan, J-H. and Dubois F. and Zohar S.},
  Journal                  = {Statistical Methods in Medical Research},
  Year                     = {2016},

  Owner                    = {emilie},
  Timestamp                = {2016.11.03}
}

@Article{Robbins70LIL,
  Title                    = {{Statistical Methods Related to the law of the iterated logarithm}},
  Author                   = {Robbins, H.},
  Journal                  = {Annals of Mathematical Statistics},
  Year                     = {1970},
  Pages                    = {1397--1409},
  Volume                   = {41(5)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.01.21}
}

@Article{Robbins52Freq,
  Title                    = {{Some aspects of the sequential design of experiments}},
  Author                   = {Robbins, H.},
  Journal                  = {Bulletin of the American Mathematical Society},
  Year                     = {1952},
  Pages                    = {527--535},
  Volume                   = {58(5)},

  Abstract                 = {First statement of the frequentist MAB Hannan consistent policies Looks for minmax rules epsilon greedy mentionned},
  Owner                    = {kaufmann},
  Timestamp                = {2012.07.06}
}

@Article{RusTsi10,
  Title                    = {{Linearly Parameterized Bandits}},
  Author                   = {Rusmevichientong, P. and Tsitsiklis, J.},
  Journal                  = {Mathematics of Operations Research},
  Year                     = {2010},
  Pages                    = {395--411},
  Volume                   = {35(2)},

  Abstract                 = {stochastic linear bandit (regret and bayesian risk) -> no dual case (a priori) Lower bound on the regret for actions on the unit sphere (for regret and bayes risk) in the stochastic setting of O(d\sqrt(n)) PEGE algorithm (separate exploration and exploitation) matches the lower bound but is efficient only on (at least) compact and strongly convex sets of actions UE algorithm (action set included in some L2 bowl, subgaussian assumption on the noise) - regret bound (O(d\sqrt(n)\log^3(n))) in expactation but based on hp results - regret bound in the finite case where Delta is defined scaling in the gaps},
  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@Article{RussoVanRoy13,
  Title                    = {{Learning to optimize via posterior sampling}},
  Author                   = {Russo, D. and {Van Roy}, B.},
  Journal                  = {Mathematics of Operations Research },
  Year                     = {2014},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.25}
}


@Article{Bastani18Greedy,
  Title                    = {Mostly Exploration-Free Algorithms for Contextual Bandits},
  Author                   = {Bastani, H. and Bayati,M. and  Khosravi, K.},
  Journal                  = {arXiv:1704.09011},
  Year                     = {2018}
}


@article{Moerland18Explo,
  author    = {Moerland, T.M. and Broekens, J. and Jonker, C.M.},
  title     = {The Potential of the Return Distribution for Exploration in {RL}},
  journal   = {arXiv:1806.04242},
  year      = {2018}
}

@Article{Kannan18Greedy,
  Title                    = {A Smoothed Analysis of the Greedy Algorithm for the Linear Contextual Bandit Problem},
  Author                   = {Kannan, S. and Morgenstern, J. and Roth, A. and  Waggoner, B. and Wu, Z.S.},
  Journal                  = {arXiv:1801.03423},
  Year                     = {2018}
}

@InProceedings{RussoVanRoy14IDS,
  Title                    = {Learning to optimize via information direct sampling},
  Author                   = {Russo, D. and Van Roy, B.},
  Booktitle                = {Advances in Neural Information Processing Systems (NeurIPS)},
  Year                     = {2014},

  Owner                    = {emilie},
  Timestamp                = {2015.11.04}
}

@inproceedings{Russo2016TTTS,
author = {Russo, Daniel},
booktitle = {Proceedings of the 29th Conference on Learning Theory (COLT)},
title = {{Simple Bayesian algorithms for best arm identification}},
year = {2016}
}

@inproceedings{Qin2017TTEI,
author = {Qin, Chao and Klabjan, Diego and Russo, Daniel},
booktitle = {Advances in Neural Information Processing Systems 30 (NIPS)},
title = {{Improving the expected improvement algorithm}},
year = {2017}
}


@InProceedings{SalomonAudibert:11Dev,
  Title                    = {{Deviations of stochastic bandit regret}},
  Author                   = {Salomon, A. and Audibert, J-Y.},
  Booktitle                = {{Proceedings of the 22nd conference on Algorithmic Learning Theory}},
  Year                     = {2011},

  Abstract                 = {PB : do Rn>Clog(n) have small probability answer : not so small for UCB, better when the horizon is known (negative result for anytime policy) UCB-H is better then UCB in terms of hp result (possible) PAC-UCB : fix our exploration rate building a sequence corresponding to our level of confidence},
  Owner                    = {kaufmann},
  Timestamp                = {2012.06.15}
}

@InProceedings{Sani:al12,
  Title                    = {{Risk-aversion in multi-armed bandits}},
  Author                   = {Sani, A. and Lazaric, A. and Munos, R.},
  Booktitle                = {{NeurIPS}},
  Year                     = {2012},

  Owner                    = {kaufmann},
  Timestamp                = {2013.07.18}
}

@Article{AmandineSTMALA,
  Title                    = {{A shrinkage-thresholding Metropolis adjusted Langevin algorithm for Bayesian variable selection}},
  Author                   = {Schreck, A. and Fort, G. and {Le Corff}, S. and Moulines, E.},
  Journal                  = {arXiv:1312.5658},
  Year                     = {2013},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.06.23}
}

@Article{Scott10,
  Title                    = {{A modern Bayesian look at the multi-armed bandit}},
  Author                   = {Scott, S.L.},
  Journal                  = {Applied Stochastic Models in Business and Industry},
  Year                     = {2010},
  Pages                    = {639--658},
  Volume                   = {26},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.24}
}

@article{Bubeck15ConvexOptim,
  author    = {S{\'{e}}bastien Bubeck},
  title     = {Convex Optimization: Algorithms and Complexity},
  journal   = {Foundations and Trends in  Machine Learning},
  volume    = {8},
  number    = {3-4},
  pages     = {231--357},
  year      = {2015}
}

@InProceedings{Shamir13Complexity,
  Title                    = {{On the Complexity of Bandit and Derivative-Free Stochastic Convex Optimization}},
  Author                   = {Shamir, O.},
  Booktitle                = {{Conference On Learning Theory}},
  Year                     = {2013},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.20}
}

@Article{ShenOQ98ConsCRM,
  Title                    = {Consistency of continual reassessment method under model misspecification},
  Author                   = {Shen, L. and O'Quigley, J.},
  Journal                  = {Biometrika},
  Year                     = {1996},
  Number                   = {2},
  Pages                    = {395-405},
  Volume                   = {83},

  Owner                    = {emilie},
  Timestamp                = {2016.11.08}
}

@Book{Siegmund:SeqAn,
  Title                    = {{Sequential Analysis}},
  Author                   = {Siegmund, D.},
  Publisher                = {Springer-Verlag},
  Year                     = {1985},

  Owner                    = {kaufmann},
  Timestamp                = {2012.11.30}
}

@Book{PDMIA08,
  Title                    = {{Processus Decisionnels de Markov et Intelligence artificielle}},
  Author                   = {Sigaud, O. and Buffet, O.},
  Publisher                = {Herm{\`e}s},
  Year                     = {2008},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.31}
}

@Article{deep.go,
  Title                    = {Mastering the game of Go with deep neural networks and tree search },
  Author                   = {David Silver and Aja Huang and Chris J. Maddison and Arthur Guez and Laurent Sifre and George van den Driessche and Julian Schrittwieser and Ioannis Antonoglou and Veda Panneershelvam and Marc Lanctot and Sander Dieleman and Dominik Grewe and John Nham and Nal Kalchbrenner and Ilya Sutskever and Timothy Lillicrap and Madeleine Leach and Koray Kavukcuoglu and Thore Graepel and Demis Hassabis},
  Journal                  = {Nature},
  Year                     = {2016},
  Pages                    = {484--489},
  Volume                   = {529}
}

@inproceedings{CrazyStone,
  author    = {R{\'{e}}mi Coulom},
  title     = {Efficient Selectivity and Backup Operators in Monte-Carlo Tree Search},
  booktitle = {Computers and Games, 5th International Conference, {CG} 2006, Turin,
               Italy, May 29-31, 2006. Revised Papers},
  pages     = {72--83},
  year      = {2006},
}

@InProceedings{Snoek14BOpt,
  Title                    = {{Practical Bayesian Optimization of Machine Learning Algorithms}},
  Author                   = {Snoek, J. and Lrochelle, H. and Adams, R.P.},
  Booktitle                = {{Advances on Neural Information Processing Systems}},
  Year                     = {2014},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.20}
}

@InProceedings{Soare14BAILin,
  Title                    = {{Best Arm Identification in Linear Bandit}},
  Author                   = {Soare, M. and Lazaric, A. and Munos, R.},
  Booktitle                = {{Advances in Neural Information Processing Systems}},
  Year                     = {2014},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.12.24}
}

@Article{GPUCB:Journal,
  Title                    = {{Information-Theoretic Regret Bounds for Gaussian Process Optimization in the Bandit Setting}},
  Author                   = {Srinivas, N. and Krause, A. and Kakade, S. and Seeger, M.},
  Journal                  = {IEEE Transactions on Information Theory},
  Year                     = {2012},
  Pages                    = {3250--3265},
  Volume                   = {58(5)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.07}
}

@InProceedings{SrinivasGPUCB,
  Title                    = {{Gaussian Process Optimization in the Bandit Setting : No Regret and Experimental Design}},
  Author                   = {Srinivas, N. and Krause, A. and Kakade, S. and Seeger, M.},
  Booktitle                = {{Proceedings of the International Conference on Machine Learning}},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@InProceedings{Strens00TSRL,
  Title                    = {{A Bayesian Framework for Reinforcement Learning}},
  Author                   = {Strens, Malcom},
  Booktitle                = {{ICML}},
  Year                     = {2000},

  Abstract                 = {Thompson in RL},
  Owner                    = {kaufmann},
  Timestamp                = {2013.01.10}
}

@inproceedings{Ouyang17TS,
  author    = {Yi Ouyang and
               Mukul Gagrani and
               Ashutosh Nayyar and
               Rahul Jain},
  title     = {Learning Unknown Markov Decision Processes: {A} Thompson Sampling
               Approach},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2017}
}

@inproceedings{Tang17CountBased,
  author    = {Haoran Tang and
               Rein Houthooft and
               Davis Foote and
               Adam Stooke and
               Xi Chen and
               Yan Duan and
               John Schulman and
               Filip De Turck and
               Pieter Abbeel},
  title     = {{\#}Exploration: {A} Study of Count-Based Exploration for Deep Reinforcement
               Learning},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2017}
}

@inproceedings{Bellemare16CountBased,
  author    = {Marc G. Bellemare and
               Sriram Srinivasan and
               Georg Ostrovski and
               Tom Schaul and
               David Saxton and
               R{\'{e}}mi Munos},
  title     = {Unifying Count-Based Exploration and Intrinsic Motivation},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2016}
}

@inproceedings{Osband16BootstrapDQN,
  author    = {Ian Osband and
               Charles Blundell and
               Alexander Pritzel and
               Benjamin Van Roy},
  title     = {Deep Exploration via Bootstrapped {DQN}},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2016}
}

@article{Fortunato17NoisyNetworks,
  author    = {Meire Fortunato and
               Mohammad Gheshlaghi Azar and
               Bilal Piot and
               Jacob Menick and
               Ian Osband and
               Alex Graves and
               Vlad Mnih and
               R{\'{e}}mi Munos and
               Demis Hassabis and
               Olivier Pietquin and
               Charles Blundell and
               Shane Legg},
  title     = {Noisy Networks for Exploration},
  journal   = {arXiv:1706.10295},
  year = {2017},
}

@Book{SuttonBarto98,
  Title                    = {Reinforcement Learning: an Introduction},
  Author                   = {Sutton, R. and Barto, A.},
  Publisher                = {MIT press},
  Year                     = {1998},

  Owner                    = {emilie},
  Timestamp                = {2016.11.07}
}


@Book{SuttonBarto2018,
  Title                    = {Reinforcement Learning: an Introduction},
  Author                   = {Sutton, R. and Barto, A.},
  Publisher                = {MIT press},
  Year                     = {2018},

  Owner                    = {emilie},
  Timestamp                = {2019.11.06}
}


@InProceedings{STOP14,
  Title                    = {Optimistic Planning in Markov Decision Processes using a generative model},
  Author                   = {Szorenyi, B. and Kedenburg, G. and Munos, R.},
  Booktitle                = {Advances in Neural Information Processing Systems},
  Year                     = {2014},

  Owner                    = {emilie},
  Timestamp                = {2016.05.26}
}

@Article{Thompson35,
  Title                    = {{On the theory of apportionment}},
  Author                   = {Thompson, W.},
  Journal                  = {American Journal of Mathematics},
  Year                     = {1935},
  Pages                    = {450--456},
  Volume                   = {57},

  Owner                    = {kaufmann},
  Timestamp                = {2014.03.24}
}

@Article{Thompson33,
  Title                    = {{On the likelihood that one unknown probability exceeds another in view of the evidence of two samples}},
  Author                   = {Thompson, W.R.},
  Journal                  = {Biometrika},
  Year                     = {1933},
  Pages                    = {285--294},
  Volume                   = {25},

  Owner                    = {kaufmann},
  Timestamp                = {2012.01.04}
}

@Article{Rajesh15Oddball,
  Title                    = {Learning to detect an oddball target},
  Author                   = {N.K. Vaidhyan and R. Sundaresan},
  Journal                  = {arXiv:1508.05572},
  Year                     = {2015},

  Owner                    = {emilie},
  Timestamp                = {2015.11.17}
}

@InProceedings{valko2013stochastic,
  Title                    = {{Stochastic simultaneous optimistic optimization}},
  Author                   = {Valko, Michal and Carpentier, Alexandra and Munos, R{\'{e}}mi},
  Booktitle                = {International Conference on Machine Learning},
  Year                     = {2013},

  Abstract                 = {We study the problem of global maximization of a function f given a finite number of evaluations perturbed by noise. We consider a very weak assumption on the function, namely that it is locally smooth (in some precise sense) with respect to some semi-metric, around one of its global maxima. Compared to previous works on bandits in general spaces (Kleinberg et al., 2008; Bubeck et al., 2011a) our algorithm does not require the knowledge of this semi-metric. Our algorithm, StoSOO, follows an optimistic strategy to iteratively construct upper confidence bounds over the hierarchical partitions of the function domain to decide which point to sample next. A finite-time analysis of StoSOO shows that it performs almost as well as the best specifically-tuned algorithms even though the local smoothness of the function is not known.},
  Owner                    = {emilie},
  Timestamp                = {2016.05.26}
}

@InProceedings{Valko:al13KernelUCB,
  Title                    = {{Finite-time analysis of kernelized contextual bandits}},
  Author                   = {Valko, M. and Korda, N. and Munos, R. and Cristinini, N.},
  Booktitle                = {{29th Conference on Uncertainty in Artificial Intelligence (UAI)}},
  Year                     = {2013},

  Owner                    = {kaufmann},
  Timestamp                = {2014.05.06}
}

@Book{VdV:Asymptotic98,
  Title                    = {{Asymptotic Statistics}},
  Author                   = {{Van der Vaart}, A.},
  Publisher                = {Cambridge University Press},
  Year                     = {1998},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.24}
}

@Book{Vapnik98,
  Title                    = {{Statistical Learning Theory}},
  Author                   = {V.~Vapnik},
  Publisher                = {Wiley},
  Year                     = {1998},

  Address                  = {New York}
}

@Article{Wald45SPRT,
  Title                    = {{Sequential Tests of Statistical Hypotheses}},
  Author                   = {Wald, A.},
  Journal                  = {Annals of Mathematical Statistics},
  Year                     = {1945},
  Pages                    = {117--186},
  Volume                   = {16(2)},

  Owner                    = {Utilisateur},
  Timestamp                = {2014.01.25}
}

@Book{AllOfStats,
  Title                    = {{All of Statistics: A concise course in statistical inference}},
  Author                   = {Wasserman, L.},
  Publisher                = {Springer},
  Year                     = {2010},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.24}
}

@Article{Weber92,
  Title                    = {{On the {G}ittins index for multiarmed bandits}},
  Author                   = {Weber, R.},
  Journal                  = {Annals of Applied Probabilities},
  Year                     = {1992},
  Pages                    = {1024--1033},
  Volume                   = {2(4)},

  Owner                    = {kaufmann},
  Timestamp                = {2014.04.01}
}

@inproceedings{Seznec19Rotting,
  author    = {Julien Seznec and
               Andrea Locatelli and
               Alexandra Carpentier and
               Alessandro Lazaric and
               Michal Valko},
  title     = {Rotting bandits are no harder than stochastic ones},
  booktitle = {The 22nd International Conference on Artificial Intelligence and Statistics,
               (AISTATS)},
  year      = {2019}
}

@inproceedings{Seznec20RestlessRotting,
  author    = {Julien Seznec and
               Pierre M\'enard and
               Alessandro Lazaric and
               Michal Valko},
  title     = {A single algorithm for both restless and rested rotting bandits},
  booktitle = {The 23rd International Conference on Artificial Intelligence and Statistics,
               (AISTATS)},
  year      = {2020}
}

@article{kiesel2000large,
  title={A large deviation principle for weighted sums of independent identically distributed random variables},
  author={Kiesel, R{\"u}diger and Stadtm{\"u}ller, Ulrich},
  journal={Journal of mathematical analysis and applications},
  volume={251},
  number={2},
  pages={929--939},
  year={2000},
  publisher={Elsevier}
}

@article{kiesel1996erdHos,
  title={Erd{\H{o}}s-R{\'e}nyi-Shepp laws and weighted sums of independent identically distributed random variables},
  author={Kiesel, R{\"u}diger and Stadtm{\"u}ller, Ulrich},
  journal={Journal of Theoretical Probability},
  volume={9},
  number={4},
  pages={961--982},
  year={1996},
  publisher={Springer}
}

<<<<<<< HEAD
@article{richardson1984wgen,
  title={WGEN: A model for generating daily weather variables},
  author={Richardson, Clarence W and Wright, David A},
  journal={ARS (USA)},
  year={1984},
  publisher={US Dept. of Agriculture, Agricultural Research Service}
}

@article{evans2017data,
  title={From data to decisions: helping crop producers build their actionable knowledge},
  author={Evans, Katherine J and Terhorst, Andrew and Kang, Byeong Ho},
  journal={Critical reviews in plant sciences},
  volume={36},
  number={2},
  pages={71--88},
  year={2017},
  publisher={Taylor \& Francis}
}

@article{hoogenboom2019dssat,
  title={The DSSAT crop modeling ecosystem},
  author={Hoogenboom, G and Porter, CH and Boote, KJ and Shelia, V and Wilkens, PW and Singh, U and White, JW and Asseng, S and Lizaso, JI and Moreno, LP and others},
  journal={Advances in crop modelling for a sustainable agriculture},
  pages={173--216},
  year={2019},
  publisher={Burleigh Dodds Science Publishing Cambridge, UK}
}

@article{cerf2006outils,
  title={Les outils de pilotage des cultures: diversit{\'e} de leurs usages et enseignements pour leur conception},
  author={Cerf, Marianne and Meynard, Jean-Marc},
  journal={Natures Sciences Soci{\'e}t{\'e}s},
  volume={14},
  number={1},
  pages={19--29},
  year={2006},
  publisher={EDP Sciences}
}

@article{hochman2011emerging,
  title={Emerging consensus on desirable characteristics of tools to support farmers’ management of climate risk in Australia},
  author={Hochman, Zvi and Carberry, PS},
  journal={Agricultural Systems},
  volume={104},
  number={6},
  pages={441--450},
  year={2011},
  publisher={Elsevier}
}

@article{evans1999yield,
  title={Yield potential: its definition, measurement, and significance},
  author={Evans, LT and Fischer, RA},
  journal={Crop science},
  volume={39},
  number={6},
  pages={1544--1551},
  year={1999},
  publisher={Wiley Online Library}
}

@article{tollenaar2002yield,
  title={Yield potential, yield stability and stress tolerance in maize},
  author={Tollenaar, M and Lee, EA},
  journal={Field crops research},
  volume={75},
  number={2-3},
  pages={161--169},
  year={2002},
  publisher={Elsevier}
}

@article{paris1992return,
  title={The Return of von Liebig's “Law of the Minimum”},
  author={Paris, Q},
  journal={Agronomy Journal},
  volume={84},
  number={6},
  pages={1040--1046},
  year={1992},
  publisher={Wiley Online Library}
}


@article{mccown2002changing,
  title={Changing systems for supporting farmers' decisions: problems, paradigms, and prospects},
  author={McCown, Robert L},
  journal={Agricultural systems},
  volume={74},
  number={1},
  pages={179--220},
  year={2002},
  publisher={Elsevier}
}

@article{shiferaw2011crops,
  title={Crops that feed the world 6. Past successes and future challenges to the role played by maize in global food security},
  author={Shiferaw, Bekele and Prasanna, Boddupalli M and Hellin, Jonathan and B{\"a}nziger, Marianne},
  journal={Food security},
  volume={3},
  number={3},
  pages={307--327},
  year={2011},
  publisher={Springer}
}

@book{brent2013algorithms,
  title={Algorithms for minimization without derivatives},
  author={Brent, Richard P},
  year={2013},
  publisher={Courier Corporation}
}

@article{LaiRobbins85,
  title={Asymptotically efficient adaptive allocation rules},
  author={Lai, Tze Leung and Robbins, Herbert},
  journal={Advances in applied mathematics},
  volume={6},
  number={1},
  pages={4--22},
  year={1985},
  publisher={Academic Press}
}

@article{burnetas96LB,
  title={Optimal adaptive policies for sequential allocation problems},
  author={Burnetas, Apostolos N and Katehakis, Michael N},
  journal={Advances in Applied Mathematics},
  volume={17},
  number={2},
  pages={122--142},
  year={1996},
  publisher={Elsevier}
}


@inproceedings{baudry21a,
  title = {Optimal Thompson Sampling strategies for support-aware CVaR bandits},
  author = {Baudry, Dorian and Gautron, Romain and Kaufmann, Emilie and Maillard, Odalric},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning},
  year = {2021}
}

@article{bubeck_heavy,
  title={Bandits with heavy tail},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo and Lugosi, G{\'a}bor},
  journal={IEEE Transactions on Information Theory},
  volume={59},
  number={11},
  pages={7711--7717},
  year={2013},
  publisher={IEEE}
}



@inproceedings{jourdan_2021_EfficientPureExploration,
 author = {Jourdan, Marc and Mutn{\`y}, Mojm{\'\i}r and Kirschner, Johannes and Krause, Andreas},
 booktitle = {Algorithmic Learning Theory (ALT)},
 title = {Efficient Pure Exploration for Combinatorial Bandits with Semi-Bandit Feedback},
 year = {2021}
}


@inproceedings{jourdan_2022_ChoosingAnswers,
  author = {Jourdan, Marc and Degenne, R{\'e}my},
  title = {Choosing Answers in $\varepsilon$-Best-Answer Identification for Linear Bandits},
  booktitle = {International Conference on Machine Learning (ICML)},
  year = {2022}
}


@article{jourdan_2022_TopTwoAlgorithms,
  author = {Jourdan, Marc and Degenne, R{\'e}my and Baudry, Dorian and De Heide, Rianne and Kaufmann, Emilie},
  title = {Top Two Algorithms Revisited},
  journal = {Advances in Neural Information Processing Systems},
  year = {2022}
}

@article{jourdan_2022_DealingUnknownVariance,
  author = {Jourdan, Marc and Degenne, R{\'e}my and Kaufmann, Emilie},
  title = {Dealing with Unknown Variances in Best-Arm Identification},
  journal = {International Conference on Algorithmic Learning Theory},
  year = {2023}
}

@article{jourdan_2022_NonAsymptoticAnalysis,
  author = {Jourdan, Marc and Degenne, R{\'e}my},
  title = {Non-Asymptotic Analysis of a UCB-based Top Two Algorithm},
  journal = {arXiv preprint arXiv:2210.05431},
  year = {2022}
}


@article{wang_2021_FastPureExploration,
  title={Fast Pure Exploration via Frank-Wolfe},
  author={Wang, Po-An and Tzeng, Ruo-Chun and Proutiere, Alexandre},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}


@article{mukherjee_2022_SPRTBAI,
  author = {Mukherjee, Arpan and Tajer, Ali},
  title={SPRT-based Efficient Best Arm Identification in Stochastic Bandits},
  journal={IEEE Journal on Selected Areas in Information Theory},
  year = {2023}
}

@article{ariu_2021_PolicyChoice,
  title={Policy Choice and Best Arm Identification: Asymptotic Analysis of Exploration Sampling under Posterior Weighted Policy Regret},
  author={Ariu, Kaito and Kato, Masahiro and Komiyama, Junpei and McAlinn, Kenichiro and Qin, Chao},
  journal={arXiv preprint arXiv:2109.08229},
  year={2021}
}

@book{pukelsheim2006optimal,
  title={Optimal design of experiments},
  author={Pukelsheim, Friedrich},
  year={2006},
  publisher={SIAM}
}

@article{chaloner1995bayesian,
  title={Bayesian experimental design: A review},
  author={Chaloner, Kathryn and Verdinelli, Isabella},
  journal={Statistical Science},
  year={1995}
}


@article{mason_2020_FindingAllEpsilon,
  title={Finding all {$\epsilon$}-good arms in stochastic bandits},
  author={Mason, Blake and Jain, Lalit and Tripathy, Ardhendu and Nowak, Robert},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}


@inproceedings{katz_samuels_2020_TrueSampleComplexity,
  title={The true sample complexity of identifying good arms},
  author={Katz-Samuels, Julian and Jamieson, Kevin},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  year={2020}
}

@phdthesis{degenne_2019_ImpactStructureDesign,
  title={Impact of structure on the design and analysis of bandit algorithms},
  author={Degenne, R{\'e}my},
  year={2019},
  school={Universit{\'e} de Paris}
}

@inproceedings{simchowitz_2017_simulator,
  title={The simulator: Understanding adaptive sampling in the moderate-confidence regime},
  author={Simchowitz, Max and Jamieson, Kevin and Recht, Benjamin},
  booktitle={Conference on Learning Theory},
  year={2017}
}


@InProceedings{barrier_2022_NonAsymptoticApproach,
  title =    {A Non-asymptotic Approach to Best-Arm Identification for Gaussian Bandits },
  author =       {Barrier, Antoine and Garivier, Aur\'elien and Koc\'ak, Tom\'a\v{s}},
  booktitle =    {Proceedings of The 25th International Conference on Artificial Intelligence and Statistics},
  year =   {2022}
}

@article{katz_2020_EmpiricalProcessApproach,
  title={An empirical process approach to the union bound: Practical algorithms for combinatorial and linear bandits},
  author={Katz-Samuels, Julian and Jain, Lalit and Jamieson, Kevin G and others},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@inproceedings{even2002pac,
  title={PAC bounds for multi-armed bandit and Markov decision processes},
  author={Even-Dar, Eyal and Mannor, Shie and Mansour, Yishay},
  booktitle={International Conference on Computational Learning Theory},
  year={2002}
}

@inproceedings{Marjani2022OnTC,
  title={On the complexity of All $\epsilon$-Best Arms Identification},
  author={Aymen Al Marjani and Tom{\'a}s Koc{\'a}k and Aur{\'e}lien Garivier},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  year={2022}
}

@article{wilson1927probable,
  title={Probable inference, the law of succession, and statistical inference},
  author={Wilson, Edwin B},
  journal={Journal of the American Statistical Association},
  volume={22},
  number={158},
  pages={209--212},
  year={1927},
  publisher={Taylor \& Francis}
}

@inproceedings{komiyama2022minimax,
  title={Minimax Optimal Algorithms for Fixed-Budget Best Arm Identification},
  author={Komiyama, Junpei and Tsuchiya, Taira and Honda, Junya},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@inproceedings{you2022information,
  title={Information-directed selection for top-two algorithms},
  author={You, Wei and Qin, Chao and Wang, Zihao and Yang, Shuoguang},
  booktitle={The Thirty Sixth Annual Conference on Learning Theory},
  pages={2850--2851},
  year={2023},
  organization={PMLR}
}

@article{chen2023balancing,
  title={Balancing optimal large deviations in sequential selection},
  author={Chen, Ye and Ryzhov, Ilya O},
  journal={Management Science},
  volume={69},
  number={6},
  pages={3457--3473},
  year={2023},
  publisher={INFORMS}
}

@article{degenne2023existence,
  title={On the Existence of a Complexity in Fixed Budget Bandit Identification},
  author={Degenne, R{\'e}my},
  journal={arXiv preprint arXiv:2303.09468},
  year={2023}
}

@inproceedings{barrier2023best,
  title={On Best-Arm Identification with a Fixed Budget in Non-Parametric Multi-Armed Bandits},
  author={Barrier, Antoine and Garivier, Aur{\'e}lien and Stoltz, Gilles},
  booktitle={International Conference on Algorithmic Learning Theory},
  pages={136--181},
  year={2023},
  organization={PMLR}
}

@inproceedings{rouyer2020tsallis,
  title={Tsallis-inf for decoupled exploration and exploitation in multi-armed bandits},
  author={Rouyer, Chlo{\'e} and Seldin, Yevgeny},
  booktitle={Conference on Learning Theory},
  pages={3227--3249},
  year={2020},
  organization={PMLR}
}

@inproceedings{avner2012decoupling,
  title={Decoupling exploration and exploitation in multi-armed bandits},
  author={Avner, Orly and Mannor, Shie and Shamir, Ohad},
  booktitle={Proceedings of the 29th International Coference on International Conference on Machine Learning},
  pages={1107--1114},
  year={2012}
}

@article{sabato2019epsilon,
  title={Epsilon-best-arm identification in pay-per-reward multi-armed bandits},
  author={Sabato, Sivan},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{jedra2020optimal,
  title={Optimal best-arm identification in linear bandits},
  author={Jedra, Yassir and Proutiere, Alexandre},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={10007--10017},
  year={2020}
}

@inproceedings{kocak2021epsilon,
  title={Epsilon Best Arm Identification in Spectral Bandits.},
  author={Koc{\'a}k, Tom{\'a}s and Garivier, Aur{\'e}lien},
  booktitle={IJCAI},
  pages={2636--2642},
  year={2021}
}

@article{mukherjee2023best,
  title={Best Arm Identification in Stochastic Bandits: Beyond $\beta$-optimality},
  author={Mukherjee, Arpan and Tajer, Ali},
  journal={arXiv preprint arXiv:2301.03785},
  year={2023}
}

@article{shin2018tractable,
  title={Tractable sampling strategies for ordinal optimization},
  author={Shin, Dongwook and Broadie, Mark and Zeevi, Assaf},
  journal={Operations Research},
  volume={66},
  number={6},
  pages={1693--1712},
  year={2018},
  publisher={INFORMS}
}
