@misc{IRM:2020,
      title={Invariant Risk Minimization}, 
      author={Martin Arjovsky and Léon Bottou and Ishaan Gulrajani and David Lopez-Paz},
      year={2020},
      eprint={1907.02893},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@book{PatternRecognitionBook:2006,
author = {Bishop, Christopher M.},
title = {Pattern Recognition and Machine Learning (Information Science and Statistics)},
year = {2006},
isbn = {0387310738},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg}
}

@inproceedings{NullItOut:2020,
    title = "Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection",
    author = "Ravfogel, Shauli  and
      Elazar, Yanai  and
      Gonen, Hila  and
      Twiton, Michael  and
      Goldberg, Yoav",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.647",
    doi = "10.18653/v1/2020.acl-main.647",
    pages = "7237--7256"
}


@article{AmnesicProbing,
  author    = {Yanai Elazar and
               Shauli Ravfogel and
               Alon Jacovi and
               Yoav Goldberg},
  title     = {Amnesic Probing: Behavioral Explanation With Amnesic Counterfactuals},
  journal   = {Trans. Assoc. Comput. Linguistics},
  volume    = {9},
  pages     = {160--175},
  year      = {2021},
  url       = {https://transacl.org/ojs/index.php/tacl/article/view/2423},
  timestamp = {Tue, 11 May 2021 18:13:29 +0200},
  biburl    = {https://dblp.org/rec/journals/tacl/ElazarRJG21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{AdvRemYoav,
    title = "Adversarial Removal of Demographic Attributes from Text Data",
    author = "Elazar, Yanai  and
      Goldberg, Yoav",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1002",
    doi = "10.18653/v1/D18-1002",
    pages = "11--21",
}

@inproceedings{AdvDomAdapGanin,
author = {Ganin, Yaroslav and Lempitsky, Victor},
title = {Unsupervised Domain Adaptation by Backpropagation},
year = {2015},
publisher = {JMLR.org},
booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37},
pages = {1180–1189},
numpages = {10},
location = {Lille, France},
series = {ICML'15}
}




@inproceedings{AdvRemNeubig,
author = {Xie, Qizhe and Dai, Zihang and Du, Yulun and Hovy, Eduard and Neubig, Graham},
title = {Controllable Invariance through Adversarial Feature Learning},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {585–596},
numpages = {12},
location = {Long Beach, California, USA},
series = {NIPS'17}
}


@article{GradDescentMaxMargin,
author = {Soudry, Daniel and Hoffer, Elad and Nacson, Mor Shpigel and Gunasekar, Suriya and Srebro, Nathan},
title = {The Implicit Bias of Gradient Descent on Separable Data},
year = {2018},
issue_date = {January 2018},
publisher = {JMLR.org},
volume = {19},
number = {1},
issn = {1532-4435},
abstract = {We examine gradient descent on unregularized logistic regression problems, with homogeneous linear predictors on linearly separable datasets. We show the predictor converges to the direction of the max-margin (hard margin SVM) solution. The result also generalizes to other monotone decreasing loss functions with an infimum at infinity, to multi-class problems, and to training a weight layer in a deep network in a certain restricted setting. Furthermore, we show this convergence is very slow, and only logarithmic in the convergence of the loss itself. This can help explain the benefit of continuing to optimize the logistic or cross-entropy loss even after the training error is zero and the training loss is extremely small, and, as we show, even if the validation loss increases. Our methodology can also aid in understanding implicit regularization in more complex models and with other optimization methods.},
journal = {J. Mach. Learn. Res.},
month = {jan},
pages = {2822–2878},
numpages = {57},
keywords = {margin, gradient descent, logistic regression, generalization, implicit regularization}
}




@inproceedings{FailureModeOODGen,
title={Understanding the failure modes of out-of-distribution generalization},
author={Vaishnavh Nagarajan and Anders Andreassen and Behnam Neyshabur},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=fSTD6NFIW_b}
}

@inproceedings{GroupDRO,
  added-at = {2021-02-14T23:47:47.000+0100},
  author = {Sagawa, Shiori and Koh, Pang Wei and Hashimoto, Tatsunori B and Liang, Percy},
  biburl = {https://www.bibsonomy.org/bibtex/2b5300c935eeeb991a48a0d1bdf0e7d1c/becker},
  booktitle = {International Conference on Learning Representations (ICLR)},
  interhash = {39cff78e095b34b5b74ac8d46dfe983c},
  intrahash = {b5300c935eeeb991a48a0d1bdf0e7d1c},
  keywords = {classification distribution known network neural p21 project:bmbf relatedwork subgroup subgroups},
  timestamp = {2021-07-25T21:45:46.000+0200},
  title = {Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization},
  year = 2020
}


@inproceedings{ravichander-etal-2021-probing,
    title = "Probing the Probing Paradigm: Does Probing Accuracy Entail Task Relevance?",
    author = "Ravichander, Abhilasha  and
      Belinkov, Yonatan  and
      Hovy, Eduard",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eacl-main.295",
    doi = "10.18653/v1/2021.eacl-main.295",
    pages = "3363--3377",
}

@article{ProbingSurvey,
    author = {Belinkov, Yonatan},
    title = "{Probing Classifiers: Promises, Shortcomings, and Advances}",
    journal = {Computational Linguistics},
    volume = {48},
    number = {1},
    pages = {207-219},
    year = {2022},
    month = {04},
    abstract = "{Probing classifiers have emerged as one of the prominent methodologies for interpreting and analyzing deep neural network models of natural language processing. The basic idea is simple—a classifier is trained to predict some linguistic property from a model’s representations—and has been used to examine a wide variety of models and properties. However, recent studies have demonstrated various methodological limitations of this approach. This squib critically reviews the probing classifiers framework, highlighting their promises, shortcomings, and advances.}",
    issn = {0891-2017},
    doi = {10.1162/coli_a_00422},
    url = {https://doi.org/10.1162/coli\_a\_00422},
    eprint = {https://direct.mit.edu/coli/article-pdf/48/1/207/2006605/coli\_a\_00422.pdf},
}






@inproceedings{li-etal-2016-visualizing,
    title = "Visualizing and Understanding Neural Models in {NLP}",
    author = "Li, Jiwei  and
      Chen, Xinlei  and
      Hovy, Eduard  and
      Jurafsky, Dan",
    booktitle = "Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N16-1082",
    doi = "10.18653/v1/N16-1082",
    pages = "681--691",
}

@inproceedings{sanyal-ren-2021-discretized,
    title = "Discretized Integrated Gradients for Explaining Language Models",
    author = "Sanyal, Soumya  and
      Ren, Xiang",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.805",
    doi = "10.18653/v1/2021.emnlp-main.805",
    pages = "10285--10299",
}

@inproceedings{han-tsvetkov-2021-influence-tuning,
    title = "Influence Tuning: Demoting Spurious Correlations via Instance Attribution and Instance-Driven Updates",
    author = "Han, Xiaochuang  and
      Tsvetkov, Yulia",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.374",
    doi = "10.18653/v1/2021.findings-emnlp.374",
    pages = "4398--4409",
}

@inproceedings{GarimaInfluenceExample,
 author = {Pruthi, Garima and Liu, Frederick and Kale, Satyen and Sundararajan, Mukund},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {19920--19930},
 publisher = {Curran Associates, Inc.},
 title = {Estimating Training Data Influence by Tracing Gradient Descent},
 url = {https://proceedings.neurips.cc/paper/2020/file/e6385d39ec9394f2f3a354d9d2b88eec-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{hewitt-liang-2019-control,
    title = "Designing and Interpreting Probes with Control Tasks",
    author = "Hewitt, John  and
      Liang, Percy",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1275",
    doi = "10.18653/v1/D19-1275",
    pages = "2733--2743",
}

@inproceedings{GururanganMNLINegationArtifact,
    title = "Annotation Artifacts in Natural Language Inference Data",
    author = "Gururangan, Suchin  and
      Swayamdipta, Swabha  and
      Levy, Omer  and
      Schwartz, Roy  and
      Bowman, Samuel  and
      Smith, Noah A.",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-2017",
    doi = "10.18653/v1/N18-2017",
    pages = "107--112",
}

@inproceedings{conneau-etal-2018-cram,
    title = "What you can cram into a single {\$}{\&}!{\#}* vector: Probing sentence embeddings for linguistic properties",
    author = {Conneau, Alexis  and
      Kruszewski, German  and
      Lample, Guillaume  and
      Barrault, Lo{\"\i}c  and
      Baroni, Marco},
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1198",
    doi = "10.18653/v1/P18-1198",
    pages = "2126--2136",
    abstract = "Although much effort has recently been devoted to training high-quality sentence embeddings, we still have a poor understanding of what they are capturing. {``}Downstream{''} tasks, often based on sentence classification, are commonly used to evaluate the quality of sentence representations. The complexity of the tasks makes it however difficult to infer what kind of information is present in the representations. We introduce here 10 probing tasks designed to capture simple linguistic features of sentences, and we use them to study embeddings generated by three different encoders trained in eight distinct ways, uncovering intriguing properties of both encoders and training methods.",
}

@inproceedings{ProbeYoavICLR17,
  author    = {Yossi Adi and
               Einat Kermany and
               Yonatan Belinkov and
               Ofer Lavi and
               Yoav Goldberg},
  title     = {Fine-grained Analysis of Sentence Embeddings Using Auxiliary Prediction
               Tasks},
  booktitle = {5th International Conference on Learning Representations, {ICLR} 2017,
               Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2017},
  url       = {https://openreview.net/forum?id=BJh6Ztuxl},
  timestamp = {Thu, 25 Jul 2019 14:25:48 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/AdiKBLG17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{McCoyMNLIArtifact,
    title = "Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference",
    author = "McCoy, Tom  and
      Pavlick, Ellie  and
      Linzen, Tal",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1334",
    doi = "10.18653/v1/P19-1334",
    pages = "3428--3448",
    abstract = "A machine learning system can score well on a given test set by relying on heuristics that are effective for frequent example types but break down in more challenging cases. We study this issue within natural language inference (NLI), the task of determining whether one sentence entails another. We hypothesize that statistical NLI models may adopt three fallible syntactic heuristics: the lexical overlap heuristic, the subsequence heuristic, and the constituent heuristic. To determine whether models have adopted these heuristics, we introduce a controlled evaluation set called HANS (Heuristic Analysis for NLI Systems), which contains many examples where the heuristics fail. We find that models trained on MNLI, including BERT, a state-of-the-art model, perform very poorly on HANS, suggesting that they have indeed adopted these heuristics. We conclude that there is substantial room for improvement in NLI systems, and that the HANS dataset can motivate and measure progress in this area.",
}

@misc{IRM,
  doi = {10.48550/ARXIV.1907.02893},
  
  url = {https://arxiv.org/abs/1907.02893},
  
  author = {Arjovsky, Martin and Bottou, Léon and Gulrajani, Ishaan and Lopez-Paz, David},
  
  keywords = {Machine Learning (stat.ML), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Invariant Risk Minimization},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{kaushik2021learningthediff,
  title={Explaining the Efficacy of Counterfactually Augmented Data},
  author={Kaushik, Divyansh and Setlur, Amrith and Hovy, Eduard and Lipton, Zachary C},
  journal={International Conference on Learning Representations (ICLR)},
  year={2021}
}

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}

@article{roberta19,
  author    = {Yinhan Liu and
               Myle Ott and
               Naman Goyal and
               Jingfei Du and
               Mandar Joshi and
               Danqi Chen and
               Omer Levy and
               Mike Lewis and
               Luke Zettlemoyer and
               Veselin Stoyanov},
  title     = {RoBERTa: {A} Robustly Optimized {BERT} Pretraining Approach},
  journal   = {CoRR},
  volume    = {abs/1907.11692},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.11692}
}


@InProceedings{mnliDataset,
  author = "Williams, Adina
            and Nangia, Nikita
            and Bowman, Samuel",
  title = "A Broad-Coverage Challenge Corpus for 
           Sentence Understanding through Inference",
  booktitle = "Proceedings of the 2018 Conference of 
               the North American Chapter of the 
               Association for Computational Linguistics:
               Human Language Technologies, Volume 1 (Long
               Papers)",
  year = "2018",
  publisher = "Association for Computational Linguistics",
  pages = "1112--1122",
  location = "New Orleans, Louisiana",
  url = "http://aclweb.org/anthology/N18-1101"
}

@inproceedings{pan16Dataset,
  author       = {Rangel, Francisco and
                  Rosso, Paolo and
                  Verhoeven, Ben and
                  Daelemans, Walter and
                  Potthast, Martin and
                  Stein, Benno},
  title        = "PAN16 Author Profiling, https://doi.org/10.5281/zenodo.3745963",
  month        = sep,
  year         = 2016,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.3745963},
  url          = {https://doi.org/10.5281/zenodo.3745963},
  booktitle = "CLEF 2016 Labs and Workshops, Notebook Papers."
}

@inproceedings{aaeDataset,
author = {Blodgett, Su Lin and Green, Lisa and O'Connor, Brendan}, 
title = {{Demographic Dialectal Variation in Social Media: A Case Study of African-American English}},
booktitle = {Proceedings of EMNLP},
year = 2016}



@inproceedings{pennington2014glove,
  author = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
  title = {GloVe: Global Vectors for Word Representation},
  year = {2014},
  pages = {1532--1543},
  url = {http://www.aclweb.org/anthology/D14-1162},
}



@article{GenderInLatent,
    author = {Koppel, Moshe and Argamon, Shlomo and Shimoni, Anat Rachel},
    title = "{Automatically Categorizing Written Texts by Author Gender}",
    journal = {Literary and Linguistic Computing},
    volume = {17},
    number = {4},
    pages = {401-412},
    year = {2002},
    month = {11},
    abstract = "{The problem of automatically determining the gender of a document's author would appear to be a more subtle problem than those of categorization by topic or authorship attribution. Nevertheless, it is shown that automated text categorization techniques can exploit combinations of simple lexical and syntactic features to infer the gender of the author of an unseen formal written document with approximately 80 per cent accuracy. The same techniques can be used to determine if a document is fiction or non‐fiction with approximately 98 per cent accuracy.}",
    issn = {0268-1145},
    doi = {10.1093/llc/17.4.401},
    url = {https://doi.org/10.1093/llc/17.4.401},
    eprint = {https://academic.oup.com/dsh/article-pdf/17/4/401/3345463/170401.pdf},
}

@article{AgeInLatentTwitter, 
title={quot;How Old Do You Think I Amquot; A Study of Language and Age in Twitter}, 
volume={7}, 
url={https://ojs.aaai.org/index.php/ICWSM/article/view/14381}, 
abstractNote={ &lt;p&gt; In this paper we focus on the connection between age and language use, exploring age prediction of Twitter users based on their tweets. We discuss the construction of a fine-grained annotation effort to assign ages and life stages to Twitter users. Using this dataset, we explore age prediction in three different ways: classifying users into age categories, by life stages, and predicting their exact age. We find that an automatic system achieves better performance than humans on these tasks and that both humans and the automatic systems have difficulties predicting the age of older people. Moreover, we present a detailed analysis of variables that change with age. We find strong patterns of change, and that most changes occur at young ages. &lt;/p&gt; }, number={1}, journal={Proceedings of the International AAAI Conference on Web and Social Media}, 
author={Nguyen, Dong and Gravel, Rilana and Trieschnigg, Dolf and Meder, Theo},
year={2021}, 
month={Aug.},
pages={439-448} 
}



@inproceedings{DutchSensitiveLatent,
    title = "{CL}i{PS} Stylometry Investigation ({CSI}) corpus: A {D}utch corpus for the detection of age, gender, personality, sentiment and deception in text",
    author = "Verhoeven, Ben  and
      Daelemans, Walter",
    booktitle = "Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14)",
    month = may,
    year = "2014",
    address = "Reykjavik, Iceland",
    publisher = "European Language Resources Association (ELRA)",
    url = "http://www.lrec-conf.org/proceedings/lrec2014/pdf/1_Paper.pdf",
    pages = "3081--3085",
    abstract = "We present the CLiPS Stylometry Investigation (CSI) corpus, a new Dutch corpus containing reviews and essays written by university students. It is designed to serve multiple purposes: detection of age, gender, authorship, personality, sentiment, deception, topic and genre. Another major advantage is its planned yearly expansion with each year{'}s new students. The corpus currently contains about 305,000 tokens spread over 749 documents. The average review length is 128 tokens; the average essay length is 1126 tokens. The corpus will be made available on the CLiPS website (www.clips.uantwerpen.be/datasets) and can freely be used for academic research purposes. An initial deception detection experiment was performed on this data. Deception detection is the task of automatically classifying a text as being either truthful or deceptive, in our case by examining the writing style of the author. This task has never been investigated for Dutch before. We performed a supervised machine learning experiment using the SVM algorithm in a 10-fold cross-validation setup. The only features were the token unigrams present in the training data. Using this simple method, we reached a state-of-the-art F-score of 72.2{\%}.",
}


@inproceedings{DebiaWordEmbProjectionBolukbasi,
author = {Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James and Saligrama, Venkatesh and Kalai, Adam},
title = {Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings},
year = {2016},
isbn = {9781510838819},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {The blind application of machine learning runs the risk of amplifying biases present in data. Such a danger is facing us with word embedding, a popular framework to represent text data as vectors which has been used in many machine learning and natural language processing tasks. We show that even word embeddings trained on Google News articles exhibit female/male gender stereotypes to a disturbing extent. This raises concerns because their widespread use, as we describe, often tends to amplify these biases. Geometrically, gender bias is first shown to be captured by a direction in the word embedding. Second, gender neutral words are shown to be linearly separable from gender definition words in the word embedding. Using these properties, we provide a methodology for modifying an embedding to remove gender stereotypes, such as the association between the words receptionist and female, while maintaining desired associations such as between the words queen and female. Using crowd-worker evaluation as well as standard benchmarks, we empirically demonstrate that our algorithms significantly reduce gender bias in embeddings while preserving the its useful properties such as the ability to cluster related concepts and to solve analogy tasks. The resulting embeddings can be used in applications without amplifying gender bias.},
booktitle = {Proceedings of the 30th International Conference on Neural Information Processing Systems},
pages = {4356–4364},
numpages = {9},
location = {Barcelona, Spain},
series = {NIPS'16}
}


@inproceedings{shi-etal-2016-stringProbing,
    title = "Does String-Based Neural {MT} Learn Source Syntax?",
    author = "Shi, Xing  and
      Padhi, Inkit  and
      Knight, Kevin",
    booktitle = "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2016",
    address = "Austin, Texas",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D16-1159",
    doi = "10.18653/v1/D16-1159",
    pages = "1526--1534",
}

@inproceedings{PartialPredictiveInvDimitris,
  author    = {Dimitris Tsipras and
               Shibani Santurkar and
               Logan Engstrom and
               Alexander Turner and
               Aleksander Madry},
  title     = {Robustness May Be at Odds with Accuracy},
  booktitle = {7th International Conference on Learning Representations, {ICLR} 2019,
               New Orleans, LA, USA, May 6-9, 2019},
  publisher = {OpenReview.net},
  year      = {2019},
  url       = {https://openreview.net/forum?id=SyxAb30cY7},
  timestamp = {Thu, 25 Jul 2019 14:26:02 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/TsiprasSETM19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{OverparamExcerbatesSpSagawa,
author = {Sagawa, Shiori and Raghunathan, Aditi and Koh, Pang Wei and Liang, Percy},
title = {An Investigation of Why Overparameterization Exacerbates Spurious Correlations},
year = {2020},
publisher = {JMLR.org},
abstract = {We study why overparameterization--increasing model size well beyond the point of zero training error--can hurt test error on minority groups despite improving average test error when there are spurious correlations in the data. Through simulations and experiments on two image datasets, we identify two key properties of the training data that drive this behavior: the proportions of majority versus minority groups, and the signal-to-noise ratio of the spurious correlations. We then analyze a linear setting and theoretically show how the inductive bias of models towards "memorizing" fewer examples can cause overparameterization to hurt. Our analysis leads to a counterintuitive approach of subsampling the majority group, which empirically achieves low minority error in the overparameterized regime, even though the standard approach of upweighting the minority fails. Overall, our results suggest a tension between using overparameterized models versus using all the training data for achieving low worst-group error.},
booktitle = {Proceedings of the 37th International Conference on Machine Learning},
articleno = {773},
numpages = {11},
series = {ICML'20}
}



@inproceedings{PostHocRemovalXu,
author = {Xu, Ke and Cao, Tongyi and Shah, Swair and Maung, Crystal and Schweitzer, Haim},
title = {Cleaning the Null Space: A Privacy Mechanism for Predictors},
year = {2017},
publisher = {AAAI Press},
abstract = {In standard machine learning and regression setting feature values are used to predict some desired information. The privacy challenge considered here is to prevent an adversary from using available feature values to predict confidential information that one wishes to keep secret. We show that this can sometimes be achieved with almost no effect on the quality of predicting desired information. We describe two algorithms aimed at providing such privacy when the predictors have a linear operator in the first stage. The desired effect can be achieved by zeroing out feature components in the approximate null space of the linear operator.},
booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
pages = {2789–2795},
numpages = {7},
location = {San Francisco, California, USA},
series = {AAAI'17}
}

@inproceedings{PostHocDuvenaud,
  author    = {Kawin Ethayarajh and
               David Duvenaud and
               Graeme Hirst},
  editor    = {Anna Korhonen and
               David R. Traum and
               Llu{\'{\i}}s M{\`{a}}rquez},
  title     = {Understanding Undesirable Word Embedding Associations},
  booktitle = {Proceedings of the 57th Conference of the Association for Computational
               Linguistics, {ACL} 2019, Florence, Italy, July 28- August 2, 2019,
               Volume 1: Long Papers},
  pages     = {1696--1705},
  publisher = {Association for Computational Linguistics},
  year      = {2019},
  url       = {https://doi.org/10.18653/v1/p19-1166},
  doi       = {10.18653/v1/p19-1166},
  timestamp = {Fri, 06 Aug 2021 00:41:01 +0200},
  biburl    = {https://dblp.org/rec/conf/acl/EthayarajhDH19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{rightfortherightreasonfinaledoshi,
  author    = {Andrew Slavin Ross and Michael C. Hughes and Finale Doshi-Velez},
  title     = {Right for the Right Reasons: Training Differentiable Models by Constraining their Explanations},
  booktitle = {Proceedings of the Twenty-Sixth International Joint Conference on
               Artificial Intelligence, {IJCAI-17}},
  pages     = {2662--2670},
  year      = {2017},
  doi       = {10.24963/ijcai.2017/371},
  url       = {https://doi.org/10.24963/ijcai.2017/371},
}


@inproceedings{victorStressTest,
  author    = {Victor Veitch and
               Alexander D'Amour and
               Steve Yadlowsky and
               Jacob Eisenstein},
  editor    = {Marc'Aurelio Ranzato and
               Alina Beygelzimer and
               Yann N. Dauphin and
               Percy Liang and
               Jennifer Wortman Vaughan},
  title     = {Counterfactual Invariance to Spurious Correlations in Text Classification},
  booktitle = {Advances in Neural Information Processing Systems 34: Annual Conference
               on Neural Information Processing Systems 2021, NeurIPS 2021, December
               6-14, 2021, virtual},
  pages     = {16196--16208},
  year      = {2021},
  url       = {https://proceedings.neurips.cc/paper/2021/hash/8710ef761bbb29a6f9d12e4ef8e4379c-Abstract.html},
  timestamp = {Tue, 03 May 2022 16:20:48 +0200},
  biburl    = {https://dblp.org/rec/conf/nips/VeitchDYE21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{kumar-talukdar-2020-nile,
    title = "{NILE} : Natural Language Inference with Faithful Natural Language Explanations",
    author = "Kumar, Sawan  and
      Talukdar, Partha",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.771",
    doi = "10.18653/v1/2020.acl-main.771",
    pages = "8730--8742",
    abstract = "The recent growth in the popularity and success of deep learning models on NLP classification tasks has accompanied the need for generating some form of natural language explanation of the predicted labels. Such generated natural language (NL) explanations are expected to be faithful, i.e., they should correlate well with the model{'}s internal decision making. In this work, we focus on the task of natural language inference (NLI) and address the following question: can we build NLI systems which produce labels with high accuracy, while also generating faithful explanations of its decisions? We propose Natural-language Inference over Label-specific Explanations (NILE), a novel NLI method which utilizes auto-generated label-specific NL explanations to produce labels along with its faithful explanation. We demonstrate NILE{'}s effectiveness over previously reported methods through automated and human evaluation of the produced labels and explanations. Our evaluation of NILE also supports the claim that accurate systems capable of providing testable explanations of their decisions can be designed. We discuss the faithfulness of NILE{'}s explanations in terms of sensitivity of the decisions to the corresponding explanations. We argue that explicit evaluation of faithfulness, in addition to label and explanation accuracy, is an important step in evaluating model{'}s explanations. Further, we demonstrate that task-specific probes are necessary to establish such sensitivity.",
}




@InProceedings{LinearConceptErasure,
  title = 	 {Linear Adversarial Concept Erasure},
  author =       {Ravfogel, Shauli and Twiton, Michael and Goldberg, Yoav and Cotterell, Ryan D},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {18400--18421},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/ravfogel22a/ravfogel22a.pdf},
}




@article{KernelConceptErasure,
  author    = {Shauli Ravfogel and
               Francisco Vargas and
               Yoav Goldberg and
               Ryan Cotterell},
  title     = {Adversarial Concept Erasure in Kernel Space},
  journal   = {CoRR},
  volume    = {abs/2201.12191},
  year      = {2022},
  url       = {https://arxiv.org/abs/2201.12191},
  eprinttype = {arXiv},
  eprint    = {2201.12191},
  timestamp = {Wed, 02 Feb 2022 15:00:01 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2201-12191.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}





@InProceedings{MaxMarginJustificationJi,
  title = 	 {The implicit bias of gradient descent on nonseparable data},
  author =       {Ji, Ziwei and Telgarsky, Matus},
  booktitle = 	 {Proceedings of the Thirty-Second Conference on Learning Theory},
  pages = 	 {1772--1798},
  year = 	 {2019},
  editor = 	 {Beygelzimer, Alina and Hsu, Daniel},
  volume = 	 {99},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {25--28 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v99/ji19a/ji19a.pdf},
  url = 	 {https://proceedings.mlr.press/v99/ji19a.html}
}


@misc{HuggingFace,
  doi = {10.48550/ARXIV.1910.03771},
  
  url = {https://arxiv.org/abs/1910.03771},
  
  author = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, Rémi and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and von Platen, Patrick and Ma, Clara and Jernite, Yacine and Plu, Julien and Xu, Canwen and Scao, Teven Le and Gugger, Sylvain and Drame, Mariama and Lhoest, Quentin and Rush, Alexander M.},
  
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {HuggingFace's Transformers: State-of-the-art Natural Language Processing},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@article{rehurek2011gensim,
  title={Gensim--python framework for vector space modelling},
  author={Rehurek, Radim and Sojka, Petr},
  journal={NLP Centre, Faculty of Informatics, Masaryk University, Brno, Czech Republic},
  volume={3},
  number={2},
  year={2011}
}


@article{relu,
  title={Deep learning using rectified linear units (relu)},
  author={Agarap, Abien Fred},
  journal={arXiv preprint arXiv:1803.08375},
  year={2018}
}






@InProceedings{DigonalizationSymmMatrix,
author={Diehl, P.
and Kellerhals, H.
and Lustig, E.},
title={Diagonalization of Symmetric Matrices},
booktitle={Computer Assistance in the Analysis of High-Resolution NMR Spectra},
year={1972},
publisher={Springer Berlin Heidelberg},
address={Berlin, Heidelberg},
pages={73--77},
isbn={978-3-642-65261-5}
}

@book{arfken_math_methods,
  added-at = {2013-03-22T02:46:59.000+0100},
  address = {San Diego},
  annote = {First edition published in 1967.},
  author = {Arfken, George},
  biburl = {https://www.bibsonomy.org/bibtex/206a7a290f700ffb0ec221872f672f5ae/drmatusek},
  edition = {Third},
  interhash = {3892ff92c99fc6b30457216863fb6b22},
  intrahash = {06a7a290f700ffb0ec221872f672f5ae},
  keywords = {ODEs analysis complex functional mathematics matrix mechanics physics quantum},
  publisher = {Academic Press, {Inc.}},
  timestamp = {2014-11-16T04:53:12.000+0100},
  title = {Mathematical Methods for Physicists},
  year = 1985
}


@inproceedings{checklist,
    title = "Beyond Accuracy: Behavioral Testing of {NLP} Models with {C}heck{L}ist",
    author = "Ribeiro, Marco Tulio  and
      Wu, Tongshuang  and
      Guestrin, Carlos  and
      Singh, Sameer",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.442",
    doi = "10.18653/v1/2020.acl-main.442",
    pages = "4902--4912"
}


@inproceedings{counterfactual_reg,
    title = "Can We Improve Model Robustness through Secondary Attribute Counterfactuals?",
    author = "Balashankar, Ananth  and
      Wang, Xuezhi  and
      Packer, Ben  and
      Thain, Nithum  and
      Chi, Ed  and
      Beutel, Alex",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.386",
    doi = "10.18653/v1/2021.emnlp-main.386",
    pages = "4701--4712"
}


@inproceedings{fairness_lit_future_hardt,
 author = {Hardt, Moritz and Price, Eric and Price, Eric and Srebro, Nati},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Equality of Opportunity in Supervised Learning},
 url = {https://proceedings.neurips.cc/paper/2016/file/9d2682367c3935defcb1f9e247a97c0d-Paper.pdf},
 volume = {29},
 year = {2016}
}


@article{fairness_survey_future_mehrabi,
author = {Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
title = {A Survey on Bias and Fairness in Machine Learning},
year = {2021},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3457607},
doi = {10.1145/3457607},
journal = {ACM Comput. Surv.},
month = {jul},
articleno = {115},
numpages = {35},
keywords = {machine learning, natural language processing, Fairness and bias in artificial intelligence, deep learning, representation learning}
}

@inproceedings{kancheti2022matching,
  title={Matching Learned Causal Effects of Neural Networks with Domain Priors},
  author={Kancheti, Sai Srinivas and Reddy, Abbavaram Gowtham and Balasubramanian, Vineeth N and Sharma, Amit},
  booktitle={International Conference on Machine Learning},
  pages={10676--10696},
  year={2022},
  organization={PMLR}
}

@inproceedings{mahajan2021domain,
  title={Domain generalization using causal matching},
  author={Mahajan, Divyat and Tople, Shruti and Sharma, Amit},
  booktitle={International Conference on Machine Learning},
  pages={7313--7324},
  year={2021},
  organization={PMLR}
}

@inproceedings{dash2022evaluating,
  title={Evaluating and mitigating bias in image classifiers: A causal perspective using counterfactuals},
  author={Dash, Saloni and Balasubramanian, Vineeth N and Sharma, Amit},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={915--924},
  year={2022}
}


@inproceedings{ruslanINLP,
  author={Paul Pu Liang and Chiyu Wu and Louis-Philippe Morency and Ruslan Salakhutdinov},
  title={Towards Understanding and Mitigating Social Biases in Language Models},
  year={2021},
  cdate={1609459200000},
  pages={6565-6576},
  url={http://proceedings.mlr.press/v139/liang21a.html},
  booktitle={ICML},
}

@inproceedings{INLPinterpret,
  author={Alon Jacovi and Swabha Swayamdipta and Shauli Ravfogel and Yanai Elazar and Yejin Choi and Yoav Goldberg},
  title={Contrastive Explanations for Model Interpretability},
  year={2021},
  cdate={1609459200000},
  pages={1597-1611},
  url={https://aclanthology.org/2021.emnlp-main.120},
  booktitle={EMNLP (1)},
}


@inproceedings{ryanCAD2019,
    title = "Counterfactual Data Augmentation for Mitigating Gender Stereotypes in Languages with Rich Morphology",
    author = "Zmigrod, Ran  and
      Mielke, Sabrina J.  and
      Wallach, Hanna  and
      Cotterell, Ryan",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1161",
    doi = "10.18653/v1/P19-1161",
    pages = "1651--1661"
}


@inproceedings{cadSen2022,
    title = "Counterfactually Augmented Data and Unintended Bias: The Case of Sexism and Hate Speech Detection",
    author = "Sen, Indira  and
      Samory, Mattia  and
      Wagner, Claudia  and
      Augenstein, Isabelle",
    booktitle = "Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.naacl-main.347",
    doi = "10.18653/v1/2022.naacl-main.347",
    pages = "4716--4726"
}


