\begin{thebibliography}{35}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Balduzzi et~al.(2019)Balduzzi, Garnelo, Bachrach, Czarnecki, Perolat,
  Jaderberg, and Graepel]{psrorn}
Balduzzi, D., Garnelo, M., Bachrach, Y., Czarnecki, W.~M., Perolat, J.,
  Jaderberg, M., and Graepel, T.
\newblock Open-ended learning in symmetric zero-sum games, 2019.

\bibitem[Bard et~al.(2020)Bard, Foerster, Chandar, Burch, Lanctot, Song,
  Parisotto, Dumoulin, Moitra, Hughes, et~al.]{hanabi2020Nolann}
Bard, N., Foerster, J.~N., Chandar, S., Burch, N., Lanctot, M., Song, H.~F.,
  Parisotto, E., Dumoulin, V., Moitra, S., Hughes, E., et~al.
\newblock The hanabi challenge: A new frontier for ai research.
\newblock \emph{Artificial Intelligence}, 280:\penalty0 103216, 2020.

\bibitem[Canaan et~al.(2022)Canaan, Gao, Togelius, Nealen, and
  Menzel]{Canaan2022Hanabi}
Canaan, R., Gao, X., Togelius, J., Nealen, A., and Menzel, S.
\newblock Generating and adapting to diverse ad-hoc partners in hanabi.
\newblock \emph{IEEE Transactions on Games}, pp.\  1--1, 2022.

\bibitem[Carroll et~al.(2019)Carroll, Shah, Ho, Griffiths, Seshia, Abbeel, and
  Dragan]{HARL}
Carroll, M., Shah, R., Ho, M.~K., Griffiths, T., Seshia, S., Abbeel, P., and
  Dragan, A.
\newblock On the utility of learning about humans for human-ai coordination.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Castro et~al.(2009)Castro, G{\'o}mez, and
  Tejada]{Castro2009PolynomialCO}
Castro, J., G{\'o}mez, D., and Tejada, J.
\newblock Polynomial calculation of the shapley value based on sampling.
\newblock \emph{Comput. Oper. Res.}, 36:\penalty0 1726--1730, 2009.

\bibitem[Chalkiadakis et~al.(2011)Chalkiadakis, Elkind, and
  Wooldridge]{chalkiadakis2011computational}
Chalkiadakis, G., Elkind, E., and Wooldridge, M.
\newblock Computational aspects of cooperative game theory.
\newblock \emph{Synthesis Lectures on Artificial Intelligence and Machine
  Learning}, 5\penalty0 (6):\penalty0 1--168, 2011.

\bibitem[Charakorn et~al.(2020)Charakorn, Manoonpong, and
  Dilokthanakul]{charakorn2020investigating}
Charakorn, R., Manoonpong, P., and Dilokthanakul, N.
\newblock Investigating partner diversification methods in cooperative
  multi-agent deep reinforcement learning.
\newblock In \emph{International Conference on Neural Information Processing},
  pp.\  395--402. Springer, 2020.

\bibitem[Freeman(1978)]{FREEMAN1978215}
Freeman, L.~C.
\newblock Centrality in social networks conceptual clarification.
\newblock \emph{Social Networks}, 1\penalty0 (3):\penalty0 215--239, 1978.
\newblock ISSN 0378-8733.

\bibitem[Fudenberg et~al.(1998)Fudenberg, Drew, Levine, and
  Levine]{Fudenberg1998Theory}
Fudenberg, D., Drew, F., Levine, D.~K., and Levine, D.~K.
\newblock \emph{The theory of learning in games}, volume~2.
\newblock MIT press, 1998.

\bibitem[Hu et~al.(2020)Hu, Lerer, Peysakhovich, and
  Foerster]{Hu2020OtherPlayFZ}
Hu, H., Lerer, A., Peysakhovich, A., and Foerster, J.~N.
\newblock "other-play" for zero-shot coordination.
\newblock In \emph{International Conference on Machine Learning}, 2020.

\bibitem[Jaderberg et~al.(2017)Jaderberg, Dalibard, Osindero, Czarnecki,
  Donahue, Razavi, Vinyals, Green, Dunning, Simonyan, et~al.]{PBT}
Jaderberg, M., Dalibard, V., Osindero, S., Czarnecki, W.~M., Donahue, J.,
  Razavi, A., Vinyals, O., Green, T., Dunning, I., Simonyan, K., et~al.
\newblock Population based training of neural networks.
\newblock \emph{arXiv preprint arXiv:1711.09846}, 2017.

\bibitem[Knott et~al.(2021)Knott, Carroll, Devlin, Ciosek, Hofmann, Dragan, and
  Shah]{knott2021evaluating}
Knott, P., Carroll, M., Devlin, S., Ciosek, K., Hofmann, K., Dragan, A.~D., and
  Shah, R.
\newblock Evaluating the robustness of collaborative agents.
\newblock \emph{arXiv preprint arXiv:2101.05507}, 2021.

\bibitem[Lanctot et~al.(2017)Lanctot, Zambaldi, Gruslys, Lazaridou, Tuyls,
  Perolat, Silver, and Graepel]{NIPS2017_3323fe11}
Lanctot, M., Zambaldi, V., Gruslys, A., Lazaridou, A., Tuyls, K., Perolat, J.,
  Silver, D., and Graepel, T.
\newblock A unified game-theoretic approach to multiagent reinforcement
  learning.
\newblock In Guyon, I., Luxburg, U.~V., Bengio, S., Wallach, H., Fergus, R.,
  Vishwanathan, S., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~30. Curran Associates, Inc., 2017.

\bibitem[Legg \& Hutter(2007)Legg and Hutter]{Legg2007Universal}
Legg, S. and Hutter, M.
\newblock Universal intelligence: A definition of machine intelligence.
\newblock \emph{Minds Mach.}, 17\penalty0 (4):\penalty0 391–444, dec 2007.

\bibitem[Lerer \& Peysakhovich(2018)Lerer and Peysakhovich]{lerer2018learning}
Lerer, A. and Peysakhovich, A.
\newblock Learning social conventions in markov games.
\newblock \emph{arXiv preprint arXiv:1806.10071}, 2018.

\bibitem[Liu et~al.(2021)Liu, Jia, Wen, Hu, Chen, Fan, Hu, and
  Yang]{liu2021towards}
Liu, X., Jia, H., Wen, Y., Hu, Y., Chen, Y., Fan, C., Hu, Z., and Yang, Y.
\newblock Towards unifying behavioral and response diversity for open-ended
  learning in zero-sum games.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 941--952, 2021.

\bibitem[Lupu et~al.(2021)Lupu, Cui, Hu, and Foerster]{TrajDi}
Lupu, A., Cui, B., Hu, H., and Foerster, J.
\newblock Trajectory diversity for zero-shot coordination.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  7204--7213. PMLR, 2021.

\bibitem[Mahajan et~al.(2022)Mahajan, Samvelyan, Gupta, Ellis, Sun,
  Rockt{\"a}schel, and Whiteson]{mahajan2022generalization}
Mahajan, A., Samvelyan, M., Gupta, T., Ellis, B., Sun, M., Rockt{\"a}schel, T.,
  and Whiteson, S.
\newblock Generalization in cooperative multi-agent systems.
\newblock \emph{arXiv preprint arXiv:2202.00104}, 2022.

\bibitem[McAleer et~al.(2020)McAleer, Lanier, Fox, and
  Baldi]{mcaleer2020pipeline}
McAleer, S., Lanier, J.~B., Fox, R., and Baldi, P.
\newblock Pipeline psro: A scalable approach for finding approximate nash
  equilibria in large games.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 20238--20248, 2020.

\bibitem[McAleer et~al.(2022)McAleer, Lanier, Wang, Baldi, Fox, and
  Sandholm]{mcaleer2022self}
McAleer, S., Lanier, J., Wang, K., Baldi, P., Fox, R., and Sandholm, T.
\newblock Self-play psro: Toward optimal populations in two-player zero-sum
  games.
\newblock \emph{arXiv preprint arXiv:2207.06541}, 2022.

\bibitem[Meier \& Mujika(2022)Meier and Mujika]{meier2022open}
Meier, R. and Mujika, A.
\newblock Open-ended reinforcement learning with neural reward functions.
\newblock \emph{arXiv preprint arXiv:2202.08266}, 2022.

\bibitem[Page et~al.(1999)Page, Brin, Motwani, and Winograd]{page1999pagerank}
Page, L., Brin, S., Motwani, R., and Winograd, T.
\newblock The pagerank citation ranking: Bringing order to the web.
\newblock Technical report, Stanford InfoLab, 1999.

\bibitem[Peleg \& Sudh{\"o}lter(2007)Peleg and Sudh{\"o}lter]{Bezalel2007intro}
Peleg, B. and Sudh{\"o}lter, P.
\newblock \emph{Introduction to the theory of cooperative games}.
\newblock Theory and Decision Library Series C. Springer Science+Business
  Media, United States, 2 edition, 2007.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{schulman2017proximal}
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Shapley(1971)]{shapley1971}
Shapley, L.~S.
\newblock Cores of convex games.
\newblock \emph{International journal of game theory}, 1:\penalty0 11--26,
  1971.

\bibitem[Srivastava et~al.(2012)Srivastava, Steunebrink, Stollenga, and
  Schmidhuber]{Srivastava2012Comtinually}
Srivastava, R., Steunebrink, B., Stollenga, M., and Schmidhuber, J.
\newblock Continually adding self-invented problems to the repertoire: First
  experiments with powerplay.
\newblock \emph{2012 IEEE International Conference on Development and Learning
  and Epigenetic Robotics, ICDL 2012}, pp.\  1--6, 11 2012.

\bibitem[Strouse et~al.(2021)Strouse, McKee, Botvinick, Hughes, and
  Everett]{FCP}
Strouse, D., McKee, K., Botvinick, M., Hughes, E., and Everett, R.
\newblock Collaborating with humans without human data.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 14502--14515, 2021.

\bibitem[Team et~al.(2021)Team, Stooke, Mahajan, Barros, Deck, Bauer,
  Sygnowski, Trebacz, Jaderberg, Mathieu, et~al.]{Team2021OpenEndedLL}
Team, O. E.~L., Stooke, A., Mahajan, A., Barros, C., Deck, C., Bauer, J.,
  Sygnowski, J., Trebacz, M., Jaderberg, M., Mathieu, M., et~al.
\newblock Open-ended learning leads to generally capable agents.
\newblock \emph{arXiv preprint arXiv:2107.12808}, 2021.

\bibitem[Tesauro(1994)]{SP}
Tesauro, G.
\newblock Td-gammon, a self-teaching backgammon program, achieves master-level
  play.
\newblock \emph{Neural computation}, 6\penalty0 (2):\penalty0 215--219, 1994.

\bibitem[Tuyls et~al.(2018)Tuyls, Perolat, Lanctot, Leibo, and
  Graepel]{Karl2018Generalised}
Tuyls, K., Perolat, J., Lanctot, M., Leibo, J.~Z., and Graepel, T.
\newblock A generalised method for empirical game theoretic analysis.
\newblock In \emph{Proceedings of the 17th International Conference on
  Autonomous Agents and MultiAgent Systems}, AAMAS '18, pp.\  77–85,
  Richland, SC, 2018.

\bibitem[Walsh et~al.(2002)Walsh, Das, Tesauro, and
  Kephart]{Walsh2002Analyzing}
Walsh, W.~E., Das, R., Tesauro, G., and Kephart, J.~O.
\newblock Analyzing complex strategic interactions in multi-agent systems.
\newblock In \emph{AAAI-02 Workshop on Game-Theoretic and Decision-Theoretic
  Agents}, pp.\  109--118, 2002.

\bibitem[Xing \& Ghorbani(2004)Xing and Ghorbani]{Xing2004Weighted}
Xing, W. and Ghorbani, A.
\newblock Weighted pagerank algorithm.
\newblock In \emph{Proceedings. Second Annual Conference on Communication
  Networks and Services Research, 2004.}, pp.\  305--314, 2004.
\newblock \doi{10.1109/DNSR.2004.1344743}.

\bibitem[Xue et~al.(2022)Xue, Wang, Yuan, Guan, Qian, and Yu]{Xue2022Heter}
Xue, K., Wang, Y., Yuan, L., Guan, C., Qian, C., and Yu, Y.
\newblock Heterogeneous multi-agent zero-shot coordination by coevolution.
\newblock \emph{arXiv preprint arXiv:2208.04957}, 2022.

\bibitem[Yang et~al.(2021)Yang, Luo, Wen, Slumbers, Graves, Bou~Ammar, Wang,
  and Taylor]{yaodong_diverse}
Yang, Y., Luo, J., Wen, Y., Slumbers, O., Graves, D., Bou~Ammar, H., Wang, J.,
  and Taylor, M.~E.
\newblock Diverse auto-curriculum is critical for successful real-world
  multiagent learning systems.
\newblock In \emph{Proceedings of the 20th International Conference on
  Autonomous Agents and MultiAgent Systems}, AAMAS '21, pp.\  51–56,
  Richland, SC, 2021.

\bibitem[Zhao et~al.(2021)Zhao, Song, Haifeng, Gao, Wu, Sun, and Wei]{MEP}
Zhao, R., Song, J., Haifeng, H., Gao, Y., Wu, Y., Sun, Z., and Wei, Y.
\newblock Maximum entropy population based training for zero-shot human-ai
  coordination.
\newblock \emph{arXiv preprint arXiv:2112.11701}, 2021.

\end{thebibliography}
