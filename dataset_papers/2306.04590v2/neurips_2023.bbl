\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ali et~al.(2021)Ali, Touvron, Caron, Bojanowski, Douze, Joulin, Laptev, Neverova, Synnaeve, Verbeek, et~al.]{ali2021xcit}
Alaaeldin Ali, Hugo Touvron, Mathilde Caron, Piotr Bojanowski, Matthijs Douze, Armand Joulin, Ivan Laptev, Natalia Neverova, Gabriel Synnaeve, Jakob Verbeek, et~al.
\newblock Xcit: Cross-covariance image transformers.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 20014--20027, 2021.

\bibitem[Bao et~al.(2022)Bao, Dong, Piao, and Wei]{bao2022beit}
Hangbo Bao, Li~Dong, Songhao Piao, and Furu Wei.
\newblock Beit: Bert pre-training of image transformers, 2022.

\bibitem[Beery et~al.(2021)Beery, Agarwal, Cole, and Birodkar]{beery2021iwildcam}
Sara Beery, Arushi Agarwal, Elijah Cole, and Vighnesh Birodkar.
\newblock The iwildcam 2021 competition dataset.
\newblock \emph{arXiv preprint arXiv:2105.03494}, 2021.

\bibitem[Bonferroni(1936)]{bonferroni1936teoria}
Carlo Bonferroni.
\newblock Teoria statistica delle classi e calcolo delle probabilita.
\newblock \emph{Pubblicazioni del R Istituto Superiore di Scienze Economiche e Commericiali di Firenze}, 8:\penalty0 3--62, 1936.

\bibitem[Brier et~al.(1950)]{brierscore}
Glenn~W Brier et~al.
\newblock Verification of forecasts expressed in terms of probability.
\newblock \emph{Monthly weather review}, 78\penalty0 (1):\penalty0 1--3, 1950.

\bibitem[Caruana et~al.(2015)Caruana, Lou, Gehrke, Koch, Sturm, and Elhadad]{caruana2015intelligible}
Rich Caruana, Yin Lou, Johannes Gehrke, Paul Koch, Marc Sturm, and Noemie Elhadad.
\newblock Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission.
\newblock In \emph{Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining}, pages 1721--1730, 2015.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei]{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern recognition}, pages 248--255. Ieee, 2009.

\bibitem[Dosovitskiy et~al.(2020)Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly, et~al.]{vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020.

\bibitem[Elfanagely et~al.(2021)Elfanagely, Toyoda, Othman, Mellia, Basta, Liu, Kording, Ungar, and Fischer]{elfanagely2021machine}
Omar Elfanagely, Yoshiko Toyoda, Sammy Othman, Joseph~A Mellia, Marten Basta, Tony Liu, Konrad Kording, Lyle Ungar, and John~P Fischer.
\newblock Machine learning and surgical outcomes prediction: a systematic review.
\newblock \emph{Journal of Surgical Research}, 264:\penalty0 346--361, 2021.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017calibration}
Chuan Guo, Geoff Pleiss, Yu~Sun, and Kilian~Q Weinberger.
\newblock On calibration of modern neural networks.
\newblock In \emph{International conference on machine learning}, pages 1321--1330. PMLR, 2017.

\bibitem[Guo et~al.(2022)Guo, Lee, Kassamali, Mita, and Nambudiri]{guo2022bias}
Lisa~N Guo, Michelle~S Lee, Bina Kassamali, Carol Mita, and Vinod~E Nambudiri.
\newblock Bias in, bias out: underreporting and underrepresentation of diverse skin types in machine learning research for skin cancer detectionâ€”a scoping review.
\newblock \emph{Journal of the American Academy of Dermatology}, 87\penalty0 (1):\penalty0 157--159, 2022.

\bibitem[He et~al.(2015)He, Zhang, Ren, and Sun]{ResNet50}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock \emph{CoRR}, abs/1512.03385, 2015.
\newblock URL \url{http://arxiv.org/abs/1512.03385}.

\bibitem[Hebert-Johnson et~al.(2018)Hebert-Johnson, Kim, Reingold, and Rothblum]{hebert2018multi}
Ursula Hebert-Johnson, Michael Kim, Omer Reingold, and Guy Rothblum.
\newblock Multicalibration: Calibration for the ({C}omputationally-identifiable) masses.
\newblock In Jennifer Dy and Andreas Krause, editors, \emph{Proceedings of the 35th International Conference on Machine Learning}, volume~80 of \emph{Proceedings of Machine Learning Research}, pages 1939--1948. PMLR, 10--15 Jul 2018.

\bibitem[Hendrycks and Dietterich(2019)]{imagenetc}
Dan Hendrycks and Thomas Dietterich.
\newblock Benchmarking neural network robustness to common corruptions and perturbations.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=HJz6tiCqYm}.

\bibitem[Hendrycks and Gimpel(2016)]{hendrycks2016baseline}
Dan Hendrycks and Kevin Gimpel.
\newblock A baseline for detecting misclassified and out-of-distribution examples in neural networks.
\newblock \emph{arXiv preprint arXiv:1610.02136}, 2016.

\bibitem[Jiang et~al.(2018)Jiang, Kim, Guan, and Gupta]{jiang2018trust}
Heinrich Jiang, Been Kim, Melody Guan, and Maya Gupta.
\newblock To trust or not to trust a classifier.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Johnson et~al.(2019)Johnson, Douze, and J{\'e}gou]{faiss}
Jeff Johnson, Matthijs Douze, and Herv{\'e} J{\'e}gou.
\newblock Billion-scale similarity search with {GPUs}.
\newblock \emph{IEEE Transactions on Big Data}, 7\penalty0 (3):\penalty0 535--547, 2019.

\bibitem[Kang et~al.(2019)Kang, Xie, Rohrbach, Yan, Gordo, Feng, and Kalantidis]{cRT}
Bingyi Kang, Saining Xie, Marcus Rohrbach, Zhicheng Yan, Albert Gordo, Jiashi Feng, and Yannis Kalantidis.
\newblock Decoupling representation and classifier for long-tailed recognition.
\newblock \emph{arXiv preprint arXiv:1910.09217}, 2019.

\bibitem[Kleinberg et~al.(2016)Kleinberg, Mullainathan, and Raghavan]{kleinberg2016inherent}
Jon~M. Kleinberg, Sendhil Mullainathan, and Manish Raghavan.
\newblock Inherent trade-offs in the fair determination of risk scores.
\newblock In \emph{Information Technology Convergence and Services}, 2016.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:12845273}.

\bibitem[Kuleshov and Deshpande(2022)]{kuleshov2022calibrated}
Volodymyr Kuleshov and Shachi Deshpande.
\newblock Calibrated and sharp uncertainties in deep learning via density estimation.
\newblock In \emph{International Conference on Machine Learning}, pages 11683--11693. PMLR, 2022.

\bibitem[Kull et~al.(2019)Kull, Perello~Nieto, K\"{a}ngsepp, Silva~Filho, Song, and Flach]{wallach2019beyond}
Meelis Kull, Miquel Perello~Nieto, Markus K\"{a}ngsepp, Telmo Silva~Filho, Hao Song, and Peter Flach.
\newblock Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with dirichlet calibration.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, \emph{Advances in Neural Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.

\bibitem[Lam and Longnecker(1983)]{lam1983modified}
FC~Lam and MT~Longnecker.
\newblock A modified wilcoxon rank sum test for paired data.
\newblock \emph{Biometrika}, 70\penalty0 (2):\penalty0 510--513, 1983.

\bibitem[Lin et~al.(2022)Lin, Trivedi, and Sun]{lin2022taking}
Zhen Lin, Shubhendu Trivedi, and Jimeng Sun.
\newblock Taking a step back with kcal: Multi-class kernel-based calibration for deep neural networks.
\newblock \emph{arXiv preprint arXiv:2202.07679}, 2022.

\bibitem[Liu et~al.(2019{\natexlab{a}})Liu, Ott, Goyal, Du, Joshi, Chen, Levy, Lewis, Zettlemoyer, and Stoyanov]{liu2019roberta}
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.
\newblock Roberta: A robustly optimized bert pretraining approach, 2019{\natexlab{a}}.

\bibitem[Liu et~al.(2019{\natexlab{b}})Liu, Miao, Zhan, Wang, Gong, and Yu]{liu2019large}
Ziwei Liu, Zhongqi Miao, Xiaohang Zhan, Jiayun Wang, Boqing Gong, and Stella~X Yu.
\newblock Large-scale long-tailed recognition in an open world.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 2537--2546, 2019{\natexlab{b}}.

\bibitem[Minderer et~al.(2021)Minderer, Djolonga, Romijnders, Hubis, Zhai, Houlsby, Tran, and Lucic]{minderer2021revisit}
Matthias Minderer, Josip Djolonga, Rob Romijnders, Frances Hubis, Xiaohua Zhai, Neil Houlsby, Dustin Tran, and Mario Lucic.
\newblock Revisiting the calibration of modern neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, volume~34, pages 15682--15694, 2021.

\bibitem[Nixon et~al.(2019)Nixon, Dusenberry, Zhang, Jerfel, and Tran]{nixon2019measuring}
Jeremy Nixon, Michael~W Dusenberry, Linchuan Zhang, Ghassen Jerfel, and Dustin Tran.
\newblock Measuring calibration in deep learning.
\newblock In \emph{CVPR Workshops}, volume~2, 2019.

\bibitem[Obermeyer et~al.(2019)Obermeyer, Powers, Vogeli, and Mullainathan]{obermeyer2019dissecting}
Ziad Obermeyer, Brian Powers, Christine Vogeli, and Sendhil Mullainathan.
\newblock Dissecting racial bias in an algorithm used to manage the health of populations.
\newblock \emph{Science}, 366\penalty0 (6464):\penalty0 447--453, 2019.

\bibitem[Parzen(1962)]{parzen1962estimation}
Emanuel Parzen.
\newblock On estimation of a probability density function and mode.
\newblock \emph{The annals of mathematical statistics}, 33\penalty0 (3):\penalty0 1065--1076, 1962.

\bibitem[Patel et~al.(2020)Patel, Beluch, Yang, Pfeiffer, and Zhang]{patel2020multi}
Kanil Patel, William Beluch, Bin Yang, Michael Pfeiffer, and Dan Zhang.
\newblock Multi-class uncertainty calibration via mutual information maximization-based binning.
\newblock \emph{arXiv preprint arXiv:2006.13092}, 2020.

\bibitem[Perez-Lebel et~al.(2023)Perez-Lebel, Morvan, and Varoquaux]{perezlebel2023calibration}
Alexandre Perez-Lebel, Marine~Le Morvan, and GaÃ«l Varoquaux.
\newblock Beyond calibration: estimating the grouping loss of modern neural networks.
\newblock In \emph{ICLR}, 2023.

\bibitem[Rafiee and Abbasi(2019)]{rafiee2019pruned}
M~Rafiee and M~Abbasi.
\newblock Pruned kd-tree: a memory-efficient algorithm for multi-field packet classification.
\newblock \emph{SN Applied Sciences}, 1\penalty0 (12):\penalty0 1537, 2019.

\bibitem[Rajkomar et~al.(2018)Rajkomar, Hardt, Howell, Corrado, and Chin]{rajkomar2018ensuring}
Alvin Rajkomar, Michaela Hardt, Michael~D Howell, Greg Corrado, and Marshall~H Chin.
\newblock Ensuring fairness in machine learning to advance health equity.
\newblock \emph{Annals of internal medicine}, 169\penalty0 (12):\penalty0 866--872, 2018.

\bibitem[Sendak et~al.(2020)Sendak, Elish, Gao, Futoma, Ratliff, Nichols, Bedoya, Balu, and O'Brien]{sendak2020human}
Mark Sendak, Madeleine~Clare Elish, Michael Gao, Joseph Futoma, William Ratliff, Marshall Nichols, Armando Bedoya, Suresh Balu, and Cara O'Brien.
\newblock The human body is a black box supporting clinical decision-making with deep learning.
\newblock In \emph{Proceedings of the 2020 conference on fairness, accountability, and transparency}, pages 99--109, 2020.

\bibitem[Taylor(2009-)]{statsmodels}
Jonathan Taylor.
\newblock {statsmodels: Statistical modeling and econometrics in Python}, 2009-.
\newblock URL \url{https://www.statsmodels.org}.

\bibitem[Tolstikhin et~al.(2021)Tolstikhin, Houlsby, Kolesnikov, Beyer, Zhai, Unterthiner, Yung, Keysers, Uszkoreit, Lucic, and Dosovitskiy]{mlp-mixer}
Ilya Tolstikhin, Neil Houlsby, Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, Thomas Unterthiner, Jessica Yung, Daniel Keysers, Jakob Uszkoreit, Mario Lucic, and Alexey Dosovitskiy.
\newblock Mlp-mixer: An all-mlp architecture for vision.
\newblock \emph{arXiv preprint arXiv:2105.01601}, 2021.

\bibitem[Tomani et~al.(2022)Tomani, Cremers, and Buettner]{tomani2022parameterized}
Christian Tomani, Daniel Cremers, and Florian Buettner.
\newblock Parameterized temperature scaling for boosting the expressive power in post-hoc uncertainty calibration.
\newblock In \emph{Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XIII}, pages 555--569. Springer, 2022.

\bibitem[Touvron et~al.(2021)Touvron, Cord, Douze, Massa, Sablayrolles, and Jegou]{deit}
Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, and Herve Jegou.
\newblock Training data-efficient image transformers and distillation through attention.
\newblock In \emph{International Conference on Machine Learning}, volume 139, pages 10347--10357, July 2021.

\bibitem[Van~Horn et~al.(2021)Van~Horn, Cole, Beery, Wilber, Belongie, and Mac~Aodha]{van2021benchmarking}
Grant Van~Horn, Elijah Cole, Sara Beery, Kimberly Wilber, Serge Belongie, and Oisin Mac~Aodha.
\newblock Benchmarking representation learning for natural world image collections.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 12884--12893, 2021.

\bibitem[Wang et~al.(2019)Wang, Ge, Lipton, and Xing]{imagenet-sketch}
Haohan Wang, Songwei Ge, Zachary Lipton, and Eric~P Xing.
\newblock Learning robust global representations by penalizing local predictive power.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages 10506--10518, 2019.

\bibitem[Wightman(2019)]{rw2019timm}
Ross Wightman.
\newblock Pytorch image models.
\newblock \url{https://github.com/rwightman/pytorch-image-models}, 2019.

\bibitem[Williams et~al.(2017)Williams, Nangia, and Bowman]{mnli}
Adina Williams, Nikita Nangia, and Samuel~R Bowman.
\newblock A broad-coverage challenge corpus for sentence understanding through inference.
\newblock \emph{arXiv preprint arXiv:1704.05426}, 2017.

\bibitem[Xiong et~al.(2022)Xiong, Li, Feng, Deng, Zhang, and Hooi]{xiong2022birds}
Miao Xiong, Shen Li, Wenjie Feng, Ailin Deng, Jihai Zhang, and Bryan Hooi.
\newblock Birds of a feather trust together: Knowing when to trust a classifier via adaptive neighborhood aggregation.
\newblock \emph{Transactions on Machine Learning Research}, 2022.
\newblock ISSN 2835-8856.
\newblock URL \url{https://openreview.net/forum?id=p5V8P2J61u}.

\bibitem[Zadrozny and Elkan(2001)]{zadrozny2001obtaining}
Bianca Zadrozny and Charles Elkan.
\newblock Obtaining calibrated probability estimates from decision trees and naive bayesian classifiers.
\newblock In \emph{International conference on machine learning}, volume~1, pages 609--616, 2001.

\bibitem[Zadrozny and Elkan(2002)]{zadrozny2002transforming}
Bianca Zadrozny and Charles Elkan.
\newblock Transforming classifier scores into accurate multiclass probability estimates.
\newblock In \emph{Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining}, pages 694--699, 2002.

\bibitem[Zhang et~al.(2020)Zhang, Kailkhura, and Han]{zhang2020mix}
Jize Zhang, Bhavya Kailkhura, and T~Yong-Jin Han.
\newblock Mix-n-match: Ensemble and compositional methods for uncertainty calibration in deep learning.
\newblock In \emph{International conference on machine learning}, pages 11117--11128. PMLR, 2020.

\bibitem[Zhang et~al.(2015)Zhang, Zhao, and LeCun]{yahoo}
Xiang Zhang, Junbo Zhao, and Yann LeCun.
\newblock Character-level convolutional networks for text classification.
\newblock \emph{Advances in neural information processing systems}, 28, 2015.

\end{thebibliography}
