% references Kushal is adding (also put in Zotero)

@article{wei2022chain,
  title={Chain of thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Chi, Ed and Le, Quoc and Zhou, Denny},
  journal={arXiv preprint arXiv:2201.11903},
  year={2022}
}

@inproceedings{fleischman2005verbs,
  title={Why verbs are harder to learn than nouns: Initial insights from a computational model of intention recognition in situated word learning},
  author={Fleischman, Michael and Roy, Deb},
  booktitle={27th Annual Meeting of the Cognitive Science Society, Stresa, Italy},
  year={2005}
}

@unpublished{spacy3,
    AUTHOR = {Honnibal, Matthew and Montani, Ines},
    TITLE  = {{spaCy 3}: Natural language understanding with {B}loom embeddings, convolutional neural networks and incremental parsing},
    YEAR   = {2022},
    Note   = {To appear}
}

@article{karpicke2007expanding,
  title={Expanding retrieval practice promotes short-term retention, but equally spaced retrieval enhances long-term retention.},
  author={Karpicke, Jeffrey D and Roediger III, Henry L},
  journal={Journal of experimental psychology: learning, memory, and cognition},
  volume={33},
  number={4},
  pages={704},
  year={2007},
  publisher={American Psychological Association}
}

@article{oren2014effects,
  title={Effects of Spaced Retrieval Training on Semantic Memory in Alzheimer's Disease: A Systematic Review},
  author={Oren, Shiri and Willerton, Charlene and Small, Jeff},
  journal={Journal of Speech, Language and Hearing Research (Online)},
  volume={57},
  number={1},
  pages={247},
  year={2014},
  publisher={American Speech-Language-Hearing Association}
}

@article{smolen2016right,
  title={The right time to learn: mechanisms and optimization of spaced learning},
  author={Smolen, Paul and Zhang, Yili and Byrne, John H},
  journal={Nature Reviews Neuroscience},
  volume={17},
  number={2},
  pages={77--88},
  year={2016},
  publisher={Nature Publishing Group}
}

% deepmind retro paper
@article{borgeaud2021improving,
  title={Improving language models by retrieving from trillions of tokens},
  author={Borgeaud, Sebastian and Mensch, Arthur and Hoffmann, Jordan and Cai, Trevor and Rutherford, Eliza and Millican, Katie and Driessche, George van den and Lespiau, Jean-Baptiste and Damoc, Bogdan and Clark, Aidan and others},
  journal={arXiv preprint arXiv:2112.04426},
  year={2021}
}

% differentiable search index
@article{tay2022transformer,
  title={Transformer memory as a differentiable search index},
  author={Tay, Yi and Tran, Vinh Q and Dehghani, Mostafa and Ni, Jianmo and Bahri, Dara and Mehta, Harsh and Qin, Zhen and Hui, Kai and Zhao, Zhe and Gupta, Jai and others},
  journal={arXiv preprint arXiv:2202.06991},
  year={2022}
}

% generalization through memorizaiton
@article{khandelwal2019generalization,
  title={Generalization through memorization: Nearest neighbor language models},
  author={Khandelwal, Urvashi and Levy, Omer and Jurafsky, Dan and Zettlemoyer, Luke and Lewis, Mike},
  journal={arXiv preprint arXiv:1911.00172},
  year={2019}
}

% language models as knowledge bases
@article{guu2020realm,
  title={Realm: Retrieval-augmented language model pre-training},
  author={Guu, Kelvin and Lee, Kenton and Tung, Zora and Pasupat, Panupong and Chang, Ming-Wei},
  journal={arXiv preprint arXiv:2002.08909},
  year={2020}
}
@article{petroni2019language,
  title={Language models as knowledge bases?},
  author={Petroni, Fabio and Rockt{\"a}schel, Tim and Lewis, Patrick and Bakhtin, Anton and Wu, Yuxiang and Miller, Alexander H and Riedel, Sebastian},
  journal={arXiv preprint arXiv:1909.01066},
  year={2019}
}

@article{alkhamissi2022review,
  title={A Review on Language Models as Knowledge Bases},
  author={AlKhamissi, Badr and Li, Millicent and Celikyilmaz, Asli and Diab, Mona and Ghazvininejad, Marjan},
  journal={arXiv preprint arXiv:2204.06031},
  year={2022}
}

% mitigating memorization attacks

@article{thakkar2020understanding,
  title={Understanding unintended memorization in federated learning},
  author={Thakkar, Om and Ramaswamy, Swaroop and Mathews, Rajiv and Beaufays, Fran{\c{c}}oise},
  journal={arXiv preprint arXiv:2006.07490},
  year={2020}
}

@article{li2021large,
  title={Large language models can be strong differentially private learners},
  author={Li, Xuechen and Tramer, Florian and Liang, Percy and Hashimoto, Tatsunori},
  journal={arXiv preprint arXiv:2110.05679},
  year={2021}
}

% membership inference attack

@article{mireshghallah2022quantifying,
  title={Quantifying Privacy Risks of Masked Language Models Using Membership Inference Attacks},
  author={Mireshghallah, Fatemehsadat and Goyal, Kartik and Uniyal, Archit and Berg-Kirkpatrick, Taylor and Shokri, Reza},
  journal={arXiv preprint arXiv:2203.03929},
  year={2022}
}

@article{hisamoto2019membership,
  title={Membership inference attacks on sequence-to-sequence models},
  author={Hisamoto, Sorami and Post, Matt and Duh, Kevin},
  journal={arXiv preprint arXiv:1904.05506},
  year={2019}
}
% -------------------------------




% extraction attack ----
@inproceedings{thomas2020investigating,
  title={Investigating the impact of pre-trained word embeddings on memorization in neural networks},
  author={Thomas, Aleena and Adelani, David Ifeoluwa and Davody, Ali and Mogadala, Aditya and Klakow, Dietrich},
  booktitle={International Conference on Text, Speech, and Dialogue},
  pages={273--281},
  year={2020},
  organization={Springer}
}

@inproceedings{carlini2019secret,
  title={The secret sharer: Evaluating and testing unintended memorization in neural networks},
  author={Carlini, Nicholas and Liu, Chang and Erlingsson, {\'U}lfar and Kos, Jernej and Song, Dawn},
  booktitle={28th USENIX Security Symposium (USENIX Security 19)},
  pages={267--284},
  year={2019}
}

% -------------------------

% conclusion references -----
@inproceedings{dwork2006calibrating,
  title={Calibrating noise to sensitivity in private data analysis},
  author={Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam},
  booktitle={Theory of cryptography conference},
  pages={265--284},
  year={2006},
  organization={Springer}
}

@article{gehman2020realtoxicityprompts,
  title={Realtoxicityprompts: Evaluating neural toxic degeneration in language models},
  author={Gehman, Samuel and Gururangan, Suchin and Sap, Maarten and Choi, Yejin and Smith, Noah A},
  journal={arXiv preprint arXiv:2009.11462},
  year={2020}
}


% -----------------------------

% intro references ----------

@inproceedings{song2019auditing,
  title={Auditing data provenance in text-generation models},
  author={Song, Congzheng and Shmatikov, Vitaly},
  booktitle={Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={196--206},
  year={2019}
}

@article{franklin2005elements,
  title={The elements of statistical learning: data mining, inference and prediction},
  author={Franklin, James},
  journal={The Mathematical Intelligencer},
  volume={27},
  number={2},
  pages={83--85},
  year={2005},
  publisher={Springer}
}

@inproceedings{brown2021memorization,
  title={When is memorization of irrelevant training data necessary for high-accuracy learning?},
  author={Brown, Gavin and Bun, Mark and Feldman, Vitaly and Smith, Adam and Talwar, Kunal},
  booktitle={Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing},
  pages={123--132},
  year={2021}
}

@article{feldman2019does,
  title={Does learning require memorization},
  author={Feldman, Vitaly},
  journal={A short tale about a long tail. CoRR, abs/1906.05271},
  year={2019}
}

@article{feldman2020neural,
  title={What neural networks memorize and why: Discovering the long tail via influence estimation},
  author={Feldman, Vitaly and Zhang, Chiyuan},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={2881--2891},
  year={2020}
}

@article{linial1991results,
  title={Results on learnability and the Vapnik-Chervonenkis dimension},
  author={Linial, Nathan and Mansour, Yishay and Rivest, Ronald L},
  journal={Information and Computation},
  volume={90},
  number={1},
  pages={33--49},
  year={1991},
  publisher={Elsevier}
}

@article{mcallester1999some,
  title={Some pac-bayesian theorems},
  author={McAllester, David A},
  journal={Machine Learning},
  volume={37},
  number={3},
  pages={355--363},
  year={1999},
  publisher={Springer}
}

@article{lee2021deduplicating,
  title={Deduplicating training data makes language models better},
  author={Lee, Katherine and Ippolito, Daphne and Nystrom, Andrew and Zhang, Chiyuan and Eck, Douglas and Callison-Burch, Chris and Carlini, Nicholas},
  journal={arXiv preprint arXiv:2107.06499},
  year={2021}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}

@article{aghajanyan2022cm3,
  title={CM3: A Causal Masked Multimodal Model of the Internet},
  author={Aghajanyan, Armen and Huang, Bernie and Ross, Candace and Karpukhin, Vladimir and Xu, Hu and Goyal, Naman and Okhonko, Dmytro and Joshi, Mandar and Ghosh, Gargi and Lewis, Mike and others},
  journal={arXiv preprint arXiv:2201.07520},
  year={2022}
}

@article{nakkiran2021deep,
  title={Deep double descent: Where bigger models and more data hurt},
  author={Nakkiran, Preetum and Kaplun, Gal and Bansal, Yamini and Yang, Tristan and Barak, Boaz and Sutskever, Ilya},
  journal={Journal of Statistical Mechanics: Theory and Experiment},
  volume={2021},
  number={12},
  pages={124003},
  year={2021},
  publisher={IOP Publishing}
}

% -----------------------

@article{loftus1985evaluating,
  title={Evaluating forgetting curves.},
  author={Loftus, Geoffrey R},
  journal={Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume={11},
  number={2},
  pages={397},
  year={1985},
  publisher={American Psychological Association}
}

@article{mantelero2013eu,
  title={The EU Proposal for a General Data Protection Regulation and the roots of the ‘right to be forgotten’},
  author={Mantelero, Alessandro},
  journal={Computer Law \& Security Review},
  volume={29},
  number={3},
  pages={229--235},
  year={2013},
  publisher={Elsevier}
}

@article{harding2019understanding,
  title={Understanding the scope and impact of the California Consumer Privacy Act of 2018},
  author={Harding, Elizabeth Liz and Vanto, Jarno J and Clark, Reece and Hannah Ji, L and Ainsworth, Sara C},
  journal={Journal of Data Protection \& Privacy},
  volume={2},
  number={3},
  pages={234--253},
  year={2019},
  publisher={Henry Stewart Publications}
}

@article{voigt2017eu,
  title={The eu general data protection regulation (gdpr)},
  author={Voigt, Paul and Von dem Bussche, Axel},
  journal={A Practical Guide, 1st Ed., Cham: Springer International Publishing},
  volume={10},
  number={3152676},
  pages={10--5555},
  year={2017},
  publisher={Springer}
}

@article{regulation2018general,
  title={General data protection regulation (GDPR)},
  author={Regulation, General Data Protection},
  journal={Intersoft Consulting, Accessed in October},
  volume={24},
  number={1},
  year={2018}
}

@inproceedings{bourtoule2021machine,
  title={Machine unlearning},
  author={Bourtoule, Lucas and Chandrasekaran, Varun and Choquette-Choo, Christopher A and Jia, Hengrui and Travers, Adelin and Zhang, Baiwu and Lie, David and Papernot, Nicolas},
  booktitle={2021 IEEE Symposium on Security and Privacy (SP)},
  pages={141--159},
  year={2021},
  organization={IEEE}
}

@article{liu2020learn,
  title={Learn to Forget: Machine Unlearning via Neuron Masking},
  author={Liu, Yang and Ma, Zhuo and Liu, Ximeng and Liu, Jian and Jiang, Zhongyuan and Ma, Jianfeng and Yu, Philip and Ren, Kui},
  journal={arXiv preprint arXiv:2003.10933},
  year={2020}
}

@article{ji2022survey,
  title={Survey of Hallucination in Natural Language Generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Yejin and Madotto, Andrea and Fung, Pascale},
  journal={arXiv preprint arXiv:2202.03629},
  year={2022}
}

@incollection{mccloskey1989catastrophic,
  title={Catastrophic interference in connectionist networks: The sequential learning problem},
  author={McCloskey, Michael and Cohen, Neal J},
  booktitle={Psychology of learning and motivation},
  volume={24},
  pages={109--165},
  year={1989},
  publisher={Elsevier}
}

@ARTICLE{Ratcliff90connectionistmodels,
    author = {Roger Ratcliff},
    title = {Connectionist models of recognition memory: Constraints imposed by learning and forgetting functions},
    journal = {Psychological Review},
    year = {1990},
    pages = {285--308}
}
  
@article{chen2018lifelong,
  title={Lifelong machine learning},
  author={Chen, Zhiyuan and Liu, Bing},
  journal={Synthesis Lectures on Artificial Intelligence and Machine Learning},
  volume={12},
  number={3},
  pages={1--207},
  year={2018},
  publisher={Morgan \& Claypool Publishers}
}
  
 @article{chen2020recall,
  title={Recall and learn: Fine-tuning deep pretrained language models with less forgetting},
  author={Chen, Sanyuan and Hou, Yutai and Cui, Yiming and Che, Wanxiang and Liu, Ting and Yu, Xiangzhan},
  journal={arXiv preprint arXiv:2004.12651},
  year={2020}
}

@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the national academy of sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Acad Sciences}
}

@article{delange2021continual,
  title={A continual learning survey: Defying forgetting in classification tasks},
  author={Delange, Matthias and Aljundi, Rahaf and Masana, Marc and Parisot, Sarah and Jia, Xu and Leonardis, Ales and Slabaugh, Greg and Tuytelaars, Tinne},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2021},
  publisher={IEEE}
}

@inproceedings{masarczyk2021robustness,
  title={On robustness of generative representations against catastrophic forgetting},
  author={Masarczyk, Wojciech and Deja, Kamil and Trzcinski, Tomasz},
  booktitle={International Conference on Neural Information Processing},
  pages={325--333},
  year={2021},
  organization={Springer}
}

@article{shao2022overcoming,
  title={Overcoming Catastrophic Forgetting beyond Continual Learning: Balanced Training for Neural Machine Translation},
  author={Shao, Chenze and Feng, Yang},
  journal={arXiv preprint arXiv:2203.03910},
  year={2022}
}

@article{mirzadeh2021wide,
  title={Wide Neural Networks Forget Less Catastrophically},
  author={Mirzadeh, Seyed Iman and Chaudhry, Arslan and Hu, Huiyi and Pascanu, Razvan and Gorur, Dilan and Farajtabar, Mehrdad},
  journal={arXiv preprint arXiv:2110.11526},
  year={2021}
}

@inproceedings{ramasesh2021effect,
  title={Effect of scale on catastrophic forgetting in neural networks},
  author={Ramasesh, Vinay Venkatesh and Lewkowycz, Aitor and Dyer, Ethan},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{li2020train,
  title={Train big, then compress: Rethinking model size for efficient training and inference of transformers},
  author={Li, Zhuohan and Wallace, Eric and Shen, Sheng and Lin, Kevin and Keutzer, Kurt and Klein, Dan and Gonzalez, Joey},
  booktitle={International Conference on Machine Learning},
  pages={5958--5968},
  year={2020},
  organization={PMLR}
}

@article{Merity2017PointerSM,
  title={Pointer Sentinel Mixture Models},
  author={Stephen Merity and Caiming Xiong and James Bradbury and Richard Socher},
  journal={ArXiv},
  year={2017},
  volume={abs/1609.07843}
}

@inproceedings{ccnews2020,
 title = {CC-News-En: A Large English News Corpus},
 author = {J. Mackenzie and R. Benham and M. Petri and J. R. Trippas and J. S. Culpepper and A. Moffat},
 booktitle = {Proc. CIKM},
 pages = {3077--3084},
 year = {2020},
}


@article{henighan2020scaling,
  title={Scaling laws for autoregressive generative modeling},
  author={Henighan, Tom and Kaplan, Jared and Katz, Mor and Chen, Mark and Hesse, Christopher and Jackson, Jacob and Jun, Heewoo and Brown, Tom B and Dhariwal, Prafulla and Gray, Scott and others},
  journal={arXiv preprint arXiv:2010.14701},
  year={2020}
}

@article{clark2022unified,
  title={Unified Scaling Laws for Routed Language Models},
  author={Clark, Aidan and Casas, Diego de las and Guy, Aurelia and Mensch, Arthur and Paganini, Michela and Hoffmann, Jordan and Damoc, Bogdan and Hechtman, Blake and Cai, Trevor and Borgeaud, Sebastian and others},
  journal={arXiv preprint arXiv:2202.01169},
  year={2022}
}

@article{hernandez2021scaling,
  title={Scaling laws for transfer},
  author={Hernandez, Danny and Kaplan, Jared and Henighan, Tom and McCandlish, Sam},
  journal={arXiv preprint arXiv:2102.01293},
  year={2021}
}

@article{rosenfeld2019constructive,
  title={A constructive prediction of the generalization error across scales},
  author={Rosenfeld, Jonathan S and Rosenfeld, Amir and Belinkov, Yonatan and Shavit, Nir},
  journal={arXiv preprint arXiv:1909.12673},
  year={2019}
}

@inproceedings{tan2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International conference on machine learning},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}

@inproceedings{banko2001mitigating,
  title={Mitigating the paucity-of-data problem: Exploring the effect of training corpus size on classifier performance for natural language processing},
  author={Banko, Michele and Brill, Eric},
  booktitle={Proceedings of the first international conference on Human language technology research},
  year={2001}
}

@article{goodman2001bit,
  title={A bit of progress in language modeling},
  author={Goodman, Joshua T},
  journal={Computer Speech \& Language},
  volume={15},
  number={4},
  pages={403--434},
  year={2001},
  publisher={Elsevier}
}

@inproceedings{banko2001scaling,
  title={Scaling to very very large corpora for natural language disambiguation},
  author={Banko, Michele and Brill, Eric},
  booktitle={Proceedings of the 39th annual meeting of the Association for Computational Linguistics},
  pages={26--33},
  year={2001}
}

@article{kharitonov2021bpe,
  title={How bpe affects memorization in transformers},
  author={Kharitonov, Eugene and Baroni, Marco and Hupkes, Dieuwke},
  journal={arXiv preprint arXiv:2110.02782},
  year={2021}
}
@article{chowdhery2022palm,
  title={PaLM: Scaling Language Modeling with Pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{rae2021scaling,
  title={Scaling language models: Methods, analysis \& insights from training gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
  journal={arXiv preprint arXiv:2112.11446},
  year={2021}
}

@article{smith2022using,
  title={Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model},
  author={Smith, Shaden and Patwary, Mostofa and Norick, Brandon and LeGresley, Patrick and Rajbhandari, Samyam and Casper, Jared and Liu, Zhun and Prabhumoye, Shrimai and Zerveas, George and Korthikanti, Vijay and others},
  journal={arXiv preprint arXiv:2201.11990},
  year={2022}
}

@article{bahri2021explaining,
  title={Explaining neural scaling laws},
  author={Bahri, Yasaman and Dyer, Ethan and Kaplan, Jared and Lee, Jaehoon and Sharma, Utkarsh},
  journal={arXiv preprint arXiv:2102.06701},
  year={2021}
}

@inproceedings{carlini2021extracting,
  title={Extracting training data from large language models},
  author={Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and others},
  booktitle={30th USENIX Security Symposium (USENIX Security 21)},
  pages={2633--2650},
  year={2021}
}

@article{carlini2022quantifying,
  title={Quantifying memorization across neural language models},
  author={Carlini, Nicholas and Ippolito, Daphne and Jagielski, Matthew and Lee, Katherine and Tramer, Florian and Zhang, Chiyuan},
  journal={arXiv preprint arXiv:2202.07646},
  year={2022}
}
% ---------------------------------------

% ---------------------------------------
@article{zhang_dive_nodate,
	title = {Dive into {Deep} {Learning}},
	language = {en},
	author = {Zhang, Aston and Lipton, Zachary C and Li, Mu and Smola, Alexander J},
	pages = {986},
}



@book{kim2018PhoenixProjectNovel,
	title = {The {Phoenix} {Project}: {A} {Novel} about {IT}, {DevOps}, and {Helping} {Your} {Business} {Win}},
	isbn = {978-1-942788-30-0},
	shorttitle = {The {Phoenix} {Project}},
	abstract = {***Over a half-million sold! And available now, the Wall Street Journal Bestselling sequel The Unicorn Project***“Every person involved in a failed IT project should be forced to read this book.”—TIM O'REILLY, Founder \& CEO of O'Reilly Media“The Phoenix Project is a must read for business and IT executives who are struggling with the growing complexity of IT.”—JIM WHITEHURST, President and CEO, Red Hat, Inc.Five years after this sleeper hit took on the world of IT and flipped it on it's head, the 5th Anniversary Edition of The Phoenix Project continues to guide IT in the DevOps revolution.In this newly updated and expanded edition of the bestselling The Phoenix Project, co-author Gene Kim includes a new afterword and a deeper delve into the Three Ways as described in The DevOps Handbook.Bill, an IT manager at Parts Unlimited, has been tasked with taking on a project critical to the future of the business, code named Phoenix Project. But the project is massively over budget and behind schedule. The CEO demands Bill must fix the mess in ninety days or else Bill's entire department will be outsourced.With the help of a prospective board member and his mysterious philosophy of The Three Ways, Bill starts to see that IT work has more in common with a manufacturing plant work than he ever imagined. With the clock ticking, Bill must organize work flow streamline interdepartmental communications, and effectively serve the other business functions at Parts Unlimited.In a fast-paced and entertaining style, three luminaries of the DevOps movement deliver a story that anyone who works in IT will recognize. Readers will not only learn how to improve their own IT organizations, they'll never view IT the same way again.“This book is a gripping read that captures brilliantly the dilemmas that face companies which depend on IT, and offers real-world solutions.”—JEZ HUMBLE, Co-author of Continuous Delivery, Lean Enterprise, Accelerate, and The DevOps Handbook},
	language = {en},
	publisher = {IT Revolution},
	author = {Kim, Gene and Behr, Kevin and Spafford, George},
	month = feb,
	year = {2018},
	keywords = {Business \& Economics / Industries / Computers \& Information Technology, Business \& Economics / Management, Business \& Economics / Production \& Operations Management},
}

@phdthesis{bastounis2018FundamentalComputationalBarriers,
	type = {{PhD} {Thesis}},
	title = {On fundamental computational barriers in the mathematics of information},
	school = {University of Cambridge},
	author = {Bastounis, Alexander James},
	year = {2018},
}

@article{smale1998MathematicalProblemsNext,
	title = {Mathematical {Problems} for the {Next} {Century}},
	language = {en},
	author = {Smale, Steve},
	year = {1998},
	pages = {29},
}

@article{neyshabur2015SearchRealInductive,
	title = {In {Search} of the {Real} {Inductive} {Bias}: {On} the {Role} of {Implicit} {Regularization} in {Deep} {Learning}},
	shorttitle = {In {Search} of the {Real} {Inductive} {Bias}},
	url = {http://arxiv.org/abs/1412.6614},
	abstract = {We present experiments demonstrating that some other form of capacity control, different from network size, plays a central role in learning multilayer feed-forward networks. We argue, partially through analogy to matrix factorization, that this is an inductive bias that can help shed light on deep learning.},
	urldate = {2022-02-13},
	journal = {arXiv:1412.6614 [cs, stat]},
	author = {Neyshabur, Behnam and Tomioka, Ryota and Srebro, Nathan},
	month = apr,
	year = {2015},
	note = {arXiv: 1412.6614},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{bartlett1998SampleComplexityPattern,
	title = {The sample complexity of pattern classification with neural networks: the size of the weights is more important than the size of the network},
	volume = {44},
	issn = {1557-9654},
	shorttitle = {The sample complexity of pattern classification with neural networks},
	doi = {10.1109/18.661502},
	abstract = {Sample complexity results from computational learning theory, when applied to neural network learning for pattern classification problems, suggest that for good generalization performance the number of training examples should grow at least linearly with the number of adjustable parameters in the network. Results in this paper show that if a large neural network is used for a pattern classification problem and the learning algorithm finds a network with small weights that has small squared error on the training patterns, then the generalization performance depends on the size of the weights rather than the number of weights. For example, consider a two-layer feedforward network of sigmoid units, in which the sum of the magnitudes of the weights associated with each unit is bounded by A and the input dimension is n. We show that the misclassification probability is no more than a certain error estimate (that is related to squared error on the training set) plus A/sup 3/ /spl radic/((log n)/m) (ignoring log A and log m factors), where m is the number of training patterns. This may explain the generalization performance of neural networks, particularly when the number of training examples is considerably smaller than the number of weights. It also supports heuristics (such as weight decay and early stopping) that attempt to keep the weights small during training. The proof techniques appear to be useful for the analysis of other pattern classifiers: when the input domain is a totally bounded metric space, we use the same approach to give upper bounds on misclassification probability for classifiers with decision boundaries that are far from the training examples.},
	number = {2},
	journal = {IEEE Transactions on Information Theory},
	author = {Bartlett, P.L.},
	month = mar,
	year = {1998},
	note = {Conference Name: IEEE Transactions on Information Theory},
	keywords = {Computer networks, Neural networks, Pattern analysis, Pattern classification, Pattern recognition, Probability distribution, Statistical learning, Training data, Upper bound, Virtual colonoscopy},
	pages = {525--536},
}

@article{mhaskar2016DeepVsShallow,
	title = {Deep vs. shallow networks : {An} approximation theory perspective},
	shorttitle = {Deep vs. shallow networks},
	url = {http://arxiv.org/abs/1608.03287},
	abstract = {The paper briefy reviews several recent results on hierarchical architectures for learning from examples, that may formally explain the conditions under which Deep Convolutional Neural Networks perform much better in function approximation problems than shallow, one-hidden layer architectures. The paper announces new results for a non-smooth activation function - the ReLU function - used in present-day neural networks, as well as for the Gaussian networks. We propose a new definition of relative dimension to encapsulate different notions of sparsity of a function class that can possibly be exploited by deep networks but not by shallow ones to drastically reduce the complexity required for approximation and learning.},
	urldate = {2022-02-13},
	journal = {arXiv:1608.03287 [cs, math]},
	author = {Mhaskar, Hrushikesh and Poggio, Tomaso},
	month = aug,
	year = {2016},
	note = {arXiv: 1608.03287},
	keywords = {Computer Science - Machine Learning, Mathematics - Functional Analysis},
}

@article{mhaskar1993ApproximationPropertiesMultilayered,
	title = {Approximation properties of a multilayered feedforward artificial neural network},
	volume = {1},
	number = {1},
	journal = {Advances in Computational Mathematics},
	author = {Mhaskar, Hrushikesh Narhar},
	year = {1993},
	note = {Publisher: Springer},
	pages = {61--80},
}

@article{cybenko1989ApproximationSuperpositionsSigmoidal,
	title = {Approximation by superpositions of a sigmoidal function},
	doi = {10.1007/BF02551274},
	abstract = {It is demonstrated that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube. In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks.},
	journal = {Math. Control. Signals Syst.},
	author = {Cybenko, G.},
	year = {1989},
}

@article{hardt2016TrainFasterGeneralize,
	title = {Train faster, generalize better: {Stability} of stochastic gradient descent},
	shorttitle = {Train faster, generalize better},
	url = {http://arxiv.org/abs/1509.01240},
	abstract = {We show that parametric models trained by a stochastic gradient method (SGM) with few iterations have vanishing generalization error. We prove our results by arguing that SGM is algorithmically stable in the sense of Bousquet and Elisseeff. Our analysis only employs elementary tools from convex and continuous optimization. We derive stability bounds for both convex and non-convex optimization under standard Lipschitz and smoothness assumptions. Applying our results to the convex case, we provide new insights for why multiple epochs of stochastic gradient methods generalize well in practice. In the non-convex case, we give a new interpretation of common practices in neural networks, and formally show that popular techniques for training large deep models are indeed stability-promoting. Our findings conceptually underscore the importance of reducing training time beyond its obvious benefit.},
	urldate = {2022-02-13},
	journal = {arXiv:1509.01240 [cs, math, stat]},
	author = {Hardt, Moritz and Recht, Benjamin and Singer, Yoram},
	month = feb,
	year = {2016},
	note = {arXiv: 1509.01240},
	keywords = {Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning},
}

@article{cohen2016ConvolutionalRectifierNetworks,
	title = {Convolutional {Rectifier} {Networks} as {Generalized} {Tensor} {Decompositions}},
	url = {http://arxiv.org/abs/1603.00162},
	abstract = {Convolutional rectifier networks, i.e. convolutional neural networks with rectified linear activation and max or average pooling, are the cornerstone of modern deep learning. However, despite their wide use and success, our theoretical understanding of the expressive properties that drive these networks is partial at best. On the other hand, we have a much firmer grasp of these issues in the world of arithmetic circuits. Specifically, it is known that convolutional arithmetic circuits possess the property of "complete depth efficiency", meaning that besides a negligible set, all functions that can be implemented by a deep network of polynomial size, require exponential size in order to be implemented (or even approximated) by a shallow network. In this paper we describe a construction based on generalized tensor decompositions, that transforms convolutional arithmetic circuits into convolutional rectifier networks. We then use mathematical tools available from the world of arithmetic circuits to prove new results. First, we show that convolutional rectifier networks are universal with max pooling but not with average pooling. Second, and more importantly, we show that depth efficiency is weaker with convolutional rectifier networks than it is with convolutional arithmetic circuits. This leads us to believe that developing effective methods for training convolutional arithmetic circuits, thereby fulfilling their expressive potential, may give rise to a deep learning architecture that is provably superior to convolutional rectifier networks but has so far been overlooked by practitioners.},
	urldate = {2022-02-13},
	journal = {arXiv:1603.00162 [cs]},
	author = {Cohen, Nadav and Shashua, Amnon},
	month = may,
	year = {2016},
	note = {arXiv: 1603.00162},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@article{telgarsky2016BenefitsDepthNeural,
	title = {Benefits of depth in neural networks},
	url = {http://arxiv.org/abs/1602.04485},
	abstract = {For any positive integer \$k\$, there exist neural networks with \${\textbackslash}Theta(k{\textasciicircum}3)\$ layers, \${\textbackslash}Theta(1)\$ nodes per layer, and \${\textbackslash}Theta(1)\$ distinct parameters which can not be approximated by networks with \${\textbackslash}mathcal\{O\}(k)\$ layers unless they are exponentially large --- they must possess \${\textbackslash}Omega(2{\textasciicircum}k)\$ nodes. This result is proved here for a class of nodes termed "semi-algebraic gates" which includes the common choices of ReLU, maximum, indicator, and piecewise polynomial functions, therefore establishing benefits of depth against not just standard networks with ReLU gates, but also convolutional networks with ReLU and maximization gates, sum-product networks, and boosted decision trees (in this last case with a stronger separation: \${\textbackslash}Omega(2{\textasciicircum}\{k{\textasciicircum}3\})\$ total tree nodes are required).},
	urldate = {2022-02-13},
	journal = {arXiv:1602.04485 [cs, stat]},
	author = {Telgarsky, Matus},
	month = may,
	year = {2016},
	note = {arXiv: 1602.04485},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@article{eldan2016PowerDepthFeedforward,
	title = {The {Power} of {Depth} for {Feedforward} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1512.03965},
	abstract = {We show that there is a simple (approximately radial) function on \${\textbackslash}reals{\textasciicircum}d\$, expressible by a small 3-layer feedforward neural networks, which cannot be approximated by any 2-layer network, to more than a certain constant accuracy, unless its width is exponential in the dimension. The result holds for virtually all known activation functions, including rectified linear units, sigmoids and thresholds, and formally demonstrates that depth -- even if increased by 1 -- can be exponentially more valuable than width for standard feedforward neural networks. Moreover, compared to related results in the context of Boolean functions, our result requires fewer assumptions, and the proof techniques and construction are very different.},
	urldate = {2022-02-13},
	journal = {arXiv:1512.03965 [cs, stat]},
	author = {Eldan, Ronen and Shamir, Ohad},
	month = may,
	year = {2016},
	note = {arXiv: 1512.03965},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@inproceedings{delalleau2011ShallowVsDeep,
	title = {Shallow vs. {Deep} {Sum}-{Product} {Networks}},
	volume = {24},
	url = {https://papers.nips.cc/paper/2011/hash/8e6b42f1644ecb1327dc03ab345e618b-Abstract.html},
	urldate = {2022-02-13},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Delalleau, Olivier and Bengio, Yoshua},
	year = {2011},
}

@article{livni2014ComputationalEfficiencyTraining,
	title = {On the {Computational} {Efficiency} of {Training} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1410.1141},
	abstract = {It is well-known that neural networks are computationally hard to train. On the other hand, in practice, modern day neural networks are trained efficiently using SGD and a variety of tricks that include different activation functions (e.g. ReLU), over-specification (i.e., train networks which are larger than needed), and regularization. In this paper we revisit the computational complexity of training neural networks from a modern perspective. We provide both positive and negative results, some of them yield new provably efficient and practical algorithms for training certain types of neural networks.},
	urldate = {2022-02-13},
	journal = {arXiv:1410.1141 [cs, stat]},
	author = {Livni, Roi and Shalev-Shwartz, Shai and Shamir, Ohad},
	month = oct,
	year = {2014},
	note = {arXiv: 1410.1141},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@book{edgington2007RandomizationTests,
	title = {Randomization {Tests}},
	isbn = {978-1-4200-1181-4},
	abstract = {The number of innovative applications of randomization tests in various fields and recent developments in experimental design, significance testing, computing facilities, and randomization test algorithms have necessitated a new edition of Randomization Tests. Updated, reorganized, and revised, the text emphasizes the irrelevance and implausibility of the random sampling assumption for the typical experiment in three completely rewritten chapters. It also discusses factorial designs and interactions and combines repeated-measures and randomized block designs in one chapter. The authors focus more attention on the practicality of N-of-1 randomization tests and the availability of user-friendly software to perform them. In addition, they provide an overview of free and commercial computer programs for all of the tests presented in the book. Building on the previous editions that have served as standard textbooks for more than twenty-five years, Randomization Tests, Fourth Edition includes downloadable resources of up-to-date randomization test programs that facilitate application of the tests to experimental data. This CD-ROM enables students to work out problems that have been added to the chapters and helps professors teach the basics of randomization tests and devise tasks for assignments and examinations.},
	language = {en},
	publisher = {CRC Press},
	author = {Edgington, Eugene and Onghena, Patrick},
	month = feb,
	year = {2007},
	note = {Google-Books-ID: SdrLBQAAQBAJ},
	keywords = {Mathematics / Probability \& Statistics / General},
}

@article{bartlett2002RademacherGaussianComplexities,
	title = {Rademacher and {Gaussian} {Complexities}: {Risk} {Bounds} and {Structural} {Results}},
	volume = {3},
	issn = {ISSN 1533-7928},
	shorttitle = {Rademacher and {Gaussian} {Complexities}},
	url = {https://www.jmlr.org/papers/v3/bartlett02a},
	abstract = {We investigate the use of certain data-dependent estimates
    of the complexity of a function class, called Rademacher and
    Gaussian complexities. In a decision theoretic setting, we
    prove general risk bounds in terms of these complexities. We
    consider function classes that can be expressed as combinations
    of functions from basis classes and show how the Rademacher and
    Gaussian complexities of such a function class can be bounded in
    terms of the complexity of the basis classes. We give examples
    of the application of these techniques in finding data-dependent
    risk bounds for decision trees, neural networks and support
    vector machines.},
	number = {Nov},
	urldate = {2022-02-12},
	journal = {Journal of Machine Learning Research},
	author = {Bartlett, Peter L. and Mendelson, Shahar},
	year = {2002},
	pages = {463--482},
}

@article{poggio2004GeneralConditionsPredictivity,
	title = {General conditions for predictivity in learning theory},
	volume = {428},
	issn = {0028-0836, 1476-4679},
	url = {http://www.nature.com/doifinder/10.1038/nature02341},
	doi = {10.1038/nature02341},
	language = {en},
	number = {6981},
	urldate = {2022-02-12},
	journal = {Nature},
	author = {Poggio, Tomaso and Rifkin, Ryan and Mukherjee, Sayan and Niyogi, Partha},
	month = mar,
	year = {2004},
	pages = {419--422},
}

@techreport{mukherjee2004StatisticalLearningStability,
	address = {Fort Belvoir, VA},
	title = {Statistical {Learning}: {Stability} is {Sufficient} for {Generalization} and {Necessary} and {Sufficient} for {Consistency} of {Empirical} {Risk} {Minimization}:},
	shorttitle = {Statistical {Learning}},
	url = {http://www.dtic.mil/docs/citations/ADA459857},
	language = {en},
	urldate = {2022-02-12},
	institution = {Defense Technical Information Center},
	author = {Mukherjee, Sayan and Niyogi, Partha and Poggio, Tomaso and Rifkin, Ryan},
	month = jan,
	year = {2004},
	doi = {10.21236/ADA459857},
}

@article{bousquet2002StabilityGeneralization,
	title = {Stability and {Generalization}},
	volume = {2},
	issn = {ISSN 1533-7928},
	url = {https://www.jmlr.org/papers/v2/bousquet02a},
	abstract = {We define notions of stability for learning algorithms and show how to use these notions to derive generalization error bounds based on the empirical error and the leave-one-out error. The methods we use can be applied in the regression framework as well as in the classification one when the classifier is obtained by thresholding a real-valued function. We study the stability properties of large classes of learning algorithms such as regularization based algorithms. In particular we focus on Hilbert space regularization and Kullback-Leibler regularization. We demonstrate how to apply the results to SVM for regression and classification.},
	number = {Mar},
	urldate = {2022-02-11},
	journal = {Journal of Machine Learning Research},
	author = {Bousquet, Olivier and Elisseeff, André},
	year = {2002},
	pages = {499--526},
}

@book{vapnik1998StatisticalLearningTheory,
	title = {Statistical {Learning} {Theory}},
	isbn = {978-0-471-03003-4},
	abstract = {Introduction: The Problem of Induction and Statistical Inference. Two Approaches to the Learning Problem. Appendix to Chapter1: Methods for Solving III-Posed Problems. Estimation of the Probability Measure and Problem of Learning. Conditions for Consistency of Empirical Risk Minimization Principle. Bounds on the Risk for Indicator Loss Functions. Appendix to Chapter 4: Lower Bounds on the Risk of the ERM Principle. Bounds on the Risk for Real-Valued Loss Functions. The Structural Risk Minimization Principle. Appendix to Chapter 6: Estimating Functions on the Basis of Indirect Measurements. Stochastic III-Posed Problems. Estimating the Values of Function at Given Points. Perceptrons and Their Generalizations. The Support Vector Method for Estimating Indicator Functions. The Support Vector Method for Estimating Real-Valued Functions. SV Machines for Pattern Recognition. SV Machines for Function Approximations, Regression Estimation, and Signal Processing. Necessary and Sufficient Conditions for Uniform Convergence of Frequencies to Their Probabilities. Necessary and Sufficient Conditions for Uniform Convergence of Means to Their Expectations. Necessary and Sufficient Conditions for Uniform One-Sided Convergence of Means to Their Expectations.},
	language = {en},
	publisher = {Wiley},
	author = {Vapnik, Vladimir Naumovich},
	month = sep,
	year = {1998},
	note = {Google-Books-ID: GowoAQAAMAAJ},
	keywords = {Computers / Artificial Intelligence / General, Mathematics / Mathematical Analysis, Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes},
}

@article{liu2021UnderstandingMemorizationPerspective,
	title = {Understanding {Memorization} from the {Perspective} of {Optimization} via {Efficient} {Influence} {Estimation}},
	url = {http://arxiv.org/abs/2112.08798},
	abstract = {Over-parameterized deep neural networks are able to achieve excellent training accuracy while maintaining a small generalization error. It has also been found that they are able to fit arbitrary labels, and this behaviour is referred to as the phenomenon of memorization. In this work, we study the phenomenon of memorization with turn-over dropout, an efficient method to estimate influence and memorization, for data with true labels (real data) and data with random labels (random data). Our main findings are: (i) For both real data and random data, the optimization of easy examples (e.g., real data) and difficult examples (e.g., random data) are conducted by the network simultaneously, with easy ones at a higher speed; (ii) For real data, a correct difficult example in the training dataset is more informative than an easy one. By showing the existence of memorization on random data and real data, we highlight the consistency between them regarding optimization and we emphasize the implication of memorization during optimization.},
	urldate = {2022-02-11},
	journal = {arXiv:2112.08798 [cs]},
	author = {Liu, Futong and Lin, Tao and Jaggi, Martin},
	month = dec,
	year = {2021},
	note = {arXiv: 2112.08798
version: 1},
	keywords = {Computer Science - Machine Learning},
}

% label memorization references

@article{zhang2017UnderstandingDeepLearning,
	title = {Understanding deep learning requires rethinking generalization},
	url = {http://arxiv.org/abs/1611.03530},
	abstract = {Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family, or to the regularization techniques used during training. Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization, and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. We interpret our experimental findings by comparison with traditional models.},
	urldate = {2022-01-31},
	journal = {arXiv:1611.03530 [cs]},
	author = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
	month = feb,
	year = {2017},
	note = {arXiv: 1611.03530},
	keywords = {Computer Science - Machine Learning},
}

@article{pondenkandath2018leveraging,
  title={Leveraging random label memorization for unsupervised pre-training},
  author={Pondenkandath, Vinaychandran and Alberti, Michele and Puran, Sammer and Ingold, Rolf and Liwicki, Marcus},
  journal={arXiv preprint arXiv:1811.01640},
  year={2018}
}

@article{zhang2021CounterfactualMemorizationNeural,
	title = {Counterfactual {Memorization} in {Neural} {Language} {Models}},
	url = {http://arxiv.org/abs/2112.12938},
	abstract = {Modern neural language models widely used in tasks across NLP risk memorizing sensitive information from their training data. As models continue to scale up in parameters, training data, and compute, understanding memorization in language models is both important from a learning-theoretical point of view, and is practically crucial in real world applications. An open question in previous studies of memorization in language models is how to filter out "common" memorization. In fact, most memorization criteria strongly correlate with the number of occurrences in the training set, capturing "common" memorization such as familiar phrases, public knowledge or templated texts. In this paper, we provide a principled perspective inspired by a taxonomy of human memory in Psychology. From this perspective, we formulate a notion of counterfactual memorization, which characterizes how a model's predictions change if a particular document is omitted during training. We identify and study counterfactually-memorized training examples in standard text datasets. We further estimate the influence of each training example on the validation set and on generated texts, and show that this can provide direct evidence of the source of memorization at test time.},
	urldate = {2022-02-02},
	journal = {arXiv:2112.12938 [cs]},
	author = {Zhang, Chiyuan and Ippolito, Daphne and Lee, Katherine and Jagielski, Matthew and Tramèr, Florian and Carlini, Nicholas},
	month = dec,
	year = {2021},
	note = {arXiv: 2112.12938
version: 1},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{saunshi2021MathematicalExplorationWhy,
	title = {A {Mathematical} {Exploration} of {Why} {Language} {Models} {Help} {Solve} {Downstream} {Tasks}},
	url = {http://arxiv.org/abs/2010.03648},
	abstract = {Autoregressive language models, pretrained using large text corpora to do well on next word prediction, have been successful at solving many downstream tasks, even with zero-shot usage. However, there is little theoretical understanding of this success. This paper initiates a mathematical study of this phenomenon for the downstream task of text classification by considering the following questions: (1) What is the intuitive connection between the pretraining task of next word prediction and text classification? (2) How can we mathematically formalize this connection and quantify the benefit of language modeling? For (1), we hypothesize, and verify empirically, that classification tasks of interest can be reformulated as sentence completion tasks, thus making language modeling a meaningful pretraining task. With a mathematical formalization of this hypothesis, we make progress towards (2) and show that language models that are \${\textbackslash}epsilon\$-optimal in cross-entropy (log-perplexity) learn features that can linearly solve such classification tasks with \${\textbackslash}mathcal\{O\}({\textbackslash}sqrt\{{\textbackslash}epsilon\})\$ error, thus demonstrating that doing well on language modeling can be beneficial for downstream tasks. We experimentally verify various assumptions and theoretical findings, and also use insights from the analysis to design a new objective function that performs well on some classification tasks.},
	urldate = {2022-02-03},
	journal = {arXiv:2010.03648 [cs, stat]},
	author = {Saunshi, Nikunj and Malladi, Sadhika and Arora, Sanjeev},
	month = apr,
	year = {2021},
	note = {arXiv: 2010.03648},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@incollection{atkinson1968HumanMemoryProposed,
	title = {Human {Memory}: {A} {Proposed} {System} and its {Control} {Processes}},
	volume = {2},
	shorttitle = {Human {Memory}},
	url = {https://www.sciencedirect.com/science/article/pii/S0079742108604223},
	abstract = {This chapter presents a general theoretical framework of human memory and describes the results of a number of experiments designed to test specific models that can be derived from the overall theory. This general theoretical framework categorizes the memory system along two major dimensions. The first categorization distinguishes permanent, structural features of the system from control processes that can be readily modified or reprogrammed at the will of the subject. The second categorization divides memory into three structural components: the sensory register, the short-term store, and the long-term store. Incoming sensory information first enters the sensory register, where it resides for a very brief period of time, then decays and is lost. The short-term store is the subject's working memory; it receives selected inputs from the sensory register and also from long-term store. The chapter also discusses the control processes associated with the sensory register. The term control process refers to those processes that are not permanent features of memory, but are instead transient phenomena under the control of the subject; their appearance depends on several factors such as instructional set, the experimental task, and the past history of the subject.},
	language = {en},
	urldate = {2022-02-04},
	booktitle = {Psychology of {Learning} and {Motivation}},
	publisher = {Academic Press},
	author = {Atkinson, R. C. and Shiffrin, R. M.},
	editor = {Spence, Kenneth W. and Spence, Janet Taylor},
	month = jan,
	year = {1968},
	doi = {10.1016/S0079-7421(08)60422-3},
	pages = {89--195},
}

@book{mackay2003InformationTheoryInference,
	title = {Information {Theory}, {Inference} and {Learning} {Algorithms}},
	isbn = {978-0-521-64298-9},
	abstract = {Information theory and inference, often taught separately, are here united in one entertaining textbook. These topics lie at the heart of many exciting areas of contemporary science and engineering - communication, signal processing, data mining, machine learning, pattern recognition, computational neuroscience, bioinformatics, and cryptography. This textbook introduces theory in tandem with applications. Information theory is taught alongside practical communication systems, such as arithmetic coding for data compression and sparse-graph codes for error-correction. A toolbox of inference techniques, including message-passing algorithms, Monte Carlo methods, and variational approximations, are developed alongside applications of these tools to clustering, convolutional codes, independent component analysis, and neural networks. The final part of the book describes the state of the art in error-correcting codes, including low-density parity-check codes, turbo codes, and digital fountain codes -- the twenty-first century standards for satellite communications, disk drives, and data broadcast. Richly illustrated, filled with worked examples and over 400 exercises, some with detailed solutions, David MacKay's groundbreaking book is ideal for self-learning and for undergraduate or graduate courses. Interludes on crosswords, evolution, and sex provide entertainment along the way. In sum, this is a textbook on information, communication, and coding for a new generation of students, and an unparalleled entry point into these subjects for professionals in areas as diverse as computational biology, financial engineering, and machine learning.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {MacKay, David J. C. and Kay, David J. C. Mac and MacKay, vid J. C.},
	month = sep,
	year = {2003},
	note = {Google-Books-ID: AKuMj4PN\_EMC},
	keywords = {Computers / Artificial Intelligence / Computer Vision \& Pattern Recognition, Computers / Computer Science, Computers / Information Theory, Computers / Programming / General, Science / Physics / General, Technology \& Engineering / Electronics / General},
}

@article{kolmogorov1965ThreeApproachesDefining,
	title = {Three approaches for defining the concept of information quantity},
	volume = {1},
	journal = {Problemy peredaci informacii},
	author = {Kolmogorov, Andrei Nikolaevich},
	year = {1965},
	pages = {3--11},
}

@article{baum1988CapabilitiesMultilayerPerceptrons,
	title = {On the capabilities of multilayer perceptrons},
	volume = {4},
	issn = {0885064X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0885064X88900209},
	doi = {10.1016/0885-064X(88)90020-9},
	language = {en},
	number = {3},
	urldate = {2022-02-03},
	journal = {Journal of Complexity},
	author = {Baum, Eric B},
	month = sep,
	year = {1988},
	pages = {193--215},
}

@article{rajput2021ExponentialImprovementMemorization,
	title = {An {Exponential} {Improvement} on the {Memorization} {Capacity} of {Deep} {Threshold} {Networks}},
	url = {http://arxiv.org/abs/2106.07724},
	abstract = {It is well known that modern deep neural networks are powerful enough to memorize datasets even when the labels have been randomized. Recently, Vershynin (2020) settled a long standing question by Baum (1988), proving that {\textbackslash}emph\{deep threshold\} networks can memorize \$n\$ points in \$d\$ dimensions using \${\textbackslash}widetilde\{{\textbackslash}mathcal\{O\}\}(e{\textasciicircum}\{1/{\textbackslash}delta{\textasciicircum}2\}+{\textbackslash}sqrt\{n\})\$ neurons and \${\textbackslash}widetilde\{{\textbackslash}mathcal\{O\}\}(e{\textasciicircum}\{1/{\textbackslash}delta{\textasciicircum}2\}(d+{\textbackslash}sqrt\{n\})+n)\$ weights, where \${\textbackslash}delta\$ is the minimum distance between the points. In this work, we improve the dependence on \${\textbackslash}delta\$ from exponential to almost linear, proving that \${\textbackslash}widetilde\{{\textbackslash}mathcal\{O\}\}({\textbackslash}frac\{1\}\{{\textbackslash}delta\}+{\textbackslash}sqrt\{n\})\$ neurons and \${\textbackslash}widetilde\{{\textbackslash}mathcal\{O\}\}({\textbackslash}frac\{d\}\{{\textbackslash}delta\}+n)\$ weights are sufficient. Our construction uses Gaussian random weights only in the first layer, while all the subsequent layers use binary or integer weights. We also prove new lower bounds by connecting memorization in neural networks to the purely geometric problem of separating \$n\$ points on a sphere using hyperplanes.},
	urldate = {2022-02-03},
	journal = {arXiv:2106.07724 [cs, math, stat]},
	author = {Rajput, Shashank and Sreenivasan, Kartik and Papailiopoulos, Dimitris and Karbasi, Amin},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.07724
version: 1},
	keywords = {Computer Science - Information Theory, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{engstrom2019AdversarialRobustnessPrior,
	title = {Adversarial {Robustness} as a {Prior} for {Learned} {Representations}},
	url = {http://arxiv.org/abs/1906.00945},
	abstract = {An important goal in deep learning is to learn versatile, high-level feature representations of input data. However, standard networks' representations seem to possess shortcomings that, as we illustrate, prevent them from fully realizing this goal. In this work, we show that robust optimization can be re-cast as a tool for enforcing priors on the features learned by deep neural networks. It turns out that representations learned by robust models address the aforementioned shortcomings and make significant progress towards learning a high-level encoding of inputs. In particular, these representations are approximately invertible, while allowing for direct visualization and manipulation of salient input features. More broadly, our results indicate adversarial robustness as a promising avenue for improving learned representations. Our code and models for reproducing these results is available at https://git.io/robust-reps .},
	urldate = {2022-02-01},
	journal = {arXiv:1906.00945 [cs, stat]},
	author = {Engstrom, Logan and Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Tran, Brandon and Madry, Aleksander},
	month = sep,
	year = {2019},
	note = {arXiv: 1906.00945},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@article{ilyas2019AdversarialExamplesAre,
	title = {Adversarial {Examples} {Are} {Not} {Bugs}, {They} {Are} {Features}},
	url = {http://arxiv.org/abs/1905.02175},
	abstract = {Adversarial examples have attracted significant attention in machine learning, but the reasons for their existence and pervasiveness remain unclear. We demonstrate that adversarial examples can be directly attributed to the presence of non-robust features: features derived from patterns in the data distribution that are highly predictive, yet brittle and incomprehensible to humans. After capturing these features within a theoretical framework, we establish their widespread existence in standard datasets. Finally, we present a simple setting where we can rigorously tie the phenomena we observe in practice to a misalignment between the (human-specified) notion of robustness and the inherent geometry of the data.},
	urldate = {2022-02-01},
	journal = {arXiv:1905.02175 [cs, stat]},
	author = {Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander},
	month = aug,
	year = {2019},
	note = {arXiv: 1905.02175},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{tsipras2019RobustnessMayBe,
	title = {Robustness {May} {Be} at {Odds} with {Accuracy}},
	url = {http://arxiv.org/abs/1805.12152},
	abstract = {We show that there may exist an inherent tension between the goal of adversarial robustness and that of standard generalization. Specifically, training robust models may not only be more resource-consuming, but also lead to a reduction of standard accuracy. We demonstrate that this trade-off between the standard accuracy of a model and its robustness to adversarial perturbations provably exists in a fairly simple and natural setting. These findings also corroborate a similar phenomenon observed empirically in more complex settings. Further, we argue that this phenomenon is a consequence of robust classifiers learning fundamentally different feature representations than standard classifiers. These differences, in particular, seem to result in unexpected benefits: the representations learned by robust models tend to align better with salient data characteristics and human perception.},
	urldate = {2022-02-01},
	journal = {arXiv:1805.12152 [cs, stat]},
	author = {Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Madry, Aleksander},
	month = sep,
	year = {2019},
	note = {arXiv: 1805.12152},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@article{santurkar2019ImageSynthesisSingle,
	title = {Image {Synthesis} with a {Single} ({Robust}) {Classifier}},
	url = {http://arxiv.org/abs/1906.09453},
	abstract = {We show that the basic classification framework alone can be used to tackle some of the most challenging tasks in image synthesis. In contrast to other state-of-the-art approaches, the toolkit we develop is rather minimal: it uses a single, off-the-shelf classifier for all these tasks. The crux of our approach is that we train this classifier to be adversarially robust. It turns out that adversarial robustness is precisely what we need to directly manipulate salient features of the input. Overall, our findings demonstrate the utility of robustness in the broader machine learning context. Code and models for our experiments can be found at https://git.io/robust-apps.},
	urldate = {2022-02-01},
	journal = {arXiv:1906.09453 [cs, stat]},
	author = {Santurkar, Shibani and Tsipras, Dimitris and Tran, Brandon and Ilyas, Andrew and Engstrom, Logan and Madry, Aleksander},
	month = aug,
	year = {2019},
	note = {arXiv: 1906.09453},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@article{akhtar2018DefenseUniversalAdversarial,
	title = {Defense against {Universal} {Adversarial} {Perturbations}},
	url = {http://arxiv.org/abs/1711.05929},
	abstract = {Recent advances in Deep Learning show the existence of image-agnostic quasi-imperceptible perturbations that when applied to `any' image can fool a state-of-the-art network classifier to change its prediction about the image label. These `Universal Adversarial Perturbations' pose a serious threat to the success of Deep Learning in practice. We present the first dedicated framework to effectively defend the networks against such perturbations. Our approach learns a Perturbation Rectifying Network (PRN) as `pre-input' layers to a targeted model, such that the targeted model needs no modification. The PRN is learned from real and synthetic image-agnostic perturbations, where an efficient method to compute the latter is also proposed. A perturbation detector is separately trained on the Discrete Cosine Transform of the input-output difference of the PRN. A query image is first passed through the PRN and verified by the detector. If a perturbation is detected, the output of the PRN is used for label prediction instead of the actual image. A rigorous evaluation shows that our framework can defend the network classifiers against unseen adversarial perturbations in the real-world scenarios with up to 97.5\% success rate. The PRN also generalizes well in the sense that training for one targeted network defends another network with a comparable success rate.},
	urldate = {2022-02-01},
	journal = {arXiv:1711.05929 [cs]},
	author = {Akhtar, Naveed and Liu, Jian and Mian, Ajmal},
	month = feb,
	year = {2018},
	note = {arXiv: 1711.05929},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{moosavi-dezfooli2017UniversalAdversarialPerturbations,
	title = {Universal adversarial perturbations},
	url = {http://arxiv.org/abs/1610.08401},
	abstract = {Given a state-of-the-art deep neural network classifier, we show the existence of a universal (image-agnostic) and very small perturbation vector that causes natural images to be misclassified with high probability. We propose a systematic algorithm for computing universal perturbations, and show that state-of-the-art deep neural networks are highly vulnerable to such perturbations, albeit being quasi-imperceptible to the human eye. We further empirically analyze these universal perturbations and show, in particular, that they generalize very well across neural networks. The surprising existence of universal perturbations reveals important geometric correlations among the high-dimensional decision boundary of classifiers. It further outlines potential security breaches with the existence of single directions in the input space that adversaries can possibly exploit to break a classifier on most natural images.},
	urldate = {2022-02-01},
	journal = {arXiv:1610.08401 [cs, stat]},
	author = {Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Fawzi, Omar and Frossard, Pascal},
	month = mar,
	year = {2017},
	note = {arXiv: 1610.08401},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{sun2021GeometricModelingOccam,
	title = {A {Geometric} {Modeling} of {Occam}'s {Razor} in {Deep} {Learning}},
	url = {http://arxiv.org/abs/1905.11027},
	abstract = {Why do deep neural networks (DNNs) benefit from very high dimensional parameter spaces? Their huge parameter complexities vs stunning performances in practice is all the more intriguing and not explainable using the standard theory of regular models. In this work, we propose a geometrically flavored information-theoretic approach to study this phenomenon. Namely, we introduce the locally varying dimensionality of the parameter space of neural network models by considering the number of significant dimensions of the Fisher information matrix, and model the parameter space as a manifold using the framework of singular semi-Riemannian geometry. We derive model complexity measures which yield short description lengths for deep neural network models based on their singularity analysis thus explaining the good performance of DNNs despite their large number of parameters.},
	urldate = {2022-02-01},
	journal = {arXiv:1905.11027 [cs, stat]},
	author = {Sun, Ke and Nielsen, Frank},
	month = dec,
	year = {2021},
	note = {arXiv: 1905.11027},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{ott2019FairseqFastExtensible,
	title = {fairseq: {A} {Fast}, {Extensible} {Toolkit} for {Sequence} {Modeling}},
	shorttitle = {fairseq},
	url = {http://arxiv.org/abs/1904.01038},
	abstract = {fairseq is an open-source sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling, and other text generation tasks. The toolkit is based on PyTorch and supports distributed training across multiple GPUs and machines. We also support fast mixed-precision training and inference on modern GPUs. A demo video can be found at https://www.youtube.com/watch?v=OtgDdWtHvto},
	urldate = {2022-01-31},
	journal = {arXiv:1904.01038 [cs]},
	author = {Ott, Myle and Edunov, Sergey and Baevski, Alexei and Fan, Angela and Gross, Sam and Ng, Nathan and Grangier, David and Auli, Michael},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.01038},
	keywords = {Computer Science - Computation and Language},
}

@inproceedings{liu2020UnderstandingDifficultyTraininga,
	address = {Online},
	title = {Understanding the {Difficulty} of {Training} {Transformers}},
	url = {https://aclanthology.org/2020.emnlp-main.463},
	doi = {10.18653/v1/2020.emnlp-main.463},
	abstract = {Transformers have proved effective in many NLP tasks. However, their training requires non-trivial efforts regarding carefully designing cutting-edge optimizers and learning rate schedulers (e.g., conventional SGD fails to train Transformers effectively). Our objective here is to understand \_\_what complicates Transformer training\_\_ from both empirical and theoretical perspectives. Our analysis reveals that unbalanced gradients are not the root cause of the instability of training. Instead, we identify an amplification effect that influences training substantially—for each layer in a multi-layer Transformer model, heavy dependency on its residual branch makes training unstable, since it amplifies small parameter perturbations (e.g., parameter updates) and results in significant disturbances in the model output. Yet we observe that a light dependency limits the model potential and leads to inferior trained models. Inspired by our analysis, we propose Admin (Adaptive model initialization) to stabilize the early stage's training and unleash its full potential in the late stage. Extensive experiments show that Admin is more stable, converges faster, and leads to better performance},
	urldate = {2022-01-29},
	booktitle = {Proceedings of the 2020 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Liu, Liyuan and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu and Han, Jiawei},
	month = nov,
	year = {2020},
	pages = {5747--5763},
}

@article{lin2021FewshotLearningMultilinguala,
	title = {Few-shot {Learning} with {Multilingual} {Language} {Models}},
	url = {http://arxiv.org/abs/2112.10668},
	abstract = {Large-scale autoregressive language models such as GPT-3 are few-shot learners that can perform a wide range of language tasks without fine-tuning. While these models are known to be able to jointly represent many different languages, their training data is dominated by English, potentially limiting their cross-lingual generalization. In this work, we train multilingual autoregressive language models on a balanced corpus covering a diverse set of languages, and study their few- and zero-shot learning capabilities in a wide range of tasks. Our largest model with 7.5 billion parameters sets new state of the art in few-shot learning in more than 20 representative languages, outperforming GPT-3 of comparable size in multilingual commonsense reasoning (with +7.4\% absolute accuracy improvement in 0-shot settings and +9.4\% in 4-shot settings) and natural language inference (+5.4\% in each of 0-shot and 4-shot settings). On the FLORES-101 machine translation benchmark, our model outperforms GPT-3 on 171 out of 182 translation directions with 32 training examples, while surpassing the official supervised baseline in 45 directions. We present a detailed analysis of where the model succeeds and fails, showing in particular that it enables cross-lingual in-context learning on some tasks, while there is still room for improvement on surface form robustness and adaptation to tasks that do not have a natural cloze form. Finally, we evaluate our models in social value tasks such as hate speech detection in five languages and find it has limitations similar to comparable sized GPT-3 models.},
	urldate = {2022-01-29},
	journal = {arXiv:2112.10668 [cs]},
	author = {Lin, Xi Victoria and Mihaylov, Todor and Artetxe, Mikel and Wang, Tianlu and Chen, Shuohui and Simig, Daniel and Ott, Myle and Goyal, Naman and Bhosale, Shruti and Du, Jingfei and Pasunuru, Ramakanth and Shleifer, Sam and Koura, Punit Singh and Chaudhary, Vishrav and O'Horo, Brian and Wang, Jeff and Zettlemoyer, Luke and Kozareva, Zornitsa and Diab, Mona and Stoyanov, Veselin and Li, Xian},
	month = dec,
	year = {2021},
	note = {arXiv: 2112.10668},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@inproceedings{petroni2019LanguageModelsKnowledge,
	address = {Hong Kong, China},
	title = {Language {Models} as {Knowledge} {Bases}?},
	url = {https://aclanthology.org/D19-1250},
	doi = {10.18653/v1/D19-1250},
	abstract = {Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as “fill-in-the-blank” cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.},
	urldate = {2022-01-29},
	booktitle = {Proceedings of the 2019 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} and the 9th {International} {Joint} {Conference} on {Natural} {Language} {Processing} ({EMNLP}-{IJCNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Petroni, Fabio and Rocktäschel, Tim and Riedel, Sebastian and Lewis, Patrick and Bakhtin, Anton and Wu, Yuxiang and Miller, Alexander},
	month = nov,
	year = {2019},
	pages = {2463--2473},
}

@article{metzen2017UniversalAdversarialPerturbations,
	title = {Universal {Adversarial} {Perturbations} {Against} {Semantic} {Image} {Segmentation}},
	url = {http://arxiv.org/abs/1704.05712},
	abstract = {While deep learning is remarkably successful on perceptual tasks, it was also shown to be vulnerable to adversarial perturbations of the input. These perturbations denote noise added to the input that was generated specifically to fool the system while being quasi-imperceptible for humans. More severely, there even exist universal perturbations that are input-agnostic but fool the network on the majority of inputs. While recent work has focused on image classification, this work proposes attacks against semantic image segmentation: we present an approach for generating (universal) adversarial perturbations that make the network yield a desired target segmentation as output. We show empirically that there exist barely perceptible universal noise patterns which result in nearly the same predicted segmentation for arbitrary inputs. Furthermore, we also show the existence of universal noise which removes a target class (e.g., all pedestrians) from the segmentation while leaving the segmentation mostly unchanged otherwise.},
	urldate = {2022-01-25},
	journal = {arXiv:1704.05712 [cs, stat]},
	author = {Metzen, Jan Hendrik and Kumar, Mummadi Chaithanya and Brox, Thomas and Fischer, Volker},
	month = jul,
	year = {2017},
	note = {arXiv: 1704.05712},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@article{akhtar2018ThreatAdversarialAttacks,
	title = {Threat of {Adversarial} {Attacks} on {Deep} {Learning} in {Computer} {Vision}: {A} {Survey}},
	shorttitle = {Threat of {Adversarial} {Attacks} on {Deep} {Learning} in {Computer} {Vision}},
	url = {http://arxiv.org/abs/1801.00553},
	abstract = {Deep learning is at the heart of the current rise of machine learning and artificial intelligence. In the field of Computer Vision, it has become the workhorse for applications ranging from self-driving cars to surveillance and security. Whereas deep neural networks have demonstrated phenomenal success (often beyond human capabilities) in solving complex problems, recent studies show that they are vulnerable to adversarial attacks in the form of subtle perturbations to inputs that lead a model to predict incorrect outputs. For images, such perturbations are often too small to be perceptible, yet they completely fool the deep learning models. Adversarial attacks pose a serious threat to the success of deep learning in practice. This fact has lead to a large influx of contributions in this direction. This article presents the first comprehensive survey on adversarial attacks on deep learning in Computer Vision. We review the works that design adversarial attacks, analyze the existence of such attacks and propose defenses against them. To emphasize that adversarial attacks are possible in practical conditions, we separately review the contributions that evaluate adversarial attacks in the real-world scenarios. Finally, we draw on the literature to provide a broader outlook of the research direction.},
	urldate = {2022-01-25},
	journal = {arXiv:1801.00553 [cs]},
	author = {Akhtar, Naveed and Mian, Ajmal},
	month = feb,
	year = {2018},
	note = {arXiv: 1801.00553},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{carlini2017EvaluatingRobustnessNeural,
	title = {Towards {Evaluating} the {Robustness} of {Neural} {Networks}},
	url = {http://arxiv.org/abs/1608.04644},
	abstract = {Neural networks provide state-of-the-art results for most machine learning tasks. Unfortunately, neural networks are vulnerable to adversarial examples: given an input \$x\$ and any target classification \$t\$, it is possible to find a new input \$x'\$ that is similar to \$x\$ but classified as \$t\$. This makes it difficult to apply neural networks in security-critical areas. Defensive distillation is a recently proposed approach that can take an arbitrary neural network, and increase its robustness, reducing the success rate of current attacks' ability to find adversarial examples from \$95{\textbackslash}\%\$ to \$0.5{\textbackslash}\%\$. In this paper, we demonstrate that defensive distillation does not significantly increase the robustness of neural networks by introducing three new attack algorithms that are successful on both distilled and undistilled neural networks with \$100{\textbackslash}\%\$ probability. Our attacks are tailored to three distance metrics used previously in the literature, and when compared to previous adversarial example generation algorithms, our attacks are often much more effective (and never worse). Furthermore, we propose using high-confidence adversarial examples in a simple transferability test we show can also be used to break defensive distillation. We hope our attacks will be used as a benchmark in future defense attempts to create neural networks that resist adversarial examples.},
	urldate = {2022-01-26},
	journal = {arXiv:1608.04644 [cs]},
	author = {Carlini, Nicholas and Wagner, David},
	month = mar,
	year = {2017},
	note = {arXiv: 1608.04644},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Cryptography and Security},
}

@article{madry2019DeepLearningModels,
	title = {Towards {Deep} {Learning} {Models} {Resistant} to {Adversarial} {Attacks}},
	url = {http://arxiv.org/abs/1706.06083},
	abstract = {Recent work has demonstrated that deep neural networks are vulnerable to adversarial examples---inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. In fact, some of the latest findings suggest that the existence of adversarial attacks may be an inherent weakness of deep learning models. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much of the prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against any adversary. These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. They also suggest the notion of security against a first-order adversary as a natural and broad security guarantee. We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models. Code and pre-trained models are available at https://github.com/MadryLab/mnist\_challenge and https://github.com/MadryLab/cifar10\_challenge.},
	urldate = {2022-01-26},
	journal = {arXiv:1706.06083 [cs, stat]},
	author = {Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
	month = sep,
	year = {2019},
	note = {arXiv: 1706.06083},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@article{thickstunTransformerModelEquations,
	title = {The {Transformer} {Model} in {Equations}},
	abstract = {This document presents a precise mathematical deﬁnition of the transformer model introduced by Vaswani et al. [2017], along with some discussion of the terminology and intuitions commonly associated with the transformer. We also draw some connections between the transformer and lstm, based on observations by Levy et al. [2018].},
	language = {en},
	author = {Thickstun, John},
	pages = {5},
}

@article{henighan2020ScalingLawsAutoregressive,
	title = {Scaling {Laws} for {Autoregressive} {Generative} {Modeling}},
	url = {http://arxiv.org/abs/2010.14701},
	abstract = {We identify empirical scaling laws for the cross-entropy loss in four domains: generative image modeling, video modeling, multimodal image↔text models, and mathematical problem solving. In all cases autoregressive Transformers smoothly improve in performance as model size and compute budgets increase, following a power-law plus constant scaling law. The optimal model size also depends on the compute budget through a power-law, with exponents that are nearly universal across all data domains.},
	language = {en},
	urldate = {2022-01-20},
	journal = {arXiv:2010.14701 [cs]},
	author = {Henighan, Tom and Kaplan, Jared and Katz, Mor and Chen, Mark and Hesse, Christopher and Jackson, Jacob and Jun, Heewoo and Brown, Tom B. and Dhariwal, Prafulla and Gray, Scott and Hallacy, Chris and Mann, Benjamin and Radford, Alec and Ramesh, Aditya and Ryder, Nick and Ziegler, Daniel M. and Schulman, John and Amodei, Dario and McCandlish, Sam},
	month = nov,
	year = {2020},
	note = {arXiv: 2010.14701},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{kaplan2020ScalingLawsNeural,
	title = {Scaling {Laws} for {Neural} {Language} {Models}},
	url = {http://arxiv.org/abs/2001.08361},
	abstract = {We study empirical scaling laws for language model performance on the cross-entropy loss. The loss scales as a power-law with model size, dataset size, and the amount of compute used for training, with some trends spanning more than seven orders of magnitude. Other architectural details such as network width or depth have minimal effects within a wide range. Simple equations govern the dependence of overﬁtting on model/dataset size and the dependence of training speed on model size. These relationships allow us to determine the optimal allocation of a ﬁxed compute budget. Larger models are signiﬁcantly more sampleefﬁcient, such that optimally compute-efﬁcient training involves training very large models on a relatively modest amount of data and stopping signiﬁcantly before convergence.},
	language = {en},
	urldate = {2022-01-20},
	journal = {arXiv:2001.08361 [cs, stat]},
	author = {Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B. and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
	month = jan,
	year = {2020},
	note = {arXiv: 2001.08361},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{tang2021RobustARTBenchmarkingRobustness,
	title = {{RobustART}: {Benchmarking} {Robustness} on {Architecture} {Design} and {Training} {Techniques}},
	shorttitle = {{RobustART}},
	url = {http://arxiv.org/abs/2109.05211},
	abstract = {Deep neural networks (DNNs) are vulnerable to adversarial noises, which motivates the benchmark of model robustness. Existing benchmarks mainly focus on evaluating the defenses, but there are no comprehensive studies of how architecture design and general training techniques affect robustness. Comprehensively benchmarking their relationships will be highly beneﬁcial for better understanding and developing robust DNNs. Thus, we propose RobustART, the ﬁrst comprehensive Robustness investigation benchmark on ImageNet (including an open-source toolkit, a pre-trained model zoo, datasets, and analyses) regarding ARchitecture design (44 human-designed off-the-shelf architectures and 1200+ networks from neural architecture search) and Training techniques (10+ general techniques, e.g., data augmentation) towards diverse noises (adversarial, natural, and system noises). Extensive experiments revealed and substantiated several insights for the ﬁrst time, for example: (1) adversarial training largely improves the clean accuracy and all types of robustness for Transformers and MLP-Mixers; (2) given comparable model sizes and aligned training settings, CNNs {\textgreater} Transformers {\textgreater} MLP-Mixers on robustness against natural and system noises; Transformers {\textgreater} MLP-Mixers {\textgreater} CNNs on adversarial robustness; (3) for some light-weight architectures (e.g., EfﬁcientNet, MobileNetV2, and MobileNetV3), increasing model sizes or using extra training data cannot improve robustness. Our benchmark http://robust.art/: (1) presents an open-source platform for conducting comprehensive evaluation on diverse robustness types; (2) provides a variety of pre-trained models with different training techniques to facilitate robustness evaluation; (3) proposes a new view to better understand the mechanism towards designing robust DNN architectures, backed up by the analysis. We will continuously contribute to building this ecosystem for the community.},
	language = {en},
	urldate = {2022-01-16},
	journal = {arXiv:2109.05211 [cs]},
	author = {Tang, Shiyu and Gong, Ruihao and Wang, Yan and Liu, Aishan and Wang, Jiakai and Chen, Xinyun and Yu, Fengwei and Liu, Xianglong and Song, Dawn and Yuille, Alan and Torr, Philip H. S. and Tao, Dacheng},
	month = oct,
	year = {2021},
	note = {arXiv: 2109.05211},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@book{keller2013ONEThingSurprisingly,
	edition = {1st edition},
	title = {The {ONE} {Thing}: {The} {Surprisingly} {Simple} {Truth} {About} {Extraordinary} {Results}},
	shorttitle = {The {ONE} {Thing}},
	language = {English},
	publisher = {Bard Press},
	author = {Keller, Gary and Papasan, Jay},
	month = apr,
	year = {2013},
}

@inproceedings{bromley1994SignatureVerificationUsing,
	title = {Signature {Verification} using a "{Siamese}" {Time} {Delay} {Neural} {Network}},
	volume = {6},
	url = {https://proceedings.neurips.cc/paper/1993/hash/288cc0ff022877bd3df94bc9360b9c5d-Abstract.html},
	urldate = {2021-11-22},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Morgan-Kaufmann},
	author = {Bromley, Jane and Guyon, Isabelle and LeCun, Yann and Säckinger, Eduard and Shah, Roopak},
	year = {1994},
}

@book{toulmin2003UsesArgument,
	title = {The {Uses} of {Argument}},
	isbn = {978-0-521-53483-3},
	abstract = {Traditionally, logic has been claimed to be 'the science of rational argument', but the relevance to our everyday disputes of the formal logician's results has remained unclear. The abstract character of traditional logic cuts the subject off from practical considerations; Mr Toulmin enquires why this is so, and shows how an alternative conception can be of more general value. Starting from an examination of the actual procedures in different fields of argument - the practice, as opposed to the theory, of logic - he discloses a richer variety than is allowed for by any available system. He argues that jurisprudence rather than mathematics should be the logician's model in analysing rational procedures, and that logic should be a comparative and not a purely formal study. These suggestions lead to conclusions which many will consider controversial; though they will also be widely recognized as interesting and illuminating. This book extends into general philosophy lines of enquiry already sketched by Mr Toulmin in his earlier books on ethics and the philosophy of science. The ordinary reader will find in it the same clarity and intelligibility; and the professional philosopher will acknowledge the same power to break new ground (and circumvent old difficulties) by posing fresh and stimulating questions.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Toulmin, Stephen E.},
	month = jul,
	year = {2003},
	note = {Google-Books-ID: 8UYgegaB1S0C},
	keywords = {Philosophy / General, Philosophy / Logic, Psychology / Cognitive Psychology \& Cognition},
}

@article{li2019VisualBERTSimplePerformant,
	title = {{VisualBERT}: {A} {Simple} and {Performant} {Baseline} for {Vision} and {Language}},
	shorttitle = {{VisualBERT}},
	url = {https://arxiv.org/abs/1908.03557v1},
	abstract = {We propose VisualBERT, a simple and flexible framework for modeling a broad range of vision-and-language tasks. VisualBERT consists of a stack of Transformer layers that implicitly align elements of an input text and regions in an associated input image with self-attention. We further propose two visually-grounded language model objectives for pre-training VisualBERT on image caption data. Experiments on four vision-and-language tasks including VQA, VCR, NLVR2, and Flickr30K show that VisualBERT outperforms or rivals with state-of-the-art models while being significantly simpler. Further analysis demonstrates that VisualBERT can ground elements of language to image regions without any explicit supervision and is even sensitive to syntactic relationships, tracking, for example, associations between verbs and image regions corresponding to their arguments.},
	language = {en},
	urldate = {2021-11-21},
	author = {Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
	month = aug,
	year = {2019},
}

@article{sutskever2014SequenceSequenceLearning,
	title = {Sequence to {Sequence} {Learning} with {Neural} {Networks}},
	url = {http://arxiv.org/abs/1409.3215},
	abstract = {Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT'14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous best result on this task. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.},
	urldate = {2021-10-28},
	journal = {arXiv:1409.3215 [cs]},
	author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
	month = dec,
	year = {2014},
	note = {arXiv: 1409.3215},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{zhu2020ModifyingMemoriesTransformer,
	title = {Modifying {Memories} in {Transformer} {Models}},
	url = {http://arxiv.org/abs/2012.00363},
	abstract = {Large Transformer models have achieved impressive performance in many natural language tasks. In particular, Transformer based language models have been shown to have great capabilities in encoding factual knowledge in their vast amount of parameters. While the tasks of improving the memorization and generalization of Transformers have been widely studied, it is not well known how to make transformers forget specific old facts and memorize new ones. In this paper, we propose a new task of {\textbackslash}emph\{explicitly modifying specific factual knowledge in Transformer models while ensuring the model performance does not degrade on the unmodified facts\}. This task is useful in many scenarios, such as updating stale knowledge, protecting privacy, and eliminating unintended biases stored in the models. We benchmarked several approaches that provide natural baseline performances on this task. This leads to the discovery of key components of a Transformer model that are especially effective for knowledge modifications. The work also provides insights into the role that different training phases (such as pretraining and fine-tuning) play towards memorization and knowledge modification.},
	urldate = {2022-01-29},
	journal = {arXiv:2012.00363 [cs]},
	author = {Zhu, Chen and Rawat, Ankit Singh and Zaheer, Manzil and Bhojanapalli, Srinadh and Li, Daliang and Yu, Felix and Kumar, Sanjiv},
	month = dec,
	year = {2020},
	note = {arXiv: 2012.00363},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{krotov2021LargeAssociativeMemory,
	title = {Large {Associative} {Memory} {Problem} in {Neurobiology} and {Machine} {Learning}},
	url = {http://arxiv.org/abs/2008.06996},
	abstract = {Dense Associative Memories or modern Hopﬁeld networks permit storage and reliable retrieval of an exponentially large (in the dimension of feature space) number of memories. At the same time, their naive implementation is non-biological, since it seemingly requires the existence of many-body synaptic junctions between the neurons. We show that these models are effective descriptions of a more microscopic (written in terms of biological degrees of freedom) theory that has additional (hidden) neurons and only requires two-body interactions between them. For this reason our proposed microscopic theory is a valid model of large associative memory with a degree of biological plausibility. The dynamics of our network and its reduced dimensional equivalent both minimize energy (Lyapunov) functions. When certain dynamical variables (hidden neurons) are integrated out from our microscopic theory, one can recover many of the models that were previously discussed in the literature, e.g. the model presented in “Hopﬁeld Networks is All You Need” paper. We also provide an alternative derivation of the energy function and the update rule proposed in the aforementioned paper and clarify the relationships between various models of this class.},
	language = {en},
	urldate = {2022-01-27},
	journal = {arXiv:2008.06996 [cond-mat, q-bio, stat]},
	author = {Krotov, Dmitry and Hopfield, John},
	month = apr,
	year = {2021},
	note = {arXiv: 2008.06996},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Condensed Matter - Disordered Systems and Neural Networks, Quantitative Biology - Neurons and Cognition, Statistics - Machine Learning},
}

@article{han2021PreTrainedModelsPresent,
	title = {Pre-{Trained} {Models}: {Past}, {Present} and {Future}},
	issn = {26666510},
	shorttitle = {Pre-{Trained} {Models}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2666651021000231},
	doi = {10.1016/j.aiopen.2021.08.002},
	language = {en},
	urldate = {2022-01-20},
	journal = {AI Open},
	author = {Han, Xu and Zhang, Zhengyan and Ding, Ning and Gu, Yuxian and Liu, Xiao and Huo, Yuqi and Qiu, Jiezhong and Zhang, Liang and Han, Wentao and Huang, Minlie and Jin, Qin and Lan, Yanyan and Liu, Yang and Liu, Zhiyuan and Lu, Zhiwu and Qiu, Xipeng and Song, Ruihua and Tang, Jie and Wen, Ji-Rong and Yuan, Jinhui and Zhao, Wayne Xin and Zhu, Jun},
	month = aug,
	year = {2021},
	pages = {S2666651021000231},
}

@article{jiang2021LearningDefendLearning,
	title = {Learning to {Defend} by {Learning} to {Attack}},
	url = {http://arxiv.org/abs/1811.01213},
	abstract = {Adversarial training provides a principled approach for training robust neural networks. From an optimization perspective, adversarial training is essentially solving a bilevel optimization problem. The leader problem is trying to learn a robust classiﬁer, while the follower problem is trying to generate adversarial samples. Unfortunately, such a bilevel problem is diﬃcult to solve due to its highly complicated structure. This work proposes a new adversarial training method based on a generic learning-to-learn (L2L) framework. Speciﬁcally, instead of applying existing hand-designed algorithms for the inner problem, we learn an optimizer, which is parametrized as a convolutional neural network. At the same time, a robust classiﬁer is learned to defense the adversarial attack generated by the learned optimizer. Experiments over CIFAR-10 and CIFAR-100 datasets demonstrate that L2L outperforms existing adversarial training methods in both classiﬁcation accuracy and computational eﬃciency. Moreover, our L2L framework can be extended to generative adversarial imitation learning and stabilize the training.},
	language = {en},
	urldate = {2022-01-16},
	journal = {arXiv:1811.01213 [cs, stat]},
	author = {Jiang, Haoming and Chen, Zhehui and Shi, Yuyang and Dai, Bo and Zhao, Tuo},
	month = may,
	year = {2021},
	note = {arXiv: 1811.01213},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{park2021ProvableMemorizationDeep,
	title = {Provable {Memorization} via {Deep} {Neural} {Networks} using {Sub}-linear {Parameters}},
	url = {http://arxiv.org/abs/2010.13363},
	abstract = {It is known that O(N ) parameters are sufﬁcient for neural networks to memorize arbitrary N inputlabel pairs. By exploiting depth, we show that O(N 2/3) parameters sufﬁce to memorize N pairs, under a mild condition on the separation of input points. In particular, deeper networks (even with width 3) are shown to memorize more pairs than shallow networks, which also agrees with the recent line of works on the beneﬁts of depth for function approximation. We also provide empirical results that support our theoretical ﬁndings.},
	language = {en},
	urldate = {2022-01-15},
	journal = {arXiv:2010.13363 [cs]},
	author = {Park, Sejun and Lee, Jaeho and Yun, Chulhee and Shin, Jinwoo},
	month = nov,
	year = {2021},
	note = {arXiv: 2010.13363},
	keywords = {Computer Science - Machine Learning},
}

@article{deisenroth2021MathematicsMachineLearning,
	title = {Mathematics for {Machine} {Learning}},
	language = {en},
	author = {Deisenroth, Marc Peter and Faisal, A Aldo and Ong, Cheng Soon},
	year = {2021},
	pages = {417},
}

@article{lecunLossFunctionsDiscriminative,
	title = {Loss {Functions} for {Discriminative} {Training} of {Energy}-{Based} {Models}.},
	abstract = {Probabilistic graphical models associate a probability to each conﬁguration of the relevant variables. Energy-based models (EBM) associate an energy to those conﬁgurations, eliminating the need for proper normalization of probability distributions. Making a decision (an inference) with an EBM consists in comparing the energies associated with various conﬁgurations of the variable to be predicted, and choosing the one with the smallest energy. Such systems must be trained discriminatively to associate low energies to the desired conﬁgurations and higher energies to undesired conﬁgurations. A wide variety of loss function can be used for this purpose. We give sufﬁcient conditions that a loss function should satisfy so that its minimization will cause the system to approach to desired behavior. We give many speciﬁc examples of suitable loss functions, and show an application to object recognition in images.},
	language = {en},
	author = {LeCun, Yann and Huang, Fu Jie},
	pages = {8},
}

@article{mnihPlayingAtariDeep,
	title = {Playing {Atari} with {Deep} {Reinforcement} {Learning}},
	abstract = {We present the ﬁrst deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We ﬁnd that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
	language = {en},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	pages = {9},
}

@article{hochreiter1997LongShortTermMemory,
	title = {Long {Short}-{Term} {Memory}},
	volume = {9},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.1997.9.8.1735},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	number = {8},
	urldate = {2021-11-21},
	journal = {Neural Computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	month = nov,
	year = {1997},
	pages = {1735--1780},
}

@article{toneva2018empirical,
  title={An empirical study of example forgetting during deep neural network learning},
  author={Toneva, Mariya and Sordoni, Alessandro and Combes, Remi Tachet des and Trischler, Adam and Bengio, Yoshua and Gordon, Geoffrey J},
  journal={arXiv preprint arXiv:1812.05159},
  year={2018}
}

@article{kirkpatrick2016OvercomingCatastrophicForgetting,
	title = {Overcoming catastrophic forgetting in neural networks},
	url = {https://arxiv.org/abs/1612.00796v2},
	abstract = {The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Neural networks are not, in general, capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks which they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on the MNIST hand written digit dataset and by learning several Atari 2600 games sequentially.},
	language = {en},
	urldate = {2021-11-21},
	author = {Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A. and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and Hassabis, Demis and Clopath, Claudia and Kumaran, Dharshan and Hadsell, Raia},
	month = dec,
	year = {2016},
}

@article{jaegle2021PerceiverGeneralPerception,
	title = {Perceiver: {General} {Perception} with {Iterative} {Attention}},
	shorttitle = {Perceiver},
	url = {https://arxiv.org/abs/2103.03206v2},
	abstract = {Biological systems perceive the world by simultaneously processing high-dimensional inputs from modalities as diverse as vision, audition, touch, proprioception, etc. The perception models used in deep learning on the other hand are designed for individual modalities, often relying on domain-specific assumptions such as the local grid structures exploited by virtually all existing vision models. These priors introduce helpful inductive biases, but also lock models to individual modalities. In this paper we introduce the Perceiver - a model that builds upon Transformers and hence makes few architectural assumptions about the relationship between its inputs, but that also scales to hundreds of thousands of inputs, like ConvNets. The model leverages an asymmetric attention mechanism to iteratively distill inputs into a tight latent bottleneck, allowing it to scale to handle very large inputs. We show that this architecture is competitive with or outperforms strong, specialized models on classification tasks across various modalities: images, point clouds, audio, video, and video+audio. The Perceiver obtains performance comparable to ResNet-50 and ViT on ImageNet without 2D convolutions by directly attending to 50,000 pixels. It is also competitive in all modalities in AudioSet.},
	language = {en},
	urldate = {2021-11-21},
	author = {Jaegle, Andrew and Gimeno, Felix and Brock, Andrew and Zisserman, Andrew and Vinyals, Oriol and Carreira, Joao},
	month = mar,
	year = {2021},
}

@article{he2017MaskRCNN,
	title = {Mask {R}-{CNN}},
	url = {https://arxiv.org/abs/1703.06870v3},
	abstract = {We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without bells and whistles, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code has been made available at: https://github.com/facebookresearch/Detectron},
	language = {en},
	urldate = {2021-11-21},
	author = {He, Kaiming and Gkioxari, Georgia and Dollár, Piotr and Girshick, Ross},
	month = mar,
	year = {2017},
}

@inproceedings{chopra2005LearningSimilarityMetric,
	address = {San Diego, CA, USA},
	title = {Learning a {Similarity} {Metric} {Discriminatively}, with {Application} to {Face} {Verification}},
	volume = {1},
	isbn = {978-0-7695-2372-9},
	url = {http://ieeexplore.ieee.org/document/1467314/},
	doi = {10.1109/CVPR.2005.202},
	abstract = {We present a method for training a similarity metric from data. The method can be used for recognition or veriﬁcation applications where the number of categories is very large and not known during training, and where the number of training samples for a single category is very small. The idea is to learn a function that maps input patterns into a target space such that the ¢¤£ norm in the target space approximates the “semantic” distance in the input space. The method is applied to a face veriﬁcation task. The learning process minimizes a discriminative loss function that drives the similarity metric to be small for pairs of faces from the same person, and large for pairs from different persons. The mapping from raw to the target space is a convolutional network whose architecture is designed for robustness to geometric distortions. The system is tested on the Purdue/AR face database which has a very high degree of variability in the pose, lighting, expression, position, and artiﬁcial occlusions such as dark glasses and obscuring scarves.},
	language = {en},
	urldate = {2021-11-21},
	booktitle = {2005 {IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR}'05)},
	publisher = {IEEE},
	author = {Chopra, S. and Hadsell, R. and LeCun, Y.},
	year = {2005},
	pages = {539--546},
}

@article{liu2019RoBERTaRobustlyOptimized,
	title = {{RoBERTa}: {A} {Robustly} {Optimized} {BERT} {Pretraining} {Approach}},
	shorttitle = {{RoBERTa}},
    journal = {arXiv e-prints},
	url = {https://arxiv.org/abs/1907.11692v1},
	abstract = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
	language = {en},
	urldate = {2021-11-21},
	author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
	month = jul,
	year = {2019},
}

@article{sutskever2013ImportanceInitializationMomentum,
	title = {On the importance of initialization and momentum in deep learning},
	abstract = {Deep and recurrent neural networks (DNNs and RNNs respectively) are powerful models that were considered to be almost impossible to train using stochastic gradient descent with momentum. In this paper, we show that when stochastic gradient descent with momentum uses a well-designed random initialization and a particular type of slowly increasing schedule for the momentum parameter, it can train both DNNs and RNNs (on datasets with long-term dependencies) to levels of performance that were previously achievable only with Hessian-Free optimization. We ﬁnd that both the initialization and the momentum are crucial since poorly initialized networks cannot be trained with momentum and well-initialized networks perform markedly worse when the momentum is absent or poorly tuned.},
	language = {en},
	author = {Sutskever, Ilya and Martens, James and Dahl, George},
	year = {2013},
	pages = {9},
}

@article{bahdanau2016NeuralMachineTranslation,
	title = {Neural {Machine} {Translation} by {Jointly} {Learning} to {Align} and {Translate}},
	url = {http://arxiv.org/abs/1409.0473},
	abstract = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},
	urldate = {2021-10-28},
	journal = {arXiv:1409.0473 [cs, stat]},
	author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
	month = may,
	year = {2016},
	note = {arXiv: 1409.0473},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@article{mikolov2010RecurrentNeuralNetwork,
	title = {Recurrent {Neural} {Network} {Based} {Language} {Model}},
	abstract = {A new recurrent neural network based language model (RNN LM) with applications to speech recognition is presented. Results indicate that it is possible to obtain around 50\% reduction of perplexity by using mixture of several RNN LMs, compared to a state of the art backoff language model. Speech recognition experiments show around 18\% reduction of word error rate on the Wall Street Journal task when comparing models trained on the same amount of data, and around 5\% on the much harder NIST RT05 task, even when the backoff model is trained on much more data than the RNN LM. We provide ample empirical evidence to suggest that connectionist language models are superior to standard n-gram techniques, except their high computational (training) complexity.},
	language = {en},
	author = {Mikolov, Tomas and Karafiat, Martin and Burget, Lukas and Cernocky, Jan and Khudanpur, Sanjeev},
	year = {2010},
	pages = {4},
}

@article{szegedy2014IntriguingPropertiesNeural,
	title = {Intriguing properties of neural networks},
	url = {http://arxiv.org/abs/1312.6199},
	abstract = {Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties.},
	language = {en},
	urldate = {2022-01-16},
	journal = {arXiv:1312.6199 [cs]},
	author = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
	month = feb,
	year = {2014},
	note = {arXiv: 1312.6199},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@article{naseer2021IntriguingPropertiesVision,
	title = {Intriguing {Properties} of {Vision} {Transformers}},
	url = {http://arxiv.org/abs/2105.10497},
	abstract = {Vision transformers (ViT) have demonstrated impressive performance across numerous machine vision tasks. These models are based on multi-head self-attention mechanisms that can ﬂexibly attend to a sequence of image patches to encode contextual cues. An important question is how such ﬂexibility (in attending image-wide context conditioned on a given patch) can facilitate handling nuisances in natural images e.g., severe occlusions, domain shifts, spatial permutations, adversarial and natural perturbations. We systematically study this question via an extensive set of experiments encompassing three ViT families and provide comparisons with a high-performing convolutional neural network (CNN). We show and analyze the following intriguing properties of ViT: (a) Transformers are highly robust to severe occlusions, perturbations and domain shifts, e.g., retain as high as 60\% top-1 accuracy on ImageNet even after randomly occluding 80\% of the image content. (b) The robustness towards occlusions is not due to texture bias, instead we show that ViTs are signiﬁcantly less biased towards local textures, compared to CNNs. When properly trained to encode shape-based features, ViTs demonstrate shape recognition capability comparable to that of human visual system, previously unmatched in the literature. (c) Using ViTs to encode shape representation leads to an interesting consequence of accurate semantic segmentation without pixel-level supervision. (d) Off-the-shelf features from a single ViT model can be combined to create a feature ensemble, leading to high accuracy rates across a range of classiﬁcation datasets in both traditional and few-shot learning paradigms. We show effective features of ViTs are due to ﬂexible and dynamic receptive ﬁelds possible via self-attention mechanisms. Code: https://git.io/Js15X.},
	language = {en},
	urldate = {2022-01-16},
	journal = {arXiv:2105.10497 [cs]},
	author = {Naseer, Muzammal and Ranasinghe, Kanchana and Khan, Salman and Hayat, Munawar and Khan, Fahad Shahbaz and Yang, Ming-Hsuan},
	month = nov,
	year = {2021},
	note = {arXiv: 2105.10497},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{kharitonov2021HowBPEAffects,
	title = {How {BPE} {Affects} {Memorization} in {Transformers}},
	url = {http://arxiv.org/abs/2110.02782},
	abstract = {Training data memorization in NLP can both be beneﬁcial (e.g., closed-book QA) and undesirable (personal data extraction). In any case, successful model training requires a non-trivial amount of memorization to store word spellings, various linguistic idiosyncrasies and common knowledge. However, little is known about what affects the memorization behavior of NLP models, as the ﬁeld tends to focus on the equally important question of generalization.},
	language = {en},
	urldate = {2022-01-15},
	journal = {arXiv:2110.02782 [cs]},
	author = {Kharitonov, Eugene and Baroni, Marco and Hupkes, Dieuwke},
	month = dec,
	year = {2021},
	note = {arXiv: 2110.02782},
	keywords = {Computer Science - Computation and Language},
}

@article{du2021GLaMEfficientScaling,
	title = {{GLaM}: {Efficient} {Scaling} of {Language} {Models} with {Mixture}-of-{Experts}},
	shorttitle = {{GLaM}},
	url = {http://arxiv.org/abs/2112.06905},
	abstract = {Scaling language models with more data, compute and parameters has driven signiﬁcant progress in natural language processing. For example, thanks to scaling, GPT-3 was able to achieve strong results on in-context learning tasks. However, training these large dense models requires signiﬁcant amounts of computing resources. In this paper, we propose and develop a family of language models named GLaM (Generalist Language Model), which uses a sparsely activated mixture-of-experts architecture to scale the model capacity while also incurring substantially less training cost compared to dense variants. The largest GLaM has 1.2 trillion parameters, which is approximately 7x larger than GPT-3. It consumes only 1/3 of the energy used to train GPT-3 and requires half of the computation ﬂops for inference, while still achieving better overall zero-shot and one-shot performance across 29 NLP tasks.},
	language = {en},
	urldate = {2022-01-15},
	journal = {arXiv:2112.06905 [cs]},
	author = {Du, Nan and Huang, Yanping and Dai, Andrew M. and Tong, Simon and Lepikhin, Dmitry and Xu, Yuanzhong and Krikun, Maxim and Zhou, Yanqi and Yu, Adams Wei and Firat, Orhan and Zoph, Barret and Fedus, Liam and Bosma, Maarten and Zhou, Zongwei and Wang, Tao and Wang, Yu Emma and Webster, Kellie and Pellat, Marie and Robinson, Kevin and Meier-Hellstern, Kathy and Duke, Toju and Dixon, Lucas and Zhang, Kun and Le, Quoc V. and Wu, Yonghui and Chen, Zhifeng and Cui, Claire},
	month = dec,
	year = {2021},
	note = {arXiv: 2112.06905},
	keywords = {Computer Science - Computation and Language},
}

@article{ramsauer2021HopfieldNetworksAll,
	title = {Hopfield {Networks} is {All} {You} {Need}},
	url = {http://arxiv.org/abs/2008.02217},
	abstract = {We introduce a modern Hopfield network with continuous states and a corresponding update rule. The new Hopfield network can store exponentially (with the dimension of the associative space) many patterns, retrieves the pattern with one update, and has exponentially small retrieval errors. It has three types of energy minima (fixed points of the update): (1) global fixed point averaging over all patterns, (2) metastable states averaging over a subset of patterns, and (3) fixed points which store a single pattern. The new update rule is equivalent to the attention mechanism used in transformers. This equivalence enables a characterization of the heads of transformer models. These heads perform in the first layers preferably global averaging and in higher layers partial averaging via metastable states. The new modern Hopfield network can be integrated into deep learning architectures as layers to allow the storage of and access to raw input data, intermediate results, or learned prototypes. These Hopfield layers enable new ways of deep learning, beyond fully-connected, convolutional, or recurrent networks, and provide pooling, memory, association, and attention mechanisms. We demonstrate the broad applicability of the Hopfield layers across various domains. Hopfield layers improved state-of-the-art on three out of four considered multiple instance learning problems as well as on immune repertoire classification with several hundreds of thousands of instances. On the UCI benchmark collections of small classification tasks, where deep learning methods typically struggle, Hopfield layers yielded a new state-of-the-art when compared to different machine learning methods. Finally, Hopfield layers achieved state-of-the-art on two drug design datasets. The implementation is available at: https://github.com/ml-jku/hopfield-layers},
	language = {en},
	urldate = {2022-01-14},
	journal = {arXiv:2008.02217 [cs, stat]},
	author = {Ramsauer, Hubert and Schäfl, Bernhard and Lehner, Johannes and Seidl, Philipp and Widrich, Michael and Adler, Thomas and Gruber, Lukas and Holzleitner, Markus and Pavlović, Milena and Sandve, Geir Kjetil and Greiff, Victor and Kreil, David and Kopp, Michael and Klambauer, Günter and Brandstetter, Johannes and Hochreiter, Sepp},
	month = apr,
	year = {2021},
	note = {arXiv: 2008.02217},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@article{dengImageNetLargeScaleHierarchical,
	title = {{ImageNet}: {A} {Large}-{Scale} {Hierarchical} {Image} {Database}},
	abstract = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a largescale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 5001000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classiﬁcation and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
	language = {en},
	author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
	pages = {2},
}

@article{lecun1998GradientBasedLearningApplied,
	title = {Gradient-{Based} {Learning} {Applied} to {Document} {Recognition}},
	language = {en},
	author = {LeCun, Yann and Bottou, Leon and Bengio, Yoshua and Ha, Patrick},
	year = {1998},
	pages = {46},
}

@book{adler2014HowReadBook,
	title = {How to {Read} a {Book}: {The} {Classic} {Guide} to {Intelligent} {Reading}},
	isbn = {978-1-4767-9015-2},
	shorttitle = {How to {Read} a {Book}},
	abstract = {With more than half a million paperback copies in print and now in this stunning hardcover keepsake edition, How to Read a Book is the classic and definitive guide to reading comprehension for students of literature, scholars across disciplines, and anyone who just loves to read.Originally written in 1940 and first published by Simon \& Schuster in 1972, How to Read a Book introduces and elucidates the various levels of reading and how to achieve them in order to gain the most understanding and insight from any book. From elementary reading, through systematic skimming and inspectional reading, to speed reading and beyond, readers will learn when and how to “judge a book by its cover,” perceive structure no matter the prose, read critically, and extract the author's message from the text.  Also included are specific reading techniques that work best for reading particular genres, whether they be practical books, imaginative literature, plays, poetry, history, science and mathematics, philosophy, or social science works. A recommended reading list and multiple comprehension tests are incorporated as well in order to measure progress in reading skills, speed, and understanding. As poignant and applicable today as it was nearly seventy-five years ago, this beautiful hardcover edition is the perfect way to rediscover How to Read a Book, the best and most successful guide to reading comprehension.},
	language = {en},
	publisher = {Simon and Schuster},
	author = {Adler, Mortimer J. and Doren, Charles Van},
	month = sep,
	year = {2014},
	note = {Google-Books-ID: 3QOZBAAAQBAJ},
	keywords = {Language Arts \& Disciplines / Literacy, Language Arts \& Disciplines / Reading Skills, Language Arts \& Disciplines / Study \& Teaching},
}

@inproceedings{goodfellow2014GenerativeAdversarialNets,
	title = {Generative {Adversarial} {Nets}},
	volume = {27},
	url = {https://proceedings.neurips.cc/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html},
	urldate = {2021-11-21},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
	year = {2014},
}

@inproceedings{krizhevsky2012ImageNetClassificationDeep,
	title = {{ImageNet} {Classification} with {Deep} {Convolutional} {Neural} {Networks}},
	volume = {25},
	url = {https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html},
	urldate = {2021-11-21},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	year = {2012},
}

@article{long2014FullyConvolutionalNetworks,
	title = {Fully {Convolutional} {Networks} for {Semantic} {Segmentation}},
	url = {https://arxiv.org/abs/1411.4038v2},
	abstract = {Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build "fully convolutional" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a novel architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20\% relative improvement to 62.2\% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes one third of a second for a typical image.},
	language = {en},
	urldate = {2021-11-21},
	author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	month = nov,
	year = {2014},
}

@article{radfordImprovingLanguageUnderstanding,
	title = {Improving {Language} {Understanding} by {Generative} {Pre}-{Training}},
	abstract = {Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classiﬁcation. Although large unlabeled text corpora are abundant, labeled data for learning these speciﬁc tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative ﬁne-tuning on each speciﬁc task. In contrast to previous approaches, we make use of task-aware input transformations during ﬁne-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures speciﬁcally crafted for each task, signiﬁcantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9\% on commonsense reasoning (Stories Cloze Test), 5.7\% on question answering (RACE), and 1.5\% on textual entailment (MultiNLI).},
	language = {en},
	author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
	pages = {12},
}

@article{thys2019FoolingAutomatedSurveillance,
	title = {Fooling automated surveillance cameras: adversarial patches to attack person detection},
	shorttitle = {Fooling automated surveillance cameras},
	url = {http://arxiv.org/abs/1904.08653},
	abstract = {Adversarial attacks on machine learning models have seen increasing interest in the past years. By making only subtle changes to the input of a convolutional neural network, the output of the network can be swayed to output a completely different result. The first attacks did this by changing pixel values of an input image slightly to fool a classifier to output the wrong class. Other approaches have tried to learn "patches" that can be applied to an object to fool detectors and classifiers. Some of these approaches have also shown that these attacks are feasible in the real-world, i.e. by modifying an object and filming it with a video camera. However, all of these approaches target classes that contain almost no intra-class variety (e.g. stop signs). The known structure of the object is then used to generate an adversarial patch on top of it. In this paper, we present an approach to generate adversarial patches to targets with lots of intra-class variety, namely persons. The goal is to generate a patch that is able successfully hide a person from a person detector. An attack that could for instance be used maliciously to circumvent surveillance systems, intruders can sneak around undetected by holding a small cardboard plate in front of their body aimed towards the surveillance camera. From our results we can see that our system is able significantly lower the accuracy of a person detector. Our approach also functions well in real-life scenarios where the patch is filmed by a camera. To the best of our knowledge we are the first to attempt this kind of attack on targets with a high level of intra-class variety like persons.},
	urldate = {2022-01-25},
	journal = {arXiv:1904.08653 [cs]},
	author = {Thys, Simen and Van Ranst, Wiebe and Goedemé, Toon},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.08653},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{mikolov2013DistributedRepresentationsWords,
	title = {Distributed {Representations} of {Words} and {Phrases} and their {Compositionality}},
	abstract = {The recently introduced continuous Skip-gram model is an efﬁcient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain signiﬁcant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling.},
	language = {en},
	author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
	year = {2013},
	pages = {9},
}

@article{moosavi-dezfooli2016DeepFoolSimpleAccurate,
	title = {{DeepFool}: a simple and accurate method to fool deep neural networks},
	shorttitle = {{DeepFool}},
	url = {http://arxiv.org/abs/1511.04599},
	abstract = {State-of-the-art deep neural networks have achieved impressive results on many image classification tasks. However, these same architectures have been shown to be unstable to small, well sought, perturbations of the images. Despite the importance of this phenomenon, no effective methods have been proposed to accurately compute the robustness of state-of-the-art deep classifiers to such perturbations on large-scale datasets. In this paper, we fill this gap and propose the DeepFool algorithm to efficiently compute perturbations that fool deep networks, and thus reliably quantify the robustness of these classifiers. Extensive experimental results show that our approach outperforms recent methods in the task of computing adversarial perturbations and making classifiers more robust.},
	urldate = {2022-01-26},
	journal = {arXiv:1511.04599 [cs]},
	author = {Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal},
	month = jul,
	year = {2016},
	note = {arXiv: 1511.04599},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{goodfellow2015ExplainingHarnessingAdversarial,
	title = {Explaining and {Harnessing} {Adversarial} {Examples}},
	url = {http://arxiv.org/abs/1412.6572},
	abstract = {Several machine learning models, including neural networks, consistently misclassify adversarial examples—inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high conﬁdence. Early attempts at explaining this phenomenon focused on nonlinearity and overﬁtting. We argue instead that the primary cause of neural networks’ vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the ﬁrst explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.},
	language = {en},
	urldate = {2022-01-26},
	journal = {arXiv:1412.6572 [cs, stat]},
	author = {Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian},
	month = mar,
	year = {2015},
	note = {arXiv: 1412.6572},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{lin2021FewshotLearningMultilingual,
	title = {Few-shot {Learning} with {Multilingual} {Language} {Models}},
	url = {http://arxiv.org/abs/2112.10668},
	abstract = {Large-scale autoregressive language models such as GPT-3 are few-shot learners that can perform a wide range of language tasks without fine-tuning. While these models are known to be able to jointly represent many different languages, their training data is dominated by English, potentially limiting their cross-lingual generalization. In this work, we train multilingual autoregressive language models on a balanced corpus covering a diverse set of languages, and study their few- and zero-shot learning capabilities in a wide range of tasks. Our largest model with 7.5 billion parameters sets new state of the art in few-shot learning in more than 20 representative languages, outperforming GPT-3 of comparable size in multilingual commonsense reasoning (with +7.4\% absolute accuracy improvement in 0-shot settings and +9.4\% in 4-shot settings) and natural language inference (+5.4\% in each of 0-shot and 4-shot settings). On the FLORES-101 machine translation benchmark, our model outperforms GPT-3 on 171 out of 182 translation directions with 32 training examples, while surpassing the official supervised baseline in 45 directions. We present a detailed analysis of where the model succeeds and fails, showing in particular that it enables cross-lingual in-context learning on some tasks, while there is still room for improvement on surface form robustness and adaptation to tasks that do not have a natural cloze form. Finally, we evaluate our models in social value tasks such as hate speech detection in 5 languages and find it has limitations similar to comparably sized GPT-3 models.},
	language = {en},
	urldate = {2022-01-20},
	journal = {arXiv:2112.10668 [cs]},
	author = {Lin, Xi Victoria and Mihaylov, Todor and Artetxe, Mikel and Wang, Tianlu and Chen, Shuohui and Simig, Daniel and Ott, Myle and Goyal, Naman and Bhosale, Shruti and Du, Jingfei and Pasunuru, Ramakanth and Shleifer, Sam and Koura, Punit Singh and Chaudhary, Vishrav and O'Horo, Brian and Wang, Jeff and Zettlemoyer, Luke and Kozareva, Zornitsa and Diab, Mona and Stoyanov, Veselin and Li, Xian},
	month = dec,
	year = {2021},
	note = {arXiv: 2112.10668},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{liu2021EfficientTrainingVisual,
	title = {Efficient {Training} of {Visual} {Transformers} with {Small} {Datasets}},
	url = {http://arxiv.org/abs/2106.03746},
	abstract = {Visual Transformers (VTs) are emerging as an architectural paradigm alternative to Convolutional networks (CNNs). Differently from CNNs, VTs can capture global relations between image elements and they potentially have a larger representation capacity. However, the lack of the typical convolutional inductive bias makes these models more data hungry than common CNNs. In fact, some local properties of the visual domain which are embedded in the CNN architectural design, in VTs should be learned from samples. In this paper, we empirically analyse different VTs, comparing their robustness in a small training set regime, and we show that, despite having a comparable accuracy when trained on ImageNet, their performance on smaller datasets can be largely different. Moreover, we propose an auxiliary selfsupervised task which can extract additional information from images with only a negligible computational overhead. This task encourages the VTs to learn spatial relations within an image and makes the VT training much more robust when training data is scarce. Our task is used jointly with the standard (supervised) training and it does not depend on speciﬁc architectural choices, thus it can be easily plugged in the existing VTs. Using an extensive evaluation with different VTs and datasets, we show that our method can improve (sometimes dramatically) the ﬁnal accuracy of the VTs. Our code is available at: https://github.com/ yhlleo/VTs-Drloc.},
	language = {en},
	urldate = {2022-01-20},
	journal = {arXiv:2106.03746 [cs]},
	author = {Liu, Yahui and Sangineto, Enver and Bi, Wei and Sebe, Nicu and Lepri, Bruno and De Nadai, Marco},
	month = nov,
	year = {2021},
	note = {arXiv: 2106.03746},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@article{bahri2021ExplainingNeuralScaling,
	title = {Explaining {Neural} {Scaling} {Laws}},
	url = {http://arxiv.org/abs/2102.06701},
	abstract = {The test loss of well-trained neural networks often follows precise power-law scaling relations with either the size of the training dataset or the number of parameters in the network. We propose a theory that explains and connects these scaling laws. We identify variance-limited and resolution-limited scaling behavior for both dataset and model size, for a total of four scaling regimes. The variance-limited scaling follows simply from the existence of a well-behaved inﬁnite data or inﬁnite width limit, while the resolution-limited regime can be explained by positing that models are eﬀectively resolving a smooth data manifold. In the large width limit, this can be equivalently obtained from the spectrum of certain kernels, and we present evidence that large width and large dataset resolution-limited scaling exponents are related by a duality. We exhibit all four scaling regimes in the controlled setting of large random feature and pretrained models and test the predictions empirically on a range of standard architectures and datasets. We also observe several empirical relationships between datasets and scaling exponents: super-classing image tasks does not change exponents, while changing input distribution (via changing datasets or adding noise) has a strong eﬀect. We further explore the eﬀect of architecture aspect ratio on scaling exponents.},
	language = {en},
	urldate = {2022-01-20},
	journal = {arXiv:2102.06701 [cond-mat, stat]},
	author = {Bahri, Yasaman and Dyer, Ethan and Kaplan, Jared and Lee, Jaehoon and Sharma, Utkarsh},
	month = feb,
	year = {2021},
	note = {arXiv: 2102.06701},
	keywords = {Computer Science - Machine Learning, Condensed Matter - Disordered Systems and Neural Networks, Statistics - Machine Learning},
}

@article{tay2020EfficientTransformersSurvey,
	title = {Efficient {Transformers}: {A} {Survey}},
	shorttitle = {Efficient {Transformers}},
	url = {http://arxiv.org/abs/2009.06732},
	abstract = {Transformer model architectures have garnered immense interest lately due to their eﬀectiveness across a range of domains like language, vision and reinforcement learning. In the ﬁeld of natural language processing for example, Transformers have become an indispensable staple in the modern deep learning stack. Recently, a dizzying number of “X-former” models have been proposed - Reformer, Linformer, Performer, Longformer, to name a few - which improve upon the original Transformer architecture, many of which make improvements around computational and memory eﬃciency. With the aim of helping the avid researcher navigate this ﬂurry, this paper characterizes a large and thoughtful selection of recent eﬃciency-ﬂavored “X-former” models, providing an organized and comprehensive overview of existing work and models across multiple domains.},
	language = {en},
	urldate = {2022-01-20},
	journal = {arXiv:2009.06732 [cs]},
	author = {Tay, Yi and Dehghani, Mostafa and Bahri, Dara and Metzler, Donald},
	month = sep,
	year = {2020},
	note = {arXiv: 2009.06732},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Information Retrieval, Computer Science - Machine Learning},
}

@article{raghuVisionTransformersSee,
	title = {Do {Vision} {Transformers} {See} {Like} {Convolutional} {Neural} {Networks}?},
	abstract = {Convolutional neural networks (CNNs) have so far been the de-facto model for visual data. Recent work has shown that (Vision) Transformer models (ViT) can achieve comparable or even superior performance on image classiﬁcation tasks. This raises a central question: how are Vision Transformers solving these tasks? Are they acting like convolutional networks, or learning entirely different visual representations? Analyzing the internal representation structure of ViTs and CNNs on image classiﬁcation benchmarks, we ﬁnd striking differences between the two architectures, such as ViT having more uniform representations across all layers. We explore how these differences arise, ﬁnding crucial roles played by self-attention, which enables early aggregation of global information, and ViT residual connections, which strongly propagate features from lower to higher layers. We study the ramiﬁcations for spatial localization, demonstrating ViTs successfully preserve input spatial information, with noticeable effects from different classiﬁcation methods. Finally, we study the effect of (pretraining) dataset scale on intermediate features and transfer learning, and conclude with a discussion on connections to new architectures such as the MLP-Mixer.},
	language = {en},
	author = {Raghu, Maithra and Unterthiner, Thomas and Kornblith, Simon and Zhang, Chiyuan and Dosovitskiy, Alexey},
	pages = {13},
}

@article{feldman2021DoesLearningRequire,
	title = {Does {Learning} {Require} {Memorization}? {A} {Short} {Tale} about a {Long} {Tail}},
	shorttitle = {Does {Learning} {Require} {Memorization}?},
	url = {http://arxiv.org/abs/1906.05271},
	abstract = {State-of-the-art results on image recognition tasks are achieved using over-parameterized learning algorithms that (nearly) perfectly ﬁt the training set and are known to ﬁt well even random labels. This tendency to memorize the labels of the training data is not explained by existing theoretical analyses. Memorization of the training data also presents signiﬁcant privacy risks when the training data contains sensitive personal information and thus it is important to understand whether such memorization is necessary for accurate learning.},
	language = {en},
	urldate = {2022-01-15},
	journal = {arXiv:1906.05271 [cs, stat]},
	author = {Feldman, Vitaly},
	month = jan,
	year = {2021},
	note = {arXiv: 1906.05271},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{gururangan2021DEMixLayersDisentangling,
	title = {{DEMix} {Layers}: {Disentangling} {Domains} for {Modular} {Language} {Modeling}},
	shorttitle = {{DEMix} {Layers}},
	url = {http://arxiv.org/abs/2108.05036},
	abstract = {We introduce a new domain expert mixture (DEMIX) layer that enables conditioning a language model (LM) on the domain of the input text. A DEMIX layer is a collection of expert feedforward networks, each specialized to a domain, that makes the LM modular: experts can be mixed, added or removed after initial training. Extensive experiments with autoregressive transformer LMs (up to 1.3B parameters) show that DEMIX layers reduce test-time perplexity, increase training efﬁciency, and enable rapid adaptation with little overhead. We show that mixing experts during inference, using a parameter-free weighted ensemble, allows the model to better generalize to heterogeneous or unseen domains. We also show that experts can be added to iteratively incorporate new domains without forgetting older ones, and that experts can be removed to restrict access to unwanted domains, without additional training. Overall, these results demonstrate beneﬁts of explicitly conditioning on textual domains during language modeling.},
	language = {en},
	urldate = {2022-01-15},
	journal = {arXiv:2108.05036 [cs]},
	author = {Gururangan, Suchin and Lewis, Mike and Holtzman, Ari and Smith, Noah A. and Zettlemoyer, Luke},
	month = aug,
	year = {2021},
	note = {arXiv: 2108.05036},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{ren2015FasterRCNNRealTime,
	title = {Faster {R}-{CNN}: {Towards} {Real}-{Time} {Object} {Detection} with {Region} {Proposal} {Networks}},
	shorttitle = {Faster {R}-{CNN}},
	url = {https://arxiv.org/abs/1506.01497v3},
	abstract = {State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features---using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available.},
	language = {en},
	urldate = {2021-11-21},
	author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
	month = jun,
	year = {2015},
}

@article{mikolov2013EfficientEstimationWord,
	title = {Efficient {Estimation} of {Word} {Representations} in {Vector} {Space}},
	url = {http://arxiv.org/abs/1301.3781},
	abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
	urldate = {2021-10-21},
	journal = {arXiv:1301.3781 [cs]},
	author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	month = sep,
	year = {2013},
	note = {arXiv: 1301.3781},
	keywords = {Computer Science - Computation and Language},
}
@article{aghajanyan2020intrinsic,
  title={Intrinsic dimensionality explains the effectiveness of language model fine-tuning},
  author={Aghajanyan, Armen and Zettlemoyer, Luke and Gupta, Sonal},
  journal={arXiv preprint arXiv:2012.13255},
  year={2020}
}
@article{gu2019BadNetsIdentifyingVulnerabilities,
	title = {{BadNets}: {Identifying} {Vulnerabilities} in the {Machine} {Learning} {Model} {Supply} {Chain}},
	shorttitle = {{BadNets}},
	url = {http://arxiv.org/abs/1708.06733},
	abstract = {Deep learning-based techniques have achieved state-of-the-art performance on a wide variety of recognition and classification tasks. However, these networks are typically computationally expensive to train, requiring weeks of computation on many GPUs; as a result, many users outsource the training procedure to the cloud or rely on pre-trained models that are then fine-tuned for a specific task. In this paper we show that outsourced training introduces new security risks: an adversary can create a maliciously trained network (a backdoored neural network, or a {\textbackslash}emph\{BadNet\}) that has state-of-the-art performance on the user's training and validation samples, but behaves badly on specific attacker-chosen inputs. We first explore the properties of BadNets in a toy example, by creating a backdoored handwritten digit classifier. Next, we demonstrate backdoors in a more realistic scenario by creating a U.S. street sign classifier that identifies stop signs as speed limits when a special sticker is added to the stop sign; we then show in addition that the backdoor in our US street sign detector can persist even if the network is later retrained for another task and cause a drop in accuracy of \{25\}{\textbackslash}\% on average when the backdoor trigger is present. These results demonstrate that backdoors in neural networks are both powerful and---because the behavior of neural networks is difficult to explicate---stealthy. This work provides motivation for further research into techniques for verifying and inspecting neural networks, just as we have developed tools for verifying and debugging software.},
	urldate = {2022-01-25},
	journal = {arXiv:1708.06733 [cs]},
	author = {Gu, Tianyu and Dolan-Gavitt, Brendan and Garg, Siddharth},
	month = mar,
	year = {2019},
	note = {arXiv: 1708.06733},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
}

@article{ren2020AdversarialAttacksDefenses,
	title = {Adversarial {Attacks} and {Defenses} in {Deep} {Learning}},
	volume = {6},
	issn = {20958099},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S209580991930503X},
	doi = {10.1016/j.eng.2019.12.012},
	abstract = {With the rapid developments of artiﬁcial intelligence (AI) and deep learning (DL) techniques, it is critical to ensure the security and robustness of the deployed algorithms. Recently, the security vulnerability of DL algorithms to adversarial samples has been widely recognized. The fabricated samples can lead to various misbehaviors of the DL models while being perceived as benign by humans. Successful implementations of adversarial attacks in real physical-world scenarios further demonstrate their practicality. Hence, adversarial attack and defense techniques have attracted increasing attention from both machine learning and security communities and have become a hot research topic in recent years. In this paper, we ﬁrst introduce the theoretical foundations, algorithms, and applications of adversarial attack techniques. We then describe a few research efforts on the defense techniques, which cover the broad frontier in the ﬁeld. Several open problems and challenges are subsequently discussed, which we hope will provoke further research efforts in this critical area.},
	language = {en},
	number = {3},
	urldate = {2022-01-25},
	journal = {Engineering},
	author = {Ren, Kui and Zheng, Tianhang and Qin, Zhan and Liu, Xue},
	month = mar,
	year = {2020},
	pages = {346--360},
}

@inproceedings{dong2018BoostingAdversarialAttacks,
	address = {Salt Lake City, UT},
	title = {Boosting {Adversarial} {Attacks} with {Momentum}},
	isbn = {978-1-5386-6420-9},
	url = {https://ieeexplore.ieee.org/document/8579055/},
	doi = {10.1109/CVPR.2018.00957},
	abstract = {Deep neural networks are vulnerable to adversarial examples, which poses security concerns on these algorithms due to the potentially severe consequences. Adversarial attacks serve as an important surrogate to evaluate the robustness of deep learning models before they are deployed. However, most of existing adversarial attacks can only fool a black-box model with a low success rate. To address this issue, we propose a broad class of momentum-based iterative algorithms to boost adversarial attacks. By integrating the momentum term into the iterative process for attacks, our methods can stabilize update directions and escape from poor local maxima during the iterations, resulting in more transferable adversarial examples. To further improve the success rates for black-box attacks, we apply momentum iterative algorithms to an ensemble of models, and show that the adversarially trained models with a strong defense ability are also vulnerable to our black-box attacks. We hope that the proposed methods will serve as a benchmark for evaluating the robustness of various deep models and defense methods. With this method, we won the ﬁrst places in NIPS 2017 Non-targeted Adversarial Attack and Targeted Adversarial Attack competitions.},
	language = {en},
	urldate = {2022-01-26},
	booktitle = {2018 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Dong, Yinpeng and Liao, Fangzhou and Pang, Tianyu and Su, Hang and Zhu, Jun and Hu, Xiaolin and Li, Jianguo},
	month = jun,
	year = {2018},
	pages = {9185--9193},
}

@article{kurakin2017AdversarialExamplesPhysical,
	title = {Adversarial examples in the physical world},
	url = {http://arxiv.org/abs/1607.02533},
	abstract = {Most existing machine learning classifiers are highly vulnerable to adversarial examples. An adversarial example is a sample of input data which has been modified very slightly in a way that is intended to cause a machine learning classifier to misclassify it. In many cases, these modifications can be so subtle that a human observer does not even notice the modification at all, yet the classifier still makes a mistake. Adversarial examples pose security concerns because they could be used to perform an attack on machine learning systems, even if the adversary has no access to the underlying model. Up to now, all previous work have assumed a threat model in which the adversary can feed data directly into the machine learning classifier. This is not always the case for systems operating in the physical world, for example those which are using signals from cameras and other sensors as an input. This paper shows that even in such physical world scenarios, machine learning systems are vulnerable to adversarial examples. We demonstrate this by feeding adversarial images obtained from cell-phone camera to an ImageNet Inception classifier and measuring the classification accuracy of the system. We find that a large fraction of adversarial examples are classified incorrectly even when perceived through the camera.},
	urldate = {2022-01-26},
	journal = {arXiv:1607.02533 [cs, stat]},
	author = {Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
	month = feb,
	year = {2017},
	note = {arXiv: 1607.02533},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{xie2017AdversarialExamplesSemantic,
	title = {Adversarial {Examples} for {Semantic} {Segmentation} and {Object} {Detection}},
	url = {http://arxiv.org/abs/1703.08603},
	abstract = {It has been well demonstrated that adversarial examples, i.e., natural images with visually imperceptible perturbations added, generally exist for deep networks to fail on image classification. In this paper, we extend adversarial examples to semantic segmentation and object detection which are much more difficult. Our observation is that both segmentation and detection are based on classifying multiple targets on an image (e.g., the basic target is a pixel or a receptive field in segmentation, and an object proposal in detection), which inspires us to optimize a loss function over a set of pixels/proposals for generating adversarial perturbations. Based on this idea, we propose a novel algorithm named Dense Adversary Generation (DAG), which generates a large family of adversarial examples, and applies to a wide range of state-of-the-art deep networks for segmentation and detection. We also find that the adversarial perturbations can be transferred across networks with different training data, based on different architectures, and even for different recognition tasks. In particular, the transferability across networks with the same architecture is more significant than in other cases. Besides, summing up heterogeneous perturbations often leads to better transfer performance, which provides an effective method of black-box adversarial attack.},
	urldate = {2022-01-25},
	journal = {arXiv:1703.08603 [cs]},
	author = {Xie, Cihang and Wang, Jianyu and Zhang, Zhishuai and Zhou, Yuyin and Xie, Lingxi and Yuille, Alan},
	month = jul,
	year = {2017},
	note = {arXiv: 1703.08603},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{naseer2019CrossDomainTransferabilityAdversarial,
	title = {Cross-{Domain} {Transferability} of {Adversarial} {Perturbations}},
	url = {http://arxiv.org/abs/1905.11736},
	abstract = {Adversarial examples reveal the blind spots of deep neural networks (DNNs) and represent a major concern for security-critical applications. The transferability of adversarial examples makes real-world attacks possible in black-box settings, where the attacker is forbidden to access the internal parameters of the model. The underlying assumption in most adversary generation methods, whether learning an instance-specific or an instance-agnostic perturbation, is the direct or indirect reliance on the original domain-specific data distribution. In this work, for the first time, we demonstrate the existence of domain-invariant adversaries, thereby showing common adversarial space among different datasets and models. To this end, we propose a framework capable of launching highly transferable attacks that crafts adversarial patterns to mislead networks trained on wholly different domains. For instance, an adversarial function learned on Paintings, Cartoons or Medical images can successfully perturb ImageNet samples to fool the classifier, with success rates as high as \${\textbackslash}sim\$99{\textbackslash}\% (\${\textbackslash}ell\_\{{\textbackslash}infty\} {\textbackslash}le 10\$). The core of our proposed adversarial function is a generative network that is trained using a relativistic supervisory signal that enables domain-invariant perturbations. Our approach sets the new state-of-the-art for fooling rates, both under the white-box and black-box scenarios. Furthermore, despite being an instance-agnostic perturbation function, our attack outperforms the conventionally much stronger instance-specific attack methods.},
	language = {en},
	urldate = {2022-01-16},
	journal = {arXiv:1905.11736 [cs]},
	author = {Naseer, Muzammal and Khan, Salman H. and Khan, Harris and Khan, Fahad Shahbaz and Porikli, Fatih},
	month = oct,
	year = {2019},
	note = {arXiv: 1905.11736},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@book{stevens2020DeepLearningPyTorch,
	title = {Deep {Learning} with {PyTorch}},
	isbn = {978-1-61729-526-3},
	abstract = {Every other day we hear about new ways to put deep learning to good use: improved medical imaging, accurate credit card fraud detection, long range weather forecasting, and more. PyTorch puts these superpowers in your hands, providing a comfortable Python experience that gets you started quickly and then grows with you as you—and your deep learning skills—become more sophisticated. Deep Learning with PyTorch will make that journey engaging and fun.Summary Every other day we hear about new ways to put deep learning to good use: improved medical imaging, accurate credit card fraud detection, long range weather forecasting, and more. PyTorch puts these superpowers in your hands, providing a comfortable Python experience that gets you started quickly and then grows with you as you—and your deep learning skills—become more sophisticated. Deep Learning with PyTorch will make that journey engaging and fun.  Foreword by Soumith Chintala, Cocreator of PyTorch. Purchase of the print book includes a free eBook in PDF, Kindle, and ePub formats from Manning Publications.  About the technology Although many deep learning tools use Python, the PyTorch library is truly Pythonic. Instantly familiar to anyone who knows PyData tools like NumPy and scikit-learn, PyTorch simplifies deep learning without sacrificing advanced features. It’s excellent for building quick models, and it scales smoothly from laptop to enterprise. Because companies like Apple, Facebook, and JPMorgan Chase rely on PyTorch, it’s a great skill to have as you expand your career options. It’s easy to get started with PyTorch. It minimizes cognitive overhead without sacrificing the access to advanced features, meaning you can focus on what matters the most - building and training the latest and greatest deep learning models and contribute to making a dent in the world. PyTorch is also a snap to scale and extend, and it partners well with other Python tooling. PyTorch has been adopted by hundreds of deep learning practitioners and several first-class players like FAIR, OpenAI, FastAI and Purdue.  About the book Deep Learning with PyTorch teaches you to create neural networks and deep learning systems with PyTorch. This practical book quickly gets you to work building a real-world example from scratch: a tumor image classifier. Along the way, it covers best practices for the entire DL pipeline, including the PyTorch Tensor API, loading data in Python, monitoring training, and visualizing results. After covering the basics, the book will take you on a journey through larger projects. The centerpiece of the book is a neural network designed for cancer detection. You'll discover ways for training networks with limited inputs and start processing data to get some results. You'll sift through the unreliable initial results and focus on how to diagnose and fix the problems in your neural network. Finally, you'll look at ways to improve your results by training with augmented data, make improvements to the model architecture, and perform other fine tuning.  What's inside  Training deep neural networks Implementing modules and loss functions Utilizing pretrained models from PyTorch Hub Exploring code samples in Jupyter Notebooks  About the reader For Python programmers with an interest in machine learning.  About the author Eli Stevens had roles from software engineer to CTO, and is currently working on machine learning in the self-driving-car industry. Luca Antiga is cofounder of an AI engineering company and an AI tech startup, as well as a former PyTorch contributor. Thomas Viehmann is a PyTorch core developer and machine learning trainer and consultant. consultant based in Munich, Germany and a PyTorch core developer.  Table of Contents  PART 1 - CORE PYTORCH  1 Introducing deep learning and the PyTorch Library  2 Pretrained networks  3 It starts with a tensor  4 Real-world data representation using tensors  5 The mechanics of learning  6 Using a neural network to fit the data  7 Telling birds from airplanes: Learning from images  8 Using convolutions to generalize  PART 2 - LEARNING FROM IMAGES IN THE REAL WORLD: EARLY DETECTION OF LUNG CANCER  9 Using PyTorch to fight cancer  10 Combining data sources into a unified dataset  11 Training a classification model to detect suspected tumors  12 Improving training with metrics and augmentation  13 Using segmentation to find suspected nodules  14 End-to-end nodule analysis, and where to go next  PART 3 - DEPLOYMENT  15 Deploying to production},
	language = {en},
	publisher = {Simon and Schuster},
	author = {Stevens, Eli and Antiga, Luca and Viehmann, Thomas},
	month = aug,
	year = {2020},
	note = {Google-Books-ID: fff1DwAAQBAJ},
	keywords = {Computers / Data Processing, Computers / Intelligence (AI) \& Semantics, Computers / Machine Theory},
}

@article{dosovitskiy2020ImageWorth16x16,
	title = {An {Image} is {Worth} 16x16 {Words}: {Transformers} for {Image} {Recognition} at {Scale}},
	shorttitle = {An {Image} is {Worth} 16x16 {Words}},
	url = {https://arxiv.org/abs/2010.11929v2},
	abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
	language = {en},
	urldate = {2021-11-21},
	author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
	month = oct,
	year = {2020},
}

@article{he2015DeepResidualLearning,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	url = {https://arxiv.org/abs/1512.03385v1},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	language = {en},
	urldate = {2021-11-21},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
}

@article{vaswani2017AttentionAllYou,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2021-10-28},
	journal = {arXiv:1706.03762 [cs]},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = dec,
	year = {2017},
	note = {arXiv: 1706.03762},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{peters2018DeepContextualizedWord,
	title = {Deep contextualized word representations},
	url = {http://arxiv.org/abs/1802.05365},
	abstract = {We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.},
	urldate = {2021-10-21},
	journal = {arXiv:1802.05365 [cs]},
	author = {Peters, Matthew E. and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
	month = mar,
	year = {2018},
	note = {arXiv: 1802.05365},
	keywords = {Computer Science - Computation and Language},
}

@article{narasimhan2021CLIPItLanguageGuidedVideo,
	title = {{CLIP}-{It}! {Language}-{Guided} {Video} {Summarization}},
	url = {http://arxiv.org/abs/2107.00650},
	abstract = {A generic video summary is an abridged version of a video that conveys the whole story and features the most important scenes. Yet the importance of scenes in a video is often subjective, and users should have the option of customizing the summary by using natural language to specify what is important to them. Further, existing models for fully automatic generic summarization have not exploited available language models, which can serve as an effective prior for saliency. This work introduces CLIP-It, a single framework for addressing both generic and query-focused video summarization, typically approached separately in the literature. We propose a language-guided multimodal transformer that learns to score frames in a video based on their importance relative to one another and their correlation with a user-defined query (for query-focused summarization) or an automatically generated dense video caption (for generic video summarization). Our model can be extended to the unsupervised setting by training without ground-truth supervision. We outperform baselines and prior work by a significant margin on both standard video summarization datasets (TVSum and SumMe) and a query-focused video summarization dataset (QFVS). Particularly, we achieve large improvements in the transfer setting, attesting to our method's strong generalization capabilities.},
	urldate = {2021-10-17},
	journal = {arXiv:2107.00650 [cs]},
	author = {Narasimhan, Medhini and Rohrbach, Anna and Darrell, Trevor},
	month = jul,
	year = {2021},
	note = {arXiv: 2107.00650},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Multimedia},
}

@inproceedings{sharif2016AccessorizeCrimeReal,
	address = {Vienna Austria},
	title = {Accessorize to a {Crime}: {Real} and {Stealthy} {Attacks} on {State}-of-the-{Art} {Face} {Recognition}},
	isbn = {978-1-4503-4139-4},
	shorttitle = {Accessorize to a {Crime}},
	url = {https://dl.acm.org/doi/10.1145/2976749.2978392},
	doi = {10.1145/2976749.2978392},
	abstract = {Machine learning is enabling a myriad innovations, including new algorithms for cancer diagnosis and self-driving cars. The broad use of machine learning makes it important to understand the extent to which machine-learning algorithms are subject to attack, particularly when used in applications where physical security or safety is at risk.},
	language = {en},
	urldate = {2022-01-25},
	booktitle = {Proceedings of the 2016 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Sharif, Mahmood and Bhagavatula, Sruti and Bauer, Lujo and Reiter, Michael K.},
	month = oct,
	year = {2016},
	pages = {1528--1540},
}

@article{duchi2011AdaptiveSubgradientMethods,
	title = {Adaptive {Subgradient} {Methods} for {Online} {Learning} and {Stochastic} {Optimization}},
	abstract = {We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to ﬁnd needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which signiﬁcantly simpliﬁes setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efﬁcient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms.},
	language = {en},
	author = {Duchi, John and Hazan, Elad and Singer, Yoram},
	year = {2011},
	pages = {39},
}
@article{RXF,
  title={Better fine-tuning by reducing representational collapse},
  author={Aghajanyan, Armen and Shrivastava, Akshat and Gupta, Anchit and Goyal, Naman and Zettlemoyer, Luke and Gupta, Sonal},
  journal={arXiv preprint arXiv:2008.03156},
  year={2020}
}
@article{gpt3,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@article{micikevicius2017mixed,
  title={Mixed precision training},
  author={Micikevicius, Paulius and Narang, Sharan and Alben, Jonah and Diamos, Gregory and Elsen, Erich and Garcia, David and Ginsburg, Boris and Houston, Michael and Kuchaiev, Oleksii and Venkatesh, Ganesh and others},
  journal={arXiv preprint arXiv:1710.03740},
  year={2017}
}

@article{hendrycks2016gaussian,
  title={Gaussian error linear units (gelus)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@article{zhang2022opt,
  title={OPT: Open Pre-trained Transformer Language Models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}


@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}


@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{efficient_lm_xlm_g,
  title={Efficient Large Scale Language Modeling with Mixtures of Experts},
  author={Artetxe, Mikel and Bhosale, Shruti and Goyal, Naman and Mihaylov, Todor and Ott, Myle and Shleifer, Sam and Lin, Xi Victoria and Du, Jingfei and Iyer, Srinivasan and Pasunuru, Ramakanth and others},
  journal={arXiv preprint arXiv:2112.10684},
  year={2021}
}
@article{pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  pages={8026--8037},
  year={2019}
}
@article{fairseq,
  title={fairseq: A fast, extensible toolkit for sequence modeling},
  author={Ott, Myle and Edunov, Sergey and Baevski, Alexei and Fan, Angela and Gross, Sam and Ng, Nathan and Grangier, David and Auli, Michael},
  journal={arXiv preprint arXiv:1904.01038},
  year={2019}
}
@Misc{fairscale,
  author =       {Mandeep Baines and Shruti Bhosale and Vittorio Caggiano and Naman Goyal and Siddharth Goyal and Myle Ott and Benjamin Lefaudeux and Vitaliy Liptchinsky and Mike Rabbat and Sam Sheiffer and Anjali Sridhar and Min Xu},
  title =        {FairScale:  A general purpose modular PyTorch library for high performance and large scale training},
  howpublished = {\url{https://github.com/facebookresearch/fairscale}},
  year =         {2021}
}

% training dynamics citations

@article{raghu2017svcca,
  title={Svcca: Singular vector canonical correlation analysis for deep learning dynamics and interpretability},
  author={Raghu, Maithra and Gilmer, Justin and Yosinski, Jason and Sohl-Dickstein, Jascha},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{gur2018gradient,
  title={Gradient descent happens in a tiny subspace},
  author={Gur-Ari, Guy and Roberts, Daniel A and Dyer, Ethan},
  journal={arXiv preprint arXiv:1812.04754},
  year={2018}
}

@article{frankle2020early,
  title={The early phase of neural network training},
  author={Frankle, Jonathan and Schwab, David J and Morcos, Ari S},
  journal={arXiv preprint arXiv:2002.10365},
  year={2020}
}

@inproceedings{achille2018critical,
  title={Critical learning periods in deep networks},
  author={Achille, Alessandro and Rovere, Matteo and Soatto, Stefano},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{morcos2018insights,
  title={Insights on representational similarity in neural networks with canonical correlation},
  author={Morcos, Ari and Raghu, Maithra and Bengio, Samy},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{saphra2018understanding,
  title={Understanding learning dynamics of language models with SVCCA},
  author={Saphra, Naomi and Lopez, Adam},
  journal={arXiv preprint arXiv:1811.00225},
  year={2018}
}

@article{liu2021probing,
  title={Probing across time: What does RoBERTa know and when?},
  author={Liu, Leo Z and Wang, Yizhong and Kasai, Jungo and Hajishirzi, Hannaneh and Smith, Noah A},
  journal={arXiv preprint arXiv:2104.07885},
  year={2021}
}

@article{chiang2020pretrained,
  title={Pretrained language model embryology: The birth of ALBERT},
  author={Chiang, Cheng-Han and Huang, Sung-Feng and Lee, Hung-yi},
  journal={arXiv preprint arXiv:2010.02480},
  year={2020}
}

@article{choshen2021grammar,
  title={The grammar-learning trajectories of neural language models},
  author={Choshen, Leshem and Hacohen, Guy and Weinshall, Daphna and Abend, Omri},
  journal={arXiv preprint arXiv:2109.06096},
  year={2021}
}

@article{blevins2022analyzing,
  title={Analyzing the Mono-and Cross-Lingual Pretraining Dynamics of Multilingual Language Models},
  author={Blevins, Terra and Gonen, Hila and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2205.11758},
  year={2022}
}

@article{chang-bergen-2022-word,
    title = "Word Acquisition in Neural Language Models",
    author = "Chang, Tyler A.  and
      Bergen, Benjamin K.",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "10",
    year = "2022",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2022.tacl-1.1",
    doi = "10.1162/tacl_a_00444",
    pages = "1--16",
    abstract = "We investigate how neural language models acquire individual words during training, extracting learning curves and ages of acquisition for over 600 words on the MacArthur-Bates Communicative Development Inventory (Fenson et al., 2007). Drawing on studies of word acquisition in children, we evaluate multiple predictors for words{'} ages of acquisition in LSTMs, BERT, and GPT-2. We find that the effects of concreteness, word length, and lexical class are pointedly different in children and language models, reinforcing the importance of interaction and sensorimotor experience in child language acquisition. Language models rely far more on word frequency than children, but, like children, they exhibit slower learning of words in longer utterances. Interestingly, models follow consistent patterns during training for both unidirectional and bidirectional models, and for both LSTM and Transformer architectures. Models predict based on unigram token frequencies early in training, before transitioning loosely to bigram probabilities, eventually converging on more nuanced predictions. These results shed light on the role of distributional learning mechanisms in children, while also providing insights for more human-like language acquisition in language models.",
}

@article{goyal2021training,
  title={Training dynamics for text summarization models},
  author={Goyal, Tanya and Xu, Jiacheng and Li, Junyi Jessy and Durrett, Greg},
  journal={arXiv preprint arXiv:2110.08370},
  year={2021}
}

@inproceedings{voita-etal-2021-analyzing,
    title = "Analyzing the Source and Target Contributions to Predictions in Neural Machine Translation",
    author = "Voita, Elena  and
      Sennrich, Rico  and
      Titov, Ivan",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.91",
    doi = "10.18653/v1/2021.acl-long.91",
    pages = "1126--1140",
    abstract = "In Neural Machine Translation (and, more generally, conditional language modeling), the generation of a target token is influenced by two types of context: the source and the prefix of the target sequence. While many attempts to understand the internal workings of NMT models have been made, none of them explicitly evaluates relative source and target contributions to a generation decision. We argue that this relative contribution can be evaluated by adopting a variant of Layerwise Relevance Propagation (LRP). Its underlying {`}conservation principle{'} makes relevance propagation unique: differently from other methods, it evaluates not an abstract quantity reflecting token importance, but the proportion of each token{'}s influence. We extend LRP to the Transformer and conduct an analysis of NMT models which explicitly evaluates the source and target relative contributions to the generation process. We analyze changes in these contributions when conditioning on different types of prefixes, when varying the training objective or the amount of training data, and during the training process. We find that models trained with more data tend to rely on source information more and to have more sharp token contributions; the training process is non-monotonic with several stages of different nature.",
}

@inproceedings{stadler2021observing,
  title={Observing the Learning Curve of NMT Systems With Regard to Linguistic Phenomena},
  author={Stadler, Patrick and Macketanz, Vivien and Avramidis, Eleftherios},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop},
  pages={186--196},
  year={2021}
}

@inproceedings{savoldi-etal-2022-dynamics,
    title = "On the Dynamics of Gender Learning in Speech Translation",
    author = "Savoldi, Beatrice  and
      Gaido, Marco  and
      Bentivogli, Luisa  and
      Negri, Matteo  and
      Turchi, Marco",
    booktitle = "Proceedings of the 4th Workshop on Gender Bias in Natural Language Processing (GeBNLP)",
    month = jul,
    year = "2022",
    address = "Seattle, Washington",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.gebnlp-1.12",
    pages = "94--111",
    abstract = "Due to the complexity of bias and the opaque nature of current neural approaches, there is a rising interest in auditing language technologies. In this work, we contribute to such a line of inquiry by exploring the emergence of gender bias in Speech Translation (ST). As a new perspective, rather than focusing on the final systems only, we examine their evolution over the course of training. In this way, we are able to account for different variables related to the learning dynamics of gender translation, and investigate when and how gender divides emerge in ST. Accordingly, for three language pairs (en ? es, fr, it) we compare how ST systems behave for masculine and feminine translation at several levels of granularity. We find that masculine and feminine curves are dissimilar, with the feminine one being characterized by more erratic behaviour and late improvements over the course of training. Also, depending on the considered phenomena, their learning trends can be either antiphase or parallel. Overall, we show how such a progressive analysis can inform on the reliability and time-wise acquisition of gender, which is concealed by static evaluations and standard metrics.",
}

@inproceedings{merchant-etal-2020-happens,
    title = "What Happens To {BERT} Embeddings During Fine-tuning?",
    author = "Merchant, Amil  and
      Rahimtoroghi, Elahe  and
      Pavlick, Ellie  and
      Tenney, Ian",
    booktitle = "Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.blackboxnlp-1.4",
    doi = "10.18653/v1/2020.blackboxnlp-1.4",
    pages = "33--44",
    abstract = "While much recent work has examined how linguistic information is encoded in pre-trained sentence representations, comparatively little is understood about how these models change when adapted to solve downstream tasks. Using a suite of analysis techniques{---}supervised probing, unsupervised similarity analysis, and layer-based ablations{---}we investigate how fine-tuning affects the representations of the BERT model. We find that while fine-tuning necessarily makes some significant changes, there is no catastrophic forgetting of linguistic phenomena. We instead find that fine-tuning is a conservative process that primarily affects the top layers of BERT, albeit with noteworthy variation across tasks. In particular, dependency parsing reconfigures most of the model, whereas SQuAD and MNLI involve much shallower processing. Finally, we also find that fine-tuning has a weaker effect on representations of out-of-domain sentences, suggesting room for improvement in model generalization.",
}

@inproceedings{hao-etal-2020-investigating,
    title = "Investigating Learning Dynamics of {BERT} Fine-Tuning",
    author = "Hao, Yaru  and
      Dong, Li  and
      Wei, Furu  and
      Xu, Ke",
    booktitle = "Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing",
    month = dec,
    year = "2020",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.aacl-main.11",
    pages = "87--92",
    abstract = "The recently introduced pre-trained language model BERT advances the state-of-the-art on many NLP tasks through the fine-tuning approach, but few studies investigate how the fine-tuning process improves the model performance on downstream tasks. In this paper, we inspect the learning dynamics of BERT fine-tuning with two indicators. We use JS divergence to detect the change of the attention mode and use SVCCA distance to examine the change to the feature extraction mode during BERT fine-tuning. We conclude that BERT fine-tuning mainly changes the attention mode of the last layers and modifies the feature extraction mode of the intermediate and last layers. Moreover, we analyze the consistency of BERT fine-tuning between different random seeds and different datasets. In summary, we provide a distinctive understanding of the learning dynamics of BERT fine-tuning, which sheds some light on improving the fine-tuning results.",
}

% repeat before forgetting citation

@inproceedings{amiri2017repeat,
  title={Repeat before forgetting: Spaced repetition for efficient and effective training of neural networks},
  author={Amiri, Hadi and Miller, Timothy and Savova, Guergana},
  booktitle={Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  pages={2401--2410},
  year={2017}
}

% RAVEN paper (ngram wikitext103 supercopying)
@article{mccoy2021much,
  title={How much do language models copy from their training data? evaluating linguistic novelty in text generation using raven},
  author={McCoy, R Thomas and Smolensky, Paul and Linzen, Tal and Gao, Jianfeng and Celikyilmaz, Asli},
  journal={arXiv preprint arXiv:2111.09509},
  year={2021}
}


% Armen
@software{Arakelyan_Aim_2020,
author = {Arakelyan, Gor and Soghomonyan, Gevorg and {The Aim team}},
doi = {10.5281/zenodo.6536395},
license = {Apache-2.0},
month = {6},
title = {{Aim}},
url = {https://github.com/aimhubio/aim},
version = {3.9.3},
year = {2020}
}