@article{yu2022strength,
  title={Strength-Adaptive Adversarial Training},
  author={Yu, Chaojian and Zhou, Dawei and Shen, Li and Yu, Jun and Han, Bo and Gong, Mingming and Wang, Nannan and Liu, Tongliang},
  journal={arXiv preprint arXiv:2210.01288},
  year={2022}
}

@inproceedings{wei2023cfa,
  title={Cfa: Class-wise calibrated fair adversarial training},
  author={Wei, Zeming and Wang, Yifei and Guo, Yiwen and Wang, Yisen},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{luo2023rethinking,
  title={Rethinking the Effect of Data Augmentation in Adversarial Contrastive Learning},
  author={Luo, Rundong and Wang, Yifei and Wang, Yisen},
  booktitle={ICLR},
  year={2023}
}

@inproceedings{wang2022self,
  title={Self-ensemble adversarial training for improved robustness},
  author={Wang, Hongjun and Wang, Yisen},
  booktitle={ICLR},
  year={2022}
}

@inproceedings{wang2021convergence,
  title={On the convergence and robustness of adversarial training},
  author={Wang, Yisen and Ma, Xingjun and Bailey, James and Yi, Jinfeng and Zhou, Bowen and Gu, Quanquan},
  booktitle={ICML},
  year={2019}
}

@inproceedings{li2023adversarial,
  title={Adversarial examples are not real features},
  author={Li, Ang and Wang, Yifei and Wang, Yisen},
  booktitle={NeurIPS},
  year={2023}
}

@article{wang2021fooling,
  title={Fooling adversarial training with inducing noise},
  author={Wang, Zhirui and Wang, Yifei and Wang, Yisen},
  journal={arXiv preprint arXiv:2111.10130},
  year={2021}
}

@article{wang2020decoder,
  title={Decoder-free Robustness Disentanglement without (Additional) Supervision},
  author={Wang, Yifei and Peng, Dan and Liu, Furui and Li, Zhenguo and Chen, Zhitang and Yang, Jiansheng},
  journal={arXiv preprint arXiv:2007.01356},
  year={2020}
}

@inproceedings{wang2020improving,
                      title={Improving Adversarial Robustness Requires Revisiting Misclassified Examples},
                      author={Yisen Wang and Difan Zou and Jinfeng Yi and James Bailey and Xingjun Ma and Quanquan Gu},
                      booktitle={ICLR},
                      year={2020}}

@inproceedings{wang2022unified,
  title={A unified contrastive energy-based model for understanding the generative ability of adversarial training},
  author={Wang, Yifei and Wang, Yisen and Yang, Jiansheng and Lin, Zhouchen},
  booktitle={ICLR},
  year={2022}
}

@inproceedings{ren2021unified,
                        title={A unified game-theoretic interpretation of adversarial robustness},
                        author={Ren, Jie and Zhang, Die and Wang, Yisen and Chen, Lu and Zhou, Zhanpeng and Chen, Yiting and Cheng, Xu and Wang, Xin and Zhou, Meng and Shi, Jie and others},
                        booktitle={NeurIPS},
                        year={2021}}

@article{engstrom2019adversarial,
  title={Adversarial robustness as a prior for learned representations},
  author={Engstrom, Logan and Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Tran, Brandon and Madry, Aleksander},
  journal={arXiv preprint arXiv:1906.00945},
  year={2019}
}

@inproceedings{santurkar2019image,
  title={Image synthesis with a single (robust) classifier},
  author={Santurkar, Shibani and Ilyas, Andrew and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander},
  booktitle={NeurIPS},
  year={2019}
}

@inproceedings{wang2023simple,
                        title={Generalist: Decoupling Natural and Robust Generalization},
                        author={Hongjun Wang and Yisen Wang},
                        booktitle={CVPR},
                        year={2023}}

@inproceedings{balcan2023nash,
  title={Nash equilibria and pitfalls of adversarial training in adversarial robustness games},
  author={Balcan, Maria-Florina and Pukdee, Rattana and Ravikumar, Pradeep and Zhang, Hongyang},
  booktitle={AISTATS},
  year={2023},
}

@inproceedings{pinot2020randomization,
  title={Randomization matters how to defend against strong adversarial attacks},
  author={Pinot, Rafael and Ettedgui, Raphael and Rizk, Geovani and Chevaleyre, Yann and Atif, Jamal},
  booktitle={ICML},
  year={2020},
}

@inproceedings{huang2021unlearnable,
                        title={Unlearnable Examples: Making Personal Data Unexploitable},
                        author={Huang, Hanxun and Ma, Xingjun and Erfani, Sarah Monazam and Bailey, James and Wang, Yisen},
                        booktitle={ICLR},
                        year={2021}}

@inproceedings{bose2020adversarial,
  title={Adversarial example games},
  author={Bose, Joey and Gidel, Gauthier and Berard, Hugo and Cianflone, Andre and Vincent, Pascal and Lacoste-Julien, Simon and Hamilton, Will},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{pal2020game,
  title={A game theoretic analysis of additive adversarial attacks and defenses},
  author={Pal, Ambar and Vidal, Ren{\'e}},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{bai2021improving,
                        title={Improving adversarial robustness via channel-wise activation suppressing},
                        author={Bai, Yang and Zeng, Yuyuan and Jiang, Yong and Xia, Shu-Tao and Ma, Xingjun and Wang, Yisen},
                        booktitle={ICLR},
                        year={2021}}

@article{bulo2016randomized,
  title={Randomized prediction games for adversarial machine learning},
  author={Bul{\`o}, Samuel Rota and Biggio, Battista and Pillai, Ignazio and Pelillo, Marcello and Roli, Fabio},
  journal={IEEE transactions on neural networks and learning systems},
  volume={28},
  number={11},
  pages={2466--2478},
  year={2016},
  publisher={IEEE}
}

@inproceedings{sagawa2019distributionally,
  title={Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization},
  author={Sagawa, Shiori and Koh, Pang Wei and Hashimoto, Tatsunori B and Liang, Percy},
  booktitle={ICLR},
  year={2020}
}

@inproceedings{yu2022understanding,
  title={Understanding robust overfitting of adversarial training and beyond},
  author={Yu, Chaojian and Han, Bo and Shen, Li and Yu, Jun and Gong, Chen and Gong, Mingming and Liu, Tongliang},
  booktitle={ICML},
  year={2022},
}

@article{zhang2021adversarial,
  title={Adversarial robustness through the lens of causality},
  author={Zhang, Yonggang and Gong, Mingming and Liu, Tongliang and Niu, Gang and Tian, Xinmei and Han, Bo and Sch{\"o}lkopf, Bernhard and Zhang, Kun},
  booktitle={ICLR},
  year={2022}
}

@inproceedings{mo2022adversarial,
                      title={When Adversarial Training Meets Vision Transformers: Recipes from Training to Architecture},
                      author={Mo, Yichuan and Wu, Dongxian and Wang, Yifei and Guo, Yiwen and Wang, Yisen},
                      booktitle={NeurIPS},
                      year={2022}}

@inproceedings{qin2019adversarial,
  title={Adversarial robustness through local linearization},
  author={Qin, Chongli and Martens, James and Gowal, Sven and Krishnan, Dilip and Dvijotham, Krishnamurthy and Fawzi, Alhussein and De, Soham and Stanforth, Robert and Kohli, Pushmeet},
  booktitle={NeurIPS},
  year={2019}
}

@inproceedings{cai2018curriculum,
  title={Curriculum adversarial training},
  author={Cai, Qi-Zhi and Du, Min and Liu, Chang and Song, Dawn},
  booktitle={IJCAI},
  year={2018}
}

@article{li2022bag,
  title={Bag of Tricks for FGSM Adversarial Training},
  author={Li, Zichao and Liu, Li and Wang, Zeyu and Zhou, Yuyin and Xie, Cihang},
  journal={arXiv preprint arXiv:2209.02684},
  year={2022}
}

@inproceedings{byol,
  title={Bootstrap your own latent-a new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{yun2019cutmix,
  title={Cutmix: Regularization strategy to train strong classifiers with localizable features},
  author={Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon},
  booktitle={ICCV},
  year={2019}
}

@article{izmailov2018averaging,
  title={Averaging weights leads to wider optima and better generalization},
  author={Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},
  journal={arXiv preprint arXiv:1803.05407},
  year={2018}
}

@inproceedings{li2019towards,
  title={Towards explaining the regularization effect of initial large learning rate in training neural networks},
  author={Li, Yuanzhi and Wei, Colin and Ma, Tengyu},
  booktitle={NeurIPS},
  year={2019}
}

@article{gu2019badnets,
  title={Badnets: Evaluating backdooring attacks on deep neural networks},
  author={Gu, Tianyu and Liu, Kang and Dolan-Gavitt, Brendan and Garg, Siddharth},
  journal={IEEE Access},
  year={2019},
  publisher={IEEE}
}

@inproceedings{saha2020hidden,
  title={Hidden trigger backdoor attacks},
  author={Saha, Aniruddha and Subramanya, Akshayvarun and Pirsiavash, Hamed},
  booktitle={AAAI},
  year={2020}
}

@incollection{cramer2016mathematical,
  title={Mathematical Methods of Statistics},
  author={Cram{\'e}r, Harald},
  booktitle={Mathematical Methods of Statistics},
  year={1946},
  publisher={Princeton university press}
}

@inproceedings{nakkiran2021deep,
  title={Deep double descent: Where bigger models and more data hurt},
  author={Nakkiran, Preetum and Kaplun, Gal and Bansal, Yamini and Yang, Tristan and Barak, Boaz and Sutskever, Ilya},
  booktitle={ICLR},
  year={2020}
}

@article{dong2021double,
  title={Double Descent in Adversarial Training: An Implicit Label Noise Perspective},
  author={Dong, Chengyu and Liu, Liyuan and Shang, Jingbo},
  journal={arXiv preprint arXiv:2110.03135},
  year={2021}
}

@inproceedings{stutz2021relating,
  title={Relating adversarially robust generalization to flat minima},
  author={Stutz, David and Hein, Matthias and Schiele, Bernt},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{zhang2021understanding,
  title={Understanding deep learning (still) requires rethinking generalization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  booktitle={ICLR},
  year={2017},
}

@inproceedings{hoffer2017train,
  title={Train longer, generalize better: closing the generalization gap in large batch training of neural networks},
  author={Hoffer, Elad and Hubara, Itay and Soudry, Daniel},
  booktitle={NeurIPS},
  year={2017}
}

@inproceedings{ilyas2019adversarial,
  title={Adversarial examples are not bugs, they are features},
  author={Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Engstrom, Logan and Tran, Brandon and Madry, Aleksander},
  booktitle={NeurIPS},
  year={2019}
}

@inproceedings{szegedy2014intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  booktitle={ICLR},
  year={2014}
}

@inproceedings{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  booktitle={ICLR},
  year={2015}
}

@inproceedings{madry2018towards,
  title={Towards Deep Learning Models Resistant to Adversarial Attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  booktitle={ICLR},
  year={2018}
}

@inproceedings{athalye2018obfuscated,
  title={Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples},
  author={Athalye, Anish and Carlini, Nicholas and Wagner, David},
  booktitle={ICML},
  year={2018},
}

@inproceedings{zhang2019theoretically,
  title={Theoretically principled trade-off between robustness and accuracy},
  author={Zhang, Hongyang and Yu, Yaodong and Jiao, Jiantao and Xing, Eric and El Ghaoui, Laurent and Jordan, Michael},
  booktitle={ICML},
  year={2019},
}

@inproceedings{wang2019improving,
  title={Improving adversarial robustness requires revisiting misclassified examples},
  author={Wang, Yisen and Zou, Difan and Yi, Jinfeng and Bailey, James and Ma, Xingjun and Gu, Quanquan},
  booktitle={ICLR},
  year={2019}
}

@inproceedings{pang2020bag,
  title={Bag of Tricks for Adversarial Training},
  author={Pang, Tianyu and Yang, Xiao and Dong, Yinpeng and Su, Hang and Zhu, Jun},
  booktitle={ICLR},
  year={2020}
}

@inproceedings{rice2020overfitting,
  title={Overfitting in adversarially robust deep learning},
  author={Rice, Leslie and Wong, Eric and Kolter, Zico},
  booktitle={ICML},
  year={2020},
}

@inproceedings{chen2020robust,
  title={Robust overfitting may be mitigated by properly learned smoothening},
  author={Chen, Tianlong and Zhang, Zhenyu and Liu, Sijia and Chang, Shiyu and Wang, Zhangyang},
  booktitle={ICLR},
  year={2021}
}

@inproceedings{rebuffi2021data,
  title={Data Augmentation Can Improve Robustness},
  author={Rebuffi, Sylvestre-Alvise and Gowal, Sven and Calian, Dan Andrei and Stimberg, Florian and Wiles, Olivia and Mann, Timothy A},
  booktitle={NeurIPS},
  year={2021}
}

@inproceedings{dong2021exploring,
  title={Exploring memorization in adversarial training},
  author={Dong, Yinpeng and Xu, Ke and Yang, Xiao and Pang, Tianyu and Deng, Zhijie and Su, Hang and Zhu, Jun},
  booktitle={ICLR},
  year={2022}
}

@article{kurakin2017adversarial,
  title={Adversarial examples in the physical world},
  author={Kurakin, Alexey and Goodfellow, Ian J and Bengio, Samy},
  year={2017}
}

@inproceedings{tsipras2018robustness,
  title={Robustness May Be at Odds with Accuracy},
  author={Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Madry, Aleksander},
  booktitle={ICLR},
  year={2018}
}

@inproceedings{ding2019mma,
  title={MMA Training: Direct Input Space Margin Maximization through Adversarial Training},
  author={Ding, Gavin Weiguang and Sharma, Yash and Lui, Kry Yik Chau and Huang, Ruitong},
  booktitle={ICLR},
  year={2019}
}

@inproceedings{zhang2020geometry,
  title={Geometry-aware Instance-reweighted Adversarial Training},
  author={Zhang, Jingfeng and Zhu, Jianing and Niu, Gang and Han, Bo and Sugiyama, Masashi and Kankanhalli, Mohan},
  booktitle={ICLR},
  year={2020}
}

@inproceedings{zhang2020attacks,
  title={Attacks which do not kill training make adversarial learning stronger},
  author={Zhang, Jingfeng and Xu, Xilie and Han, Bo and Niu, Gang and Cui, Lizhen and Sugiyama, Masashi and Kankanhalli, Mohan},
  booktitle={ICML},
  year={2020},
}

@inproceedings{pang2019improving,
  title={Improving adversarial robustness via promoting ensemble diversity},
  author={Pang, Tianyu and Xu, Kun and Du, Chao and Chen, Ning and Zhu, Jun},
  booktitle={ICML},
  year={2019},
}

@inproceedings{tramer2019adversarial,
  title={Adversarial training and robustness for multiple perturbations},
  author={Tramer, Florian and Boneh, Dan},
  booktitle={NeurIPS},
  year={2019}
}

@article{shafahi2019adversarial,
  title={Adversarial training for free!},
  author={Shafahi, Ali and Najibi, Mahyar and Ghiasi, Mohammad Amin and Xu, Zheng and Dickerson, John and Studer, Christoph and Davis, Larry S and Taylor, Gavin and Goldstein, Tom},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{wong2019fast,
  title={Fast is better than free: Revisiting adversarial training},
  author={Wong, Eric and Rice, Leslie and Kolter, J Zico},
  booktitle={ICLR},
  year={2019}
}


@article{hinton2015distilling,
  title={Distilling the Knowledge in a Neural Network},
  author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
  journal={arXiv preprint arXiv:1503.02531},
  year={2015}
}

@inproceedings{samuli2017temporal,
  title={Temporal ensembling for semi-supervised learning},
  author={Samuli, Laine and Timo, Aila},
  booktitle={ICLR},
  year={2017}
}

@inproceedings{wu2020adversarial,
  title={Adversarial weight perturbation helps robust generalization},
  author={Wu, Dongxian and Xia, Shu-Tao and Wang, Yisen},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{fowl2021adversarial,
  title={Adversarial Examples Make Strong Poisons},
  author={Fowl, Liam H and Goldblum, Micah and Chiang, Ping-yeh and Geiping, Jonas and Czaja, Wojciech and Goldstein, Tom},
  booktitle={NeurIPS},
  year={2021}
}

@inproceedings{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  year={2016}
}

@inproceedings{carlini2017towards,
  title={Towards evaluating the robustness of neural networks},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={2017 ieee symposium on security and privacy (sp)},
  year={2017},
  organization={IEEE}
}

@inproceedings{croce2020reliable,
  title={Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks},
  author={Croce, Francesco and Hein, Matthias},
  booktitle={ICML},
  year={2020},
}

@inproceedings{he2016identity,
  title={Identity mappings in deep residual networks},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={ECCV},
  year={2016},
}

@inproceedings{zagoruyko2016wide,
  title={Wide Residual Networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  booktitle={BMVC},
  year={2016}
}

@article{gowal2020uncovering,
  title={Uncovering the limits of adversarial training against norm-bounded adversarial examples},
  author={Gowal, Sven and Qin, Chongli and Uesato, Jonathan and Mann, Timothy and Kohli, Pushmeet},
  journal={arXiv preprint arXiv:2010.03593},
  year={2020}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={CVPR},
  year={2009}
}

@inproceedings{sandler2018mobilenetv2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={CVPR},
  year={2018}
}

@inproceedings{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  booktitle={ICLR},
  year={2015}
}

@article{ortiz2022catastrophic,
  title={Catastrophic overfitting is a bug but also a feature},
  author={Ortiz-Jim{\'e}nez, Guillermo and de Jorge, Pau and Sanyal, Amartya and Bibi, Adel and Dokania, Puneet K and Frossard, Pascal and Rog{\'e}z, Gregory and Torr, Philip HS},
  journal={arXiv preprint arXiv:2206.08242},
  year={2022}
}

@article{li2018visualizing,
  title={Visualizing the loss landscape of neural nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  journal={NeurIPS},
  year={2018}
}

@inproceedings{addepalli2022scaling,
  title={Scaling adversarial training to large perturbation bounds},
  author={Addepalli, Sravanti and Jain, Samyak and Sriramanan, Gaurang and Venkatesh Babu, R},
  booktitle={ECCV},
  year={2022},
}

@inproceedings{li2023data,
  title={Data Augmentation Alone Can Improve Adversarial Training},
  author={Li, Lin and Spratling, Michael},
  booktitle={ICLR},
  year={2023}
}

@article{li2023understanding,
  title={Understanding and combating robust overfitting via input loss landscape analysis and regularization},
  author={Li, Lin and Spratling, Michael},
  journal={Pattern Recognition},
  year={2023}
}