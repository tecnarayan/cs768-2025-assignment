\begin{thebibliography}{30}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Anandkumar et~al.(2012)Anandkumar, Hsu, and
  Kakade]{anandkumar2012method}
A.~Anandkumar, D.~Hsu, and S.~M. Kakade.
\newblock A method of moments for mixture models and hidden markov models.
\newblock In \emph{Conference on Learning Theory}, pages 33--1, 2012.

\bibitem[Anandkumar et~al.(2014)Anandkumar, Ge, Hsu, Kakade, and
  Telgarsky]{anandkumar2014tensor}
A.~Anandkumar, R.~Ge, D.~Hsu, S.~M. Kakade, and M.~Telgarsky.
\newblock Tensor decompositions for learning latent variable models.
\newblock \emph{Journal of Machine Learning Research}, 15:\penalty0 2773--2832,
  2014.

\bibitem[Azizzadenesheli et~al.(2016)Azizzadenesheli, Lazaric, and
  Anandkumar]{azizzadenesheli2016reinforcement}
K.~Azizzadenesheli, A.~Lazaric, and A.~Anandkumar.
\newblock Reinforcement learning of pomdps using spectral methods.
\newblock \emph{29th Annual Conference on Learning Theory}, 2016.

\bibitem[Bazinin and Shani(2018)]{bazinin2018iterative}
S.~Bazinin and G.~Shani.
\newblock Iterative planning for deterministic qdec-pomdps.
\newblock In \emph{GCAI}, pages 15--28, 2018.

\bibitem[Besse and Chaib-Draa(2009)]{besse2009quasi}
C.~Besse and B.~Chaib-Draa.
\newblock Quasi-deterministic partially observable markov decision processes.
\newblock In \emph{International Conference on Neural Information Processing},
  pages 237--246. Springer, 2009.

\bibitem[Bonet(2012)]{bonet2012deterministic}
B.~Bonet.
\newblock Deterministic pomdps revisited.
\newblock \emph{arXiv preprint arXiv:1205.2659}, 2012.

\bibitem[Boots et~al.(2011)Boots, Siddiqi, and Gordon]{boots2011closing}
B.~Boots, S.~M. Siddiqi, and G.~J. Gordon.
\newblock Closing the learning-planning loop with predictive state
  representations.
\newblock \emph{The International Journal of Robotics Research}, 30\penalty0
  (7):\penalty0 954--966, 2011.

\bibitem[Brown and Sandholm(2018)]{brown2018superhuman}
N.~Brown and T.~Sandholm.
\newblock Superhuman ai for heads-up no-limit poker: Libratus beats top
  professionals.
\newblock \emph{Science}, 359\penalty0 (6374):\penalty0 418--424, 2018.

\bibitem[Carlyle and Paz(1971)]{carlyle1971realizations}
J.~W. Carlyle and A.~Paz.
\newblock Realizations by stochastic finite automata.
\newblock \emph{Journal of Computer and System Sciences}, 5\penalty0
  (1):\penalty0 26--40, 1971.

\bibitem[Cassandra et~al.(1996)Cassandra, Kaelbling, and
  Kurien]{cassandra1996acting}
A.~R. Cassandra, L.~P. Kaelbling, and J.~A. Kurien.
\newblock Acting under uncertainty: Discrete bayesian models for mobile-robot
  navigation.
\newblock In \emph{Proceedings of IEEE/RSJ International Conference on
  Intelligent Robots and Systems. IROS'96}, volume~2, pages 963--972. IEEE,
  1996.

\bibitem[Even-Dar et~al.(2005)Even-Dar, Kakade, and
  Mansour]{even2005reinforcement}
E.~Even-Dar, S.~M. Kakade, and Y.~Mansour.
\newblock Reinforcement learning in pomdps without resets.
\newblock 2005.

\bibitem[Guo et~al.(2016)Guo, Doroudi, and Brunskill]{guo2016pac}
Z.~D. Guo, S.~Doroudi, and E.~Brunskill.
\newblock A pac rl algorithm for episodic pomdps.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 510--518,
  2016.

\bibitem[Hauskrecht and Fraser(2000)]{hauskrecht2000planning}
M.~Hauskrecht and H.~Fraser.
\newblock Planning treatment of ischemic heart disease with partially
  observable markov decision processes.
\newblock \emph{Artificial Intelligence in Medicine}, 18\penalty0 (3):\penalty0
  221--244, 2000.

\bibitem[Hsu et~al.(2012)Hsu, Kakade, and Zhang]{hsu2012spectral}
D.~Hsu, S.~M. Kakade, and T.~Zhang.
\newblock A spectral algorithm for learning hidden markov models.
\newblock \emph{Journal of Computer and System Sciences}, 78\penalty0
  (5):\penalty0 1460--1480, 2012.

\bibitem[Jaeger(1998)]{jaeger1998discrete}
H.~Jaeger.
\newblock \emph{Discrete-time, discrete-valued observable operator models: a
  tutorial}.
\newblock GMD-Forschungszentrum Informationstechnik, 1998.

\bibitem[Jaeger(2000)]{jaeger2000observable}
H.~Jaeger.
\newblock Observable operator models for discrete stochastic time series.
\newblock \emph{Neural computation}, 12\penalty0 (6):\penalty0 1371--1398,
  2000.

\bibitem[Jin et~al.(2019)Jin, Netrapalli, Ge, Kakade, and Jordan]{jin2019short}
C.~Jin, P.~Netrapalli, R.~Ge, S.~M. Kakade, and M.~I. Jordan.
\newblock A short note on concentration inequalities for random vectors with
  subgaussian norm.
\newblock \emph{arXiv preprint arXiv:1902.03736}, 2019.

\bibitem[Kamyar et~al.(2018)Kamyar, Yue, and
  Anandkumar]{azizzadenesheli2018policy}
A.~Kamyar, Y.~Yue, and A.~Anandkumar.
\newblock Policy gradient in partially observable environments: Approximation
  and convergence.
\newblock \emph{arXiv preprint arXiv:1810.07900}, 2018.

\bibitem[Krishnamurthy et~al.(2016)Krishnamurthy, Agarwal, and
  Langford]{krishnamurthy2016pac}
A.~Krishnamurthy, A.~Agarwal, and J.~Langford.
\newblock Pac reinforcement learning with rich observations.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1840--1848, 2016.

\bibitem[Littman and Sutton(2002)]{littman2002predictive}
M.~L. Littman and R.~S. Sutton.
\newblock Predictive representations of state.
\newblock In \emph{Advances in neural information processing systems}, pages
  1555--1561, 2002.

\bibitem[Mossel and Roch(2005)]{mossel2005learning}
E.~Mossel and S.~Roch.
\newblock Learning nonsingular phylogenies and hidden markov models.
\newblock In \emph{Proceedings of the thirty-seventh annual ACM symposium on
  Theory of computing}, pages 366--375, 2005.

\bibitem[Mundhenk et~al.(2000)Mundhenk, Goldsmith, Lusena, and
  Allender]{mundhenk2000complexity}
M.~Mundhenk, J.~Goldsmith, C.~Lusena, and E.~Allender.
\newblock Complexity of finite-horizon markov decision process problems.
\newblock \emph{Journal of the ACM (JACM)}, 47\penalty0 (4):\penalty0 681--720,
  2000.

\bibitem[Papadimitriou and Tsitsiklis(1987)]{papadimitriou1987complexity}
C.~H. Papadimitriou and J.~N. Tsitsiklis.
\newblock The complexity of markov decision processes.
\newblock \emph{Mathematics of operations research}, 12\penalty0 (3):\penalty0
  441--450, 1987.

\bibitem[Poupart and Vlassis(2008)]{poupart2008model}
P.~Poupart and N.~Vlassis.
\newblock Model-based bayesian reinforcement learning in partially observable
  domains.
\newblock In \emph{Proc Int. Symp. on Artificial Intelligence and
  Mathematics,}, pages 1--2, 2008.

\bibitem[Rafferty et~al.(2011)Rafferty, Brunskill, Griffiths, and
  Shafto]{rafferty2011faster}
A.~N. Rafferty, E.~Brunskill, T.~L. Griffiths, and P.~Shafto.
\newblock Faster teaching by pomdp planning.
\newblock In \emph{International Conference on Artificial Intelligence in
  Education}, pages 280--287. Springer, 2011.

\bibitem[Ross et~al.(2008)Ross, Chaib-draa, and Pineau]{ross2008bayes}
S.~Ross, B.~Chaib-draa, and J.~Pineau.
\newblock Bayes-adaptive pomdps.
\newblock In \emph{Advances in neural information processing systems}, pages
  1225--1232, 2008.

\bibitem[Sch{\"u}tzenberger(1961)]{schutzenberger1961definition}
M.~P. Sch{\"u}tzenberger.
\newblock On the definition of a family of automata.
\newblock \emph{Information and control}, 4\penalty0 (2-3):\penalty0 245--270,
  1961.

\bibitem[Sharan et~al.(2017)Sharan, Kakade, Liang, and
  Valiant]{sharan2017learning}
V.~Sharan, S.~M. Kakade, P.~S. Liang, and G.~Valiant.
\newblock Learning overcomplete hmms.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  940--949, 2017.

\bibitem[Song et~al.(2010)Song, Boots, Siddiqi, Gordon, and
  Smola]{song2010hilbert}
L.~Song, B.~Boots, S.~Siddiqi, G.~J. Gordon, and A.~Smola.
\newblock Hilbert space embeddings of hidden markov models.
\newblock 2010.

\bibitem[Vlassis et~al.(2012)Vlassis, Littman, and
  Barber]{vlassis2012computational}
N.~Vlassis, M.~L. Littman, and D.~Barber.
\newblock On the computational complexity of stochastic controller optimization
  in pomdps.
\newblock \emph{ACM Transactions on Computation Theory (TOCT)}, 4\penalty0
  (4):\penalty0 1--8, 2012.

\end{thebibliography}
