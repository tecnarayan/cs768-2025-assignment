\begin{thebibliography}{125}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[ima(2014)]{imageclef2014}
The imageclef-da challenge 2014.
\newblock https://www.imageclef.org/2014, 2014.

\bibitem[Arjovsky et~al.(2019)Arjovsky, Bottou, Gulrajani, and
  Lopez-Paz]{arjovsky2019invariant}
M.~Arjovsky, L.~Bottou, I.~Gulrajani, and D.~Lopez-Paz.
\newblock Invariant risk minimization.
\newblock \emph{arXiv preprint arXiv:1907.02893}, 2019.

\bibitem[Atzmon et~al.(2020)Atzmon, Kreuk, Shalit, and
  Chechik]{atzmon2020causal}
Y.~Atzmon, F.~Kreuk, U.~Shalit, and G.~Chechik.
\newblock A causal view of compositional zero-shot recognition.
\newblock \emph{Advances in Neural Information Processing Systems}, 33, 2020.

\bibitem[Bahadori et~al.(2017)Bahadori, Chalupka, Choi, Chen, Stewart, and
  Sun]{bahadori2017causal}
M.~T. Bahadori, K.~Chalupka, E.~Choi, R.~Chen, W.~F. Stewart, and J.~Sun.
\newblock Causal regularization.
\newblock \emph{arXiv preprint arXiv:1702.02604}, 2017.

\bibitem[Baktashmotlagh et~al.(2013)Baktashmotlagh, Harandi, Lovell, and
  Salzmann]{baktashmotlagh2013unsupervised}
M.~Baktashmotlagh, M.~T. Harandi, B.~C. Lovell, and M.~Salzmann.
\newblock Unsupervised domain adaptation by domain invariant projection.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pages 769--776, 2013.

\bibitem[Beery et~al.(2018)Beery, Van~Horn, and Perona]{beery2018recognition}
S.~Beery, G.~Van~Horn, and P.~Perona.
\newblock Recognition in terra incognita.
\newblock In \emph{Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 456--473, 2018.

\bibitem[Ben-David et~al.(2010{\natexlab{a}})Ben-David, Blitzer, Crammer,
  Kulesza, Pereira, and Vaughan]{ben2010theory}
S.~Ben-David, J.~Blitzer, K.~Crammer, A.~Kulesza, F.~Pereira, and J.~W.
  Vaughan.
\newblock A theory of learning from different domains.
\newblock \emph{Machine learning}, 79\penalty0 (1-2):\penalty0 151--175,
  2010{\natexlab{a}}.

\bibitem[Ben-David et~al.(2010{\natexlab{b}})Ben-David, Lu, Luu, and
  P{\'a}l]{ben2010impossibility}
S.~Ben-David, T.~Lu, T.~Luu, and D.~P{\'a}l.
\newblock Impossibility theorems for domain adaptation.
\newblock In \emph{Proceedings of the Thirteenth International Conference on
  Artificial Intelligence and Statistics}, pages 129--136, 2010{\natexlab{b}}.

\bibitem[Bengio et~al.(2020)Bengio, Deleu, Rahaman, Ke, Lachapelle, Bilaniuk,
  Goyal, and Pal]{bengio2019meta}
Y.~Bengio, T.~Deleu, N.~Rahaman, N.~R. Ke, S.~Lachapelle, O.~Bilaniuk,
  A.~Goyal, and C.~J. Pal.
\newblock A meta-transfer objective for learning to disentangle causal
  mechanisms.
\newblock In \emph{8th International Conference on Learning Representations,
  {ICLR} 2020, Addis Ababa, Ethiopia, April 26-30, 2020}, 2020.

\bibitem[Besserve et~al.(2018)Besserve, Shajarisales, Sch{\"o}lkopf, and
  Janzing]{besserve2018group}
M.~Besserve, N.~Shajarisales, B.~Sch{\"o}lkopf, and D.~Janzing.
\newblock Group invariance principles for causal generative models.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 557--565. PMLR, 2018.

\bibitem[Besserve et~al.(2020)Besserve, Mehrjou, Sun, and
  Sch{\"o}lkopf]{besserve2020counterfactuals}
M.~Besserve, A.~Mehrjou, R.~Sun, and B.~Sch{\"o}lkopf.
\newblock Counterfactuals uncover the modular structure of deep generative
  models.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR 2020)}, 2020.

\bibitem[Biederman(1987)]{biederman1987recognition}
I.~Biederman.
\newblock Recognition-by-components: a theory of human image understanding.
\newblock \emph{Psychological review}, 94\penalty0 (2):\penalty0 115, 1987.

\bibitem[Billingsley(2012)]{billingsley2012probability}
P.~Billingsley.
\newblock \emph{Probability and Measure}.
\newblock John Wiley \& Sons, New Jersey, 2012.
\newblock ISBN 978-1-118-12237-2.

\bibitem[Bishop(2006)]{bishop2006pattern}
C.~M. Bishop.
\newblock \emph{Pattern recognition and machine learning}.
\newblock springer, 2006.

\bibitem[Brendel and Bethge(2019)]{brendel2019approximating}
W.~Brendel and M.~Bethge.
\newblock Approximating {CNNs} with bag-of-local-features models works
  surprisingly well on {ImageNet}.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR 2019)}, 2019.

\bibitem[B{\"u}hlmann(2018)]{buhlmann2018invariance}
P.~B{\"u}hlmann.
\newblock Invariance, causality and robustness.
\newblock \emph{arXiv preprint arXiv:1812.08233}, 2018.

\bibitem[B{\"u}hlmann et~al.(2014)B{\"u}hlmann, Peters, Ernest,
  et~al.]{buhlmann2014cam}
P.~B{\"u}hlmann, J.~Peters, J.~Ernest, et~al.
\newblock {CAM}: Causal additive models, high-dimensional order search and
  penalized regression.
\newblock \emph{The Annals of Statistics}, 42\penalty0 (6):\penalty0
  2526--2556, 2014.

\bibitem[Cai et~al.(2019)Cai, Li, Wei, Qiao, Zhang, and Hao]{cai2019learning}
R.~Cai, Z.~Li, P.~Wei, J.~Qiao, K.~Zhang, and Z.~Hao.
\newblock Learning disentangled semantic representation for domain adaptation.
\newblock In \emph{Proceedings of the Conference of IJCAI}, volume 2019, page
  2060. NIH Public Access, 2019.

\bibitem[Castro et~al.(2020)Castro, Walker, and Glocker]{castro2020causality}
D.~C. Castro, I.~Walker, and B.~Glocker.
\newblock Causality matters in medical imaging.
\newblock \emph{Nature Communications}, 11\penalty0 (1):\penalty0 1--10, 2020.

\bibitem[Chen and Batmanghelich(2020)]{chen2020weakly}
J.~Chen and K.~Batmanghelich.
\newblock Weakly supervised disentanglement by pairwise similarities.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pages 3495--3502, 2020.

\bibitem[Chen et~al.(2018)Chen, Li, Grosse, and Duvenaud]{chen2018isolating}
R.~T. Chen, X.~Li, R.~B. Grosse, and D.~K. Duvenaud.
\newblock Isolating sources of disentanglement in variational autoencoders.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2610--2620, 2018.

\bibitem[Chen et~al.(2016)Chen, Duan, Houthooft, Schulman, Sutskever, and
  Abbeel]{chen2016infogan}
X.~Chen, Y.~Duan, R.~Houthooft, J.~Schulman, I.~Sutskever, and P.~Abbeel.
\newblock Info{GAN}: Interpretable representation learning by information
  maximizing generative adversarial nets.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2172--2180, 2016.

\bibitem[Chuang et~al.(2020)Chuang, Torralba, and
  Jegelka]{chuang2020estimating}
C.-Y. Chuang, A.~Torralba, and S.~Jegelka.
\newblock Estimating generalization under distribution shifts via
  domain-invariant representations.
\newblock In \emph{International Conference on Machine Learning}, pages
  1984--1994. PMLR, 2020.

\bibitem[Cover and Thomas(2006)]{cover2006elements}
T.~M. Cover and J.~A. Thomas.
\newblock \emph{Elements of information theory}.
\newblock John Wiley \& Sons, 2006.

\bibitem[Cui et~al.(2020)Cui, Wang, Zhuo, Li, Huang, and Tian]{cui2020towards}
S.~Cui, S.~Wang, J.~Zhuo, L.~Li, Q.~Huang, and Q.~Tian.
\newblock Towards discriminability and diversity: Batch nuclear-norm
  maximization under label insufficient situations.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 3941--3950, 2020.

\bibitem[Dai and Wipf(2019)]{dai2019diagnosing}
B.~Dai and D.~Wipf.
\newblock Diagnosing and enhancing {VAE} models.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[D'Amour et~al.(2020)D'Amour, Heller, Moldovan, Adlam, Alipanahi,
  Beutel, Chen, Deaton, Eisenstein, Hoffman, et~al.]{d2020underspecification}
A.~D'Amour, K.~Heller, D.~Moldovan, B.~Adlam, B.~Alipanahi, A.~Beutel, C.~Chen,
  J.~Deaton, J.~Eisenstein, M.~D. Hoffman, et~al.
\newblock Underspecification presents challenges for credibility in modern
  machine learning.
\newblock \emph{arXiv preprint arXiv:2011.03395}, 2020.

\bibitem[Durkan and Song(2021)]{durkan2021maximum}
C.~Durkan and Y.~Song.
\newblock On maximum likelihood training of score-based generative models.
\newblock \emph{arXiv preprint arXiv:2101.09258}, 2021.

\bibitem[Endres and Schindelin(2003)]{endres2003new}
D.~M. Endres and J.~E. Schindelin.
\newblock A new metric for probability distributions.
\newblock \emph{IEEE Transactions on Information theory}, 49\penalty0
  (7):\penalty0 1858--1860, 2003.

\bibitem[Fang et~al.(2013)Fang, Xu, and Rockmore]{fang2013unbiased}
C.~Fang, Y.~Xu, and D.~N. Rockmore.
\newblock Unbiased metric learning: On the utilization of multiple datasets and
  web images for softening bias.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pages 1657--1664, 2013.

\bibitem[Fefferman et~al.(2016)Fefferman, Mitter, and
  Narayanan]{fefferman2016testing}
C.~Fefferman, S.~Mitter, and H.~Narayanan.
\newblock Testing the manifold hypothesis.
\newblock \emph{Journal of the American Mathematical Society}, 29\penalty0
  (4):\penalty0 983--1049, 2016.

\bibitem[Gal and Ghahramani(2016)]{gal2016dropout}
Y.~Gal and Z.~Ghahramani.
\newblock Dropout as a {B}ayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, pages 1050--1059, 2016.

\bibitem[Ganin et~al.(2016)Ganin, Ustinova, Ajakan, Germain, Larochelle,
  Laviolette, Marchand, and Lempitsky]{ganin2016domain}
Y.~Ganin, E.~Ustinova, H.~Ajakan, P.~Germain, H.~Larochelle, F.~Laviolette,
  M.~Marchand, and V.~Lempitsky.
\newblock Domain-adversarial training of neural networks.
\newblock \emph{Journal of Machine Learning Research}, 17:\penalty0 1--35,
  2016.

\bibitem[Geirhos et~al.(2019)Geirhos, Rubisch, Michaelis, Bethge, Wichmann, and
  Brendel]{geirhos2019imagenet}
R.~Geirhos, P.~Rubisch, C.~Michaelis, M.~Bethge, F.~A. Wichmann, and
  W.~Brendel.
\newblock {ImageNet}-trained {CNNs} are biased towards texture; increasing
  shape bias improves accuracy and robustness.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR 2019)}, 2019.

\bibitem[Gong et~al.(2016)Gong, Zhang, Liu, Tao, Glymour, and
  Sch{\"o}lkopf]{gong2016domain}
M.~Gong, K.~Zhang, T.~Liu, D.~Tao, C.~Glymour, and B.~Sch{\"o}lkopf.
\newblock Domain adaptation with conditional transferable components.
\newblock In \emph{International Conference on Machine Learning}, pages
  2839--2848, 2016.

\bibitem[Gong et~al.(2018)Gong, Zhang, Huang, Glymour, Tao, and
  Batmanghelich]{gong2018causal}
M.~Gong, K.~Zhang, B.~Huang, C.~Glymour, D.~Tao, and K.~Batmanghelich.
\newblock Causal generative domain adaptation networks.
\newblock \emph{arXiv preprint arXiv:1804.04333}, 2018.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
I.~Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair,
  A.~Courville, and Y.~Bengio.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2672--2680, Montréal, Canada, 2014. NIPS Foundation.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and
  Szegedy]{goodfellow2015explaining}
I.~J. Goodfellow, J.~Shlens, and C.~Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR 2015)}, 2015.

\bibitem[Gulrajani and Lopez-Paz(2020)]{gulrajani2020search}
I.~Gulrajani and D.~Lopez-Paz.
\newblock In search of lost domain generalization.
\newblock \emph{arXiv preprint arXiv:2007.01434}, 2020.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem[He et~al.(2019)He, Shen, and Cui]{he2019towards}
Y.~He, Z.~Shen, and P.~Cui.
\newblock Towards non-i.i.d. image classification: A dataset and baselines.
\newblock \emph{arXiv preprint arXiv:1906.02899}, 2019.

\bibitem[Heinze-Deml and Meinshausen(2019)]{heinze2019conditional}
C.~Heinze-Deml and N.~Meinshausen.
\newblock Conditional variance penalties and domain shift robustness.
\newblock \emph{stat}, 1050:\penalty0 13, 2019.

\bibitem[Higgins et~al.(2017)Higgins, Matthey, Pal, Burgess, Glorot, Botvinick,
  Mohamed, and Lerchner]{higgins2017beta}
I.~Higgins, L.~Matthey, A.~Pal, C.~Burgess, X.~Glorot, M.~Botvinick,
  S.~Mohamed, and A.~Lerchner.
\newblock Beta-{VAE}: Learning basic visual concepts with a constrained
  variational framework.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR 2017)}, 2017.

\bibitem[Higgins et~al.(2018)Higgins, Amos, Pfau, Racaniere, Matthey, Rezende,
  and Lerchner]{higgins2018towards}
I.~Higgins, D.~Amos, D.~Pfau, S.~Racaniere, L.~Matthey, D.~Rezende, and
  A.~Lerchner.
\newblock Towards a definition of disentangled representations.
\newblock \emph{arXiv preprint arXiv:1812.02230}, 2018.

\bibitem[Hoyer et~al.(2008)Hoyer, Shimizu, Kerminen, and
  Palviainen]{hoyer2008estimation}
P.~O. Hoyer, S.~Shimizu, A.~J. Kerminen, and M.~Palviainen.
\newblock Estimation of causal effects using linear non-gaussian causal models
  with hidden variables.
\newblock \emph{International Journal of Approximate Reasoning}, 49\penalty0
  (2):\penalty0 362--378, 2008.

\bibitem[Husz{\'a}r(2015)]{huszar2015not}
F.~Husz{\'a}r.
\newblock How (not) to train your generative model: Scheduled sampling,
  likelihood, adversary?
\newblock \emph{arXiv preprint arXiv:1511.05101}, 2015.

\bibitem[Hyv{\"a}rinen(2005)]{hyvarinen2005estimation}
A.~Hyv{\"a}rinen.
\newblock Estimation of non-normalized statistical models by score matching.
\newblock \emph{Journal of Machine Learning Research}, 6\penalty0
  (Apr):\penalty0 695--709, 2005.

\bibitem[Ilse et~al.(2020{\natexlab{a}})Ilse, Tomczak, and
  Forr{\'e}]{ilse2020designing}
M.~Ilse, J.~M. Tomczak, and P.~Forr{\'e}.
\newblock Designing data augmentation for simulating interventions.
\newblock \emph{arXiv preprint arXiv:2005.01856}, 2020{\natexlab{a}}.

\bibitem[Ilse et~al.(2020{\natexlab{b}})Ilse, Tomczak, Louizos, and
  Welling]{ilse2020diva}
M.~Ilse, J.~M. Tomczak, C.~Louizos, and M.~Welling.
\newblock {DIVA}: Domain invariant variational autoencoders.
\newblock In \emph{Medical Imaging with Deep Learning}, pages 322--348. PMLR,
  2020{\natexlab{b}}.

\bibitem[Ilyas et~al.(2019)Ilyas, Santurkar, Tsipras, Engstrom, Tran, and
  Madry]{ilyas2019adversarial}
A.~Ilyas, S.~Santurkar, D.~Tsipras, L.~Engstrom, B.~Tran, and A.~Madry.
\newblock Adversarial examples are not bugs, they are features.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  125--136, 2019.

\bibitem[Janzing et~al.(2009)Janzing, Peters, Mooij, and
  Sch{\"o}lkopf]{janzing2009identifying}
D.~Janzing, J.~Peters, J.~M. Mooij, and B.~Sch{\"o}lkopf.
\newblock Identifying confounders using additive noise models.
\newblock In \emph{Proceedings of the 25th Conference on Uncertainty in
  Artificial Intelligence (UAI 2009)}, pages 249--257. AUAI Press, 2009.

\bibitem[Janzing et~al.(2011)Janzing, Sgouritsa, Stegle, Peters, and
  Sch{\"o}lkopf]{janzing2011detecting}
D.~Janzing, E.~Sgouritsa, O.~Stegle, J.~Peters, and B.~Sch{\"o}lkopf.
\newblock Detecting low-complexity unobserved causes.
\newblock In \emph{27th Conference on Uncertainty in Artificial Intelligence
  (UAI 2011)}, pages 383--391. AUAI Press, 2011.

\bibitem[Jiang et~al.(2020)Jiang, Fu, and Long]{dalib}
J.~Jiang, B.~Fu, and M.~Long.
\newblock Transfer-learning-library.
\newblock \url{https://github.com/thuml/Transfer-Learning-Library}, 2020.

\bibitem[Johansson et~al.(2019)Johansson, Sontag, and
  Ranganath]{johansson2019support}
F.~D. Johansson, D.~Sontag, and R.~Ranganath.
\newblock Support and invertibility in domain-invariant representations.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 527--536, 2019.

\bibitem[Jordan et~al.(1999)Jordan, Ghahramani, Jaakkola, and
  Saul]{jordan1999introduction}
M.~I. Jordan, Z.~Ghahramani, T.~S. Jaakkola, and L.~K. Saul.
\newblock An introduction to variational methods for graphical models.
\newblock \emph{Machine learning}, 37\penalty0 (2):\penalty0 183--233, 1999.

\bibitem[Ke et~al.(2019)Ke, Bilaniuk, Goyal, Bauer, Larochelle, Pal, and
  Bengio]{ke2019learning}
N.~R. Ke, O.~Bilaniuk, A.~Goyal, S.~Bauer, H.~Larochelle, C.~Pal, and
  Y.~Bengio.
\newblock Learning neural causal models from unknown interventions.
\newblock \emph{arXiv preprint arXiv:1910.01075}, 2019.

\bibitem[Khemakhem et~al.(2020{\natexlab{a}})Khemakhem, Kingma, Monti, and
  Hyv{\"{a}}rinen]{khemakhem2019variational}
I.~Khemakhem, D.~P. Kingma, R.~P. Monti, and A.~Hyv{\"{a}}rinen.
\newblock Variational autoencoders and nonlinear {ICA:} {A} unifying framework.
\newblock In S.~Chiappa and R.~Calandra, editors, \emph{The 23rd International
  Conference on Artificial Intelligence and Statistics, {AISTATS} 2020, 26-28
  August 2020, Online [Palermo, Sicily, Italy]}, volume 108 of
  \emph{Proceedings of Machine Learning Research}, pages 2207--2217,
  2020{\natexlab{a}}.

\bibitem[Khemakhem et~al.(2020{\natexlab{b}})Khemakhem, Monti, Kingma, and
  Hyv{\"a}rinen]{khemakhem2020ice}
I.~Khemakhem, R.~P. Monti, D.~P. Kingma, and A.~Hyv{\"a}rinen.
\newblock {ICE-BeeM}: Identifiable conditional energy-based deep models.
\newblock \emph{arXiv preprint arXiv:2002.11537}, 2020{\natexlab{b}}.

\bibitem[Kilbertus et~al.(2018)Kilbertus, Parascandolo, and
  Sch{\"o}lkopf]{kilbertus2018generalization}
N.~Kilbertus, G.~Parascandolo, and B.~Sch{\"o}lkopf.
\newblock Generalization in anti-causal learning.
\newblock \emph{arXiv preprint arXiv:1812.00524}, 2018.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
D.~P. Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kingma and Dhariwal(2018)]{kingma2018glow}
D.~P. Kingma and P.~Dhariwal.
\newblock Glow: Generative flow with invertible 1x1 convolutions.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2018.

\bibitem[Kingma and Welling(2014)]{kingma2014auto}
D.~P. Kingma and M.~Welling.
\newblock Auto-encoding variational {B}ayes.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR 2014)}, Banff, Canada, 2014. ICLR Committee.

\bibitem[Kingma et~al.(2014)Kingma, Mohamed, Rezende, and
  Welling]{kingma2014semi}
D.~P. Kingma, S.~Mohamed, D.~J. Rezende, and M.~Welling.
\newblock Semi-supervised learning with deep generative models.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  3581--3589, 2014.

\bibitem[Kocaoglu et~al.(2018)Kocaoglu, Shakkottai, Dimakis, Caramanis, and
  Vishwanath]{kocaoglu2018entropic}
M.~Kocaoglu, S.~Shakkottai, A.~G. Dimakis, C.~Caramanis, and S.~Vishwanath.
\newblock Entropic latent variable discovery.
\newblock \emph{arXiv preprint arXiv:1807.10399}, 2018.

\bibitem[Koopmans and Reiersol(1950)]{koopmans1950identification}
T.~C. Koopmans and O.~Reiersol.
\newblock The identification of structural characteristics.
\newblock \emph{The Annals of Mathematical Statistics}, 21\penalty0
  (2):\penalty0 165--181, 1950.

\bibitem[Krueger et~al.(2020)Krueger, Caballero, Jacobsen, Zhang, Binas, Priol,
  and Courville]{krueger2020out}
D.~Krueger, E.~Caballero, J.-H. Jacobsen, A.~Zhang, J.~Binas, R.~L. Priol, and
  A.~Courville.
\newblock Out-of-distribution generalization via risk extrapolation {(REx)}.
\newblock \emph{arXiv preprint arXiv:2003.00688}, 2020.

\bibitem[Kurakin et~al.(2016)Kurakin, Goodfellow, and
  Bengio]{kurakin2016adversarial}
A.~Kurakin, I.~Goodfellow, and S.~Bengio.
\newblock Adversarial examples in the physical world.
\newblock \emph{arXiv preprint arXiv:1607.02533}, 2016.

\bibitem[Lee et~al.(2019)Lee, Hart, Richens, and Johri]{lee2019leveraging}
C.~M. Lee, C.~Hart, J.~G. Richens, and S.~Johri.
\newblock Leveraging directed causal discovery to detect latent common causes.
\newblock \emph{arXiv preprint arXiv:1910.10174}, 2019.

\bibitem[Li et~al.(2017)Li, Yang, Song, and Hospedales]{li2017deeper}
D.~Li, Y.~Yang, Y.-Z. Song, and T.~M. Hospedales.
\newblock Deeper, broader and artier domain generalization.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pages 5542--5550, 2017.

\bibitem[Locatello et~al.(2019{\natexlab{a}})Locatello, Bauer, Lucic, Raetsch,
  Gelly, Sch{\"o}lkopf, and Bachem]{locatello2019challenging}
F.~Locatello, S.~Bauer, M.~Lucic, G.~Raetsch, S.~Gelly, B.~Sch{\"o}lkopf, and
  O.~Bachem.
\newblock Challenging common assumptions in the unsupervised learning of
  disentangled representations.
\newblock In K.~Chaudhuri and R.~Salakhutdinov, editors, \emph{Proceedings of
  the 36th International Conference on Machine Learning}, volume~97 of
  \emph{Proceedings of Machine Learning Research}, pages 4114--4124, Long
  Beach, California, USA, 09--15 Jun 2019{\natexlab{a}}. PMLR.

\bibitem[Locatello et~al.(2019{\natexlab{b}})Locatello, Tschannen, Bauer,
  R{\"a}tsch, Sch{\"o}lkopf, and Bachem]{locatello2019disentangling}
F.~Locatello, M.~Tschannen, S.~Bauer, G.~R{\"a}tsch, B.~Sch{\"o}lkopf, and
  O.~Bachem.
\newblock Disentangling factors of variation using few labels.
\newblock \emph{arXiv preprint arXiv:1905.01258}, 2019{\natexlab{b}}.

\bibitem[Locatello et~al.(2020)Locatello, Poole, R{\"a}tsch, Sch{\"o}lkopf,
  Bachem, and Tschannen]{locatello2020weakly}
F.~Locatello, B.~Poole, G.~R{\"a}tsch, B.~Sch{\"o}lkopf, O.~Bachem, and
  M.~Tschannen.
\newblock Weakly-supervised disentanglement without compromises.
\newblock In \emph{International Conference on Machine Learning}, pages
  6348--6359. PMLR, 2020.

\bibitem[Long et~al.(2015)Long, Cao, Wang, and Jordan]{long2015learning}
M.~Long, Y.~Cao, J.~Wang, and M.~Jordan.
\newblock Learning transferable features with deep adaptation networks.
\newblock In \emph{International conference on machine learning}, pages
  97--105, 2015.

\bibitem[Long et~al.(2018)Long, Cao, Wang, and Jordan]{long2018conditional}
M.~Long, Z.~Cao, J.~Wang, and M.~I. Jordan.
\newblock Conditional adversarial domain adaptation.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1640--1650, 2018.

\bibitem[Lopez-Paz et~al.(2017)Lopez-Paz, Nishihara, Chintala, Sch{\"o}lkopf,
  and Bottou]{lopez2017discovering}
D.~Lopez-Paz, R.~Nishihara, S.~Chintala, B.~Sch{\"o}lkopf, and L.~Bottou.
\newblock Discovering causal signals in images.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pages 6979--6987, 2017.

\bibitem[Louizos et~al.(2017)Louizos, Shalit, Mooij, Sontag, Zemel, and
  Welling]{louizos2017causal}
C.~Louizos, U.~Shalit, J.~M. Mooij, D.~Sontag, R.~Zemel, and M.~Welling.
\newblock Causal effect inference with deep latent-variable models.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  6446--6456, 2017.

\bibitem[Magliacane et~al.(2018)Magliacane, van Ommen, Claassen, Bongers,
  Versteeg, and Mooij]{magliacane2018domain}
S.~Magliacane, T.~van Ommen, T.~Claassen, S.~Bongers, P.~Versteeg, and J.~M.
  Mooij.
\newblock Domain adaptation by using causal inference to predict invariant
  conditional distributions.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  10846--10856, 2018.

\bibitem[Mcauliffe and Blei(2008)]{mcauliffe2008supervised}
J.~D. Mcauliffe and D.~M. Blei.
\newblock Supervised topic models.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  121--128, Vancouver, Canada, 2008. NIPS Foundation.

\bibitem[Mitrovic et~al.(2021)Mitrovic, McWilliams, Walker, Buesing, and
  Blundell]{mitrovic2021representation}
J.~Mitrovic, B.~McWilliams, J.~C. Walker, L.~H. Buesing, and C.~Blundell.
\newblock Representation learning via invariant causal mechanisms.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=9p2ekP904Rs}.

\bibitem[Muandet et~al.(2013)Muandet, Balduzzi, and
  Sch{\"o}lkopf]{muandet2013domain}
K.~Muandet, D.~Balduzzi, and B.~Sch{\"o}lkopf.
\newblock Domain generalization via invariant feature representation.
\newblock In \emph{International Conference on Machine Learning}, pages 10--18,
  2013.

\bibitem[Murphy(2012)]{murphy2012machine}
K.~P. Murphy.
\newblock \emph{Machine learning: a probabilistic perspective}.
\newblock MIT press, 2012.

\bibitem[Neal(1995)]{neal1995bayesian}
R.~M. Neal.
\newblock \emph{{B}ayesian learning for neural networks}.
\newblock PhD thesis, University of Toronto, 1995.

\bibitem[Pan et~al.(2010)Pan, Tsang, Kwok, and Yang]{pan2010domain}
S.~J. Pan, I.~W. Tsang, J.~T. Kwok, and Q.~Yang.
\newblock Domain adaptation via transfer component analysis.
\newblock \emph{IEEE Transactions on Neural Networks}, 22\penalty0
  (2):\penalty0 199--210, 2010.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
A.~Paszke, S.~Gross, F.~Massa, A.~Lerer, J.~Bradbury, G.~Chanan, T.~Killeen,
  Z.~Lin, N.~Gimelshein, L.~Antiga, et~al.
\newblock {PyTorch}: An imperative style, high-performance deep learning
  library.
\newblock \emph{Advances in Neural Information Processing Systems},
  32:\penalty0 8026--8037, 2019.

\bibitem[Pearl(2009)]{pearl2009causality}
J.~Pearl.
\newblock \emph{Causality}.
\newblock Cambridge university press, 2009.

\bibitem[Peters et~al.(2014)Peters, Mooij, Janzing, and
  Sch{\"o}lkopf]{peters2014causal}
J.~Peters, J.~M. Mooij, D.~Janzing, and B.~Sch{\"o}lkopf.
\newblock Causal discovery with continuous additive noise models.
\newblock \emph{Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 2009--2053, 2014.

\bibitem[Peters et~al.(2016)Peters, B{\"u}hlmann, and
  Meinshausen]{peters2016causal}
J.~Peters, P.~B{\"u}hlmann, and N.~Meinshausen.
\newblock Causal inference by using invariant prediction: identification and
  confidence intervals.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 78\penalty0 (5):\penalty0 947--1012, 2016.

\bibitem[Peters et~al.(2017)Peters, Janzing, and
  Sch{\"o}lkopf]{peters2017elements}
J.~Peters, D.~Janzing, and B.~Sch{\"o}lkopf.
\newblock \emph{Elements of causal inference: foundations and learning
  algorithms}.
\newblock MIT press, 2017.

\bibitem[Qiao et~al.(2020)Qiao, Zhao, and Peng]{qiao2020learning}
F.~Qiao, L.~Zhao, and X.~Peng.
\newblock Learning to learn single domain generalization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pages 12556--12565, 2020.

\bibitem[Radford et~al.(2016)Radford, Metz, and
  Chintala]{radford2015unsupervised}
A.~Radford, L.~Metz, and S.~Chintala.
\newblock Unsupervised representation learning with deep convolutional
  generative adversarial networks.
\newblock In Y.~Bengio and Y.~LeCun, editors, \emph{4th International
  Conference on Learning Representations, {ICLR} 2016, San Juan, Puerto Rico,
  May 2-4, 2016, Conference Track Proceedings}, 2016.

\bibitem[Ribeiro et~al.(2016)Ribeiro, Singh, and Guestrin]{ribeiro2016why}
M.~T. Ribeiro, S.~Singh, and C.~Guestrin.
\newblock "{Why} should {I} trust you?": Explaining the predictions of any
  classifier.
\newblock In \emph{Proceedings of the 22nd {ACM} {SIGKDD} International
  Conference on Knowledge Discovery and Data Mining, San Francisco, CA, USA,
  August 13-17, 2016}, pages 1135--1144, 2016.

\bibitem[Richardson et~al.(2002)Richardson, Spirtes,
  et~al.]{richardson2002ancestral}
T.~Richardson, P.~Spirtes, et~al.
\newblock Ancestral graph {M}arkov models.
\newblock \emph{The Annals of Statistics}, 30\penalty0 (4):\penalty0 962--1030,
  2002.

\bibitem[Rojas-Carulla et~al.(2018)Rojas-Carulla, Sch{\"o}lkopf, Turner, and
  Peters]{rojas2018invariant}
M.~Rojas-Carulla, B.~Sch{\"o}lkopf, R.~Turner, and J.~Peters.
\newblock Invariant models for causal transfer learning.
\newblock \emph{The Journal of Machine Learning Research}, 19\penalty0
  (1):\penalty0 1309--1342, 2018.

\bibitem[Romeijn and Williamson(2018)]{romeijn2018intervention}
J.-W. Romeijn and J.~Williamson.
\newblock Intervention and identifiability in latent variable modelling.
\newblock \emph{Minds and machines}, 28\penalty0 (2):\penalty0 243--264, 2018.

\bibitem[Rothenh{\"a}usler et~al.(2018)Rothenh{\"a}usler, Meinshausen,
  B{\"u}hlmann, and Peters]{rothenhausler2018anchor}
D.~Rothenh{\"a}usler, N.~Meinshausen, P.~B{\"u}hlmann, and J.~Peters.
\newblock Anchor regression: heterogeneous data meets causality.
\newblock \emph{arXiv preprint arXiv:1801.06229}, 2018.

\bibitem[Sch{\"o}lkopf(2019)]{scholkopf2019causality}
B.~Sch{\"o}lkopf.
\newblock Causality for machine learning.
\newblock \emph{arXiv preprint arXiv:1911.10500}, 2019.

\bibitem[Sch{\"o}lkopf et~al.(2012)Sch{\"o}lkopf, Janzing, Peters, Sgouritsa,
  Zhang, and Mooij]{scholkopf2012causal}
B.~Sch{\"o}lkopf, D.~Janzing, J.~Peters, E.~Sgouritsa, K.~Zhang, and J.~M.
  Mooij.
\newblock On causal and anticausal learning.
\newblock In \emph{International Conference on Machine Learning (ICML 2012)},
  pages 1255--1262. International Machine Learning Society, 2012.

\bibitem[Sch{\"o}lkopf et~al.(2021)Sch{\"o}lkopf, Locatello, Bauer, Ke,
  Kalchbrenner, Goyal, and Bengio]{scholkopf2021toward}
B.~Sch{\"o}lkopf, F.~Locatello, S.~Bauer, N.~R. Ke, N.~Kalchbrenner, A.~Goyal,
  and Y.~Bengio.
\newblock Toward causal representation learning.
\newblock \emph{Proceedings of the IEEE}, 109\penalty0 (5):\penalty0 612--634,
  2021.

\bibitem[Sgouritsa et~al.(2013)Sgouritsa, Janzing, Peters, and
  Sch{\"o}lkopf]{sgouritsa2013identifying}
E.~Sgouritsa, D.~Janzing, J.~Peters, and B.~Sch{\"o}lkopf.
\newblock Identifying finite mixtures of nonparametric product distributions
  and causal inference of confounders.
\newblock In \emph{Proceedings of the 29th Conference on Uncertainty in
  Artificial Intelligence (UAI 2013)}, pages 556--575. AUAI Press, 2013.

\bibitem[Shalit et~al.(2017)Shalit, Johansson, and
  Sontag]{shalit2017estimating}
U.~Shalit, F.~D. Johansson, and D.~Sontag.
\newblock Estimating individual treatment effect: generalization bounds and
  algorithms.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 3076--3085. JMLR.org, 2017.

\bibitem[Shankar et~al.(2018)Shankar, Piratla, Chakrabarti, Chaudhuri, Jyothi,
  and Sarawagi]{shankar2018generalizing}
S.~Shankar, V.~Piratla, S.~Chakrabarti, S.~Chaudhuri, P.~Jyothi, and
  S.~Sarawagi.
\newblock Generalizing across domains via cross-gradient training.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR 2018)}, 2018.

\bibitem[Shen et~al.(2018)Shen, Cui, Kuang, Li, and Chen]{shen2018causally}
Z.~Shen, P.~Cui, K.~Kuang, B.~Li, and P.~Chen.
\newblock Causally regularized learning with agnostic data selection bias.
\newblock In \emph{2018 ACM Multimedia Conference on Multimedia Conference},
  pages 411--419. ACM, 2018.

\bibitem[Shpitser et~al.(2014)Shpitser, Evans, Richardson, and
  Robins]{shpitser2014introduction}
I.~Shpitser, R.~J. Evans, T.~S. Richardson, and J.~M. Robins.
\newblock Introduction to nested {M}arkov models.
\newblock \emph{Behaviormetrika}, 41\penalty0 (1):\penalty0 3--39, 2014.

\bibitem[Shu et~al.(2020)Shu, Chen, Kumar, Ermon, and Poole]{shu2020weakly}
R.~Shu, Y.~Chen, A.~Kumar, S.~Ermon, and B.~Poole.
\newblock Weakly supervised disentanglement with guarantees.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Spirtes et~al.(2000)Spirtes, Glymour, Scheines, and
  Heckerman]{spirtes2000causation}
P.~Spirtes, C.~N. Glymour, R.~Scheines, and D.~Heckerman.
\newblock \emph{Causation, prediction, and search}.
\newblock MIT press, 2000.

\bibitem[Srivastava et~al.(2014)Srivastava, Hinton, Krizhevsky, Sutskever, and
  Salakhutdinov]{srivastava2014dropout}
N.~Srivastava, G.~Hinton, A.~Krizhevsky, I.~Sutskever, and R.~Salakhutdinov.
\newblock Dropout: a simple way to prevent neural networks from overfitting.
\newblock \emph{The Journal of Machine Learning Research}, 15\penalty0
  (1):\penalty0 1929--1958, 2014.

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan,
  Goodfellow, and Fergus]{szegedy2014intriguing}
C.~Szegedy, W.~Zaremba, I.~Sutskever, J.~Bruna, D.~Erhan, I.~Goodfellow, and
  R.~Fergus.
\newblock Intriguing properties of neural networks.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations (ICLR 2014)}, 2014.

\bibitem[Teshima et~al.(2020)Teshima, Sato, and Sugiyama]{teshima2020few}
T.~Teshima, I.~Sato, and M.~Sugiyama.
\newblock Few-shot domain adaptation by causal mechanism transfer.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning, {ICML} 2020, 13-18 July 2020, Virtual Event}, volume 119 of
  \emph{Proceedings of Machine Learning Research}, pages 9458--9469, 2020.

\bibitem[Theis et~al.(2016)Theis, van~den Oord, and Bethge]{theis2016note}
L.~Theis, A.~van~den Oord, and M.~Bethge.
\newblock A note on the evaluation of generative models.
\newblock In \emph{International Conference on Learning Representations (ICLR
  2016)}, pages 1--10, 2016.

\bibitem[Tieleman and Hinton(2012)]{tieleman2012lecture}
T.~Tieleman and G.~Hinton.
\newblock Lecture 6.5-{RMSprop}: Divide the gradient by a running average of
  its recent magnitude.
\newblock \emph{COURSERA: Neural networks for machine learning}, 4\penalty0
  (2):\penalty0 26--31, 2012.

\bibitem[Verma and Pearl(1991)]{verma1991equivalence}
T.~Verma and J.~Pearl.
\newblock \emph{Equivalence and synthesis of causal models}.
\newblock UCLA, Computer Science Department, 1991.

\bibitem[Wainwright et~al.(2008)Wainwright, Jordan,
  et~al.]{wainwright2008graphical}
M.~J. Wainwright, M.~I. Jordan, et~al.
\newblock Graphical models, exponential families, and variational inference.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  1\penalty0 (1--2):\penalty0 1--305, 2008.

\bibitem[Wang et~al.(2021)Wang, Lan, Liu, Ouyang, and
  Qin]{wang2021generalizing}
J.~Wang, C.~Lan, C.~Liu, Y.~Ouyang, and T.~Qin.
\newblock Generalizing to unseen domains: A survey on domain generalization.
\newblock In \emph{Proceedings of the Thirtieth International Joint Conference
  on Artificial Intelligence, {IJCAI-21}}, pages 4627--4635. International
  Joint Conferences on Artificial Intelligence Organization, 2021.
\newblock Survey Track.

\bibitem[Wang and Blei(2019)]{wang2019blessings}
Y.~Wang and D.~M. Blei.
\newblock The blessings of multiple causes.
\newblock \emph{Journal of the American Statistical Association}, 114\penalty0
  (528):\penalty0 1574--1596, 2019.

\bibitem[Weinberger and Saul(2006)]{weinberger2006unsupervised}
K.~Q. Weinberger and L.~K. Saul.
\newblock Unsupervised learning of image manifolds by semidefinite programming.
\newblock \emph{International Journal of Computer Vision}, 70\penalty0
  (1):\penalty0 77--90, 2006.

\bibitem[Yacoby et~al.(2019)Yacoby, Pan, and Doshi-Velez]{yacoby2019learning}
Y.~Yacoby, W.~Pan, and F.~Doshi-Velez.
\newblock Learning deep bayesian latent variable regression models that
  generalize: When non-identifiability is a problem.
\newblock \emph{arXiv preprint arXiv:1911.00569}, 2019.

\bibitem[Yang et~al.(2020)Yang, Liu, Chen, Shen, Hao, and
  Wang]{yang2020causalvae}
M.~Yang, F.~Liu, Z.~Chen, X.~Shen, J.~Hao, and J.~Wang.
\newblock {CausalVAE}: Structured causal disentanglement in variational
  autoencoder.
\newblock \emph{arXiv preprint arXiv:2004.08697}, 2020.

\bibitem[Yao et~al.(2018)Yao, Li, Li, Huai, Gao, and
  Zhang]{yao2018representation}
L.~Yao, S.~Li, Y.~Li, M.~Huai, J.~Gao, and A.~Zhang.
\newblock Representation learning for treatment effect estimation from
  observational data.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2633--2643, 2018.

\bibitem[Ye et~al.(2021)Ye, Xie, Cai, Li, Li, and Wang]{ye2021towards}
H.~Ye, C.~Xie, T.~Cai, R.~Li, Z.~Li, and L.~Wang.
\newblock Towards a theoretical framework of out-of-distribution
  generalization.
\newblock \emph{arXiv preprint arXiv:2106.04496}, 2021.

\bibitem[You et~al.(2019)You, Wang, Long, and Jordan]{you2019towards}
K.~You, X.~Wang, M.~Long, and M.~Jordan.
\newblock Towards accurate model selection in deep unsupervised domain
  adaptation.
\newblock In \emph{International Conference on Machine Learning}, pages
  7124--7133, 2019.

\bibitem[Zhang et~al.(2020)Zhang, Zhang, and Li]{zhang2020causal}
C.~Zhang, K.~Zhang, and Y.~Li.
\newblock A causal view on robustness of neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2020.

\bibitem[Zhang and Hyv{\"a}rinen(2009)]{zhang2009identifiability}
K.~Zhang and A.~Hyv{\"a}rinen.
\newblock On the identifiability of the post-nonlinear causal model.
\newblock In \emph{Proceedings of the 25th Conference on Uncertainty in
  Artificial Intelligence (UAI 2009)}, pages 647--655. AUAI Press, 2009.

\bibitem[Zhang et~al.(2013)Zhang, Sch{\"o}lkopf, Muandet, and
  Wang]{zhang2013domain}
K.~Zhang, B.~Sch{\"o}lkopf, K.~Muandet, and Z.~Wang.
\newblock Domain adaptation under target and conditional shift.
\newblock In \emph{International Conference on Machine Learning}, pages
  819--827, 2013.

\bibitem[Zhang et~al.(2019)Zhang, Liu, Long, and Jordan]{zhang2019bridging}
Y.~Zhang, T.~Liu, M.~Long, and M.~Jordan.
\newblock Bridging theory and algorithm for domain adaptation.
\newblock In \emph{International Conference on Machine Learning}, pages
  7404--7413, 2019.

\bibitem[Zhao et~al.(2019)Zhao, Des~Combes, Zhang, and
  Gordon]{zhao2019learning}
H.~Zhao, R.~T. Des~Combes, K.~Zhang, and G.~Gordon.
\newblock On learning invariant representations for domain adaptation.
\newblock In \emph{International Conference on Machine Learning}, pages
  7523--7532, 2019.

\end{thebibliography}
