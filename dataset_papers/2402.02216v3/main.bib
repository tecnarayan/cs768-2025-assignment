@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@article{ling2021deep,
  title={Deep graph matching and searching for semantic code retrieval},
  author={Ling, Xiang and Wu, Lingfei and Wang, Saizhuo and Pan, Gaoning and Ma, Tengfei and Xu, Fangli and Liu, Alex X and Wu, Chunming and Ji, Shouling},
  journal={ACM Transactions on Knowledge Discovery from Data (TKDD)},
  volume={15},
  number={5},
  pages={1--21},
  year={2021},
  publisher={ACM New York, NY, USA}
}
@article{videoworldsimulators2024,
  title={Video generation models as world simulators},
  author={Tim Brooks and Bill Peebles and Connor Holmes and Will DePue and Yufei Guo and Li Jing and David Schnurr and Joe Taylor and Troy Luhman and Eric Luhman and Clarence Ng and Ricky Wang and Aditya Ramesh},
  year={2024},
  url={https://openai.com/research/video-generation-models-as-world-simulators},
}
@article{rafi2024towards,
  title={Towards Better Graph Neural Neural Network-based Fault Localization Through Enhanced Code Representation},
  author={Rafi, Md Nakhla and Kim, Dong Jae and Chen, An Ran and Chen, Tse-Hsun and Wang, Shaowei},
  journal={arXiv preprint arXiv:2404.04496},
  year={2024}
}

@article{liu2024source,
  title={Source Code Vulnerability Detection: Combining Code Language Models and Code Property Graphs},
  author={Liu, Ruitong and Wang, Yanbin and Xu, Haitao and Liu, Bin and Sun, Jianguo and Guo, Zhenhao and Ma, Wenrui},
  journal={arXiv preprint arXiv:2404.14719},
  year={2024}
}

@inproceedings{CLIP,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{yin2022algorithm,
  title={Algorithm and system co-design for efficient subgraph-based graph representation learning},
  author={Yin, Haoteng and Zhang, Muhan and Wang, Yanbang and Wang, Jianguo and Li, Pan},
  journal={arXiv preprint arXiv:2202.13538},
  year={2022}
}

@inproceedings{ribeiro2009strategies,
  title={Strategies for network motifs discovery},
  author={Ribeiro, Pedro and Silva, Fernando and Kaiser, Marcus},
  booktitle={2009 Fifth IEEE International Conference on e-Science},
  pages={80--87},
  year={2009},
  organization={IEEE}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}
@article{taylor2022galactica,
  title={Galactica: A large language model for science},
  author={Taylor, Ross and Kardas, Marcin and Cucurull, Guillem and Scialom, Thomas and Hartshorn, Anthony and Saravia, Elvis and Poulton, Andrew and Kerkez, Viktor and Stojnic, Robert},
  journal={arXiv preprint arXiv:2211.09085},
  year={2022}
}


@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}

@article{gpt4,
  title={Sparks of artificial general intelligence: Early experiments with gpt-4},
  author={Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
  journal={arXiv preprint arXiv:2303.12712},
  year={2023}
}


@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{oneforall,
  title={One for All: Towards Training One Graph Model for All Classification Tasks},
  author={Liu, Hao and Feng, Jiarui and Kong, Lecheng and Liang, Ningyue and Tao, Dacheng and Chen, Yixin and Zhang, Muhan},
  journal={arXiv preprint arXiv:2310.00149},
  year={2023}
}

@article{han2021pre,
  title={Pre-trained models: Past, present and future},
  author={Han, Xu and Zhang, Zhengyan and Ding, Ning and Gu, Yuxian and Liu, Xiao and Huo, Yuqi and Qiu, Jiezhong and Yao, Yuan and Zhang, Ao and Zhang, Liang and others},
  journal={AI Open},
  volume={2},
  pages={225--250},
  year={2021},
  publisher={Elsevier}
}


@article{icl,
  title={A survey for in-context learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Wu, Zhiyong and Chang, Baobao and Sun, Xu and Xu, Jingjing and Sui, Zhifang},
  journal={arXiv preprint arXiv:2301.00234},
  year={2022}
}

@article{menon2022visual,
  author    = {Menon, Sachit and Vondrick, Carl},
  title     = {Visual Classification via Description from Large Language Models},
  journal   = {ICLR},
  year      = {2023},
}

@article{zheng2023predicting,
title={Towards Predicting Equilibrium Distributions for Molecular Systems with Deep Learning},
author={Shuxin Zheng and Jiyan He and Chang Liu and Yu Shi and Ziheng Lu and Weitao Feng and Fusong Ju and Jiaxi Wang and Jianwei Zhu and Yaosen Min and He Zhang and Shidi Tang and Hongxia Hao and Peiran Jin and Chi Chen and Frank Noé and Haiguang Liu and Tie-Yan Liu},
journal={arXiv preprint arXiv:2306.05445},
year={2023},
}


@article{CIN,
  title={Weisfeiler and lehman go cellular: Cw networks},
  author={Bodnar, Cristian and Frasca, Fabrizio and Otter, Nina and Wang, Yuguang and Lio, Pietro and Montufar, Guido F and Bronstein, Michael},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={2625--2640},
  year={2021}
}

@article{GCN,
  title={Semi-supervised classification with graph convolutional networks},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1609.02907},
  year={2016}
}


@article{BUDDY,
  title={Graph neural networks for link prediction with subgraph sketching},
  author={Chamberlain, Benjamin Paul and Shirobokov, Sergey and Rossi, Emanuele and Frasca, Fabrizio and Markovich, Thomas and Hammerla, Nils and Bronstein, Michael M and Hansmire, Max},
  journal={arXiv preprint arXiv:2209.15486},
  year={2022}
}


@article{mao2023demystifyingNC,
  title={Demystifying Structural Disparity in Graph Neural Networks: Can One Size Fit All?},
  author={Mao, Haitao and Chen, Zhikai and Jin, Wei and Han, Haoyu and Ma, Yao and Zhao, Tong and Shah, Neil and Tang, Jiliang},
  journal={arXiv preprint arXiv:2306.01323},
  year={2023}
}


@article{li2023evaluatingLP,
  title={Evaluating Graph Neural Networks for Link Prediction: Current Pitfalls and New Benchmarking},
  author={Li, Juanhui and Shomer, Harry and Mao, Haitao and Zeng, Shenglai and Ma, Yao and Shah, Neil and Tang, Jiliang and Yin, Dawei},
  journal={arXiv preprint arXiv:2306.10453},
  year={2023}
}
@inproceedings{barcelo2022weisfeiler,
  title={Weisfeiler and leman go relational},
  author={Barcelo, Pablo and Galkin, Mikhail and Morris, Christopher and Orth, Miguel Romero},
  booktitle={Learning on Graphs Conference},
  pages={46--1},
  year={2022},
  organization={PMLR}
}
@article{li2022graph,
  title={Are graph neural networks really helpful for knowledge graph completion?},
  author={Li, Juanhui and Shomer, Harry and Ding, Jiayuan and Wang, Yiqi and Ma, Yao and Shah, Neil and Tang, Jiliang and Yin, Dawei},
  journal={arXiv preprint arXiv:2205.10652},
  year={2022}
}
@article{mao2023revisitingLP,
  title={Revisiting Link Prediction: A Data Perspective},
  author={Mao, Haitao and Li, Juanhui and Shomer, Harry and Li, Bingheng and Fan, Wenqi and Ma, Yao and Zhao, Tong and Shah, Neil and Tang, Jiliang},
  journal={arXiv preprint arXiv:2310.00793},
  year={2023}
}


@article{wu2020comprehensiveGNNSurvey,
  title={A comprehensive survey on graph neural networks},
  author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Philip, S Yu},
  journal={IEEE transactions on neural networks and learning systems},
  volume={32},
  number={1},
  pages={4--24},
  year={2020},
  publisher={IEEE}
}

@article{galkin2023towardsULTRA,
  title={Towards foundation models for knowledge graph reasoning},
  author={Galkin, Mikhail and Yuan, Xinyu and Mostafa, Hesham and Tang, Jian and Zhu, Zhaocheng},
  journal={arXiv preprint arXiv:2310.04562},
  year={2023}
}


@article{fatemi2023talk,
  title={Talk like a graph: Encoding graphs for large language models},
  author={Fatemi, Bahare and Halcrow, Jonathan and Perozzi, Bryan},
  journal={arXiv preprint arXiv:2310.04560},
  year={2023}
}

@article{Chen2023ExploringTP,
  title={Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs},
  author={Zhikai Chen and Haitao Mao and Hang Li and Wei Jin and Haifang Wen and Xiaochi Wei and Shuaiqiang Wang and Dawei Yin and Wenqi Fan and Hui Liu and Jiliang Tang},
  journal={ArXiv},
  year={2023},
  volume={abs/2307.03393}
}

@misc{he2023harnessingTAPE,
      title={Harnessing Explanations: LLM-to-LM Interpreter for Enhanced Text-Attributed Graph Representation Learning}, 
      author={Xiaoxin He and Xavier Bresson and Thomas Laurent and Adam Perold and Yann LeCun and Bryan Hooi},
      year={2023},
      eprint={2305.19523},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{
wang2023NLGRAPH,
title={Can Language Models Solve Graph Problems in Natural Language?},
author={Heng Wang and Shangbin Feng and Tianxing He and Zhaoxuan Tan and Xiaochuang Han and Yulia Tsvetkov},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=UDqHhbqYJV}
}


@inproceedings{
anonymous2024online,
title={Online {GNN} Evaluation Under Test-time Graph Distribution Shifts},
author={Anonymous},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=KbetDM33YG}
}


@article{nodeformer,
  title={Nodeformer: A scalable graph structure learning transformer for node classification},
  author={Wu, Qitian and Zhao, Wentao and Li, Zenan and Wipf, David P and Yan, Junchi},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27387--27401},
  year={2022}
}
@inproceedings{li2022finding,
  title={Finding global homophily in graph neural networks when meeting heterophily},
  author={Li, Xiang and Zhu, Renyu and Cheng, Yao and Shan, Caihua and Luo, Siqiang and Li, Dongsheng and Qian, Weining},
  booktitle={International Conference on Machine Learning},
  pages={13242--13256},
  year={2022},
  organization={PMLR}
}
@article{zhu2020beyond,
  title={Beyond homophily in graph neural networks: Current limitations and effective designs},
  author={Zhu, Jiong and Yan, Yujun and Zhao, Lingxiao and Heimann, Mark and Akoglu, Leman and Koutra, Danai},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={7793--7804},
  year={2020}
}


@article{oversmoothing,
  title={A survey on oversmoothing in graph neural networks},
  author={Rusch, T Konstantin and Bronstein, Michael M and Mishra, Siddhartha},
  journal={arXiv preprint arXiv:2303.10993},
  year={2023}
}

@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={arXiv preprint arXiv:2206.07682},
  year={2022}
}

@article{dosovitskiy2020imageVIT,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{ma2021homophily,
  title={Is homophily a necessity for graph neural networks?},
  author={Ma, Yao and Liu, Xiaorui and Shah, Neil and Tang, Jiliang},
  journal={arXiv preprint arXiv:2106.06134},
  year={2021}
}


@article{ju2023multiParetoGNN,
  title={Multi-task Self-supervised Graph Neural Networks Enable Stronger Task Generalization},
  author={Ju, Mingxuan and Zhao, Tong and Wen, Qianlong and Yu, Wenhao and Shah, Neil and Ye, Yanfang and Zhang, Chuxu},
  booktitle={International Conference on Learning Representations},
  year={2023}
}

@article{lim2021largeLINKX,
  title={Large scale learning on non-homophilous graphs: New benchmarks and strong simple methods},
  author={Lim, Derek and Hohne, Felix and Li, Xiuyu and Huang, Sijia Linda and Gupta, Vaishnavi and Bhalerao, Omkar and Lim, Ser Nam},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={20887--20902},
  year={2021}
}


@article{hu2020openOGB,
  title={Open graph benchmark: Datasets for machine learning on graphs},
  author={Hu, Weihua and Fey, Matthias and Zitnik, Marinka and Dong, Yuxiao and Ren, Hongyu and Liu, Bowen and Catasta, Michele and Leskovec, Jure},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={22118--22133},
  year={2020}
}

@article{li2022findingGLOGNN,
  title={Finding Global Homophily in Graph Neural Networks When Meeting Heterophily},
  author={Li, Xiang and Zhu, Renyu and Cheng, Yao and Shan, Caihua and Luo, Siqiang and Li, Dongsheng and Qian, Weining},
  journal={arXiv preprint arXiv:2205.07308},
  year={2022}
}


@misc{dirgnn_rossi_2023,
    title={Edge Directionality Improves Learning on Heterophilic Graphs},
    author={Emanuele Rossi and Bertrand Charpentier and Francesco Di Giovanni and Fabrizio Frasca and Stephan Günnemann and Michael Bronstein},
    publisher={arXiv},
    year={2023}
}


@article{sun2022doesSSLFAIL,
  title={Does GNN Pretraining Help Molecular Representation?},
  author={Sun, Ruoxi and Dai, Hanjun and Yu, Adams Wei},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={12096--12109},
  year={2022}
}


@article{beaini2023towardsMoleculeFM,
  title={Towards Foundational Models for Molecular Learning on Large-Scale Multi-Task Datasets},
  author={Beaini, Dominique and Huang, Shenyang and Cunha, Joao Alex and Moisescu-Pareja, Gabriela and Dymov, Oleksandr and Maddrell-Mander, Samuel and McLean, Callum and Wenkel, Frederik and M{\"u}ller, Luis and Mohamud, Jama Hussein and others},
  journal={arXiv preprint arXiv:2310.04292},
  year={2023}
}


@article{frey2023neuralChemicalScale,
  title={Neural scaling of deep chemical models},
  author={Frey, Nathan C and Soklaski, Ryan and Axelrod, Simon and Samsi, Siddharth and Gomez-Bombarelli, Rafael and Coley, Connor W and Gadepally, Vijay},
  journal={Nature Machine Intelligence},
  volume={5},
  number={11},
  pages={1297--1305},
  year={2023},
  publisher={Nature Publishing Group UK London}
}


@article{kaplan2020scalingNLP,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@inproceedings{dehghani2023scalingVIT,
  title={Scaling vision transformers to 22 billion parameters},
  author={Dehghani, Mostafa and Djolonga, Josip and Mustafa, Basil and Padlewski, Piotr and Heek, Jonathan and Gilmer, Justin and Steiner, Andreas Peter and Caron, Mathilde and Geirhos, Robert and Alabdulmohsin, Ibrahim and others},
  booktitle={International Conference on Machine Learning},
  pages={7480--7512},
  year={2023},
  organization={PMLR}
}

@inproceedings{
chen2023uncoveringMoleculeScaling,
title={Uncovering Neural Scaling Laws in Molecular Representation Learning},
author={Dingshuo Chen and Yanqiao Zhu and Jieyu Zhang and Yuanqi Du and Zhixun Li and Qiang Liu and Shu Wu and Liang Wang},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2023},
url={https://openreview.net/forum?id=Ys8RmfF9w1}
}


@inproceedings{scalingandforgetting,title	= {Effect of scale on catastrophic forgetting in neural networks},author	= {Ethan Dyer and Aitor Lewkowycz and Vinay Ramasesh},year	= {2022},URL	= {https://openreview.net/forum?id=GhVS8_yPeEa},booktitle	= {ICLR}}


@article{liu2023towardsGFMSurvey,
  title={Towards graph foundation models: A survey and beyond},
  author={Liu, Jiawei and Yang, Cheng and Lu, Zhiyuan and Chen, Junze and Li, Yibo and Zhang, Mengmei and Bai, Ting and Fang, Yuan and Sun, Lichao and Yu, Philip S and others},
  journal={arXiv preprint arXiv:2310.11829},
  year={2023}
}


@inproceedings{
huang2023lexinvariant,
title={Lexinvariant Language Models},
author={Qian Huang and Eric Zelikman and Sarah Li Chen and Yuhuai Wu and Gregory Valiant and Percy Liang},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=NiQTy0NW1L}
}


@inproceedings{NEURIPS2021_EGOCL,
 author = {Zhu, Qi and Yang, Carl and Xu, Yidan and Wang, Haonan and Zhang, Chao and Han, Jiawei},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {1766--1779},
 publisher = {Curran Associates, Inc.},
 title = {Transfer Learning of Graph Neural Networks with Ego-graph Information Maximization},
 url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/0dd6049f5fa537d41753be6d37859430-Paper.pdf},
 volume = {34},
 year = {2021}
}




@inproceedings{you2023graphSpecReg,
title={Graph Domain Adaptation via Theory-Grounded Spectral Regularization},
author={Yuning You and Tianlong Chen and Zhangyang Wang and Yang Shen},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=OysfLgrk8mk}
}

@article{dong2024universal,
  title={Universal link predictor by In-context Learning},
  author={Dong, Kaiwen and Mao, Haitao and Guo, Zhichun and Chawla, Nitesh V},
  journal={arXiv preprint arXiv:2402.07738},
  year={2024}
}


@inproceedings{wu2020UDAGCN,
author={Man Wu and Shirui Pan and Chuan Zhou and Xiaojun Chang and Xingquan Zhu},
title={Unsupervised Domain Adaptive Graph Convolutional Networks},
journal={{WWW} '20: The Web Conference},
year={2020}
}


@inproceedings{di2023overSquashing,
  title={On over-squashing in message passing neural networks: The impact of width, depth, and topology},
  author={Di Giovanni, Francesco and Giusti, Lorenzo and Barbero, Federico and Luise, Giulia and Lio, Pietro and Bronstein, Michael M},
  booktitle={International Conference on Machine Learning},
  pages={7865--7885},
  year={2023},
  organization={PMLR}
}


@inproceedings{
ying2021doGraphormer,
title={Do Transformers Really Perform Badly for Graph Representation?},
author={Chengxuan Ying and Tianle Cai and Shengjie Luo and Shuxin Zheng and Guolin Ke and Di He and Yanming Shen and Tie-Yan Liu},
booktitle={Thirty-Fifth Conference on Neural Information Processing Systems},
year={2021},
url={https://openreview.net/forum?id=OeWooOxFwDa}
}


@inproceedings{
gui2022good,
title={{GOOD}: A Graph Out-of-Distribution Benchmark},
author={Shurui Gui and Xiner Li and Limei Wang and Shuiwang Ji},
booktitle={Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2022},
url={https://openreview.net/forum?id=8hHg-zs_p-h}
}


@article{li2022out,
  title={Out-of-distribution generalization on graphs: A survey},
  author={Li, Haoyang and Wang, Xin and Zhang, Ziwei and Zhu, Wenwu},
  journal={arXiv preprint arXiv:2202.07987},
  year={2022}
}

@article{liu2022graphGSSL,
  title={Graph self-supervised learning: A survey},
  author={Liu, Yixin and Jin, Ming and Pan, Shirui and Zhou, Chuan and Zheng, Yu and Xia, Feng and Philip, S Yu},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={35},
  number={6},
  pages={5879--5900},
  year={2022},
  publisher={IEEE}
}


@article{huang2020graphGMETA,
  title={Graph meta learning via local subgraphs},
  author={Huang, Kexin and Zitnik, Marinka},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={5862--5874},
  year={2020}
}


@article{velivckovic2018deepDGI,
  title={Deep graph infomax},
  author={Veli{\v{c}}kovi{\'c}, Petar and Fedus, William and Hamilton, William L and Li{\`o}, Pietro and Bengio, Yoshua and Hjelm, R Devon},
  journal={arXiv preprint arXiv:1809.10341},
  year={2018}
}

@incollection{icml2020_1971MVGRL,
 author = {Hassani, Kaveh and Khasahmadi, Amir Hosein},
 booktitle = {Proceedings of International Conference on Machine Learning},
 pages = {3451--3461},
 title = {Contrastive Multi-View Representation Learning on Graphs},
 year = {2020}
}

@article{sun2019infograph,
  title={Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization},
  author={Sun, Fan-Yun and Hoffmann, Jordan and Verma, Vikas and Tang, Jian},
  journal={arXiv preprint arXiv:1908.01000},
  year={2019}
}

@inproceedings{hou2022graphmae,
  title={Graphmae: Self-supervised masked graph autoencoders},
  author={Hou, Zhenyu and Liu, Xiao and Cen, Yukuo and Dong, Yuxiao and Yang, Hongxia and Wang, Chunjie and Tang, Jie},
  booktitle={Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={594--604},
  year={2022}
}

@inproceedings{hou2023graphmae2,
  title={GraphMAE2: A Decoding-Enhanced Masked Self-Supervised Graph Learner},
  author={Hou, Zhenyu and He, Yufei and Cen, Yukuo and Liu, Xiao and Dong, Yuxiao and Kharlamov, Evgeny and Tang, Jie},
  booktitle={Proceedings of the ACM Web Conference 2023},
  pages={737--746},
  year={2023}
}


@article{you2020graphGCL,
  title={Graph contrastive learning with augmentations},
  author={You, Yuning and Chen, Tianlong and Sui, Yongduo and Chen, Ting and Wang, Zhangyang and Shen, Yang},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={5812--5823},
  year={2020}
}

@inproceedings{zhou2022mentorgnn,
  title={Mentorgnn: Deriving curriculum for pre-training gnns},
  author={Zhou, Dawei and Zheng, Lecheng and Fu, Dongqi and Han, Jiawei and He, Jingrui},
  booktitle={Proceedings of the 31st ACM International Conference on Information \& Knowledge Management},
  pages={2721--2731},
  year={2022}
}



@inproceedings{GPPT,
author = {Sun, Mingchen and Zhou, Kaixiong and He, Xin and Wang, Ying and Wang, Xin},
title = {GPPT: Graph Pre-training and Prompt Tuning to Generalize Graph Neural Networks},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539249},
doi = {10.1145/3534678.3539249},
abstract = {Despite the promising representation learning of graph neural networks (GNNs), the supervised training of GNNs notoriously requires large amounts of labeled data from each application. An effective solution is to apply the transfer learning in graph: using easily accessible information to pre-train GNNs, and fine-tuning them to optimize the downstream task with only a few labels. Recently, many efforts have been paid to design the self-supervised pretext tasks, and encode the universal graph knowledge among the various applications. However, they rarely notice the inherent training objective gap between the pretext and downstream tasks. This significant gap often requires costly fine-tuning for adapting the pre-trained model to downstream problem, which prevents the efficient elicitation of pre-trained knowledge and then results in poor results. Even worse, the naive pre-training strategy usually deteriorates the downstream task, and damages the reliability of transfer learning in graph data. To bridge the task gap, we propose a novel transfer learning paradigm to generalize GNNs, namely graph pre-training and prompt tuning (GPPT). Specifically, we first adopt the masked edge prediction, the most simplest and popular pretext task, to pre-train GNNs. Based on the pre-trained model, we propose the graph prompting function to modify the standalone node into a token pair, and reformulate the downstream node classification looking the same as edge prediction. The token pair is consisted of candidate label class and node entity. Therefore, the pre-trained GNNs could be applied without tedious fine-tuning to evaluate the linking probability of token pair, and produce the node classification decision. The extensive experiments on eight benchmark datasets demonstrate the superiority of GPPT, delivering an average improvement of 4.29\% in few-shot graph analysis and accelerating the model convergence up to 4.32X. The code is available in: https://github.com/MingChen-Sun/GPPT.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1717–1727},
numpages = {11},
keywords = {prompt tuning, pre-training, graph neural networks},
location = {Washington DC, USA},
series = {KDD '22}
}


@article{granovetter1973strength,
  title={The strength of weak ties},
  author={Granovetter, Mark S},
  journal={American journal of sociology},
  volume={78},
  number={6},
  pages={1360--1380},
  year={1973},
  publisher={University of Chicago Press}
}

@article{zheng2022rethinkingGCL,
  title={Rethinking and scaling up graph contrastive learning: An extremely efficient approach with group discrimination},
  author={Zheng, Yizhen and Pan, Shirui and Lee, Vincent and Zheng, Yu and Yu, Philip S},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={10809--10820},
  year={2022}
}

@article{zhao2023graphgpt,
  title={GraphGPT: Graph Learning with Generative Pre-trained Transformers},
  author={Zhao, Qifang and Ren, Weidong and Li, Tianyu and Xu, Xiaoxiao and Liu, Hong},
  journal={arXiv preprint arXiv:2401.00529},
  year={2023}
}


@inproceedings{
xia2023molebert,
title={Mole-{BERT}: Rethinking Pre-training Graph Neural Networks for Molecules},
author={Jun Xia and Chengshuai Zhao and Bozhen Hu and Zhangyang Gao and Cheng Tan and Yue Liu and Siyuan Li and Stan Z. Li},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=jevY-DtiZTR}
}

@article{mandal2022metalearning,
  title={Metalearning with graph neural networks: Methods and applications},
  author={Mandal, Debmalya and Medya, Sourav and Uzzi, Brian and Aggarwal, Charu},
  journal={ACM SIGKDD Explorations Newsletter},
  volume={23},
  number={2},
  pages={13--22},
  year={2022},
  publisher={ACM New York, NY, USA}
}

@inproceedings{zhou2019meta,
  title={Meta-gnn: On few-shot node classification in graph meta-learning},
  author={Zhou, Fan and Cao, Chengtai and Zhang, Kunpeng and Trajcevski, Goce and Zhong, Ting and Geng, Ji},
  booktitle={Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
  pages={2357--2360},
  year={2019}
}



@article{zhang2021motif,
  title={Motif-based graph self-supervised learning for molecular property prediction},
  author={Zhang, Zaixi and Liu, Qi and Wang, Hao and Lu, Chengqiang and Lee, Chee-Kong},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={15870--15882},
  year={2021}
}


@article{hu2019strategiesAttrMask,
  title={Strategies for pre-training graph neural networks},
  author={Hu, Weihua and Liu, Bowen and Gomes, Joseph and Zitnik, Marinka and Liang, Percy and Pande, Vijay and Leskovec, Jure},
  journal={arXiv preprint arXiv:1905.12265},
  year={2019}
}

@inproceedings{qiu2020gcc,
  title={Gcc: Graph contrastive coding for graph neural network pre-training},
  author={Qiu, Jiezhong and Chen, Qibin and Dong, Yuxiao and Zhang, Jing and Yang, Hongxia and Ding, Ming and Wang, Kuansan and Tang, Jie},
  booktitle={Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery \& data mining},
  pages={1150--1160},
  year={2020}
}

@article{cao2023preW2PGNN,
  title={When to Pre-Train Graph Neural Networks? An Answer from Data Generation Perspective!},
  author={Cao, Yuxuan and Xu, Jiarong and Yang, Carl and Wang, Jiaan and Zhang, Yunchao and Wang, Chunping and Chen, Lei and Yang, Yang},
  journal={arXiv preprint arXiv:2303.16458},
  year={2023}
}

@article{xu2023betterWITHLESS,
  title={Better with Less: A Data-Active Perspective on Pre-Training Graph Neural Networks},
  author={Xu, Jiarong and Huang, Renhong and Jiang, Xin and Cao, Yuxuan and Yang, Carl and Wang, Chunping and Yang, Yang},
  journal={arXiv preprint arXiv:2311.01038},
  year={2023}
}


@inproceedings{NEURIPS2021_0dd6049f_EGI,
 author = {Zhu, Qi and Yang, Carl and Xu, Yidan and Wang, Haonan and Zhang, Chao and Han, Jiawei},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {1766--1779},
 publisher = {Curran Associates, Inc.},
 title = {Transfer Learning of Graph Neural Networks with Ego-graph Information Maximization},
 url = {https://proceedings.neurips.cc/paper_files/paper/2021/file/0dd6049f5fa537d41753be6d37859430-Paper.pdf},
 volume = {34},
 year = {2021}
}

@article{huang2023prodigy,
  title={PRODIGY: Enabling In-context Learning Over Graphs},
  author={Huang, Qian and Ren, Hongyu and Chen, Peng and Kr{\v{z}}manc, Gregor and Zeng, Daniel and Liang, Percy and Leskovec, Jure},
  journal={arXiv preprint arXiv:2305.12600},
  year={2023}
}


@article{kouw2018introductionGENERALTL,
  title={An introduction to domain adaptation and transfer learning},
  author={Kouw, Wouter M and Loog, Marco},
  journal={arXiv preprint arXiv:1812.11806},
  year={2018}
}


@inproceedings{
ma2022is,
title={Is Homophily a Necessity for Graph Neural Networks?},
author={Yao Ma and Xiaorui Liu and Neil Shah and Jiliang Tang},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=ucASPPD9GKN}
}


@inproceedings{ying2018graphPINSAGE,
  title={Graph convolutional neural networks for web-scale recommender systems},
  author={Ying, Rex and He, Ruining and Chen, Kaifeng and Eksombatchai, Pong and Hamilton, William L and Leskovec, Jure},
  booktitle={Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery \& data mining},
  pages={974--983},
  year={2018}
}
@article{luan2023graph,
  title={When do graph neural networks help with node classification: Investigating the homophily principle on node distinguishability},
  author={Luan, Sitao and Hua, Chenqing and Xu, Minkai and Lu, Qincheng and Zhu, Jiaqi and Chang, Xiao-Wen and Fu, Jie and Leskovec, Jure and Precup, Doina},
  journal={arXiv preprint arXiv:2304.14274},
  year={2023}
}
@article{wang2024understanding,
  title={Understanding Heterophily for Graph Neural Networks},
  author={Wang, Junfu and Guo, Yuanfang and Yang, Liang and Wang, Yunhong},
  journal={arXiv preprint arXiv:2401.09125},
  year={2024}
}
@article{zhang2018link,
  title={Link prediction based on graph neural networks},
  author={Zhang, Muhan and Chen, Yixin},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
@article{zheng2023you,
  title={You Only Transfer What You Share: Intersection-Induced Graph Transfer Learning for Link Prediction},
  author={Zheng, Wenqing and Huang, Edward W and Rao, Nikhil and Wang, Zhangyang and Subbian, Karthik},
  journal={arXiv preprint arXiv:2302.14189},
  year={2023}
}

@article{bronstein2021geometric,
  title={Geometric deep learning: Grids, groups, graphs, geodesics, and gauges},
  author={Bronstein, Michael M and Bruna, Joan and Cohen, Taco and Veli{\v{c}}kovi{\'c}, Petar},
  journal={arXiv preprint arXiv:2104.13478},
  year={2021}
}

@article{li2023universal,
  title={Universal representations: A unified look at multiple task and domain learning},
  author={Li, Wei-Hong and Liu, Xialei and Bilen, Hakan},
  journal={International Journal of Computer Vision},
  pages={1--25},
  year={2023},
  publisher={Springer}
}



@inproceedings{holtz2019multiTaskGraph,
  title={Multi-task learning on graphs with node and graph level labels},
  author={Holtz, Chester and Atan, Onur and Carey, Ryan and Jain, Tushit},
  booktitle={NeurIPS Workshop on Graph Representation Learning},
  year={2019}
}

@article{sun2023graphPrompt,
  title={Graph Prompt Learning: A Comprehensive Survey and Beyond},
  author={Sun, Xiangguo and Zhang, Jiawen and Wu, Xixi and Cheng, Hong and Xiong, Yun and Li, Jia},
  journal={arXiv preprint arXiv:2311.16534},
  year={2023}
}


@inproceedings{liu2023graphpromptWWW,
  title={Graphprompt: Unifying pre-training and downstream tasks for graph neural networks},
  author={Liu, Zemin and Yu, Xingtong and Fang, Yuan and Zhang, Xinming},
  booktitle={Proceedings of the ACM Web Conference 2023},
  pages={417--428},
  year={2023}
}

@article{li2023surveyGraphLLM,
  title={A survey of graph meets large language model: Progress and future directions},
  author={Li, Yuhan and Li, Zhixun and Wang, Peisong and Li, Jia and Sun, Xiangguo and Cheng, Hong and Yu, Jeffrey Xu},
  journal={arXiv preprint arXiv:2311.12399},
  year={2023}
}

@article{sun2023all,
  title={All in One: Multi-Task Prompting for Graph Neural Networks},
  author={Sun, Xiangguo and Cheng, Hong and Li, Jia and Liu, Bo and Guan, Jihong},
  year={2023}
}


@inproceedings{
wang2023can,
title={Can Language Models Solve Graph Problems in Natural Language?},
author={Heng Wang and Shangbin Feng and Tianxing He and Zhaoxuan Tan and Xiaochuang Han and Yulia Tsvetkov},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=UDqHhbqYJV}
}

@article{tang2023graphgpt,
  title={Graphgpt: Graph instruction tuning for large language models},
  author={Tang, Jiabin and Yang, Yuhao and Wei, Wei and Shi, Lei and Su, Lixin and Cheng, Suqi and Yin, Dawei and Huang, Chao},
  journal={arXiv preprint arXiv:2310.13023},
  year={2023}
}


@article{ye2023natural,
  title={Natural language is all a graph needs},
  author={Ye, Ruosong and Zhang, Caiqi and Wang, Runhui and Xu, Shuyuan and Zhang, Yongfeng},
  journal={arXiv:2308.07134},
  year={2023}
}



@InProceedings{pmlr-v97-you19bPGNN,
  title = 	 {Position-aware Graph Neural Networks},
  author =       {You, Jiaxuan and Ying, Rex and Leskovec, Jure},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {7134--7143},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/you19b/you19b.pdf},
  url = 	 {https://proceedings.mlr.press/v97/you19b.html},
  abstract = 	 {Learning node embeddings that capture a node’s position within the broader graph structure is crucial for many prediction tasks on graphs. However, existing Graph Neural Network (GNN) architectures have limited power in capturing the position/location of a given node with respect to all other nodes of the graph. Here we propose Position-aware Graph Neural Networks (P-GNNs), a new class of GNNs for computing position-aware node embeddings. P-GNN first samples sets of anchor nodes, computes the distance of a given target node to each anchor-set, and then learns a non-linear distance-weighted aggregation scheme over the anchor-sets. This way P-GNNs can capture positions/locations of nodes with respect to the anchor nodes. P-GNNs have several advantages: they are inductive, scalable, and can incorporate node feature information. We apply P-GNNs to multiple prediction tasks including link prediction and community detection. We show that P-GNNs consistently outperform state of the art GNNs, with up to 66% improvement in terms of the ROC AUC score.}
}


@article{srinivasan2019equivalence,
  title={On the equivalence between positional node embeddings and structural graph representations},
  author={Srinivasan, Balasubramaniam and Ribeiro, Bruno},
  journal={arXiv preprint arXiv:1910.00452},
  year={2019}
}

@article{zhang2021labeling,
  title={Labeling trick: A theory of using graph neural networks for multi-node representation learning},
  author={Zhang, Muhan and Li, Pan and Xia, Yinglong and Wang, Kai and Jin, Long},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={9061--9073},
  year={2021}
}


@article{galkin2021nodepiece,
  title={Nodepiece: Compositional and parameter-efficient representations of large knowledge graphs},
  author={Galkin, Mikhail and Denis, Etienne and Wu, Jiapeng and Hamilton, William L},
  journal={arXiv preprint arXiv:2106.12144},
  year={2021}
}


@article{zhu2021neuralNBF,
  title={Neural bellman-ford networks: A general graph neural network framework for link prediction},
  author={Zhu, Zhaocheng and Zhang, Zuobai and Xhonneux, Louis-Pascal and Tang, Jian},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={29476--29490},
  year={2021}
}

@article{huang2023theoryLP,
  title={A theory of link prediction via relational weisfeiler-leman},
  author={Huang, Xingyue and Orth, Miguel Romero and Ceylan, {\.I}smail {\.I}lkan and Barcel{\'o}, Pablo},
  journal={arXiv preprint arXiv:2302.02209},
  year={2023}
}
@inproceedings{vashishth2019composition,
  title={Composition-based Multi-Relational Graph Convolutional Networks},
  author={Vashishth, Shikhar and Sanyal, Soumya and Nitin, Vikram and Talukdar, Partha},
  booktitle={International Conference on Learning Representations},
  year={2019}
}
@inproceedings{schlichtkrull2018modeling,
  title={Modeling relational data with graph convolutional networks},
  author={Schlichtkrull, Michael and Kipf, Thomas N and Bloem, Peter and Van Den Berg, Rianne and Titov, Ivan and Welling, Max},
  booktitle={The Semantic Web: 15th International Conference, ESWC 2018, Heraklion, Crete, Greece, June 3--7, 2018, Proceedings 15},
  pages={593--607},
  year={2018},
  organization={Springer}
}
@article{gao2023doubleEquivariant,
  title={Double permutation equivariance for knowledge graph completion},
  author={Gao, Jianfei and Zhou, Yangze and Ribeiro, Bruno},
  journal={arXiv preprint arXiv:2302.01313},
  year={2023}
}


@inproceedings{esser2021tamingVQGAN,
  title={Taming transformers for high-resolution image synthesis},
  author={Esser, Patrick and Rombach, Robin and Ommer, Bjorn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12873--12883},
  year={2021}
}

@article{yu2023language,
  title={Language Model Beats Diffusion--Tokenizer is Key to Visual Generation},
  author={Yu, Lijun and Lezama, Jos{\'e} and Gundavarapu, Nitesh B and Versari, Luca and Sohn, Kihyuk and Minnen, David and Cheng, Yong and Gupta, Agrim and Gu, Xiuye and Hauptmann, Alexander G and others},
  journal={arXiv preprint arXiv:2310.05737},
  year={2023}
}


@misc{wang2023gvtGOODVISUALTOKENIZERS,
      title={What Makes for Good Visual Tokenizers for Large Language Models?}, 
      author={Guangzhi Wang and Yixiao Ge and Xiaohan Ding and Mohan Kankanhalli and Ying Shan},
      year={2023},
      eprint={2305.12223},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@article{yasunaga2022linkbert,
  title={Linkbert: Pretraining language models with document links},
  author={Yasunaga, Michihiro and Leskovec, Jure and Liang, Percy},
  journal={arXiv preprint arXiv:2203.15827},
  year={2022}
}

@article{jin2023patton,
  title={Patton: Language Model Pretraining on Text-Rich Networks},
  author={Jin, Bowen and Zhang, Wentao and Zhang, Yu and Meng, Yu and Zhang, Xinyang and Zhu, Qi and Han, Jiawei},
  journal={arXiv preprint arXiv:2305.12268},
  year={2023}
}

@InProceedings{yasunaga2022dragon,
  author =  {Michihiro Yasunaga and Antoine Bosselut and Hongyu Ren and Xikun Zhang and Christopher D. Manning and Percy Liang and Jure Leskovec},
  title =   {Deep Bidirectional Language-Knowledge Graph Pretraining},
  year =    {2022},  
  booktitle = {Neural Information Processing Systems (NeurIPS)},  
}


@inproceedings{joshi2023expressive,
  title={On the Expressive Power of Geometric Graph Neural Networks},
  author={Joshi, Chaitanya K. and Bodnar, Cristian and  Mathis, Simon V. and Cohen, Taco and Liò, Pietro},
  booktitle={International Conference on Machine Learning},
  year={2023},
}

@article{JMLR:v24:22-0240_WLStory,
  author  = {Christopher Morris and Yaron Lipman and Haggai Maron and Bastian Rieck and Nils M. Kriege and Martin Grohe and Matthias Fey and Karsten Borgwardt},
  title   = {Weisfeiler and Leman go Machine Learning: The Story so far},
  journal = {Journal of Machine Learning Research},
  year    = {2023},
  volume  = {24},
  number  = {333},
  pages   = {1--59},
  url     = {http://jmlr.org/papers/v24/22-0240.html}
}


@inproceedings{hibshman2021joint,
  title={Joint subgraph-to-subgraph transitions: Generalizing triadic closure for powerful and interpretable graph modeling},
  author={Hibshman, Justus Isaiah and Gonzalez, Daniel and Sikdar, Satyaki and Weninger, Tim},
  booktitle={Proceedings of the 14th ACM International Conference on Web Search and Data Mining},
  pages={815--823},
  year={2021}
}
@inproceedings{dong2017structural,
  title={Structural diversity and homophily: A study across more than one hundred big networks},
  author={Dong, Yuxiao and Johnson, Reid A and Xu, Jian and Chawla, Nitesh V},
  booktitle={Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  pages={807--816},
  year={2017}
}
@article{li2023graphcleaner,
  title={GraphCleaner: Detecting Mislabelled Samples in Popular Graph Learning Benchmarks},
  author={Li, Yuwen and Xiong, Miao and Hooi, Bryan},
  journal={arXiv preprint arXiv:2306.00015},
  year={2023}
}
@article{kriege2020survey,
  title={A survey on graph kernels},
  author={Kriege, Nils M and Johansson, Fredrik D and Morris, Christopher},
  journal={Applied Network Science},
  volume={5},
  number={1},
  pages={1--42},
  year={2020},
  publisher={SpringerOpen}
}
@inproceedings{abuoda2020link,
  title={Link prediction via higher-order motif features},
  author={AbuOda, Ghadeer and De Francisci Morales, Gianmarco and Aboulnaga, Ashraf},
  booktitle={Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2019, W{\"u}rzburg, Germany, September 16--20, 2019, Proceedings, Part I},
  pages={412--429},
  year={2020},
  organization={Springer}
}


@article{huang2023stability,
  title={On the stability of expressive positional encodings for graph neural networks},
  author={Huang, Yinan and Lu, William and Robinson, Joshua and Yang, Yu and Zhang, Muhan and Jegelka, Stefanie and Li, Pan},
  journal={arXiv preprint arXiv:2310.02579},
  year={2023}
}
@article{chen2020can,
  title={Can graph neural networks count substructures?},
  author={Chen, Zhengdao and Chen, Lei and Villar, Soledad and Bruna, Joan},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={10383--10395},
  year={2020}
}
@article{liu2023simga,
  title={SIMGA: A Simple and Effective Heterophilous Graph Neural Network with Efficient Global Aggregation},
  author={Liu, Haoyu and Liao, Ningyi and Luo, Siqiang},
  journal={arXiv preprint arXiv:2305.09958},
  year={2023}
}
@article{yue2023llamarec,
  title={LlamaRec: Two-Stage Recommendation using Large Language Models for Ranking},
  author={Yue, Zhenrui and Rabhi, Sara and Moreira, Gabriel de Souza Pereira and Wang, Dong and Oldridge, Even},
  journal={arXiv preprint arXiv:2311.02089},
  year={2023}
}
@article{kreuzer2021rethinking,
  title={Rethinking graph transformers with spectral attention},
  author={Kreuzer, Devin and Beaini, Dominique and Hamilton, Will and L{\'e}tourneau, Vincent and Tossou, Prudencio},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={21618--21629},
  year={2021}
}
@inproceedings{lim2022sign,
  title={Sign and Basis Invariant Networks for Spectral Graph Representation Learning},
  author={Lim, Derek and Robinson, Joshua David and Zhao, Lingxiao and Smidt, Tess and Sra, Suvrit and Maron, Haggai and Jegelka, Stefanie},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@inproceedings{
    xu2018how,
    title={How Powerful are Graph Neural Networks?},
    author={Keyulu Xu and Weihua Hu and Jure Leskovec and Stefanie Jegelka},
    booktitle={International Conference on Learning Representations},
    year={2019},
    url={https://openreview.net/forum?id=ryGs6iA5Km},
}

@inproceedings{morris2019weisfeiler,
  title={Weisfeiler and leman go neural: Higher-order graph neural networks},
  author={Morris, Christopher and Ritzert, Martin and Fey, Matthias and Hamilton, William L and Lenssen, Jan Eric and Rattan, Gaurav and Grohe, Martin},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={4602--4609},
  year={2019}
}

@article{nt2019revisiting,
  title={Revisiting graph neural networks: All we have is low-pass filters},
  author={Nt, Hoang and Maehara, Takanori},
  journal={arXiv preprint arXiv:1905.09550},
  year={2019}
}
@inproceedings{shi2022learning,
  title={Learning Symbolic Models for Graph-structured Physical Mechanism},
  author={Shi, Hongzhi and Ding, Jingtao and Cao, Yufan and Liu, Li and Li, Yong and others},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}
@article{wang2023neural,
  title={Neural Common Neighbor with Completion for Link Prediction},
  author={Wang, Xiyuan and Yang, Haotong and Zhang, Muhan},
  journal={arXiv preprint arXiv:2302.00890},
  year={2023}
}
@inproceedings{chen2022representing,
  title={On Representing Linear Programs by Graph Neural Networks},
  author={Chen, Ziang and Liu, Jialin and Wang, Xinshang and Yin, Wotao},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}
@article{zhai2023commonscenes,
  title={CommonScenes: Generating Commonsense 3D Indoor Scenes with Scene Graphs},
  author={Zhai, Guangyao and {\"O}rnek, Evin Pinar and Wu, Shun-Cheng and Di, Yan and Tombari, Federico and Navab, Nassir and Busam, Benjamin},
  journal={arXiv preprint arXiv:2305.16283},
  year={2023}
}
@inproceedings{barcelo2020,
title={The Logical Expressiveness of Graph Neural Networks},
author={Pablo Barceló and Egor V. Kostylev and Mikael Monet and Jorge Pérez and Juan Reutter and Juan Pablo Silva},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=r1lZ7AEKvB}
}

@InProceedings{pmlr-v202-morris23aWLVC,
  title = 	 {{WL} meet {VC}},
  author =       {Morris, Christopher and Geerts, Floris and T\"{o}nshoff, Jan and Grohe, Martin},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {25275--25302},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/morris23a/morris23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/morris23a.html},
  abstract = 	 {Recently, many works studied the expressive power of graph neural networks (GNNs) by linking it to the $1$-dimensional Weisfeiler-Leman algorithm ($1\text{-}\mathsf{WL}$). Here, the $1\text{-}\mathsf{WL}$ is a well-studied heuristic for the graph isomorphism problem, which iteratively colors or partitions a graph’s vertex set. While this connection has led to significant advances in understanding and enhancing GNNs’ expressive power, it does not provide insights into their generalization performance, i.e., their ability to make meaningful predictions beyond the training set. In this paper, we study GNNs’ generalization ability through the lens of Vapnik-Chervonenkis (VC) dimension theory in two settings, focusing on graph-level predictions. First, when no upper bound on the graphs’ order is known, we show that the bitlength of GNNs’ weights tightly bounds their VC dimension. Further, we derive an upper bound for GNNs’ VC dimension using the number of colors produced by the $1\text{-}\mathsf{WL}$. Secondly, when an upper bound on the graphs’ order is known, we show a tight connection between the number of graphs distinguishable by the $1\text{-}\mathsf{WL}$ and GNNs’ VC dimension. Our empirical study confirms the validity of our theoretical findings.}
}

@inproceedings{bevilacqua2021sizeInvariance,
  title={Size-invariant graph representations for graph classification extrapolations},
  author={Bevilacqua, Beatrice and Zhou, Yangze and Ribeiro, Bruno},
  booktitle={International Conference on Machine Learning},
  pages={837--851},
  year={2021},
  organization={PMLR}
}


@inproceedings{yehudai2021localSizeSSL,
  title={From local structures to size generalization in graph neural networks},
  author={Yehudai, Gilad and Fetaya, Ethan and Meirom, Eli and Chechik, Gal and Maron, Haggai},
  booktitle={International Conference on Machine Learning},
  pages={11975--11986},
  year={2021},
  organization={PMLR}
}

@inproceedings{
  buffelli2022sizeshiftreg,
  title={SizeShiftReg: a Regularization Method for Improving Size-Generalization in Graph Neural Networks},
  author={Davide Buffelli and Pietro Lio and Fabio Vandin},
  booktitle={Advances in Neural Information Processing Systems},
  editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
  year={2022},
  url={https://openreview.net/forum?id=wOI0AUAq9BR}
}

%%%% dataset

@article{henighan2020scaling,
  title={Scaling laws for autoregressive generative modeling},
  author={Henighan, Tom and Kaplan, Jared and Katz, Mor and Chen, Mark and Hesse, Christopher and Jackson, Jacob and Jun, Heewoo and Brown, Tom B and Dhariwal, Prafulla and Gray, Scott and others},
  journal={arXiv preprint arXiv:2010.14701},
  year={2020}
}

@inproceedings{chen2023uncovering,
  title={Uncovering Neural Scaling Laws in Molecular Representation Learning},
  author={Dingshuo Chen and Yanqiao Zhu and Jieyu Zhang and Yuanqi Du and Zhixun Li and Qiang Liu and Shu Wu and Liang Wang},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2023},
  url={https://openreview.net/forum?id=Ys8RmfF9w1}
}

@inproceedings{khatua2023igb,
  author = {Khatua, Arpandeep and Mailthody, Vikram Sharma and Taleka, Bhagyashree and Ma, Tengfei and Song, Xiang and Hwu, Wen-mei},
  title = {IGB: Addressing The Gaps In Labeling, Features, Heterogeneity, and Size of Public Graph Datasets for Deep Learning Research},
  year = {2023},
  isbn = {9798400701030},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3580305.3599843},
  doi = {10.1145/3580305.3599843},
  booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages = {4284–4295},
  numpages = {12},
}

@article{hu2020open,
  title={Open graph benchmark: Datasets for machine learning on graphs},
  author={Hu, Weihua and Fey, Matthias and Zitnik, Marinka and Dong, Yuxiao and Ren, Hongyu and Liu, Bowen and Catasta, Michele and Leskovec, Jure},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={22118--22133},
  year={2020}
}

@inproceedings{um2023confidencebased,
  title={Confidence-Based Feature Imputation for Graphs with Partially Known Features},
  author={Daeho Um and Jiwoong Park and Seulki Park and Jin young Choi},
  booktitle={The Eleventh International Conference on Learning Representations },
  year={2023},
  url={https://openreview.net/forum?id=YPKBIILy-Kt}
}

@inproceedings{rossi2022unreasonable,
  title={On the unreasonable effectiveness of feature propagation in learning on graphs with missing node features},
  author={Rossi, Emanuele and Kenlay, Henry and Gorinova, Maria I and Chamberlain, Benjamin Paul and Dong, Xiaowen and Bronstein, Michael M},
  booktitle={Learning on Graphs Conference},
  pages={11--1},
  year={2022},
  organization={PMLR}
}

@article{taguchi2021graph,
  title={Graph convolutional networks for graphs containing missing features},
  author={Taguchi, Hibiki and Liu, Xin and Murata, Tsuyoshi},
  journal={Future Generation Computer Systems},
  volume={117},
  pages={155--168},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{gupta2023grafenne,
  title={GRAFENNE: learning on graphs with heterogeneous and dynamic feature sets},
  author={Gupta, Shubham and Manchanda, Sahil and Ranu, Sayan and Bedathur, Srikanta J},
  booktitle={International Conference on Machine Learning},
  pages={12165--12181},
  year={2023},
  organization={PMLR}
}

@inproceedings{liu2023visual,
  title={Visual Instruction Tuning},
  author={Haotian Liu and Chunyuan Li and Qingyang Wu and Yong Jae Lee},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023},
  url={https://openreview.net/forum?id=w0H2xGHlkw}
}

@article{bai2023qwen,
  title={Qwen-vl: A frontier large vision-language model with versatile abilities},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  year={2023}
}

@inproceedings{tang2020investigating,
  title={Investigating and mitigating degree-related biases in graph convolutional networks},
  author={Tang, Xianfeng and Yao, Huaxiu and Sun, Yiwei and Wang, Yiqi and Tang, Jiliang and Aggarwal, Charu and Mitra, Prasenjit and Wang, Suhang},
  booktitle={Proceedings of the 29th ACM International Conference on Information \& Knowledge Management},
  pages={1435--1444},
  year={2020}
}

@inproceedings{zheng2021cold,
  title={Cold Brew: Distilling Graph Node Representations with Incomplete or Missing Neighborhoods},
  author={Zheng, Wenqing and Huang, Edward W and Rao, Nikhil and Katariya, Sumeet and Wang, Zhangyang and Subbian, Karthik},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{lu2020meta,
  title={Meta-learning on heterogeneous information networks for cold-start recommendation},
  author={Lu, Yuanfu and Fang, Yuan and Shi, Chuan},
  booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={1563--1573},
  year={2020}
}

@article{xie2023graphGALM,
  title={Graph-Aware Language Model Pre-Training on a Large Graph Corpus Can Help Multiple Graph Applications},
  author={Xie, Han and Zheng, Da and Ma, Jun and Zhang, Houyu and Ioannidis, Vassilis N and Song, Xiang and Ping, Qing and Wang, Sheng and Yang, Carl and Xu, Yi and others},
  journal={arXiv preprint arXiv:2306.02592},
  year={2023}
}


@article{dong2022survey,
  title={A survey for in-context learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Wu, Zhiyong and Chang, Baobao and Sun, Xu and Xu, Jingjing and Sui, Zhifang},
  journal={arXiv preprint arXiv:2301.00234},
  year={2022}
}

@article{kipf2016variationalVGAE,
  title={Variational graph auto-encoders},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1611.07308},
  year={2016}
}

@article{jin2021automatedAUTOSSL,
  title={Automated self-supervised learning for graphs},
  author={Jin, Wei and Liu, Xiaorui and Zhao, Xiangyu and Ma, Yao and Shah, Neil and Tang, Jiliang},
  journal={arXiv preprint arXiv:2106.05470},
  year={2021}
}


@inproceedings{liu2023rethinkingSIMSGT,
    title={Rethinking Tokenizer and Decoder in Masked Graph Modeling for Molecules},
    author={Liu, Zhiyuan and Shi, Yaorui and Zhang, An and Zhang, Enzhi and Kawaguchi, Kenji and Wang, Xiang and Chua, Tat-Seng},
    booktitle={NeurIPS},
    year={2023},
    url={https://openreview.net/forum?id=fWLf8DV0fI}
}
@article{brugere2018network,
  title={Network structure inference, a survey: Motivations, methods, and applications},
  author={Brugere, Ivan and Gallagher, Brian and Berger-Wolf, Tanya Y},
  journal={ACM Computing Surveys (CSUR)},
  volume={51},
  number={2},
  pages={1--39},
  year={2018},
  publisher={ACM New York, NY, USA}
}
@inproceedings{zhu2021empirical,
  title={An Empirical Study of Graph Contrastive Learning},
  author={Zhu, Yanqiao and Xu, Yichen and Liu, Qiang and Wu, Shu},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year={2021}
}

@inproceedings{he2022maskedMAE,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={16000--16009},
  year={2022}
}


@article{jin2020self,
  title={Self-supervised learning on graphs: Deep insights and new direction},
  author={Jin, Wei and Derr, Tyler and Liu, Haochen and Wang, Yiqi and Wang, Suhang and Liu, Zitao and Tang, Jiliang},
  journal={arXiv preprint arXiv:2006.10141},
  year={2020}
}


@article{fang2022prompt,
  title={Prompt tuning for graph neural networks},
  author={Fang, Taoran and Zhang, Yunchao and Yang, Yang and Wang, Chunping},
  journal={arXiv preprint arXiv:2209.15240},
  year={2022}
}

@article{jin2023largesurvey,
  title={Large Language Models on Graphs: A Comprehensive Survey},
  author={Jin, Bowen and Liu, Gang and Han, Chi and Jiang, Meng and Ji, Heng and Han, Jiawei},
  journal={arXiv preprint arXiv:2312.02783},
  year={2023}
}

@article{chen2024llaga,
  title={LLaGA: Large Language and Graph Assistant},
  author={Chen, Runjin and Zhao, Tong and Jaiswal, Ajay and Shah, Neil and Wang, Zhangyang},
  journal={arXiv preprint arXiv:2402.08170},
  year={2024}
}

@article{pan2024unifyingsurvey,
  title={Unifying large language models and knowledge graphs: A roadmap},
  author={Pan, Shirui and Luo, Linhao and Wang, Yufei and Chen, Chen and Wang, Jiapu and Wu, Xindong},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2024},
  publisher={IEEE}
}
@inproceedings{wang2021equivariant,
  title={Equivariant and Stable Positional Encoding for More Powerful Graph Neural Networks},
  author={Wang, Haorui and Yin, Haoteng and Zhang, Muhan and Li, Pan},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{zhang2023graph,
  title={Graph Meets LLMs: Towards Large Graph Models},
  author={Zhang, Ziwei and Li, Haoyang and Zhang, Zeyang and Qin, Yijian and Wang, Xin and Zhu, Wenwu},
  booktitle={NeurIPS 2023 Workshop: New Frontiers in Graph Learning},
  year={2023}
}
@article{khanam2020homophily,
  title={The homophily principle in social network analysis},
  author={Khanam, Kazi Zainab and Srivastava, Gautam and Mago, Vijay},
  journal={arXiv preprint arXiv:2008.10383},
  year={2020}
}
@inproceedings{you2023graph,
  title={Graph domain adaptation via theory-grounded spectral regularization},
  author={You, Yuning and Chen, Tianlong and Wang, Zhangyang and Shen, Yang},
  booktitle={The eleventh international conference on learning representations},
  year={2023}
}
@article{zhang2024beyond,
  title={Beyond Weisfeiler-Lehman: A Quantitative Framework for GNN Expressiveness},
  author={Zhang, Bohang and Gai, Jingchu and Du, Yiheng and Ye, Qiwei and He, Di and Wang, Liwei},
  journal={arXiv preprint arXiv:2401.08514},
  year={2024}
}
@article{liu2023data,
  title={Data-Centric Learning from Unlabeled Graphs with Diffusion Model},
  author={Liu, Gang and Inae, Eric and Zhao, Tong and Xu, Jiaxin and Luo, Tengfei and Jiang, Meng},
  journal={arXiv preprint arXiv:2303.10108},
  year={2023}
}
@article{zhao2023graphtext,
  title={Graphtext: Graph reasoning in text space},
  author={Zhao, Jianan and Zhuo, Le and Shen, Yikang and Qu, Meng and Liu, Kai and Bronstein, Michael and Zhu, Zhaocheng and Tang, Jian},
  journal={arXiv preprint arXiv:2310.01089},
  year={2023}
}
@inproceedings{gao2023double,
  title={Double Equivariance for Inductive Link Prediction for Both New Nodes and New Relation Types},
  author={Gao, Jianfei and Zhou, Yangze and Zhou, Jincheng and Ribeiro, Bruno},
  booktitle={NeurIPS 2023 Workshop: New Frontiers in Graph Learning},
  year={2023}
}
@article{zhang2023largeLLMsurvey,
  title={Large graph models: A perspective},
  author={Zhang, Ziwei and Li, Haoyang and Zhang, Zeyang and Qin, Yijian and Wang, Xin and Zhu, Wenwu},
  journal={arXiv preprint arXiv:2308.14522},
  year={2023}
}

@article{leskovec2010kronecker,
  title={Kronecker graphs: an approach to modeling networks.},
  author={Leskovec, Jure and Chakrabarti, Deepayan and Kleinberg, Jon and Faloutsos, Christos and Ghahramani, Zoubin},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={2},
  year={2010}
}

@article{albert2002statistical,
  title={Statistical mechanics of complex networks},
  author={Albert, R{\'e}ka and Barab{\'a}si, Albert-L{\'a}szl{\'o}},
  journal={Reviews of modern physics},
  volume={74},
  number={1},
  pages={47},
  year={2002},
  publisher={APS}
}

@article{robins2007introduction,
  title={An introduction to exponential random graph (p*) models for social networks},
  author={Robins, Garry and Pattison, Pip and Kalish, Yuval and Lusher, Dean},
  journal={Social networks},
  volume={29},
  number={2},
  pages={173--191},
  year={2007},
  publisher={Elsevier}
}

@article{airoldi2008mixed,
  title={Mixed membership stochastic blockmodels},
  author={Airoldi, Edo M and Blei, David and Fienberg, Stephen and Xing, Eric},
  journal={Advances in neural information processing systems},
  volume={21},
  year={2008}
}

@inproceedings{jin2020hierarchical,
  title={Hierarchical generation of molecular graphs using structural motifs},
  author={Jin, Wengong and Barzilay, Regina and Jaakkola, Tommi},
  booktitle={International conference on machine learning},
  pages={4839--4848},
  year={2020},
  organization={PMLR}
}

@article{ma2018constrained,
  title={Constrained generation of semantically valid graphs via regularizing variational autoencoders},
  author={Ma, Tengfei and Chen, Jie and Xiao, Cao},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{de2018molgan,
  title={MolGAN: An implicit generative model for small molecular graphs},
  author={De Cao, Nicola and Kipf, Thomas},
  journal={ICML 2018 workshop on Theoretical Foundations and Applications of Deep Generative Models},
  year={2018}
}

@inproceedings{bojchevski2018netgan,
  title={Netgan: Generating graphs via random walks},
  author={Bojchevski, Aleksandar and Shchur, Oleksandr and Z{\"u}gner, Daniel and G{\"u}nnemann, Stephan},
  booktitle={International conference on machine learning},
  pages={610--619},
  year={2018},
  organization={PMLR}
}

@inproceedings{Shi2020GraphAF,
  title={GraphAF: a Flow-based Autoregressive Model for Molecular Graph Generation},
  author={Chence Shi* and Minkai Xu* and Zhaocheng Zhu and Weinan Zhang and Ming Zhang and Jian Tang},
  booktitle={International Conference on Learning Representations},
  year={2020},
  url={https://openreview.net/forum?id=S1esMkHYPr}
}

@inproceedings{luo2021graphdf,
  title={Graphdf: A discrete flow model for molecular graph generation},
  author={Luo, Youzhi and Yan, Keqiang and Ji, Shuiwang},
  booktitle={International Conference on Machine Learning},
  pages={7192--7203},
  year={2021},
  organization={PMLR}
}

@inproceedings{jo2022score,
  title={Score-based generative modeling of graphs via the system of stochastic differential equations},
  author={Jo, Jaehyeong and Lee, Seul and Hwang, Sung Ju},
  booktitle={International Conference on Machine Learning},
  pages={10362--10383},
  year={2022},
  organization={PMLR}
}

@inproceedings{vignac2023digress,
  title={DiGress: Discrete Denoising diffusion for graph generation},
  author={Clement Vignac and Igor Krawczuk and Antoine Siraudin and Bohan Wang and Volkan Cevher and Pascal Frossard},
  booktitle={The Eleventh International Conference on Learning Representations },
  year={2023},
  url={https://openreview.net/forum?id=UaAD-Nu86WX}
}

@inproceedings{palowitch2022graphworld,
  title={Graphworld: Fake graphs bring real insights for gnns},
  author={Palowitch, John and Tsitsulin, Anton and Mayer, Brandon and Perozzi, Bryan},
  booktitle={Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={3691--3701},
  year={2022}
}

@inproceedings{palowitch2022synthetic,
  title={Synthetic Graph Generation to Benchmark Graph Learning},
  author={Palowitch, John and Tsitsulin, Anton and Perozzi, Bryan and Mayer, Brandon A},
  booktitle={NeurIPS 2022 Workshop: New Frontiers in Graph Learning},
  year={2022}
}
@article{liu2022revisitingSGCL,
  title={Revisiting graph contrastive learning from the perspective of graph spectrum},
  author={Liu, Nian and Wang, Xiao and Bo, Deyu and Shi, Chuan and Pei, Jian},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={2972--2983},
  year={2022}
}

@inproceedings{liu2023datacentric,
  title={Data-Centric Learning from Unlabeled Graphs with Diffusion Model},
  author={Gang Liu and Eric Inae and Tong Zhao and Jiaxin Xu and Tengfei Luo and Meng Jiang},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023},
  url={https://openreview.net/forum?id=DmakwvCJ7l}
}

@inproceedings{mishra2022task2sim,
  title={Task2sim: Towards effective pre-training and transfer from synthetic data},
  author={Mishra, Samarth and Panda, Rameswar and Phoo, Cheng Perng and Chen, Chun-Fu Richard and Karlinsky, Leonid and Saenko, Kate and Saligrama, Venkatesh and Feris, Rogerio S},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9194--9204},
  year={2022}
}

@article{trinh2024solving,
  title={Solving olympiad geometry without human demonstrations},
  author={Trinh, Trieu H and Wu, Yuhuai and Le, Quoc V and He, He and Luong, Thang},
  journal={Nature},
  volume={625},
  number={7995},
  pages={476--482},
  year={2024},
  publisher={Nature Publishing Group}
}

@inproceedings{cascante2023going,
  title={Going beyond nouns with vision \& language models using synthetic data},
  author={Cascante-Bonilla, Paola and Shehada, Khaled and Smith, James Seale and Doveh, Sivan and Kim, Donghyun and Panda, Rameswar and Varol, Gul and Oliva, Aude and Ordonez, Vicente and Feris, Rogerio and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={20155--20165},
  year={2023}
}

@inproceedings{han2022g,
  title={G-mixup: Graph data augmentation for graph classification},
  author={Han, Xiaotian and Jiang, Zhimeng and Liu, Ninghao and Hu, Xia},
  booktitle={International Conference on Machine Learning},
  pages={8230--8248},
  year={2022},
  organization={PMLR}
}

@inproceedings{luo2022automated,
  title={Automated Data Augmentations for Graph Classification},
  author={Luo, Youzhi and McThrow, Michael Curtis and Au, Wing Yee and Komikado, Tao and Uchino, Kanji and Maruhashi, Koji and Ji, Shuiwang},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@inproceedings{rong2019dropedge,
  title={DropEdge: Towards Deep Graph Convolutional Networks on Node Classification},
  author={Rong, Yu and Huang, Wenbing and Xu, Tingyang and Huang, Junzhou},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{you2020graph,
  title={Graph contrastive learning with augmentations},
  author={You, Yuning and Chen, Tianlong and Sui, Yongduo and Chen, Ting and Wang, Zhangyang and Shen, Yang},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={5812--5823},
  year={2020}
}

@article{milo2002network,
  title={Network motifs: simple building blocks of complex networks},
  author={Milo, Ron and Shen-Orr, Shai and Itzkovitz, Shalev and Kashtan, Nadav and Chklovskii, Dmitri and Alon, Uri},
  journal={Science},
  volume={298},
  number={5594},
  pages={824--827},
  year={2002},
  publisher={American Association for the Advancement of Science}
}

@article{battiston2020networks,
  title={Networks beyond pairwise interactions: Structure and dynamics},
  author={Battiston, Federico and Cencetti, Giulia and Iacopini, Iacopo and Latora, Vito and Lucas, Maxime and Patania, Alice and Young, Jean-Gabriel and Petri, Giovanni},
  journal={Physics Reports},
  volume={874},
  pages={1--92},
  year={2020},
  publisher={Elsevier}
}

@article{benson2016higher,
  title={Higher-order organization of complex networks},
  author={Benson, Austin R and Gleich, David F and Leskovec, Jure},
  journal={Science},
  volume={353},
  number={6295},
  pages={163--166},
  year={2016},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{yuan2021explainability,
  title={On explainability of graph neural networks via subgraph explorations},
  author={Yuan, Hao and Yu, Haiyang and Wang, Jie and Li, Kang and Ji, Shuiwang},
  booktitle={International conference on machine learning},
  pages={12241--12252},
  year={2021},
  organization={PMLR}
}

@article{zheng2023towards,
  title={Towards Predicting Equilibrium Distributions for Molecular Systems with Deep Learning},
  author={Zheng, Shuxin and He, Jiyan and Liu, Chang and Shi, Yu and Lu, Ziheng and Feng, Weitao and Ju, Fusong and Wang, Jiaxi and Zhu, Jianwei and Min, Yaosen and others},
  journal={arXiv preprint arXiv:2306.05445},
  year={2023}
}


@article{liu2024neural,
  title={Neural scaling laws on graphs},
  author={Liu, Jingzhe and Mao, Haitao and Chen, Zhikai and Zhao, Tong and Shah, Neil and Tang, Jiliang},
  year={2024}
}

@inproceedings{liu2023llava,
    author      = {Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
    title       = {Visual Instruction Tuning},
    booktitle   = {NeurIPS},
    year        = {2023}
  }

@article{mccoy2023embers,
  title={Embers of autoregression: Understanding large language models through the problem they are trained to solve},
  author={McCoy, R Thomas and Yao, Shunyu and Friedman, Dan and Hardy, Matthew and Griffiths, Thomas L},
  journal={arXiv preprint arXiv:2309.13638},
  year={2023}
}
@article{saparov2022language,
  title={Language models are greedy reasoners: A systematic formal analysis of chain-of-thought},
  author={Saparov, Abulhair and He, He},
  journal={arXiv preprint arXiv:2210.01240},
  year={2022}
}
@article{dziri2023faith,
  title={Faith and Fate: Limits of Transformers on Compositionality},
  author={Dziri, Nouha and Lu, Ximing and Sclar, Melanie and Li, Xiang Lorraine and Jian, Liwei and Lin, Bill Yuchen and West, Peter and Bhagavatula, Chandra and Bras, Ronan Le and Hwang, Jena D and others},
  journal={arXiv preprint arXiv:2305.18654},
  year={2023}
}

@article{chai2023graphllm,
  title={Graphllm: Boosting graph reasoning ability of large language model},
  author={Chai, Ziwei and Zhang, Tianjie and Wu, Liang and Han, Kaiqiao and Hu, Xiaohai and Huang, Xuanwen and Yang, Yang},
  journal={arXiv preprint arXiv:2310.05845},
  year={2023}
}

@article{zhou2023oodLP,
  title={An ood multi-task perspective for link prediction with new relation types and nodes},
  author={Zhou, Jincheng and Bevilacqua, Beatrice and Ribeiro, Bruno},
  journal={arXiv preprint arXiv:2307.06046},
  year={2023}
}


@article{yu2023languageTOKEN,
  title={Language Model Beats Diffusion--Tokenizer is Key to Visual Generation},
  author={Yu, Lijun and Lezama, Jos{\'e} and Gundavarapu, Nitesh B and Versari, Luca and Sohn, Kihyuk and Minnen, David and Cheng, Yong and Gupta, Agrim and Gu, Xiuye and Hauptmann, Alexander G and others},
  journal={arXiv preprint arXiv:2310.05737},
  year={2023}
}



@misc{gender-bias-llm,
title = {Gender Bias in LLMs},
author = {Hadas Kotek and Rikker Dockum and David Q. Sun},
year = {2023},
URL = {https://arxiv.org/abs/2308.14921}
}

@article{ganguli2023capacity,
  title={The capacity for moral self-correction in large language models},
  author={Ganguli, Deep and Askell, Amanda and Schiefer, Nicholas and Liao, Thomas and Luko{\v{s}}i{\=u}t{\.e}, Kamil{\.e} and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and Olsson, Catherine and Hernandez, Danny and others},
  journal={arXiv preprint arXiv:2302.07459},
  year={2023}
}


@article{zhang2022surveyNT,
  title={A survey on negative transfer},
  author={Zhang, Wen and Deng, Lingfei and Zhang, Lei and Wu, Dongrui},
  journal={IEEE/CAA Journal of Automatica Sinica},
  volume={10},
  number={2},
  pages={305--329},
  year={2022},
  publisher={IEEE}
}
@article{cai2020note,
  title={A note on over-smoothing for graph neural networks},
  author={Cai, Chen and Wang, Yusu},
  journal={arXiv preprint arXiv:2006.13318},
  year={2020}
}
@inproceedings{yang2021graph,
  title={Graph neural networks inspired by classical iterative algorithms},
  author={Yang, Yongyi and Liu, Tang and Wang, Yangkun and Zhou, Jinjing and Gan, Quan and Wei, Zhewei and Zhang, Zheng and Huang, Zengfeng and Wipf, David},
  booktitle={International Conference on Machine Learning},
  pages={11773--11783},
  year={2021},
  organization={PMLR}
}
@inproceedings{alon2020bottleneck,
  title={On the Bottleneck of Graph Neural Networks and its Practical Implications},
  author={Alon, Uri and Yahav, Eran},
  booktitle={International Conference on Learning Representations},
  year={2020}
}
@article{wu2023demystifying,
  title={Demystifying Oversmoothing in Attention-Based Graph Neural Networks},
  author={Wu, Xinyi and Ajorlou, Amir and Wu, Zihui and Jadbabaie, Ali},
  journal={arXiv preprint arXiv:2305.16102},
  year={2023}
}
@inproceedings{oono2019graph,
  title={Graph Neural Networks Exponentially Lose Expressive Power for Node Classification},
  author={Oono, Kenta and Suzuki, Taiji},
  booktitle={International Conference on Learning Representations},
  year={2019}
}
@article{di2023does,
  title={How does over-squashing affect the power of GNNs?},
  author={Di Giovanni, Francesco and Rusch, T Konstantin and Bronstein, Michael M and Deac, Andreea and Lackenby, Marc and Mishra, Siddhartha and Veli{\v{c}}kovi{\'c}, Petar},
  journal={arXiv preprint arXiv:2306.03589},
  year={2023}
}
@inproceedings{topping2021understanding,
  title={Understanding over-squashing and bottlenecks on graphs via curvature},
  author={Topping, Jake and Di Giovanni, Francesco and Chamberlain, Benjamin Paul and Dong, Xiaowen and Bronstein, Michael M},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{chang2021comprehensiveSGSurvey,
  title={A comprehensive survey of scene graphs: Generation and application},
  author={Chang, Xiaojun and Ren, Pengzhen and Xu, Pengfei and Li, Zhihui and Chen, Xiaojiang and Hauptmann, Alex},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={45},
  number={1},
  pages={1--26},
  year={2021},
  publisher={IEEE}
}


@book{Menczer_Fortunato_Davis_2020, place={Cambridge}, title={A First Course in Network Science}, publisher={Cambridge University Press}, author={Menczer, Filippo and Fortunato, Santo and Davis, Clayton A.}, year={2020}} 


@ARTICLE{gnn_stability,
  author={Ruiz, Luana and Chamon, Luiz F. O. and Ribeiro, Alejandro},
  journal={IEEE Transactions on Signal Processing}, 
  title={Transferability Properties of Graph Neural Networks}, 
  year={2023},
  volume={71},
  number={},
  pages={3474-3489},
  keywords={Filtering theory;Convolution;Graph neural networks;Training;Behavioral sciences;Task analysis;Stochastic processes;Graph neural networks;transferability;graph signal processing;graphons},
  doi={10.1109/TSP.2023.3297848}}


@article{morris2021weisfeiler,
  title={Weisfeiler and leman go machine learning: The story so far},
  author={Morris, Christopher and Lipman, Yaron and Maron, Haggai and Rieck, Bastian and Kriege, Nils M and Grohe, Martin and Fey, Matthias and Borgwardt, Karsten},
  journal={arXiv preprint arXiv:2112.09992},
  year={2021}
}

@article{luan2021heterophily,
  title={Is heterophily a real nightmare for graph neural networks to do node classification?},
  author={Luan, Sitao and Hua, Chenqing and Lu, Qincheng and Zhu, Jiaqi and Zhao, Mingde and Zhang, Shuyuan and Chang, Xiao-Wen and Precup, Doina},
  journal={arXiv preprint arXiv:2109.05641},
  year={2021}
}


@inproceedings{jing2023deepGR,
  title={Deep Graph Reprogramming},
  author={Jing, Yongcheng and Yuan, Chongbin and Ju, Li and Yang, Yiding and Wang, Xinchao and Tao, Dacheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={24345--24354},
  year={2023}
}


@inproceedings{nr,
  title = {The Network Data Repository with Interactive Graph Analytics and Visualization},
  author={Ryan A. Rossi and Nesreen K. Ahmed},
  booktitle = {AAAI},
  url={http://networkrepository.com},
  year={2015}
}

@article{2019t5,
    author = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
    title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
    journal = {arXiv e-prints},
    year = {2019},
    archivePrefix = {arXiv},
    eprint = {1910.10683},
}


@article{muller2023attending,
  title={Attending to graph transformers},
  author={M{\"u}ller, Luis and Galkin, Mikhail and Morris, Christopher and Ramp{\'a}{\v{s}}ek, Ladislav},
  journal={arXiv preprint arXiv:2302.04181},
  year={2023}
}

@article{fey2019fast,
  title={Fast graph representation learning with PyTorch Geometric},
  author={Fey, Matthias and Lenssen, Jan Eric},
  journal={arXiv preprint arXiv:1903.02428},
  year={2019}
}


@inproceedings{ma2023GraphInductiveBiasesGRIT,
	title = {Graph {Inductive} {Biases} in {Transformers} without {Message} {Passing}},
	booktitle = {Proc. {Int}. {Conf}. {Mach}. {Learn}.},
	author = {Ma, Liheng and Lin, Chen and Lim, Derek and Romero-Soriano, Adriana and K. Dokania and Coates, Mark and H.S. Torr, Philip and Lim, Ser-Nam},
	year = {2023},
}


@article{kim2022pureTOKENGT,
  author    = {Jinwoo Kim and Tien Dat Nguyen and Seonwoo Min and Sungjun Cho and Moontae Lee and Honglak Lee and Seunghoon Hong},
  title     = {Pure Transformers are Powerful Graph Learners},
  journal   = {arXiv},
  volume    = {abs/2207.02505},
  year      = {2022},
  url       = {https://arxiv.org/abs/2207.02505}
}

@article{bai2023sequential,
  title={Sequential modeling enables scalable learning for large vision models},
  author={Bai, Yutong and Geng, Xinyang and Mangalam, Karttikeya and Bar, Amir and Yuille, Alan and Darrell, Trevor and Malik, Jitendra and Efros, Alexei A},
  journal={arXiv preprint arXiv:2312.00785},
  year={2023}
}


@inproceedings{sanner2023largeCOLDSTART,
  title={Large language models are competitive near cold-start recommenders for language-and item-based preferences},
  author={Sanner, Scott and Balog, Krisztian and Radlinski, Filip and Wedin, Ben and Dixon, Lucas},
  booktitle={Proceedings of the 17th ACM conference on recommender systems},
  pages={890--896},
  year={2023}
}


@inproceedings{Morris+2020,
    title={TUDataset: A collection of benchmark datasets for learning with graphs},
    author={Christopher Morris and Nils M. Kriege and Franka Bause and Kristian Kersting and Petra Mutzel and Marion Neumann},
    booktitle={ICML 2020 Workshop on Graph Representation Learning and Beyond (GRL+ 2020)},
    archivePrefix={arXiv},
    eprint={2007.08663},
    url={www.graphlearning.io},
    year={2020}
}

@misc{snapnets,
    author       = {Jure Leskovec and Andrej Krevl},
    title        = {{SNAP Datasets}: {Stanford} Large Network Dataset Collection},
    howpublished = {\url{http://snap.stanford.edu/data}},
    month        = jun,
    year         = 2014
  }



@inproceedings{aminer,
author = {Tang, Jie},
title = {AMiner: Toward Understanding Big Scholar Data},
year = {2016},
isbn = {9781450337168},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2835776.2835849},
doi = {10.1145/2835776.2835849},
abstract = {In this talk, I will present a novel academic search and mining system, AMiner, the second generation of the ArnetMiner system. Different from traditional academic search systems that focus on document (paper) search, AMiner aims to provide a systematic modeling approach for researchers (authors), ultimately to gain a deep understanding of the big (heterogeneous) network formed by authors, papers they have published, and venues they published those papers. The system extracts researchers' profiles automatically from the Web and integrates the researcher profiles with publication papers after name disambiguation. For now, the system has collected a big scholar data with more than 130,000,000 researcher profiles and 100,000,000 papers from multiple publication databases. We also developed an approach named COSNET to connect AMiner with several professional social networks such as LinkedIn and VideoLectures, which significantly enriches the metadata of the scholarly data. Based on the integrated big scholar data, we devise a unified topic modeling approach for modeling the different entities (authors, papers, venues) simultaneously and provide a topic-level expertise search by leveraging the modeling results. In addition, AMiner offers a set of researcher-centered functions including social influence analysis, influence visualization, collaboration recommendation, relationship mining, similarity analysis and community evolution. The system has been put into operation since 2006 and has attracted more than 7,000,000 independent IP accesses from over 200 countries/regions.},
booktitle = {Proceedings of the Ninth ACM International Conference on Web Search and Data Mining},
pages = {467},
numpages = {1},
keywords = {social influence, recommendation, integration, community evolution, academic search},
location = {San Francisco, California, USA},
series = {WSDM '16}
}


@ARTICLE{OAG,
  author={Zhang, Fanjin and Liu, Xiao and Tang, Jie and Dong, Yuxiao and Yao, Peiran and Zhang, Jie and Gu, Xiaotao and Wang, Yan and Kharlamov, Evgeny and Shao, Bin and Li, Rui and Wang, Kuansan},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={OAG: Linking Entities Across Large-Scale Heterogeneous Knowledge Graphs}, 
  year={2023},
  volume={35},
  number={9},
  pages={9225-9239},
  keywords={Task analysis;Convolutional neural networks;Computer science;Imaging;Analytical models;Solid modeling;Long short term memory;Entity linking;name ambiguity;heterogeneous networks;OAG;task relationships},
  doi={10.1109/TKDE.2022.3222168}}


@inproceedings{Dess2022CSKGAL,
  title={CS-KG: A Large-Scale Knowledge Graph of Research Entities and Claims in Computer Science},
  author={Danilo Dess{\'i} and Francesco Osborne and Diego Reforgiato Recupero and D. Buscaldi and Enrico Motta},
  booktitle={International Workshop on the Semantic Web},
  year={2022},
  url={https://api.semanticscholar.org/CorpusID:253021556}
}

@article{freitas2021malnet,
  title={MalNet: A Large-Scale Image Database of Malicious Software},
  author={Freitas, Scott and Duggal, Rahul and Chau, Duen Horng},
  journal={arXiv preprint arXiv:2102.01072},
  year={2021}
}

@article{zhang2023live,
  title={Live Graph Lab: Towards Open, Dynamic and Real Transaction Graphs with NFT},
  author={Zhang, Zhen and Luo, Bingqiao and Lu, Shengliang and He, Bingsheng},
  journal={arXiv preprint arXiv:2310.11709},
  year={2023}
}


@book{MoleculeNet,
    title={Deep Learning for the Life Sciences},
    author={Bharath Ramsundar and Peter Eastman and Patrick Walters and Vijay Pande and Karl Leswing and Zhenqin Wu},
    publisher={O'Reilly Media},
    note={\url{https://www.amazon.com/Deep-Learning-Life-Sciences-Microscopy/dp/1492039837}},
    year={2019}
}


@article{huang2023temporal,
  title={Temporal graph benchmark for machine learning on temporal graphs},
  author={Huang, Shenyang and Poursafaei, Farimah and Danovitch, Jacob and Fey, Matthias and Hu, Weihua and Rossi, Emanuele and Leskovec, Jure and Bronstein, Michael and Rabusseau, Guillaume and Rabbany, Reihaneh},
  journal={arXiv preprint arXiv:2307.01026},
  year={2023}
}


@article{zeng2019graphsaint,
  title={Graphsaint: Graph sampling based inductive learning method},
  author={Zeng, Hanqing and Zhou, Hongkuan and Srivastava, Ajitesh and Kannan, Rajgopal and Prasanna, Viktor},
  journal={arXiv preprint arXiv:1907.04931},
  year={2019}
}

@inproceedings{
    shaDow,
    title={Decoupling the Depth and Scope of Graph Neural Networks},
    author={Hanqing Zeng and Muhan Zhang and Yinglong Xia and Ajitesh Srivastava and Andrey Malevich and Rajgopal Kannan and Viktor Prasanna and Long Jin and Ren Chen},
    booktitle={Advances in Neural Information Processing Systems},
    editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
    year={2021},
    url={https://openreview.net/forum?id=d0MtHWY0NZ}
}

@inproceedings{fey2021gnnautoscale,
  title={Gnnautoscale: Scalable and expressive graph neural networks via historical embeddings},
  author={Fey, Matthias and Lenssen, Jan E and Weichert, Frank and Leskovec, Jure},
  booktitle={International conference on machine learning},
  pages={3294--3304},
  year={2021},
  organization={PMLR}
}


@article{cao2023learningSEGMENT,
  title={Learning Large Graph Property Prediction via Graph Segment Training},
  author={Cao, Kaidi and Phothilimthana, Phitchaya Mangpo and Abu-El-Haija, Sami and Zelle, Dustin and Zhou, Yanqi and Mendis, Charith and Leskovec, Jure and Perozzi, Bryan},
  journal={arXiv preprint arXiv:2305.12322},
  year={2023}
}

@article{zhou2021acceleratingPRUNING,
  title={Accelerating large scale real-time GNN inference using channel pruning},
  author={Zhou, Hongkuan and Srivastava, Ajitesh and Zeng, Hanqing and Kannan, Rajgopal and Prasanna, Viktor},
  journal={arXiv preprint arXiv:2105.04528},
  year={2021}
}

@article{tailor2020degreeQUANT,
  title={Degree-quant: Quantization-aware training for graph neural networks},
  author={Tailor, Shyam A and Fernandez-Marques, Javier and Lane, Nicholas D},
  journal={arXiv preprint arXiv:2008.05000},
  year={2020}
}

@article{zhang2021graphless,
  title={Graph-less neural networks: Teaching old mlps new tricks via distillation},
  author={Zhang, Shichang and Liu, Yozen and Sun, Yizhou and Shah, Neil},
  journal={arXiv preprint arXiv:2110.08727},
  year={2021}
}

@misc{recsys, title={Recommender systems and Personalization datasets}, url={https://cseweb.ucsd.edu/~jmcauley/datasets.html}, journal={Recommender Systems Datasets}, author={Project, UCSD CSE Research}} 


@inproceedings{
ramasesh2022effect,
title={Effect of scale on catastrophic forgetting in neural networks},
author={Vinay Venkatesh Ramasesh and Aitor Lewkowycz and Ethan Dyer},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=GhVS8_yPeEa}
}


@article{activitycliff,
author = {van Tilborg, Derek and Alenicheva, Alisa and Grisoni, Francesca},
year = {2022},
month = {08},
title = {Exposing the limitations of molecular machine learning with activity cliffs.},
doi = {10.26434/chemrxiv-2022-mfq52-v3}
}

@article{chen2023labelLLMGNN,
  title={Label-free node classification on graphs with large language models (llms)},
  author={Chen, Zhikai and Mao, Haitao and Wen, Hongzhi and Han, Haoyu and Jin, Wei and Zhang, Haiyang and Liu, Hui and Tang, Jiliang},
  journal={arXiv preprint arXiv:2310.04668},
  year={2023}
}

@article{zhao2023gimlet,
  title={GIMLET: A Unified Graph-Text Model for Instruction-Based Molecule Zero-Shot Learning},
  author={Zhao, Haiteng and Liu, Shengchao and Ma, Chang and Xu, Hannan and Fu, Jie and Deng, Zhi-Hong and Kong, Lingpeng and Liu, Qi},
  journal={bioRxiv},
  pages={2023--05},
  year={2023},
  publisher={Cold Spring Harbor Laboratory}
}

@article{gps_plusplus,
    title={GPS++: An Optimised Hybrid MPNN/Transformer for Molecular Property Prediction},
    author={Dominic Masters and Josef Dean and Kerstin Klaser and Zhiyi Li and Sam Maddrell-Mander and Adam Sanders and Hatem Helal and Deniz Beker and Ladislav Rampášek and Dominique Beaini},
    year={2022},
    journal={arXiv preprint arXiv:2212.02229},
}

@article{unimol,
    title={Highly Accurate Quantum Chemical Property Prediction with Uni-Mol+},
    author={Shuqi Lu and Zhifeng Gao and Di He and Linfeng Zhang and Guolin Ke},
    year={2023},
    journal={arXiv preprint arXiv:2303.16982},
    archivePrefix={arXiv},
    primaryClass={physics.chem-ph}
}

@article{zhang2023dpa2,
    title={DPA-2: Towards a universal large atomic model for molecular and material simulation},
    author={Duo Zhang and Xinzijian Liu and Xiangyu Zhang and Chengqian Zhang and Chun Cai and Hangrui Bi and Yiming Du and Xuejian Qin and Jiameng Huang and Bowen Li and Yifan Shan and Jinzhe Zeng and Yuzhi Zhang and Siyuan Liu and Yifan Li and Junhan Chang and Xinyan Wang and Shuo Zhou and Jianchuan Liu and Xiaoshan Luo and Zhenyu Wang and Wanrun Jiang and Jing Wu and Yudi Yang and Jiyuan Yang and Manyi Yang and Fu-Qiang Gong and Linshuang Zhang and Mengchao Shi and Fu-Zhi Dai and Darrin M. York and Shi Liu and Tong Zhu and Zhicheng Zhong and Jian Lv and Jun Cheng and Weile Jia and Mohan Chen and Guolin Ke and Weinan E and Linfeng Zhang and Han Wang},
    year={2023},
    journal={arXiv preprint arXiv:2312.15492},
    archivePrefix={arXiv},
    primaryClass={physics.chem-ph}
}

@misc{shoghi2023jmp,
    title={From Molecules to Materials: Pre-training Large Generalizable Models for Atomic Property Prediction},
    author={Nima Shoghi and Adeesh Kolluru and John R. Kitchin and Zachary W. Ulissi and C. Lawrence Zitnick and Brandon M. Wood},
    year={2023},
    eprint={arXiv preprint arXiv:2310.16802},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{batatia2023macemp,
      title={A foundation model for atomistic materials chemistry}, 
      author={Ilyes Batatia and Philipp Benner and Yuan Chiang and Alin M. Elena and Dávid P. Kovács and Janosh Riebesell and Xavier R. Advincula and Mark Asta and William J. Baldwin and Noam Bernstein and Arghya Bhowmik and Samuel M. Blau and Vlad Cărare and James P. Darby and Sandip De and Flaviano Della Pia and Volker L. Deringer and Rokas Elijošius and Zakariya El-Machachi and Edvin Fako and Andrea C. Ferrari and Annalena Genreith-Schriever and Janine George and Rhys E. A. Goodall and Clare P. Grey and Shuang Han and Will Handley and Hendrik H. Heenen and Kersti Hermansson and Christian Holm and Jad Jaafar and Stephan Hofmann and Konstantin S. Jakob and Hyunwook Jung and Venkat Kapil and Aaron D. Kaplan and Nima Karimitari and Namu Kroupa and Jolla Kullgren and Matthew C. Kuner and Domantas Kuryla and Guoda Liepuoniute and Johannes T. Margraf and Ioan-Bogdan Magdău and Angelos Michaelides and J. Harry Moore and Aakash A. Naik and Samuel P. Niblett and Sam Walton Norwood and Niamh O'Neill and Christoph Ortner and Kristin A. Persson and Karsten Reuter and Andrew S. Rosen and Lars L. Schaaf and Christoph Schran and Eric Sivonxay and Tamás K. Stenczel and Viktor Svahn and Christopher Sutton and Cas van der Oord and Eszter Varga-Umbrich and Tejs Vegge and Martin Vondrák and Yangshuai Wang and William C. Witt and Fabian Zills and Gábor Csányi},
      year={2023},
      journal={arXiv preprint arXiv:2401.00096},
      archivePrefix={arXiv},
      primaryClass={physics.chem-ph}
}


@article{behnamghader2024llm2vec,
  title={Llm2vec: Large language models are secretly powerful text encoders},
  author={BehnamGhader, Parishad and Adlakha, Vaibhav and Mosbach, Marius and Bahdanau, Dzmitry and Chapados, Nicolas and Reddy, Siva},
  journal={arXiv preprint arXiv:2404.05961},
  year={2024}
}

@article{gruver2024fine,
  title={Fine-Tuned Language Models Generate Stable Inorganic Materials as Text},
  author={Gruver, Nate and Sriram, Anuroop and Madotto, Andrea and Wilson, Andrew Gordon and Zitnick, C Lawrence and Ulissi, Zachary},
  journal={arXiv preprint arXiv:2402.04379},
  year={2024}
}

@article{van2017neural,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{he2024g,
  title={G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering},
  author={He, Xiaoxin and Tian, Yijun and Sun, Yifei and Chawla, Nitesh V and Laurent, Thomas and LeCun, Yann and Bresson, Xavier and Hooi, Bryan},
  journal={arXiv preprint arXiv:2402.07630},
  year={2024}
}
@article{zhang2023and,
  title={What and how does in-context learning learn? bayesian model averaging, parameterization, and generalization},
  author={Zhang, Yufeng and Zhang, Fengzhuo and Yang, Zhuoran and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2305.19420},
  year={2023}
}
@inproceedings{panwar2023context,
  title={In-Context Learning through the Bayesian Prism},
  author={Panwar, Madhur and Ahuja, Kabir and Goyal, Navin},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}
@article{gruver2024large,
  title={Large language models are zero-shot time series forecasters},
  author={Gruver, Nate and Finzi, Marc and Qiu, Shikai and Wilson, Andrew G},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{yang2023vqgraph,
  title={Vqgraph: Graph vector-quantization for bridging gnns and mlps},
  author={Yang, Ling and Tian, Ye and Xu, Minkai and Liu, Zhongyi and Hong, Shenda and Qu, Wei and Zhang, Wentao and Cui, Bin and Zhang, Muhan and Leskovec, Jure},
  journal={arXiv preprint arXiv:2308.02117},
  year={2023}
}



@inproceedings{you2019position,
  title={Position-aware graph neural networks},
  author={You, Jiaxuan and Ying, Rex and Leskovec, Jure},
  booktitle={International conference on machine learning},
  pages={7134--7143},
  year={2019},
  organization={PMLR}
}

@inproceedings{you2021identity,
  title={Identity-aware graph neural networks},
  author={You, Jiaxuan and Gomes-Selman, Jonathan M and Ying, Rex and Leskovec, Jure},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  number={12},
  pages={10737--10745},
  year={2021}
}


@article{zhao2024gimlet,
  title={Gimlet: A unified graph-text model for instruction-based molecule zero-shot learning},
  author={Zhao, Haiteng and Liu, Shengchao and Chang, Ma and Xu, Hannan and Fu, Jie and Deng, Zhihong and Kong, Lingpeng and Liu, Qi},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{Klicpera2018PredictTP,
  title={Predict then Propagate: Graph Neural Networks meet Personalized PageRank},
  author={Johannes Klicpera and Aleksandar Bojchevski and Stephan G{\"u}nnemann},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{velivckovic2017graph,
  title={Graph attention networks},
  author={Veli{\v{c}}kovi{\'c}, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Lio, Pietro and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1710.10903},
  year={2017}
}

@article{mao2024data,
  title={A Data Generation Perspective to the Mechanism of In-Context Learning},
  author={Mao, Haitao and Liu, Guangliang and Ma, Yao and Wang, Rongrong and Tang, Jiliang},
  journal={arXiv preprint arXiv:2402.02212},
  year={2024}
}

@inproceedings{velivckovic2022clrs,
  title={The clrs algorithmic reasoning benchmark},
  author={Veli{\v{c}}kovi{\'c}, Petar and Badia, Adri{\`a} Puigdom{\`e}nech and Budden, David and Pascanu, Razvan and Banino, Andrea and Dashevskiy, Misha and Hadsell, Raia and Blundell, Charles},
  booktitle={International Conference on Machine Learning},
  pages={22084--22102},
  year={2022},
  organization={PMLR}
}

@inproceedings{ibarz2022generalist,
  title={A generalist neural algorithmic learner},
  author={Ibarz, Borja and Kurin, Vitaly and Papamakarios, George and Nikiforou, Kyriacos and Bennani, Mehdi and Csord{\'a}s, R{\'o}bert and Dudzik, Andrew Joseph and Bo{\v{s}}njak, Matko and Vitvitskyi, Alex and Rubanova, Yulia and others},
  booktitle={Learning on graphs conference},
  pages={2--1},
  year={2022},
  organization={PMLR}
}

@article{zhai2024commonscenes,
  title={Commonscenes: Generating commonsense 3d indoor scenes with scene graphs},
  author={Zhai, Guangyao and {\"O}rnek, Evin P{\i}nar and Wu, Shun-Cheng and Di, Yan and Tombari, Federico and Navab, Nassir and Busam, Benjamin},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@article{prystawski2023think,
  title={Why think step-by-step? Reasoning emerges from the locality of experience},
  author={Prystawski, Ben and Goodman, Noah D},
  journal={arXiv preprint arXiv:2304.03843},
  year={2023}
}

@article{xu2020can,
  title={What Can Neural Networks Reason About?},
  author={Xu, Keylu and Li, Jingling and Zhang, Mozhi and Du, Simon S and Kawarabayashi, Ken-ichi and Jegelka, Stefanie},
  journal={ICLR 2020},
  year={2020}
}

@article{Edmonds1973MatchingET,
  title={Matching, Euler tours and the Chinese postman},
  author={Jack Edmonds and Ellis L. Johnson},
  journal={Mathematical Programming},
  year={1973},
  volume={5},
  pages={88-124},
  url={https://api.semanticscholar.org/CorpusID:15249924}
}

@article{galkin2024zero,
  title={Zero-shot Logical Query Reasoning on any Knowledge Graph},
  author={Galkin, Mikhail and Zhou, Jincheng and Ribeiro, Bruno and Tang, Jian and Zhu, Zhaocheng},
  journal={arXiv preprint arXiv:2404.07198},
  year={2024}
}

@article{wang2023generating,
  title={Generating molecular conformer fields},
  author={Wang, Yuyang and Elhag, Ahmed A and Jaitly, Navdeep and Susskind, Joshua M and Bautista, Miguel Angel},
  journal={arXiv preprint arXiv:2311.17932},
  year={2023}
}
@article{perozzi2024let,
  title={Let Your Graph Do the Talking: Encoding Structured Data for LLMs},
  author={Perozzi, Bryan and Fatemi, Bahare and Zelle, Dustin and Tsitsulin, Anton and Kazemi, Mehran and Al-Rfou, Rami and Halcrow, Jonathan},
  journal={arXiv preprint arXiv:2402.05862},
  year={2024}
}

@article{abramson2024accurate,
  title={Accurate structure prediction of biomolecular interactions with AlphaFold 3},
  author={Abramson, Josh and Adler, Jonas and Dunger, Jack and Evans, Richard and Green, Tim and Pritzel, Alexander and Ronneberger, Olaf and Willmore, Lindsay and Ballard, Andrew J and Bambrick, Joshua and others},
  journal={Nature},
  pages={1--3},
  year={2024},
  publisher={Nature Publishing Group UK London}
}
@inproceedings{
chien2021adaptiveGPRGNN,
title={Adaptive Universal Generalized PageRank Graph Neural Network},
author={Eli Chien and Jianhao Peng and Pan Li and Olgica Milenkovic},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=n6jl7fLxrP}
}

@article{chawla2005learningLP,
  title={Learning from labeled and unlabeled data: An empirical study across techniques and domains},
  author={Chawla, Nitesh V and Karakoulas, Grigoris},
  journal={Journal of Artificial Intelligence Research},
  volume={23},
  pages={331--366},
  year={2005}
}

@article{huang2015triadic,
  title={Triadic closure pattern analysis and prediction in social networks},
  author={Huang, Hong and Tang, Jie and Liu, Lu and Luo, JarDer and Fu, Xiaoming},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={27},
  number={12},
  pages={3374--3389},
  year={2015},
  publisher={IEEE}
}

@article{adamic2003friends,
  title={Friends and neighbors on the web},
  author={Adamic, Lada A and Adar, Eytan},
  journal={Social networks},
  volume={25},
  number={3},
  pages={211--230},
  year={2003},
  publisher={Elsevier}
}

@article{katz1953new,
  title={A new status index derived from sociometric analysis},
  author={Katz, Leo},
  journal={Psychometrika},
  volume={18},
  number={1},
  pages={39--43},
  year={1953},
  publisher={Springer}
}

@inproceedings{jeh2002simrank,
  title={Simrank: a measure of structural-context similarity},
  author={Jeh, Glen and Widom, Jennifer},
  booktitle={Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={538--543},
  year={2002}
}

@article{murase2019structural,
  title={Structural transition in social networks},
  author={Murase, Yohsuke and Jo, Hang Hyun and T{\"o}r{\"o}k, J{\'a}nos and Kert{\'e}sz, J{\'a}nos and Kaski, Kimmo and others},
  year={2019},
  publisher={NATURE PUBLISHING GROUP}
}

@article{ye2022generative,
  title={Generative knowledge graph construction: A review},
  author={Ye, Hongbin and Zhang, Ningyu and Chen, Hui and Chen, Huajun},
  journal={arXiv preprint arXiv:2210.12714},
  year={2022}
}


@article{vishwanathan2010graphkernel,
  title={Graph kernels},
  author={Vishwanathan, S Vichy N and Schraudolph, Nicol N and Kondor, Risi and Borgwardt, Karsten M},
  journal={Journal of Machine Learning Research},
  volume={11},
  pages={1201--1242},
  year={2010},
  publisher={MIT Press}
}


@inproceedings{zhong2021learningSCENEGRAPH,
  title={Learning to generate scene graph from natural language supervision},
  author={Zhong, Yiwu and Shi, Jing and Yang, Jianwei and Xu, Chenliang and Li, Yin},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1823--1834},
  year={2021}
}



@inproceedings{ye2024language,
  title={Language is all a graph needs},
  author={Ye, Ruosong and Zhang, Caiqi and Wang, Runhui and Xu, Shuyuan and Zhang, Yongfeng},
  booktitle={Findings of the Association for Computational Linguistics: EACL 2024},
  pages={1955--1973},
  year={2024}
}

@article{wang2024instructgraph,
  title={InstructGraph: Boosting Large Language Models via Graph-centric Instruction Tuning and Preference Alignment},
  author={Wang, Jianing and Wu, Junda and Hou, Yupeng and Liu, Yao and Gao, Ming and McAuley, Julian},
  journal={arXiv preprint arXiv:2402.08785},
  year={2024}
}

@article{li2024zerog,
  title={ZeroG: Investigating Cross-dataset Zero-shot Transferability in Graphs},
  author={Li, Yuhan and Wang, Peisong and Li, Zhixun and Yu, Jeffrey Xu and Li, Jia},
  journal={arXiv preprint arXiv:2402.11235},
  year={2024}
}

@article{chen2024graphwiz,
  title={GraphWiz: An Instruction-Following Language Model for Graph Problems},
  author={Chen, Nuo and Li, Yuhan and Tang, Jianheng and Li, Jia},
  journal={arXiv preprint arXiv:2402.16029},
  year={2024}
}

@article{luo2024graphinstruct,
  title={GraphInstruct: Empowering Large Language Models with Graph Understanding and Reasoning Capability},
  author={Luo, Zihan and Song, Xiran and Huang, Hong and Lian, Jianxun and Zhang, Chenhao and Jiang, Jinqi and Xie, Xing and Jin, Hai},
  journal={arXiv preprint arXiv:2403.04483},
  year={2024}
}
@article{wang2024microstructures,
  title={Microstructures and Accuracy of Graph Recall by Large Language Models},
  author={Wang, Yanbang and Cui, Hejie and Kleinberg, Jon},
  journal={arXiv preprint arXiv:2402.11821},
  year={2024}
}
@article{ribeiro2021survey,
  title={A survey on subgraph counting: concepts, algorithms, and applications to network motifs and graphlets},
  author={Ribeiro, Pedro and Paredes, Pedro and Silva, Miguel EP and Aparicio, David and Silva, Fernando},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={2},
  pages={1--36},
  year={2021},
  publisher={ACM New York, NY, USA}
}
@article{hovcevar2014combinatorial,
  title={A combinatorial approach to graphlet counting},
  author={Ho{\v{c}}evar, Toma{\v{z}} and Dem{\v{s}}ar, Janez},
  journal={Bioinformatics},
  volume={30},
  number={4},
  pages={559--565},
  year={2014},
  publisher={Oxford University Press}
}
@inproceedings{stechly2023gpt,
  title={GPT-4 Doesn’t Know It’s Wrong: An Analysis of Iterative Prompting for Reasoning Problems},
  author={Stechly, Kaya and Marquez, Matthew and Kambhampati, Subbarao},
  booktitle={NeurIPS 2023 Foundation Models for Decision Making Workshop},
  year={2023}
}
@article{yao2024exploring,
  title={Exploring the Potential of Large Language Models in Graph Generation},
  author={Yao, Yang and Wang, Xin and Zhang, Zeyang and Qin, Yijian and Zhang, Ziwei and Chu, Xu and Yang, Yuekui and Zhu, Wenwu and Mei, Hong},
  journal={arXiv preprint arXiv:2403.14358},
  year={2024}
}