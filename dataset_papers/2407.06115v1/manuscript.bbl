\begin{thebibliography}{10}

\bibitem{akhtar2019multi}
Md~Shad Akhtar, Dushyant~Singh Chauhan, Deepanway Ghosal, Soujanya Poria, Asif Ekbal, and Pushpak Bhattacharyya.
\newblock Multi-task learning for multi-modal emotion recognition and sentiment analysis.
\newblock {\em arXiv preprint arXiv:1905.05812}, 2019.

\bibitem{Alhujaili2021SentimentAF}
Rawan~Fahad Alhujaili and Wael M.~S. Yafooz.
\newblock Sentiment analysis for youtube videos with user comments: Review.
\newblock {\em 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS)}, pages 814--820, 2021.

\bibitem{alqahtani2022predicting}
Ghadah Alqahtani and Abdulrahman Alothaim.
\newblock Predicting emotions in online social networks: challenges and opportunities.
\newblock {\em Multimedia Tools and Applications}, 81(7):9567--9605, 2022.

\bibitem{8489099}
Pablo Barros, Nikhil Churamani, Egor Lakomkin, Henrique Siqueira, Alexander Sutherland, and Stefan Wermter.
\newblock The omg-emotion behavior dataset.
\newblock In {\em 2018 International Joint Conference on Neural Networks (IJCNN)}, pages 1--7, 2018.

\bibitem{10.1145/3479574}
Kristen Barta and Nazanin Andalibi.
\newblock Constructing authenticity on tiktok: Social norms and social support on the "fun" platform.
\newblock {\em Proc. ACM Hum.-Comput. Interact.}, 5(CSCW2), oct 2021.

\bibitem{baveye2013large}
Yoann Baveye, Jean-No{\"e}l Bettinelli, Emmanuel Dellandr{\'e}a, Liming Chen, and Christel Chamaret.
\newblock A large video database for computational models of induced emotion.
\newblock In {\em 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction}, pages 13--18. IEEE, 2013.

\bibitem{benini2011connotative}
Sergio Benini, Luca Canini, and Riccardo Leonardi.
\newblock A connotative space for supporting movie affective recommendation.
\newblock {\em IEEE Transactions on Multimedia}, 13(6):1356--1370, 2011.

\bibitem{busso2008iemocap}
Carlos Busso, Murtaza Bulut, Chi-Chun Lee, Abe Kazemzadeh, Emily Mower, Samuel Kim, Jeannette~N Chang, Sungbok Lee, and Shrikanth~S Narayanan.
\newblock Iemocap: Interactive emotional dyadic motion capture database.
\newblock {\em Language resources and evaluation}, 42:335--359, 2008.

\bibitem{carreira2017quo}
Joao Carreira and Andrew Zisserman.
\newblock Quo vadis, action recognition? a new model and the kinetics dataset.
\newblock In {\em proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pages 6299--6308, 2017.

\bibitem{oro32459}
Smitashree Choudhury and John~G. Breslin.
\newblock User sentiment detection: a youtube use case.
\newblock In {\em The 21st National Conference on Artificial Intelligence and Cognitive Science}, August 2010.

\bibitem{delbrouck2020transformer}
Jean-Benoit Delbrouck, No{\'e} Tits, Mathilde Brousmiche, and St{\'e}phane Dupont.
\newblock A transformer-based joint-encoding for emotion recognition and sentiment analysis.
\newblock {\em arXiv preprint arXiv:2006.15955}, 2020.

\bibitem{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language understanding.
\newblock {\em arXiv preprint arXiv:1810.04805}, 2018.

\bibitem{GANDHI2023424}
Ankita Gandhi, Kinjal Adhvaryu, Soujanya Poria, Erik Cambria, and Amir Hussain.
\newblock Multimodal sentiment analysis: A systematic review of history, datasets, multimodal fusion methods, applications, challenges and future directions.
\newblock {\em Information Fusion}, 91:424--444, 2023.

\bibitem{aup:/content/journals/10.5117/CCR2022.2.004.GUIN}
Benjamin Guinaudeau, Kevin Munger, and Fabio Votta.
\newblock Fifteen seconds of fame: Tiktok and the supply side of social video.
\newblock {\em Computational Communication Research}, 4(2):463--485, 2022.

\bibitem{han2021improving}
Wei Han, Hui Chen, and Soujanya Poria.
\newblock Improving multimodal fusion with hierarchical mutual information maximization for multimodal sentiment analysis, 2021.

\bibitem{hazarika2020misa}
Devamanyu Hazarika, Roger Zimmermann, and Soujanya Poria.
\newblock Misa: Modality-invariant and-specific representations for multimodal sentiment analysis.
\newblock In {\em Proceedings of the 28th ACM International Conference on Multimedia}, pages 1122--1131, 2020.

\bibitem{kallinen2006emotion}
Kari Kallinen and Niklas Ravaja.
\newblock Emotion perceived and emotion felt: Same and different.
\newblock {\em Musicae Scientiae}, 10(2):191--213, 2006.

\bibitem{5871728}
Sander Koelstra, Christian Muhl, Mohammad Soleymani, Jong-Seok Lee, Ashkan Yazdani, Touradj Ebrahimi, Thierry Pun, Anton Nijholt, and Ioannis Patras.
\newblock Deap: A database for emotion analysis ;using physiological signals.
\newblock {\em IEEE Transactions on Affective Computing}, 3(1):18--31, 2012.

\bibitem{liu2022make}
Yihe Liu, Ziqi Yuan, Huisheng Mao, Zhiyun Liang, Wanqiuyue Yang, Yuanzhe Qiu, Tie Cheng, Xiaoteng Li, Hua Xu, and Kai Gao.
\newblock Make acoustic and visual cues matter: Ch-sims v2.0 dataset and av-mixup consistent module, 2022.

\bibitem{liu2019roberta}
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.
\newblock Roberta: A robustly optimized bert pretraining approach.
\newblock {\em arXiv preprint arXiv:1907.11692}, 2019.

\bibitem{liu2017real}
Yong-Jin Liu, Minjing Yu, Guozhen Zhao, Jinjing Song, Yan Ge, and Yuanchun Shi.
\newblock Real-time movie-induced discrete emotion recognition from eeg signals.
\newblock {\em IEEE Transactions on Affective Computing}, 9(4):550--562, 2017.

\bibitem{LOVETT2021126}
Jessica~T. Lovett, Kamran Munawar, Sharon Mohammed, and Vinay Prabhu.
\newblock Radiology content on tiktok: Current use of a novel video-based social media platform and opportunities for radiology.
\newblock {\em Current Problems in Diagnostic Radiology}, 50(2):126--131, 2021.

\bibitem{10.1145/3394231.3397916}
Juan~Carlos Medina~Serrano, Orestis Papakyriakopoulos, and Simon Hegelich.
\newblock Dancing to the partisan beat: A first analysis of political communication on tiktok.
\newblock In {\em Proceedings of the 12th ACM Conference on Web Science}, WebSci '20, page 257–266, New York, NY, USA, 2020. Association for Computing Machinery.

\bibitem{Muhammad2019SentimentAO}
Abbi~Nizar Muhammad, Saiful Bukhori, and Priza Pandunata.
\newblock Sentiment analysis of positive and negative of youtube comments using na{\"i}ve bayes – support vector machine (nbsvm) classifier.
\newblock {\em 2019 International Conference on Computer Science, Information Technology, and Electrical Engineering (ICOMITEE)}, pages 199--205, 2019.

\bibitem{muszynski2019recognizing}
Michal Muszynski, Leimin Tian, Catherine Lai, Johanna~D Moore, Theodoros Kostoulas, Patrizia Lombardo, Thierry Pun, and Guillaume Chanel.
\newblock Recognizing induced emotions of movie audiences from multimodal information.
\newblock {\em IEEE Transactions on Affective Computing}, 12(1):36--52, 2019.

\bibitem{NEURIPS2019_9015}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith Chintala.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In {\em Advances in Neural Information Processing Systems 32}, pages 8024--8035. Curran Associates, Inc., 2019.

\bibitem{peng2015mixed}
Kuan-Chuan Peng, Tsuhan Chen, Amir Sadovnik, and Andrew~C Gallagher.
\newblock A mixed bag of emotions: Model, predict, and transfer emotion distributions.
\newblock In {\em Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 860--868, 2015.

\bibitem{PrezRosas2013UtteranceLevelMS}
Ver{\'o}nica P{\'e}rez-Rosas, Rada Mihalcea, and Louis-Philippe Morency.
\newblock Utterance-level multimodal sentiment analysis.
\newblock In {\em Annual Meeting of the Association for Computational Linguistics}, 2013.

\bibitem{PLUTCHIK19803}
ROBERT PLUTCHIK.
\newblock Chapter 1 - a general psychoevolutionary theory of emotion.
\newblock In Robert Plutchik and Henry Kellerman, editors, {\em Theories of Emotion}, pages 3--33. Academic Press, 1980.

\bibitem{Pokharel2021ClassifyingYC}
Rhitabrat Pokharel and Dixit Bhatta.
\newblock Classifying youtube comments based on sentiment and type of sentence.
\newblock {\em ArXiv}, abs/2111.01908, 2021.

\bibitem{poria-etal-2019-meld}
Soujanya Poria, Devamanyu Hazarika, Navonil Majumder, Gautam Naik, Erik Cambria, and Rada Mihalcea.
\newblock {MELD}: A multimodal multi-party dataset for emotion recognition in conversations.
\newblock In {\em Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics}, pages 527--536, Florence, Italy, July 2019. Association for Computational Linguistics.

\bibitem{qiyang2019learning}
Zea Qiyang and Heekyoung Jung.
\newblock Learning and sharing creative skills with short videos: A case study of user behavior in tiktok and bilibili.
\newblock 2019.

\bibitem{5975141}
Mohammad Soleymani, Jeroen Lichtenauer, Thierry Pun, and Maja Pantic.
\newblock A multimodal database for affect recognition and implicit tagging.
\newblock {\em IEEE Transactions on Affective Computing}, 3(1):42--55, 2012.

\bibitem{SOUTHWICK2021234}
Lauren Southwick, Sharath~C. Guntuku, Elissa~V. Klinger, Emily Seltzer, Haley~J. McCalpin, and Raina~M. Merchant.
\newblock Characterizing covid-19 content posted to tiktok: Public sentiment and response during the first phase of the covid-19 pandemic.
\newblock {\em Journal of Adolescent Health}, 69(2):234--241, 2021.

\bibitem{sukhwal2022determining}
Prakash~Chandra Sukhwal and Atreyi Kankanhalli.
\newblock Determining containment policy impacts on public sentiment during the pandemic using social media data.
\newblock {\em Proceedings of the National Academy of Sciences}, 119(19):e2117292119, 2022.

\bibitem{10.1145/3503161.3548025}
Hao Sun, Hongyi Wang, Jiaqing Liu, Yen-Wei Chen, and Lanfen Lin.
\newblock Cubemlp: An mlp-based model for multimodal sentiment analysis and depression estimation.
\newblock In {\em Proceedings of the 30th ACM International Conference on Multimedia}, MM '22, page 3722–3729, New York, NY, USA, 2022. Association for Computing Machinery.

\bibitem{teixeira2012emotion}
Thales Teixeira, Michel Wedel, and Rik Pieters.
\newblock Emotion-induced engagement in internet video advertisements.
\newblock {\em Journal of marketing research}, 49(2):144--159, 2012.

\bibitem{tian2017recognizing}
Leimin Tian, Michal Muszynski, Catherine Lai, Johanna~D Moore, Theodoros Kostoulas, Patrizia Lombardo, Thierry Pun, and Guillaume Chanel.
\newblock Recognizing induced emotions of movie audiences: Are induced and perceived emotions the same?
\newblock In {\em 2017 Seventh International Conference on Affective Computing and Intelligent Interaction (ACII)}, pages 28--35. IEEE, 2017.

\bibitem{Uryupina2014SenTubeAC}
Olga Uryupina, Barbara Plank, Aliaksei Severyn, Agata Rotondi, and Alessandro Moschitti.
\newblock Sentube: A corpus for sentiment analysis on youtube social media.
\newblock In {\em International Conference on Language Resources and Evaluation}, 2014.

\bibitem{doi:10.1080/1057610X.2020.1780027}
Gabriel Weimann and Natalie Masri.
\newblock Research note: Spreading hate on tiktok.
\newblock {\em Studies in Conflict \& Terrorism}, 46(5):752--765, 2023.

\bibitem{Xu2021TikTokAP}
Alex~J. Xu, Jacob Taylor, Tian Gao, Rada Mihalcea, Ver{\'o}nica P{\'e}rez-Rosas, and Stacy Loeb.
\newblock Tiktok and prostate cancer: misinformation and quality of information using validated questionnaires.
\newblock {\em BJU International}, 128, 2021.

\bibitem{YASMINA2016292}
Douiji yasmina, Mousannif Hajar, and Al~Moatassime Hassan.
\newblock Using youtube comments for text-based emotion recognition.
\newblock {\em Procedia Computer Science}, 83:292--299, 2016.
\newblock The 7th International Conference on Ambient Systems, Networks and Technologies (ANT 2016) / The 6th International Conference on Sustainable Energy Information Technology (SEIT-2016) / Affiliated Workshops.

\bibitem{yu-etal-2020-ch}
Wenmeng Yu, Hua Xu, Fanyang Meng, Yilin Zhu, Yixiao Ma, Jiele Wu, Jiyun Zou, and Kaicheng Yang.
\newblock {CH}-{SIMS}: A {C}hinese multimodal sentiment analysis dataset with fine-grained annotation of modality.
\newblock In {\em Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics}, pages 3718--3727, Online, July 2020. Association for Computational Linguistics.

\bibitem{yu2021learning}
Wenmeng Yu, Hua Xu, Ziqi Yuan, and Jiele Wu.
\newblock Learning modality-specific representations with self-supervised multi-task learning for multimodal sentiment analysis, 2021.

\bibitem{zadeh2018multimodal}
AmirAli~Bagher Zadeh, Paul~Pu Liang, Soujanya Poria, Erik Cambria, and Louis-Philippe Morency.
\newblock Multimodal language analysis in the wild: Cmu-mosei dataset and interpretable dynamic fusion graph.
\newblock In {\em Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 2236--2246, 2018.

\bibitem{Zlatintsi2017COGNIMUSEAM}
Athanasia Zlatintsi, Petros Koutras, Georgios Evangelopoulos, Nikos Malandrakis, Niki Efthymiou, Katerina Pastra, Alexandros Potamianos, and Petros Maragos.
\newblock Cognimuse: a multimodal video database annotated with saliency, events, semantics and emotion with application to summarization.
\newblock {\em EURASIP Journal on Image and Video Processing}, 2017:1--24, 2017.

\end{thebibliography}
