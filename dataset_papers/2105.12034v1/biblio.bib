@inproceedings{piot2013learning,
  title={Learning from demonstrations: Is it worth estimating a reward function?},
  author={Piot, Bilal and Geist, Matthieu and Pietquin, Olivier},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={17--32},
  year={2013},
  organization={Springer}
}

@inproceedings{kim2013learning,
  title={Learning from limited demonstrations},
  author={Kim, Beomjoon and Farahmand, Amir-massoud and Pineau, Joelle and Precup, Doina},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2859--2867},
  year={2013}
}
@inproceedings{piot2014boosted,
  title={Boosted bellman residual minimization handling expert demonstrations},
  author={Piot, Bilal and Geist, Matthieu and Pietquin, Olivier},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={549--564},
  year={2014},
  organization={Springer}
}

@article{SCHAAL1999233,
title = "Is imitation learning the route to humanoid robots?",
journal = "Trends in Cognitive Sciences",
volume = "3",
number = "6",
pages = "233 - 242",
year = "1999",
issn = "1364-6613",
doi = "https://doi.org/10.1016/S1364-6613(99)01327-3",
url = "http://www.sciencedirect.com/science/article/pii/S1364661399013273",
author = "Stefan Schaal",
keywords = "Motor control, Learning, Imitation, Humanoid robot, Action-perception coupling, Mirror neurons",
abstract = "This review investigates two recent developments in artificial intelligence and neural computation: learning from imitation and the development of humanoid robots. It is postulated that the study of imitation learning offers a promising route to gain new insights into mechanisms of perceptual motor control that could ultimately lead to the creation of autonomous humanoid robots. Imitation learning focuses on three important issues: efficient motor learning, the connection between action and perception, and modular motor control in the form of movement primitives. It is reviewed here how research on representations of, and functional connections between, action and perception have contributed to our understanding of motor acts of other beings. The recent discovery that some areas in the primate brain are active during both movement perception and execution has provided a hypothetical neural basis of imitation. Computational approaches to imitation learning are also described, initially from the perspective of traditional AI and robotics, but also from the perspective of neural network models and statistical-learning research. Parallels and differences between biological and computational approaches to imitation are highlighted and an overview of current projects that actually employ imitation learning for humanoid robots is given."
}

@article{fu2020d4rl,
  title={D4rl: Datasets for deep data-driven reinforcement learning},
  author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.07219},
  year={2020}
}
@inproceedings{wang2019random,
  title={Random expert distillation: Imitation learning via expert policy support estimation},
  author={Wang, Ruohan and Ciliberto, Carlo and Amadori, Pierluigi Vito and Demiris, Yiannis},
  booktitle={International Conference on Machine Learning},
  pages={6536--6544},
  year={2019},
  organization={PMLR}
}
@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}
@article{haarnoja2018soft2,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}
@article{dadashi2020primal,
  title={Primal wasserstein imitation learning},
  author={Dadashi, Robert and Hussenot, L{\'e}onard and Geist, Matthieu and Pietquin, Olivier},
  journal={arXiv preprint arXiv:2006.04678},
  year={2020}
}

@article{kostrikov2018discriminator,
  title={Discriminator-actor-critic: Addressing sample inefficiency and reward bias in adversarial imitation learning},
  author={Kostrikov, Ilya and Agrawal, Kumar Krishna and Dwibedi, Debidatta and Levine, Sergey and Tompson, Jonathan},
  journal={arXiv preprint arXiv:1809.02925},
  year={2018}
}

@article{ho2016generative,
  title={Generative adversarial imitation learning},
  author={Ho, Jonathan and Ermon, Stefano},
  journal={arXiv preprint arXiv:1606.03476},
  year={2016}
}

@article{pomerleau1991efficient,
  title={Efficient training of artificial neural networks for autonomous navigation},
  author={Pomerleau, Dean A},
  journal={Neural computation},
  volume={3},
  number={1},
  pages={88--97},
  year={1991},
  publisher={MIT Press}
}

@phdthesis{Kumar2016thesis,
    title    = {Manipulators and Manipulation in high dimensional spaces},
    school   = {University of Washington, Seattle},
    author   = {Kumar, Vikash},
    year     = {2016},
    url      = {https://digital.lib.washington.edu/researchworks/handle/1773/38104}
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@article{burda2018exploration,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}
@article{andrychowicz2020matters,
  title={What matters in on-policy reinforcement learning? a large-scale empirical study},
  author={Andrychowicz, Marcin and Raichuk, Anton and Sta{\'n}czyk, Piotr and Orsini, Manu and Girgin, Sertan and Marinier, Raphael and Hussenot, L{\'e}onard and Geist, Matthieu and Pietquin, Olivier and Michalski, Marcin and others},
  journal={arXiv preprint arXiv:2006.05990},
  year={2020}
}

@article{paine2020hyperparameter,
  title={Hyperparameter selection for offline reinforcement learning},
  author={Paine, Tom Le and Paduraru, Cosmin and Michi, Andrea and Gulcehre, Caglar and Zolna, Konrad and Novikov, Alexander and Wang, Ziyu and de Freitas, Nando},
  journal={arXiv preprint arXiv:2007.09055},
  year={2020}
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}


@article{bergstra2012random,
  title={Random search for hyper-parameter optimization.},
  author={Bergstra, James and Bengio, Yoshua},
  journal={Journal of machine learning research},
  volume={13},
  number={2},
  year={2012}
}

@inproceedings{larochelle2007empirical,
  title={An empirical evaluation of deep architectures on problems with many factors of variation},
  author={Larochelle, Hugo and Erhan, Dumitru and Courville, Aaron and Bergstra, James and Bengio, Yoshua},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={473--480},
  year={2007}
}

@incollection{lecun2012efficient,
  title={Efficient backprop},
  author={LeCun, Yann A and Bottou, L{\'e}on and Orr, Genevieve B and M{\"u}ller, Klaus-Robert},
  booktitle={Neural networks: Tricks of the trade},
  pages={9--48},
  year={2012},
  publisher={Springer}
}

@article{jaderberg2017population,
  title={Population based training of neural networks},
  author={Jaderberg, Max and Dalibard, Valentin and Osindero, Simon and Czarnecki, Wojciech M and Donahue, Jeff and Razavi, Ali and Vinyals, Oriol and Green, Tim and Dunning, Iain and Simonyan, Karen and others},
  journal={arXiv preprint arXiv:1711.09846},
  year={2017}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{tesauro1995temporal,
  title={Temporal difference learning and TD-Gammon},
  author={Tesauro, Gerald},
  journal={Communications of the ACM},
  volume={38},
  number={3},
  pages={58--68},
  year={1995}
}

@article{vinyals2017starcraft,
  title={Starcraft ii: A new challenge for reinforcement learning},
  author={Vinyals, Oriol and Ewalds, Timo and Bartunov, Sergey and Georgiev, Petko and Vezhnevets, Alexander Sasha and Yeo, Michelle and Makhzani, Alireza and K{\"u}ttler, Heinrich and Agapiou, John and Schrittwieser, Julian and others},
  journal={arXiv preprint arXiv:1708.04782},
  year={2017}
}

@article{bellemare2013arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}


@inproceedings{cobbe2020leveraging,
  title={Leveraging procedural generation to benchmark reinforcement learning},
  author={Cobbe, Karl and Hesse, Chris and Hilton, Jacob and Schulman, John},
  booktitle={International conference on machine learning},
  pages={2048--2056},
  year={2020},
  organization={PMLR}
}

@inproceedings{henderson2018deep,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}

@article{engstrom2020implementation,
  title={Implementation matters in deep policy gradients: A case study on PPO and TRPO},
  author={Engstrom, Logan and Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Janoos, Firdaus and Rudolph, Larry and Madry, Aleksander},
  journal={arXiv preprint arXiv:2005.12729},
  year={2020}
}



@inproceedings{finn2016guided,
  title={Guided cost learning: Deep inverse optimal control via policy optimization},
  author={Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={49--58},
  year={2016},
  organization={PMLR}
}

@article{ke2019imitation,
  title={Imitation Learning as $ f $-Divergence Minimization},
  author={Ke, Liyiming and Barnes, Matt and Sun, Wen and Lee, Gilwoo and Choudhury, Sanjiban and Srinivasa, Siddhartha},
  journal={arXiv preprint arXiv:1905.12888},
  year={2019}
}

@inproceedings{ghasemipour2020divergence,
  title={A divergence minimization perspective on imitation learning methods},
  author={Ghasemipour, Seyed Kamyar Seyed and Zemel, Richard and Gu, Shixiang},
  booktitle={Conference on Robot Learning},
  pages={1259--1277},
  year={2020},
  organization={PMLR}
}

@article{ernst2005tree,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  pages={503--556},
  year={2005},
  publisher={Microtome Publishing}
}

@inproceedings{riedmiller2005neural,
  title={Neural fitted Q iteration--first experiences with a data efficient neural reinforcement learning method},
  author={Riedmiller, Martin},
  booktitle={European Conference on Machine Learning},
  pages={317--328},
  year={2005},
  organization={Springer}
}

@article{lagoudakis2003least,
  title={Least-squares policy iteration},
  author={Lagoudakis, Michail G and Parr, Ronald},
  journal={The Journal of Machine Learning Research},
  volume={4},
  pages={1107--1149},
  year={2003},
  publisher={JMLR. org}
}

@incollection{lange2012batch,
  title={Batch reinforcement learning},
  author={Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
  booktitle={Reinforcement learning},
  pages={45--73},
  year={2012},
  publisher={Springer}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{gulcehre2020rl,
  title={Rl unplugged: Benchmarks for offline reinforcement learning},
  author={Gulcehre, Caglar and Wang, Ziyu and Novikov, Alexander and Paine, Tom Le and Colmenarejo, Sergio G{\'o}mez and Zolna, Konrad and Agarwal, Rishabh and Merel, Josh and Mankowitz, Daniel and Paduraru, Cosmin and others},
  journal={arXiv preprint arXiv:2006.13888},
  year={2020}
}
@inproceedings{ziebart2008maximum,
  title={Maximum entropy inverse reinforcement learning.},
  author={Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K},
  booktitle={Aaai},
  volume={8},
  pages={1433--1438},
  year={2008},
  organization={Chicago, IL, USA}
}
@inproceedings{hester2018deep,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  number={1},
  year={2018}
}
@article{atc,
  title={Decoupling representation learning from reinforcement learning},
  author={Stooke, Adam and Lee, Kimin and Abbeel, Pieter and Laskin, Michael},
  journal={arXiv preprint arXiv:2009.08319},
  year={2020}
}
@inproceedings{tcn,
  title={Time-contrastive networks: Self-supervised learning from video},
  author={Sermanet, Pierre and Lynch, Corey and Chebotar, Yevgen and Hsu, Jasmine and Jang, Eric and Schaal, Stefan and Levine, Sergey and Brain, Google},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1134--1141},
  year={2018},
  organization={IEEE}
}
@article{pi-sac,
  title={Predictive information accelerates learning in rl},
  author={Lee, Kuang-Huei and Fischer, Ian and Liu, Anthony and Guo, Yijie and Lee, Honglak and Canny, John and Guadarrama, Sergio},
  journal={arXiv preprint arXiv:2007.12401},
  year={2020}
}
@article{mazoure2020deep,
  title={Deep reinforcement and infomax learning},
  author={Mazoure, Bogdan and Combes, Remi Tachet des and Doan, Thang and Bachman, Philip and Hjelm, R Devon},
  journal={arXiv preprint arXiv:2006.07217},
  year={2020}
}
@incollection{goodhart1984problems,
  title={Problems of monetary management: the UK experience},
  author={Goodhart, Charles AE},
  booktitle={Monetary theory and practice},
  pages={91--121},
  year={1984},
  publisher={Springer}
}
@inproceedings{atkeson1997robot,
  title={Robot learning from demonstration},
  author={Atkeson, Christopher G and Schaal, Stefan},
  booktitle={ICML},
  volume={97},
  pages={12--20},
  year={1997},
  organization={Citeseer}
}
@article{argall2009survey,
  title={A survey of robot learning from demonstration},
  author={Argall, Brenna D and Chernova, Sonia and Veloso, Manuela and Browning, Brett},
  journal={Robotics and autonomous systems},
  volume={57},
  number={5},
  pages={469--483},
  year={2009},
  publisher={Elsevier}
}
@article{dota,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and Debiak, Przemysaw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}
@article{starcraft,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group}
}
@article{popov2017data,
  title={Data-efficient deep reinforcement learning for dexterous manipulation},
  author={Popov, Ivaylo and Heess, Nicolas and Lillicrap, Timothy and Hafner, Roland and Barth-Maron, Gabriel and Vecerik, Matej and Lampe, Thomas and Tassa, Yuval and Erez, Tom and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1704.03073},
  year={2017}
}

@inproceedings{ng2000algorithms,
  title={Algorithms for inverse reinforcement learning.},
  author={Ng, Andrew Y and Russell, Stuart J and others},
  booktitle={Icml},
  volume={1},
  pages={2},
  year={2000}
}
@article{dropout,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {56},
  pages   = {1929-1958},
  url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}
@article{adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}
@article{zolna2020offline,
  title={Offline Learning from Demonstrations and Unlabeled Experience},
  author={Zolna, Konrad and Novikov, Alexander and Konyushkova, Ksenia and Gulcehre, Caglar and Wang, Ziyu and Aytar, Yusuf and Denil, Misha and de Freitas, Nando and Reed, Scott},
  journal={arXiv preprint arXiv:2011.13885},
  year={2020}
}

@inproceedings{russell1998learning,
  title={Learning agents for uncertain environments},
  author={Russell, Stuart},
  booktitle={Conference on Computational learning theory},
  year={1998}
}

@book{villani2008optimal,
  title={Optimal transport: old and new},
  author={Villani, C{\'e}dric},
  year={2008},
}
@misc{flamary2017pot,
title={POT Python Optimal Transport library},
author={Flamary, R{'e}mi and Courty, Nicolas},
url={https://pythonot.github.io/},
year={2017}
}

@article{feldt1998generating,
  title={Generating diverse software versions with genetic programming: an experimental study},
  author={Feldt, Robert},
  journal={IEE Proceedings-Software},
  volume={145},
  number={6},
  pages={228--236},
  year={1998},
  publisher={IET}
}

@inproceedings{sims1994evolving,
  title={Evolving virtual creatures},
  author={Sims, Karl},
  booktitle={Proceedings of the 21st annual conference on Computer graphics and interactive techniques},
  pages={15--22},
  year={1994}
}

@article{ecoffet2021first,
  title={First return, then explore},
  author={Ecoffet, Adrien and Huizinga, Joost and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff},
  journal={Nature},
  volume={590},
  number={7847},
  pages={580--586},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{acme,
  title={Acme: A research framework for distributed reinforcement learning},
  author={Hoffman, Matt and Shahriari, Bobak and Aslanides, John and Barth-Maron, Gabriel and Behbahani, Feryal and Norman, Tamara and Abdolmaleki, Abbas and Cassirer, Albin and Yang, Fan and Baumli, Kate and others},
  journal={arXiv preprint arXiv:2006.00979},
  year={2020}
}

@software{jax,
  author = {James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Skye Wanderman-{M}ilne and Qiao Zhang},
  title = {{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url = {http://github.com/google/jax},
  version = {0.2.5},
  year = {2018},
}

@software{flax,
  author = {Jonathan Heek and Anselm Levskaya and Avital Oliver and Marvin Ritter and Bertrand Rondepierre and Andreas Steiner and Marc van {Z}ee},
  title = {{F}lax: A neural network library and ecosystem for {JAX}},
  url = {http://github.com/google/flax},
  version = {0.3.3},
  year = {2020},
}