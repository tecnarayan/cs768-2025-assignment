\begin{thebibliography}{74}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2018)Agarwal, Beygelzimer, Dud{\'{\i}}k, Langford, and
  Wallach]{DBLP:conf/icml/AgarwalBD0W18}
A.~Agarwal, A.~Beygelzimer, M.~Dud{\'{\i}}k, J.~Langford, and H.~M. Wallach.
\newblock A reductions approach to fair classification.
\newblock In \emph{ICML}, pages 60--69, 2018.

\bibitem[Ak{\c{c}}ay et~al.(2007)Ak{\c{c}}ay, Li, and Xu]{akccay2007greedy}
Y.~Ak{\c{c}}ay, H.~Li, and S.~H. Xu.
\newblock Greedy algorithm for the general multidimensional knapsack problem.
\newblock \emph{Annals of Operations Research}, 150\penalty0 (1):\penalty0
  17--29, 2007.

\bibitem[Angwin et~al.(2016)Angwin, Larson, Mattu, and Kirchner]{Compas}
J.~Angwin, J.~Larson, S.~Mattu, and L.~Kirchner.
\newblock Machine bias: {T}here's software used across the country to predict
  future criminals. {A}nd its biased against blacks.
\newblock ProPublica, 2016.

\bibitem[Arazo et~al.(2019)Arazo, Ortego, Albert, O’Connor, and
  McGuinness]{arazo2019unsupervised}
E.~Arazo, D.~Ortego, P.~Albert, N.~O’Connor, and K.~McGuinness.
\newblock Unsupervised label noise modeling and loss correction.
\newblock In \emph{ICML}, pages 312--321, 2019.

\bibitem[Awasthi et~al.(2020)Awasthi, Kleindessner, and
  Morgenstern]{pmlr-v108-awasthi20a}
P.~Awasthi, M.~Kleindessner, and J.~Morgenstern.
\newblock Equalized odds postprocessing under imperfect group information.
\newblock In \emph{AISTATS}, pages 1770--1780, 2020.

\bibitem[Bekker and Goldberger(2016)]{bekker2016training}
A.~J. Bekker and J.~Goldberger.
\newblock Training deep neural-networks based on unreliable labels.
\newblock In \emph{IEEE ICASSP}, pages 2682--2686, 2016.

\bibitem[Bellamy et~al.(2019)Bellamy, Dey, Hind, Hoffman, Houde, Kannan, Lohia,
  Martino, Mehta, Mojsilovic, Nagar, Ramamurthy, Richards, Saha, Sattigeri,
  Singh, Varshney, and Zhang]{aif360-oct-2018}
R.~K.~E. Bellamy, K.~Dey, M.~Hind, S.~C. Hoffman, S.~Houde, K.~Kannan,
  P.~Lohia, J.~Martino, S.~Mehta, A.~Mojsilovic, S.~Nagar, K.~N. Ramamurthy,
  J.~T. Richards, D.~Saha, P.~Sattigeri, M.~Singh, K.~R. Varshney, and
  Y.~Zhang.
\newblock {AI} fairness 360: An extensible toolkit for detecting and mitigating
  algorithmic bias.
\newblock \emph{{IBM} J. Res. Dev.}, 63\penalty0 (4/5):\penalty0 4:1--4:15,
  2019.

\bibitem[Caprara et~al.(2000)Caprara, Kellerer, Pferschy, and
  Pisinger]{caprara2000approximation}
A.~Caprara, H.~Kellerer, U.~Pferschy, and D.~Pisinger.
\newblock Approximation algorithms for knapsack problems with cardinality
  constraints.
\newblock \emph{EJOR}, 123\penalty0 (2):\penalty0 333--345, 2000.

\bibitem[Celis et~al.(2021)Celis, Huang, Keswani, and Vishnoi]{Celis2021FairCW}
L.~E. Celis, L.~Huang, V.~Keswani, and N.~K. Vishnoi.
\newblock Fair classification with noisy protected attributes: A framework with
  provable guarantees.
\newblock In \emph{ICML}, 2021.

\bibitem[Chang et~al.(2020)Chang, Nguyen, Murakonda, Kazemi, and
  Shokri]{chang2020adversarial}
H.~Chang, T.~D. Nguyen, S.~K. Murakonda, E.~Kazemi, and R.~Shokri.
\newblock On adversarial bias and the robustness of fair machine learning.
\newblock \emph{ArXiv}, 2020.

\bibitem[Chang et~al.(2017)Chang, Learned-Miller, and
  McCallum]{NIPS2017_2f37d101}
H.-S. Chang, E.~Learned-Miller, and A.~McCallum.
\newblock Active bias: Training more accurate neural networks by emphasizing
  high variance samples.
\newblock In \emph{NeurIPS}, 2017.

\bibitem[Chen et~al.(2019)Chen, Liao, Chen, and Zhang]{chen2019understanding}
P.~Chen, B.~B. Liao, G.~Chen, and S.~Zhang.
\newblock Understanding and utilizing deep neural networks trained with noisy
  labels.
\newblock In \emph{ICML}, pages 1062--1070, 2019.

\bibitem[Chen and Gupta(2015)]{chen2015webly}
X.~Chen and A.~Gupta.
\newblock Webly supervised learning of convolutional networks.
\newblock In \emph{ICCV}, pages 1431--1439, 2015.

\bibitem[Choi et~al.(2020)Choi, Grover, Singh, Shu, and Ermon]{choi2020fair}
K.~Choi, A.~Grover, T.~Singh, R.~Shu, and S.~Ermon.
\newblock Fair generative modeling via weak supervision.
\newblock In \emph{ICML}, 2020.

\bibitem[Chzhen et~al.(2019)Chzhen, Denis, Hebiri, Oneto, and
  Pontil]{NIPS2019_9437}
E.~Chzhen, C.~Denis, M.~Hebiri, L.~Oneto, and M.~Pontil.
\newblock Leveraging labeled and unlabeled data for consistent fair binary
  classification.
\newblock In \emph{NeurIPS}, pages 12760--12770. 2019.

\bibitem[Cotter et~al.(2019)Cotter, Jiang, and
  Sridharan]{DBLP:conf/alt/CotterJS19}
A.~Cotter, H.~Jiang, and K.~Sridharan.
\newblock Two-player games for efficient non-convex constrained optimization.
\newblock In \emph{ALT}, pages 300--332, 2019.

\bibitem[Du and Wu(2021)]{du2021robust}
W.~Du and X.~Wu.
\newblock Robust fairness-aware learning under sample selection bias.
\newblock \emph{arXiv preprint arXiv:2105.11570}, 2021.

\bibitem[du~Pin~Calmon et~al.(2017)du~Pin~Calmon, Wei, Vinzamuri, Ramamurthy,
  and Varshney]{DBLP:conf/nips/CalmonWVRV17}
F.~du~Pin~Calmon, D.~Wei, B.~Vinzamuri, K.~N. Ramamurthy, and K.~R. Varshney.
\newblock Optimized pre-processing for discrimination prevention.
\newblock In \emph{NeurIPS}, pages 3995--4004, 2017.

\bibitem[Dwork et~al.(2012)Dwork, Hardt, Pitassi, Reingold, and
  Zemel]{DBLP:conf/innovations/DworkHPRZ12}
C.~Dwork, M.~Hardt, T.~Pitassi, O.~Reingold, and R.~S. Zemel.
\newblock Fairness through awareness.
\newblock In \emph{ITCS}, pages 214--226, 2012.

\bibitem[Feldman et~al.(2015)Feldman, Friedler, Moeller, Scheidegger, and
  Venkatasubramanian]{DBLP:conf/kdd/FeldmanFMSV15}
M.~Feldman, S.~A. Friedler, J.~Moeller, C.~Scheidegger, and
  S.~Venkatasubramanian.
\newblock Certifying and removing disparate impact.
\newblock In \emph{SIGKDD}, pages 259--268, 2015.

\bibitem[Garey and Johnson(1979)]{garey1979computers}
M.~R. Garey and D.~S. Johnson.
\newblock \emph{Computers and Intractability: A Guide to the Theory of
  NP-completeness}.
\newblock Mathematical Sciences Series. W. H. Freeman, 1979.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and Szegedy]{43405}
I.~Goodfellow, J.~Shlens, and C.~Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{ICLR}, 2015.

\bibitem[Google(2020)]{google}
Google.
\newblock Responsible ai practices.
\newblock \url{https://ai.google/responsibilities/responsible-ai-practices},
  2020.

\bibitem[Han et~al.(2018{\natexlab{a}})Han, Yao, Gang, Zhou, Tsang, Zhang, and
  Sugiyama]{han2018masking}
B.~Han, J.~Yao, N.~Gang, M.~Zhou, I.~Tsang, Y.~Zhang, and M.~Sugiyama.
\newblock Masking: A new perspective of noisy supervision.
\newblock In \emph{NeurIPS}, pages 5839--5849, 2018{\natexlab{a}}.

\bibitem[Han et~al.(2018{\natexlab{b}})Han, Yao, Yu, Niu, Xu, Hu, Tsang, and
  Sugiyama]{NEURIPS2018_a19744e2}
B.~Han, Q.~Yao, X.~Yu, G.~Niu, M.~Xu, W.~Hu, I.~Tsang, and M.~Sugiyama.
\newblock Co-teaching: Robust training of deep neural networks with extremely
  noisy labels.
\newblock In \emph{NeurIPS}, pages 8535--8545, 2018{\natexlab{b}}.

\bibitem[Hardt et~al.(2016)Hardt, Price, and Srebro]{DBLP:conf/nips/HardtPNS16}
M.~Hardt, E.~Price, and N.~Srebro.
\newblock Equality of opportunity in supervised learning.
\newblock In \emph{NeurIPS}, pages 3315--3323, 2016.

\bibitem[Hashimoto et~al.(2018)Hashimoto, Srivastava, Namkoong, and
  Liang]{pmlr-v80-hashimoto18a}
T.~Hashimoto, M.~Srivastava, H.~Namkoong, and P.~Liang.
\newblock Fairness without demographics in repeated loss minimization.
\newblock In \emph{ICML}, pages 1929--1938, 2018.

\bibitem[Hendrycks et~al.(2019)Hendrycks, Lee, and Mazeika]{hendrycks2019using}
D.~Hendrycks, K.~Lee, and M.~Mazeika.
\newblock Using pre-training can improve model robustness and uncertainty.
\newblock In \emph{ICML}, pages 2712--2721, 2019.

\bibitem[IBM(2020)]{ibm}
IBM.
\newblock Trusting ai.
\newblock
  \url{https://www.research.ibm.com/artificial-intelligence/trusted-ai/}, 2020.

\bibitem[Jiang and Nachum(2020)]{pmlr-v108-jiang20a}
H.~Jiang and O.~Nachum.
\newblock Identifying and correcting label bias in machine learning.
\newblock In \emph{AISTATS}, pages 702--712, 2020.

\bibitem[Jiang et~al.(2018)Jiang, Zhou, Leung, Li, and
  Fei-Fei]{jiang2018mentornet}
L.~Jiang, Z.~Zhou, T.~Leung, L.-J. Li, and L.~Fei-Fei.
\newblock Mentornet: Learning data-driven curriculum for very deep neural
  networks on corrupted labels.
\newblock In \emph{ICML}, pages 2304--2313, 2018.

\bibitem[Jindal et~al.(2016)Jindal, Nokleby, and Chen]{jindal2016learning}
I.~Jindal, M.~Nokleby, and X.~Chen.
\newblock Learning deep networks from noisy labels with dropout regularization.
\newblock In \emph{IEEE ICDM}, pages 967--972, 2016.

\bibitem[Kamiran and Calders(2011)]{DBLP:journals/kais/KamiranC11}
F.~Kamiran and T.~Calders.
\newblock Data preprocessing techniques for classification without
  discrimination.
\newblock \emph{Knowl. Inf. Syst.}, 33\penalty0 (1):\penalty0 1--33, 2011.

\bibitem[Kamiran et~al.(2012)Kamiran, Karim, and
  Zhang]{DBLP:conf/icdm/KamiranKZ12}
F.~Kamiran, A.~Karim, and X.~Zhang.
\newblock Decision theory for discrimination-aware classification.
\newblock In \emph{IEEE ICDM}, pages 924--929, 2012.

\bibitem[Kamishima et~al.(2012)Kamishima, Akaho, Asoh, and
  Sakuma]{DBLP:conf/pkdd/KamishimaAAS12}
T.~Kamishima, S.~Akaho, H.~Asoh, and J.~Sakuma.
\newblock Fairness-aware classifier with prejudice remover regularizer.
\newblock In \emph{ECML PKDD}, pages 35--50, 2012.

\bibitem[Kellerer et~al.(2004)Kellerer, Pferschy, and
  Pisinger]{kellerer2004knapsack}
H.~Kellerer, U.~Pferschy, and D.~Pisinger.
\newblock \emph{Knapsack Problems}.
\newblock Springer Nature Book Archives Millennium. 2004.

\bibitem[Khademi et~al.(2019)Khademi, Lee, Foley, and
  Honavar]{10.1145/3308558.3313559}
A.~Khademi, S.~Lee, D.~Foley, and V.~Honavar.
\newblock Fairness in algorithmic decision making: An excursion through the
  lens of causality.
\newblock In \emph{WWW}, pages 2907--2914, 2019.

\bibitem[Khani and Liang(2021)]{khani2021removing}
F.~Khani and P.~Liang.
\newblock Removing spurious features can hurt accuracy and affect groups
  disproportionately.
\newblock In \emph{ACM FAccT}, pages 196--205, 2021.

\bibitem[Kilbertus et~al.(2017)Kilbertus, Rojas-Carulla, Parascandolo, Hardt,
  Janzing, and Sch\"{o}lkopf]{10.5555/3294771.3294834}
N.~Kilbertus, M.~Rojas-Carulla, G.~Parascandolo, M.~Hardt, D.~Janzing, and
  B.~Sch\"{o}lkopf.
\newblock Avoiding discrimination through causal reasoning.
\newblock In \emph{NeurIPS}, pages 656--666, 2017.

\bibitem[Kohavi(1996)]{DBLP:conf/kdd/Kohavi96}
R.~Kohavi.
\newblock Scaling up the accuracy of naive-bayes classifiers: {A} decision-tree
  hybrid.
\newblock In \emph{SIGKDD}, pages 202--207, 1996.

\bibitem[Konstantinov and Lampert(2021)]{Konstantinov2021FairnessAwareLF}
N.~Konstantinov and C.~H. Lampert.
\newblock Fairness-aware learning from corrupted data.
\newblock \emph{ArXiv}, 2021.

\bibitem[Kusner et~al.(2017)Kusner, Loftus, Russell, and Silva]{NIPS2017_6995}
M.~J. Kusner, J.~Loftus, C.~Russell, and R.~Silva.
\newblock Counterfactual fairness.
\newblock In \emph{NeurIPS}, pages 4066--4076. 2017.

\bibitem[Lahoti et~al.(2020)Lahoti, Beutel, Chen, Lee, Prost, Thain, Wang, and
  Chi]{NEURIPS2020_07fc15c9}
P.~Lahoti, A.~Beutel, J.~Chen, K.~Lee, F.~Prost, N.~Thain, X.~Wang, and E.~Chi.
\newblock Fairness without demographics through adversarially reweighted
  learning.
\newblock In \emph{NeurIPS}, pages 728--740, 2020.

\bibitem[Lamy et~al.(2019)Lamy, Zhong, Menon, and Verma]{NEURIPS2019_8d5e957f}
A.~Lamy, Z.~Zhong, A.~K. Menon, and N.~Verma.
\newblock Noise-tolerant fair classification.
\newblock In \emph{NeurIPS}, 2019.

\bibitem[Lee et~al.(2021)Lee, Roh, Song, and Whang]{kdd2021tutorial}
J.-G. Lee, Y.~Roh, H.~Song, and S.~E. Whang.
\newblock Machine learning robustness, fairness, and their convergence.
\newblock In \emph{SIGKDD}, 2021.

\bibitem[Liu and Tao(2015)]{liu2015classification}
T.~Liu and D.~Tao.
\newblock Classification with noisy labels by importance reweighting.
\newblock \emph{IEEE TPAMI}, 38\penalty0 (3):\penalty0 447--461, 2015.

\bibitem[Ma et~al.(2018)Ma, Wang, Houle, Zhou, Erfani, Xia, Wijewickrema, and
  Bailey]{ma2018dimensionality}
X.~Ma, Y.~Wang, M.~E. Houle, S.~Zhou, S.~Erfani, S.~Xia, S.~Wijewickrema, and
  J.~Bailey.
\newblock Dimensionality-driven learning with noisy labels.
\newblock In \emph{ICML}, pages 3355--3364, 2018.

\bibitem[Mandal et~al.(2020)Mandal, Deng, Jana, Wing, and
  Hsu]{NEURIPS2020_d6539d3b}
D.~Mandal, S.~Deng, S.~Jana, J.~Wing, and D.~J. Hsu.
\newblock Ensuring fairness beyond the training data.
\newblock In \emph{NeurIPS}, pages 18445--18456, 2020.

\bibitem[Menon et~al.(2020)Menon, Rawat, Reddi, and Kumar]{Menon2020Can}
A.~K. Menon, A.~S. Rawat, S.~J. Reddi, and S.~Kumar.
\newblock Can gradient clipping mitigate label noise?
\newblock In \emph{ICLR}, 2020.

\bibitem[Microsoft(2021)]{microsoft}
Microsoft.
\newblock Responsible ai principles from microsoft.
\newblock \url{https://www.microsoft.com/en-us/ai/responsible-ai}, 2021.

\bibitem[Nabi and Shpitser(2018)]{Nabi2018FairIO}
R.~Nabi and I.~Shpitser.
\newblock Fair inference on outcomes.
\newblock In \emph{AAAI}, pages 1931--1940, 2018.

\bibitem[Narayanan(2018)]{narayanan2018translation}
A.~Narayanan.
\newblock Translation tutorial: 21 fairness definitions and their politics.
\newblock In \emph{ACM FAccT}, volume 1170, 2018.

\bibitem[Patrini et~al.(2017)Patrini, Rozza, Krishna~Menon, Nock, and
  Qu]{patrini2017making}
G.~Patrini, A.~Rozza, A.~Krishna~Menon, R.~Nock, and L.~Qu.
\newblock Making deep neural networks robust to label noise: A loss correction
  approach.
\newblock In \emph{CVPR}, pages 1944--1952, 2017.

\bibitem[Paudice et~al.(2018)Paudice, Mu{\~{n}}oz{-}Gonz{\'{a}}lez, and
  Lupu]{DBLP:conf/pkdd/PaudiceML18}
A.~Paudice, L.~Mu{\~{n}}oz{-}Gonz{\'{a}}lez, and E.~C. Lupu.
\newblock Label sanitization against label flipping poisoning attacks.
\newblock In \emph{ECML PKDD}, pages 5--15, 2018.

\bibitem[Pereyra et~al.(2017)Pereyra, Tucker, Chorowski, Kaiser, and
  Hinton]{pereyra2017regularizing}
G.~Pereyra, G.~Tucker, J.~Chorowski, {\L}.~Kaiser, and G.~Hinton.
\newblock Regularizing neural networks by penalizing confident output
  distributions.
\newblock 2017.

\bibitem[Pleiss et~al.(2017)Pleiss, Raghavan, Wu, Kleinberg, and
  Weinberger]{DBLP:conf/nips/PleissRWKW17}
G.~Pleiss, M.~Raghavan, F.~Wu, J.~M. Kleinberg, and K.~Q. Weinberger.
\newblock On fairness and calibration.
\newblock In \emph{NeurIPS}, pages 5684--5693, 2017.

\bibitem[Ren et~al.(2018)Ren, Zeng, Yang, and Urtasun]{DBLP:conf/icml/RenZYU18}
M.~Ren, W.~Zeng, B.~Yang, and R.~Urtasun.
\newblock Learning to reweight examples for robust deep learning.
\newblock In \emph{ICML}, pages 4331--4340, 2018.

\bibitem[Rezaei et~al.(2021)Rezaei, Liu, Memarrast, and
  Ziebart]{Rezaei_Liu_Memarrast_Ziebart_2021}
A.~Rezaei, A.~Liu, O.~Memarrast, and B.~D. Ziebart.
\newblock Robust fairness under covariate shift.
\newblock \emph{AAAI}, pages 9419--9427, 2021.

\bibitem[Roh et~al.(2020)Roh, Lee, Whang, and Suh]{pmlr-v119-roh20a}
Y.~Roh, K.~Lee, S.~E. Whang, and C.~Suh.
\newblock {FR}-{T}rain: A mutual information-based approach to fair and robust
  training.
\newblock In \emph{ICML}, pages 8147--8157, 2020.

\bibitem[Roh et~al.(2021)Roh, Lee, Whang, and Suh]{roh2021fairbatch}
Y.~Roh, K.~Lee, S.~E. Whang, and C.~Suh.
\newblock {F}air{B}atch: Batch selection for model fairness.
\newblock In \emph{ICLR}, 2021.

\bibitem[Rousseeuw(1984)]{doi:10.1080/01621459.1984.10477105}
P.~J. Rousseeuw.
\newblock Least median of squares regression.
\newblock \emph{Journal of the American Statistical Association}, 79\penalty0
  (388):\penalty0 871--880, 1984.

\bibitem[Shen and Sanghavi(2019)]{pmlr-v97-shen19e}
Y.~Shen and S.~Sanghavi.
\newblock Learning with bad training data via iterative trimmed loss
  minimization.
\newblock In \emph{ICML}, pages 5739--5748, 2019.

\bibitem[Solans et~al.(2020)Solans, Biggio, and
  Castillo]{DBLP:conf/pkdd/SolansB020}
D.~Solans, B.~Biggio, and C.~Castillo.
\newblock Poisoning attacks on algorithmic fairness.
\newblock In \emph{{ECML} {PKDD}}, pages 162--177, 2020.

\bibitem[Song et~al.(2019)Song, Kim, and Lee]{song2019selfie}
H.~Song, M.~Kim, and J.-G. Lee.
\newblock Selfie: Refurbishing unclean samples for robust deep learning.
\newblock In \emph{ICML}, pages 5907--5915, 2019.

\bibitem[Song et~al.(2020)Song, Kim, Park, and Lee]{song2020learning}
H.~Song, M.~Kim, D.~Park, and J.-G. Lee.
\newblock Learning from noisy labels with deep neural networks: A survey.
\newblock \emph{ArXiv}, 2020.

\bibitem[Tanno et~al.(2019)Tanno, Saeedi, Sankaranarayanan, Alexander, and
  Silberman]{tanno2019learning}
R.~Tanno, A.~Saeedi, S.~Sankaranarayanan, D.~C. Alexander, and N.~Silberman.
\newblock Learning from noisy labels by regularized estimation of annotator
  confusion.
\newblock In \emph{CVPR}, pages 11244--11253, 2019.

\bibitem[Wang et~al.(2020)Wang, Guo, Narasimhan, Cotter, Gupta, and
  Jordan]{NEURIPS2020_37d097ca}
S.~Wang, W.~Guo, H.~Narasimhan, A.~Cotter, M.~Gupta, and M.~Jordan.
\newblock Robust optimization for fairness with noisy protected groups.
\newblock In \emph{NeurIPS}, pages 5190--5203, 2020.

\bibitem[Xiao et~al.(2015)Xiao, Xia, Yang, Huang, and Wang]{xiao2015learning}
T.~Xiao, T.~Xia, Y.~Yang, C.~Huang, and X.~Wang.
\newblock Learning from massive noisy labeled data for image classification.
\newblock In \emph{CVPR}, pages 2691--2699, 2015.

\bibitem[Yu et~al.(2018)Yu, Liu, Gong, Batmanghelich, and Tao]{yu2018efficient}
X.~Yu, T.~Liu, M.~Gong, K.~Batmanghelich, and D.~Tao.
\newblock An efficient and provable approach for mixture proportion estimation
  using linear independence assumption.
\newblock In \emph{CVPR}, pages 4480--4489, 2018.

\bibitem[Zafar et~al.(2017{\natexlab{a}})Zafar, Valera, Gomez{-}Rodriguez, and
  Gummadi]{DBLP:conf/aistats/ZafarVGG17}
M.~B. Zafar, I.~Valera, M.~Gomez{-}Rodriguez, and K.~P. Gummadi.
\newblock Fairness constraints: {M}echanisms for fair classification.
\newblock In \emph{AISTATS}, pages 962--970, 2017{\natexlab{a}}.

\bibitem[Zafar et~al.(2017{\natexlab{b}})Zafar, Valera, Gomez{-}Rodriguez, and
  Gummadi]{DBLP:conf/www/ZafarVGG17}
M.~B. Zafar, I.~Valera, M.~Gomez{-}Rodriguez, and K.~P. Gummadi.
\newblock Fairness beyond disparate treatment {\&} disparate impact: {L}earning
  classification without disparate mistreatment.
\newblock In \emph{WWW}, pages 1171--1180, 2017{\natexlab{b}}.

\bibitem[Zemel et~al.(2013)Zemel, Wu, Swersky, Pitassi, and
  Dwork]{DBLP:conf/icml/ZemelWSPD13}
R.~S. Zemel, Y.~Wu, K.~Swersky, T.~Pitassi, and C.~Dwork.
\newblock Learning fair representations.
\newblock In \emph{ICML}, pages 325--333, 2013.

\bibitem[Zhang et~al.(2018)Zhang, Lemoine, and
  Mitchell]{DBLP:conf/aies/ZhangLM18}
B.~H. Zhang, B.~Lemoine, and M.~Mitchell.
\newblock Mitigating unwanted biases with adversarial learning.
\newblock In \emph{AIES}, pages 335--340, 2018.

\bibitem[Zhang and Bareinboim(2018)]{Zhang2018FairnessID}
J.~Zhang and E.~Bareinboim.
\newblock Fairness in decision-making - the causal explanation formula.
\newblock In \emph{AAAI}, pages 2037--2045, 2018.

\end{thebibliography}
