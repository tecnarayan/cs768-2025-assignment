\begin{thebibliography}{38}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Adcock and Dexter(2021)]{adcock2021gap}
Ben Adcock and Nick Dexter.
\newblock The gap between theory and practice in function approximation with
  deep neural networks.
\newblock \emph{SIAM Journal on Mathematics of Data Science}, 3\penalty0
  (2):\penalty0 624--655, 2021.

\bibitem[Bao et~al.(2021)Bao, Zhou, Zottola, Brubach, Desmarais, Horowitz, Lum,
  and Venkatasubramanian]{bao2021s}
Michelle Bao, Angela Zhou, Samantha~A Zottola, Brian Brubach, Sarah Desmarais,
  Aaron~Seth Horowitz, Kristian Lum, and Suresh Venkatasubramanian.
\newblock It's {COMPASlicated}: The messy relationship between {RAI} datasets
  and algorithmic fairness benchmarks.
\newblock In \emph{Thirty-fifth Conference on Neural Information Processing
  Systems Datasets and Benchmarks Track (Round 1)}, 2021.

\bibitem[Baron and Kenny(1986)]{baron1986moderator}
Reuben~M Baron and David~A Kenny.
\newblock The moderator--mediator variable distinction in social psychological
  research: Conceptual, strategic, and statistical considerations.
\newblock \emph{Journal of Personality and Social Psychology}, 51\penalty0
  (6):\penalty0 1173, 1986.

\bibitem[Bartlett et~al.(2020)Bartlett, Long, Lugosi, and
  Tsigler]{bartlett2020benign}
Peter~L Bartlett, Philip~M Long, G{\'a}bor Lugosi, and Alexander Tsigler.
\newblock Benign overfitting in linear regression.
\newblock \emph{Proceedings of the National Academy of Sciences}, 117\penalty0
  (48):\penalty0 30063--30070, 2020.

\bibitem[Brown et~al.(2022)Brown, Mansour, Wang, Chuchuca, Minchenberg,
  Chandnani, Liu, Gross, Sengupta, and Berzin]{brown2022deep}
Jeremy R~Glissen Brown, Nabil~M Mansour, Pu~Wang, Maria~Aguilera Chuchuca,
  Scott~B Minchenberg, Madhuri Chandnani, Lin Liu, Seth~A Gross, Neil Sengupta,
  and Tyler~M Berzin.
\newblock Deep learning computer-aided polyp detection reduces adenoma miss
  rate: a {United States} multi-center randomized tandem colonoscopy study
  ({CADeT-CS Trial}).
\newblock \emph{Clinical Gastroenterology and Hepatology}, 20\penalty0
  (7):\penalty0 1499--1507, 2022.

\bibitem[Chen et~al.(2022)Chen, Klivans, and Meka]{chen2022learning}
Sitan Chen, Adam~R Klivans, and Raghu Meka.
\newblock Learning deep {ReLU} networks is fixed-parameter tractable.
\newblock In \emph{2021 IEEE 62nd Annual Symposium on Foundations of Computer
  Science (FOCS)}, pages 696--707. IEEE, 2022.

\bibitem[Chen et~al.(2020)Chen, Liu, Ma, and Zhang]{chen2020causal}
Xiaohong Chen, Ying Liu, Shujie Ma, and Zheng Zhang.
\newblock Casual inference of general treatment effects using neural networks
  with a diverging number of confounders.
\newblock \emph{arXiv preprint arXiv:2009.07055}, 2020.

\bibitem[Chernozhukov et~al.(2020)Chernozhukov, Newey, Singh, and
  Syrgkanis]{chernozhukov2020adversarial}
Victor Chernozhukov, Whitney Newey, Rahul Singh, and Vasilis Syrgkanis.
\newblock Adversarial estimation of {Riesz} representers.
\newblock \emph{arXiv preprint arXiv:2101.00009}, 2020.

\bibitem[Cui and {Tchetgen Tchetgen}(2019)]{cui2019selective}
Yifan Cui and Eric {Tchetgen Tchetgen}.
\newblock Selective machine learning of doubly robust functionals.
\newblock \emph{arXiv preprint arXiv:1911.02029}, 2019.

\bibitem[Dressel and Farid(2018)]{dressel2018accuracy}
Julia Dressel and Hany Farid.
\newblock The accuracy, fairness, and limits of predicting recidivism.
\newblock \emph{Science Advances}, 4\penalty0 (1):\penalty0 eaao5580, 2018.

\bibitem[Farbmacher et~al.(2022)Farbmacher, Huber, Laff{\'e}rs, Langen, and
  Spindler]{farbmacher2022causal}
Helmut Farbmacher, Martin Huber, Luk{\'a}{\v{s}} Laff{\'e}rs, Henrika Langen,
  and Martin Spindler.
\newblock Causal mediation analysis with double machine learning.
\newblock \emph{The Econometrics Journal}, 25\penalty0 (2):\penalty0 277--300,
  2022.

\bibitem[Farrell et~al.(2021)Farrell, Liang, and Misra]{farrell2021deep}
Max~H Farrell, Tengyuan Liang, and Sanjog Misra.
\newblock Deep neural networks for estimation and inference.
\newblock \emph{Econometrica}, 89\penalty0 (1):\penalty0 181--213, 2021.

\bibitem[Gottschling et~al.(2020)Gottschling, Antun, Adcock, and
  Hansen]{gottschling2020troublesome}
Nina~M Gottschling, Vegard Antun, Ben Adcock, and Anders~C Hansen.
\newblock The troublesome kernel: why deep learning for inverse problems is
  typically unstable.
\newblock \emph{arXiv preprint arXiv:2001.01258}, 2020.

\bibitem[H{\"a}rdle et~al.(1998)H{\"a}rdle, Kerkyacharian, Picard, and
  Tsybakov]{hardle1998wavelets}
Wolfgang H{\"a}rdle, Gerard Kerkyacharian, Dominique Picard, and Alexander
  Tsybakov.
\newblock \emph{Wavelets, approximation, and statistical applications}, volume
  129.
\newblock Springer Science \& Business Media, 1998.

\bibitem[Jiao et~al.(2021)Jiao, Shen, Lin, and Huang]{jiao2021deep}
Yuling Jiao, Guohao Shen, Yuanyuan Lin, and Jian Huang.
\newblock Deep nonparametric regression on approximately low-dimensional
  manifolds.
\newblock \emph{arXiv preprint arXiv:2104.06708}, 2021.

\bibitem[Jumper et~al.(2021)Jumper, Evans, Pritzel, Green, Figurnov,
  Ronneberger, Tunyasuvunakool, Bates, {\v{Z}}{\'\i}dek, Potapenko,
  et~al.]{jumper2021highly}
John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov,
  Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin
  {\v{Z}}{\'\i}dek, Anna Potapenko, et~al.
\newblock Highly accurate protein structure prediction with {AlphaFold}.
\newblock \emph{Nature}, 596\penalty0 (7873):\penalty0 583--589, 2021.

\bibitem[Kaddour et~al.(2022)Kaddour, Lynch, Liu, Kusner, and
  Silva]{kaddour2022causal}
Jean Kaddour, Aengus Lynch, Qi~Liu, Matt~J Kusner, and Ricardo Silva.
\newblock Causal machine learning: A survey and open problems.
\newblock \emph{arXiv preprint arXiv:2206.15475}, 2022.

\bibitem[Kingma and Ba(2015)]{kingma2015adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2012imagenet}
Alex Krizhevsky, Ilya Sutskever, and Geoffrey~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~25, pages 1097--1105, 2012.

\bibitem[Li et~al.(2005)Li, {Tchetgen Tchetgen}, {van der Vaart}, and
  Robins]{li2005robust}
Lingling Li, Eric {Tchetgen Tchetgen}, Aad {van der Vaart}, and James Robins.
\newblock Robust inference with higher order influence functions: Parts {I} and
  {II}.
\newblock In \emph{Joint Statistical Meetings, Minneapolis, Minnesota}, 2005.

\bibitem[Liu et~al.(2020)Liu, Mukherjee, and Robins]{liu2020nearly}
Lin Liu, Rajarshi Mukherjee, and James~M Robins.
\newblock On nearly assumption-free tests of nominal confidence interval
  coverage for causal parameters estimated by machine learning.
\newblock \emph{Statistical Science}, 35\penalty0 (3):\penalty0 518--539, 2020.

\bibitem[Lu et~al.(2021)Lu, Shen, Yang, and Zhang]{lu2021deep}
Jianfeng Lu, Zuowei Shen, Haizhao Yang, and Shijun Zhang.
\newblock Deep network approximation for smooth functions.
\newblock \emph{SIAM Journal on Mathematical Analysis}, 53\penalty0
  (5):\penalty0 5465--5506, 2021.

\bibitem[Malinsky et~al.(2019)Malinsky, Shpitser, and
  Richardson]{malinsky2019potential}
Daniel Malinsky, Ilya Shpitser, and Thomas Richardson.
\newblock A potential outcomes calculus for identifying conditional
  path-specific effects.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 3080--3088. PMLR, 2019.

\bibitem[Miles et~al.(2020)Miles, Shpitser, Kanki, Meloni, and
  Tchetgen~Tchetgen]{miles2020semiparametric}
Caleb~H Miles, Ilya Shpitser, Phyllis Kanki, Seema Meloni, and Eric~J
  Tchetgen~Tchetgen.
\newblock On semiparametric estimation of a path-specific effect in the
  presence of mediator-outcome confounding.
\newblock \emph{Biometrika}, 107\penalty0 (1):\penalty0 159--172, 2020.

\bibitem[Nabi and Shpitser(2018)]{nabi2018fair}
Razieh Nabi and Ilya Shpitser.
\newblock Fair inference on outcomes.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~32, 2018.

\bibitem[Newey(1990)]{newey1990semiparametric}
Whitney~K Newey.
\newblock Semiparametric efficiency bounds.
\newblock \emph{Journal of Applied Econometrics}, 5\penalty0 (2):\penalty0
  99--135, 1990.

\bibitem[Neyshabur(2017)]{neyshabur2017implicit}
Behnam Neyshabur.
\newblock \emph{Implicit regularization in deep learning}.
\newblock PhD thesis, Toyota Technological Institute at Chicago (TTIC), 2017.

\bibitem[Pearl(2001)]{pearl2001direct}
Judea Pearl.
\newblock Direct and indirect effects.
\newblock In \emph{Proceedings of the Seventeenth Conference on Uncertainty and
  Artificial Intelligence}, pages 411--420. Morgan Kaufman, 2001.

\bibitem[Pineau et~al.(2021)Pineau, Vincent-Lamarre, Sinha, Larivi{\`e}re,
  Beygelzimer, d'Alch{\'e} Buc, Fox, and Larochelle]{pineau2021improving}
Joelle Pineau, Philippe Vincent-Lamarre, Koustuv Sinha, Vincent Larivi{\`e}re,
  Alina Beygelzimer, Florence d'Alch{\'e} Buc, Emily Fox, and Hugo Larochelle.
\newblock Improving reproducibility in machine learning research: a report from
  the {NeurIPS} 2019 reproducibility program.
\newblock \emph{Journal of Machine Learning Research}, 22, 2021.

\bibitem[Robins et~al.(2020)Robins, Sued, Lei-Gomez, and
  Rotnitzky]{robins2020double}
James Robins, Mariela Sued, Quanhong Lei-Gomez, and Andrea Rotnitzky.
\newblock Double-robust and efficient methods for estimating the causal effects
  of a binary treatment.
\newblock \emph{arXiv preprint arXiv:2008.00507}, 2020.

\bibitem[Robins and Greenland(1992)]{robins1992identifiability}
James~M Robins and Sander Greenland.
\newblock Identifiability and exchangeability for direct and indirect effects.
\newblock \emph{Epidemiology}, 3\penalty0 (2):\penalty0 143--155, 1992.

\bibitem[Rotnitzky et~al.(2021)Rotnitzky, Smucler, and
  Robins]{rotnitzky2021characterization}
Andrea Rotnitzky, Ezequiel Smucler, and James~M Robins.
\newblock Characterization of parameters with a mixed bias property.
\newblock \emph{Biometrika}, 108\penalty0 (1):\penalty0 231--238, 2021.

\bibitem[Schmidt-Hieber(2020)]{schmidt2020nonparametric}
Johannes Schmidt-Hieber.
\newblock Nonparametric regression using deep neural networks with {R}e{LU}
  activation function.
\newblock \emph{Annals of Statistics}, 48\penalty0 (4):\penalty0 1875--1897,
  2020.

\bibitem[Stone(1982)]{stone1982optimal}
Charles~J Stone.
\newblock Optimal global rates of convergence for nonparametric regression.
\newblock \emph{The Annals of Statistics}, 10\penalty0 (4):\penalty0
  1040--1053, 1982.

\bibitem[Suzuki(2019)]{suzuki2019adaptivity}
Taiji Suzuki.
\newblock Adaptivity of deep {R}e{LU} network for learning in {B}esov and mixed
  smooth {B}esov spaces: optimal rate and curse of dimensionality.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[{Tchetgen Tchetgen} and Shpitser(2012)]{tchetgen2012semiparametric}
Eric~J {Tchetgen Tchetgen} and Ilya Shpitser.
\newblock Semiparametric theory for causal mediation analysis: Efficiency
  bounds, multiple robustness and sensitivity analysis.
\newblock \emph{The Annals of Statistics}, 40\penalty0 (3):\penalty0
  1816--1845, 2012.

\bibitem[Tsuji and Suzuki(2021)]{tsuji2021estimation}
Kazuma Tsuji and Taiji Suzuki.
\newblock Estimation error analysis of deep learning on the regression problem
  on the variable exponent {B}esov space.
\newblock \emph{Electronic Journal of Statistics}, 15\penalty0 (1):\penalty0
  1869--1908, 2021.

\bibitem[Wolf et~al.(2019)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac,
  Rault, Louf, Funtowicz, et~al.]{wolf2019huggingface}
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
  Anthony Moi, Pierric Cistac, Tim Rault, R{\'e}mi Louf, Morgan Funtowicz,
  et~al.
\newblock Huggingface's transformers: State-of-the-art natural language
  processing.
\newblock \emph{arXiv preprint arXiv:1910.03771}, 2019.

\end{thebibliography}
