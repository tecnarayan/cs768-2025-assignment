\begin{thebibliography}{42}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Beaudry \& Renner(2012)Beaudry and Renner]{beaudry2012intuitive}
Beaudry, N.~J. and Renner, R.
\newblock An intuitive proof of the data processing inequality.
\newblock \emph{Quantum Information \& Computation}, 12\penalty0 (5-6):\penalty0 432--441, 2012.

\bibitem[Clark et~al.(2020)Clark, Luong, Le, and Manning]{clark2020electra}
Clark, K., Luong, M.-T., Le, Q.~V., and Manning, C.~D.
\newblock Electra: Pre-training text encoders as discriminators rather than generators.
\newblock \emph{ICLR}, 2020.

\bibitem[Craswell et~al.(2020)Craswell, Mitra, Yilmaz, Campos, and Voorhees]{craswell2020overview}
Craswell, N., Mitra, B., Yilmaz, E., Campos, D., and Voorhees, E.~M.
\newblock Overview of the trec 2019 deep learning track.
\newblock \emph{arXiv preprint arXiv:2003.07820}, 2020.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language understanding.
\newblock \emph{NAACL}, 2019.

\bibitem[Esser et~al.(2021)Esser, Rombach, and Ommer]{esser2021taming}
Esser, P., Rombach, R., and Ommer, B.
\newblock Taming transformers for high-resolution image synthesis.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pp.\  12873--12883, 2021.

\bibitem[Gao et~al.(2021)Gao, Yao, and Chen]{gao2021simcse}
Gao, T., Yao, X., and Chen, D.
\newblock {SimCSE}: Simple contrastive learning of sentence embeddings.
\newblock In \emph{EMNLP}, 2021.

\bibitem[He et~al.(2018)He, Spokoyny, Neubig, and Berg-Kirkpatrick]{he2018lagging}
He, J., Spokoyny, D., Neubig, G., and Berg-Kirkpatrick, T.
\newblock Lagging inference networks and posterior collapse in variational autoencoders.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[He \& McAuley(2016)He and McAuley]{he2016ups}
He, R. and McAuley, J.
\newblock Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering.
\newblock In \emph{WWW}, pp.\  507--517, 2016.

\bibitem[Hidasi et~al.(2016)Hidasi, Karatzoglou, Baltrunas, and Tikk]{hidasi2015session}
Hidasi, B., Karatzoglou, A., Baltrunas, L., and Tikk, D.
\newblock Session-based recommendations with recurrent neural networks.
\newblock In \emph{ICLR}, 2016.

\bibitem[Horgan(1995)]{horgan1995complexity}
Horgan, J.
\newblock From complexity to perplexity.
\newblock \emph{Scientific American}, 272\penalty0 (6):\penalty0 104--109, 1995.

\bibitem[Hua et~al.(2023)Hua, Xu, Ge, and Zhang]{hua2023index}
Hua, W., Xu, S., Ge, Y., and Zhang, Y.
\newblock How to index item ids for recommendation foundation models.
\newblock \emph{arXiv preprint arXiv:2305.06569}, 2023.

\bibitem[Jang et~al.(2016)Jang, Gu, and Poole]{jang2016categorical}
Jang, E., Gu, S., and Poole, B.
\newblock Categorical reparameterization with gumbel-softmax.
\newblock In \emph{International Conference on Learning Representations}, 2016.

\bibitem[Jin et~al.(2023)Jin, Liu, Han, Jiang, Ji, and Han]{jin2023large}
Jin, B., Liu, G., Han, C., Jiang, M., Ji, H., and Han, J.
\newblock Large language models on graphs: A comprehensive survey.
\newblock \emph{arXiv preprint arXiv:2312.02783}, 2023.

\bibitem[Karpukhin et~al.(2020)Karpukhin, Oguz, Min, Lewis, Wu, Edunov, Chen, and Yih]{karpukhin2020dense}
Karpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., and Yih, W.-t.
\newblock Dense passage retrieval for open-domain question answering.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)}, pp.\  6769--6781, 2020.

\bibitem[Kousha \& Thelwall(2007)Kousha and Thelwall]{kousha2007google}
Kousha, K. and Thelwall, M.
\newblock Google scholar citations and google web/url citations: A multi-discipline exploratory analysis.
\newblock \emph{Journal of the American Society for Information Science and Technology}, 58\penalty0 (7):\penalty0 1055--1065, 2007.

\bibitem[Kwiatkowski et~al.(2019)Kwiatkowski, Palomaki, Redfield, Collins, Parikh, Alberti, Epstein, Polosukhin, Devlin, Lee, et~al.]{kwiatkowski2019natural}
Kwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A., Alberti, C., Epstein, D., Polosukhin, I., Devlin, J., Lee, K., et~al.
\newblock Natural questions: a benchmark for question answering research.
\newblock \emph{Transactions of the Association for Computational Linguistics}, 7:\penalty0 453--466, 2019.

\bibitem[Lee et~al.(2022)Lee, Kim, Kim, Cho, and Han]{lee2022autoregressive}
Lee, D., Kim, C., Kim, S., Cho, M., and Han, W.-S.
\newblock Autoregressive image generation using residual quantization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  11523--11532, 2022.

\bibitem[Liu et~al.(2019)Liu, Ott, Goyal, Du, Joshi, Chen, Levy, Lewis, Zettlemoyer, and Stoyanov]{liu2019roberta}
Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer, L., and Stoyanov, V.
\newblock Roberta: A robustly optimized bert pretraining approach.
\newblock \emph{arXiv preprint arXiv:1907.11692}, 2019.

\bibitem[Ma et~al.(2019)Ma, Kang, and Liu]{ma2019hierarchical}
Ma, C., Kang, P., and Liu, X.
\newblock Hierarchical gating networks for sequential recommendation.
\newblock In \emph{Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery \& data mining}, pp.\  825--833, 2019.

\bibitem[Ma et~al.(2022)Ma, Zhang, Guo, Fan, and Cheng]{ma2022contrastive}
Ma, X., Zhang, R., Guo, J., Fan, Y., and Cheng, X.
\newblock A contrastive pre-training approach to discriminative autoencoder for dense retrieval.
\newblock In \emph{Proceedings of the 31st ACM International Conference on Information \& Knowledge Management}, pp.\  4314--4318, 2022.

\bibitem[Murtagh \& Contreras(2012)Murtagh and Contreras]{murtagh2012algorithms}
Murtagh, F. and Contreras, P.
\newblock Algorithms for hierarchical clustering: an overview.
\newblock \emph{Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery}, 2\penalty0 (1):\penalty0 86--97, 2012.

\bibitem[Nguyen et~al.(2016)Nguyen, Rosenberg, Song, Gao, Tiwary, Majumder, and Deng]{nguyen2016ms}
Nguyen, T., Rosenberg, M., Song, X., Gao, J., Tiwary, S., Majumder, R., and Deng, L.
\newblock Ms marco: A human-generated machine reading comprehension dataset.
\newblock 2016.

\bibitem[Nogueira et~al.(2019)Nogueira, Lin, and Epistemic]{nogueira2019doc2query}
Nogueira, R., Lin, J., and Epistemic, A.
\newblock From doc2query to doctttttquery.
\newblock \emph{Online preprint}, 6:\penalty0 2, 2019.

\bibitem[Opitz \& Burst(2019)Opitz and Burst]{opitz2019macro}
Opitz, J. and Burst, S.
\newblock Macro f1 and macro f1.
\newblock \emph{arXiv preprint arXiv:1911.03347}, 2019.

\bibitem[Pradeep et~al.(2023)Pradeep, Hui, Gupta, Lelkes, Zhuang, Lin, Metzler, and Tran]{pradeep2023does}
Pradeep, R., Hui, K., Gupta, J., Lelkes, A.~D., Zhuang, H., Lin, J., Metzler, D., and Tran, V.~Q.
\newblock How does generative retrieval scale to millions of passages?
\newblock \emph{arXiv preprint arXiv:2305.11841}, 2023.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, Sutskever, et~al.]{radford2019language}
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et~al.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI blog}, 2019.

\bibitem[Raffel et~al.(2020)Raffel, Shazeer, Roberts, Lee, Narang, Matena, Zhou, Li, Liu, et~al.]{raffel2020exploring}
Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., Liu, P.~J., et~al.
\newblock Exploring the limits of transfer learning with a unified text-to-text transformer.
\newblock \emph{JMLR}, 2020.

\bibitem[Rajput et~al.(2023)Rajput, Mehta, Singh, Keshavan, Vu, Heldt, Hong, Tay, Tran, Samost, et~al.]{rajput2023recommender}
Rajput, S., Mehta, N., Singh, A., Keshavan, R.~H., Vu, T., Heldt, L., Hong, L., Tay, Y., Tran, V.~Q., Samost, J., et~al.
\newblock Recommender systems with generative retrieval.
\newblock \emph{arXiv preprint arXiv:2305.05065}, 2023.

\bibitem[Reddy et~al.(2022)Reddy, Màrquez, Valero, Rao, Zaragoza, Bandyopadhyay, Biswas, Xing, and Subbian]{reddy2022shopping}
Reddy, C.~K., Màrquez, L., Valero, F., Rao, N., Zaragoza, H., Bandyopadhyay, S., Biswas, A., Xing, A., and Subbian, K.
\newblock Shopping queries dataset: A large-scale {ESCI} benchmark for improving product search, 2022.

\bibitem[Robertson et~al.(2009)Robertson, Zaragoza, et~al.]{robertson2009probabilistic}
Robertson, S., Zaragoza, H., et~al.
\newblock The probabilistic relevance framework: Bm25 and beyond.
\newblock \emph{Foundations and Trends{\textregistered} in Information Retrieval}, 3\penalty0 (4):\penalty0 333--389, 2009.

\bibitem[Sun et~al.(2019)Sun, Liu, Wu, Pei, Lin, Ou, and Jiang]{sun2019bert4rec}
Sun, F., Liu, J., Wu, J., Pei, C., Lin, X., Ou, W., and Jiang, P.
\newblock Bert4rec: Sequential recommendation with bidirectional encoder representations from transformer.
\newblock In \emph{Proceedings of the 28th ACM international conference on information and knowledge management}, pp.\  1441--1450, 2019.

\bibitem[Sun et~al.(2023)Sun, Yan, Chen, Wang, Zhu, Ren, Chen, Yin, de~Rijke, and Ren]{sun2023learning}
Sun, W., Yan, L., Chen, Z., Wang, S., Zhu, H., Ren, P., Chen, Z., Yin, D., de~Rijke, M., and Ren, Z.
\newblock Learning to tokenize for generative retrieval.
\newblock \emph{arXiv preprint arXiv:2304.04171}, 2023.

\bibitem[Tay et~al.(2022)Tay, Tran, Dehghani, Ni, Bahri, Mehta, Qin, Hui, Zhao, Gupta, et~al.]{tay2022transformer}
Tay, Y., Tran, V., Dehghani, M., Ni, J., Bahri, D., Mehta, H., Qin, Z., Hui, K., Zhao, Z., Gupta, J., et~al.
\newblock Transformer memory as a differentiable search index.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 21831--21843, 2022.

\bibitem[Van Den~Oord et~al.(2017)Van Den~Oord, Vinyals, et~al.]{van2017neural}
Van Den~Oord, A., Vinyals, O., et~al.
\newblock Neural discrete representation learning.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N., Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Vinh et~al.(2009)Vinh, Epps, and Bailey]{vinh2009information}
Vinh, N.~X., Epps, J., and Bailey, J.
\newblock Information theoretic measures for clusterings comparison: is a correction for chance necessary?
\newblock In \emph{Proceedings of the 26th annual international conference on machine learning}, pp.\  1073--1080, 2009.

\bibitem[Wang \& Isola(2020)Wang and Isola]{wang2020understanding}
Wang, T. and Isola, P.
\newblock Understanding contrastive representation learning through alignment and uniformity on the hypersphere.
\newblock In \emph{International Conference on Machine Learning}, pp.\  9929--9939. PMLR, 2020.

\bibitem[Wang et~al.(2022)Wang, Hou, Wang, Miao, Wu, Chen, Xia, Chi, Zhao, Liu, et~al.]{wang2022neural}
Wang, Y., Hou, Y., Wang, H., Miao, Z., Wu, S., Chen, Q., Xia, Y., Chi, C., Zhao, G., Liu, Z., et~al.
\newblock A neural corpus indexer for document retrieval.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 25600--25614, 2022.

\bibitem[Wei et~al.(2023)Wei, Jin, Li, Zeng, Wang, Sun, Yin, Lu, Wang, He, et~al.]{wei2023towards}
Wei, T., Jin, B., Li, R., Zeng, H., Wang, Z., Sun, J., Yin, Q., Lu, H., Wang, S., He, J., et~al.
\newblock Towards universal multi-modal personalization: A language model empowered generative paradigm.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2023.

\bibitem[Xiao et~al.(2022)Xiao, Liu, Shao, and Cao]{xiao2022retromae}
Xiao, S., Liu, Z., Shao, Y., and Cao, Z.
\newblock Retromae: Pre-training retrieval-oriented language models via masked auto-encoder.
\newblock In \emph{Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing}, pp.\  538--548, 2022.

\bibitem[Zeng et~al.(2023)Zeng, Luo, Jin, Sarwar, Wei, and Zamani]{zeng2023scalable}
Zeng, H., Luo, C., Jin, B., Sarwar, S.~M., Wei, T., and Zamani, H.
\newblock Scalable and effective generative information retrieval.
\newblock \emph{arXiv preprint arXiv:2311.09134}, 2023.

\bibitem[Zhang et~al.(2019)Zhang, Zhao, Liu, Sheng, Xu, Wang, Liu, Zhou, et~al.]{zhang2019feature}
Zhang, T., Zhao, P., Liu, Y., Sheng, V.~S., Xu, J., Wang, D., Liu, G., Zhou, X., et~al.
\newblock Feature-level deeper self-attention network for sequential recommendation.
\newblock In \emph{IJCAI}, pp.\  4320--4326, 2019.

\end{thebibliography}
