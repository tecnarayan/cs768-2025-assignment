\begin{thebibliography}{10}

\bibitem{agrawal2013multi}
R.~Agrawal, A.~Gupta, Y.~Prabhu, and M.~Varma.
\newblock Multi-label learning with millions of labels: Recommending advertiser
  bid phrases for web pages.
\newblock In {\em Proceedings of the 22nd international conference on World
  Wide Web}, pages 13--24. ACM, 2013.

\bibitem{babbar2017dismec}
R.~Babbar and B.~Sch{\"o}lkopf.
\newblock Dismec: Distributed sparse machines for extreme multi-label
  classification.
\newblock In {\em Proceedings of the Tenth ACM International Conference on Web
  Search and Data Mining}, pages 721--729. ACM, 2017.

\bibitem{babbar2019data}
R.~Babbar and B.~Sch{\"o}lkopf.
\newblock Data scarcity, robustness and extreme multi-label classification.
\newblock {\em Machine Learning}, 108(8-9):1329--1351, 2019.

\bibitem{Indyk2008}
R.~Berinde, A.~Gilbert, P.~Indyk, H.~Karloff, and M.~Strauss.
\newblock Combining geometry and combinatorics: A unified approach to sparse
  signal recovery.
\newblock {\em CoRR}, abs/0804.4666, 01 2008.

\bibitem{bhatia2015sparse}
K.~Bhatia, H.~Jain, P.~Kar, M.~Varma, and P.~Jain.
\newblock Sparse local embeddings for extreme multi-label classification.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  730--738, 2015.

\bibitem{bi2013efficient}
W.~Bi and J.~T.~Y. Kwok.
\newblock Efficient multi-label classification with many labels.
\newblock In {\em 30th International Conference on Machine Learning, ICML
  2013}, pages 405--413, 2013.

\bibitem{chang2019modular}
W.-C. Chang, H.-F. Yu, K.~Zhong, Y.~Yang, and I.~Dhillon.
\newblock A modular deep learning approach for extreme multi-label text
  classification.
\newblock {\em arXiv preprint arXiv:1905.02331}, 2019.

\bibitem{chen2012feature}
Y.-N. Chen and H.-T. Lin.
\newblock Feature-aware label space dimension reduction for multi-label
  classification.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  1529--1537, 2012.

\bibitem{Deng2011}
J.~Deng, S.~Satheesh, A.~C. Berg, and F.~Li.
\newblock Fast and balanced: Efficient label tree learning for large scale
  object recognition.
\newblock In J.~Shawe-Taylor, R.~S. Zemel, P.~L. Bartlett, F.~Pereira, and
  K.~Q. Weinberger, editors, {\em Advances in Neural Information Processing
  Systems 24}, pages 567--575. Curran Associates, Inc., 2011.

\bibitem{gallager62}
R.~{Gallager}.
\newblock Low-density parity-check codes.
\newblock {\em IRE Transactions on Information Theory}, 8(1):21--28, January
  1962.

\bibitem{gupta1997fast}
A.~Gupta.
\newblock Fast and effective algorithms for graph partitioning and
  sparse-matrix ordering.
\newblock {\em IBM Journal of Research and Development}, 41(1.2):171--183,
  1997.

\bibitem{gupta2019distributional}
V.~Gupta, R.~Wadbude, N.~Natarajan, H.~Karnick, P.~Jain, and P.~Rai.
\newblock Distributional semantics meets multi-label learning.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 3747--3754, 2019.

\bibitem{dingNMF}
C.~H.~Q.~Ding and X.~He.
\newblock On the equivalence of nonnegative matrix factorization and spectral
  clustering.
\newblock In {\em Proceedings of the SIAM International Conference on Data
  Mining}, pages 606--610, 01 2005.

\bibitem{hsu2009multi}
D.~Hsu, S.~M. Kakade, J.~Langford, and T.~Zhang.
\newblock Multi-label prediction via compressed sensing.
\newblock {\em NIPS}, 22:772--780, 2009.

\bibitem{Jain2019slice}
H.~Jain, V.~Balasubramanian, B.~Chunduri, and M.~Varma.
\newblock Slice: Scalable linear extreme classifiers trained on 100 million
  labels for related searches.
\newblock In {\em Proceedings of the Twelfth ACM International Conference on
  Web Search and Data Mining}, WSDM '19, pages 528--536. ACM, 2019.

\bibitem{jain2016extreme}
H.~Jain, Y.~Prabhu, and M.~Varma.
\newblock Extreme multi-label loss functions for recommendation, tagging,
  ranking \& other missing label applications.
\newblock In {\em Proceedings of the 22nd ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, pages 935--944. ACM, 2016.

\bibitem{ijcai2019-361}
A.~Jalan and P.~Kar.
\newblock Accelerating extreme classification via adaptive feature
  agglomeration.
\newblock In {\em Proceedings of the Twenty-Eighth International Joint
  Conference on Artificial Intelligence, {IJCAI-19}}, pages 2600--2606.
  International Joint Conferences on Artificial Intelligence Organization, 7
  2019.

\bibitem{pmlr-v48-jasinska16}
K.~Jasinska, K.~Dembczynski, R.~Busa-Fekete, K.~Pfannschmidt, T.~Klerx, and
  E.~Hullermeier.
\newblock Extreme f-measure maximization using sparse probability estimates.
\newblock In M.~F. Balcan and K.~Q. Weinberger, editors, {\em Proceedings of
  The 33rd International Conference on Machine Learning}, volume~48 of {\em
  Proceedings of Machine Learning Research}, pages 1435--1444, New York, New
  York, USA, 20--22 Jun 2016.

\bibitem{karypis1998fast}
G.~Karypis and V.~Kumar.
\newblock A fast and high quality multilevel scheme for partitioning irregular
  graphs.
\newblock {\em SIAM Journal on scientific Computing}, 20(1):359--392, 1998.

\bibitem{khandagale2019bonsai}
S.~Khandagale, H.~Xiao, and R.~Babbar.
\newblock Bonsai-diverse and shallow trees for extreme multi-label
  classification.
\newblock {\em arXiv preprint arXiv:1904.08249}, 2019.

\bibitem{klein2012101}
A.~Klein and J.~Tourville.
\newblock 101 labeled brain images and a consistent human cortical labeling
  protocol.
\newblock {\em Frontiers in neuroscience}, 6:171, 2012.

\bibitem{symmNMF}
D.~Kuang, C.~Ding, and H.~Park.
\newblock Symmetric nonnegative matrix factorization for graph clustering.
\newblock In {\em Proceedings of the 2012 SIAM International Conference on Data
  Mining}, pages 106--117, 2012.

\bibitem{Saffron2016}
K.~{Lee}, R.~{Pedarsani}, and K.~{Ramchandran}.
\newblock Saffron: A fast, efficient, and robust framework for group testing
  based on sparse-graph codes.
\newblock In {\em 2016 IEEE International Symposium on Information Theory
  (ISIT)}, pages 2873--2877, July 2016.

\bibitem{Liu2017XMLCNN}
J.~Liu, W.-C. Chang, Y.~Wu, and Y.~Yang.
\newblock Deep learning for extreme multi-label text classification.
\newblock In {\em Proceedings of the 40th International ACM SIGIR Conference on
  Research and Development in Information Retrieval}, SIGIR '17, pages
  115--124, New York, NY, USA, 2017.

\bibitem{mcdiarmid1989method}
C.~McDiarmid.
\newblock On the method of bounded differences.
\newblock {\em Surveys in combinatorics}, 141(1):148--188, 1989.

\bibitem{mikolov2013distributed}
T.~Mikolov, I.~Sutskever, K.~Chen, G.~S. Corrado, and J.~Dean.
\newblock Distributed representations of words and phrases and their
  compositionality.
\newblock In {\em Advances in neural information processing systems}, pages
  3111--3119, 2013.

\bibitem{Prabhu2018swift}
Y.~Prabhu, A.~Kag, S.~Gopinath, K.~Dahiya, S.~Harsola, R.~Agrawal, and
  M.~Varma.
\newblock Extreme multi-label learning with label features for warm-start
  tagging, ranking \&\#38; recommendation.
\newblock In {\em Proceedings of the Eleventh ACM International Conference on
  Web Search and Data Mining}, WSDM '18, pages 441--449. ACM, 2018.

\bibitem{Prabhu2018parabel}
Y.~Prabhu, A.~Kag, S.~Harsola, R.~Agrawal, and M.~Varma.
\newblock Parabel: Partitioned label trees for extreme classification with
  application to dynamic search advertising.
\newblock In {\em Proceedings of the 2018 World Wide Web Conference}, WWW '18,
  pages 993--1002, Republic and Canton of Geneva, Switzerland, 2018.
  
\bibitem{Prabhu20141fastxml}
Y.~Prabhu and M.~Varma.
\newblock Fastxml: A fast, accurate and stable tree-classifier for extreme
  multi-label learning.
\newblock In {\em Proceedings of the 20th ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, KDD '14, pages 263--272. ACM, 2014.

\bibitem{saad2003iterative}
Y.~Saad.
\newblock {\em Iterative methods for sparse linear systems}, volume~82.
\newblock siam, 2003.

\bibitem{siblini2018craftml}
W.~Siblini, P.~Kuntz, and F.~Meyer.
\newblock Craftml, an efficient clustering-based random forest for extreme
  multi-label learning.
\newblock In {\em International Conference on Machine Learning}, pages
  4664--4673, 2018.

\bibitem{tai2012multilabel}
F.~Tai and H.-T. Lin.
\newblock Multilabel classification with principal label space transformation.
\newblock {\em Neural Computation}, 24(9):2508--2542, 2012.

\bibitem{trohidis2008multi}
K.~Trohidis.
\newblock Multi-label classification of music into emotions.
\newblock In {\em 9th International Con- ference on Music Information
  Retrieval}, pages 325–-- 330, 2008.

\bibitem{tsoumakas2008effective}
G.~Tsoumakas, I.~Katakis, and I.~Vlahavas.
\newblock Effective and efficient multilabel classification in domains with
  large number of labels.
\newblock In {\em ECML/PKDD 2008 Workshop on Mining Multidimensional Data
  (MMD’08)}, 2008.

\bibitem{ubaru2017multilabel}
S.~Ubaru and A.~Mazumdar.
\newblock Multilabel classification with group testing and codes.
\newblock In {\em Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 3492--3501. JMLR. org, 2017.

\bibitem{ubaru2016group}
S.~Ubaru, A.~Mazumdar, and A.~Barg.
\newblock Group testing schemes from low-weight codewords of {BCH} codes.
\newblock In {\em Information Theory (ISIT), 2016 IEEE International Symposium
  on}, pages 2863--2867. IEEE, 2016.

\bibitem{symcord}
A.~{Vandaele}, N.~{Gillis}, Q.~{Lei}, K.~{Zhong}, and I.~{Dhillon}.
\newblock Efficient and non-convex coordinate descent for symmetric nonnegative
  matrix factorization.
\newblock {\em IEEE Transactions on Signal Processing}, 64(21):5571--5584,
  2016.

\bibitem{fast2017}
A.~Vem, N.~Thenkarai~Janakiraman, and K.~Narayanan.
\newblock Group testing using left-and-right-regular sparse-graph codes.
\newblock {\em arxiv.org:1701.07477.}, 2017.

\bibitem{wang2009multi}
C.~Wang, S.~Yan, L.~Zhang, and H.-J. Zhang.
\newblock Multi-label sparse coding for automatic image annotation.
\newblock In {\em Computer Vision and Pattern Recognition, 2009. CVPR 2009.
  IEEE Conference on}, pages 1643--1650. IEEE, 2009.

\bibitem{wydmuch2018no}
M.~Wydmuch, K.~Jasinska, M.~Kuznetsov, R.~Busa-Fekete, and K.~Dembczynski.
\newblock A no-regret generalization of hierarchical softmax to extreme
  multi-label classification.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  6355--6366, 2018.

\bibitem{xu2016robust}
C.~Xu, D.~Tao, and C.~Xu.
\newblock Robust extreme multi-label learning.
\newblock In {\em Proceedings of the 22nd ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, pages 1275--1284. ACM, 2016.

\bibitem{yen2017ppd}
I.~E.-H. Yen, X.~Huang, W.~Dai, P.~Ravikumar, I.~Dhillon, and E.~Xing.
\newblock Ppdsparse: A parallel primal-dual sparse method for extreme
  classification.
\newblock In {\em Proceedings of the 23rd ACM SIGKDD International Conference
  on Knowledge Discovery and Data Mining}, KDD, pages 545--553, 2017.

\bibitem{Yen2016pdsparse}
I.~E.~H. Yen, X.~Huang, K.~Zhong, P.~Ravikumar, and I.~S. Dhillon.
\newblock Pd-sparse: A primal and dual sparse approach to extreme multiclass
  and multilabel classification.
\newblock In {\em Proceedings of the 33rd International Conference on
  International Conference on Machine Learning - Volume 48}, ICML'16, pages
  3069--3077. JMLR.org, 2016.

\bibitem{you2018attentionxml}
R.~You, S.~Dai, Z.~Zhang, H.~Mamitsuka, and S.~Zhu.
\newblock Attentionxml: Extreme multi-label text classification with
  multi-label attention based recurrent neural networks.
\newblock {\em arXiv preprint arXiv:1811.01727}, 2018.

\bibitem{yu2014large}
H.-f. Yu, P.~Jain, P.~Kar, and I.~Dhillon.
\newblock Large-scale multi-label learning with missing labels.
\newblock In {\em Proceedings of the 31st International Conference on Machine
  Learning (ICML-14)}, pages 593--601, 2014.

\bibitem{Zhang2018}
M.-L. Zhang, Y.-K. Li, X.-Y. Liu, and X.~Geng.
\newblock Binary relevance for multi-label learning: an overview.
\newblock {\em Frontiers of Computer Science}, 2018.

\bibitem{Zhang2018Deep}
W.~Zhang, J.~Yan, X.~Wang, and H.~Zha.
\newblock Deep extreme multi-label learning.
\newblock In {\em Proceedings of the 2018 ACM on International Conference on
  Multimedia Retrieval}, ICMR '18, pages 100--107, New York, NY, USA, 2018.
  ACM.

\bibitem{zhang2011multi}
Y.~Zhang and J.~G. Schneider.
\newblock Multi-label output codes using canonical correlation analysis.
\newblock In {\em AISTATS}, pages 873--–882, 2011.

\end{thebibliography}
