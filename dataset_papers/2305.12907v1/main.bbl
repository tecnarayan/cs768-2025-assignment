\begin{thebibliography}{10}

\bibitem{eloundou2023gpts}
Tyna Eloundou, Sam Manning, Pamela Mishkin, and Daniel Rock.
\newblock Gpts are gpts: An early look at the labor market impact potential of
  large language models.
\newblock {\em arXiv preprint arXiv:2303.10130}, 2023.

\bibitem{kasneci2023chatgpt}
Enkelejda Kasneci, Kathrin Se{\ss}ler, Stefan K{\"u}chemann, Maria Bannert,
  Daryna Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan
  G{\"u}nnemann, Eyke H{\"u}llermeier, et~al.
\newblock Chatgpt for good? on opportunities and challenges of large language
  models for education.
\newblock {\em Learning and Individual Differences}, 103:102274, 2023.

\bibitem{birhane2023science}
Abeba Birhane, Atoosa Kasirzadeh, David Leslie, and Sandra Wachter.
\newblock Science in the age of large language models.
\newblock {\em Nature Reviews Physics}, pages 1--4, 2023.

\bibitem{drori2022neural}
Iddo Drori, Sarah Zhang, Reece Shuttleworth, Leonard Tang, Albert Lu, Elizabeth
  Ke, Kevin Liu, Linda Chen, Sunny Tran, Newman Cheng, et~al.
\newblock A neural network solves, explains, and generates university math
  problems by program synthesis and few-shot learning at human level.
\newblock {\em Proceedings of the National Academy of Sciences},
  119(32):e2123433119, 2022.

\bibitem{webb2022emergent}
Taylor Webb, Keith~J Holyoak, and Hongjing Lu.
\newblock Emergent analogical reasoning in large language models.
\newblock {\em arXiv preprint arXiv:2212.09196}, 2022.

\bibitem{brown2020language}
Tom~B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
  Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
  Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
  Rewon Child, Aditya Ramesh, Daniel~M. Ziegler, Jeffrey Wu, Clemens Winter,
  Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,
  Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford,
  Ilya Sutskever, and Dario Amodei.
\newblock Language models are few-shot learners, 2020.

\bibitem{chan2022data&burstiness}
Stephanie C.~Y. Chan, Adam Santoro, Andrew~K. Lampinen, Jane~X. Wang, Aaditya
  Singh, Pierre~H. Richemond, Jay McClelland, and Felix Hill.
\newblock Data distributional properties drive emergent in-context learning in
  transformers, 2022.

\bibitem{min2022rethinking}
Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh
  Hajishirzi, and Luke Zettlemoyer.
\newblock Rethinking the role of demonstrations: What makes in-context learning
  work?, 2022.

\bibitem{xie2022bayesianexplanation}
Sang~Michael Xie, Aditi Raghunathan, Percy Liang, and Tengyu Ma.
\newblock An explanation of in-context learning as implicit bayesian inference,
  2022.

\bibitem{Lovre}
Lovre.
\newblock Who models the models that model models? an exploration of gpt-3's
  in-context model fitting ability.
\newblock
  \url{https://www.alignmentforum.org/posts/c2RzFadrxkzyRAFXa/who-models-the-models-that-model-models-an-exploration-of}.

\bibitem{hegselmann2023tabllm}
Stefan Hegselmann, Alejandro Buendia, Hunter Lang, Monica Agrawal, Xiaoyi
  Jiang, and David Sontag.
\newblock Tabllm: Few-shot classification of tabular data with large language
  models, 2023.

\bibitem{binz2022using}
Marcel Binz and Eric Schulz.
\newblock Using cognitive psychology to understand gpt-3.
\newblock {\em Proceedings of the National Academy of Sciences},
  120(6):e2218523120, 2023.

\bibitem{binz2023meta}
Marcel Binz, Ishita Dasgupta, Akshay Jagadish, Matthew Botvinick, Jane~X Wang,
  and Eric Schulz.
\newblock Meta-learned models of cognition.
\newblock {\em arXiv preprint arXiv:2304.06729}, 2023.

\bibitem{ortega2019metalearning}
Pedro~A. Ortega, Jane~X. Wang, Mark Rowland, Tim Genewein, Zeb Kurth-Nelson,
  Razvan Pascanu, Nicolas Heess, Joel Veness, Alex Pritzel, Pablo Sprechmann,
  Siddhant~M. Jayakumar, Tom McGrath, Kevin Miller, Mohammad Azar, Ian Osband,
  Neil Rabinowitz, András György, Silvia Chiappa, Simon Osindero, Yee~Whye
  Teh, Hado van Hasselt, Nando de~Freitas, Matthew Botvinick, and Shane Legg.
\newblock Meta-learning of sequential strategies, 2019.

\bibitem{hochreiter2001learning}
Sepp Hochreiter, A~Steven Younger, and Peter~R Conwell.
\newblock Learning to learn using gradient descent.
\newblock In {\em International Conference on Artificial Neural Networks},
  pages 87--94. Springer, 2001.

\bibitem{wang2016learning}
Jane~X Wang, Zeb Kurth-Nelson, Dhruva Tirumala, Hubert Soyer, Joel~Z Leibo,
  Remi Munos, Charles Blundell, Dharshan Kumaran, and Matt Botvinick.
\newblock Learning to reinforcement learn.
\newblock {\em arXiv preprint arXiv:1611.05763}, 2016.

\bibitem{duan2016rl}
Yan Duan, John Schulman, Xi~Chen, Peter~L Bartlett, Ilya Sutskever, and Pieter
  Abbeel.
\newblock Rl $^2$: Fast reinforcement learning via slow reinforcement learning.
\newblock {\em arXiv preprint arXiv:1611.02779}, 2016.

\bibitem{santoro2016meta}
Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy
  Lillicrap.
\newblock Meta-learning with memory-augmented neural networks.
\newblock In {\em International conference on machine learning}, pages
  1842--1850. PMLR, 2016.

\bibitem{vonoswald2022transformers}
Johannes von Oswald, Eyvind Niklasson, Ettore Randazzo, João Sacramento,
  Alexander Mordvintsev, Andrey Zhmoginov, and Max Vladymyrov.
\newblock Transformers learn in-context by gradient descent, 2022.

\bibitem{garg2023transformers}
Shivam Garg, Dimitris Tsipras, Percy Liang, and Gregory Valiant.
\newblock What can transformers learn in-context? a case study of simple
  function classes, 2023.

\bibitem{akyurek2022learning}
Ekin Aky{\"u}rek, Dale Schuurmans, Jacob Andreas, Tengyu Ma, and Denny Zhou.
\newblock What learning algorithm is in-context learning? investigations with
  linear models.
\newblock {\em arXiv preprint arXiv:2211.15661}, 2022.

\bibitem{lampinen2023language}
Andrew~Kyle Lampinen.
\newblock Can language models handle recursively nested grammatical structures?
  a case study on comparing models and humans.
\newblock {\em arXiv preprint arXiv:2210.15303}, 2022.

\bibitem{dasgupta2022language}
Ishita Dasgupta, Andrew~K Lampinen, Stephanie~CY Chan, Antonia Creswell,
  Dharshan Kumaran, James~L McClelland, and Felix Hill.
\newblock Language models show human-like content effects on reasoning.
\newblock {\em arXiv preprint arXiv:2207.07051}, 2022.

\bibitem{coda2023inducing}
Julian Coda-Forno, Kristin Witte, Akshay~K Jagadish, Marcel Binz, Zeynep Akata,
  and Eric Schulz.
\newblock Inducing anxiety in large language models increases exploration and
  bias.
\newblock {\em arXiv preprint arXiv:2304.11111}, 2023.

\bibitem{hagendorff2023machine}
Thilo Hagendorff.
\newblock Machine psychology: Investigating emergent capabilities and behavior
  in large language models using psychological methods.
\newblock {\em arXiv preprint arXiv:2303.13988}, 2023.

\bibitem{openaiAPI}
Openai api.
\newblock \url{https://platform.openai.com}.
\newblock Accessed: 2023-05-10.

\bibitem{gershman2018deconstructing}
Samuel~J Gershman.
\newblock Deconstructing the human algorithms for exploration.
\newblock {\em Cognition}, 173:34--42, 2018.

\bibitem{binz2022modeling}
Marcel Binz and Eric Schulz.
\newblock Modeling human exploration through resource-rational reinforcement
  learning.
\newblock In {\em Advances in Neural Information Processing Systems}, 2022.

\bibitem{Lichtenberg2017SimpleRM}
Jan~Malte Lichtenberg and {\"O}zg{\"u}r Simsek.
\newblock Simple regression models.
\newblock In {\em IDM@NIPS}, 2017.

\end{thebibliography}
