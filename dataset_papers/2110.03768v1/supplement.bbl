\begin{thebibliography}{21}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[{Jordan} et~al.(1998){Jordan}, {Kinderlehrer}, and
  {Otto}]{jordan1998the}
Richard {Jordan}, David {Kinderlehrer}, and Felix {Otto}.
\newblock The variational formulation of the {F}okker-{P}lanck equation.
\newblock \emph{SIAM Journal on Mathematical Analysis}, 29\penalty0
  (1):\penalty0 1--17, 1998.

\bibitem[{Stein}(1972)]{stein1972a}
Charles {Stein}.
\newblock A bound for the error in the normal approximation to the distribution
  of a sum of dependent random variables.
\newblock \emph{Proceedings of the Sixth Berkeley Symposium on Mathematical
  Statistics and Probability, Volume 2: Probability Theory}, 1972.

\bibitem[{Gorham} et~al.(2019){Gorham}, {Duncan}, {Vollmer}, and
  {Mackey}]{gorham2019measuring}
Jackson {Gorham}, Andrew~B. {Duncan}, Sebastian~J. {Vollmer}, and Lester
  {Mackey}.
\newblock Measuring sample quality with diffusions.
\newblock \emph{Annals of Applied Probability}, 29\penalty0 (5):\penalty0
  2884--2928, 2019.

\bibitem[{Liu} and {Wang}(2016)]{liu2016stein}
Qiang {Liu} and Dilin {Wang}.
\newblock Stein variational gradient descent: A general purpose {B}ayesian
  inference algorithm.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~29, pages 2378--2386, 2016.

\bibitem[{Gallego} and {Insua}(2018)]{gallego2018stochastic}
Víctor {Gallego} and David~Ríos {Insua}.
\newblock Stochastic gradient {MCMC} with repulsive forces.
\newblock \emph{arXiv preprint arXiv:1812.00071}, 2018.

\bibitem[{Zhang} et~al.(2020){Zhang}, {Zhang}, {Carin}, and
  {Chen}]{zhang2020stochastic}
Jianyi {Zhang}, Ruiyi {Zhang}, Lawrence {Carin}, and Changyou {Chen}.
\newblock Stochastic particle-optimization sampling and the non-asymptotic
  convergence theory.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 1877--1887, 2020.

\bibitem[{Liu} et~al.(2019{\natexlab{a}}){Liu}, {Zhuo}, {Cheng}, {Zhang}, and
  {Zhu}]{liu2019understanding}
Chang {Liu}, Jingwei {Zhuo}, Pengyu {Cheng}, Ruiyi {Zhang}, and Jun {Zhu}.
\newblock Understanding and accelerating particle-based variational inference.
\newblock In \emph{International Conference on Machine Learning}, pages
  4082--4092, 2019{\natexlab{a}}.

\bibitem[{Li} and {Turner}(2017)]{li2017gradient}
Yingzhen {Li} and Richard~E. {Turner}.
\newblock Gradient estimators for implicit models.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[{Benamou} and {Brenier}(2000)]{benamou2000a}
Jean-David {Benamou} and Yann {Brenier}.
\newblock A computational fluid mechanics solution to the {M}onge-{K}antorovich
  mass transfer problem.
\newblock \emph{Numerische Mathematik}, 84\penalty0 (3):\penalty0 375--393,
  2000.

\bibitem[{Girolami} and {Calderhead}(2011)]{girolami2011riemann}
Mark {Girolami} and Ben {Calderhead}.
\newblock Riemann manifold langevin and hamiltonian monte carlo methods.
\newblock \emph{Journal of The Royal Statistical Society Series B-statistical
  Methodology}, 73\penalty0 (2):\penalty0 123--214, 2011.

\bibitem[{Ma} et~al.(2019){Ma}, {Chatterji}, {Cheng}, {Flammarion}, {Bartlett},
  and {Jordan}]{ma2019is}
Yi-An {Ma}, Niladri~S. {Chatterji}, Xiang {Cheng}, Nicolas {Flammarion},
  Peter~L. {Bartlett}, and Michael~I. {Jordan}.
\newblock Is there an analog of {N}esterov acceleration for {MCMC}.
\newblock \emph{arXiv preprint arXiv:1902.00996}, 2019.

\bibitem[{Mou} et~al.(2021){Mou}, {Ma}, {Wainwright}, {Bartlett}, and
  {Jordan}]{mou2021high}
Wenlong {Mou}, Yi-An {Ma}, Martin~J. {Wainwright}, Peter~L. {Bartlett}, and
  Michael~I. {Jordan}.
\newblock High-order {L}angevin {D}iffusion yields an accelerated {MCMC}
  algorithm.
\newblock \emph{Journal of Machine Learning Research}, 22\penalty0
  (42):\penalty0 1--41, 2021.

\bibitem[{Ma} et~al.(2015){Ma}, {Chen}, and {Fox}]{ma2015a}
Yi-An {Ma}, Tianqi {Chen}, and Emily~B. {Fox}.
\newblock A complete recipe for stochastic gradient {MCMC}.
\newblock In \emph{NIPS'15 Proceedings of the 28th International Conference on
  Neural Information Processing Systems - Volume 2}, volume~28, pages
  2917--2925, 2015.

\bibitem[{Liu} and {Zhu}(2017)]{liu2017riemannian}
Chang {Liu} and Jun {Zhu}.
\newblock {R}iemannian {S}tein variational gradient descent for bayesian
  inference.
\newblock In \emph{AAAI}, pages 3627--3634, 2017.

\bibitem[{Chen} et~al.(2014){Chen}, {Fox}, and {Guestrin}]{chen2014stochastic}
Tianqi {Chen}, Emily {Fox}, and Carlos {Guestrin}.
\newblock Stochastic gradient {H}amiltonian {M}onte {C}arlo.
\newblock In \emph{International conference on machine learning}, pages
  1683--1691, 2014.

\bibitem[Bradbury et~al.(2018)Bradbury, Frostig, Hawkins, Johnson, Leary,
  Maclaurin, Necula, Paszke, Vander{P}las, Wanderman-{M}ilne, and
  Zhang]{jax2018github}
James Bradbury, Roy Frostig, Peter Hawkins, Matthew~James Johnson, Chris Leary,
  Dougal Maclaurin, George Necula, Adam Paszke, Jake Vander{P}las, Skye
  Wanderman-{M}ilne, and Qiao Zhang.
\newblock {JAX}: composable transformations of {P}ython+{N}um{P}y programs,
  2018.
\newblock URL \url{http://github.com/google/jax}.

\bibitem[{Welling} and {Teh}(2011)]{welling2011bayesian}
Max {Welling} and Yee~W. {Teh}.
\newblock Bayesian learning via stochastic gradient {L}angevin dynamics.
\newblock In \emph{Proceedings of the 28th International Conference on Machine
  Learning}, pages 681--688, 2011.

\bibitem[{Chen} et~al.(2018){Chen}, {Zhang}, {Wang}, {Li}, and
  {Chen}]{chen2018a}
Changyou {Chen}, Ruiyi {Zhang}, Wenlin {Wang}, Bai {Li}, and Liqun {Chen}.
\newblock A unified particle-optimization framework for scalable {B}ayesian
  sampling.
\newblock In \emph{UAI}, pages 746--755, 2018.

\bibitem[{Lakshminarayanan} et~al.(2017){Lakshminarayanan}, {Pritzel}, and
  {Blundell}]{lakshminarayanan2017simple}
Balaji {Lakshminarayanan}, Alexander {Pritzel}, and Charles {Blundell}.
\newblock Simple and scalable predictive uncertainty estimation using deep
  ensembles.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~30, pages 6402--6413, 2017.

\bibitem[{Liu} et~al.(2019{\natexlab{b}}){Liu}, {Zhuo}, and {Zhu}]{liu2019mcmc}
Chang {Liu}, Jingwei {Zhuo}, and Jun {Zhu}.
\newblock Understanding {MCMC} dynamics as flows on the {W}asserstein space.
\newblock In \emph{International Conference on Machine Learning}, pages
  4093--4103, 2019{\natexlab{b}}.

\bibitem[{Ding} et~al.(2014){Ding}, {Fang}, {Babbush}, {Chen}, {Skeel}, and
  {Neven}]{ding2014bayesian}
Nan {Ding}, Youhan {Fang}, Ryan {Babbush}, Changyou {Chen}, Robert~D {Skeel},
  and Hartmut {Neven}.
\newblock Bayesian sampling using stochastic gradient thermostats.
\newblock In \emph{Advances in Neural Information Processing Systems 27},
  volume~27, pages 3203--3211, 2014.

\end{thebibliography}
