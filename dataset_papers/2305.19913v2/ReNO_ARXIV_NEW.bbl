\begin{thebibliography}{10}

\bibitem{alberti2022continuous}
G.~S. Alberti, M.~Santacesaria, and S.~Sciutto.
\newblock Continuous generative neural networks.
\newblock {\em arXiv preprint arXiv:2205.14627}, 2022.

\bibitem{benedetto1992irregular}
J.~J. Benedetto.
\newblock Irregular sampling and frames.
\newblock {\em Wavelets: A Tutorial in Theory and Applications}, 2:445--507, 1992.

\bibitem{Imgbook}
M.~Bertero, P.~Bocacci, and C.~De~Mol.
\newblock {\em Introduction to inverse problems in imaging}.
\newblock CRC press, 2021.

\bibitem{pcanet}
K.~Bhattacharya, B.~Hosseini, N.~B. Kovachki, and A.~M. Stuart.
\newblock Model {Reduction} {And} {Neural} {Networks} {For} {Parametric} {PDEs}.
\newblock {\em The SMAI journal of computational mathematics}, 7:121--157, 2021.

\bibitem{cao1}
S.~Cao.
\newblock Choose a transformer: {F}ourier or galerkin.
\newblock In {\em 35th conference on neural information processing systems}, 2021.

\bibitem{chenchen}
T.~Chen and H.~Chen.
\newblock Universal approximation to nonlinear operators by neural networks with arbitrary activation functions and its application to dynamical systems.
\newblock {\em IEEE Transactions on Neural Networks}, 6(4):911--917, 1995.

\bibitem{christensen2008frames}
O.~Christensen.
\newblock {\em Frames and bases: An introductory course}.
\newblock Springer Science \& Business Media, 2008.

\bibitem{chebfun}
T.~A. Driscoll, N.~Hale, and L.~N. Trefethen.
\newblock {\em Chebfun Guide}.
\newblock Pafnuty Publishers, Oxford, 2014.

\bibitem{Evansbook}
L.~C. Evans.
\newblock {\em Partial differential equations}, volume~19.
\newblock American Mathematical Soc., 2010.

\bibitem{fanaskov2022spectral}
V.~Fanaskov and I.~Oseledets.
\newblock Spectral neural operators.
\newblock {\em arXiv preprint arXiv:2205.10573}, 2022.

\bibitem{gruver2023the}
N.~Gruver, M.~A. Finzi, M.~Goldblum, and A.~G. Wilson.
\newblock The lie derivative for measuring learned equivariance.
\newblock In {\em The Eleventh International Conference on Learning Representations}, 2023.

\bibitem{Invbook}
V.~Isakov.
\newblock {\em Inverse Problems for Partial Differential Equations}.
\newblock Springer, 2017.

\bibitem{loca}
G.~Kissas, J.~H. Seidman, L.~F. Guilhoto, V.~M. Preciado, G.~J. Pappas, and P.~Perdikaris.
\newblock Learning operators with coupled attention.
\newblock {\em Journal of Machine Learning Research}, 23(215):1--63, 2022.

\bibitem{KLM1}
N.~Kovachki, S.~Lanthaler, and S.~Mishra.
\newblock On universal approximation and error bounds for {F}ourier neural operators.
\newblock {\em Journal of Machine Learning Research}, 22:Art--No, 2021.

\bibitem{NO}
N.~B. Kovachki, Z.~Li, B.~Liu, K.~Azizzadenesheli, K.~Bhattacharya, A.~M. Stuart, and A.~Anandkumar.
\newblock Neural operator: Learning maps between function spaces.
\newblock {\em CoRR}, abs/2108.08481, 2021.

\bibitem{LMK1}
S.~Lanthaler, S.~Mishra, and G.~E. Karniadakis.
\newblock Error estimates for {D}eep{ON}ets: {A} deep learning framework in infinite dimensions.
\newblock {\em Transactions of Mathematics and Its Applications}, 6(1):tnac001, 2022.

\bibitem{FNO}
Z.~Li, N.~B. Kovachki, K.~Azizzadenesheli, B.~liu, K.~Bhattacharya, A.~Stuart, and A.~Anandkumar.
\newblock {F}ourier neural operator for parametric partial differential equations.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{GNO}
Z.~Li, N.~B. Kovachki, K.~Azizzadenesheli, B.~Liu, K.~Bhattacharya, A.~M. Stuart, and A.~Anandkumar.
\newblock Neural operator: Graph kernel network for partial differential equations.
\newblock {\em CoRR}, abs/2003.03485, 2020.

\bibitem{MPNO}
Z.~Li, N.~B. Kovachki, K.~Azizzadenesheli, B.~Liu, A.~M. Stuart, K.~Bhattacharya, and A.~Anandkumar.
\newblock Multipole graph neural operator for parametric partial differential equations.
\newblock In H.~Larochelle, M.~Ranzato, R.~Hadsell, M.~F. Balcan, and H.~Lin, editors, {\em Advances in Neural Information Processing Systems (NeurIPS)}, volume~33, pages 6755--6766. Curran Associates, Inc., 2020.

\bibitem{deeponets}
L.~Lu, P.~Jin, G.~Pang, Z.~Zhang, and G.~E. Karniadakis.
\newblock {Learning nonlinear operators via DeepONet based on the universal approximation theorem of operators}.
\newblock {\em Nature Machine Intelligence}, 3(3):218--229, 2021.

\bibitem{vidon}
M.~Prasthofer, T.~De~Ryck, and S.~Mishra.
\newblock Variable input deep operator networks.
\newblock {\em arXiv preprint arXiv:2205.11404}, 2022.

\bibitem{NAbook}
A.~Quarteroni and A.~Valli.
\newblock {\em Numerical approximation of Partial differential equations}, volume~23.
\newblock Springer, 1994.

\bibitem{CNO}
B.~Raonić, R.~Molinaro, T.~De~Ryck, T.~Rohner, F.~Bartolucci, R.~Alaifari, S.~Mishra, and E.~de~Bézenac.
\newblock Convolutional neural operators for robust and accurate learning of {P}{D}{E}s.
\newblock {\em To appear in 37th conference on neural information processing systems, https://arxiv.org/abs/2302.01178}, 2023.

\bibitem{nomad}
J.~H. Seidman, G.~Kissas, P.~Perdikaris, and G.~J. Pappas.
\newblock {NOMAD}: {N}onlinear manifold decoders for operator learning.
\newblock {\em arXiv preprint arXiv:2206.03551}, 2022.

\bibitem{unser2000sampling}
M.~Unser.
\newblock Sampling-50 years after {S}hannon.
\newblock {\em Proceedings of the IEEE}, 88(4):569--587, 2000.

\bibitem{AHAbook}
M.~Vetterli, J.~Kovacevic, and V.~Goyal.
\newblock {\em Foundations of Signal Processing}.
\newblock Cambridge University Press, 2014.

\end{thebibliography}
