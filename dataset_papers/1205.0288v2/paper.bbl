\begin{thebibliography}{}

\bibitem[Argyriou et~al., 2006]{argyriou2006dc}
Argyriou, A., Hauser, R., Micchelli, C., and Pontil, M. (2006).
\newblock {A {DC}-programming algorithm for kernel selection}.
\newblock In {\em Proceedings of the 23rd International Conference on Machine
  Learning}, pages 41--48.

\bibitem[Argyriou et~al., 2005]{argyriou2005learning}
Argyriou, A., Micchelli, C., and Pontil, M. (2005).
\newblock Learning convex combinations of continuously parameterized basic
  kernels.
\newblock In {\em Proceedings of the 18th Annual Conference on Learning
  Theory}, pages 338--352.

\bibitem[Aronszajn, 1950]{Aro50}
Aronszajn, N. (1950).
\newblock Theory of reproducing kernels.
\newblock {\em Transactions of the American Mathematical Society},
  68(3):337--404.

\bibitem[Bach, 2008]{bach2008exploring}
Bach, F. (2008).
\newblock Exploring large feature spaces with hierarchical multiple kernel
  learning.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~21, pages 105--112.

\bibitem[Beck and Teboulle, 2003]{beck2003mirror}
Beck, A. and Teboulle, M. (2003).
\newblock Mirror descent and nonlinear projected subgradient methods for convex
  optimization.
\newblock {\em Operations Research Letters}, 31(3):167--175.

\bibitem[Boyd and Vandenberghe, 2004]{boyd2004convex}
Boyd, S. and Vandenberghe, L. (2004).
\newblock {\em Convex optimization}.
\newblock Cambridge University Press.

\bibitem[Brown and Page, 1970]{BrPa70}
Brown, A. and Page, A. (1970).
\newblock {\em Elements of Functional Analysis}.
\newblock Van Nostrand Reinhold Company, Windsor House, 46 Victoria Street,
  London S .W.1, England.

\bibitem[Cesa-Bianchi and Lugosi, 2006]{CBLu06:book}
Cesa-Bianchi, N. and Lugosi, G. (2006).
\newblock {\em Prediction, Learning, and Games}.
\newblock Cambridge University Press, New York, NY, USA.

\bibitem[Cortes et~al., 2009]{cortes2009learning}
Cortes, C., Mohri, M., and Rostamizadeh, A. (2009).
\newblock Learning non-linear combinations of kernels.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~22, pages 396--404.

\bibitem[Frank and Asuncion, 2010]{frank2010uci}
Frank, A. and Asuncion, A. (2010).
\newblock {UCI} machine learning repository.

\bibitem[Gehler and Nowozin, 2008]{gehler2008infinite}
Gehler, P. and Nowozin, S. (2008).
\newblock Infinite kernel learning.
\newblock Technical Report 178, Max Planck Institute For Biological
  Cybernetics.

\bibitem[G\"{o}nen and Alpayd{\i}n, 2011]{gonen2011multiple}
G\"{o}nen, M. and Alpayd{\i}n, E. (2011).
\newblock Multiple kernel learning algorithms.
\newblock {\em Journal of Machine Learning Research}, 12:2211--2268.

\bibitem[Hastie et~al., 2009]{HaTiFri09}
Hastie, T., Tibshirani, R., and Friedman, J. (2009).
\newblock {\em The Elements of Statistical Learning: Data Mining, Inference,
  Prediction}.
\newblock Springer, 2nd edition.

\bibitem[Hazan et~al., 2007]{HaAgKa07}
Hazan, E., Agarwal, A., and Kale, S. (2007).
\newblock Logarithmic regret algorithms for online convex optimization.
\newblock {\em Machine Learning Journal}, 69(2-3):169--192.

\bibitem[Hazan and Kale, 2011]{HaKa11}
Hazan, E. and Kale, S. (2011).
\newblock Beyond the regret minimization barrier: an optimal algorithm for
  stochastic strongly-convex optimization.
\newblock In {\em Proceedings of the 24th Annual Conference on Learning
  Theory}, volume~19 of {\em JMLR Workshop and Conference Proceedings}, pages
  421--436.

\bibitem[Kloft et~al., 2011]{kloft2011lp}
Kloft, M., Brefeld, U., Sonnenburg, S., and Zien, A. (2011).
\newblock $l_p$-norm multiple kernel learning.
\newblock {\em Journal of Machine Learning Research}, 12:953--997.

\bibitem[Martinet, 1978]{Mar78}
Martinet, B. (1978).
\newblock Perturbation des m\'ethodes d'optimisation. {A}pplications.
\newblock {\em RAIRO Analyse Num\'erique}, 12:153--171.

\bibitem[Micchelli and Pontil, 2005]{MiPo05}
Micchelli, C. and Pontil, M. (2005).
\newblock Learning the kernel function via regularization.
\newblock {\em Journal of Machine Learning Research}, 6:1099--1125.

\bibitem[Nath et~al., 2009]{NaDiRa09}
Nath, J., Dinesh, G., Raman, S., Bhattacharyya, C., Ben-Tal, A., and
  Ramakrishnan, K. (2009).
\newblock On the algorithmics and applications of a mixed-norm based kernel
  learning formulation.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~22, pages 844--852.

\bibitem[Nemirovski et~al., 2009a]{NeJuLaSh09}
Nemirovski, A., Juditsky, A., Lan, G., and Shapiro, A. (2009a).
\newblock Robust stochastic approximation approach to stochastic programming.
\newblock {\em {SIAM} J. Optimization}, 4:1574--1609.

\bibitem[Nemirovski et~al., 2009b]{nemirovski2009robust}
Nemirovski, A., Juditsky, A., Lan, G., and Shapiro, A. (2009b).
\newblock Robust stochastic approximation approach to stochastic programming.
\newblock {\em SIAM Journal on Optimization}, 19(4):1574--1609.

\bibitem[Nemirovski and Yudin, 1998]{NY83}
Nemirovski, A. and Yudin, D. (1998).
\newblock {\em Problem Complexity and Method Efficiency in Optimization}.
\newblock Wiley.

\bibitem[Nesterov, 2010]{Nes10}
Nesterov, Y. (2010).
\newblock Efficiency of coordinate descent methods on huge-scale optimization
  problems.
\newblock {\em CORE Discussion paper}, (2010/2).

\bibitem[Nesterov, 2012]{Nes12}
Nesterov, Y. (2012).
\newblock Subgradient methods for huge-scale optimization problems.
\newblock {\em CORE Discussion paper}, (2012/2).

\bibitem[Orabona and Luo, 2011]{orabona11-sparseMKL}
Orabona, F. and Luo, J. (2011).
\newblock Ultra-fast optimization algorithm for sparse multi kernel learning.
\newblock In {\em Proceedings of the 28th International Conference on Machine
  Learning}, pages 249--256.

\bibitem[Rakotomamonjy et~al., 2008]{rakotomamonjy2008simplemkl}
Rakotomamonjy, A., Bach, F., Canu, S., and Grandvalet, Y. (2008).
\newblock Simple{MKL}.
\newblock {\em Journal of Machine Learning Research}, 9:2491--2521.

\bibitem[Richt{\'a}rik and Tak\'a\^c, 2011]{RichTa11}
Richt{\'a}rik, P. and Tak\'a\^c, M. (2011).
\newblock Iteration complexity of randomized block-coordinate descent methods
  for minimizing a composite function.
\newblock (revised July 4, 2011) submitted to Mathematical Programming.

\bibitem[Rockafellar, 1976]{Roc76}
Rockafellar, R. (1976).
\newblock Monotone operators and the proximal point algorithm.
\newblock {\em SIAM Journal on Control and Optimization}, 14(1):877--898.

\bibitem[Sch{\"o}lkopf and Smola, 2002]{scholkopf2002learning}
Sch{\"o}lkopf, B. and Smola, A. (2002).
\newblock {\em Learning with Kernels: Support Vector Machines, Regularization,
  Optimization, and Beyond}.
\newblock MIT Press, Cambridge, MA, USA.

\bibitem[Shalev-Shwartz and Tewari, 2011]{ShTe11}
Shalev-Shwartz, S. and Tewari, A. (2011).
\newblock Stochastic methods for $l_1$-regularized loss minimization.
\newblock {\em Journal of Machine Learning Research}, 12:1865--1892.

\bibitem[Shawe-Taylor and Cristianini, 2004]{shawe2004kernel}
Shawe-Taylor, J. and Cristianini, N. (2004).
\newblock {\em Kernel Methods for Pattern Analysis}.
\newblock Cambridge Univ Press.

\bibitem[Sonnenburg et~al., 2006]{sonnenburg2006large}
Sonnenburg, S., R{\"a}tsch, G., Sch{\"a}fer, C., and Sch{\"o}lkopf, B. (2006).
\newblock Large scale multiple kernel learning.
\newblock {\em The Journal of Machine Learning Research}, 7:1531--1565.

\bibitem[Xu et~al., 2008]{XuJiKiLyu08}
Xu, Z., Jin, R., King, I., and Lyu, M. (2008).
\newblock An extended level method for efficient multiple kernel learning.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~21, pages 1825--1832.

\bibitem[Xu et~al., 2010]{Xu10-MKLLasso}
Xu, Z., Jin, R., Yang, H., King, I., and Lyu, M.~R. (2010).
\newblock Simple and efficient multiple kernel learning by group lasso.
\newblock In {\em Proceedings of the 27th International Conference on Machine
  Learning}, pages 1175--1182.

\end{thebibliography}
