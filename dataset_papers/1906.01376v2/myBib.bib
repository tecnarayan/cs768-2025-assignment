@inproceedings{Abdelrahman2016,
author = {Abdelrahman, Hany and Berkenkamp, Felix and Poland, Jan and Krause, Andreas},
booktitle = {2016 European Control Conference},
doi = {10.1109/ECC.2016.7810598},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abdelrahman et al. - 2016 - Bayesian optimization for maximum power point tracking in photovoltaic power plants.pdf:pdf},
isbn = {978-1-5090-2591-6},
keywords = {Machine learning,Power plants},
pages = {2078--2083},
title = {{Bayesian Optimization for Maximum Power Point Tracking in Photovoltaic Power Plants}},
url = {http://ieeexplore.ieee.org/document/7810598/},
year = {2016}
}
@book{Abramowitz1965,
address = {New York},
archivePrefix = {arXiv},
arxivId = {1701.01870},
author = {Abramowitz, Milton and Segun, Irene A.},
doi = {10.1115/1.3625776},
eprint = {1701.01870},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abramowitz, Segun - 1965 - Handbook of Methematical Funcions.pdf:pdf},
isbn = {0486612724},
issn = {00218936},
pmid = {20699170},
publisher = {Dover},
title = {{Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables}},
year = {1965}
}
@book{Adler2007,
author = {Adler, Robert and Taylor, Jonathan},
file = {:home/alederer/Local/Literatur/Books/Random Fields And Geometry.pdf:pdf},
isbn = {9780387481128},
publisher = {Springer Science {\&} Business Media},
title = {{Random Fields and Geometry}},
year = {2007}
}
@article{Afshani2009,
abstract = {We give the first optimal solution to a standard problem in computational geometry: three-dimensional halfspace range reporting. We show that n points in 3-d can be stored in a linear-space data structure so that all k points inside a query halfspace can be reported in O(log n + k) time. The data structure can be built in O(n log n) expected time. The previous methods with optimal query time required superlinear (O(n log log n)) space. We also mention consequences, for example, to higher dimensions and to external-memory data structures. As an aside, we partially answer another open question concerning the crossing number in Matou{\v{s}}ek's shallow partition theorem in the 3-d case (a tool used in many known halfspace range reporting methods). Copyright {\textcopyright} by SIAM.},
author = {Afshani, Peyman and Chan, Timothy M.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Afshani, Chan - 2009 - Optimal halfspace range reporting in three dimensions.pdf:pdf},
isbn = {9780898716801},
pages = {180--186},
title = {{Optimal halfspace range reporting in three dimensions}},
year = {2009}
}
@article{Aggarwal1990,
author = {Aggarwal, A and Hansen, M and Leighton, T},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aggarwal, Hansen, Leighton - 1990 - Solving query-retrieval problems by compacting Voronoi diagrams.pdf:pdf},
isbn = {0897913612},
journal = {Proc. 22nd Annu. ACM Sympos. Theory Comput.},
keywords = {Voronoi diagram,filtering search,probabilistic geometry,searching,separator},
pages = {331--340},
title = {{Solving query-retrieval problems by compacting Voronoi diagrams}},
year = {1990}
}
@article{Ahmad2015,
abstract = {Many conditions have been found for the absolute stability of discrete-time Lur'e systems in the literature. It is advantageous to find convex searches via LMIs where possible. In this note we construct two less conservative LMI conditions for discrete-time systems with slope-restricted nonlinearities. The first condition is derived via Lyapunov theory while the second is derived via the theory of integral quadratic constraints (IQCs) and noncausal Zames-Falb multipliers. Both conditions are related to the Jury-Lee criterion most appropriate for systems with such nonlinearities, and the second generalises it. Numerical examples demonstrate a significant reduction in conservatism over competing approaches.},
author = {Ahmad, N. Syazreen and Carrasco, J. and Heath, W. P.},
doi = {10.1109/TAC.2014.2361398},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ahmad, Carrasco, Heath - 2015 - A less conservative LMI condition for stability of discrete-time systems with slope-restricted nonlinear.pdf:pdf},
issn = {00189286},
journal = {IEEE Transactions on Automatic Control},
keywords = {Convex LMI,Lyapunov stability,discrete-time,multiplier theory},
number = {6},
pages = {1692--1697},
publisher = {IEEE},
title = {{A less conservative LMI condition for stability of discrete-time systems with slope-restricted nonlinearities}},
volume = {60},
year = {2015}
}
@inproceedings{Akametalu2014,
abstract = {Reinforcement learning for robotic applications faces the challenge of constraint satisfaction, which currently impedes its application to safety critical systems. Recent approaches successfully introduce safety based on reachability analysis, determining a safe region of the state space where the system can operate. However, overly constraining the freedom of the system can negatively affect performance, while attempting to learn less conservative safety constraints might fail to preserve safety if the learned constraints are inaccurate. We propose a novel method that uses a principled approach to learn the system's unknown dynamics based on a Gaussian process model and iteratively approximates the maximal safe set. A modified control strategy based on real-time model validation preserves safety under weaker conditions than current approaches. Our framework further incorporates safety into the reinforcement learning performance metric, allowing a better integration of safety and learning. We demonstrate our algorithm on simulations of a cart-pole system and on an experimental quadrotor application and show how our proposed scheme succeeds in preserving safety where current approaches fail to avoid an unsafe condition.},
author = {Akametalu, Anayo K. and Kaynama, Shahab and Fisac, Jaime F. and Zeilinger, Melanie N. and Gillula, Jeremy H. and Tomlin, Claire J.},
booktitle = {Proceedings of the IEEE Conference on Decision and Control},
doi = {10.1109/CDC.2014.7039601},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Akametalu et al. - 2014 - Reachability-based safe learning with Gaussian processes.pdf:pdf},
isbn = {978-1-4799-7746-8},
issn = {07431546},
pages = {1424--1431},
title = {{Reachability-based safe learning with Gaussian processes}},
year = {2014}
}
@article{Alamo2009,
author = {Alamo, Teodoro and Tempo, Roberto and Camacho, Eduardo F.},
doi = {10.1109/TAC.2009.2031207},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alamo, Tempo, Camacho - 2009 - Randomized strategies for probabilistic solutions of uncertain feasibility and optimization problems.pdf:pdf},
issn = {00189286},
journal = {IEEE Transactions on Automatic Control},
keywords = {Probabilistic robustness,Randomized algorithms,Statistical learning theory,Uncertain systems},
number = {11},
pages = {2545--2559},
title = {{Randomized strategies for probabilistic solutions of uncertain feasibility and optimization problems}},
volume = {54},
year = {2009}
}
@article{Alamo2015,
abstract = {In this paper, we study randomized methods for feedback design of uncertain systems. The first contribution is to derive the sample complexity of various constrained control problems. In particular, we show the key role played by the binomial distribution and related tail inequalities, and compute the sample complexity. This contribution significantly improves the existing results by reducing the number of required samples in the randomized algorithm. These results are then applied to the analysis of worst-case performance and design with robust optimization. The second contribution of the paper is to introduce a general class of sequential algorithms, denoted as Sequential Probabilistic Validation (SPV). In these sequential algorithms, at each iteration, a candidate solution is probabilistically validated, and corrected if necessary, to meet the required specifications. The results we derive provide the sample complexity which guarantees that the solutions obtained with SPV algorithms meet some pre-specified probabilistic accuracy and confidence. The performance of these algorithms is illustrated and compared with other existing methods using a numerical example dealing with robust system identification.},
archivePrefix = {arXiv},
arxivId = {1304.0678},
author = {Alamo, Teodoro and Tempo, Roberto and Luque, Amalia and Ramirez, Daniel R.},
doi = {10.1016/j.automatica.2014.11.004},
eprint = {1304.0678},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alamo et al. - 2015 - Randomized methods for design of uncertain systems Sample complexity and sequential algorithms.pdf:pdf},
isbn = {0005-1098},
issn = {00051098},
journal = {Automatica},
keywords = {Randomized and probabilistic algorithms,Sample complexity,Uncertain systems},
pages = {160--172},
publisher = {Elsevier Ltd},
title = {{Randomized methods for design of uncertain systems: Sample complexity and sequential algorithms}},
volume = {52},
year = {2015}
}
@article{Alefeld2000,
abstract = {We give an overview on applications of interval arithmetic. Among others we discuss veri{\"{y}}cation methods for linear systems of equations, nonlinear systems, the algebraic eigenvalue problem, initial value problems for ODEs and boundary value problems for elliptic PDEs of second order. We also consider the item software in this {\"{y}}eld and give some historical remarks.},
author = {Alefeld, Goetz and Mayer, Guenter},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alefeld, Mayer - 2000 - Interval analysis theory and applications.pdf:pdf},
journal = {Journal of Computational and Applied Mathematics},
pages = {421--464},
title = {{Interval analysis: theory and applications}},
volume = {121},
year = {2000}
}
@incollection{Alessio2009,
abstract = {Explicit model predictive control (MPC) addresses the problem of removing one of the main drawbacks of MPC, namely the need to solve a mathematical program on line to compute the control action. This computation prevents the application of MPC in several contexts, either because the computer technology needed to solve the optimization problem within the sampling time is too expensive or simply infeasible, or because the computer code implementing the numerical solver causes software certification concerns,especially in safety critical applications. Explicit MPC allows one to solve the optimization problem off-line for a given range of operating conditions of interest. By exploiting multiparametric programming techniques, explicit MPC computes the optimal control action off line as an explicit function of the state and reference vectors, so that on-line operations reduce to a simple function evaluation. Such a function is piecewise affine in most cases, so that the MPC controller maps into a lookup table of linear gains. In this paper we survey the main contributions on explicit MPC appeared in the scientific literature. After recalling the basic concepts and problem formulations of MPC, we review the main approaches to solve explicit MPC problems, including a novel and simple suboptimal practical approach to reduce the complexity of the explicit form. The paper concludes with some comments on future research directions.},
author = {Alessio, Alessandro and Bemporad, Alberto},
booktitle = {Nonlinear Model Predictive Control: Towards New Challenging Applications},
editor = {Magni, Lalo and Raimondo, Davide Martino and Allg{\"{o}}wer, Frank},
file = {:home/alederer/Documents/Literatur/Learning Based MPC/else mpc/A Survey on Explicit Model Predictive Control.pdf:pdf},
keywords = {Explicit solutions,Hybrid systems,Min-max control,Model predictive control,Multiparametric programming,Piecewise affine controllers},
pages = {345--369},
publisher = {Springer Berlin Heidelberg},
title = {{A survey on explicit model predictive control}},
year = {2009}
}
@article{Alpcan2015,
abstract = {Dual control aims to concurrently learn and control an unknown system. However, actively learning the system conflicts directly with any given control objective for it will disturb the system during exploration. This paper presents a receding horizon approach to dual control, where a multiobjective optimization problem is solved repeatedly and subject to constraints representing system dynamics. Balancing a standard finite-horizon control objective, a knowledge gain objective is defined to explicitly quantify the information acquired when learning the system dynamics. Measures from information theory, such as entropy-based uncertainty, Fisher information, and relative entropy, are studied and used to quantify the knowledge gained as a result of the control actions. The resulting iterative framework is applied to Markov decision processes and discrete-time nonlinear systems. Thus, the broad applicability and usefulness of the presented approach is demonstrated in diverse problem settings. The framework is illustrated with multiple numerical examples.},
author = {Alpcan, Tansu and Shames, Iman},
doi = {10.1109/TNNLS.2015.2392122},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alpcan, Shames - 2015 - An Information-Based Learning Approach to Dual Control.pdf:pdf},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Active learning,black-box systems,dual control,information theory,nonlinear systems},
number = {11},
pages = {2736--2748},
pmid = {25730828},
title = {{An Information-Based Learning Approach to Dual Control}},
volume = {26},
year = {2015}
}
@inproceedings{Alpcan2013,
author = {Alpcan, Tansu and Shames, Iman and Cantoni, Michael and Nair, Girish},
booktitle = {2013 9th Asian Control Conference (ASCC)},
doi = {10.1109/ASCC.2013.6606212},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Alpcan et al. - 2013 - Learning and information for dual control.pdf:pdf},
isbn = {978-1-4673-5769-2},
pages = {1--6},
title = {{Learning and information for dual control}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6606212},
year = {2013}
}
@article{Anghel2013,
abstract = {We present a methodology for the algorithmic construction of Lyapunov functions for the transient stability analysis of classical power system models. The proposed methodology uses recent advances in the theory of positive polynomials, semidefinite programming, and sum of squares decomposition, which have been powerful tools for the analysis of systems with polynomial vector fields. In order to apply these techniques to power grid systems described by trigonometric nonlinearities we use an algebraic reformulation technique to recast the system's dynamics into a set of polynomial differential algebraic equations. We demonstrate the application of these techniques to the transient stability analysis of power systems by estimating the region of attraction of the stable operating point. An algorithm to compute the local stability Lyapunov function is described together with an optimization algorithm designed to improve this estimate.},
author = {Anghel, Marian and Milano, Federico and Papachristodoulou, Antonis},
doi = {10.1109/TCSI.2013.2246233},
file = {:home/alederer/Local/Literatur/sampling based Stability analysis/Algorithmic Construction of Lyapunov Functions for Power System Stability Analysis.pdf:pdf},
issn = {15498328},
journal = {IEEE Transactions on Circuits and Systems I: Regular Papers},
keywords = {Lyapunov methods,nonlinear systems,power system transient stability,sum of squares,transient energy function},
number = {9},
pages = {2533--2546},
publisher = {IEEE},
title = {{Algorithmic construction of lyapunov functions for power system stability analysis}},
volume = {60},
year = {2013}
}
@article{Anghel2013,
abstract = {We present a methodology for the algorithmic construction of Lyapunov functions for the transient stability analysis of classical power system models. The proposed methodology uses recent advances in the theory of positive polynomials, semidefinite programming, and sum of squares decomposition, which have been powerful tools for the analysis of systems with polynomial vector fields. In order to apply these techniques to power grid systems described by trigonometric nonlinearities we use an algebraic reformulation technique to recast the system's dynamics into a set of polynomial differential algebraic equations. We demonstrate the application of these techniques to the transient stability analysis of power systems by estimating the region of attraction of the stable operating point. An algorithm to compute the local stability Lyapunov function is described together with an optimization algorithm designed to improve this estimate.},
author = {Anghel, Marian and Milano, Federico and Papachristodoulou, Antonis},
doi = {10.1109/TCSI.2013.2246233},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anghel, Milano, Papachristodoulou - 2013 - Algorithmic construction of lyapunov functions for power system stability analysis.pdf:pdf},
issn = {15498328},
journal = {IEEE Transactions on Circuits and Systems I: Regular Papers},
keywords = {Lyapunov methods,nonlinear systems,power system transient stability,sum of squares,transient energy function},
number = {9},
pages = {2533--2546},
publisher = {IEEE},
title = {{Algorithmic construction of lyapunov functions for power system stability analysis}},
volume = {60},
year = {2013}
}
@inproceedings{Anil2019,
abstract = {Training neural networks subject to a Lipschitz constraint is useful for generalization bounds, provable adversarial robustness, interpretable gradients, and Wasserstein distance estimation. By the composition property of Lipschitz functions, it suffices to ensure that each individual affine transformation or nonlinear activation function is 1-Lipschitz. The challenge is to do this while maintaining the expressive power. We identify a necessary property for such an architecture: each of the layers must preserve the gradient norm during backpropagation. Based on this, we propose to combine a gradient norm preserving activation function, GroupSort, with norm-constrained weight matrices. We show that norm-constrained GroupSort architectures are universal Lipschitz function approximators. Empirically, we show that norm-constrained GroupSort networks achieve tighter estimates of Wasserstein distance than their ReLU counterparts and can achieve provable adversarial robustness guarantees with little cost to accuracy.},
archivePrefix = {arXiv},
arxivId = {1811.05381},
author = {Anil, Cem and Lucas, James and Grosse, Roger},
booktitle = {International Conference on Machine Learning},
eprint = {1811.05381},
file = {:home/alederer/Documents/Literatur/Learning/Deep Learning/Sorting Out Lipschtiz Function Approximation.pdf:pdf},
pages = {1--11},
title = {{Sorting out Lipschitz function approximation}},
url = {http://arxiv.org/abs/1811.05381},
year = {2019}
}
@inproceedings{Ashton2012,
abstract = {We study the average case performance of multi-task Gaussian process (GP) regression as captured in the learning curve, i.e. the average Bayes error for a chosen task versus the total number of examples {\$}n{\$} for all tasks. For GP covariances that are the product of an input-dependent covariance function and a free-form inter-task covariance matrix, we show that accurate approximations for the learning curve can be obtained for an arbitrary number of tasks {\$}T{\$}. We use these to study the asymptotic learning behaviour for large {\$}n{\$}. Surprisingly, multi-task learning can be asymptotically essentially useless, in the sense that examples from other tasks help only when the degree of inter-task correlation, {\$}\backslashrho{\$}, is near its maximal value {\$}\backslashrho=1{\$}. This effect is most extreme for learning of smooth target functions as described by e.g. squared exponential kernels. We also demonstrate that when learning many tasks, the learning curves separate into an initial phase, where the Bayes error on each task is reduced down to a plateau value by "collective learning" even though most tasks have not seen examples, and a final decay that occurs once the number of examples is proportional to the number of tasks.},
author = {Ashton, Simon R. F. and Sollich, Peter},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ashton, Sollich - 2012 - Learning curves for multi-task Gaussian process regression(2).pdf:pdf},
pages = {1393--1428},
title = {{Learning Curves for Multi-task Gaussian Process Regression}},
year = {2012}
}
@inproceedings{Aswani2012,
abstract = {AbstractA new technique called learning-based model predictive control (LBMPC) rigorously combines statistics and learning with control engineering, while providing levels of guarantees about safety, robustness, and convergence. This paper describes modifications of LBMPC that enable its real- time implementation on an ultra-low-voltage processor that is onboard a quadrotor helicopter testbed, and it also discusses the numerical algorithms used to implement the control scheme on the quadrotor. Experimental results are provided that demonstrate the improvement to dynamic response that the learning in LBMPC provides, as well as the robustness of LBMPC to mis-learning.},
author = {Aswani, Anil and Bouffard, Patrick and Tomlin, Claire},
booktitle = {Proceedings of the American Control Conference},
doi = {10.1109/ACC.2012.6315483},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aswani, Bouffard, Tomlin - 2012 - Extensions of Learning-Based Model Predictive Control for Real-Time Application to a Quadrotor Helicop.pdf:pdf},
isbn = {9781457710964},
issn = {0743-1619},
pages = {4661--4666},
title = {{Extensions of Learning-Based Model Predictive Control for Real-Time Application to a Quadrotor Helicopter}},
year = {2012}
}
@article{Aswani2013,
abstract = {Controller design faces a trade-off between robustness and performance, and the reliability of linear controllers has caused many practitioners to focus on the former. However, there is renewed interest in improving system performance to deal with growing energy constraints. This paper describes a learning-based model predictive control (LBMPC) scheme that provides deterministic guarantees on robustness, while statistical identification tools are used to identify richer models of the system in order to improve performance; the benefits of this framework are that it handles state and input constraints, optimizes system performance with respect to a cost function, and can be designed to use a wide variety of parametric or nonparametric statistical tools. The main insight of LBMPC is that safety and performance can be decoupled under reasonable conditions in an optimization framework by maintaining two models of the system. The first is an approximate model with bounds on its uncertainty, and the second model is updated by statistical methods. LBMPC improves performance by choosing inputs that minimize a cost subject to the learned dynamics, and it ensures safety and robustness by checking whether these same inputs keep the approximate model stable when it is subject to uncertainty. Furthermore, we show that if the system is sufficiently excited, then the LBMPC control action probabilistically converges to that of an MPC computed using the true dynamics. {\textcopyright} 2013 Elsevier Ltd. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {1107.2487},
author = {Aswani, Anil and Gonzalez, Humberto and Sastry, S. Shankar and Tomlin, Claire},
doi = {10.1016/j.automatica.2013.02.003},
eprint = {1107.2487},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aswani et al. - 2013 - Provably safe and robust learning-based model predictive control(2).pdf:pdf},
isbn = {00051098},
issn = {00051098},
journal = {Automatica},
keywords = {Learning control,Predictive control,Robustness,Safety analysis,Statistics},
number = {5},
pages = {1216--1226},
title = {{Provably safe and robust learning-based model predictive control}},
volume = {49},
year = {2013}
}
@inproceedings{Axelrod2015,
author = {Axelrod, Allan M. and Kingravi, Hassan A. and Chowdhary, Girish V.},
booktitle = {Proceedings of the American Control Conference},
doi = {10.1109/ACC.2015.7171173},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Axelrod, Kingravi, Chowdhary - 2015 - Gaussian process based subsumption of a parasitic control component.pdf:pdf},
isbn = {9781479986842},
issn = {07431619},
pages = {2888--2893},
title = {{Gaussian process based subsumption of a parasitic control component}},
year = {2015}
}
@article{Aylward2008,
abstract = {A wide variety of stability and performance questions about linear dynamical systems can be reformulated as convex optimization problems involving linear matrix inequalities (LMIs). These techniques have been recently extended to nonlinear systems with polynomial or rational dynamics through the use of sum of squares (SOS) programming. In this paper we further extend the class of systems that can be analyzed with convexity-based methods. We show how to analyze the robust stability properties of uncertain nonlinear systems with polynomial or rational dynamics, via contraction analysis and SOS programming. Since the existence of a global contraction metric is a sufficient condition for global stability of an autonomous system, we develop an algorithm for finding such contraction metrics using SOS programming. The search process is made computationally tractable by relaxing matrix definiteness constraints, the feasibility of which indicates the existence of a contraction metric, to SOS constraints on polynomial matrices. We illustrate our results through examples from the literature and show how our contraction-based approach offers advantages when compared with traditional Lyapunov analysis. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {math/0603313},
author = {Aylward, Erin M. and Parrilo, Pablo A. and Slotine, J. J E},
doi = {10.1016/j.automatica.2007.12.012},
eprint = {0603313},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aylward, Parrilo, Slotine - 2008 - Stability and robustness analysis of nonlinear systems via contraction metrics and SOS programming.pdf:pdf},
isbn = {0005-1098},
issn = {00051098},
journal = {Automatica},
keywords = {Contraction analysis,Nonlinear systems,Robust stability,Sum of squares},
number = {8},
pages = {2163--2170},
primaryClass = {math},
title = {{Stability and robustness analysis of nonlinear systems via contraction metrics and SOS programming}},
volume = {44},
year = {2008}
}
@article{Baeyens2016,
abstract = {blackA direct search algorithm is proposed for minimizing an arbitrary real valued function. The algorithm uses a new function transformation and three simplex-based operations. The function transformation provides global exploration features, while the simplex-based operations guarantees the termination of the algorithm and provides global convergence to a stationary point if the cost function is differentiable and its gradient is Lipschitz continuous. The algorithm's performance has been extensively tested using benchmark functions and compared to some well-known global optimization algorithms. The results of the computational study show that the algorithm combines both simplicity and efficiency and is competitive with the heuristics-based strategies presently used for global optimization.},
author = {Baeyens, Enrique and Herreros, Alberto and Per{\'{a}}n, Jos{\'{e}} R.},
doi = {10.3390/a9020040},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baeyens, Herreros, Per{\'{a}}n - 2016 - A direct search algorithm for global optimization.pdf:pdf},
issn = {19994893},
journal = {Algorithms},
keywords = {Derivative-free optimization,Direct search methods,Global optimization,Heuristics-based optimization,Search space transformation},
number = {2},
pages = {1--22},
title = {{A direct search algorithm for global optimization}},
volume = {9},
year = {2016}
}
@inproceedings{Baheri2017,
abstract = {This paper presents a framework by which a data-driven optimization technique known as Bayesian Optimization can be used for real-time optimal control. In particular, Bayesian Optimization is applied to the real-time altitude optimization of an Airborne Wind Energy (AWE) system, for the purpose of maximizing net energy production. Determining the optimal operating altitude of an AWE system is challenging, as the wind speed constantly varies with both time and altitude. Furthermore, without expensive auxiliary equipment, the wind speed is only measurable at the AWE system's operating altitude. In this work, Gaussian Process modeling and Bayesian Optimization are used in real-time to optimize the AWE system's operating altitude efficiently, without the use of auxiliary wind profiling equipment. Specifically, the underlying objective function is modeled by a Gaussian Process (GP); then, Bayesian Optimization utilizes the predictive uncertainty information from the GP to determine the best subsequent operating altitude. In the AWE application, context-dependent Bayesian Optimization is used to handle the time-varying nature of the wind shear profile (wind speed vs. altitude). Using real wind data, our method is validated against three baseline approaches. Our simulation results show that the Bayesian Optimization method is successful in significantly increasing power production over these baselines. {\textcopyright} 2017 Elsevier Ltd},
author = {Baheri, Ali and Vermillion, Chris},
booktitle = {Control Engineering Practice},
doi = {10.1016/j.conengprac.2017.09.007},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baheri, Vermillion - 2017 - Real-Time Control Using Bayesian Optimization A Case Study in Airborne Wind Energy Systems.pdf:pdf},
issn = {09670661},
keywords = {Auxiliary equipment,Bayesian optimization,Data-driven optimization,Energy systems,Gaussian distribution,Gaussian noise (electronic),Gaussian process models,Optimal controls,Predictive uncertainty,Real time control,Real time optimal control,Real time systems,Wind,Wind energy systems,Wind power},
number = {1},
pages = {131--140},
title = {{Real-Time Control Using Bayesian Optimization: A Case Study in Airborne Wind Energy Systems}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030857220{\&}doi=10.1016/j.conengprac.2017.09.007{\&}partnerID=40{\&}md5=772cfa0c14a3556303c0a8f8a1200764},
volume = {69},
year = {2017}
}
@inproceedings{Baird1995,
abstract = {A number of reinforcement learning algorithms have been developed that are guaranteed to converge to the optimal solution when used with lookup tables. It is shown, however, that these algorithms can easily become unstable when implemented directly with a general function-approximation system, such as a sigmoidal multilayer perceptron, a radial-basisfunction system, a memory-based learning system, or even a linear function-approximation system. A new class of algorithms, residual gradient algorithms, is proposed, which perform gradient descent on the mean squared Bellman residual, guaranteeing convergence. It is shown, however, that they may learn very slowly in some cases. A larger class of algorithms, residual algorithms, is proposed that has the guaranteed convergence of the residual gradient algorithms, yet can retain the fast learning speed of direct algorithms. In fact, both direct and residual gradient algorithms are shown to be special cases of residual algorithms, and it is shown that residual algorithms can combine the advantages of each approach. The direct, residual gradient, and residual forms of value iteration, Qlearning, and advantage learning are all presented. Theoretical analysis is given explaining the properties these algorithms have, and simulation results are given that demonstrate these properties.},
author = {Baird, Leemon},
booktitle = {Proceedings of the Twelfth International Conference on Machine Learning},
doi = {10.1.1.48.3256},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baird - 1995 - Residual algorithms Reinforcement learning with function approximation.pdf:pdf},
issn = {00043702},
pages = {30--37},
title = {{Residual algorithms: Reinforcement learning with function approximation}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.140.2956{\&}rep=rep1{\&}type=pdf},
year = {1995}
}
@article{Bakx2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1507.05031v2},
author = {Bakx, R and Kleiss, R H P and Versteegen, F},
eprint = {arXiv:1507.05031v2},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bakx, Kleiss, Versteegen - 2016 - First- and Second-order Error Estimates in Monte Carlo Integration.pdf:pdf},
journal = {Computer Physics Communications},
pages = {29--34},
title = {{First- and Second-order Error Estimates in Monte Carlo Integration}},
volume = {208},
year = {2016}
}
@article{Baumeister2018,
abstract = {Self-tuning optical systems are of growing importance in technological applications such as mode-locked fiber lasers. Such self-tuning paradigms require {\{}$\backslash$em intelligent{\}} algorithms capable of inferring approximate models of the underlying physics and discovering appropriate control laws in order to maintain robust performance for a given objective. In this work, we demonstrate the first integration of a {\{}$\backslash$em deep learning{\}} (DL) architecture with {\{}$\backslash$em model predictive control{\}} (MPC) in order to self-tune a mode-locked fiber laser. Not only can our DL-MPC algorithmic architecture approximate the unknown fiber birefringence, it also builds a dynamical model of the laser and appropriate control law for maintaining robust, high-energy pulses despite a stochastically drifting birefringence. We demonstrate the effectiveness of this method on a fiber laser which is mode-locked by nonlinear polarization rotation. The method advocated can be broadly applied to a variety of optical systems that require robust controllers.},
archivePrefix = {arXiv},
arxivId = {1711.02702},
author = {Baumeister, Thomas and Brunton, Steven L. and Kutz, J. Nathan},
doi = {10.1364/JOSAB.35.000617},
eprint = {1711.02702},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baumeister, Brunton, Kutz - 2018 - Deep Learning and Model Predictive Control for Self-Tuning Mode-Locked Lasers.pdf:pdf},
journal = {Journal of the Optical Society of America B},
number = {3},
pages = {617--626},
title = {{Deep Learning and Model Predictive Control for Self-Tuning Mode-Locked Lasers}},
volume = {35},
year = {2018}
}
@article{Beatson2010,
abstract = {We present error bounds for the interpolation with anisotropically transformed radial basis functions for both a function and its partial derivatives. The bounds rely on a growth function and do not contain unknown constants. For polyharmonic basic functions in R2, we show that the anisotropic estimates predict a significant improvement of the approximation error if both the target function and the placement of the centers are anisotropic, and this improvement is confirmed numerically. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
author = {Beatson, Rick and Davydov, Oleg and Levesley, Jeremy},
doi = {10.1016/j.jat.2009.08.004},
file = {:home/alederer/Local/Literatur/Learning/learning theory/Error Bounds for Anisotropic RBF Interpolation.pdf:pdf},
issn = {00219045},
journal = {Journal of Approximation Theory},
keywords = {Anisotropic approximation,Radial basis functions},
number = {3},
pages = {512--527},
title = {{Error Bounds for Anisotropic RBF Interpolation}},
volume = {162},
year = {2010}
}
@inproceedings{Beckers2018,
author = {Beckers, T and Hirche, S},
booktitle = {Proceedings of the European Control Conference},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Beckers, Hirche - 2018 - Gaussian Process based Passivation of a Class of Nonlinear Systems with Unknown Dynamics.pdf:pdf},
title = {{Gaussian Process based Passivation of a Class of Nonlinear Systems with Unknown Dynamics}},
year = {2018}
}
@inproceedings{Beckers2017a,
author = {Beckers, T and Umlauft, J and Hirche, S},
booktitle = {Proceedings of the IFAC World Congress},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Beckers, Umlauft, Hirche - 2017 - Stable Model-based Control with Gaussian Process Regression for Robot Manipulators.pdf:pdf},
keywords = {adaptive system and control,data-based control,nonparametric methods,robotic manipulators,stability of nonlinear systems,stochastic control},
pages = {3877--3884},
title = {{Stable Model-based Control with Gaussian Process Regression for Robot Manipulators}},
year = {2017}
}
@inproceedings{Beckers2016,
author = {Beckers, Thomas and Hirche, Sandra},
booktitle = {Proceedings of the European Control Conference},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Beckers, Hirche - 2016 - Stability of Gaussian process state space models.pdf:pdf},
pages = {2275--2281},
title = {{Stability of Gaussian Process State Space Models}},
year = {2016}
}
@inproceedings{Beckers2016a,
abstract = {{\textcopyright} 2016 IEEE. Gaussian Process State Space Models (GP-SSM) are a data-driven stochastic model class suitable to represent nonlinear dynamics. They have become increasingly popular in non-parametric modeling approaches since they provide not only a prediction of the system behavior but also an accuracy of the prediction. For the application of these models, the analysis of fundamental system properties is required. In this paper, we analyze equilibrium distributions and stability properties of the GP-SSM. The computation of equilibrium distributions is based on the numerical solution of a Fredholm integral equation of the second kind and is suitable for any covariance function. Besides, we show that the GP-SSM with squared exponential covariance function is always mean square bounded and there exists a set which is positive recurrent.},
author = {Beckers, Thomas and Hirche, Sandra},
booktitle = {Proceedings of the IEEE Conference on Decision and Control},
file = {:home/alederer/Documents/Literatur/colleage papers/Equilibrium Distributions and Stability Analysis of Gaussian Process State Space Models.pdf:pdf},
pages = {6355--6361},
title = {{Equilibrium distributions and stability analysis of Gaussian Process State Space Models}},
year = {2016}
}
@article{Beckers2019,
abstract = {Perfect tracking control for real-world Euler–Lagrange systems is challenging due to uncertainties in the system model and external disturbances. The magnitude of the tracking error can be reduced either by increasing the feedback gains or improving the model of the system. The latter is clearly preferable as it allows to maintain good tracking performance at low feedback gains. However, accurate models are often difficult to obtain. In this article, we address the problem of stable high-performance tracking control for unknown Euler–Lagrange systems. In particular, we employ Gaussian Process regression to obtain a data-driven model that is used for the feed-forward compensation of unknown dynamics of the system. The model fidelity is used to adapt the feedback gains allowing low feedback gains in state space regions of high model confidence. The proposed control law guarantees a globally bounded tracking error with a specific probability. Simulation studies demonstrate the superiority over state of the art tracking control approaches.},
archivePrefix = {arXiv},
arxivId = {arXiv:1806.07190v2},
author = {Beckers, Thomas and Kuli{\'{c}}, Dana and Hirche, Sandra},
doi = {10.1016/j.automatica.2019.01.023},
eprint = {arXiv:1806.07190v2},
file = {:home/alederer/Documents/Literatur/colleage papers/Stable Gaussian Process based Tracking Control of Euler-Lagrange Systems.pdf:pdf},
issn = {00051098},
journal = {Automatica},
keywords = {Adaptive system and control,Data-based control,Nonparametric methods,Robotic manipulators,Stability of nonlinear systems,Stochastic control},
number = {23},
pages = {390--397},
title = {{Stable Gaussian Process based Tracking Control of Euler–Lagrange Systems}},
volume = {103},
year = {2019}
}
@inproceedings{Beckers2018a,
abstract = {Nonparametric modeling approaches show very promising results in the area of system identification and control. A naturally provided model confidence is highly relevant for system-theoretical considerations to provide guarantees for application scenarios. Gaussian process regression represents one approach which provides such an indicator for the model confidence. However, this measure is only valid if the covariance function and its hyperparameters fit the underlying data generating process. In this paper, we derive an upper bound for the mean square prediction error of misspecified Gaussian process models based on a pseudo-concave optimization problem. We present application scenarios and a simulation to compare the derived upper bound with the true mean square error.},
author = {Beckers, Thomas and Umlauft, Jonas and Hirche, Sandra},
booktitle = {Proceedings of the IEEE Conference on Decision and Control},
file = {:home/alederer/Documents/Literatur/colleage papers/Mean Square Prediction Error of Misspecified Gaussian Process Models.pdf:pdf},
isbn = {9781538613955},
issn = {07431546},
pages = {1162--1167},
title = {{Mean Square Prediction Error of Misspecified Gaussian Process Models}},
year = {2018}
}
@inproceedings{Beckers2017,
archivePrefix = {arXiv},
arxivId = {1806.},
author = {Beckers, Thomas and Umlauft, Jonas and Kuli{\'{c}}, Dana and Hirche, Sandra},
booktitle = {Proceedings of the IEEE Conference on Decision and Control},
eprint = {1806.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Beckers et al. - 2017 - Stable Gaussian Process based Tracking Control of Lagrangian Systems.pdf:pdf},
keywords = {Machine learning,Robust adaptive control,Stability},
pages = {5180--5185},
title = {{Stable Gaussian Process based Tracking Control of Lagrangian Systems}},
year = {2017}
}
@incollection{Bemporad1999,
author = {Bemporad, Alberto and Morari, Manfred},
booktitle = {Lecture Notes in Control and Information Sciences},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bemporad, Morari - 1999 - Robust Model Predictive Control A Survey.pdf:pdf},
pages = {207--226},
title = {{Robust Model Predictive Control: A Survey}},
year = {1999}
}
@techreport{Berkenkamp,
abstract = {Bud scar analysis integrated with mathematical analysis of DNA and protein distributions obtained by flow microfluorometry have been used to analyze the cell cycle of the budding yeast Saccharomyces cerevisiae. In populations of this yeast growing exponentially in batch at 30 degrees C on different carbon and nitrogen sources with duplication times between 75 and 314 min, the budded period is always shorter (approximately 5 to 10 min) than the sum of the S + G2 + M + G1* phases (determined by the Fried analysis of DNA distributions), and parent cells always show a prereplicative unbudded period. The analysis of protein distributions obtained by flow microfluorometry indicates that the protein level per cell required for bud emergence increases at each new generation of parent cells, as observed previously for cell volume. A wide heterogeneity of cell populations derives from this pattern of budding, since older (and less frequent) parent cells have shorter generation times and produce larger (and with shorter cycle times) daughter cells. A possible molecular mechanism for the observed increase with genealogical age of the critical protein level required for bud emergence is discussed.},
address = {Z{\"{u}}rich},
archivePrefix = {arXiv},
arxivId = {arXiv:1508.04886v1},
author = {Berkenkamp, Felix and Krause, Andreas and Schoellig, Angela P.},
eprint = {arXiv:1508.04886v1},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berkenkamp, Krause, Schoellig - 2016 - Bayesian Optimization with Safety Constraints Safe Automatic Parameter Tuning in Robotics.pdf:pdf},
institution = {ETH Z{\"{u}}rich},
keywords = {bayesian optimization,constrained policy search,quadrotors,robotics,safe reinforcement learning,unmanned},
title = {{Bayesian Optimization with Safety Constraints: Safe Automatic Parameter Tuning in Robotics}},
year = {2016}
}
@inproceedings{Berkenkamp2016a,
abstract = {Control theory can provide useful insights into the properties of controlled, dynamic systems. One important property of nonlinear systems is the region of attraction (ROA), a safe subset of the state space in which a given controller renders an equilibrium point asymptotically stable. The ROA is typically estimated based on a model of the system. However, since models are only an approximation of the real world, the resulting estimated safe region can contain states outside the ROA of the real system. This is not acceptable in safety-critical applications. In this paper, we consider an approach that learns the ROA from experiments on a real system, without ever leaving the true ROA and, thus, without risking safety-critical failures. Based on regularity assumptions on the model errors in terms of a Gaussian process prior, we use an underlying Lyapunov function in order to determine a region in which an equilibrium point is asymptotically stable with high probability. Moreover, we provide an algorithm to actively and safely explore the state space in order to expand the ROA estimate. We demonstrate the effectiveness of this method in simulation.},
author = {Berkenkamp, Felix and Moriconi, Riccardo and Schoellig, Angela P. and Krause, Andreas},
booktitle = {Proceedings of the IEEE Conference on Decision and Control},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berkenkamp et al. - 2016 - Safe learning of regions of attraction for uncertain, nonlinear systems with Gaussian processes.pdf:pdf},
pages = {4661--4666},
title = {{Safe Learning of Regions of Attraction for Uncertain, Nonlinear Systems with Gaussian Processes}},
year = {2016}
}
@inproceedings{Berkenkamp2017a,
author = {Berkenkamp, Felix and Schoellig, Angela P and Turchetta, Matteo and Krause, Andreas},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berkenkamp et al. - 2017 - Safe Model-based Reinforcement Learning with Stability Guarantees(2).pdf:pdf},
title = {{Safe Model-based Reinforcement Learning with Stability Guarantees}},
year = {2017}
}
@inproceedings{Berkenkamp2015,
abstract = {This paper introduces a learning-based robust control algorithm that provides robust stability and perfor- mance guarantees during learning. The approach uses Gaus- sian process (GP) regression based on data gathered during operation to update an initial model of the system and to gradually decrease the uncertainty related to this model. Em- bedding this data-based update scheme in a robust control framework guarantees stability during the learning process. Traditional robust control approaches have not considered online adaptation of the model and its uncertainty before. As a result, their controllers do not improve performance during operation. Typical machine learning algorithms that have achieved similar high-performance behavior by adapting the model and controller online do not provide the guarantees presented in this paper. In particular, this paper considers a stabilization task, linearizes the nonlinear, GP-based model around a desired operating point, and solves a convex optimiza- tion problem to obtain a linear robust controller. The resulting performance improvements due to the learning-based controller are demonstrated in experiments on a quadrotor vehicle.},
author = {Berkenkamp, Felix and Schoellig, Angela P.},
booktitle = {Proceedings of the European Control Conference},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berkenkamp, Schoellig - 2015 - Safe and robust learning control with Gaussian processes.pdf:pdf},
pages = {2496--2501},
title = {{Safe and Robust Learning Control with Gaussian Processes}},
year = {2015}
}
@inproceedings{Berkenkamp2016,
abstract = {One of the most fundamental problems when designing controllers for dynamic systems is the tuning of the controller parameters. Typically, a model of the system is used to obtain an initial controller, but ultimately the controller parameters must be tuned manually on the real system to achieve the best performance. To avoid this manual tuning step, methods from machine learning, such as Bayesian optimization, have been used. However, as these methods evaluate different controller parameters on the real system, safety-critical system failures may happen. In this paper, we overcome this problem by applying, for the first time, a recently developed safe optimization algorithm, SafeOpt, to the problem of automatic controller parameter tuning. Given an initial, low-performance controller, SafeOpt automatically optimizes the parameters of a control law while guaranteeing safety. It models the underlying performance measure as a Gaussian process and only explores new controller parameters whose performance lies above a safe performance threshold with high probability. Experimental results on a quadrotor vehicle indicate that the proposed method enables fast, automatic, and safe optimization of controller parameters without human intervention.},
author = {Berkenkamp, Felix and Schoellig, Angela P. and Krause, Andreas},
booktitle = {Proceedings of the IEEE International Conference on Robotics and Automation},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berkenkamp, Schoellig, Krause - 2016 - Safe controller optimization for quadrotors with Gaussian processes.pdf:pdf},
pages = {491--496},
title = {{Safe Controller Optimization for Quadrotors with Gaussian Processes}},
year = {2016}
}
@inproceedings{Berkenkamp2017,
abstract = {Reinforcement learning is a powerful paradigm for learning optimal policies from experimental data. However, to find optimal policies, most reinforcement learning algorithms explore all possible actions, which may be harmful for real-world systems. As a consequence, learning algorithms are rarely applied on safety-critical systems in the real world. In this paper, we present a learning algorithm that explicitly considers safety, defined in terms of stability guarantees. Specifically, we extend control-theoretic results on Lyapunov stability verification and show how to use statistical models of the dynamics to obtain high-performance control policies with provable stability certificates. Moreover, under additional regularity assumptions in terms of a Gaussian process prior, we prove that one can effectively and safely collect data in order to learn about the dynamics and thus both improve control performance and expand the safe region of the state space. In our experiments, we show how the resulting algorithm can safely optimize a neural network policy on a simulated inverted pendulum, without the pendulum ever falling down.},
author = {Berkenkamp, Felix and Turchetta, Matteo and Schoellig, Angela P. and Krause, Andreas},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berkenkamp et al. - 2017 - Safe Model-based Reinforcement Learning with Stability Guarantees.pdf:pdf},
pages = {908--918},
title = {{Safe Model-based Reinforcement Learning with Stability Guarantees}},
year = {2017}
}
@book{Berlinet2004,
author = {Berlinet, Alain and Thomas-Agnan, Christine},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Berlinet, Thomas-Agnan - 2004 - Reproducing Kernel Hilbert Spaces in Probability and Statistics.pdf:pdf},
isbn = {9781461347927},
publisher = {Springer US},
title = {{Reproducing Kernel Hilbert Spaces in Probability and Statistics}},
year = {2004}
}
@phdthesis{Bethke2010,
abstract = {Many sequential decision-making problems related to multi-agent robotic systems can be naturally posed as Markov Decision Processes (MDPs). An important advantage of the MDP framework is the ability to utilize stochastic system models, thereby allowing the system to make sound decisions even if there is randomness in the system evolution over time. Unfortunately, the curse of dimensionality prevents most MDPs of practical size from being solved exactly. One main focus of the thesis is on the development of a new family of algorithms for computing approximate solutions to large-scale MDPs. Our algorithms are similar in spirit to Bellman residual methods, which attempt to minimize the error incurred in solving Bellman's equation at a set of sample states. However, by exploiting kernel-based regression techniques (such as support vector regression and Gaussian process regression) with nondegenerate kernel functions as the underlying cost-to-go function approximation architecture, our algorithms are able to construct cost-to-go solutions for which the Bellman residuals are explicitly forced to zero at the sample states. For this reason, we have named our approach Bellman residual elimination (BRE). In addition to developing the basic ideas behind BRE, we present multi-stage and model-free extensions to the approach. The multi-stage extension allows for automatic selection of an appropriate kernel for the MDP at hand, while the model-free extension can use simulated or real state trajectory data to learn an approximate policy when a system model is unavailable. We present theoretical analysis of all BRE algorithms proving convergence to the optimal policy in the limit of sampling the entire state space, and show computational results on several benchmark problems. Another challenge in implementing control policies based on MDPs is that there may be parameters of the system model that are poorly known and/or vary with time as the system operates. System performance can suffer if the model used to compute the policy differs from the true model. To address this challenge, we develop an adaptive architecture that allows for online MDP model learning and simultaneous re-computation of the policy. As a result, the adaptive architecture allows the system to continuously re-tune its control policy to account for better model information obtained through observations of the actual system in operation, and react to changes in the model as they occur. Planning in complex, large-scale multi-agent robotic systems is another focus of the thesis. In particular, we investigate the persistent surveillance problem, in which one or more unmanned aerial vehicles (UAVs) and/or unmanned ground vehicles (UGVs) must provide sensor coverage over a designated location on a continuous basis. This continuous coverage must be maintained even in the event that agents suffer failures over the course of the mission. The persistent surveillance problem is pertinent to a number of applications, including search and rescue, natural disaster relief operations, urban traffic monitoring, etc. Using both simulations and actual flight experiments conducted in the MIT RAVEN indoor flight facility, we demonstrate the successful application of the BRE algorithms and the adaptive MDP architecture in achieving high mission performance despite the random occurrence of failures. Furthermore, we demonstrate performance benefits of our approach over a deterministic planning approach that does not account for these failures. (Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)},
author = {Bethke, Brett M},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bethke - 2010 - Kernel-based approximate dynamic programming using Bellman residual elimination.pdf:pdf},
isbn = {9781424474271},
keywords = {0538:Aerospace engineering,Aerospace engineering,Applied sciences,Approximate dynamic programming,Bellman residual elimination,Markov decision processes},
school = {Massachusetts Institute of Technology},
title = {{Kernel-based approximate dynamic programming using Bellman residual elimination}},
year = {2010}
}
@inproceedings{Bethke2009,
abstract = {This paper presents an approximate policy iteration algorithm for solving infinite-horizon, discounted Markov decision processes (MDPs) for which a model of the system is available. The algorithm is similar in spirit to Bellman residual minimization methods. However, by using Gaussian process regression with nondegenerate kernel functions as the underlying cost-to-go function approximation architecture, the algorithm is able to explicitly construct cost-to-go solutions for which the Bellman residuals are identically zero at a set of chosen sample states. For this reason, we have named our approach Bellman residual elimination (BRE). Since the Bellman residuals are zero at the sample states, our BRE algorithm can be proven to reduce to exact policy iteration in the limit of sampling the entire state space. Furthermore, the algorithm can automatically optimize the choice of any free kernel parameters and provide error bounds on the resulting cost-to-go solution. Computational results on a classic reinforcement learning problem indicate that the algorithm yields a high-quality policy and cost approximation.},
author = {Bethke, Brett and How, Jonathan P.},
booktitle = {2009 American Control Conference},
doi = {10.1109/ACC.2009.5160344},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bethke, How - 2009 - Approximate dynamic programming using Bellman residual elimination and Gaussian process regression.pdf:pdf},
isbn = {978-1-4244-4523-3},
issn = {0743-1619},
keywords = {Machine learning,Markov processes},
pages = {745--750},
title = {{Approximate dynamic programming using Bellman residual elimination and Gaussian process regression}},
year = {2009}
}
@inproceedings{Bethke2010a,
author = {Bethke, Brett and How, Jonathan P.},
booktitle = {2010 American Control Conference},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bethke, How - 2010 - Approximate dynamic programming using bellman model-free residual elimination.pdf:pdf},
isbn = {142444523X},
pages = {745--750},
title = {{Approximate dynamic programming using bellman model-free residual elimination}},
year = {2010}
}
@inproceedings{Binet2012,
author = {Binet, Giovanni and Krenn, Rainer and Bemporad, Alberto},
booktitle = {11th International Symposium on Artificial Intelligence, Robotics and Automation in Space},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Binet, Krenn, Bemporad - 2012 - Model predictive control applications for planetary rovers.pdf:pdf},
number = {1},
title = {{Model predictive control applications for planetary rovers}},
year = {2012}
}
@book{Bishop2006,
address = {New York, NY},
author = {Bishop, Christopher M.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bishop - 2006 - Pattern Recognition and Machine Learning.pdf:pdf},
publisher = {Springer Science+Business Media},
title = {{Pattern Recognition and Machine Learning}},
year = {2006}
}
@article{Bjorkman1999,
abstract = {We discuss the e and implementation details of an algorithm for the global minimum of a multi-variate function subject to simple bounds on the variables. The algorithm DIRECT, developed by D. R. Jones, C. D. Perttunen and B. E. Stuckman, is a modiication of the standard Lipschitzian approach that eliminates the need to specify a Lipschitz constant. We have implemented the DIRECT algorithm in Matlab and the eeciency of our implementation is analyzed by comparing it to the results of Jones's implementation on nine standard test problems for box-bounded global optimization. In out of eighteen runs the results are in favor of our implementation. We also present performance results for our implementation on the more challenging test set used in the contest on evolutionary optimization (ICEO). An application from computational is also discussed. Our DIRECT code is available in two v ersions. One, glbSolve, i s i n tegrated in the Matlab optimization environment T O M L A B , as part of the toolbox NLPLIB TB for nonlinear pro-gramming and parameter estimation. The other, gblSolve, is a stand-alone version. Both TOMLAB and gblSolve are free for academic use and downloadable at the home page of the Applied Optimization and Modeling group, see the URL: http://www.ima.mdh.se/tom.},
author = {Bjorkman, M. and Holmstrom, K.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bjorkman, Holmstrom - 1999 - Global Optimization Using the DIRECT Algorithm in Matlab.pdf:pdf},
journal = {Advanced Modeling and Optimization},
keywords = {Algorithms,DIRECT,Global optimization,Lipschitzian optimization,Optimization,Software Engineering,mathematical software,matlab},
number = {2},
pages = {17--37},
title = {{Global Optimization Using the DIRECT Algorithm in Matlab}},
volume = {1},
year = {1999}
}
@article{Bjornsson2014,
abstract = {— The numerical construction of Lyapunov functions provides useful information on system behavior. In the Contin-uous and Piecewise Affine (CPA) method, linear programming is used to compute a CPA Lyapunov function for continuous nonlinear systems. This method is relatively slow due to the linear program that has to be solved. A recent proposal was to compute the CPA Lyapunov function based on a Lyapunov function in a converse Lyapunov theorem by Yoshizawa. In this paper we propose computing CPA Lyapunov functions using a Lyapunov function construction in a classic converse Lyapunov theorem by Massera. We provide the theory for such a computation and present several examples to illustrate the utility of this approach.},
author = {Bjornsson, Johann and Giesl, Peter and Hafstein, Sigurdur and Kellett, Christopher M. and Li, Huijuan},
doi = {10.1109/CDC.2014.7040250},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bjornsson et al. - 2014 - Computation of continuous and piecewise affine Lyapunov functions by numerical approximations of the Massera c.pdf:pdf},
isbn = {9781467360883},
issn = {07431546},
journal = {Proceedings of the IEEE Conference on Decision and Control},
number = {February},
pages = {5506--5511},
title = {{Computation of continuous and piecewise affine Lyapunov functions by numerical approximations of the Massera construction}},
volume = {2015-Febru},
year = {2014}
}
@inproceedings{Blocher2017,
abstract = {This paper discusses the learning of robot point-to-point motions via non-linear dynamical systems and Gaussian Mixture Regression (GMR). The novelty of the proposed approach consists in guaranteeing the stability of a learned dynamical system via Contraction theory. A contraction analysis is performed to derive sufficient conditions for the global stability of a dynamical system represented by GMR. The results of this analysis are exploited to automatically compute a control input which stabilizes the learned system on-line. Simple and effective solutions are proposed to generate motion trajectories close to the demonstrated ones, without affecting the stability of the overall system. The proposed approach is evaluated on a public benchmark of point-to-point motions and compared with state-of-the-art algorithms based on Lyapunov stability theory.},
author = {Blocher, Caroline and Saveriano, Matteo and Lee, Dongheui},
booktitle = {Proceedings of the International Conference on Ubiquitous Robots and Ambient Intelligence},
doi = {10.1109/URAI.2017.7992901},
file = {:home/alederer/Documents/Literatur/Learning/Stable Systems/Learning Stable Dynamical Systems using Contraction Theory.pdf:pdf},
isbn = {9781509030552},
keywords = {Learning contracting systems. Stable discrete move},
pages = {124--129},
title = {{Learning stable dynamical systems using contraction theory}},
year = {2017}
}
@inproceedings{Blundell2015,
abstract = {We introduce a new, efficient, principled and backpropagation-compatible algorithm for learning a probability distribution on the weights of a neural network, called Bayes by Backprop. It regularises the weights by minimising a compression cost, known as the variational free energy or the expected lower bound on the marginal likelihood. We show that this principled kind of regularisation yields comparable performance to dropout on MNIST classification. We then demonstrate how the learnt uncertainty in the weights can be used to improve generalisation in non-linear regression problems, and how this weight uncertainty can be used to drive the exploration-exploitation trade-off in reinforcement learning.},
author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
booktitle = {Proceedings of the International Conference on Machine Learning},
file = {:home/alederer/Documents/Literatur/Learning/Deep Learning/Weight Uncertainty in Neural Networks.pdf:pdf},
pages = {1613--1622},
title = {{Weight Uncertainty in Neural Networks}},
year = {2015}
}
@article{Bobiti2018,
author = {Bobiti, Ruxandra and Lazar, Mircea},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bobiti, Lazar - 2018 - Automated-Sampling-Based Stability Verification and DOA Estimation for Nonlinear Systems.pdf:pdf},
journal = {IEEE Transactions on Automatic Control},
keywords = {Nonlinear systems,lyapunov methods,sampling methods,stability analysis},
number = {11},
pages = {3659--3674},
title = {{Automated-Sampling-Based Stability Verification and DOA Estimation for Nonlinear Systems}},
volume = {63},
year = {2018}
}
@article{Bobiti2017,
abstract = {This paper considers the problem of stability verification for discrete–time nonlinear systems via Lyapunov functions. Depending on the system dynamics, the candidate Lyapunov function and the set of initial states of interest, one generally needs to handle large, possibly non–convex or non– feasible optimization problems. To avoid such problems, we propose a constructive and systematically applicable sampling– based approach to stability analysis of nonlinear systems. This approach proposes verification of the decrease condition for a candidate Lyapunov function on a finite sampling of a bounded set of initial conditions and then it extends the validity of the Lyapunov function to an infinite set of initial conditions by exploiting continuity properties. This result involves no apriori analytic description of the continuity property and it is based on multi–resolution sampling, to perform efficient state–space exploration. Moreover, the stability verification is decentralized in the sampling points, which makes the method parallelizable. The proposed methodology is illustrated on two examples.},
author = {Bobiti, Ruxandra and Lazar, Mircea},
doi = {10.1109/ECC.2016.7810344},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bobiti, Lazar - 2017 - A sampling approach to finding Lyapunov functions for nonlinear discrete-time systems.pdf:pdf},
isbn = {9781509025916},
journal = {2016 European Control Conference, ECC 2016},
pages = {561--566},
pmid = {8893},
publisher = {IEEE},
title = {{A sampling approach to finding Lyapunov functions for nonlinear discrete-time systems}},
year = {2017}
}
@article{Bock2014,
abstract = {A path-following controller is developed and applied to a laboratory tower crane. The control task is to move a load along a predefined geometric path. The time evolution along the path is not fixed but left as a degree of freedom to be determined by the controller. In order to be able to account for system constraints, a model predictive control scheme is adopted with special focus on real-time feasibility with small sampling times. The resulting controller is applied to a laboratory-scale tower crane and validated through simulation studies and measurement results.},
author = {B{\"{o}}ck, Martin and Kugi, Andreas},
doi = {10.1109/TCST.2013.2280464},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/B{\"{o}}ck, Kugi - 2014 - Real-time nonlinear model predictive path-following control of a laboratory tower crane.pdf:pdf},
isbn = {1063-6536},
issn = {10636536},
journal = {IEEE Transactions on Control Systems Technology},
keywords = {Model predictive control (MPC),optimal control,path-following,real-time control,state constraint,tower crane},
number = {4},
pages = {1461--1473},
title = {{Real-time nonlinear model predictive path-following control of a laboratory tower crane}},
volume = {22},
year = {2014}
}
@inproceedings{Boedecker2014,
abstract = {In this paper we present a fully automated approach to (approximate) optimal control of non-linear systems. Our algorithm jointly learns a non-parametric model of the system dynamics - based on Gaussian Process Regression (GPR) - and performs receding horizon control using an adapted iterative LQR formulation. This results in an extremely data-efficient learning algorithm that can operate under real-time constraints. When combined with an exploration strategy based on GPR variance, our algorithm successfully learns to control two benchmark problems in simulation (two-link manipulator, cart-pole) as well as to swing-up and balance a real cart-pole system. For all considered problems learning from scratch, that is without prior knowledge provided by an expert, succeeds in less than 10 episodes of interaction with the system.},
author = {Boedecker, Joschka and Springenberg, Jost Tobias and Wulfing, Jan and Riedmiller, Martin},
booktitle = {2014 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL)},
doi = {10.1109/ADPRL.2014.7010608},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boedecker et al. - 2014 - Approximate real-time optimal control based on sparse Gaussian process models.pdf:pdf},
isbn = {978-1-4799-4552-8},
issn = {2325-1824},
pages = {1--8},
title = {{Approximate real-time optimal control based on sparse Gaussian process models}},
year = {2014}
}
@article{Bolton2007,
author = {Bolton, D. W.},
doi = {10.2307/3611846},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bolton - 2007 - The Multinomial Theorem.pdf:pdf},
issn = {00255572},
journal = {The Mathematical Gazette},
number = {382},
pages = {336},
title = {{The Multinomial Theorem}},
volume = {52},
year = {2007}
}
@inproceedings{Bouffard2012,
abstract = {In this paper, we present details of the real time implementation onboard a quadrotor helicopter of learning-based model predictive control (LBMPC). LBMPC rigorously combines statistical learning with control engineering, while providing levels of guarantees about safety, robustness, and convergence. Experimental results show that LBMPC can learn physically based updates to an initial model, and how as a result LBMPC improves transient response performance. We demonstrate robustness to mis-learning. Finally, we show the use of LBMPC in an integrated robotic task demonstration-The quadrotor is used to catch a ball thrown with an a priori unknown trajectory.},
author = {Bouffard, P and Aswani, A and Tomlin, C},
booktitle = {Proceedings of the 2012 IEEE International Conference on Robotics and Automation (ICRA)},
doi = {10.1109/ICRA.2012.6225035},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bouffard, Aswani, Tomlin - 2012 - Learning-based model predictive control on a quadrotor Onboard implementation and experimental results.pdf:pdf},
isbn = {1050-4729 VO -},
issn = {1050-4729},
keywords = {Force,Predictive models,Robots,Trajectory,Vectors,Vehicle dynamics,Vehicles,autonomous aerial vehicles,control engineering,convergence,experimental results,helicopters,learning (artificial intelligence),learning-based model predictive control,onboard implementation,predictive control,quadrotor,robustness,safety,statistical learning,transient response,transient response performance},
pages = {279--284},
title = {{Learning-based model predictive control on a quadrotor: Onboard implementation and experimental results}},
year = {2012}
}
@article{Boyd1986,
abstract = {Using Generalized Harmonic Analysis, a complete description of parameter convergence in Model Reference Adaptive Control (MRAC) is given in terms of the spectrum of the exogenous reference input signal. Roughly speaking, if the reference signal "contains enough frequencies" then the parameter vector converges to its correct value. If not, it converges to an easily characterizable subspace in parameter space. {\textcopyright} 1986.},
author = {Boyd, Stephen and Sastry, S. S.},
file = {:home/alederer/Documents/Literatur/Learning/Linear Systems/Necessary and Sufficient Conditions for Parameter Convergence in Adaptive Control.pdf:pdf},
journal = {Automatica},
keywords = {Adaptive control,adaptive systems,identifiability,parameter estimation},
number = {6},
pages = {629--639},
title = {{Necessary and sufficient conditions for parameter convergence in adaptive control}},
volume = {22},
year = {1986}
}
@phdthesis{Broderick2012,
author = {Broderick, David J.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Broderick - 2012 - Dynamic Gaussian Process Models for Model Predictive Control of Vehicle Roll.pdf:pdf},
keywords = {broderick,copyright 2012 by david,gaussian process,j,model predictive control,stability control},
school = {Auburn University},
title = {{Dynamic Gaussian Process Models for Model Predictive Control of Vehicle Roll}},
year = {2012}
}
@book{Brooks2011,
abstract = {Hamiltonian dynamics can be used to produce distant proposals for the Metropolis algorithm, thereby avoiding the slow exploration of the state space that results from the diffusive behaviour of simple random-walk proposals. Though originating in physics, Hamiltonian dynamics can be applied to most problems with continuous state spaces by simply introducing fictitious "momentum" variables. A key to its usefulness is that Hamiltonian dynamics preserves volume, and its trajectories can thus be used to define complex mappings without the need to account for a hard to compute Jacobian factor - a property that can be exactly maintained even when the dynamics is approximated by discretizing time. In this review, discuss theoretical and practical aspects of Hamiltonian Monte Carlo, and present some of its variations, including using windows of states for approximations, tempering during the course of a trajectory to handle isolated modes, and short-cut methods that prevent useless trajectories form taking much computation time.},
editor = {Brooks, Steve and Gelman, Andrew and Jones, Galin L. and Meng, Xiao-Li},
file = {:home/alederer/Documents/Literatur/Learning/Hidden Markov Models/Handbook of Markov Chain Monte Carlo.pdf:pdf},
publisher = {CRC Press},
title = {{Handbook of Markov Chain Monte Carlo}},
year = {2011}
}
@article{Broomhead2016,
author = {Broomhead, Timothy J. and Manzie, Chris and Hield, Peter and Shekhar, Rohan and Brear, Michael John},
doi = {10.1109/TCST.2016.2574758},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Broomhead et al. - 2016 - Economic Model Predictive Control and Applications for Diesel Generators.pdf:pdf},
issn = {1063-6536},
journal = {IEEE Transactions on Control Systems Technology},
number = {2},
pages = {388--400},
title = {{Economic Model Predictive Control and Applications for Diesel Generators}},
volume = {25},
year = {2016}
}
@article{Bubeck2012,
abstract = {Multi-armed bandit problems are the most basic examples of sequential decision problems with an exploration-exploitation trade-off. This is the balance between staying with the option that gave highest payoffs in the past and exploring new options that might give higher payoffs in the future. Although the study of bandit problems dates back to the Thirties, exploration-exploitation trade-offs arise in several modern applications, such as ad placement, website optimization, and packet routing. Mathematically, a multi-armed bandit is defined by the payoff process associated with each option. In this survey, we focus on two extreme cases in which the analysis of regret is particularly simple and elegant: i.i.d. payoffs and adversarial payoffs. Besides the basic setting of finitely many actions, we also analyze some of the most important variants and extensions, such as the contextual bandit model.},
archivePrefix = {arXiv},
arxivId = {1204.5721},
author = {Bubeck, S{\'{e}}bastien and Cesa-Bianchi, Nicol{\`{o}}},
doi = {10.1561/2200000024},
eprint = {1204.5721},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bubeck, Cesa-Bianchi - 2012 - Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems.pdf:pdf},
journal = {Foundations and Trends in Machine Learning},
number = {1},
pages = {1--122},
title = {{Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems}},
url = {http://arxiv.org/abs/1204.5721},
volume = {5},
year = {2012}
}
@incollection{Busoniu2010,
abstract = {Dynamic programming (DP) and reinforcement learning (RL) can be used to address problems from a variety of fields, including automatic control, arti- ficial intelligence, operations research, and economy.Many problems in these fields are described by continuous variables, whereas DP and RL can find exact solutions only in the discrete case. Therefore, approximation is essential in practical DP and RL. This chapter provides an in-depth review of the literature on approximate DP and RL in large or continuous-space, infinite-horizon problems.Value iteration, pol- icy iteration, and policy search approaches are presented in turn.Model-based (DP) as well as online and batch model-free (RL) algorithms are discussed. We review theoretical guarantees on the approximate solutions produced by these algorithms. Numerical examples illustrate the behavior of several representative algorithms in practice. Techniques to automatically derive value function approximators are dis- cussed, and a comparison between value iteration, policy iteration, and policy search is provided. The chapter closes with a discussion of open issues and promising re- search directions in approximate DP and RL.},
author = {Buşoniu, L and Schutter, Bart De and Babu{\v{s}}ka, R},
booktitle = {Collaborative Information Systems},
doi = {10.1007/978-3-642-11688-9_1},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Buşoniu, Schutter, Babu{\v{s}}ka - 2010 - Approximate dynamic programming and reinforcement learning.pdf:pdf},
isbn = {9783642116872},
issn = {1860949X},
pages = {1--43},
title = {{Approximate dynamic programming and reinforcement learning}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-11688-9{\_}1},
year = {2010}
}
@article{Calafiore2006,
abstract = { This paper proposes a new probabilistic solution framework for robust control analysis and synthesis problems that can be expressed in the form of minimization of a linear objective subject to convex constraints parameterized by uncertainty terms. This includes the wide class of NP-hard control problems representable by means of parameter-dependent linear matrix inequalities (LMIs). It is shown in this paper that by appropriate sampling of the constraints one obtains a standard convex optimization problem (the scenario problem) whose solution is approximately feasible for the original (usually infinite) set of constraints, i.e., the measure of the set of original constraints that are violated by the scenario solution rapidly decreases to zero as the number of samples is increased. We provide an explicit and efficient bound on the number of samples required to attain a-priori specified levels of probabilistic guarantee of robustness. A rich family of control problems which are in general hard to solve in a deterministically robust sense is therefore amenable to polynomial-time solution, if robustness is intended in the proposed risk-adjusted sense.},
author = {Calafiore, G.C. and Campi, M.C.},
doi = {10.1109/TAC.2006.875041},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Calafiore, Campi - 2006 - The scenario approach to robust control design.pdf:pdf},
isbn = {9783902661104},
issn = {0018-9286},
journal = {IEEE Transactions on Automatic Control},
keywords = {Probabilistic robustness,randomized algorithms,robust control,robust convex optimization,uncertainty},
number = {5},
pages = {742--753},
title = {{The scenario approach to robust control design}},
volume = {51},
year = {2006}
}
@article{Calafiore2017,
abstract = {—Repetitive Scenario Design (RSD) is a random-ized approach to robust design based on iterating two phases: a standard scenario design phase that uses N sce-narios (design samples), followed by randomized feasibility phase that uses N o test samples on the scenario solution. We give a full and exact probabilistic characterization of the number of iterations required by the RSD approach for returning a solution, as a function of N , N o , and of the desired levels of probabilistic robustness in the solution. This novel approach broadens the applicability of the sce-nario technology, since the user is now presented with a clear tradeoff between the number N of design samples and the ensuing expected number of repetitions required by the RSD algorithm. The plain (one-shot) scenario design becomes just one of the possibilities, sitting at one extreme of the tradeoff curve, in which one insists in finding a solution in a single repetition: this comes at the cost of possibly high N . Other possibilities along the tradeoff curve use lower N values, but possibly require more than one repetition.},
author = {Calafiore, Giuseppe C.},
doi = {10.1109/TAC.2016.2575859},
file = {:home/alederer/Local/Literatur/Scenario Optimization/Repetitive Scenario Desig.pdf:pdf},
isbn = {9781509018376},
issn = {00189286},
journal = {IEEE Transactions on Automatic Control},
keywords = {Probabilistic robustness,random convex programs,randomized algorithms,scenario design},
number = {3},
pages = {1125--1137},
title = {{Repetitive Scenario Design}},
volume = {62},
year = {2017}
}
@article{Calafiore2011,
abstract = {A novel approach based on probability and randomization has emerged to synergize with the standard deterministic methods for control of systems with uncertainty. The main objective of this paper is to provide a broad perspective on this area of research known as "probabilistic robust control", and to address in a systematic manner recent advances. The focal point is on design methods, based on the interplay between uncertainty randomization and convex optimization, and on the illustration of specific control applications. {\textcopyright} 2011 Elsevier Ltd. All rights reserved.},
author = {Calafiore, Giuseppe C. and Dabbene, Fabrizio and Tempo, Roberto},
doi = {10.1016/j.automatica.2011.02.029},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Calafiore, Dabbene, Tempo - 2011 - Research on probabilistic methods for control system design.pdf:pdf},
issn = {00051098},
journal = {Automatica},
keywords = {Control of uncertain systems,Optimization,Randomized algorithms},
number = {7},
pages = {1279--1293},
publisher = {Elsevier Ltd},
title = {{Research on probabilistic methods for control system design}},
volume = {47},
year = {2011}
}
@inproceedings{Calandra2014,
abstract = {The K-armed bandit problem is a formalization of the exploration versus exploitation dilemma, a well-known issue in stochastic optimization tasks. In a K-armed bandit problem, a player is confronted with a gambling machine with K arms where each arm is associated to an unknown gain distribution and the goal is to maximize the sum of the rewards (or minimize the sum of losses). Several approaches have been proposed in literature to deal with the K-armed bandit problem. Most of them combine a greedy exploitation strategy with a random exploratory phase. This paper focuses on the improvement of the exploration step by having recourse to the notion of probability of correct selection (PCS), a well-known notion in the simulation literature yet overlooked in the optimization domain. The rationale of our approach is to perform at each exploration step the arm sampling which maximizes the probability of selecting the optimal arm (i.e. the PCS) at the following step. This strategy is implemented by a bandit algorithm, called -PCSgreedy, which integrates the PCS exploration approach with the classical -greedy schema. A set of numerical experiments on artificial and real datasets shows that a more effective exploration may improve the performance of the entire bandit strategy.},
author = {Calandra, Roberto and Gopalan, Nakul and Seyfarth, Andre and Peters, Jan and Deisenroth, Marc Peter},
booktitle = {Proceedings of the International Conference on Learning and Intelligent Optimization},
doi = {10.1007/978-3-540-92695-5},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Calandra et al. - 2014 - Bayesian Gait Optimization for Bipedal Locomotion.pdf:pdf},
isbn = {9783540926948},
issn = {03029743},
keywords = {bayesian optimization},
pages = {274--290},
title = {{Bayesian Gait Optimization for Bipedal Locomotion}},
url = {http://www.springerlink.com/index/10.1007/978-3-540-92695-5},
year = {2014}
}
@article{Campi2008,
abstract = {Many optimization problems are naturally delivered in an uncertain framework, and one would like to exercise prudence against the uncertainty elements present in the problem. In pre- vious contributions, it has been shown that solutions to uncertain convex programs that bear a high probability to satisfy uncertain constraints can be obtained at low computational cost through con- straint randomization. In this paper, we establish new feasibility results for randomized algorithms. Specifically, the exact feasibility for the class of the so-called fully-supported problems is obtained. It turns out that all fully-supported problems share the same feasibility properties, revealing a deep kinship among problems of this class. It is further proven that the feasibility of the randomized solutions for all other convex programs can be bounded based on the feasibility for the prototype class of fully-supported problems. The feasibility result of this paper outperforms previous bounds and is not improvable because it is exact for fully-supported problems.},
archivePrefix = {arXiv},
arxivId = {arXiv:1302.5877},
author = {Campi, M C and Garatti, S},
doi = {10.1137/07069821X},
eprint = {arXiv:1302.5877},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Campi, Garatti - 2008 - The Exact Feasibility of Randomized Solutions of Uncertain Convex Programs.pdf:pdf},
isbn = {0001405101},
issn = {1052-6234},
journal = {SIAM Journal on Optimization},
keywords = {07069821x,10,1137,68w20,90c15,90c25,90c34,ams subject classifications,chance-constrained,convex optimization,doi,programming,randomized methods,robust optimization,semi-infinite,uncertain optimization},
number = {3},
pages = {1211--1230},
title = {{The Exact Feasibility of Randomized Solutions of Uncertain Convex Programs}},
volume = {19},
year = {2008}
}
@article{Campi2018,
abstract = {{IEEE The scenario approach is a general methodology for data-based optimization that has attracted a great deal of attention in the past few years. It prescribes that one collects a record of previous cases (scenarios) from the same setup in which optimization is being conducted and makes a decision which attains optimality for the seen cases. Scenario optimization is by now very well understood for convex problems, where a theory exists that rigorously certifies the generalization properties of the solution, that is, the ability of the solution to perform well in connection to new situations. This theory theoretically supports the scenario methodology and justifies its use. This paper considers non-convex{\}} problems. While other contributions in the non-convex setup already exist, we here take a major departure from previous approaches. We suggest that the generalization level is evaluated only after the solution is found and its complexity in terms of the length of a support sub-sample (a notion precisely introduced in this paper) is assessed. As a consequence, the generalization level is stochastic and adjusted case by case to the available scenarios. This fact is key to obtain tig},
author = {Campi, M. C. and Garatti, Simone and Ramponi, Federico Alessandro},
doi = {10.1109/TAC.2018.2808446},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Campi, Garatti, Ramponi - 2018 - A general scenario theory for non-convex optimization and decision making.pdf:pdf},
issn = {00189286},
journal = {IEEE Transactions on Automatic Control},
keywords = {Complexity theory,Convex functions,Cost function,Decision making,Electronic mail,Robustness,Scenario approach,nonconvex optimization,robust control,robust decision-making,stochastic programming},
pages = {1--1},
title = {{A general scenario theory for non-convex optimization and decision making}},
year = {2018}
}
@article{Campi2009,
abstract = {The 'scenario approach' is an innovative technology that has been introduced to solve convex optimization problems with an infinite number of constraints, a class of problems which often occurs when dealing with uncertainty. This technology relies on random sampling of constraints, and provides a powerful means for solving a variety of design problems in systems and control. The objective of this paper is to illustrate the scenario approach at a tutorial level, focusing mainly on algorithmic aspects. Its versatility and virtues will be pointed out through a number of examples in model reduction, robust and optimal control. {\textcopyright} 2009 Elsevier Ltd. All rights reserved.},
author = {Campi, Marco C. and Garatti, Simone and Prandini, Maria},
doi = {10.1016/j.arcontrol.2009.07.001},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Campi, Garatti, Prandini - 2009 - The scenario approach for systems and control design.pdf:pdf},
isbn = {1367-5788},
issn = {13675788},
journal = {Annual Reviews in Control},
keywords = {Probabilistic methods,Randomized algorithms,Robust convex optimization,Systems and control design},
number = {2},
pages = {149--157},
title = {{The scenario approach for systems and control design}},
volume = {33},
year = {2009}
}
@inproceedings{Campi2015,
author = {Campi, Marco C. and Garatti, Simone and Ramponi, Federico A.},
booktitle = {Proceedings of the IEEE Conference on Decision and Control},
doi = {10.1109/CDC.2015.7402845},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Campi, Garatti, Ramponi - 2015 - Non-convex scenario optimization with application to system identification.pdf:pdf},
isbn = {9781479978861},
issn = {07431546},
pages = {4023--4028},
title = {{Non-convex scenario optimization with application to system identification}},
year = {2015}
}
@article{Canale2012,
author = {Canale, M. and Fagiano, L. and Signorile, M. C.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Canale, Fagiano, Signorile - 2012 - Nonlinear Model Predictive Control from Data A Set Membership approach.pdf:pdf},
isbn = {9120256922},
issn = {10498923},
journal = {International Journal of Robust and Nonlinear Control},
keywords = {nonlinear control,predictive control,robust stability},
number = {1},
pages = {123--139},
title = {{Nonlinear Model Predictive Control from Data: A Set Membership approach}},
volume = {24},
year = {2012}
}
@article{Cannon2011,
abstract = {Stochastic model predictive control (MPC) strategies can provide guarantees of stability and constraint satisfaction, but their online computation can be formidable. This difficulty is avoided in the current technical note through the use of tubes of fixed cross section and variable scaling. A model describing the evolution of predicted tube scalings facilitates the computation of stochastic tubes; furthermore this procedure can be performed offline. The resulting MPC scheme has a low online computational load even for long prediction horizons, thus allowing for performance improvements. The efficacy of the approach is illustrated by numerical examples.},
archivePrefix = {arXiv},
arxivId = {arXiv:1410.4535v1},
author = {Cannon, Mark and Kouvaritakis, Basil and Rakovi{\'{c}}, Sa{\v{s}}a V. and Cheng, Qifeng},
doi = {10.1109/TAC.2010.2086553},
eprint = {arXiv:1410.4535v1},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cannon et al. - 2011 - Stochastic tubes in model predictive control with probabilistic constraints.pdf:pdf},
isbn = {978-1-4244-7426-4},
issn = {00189286},
journal = {IEEE Transactions on Automatic Control},
keywords = {Constrained control,model predictive control (MPC),probabilistic constraints,stochastic systems},
number = {1},
pages = {194--200},
title = {{Stochastic tubes in model predictive control with probabilistic constraints}},
volume = {56},
year = {2011}
}
@phdthesis{Cao,
author = {Cao, Gang},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cao - 2017 - Gaussian process based model predictive control.pdf:pdf},
school = {Massey University},
title = {{Gaussian process based model predictive control}},
year = {2017}
}
@article{Cao2017,
abstract = {The Model Predictive Control (MPC) trajectory tracking problem of an unmanned quadrotor with input and output constraints is addressed. In this article, the dynamic models of the quadrotor are obtained purely from operational data in the form of probabilistic Gaussian Process (GP) models. This is different from conventional models obtained through Newtonian analysis. A hierarchical control scheme is used to handle the trajectory tracking problem with the translational subsystem in the outer loop and the rotational subsystem in the inner loop. Constrained GP based MPC are formulated separately for both subsystems. The resulting MPC problems are typically nonlinear and non-convex. We derived 15 a GP based local dynamical model that allows these optimization problems to be relaxed to convex ones which can be efficiently solved with a simple active-set algorithm. The performance of the proposed approach is compared with an existing unconstrained Nonlinear Model Predictive Control (NMPC). Simulation results show that the two approaches exhibit similar trajectory tracking performance. However, our approach has the advantage of incorporating constraints on the control inputs. In addition, our approach only requires 20{\%} of the computational time for NMPC.},
archivePrefix = {arXiv},
arxivId = {1707.04515},
author = {Cao, Gang and Lai, Edmund M-K and Alam, Fakhrul},
doi = {10.1007/s10846-017-0549-y},
eprint = {1707.04515},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cao, Lai, Alam - 2017 - Gaussian Process Model Predictive Control of An Unmanned Quadrotor.pdf:pdf},
isbn = {9781467398596},
issn = {0921-0296},
journal = {Journal of Intelligent {\&} Robotic Systems},
keywords = {Gaussian process,Model predictive control,Quadrotor trajectory tracking,gaussian process,model,predictive control,quadrotor trajectory tracking},
number = {1},
pages = {147--162},
publisher = {Journal of Intelligent {\&} Robotic Systems},
title = {{Gaussian Process Model Predictive Control of An Unmanned Quadrotor}},
volume = {88},
year = {2017}
}
@inproceedings{Cao2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1612.01211v1},
author = {Cao, Gang and Lai, Edmund M-k and Alam, Fakhrul},
booktitle = {Proceedings of the International Conference on Control, Automation and Robotics},
eprint = {arXiv:1612.01211v1},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cao, Lai, Alam - 2016 - Gaussian Process Model Predictive Control of Unmanned Quadrotors.pdf:pdf},
isbn = {9781467398596},
keywords = {-gaussian process},
pages = {200--206},
title = {{Gaussian Process Model Predictive Control of Unmanned Quadrotors}},
year = {2016}
}
@inproceedings{Cardelli2018,
abstract = {Bayesian inference and Gaussian processes are widely used in applications ranging from robotics and control to biological systems. Many of these applications are safety-critical and require a characterization of the uncertainty associated with the learning model and formal guarantees on its predictions. In this paper we define a robustness measure for Bayesian inference against input perturbations, given by the probability that, for a test point and a compact set in the input space containing the test point, the prediction of the learning model will remain {\$}\backslashdelta-{\$}close for all the points in the set, for {\$}\backslashdelta{\textgreater}0.{\$} Such measures can be used to provide formal guarantees for the absence of adversarial examples. By employing the theory of Gaussian processes, we derive tight upper bounds on the resulting robustness by utilising the Borell-TIS inequality, and propose algorithms for their computation. We evaluate our techniques on two examples, a GP regression problem and a fully-connected deep neural network, where we rely on weak convergence to GPs to study adversarial examples on the MNIST dataset.},
author = {Cardelli, Luca and Kwiatkowska, Marta and Laurenti, Luca and Patane, Andrea},
booktitle = {Thirty-Third AAAI Conference on Artificial Intelligence},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cardelli et al. - 2019 - Robustness Guarantees for Bayesian Inference with Gaussian Processes.pdf:pdf},
title = {{Robustness Guarantees for Bayesian Inference with Gaussian Processes}},
year = {2019}
}
@article{Carron2019,
author = {Carron, Andrea and Arcari, Elena and Wermelinger, Martin and Hewing, Lukas and Hutter, Marco and Zeilinger, Melanie N.},
doi = {10.1109/lra.2019.2929987},
file = {:home/alederer/Documents/Literatur/Learning Based MPC/gp mpc/Data-Driven Model Predictive Control for Trajectory Tracking With a Robotic Arm.pdf:pdf},
journal = {IEEE Robotics and Automation Letters},
number = {4},
pages = {3758--3765},
title = {{Data-Driven Model Predictive Control for Trajectory Tracking With a Robotic Arm}},
volume = {4},
year = {2019}
}
@article{Casale2018,
abstract = {Variational autoencoders (VAE) are a powerful and widely-used class of models to learn complex data distributions in an unsupervised fashion. One important limitation of VAEs is the prior assumption that latent sample representations are independent and identically distributed. However, for many important datasets, such as time-series of images, this assumption is too strong: accounting for covariances between samples, such as those in time, can yield to a more appropriate model specification and improve performance in downstream tasks. In this work, we introduce a new model, the Gaussian Process (GP) Prior Variational Autoencoder (GPPVAE), to specifically address this issue. The GPPVAE aims to combine the power of VAEs with the ability to model correlations afforded by GP priors. To achieve efficient inference in this new class of models, we leverage structure in the covariance matrix, and introduce a new stochastic backpropagation strategy that allows for computing stochastic gradients in a distributed and low-memory fashion. We show that our method outperforms conditional VAEs (CVAEs) and an adaptation of standard VAEs in two image data applications.},
archivePrefix = {arXiv},
arxivId = {1810.11738},
author = {Casale, Francesco Paolo and Dalca, Adrian V and Saglietti, Luca and Listgarten, Jennifer and Fusi, Nicolo},
doi = {arXiv:1810.11738v1},
eprint = {1810.11738},
file = {:home/alederer/Local/Literatur/Parkinson/GP Modelling/Gaussian Process Prior Variational Autoencoders.pdf:pdf},
number = {NeurIPS},
title = {{Gaussian Process Prior Variational Autoencoders}},
url = {http://arxiv.org/abs/1810.11738},
year = {2018}
}
@article{Chagra2018,
author = {Chagra, Wassila and Degachi, Hajer and Ksouri, Moufida},
doi = {10.1007/s11071-017-3544-8},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chagra, Degachi, Ksouri - 2017 - Nonlinear model predictive control based on Nelder Mead optimization method.pdf:pdf},
isbn = {1107101735448},
issn = {1573269X},
journal = {Nonlinear Dynamics},
keywords = {Computation time,Gradient method,Hammerstein model,Model predictive control,Nelder Mead algorithm,Optimization},
number = {2},
pages = {127--138},
publisher = {Springer Netherlands},
title = {{Nonlinear model predictive control based on Nelder Mead optimization method}},
url = {"http://dx.doi.org/10.1007/s11071-017-3544-8},
volume = {92},
year = {2017}
}
@article{Chai2009,
abstract = {We provide some insights into how task correlations in multi-task Gaussian process (GP) regression affect the generalization error and the learning curve. We analyze the asymmetric two-tasks case, where a secondary task is to help the learning of a primary task. Within this setting, we give bounds on the generalization error and the learning curve of the primary task. Our approach admits intuitive understandings of the multi-task GP by relating it to single-task GPs. For the case of one-dimensional input-space under optimal sampling with data only for the secondary task, the limitations of multi-task GP can be quantified explicitly.},
author = {Chai, K. M.},
file = {:home/alederer/Local/Literatur/Learning/learning theory/Generalization Errors and Learning Curves for Regression with Multi-task Gaussian Processes.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
keywords = {learning,statistics {\&} optimisation,theory {\&} algorithms},
pages = {1--9},
title = {{Generalization Errors and Learning Curves for Regression with Multi-task Gaussian Processes}},
year = {2009}
}
@article{Chakrabarty2017,
abstract = {{\textcopyright} 1963-2012 IEEE. In this paper, an explicit nonlinear model predictive controller (ENMPC) for the stabilization of nonlinear systems is investigated. The proposed ENMPC is constructed using tensored polynomial basis functions and samples drawn from low-discrepancy sequences. Solutions of a finite-horizon optimal control problem at the sampled nodes are used 1) to learn an inner and outer approximation of the feasible region of the ENMPC using support vector machines, and 2) to construct the ENMPC control surface on the computed feasible region using regression or sparse-grid interpolation, depending on the shape of the feasible region. The attractiveness of the proposed control scheme lies in its tractability to higher-dimensional systems with feasibility and stability guarantees, significantly small online computation times, and ease of implementation.},
author = {Chakrabarty, Ankush and Dinh, Vu and Corless, Martin J. and Rundell, Ann E. and Zak, Stanislaw H. and Buzzard, Gregery T.},
doi = {10.1109/TAC.2016.2539222},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chakrabarty et al. - 2017 - Support Vector Machine Informed Explicit Nonlinear Model Predictive Control Using Low-Discrepancy Sequences.pdf:pdf},
issn = {00189286},
journal = {IEEE Transactions on Automatic Control},
keywords = {Function approximation,low-discrepancy sampling,model predictive control,nonlinear systems,supervised learning},
number = {1},
pages = {135--148},
title = {{Support Vector Machine Informed Explicit Nonlinear Model Predictive Control Using Low-Discrepancy Sequences}},
volume = {62},
year = {2017}
}
@article{Chakraborty2011,
abstract = {Current practice for flight control validation relies heavily on linear analyses and nonlinear, high-fidelity simulations. This process would be enhanced by the addition of nonlinear analyses of the flight control system. This paper demonstrates the use of region of attraction estimation for studying nonlinear effects. A nonlinear polynomial model is constructed for the longitudinal dynamics of NASA's Generic Transport Model aircraft. A polynomial model for the short period dynamics is obtained by decoupling this mode from the nonlinear longitudinal model. Polynomial optimization techniques are applied to estimate region of attractions around trim conditions. {\{}{\textcopyright}{\}} 2010 Elsevier Ltd.},
author = {Chakraborty, Abhijit and Seiler, Peter and Balas, Gary J},
file = {:home/alederer/Local/Literatur/sampling based Stability analysis/Nonlinear region of attraction analysis for flight control verification and validation.pdf:pdf},
journal = {Control Engineering Practice},
keywords = {Flight control,Nonlinear analysis,Region of attraction,Validation and verification},
number = {4},
pages = {335--345},
publisher = {Elsevier},
title = {{Nonlinear region of attraction analysis for flight control verification and validation}},
volume = {19},
year = {2011}
}
@article{Chakraborty2011,
abstract = {Current practice for flight control validation relies heavily on linear analyses and nonlinear, high-fidelity simulations. This process would be enhanced by the addition of nonlinear analyses of the flight control system. This paper demonstrates the use of region of attraction estimation for studying nonlinear effects. A nonlinear polynomial model is constructed for the longitudinal dynamics of NASA's Generic Transport Model aircraft. A polynomial model for the short period dynamics is obtained by decoupling this mode from the nonlinear longitudinal model. Polynomial optimization techniques are applied to estimate region of attractions around trim conditions. {\textcopyright} 2010 Elsevier Ltd.},
author = {Chakraborty, Abhijit and Seiler, Peter and Balas, Gary J.},
doi = {10.1016/j.conengprac.2010.12.001},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chakraborty, Seiler, Balas - 2011 - Nonlinear region of attraction analysis for flight control verification and validation.pdf:pdf},
issn = {09670661},
journal = {Control Engineering Practice},
keywords = {Flight control,Nonlinear analysis,Region of attraction,Validation and verification},
number = {4},
pages = {335--345},
title = {{Nonlinear region of attraction analysis for flight control verification and validation}},
volume = {19},
year = {2011}
}
@article{Chauhdry2012,
author = {Chauhdry, Majid H M and Luh, Peter B},
doi = {10.1016/j.conengprac.2012.05.003},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chauhdry, Luh - 2012 - Nested partitions for global optimization in nonlinear model predictive control.pdf:pdf},
issn = {0967-0661},
journal = {Control Engineering Practice},
keywords = {Nested partitions,Nonconvex optimization,Nonlinear model predictive control,Partitioning scheme,Solution quality,Stochastic optimization,nonconvex optimization,nonlinear model predictive control,stochastic optimization},
number = {9},
pages = {869--881},
title = {{Nested partitions for global optimization in nonlinear model predictive control}},
url = {http://dx.doi.org/10.1016/j.conengprac.2012.05.003},
volume = {20},
year = {2012}
}
@article{Chen,
author = {Chen, Ling and Chen, Gencai},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Chen - Unknown - Voronoi-based Range Query for Trajectory Data in Spatial Networks.pdf:pdf},
isbn = {9781450301138},
keywords = {range query,spatial network,trajectory,voronoi diagram},
pages = {1022--1026},
title = {{Voronoi-based Range Query for Trajectory Data in Spatial Networks}}
}
@inproceedings{Chen2018,
author = {Chen, Steven and Saulnier, Kelsey and Atanasov, Nikolay},
booktitle = {Proceedings of the American Control Conference},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Saulnier, Atanasov - 2018 - Approximating Explicit Model Predictive Control Using Constrained Neural Networks.pdf:pdf},
pages = {1520--1527},
title = {{Approximating Explicit Model Predictive Control Using Constrained Neural Networks}},
year = {2018}
}
@article{Chen2003,
abstract = {In this self-contained survey/review paper, we system- atically investigate the roots of Bayesian filtering as well as its rich leaves in the literature. Stochastic filtering theory is briefly reviewed with emphasis on nonlinear and non-Gaussian filtering. Following the Bayesian statistics, different Bayesian filtering techniques are de- veloped given different scenarios. Under linear quadratic Gaussian circumstance, the celebrated Kalman filter can be derived within the Bayesian framework. Optimal/suboptimal nonlinear filtering tech- niques are extensively investigated. In particular, we focus our at- tention on the Bayesian filtering approach based on sequential Monte Carlo sampling, the so-called particle filters. Many variants of the particle filter as well as their features (strengths and weaknesses) are discussed. Related theoretical and practical issues are addressed in detail. In addition, some other (new) directions on Bayesian filtering are also explored.},
author = {Chen, Z.},
file = {:home/alederer/Documents/Literatur/Multi-step predictions/Bayesian Filtering{\_} From Kalman Filters to Particle Filters, and Beyond.pdf:pdf},
journal = {Statistics: A Journal of Theoretical and Applied Statistics},
keywords = {Adaptive Systems Lab,McMaster University},
pages = {1--69},
title = {{Bayesian filtering: From Kalman filters to particle filters, and beyond}},
url = {http://www.damas.ift.ulaval.ca/{\_}seminar/filesA11/10.1.1.107.7415.pdf},
volume = {182},
year = {2003}
}
@article{Chiang1989,
author = {Chiang, Hsiao-Dong and Thorp, James S.},
doi = {10.1017/cbo9781139548861},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chiang, Thorp - 1989 - Stability Regions of Nonlinear Dynamical Systems A Constructive Methology.pdf:pdf},
journal = {IEEE Transactions on Automatic Control},
number = {12},
pages = {1229--1241},
title = {{Stability Regions of Nonlinear Dynamical Systems: A Constructive Methology}},
volume = {34},
year = {1989}
}
@inproceedings{Chowdhury2017a,
abstract = {We consider the stochastic bandit problem with a continuous set of arms, with the expected reward function over the arms assumed to be fixed but unknown. We provide two new Gaussian process-based algorithms for continuous bandit optimization-Improved GP-UCB (IGP-UCB) and GP-Thomson sampling (GP-TS), and derive corresponding regret bounds. Specifically, the bounds hold when the expected reward function belongs to the reproducing kernel Hilbert space (RKHS) that naturally corresponds to a Gaussian process kernel used as input by the algorithms. Along the way, we derive a new self-normalized concentration inequality for vector- valued martingales of arbitrary, possibly infinite, dimension. Finally, experimental evaluation and comparisons to existing algorithms on synthetic and real-world environments are carried out that highlight the favorable gains of the proposed strategies in many cases.},
author = {Chowdhury, Sayak Ray and Gopalan, Aditya},
booktitle = {Proceedings of the International Conference on Machine Learning},
file = {:home/alederer/Local/Literatur/Learning/learning theory/On Kernelized Multi-armed Bandits.pdf:pdf},
pages = {844--853},
title = {{On Kernelized Multi-armed Bandits}},
year = {2017}
}
@inproceedings{Chua2018,
abstract = {Model-based reinforcement learning (RL) algorithms can attain excellent sample efficiency, but often lag behind the best model-free algorithms in terms of asymptotic performance. This is especially true with high-capacity parametric function approximators, such as deep networks. In this paper, we study how to bridge this gap, by employing uncertainty-aware dynamics models. We propose a new algorithm called probabilistic ensembles with trajectory sampling (PETS) that combines uncertainty-aware deep network dynamics models with sampling-based uncertainty propagation. Our comparison to state-of-the-art model-based and model-free deep RL algorithms shows that our approach matches the asymptotic performance of model-free algorithms on several challenging benchmark tasks, while requiring significantly fewer samples (e.g., 8 and 125 times fewer samples than Soft Actor Critic and Proximal Policy Optimization respectively on the half-cheetah task).},
author = {Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/alederer/Documents/Literatur/Reinforcement Learning/Multi-step predictions/deep reinforcement learning in a handful of trials using probabilistic dynamics models.pdf:pdf},
issn = {10495258},
pages = {4754--4765},
title = {{Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models}},
year = {2018}
}
@article{Cizniar2008,
author = {{\v{C}}i{\v{z}}niar, Michal and Fikar, Miroslav and Latifi, M. A.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/{\v{C}}i{\v{z}}niar, Fikar, Latifi - 2008 - Design of constrained nonlinear model predictive control based on global optimisation.pdf:pdf},
journal = {18th European Symposium on Computer Aided Process Engineering - ESCAPE 18},
keywords = {cnmpc,dynamic optimisation,finite elements,global optimisation,orthogonal collocation},
pages = {1--6},
title = {{Design of constrained nonlinear model predictive control based on global optimisation}},
year = {2008}
}
@book{Cormen2009,
address = {Cambridge, Massachusetts},
author = {Cormen, Thomas H. and Leiserson, Charles E. and Rivest, Ronald L. and Stein, Clifford},
edition = {third},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cormen et al. - 2009 - Introduction to Algorithms.pdf:pdf},
pages = {1186},
publisher = {The MIT Press},
title = {{Introduction to Algorithms}},
year = {2009}
}
@article{Cortes2010,
abstract = {Kernel approximation is commonly used to scale kernel-based algorithms to applications contain- ing as many as several million instances. This paper analyzes the effect of such approximations in the kernel matrix on the hypothesis generated by several widely used learning algorithms. We give stability bounds based on the norm of the kernel approximation for these algorithms, in- cluding SVMs, KRR, and graph Laplacian-based regularization algorithms. These bounds help de- termine the degree of approximation that can be tolerated in the estimation of the kernel matrix. Our analysis is general and applies to arbitrary approximations of the kernel matrix. However, we also give a specific analysis of the Nystr¨ om low-rank approximation in this context and re- port the results of experiments evaluating the quality of the Nystr¨ om low-rank kernel approx- imation when used with ridge regression.},
author = {Cortes, Corinna and Mohri, Mehryar and Talwalkar, Ameet},
file = {:home/alederer/Local/Literatur/Learning/learning theory/On the Impact of Kernel Approximation on Learning Accuracy.pdf:pdf},
journal = {Proceedings of 13th International Conference on Artificial Intelligece and Statistics},
pages = {113--120},
title = {{On the Impact of Kernel Approximation on Learning Accuracy}},
volume = {9},
year = {2010}
}
@article{Couellan2019,
abstract = {We investigate robustness of deep feed-forward neural networks when input data are subject to random uncertainties. More specifically, we consider regularization of the network by its Lipschitz constant and emphasize its role. We highlight the fact that this regularization is not only a way to control the magnitude of the weights but has also a coupling effect on the network weights accross the layers. We claim and show evidence on a dataset that this coupling effect brings a tradeoff between robustness and expressiveness of the network. This suggests that Lipschitz regularization should be carefully implemented so as to maintain coupling accross layers.},
archivePrefix = {arXiv},
arxivId = {1904.06253},
author = {Couellan, Nicolas},
eprint = {1904.06253},
file = {:home/alederer/Documents/Literatur/Learning/Deep Learning/The Coupling Effect of Lipschitz Regularization in Deep Neural Networks.pdf:pdf},
title = {{The coupling effect of Lipschitz regularization in deep neural networks}},
url = {http://arxiv.org/abs/1904.06253},
year = {2019}
}
@article{Csato2002,
author = {Csat{\'{o}}, Lehel and Opper, Manfred},
file = {:home/alederer/Documents/Literatur/Learning/Local GP/Sparse Online Gaussian Processes.pdf:pdf},
journal = {Neural Computation},
title = {{Sparse Online Gaussian Processes}},
year = {2002}
}
@article{Dai2015,
abstract = {We develop a scalable deep non-parametric generative model by augmenting deep Gaussian processes with a recognition model. Inference is performed in a novel scalable variational framework where the variational posterior distributions are reparametrized through a multilayer perceptron. The key aspect of this reformulation is that it prevents the proliferation of variational parameters which otherwise grow linearly in proportion to the sample size. We derive a new formulation of the variational lower bound that allows us to distribute most of the computation in a way that enables to handle datasets of the size of mainstream deep learning tasks. We show the efficacy of the method on a variety of challenges including deep unsupervised learning and deep Bayesian optimization.},
archivePrefix = {arXiv},
arxivId = {1511.06455},
author = {Dai, Zhenwen and Damianou, Andreas and Gonz{\'{a}}lez, Javier and Lawrence, Neil},
doi = {10.1080/02601370210156718},
eprint = {1511.06455},
file = {:home/alederer/Local/Literatur/Parkinson/GP Modelling/Variational Auto-Encoded Deep Gaussian Processes.pdf:pdf},
isbn = {1511.06455v2},
issn = {0968-0896},
pages = {1--11},
title = {{Variational Auto-encoded Deep Gaussian Processes}},
url = {http://arxiv.org/abs/1511.06455},
year = {2015}
}
@inproceedings{Damianou2011,
abstract = {High dimensional time series are endemic in applications of machine learning such as robotics (sensor data), computational biology (gene expression data), vision (video sequences) and graphics (motion capture data). Practical nonlinear probabilistic approaches to this data are required. In this paper we introduce the variational Gaussian process dynamical system. Our work builds on recent variational approximations for Gaussian process latent variable models to allow for nonlinear dimensionality reduction simultaneously with learning a dynamical prior in the latent space. The approach also allows for the appropriate dimensionality of the latent space to be automatically determined. We demonstrate the model on a human motion capture data set and a series of high resolution video sequences.},
archivePrefix = {arXiv},
arxivId = {1107.4985},
author = {Damianou, Andreas C. and Titsias, Michalis K. and Lawrence, Neil D.},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1107.4985},
file = {:home/alederer/Local/Literatur/Parkinson/GP Modelling/Variational Gaussian Process Dynamical Systems.pdf:pdf},
isbn = {9781618395993},
pages = {1--16},
title = {{Variational Gaussian Process Dynamical Systems}},
url = {http://arxiv.org/abs/1107.4985},
year = {2011}
}
@article{Dann2017,
abstract = {Statistical performance bounds for reinforcement learning (RL) algorithms can be critical for high-stakes applications like healthcare. This paper introduces a new framework for theoretically measuring the performance of such algorithms called Uniform-PAC, which is a strengthening of the classical Probably Approximately Correct (PAC) framework. In contrast to the PAC framework, the uniform version may be used to derive high probability regret guarantees and so forms a bridge between the two setups that has been missing in the literature. We demonstrate the benefits of the new framework for finite-state episodic MDPs with a new algorithm that is Uniform-PAC and simultaneously achieves optimal regret and PAC guarantees except for a factor of the horizon.},
archivePrefix = {arXiv},
arxivId = {1703.07710},
author = {Dann, Christoph and Lattimore, Tor and Brunskill, Emma},
eprint = {1703.07710},
file = {:home/alederer/Documents/Literatur/Learning/PAC Bounds for RL/Unifying PAC and Regret{\_} Uniform PAC Bounds for Episodic Reinforcement Learning.pdf:pdf},
number = {c},
title = {{Unifying PAC and Regret: Uniform PAC Bounds for Episodic Reinforcement Learning}},
url = {http://arxiv.org/abs/1703.07710},
year = {2017}
}
@article{Dann2018,
abstract = {The performance of a reinforcement learning algorithm can vary drastically during learning because of exploration. Existing algorithms provide little information about the quality of their current policy before executing it, and thus have limited use in high-stakes applications, such as healthcare. We address this lack of accountability by proposing that algorithms output policy certificates. These certificates bound the sub-optimality and return of the policy in the next episode, allowing humans to intervene when the certified quality is not satisfactory. We further introduce two new algorithms with certificates and present a new framework for theoretical analysis that guarantees the quality of their policies and certificates. For tabular MDPs, we show that computing certificates can even improve the sample-efficiency of optimism-based exploration. As a result, one of our algorithms achieves regret and PAC bounds that are minimax up to lower-order terms.},
archivePrefix = {arXiv},
arxivId = {1811.03056},
author = {Dann, Christoph and Li, Lihong and Wei, Wei and Brunskill, Emma},
eprint = {1811.03056},
file = {:home/alederer/Documents/Literatur/Learning/Off-Policy Policy Evaluation/Policy Certificates{\_} Towards Accountable Reinforcement Learning.pdf:pdf},
title = {{Policy Certificates: Towards Accountable Reinforcement Learning}},
url = {http://arxiv.org/abs/1811.03056},
year = {2018}
}
@book{DeBerg2008,
abstract = {This well-accepted introduction to computational geometry is a textbook for high-level undergraduate and low-level graduate courses. The focus is on algorithms and hence the book is well suited for students in computer science and engineering. Motivation is provided from the application areas: all solutions and techniques from computational geometry are related to particular applications in robotics, graphics, CAD/CAM, and geographic information systems. For students this motivation will be especially welcome. Modern insights in computational geometry are used to provide solutions that are both efficient and easy to understand and implement. All the basic techniques and topics from computational geometry, as well as several more advanced topics, are covered. The book is largely self-contained and can be used for self-study by anyone with a basic background in algorithms. In this third edition, besides revisions to the second edition, new sections discussing Voronoi diagrams of line segments, farthest-point Voronoi diagrams, and realistic input models have been added.},
author = {{De Berg}, Mark and Cheong, Otfried and {Van Kreveld}, Marc and Overmars, Mark},
doi = {10.2307/3620533},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Berg et al. - 2008 - Computational Geometry Algorithms and Applications.pdf:pdf},
isbn = {3540779736},
issn = {00255572},
publisher = {Springer, Berlin, Heidelberg},
title = {{Computational Geometry: Algorithms and Applications}},
year = {2008}
}
@article{Dean2018,
abstract = {We study the constrained linear quadratic regulator with unknown dynamics, addressing the tension between safety and exploration in data-driven control techniques. We present a framework which allows for system identification through persistent excitation, while maintaining safety by guaranteeing the satisfaction of state and input constraints. This framework involves a novel method for synthesizing robust constraint-satisfying feedback controllers, leveraging newly developed tools from system level synthesis. We connect statistical results with cost sub-optimality bounds to give non-asymptotic guarantees on both estimation and controller performance.},
archivePrefix = {arXiv},
arxivId = {1809.10121},
author = {Dean, Sarah and Tu, Stephen and Matni, Nikolai and Recht, Benjamin},
eprint = {1809.10121},
file = {:home/alederer/Documents/Literatur/Reinforcement Learning/Safely Learning to Control the Constrained Linear Quadratic Regulator.pdf:pdf},
pages = {1--31},
title = {{Safely Learning to Control the Constrained Linear Quadratic Regulator}},
url = {http://arxiv.org/abs/1809.10121},
year = {2018}
}
@inproceedings{Degachi2015a,
author = {Degachi, Hajer and Chagra, Wassila and Ksouri, Moufida},
booktitle = {International Multi-Conference on Systems, Signals {\&} Devices},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Degachi, Chagra, Ksouri - 2015 - Global Optimization Method for Model Predictive Control Based on Wiener Model.pdf:pdf},
isbn = {9781479917587},
keywords = {generalized geometric programming,model predictive control,network,neural,optimization,wiener model},
pages = {1--6},
title = {{Global Optimization Method for Model Predictive Control Based on Wiener Model}},
year = {2015}
}
@inproceedings{Degachi2015,
author = {Degachi, Hajer and Chagra, Wassila and Ksouri, Moufida},
booktitle = {International Conference on Modelling, Identification and Control},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Degachi, Chagra, Ksouri - 2015 - Global Optimization Method for Min-Max MPC Based on Wiener Model.pdf:pdf},
isbn = {9781479917587},
keywords = {generalized geometric programming,model predictive control,network,neural,optimization,wiener model},
pages = {1--6},
title = {{Global Optimization Method for Min-Max MPC Based on Wiener Model}},
year = {2015}
}
@phdthesis{Deisenroth2009,
abstract = {This book examines Gaussian processes (GPs) in model-based reinforcement learning (RL) and inference in nonlinear dynamic systems. First, we introduce PILCO, a fully Bayesian approach for efficient RL in continuous-valued state and action spaces when no expert knowledge is available. PILCO learns fast since it takes model uncertainties consistently into account during long-term planning and decision making. Thus, it reduces model bias, a common problem in model-based RL. Due to its generality and efficiency, PILCO is a conceptual and practical approach to jointly learning models and controllers fully automatically. Across all tasks, we report an unprecedented degree of automation and an unprecedented speed of learning. Second, we propose principled algorithms for robust filtering and smoothing in GP dynamic systems. Our methods are based on analytic moment matching and clearly advance state-of-the-art methods.},
author = {Deisenroth, Marc P},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deisenroth - 2009 - Efficient Reinforcement Learning using Gaussian Processes.pdf:pdf},
school = {Karlsruher Institut f{\"{u}}r Technologie},
title = {{Efficient Reinforcement Learning using Gaussian Processes}},
year = {2009}
}
@inproceedings{Deisenroth2011,
abstract = {In this paper, we introduce PILCO, a practical, data-efficient model-based$\backslash$npolicy search method. PILCO reduces model bias, one of the key problems$\backslash$nof model-based reinforcement learning, in a principled way. By learning$\backslash$na probabilistic dynamics model and explicitly incorporating model$\backslash$nuncertainty into long-term planning, PILCO can cope with very little$\backslash$ndata and facilitates learning from scratch in only a few trials.$\backslash$nPolicy evaluation is performed in closed form using state-of-the-art$\backslash$napproximate inference. Furthermore, policy gradients are computed$\backslash$nanalytically for policy improvement. We report unprecedented learning$\backslash$nefficiency on challenging and high-dimensional control tasks.},
author = {Deisenroth, Marc P and Rasmussen, Carl E},
booktitle = {Proceedings of the International Conference on Machine Learning},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deisenroth, Rasmussen - 2011 - PILCO A Model-Based and Data-Efficient Approach to Policy Search.pdf:pdf},
isbn = {978-1-4503-0619-5},
keywords = {Gaussian processes,data efficient reinforcement learning,policy search},
pages = {465--472},
title = {{PILCO: A Model-Based and Data-Efficient Approach to Policy Search}},
year = {2011}
}
@inproceedings{Deisenroth2008,
abstract = {In general, it is difficult to determine an optimal closed-loop policy in nonlinear control problems with continuous-valued state and control domains. Hence, approximations are often inevitable. The standard method of discretizing states and controls suffers from the curse of dimensionality and strongly depends on the chosen temporal sampling rate. In this paper, we introduce Gaussian process dynamic programming (GPDP) and determine an approximate globally optimal closed-loop policy. In GPDP, value functions in the Bellman recursion of the dynamic programming algorithm are modeled using Gaussian processes. GPDP returns an optimal state- feedback for a finite set of states. Based on these outcomes, we learn a possibly discontinuous closed-loop policy on the entire state space by switching between two independently trained Gaussian processes. A binary classifier selects one Gaussian process to predict the optimal control signal. We show that GPDP is able to yield an almost optimal solution to an LQ problem using few sample points. Moreover, we successfully apply GPDP to the underpowered pendulum swing up, a complex nonlinear control problem.},
author = {Deisenroth, Marc P. and Peters, Jan and Rasmussen, Carl E.},
booktitle = {2008 American Control Conference},
doi = {10.1109/ACC.2008.4587201},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deisenroth, Peters, Rasmussen - 2008 - Approximate dynamic programming with Gaussian processes.pdf:pdf},
isbn = {978-1-4244-2078-0},
issn = {0743-1619},
pages = {4480--4485},
title = {{Approximate dynamic programming with Gaussian processes}},
url = {http://ieeexplore.ieee.org/document/4587201/},
year = {2008}
}
@article{Deisenroth2011a,
abstract = {Policy search is a subfield in reinforcement learning which focuses on finding good parameters for a given policy parametrization. It is well suited for robotics as it can cope with high-dimensional state and action spaces, one of the main challenges in robot learning. We review recent successes of both model-free and model-based policy search in robot learning. Model-free policy search is a general approach to learn policies based on sampled trajectories. We classify model-free methods based on their policy evaluation strategy, policy update strategy, and exploration strategy and present a unified view on existing algorithms. Learning a policy is often easier than learning an accurate forward model, and, hence, model-free methods are more frequently used in practice. However, for each sampled trajectory, it is necessary to interact with the robot, which can be time consuming and challenging in practice. Model-based policy search addresses this problem by first learning a simulator of the robot's dynamics from data. Subsequently, the simulator generates trajectories that are used for policy learning. For both model-free and model-based policy search methods, we review their respective properties and their applicability to robotic systems.},
author = {Deisenroth, Marc Peter},
doi = {10.1561/2300000021},
file = {:home/alederer/Documents/Literatur/Reinforcement Learning/A Survey on Policy Search for Robotics.pdf:pdf},
issn = {1935-8253},
journal = {Foundations and Trends in Robotics},
number = {1-2},
pages = {1--142},
title = {{A Survey on Policy Search for Robotics}},
volume = {2},
year = {2013}
}
@article{Deisenroth2015,
abstract = {Autonomous learning has been a promising direction in control and robotics for more than a decade since data-driven learning allows to reduce the amount of engineering knowledge, which is otherwise required. However, autonomous reinforcement learning (RL) approaches typically require many interactions with the system to learn controllers, which is a practical limitation in real systems, such as robots, where many interactions can be impractical and time consuming. To address this problem, current learning approaches typically require task-specific knowledge in form of expert demonstrations, realistic simulators, pre-shaped policies, or specific knowledge about the underlying dynamics. In this paper, we follow a different approach and speed up learning by extracting more information from data. In particular, we learn a probabilistic, non-parametric Gaussian process transition model of the system. By explicitly incorporating model uncertainty into long-term planning and controller learning our approach reduces the effects of model errors, a key problem in model-based learning. Compared to state-of-the art RL our model-based policy search method achieves an unprecedented speed of learning. We demonstrate its applicability to autonomous learning in real robot and control tasks.},
archivePrefix = {arXiv},
arxivId = {arXiv:1502.02860v1},
author = {Deisenroth, Marc Peter and Fox, Dieter and Rasmussen, Carl Edward},
doi = {10.1109/TPAMI.2013.218},
eprint = {arXiv:1502.02860v1},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deisenroth, Fox, Rasmussen - 2015 - Gaussian Processes for Data-Efﬁcient Learning in Robotics and Control.pdf:pdf},
isbn = {0162-8828 VO - 37},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Bayesian inference,Gaussian processes,Policy search,control,reinforcement learning,robotics},
number = {2},
pages = {408--423},
pmid = {26353251},
title = {{Gaussian Processes for Data-Efﬁcient Learning in Robotics and Control}},
volume = {37},
year = {2015}
}
@inproceedings{Deisenroth2009b,
abstract = {We propose an analytic moment-based filter for nonlinear stochastic dynamic systems modeled by Gaussian processes. Exact expressions for the expected value and the covariance matrix are provided for both the prediction step and the filter step, where an additional Gaussian assumption is exploited in the latter case. Our filter does not require further approximations. In particular, it avoids finite-sample approximations. We compare the filter to a variety of Gaussian filters, that is, the EKF, the UKF, and the recent GP-UKF proposed by Ko et al. (2007).},
author = {Deisenroth, Marc Peter and Huber, Marco F. and Hanebeck, Uwe D.},
booktitle = {Proceedings of the International Conference on Machine Learning},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deisenroth, Huber, Hanebeck - 2009 - Analytic moment-based Gaussian process filtering.pdf:pdf},
pages = {1--8},
title = {{Analytic moment-based Gaussian process filtering}},
year = {2009}
}
@article{Deisenroth2009a,
abstract = {Reinforcement learning (RL) and optimal control of systems with continuous states and actions require approximation techniques in most interesting cases. In this article, we introduce Gaussian process dynamic programming (GPDP), an approximate value function-based RL algorithm. We consider both a classic optimal control problem, where problem-specific prior knowledge is available, and a classic RL problem, where only very general priors can be used. For the classic optimal control problem, GPDP models the unknown value functions with Gaussian processes and generalizes dynamic programming to continuous-valued states and actions. For the RL problem, GPDP starts from a given initial state and explores the state space using Bayesian active learning. To design a fast learner, available data have to be used efficiently. Hence, we propose to learn probabilistic models of the a priori unknown transition dynamics and the value functions on the fly. In both cases, we successfully apply the resulting continuous-valued controllers to the under-actuated pendulum swing up and analyze the performances of the suggested algorithms. It turns out that GPDP uses data very efficiently and can be applied to problems, where classic dynamic programming would be cumbersome. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {1511.02222},
author = {Deisenroth, Marc Peter and Rasmussen, Carl Edward and Peters, Jan},
doi = {10.1016/j.neucom.2008.12.019},
eprint = {1511.02222},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deisenroth, Rasmussen, Peters - 2009 - Gaussian process dynamic programming.pdf:pdf},
isbn = {0925-2312},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Bayesian active learning,Dynamic programming,Gaussian processes,Optimal control,Policy learning,Reinforcement learning},
number = {7-9},
pages = {1508--1524},
pmid = {264993200014},
title = {{Gaussian process dynamic programming}},
volume = {72},
year = {2009}
}
@inproceedings{Depeweg2017,
abstract = {We present an algorithm for model-based reinforcement learning that combines Bayesian neural networks (BNNs) with random roll-outs and stochastic optimization for policy learning. The BNNs are trained by minimizing {\$}\backslashalpha{\$}-divergences, allowing us to capture complicated statistical patterns in the transition dynamics, e.g. multi-modality and heteroskedasticity, which are usually missed by other common modeling approaches. We illustrate the performance of our method by solving a challenging benchmark where model-based approaches usually fail and by obtaining promising results in a real-world scenario for controlling a gas turbine.},
author = {Depeweg, Stefan and Hern{\'{a}}ndez-Lobato, Jos{\'{e}} Miguel and Doshi-Velez, Finale and Udluft, Steffen},
booktitle = {International Conference on Learning Representations},
file = {:home/alederer/Documents/Literatur/Learning/Deep Learning/Learning and Policy Search in Stochastic Dynamical Systems with Bayesian Neural Networks.pdf:pdf},
pages = {1--14},
title = {{Learning and Policy Search in Stochastic Dynamical Systems with Bayesian Neural Networks}},
year = {2017}
}
@inproceedings{Desaraju2016,
author = {Desaraju, Vishnu R and Michael, Nathan},
booktitle = {Workshop on Robot Learning and Planning (RLP) at Robotics: Science and Systems},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Desaraju, Michael - 2016 - Experience-driven Predictive Control.pdf:pdf},
title = {{Experience-driven Predictive Control}},
year = {2016}
}
@inproceedings{Desaraju2017,
abstract = {—We present an extension to Experience-driven Pre-dictive Control (EPC) that leverages a Gaussian belief prop-agation strategy to compute an uncertainty set bounding the evolution of the system state in the presence of time-varying state uncertainty. This uncertainty set is used to tighten the constraints in the predictive control formulation via a chance constrained ap-proach, thereby providing a probabilistic guarantee of constraint satisfaction. The parameterized form of the controllers produced by EPC coupled with online uncertainty estimates ensures this robust constraint satisfaction property persists even as the system switches controllers and experiences variations in the uncertainty model. We validate the online performance and robust constraint satisfaction of the proposed Robust EPC algorithm through a series of experimental trials with a small quadrotor platform subjected to changes in state estimate quality.},
author = {Desaraju, Vishnu R and Spitzer, Alexander E and Michael, Nathan},
booktitle = {Proceedings of Robotics: Science and Systems},
doi = {10.15607/RSS.2017.XIII.067},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Desaraju, Spitzer, Michael - 2017 - Experience-driven Predictive Control with Robust Constraint Satisfaction under Time-Varying State Un.pdf:pdf},
title = {{Experience-driven Predictive Control with Robust Constraint Satisfaction under Time-Varying State Uncertainty}},
year = {2017}
}
@article{Dicker2017,
abstract = {Regularization is an essential element of virtually all kernel methods for nonparametric regression problems. A critical factor in the effectiveness of a given kernel method is the type of regularization that is employed. This article compares and contrasts members from a general class of regularization techniques, which notably includes ridge regression and principal component regression. We derive an explicit finite-sample risk bound for regularization-based estimators that simultaneously accounts for (i) the structure of the ambient function space, (ii) the regularity of the true regression function, and (iii) the adaptability (or qualification) of the regularization. A simple consequence of this upper bound is that the risk of the regularization-based estimators matches the minimax rate in a variety of settings. The general bound also illustrates how some regularization techniques are more adaptable than others to favorable regularity properties that the true regression function may possess. This, in particular, demonstrates a striking difference between kernel ridge regression and kernel principal component regression. Our theoretical results are supported by numerical experiments.},
author = {Dicker, Lee H. and Foster, Dean P. and Hsu, Daniel},
doi = {10.1214/17-EJS1258},
file = {:home/alederer/Local/Literatur/Learning/learning theory/Kernel Ridge vs Principal Component Regression{\_} Minimax Bounds and the Qualification of Regularization Operators.pdf:pdf},
issn = {19357524},
journal = {Electronic Journal of Statistics},
keywords = {62G08Nonparametric regression,reproducing kernel},
number = {1},
pages = {1022--1047},
title = {{Kernel Ridge vs. Principal Component Regression: Minimax Bounds and the Qualification of Regularization Operators}},
volume = {11},
year = {2017}
}
@article{Ding2010,
abstract = {This paper investigates the tracking performance of continuous-time, multi-input multi-output, linear timeinvariant systems in which the output feedback is subject to an additive white Gaussian noise corruption. The problem under consideration amounts to determining the minimal error in tracking a Brownian motion random process, which emulates a step reference signal in the deterministic setting. We consider both the unity feedback and two-parameter controllers. In the former case we derive an explicit bound, and in the latter an exact expression of the minimal tracking error attainable under the noise effect. Both results demonstrate how the white Gaussian noise may impede the tracking performance, and how the norse effect may intertwine with such intrinsic characteristics of the plant as unstable poles and nonminimum phase zeros. {\textcopyright}2009 ACA.},
author = {Ding, Li and Wang, Hou Neng and Guan, Zhi Hong and Chen, Jie},
doi = {10.1049/iet-cta.2009.0449},
file = {:home/alederer/Documents/Literatur/Learning for Control/Gaussian Noise/Tracking under additive white Gaussian noise effect.pdf:pdf},
isbn = {9788995605691},
journal = {IET Control Theory and Applications},
number = {11},
pages = {2471--2478},
title = {{Tracking under additive white Gaussian noise effect}},
volume = {4},
year = {2010}
}
@article{Doban2014,
abstract = {— In this paper we propose the use of rational Lyapunov functions to estimate the domain of attraction of the tumor dormancy equilibrium of immune cells–malignant cells interaction dynamics. A procedure for computing rational Lyapunov functions is worked out, with focus on obtaining a meaningful domain of attraction for the considered tumor dy-namics. A valid, nonconvex domain of attraction was obtained, which is consistent with non–trivial tumor evolutions from real– life.},
author = {Doban, Alina I. and Lazar, Mircea},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doban, Lazar - 2014 - Domain of attraction computation for tumor dynamics.pdf:pdf},
journal = {Proceedings of the IEEE Conference on Decision and Control},
number = {February},
pages = {6987--6992},
publisher = {IEEE},
title = {{Domain of attraction computation for tumor dynamics}},
volume = {2015-Febru},
year = {2014}
}
@inproceedings{Doerr2017,
abstract = {We propose a novel long-term optimization criterion to improve the 1 robustness of model-based reinforcement learning in real-world scenarios. Learn-2 ing a dynamics model to derive a solution promises much greater data-efficiency 3 and reusability compared to model-free alternatives. In practice, however, model-4 based RL suffers from various imperfections such as noisy input and output data, 5 delays and unmeasured (latent) states. To achieve higher resilience against such 6 effects, we propose to optimize a generative long-term prediction model directly 7 with respect to the likelihood of observed trajectories as opposed to the common 8 approach of optimizing a dynamics model for one-step-ahead predictions. We 9 evaluate the proposed method on several artificial and real-world benchmark prob-10 lems and compare it to PILCO, a model-based RL framework, in experiments on 11 a manipulation robot. The results show that the proposed method is competitive 12 compared to state-of-the-art model learning methods. In contrast to these more 13 involved models, our model can directly be employed for policy search and out-14 performs a baseline method in the robot experiment.},
archivePrefix = {arXiv},
arxivId = {1706.09911},
author = {Doerr, Andreas and Daniel, Christian and Nguyen-tuong, Duy and Marco, Alonso and Schaal, Stefan and Toussaint, Marc and Trimpe, Sebastian},
booktitle = {Proceedings of the Conference on Robot Learning},
doi = {10.1177/ToBeAssigned},
eprint = {1706.09911},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Doerr et al. - 2017 - Optimizing Long-term Predictions for Model-based Policy Search.pdf:pdf},
isbn = {0037549716666},
issn = {1756-8277},
keywords = {gaussian process dynamics model,learning control,long-term predictions,model learning,model-based policy search,reinforcement learning},
pages = {1--12},
title = {{Optimizing Long-term Predictions for Model-based Policy Search}},
year = {2017}
}
@inproceedings{Domahidi2011,
abstract = {Fast model predictive control on embedded systems has been successfully applied to plants with microsecond sampling times employing a precomputed state-to-input map. However, the complexity of this so-called explicit MPC can be prohibitive even for low-dimensional systems. In this paper, we introduce a new synthesis method for low-complexity suboptimal MPC controllers based on function approximation from randomly chosen point-wise sample values. In addition to standard machine learning algorithms formulated as convex programs, we provide sufficient conditions on the learning algorithm in the form of tractable convex constraints that guarantee input and state constraint satisfaction, recursive feasibility and stability of the closed loop system. The resulting control law can be fully parallelized, which renders the approach particularly suitable for highly concurrent embedded platforms such as FPGAs. A numerical example shows the effectiveness of the proposed method.},
author = {Domahidi, Alexander and Zeilinger, Melanie N and Morari, Manfred and Jones, Colin N},
booktitle = {Proceedings of the IEEE Conference on Decision and Control},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Domahidi et al. - 2011 - Learning a Feasible and Stabilizing Explicit Model Predictive Control Law by Robust Optimization.pdf:pdf},
pages = {513--519},
title = {{Learning a Feasible and Stabilizing Explicit Model Predictive Control Law by Robust Optimization}},
year = {2011}
}
@article{Dong2014,
abstract = {Current research studies show that building heating, cooling and ventilation energy consumption account for nearly 40{\%} of the total building energy use in the U.S. The potential for saving energy through building control systems varies from 5{\%} to 20{\%} based on recent market surveys. This papers introduces and illustrates a methodology for integrated building heating and cooling control to reduce energy consumption and maintain indoor temperature set-point, based on the prediction of occupant behavior patterns and local weather conditions. Advanced machine learning methods including Adaptive Gaussian Process, Hidden Markov Model, Episode Discovery and Semi-Markov Model are modified and implemented into this study. A Nonlinear Model Predictive Control (NMPC) is designed and implemented in real-time based on dynamic programming. The experiment test-bed is setup in the Solar House, with over 100 sensor points measuring indoor environmental parameters, power consumption and ambient conditions. The experiments are carried out for two continuous months in the heating season and for a week in the cooling season. The results show that there is a 30.1{\%} measured energy reduction in the heating season compared with the conventional scheduled temperature set-points, and 17.8{\%} energy reduction in the cooling season. {\textcopyright} 2013 Tsinghua University Press and Springer-Verlag Berlin Heidelberg.},
author = {Dong, Bing and Lam, Khee Poh},
file = {:home/alederer/Documents/Literatur/Learning/Hidden Markov Models/A real-time model predictive control for building heating and cooling systems based on the occupancy behavior pattern detection and local weather forecasting.pdf:pdf},
journal = {Building Simulation},
keywords = {model predictive control,occupancy behavior patterns,real-time implementation,weather forecasting},
number = {1},
pages = {89--106},
title = {{A real-time model predictive control for building heating and cooling systems based on the occupancy behavior pattern detection and local weather forecasting}},
volume = {7},
year = {2014}
}
@article{Doroudi2019,
author = {Doroudi, Shayan and Brunskill, Emma},
doi = {10.1145/3303772.3303838},
file = {:home/alederer/Documents/Literatur/Learning/human in the loop/Fairer but not fair enough{\_} On the Equitability of Knowledge Tracing.pdf:pdf},
isbn = {9781450362566},
keywords = {2019,acm reference format,brunskill,enough on,equity,fairer but not fair,fairness,knowledge tracing,model misspecification,shayan doroudi and emma},
pages = {335--339},
title = {{Fairer but Not Fair Enough On the Equitability of Knowledge Tracing}},
year = {2019}
}
@article{Doroudi2018,
abstract = {We consider the problem of off-policy policy selection in reinforcement learning: using historical data generated from running one policy to compare two or more policies. We show that approaches based on importance sampling can be unfair---they can select the worse of two policies more often than not. We then give an example that shows importance sampling is systematically unfair in a practically relevant setting; namely, we show that it unreasonably favors shorter trajectory lengths. We then present sufficient conditions to theoretically guarantee fairness. Finally, we provide a practical importance sampling-based estimator to help mitigate the unfairness due to varying trajectory lengths.},
author = {Doroudi, Shayan and Thomas, Philip S. and Brunskill, Emma},
file = {:home/alederer/Documents/Literatur/Learning/Off-Policy Policy Evaluation/Importance Sampling for Fair Policy Selection.pdf:pdf},
isbn = {9780999241127},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
pages = {5239--5243},
title = {{Importance sampling for fair policy selection}},
volume = {2018-July},
year = {2018}
}
@article{Douc2012,
abstract = {Let (Y k ) k∈Z be a stationary sequence on a probability space ($\Omega$,A,P) taking values in a standard Borel space Y. Consider the associated maximum likelihood estimator with respect to a parametrized family of hidden Markov models such that the law of the observations (Y k ) k∈Z is not assumed to be described by any of the hidden Markov models of this family. In this paper we investigate the consistency of this estimator in such misspecified models under mild assumptions. {\textcopyright} Institute of Mathematical Statistics, 2012.},
author = {Douc, Randal and Moulines, Eric},
file = {:home/alederer/Documents/Literatur/Learning/Misspecified Priors/Asymptotic Properties of the Maximum Lieklihood Estimation in Misspecified Hidden Markov Models.pdf:pdf},
journal = {Annals of Statistics},
keywords = {Hidden Markov models,Maximum likelihood estimator,Misspecified models,State space models,Strong consistency},
number = {5},
pages = {2697--2732},
title = {{Asymptotic properties of the maximum likelihood estimation in misspecified hidden Markov models}},
volume = {40},
year = {2012}
}
@article{Draeger1995,
abstract = {In this article, we present the application of a neural-network-based model predictive control scheme to control pH in a laboratory-scale neutralization reactor. We use a feedforward neural network as the nonlinear prediction model in an extended DMC-algorithm to control the pH-value. The training data set for the neural network was obtained from measurements of the inputs and outputs of the real plant operating with a PI-controller. Thus, no a priori information about the dynamics of the plant and no special operating conditions of the plant were needed to design the controller. The training algorithm used is a combination of an adaptive backpropagation algorithm that tunes the connection weights with a genetic algorithm to modify the slopes of the activation function of each neuron. This combination turned out to be very robust against getting caught in local minima and it is very insensitive to the initial settings of the weights of the network. Experimental results show that the resulting control algorithm performs much better than the conventional PI-controller which was used for the generation of the training data set},
author = {Draeger, Andreas and Engell, Sebastian and Ranke, Horst},
doi = {10.1109/37.466261},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Draeger, Engell, Ranke - 1995 - Model predictive control using neural networks.pdf:pdf},
issn = {02721708},
journal = {IEEE Control Systems Magazine},
number = {October},
pages = {61--66},
title = {{Model predictive control using neural networks}},
volume = {15},
year = {1995}
}
@inproceedings{Drews2017,
abstract = {We present a framework for vision-based model predictive control (MPC) for the task of aggressive, high-speed autonomous driving. Our approach uses deep convolutional neural networks to predict cost functions from input video which are directly suitable for online trajectory optimization with MPC. We demonstrate the method in a high speed autonomous driving scenario, where we use a single monocular camera and a deep convolutional neural network to predict a cost map of the track in front of the vehicle. Results are demonstrated on a 1:5 scale autonomous vehicle given the task of high speed, aggressive driving.},
archivePrefix = {arXiv},
arxivId = {1707.05303},
author = {Drews, Paul and Williams, Grady and Goldfain, Brian and Theodorou, Evangelos A and Rehg, James M},
booktitle = {Proceedings of the 1st Annual Conference on Robot Learning},
eprint = {1707.05303},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Drews et al. - 2017 - Aggressive Deep Driving Combining Convolutional Neural Networks and Model Predictive Control.pdf:pdf},
issn = {1938-7228},
keywords = {autonomous driving,convolutional neural networks,model predictive control},
pages = {133--142},
title = {{Aggressive Deep Driving: Combining Convolutional Neural Networks and Model Predictive Control}},
year = {2017}
}
@article{Drgona2018,
abstract = {Many studies have proven that the building sector can significantly benefit from replacing the current practice rule-based controllers (RBC) by more advanced control strategies like model predictive control (MPC). However, the optimization-based control algorithms, like MPC, impose increasing hardware and software requirements, together with more complicated error handling capabilities required from the commissioning staff. In recent years, several studies introduced promising remedy for these problems by using machine learning algorithms. The idea is based on devising simplified control laws learned from MPC. The main advantage of the proposed methods stems from their easy implementation even on low-level hardware. However, most of the reported studies were dealing only with problems with a limited complexity of the parametric space, and devising laws only for a single control variable, which inevitably limits their applicability to more complex building control problems. In this paper, we introduce a versatile framework for synthesis of simple, yet well-performing control strategies that mimic the behavior of optimization-based controllers, also for large scale multiple-input-multiple-output (MIMO) control problems which are common in the building sector. The approach employs multivariate regression and dimensionality reduction algorithms. Particularly, deep time delay neural networks (TDNN) and regression trees (RT) are used to derive the dependency of multiple real-valued control inputs on parameters. The complexity of the problem, as well as implementation cost, are further reduced by selecting the most significant features from the set of parameters. This reduction is based on straightforward manual selection, principal component analysis (PCA) and dynamic analysis of the building model. The approach is demonstrated on a case study employing temperature control in a six-zone building, described by a linear model with 286 states and 42 disturbances, resulting in an MPC problem with more than thousand of parameters. The results show that simplified control laws retain most of the performance of the complex MPC, while significantly decreasing the complexity and implementation cost.},
author = {Drgoňa, J{\'{a}}n and Picard, Damien and Kvasnica, Michal and Helsen, Lieve},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Drgoňa et al. - 2018 - Approximate model predictive building control via machine learning.pdf:pdf},
journal = {Applied Energy},
keywords = {Building climate control,Dimensionality reduction,Machine learning,Model predictive control,Regression trees,Time delay neural networks},
pages = {199--216},
title = {{Approximate model predictive building control via machine learning}},
volume = {218},
year = {2018}
}
@article{Dudley1967,
abstract = {1. THE SIZES OF COMPACT SETS The first two sections of this paper are introductory and correspond to the two halves of the title. As is well known, there is no complete analog of Lebesgue or Haar measure in an infinite-dimensional Hilbert space H, but there is a need for some measure of the sizes of subsets of H. In this paper we shall study subsets C of H which are closed, bounded, convex and symme-tric (-x E C if x E C). Such a set C will be called a Banach ball, since it is the unit ball of a complete Banach norm on its linear span. In most cases in this paper C will be compact. We use three main measures of the size of C. One is as follows. Let V, = V,(C) be the supremum of (n-dimensional Lebesgue) volumes of projections P,(C) where P, is any orthogonal projection with n-dimensional range. Then we define the exponent of volume of C, J-V), by 1{\%} vn EV(C) = lim sup {\~{}}. n+cc nlogn Another numerical measure of the size of C involves the notion of E-entropy [12]. Let (S, d) b e a metric space. The diameter of a set T C S is defined as sup (4{\%} r) : x, y E T). Given E {\textgreater} 0, one defines N(S, E) as the minimal number of sets of diameter at most 2{\~{}} which cover S. Then the r-entropy of S, H(S, E), * Fellow of the Alfred P. Sloan Foundation. 290 SIZES OF COMPACT SUBSETS OF HILBERT SPACE 291 is defined as log N(S, E). (The logarithm is taken to the base e. The ideas of information theory and thermodynamics play no explicit role in this paper.) Finally, we define the exponent of entropy r by (In case the lim sup is equal to a limit, r has been called the metric or{\&}v of S-see [12], p. 22.) We prove below (Proposition 5.8) that if EV(C) {\textgreater} -l/2, then r(C) = + co, while if H'(C) {\textless} -l/2, then r(C) {\textgreater}, -2 1 + 2EV(C) *},
author = {Dudley, R. M.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dudley - 1967 - The sizes of compact subsets of Hilbert space and continuity of Gaussian processes.pdf:pdf},
journal = {Journal of Functional Analysis},
number = {3},
pages = {290--330},
title = {{The Sizes of Compact Subsets of Hilbert Space and Continuity of Gaussian Processes}},
volume = {1},
year = {1967}
}
@article{Duivenvoorden2017,
abstract = {Tuning controller parameters is a recurring and time-consuming problem in control. This is especially true in the field of adaptive control, where good performance is typically only achieved after significant tuning. Recently, it has been shown that constrained Bayesian optimization is a promising approach to automate the tuning process without risking system failures during the optimization process. However, this approach is computationally too expensive for tuning more than a couple of parameters. In this paper, we provide a heuristic in order to efficiently perform constrained Bayesian optimization in high-dimensional parameter spaces by using an adaptive discretization based on particle swarms. We apply the method to the tuning problem of an L1adaptive controller on a quadrotor vehicle and show that we can reliably and automatically tune parameters in experiments.},
author = {Duivenvoorden, Rikky R.P.R. and Berkenkamp, Felix and Carion, Nicolas and Krause, Andreas and Schoellig, Angela P.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Duivenvoorden et al. - 2017 - Constrained Bayesian Optimization with Particle Swarms for Safe Adaptive Controller Tuning.pdf:pdf},
journal = {Proceedings of the IFAC World Congress},
keywords = {Adaptive Control,Constrained Bayesian Optimization,Gaussian Process,Particle Swarm Optimization,Policy Search,Reinforcement learning,Safety},
number = {1},
pages = {11800--11807},
publisher = {Elsevier B.V.},
title = {{Constrained Bayesian Optimization with Particle Swarms for Safe Adaptive Controller Tuning}},
volume = {50},
year = {2017}
}
@book{Dunford1988,
address = {Hoboken, New Jersey},
author = {Dunford, N. and Schwartz, J. T.},
file = {:home/alederer/Documents/Literatur/Books/Linear Operators Part I$\backslash$: General Theory.pdf:pdf},
publisher = {Wiley},
title = {{Linear Operators. Part I: General Theory.}},
year = {1988}
}
@inproceedings{El-Yaniv2011,
abstract = {Focusing on short term trend prediction in a financial context, we consider the problem of selective prediction whereby the predictor can abstain from prediction in order to improve performance. We examine two types of selective mechanisms for HMM predictors. The first is a rejection in the spirit of Chow's well-known ambiguity principle. The second is a specialized mechanism for HMMs that identifies low quality HMM states and abstain from prediction in those states. We call this model selective HMM (sHMM). In both approaches we can trade-off prediction coverage to gain better accuracy in a controlled manner. We compare performance of the ambiguity-based rejection technique with that of the sHMM approach. Our results indicate that both methods are effective, and that the sHMM model is superior.},
author = {El-Yaniv, Ran and Pidan, Dmitry},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/alederer/Documents/Literatur/Learning/Hidden Markov Models/Selective Prediction of Financial Trends with Hidden Markov Models.pdf:pdf},
pages = {855--863},
title = {{Selective prediction of financial trends with Hidden Markov Models}},
year = {2011}
}
@article{Endo2018,
author = {Endo, S and Pfister, F J and Fr{\"{o}}hner, J and Fietzek, U and Pichler, D and Abedinpour, K and Um, T T and Kuli{\'{c}}, D and Lang, M and Hirche, S},
file = {:home/alederer/Local/Literatur/Parkinson/Parkinson Prediction/Endo{\_}2018{\_}CPHS.pdf:pdf},
journal = {Second IFAC Conference on Cyber-Physical {\&} Human Systems},
keywords = {dynamical systems,gaussian processes,inertial sensors,medical applications},
title = {{Dynamics-based estimation of Parkinson's disease severity using Gaussian Processes}},
year = {2018}
}
@article{Esfahani2013,
archivePrefix = {arXiv},
arxivId = {arXiv:1307.0345v2},
author = {Esfahani, Peyman Mohajerin and Sutter, Tobias and Lygeros, John},
eprint = {arXiv:1307.0345v2},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Esfahani, Sutter, Lygeros - 2013 - Performance Bounds for the Scenario Approach and an Extension to a Class of Non-Convex Programs.pdf:pdf},
journal = {IEEE Transactions on Automatic Control},
number = {257005},
pages = {1--19},
title = {{Performance Bounds for the Scenario Approach and an Extension to a Class of Non-Convex Programs}},
volume = {60},
year = {2013}
}
@inproceedings{Fanger2016,
abstract = {Dynamic Movement Primitives (DMPs) represent stable goal-directed or periodic movements, which are learned from observations or demonstrations. They rely on proper function approximators, which are sufficiently flexible to represent arbitrary movements but also ensure goal convergence in pointtopoint motions. This work shows that Gaussian Processes (GPs) are suitable as a regressor for learning movements with DMPs ensuring stability. In addition, GPs provide a measure for the uncertainty about the current movement, which we exploit by proposing a new cooperation scheme for DMPs: For better reproduction of demonstrations, we follow the intuition, that individuals with more knowledge lead towards the goal, while others follow and focus on cooperation. Along with simulation results, we validate the presented methods in a robotic cooperative object manipulation task.},
author = {Fanger, Yunis and Umlauft, Jonas and Hirche, Sandra},
booktitle = {Proceedings of the IEEE Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2016.7759576},
file = {:home/alederer/Documents/Literatur/Learning/Stable Systems/Gaussian Processes for Dynamic Movement Primitives with Application in Knowledge-based Cooperation.pdf:pdf},
isbn = {9781509037629},
issn = {21530866},
pages = {3913--3919},
title = {{Gaussian Processes for Dynamic Movement Primitives with Application in Knowledge-based Cooperation}},
year = {2016}
}
@article{Faulwasser2016,
archivePrefix = {arXiv},
arxivId = {1502.02468},
author = {Faulwasser, Timm and Findeisen, Rolf},
doi = {10.1109/TAC.2015.2466911},
eprint = {1502.02468},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Faulwasser, Findeisen - 2016 - Nonlinear model predictive control for constrained output path following.pdf:pdf},
isbn = {0018-9286},
issn = {00189286},
journal = {IEEE Transactions on Automatic Control},
keywords = {Constraints,Nonlinear model predictive control,Path following,Stability,Transverse normal forms},
number = {4},
pages = {1026--1039},
title = {{Nonlinear model predictive control for constrained output path following}},
volume = {61},
year = {2016}
}
@article{Faulwasser2017,
abstract = {Many robotic applications, such as milling, gluing, or high precision measurements, require the exact following of a pre-defined geometric path. In this paper, we investigate the real-time feasible implementation of model predictive path-following control for an industrial robot. We consider constrained output path following with and without reference speed assignment. We present results from an implementation of the proposed model predictive path-following controller on a KUKA LWR IV robot.},
archivePrefix = {arXiv},
arxivId = {1506.09084},
author = {Faulwasser, Timm and Weber, Tobias and Zometa, Pablo and Findeisen, Rolf},
doi = {10.1109/TCST.2016.2601624},
eprint = {1506.09084},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Faulwasser et al. - 2017 - Implementation of Nonlinear Model Predictive Path-Following Control for an Industrial Robot.pdf:pdf},
issn = {10636536},
journal = {IEEE Transactions on Control Systems Technology},
keywords = {Constraints,KUKA LWR IV,nonlinear model predictive control (NMPC),optimal control,path following},
number = {4},
pages = {1505--1511},
title = {{Implementation of Nonlinear Model Predictive Path-Following Control for an Industrial Robot}},
volume = {25},
year = {2017}
}
@book{Feller1950,
address = {New York},
author = {Feller, William},
edition = {second},
file = {:home/alederer/Documents/Literatur/Books/An Introduction To Probability Theory And Its Applications.pdf:pdf},
publisher = {Wiley},
title = {{An Introduction to Probability Theory and Its Applications}},
year = {1950}
}
@article{Findeisen2003,
abstract = {The purpose of this paper is twofold. In the first part we give a review on the current state of nonlinear model predictive control (NMPC). After a brief presentation of the basic principle of predictive control we outline some of the theoretical, computational, and implementational aspects of this control strategy. Most of the theoretical developments in the area of NMPC are based on the assumption that the full state is available for measurement, an assumption that does not hold in the typical practical case. Thus, in the second part of this paper we focus on the output feedback problem in NMPC. After a brief overview on existing output feedback NMPC approaches we derive conditions that guarantee stability of the closed-loop if an NMPC state feedback controller is used together with a full state observer for the recovery of the system state.},
author = {Findeisen, Rolf and Imsland, Lars and Allgower, Frank and Foss, Bjarne A.},
doi = {10.3166/ejc.9.190-206},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Findeisen et al. - 2003 - State and Output Feedback Nonlinear Model Predictive Control An Overview.pdf:pdf},
issn = {09473580},
journal = {European Journal of Control},
keywords = {nonlinear model predictive control,output feedback,performance,stability},
number = {2-3},
pages = {190--206},
title = {{State and Output Feedback Nonlinear Model Predictive Control: An Overview}},
volume = {9},
year = {2003}
}
@book{Forbes2011,
address = {Hoboken, New Jersey},
author = {Forbes, Catherine and Evans, Merran and Hastings, Nicholas and Peacock, Brian},
edition = {fourth},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Forbes et al. - 2011 - Statistical Distributions.pdf:pdf},
publisher = {Wiley},
title = {{Statistical Distributions}},
year = {2011}
}
@inproceedings{Forbes2015,
abstract = {With decades of successful application of model predictive control (MPC) to industrial processes, practitioners are now focused on ease of commissioning, monitoring, and automation of maintenance. Many industries do not necessarily need better algorithms, but rather improved usability of existing technologies to allow a limited workforce of varying expertise to easily commission, use, and maintain these valued applications. Continuous performance monitoring, and automated model re-identification are being used as vendors work to deliver automated adaptive MPC. This paper examines industrial practice and emerging research trends towards providing sustained MPC performance.},
author = {Forbes, M. G. and Patwardhan, R. S. and Gopaluni, R. B.},
booktitle = {Advanced Control of Chemical Processes},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Forbes, Patwardhan, Gopaluni - 2015 - Model predictive control in industry challenges and opportunities.pdf:pdf},
keywords = {adaptive control,control applications,human factors,industrial control,model-based control,performance monitoring,predictive control,process control},
pages = {532--539},
title = {{Model predictive control in industry challenges and opportunities}},
year = {2015}
}
@article{Gaitsgory2018,
abstract = {We consider stabilization of an equilibrium point via infinite horizon discounted optimal control in discrete-time. In addition to applications in economics and social sciences, discounted optimal control is a commonly used numerical technique guaranteeing solvability of certain classes of optimal control problems. In this paper, we present conditions based on strict dissipativity that ensure that the optimally controlled system is asymptotically stable or practically asymptotically stable. These conditions are shown to be complementary to recently proposed conditions based on a detectability property. Illustrative examples are provided.},
author = {Gaitsgory, Vladimir and Gr{\"{u}}ne, Lars and H{\"{o}}ger, Matthias and Kellett, Christopher M. and Weller, Steven R.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gaitsgory et al. - 2018 - Stabilization of strictly dissipative discrete time systems with discounted optimal control.pdf:pdf},
journal = {Automatica},
keywords = {Discounted optimal control,Lyapunov function,Stabilization,Strict dissipativity},
pages = {311--320},
title = {{Stabilization of strictly dissipative discrete time systems with discounted optimal control}},
volume = {93},
year = {2018}
}
@inproceedings{Gandhi2017,
abstract = {How do you learn to navigate an Unmanned Aerial Vehicle (UAV) and avoid obstacles? One approach is to use a small dataset collected by human experts: however, high capacity learning algorithms tend to overfit when trained with little data. An alternative is to use simulation. But the gap between simulation and real world remains large especially for perception problems. The reason most research avoids using large-scale real data is the fear of crashes! In this paper, we propose to bite the bullet and collect a dataset of crashes itself! We build a drone whose sole purpose is to crash into objects: it samples naive trajectories and crashes into random objects. We crash our drone 11,500 times to create one of the biggest UAV crash dataset. This dataset captures the different ways in which a UAV can crash. We use all this negative flying data in conjunction with positive data sampled from the same trajectories to learn a simple yet powerful policy for UAV navigation. We show that this simple self-supervised model is quite effective in navigating the UAV even in extremely cluttered environments with dynamic obstacles including humans. For supplementary video see: https://youtu.be/u151hJaGKUo},
archivePrefix = {arXiv},
arxivId = {arXiv:1704.05588v2},
author = {Gandhi, Dhiraj and Pinto, Lerrel and Gupta, Abhinav},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2017.8206247},
eprint = {arXiv:1704.05588v2},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gandhi, Pinto, Gupta - 2017 - Learning to fly by crashing.pdf:pdf},
isbn = {9781538626825},
issn = {21530866},
pages = {3948--3955},
title = {{Learning to fly by crashing}},
year = {2017}
}
@article{Garatti2013,
abstract = {Many problems in systems and control, such as controller synthesis and state estimation, are often formulated as optimization problems. In many cases, the cost function incorporates variables that are used to model uncertainty, in addition to optimization variables, and this article employs uncertainty described as probabilistic variables. In a probabilistic setup, a cost value can only be guaranteed with a certain probability. Like pulling down one end of a rope wrapped around a pulley lifts the other end, decreasing the probability improves the cost value. This article analyzes this trade-off and describes quantitative tools to drive the user's choice toward a suitable compromise.},
author = {Garatti, Simone and Campi, Marco C},
doi = {10.1109/MCS.2012.2234964},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garatti, Campi - 2013 - Modulating robustness in control designPrinciples and algorithms.pdf:pdf},
issn = {1066-033X},
journal = {IEEE Control Systems},
number = {2},
pages = {36--51},
title = {{Modulating robustness in control design:Principles and algorithms}},
volume = {33},
year = {2013}
}
@article{Garatti2012,
author = {Garatti, Simone and Prandini, Maria},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garatti, Prandini - 2012 - Design in the presence of uncertainty the scenario approach Problem formulation.pdf:pdf},
pages = {1--23},
title = {{Design in the presence of uncertainty : the scenario approach Problem formulation}},
year = {2012}
}
@article{Gershgorin1931,
author = {Gershgorin, S.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gershgorin - 1931 - Ueber die Abgrenzung der Eigenwerte einer Matrix(3).pdf:pdf},
journal = {Bulletin de l'Academie des Sciences de l'URSS. Classe des sciences mathematiques et na},
number = {6},
pages = {749--754},
title = {{Ueber die Abgrenzung der Eigenwerte einer Matrix}},
year = {1931}
}
@article{Ghosal2006,
abstract = {Consider binary observations whose response probability is an unknown smooth function of a set of covariates. Suppose that a prior on the response probability function is induced by a Gaussian process mapped to the unit interval through a link function. In this paper we study consistency of the resulting posterior distribution. If the covariance kernel has derivatives up to a desired order and the bandwidth parameter of the kernel is allowed to take arbitrarily small values, we show that the posterior distribution is consistent in the L1-distance. As an auxiliary result to our proofs, we show that, under certain conditions, a Gaussian process assigns positive probabilities to the uniform neighborhoods of a continuous function. This result may be of independent interest in the literature for small ball probabilities of Gaussian processes.},
author = {Ghosal, Subhashis and Roy, Anindya},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghosal, Roy - 2006 - Posterior consistency of Gaussian process prior for nonparametric binary regression.pdf:pdf},
journal = {The Annals of Statistics},
number = {5},
pages = {2413--2429},
title = {{Posterior Consistency of Gaussian Process Prior for Nonparametric Binary Regression}},
volume = {34},
year = {2006}
}
@article{Giesl2008,
abstract = {The basin of attraction of an asymptotically stable fixed point of the discrete dynamical system given by the iteration xn + 1 = g (xn) can be determined through sublevel sets of a Lyapunov function. In Giesl [On the determination of the basin of attraction of discrete dynamical systems. J. Difference Equ. Appl. 13(6) (2007) 523-546] a Lyapunov function is constructed by approximating the solution of a difference equation using radial basis functions. However, the resulting Lyapunov function is non-local, i.e. it has no negative discrete orbital derivative in a neighborhood of the fixed point. In this paper we modify the construction method by using the Taylor polynomial and thus obtain a Lyapunov function with negative discrete orbital derivative both locally and globally. {\textcopyright} 2008 Elsevier Inc. All rights reserved.},
author = {Giesl, Peter},
doi = {10.1016/j.jat.2008.01.007},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Giesl - 2008 - Construction of a local and global Lyapunov function for discrete dynamical systems using radial basis functions.pdf:pdf},
issn = {00219045},
journal = {Journal of Approximation Theory},
keywords = {Basin of attraction,Discrete dynamical system,Error estimates,Lyapunov function,Radial basis functions},
number = {2},
pages = {184--211},
title = {{Construction of a local and global Lyapunov function for discrete dynamical systems using radial basis functions}},
volume = {153},
year = {2008}
}
@article{Giesl2014,
author = {Giesl, Peter and Hafstein, Sigurdur},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Giesl, Hafstein - 2014 - Computation of Lyapunov functions for nonlinear discrete.pdf:pdf},
journal = {Journal of Diffence Equations and Applications},
number = {4},
pages = {610--640},
title = {{Computation of Lyapunov functions for nonlinear discrete systems by linear programming}},
volume = {20},
year = {2014}
}
@article{Gijsberts2013,
abstract = {Novel applications in unstructured and non-stationary human environments require robots that learn from experience and adapt autonomously to changing conditions. Predictive models therefore not only need to be accurate, but should also be updated incrementally in real-time and require minimal human intervention. Incremental Sparse Spectrum Gaussian Process Regression is an algorithm that is targeted specifically for use in this context. Rather than developing a novel algorithm from the ground up, the method is based on the thoroughly studied Gaussian Process Regression algorithm, therefore ensuring a solid theoretical foundation. Non-linearity and a bounded update complexity are achieved simultaneously by means of a finite dimensional random feature mapping that approximates a kernel function. As a result, the computational cost for each update remains constant over time. Finally, algorithmic simplicity and support for automated hyperparameter optimization ensures convenience when employed in practice. Empirical validation on a number of synthetic and real-life learning problems confirms that the performance of Incremental Sparse Spectrum Gaussian Process Regression is superior with respect to the popular Locally Weighted Projection Regression, while computational requirements are found to be significantly lower. The method is therefore particularly suited for learning with real-time constraints or when computational resources are limited. {\textcopyright} 2012 Elsevier Ltd.},
author = {Gijsberts, Arjan and Metta, Giorgio},
doi = {10.1016/j.neunet.2012.08.011},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gijsberts, Metta - 2013 - Real-time model learning using Incremental Sparse Spectrum Gaussian Process Regression.pdf:pdf},
isbn = {1879-2782 (Electronic) 0893-6080 (Linking)},
issn = {08936080},
journal = {Neural Networks},
keywords = {Function approximation,Incremental learning,Online learning,Real-time,Robotics},
pages = {59--69},
pmid = {22985935},
publisher = {Elsevier Ltd},
title = {{Real-time model learning using Incremental Sparse Spectrum Gaussian Process Regression}},
volume = {41},
year = {2013}
}
@book{Gilks1995,
address = {New York},
editor = {Gilks, W.R. and Richardson, S. and Spiegelhalter, D.J.},
file = {:home/alederer/Documents/Literatur/Learning/Hidden Markov Models/Markov Chain Monte Carlo in Practice.pdf:pdf},
publisher = {Chapman {\&} Hall},
title = {{Markov Chain Monte Carlo in Practice}},
year = {1995}
}
@phdthesis{Girard2004,
abstract = {This thesis presents extensions of the Gaussian Process (GP) model, based on approximate methods allowing the model to deal with input uncertainty. Zero-mean GPs with Gaussian covariance function are of particular interest, as they allow to carry out many derivations exactly, as well as having been shown to have modelling abilities and predictive performance comparable to that of neural networks (Rasmussen, 1996a). With this model, given observed data and a new input, making a prediction corresponds to computing the (Gaussian) predictive distribution of the associated output, whose mean can be used as an estimate. This way, the predictive variance provides error-bars or confidence intervals on this estimate: It quantifies the model's degree of belief in its ‘best guess'. Using the knowledge of the predictive variance in an informative manner is at the centre of this thesis, as the problems of how to propagate it in the model, how to account for it when derivative observations are available, and how to derive a control law with a cautious behaviour are addressed. The task of making a prediction when the new input presented to the model is noisy is introduced. Assuming a normally distributed input, only the mean and variance of the corresponding non-Gaussian predictive distribution are computed (Gaussian approximation). Depending on the parametric form of the covariance function of the process, exact or approximate moments are derived. These results are then used for the multiple-step-ahead iterative forecasting of nonlinear dynamic systems, with propagation of the uncertainty. Within a nonlinear auto-regressive representation of the system, modelled by a GP, a one-step-ahead model is iterated up to the desired horizon. At each time-step, the uncertainty induced by each successive prediction is propagated, that is, the whole predictive distribution of the output just predicted is fed back into the state for the next time-step. Not only are the predictive variances of each delayed output accounted for, but also the cross-covariances between them. The approach is illustrated on the simulated Mackey-Glass chaotic time-series, as well as on two real-life dynamic processes, a gas-liquid separator and a pH neutralisation process. The emphasis is on the use of Gaussian Processes for modelling nonlinear dynamic systems. GPs have not yet gained widespread popularity among the engineering community. It is well known that the modelling of such systems is in practice rendered difficult by the fact that most available data lies around equilibrium regions, and very few points in transient areas, and a common approach has been to consider linearisations around those equilibrium points. Derivative observations can be elegantly integrated in a GP model where function observations are already available, as shown in (Solak et al., 2003). As well as being in accord with engineering practice, derivative observations can potentially reduce the computational burden usually associated with GPs (typically, a linear region can be summarised by one derivative observation, instead of many function observations). For this mixed training set, the explicit expressions of the predictive mean and variance of a function output corresponding to a noise-free and to a noisy input are then derived, the latter being tackled within the Gaussian approximation. The other field where GPs can present an advantage other over models is in the control of nonlinear dynamic systems. Commonly, researchers have used nonlinear parametric models and have adopted the certainty equivalence principle when deriving the control law, whereby the model's predictions are used as if they were the true system's outputs. Deriving controllers with ‘cautious' and ‘probing' features is difficult and has been the scope of much work in the control community. The propagation of uncertainty method is applied for a cautious controller, where the cautiousness is accounted for in a cost function that does not disregard the variance associated with the model's estimate.},
author = {Girard, Agathe},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Girard - 2004 - Approximate methods for propagation of uncertainty with Gaussian process models.pdf:pdf},
school = {University of Glasgow},
title = {{Approximate methods for propagation of uncertainty with Gaussian process models}},
year = {2004}
}
@article{Girard2003,
abstract = {We consider the problem of multi-step ahead prediction in time series analysis using the non-parametric Gaussian process model. k-step ahead forecasting of a discrete-time non-linear dynamic system can be performed by doing repeated one-step ahead predictions. For a state-space model of the form y t = f(Yt-1 ,..., Yt-L ), the prediction of y at time t + k is based on the point estimates of the previous outputs. In this paper, we show how, using an analytical Gaussian approximation, we can formally incorporate the uncertainty about intermediate regressor values, thus updating the uncertainty on the current prediction.},
author = {Girard, Agathe and Rasmussen, Carl Edward and Candela, Joaquin Quinonero and Murray-Smith, Roderick},
file = {:home/alederer/Documents/Literatur/Reinforcement Learning/Multi-step predictions/Gaussian Process Priors With Uncertain Inputs
Application to Multiple-Step Ahead Time Series
Forecasting
.pdf:pdf},
isbn = {0-262-02550-7},
issn = {1049-5258},
journal = {Advances in Neural Information Processing Systems},
pages = {545--552},
title = {{Gaussian process priors with uncertain inputs-application to multiple-step ahead time series forecasting}},
year = {2003}
}
@techreport{Girard2002,
abstract = {Abstract We consider the problem of multi-step ahead prediction in time series analysis using the non-parametric Gaussian process model. k-step ahead forecasting of a discrete- time nonlinear dynamic system can be performed by doing repeated one-step ahead ... {\$}\backslash{\$}n},
author = {Girard, Agathe and Rasmussen, Carl Edward and Murray-Smith, Roderick},
booktitle = {Technical Report TR-2002-119},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Girard, Rasmussen, Murray-Smith - 2002 - Gaussian Process priors with Uncertain Inputs Multiple-Step-Ahead Prediction(2).pdf:pdf},
pages = {1--18},
title = {{Gaussian Process priors with Uncertain Inputs : Multiple-Step-Ahead Prediction}},
year = {2002}
}
@inproceedings{Goel2017,
abstract = {Optimal stopping problems consider the question of deciding when to stop an observation-generating process in order to maximize a return. We examine the problem of simultaneously learning and planning in such domains, when data is collected directly from the environment. We propose GFSE, a simple and flexible model-free policy search method that reuses data for sample efficiency by leveraging problem structure. We bound the sample complexity of our approach to guarantee uniform convergence of policy value estimates, tightening existing PAC bounds to achieve logarithmic dependence on horizon length for our setting. We also examine the benefit of our method against prevalent model-based and model-free approaches on 3 domains taken from diverse fields.},
archivePrefix = {arXiv},
arxivId = {arXiv:1702.06238v2},
author = {Goel, Karan and Dann, Christoph and Brunskill, Emma},
booktitle = {IJCAI International Joint Conference on Artificial Intelligence},
eprint = {arXiv:1702.06238v2},
file = {:home/alederer/Documents/Literatur/Learning/Reinforcement Learning Problems/Sample Efficient Policy Search for Optimal Stopping Domains.pdf:pdf},
isbn = {9780999241103},
issn = {10450823},
pages = {1711--1717},
title = {{Sample efficient policy search for optimal stopping domains}},
year = {2017}
}
@inproceedings{Gonzalez2016,
abstract = {The popularity of Bayesian optimization methods for efficient exploration of parameter spaces has lead to a series of papers applying Gaussian processes as surrogates in the optimization of functions. However, most proposed approaches only allow the exploration of the parameter space to occur sequentially. Often, it is desirable to simultaneously propose batches of parameter values to explore. This is particularly the case when large parallel processing facilities are available. These facilities could be computational or physical facets of the process being optimized. E.g. in biological experiments many experimental set ups allow several samples to be simultaneously processed. Batch methods, however, require modeling of the interaction between the evaluations in the batch, which can be expensive in complex scenarios. We investigate a simple heuristic based on an estimate of the Lipschitz constant that captures the most important aspect of this interaction (i.e. local repulsion) at negligible computational overhead. The resulting algorithm compares well, in running time, with much more elaborate alternatives. The approach assumes that the function of interest, {\$}f{\$}, is a Lipschitz continuous function. A wrap-loop around the acquisition function is used to collect batches of points of certain size minimizing the non-parallelizable computational effort. The speed-up of our method with respect to previous approaches is significant in a set of computationally expensive experiments.},
author = {Gonz{\'{a}}lez, Javier and Dai, Zhenwen and Hennig, Philipp and Lawrence, Neil D.},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Statistics},
file = {:home/alederer/Documents/Literatur/Reinforcement Learning/Bandit Problems/Batch Bayesian Optimization via Local Penalization.pdf:pdf},
pages = {648--657},
title = {{Batch Bayesian Optimization via Local Penalization}},
year = {2016}
}
@book{Goodfellow2016,
author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
file = {:home/alederer/Documents/Literatur/Books/Deep Learning.pdf:pdf},
publisher = {MIT Press},
title = {{Deep Learning}},
year = {2016}
}
@article{Gopalan2012,
abstract = {Time series data of high dimensions are frequently encountered in fields like robotics, computer vision, economics and motion capture. In this survey paper we look first at Gaussian Process Latent Variable Model (GPLVM) which is a proba-bilistic nonlinear dimensionality reduction method. Further we discuss Gaussian Process Dynamical Model (GPDMs) which are based GPLVM. GPDM is a proba-bilistic approach to model high dimensional time series data in a low dimensional latent space with a dynamical model. We also discuss variational approximations of GPLVM and Variational Gaussian Process Dynamical System (VGPDS) which is a dynamical model based on these variational approximations.},
author = {Gopalan, Nakul},
file = {:home/alederer/Local/Literatur/Parkinson/GP Modelling/Gaussian Process Latent Variable Models for Dimensionality Reduction and Time Series Modeling.pdf:pdf},
number = {1},
pages = {1--10},
title = {{Gaussian Process Latent Variable Models for Dimensionality Reduction and Time Series Modeling}},
url = {https://www.ias.informatik.tu-darmstadt.de/uploads/Teaching/RobotLearningSeminar/Goppalan{\_}RLS{\_}2012.pdf},
year = {2012}
}
@article{Gottesman2019,
abstract = {We consider a model-based approach to perform batch off-policy evaluation in reinforcement learning. Our method takes a mixture-of-experts approach to combine parametric and non-parametric models of the environment such that the final value estimate has the least expected error. We do so by first estimating the local accuracy of each model and then using a planner to select which model to use at every time step as to minimize the return error estimate along entire trajectories. Across a variety of domains, our mixture-based approach outperforms the individual models alone as well as state-of-the-art importance sampling-based estimators.},
archivePrefix = {arXiv},
arxivId = {1905.05787},
author = {Gottesman, Omer and Liu, Yao and Sussex, Scott and Brunskill, Emma and Doshi-Velez, Finale},
eprint = {1905.05787},
file = {:home/alederer/Documents/Literatur/Learning/Off-Policy Policy Evaluation/Combining Parametric and Nonparametric Models for Off-Policy Evaluation.pdf:pdf},
title = {{Combining Parametric and Nonparametric Models for Off-Policy Evaluation}},
url = {http://arxiv.org/abs/1905.05787},
year = {2019}
}
@article{Gramacy2015,
abstract = {We provide a new approach to approximate emulation of large computer experiments. By focusing expressly on desirable properties of the predictive equations, we derive a family of local sequential design schemes that dynamically define the support of a Gaussian process predictor based on a local subset of the data. We further derive expressions for fast sequential updating of all needed quantities as the local designs are built-up iteratively. Then we show how independent application of our local design strategy across the elements of a vast predictive grid facilitates a trivially parallel implementation. The end result is a global predictor able to take advantage of modern multicore architectures, while at the same time allowing for a nonstationary modeling feature as a bonus. We demonstrate our method on two examples utilizing designs sized in the thousands, and tens of thousands of data points. Comparisons are made to the method of compactly supported covariances.},
archivePrefix = {arXiv},
arxivId = {arXiv:1303.0383v4},
author = {Gramacy, Robert B. and Apley, Daniel W.},
doi = {10.1080/10618600.2014.914442},
eprint = {arXiv:1303.0383v4},
file = {:home/alederer/Documents/Literatur/Learning/Local GP/Local Gaussian Process Approximation for Large Computer Experiments.pdf:pdf},
issn = {15372715},
journal = {Journal of Computational and Graphical Statistics},
keywords = {Active learning,Compactly supported,Covariance,Emulator,Local kriging neighborhoods,Sequential design,Sequential updating,Surrogate model},
number = {2},
pages = {561--578},
title = {{Local Gaussian Process Approximation for Large Computer Experiments}},
volume = {24},
year = {2015}
}
@article{Gramacy2014,
abstract = {We explore how the big-three computing paradigms -- symmetric multi-processor (SMC), graphical processing units (GPUs), and cluster computing -- can together be brought to bare on large-data Gaussian processes (GP) regression problems via a careful implementation of a newly developed local approximation scheme. Our methodological contribution focuses primarily on GPU computation, as this requires the most care and also provides the largest performance boost. However, in our empirical work we study the relative merits of all three paradigms to determine how best to combine them. The paper concludes with two case studies. One is a real data fluid-dynamics computer experiment which benefits from the local nature of our approximation; the second is a synthetic data example designed to find the largest design for which (accurate) GP emulation can performed on a commensurate predictive set under an hour.},
author = {Gramacy, Robert B. and Niemi, Jarad and Weiss, Robin M.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gramacy, Niemi, Weiss - 2014 - Massively parallel approximate Gaussian process regression.pdf:pdf},
journal = {SIAM/ASA Journal on Uncertainty Quantification},
keywords = {big data,cluster computing,computer experiment,emulator,graphical processing unit,multi-processor,nonparametric regression,symmetric},
number = {1},
pages = {564--584},
title = {{Massively parallel approximate Gaussian process regression}},
volume = {2},
year = {2014}
}
@article{Grammatico2016,
abstract = {Randomized optimization is an established tool for control design with modulated robustness. While for uncertain convex programs there exist randomized approaches with efficient sampling, this is not the case for non-convex problems. Approaches based on statistical learning theory are applicable to non-convex problems, but they usually are conservative in terms of performance and require high sample complexity to achieve the desired probabilistic guarantees. In this paper, we derive a novel scenario approach for a wide class of random non-convex programs, with a sample complexity similar to that of uncertain convex programs and with probabilistic guarantees that hold not only for the optimal solution of the scenario program, but for all feasible solutions inside a set of a-priori chosen complexity. We also address measure-theoretic issues for uncertain convex and non-convex programs. Among the family of non-convex control- design problems that can be addressed via randomization, we apply our scenario approach to randomized Model Predictive Control for chance-constrained nonlinear control-affine systems.},
archivePrefix = {arXiv},
arxivId = {1401.2200},
author = {Grammatico, Sergio and Zhang, Xiaojing and Margellos, Kostas and Goulart, Paul and Lygeros, John},
doi = {10.1109/TAC.2015.2433591},
eprint = {1401.2200},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Grammatico et al. - 2016 - A Scenario Approach for Non-Convex Control Design.pdf:pdf},
isbn = {9781479932726},
issn = {00189286},
journal = {IEEE Transactions on Automatic Control},
keywords = {Chance constrained programs (CCPs),model predictive control (MPC),scenario program (SP)},
number = {2},
pages = {334--345},
title = {{A Scenario Approach for Non-Convex Control Design}},
volume = {61},
year = {2016}
}
@inproceedings{Grancharova2007,
abstract = {Nonlinear Model Predictive Control (NMPC) algorithms are based on various nonlinear models. Recently, an on-line optimization approach for stochastic NMPC based on a Gaussian process model was proposed. A significant advantage of the Gaussian process models is that they provide information about prediction uncertainties, which would be of help in NMPC design. On the other hand, an explicit solution to the stochastic NMPC problem based on Gaussian process model would allow efficient on-line computations as well as verifiability of the implementation. This paper suggests an approximate multi-parametric Nonlinear Programming approach to explicit solution of stochastic NMPC problems for constrained nonlinear systems based on Gaussian process model. In particular, the reference tracking problem is considered. The approach builds an orthogonal search tree structure of the state space partition and consists in constructing a feasible PWL approximation to the optimal control sequence.},
author = {Grancharova, Alexandra and Kocijan, J. and Johansen, T.a.},
booktitle = {Proceedings of the 9th European Control Conference},
doi = {10.1007/978-3-642-28780-0},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Grancharova, Kocijan, Johansen - 2007 - Explicit stochastic nonlinear predictive control based on Gaussian process models.pdf:pdf},
isbn = {978-3-642-28779-4},
pages = {2340--2347},
title = {{Explicit stochastic nonlinear predictive control based on Gaussian process models}},
year = {2007}
}
@article{Grancharova2008,
abstract = {Energy production is one of the largest sources of air pollution. A feasible method to reduce the harmful flue gases emissions and to increase the efficiency is to improve the control strategies of the existing thermoelectric power plants. This makes the Nonlinear Model Predictive Control (NMPC) method very suitable for achieving an efficient combustion control. Recently, an explicit approximate approach for stochastic NMPC based on a Gaussian process model was proposed. The benefits of an explicit solution, in addition to the efficient on-line computations, include also verifiability of the implementation, which is an essential issue in safety-critical applications. This paper considers the application of an explicit approximate approach for stochastic NMPC to the design of an explicit reference tracking NMPC controller for a combustion plant based on its Gaussian process model. The controller brings the air factor (respectively the concentration of oxygen in the flue gases) on its optimal value with every change of the load factor and thus an optimal operation of the combustion plant is achieved. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Grancharova, Alexandra and Kocijan, Ju{\v{s}} and Johansen, Tor A.},
doi = {10.1016/j.automatica.2008.04.002},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Grancharova, Kocijan, Johansen - 2008 - Explicit stochastic predictive control of combustion plants based on Gaussian process models.pdf:pdf},
isbn = {978-3-642-28779-4},
issn = {00051098},
journal = {Automatica},
keywords = {Model predictive control,Multi-parametric nonlinear programming,Power plants,Probabilistic models,Stochastic systems},
number = {6},
pages = {1621--1631},
title = {{Explicit stochastic predictive control of combustion plants based on Gaussian process models}},
volume = {44},
year = {2008}
}
@inproceedings{Gregorcic2003,
abstract = {To improve transparency and reduce the curse of dimensionality of non-linear black-box models, the local modelling approach was proposed. Poor transient response of local model networks led to the use of non-parametrical probabilistic models such as the Gaussian process prior approach. Recently, Gaussian process models were applied for minimum variance model for non-linear internal model control. The invertibility of the Gaussian process model is discussed and the use of predicted variance is illustrated on a simulated example.},
author = {Gregor{\v{c}}i{\v{c}}, G. and Lightbody, G.},
booktitle = {Proceedings of the American Control Conference 2003},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gregor{\v{c}}i{\v{c}}, Lightbody - 2003 - Internal model control based on a Gaussian process prior model.pdf:pdf},
isbn = {0-7803-7896-2},
issn = {0743-1619},
keywords = {Gaussian process model,internal model control,local modelling approach,local network models,minimum variance control,nonlinear black-box models,nonlinear internal model control,poor transient response},
pages = {4981 -- 4986},
title = {{Internal model control based on a Gaussian process prior model}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1242513},
year = {2003}
}
@article{Gregorcic2007,
abstract = {A Bayesian Gaussian process (GP) modeling approach has recently been introduced to model-based control strategies. The estimate of the variance of the predicted output is the most useful advantage of GPs in comparison to neural networks (NNs) and fuzzy models. However, the GP model is computationally demanding and nontransparent. To reduce the computation load and increase transparency, a local linear GP model network is proposed in this paper. The proposed methodology combines the local model network principle with the GP prior approach. A novel algorithm for structure determination and optimization is introduced, which is widely applicable to the training of local model networks. The modeling procedure of the local linear GP (LGP) model network is demonstrated on an example of a nonlinear laboratory scale process rig.},
author = {Gregor{\v{c}}i{\v{c}}, Gregor and Lightbody, Gordon},
doi = {10.1109/TNN.2007.895825},
file = {:home/alederer/Documents/Literatur/Learning/Local GP/Local Model Network Identification
With Gaussian Processes.pdf:pdf},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
keywords = {Gaussian processes (GPs),Local linear Gaussian process model network,Nonlinear system identification,Prediction variance,Structure optimization},
number = {5},
pages = {1404--1423},
title = {{Local model network identification with Gaussian processes}},
volume = {18},
year = {2007}
}
@article{Grosso2014,
abstract = {This paper addresses a chance-constrained model predictive control (CC-MPC) strategy for the management of drinking water networks (DWNs) based on a finite horizon stochastic optimisation problem with joint probabilistic (chance) constraints. In this approach, water demands are considered additive stochastic disturbances with non-stationary uncertainty description, unbounded support and known (or approximated) quasi-concave probabilistic distribution. A deterministic equivalent of the stochastic problem is formulated using Boole's inequality to decompose joint chance constraints into single chance constraints and by considering a uniform allocation of risk to bound these later constraints. The resultant deterministic-equivalent optimisation problem is suitable to be solved with tractable quadratic programming (QP) or second order cone programming (SOCP) algorithms. The reformulation allows to explicitly and easily propagate uncertainty over the prediction horizon, and leads to a cost-efficient management of risk that consists in a dynamic back-off to avoid frequent violation of constraints. Results of applying the proposed approach to a real case study – the Barcelona DWN (Spain) – have shown that the network performance (in terms of operational costs) and the necessary back-off (to cope with stochastic disturbances) are optimised simultaneously within a single problem, keeping tractability of the solution, even in large-scale networks. The general formulation of the approach and the automatic computation of proper back-off within the MPC framework replace the need of experience-based heuristics or bi-level optimisation schemes that might compromise the trade-off between profits, reliability and computational burden.},
author = {Grosso, J.M. and Ocampo-Mart{\'{i}}nez, C. and Puig, V. and Joseph, B.},
doi = {10.1016/j.jprocont.2014.01.010},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Grosso et al. - 2014 - Chance-constrained model predictive control for drinking water networks.pdf:pdf},
issn = {09591524},
journal = {Journal of Process Control},
keywords = {Chance constraints,Drinking water networks,MPC,Reliability,Robustness},
number = {5},
pages = {504--516},
title = {{Chance-constrained model predictive control for drinking water networks}},
volume = {24},
year = {2014}
}
@book{Grune2017,
author = {Gr{\"{u}}ne, Lars and Pannek, J{\"{u}}rgen},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gr{\"{u}}ne, Pannek - 2017 - Nonlinear Model Predictive Control Theory and Algorithms.pdf:pdf},
keywords = {NMPC},
publisher = {Springer Nature},
title = {{Nonlinear Model Predictive Control: Theory and Algorithms}},
year = {2017}
}
@article{Grunewalder2010,
author = {Gr{\"{u}}new{\"{a}}lder, Steffen and Audibert, Jean-Yves and Opper, Manfred and Shawe-Taylor, John},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gr{\"{u}}new{\"{a}}lder et al. - 2010 - Regret Bounds for Gaussian Process Bandit Problems.pdf:pdf},
journal = {Journal of Machine Learning Research},
pages = {273--280},
title = {{Regret Bounds for Gaussian Process Bandit Problems}},
volume = {9},
year = {2010}
}
@article{Guo2017,
abstract = {Evaluating a policy by deploying it in the real world can be risky and costly. Off-policy policy evaluation (OPE) algorithms use historical data collected from running a previous policy to evaluate a new policy, which provides a means for evaluating a policy without requiring it to ever be deployed. Importance sampling is a popular OPE method because it is robust to partial observability and works with continuous states and actions. However, the amount of historical data required by importance sampling can scale exponentially with the horizon of the problem: the number of sequential decisions that are made. We propose using policies over temporally extended actions, called options, and show that combining these policies with importance sampling can significantly improve performance for long-horizon problems. In addition, we can take advantage of special cases that arise due to options-based policies to further improve the performance of importance sampling. We further generalize these special cases to a general covariance testing rule that can be used to decide which weights to drop in an IS estimate, and derive a new IS algorithm called Incremental Importance Sampling that can provide significantly more accurate estimates for a broad class of domains.},
archivePrefix = {arXiv},
arxivId = {1703.03453},
author = {Guo, Zhaohan Daniel and Thomas, Philip S. and Brunskill, Emma},
eprint = {1703.03453},
file = {:home/alederer/Documents/Literatur/Learning/Off-Policy Policy Evaluation/Using Options and Covariance Testing for Long Horizon Off-Policy Policy Evaluation.pdf:pdf},
number = {Nips},
title = {{Using Options and Covariance Testing for Long Horizon Off-Policy Policy Evaluation}},
url = {http://arxiv.org/abs/1703.03453},
year = {2017}
}
@article{Hadidi1979,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Hadidi, M.T. and Schwartz, S.C.},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:home/alederer/Documents/Literatur/Learning for Control/Gaussian Noise/Linear Recursive State Estimators Under Uncertain Observations.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
journal = {IEEE Transactions on Automatic Control},
keywords = {icle},
number = {6},
pages = {944--948},
pmid = {25246403},
title = {{Linear Recursive State Estimators Under Uncertain Observations}},
volume = {24},
year = {1979}
}
@article{Hafstein2014,
abstract = {We present a novel numerical technique for the computation of a Lyapunov function for nonlinear systems with an asymptotically stable equilibrium point. Our proposed approach constructs a continuous piecewise affine (CPA) function given a suitable partition of the state space, called a triangulation, and values at the vertices of the triangulation. The vertex values are obtained from a Lyapunov function in a classical converse Lyapunov theorem and verification that the obtained CPA function is a Lyapunov function is shown to be equivalent to verification of several simple inequalities. Furthermore, by refining the triangulation, we show that it is always possible to construct a CPA Lyapunov function. Numerical examples are presented demonstrating the effectiveness of the proposed method. {\textcopyright} 2014 American Automatic Control Council.},
author = {Hafstein, Sigurdur and Kellett, Christopher M. and Li, Huijuan},
doi = {10.1109/ACC.2014.6858660},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hafstein, Kellett, Li - 2014 - Continuous and piecewise affine Lyapunov functions using the Yoshizawa construction.pdf:pdf},
isbn = {9781479932726},
issn = {07431619},
journal = {Proceedings of the American Control Conference},
keywords = {Computational methods,Nonlinear systems},
pages = {548--553},
title = {{Continuous and piecewise affine Lyapunov functions using the Yoshizawa construction}},
year = {2014}
}
@article{Harrison2018,
abstract = {Gaussian Process (GP) regression has seen widespread use in robotics due to its generality, simplicity of use, and the utility of Bayesian predictions. The predominant implementation of GP regression is a nonparameteric kernel-based approach, as it enables fitting of arbitrary nonlinear functions. However, this approach suffers from two main drawbacks: (1) it is computationally inefficient, as computation scales poorly with the number of samples; and (2) it can be data inefficient, as encoding prior knowledge that can aid the model through the choice of kernel and associated hyperparameters is often challenging and unintuitive. In this work, we propose ALPaCA, an algorithm for efficient Bayesian regression which addresses these issues. ALPaCA uses a dataset of sample functions to learn a domain-specific, finite-dimensional feature encoding, as well as a prior over the associated weights, such that Bayesian linear regression in this feature space yields accurate online predictions of the posterior predictive density. These features are neural networks, which are trained via a meta-learning (or "learning-to-learn") approach. ALPaCA extracts all prior information directly from the dataset, rather than restricting prior information to the choice of kernel hyperparameters. Furthermore, by operating in the weight space, it substantially reduces sample complexity. We investigate the performance of ALPaCA on two simple regression problems, two simulated robotic systems, and on a lane-change driving task performed by humans. We find our approach outperforms kernel-based GP regression, as well as state of the art meta-learning approaches, thereby providing a promising plug-in tool for many regression tasks in robotics where scalability and data-efficiency are important.},
archivePrefix = {arXiv},
arxivId = {1807.08912},
author = {Harrison, James and Sharma, Apoorva and Pavone, Marco},
eprint = {1807.08912},
file = {:home/alederer/Documents/Literatur/Learning/Online Learning/Meta-Learning Priors for Efficient Online Bayesian Regression.pdf:pdf},
title = {{Meta-Learning Priors for Efficient Online Bayesian Regression}},
url = {http://arxiv.org/abs/1807.08912},
year = {2018}
}
@inproceedings{Hazan2018,
abstract = {We give a polynomial-time algorithm for learning latent-state linear dynamical systems without system identification, and without assumptions on the spectral radius of the system's transition matrix. The algorithm extends the recently introduced technique of spectral filtering, previously applied only to systems with a symmetric transition matrix, using a novel convex relaxation to allow for the efficient identification of phases.},
author = {Hazan, Elad and Lee, Holden and Singh, Karan and Zhang, Cyril and Zhang, Yi},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hazan et al. - 2018 - Spectral filtering for general linear dynamical systems.pdf:pdf},
issn = {10495258},
pages = {4634--4643},
title = {{Spectral filtering for general linear dynamical systems}},
year = {2018}
}
@inproceedings{Hazan2017,
abstract = {We present an efficient and practical algorithm for the online prediction of discrete-time linear dynamical systems with a symmetric transition matrix. We circumvent the non-convex optimization problem using improper learning: carefully overparameterize the class of LDSs by a polylogarithmic factor, in exchange for convexity of the loss functions. From this arises a polynomial-time algorithm with a near-optimal regret guarantee, with an analogous sample complexity bound for agnostic learning. Our algorithm is based on a novel filtering technique, which may be of independent interest: we convolve the time series with the eigenvectors of a certain Hankel matrix.},
author = {Hazan, Elad and Singh, Karan and Zhang, Cyril},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hazan, Singh, Zhang - 2017 - Learning linear dynamical systems via spectral filtering.pdf:pdf},
issn = {10495258},
pages = {6703--6713},
title = {{Learning linear dynamical systems via spectral filtering}},
year = {2017}
}
@article{Hedjar2016,
author = {Hedjar, Ramdane and Bounkhel, Messaoud},
doi = {10.1177/1687814016643639},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hedjar, Bounkhel - 2016 - Wireless model predictive control Application to water-level system.pdf:pdf},
issn = {1687-8140},
journal = {Advances in Mechanical Engineering},
keywords = {16 march 2016,24 december 2015,academic editor,accepted,date received,integral action,jianyong yao,model predictive control,water-level systems,wireless communication},
number = {4},
pages = {1--13},
title = {{Wireless model predictive control : Application to water-level system}},
volume = {8},
year = {2016}
}
@inproceedings{Helwa2018,
abstract = {Lagrangian systems represent a wide range of robotic systems, including manipulators, wheeled and legged robots, and quadrotors. Inverse dynamics control and feedforward linearization techniques are typically used to convert the complex nonlinear dynamics of Lagrangian systems to a set of decoupled double integrators, and then a standard, outer-loop controller can be used to calculate the commanded acceleration for the linearized system. However, these methods typically depend on having a very accurate system model, which is often not available in practice. While this challenge has been addressed in the literature using different learning approaches, most of these approaches do not provide safety guarantees in terms of stability of the learning-based control system. In this paper, we provide a novel, learning-based control approach based on Gaussian processes (GPs) that ensures both stability of the closed-loop system and high-accuracy tracking. We use GPs to approximate the error between the commanded acceleration and the actual acceleration of the system, and then use the predicted mean and variance of the GP to calculate an upper bound on the uncertainty of the linearized model. This uncertainty bound is then used in a robust, outer-loop controller to ensure stability of the overall system. Moreover, we show that the tracking error converges to a ball with a radius that can be made arbitrarily small. Furthermore, we verify the effectiveness of our approach via simulations on a 2 degree-of-freedom (DOF) planar manipulator and experimentally on a 6 DOF industrial manipulator.},
author = {Helwa, Mohamed K. and Heins, Adam and Schoellig, Angela P.},
booktitle = {Proceedings of the IEEE Conference on Decision and Control},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Helwa, Heins, Schoellig - 2018 - Provably Robust Learning-Based Approach for High-Accuracy Tracking Control of Lagrangian Systems.pdf:pdf},
title = {{Provably Robust Learning-Based Approach for High-Accuracy Tracking Control of Lagrangian Systems}},
year = {2018}
}
@article{Hertneck2018,
author = {Hertneck, Michael and K{\"{o}}hler, Johannes and Trimpe, Sebastian and Allg{\"{o}}wer, Frank},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hertneck et al. - 2018 - Learning an Approximate Model Predictive Controller with Guarantees.pdf:pdf},
journal = {IEEE Control Systems Letters},
number = {3},
pages = {543--548},
title = {{Learning an Approximate Model Predictive Controller with Guarantees}},
volume = {2},
year = {2018}
}
@inproceedings{Hewing2017a,
abstract = {This paper presents an adaptive high performance control method for autonomous miniature race cars. Racing dynamics are notoriously hard to model from first principles, which is addressed by means of a cautious nonlinear model predictive control (NMPC) approach that learns to improve its dynamics model from data and safely increases racing performance. The approach makes use of a Gaussian Process (GP) and takes residual model uncertainty into account through a chance constrained formulation. We present a sparse GP approximation with dynamically adjusting inducing inputs, enabling a real-time implementable controller. The formulation is demonstrated in simulations, which show significant improvement with respect to both lap time and constraint satisfaction compared to an NMPC without model learning.},
archivePrefix = {arXiv},
arxivId = {1711.06586},
author = {Hewing, Lukas and Liniger, Alexander and Zeilinger, Melanie N.},
booktitle = {Proceedings of the 2018 European Control Conference},
eprint = {1711.06586},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hewing, Liniger, Zeilinger - 2018 - Cautious NMPC with Gaussian Process Dynamics for Miniature Race Cars.pdf:pdf},
pages = {1341--1348},
title = {{Cautious NMPC with Gaussian Process Dynamics for Miniature Race Cars}},
year = {2018}
}
@article{Hewing2017,
abstract = {Gaussian process (GP) regression has been widely used in supervised machine learning for its flexibility and inherent ability to describe uncertainty in the function estimation. In the context of control, it is seeing increasing use for modeling of nonlinear dynamical systems from data, as it allows the direct assessment of residual model uncertainty. We present a model predictive control (MPC) approach that integrates a nominal linear system with an additive nonlinear part of the dynamics modeled as a GP. Approximation techniques for propagating the state distribution are reviewed and the benefits of considering feedback in the prediction is demonstrated. We describe a principled way of formulating the chance constrained MPC problem, which takes into account residual uncertainties provided by the GP model to enable cautious control. Efficient computation with state-of-the-art solvers is discussed and simulation examples demonstrate the feasibility of the approach for systems with sub-second sampling times.},
archivePrefix = {arXiv},
arxivId = {1705.10702},
author = {Hewing, Lukas and Zeilinger, Melanie N.},
eprint = {1705.10702},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hewing, Zeilinger - 2017 - Cautious Model Predictive Control using Gaussian Process Regression.pdf:pdf},
journal = {ArXiv e-prints},
title = {{Cautious Model Predictive Control using Gaussian Process Regression}},
year = {2017}
}
@article{Hoeffding1963,
author = {Hoeffding, Wassily},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hoeffding - 1963 - Probability Inequalities for Sums of Bounded Random Variables.pdf:pdf},
journal = {Journal of the American Statistical Association},
number = {301},
pages = {13--30},
title = {{Probability Inequalities for Sums of Bounded Random Variables}},
volume = {58},
year = {1963}
}
@inproceedings{Hrovat2012,
abstract = {Model Predictive Control (MPC) is an established control technique in chemical process control, due to its capability of optimally controlling multivariable systems with constraints on plant and actuators. In recent years, the advances in MPC algorithms and design processes, the increased computational power of electronic control units, and the need for improved performance, safety and reduced emissions, have drawn considerable interest in MPC from the automotive industry. In this paper we survey the investigations of MPC in the automotive industry with particular focus on the developments at Ford Motor Company. First, we describe the basic MPC techniques used in the automotive industry, and the early exploratory investigations. Then we present three applications that have been recently prototyped in fully functional production-like vehicles, highlighting the features that make MPC a good candidate strategy for each case. We finally present our perspectives on the next challenges and future applications of MPC in the automotive industry.},
author = {Hrovat, D. and {Di Cairano}, S. and Tseng, H.E. and Kolmanovsky, I.V.},
booktitle = {2012 IEEE International Conference on Control Applications},
doi = {10.1109/CCA.2012.6402735},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hrovat et al. - 2012 - The development of Model Predictive Control in automotive industry A survey.pdf:pdf},
isbn = {978-1-4673-4505-7},
issn = {1085-1992},
keywords = {Actuators,Automotive engineering,Engines,Ford Motor Company,MPC,Magnetic materials,Photonic crystals,Sparks,Vehicles,automobile industry,automotive industry,chemical process control,electronic control unit,model predictive control,multivariable control systems,multivariable system,predictive control},
pages = {295--302},
title = {{The development of Model Predictive Control in automotive industry: A survey}},
year = {2012}
}
@article{Hubbert2004,
abstract = {In this paper we review the variational approach to radial basis function interpolation on the sphere and establish new Lp -error bounds, for p∈[1,∞]. These bounds are given in terms of a measure of the density of the interpolation points, the dimension of the sphere and the smoothness of the underlying basis function. {\textcopyright} 2004 Elsevier Inc. All rights reserved.},
author = {Hubbert, Simon and Morton, Tanya M.},
doi = {10.1016/j.jat.2004.04.006},
file = {:home/alederer/Local/Literatur/Learning/learning theory/Lp-error Estimates for Radial Basis Function Interpolation on the Sphere.pdf:pdf},
issn = {00219045},
journal = {Journal of Approximation Theory},
keywords = {Approximation theory,Error estimates,Radial basis functions},
number = {1},
pages = {58--77},
title = {{Lp-Error Estimates for Radial Basis Function Interpolation on the Sphere}},
volume = {129},
year = {2004}
}
@article{Hurwitz1895,
author = {Hurwitz, A.},
doi = {10.1007/BF01446812},
file = {:home/alederer/Documents/Literatur/Books/Ueber die Bedingungen, unter welchen eine Gleichung nur Wurzeln mit negativen reellen Theilen besitzt.pdf:pdf},
issn = {00255831},
journal = {Mathematische Annalen},
number = {2},
pages = {273--284},
title = {{Ueber die Bedingungen, unter welchen eine Gleichung nur Wurzeln mit negativen reellen Theilen besitzt}},
volume = {46},
year = {1895}
}
@article{Husler2003,
abstract = {The statistical properties of a cubic smoothing spline and its derivative are analyzed. It is shown that unless unnatural boundary conditions hold, the integrated squared bias is dominated by local effects near the boundary. Similar effects are shown to occur in the regularized solution of a translation- kernel integral equation. These results are derived by developing a Fourier representation for a smoothing spline},
author = {H{\"{u}}sler, J. and Piterbarg, V. and Seleznjev, O.},
doi = {10.1080/01621459.1938.10503387},
file = {:home/alederer/Local/Literatur/Learning/learning theory/On Convergence of the Uniform Norms of Gaussian Processes and Linear Approximation Problems.pdf:pdf},
issn = {0162-1459},
journal = {The Annals of Applied Probability},
number = {4},
pages = {1615--1653},
title = {{On Convergence of the Uniform Norms for Gaussian Processes and Linear Approximation Problems}},
volume = {13},
year = {2003}
}
@article{Huval2015,
abstract = {Numerous groups have applied a variety of deep learning techniques to computer vision problems in highway perception scenarios. In this paper, we presented a number of empirical evaluations of recent deep learning advances. Computer vision, combined with deep learning, has the potential to bring about a relatively inexpensive, robust solution to autonomous driving. To prepare deep learning for industry uptake and practical applications, neural networks will require large data sets that represent all possible driving environments and scenarios. We collect a large data set of highway data and apply deep learning and computer vision algorithms to problems such as car and lane detection. We show how existing convolutional neural networks (CNNs) can be used to perform lane and vehicle detection while running at frame rates required for a real-time system. Our results lend credence to the hypothesis that deep learning holds promise for autonomous driving.},
archivePrefix = {arXiv},
arxivId = {1504.01716},
author = {Huval, Brody and Wang, Tao and Tandon, Sameep and Kiske, Jeff and Song, Will and Pazhayampallil, Joel and Andriluka, Mykhaylo and Rajpurkar, Pranav and Migimatsu, Toki and Cheng-Yue, Royce and Mujica, Fernando and Coates, Adam and Ng, Andrew Y.},
eprint = {1504.01716},
file = {:home/alederer/Documents/Literatur/Learning/Deep Learning/An Empirical Evaluation of Deep Learning on Highway Driving.pdf:pdf},
pages = {1--7},
title = {{An Empirical Evaluation of Deep Learning on Highway Driving}},
url = {http://arxiv.org/abs/1504.01716},
year = {2015}
}
@article{Ingber1996,
abstract = {Adaptive simulated annealing (ASA) is a global optimization algorithm based on an associated proof that the parameter space can be sampled much more efficiently than by using other previous simulated annealing algorithms. The author's ASA code has been publicly available for over two years. During this time the author has volunteered to help people via e-mail, and the feedback obtained has been used to further develop the code. Some lessons learned, in particular some which are relevant to other simulated annealing algorithms, are described.},
author = {Ingber, Lester},
file = {:home/alederer/Documents/Literatur/Learning Based MPC/Global Optimization/Adaptive Simulated Annealing (ASA)$\backslash$: Lessons learned.pdf:pdf},
journal = {Control and Cybernetics},
number = {1},
pages = {32--54},
title = {{Adaptive simulated annealing (ASA): Lessons learned}},
volume = {25},
year = {1996}
}
@article{Itakura2009,
abstract = {In this paper we introduce a new underlying probabilistic model for prin- cipal component analysis (PCA). Our formulation interprets PCA as a particular Gaussian process prior on a mapping from a latent space to the observed data-space. We show that if the prior's covariance func- tion constrains the mappings to be linear the model is equivalent to PCA, we then extend the model by considering less restrictive covariance func- tions which allownon-linear mappings. This more general Gaussian pro- cess latent variable model (GPLVM) is then evaluated as an approach to the visualisation of high dimensional data for three different data-sets. Additionally our non-linear algorithm can be further kernelised leading to ‘twin kernel PCA' in which a mapping between feature spaces occurs.},
author = {Itakura, Hiroshi and Ito, Sho and Kitazawa, Daisuke and Tsunoda, Tomoyuki and Bao, Weiguang and Kinoshita, Takeshi and Fujino, Masatoshi},
doi = {10.1115/omae2008-57170},
file = {:home/alederer/Local/Literatur/Parkinson/GP Modelling/Gaussian Process Latent Variable Models for Visualisation of High Dimensional Data.pdf:pdf},
isbn = {0-7918-3821-8},
issn = {10495258},
pages = {415--420},
title = {{Hydrodynamic Forces and Motion Responses of Feeding Platform and Sea Cages}},
year = {2009}
}
@article{Ito2017,
abstract = {Guaranteeing stability of a designed control system is a challenging problem in data-driven control approaches such as Gaussian process (GP)-based control. The reason is that the inequality conditions, which are used in ensuring the stability, should be evaluated for all states in the state space, meaning that an infinite number of inequalities must be evaluated. Previous research introduced the idea of using a finite number of sampled states with the bounds of the stability inequalities near the samples. However, high-order bounds with respect to the distance between the samples are essential to decrease the number of sampling. From the standpoint of control theory, the requirement is not only evaluating stability but also simultaneously designing a controller. This paper overcomes theses two issues to stabilize GP-based dynamical systems. Second-order bounds of the stability inequalities are derived whereas existing approaches use first-order bounds. The proposed method obtaining the bounds are widely applicable to various functions such as polynomials, Gaussian processes, Gaussian mixture models, and sum/product functions of them. Unifying the derived bounds and nonlinear optimal control theory yields a stabilizing (sub-)optimal controller for GP dynamics. A numerical simulation demonstrates the stability performance of the proposed approach.},
archivePrefix = {arXiv},
arxivId = {1707.06240},
author = {Ito, Yuji and Fujimoto, Kenji and Tadokoro, Yukihiro},
eprint = {1707.06240},
file = {:home/alederer/Documents/Literatur/Learning for Control/Stabilizing/Second-order Bounds of Gaussian Kernel-based Functions and its Application to Nonlinear Optimal Control with Stability.pdf:pdf},
title = {{Second-order Bounds of Gaussian Kernel-based Functions and its Application to Nonlinear Optimal Control with Stability}},
url = {http://arxiv.org/abs/1707.06240},
year = {2017}
}
@inproceedings{Jain2018,
abstract = {Building physics-based models of complex physical systems like buildings and chemical plants is extremely cost and time prohibitive for applications such as real-time optimal control, production planning and supply chain logistics. Machine learning algorithms can reduce this cost and time complexity, and are, consequently, more scalable for large-scale physical systems. However, there are many practical challenges that must be addressed before employing machine learning for closed-loop control. This paper proposes the use of Gaussian Processes (GP) for learning control-oriented models: (1) We develop methods for the optimal experiment design (OED) of functional tests to learn models of a physical system, subject to stringent operational constraints and limited availability of the system. Using a Bayesian approach with GP, our methods seek to select the most informative data for optimally updating an existing model. (2) We also show that black-box GP models can be used for receding horizon optimal control with probabilistic guarantees on constraint satisfaction through chance constraints. (3) We further propose an online method for continuously improving the GP model in closed-loop with a real-time controller. Our methods are demonstrated and validated in a case study of building energy control and Demand Response. Abstract—Building physics-based models of complex physical systems like buildings and chemical plants is extremely cost and time prohibitive for applications such as real-time optimal control, production planning and supply chain logistics. Machine learning algorithms can reduce this cost and time complexity, and are, consequently, more scalable for large-scale physical systems. However, there are many practical challenges that must be addressed before employing machine learning for closed-loop control. This paper proposes the use of Gaussian Processes (GP) for learning control-oriented models: (1) We develop methods for the optimal experiment design (OED) of functional tests to learn models of a physical system, subject to stringent operational constraints and limited availability of the system. Using a Bayesian approach with GP, our methods seek to select the most informative data for optimally updating an existing model. (2) We also show that black-box GP models can be used for receding horizon optimal control with probabilistic guarantees on constraint satisfaction through chance constraints. (3) We further propose an online method for continuously improving the GP model in closed-loop with a real-time controller. Our methods are demonstrated and validated in a case study of building energy control and Demand Response.},
author = {Jain, Achin and Nghiem, Truong X and Morari, Manfred and Mangharam, Rahul},
booktitle = {Proceedings of the 9th ACM/IEEE International Conference on Cyber-Physical Systems},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jain et al. - 2018 - Learning and Control using Gaussian Processes.pdf:pdf},
keywords = {Gaussian Processes,Machine learning,active learning,active learning Index Terms—Machine learning,optimal experiment design,receding horizon control},
pages = {140--149},
title = {{Learning and Control using Gaussian Processes}},
url = {https://repository.upenn.edu/mlab{\_}papers https://repository.upenn.edu/mlab{\_}papers/104},
year = {2018}
}
@article{Jain2018a,
abstract = {Model Predictive Control (MPC) plays an important role in optimizing operations of complex cyber-physical systems because of its ability to forecast system's behavior and act under system level constraints. However, MPC requires reasonably accurate underlying models of the system. In many applications, such as build-ing control for energy management, Demand Response, or peak power reduction, obtaining a high-fidelity physics-based model is cost and time prohibitive, thus limiting the widespread adoption of MPC. To this end, we propose a data-driven control algorithm for MPC that relies only on the historical data. We use multi-output regression trees to represent the system's dynamics over multiple future time steps and formulate a finite receding horizon control problem that can be solved in real-time in closed-loop with the physical plant. We apply this algorithm to peak power reduction in buildings to optimally trade-off peak power reduction against thermal comfort without having to learn white/grey box models of the systems dynamics.},
author = {Jain, Achin and Smarra, Francesco and Behl, Madhur and Mangharam, Rahul},
doi = {10.1145/3127023},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jain et al. - 2018 - Data-Driven Model Predictive Control with Regression Trees An Application to Building Energy Management.pdf:pdf},
journal = {ACM Transaction on Cyber-Physical Systems},
keywords = {Additional Key Words and Phrases,CCS Concepts,Machine learning,cyber-physical systems,demand response,peak power reduction,predictive control},
number = {1},
pages = {1--21},
title = {{Data-Driven Model Predictive Control with Regression Trees: An Application to Building Energy Management}},
volume = {2},
year = {2018}
}
@article{Jasour2016,
abstract = {We consider the Chance Constrained Model Predictive Control problem for polynomial systems subject to disturbances. In this problem, we aim at finding optimal control input for given disturbed dynamical system to minimize a given cost function subject to probabilistic constraints, over a finite horizon. The control laws provided have a predefined (low) risk of not reaching the desired target set. Building on the theory of measures and moments, a sequence of finite semidefinite programmings are provided, whose solution is shown to converge to the optimal solution of the original problem. Numerical examples are presented to illustrate the computational performance of the proposed approach.},
archivePrefix = {arXiv},
arxivId = {1603.07413},
author = {Jasour, Ashkan and Lagoa, Constantino},
eprint = {1603.07413},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jasour, Lagoa - 2016 - Convex Chance Constrained Model Predictive Control.pdf:pdf},
isbn = {9781509018369},
keywords = {chance constraints,constrained model predictive control,robustness},
pages = {1--14},
title = {{Convex Chance Constrained Model Predictive Control}},
year = {2016}
}
@article{Jerbi2014,
abstract = {{\textcopyright} 2017, Indian Potato Association. All rights reserved. Potato has been considered as a serious food security option worldwide and about 15.5{\%} of potato tubers are processed into various products. This study undertakes analysis of patents data for having insight into the direction and extent of global research on potato processing. North America has demonstrated that protection of intellectual properties create global businesses, however massive efforts from China in recent years indicate their gigantic future plans in potato processing. The study indicates that western developed world was skewed towards French fries and Potato Chips/ Crisps while China has greater balance in their focus as Other Potato products, Dehydrated Products and Processing Machinery have also been adequately focussed.},
author = {Jerbi, Houssem and Braiek, Naceur Benhadj and Bacha, Anis Belhadj Brahim},
doi = {10.1007/s13369-014-0947-4},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jerbi, Braiek, Bacha - 2014 - A Method of Estimating the Domain of Attraction for Nonlinear Discrete-Time Systems.pdf:pdf},
isbn = {978-1-4020-5597-3},
issn = {21914281},
journal = {Arabian Journal for Science and Engineering},
keywords = {Asymptotic stability,Attraction domain,Non-Lyapunov methods,Nonlinear polynomial discrete-time systems,Stable equilibrium point},
number = {5},
pages = {3841--3849},
pmid = {22236664},
title = {{A Method of Estimating the Domain of Attraction for Nonlinear Discrete-Time Systems}},
volume = {39},
year = {2014}
}
@article{Jiang2014,
abstract = {Learning low dimensional manifold from highly nonlinear data of high dimensionality has become increasingly important for discovering intrinsic representation that can be utilized for data visualization and preprocessing. The autoencoder is a powerful dimensionality reduction technique based on minimizing reconstruction error, and it has regained popularity because it has been efficiently used for greedy pre-training of deep neural networks. Compared to Neural Network (NN), the superiority of Gaussian Process (GP) has been shown in model inference, optimization and performance. GP has been successfully applied in nonlinear Dimensionality Reduction (DR) algorithms, such as Gaussian Process Latent Variable Model (GPLVM). In this paper we propose the Gaussian Processes Autoencoder Model (GPAM) for dimensionality reduction by extending the classic NN based autoencoder to GP based autoencoder. More interestingly, the novel model can also be viewed as back constrained GPLVM (BC-GPLVM) where the back constraint smooth function is represented by a GP. Experiments verify the performance of the newly proposed model.},
author = {Jiang, Xinwei and Gao, Junbin and Hong, Xia and Cai, Zhihua},
doi = {10.1007/978-3-319-06605-9_6},
file = {:home/alederer/Local/Literatur/Parkinson/GP Modelling/Gaussian Processes Autoencoder for Dimensionality Reduction.pdf:pdf},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Autoencoder,Dimensionality Reduction,Gaussian Process,Latent Variable Model,Neural Networks},
number = {PART 2},
pages = {62--73},
title = {{Gaussian processes autoencoder for dimensionality reduction}},
volume = {8444 LNAI},
year = {2014}
}
@article{Jiang1994,
abstract = {We introduce a concept of input-to-output practical stability (IOpS) which is a natural generalization of input-to-state stability proposed by Sontag. It allows us to establish two important results. The first one states that the general interconnection of two IOpS systems is again an IOpS system if an appropriate composition of the gain functions is smaller than the identity function. The second one shows an example of gain function assignment by feedback. As an illustration of the interest of these results, we address the problem of global asymptotic stabilization via partial-state feedback for linear systems with nonlinear, stable dynamic perturbations and for systems which have a particular disturbed recurrent structure.},
author = {Jiang, Z. P. and Teel, A. R. and Praly, L.},
doi = {10.1007/BF01211469},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiang, Teel, Praly - 1994 - Small-gain theorem for ISS systems and applications.pdf:pdf},
issn = {09324194},
journal = {Mathematics of Control, Signals, and Systems},
keywords = {Global stability,Input-to-state stability,Nonlinear systems,Partial-state feedback},
number = {2},
pages = {95--120},
title = {{Small-gain theorem for ISS systems and applications}},
volume = {7},
year = {1994}
}
@article{Jiang2001,
abstract = {In this work we study the input-to-state stability (ISS) property for discrete-time nonlinear systems. It is shown that most ISS results for continuous-time nonlinear systems in the current literature can be extended to the discrete-time case. Several equivalent characterizations of ISS are introduced and two ISS small-gain theorems are proved for nonlinear and interconnected discrete-time systems. ISS stabilizability is discussed and comparisons with the continuous-time case are made. As in the continuous time framework, where the notion ISS found wide applications, we expect that this notion will provide a useful tool in areas related to stability and stabilization for nonlinear discrete time systems as well.},
author = {Jiang, Zhong-Ping and Wang, Yuan},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jiang, Wang - 2001 - Input-to-state stability for discrete-time nonlinear systems.pdf:pdf},
journal = {Automatica},
keywords = {discrete time systems,input-to-state stability,lyapunov functions,nonlinear small-gain,nonlinear stability},
number = {6},
pages = {857--869},
title = {{Input-to-state stability for discrete-time nonlinear systems}},
volume = {37},
year = {2001}
}
@book{Johnson2004,
address = {New York},
editor = {Johnson, Mark and Khudanpur, Sanjeev P. and Ostendorf, Mari and Rosenfel, Roni},
file = {:home/alederer/Documents/Literatur/Learning/Hidden Markov Models/Mathematical Foundations of Speech and Language Processing.pdf:pdf},
publisher = {Springer Science+Business Media},
title = {{Mathematical Foundations of Speech and Language Processing}},
year = {2004}
}
@incollection{Jones2001,
author = {Jones, D. R.},
booktitle = {The Encyclopedia of Optimization},
doi = {10.1007/978-0-387-74759-0_128},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jones - 2001 - Direct Global Optimization Algorithm.pdf:pdf},
keywords = {Black-box optimization,Constraints,Deterministic optimization,Global optimization,Nonsmooth optimization},
pages = {725--735},
title = {{Direct Global Optimization Algorithm}},
year = {2001}
}
@article{Jones1993,
abstract = {We present a new algorithm for finding the global minimum of a multivariate function subject to simple bounds. The algorithm is a modification of the standard Lipschitzian approach that eliminates the need to specify a Lipschitz constant. This is done by carrying out simultaneous searches using all possible constants from zero to infinity. On nine standard test functions, the new algorithm converges in fewer function evaluations than most competing methods. The motivation for the new algorithm stems from a different way of looking at the Lipschitz constant. In particular, the Lipschitz constant is viewed as a weighting parameter that indicates how much emphasis to place on global versus local search. In standard Lipschitzian methods, this constant is usually large because it must equal or exceed the maximum rate of change of the objective function. As a result, these methods place a high emphasis on global search and exhibit slow convergence. In contrast, the new algorithm carries out simultaneous searches using all possible constants, and therefore operates at both the global and local level. Once the global part of the algorithm finds the basin of convergence of the optimum, the local part of the algorithm quickly and automatically exploits it. This accounts for the fast convergence of the new algorithm on the test functions.},
author = {Jones, D. R. and Perttunen, C. D. and Stuckman, B. E.},
doi = {10.1007/BF00941892},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jones, Perttunen, Stuckman - 1993 - Lipschitzian optimization without the Lipschitz constant.pdf:pdf},
isbn = {0022-3239},
issn = {00223239},
journal = {Journal of Optimization Theory and Applications},
keywords = {Global optimization,Lipschitzian optimization,space covering,space partitioning},
number = {1},
pages = {157--181},
pmid = {484},
title = {{Lipschitzian optimization without the Lipschitz constant}},
volume = {79},
year = {1993}
}
@inproceedings{Joukov2017,
author = {Joukov, Vladimir and Kulic, Dana},
booktitle = {IEEE-RAS International Conference on Humanoid Robotics},
doi = {10.1109/HUMANOIDS.2017.8246971},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Joukov, Kulic - 2017 - Gaussian process based model predictive controller for imitation learning.pdf:pdf},
isbn = {978-1-5386-4678-6},
pages = {850--855},
title = {{Gaussian process based model predictive controller for imitation learning}},
url = {http://ieeexplore.ieee.org/document/8246971/},
year = {2017}
}
@article{Kailath1968,
abstract = {The innovations approach to linear least-squares approximation problems is first to "whiten" the observed data by a causal and invertible operation, and then to treat the resulting simpler white-noise observations problem. This technique was successfully used by Bode and Shannon to obtain a simple derivation of the classical Wiener filtering problem for stationary processes over a semi-infinite interval. Here we shall extend the technique to handle nonstationary continuous-time processes over finite intervals. In Part I we shall apply this method to obtain a simple derivation of the Kalman-Bucy recursive filtering formulas (for both continuous-time and discrete-time processes) and also some minor generalizations thereof.},
author = {Kailath, T},
doi = {10.1109/TAC.1968.1099025},
file = {:home/alederer/Documents/Literatur/Learning for Control/Gaussian Noise/An Innovations Approach to Least-Squares Estimation-Part III$\backslash$: Nonlinear Estimation in White Gaussian Noise.pdf:pdf},
issn = {0018-9286},
journal = {IEEE Transactions on Automatic Control},
number = {6},
pages = {646--655},
title = {{An Innovations Approach to Least-Squares Estimation}},
volume = {13},
year = {1968}
}
@article{Kaiser2019,
abstract = {Model-free reinforcement learning (RL) can be used to learn effective policies for complex tasks, such as Atari games, even from image observations. However, this typically requires very large amounts of interaction -- substantially more, in fact, than a human would need to learn the same games. How can people learn so quickly? Part of the answer may be that people can learn how the game works and predict which actions will lead to desirable outcomes. In this paper, we explore how video prediction models can similarly enable agents to solve Atari games with fewer interactions than model-free methods. We describe Simulated Policy Learning (SimPLe), a complete model-based deep RL algorithm based on video prediction models and present a comparison of several model architectures, including a novel architecture that yields the best results in our setting. Our experiments evaluate SimPLe on a range of Atari games in low data regime of {\$}100{\$}K interactions between the agent and the environment, which corresponds to two hours of real-time play. In most games SimPLe outperforms state-of-the-art model-free algorithms, in some games by over an order of magnitude.},
archivePrefix = {arXiv},
arxivId = {1903.00374},
author = {Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and Mohiuddin, Afroz and Sepassi, Ryan and Tucker, George and Michalewski, Henryk},
eprint = {1903.00374},
file = {:home/alederer/Documents/Literatur/Reinforcement Learning/Multi-step predictions/Model Based Reinforcement Learning for Atari.pdf:pdf},
title = {{Model-Based Reinforcement Learning for Atari}},
url = {http://arxiv.org/abs/1903.00374},
year = {2019}
}
@inproceedings{Kamthe2018,
abstract = {Trial-and-error based reinforcement learning (RL) has seen rapid advancements in recent times, especially with the advent of deep neural networks. However, the majority of autonomous RL algorithms require a large number of interactions with the environment. A large number of interactions may be impractical in many real-world applications, such as robotics, and many practical systems have to obey limitations in the form of state space or control constraints. To reduce the number of system interactions while simultaneously handling constraints, we propose a model-based RL framework based on probabilistic Model Predictive Control (MPC). In particular, we propose to learn a probabilistic transition model using Gaussian Processes (GPs) to incorporate model uncertainty into long-term predictions, thereby, reducing the impact of model errors. We then use MPC to find a control sequence that minimises the expected long-term cost. We provide theoretical guarantees for first-order optimality in the GP-based transition models with deterministic approximate inference for long-term planning. We demonstrate that our approach does not only achieve state-of-the-art data efficiency, but also is a principled way for RL in constrained environments.},
archivePrefix = {arXiv},
arxivId = {1706.06491},
author = {Kamthe, Sanket and Deisenroth, Marc Peter},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Statistics},
eprint = {1706.06491},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kamthe, Deisenroth - 2018 - Data-Efficient Reinforcement Learning with Probabilistic Model Predictive Control.pdf:pdf},
pages = {1701--1710},
title = {{Data-Efficient Reinforcement Learning with Probabilistic Model Predictive Control}},
year = {2018}
}
@article{Kanagawa2018,
abstract = {This paper is an attempt to bridge the conceptual gaps between researchers working on the two widely used approaches based on positive definite kernels: Bayesian learning or inference using Gaussian processes on the one side, and frequentist kernel methods based on reproducing kernel Hilbert spaces on the other. It is widely known in machine learning that these two formalisms are closely related; for instance, the estimator of kernel ridge regression is identical to the posterior mean of Gaussian process regression. However, they have been studied and developed almost independently by two essentially separate communities, and this makes it difficult to seamlessly transfer results between them. Our aim is to overcome this potential difficulty. To this end, we review several old and new results and concepts from either side, and juxtapose algorithmic quantities from each framework to highlight close similarities. We also provide discussions on subtle philosophical and theoretical differences between the two approaches.},
archivePrefix = {arXiv},
arxivId = {1807.02582},
author = {Kanagawa, Motonobu and Hennig, Philipp and Sejdinovic, Dino and Sriperumbudur, Bharath K},
eprint = {1807.02582},
file = {:home/alederer/Local/Literatur/Learning/learning theory/Gaussian Processes and Kernel Methods{\_} A Review on Connections and Equivalences.pdf:pdf},
pages = {1--64},
title = {{Gaussian Processes and Kernel Methods: A Review on Connections and Equivalences}},
url = {http://arxiv.org/abs/1807.02582},
year = {2018}
}
@article{Kapinski2015,
abstract = {We describe a numerical technique for discovering forward invari-ant sets for discrete-time nonlinear dynamical systems. Given a region of interest in the state-space, our technique uses simulation traces originating at states within this region to construct candidate Lyapunov functions, which are in turn used to obtain candidate forward invariant sets. To vet a candi-date invariant set, our technique samples a finite number of states from the set and tests them. We derive sufficient conditions on the sample density that formally guarantee that the candidate invariant set is indeed forward invariant. Finally, we present a numerical example illustrating the efficacy of the technique.},
author = {Kapinski, James and Deshmukh, Jyotirmoy},
doi = {10.1007/978-3-319-12307-3_37},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kapinski, Deshmukh - 2015 - Discovering forward invariant sets for nonlinear dynamical systems.pdf:pdf},
isbn = {9783319123066},
issn = {21941017},
journal = {Springer Proceedings in Mathematics and Statistics},
pages = {259--264},
title = {{Discovering forward invariant sets for nonlinear dynamical systems}},
volume = {117},
year = {2015}
}
@article{Kapinski2014,
abstract = {Lyapunov functions are used to prove stability and to obtain performance bounds on system behaviors for nonlinear and hybrid dynamical systems, but discovering Lyapunov func-tions is a difficult task in general. We present a technique for discovering Lyapunov functions and barrier certificates for nonlinear and hybrid dynamical systems using a search-based approach. Our approach uses concrete executions, such as those obtained through simulation, to formulate a series of linear programming (LP) optimization problems; the solution to each LP creates a candidate Lyapunov func-tion. Intermediate candidates are iteratively improved using a global optimizer guided by the Lie derivative of the candi-date Lyapunov function. The analysis is refined using coun-terexamples from a Satisfiability Modulo Theories (SMT) solver. When no counterexamples are found, the soundness of the analysis is verified using an arithmetic solver. The technique can be applied to a broad class of nonlinear dy-namical systems, including hybrid systems and systems with polynomial and even transcendental dynamics. We present several examples illustrating the efficacy of the technique, including two automotive powertrain control examples.},
author = {Kapinski, James and Deshmukh, Jyotirmoy V and Sankaranarayanan, Sriram and Arechiga, Nikos},
doi = {10.1145/2562059.2562139},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kapinski et al. - 2014 - Simulation-guided lyapunov analysis for hybrid dynamical systems.pdf:pdf},
isbn = {978-1-4503-2732-9},
journal = {HSCC '14 Proceedings of the 17th international conference on Hybrid systems: computation and control},
keywords = {barrier cer-,invariant sets,lyapunov functions,simulation,stability,tificates},
pages = {133--142},
title = {{Simulation-guided lyapunov analysis for hybrid dynamical systems}},
url = {http://doi.acm.org/10.1145/2562059.2562139},
year = {2014}
}
@article{Kapinski2016,
abstract = {{\textcopyright} 2016 IEEE. Designers of industrial embedded control systems, such as automotive, aerospace, and medical-device control systems, use verification and testing activities to increase their confidence that performance requirements and safety standards are met. Since testing and verification tasks account for a significant portion of the development effort, increasing the efficiency of testing and verification will have a significant impact on the total development cost. Existing and emerging simulation-based approaches offer improved means of testing and, in some cases, verifying the correctness of control system designs.},
author = {Kapinski, James and Deshmukh, Jyotirmoy V. and Jin, Xiaoqing and Ito, Hisahiro and Butts, Ken},
doi = {10.1109/MCS.2016.2602089},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kapinski et al. - 2016 - Simulation-Based Approaches for Verification of Embedded Control Systems An Overview of Traditional and Advance.pdf:pdf},
isbn = {1066-033X VO - 36},
issn = {1066033X},
journal = {IEEE Control Systems},
number = {6},
pages = {45--64},
publisher = {IEEE},
title = {{Simulation-Based Approaches for Verification of Embedded Control Systems: An Overview of Traditional and Advanced Modeling, Testing, and Verification Techniques}},
volume = {36},
year = {2016}
}
@article{Karg2018,
abstract = {We show that artificial neural networks with rectifier units as activation functions can exactly represent the piecewise affine function that results from the formulation of model predictive control of linear time-invariant systems. The choice of deep neural networks is particularly interesting as they can represent exponentially many more affine regions compared to networks with only one hidden layer. We provide theoretical bounds on the minimum number of hidden layers and neurons per layer that a neural network should have to exactly represent a given model predictive control law. The proposed approach has a strong potential as an approximation method of predictive control laws, leading to better approximation quality and significantly smaller memory requirements than previous approaches, as we illustrate via simulation examples. Since the online evaluation of neural networks is extremely simple, the proposed approach is a perfect candidate for embedded applications.},
archivePrefix = {arXiv},
arxivId = {1806.10644},
author = {Karg, Benjamin and Lucia, Sergio},
eprint = {1806.10644},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karg, Lucia - 2018 - Efficient representation and approximation of model predictive control laws via deep learning.pdf:pdf},
keywords = {machine learning,neural networks,predictive control},
title = {{Efficient representation and approximation of model predictive control laws via deep learning}},
year = {2018}
}
@book{Khalil2002,
address = {Upper Saddle River, NJ},
author = {Khalil, Hassan K.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khalil - 2002 - Nonlinear Systems 3rd ed.pdf:pdf},
isbn = {0130673897},
publisher = {Prentice-Hall},
title = {{Nonlinear Systems; 3rd ed.}},
year = {2002}
}
@article{Khansari-Zadeh2011,
abstract = {This paper presents a method to learn discrete robot motions froma set of demonstrations.We model a motion as a non- linear autonomous (i.e., time-invariant) dynamical system (DS) and define sufficient conditions to ensure global asymptotic stability at the target. We propose a learning method, which is called Stable Estimator of Dynamical Systems (SEDS), to learn the parameters of the DS to ensure that all motions closely follow the demonstra- tions while ultimately reaching and stopping at the target. Time- invariance and global asymptotic stability at the target ensures that the system can respond immediately and appropriately to pertur- bations that are encountered during the motion. The method is evaluated through a set of robot experiments and on a library of human handwriting motions.},
author = {Khansari-Zadeh, S. Mohammad and Billard, Aude},
doi = {10.1109/TRO.2011.2159412},
file = {:home/alederer/Documents/Literatur/Learning/Stable Systems/Learning Stable Nonlinear Dynamical Systems With Gaussian Mixture Models.pdf:pdf},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {Dynamical systems (DS),Gaussian mixture model,imitation learning,point-to-point motions,stability analysis},
number = {5},
pages = {943--957},
publisher = {IEEE},
title = {{Learning stable nonlinear dynamical systems with Gaussian mixture models}},
volume = {27},
year = {2011}
}
@inproceedings{Kirschner2018,
abstract = {In the stochastic bandit problem, the goal is to maximize an unknown function via a sequence of noisy evaluations. Typically, the observation noise is assumed to be independent of the evaluation point and to satisfy a tail bound uniformly on the domain; a restrictive assumption for many applications. In this work, we consider bandits with heteroscedastic noise, where we explicitly allow the noise distribution to depend on the evaluation point. We show that this leads to new trade-offs for information and regret, which are not taken into account by existing approaches like upper confidence bound algorithms (UCB) or Thompson Sampling. To address these shortcomings, we introduce a frequentist regret analysis framework, that is similar to the Bayesian framework of Russo and Van Roy (2014), and we prove a new high-probability regret bound for general, possibly randomized policies, which depends on a quantity we refer to as regret-information ratio. From this bound, we define a frequentist version of Information Directed Sampling (IDS) to minimize the regret-information ratio over all possible action sampling distributions. This further relies on concentration inequalities for online least squares regression in separable Hilbert spaces, which we generalize to the case of heteroscedastic noise. We then formulate several variants of IDS for linear and reproducing kernel Hilbert space response functions, yielding novel algorithms for Bayesian optimization. We also prove frequentist regret bounds, which in the homoscedastic case recover known bounds for UCB, but can be much better when the noise is heteroscedastic. Empirically, we demonstrate in a linear setting with heteroscedastic noise, that some of our methods can outperform UCB and Thompson Sampling, while staying competitive when the noise is homoscedastic.},
author = {Kirschner, Johannes and Krause, Andreas},
booktitle = {Conference on Learning Theory},
file = {:home/alederer/Documents/Literatur/Reinforcement Learning/Information Directed Sampling and Bandits with Heteroscedastic Noise.pdf:pdf},
pages = {358--384},
title = {{Information Directed Sampling and Bandits with Heteroscedastic Noise}},
year = {2018}
}
@article{Klenske2016,
abstract = {—Many controlled systems suffer from unmodeled nonlinear effects that recur periodically over time. Model-free controllers generally cannot compensate these effects, and good physical models for such periodic dynamics are challenging to construct. We investigate nonparametric system identification for periodically recurring nonlinear effects. Within a Gaussian process regression framework, we use a locally periodic co-variance function to shape the hypothesis space, which allows for a structured extrapolation that is not possible with more widely used covariance functions. We show that hyperparameter estimation can be performed online by using the maximum a-posteriori point estimate, which provides an accuracy comparable to sampling methods as soon as enough data to cover the periodic structure has been collected. It is also shown how the periodic structure can be exploited in the hyperparameter optimization. The predictions obtained from the Gaussian process model are then used in a model predictive control framework to correct for the external effect. The availability of good continuous predictions allows control at a rate higher than that of the measurements. We show that the proposed approach is particularly beneficial for sampling times that are smaller than, but of the same order of magnitude as, the period length of the external effect. In experiments on a physical system, an electrically actuated telescope mount, this approach achieves a reduction of about 20 {\%} in root mean square tracking error.},
author = {Klenske, Edgar D and Zeilinger, Melanie N and Sch{\"{o}}lkopf, Bernhard and Hennig, Philipp},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Klenske et al. - 2016 - Gaussian Process Based Predictive Control for Periodic Error Correction.pdf:pdf},
journal = {IEEE Transactions on Control Systems Technology},
number = {1},
pages = {110--121},
title = {{Gaussian Process Based Predictive Control for Periodic Error Correction}},
volume = {24},
year = {2016}
}
@inproceedings{Ko2007a,
author = {Ko, Jonathan and Klein, Daniel J and Fox, Dieter and Haehnel, Dirk},
booktitle = {Proceedings of the International Conference on Intelligent Robots and Systems},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ko et al. - 2007 - GP-UKF Unscented Kalman Filters with Gaussian Process Prediction and Observation Models.pdf:pdf},
title = {{GP-UKF: Unscented Kalman Filters with Gaussian Process Prediction and Observation Models}},
year = {2007}
}
@inproceedings{Ko2007,
abstract = {Blimps are a promising platform for aerial robotics and have been$\backslash$nstudied extensively for this purpose. Unlike other aerial vehicles,$\backslash$nblimps are relatively safe and also possess the ability to loiter$\backslash$nfor long periods. These advantages, however, have been difficult$\backslash$nto exploit because blimp dynamics are complex and inherently non-linear.$\backslash$nThe classical approach to system modeling represents the system as$\backslash$nan ordinary differential equation (ODE) based on Newtonian principles.$\backslash$nA more recent modeling approach is based on representing state transitions$\backslash$nas a Gaussian process (GP). In this paper, we present a general technique$\backslash$nfor system identification that combines these two modeling approaches$\backslash$ninto a single formulation. This is done by training a Gaussian process$\backslash$non the residual between the non-linear model and ground truth training$\backslash$ndata. The result is a GP-enhanced model that provides an estimate$\backslash$nof uncertainty in addition to giving better state predictions than$\backslash$neither ODE or GP alone. We show how the GP-enhanced model can be$\backslash$nused in conjunction with reinforcement learning to generate a blimp$\backslash$ncontroller that is superior to those learned with ODE or GP models$\backslash$nalone.},
author = {Ko, Jonathan and Klein, Daniel J and Fox, Dieter and Haehnel, Dirk},
booktitle = {Proceedings of the International Conference on Robotics and Automation},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ko et al. - 2007 - Gaussian Processes and Reinforcement Learning for Identification and Control of an Autonomous Blimp.pdf:pdf},
isbn = {1424406021},
pages = {742--747},
title = {{Gaussian Processes and Reinforcement Learning for Identification and Control of an Autonomous Blimp}},
year = {2007}
}
@article{Kober2012,
archivePrefix = {arXiv},
arxivId = {cs/9605103},
author = {Kober, Jens and Peters, Jan},
doi = {10.1177/0278364913495721},
eprint = {9605103},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kober, Peters - 2012 - Reinforcement learning in robots A survey.pdf:pdf},
isbn = {0278-3649},
issn = {0278-3649},
journal = {Reinforcement Learning: State of the Art},
keywords = {learning control,reinforcement learning},
pages = {579--610},
pmid = {17255001},
primaryClass = {cs},
title = {{Reinforcement learning in robots: A survey}},
year = {2012}
}
@inproceedings{Kocijan2004,
abstract = {Gaussian process models provide a probabilistic non-parametric modelling approach for black-box identification of non-linear dynamic systems. The Gaussian processes can highlight areas of the input space where prediction quality is poor, due to the lack of data or its complexity, by indicating the higher variance around the predicted mean. Gaussian process models contain noticeably less coefficients to be optimized. This paper illustrates possible application of Gaussian process models within model-based predictive control. The extra information provided within Gaussian process model is used in predictive control, where optimization of control signal takes the variance information into account. The predictive control principle is demonstrated on control of pH process benchmark.},
author = {Kocijan, J and Murray-Smith, R and Rasmussen, C E and Girard, A},
booktitle = {Proceedings of the 2004 American Control Conference},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kocijan et al. - 2004 - Gaussian process model based predictive control.pdf:pdf},
isbn = {0780383354},
issn = {0743-1619},
keywords = {tk electrical engineering. electronics nuclear eng},
pages = {2214--2219},
title = {{Gaussian process model based predictive control}},
year = {2004}
}
@article{Kocijan2008,
abstract = {The Gaussian-process (GP) model is an example of a probabilistic, nonparametric model with uncertainty predictions. It can be used for the modelling of complex nonlinear systems and also for dynamic systems identification. The output of the GP model is a normal distribution, expressed in terms of the mean and variance. The modelling case study of a gas-liquid separator is presented in this paper. It describes the comparison of three methods for dynamic GP model simulation in the phase of model validation. The level of the computational burden associated with each approach increases with the complexity of the computation necessary for an approximation of the uncertainty propagation. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
author = {Kocijan, J. and Likar, B.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kocijan, Likar - 2008 - Gas-liquid separator modelling and simulation with Gaussian-process models.pdf:pdf},
journal = {Simulation Modelling Practice and Theory},
keywords = {Dynamic system models,Gaussian-process models,Simulation,System identification},
number = {8},
pages = {910--922},
title = {{Gas-liquid separator modelling and simulation with Gaussian-process models}},
volume = {16},
year = {2008}
}
@inproceedings{Kocijan2003,
abstract = {This paper describes model-based predictive control based on Gaussian processes. Gaussian process models provide a probabilistic non-parametric modelling approach for black-box identification of nonlinear dynamic systems. It offers more insight in variance of obtained model response, as well as fewer parameters to determine than other models. The Gaussian processes can highlight areas of the input space where prediction quality is poor, due to the lack of data or its complexity, by indicating the higher variance around the predicted mean. This property is used in predictive control, where optimisation of control signal takes the variance information into account. The predictive control principle is demonstrated on a simulated example of nonlinear system.},
author = {Kocijan, J. and Murray-Smith, R. and Rasmussen, C.E. and Likar, B.},
booktitle = {The IEEE Region 8 EUROCON 2003. Computer as a Tool.},
doi = {10.1109/EURCON.2003.1248042},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kocijan et al. - 2003 - Predictive control with Gaussian process models.pdf:pdf},
isbn = {0-7803-7763-X},
keywords = {constraint optimisation,gaussian process models,model based predictive control,nonlinear control},
pages = {352--356},
title = {{Predictive control with Gaussian process models}},
year = {2003}
}
@book{Kocijan2016,
abstract = {This monograph opens up new horizons for engineers and researchers in academia and in industry dealing with or interested in new developments in the field of system identification and control. It emphasizes guidelines for working solutions and practical advice for their implementation rather than the theoretical background of Gaussian process (GP) models. The book demonstrates the potential of this recent development in probabilistic machine-learning methods and gives the reader an intuitive understanding of the topic. The current state of the art is treated along with possible future directions for research. Systems control design relies on mathematical models and these may be developed from measurement data. This process of system identification, when based on GP models, can play an integral part of control design in data-based control and its description as such is an essential aspect of the text. The background of GP regression is introduced first with system identification and incorporation of prior knowledge then leading into full-blown control. The book is illustrated by extensive use of examples, line drawings, and graphical presentation of computer-simulation results and plant measurements. The research results presented are applied in real-life case studies drawn from successful applications including: a gas–liquid separator control; urban-traffic signal modelling and reconstruction; and prediction of atmospheric ozone concentration. A MATLAB{\textregistered} toolbox, for identification and simulation of dynamic GP models is provided for download.},
author = {Kocijan, Ju{\v{s}}},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kocijan - 2016 - Modelling and Control of Dynamic Systems Using Gaussian Process Models.pdf:pdf},
publisher = {Springer International Publishing},
title = {{Modelling and Control of Dynamic Systems Using Gaussian Process Models}},
year = {2016}
}
@incollection{Kocijan2003a,
author = {Kocijan, Ju{\v{s}} and Murray-Smith, Roderick},
booktitle = {Switching and Learning in Feedback Systems},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2003 - Switching and Learning in Feedback Systems.pdf:pdf},
pages = {185--200},
title = {{Nonlinear Predictive Control with a Gaussian Process Model}},
year = {2003}
}
@inproceedings{Koller2018,
abstract = {Learning-based methods have been successful in solving complex control tasks without significant prior knowledge about the system. However, these methods typically do not provide any safety guarantees, which prevents their use in safety-critical, real-world applications. In this paper, we present a learning-based model predictive control scheme that provides provable high-probability safety guarantees. To this end, we exploit regularity assumptions on the dynamics in terms of a Gaussian process prior to construct provably accurate confidence intervals on predicted trajectories. Unlike previous approaches, we do not assume that model uncertainties are independent. Based on these predictions, we guarantee that trajectories satisfy safety constraints. Moreover, we use a terminal set constraint to recursively guarantee the existence of safe control actions at every iteration. In our experiments, we show that the resulting algorithm can be used to safely and efficiently explore and learn about dynamic systems.},
archivePrefix = {arXiv},
arxivId = {1803.08287},
author = {Koller, Torsten and Berkenkamp, Felix and Turchetta, Matteo and Krause, Andreas},
booktitle = {Proceedings of the IEEE Conference on Decision and Control},
eprint = {1803.08287},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Koller et al. - 2018 - Learning-based Model Predictive Control for Safe Exploration and Reinforcement Learning.pdf:pdf},
pages = {6059--6066},
title = {{Learning-based Model Predictive Control for Safe Exploration}},
year = {2018}
}
@article{Komaee2012,
author = {Komaee, Arash},
doi = {10.1109/TAC.2012.2187229},
file = {:home/alederer/Documents/Literatur/Learning for Control/Gaussian Noise/Estimation of a Low-Intensity Filtered Poisson Process in Additive White Gaussian Noise.pdf:pdf},
issn = {00189286},
journal = {IEEE Transactions on Automatic Control},
keywords = {Estimation,filtered Poisson process,nonlinear filter,single photon detection,white Gaussian noise},
number = {10},
pages = {2518--2531},
publisher = {IEEE},
title = {{Estimation of a low-intensity filtered poisson process in additive white gaussian noise}},
volume = {57},
year = {2012}
}
@article{Koppel,
author = {Koppel, Alec},
file = {:home/alederer/Local/Literatur/Learning/Local GP/Consistent Online Gaussian Process Regression Without the Sample Complexity Bottleneck.pdf:pdf},
title = {{Consistent Online Gaussian Process Regression Without the Sample Complexity Bottleneck}}
}
@article{Krause2008,
abstract = {When monitoring spatial phenomena, which can often be modeled as Gaussian processes (GPs), choosing sensor locations is a fundamental task. There are several common strategies to address this task, for example, geometry or disk models, placing sensors at the points of highest entropy (vari-ance) in the GP model, and A-, D-, or E-optimal design. In this paper, we tackle the combinatorial optimization problem of maximizing the mutual information between the chosen locations and the locations which are not selected. We prove that the problem of finding the configuration that max-imizes mutual information is NP-complete. To address this issue, we describe a polynomial-time approximation that is within (1 − 1/e) of the optimum by exploiting the submodularity of mutual information. We also show how submodularity can be used to obtain online bounds, and design branch and bound search procedures. We then extend our algorithm to exploit lazy evaluations and local structure in the GP, yielding significant speedups. We also extend our approach to find placements which are robust against node failures and uncertainties in the model. These extensions are again associated with rigorous theoretical approximation guarantees, exploiting the submodu-larity of the objective function. We demonstrate the advantages of our approach towards optimizing mutual information in a very extensive empirical study on two real-world data sets.},
author = {Krause, A and Singh, Aarti and Guestrin, C},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krause, Singh, Guestrin - 2008 - Near-optimal sensor placements in Gaussian processes Theory, efficient algorithms and empirical studies.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {Gaussian processes,active learning,experimental design,submodularity},
pages = {235--284},
title = {{Near-optimal Sensor Placements in Gaussian Processes: Theory, Efficient Algorithms and Empirical Studies}},
volume = {9},
year = {2008}
}
@inproceedings{Krenn2013,
address = {Noordwijk, The Netherlands},
author = {Krenn, Rainer and Gibbesch, Andreas and Binet, Giovanni and Bemporad, Alberto},
booktitle = {Proceedings of the 12th Symposium on Advanced Space Technologies in Automation and Robotics},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krenn et al. - 2013 - Model predictive traction and steering control of planetary rovers.pdf:pdf},
pages = {13--20},
title = {{Model predictive traction and steering control of planetary rovers}},
year = {2013}
}
@inproceedings{Kuindersma2012,
abstract = {Abstract—We present a new Bayesian policy search algorithm suitable for problems with policy-dependent cost variance, a property present in many robot control tasks. We extend recent work on variational heteroscedastic Gaussian processes to the optimization case to ... $\backslash$n},
author = {Kuindersma, S and Grupen, R},
booktitle = {Robotics: Science and {\ldots}},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuindersma, Grupen - 2012 - Variational Bayesian optimization for runtime risk-sensitive control.pdf:pdf},
isbn = {9780262519687},
issn = {{\textless}null{\textgreater}},
pages = {201--206},
title = {{Variational Bayesian optimization for runtime risk-sensitive control}},
url = {http://people.cs.umass.edu/{~}scottk/files/vbo-rss.pdf$\backslash$npapers2://publication/uuid/258F3338-DF5F-4C2C-840E-AA19884E3B56},
year = {2012}
}
@article{Kuindersma2013,
abstract = {We present new global and local policy search algorithms suitable for problems with policy-dependent cost variance (or risk), a property present in many robot control tasks. These algorithms exploit new techniques in nonparameteric heteroscedastic regression to directly model the policy-dependent distribu-tion of cost. For local search, the learned cost model can be used as a critic for performing risk-sensitive gradient descent. Alternatively, decision-theoretic criteria can be applied to globally select policies to balance exploration and exploitation in a principled way, or to perform greedy minimization with respect to various risk-sensitive criteria. This separation of learning and policy selection permits variable risk control, where risk sensitivity can be flexibly adjusted and appropriate policies can be selected at runtime without relearning. We describe experiments in dynamic stabilization and manipulation with a mobile manipulator that demonstrate learning of flexible, risk-sensitive policies in very few trials.},
author = {Kuindersma, Scott R. and Grupen, Roderic A. and Barto, Andrew G.},
doi = {10.1177/0278364913476124},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kuindersma, Grupen, Barto - 2013 - Variable Risk Control via Stochastic Optimization.pdf:pdf},
issn = {0278-3649},
journal = {International Journal of Robotics Research},
number = {7},
pages = {806--825},
title = {{Variable Risk Control via Stochastic Optimization}},
url = {http://www-robotics.cs.umass.edu/uploads/Main/Kuindersma{\_}etal{\_}IJRR13.pdf},
volume = {32},
year = {2013}
}
@inproceedings{Lai2016,
author = {Lai, Edmund M-k and Cao, Gang and Lai, Edmund M-k and Alam, Fakhrul},
booktitle = {2016 IEEE 14th International Workshop on Advanced Motion Control},
doi = {10.1109/AMC.2016.7496359},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lai et al. - 2016 - Gaussian Process Model based Probabilistic Model Predictive Control for Linear Time Varying Systems.pdf:pdf},
isbn = {9781479984640},
pages = {251--256},
title = {{Gaussian Process Model based Probabilistic Model Predictive Control for Linear Time Varying Systems}},
year = {2016}
}
@article{Lang2018,
abstract = {The assessment of Parkinson's disease (PD) poses a significant challenge as it is influenced by various factors which lead to a complex and fluctuating symptom manifestation. Thus, a frequent and objective PD assessment is highly valuable for effective health management of people with Parkinson's disease (PwP). Here, we propose a method for monitoring PwP by stochastically modeling the relationships between their wrist movements during unscripted daily activities and corresponding annotations about clinical displays of movement abnormalities. We approach the estimation of PD motor signs by independently modeling and hierarchically stacking Gaussian process models for three classes of commonly observed movement abnormalities in PwP including tremor, (non-tremulous) bradykinesia, and (non-tremulous) dyskinesia. We use clinically adopted severity measures as annotations for training the models, thus allowing our multi-layer Gaussian process prediction models to estimate not only their presence but also their severities. The experimental validation of our approach demonstrates strong agreement of the model predictions with these PD annotations. Our results show the proposed method produces promising results in objective monitoring of movement abnormalities of PD in the presence of arbitrary and unknown voluntary motions, and makes an important step towards continuous monitoring of PD in the home environment.},
archivePrefix = {arXiv},
arxivId = {1808.10663},
author = {Lang, Muriel and Fietzek, Urban and Fr{\"{o}}hner, Jakob and Pfister, Franz M. J. and Pichler, Daniel and Abedinpour, Kian and Um, Terry T. and Kuli{\'{c}}, Dana and Endo, Satoshi and Hirche, Sandra},
eprint = {1808.10663},
file = {:home/alederer/Local/Literatur/Parkinson/Parkinson Prediction/Lang{\_}sumbitted{\_}TBME.pdf:pdf},
pages = {1--11},
title = {{A Multi-layer Gaussian Process for Motor Symptom Estimation in People with Parkinson's Disease}},
url = {http://arxiv.org/abs/1808.10663},
year = {2018}
}
@article{Laurent2000,
abstract = {We consider the problem of estimating s 2 when s belongs to some separable Hilbert space and one observes the Gaussian process Yt = ss t + $\sigma$Lt, for all t ∈ , where L is some Gaussian isonormal process. This framework allows us in particular to consider the classical " Gaussian sequence model " for which = l 2 * and Lt = $\lambda$≥1 t $\lambda$ $\epsilon$ $\lambda$ , where $\epsilon$ $\lambda$ $\lambda$≥1 is a sequence of i.i.d. standard normal variables. Our approach consists in considering some at most countable families of finite-dimensional linear subspaces of (the models) and then using model selection via some con-veniently penalized least squares criterion to build new estimators of s 2 . We prove a general nonasymptotic risk bound which allows us to show that such penalized estimators are adaptive on a variety of collections of sets for the parameter s, depending on the family of models from which they are built. In particular, in the context of the Gaussian sequence model, a con-venient choice of the family of models allows defining estimators which are adaptive over collections of hyperrectangles, ellipsoids, l p -bodies or Besov bodies. We take special care to describe the conditions under which the penalized estimator is efficient when the level of noise $\sigma$ tends to zero. Our construction is an alternative to the one by Efromovich and Low for hyperrectangles and provides new results otherwise.},
author = {Laurent, B. and Massart, Pascal},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Laurent, Massart - 2000 - Adaptive Estimation of a Quadratic Functional by Model Selection.pdf:pdf},
journal = {The Annals of Statistics},
keywords = {Adaptive minimax estimation,Besov bodies,Haar basis,Projection estimators,Quadratic functional estimation,Weighted distributions},
number = {5},
pages = {1302--1338},
title = {{Adaptive Estimation of a Quadratic Functional by Model Selection}},
volume = {28},
year = {2000}
}
@article{LawrenceNEIL2005,
abstract = {Summarising a high dimensional data set with a low dimensional embedding is a standard approach for exploring its structure. In this paper we provide an overview of some existing techniques for discovering such embeddings. We then introduce a novel probabilistic interpretation of principal component analysis (PCA) that we term dual probabilistic PCA (DPPCA). The DPPCA model has the additional advantage that the linear mappings from the embedded space can easily be non-linearised through Gaussian processes. We refer to this model as a Gaussian process latent variable model (GP-LVM). Through analysis of the GP-LVM objective function, we relate the model to popular spectral techniques such as kernel PCA and multidimensional scaling. We then review a practical algorithm for GP-LVMs in the context of large data sets and develop it to also handle discrete valued data and missing attributes. We demonstrate the model on a range of real-world and artificially generated data sets.},
author = {Lawrence, Neil D.},
file = {:home/alederer/Local/Literatur/Parkinson/GP Modelling/Probabilistic Non-linear Principal Component Analysis with Gaussian Process Latent Variable Models.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {gaussian processes,latent variable models,methods,principal component analysis,spectral,unsupervised learning,visualisation},
pages = {1783--1816},
title = {{Probabilistic Non-linear Principal Component Analysis with Gaussian Process Latent Variable Models}},
volume = {6},
year = {2005}
}
@article{Lazopoulos2004,
author = {Lazopoulos, Achilleas},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lazopoulos - 2004 - Error estimates in Monte Carlo and Quasi-Monte Carlo integration.pdf:pdf},
issn = {05874254},
journal = {Acta Physica Polonica B},
number = {11},
pages = {2617--2632},
title = {{Error estimates in Monte Carlo and Quasi-Monte Carlo integration}},
volume = {35},
year = {2004}
}
@article{LeGratiet2014,
abstract = {This paper deals with the learning curve in a Gaussian process regression frame-work. The learning curve describes the generalization error of the Gaussian process used for the regression. The main result is the proof of a theorem giving the generalization error for a large class of correlation kernels and for any dimension when the number of observations is large. From this theorem, we can deduce the asymptotic behavior of the generalization error when the observation error is small. The presented proof generalizes previous ones that were limited to special kernels or to small dimensions (one or two). The theoretical results are applied to a nuclear safety problem.},
author = {{Le Gratiet}, Loic and Garnier, Josselin},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Le Gratiet, Garnier - 2014 - Asymptotic analysis of the learning curve for Gaussian process regression.pdf:pdf},
journal = {Machine Learning},
keywords = {Asymptotic mean squared error,Convergence rate,Gaussian process regression,Generalization error,Learning curves},
number = {3},
pages = {407--433},
title = {{Asymptotic Analysis of the Learning Curve for Gaussian Process Regression}},
volume = {98},
year = {2014}
}
@inproceedings{Lederer2019,
author = {Lederer, Armin and Hirche, Sandra},
booktitle = {Proceedings of the IEEE Conference on Decision and Control},
file = {:home/alederer/Documents/gitlab/bre-for-stab/paper/root.pdf:pdf},
title = {{Local Asymptotic Stability Analysis and Region of Attraction Estimation with Gaussian Processes}},
year = {2019}
}
@article{Lederer2019a,
abstract = {The posterior variance of Gaussian processes is a valuable measure of the learning error which is exploited in various applications such as safe reinforcement learning and control design. However, suitable analysis of the posterior variance which captures its behavior for finite and infinite number of training data is missing. This paper derives a novel bound for the posterior variance function which requires only local information because it depends only on the number of training samples in the proximity of a considered test point. Furthermore, we prove sufficient conditions which ensure the convergence of the posterior variance to zero. Finally, we demonstrate that the extension of our bound to an average learning bound outperforms existing approaches.},
archivePrefix = {arXiv},
arxivId = {1906.01404},
author = {Lederer, Armin and Umlauft, Jonas and Hirche, Sandra},
eprint = {1906.01404},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lederer, Umlauft, Hirche - Unknown - Posterior Variance Analysis of Gaussian Processes with Application to Average Learning Curves.pdf:pdf},
title = {{Posterior Variance Analysis of Gaussian Processes with Application to Average Learning Curves}},
url = {http://arxiv.org/abs/1906.01404},
year = {2019}
}
@inproceedings{Lederer2019,
abstract = {Data-driven models are subject to model errors due to limited and noisy training data. Key to the application of such models in safety-critical domains is the quantification of their model error. Gaussian processes provide such a measure and uniform error bounds have been derived, which allow safe control based on these models. However, existing error bounds require restrictive assumptions. In this paper, we employ the Gaussian process distribution and continuity arguments to derive a novel uniform error bound under weaker assumptions. Furthermore, we demonstrate how this distribution can be used to derive probabilistic Lipschitz constants and analyze the asymptotic behavior of our bound. Finally, we derive safety conditions for the control of unknown dynamical systems based on Gaussian process models and evaluate them in simulations of a robotic manipulator.},
archivePrefix = {arXiv},
arxivId = {1906.01376},
author = {Lederer, Armin and Umlauft, Jonas and Hirche, Sandra},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1906.01376},
file = {:home/alederer/Documents/gitlab/gp-error-bound/arxiv Paper/nips{\_}2019.pdf:pdf},
title = {{Uniform Error Bounds for Gaussian Process Regression with Application to Safe Control}},
url = {http://arxiv.org/abs/1906.01376},
year = {2019}
}
@article{Lee2017,
abstract = {As we aim to control complex systems, use of a simulator in model-based reinforcement learning is becoming more common. However, it has been challenging to overcome the Reality Gap, which comes from nonlinear model bias and susceptibility to disturbance. To address these problems, we propose a novel algorithm that combines data-driven system identification approach (Gaussian Process) with a Differential-Dynamic-Programming-based robust optimal control method (Iterative Linear Quadratic Control). Our algorithm uses the simulator's model as the mean function for a Gaussian Process and learns only the difference between the simulator's prediction and actual observations, making it a natural hybrid of simulation and real-world observation. We show that our approach quickly corrects incorrect models, comes up with robust optimal controllers, and transfers its acquired model knowledge to new tasks efficiently.},
archivePrefix = {arXiv},
arxivId = {1705.05344},
author = {Lee, Gilwoo and Srinivasa, Siddhartha S. and Mason, Matthew T.},
eprint = {1705.05344},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee, Srinivasa, Mason - 2017 - GP-ILQG Data-driven Robust Optimal Control for Uncertain Nonlinear Dynamical Systems.pdf:pdf},
isbn = {9781538626818},
title = {{GP-ILQG: Data-driven Robust Optimal Control for Uncertain Nonlinear Dynamical Systems}},
url = {http://arxiv.org/abs/1705.05344},
year = {2017}
}
@article{Lee2017a,
abstract = {It has long been known that a single-layer fully-connected neural network with an i.i.d. prior over its parameters is equivalent to a Gaussian process (GP), in the limit of infinite network width. This correspondence enables exact Bayesian inference for infinite width neural networks on regression tasks by means of evaluating the corresponding GP. Recently, kernel functions which mimic multi-layer random neural networks have been developed, but only outside of a Bayesian framework. As such, previous work has not identified that these kernels can be used as covariance functions for GPs and allow fully Bayesian prediction with a deep neural network. In this work, we derive the exact equivalence between infinitely wide deep networks and GPs. We further develop a computationally efficient pipeline to compute the covariance function for these GPs. We then use the resulting GPs to perform Bayesian inference for wide deep neural networks on MNIST and CIFAR-10. We observe that trained neural network accuracy approaches that of the corresponding GP with increasing layer width, and that the GP uncertainty is strongly correlated with trained network prediction error. We further find that test performance increases as finite-width trained networks are made wider and more similar to a GP, and thus that GP predictions typically outperform those of finite-width networks. Finally we connect the performance of these GPs to the recent theory of signal propagation in random neural networks.},
archivePrefix = {arXiv},
arxivId = {1711.00165},
author = {Lee, Jaehoon and Bahri, Yasaman and Novak, Roman and Schoenholz, Samuel S. and Pennington, Jeffrey and Sohl-Dickstein, Jascha},
doi = {arXiv:1711.00165v3},
eprint = {1711.00165},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee et al. - 2017 - Deep Neural Networks as Gaussian Processes.pdf:pdf},
isbn = {0022-1767 (Print)$\backslash$r0022-1767 (Linking)},
issn = {18785352},
pmid = {7594604},
title = {{Deep Neural Networks as Gaussian Processes}},
url = {http://arxiv.org/abs/1711.00165},
year = {2017}
}
@article{Lee2018,
author = {Lee, Jaehwa and Zhang, Pengfei and Gan, Leong Kit and Howey, David A and Michael, A and Tosi, Alessandra and Duncan, Stephen},
doi = {10.1109/JESTPE.2018.2820071},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee et al. - 2018 - Optimal operation of an energy management system using model predictive control and Gaussian process time-series mod.pdf:pdf},
journal = {IEEE Journal of Emerging and Selected Topics in Power Electronics},
pages = {1--22},
title = {{Optimal operation of an energy management system using model predictive control and Gaussian process time-series modelling}},
year = {2018}
}
@inproceedings{Lehnert2013,
abstract = {This paper proposes an online learning control system that uses the strategy of Model Predictive Control (MPC) in a model based locally weighted learning framework. The new approach, named Locally Weighted Learning Model Predictive Control (LWL-MPC), is proposed as a solution to learn to control robotic systems with nonlinear and time varying dynamics. This paper demonstrates the capability of LWL-MPC to perform online learning while controlling the joint trajectories of a low cost, three degree of freedom elastic joint robot. The learning performance is investigated in both an initial learning phase, and when the system dynamics change due to a heavy object added to the tool point. The experiment on the real elastic joint robot is presented and LWL-MPC is shown to successfully learn to control the system with and without the object. The results highlight the capability of the learning control system to accommodate the lack of mechanical consistency and linearity in a low cost robot arm.},
author = {Lehnert, Christopher and Wyeth, Gordon},
booktitle = {2013 IEEE International Conference on Robotics and Automation (ICRA)},
doi = {10.1109/ICRA.2013.6630936},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lehnert, Wyeth - 2013 - Locally Weighted Learning Model Predictive Control for Nonlinear and Time Varying Dynamics.pdf:pdf},
isbn = {9781467356428},
issn = {1050-4729},
keywords = {Learning and Adaptive Systems},
pages = {2619--2625},
title = {{Locally Weighted Learning Model Predictive Control for Nonlinear and Time Varying Dynamics}},
year = {2013}
}
@book{Lemieux2009,
address = {New York},
author = {Lemieux, Christiane},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lemieux - 2009 - Monte Carlo and Quasi-Monte Carlo Sampling.pdf:pdf},
isbn = {9780387848570},
issn = {03436993},
pmid = {15512507},
publisher = {Springer Science+Business Media},
title = {{Monte Carlo and Quasi-Monte Carlo Sampling}},
year = {2009}
}
@inproceedings{Lenz2015,
abstract = {Designing controllers for tasks with complex non- linear dynamics is extremely challenging, time-consuming, and in many cases, infeasible. This difficulty is exacerbated in tasks such as robotic food-cutting, in which dynamics might vary both with environmental properties, such as material and tool class, and with time while acting. In this work, we present DeepMPC, an online real-time model-predictive control approach designed to handle such difficult tasks. Rather than hand-design a dynamics model for the task, our approach uses a novel deep architecture and learning algorithm, learning controllers for complex tasks directly from data. We validate our method in experiments on a large-scale dataset of 1488 material cuts for 20 diverse classes, and in 450 real-world robotic experiments, demonstrating significant improvement over several other approaches.},
author = {Lenz, Ian and Knepper, Ross and Saxena, Ashutosh},
booktitle = {Proceedings of Robotics: Science and Systems XI},
doi = {10.15607/RSS.2015.XI.012},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lenz, Knepper, Saxena - 2015 - DeepMPC Learning Deep Latent Features for Model Predictive Control.pdf:pdf},
isbn = {9780992374716},
issn = {2330765X},
title = {{DeepMPC: Learning Deep Latent Features for Model Predictive Control}},
year = {2015}
}
@article{Li2013,
abstract = { This paper studies the stability for nonlinear stochastic discrete-time systems. First of all, several definitions on stability are introduced, such as stability, asymptotical stability, and p th moment exponential stability. Moreover, using the method of the Lyapunov functionals, some efficient criteria for stochastic stability are obtained. Some examples are presented to illustrate the effectiveness of the proposed theoretical results. },
author = {Li, Yan and Zhang, Weihai and Liu, Xikui},
doi = {10.1155/2013/356746},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li, Zhang, Liu - 2013 - Stability of nonlinear stochastic discrete-time systems.pdf:pdf},
issn = {1110757X},
journal = {Journal of Applied Mathematics},
number = {2},
title = {{Stability of nonlinear stochastic discrete-time systems}},
volume = {2013},
year = {2013}
}
@article{Liang2005,
abstract = {In this article, we apply Bayesian neural networks (BNNs) to time series analysis, and propose a Monte Carlo algorithm for BNN training. In addition, we go a step further in BNN model selection by putting a prior on network connections instead of hidden units as done by other authors. This allows us to treat the selection of hidden units and the selection of input variables uniformly. The BNN model is compared to a number of competitors, such as the Box-Jenkins model, bilinear model, threshold autoregressive model, and traditional neural network model, on a number of popular and challenging data sets. Numerical results show that the BNN model has achieved a consistent improvement over the competitors in forecasting future values. Insights on how to improve the generalization ability of BNNs are revealed in many respects of our implementation, such as the selection of input variables, the specification of prior distributions, and the treatment of outliers.},
author = {Liang, Faming},
file = {:home/alederer/Documents/Literatur/Learning/Deep Learning/Bayesian Neural Networks for Nonlinear Time Series Forecasting.pdf:pdf},
issn = {09603174},
journal = {Statistics and Computing},
keywords = {Bayesian model averaging,Bayesian neural network,Evolutionary Monte Carlo,Markov Chain Monte Carlo,Nonlinear time series forecasting},
number = {1},
pages = {13--29},
title = {{Bayesian neural networks for nonlinear time series forecasting}},
volume = {15},
year = {2005}
}
@article{Likar2007,
abstract = {Gaussian process models provide a probabilistic non-parametric modelling approach for black-box identification of non-linear dynamic systems. The Gaussian processes can highlight areas of the input space where prediction quality is poor, due to the lack of data or to its complexity, by indicating the higher variance around the predicted mean. Gaussian process models contain noticeably less coefficients to be optimised. This paper demonstrates feasibility of application and realisation of a control algorithm based on a Gaussian process model. The extra information provided by the Gaussian process model is used in predictive control, where optimisation of the control signal takes the variance information into account. The feasibility of Gaussian process model usage for predictive control in industrial practice is demonstrated via the control of a gas–liquid separation plant.},
author = {Likar, Bojan and Kocijan, Ju{\v{s}}},
doi = {http://dx.doi.org/10.1016/j.compchemeng.2006.05.011},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Likar, Kocijan - 2007 - Predictive control of a gas–liquid separation plant based on a Gaussian process model.pdf:pdf},
issn = {0098-1354},
journal = {Computers {\&} Chemical Engineering},
keywords = {Dynamic systems identification,Gas–liquid separation plant,Gaussian process model,Model-based predictive control,Process control},
number = {3},
pages = {142--152},
title = {{Predictive control of a gas–liquid separation plant based on a Gaussian process model}},
url = {http://www.sciencedirect.com/science/article/pii/S009813540600127X},
volume = {31},
year = {2007}
}
@article{Limon2006b,
abstract = {Min-max model predictive control (MPC) is one of the control techniques capable of robustly stabilize uncertain nonlinear systems subject to constraints. In this paper we extend existing results on robust stability of min-max MPC to the case of systems with uncertainties which depend on the state and the input and not necessarily decaying, i.e. state and input dependent bounded uncertainties. This allows us to consider both plant uncertainties and external disturbances in a less conservative way. It is shown that the input-to-state practical stability (ISpS) notion is suitable to analyze the stability of worst-case based controllers. Thus, we provide Lyapunov-like sufficient conditions for ISpS. Based on this, it is proved that if the terminal cost is an ISpS-Lyapunov function then the optimal cost is also an ISpS-Lyapunov function for the system controlled by the min-max MPC and hence, the controlled system is ISpS. Moreover, we show that if the system controlled by the terminal control law locally admits certain stability margin, then the system controlled by the min-max MPC retains the stability margin in the feasibility region. {\textcopyright} 2006 Elsevier Ltd. All rights reserved.},
author = {Limon, D. and Alamo, T. and Salas, F. and Camacho, E. F.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Limon et al. - 2006 - Input to state stability of min-max MPC controllers for nonlinear systems with bounded uncertainties.pdf:pdf},
journal = {Automatica},
keywords = {Constraints,Input-to-state stability,Model predictive control,Nonlinear systems},
number = {5},
pages = {797--803},
title = {{Input to state stability of min-max MPC controllers for nonlinear systems with bounded uncertainties}},
volume = {42},
year = {2006}
}
@article{Limon2017,
abstract = {This paper presents stabilizing Model Predictive Controllers (MPC) in which prediction models are inferred from experimental data of the inputs and outputs of the plant. Using a nonparametric machine learning technique called LACKI, the estimated (possibly nonlinear) model function together with an estimation of Holder constant is provided. Based on these, a number of predictive controllers with stability guaranteed by design are proposed. Firstly, the case when the prediction model is estimated offline is considered and robust stability and recursive feasibility is ensured by using tightened constraints in the optimisation problem. This controller has been extended to the more interesting and complex case: the online learning of the model, where the new data collected from feedback is added to enhance the prediction model. An on-line learning MPC based on a double sequence of predictions is proposed.},
author = {Limon, D. and Calliess, J. and Maciejowski, J. M.},
doi = {10.1016/j.ifacol.2017.08.1050},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Limon, Calliess, Maciejowski - 2017 - Learning-based Nonlinear Model Predictive Control.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Data-based control,Input-to-state stability,MPC,Machine learning},
number = {1},
pages = {7769--7776},
publisher = {Elsevier B.V.},
title = {{Learning-based Nonlinear Model Predictive Control}},
volume = {50},
year = {2017}
}
@incollection{Limon2007,
author = {Limon, Daniel and Alamo, Teodoro and Raimondo, Davide M. and {Pena Munoz de la}, David and Bravo, Jose Manuel and Ferramosca, Antonio and Camacho, Eduardo F.},
booktitle = {Lecture Notes in Control and Information Sciences},
doi = {10.1007/978-3-540-74356-9},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Limon et al. - 2007 - Input-to-State Stability A Unifying Framework for Robust Model Predictive Control.pdf:pdf},
isbn = {3540743545},
issn = {01708643},
pages = {1--26},
title = {{Input-to-State Stability: A Unifying Framework for Robust Model Predictive Control}},
year = {2007}
}
@article{Liu2018,
abstract = {Efficient exploration is one of the key challenges for reinforcement learning (RL) algorithms. Most traditional sample efficiency bounds require strategic exploration. Recently many deep RL algorithms with simple heuristic exploration strategies that have few formal guarantees, achieve surprising success in many domains. These results pose an important question about understanding these exploration strategies such as {\$}e{\$}-greedy, as well as understanding what characterize the difficulty of exploration in MDPs. In this work we propose problem specific sample complexity bounds of {\$}Q{\$} learning with random walk exploration that rely on several structural properties. We also link our theoretical results to some empirical benchmark domains, to illustrate if our bound gives polynomial sample complexity in these domains and how that is related with the empirical performance.},
archivePrefix = {arXiv},
arxivId = {1805.09045},
author = {Liu, Yao and Brunskill, Emma},
eprint = {1805.09045},
file = {:home/alederer/Documents/Literatur/Learning/PAC Bounds for RL/When Simple Exploration is Sample Efficient{\_} Identifying Sufficient Conditions for Random Exploration to Yield PAC RL Algorithms.pdf:pdf},
number = {October},
title = {{When Simple Exploration is Sample Efficient: Identifying Sufficient Conditions for Random Exploration to Yield PAC RL Algorithms}},
url = {http://arxiv.org/abs/1805.09045},
volume = {14},
year = {2018}
}
@article{Liu2018a,
abstract = {We study the problem of off-policy policy evaluation (OPPE) in RL. In contrast to prior work, we consider how to estimate both the individual policy value and average policy value accurately. We draw inspiration from recent work in causal reasoning, and propose a new finite sample generalization error bound for value estimates from MDP models. Using this upper bound as an objective, we develop a learning algorithm of an MDP model with a balanced representation, and show that our approach can yield substantially lower MSE in common synthetic benchmarks and a HIV treatment simulation domain.},
archivePrefix = {arXiv},
arxivId = {1805.09044},
author = {Liu, Yao and Gottesman, Omer and Raghu, Aniruddh and Komorowski, Matthieu and Faisal, Aldo and Doshi-Velez, Finale and Brunskill, Emma},
eprint = {1805.09044},
file = {:home/alederer/Documents/Literatur/Learning/Off-Policy Policy Evaluation/Representation Balancing MDPs for Off-Policy Policy Evaluation.pdf:pdf},
number = {NeurIPS},
title = {{Representation Balancing MDPs for Off-Policy Policy Evaluation}},
url = {http://arxiv.org/abs/1805.09044},
year = {2018}
}
@article{Long2006,
abstract = {This paper presents a Nonlinear Model Predictive Control (NMPC) algorithm utilizing a deterministic global optimization method. Utilizing local techniques on nonlinear nonconvex problems leaves one susceptible to suboptimal solutions at each iteration. In complex problems, local solver reliability is difficult to predict and dependent upon the choice of initial guess. This paper demonstrates the application of a deterministic global solution technique to an example NMPC problem. A terminal state constraint is used in the example case study. In some cases the local solution method becomes infeasible, while the global solution correctly finds the feasible global solution. Increased computational burden is the most significant limitation for global optimization based online control techniques. This paper provides methods for improving the global optimization rates of convergence. This paper also shows that globally optimal NMPC methods can provide benefits over local techniques and can successfully be used for online control. {\textcopyright} 2006 Elsevier Ltd. All rights reserved.},
author = {Long, C. E. and Polisetty, P. K. and Gatzke, E. P.},
doi = {10.1016/j.jprocont.2005.11.001},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Long, Polisetty, Gatzke - 2006 - Nonlinear model predictive control using deterministic global optimization.pdf:pdf},
issn = {09591524},
journal = {Journal of Process Control},
keywords = {Branch-and-reduce,Constrained nonlinear control,Global optimization,Nonlinear model predictive control},
number = {6},
pages = {635--643},
title = {{Nonlinear model predictive control using deterministic global optimization}},
volume = {16},
year = {2006}
}
@article{Long2004,
author = {Long, C.E. and Polisetty, P.K. and Gatzke, E.P.},
doi = {10.1016/S1474-6670(17)31798-6},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Long, Polisetty, Gatzke - 2004 - Globally Optimal Nonlinear Model Predictive Control.pdf:pdf},
issn = {14746670},
journal = {IFAC Proceedings Volumes},
keywords = {Constrained Nonlinear Control,Nonlinear Model Pred,branch-and-reduce,constrained nonlinear control,convexification,global,nonlinear model predictive control,optimization},
number = {9},
pages = {83--88},
publisher = {Elsevier},
title = {{Globally Optimal Nonlinear Model Predictive Control}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1474667017317986},
volume = {37},
year = {2004}
}
@article{Gatzke2006,
abstract = {Asymptotic output-feedback tracking in a class of causal nonminimum phase uncertain nonlinear systems is addressed via sliding mode techniques. Sliding mode control is proposed for robust stabilization of the output tracking error in the presence of a bounded disturbance. The output reference profile and the unknown input/disturbance are supposed to be described by unknown linear exogenous systems of a given order. Local asymptotic stability of the output tracking error dynamics along with the boundedness of the internal states are proven. The unstable internal states are estimated asymptotically via the proposed multistage observer that is based on the method of extended system center. A higher-order sliding mode observer/differentiator is used for the exact estimation of the input–output states in a finite time. The bounded disturbance is reconstructed asymptotically. A numerical example illustrates the efficiency of the proposed output-feedback tracking approach developed for causal nonminimum phase nonlinear systems.},
archivePrefix = {arXiv},
arxivId = {arXiv:1505.02595v1},
author = {Long, Christopher E. and Polisetty, Pradeep K. and Gatzke, Edward P.},
doi = {10.1002/rnc},
eprint = {arXiv:1505.02595v1},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Long, Polisetty, Gatzke - 2006 - Deterministic Global Optimization for Nonlinear Model Predictive Control of Hybrid Dynamic Systems.pdf:pdf},
isbn = {1049-8923},
issn = {10498923},
journal = {International Journal of Robust and Nonlinear Control},
keywords = {higher-order sliding mode,nonminimum phase,output-feedback tracking},
pages = {1232--1250},
pmid = {18795146},
title = {{Deterministic Global Optimization for Nonlinear Model Predictive Control of Hybrid Dynamic Systems}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/rnc.1553/abstract},
volume = {17},
year = {2006}
}
@article{Lourenco2013,
abstract = {This paper presents Nonlinear Model Predictive Control (NMPC) of neuromuscular blockade induced by atracurium on patients subject to general anesthesia. In order to tackle the high levels of uncertainty in the process behavior, probabilistic and non-parametric Gaussian process models are used in the NMPC approach. The proposed control structure was tested in a bank of models that represent patients subject to general anesthesia under elective surgery. All patients models were stabilized and yield a satisfactory performance. {\textcopyright} 2012 Elsevier Ltd. All rights reserved.},
author = {Louren{\c{c}}o, J. M. and Lemos, J. M. and Marques, J. S.},
doi = {10.1016/j.bspc.2012.10.007},
file = {:home/alederer/Documents/Literatur/Learning Based MPC/gp mpc/Control of neuromuscular blockade with Gaussian process models.pdf:pdf},
issn = {17468094},
journal = {Biomedical Signal Processing and Control},
keywords = {Anesthesia,Gaussian process models,Neuromuscular blockade,Nonlinear model predictive control,Nonlinear systems},
number = {3},
pages = {244--254},
title = {{Control of neuromuscular blockade with Gaussian process models}},
volume = {8},
year = {2013}
}
@article{Lu2002,
abstract = {In this paper, the authors give explicit inverse formulae for 2 × 2 block matrices with three different partitions. Then these results are applied to obtain inverses of block triangular matrices and various structured matrices such as Hamiltonian, per-Hermitian, and centro-Hermitian matrices.},
author = {Lu, Tzon Tzer and Shiou, Sheng H.},
file = {:home/alederer/Documents/Literatur/Books/Inverses of 2x2 Block Matrices.pdf:pdf},
isbn = {0898-1221},
issn = {08981221},
journal = {Computers and Mathematics with Applications},
keywords = {1,2 x 2 block,e r is devoted,i n t r,inverse matrix,matrices,o d u c,structured matrix,t i o n,this p a p,to the inverses of,x 2 block matrix},
number = {1-2},
pages = {119--129},
title = {{Inverses of 2 {\$}\backslashtimes{\$} 2 block matrices}},
volume = {43},
year = {2002}
}
@article{Lucia2018,
abstract = {Dealing with uncertainties is one of the most challenging issues that prevent nonlinear model predictive control (NMPC) from being a widespread reality. Many different robust schemes have been presented recently, such as multi-stage NMPC, in which the uncertainty is represented as a scenario tree. While multi-stage NMPC achieves promising performance in practice, it suffers from an exponential increase in complexity with the number of uncertainties considered making its real-time application difficult for large case studies. We suggest in this work to use multi-stage NMPC as a generator of data pairs that are used to learn the robust NMPC policy by means of deep neural networks. This choice is motivated by recent practical successes of deep learning and theoretical results that explain the improved representation capabilities of deep networks with respect to shallow networks. We present empirical evidence which shows that the use of deep neural networks with many hidden layers as opposed to shallow networks with only one significantly improves the learning process of a robust NMPC control law. These findings are illustrated with simulation studies of an industrial polymerization reactor.},
author = {Lucia, Sergio and Karg, Benjamin},
file = {:home/alederer/Documents/Literatur/Learning Based MPC/deep mpc/A deep learning-based approach to robust nonlinear model predictive control.pdf:pdf},
journal = {IFAC-PapersOnLine},
number = {20},
pages = {511--516},
publisher = {Elsevier B.V.},
title = {{A deep learning-based approach to robust nonlinear model predictive control}},
volume = {51},
year = {2018}
}
@article{Ludwig1997,
author = {Ludwig, Donald and Walker, Brian and Holling, Crawford S},
file = {:home/alederer/Local/Literatur/sampling based Stability analysis/Sustainability, Stability, and Resilience.pdf:pdf},
journal = {Conservation Ecology},
keywords = {bifurcation,multiple stable states,resilience,stability},
number = {1},
title = {{Sustainability, Stability, and Resilience}},
volume = {1},
year = {1997}
}
@article{Ludwig1997,
author = {Ludwig, Donald and Walker, Brian and Holling, Crawford S},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ludwig, Walker, Holling - 1997 - Sustainability , Stability , and Resilience.pdf:pdf},
journal = {Conservation Ecology},
keywords = {bifurcation,multiple stable states,resilience,stability},
number = {1},
pages = {1--23},
title = {{Sustainability, Stability, and Resilience}},
volume = {1},
year = {1997}
}
@article{Luk2015,
author = {Luk, Chuen Kit and Chesi, Graziano},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Luk, Chesi - 2015 - On the Estimation of the Domain of Attraction for Discrete-Time Switched and Hybrid Nonlinear Systems.pdf:pdf},
journal = {International Journal of Systems Science},
number = {15},
pages = {2781--2787},
title = {{On the Estimation of the Domain of Attraction for Discrete-Time Switched and Hybrid Nonlinear Systems}},
volume = {46},
year = {2015}
}
@article{Lygeros2015,
abstract = {Motivated by chance constrained optimisation problems that arise in stochastic model predictive control we investigate the connections between compression learning and scenario based optimisation. We discuss how compression learning provides powerful insight into a fundamental property that ensures optimal solutions to optimisation problems formulated using a finite number of realisations of the uncertainty will also be feasible for other, unseen instances of the uncertainty. This property, known as -consistency-, roughly translates to the requirement that a fixed cardinality subset of the scenarios used to generate the optimal solution are enough to encode all the information needed to reconstruct the solution; all remaining scenarios are in a sense redundant. Computationally the catch of course is it is impossible to know a-priori which of the scenarios will be essential and which not. Moreover, the -unnecessary- scenarios are not wasted even in theory: Their presence is what provides the confidence level with which we can make the statement that the solution is feasible for unseen uncertainty instances. We demonstrate this connection through chance constrained optimisation programs based on a combination of scenarios and robust optimisation.},
author = {Lygeros, John and Margellos, Kostas and Prandini, Maria},
doi = {10.1016/j.ifacol.2015.11.297},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lygeros, Margellos, Prandini - 2015 - Compression learning for chance constrained stochastic MPC.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Model predictive control,machine learning,optimisation problems,randomised optimisation,stochastic systems},
number = {23},
pages = {286--293},
publisher = {Elsevier B.V.},
title = {{Compression learning for chance constrained stochastic MPC}},
volume = {48},
year = {2015}
}
@inproceedings{Maciejowski2013,
author = {Maciejowski, Jan M. and Yang, Xiaoke},
booktitle = {Proceedings of the 2013 Conference on Control and Fault-Tolerant Systems (SysTol)},
doi = {10.1109/SysTol.2013.6693820},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Maciejowski, Yang - 2013 - Fault tolerant control using Gaussian processes and model predictive control.pdf:pdf},
isbn = {978-1-4799-2855-2},
pages = {1--12},
title = {{Fault tolerant control using Gaussian processes and model predictive control}},
year = {2013}
}
@article{Mackay1998,
author = {Mackay, David J.C.},
file = {:home/alederer/Documents/Literatur/Books/Introduction to Gaussian Processes.pdf:pdf},
journal = {NATO ASI Series F Computer and Systems Sciences},
pages = {133--166},
title = {{Introduction to Gaussian Processes}},
volume = {168},
year = {1998}
}
@article{Madani2012,
abstract = {In this paper, we investigate the problem of designing compact-support interpolation kernels for a given class of signals. By using calculus of variations, we simplify the optimization problem from an nonlinear infinite dimensional problem to a linear finite dimensional case, and then find the optimum compact-support function that best approximates a given filter in the least square sense (ℓ2 norm). The benefit of compact-support interpolants is the low computational complexity in the interpolation process while the optimum compact-support interpolant guarantees the highest achievable signal-to-noise ratio (SNR). Our simulation results confirm the superior performance of the proposed kernel compared to other conventional compact-support interpolants such as cubic spline.},
author = {Madani, Ramtin and Ayremlou, Ali and Amini, Arash and Marvasti, Farrokh},
doi = {10.1109/TSP.2011.2174987},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Madani et al. - 2012 - Optimized compact-support interpolation kernels.pdf:pdf},
issn = {1053587X},
journal = {IEEE Transactions on Signal Processing},
keywords = {Compact-support,filter design,interpolation,spline},
number = {2},
pages = {626--633},
title = {{Optimized compact-support interpolation kernels}},
volume = {60},
year = {2012}
}
@article{Magni2003,
abstract = {This paper describes a model predictive control (MPC) algorithm for the solution of a state-feedback robust control problem for discrete-time nonlinear systems. The control law is obtained through the solution of a finite-horizon dynamic game and guarantees robust stability in the face of a class of bounded disturbances and/or parameter uncertainties. A simulation example is reported to show the applicability of the method. Copyright $\backslash$textcopyright{\{}{\}}2003 John Wiley {\&} Sons, Ltd.},
author = {Magni, L. and {De Nicolao}, G. and Scattolini, R. and Allg{\"{o}}wer, F.},
doi = {10.1002/rnc.815},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Magni et al. - 2003 - Robust model predictive control for nonlinear discrete-time systems.pdf:pdf},
isbn = {9781479999361},
issn = {10498923},
journal = {International Journal of Robust and Nonlinear Control},
keywords = {Discrete-time systems,Nonlinear model predictive control,Robust control},
number = {3-4},
pages = {229--246},
title = {{Robust model predictive control for nonlinear discrete-time systems}},
volume = {13},
year = {2003}
}
@article{Maiworm2018,
abstract = {We present an output feedback nonlinear model predictive control approach that uses a Gaussian process model for prediction. We show nominal stability assuming that the Gaussian process model is able to represent the real process and establish input-to-state stability assuming a bounded error between the real process and the Gaussian model approximation. These results are achieved using a predictive control formulation without terminal region. The approach is illustrated using a continuous stirred-tank reactor benchmark problem.},
author = {Maiworm, Michael and Limon, Daniel and {Maria Manzano}, Jose and Findeisen, Rolf},
doi = {10.1016/j.ifacol.2018.11.047},
file = {:home/alederer/Local/Literatur/Learning Based MPC/gp mpc/Stability of Gaussian Process Learning Based Output Feedback Model Predictive Control.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Gaussian processes,learning,output feedback,predictive control,robust,stability},
number = {20},
pages = {455--461},
publisher = {Elsevier B.V.},
title = {{Stability of Gaussian Process Learning Based Output Feedback Model Predictive Control⁎}},
url = {https://doi.org/10.1016/j.ifacol.2018.11.047},
volume = {51},
year = {2018}
}
@article{Majumdar2014,
abstract = {In this paper, we consider linear programming (LP) and second order cone programming (SOCP) based alternatives to sum of squares (SOS) programming and apply this framework to high-dimensional problems arising in control applications. Despite the wide acceptance of SOS programming in the control and optimization communities, scalability has been a key challenge due to its reliance on semidefinite programming (SDP) as its main computational engine. While SDPs have many appealing features, current SDP solvers do not approach the scalability or numerical maturity of LP and SOCP solvers. Our approach is based on the recent work of Ahmadi and Majumdar [1], which replaces the positive semidefiniteness constraint inherent in the SOS approach with stronger conditions based on diagonal dominance and scaled diagonal dominance. This leads to the DSOS and SDSOS cones of polynomials, which can be optimized over using LP and SOCP respectively. We demonstrate this approach on four high dimensional control problems that are currently well beyond the reach of SOS programming: computing a region of attraction for a 22 dimensional system, analysis of a 50 node network of oscillators, searching for degree 3 controllers and degree 8 Lyapunov functions for an Acrobot system (with the resulting controller validated on a hardware platform), and a balancing controller for a 30 state and 14 control input model of the ATLAS humanoid robot. While there is additional conservatism introduced by our approach, extensive numerical experiments on smaller instances of our problems demonstrate that this conservatism can be small compared to SOS programming.},
author = {Majumdar, Anirudha and Ahmadi, Amir Ali and Tedrake, Russ},
doi = {10.1109/CDC.2014.7039413},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Majumdar, Ahmadi, Tedrake - 2014 - Control and verification of high-dimensional systems with DSOS and SDSOS programming.pdf:pdf},
isbn = {978-1-4673-6090-6},
issn = {07431546},
journal = {Proceedings of the IEEE Conference on Decision and Control},
number = {February},
pages = {394--401},
publisher = {IEEE},
title = {{Control and verification of high-dimensional systems with DSOS and SDSOS programming}},
volume = {2015-Febru},
year = {2014}
}
@article{Malzahn2001,
abstract = {Based on a statistical mechanics approach, we develop a method for approximately computing average case learning curves for Gaus-sian process regression models. The approximation works well in the large sample size limit and for arbitrary dimensionality of the input space. We explain how the approximation can be systemati-cally improved and argue that similar techniques can be applied to general likelihood models.},
author = {Malzahn, D{\"{o}}rthe and Opper, Manfred},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Malzahn, Opper - 2001 - Learning Curves for Gaussian Processes Regression A Framework for Good Approximations.pdf:pdf},
journal = {Advances in Neural Information Processing Systems 13},
pages = {273--279},
title = {{Learning Curves for Gaussian Processes Regression: A Framework for Good Approximations}},
year = {2001}
}
@inproceedings{Malzahn2002,
abstract = {Abstract We combine the replica approach from statistical physics with a variational approach to analyze learning curves analytically. We apply the method to Gaussian process regression. As a main result we derive approximative relations between empirical error ...},
author = {Malzahn, D{\"{o}}rthe and Opper, Manfred},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Malzahn, Opper - 2002 - A Variational Approach to Learning Curves.pdf:pdf},
isbn = {0262042088},
issn = {10495258},
pages = {463--469},
title = {{A Variational Approach to Learning Curves}},
url = {http://papers.nips.cc/paper/2090-a-variational-approach-to-learning-curves.pdf{\%}5Cnfiles/4643/Malzahn ? Opper - 2002 - A Variational Approach to Learning Curves.pdf{\%}5Cnfiles/4644/2090-a-variational-approach-to-learning-curves.html},
year = {2002}
}
@article{Mandel2017,
abstract = {In order for reinforcement learning systems to learn quickly in vast action spaces such as the space of all possible pieces of text or the space of all images, leveraging human intuition and creativity is key. However, a human-designed action space is likely to be initially imperfect and limited; furthermore, hu-mans may improve at creating useful actions with practice or new information. Therefore, we propose a framework in which a human adds actions to a reinforcement learning sys-tem over time to boost performance. In this setting, however, it is key that we use human effort as efficiently as possible, and one significant danger is that humans waste effort adding actions at places (states) that aren't very important. There-fore, we propose Expected Local Improvement (ELI), an au-tomated method which selects states at which to query hu-mans for a new action. We evaluate ELI on a variety of simu-lated domains adapted from the literature, including domains with over a million actions and domains where the simulated experts change over time. We find ELI demonstrates excellent empirical performance, even in settings where the synthetic " experts " are quite poor.},
author = {Mandel, Travis and Liu, Yun-en and Brunskill, Emma and Popovi, Zoran},
file = {:home/alederer/Documents/Literatur/Learning/human in the loop/Where to Add Actions in Human-in-the-Loop Reinforcement Learning.pdf:pdf},
journal = {Proceedings of the 31st Conference on Artificial Intelligence (AAAI 2017)},
pages = {2322--2328},
title = {{Where to Add Actions in Human-in-the-Loop Reinforcement Learning}},
year = {2017}
}
@inproceedings{Marco2017,
abstract = {In practice, the parameters of control policies are often tuned manually. This is time-consuming and frustrating. Reinforcement learning is a promising alternative that aims to automate this process, yet often requires too many experiments to be practical. In this paper, we propose a solution to this problem by exploiting prior knowledge from simulations, which are readily available for most robotic platforms. Specifically, we extend Entropy Search, a Bayesian optimization algorithm that maximizes information gain from each experiment, to the case of multiple information sources. The result is a principled way to automatically combine cheap, but inaccurate information from simulations with expensive and accurate physical experiments in a cost-effective manner. We apply the resulting method to a cart-pole system, which confirms that the algorithm can find good control policies with fewer experiments than standard Bayesian optimization on the physical system only.},
archivePrefix = {arXiv},
arxivId = {1703.01250},
author = {Marco, Alonso and Berkenkamp, Felix and Hennig, Philipp and Schoellig, Angela P. and Krause, Andreas and Schaal, Stefan and Trimpe, Sebastian},
booktitle = {Proceedings of the IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2017.7989186},
eprint = {1703.01250},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Marco et al. - 2017 - Virtual vs. real Trading off simulations and physical experiments in reinforcement learning with Bayesian optimiza.pdf:pdf},
isbn = {9781509046331},
issn = {10504729},
pages = {1557--1563},
title = {{Virtual vs. Real: Trading off Simulations and Physical Experiments in Reinforcement Learning with Bayesian Optimization}},
year = {2017}
}
@inproceedings{Marco2016,
abstract = {This paper proposes an automatic controller tuning framework based on linear optimal control combined with Bayesian optimization. With this framework, an initial set of controller gains is automatically improved according to a pre-defined performance objective evaluated from experimental data. The underlying Bayesian optimization algorithm is Entropy Search, which represents the latent objective as a Gaussian process and constructs an explicit belief over the location of the objective minimum. This is used to maximize the information gain from each experimental evaluation. Thus, this framework shall yield improved controllers with fewer evaluations compared to alternative approaches. A seven-degree-of-freedom robot arm balancing an inverted pole is used as the experimental demonstrator. Results of a two- and four-dimensional tuning problems highlight the method's potential for automatic controller tuning on robotic platforms.},
archivePrefix = {arXiv},
arxivId = {1605.01950},
author = {Marco, Alonso and Hennig, Philipp and Bohg, Jeannette and Schaal, Stefan and Trimpe, Sebastian},
booktitle = {Proceedings of the IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2016.7487144},
eprint = {1605.01950},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Marco et al. - 2016 - Automatic LQR tuning based on Gaussian process global optimization.pdf:pdf},
isbn = {9781467380263},
issn = {10504729},
pages = {270--277},
title = {{Automatic LQR Tuning based on Gaussian Process Global Optimization}},
year = {2016}
}
@inproceedings{Marco2018,
abstract = {Finding optimal feedback controllers for nonlinear dynamic systems from data is hard. Recently, Bayesian optimization (BO) has been proposed as a powerful framework for direct controller tuning from experimental trials. For selecting the next query point and finding the global optimum, BO relies on a probabilistic description of the latent objective function, typically a Gaussian process (GP). As is shown herein, GPs with a common kernel choice can, however, lead to poor learning outcomes on standard quadratic control problems. For a first-order system, we construct two kernels that specifically leverage the structure of the well-known Linear Quadratic Regulator (LQR), yet retain the flexibility of Bayesian nonparametric learning. Simulations of uncertain linear and nonlinear systems demonstrate that the LQR kernels yield superior learning performance.},
archivePrefix = {arXiv},
arxivId = {1709.07089},
author = {Marco, Alonso and Hennig, Philipp and Schaal, Stefan and Trimpe, Sebastian},
booktitle = {Proceedings of the IEEE Conference on Decision and Control},
doi = {10.1109/CDC.2017.8264429},
eprint = {1709.07089},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Marco et al. - 2017 - On the design of LQR kernels for efficient controller learning.pdf:pdf},
isbn = {9781509028733},
pages = {5193--5200},
title = {{On the Design of LQR Kernels for Efficient Controller Learning}},
year = {2017}
}
@book{Massart2003,
abstract = {Model selection is a classical topic in statistics. The idea of selecting a model via penalizing a log-likelihood type criterion goes back to the early seventies with the pioneering works of Mallows and Akaike. One can find many consistency results in the literature for such criteria. These results are asymptotic in the sense that one deals with a given number of models and the number of observations tends to infinity. We shall give an overview of a non asymptotic theory for model selection which has emerged during the past ten years. In various contexts of function estimation it is possible to design penalized log-likelihood type criteria with penalty terms depending not only on the number of parameters defining each model (as for the classical criteria) but also on the $\backslash$guillemotleft complexity$\backslash$guillemotright$\backslash$ of the whole collection of models to be considered. The performance of such a criterion is analyzed via non asymptotic risk bounds for the corresponding penalized estimator which express that it performs almost as well as if the $\backslash$guillemotleft best model$\backslash$guillemotright$\backslash$ (i.e. with minimal risk) were known. For practical relevance of these methods, it is desirable to get a precise expression of the penalty terms involved in the penalized criteria on which they are based. This is why this approach heavily relies on concentration inequalities, the prototype being Talagrand's inequality for empirical processes. Our purpose will be to give an account of the theory and discuss some selected applications such as variable selection or change points detection.},
author = {Massart, Pascal},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Massart - 2003 - Concentration Inequalities and Model Selection.pdf:pdf},
publisher = {Springer, Berlin, Heidelberg},
title = {{Concentration Inequalities and Model Selection}},
year = {2003}
}
@article{Matthews2018,
abstract = {Whilst deep neural networks have shown great empirical success, there is still much work to be done to understand their theoretical properties. In this paper, we study the relationship between random, wide, fully connected, feedforward networks with more than one hidden layer and Gaussian processes with a recursive kernel definition. We show that, under broad conditions, as we make the architecture increasingly wide, the implied random function converges in distribution to a Gaussian process, formalising and extending existing results by Neal (1996) to deep networks. To evaluate convergence rates empirically, we use maximum mean discrepancy. We then compare finite Bayesian deep networks from the literature to Gaussian processes in terms of the key predictive quantities of interest, finding that in some cases the agreement can be very close. We discuss the desirability of Gaussian process behaviour and review non-Gaussian alternative models from the literature.},
archivePrefix = {arXiv},
arxivId = {1804.11271},
author = {Matthews, Alexander G. de G. and Rowland, Mark and Hron, Jiri and Turner, Richard E. and Ghahramani, Zoubin},
doi = {10.1039/f19868202801},
eprint = {1804.11271},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Matthews et al. - 2018 - Gaussian Process Behaviour in Wide Deep Neural Networks.pdf:pdf},
isbn = {1804.11271v2},
issn = {0300-9589},
pages = {1--36},
title = {{Gaussian Process Behaviour in Wide Deep Neural Networks}},
url = {http://arxiv.org/abs/1804.11271},
year = {2018}
}
@article{Mayne2011,
abstract = {Asymptotic output-feedback tracking in a class of causal nonminimum phase uncertain nonlinear systems is addressed via sliding mode techniques. Sliding mode control is proposed for robust stabilization of the output tracking error in the presence of a bounded disturbance. The output reference profile and the unknown input/disturbance are supposed to be described by unknown linear exogenous systems of a given order. Local asymptotic stability of the output tracking error dynamics along with the boundedness of the internal states are proven. The unstable internal states are estimated asymptotically via the proposed multistage observer that is based on the method of extended system center. A higher-order sliding mode observer/differentiator is used for the exact estimation of the input–output states in a finite time. The bounded disturbance is reconstructed asymptotically. A numerical example illustrates the efficiency of the proposed output-feedback tracking approach developed for causal nonminimum phase nonlinear systems.},
archivePrefix = {arXiv},
arxivId = {arXiv:1505.02595v1},
author = {Mayne, David Q. and Kerrigan, Eric C. and van Wyk, E. C. and Falugi, Paola},
doi = {10.1002/rnc},
eprint = {arXiv:1505.02595v1},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mayne et al. - 2011 - Tube-based robust nonlinear model predictive control.pdf:pdf},
isbn = {1049-8923},
issn = {10498923},
journal = {International Journal of Robust and Nonlinear Control},
keywords = {higher-order sliding mode,nonminimum phase,output-feedback tracking},
number = {11},
pages = {1341--1353},
pmid = {18795146},
title = {{Tube-based robust nonlinear model predictive control}},
volume = {21},
year = {2011}
}
@article{Mayne2000,
abstract = {Model predictive control is a form of control in which the current control action is obtained by solving, at each sampling instant, a "nite horizon open-loop optimal control problem, using the current state of the plant as the initial state; the optimization yields an optimal control sequence and the "rst control in this sequence is applied to the plant. An important advantage of this type of control is its ability to cope with hard constraints on controls and states. It has, therefore, been widely applied in petro-chemical and related industries where satisfaction of constraints is particularly important because e{\$}ciency demands operating points on or close to the boundary of the set of admissible states and controls. In this review, we focus on model predictive control of constrained systems, both linear and nonlinear and discuss only brie{\#}y model predictive control of unconstrained nonlinear and/or time-varying systems. We concentrate our attention on research dealing with stability and optimality; in these areas the subject has developed, in our opinion, to a stage where it has achieved su{\$}cient maturity to warrant the active interest of researchers in nonlinear control. We distill from an extensive literature essential principles that ensure stability and use these to present a concise characterization of most of the model predictive controllers that have been proposed in the literature. In some cases the "nite horizon optimal control problem solved on-line is exactly equivalent to the same problem with an in"nite horizon; in other cases it is equivalent to a modi"ed in"nite horizon optimal control problem. In both situations, known advantages of in"nite horizon optimal control accrue. 2000 Elsevier Science Ltd. All rights reserved.},
author = {Mayne, David Q. and Rawlings, James B. and Rao, C. V. and Scokaert, P. O. M.},
file = {:home/alederer/Documents/Literatur/Learning Based MPC/MPC applications/Constrained Model Predictive Control{\_} Stability and Optimality.pdf:pdf},
journal = {Automatica},
keywords = {model predictive control,optimality,robustness,stability},
pages = {789--814},
title = {{Constrained Model Predictive Control: Stability and Optimality}},
volume = {36},
year = {2000}
}
@misc{Meier2014a,
abstract = {Locally weighted regression was created as a nonparametric learning method that is computationally efficient, can learn from very large amounts of data and add data incrementally. An interesting feature of locally weighted regression is that it can work with spatially varying length scales, a beneficial property, for instance, in control problems. However, it does not provide a generative model for function values and requires training and test data to be generated identically, independently. Gaussian (process) regression, on the other hand, provides a fully generative model without significant formal requirements on the distribution of training data, but has much higher computational cost and usually works with one global scale per input dimension. Using a localising function basis and approximate inference techniques, we take Gaussian (process) regression to increasingly localised properties and toward the same computational complexity class as locally weighted regression.},
archivePrefix = {arXiv},
arxivId = {1402.0645},
author = {Meier, Franziska and Hennig, Philipp and Schaal, Stefan},
eprint = {1402.0645},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meier, Hennig, Schaal - 2014 - Local Gaussian Regression.pdf:pdf},
issn = {10495258},
pages = {1--9},
title = {{Local Gaussian Regression}},
year = {2014}
}
@article{Meier2014,
abstract = {Model-based control is essential for compliant control and force control in many modern complex robots, like humanoid or disaster robots. Due to many unknown and hard to model nonlinearities, analytical models of such robots are often only very rough approximations. However, modern optimization controllers frequently depend on reasonably accurate models, and degrade greatly in robustness and performance if model errors are too large. For a long time, machine learning has been expected to provide automatic empirical model synthesis, yet so far, research has only generated feasibility studies but no learning algorithms that run reliably on complex robots. In this paper, we combine two promising worlds of regression techniques to generate a more powerful regression learning system. On the one hand, locally weighted regression techniques are computationally efficient, but hard to tune due to a variety of data dependent meta-parameters. On the other hand, Bayesian regression has rather automatic and robust methods to set learning parameters, but becomes quickly computationally infeasible for big and high-dimensional data sets. By reducing the complexity of Bayesian regression in the spirit of local model learning through variational approximations, we arrive at a novel algorithm that is computationally efficient and easy to initialize for robust learning. Evaluations on several datasets demonstrate very good learning performance and the potential for a general regression learning tool for robotics.},
author = {Meier, Franziska and Hennig, Philipp and Schaal, Stefan},
doi = {10.1109/IROS.2014.6942865},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meier, Hennig, Schaal - 2014 - Efficient Bayesian local model learning for control.pdf:pdf},
isbn = {978-1-4799-6934-0},
issn = {2153-0858},
journal = {2014 IEEE/RSJ International Conference on Intelligent Robots and Systems},
keywords = {Learning Control,Model Learning,Robot Learning},
pages = {2244--2249},
title = {{Efficient Bayesian local model learning for control}},
year = {2014}
}
@article{Melkumyan2009,
abstract = {Despite the success of Gaussian processes (GPs) in modelling spatial stochastic processes, dealing with large datasets is still challenging. The problem arises by the need to invert a potentially large covariance matrix during inference. In this paper we address the complexity problem by constructing a new stationary covariance function (Mercer kernel) that naturally provides a sparse covariance matrix. The sparseness of the matrix is defined by hyperparameters optimised during learning. The new covariance function enables exact GP inference and performs comparatively to the squared-exponential one, at a lower computational cost. This allows the application of GPs to large-scale problems such as ore grade prediction in mining or 3D surface modelling. Experiments show that using the proposed covariance function, very sparse covariance matrices are normally obtained which can be effectively used for faster inference and less memory usage.},
author = {Melkumyan, Arman and Ramos, Fabio},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Melkumyan, Ramos - 2009 - A sparse covariance function for exact gaussian process inference in large datasets.pdf:pdf},
isbn = {9781577354260},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
keywords = {"Uncertainty in Artificial Intelligence, Gaussian},
pages = {1936--1942},
title = {{A sparse covariance function for exact gaussian process inference in large datasets}},
year = {2009}
}
@article{Mendelson2002,
abstract = {We study the sample complexity of proper and improper learning problems with respect to different q-loss functions. We improve the known estimates for classes which have relatively small covering numbers in empirical L2 spaces (e.g. log-covering numbers which are polynomial with exponent p{\textless}2). We present several examples of relevant classes which have a "small" fat-shattering dimension, and hence fit our setup, the most important of which are kernel machines},
author = {Mendelson, Shahar},
doi = {10.1109/TIT.2002.1013137},
file = {:home/alederer/Local/Literatur/Learning/learning theory/Improving the Sample Complexity Using Global Data.pdf:pdf},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
keywords = {Fat-shattering dimension,Glivenko-Cantelli classes,Kernel machines,Learning sample complexity,Uniform convexity},
number = {7},
pages = {1977--1991},
title = {{Improving the Sample Complexity using Global Data}},
volume = {48},
year = {2002}
}
@article{Mercer1909,
abstract = {"... any continuous, symmetric, positive semi-definite kernel function K(x,y) can be expressed as a dot product in a high-dimensional space. ..." (Jstor)'09, http://rsta.royalsocietypublishing.org/content/209/441-458/415.full.pdf+html (PTRS)'10, and (wikip)'09.},
author = {Mercer, J.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mercer - 1909 - Functions of Positive and Negative Type, and their Connection with the Theory of Integral Equations.pdf:pdf},
journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
number = {441-458},
pages = {415--446},
title = {{Functions of Positive and Negative Type, and their Connection with the Theory of Integral Equations}},
volume = {209},
year = {1909}
}
@article{Merola2008,
abstract = {The trajectories of the dynamic system which regulates the competition between the populations of malignant cells and immune cells may tend to an asymptotically stable equilibrium in which the sizes of these populations do not vary, which is called tumor dormancy. Especially for lower steady-state sizes of the population of malignant cells, this equilibrium represents a desirable clinical condition since the tumor growth is blocked. In this context, it is of mandatory importance to analyze the robustness of this clinical favorable state of health in the face of perturbations. To this end, the paper presents an optimization technique to determine whether an assigned rectangular region, which surrounds an asymptotically stable equilibrium point of a quadratic systems, is included into the domain of attraction of the equilibrium itself. The biological relevance of the application of this technique to the analysis of tumor growth dynamics is shown on the basis of a recent quadratic model of the tumor-immune system competition dynamics. Indeed the application of the proposed methodology allows to ensure that a given safety region, determined on the basis of clinical considerations, belongs to the domain of attraction of the tumor blocked equilibrium; therefore for the set of perturbed initial conditions which belong to such region, the convergence to the healthy steady state is guaranteed. The proposed methodology can also provide an optimal strategy for cancer treatment. {\{}{\textcopyright}{\}} 2008 Elsevier Ltd. All rights reserved.},
author = {Merola, A and Cosentino, C and Amato, F},
file = {:home/alederer/Local/Literatur/sampling based Stability analysis/An insight into tumor dormacy equilibrium via the analysis of its domain of attraction.pdf:pdf},
journal = {Biomedical Signal Processing and Control},
keywords = {Domain of attraction,Linear matrix inequalities,Quadratic systems,Tumor-immune system competition dynamics},
number = {3},
pages = {212--219},
title = {{An insight into tumor dormancy equilibrium via the analysis of its domain of attraction}},
volume = {3},
year = {2008}
}
@article{Merola2008,
abstract = {The trajectories of the dynamic system which regulates the competition between the populations of malignant cells and immune cells may tend to an asymptotically stable equilibrium in which the sizes of these populations do not vary, which is called tumor dormancy. Especially for lower steady-state sizes of the population of malignant cells, this equilibrium represents a desirable clinical condition since the tumor growth is blocked. In this context, it is of mandatory importance to analyze the robustness of this clinical favorable state of health in the face of perturbations. To this end, the paper presents an optimization technique to determine whether an assigned rectangular region, which surrounds an asymptotically stable equilibrium point of a quadratic systems, is included into the domain of attraction of the equilibrium itself. The biological relevance of the application of this technique to the analysis of tumor growth dynamics is shown on the basis of a recent quadratic model of the tumor-immune system competition dynamics. Indeed the application of the proposed methodology allows to ensure that a given safety region, determined on the basis of clinical considerations, belongs to the domain of attraction of the tumor blocked equilibrium; therefore for the set of perturbed initial conditions which belong to such region, the convergence to the healthy steady state is guaranteed. The proposed methodology can also provide an optimal strategy for cancer treatment. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Merola, A. and Cosentino, C. and Amato, F.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Merola, Cosentino, Amato - 2008 - An insight into tumor dormancy equilibrium via the analysis of its domain of attraction.pdf:pdf},
journal = {Biomedical Signal Processing and Control},
keywords = {Domain of attraction,Linear matrix inequalities,Quadratic systems,Tumor-immune system competition dynamics},
number = {3},
pages = {212--219},
title = {{An insight into tumor dormancy equilibrium via the analysis of its domain of attraction}},
volume = {3},
year = {2008}
}
@article{Mesbah2017,
abstract = {This paper considers the model predictive control (MPC) of critical quality attributes (CQAs) of products in an end-to-end continuous pharmaceutical manufacturing pilot plant, which was designed and constructed at the Novartis-MIT Center for Continuous Manufacturing. Feedback control is crucial for achieving the stringent regulatory requirements on CQAs of pharmaceutical products in the presence of process uncertainties and disturbances. To this end, a key challenge arises from complex plant-wide dynamics of the integrated process units in a continuous pharmaceutical process, that is, dynamical interactions between several process units. This paper presents two plant-wide MPC designs for the end-to-end continuous pharmaceutical manufacturing pilot plant using the quadratic dynamic matrix control algorithm. The plant-wide MPC designs are based on different modeling approaches—subspace identification and linearization of nonlinear differential-algebraic equations that yield, respectively, linear low-dimensi...},
author = {Mesbah, Ali and Paulson, Joel A. and Lakerveld, Richard and Braatz, Richard D.},
doi = {10.1021/acs.oprd.7b00058},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mesbah et al. - 2017 - Model Predictive Control of an Integrated Continuous Pharmaceutical Manufacturing Pilot Plant.pdf:pdf},
issn = {1083-6160},
journal = {Organic Process Research {\&} Development},
number = {6},
pages = {844--854},
title = {{Model Predictive Control of an Integrated Continuous Pharmaceutical Manufacturing Pilot Plant}},
volume = {21},
year = {2017}
}
@inproceedings{Miao2002,
author = {Miao, Qi and Wang, Shi-Fu},
booktitle = {Proceedings of the 2002 International Conference on Machine Learning and Cybernetics},
doi = {10.1109/ICMLC.2002.1167494},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Miao, Wang - 2002 - Nonlinear model predictive control based on support vector regression.pdf:pdf},
isbn = {0780375084},
keywords = {neural networks,nonlinear model-based predictive control,regression,support vector},
pages = {1657--1661},
title = {{Nonlinear model predictive control based on support vector regression}},
year = {2002}
}
@inproceedings{Muhlpfordt2016,
abstract = {— In many control problems, not all states can be measured and the system is subject to parametric uncertainties, measurement noise, and hard input constraints. To tackle such problems for linear systems, we propose to combine a recursive parameter and state estimator (based on Bayes' theorem) with a stochastic model predictive control approach. Problem formulations and solution methods are discussed for both the estimation and control problems. To efficiently obtain the probability density functions for the random variables and to propagate the uncertainties, Polynomial chaos theory is used. The parameter and state distributions are recursively estimated via Bayes theorem, which is solved as a nonlinear least-squares problem. These distributions are utilized in a model predictive controller to steer the system to the desired reference while satisfying input constraints. The efficiency and properties of the resulting output feedback strategy are illustrated with two example systems, a simple paper-machine example, and the control of a chemical process.},
author = {M{\"{u}}hlpfordt, Tillmann and Paulson, Joel A and Braatz, Richard D and Findeisen, Rolf},
booktitle = {Proceedings of the 2016 American Control Conference},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/M{\"{u}}hlpfordt et al. - 2016 - Output Feedback Model Predictive Control with Probabilistic Uncertainties for Linear Systems.pdf:pdf},
isbn = {9781467386814},
keywords = {Output regulation,Predictive control for linear systems,Process Control},
pages = {2035--2040},
title = {{Output Feedback Model Predictive Control with Probabilistic Uncertainties for Linear Systems}},
year = {2016}
}
@article{Munz2013,
abstract = {The integration of renewable energy sources in power systems requires a well-balanced control to guarantee system stability in view of fast fluctuating power injections. We present several conditions on the stability reserve of a power system in terms of the region of attraction of its steady state that can be used to design and evaluate such controllers. The power system is modeled by the coupled swing equations. The region of attraction of this nonlinear systems is determined based on Lyapunov theory and Barbalat's lemma. The resulting conditions provide both 2-norm and ∞-norm regions of attractions. The different conditions differ, e.g., in their conservatism and in the required knowledge of the power system parameters. Copyright {\textcopyright} 2013 IFAC.},
author = {M{\"{u}}nz, Ulrich and Romeres, Diego},
file = {:home/alederer/Documents/Literatur/Stabiliy Analysis/Region of Attraction of Power Systems.pdf:pdf},
journal = {IFAC Proceedings Volumes},
keywords = {Coupled swing equations,Power system,Region of attraction,Robustness,Stability},
number = {27},
pages = {49--54},
title = {{Region of attraction of power systems}},
volume = {46},
year = {2013}
}
@book{Murray-Smith2002,
author = {Murray-Smith, Roderick and Sbarbaro, Daniel},
booktitle = {IFAC Proceedings Volumes},
doi = {10.3182/20020721-6-ES-1901.01040},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Murray-Smith, Sbarbaro - 2002 - Nonlinear Adaptive Control Using Nonparametric Gaussian Process Prior Models.pdf:pdf},
issn = {14746670},
keywords = {Gaussian process priors,dual control,gaussian process priors,model-based predictive control,nonlinear,nonlinear model-based predictive control,nonparametric models},
number = {1},
pages = {325--330},
publisher = {IFAC},
title = {{Nonlinear Adaptive Control Using Nonparametric Gaussian Process Prior Models}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1474667015394611},
volume = {35},
year = {2002}
}
@article{MURRAYSMITH03,
annote = {From Duplicate 1 (Adaptive, cautious, predictive control with gaussian process priors - Murray-Smith, Roderick; Sbarbaro, Daniel; Rasmussen, Carl Edward; Girard, Agathe)

13th IFAC Symposium on System Identification (SYSID 2003), Rotterdam, The Netherlands, 27-29 August, 2003},
author = {Murray-Smith, Roderick and Sbarbaro, Daniel and Rasmussen, Carl Edward and Girard, Agathe},
doi = {https://doi.org/10.1016/S1474-6670(17)34915-7},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Murray-Smith et al. - Unknown - Adaptive, Cautious, Predictive Control With Gaussian Process Priors.pdf.pdf:pdf},
issn = {1474-6670},
journal = {IFAC Proceedings Volumes},
keywords = {Cautious control,Gaussian process priors,nonlinear model-based predictive control,nonparametric models,propagation of uncertainty},
number = {16},
pages = {1155--1160},
title = {{Adaptive, cautious, predictive control with gaussian process priors}},
volume = {36},
year = {2003}
}
@book{Murray-Smith2003,
doi = {10.1007/b105497},
editor = {Murray-Smith, Roderick and Shorten, Robert},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2003 - Switching and Learning in Feedback Systems.pdf:pdf},
isbn = {978-3-540-24457-8},
title = {{Switching and Learning in Feedback Systems}},
volume = {3355},
year = {2003}
}
@book{Murray1994,
abstract = {A Mathematical Introduction to Robotic Manipulation presents a mathematical formulation of the kinematics, dynamics, and control of robot manipulators. It uses an elegant set of mathematical tools that emphasizes the geometry of robot motion and allows a large class of robotic manipulation problems to be analyzed within a unified framework.The foundation of the book is a derivation of robot kinematics using the product of the exponentials formula. The authors explore the kinematics of open-chain manipulators and multifingered robot hands, present an analysis of the dynamics and control of robot systems, discuss the specification and control of internal forces and internal motions, and address the implications of the nonholonomic nature of rolling contact are addressed, as well.The wealth of information, numerous examples, and exercises make A Mathematical Introduction to Robotic Manipulation valuable as both a reference for robotics researchers and a text for students in advanced robotics courses.},
author = {Murray, Richard M. and Li, Zexiang and {Shankar Sastry}, S.},
doi = {10.1201/9781315136370},
file = {:home/alederer/Documents/Literatur/Books/A Mathematical Introduction to Robotic Manipulation.pdf:pdf},
isbn = {9781351469791},
pages = {1--456},
publisher = {CRC Press},
title = {{A Mathematical Introduction to Robotic Manipulation}},
year = {1994}
}
@article{Nagabandi2018,
abstract = {Model-free deep reinforcement learning algorithms have been shown to be capable of learning a wide range of robotic skills, but typically require a very large number of samples to achieve good performance. Model-based algorithms, in principle, can provide for much more efficient learning, but have proven difficult to extend to expressive, high-capacity models such as deep neural networks. In this work, we demonstrate that medium-sized neural network models can in fact be combined with model predictive control (MPC) to achieve excellent sample complexity in a model-based reinforcement learning algorithm, producing stable and plausible gaits to accomplish various complex locomotion tasks. We also propose using deep neural network dynamics models to initialize a model-free learner, in order to combine the sample efficiency of model-based approaches with the high task-specific performance of model-free methods. We empirically demonstrate on MuJoCo locomotion tasks that our pure model-based approach trained on just random action data can follow arbitrary trajectories with excellent sample efficiency, and that our hybrid algorithm can accelerate model-free learning on high-speed benchmark tasks, achieving sample efficiency gains of 3-5x on swimmer, cheetah, hopper, and ant agents. Videos can be found at https://sites.google.com/view/mbmf},
archivePrefix = {arXiv},
arxivId = {arXiv:1708.02596v2},
author = {Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S. and Levine, Sergey},
doi = {10.1109/ICRA.2018.8463189},
eprint = {arXiv:1708.02596v2},
file = {:home/alederer/Documents/Literatur/Reinforcement Learning/Multi-step predictions/Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning.pdf:pdf},
isbn = {9781538630815},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
pages = {7579--7586},
title = {{Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning}},
year = {2018}
}
@article{Najafi2016,
abstract = {Most stabilizing controllers designed for nonlinear systems are valid only within a specific region of the state space, called the domain of attrac-tion (DoA). Computation of the DoA is usually costly and time-consuming. This paper proposes a compu-tationally effective sampling approach to estimate the DoAs of nonlinear systems in real time. This method is validated to approximate the DoAs of stable equi-libria in several nonlinear systems. In addition, it is implemented for the passivity-based learning controller designed for a second-order dynamical system. Simu-lation and experimental results show that, in all cases studied, the proposed sampling technique quickly esti-mates the DoAs, corroborating its suitability for real-time applications.},
author = {Najafi, Esmaeil and Babu{\v{s}}ka, Robert and Lopes, Gabriel A.D.},
doi = {10.1007/s11071-016-2926-7},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Najafi, Babu{\v{s}}ka, Lopes - 2016 - A fast sampling method for estimating the domain of attraction.pdf:pdf},
issn = {1573269X},
journal = {Nonlinear Dynamics},
keywords = {Domain of attraction,Lyapunov function,Optimization,Sampling method},
number = {2},
pages = {823--834},
publisher = {Springer Netherlands},
title = {{A fast sampling method for estimating the domain of attraction}},
url = {"http://dx.doi.org/10.1007/s11071-016-2926-7},
volume = {86},
year = {2016}
}
@article{Nakanishi2004,
abstract = {In this paper, we present our theoretical investigations of the technique of feedback error learning (FEL) from the viewpoint of adaptive control. We first discuss the relationship between FEL and nonlinear adaptive control with adaptive feedback linearization, and show that FEL can be interpreted as a form of nonlinear adaptive control. Second, we present a Lyapunov analysis suggesting that the condition of strictly positive realness (SPR) associated with the tracking error dynamics is a sufficient condition for asymptotic stability of the closed-loop dynamics. Specifically, for a class of second order SISO systems, we show that this condition reduces to K D2{\textgreater}K P, where K P and K D are positive position and velocity feedback gains, respectively. Moreover, we provide a 'passivity'-based stability analysis which suggests that SPR of the tracking error dynamics is a necessary and sufficient condition for asymptotic hyperstability. Thus, the condition K D2{\textgreater}K P mentioned above is not only a sufficient but also necessary condition to guarantee asymptotic hyperstability of FEL, i.e. the tracking error is bounded and asymptotically converges to zero. As a further point, we explore the adaptive control and FEL framework for feedforward control formulations, and derive an additional sufficient condition for asymptotic stability in the sense of Lyapunov. Finally, we present numerical simulations to illustrate the stability properties of FEL obtained from our mathematical analysis. {\textcopyright} 2004 Elsevier Ltd. All rights reserved.},
author = {Nakanishi, Jun and Schaal, Stefan},
doi = {10.1016/j.neunet.2004.05.003},
file = {:home/alederer/Documents/Literatur/Learning/Local GP/Feedback Error Learning and Nonlinear Adaptive Control.pdf:pdf},
isbn = {8177495240},
issn = {08936080},
journal = {Neural Networks},
keywords = {Adaptive control,Feedback and feedforward control,Feedback error learning,Lyapunov stability,Passivity,Strictly positive realness},
number = {10},
pages = {1453--1465},
title = {{Feedback error learning and nonlinear adaptive control}},
volume = {17},
year = {2004}
}
@article{Narcowich2006,
author = {Narcowich, F. J. and Ward, J. D. and Wendland, H.},
file = {:home/alederer/Local/Literatur/Learning/learning theory/Sobolev Error Estimates and a Bernstein Inequality for Scattered Data Interpolation via Radial Basis Functions.pdf:pdf},
journal = {Constructive Approximation},
number = {2},
pages = {175--186},
title = {{Sobolev Error Estimates and a Bernstein Inequality for Scattered Data Interpolation via Radial Basis Functions}},
volume = {24},
year = {2006}
}
@article{Narendra1990,
abstract = {It is demonstrated that neural networks can be used effectively for the identification and control of nonlinear dynamical systems. The emphasis is on models for both identification and control. Static and dynamic backpropagation methods for the adjustment of parameters are discussed. In the models that are introduced, multilayer and recurrent networks are interconnected in novel configurations, and hence there is a real need to study them in a unified fashion. Simulation results reveal that the identification and adaptive control schemes suggested are practically feasible. Basic concepts and definitions are introduced throughout, and theoretical questions that have to be addressed are also described.},
author = {Narendra, K.S. and Parthasarathy, K},
doi = {10.1109/72.80202},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Narendra, Parthasarathy - 1990 - Identification and control of dynamical systems using neural networks.pdf:pdf},
isbn = {1045-9227},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
number = {1},
pages = {4--27},
pmid = {18282820},
title = {{Identification and control of dynamical systems using neural networks}},
url = {http://ieeexplore.ieee.org/document/80202/},
volume = {1},
year = {1990}
}
@book{Neal1996,
author = {Neal, Radford M},
doi = {10.1007/978-1-4612-0745-0},
file = {:home/alederer/Documents/Literatur/Books/Bayesian Learning for Neural Networks.pdf:pdf},
isbn = {9783642124648},
title = {{Lecture Notes in Statistics: Bayesian Learning for Neural Networks}},
year = {1996}
}
@inproceedings{Nghiem2017,
abstract = {{\textcopyright} 2017 American Automatic Control Council (AACC). This paper presents an approach to provide demand response services with buildings. Each building receives a normalized signal that tells it to increase or decrease its power demand, and the building is free to implement any suitable strategy to follow the command, most likely by changing some of its setpoints. Due to this freedom, the proposed approach lowers the barrier for any buildings equipped with a reasonably functional building management system to participate in the scheme. The response of the buildings to the control signal is modeled by a Gaussian Process, which can predict the power demand of the buildings and also provide a measure of its confidence in the prediction. A battery is included in the system to compensate for this uncertainty and improve the demand response performance of the system. A model predictive controller is developed to optimally control the buildings and the battery, while ensuring their operational constraints with high probability. Our approach is validated by realistic co-simulations between Matlab and the building energy simulator EnergyPlus.},
author = {Nghiem, T.X. and Jones, C.N.},
booktitle = {Proceedings of the American Control Conference},
doi = {10.23919/ACC.2017.7963394},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nghiem, Jones - 2017 - Data-driven demand response modeling and control of buildings with Gaussian Processes.pdf:pdf},
isbn = {9781509059928},
issn = {07431619},
pages = {2919--2924},
title = {{Data-driven demand response modeling and control of buildings with Gaussian Processes}},
year = {2017}
}
@article{Nguyen-Tuong2010,
abstract = {Online model learning in real-time is required by many applications such as in robot tracking control. It poses a difficult problem, as fast and incremental online regression with large data sets is the essential component which cannot be achieved by straightforward usage of off-the-shelf machine learning methods (such as Gaussian process regression or support vector regression). In this paper, we propose a framework for online, incremental sparsification with a fixed budget designed for large scale real-time model learning. The proposed approach combines a sparsification method based on an independence measure with a large scale database. In combination with an incremental learning approach such as sequential support vector regression, we obtain a regression method which is applicable in real-time online learning. It exhibits competitive learning accuracy when compared with standard regression techniques. Implementation on a real robot emphasizes the applicability of the proposed approach in real-time online model learning for real world systems. Copyright 2010 by the authors.},
author = {Nguyen-Tuong, Duy and Peters, Jan},
file = {:home/alederer/Documents/Literatur/Learning/Local GP/Incremental Online Sparsification for Model Learning in Real-time Robot Control.pdf:pdf},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {inverse dynamics,machine learning,real-time online model learning,sparse data},
pages = {557--564},
title = {{Incremental sparsification for real-time online model learning}},
volume = {9},
year = {2010}
}
@inproceedings{Nguyen-Tuong2009a,
abstract = {Precise models of robot inverse dynamics allow the design of significantly more accurate, energy-efficient and compliant robot control. However, in some cases the accuracy of rigid-body models does not suffice for sound control performance due to unmodeled nonlinearities arising from hydraulic cable dynamics, complex friction or actuator dynamics. In such cases, estimating the inverse dynamics model from measured data poses an interesting alternative. Nonparametric regression methods, such as Gaussian process regression (GPR) or locally weighted projection regression (LWPR), are not as restrictive as parametric models and, thus, offer a more flexible framework for approximating unknown nonlinearities. In this paper, we propose a local approximation to the standard GPR, called local GPR (LGP), for real-time model online learning by combining the strengths of both regression methods, i.e., the high accuracy of GPR and the fast speed of LWPR. The approach is shown to have competitive learning performance for high-dimensional data while being sufficiently fast for real-time learning. The effectiveness of LGP is exhibited by a comparison with the state-of-the-art regression techniques, such as GPR, LWPR and $\nu$-support vector regression. The applicability of the proposed LGP method is demonstrated by real-time online learning of the inverse dynamics model for robot model-based control on a Barrett WAM robot arm.},
author = {Nguyen-Tuong, Duy and Seeger, Matthias and Peters, Jan},
booktitle = {Advances in neural information processing systems},
doi = {10.1163/016918609X12529286896877},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen-Tuong, Seeger, Peters - 2009 - Local Gaussian Process Regression for Real Time Online Model Learning and Control.pdf:pdf},
isbn = {978-1-4244-2057-5},
issn = {01691864},
keywords = {Inverse dynamics,Machine learning,Model-based control,Nonparametric regression,Robotics},
pages = {1193--1200},
title = {{Local Gaussian Process Regression for Real Time Online Model Learning and Control}},
year = {2009}
}
@article{Nguyen-Tuong2008,
abstract = {Computed torque control allows the design of considerably more precise, energy-efficient and compliant controls for robots. However, the major obstacle is the requirement of an accurate model for torque generation, which cannot be obtained in some cases using rigid-body formulations due to unmodeled nonlinearities, such as complex friction or actuator dynamics. In such cases, models approximated from robot data present an appealing alternative. In this paper, we compare two non- parametric regression methods for model approximation, i.e., locally weighted projection regression (LWPR) and Gaussian process regression (GPR). While locally weighted regression was employed for real-time model estimation in learning adaptive control, Gaussian process regression has not been used in control to-date due to high computational requirements. The comparison includes the assessment of model approximation for both regression methods using data originated from SARCOS robot arm, as well as an evaluation of the robot tracking performance in computed torque control employing the approximated models. Our results show that GPR can be applied for realtime control achieving higher accuracy. However, for the online learning LWPR is superior by reason of lower computational requirements.},
author = {Nguyen-Tuong, Duy and Seeger, Matthias and Peters, Jan},
doi = {10.1109/ACC.2008.4586493},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen-Tuong, Seeger, Peters - 2008 - Computed Torque Control with Nonparametric Regression Models.pdf:pdf},
isbn = {978-1-4244-2078-0},
issn = {0743-1619},
journal = {American Control Conference},
pages = {212--217},
title = {{Computed Torque Control with Nonparametric Regression Models}},
year = {2008}
}
@article{Nguyen-Tuong2009,
abstract = {Precise models of robot inverse dynamics allow the design of significantly more accurate, energy-efficient and compliant robot control. However, in some cases the accuracy of rigid-body models does not suffice for sound control performance due to unmodeled nonlinearities arising from hydraulic cable dynamics, complex friction or actuator dynamics. In such cases, estimating the inverse dynamics model from measured data poses an interesting alternative. Nonparametric regression methods, such as Gaussian process regression (GPR) or locally weighted projection regression (LWPR), are not as restrictive as parametric models and, thus, offer a more flexible framework for approximating unknown nonlinearities. In this paper, we propose a local approximation to the standard GPR, called local GPR (LGP), for real-time model online learning by combining the strengths of both regression methods, i.e., the high accuracy of GPR and the fast speed of LWPR. The approach is shown to have competitive learning performance for high-dimensional data while being sufficiently fast for real-time learning. The effectiveness of LGP is exhibited by a comparison with the state-of-the-art regression techniques, such as GPR, LWPR and $\nu$-support vector regression. The applicability of the proposed LGP method is demonstrated by real-time online learning of the inverse dynamics model for robot model-based control on a Barrett WAM robot arm.},
author = {Nguyen-Tuong, Duy and Seeger, Matthias and Peters, Jan},
doi = {10.1163/016918609X12529286896877},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen-Tuong, Seeger, Peters - 2009 - Model learning with local Gaussian process regression.pdf:pdf},
isbn = {978-1-4244-2057-5},
issn = {01691864},
journal = {Advanced Robotics},
keywords = {Inverse dynamics,Machine learning,Model-based control,Nonparametric regression,Robotics},
number = {15},
pages = {2015--2034},
title = {{Model learning with local Gaussian process regression}},
volume = {23},
year = {2009}
}
@article{Nguyen2017,
abstract = {Future stock prices depend on many internal and external factors that are not easy to evaluate. In this paper, we use the Hidden Markov Model, (HMM), to predict a daily stock price of three active trading stocks: Apple, Google, and Facebook, based on their historical data. We first use the Akaike information criterion (AIC) and Bayesian information criterion (BIC) to choose the numbers of states from HMM. We then use the models to predict close prices of these three stocks using both single observation data and multiple observation data. Finally, we use the predictions as signals for trading these stocks. The criteria tests' results showed that HMM with two states worked the best among two, three and four states for the three stocks. Our results also demonstrate that the HMM outperformed the na{\"{i}}ve method in forecasting stock prices. The results also showed that active traders using HMM got a higher return than using the na{\"{i}}ve forecast for Facebook and Google stocks. The stock price prediction method has a significant impact on stock trading and derivative hedging.},
author = {Nguyen, Nguyet},
doi = {10.3390/risks5040062},
file = {:home/alederer/Documents/Literatur/Learning/Hidden Markov Models/An Analysis and Implementation of the Hidden Markov Model to Technology Stock Prediction.pdf:pdf},
journal = {Risks},
keywords = {aic,bic,hidden markov model,observations,predictions,states,stock prices},
number = {62},
title = {{An Analysis and Implementation of the Hidden Markov Model to Technology Stock Prediction}},
volume = {5},
year = {2017}
}
@article{Nguyen2018,
abstract = {Hidden Markov model (HMM) is a statistical signal prediction model, which has been widely used to predict economic regimes and stock prices. In this paper, we introduce the application of HMM in trading stocks (with S{\&}P 500 index being an example) based on the stock price predictions. The procedure starts by using four criteria, including the Akaike information, the Bayesian information, the Hannan Quinn information, and the Bozdogan Consistent Akaike Information, in order to determine an optimal number of states for the HMM. The selected four-state HMM is then used to predict monthly closing prices of the S{\&}P 500 index. For this work, the out-of-sample R 2 OS , and some other error estimators are used to test the HMM predictions against the historical average model. Finally, both the HMM and the historical average model are used to trade the S{\&}P 500. The obtained results clearly prove that the HMM outperforms this traditional method in predicting and trading stocks.},
author = {Nguyen, Nguyet},
file = {:home/alederer/Documents/Literatur/Learning/Hidden Markov Models/Hidden Markov Models for Stock Trading.pdf:pdf},
journal = {International Journal of Financial Studies},
keywords = {hidden markov model,model validation,observations,out-of-sample r 2,predictions,regimes,states,stock prices,trading},
number = {2},
pages = {36},
title = {{Hidden Markov Model for Stock Trading}},
volume = {6},
year = {2018}
}
@book{Nocedal2006,
abstract = {Optimization is an important tool used in decision science and for the analysis of physical systems used in engineering. One can trace its roots to the Calculus of Variations and the work of Euler and Lagrange. This natural and reasonable approach to mathematical programming covers numerical methods for finite-dimensional optimization problems. It begins with very simple ideas progressing through more complicated concepts, concentrating on methods for both unconstrained and constrained optimization.},
address = {New York, NY},
author = {Nocedal, J and Wright, S},
booktitle = {Springer},
edition = {second},
file = {:home/alederer/Documents/Literatur/Books/Numerical Optimization.pdf:pdf},
pages = {686},
publisher = {Springer Science+Business Media},
title = {{Numerical optimization, series in operations research and financial engineering}},
year = {2006}
}
@book{Norgard2000,
address = {London},
author = {N{\o}rg{\aa}rd, P. M. and Ravn, O. and Poulsen, N. K. and Hansen, L. K.},
publisher = {Springer},
title = {{Neural Networks for Modelling and Control of Dynamical Systems - A Practicioner's Handbook}},
year = {2000}
}
@article{Oberman2018,
abstract = {Generalization of deep neural networks (DNNs) is an open problem which, if solved, could impact the reliability and verification of deep neural network architectures. In this paper, we show that if the usual fidelity term used in training DNNs is augmented by a Lipschitz regularization term, then the networks converge and generalize. The convergence is in the limit as the number of data points, {\$}n\backslashto \backslashinfty{\$}, while also allowing the network to grow as needed to fit the data. Two regimes are identified: in the case of clean labels, we prove convergence to the label function which corresponds to zero loss, in the case of corrupted labels which we prove convergence to a regularized label function which is the solution of a limiting variational problem. In both cases, a convergence rate is also provided.},
archivePrefix = {arXiv},
arxivId = {1808.09540},
author = {Oberman, Adam M and Calder, Jeff},
eprint = {1808.09540},
file = {:home/alederer/Documents/Literatur/Learning/Deep Learning/Lipschitz Regularized Deep Neural Networks Converge and Generalize.pdf:pdf},
pages = {1--17},
title = {{Lipschitz regularized Deep Neural Networks converge and generalize}},
url = {http://arxiv.org/abs/1808.09540},
year = {2018}
}
@article{Ocampo-Martinez2016,
author = {Ocampo-Martinez, Carlos and Wang, Ye and Puig, Vicen{\c{c}}},
doi = {10.1049/iet-cta.2015.0657},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ocampo-Martinez, Wang, Puig - 2016 - Stochastic model predictive control based on Gaussian processes applied to drinking water networks.pdf:pdf},
issn = {1751-8644},
journal = {IET Control Theory {\&} Applications},
number = {8},
pages = {947--955},
title = {{Stochastic model predictive control based on Gaussian processes applied to drinking water networks}},
volume = {10},
year = {2016}
}
@incollection{Opper1997,
author = {Opper, Manfred},
booktitle = {Hong Kong International Workshop on Theoretical Aspects of Neural Computation: A Multidisciplinary Perspective},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Opper - 1997 - Regression with Gaussian processes Average case performance.pdf:pdf},
pages = {17--23},
publisher = {World Scientific},
title = {{Regression with Gaussian Processes: Average Case Performance}},
year = {1997}
}
@article{Opper1999,
author = {Opper, Manfred and Vivarelli, Francesco},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Opper, Vivarelli - 1999 - General Bounds on Bayes Errors for Regression with Gaussian Processes.pdf:pdf},
isbn = {0262112450},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {302--308},
title = {{General Bounds on Bayes Errors for Regression with Gaussian Processes}},
year = {1999}
}
@inproceedings{Ortmann2017,
abstract = {The insulin sensitivity (IS) of the human body changes with a circadian rhythm. This adds to the time-varying feature of the glucose metabolism process and places challenges on the blood glucose (BG) control of patients with Type 1 Diabetes Mellitus. This paper presents a Model Predictive Controller that takes the periodic IS into account, in order to enhance BG control. The future effect of the IS is predicted using a machine learning technique, namely, a customized Gaussian Process (GP), based on historical training data. The training data for the GP is continuously updated during closed-loop control, which enables the control scheme to learn and adapt to intra-individual and inter-individual changes of the circadian IS rhythm. The necessary state information is provided by an Unscented Kalman Filter. The closed-loop performance of the proposed control scheme is evaluated for different scenarios (including fasting, announced meals and skipped meals) through in silico studies on simulation models of G$\backslash$"ottingen Minipigs.},
archivePrefix = {arXiv},
arxivId = {1707.09948},
author = {Ortmann, Lukas and Shi, Dawei and Dassau, Eyal and Doyle, Francis J. and Leonhardt, Steffen and Misgeld, Berno J. E.},
booktitle = {Proceedings of the 11th Asian Control Conference (ASCC)},
eprint = {1707.09948},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ortmann et al. - 2017 - Gaussian Process-Based Model Predictive Control of Blood Glucose for Patients with Type 1 Diabetes Mellitus.pdf:pdf},
isbn = {9781509015726},
keywords = {Biological Systems,Intelligent and Learning Control,Predictive Control},
pages = {1092--1097},
title = {{Gaussian Process-Based Model Predictive Control of Blood Glucose for Patients with Type 1 Diabetes Mellitus}},
year = {2017}
}
@article{Ortner2013,
abstract = {We derive sublinear regret bounds for undiscounted reinforcement learning in continuous state space. The proposed algorithm combines state aggregation with the use of upper confidence bounds for implementing optimism in the face of uncertainty. Beside the existence of an optimal policy which satisfies the Poisson equation, the only assumptions made are Holder continuity of rewards and transition probabilities.},
archivePrefix = {arXiv},
arxivId = {1302.2550},
author = {Ortner, Ronald and Ryabko, Daniil},
eprint = {1302.2550},
file = {:home/alederer/Documents/Literatur/Reinforcement Learning/Online Regret Bounds for Undiscounted Continuous Reinforcement Learning.pdf:pdf},
title = {{Online Regret Bounds for Undiscounted Continuous Reinforcement Learning}},
url = {http://arxiv.org/abs/1302.2550},
year = {2013}
}
@inproceedings{Ostafew2015,
abstract = {This paper presents a Learning-based Nonlinear Model Predictive Control (LB-NMPC) algorithm to achieve high-performance path tracking in challenging off-road terrain through learning. The LB-NMPC algorithm uses a simple a priori vehicle model and a learned disturbance model. Disturbances are modeled as a Gaussian process (GP) as a function of system state, input, and other relevant variables. The GP is updated based on experience collected during previous trials. Localization for the controller is provided by an onboard, vision-based mapping and navigation system enabling operation in large-scale, GPS-denied environments. The paper presents experimental results including over 3 km of travel by three significantly different robot platforms with masses ranging from 50 to 600 kg and at speeds ranging from 0.35 to 1.2 m/s (associated video at http://tiny.cc/RoverLearnsDisturbances). Planned speeds are generated by a novel experience-based speed scheduler that balances overall travel time, path-tracking errors, and localization reliability. The results show that the controller can start from a generic a priori vehicle model and subsequently learn to reduce vehicle- and trajectory-specific path-tracking errors based on experience.},
author = {Ostafew, Ch.J. and Schoellig, A.P. and Barfoot, T.D. and Collier, J.},
booktitle = {Proceedings of the 2014 International Conference on Robotics and Automation (ICRA)},
doi = {10.1002/rob.21587},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ostafew et al. - 2014 - Learning-based Nonlinear Model Predictive Control to Improve Vision-based Mobile Robot Path Tracking.pdf:pdf},
isbn = {9781479936854},
issn = {15564959},
pages = {133--152},
title = {{Learning-based Nonlinear Model Predictive Control to Improve Vision-based Mobile Robot Path Tracking}},
year = {2014}
}
@inproceedings{Ostafew2015a,
abstract = {Robust control maintains stability and performance for a fixed amount of model uncertainty but can be conservative since the model is not updated online. Learning-based control, on the other hand, uses data to improve the model over time but is not typically guaranteed to be robust throughout the process. This paper proposes a novel combination of both ideas: a robust Min-Max Learning-Based Nonlinear Model Predictive Control (MM-LB-NMPC) algorithm. Based on an existing LB-NMPC algorithm, we present an efficient and robust extension, altering the NMPC performance objective to optimize for the worst-case scenario. The algorithm uses a simple a priori vehicle model and a learned disturbance model. Disturbances are modelled as a Gaussian Process (GP) based on experience collected during previous trials as a function of system state, input, and other relevant variables. Nominal state sequences are predicted using an Unscented Transform and worst-case scenarios are defined as sequences bounding the 3{\&}{\#}x03C3; confidence region. Localization for the controller is provided by an on-board, vision-based mapping and navigation system enabling operation in large-scale, GPS-denied environments. The paper presents experimental results from testing on a 50 kg skid-steered robot executing a path-tracking task. The results show reductions in maximum lateral and heading path-tracking errors by up to 30{\%} and a clear transition from robust control when the model uncertainty is high to optimal control when model uncertainty is reduced.},
author = {Ostafew, Chris J. and Schoellig, Angela P. and Barfoot, Timothy D.},
booktitle = {Proceedings of the IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2015.7139033},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ostafew, Schoellig, Barfoot - 2015 - Conservative to confident Treating uncertainty robustly within Learning-Based Control.pdf:pdf},
isbn = {VO -},
issn = {10504729},
pages = {421--427},
title = {{Conservative to confident: Treating uncertainty robustly within Learning-Based Control}},
year = {2015}
}
@article{Ostafew2016,
abstract = {This paper presents a Robust Constrained Learning-based Nonlinear Model Predictive Control (RC-LB-NMPC) algo- rithm for path-tracking in off-road terrain. For mobile robots, constraints may represent solid obstacles or localization limits. As a result, constraint satisfaction is required for safety. Constraint satisfaction is typically guaranteed through the use of accurate, a priori models or robust control. However, accurate models are generally not available for off-road operation. Furthermore, robust controllers are often conservative, since model uncertainty is not updated online. In this work our goal is to use learning to generate low-uncertainty, non-parametric models in situ. Based on these models, the predictive controller computes both linear and angular velocities in real-time, such that the robot drives at or near its capabilities while respecting path and localization constraints. Localization for the controller is provided by an on-board, vision-based mapping and navigation system enabling operation in large-scale, off-road environments. The paper presents experimental results, including over 5 km of travel by a 900 kg skid-steered robot at speeds of up to 2.0 m/s. The result is a robust, learning controller that provides safe, conservative control during initial trials when model uncertainty is high and converges to high-performance, optimal control during later trials when model uncertainty is reduced with experience.},
author = {Ostafew, Chris J. and Schoellig, Angela P. and Barfoot, Timothy D.},
doi = {10.1177/0278364916645661},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ostafew, Schoellig, Barfoot - 2016 - Robust Constrained Learning-based NMPC enabling reliable mobile robot path tracking.pdf:pdf},
issn = {17413176},
journal = {International Journal of Robotics Research},
keywords = {Gaussian process,Model predictive control,robust control},
number = {13},
pages = {1547--1563},
title = {{Robust Constrained Learning-based NMPC enabling reliable mobile robot path tracking}},
volume = {35},
year = {2016}
}
@inproceedings{Pan2014,
abstract = {We present a data-driven, probabilistic trajectory optimization framework for sys-tems with unknown dynamics, called Probabilistic Differential Dynamic Program-ming (PDDP). PDDP takes into account uncertainty explicitly for dynamics mod-els using Gaussian processes (GPs). Based on the second-order local approxi-mation of the value function, PDDP performs Dynamic Programming around a nominal trajectory in Gaussian belief spaces. Different from typical gradient-based policy search methods, PDDP does not require a policy parameterization and learns a locally optimal, time-varying control policy. We demonstrate the ef-fectiveness and efficiency of the proposed algorithm using two nontrivial tasks. Compared with the classical DDP and a state-of-the-art GP-based policy search method, PDDP offers a superior combination of learning speed, data efficiency and applicability.},
author = {Pan, Yunpeng and Theodorou, Evangelos},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pan, Theodorou - 2014 - Probabilistic Differential Dynamic Programming.pdf:pdf},
isbn = {9781479936847},
issn = {10495258},
pages = {1907--1915},
title = {{Probabilistic Differential Dynamic Programming}},
url = {http://papers.nips.cc/paper/5248-probabilistic-differential-dynamic-programming},
year = {2014}
}
@inproceedings{Pan2015,
abstract = {We present a Bayesian nonparametric trajectory optimization framework for systems with unknown dynamics using Gaussian Processes (GPs), called Gaussian Process Differential Dynamic Programming (GPDDP). Rooted in the Dynamic Programming principle and second-order local approximations of the value function, GPDDP learns time-varying optimal control policies from sampled data. Based on this framework, we propose two algorithms for implementations. We demonstrate the effectiveness and efficiency of the proposed framework using three numerical examples.},
author = {Pan, Yunpeng and Theodorou, Evangelos A.},
booktitle = {2015 American Control Conference (ACC)},
doi = {10.1109/ACC.2015.7172032},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pan, Theodorou - 2015 - Data-driven differential dynamic programming using Gaussian processes.pdf:pdf},
isbn = {978-1-4799-8684-2},
issn = {07431619},
keywords = {Approximation algorithms,Approximation methods,Bayes methods,Bayesian nonparametric trajectory optimization fra,Dynamic programming,GPDDP,Gaussian process differential dynamic programming,Gaussian processes,Helicopters,Heuristic algorithms,Optimal control,Trajectory,data-driven differential dynamic programming,dynamic programming,second-order local approximations,time-varying optimal control policies,value function},
pages = {4467--4472},
title = {{Data-driven differential dynamic programming using Gaussian processes}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7172032},
year = {2015}
}
@article{Pan2012,
abstract = {—In this paper, we present a neurodynamic approach to model predictive control (MPC) of unknown nonlinear dynam-ical systems based on two recurrent neural networks (RNNs). The echo state network (ESN) and simplified dual network (SDN) are adopted for system identification and dynamic optimization, respectively. First, the unknown nonlinear system is identified based on the ESN with input-output training and testing samples. Then, the resulting nonconvex optimization problem associated with nonlinear MPC is decomposed via Taylor expansion. To estimate the higher order unknown term resulted from the de-composition, an online supervised learning algorithm is developed. Next, the SDN is applied for solving the relaxed convex optimiza-tion problem to compute the optimal control actions over the predicted horizon. Simulation results are provided to demonstrate the effectiveness and characteristics of the proposed approach. The proposed RNN-based approach has many desirable properties such as global convergence and low complexity. It is shown that the RNN-based nonlinear MPC scheme is effective and potentially suitable for real-time MPC implementation in many applications. Index Terms—Model predictive control (MPC), recurrent neural networks (RNNs), unknown nonlinear systems.},
author = {Pan, Yunpeng and Wang, Jun},
doi = {10.1109/TIE.2011.2169636},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pan, Wang - 2012 - Model predictive control of unknown nonlinear dynamical systems based on recurrent neural networks.pdf:pdf},
isbn = {0278-0046},
issn = {0278-0046},
journal = {IEEE Transactions on Industrial Electronics},
number = {8},
pages = {3089--3101},
title = {{Model predictive control of unknown nonlinear dynamical systems based on recurrent neural networks}},
volume = {59},
year = {2012}
}
@inproceedings{Papachristodoulou2005,
abstract = {This tutorial is about new system analysis techniques that were developed in the past few years based on the sum of squares decomposition. We will present stability and robust stability analysis tools for different classes of systems: systems described by nonlinear ordinary differential equations or differential algebraic equations, hybrid systems with nonlinear subsystems and/or nonlinear switching surfaces, and time-delay systems described by nonlinear functional differential equations. We will also discuss how different analysis questions such as model validation and safety verification can be answered for uncertain nonlinear and hybrid systems. {\textcopyright} 2005 AACC.},
author = {Papachristodoulou, Antonis and Prajna, Stephen},
booktitle = {Proceedings of the American Control Conference},
file = {:home/alederer/Documents/Literatur/SOS/A Tutorial on Sum of Squares Techniques for Systems Analysis.pdf:pdf},
issn = {07431619},
pages = {2686--2700},
title = {{A tutorial on sum of squares techniques for systems analysis}},
year = {2005}
}
@article{Park2016,
abstract = {This paper develops an efficient computational method for solving a Gaussian process (GP) regression for large spatial data sets using a collection of suitably defined local GP regressions. The conventional local GP approach first partitions a domain into multiple non-overlapping local regions, and then fits an independent GP regression for each local region using the training data belonging to the region. Two key issues with the local GP are (1) the prediction around the boundary of a local region is not as accurate as the prediction at interior of the local region, and (2) two local GP regressions for two neighboring local regions produce different predictions at the boundary of the two regions, creating undesirable discontinuity in the prediction. We address these issues by constraining the predictions of local GP regressions sharing a common boundary to satisfy the same boundary constraints, which in turn are estimated by the data. The boundary constrained local GP regressions are solved by a finite element method. Our approach shows competitive performance when compared with several state-of-the-art methods using two synthetic data sets and three real data sets.},
author = {Park, Chiwoo and Huang, Jianhua Z.},
file = {:home/alederer/Documents/Literatur/Learning/Local GP/Efficient Computation of Gaussian Process Regression for Large Spatial Data Sets by Patching Local Gaussian Processes.pdf:pdf},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {Boundary value problem,Constrained Gaussian process regression,Kriging,Local regression,Spatial prediction,Variational problem},
pages = {1--29},
title = {{Efficient computation of Gaussian process regression for large spatial data sets by patching local Gaussian processes}},
volume = {17},
year = {2016}
}
@inproceedings{Park2013,
abstract = {In recent years, robots have started being utilized in applications with complex/unknown interaction environment, which makes system/interface modeling to be very challenging. In order to meet the demand from such applications, the experience based learning approach can be a suitable tool. In this paper, a general algorithm for learning based robot control is presented, and a novel online algorithm using sequential Gaussian process is introduced. As a case study, a simple inverted pendulum is tested to present the capabilities of the proposed algorithm.},
author = {Park, Sooho and Mustafa, Shabbir Kurbanhusen and Shimada, Kenji},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2013.6696503},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Park, Mustafa, Shimada - 2013 - Learning-based robot control with localized sparse online Gaussian process.pdf:pdf},
isbn = {9781467363587},
issn = {21530858},
pages = {1202--1207},
title = {{Learning-based robot control with localized sparse online Gaussian process}},
year = {2013}
}
@inproceedings{Patan2014,
author = {Patan, Krzysztof and Witczak, Piotr},
booktitle = {Proceedings of the 2014 IEEE International Symposium on Intelligent Control},
doi = {10.1109/ISIC.2014.6967615},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Patan, Witczak - 2014 - Robust model predictive control using neural networks.pdf:pdf},
isbn = {9781479974061},
keywords = {Modeling,Neural networks,Predictive control},
pages = {1107--1112},
title = {{Robust model predictive control using neural networks}},
year = {2014}
}
@article{Patil2017,
abstract = {This paper presents a improved Bernstein global optimization algorithm based model predictive control (MPC) scheme for the nonlinear systems. A new improvement in the Bernstein algorithm is the introduction of a box pruning operator, which during a branch-and-bound search, discard portions of the solution search space that do not contain global solution, thereby speeding up the algorithm. The applicability of this MPC scheme is demonstrated with a simulation studies on a nonlinear single machine infinite bus power system over a wide range of operating conditions. The simulation results show improvement in the system damping and settling time compared with the classical power system stabilizer and partial feedback linearization control schemes.},
author = {Patil, Bhagyesh V. and Maciejowski, Jan and Ling, K. V.},
doi = {10.1016/j.ifacol.2017.08.059},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Patil, Maciejowski, Ling - 2017 - Improved Bernstein Optimization Based Nonlinear Model Predictive Control Scheme for Power Systems.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Bernstein polynomials,Excitation control,Global optimization,Nonlinear model predictive control,Single machine infinite bus,Synchronous Generators},
number = {1},
pages = {537--544},
publisher = {Elsevier B.V.},
title = {{Improved Bernstein Optimization Based Nonlinear Model Predictive Control Scheme for Power Systems}},
url = {https://doi.org/10.1016/j.ifacol.2017.08.059},
volume = {50},
year = {2017}
}
@article{Pentland1999,
abstract = {We propose that many human behaviors can be accurately described as a set of dynamic modes (e.g., Kalman filters) sequenced together by a Markov chain. We then use these dynamic Markov models to recognize human behaviors from sensory data and to predict human behaviors over a few seconds time. To test the power of this modeling approach, we report an experiment in which we were able to achieve 95{\%} accuracy at predicting automobile drivers' subsequent actions from their initial preparatory movements.},
author = {Pentland, Alex and Andrew, Liu},
file = {:home/alederer/Documents/Literatur/Learning/Hidden Markov Models/Modeling and Prediction of Human Behavior.pdf:pdf},
journal = {Neural Computation},
number = {1},
pages = {229--242},
title = {{Modeling and prediction of human behavior}},
volume = {11},
year = {1999}
}
@inproceedings{Peters2006,
author = {Peters, Jan and Schaal, Stefan},
booktitle = {Proceedings of the 2006 IEEE/RSJ International Conference on Intelligent Robots and Systems},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Peters, Schaal - 2006 - Policy Gradient Methods for Robotics.pdf:pdf},
pages = {2219--2225},
title = {{Policy Gradient Methods for Robotics}},
year = {2006}
}
@article{Piche2000,
abstract = {A neural-network-based technique for developing nonlinear dynamic models from empirical data for an model predictive control (MPC) algorithm is presented. These models can be derived for a wide variety of processes and can also be used efficiently in an MPC framework. The nonlinear MPC-based approach presented has been successfully implemented in a number of industrial applications in the refining, petrochemical, pulp and paper, power, and food industries. Performance of the controller on a nonlinear industrial process, a polyethylene reactor, and a simulated continuous stirred tank reactor is presented},
author = {Piche, Stephen and Sayyar-Rodsari, Bijan and Johnson, Doug and Gerules, Mark},
doi = {10.1109/37.845038},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Piche et al. - 2000 - Nonlinear Model Predictive Control Using Neural Networks.pdf:pdf},
isbn = {1066-033X VO  - 20},
issn = {1066033X},
journal = {IEEE Control Systems},
number = {3},
pages = {53--62},
title = {{Nonlinear Model Predictive Control Using Neural Networks}},
volume = {20},
year = {2000}
}
@article{Piga2019,
abstract = {Model Predictive Control (MPC) is an enabling technology in applications requiring controlling physical processes in an optimized way under constraints on inputs and outputs. However, in MPC closed-loop performance is pushed to the limits only if the plant under control is accurately modeled; otherwise, robust architectures need to be employed, at the price of reduced performance due to worst-case conservative assumptions. In this paper, instead of adapting the controller to handle uncertainty, we adapt the learning procedure so that the prediction model is selected to provide the best closed-loop performance. More specifically, we apply for the first time the above "identification for control" rationale to hierarchical MPC using data-driven methods and Bayesian optimization.},
archivePrefix = {arXiv},
arxivId = {arXiv:1904.10839v1},
author = {Piga, Dario and Forgione, Marco and Formentin, Simone and Bemporad, Alberto},
doi = {10.1109/LCSYS.2019.2913347},
eprint = {arXiv:1904.10839v1},
file = {:home/alederer/Documents/Literatur/Learning Based MPC/gp mpc/Performance-oriented model learning for data-driven MPC design.pdf:pdf},
issn = {24751456},
journal = {IEEE Control Systems Letters},
keywords = {Predictive control for nonlinear systems,identification for control,machine learning},
number = {3},
pages = {577--582},
title = {{Performance-oriented model learning for data-driven mpc design}},
volume = {3},
year = {2019}
}
@article{Pohler2019,
abstract = {Data-driven approaches are well suited to represent human motion because arbitrary complex trajectories can be captured. Gaussian process state space models allow to encode human motion while quantifying uncertainty due to missing data. Such human motion models are relevant for many application domains such as learning by demonstration and motion prediction in human-robot collaboration. For goal-directed tasks it is essential to impose stability constraints on the model representing the human motion. Motivated by learning by demonstration applications, this paper proposes an uncertainty-based control Lyapunov function approach for goal-directed path tracking. We exploit the model fidelity which is related to the location of the training and test data: Our approach actively strives into regions with more demonstration data and thus higher model certainty. This achieves accurate reproduction of the human motion independent of the initial condition and we show that generated trajectories are uniformly globally asymptotically stable. The approach is validated in a nonlinear learning by demonstration task where human-demonstrated motions are reproduced by the learned dynamical system, and higher precision than competitive state of the art methods is achieved.},
author = {P{\"{o}}hler, Lukas and Umlauft, Jonas and Hirche, Sandra},
doi = {10.1016/j.ifacol.2019.01.002},
file = {:home/alederer/Documents/Literatur/colleage papers/Uncertainty-based Human Motion Tracking with Stable Gaussian Process State Space Models.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Control under uncertainty,Human centered automation,Lyapunov methods,Modeling of human performance,Nonlinear system identification,Path tracking},
number = {34},
pages = {8--14},
title = {{Uncertainty-based Human Motion Tracking with Stable Gaussian Process State Space Models}},
volume = {51},
year = {2019}
}
@article{Polymenakos2017,
abstract = {We propose a method to optimise the parameters of a policy which will be used to safely perform a given task in a data-efficient manner. We train a Gaussian process model to capture the system dynamics, based on the PILCO framework. Our model has useful analytic properties, which allow closed form computation of error gradients and estimating the probability of violating given state space constraints. During training, as well as operation, only policies that are deemed safe are implemented on the real system, minimising the risk of failure.},
archivePrefix = {arXiv},
arxivId = {1712.05556},
author = {Polymenakos, Kyriakos and Abate, Alessandro and Roberts, Stephen},
eprint = {1712.05556},
file = {:home/alederer/Documents/Literatur/Reinforcement Learning/Multi-step predictions/Safe Policy Search using Gaussian Process Models.pdf:pdf},
keywords = {gauss-,model-based reinforcement learning,safety critical systems},
number = {Aamas},
title = {{Safe Policy Search with Gaussian Process Models}},
url = {http://arxiv.org/abs/1712.05556},
year = {2017}
}
@inproceedings{Qi2015,
abstract = {{\textcopyright} 2014 IEEE. A methodology is presented in this paper for stochastic optimal control of unmanned aerial vehicle performing the task of perimeter patrol. The optimal control problem is modeled as a Markov decision processes, and an approximate policy iteration algorithm is used for the cost-to-go function (value function) by introducing Gaussian process regression, resulting in improved quality of the decisions made while retaining computationally feasibility. The approximate dynamic programming (ADP) framework is developed to tackle the issues, in which situations standard dynamic programming algorithms become computationally too demanding. As a nonparametric ADP algorithm, the Gaussian processes that provide the combination of the prior and noise models presents a sub-solution in a lower dimensional space by exploiting kernel-based method. The numerical results that corroborate the effectiveness of the proposed methodology are also provided.},
author = {Qi, N. and Sun, X. and Sun, K. and Liu, X. and Wu, F. and Liu, C.},
booktitle = {Proceedings - 2014 International Conference on Mechatronics and Control, ICMC 2014},
doi = {10.1109/ICMC.2014.7231861},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qi et al. - 2015 - Approximate dynamic programming based on Gaussian process regression for the perimeter patrol optimization problem.pdf:pdf},
isbn = {9781479925384},
keywords = {Approximate dynamic programming (ADP),Gaussian process regression,Markov decision processes,perimeter patrol,unmanned air vehicle},
pages = {1750--1754},
title = {{Approximate dynamic programming based on Gaussian process regression for the perimeter patrol optimization problem}},
year = {2015}
}
@article{Qian2018,
abstract = {We introduce and analyse two algorithms for exploration-exploitation in discrete and continuous Markov Decision Processes (MDPs) based on exploration bonuses. SCAL{\$}{\^{}}+{\$} is a variant of SCAL (Fruit et al., 2018) that performs efficient exploration-exploitation in any unknown weakly-communicating MDP for which an upper bound C on the span of the optimal bias function is known. For an MDP with {\$}S{\$} states, {\$}A{\$} actions and {\$}\backslashGamma \backslashleq S{\$} possible next states, we prove that SCAL{\$}{\^{}}+{\$} achieves the same theoretical guarantees as SCAL (i.e., a high probability regret bound of {\$}\backslashwidetilde{\{}O{\}}(C\backslashsqrt{\{}\backslashGamma SAT{\}}){\$}), with a much smaller computational complexity. Similarly, C-SCAL{\$}{\^{}}+{\$} exploits an exploration bonus to achieve sublinear regret in any undiscounted MDP with continuous state space. We show that C-SCAL{\$}{\^{}}+{\$} achieves the same regret bound as UCCRL (Ortner and Ryabko, 2012) while being the first implementable algorithm with regret guarantees in this setting. While optimistic algorithms such as UCRL, SCAL or UCCRL maintain a high-confidence set of plausible MDPs around the true unknown MDP, SCAL{\$}{\^{}}+{\$} and C-SCAL{\$}{\^{}}+{\$} leverage on an exploration bonus to directly plan on the empirically estimated MDP, thus being more computationally efficient.},
archivePrefix = {arXiv},
arxivId = {1812.04363},
author = {Qian, Jian and Fruit, Ronan and Pirotta, Matteo and Lazaric, Alessandro},
eprint = {1812.04363},
file = {:home/alederer/Documents/Literatur/Reinforcement Learning/Exploration Bonus for Regret Minimization in Undiscounted Discrete and Continuous Markov Decision Process.pdf:pdf},
title = {{Exploration Bonus for Regret Minimization in Undiscounted Discrete and Continuous Markov Decision Processes}},
url = {http://arxiv.org/abs/1812.04363},
volume = {1},
year = {2018}
}
@inproceedings{Qu2018,
author = {Qu, Ting and Yu, Shuyou and Shi, Zhuqing and Chen, Hong},
booktitle = {Proceedings of the Asian Control Conference},
file = {:home/alederer/Documents/Literatur/Learning/Hidden Markov Models/Modeling Driver's Car-Following Behavior Based on Hidden Markov Model and Model Predictive Control{\_} A Cyber Physical System Approach.pdf:pdf},
keywords = {Control Applications,Human-Machine Systems,Predictive Control},
pages = {114--119},
title = {{Modeling driver's car-following behavior based on hidden Markov model and model predictive control: A cyber-physical system approach}},
year = {2018}
}
@techreport{Quinonero-Candela2003,
author = {Quinonero-Candela, J and Girard, Agathe and Rasmussen, C E},
booktitle = {Technical Report},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Quinonero-Candela, Girard, Rasmussen - 2003 - Prediction at an Uncertain Input for Gaussian Processes and Relevance Vector Machines A(2).pdf:pdf},
institution = {Technical University of Denmark},
title = {{Prediction at an Uncertain Input for Gaussian Processes and Relevance Vector Machines Application to Multiple-Step Ahead Time-Series Forecasting}},
year = {2003}
}
@article{Quinonero-candela2005,
abstract = {We provide a new unifying view, including all existing proper probabilistic sparse approximations for Gaussian process regression. Our approach relies on expressing the effective prior which the methods are using. This allows new insights to be gained, and highlights the relationship between existing methods. It also allows for a clear theoretically justified ranking of the closeness of the known approximations to the corresponding full GPs. Finally we point directly to designs of new better sparse approximations, combining the best of the existing strategies, within attractive computational constraints.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Qui{\~{n}}onero-candela, Joaquin and Rasmussen, Carl Edward and Herbrich, Ralf},
doi = {10.1163/016918609X12529286896877},
eprint = {arXiv:1011.1669v3},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qui{\~{n}}onero-candela, Rasmussen, Herbrich - 2005 - A unifying view of sparse approximate Gaussian process regression.pdf:pdf},
isbn = {1532-4435},
issn = {1533-7928},
journal = {Journal of Machine Learning Research},
keywords = {Bayesian committee,Gaussian process,machine,probabilistic regression,sparse approximation},
pages = {1935--1959},
pmid = {236331100003},
title = {{A unifying view of sparse approximate Gaussian process regression}},
volume = {6},
year = {2005}
}
@article{Quirion2008,
abstract = {Gaussian Process Latent Variable Models (GPLVMs) have been found to allow dramatic dimensionality reduction in character animations, often yielding two-dimensional or three-dimensional spaces from which the animation can be retrieved without perceptible alterations. Recently, many researchers have used this approach and improved on it for their purposes, thus creating a number of GPLVM-based approaches. The current paper introduces the main concepts behind GPLVMs and introduces its most widely known variants. Each approach is then compared based on various criteria pertaining to the task of dimensionality reduction in character animation. In the light of our experiments, no single approach is preferred over all others in all respects. Depending whether dimensionality reduction is used for compression purposes, to interpolate new natural looking poses or to synthesize entirely new motions, different approaches will be preferred.},
author = {Quirion, S{\'{e}}bastien and Duchesne, Chantale and Laurendeau, Denis},
file = {:home/alederer/Local/Literatur/Parkinson/GP Modelling/Comparing GPLVM Approaches for Dimensionality Reduction in Character Animation.pdf:pdf},
journal = {Jwscg},
keywords = {b-gpdm,character animation,degrees of freedom,dimensionality reduction,gaussian process,gpdm,gplvm,nonlinear transform,pca,sgplvm},
number = {13},
title = {{Comparing GPLVM Approaches for Dimensionality}},
url = {http://wscg.zcu.cz/wscg2008/Papers{\_}2008/journal/B53-full.pdf},
volume = {16},
year = {2008}
}
@article{Raimondo2009,
abstract = {Min - Max model predictive control (MPC) is one of the few techniques suitable for robust stabilization of uncertain nonlinear systems subject to constraints. Stability issues as well as robustness have been recently studied and some novel contributions on this topic have appeared in the ...},
author = {Raimondo, Davide Martino and Limon, Daniel and Lazar, Mircea and Magni, Lalo and Camacho, Eduardo Fern{\'{a}}ndez},
doi = {10.3166/ejc.15.5-21},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Raimondo et al. - 2009 - Min-max Model Predictive Control of Nonlinear Systems A Unifying Overview on Stability.pdf:pdf},
issn = {09473580},
journal = {European Journal of Control},
keywords = {input-to-state stability,nonlinear model predictive control,robust control},
number = {1},
pages = {5--21},
title = {{Min-max Model Predictive Control of Nonlinear Systems: A Unifying Overview on Stability}},
volume = {15},
year = {2009}
}
@article{Ranganathan2011,
abstract = {We present a new Gaussian process (GP) inference algorithm, called online sparse matrix Gaussian processes (OSMGP), and demonstrate its merits by applying it to the problems of head pose estimation and visual tracking. The OSMGP is based upon the observation that for kernels with local support, the Gram matrix is typically sparse. Maintaining and updating the sparse Cholesky factor of the Gram matrix can be done efficiently using Givens rotations. This leads to an exact, online algorithm whose update time scales linearly with the size of the Gram matrix. Further, we provide a method for constant time operation of the OSMGP using matrix downdates. The downdates maintain the Cholesky factor at a constant size by removing certain rows and columns corresponding to discarded training examples. We demonstrate that, using these matrix downdates, online hyperparameter estimation can be included at cost linear in the number of total training examples. We describe a robust appearance-based head pose estimation system based upon the OSMGP. Numerous experiments and comparisons with existing methods using a large dataset system demonstrate the efficiency and accuracy of our system. Further, to showcase the applicability of OSMGP to a wide variety of problems, we also describe a regression-based visual tracking method. Experiments show that our OSMGP algorithm generalizes well using online learning.},
author = {Ranganathan, Ananth and Yang, Ming Hsuan and Ho, Jeffrey},
doi = {10.1109/TIP.2010.2066984},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ranganathan, Yang, Ho - 2011 - Online sparse gaussian process regression and its applications.pdf:pdf},
isbn = {1057-7149 VO - 20},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {Gaussian process,matrix algebra,online algorithm,pose estimation,visual tracking},
number = {2},
pages = {391--404},
pmid = {20716500},
title = {{Online sparse gaussian process regression and its applications}},
volume = {20},
year = {2011}
}
@article{Ranganathan2008,
author = {Ranganathan, Ananth and Yang, Ming-hsuan},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ranganathan, Yang - 2008 - Online Sparse Matrix Gaussian Process Regression and Vision Applications.pdf:pdf},
pages = {468--482},
title = {{Online Sparse Matrix Gaussian Process Regression and Vision Applications}},
year = {2008}
}
@book{Rasmussen2006,
abstract = {Gaussian processes (GPs) are natural generalisations of multivariate Gaussian random variables to infinite (countably or continuous) index sets. GPs have been applied in a large number of fields to a diverse range of ends, and very many deep theoretical analyses of various properties are available. This paper gives an introduction to Gaussian processes on a fairly elementary level with special emphasis on characteristics relevant in machine learning. It draws explicit connections to branches such as spline smoothing models and support vector machines in which similar ideas have been investigated. Gaussian process models are routinely used to solve hard machine learning problems. They are attractive because of their flexible non-parametric nature and computational simplicity. Treated within a Bayesian framework, very powerful statistical methods can be implemented which offer valid estimates of uncertainties in our predictions and generic model selection procedures cast as nonlinear optimization problems. Their main drawback of heavy computational scaling has recently been alleviated by the introduction of generic sparse approximations.13,78,31 The mathematical literature on GPs is large and often uses deep concepts which are not required to fully understand most machine learning applications. In this tutorial paper, we aim to present characteristics of GPs relevant to machine learning and to show up precise connections to other "kernel machines" popular in the community. Our focus is on a simple presentation, but references to more detailed sources are provided.},
address = {Cambridge, MA},
author = {Rasmussen, Carl E. and Williams, Christopher K. I.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rasmussen, Williams - 2006 - Gaussian processes for machine learning.pdf:pdf},
publisher = {The MIT Press},
title = {{Gaussian Processes for Machine Learning}},
year = {2006}
}
@article{Ratschan2010,
abstract = {In this paper, we present a method for computing a basin of attraction to a target region for polynomial ordinary differential equations. This basin of attraction is ensured by a Lyapunov-like polynomial function that we compute using an interval based branch-and-relax algorithm. This algorithm relaxes the necessary conditions on the coefficients of the Lyapunov-like function to a system of linear interval inequalities that can then be solved exactly. It iteratively refines these relaxations in order to ensure that, whenever a nondegenerate solution exists, it will eventually be found by the algorithm. Application of an implementation to a range of benchmark problems shows the usefulness of the approach.},
author = {Ratschan, Stefan and She, Zhikun},
doi = {10.1137/090749955},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ratschan, She - 2010 - Providing a Basin of Attraction to a Target Region of Polynomial Systems by Computation of Lyapunov-Like Function.pdf:pdf},
issn = {0363-0129},
journal = {SIAM Journal on Control and Optimization},
keywords = {090749955,1,10,1137,65g40,65p40,68u99,a sufficient condition for,algorithms,ams subject classifications,basin of attraction,constraint solving,differ-,doi,interval computation,introduction,stability,verifying stability of ordinary},
number = {7},
pages = {4377--4394},
title = {{Providing a Basin of Attraction to a Target Region of Polynomial Systems by Computation of Lyapunov-Like Functions}},
url = {http://epubs.siam.org/doi/10.1137/090749955},
volume = {48},
year = {2010}
}
@book{Rawlings2016,
address = {Madison, Wi},
author = {Rawlings, James B. and Mayne, David Q.},
edition = {second},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rawlings, Mayne - 2016 - Model Predictive Control Theory and Design.pdf:pdf},
pages = {715},
publisher = {Nob Hill Publishing},
title = {{Model Predictive Control: Theory and Design}},
year = {2016}
}
@book{Rawlings2012,
abstract = {provide a comprehensive and foundational treatment of the theory and design of model predictive control (MPC)},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Rawlings, James B. and Mayne, David Q.},
doi = {10.1109/TBME.2009.2039571},
eprint = {arXiv:1011.1669v3},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rawlings, Mayne - 2012 - Model Predictive Control Theory and Design.pdf:pdf},
isbn = {978-0-975-93770-9},
issn = {15582531},
pmid = {20172797},
publisher = {Nob Hill Publishing},
title = {{Model Predictive Control : Theory and Design}},
year = {2012}
}
@inproceedings{Reeb2018,
author = {Reeb, David and Doerr, Andreas and Gerwinn, Sebastian and Rakitsch, Barbara},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reeb et al. - 2018 - Learning Gaussian Processes by Minimizing PAC-Bayesian Generalization Bounds.pdf:pdf},
title = {{Learning Gaussian Processes by Minimizing PAC-Bayesian Generalization Bounds}},
year = {2018}
}
@book{Ritter2000,
author = {Ritter, Klaus},
file = {:home/alederer/Local/Literatur/Learning/learning theory/Average-Case Analysis of Numerical Problems.pdf:pdf},
isbn = {3540674497},
publisher = {Springer Science {\&} Business Media},
title = {{Average-Case Analysis of Numerical Problems}},
year = {2000}
}
@article{Ritter1996,
abstract = {We study differentiation of functions f based on noisy data f(ti) + $\epsilon$i. We recover f(k)either at a single point or on the interval [0, 1] in L2-norm. Under stochastic assumptions on f and $\epsilon$i, we determine the order of the errors of the best linear methods which use n noisy function values. Polynomial interpolation for the pointwise problem and smoothing splines for the problem in L2-norm are shown to be almost optimal. The analysis involves worst case estimates in reproducing kernel Hilbert spaces and a Landau inequality. {\textcopyright} 1996 Academic Press, Inc.},
author = {Ritter, Klaus},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ritter - 1996 - Almost optimal differentiation using noisy data.pdf:pdf},
journal = {Journal of Approximation Theory},
number = {3},
pages = {293--309},
title = {{Almost optimal differentiation using noisy data}},
volume = {86},
year = {1996}
}
@book{Robert2004,
address = {New York, NY},
author = {Robert, Christian P. and Casella, George},
edition = {second},
file = {:home/alederer/Documents/Literatur/Books/Monte Carlo Statistical Methods.pdf:pdf},
publisher = {Springer Science+Business Media},
title = {{Monte Carlo Statistical Methods}},
year = {2004}
}
@article{Rosset,
author = {Rosset, Corbin and Ige, Matthew and Duhaime, Edmund},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rosset, Ige, Duhaime - Unknown - Regretful Bandits A Survey of Algorithms and Regret Bounds for Adversarial Multi-Armed Bandits.pdf:pdf},
keywords = {multi-armed bandit,stochasticity},
pages = {1--16},
title = {{Regretful Bandits: A Survey of Algorithms and Regret Bounds for Adversarial Multi-Armed Bandits}}
}
@article{Ruan2019,
abstract = {Advances in conversational AI have the potential to enable more engaging and effective ways to teach factual knowledge. To investigate this hypothesis, we created QuizBot, a dialogue-based agent that helps students learn factual knowledge in science, safety, and English vocabulary. We evaluated QuizBot with 76 students through two within-subject studies against a flashcard app, the traditional medium for learning factual knowledge. Though both systems used the same algorithm for sequencing materials, QuizBot led to students recognizing (and recalling) over 20{\%} more correct answers than when students used the flashcard app. Using a conversational agent is more time consuming to practice with; but in a second study, of their own volition, students spent 2.6x more time learning with QuizBot than with flashcards and reported preferring it strongly for casual learning. Our results in this second study showed QuizBot yielded improved learning gains over flashcards on recall. These results suggest that educational chatbot systems may have beneficial use, particularly for learning outside of traditional settings.},
author = {Ruan, Sherry and Jiang, Liwei and Xu, Justin and Tham, Bryce Joe-Kun and Qiu, Zhengneng and Zhu, Yeshuang and Murnane, Elizabeth L and Brunskill, Emma and Landay, James A},
doi = {10.1145/3290605.3300587},
file = {:home/alederer/Documents/Literatur/Learning/human in the loop/QuizBot{\_} A Dialogue-based Adaptive Learning System for Factual Knowledge.pdf:pdf},
isbn = {9781450359702},
journal = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems - CHI '19},
keywords = {chatbots,conversational user interfaces,educational applications,intelligent systems,pedagogical agents},
number = {Chi},
pages = {1--13},
title = {{QuizBot: A Dialogue-based Adaptive Learning System for Factual Knowledge Sherry}},
url = {http://dl.acm.org/citation.cfm?doid=3290605.3300587},
year = {2019}
}
@article{Ryden2008,
abstract = {Hidden Markov models (HMMs) and related models have become stan- dard in statistics during the last 15–20 years, with applications in diverse areas like speech and other statistical signal processing, hydrology, financial statistics and econometrics, bioinformatics etc. Inference in HMMs is traditionally often carried out using the EM algorithm, but examples of Bayesian estimation, in general implemented through Markov chain Monte Carlo (MCMC) sampling are also frequent in the HMM literature. The purpose of this paper is to compare the EM and MCMC approaches in three cases of different complexity; the examples include model order selection, continuous-time HMMs and variants of HMMs in which the observed data depends on many hidden variables in an overlapping fashion. All these examples in some way or another originate from real-data applications. Neither EM nor MCMC analysis of HMMs is a black-box methodology without need for user-interaction, and we will illustrate some of the problems, like poor mixing and long computation times, one may expect to encounter.},
author = {Ryd{\'{e}}n, Tobias},
file = {:home/alederer/Documents/Literatur/Learning/Hidden Markov Models/EM versus Makrov Chain Monte Carlo for Estimation of Hidden Markov Models{\_} A Computational Perspective.pdf:pdf},
journal = {Bayesian Analysis},
keywords = {Computational statistics,Em,Hidden Markov model,Incomplete data,Markov chain Monte Carlo,Missing data,Trans-dimensional Monte Carlo},
number = {4},
pages = {659--688},
title = {{EM versus Markov chain monte carlo for estimation of hidden Markov models: A computational perspective}},
volume = {3},
year = {2008}
}
@article{Saint-donatt1991,
author = {Saint-Donatt, Jean and Bhatt, Naveen and Mcavoy, Thomas J and Recently, Introduction},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saint-Donatt et al. - 1991 - Neural net based model predictive control.pdf:pdf},
journal = {International Journal of Control},
number = {6},
pages = {1453--1468},
title = {{Neural net based model predictive control}},
volume = {54},
year = {1991}
}
@inproceedings{Sarkka2011,
abstract = {This paper is concerned with estimation of learning curves for Gaussian process regression with multidimensional numerical inte-gration. We propose an approach where the recursion equations for the generalization error are approximately solved using numerical cubature integration methods. The advantage of the approach is that the eigen-function expansion of the covariance function does not need to be known. The accuracy of the proposed method is compared to eigenfunction ex-pansion based approximations to the learning curve.},
author = {S{\"{a}}rkk{\"{a}}, Simo},
booktitle = {Proceedings of the International Conference on Artificial Neural Networks},
doi = {10.1007/978-3-642-21735-7_25},
file = {:home/alederer/Local/Literatur/Learning/learning theory/Learning Curves for Gaussian Processes via Numerical Cubature Integration.pdf:pdf},
isbn = {9783642217340},
issn = {03029743},
keywords = {Gaussian process regression,learning curve,numerical cubature},
pages = {201--208},
title = {{Learning Curves for Gaussian Processes via Numerical Cubature Integration}},
year = {2011}
}
@inproceedings{Sarkka2013,
author = {S{\"{a}}rkk{\"{a}}, Simo and Solin, Arno},
booktitle = {Image Analysis},
doi = {10.1007/978-3-642-38886-6_17},
editor = {K{\"{a}}m{\"{a}}r{\"{a}}inen, Joni-Kristian and Koskela, Markus},
file = {:home/alederer/Local/Literatur/Learning/learning theory/Continuous-Space Gaussian Process Regression and Generalized Wiener Filtering with Application to Learning Curves.pdf:pdf},
isbn = {9783642388859},
issn = {03029743},
keywords = {Gaussian process regression,Wiener filter,continuous-space measurement,learning curve},
pages = {172--181},
publisher = {Springer Berlin Heidelberg},
title = {{Continuous-space Gaussian Process Regression and Generalized Wiener Filtering with Application to Learning Curves}},
year = {2013}
}
@book{Sauer1998,
address = {Upper Saddle River, NJ},
author = {Sauer, Peter W. and Pai, M.A.},
file = {:home/alederer/Documents/Literatur/Stabiliy Analysis/Power System Dynamics and Stability.pdf:pdf},
publisher = {Prentice-Hall},
title = {{Power System Dynamics and Stability}},
year = {1998}
}
@article{Sbarbaro2005,
abstract = {This book explains the management principles and business philosophy behind Toyota's worldwide reputation for quality and reliability. It also shows managers in every industry how to improve business processes.},
author = {Sbarbaro, Daniel and Murray-Smith, Roderick},
file = {:home/alederer/Documents/Literatur/Learning Based MPC/gp mpc/AN ADAPTIVE NONPARAMETRIC CONTROLLER FOR A CLASS OF NONMINIMUM PHASE NON-LINEAR SYSTEM.pdf:pdf},
isbn = {0071392319},
keywords = {adaptive systems,discrete non-linear system,generalized minimum,non-parametric models,variance},
title = {{An Adaptive Nonparametric Controller for a Class of Nonminimum Phase Non-linear System}},
url = {http://biblioteca.usac.edu.gt/tesis/08/08{\_}2469{\_}C.pdf},
year = {2005}
}
@inproceedings{Scaman2019,
abstract = {Deep neural networks are notorious for being sensitive to small well-chosen perturbations, and estimating the regularity of such architectures is of utmost importance for safe and robust practical applications. In this paper, we investigate one of the key characteristics to assess the regularity of such methods: the Lipschitz constant of deep learning architectures. First, we show that, even for two layer neural networks, the exact computation of this quantity is NP-hard and state-of-art methods may significantly overestimate it. Then, we both extend and improve previous estimation methods by providing AutoLip, the first generic algorithm for upper bounding the Lipschitz constant of any automatically differentiable function. We provide a power method algorithm working with automatic differentiation, allowing efficient computations even on large convolutions. Second, for sequential neural networks, we propose an improved algorithm named SeqLip that takes advantage of the linear computation graph to split the computation per pair of consecutive layers. Third we propose heuristics on SeqLip in order to tackle very large networks. Our experiments show that SeqLip can significantly improve on the existing upper bounds.},
author = {Scaman, Kevin and Virmaux, Aladin},
booktitle = {International Conference on Machine Learning},
file = {:home/alederer/Documents/Literatur/Learning/Deep Learning/Lipschitz Regularity of Deep Neural Networkds{\_} Analysis and Efficient Estimation.pdf:pdf},
pages = {1--10},
title = {{Lipschitz regularity of deep neural networks: analysis and efficient estimation}},
year = {2018}
}
@article{Schaal2010,
author = {Schaal, Stefan and Atkeson, Christopher G.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schaal, Atkeson - 2010 - Learning Control in Robotics.pdf:pdf},
journal = {IEEE Robotics {\&} Automation Magazine},
number = {2},
pages = {20--29},
title = {{Learning Control in Robotics}},
volume = {17},
year = {2010}
}
@article{Schaback2002,
abstract = {If additional smoothness requirements and boundary conditions are met, the well-known approximation orders of scattered data interpolants by radial functions can roughly be doubled.},
author = {Schaback, R.},
doi = {10.1090/s0025-5718-99-01009-1},
file = {:home/alederer/Local/Literatur/Learning/learning theory/Improved Error Bounds for Scattered Data Interpolation.pdf:pdf},
issn = {0025-5718},
journal = {Mathematics of Computation},
number = {225},
pages = {201--217},
title = {{Improved Error Bounds for Scattered Data Interpolation by Radial Basis Functions}},
volume = {68},
year = {2002}
}
@article{Schaback2006,
author = {Schaback, Robert and Wendland, Holger},
doi = {10.1017/S0962492904000077},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schaback, Wendland - 2006 - Kernel Techniques From Machine Learning to Meshless Methods.pdf:pdf},
journal = {Acta Numerica},
pages = {543--639},
title = {{Kernel Techniques : From Machine Learning to Meshless Methods}},
volume = {15},
year = {2006}
}
@article{Scheuerer2013,
author = {Scheuerer, M and Schaback, R and Schlather, M},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Scheuerer, Schaback, Schlather - 2013 - Interpolation of Spatial Data - A Stochastic or a Deterministic Problem.pdf:pdf},
journal = {European Journal of Applied Mathematics},
number = {4},
pages = {601--629},
title = {{Interpolation of Spatial Data - A Stochastic or a Deterministic Problem ?}},
volume = {24},
year = {2013}
}
@article{Schildbach2014,
abstract = {Many practical applications in control require that constraints on the inputs and states of the system are respected, while some performance criterion is optimized. In the presence of model uncertainties or disturbances, it is often sufficient to satisfy the state constraints for at least a prescribed share of the time, such as in building climate control or load mitigation for wind turbines. For such systems, this paper presents a new method of Scenario-Based Model Predictive Control (SCMPC). The basic idea is to optimize the control inputs over a finite horizon, subject to robust constraint satisfaction under a finite number of random scenarios of the uncertainty and/or disturbances. Previous SCMPC approaches have suffered from a substantial gap between the rate of constraint violations specified in the optimal control problem and that actually observed in closed-loop operation of the controlled system. This paper identifies the two theoretical explanations for this gap. First, accounting for the special structure of the optimal control problem leads to a substantial reduction of the problem dimension. Second, the probabilistic constraints have to be interpreted as average-in-time, rather than pointwise-in-time. Based on these insights, a novel SCMPC method can be devised for general linear systems with additive and multiplicative disturbances, for which the number of scenarios is significantly reduced. The presented method retains the essential advantages of the general SCMPC approach, namely a low computational complexity and the ability to handle arbitrary probability distributions. Moreover, the computational complexity can be adjusted by a sample-and-remove strategy.},
archivePrefix = {arXiv},
arxivId = {1307.5640},
author = {Schildbach, Georg and Fagiano, Lorenzo and Frei, Christoph and Morari, Manfred},
doi = {10.1016/j.automatica.2014.10.035},
eprint = {1307.5640},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schildbach et al. - 2014 - The scenario approach for Stochastic Model Predictive Control with bounds on closed-loop constraint violation.pdf:pdf},
isbn = {4144632121},
issn = {00051098},
journal = {Automatica},
keywords = {Chance constraints,MPC,Scenario optimization,Scenario-Based,Soft constraints,Stochastic,Stochastic systems},
number = {12},
pages = {3009--3018},
publisher = {Elsevier Ltd},
title = {{The scenario approach for Stochastic Model Predictive Control with bounds on closed-loop constraint violations}},
volume = {50},
year = {2014}
}
@article{Schillinger2017,
abstract = {In the combustion engine calibration domain, many controllers are still tuned manually or using simple adjustment laws. In order to increase workforce efficiency, automated methods for controller tuning are desirable. Often, the structure of the controller is fixed and only its parameters have to be optimized. Model based controller tuning methods require a good dynamic model of the system. Such models are often hard to obtain, as deep system knowledge or extensive measurements at the system, potentially in open loop, may be required. In some cases only closed loop measurements are possible, for example, due to system instability. If controller tuning methods interact with the real system for which the controller shall be tuned, they have to comply with safety constraints. For example, parameter sets resulting in unstable control loops or ones causing critical system states as with very high overshoot should not be tested at the real system. In this contribution, two optimization-based methods for tuning controller parameters are compared. The first method, Safe Active Learning for control, learns a loss function based on controller parameters. Subsequently, an offline optimization is pursued. The second method, a newly proposed Safe Bayesian Optimization algorithm, combines learning of a loss function model with online optimization. Both methods perform closed loop measurements and take safety constraints into account. The methods are evaluated and compared at a PI controller of a real high pressure fuel supply system in a test vehicle.},
author = {Schillinger, Mark and Hartmann, Benjamin and Skalecki, Patric and Meister, Mona and Nguyen-Tuong, Duy and Nelles, Oliver},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schillinger et al. - 2017 - Safe Active Learning and Safe Bayesian Optimization for Tuning a PI-Controller.pdf:pdf},
journal = {Proceedings of the IFAC World Congress},
keywords = {control,diagnosis of automotive systems,engine modelling,modeling,supervision},
number = {1},
pages = {5967--5972},
publisher = {Elsevier B.V.},
title = {{Safe Active Learning and Safe Bayesian Optimization for Tuning a PI-Controller}},
volume = {50},
year = {2017}
}
@article{Schneider2010,
abstract = {In recent years there was a tremendous progress in robotic systems, and however also increased expectations: A robot should be easy to program and reliable in task execution. Learning from Demonstration (LfD) offers a very promising alternative to classical engineering approaches. LfD is a very natural way for humans to interact with robots and will be an essential part of future service robots. In this work we first review heteroscedastic Gaussian processes and show how these can be used to encode a task. We then introduce a new Gaussian process regression model that clusters the input space into smaller subsets similar to the work in [11]. In the next step we show how these approaches fit into the Learning by Demonstration framework of [2], [3]. At the end we present an experiment on a real robot arm that shows how all these approaches interact.},
author = {Schneider, Markus and Ertel, Wolfgang},
doi = {10.1109/IROS.2010.5650949},
file = {:home/alederer/Documents/Literatur/Learning/Local GP/Robot Learning by Demonstration with Local Gaussian Process Regression.pdf:pdf},
isbn = {9781424466757},
journal = {IEEE/RSJ 2010 International Conference on Intelligent Robots and Systems, IROS 2010 - Conference Proceedings},
pages = {255--260},
title = {{Robot learning by demonstration with local gaussian process regression}},
year = {2010}
}
@article{Schreiter2016,
abstract = {Sparse Gaussian process models provide an efficient way to perform regression on large data sets. Sparsification approaches deal with the selection of a representative subset of available training data for inducing the sparse model approximation. A variety of insertion and deletion criteria have been proposed, but they either lack accuracy or suffer from high computational costs. In this paper, we present a new and straightforward criterion for successive selection and deletion of training points in sparse Gaussian process regression. The proposed novel strategies for sparsification are as fast as the purely randomized schemes and, thus, appropriate for applications in online learning. Experiments on real-world robot data demonstrate that our obtained regression models are competitive with the computationally intensive state-of-the-art methods in terms of generalization and accuracy. Furthermore, we employ our approach in learning inverse dynamics models for compliant robot control using very large data sets, i.e. with half a million training points. In this experiment, it is also shown that our approximated sparse Gaussian process model is sufficiently fast for real-time prediction in robot control.},
author = {Schreiter, Jens and Nguyen-Tuong, Duy and Toussaint, Marc},
doi = {10.1016/j.neucom.2016.02.032},
file = {:home/alederer/Documents/Literatur/Learning/Local GP/Efficient Sparsification for Gaussian Process Regression.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Gaussian processes,Greedy subset selection,Learning robot inverse dynamics,Sparse approximations},
number = {May},
pages = {29--37},
publisher = {Elsevier},
title = {{Efficient sparsification for Gaussian process regression}},
url = {http://dx.doi.org/10.1016/j.neucom.2016.02.032},
volume = {192},
year = {2016}
}
@inproceedings{Schulz2015,
abstract = {How do we perceive the predictability of functions? We derive a rational measure of a function's predictabil- ity based on Gaussian process learning curves. Using this measure, we show that the smoothness of a func- tion can be more important to predictability judgments than the variance of additive noise or the number of samples. These patterns can be captured well by the learning curve for Gaussian process regression, which in turn crucially depends on the eigenvalue spectrum of the covariance function. Using approximate bounds on the learning curve, we model participants' predictabil- ity judgments about sampled functions and find that smoothness is indeed a better predictor for perceived predictability than both the variance and the sample size. This means that it can sometimes be preferable to learn about noisy but smooth functions instead of deterministic complex ones.},
author = {Schulz, Eric and Tenenbaum, Joshua B. and Reshef, David N. and Speekenbrink, Maarten and Gershman, Samuel J.},
booktitle = {Proceedings of the Conference of the Cognitive Science Society},
file = {:home/alederer/Local/Literatur/Learning/learning theory/Assesing the Perceived Predictability of Functions.pdf:pdf},
keywords = {Function learning,Gaussian processes,predictability,smooth- ness},
pages = {2116--2121},
title = {{Assessing the Perceived Predictability of Functions}},
year = {2015}
}
@article{Schuster-Bockler1986,
abstract = {This unit introduces the concept of hidden Markov models in computational biology. It describes them using simple biological examples, requiring as little mathematical knowledge as possible. The unit also presents a brief history of hidden Markov models and an overview of their current applications before concluding with a discussion of their limitations.},
author = {Schuster-B{\"{o}}ckler, Benjamin and Bateman, Alex},
file = {:home/alederer/Documents/Literatur/Reinforcement Learning/Multi-step predictions/An Introduction to Hidden Markov Models.pdf:pdf},
isbn = {0740-7467},
issn = {1934-340X},
journal = {IEEE ASSP Magazine},
number = {1},
pages = {4--16},
pmid = {18428778},
title = {{An Introduction to Hidden Markov Models}},
year = {1986}
}
@article{Scott2002,
author = {Scott, Steven L.},
file = {:home/alederer/Documents/Literatur/Learning/Hidden Markov Models/Bayesian Methods for Hidden Markov Models$\backslash$: Recursive Computing in the 21st Century.pdf:pdf},
journal = {Journal of the American Statistical Association},
keywords = {a hidden markov model,and using,diagnostics to assess model,finite state markov chain,forward-backward recursion,gibbs sampler,hmm,hmms,is a mixture model,kalman filter,local computation,markov chain monte carlo,mixing distribution is a,of the hidden chain,s state space,validity and mcmc convergence,whose mining the size},
number = {457},
pages = {337--351},
title = {{Bayesian Methods for Hidden Markov Models: Recursive Computing in the 21st Century}},
volume = {97},
year = {2002}
}
@article{Seeger2002,
author = {Seeger, Matthias},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Seeger - 2002 - PAC-Bayesian Generalisation Error Bounds for Gaussian Process Classification.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {bayesian learning,convex,gaussian processes,generalisation error bounds,gibbs classifier,kernel machines,pac-bayesian framework,sparse approximations},
pages = {233--269},
title = {{PAC-Bayesian Generalisation Error Bounds for Gaussian Process Classification}},
volume = {3},
year = {2002}
}
@inproceedings{Seeger,
author = {Seeger, Matthias and Williams, Christopher K. I. and Lawrence, Neil D.},
booktitle = {Workshop on AI and Statistics},
file = {:home/alederer/Local/Literatur/Learning/learning theory/Fast Forward Selection to Speed Up Sparse Gaussian Process Regression.pdf:pdf},
title = {{Fast Forward Selection to Speed Up Sparse Gaussian Process Regression}},
year = {2003}
}
@incollection{Seifert2017,
abstract = {In recent years, Deep Neural Networks (DNNs) have been shown to outperform the state-of-the-art in multiple areas, such as visual object recognition, genomics and speech recognition. Due to the distributed encodings of information, DNNs are hard to understand and interpret. To this end, visualizations have been used to understand how deep architecture work in general, what different layers of the network encode, what the limitations of the trained model was and how to interactively collect user feedback. In this chapter, we provide a survey of visualizations of DNNs in the field of computer vision. We define a classification scheme describing visualization goals and methods as well as the application areas. This survey gives an overview of what can be learned from visualizing DNNs and which visualization methods were used to gain which insights. We found that most papers use Pixel Displays to show neuron activations. However, recently more sophisticated visualizations like interactive node-link diagrams were proposed. The presented overview can serve as a guideline when applying visualizations while designing DNNs.},
author = {Seifert, Christin and Aamir, Aisha and Balagopalan, Aparna and Jain, Dhruv and Sharma, Abhinav and Grottel, Sebastian and Gumhold, Stefan},
booktitle = {Transparent Data Mining for Big and Small Data},
doi = {10.1007/978-3-319-54024-5_6},
editor = {Cerquitelli, Tania and Quercia, Daniele and Pasquale, Frank},
file = {:home/alederer/Documents/Literatur/Learning/Deep Learning/Visualizations of Deep Neural Networks in Computer Vision{\_} A Survey.pdf:pdf},
isbn = {978-3-319-54024-5},
pages = {123--144},
publisher = {Springer International Publishing},
title = {{Visualizations of Deep Neural Networks in Computer Vision: A Survey}},
year = {2017}
}
@article{Sharma2017,
author = {Sharma, Sanjib},
file = {:home/alederer/Documents/Literatur/Learning/Hidden Markov Models/Markov Chain Monte Carlo Methods for Bayesian Data Analysis in Astronomy.pdf:pdf},
journal = {Annual Review of Astronomy and Astrophysics},
pages = {213--259},
title = {{Markov Chain Monte Carlo Methods for Bayesian Data Analysis in Astronomy}},
volume = {55},
year = {2017}
}
@article{Shekhar2018,
author = {Shekhar, Shubhanshu and Javidi, Tara},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shekhar, Javidi - 2018 - Gaussian process bandits with adaptive discretization.pdf:pdf},
journal = {Electronic Journal of Statistics},
keywords = {Bayesian optimization,Gaussian processes,and phrases,bandits,bayesian optimiza-,gaussian processes},
pages = {3829--3874},
title = {{Gaussian Process Bandits with Adaptive Discretization}},
volume = {12},
year = {2018}
}
@article{Shen2013,
author = {Shen, Gang and Cao, Yu},
doi = {10.4028/www.scientific.net/AMM.433-435.1015},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shen, Cao - 2013 - A Gaussian Process Based Model Predictive Controller for Nonlinear Systems with Uncertain Input-Output Delay.pdf:pdf},
isbn = {978-3-03785-894-3},
issn = {1662-7482},
journal = {Applied Mechanics and Materials},
keywords = {abstract,based on gaussian,delay that follows a,external gaussian disturbances,gaussian process,gaussian process based mpc,in this paper,investigate the ability of,model predictive control,mpc,on handling the variable,predictive controller,process for nonlinear systems,uncertain delay,we,we propose a model,with uncertain delays and},
pages = {1015--1020},
title = {{A Gaussian Process Based Model Predictive Controller for Nonlinear Systems with Uncertain Input-Output Delay}},
url = {http://www.scientific.net/AMM.433-435.1015},
volume = {433-435},
year = {2013}
}
@inproceedings{Shen2006,
abstract = {The computation required for Gaussian process regression with n training examples in about O(n{\^{}}3) during training and O(n) for each prediction This makes Gaussian process regression too slow for large datasets. In this paper, we present a fast approximation method, based on kd-trees, that significantly reduces both the prediction and the training times of Gaussian process regression.},
author = {Shen, Yirong and Ng, Andrew Y. and Seeger, Matthias},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/alederer/Documents/Literatur/Learning/Local GP/Fast Gaussian Process Regression using KD-Trees.pdf:pdf},
title = {{Fast Gaussian process regression using KD-Trees}},
year = {2006}
}
@article{Shi2013,
abstract = {We consider a coefficient-based regularized regression in a data dependent hypothesis space. For a given set of samples, functions in this hypothesis space are defined to be linear combinations of basis functions generated by a kernel function and sample data. We do not need the kernel to be symmetric or positive semi-definite, which provides flexibility and adaptivity for the learning algorithm. Another advantage of this algorithm is that, it is computationally effective without any optimization processes. In this paper, we apply concentration techniques with ℓ2-empirical covering numbers to present an elaborate capacity dependent analysis for the algorithm, which yields shaper estimates in both confidence estimation and convergence rate. When the kernel is IC, under a very mild regularity condition on the regression function, the rate can be arbitrarily close to m-1. {\textcopyright} 2012 Elsevier Inc.},
author = {Shi, Lei},
doi = {10.1016/j.acha.2012.05.001},
file = {:home/alederer/Local/Literatur/Learning/learning theory/Learning Theory Estimates for Coefficient-based Reularized Regression.pdf:pdf},
issn = {10635203},
journal = {Applied and Computational Harmonic Analysis},
keywords = {Capacity dependent error bounds,Coefficient-based regularization,Data dependent hypothesis space,Learning theory,ℓ2-Empirical covering number},
number = {2},
pages = {252--265},
publisher = {Elsevier Inc.},
title = {{Learning Theory Estimates for Coefficient-based Regularized Regression}},
volume = {34},
year = {2013}
}
@article{Snelson2012,
abstract = {The sparse pseudo-input Gaussian process (SPGP) is a new approximation method for speeding up GP regression in the case of a large number of data points N. The approximation is controlled by the gradient optimization of a small set of M `pseudo-inputs', thereby reducing complexity from N{\^{}}3 to NM{\^{}}2. One limitation of the SPGP is that this optimization space becomes impractically big for high dimensional data sets. This paper addresses this limitation by performing automatic dimensionality reduction. A projection of the input space to a low dimensional space is learned in a supervised manner, alongside the pseudo-inputs, which now live in this reduced space. The paper also investigates the suitability of the SPGP for modeling data with input-dependent noise. A further extension of the model is made to make it even more powerful in this regard - we learn an uncertainty parameter for each pseudo-input. The combination of sparsity, reduced dimension, and input-dependent noise makes it possible to apply GPs to much larger and more complex data sets than was previously practical. We demonstrate the benefits of these methods on several synthetic and real world problems.},
archivePrefix = {arXiv},
arxivId = {1206.6873},
author = {Snelson, Edward and Ghahramani, Zoubin},
eprint = {1206.6873},
file = {:home/alederer/Local/Literatur/Parkinson/GP Modelling/Variable Noise and Dimensionality Reduction for Sparse Gaussian Processes.pdf:pdf},
title = {{Variable noise and dimensionality reduction for sparse Gaussian processes}},
url = {http://arxiv.org/abs/1206.6873},
year = {2012}
}
@inproceedings{Snelson2009,
abstract = {We present a new Gaussian process (GP) regression model whose co-variance is parameterized by the the locations of M pseudo-input points, which we learn by a gradient based optimization. We take M N , where N is the number of real data points, and hence obtain a sparse regression method which has O(M 2 N) training cost and O(M 2) prediction cost per test case. We also find hyperparameters of the covari-ance function in the same joint optimization. The method can be viewed as a Bayesian regression model with particular input dependent noise. The method turns out to be closely related to several other sparse GP approaches , and we discuss the relation in detail. We finally demonstrate its performance on some large data sets, and make a direct comparison to other sparse GP methods. We show that our method can match full GP performance with small M , i.e. very sparse solutions, and it significantly outperforms other approaches in this regime.},
author = {Snelson, Edward and Ghahramani, Zoubin},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/alederer/Local/Literatur/Learning/Sparse GP/Sparse Gaussian Processes using Pseudo-inputs.pdf:pdf},
pages = {1--24},
title = {{Sparse Gaussian Processes using Pseudo-inputs}},
year = {2009}
}
@article{Solin2014,
abstract = {This paper proposes a novel scheme for reduced-rank Gaussian process regression. The method is based on an approximate series expansion of the covariance function in terms of an eigenfunction expansion of the Laplace operator in a compact subset of {\$}\backslashmathbb{\{}R{\}}{\^{}}d{\$}. On this approximate eigenbasis the eigenvalues of the covariance function can be expressed as simple functions of the spectral density of the Gaussian process, which allows the GP inference to be solved under a computational cost scaling as {\$}\backslashmathcal{\{}O{\}}(nm{\^{}}2){\$} (initial) and {\$}\backslashmathcal{\{}O{\}}(m{\^{}}3){\$} (hyperparameter learning) with {\$}m{\$} basis functions and {\$}n{\$} data points. The approach also allows for rigorous error analysis with Hilbert space theory, and we show that the approximation becomes exact when the size of the compact subset and the number of eigenfunctions go to infinity. The expansion generalizes to Hilbert spaces with an inner product which is defined as an integral over a specified input density. The method is compared to previously proposed methods theoretically and through empirical tests with simulated and real data.},
archivePrefix = {arXiv},
arxivId = {1401.5508},
author = {Solin, Arno and S{\"{a}}rkk{\"{a}}, Simo},
eprint = {1401.5508},
file = {:home/alederer/Documents/Literatur/Learning/Sparse GP/Hilbert Space Methods for Reduced-Rank Gaussian Process Regression.pdf:pdf},
keywords = {eigenfunction expansion,gaussian process regression,laplace,operator,pseudo-differential,reduced-rank approximation},
title = {{Hilbert Space Methods for Reduced-Rank Gaussian Process Regression}},
url = {http://arxiv.org/abs/1401.5508},
year = {2014}
}
@inproceedings{Sollich1999,
abstract = {I consider the problem of calculating learning$\backslash$ncurves (i.e., average generalization performance)$\backslash$nof Gaussian processes used for regression. A simple$\backslash$nexpression for the generalization error in terms of$\backslash$nthe eigenvalue decomposition of the covariance$\backslash$nfunction is derived, and used as the starting point$\backslash$nfor several approximation schemes. I identify where$\backslash$nthese become exact, and compare with existing$\backslash$nbounds on learning curves; the new approximations,$\backslash$nwhich can be used for any input space dimension,$\backslash$ngenerally get substantially closer to the truth.},
author = {Sollich, Peter},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sollich - 1999 - Learning curves for Gaussian Processes.pdf:pdf},
isbn = {0262112450},
issn = {10495258},
pages = {344--350},
title = {{Learning Curves for Gaussian Processes}},
year = {1999}
}
@article{Sollich2002,
abstract = {We study the average case performance of multi-task Gaussian process (GP) regression as captured in the learning curve, i.e. the average Bayes error for a chosen task versus the total number of examples {\$}n{\$} for all tasks. For GP covariances that are the product of an input-dependent covariance function and a free-form inter-task covariance matrix, we show that accurate approximations for the learning curve can be obtained for an arbitrary number of tasks {\$}T{\$}. We use these to study the asymptotic learning behaviour for large {\$}n{\$}. Surprisingly, multi-task learning can be asymptotically essentially useless, in the sense that examples from other tasks help only when the degree of inter-task correlation, {\$}\backslashrho{\$}, is near its maximal value {\$}\backslashrho=1{\$}. This effect is most extreme for learning of smooth target functions as described by e.g. squared exponential kernels. We also demonstrate that when learning many tasks, the learning curves separate into an initial phase, where the Bayes error on each task is reduced down to a plateau value by "collective learning" even though most tasks have not seen examples, and a final decay that occurs once the number of examples is proportional to the number of tasks.},
author = {Sollich, Peter and Halees, Anason},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sollich, Halees - 2002 - Learning Curves for Gaussian Process Regression Approximations and Bounds.pdf:pdf},
journal = {Neural Computation},
pages = {1393--1428},
title = {{Learning Curves for Gaussian Process Regression: Approximations and Bounds}},
volume = {14},
year = {2002}
}
@article{Sollich2002,
abstract = {We study the average case performance of multi-task Gaussian process (GP) regression as captured in the learning curve, i.e. the average Bayes error for a chosen task versus the total number of examples {\{}{\$}{\}}n{\{}{\$}{\}} for all tasks. For GP covariances that are the product of an input-dependent covariance function and a free-form inter-task covariance matrix, we show that accurate approximations for the learning curve can be obtained for an arbitrary number of tasks {\{}{\$}{\}}T{\{}{\$}{\}}. We use these to study the asymptotic learning behaviour for large {\{}{\$}{\}}n{\{}{\$}{\}}. Surprisingly, multi-task learning can be asymptotically essentially useless, in the sense that examples from other tasks help only when the degree of inter-task correlation, {\{}{\$}{\}}\backslashbackslashrho{\{}\backslash{\$}{\}}, is near its maximal value {\{}{\$}{\}}\backslashbackslashrho=1{\{}{\$}{\}}. This effect is most extreme for learning of smooth target functions as described by e.g. squared exponential kernels. We also demonstrate that when learning many tasks, the learning curves separate into an initial phase, where the Bayes error on each task is reduced down to a plateau value by "collective learning" even though most tasks have not seen examples, and a final decay that occurs once the number of examples is proportional to the number of tasks.},
author = {Sollich, Peter and Halees, Anason},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ashton, Sollich - 2012 - Learning curves for multi-task Gaussian process regression.pdf:pdf},
journal = {Neural Computation},
pages = {1393--1428},
title = {{Learning Curves for Gaussian Process Regression: Approximations and Bounds}},
volume = {14},
year = {2002}
}
@inproceedings{Soloperto2017,
author = {Soloperto, Raffaele and M{\"{u}}ller, Matthias A. and Trimpe, Sebastian and Allg{\"{o}}wer, Frank},
booktitle = {6th IFAC Conference on Nonlinear Model Predictive Control},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Soloperto et al. - 2017 - Learning-Based Robust Model Predictive Control with State-Dependent Uncertainty.pdf:pdf},
keywords = {gaussian process,learning-based mpc,robust mpc,state-dependent uncertainty},
title = {{Learning-Based Robust Model Predictive Control with State-Dependent Uncertainty}},
year = {2017}
}
@article{Sontag1996,
abstract = {Location: Shelf Keywords: Input-to-State Stability, Nonlinear Systems,$\backslash$nBounded Input- Bounded Output Stability, Nonlinear Stability, Stability$\backslash$nConcepts Comments: We present new characterizations of th input-to-state$\backslash$nstability property. As a consequence of these results, we show the$\backslash$nequivalence between the ISS property and several (apparent) variations$\backslash$nproposed in the literature.},
author = {Sontag, Eduardo D. and Wang, Yuan},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sontag, Wang - 1996 - New characterizations of input-to-state stability.pdf:pdf},
journal = {IEEE Transactions on Automatic Control},
number = {9},
pages = {1283--1294},
title = {{New characterizations of input-to-state stability}},
volume = {41},
year = {1996}
}
@article{Srinivas2012,
abstract = {Many applications require optimizing an unknown, noisy function that is expensive to evaluate. We formalize this task as a multiarmed bandit problem, where the payoff function is either sampled from a Gaussian process (GP) or has low norm in a reproducing kernel Hilbert space. We resolve the important open problem of deriving regret bounds for this setting, which imply novel convergence rates for GP optimization. We analyze an intuitive Gaussian process upper confidence bound (GP-UCB) algorithm, and bound its cumulative regret in terms of maximal in- formation gain, establishing a novel connection between GP optimization and experimental design. Moreover, by bounding the latter in terms of operator spectra, we obtain explicit sublinear regret bounds for many commonly used covariance functions. In some important cases, our bounds have surprisingly weak dependence on the dimensionality. In our experiments on real sensor data, GP-UCB compares favorably with other heuristical GP optimization approaches.},
author = {Srinivas, Niranjan and Krause, Andreas and Kakade, Sham M. and Seeger, Matthias W.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Srinivas et al. - 2012 - Information-theoretic regret bounds for Gaussian process optimization in the bandit setting.pdf:pdf},
journal = {IEEE Transactions on Information Theory},
keywords = {Bandit problems,Bayesian prediction,Gaussian process (GP),experimental design,information gain,nonparametric statistics,online learning,regret bound,statistical learning},
number = {5},
pages = {3250--3265},
title = {{Information-Theoretic Regret Bounds for Gaussian Process Optimization in the Bandit Setting}},
volume = {58},
year = {2012}
}
@inproceedings{Srinivas2010,
abstract = {Many applications require optimizing an unknown, noisy function that is expensive to evaluate. We formalize this task as a multi-armed bandit problem, where the payoff function is either sampled from a Gaussian process (GP) or has low RKHS norm. We resolve the important open problem of deriving regret bounds for this setting, which imply novel convergence rates for GP optimization. We analyze GP-UCB, an intuitive upper-confidence based algorithm, and bound its cumulative regret in terms of maximal information gain, establishing a novel connection between GP optimization and experimental design. Moreover, by bounding the latter in terms of operator spectra, we obtain explicit sublinear regret bounds for many commonly used covariance functions. In some important cases, our bounds have surprisingly weak dependence on the dimensionality. In our experiments on real sensor data, GP-UCB compares favorably with other heuristical GP optimization approaches.},
author = {Srinivas, Niranjan and Krause, Andreas and Kakade, Sham and Seeger, Matthias},
booktitle = {Proceedings of the International Conference on Machine Learning},
file = {:home/alederer/Documents/Literatur/Reinforcement Learning/Bandit Problems/Gaussian Process Optimization in the Bandit Setting$\backslash$: No Regret and Experimental Design.pdf:pdf},
isbn = {9781605589077},
pages = {1015--1022},
title = {{Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design}},
year = {2010}
}
@article{Sriniwas1997,
abstract = {In nonlinear model predictive control algorithms, a nonlinear objective function is minimized on-line at every sampling time. Finding a global optimum is not very easy as the objective function is generally nonlinear and nonconvex. In this paper we show that the structure of the polynomial ARX models lends model predictive algorithms some useful properties that are helpful in determining the global optimum solution. The approach used is based on transformation and change of variables to recast the problem into a convex objective function with convex constraints. A method is then proposed that guarantees a global solution to the optimization problem.},
author = {Sriniwas, Ravi G. and Arkun, Yaman},
doi = {10.1016/S0098-1354(96)00279-7},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sriniwas, Arkun - 1997 - A global solution to the nonlinear model predictive control algorithms using polynomial ARX models.pdf:pdf},
issn = {00981354},
journal = {Computers {\&} Chemical Engineering},
number = {4},
pages = {431--439},
title = {{A global solution to the nonlinear model predictive control algorithms using polynomial ARX models}},
url = {http://www.sciencedirect.com/science/article/pii/S0098135496002797},
volume = {21},
year = {1997}
}
@book{Stein1999,
author = {Stein, Michael L.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stein - 1999 - Interpolation of Spatial Data Some Theory for Kriging.pdf:pdf},
isbn = {9781461271666},
publisher = {Springer Science {\&} Business Media},
title = {{Interpolation of Spatial Data: Some Theory for Kriging}},
year = {1999}
}
@article{Steinwart2001,
abstract = {In this article we study the generalization abilities of several classifiers of support vector machine (SVM) type using a certain class of kernels that we call universal. It is shown that the soft margin algorithms with universal kernels are consistent for a large class of classification problems including some kind of noisy tasks provided that the regularization parameter is chosen well. In particular we derive a simple sufficient condition for this parameter in the case of Gaussian RBF kernels. On the one hand our considerations are based on an investigation of an approximation property---the so-called universality---of the used kernels that ensures that all continuous functions can be approximated by certain kernel expressions. This approximation property also gives a new insight into the role of kernels in these and other algorithms. On the other hand the results are achieved by a precise study of the underlying optimization problems of the classifiers. Furthermore, we show consistency for the maximal margin classifier as well as for the soft margin SVM's in the presence of large margins. In this case it turns out that also constant regularization parameters ensure consistency for the soft margin SVM's. Finally we prove that even for simple, noise free classification problems SVM's with polynomial kernels can behave arbitrarily badly.},
author = {Steinwart, Ingo},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Steinwart - 2001 - On the Influence of the Kernel on the Consistency of Support Vector Machines.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {computational learning theory,kernel methods,pac model,pattern recognition,support,vector machines},
pages = {67--93},
title = {{On the Influence of the Kernel on the Consistency of Support Vector Machines}},
volume = {2},
year = {2001}
}
@article{Steinwart2006,
abstract = {Although Gaussian radial basis function (RBF) kernels are one of the most often used kernels in modern machine learning methods such as support vector machines (SVMs), little is known about the struc- ture of their reproducing kernel Hilbert spaces (RKHSs). In this work, two distinct explicit descriptions of the RKHSs corresponding to GaussianRBF kernels are given and some consequences are discussed. Furthermore, an orthonormal basis for these spaces is presented. Finally, it is discussed how the results can be used for analyzing the learning performance of SVMs.},
author = {Steinwart, Ingo and Hush, Don and Scovel, Clint},
doi = {10.1109/TIT.2006.881713},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Steinwart, Hush, Scovel - 2006 - An explicit description of the reproducing kernel hilbert spaces of gaussian rbf kernels.pdf:pdf},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
number = {10},
pages = {4635--4643},
title = {{An explicit description of the reproducing kernel hilbert spaces of gaussian rbf kernels}},
volume = {52},
year = {2006}
}
@article{Steinwart2012,
abstract = {Given a compact metric space X and a strictly positive Borel measure $\nu$ on X, Mercer's classical theorem states that the spectral decomposition of a positive self-adjoint integral operator T k :L 2($\nu$)→L 2($\nu$) of a continuous k yields a series representation of k in terms of the eigenvalues and -functions of T k . An immediate consequence of this representation is that k is a (reproducing) kernel and that its reproducing kernel Hilbert space can also be described by these eigenvalues and -functions. It is well known that Mercer's theorem has found important applications in various branches of mathematics, including probability theory and statistics. In particular, for some applications in the latter areas, however, it would be highly convenient to have a form of Mercer's theorem for more general spaces X and kernels k. Unfortunately, all extensions of Mercer's theorem in this direction either stick too closely to the original topological structure of X and k, or replace the absolute and uniform convergence by weaker notions of convergence that are not strong enough for many statistical applications. In this work, we fill this gap by establishing several Mercer type series representations for k that, on the one hand, make only very mild assumptions on X and k, and, on the other hand, provide convergence results that are strong enough for interesting applications in, e.g., statistical learning theory. To illustrate the latter, we first use these series representations to describe ranges of fractional powers of T k in terms of interpolation spaces and investigate under which conditions these interpolation spaces are contained in L ∞($\nu$). For these two results, we then discuss applications related to the analysis of so-called least squares support vector machines, which are a state-of-the-art learning algorithm. Besides these results, we further use the obtained Mercer representations to show that every self-adjoint nuclear operator L 2($\nu$)→L 2($\nu$) is an integral operator whose representing function k is the difference of two (reproducing) kernels.},
author = {Steinwart, Ingo and Scovel, Clint},
doi = {10.1007/s00365-012-9153-3},
file = {:home/alederer/Local/Literatur/Learning/learning theory/Mercers Theorem on General Domains{\_} On the Interaction between Measures, Kernels, and RKHSs.pdf:pdf},
issn = {01764276},
journal = {Constructive Approximation},
keywords = {Eigenvalues,Integral operators,Interpolation spaces,Reproducing Kernel Hilbert spaces,Statistical learning theory},
number = {3},
pages = {363--417},
title = {{Mercer's Theorem on General Domains: On the Interaction between Measures, Kernels, and RKHSs}},
volume = {35},
year = {2012}
}
@article{Stuart2018,
abstract = {We study the use of Gaussian process emulators to approximate the parameter-to-observation map or the negative log-likelihood in Bayesian inverse problems. We prove error bounds on the Hellinger distance between the true posterior distribution and various approximations based on the Gaussian process emulator. Our analysis includes approximations based on the mean of the predictive process, as well as approximations based on the full Gaussian process emulator. Our results show that the Hellinger distance between the true posterior and its approximations can be bounded by moments of the error in the emulator. Numerical results confirm our theoretical findings.},
author = {Stuart, Andrew M. and Teckentrup, Aretha L.},
file = {:home/alederer/Local/Literatur/Learning/learning theory/Posterior Consistency for Gaussian Process Approximations of Bayesian Posterior Distributions.pdf:pdf},
journal = {Mathematics of Computation},
keywords = {Bayesian approach,Gaussian process regression,Inverse problem,and phrases,bayesian approach,gaussian pro-,inverse problem,posterior consistency,surrogate model},
number = {310},
pages = {721--753},
title = {{Posterior Consistency for Gaussian Process Approximations of Bayesian Posterior Distributions}},
volume = {87},
year = {2018}
}
@article{Su2018,
author = {Su, Jie and Wu, Junfeng and Cheng, Peng and Chen, Jiming},
doi = {10.1109/TVT.2018.2819806},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Su et al. - 2018 - Autonomous Vehicle Control Through the Dynamics and Controller Learning.pdf:pdf},
issn = {00189545},
journal = {IEEE Transactions on Vehicular Technology},
keywords = {Autonomous vehicle,Bayesian optimization,Gaussian processes,controller tuning,time-varying cost},
number = {7},
pages = {5650--5657},
publisher = {IEEE},
title = {{Autonomous Vehicle Control Through the Dynamics and Controller Learning}},
volume = {67},
year = {2018}
}
@inproceedings{Sui2015,
abstract = {We consider sequential decision problems under uncertainty, where we seek to optimize an unknown function from noisy samples. This requires balancing exploration (learning about the objective) and exploitation (localizing the maximum), a problem well-studied in the multi-armed bandit literature. In many applications, however, we require that the sampled function values exceed some prespecified " safety " thresh-old, a requirement that existing algorithms fail to meet. Examples include medical applications where patient comfort must be guaranteed, recommender systems aiming to avoid user dissatisfaction, and robotic control, where one seeks to avoid controls causing physical harm to the platform. We tackle this novel, yet rich, set of problems under the assumption that the unknown function satisfies regularity conditions expressed via a Gaussian process prior. We develop an efficient algorithm called SAFEOPT, and theoretically guarantee its convergence to a natural notion of optimum reachable under safety constraints. We evaluate SAFEOPT on synthetic data, as well as two real applications: movie recommendation, and therapeutic spinal cord stimulation. Proceedings of the 32 nd International Conference on Machine Learning, Lille, France, 2015. JMLR: W{\&}CP volume 37. Copy-right 2015 by the author(s).},
author = {Sui, Yanan and Gotovos, Alkis and Burdick, Joel and Krause, Andreas},
booktitle = {Proceedings of The 32nd International Conference on Machine Learning},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sui et al. - 2015 - Safe Exploration for Optimization with Gaussian Processes.pdf:pdf},
pages = {997--1005},
title = {{Safe Exploration for Optimization with Gaussian Processes}},
year = {2015}
}
@inproceedings{Sui2018,
abstract = {Enforcing safety is a key aspect of many problems pertaining to sequential decision making under uncertainty, which require the decisions made at every step to be both informative of the optimal decision and also safe. For example, we value both efficacy and comfort in medical therapy, and efficiency and safety in robotic control. We consider this problem of optimizing an unknown utility function with absolute feedback or preference feedback subject to unknown safety constraints. We develop an efficient safe Bayesian optimization algorithm, StageOpt, that separates safe region expansion and utility function maximization into two distinct stages. Compared to existing approaches which interleave between expansion and optimization, we show that StageOpt is more efficient and naturally applicable to a broader class of problems. We provide theoretical guarantees for both the satisfaction of safety constraints as well as convergence to the optimal utility value. We evaluate StageOpt on both a variety of synthetic experiments, as well as in clinical practice. We demonstrate that StageOpt is more effective than existing safe optimization approaches, and is able to safely and effectively optimize spinal cord stimulation therapy in our clinical experiments.},
author = {Sui, Yanan and Zhuang, Vincent and Burdick, Joel W. and Yue, Yisong},
booktitle = {Proceedings of the International Conference on Machine Learning},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sui et al. - 2018 - Stagewise Safe Bayesian Optimization with Gaussian Processes.pdf:pdf},
title = {{Stagewise Safe Bayesian Optimization with Gaussian Processes}},
year = {2018}
}
@book{Sutton2017,
abstract = {Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability.The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning.},
archivePrefix = {arXiv},
arxivId = {1603.02199},
author = {Sutton, Richard S. and Barto, Andrew G.},
booktitle = {Trends in Cognitive Sciences},
doi = {10.1016/S1364-6613(99)01331-5},
edition = {second},
eprint = {1603.02199},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sutton, Barto - 2017 - Reinforcement Learning An Introduction.pdf:pdf},
isbn = {0262193981},
issn = {13646613},
pages = {360},
pmid = {18255791},
publisher = {The MIT Press},
title = {{Reinforcement Learning: An Introduction}},
year = {2017}
}
@inproceedings{Suzuki2012,
author = {Suzuki, Taiji},
booktitle = {Conference on Learning Theory},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Suzuki - 2012 - PAC-Bayesian Bound for Gaussian Process Regression and Multiple Kernel Additive Model.pdf:pdf},
keywords = {gaussian process,group lasso,multiple kernel learning,pac-bayes,sparse learn-},
pages = {1--20},
title = {{PAC-Bayesian Bound for Gaussian Process Regression and Multiple Kernel Additive Model}},
year = {2012}
}
@article{Talagrand1994,
author = {Talagrand, M.},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Talagrand - 1994 - Sharper Bounds for Gaussian and Empirical Processes.pdf:pdf},
journal = {The Annals of Probability},
number = {1},
pages = {28--76},
title = {{Sharper Bounds for Gaussian and Empirical Processes}},
volume = {22},
year = {1994}
}
@inproceedings{Talsma2014,
abstract = {A pilot project in 2012 for the Dutch regional water authority Noorderzijlvest has shown that the application of Model Predictive Control (MPC) can increase the safety level of the water system during flood events by an anticipatory pre-release of water. Furthermore, energy costs of pumps can be reduced by making tactical use of the water storage and shifting pump activities during normal operating conditions to off-peak hours. In this paper, the extension of the pilot to a real time decision support system is presented. It supports the daily operation of 34 aggregated structures both in wet and dry periods by providing optimal control settings through the application of MPC. We explain the improved prediction model that is accurate and fast enough for optimization purposes, and how it is integrated in the operational flood early warning system. Besides the prediction model, the weights of the individual objective function terms are an important element of MPC, since they shape the overall control objective. We developed special features in the forecasting system to permit the operators to adjust the objective function with respect to seasonal changes in order to evaluate different control strategies.},
author = {Talsma, Jan and Schwanenberg, Dirk and Gooijer, Jan and Van, Klaas-Jan and Bernhard, Heeringen and Becker, P J and Talsma, Jan ; and Schwanenberg, Dirk ; and Gooijer, Jan ; and {Van Heeringen}, Klaas-Jan and Becker, Bernhard P J and Becker, Bernhard},
booktitle = {11th International Conference on Hydroinformatics},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Talsma et al. - 2014 - Model Predictive Control For Real Time Operation Of Hydraulic Structures For Draining The Operational Area Of The.pdf:pdf},
title = {{Model Predictive Control For Real Time Operation Of Hydraulic Structures For Draining The Operational Area Of The Dutch Water Authority Noorderzijlvest}},
year = {2014}
}
@article{Theodorou2010,
abstract = {With the goal to generate more scalable algorithms with higher efficiency and fewer open parameters, reinforcement learning (RL) has recently moved towards combining classical techniques from optimal control and dynamic programming with modern learning techniques from statistical estimation theory. In this vein, this paper suggests to use the framework of stochastic optimal control with path integrals to derive a novel approach to RL with parameterized policies. While solidly grounded in value function estimation and optimal control based on the stochastic Hamilton-Jacobi-Bellman (HJB) equations, policy improvements can be transformed into an approximation problem of a path integral which has no open algorithmic parameters other than the exploration noise. The resulting algorithm can be conceived of as model-based, semi-model-based, or even model free, depending on how the learning problem is structured. The update equations have no danger of numerical instabilities as neither matrix inversions nor gradient learning rates are required. Our new algorithm demonstrates interesting similarities with previous RL research in the framework of probability matching and provides intuition why the slightly heuristically motivated probability matching approach can actually perform well. Empirical evaluations demonstrate significant performance improvements over gradient-based policy learning and scalability to high-dimensional control problems. Finally, a learning experiment on a simulated 12 degree-of-freedom robot dog illustrates the functionality of our algorithm in a complex robot learning scenario. We believe that Policy Improvement with Path Integrals (PI2) offers currently one of the most efficient, numerically robust, and easy to implement algorithms for RL based on trajectory roll-outs.},
author = {Theodorou, Evangelos and Buchli, Jonas and Schaal, Stefan},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Theodorou, Buchli, Schaal - 2010 - A Generalized Path Integral Control Approach to Reinforcement Learning.pdf:pdf},
isbn = {1532-4435},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {parameterized policies,reinforcement learning,stochastic optimal control},
pages = {3137----3181},
title = {{A Generalized Path Integral Control Approach to Reinforcement Learning}},
volume = {11},
year = {2010}
}
@article{Thomas2017,
abstract = {In this paper we consider the problem of evaluating one digi-tal marketing policy (or more generally, a policy for an MDP with unknown transition and reward functions) using data collected from the execution of a different policy. We call this problem off-policy policy evaluation. Existing methods for off-policy policy evaluation assume that the transition and reward functions of the MDP are stationary—an assumption that is typically false, particularly for digital marketing appli-cations. This means that existing off-policy policy evaluation methods are reactive to nonstationarity, in that they slowly correct for changes after they occur. We argue that off-policy policy evaluation for nonstationary MDPs can be phrased as a time series prediction problem, which results in predictive methods that can anticipate changes before they happen. We therefore propose a synthesis of existing off-policy policy evaluation methods with existing time series prediction meth-ods, which we show results in a drastic reduction of mean squared error when evaluating policies using real digital mar-keting data set.},
author = {Thomas, Philip S and Theocharous, Georgios and Ghavamzadeh, Mohammad and Durugkar, Ishan and Brunskill, Emma},
file = {:home/alederer/Documents/Literatur/Learning/Off-Policy Policy Evaluation/Predictive Off-Policy Policy Evaluation for Nonstationary Decision Problems, with Applications to Digital Marketing.pdf:pdf},
journal = {Proceedings of the 29th AAAI Conference on Innovative Applications},
keywords = {Emerging Application Case Studies},
pages = {4740--4745},
title = {{Predictive Off-Policy Policy Evaluation for Nonstationary Decision Problems, with Applications to Digital Marketing}},
year = {2017}
}
@article{Tian2009,
abstract = {This paper studies relationships between the best linear unbiased estimators (BLUEs) of an estimable parametric functions K$\beta$ under the Gauss-Markov model {\{}y, X$\beta$, $\sigma$2$\Sigma${\}} and its misspecified model {\{}y, X0$\beta$, $\sigma$2$\Sigma$0{\}}. In addition, relationships between BLUEs under a restricted Gauss-Markov model and its misspecified model are also investigated. {\textcopyright} The Editorial Office of AMS {\&} Springer-Verlag 2009.},
author = {Tian, Yong Ge},
file = {:home/alederer/Documents/Literatur/Learning/Misspecified Priors/On Equalities for BLUEs under Misspecified Gauss-Markov Models.pdf:pdf},
issn = {14398516},
journal = {Acta Mathematica Sinica, English Series},
keywords = {BLUE,Equality of estimations,Matrix rank method,Misspecified model,Original model,Restricted model},
number = {11},
pages = {1907--1920},
title = {{On equalities for BLUEs under misspecified Gauss-Markov models}},
volume = {25},
year = {2009}
}
@techreport{Titsias2009,
abstract = {Sparse Gaussian process methods that use inducing variables require the selection of the inducing inputs and the kernel hyperparameters. We introduce a variational formulation for sparse approxima- tions that jointly infers the inducing inputs and the kernel hyperparameters by maximizing a lower bound of the true log marginal likelihood. The key property of this formulation is that the inducing inputs are defined to be variational parameters which are selected by minimizing the Kullback-Leibler divergence between the variational distribution and the exact posterior distribution over the latent function values. We apply this technique to regression and we compare it with other approaches in the literature.},
author = {Titsias, Michalis K},
file = {:home/alederer/Documents/Literatur/Parkinson/GP Modelling/Variational Model Selection for Sparse Gaussian Process Regression.pdf:pdf},
institution = {University of Manchester},
pages = {1--20},
title = {{Variational Model Selection for Sparse Gaussian Process Regression}},
year = {2009}
}
@inproceedings{Titsias1998,
abstract = {The expression persistence and inheritance of the marker gene nptII were investigated in inbred transgenic tobacco (Nicotiana tabacum) plants. The inheritance of nptII in most examined plants corresponded to mono- and dihybrid segregation. Two successive self-pollinations of the plant T0-5 resulted in silencing of the marker gene with a frequency of 33.3{\%}. The silencing persisted in the subsequent self-pollinating generations. Reversions of the nptII gene expression were found in crosses between Km-sensitive transgenic tobacco plants (2 × 10-4) and in plants regenerated from explants of Km-sensitive genotypes (about 50{\%}).},
author = {Titsias, Michalis K.},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Statistics},
file = {:home/alederer/Documents/Literatur/Parkinson/GP Modelling/Variational Learning of Inducing Variables in Sparse Gaussian Processes.pdf:pdf},
issn = {10227954},
pages = {567--574},
title = {{Variational Learning of Inducing Variables in Sparse Gaussian Processes}},
year = {1998}
}
@inproceedings{Zhang2016,
abstract = {A sensitive photoelectrochemical (PEC) method for Hg 2+ detection is reported, based on the Hg 2+ -mediated structural switch of an oligonucleotide strand and biocatalytic precipitation (BCP) on a CdS quantum dot electrode. A sensitive photoelectrochemical (PEC) method for Hg 2+ detection is reported, based on the Hg 2+ -mediated structural switch of an oligonucleotide strand and biocatalytic precipitation (BCP) on a CdS quantum dot electrode. The principle is that, in the absence of Hg 2+ , the oligonucleotide strand forms a stem-loop, thus a G-rich sequence in the strand is partially caged in the stem-loop structure and cannot fold into a G-quadruplex. While in the presence of Hg 2+ , the T–Hg 2+ –T coordination leads to the formation of another stem-loop structure and allows the G-rich sequence to fold properly and bind hemin to form a stable G-quadruplex/hemin complex, which could accelerate oxidation of 4-chloro-1-naphthol (4-CN) by H 2 O 2 to yield the insoluble (BCP reaction) and insulating product benzo-4-chlorohexadienone on the photoelectrode, thereby efficiently causing the change in the photocurrent signal. This simple PEC sensor could detect aqueous Hg 2+ at concentrations as low as 4 nM with high selectivity.},
author = {Titsias, Michalis K. and Lawrence, Neil D.},
booktitle = {Proceedings of the International Conference on Artificial Intelligence and Statistics},
doi = {10.1039/c6ay02222g},
file = {:home/alederer/Local/Literatur/Parkinson/GP Modelling/Bayesian Gaussian Process Latent Variable Model.pdf:pdf},
issn = {17599679},
pages = {844--851},
title = {{Bayesian Gaussian Process Latent Variable Model}},
year = {2010}
}
@inproceedings{Tomanek2008,
abstract = {Active learning (AL) is getting more and more popular as a methodology to considerably reduce the annotation effort when building training material for statistical learning methods for various NLP tasks. A crucial issue rarely addressed, however, is when to actually stop the annotation process to profit from the savings in efforts. This question is tightly related to estimating the classifier performance after a certain amount of data has already been annotated. While learning curves are the default means to monitor the progress of the annotation process in terms of classifier performance, this requires a labeled gold standard which – in realistic annotation settings, at least – is often unavailable. We here propose a method for committee-based AL to approximate the progression of the learning curve based on the disagreement among the committee members. This method relies on a separate, unlabeled corpus and is thus well suited for situations where a labeled gold standard is not available or would be too expensive to obtain. Considering named entity recognition as a test case we provide empirical evidence that this approach works well under simulation as well as under real-world annotation conditions.},
author = {Tomanek, Katrin and Hahn, Udo},
booktitle = {Language Resources and Evaluation LRES},
file = {:home/alederer/Documents/Literatur/Learning/Active Learning/Approximating Learning Curves for Active-Learning-Driven Annotation.pdf:pdf},
isbn = {2951740840},
pages = {1319--1324},
title = {{Approximating Learning Curves for Active-Learning-Driven Annotation.}},
url = {http://repository.dlsi.ua.es/242/1/pdf/335{\_}paper.pdf},
year = {2008}
}
@article{Topcu2008,
abstract = {The problem of computing bounds on the region-of-attraction for systems with polynomial vector fields is considered. Invariant subsets of the region-of-attraction are characterized as sublevel sets of Lyapunov functions. Finite-dimensional polynomial parametrizations for Lyapunov functions are used. A methodology utilizing information from simulations to generate Lyapunov function candidates satisfying necessary conditions for bilinear constraints is proposed. The suitability of Lyapunov function candidates is assessed solving linear sum-of-squares optimization problems. Qualified candidates are used to compute invariant subsets of the region-of-attraction and to initialize various bilinear search strategies for further optimization. We illustrate the method on small examples from the literature and several control oriented systems. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Topcu, Ufuk and Packard, Andrew and Seiler, Peter},
doi = {10.1016/j.automatica.2008.03.010},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Topcu, Packard, Seiler - 2008 - Local stability analysis using simulations and sum-of-squares programming.pdf:pdf},
isbn = {0808912038},
issn = {00051098},
journal = {Automatica},
keywords = {Local stability,Nonlinear dynamics,Region-of-attraction,Simulations,Sum-of-squares programming},
number = {10},
pages = {2669--2675},
title = {{Local stability analysis using simulations and sum-of-squares programming}},
volume = {44},
year = {2008}
}
@article{Ueno2018,
abstract = {Spectroscopy is a widely used experimental technique, and enhancing its efficiency can have a strong impact on materials research. We propose an adaptive design for spectroscopy experiments that uses a machine learning technique to improve efficiency. We examined X-ray magnetic circular dichroism (XMCD) spectroscopy for the applicability of a machine learning technique to spectroscopy. An XMCD spectrum was predicted by Gaussian process modelling with learning of an experimental spectrum using a limited number of observed data points. Adaptive sampling of data points with maximum variance of the predicted spectrum successfully reduced the total data points for the evaluation of magnetic moments while providing the required accuracy. The present method reduces the time and cost for XMCD spectroscopy and has potential applicability to various spectroscopies.},
author = {Ueno, Tetsuro and Hino, Hideitsu and Hashimoto, Ai and Takeichi, Yasuo and Sawada, Masahiro and Ono, Kanta},
file = {:home/alederer/Local/Literatur/Learning/learning theory/Adaptive design of an X-ray magnetic circular dichroism spectroscopy experiment with Gaussian process modelling.pdf:pdf},
journal = {npj Computational Materials},
number = {1},
pages = {1--8},
publisher = {Springer US},
title = {{Adaptive Design of an X-ray Magnetic Circular Dichroism Spectroscopy Experiment with Gaussian Process Modeling}},
volume = {4},
year = {2018}
}
@article{Um2018,
abstract = {Parkinson's Disease (PD) is characterized by disorders in motor function such as freezing of gait, rest tremor, rigidity, and slowed and hyposcaled movements. Medication with dopaminergic medication may alleviate those motor symptoms, however, side-effects may include uncontrolled movements, known as dyskinesia. In this paper, an automatic PD motor-state assessment in free-living conditions is proposed using an accelerometer in a wrist-worn wearable sensor. In particular, an ensemble of convolutional neural networks (CNNs) is applied to capture the large variability of daily-living activities and overcome the dissimilarity between training and test patients due to the inter-patient variability. In addition, class activation map (CAM), a visualization technique for CNNs, is applied for providing an interpretation of the results.},
archivePrefix = {arXiv},
arxivId = {1808.02870},
author = {Um, Terry Taewoong and Pfister, Franz Michael Josef and Pichler, Daniel Christian and Endo, Satoshi and Lang, Muriel and Hirche, Sandra and Fietzek, Urban and Kuli{\'{c}}, Dana},
eprint = {1808.02870},
file = {:home/alederer/Local/Literatur/Parkinson/Parkinson Prediction/Um{\_}submitted{\_}ABME.pdf:pdf},
keywords = {canada,computer engineering,convolutional neural network,dana kuli{\'{c}},deep learning,department of electrical and,ensemble,on,parkinson,s disease,terry taewoong um and,university of waterloo,visualization,waterloo,wearable sensor},
title = {{Parkinson's Disease Assessment from a Wrist-Worn Wearable Sensor in Free-Living Conditions: Deep Ensemble Learning and Visualization}},
url = {http://arxiv.org/abs/1808.02870},
year = {2018}
}
@article{Um2017,
abstract = {While convolutional neural networks (CNNs) have been successfully applied to many challenging classification applications, they typically require large datasets for training. When the availability of labeled data is limited, data augmentation is a critical preprocessing step for CNNs. However, data augmentation for wearable sensor data has not been deeply investigated yet. In this paper, various data augmentation methods for wearable sensor data are proposed. The proposed methods and CNNs are applied to the classification of the motor state of Parkinson's Disease patients, which is challenging due to small dataset size, noisy labels, and large intra-class variability. Appropriate augmentation improves the classification performance from 77.54$\backslash${\%} to 86.88$\backslash${\%}.},
archivePrefix = {arXiv},
arxivId = {1706.00527},
author = {Um, Terry Taewoong and Pfister, Franz Michael Josef and Pichler, Daniel and Endo, Satoshi and Lang, Muriel and Hirche, Sandra and Fietzek, Urban and Kuli{\'{c}}, Dana},
doi = {10.1145/3136755.3136817},
eprint = {1706.00527},
file = {:home/alederer/Local/Literatur/Parkinson/Parkinson Prediction/Um{\_}2018{\_}ACM.pdf:pdf},
isbn = {9781450355438},
issn = {16130073},
keywords = {Data augmentation,Parkinson's disease,acm reference format,convolutional neural net-,convolutional neural networks,data augmentation,health monitoring,parkinson,s disease,wearable sensor,works},
pages = {216--220},
title = {{Data Augmentation of Wearable Sensor Data for Parkinson's Disease Monitoring using Convolutional Neural Networks}},
url = {http://arxiv.org/abs/1706.00527 http://dx.doi.org/10.1145/3136755.3136817},
year = {2017}
}
@article{Um,
author = {Um, Terry Taewoong and Pichler, Daniel and Goschenhofer, Jann and Lang, Muriel and Endo, Satoshi and Ceballos-, Andres O and Bischl, Bernd and Fietzek, Urban M},
file = {:home/alederer/Local/Literatur/Parkinson/Parkinson Prediction/Pfister{\_}2018{\_}ScientificReport.pdf:pdf},
title = {{High-Resolution Motor State Detection in Parkinson's Disease Using Convolutional Neural Networks}}
}
@inproceedings{Umlauft2018a,
author = {Umlauft, Jonas and Beckers, Thomas and Hirche, Sandra},
booktitle = {Proceedings of the European Control Conference},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Umlauft, Beckers, Hirche - 2018 - Scenario-based Optimal Control for Gaussian Process State Space Models.pdf:pdf},
title = {{Scenario-based Optimal Control for Gaussian Process State Space Models}},
year = {2018}
}
@inproceedings{Umlauft2017,
author = {Umlauft, Jonas and Beckers, Thomas and Kimmel, Melanie and Hirche, Sandra},
booktitle = {Proceedings of the IEEE Conference on Decision and Control},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Umlauft et al. - 2017 - Feedback Linearization using Gaussian Processes.pdf:pdf},
pages = {5249--5255},
title = {{Feedback Linearization using Gaussian Processes}},
year = {2017}
}
@inproceedings{Umlauft2017b,
abstract = {Programming by Demonstration allows to transfer skills from human demonstrators to robotic systems by observation and reproduction. One aspect that is often overlooked is that humans show different trajectories over multiple demonstrations for the same task. Observed movements may be more precise in some phases and more diverse in others. It is well-known that the variability of the execution carries important information about the task. Therefore, we propose a Bayesian approach to model uncertainties from training data and to infer them in regions with sparse information. The approach is validated in simulation, where it shows higher precision than existing methods, and a robotic experiment with variance based impedance adaptation.},
author = {Umlauft, Jonas and Fanger, Yunis and Hirche, Sandra},
booktitle = {Proceedings of the IEEE Conference on Robotics and Automation},
doi = {10.1109/ICRA.2017.7989759},
file = {:home/alederer/Documents/Literatur/Learning/Stable Systems/Bayesian Uncertainty Modeling for Programming by Demonstration.pdf:pdf},
isbn = {9781509046331},
issn = {10504729},
pages = {6428--6434},
title = {{Bayesian Uncertainty Modeling for Programming by Demonstration}},
year = {2017}
}
@inproceedings{Umlauft2017a,
abstract = {— Data-driven nonparametric models gain impor-tance as control systems are increasingly applied in domains where classical system identification is difficult, e.g., because of the system's complexity, sparse training data or its probabilistic nature. Gaussian process state space models (GP-SSM) are a data-driven approach which requires only high-level prior knowledge like smoothness characteristics. Prior known prop-erties like stability are also often available but rarely exploited during modeling. The enforcement of stability using control Lyapunov functions allows to incorporate this prior knowl-edge, but requires a data-driven Lyapunov function search. Therefore, we propose the use of Sum of Squares to enforce convergence of GP-SSMs and compare the performance to other approaches on a real-world handwriting motion dataset.},
author = {Umlauft, Jonas and Lederer, Armin and Hirche, Sandra},
booktitle = {Proceedings of the American Control Conference},
doi = {10.23919/ACC.2017.7963165},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Umlauft, Lederer, Hirche - 2017 - Learning stable Gaussian process state space models.pdf:pdf},
isbn = {9781509059928},
issn = {07431619},
keywords = {Identification for control,Learning,Stochastic systems},
pages = {1499--1504},
title = {{Learning Stable Gaussian Process State Space Models}},
year = {2017}
}
@article{Umlauft2018,
author = {Umlauft, Jonas and P{\"{o}}hler, Lukas and Hirche, Sandra},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Umlauft, P{\"{o}}hler, Hirche - 2018 - An Uncertainty-Based Control Lyapunov Approach for Control-Affine Systems Modeled by Gaussian Process.pdf:pdf},
journal = {IEEE Control Systems Letters},
number = {3},
pages = {483--488},
title = {{An Uncertainty-Based Control Lyapunov Approach for Control-Affine Systems Modeled by Gaussian Process}},
volume = {2},
year = {2018}
}
@article{Urry,
author = {Urry, Matthew J and Sollich, Peter},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Urry, Sollich - Unknown - Learning curves for Gaussian process regression on random graphs effects of graph structure.pdf:pdf},
pages = {1--8},
title = {{Learning curves for Gaussian process regression on random graphs: effects of graph structure}}
}
@article{Urry2013,
author = {Urry, Matthew J and Sollich, Peter},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Urry, Sollich - 2013 - Random Walk Kernels and Learning Curves for Gaussian Process Regression on Random Graphs.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {belief propaga-,cavity method,gaussian process,generalisation error,graph,learning curve,random walk kernel,tion},
pages = {1801--1835},
title = {{Random Walk Kernels and Learning Curves for Gaussian Process Regression on Random Graphs}},
volume = {14},
year = {2013}
}
@article{VanderVaart2011,
abstract = {We consider the quality of learning a response function by a nonparametric Bayesian approach using a Gaussian process (GP) prior on the response function. We upper bound the quadratic risk of the learning procedure, which in turn is an upper bound on the Kullback-Leibler information between the predictive and true data distribution. The upper bound is expressed in small ball probabilities and concentration measures of the GP prior. We illustrate the computation of the upper bound for the Mat{\'{e}}rn and squared exponential kernels. For these priors the risk, and hence the information criterion, tends to zero for all continuous response functions. However, the rate at which this happens depends on the combination of true response function and Gaussian prior, and is expressible in a certain concentration function. In particular, the results show that for good performance, the regularity of the GP prior should match the regularity of the unknown response function.},
author = {van der Vaart, Aad and van Zanten, Harry},
file = {:home/alederer/Local/Literatur/Learning/learning theory/Information Rates of Nonparametric Gaussian Process Methods.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {Bayesian learning,Gaussian prior,Mat{\'{e}}rn kernel,information rate,risk,squared exponential kernel},
pages = {2095--2119},
title = {{Information Rates of Nonparametric Gaussian Process Methods}},
volume = {12},
year = {2011}
}
@article{Vazquez2010,
archivePrefix = {arXiv},
arxivId = {arXiv:0712.3744v3},
author = {Vazquez, Emmanuel and Bect, Julien},
eprint = {arXiv:0712.3744v3},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vazquez, Bect - 2010 - Convergence properties of the expected improvement algorithm with fixed mean and covariance functions.pdf:pdf},
journal = {Journal of Statistical Planning and Inference},
keywords = {46e22,60g15,60g25,62k20,62m20,90c99,Global Optimization Gaussian process Expected Impr,bayesian optimization,computer experiments,gaussian process,global optimization,rkhs,sequential design},
number = {11},
pages = {3088--3095},
title = {{Convergence properties of the expected improvement algorithm with fixed mean and covariance functions}},
volume = {140},
year = {2010}
}
@article{Vazquez2014,
abstract = {Model-based predictive control (MPC) for power converters and drives is a control technique that has gained attention in the research community. The main reason for this is that although MPC presents high computational burden, it can easily handle multivariable case and system constraints and nonlinearities in a very intuitive way. Taking advantage of that, MPC has been successfully used for different applications such as an active front end (AFE), power converters connected to resistor inductor RL loads, uninterruptible power supplies, and high-performance drives for induction machines, among others. This article provides a review of the application of MPC in the power electronics area.},
author = {Vazquez, Sergio and Leon, Jose I. and Franquelo, Leopoldo G. and Rodriguez, Jose and Young, Hector A. and Marquez, Abraham and Zanchetta, Pericle},
doi = {10.1109/MIE.2013.2290138},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vazquez et al. - 2014 - Model predictive control A review of its applications in power electronics.pdf:pdf},
isbn = {1932-4529 VO - 8},
issn = {19324529},
journal = {IEEE Industrial Electronics Magazine},
number = {1},
pages = {16--31},
pmid = {20172797},
title = {{Model predictive control: A review of its applications in power electronics}},
volume = {8},
year = {2014}
}
@book{Vidyasagar1993,
abstract = {When M. Vidyasagar wrote the first edition of Nonlinear Systems Analysis, most control theorists considered the subject of nonlinear systems a mystery. Since then, advances in the application of differential geometric methods to nonlinear analysis have matured to a stage where every control theorist needs to possess knowledge of the basic techniques because virtually all physical systems are nonlinear in nature. The second edition, now republished in SIAM's Classics in Applied Mathematics series, provides a rigorous mathematical analysis of the behavior of nonlinear control systems under a variety of situations. It develops nonlinear generalizations of a large number of techniques and methods widely used in linear control theory. The book contains three extensive chapters devoted to the key topics of Lyapunov stability, input-output stability, and the treatment of differential geometric control theory. Audience: this text is designed for use at the graduate level in the area of nonlinear systems and as a resource for professional researchers and practitioners working in areas such as robotics, spacecraft control, motor control, and power systems.},
address = {Englewood Cliffs, NJ},
author = {Vidyasagar, M.},
edition = {second},
file = {:home/alederer/Documents/Literatur/Books/Nonlinear Systems Analysis.pdf:pdf},
publisher = {Prentice-Hall},
title = {{Nonlinear systems analysis}},
year = {1993}
}
@article{Villanueva2017,
abstract = {This paper is concerned with tube-based model predictive control (MPC) for both linear and nonlinear, input-affine continuous-time dynamic systems that are affected by time-varying disturbances. We derive a min–max differential inequality describing the support function of positive robust forward invariant tubes, which can be used to construct a variety of tube-based model predictive controllers. These constructions are conservative, but computationally tractable and their complexity scales linearly with the length of the prediction horizon. In contrast to many existing tube-based MPC implementations, the proposed framework does not involve discretizing the control policy and, therefore, the conservatism of the predicted tube depends solely on the accuracy of the set parameterization. The proposed approach is then used to construct a robust MPC scheme based on tubes with ellipsoidal cross-sections. This ellipsoidal MPC scheme is based on solving an optimal control problem under linear matrix inequality constraints. We illustrate these results with the numerical case study of a spring–mass–damper system.},
archivePrefix = {arXiv},
arxivId = {1611.03924},
author = {Villanueva, Mario E. and Quirynen, Rien and Diehl, Moritz and Chachuat, Beno{\^{i}}t and Houska, Boris},
doi = {10.1016/j.automatica.2016.11.022},
eprint = {1611.03924},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Villanueva et al. - 2017 - Robust MPC via min–max differential inequalities.pdf:pdf},
issn = {00051098},
journal = {Automatica},
keywords = {Differential inequalities,Model predictive control,Robust control,Robust forward invariant tube,Tube-based control},
pages = {311--321},
publisher = {Elsevier Ltd},
title = {{Robust MPC via min–max differential inequalities}},
url = {http://dx.doi.org/10.1016/j.automatica.2016.11.022},
volume = {77},
year = {2017}
}
@phdthesis{Vinogradska2017,
author = {Vinogradska, Julia},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vinogradska - 2017 - Gaussian Processes in Reinforcement Learning Stability Analysis and Efficient Value Propagation.pdf:pdf},
school = {Technische Universit{\"{a}}t Darmstadt},
title = {{Gaussian Processes in Reinforcement Learning: Stability Analysis and Efficient Value Propagation}},
year = {2017}
}
@article{Vinogradska2017a,
abstract = {Learning control has become an appealing alternative to the derivation of control laws based on classic control theory. However, a major shortcoming of learning control is the lack of performance guarantees which prevents its application in many real-world scenarios. As a step towards widespread deployment of learning control, we provide stability analysis tools for controllers acting on dynamics represented by Gaussian processes (GPs). We consider differentiable Markovian control policies and system dynamics given as (i) the mean of a GP, and (ii) the full GP distribution. For both cases, we analyze finite and infinite time horizons. Furthermore, we study the effect of disturbances on the stability results. Empirical evaluations on simulated benchmark problems support our theoretical results.},
author = {Vinogradska, Julia and Bischoff, Bastian and Nguyen-Tuong, Duy and Peters, Jan},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vinogradska et al. - 2017 - Stability of Controllers for Gaussian Process Dynamics.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {Control,Gaussian Process,Reinforcement Learning,Stability},
pages = {1--37},
title = {{Stability of Controllers for Gaussian Process Dynamics}},
volume = {18},
year = {2017}
}
@article{Vinogradska2016,
abstract = {Learning control has become an appealing alterna-tive to the derivation of control laws based on clas-sic control theory. However, a major shortcoming of learning control is the lack of performance guarantees which prevents its application in many real-world scenarios. As a step in this direction, we provide a stability analysis tool for controllers acting on dynamics represented by Gaussian pro-cesses (GPs). We consider arbitrary Markovian control policies and system dynamics given as (i) the mean of a GP, and (ii) the full GP distribu-tion. For the first case, our tool finds a state space region, where the closed-loop system is provably stable. In the second case, it is well known that infinite horizon stability guarantees cannot ex-ist. Instead, our tool analyzes finite time stability. Empirical evaluations on simulated benchmark problems support our theoretical results.},
author = {Vinogradska, Julia and Bischoff, Bastian and Nguyen-Tuong, Duy and Schmidt, Henner and Romer, Anne and Peters, Jan},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vinogradska et al. - 2016 - Stability of Controllers for Gaussian Process Forward Models.pdf:pdf},
isbn = {9781510829008},
journal = {International Conference on Machine Learning},
pages = {545--554},
title = {{Stability of Controllers for Gaussian Process Forward Models}},
url = {http://proceedings.mlr.press/v48/vinogradska16.pdf},
volume = {48},
year = {2016}
}
@phdthesis{Vivarelli1998,
author = {Vivarelli, Francesco},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vivarelli - 1998 - Studies on the Generalisation of Gaussian Processes and Bayesian Neural Networks.pdf:pdf},
school = {Aston University},
title = {{Studies on the Generalisation of Gaussian Processes and Bayesian Neural Networks}},
year = {1998}
}
@inproceedings{Wabersich2017,
abstract = {The control of complex systems faces a trade-off between high performance and safety guarantees, which in particular restricts the application of learning-based methods to safety-critical systems. A recently proposed framework to address this issue is the use of a safety controller, which guarantees to keep the system within a safe region of the state space. This paper introduces efficient techniques for the synthesis of a safe set and control law, which offer improved scalability properties by relying on approximations based on convex optimization problems. The first proposed method requires only an approximate linear system model and Lipschitz continuity of the unknown nonlinear dynamics. The second method extends the results by showing how a Gaussian process prior on the unknown system dynamics can be used in order to reduce conservatism of the resulting safe set. We demonstrate the results with numerical examples, including an autonomous convoy of vehicles.},
author = {Wabersich, Kim P. and Zeilinger, Melanie N.},
booktitle = {Proceedings of the European Control Conference},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wabersich, Zeilinger - 2018 - Scalable synthesis of safety certificates from data with application to learning-based control.pdf:pdf},
pages = {1691--1697},
title = {{Scalable Synthesis of Safety Certificates from data with Application to Learning-based Control}},
year = {2018}
}
@article{Wagberg2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1606.03865v3},
author = {W{\aa}gberg, Johan and Zachariah, Dave and Sch{\"{o}}n, Thomas B and Stoica, Petre},
eprint = {arXiv:1606.03865v3},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/W{\aa}gberg et al. - 2017 - Prediction performance after learning in Gaussian process regression.pdf:pdf},
pages = {1--14},
title = {{Prediction performance after learning in Gaussian process regression}},
year = {2017}
}
@article{Park2014,
abstract = {We introduce Gaussian process dynamical models (GPDM) for nonlinear time series analysis, with applications to learning models of human pose and motion from high-dimensionalmotion capture data. A GPDM is a latent variable model. It comprises a low-dimensional latent space with associated dynamics, and a map from the latent space to an observation space. We marginalize out the model parameters in closed-form, using Gaussian process priors for both the dynamics and the observation mappings. This results in a non-parametric model for dynamical systems that accounts for uncertainty in the model. We demonstrate the approach, and compare four learning algorithms on human motion capture data in which each pose is 50-dimensional. Despite the use of small data sets, the GPDM learns an effective representation of the nonlinear dynamics in these spaces.},
author = {Wang, Jack M. and Fleet, David J. and Hertzmann, Aaron},
doi = {10.1142/s0219843614410011},
file = {:home/alederer/Local/Literatur/Parkinson/GP Modelling/Gaussian Process Dynamical Models for Human Motion.pdf:pdf},
isbn = {978-1-4577-1102-2},
issn = {0219-8436},
journal = {Transactions on Pattern Analysis and Machine Intelligence},
number = {2},
pages = {283--298},
pmid = {18084059},
title = {{Gaussian Process Dynamical Models for Human Motion}},
volume = {30},
year = {2008}
}
@inproceedings{Wang2018a,
abstract = {To effectively control complex dynamical systems, accurate nonlinear models are typically needed. However, these models are not always known. In this paper, we present a data-driven approach based on Gaussian processes that learns models of quadrotors operating in partially unknown environments. What makes this challenging is that if the learning process is not carefully controlled, the system will go unstable, i.e., the quadcopter will crash. To this end, barrier certificates are employed for safe learning. The barrier certificates establish a non-conservative forward invariant safe region, in which high probability safety guarantees are provided based on the statistics of the Gaussian Process. A learning controller is designed to efficiently explore those uncertain states and expand the barrier certified safe region based on an adaptive sampling scheme. In addition, a recursive Gaussian Process prediction method is developed to learn the complex quadrotor dynamics in real-time. Simulation results are provided to demonstrate the effectiveness of the proposed approach.},
author = {Wang, Li and Theodorou, Evangelos A. and Egerstedt, Magnus},
booktitle = {Proceedings of the IEEE Conference on Robotics and Automation},
file = {:home/alederer/Documents/Literatur/Reinforcement Learning/Safe Learning of Quadrotot Dynamics Using Barrier Certificates.pdf:pdf},
pages = {2460--2465},
title = {{Safe Learning of Quadrotor Dynamics Using Barrier Certificates}},
year = {2018}
}
@article{Wang2015,
abstract = {This paper investigates the multirate networked industrial process control problem in double-layer architecture. First, the output tracking problem for sampled-data nonlinear plant at device layer with sampling period Td is investigated using adaptive neural network (NN) control, and it is shown that the outputs of subsystems at device layer can track the decomposed setpoints. Then, the outputs and inputs of the device layer subsystems are sampled with sampling period Tu at operation layer to form the index prediction, which is used to predict the overall performance index at lower frequency. Radial basis function NN is utilized as the prediction function due to its approximation ability. Then, considering the dynamics of the overall closed-loop system, nonlinear model predictive control method is proposed to guarantee the system stability and compensate the network-induced delays and packet dropouts. Finally, a continuous stirred tank reactor system is given in the simulation part to demonstrate the effectiveness of the proposed method.},
author = {Wang, Tong and Gao, Huijun and Qiu, Jianbin},
doi = {10.1109/TNNLS.2015.2411671},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Gao, Qiu - 2015 - A Combined Adaptive Neural Network and Nonlinear Model Predictive Control for Multirate Networked Industrial Pro.pdf:pdf},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
number = {2},
pages = {416--425},
pmid = {25898246},
title = {{A Combined Adaptive Neural Network and Nonlinear Model Predictive Control for Multirate Networked Industrial Process Control}},
volume = {27},
year = {2015}
}
@article{Wang2018,
abstract = {Scientists and engineers commonly use simulation models, or computer experiments, to study real systems for which actual experimentation is costly, difficult, or impossible. Many computer experiments are $\backslash$emph{\{}stochastic{\}} in the sense that repeated runs with the same input configuration will result in slightly or drastically different outputs. For expensive or time-consuming simulations, stochastic kriging $\backslash$citep{\{}ankenman{\}} is commonly used to generate predictions for simulation model outputs subject to uncertainty due to both function approximation and stochastic variation. Here, we decompose error in stochastic kriging predictions into nominal, numeric, parameter estimation and parameter estimation numeric components and provide means to control each in terms of properties of the underlying experimental design. The design properties implied for each source of error are weakly conflicting and several broad principles are proposed. In brief, the space-filling properties "small fill distance" and "large separation distance" should balance with replication at unique input configurations, with number of replications depending on the relative magnitudes of the stochastic and process variability. Non-stationarity implies higher input density in more active regions, while regression functions imply a balance with traditional design properties. A few examples are presented to illustrate the results.},
author = {Wang, Wenjia and Haaland, Benjamin},
file = {:home/alederer/Documents/Literatur/Learning/learning theory/Controlling Sources of Inaccuracy in Stochastic Kriging.pdf:pdf},
issn = {15372723},
journal = {Technometrics},
keywords = {Computer experiment,Emulation,Experimental design,Gaussian process,Stochastic kriging},
pages = {1--13},
title = {{Controlling Sources of Inaccuracy in Stochastic Kriging}},
year = {2018}
}
@article{Wang2019,
abstract = {Kriging based on Gaussian random fields is widely used in reconstructing unknown functions. The kriging method has pointwise predictive distributions which are computationally simple. However, in many applications one would like to predict for a range of untried points simultaneously. In this work we obtain some error bounds for the (simple) kriging predictor under the uniform metric. It works for a scattered set of input points in an arbitrary dimension, and also covers the case where the covariance function of the Gaussian process is misspecified. These results lead to a better understanding of the rate of convergence of kriging under the Gaussian or the Mat$\backslash$'ern correlation functions, the relationship between space-filling designs and kriging models, and the robustness of the Mat$\backslash$'ern correlation functions.},
author = {Wang, Wenjia and Tuo, Rui and Wu, C F Jeff},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Tuo, Wu - Unknown - On Prediction Properties of Kriging Uniform Error Bounds and Robustness.pdf:pdf},
journal = {Journal of the American Statistical Society},
keywords = {atlanta,basis functions,d,email,ga 30332,gaussian process modeling,in georgia institute of,ph,radial,space-filling designs,spatial statistics,technology,uniform convergence,usa,wenji-,wenjia wang is a},
pages = {1--38},
title = {{On Prediction Properties of Kriging: Uniform Error Bounds and Robustness}},
year = {2019}
}
@article{Wang2017,
abstract = {Kriging based on Gaussian random fields is widely used in reconstructing unknown functions. The kriging method has pointwise predictive distributions which are computationally simple. However, in many applications one would like to predict for a range of untried points simultaneously. In this work we obtain some error bounds for the (simple) kriging predictor under the uniform metric. It works for a scattered set of input points in an arbitrary dimension, and also covers the case where the covariance function of the Gaussian process is misspecified. These results lead to a better understanding of the rate of convergence of kriging under the Gaussian or the Mat$\backslash$'ern correlation functions, the relationship between space-filling designs and kriging models, and the robustness of the Mat$\backslash$'ern correlation functions.},
archivePrefix = {arXiv},
arxivId = {1710.06959},
author = {Wang, Wenjia and Tuo, Rui and Wu, C. F. Jeff},
eprint = {1710.06959},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Tuo, Wu - 2017 - Universal Convergence of Kriging.pdf:pdf},
keywords = {gaussian process modeling,radial,space-filling designs,uniform convergence},
pages = {1--25},
title = {{Universal Convergence of Kriging}},
url = {http://arxiv.org/abs/1710.06959},
year = {2017}
}
@inproceedings{Wang2015a,
author = {Wang, Ye and Ocampo-Martinez, Carlos and Puig, Vicen{\c{c}}},
booktitle = {Proceedings of the 2015 European Control Conference (ECC)},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Ocampo-Martinez, Puig - 2015 - Robust model predictive control based on Gaussian processes application to drinking water networks.pdf:pdf},
keywords = {Predictive control for linear systems,Stochastic systems},
pages = {3292--3297},
title = {{Robust model predictive control based on Gaussian processes: application to drinking water networks}},
year = {2015}
}
@book{Wendland2005,
author = {Wendland, Holger},
publisher = {Cambridge University Press},
title = {{Scattered Data Approximation}},
year = {2004}
}
@article{Williams2000,
abstract = {In this paper we introduce and illustrate non-trivial upper and lower bounds on the learning curves for one-dimensional Gaussian Processes. The analysis is carried out emphasising the effects induced on the bounds by the smoothness of the random process described by the Modified Bessel and the Squared Exponential covariance functions. We present an explanation of the early, linearly-decreasing behaviour of the learning curves and the bounds as well as a study of the asymptotic behaviour of the curves. The effects of the noise level and the lengthscale on the tightness of the bounds are also discussed.},
author = {Williams, Christopher K I and Vivarelli, F},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Williams, Vivarelli - 2000 - Upper and lower bounds on the learning curve for Gaussian processes.pdf:pdf},
journal = {Machine Learning},
keywords = {bayesian inference,bounds,gaussian processes,generalisation error},
pages = {77--102},
title = {{Upper and Lower Bounds on the Learning Curve for Gaussian Processes}},
volume = {40},
year = {2000}
}
@article{Wolff2004,
archivePrefix = {arXiv},
arxivId = {arXiv:hep-lat/0306017v4},
author = {Wolff, Ulli},
eprint = {0306017v4},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wolff - 2004 - Monte Carlo errors with less errors.pdf:pdf},
journal = {Computer Physics Communications},
pages = {143--153},
primaryClass = {arXiv:hep-lat},
title = {{Monte Carlo errors with less errors}},
volume = {156},
year = {2004}
}
@inproceedings{Wong2008,
abstract = {Model predictive controllers are often designed with integral action to impart robustness. For this, disturbance models are usually employed. It is customary to append integrated white-noises to either the input or output channels. However, neither by themselves may be adequate representations in the presence of switching disturbance patterns that are typically witnessed in process industries. In order to handle such scenarios, we first propose a differenced state-space formulation that can incorporate both input and output disturbances while retaining detectability. Then, we couple it with Hidden Markov Model (HMM) to express the switching characteristics of the disturbances. This bypasses the need to add artificial noises into state variables to consider both the input and output disturbances, as previously suggested. Simulation examples are provided to highlight closed-loop performance improvement as a result of the proposed formulation. Copyright {\textcopyright} 2007 International Federation of Automatic Control All Rights Reserved.},
author = {Wong, Wee Chin and Lee, Jay},
booktitle = {IFAC Proceedings Volumes},
file = {:home/alederer/Documents/Literatur/Learning/Hidden Markov Models/A Hidden Markov disturbance model for Offset-free linear model predictive control.pdf:pdf},
keywords = {Model predictive and optimization-based control,Nonlinear process control},
pages = {1940--1945},
title = {{A hidden Markov disturbance model for offset-free linear model predictive control}},
year = {2008}
}
@article{Wright1996,
abstract = {The connections between optimization and control theory have been explored by m a n y r e -searchers, and optimization algorithms have been applied with success to optimal control. The rapid pace of developments in model predictive c o n trol has given rise to a host of new problems to which optimization has yet to be applied. Concurrently, d e v elopments in optimization, and es-pecially in interior-point methods, have produced a new set of algorithms that may be especially helpful in this context. In this paper, we reexamine the relatively simple problem of control of linear processes subject to quadratic objectives and general linear constraints. We s h o w h o w n e w algorithms for quadratic programming can be applied eeciently to this problem. The approach extends to several more general problems in straightforward ways.},
author = {Wright, Stephen J},
doi = {10.1.1.55.5317},
file = {:home/alederer/Local/Literatur/Global Optimization/Global Optimization MPC/Applying new Optimization Algorithms to Model Predictive Control.pdf:pdf},
journal = {Proceedings of the international conference on chemical process control},
keywords = {interior point methods,model predictive control,optimization},
number = {1},
pages = {147--155},
title = {{Applying New Optimization Algorithms To Model Predictive Control}},
year = {1997}
}
@article{Wright1996,
abstract = {The connections between optimization and control theory have been explored by m a n y r e -searchers, and optimization algorithms have been applied with success to optimal control. The rapid pace of developments in model predictive c o n trol has given rise to a host of new problems to which optimization has yet to be applied. Concurrently, d e v elopments in optimization, and es-pecially in interior-point methods, have produced a new set of algorithms that may be especially helpful in this context. In this paper, we reexamine the relatively simple problem of control of linear processes subject to quadratic objectives and general linear constraints. We s h o w h o w n e w algorithms for quadratic programming can be applied eeciently to this problem. The approach extends to several more general problems in straightforward ways.},
author = {Wright, Stephen J},
doi = {10.1.1.55.5317},
file = {:home/alederer/Local/Literatur/Global Optimization/Global Optimization MPC/Applying new Optimization Algorithms to Model Predictive Control.pdf:pdf},
journal = {Proceedings of international conference chemical process control},
keywords = {interior point methods,model predictive control,optimization},
number = {1},
pages = {147--155},
title = {{Applying New Optimization Algorithms To Model Predictive Control}},
year = {1996}
}
@article{Wu1993,
abstract = {Introducing a suitable variational formulation for the local error of scattered data interpolation by radial basis functions phi(r), the error can be bounded by a term depending on the Fourier transform of the interpolated function f and a certain 'Kriging function', which allows a formulation as an integral involving the Fourier transform of phi. The explicit construction of locally well-behaving admissible coefficient vectors makes the Kriging function bounded by some power of the local density h of data points. This leads to error estimates for interpolation of functions f whose Fourier transform f is 'dominated' by the nonnegative Fourier transform psi of psi(x) = phi($\backslash$$\backslash$x$\backslash$$\backslash$) in the sense integral $\backslash$f$\backslash$2 psi-1 dt {\textless} infinity. Approximation orders are arbitrarily high for interpolation with Hardy multiquadrics, inverse multiquadrics and Gaussian kernels. This was also proven in recent papers by Madych and Nelson, using a reproducing kernel Hilbert space approach and requiring the same hypothesis as above on f, which limits the practical applicability of the results. This work uses a different and simpler analytic technique and allows to handle the cases of interpolation with phi(r) = r(s) for S is-an-element-of R, s {\textgreater} 1, s is-not-an-element-of 2N, and phi(r) = r(s) log r for S is-an-element-of 2N, which are shown to have accuracy O(h(s/2)).},
author = {Wu, Zong Min and Schaback, Robert},
doi = {10.1093/imanum/13.1.13},
file = {:home/alederer/Local/Literatur/Learning/learning theory/Local Error Estimates for Radial Basis Function Interpolation of Scattered Data.pdf:pdf},
issn = {02724979},
journal = {IMA Journal of Numerical Analysis},
keywords = {kriging,multiquadrics,multivariate interpolation,orders of convergence,thin},
number = {1},
pages = {13--27},
title = {{Local Error Estimates for Radial Basis Function Interpolation of Scattered Data}},
volume = {13},
year = {1993}
}
@article{Xu2011,
abstract = {In this paper, we consider mobile sensor networks that use spatiotemporal Gaussian processes to predict a wide range of spatiotemporal physical phenomena. Nonparametric Gaussian process regression that is based on truncated observations is proposed for mobile sensor networks with limited memory and computational power. We first provide a theoretical foundation of Gaussian process regression with truncated observations. In particular, we demonstrate that prediction using all observations can be well approximated by prediction using truncated observations under certain conditions. Inspired by the analysis, we then propose a centralized navigation strategy for mobile sensor networks to move in order to reduce prediction error variances at points of interest. For the case in which each agent has a limited communication range, we propose a distributed navigation strategy. Particularly, we demonstrate that mobile sensing agents with the distributed navigation strategy produce an emergent, swarming-like, collective behavior for communication connectivity and are coordinated to improve the quality of the collective prediction capability.},
author = {Xu, Yunfei and Choi, Jongeun and Oh, Songhwai},
doi = {10.1109/TRO.2011.2162766},
file = {:home/alederer/Local/Literatur/Learning/learning theory/Mobile Sensor Network Navigation Using Gaussian Processes with Truncated Observations.pdf:pdf},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {Distributed algorithms,Gaussian processes,mobile sensor networks},
number = {6},
pages = {1118--1131},
publisher = {IEEE},
title = {{Mobile Sensor Network Navigation using Gaussian Processes with Truncated Observations}},
volume = {27},
year = {2011}
}
@article{Yan2012,
abstract = {This paper presents new results on a neural network approach to nonlinear model predictive control. At first, a nonlinear system with unmodeled dynamics is decomposed by means of Jacobian linearization to an affine part and a higher-order unknown term. The unknown higher-order term resulted from the decomposition, together with the unmodeled dynamics of the original plant, are modeled by using a feedforward neural network via supervised learning. The optimization problem for nonlinear model predictive control is then formulated as a quadratic programming problem based on successive Jacobian linearization about varying operating points and iteratively solved by using a recurrent neural network called the simplified dual network. Simulation results are included to substantiate the effectiveness and illustrate the performance of the proposed approach.},
author = {Yan, Zheng and Wang, Jun},
doi = {10.1109/TII.2012.2205582},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yan, Wang - 2012 - Model Predictive Control of Nonlinear Systems With Unmodeled Dynamics Based on Feedforward and Recurrent Neural Netwo.pdf:pdf},
isbn = {1551-3203 VO - 8},
issn = {2162-237X},
journal = {IEEE Transactions on Industrial Informatics},
keywords = {Feedforward neural networks,Jacobian matrices,Optimization,Predictive control,Predictive models,Real-time systems,Recurrent neural networks,Supervisory control,affine part,dual network,feedforward neural nets,feedforward neural networks,higher-order unknown term,learning (artificial intelligence),linearisation techniques,model predictive control (MPC),neurocontrollers,nonlinear control systems,nonlinear model predictive control,nonlinear systems,optimization problem,predictive control,quadratic programming,quadratic programming problem,real-time optimization,recurrent neural nets,recurrent neural networks,successive Jacobian linearization,supervised learning,unmodeled dynamics},
number = {4},
pages = {746--756},
title = {{Model Predictive Control of Nonlinear Systems With Unmodeled Dynamics Based on Feedforward and Recurrent Neural Networks}},
volume = {8},
year = {2012}
}
@phdthesis{Yang2014,
author = {Yang, Xiaoke},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang - 2014 - Fault-Tolerant Predictive Control A Gaussian Process Model Based Approach.pdf:pdf},
school = {University of Cambridge},
title = {{Fault-Tolerant Predictive Control: A Gaussian Process Model Based Approach}},
year = {2014}
}
@article{Yang2015,
abstract = {This paper proposes the use of risk-sensitive costs in a model predictive controller (MPC) with Gaussian process (GP) models, for more effective online learning and control. Being a probabilistic model, a GP incorporates the uncertainty information due to imperfect knowledge of the system. The MPC then utilises this uncertainty information in a risk-sensitive, especially risk-seeking fashion, to balance the exploration of the unknown characteristics and the exploitative control actions simultaneously. Comparison of MPCs with the risk-seeking cost and the risk-neutral cost, i.e. the standard quadratic cost, on the swing-up control of a cart-pendulum system demonstrates that the risk-seeking cost exhibits an effective exploratory behaviour which leads to a better learning of the unknown system and in turn gives improved control performance.},
author = {Yang, Xiaoke and Maciejowski, Jan},
doi = {10.1016/j.ifacol.2015.12.156},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang, Maciejowski - 2015 - Risk-Sensitive Model Predictive Control with Gaussian Process Models.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Gaussian process model,adaptive control,learning control systems,model predictive control,risk-sensitive control},
number = {28},
pages = {374--379},
publisher = {Elsevier B.V.},
title = {{Risk-Sensitive Model Predictive Control with Gaussian Process Models}},
url = {http://dx.doi.org/10.1016/j.ifacol.2015.12.156},
volume = {48},
year = {2015}
}
@article{Yang2015a,
abstract = {Essential ingredients for fault-tolerant control are the ability to represent system behaviour following the occurrence of a fault, and the ability to exploit this representation for deciding control actions. Gaussian processes seem to be very promising candidates for the first of these, and model predictive control has a proven capability for the second. We therefore propose to use the two together to obtain fault-tolerant control functionality. Our proposal is illustrated by several reasonably realistic examples drawn from flight control.},
author = {Yang, Xiaoke and Maciejowski, Jan M.},
doi = {10.1515/amcs-2015-0010},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang, Maciejowski - 2015 - Fault tolerant control using Gaussian processes and model predictive control.pdf:pdf},
isbn = {9781479928552},
issn = {1641876X},
journal = {International Journal of Applied Mathematics and Computer Science},
keywords = {Gaussian process,aircraft control,fault-tolerant control,model predictive control,probabilistic modelling},
number = {1},
pages = {133--148},
title = {{Fault tolerant control using Gaussian processes and model predictive control}},
volume = {25},
year = {2015}
}
@article{Yang2017,
abstract = {{\textcopyright} 2016 IEEE. State estimation of nonlinear dynamic systems is an important problem in practice. This paper proposes a recursive state estimation method for nonlinear dynamic systems using Gaussian processes (GP) and pre-computed local linear models. Gaussian processes exhibit remarkable learning, or nonlinear regression capabilities from measurement data. The incorporation of pre-computed local linear models reduces the amount of data required and improves the regression performance of the GP. Based on such an improved GP model for nonlinear dynamic systems, a recursive Bayesian filtering method is implemented for the estimation of the unknown states of the system. Simulations on an aircraft benchmark model demonstrate that the proposed method is capable of estimating the unknown angle of attack of the aircraft, and the existence of the local linear models significantly improves the estimation performance of the filter. This method is especially useful in a control systems design context in which local linearisations of nonlinear dynamic systems are usually readily available.},
author = {Yang, Xiaoke and Peng, Bo and Zhou, Hang and Yang, Lingyu},
doi = {10.1109/CGNCC.2016.7829090},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2017 - State estimation for nonlinear dynamic systems using Gaussian processes and pre-computed local linear models.pdf:pdf},
isbn = {9781467383189},
journal = {CGNCC 2016 - 2016 IEEE Chinese Guidance, Navigation and Control Conference},
keywords = {Bayesian Filtering Method,Derivative Observation,Gaussian Process,Nonlinear Dynamic Systems,State Estimation},
pages = {1963--1968},
title = {{State estimation for nonlinear dynamic systems using Gaussian processes and pre-computed local linear models}},
year = {2017}
}
@inproceedings{Yesildirek1995,
abstract = {Due to their multiple rotation capabilities, robots are considered to be strongly nonlinear systems. In this chapter, we will look at designing nonlinear controllers in order to constrain the state vector of the robot to follow a fixed forward path or to remain within a determined area of its workspace. In contrast to the linear approach, which offers a general methodology but is limited to the neighborhood of a point of the state space, nonlinear approaches only apply to limited classes of systems, but they allow us to extend the effective operating range of the system. Indeed, there is no general method of globally stabilizing nonlinear systems. However, there is a multitude of methods that apply to particular cases. The aim of this chapter is to present one of the more representative theoretical methods (whereas in the following chapter, we will be looking at more pragmatic approaches). This method is called feedback linearization and it requires knowledge of an accurate and reliable state machine for our robot. The robots considered here are mechanical systems whose modeling can be found in. We will assume in this chapter that the state vector is entirely known. In practice, it has to be approximated from sensor measurements. We will see in Chapter 7 how such an approximation is performed.},
author = {Yesildirek, A. and Lewis, F.L.},
booktitle = {Proceedings of the IEEE Conference on Decision and Control},
doi = {10.4249/scholarpedia.6517},
file = {:home/alederer/Documents/Literatur/Learning for Control/Stabilizing/Feedback Linearization Using Neural Networks.pdf:pdf},
isbn = {078031901X},
pages = {2539--2544},
title = {{Feedback linearization Using Neural Networks}},
year = {1995}
}
@article{Yuan2018,
author = {Yuan, Guoqiang and Li, Yinghui},
doi = {10.1177/0142331217752799},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yuan, Li - 2018 - Estimation of the regions of attraction for autonomous nonlinear systems.pdf:pdf},
issn = {0142-3312},
journal = {Transactions of the Institute of Measurement and Control},
keywords = {hamilton,jacobi equations,nonlinear systems,regions of attraction,stability region,viscosity solution},
number = {1},
pages = {014233121775279},
title = {{Estimation of the regions of attraction for autonomous nonlinear systems}},
url = {http://journals.sagepub.com/doi/10.1177/0142331217752799},
volume = {41},
year = {2018}
}
@article{Zanette2018,
abstract = {In order to make good decision under uncertainty an agent must learn from observations. To do so, two of the most common frameworks are Contextual Bandits and Markov Decision Processes (MDPs). In this paper, we study whether there exist algorithms for the more general framework (MDP) which automatically provide the best performance bounds for the specific problem at hand without user intervention and without modifying the algorithm. In particular, it is found that a very minor variant of a recently proposed reinforcement learning algorithm for MDPs already matches the best possible regret bound {\$}\backslashtilde O (\backslashsqrt{\{}SAT{\}}){\$} in the dominant term if deployed on a tabular Contextual Bandit problem despite the agent being agnostic to such setting.},
author = {Zanette, Andrea and Brunskill, Emma},
file = {:home/alederer/Documents/Literatur/Learning/Reinforcement Learning Problems/Problem Dependent Reinforcement Learning Bounds Which Can Identify Bandit Structure in MDPs.pdf:pdf},
journal = {Proceedings of the 35th International Conference on Machine Learning},
pages = {5747--5755},
title = {{Problem Dependent Reinforcement Learning Bounds Which Can Identify Bandit Structure in {\{}MDP{\}}s}},
url = {http://proceedings.mlr.press/v80/zanette2018a.html},
volume = {80},
year = {2018}
}
@article{Zanette2019,
abstract = {Strong worst-case performance bounds for episodic reinforcement learning exist but fortunately in practice RL algorithms perform much better than such bounds would predict. Algorithms and theory that provide strong problem-dependent bounds could help illuminate the key features of what makes a RL problem hard and reduce the barrier to using RL algorithms in practice. As a step towards this we derive an algorithm for finite horizon discrete MDPs and associated analysis that both yields state-of-the art worst-case regret bounds in the dominant terms and yields substantially tighter bounds if the RL environment has small environmental norm, which is a function of the variance of the next-state value functions. An important benefit of our algorithmic is that it does not require apriori knowledge of a bound on the environmental norm. As a result of our analysis, we also help address an open learning theory question{\~{}}$\backslash$cite{\{}jiang2018open{\}} about episodic MDPs with a constant upper-bound on the sum of rewards, providing a regret bound with no {\$}H{\$}-dependence in the leading term that scales a polynomial function of the number of episodes.},
archivePrefix = {arXiv},
arxivId = {1901.00210},
author = {Zanette, Andrea and Brunskill, Emma},
eprint = {1901.00210},
file = {:home/alederer/Documents/Literatur/Learning/PAC Bounds for RL/Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Value Function Bounds.pdf:pdf},
title = {{Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Value Function Bounds}},
url = {http://arxiv.org/abs/1901.00210},
year = {2019}
}
@article{Zanon2019,
abstract = {Reinforcement Learning (RL) has demonstrated a huge potential in learning optimal policies without any prior knowledge of the process to be controlled. Model Predictive Control (MPC) is a popular control technique which is able to deal with nonlinear dynamics and state and input constraints. The main drawback of MPC is the need of identifying an accurate model, which in many cases cannot be easily obtained. Because of model inaccuracy, MPC can fail at delivering satisfactory closed-loop performance. Using RL to tune the MPC formulation or, conversely, using MPC as a function approximator in RL allows one to combine the advantages of the two techniques. This approach has important advantages, but it requires an adaptation of the existing algorithms. We therefore propose an improved RL algorithm for MPC and test it in simulations on a rather challenging example.},
archivePrefix = {arXiv},
arxivId = {1904.04614},
author = {Zanon, Mario and Gros, S{\'{e}}bastien and Bemporad, Alberto},
eprint = {1904.04614},
file = {:home/alederer/Documents/Literatur/Reinforcement Learning/Practical Reinforcement Learning of Stabilizing Economic MPC.pdf:pdf},
title = {{Practical Reinforcement Learning of Stabilizing Economic MPC}},
url = {http://arxiv.org/abs/1904.04614},
year = {2019}
}
@article{Zarghami2017,
abstract = {The contribution described in this paper is concentrated on the integration of exhaust gas recirculation (EGR) system into the process of combustion in an optimal manner. In practice, deriving a state-space model of this actuator is an energetic task as a result of involving some uncertain chemical reactions. To alleviate the effect of unobserved phenomena, which does not seem to be easy in modeling, an improved Gaussian Process (GP) is represented for identifying such dynamics. In this approach, practical modification in general formulation of GP is provided based on proportional feedback gain adjustment. Afterwards, the obtained model is considered for design of optimal model-based control strategy. The whole aim is focused on achieving a green economically gasoline engine by optimizing the trend of fuel consumption. Eventually, simulation results illustrate the effectiveness of proposed structure in EGR systems.},
author = {Zarghami, Mahdi and Hosseinnia, S. Hassan and Babazadeh, Mehrdad},
doi = {10.1016/j.ifacol.2017.08.476},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zarghami, Hosseinnia, Babazadeh - 2017 - Optimal Control of EGR System in Gasoline Engine Based on Gaussian Process.pdf:pdf},
issn = {24058963},
journal = {IFAC-PapersOnLine},
keywords = {Automotive engineering,Diesel engines,EGR valve,Fractional control,Gaussian Process},
number = {1},
pages = {3750--3755},
publisher = {Elsevier B.V.},
title = {{Optimal Control of EGR System in Gasoline Engine Based on Gaussian Process}},
url = {https://doi.org/10.1016/j.ifacol.2017.08.476},
volume = {50},
year = {2017}
}
@article{Zhai2019,
abstract = {This paper introduces a novel framework to construct the region of attraction (ROA) of a power system centered around a stable equilibrium by using stable state trajectories of system dynamics. Most existing works on estimating ROA rely on analytical Lyapunov functions, which are subject to two limitations: the analytic Lyapunov functions may not be always readily available, and the resulting ROA may be overly conservative. This work overcomes these two limitations by leveraging the converse Lyapunov theorem in control theory to eliminate the need of an analytic Lyapunov function and learning the unknown Lyapunov function with the Gaussian Process (GP) approach. In addition, a Gaussian Process Upper Confidence Bound (GP-UCB) based sampling algorithm is designed to reconcile the trade-off between the exploitation for enlarging the ROA and the exploration for reducing the uncertainty of sampling region. Within the constructed ROA, it is guaranteed in probability that the system state will converge to the stable equilibrium with a confidence level. Numerical simulations are also conducted to validate the assessment approach for the ROA of the single machine infinite bus system and the New England {\$}39{\$}-bus system. Numerical results demonstrate that our approach can significantly enlarge the estimated ROA compared to that of the analytic Lyapunov counterpart.},
archivePrefix = {arXiv},
arxivId = {1906.03590},
author = {Zhai, Chao and Nguyen, Hung D},
eprint = {1906.03590},
file = {:home/alederer/Documents/Literatur/Stabiliy Analysis/Region of Attraction for Power Systems using Gaussian Process and Converse Lyapunov Function - Part I{\_} Theoretical Framework and Off-line Study.pdf:pdf},
pages = {1--10},
title = {{Region of Attraction for Power Systems using Gaussian Process and Converse Lyapunov Function -- Part I: Theoretical Framework and Off-line Study}},
url = {http://arxiv.org/abs/1906.03590},
year = {2019}
}
@inproceedings{Zhan2016,
abstract = {Policy advice is a transfer learning method where a student agent is able to learn faster via advice from a teacher. However, both this and other reinforcement learning transfer methods have little theoretical analysis. This paper formally defines a setting where multiple teacher agents can provide advice to a student and introduces an algorithm to leverage both autonomous exploration and teacher's advice. Our regret bounds justify the intuition that good teachers help while bad teachers hurt. Using our formalization, we are also able to quantify, for the first time, when negative transfer can occur within such a reinforcement learning setting.},
archivePrefix = {arXiv},
arxivId = {1604.03986},
author = {Zhan, Yusen and Ammar, Haitham Bou and Taylor, Matthew E.},
booktitle = {IJCAI International Joint Conference on Artificial Intelligence},
doi = {10.1038/nature14236},
eprint = {1604.03986},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhan, Ammar, Taylor - 2016 - Theoretically-grounded policy advice from multiple teachers in reinforcement learning settings with applica.pdf:pdf},
isbn = {1476-4687 (Electronic) 0028-0836 (Linking)},
issn = {10450823},
pages = {2315--2321},
pmid = {25719670},
publisher = {Nature Publishing Group},
title = {{Theoretically-grounded policy advice from multiple teachers in reinforcement learning settings with applications to negative transfer}},
year = {2016}
}
@article{Zhang2005,
abstract = {Kernel methods can embed finite-dimensional data into infinite-dimensional feature spaces. In spite of the large underlying feature dimensionality, kernel methods can achieve good generalization ability. This observation is often wrongly interpreted, and it has been used to argue that kernel learning can magically avoid the "curse-of-dimensionality" phenomenon encountered in statistical estimation problems. This letter shows that although using kernel representation, one can embed data into an infinite-dimensional feature space; the effective dimensionality of this embedding, which determines the learning complexity of the underlying kernel machine, is usually small. In particular, we introduce an algebraic definition of a scale-sensitive effective dimension associated with a kernel representation. Based on this quantity, we derive upper bounds on the generalization performance of some kernel regression methods. Moreover, we show that the resulting convergent rates are optimal under various circumstances.},
author = {Zhang, Tong},
doi = {10.1162/0899766054323008},
file = {:home/alederer/Local/Literatur/Learning/learning theory/Learning Bounds for Kernel Regression Using Effective Data Dimensionality.pdf:pdf},
issn = {08997667},
journal = {Neural Computation},
number = {9},
pages = {2077--2098},
title = {{Learning Bounds for Kernel Regression using Effective Data Dimensionality}},
volume = {17},
year = {2005}
}
@inproceedings{Zhou2016,
author = {Zhou, Min and Guo, Zhao-Qin and Li, Xiang},
booktitle = {2016 IEEE 21st International Conference on Emerging Technologies and Factory Automation (ETFA)},
doi = {10.1109/ETFA.2016.7733737},
file = {:home/alederer/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou, Guo, Li - 2016 - Design of model predictive control for time-varying nonlinear system based on gaussian process regression modelin.pdf:pdf},
isbn = {978-1-5090-1314-2},
keywords = {cess models,gaussian pro-,model predictive control,online modeling,time-varying systems},
pages = {1--6},
title = {{Design of model predictive control for time-varying nonlinear system based on gaussian process regression modeling}},
url = {http://ieeexplore.ieee.org/document/7733737/},
year = {2016}
}
@article{Zimmer2018,
abstract = {Learning time-series models is useful for many applications, such as simulation and forecasting. In this study, we consider the problem of actively learning time-series models while taking given safety constraints into account. For time-series modeling we employ a Gaussian process with a nonlinear exogenous input structure. The proposed approach generates data appropriate for time series model learning, i.e. input and output trajectories, by dynamically exploring the input space. The approach parametrizes the input trajectory as consecutive trajectory sections, which are determined stepwise given safety requirements and past observations. We analyze the proposed algorithm and evaluate it empirically on a technical application. The results show the effectiveness of our approach in a realistic technical use case.},
author = {Zimmer, Christoph and Meister, Mona and Nguyen-Tuong, Duy},
file = {:home/alederer/Documents/Literatur/Learning/Active Learning/Safe Active Learning for Time-Series Modeling with Gaussian Processes.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {NeurIPS},
pages = {2730--2739},
title = {{Safe active learning for time-series modeling with Gaussian processes}},
volume = {2018-Decem},
year = {2018}
}
