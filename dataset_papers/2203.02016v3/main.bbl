\begin{thebibliography}{58}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agrawal et~al.(2019)Agrawal, Squires, Yang, Shanmugam, and
  Uhler]{agrawal2019abcd}
Raj Agrawal, Chandler Squires, Karren Yang, Karthikeyan Shanmugam, and Caroline
  Uhler.
\newblock Abcd-strategy: Budgeted experimental design for targeted causal
  structure discovery.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 3400--3409. PMLR, 2019.

\bibitem[Annadani et~al.(2021)Annadani, Rothfuss, Lacoste, Scherrer, Goyal,
  Bengio, and Bauer]{annadani2021variational}
Yashas Annadani, Jonas Rothfuss, Alexandre Lacoste, Nino Scherrer, Anirudh
  Goyal, Yoshua Bengio, and Stefan Bauer.
\newblock Variational causal networks: Approximate bayesian inference over
  causal structures.
\newblock \emph{arXiv preprint arXiv:2106.07635}, 2021.

\bibitem[Barab{\'a}si and Albert(1999)]{barabasi1999emergence}
Albert-L{\'a}szl{\'o} Barab{\'a}si and R{\'e}ka Albert.
\newblock Emergence of scaling in random networks.
\newblock \emph{science}, 286\penalty0 (5439):\penalty0 509--512, 1999.

\bibitem[Batagelj and Brandes(2005)]{batagelj2005efficient}
Vladimir Batagelj and Ulrik Brandes.
\newblock Efficient generation of large random networks.
\newblock \emph{Physical Review E}, 71\penalty0 (3):\penalty0 036113, 2005.

\bibitem[Bengio et~al.(2019)Bengio, Deleu, Rahaman, Ke, Lachapelle, Bilaniuk,
  Goyal, and Pal]{bengio2019meta}
Yoshua Bengio, Tristan Deleu, Nasim Rahaman, Rosemary Ke, S{\'e}bastien
  Lachapelle, Olexa Bilaniuk, Anirudh Goyal, and Christopher Pal.
\newblock A meta-transfer objective for learning to disentangle causal
  mechanisms.
\newblock \emph{arXiv preprint arXiv:1901.10912}, 2019.

\bibitem[Brouillard et~al.(2020)Brouillard, Lachapelle, Lacoste,
  Lacoste-Julien, and Drouin]{brouillard2020differentiable}
Philippe Brouillard, S{\'e}bastien Lachapelle, Alexandre Lacoste, Simon
  Lacoste-Julien, and Alexandre Drouin.
\newblock Differentiable causal discovery from interventional data.
\newblock \emph{arXiv preprint arXiv:2007.01754}, 2020.

\bibitem[Chaloner and Verdinelli(1995)]{chaloner1995bayesian}
Kathryn Chaloner and Isabella Verdinelli.
\newblock Bayesian experimental design: A review.
\newblock \emph{Statistical Science}, pages 273--304, 1995.

\bibitem[Cho et~al.(2016)Cho, Berger, and Peng]{cho2016reconstructing}
Hyunghoon Cho, Bonnie Berger, and Jian Peng.
\newblock Reconstructing causal biological networks through active learning.
\newblock \emph{PloS one}, 11\penalty0 (3):\penalty0 e0150611, 2016.

\bibitem[Cundy et~al.(2021)Cundy, Grover, and Ermon]{cundy2021bcd}
Chris Cundy, Aditya Grover, and Stefano Ermon.
\newblock Bcd nets: Scalable variational approaches for bayesian causal
  discovery.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Erd{\H{o}}s and R{\'e}nyi(1959)]{erdHos1959random}
P~Erd{\H{o}}s and A~R{\'e}nyi.
\newblock On random graphs i. publicationes mathematicae (debrecen).
\newblock 1959.

\bibitem[Foster et~al.(2019)Foster, Jankowiak, Bingham, Horsfall, Teh,
  Rainforth, and Goodman]{foster2019variational}
Adam Foster, Martin Jankowiak, Eli Bingham, Paul Horsfall, Yee~Whye Teh, Tom
  Rainforth, and Noah Goodman.
\newblock Variational bayesian optimal experimental design.
\newblock \emph{arXiv preprint arXiv:1903.05480}, 2019.

\bibitem[Foster et~al.(2020)Foster, Jankowiak, O’Meara, Teh, and
  Rainforth]{foster2020unified}
Adam Foster, Martin Jankowiak, Matthew O’Meara, Yee~Whye Teh, and Tom
  Rainforth.
\newblock A unified stochastic gradient approach to designing bayesian-optimal
  experiments.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 2959--2969. PMLR, 2020.

\bibitem[Foster et~al.(2021)Foster, Ivanova, Malik, and
  Rainforth]{foster2021deep}
Adam Foster, Desi~R Ivanova, Ilyas Malik, and Tom Rainforth.
\newblock Deep adaptive design: Amortizing sequential bayesian experimental
  design.
\newblock \emph{arXiv preprint arXiv:2103.02438}, 2021.

\bibitem[Friedman et~al.(2013)Friedman, Goldszmidt, and
  Wyner]{friedman2013data}
Nir Friedman, Moises Goldszmidt, and Abraham Wyner.
\newblock Data analysis with bayesian networks: A bootstrap approach.
\newblock \emph{arXiv preprint arXiv:1301.6695}, 2013.

\bibitem[Gamella and Heinze-Deml(2020)]{gamella2020active}
Juan~L Gamella and Christina Heinze-Deml.
\newblock Active invariant causal prediction: Experiment selection through
  stability.
\newblock \emph{arXiv preprint arXiv:2006.05690}, 2020.

\bibitem[Greenewald et~al.(2019)Greenewald, Katz, Shanmugam, Magliacane,
  Kocaoglu, Boix~Adsera, and Bresler]{greenewald2019sample}
Kristjan Greenewald, Dmitriy Katz, Karthikeyan Shanmugam, Sara Magliacane,
  Murat Kocaoglu, Enric Boix~Adsera, and Guy Bresler.
\newblock Sample efficient active learning of causal trees.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Greenfield et~al.(2010)Greenfield, Madar, Ostrer, and
  Bonneau]{greenfield2010dream4}
Alex Greenfield, Aviv Madar, Harry Ostrer, and Richard Bonneau.
\newblock Dream4: Combining genetic and dynamic information to identify
  biological networks and dynamical models.
\newblock \emph{PloS one}, 5\penalty0 (10):\penalty0 e13397, 2010.

\bibitem[He and Geng(2008)]{he2008active}
Yang-Bo He and Zhi Geng.
\newblock Active learning of causal networks with intervention experiments and
  optimal designs.
\newblock \emph{Journal of Machine Learning Research}, 9\penalty0
  (Nov):\penalty0 2523--2547, 2008.

\bibitem[Houlsby et~al.(2011)Houlsby, Husz{\'a}r, Ghahramani, and
  Lengyel]{houlsby2011bayesian}
Neil Houlsby, Ferenc Husz{\'a}r, Zoubin Ghahramani, and M{\'a}t{\'e} Lengyel.
\newblock Bayesian active learning for classification and preference learning.
\newblock \emph{arXiv preprint arXiv:1112.5745}, 2011.

\bibitem[Ivanova et~al.(2021)Ivanova, Foster, Kleinegesse, Gutmann, and
  Rainforth]{ivanova2021implicit}
Desi~R Ivanova, Adam Foster, Steven Kleinegesse, Michael~U Gutmann, and Thomas
  Rainforth.
\newblock Implicit deep adaptive design: policy-based experimental design
  without likelihoods.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 25785--25798, 2021.

\bibitem[Ke et~al.(2019)Ke, Bilaniuk, Goyal, Bauer, Larochelle, Sch{\"o}lkopf,
  Mozer, Pal, and Bengio]{ke2019learning}
Nan~Rosemary Ke, Olexa Bilaniuk, Anirudh Goyal, Stefan Bauer, Hugo Larochelle,
  Bernhard Sch{\"o}lkopf, Michael~C Mozer, Chris Pal, and Yoshua Bengio.
\newblock Learning neural causal models from unknown interventions.
\newblock \emph{arXiv preprint arXiv:1910.01075}, 2019.

\bibitem[Kirsch et~al.(2019)Kirsch, Van~Amersfoort, and
  Gal]{kirsch2019batchbald}
Andreas Kirsch, Joost Van~Amersfoort, and Yarin Gal.
\newblock Batchbald: Efficient and diverse batch acquisition for deep bayesian
  active learning.
\newblock \emph{Advances in neural information processing systems},
  32:\penalty0 7026--7037, 2019.

\bibitem[Kirsch et~al.(2021)Kirsch, Farquhar, and Gal]{kirsch2021simple}
Andreas Kirsch, Sebastian Farquhar, and Yarin Gal.
\newblock A simple baseline for batch active learning with stochastic
  acquisition functions.
\newblock \emph{arXiv preprint arXiv:2106.12059}, 2021.

\bibitem[Kleinegesse and Gutmann(2019)]{kleinegesse2019efficient}
Steven Kleinegesse and Michael~U Gutmann.
\newblock Efficient bayesian experimental design for implicit models.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 476--485. PMLR, 2019.

\bibitem[Kocaoglu et~al.(2017)Kocaoglu, Dimakis, and
  Vishwanath]{kocaoglu2017cost}
Murat Kocaoglu, Alex Dimakis, and Sriram Vishwanath.
\newblock Cost-optimal learning of causal graphs.
\newblock In \emph{International Conference on Machine Learning}, pages
  1875--1884. PMLR, 2017.

\bibitem[Krause and Guestrin(2012)]{krause2012near}
Andreas Krause and Carlos~E Guestrin.
\newblock Near-optimal nonmyopic value of information in graphical models.
\newblock \emph{arXiv preprint arXiv:1207.1394}, 2012.

\bibitem[Kushner(1964)]{kushner1964new}
Harold~J Kushner.
\newblock A new method of locating the maximum point of an arbitrary multipeak
  curve in the presence of noise.
\newblock 1964.

\bibitem[Lim et~al.(2022)Lim, Novoseller, Ichnowski, Huang, and
  Goldberg]{lim2022policy}
Vincent Lim, Ellen Novoseller, Jeffrey Ichnowski, Huang Huang, and Ken
  Goldberg.
\newblock Policy-based bayesian experimental design for non-differentiable
  implicit models.
\newblock \emph{arXiv preprint arXiv:2203.04272}, 2022.

\bibitem[Lindley(1956)]{lindley1956measure}
Dennis~V Lindley.
\newblock On a measure of the information provided by an experiment.
\newblock \emph{The Annals of Mathematical Statistics}, pages 986--1005, 1956.

\bibitem[Liu and Wang(2016)]{liu2016stein}
Qiang Liu and Dilin Wang.
\newblock Stein variational gradient descent: A general purpose bayesian
  inference algorithm.
\newblock \emph{arXiv preprint arXiv:1608.04471}, 2016.

\bibitem[Lorch et~al.(2021)Lorch, Rothfuss, Sch{\"o}lkopf, and
  Krause]{lorch2021dibs}
Lars Lorch, Jonas Rothfuss, Bernhard Sch{\"o}lkopf, and Andreas Krause.
\newblock Dibs: Differentiable bayesian structure learning.
\newblock \emph{arXiv preprint arXiv:2105.11839}, 2021.

\bibitem[Mena et~al.(2018)Mena, Belanger, Linderman, and
  Snoek]{mena2018learning}
Gonzalo Mena, David Belanger, Scott Linderman, and Jasper Snoek.
\newblock Learning latent permutations with gumbel-sinkhorn networks.
\newblock \emph{arXiv preprint arXiv:1802.08665}, 2018.

\bibitem[Mo{\v{c}}kus(1975)]{movckus1975bayesian}
Jonas Mo{\v{c}}kus.
\newblock On bayesian methods for seeking the extremum.
\newblock In \emph{Optimization techniques IFIP technical conference}, pages
  400--404. Springer, 1975.

\bibitem[Murphy(2001)]{murphy2001active}
Kevin~P Murphy.
\newblock Active learning of causal bayes net structure.
\newblock 2001.

\bibitem[Nemhauser et~al.(1978)Nemhauser, Wolsey, and
  Fisher]{nemhauser1978analysis}
George~L Nemhauser, Laurence~A Wolsey, and Marshall~L Fisher.
\newblock An analysis of approximations for maximizing submodular set
  functions—i.
\newblock \emph{Mathematical programming}, 14\penalty0 (1):\penalty0 265--294,
  1978.

\bibitem[Ness et~al.(2017)Ness, Sachs, Mallick, and Vitek]{ness2017bayesian}
Robert~Osazuwa Ness, Karen Sachs, Parag Mallick, and Olga Vitek.
\newblock A bayesian active learning experimental design for inferring
  signaling networks.
\newblock In \emph{International Conference on Research in Computational
  Molecular Biology}, pages 134--156. Springer, 2017.

\bibitem[Pearl(2009)]{pearl2009causality}
Judea Pearl.
\newblock \emph{Causality}.
\newblock Cambridge university press, 2009.

\bibitem[Peters and B{\"u}hlmann(2015)]{peters2015structural}
Jonas Peters and Peter B{\"u}hlmann.
\newblock Structural intervention distance for evaluating causal graphs.
\newblock \emph{Neural computation}, 27\penalty0 (3):\penalty0 771--799, 2015.

\bibitem[Peters et~al.(2012)Peters, Mooij, Janzing, and
  Sch{\"o}lkopf]{peters2012identifiability}
Jonas Peters, Joris Mooij, Dominik Janzing, and Bernhard Sch{\"o}lkopf.
\newblock Identifiability of causal graphs using functional models.
\newblock \emph{arXiv preprint arXiv:1202.3757}, 2012.

\bibitem[Peters et~al.(2016)Peters, B{\"u}hlmann, and
  Meinshausen]{peters2016causal}
Jonas Peters, Peter B{\"u}hlmann, and Nicolai Meinshausen.
\newblock Causal inference by using invariant prediction: identification and
  confidence intervals.
\newblock \emph{Journal of the Royal Statistical Society. Series B (Statistical
  Methodology)}, pages 947--1012, 2016.

\bibitem[Peters et~al.(2017)Peters, Janzing, and
  Sch{\"o}lkopf]{peters2017elements}
Jonas Peters, Dominik Janzing, and Bernhard Sch{\"o}lkopf.
\newblock \emph{Elements of causal inference: foundations and learning
  algorithms}.
\newblock The MIT Press, 2017.

\bibitem[Poole et~al.(2019)Poole, Ozair, Van Den~Oord, Alemi, and
  Tucker]{poole2019variational}
Ben Poole, Sherjil Ozair, Aaron Van Den~Oord, Alex Alemi, and George Tucker.
\newblock On variational bounds of mutual information.
\newblock In \emph{International Conference on Machine Learning}, pages
  5171--5180. PMLR, 2019.

\bibitem[Rainforth et~al.(2018)Rainforth, Cornish, Yang, Warrington, and
  Wood]{rainforth2018nesting}
Tom Rainforth, Rob Cornish, Hongseok Yang, Andrew Warrington, and Frank Wood.
\newblock On nesting monte carlo estimators.
\newblock In \emph{International Conference on Machine Learning}, pages
  4267--4276. PMLR, 2018.

\bibitem[Rasmussen(2003)]{rasmussen2003gaussian}
Carl~Edward Rasmussen.
\newblock Gaussian processes in machine learning.
\newblock In \emph{Summer school on machine learning}, pages 63--71. Springer,
  2003.

\bibitem[Sachs et~al.(2005)Sachs, Perez, Pe'er, Lauffenburger, and
  Nolan]{sachs2005causal}
Karen Sachs, Omar Perez, Dana Pe'er, Douglas~A Lauffenburger, and Garry~P
  Nolan.
\newblock Causal protein-signaling networks derived from multiparameter
  single-cell data.
\newblock \emph{Science}, 308\penalty0 (5721):\penalty0 523--529, 2005.

\bibitem[Schaffter et~al.(2011)Schaffter, Marbach, and
  Floreano]{schaffter2011genenetweaver}
Thomas Schaffter, Daniel Marbach, and Dario Floreano.
\newblock Genenetweaver: in silico benchmark generation and performance
  profiling of network inference methods.
\newblock \emph{Bioinformatics}, 27\penalty0 (16):\penalty0 2263--2270, 2011.

\bibitem[Scherrer et~al.(2021)Scherrer, Bilaniuk, Annadani, Goyal, Schwab,
  Sch{\"o}lkopf, Mozer, Bengio, Bauer, and Ke]{scherrer2021learning}
Nino Scherrer, Olexa Bilaniuk, Yashas Annadani, Anirudh Goyal, Patrick Schwab,
  Bernhard Sch{\"o}lkopf, Michael~C Mozer, Yoshua Bengio, Stefan Bauer, and
  Nan~Rosemary Ke.
\newblock Learning neural causal models with active interventions.
\newblock \emph{arXiv preprint arXiv:2109.02429}, 2021.

\bibitem[Schmidt et~al.(2007)Schmidt, Niculescu-Mizil, Murphy,
  et~al.]{schmidt2007learning}
Mark Schmidt, Alexandru Niculescu-Mizil, Kevin Murphy, et~al.
\newblock Learning graphical model structure using l1-regularization paths.
\newblock In \emph{AAAI}, volume~7, pages 1278--1283, 2007.

\bibitem[Shanmugam et~al.(2015)Shanmugam, Kocaoglu, Dimakis, and
  Vishwanath]{shanmugam2015learning}
Karthikeyan Shanmugam, Murat Kocaoglu, Alexandros~G Dimakis, and Sriram
  Vishwanath.
\newblock Learning causal graphs with small interventions.
\newblock \emph{Advances in Neural Information Processing Systems}, 28, 2015.

\bibitem[Squires et~al.(2020)Squires, Magliacane, Greenewald, Katz, Kocaoglu,
  and Shanmugam]{squires2020active}
Chandler Squires, Sara Magliacane, Kristjan Greenewald, Dmitriy Katz, Murat
  Kocaoglu, and Karthikeyan Shanmugam.
\newblock Active structure learning of causal dags via directed clique trees.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 21500--21511, 2020.

\bibitem[Srinivas et~al.(2010)Srinivas, Krause, Kakade, and
  Seeger]{srinivas2010gaussian}
Niranjan Srinivas, Andreas Krause, Sham Kakade, and Matthias~W Seeger.
\newblock Gaussian process optimization in the bandit setting: No regret and
  experimental design.
\newblock In \emph{ICML}, 2010.

\bibitem[Sussex et~al.(2021)Sussex, Krause, and Uhler]{sussex2021near}
Scott Sussex, Andreas Krause, and Caroline Uhler.
\newblock Near-optimal multi-perturbation experimental design for causal
  structure learning.
\newblock \emph{arXiv preprint arXiv:2105.14024}, 2021.

\bibitem[Thomas and Joy(2006)]{thomas2006elements}
MTCAJ Thomas and A~Thomas Joy.
\newblock \emph{Elements of information theory}.
\newblock Wiley-Interscience, 2006.

\bibitem[Tong and Koller(2001)]{tong2001active}
Simon Tong and Daphne Koller.
\newblock Active learning for structure in bayesian networks.
\newblock In \emph{International joint conference on artificial intelligence},
  volume~17, pages 863--869. Citeseer, 2001.

\bibitem[von K{\"u}gelgen et~al.(2019)von K{\"u}gelgen, Rubenstein,
  Sch{\"o}lkopf, and Weller]{von2019optimal}
Julius von K{\"u}gelgen, Paul~K Rubenstein, Bernhard Sch{\"o}lkopf, and Adrian
  Weller.
\newblock Optimal experimental design via bayesian optimization: active causal
  structure learning for gaussian process networks.
\newblock \emph{arXiv preprint arXiv:1910.03962}, 2019.

\bibitem[Zhang et~al.(2021)Zhang, Squires, and Uhler]{zhang2021matching}
Jiaqi Zhang, Chandler Squires, and Caroline Uhler.
\newblock Matching a desired causal state via shift interventions.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 19923--19934, 2021.

\bibitem[Zheng et~al.(2018)Zheng, Aragam, Ravikumar, and Xing]{zheng2018dags}
Xun Zheng, Bryon Aragam, Pradeep Ravikumar, and Eric~P Xing.
\newblock Dags with no tears: Continuous optimization for structure learning.
\newblock \emph{arXiv preprint arXiv:1803.01422}, 2018.

\bibitem[Zhilinskas(1975)]{zhilinskas1975single}
AG~Zhilinskas.
\newblock Single-step bayesian search method for an extremum of functions of a
  single variable.
\newblock \emph{Cybernetics}, 11\penalty0 (1):\penalty0 160--166, 1975.

\end{thebibliography}
