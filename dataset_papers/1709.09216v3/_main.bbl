\begin{thebibliography}{46}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahn et~al.(2012)Ahn, Korattikara, and Welling]{Ahn:2012}
S.~Ahn, A.~Korattikara, and M.~Welling.
\newblock {Bayesian} posterior sampling via stochastic gradient {Fisher}
  scoring.
\newblock In \emph{International Conference on Machine Learning}, 2012.

\bibitem[Alquier et~al.(2016)Alquier, Friel, Everitt, and Boland]{Alquier:2016}
P.~Alquier, N.~Friel, R.~Everitt, and A.~Boland.
\newblock {Noisy Monte Carlo: convergence of Markov chains with approximate
  transition kernels}.
\newblock \emph{Statistics and Computing}, 26:\penalty0 29--47, 2016.

\bibitem[Angelino et~al.(2016)Angelino, Johnson, and Adams]{Angelino:2016}
E.~Angelino, M.~J. Johnson, and R.~P. Adams.
\newblock Patterns of scalable {B}ayesian inference.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  9\penalty0 (2-3):\penalty0 119--247, 2016.

\bibitem[Bachem et~al.(2017)Bachem, Lucic, and Krause]{Bachem:2017}
O.~Bachem, M.~Lucic, and A.~Krause.
\newblock Practical coreset constructions for machine learning.
\newblock \emph{arXiv.org}, Mar. 2017.

\bibitem[Bardenet et~al.(2014)Bardenet, Doucet, and Holmes]{Bardenet:2014}
R.~Bardenet, A.~Doucet, and C.~C. Holmes.
\newblock {Towards scaling up Markov chain Monte Carlo: an adaptive subsampling
  approach}.
\newblock In \emph{International Conference on Machine Learning}, pages
  405--413, 2014.

\bibitem[Bardenet et~al.(2017)Bardenet, Doucet, and Holmes]{Bardenet:2015}
R.~Bardenet, A.~Doucet, and C.~C. Holmes.
\newblock {On Markov chain Monte Carlo methods for tall data}.
\newblock \emph{Journal of Machine Learning Research}, 18:\penalty0 1--43,
  2017.

\bibitem[Betancourt(2015)]{Betancourt:2015}
M.~J. Betancourt.
\newblock The fundamental incompatibility of {Hamiltonian Monte Carlo} and data
  subsampling.
\newblock In \emph{International Conference on Machine Learning}, 2015.

\bibitem[Bierkens et~al.(2016)Bierkens, Fearnhead, and Roberts]{Bierkens:2016a}
J.~Bierkens, P.~Fearnhead, and G.~O. Roberts.
\newblock The zig-zag process and super-efficient sampling for {Bayesian}
  analysis of big data.
\newblock \emph{arXiv.org}, July 2016.

\bibitem[Bouchard-C{\^o}t{\'e} et~al.(2016)Bouchard-C{\^o}t{\'e}, Vollmer, and
  Doucet]{BouchardCote:2016}
A.~Bouchard-C{\^o}t{\'e}, S.~J. Vollmer, and A.~Doucet.
\newblock The bouncy particle sampler: A non-reversible rejection-free {Markov}
  chain {Monte Carlo} method.
\newblock \emph{arXiv.org}, pages 1--37, Jan. 2016.

\bibitem[Boucheron et~al.(2013)Boucheron, Lugosi, and Massart]{Boucheron:2013}
S.~Boucheron, G.~Lugosi, and P.~Massart.
\newblock \emph{{Concentration Inequalities: A nonasymptotic theory of
  independence}}.
\newblock Oxford University Press, 2013.

\bibitem[Broderick et~al.(2013)Broderick, Boyd, Wibisono, Wilson, and
  Jordan]{Broderick:2013b}
T.~Broderick, N.~Boyd, A.~Wibisono, A.~C. Wilson, and M.~I. Jordan.
\newblock Streaming variational {Bayes}.
\newblock In \emph{Advances in Neural Information Processing Systems}, Dec.
  2013.

\bibitem[Campbell et~al.(2015)Campbell, Straub, Fisher, and How]{Campbell:2015}
T.~Campbell, J.~Straub, J.~W. Fisher, III, and J.~P. How.
\newblock Streaming, distributed variational inference for {Bayesian}
  nonparametrics.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2015.

\bibitem[Eberle(2015)]{Eberle:2015}
A.~Eberle.
\newblock {Reflection couplings and contraction rates for diffusions}.
\newblock \emph{Probability theory and related fields}, pages 1--36, Oct. 2015.

\bibitem[Entezari et~al.(2016)Entezari, Craiu, and Rosenthal]{Entezari:2016}
R.~Entezari, R.~V. Craiu, and J.~S. Rosenthal.
\newblock Likelihood inflating sampling algorithm.
\newblock \emph{arXiv.org}, May 2016.

\bibitem[Feldman et~al.(2011)Feldman, Faulkner, and Krause]{Feldman:2011b}
D.~Feldman, M.~Faulkner, and A.~Krause.
\newblock {Scalable training of mixture models via coresets}.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2142--2150, 2011.

\bibitem[Fithian and Hastie(2014)]{Fithian:2014}
W.~Fithian and T.~Hastie.
\newblock {Local case-control sampling: Efficient subsampling in imbalanced
  data sets}.
\newblock \emph{The Annals of Statistics}, 42\penalty0 (5):\penalty0
  1693--1724, Oct. 2014.

\bibitem[Gelman et~al.(2014)Gelman, Vehtari, Jyl{\"a}nki, Sivula, Tran, Sahai,
  Blomstedt, Cunningham, Schiminovich, and Robert]{Gelman:2014}
A.~Gelman, A.~Vehtari, P.~Jyl{\"a}nki, T.~Sivula, D.~Tran, S.~Sahai,
  P.~Blomstedt, J.~P. Cunningham, D.~Schiminovich, and C.~Robert.
\newblock {Expectation propagation as a way of life: A framework for Bayesian
  inference on partitioned data}.
\newblock \emph{arXiv.org}, Dec. 2014.

\bibitem[Gorham et~al.(2016)Gorham, Duncan, Vollmer, and Mackey]{Gorham:2016b}
J.~Gorham, A.~B. Duncan, S.~J. Vollmer, and L.~Mackey.
\newblock Measuring sample quality with diffusions.
\newblock \emph{arXiv.org}, Nov. 2016.

\bibitem[Han et~al.(2016)Han, Yang, and Zhang]{Han:2016}
L.~Han, T.~Yang, and T.~Zhang.
\newblock Local uncertainty sampling for large-scale multi-class logistic
  regression.
\newblock \emph{arXiv.org}, Apr. 2016.

\bibitem[Hasenclever et~al.(2017)Hasenclever, Webb, Lienart, Vollmer,
  Lakshminarayanan, Blundell, and Teh]{Teh:2015}
L.~Hasenclever, S.~Webb, T.~Lienart, S.~Vollmer, B.~Lakshminarayanan,
  C.~Blundell, and Y.~W. Teh.
\newblock Distributed {Bayesian} learning with stochastic natural-gradient
  expectation propagation and the posterior server.
\newblock \emph{Journal of Machine Learning Research}, 18:\penalty0 1--37,
  2017.

\bibitem[Hoffman et~al.(2013)Hoffman, Blei, Wang, and Paisley]{Hoffman:2013}
M.~D. Hoffman, D.~M. Blei, C.~Wang, and J.~Paisley.
\newblock {Stochastic variational inference}.
\newblock \emph{Journal of Machine Learning Research}, 14:\penalty0 1303--1347,
  2013.

\bibitem[Huggins and Zou(2017)]{Huggins:2017}
J.~H. Huggins and J.~Zou.
\newblock {Quantifying the accuracy of approximate diffusions and Markov
  chains}.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2017.

\bibitem[Huggins et~al.(2016)Huggins, Campbell, and Broderick]{Huggins:2016}
J.~H. Huggins, T.~Campbell, and T.~Broderick.
\newblock Coresets for scalable {Bayesian} logistic regression.
\newblock In \emph{Advances in Neural Information Processing Systems}, May
  2016.

\bibitem[Jaakkola and Jordan(1997)]{jaakkola1997variational}
T.~Jaakkola and M.~I. Jordan.
\newblock A variational approach to {B}ayesian logistic regression models and
  their extensions.
\newblock In \emph{Sixth International Workshop on Artificial Intelligence and
  Statistics}, volume~82, 1997.

\bibitem[Korattikara et~al.(2014)Korattikara, Chen, and
  Welling]{Korattikara:2014}
A.~Korattikara, Y.~Chen, and M.~Welling.
\newblock Austerity in {MCMC} land: {C}utting the {Metropolis-Hastings} budget.
\newblock In \emph{International Conference on Machine Learning}, 2014.

\bibitem[Kucukelbir et~al.(2015)Kucukelbir, Ranganath, Gelman, and
  Blei]{Kucukelbir:2015vs}
A.~Kucukelbir, R.~Ranganath, A.~Gelman, and D.~M. Blei.
\newblock Automatic variational inference in {Stan}.
\newblock In \emph{Advances in Neural Information Processing Systems}, June
  2015.

\bibitem[Li et~al.(2006)Li, Hastie, and Church]{Li:2006}
P.~Li, T.~J. Hastie, and K.~W. Church.
\newblock {Very sparse random projections}.
\newblock In \emph{SIGKDD Conference on Knowledge Discovery and Data Mining},
  2006.

\bibitem[Lucic et~al.(2017)Lucic, Faulkner, Krause, and Feldman]{Lucic:2017}
M.~Lucic, M.~Faulkner, A.~Krause, and D.~Feldman.
\newblock Training mixture models at scale via coresets.
\newblock \emph{arXiv.org}, Mar. 2017.

\bibitem[Maclaurin and Adams(2014)]{Maclaurin:2014}
D.~Maclaurin and R.~P. Adams.
\newblock Firefly {Monte Carlo}: {E}xact {MCMC} with subsets of data.
\newblock In \emph{Uncertainty in Artificial Intelligence}, Mar. 2014.

\bibitem[Mason and Handscomb(2003)]{Mason:2003}
J.~C. Mason and D.~C. Handscomb.
\newblock \emph{{Chebyshev Polynomials}}.
\newblock Chapman and Hall/CRC, New York, 2003.

\bibitem[Minka(2001)]{Minka:2001we}
T.~P. Minka.
\newblock Expectation propagation for approximate {Bayesian} inference.
\newblock In \emph{Uncertainty in Artificial Intelligence}. Morgan Kaufmann
  Publishers Inc, Aug. 2001.

\bibitem[Nishihara et~al.(2017)Nishihara, Moritz, Wang, Tumanov, Paul,
  Schleier-Smith, Liaw, Niknami, Jordan, and Stoica]{nishihara2017}
R.~Nishihara, P.~Moritz, S.~Wang, A.~Tumanov, W.~Paul, J.~Schleier-Smith,
  R.~Liaw, M.~Niknami, M.~I. Jordan, and I.~Stoica.
\newblock Real-time machine learning: The missing pieces.
\newblock In \emph{Workshop on Hot Topics in Operating Systems}, 2017.

\bibitem[Pakman et~al.(2017)Pakman, Gilboa, Carlson, and Paninski]{Pakman:2016}
A.~Pakman, D.~Gilboa, D.~Carlson, and L.~Paninski.
\newblock Stochastic bouncy particle sampler.
\newblock In \emph{International Conference on Machine Learning}, Sept. 2017.

\bibitem[Pillai and Smith(2014)]{Pillai:2014}
N.~S. Pillai and A.~Smith.
\newblock Ergodicity of approximate {MCMC} chains with applications to large
  data sets.
\newblock \emph{arXiv.org}, May 2014.

\bibitem[Pollock et~al.(2016)Pollock, Fearnhead, Johansen, and
  Roberts]{Pollock:2016}
M.~Pollock, P.~Fearnhead, A.~M. Johansen, and G.~O. Roberts.
\newblock The scalable {Langevin} exact algorithm: {Bayesian} inference for big
  data.
\newblock \emph{arXiv.org}, Sept. 2016.

\bibitem[Rabinovich et~al.(2015)Rabinovich, Angelino, and
  Jordan]{Rabinovich:2015}
M.~Rabinovich, E.~Angelino, and M.~I. Jordan.
\newblock {Variational consensus Monte Carlo}.
\newblock \emph{arXiv.org}, June 2015.

\bibitem[Rahimi and Recht(2009)]{Rahimi:2009tm}
A.~Rahimi and B.~Recht.
\newblock {Weighted sums of random kitchen sinks: Replacing minimization with
  randomization in learning}.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1313--1320, 2009.

\bibitem[Scott et~al.(2013)Scott, Blocker, Bonassi, Chipman, George, and
  McCulloch]{Scott:2013}
S.~L. Scott, A.~W. Blocker, F.~V. Bonassi, H.~A. Chipman, E.~I. George, and
  R.~E. McCulloch.
\newblock {Bayes and big data: The consensus Monte Carlo algorithm}.
\newblock In \emph{Bayes 250}, 2013.

\bibitem[Simon and Blume(1994)]{Simon:1994}
C.~Simon and L.~E. Blume.
\newblock \emph{{Mathematics for Economists}}.
\newblock W. W. Norton {\&} Company, 1994.

\bibitem[Srivastava et~al.(2015)Srivastava, Cevher, Tran-Dinh, and
  Dunson]{Srivastava:2015}
S.~Srivastava, V.~Cevher, Q.~Tran-Dinh, and D.~Dunson.
\newblock {WASP: Scalable Bayes via barycenters of subset posteriors}.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2015.

\bibitem[Stephanou et~al.(2017)Stephanou, Varughese, and
  Macdonald]{Stephanou:2017}
M.~Stephanou, M.~Varughese, and I.~Macdonald.
\newblock {Sequential quantiles via Hermite series density estimation}.
\newblock \emph{Electronic Journal of Statistics}, 11\penalty0 (1):\penalty0
  570--607, 2017.

\bibitem[Szeg{\"o}(1975)]{Szego:1975}
G.~Szeg{\"o}.
\newblock \emph{{Orthogonal Polynomials}}.
\newblock American Mathematical Society, 4th edition, 1975.

\bibitem[Teh et~al.(2016)Teh, Thiery, and Vollmer]{Teh:2016}
Y.~W. Teh, A.~H. Thiery, and S.~Vollmer.
\newblock {Consistency and fluctuations for stochastic gradient Langevin
  dynamics}.
\newblock \emph{Journal of Machine Learning Research}, 17\penalty0
  (7):\penalty0 1--33, Mar. 2016.

\bibitem[Tierney and Kadane(1986)]{tierney1986accurate}
L.~Tierney and J.~B. Kadane.
\newblock Accurate approximations for posterior moments and marginal densities.
\newblock \emph{Journal of the American Statistical Association}, 81\penalty0
  (393):\penalty0 82--86, 1986.

\bibitem[van~der Vaart(1998)]{vanderVaart:1998}
A.~W. van~der Vaart.
\newblock \emph{{Asymptotic Statistics}}.
\newblock University of Cambridge, 1998.

\bibitem[Welling and Teh(2011)]{Welling:2011}
M.~Welling and Y.~W. Teh.
\newblock Bayesian learning via stochastic gradient {Langevin} dynamics.
\newblock In \emph{International Conference on Machine Learning}, 2011.

\end{thebibliography}
