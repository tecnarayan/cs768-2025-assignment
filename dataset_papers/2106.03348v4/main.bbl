\begin{thebibliography}{100}\itemsep=-1pt

\bibitem{adelson1984pyramid}
E.~H. Adelson, C.~H. Anderson, J.~R. Bergen, P.~J. Burt, and J.~M. Ogden.
\newblock Pyramid methods in image processing.
\newblock {\em RCA engineer}, 29(6):33--41, 1984.

\bibitem{ba2016layer}
J.~L. Ba, J.~R. Kiros, and G.~E. Hinton.
\newblock Layer normalization.
\newblock {\em arXiv preprint arXiv:1607.06450}, 2016.

\bibitem{bay2006surf}
H.~Bay, T.~Tuytelaars, and L.~Van~Gool.
\newblock Surf: Speeded up robust features.
\newblock In {\em European conference on computer vision}, pages 404--417.
  Springer, 2006.

\bibitem{burt1987laplacian}
P.~J. Burt and E.~H. Adelson.
\newblock The laplacian pyramid as a compact image code.
\newblock In {\em Readings in computer vision}, pages 671--679. Elsevier, 1987.

\bibitem{cai2018cascade}
Z.~Cai and N.~Vasconcelos.
\newblock Cascade r-cnn: Delving into high quality object detection.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 6154--6162, 2018.

\bibitem{chen2021crossvit}
C.-F. Chen, Q.~Fan, and R.~Panda.
\newblock Crossvit: Cross-attention multi-scale vision transformer for image
  classification.
\newblock {\em arXiv preprint arXiv:2103.14899}, 2021.

\bibitem{chen2020pre}
H.~Chen, Y.~Wang, T.~Guo, C.~Xu, Y.~Deng, Z.~Liu, S.~Ma, C.~Xu, C.~Xu, and
  W.~Gao.
\newblock Pre-trained image processing transformer.
\newblock {\em arXiv preprint arXiv:2012.00364}, 2020.

\bibitem{chen2017rethinking}
L.-C. Chen, G.~Papandreou, F.~Schroff, and H.~Adam.
\newblock Rethinking atrous convolution for semantic image segmentation.
\newblock {\em arXiv preprint arXiv:1706.05587}, 2017.

\bibitem{chen2021empirical}
X.~Chen, S.~Xie, and K.~He.
\newblock An empirical study of training self-supervised vision transformers.
\newblock {\em arXiv preprint arXiv:2104.02057}, 2021.

\bibitem{chu2021twins}
X.~Chu, Z.~Tian, Y.~Wang, B.~Zhang, H.~Ren, X.~Wei, H.~Xia, and C.~Shen.
\newblock Twins: Revisiting spatial attention design in vision transformers.
\newblock {\em arXiv preprint arXiv:2104.13840}, 2021.

\bibitem{chu2021conditional}
X.~Chu, Z.~Tian, B.~Zhang, X.~Wang, X.~Wei, H.~Xia, and C.~Shen.
\newblock Conditional positional encodings for vision transformers.
\newblock {\em arXiv preprint arXiv:2102.10882}, 2021.

\bibitem{mmseg2020}
M.~Contributors.
\newblock {MMSegmentation}: Openmmlab semantic segmentation toolbox and
  benchmark.
\newblock \url{https://github.com/open-mmlab/mmsegmentation}, 2020.

\bibitem{mmpose2020}
M.~Contributors.
\newblock Openmmlab pose estimation toolbox and benchmark.
\newblock \url{https://github.com/open-mmlab/mmpose}, 2020.

\bibitem{dai2019transformer}
Z.~Dai, Z.~Yang, Y.~Yang, J.~Carbonell, Q.~V. Le, and R.~Salakhutdinov.
\newblock Transformer-xl: Attentive language models beyond a fixed-length
  context.
\newblock {\em arXiv preprint arXiv:1901.02860}, 2019.

\bibitem{d2021convit}
S.~d'Ascoli, H.~Touvron, M.~Leavitt, A.~Morcos, G.~Biroli, and L.~Sagun.
\newblock Convit: Improving vision transformers with soft convolutional
  inductive biases.
\newblock {\em arXiv preprint arXiv:2103.10697}, 2021.

\bibitem{demirel2010image}
H.~Demirel and G.~Anbarjafari.
\newblock Image resolution enhancement by using discrete and stationary wavelet
  decomposition.
\newblock {\em IEEE transactions on image processing}, 20(5):1458--1460, 2010.

\bibitem{devlin2018bert}
J.~Devlin, M.-W. Chang, K.~Lee, and K.~Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock {\em arXiv preprint arXiv:1810.04805}, 2018.

\bibitem{ding2021repmlp}
X.~Ding, X.~Zhang, J.~Han, and G.~Ding.
\newblock Repmlp: Re-parameterizing convolutions into fully-connected layers
  for image recognition.
\newblock {\em arXiv preprint arXiv:2105.01883}, 2021.

\bibitem{dosovitskiy2020image}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai,
  T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock {\em arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{el2021xcit}
A.~El-Nouby, H.~Touvron, M.~Caron, P.~Bojanowski, M.~Douze, A.~Joulin,
  I.~Laptev, N.~Neverova, G.~Synnaeve, J.~Verbeek, et~al.
\newblock Xcit: Cross-covariance image transformers.
\newblock {\em arXiv preprint arXiv:2106.09681}, 2021.

\bibitem{graham2021levit}
B.~Graham, A.~El-Nouby, H.~Touvron, P.~Stock, A.~Joulin, H.~J{\'e}gou, and
  M.~Douze.
\newblock Levit: a vision transformer in convnet's clothing for faster
  inference.
\newblock {\em arXiv preprint arXiv:2104.01136}, 2021.

\bibitem{guo2021beyond}
M.-H. Guo, Z.-N. Liu, T.-J. Mu, and S.-M. Hu.
\newblock Beyond self-attention: External attention using two linear layers for
  visual tasks.
\newblock {\em arXiv preprint arXiv:2105.02358}, 2021.

\bibitem{han2021transformer}
K.~Han, A.~Xiao, E.~Wu, J.~Guo, C.~Xu, and Y.~Wang.
\newblock Transformer in transformer.
\newblock {\em arXiv preprint arXiv:2103.00112}, 2021.

\bibitem{he2017mask}
K.~He, G.~Gkioxari, P.~Doll{\'a}r, and R.~Girshick.
\newblock Mask r-cnn.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 2961--2969, 2017.

\bibitem{he2015spatial}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Spatial pyramid pooling in deep convolutional networks for visual
  recognition.
\newblock {\em IEEE transactions on pattern analysis and machine intelligence},
  37(9):1904--1916, 2015.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem{he2021gauge}
L.~He, Y.~Dong, Y.~Wang, D.~Tao, and Z.~Lin.
\newblock Gauge equivariant transformer.
\newblock In {\em Thirty-Fifth Conference on Neural Information Processing
  Systems}, 2021.

\bibitem{heo2021pit}
B.~Heo, S.~Yun, D.~Han, S.~Chun, J.~Choe, and S.~J. Oh.
\newblock Rethinking spatial dimensions of vision transformers.
\newblock In {\em International Conference on Computer Vision (ICCV)}, 2021.

\bibitem{heo2021rethinking}
B.~Heo, S.~Yun, D.~Han, S.~Chun, J.~Choe, and S.~J. Oh.
\newblock Rethinking spatial dimensions of vision transformers.
\newblock {\em arXiv preprint arXiv:2103.16302}, 2021.

\bibitem{hinton2015distilling}
G.~Hinton, O.~Vinyals, and J.~Dean.
\newblock Distilling the knowledge in a neural network.
\newblock In {\em NIPS Deep Learning and Representation Learning Workshop},
  2015.

\bibitem{howard2017mobilenets}
A.~G. Howard, M.~Zhu, B.~Chen, D.~Kalenichenko, W.~Wang, T.~Weyand,
  M.~Andreetto, and H.~Adam.
\newblock Mobilenets: Efficient convolutional neural networks for mobile vision
  applications.
\newblock {\em arXiv preprint arXiv:1704.04861}, 2017.

\bibitem{huang2017densely}
G.~Huang, Z.~Liu, L.~Van Der~Maaten, and K.~Q. Weinberger.
\newblock Densely connected convolutional networks.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 4700--4708, 2017.

\bibitem{huang2021shuffle}
Z.~Huang, Y.~Ben, G.~Luo, P.~Cheng, G.~Yu, and B.~Fu.
\newblock Shuffle transformer: Rethinking spatial shuffle for vision
  transformer.
\newblock {\em arXiv preprint arXiv:2106.03650}, 2021.

\bibitem{ioffe2015batch}
S.~Ioffe and C.~Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In {\em International conference on machine learning}, pages
  448--456. PMLR, 2015.

\bibitem{ke2004pca}
Y.~Ke and R.~Sukthankar.
\newblock Pca-sift: A more distinctive representation for local image
  descriptors.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, volume~2, pages II--II. IEEE, 2004.

\bibitem{KrauseStarkDengFei-Fei_3DRR2013}
J.~Krause, M.~Stark, J.~Deng, and L.~Fei-Fei.
\newblock 3d object representations for fine-grained categorization.
\newblock In {\em 4th International IEEE Workshop on 3D Representation and
  Recognition (3dRR-13)}, Sydney, Australia, 2013.

\bibitem{krizhevsky2009learning}
A.~Krizhevsky, G.~Hinton, et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem{krizhevsky2012imagenet}
A.~Krizhevsky, I.~Sutskever, and G.~E. Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock {\em Advances in neural information processing systems},
  25:1097--1105, 2012.

\bibitem{lai2017deep}
W.-S. Lai, J.-B. Huang, N.~Ahuja, and M.-H. Yang.
\newblock Deep laplacian pyramid networks for fast and accurate
  super-resolution.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 624--632, 2017.

\bibitem{lan2019albert}
Z.~Lan, M.~Chen, S.~Goodman, K.~Gimpel, P.~Sharma, and R.~Soricut.
\newblock Albert: A lite bert for self-supervised learning of language
  representations.
\newblock {\em arXiv preprint arXiv:1909.11942}, 2019.

\bibitem{lecun1995convolutional}
Y.~LeCun, Y.~Bengio, et~al.
\newblock Convolutional networks for images, speech, and time series.
\newblock {\em The handbook of brain theory and neural networks},
  3361(10):1995, 1995.

\bibitem{lecun2015deep}
Y.~LeCun, Y.~Bengio, and G.~Hinton.
\newblock Deep learning.
\newblock {\em nature}, 521(7553):436--444, 2015.

\bibitem{li2021localvit}
Y.~Li, K.~Zhang, J.~Cao, R.~Timofte, and L.~Van~Gool.
\newblock Localvit: Bringing locality to vision transformers.
\newblock {\em arXiv preprint arXiv:2104.05707}, 2021.

\bibitem{lin2016efficient}
G.~Lin, C.~Shen, A.~Van Den~Hengel, and I.~Reid.
\newblock Efficient piecewise training of deep structured models for semantic
  segmentation.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 3194--3203, 2016.

\bibitem{lin2017feature}
T.-Y. Lin, P.~Doll{\'a}r, R.~Girshick, K.~He, B.~Hariharan, and S.~Belongie.
\newblock Feature pyramid networks for object detection.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2117--2125, 2017.

\bibitem{liu2019roberta}
Y.~Liu, M.~Ott, N.~Goyal, J.~Du, M.~Joshi, D.~Chen, O.~Levy, M.~Lewis,
  L.~Zettlemoyer, and V.~Stoyanov.
\newblock Roberta: A robustly optimized bert pretraining approach.
\newblock {\em arXiv preprint arXiv:1907.11692}, 2019.

\bibitem{liu2021swin}
Z.~Liu, Y.~Lin, Y.~Cao, H.~Hu, Y.~Wei, Z.~Zhang, S.~Lin, and B.~Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock {\em arXiv preprint arXiv:2103.14030}, 2021.

\bibitem{loshchilov2018decoupled}
I.~{Loshchilov} and F.~{Hutter}.
\newblock Decoupled weight decay regularization.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{luo2016understanding}
W.~{Luo}, Y.~{Li}, R.~{Urtasun}, and R.~S. {Zemel}.
\newblock Understanding the effective receptive field in deep convolutional
  neural networks.
\newblock In {\em Proceedings of the 30th International Conference on Neural
  Information Processing Systems}, volume~29, pages 4898--4906, 2016.

\bibitem{melas-kyriazi2021do}
L.~{Melas-Kyriazi}.
\newblock Do you even need attention? a stack of feed-forward layers does
  surprisingly well on imagenet.
\newblock {\em arXiv: Computer Vision and Pattern Recognition}, 2021.

\bibitem{nam2017dual}
H.~Nam, J.-W. Ha, and J.~Kim.
\newblock Dual attention networks for multimodal reasoning and matching.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 299--307, 2017.

\bibitem{ng2003sift}
P.~C. Ng and S.~Henikoff.
\newblock Sift: Predicting amino acid changes that affect protein function.
\newblock {\em Nucleic acids research}, 31(13):3812--3814, 2003.

\bibitem{Nilsback08}
M.-E. Nilsback and A.~Zisserman.
\newblock Automated flower classification over a large number of classes.
\newblock In {\em Indian Conference on Computer Vision, Graphics and Image
  Processing}, Dec 2008.

\bibitem{oh2019video}
S.~W. Oh, J.-Y. Lee, N.~Xu, and S.~J. Kim.
\newblock Video object segmentation using space-time memory networks.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pages 9226--9235, 2019.

\bibitem{olkkonen1996gaussian}
H.~Olkkonen and P.~Pesola.
\newblock Gaussian pyramid wavelet transform for multiresolution analysis of
  images.
\newblock {\em Graphical Models and Image Processing}, 58(4):394--398, 1996.

\bibitem{parkhi12a}
O.~M. Parkhi, A.~Vedaldi, A.~Zisserman, and C.~V. Jawahar.
\newblock Cats and dogs.
\newblock In {\em IEEE Conference on Computer Vision and Pattern Recognition},
  2012.

\bibitem{paszke2019pytorch}
A.~{Paszke}, S.~{Gross}, F.~{Massa}, A.~{Lerer}, J.~{Bradbury}, G.~{Chanan},
  T.~{Killeen}, Z.~{Lin}, N.~{Gimelshein}, L.~{Antiga}, A.~{Desmaison},
  A.~{Kopf}, E.~{Yang}, Z.~{DeVito}, M.~{Raison}, A.~{Tejani},
  S.~{Chilamkurthy}, B.~{Steiner}, L.~{Fang}, J.~{Bai}, and S.~{Chintala}.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~32, pages 8026--8037, 2019.

\bibitem{peng2021conformer}
Z.~Peng, W.~Huang, S.~Gu, L.~Xie, Y.~Wang, J.~Jiao, and Q.~Ye.
\newblock Conformer: Local features coupling global representations for visual
  recognition.
\newblock {\em arXiv preprint arXiv:2105.03889}, 2021.

\bibitem{perazzi2016benchmark}
F.~Perazzi, J.~Pont-Tuset, B.~McWilliams, L.~Van~Gool, M.~Gross, and
  A.~Sorkine-Hornung.
\newblock A benchmark dataset and evaluation methodology for video object
  segmentation.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 724--732, 2016.

\bibitem{pont20172017}
J.~Pont-Tuset, F.~Perazzi, S.~Caelles, P.~Arbel{\'a}ez, A.~Sorkine-Hornung, and
  L.~Van~Gool.
\newblock The 2017 davis challenge on video object segmentation.
\newblock {\em arXiv preprint arXiv:1704.00675}, 2017.

\bibitem{radford2019language}
A.~Radford, J.~Wu, R.~Child, D.~Luan, D.~Amodei, and I.~Sutskever.
\newblock Language models are unsupervised multitask learners.
\newblock {\em OpenAI blog}, 1(8):9, 2019.

\bibitem{radosavovic2020designing}
I.~Radosavovic, R.~P. Kosaraju, R.~Girshick, K.~He, and P.~Doll{\'a}r.
\newblock Designing network design spaces.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 10428--10436, 2020.

\bibitem{rublee2011orb}
E.~Rublee, V.~Rabaud, K.~Konolige, and G.~Bradski.
\newblock Orb: An efficient alternative to sift or surf.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 2564--2571. Ieee, 2011.

\bibitem{sabour2017dynamic}
S.~Sabour, N.~Frosst, and G.~E. Hinton.
\newblock Dynamic routing between capsules.
\newblock {\em arXiv preprint arXiv:1710.09829}, 2017.

\bibitem{sandler2018mobilenetv2}
M.~Sandler, A.~Howard, M.~Zhu, A.~Zhmoginov, and L.-C. Chen.
\newblock Mobilenetv2: Inverted residuals and linear bottlenecks.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 4510--4520, 2018.

\bibitem{selvaraju2017grad}
R.~R. Selvaraju, M.~Cogswell, A.~Das, R.~Vedantam, D.~Parikh, and D.~Batra.
\newblock Grad-cam: Visual explanations from deep networks via gradient-based
  localization.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 618--626, 2017.

\bibitem{shaw2018self}
P.~Shaw, J.~Uszkoreit, and A.~Vaswani.
\newblock Self-attention with relative position representations.
\newblock {\em arXiv preprint arXiv:1803.02155}, 2018.

\bibitem{simonyan2014very}
K.~Simonyan and A.~Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock {\em arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{srinivas2021bottleneck}
A.~Srinivas, T.-Y. Lin, N.~Parmar, J.~Shlens, P.~Abbeel, and A.~Vaswani.
\newblock Bottleneck transformers for visual recognition.
\newblock {\em arXiv preprint arXiv:2101.11605}, 2021.

\bibitem{szegedy2017inception}
C.~Szegedy, S.~Ioffe, V.~Vanhoucke, and A.~Alemi.
\newblock Inception-v4, inception-resnet and the impact of residual connections
  on learning.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~31, 2017.

\bibitem{szegedy2015going}
C.~Szegedy, W.~Liu, Y.~Jia, P.~Sermanet, S.~Reed, D.~Anguelov, D.~Erhan,
  V.~Vanhoucke, and A.~Rabinovich.
\newblock Going deeper with convolutions.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1--9, 2015.

\bibitem{szegedy2016rethinking}
C.~Szegedy, V.~Vanhoucke, S.~Ioffe, J.~Shlens, and Z.~Wojna.
\newblock Rethinking the inception architecture for computer vision.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2818--2826, 2016.

\bibitem{tan2019efficientnet}
M.~Tan and Q.~Le.
\newblock Efficientnet: Rethinking model scaling for convolutional neural
  networks.
\newblock In {\em International Conference on Machine Learning}, pages
  6105--6114. PMLR, 2019.

\bibitem{tolstikhin2021mlp}
I.~{Tolstikhin}, N.~{Houlsby}, A.~{Kolesnikov}, L.~{Beyer}, X.~{Zhai},
  T.~{Unterthiner}, J.~{Yung}, D.~{Keysers}, J.~{Uszkoreit}, M.~{Lucic}, and
  A.~{Dosovitskiy}.
\newblock Mlp-mixer: An all-mlp architecture for vision.
\newblock {\em arXiv preprint arXiv:2105.01601}, 2021.

\bibitem{touvron2021resmlp}
H.~Touvron, P.~Bojanowski, M.~Caron, M.~Cord, A.~El-Nouby, E.~Grave, A.~Joulin,
  G.~Synnaeve, J.~Verbeek, and H.~J{\'e}gou.
\newblock Resmlp: Feedforward networks for image classification with
  data-efficient training.
\newblock {\em arXiv preprint arXiv:2105.03404}, 2021.

\bibitem{touvron2020training}
H.~Touvron, M.~Cord, M.~Douze, F.~Massa, A.~Sablayrolles, and H.~J{\'e}gou.
\newblock Training data-efficient image transformers \& distillation through
  attention.
\newblock {\em arXiv preprint arXiv:2012.12877}, 2020.

\bibitem{touvron2021going}
H.~Touvron, M.~Cord, A.~Sablayrolles, G.~Synnaeve, and H.~J{\'e}gou.
\newblock Going deeper with image transformers.
\newblock {\em arXiv preprint arXiv:2103.17239}, 2021.

\bibitem{touvron2020grafit}
H.~Touvron, A.~Sablayrolles, M.~Douze, M.~Cord, and H.~J{\'e}gou.
\newblock Grafit: Learning fine-grained image representations with coarse
  labels.
\newblock {\em arXiv preprint arXiv:2011.12982}, 2020.

\bibitem{vaswani2017attention}
A.~{Vaswani}, N.~{Shazeer}, N.~{Parmar}, J.~{Uszkoreit}, L.~{Jones}, A.~N.
  {Gomez}, L.~{Kaiser}, and I.~{Polosukhin}.
\newblock Attention is all you need.
\newblock In {\em Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, volume~30, pages 5998--6008, 2017.

\bibitem{wang2021pyramid}
W.~Wang, E.~Xie, X.~Li, D.-P. Fan, K.~Song, D.~Liang, T.~Lu, P.~Luo, and
  L.~Shao.
\newblock Pyramid vision transformer: A versatile backbone for dense prediction
  without convolutions.
\newblock {\em arXiv preprint arXiv:2102.12122}, 2021.

\bibitem{wang2018non}
X.~Wang, R.~Girshick, A.~Gupta, and K.~He.
\newblock Non-local neural networks.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 7794--7803, 2018.

\bibitem{rw2019timm}
R.~Wightman.
\newblock Pytorch image models.
\newblock \url{https://github.com/rwightman/pytorch-image-models}, 2019.

\bibitem{wu2021cvt}
H.~Wu, B.~Xiao, N.~Codella, M.~Liu, X.~Dai, L.~Yuan, and L.~Zhang.
\newblock Cvt: Introducing convolutions to vision transformers.
\newblock {\em arXiv preprint arXiv:2103.15808}, 2021.

\bibitem{Xiao_2018_ECCV}
B.~Xiao, H.~Wu, and Y.~Wei.
\newblock Simple baselines for human pose estimation and tracking.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, September 2018.

\bibitem{xiao2018unified}
T.~Xiao, Y.~Liu, B.~Zhou, Y.~Jiang, and J.~Sun.
\newblock Unified perceptual parsing for scene understanding.
\newblock In {\em Proceedings of the European Conference on Computer Vision
  (ECCV)}, pages 418--434, 2018.

\bibitem{xie2021so}
J.~Xie, R.~Zeng, Q.~Wang, Z.~Zhou, and P.~Li.
\newblock So-vit: Mind visual tokens for vision transformer.
\newblock {\em arXiv preprint arXiv:2104.10935}, 2021.

\bibitem{xie2017aggregated}
S.~Xie, R.~Girshick, P.~Doll{\'a}r, Z.~Tu, and K.~He.
\newblock Aggregated residual transformations for deep neural networks.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1492--1500, 2017.

\bibitem{Xu_2021_ICCV}
W.~Xu, Y.~Xu, T.~Chang, and Z.~Tu.
\newblock Co-scale conv-attentional image transformers.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 9981--9990, October 2021.

\bibitem{yan2021contnet}
H.~Yan, Z.~Li, W.~Li, C.~Wang, M.~Wu, and C.~Zhang.
\newblock Contnet: Why not use convolution and transformer at the same time?
\newblock {\em arXiv preprint arXiv:2104.13497}, 2021.

\bibitem{yu2016multi}
F.~{Yu} and V.~{Koltun}.
\newblock Multi-scale context aggregation by dilated convolutions.
\newblock In {\em ICLR 2016 : International Conference on Learning
  Representations 2016}, 2016.

\bibitem{yu2017dilated}
F.~Yu, V.~Koltun, and T.~Funkhouser.
\newblock Dilated residual networks.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 472--480, 2017.

\bibitem{yuan2021incorporating}
K.~Yuan, S.~Guo, Z.~Liu, A.~Zhou, F.~Yu, and W.~Wu.
\newblock Incorporating convolution designs into visual transformers.
\newblock {\em arXiv preprint arXiv:2103.11816}, 2021.

\bibitem{yuan2021tokens}
L.~Yuan, Y.~Chen, T.~Wang, W.~Yu, Y.~Shi, Z.~Jiang, F.~E. Tay, J.~Feng, and
  S.~Yan.
\newblock Tokens-to-token vit: Training vision transformers from scratch on
  imagenet.
\newblock {\em arXiv preprint arXiv:2101.11986}, 2021.

\bibitem{zeiler2014visualizing}
M.~D. Zeiler and R.~Fergus.
\newblock Visualizing and understanding convolutional networks.
\newblock In {\em European conference on computer vision}, pages 818--833.
  Springer, 2014.

\bibitem{zhang2018shufflenet}
X.~Zhang, X.~Zhou, M.~Lin, and J.~Sun.
\newblock Shufflenet: An extremely efficient convolutional neural network for
  mobile devices.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 6848--6856, 2018.

\bibitem{zhao2017pyramid}
H.~Zhao, J.~Shi, X.~Qi, X.~Wang, and J.~Jia.
\newblock Pyramid scene parsing network.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 2881--2890, 2017.

\bibitem{zheng2020rethinking}
S.~{Zheng}, J.~{Lu}, H.~{Zhao}, X.~{Zhu}, Z.~{Luo}, Y.~{Wang}, Y.~{Fu},
  J.~{Feng}, T.~{Xiang}, P.~H.~S. {Torr}, and L.~{Zhang}.
\newblock Rethinking semantic segmentation from a sequence-to-sequence
  perspective with transformers.
\newblock {\em arXiv preprint arXiv:2012.15840}, 2020.

\bibitem{zhou2017scene}
B.~Zhou, H.~Zhao, X.~Puig, S.~Fidler, A.~Barriuso, and A.~Torralba.
\newblock Scene parsing through ade20k dataset.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 633--641, 2017.

\bibitem{zhou2019semantic}
B.~Zhou, H.~Zhao, X.~Puig, T.~Xiao, S.~Fidler, A.~Barriuso, and A.~Torralba.
\newblock Semantic understanding of scenes through the ade20k dataset.
\newblock {\em International Journal of Computer Vision}, 127(3):302--321,
  2019.

\bibitem{zhu2021deformable}
X.~{Zhu}, W.~{Su}, L.~{Lu}, B.~{Li}, X.~{Wang}, and J.~{Dai}.
\newblock Deformable detr: Deformable transformers for end-to-end object
  detection.
\newblock In {\em International Conference on Learning Representations}, 2021.

\end{thebibliography}
