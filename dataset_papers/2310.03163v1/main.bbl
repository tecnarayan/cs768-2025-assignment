\begin{thebibliography}{29}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[McMahan et~al.(2017)McMahan, Moore, Ramage, Hampson, and
  y~Arcas]{mcmahan2017communication}
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise~Aguera
  y~Arcas.
\newblock Communication-efficient learning of deep networks from decentralized
  data.
\newblock In \emph{Artificial intelligence and statistics}, pages 1273--1282.
  PMLR, 2017.

\bibitem[Kairouz et~al.(2021)Kairouz, McMahan, Avent, Bellet, Bennis, Bhagoji,
  Bonawitz, Charles, Cormode, Cummings, et~al.]{kairouz2021advances}
Peter Kairouz, H~Brendan McMahan, Brendan Avent, Aur{\'e}lien Bellet, Mehdi
  Bennis, Arjun~Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham
  Cormode, Rachel Cummings, et~al.
\newblock Advances and open problems in federated learning.
\newblock \emph{Foundations and Trends in Machine Learning}, 14\penalty0
  (1-2):\penalty0 1--210, 2021.

\bibitem[Wang et~al.(2021)Wang, Charles, Xu, Joshi, McMahan, Al-Shedivat,
  Andrew, Avestimehr, Daly, Data, et~al.]{wang2021field}
Jianyu Wang, Zachary Charles, Zheng Xu, Gauri Joshi, H~Brendan McMahan, Maruan
  Al-Shedivat, Galen Andrew, Salman Avestimehr, Katharine Daly, Deepesh Data,
  et~al.
\newblock A field guide to federated optimization.
\newblock \emph{arXiv preprint arXiv:2107.06917}, 2021.

\bibitem[Li et~al.(2020{\natexlab{a}})Li, Sahu, Zaheer, Sanjabi, Talwalkar, and
  Smith]{li2020federated}
Tian Li, Anit~Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
  Virginia Smith.
\newblock Federated optimization in heterogeneous networks.
\newblock \emph{Proceedings of Machine learning and systems}, 2:\penalty0
  429--450, 2020{\natexlab{a}}.

\bibitem[Rieke et~al.(2020)Rieke, Hancox, Li, Milletari, Roth, Albarqouni,
  Bakas, Galtier, Landman, Maier-Hein, et~al.]{rieke2020future}
Nicola Rieke, Jonny Hancox, Wenqi Li, Fausto Milletari, Holger~R Roth, Shadi
  Albarqouni, Spyridon Bakas, Mathieu~N Galtier, Bennett~A Landman, Klaus
  Maier-Hein, et~al.
\newblock The future of digital health with federated learning.
\newblock \emph{NPJ digital medicine}, 3\penalty0 (1):\penalty0 119, 2020.

\bibitem[Karimireddy et~al.(2020)Karimireddy, Kale, Mohri, Reddi, Stich, and
  Suresh]{karimireddy2020scaffold}
Sai~Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian
  Stich, and Ananda~Theertha Suresh.
\newblock Scaffold: Stochastic controlled averaging for federated learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  5132--5143. PMLR, 2020.

\bibitem[Kone{\v{c}}n{\`y} et~al.(2016)Kone{\v{c}}n{\`y}, McMahan, Ramage, and
  Richt{\'a}rik]{konevcny2016federated}
Jakub Kone{\v{c}}n{\`y}, H~Brendan McMahan, Daniel Ramage, and Peter
  Richt{\'a}rik.
\newblock Federated optimization: Distributed machine learning for on-device
  intelligence.
\newblock \emph{arXiv preprint arXiv:1610.02527}, 2016.

\bibitem[Mohri et~al.(2019)Mohri, Sivek, and Suresh]{mohri2019agnostic}
Mehryar Mohri, Gary Sivek, and Ananda~Theertha Suresh.
\newblock Agnostic federated learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  4615--4625. PMLR, 2019.

\bibitem[Reddi et~al.(2020)Reddi, Charles, Zaheer, Garrett, Rush,
  Kone{\v{c}}n{\`y}, Kumar, and McMahan]{reddi2020adaptive}
Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush,
  Jakub Kone{\v{c}}n{\`y}, Sanjiv Kumar, and H~Brendan McMahan.
\newblock Adaptive federated optimization.
\newblock \emph{arXiv preprint arXiv:2003.00295}, 2020.

\bibitem[Wang et~al.(2020{\natexlab{a}})Wang, Liu, Liang, Joshi, and
  Poor]{wang2020tackling}
Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and H~Vincent Poor.
\newblock Tackling the objective inconsistency problem in heterogeneous
  federated optimization.
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 7611--7623, 2020{\natexlab{a}}.

\bibitem[Li et~al.(2020{\natexlab{b}})Li, Huang, Yang, Wang, and
  Zhang]{li2020convergence}
Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang.
\newblock On the convergence of fedavg on non-iid data.
\newblock In \emph{International Conference on Learning Representations},
  2020{\natexlab{b}}.

\bibitem[Yurochkin et~al.(2019)Yurochkin, Agarwal, Ghosh, Greenewald, Hoang,
  and Khazaeni]{yurochkin2019bayesian}
Mikhail Yurochkin, Mayank Agarwal, Soumya Ghosh, Kristjan Greenewald, Nghia
  Hoang, and Yasaman Khazaeni.
\newblock Bayesian nonparametric federated learning of neural networks.
\newblock In \emph{International Conference on Machine Learning}, pages
  7252--7261. PMLR, 2019.

\bibitem[Wang et~al.(2020{\natexlab{b}})Wang, Yurochkin, Sun, Papailiopoulos,
  and Khazaeni]{wang2020federated}
Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Papailiopoulos, and
  Yasaman Khazaeni.
\newblock Federated learning with matched averaging.
\newblock In \emph{International Conference on Learning Representations},
  2020{\natexlab{b}}.

\bibitem[Bonawitz et~al.(2017)Bonawitz, Ivanov, Kreuter, Marcedone, McMahan,
  Patel, Ramage, Segal, and Seth]{bonawitz2017practical}
Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H~Brendan
  McMahan, Sarvar Patel, Daniel Ramage, Aaron Segal, and Karn Seth.
\newblock Practical secure aggregation for privacy-preserving machine learning.
\newblock In \emph{proceedings of the 2017 ACM SIGSAC Conference on Computer
  and Communications Security}, pages 1175--1191, 2017.

\bibitem[Bonawitz et~al.(2019)Bonawitz, Eichner, Grieskamp, Huba, Ingerman,
  Ivanov, Kiddon, Kone{\v{c}}n{\`y}, Mazzocchi, McMahan,
  et~al.]{bonawitz2019towards}
Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex
  Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub Kone{\v{c}}n{\`y}, Stefano
  Mazzocchi, Brendan McMahan, et~al.
\newblock Towards federated learning at scale: System design.
\newblock \emph{Proceedings of Machine Learning and Systems}, 1:\penalty0
  374--388, 2019.

\bibitem[He et~al.(2020)He, Li, So, Zeng, Zhang, Wang, Wang, Vepakomma, Singh,
  Qiu, et~al.]{he2020fedml}
Chaoyang He, Songze Li, Jinhyun So, Xiao Zeng, Mi~Zhang, Hongyi Wang, Xiaoyang
  Wang, Praneeth Vepakomma, Abhishek Singh, Hang Qiu, et~al.
\newblock Fedml: A research library and benchmark for federated machine
  learning.
\newblock \emph{arXiv preprint arXiv:2007.13518}, 2020.

\bibitem[Sun et~al.(2019)Sun, Kairouz, Suresh, and McMahan]{sun2019can}
Ziteng Sun, Peter Kairouz, Ananda~Theertha Suresh, and H~Brendan McMahan.
\newblock Can you really backdoor federated learning?
\newblock \emph{arXiv preprint arXiv:1911.07963}, 2019.

\bibitem[McMahan et~al.(2018)McMahan, Ramage, Talwar, and
  Zhang]{mcmahan2018learning}
H~Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li~Zhang.
\newblock Learning differentially private recurrent language models.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Fredrikson et~al.(2015)Fredrikson, Jha, and
  Ristenpart]{fredrikson2015model}
Matt Fredrikson, Somesh Jha, and Thomas Ristenpart.
\newblock Model inversion attacks that exploit confidence information and basic
  countermeasures.
\newblock In \emph{Proceedings of the 22nd ACM SIGSAC conference on computer
  and communications security}, pages 1322--1333, 2015.

\bibitem[Loshchilov and Hutter(2017)]{loshchilov2017decoupled}
Ilya Loshchilov and Frank Hutter.
\newblock Decoupled weight decay regularization.
\newblock \emph{arXiv preprint arXiv:1711.05101}, 2017.

\bibitem[Zhou et~al.()Zhou, Xie, and Shuicheng]{zhou2022win}
Pan Zhou, Xingyu Xie, and YAN Shuicheng.
\newblock Win: Weight-decay-integrated nesterov acceleration for adaptive
  gradient algorithms.
\newblock In \emph{Has it Trained Yet? NeurIPS 2022 Workshop}.

\bibitem[Li et~al.(2023)Li, Lin, Shang, and Wu]{li2023revisiting}
Zexi Li, Tao Lin, Xinyi Shang, and Chao Wu.
\newblock Revisiting weighted aggregation in federated learning with neural
  networks.
\newblock \emph{arXiv preprint arXiv:2302.10911}, 2023.

\bibitem[Hanson and Pratt(1988)]{hanson1988comparing}
Stephen Hanson and Lorien Pratt.
\newblock Comparing biases for minimal network construction with
  back-propagation.
\newblock \emph{Advances in neural information processing systems}, 1, 1988.

\bibitem[Jhunjhunwala et~al.(2023)Jhunjhunwala, Wang, and
  Joshi]{jhunjhunwala2023fedexp}
Divyansh Jhunjhunwala, Shiqiang Wang, and Gauri Joshi.
\newblock Fedexp: Speeding up federated averaging via extrapolation.
\newblock \emph{arXiv preprint arXiv:2301.09604}, 2023.

\bibitem[Hsu et~al.(2019)Hsu, Qi, and Brown]{hsu2019measuring}
Tzu-Ming~Harry Hsu, Hang Qi, and Matthew Brown.
\newblock Measuring the effects of non-identical data distribution for
  federated visual classification.
\newblock \emph{arXiv preprint arXiv:1909.06335}, 2019.

\bibitem[Acar et~al.(2021)Acar, Zhao, Navarro, Mattina, Whatmough, and
  Saligrama]{acar2021federated}
Durmus Alp~Emre Acar, Yue Zhao, Ramon~Matas Navarro, Matthew Mattina, Paul~N
  Whatmough, and Venkatesh Saligrama.
\newblock Federated learning based on dynamic regularization.
\newblock \emph{arXiv preprint arXiv:2111.04263}, 2021.

\bibitem[Zhang et~al.(2019)Zhang, He, Sra, and Jadbabaie]{zhang2019gradient}
Jingzhao Zhang, Tianxing He, Suvrit Sra, and Ali Jadbabaie.
\newblock Why gradient clipping accelerates training: A theoretical
  justification for adaptivity.
\newblock \emph{arXiv preprint arXiv:1905.11881}, 2019.

\bibitem[Rothchild et~al.(2020)Rothchild, Panda, Ullah, Ivkin, Stoica,
  Braverman, Gonzalez, and Arora]{rothchild2020fetchsgd}
Daniel Rothchild, Ashwinee Panda, Enayat Ullah, Nikita Ivkin, Ion Stoica,
  Vladimir Braverman, Joseph Gonzalez, and Raman Arora.
\newblock Fetchsgd: Communication-efficient federated learning with sketching.
\newblock In \emph{International Conference on Machine Learning}, pages
  8253--8265. PMLR, 2020.

\bibitem[Caldas et~al.(2018)Caldas, Duddu, Wu, Li, Kone{\v{c}}n{\`y}, McMahan,
  Smith, and Talwalkar]{caldas2018leaf}
Sebastian Caldas, Sai Meher~Karthik Duddu, Peter Wu, Tian Li, Jakub
  Kone{\v{c}}n{\`y}, H~Brendan McMahan, Virginia Smith, and Ameet Talwalkar.
\newblock Leaf: A benchmark for federated settings.
\newblock \emph{arXiv preprint arXiv:1812.01097}, 2018.

\end{thebibliography}
