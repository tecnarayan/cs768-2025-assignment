\begin{thebibliography}{24}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal and Duchi(2011)]{agarwal2011delayed}
A.~Agarwal and J.~C. Duchi.
\newblock Distributed delayed stochastic optimization.
\newblock In \emph{NIPS}, pages 873--881, 2011.

\bibitem[Agarwal et~al.(2008)Agarwal, Chen, Elango, Motgi, Park, Ramakrishnan,
  Roy, and Zachariah]{COKE2008}
D.~Agarwal, B.-C. Chen, P.~Elango, N.~Motgi, S.-T. Park, R.~Ramakrishnan,
  S.~Roy, and J.~Zachariah.
\newblock Online models for content optimization.
\newblock In \emph{NIPS}, pages 17--24, December 2008.

\bibitem[Anthony and Bartlett(1999)]{anthony1999neural}
M.~Anthony and P.~Bartlett.
\newblock \emph{Neural network learning: Theoretical foundations}.
\newblock Cambridge University Press, 1999.

\bibitem[Audibert et~al.(2010)Audibert, Bubeck, and Munos]{audibert10}
J.-Y. Audibert, S.~Bubeck, and R.~Munos.
\newblock Best arm identification in multi-armed bandits.
\newblock In \emph{COLT}, pages 41--53, 2010.

\bibitem[Auer and Ortner(2010)]{auer2010ucb}
P.~Auer and R.~Ortner.
\newblock {UCB} revisited: Improved regret bounds for the stochastic
  multi-armed bandit problem.
\newblock \emph{Periodica Mathematica Hungarica}, 61\penalty0 (1-2):\penalty0
  55--65, 2010.

\bibitem[Auer et~al.(2002)Auer, Cesa-Bianchi, and Fischer]{auer2002finite}
P.~Auer, N.~Cesa-Bianchi, and P.~Fischer.
\newblock Finite-time analysis of the multiarmed bandit problem.
\newblock \emph{Machine learning}, 47\penalty0 (2):\penalty0 235--256, 2002.

\bibitem[Balcan et~al.(2012)Balcan, Blum, Fine, and Mansour]{balcan12}
M.~Balcan, A.~Blum, S.~Fine, and Y.~Mansour.
\newblock Distributed learning, communication complexity and privacy.
\newblock \emph{Arxiv preprint arXiv:1204.3514}, 2012.

\bibitem[Bubeck et~al.(2009)Bubeck, Munos, and Stoltz]{bubeck2009pure}
S.~Bubeck, R.~Munos, and G.~Stoltz.
\newblock Pure exploration in multi-armed bandits problems.
\newblock In \emph{Algorithmic Learning Theory}, pages 23--37. Springer, 2009.

\bibitem[Chakrabarti et~al.(2008)Chakrabarti, Kumar, Radlinski, and
  Upfal]{COKE-mortal2008}
D.~Chakrabarti, R.~Kumar, F.~Radlinski, and E.~Upfal.
\newblock Mortal multi-armed bandits.
\newblock In \emph{NIPS}, pages 273--280, 2008.

\bibitem[Daum{\'e}~III et~al.(2012{\natexlab{a}})Daum{\'e}~III, Phillips, Saha,
  and Venkatasubramanian]{daume2012efficient}
H.~Daum{\'e}~III, J.~M. Phillips, A.~Saha, and S.~Venkatasubramanian.
\newblock Efficient protocols for distributed classification and optimization.
\newblock In \emph{ALT}, 2012{\natexlab{a}}.

\bibitem[Daum{\'e}~III et~al.(2012{\natexlab{b}})Daum{\'e}~III, Phillips, Saha,
  and Venkatasubramanian]{daume2012protocols}
H.~Daum{\'e}~III, J.~M. Phillips, A.~Saha, and S.~Venkatasubramanian.
\newblock Protocols for learning classifiers on distributed data.
\newblock \emph{AISTAT}, 2012{\natexlab{b}}.

\bibitem[Dean and Ghemawat(2008)]{MapReduce08}
J.~Dean and S.~Ghemawat.
\newblock Map{R}educe: simplified data processing on large clusters.
\newblock \emph{Commun. ACM}, 51\penalty0 (1):\penalty0 107--113, Jan. 2008.

\bibitem[Dekel et~al.(2012)Dekel, Gilad-Bachrach, Shamir, and Xiao]{dekel12}
O.~Dekel, R.~Gilad-Bachrach, O.~Shamir, and L.~Xiao.
\newblock Optimal distributed online prediction using mini-batches.
\newblock \emph{Journal of Machine Learning Research}, 13:\penalty0 165--202,
  2012.

\bibitem[Duchi et~al.(2010)Duchi, Agarwal, and
  Wainwright]{duchi2010distributed}
J.~Duchi, A.~Agarwal, and M.~J. Wainwright.
\newblock Distributed dual averaging in networks.
\newblock \emph{NIPS}, 23, 2010.

\bibitem[Even-Dar et~al.(2006)Even-Dar, Mannor, and Mansour]{evendar06}
E.~Even-Dar, S.~Mannor, and Y.~Mansour.
\newblock Action elimination and stopping conditions for the multi-armed bandit
  and reinforcement learning problems.
\newblock \emph{The Journal of Machine Learning Research}, 7:\penalty0
  1079--1105, 2006.

\bibitem[Gabillon et~al.(2011)Gabillon, Ghavamzadeh, Lazaric, and
  Bubeck]{gabillon2011multi}
V.~Gabillon, M.~Ghavamzadeh, A.~Lazaric, and S.~Bubeck.
\newblock Multi-bandit best arm identification.
\newblock \emph{NIPS}, 2011.

\bibitem[Kanade et~al.(2012)Kanade, Liu, and Radunovic]{kanade2012distributed}
V.~Kanade, Z.~Liu, and B.~Radunovic.
\newblock Distributed non-stochastic experts.
\newblock In \emph{Advances in Neural Information Processing Systems 25}, pages
  260--268, 2012.

\bibitem[Karnin et~al.(2013)Karnin, Koren, and Somekh]{karnin2013almost}
Z.~Karnin, T.~Koren, and O.~Somekh.
\newblock Almost optimal exploration in multi-armed bandits.
\newblock In \emph{Proceedings of the 30th International Conference on Machine
  Learning}, 2013.

\bibitem[Liu and Zhao(2010)]{liu2010distributed}
K.~Liu and Q.~Zhao.
\newblock Distributed learning in multi-armed bandit with multiple players.
\newblock \emph{IEEE Transactions on Signal Processing}, 58\penalty0
  (11):\penalty0 5667--5681, Nov. 2010.

\bibitem[Mannor and Tsitsiklis(2004)]{mannor04}
S.~Mannor and J.~Tsitsiklis.
\newblock The sample complexity of exploration in the multi-armed bandit
  problem.
\newblock \emph{The Journal of Machine Learning Research}, 5:\penalty0
  623--648, 2004.

\bibitem[Maron and Moore(1994)]{maron1994hoeffding}
O.~Maron and A.~W. Moore.
\newblock Hoeffding races: Accelerating model selection search for
  classification and function approximation.
\newblock In \emph{NIPS}, 1994.

\bibitem[Mnih et~al.(2008)Mnih, Szepesv{\'a}ri, and
  Audibert]{mnih2008empirical}
V.~Mnih, C.~Szepesv{\'a}ri, and J.-Y. Audibert.
\newblock Empirical bernstein stopping.
\newblock In \emph{ICML}, pages 672--679. ACM, 2008.

\bibitem[Radlinski et~al.(2008)Radlinski, Kurup, and
  Joachims]{InterleavedBuckets}
F.~Radlinski, M.~Kurup, and T.~Joachims.
\newblock How does clickthrough data reflect retrieval quality?
\newblock In \emph{CIKM}, pages 43--52, October 2008.

\bibitem[Yue and Joachims(2009)]{Dueling2009}
Y.~Yue and T.~Joachims.
\newblock Interactively optimizing information retrieval systems as a dueling
  bandits problem.
\newblock In \emph{ICML}, page 151, June 2009.

\end{thebibliography}
