@article{chen2024deconstructing,
  title={Deconstructing denoising diffusion models for self-supervised learning},
  author={Chen, Xinlei and Liu, Zhuang and Xie, Saining and He, Kaiming},
  journal={arXiv preprint arXiv:2401.14404},
  year={2024}
}

@article{vidiff,
  title={Vidiff: Translating videos via multi-modal instructions with diffusion models},
  author={Xing, Zhen and Dai, Qi and Zhang, Zihao and Zhang, Hui and Hu, Han and Wu, Zuxuan and Jiang, Yu-Gang},
  journal={arXiv preprint arXiv:2311.18837},
  year={2023}
}

@article{zhang2023adadiff,
  title={Adadiff: Adaptive step selection for fast diffusion},
  author={Zhang, Hui and Wu, Zuxuan and Xing, Zhen and Shao, Jie and Jiang, Yu-Gang},
  journal={arXiv preprint arXiv:2311.14768},
  year={2023}
}


@article{xing2023survey,
  title={A survey on video diffusion models},
  author={Xing, Zhen and Feng, Qijun and Chen, Haoran and Dai, Qi and Hu, Han and Xu, Hang and Wu, Zuxuan and Jiang, Yu-Gang},
  journal={ACM Computing Surveys},
  year={2023},
  publisher={ACM New York, NY}
}

@article{blattmann2023stable,
  title={Stable video diffusion: Scaling latent video diffusion models to large datasets},
  author={Blattmann, Andreas and Dockhorn, Tim and Kulal, Sumith and Mendelevitch, Daniel and Kilian, Maciej and Lorenz, Dominik and Levi, Yam and English, Zion and Voleti, Vikram and Letts, Adam and others},
  journal={arXiv preprint arXiv:2311.15127},
  year={2023}
}

@article{kay2017kinetics,
  title={The kinetics human action video dataset},
  author={Kay, Will and Carreira, Joao and Simonyan, Karen and Zhang, Brian and Hillier, Chloe and Vijayanarasimhan, Sudheendra and Viola, Fabio and Green, Tim and Back, Trevor and Natsev, Paul and others},
  journal={arXiv preprint arXiv:1705.06950},
  year={2017}
}

@inproceedings{ceylan2023pix2video,
  title={Pix2video: Video editing using image diffusion},
  author={Ceylan, Duygu and Huang, Chun-Hao P and Mitra, Niloy J},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{chai2023stablevideo,
  title={Stablevideo: Text-driven consistency-aware diffusion video editing},
  author={Chai, Wenhao and Guo, Xun and Wang, Gaoang and Lu, Yan},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={23040--23050},
  year={2023}
}

@article{liew2023magicedit,
  title={Magicedit: High-fidelity and temporally coherent video editing},
  author={Liew, Jun Hao and Yan, Hanshu and Zhang, Jianfeng and Xu, Zhongcong and Feng, Jiashi},
  journal={arXiv preprint arXiv:2308.14749},
  year={2023}
}

@article{molad2023dreamix,
  title={Dreamix: Video diffusion models are general video editors},
  author={Molad, Eyal and Horwitz, Eliahu and Valevski, Dani and Acha, Alex Rav and Matias, Yossi and Pritch, Yael and Leviathan, Yaniv and Hoshen, Yedid},
  journal={arXiv preprint arXiv:2302.01329},
  year={2023}
}

@inproceedings{esser2023structure,
  title={Structure and content-guided video synthesis with diffusion models},
  author={Esser, Patrick and Chiu, Johnathan and Atighehchian, Parmida and Granskog, Jonathan and Germanidis, Anastasis},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{ge2023preserve,
  title={Preserve your own correlation: A noise prior for video diffusion models},
  author={Ge, Songwei and Nah, Seungjun and Liu, Guilin and Poon, Tyler and Tao, Andrew and Catanzaro, Bryan and Jacobs, David and Huang, Jia-Bin and Liu, Ming-Yu and Balaji, Yogesh},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{blattmann2023align,
  title={Align your latents: High-resolution video synthesis with latent diffusion models},
  author={Blattmann, Andreas and Rombach, Robin and Ling, Huan and Dockhorn, Tim and Kim, Seung Wook and Fidler, Sanja and Kreis, Karsten},
  booktitle={CVPR},
  year={2023}
}

@article{xing2023simda,
  title={Simda: Simple diffusion adapter for efficient video generation},
  author={Xing, Zhen and Dai, Qi and Hu, Han and Wu, Zuxuan and Jiang, Yu-Gang},
  journal={arXiv preprint arXiv:2308.09710},
  year={2023}
}



@inproceedings{ye2024stdiff,
  title={STDiff: Spatio-Temporal Diffusion for Continuous Stochastic Video Prediction},
  author={Ye, Xi and Bilodeau, Guillaume-Alexandre},
  booktitle={AAAI},
  year={2024}
}

@article{gu2023seer,
  title={Seer: Language instructed video prediction with latent diffusion models},
  author={Gu, Xianfan and Wen, Chuan and Ye, Weirui and Song, Jiaming and Gao, Yang},
  journal={arXiv preprint arXiv:2303.14897},
  year={2023}
}

@article{hoppe2022diffusion,
  title={Diffusion models for video prediction and infilling},
  author={H{\"o}ppe, Tobias and Mehrjou, Arash and Bauer, Stefan and Nielsen, Didrik and Dittadi, Andrea},
  journal={arXiv preprint arXiv:2206.07696},
  year={2022}
}

@inproceedings{xu2023open,
  title={Open-vocabulary panoptic segmentation with text-to-image diffusion models},
  author={Xu, Jiarui and Liu, Sifei and Vahdat, Arash and Byeon, Wonmin and Wang, Xiaolong and De Mello, Shalini},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{tang2023emergent,
  title={Emergent correspondence from image diffusion},
  author={Tang, Luming and Jia, Menglin and Wang, Qianqian and Phoo, Cheng Perng and Hariharan, Bharath},
  booktitle={NeurIPS},
  year={2023}
}

@article{song2020score,
  title={Score-based generative modeling through stochastic differential equations},
  author={Song, Yang and Sohl-Dickstein, Jascha and Kingma, Diederik P and Kumar, Abhishek and Ermon, Stefano and Poole, Ben},
  journal={arXiv preprint arXiv:2011.13456},
  year={2020}
}

@inproceedings{karras2022elucidating,
  title={Elucidating the design space of diffusion-based generative models},
  author={Karras, Tero and Aittala, Miika and Aila, Timo and Laine, Samuli},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{dhariwal2021diffusion,
  title={Diffusion models beat gans on image synthesis},
  author={Dhariwal, Prafulla and Nichol, Alexander},
  booktitle={NeurIPS},
  year={2021}
}

@article{unterthiner2018towards,
  title={Towards accurate generative models of video: A new metric \& challenges},
  author={Unterthiner, Thomas and Van Steenkiste, Sjoerd and Kurach, Karol and Marinier, Raphael and Michalski, Marcin and Gelly, Sylvain},
  journal={arXiv preprint arXiv:1812.01717},
  year={2018}
}


@inproceedings{goyal2017something,
  title={The" something something" video database for learning and evaluating visual common sense},
  author={Goyal, Raghav and Ebrahimi Kahou, Samira and Michalski, Vincent and Materzynska, Joanna and Westphal, Susanne and Kim, Heuna and Haenel, Valentin and Fruend, Ingo and Yianilos, Peter and Mueller-Freitag, Moritz and others},
  booktitle={ICCV},
  year={2017}
}

@article{soomro2012ucf101,
  title={UCF101: A dataset of 101 human actions classes from videos in the wild},
  author={Soomro, Khurram and Zamir, Amir Roshan and Shah, Mubarak},
  journal={arXiv preprint arXiv:1212.0402},
  year={2012}
}

@article{damen2022rescaling,
  title={Rescaling egocentric vision: Collection, pipeline and challenges for epic-kitchens-100},
  author={Damen, Dima and Doughty, Hazel and Farinella, Giovanni Maria and Furnari, Antonino and Kazakos, Evangelos and Ma, Jian and Moltisanti, Davide and Munro, Jonathan and Perrett, Toby and Price, Will and others},
  journal={IJCV},
  year={2022},
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  year={2021},
}

@article{ho2022classifier,
  title={Classifier-free diffusion guidance},
  author={Ho, Jonathan and Salimans, Tim},
  journal={arXiv preprint arXiv:2207.12598},
  year={2022}
}

@inproceedings{ge2022long,
  title={Long video generation with time-agnostic vqgan and time-sensitive transformer},
  author={Ge, Songwei and Hayes, Thomas and Yang, Harry and Yin, Xi and Pang, Guan and Jacobs, David and Huang, Jia-Bin and Parikh, Devi},
  booktitle={ECCV},
  year={2022},
}

@inproceedings{voleti2022mcvd,
  title={Mcvd-masked conditional video diffusion for prediction, generation, and interpolation},
  author={Voleti, Vikram and Jolicoeur-Martineau, Alexia and Pal, Chris},
  booktitle={NeurIPS},
  year={2022}
}


@inproceedings{gao2022simvp,
  title={Simvp: Simpler yet better video prediction},
  author={Gao, Zhangyang and Tan, Cheng and Wu, Lirong and Li, Stan Z},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{luo2023videofusion,
  title={Videofusion: Decomposed diffusion models for high-quality video generation},
  author={Luo, Zhengxiong and Chen, Dayou and Zhang, Yingya and Huang, Yan and Wang, Liang and Shen, Yujun and Zhao, Deli and Zhou, Jingren and Tan, Tieniu},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{wu2023tune,
  title={Tune-a-video: One-shot tuning of image diffusion models for text-to-video generation},
  author={Wu, Jay Zhangjie and Ge, Yixiao and Wang, Xintao and Lei, Stan Weixian and Gu, Yuchao and Shi, Yufei and Hsu, Wynne and Shan, Ying and Qie, Xiaohu and Shou, Mike Zheng},
  booktitle={ICCV},
  year={2023}
}

@inproceedings{stergiou2023wisdom,
  title={The wisdom of crowds: Temporal progressive attention for early action prediction},
  author={Stergiou, Alexandros and Damen, Dima},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{wang2023masked,
  title={Masked video distillation: Rethinking masked feature modeling for self-supervised video representation learning},
  author={Wang, Rui and Chen, Dongdong and Wu, Zuxuan and Chen, Yinpeng and Dai, Xiyang and Liu, Mengchen and Yuan, Lu and Jiang, Yu-Gang},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{tong2022videomae,
  title={Videomae: Masked autoencoders are data-efficient learners for self-supervised video pre-training},
  author={Tong, Zhan and Song, Yibing and Wang, Jue and Wang, Limin},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{girdhar2023omnimae,
  title={Omnimae: Single model masked pretraining on images and videos},
  author={Girdhar, Rohit and El-Nouby, Alaaeldin and Singh, Mannat and Alwala, Kalyan Vasudev and Joulin, Armand and Misra, Ishan},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{clark2024text,
  title={Text-to-Image Diffusion Models are Zero Shot Classifiers},
  author={Clark, Kevin and Jaini, Priyank},
  booktitle={NeurIPS},
  year={2024}
}


@inproceedings{saharia2022photorealistic,
  title={Photorealistic text-to-image diffusion models with deep language understanding},
  author={Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily L and Ghasemipour, Kamyar and Gontijo Lopes, Raphael and Karagol Ayan, Burcu and Salimans, Tim and others},
  booktitle={NeurIPS},
  year={2022}
}

@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={ICML},
  year={2021},
}

@inproceedings{kawar2023imagic,
  title={Imagic: Text-based real image editing with diffusion models},
  author={Kawar, Bahjat and Zada, Shiran and Lang, Oran and Tov, Omer and Chang, Huiwen and Dekel, Tali and Mosseri, Inbar and Irani, Michal},
  booktitle={CVPR},
  year={2023}
}

@article{wang2023diffusion,
  title={Diffusion model is secretly a training-free open vocabulary semantic segmenter},
  author={Wang, Jinglong and Li, Xiawei and Zhang, Jing and Xu, Qingyuan and Zhou, Qin and Yu, Qian and Sheng, Lu and Xu, Dong},
  journal={arXiv preprint arXiv:2309.02773},
  year={2023}
}

@article{chen2023robust,
  title={Robust classification via a single diffusion model},
  author={Chen, Huanran and Dong, Yinpeng and Wang, Zhengyi and Yang, Xiao and Duan, Chengqi and Su, Hang and Zhu, Jun},
  journal={arXiv preprint arXiv:2305.15241},
  year={2023}
}

@inproceedings{chen2023diffusiondet,
  title={Diffusiondet: Diffusion model for object detection},
  author={Chen, Shoufa and Sun, Peize and Song, Yibing and Luo, Ping},
  booktitle={ICCV},
  year={2023}
}

@article{zhang2023diffusionad,
  title={Diffusionad: Denoising diffusion for anomaly detection},
  author={Zhang, Hui and Wang, Zheng and Wu, Zuxuan and Jiang, Yu-Gang},
  journal={arXiv preprint arXiv:2303.08730},
  year={2023}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{cao2013recognize,
  title={Recognize human activities from partially observed videos},
  author={Cao, Yu and Barrett, Daniel and Barbu, Andrei and Narayanaswamy, Siddharth and Yu, Haonan and Michaux, Aaron and Lin, Yuewei and Dickinson, Sven and Mark Siskind, Jeffrey and Wang, Song},
  booktitle={CVPR},
  year={2013}
}

@inproceedings{lan2014hierarchical,
  title={A hierarchical representation for future action prediction},
  author={Lan, Tian and Chen, Tsung-Chuan and Savarese, Silvio},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part III 13},
  year={2014},
}

@inproceedings{lu2023vdt,
  title={Vdt: General-purpose video diffusion transformers via mask modeling},
  author={Lu, Haoyu and Yang, Guoxing and Fei, Nanyi and Huo, Yuqi and Lu, Zhiwu and Luo, Ping and Ding, Mingyu},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}


@inproceedings{ryali2023hiera,
  title={Hiera: A hierarchical vision transformer without the bells-and-whistles},
  author={Ryali, Chaitanya and Hu, Yuan-Ting and Bolya, Daniel and Wei, Chen and Fan, Haoqi and Huang, Po-Yao and Aggarwal, Vaibhav and Chowdhury, Arkabandhu and Poursaeed, Omid and Hoffman, Judy and others},
  booktitle={ICML},
  year={2023},
}

@inproceedings{wei2022masked,
  title={Masked feature prediction for self-supervised visual pre-training},
  author={Wei, Chen and Fan, Haoqi and Xie, Saining and Wu, Chao-Yuan and Yuille, Alan and Feichtenhofer, Christoph},
  booktitle={CVPR},
  year={2022}
}

@article{wang2022internvideo,
  title={Internvideo: General video foundation models via generative and discriminative learning},
  author={Wang, Yi and Li, Kunchang and Li, Yizhuo and He, Yinan and Huang, Bingkun and Zhao, Zhiyu and Zhang, Hongjie and Xu, Jilan and Liu, Yi and Wang, Zun and others},
  journal={arXiv preprint arXiv:2212.03191},
  year={2022}
}

@article{wang2024internvideo2,
  title={Internvideo2: Scaling video foundation models for multimodal video understanding},
  author={Wang, Yi and Li, Kunchang and Li, Xinhao and Yu, Jiashuo and He, Yinan and Chen, Guo and Pei, Baoqi and Zheng, Rongkun and Xu, Jilan and Wang, Zun and others},
  journal={arXiv preprint arXiv:2403.15377},
  year={2024}
}

@inproceedings{srivastava2024omnivec,
  title={Omnivec: Learning robust representations with cross modal sharing},
  author={Srivastava, Siddharth and Sharma, Gaurav},
  booktitle={WACV},
  year={2024}
}

@inproceedings{srivastava2024omnivec2,
  title={OmniVec2-A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning},
  author={Srivastava, Siddharth and Sharma, Gaurav},
  booktitle={CVPR},
  year={2024}
}


@inproceedings{weng2023open,
  title={Open-vclip: Transforming clip to an open-vocabulary video model via interpolated weight optimization},
  author={Weng, Zejia and Yang, Xitong and Li, Ang and Wu, Zuxuan and Jiang, Yu-Gang},
  booktitle={ICML},
  year={2023},
}

@article{wu2024building,
  title={Building an open-vocabulary video CLIP model with better architectures, optimization and data},
  author={Wu, Zuxuan and Weng, Zejia and Peng, Wujian and Yang, Xitong and Li, Ang and Davis, Larry S and Jiang, Yu-Gang},
  journal={TPAMI},
  year={2024},
}

@article{weng2023hcms,
  title={Hcms: Hierarchical and conditional modality selection for efficient video recognition},
  author={Weng, Zejia and Wu, Zuxuan and Li, Hengduo and Chen, Jingjing and Jiang, Yu-Gang},
  journal={ACM TOMM},
  year={2023},
}