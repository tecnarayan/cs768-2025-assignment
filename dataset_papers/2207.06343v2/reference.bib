@inproceedings{karimireddy2020scaffold,
  title={Scaffold: Stochastic controlled averaging for federated learning},
  author={Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
  booktitle={International Conference on Machine Learning},
  pages={5132--5143},
  year={2020},
  organization={PMLR}
}

@article{wei2022more,
  title={More Than a Toy: Random Matrix Models Predict How Real-World Neural Representations Generalize},
  author={Wei, Alexander and Hu, Wei and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2203.06176},
  year={2022}
}

@article{van2015lecture,
  title={Lecture notes on ridge regression},
  author={van Wieringen, Wessel N},
  journal={arXiv preprint arXiv:1509.09169},
  year={2015}
}


@article{xiao2017fashion,
  title={Fashion-{MNIST}: a novel image dataset for benchmarking machine learning algorithms},
  author={Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  journal={arXiv preprint arXiv:1708.07747},
  year={2017}
}


@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Citeseer}
}

@article{li2021federated,
  title={Federated learning on non-iid data silos: An experimental study},
  author={Li, Qinbin and Diao, Yiqun and Chen, Quan and He, Bingsheng},
  journal={arXiv preprint arXiv:2102.02079},
  year={2021}
}

@article{lin2020ensemble,
  title={Ensemble distillation for robust model fusion in federated learning},
  author={Lin, Tao and Kong, Lingjing and Stich, Sebastian U and Jaggi, Martin},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={2351--2363},
  year={2020}
}

@article{wang2020tackling,
  title={Tackling the objective inconsistency problem in heterogeneous federated optimization},
  author={Wang, Jianyu and Liu, Qinghua and Liang, Hao and Joshi, Gauri and Poor, H Vincent},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7611--7623},
  year={2020}
}

@inproceedings{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial Intelligence and Statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}


@article{he2022byzantine,
  title={Byzantine-robust decentralized learning via self-centered clipping},
  author={He, Lie and Karimireddy, Sai Praneeth and Jaggi, Martin},
  journal={arXiv preprint arXiv:2202.01545},
  year={2022}
}

@article{li2020federated,
  title={Federated optimization in heterogeneous networks},
  author={Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
  journal={Proceedings of Machine Learning and Systems},
  volume={2},
  pages={429--450},
  year={2020}
}

@article{kairouz2019federated,
  title={Advances and open problems in federated learning},
    author = {Peter Kairouz and
H. Brendan McMahan and
others},
journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={14},
  number={1--2},
  pages={1--210},
  year={2021},
  publisher={Now Publishers, Inc.}
}

@article{dean2012large,
  title={Large scale distributed deep networks},
  author={Dean, Jeffrey and Corrado, Greg and Monga, Rajat and Chen, Kai and Devin, Matthieu and Mao, Mark and Ranzato, Marc'aurelio and Senior, Andrew and Tucker, Paul and Yang, Ke and others},
  journal={Advances in Neural Information Processing Systems},
  volume={25},
  year={2012}
}

@inproceedings{iandola2016firecaffe,
  title={Firecaffe: near-linear acceleration of deep neural network training on compute clusters},
  author={Iandola, Forrest N and Moskewicz, Matthew W and Ashraf, Khalid and Keutzer, Kurt},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2592--2600},
  year={2016}
}

@article{goyal2017accurate,
  title={Accurate, large minibatch {SGD}: Training {I}magenet in 1 hour},
  author={Goyal, Priya and Doll{\'a}r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  journal={arXiv preprint arXiv:1706.02677},
  year={2017}
}



@article{jones2020nonrivalry,
    author = {Jones, Charles I and Tonetti, Christopher},
    journal = {American Economic Review},
    number = {9},
    pages = {2819--58},
    title = {Nonrivalry and the Economics of Data},
    volume = {110},
    year = {2020}
}

@misc{paml2020,
    author={Kulynych, Bogdan and Madras, David and Milli, Smitha and
            Raji, Inioluwa Deborah and Zhou, Angela and Zemel, Richard},
    title={Participatory Approaches to Machine Learning},
    howpublished={International Conference on Machine Learning Workshop},
    year={2020}
}



@article{mancini2021data,
  title={Data Portability, Interoperability and Digital Platform Competition: OECD Background Paper},
  author={Mancini, James},
  journal={Interoperability and Digital Platform Competition: OECD Background Paper (June 8, 2021)},
  year={2021}
}

@book{pentland2021building,
  title={Building the New Economy: Data as Capital},
  author={Pentland, Alex and Lipton, Alexander and Hardjono, Thomas},
  year={2021},
  publisher={MIT Press}
}


@article{wang2021field,
  title={A field guide to federated optimization},
  author={Wang, Jianyu and Charles, Zachary and Xu, Zheng and Joshi, Gauri and McMahan, H Brendan and Al-Shedivat, Maruan and Andrew, Galen and Avestimehr, Salman and Daly, Katharine and Data, Deepesh and others},
  journal={arXiv preprint arXiv:2107.06917},
  year={2021}
}

@inproceedings{
reddi2021adaptive,
title={Adaptive Federated Optimization},
author={Sashank J. Reddi and Zachary Charles and Manzil Zaheer and Zachary Garrett and Keith Rush and Jakub Kone{\v{c}}n{\'y} and Sanjiv Kumar and Hugh Brendan McMahan},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=LkFG3lB13U5}
}


@inproceedings{
acar2021federated,
title={Federated Learning Based on Dynamic Regularization},
author={Durmus Alp Emre Acar and Yue Zhao and Ramon Matas and Matthew Mattina and Paul Whatmough and Venkatesh Saligrama},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=B7v4QMR6Z9w}
}

@inproceedings{li2021model,
  title={Model-contrastive federated learning},
  author={Li, Qinbin and He, Bingsheng and Song, Dawn},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10713--10722},
  year={2021}
}

@article{afonin2021towards,
  title={Towards Model Agnostic Federated Learning Using Knowledge Distillation},
  author={Afonin, Andrei and Karimireddy, Sai Praneeth},
  journal={arXiv preprint arXiv:2110.15210},
  year={2021}
}

@inproceedings{hsieh2020non,
  title={The non-iid data quagmire of decentralized machine learning},
  author={Hsieh, Kevin and Phanishayee, Amar and Mutlu, Onur and Gibbons, Phillip},
  booktitle={International Conference on Machine Learning},
  pages={4387--4398},
  year={2020},
  organization={PMLR}
}

@article{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{lee2019wide,
  title={Wide neural networks of any depth evolve as linear models under gradient descent},
  author={Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel and Bahri, Yasaman and Novak, Roman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{karimireddy2020mime,
  title={Mime: Mimicking centralized stochastic algorithms in federated learning},
  author={Karimireddy, Sai Praneeth and Jaggi, Martin and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank J and Stich, Sebastian U and Suresh, Ananda Theertha},
  journal={arXiv preprint arXiv:2008.03606},
  year={2020}
}

@article{bonawitz2019towards,
  title={Towards federated learning at scale: System design},
  author={Bonawitz, Keith and Eichner, Hubert and Grieskamp, Wolfgang and Huba, Dzmitry and Ingerman, Alex and Ivanov, Vladimir and Kiddon, Chloe and Kone{\v{c}}n{\`y}, Jakub and Mazzocchi, Stefano and McMahan, Brendan and others},
  journal={Proceedings of Machine Learning and Systems},
  volume={1},
  pages={374--388},
  year={2019}
}

@article{bonawitz2021federated,
  title={Federated Learning and Privacy: Building privacy-preserving systems for machine learning and data science on decentralized data},
  author={Bonawitz, Kallista and Kairouz, Peter and McMahan, Brendan and Ramage, Daniel},
  journal={Queue},
  volume={19},
  number={5},
  pages={87--114},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{ramaswamy2020training,
  title={Training production language models without memorizing user data},
  author={Ramaswamy, Swaroop and Thakkar, Om and Mathews, Rajiv and Andrew, Galen and McMahan, H Brendan and Beaufays, Fran{\c{c}}oise},
  journal={arXiv preprint arXiv:2009.10031},
  year={2020}
}

@article{conger2018uber,
  title={Uber settles data breach investigation for \$148 million},
  author={Conger, Kate},
  journal={The New York Times},
  year={2018}
}

@article{satariano2019google,
  title={Google is fined \$57 million under Europeâ€™s data privacy law},
  author={Satariano, Adam},
  journal={The New York Times},
  volume={21},
  year={2019}
}

@article{li2019federated,
  title={Federated Learning Systems: Vision, Hype and Reality for Data Privacy and Protection.},
  author={Li, Qinbin and Wen, Zeyi and He, Bingsheng},
  year={2019}
}

@inproceedings{mohri2019agnostic,
  title={Agnostic federated learning},
  author={Mohri, Mehryar and Sivek, Gary and Suresh, Ananda Theertha},
  booktitle={International Conference on Machine Learning},
  pages={4615--4625},
  year={2019},
  organization={PMLR}
}

@article{li2019fair,
  title={Fair resource allocation in federated learning},
  author={Li, Tian and Sanjabi, Maziar and Beirami, Ahmad and Smith, Virginia},
  journal={arXiv preprint arXiv:1905.10497},
  year={2019}
}

@article{shi2021survey,
  title={A Survey of Fairness-Aware Federated Learning},
  author={Shi, Yuxin and Yu, Han and Leung, Cyril},
  journal={arXiv preprint arXiv:2111.01872},
  year={2021}
}
@inproceedings{bonawitz2017practical,
  title={Practical secure aggregation for privacy-preserving machine learning},
  author={Bonawitz, Keith and Ivanov, Vladimir and Kreuter, Ben and Marcedone, Antonio and McMahan, H Brendan and Patel, Sarvar and Ramage, Daniel and Segal, Aaron and Seth, Karn},
  booktitle={Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security},
  pages={1175--1191},
  year={2017}
}


@inproceedings{fang2020local,
  title={Local Model Poisoning Attacks to $\{$Byzantine-Robust$\}$ Federated Learning},
  author={Fang, Minghong and Cao, Xiaoyu and Jia, Jinyuan and Gong, Neil},
  booktitle={29th USENIX Security Symposium (USENIX Security 20)},
  pages={1605--1622},
  year={2020}
}

@article{so2020byzantine,
  title={Byzantine-resilient secure federated learning},
  author={So, Jinhyun and G{\"u}ler, Ba{\c{s}}ak and Avestimehr, A Salman},
  journal={IEEE Journal on Selected Areas in Communications},
  volume={39},
  number={7},
  pages={2168--2181},
  year={2020},
  publisher={IEEE}
}

@inproceedings{karimireddy2022byzantine,
  title={Byzantine-Robust Learning on Heterogeneous Datasets via Bucketing},
  author={Karimireddy, Sai Praneeth and He, Lie and Jaggi, Martin},
  booktitle={International Conference on Learning Representations},
    year={2021},
}

@article{blanchard2017machine,
  title={Machine learning with adversaries: Byzantine tolerant gradient descent},
  author={Blanchard, Peva and El Mhamdi, El Mahdi and Guerraoui, Rachid and Stainer, Julien},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@inproceedings{bagdasaryan2020backdoor,
  title={How to backdoor federated learning},
  author={Bagdasaryan, Eugene and Veit, Andreas and Hua, Yiqing and Estrin, Deborah and Shmatikov, Vitaly},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2938--2948},
  year={2020},
  organization={PMLR}
}

@article{mothukuri2021survey,
  title={A survey on security and privacy of federated learning},
  author={Mothukuri, Viraaji and Parizi, Reza M and Pouriyeh, Seyedamin and Huang, Yan and Dehghantanha, Ali and Srivastava, Gautam},
  journal={Future Generation Computer Systems},
  volume={115},
  pages={619--640},
  year={2021},
  publisher={Elsevier}
}

@article{fung2018mitigating,
  title={Mitigating sybils in federated learning poisoning},
  author={Fung, Clement and Yoon, Chris JM and Beschastnikh, Ivan},
  journal={arXiv preprint arXiv:1808.04866},
  year={2018}
}

@article{wang2020attack,
  title={Attack of the tails: Yes, you really can backdoor federated learning},
  author={Wang, Hongyi and Sreenivasan, Kartik and Rajput, Shashank and Vishwakarma, Harit and Agarwal, Saurabh and Sohn, Jy-yong and Lee, Kangwook and Papailiopoulos, Dimitris},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={16070--16084},
  year={2020}
}

@article{sun2019can,
  title={Can you really backdoor federated learning?},
  author={Sun, Ziteng and Kairouz, Peter and Suresh, Ananda Theertha and McMahan, H Brendan},
  journal={arXiv preprint arXiv:1911.07963},
  year={2019}
}

@article{lyu2020threats,
  title={Threats to federated learning: A survey},
  author={Lyu, Lingjuan and Yu, Han and Yang, Qiang},
  journal={arXiv preprint arXiv:2003.02133},
  year={2020}
}


@article{ozkara2021quped,
  title={QuPeD: Quantized Personalization via Distillation with Applications to Federated Learning},
  author={Ozkara, Kaan and Singh, Navjot and Data, Deepesh and Diggavi, Suhas},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}


@article{deng2020adaptive,
  title={Adaptive personalized federated learning},
  author={Deng, Yuyang and Kamani, Mohammad Mahdi and Mahdavi, Mehrdad},
  journal={arXiv preprint arXiv:2003.13461},
  year={2020}
}

@article{fallah2020personalized,
  title={Personalized federated learning: A meta-learning approach},
  author={Fallah, Alireza and Mokhtari, Aryan and Ozdaglar, Asuman},
  journal={arXiv preprint arXiv:2002.07948},
  year={2020}
}

@article{wu2020personalized,
  title={Personalized federated learning for intelligent {IoT} applications: A cloud-edge based framework},
  author={Wu, Qiong and He, Kaiwen and Chen, Xu},
  journal={IEEE Open Journal of the Computer Society},
  volume={1},
  pages={35--44},
  year={2020},
  publisher={IEEE}
}

@inproceedings{collins2021exploiting,
  title={Exploiting shared representations for personalized federated learning},
  author={Collins, Liam and Hassani, Hamed and Mokhtari, Aryan and Shakkottai, Sanjay},
  booktitle={International Conference on Machine Learning},
  pages={2089--2099},
  year={2021},
  organization={PMLR}
}

@inproceedings{kulkarni2020survey,
  title={Survey of personalization techniques for federated learning},
  author={Kulkarni, Viraj and Kulkarni, Milind and Pant, Aniruddha},
  booktitle={2020 Fourth World Conference on Smart Trends in Systems, Security and Sustainability (WorldS4)},
  pages={794--797},
  year={2020},
  organization={IEEE}
}

@inproceedings{suresh2017distributed,
  title={Distributed mean estimation with limited communication},
  author={Suresh, Ananda Theertha and Felix, X Yu and Kumar, Sanjiv and McMahan, H Brendan},
  booktitle={International Conference on Machine Learning},
  pages={3329--3337},
  year={2017},
  organization={PMLR}
}

@article{stich2020error,
  title={The error-feedback framework: Better rates for sgd with delayed gradients and compressed updates},
  author={Stich, Sebastian U and Karimireddy, Sai Praneeth},
  journal={Journal of Machine Learning Research},
  volume={21},
  pages={1--36},
  year={2020}
}

@article{long2021properties,
  title={Properties of the after kernel},
  author={Long, Philip M},
  journal={arXiv preprint arXiv:2105.10585},
  year={2021}
}


@inproceedings{haddadpour2021federated,
  title={Federated learning with compression: Unified analysis and sharp guarantees},
  author={Haddadpour, Farzin and Kamani, Mohammad Mahdi and Mokhtari, Aryan and Mahdavi, Mehrdad},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2350--2358},
  year={2021},
  organization={PMLR}
}

@article{alistarh2017qsgd,
  title={{QSGD}: Communication-efficient {SGD} via gradient quantization and encoding},
  author={Alistarh, Dan and Grubic, Demjan and Li, Jerry and Tomioka, Ryota and Vojnovic, Milan},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{du2022flamby,
  title={FLamby: Datasets and Benchmarks for Cross-Silo Federated Learning in Realistic Settings},
  author={du Terrail, Jean Ogier and Ayed, Samy-Safwan and Cyffers, Edwige and Grimberg, Felix and He, Chaoyang and Loeb, Regis and Mangold, Paul and Marchand, Tanguy and Marfoq, Othmane and Mushtaq, Erum and others},
  year={2022}
}

@article{goldblum2019truth,
  title={Truth or backpropaganda? An empirical investigation of deep learning theory},
  author={Goldblum, Micah and Geiping, Jonas and Schwarzschild, Avi and Moeller, Michael and Goldstein, Tom},
  journal={arXiv preprint arXiv:1910.00359},
  year={2019}
}

@article{mu2020gradients,
  title={Gradients as features for deep representation learning},
  author={Mu, Fangzhou and Liang, Yingyu and Li, Yin},
  journal={arXiv preprint arXiv:2004.05529},
  year={2020}
}

@inproceedings{achille2021lqf,
  title={Lqf: Linear quadratic fine-tuning},
  author={Achille, Alessandro and Golatkar, Aditya and Ravichandran, Avinash and Polito, Marzia and Soatto, Stefano},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15729--15739},
  year={2021}
}

@article{bai2020taylorized,
  title={Taylorized training: Towards better approximation of neural network training at finite width},
  author={Bai, Yu and Krause, Ben and Wang, Huan and Xiong, Caiming and Socher, Richard},
  journal={arXiv preprint arXiv:2002.04010},
  year={2020}
}

@article{zancato2020predicting,
  title={Predicting training time without training},
  author={Zancato, Luca and Achille, Alessandro and Ravichandran, Avinash and Bhotika, Rahul and Soatto, Stefano},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6136--6146},
  year={2020}
}

@inproceedings{avron17sharper,
  author    = {Haim Avron and
               Kenneth L. Clarkson and
               David P. Woodruff},
  title     = {Sharper Bounds for Regularized Data Fitting},
  booktitle = {Approximation, Randomization, and Combinatorial Optimization. Algorithms
               and Techniques, {}}},
  volume    = {81},
  pages     = {27:1--27:22},
  year      = {2017},
}



@article{woodworth2020minibatch,
  title={Minibatch vs local sgd for heterogeneous distributed learning},
  author={Woodworth, Blake E and Patel, Kumar Kshitij and Srebro, Nati},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6281--6292},
  year={2020}
}

@article{johnson2013accelerating,
  title={Accelerating stochastic gradient descent using predictive variance reduction},
  author={Johnson, Rie and Zhang, Tong},
  journal={Advances in Neural Information Processing Systems},
  volume={26},
  year={2013}
}

@article{defazio2014saga,
  title={SAGA: A fast incremental gradient method with support for non-strongly convex composite objectives},
  author={Defazio, Aaron and Bach, Francis and Lacoste-Julien, Simon},
  journal={Advances in Neural Information Processing Systems},
  volume={27},
  year={2014}
}

@article{mishchenko2022proxskip,
  title={ProxSkip: Yes! Local Gradient Steps Provably Lead to Communication Acceleration! Finally!},
  author={Mishchenko, Konstantin and Malinovsky, Grigory and Stich, Sebastian and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:2202.09357},
  year={2022}
}

@article{hsu2019measuring,
  title={Measuring the effects of non-identical data distribution for federated visual classification},
  author={Hsu, Tzu-Ming Harry and Qi, Hang and Brown, Matthew},
  journal={arXiv preprint arXiv:1909.06335},
  year={2019}
}

@article{wang2019slowmo,
  title={SlowMo: Improving communication-efficient distributed SGD with slow momentum},
  author={Wang, Jianyu and Tantia, Vinayak and Ballas, Nicolas and Rabbat, Michael},
  journal={arXiv preprint arXiv:1910.00643},
  year={2019}
}

@article{charles2021large,
  title={On large-cohort training for federated learning},
  author={Charles, Zachary and Garrett, Zachary and Huo, Zhouyuan and Shmulyian, Sergei and Smith, Virginia},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{wang2019adaptive,
  title={Adaptive federated learning in resource constrained edge computing systems},
  author={Wang, Shiqiang and Tuor, Tiffany and Salonidis, Theodoros and Leung, Kin K and Makaya, Christian and He, Ting and Chan, Kevin},
  journal={IEEE Journal on Selected Areas in Communications},
  volume={37},
  number={6},
  pages={1205--1221},
  year={2019},
  publisher={IEEE}
}

@article{singh2020model,
  title={Model fusion via optimal transport},
  author={Singh, Sidak Pal and Jaggi, Martin},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={22045--22055},
  year={2020}
}

@inproceedings{yu2021fed2,
  title={Fed2: Feature-Aligned Federated Learning},
  author={Yu, Fuxun and Zhang, Weishan and Qin, Zhuwei and Xu, Zirui and Wang, Di and Liu, Chenchen and Tian, Zhi and Chen, Xiang},
  booktitle={Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
  pages={2066--2074},
  year={2021}
}



@article{tan2021fedproto,
  title={Fedproto: Federated prototype learning over heterogeneous devices},
  author={Tan, Yue and Long, Guodong and Liu, Lu and Zhou, Tianyi and Lu, Qinghua and Jiang, Jing and Zhang, Chengqi},
  journal={arXiv preprint arXiv:2105.00243},
  year={2021}
}

@article{wortsman2022model,
  title={Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Gadre, Samir Yitzhak and Roelofs, Rebecca and Gontijo-Lopes, Raphael and Morcos, Ari S and Namkoong, Hongseok and Farhadi, Ali and Carmon, Yair and Kornblith, Simon and others},
  journal={arXiv preprint arXiv:2203.05482},
  year={2022}
}

@article{izmailov2018averaging,
  title={Averaging weights leads to wider optima and better generalization},
  author={Izmailov, Pavel and Podoprikhin, Dmitrii and Garipov, Timur and Vetrov, Dmitry and Wilson, Andrew Gordon},
  journal={arXiv preprint arXiv:1803.05407},
  year={2018}
}

@article{lin2021quasi,
  title={Quasi-global momentum: Accelerating decentralized deep learning on heterogeneous data},
  author={Lin, Tao and Karimireddy, Sai Praneeth and Stich, Sebastian U and Jaggi, Martin},
  journal={arXiv preprint arXiv:2102.04761},
  year={2021}
}

@article{yu2022predicting,
  title={Predicting Out-of-Distribution Error with the Projection Norm},
  author={Yu, Yaodong and Yang, Zitong and Wei, Alexander and Ma, Yi and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2202.05834},
  year={2022}
}

@inproceedings{eichner2019semi,
  title={Semi-cyclic stochastic gradient descent},
  author={Eichner, Hubert and Koren, Tomer and McMahan, Brendan and Srebro, Nathan and Talwar, Kunal},
  booktitle={International Conference on Machine Learning},
  pages={1764--1773},
  year={2019},
  organization={PMLR}
}

@article{ryabinin2020towards,
  title={Towards crowdsourced training of large neural networks using decentralized mixture-of-experts},
  author={Ryabinin, Max and Gusev, Anton},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3659--3672},
  year={2020}
}

@article{collins2022maml,
  title={MAML and ANIL provably learn representations},
  author={Collins, Liam and Mokhtari, Aryan and Oh, Sewoong and Shakkottai, Sanjay},
  journal={arXiv preprint arXiv:2202.03483},
  year={2022}
}

@article{dwork2014algorithmic,
  title={The algorithmic foundations of differential privacy.},
  author={Dwork, Cynthia and Roth, Aaron and others},
  journal={Found. Trends Theor. Comput. Sci.},
  volume={9},
  number={3-4},
  pages={211--407},
  year={2014}
}


@inproceedings{gulrajani2020search,
  title={In Search of Lost Domain Generalization},
  author={Gulrajani, Ishaan and Lopez-Paz, David},
  booktitle={International Conference on Learning Representations},
  year={2020}
}


@inproceedings{
yuan2022what,
title={What Do We Mean by Generalization in Federated Learning?},
author={Honglin Yuan and Warren Richard Morningstar and Lin Ning and Karan Singhal},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=VimqQq-i_Q}
}


@inproceedings{fortntk,
 author = {Fort, Stanislav and Dziugaite, Gintare Karolina and Paul, Mansheej and Kharaghani, Sepideh and Roy, Daniel M and Ganguli, Surya},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {5850--5861},
 title = {Deep learning versus kernel learning: an empirical study of loss landscape geometry and the time evolution of the Neural Tangent Kernel},
 volume = {33},
 year = {2020}
}

@article{hui2020evaluation,
  title={Evaluation of neural architectures trained with square loss vs cross-entropy in classification tasks},
  author={Hui, Like and Belkin, Mikhail},
  journal={arXiv preprint arXiv:2006.07322},
  year={2020}
}



@article{chayti2022optimization,
  title={Optimization with access to auxiliary information},
  author={Chayti, El Mahdi and Karimireddy, Sai Praneeth},
  journal={arXiv preprint arXiv:2206.00395},
  year={2022}
}


@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={PMLR}
}


@inproceedings{wu2018group,
  title={Group normalization},
  author={Wu, Yuxin and He, Kaiming},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={3--19},
  year={2018}
}


@article{wang2022unreasonable,
  title={On the Unreasonable Effectiveness of Federated Averaging with Heterogeneous Data},
  author={Wang, Jianyu and Das, Rudrajit and Joshi, Gauri and Kale, Satyen and Xu, Zheng and Zhang, Tong},
  journal={arXiv preprint arXiv:2206.04723},
  year={2022}
}
