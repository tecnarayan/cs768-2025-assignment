@inproceedings{
keskar2017on,
title={On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima},
author={Nitish Shirish Keskar and Dheevatsa Mudigere and Jorge Nocedal and Mikhail Smelyanskiy and Ping Tak Peter Tang},
booktitle={Proc.~ICLR'17},
year={2017}
}

@article{kamri2022worst,
  title={On the Worst-Case Analysis of Cyclic Coordinate-Wise Algorithms on Smooth Convex Functions},
  author={Kamri, Yassine and Hendrickx, Julien M and Glineur, Fran{\c{c}}ois},
  journal={arXiv preprint arXiv:2211.17018},
  year={2022}
}

@inproceedings{
miyato2018spectral,
title={Spectral Normalization for Generative Adversarial Networks},
author={Takeru Miyato and Toshiki Kataoka and Masanori Koyama and Yuichi Yoshida},
booktitle={Proc.~ICLR'18},
year={2018}
}

@inproceedings{tibshirani2017dykstra,
  title={Dykstra's algorithm, ADMM, and coordinate descent: Connections, insights, and extensions},
  author={Tibshirani, Ryan J},
  booktitle={Proc.~NeurIPS'17},
  year={2017}
}

@article{vandaele2016efficient,
  title={Efficient and non-convex coordinate descent for symmetric nonnegative matrix factorization},
  author={Vandaele, Arnaud and Gillis, Nicolas and Lei, Qi and Zhong, Kai and Dhillon, Inderjit},
  journal={IEEE Transactions on Signal Processing},
  volume={64},
  number={21},
  pages={5571--5584},
  year={2016},
  publisher={IEEE}
}

@article{zeng2020coordinate,
  title={Coordinate descent algorithms for phase retrieval},
  author={Zeng, Wen-Jun and So, Hing-Cheung},
  journal={Signal Processing},
  volume={169},
  pages={107418},
  year={2020},
  publisher={Elsevier}
}

@article{nie2021coordinate,
  title={Coordinate Descent Method for $ k $ k-means},
  author={Nie, Feiping and Xue, Jingjing and Wu, Danyang and Wang, Rong and Li, Hui and Li, Xuelong},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={44},
  number={5},
  pages={2371--2385},
  year={2021},
  publisher={IEEE}
}

@inproceedings{li2017provable,
  title={Provable alternating gradient descent for non-negative matrix factorization with strong correlations},
  author={Li, Yuanzhi and Liang, Yingyu},
  booktitle={Proc.~ICML'17},
  year={2017},
  organization={PMLR}
}

@article{hoffman2013stochastic,
  title={Stochastic variational inference},
  author={Hoffman, Matthew D and Blei, David M and Wang, Chong and Paisley, John},
  journal={Journal of Machine Learning Research},
  year={2013}
}

@article{blei2017variational,
  title={Variational inference: A review for statisticians},
  author={Blei, David M and Kucukelbir, Alp and McAuliffe, Jon D},
  journal={Journal of the American statistical Association},
  volume={112},
  number={518},
  pages={859--877},
  year={2017},
  publisher={Taylor \& Francis}
}

@article{tzikas2008variational,
  title={The variational approximation for Bayesian inference},
  author={Tzikas, Dimitris G and Likas, Aristidis C and Galatsanos, Nikolaos P},
  journal={IEEE Signal Processing Magazine},
  volume={25},
  number={6},
  pages={131--146},
  year={2008},
  publisher={IEEE}
}

@article{plummer2020dynamics,
  title={Dynamics of coordinate ascent variational inference: A case study in 2d ising models},
  author={Plummer, Sean and Pati, Debdeep and Bhattacharya, Anirban},
  journal={Entropy},
  volume={22},
  number={11},
  pages={1263},
  year={2020},
  publisher={MDPI}
}


@article{driggs2020spring,
author = {Driggs, Derek and Tang, Junqi and Liang, Jingwei and Davies, Mike and Sch\"{o}nlieb, Carola-Bibiane},
title = {A Stochastic Proximal Alternating Minimization for Nonsmooth and Nonconvex Optimization},
journal = {SIAM Journal on Imaging Sciences},
volume = {14},
number = {4},
pages = {1932-1970},
year = {2021}
}


@inproceedings{zheng2016fast,
  title={Fast-and-Light Stochastic ADMM.},
  author={Zheng, Shuai and Kwok, James T},
  booktitle={Proc.~IJCAI'16},
  year={2016}
}

@article{zeng2014cyclic,
  title={A Cyclic Coordinate Descent Algorithm for lq Regularization},
  author={Zeng, Jinshan and Peng, Zhimin and Lin, Shaobo and Xu, Zongben},
  journal={arXiv preprint arXiv:1408.0578},
  year={2014}
}

@inproceedings{hanzely2020variance,
  title={Variance reduced coordinate descent with acceleration: New method with a surprising application to finite-sum problems},
  author={Hanzely, Filip and Kovalev, Dmitry and Richt{\'a}rik, Peter},
  booktitle={Proc.~ICML'20},
  year={2020}
}

@article{aberdam2022accelerated,
  title={An Accelerated Coordinate Gradient Descent Algorithm for Non-separable Composite Optimization},
  author={Aberdam, Aviad and Beck, Amir},
  journal={Journal of Optimization Theory and Applications},
  volume={193},
  number={1},
  pages={219--246},
  year={2022},
  publisher={Springer}
}

@inproceedings{gorbunov2020unified,
  title={A unified theory of SGD: Variance reduction, sampling, quantization and coordinate descent},
  author={Gorbunov, Eduard and Hanzely, Filip and Richt{\'a}rik, Peter},
  booktitle={Proc.~AISTATS'20},
  year={2020}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Citeseer}
}

@inproceedings{loshchilov2016sgdr,
  author    = {Ilya Loshchilov and
               Frank Hutter},
  title     = {{SGDR:} Stochastic Gradient Descent with Warm Restarts},
  booktitle = {Proc.~ICLR'17,},
  year      = {2017}
}

@inproceedings{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  booktitle={Proc.~NeurIPS'19},
  year={2019}
}

@article{tseng2001convergence,
  title={Convergence of a block coordinate descent method for nondifferentiable minimization},
  author={Tseng, Paul},
  journal={Journal of Optimization Theory and Applications},
  volume={109},
  number={3},
  pages={475--494},
  year={2001},
  publisher={Springer}
}

@article{grippof1999globally,
  title={Globally convergent block-coordinate techniques for unconstrained optimization},
  author={Grippof, Luigi and Sciandrone, Marco},
  journal={Optimization Methods and Software},
  volume={10},
  number={4},
  pages={587--637},
  year={1999},
  publisher={Taylor \& Francis}
}

@article{chow2017cyclic,
  title={Cyclic coordinate-update algorithms for fixed-point problems: Analysis and applications},
  author={Chow, Yat Tin and Wu, Tianyu and Yin, Wotao},
  journal={SIAM Journal on Scientific Computing},
  volume={39},
  number={4},
  pages={A1280--A1300},
  year={2017},
  publisher={SIAM}
}

@article{chen2021global,
  title={On the global convergence of randomized coordinate gradient descent for non-convex optimization},
  author={Chen, Ziang and Li, Yingzhou and Lu, Jianfeng},
  journal={arXiv preprint arXiv:2101.01323},
  year={2021}
}

@article{khorram2021stochastic,
  title={Stochastic Block-{ADMM} for Training Deep Networks},
  author={Khorram, Saeed and Fu, Xiao and Danesh, Mohamad H and Qi, Zhongang and Fuxin, Li},
  journal={arXiv preprint arXiv:2105.00339},
  year={2021}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proc.~CVPR'16},
  year={2016}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={IEEE}
}

@inproceedings{wang2016randomized,
  title={Randomized block coordinate descendant STRONG for large-scale stochastic optimization},
  author={Wang, Wenyu and Wan, Hong and Chang, Kuo-Hao},
  booktitle={Proc.~WSC'16},
  year={2016},
}

@article{lei2020asynchronous,
  title={Asynchronous variance-reduced block schemes for composite non-convex stochastic optimization: block-specific steplengths and adapted batch-sizes},
  author={Lei, Jinlong and Shanbhag, Uday V},
  journal={Optimization Methods and Software},
  pages={1--31},
  year={2020},
  publisher={Taylor \& Francis}
}

@inproceedings{chauhan2017mini,
  title={Mini-batch block-coordinate based stochastic average adjusted gradient methods to solve big data problems},
  author={Chauhan, Vinod Kumar and Dahiya, Kalpana and Sharma, Anuj},
  booktitle={Proc.~ACML'16},
  year={2017}
}

@inproceedings{chen2016accelerated,
  title={Accelerated Stochastic Block Coordinate Gradient Descent for Sparsity Constrained Nonconvex Optimization.},
  author={Chen, Jinghui and Gu, Quanquan},
  booktitle={Proc.~UAI'16},
  year={2016}
}

@article{fu2020block,
  title={Block-randomized stochastic proximal gradient for low-rank tensor factorization},
  author={Fu, Xiao and Ibrahim, Shahana and Wai, Hoi-To and Gao, Cheng and Huang, Kejun},
  journal={IEEE Transactions on Signal Processing},
  volume={68},
  pages={2170--2185},
  year={2020},
  publisher={IEEE}
}

@article{nakamura2021block,
  title={Block-cyclic stochastic coordinate descent for deep neural networks},
  author={Nakamura, Kensuke and Soatto, Stefano and Hong, Byung-Woo},
  journal={Neural Networks},
  volume={139},
  pages={348--357},
  year={2021},
  publisher={Elsevier}
}

@article{razaviyayn2013unified,
  title={A unified convergence analysis of block successive minimization methods for nonsmooth optimization},
  author={Razaviyayn, Meisam and Hong, Mingyi and Luo, Zhi-Quan},
  journal={SIAM Journal on Optimization},
  volume={23},
  number={2},
  pages={1126--1153},
  year={2013},
  publisher={SIAM}
}

@incollection{wen2012block,
  title={Block coordinate descent methods for semidefinite programming},
  author={Wen, Zaiwen and Goldfarb, Donald and Scheinberg, Katya},
  booktitle={Handbook on Semidefinite, Conic and Polynomial Optimization},
  pages={533--564},
  year={2012},
  publisher={Springer}
}

@inproceedings{peng2013parallel,
  title={Parallel and distributed sparse optimization},
  author={Peng, Zhimin and Yan, Ming and Yin, Wotao},
  booktitle={2013 Asilomar Conference on Signals, Systems and Computers},
  year={2013}
}

@article{chang2008coordinate,
  title={Coordinate descent method for large-scale l2-loss linear support vector machines.},
  author={Chang, Kai-Wei and Hsieh, Cho-Jui and Lin, Chih-Jen},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={7},
  year={2008}
}

@inproceedings{nutini2015coordinate,
  title={Coordinate descent converges faster with the {G}auss-{S}outhwell rule than random selection},
  author={Nutini, Julie and Schmidt, Mark and Laradji, Issam and Friedlander, Michael and Koepke, Hoyt},
  booktitle={Proc.~ICML'15},
  year={2015}
}

@article{nesterov2017efficiency,
  title={Efficiency of the accelerated coordinate descent method on structured optimization problems},
  author={Nesterov, Yurii and Stich, Sebastian U},
  journal={SIAM Journal on Optimization},
  volume={27},
  number={1},
  pages={110--123},
  year={2017},
  publisher={SIAM}
}


@article{saha2013nonasymptotic,
  title={On the nonasymptotic convergence of cyclic coordinate descent methods},
  author={Saha, Ankan and Tewari, Ambuj},
  journal={SIAM Journal on Optimization},
  volume={23},
  number={1},
  pages={576--601},
  year={2013},
  publisher={SIAM}
}

@article{richtarik2014iteration,
  title={Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function},
  author={Richt{\'a}rik, Peter and Tak{\'a}{\v{c}}, Martin},
  journal={Mathematical Programming},
  volume={144},
  number={1},
  pages={1--38},
  year={2014},
  publisher={Springer}
}

@article{lu2015complexity,
  title={On the complexity analysis of randomized block-coordinate descent methods},
  author={Lu, Zhaosong and Xiao, Lin},
  journal={Mathematical Programming},
  volume={152},
  number={1},
  pages={615--642},
  year={2015},
  publisher={Springer}
}

@article{hong2017iteration,
  title={Iteration complexity analysis of block coordinate descent methods},
  author={Hong, Mingyi and Wang, Xiangfeng and Razaviyayn, Meisam and Luo, Zhi-Quan},
  journal={Mathematical Programming},
  volume={163},
  number={1},
  pages={85--114},
  year={2017},
  publisher={Springer}
}

@article{beck2013convergence,
  title={On the convergence of block coordinate descent type methods},
  author={Beck, Amir and Tetruashvili, Luba},
  journal={SIAM journal on Optimization},
  volume={23},
  number={4},
  pages={2037--2060},
  year={2013},
  publisher={SIAM}
}

@inproceedings{diakonikolas2018alternating,
  title={Alternating randomized block coordinate descent},
  author={Diakonikolas, Jelena and Orecchia, Lorenzo},
  booktitle={Proc.~ICML'18},
  year={2018}
}

@inproceedings{gurbuzbalaban2017cyclic,
  title={When cyclic coordinate descent outperforms randomized coordinate descent},
  author={Gurbuzbalaban, Mert and Ozdaglar, Asuman and Parrilo, Pablo A and Vanli, Nuri},
  booktitle={Proc.~NeurIPS'17},
  year={2017}
}

@inproceedings{alacaoglu2017smooth,
  title={Smooth primal-dual coordinate descent algorithms for nonsmooth convex optimization},
  author={Alacaoglu, Ahmet and Tran Dinh, Quoc and Fercoq, Olivier and Cevher, Volkan},
  booktitle={Proc.~NeurIPS'17},
  year={2017}
}

@inproceedings{allen2016even,
  title={Even faster accelerated coordinate descent using non-uniform sampling},
  author={Allen-Zhu, Zeyuan and Qu, Zheng and Richt{\'a}rik, Peter and Yuan, Yang},
  booktitle={Proc.~ICML'16},
  year={2016}
}

@article{lin2015accelerated,
  title={An accelerated randomized proximal coordinate gradient method and its application to regularized empirical risk minimization},
  author={Lin, Qihang and Lu, Zhaosong and Xiao, Lin},
  journal={SIAM Journal on Optimization},
  volume={25},
  number={4},
  pages={2244--2273},
  year={2015},
  publisher={SIAM}
}

@article{friedman2010regularization,
  title={Regularization paths for generalized linear models via coordinate descent},
  author={Friedman, Jerome and Hastie, Trevor and Tibshirani, Rob},
  journal={Journal of Statistical Software},
  volume={33},
  number={1},
  pages={1},
  year={2010},
  publisher={NIH Public Access}
}

@article{wu2008coordinate,
  title={Coordinate descent algorithms for lasso penalized regression},
  author={Wu, Tong Tong and Lange, Kenneth},
  journal={The Annals of Applied Statistics},
  volume={2},
  number={1},
  pages={224--244},
  year={2008},
  publisher={Institute of Mathematical Statistics}
}

@article{xu2015block,
  title={Block stochastic gradient iteration for convex and nonconvex optimization},
  author={Xu, Yangyang and Yin, Wotao},
  journal={SIAM Journal on Optimization},
  volume={25},
  number={3},
  pages={1686--1716},
  year={2015},
  publisher={SIAM}
}

@article{nesterov2012efficiency,
  title={Efficiency of coordinate descent methods on huge-scale optimization problems},
  author={Nesterov, Yu},
  journal={SIAM Journal on Optimization},
  volume={22},
  number={2},
  pages={341--362},
  year={2012},
  publisher={SIAM}
}

@article{song2021fast,
  title={Fast Cyclic Coordinate Dual Averaging with Extrapolation for Generalized Variational Inequalities},
  author={Song, Chaobing and Diakonikolas, Jelena},
  journal={arXiv preprint arXiv:2102.13244},
  year={2021}
}


@article{mazumder2011sparsenet,
  title={Sparsenet: Coordinate descent with nonconvex penalties},
  author={Mazumder, Rahul and Friedman, Jerome H and Hastie, Trevor},
  journal={Journal of the American Statistical Association},
  volume={106},
  number={495},
  pages={1125--1138},
  year={2011},
  publisher={Taylor \& Francis}
}

@article{xu2017globally,
  title={A globally convergent algorithm for nonconvex optimization based on block coordinate update},
  author={Xu, Yangyang and Yin, Wotao},
  journal={Journal of Scientific Computing},
  volume={72},
  number={2},
  pages={700--734},
  year={2017},
  publisher={Springer}
}


@inproceedings{zhang2017convergence,
  title={On the convergence of block coordinate descent in training DNNs with Tikhonov regularization},
  author={Zhang, Ziming and Brand, Matthew},
  booktitle={Proc.~NeurIPS'17},
  year={2017}
}

@article{patrascu2015efficient,
  title={Efficient random coordinate descent algorithms for large-scale structured nonconvex optimization},
  author={Patrascu, Andrei and Necoara, Ion},
  journal={Journal of Global Optimization},
  volume={61},
  number={1},
  pages={19--46},
  year={2015},
  publisher={Springer}
}

@inproceedings{zeng2019global,
  title={Global convergence of block coordinate descent in deep learning},
  author={Zeng, Jinshan and Lau, Tim Tsz-Kit and Lin, Shaobo and Yao, Yuan},
  booktitle={Proc.~NeurIPS'19},
  year={2019}
}

@article{yang2019inexact,
  title={Inexact block coordinate descent algorithms for nonsmooth nonconvex optimization},
  author={Yang, Yang and Pesavento, Marius and Luo, Zhi-Quan and Ottersten, Bj{\"o}rn},
  journal={IEEE Transactions on Signal Processing},
  volume={68},
  pages={947--961},
  year={2019},
  publisher={IEEE}
}

@article{lyu2020convergence,
  title={Convergence of block coordinate descent with diminishing radius for nonconvex optimization},
  author={Lyu, Hanbaek},
  journal={arXiv preprint arXiv:2012.03503},
  year={2020}
}

@article{wright2015coordinate,
  title={Coordinate descent algorithms},
  author={Wright, Stephen J},
  journal={Mathematical Programming},
  volume={151},
  number={1},
  pages={3--34},
  year={2015},
  publisher={Springer}
}

@article{shi2016primer,
  title={A primer on coordinate descent algorithms},
  author={Shi, Hao-Jun Michael and Tu, Shenyinying and Xu, Yangyang and Yin, Wotao},
  journal={arXiv preprint arXiv:1610.00040},
  year={2016}
}

@article{xu2013block,
  title={A block coordinate descent method for regularized multiconvex optimization with applications to nonnegative tensor factorization and completion},
  author={Xu, Yangyang and Yin, Wotao},
  journal={SIAM Journal on Imaging Sciences},
  volume={6},
  number={3},
  pages={1758--1789},
  year={2013},
  publisher={SIAM}
}

@article{bonettini2016cyclic,
  title={A cyclic block coordinate descent method with generalized gradient projections},
  author={Bonettini, Silvia and Prato, Marco and Rebegoldi, Simone},
  journal={Applied Mathematics and Computation},
  volume={286},
  pages={288--300},
  year={2016},
  publisher={Elsevier}
}

@inproceedings{sun2015improved,
 author = {Sun, Ruoyu and Hong, Mingyi},
 booktitle = {Proc.~NeurIPS'15},
 title = {Improved Iteration Complexity Bounds of Cyclic Block Coordinate Descent for Convex Problems},
 year = {2015}
}

@InProceedings{deng2021efficiency,
author="Deng, Qi
and Lan, Chenghao",
editor="Hutter, Frank
and Kersting, Kristian
and Lijffijt, Jefrey
and Valera, Isabel",
title="Efficiency of Coordinate Descent Methods for Structured Nonconvex Optimization",
booktitle="Machine Learning and Knowledge Discovery in Databases",
year="2021"
}

@article{kim2014algorithms,
  title={Algorithms for nonnegative matrix and tensor factorizations: A unified view based on block coordinate descent framework},
  author={Kim, Jingu and He, Yunlong and Park, Haesun},
  journal={Journal of Global Optimization},
  volume={58},
  number={2},
  pages={285--319},
  year={2014},
  publisher={Springer}
}

@article{razaviyayn2014parallel,
  title={Parallel Successive Convex Approximation for Nonsmooth Nonconvex Optimization},
  author={Razaviyayn, Meisam and Hong, Mingyi and Luo, Zhi-Quan and Pang, Jong-Shi},
  journal={Proc.~NeurIPS'14},
  year={2014}
} 


@article{sun2021worst,
  title={Worst-case complexity of cyclic coordinate descent: {$ O (n^2) $} gap with randomized version},
  author={Sun, Ruoyu and Ye, Yinyu},
  journal={Mathematical Programming},
  volume={185},
  number={1},
  pages={487--520},
  year={2021},
  publisher={Springer}
}

@article{breheny2011coordinate,
  title={Coordinate descent algorithms for nonconvex penalized regression, with applications to biological feature selection},
  author={Breheny, Patrick and Huang, Jian},
  journal={The Annals of Applied Statistics},
  volume={5},
  number={1},
  pages={232},
  year={2011},
  publisher={NIH Public Access}
}

@article{li2017faster,
  title={On faster convergence of cyclic block coordinate descent-type methods for strongly convex minimization},
  author={Li, Xingguo and Zhao, Tuo and Arora, Raman and Liu, Han and Hong, Mingyi},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={6741--6764},
  year={2017},
  publisher={JMLR. org}
}

@article{lee2019random,
  title={Random permutations fix a worst case for cyclic coordinate descent},
  author={Lee, Ching-Pei and Wright, Stephen J},
  journal={IMA Journal of Numerical Analysis},
  volume={39},
  number={3},
  pages={1246--1275},
  year={2019},
  publisher={Oxford University Press}
}

@article{wright2020analyzing,
  title={Analyzing random permutations for cyclic coordinate descent},
  author={Wright, Stephen and Lee, Ching-pei},
  journal={Mathematics of Computation},
  volume={89},
  number={325},
  pages={2217--2248},
  year={2020}
}

@article{lee2020inexact,
  title={Inexact variable metric stochastic block-coordinate descent for regularized optimization},
  author={Lee, Ching-pei and Wright, Stephen J},
  journal={Journal of Optimization Theory and Applications},
  volume={185},
  number={1},
  pages={151--187},
  year={2020},
  publisher={Springer}
}

@misc{Dua:2019 ,
author = "Dua, Dheeru and Graff, Casey",
year = "2017",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }

@article{HAMIDIEH2018346,
title = {A data-driven statistical model for predicting the critical temperature of a superconductor},
journal = {Computational Materials Science},
volume = {154},
pages = {346-354},
year = {2018},
author = {Kam Hamidieh}
}

@article{chambolle2018stochastic,
  title={Stochastic primal-dual hybrid gradient algorithm with arbitrary sampling and imaging applications},
  author={Chambolle, Antonin and Ehrhardt, Matthias J and Richt{\'a}rik, Peter and Schonlieb, Carola-Bibiane},
  journal={SIAM Journal on Optimization},
  volume={28},
  number={4},
  pages={2783--2808},
  year={2018},
  publisher={SIAM}
}

@inproceedings{golowich2020last,
  title={Last iterate is slower than averaged iterate in smooth convex-concave saddle point problems},
  author={Golowich, Noah and Pattathil, Sarath and Daskalakis, Constantinos and Ozdaglar, Asuman},
  booktitle={Proc.~COLT'20},
  year={2020}
}


@article{cassotti2014prediction,
  title={Prediction of acute aquatic toxicity toward daphnia magna by using the ga-k nn method},
  author={Cassotti, Matteo and Ballabio, Davide and Consonni, Viviana and Mauri, Andrea and Tetko, Igor V and Todeschini, Roberto},
  journal={Alternatives to Laboratory Animals},
  volume={42},
  number={1},
  pages={31--41},
  year={2014},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{yang2020global,
  title={Global convergence and variance-reduced optimization for a class of nonconvex-nonconcave minimax problems},
  author={Yang, Junchi and Kiyavash, Negar and He, Niao},
  journal={arXiv preprint arXiv:2002.09621},
  year={2020}
}

@inproceedings{du2019linear,
  title={Linear convergence of the primal-dual gradient method for convex-concave saddle point problems without strong convexity},
  author={Du, Simon S and Hu, Wei},
  booktitle={Proc.~AISTATS'19},
  year={2019},
}

@article{el1997robust,
  title={Robust solutions to least-squares problems with uncertain data},
  author={El Ghaoui, Laurent and Lebret, Herv{\'e}},
  journal={SIAM Journal on Matrix Analysis and Applications},
  volume={18},
  number={4},
  pages={1035--1064},
  year={1997},
  publisher={SIAM}
}

@inproceedings{zhou2018stochastic,
  title={Stochastic nested variance reduction for nonconvex optimization},
  author={Zhou, Dongruo and Xu, Pan and Gu, Quanquan},
  booktitle={Proc.~NeurIPS'18},
  year={2018}
}

@article{ghadimi2012optimal,
  title={Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization {I}: A generic algorithmic framework},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={SIAM Journal on Optimization},
  volume={22},
  number={4},
  pages={1469--1492},
  year={2012}
}


@article{zhou2018finding,
  title={Finding local minima via stochastic nested variance reduction},
  author={Zhou, Dongruo and Xu, Pan and Gu, Quanquan},
  journal={arXiv preprint arXiv:1806.08782},
  year={2018}
}

@inproceedings{fang2018spider,
  title={Spider: Near-optimal non-convex optimization via stochastic path-integrated differential estimator},
  author={Fang, Cong and Li, Chris Junchi and Lin, Zhouchen and Zhang, Tong},
  booktitle={Proc.~NeurIPS'18},
  year={2018}
}

@inproceedings{nguyen2017sarah,
  title={SARAH: A novel method for machine learning problems using stochastic recursive gradient},
  author={Nguyen, Lam M and Liu, Jie and Scheinberg, Katya and Tak{\'a}{\v{c}}, Martin},
  booktitle={Proc.~ICML'17},
  year={2017}
}

@article{nesterov2005smooth,
  title={Smooth minimization of non-smooth functions},
  author={Nesterov, Yu},
  journal={Mathematical programming},
  volume={103},
  number={1},
  pages={127--152},
  year={2005},
  publisher={Springer}
}

@misc{nesterov1998introductory,
  title={Introductory lectures on convex programming},
  author={Nesterov, Yu},
  year={1998}
}

@article{Nesterov1983AMF,
  title={A method for solving the convex programming problem with convergence rate {$O(1/k^2)$}},
  author={Yurii Nesterov},
  journal={Proceedings of the USSR Academy of Sciences},
  year={1983},
  volume={269},
  pages={543-547}
}

@article{allen2017katyusha,
  title={Katyusha: The first direct acceleration of stochastic gradient methods},
  author={Allen-Zhu, Zeyuan},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={8194--8244},
  year={2017},
  publisher={JMLR. org}
}

@inproceedings{defazio2014saga,
  title={{SAGA}: A fast incremental gradient method with support for non-strongly convex composite objectives},
  author={Defazio, Aaron and Bach, Francis and Lacoste-Julien, Simon},
  booktitle={Proc.~NeurIPS'14},
  year={2014}
}

@inproceedings{johnson2013accelerating,
 author = {Johnson, Rie and Zhang, Tong},
 booktitle = {Proc.~NeurIPS'13},
 title = {Accelerating Stochastic Gradient Descent using Predictive Variance Reduction},
 year = {2013}
}

@article{schmidt2017minimizing,
  title={Minimizing finite sums with the stochastic average gradient},
  author={Schmidt, Mark and Le Roux, Nicolas and Bach, Francis},
  journal={Mathematical Programming},
  volume={162},
  number={1},
  pages={83--112},
  year={2017},
  publisher={Springer}
}

@inproceedings{diakonikolas2021efficient,
  title={Efficient methods for structured nonconvex-nonconcave min-max optimization},
  author={Diakonikolas, Jelena and Daskalakis, Constantinos and Jordan, Michael},
  booktitle={Proc.~AISTATS'21},
  year={2021}
}

@inproceedings{lee2021fast,
  title={Fast extra gradient methods for smooth structured nonconvex-nonconcave minimax problems},
  author={Lee, Sucheol and Kim, Donghwan},
  booktitle={Proc.~NeurIPS'21},
  volume={34},
  year={2021}
}

@article{tran2021halpern,
  title={Halpern-Type Accelerated and Splitting Algorithms For Monotone Inclusions},
  author={Tran-Dinh, Quoc and Luo, Yang},
  journal={arXiv preprint arXiv:2110.08150},
  year={2021}
}

@article{diakonikolas2021potential,
  title={Potential function-based framework for minimizing gradients in convex and min-max optimization},
  author={Diakonikolas, Jelena and Wang, Puqian},
  journal={SIAM Journal on Optimization},
  volume={32},
  number={3},
  pages={1668--1697},
  year={2022},
  publisher={SIAM}
}

@book{kinderlehrer2000introduction,
  title={An introduction to variational inequalities and their applications},
  author={Kinderlehrer, David and Stampacchia, Guido},
  year={2000},
  publisher={SIAM}
}

@article{pang1997error,
  title={Error bounds in mathematical programming},
  author={Pang, Jong-Shi},
  journal={Mathematical Programming},
  volume={79},
  number={1},
  pages={299--332},
  year={1997},
  publisher={Springer}
}

@article{kotsalis2020simple,
  title={Simple and optimal methods for stochastic variational inequalities, I: operator extrapolation},
  author={Kotsalis, Georgios and Lan, Guanghui and Li, Tianjiao},
  journal={arXiv preprint arXiv:2011.02987},
  year={2020}
}

@article{roulet2020sharpness,
  title={Sharpness, Restart, and Acceleration},
  author={Roulet, Vincent and d'Aspremont, Alexandre},
  journal={SIAM Journal on Optimization},
  volume={30},
  number={1},
  pages={262--289},
  year={2020},
  publisher={SIAM}
}

@article{stampacchia1964formes,
author = {Stampacchia, Guido},
title = {Formes Bilineaires Coercitives Sur Les Ensembles Convexes},
journal = {Acad\'emie des Sciences de Paris},
volume = {258},
pages = {4413--4416},
year = {1964}}

@article{rockafellar1970monotone,
  title={Monotone operators associated with saddle-functions and minimax problems},
  author={Rockafellar, R Tyrrell},
  journal={Nonlinear Functional Analysis},
  volume={18},
  number={part 1},
  pages={397--407},
  year={1970},
  publisher={Proceedings of Symposia in Pure Mathematics, American Mathematical Society}
}

@article{rockafellar1976monotone,
  title={Monotone operators and the proximal point algorithm},
  author={Rockafellar, R Tyrrell},
  journal={SIAM Journal on Control and Optimization},
  volume={14},
  number={5},
  pages={877--898},
  year={1976},
  publisher={SIAM}
}

@book{kinderlehrer2000introduction,
  title={An introduction to variational inequalities and their applications},
  author={Kinderlehrer, David and Stampacchia, Guido},
  year={2000},
  publisher={SIAM}
}

@article{minty1962monotone,
  title={Monotone (nonlinear) operators in Hilbert space},
  author={Minty, George J},
  journal={Duke Mathematical Journal},
  volume={29},
  number={3},
  pages={341--346},
  year={1962},
  publisher={Duke University Press}
}

@article{iusem2017extragradient,
  title={Extragradient method with variance reduction for stochastic variational inequalities},
  author={Iusem, Alfredo N and Jofr{\'e}, Alejandro and Oliveira, Roberto Imbuzeiro and Thompson, Philip},
  journal={SIAM Journal on Optimization},
  volume={27},
  number={2},
  pages={686--724},
  year={2017},
  publisher={SIAM}
}

@inproceedings{alacaoglu2021stochastic,
  title={Stochastic variance reduction for variational inequality methods},
  author={Alacaoglu, Ahmet and Malitsky, Yura},
  booktitle={Proc.~NIPS'22},
  year={2022}
}

@article{palaniappan2016stochastic,
  title={Stochastic variance reduction methods for saddle-point problems},
  author={Palaniappan, Balamurugan and Bach, Francis},
  journal={Proc.~NIPS'16},
  volume={29},
  year={2016}
}

@article{chavdarova2019reducing,
  title={Reducing noise in GAN training with variance reduced extragradient},
  author={Chavdarova, Tatjana and Gidel, Gauthier and Fleuret, Fran{\c{c}}ois and Lacoste-Julien, Simon},
  journal={Proc.~NeurIPS'19},
  year={2019}
}

@article{carmon2019variance,
  title={Variance reduction for matrix games},
  author={Carmon, Yair and Jin, Yujia and Sidford, Aaron and Tian, Kevin},
  journal={Proc.~NeurIPS'19},
  year={2019}
}


@article{signorini1959questioni,
  title={Questioni di elasticit{\`a} non linearizzata e semilinearizzata},
  author={Signorini, Antonio},
  journal={Rendiconti di Matematica e delle sue applicazioni},
  volume={18},
  pages={95--139},
  year={1959}
}


@article{korpelevich1977extragradient,
  title={Extragradient method for finding saddle points and other problems},
  author={Korpelevich, GM},
  journal={Matekon},
  volume={13},
  number={4},
  pages={35--49},
  year={1977}
}



@article{thegaptechnique,
	Author = {Diakonikolas, Jelena and Orecchia, Lorenzo},
	Journal = {SIAM Journal on Optimization},
	Number = {1},
	Pages = {660-689},
	Title = {The Approximate Duality Gap Technique: A Unified Theory of First-Order Methods},
	Volume = {29},
	Year = {2019}}
	
@article{juditsky2011solving,
  title={Solving variational inequalities with stochastic mirror-prox algorithm},
  author={Juditsky, Anatoli and Nemirovski, Arkadi and Tauvel, Claire},
  journal={Stochastic Systems},
  volume={1},
  number={1},
  pages={17--58},
  year={2011},
  publisher={INFORMS}
}

@inproceedings{gorbunov2022extragradient,
  title={Extragradient method: $O (1/K)$ last-iterate convergence for monotone variational inequalities and connections with cocoercivity},
  author={Gorbunov, Eduard and Loizou, Nicolas and Gidel, Gauthier},
  booktitle={Proc.~AISTATS'22},
  year={2022}
  }

@article{loizou2021stochastic,
  title={Stochastic gradient descent-ascent and consensus optimization for smooth games: Convergence analysis under expected co-coercivity},
  author={Loizou, Nicolas and Berard, Hugo and Gidel, Gauthier and Mitliagkas, Ioannis and Lacoste-Julien, Simon},
  journal={Proc.~NeurIPS'21},
  year={2021}
}


@inproceedings{mertikopoulos2018optimistic,
  title={Optimistic mirror descent in saddle-point problems: Going the extra (gradient) mile},
  author={Mertikopoulos, Panayotis and Lecouat, Bruno and Zenati, Houssam and Foo, Chuan-Sheng and Chandrasekhar, Vijay and Piliouras, Georgios},
  booktitle = {Proc.~ICLR'19},
  year={2019}
}

@article{browder1967nonlinear,
  title={Nonlinear mappings of nonexpansive and accretive type in {B}anach spaces},
  author={Browder, Felix E},
  journal={Bulletin of the American Mathematical Society},
  volume={73},
  number={6},
  pages={875--882},
  year={1967}
}

@Article{Malitsky2019,
author="Malitsky, Yura",
title="Golden ratio algorithms for variational inequalities",
journal="Mathematical Programming",
year="2019",
month="Jul",
day="31"
}

@article{Sabach:2017,
  author    = {Shoham Sabach and
               Shimrit Shtern},
  title     = {A First Order Method for Solving Convex Bilevel Optimization Problems},
  journal   = {{SIAM} Journal on Optimization},
  volume    = {27},
  number    = {2},
  pages     = {640--660},
  year      = {2017}
}

@article{Contreras:2021,
      title={Optimal error bounds for nonexpansive fixed-point iterations in normed spaces}, 
      author={Contreras, Juan Pablo and Cominetti, Roberto},
            journal={arXiv preprint, arXiv:2108.10969},
      year={2021}
}

@book{bauschke2011convex,
  title={Convex analysis and monotone operator theory in {H}ilbert spaces},
  author={Bauschke, Heinz H and Combettes, Patrick L},
  volume={408},
  year={2011},
  publisher={Springer}
}

@inproceedings{arjevani2020second,
  title={Second-order information in non-convex stochastic optimization: Power and limitations},
  author={Arjevani, Yossi and Carmon, Yair and Duchi, John C and Foster, Dylan J and Sekhari, Ayush and Sridharan, Karthik},
  booktitle={Proc.~COLT'20},
  year={2020}
}

@inproceedings{li2020page,
  title={{PAGE}: A simple and optimal probabilistic gradient estimator for nonconvex optimization},
  author={Li, Zhize and Bao, Hongyan and Zhang, Xiangliang and Richt{\'a}rik, Peter},
  booktitle={Proc.~ICML21},
  year={2021}
}

@inproceedings{diakonikolas2020halpern,
  title={Halpern Iteration for Near-Optimal and Parameter-Free Monotone Inclusion and Strong Solutions to Variational Inequalities},
  author={Diakonikolas, Jelena},
  booktitle={Proc.~COLT'20},
  year={2020}
}


@article{nemirovski2004prox,
  title={Prox-method with rate of convergence {$O(1/t)$} for variational inequalities with {L}ipschitz continuous monotone operators and smooth convex-concave saddle point problems},
  author={Nemirovski, Arkadi},
  journal={SIAM Journal on Optimization},
  volume={15},
  number={1},
  pages={229--251},
  year={2004},
  publisher={SIAM}
}

@Article{Popov1980,
author="Popov, L. D.",
title="A modification of the {Arrow-Hurwicz} method for search of saddle points",
journal="Mathematical notes of the Academy of Sciences of the USSR",
year="1980",
month="Nov",
day="01",
volume="28",
number="5",
pages="845--848"
}

@article{thegaptechnique,
	Author = {Diakonikolas, Jelena and Orecchia, Lorenzo},
	Journal = {SIAM Journal on Optimization},
	Number = {1},
	Pages = {660-689},
	Title = {The Approximate Duality Gap Technique: A Unified Theory of First-Order Methods},
	Volume = {29},
	Year = {2019}}
	
@article{juditsky2011solving,
  title={Solving variational inequalities with stochastic mirror-prox algorithm},
  author={Juditsky, Anatoli and Nemirovski, Arkadi and Tauvel, Claire},
  journal={Stochastic Systems},
  volume={1},
  number={1},
  pages={17--58},
  year={2011},
  publisher={INFORMS}
}

@inproceedings{mertikopoulos2018optimistic,
  title={Optimistic mirror descent in saddle-point problems: Going the extra (gradient) mile},
  author={Mertikopoulos, Panayotis and Lecouat, Bruno and Zenati, Houssam and Foo, Chuan-Sheng and Chandrasekhar, Vijay and Piliouras, Georgios},
  booktitle = {Proc.~ICLR'19},
  year={2019}
}

@inproceedings{Rivasplata:2018, 
author = {Rivasplata, Omar and Parrado-Hern\'{a}ndez, Emilio and Shawe-Taylor, John and Sun, Shiliang and Szepesv\'{a}ri, Csaba},
title = {PAC-Bayes Bounds for Stable Algorithms with Instance-Dependent Priors},
year = {2018}, 
booktitle = {Proc.~NIPS'18}
}

@book{bauschke2011convex,
  title={Convex analysis and monotone operator theory in Hilbert spaces},
  author={Bauschke, Heinz H and Combettes, Patrick L},
  volume={408},
  year={2011},
  publisher={Springer}
}

@article{lieder2019convergence,
  title={On the Convergence Rate of the {Halpern}-Iteration},
  author={Lieder, Felix},
  journal={Optimization Letters},
  volume={15},
  number={2},
  pages={405--418},
  year={2021},
  publisher={Springer}
}

@book{nesterov2018lectures,
  title={Lectures on convex optimization},
  author={Nesterov, Yurii},
  volume={137},
  year={2018},
  publisher={Springer}
}

@article{bauschke2012firmly,
  title={Firmly nonexpansive mappings and maximally monotone operators: correspondence and duality},
  author={Bauschke, Heinz H and Moffat, Sarah M and Wang, Xianfu},
  journal={Set-Valued and Variational Analysis},
  volume={20},
  number={1},
  pages={131--153},
  year={2012},
  publisher={Springer}
}

@article{ghadimi2016accelerated,
  title={Accelerated gradient methods for nonconvex nonlinear and stochastic programming},
  author={Ghadimi, Saeed and Lan, Guanghui},
  journal={Mathematical Programming},
  volume={156},
  number={1-2},
  pages={59--99},
  year={2016}
}

@article{nesterov2011solving,
  title={Solving strongly monotone variational and quasi-variational inequalities},
  author={Nesterov, Yurii and Scrimali, Laura},
  journal={Discrete \& Continuous Dynamical Systems-A},
  volume={31},
  number={4},
  pages={1383--1396},
  year={2011}
}

@Article{Ouyang2019,
author="Ouyang, Yuyuan
and Xu, Yangyang",
title="Lower complexity bounds of first-order methods for convex-concave bilinear saddle-point problems",
journal="Mathematical Programming",
year="2019",
month="Aug"
}

@article{mokhtari2019unified,
  title={A unified analysis of extra-gradient and optimistic gradient methods for saddle point problems: Proximal point approach},
  author={Mokhtari, Aryan and Ozdaglar, Asuman and Pattathil, Sarath},
  journal={arXiv preprint arXiv:1901.08511},
  year={2019}
}

@inproceedings{gidel2018variational,
  title={A Variational Inequality Perspective on Generative Adversarial Networks},
  author={Gidel, Gauthier and Berard, Hugo and Vignoud, Ga{\"e}tan and Vincent, Pascal and Lacoste-Julien, Simon},
  booktitle = {Proc.~ICLR'19},
  year={2019}
}

@article{stonyakin2018generalized,
  title={Generalized Mirror Prox for Monotone Variational Inequalities: Universality and Inexact Oracle},
  author={Stonyakin, Fedor and Gasnikov, Alexander and Dvurechensky, Pavel and Alkousa, Mohammad and Titov, Alexander},
  journal={arXiv preprint arXiv:1806.05140},
  year={2018}
}

@article{nesterov2007dual,
  title={Dual extrapolation and its applications to solving variational inequalities and related problems},
  author={Nesterov, Yurii},
  journal={Mathematical Programming},
  volume={109},
  number={2-3},
  pages={319--344},
  year={2007},
  publisher={Springer}
}

@book{facchinei2007finite,
  title={Finite-dimensional variational inequalities and complementarity problems},
  author={Facchinei, Francisco and Pang, Jong-Shi},
  year={2003},
  publisher={Springer Science \& Business Media}
}


@InProceedings{Yurtsever:2019,
  title = 	 {Conditional Gradient Methods via Stochastic Path-Integrated Differential Estimator},
  author =       {Yurtsever, Alp and Sra, Suvrit and Cevher, Volkan},
  booktitle = 	 {Proc.~NeurIPS'19},
  year = 	 {2019}
}

@article{Hassani:2020,
  author    = {Hamed Hassani and
               Amin Karbasi and
               Aryan Mokhtari and
               Zebang Shen},
  title     = {Stochastic Conditional Gradient++: (Non)Convex Minimization and Continuous
               Submodular Maximization},
  journal   = {{SIAM} J. Optim.},
  volume    = {30},
  number    = {4},
  pages     = {3315--3344},
  year      = {2020}
}

@inproceedings{madry2018towards,
  title={Towards Deep Learning Models Resistant to Adversarial Attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  booktitle = {Proc.~ICLR'18},
  year={2018}
}

@inproceedings{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Proc.~NeurIPS'14},
  year={2014}
}

@inproceedings{arjovsky2016towards,
  title={Towards Principled Methods for Training Generative Adversarial Networks},
  author={Arjovsky, Martin and Bottou, Leon},
  booktitle = {Proc.~ICLR'17},
  year={2017}
}

@article{arjovsky2017wasserstein,
  title={Wasserstein {GAN}},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  journal={arXiv preprint arXiv:1701.07875},
  year={2017}
}

@InProceedings{Yoon2021OptimalGradientNorm,
title={Accelerated Algorithms for Smooth Convex-Concave Minimax Problems with {$O(1/k^2)$} Rate on Squared Gradient Norm},
author={Yoon, Taeho and Ryu, Ernest K},
booktitle = 	 {Proc.~ICML'21},
  year = 	 {2021}
  }


@article{ryu2016primer,
  title={Primer on monotone operator methods},
  author={Ryu, Ernest K and Boyd, Stephen},
  journal={Applied and Computational Mathematics},
  volume={15},
  number={1},
  pages={3--43},
  year={2016}
}

@article{lin2017catalyst,
  title={Catalyst acceleration for first-order convex optimization: From theory to practice},
  author={Lin, Hongzhou and Mairal, Julien and Harchaoui, Zaid},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={7854--7907},
  year={2017},
  publisher={JMLR. org}
}

@article{nesterov2012make,
  title={How to make the gradients small},
  author={Nesterov, Yurii},
  journal={Optima. Mathematical Optimization Society Newsletter},
  number={88},
  pages={10--11},
  year={2012}}
}

@article{kim2018optimizing,
  title={Optimizing the efficiency of first-order methods for decreasing the gradient of smooth convex functions},
  author={Kim, Donghwan and Fessler, Jeffrey A},
  journal={arXiv preprint arXiv:1803.06600},
  year={2018}
}

@article{halpern1967fixed,
  title={Fixed points of nonexpanding maps},
  author={Halpern, Benjamin},
  journal={Bulletin of the American Mathematical Society},
  volume={73},
  number={6},
  pages={957--961},
  year={1967}
}

@article{wittmann1992approximation,
  title={Approximation of fixed points of nonexpansive mappings},
  author={Wittmann, Rainer},
  journal={Archiv der Mathematik},
  volume={58},
  number={5},
  pages={486--491},
  year={1992}
}

@article{kornlein2015quantitative,
  title={Quantitative results for Halpern iterations of nonexpansive mappings},
  author={K{\"o}rnlein, Daniel},
  journal={Journal of Mathematical Analysis and Applications},
  volume={428},
  number={2},
  pages={1161--1172},
  year={2015}
}

@article{bauschke1996approximation,
  title={The approximation of fixed points of compositions of nonexpansive mappings in {H}ilbert space},
  author={Bauschke, Heinz H},
  journal={Journal of Mathematical Analysis and Applications},
  volume={202},
  number={1},
  pages={150--159},
  year={1996}
}

@article{leustean2007rates,
  title={Rates of Asymptotic Regularity for Halpern Iterations of Nonexpansive Mappings.},
  author={Leustean, Laurentiu},
  journal={Journal of Universal Computer Science},
  volume={13},
  number={11},
  pages={1680--1691},
  year={2007}
}

@book{kohlenbach2008applied,
  title={Applied proof theory: proof interpretations and their use in mathematics},
  author={Kohlenbach, Ulrich},
  year={2008},
  publisher={Springer Science \& Business Media}
}

@article{browder1967convergence,
  title={Convergence of approximants to fixed points of nonexpansive nonlinear mappings in {B}anach spaces},
  author={Browder, Felix E},
  journal={Archive for Rational Mechanics and Analysis},
  volume={24},
  number={1},
  pages={82--90},
  year={1967}
}

@article{xu2002iterative,
  title={Iterative algorithms for nonlinear operators},
  author={Xu, Hong-Kun},
  journal={Journal of the London Mathematical Society},
  volume={66},
  number={1},
  pages={240--256},
  year={2002}
}

@article{kim2019accelerated,
  title={Accelerated Proximal Point Method and Forward Method for Monotone Inclusions},
  author={Kim, Donghwan},
  journal={arXiv preprint arXiv:1905.05149},
  year={2019}
}

@article{drori2014performance,
  title={Performance of first-order methods for smooth convex minimization: a novel approach},
  author={Drori, Yoel and Teboulle, Marc},
  journal={Mathematical Programming},
  volume={145},
  number={1-2},
  pages={451--482},
  year={2014}
}

@article{davis2019stochastic,
  title={Stochastic model-based minimization of weakly convex functions},
  author={Davis, Damek and Drusvyatskiy, Dmitriy},
  journal={SIAM Journal on Optimization},
  volume={29},
  number={1},
  pages={207--239},
  year={2019}
}

@article{davis2019proximally,
  title={Proximally guided stochastic subgradient method for nonsmooth, nonconvex problems},
  author={Davis, Damek and Grimmer, Benjamin},
  journal={SIAM Journal on Optimization},
  volume={29},
  number={3},
  pages={1908--1930},
  year={2019}
}

@article{asi2019stochastic,
  title={Stochastic (approximate) proximal point methods: Convergence, optimality, and adaptivity},
  author={Asi, Hilal and Duchi, John C},
  journal={SIAM Journal on Optimization},
  volume={29},
  number={3},
  pages={2257--2290},
  year={2019}
}

@article{lin2018solving,
  title={Solving weakly-convex-weakly-concave saddle-point problems as weakly-monotone variational inequality},
  author={Lin, Qihang and Liu, Mingrui and Rafique, Hassan and Yang, Tianbao},
  journal={arXiv preprint arXiv:1810.10207},
  year={2018}
}

@article{ryu2019ode,
  title={{ODE} Analysis of Stochastic Gradient Methods with Optimism and Anchoring for Minimax Problems and {GAN}s},
  author={Ryu, Ernest K and Yuan, Kun and Yin, Wotao},
  journal={arXiv preprint arXiv:1905.10899},
  year={2019}
}

@article{dang2015convergence,
  title={On the convergence properties of non-{E}uclidean extragradient methods for variational inequalities with generalized monotone operators},
  author={Dang, Cong D and Lan, Guanghui},
  journal={Computational Optimization and Applications},
  volume={60},
  number={2},
  pages={277--310},
  year={2015}
}

@article{kohlenbach2011quantitative,
  title={On quantitative versions of theorems due to FE Browder and R. Wittmann},
  author={Kohlenbach, Ulrich},
  journal={Advances in Mathematics},
  volume={226},
  number={3},
  pages={2764--2795},
  year={2011},
  publisher={Elsevier}
}

@inproceedings{bach2019universal,
  title={A universal algorithm for variational inequalities adaptive to smoothness and noise},
  author={Bach, Francis and Levy, Kfir Y},
  booktitle={Proc.~COLT'19},
  year={2019}
}

@inproceedings{thekumparampil2019efficient,
  title={Efficient algorithms for smooth minimax optimization},
  author={Thekumparampil, Kiran K and Jain, Prateek and Netrapalli, Praneeth and Oh, Sewoong},
  booktitle={Proc.~NeurIPS'19},
  year={2019}
}

@book{beck2017first,
  title={First-order methods in optimization},
  author={Beck, Amir},
  volume={25},
  year={2017},
  publisher={SIAM}
}

@inproceedings{reddi2016stochastic,
  title={Stochastic variance reduction for nonconvex optimization},
  author={Reddi, Sashank J and Hefny, Ahmed and Sra, Suvrit and Poczos, Barnabas and Smola, Alex},
  booktitle={Proc.~ICML'16},
  year={2016}
}


@inproceedings{song2020variance,
  title={Variance reduction via accelerated dual averaging for finite-sum optimization},
  author={Song, Chaobing and Jiang, Yong and Ma, Yi},
  booktitle={Proc.~NeurIPS'20},
  year={2020}
}

@inproceedings{lei2017non,
  title={Non-convex finite-sum optimization via {SCSG} methods},
  author={Lei, Lihua and Ju, Cheng and Chen, Jianbo and Jordan, Michael I},
  booktitle={Proc.~NeurIPS'17},
  year={2017}
}

@inproceedings{cutkosky2019momentum,
  title={Momentum-based variance reduction in non-convex {SGD}},
  author={Cutkosky, Ashok and Orabona, Francesco},
  booktitle={Proc.~NeurIPS'19},
  year={2019}
}











































