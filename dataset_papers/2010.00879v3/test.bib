@article{willett1965discrete,
  title={On the discrete analogues of some generalizations of {G}ronwall's inequality},
  author={Willett, D and Wong, JSW},
  journal={Monatshefte f{\"u}r Mathematik},
  volume={69},
  number={4},
  pages={362--367},
  year={1965},
  publisher={Springer-Verlag}
}

@article{JMLR:v21:17-678,
  author  = {James Martens},
  title   = {New Insights and Perspectives on the Natural Gradient Method},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {146},
  pages   = {1-76}
}

@article{cookbook,
  title={The {M}atrix {C}ookbook},
  author={Petersen, K. B. and Pedersen, M. S.},
  year={2012},
  publisher={Technical University of Denmark}
}


@article{heskes2000natural,
  title={On “natural” learning and pruning in multilayered perceptrons},
  author={Heskes, Tom},
  journal={Neural Computation},
  volume={12},
  number={4},
  pages={881--901},
  year={2000},
  publisher={MITP}
}

@inproceedings{thomas2014genga,
  title={{G}e{NGA}: A generalization of natural gradient ascent with positive and negative convergence results},
  author={Thomas, Philip},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={1575--1583},
  year={2014}
}

@inproceedings{rudner2019,
  title={The Natural Neural Tangent Kernel: Neural Network Training Dynamics under Natural Gradient Descent},
  author={Rudner, Tim G. J. and Wenzel, Florian and Teh, Yee Whye and Gal, Yarin},
  booktitle={4th workshop on Bayesian Deep Learning (NeurIPS 2019)},
  year={2019}
}

@article{yang2019scaling,
  title={Scaling limits of wide neural networks with weight sharing: Gaussian process behavior, gradient independence, and neural tangent kernel derivation},
  author={Yang, Greg},
  journal={arXiv preprint arXiv:1902.04760},
  year={2019}
}

@article{amari1998natural,
  title={Natural gradient works efficiently in learning},
  author={Amari, Shun-ichi},
  journal={Neural computation},
  volume={10},
  number={2},
  pages={251--276},
  year={1998},
  publisher={MIT Press}
}

@article{noschese2013tridiagonal,
  title={Tridiagonal {T}oeplitz matrices: properties and novel applications},
  author={Noschese, Silvia and Pasquini, Lionello and Reichel, Lothar},
  journal={Numerical linear algebra with applications},
  volume={20},
  number={2},
  pages={302--326},
  year={2013},
  publisher={Wiley Online Library}
}

@article{da2001explicit,
  title={Explicit inverses of some tridiagonal matrices},
  author={da Fonseca, CM and Petronilho, J},
  journal={Linear Algebra and Its Applications},
  volume={1},
  number={325},
  pages={7--21},
  year={2001}
}

@inproceedings{bernacchia2018exact,
  title={Exact natural gradient in deep linear networks and its application to the nonlinear case},
  author={Bernacchia, Alberto and Lengyel, M{\'a}t{\'e} and Hennequin, Guillaume},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={5941--5950},
  year={2018}
}

@inproceedings{zhang2019fast,
  title={Fast Convergence of Natural Gradient Descent for Over-Parameterized Neural Networks},
  author={Zhang, Guodong and Martens, James and Grosse, Roger B},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={8080--8091},
  year={2019}
}

@inproceedings{allen2019learning,
  title={Learning and generalization in overparameterized neural networks, going beyond two layers},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Liang, Yingyu},
  booktitle={Advances in neural information processing systems (NeurIPS)},
  pages={6155--6166},
  year={2019}
}

@inproceedings{allen2019convergence,
  title={A Convergence Theory for Deep Learning via Over-Parameterization},
  author={Allen-Zhu, Zeyuan and Li, Yuanzhi and Song, Zhao},
  booktitle={International Conference on Machine Learning},
  pages={242--252},
  year={2019}
}

@inproceedings{arora2019exact,
  title={On exact computation with an infinitely wide neural net},
  author={Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Russ R and Wang, Ruosong},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2019}
}

@inproceedings{arora2019fine,
  title={Fine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks},
  author={Arora, Sanjeev and Du, Simon and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={322--332},
  year={2019}
}

@article{bach2017breaking,
  title={Breaking the curse of dimensionality with convex neural networks},
  author={Bach, Francis},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={629--681},
  year={2017},
  publisher={JMLR. org}
}

@inproceedings{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  booktitle={Advances in neural information processing systems (NeurIPS)},
  pages={8571--8580},
  year={2018}
}

@inproceedings{grosse2016kronecker,
  title={A {K}ronecker-factored approximate {F}isher matrix for convolution layers},
  author={Grosse, Roger and Martens, James},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={573--582},
  year={2016}
}

@article{le1991eigenvalues,
  title={Eigenvalues of covariance matrices: Application to neural-network learning},
  author={LeCun, Yann and Kanter, Ido and Solla, Sara A},
  journal={Physical Review Letters},
  volume={66},
  number={18},
  pages={2396},
  year={1991},
  publisher={APS}
}

@inproceedings{kunstner2019limitations,
  title={Limitations of the Empirical {F}isher Approximation},
  author={Kunstner, Frederik and Balles, Lukas and Hennig, Philipp},
  booktitle={Advances in neural information processing systems (NeurIPS)},
  year={2019}
}


@InProceedings{He_2015_ICCV,
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
title = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification},
booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
month = {December},
year = {2015}
}

@article{jacot2019,
  author    = {Arthur Jacot and
               Franck Gabriel and
               Cl{\'{e}}ment Hongler},
  title     = {Freeze and Chaos for DNNs: an {NTK} view of Batch Normalization, Checkerboard
               and Boundary Effects},
  journal   = {arXiv:1907.05715},
  year      = {2019}
}



@inproceedings{suzuki2018fast,
  title={Fast generalization error bound of deep learning from a kernel perspective},
  author={Suzuki, Taiji},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={1397--1406},
  year={2018}
}

@article{Sun2019,
  title={Lightlike Neuromanifolds, Occam's Razor and Deep Learning},
  author={Sun, Ke and Nielsen, Frank},
  journal={arXiv preprint arXiv:1905.11027},
  year={2019}
}

@inproceedings{lee2019wide,
  title={Wide neural networks of any depth evolve as linear models under gradient descent},
  author={Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel S and Bahri, Yasaman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
  booktitle={Advances in neural information processing systems (NeurIPS)},
  year={2019}
}

@inproceedings{karakida2019normalization,
  title={The Normalization Method for Alleviating Pathological Sharpness in Wide Neural Networks},
  author={Karakida, Ryo and Akaho, Shotaro and Amari, Shun-ichi},
  booktitle={Advances in neural information processing systems (NeurIPS)},
  year={2019}
}

@article{yang2020tensor,
  title={Tensor Programs {II}: Neural Tangent Kernel for Any Architecture},
  author={Yang, Greg},
  journal={arXiv preprint arXiv:2006.14548},
  year={2020}
}

@article{cai2019gram,
  title={A {G}ram-{G}auss-{N}ewton method learning overparameterized deep neural networks for regression problems},
  author={Cai, Tianle and Gao, Ruiqi and Hou, Jikai and Chen, Siyu and Wang, Dong and He, Di and Zhang, Zhihua and Wang, Liwei},
  journal={arXiv preprint arXiv:1905.11675},
  year={2019}
}

@inproceedings{roux2008topmoumoute,
  title={Topmoumoute online natural gradient algorithm},
  author={Roux, Nicolas L and Manzagol, Pierre-Antoine and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems (NeurIPS)},
  pages={849--856},
  year={2008}
}

@inproceedings{papyan2019measurements,
  title={Measurements of Three-Level Hierarchical Structure in the Outliers in the Spectrum of Deepnet Hessians},
  author={Papyan, Vardan},
  booktitle={Proceedings of International Conference on Machine Learning (ICML)},
  year={2019}
}

@inproceedings{li2018visualizing,
  title={Visualizing the loss landscape of neural nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  booktitle={Proceedings of Advances in Neural Information Processing Systems (NeurIPS)},
  pages={6389--6399},
  year={2018}
}

@article{wei2019meanfield,
    title={Mean-field Analysis of Batch Normalization},
    author={Mingwei Wei and James Stokes and David J Schwab},
     journal={arXiv:1903.02606},
    year={2019}
}



@inproceedings{amari2018fisher,
  title={Fisher Information and Natural Gradient Learning of Random Deep Networks},
  author={Amari, Shun-ichi and Karakida, Ryo and Oizumi, Masafumi},
  booktitle={Proceedings of International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={694--702},
  year={2019}
}




@inproceedings{kohler2018towards,
  title={Exponential convergence rates for Batch Normalization: The power of length-direction decoupling in non-convex optimization},
  author={Kohler, Jonas and Daneshmand, Hadi and Lucchi, Aurelien and Hofmann, Thomas and Zhou, Ming and Neymeyr, Klaus},
  booktitle={Proceedings of International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={806--815},
  year={2019}
}


@inproceedings{bjorck2018understanding,
  title={Understanding batch normalization},
  author={Bjorck, Nils and Gomes, Carla P and Selman, Bart and Weinberger, Kilian Q},
  booktitle={Proceedings of Advances in Neural Information Processing Systems (NeurIPS)},
  pages={7694--7705},
  year={2018}
}

@inproceedings{pennington2018spectrum,
  title={The Spectrum of the Fisher Information Matrix of a Single-Hidden-Layer Neural Network},
  author={Pennington, Jeffrey and Worah, Pratik},
  booktitle={Proceedings of Advances in Neural Information Processing Systems (NeurIPS)},
  pages={5410--5419},
  year={2018}
}

@article{yos2019,
author = {Yoshida, Yuki and Karakida, Ryo and Okada, Masato and Amari, Shun-ichi},
year = {2019},
month = {02},
pages = {},
title = {Statistical mechanical analysis of learning dynamics of two-layer perceptron with multiple output units},
journal = {Journal of Physics A: Mathematical and Theoretical},
doi = {10.1088/1751-8121/ab0669}
}

@article{amari2018dynamics,
  title={Dynamics of learning in mlp: Natural gradient and singularity revisited},
  author={Amari, Shun-ichi and Ozeki, Tomoko and Karakida, Ryo and Yoshida, Yuki and Okada, Masato},
  journal={Neural computation},
  volume={30},
  number={1},
  pages={1--33},
  year={2018},
  publisher={MIT Press}
}



@article{karakida2016dynamical,
  title={Dynamical analysis of contrastive divergence learning: restricted Boltzmann machines with Gaussian visible units},
  author={Karakida, Ryo and Okada, Masato and Amari, Shun-ichi},
  journal={Neural Networks},
  volume={79},
  pages={78--87},
  year={2016},
  publisher={Elsevier}
}

@article{lee2017deep,
  title={Deep neural networks as gaussian processes},
  author={Lee, Jaehoon and Bahri, Yasaman and Novak, Roman and Schoenholz, Samuel S and Pennington, Jeffrey and Sohl-Dickstein, Jascha},
  journal={ICLR 2018, arXiv:1711.00165},
  year={2018}
}

@article{novak2018sensitivity,
  title={Sensitivity and generalization in neural networks: an empirical study},
  author={Novak, Roman and Bahri, Yasaman and Abolafia, Daniel A and Pennington, Jeffrey and Sohl-Dickstein, Jascha},
  journal={ICLR'2018,  arXiv:1802.08760},
  year={2018}
}

@inproceedings{yao2018hessian,
  title={Hessian-based Analysis of Large Batch Training and Robustness to Adversaries},
  author={Yao, Zhewei and Gholami, Amir and Lei, Qi and Keutzer, Kurt and Mahoney, Michael W},
  booktitle={Proceedings of Advances in Neural Information Processing Systems (NeurIPS)},
  pages={4949--4959},
  year={2018}
}

@inproceedings{ioffe2015batch,
  title={Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={Proceedings of International Conference on Machine Learning (ICML)},
  pages={448--456},
  year={2015}
}

@inproceedings{karakida2018universal,
  title={Universal Statistics of {F}isher Information in Deep Neural Networks: Mean Field Approach},
  author={Karakida, Ryo and Akaho, Shotaro and Amari, Shun-ichi},
  booktitle={Proceedings of International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={1032--1041},
  year={2019}
}

@article{yang2019bn,
  title={A Mean Field Theory of Batch Normalization},
  author={Yang, Greg and Pennington, Jeffrey and Rao,  Vinay and   Sohl-Dickstein, Jascha and Schoenholz, Samuel S },
  journal={ICLR2019 arXiv:1902.08129},
  year={2019}
}



@article{santurkar2018does,
  title={How Does Batch Normalization Help Optimization?},
  author={Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew and Madry, Aleksander},
  journal={Proceedings of Advances in Neural Information Processing Systems (NeurIPS)},
  year={2018}
}


@inproceedings{xiao2018dynamical,
  title={Dynamical Isometry and a Mean Field Theory of {CNN}s: How to Train 10,000-Layer Vanilla Convolutional Neural Networks},
  author={Xiao, Lechao and Bahri, Yasaman and Sohl-Dickstein, Jascha and Schoenholz, Samuel S and Pennington, Jeffrey},
  booktitle={Proceedings of  International Conference on Machine Learning (ICML)},
    pages = 	 {5393--5402},
  year={2018}
}

@article{amari1974method,
  title={A method of statistical neurodynamics},
  author={Amari, Shun-ichi},
  journal={Kybernetik},
  volume={14},
  number={4},
  pages={201--215},
  year={1974},
  publisher={Springer}
}

@inproceedings{raiko2012deep,
  title={Deep learning made easier by linear transformations in perceptrons},
  author={Raiko, Tapani and Valpola, Harri and LeCun, Yann},
  booktitle={Proceedings of International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={924--932},
  year={2012}
}

@inproceedings{pennington2018emergence,
  title={The emergence of spectral universality in deep networks},
  author={Pennington, Jeffrey and Schoenholz, Samuel and Ganguli, Surya},
  booktitle={Proceedings of International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={1924--1932},
  year={2018}
}

@article{candes2006near,
  title={Near-optimal signal recovery from random projections: Universal encoding strategies?},
  author={Candes, Emmanuel J and Tao, Terence},
  journal={IEEE transactions on information theory},
  volume={52},
  number={12},
  pages={5406--5425},
  year={2006},
  publisher={IEEE}
}

@inproceedings{pennington2017geometry,
  title={Geometry of neural network loss surfaces via random matrix theory},
  author={Pennington, Jeffrey and Bahri, Yasaman},
  booktitle={Proceedings of International Conference on Machine Learning (ICML)},
  pages={2798--2806},
  year={2017}
}

@article{louart2017random,
  title={A Random Matrix Approach to Neural Networks},
  author={Louart, Cosme and Liao, Zhenyu and Couillet, Romain},
  journal={arXiv preprint arXiv:1702.05419},
  year={2017}
}

@inproceedings{daniely2016toward,
  title={Toward deeper understanding of neural networks: The power of initialization and a dual view on expressivity},
  author={Daniely, Amit and Frostig, Roy and Singer, Yoram},
  booktitle={Proceedings of Advances In Neural Information Processing Systems (NeurIPS)},
  pages={2253--2261},
  year={2016}
}

@inproceedings{cox2011beyond,
  title={Beyond simple features: A large-scale feature search approach to unconstrained face recognition},
  author={Cox, David and Pinto, Nicolas},
  booktitle={Automatic Face \& Gesture Recognition and Workshops (FG 2011), 2011 IEEE International Conference on},
  pages={8--15},
  year={2011},
  organization={IEEE}
}

@inproceedings{mairal2014convolutional,
  title={Convolutional kernel networks},
  author={Mairal, Julien and Koniusz, Piotr and Harchaoui, Zaid and Schmid, Cordelia},
  booktitle={Advances in neural information processing systems},
  pages={2627--2635},
  year={2014}
}
@inproceedings{glorot2010understanding,
  title={Understanding the difficulty of training deep feedforward neural networks},
  author={Glorot, Xavier and Bengio, Yoshua},
  booktitle={international conference on artificial intelligence and statistics (AISTATS)},
  pages={249--256},
  year={2010}
}

@inproceedings{pennington2017nonlinear,
  title={Nonlinear random matrix theory for deep learning},
  author={Pennington, Jeffrey and Worah, Pratik},
  booktitle={Proceedings of  Advances in Neural Information Processing Systems (NeurIPS)},
  pages={2634--2643},
  year={2017}
}

@inproceedings{saxe2011random,
  title={On Random Weights and Unsupervised Feature Learning.},
  author={Saxe, Andrew M and Koh, Pang Wei and Chen, Zhenghao and Bhand, Maneesh and Suresh, Bipin and Ng, Andrew Y},
  booktitle={ICML},
  pages={1089--1096},
  year={2011}
}

@article{kirkpatrick2017overcoming,
  title={Overcoming catastrophic forgetting in neural networks},
  author={Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and others},
  journal={Proceedings of the National Academy of Sciences},
  volume={114},
  number={13},
  pages={3521--3526},
  year={2017},
  publisher={National Acad Sciences}
}

@article{giryes2016deep,
  title={Deep neural networks with random Gaussian weights: a universal classification strategy?},
  author={Giryes, Raja and Sapiro, Guillermo and Bronstein, Alexander M},
  journal={IEEE Trans. Signal Processing},
  volume={64},
  number={13},
  pages={3444--3457},
  year={2016}
}

@inproceedings{hoffer2017train,
  title={Train longer, generalize better: closing the generalization gap in large batch training of neural networks},
  author={Hoffer, Elad and Hubara, Itay and Soudry, Daniel},
  booktitle={Proceedings of  Advances in Neural Information Processing Systems (NeurIPS)},
  pages={1729--1739},
  year={2017}
}

@inproceedings{arora2014provable,
  title={Provable bounds for learning some deep representations},
  author={Arora, Sanjeev and Bhaskara, Aditya and Ge, Rong and Ma, Tengyu},
  booktitle={International Conference on Machine Learning},
  pages={584--592},
  year={2014}
}

@inproceedings{montufar2014number,
  title={On the number of linear regions of deep neural networks},
  author={Montufar, Guido F and Pascanu, Razvan and Cho, Kyunghyun and Bengio, Yoshua},
  booktitle={Advances in Neural Information Processing Systems (NIPS)},
  pages={2924--2932},
  year={2014}
}

@article{soudry2016,
  title={No bad local minima: Data independent training error guarantees for multilayer neural networks},
  author={Soudry, Daniel and Carmon, Yair},
  journal={arXiv preprint arXiv:1605.08361},
  year={2016}
}

@incollection{lecun1998efficient,
  title={Efficient backprop},
  author={LeCun, Yann and Bottou, L{\'e}on and Orr, Genevieve B and M{\"u}ller, Klaus-Robert},
  booktitle={Neural networks: Tricks of the trade},
  pages={9--50},
  year={1998},
  publisher={Springer}
}

@article{gori1992,
  title={On the problem of local minima in backpropagation},
  author={Gori, Marco and Tesi, Alberto},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={14},
  number={1},
  pages={76--86},
  year={1992}
}

@inproceedings{nguyen2017loss,
  title={The Loss Surface of Deep and Wide Neural Networks},
  author={Nguyen, Quynh and Hein, Matthias},
  booktitle={Proceedings of International Conference on Machine Learning (ICML)},
  pages={2603--2612},
  year={2017}
}

@article{swirszcz2016,
  title={Local minima in training of deep networks},
  author={Swirszcz, Grzegorz and Czarnecki, Wojciech Marian and Pascanu, Razvan},
  journal={arXiv preprint arXiv:1611.06310},
  year={2016}
}



@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}


@incollection{yang2017,
title = {Mean Field Residual Networks: On the Edge of Chaos},
author = {Yang, Greg and Schoenholz, Samuel},
booktitle = {Proceedings of  Advances in Neural Information Processing Systems (NIPS)},
pages = {2865--2873},
year = {2017}
}


@article{schoenholz2016,
  title={Deep information propagation},
  author={Schoenholz, Samuel S and Gilmer, Justin and Ganguli, Surya and Sohl-Dickstein, Jascha},
  journal={ICLR2017 arXiv:1611.01232},
  year={2017}
}

@inproceedings{poole2016,
  title={Exponential expressivity in deep neural networks through transient chaos},
  author={Poole, Ben and Lahiri, Subhaneil and Raghu, Maithreyi and Sohl-Dickstein, Jascha and Ganguli, Surya},
  booktitle={Proceedings of Advances In Neural Information Processing Systems (NIPS)},
  pages={3360--3368},
  year={2016}
}

@inproceedings{kadmon2016,
  title={Optimal architectures in a solvable model of deep networks},
  author={Kadmon, Jonathan and Sompolinsky, Haim},
  booktitle={Proceedings of Advances in Neural Information Processing Systems (NIPS)},
  pages={4781--4789},
  year={2016}
}

@article{sagun2017empirical,
  title={Empirical Analysis of the Hessian of Over-Parametrized Neural Networks},
  author={Sagun, Levent and Evci, Utku and Guney, V Ugur and Dauphin, Yann and Bottou, Leon},
  journal={arXiv:1706.04454},
  year={2017}
}

@article{wu2017towards,
  title={Towards Understanding Generalization of Deep Learning: Perspective of Loss Landscapes},
  author={Wu, Lei and Zhu, Zhanxing and others},
  journal={arXiv preprint arXiv:1706.10239},
  year={2017}
}

@InProceedings{liang2017fisher,
  title = 	 {Fisher-Rao Metric, Geometry, and Complexity of Neural Networks},
  author = 	 {Liang, Tengyuan and Poggio, Tomaso and Rakhlin, Alexander and Stokes, James},
  booktitle = 	 {Proceedings of International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages = 	 {888--896},
  year = 	 {2019},
}

@inproceedings{martens2015optimizing,
  title={Optimizing neural networks with {K}ronecker-factored approximate curvature},
  author={Martens, James and Grosse, Roger},
  booktitle={Proceedings of International Conference on Machine Learning (ICML)},
  pages={2408--2417},
  year={2015}
}

@article{saad1998,
  title={Natural gradient descent for on-line learning},
  author={Rattray, Magnus and Saad, David and Amari, Shun-ichi},
  journal={Physical review letters},
  volume={81},
  number={24},
  pages={5461},
  year={1998},
  publisher={APS}
}


@article{nature2015,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={Nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{safran2016quality,
  title={On the quality of the initial basin in overspecified neural networks},
  author={Safran, Itay and Shamir, Ohad},
  booktitle={Proceedings of International Conference on Machine Learning (ICML)},
  pages={774--782},
  year={2016}
}

@incollection{trick2012,
  title={Training deep and recurrent networks with hessian-free optimization},
  author={Martens, James and Sutskever, Ilya},
  booktitle={Neural networks: Tricks of the trade},
  pages={479--535},
  year={2012},
  publisher={Springer}
}
@article{soudry2017exponentially,
  title={Exponentially vanishing sub-optimal local minima in multilayer neural networks},
  author={Soudry, Daniel and Hoffer, Elad},
  journal={arXiv preprint arXiv:1702.05777},
  year={2017}
}



@inproceedings{neyshabur2015norm,
  title={Norm-based capacity control in neural networks},
  author={Neyshabur, Behnam and Tomioka, Ryota and Srebro, Nathan},
  booktitle={Proceedings of Conference on Learning Theory (COLT)},
  pages={1376--1401},
  year={2015}
}

@inproceedings{safran2016quality,
  title={On the quality of the initial basin in overspecified neural networks},
  author={Safran, Itay and Shamir, Ohad},
  booktitle={Proceedings of International Conference on Machine Learning (ICML)},
  pages={774--782},
  year={2016}
}



@inproceedings{saad1996dynamics,
  title={Dynamics of on-line gradient descent learning for multilayer neural networks},
  author={Saad, David and Solla, Sara A},
  booktitle={Proceedings of Advances in neural information processing systems (NIPS)},
  pages={302--308},
  year={1996}
}

@inproceedings{specnorm,
title = {Spectrally-normalized margin bounds for neural networks},
author = {Bartlett, Peter L and Foster, Dylan J and Telgarsky, Matus J},
booktitle = {Proceedings of  Advances in Neural Information Processing Systems (NIPS)},
pages = {6241--6250},
year = {2017}
}

@article{saad1995exact,
  title={Exact solution for on-line learning in multilayer neural networks},
  author={Saad, David and Solla, Sara A},
  journal={Physical Review Letters},
  volume={74},
  number={21},
  pages={4337},
  year={1995},
  publisher={APS}
}



@article{du2018gradient,
  title={Gradient descent provably optimizes over-parameterized neural networks},
  author={Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
  journal={ICLR 2019, arXiv:1810.02054},
  year={2019}
}

@inproceedings{dinh2017sharp,
  title={Sharp Minima Can Generalize For Deep Nets},
  author={Dinh, Laurent and Pascanu, Razvan and Bengio, Samy and Bengio, Yoshua},
  booktitle={Proceedings of International Conference on Machine Learning (ICML)},
  pages={1019--1028},
  year={2017}
}

@article{du2018gradient,
  title={Gradient descent provably optimizes over-parameterized neural networks},
  author={Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
  journal={arXiv preprint arXiv:1810.02054},
  year={2018}
}

@inproceedings{sfn2014,
  title={Identifying and attacking the saddle point problem in high-dimensional non-convex optimization},
  author={Dauphin, Yann N and Pascanu, Razvan and Gulcehre, Caglar and Cho, Kyunghyun and Ganguli, Surya and Bengio, Yoshua},
  booktitle={Proceedings of Advances in Neural Information Processing Systems (NIPS)},
  pages={2933--2941},
  year={2014}
}


@article{keskar2016large,
  title={On large-batch training for deep learning: Generalization gap and sharp minima},
  author={Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
  journal={ICLR2017 arXiv:1609.04836},
  year={2017}
}

@article{hochreiter1997flat,
  title={Flat minima},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural Computation},
  volume={9},
  number={1},
  pages={1--42},
  year={1997},
  publisher={MIT Press}
}

@inproceedings{nnn2015,
  title={Natural neural networks},
  author={Desjardins, Guillaume and Simonyan, Karen and Pascanu, Razvan and others},
  booktitle={Proceedings of Advances in Neural Information Processing Systems (NIPS)},
  pages={2071--2079},
  year={2015}
}


@article{baldi1989neural,
  title={Neural networks and principal component analysis: Learning from examples without local minima},
  author={Baldi, Pierre and Hornik, Kurt},
  journal={Neural networks},
  volume={2},
  number={1},
  pages={53--58},
  year={1989},
  publisher={Elsevier}
}

@article{matthews2018gaussian,
  title={Gaussian process behaviour in wide deep neural networks},
  author={Matthews, Alexander G de G and Rowland, Mark and Hron, Jiri and Turner, Richard E and Ghahramani, Zoubin},
  journal={ICLR2018, arXiv:1804.11271},
  year={2018}
}

@article{cousseau2008dynamics,
  title={Dynamics of learning in multilayer perceptrons near singularities},
  author={Cousseau, Florent and Ozeki, Tomoko and Amari, Shun-ichi},
  journal={IEEE Transactions on Neural Networks},
  volume={19},
  number={8},
  pages={1313--1328},
  year={2008},
  publisher={IEEE}
}

@article{amari2006,
 title={Singularities affect dynamics of learning in neuromanifolds},
  author={Amari, Shun-ichi and Park, Hyeyoung and Ozeki, Tomoko},
  journal={Neural computation},
  volume={18},
  number={5},
  pages={1007--1065},
  year={2006},
  publisher={MIT Press}
}
@article{wei2008,
  title={Dynamics of learning near singularities in layered networks},
  author={Wei, Haikun and Zhang, Jun and Cousseau, Florent and Ozeki, Tomoko and Amari, Shun-ichi},
  journal={Neural computation},
  volume={20},
  number={3},
  pages={813--843},
  year={2008},
  publisher={MIT Press}
}

@article{fuk2000,
  title={Local minima and plateaus in hierarchical structures of multilayer perceptrons},
  author={Fukumizu, Kenji and Amari, Shun-ichi},
  journal={Neural Networks},
  volume={13},
  number={3},
  pages={317--327},
  year={2000},
  publisher={Elsevier}
}

@article{fuk1996,
  title={A regularity condition of the information matrix of a multilayer perceptron network},
  author={Fukumizu, Kenji},
  journal={Neural Networks},
  volume={9},
  number={5},
  pages={871--879},
  year={1996},
  publisher={Elsevier}
}

@incollection{amari2016,
  title={Natural Gradient Learning and Its Dynamics in Singular Regions},
  author={Amari, Shun-ichi},
  booktitle={Information Geometry and Its Applications},
  pages={279--314},
  year={2016},
  publisher={Springer}
}

@article{dynamics2008,
  title={Dynamics of learning in multilayer perceptrons near singularities},
  author={Cousseau, Florent and Ozeki, Tomoko and Amari, Shun-ichi},
  journal={Neural Networks, IEEE Transactions on},
  volume={19},
  number={8},
  pages={1313--1328},
  year={2008},
  publisher={IEEE}
}

@inproceedings{hf2010,
  title={Deep learning via Hessian-free optimization},
  author={Martens, James},
  booktitle={Proceedings of  International Conference on Machine Learning (ICML)},
  year={2010}
}

@article{park2000,
  title={Adaptive natural gradient learning algorithms for various stochastic models},
  author={Park, Hyeyoung and Amari, Shun-ichi and Fukumizu, Kenji},
  journal={Neural Networks},
  volume={13},
  number={7},
  pages={755--764},
  year={2000},
  publisher={Elsevier}
}

@inproceedings{Saxe2013,
 author               = {Saxe, Andrew M and McClelland, James L and Ganguli, Surya},
 booktitle            = {International Conference on Learning Representations (ICLR)},
 title                = {Exact solutions to the nonlinear dynamics of learning in deep linear neural networks},
 year                 = {2014},
 }
 
 @article{Amari1977,
 author               = {Amari, Shun-ichi},
 journal              = {Biological Cybernetics},
 number               = {3},
 pages                = {175--185},
 title                = {Neural theory of association and concept-formation},
 volume               = {26},
 year                 = {1977},
 }

@article{Amari1990,
 author               = {Amari, Shun-ichi},
 journal              = {Proceedings of the IEEE},
 number               = {9},
 pages                = {1443--1463},
 publisher            = {IEEE},
 title                = {Mathematical foundations of neurocomputing},
 volume               = {78},
 year                 = {1990},
 }
 
 @article{bottou1998online,
  title={Online learning and stochastic approximations},
  author={Bottou, L{\'e}on},
  journal={On-line learning in neural networks},
  volume={17},
  number={9},
  pages={9--42},
  year={1998},
  publisher={Cambridge Univ Pr}
}
 
@article{ollivier2015riemannian,
  title={Riemannian metrics for neural networks {I}: feedforward networks},
  author={Ollivier, Yann},
  journal={Information and Inference: A Journal of the IMA},
  volume={4},
  number={2},
  pages={108--153},
  year={2015},
  publisher={Oxford University Press}
}

@article{lillicrap2016random,
  title={Random synaptic feedback weights support error backpropagation for deep learning},
  author={Lillicrap, Timothy P and Cownden, Daniel and Tweed, Douglas B and Akerman, Colin J},
  journal={Nature Communications},
  volume={7},
  pages={13276(1--10)},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{amari1990mathematical,
  title={Mathematical foundations of neurocomputing},
  author={Amari, S-I},
  journal={Proceedings of the IEEE},
  volume={78},
  number={9},
  pages={1443--1463},
  year={1990},
  publisher={IEEE}
}

@article{lei2016layer,
  title={Layer normalization},
  author={Lei Ba, Jimmy and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv:1607.06450},
  year={2016}
}

@book{amari2016information,
  title={Information geometry and its applications},
  author={Amari, Shun-ichi},
  year={2016},
  publisher={Springer}
}

@article{pascanu2013,
  title={Revisiting natural gradient for deep networks},
  author={Pascanu, Razvan and Bengio, Yoshua},
  journal={ICLR 2014, arXiv:1301.3584},
  year={2014}
}

@article{ama1998,
  title={Natural gradient works efficiently in learning},
  author={Amari, Shun-ichi},
  journal={Neural Computation},
  volume={10},
  number={2},
  pages={251--276},
  year={1998},
  publisher={MIT Press}
}

@article{mei2016landscape,
  title={The landscape of empirical risk for non-convex losses},
  author={Mei, Song and Bai, Yu and Montanari, Andrea},
  journal={arXiv preprint arXiv:1607.06534},
  year={2016}
}

@inproceedings{tian2016symmetry,
  title={An Analytical Formula of Population Gradient for two-layered {R}e{LU} network and its Applications in Convergence and Critical Point Analysis},
   author={Tian, Yuandong},
   booktitle = {Proceedings of International Conference on Machine Learning (ICML)},
  pages = 	 {3404--3413},
  year = 	 {2017}
}

@article{raghu2016expressive,
  title={On the expressive power of deep neural networks},
  author={Raghu, Maithra and Poole, Ben and Kleinberg, Jon and Ganguli, Surya and Sohl-Dickstein, Jascha},
  journal={Proceedings of ICML},
  year={2017}
}
