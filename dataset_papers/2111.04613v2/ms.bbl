\begin{thebibliography}{10}

\bibitem{akkaya2019solving}
Ilge Akkaya, Marcin Andrychowicz, Maciek Chociej, Mateusz Litwin, Bob McGrew,
  Arthur Petron, Alex Paino, Matthias Plappert, Glenn Powell, Raphael Ribas,
  et~al.
\newblock Solving rubik's cube with a robot hand.
\newblock {\em arXiv preprint arXiv:1910.07113}, 2019.

\bibitem{baker2020emergent}
Bowen Baker, Ingmar Kanitscheider, Todor Markov, Yi~Wu, Glenn Powell, Bob
  McGrew, and Igor Mordatch.
\newblock Emergent tool use from multi-agent autocurricula.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{bard2020hanabi}
Nolan Bard, Jakob~N Foerster, Sarath Chandar, Neil Burch, Marc Lanctot,
  H~Francis Song, Emilio Parisotto, Vincent Dumoulin, Subhodeep Moitra, Edward
  Hughes, et~al.
\newblock The hanabi challenge: A new frontier for ai research.
\newblock {\em Artificial Intelligence}, 280:103216, 2020.

\bibitem{bengio2009curriculum}
Yoshua Bengio, J{\'e}r{\^o}me Louradour, Ronan Collobert, and Jason Weston.
\newblock Curriculum learning.
\newblock In {\em Proceedings of the 26th annual international conference on
  machine learning}, pages 41--48, 2009.

\bibitem{berner2019dota}
Christopher Berner, Greg Brockman, Brooke Chan, Vicki Cheung, Przemys{\l}aw
  Debiak, Christy Dennison, David Farhi, Quirin Fischer, Shariq Hashme, Chris
  Hesse, et~al.
\newblock Dota 2 with large scale deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1912.06680}, 2019.

\bibitem{campero2021learning}
Andres Campero, Roberta Raileanu, Heinrich Kuttler, Joshua~B. Tenenbaum, Tim
  Rockt{\"a}schel, and Edward Grefenstette.
\newblock Learning with {\{}amig{\}}o: Adversarially motivated intrinsic goals.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{fang2021adaptive}
Kuan Fang, Yuke Zhu, Silvio Savarese, and Fei-Fei Li.
\newblock Adaptive procedural task generation for hard-exploration problems.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{feng2020solving}
Dieqiao Feng, Carla Gomes, and Bart Selman.
\newblock Solving hard ai planning instances using curriculum-driven deep
  reinforcement learning.
\newblock In {\em Proceedings of the Twenty-Ninth International Joint
  Conference on Artificial Intelligence, {IJCAI-20}}, 2020.

\bibitem{florensa2018automatic}
Carlos Florensa, David Held, Xinyang Geng, and Pieter Abbeel.
\newblock Automatic goal generation for reinforcement learning agents.
\newblock In {\em International conference on machine learning}, pages
  1515--1528. PMLR, 2018.

\bibitem{florensa2017reverse}
Carlos Florensa, David Held, Markus Wulfmeier, Michael Zhang, and Pieter
  Abbeel.
\newblock Reverse curriculum generation for reinforcement learning.
\newblock In {\em Conference on robot learning}, pages 482--495. PMLR, 2017.

\bibitem{ivanovic2019barc}
Boris Ivanovic, James Harrison, Apoorva Sharma, Mo~Chen, and Marco Pavone.
\newblock Barc: Backward reachability curriculum for robotic reinforcement
  learning.
\newblock In {\em 2019 International Conference on Robotics and Automation
  (ICRA)}, pages 15--21. IEEE, 2019.

\bibitem{jabri2019unsupervised}
Allan Jabri, Kyle Hsu, Abhishek Gupta, Ben Eysenbach, Sergey Levine, and
  Chelsea Finn.
\newblock Unsupervised curricula for visual meta-reinforcement learning.
\newblock In {\em Advances in Neural Information Processing Systems}, 2019.

\bibitem{NIPS2018_7956}
Jiechuan Jiang and Zongqing Lu.
\newblock Learning attentional communication for multi-agent cooperation.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, {\em Advances in Neural Information Processing
  Systems 31}, pages 7254--7264. Curran Associates, Inc., 2018.

\bibitem{klink2019self}
Pascal Klink, Hany Abdulsamad, Boris Belousov, and Jan Peters.
\newblock Self-paced contextual reinforcement learning.
\newblock In {\em CoRL}, 2019.

\bibitem{klink2020self}
Pascal Klink, Carlo D'Eramo, Jan Peters, and Joni Pajarinen.
\newblock Self-paced deep reinforcement learning.
\newblock In {\em NeurIPS}, 2020.

\bibitem{leibo2019autocurricula}
Joel~Z Leibo, Edward Hughes, Marc Lanctot, and Thore Graepel.
\newblock Autocurricula and the emergence of innovation from social
  interaction: A manifesto for multi-agent intelligence research.
\newblock {\em arXiv preprint arXiv:1903.00742}, 2019.

\bibitem{liu2016stein}
Qiang Liu and Dilin Wang.
\newblock Stein variational gradient descent: a general purpose bayesian
  inference algorithm.
\newblock In {\em Proceedings of the 30th International Conference on Neural
  Information Processing Systems}, pages 2378--2386, 2016.

\bibitem{long2020evolutionary}
Qian Long, Zihan Zhou, Abhinav Gupta, Fei Fang, Yi~Wu, and Xiaolong Wang.
\newblock Evolutionary population curriculum for scaling multi-agent
  reinforcement learning.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{lowe2017multi}
Ryan Lowe, Yi~Wu, Aviv Tamar, Jean Harb, Pieter Abbeel, and Igor Mordatch.
\newblock Multi-agent actor-critic for mixed cooperative-competitive
  environments.
\newblock In {\em Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, 2017.

\bibitem{matiisen2019teacher}
Tambet Matiisen, Avital Oliver, Taco Cohen, and John Schulman.
\newblock Teacher-student curriculum learning.
\newblock {\em IEEE transactions on neural networks and learning systems},
  2019.

\bibitem{mehta2020active}
Bhairav Mehta, Manfred Diaz, Florian Golemo, Christopher~J Pal, and Liam Paull.
\newblock Active domain randomization.
\newblock In {\em Conference on Robot Learning}, pages 1162--1176. PMLR, 2020.

\bibitem{morad2021embodied}
Steven Morad, Roberto Mecca, Rudra Poudel, Stephan Liwicki, and Roberto
  Cipolla.
\newblock Embodied visual navigation with automatic curriculum learning in real
  environments.
\newblock {\em IEEE Robotics and Automation Letters}, 2021.

\bibitem{panait2005cooperative}
Liviu Panait and Sean Luke.
\newblock Cooperative multi-agent learning: The state of the art.
\newblock {\em Autonomous agents and multi-agent systems}, 11(3):387--434,
  2005.

\bibitem{portelas2019teacher}
R{\'e}my Portelas, C{\'e}dric Colas, Katja Hofmann, and Pierre-Yves Oudeyer.
\newblock Teacher algorithms for curriculum learning of deep {RL} in
  continuously parameterized environments.
\newblock {\em arXiv preprint arXiv:1910.07224}, 2019.

\bibitem{portelas2020automatic}
R{\'e}my Portelas, C{\'e}dric Colas, Lilian Weng, Katja Hofmann, and
  Pierre-Yves Oudeyer.
\newblock Automatic curriculum learning for deep rl: A short survey.
\newblock {\em arXiv preprint arXiv:2003.04664}, 2020.

\bibitem{Racaniere2020Automated}
Sebastien Racaniere, Andrew Lampinen, Adam Santoro, David Reichert, Vlad
  Firoiu, and Timothy Lillicrap.
\newblock Automated curriculum generation through setter-solver interactions.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{ren2019exploration}
Zhizhou Ren, Kefan Dong, Yuan Zhou, Qiang Liu, and Jian Peng.
\newblock Exploration via hindsight goal generation.
\newblock {\em arXiv preprint arXiv:1906.04279}, 2019.

\bibitem{sukhbaatar2018intrinsic}
Sainbayar Sukhbaatar, Zeming Lin, Ilya Kostrikov, Gabriel Synnaeve, Arthur
  Szlam, and Rob Fergus.
\newblock Intrinsic motivation and automatic curricula via asymmetric
  self-play.
\newblock In {\em International Conference on Learning Representations}, 2018.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In {\em Advances in neural information processing systems}, pages
  5998--6008, 2017.

\bibitem{vinyals2019grandmaster}
Oriol Vinyals, Igor Babuschkin, Wojciech~M Czarnecki, Micha{\"e}l Mathieu,
  Andrew Dudzik, Junyoung Chung, David~H Choi, Richard Powell, Timo Ewalds,
  Petko Georgiev, et~al.
\newblock Grandmaster level in {StarCraft II} using multi-agent reinforcement
  learning.
\newblock {\em Nature}, 575(7782):350--354, 2019.

\bibitem{wang2020enhanced}
Rui Wang, Joel Lehman, Aditya Rawal, Jiale Zhi, Yulun Li, Jeffrey Clune, and
  Kenneth Stanley.
\newblock Enhanced poet: Open-ended reinforcement learning through unbounded
  invention of learning challenges and their solutions.
\newblock In {\em International Conference on Machine Learning}, pages
  9940--9951. PMLR, 2020.

\bibitem{wang2019largescale}
Weixun Wang, Tianpei Yang, Yong Liu, Jianye Hao, Xiaotian Hao, Yujing Hu,
  Yingfeng Chen, Changjie Fan, and Yang Gao.
\newblock From few to more: Large-scale dynamic multiagent curriculum learning,
  2019.

\bibitem{wohlke2020performance}
Jan W{\"o}hlke, Felix Schmitt, and Herke van Hoof.
\newblock A performance-based start state curriculum framework for
  reinforcement learning.
\newblock In {\em Proceedings of the 19th International Conference on
  Autonomous Agents and MultiAgent Systems}, pages 1503--1511, 2020.

\bibitem{yang2020multitask}
Ruihan Yang, Huazhe Xu, Yi~Wu, and Xiaolong Wang.
\newblock Multi-task reinforcement learning with soft modularization.
\newblock In {\em Advances in Neural Information Processing Systems}, 2020.

\bibitem{yu2021surprising}
Chao Yu, Akash Velu, Eugene Vinitsky, Yu~Wang, Alexandre Bayen, and Yi~Wu.
\newblock The surprising effectiveness of ppo in cooperative, multi-agent
  games, 2021.

\end{thebibliography}
