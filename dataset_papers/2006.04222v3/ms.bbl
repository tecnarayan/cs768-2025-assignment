\begin{thebibliography}{44}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal et~al.(2019)Agarwal, Kumar, and Sycara]{agarwal2019learning}
Agarwal, A., Kumar, S., and Sycara, K.
\newblock Learning transferable cooperative behavior in multi-agent teams.
\newblock \emph{arXiv preprint arXiv:1906.01202}, 2019.

\bibitem[Baker et~al.(2019)Baker, Kanitscheider, Markov, Wu, Powell, McGrew,
  and Mordatch]{baker2019emergent}
Baker, B., Kanitscheider, I., Markov, T., Wu, Y., Powell, G., McGrew, B., and
  Mordatch, I.
\newblock Emergent tool use from multi-agent autocurricula.
\newblock In \emph{International Conference on Learning Representations}, 2019.

\bibitem[Bansal et~al.(2018)Bansal, Pachocki, Sidor, Sutskever, and
  Mordatch]{Bansal2017-qm}
Bansal, T., Pachocki, J., Sidor, S., Sutskever, I., and Mordatch, I.
\newblock Emergent complexity via multi-agent competition.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[B{\"{o}}hmer et~al.(2020)B{\"{o}}hmer, Kurin, and
  Whiteson]{boehmer2019dcg}
B{\"{o}}hmer, W., Kurin, V., and Whiteson, S.
\newblock Deep coordination graphs.
\newblock In \emph{Proceedings of Machine Learning and Systems (ICML)}, pp.\
  2611--2622, 2020.

\bibitem[Burden(2020)]{burden_deep_2020}
Burden, N.
\newblock Deep {Multi}-{Agent} {Reinforcement} {Learning} in {Starcraft} {II}.
\newblock Master's thesis, University of Oxford, 2020.

\bibitem[Carion et~al.(2019)Carion, Usunier, Synnaeve, and
  Lazaric]{carion2019structured}
Carion, N., Usunier, N., Synnaeve, G., and Lazaric, A.
\newblock A structured prediction approach for generalization in cooperative
  multi-agent reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  8128--8138, 2019.

\bibitem[Chung et~al.(2014)Chung, Gulcehre, Cho, and
  Bengio]{chung2014empirical}
Chung, J., Gulcehre, C., Cho, K., and Bengio, Y.
\newblock Empirical evaluation of gated recurrent neural networks on sequence
  modeling.
\newblock In \emph{NIPS 2014 Workshop on Deep Learning, December 2014}, 2014.

\bibitem[Claus \& Boutilier(1998)Claus and Boutilier]{claus1998dynamics}
Claus, C. and Boutilier, C.
\newblock The dynamics of reinforcement learning in cooperative multiagent
  systems.
\newblock \emph{AAAI/IAAI}, 1998\penalty0 (746-752):\penalty0 2, 1998.

\bibitem[Clevert et~al.(2015)Clevert, Unterthiner, and
  Hochreiter]{clevert2015fast}
Clevert, D.-A., Unterthiner, T., and Hochreiter, S.
\newblock Fast and accurate deep network learning by exponential linear units
  (elus).
\newblock \emph{arXiv preprint arXiv:1511.07289}, 2015.

\bibitem[Foerster et~al.(2018)Foerster, Farquhar, Afouras, Nardelli, and
  Whiteson]{Foerster2017-do}
Foerster, J., Farquhar, G., Afouras, T., Nardelli, N., and Whiteson, S.
\newblock Counterfactual multi-agent policy gradients.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2018.

\bibitem[Ha et~al.(2017)Ha, Dai, and Le]{ha2016hypernetworks}
Ha, D., Dai, A.~M., and Le, Q.~V.
\newblock Hypernetworks.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Hausknecht(2016)]{hausknecht_cooperation_2016}
Hausknecht, M.~J.
\newblock \emph{Cooperation and {Communication} in {Multiagent} {Deep}
  {Reinforcement} {Learning}}.
\newblock {PhD} thesis, The University of Texas at Austin, 2016.

\bibitem[Hausknecht \& Stone(2015)Hausknecht and Stone]{Hausknecht15}
Hausknecht, M.~J. and Stone, P.
\newblock Deep recurrent q-learning for partially observable mdps.
\newblock In \emph{2015 {AAAI} Fall Symposia}, pp.\  29--37, 2015.

\bibitem[Hu et~al.(2021)Hu, Zhu, Chang, and Liang]{hu2021updet}
Hu, S., Zhu, F., Chang, X., and Liang, X.
\newblock {\{}UPD{\}}et: Universal multi-agent {\{}rl{\}} via policy decoupling
  with transformers.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Iqbal \& Sha(2019)Iqbal and Sha]{pmlr-v97-iqbal19a}
Iqbal, S. and Sha, F.
\newblock Actor-attention-critic for multi-agent reinforcement learning.
\newblock In Chaudhuri, K. and Salakhutdinov, R. (eds.), \emph{Proceedings of
  the 36th International Conference on Machine Learning}, volume~97 of
  \emph{Proceedings of Machine Learning Research}, pp.\  2961--2970, Long
  Beach, California, USA, 09--15 Jun 2019. PMLR.

\bibitem[Jiang \& Lu(2018)Jiang and Lu]{jiang2018learning}
Jiang, J. and Lu, Z.
\newblock Learning attentional communication for multi-agent cooperation.
\newblock In Bengio, S., Wallach, H., Larochelle, H., Grauman, K.,
  Cesa-Bianchi, N., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems}, volume~31, pp.\  7254--7264. Curran
  Associates, Inc., 2018.

\bibitem[Koller \& Parr(1999)Koller and Parr]{koller1999computing}
Koller, D. and Parr, R.
\newblock Computing factored value functions for policies in structured mdps.
\newblock In \emph{IJCAI}, volume~99, pp.\  1332--1339, 1999.

\bibitem[Lanctot et~al.(2017)Lanctot, Zambaldi, Gruslys, Lazaridou, Tuyls,
  Perolat, Silver, and Graepel]{Lanctot2017-gr}
Lanctot, M., Zambaldi, V., Gruslys, A., Lazaridou, A., Tuyls, K., Perolat, J.,
  Silver, D., and Graepel, T.
\newblock A unified {Game-Theoretic} approach to multiagent reinforcement
  learning.
\newblock In Guyon, I., Luxburg, U.~V., Bengio, S., Wallach, H., Fergus, R.,
  Vishwanathan, S., and Garnett, R. (eds.), \emph{Advances in Neural
  Information Processing Systems 30}, pp.\  4193--4206. Curran Associates,
  Inc., 2017.

\bibitem[Lee et~al.(2019)Lee, Lee, Kim, Kosiorek, Choi, and
  Teh]{pmlr-v97-lee19d}
Lee, J., Lee, Y., Kim, J., Kosiorek, A., Choi, S., and Teh, Y.~W.
\newblock Set transformer: A framework for attention-based
  permutation-invariant neural networks.
\newblock In Chaudhuri, K. and Salakhutdinov, R. (eds.), \emph{Proceedings of
  the 36th International Conference on Machine Learning}, volume~97 of
  \emph{Proceedings of Machine Learning Research}, pp.\  3744--3753, Long
  Beach, California, USA, 09--15 Jun 2019. PMLR.

\bibitem[Lin(1992)]{Lin92}
Lin, L.-J.
\newblock Self-improving reactive agents based on reinforcement learning,
  planning and teaching.
\newblock \emph{Machine Learning}, 8\penalty0 (3):\penalty0 293--321, 1992.

\bibitem[Long et~al.(2020)Long, Zhou, Gupta, Fang, Wu, and
  Wang]{Long2020Evolutionary}
Long, Q., Zhou, Z., Gupta, A., Fang, F., Wu, Y., and Wang, X.
\newblock Evolutionary population curriculum for scaling multi-agent
  reinforcement learning.
\newblock In \emph{International Conference on Learning Representations}, 2020.

\bibitem[Lowe et~al.(2017)Lowe, Wu, Tamar, Harb, Abbeel, and
  Mordatch]{lowe2017multi}
Lowe, R., Wu, Y., Tamar, A., Harb, J., Abbeel, O.~P., and Mordatch, I.
\newblock Multi-agent actor-critic for mixed cooperative-competitive
  environments.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  6382--6393, 2017.

\bibitem[Mahajan et~al.(2019)Mahajan, Rashid, Samvelyan, and
  Whiteson]{mahajan2019maven}
Mahajan, A., Rashid, T., Samvelyan, M., and Whiteson, S.
\newblock Maven: Multi-agent variational exploration.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  7613--7624, 2019.

\bibitem[Mnih et~al.(2015)Mnih, Kavukcuoglu, Silver, Rusu, Veness, Bellemare,
  Graves, Riedmiller, Fidjeland, Ostrovski, et~al.]{mnih2015human}
Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.~A., Veness, J., Bellemare,
  M.~G., Graves, A., Riedmiller, M., Fidjeland, A.~K., Ostrovski, G., et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock \emph{Nature}, 518\penalty0 (7540):\penalty0 529, 2015.

\bibitem[Oliehoek et~al.(2008)Oliehoek, Spaan, Vlassis, and
  Whiteson]{oliehoek2008exploiting}
Oliehoek, F.~A., Spaan, M.~T., Vlassis, N., and Whiteson, S.
\newblock Exploiting locality of interaction in factored dec-pomdps.
\newblock In \emph{Int. Joint Conf. on Autonomous Agents and Multi-Agent
  Systems}, pp.\  517--524, 2008.

\bibitem[Oliehoek et~al.(2016)Oliehoek, Amato, et~al.]{oliehoek2016concise}
Oliehoek, F.~A., Amato, C., et~al.
\newblock \emph{A concise introduction to decentralized POMDPs}, volume~1.
\newblock Springer, 2016.

\bibitem[Prorok et~al.(2017)Prorok, Hsieh, and Kumar]{prorok2017impact}
Prorok, A., Hsieh, M.~A., and Kumar, V.
\newblock The impact of diversity on optimal control policies for heterogeneous
  robot swarms.
\newblock \emph{IEEE Transactions on Robotics}, 33\penalty0 (2):\penalty0
  346--358, 2017.

\bibitem[Rashid et~al.(2018)Rashid, Samvelyan, Schroeder, Farquhar, Foerster,
  and Whiteson]{rashid2018qmix}
Rashid, T., Samvelyan, M., Schroeder, C., Farquhar, G., Foerster, J., and
  Whiteson, S.
\newblock {QMIX}: Monotonic value function factorisation for deep multi-agent
  reinforcement learning.
\newblock In \emph{Proceedings of the 35th International Conference on Machine
  Learning}, volume~80 of \emph{Proceedings of Machine Learning Research}, pp.\
   4295--4304, Stockholmsm√§ssan, Stockholm Sweden, 10--15 Jul 2018.

\bibitem[Rashid et~al.(2020)Rashid, Samvelyan, de~Witt, Farquhar, Foerster, and
  Whiteson]{JMLR:v21:20-081}
Rashid, T., Samvelyan, M., de~Witt, C.~S., Farquhar, G., Foerster, J., and
  Whiteson, S.
\newblock Monotonic value function factorisation for deep multi-agent
  reinforcement learning.
\newblock \emph{Journal of Machine Learning Research}, 21\penalty0
  (178):\penalty0 1--51, 2020.

\bibitem[Russell \& Zimdars(2003)Russell and
  Zimdars]{russell_q-decomposition_2003}
Russell, S. and Zimdars, A.~L.
\newblock Q-decomposition for reinforcement learning agents.
\newblock In \emph{Proceedings of the {Twentieth} {International} {Conference}
  on {International} {Conference} on {Machine} {Learning}}, {ICML}'03, pp.\
  656--663, Washington, DC, USA, August 2003. AAAI Press.
\newblock ISBN 978-1-57735-189-4.

\bibitem[Samvelyan et~al.(2019)Samvelyan, Rashid, Schroeder~de Witt, Farquhar,
  Nardelli, Rudner, Hung, Torr, Foerster, and Whiteson]{samvelyan2019starcraft}
Samvelyan, M., Rashid, T., Schroeder~de Witt, C., Farquhar, G., Nardelli, N.,
  Rudner, T.~G., Hung, C.-M., Torr, P.~H., Foerster, J., and Whiteson, S.
\newblock The starcraft multi-agent challenge.
\newblock In \emph{Proceedings of the 18th International Conference on
  Autonomous Agents and MultiAgent Systems}, pp.\  2186--2188. International
  Foundation for Autonomous Agents and Multiagent Systems, 2019.

\bibitem[Schneider et~al.(1999)Schneider, Wong, Moore, and
  Riedmiller]{schneider_distributed_1999}
Schneider, J., Wong, W.-K., Moore, A., and Riedmiller, M.
\newblock Distributed {Value} {Functions}.
\newblock In \emph{In {Proceedings} of the {Sixteenth} {International}
  {Conference} on {Machine} {Learning}}, pp.\  371--378. Morgan Kaufmann, 1999.

\bibitem[Schroeder~de Witt et~al.(2019)Schroeder~de Witt, Foerster, Farquhar,
  Torr, Boehmer, and Whiteson]{NIPS2019_9184}
Schroeder~de Witt, C., Foerster, J., Farquhar, G., Torr, P., Boehmer, W., and
  Whiteson, S.
\newblock Multi-agent common knowledge reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pp.\
  9927--9939. Curran Associates, Inc., 2019.

\bibitem[Son et~al.(2019)Son, Kim, Kang, Hostallero, and Yi]{son2019qtran}
Son, K., Kim, D., Kang, W.~J., Hostallero, D.~E., and Yi, Y.
\newblock Qtran: Learning to factorize with transformation for cooperative
  multi-agent reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5887--5896, 2019.

\bibitem[Srivastava et~al.(2014)Srivastava, Hinton, Krizhevsky, Sutskever, and
  Salakhutdinov]{srivastava2014dropout}
Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov,
  R.
\newblock Dropout: a simple way to prevent neural networks from overfitting.
\newblock \emph{The journal of machine learning research}, 15\penalty0
  (1):\penalty0 1929--1958, 2014.

\bibitem[Sunehag et~al.(2018)Sunehag, Lever, Gruslys, Czarnecki, Zambaldi,
  Jaderberg, Lanctot, Sonnerat, Leibo, Tuyls, and Graepel]{sunehag2017value}
Sunehag, P., Lever, G., Gruslys, A., Czarnecki, W.~M., Zambaldi, V., Jaderberg,
  M., Lanctot, M., Sonnerat, N., Leibo, J.~Z., Tuyls, K., and Graepel, T.
\newblock Value-decomposition networks for cooperative multi-agent learning
  based on team reward.
\newblock In \emph{Proceedings of the 17th International Conference on
  Autonomous Agents and MultiAgent Systems}, AAMAS '18, pp.\  2085--2087,
  Richland, SC, 2018. International Foundation for Autonomous Agents and
  Multiagent Systems.

\bibitem[Tieleman \& Hinton(2012)Tieleman and Hinton]{tieleman2012lecture}
Tieleman, T. and Hinton, G.
\newblock Lecture 6.5-rmsprop: Divide the gradient by a running average of its
  recent magnitude.
\newblock \emph{COURSERA: Neural networks for machine learning}, 4\penalty0
  (2):\penalty0 26--31, 2012.

\bibitem[van Hasselt et~al.(2016)van Hasselt, Guez, and Silver]{Hasselt16}
van Hasselt, H., Guez, A., and Silver, D.
\newblock Deep reinforcement learning with double q-learning.
\newblock In \emph{Proceedings of the 13th AAAI Conference on Artificial
  Intelligence}, pp.\  2094--2100, 2016.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.~N.,
  Kaiser, {\L}., and Polosukhin, I.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  6000--6010, 2017.

\bibitem[Wang et~al.(2020{\natexlab{a}})Wang, Dong, Lesser, and
  Zhang]{wang2020roma}
Wang, T., Dong, H., Lesser, V., and Zhang, C.
\newblock Roma: Multi-agent reinforcement learning with emergent roles.
\newblock In \emph{Proceedings of the 37th International Conference on Machine
  Learning}, 2020{\natexlab{a}}.

\bibitem[Wang et~al.(2021)Wang, Gupta, Mahajan, Peng, Whiteson, and
  Zhang]{wang2021rode}
Wang, T., Gupta, T., Mahajan, A., Peng, B., Whiteson, S., and Zhang, C.
\newblock {\{}RODE{\}}: Learning roles to decompose multi-agent tasks.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Wang et~al.(2020{\natexlab{b}})Wang, Yang, Liu, Hao, Hao, Hu, Chen,
  Fan, and Gao]{wang2020action}
Wang, W., Yang, T., Liu, Y., Hao, J., Hao, X., Hu, Y., Chen, Y., Fan, C., and
  Gao, Y.
\newblock Action semantics network: Considering the effects of actions in
  multiagent systems.
\newblock In \emph{International Conference on Learning Representations},
  2020{\natexlab{b}}.

\bibitem[Wang et~al.(2020{\natexlab{c}})Wang, Yang, Liu, Hao, Hao, Hu, Chen,
  Fan, and Gao]{wang2020few}
Wang, W., Yang, T., Liu, Y., Hao, J., Hao, X., Hu, Y., Chen, Y., Fan, C., and
  Gao, Y.
\newblock From few to more: Large-scale dynamic multiagent curriculum learning.
\newblock In \emph{AAAI Conference on Artificial Intelligence},
  2020{\natexlab{c}}.

\bibitem[Yang et~al.(2020)Yang, Hao, Liao, Shao, Chen, Liu, and
  Tang]{yang2020qatten}
Yang, Y., Hao, J., Liao, B., Shao, K., Chen, G., Liu, W., and Tang, H.
\newblock Qatten: A general framework for cooperative multiagent reinforcement
  learning.
\newblock \emph{arXiv preprint arXiv:2002.03939}, 2020.

\end{thebibliography}
