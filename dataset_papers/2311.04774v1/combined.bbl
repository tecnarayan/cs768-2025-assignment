\begin{thebibliography}{58}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahuja et~al.(2022)Ahuja, Hartford, and Bengio]{ahuja2022weakly}
K.~Ahuja, J.~Hartford, and Y.~Bengio.
\newblock Weakly supervised representation learning with sparse perturbations.
\newblock \emph{arXiv preprint arXiv:2206.01101}, 2022.

\bibitem[Bachman et~al.(2019)Bachman, Hjelm, and
  Buchwalter]{bachman2019learning}
P.~Bachman, R.~D. Hjelm, and W.~Buchwalter.
\newblock Learning representations by maximizing mutual information across
  views.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Barlow et~al.(1989)Barlow, Kaushal, and Mitchison]{barlow1989finding}
H.~B. Barlow, T.~P. Kaushal, and G.~J. Mitchison.
\newblock Finding minimum entropy codes.
\newblock \emph{Neural Computation}, 1\penalty0 (3):\penalty0 412--423, 1989.

\bibitem[Ben-Israel(1999)]{prob_transform}
A.~Ben-Israel.
\newblock The change-of-variables formula using matrix volume.
\newblock \emph{SIAM Journal on Matrix Analysis and Applications}, 21\penalty0
  (1):\penalty0 300--312, 1999.

\bibitem[Brehmer et~al.(2022)Brehmer, De~Haan, Lippe, and
  Cohen]{brehmer2022weakly}
J.~Brehmer, P.~De~Haan, P.~Lippe, and T.~S. Cohen.
\newblock Weakly supervised causal representation learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  35:\penalty0 38319--38331, 2022.

\bibitem[Brouwer(1911)]{brouwer1911beweis}
L.~E. Brouwer.
\newblock Beweis der invarianz des n-dimensionalen gebiets.
\newblock \emph{Mathematische Annalen}, 71:\penalty0 305--313, 1911.

\bibitem[Cardoso(1998)]{cardoso1998blind}
J.-F. Cardoso.
\newblock Blind signal separation: statistical principles.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (10):\penalty0
  2009--2025, 1998.

\bibitem[Chen et~al.(2020)Chen, Kornblith, Norouzi, and Hinton]{simclr}
T.~Chen, S.~Kornblith, M.~Norouzi, and G.~Hinton.
\newblock A simple framework for contrastive learning of visual
  representations.
\newblock In \emph{International conference on machine learning}, pages
  1597--1607. PMLR, 2020.

\bibitem[Chen et~al.(2021)Chen, Luo, and Li]{chen2021intriguing}
T.~Chen, C.~Luo, and L.~Li.
\newblock Intriguing properties of contrastive losses.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 11834--11845, 2021.

\bibitem[Creager et~al.(2019)Creager, Madras, Jacobsen, Weis, Swersky, Pitassi,
  and Zemel]{creager2019flexibly}
E.~Creager, D.~Madras, J.-H. Jacobsen, M.~Weis, K.~Swersky, T.~Pitassi, and
  R.~Zemel.
\newblock Flexibly fair representation learning by disentanglement.
\newblock In \emph{International conference on machine learning}, pages
  1436--1445. PMLR, 2019.

\bibitem[Eastwood and Williams(2018)]{eastwood2018framework}
C.~Eastwood and C.~K. Williams.
\newblock A framework for the quantitative evaluation of disentangled
  representations.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Fumero et~al.(2021)Fumero, Cosmo, Melzi, and
  Rodol{\`a}]{fumero2021learning}
M.~Fumero, L.~Cosmo, S.~Melzi, and E.~Rodol{\`a}.
\newblock Learning disentangled representations via product manifold
  projection.
\newblock In \emph{International conference on machine learning}, pages
  3530--3540. PMLR, 2021.

\bibitem[Gao et~al.(2019)Gao, Mao, Dong, Jing, and Chinnam]{gao2019learning}
L.~Gao, Q.~Mao, M.~Dong, Y.~Jing, and R.~Chinnam.
\newblock On learning disentangled representation for acoustic event detection.
\newblock In \emph{Proceedings of the 27th ACM International Conference on
  Multimedia}, pages 2006--2014, 2019.

\bibitem[Geiger et~al.(2012)Geiger, Lenz, and Urtasun]{geiger2012we}
A.~Geiger, P.~Lenz, and R.~Urtasun.
\newblock Are we ready for autonomous driving? the kitti vision benchmark
  suite.
\newblock In \emph{2012 IEEE conference on computer vision and pattern
  recognition}, pages 3354--3361. IEEE, 2012.

\bibitem[Geirhos et~al.(2020)Geirhos, Jacobsen, Michaelis, Zemel, Brendel,
  Bethge, and Wichmann]{geirhos2020shortcut}
R.~Geirhos, J.-H. Jacobsen, C.~Michaelis, R.~Zemel, W.~Brendel, M.~Bethge, and
  F.~A. Wichmann.
\newblock Shortcut learning in deep neural networks.
\newblock \emph{Nature Machine Intelligence}, 2\penalty0 (11):\penalty0
  665--673, 2020.

\bibitem[Gresele et~al.(2020)Gresele, Rubenstein, Mehrjou, Locatello, and
  Sch{\"o}lkopf]{gresele2020incomplete}
L.~Gresele, P.~K. Rubenstein, A.~Mehrjou, F.~Locatello, and B.~Sch{\"o}lkopf.
\newblock The incomplete rosetta stone problem: Identifiability results for
  multi-view nonlinear ica.
\newblock In \emph{Uncertainty in Artificial Intelligence}, pages 217--227.
  PMLR, 2020.

\bibitem[Gresele et~al.(2021)Gresele, Von~K{\"u}gelgen, Stimper, Sch{\"o}lkopf,
  and Besserve]{ima}
L.~Gresele, J.~Von~K{\"u}gelgen, V.~Stimper, B.~Sch{\"o}lkopf, and M.~Besserve.
\newblock Independent mechanism analysis, a new concept?
\newblock \emph{Advances in neural information processing systems},
  34:\penalty0 28233--28248, 2021.

\bibitem[Gutmann and Hyv{\"a}rinen(2010)]{nce}
M.~Gutmann and A.~Hyv{\"a}rinen.
\newblock Noise-contrastive estimation: A new estimation principle for
  unnormalized statistical models.
\newblock In \emph{Proceedings of the thirteenth international conference on
  artificial intelligence and statistics}, pages 297--304. JMLR Workshop and
  Conference Proceedings, 2010.

\bibitem[Gutmann and Hyv{\"a}rinen(2012)]{nce2}
M.~U. Gutmann and A.~Hyv{\"a}rinen.
\newblock Noise-contrastive estimation of unnormalized statistical models, with
  applications to natural image statistics.
\newblock \emph{Journal of machine learning research}, 13\penalty0 (2), 2012.

\bibitem[HaoChen et~al.(2021)HaoChen, Wei, Gaidon, and Ma]{scl}
J.~Z. HaoChen, C.~Wei, A.~Gaidon, and T.~Ma.
\newblock Provable guarantees for self-supervised deep learning with spectral
  contrastive loss.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 5000--5011, 2021.

\bibitem[He et~al.(2020)He, Fan, Wu, Xie, and Girshick]{he2020momentum}
K.~He, H.~Fan, Y.~Wu, S.~Xie, and R.~Girshick.
\newblock Momentum contrast for unsupervised visual representation learning.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision
  and pattern recognition}, pages 9729--9738, 2020.

\bibitem[Hendrycks and Gimpel(2016)]{hendrycks2016gaussian}
D.~Hendrycks and K.~Gimpel.
\newblock Gaussian error linear units (gelus).
\newblock \emph{arXiv preprint arXiv:1606.08415}, 2016.

\bibitem[Hjelm et~al.(2018)Hjelm, Fedorov, Lavoie-Marchildon, Grewal, Bachman,
  Trischler, and Bengio]{dim}
R.~D. Hjelm, A.~Fedorov, S.~Lavoie-Marchildon, K.~Grewal, P.~Bachman,
  A.~Trischler, and Y.~Bengio.
\newblock Learning deep representations by mutual information estimation and
  maximization.
\newblock \emph{arXiv preprint arXiv:1808.06670}, 2018.

\bibitem[Horan et~al.(2021)Horan, Richardson, and Weiss]{horan2021unsupervised}
D.~Horan, E.~Richardson, and Y.~Weiss.
\newblock When is unsupervised disentanglement possible?
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 5150--5161, 2021.

\bibitem[Hyv{\"a}rinen and Morioka(2016)]{tcl}
A.~Hyv{\"a}rinen and H.~Morioka.
\newblock Unsupervised feature extraction by time-contrastive learning and
  nonlinear ica.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Hyv{\"a}rinen and Morioka(2017)]{pcl}
A.~Hyv{\"a}rinen and H.~Morioka.
\newblock Nonlinear ica of temporally dependent stationary sources.
\newblock In \emph{Artificial Intelligence and Statistics}, pages 460--469.
  PMLR, 2017.

\bibitem[Hyv{\"a}rinen and Pajunen(1999)]{hyvarinen1999nonlinear}
A.~Hyv{\"a}rinen and P.~Pajunen.
\newblock Nonlinear independent component analysis: Existence and uniqueness
  results.
\newblock \emph{Neural networks}, 12\penalty0 (3):\penalty0 429--439, 1999.

\bibitem[Hyv{\"a}rinen et~al.(2019)Hyv{\"a}rinen, Sasaki, and Turner]{gcl}
A.~Hyv{\"a}rinen, H.~Sasaki, and R.~E. Turner.
\newblock Nonlinear ica using auxiliary variables and generalized contrastive
  learning.
\newblock In \emph{The 22nd International Conference on Artificial Intelligence
  and Statistics}, pages 859--868. PMLR, 2019.

\bibitem[Jozefowicz et~al.(2016)Jozefowicz, Vinyals, Schuster, Shazeer, and
  Wu]{jozefowicz2016exploring}
R.~Jozefowicz, O.~Vinyals, M.~Schuster, N.~Shazeer, and Y.~Wu.
\newblock Exploring the limits of language modeling.
\newblock \emph{arXiv preprint arXiv:1602.02410}, 2016.

\bibitem[Khemakhem et~al.(2020{\natexlab{a}})Khemakhem, Kingma, Monti, and
  Hyvarinen]{ivae}
I.~Khemakhem, D.~Kingma, R.~Monti, and A.~Hyvarinen.
\newblock Variational autoencoders and nonlinear ica: A unifying framework.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 2207--2217. PMLR, 2020{\natexlab{a}}.

\bibitem[Khemakhem et~al.(2020{\natexlab{b}})Khemakhem, Monti, Kingma, and
  Hyvarinen]{ice_beem}
I.~Khemakhem, R.~Monti, D.~Kingma, and A.~Hyvarinen.
\newblock Ice-beem: Identifiable conditional energy-based deep models based on
  nonlinear ica.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 12768--12778, 2020{\natexlab{b}}.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
D.~P. Kingma and J.~Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kingma and Welling(2014)]{vae}
D.~P. Kingma and M.~Welling.
\newblock {Auto-Encoding Variational Bayes}.
\newblock In \emph{2nd International Conference on Learning Representations,
  {ICLR} 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track
  Proceedings}, 2014.

\bibitem[Klindt et~al.(2020)Klindt, Schott, Sharma, Ustyuzhaninov, Brendel,
  Bethge, and Paiton]{slow_vae}
D.~Klindt, L.~Schott, Y.~Sharma, I.~Ustyuzhaninov, W.~Brendel, M.~Bethge, and
  D.~Paiton.
\newblock Towards nonlinear disentanglement in natural data with temporal
  sparse coding.
\newblock \emph{arXiv preprint arXiv:2007.10930}, 2020.

\bibitem[Lachapelle et~al.(2022)Lachapelle, Rodriguez, Sharma, Everett,
  Le~Priol, Lacoste, and Lacoste-Julien]{lachapelle2022disentanglement}
S.~Lachapelle, P.~Rodriguez, Y.~Sharma, K.~E. Everett, R.~Le~Priol, A.~Lacoste,
  and S.~Lacoste-Julien.
\newblock Disentanglement via mechanism sparsity regularization: A new
  principle for nonlinear ica.
\newblock In \emph{Conference on Causal Learning and Reasoning}, pages
  428--484. PMLR, 2022.

\bibitem[Le-Khac et~al.(2020)Le-Khac, Healy, and Smeaton]{review_cl}
P.~H. Le-Khac, G.~Healy, and A.~F. Smeaton.
\newblock Contrastive representation learning: A framework and review.
\newblock \emph{Ieee Access}, 8:\penalty0 193907--193934, 2020.

\bibitem[Li and So(1994)]{li1994isometries}
C.-K. Li and W.~So.
\newblock Isometries of $\ell_p$-norm.
\newblock \emph{The American mathematical monthly}, 101\penalty0 (5):\penalty0
  452--453, 1994.

\bibitem[Lippe et~al.(2022)Lippe, Magliacane, L{\"o}we, Asano, Cohen, and
  Gavves]{lippe2022citris}
P.~Lippe, S.~Magliacane, S.~L{\"o}we, Y.~M. Asano, T.~Cohen, and S.~Gavves.
\newblock Citris: Causal identifiability from temporal intervened sequences.
\newblock In \emph{International Conference on Machine Learning}, pages
  13557--13603. PMLR, 2022.

\bibitem[Locatello et~al.(2019{\natexlab{a}})Locatello, Abbati, Rainforth,
  Bauer, Sch{\"o}lkopf, and Bachem]{locatello2019fairness}
F.~Locatello, G.~Abbati, T.~Rainforth, S.~Bauer, B.~Sch{\"o}lkopf, and
  O.~Bachem.
\newblock On the fairness of disentangled representations.
\newblock \emph{Advances in neural information processing systems}, 32,
  2019{\natexlab{a}}.

\bibitem[Locatello et~al.(2019{\natexlab{b}})Locatello, Bauer, Lucic, Raetsch,
  Gelly, Sch{\"o}lkopf, and Bachem]{locatello2019challenging}
F.~Locatello, S.~Bauer, M.~Lucic, G.~Raetsch, S.~Gelly, B.~Sch{\"o}lkopf, and
  O.~Bachem.
\newblock Challenging common assumptions in the unsupervised learning of
  disentangled representations.
\newblock In \emph{international conference on machine learning}, pages
  4114--4124. PMLR, 2019{\natexlab{b}}.

\bibitem[Locatello et~al.(2019{\natexlab{c}})Locatello, Tschannen, Bauer,
  R{\"a}tsch, Sch{\"o}lkopf, and Bachem]{locatello2019disentangling}
F.~Locatello, M.~Tschannen, S.~Bauer, G.~R{\"a}tsch, B.~Sch{\"o}lkopf, and
  O.~Bachem.
\newblock Disentangling factors of variation using few labels.
\newblock \emph{arXiv preprint arXiv:1905.01258}, 2019{\natexlab{c}}.

\bibitem[Locatello et~al.(2020)Locatello, Poole, R{\"a}tsch, Sch{\"o}lkopf,
  Bachem, and Tschannen]{locatello2020weakly}
F.~Locatello, B.~Poole, G.~R{\"a}tsch, B.~Sch{\"o}lkopf, O.~Bachem, and
  M.~Tschannen.
\newblock Weakly-supervised disentanglement without compromises.
\newblock In \emph{International Conference on Machine Learning}, pages
  6348--6359. PMLR, 2020.

\bibitem[Ma and Collins(2018)]{rank_loss}
Z.~Ma and M.~Collins.
\newblock Noise contrastive estimation and negative sampling for conditional
  models: Consistency and statistical efficiency.
\newblock \emph{arXiv preprint arXiv:1809.01812}, 2018.

\bibitem[Mankiewicz(1972)]{mankiewicz1972extension}
P.~Mankiewicz.
\newblock On extension of isometries in normed linear spaces.
\newblock \emph{Bull. Acad. Pol. Sci., S{\'e}r. Sci. Math. Astron. Phys},
  20:\penalty0 367--371, 1972.

\bibitem[Mnih and Kavukcuoglu(2013)]{mnih2013learning}
A.~Mnih and K.~Kavukcuoglu.
\newblock Learning word embeddings efficiently with noise-contrastive
  estimation.
\newblock \emph{Advances in neural information processing systems}, 26, 2013.

\bibitem[Nguyen et~al.(2010)Nguyen, Wainwright, and Jordan]{nwj}
X.~Nguyen, M.~J. Wainwright, and M.~I. Jordan.
\newblock Estimating divergence functionals and the likelihood ratio by convex
  risk minimization.
\newblock \emph{IEEE Transactions on Information Theory}, 56\penalty0
  (11):\penalty0 5847--5861, 2010.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{info_nce}
A.~v.~d. Oord, Y.~Li, and O.~Vinyals.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Ridgeway and Mozer(2018)]{ridgeway2018learning}
K.~Ridgeway and M.~C. Mozer.
\newblock Learning deep disentangled embeddings with the f-statistic loss.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Shu et~al.(2019)Shu, Chen, Kumar, Ermon, and Poole]{shu2019weakly}
R.~Shu, Y.~Chen, A.~Kumar, S.~Ermon, and B.~Poole.
\newblock Weakly supervised disentanglement with guarantees.
\newblock \emph{arXiv preprint arXiv:1910.09772}, 2019.

\bibitem[Taleb and Jutten(1999)]{taleb1999source}
A.~Taleb and C.~Jutten.
\newblock Source separation in post-nonlinear mixtures.
\newblock \emph{IEEE Transactions on signal Processing}, 47\penalty0
  (10):\penalty0 2807--2820, 1999.

\bibitem[Tian et~al.(2020{\natexlab{a}})Tian, Krishnan, and Isola]{cmc}
Y.~Tian, D.~Krishnan, and P.~Isola.
\newblock Contrastive multiview coding.
\newblock In \emph{Computer Vision--ECCV 2020: 16th European Conference,
  Glasgow, UK, August 23--28, 2020, Proceedings, Part XI 16}, pages 776--794.
  Springer, 2020{\natexlab{a}}.

\bibitem[Tian et~al.(2020{\natexlab{b}})Tian, Sun, Poole, Krishnan, Schmid, and
  Isola]{tian2020makes}
Y.~Tian, C.~Sun, B.~Poole, D.~Krishnan, C.~Schmid, and P.~Isola.
\newblock What makes for good views for contrastive learning?
\newblock \emph{Advances in neural information processing systems},
  33:\penalty0 6827--6839, 2020{\natexlab{b}}.

\bibitem[Tschannen et~al.(2019)Tschannen, Djolonga, Rubenstein, Gelly, and
  Lucic]{tschannen2019mutual}
M.~Tschannen, J.~Djolonga, P.~K. Rubenstein, S.~Gelly, and M.~Lucic.
\newblock On mutual information maximization for representation learning.
\newblock \emph{arXiv preprint arXiv:1907.13625}, 2019.

\bibitem[Van~Steenkiste et~al.(2019)Van~Steenkiste, Locatello, Schmidhuber, and
  Bachem]{van2019disentangled}
S.~Van~Steenkiste, F.~Locatello, J.~Schmidhuber, and O.~Bachem.
\newblock Are disentangled representations helpful for abstract visual
  reasoning?
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Von~K{\"u}gelgen et~al.(2021)Von~K{\"u}gelgen, Sharma, Gresele,
  Brendel, Sch{\"o}lkopf, Besserve, and Locatello]{von2021self}
J.~Von~K{\"u}gelgen, Y.~Sharma, L.~Gresele, W.~Brendel, B.~Sch{\"o}lkopf,
  M.~Besserve, and F.~Locatello.
\newblock Self-supervised learning with data augmentations provably isolates
  content from style.
\newblock \emph{Advances in neural information processing systems},
  34:\penalty0 16451--16467, 2021.

\bibitem[Wang and Isola(2020)]{wang2020understanding}
T.~Wang and P.~Isola.
\newblock Understanding contrastive representation learning through alignment
  and uniformity on the hypersphere.
\newblock In \emph{International Conference on Machine Learning}, pages
  9929--9939. PMLR, 2020.

\bibitem[Wobst(1975)]{wobst1975isometrien}
R.~Wobst.
\newblock Isometrien in metrischen vektorr{\"a}umen.
\newblock \emph{Studia Mathematica}, 1\penalty0 (54):\penalty0 41--54, 1975.

\bibitem[Zimmermann et~al.(2021)Zimmermann, Sharma, Schneider, Bethge, and
  Brendel]{cl_ica}
R.~S. Zimmermann, Y.~Sharma, S.~Schneider, M.~Bethge, and W.~Brendel.
\newblock Contrastive learning inverts the data generating process.
\newblock In \emph{International Conference on Machine Learning}, pages
  12979--12990. PMLR, 2021.

\end{thebibliography}
