\begin{thebibliography}{40}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abadi et~al.(2016)Abadi, Barham, Chen, Chen, Davis, Dean, Devin,
  Ghemawat, Irving, Isard, et~al.]{2016tensorflow}
Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M.,
  Ghemawat, S., Irving, G., Isard, M., et~al.
\newblock Tensorflow: A system for large-scale machine learning.
\newblock In \emph{OSDI}, volume~16, pp.\  265--283, 2016.

\bibitem[Andrychowicz et~al.(2016)Andrychowicz, Denil, Gomez, Hoffman, Pfau,
  Schaul, and de~Freitas]{2016learning2learn}
Andrychowicz, M., Denil, M., Gomez, S., Hoffman, M.~W., Pfau, D., Schaul, T.,
  and de~Freitas, N.
\newblock Learning to learn by gradient descent by gradient descent.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3981--3989, 2016.

\bibitem[Ba et~al.(2016)Ba, Hinton, Mnih, Leibo, and Ionescu]{2016usingfast}
Ba, J., Hinton, G.~E., Mnih, V., Leibo, J.~Z., and Ionescu, C.
\newblock Using fast weights to attend to the recent past.
\newblock In \emph{Advances In Neural Information Processing Systems}, pp.\
  4331--4339, 2016.

\bibitem[Doshi-Velez \& Kim(2017)Doshi-Velez and Kim]{doshi-velez2017towards}
Doshi-Velez, F. and Kim, B.
\newblock Towards a rigorous science of interpretable machine learning.
\newblock \emph{arXiv preprint arXiv:1702.08608}, 2017.

\bibitem[Feizi et~al.(2017)Feizi, Javadi, Zhang, and Tse]{2017porcupine}
Feizi, S., Javadi, H., Zhang, J., and Tse, D.
\newblock Porcupine neural networks:(almost) all local optima are global.
\newblock \emph{arXiv preprint arXiv:1710.02196}, 2017.

\bibitem[Finn et~al.(2017)Finn, Abbeel, and Levine]{2017maml}
Finn, C., Abbeel, P., and Levine, S.
\newblock Model-agnostic meta-learning for fast adaptation of deep networks.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning}, pp.\  1126--1135, 2017.

\bibitem[Gidaris \& Komodakis(2018)Gidaris and Komodakis]{2018dflwf}
Gidaris, S. and Komodakis, N.
\newblock Dynamic few-shot visual learning without forgetting.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  4367--4375, 2018.

\bibitem[Harrison~Edwards(2017)]{2017neuralstatistician}
Harrison~Edwards, A.~S.
\newblock Towards a neural statistician.
\newblock In \emph{In International Conference on Learning Representations
  (ICLR)}, 2017.

\bibitem[He et~al.(2015)He, Zhang, Ren, and Sun]{2015prelu}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Delving deep into rectifiers: Surpassing human-level performance on
  imagenet classification.
\newblock In \emph{Proceedings of IEEE International Conference on Computer
  Vision}, pp.\  1026--1034, 2015.

\bibitem[Hinton \& Plaut(1987)Hinton and Plaut]{1987fast}
Hinton, G.~E. and Plaut, D.~C.
\newblock Using fast weights to deblur old memories.
\newblock In \emph{Proceedings of the 9th Annual Conference of the Cognitive
  Science Society}, pp.\  177--186, 1987.

\bibitem[Hochreiter \& Schmidhuber(1997)Hochreiter and Schmidhuber]{1997lstm}
Hochreiter, S. and Schmidhuber, J.
\newblock Long short-term memory.
\newblock \emph{Neural computation}, 9\penalty0 (8):\penalty0 1735--1780, 1997.

\bibitem[Hu et~al.(2007)Hu, Wang, Yang, and Qu]{hu2007add}
Hu, B.-G., Wang, Y., Yang, S.-H., and Qu, H.-B.
\newblock How to add transparency to artificial neural networks.
\newblock \emph{Pattern Recognition and Artificial Intelligence}, 20\penalty0
  (1):\penalty0 72--84, 2007.

\bibitem[Ioffe \& Szegedy(2015)Ioffe and Szegedy]{2015bn}
Ioffe, S. and Szegedy, C.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift.
\newblock In \emph{Proceedings of the 32nd International Conference on Machine
  Learning}, pp.\  448--456, 2015.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{2014adam}
Kingma, D. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2015.

\bibitem[Koch et~al.(2015)Koch, Zemel, and Salakhutdinov]{2015siamese}
Koch, G., Zemel, R., and Salakhutdinov, R.
\newblock Siamese neural networks for one-shot image recognition.
\newblock In \emph{ICML Deep Learning Workshop}, volume~2, 2015.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and Hinton]{2012alexnet}
Krizhevsky, A., Sutskever, I., and Hinton, G.~E.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  1097--1105, 2012.

\bibitem[Lake et~al.(2011)Lake, Salakhutdinov, Gross, and
  Tenenbaum]{2011omniglot}
Lake, B., Salakhutdinov, R., Gross, J., and Tenenbaum, J.
\newblock One shot learning of simple visual concepts.
\newblock In \emph{Proceedings of the 33rd Annual Conference of the Cognitive
  Science Society}, pp.\  2568--2573, 2011.

\bibitem[Lake et~al.(2017)Lake, Ullman, Tenenbaum, and Gershman]{2017building}
Lake, B.~M., Ullman, T.~D., Tenenbaum, J.~B., and Gershman, S.~J.
\newblock Building machines that learn and think like people.
\newblock \emph{Behavioral and Brain Sciences}, 40, 2017.

\bibitem[Li et~al.(2018)Li, Xu, Taylor, Studer, and Goldstein]{2017visualizing}
Li, H., Xu, Z., Taylor, G., Studer, C., and Goldstein, T.
\newblock Visualizing the loss landscape of neural nets.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  6389--6399, 2018.

\bibitem[Li et~al.(2017)Li, Zhou, Chen, and Li]{2017meta-sgd}
Li, Z., Zhou, F., Chen, F., and Li, H.
\newblock {Meta-SGD}: Learning to learn quickly for few shot learning.
\newblock \emph{arXiv preprint arXiv:1707.09835}, 2017.

\bibitem[Long et~al.(2015)Long, Shelhamer, and Darrell]{2015fcn}
Long, J., Shelhamer, E., and Darrell, T.
\newblock Fully convolutional networks for semantic segmentation.
\newblock In \emph{Proceedings of IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  3431--3440, 2015.

\bibitem[Maaten \& Hinton(2008)Maaten and Hinton]{2008tsne}
Maaten, L. v.~d. and Hinton, G.
\newblock {Visualizing data using t-SNE}.
\newblock \emph{Journal of Machine Learning Research}, 9:\penalty0 2579--2605,
  2008.

\bibitem[Mishra et~al.(2018)Mishra, Rohaninejad, Chen, and Abbeel]{2018snail}
Mishra, N., Rohaninejad, M., Chen, X., and Abbeel, P.
\newblock A simple neural attentive meta-learner.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2018.

\bibitem[Motiian et~al.(2017)Motiian, Jones, Iranmanesh, and
  Doretto]{2017fsada}
Motiian, S., Jones, Q., Iranmanesh, S., and Doretto, G.
\newblock Few-shot adversarial domain adaptation.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  6670--6680, 2017.

\bibitem[Munkhdalai \& Yu(2017)Munkhdalai and Yu]{2017metanets}
Munkhdalai, T. and Yu, H.
\newblock Meta networks.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning}, pp.\  2554--2563, 2017.

\bibitem[{Murdoch} et~al.(2019){Murdoch}, {Singh}, {Kumbier}, {Abbasi-Asl}, and
  {Yu}]{murdoch2019interpretable}
{Murdoch}, W.~J., {Singh}, C., {Kumbier}, K., {Abbasi-Asl}, R., and {Yu}, B.
\newblock Interpretable machine learning: definitions, methods, and
  applications.
\newblock \emph{arXiv preprint arXiv:1901.04592}, 2019.

\bibitem[Nichol \& Schulman(2018)Nichol and Schulman]{2018reptile}
Nichol, A. and Schulman, J.
\newblock Reptile: a scalable metalearning algorithm.
\newblock \emph{arXiv preprint arXiv:1803.02999}, 2018.

\bibitem[Qiao et~al.(2018)Qiao, Liu, Shen, and Yuille]{2018qiao}
Qiao, S., Liu, C., Shen, W., and Yuille, A.~L.
\newblock Few-shot image recognition by predicting parameters from activations.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  7229--7238, 2018.

\bibitem[Ravi \& Larochelle(2017)Ravi and Larochelle]{2017meta-lstm}
Ravi, S. and Larochelle, H.
\newblock Optimization as a model for few-shot learning.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2017.

\bibitem[Ren et~al.(2015)Ren, He, Girshick, and Sun]{2015fasterrcnn}
Ren, S., He, K., Girshick, R., and Sun, J.
\newblock Faster r-cnn: Towards real-time object detection with region proposal
  networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  91--99, 2015.

\bibitem[Ruder(2016)]{2016sgdoverview}
Ruder, S.
\newblock An overview of gradient descent optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1609.04747}, 2016.

\bibitem[Rusu et~al.(2019)Rusu, Rao, Sygnowski, Vinyals, Pascanu, Osindero, and
  Hadsell]{2018leo}
Rusu, A.~A., Rao, D., Sygnowski, J., Vinyals, O., Pascanu, R., Osindero, S.,
  and Hadsell, R.
\newblock Meta-learning with latent embedding optimization.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2019.

\bibitem[Salimans \& Kingma(2016)Salimans and Kingma]{2016weightnorm}
Salimans, T. and Kingma, D.~P.
\newblock Weight normalization: A simple reparameterization to accelerate
  training of deep neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  901--909, 2016.

\bibitem[Snell et~al.(2017)Snell, Swersky, and Zemel]{2017prototypicalnets}
Snell, J., Swersky, K., and Zemel, R.
\newblock Prototypical networks for few-shot learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  4077--4087, 2017.

\bibitem[Sung et~al.(2018)Sung, Yang, Zhang, Xiang, Torr, and
  Hospedales]{2017learn2compare}
Sung, F., Yang, Y., Zhang, L., Xiang, T., Torr, P.~H., and Hospedales, T.~M.
\newblock Learning to compare: Relation network for few-shot learning.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition}, pp.\  1199--1208, 2018.

\bibitem[Thrun \& Pratt(2012)Thrun and Pratt]{thrun2012learning}
Thrun, S. and Pratt, L.
\newblock \emph{Learning to learn}.
\newblock Springer Science \& Business Media, 2012.

\bibitem[{Tickle} et~al.(1998){Tickle}, {Andrews}, {Golea}, and
  {Diederich}]{tickle1998the}
{Tickle}, A.~B., {Andrews}, R., {Golea}, M., and {Diederich}, J.
\newblock The truth will come to light: directions and challenges in extracting
  the knowledge embedded within trained artificial neural networks.
\newblock \emph{IEEE Transactions on Neural Networks}, 9\penalty0 (6):\penalty0
  1057--1068, 1998.

\bibitem[Vinyals et~al.(2016)Vinyals, Blundell, Lillicrap, Wierstra,
  et~al.]{2016matchingnets}
Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et~al.
\newblock Matching networks for one shot learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3630--3638, 2016.

\bibitem[Weiss et~al.(2016)Weiss, Khoshgoftaar, and Wang]{2016tlsurvey}
Weiss, K., Khoshgoftaar, T.~M., and Wang, D.
\newblock A survey of transfer learning.
\newblock \emph{Journal of Big Data}, 3\penalty0 (1):\penalty0 9, 2016.

\bibitem[Wu et~al.(2018)Wu, Peurifoy, Chuang, and Tegmark]{2018mela}
Wu, T., Peurifoy, J., Chuang, I.~L., and Tegmark, M.
\newblock Meta-learning autoencoders for few-shot prediction.
\newblock \emph{arXiv preprint arXiv:1807.09912}, 2018.

\end{thebibliography}
