@inproceedings{AlexNet,
	author    = {Alex Krizhevsky and
	Ilya Sutskever and
	Geoffrey E. Hinton},
	title     = {ImageNet Classification with Deep Convolutional Neural Networks},
	booktitle = {Advances in Neural Information Processing Systems 25},
	pages     = {1106--1114},
	year      = {2012},
}

@inproceedings{ResNet,
	author    = {Kaiming He and
	Xiangyu Zhang and
	Shaoqing Ren and
	Jian Sun},
	title     = {Deep Residual Learning for Image Recognition},
	booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition},
	pages     = {770--778},
	year      = {2016},
}

@inproceedings{Transformer,
	author    = {Ashish Vaswani and
	Noam Shazeer and
	Niki Parmar and
	Jakob Uszkoreit and
	Llion Jones and
	Aidan N. Gomez and
	Lukasz Kaiser and
	Illia Polosukhin},
	title     = {Attention is All you Need},
	booktitle = {Advances in Neural Information Processing Systems 30},
	pages     = {5998--6008},
	year      = {2017},
}

@inproceedings{ImageNet,
	author    = {Jia Deng and
	Wei Dong and
	Richard Socher and
	Li{-}Jia Li and
	Kai Li and
	Li Fei{-}Fei},
	title     = {ImageNet: {A} large-scale hierarchical image database},
	booktitle = {2009 {IEEE} Computer Society Conference on Computer Vision and Pattern
	Recognition},
	pages     = {248--255},
	year      = {2009},
}


@inproceedings{BERT,
	author    = {Jacob Devlin and
	Ming{-}Wei Chang and
	Kenton Lee and
	Kristina Toutanova},
	title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
	Understanding},
	booktitle = {Proceedings of the 2019 Conference of the North American Chapter of
	the Association for Computational Linguistics: Human Language Technologies},
	pages     = {4171--4186},
	year      = {2019},
}

@inproceedings{ModelCompression,
	author    = {Cristian Bucila and
	Rich Caruana and
	Alexandru Niculescu{-}Mizil},
	title     = {Model compression},
	booktitle = {Proceedings of the Twelfth {ACM} {SIGKDD} International Conference
	on Knowledge Discovery and Data Mining},
	pages     = {535--541},
	year      = {2006},
}

@article{MobileNet,
	author    = {Andrew G. Howard and
	Menglong Zhu and
	Bo Chen and
	Dmitry Kalenichenko and
	Weijun Wang and
	Tobias Weyand and
	Marco Andreetto and
	Hartwig Adam},
	title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
	Applications},
	journal   = {CoRR},
	volume    = {abs/1704.04861},
	year      = {2017},
}

@inproceedings{MobileNetV2,
	author    = {Mark Sandler and
	Andrew G. Howard and
	Menglong Zhu and
	Andrey Zhmoginov and
	Liang{-}Chieh Chen},
	title     = {MobileNetV2: Inverted Residuals and Linear Bottlenecks},
	booktitle = {2018 {IEEE} Conference on Computer Vision and Pattern Recognition},
	pages     = {4510--4520},
	year      = {2018},
}

@inproceedings{ShuffleNet,
	author    = {Xiangyu Zhang and
	Xinyu Zhou and
	Mengxiao Lin and
	Jian Sun},
	title     = {ShuffleNet: An Extremely Efficient Convolutional Neural Network for
	Mobile Devices},
	booktitle = {2018 {IEEE} Conference on Computer Vision and Pattern Recognition},
	pages     = {6848--6856},
	year      = {2018},
}


@inproceedings{ShuffleNetV2,
	author    = {Ningning Ma and
	Xiangyu Zhang and
	Hai{-}Tao Zheng and
	Jian Sun},
	title     = {ShuffleNet {V2:} Practical Guidelines for Efficient {CNN} Architecture
	Design},
	booktitle = {Computer Vision - {ECCV} 2018 - 15th European Conference},
	pages     = {122--138},
	year      = {2018},
}


@inproceedings{DoDeep,
	author    = {Gregor Urban and
	Krzysztof J. Geras and
	Samira Ebrahimi Kahou and
	{\"{O}}zlem Aslan and
	Shengjie Wang and
	Abdelrahman Mohamed and
	Matthai Philipose and
	Matthew Richardson and
	Rich Caruana},
	title     = {Do Deep Convolutional Nets Really Need to be Deep and Convolutional?},
	booktitle = {The 5th International Conference on Learning Representations},
	year      = {2017},
}


@article{KD,
	author    = {Geoffrey E. Hinton and
	Oriol Vinyals and
	Jeffrey Dean},
	title     = {Distilling the Knowledge in a Neural Network},
	journal   = {CoRR},
	volume    = {abs/1503.02531},
	year      = {2015},
}

@article{KD-Survey-IJCV,
	author    = {Jianping Gou and
	Baosheng Yu and
	Stephen J. Maybank and
	Dacheng Tao},
	title     = {Knowledge Distillation: {A} Survey},
	journal   = {International Journal of Computer Vision},
	volume    = {129},
	number    = {6},
	pages     = {1789--1819},
	year      = {2021},
}

@article{KD-Survey-CoRR,
	author    = {Lin Wang and
	Kuk{-}Jin Yoon},
	title     = {Knowledge Distillation and Student-Teacher Learning for Visual Intelligence:
	{A} Review and New Outlooks},
	journal   = {CoRR},
	volume    = {abs/2004.05937},
	year      = {2020},
}

@inproceedings{FeatKD-FitNet,
	author    = {Adriana Romero and
	Nicolas Ballas and
	Samira Ebrahimi Kahou and
	Antoine Chassang and
	Carlo Gatta and
	Yoshua Bengio},
	title     = {FitNets: Hints for Thin Deep Nets},
	booktitle = {The 3rd International Conference on Learning Representations},
	year      = {2015},
}

@inproceedings{FeatKD-AT,
	author    = {Sergey Zagoruyko and
	Nikos Komodakis},
	title     = {Paying More Attention to Attention: Improving the Performance of Convolutional
	Neural Networks via Attention Transfer},
	booktitle = {The 5th International Conference on Learning Representations},
	year      = {2017},
}


@inproceedings{FeatKD-VID,
	author    = {Sungsoo Ahn and
	Shell Xu Hu and
	Andreas C. Damianou and
	Neil D. Lawrence and
	Zhenwen Dai},
	title     = {Variational Information Distillation for Knowledge Transfer},
	booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition},
	pages     = {9163--9171},
	year      = {2019},
}


@article{FeatKD-NST,
	author    = {Zehao Huang and
	Naiyan Wang},
	title     = {Like What You Like: Knowledge Distill via Neuron Selectivity Transfer},
	journal   = {CoRR},
	volume    = {abs/1707.01219},
	year      = {2017},
}

@inproceedings{FeatKD-AB,
	author    = {Byeongho Heo and
	Minsik Lee and
	Sangdoo Yun and
	Jin Young Choi},
	title     = {Knowledge Transfer via Distillation of Activation Boundaries Formed
	by Hidden Neurons},
	booktitle = {The Thirty-Third {AAAI} Conference on Artificial Intelligence},
	pages     = {3779--3787},
	year      = {2019},
}

@inproceedings{FeatKD-PKT,
	author    = {Nikolaos Passalis and
	Anastasios Tefas},
	title     = {Learning Deep Representations with Probabilistic Knowledge Transfer},
	booktitle = {Computer Vision - {ECCV} 2018 - 15th European Conference},
	volume    = {11215},
	pages     = {283--299},
	year      = {2018},
}


@inproceedings{ReKD-Gift,
	author    = {Junho Yim and
	Donggyu Joo and
	Ji{-}Hoon Bae and
	Junmo Kim},
	title     = {A Gift from Knowledge Distillation: Fast Optimization, Network Minimization
	and Transfer Learning},
	booktitle = {2017 {IEEE} Conference on Computer Vision and Pattern Recognition},
	pages     = {7130--7138},
	year      = {2017},
}

@inproceedings{ReKD-Graph,
	author    = {Yufan Liu and
	Jiajiong Cao and
	Bing Li and
	Chunfeng Yuan and
	Weiming Hu and
	Yangxi Li and
	Yunqiang Duan},
	title     = {Knowledge Distillation via Instance Relationship Graph},
	booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition},
	pages     = {7096--7104},
	year      = {2019},
}

@inproceedings{ReKD-CC,
	author    = {Baoyun Peng and
	Xiao Jin and
	Dongsheng Li and
	Shunfeng Zhou and
	Yichao Wu and
	Jiaheng Liu and
	Zhaoning Zhang and
	Yu Liu},
	title     = {Correlation Congruence for Knowledge Distillation},
	booktitle = {2019 {IEEE/CVF} International Conference on Computer Vision},
	pages     = {5006--5015},
	year      = {2019},
}

@inproceedings{ReKD-SP,
	author    = {Frederick Tung and
	Greg Mori},
	title     = {Similarity-Preserving Knowledge Distillation},
	booktitle = {2019 {IEEE/CVF} International Conference on Computer Vision},
	pages     = {1365--1374},
	year      = {2019},
}

@inproceedings{ReKD-CRD,
	author    = {Yonglong Tian and
	Dilip Krishnan and
	Phillip Isola},
	title     = {Contrastive Representation Distillation},
	booktitle = {The 8th International Conference on Learning Representations},
	year      = {2020},
}

@inproceedings{ReKD-Metric,
	author    = {Lu Yu and
	Vacit Oguz Yazici and
	Xialei Liu and
	Joost van de Weijer and
	Yongmei Cheng and
	Arnau Ramisa},
	title     = {Learning Metrics From Teachers: Compact Networks for Image Embedding},
	booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition},
	pages     = {2907--2916},
	year      = {2019},
}

@inproceedings{ReKD-Refilled,
	author    = {Han{-}Jia Ye and
	Su Lu and
	De{-}Chuan Zhan},
	title     = {Distilling Cross-Task Knowledge via Relationship Matching},
	booktitle = {2020 {IEEE/CVF} Conference on Computer Vision and Pattern Recognition},
	pages     = {12393--12402},
	year      = {2020},
}

@inproceedings{ParamKD-L2SP,
	author    = {Xuhong Li and
	Yves Grandvalet and
	Franck Davoine},
	title     = {Explicit Inductive Bias for Transfer Learning with Convolutional Networks},
	booktitle = {Proceedings of the 35th International Conference on Machine Learning},
	pages     = {2830--2839},
	year      = {2018},
}

@inproceedings{ParamKD-KR,
	author    = {Junjie Liu and
	Dongchao Wen and
	Hongxing Gao and
	Wei Tao and
	Tse{-}Wei Chen and
	Kinya Osa and
	Masami Kato},
	title     = {Knowledge Representing: Efficient, Sparse Representation of Prior
	Knowledge for Knowledge Distillation},
	booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition Workshops},
	pages     = {638--646},
	year      = {2019},
}


@inproceedings{DML,
	author    = {Ying Zhang and
	Tao Xiang and
	Timothy M. Hospedales and
	Huchuan Lu},
	title     = {Deep Mutual Learning},
	booktitle = {2018 {IEEE} Conference on Computer Vision and Pattern Recognition},
	pages     = {4320--4328},
	year      = {2018},
}


@inproceedings{OnlineKD,
	author    = {Rohan Anil and
	Gabriel Pereyra and
	Alexandre Passos and
	R{\'{o}}bert Orm{\'{a}}ndi and
	George E. Dahl and
	Geoffrey E. Hinton},
	title     = {Large scale distributed neural network training through online distillation},
	booktitle = {The 6th International Conference on Learning Representations},
	year      = {2018},
}


@inproceedings{SelfKD-BYOT,
	author    = {Linfeng Zhang and
	Jiebo Song and
	Anni Gao and
	Jingwei Chen and
	Chenglong Bao and
	Kaisheng Ma},
	title     = {Be Your Own Teacher: Improve the Performance of Convolutional Neural
	Networks via Self Distillation},
	booktitle = {2019 {IEEE/CVF} International Conference on Computer Vision},
	pages     = {3712--3721},
	year      = {2019},
}

@InProceedings{SelfKD-PSKD,
	author    = {Kim, Kyungyul and Ji, ByeongMoon and Yoon, Doyoung and Hwang, Sangheum},
	title     = {Self-Knowledge Distillation With Progressive Refinement of Targets},
	booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
	year      = {2021},
	pages     = {6567-6576}
}


@article{ImproveKD,
	author    = {Jiaxi Tang and
	Rakesh Shivanna and
	Zhe Zhao and
	Dong Lin and
	Anima Singh and
	Ed H. Chi and
	Sagar Jain},
	title     = {Understanding and Improving Knowledge Distillation},
	journal   = {CoRR},
	volume    = {abs/2002.03532},
	year      = {2020},
}


@inproceedings{KDWide,
	author    = {Guangda Ji and
	Zhanxing Zhu},
	title     = {Knowledge Distillation in Wide Neural Networks: Risk Bound, Data Efficiency
	and Imperfect Teacher},
	booktitle = {Advances in Neural Information Processing Systems 33},
	year      = {2020},
}

@inproceedings{KDConcept,
	author    = {Xu Cheng and
	Zhefan Rao and
	Yilan Chen and
	Quanshi Zhang},
	title     = {Explaining Knowledge Distillation by Quantifying the Knowledge},
	booktitle = {2020 {IEEE/CVF} Conference on Computer Vision and Pattern Recognition},
	pages     = {12922--12932},
	year      = {2020},
}


@inproceedings{KDBiasVar,
	author    = {Helong Zhou and
	Liangchen Song and
	Jiajie Chen and
	Ye Zhou and
	Guoli Wang and
	Junsong Yuan and
	Qian Zhang},
	title     = {Rethinking Soft Labels for Knowledge Distillation: {A} Bias-Variance
	Tradeoff Perspective},
	booktitle = {The 9th International Conference on Learning Representations},
	year      = {2021},
}


@inproceedings{StasticalKD,
	author    = {Aditya Krishna Menon and
	Ankit Singh Rawat and
	Sashank J. Reddi and
	Seungyeon Kim and
	Sanjiv Kumar},
	title     = {A statistical perspective on distillation},
	booktitle = {Proceedings of the 38th International Conference on Machine Learning},
	pages     = {7632--7642},
	year      = {2021},
}


@inproceedings{TowardsKD,
	author    = {Mary Phuong and
	Christoph Lampert},
	title     = {Towards Understanding Knowledge Distillation},
	booktitle = {Proceedings of the 36th International Conference on Machine Learning},
	pages     = {5142--5151},
	year      = {2019},
}

@inproceedings{GeneralizeBound,
	author    = {Daniel Hsu and
	Ziwei Ji and
	Matus Telgarsky and
	Lan Wang},
	title     = {Generalization bounds via distillation},
	booktitle = {The 9th International Conference on Learning Representations},
	year      = {2021},
}

@inproceedings{KDPrivileged,
	author    = {David Lopez{-}Paz and
	L{\'{e}}on Bottou and
	Bernhard Sch{\"{o}}lkopf and
	Vladimir Vapnik},
	title     = {Unifying distillation and privileged information},
	booktitle = {The 4th International Conference on Learning Representations},
	year      = {2016},
}

@inproceedings{KDSemiParametric,
	author    = {Tri Dao and
	Govinda M. Kamath and
	Vasilis Syrgkanis and
	Lester Mackey},
	title     = {Knowledge Distillation as Semiparametric Inference},
	booktitle = {The 9th International Conference on Learning Representations},
	year      = {2021},
}

@inproceedings{KDLSR,
	author    = {Li Yuan and
	Francis E. H. Tay and
	Guilin Li and
	Tao Wang and
	Jiashi Feng},
	title     = {Revisiting Knowledge Distillation via Label Smoothing Regularization},
	booktitle = {2020 {IEEE/CVF} Conference on Computer Vision and Pattern Recognition},
	pages     = {3902--3910},
	year      = {2020},
}

@inproceedings{WhenLSHelp,
	author    = {Rafael M{\"{u}}ller and
	Simon Kornblith and
	Geoffrey E. Hinton},
	title     = {When does label smoothing help?},
	booktitle = {Advances in Neural Information Processing Systems 32},
	pages     = {4696--4705},
	year      = {2019},
}

@inproceedings{ISLS,
	author    = {Zhiqiang Shen and
	Zechun Liu and
	Dejia Xu and
	Zitian Chen and
	Kwang{-}Ting Cheng and
	Marios Savvides},
	title     = {Is Label Smoothing Truly Incompatible with Knowledge Distillation:
	An Empirical Study},
	booktitle = {The 9th International Conference on Learning Representations},
	year      = {2021},
}

@inproceedings{KDEfficacy,
	author    = {Jang Hyun Cho and
	Bharath Hariharan},
	title     = {On the Efficacy of Knowledge Distillation},
	booktitle = {{IEEE/CVF} International Conference on Computer Vision},
	pages     = {4793--4801},
	year      = {2019},
}

@inproceedings{KDConsistency,
	author    = {Ruofan Liang and
	Tianlin Li and
	Longfei Li and
	Jing Wang and
	Quanshi Zhang},
	title     = {Knowledge Consistency between Neural Networks and Beyond},
	booktitle = {The 8th International Conference on Learning Representations},
	year      = {2020},
}

@inproceedings{MeanTeacher,
	author    = {Antti Tarvainen and
	Harri Valpola},
	title     = {Mean teachers are better role models: Weight-averaged consistency
	targets improve semi-supervised deep learning results},
	booktitle = {The 5th International Conference on Learning Representations},
	year      = {2017},
}

@inproceedings{TolerantKD,
	author    = {Chenglin Yang and
	Lingxi Xie and
	Siyuan Qiao and
	Alan L. Yuille},
	title     = {Training Deep Neural Networks in Generations: {A} More Tolerant Teacher
	Educates Better Students},
	booktitle = {Proceedings of the 33rd {AAAI} Conference on Artificial Intelligence},
	pages     = {5628--5635},
	year      = {2019},
}

@inproceedings{TAKD,
	author    = {Seyed{-}Iman Mirzadeh and
	Mehrdad Farajtabar and
	Ang Li and
	Nir Levine and
	Akihiro Matsukawa and
	Hassan Ghasemzadeh},
	title     = {Improved Knowledge Distillation via Teacher Assistant},
	booktitle = {The Thirty-Fourth {AAAI} Conference on Artificial Intelligence},
	pages     = {5191--5198},
	year      = {2020},
}

@article{ResKD-TIP,
	author    = {Xuewei Li and
	Songyuan Li and
	Bourahla Omar and
	Fei Wu and
	Xi Li},
	title     = {ResKD: Residual-Guided Knowledge Distillation},
	journal   = {IEEE Transactions on Image Processing},
	volume    = {30},
	pages     = {4735--4746},
	year      = {2021},
}

@article{ResKD-NC,
	author    = {Mengya Gao and
	Yujun Wang and
	Liang Wan},
	title     = {Residual error based knowledge distillation},
	journal   = {Neurocomputing},
	volume    = {433},
	pages     = {154--161},
	year      = {2021},
}

@inproceedings{SCKD,
	title={Student Customized Knowledge Distillation: Bridging the Gap Between Student and Teacher},
	booktitle = {{IEEE/CVF} International Conference on Computer Vision},
	author={Yichen Zhu, Yi Wang},
	year = {2021},
}

@inproceedings{BAN,
	author    = {Tommaso Furlanello and
	Zachary Chase Lipton and
	Michael Tschannen and
	Laurent Itti and
	Anima Anandkumar},
	title     = {Born-Again Neural Networks},
	booktitle = {Proceedings of the 35th International Conference on Machine Learning},
	volume    = {80},
	pages     = {1602--1611},
	year      = {2018},
}


@inproceedings{SelfKD-LS,
	author    = {Zhilu Zhang and
	Mert R. Sabuncu},
	title     = {Self-Distillation as Instance-Specific Label Smoothing},
	booktitle = {Advances in Neural Information Processing Systems 33},
	year      = {2020},
}


@article{cifar,
	author = {Krizhevsky, Alex},
	year = {2012},
	pages = {},
	title = {Learning Multiple Layers of Features from Tiny Images},
}

@techreport{CUB,
	Title = {{The Caltech-UCSD Birds-200-2011 Dataset}},
	Author = {Wah, C. and Branson, S. and Welinder, P. and Perona, P. and Belongie, S.},
	Year = {2011}
	Institution = {California Institute of Technology},
	Number = {CNS-TR-2011-001}
}

@inproceedings{dogs,
	author = {Aditya Khosla and Nityananda Jayadevaprakash and Bangpeng Yao and Fei-fei Li},
	title = {Novel dataset for fine-grained image categorization},
	booktitle = {First Workshop on Fine-Grained Visual Categorization, CVPR (2011)},
	year = {}
}

@article{TinyImageNet,
	author    = {Amirhossein Tavanaei},
	title     = {Embedded Encoder-Decoder in Convolutional Networks Towards Explainable
	{AI}},
	journal   = {CoRR},
	volume    = {abs/2007.06712},
	year      = {2020},
}

@article{SpeechCommands,
	author    = {Pete Warden},
	title     = {Speech Commands: {A} Dataset for Limited-Vocabulary Speech Recognition},
	journal   = {CoRR},
	volume    = {abs/1804.03209},
	year      = {2018},
}

@article{KWS-DSCNN,
	author    = {Yundong Zhang and
	Naveen Suda and
	Liangzhen Lai and
	Vikas Chandra},
	title     = {Hello Edge: Keyword Spotting on Microcontrollers},
	journal   = {CoRR},
	volume    = {abs/1711.07128},
	year      = {2017},
}

@inproceedings{KWS-ResNet,
	author    = {Raphael Tang and
	Jimmy Lin},
	title     = {Deep Residual Learning for Small-Footprint Keyword Spotting},
	booktitle = {{IEEE} International Conference on Acoustics, Speech and Signal
	Processing},
	pages     = {5484--5488},
	year      = {2018},
}

@inproceedings{TSNE,
	author    = {Laurens van der Maaten},
	title     = {Barnes-Hut-SNE},
	booktitle = {1st International Conference on Learning Representations},
	year      = {2013},
}

@inproceedings{VGG,
	author    = {Karen Simonyan and
	Andrew Zisserman},
	title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
	booktitle = {3rd International Conference on Learning Representations},
	year      = {2015},
}

@inproceedings{WideResNet,
	author    = {Sergey Zagoruyko and
	Nikos Komodakis},
	title     = {Wide Residual Networks},
	booktitle = {Proceedings of the British Machine Vision Conference},
	year      = {2016},
}

@inproceedings{ResNeXt,
	author    = {Saining Xie and
	Ross B. Girshick and
	Piotr Doll{\'{a}}r and
	Zhuowen Tu and
	Kaiming He},
	title     = {Aggregated Residual Transformations for Deep Neural Networks},
	booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition},
	pages     = {5987--5995},
	year      = {2017},
}

@article{KendallTau-Int,
	author    = {Ronald Fagin and
	Ravi Kumar and
	D. Sivakumar},
	title     = {Comparing Top k Lists},
	journal   = {SIAM Journal on Discrete Mathematics},
	volume    = {17},
	number    = {1},
	pages     = {134--160},
	year      = {2003},
}

@inproceedings{LogME,
	author    = {Kaichao You and
	Yong Liu and
	Jianmin Wang and
	Mingsheng Long},
	title     = {LogME: Practical Assessment of Pre-trained Models for Transfer Learning},
	booktitle = {Proceedings of the 38th International Conference on Machine Learning},
	pages     = {12133--12143},
	year      = {2021},
}

@inproceedings{RevisitKD,
	author    = {Zhen Huang and
	Xu Shen and
	Jun Xing and
	Tongliang Liu and
	Xinmei Tian and
	Houqiang Li and
	Bing Deng and
	Jianqiang Huang and
	Xian{-}Sheng Hua},
	title     = {Revisiting Knowledge Distillation: An Inheritance and Exploration
	Framework},
	booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition},
	pages     = {3579--3588},
	year      = {2021},
}

@inproceedings{ReviewKD,
	author    = {Pengguang Chen and
	Shu Liu and
	Hengshuang Zhao and
	Jiaya Jia},
	title     = {Distilling Knowledge via Knowledge Review},
	booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition},
	pages     = {5008--5017},
	year      = {2021},
}