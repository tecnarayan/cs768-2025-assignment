\begin{thebibliography}{21}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Benveniste et~al.(2012)Benveniste, M{\'e}tivier, and
  Priouret]{benveniste2012adaptive}
A.~Benveniste, M.~M{\'e}tivier, and P.~Priouret.
\newblock \emph{Adaptive algorithms and stochastic approximations}, volume~22.
\newblock Springer Science \& Business Media, 2012.

\bibitem[Bertsekas(2011)]{bertsekas2011dynamic}
D.~P. Bertsekas.
\newblock Dynamic programming and optimal control 3rd edition, volume {II}.
\newblock \emph{Belmont, MA: Athena Scientific}, 2011.

\bibitem[Bertsekas and Tsitsiklis(1996)]{bertsekas1996neuro}
D.~P. Bertsekas and J.~N. Tsitsiklis.
\newblock \emph{Neuro-dynamic programming}.
\newblock Athena, 1996.

\bibitem[Bhandari et~al.(2018)Bhandari, Russo, and Singal]{bhandari2018finite}
J.~Bhandari, D.~Russo, and R.~Singal.
\newblock A finite time analysis of temporal difference learning with linear
  function approximation.
\newblock \emph{arXiv preprint arXiv:1806.02450}, 2018.

\bibitem[Bhatnagar et~al.(2012)Bhatnagar, Prasad, and
  Prashanth]{bhatnagar2012stochastic}
S.~Bhatnagar, H.~L. Prasad, and L.~A. Prashanth.
\newblock \emph{Stochastic recursive algorithms for optimization: simultaneous
  perturbation methods}, volume 434.
\newblock Springer, 2012.

\bibitem[Bhatnagar et~al.(2009)Bhatnagar, Precup, Silver, Sutton, Maei, and
  Szepesv{\'a}ri]{bhatnagar2009convergent}
Shalabh Bhatnagar, Doina Precup, David Silver, Richard~S Sutton, Hamid~R Maei,
  and Csaba Szepesv{\'a}ri.
\newblock Convergent temporal-difference learning with arbitrary smooth
  function approximation.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1204--1212, 2009.

\bibitem[Borkar(2009)]{borkar2009stochastic}
V.~S. Borkar.
\newblock \emph{Stochastic approximation: a dynamical systems viewpoint}.
\newblock Springer, 2009.

\bibitem[Dalal et~al.(2017{\natexlab{a}})Dalal, Sz{\"o}r{\'e}nyi, Thoppe, and
  Mannor]{dalal2017finite}
G.~Dalal, B.~Sz{\"o}r{\'e}nyi, G.~Thoppe, and S.~Mannor.
\newblock Finite sample analyses for {TD(0)} with function approximation.
\newblock \emph{arXiv preprint arXiv:1704.01161}, 2017{\natexlab{a}}.
\newblock Also appeared in AAAI 2018.

\bibitem[Dalal et~al.(2017{\natexlab{b}})Dalal, Szorenyi, Thoppe, and
  Mannor]{dalal2017finitetwo}
G.~Dalal, B.~Szorenyi, G.~Thoppe, and S.~Mannor.
\newblock Finite sample analysis of two-timescale stochastic approximation with
  applications to reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1703.05376}, 2017{\natexlab{b}}.
\newblock Also appeared in COLT 2018.

\bibitem[Khalil(2002)]{khalil2002nonlinear}
H.~K. Khalil.
\newblock \emph{Nonlinear Systems}, volume~3.
\newblock Prentice hall Upper Saddle River, NJ, 2002.

\bibitem[Kokotovic et~al.(1999)Kokotovic, Khalil, and
  O'Reilly]{kokotovic1999singular}
P.~Kokotovic, H.~K. Khalil, and J.~O'Reilly.
\newblock \emph{Singular perturbation methods in control: analysis and design},
  volume~25.
\newblock SIAM, 1999.

\bibitem[Konidaris et~al.(2011)Konidaris, Osentoski, and
  Thomas]{konidaris2011value}
G.~Konidaris, S.~Osentoski, and P.~Thomas.
\newblock Value function approximation in reinforcement learning using the
  fourier basis.
\newblock In \emph{Twenty-fifth AAAI conference on artificial intelligence},
  2011.

\bibitem[Kushner and Yin(2003)]{kushner2003stochastic}
H.~Kushner and G.~G. Yin.
\newblock \emph{Stochastic approximation and recursive algorithms and
  applications}, volume~35.
\newblock Springer Science \& Business Media, 2003.

\bibitem[Lakshminarayanan and Szepesvari(2018)]{lakshminarayanan2018linear}
C.~Lakshminarayanan and C.~Szepesvari.
\newblock Linear stochastic approximation: How far does constant step-size and
  iterate averaging go?
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pages 1347--1355, 2018.

\bibitem[Srikant and Ying(2019)]{srikant2019finite}
R.~Srikant and L.~Ying.
\newblock Finite-time error bounds for linear stochastic approximation and {TD}
  learning.
\newblock \emph{Conference on Learning Theorey (COLT)}, 2019.
\newblock ArXiv preprint arXiv:1902.00923.

\bibitem[Sutton(1988)]{sutton1988learning}
R.~S. Sutton.
\newblock Learning to predict by the methods of temporal differences.
\newblock \emph{Machine learning}, 3\penalty0 (1):\penalty0 9--44, 1988.

\bibitem[Sutton and Barto(2018)]{sutton2018reinforcement}
R.~S. Sutton and A.~G. Barto.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem[Sutton et~al.(2009)Sutton, Maei, Precup, Bhatnagar, Silver,
  Szepesv{\'a}ri, and Wiewiora]{sutton2009fast}
R.~S. Sutton, H.~R. Maei, D.~Precup, S.~Bhatnagar, D.~Silver,
  C.~Szepesv{\'a}ri, and E.~Wiewiora.
\newblock Fast gradient-descent methods for temporal-difference learning with
  linear function approximation.
\newblock In \emph{Proceedings of the 26th Annual International Conference on
  Machine Learning}, pages 993--1000. ACM, 2009.

\bibitem[Sutton et~al.(2008)Sutton, Szepesv{\'a}ri, and
  Maei]{sutton2008convergent}
Richard~S Sutton, Csaba Szepesv{\'a}ri, and Hamid~Reza Maei.
\newblock A convergent {O(n)} algorithm for off-policy temporal-difference
  learning with linear function approximation.
\newblock \emph{Advances in neural information processing systems}, 21\penalty0
  (21):\penalty0 1609--1616, 2008.

\bibitem[Szepesv{\'a}ri(2010)]{szepesvari2010algorithms}
C.~Szepesv{\'a}ri.
\newblock Algorithms for reinforcement learning.
\newblock \emph{Synthesis lectures on {Artificial} {Intelligence} and {Machine}
  {Learning}}, 4\penalty0 (1):\penalty0 1--103, 2010.

\bibitem[Tsitsiklis and Van~Roy(1997)]{tsitsiklis1997analysis}
J.~N. Tsitsiklis and B.~Van~Roy.
\newblock An analysis of temporal-difference learning with function
  approximation.
\newblock \emph{IEEE Transactions on Automatic Control}, 42\penalty0 (5), 1997.

\end{thebibliography}
