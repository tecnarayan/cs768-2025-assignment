\begin{thebibliography}{50}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ajay et~al.(2022)Ajay, Yilun~Du, Tenenbaum, Jaakkola, and
  Agrawal]{ajay2022dd}
Anurag Ajay, Abhi~Gupta Yilun~Du, Joshua Tenenbaum, Tommi Jaakkola, and Pulkit
  Agrawal.
\newblock Is conditional generative modeling all you need for decision-making.
\newblock \emph{arXiv preprint arXiv:2211.15657}, Dec 2022.

\bibitem[Andrychowicz et~al.(2017)Andrychowicz, Wolski, Ray, Schneider, Fong,
  Welinder, McGrew, Tobin, Abbeel, and Zaremba]{andrychowicz2017hindsight}
Marcin Andrychowicz, Filip Wolski, Alex Ray, Jonas Schneider, Rachel Fong,
  Peter Welinder, Bob McGrew, Josh Tobin, Pieter Abbeel, and Wojciech Zaremba.
\newblock Hindsight experience replay.
\newblock In \emph{Advances in Neural Information Processing Systems}, Long
  Beach, US, Dec 2017.

\bibitem[Chen et~al.(2021)Chen, Lu, Rajeswaran, Lee, Grover, Laskin, Abbeel,
  Srinivas, and Mordatch]{chen2021decision}
Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Misha
  Laskin, Pieter Abbeel, Aravind Srinivas, and Igor Mordatch.
\newblock Decision transformer: Reinforcement learning via sequence modeling.
\newblock In \emph{Advances in Neural Information Processing Systems}, Virtual
  conference, Dec 2021.

\bibitem[Chi et~al.(2023)Chi, Feng, Du, Xu, Cousineau, Burchfiel, and
  Song]{chi2023diffusionpolicy}
Cheng Chi, Siyuan Feng, Yilun Du, Zhenjia Xu, Eric Cousineau, Benjamin
  Burchfiel, and Shuran Song.
\newblock Diffusion policy: Visuomotor policy learning via action diffusion.
\newblock In \emph{Proceedings of Robotics: Science and Systems (RSS)}, Daegu,
  KR, Jul 2023.

\bibitem[Dhariwal and Nichol(2021)]{dhariwal2021diffusion}
Prafulla Dhariwal and Alexander Nichol.
\newblock Diffusion models beat {GAN}s on image synthesis.
\newblock In \emph{Advances in Neural Information Processing Systems}, Virutal
  Conference, Dec 2021.

\bibitem[Eysenbach et~al.(2021)Eysenbach, Levine, and
  Salakhutdinov]{eysenbach2021replacing}
Benjamin Eysenbach, Sergey Levine, and Ruslan Salakhutdinov.
\newblock Replacing rewards with examples: Example-based policy search via
  recursive classification.
\newblock In \emph{Advances in Neural Information Processing Systems}, Virtual
  Conference, Dec 2021.

\bibitem[Eysenbach et~al.(2022)Eysenbach, Zhang, Levine, and
  Salakhutdinov]{eysenbach2022contrastive}
Benjamin Eysenbach, Tianjun Zhang, Sergey Levine, and Ruslan Salakhutdinov.
\newblock Contrastive learning as goal-conditioned reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, New
  Orleans, US, Dec 2022.

\bibitem[Fu et~al.(2020)Fu, Kumar, Nachum, Tucker, and Levine]{fu2020d4rl}
Justin Fu, Aviral Kumar, Ofir Nachum, George Tucker, and Sergey Levine.
\newblock {D4RL}: Datasets for deep data-driven reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2004.07219}, Apr 2020.

\bibitem[Fujimoto and Gu(2021)]{fujimoto2021minimalist}
Scott Fujimoto and Shixiang~Shane Gu.
\newblock A minimalist approach to offline reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, Virtual
  conference, Dec 2021.

\bibitem[Fujimoto et~al.(2018)Fujimoto, van Hoof, and Meger]{fujimoto2018td3}
Scott Fujimoto, Herke van Hoof, and David Meger.
\newblock Addressing function approximiation error in actor-critic methods.
\newblock In \emph{Proceedings of International Conference on Machine
  Learning}, Stockholm, SE, Jul 2018.

\bibitem[Fujimoto et~al.(2019)Fujimoto, Meger, and Precup]{fujimoto2019bcq}
Scott Fujimoto, David Meger, and Doina Precup.
\newblock Off-policy deep reinforcement learning without exploration.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, Long Beach, US, Jun 2019.

\bibitem[Guo et~al.(2022)Guo, Thakoor, P{\^\i}slar, Avila~Pires, Altch{\'e},
  Tallec, Saade, Calandriello, Grill, Tang, et~al.]{guo2022byolexplore}
Zhaohan Guo, Shantanu Thakoor, Miruna P{\^\i}slar, Bernardo Avila~Pires,
  Florent Altch{\'e}, Corentin Tallec, Alaa Saade, Daniele Calandriello,
  Jean-Bastien Grill, Yunhao Tang, et~al.
\newblock Byol-explore: Exploration by bootstrapped prediction.
\newblock In \emph{Advances in neural information processing systems}, New
  Orleans, US, Dec 2022.

\bibitem[Gupta et~al.(2019)Gupta, Kumar, Lynch, Levine, and
  Hausman]{gupta2019relay}
Abhishek Gupta, Vikash Kumar, Corey Lynch, Sergey Levine, and Karol Hausman.
\newblock Relay policy learning: Solving long-horizon tasks via imitation and
  reinforcement learning.
\newblock In \emph{Proceedings of the Conference on Robot Learning}, Osaka, JP,
  Oct 2019.

\bibitem[Haarnoja et~al.(2019)Haarnoja, Ha, Zhou, Tan, Tucker, and
  Levine]{haarnoja2019learning}
Tuomas Haarnoja, Sehoon Ha, Aurick Zhou, Jie Tan, George Tucker, and Sergey
  Levine.
\newblock Learning to walk via deep reinforcement learning.
\newblock In \emph{Proceedings of the Robotics: Science and Systems
  Conference}, Messe Freiburg, DE, Jun 2019.

\bibitem[Harvey et~al.(2022)Harvey, Naderiparizi, Masrani, Weilbach, and
  Wood]{harvey2022flexible}
William Harvey, Saeid Naderiparizi, Vaden Masrani, Christian~Dietrich Weilbach,
  and Frank Wood.
\newblock Flexible diffusion modeling of long videos.
\newblock In \emph{Advances in Neural Information Processing Systems}, Virtual
  Conference, Dec 2022.

\bibitem[He et~al.(2023)He, Yang, Zhang, Shan, and Chen]{he2023latentvideo}
Yingqing He, Tianyu Yang, Yong Zhang, Ying Shan, and Qifeng Chen.
\newblock Latent video diffusion models for high-fidelity long video
  generation.
\newblock \emph{arXiv preprint arXiv:2211.13221}, Mar 2023.

\bibitem[Ho and Salimans(2022)]{ho2022classifer}
Jonathan Ho and Tim Salimans.
\newblock Classifier-free diffusion guidance.
\newblock \emph{arXiv preprint arXiv:2207.12598}, Jul 2022.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock In \emph{Advances in Neural Information Processing Systems}, Virtual
  conference, Dec 2020.

\bibitem[Ho et~al.(2022)Ho, Salimans, Gritsenko, Chan, Norouzi, and
  Fleet]{ho2022video}
Jonathan Ho, Tim Salimans, Alexey Gritsenko, William Chan, Mohammad Norouzi,
  and David~J. Fleet.
\newblock Video diffusion models.
\newblock \emph{arXiv preprint arXiv:2204.03458}, Apr 2022.

\bibitem[Janner et~al.(2021)Janner, Li, and Levine]{janner2021offline}
Michael Janner, Qiyang Li, and Sergey Levine.
\newblock Offline reinforcement learning as one big sequence modeling problem.
\newblock In \emph{Advances in Neural Information Processing Systems}, Virtual
  conference, Dec 2021.

\bibitem[Janner et~al.(2022)Janner, Du, Tenenbaum, and
  Levine]{janner2022planning}
Michael Janner, Yilun Du, Joshua Tenenbaum, and Sergey Levine.
\newblock Planning with diffusion for flexible behavior synthesis.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, Baltimore, US, Jul 2022.

\bibitem[Kidambi et~al.(2020)Kidambi, Rajeswaran, Netrapalli, and
  Joachims]{kidambi2020morel}
Rahul Kidambi, Aravind Rajeswaran, Praneeth Netrapalli, and Thorsten Joachims.
\newblock {MOR}e{L}: Model-based offline reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, Virtual
  Conference, Dec 2020.

\bibitem[Kingma and Ba(2015)]{kingma2015adam}
Diederik~P. Kingma and Jimmy~Lei Ba.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{Proceedings of International Conference on Learning
  Representations}, San Diego, US, May 2015.

\bibitem[Kostrikov et~al.(2021)Kostrikov, Tompson, Fergus, and
  Nachum]{kostrikov2021fisher}
Ilya Kostrikov, Jonathan Tompson, Rob Fergus, and Ofir Nachum.
\newblock Offline reinforcement learning with {F}isher divergence critic
  regularization.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, Virtual Conference, Jul 2021.

\bibitem[Kostrikov et~al.(2022)Kostrikov, Nair, and Levine]{kostrikov2022iql}
Ilya Kostrikov, Ashvin Nair, and Sergey Levine.
\newblock Offline reinforcement learning with implicit q-learning.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations}, Virtual conference, Apr 2022.

\bibitem[Kumar et~al.(2020)Kumar, Zhou, Tucker, and Levine]{kumar2020cql}
Aviral Kumar, Aurick Zhou, George Tucker, and Sergey Levine.
\newblock Conservative q-learning for offline reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, Virtual
  conference, Dec 2020.

\bibitem[Lillicrap et~al.(2016)Lillicrap, Hunt, Pritzel, Heess, Erez, Tassa,
  Silver, and Wierstra]{lillicrap2016ddpg}
Timothy~P. Lillicrap, Jonathan~J. Hunt, Alexander Pritzel, Nicolas Heess, Tom
  Erez, Yuval Tassa, David Silver, and Daan Wierstra.
\newblock Continuous control with deep reinforcement learning.
\newblock In \emph{Proceedings of International Conference on Learning
  Representations}, San Juan, PR, May 2016.

\bibitem[Lynch et~al.(2019)Lynch, Khansari, Xiao, Kumar, Tompson, Levine, and
  Sermanet]{lynch2019playlmp}
Corey Lynch, Mohi Khansari, Ted Xiao, Vikash Kumar, Jonathan Tompson, Sergey
  Levine, and Pierre Sermanet.
\newblock Learning latent plans from play.
\newblock In \emph{Proceedings of the Conference on Robot Learning}, Osaka, JP,
  Oct 2019.

\bibitem[Mees et~al.(2022)Mees, Hermann, Rosete-Beas, and
  Burgard]{mees2022calvin}
Oier Mees, Lukas Hermann, Erick Rosete-Beas, and Wolfram Burgard.
\newblock {CALVIN}: A benchmark for language-conditioned policy learning for
  long-horizon robot manipulation tasks.
\newblock \emph{IEEE Robotics and Automation Letters}, 7\penalty0 (3):\penalty0
  7327--7334, Jul 2022.

\bibitem[Mnih et~al.(2013)Mnih, Kavukcuoglu, Silver, Graves, Antonoglou,
  Wierstra, and Riedmiller]{mnih2013atari}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis
  Antonoglou, Daan Wierstra, and Martin Riedmiller.
\newblock Playing atari with deep reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1312.5602}, Dec 2013.

\bibitem[Nichol et~al.(2022)Nichol, Dhariwal, Ramesh, Shyam, Mishkin, McGrew,
  Sutskever, and Chen]{nichol2022glide}
Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin,
  Bob McGrew, Ilya Sutskever, and Mark Chen.
\newblock {GLIDE}: Towards photorealistic image generation and editing with
  text-guided diffusion models.
\newblock In \emph{Proceedings of the International Conference on Machine
  Learning}, Baltimore, US, Jul 2022.

\bibitem[Peng et~al.(2019)Peng, Kumar, Zhang, and Levine]{peng2019awr}
Xue~Bin Peng, Aviral Kumar, Grace Zhang, and Sergey Levine.
\newblock Advantage-weighted regression: Simple and scalable off-policy
  reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1910.00177}, Oct 2019.

\bibitem[Ramesh et~al.(2022)Ramesh, Dhariwal, Nichol, Chu, and
  Chen]{ramesh2022hierarchical}
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.
\newblock Hierarchical text-conditional image generation with {CLIP} latents.
\newblock \emph{arXiv preprint arXiv:2204.06125}, Apr 2022.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and
  Ommer]{rombach2022highresolution}
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\"{o}rn
  Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceddings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, New Orleans, US, Jun 2022.

\bibitem[Rosete-Beas et~al.(2022)Rosete-Beas, Mees, Kalweit, Boedecker, and
  Burgard]{rosete2022tacorl}
Erick Rosete-Beas, Oier Mees, Gabriel Kalweit, Joschka Boedecker, and Wolfram
  Burgard.
\newblock Latent plans for task agnostic offline reinforcement learning.
\newblock In \emph{Proceedings of the Conference on Robot Learning}, Auckland,
  NZ, Dec 2022.

\bibitem[Saharia et~al.(2022)Saharia, Chan, Saxena, Li, Whang, Denton,
  Ghasemipour, Lopes, Ayan, Salimans, Ho, Fleet, and
  Norouzi]{saharia2022photorealistic}
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily~L.
  Denton, Kamyar Ghasemipour, Raphael~Gontijo Lopes, Burcu~Karagol Ayan, Tim
  Salimans, Jonathan Ho, David~J. Fleet, and Mohammad Norouzi.
\newblock Photorealistic text-to-image diffusion models with deep language
  understanding.
\newblock In \emph{Advances in Neural Information Processing Systems}, New
  Orleans, US, Dec 2022.

\bibitem[Silver et~al.(2016)Silver, Huang, Maddison, Guez, Sifre, Driessche,
  Schrittwieser, Antonoglou, Panneershelvam, Lanctot, Dieleman, Grewe, Nham,
  Kalchbrenner, Sutskever, Lillicrap, Leach, Kavukcuoglu, Graepel, and
  Hassabis]{silver2016mastergo}
David Silver, Aja Huang, Christopher Maddison, Arthur Guez, Laurent Sifre,
  George Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda
  Panneershelvam, Marc Lanctot, Sander Dieleman, Dominik Grewe, John Nham, Nal
  Kalchbrenner, Ilya Sutskever, Timothy Lillicrap, Madeleine Leach, Koray
  Kavukcuoglu, Thore Graepel, and Demis Hassabis.
\newblock Mastering the game of {G}o with deep neural networks and tree search.
\newblock \emph{Nature}, 529:\penalty0 484--489, Jan 2016.

\bibitem[Song et~al.(2021)Song, Meng, and Ermon]{song2021denoising}
Jiaming Song, Chenlin Meng, and Stefano Ermon.
\newblock Denoising diffusion implicit models.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations}, Virtual Conference, May 2021.

\bibitem[Song and Ermon(2019)]{song2019generative}
Yang Song and Stefano Ermon.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock In \emph{Advances in Neural Information Processing Systems},
  Vancouver, CA, Dec 2019.

\bibitem[Srinivas et~al.(2018)Srinivas, Jabri, Abbeel, Levine, and
  Finn]{srinivas2018upn}
Aravind Srinivas, Allan Jabri, Pieter Abbeel, Sergey Levine, and Chelsea Finn.
\newblock Universal planning networks.
\newblock In \emph{Proceedings of International Conference on Machine
  Learning}, Stockholm, SE, Jul 2018.

\bibitem[Tian et~al.(2021)Tian, Nair, Ebert, Dasari, Eysenbach, Finn, and
  Levine]{tian2021modelbased}
Stephen Tian, Suraj Nair, Frederik Ebert, Sudeep Dasari, Benjamin Eysenbach,
  Cehlsea Finn, and Sergey Levine.
\newblock Model-based visual planning with self-supervised functional
  distances.
\newblock In \emph{Proceedings of the International Conference on Learning
  Representations}, Virtual Conference, May 2021.

\bibitem[Urain et~al.(2023)Urain, Func, Peters, and Chalvatzaki]{urain2023se3}
Julen Urain, Niklas Func, Jan Peters, and Georgia Chalvatzaki.
\newblock {SE}(3)-{D}iffusion{F}ields: Learning smooth cost functions for joint
  grasp and motion optimization through diffusion.
\newblock \emph{arXiv preprint arXiv:2209.03855}, Mar 2023.

\bibitem[Van~der Maaten and Hinton(2008)]{van2008visualizing}
Laurens Van~der Maaten and Geoffrey Hinton.
\newblock Visualizing data using t-sne.
\newblock \emph{Journal of machine learning research}, 9:\penalty0 2579--2605,
  Nov 2008.

\bibitem[van Hasselt et~al.(2016)van Hasselt, Guez, and
  Silver]{hasselt2016doubleq}
Hado van Hasselt, Arthur Guez, and David Silver.
\newblock Deep reinforcement learning with double q-learning.
\newblock In \emph{Proceedings of AAAI Conference on Artificial Intelligence},
  Phoenix, US, Feb 2016.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N. Gomez, Lukasz Kaiser, and Illia Polosukhin.
\newblock Attention in all you need.
\newblock In \emph{Advances in Neural Information Processing Systems}, Long
  Beach, US, Dec 2017.

\bibitem[Wang et~al.(2022)Wang, Hunt, and Zhou]{wang2022diffpolicy}
Zhendong Wang, Jonathan~J. Hunt, and Mingyuan Zhou.
\newblock Diffusion policies as an expressive policy class for offline
  reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2208.06193}, Aug 2022.

\bibitem[Wu et~al.(2019)Wu, Tucker, and Nachum]{wu2019behavior}
Yifan Wu, George Tucker, and Ofir Nachum.
\newblock Behavior regularized offline reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1911.11361}, Nov 2019.

\bibitem[Yin and Wang(2021)]{yin2021ope}
Ming Yin and Yu-Xiang Wang.
\newblock Optimal uniform {OPE} and model-based offline reinforcement learning
  in time-homogeneous, reward-free and task-agnostic settings.
\newblock In \emph{Advances in Neural Information Processing Systems}, Virtual
  Conference, Dec 2021.

\bibitem[Yoo et~al.(2022)Yoo, Cho, and Woo]{yoo2022srtd}
Minjong Yoo, Sangwoo Cho, and Honguk Woo.
\newblock Skills regularized task decomposition for multi-task offline
  reinforcement learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, Long
  Beach, US, Dec 2022.

\bibitem[Zhou et~al.(2022)Zhou, Wang, Yan, Lv, Zhu, and
  Feng]{zhou2022magicvideo}
Daquan Zhou, Weimin Wang, Hanshu Yan, Weiwei Lv, Yizhe Zhu, and Jiashi Feng.
\newblock Magic{V}ideo: Efficient video generation with latent diffusion
  models.
\newblock \emph{arXiv preprint arXiv:2211.11018}, Nov 2022.

\end{thebibliography}
