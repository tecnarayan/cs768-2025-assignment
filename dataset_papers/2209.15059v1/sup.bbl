\begin{thebibliography}{17}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abboud et~al.(2021)Abboud, Ceylan, Grohe, and Lukasiewicz]{Abboud2021}
R.~Abboud, I.~I. Ceylan, M.~Grohe, and T.~Lukasiewicz.
\newblock The surprising power of graph neural networks with random node
  initialization.
\newblock In \emph{International Joint Conference on Artificial Intelligence
  (IJCAI)}, 2021.

\bibitem[Bouritsas et~al.(2020)Bouritsas, Frasca, Zafeiriou, and
  Bronstein]{Bouritsas2020}
G.~Bouritsas, F.~Frasca, S.~Zafeiriou, and M.~M. Bronstein.
\newblock Improving graph neural network expressivity via subgraph isomorphism
  counting.
\newblock In \emph{Arxiv e-prints}, 2020.

\bibitem[Defferrard et~al.(2018)Defferrard, Bresson, and
  Vandergheynst]{Defferrard16}
M.~Defferrard, X.~Bresson, and P.~Vandergheynst.
\newblock Convolutional neural networks on graphs with fast localized spectral
  filtering.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2018.

\bibitem[Gao and Ribeiro(2021)]{Gao2021}
J.~Gao and B.~Ribeiro.
\newblock On the equivalence between temporal and static graph representations
  for observational predictions.
\newblock \emph{ArXiv}, 2103.07016, 2021.

\bibitem[Kreuzer et~al.(2021)Kreuzer, Beaini, Hamilton, Letourneau, and
  Tossou]{Kreuzer2021}
D.~Kreuzer, D.~Beaini, W.~L. Hamilton, V.~Letourneau, and P.~Tossou.
\newblock Rethinking graph transformers with spectral attention.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2021.

\bibitem[Li et~al.(2020)Li, Wang, Wang, and Leskovec]{Li2020}
P.~Li, Y.~Wang, H.~Wang, and J.~Leskovec.
\newblock Distance encoding: Design provably more powerful neural networks for
  graph representation learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2020.

\bibitem[Mahdavi et~al.(2018)Mahdavi, Khoshraftar, and An]{Mahdavi2018}
S.~Mahdavi, S.~Khoshraftar, and A.~An.
\newblock dynnode2vec: Scalable dynamic network embedding.
\newblock In \emph{International Conference on Big Data}, 2018.

\bibitem[Makarov et~al.(2021)Makarov, Savchenko, Korovko, Sherstyuk, Severin,
  Mikheev, and Babaev]{tgn-caw}
I.~Makarov, A.~V. Savchenko, A.~Korovko, L.~Sherstyuk, N.~Severin, A.~Mikheev,
  and D.~Babaev.
\newblock Temporal graph network embedding with causal anonymous walks
  representations.
\newblock \emph{ArXiv}, 2108.08754, 2021.

\bibitem[Manessi et~al.(2020)Manessi, Rozza, and Manzo]{Manessi2020}
F.~Manessi, A.~Rozza, and M.~Manzo.
\newblock Dynamic graph convolutional networks.
\newblock \emph{Pattern Recognition}, 97, 2020.

\bibitem[Pareja et~al.(2020)Pareja, Domeniconi, Chen, Ma, T.~Suzumura, Kaler,
  Schardl, and Leiserson]{Pareja2020}
A.~Pareja, G.~Domeniconi, J.~Chen, T.~Ma, H.~Kanezashi T.~Suzumura, T.~Kaler,
  T.~B. Schardl, and C.~E. Leiserson.
\newblock {EvolveGCN}: Evolving graph convolutional networks for dynamic
  graphs.
\newblock In \emph{AAAI Conference on Artificial Intelligence (AAAI)}, 2020.

\bibitem[Sankar et~al.(2020)Sankar, Wu, Gou, Zhang, and Yang]{Sankar2020}
A.~Sankar, Y.~Wu, L.~Gou, W.~Zhang, and H.~Yang.
\newblock Dy{SAT}: Deep neural representation learning on dynamic graphs via
  self-attention networks.
\newblock In \emph{International Conference on Web Search and Data Mining
  (WSDM)}, 2020.

\bibitem[Sato et~al.(2021)Sato, Yamada, and Kashima]{Sato2021RandomFS}
R.~Sato, M.~Yamada, and H.~Kashima.
\newblock Random features strengthen graph neural networks.
\newblock In \emph{SIAM International Conference on Data Mining (SDM)}, 2021.

\bibitem[Seo et~al.(2018)Seo, Defferrard, Vandergheynst, and Bresson]{Seo2018}
Y.~Seo, M.~Defferrard, P.~Vandergheynst, and X.~Bresson.
\newblock Structured sequence modeling with graph convolutional recurrent
  networks.
\newblock In \emph{International Conference on Neural Information Processing
  (ICONIP)}, 2018.

\bibitem[Skarding et~al.(2021)Skarding, Gabrys, and
  Musial]{Skarding2021FoundationsAM}
J.~Skarding, B.~Gabrys, and K.~Musial.
\newblock Foundations and modeling of dynamic networks using dynamic graph
  neural networks: A survey.
\newblock \emph{IEEE Access}, 9:\penalty0 79143--79168, 2021.

\bibitem[Srinivasan and Ribeiro(2020)]{Srinivasan2020}
B.~Srinivasan and B.~Ribeiro.
\newblock On the equivalence between positional node embeddings and structural
  graph representations.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2020.

\bibitem[Wang et~al.(2022)Wang, Yin, Zhang, and Li]{Wang2022}
H.~Wang, H.~Yin, M.~Zhang, and P.~Li.
\newblock Equivariant and stable positional encoding for more powerful graph
  neural networks.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, 2022.

\bibitem[Wang et~al.(2021)Wang, Lyu, Li, Xia, Yang, Wang, Wang, Cui, Yang, Sun,
  and Guo]{APAN2021}
X.~Wang, D.~Lyu, M.~Li, Y.~Xia, Q.~Yang, X.~Wang, X.~Wang, P.~Cui, Y.~Yang,
  B.~Sun, and Z.~Guo.
\newblock {APAN}: Asynchronous propagation attention network for real-time
  temporal graph embedding.
\newblock \emph{International Conference on Management of Data}, 2021.

\end{thebibliography}
