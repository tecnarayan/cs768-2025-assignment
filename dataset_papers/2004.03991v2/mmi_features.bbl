\begin{thebibliography}{42}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alemi et~al.(2017)Alemi, Fischer, Dillon, and Murphy]{45903}
Alemi, A., Fischer, I., Dillon, J., and Murphy, K.
\newblock Deep variational information bottleneck.
\newblock In \emph{ICLR}, 2017.
\newblock URL \url{https://arxiv.org/abs/1612.00410}.

\bibitem[Bachman et~al.(2019)Bachman, Hjelm, and
  Buchwalter]{bachman2019learning}
Bachman, P., Hjelm, R.~D., and Buchwalter, W.
\newblock Learning representations by maximizing mutual information across
  views.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  15509--15519, 2019.

\bibitem[Belghazi et~al.(2018)Belghazi, Baratin, Rajeshwar, Ozair, Bengio,
  Courville, and Hjelm]{MINE}
Belghazi, M.~I., Baratin, A., Rajeshwar, S., Ozair, S., Bengio, Y., Courville,
  A., and Hjelm, D.
\newblock Mutual information neural estimation.
\newblock In Dy, J. and Krause, A. (eds.), \emph{Proceedings of the 35th
  International Conference on Machine Learning}, volume~80 of \emph{Proceedings
  of Machine Learning Research}, pp.\  531--540, Stockholmsm√§ssan, Stockholm
  Sweden, 10--15 Jul 2018. PMLR.

\bibitem[Bell \& Sejnowski(1995)Bell and Sejnowski]{bell1995information}
Bell, A.~J. and Sejnowski, T.~J.
\newblock An information-maximization approach to blind separation and blind
  deconvolution.
\newblock \emph{Neural computation}, 7\penalty0 (6):\penalty0 1129--1159, 1995.

\bibitem[Bengio et~al.(2013)Bengio, L{\'e}onard, and
  Courville]{bengio2013estimating}
Bengio, Y., L{\'e}onard, N., and Courville, A.
\newblock Estimating or propagating gradients through stochastic neurons for
  conditional computation.
\newblock \emph{arXiv preprint arXiv:1308.3432}, 2013.

\bibitem[Brown et~al.(1992)Brown, Desouza, Mercer, Pietra, and
  Lai]{brown1992class}
Brown, P.~F., Desouza, P.~V., Mercer, R.~L., Pietra, V.~J.~D., and Lai, J.~C.
\newblock Class-based $n$-gram models of natural language.
\newblock \emph{Computational Linguistics}, 18\penalty0 (4):\penalty0 467--479,
  1992.

\bibitem[Chaidaroon et~al.(2018)Chaidaroon, Ebesu, and
  Fang]{chaidaroon2018deep}
Chaidaroon, S., Ebesu, T., and Fang, Y.
\newblock Deep semantic text hashing with weak supervision.
\newblock In \emph{The 41st International ACM SIGIR Conference on Research \&
  Development in Information Retrieval}, pp.\  1109--1112, 2018.

\bibitem[Chen et~al.(2016)Chen, Duan, Houthooft, Schulman, Sutskever, and
  Abbeel]{chen2016infogan}
Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., and Abbeel, P.
\newblock Infogan: Interpretable representation learning by information
  maximizing generative adversarial nets.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  2172--2180, 2016.

\bibitem[Datar et~al.(2004)Datar, Immorlica, Indyk, and
  Mirrokni]{datar2004locality}
Datar, M., Immorlica, N., Indyk, P., and Mirrokni, V.~S.
\newblock Locality-sensitive hashing scheme based on p-stable distributions.
\newblock In \emph{Proceedings of the twentieth annual symposium on
  Computational geometry}, pp.\  253--262, 2004.

\bibitem[Devlin et~al.(2019)Devlin, Chang, Lee, and Toutanova]{devlin2019bert}
Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In \emph{Proceedings of the 2019 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pp.\  4171--4186, 2019.

\bibitem[Dong et~al.(2019)Dong, Su, Shen, and Chen]{dong2019document}
Dong, W., Su, Q., Shen, D., and Chen, C.
\newblock Document hashing with mixture-prior generative models.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing and the 9th International Joint Conference on
  Natural Language Processing (EMNLP-IJCNLP)}, pp.\  5229--5238, 2019.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair,
  S., Courville, A., and Bengio, Y.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  2672--2680, 2014.

\bibitem[He et~al.(2019)He, Spokoyny, Neubig, and Berg-Kirkpatrick]{he19iclr}
He, J., Spokoyny, D., Neubig, G., and Berg-Kirkpatrick, T.
\newblock Lagging inference networks and posterior collapse in variational
  autoencoders.
\newblock In \emph{International Conference on Learning Representations
  (ICLR)}, New Orleans, LA, USA, May 2019.
\newblock URL \url{https://openreview.net/pdf?id=rylDfnCqF7}.

\bibitem[Higgins et~al.(2017)Higgins, Matthey, Pal, Burgess, Glorot, Botvinick,
  Mohamed, and Lerchner]{higgins2017beta}
Higgins, I., Matthey, L., Pal, A., Burgess, C., Glorot, X., Botvinick, M.,
  Mohamed, S., and Lerchner, A.
\newblock beta-vae: Learning basic visual concepts with a constrained
  variational framework.
\newblock \emph{Iclr}, 2\penalty0 (5):\penalty0 6, 2017.

\bibitem[Hinton(2012)]{hinton2012practical}
Hinton, G.~E.
\newblock A practical guide to training restricted boltzmann machines.
\newblock In \emph{Neural networks: Tricks of the trade}, pp.\  599--619.
  Springer, 2012.

\bibitem[Hjelm et~al.(2019)Hjelm, Fedorov, Lavoie-Marchildon, Grewal, Bachman,
  Trischler, and Bengio]{DIM}
Hjelm, R.~D., Fedorov, A., Lavoie-Marchildon, S., Grewal, K., Bachman, P.,
  Trischler, A., and Bengio, Y.
\newblock Learning deep representations by mutual information estimation and
  maximization.
\newblock In \emph{International Conference on Learning Representations}, 2019.
\newblock URL \url{https://openreview.net/forum?id=Bklr3j0cKX}.

\bibitem[Hwa(2000)]{hwa2000sample}
Hwa, R.
\newblock Sample selection for statistical grammar induction.
\newblock In \emph{Proceedings of the 2000 Joint SIGDAT conference on Empirical
  methods in natural language processing and very large corpora: held in
  conjunction with the 38th Annual Meeting of the Association for Computational
  Linguistics-Volume 13}, pp.\  45--52. Association for Computational
  Linguistics, 2000.

\bibitem[Jang et~al.(2017)Jang, Gu, and Poole]{jang2017categorical}
Jang, E., Gu, S., and Poole, B.
\newblock Categorical reparameterization with gumbel-softmax.
\newblock In \emph{Proceedings of International Conference on Learning
  Representations (ICLR)}, 2017.
\newblock URL \url{https://arxiv.org/abs/1611.01144}.

\bibitem[Kaiser et~al.(2018)Kaiser, Bengio, Roy, Vaswani, Parmar, Uszkoreit,
  and Shazeer]{kaiser2018fast}
Kaiser, L., Bengio, S., Roy, A., Vaswani, A., Parmar, N., Uszkoreit, J., and
  Shazeer, N.
\newblock Fast decoding in sequence models using discrete latent variables.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  2390--2399, 2018.

\bibitem[Kingma \& Ba(2014)Kingma and Ba]{kingma2014adam}
Kingma, D.~P. and Ba, J.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{arXiv preprint arXiv:1412.6980}, 2014.

\bibitem[Kingma \& Welling(2014)Kingma and Welling]{kingma2014autoencoding}
Kingma, D.~P. and Welling, M.
\newblock Auto-encoding variational bayes.
\newblock In \emph{Proceedings of International Conference on Learning
  Representations (ICLR)}, 2014.
\newblock URL \url{https://arxiv.org/abs/1312.6114}.

\bibitem[Kudo \& Richardson(2018)Kudo and Richardson]{kudo2018sentencepiece}
Kudo, T. and Richardson, J.
\newblock Sentencepiece: A simple and language independent subword tokenizer
  and detokenizer for neural text processing.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing: System Demonstrations}, pp.\  66--71, 2018.

\bibitem[Maddison et~al.(2017)Maddison, Mnih, and Teh]{maddison2017concrete}
Maddison, C.~J., Mnih, A., and Teh, Y.~W.
\newblock The concrete distribution: A continuous relaxation of discrete random
  variables.
\newblock In \emph{Proceedings of International Conference on Learning
  Representations (ICLR)}, 2017.
\newblock URL \url{https://arxiv.org/abs/1611.00712}.

\bibitem[McAllester(2018)]{IT-cotrain}
McAllester, D.
\newblock Information theoretic co-training.
\newblock \emph{arXiv preprint arXiv:1802.07572}, 2018.

\bibitem[McAllester \& Stratos(2020)McAllester and Stratos]{limit}
McAllester, D. and Stratos, K.
\newblock Formal limitations on the measurement of mutual information.
\newblock In \emph{Artificial Intelligence and Statistics}, 2020.

\bibitem[Mikolov et~al.(2013)Mikolov, Chen, Corrado, and
  Dean]{mikolov2013efficient}
Mikolov, T., Chen, K., Corrado, G., and Dean, J.
\newblock Efficient estimation of word representations in vector space.
\newblock \emph{arXiv preprint arXiv:1301.3781}, 2013.

\bibitem[Mnih \& Gregor(2014)Mnih and Gregor]{Mnih2014}
Mnih, A. and Gregor, K.
\newblock {N}eural {V}ariational {I}nference and {L}earning in {B}elief
  {N}etworks.
\newblock In \emph{Proceedings of ICML}, 2014.

\bibitem[Mnih \& Rezende(2016)Mnih and Rezende]{Mnih2016}
Mnih, A. and Rezende, D.~J.
\newblock {V}ariational {I}nference for {M}onte {C}arlo {O}bjectives.
\newblock In \emph{Proceedings of ICML}, 2016.

\bibitem[Onishi et~al.(2016)Onishi, Wang, Bansal, Gimpel, and
  McAllester]{onishi2016did}
Onishi, T., Wang, H., Bansal, M., Gimpel, K., and McAllester, D.
\newblock Who did what: A large-scale person-centered cloze dataset.
\newblock In \emph{Proceedings of the 2016 Conference on Empirical Methods in
  Natural Language Processing}, pp.\  2230--2235, 2016.

\bibitem[Oord et~al.(2018)Oord, Li, and Vinyals]{Contrastive}
Oord, A. v.~d., Li, Y., and Vinyals, O.
\newblock Representation learning with contrastive predictive coding.
\newblock \emph{arXiv preprint arXiv:1807.03748}, 2018.

\bibitem[Peters et~al.(2018)Peters, Neumann, Iyyer, Gardner, Clark, Lee, and
  Zettlemoyer]{peters2018deep}
Peters, M., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., and
  Zettlemoyer, L.
\newblock Deep contextualized word representations.
\newblock In \emph{Proceedings of the 2018 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long Papers)}, pp.\  2227--2237, 2018.

\bibitem[Poole et~al.(2019)Poole, Ozair, Van Den~Oord, Alemi, and
  Tucker]{poole2019variational}
Poole, B., Ozair, S., Van Den~Oord, A., Alemi, A., and Tucker, G.
\newblock On variational bounds of mutual information.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  5171--5180, 2019.

\bibitem[Rabiner(1989)]{rabiner1989tutorial}
Rabiner, L.~R.
\newblock A tutorial on hidden markov models and selected applications in
  speech recognition.
\newblock \emph{Proceedings of the IEEE}, 77\penalty0 (2):\penalty0 257--286,
  1989.

\bibitem[Razavi et~al.(2019)Razavi, van~den Oord, and
  Vinyals]{razavi2019generating}
Razavi, A., van~den Oord, A., and Vinyals, O.
\newblock Generating diverse high-fidelity images with vq-vae-2.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  14837--14847, 2019.

\bibitem[Rezende et~al.(2014)Rezende, Mohamed, and
  Wierstra]{rezende2014stochastic}
Rezende, D.~J., Mohamed, S., and Wierstra, D.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock In \emph{Proceedings of the 31st International Conference on Machine
  Learning}, volume~32, pp.\  1278--1286. PMLR, 2014.

\bibitem[Shen et~al.(2018)Shen, Su, Chapfuwa, Wang, Wang, Henao, and
  Carin]{shen2018nash}
Shen, D., Su, Q., Chapfuwa, P., Wang, W., Wang, G., Henao, R., and Carin, L.
\newblock Nash: Toward end-to-end neural architecture for generative semantic
  hashing.
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pp.\  2041--2050,
  2018.

\bibitem[Stratos(2019)]{PartOfSpeech}
Stratos, K.
\newblock Mutual information maximization for simple and accurate
  part-of-speech induction.
\newblock In \emph{Proceedings of the 2019 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}. Association for Computational Linguistics, 2019.

\bibitem[Tishby et~al.(1999)Tishby, Pereira, and Bialek]{bottleneck}
Tishby, N., Pereira, F.~C., and Bialek, W.
\newblock The information bottleneck method.
\newblock In \emph{Proceedings of the 37-th Annual Allerton Conference on
  Communication, Control and Computing}, pp.\  368--377, 1999.

\bibitem[van~den Oord et~al.(2017)van~den Oord, Vinyals, et~al.]{van2017neural}
van~den Oord, A., Vinyals, O., et~al.
\newblock Neural discrete representation learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  6306--6315, 2017.

\bibitem[Viterbi(1967)]{viterbi1967error}
Viterbi, A.
\newblock Error bounds for convolutional codes and an asymptotically optimum
  decoding algorithm.
\newblock \emph{IEEE transactions on Information Theory}, 13\penalty0
  (2):\penalty0 260--269, 1967.

\bibitem[Weiss et~al.(2009)Weiss, Torralba, and Fergus]{weiss2009spectral}
Weiss, Y., Torralba, A., and Fergus, R.
\newblock Spectral hashing.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1753--1760, 2009.

\bibitem[Zhang et~al.(2010)Zhang, Wang, Cai, and Lu]{zhang2010self}
Zhang, D., Wang, J., Cai, D., and Lu, J.
\newblock Self-taught hashing for fast similarity search.
\newblock In \emph{Proceedings of the 33rd international ACM SIGIR conference
  on Research and development in information retrieval}, pp.\  18--25, 2010.

\end{thebibliography}
