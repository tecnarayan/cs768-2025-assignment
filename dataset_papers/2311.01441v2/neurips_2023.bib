@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NeurIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

%%%%%%% papers

@article{gou2021knowledge,
  title={Knowledge distillation: A survey},
  author={Gou, Jianping and Yu, Baosheng and Maybank, Stephen J and Tao, Dacheng},
  journal={International Journal of Computer Vision},
  volume={129},
  number={6},
  pages={1789--1819},
  year={2021},
  publisher={Springer}
}

@article{wang2021data,
  title={Data-free knowledge distillation with soft targeted transfer set synthesis},
  author={Wang, Zi},
  journal={arXiv preprint arXiv:2104.04868},
  year={2021}
}

@article{hinton2015kd,
    title={Distilling the knowledge in a neural network},
    author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
    journal={arXiv:1503.02531},
    year={2015}
}

@InProceedings{Huang_2023_ICCV,
    author    = {Huang, Zeyi and Zhou, Andy and Ling, Zijian and Cai, Mu and Wang, Haohan and Lee, Yong Jae},
    title     = {A Sentence Speaks a Thousand Images: Domain Generalization through Distilling CLIP with Language Guidance},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2023},
    pages     = {11685-11695}
}

@article{goldblum2020ard,
    title={Adversarially Robust Distillation},
    author={Goldblum, Micah and Fowl, Liam and Feizi, Soheil and Goldstein, Tom},
    journal={AAAI},
    year={2020}
}

@inproceedings{mao2022dat,
  author = {Mao, Xiaofeng and Chen, Yuefeng and Duan, Ranjie and Zhu, Yao and Qi, Gege and Ye, Shaokai and Li, Xiaodan and Zhang, Rong and Xue, Hui},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Enhance the Visual Representation via Discrete Adversarial Training},
  booktitle={NeurIPS},
  year = {2022}
}

@article{zi2021rslad,
  title={Revisiting Adversarial Robustness Distillation: Robust Soft Labels Make Student Better},
  author={Bojia Zi and Shihao Zhao and Xingjun Ma and Yu-Gang Jiang},
  journal={ICCV},
  year={2021}
}

@article{wang2022dakd,
  author = {Wang, Huan and Lohit, Suhas and Jones, Mike and Fu, Yun},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {What Makes a "Good" Data Augmentation in Knowledge Distillation -- A Statistical Perspective},
  
  journal={NeurIPS},
  
  year = {2020}
}

@article{hendrycks2019augmix,
  author = {Hendrycks, Dan and Mu, Norman and Cubuk, Ekin D. and Zoph, Barret and Gilmer, Justin and Lakshminarayanan, Balaji},
  title = {AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty},
  journal={ICLR},
  year={2019},
}

@inproceedings{tian2019crd,
  title={Contrastive Representation Distillation},
  author={Yonglong Tian and Dilip Krishnan and Phillip Isola},
  booktitle={ICLR},
  year={2020}
}

@inproceedings{minderer2021revisiting,
      title={Revisiting the Calibration of Modern Neural Networks},
      author={Matthias Minderer and Josip Djolonga and Rob Romijnders and Frances Hubis and Xiaohua Zhai and Neil Houlsby and Dustin Tran and Mario Lucic},
      booktitle={35th Conference on Neural Information Processing Systems (NeurIPS)},
      year={2021}
}

@inproceedings{geirhos2022imagenettrained,
      title={ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness},
      author={Robert Geirhos and Patricia Rubisch and Claudio Michaelis and Matthias Bethge and Felix A. Wichmann and Wieland Brendel},
      booktitle={ICLR},
      year={2019}
}

@inproceedings{mao2022discrete,
      title={Discrete Representations Strengthen Vision Transformer Robustness}, 
      author={Chengzhi Mao and Lu Jiang and Mostafa Dehghani and Carl Vondrick and Rahul Sukthankar and Irfan Essa},
      booktitle={ICLR},
      year={2022}
}

@inproceedings{
calian2022defending,
title={Defending Against Image Corruptions Through Adversarial Augmentations},
author={Dan Andrei Calian and Florian Stimberg and Olivia Wiles and Sylvestre-Alvise Rebuffi and Andr{\'a}s Gy{\"o}rgy and Timothy A Mann and Sven Gowal},
booktitle={ICLR},
year={2022},
url={https://openreview.net/forum?id=jJOjjiZHy3h}
}

@inproceedings{yun2019cutmix,
      title={CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features},
      author={Sangdoo Yun and Dongyoon Han and Seong Joon Oh and Sanghyuk Chun and Junsuk Choe and Youngjoon Yoo},
      booktitle={IEEE/CVF International Conference on Computer Vision (ICCV)},
      year={2019}
}

@inproceedings{mei2022fast,
      title={Fast AdvProp},
      author={Jieru Mei and Yucheng Han and Yutong Bai and Yixiao Zhang and Yingwei Li and Xianhang Li and Alan Yuille and Cihang Xie},
      booktitle={ICLR},
      year={2022}
}


@article{taori2020measuring,
      title={Measuring Robustness to Natural Distribution Shifts in Image Classification}, 
      author={Rohan Taori and Achal Dave and Vaishaal Shankar and Nicholas Carlini and Benjamin Recht and Ludwig Schmidt},
      year={2020},
      journal={arXiv:2007.00644}
}

@inproceedings{hendrycks2019benchmarking,
      title={Benchmarking Neural Network Robustness to Common Corruptions and Perturbations},
      author={Dan Hendrycks and Thomas Dietterich},
      booktitle={ICLR},
      year={2019}
}


@inproceedings{recht2019imagenet,
  title={Do ImageNet Classifiers Generalize to ImageNet?},
  author={Benjamin Recht and Rebecca Roelofs and Ludwig Schmidt and Vaishaal Shankar},
  booktitle={ICML},
  year={2019}
}

@inproceedings{addepalli2022efficient,
      title={Efficient and Effective Augmentation Strategy for Adversarial Training},
      author={Sravanti Addepalli and Samyak Jain and R. Venkatesh Babu},
      booktitle={35th Conference on Neural Information Processing Systems (NeurIPS 2022)},
      year={2022}
}

@article{Chae2020WassersteinUB,
  title={Wasserstein upper bounds of the total variation for smooth densities},
  author={Minwoo Chae and Stephen G. Walker},
  journal={Statistics \& Probability Letters},
  year={2020},
  volume={163},
  pages={108771}
}

@inproceedings{xie2020adversarial,
  title={Adversarial Examples Improve Image Recognition},
  author={Xie, Cihang and Tan, Mingxing and Gong, Boqing and Wang, Jiang and Yuille, Alan and Le, Quoc V.},
  booktitle={CVPR},
  year={2020}
}

@inproceedings{li2020shape,
  title={Shape-texture debiased neural network training},
  author={Li, Yingwei and Yu, Qihang and Tan, Mingxing and Mei, Jieru and Tang, Peng and Shen, Wei and Yuille, Alan and others},
  booktitle={ICLR},
  year={2020}
}


@inproceedings{tu2019theoretical,
      title={Theoretical Analysis of Adversarial Learning: A Minimax Approach}, 
      author={Tu, Zhuozhuo and Zhang, Jingwei and Tao, Dacheng},
      booktitle={NeurIPS},
      year={2019}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  year={2016}
}


@inproceedings{fang2022data,
      title={Data Determines Distributional Robustness in Contrastive Language Image Pre-training (CLIP)},
      author={Alex Fang and Gabriel Ilharco and Mitchell Wortsman and Yuhao Wan and Vaishaal Shankar and Achal Dave and Ludwig Schmidt},
      booktitle={ICML},
      year={2022}
}

@article{yang2019invariance,
  title={Invariance-inducing regularization using worst-case transformations suffices to boost accuracy and spatial robustness},
  author={Yang, Fanny and Wang, Zuowen and Heinze-Deml, Christina},
  journal={NeurIPS},
  volume={32},
  year={2019}
}

@incollection{kurakin2018adversarial,
  title={Adversarial examples in the physical world},
  author={Kurakin, Alexey and Goodfellow, Ian J and Bengio, Samy},
  booktitle={Artificial intelligence safety and security},
  pages={99--112},
  year={2018},
  publisher={Chapman and Hall/CRC}
}

@article{https://doi.org/10.48550/arxiv.2205.01917,
  author = {Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  
  title = {CoCa: Contrastive Captioners are Image-Text Foundation Models},
  
  journal={arXiv:2205.01917},
  
  year = {2022},
}


@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  year={2021}
}

@inproceedings{minderer2021revisiting,
  title={Revisiting the Calibration of Modern Neural Networks},
  author={Minderer, Matthias and Djolonga, Josip and Romijnders, Rob and Hubis, Frances and Zhai, Xiaohua and Houlsby, Neil and Tran, Dustin and Lucic, Mario},
  booktitle={NeurIPS (NeurIPS)},
  year={2021}
}

@article{gowal2021improving,
  title={Improving robustness using generated data},
  author={Gowal, Sven and Rebuffi, Sylvestre-Alvise and Wiles, Olivia and Stimberg, Florian and Calian, Dan Andrei and Mann, Timothy A},
  journal={NeurIPS},
  year={2021}
}

@misc{xu2020unixkd,
      title={Computation-Efficient Knowledge Distillation via Uncertainty-Aware Mixup}, 
      author={Guodong Xu and Ziwei Liu and Chen Change Loy},
      year={2020},
      eprint={2012.09413},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{schuhmann2022laion5b,
      title={LAION-5B: An open large-scale dataset for training next generation image-text models}, 
      author={Christoph Schuhmann and Romain Beaumont and Richard Vencu and Cade Gordon and Ross Wightman and Mehdi Cherti and Theo Coombes and Aarush Katta and Clayton Mullis and Mitchell Wortsman and Patrick Schramowski and Srivatsa Kundurthy and Katherine Crowson and Ludwig Schmidt and Robert Kaczmarczyk and Jenia Jitsev},
      booktitle={NeurIPS},
      year={2022}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv:2010.11929},
  year={2020}
}

@inproceedings{wortsman2022robust,
  title={Robust fine-tuning of zero-shot models},
  author={Wortsman, Mitchell and Ilharco, Gabriel and Kim, Jong Wook and Li, Mike and Kornblith, Simon and Roelofs, Rebecca and Lopes, Raphael Gontijo and Hajishirzi, Hannaneh and Farhadi, Ali and Namkoong, Hongseok and others},
  booktitle={CVPR},
  year={2022}
}

@misc{mao2022easyrobust,
  author =       {Xiaofeng Mao and Yuefeng Chen and Xiaodan Li and Gege Qi and Ranjie Duan and Rong Zhang and Hui Xue},
  title =        {EasyRobust: A Comprehensive and Easy-to-use Toolkit for Robust Computer Vision},
  howpublished = {\url{https://github.com/alibaba/easyrobust}},
  year =         {2022}
}

@inproceedings{wen2020towards,
  title={Towards understanding the regularization of adversarial robustness on neural networks},
  author={Wen, Yuxin and Li, Shuai and Jia, Kui},
  booktitle={International Conference on Machine Learning},
  pages={10225--10235},
  year={2020},
  organization={PMLR}
}

@inproceedings{wang2019learning,
        title={Learning Robust Global Representations by Penalizing Local Predictive Power},
        author={Wang, Haohan and Ge, Songwei and Lipton, Zachary and Xing, Eric P},
        booktitle={NeurIPS},
        year={2019}
}

@inproceedings{esser2021taming,
  title={Taming transformers for high-resolution image synthesis},
  author={Esser, Patrick and Rombach, Robin and Ommer, Bjorn},
  booktitle={CVPR},
  year={2021}
}

@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv:1412.6572},
  year={2014}
}

@inproceedings{zhang2019theoretically,
  title={Theoretically principled trade-off between robustness and accuracy},
  author={Zhang, Hongyang and Yu, Yaodong and Jiao, Jiantao and Xing, Eric and El Ghaoui, Laurent and Jordan, Michael},
  booktitle={ICML},
  year={2019}
}

@article{wang2022toward,
  title={Toward Learning Robust and Invariant Representations with Alignment Regularization and Data Augmentation},
  author={Wang, Haohan and Huang, Zeyi and Wu, Xindi and Xing, Eric P},
  journal={arXiv preprint arXiv:2206.01909},
  year={2022}
}

@inproceedings{tsipras2019robustness,
  title={Robustness may be at odds with accuracy},
  author={Tsipras, Dimitris and Santurkar, Shibani and Engstrom, Logan and Turner, Alexander and Madry, Aleksander},
  booktitle={ICML},
  year={2019}
}

@inproceedings{zhang2018mixup,
  title={MixUp: Beyond Empirical Risk Minimization},
  author={Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N and Lopez-Paz, David},
  booktitle={ICLR},
  year={2018}
}

@article{ghiasi2021augmax,
  title={AugMax: Adversarial Composition of Mixtures for Robust Data Augmentation},
  author={Ghiasi, Golnaz and Touvron, Hugo and DeVries, Tom and Lin, Tsung-Yi and LeCun, Yann and Mottaghi, Roozbeh},
  journal={arXiv:2106.00582},
  year={2021}
}

@inproceedings{gong2021maxup,
  title={MaxUp: A Simple Way to Improve Generalization of Neural Network Training},
  author={Gong, Chengyue and Ren, Tongzheng and Ye, Mao and Liu, Qiang},
  booktitle={CVPR},
  year={2021}
}

@inproceedings{hendrycks2021manyfaces,
  title={The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization},
  author={Hendrycks, Dan and Basart, Steven and Mu, Norman and Kadavath, Saurav and Wang, Frank and Dorundo, Evan and Desai, Rahul and Zhu, Tyler and Parajuli, Samyak and Guo, Mike and Song, Dawn and Steinhardt, Jacob and Gilmer, Justin},
  booktitle={ICCV},
  year={2021}
}

@inproceedings{geirhos2018generalisation,
  title={Generalisation in humans and deep neural networks},
  author={Geirhos, Robert and Temme, Carlos R. Medina and Rauber, Jonas and Sch{\"u}tt, Heiko H. and Bethge, Matthias and Wichmann, Felix A.},
  booktitle={NeurIPS (NeurIPS)},
  pages={7549--7561},
  year={2018}
}

@inproceedings{volpi2018generalizing,
  title={Generalizing to Unseen Domains via Adversarial Data Augmentation},
  author={Volpi, Riccardo and Namkoong, Hongseok and Sener, Ozan and Duchi, John C. and Murino, Vittorio and Savarese, Silvio},
  booktitle={NeurIPS (NeurIPS)},
  pages={5334--5344},
  year={2018}
}

@inproceedings{zhao2020maximum,
  title={Maximum-Entropy Adversarial Data Augmentation for Improved Generalization and Robustness},
  author={Zhao, Long and Liu, Ting and Peng, Xi and Metaxas, Dimitris},
  booktitle={NeurIPS (NeurIPS)},
  year={2020}
}


@inproceedings{zhang2020attacks,
  title={Attacks Which Do Not Kill Training Make Adversarial Learning Stronger},
  author={Zhang, Jingfeng and Xu, Xilie and Han, Bo and Niu, Gang and Cui, Lizhen and Sugiyama, Masashi and Kankanhalli, Mohan},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={11278--11287},
  year={2020}
}

@article{yang2022image,
      title={Image Data Augmentation for Deep Learning: A Survey}, 
      author={Suorong Yang and Weikang Xiao and Mengcheng Zhang and Suhan Guo and Jian Zhao and Furao Shen},
      journal={arXiv:2204.08610},
      year={2022}
}


@inproceedings{menon2021statistical,
  title={A Statistical Perspective on Distillation},
  author={Menon, Aditya K and Rawat, Ankit Singh and Reddi, Sashank and Kim, Seungyeon and Kumar, Sanjiv},
  booktitle={ICML},
  year={2021}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={CVPR},
  year={2009}
}

@inproceedings{gowal2020achieving,
  title={Achieving Robustness in the Wild via Adversarial Mixing with Disentangled Representations},
  author={Gowal, Sven and Qin, Chuan and Huang, Po-Sen and Cemgil, Taylan and Dvijotham, Krishnamurthy and Mann, Tim and Kohli, Pushmeet},
  booktitle={CVPR},
  year={2020}
}

@inproceedings{Fang2021MosaickingTD,
  title={Mosaicking to Distill: Knowledge Distillation from Out-of-Domain Data},
  author={Gongfan Fang and Yifan Bao and Jie Song and Xinchao Wang and Don Xie and Chengchao Shen and Mingli Song},
  booktitle={NeurIPS (NeurIPS)},
  year={2021}
}

@inproceedings{szegedy2019intriguing,
  title={Intriguing properties of neural networks},
  author={Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, D. and Goodfellow, Ian J. and Fergus, Rob},
  booktitle={ICLR},
  year={2014}
}

@inproceedings{geirhos2019imagenet,
  title={Imagenet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness},
  author={Geirhos, Robert and Rubisch, Patricia and Michaelis, Claudio and Bethge, Matthias and Wichmann, Felix A and Brendel, Wieland},
  booktitle={ICLR},
  year={2019}
}

@inproceedings{hendrycks2021natural,
    title={Natural adversarial examples},
    author={Hendrycks, Dan and Zhao, Kevin and Basart, Steven and Steinhardt, Jacob and Song, Dawn},
    booktitle={CVPR},
    year={2021}
}


@inproceedings{dehghani2023scaling,
    title={Scaling Vision Transformers to 22 Billion Parameters},
    author={Dehghani, Mostafa and Djolonga, Josip and Mustafa, Basil and others},
    booktitle={ICML},
    year={2023}
}



@inproceedings{mahmood2021robustness,
      title={On the Robustness of Vision Transformers to Adversarial Examples},
      author={Kaleel Mahmood and Rigel Mahmood and Marten van Dijk},
      booktitle={IEEE/CVF International Conference on Computer Vision (ICCV)},
      year={2021}
}

@inproceedings{cho2019efficacy,
  title={On the Efficacy of Knowledge Distillation},
  author={Cho, Jang Hyun and Hariharan, Bharath},
  booktitle={ICCV},
  year={2019}
}

@inproceedings{mirzadeh2020improved,
  title={Improved knowledge distillation via teacher assistant},
  author={Mirzadeh, Seyed Iman and Farajtabar, Mehrdad and Li, Ang and Levine, Nir and Matsukawa, Akihiro and Ghasemzadeh, Hassan},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2020}
}

@inproceedings{Zhao2022EnhancedAA,
  title={Enhanced Accuracy and Robustness via Multi-teacher Adversarial Distillation},
  author={Shiji Zhao and Jie Yu and Zhenlong Sun and Bo Zhang and Xingxing Wei},
  booktitle={ECCV},
  year={2022}
}

@inproceedings{zagoruyko2017paying,
  title={Paying more attention to attention: Improving the performance of convolutional neural networks via attention transfer},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  booktitle={ICLR},
  year={2017}
}


@inproceedings{wang2020collaborative,
  title={Collaborative Distillation for Ultra-Resolution Universal Style Transfer},
  author={Wang, Huan and Li, Yijun and Wang, Yuehai and Hu, Haoji and Yang, Ming-Hsuan},
  booktitle={CVPR},
  year={2020}
}

@article{Chen2020WassersteinCR,
  title={Wasserstein Contrastive Representation Distillation},
  author={Liqun Chen and Zhe Gan and Dong Wang and Jingjing Liu and Ricardo Henao and Lawrence Carin},
  journal={CVPR},
  year={2020}
}

@inproceedings{tung2019similarity,
  title={Similarity-Preserving Knowledge Distillation},
  author={Tung, Frederick and Mori, Greg},
  booktitle={CVPR},
  year={2019}
}

@inproceedings{liu2019knowledge,
  title={Knowledge Distillation via Instance Relationship Graph},
  author={Liu, Yufan and Cao, Jiajiong and Li, Bing and Yuan, Chunfeng and Hu, Weiming and Li, Yangxi and Duan, Yunqiang},
  booktitle={CVPR},
  year={2019}
}

@inproceedings{passalis2018learning,
  title={Learning Deep Representations with Probabilistic Knowledge Transfer},
  author={Passalis, Nikolaos and Tefas, Anastasios},
  booktitle={ECCV},
  year={2018}
}

@inproceedings{park2019relational,
  title={Relational Knowledge Distillation},
  author={Park, Wonpyo and Kim, Dongju and Lu, Yan and Cho, Minsu},
  booktitle={CVPR},
  year={2019}
}

@inproceedings{heo2019knowledge,
  title={Knowledge Transfer via Distillation of Activation Boundaries Formed by Hidden Neurons},
  author={Heo, Byeongho and Lee, Minsik and Yun, Sangdoo and Choi, Jin Young},
  booktitle={AAAI},
  year={2019}
}

@inproceedings{heo2019comprehensive,
  title={A Comprehensive Overhaul of Feature Distillation},
  author={Heo, Byeongho and Kim, Jeesoo and Yun, Sangdoo and Park, Hyojin and Kwak, Nojun and Choi, Jin Young},
  booktitle={ICCV},
  year={2019}
}


@inproceedings{zagoruyko2017attention,
  title={Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  booktitle={ICLR},
  year={2017}
}

@inproceedings{romero2015fitnets,
  title={Fitnets: Hints for Thin Deep Nets},
  author={Romero, Adriana and Ballas, Nicolas and Kahou, Samira Ebrahimi and Chassang, Antoine and Gatta, Carlo and Bengio, Yoshua},
  booktitle={ICLR},
  year={2015}
}

@article{sanh2020distilbert,
      title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter}, 
      author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
      journal={arXiv:1910.01108},
      year={2020}
}

@inproceedings{chen2017learning,
  title={Learning Efficient Object Detection Models with Knowledge Distillation},
  author={Chen, Guobin and Choi, Wongun and Yu, Xiang and Han, Tony and Chandraker, Manmohan},
  booktitle={NeurIPS},
  year={2017}
}

@inproceedings{qin2019adversarial,
  title={Adversarial Robustness through Local Linearization},
  author={Qin, C. and Martens, J. and Gowal, S. and Krishnan, D. and Dvijotham, K. and Fawzi, A. and De, S. and Stanforth, R. and Kohli, P.},
  booktitle={NeurIPS},
  year={2019}
}

@inproceedings{schmidt2018adversarially,
  title={Adversarially robust generalization requires more data},
  author={Schmidt, L. and Santurkar, S. and Tsipras, D. and Talwar, K. and Madry, A.},
  booktitle={NeurIPS},
  year={2018}
}

@inproceedings{wu2020adversarial,
  title={Adversarial weight perturbation helps robust generalization},
  author={Wu, D. and Xia, S.-T. and Wang, Y.},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{tack2022consistency,
  title={Consistency Regularization for Adversarial Robustness},
  author={Tack, Jihoon and Yu, Sihyun and Jeong, Jongheon and Kim, Minseon and Hwang, Sung Ju and Shin, Jinwoo},
  booktitle={AAAI},
  year={2022}
}

@inproceedings{li2023data,
      title={Data Augmentation Alone Can Improve Adversarial Training}, 
      author={Lin Li and Michael Spratling},
      booktitle={International Conference on Learning Representations},
      year={2023}
}

@article{bommasani2022opportunities,
  title={On the Opportunities and Risks of Foundation Models},
  author={Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and others},
  journal={arXiv:2108.07258},
  year={2022}
}

@inproceedings{raghunathan2020understanding_icml,
  title={Understanding and mitigating the tradeoff between robustness and accuracy},
  author={Raghunathan, Aditi and Xie, Sang Michael and Yang, Fanny and Duchi, John C. and Liang, Percy},
  booktitle={ICML},
  year={2020}
}

@inproceedings{shamsabadi2020colorfool,
  title={Colorfool: Semantic adversarial colorization},
  author={Shamsabadi, Ali Shahin and Sanchez-Matilla, Ricardo and Cavallaro, Andrea},
  booktitle={CVPR},
  year={2020}
}

@inproceedings{xie2019improving,
  title={Improving transferability of adversarial examples with input diversity},
  author={Xie, Cihang and Zhang, Zhishuai and Zhou, Yuyin and Bai, Song and Wang, Jianyu and Ren, Zhou and Yuille, Alan L},
  booktitle={CVPR},
  year={2019}
}

@article{liang2020mixkd,
  title={MixKD: Towards efficient distillation of large-scale language models},
  author={Liang, Kevin J and Hao, Weituo and Shen, Dinghan and Zhou, Yufan and Chen, Weizhu and Chen, Changyou and Carin, Lawrence},
  journal={arXiv preprint arXiv:2011.00593},
  year={2020}
}

@inproceedings{huang2022knowledge,
  title={Knowledge Distillation from A Stronger Teacher},
  author={Huang, Tao and You, Shan and Wang, Fei and Qian, Chen and Xu, Chang},
  booktitle={NeurIPS},
  year={2022}
}

@article{steiner2022train,
      title={How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers}, 
      author={Andreas Steiner and Alexander Kolesnikov and Xiaohua Zhai and Ross Wightman and Jakob Uszkoreit and Lucas Beyer},
      year={2022},
      journal={arXiv:2106.10270}
}

@inproceedings{croce2020reliable,
    title = {Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks},
    author = {Francesco Croce and Matthias Hein},
    booktitle = {ICML},
    year = {2020}
}

@inproceedings{rombach2021highresolution,
      title={High-Resolution Image Synthesis with Latent Diffusion Models}, 
      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Bj√∂rn Ommer},
      booktitle = {CVPR},
      year={2022}
}

@InProceedings{Cubuk_2019_CVPR,
    author = {Cubuk, Ekin D. and Zoph, Barret and Mane, Dandelion and Vasudevan, Vijay and Le, Quoc V.},
    title = {AutoAugment: Learning Augmentation Strategies From Data},
    booktitle = {CVPR},
    month = {June},
    year = {2019}
}

@article{xu2020computation,
  title={Computation-efficient knowledge distillation via uncertainty-aware mixup},
  author={Xu, Guodong and Liu, Ziwei and Loy, Chen Change},
  journal={arXiv preprint arXiv:2012.09413},
  year={2020}
}

@inproceedings{zhang2019adversarial,
  title={Adversarial autoaugment},
  author={Zhang, Xinyu and Wang, Qiang and Zhang, Jian and Zhong, Zhao},
  booktitle={ICLR},
  year={2019}
}

@inproceedings{baykal2023robust,
  title={Robust Active Distillation},
  author={Baykal, Cenk and Trinh, Khoa and Iliopoulos, Fotis and Menghani, Gaurav and Vee, Erik},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023}
}

@misc{menon2020distillation,
      title={Why distillation helps: a statistical perspective}, 
      author={Aditya Krishna Menon and Ankit Singh Rawat and Sashank J. Reddi and Seungyeon Kim and Sanjiv Kumar},
      year={2020},
      journal={arXiv:2005.10419}
}

@inproceedings{wang2022toward2,
  title={Toward learning robust and invariant representations with alignment regularization and data augmentation},
  author={Wang, Haohan and Huang, Zeyi and Wu, Xindi and Xing, Eric},
  booktitle={Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  year={2022}
}

@inproceedings{wang2020high,
  title={High-frequency component helps explain the generalization of convolutional neural networks},
  author={Wang, Haohan and Wu, Xindi and Huang, Zeyi and Xing, Eric P},
  booktitle={CVPR},
  year={2020}
}

@article{zhang2023foundation,
  title={Foundation Model-oriented Robustness: Robust Image Model Evaluation with Pretrained Models},
  author={Zhang, Peiyan and Liu, Haoyang and Li, Chaozhuo and Xie, Xing and Kim, Sunghun and Wang, Haohan},
  journal={arXiv:2308.10632},
  year={2023}
}

@inproceedings{cubuk2019randaugment,
  title={Randaugment: Practical automated data augmentation with a reduced search space},
  author={Cubuk, Ekin Dogus and Zoph, Barret and Shlens, Jon and Le, Quoc},
  booktitle={NeurIPS},
  editor={Larochelle, H. and Ranzato, M. and Hadsell, R. and Balcan, M. F. and Lin, H.},
  year={2019}
}

@inproceedings{karras2019style,
  title={A style-based generator architecture for generative adversarial networks},
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle={CVPR},
  year={2019}
}

@inproceedings{oord2017neural,
  title={Neural Discrete Representation Learning},
  author={van den Oord, Aaron and Vinyals, Oriol and Kavukcuoglu, Koray},
  booktitle={NeurIPS},
  year={2017}
}

@inproceedings{liu2017delving,
  title={Delving into Transferable Adversarial Examples and Black-box Attacks},
  author={Liu, Yanpei and Chen, Xinyun and Liu, Chang and Song, Dawn},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2017}
}

@inproceedings{li2023data,
  title={Data Augmentation Alone Can Improve Adversarial Training},
  author={Li, Lin and Spratling, Michael},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023}
}

@inproceedings{li2023making,
  title={Making Substitute Models More Bayesian Can Enhance Transferability of Adversarial Examples},
  author={Li, Qizhang and Guo, Yiwen and Zuo, Wangmeng and Chen, Hao},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023}
}

@inproceedings{cha2022domain,
  title={Domain Generalization by Mutual-Information Regularization with Pre-trained Models},
  author={Cha, Junbum and Lee, Kyungjae and Park, Sungrae and Chun, Sanghyuk},
  booktitle={ECCV},
  year={2022}
}

@inproceedings{Robey2021ModelBasedDG,
  title={Model-Based Domain Generalization},
  author={Alexander Robey and George J. Pappas and Hamed Hassani},
  booktitle={NeurIPS},
  year={2021}
}

@inproceedings{carmon2019unlabeled,
  title={Unlabeled Data Improves Adversarial Robustness},
  author={Carmon, Yair and Raghunathan, Aditi and Schmidt, Ludwig and Duchi, John C and Liang, Percy S},
  booktitle={NeurIPS},
  year={2019}
}

@inproceedings{madry2018towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  booktitle={ICLR},
  year={2018}
}

@inproceedings{rade2021reducing,
  title={Reducing excessive margin to achieve a better accuracy vs. robustness trade-off},
  author={Rade, Rahul and Moosavi-Dezfooli, Seyed-Mohsen},
  booktitle={ICLR},
  year={2021}
}

@inproceedings{rebuffi2023revisiting,
  title={Revisiting adapters with adversarial training},
  author={Rebuffi, Sylvestre-Alvise and Croce, Francesco and Gowal, Sven},
  booktitle={ICLR},
  year={2023}
}

@inproceedings{kim2023feature,
  title={Feature Separation and Recalibration for Adversarial Robustness},
  author={Kim, Woo Jae and Cho, Yoonki and Jung, Junsik and Yoon, Sung-Eui},
  booktitle={CVPR},
  year={2023}
}

@inproceedings{herrmann2022pyramid,
  title={Pyramid adversarial training improves ViT performance},
  author={Herrmann, Charles and Sargent, Kyle and Jiang, Lu and Zabih, Ramin and Chang, Huiwen and Liu, Ce and Krishnan, Dilip and Sun, Deqing},
  booktitle={CVPR},
  year={2022}
}

@inproceedings{cheng2019robust,
  title={Robust neural machine translation with doubly adversarial inputs},
  author={Cheng, Yong and Jiang, Lu and Macherey, Wolfgang},
  booktitle={57th Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2019}
}

@inproceedings{mao2023understanding,
  title={Understanding Zero-Shot Adversarial Robustness for Large-Scale Models},
  author={Mao, Chengzhi and Geng, Scott and Yang, Junfeng and Wang, Xin and Vondrick, Carl},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2023}
}

@inproceedings{cheng2020advaug,
  title={Advaug: Robust adversarial augmentation for neural machine translation},
  author={Cheng, Yong and Jiang, Lu and Macherey, Wolfgang and Eisenstein, Jacob},
  booktitle={58th Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2020}
}

@book{gine2021mathematical,
  title={Mathematical foundations of infinite-dimensional statistical models},
  author={Gin{\'e}, Evarist and Nickl, Richard},
  year={2021},
  publisher={Cambridge university press}
}

@article{CHAE2020108771,
title = {Wasserstein upper bounds of the total variation for smooth densities},
journal = {Statistics and Probability Letters},
volume = {163},
pages = {108771},
year = {2020},
issn = {0167-7152},
doi = {https://doi.org/10.1016/j.spl.2020.108771},
url = {https://www.sciencedirect.com/science/article/pii/S0167715220300742},
author = {Minwoo Chae and Stephen G. Walker},
keywords = {Probability inequality, Probability metric, Total variation, Sobolev space, Wasserstein metric},
abstract = {The total variation distance between probability measures cannot be bounded by the Wasserstein metric in general. If we consider sufficiently smooth probability densities, however, it is possible to bound the total variation by a power of the Wasserstein distance. We provide a sharp upper bound which depends on the Sobolev norms of the densities involved.}
}


@article{liu2023towards,
  title={Towards Trustworthy and Aligned Machine Learning: A Data-centric Survey with Causality Perspectives},
  author={Liu, Haoyang and Chaudhary, Maheep and Wang, Haohan},
  journal={arXiv:2307.16851},
  year={2023}
}

