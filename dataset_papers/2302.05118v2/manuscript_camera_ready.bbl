\begin{thebibliography}{54}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ashukha et~al.(2020)Ashukha, Lyzhov, Molchanov, and
  Vetrov]{ashukha2020pitfalls}
Ashukha, A., Lyzhov, A., Molchanov, D., and Vetrov, D.
\newblock Pitfalls of in-domain uncertainty estimation and ensembling in deep
  learning.
\newblock \emph{arXiv preprint arXiv:2002.06470}, 2020.

\bibitem[Barbu et~al.(2019)Barbu, Mayo, Alverio, Luo, Wang, Gutfreund,
  Tenenbaum, and Katz]{barbu2019objectnet}
Barbu, A., Mayo, D., Alverio, J., Luo, W., Wang, C., Gutfreund, D., Tenenbaum,
  J., and Katz, B.
\newblock Objectnet: A large-scale bias-controlled dataset for pushing the
  limits of object recognition models.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Chen \& Koltun(2017)Chen and Koltun]{chen2017photographic}
Chen, Q. and Koltun, V.
\newblock Photographic image synthesis with cascaded refinement networks.
\newblock In \emph{Proceedings of the IEEE international conference on computer
  vision}, pp.\  1511--1520, 2017.

\bibitem[Chollet(2017)]{chollet2017xception}
Chollet, F.
\newblock Xception: Deep learning with depthwise separable convolutions.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  1251--1258, 2017.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern
  recognition}, pp.\  248--255. Ieee, 2009.

\bibitem[Dosovitskiy et~al.(2020{\natexlab{a}})Dosovitskiy, Beyer, Kolesnikov,
  Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly,
  et~al.]{dosovitskiy2020image}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020{\natexlab{a}}.

\bibitem[Dosovitskiy et~al.(2020{\natexlab{b}})Dosovitskiy, Beyer, Kolesnikov,
  Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly,
  et~al.]{dosovitskiy2020image_vit}
Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X.,
  Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock \emph{arXiv preprint arXiv:2010.11929}, 2020{\natexlab{b}}.

\bibitem[Gal \& Ghahramani(2016)Gal and Ghahramani]{gal2016dropout}
Gal, Y. and Ghahramani, Z.
\newblock Dropout as a bayesian approximation: Representing model uncertainty
  in deep learning.
\newblock In \emph{international conference on machine learning}, pp.\
  1050--1059, 2016.

\bibitem[Gatys et~al.(2016)Gatys, Ecker, and Bethge]{gatys2016image}
Gatys, L.~A., Ecker, A.~S., and Bethge, M.
\newblock Image style transfer using convolutional neural networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  2414--2423, 2016.

\bibitem[Gong et~al.(2021)Gong, Lin, Yao, Dietterich, Divakaran, and
  Gervasio]{gong2021confidence}
Gong, Y., Lin, X., Yao, Y., Dietterich, T.~G., Divakaran, A., and Gervasio, M.
\newblock Confidence calibration for domain generalization under covariate
  shift.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  8958--8967, 2021.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and
  Weinberger]{guo_calibration_2017}
Guo, C., Pleiss, G., Sun, Y., and Weinberger, K.~Q.
\newblock On calibration of modern neural networks.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pp.\  1321--1330. {JMLR}. org, 2017.

\bibitem[Gupta et~al.(2021)Gupta, Rahimi, Ajanthan, Mensink, Sminchisescu, and
  Hartley]{gupta2020calibration}
Gupta, K., Rahimi, A., Ajanthan, T., Mensink, T., Sminchisescu, C., and
  Hartley, R.
\newblock Calibration of neural networks using splines.
\newblock In \emph{International Conference on Learning Representations}, 2021.
\newblock URL \url{https://openreview.net/forum?id=eQe8DEWNN2W}.

\bibitem[He et~al.(2016{\natexlab{a}})He, Zhang, Ren, and
  Sun]{he2016deep_resnet}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016{\natexlab{a}}.

\bibitem[He et~al.(2016{\natexlab{b}})He, Zhang, Ren, and
  Sun]{he2016identity_resnetV2}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Identity mappings in deep residual networks.
\newblock In \emph{European conference on computer vision}, pp.\  630--645.
  Springer, 2016{\natexlab{b}}.

\bibitem[Hendrycks \& Dietterich(2019)Hendrycks and
  Dietterich]{hendrycks2019benchmarking_imagenet_c}
Hendrycks, D. and Dietterich, T.
\newblock Benchmarking neural network robustness to common corruptions and
  perturbations.
\newblock \emph{International Conference on Learning Representations 2019},
  2019.

\bibitem[Hendrycks \& Gimpel(2017)Hendrycks and
  Gimpel]{hendrycks2017oodbaseline}
Hendrycks, D. and Gimpel, K.
\newblock A baseline for detecting misclassified and out-of-distribution
  examples in neural networks.
\newblock In \emph{ICLR}, 2017.

\bibitem[Hendrycks et~al.(2019)Hendrycks, Mazeika, Kadavath, and
  Song]{hendrycks2019using}
Hendrycks, D., Mazeika, M., Kadavath, S., and Song, D.
\newblock Using self-supervised learning can improve model robustness and
  uncertainty.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Huang et~al.(2017)Huang, Liu, Van Der~Maaten, and
  Weinberger]{huang2017densely_densenet}
Huang, G., Liu, Z., Van Der~Maaten, L., and Weinberger, K.~Q.
\newblock Densely connected convolutional networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  4700--4708, 2017.

\bibitem[Johnson et~al.(2019)Johnson, Douze, and J{\'e}gou]{johnson2019billion}
Johnson, J., Douze, M., and J{\'e}gou, H.
\newblock Billion-scale similarity search with {GPUs}.
\newblock \emph{IEEE Transactions on Big Data}, 7\penalty0 (3):\penalty0
  535--547, 2019.

\bibitem[Kolesnikov et~al.(2020)Kolesnikov, Beyer, Zhai, Puigcerver, Yung,
  Gelly, and Houlsby]{kolesnikov2020big}
Kolesnikov, A., Beyer, L., Zhai, X., Puigcerver, J., Yung, J., Gelly, S., and
  Houlsby, N.
\newblock Big transfer (bit): General visual representation learning.
\newblock In \emph{European conference on computer vision}, pp.\  491--507.
  Springer, 2020.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning_cifar}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock 2009.

\bibitem[Kull et~al.(2019)Kull, Perello~Nieto, K{\"a}ngsepp, Silva~Filho, Song,
  and Flach]{kull2019beyond}
Kull, M., Perello~Nieto, M., K{\"a}ngsepp, M., Silva~Filho, T., Song, H., and
  Flach, P.
\newblock Beyond temperature scaling: Obtaining well-calibrated multi-class
  probabilities with dirichlet calibration.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Lakshminarayanan et~al.(2017)Lakshminarayanan, Pritzel, and
  Blundell]{lakshminarayanan2017simple}
Lakshminarayanan, B., Pritzel, A., and Blundell, C.
\newblock Simple and scalable predictive uncertainty estimation using deep
  ensembles.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Lee et~al.(2018)Lee, Lee, Lee, and Shin]{lee2018mahalanobis}
Lee, K., Lee, K., Lee, H., and Shin, J.
\newblock A simple unified framework for detecting out-of-distribution samples
  and adversarial attacks.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Liang et~al.(2018)Liang, Li, and Srikant]{liang2018odin}
Liang, S., Li, Y., and Srikant, R.
\newblock Enhancing the reliability of out-of-distribution image detection in
  neural networks.
\newblock In \emph{ICLR}, 2018.

\bibitem[Maddox et~al.(2019)Maddox, Izmailov, Garipov, Vetrov, and
  Wilson]{maddox2019simple_rel_d}
Maddox, W.~J., Izmailov, P., Garipov, T., Vetrov, D.~P., and Wilson, A.~G.
\newblock A simple baseline for bayesian uncertainty in deep learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Mahajan et~al.(2018)Mahajan, Girshick, Ramanathan, He, Paluri, Li,
  Bharambe, and van~der Maaten]{wslimageseccv2018}
Mahajan, D.~K., Girshick, R.~B., Ramanathan, V., He, K., Paluri, M., Li, Y.,
  Bharambe, A., and van~der Maaten, L.
\newblock Exploring the limits of weakly supervised pretraining.
\newblock In \emph{ECCV}, 2018.

\bibitem[Milios et~al.(2018)Milios, Camoriano, Michiardi, Rosasco, and
  Filippone]{milios2018dirichlet}
Milios, D., Camoriano, R., Michiardi, P., Rosasco, L., and Filippone, M.
\newblock Dirichlet-based gaussian processes for large-scale calibrated
  classification.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Minderer et~al.(2021)Minderer, Djolonga, Romijnders, Hubis, Zhai,
  Houlsby, Tran, and Lucic]{minderer2021revisiting}
Minderer, M., Djolonga, J., Romijnders, R., Hubis, F., Zhai, X., Houlsby, N.,
  Tran, D., and Lucic, M.
\newblock Revisiting the calibration of modern neural networks.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 15682--15694, 2021.

\bibitem[M{\"u}ller et~al.(2019)M{\"u}ller, Kornblith, and
  Hinton]{muller2019does}
M{\"u}ller, R., Kornblith, S., and Hinton, G.~E.
\newblock When does label smoothing help?
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Naeini et~al.(2015)Naeini, Cooper, and
  Hauskrecht]{naeini2015obtaining}
Naeini, M.~P., Cooper, G., and Hauskrecht, M.
\newblock Obtaining well calibrated probabilities using bayesian binning.
\newblock In \emph{Twenty-Ninth AAAI Conference on Artificial Intelligence},
  2015.

\bibitem[Ovadia et~al.(2019)Ovadia, Fertig, Ren, Nado, Sculley, Nowozin,
  Dillon, Lakshminarayanan, and Snoek]{snoek2019can}
Ovadia, Y., Fertig, E., Ren, J., Nado, Z., Sculley, D., Nowozin, S., Dillon,
  J., Lakshminarayanan, B., and Snoek, J.
\newblock Can you trust your model's uncertainty? evaluating predictive
  uncertainty under dataset shift.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  13991--14002, 2019.

\bibitem[Platt(1999)]{Platt99probabilisticoutputs}
Platt, J.~C.
\newblock Probabilistic outputs for support vector machines and comparisons to
  regularized likelihood methods.
\newblock In \emph{Advances in large margin classifiers}, pp.\  61--74. MIT
  Press, 1999.

\bibitem[Rahimi et~al.(2020{\natexlab{a}})Rahimi, Gupta, Ajanthan, Mensink,
  Sminchisescu, and Hartley]{rahimi2020post}
Rahimi, A., Gupta, K., Ajanthan, T., Mensink, T., Sminchisescu, C., and
  Hartley, R.
\newblock Post-hoc calibration of neural networks.
\newblock \emph{arXiv preprint arXiv:2006.12807}, 2020{\natexlab{a}}.

\bibitem[Rahimi et~al.(2020{\natexlab{b}})Rahimi, Shaban, Cheng, Hartley, and
  Boots]{rahimi2020intra}
Rahimi, A., Shaban, A., Cheng, C.-A., Hartley, R., and Boots, B.
\newblock Intra order-preserving functions for calibration of multi-class
  neural networks.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 13456--13467, 2020{\natexlab{b}}.

\bibitem[Sensoy et~al.(2018)Sensoy, Kaplan, and
  Kandemir]{sensoy_evidential_2018}
Sensoy, M., Kaplan, L., and Kandemir, M.
\newblock Evidential deep learning to quantify classification uncertainty.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  3179--3189, 2018.

\bibitem[Simonyan \& Zisserman(2014)Simonyan and
  Zisserman]{simonyan2014very_vgg}
Simonyan, K. and Zisserman, A.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock \emph{arXiv preprint arXiv:1409.1556}, 2014.

\bibitem[Sun et~al.(2022)Sun, Ming, Zhu, and Li]{sun2022out}
Sun, Y., Ming, Y., Zhu, X., and Li, Y.
\newblock Out-of-distribution detection with deep nearest neighbors.
\newblock \emph{arXiv preprint arXiv:2204.06507}, 2022.

\bibitem[Thulasidasan et~al.(2019)Thulasidasan, Chennupati, Bilmes,
  Bhattacharya, and Michalak]{thulasidasan2019mixup}
Thulasidasan, S., Chennupati, G., Bilmes, J.~A., Bhattacharya, T., and
  Michalak, S.
\newblock On mixup training: Improved calibration and predictive uncertainty
  for deep neural networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Tomani \& Buettner(2021)Tomani and Buettner]{tomani2021falcon}
Tomani, C. and Buettner, F.
\newblock Towards trustworthy predictions from deep neural networks with fast
  adversarial calibration.
\newblock In \emph{Thirty-Fifth AAAI Conference on Artificial Intelligence},
  2021.

\bibitem[Tomani et~al.(2021)Tomani, Gruber, Erdem, Cremers, and
  Buettner]{tomani2021post}
Tomani, C., Gruber, S., Erdem, M.~E., Cremers, D., and Buettner, F.
\newblock Post-hoc uncertainty calibration for domain drift scenarios.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  10124--10132, 2021.

\bibitem[Tomani et~al.(2022)Tomani, Cremers, and
  Buettner]{tomani2022parameterized}
Tomani, C., Cremers, D., and Buettner, F.
\newblock Parameterized temperature scaling for boosting the expressive power
  in post-hoc uncertainty calibration.
\newblock In \emph{European Conference on Computer Vision}, pp.\  555--569.
  Springer, 2022.

\bibitem[Wald et~al.(2021)Wald, Feder, Greenfeld, and
  Shalit]{wald2021calibration}
Wald, Y., Feder, A., Greenfeld, D., and Shalit, U.
\newblock On calibration and out-of-domain generalization.
\newblock \emph{Advances in neural information processing systems},
  34:\penalty0 2215--2227, 2021.

\bibitem[Wang et~al.(2021)Wang, Feng, and Zhang]{wang2021rethinking}
Wang, D.-B., Feng, L., and Zhang, M.-L.
\newblock Rethinking calibration of deep neural networks: Do not be afraid of
  overconfidence.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 11809--11820, 2021.

\bibitem[Wang et~al.(2020)Wang, Long, Wang, and Jordan]{wang2020transferable}
Wang, X., Long, M., Wang, J., and Jordan, M.
\newblock Transferable calibration with lower bias and variance in domain
  adaptation.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 19212--19223, 2020.

\bibitem[Wen et~al.(2018)Wen, Vicol, Ba, Tran, and Grosse]{wen2018flipout}
Wen, Y., Vicol, P., Ba, J., Tran, D., and Grosse, R.
\newblock Flipout: Efficient pseudo-independent weight perturbations on
  mini-batches.
\newblock \emph{arXiv preprint arXiv:1803.04386}, 2018.

\bibitem[Wenger et~al.(2020)Wenger, Kjellstr{\"o}m, and Triebel]{wenger2020non}
Wenger, J., Kjellstr{\"o}m, H., and Triebel, R.
\newblock Non-parametric calibration for classification.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, pp.\  178--190. PMLR, 2020.

\bibitem[Xie et~al.(2017)Xie, Girshick, Doll{\'a}r, Tu, and
  He]{xie2017aggregated_resnext}
Xie, S., Girshick, R., Doll{\'a}r, P., Tu, Z., and He, K.
\newblock Aggregated residual transformations for deep neural networks.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  1492--1500, 2017.

\bibitem[Yu et~al.(2022)Yu, Bates, Ma, and Jordan]{yu2022robust}
Yu, Y., Bates, S., Ma, Y., and Jordan, M.~I.
\newblock Robust calibration with multi-domain temperature scaling.
\newblock \emph{arXiv preprint arXiv:2206.02757}, 2022.

\bibitem[Zadrozny \& Elkan(2001)Zadrozny and Elkan]{zadrozny2001obtaining}
Zadrozny, B. and Elkan, C.
\newblock Obtaining calibrated probability estimates from decision trees and
  naive bayesian classifiers.
\newblock In \emph{Icml}, volume~1, pp.\  609--616. Citeseer, 2001.

\bibitem[Zadrozny \& Elkan(2002)Zadrozny and Elkan]{zadrozny2002transforming}
Zadrozny, B. and Elkan, C.
\newblock Transforming classifier scores into accurate multiclass probability
  estimates.
\newblock In \emph{Proceedings of the eighth ACM SIGKDD international
  conference on Knowledge discovery and data mining}, pp.\  694--699, 2002.

\bibitem[Zhang et~al.(2017)Zhang, Cisse, Dauphin, and
  Lopez-Paz]{zhang2017mixup}
Zhang, H., Cisse, M., Dauphin, Y.~N., and Lopez-Paz, D.
\newblock mixup: Beyond empirical risk minimization.
\newblock \emph{arXiv preprint arXiv:1710.09412}, 2017.

\bibitem[Zhang et~al.(2020)Zhang, Kailkhura, and Han]{zhang2020mix}
Zhang, J., Kailkhura, B., and Han, T.
\newblock Mix-n-match: Ensemble and compositional methods for uncertainty
  calibration in deep learning.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.

\bibitem[Zhang et~al.(2018)Zhang, Isola, Efros, Shechtman, and
  Wang]{zhang2018perceptual}
Zhang, R., Isola, P., Efros, A.~A., Shechtman, E., and Wang, O.
\newblock The unreasonable effectiveness of deep features as a perceptual
  metric.
\newblock In \emph{CVPR}, 2018.

\end{thebibliography}
