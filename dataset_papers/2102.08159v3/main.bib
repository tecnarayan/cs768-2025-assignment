@article{acerbi2002coherence,
  title={On the coherence of expected shortfall},
  author={Acerbi, Carlo and Tasche, Dirk},
  journal={Journal of Banking \& Finance},
  volume={26},
  number={7},
  pages={1487--1503},
  year={2002},
  publisher={Elsevier}
}

@inproceedings{yang2019fully,
  title={Fully parameterized quantile function for distributional reinforcement learning},
  author={Yang, Derek and Zhao, Li and Lin, Zichuan and Qin, Tao and Bian, Jiang and Liu, Tie-Yan},
  booktitle={NeurIPS},
  pages={6193--6202},
  year={2019}
}

@book{oliehoek2016concise,
  title={A Concise Introduction to Decentralized {POMDPs}},
  author={Oliehoek, Frans A and Amato, Christopher and others},
  volume={1},
  year={2016},
  publisher={Springer}
}

@inproceedings{rashid2018qmix,
  title={{QMIX}: Monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and Schroeder, Christian and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  booktitle={International Conference on Machine Learning},
  pages={4295--4304},
  year={2018},
}

@article{sunehag2017value,
  title={Value-decomposition networks for cooperative multi-agent learning},
  author={Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others},
  journal={arXiv preprint arXiv:1706.05296},
  year={2017}
}

@inproceedings{bellemare2017distributional,
  title={A Distributional Perspective on Reinforcement Learning},
  author={Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={449--458},
  year={2017}
}


@article{rowland2018analysis,
  title={An analysis of categorical distributional reinforcement learning},
  author={Rowland, Mark and Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi and Teh, Yee Whye},
  journal={arXiv preprint arXiv:1802.08163},
  year={2018}
}

@inproceedings{dabney2018distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, R{\'e}mi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  pages={2892--2901},
  year={2018}
}

@inproceedings{dabney2018IQN,
  title={Implicit quantile networks for distributional reinforcement learning},
  author={Dabney, Will and Ostrovski, Georg and Silver, David and Munos, Remi},
  booktitle={International Conference on Machine Learning},
  pages={1096--1105},
  year={2018}
}

@article{samvelyan19smac,
  title = {{The} {StarCraft} {Multi}-{Agent} {Challenge}},
  author = {Mikayel Samvelyan and Tabish Rashid and Christian Schroeder de Witt and Gregory Farquhar and Nantas Nardelli and Tim G. J. Rudner and Chia-Man Hung and Philiph H. S. Torr and Jakob Foerster and Shimon Whiteson},
  journal = {CoRR},
  volume = {abs/1902.04043},
  year = {2019},
}

@article{rockafellar2000optimization,
  title={Optimization of conditional value-at-risk},
  author={Rockafellar, R Tyrrell and Uryasev, Stanislav and others},
  journal={Journal of Risk},
  volume={2},
  pages={21--42},
  year={2000}
}

@inproceedings{van2016pixel,
  title={Pixel recurrent neural networks},
  author={Van Den Oord, A{\"a}ron and Kalchbrenner, Nal and Kavukcuoglu, Koray},
  booktitle={Proceedings of the 33rd International Conference on International Conference on Machine Learning-Volume 48},
  pages={1747--1756},
  year={2016}
}

@article{tucker1959generalization,
  title={A generalization of the {Glivenko-Cantelli} theorem},
  author={Tucker, Howard G},
  journal={The Annals of Mathematical Statistics},
  volume={30},
  number={3},
  pages={828--830},
  year={1959},
  publisher={JSTOR}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{barth2018distributed,
  title={Distributed Distributional Deterministic Policy Gradients},
  author={Barth-Maron, Gabriel and Hoffman, Matthew W and Budden, David and Dabney, Will and Horgan, Dan and Dhruva, TB and Muldal, Alistair and Heess, Nicolas and Lillicrap, Timothy},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{mahajan2019maven,
  title={{MAVEN}: Multi-agent variational exploration},
  author={Mahajan, Anuj and Rashid, Tabish and Samvelyan, Mikayel and Whiteson, Shimon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7613--7624},
  year={2019}
}

@article{kolla2019concentration,
  title={Concentration bounds for empirical conditional value-at-risk: The unbounded case},
  author={Kolla, Ravi Kumar and Prashanth, LA and Bhat, Sanjay P and Jagannathan, Krishna},
  journal={Operations Research Letters},
  volume={47},
  number={1},
  pages={16--20},
  year={2019},
  publisher={Elsevier}
}

@article{huttenrauch2017guided,
  title={Guided Deep Reinforcement Learning for Swarm Systems},
  author={H{\"u}ttenrauch, Maximilian and {\v{S}}o{\v{s}}i{\'c}, Adrian and Neumann, Gerhard},
  journal={In AAMAS 2017 Autonomous Robots and Multirobot Systems (ARMS) Workshop},
  pages={},
  year={2017}
}

@article{vinyals2019grandmaster,
  title={Grandmaster level in {StarCraft II} using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group}
}

@inproceedings{singh2020hierarchical,
  title={Hierarchical Multiagent Reinforcement Learning for Maritime Traffic Management},
  author={Singh, Arambam James and Kumar, Akshat and Lau, Hoong Chuin},
  booktitle={Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems},
  pages={1278--1286},
  year={2020}
}

@inproceedings{qiu2019dynamic,
  title={Dynamic electronic toll collection via multi-agent deep reinforcement learning with edge-based graph convolutional networks},
  author={Qiu, Wei and Chen, Haipeng and An, Bo},
  booktitle={Proceedings of the 28th International Joint Conference on Artificial Intelligence},
  pages={4568--4574},
  year={2019},
  organization={AAAI Press}
}

@inproceedings{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  booktitle={International Conference on Learning Representations},
  year={2016}
}

@article{silver2017mastering1,
  title={Mastering the game of {Go} without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={Nature},
  volume={550},
  number={7676},
  pages={354â€“359},
  year={2017},
  publisher={Nature Publishing Group}
}

@inproceedings{lowe2017multi,
  title={Multi-agent actor-critic for mixed cooperative-competitive environments},
  author={Lowe, Ryan and Wu, Yi and Tamar, Aviv and Harb, Jean and Abbeel, OpenAI Pieter and Mordatch, Igor},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6379--6390},
  year={2017}
}

@article{tampuu2017multiagent,
  title={Multiagent cooperation and competition with deep reinforcement learning},
  author={Tampuu, Ardi and Matiisen, Tambet and Kodelja, Dorian and Kuzovkin, Ilya and Korjus, Kristjan and Aru, Juhan and Aru, Jaan and Vicente, Raul},
  journal={PLoS ONE},
  volume={12},
  number={4},
  year={2017},
  publisher={Public Library of Science}
}

@inproceedings{son2019qtran,
  title={{QTRAN}: Learning to Factorize with Transformation for Cooperative Multi-Agent Reinforcement Learning},
  author={Son, Kyunghwan and Kim, Daewoo and Kang, Wan Ju and Hostallero, David Earl and Yi, Yung},
  booktitle={International Conference on Machine Learning},
  pages={5887--5896},
  year={2019}
}

@article{foerster2017counterfactual,
  title={Counterfactual multi-agent policy gradients},
  author={Foerster, Jakob and Farquhar, Gregory and Afouras, Triantafyllos and Nardelli, Nantas and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1705.08926},
  year={2017}
}

@article{wang2020qplex,
  title={QPLEX: Duplex Dueling Multi-Agent Q-Learning},
  author={Wang, Jianhao and Ren, Zhizhou and Liu, Terry and Yu, Yang and Zhang, Chongjie},
  journal={arXiv preprint arXiv:2008.01062},
  year={2020}
}

@article{wang2020off,
  title={Off-Policy Multi-Agent Decomposed Policy Gradients},
  author={Wang, Yihan and Han, Beining and Wang, Tonghan and Dong, Heng and Zhang, Chongjie},
  journal={arXiv preprint arXiv:2007.12322},
  year={2020}
}

@inproceedings{keramati2019being,
  title={Being optimistic to be conservative: Quickly learning a cvar policy},
  author={Keramati, Ramtin and Dann, Christoph and Tamkin, Alex and Brunskill, Emma},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  pages     = {4436--4443},
  year      = {2020},
}

@inproceedings{zhang2019quota,
  title={QUOTA: The quantile option architecture for reinforcement learning},
  author={Zhang, Shangtong and Yao, Hengshuai},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={5797--5804},
  year={2019}
}

@inproceedings{tang2019worst,
  title={Worst Cases Policy Gradients},
  author={Tang, Yichuan Charlie and Zhang, Jian and Salakhutdinov, Ruslan},
  booktitle={Conference on Robot Learning},
  pages={1078--1093},
  year={2020},
}

@article{ma2020distributional,
  title={Distributional Soft Actor Critic for Risk Sensitive Learning},
  author={Ma, Xiaoteng and Zhang, Qiyuan and Xia, Li and Zhou, Zhengyuan and Yang, Jun and Zhao, Qianchuan},
  journal={arXiv preprint arXiv:2004.14547},
  year={2020}
}

@article{garcia2015comprehensive,
  title={A Comprehensive Survey on Safe Reinforcement Learning},
  author={Garc{\'\i}a, Javier and others},
  journal={Journal of Machine Learning Research},
  volume={16},
  number={42},
  pages={1437--1480},
  year={2015}
}

@inproceedings{tamar2015policy,
  title={Policy gradient for coherent risk measures},
  author={Tamar, Aviv and Chow, Yinlam and Ghavamzadeh, Mohammad and Mannor, Shie},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1468--1476},
  year={2015}
}

@inproceedings{chow2014algorithms,
  title={Algorithms for CVaR optimization in {MDP}s},
  author={Chow, Yinlam and Ghavamzadeh, Mohammad},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3509--3517},
  year={2014}
}

@incollection{majumdar2020should,
  title={How should a robot assess risk? {T}owards an axiomatic theory of risk in robotics},
  author={Majumdar, Anirudha and Pavone, Marco},
  booktitle={Robotics Research},
  pages={75--84},
  year={2020},
  publisher={Springer}
}

@article{bu2008comprehensive,
  title={A comprehensive survey of multiagent reinforcement learning},
  author={Bu{\c{s}}oniu, Lucian and Babu{\v{s}}ka, Robert and De Schutter, Bart},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  volume={38},
  number={2},
  pages={156--172},
  year={2008},
  publisher={IEEE}
}

@inproceedings{foerster2017stabilising,
  title={Stabilising experience replay for deep multi-agent reinforcement learning},
  author={Foerster, Jakob and Nardelli, Nantas and Farquhar, Gregory and Afouras, Triantafyllos and Torr, Philip HS and Kohli, Pushmeet and Whiteson, Shimon},
  booktitle={International Conference on Machine Learning},
  pages={1146--1155},
  year={2017}
}

@inproceedings{fischer2004hierarchical,
  title={Hierarchical reinforcement learning in communication-mediated multiagent coordination},
  author={Fischer, Felix and Rovatsos, Michael and Weiss, Gerhard},
  booktitle={AAMAS},
  pages={1334--1335},
  year={2004},
}

@inproceedings{foerster2016learning,
  title={Learning to communicate with deep multi-agent reinforcement learning},
  author={Foerster, Jakob and Assael, Ioannis Alexandros and de Freitas, Nando and Whiteson, Shimon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2137--2145},
  year={2016}
}

@inproceedings{he2016opponent,
  title={Opponent modeling in deep reinforcement learning},
  author={He, He and Boyd-Graber, Jordan and Kwok, Kevin and Daum{\'e} III, Hal},
  booktitle={International Conference on Machine Learning},
  pages={1804--1813},
  year={2016}
}

@article{schulman2017proximal,
  title={Proximal Policy Optimization Algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{reddy2019risk,
  title={Risk averse reinforcement learning for mixed multi-agent environments},
  author={Reddy, D Sai Koti and Saha, Amrita and Tamilselvam, Srikanth G and Agrawal, Priyanka and Dayama, Pankaj},
  booktitle={Proceedings of the 18th International Conference on Autonomous Agents and MultiAgent Systems},
  pages={2171--2173},
  year={2019}
}

@inproceedings{lyu2020likelihood,
  title={Likelihood Quantile Networks for Coordinating Multi-Agent Reinforcement Learning},
  author={Lyu, Xueguang and Amato, Christopher},
  booktitle={Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems},
  pages={798--806},
  year={2020}
}


@inproceedings{jiang2018learning,
  title={Learning attentional communication for multi-agent cooperation},
  author={Jiang, Jiechuan and Lu, Zongqing},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7254--7264},
  year={2018}
}

@article{wang2020imac,
  title={Learning Efficient Multi-agent Communication: An Information Bottleneck Approach},
  author={Wang, Rundong and He, Xu and Yu, Runsheng and Qiu, Wei and An, Bo and Rabinovich, Zinovi},
  journal={International Conference on Machine Learning},
  pages={},
  year={2020}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@inproceedings{iqbal2019actor,
  title={Actor-attention-critic for multi-agent reinforcement learning},
  author={Iqbal, Shariq and Sha, Fei},
  booktitle={International Conference on Machine Learning},
  pages={2961--2970},
  year={2019}
}

@inproceedings{das2019tarmac,
  title={Tarmac: Targeted multi-agent communication},
  author={Das, Abhishek and Gervet, Th{\'e}ophile and Romoff, Joshua and Batra, Dhruv and Parikh, Devi and Rabbat, Mike and Pineau, Joelle},
  booktitle={International Conference on Machine Learning},
  pages={1538--1546},
  year={2019}
}

@inproceedings{hiraoka2019learning,
  title={Learning Robust Options by Conditional Value at Risk Optimization},
  author={Hiraoka, Takuya and Imagawa, Takahisa and Mori, Tatsuya and Onishi, Takashi and Tsuruoka, Yoshimasa},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2619--2629},
  year={2019}
}

@inproceedings{wang2020roma,
  title={ROMA: Multi-Agent Reinforcement Learning with Emergent Roles.},
  author={Wang, Tonghan and Dong, Heng and Lesser, Victor and Zhang, Chongjie},
  booktitle={Proceedings of the 37th International Conference on Machine Learning},
  year={2020}
}

@article{vinyals2017starcraft,
  title={{StarCraft II}: A new challenge for reinforcement learning},
  author={Vinyals, Oriol and Ewalds, Timo and Bartunov, Sergey and Georgiev, Petko and Vezhnevets, Alexander Sasha and Yeo, Michelle and Makhzani, Alireza and K{\"u}ttler, Heinrich and Agapiou, John and Schrittwieser, Julian and others},
  journal={arXiv preprint arXiv:1708.04782},
  year={2017}
}

@article{maaten2008visualizing,
  title={Visualizing data using t-SNE},
  author={Maaten, Laurens van der and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={Nov},
  pages={2579--2605},
  year={2008}
}

@inproceedings{chow2015risk,
  title={Risk-sensitive and robust decision-making: a cvar optimization approach},
  author={Chow, Yinlam and Tamar, Aviv and Mannor, Shie and Pavone, Marco},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1522--1530},
  year={2015}
}

@inproceedings{tamar2015optimizing,
  title={Optimizing the CVaR via sampling},
  author={Tamar, Aviv and Glassner, Yonatan and Mannor, Shie},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  pages={2993--2999},
  year={2015}
}

@inproceedings{chung2014empirical,
  title={Empirical evaluation of gated recurrent neural networks on sequence modeling},
  author={Chung, Junyoung and Gulcehre, Caglar and Cho, Kyunghyun and Bengio, Yoshua},
  booktitle={Advances in Neural Information Processing Systems 2014 Workshop on Deep Learning},
  year={2014}
}

@inproceedings{ha2016hypernetworks,
  title={HyperNetworks},
  author={Ha, David and Dai, Andrew and Le, Quoc V},
  booktitle = {International Conference on Learning Representations},
  publisher = {OpenReview.net},
  year      = {2017},
}

@article{artzner1999coherent,
  title={Coherent measures of risk},
  author={Artzner, Philippe and Delbaen, Freddy and Eber, Jean-Marc and Heath, David},
  journal={Mathematical Finance},
  volume={9},
  number={3},
  pages={203--228},
  year={1999},
  publisher={Wiley Online Library}
}

@article{rockafellar2002conditional,
  title={Conditional value-at-risk for general loss distributions},
  author={Rockafellar, R Tyrrell and Uryasev, Stanislav},
  journal={Journal of Banking \& Finance},
  volume={26},
  number={7},
  pages={1443--1471},
  year={2002},
  publisher={Elsevier}
}

@article{rashid2020weighted,
  title={Weighted QMIX: Expanding Monotonic Value Function Factorisation},
  author={Rashid, Tabish and Farquhar, Gregory and Peng, Bei and Whiteson, Shimon},
  journal={arXiv preprint arXiv:2006.10800},
  year={2020}
}

@book{sutton2018reinforcement,
  title={Reinforcement Learning: An Introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{yang2020qatten,
  title={Qatten: A General Framework for Cooperative Multiagent Reinforcement Learning},
  author={Yang, Yaodong and Hao, Jianye and Liao, Ben and Shao, Kun and Chen, Guangyong and Liu, Wulong and Tang, Hongyao},
  journal={arXiv preprint arXiv:2002.03939},
  year={2020}
}

@article{oliehoek2008optimal,
  title={Optimal and approximate Q-value functions for decentralized {POMDP}s},
  author={Oliehoek, Frans A and Spaan, Matthijs TJ and Vlassis, Nikos},
  journal={Journal of Artificial Intelligence Research},
  volume={32},
  pages={289--353},
  year={2008}
}

@article{kraemer2016multi,
  title={Multi-agent reinforcement learning as a rehearsal for decentralized planning},
  author={Kraemer, Landon and Banerjee, Bikramjit},
  journal={Neurocomputing},
  volume={190},
  pages={82--94},
  year={2016},
  publisher={Elsevier}
}

@misc{fra,
author = {Privault, Nicolas},
title = {Notes on {F}inancial {R}isk and {A}nalytics},
howpublished = {Course notes, 268 pages},
note = {Accessed: 2020-09-27},
year = {2020}
}

@book{von1947theory,
  title={Theory of {G}ames and {E}conomic {B}ehavior, 2nd rev},
  author={Von Neumann, John and Morgenstern, Oskar},
  year={1947},
  publisher={Princeton university press}
}

@article{iancu2015tight,
  title={Tight approximations of dynamic risk measures},
  author={Iancu, Dan A and Petrik, Marek and Subramanian, Dharmashankar},
  journal={Mathematics of Operations Research},
  volume={40},
  number={3},
  pages={655--682},
  year={2015},
  publisher={INFORMS}
}

@article{ruszczynski2010risk,
  title={Risk-averse dynamic programming for Markov decision processes},
  author={Ruszczy{\'n}ski, Andrzej},
  journal={Mathematical Programming},
  volume={125},
  number={2},
  pages={235--261},
  year={2010},
  publisher={Springer}
}

@article{tversky1992advances,
  title={Advances in prospect theory: Cumulative representation of uncertainty},
  author={Tversky, Amos and Kahneman, Daniel},
  journal={Journal of Risk and uncertainty},
  volume={5},
  number={4},
  pages={297--323},
  year={1992},
  publisher={Springer}
}

@article{zhang2020cautious,
  title={Cautious Reinforcement Learning via Distributional Risk in the Dual Domain},
  author={Zhang, Junyu and Bedi, Amrit Singh and Wang, Mengdi and Koppel, Alec},
  journal={arXiv preprint arXiv:2002.12475},
  year={2020}
}

@article{hu2020qr,
  title={QR-MIX: Distributional Value Function Factorisation for Cooperative Multi-Agent Reinforcement Learning},
  author={Hu, Jian and Harding, Seth Austin and Wu, Haibin and Liao, Shih-wei},
  journal={arXiv preprint arXiv:2009.04197},
  year={2020}
}

@inproceedings{lan2019maxmin,
  title={Maxmin Q-learning: Controlling the Estimation Bias of Q-learning},
  author={Lan, Qingfeng and Pan, Yangchen and Fyshe, Alona and White, Martha},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{chen2021randomized,
  title={Randomized Ensembled Double Q-Learning: Learning Fast Without a Model},
  author={Xinyue Chen and Che Wang and Zijian Zhou and Keith W. Ross},
  booktitle={International Conference on Learning Representations},
  year={2021},
  url={}
}

@inproceedings{hasselt2010double,
  title={Double Q-learning},
  author={Hasselt, Hado V},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2613--2621},
  year={2010}
}

@inproceedings{thrun1993issues,
  title={Issues in using function approximation for reinforcement learning},
  author={Thrun, Sebastian and Schwartz, Anton},
  booktitle={Proceedings of the Fourth Connectionist Models Summer School},
  pages={255--263},
  year={1993},
}

@article{rashid2020monotonic,
  title={Monotonic value function factorisation for deep multi-agent reinforcement learning},
  author={Rashid, Tabish and Samvelyan, Mikayel and De Witt, Christian Schroeder and Farquhar, Gregory and Foerster, Jakob and Whiteson, Shimon},
  journal={Journal of Machine Learning Research},
  volume={21},
  number={178},
  pages={1--51},
  year={2020},
  publisher={Journal of Machine Learning Research}
}

@inproceedings{arjovsky2017wasserstein,
  title={Wasserstein generative adversarial networks},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  booktitle={International Conference on Machine Learning},
  pages={214--223},
  year={2017},
  organization={PMLR}
}

@inproceedings{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2672--2680},
  year={2014}
}
