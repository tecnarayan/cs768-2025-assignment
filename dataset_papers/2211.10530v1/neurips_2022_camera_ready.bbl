\begin{thebibliography}{10}

\bibitem{DBLP:conf/aaai/ChenCBLELMS19}
Bryant Chen, Wilka Carvalho, Nathalie Baracaldo, Heiko Ludwig, Benjamin
  Edwards, Taesung Lee, Ian Molloy, and Biplav Srivastava.
\newblock Detecting backdoor attacks on deep neural networks by activation
  clustering.
\newblock In {\em SafeAI@AAAI}, 2019.

\bibitem{NEURIPS2019_95e1533e}
Mahyar Fazlyab, Alexander Robey, Hamed Hassani, Manfred Morari, and George
  Pappas.
\newblock Efficient and accurate estimation of lipschitz constants for deep
  neural networks.
\newblock In {\em Advances in Neural Information Processing Systems},
  volume~32, 2019.

\bibitem{gao2019strip}
Yansong Gao, Chang Xu, Derui Wang, Shiping Chen, Damith~C Ranasinghe, and Surya
  Nepal.
\newblock Strip: A defence against trojan attacks on deep neural networks.
\newblock In {\em 35th Annual Computer Security Applications Conference
  (ACSAC)}, 2019.

\bibitem{badnets_2019}
Tianyu Gu, Kang Liu, Brendan Dolan-Gavitt, and Siddharth Garg.
\newblock Badnets: Evaluating backdooring attacks on deep neural networks.
\newblock {\em IEEE Access}, 7:47230--47244, 2019.

\bibitem{https://doi.org/10.48550/arxiv.2202.03609}
Junfeng Guo, Ang Li, and Cong Liu.
\newblock Backdoor detection in reinforcement learning.
\newblock {\em arXiv preprint arXiv:2202.03609}, 2022.

\bibitem{Karra2020TheTS}
Kiran Karra, Chace Ashcraft, and Neil Fendley.
\newblock The {TrojAI} software framework: An opensource tool for embedding
  trojans into deep learning models.
\newblock {\em arXiv preprint arXiv:2003.07233}, 2020.

\bibitem{trojdrl_2019}
Panagiota Kiourti, Kacper Wardega, Susmit Jha, and Wenchao Li.
\newblock Trojdrl: Evaluation of backdoor attacks on deep reinforcement
  learning.
\newblock In {\em Proceedings of the 57th ACM/EDAC/IEEE Design Automation
  Conference}, DAC '20. IEEE Press, 2020.

\bibitem{li2021neural}
Yige Li, Xixiang Lyu, Nodens Koren, Lingjuan Lyu, Bo~Li, and Xingjun Ma.
\newblock Neural attention distillation: Erasing backdoor triggers from deep
  neural networks.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{liu2018fine-pruning}
Kang Liu, Brendan Dolan-Gavitt, and Siddharth Garg.
\newblock Fine-pruning: Defending against backdooring attacks on deep neural
  networks.
\newblock In {\em Research in Attacks, Intrusions, and Defenses}, pages
  273--294, 2018.

\bibitem{10.1109/INFOCOM48880.2022.9796974}
Yang Liu, Mingyuan Fan, Cen Chen, Ximeng Liu, Zhuo Ma, Li~Wang, and Jianfeng
  Ma.
\newblock Backdoor defense with machine unlearning.
\newblock In {\em IEEE INFOCOM 2022 - IEEE Conference on Computer
  Communications}, page 280–289. IEEE Press, 2022.

\bibitem{Trojannn}
Yingqi Liu, Shiqing Ma, Yousra Aafer, Wen-Chuan Lee, Juan Zhai, Weihang Wang,
  and Xiangyu Zhang.
\newblock Trojaning attack on neural networks.
\newblock In {\em 25th Annual Network and Distributed System Security
  Symposium, {NDSS} 2018, San Diego, California, USA, February 18-221, 2018}.
  The Internet Society, 2018.

\bibitem{neural_trojans2017}
Yuntao Liu, Yang Xie, and Ankur Srivastava.
\newblock Neural trojans.
\newblock In {\em 2017 IEEE International Conference on Computer Design
  (ICCD)}, pages 45--48, 2017.

\bibitem{Saha_Subramanya_Pirsiavash_2020}
Aniruddha Saha, Akshayvarun Subramanya, and Hamed Pirsiavash.
\newblock Hidden trigger backdoor attacks.
\newblock {\em Proceedings of the AAAI Conference on Artificial Intelligence},
  34(07):11957--11965, Apr. 2020.

\bibitem{10.5555/3327144.3327299}
Kevin Scaman and Aladin Virmaux.
\newblock Lipschitz regularity of deep neural networks: Analysis and efficient
  estimation.
\newblock In {\em Proceedings of the 32nd International Conference on Neural
  Information Processing Systems}, NIPS'18, page 3839–3848, 2018.

\bibitem{https://doi.org/10.48550/arxiv.1707.06347}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock {\em arXiv preprint arXiv:1707.06347}, 2017.

\bibitem{NEURIPS2018_280cf18b}
Brandon Tran, Jerry Li, and Aleksander Madry.
\newblock Spectral signatures in backdoor attacks.
\newblock In S.~Bengio, H.~Wallach, H.~Larochelle, K.~Grauman, N.~Cesa-Bianchi,
  and R.~Garnett, editors, {\em Advances in Neural Information Processing
  Systems}, volume~31, 2018.

\bibitem{vershynin2018high}
Roman Vershynin.
\newblock {\em High-dimensional probability: An introduction with applications
  in data science}, volume~47.
\newblock Cambridge university press, 2018.

\bibitem{NeuralCleanse}
Bolun Wang, Yuanshun Yao, Shawn Shan, Huiying Li, Bimal Viswanath, Haitao
  Zheng, and Ben~Y. Zhao.
\newblock Neural cleanse: Identifying and mitigating backdoor attacks in neural
  networks.
\newblock In {\em 2019 IEEE Symposium on Security and Privacy (SP)}, pages
  707--723, 2019.

\bibitem{ijcai2021p509}
Lun Wang, Zaynah Javed, Xian Wu, Wenbo Guo, Xinyu Xing, and Dawn Song.
\newblock Backdoorl: Backdoor attack against competitive reinforcement
  learning.
\newblock In Zhi-Hua Zhou, editor, {\em Proceedings of the Thirtieth
  International Joint Conference on Artificial Intelligence, {IJCAI-21}}, pages
  3699--3705. International Joint Conferences on Artificial Intelligence
  Organization, 8 2021.
\newblock Main Track.

\bibitem{NIPS2014_375c7134}
Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson.
\newblock How transferable are features in deep neural networks?
\newblock In Z.~Ghahramani, M.~Welling, C.~Cortes, N.~Lawrence, and K.Q.
  Weinberger, editors, {\em Advances in Neural Information Processing Systems},
  volume~27, 2014.

\bibitem{10.1093/biomet/asv008}
Y.~Yu, T.~Wang, and R.~J. Samworth.
\newblock {A useful variant of the Davis–Kahan theorem for statisticians}.
\newblock {\em Biometrika}, 102(2):315--323, 04 2014.

\end{thebibliography}
