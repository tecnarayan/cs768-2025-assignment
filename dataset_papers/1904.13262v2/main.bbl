\begin{thebibliography}{26}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Advani and Saxe(2017)]{advani2017high}
M.~S. Advani and A.~M. Saxe.
\newblock High-dimensional dynamics of generalization error in neural networks.
\newblock \emph{arXiv preprint arXiv:1710.03667}, 2017.

\bibitem[Berglund(2001)]{berglund2001perturbation}
N.~Berglund.
\newblock Perturbation theory of dynamical systems.
\newblock \emph{arXiv preprint math/0111178}, 2001.

\bibitem[Coddington and Levinson(1955)]{coddington1955theory}
E.~A. Coddington and N.~Levinson.
\newblock \emph{Theory of Ordinary Differential Equations}.
\newblock Tata McGraw-Hill Education, 1955.

\bibitem[Combes et~al.(2018)Combes, Pezeshki, Shabanian, Courville, and
  Bengio]{combes2018learning}
R.~T.~d. Combes, M.~Pezeshki, S.~Shabanian, A.~Courville, and Y.~Bengio.
\newblock On the learning dynamics of deep neural networks.
\newblock \emph{arXiv preprint arXiv:1809.06848}, 2018.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
J.~Deng, W.~Dong, R.~Socher, L.-J. Li, K.~Li, and L.~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{CVPR}, 2009.

\bibitem[Gronwall(1919)]{gronwall1919note}
T.~H. Gronwall.
\newblock Note on the derivatives with respect to a parameter of the solutions
  of a system of differential equations.
\newblock \emph{Annals of Mathematics}, 1919.

\bibitem[Gunasekar et~al.(2017)Gunasekar, Woodworth, Bhojanapalli, Neyshabur,
  and Srebro]{gunasekar2017implicit}
S.~Gunasekar, B.~E. Woodworth, S.~Bhojanapalli, B.~Neyshabur, and N.~Srebro.
\newblock Implicit regularization in matrix factorization.
\newblock In \emph{NIPS}, 2017.

\bibitem[Gunasekar et~al.(2018)Gunasekar, Lee, Soudry, and
  Srebro]{gunasekar2018implicit}
S.~Gunasekar, J.~Lee, D.~Soudry, and N.~Srebro.
\newblock Implicit bias of gradient descent on linear convolutional networks.
\newblock \emph{arXiv preprint arXiv:1806.00468}, 2018.

\bibitem[Horn et~al.(1985)Horn, Horn, and Johnson]{horn1985matrix}
R.~A. Horn, R.~A. Horn, and C.~R. Johnson.
\newblock \emph{Matrix Analysis}.
\newblock Cambridge University Press, 1985.

\bibitem[Izenman(1975)]{izenman1975reduced}
A.~J. Izenman.
\newblock Reduced-rank regression for the multivariate linear model.
\newblock \emph{Journal of Multivariate Analysis}, 1975.

\bibitem[Krizhevsky et~al.(2014)Krizhevsky, Nair, and
  Hinton]{krizhevsky2014cifar}
A.~Krizhevsky, V.~Nair, and G.~Hinton.
\newblock The {CIFAR-10} dataset.
\newblock \emph{online: http://www. cs. toronto. edu/kriz/cifar. html}, 2014.

\bibitem[Lampinen and Ganguli(2019)]{lampinen2018an}
A.~K. Lampinen and S.~Ganguli.
\newblock An analytic theory of generalization dynamics and transfer learning
  in deep linear networks.
\newblock In \emph{ICLR}, 2019.

\bibitem[LeCun et~al.(2010)LeCun, Cortes, and Burges]{lecun2010mnist}
Y.~LeCun, C.~Cortes, and C.~Burges.
\newblock {MNIST} handwritten digit database.
\newblock \emph{AT\&T Labs [Online]. Available: http://yann. lecun.
  com/exdb/mnist}, 2010.

\bibitem[Li et~al.(2018)Li, Ma, and Zhang]{li2018algorithmic}
Y.~Li, T.~Ma, and H.~Zhang.
\newblock Algorithmic regularization in over-parameterized matrix sensing and
  neural networks with quadratic activations.
\newblock In \emph{Conference On Learning Theory}, pages 2--47, 2018.

\bibitem[Nar and Sastry(2018)]{nar2018step}
K.~Nar and S.~Sastry.
\newblock Step size matters in deep learning.
\newblock In \emph{NeurIPS}, 2018.

\bibitem[Neyshabur(2017)]{neyshabur2017implicit}
B.~Neyshabur.
\newblock \emph{Implicit Regularization in Deep Learning}.
\newblock PhD thesis, TTIC, 2017.

\bibitem[Neyshabur et~al.(2015{\natexlab{a}})Neyshabur, Salakhutdinov, and
  Srebro]{neyshabur2015path}
B.~Neyshabur, R.~R. Salakhutdinov, and N.~Srebro.
\newblock Path-{SGD}: Path-normalized optimization in deep neural networks.
\newblock In \emph{NIPS}, 2015{\natexlab{a}}.

\bibitem[Neyshabur et~al.(2015{\natexlab{b}})Neyshabur, Tomioka, and
  Srebro]{neyshabur2014search}
B.~Neyshabur, R.~Tomioka, and N.~Srebro.
\newblock In search of the real inductive bias: On the role of implicit
  regularization in deep learning.
\newblock In \emph{ICLR}, 2015{\natexlab{b}}.

\bibitem[Neyshabur et~al.(2017)Neyshabur, Tomioka, Salakhutdinov, and
  Srebro]{neyshabur2017geometry}
B.~Neyshabur, R.~Tomioka, R.~Salakhutdinov, and N.~Srebro.
\newblock Geometry of optimization and implicit regularization in deep
  learning.
\newblock \emph{arXiv preprint arXiv:1705.03071}, 2017.

\bibitem[Reinsel and Velu(1998)]{velu2013multivariate}
G.~C. Reinsel and R.~Velu.
\newblock \emph{Multivariate Reduced-Rank Regression: Theory and Applications}.
\newblock Springer Science \& Business Media, 1998.

\bibitem[Saxe et~al.(2013)Saxe, McClellans, and Ganguli]{saxe2013learning}
A.~M. Saxe, J.~L. McClellans, and S.~Ganguli.
\newblock Learning hierarchical categories in deep neural networks.
\newblock In \emph{Proceedings of the Annual Meeting of the Cognitive Science
  Society}, 2013.

\bibitem[Saxe et~al.(2014)Saxe, McClelland, and Ganguli]{saxe2014exact}
A.~M. Saxe, J.~L. McClelland, and S.~Ganguli.
\newblock Exact solutions to the nonlinear dynamics of learning in deep linear
  neural networks.
\newblock In \emph{ICLR}, 2014.

\bibitem[Saxe et~al.(2018)Saxe, McClelland, and Ganguli]{saxe2018mathematical}
A.~M. Saxe, J.~L. McClelland, and S.~Ganguli.
\newblock A mathematical theory of semantic development in deep neural
  networks.
\newblock \emph{arXiv preprint arXiv:1810.10531}, 2018.

\bibitem[Soudry et~al.(2018)Soudry, Hoffer, and Srebro]{soudry2017implicit}
D.~Soudry, E.~Hoffer, and N.~Srebro.
\newblock The implicit bias of gradient descent on separable data.
\newblock In \emph{ICLR}, 2018.

\bibitem[Uschmajew and Vandereycken(2018)]{uschmajew2018critical}
A.~Uschmajew and B.~Vandereycken.
\newblock On critical points of quadratic low-rank matrix optimization
  problems.
\newblock Tech. report (submitted), July 2018.

\bibitem[Zhang et~al.(2017)Zhang, Bengio, Hardt, Recht, and
  Vinyals]{zhang2017understanding}
C.~Zhang, S.~Bengio, M.~Hardt, B.~Recht, and O.~Vinyals.
\newblock Understanding deep learning requires rethinking generalization.
\newblock 2017.

\end{thebibliography}
