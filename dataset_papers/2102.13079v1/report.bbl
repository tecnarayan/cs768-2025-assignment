\begin{thebibliography}{62}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Achlioptas(2003)]{Article:Achlioptas_JCSS03}
Dimitris Achlioptas.
\newblock Database-friendly random projections: Johnson-lindenstrauss with
  binary coins.
\newblock \emph{J. Comput. Syst. Sci.}, 66\penalty0 (4):\penalty0 671--687,
  2003.

\bibitem[Affandi et~al.(2013)Affandi, Fox, and Taskar]{Proc:Affandi_NIPS13}
Raja~Hafiz Affandi, Emily~B. Fox, and Ben Taskar.
\newblock Approximate inference in continuous determinantal processes.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pages 1430--1438, Lake Tahoe, NV, 2013.

\bibitem[Alaoui and Mahoney(2015)]{Proc:Alaoui_NIPS15}
Ahmed~El Alaoui and Michael~W. Mahoney.
\newblock Fast randomized kernel ridge regression with statistical guarantees.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pages 775--783, Montreal, Canada, 2015.

\bibitem[Avron et~al.(2017)Avron, Kapralov, Musco, Musco, Velingker, and
  Zandieh]{Proc:Avron_ICML17}
Haim Avron, Michael Kapralov, Cameron Musco, Christopher Musco, Ameya
  Velingker, and Amir Zandieh.
\newblock Random fourier features for kernel ridge regression: Approximation
  bounds and statistical guarantees.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning (ICML)}, pages 253--262, Sydney, Australia, 2017.

\bibitem[Bach(2013)]{Proc:Bach_COLT13}
Francis~R. Bach.
\newblock Sharp analysis of low-rank kernel matrix approximations.
\newblock In \emph{Proceedings of the 26th Annual Conference on Learning Theory
  (COLT)}, pages 185--209, Princeton University, NJ, 2013.

\bibitem[Bingham and Mannila(2001)]{Proc:Bingham_KDD01}
Ella Bingham and Heikki Mannila.
\newblock Random projection in dimensionality reduction: Applications to image
  and text data.
\newblock In \emph{Proceedings of the Seventh {ACM} {SIGKDD} International
  Conference on Knowledge Discovery and Data Mining (KDD)}, pages 245--250, San
  Francisco, CA, 2001.

\bibitem[Borwein and Erd{\'e}lyi(1995)]{1995polynomials}
Peter Borwein and Tam{\'a}s Erd{\'e}lyi.
\newblock \emph{Polynomials and polynomial inequalities}, volume 161.
\newblock Springer Science \& Business Media, 1995.

\bibitem[Bottou et~al.(2007)Bottou, Chapelle, DeCoste, and
  Weston]{Book:Bottou_07}
L\'eon Bottou, Olivier Chapelle, Dennis DeCoste, and Jason Weston, editors.
\newblock \emph{Large-Scale Kernel Machines}.
\newblock The MIT Press, Cambridge, MA, 2007.

\bibitem[Buhler(2001)]{Article:Buher_01}
Jeremy Buhler.
\newblock Efficient large-scale sequence comparison by locality-sensitive
  hashing.
\newblock \emph{Bioinformatics}, 17\penalty0 (5):\penalty0 419--428, 2001.

\bibitem[Cand{\`{e}}s et~al.(2006)Cand{\`{e}}s, Romberg, and
  Tao]{Article:Candes_IT06}
Emmanuel~J. Cand{\`{e}}s, Justin~K. Romberg, and Terence Tao.
\newblock Robust uncertainty principles: exact signal reconstruction from
  highly incomplete frequency information.
\newblock \emph{{IEEE} Trans. Inf. Theory}, 52\penalty0 (2):\penalty0 489--509,
  2006.

\bibitem[Charikar(2002)]{Proc:Charikar_STOC02}
Moses~S. Charikar.
\newblock Similarity estimation techniques from rounding algorithms.
\newblock In \emph{Proceedings on 34th Annual {ACM} Symposium on Theory of
  Computing (STOC)}, pages 380--388, Montreal, Canada, 2002.

\bibitem[Chwialkowski et~al.(2015)Chwialkowski, Ramdas, Sejdinovic, and
  Gretton]{Chwialkowski_NIPS15}
Kacper Chwialkowski, Aaditya Ramdas, Dino Sejdinovic, and Arthur Gretton.
\newblock Fast two-sample testing with analytic representations of probability
  measures.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pages 1981--1989, Montreal, Canada, 2015.

\bibitem[Cortes et~al.(2010)Cortes, Mohri, and
  Talwalkar]{Proc:Cortes_AISTATS10}
Corinna Cortes, Mehryar Mohri, and Ameet Talwalkar.
\newblock On the impact of kernel approximation on learning accuracy.
\newblock In \emph{Proceedings of the Thirteenth International Conference on
  Artificial Intelligence and Statistics (AISTATS)}, pages 113--120, Chia
  Laguna Resort, Sardinia, Italy, 2010.

\bibitem[Dai et~al.(2014)Dai, Xie, He, Liang, Raj, Balcan, and
  Song]{Proc:Dai_NIPS14}
Bo~Dai, Bo~Xie, Niao He, Yingyu Liang, Anant Raj, Maria{-}Florina Balcan, and
  Le~Song.
\newblock Scalable kernel methods via doubly stochastic gradients.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pages 3041--3049, Montreal, Canada, 2014.

\bibitem[Dasgupta(2000)]{Proc:Dasgupta_UAI00}
Sanjoy Dasgupta.
\newblock Experiments with random projection.
\newblock In \emph{Proceedings of the 16th Conference in Uncertainty in
  Artificial Intelligence (UAI)}, pages 143--151, Stanford, CA, 2000.

\bibitem[Datar et~al.(2004)Datar, Immorlica, Indyk, and
  Mirrokn]{Proc:Datar_SCG04}
Mayur Datar, Nicole Immorlica, Piotr Indyk, and Vahab~S. Mirrokn.
\newblock Locality-sensitive hashing scheme based on p-stable distributions.
\newblock In \emph{Proceedings of the 20th {ACM} Symposium on Computational
  Geometr (SCG)}, pages 253 -- 262, Brooklyn, NY, 2004.

\bibitem[Donoho(2006)]{Article:Donoho_IT06}
David~L. Donoho.
\newblock Compressed sensing.
\newblock \emph{{IEEE} Trans. Inf. Theory}, 52\penalty0 (4):\penalty0
  1289--1306, 2006.

\bibitem[Dua and Graff(2017)]{UCI}
Dheeru Dua and Casey Graff.
\newblock {UCI} machine learning repository, 2017.
\newblock URL \url{http://archive.ics.uci.edu/ml}.

\bibitem[Fan et~al.(2008)Fan, Chang, Hsieh, Wang, and Lin]{Article:Fan_JMLR08}
Rong{-}En Fan, Kai{-}Wei Chang, Cho{-}Jui Hsieh, Xiang{-}Rui Wang, and
  Chih{-}Jen Lin.
\newblock {LIBLINEAR:} {A} library for large linear classification.
\newblock \emph{J. Mach. Learn. Res.}, 9:\penalty0 1871--1874, 2008.

\bibitem[Fern and Brodley(2003)]{Proc:Fern_ICML03}
Xiaoli~Zhang Fern and Carla~E. Brodley.
\newblock Random projection for high dimensional data clustering: A cluster
  ensemble approach.
\newblock In \emph{Proceedings of the Twentieth International Conference
  (ICML)}, pages 186--193, Washington, DC, 2003.

\bibitem[Freund et~al.(2007)Freund, Dasgupta, Kabra, and
  Verma]{Proc:Frund_NIPS07}
Yoav Freund, Sanjoy Dasgupta, Mayank Kabra, and Nakul Verma.
\newblock Learning the structure of manifolds using random projections.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pages 473--480, Vancouver, Canada, 2007.

\bibitem[Gittens and Mahoney(2013)]{Proc:Gitten_ICML13}
Alex Gittens and Michael~W. Mahoney.
\newblock Revisiting the nystr\"om method for improved large-scale machine
  learning.
\newblock In \emph{Proceedings of the 30th International Conference on Machine
  Learning (ICML)}, pages 567--575, Atlanta, GA, 2013.

\bibitem[Goemans and Williamson(1995)]{Article:Goemans_JACM95}
Michel~X. Goemans and David~P. Williamson.
\newblock Improved approximation algorithms for maximum cut and satisfiability
  problems using semidefinite programming.
\newblock \emph{Journal of ACM}, 42\penalty0 (6):\penalty0 1115--1145, 1995.

\bibitem[Hastie et~al.(2001)Hastie, Tibshirani, and
  Friedman]{Book:Hastie_Tib_Friedman}
Trevor~J. Hastie, Robert Tibshirani, and Jerome~H. Friedman.
\newblock \emph{The Elements of Statistical Learning:Data Mining, Inference,
  and Prediction}.
\newblock Springer, New York, NY, 2001.

\bibitem[Hern{\'{a}}ndez{-}Lobato et~al.(2014)Hern{\'{a}}ndez{-}Lobato,
  Hoffman, and Ghahramani]{Proc:Hern_NIPS14}
Jos{\'{e}}~Miguel Hern{\'{a}}ndez{-}Lobato, Matthew~W. Hoffman, and Zoubin
  Ghahramani.
\newblock Predictive entropy search for efficient global optimization of
  black-box functions.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pages 918--926, Montreal, Canada, 2014.

\bibitem[Hsieh et~al.(2014)Hsieh, Si, and Dhillon]{Proc:Hsieh_NIPS14}
Cho{-}Jui Hsieh, Si~Si, and Inderjit~S. Dhillon.
\newblock Fast prediction for large-scale kernel machines.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pages 3689--3697, Montreal, Canada, 2014.

\bibitem[Indyk and Motwani(1998)]{Proc:Indyk_Motwani_STOC98}
Piotr Indyk and Rajeev Motwani.
\newblock Approximate nearest neighbors: Towards removing the curse of
  dimensionality.
\newblock In \emph{Proceedings of the Thirtieth Annual {ACM} Symposium on the
  Theory of Computing (STOC)}, pages 604--613, Dallas, TX, 1998.

\bibitem[Jacques et~al.(2013)Jacques, Laska, Boufounos, and
  Baraniuk]{Article:Jacques_JIT13}
Laurent Jacques, Jason~N. Laska, Petros~T. Boufounos, and Richard~G. Baraniuk.
\newblock Robust 1-bit compressive sensing via binary stable embeddings of
  sparse vectors.
\newblock \emph{IEEE Transactions on Information Theory}, 59\penalty0
  (4):\penalty0 2082--2102, 2013.

\bibitem[Joachims(2006)]{Proc:Joachims_KDD06}
Thorsten Joachims.
\newblock Training linear svms in linear time.
\newblock In \emph{Proceedings of the Twelfth {ACM} {SIGKDD} International
  Conference on Knowledge Discovery and Data Mining (KDD)}, pages 217--226,
  Philadelphia, PA, 2006.

\bibitem[Johnson and Lindenstrauss(1984)]{Article:JL84}
William~B. Johnson and Joram Lindenstrauss.
\newblock Extensions of \text{Lipschitz} mapping into \text{Hilbert} space.
\newblock \emph{Contemporary Mathematics}, 26:\penalty0 189--206, 1984.

\bibitem[Leng et~al.(2014)Leng, Cheng, and Lu]{Proc:Leng_SIGIR14}
Cong Leng, Jian Cheng, and Hanqing Lu.
\newblock Random subspace for binary codes learning in large scale image
  retrieval.
\newblock In \emph{Proceedings of the 37th International {ACM} {SIGIR}
  Conference on Research and Development in Information Retrieval (SIGIR)},
  pages 1031--1034, Gold Coast, Australia, 2014.

\bibitem[Li et~al.(2016)Li, Cheng, Wang, Morstatter, Robert, Tang, and
  Liu]{ASU}
Jundong Li, Kewei Cheng, Suhang Wang, Fred Morstatter, Trevino Robert, Jiliang
  Tang, and Huan Liu.
\newblock Feature selection: A data perspective.
\newblock \emph{arXiv:1601.07996}, 2016.

\bibitem[Li(2007)]{Proc:Li_KDD07}
Ping Li.
\newblock Very sparse stable random projections for dimension reduction in
  $l_\alpha$ {($0<\alpha\leq2$) norm}.
\newblock In \emph{Proceedings of the 13th {ACM} {SIGKDD} International
  Conference on Knowledge Discovery and Data Mining (KDD)}, pages 440--449, San
  Jose, CA, 2007.

\bibitem[Li(2017{\natexlab{a}})]{Proc:Li_AISTATS17}
Ping Li.
\newblock Binary and multi-bit coding for stable random projections.
\newblock In \emph{Proceedings of the 20th International Conference on
  Artificial Intelligence and Statistics (AISTATS)}, pages 1430--1438, Fort
  Lauderdale, FL, 2017{\natexlab{a}}.

\bibitem[Li(2017{\natexlab{b}})]{Proc:Li_KDD17}
Ping Li.
\newblock Linearized {GMM} kernels and normalized random {Fourier} features.
\newblock In \emph{Proceedings of the 23rd {ACM} {SIGKDD} International
  Conference on Knowledge Discovery and Data Mining (KDD)}, pages 315--324,
  2017{\natexlab{b}}.

\bibitem[Li and Slawski(2017)]{Proc:Li_NIPS17}
Ping Li and Martin Slawski.
\newblock Simple strategies for recovering inner products from coarsely
  quantized random projections.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pages 4567--4576, Long Beach, CA, 2017.

\bibitem[Li et~al.(2006)Li, Hastie, and Church]{Proc:Li_Hastie_Church_COLT06}
Ping Li, Trevor~J. Hastie, and Kenneth~W. Church.
\newblock Improving random projections using marginal information.
\newblock In \emph{Proceedings of the 19th Annual Conference on Learning Theory
  (COLT)}, pages 635--649, Pittsburgh, PA, 2006.

\bibitem[Li et~al.(2013)Li, Samorodnitsky, and Hopcroft]{Proc:Li_NIPS13}
Ping Li, Gennady Samorodnitsky, and John~E. Hopcroft.
\newblock Sign cauchy projections and chi-square kernel.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pages 2571--2579, Lake Tahoe, NV, 2013.

\bibitem[Li et~al.(2014)Li, Mitzenmacher, and Shrivastava]{Proc:Li_ICML14}
Ping Li, Michael Mitzenmacher, and Anshumali Shrivastava.
\newblock Coding for random projections.
\newblock In \emph{Proceedings of the 31th International Conference on Machine
  Learning (ICML)}, pages 676--684, Beijing, China, 2014.

\bibitem[Li and Li(2019{\natexlab{a}})]{Proc:Li_NIPS19}
Xiaoyun Li and Ping Li.
\newblock Generalization error analysis of quantized compressive learning.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, Vancouver, Canada, 2019{\natexlab{a}}.

\bibitem[Li and Li(2019{\natexlab{b}})]{Proc:Li_NeurIPS19_asymmetric}
Xiaoyun Li and Ping Li.
\newblock Random projections with asymmetric quantization.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, Vancouver, Canada, 2019{\natexlab{b}}.

\bibitem[Li et~al.(2020)Li, Gui, and Li]{Proc:Li_ECAI20}
Xiaoyun Li, Jie Gui, and Ping Li.
\newblock Randomized kernel multi-view discriminant analysis.
\newblock In \emph{Proceedings of the 24th European Conference on Artificial
  Intelligence (ECAI)}, pages 1276--1284, Santiago de Compostela, Spain, 2020.

\bibitem[Lloyd(1982)]{Article:Lloyd_JIT82}
Stuart~P. Lloyd.
\newblock Least squares quantization in {PCM}.
\newblock \emph{{IEEE} Trans. Information Theory}, 28\penalty0 (2):\penalty0
  129--136, 1982.

\bibitem[Max(1960)]{Article:Max60}
Joel Max.
\newblock Quantizing for minimum distortion.
\newblock \emph{{IRE} Trans. Information Theory}, 6\penalty0 (1):\penalty0
  7--12, 1960.

\bibitem[Platt(1998)]{Proc:Platt_NIPS98}
John~C. Platt.
\newblock Using analytic \text{QP} and sparseness to speed training of support
  vector machines.
\newblock In \emph{NIPS}, pages 557--563, Vancouver, BC, Canada, 1998.

\bibitem[Raginsky and Lazebnik(2009)]{Proc:Raginsky_NIPS09}
Maxim Raginsky and Svetlana Lazebnik.
\newblock Locality-sensitive binary codes from shift-invariant kernels.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pages 1509--1517, Vancouver, Canada, 2009.

\bibitem[Rahimi and Recht(2007)]{Proc:Rahimi_NIPS07}
Ali Rahimi and Benjamin Recht.
\newblock Random features for large-scale kernel machines.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pages 1177--1184, Vancouver, Canada, 2007.

\bibitem[Richard et~al.(2015)Richard, Goetz, and Chichilnisky]{Richard_NIPS15}
Emile Richard, Georges Goetz, and E.~J. Chichilnisky.
\newblock Recognizing retinal ganglion cells in the dark.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pages 2476--2484, Montreal, Canada, 2015.

\bibitem[Rudin(1990)]{Book:Rudin_90}
Walter Rudin.
\newblock \emph{Fourier Analysis on Groups}.
\newblock John Wiley \& Sons, New York, NY, 1990.

\bibitem[Sch\"olkopf and Smola(2002)]{Book:Scholkopf_02}
Bernhard Sch\"olkopf and Alexander~J. Smola.
\newblock \emph{Learning with Kernels}.
\newblock The MIT Press, Cambridge, MA, 2002.

\bibitem[Shah and Ghahramani(2015)]{Proc:Shah_NIPS15}
Amar Shah and Zoubin Ghahramani.
\newblock Parallel predictive entropy search for batch global optimization of
  expensive objective functions.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pages 3330--3338, Montreal, Canada, 2015.

\bibitem[Shalev{-}Shwartz et~al.(2011)Shalev{-}Shwartz, Singer, Srebro, and
  Cotter]{Article:Shalev-Shwartz_MP11}
Shai Shalev{-}Shwartz, Yoram Singer, Nathan Srebro, and Andrew Cotter.
\newblock Pegasos: primal estimated sub-gradient solver for {SVM}.
\newblock \emph{Math. Program.}, 127\penalty0 (1):\penalty0 3--30, 2011.

\bibitem[Slawski and Li(2018)]{Article:Slawski_IT18}
Martin Slawski and Ping Li.
\newblock On the trade-off between bit depth and number of samples for a basic
  approach to structured signal recovery from b-bit quantized linear
  measurements.
\newblock \emph{{IEEE} Trans. Inf. Theory}, 64\penalty0 (6):\penalty0
  4159--4178, 2018.

\bibitem[Sun et~al.(2018)Sun, Gilbert, and Tewari]{Proc:Sun_NeurIPS18}
Yitong Sun, Anna~C. Gilbert, and Ambuj Tewari.
\newblock But how does it work in theory? linear {SVM} with random features.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, pages 3383--3392, Montr{\'{e}}al, Canada, 2018.

\bibitem[Sutherland and Schneider(2015)]{Proc:Sutherland_UAI15}
Danica~J. Sutherland and Jeff~G. Schneider.
\newblock On the error of random fourier features.
\newblock In \emph{Proceedings of the Thirty-First Conference on Uncertainty in
  Artificial Intelligence (UAI)}, pages 862--871, Amsterdam, The Netherlands,
  2015.

\bibitem[Tompkins and Ramos(2018)]{Proc:Tompkins_aaai18}
Anthony Tompkins and Fabio Ramos.
\newblock Fourier feature approximations for periodic kernels in time-series
  modelling.
\newblock In \emph{Proceedings of the Thirty-Second {AAAI} Conference on
  Artificial Intelligence (AAAI)}, pages 4155--4162, New Orleans, LA, 2018.

\bibitem[Widrow and Koll{\'a}r(2008)]{Book:Widrow_2008}
Bernard Widrow and Istv{\'a}n Koll{\'a}r.
\newblock Quantization noise.
\newblock \emph{Cambridge University Press}, 2008.

\bibitem[Wu(1992)]{Article:Wu_IT92}
Xiaolin Wu.
\newblock On convergence of lloyd's method {I}.
\newblock \emph{{IEEE} Trans. Inf. Theory}, 38\penalty0 (1):\penalty0 171--174,
  1992.

\bibitem[Yang et~al.(2012)Yang, Li, Mahdavi, Jin, and Zhou]{Proc:Yang_NIPS12}
Tianbao Yang, Yu{-}Feng Li, Mehrdad Mahdavi, Rong Jin, and Zhi{-}Hua Zhou.
\newblock Nystr{\"{o}}m method vs random fourier features: {A} theoretical and
  empirical comparison.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pages 485--493, Lake Tahoe, NV, 2012.

\bibitem[Yen et~al.(2014)Yen, Lin, Lin, Ravikumar, and
  Dhillon]{Proc:Yen_NIPS14}
Ian~En{-}Hsu Yen, Ting{-}Wei Lin, Shou{-}De Lin, Pradeep Ravikumar, and
  Inderjit~S. Dhillon.
\newblock Sparse random feature algorithm as coordinate descent in hilbert
  space.
\newblock In \emph{Advances in Neural Information Processing Systems (NIPS)},
  pages 2456--2464, Montreal, Canada, 2014.

\bibitem[Zhang et~al.(2019)Zhang, May, Dao, and R{\'{e}}]{Proc:Zhang_AISTATS19}
Jian Zhang, Avner May, Tri Dao, and Christopher R{\'{e}}.
\newblock Low-precision random fourier features for memory-constrained kernel
  approximation.
\newblock In \emph{Proceedings of the 22nd International Conference on
  Artificial Intelligence and Statistics (AISTATS)}, pages 1264--1274, Naha,
  Okinawa, Japan, 2019.

\bibitem[Zymnis et~al.(2010)Zymnis, Boyd, and
  Cand{\`{e}}s]{Article:zymnis_SPL10}
Argyrios Zymnis, Stephen~P. Boyd, and Emmanuel~J. Cand{\`{e}}s.
\newblock Compressed sensing with quantized measurements.
\newblock \emph{{IEEE} Signal Process. Lett.}, 17\penalty0 (2):\penalty0
  149--152, 2010.

\end{thebibliography}
