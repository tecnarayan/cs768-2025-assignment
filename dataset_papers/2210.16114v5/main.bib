@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}
@Article{simplex,
  Title                    = {A simplex method for function minimization},
  Author                   = {John A. Nelder and Roger Mead},
  Journal                  = {Computer Journal},
  Year                     = {1965},
  Pages                    = {308--313},
  Volume                   = {7}
}


@inproceedings{DBLP:conf/kbse/GopinathCPT19,
  author    = {Divya Gopinath and
               Hayes Converse and
               Corina S. Pasareanu and
               Ankur Taly},
  title     = {Property Inference for Deep Neural Networks},
  booktitle = {34th {IEEE/ACM} International Conference on Automated Software Engineering,
               {ASE} 2019, San Diego, CA, USA, November 11-15, 2019},
  pages     = {797--809},
  publisher = {{IEEE}},
  year      = {2019},
  url       = {https://doi.org/10.1109/ASE.2019.00079},
  doi       = {10.1109/ASE.2019.00079},
  timestamp = {Sun, 19 Jan 2020 15:19:48 +0100},
  biburl    = {https://dblp.org/rec/conf/kbse/GopinathCPT19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{LR2,
  author    = {Boris Hanin and
               David Rolnick},
  title     = {Deep ReLU Networks Have Surprisingly Few Activation Patterns},
  booktitle = {NeurIPS},
  pages     = {359--368},
  year      = {2019}
}



@inproceedings{LR1,
  author    = {Boris Hanin and
               David Rolnick},
  title     = {Complexity of Linear Regions in Deep Networks},
  booktitle = {{ICML}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {97},
  pages     = {2596--2604},
  publisher = {{PMLR}},
  year      = {2019}
}




@article{nap2,
Author = {Wang, Longwei and Wang, Chengfei and Li, Yupeng Li and Wang, Rui},
Title = {Explaining the Behavior of Neuron Activations in Deep Neural Networks},
Journal = {Ad Hoc Networks},
Volumn = {111},
Year = {2021},
url = {https://doi.org/10.1016/j.adhoc.2020.102346.},
Abstract = {Deep Neural Networks has shown superior performance in various applications. But it is often seen as black box in real world applications, which is challenging to explain from the viewpoint of humans. It is important to understand the behavior of deep neural networks so as to trust the decision made and improve the classification accuracy of deep neural networks. In this study, the information theoretical analysis is used to investigate the behavior of layer-wise neurons in deep neural networks. The activation patterns of individual neurons in fully connected layers can provide insights for the performance of the neural network model. The behavior of neuron activation is investigated based on state-of-art classification network model. We study and compare the layer-wise pattern of neurons activation in fully connected layers given the same image input. Experiments are conducted on various data sets. We find that in a well trained classification model, the randomness level of the neurons activation pattern is reduced with the depth of the fully connected layers. This means that the neuron activation patterns of deep layers is more stable than that of shallow layers. The results in this study can also answer the question of how many layers are needed to avoid overfitting in deep neural networks. Corresponding experiments are conducted to validate the assumptions.}
}


@article{grad_cam,
  author    = {Ramprasaath R. Selvaraju and
               Abhishek Das and
               Ramakrishna Vedantam and
               Michael Cogswell and
               Devi Parikh and
               Dhruv Batra},
  title     = {Grad-CAM: Why did you say that? Visual Explanations from Deep Networks
               via Gradient-based Localization},
  journal   = {CoRR},
  volume    = {abs/1610.02391},
  year      = {2016},
  url       = {http://arxiv.org/abs/1610.02391},
  eprinttype = {arXiv},
  eprint    = {1610.02391},
  timestamp = {Mon, 13 Aug 2018 16:46:58 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SelvarajuDVCPB16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
a service of  Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchabout

@inproceedings{Erhan2009VisualizingHF,
  title={Visualizing Higher-Layer Features of a Deep Network},
  author={D. Erhan and Yoshua Bengio and Aaron C. Courville and Pascal Vincent},
  year={2009}
}

@article{diffusion,
  author    = {Jonathan Ho and
               Ajay Jain and
               Pieter Abbeel},
  title     = {Denoising Diffusion Probabilistic Models},
  journal   = {CoRR},
  volume    = {abs/2006.11239},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.11239},
  eprinttype = {arXiv},
  eprint    = {2006.11239},
  timestamp = {Tue, 23 Jun 2020 17:57:22 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-11239.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{vis_network,
  doi = {10.48550/ARXIV.1506.06579},
  
  url = {https://arxiv.org/abs/1506.06579},
  
  author = {Yosinski, Jason and Clune, Jeff and Nguyen, Anh and Fuchs, Thomas and Lipson, Hod},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Understanding Neural Networks Through Deep Visualization},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {Creative Commons Attribution Non Commercial Share Alike 3.0 Unported}
}

@book{10.5555/2821082,
author = {Cox, David A. and Little, John and O’Shea, Donal},
title = {Ideals, Varieties, and Algorithms: An Introduction to Computational Algebraic Geometry and Commutative Algebra},
year = {2015},
isbn = {3319167200},
publisher = {Springer Publishing Company, Incorporated},
edition = {4th}
}
@book{10.5555/2512973,
author = {Gathen, Joachim von zur and Gerhard, Jrgen},
title = {Modern Computer Algebra},
year = {2013},
isbn = {1107039037},
publisher = {Cambridge University Press},
address = {USA},
edition = {3rd}
}

@inproceedings{textcnn,
    title = "Convolutional Neural Networks for Sentence Classification",
    author = "Kim, Yoon",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D14-1181",
    doi = "10.3115/v1/D14-1181",
    pages = "1746--1751",
}

@inproceedings{sanity4saliency,
author = {Adebayo, Julius and Gilmer, Justin and Muelly, Michael and Goodfellow, Ian and Hardt, Moritz and Kim, Been},
title = {Sanity Checks for Saliency Maps},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Saliency methods have emerged as a popular tool to highlight features in an input deemed relevant for the prediction of a learned model. Several saliency methods have been proposed, often guided by visual appeal on image data. In this work, we propose an actionable methodology to evaluate what kinds of explanations a given method can and cannot provide. We find that reliance, solely, on visual assessment can be misleading. Through extensive experiments we show that some existing saliency methods are independent both of the model and of the data generating process. Consequently, methods that fail the proposed tests are inadequate for tasks that are sensitive to either data or model, such as, finding outliers in the data, explaining the relationship between inputs and outputs that the model learned, and debugging the model. We interpret our findings through an analogy with edge detection in images, a technique that requires neither training data nor model. Theory in the case of a linear model and a single-layer convolutional neural network supports our experimental findings.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {9525–9536},
numpages = {12},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}
@book{IML,
  title      = {Interpretable Machine Learning},
  author     = {Christoph Molnar},
  year       = {2022},
  subtitle   = {A Guide for Making Black Box Models Explainable},
  edition    = {2},
  url        = {https://christophm.github.io/interpretable-ml-book}
}



@article{tanh,
  author    = {Chigozie Nwankpa and
               Winifred Ijomah and
               Anthony Gachagan and
               Stephen Marshall},
  title     = {Activation Functions: Comparison of trends in Practice and Research
               for Deep Learning},
  journal   = {CoRR},
  volume    = {abs/1811.03378},
  year      = {2018}
}

@misc{lipton,
  doi = {10.48550/ARXIV.1606.03490},
  
  url = {https://arxiv.org/abs/1606.03490},
  
  author = {Lipton, Zachary C.},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), Neural and Evolutionary Computing (cs.NE), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {The Mythos of Model Interpretability},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@InProceedings{reluplex,
author="Katz, Guy
and Barrett, Clark
and Dill, David L.
and Julian, Kyle
and Kochenderfer, Mykel J.",
editor="Majumdar, Rupak
and Kun{\v{c}}ak, Viktor",
title="Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks",
booktitle="Computer Aided Verification",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="97--117",
abstract="Deep neural networks have emerged as a widely used and effective means for tackling complex, real-world problems. However, a major obstacle in applying them to safety-critical systems is the great difficulty in providing formal guarantees about their behavior. We present a novel, scalable, and efficient technique for verifying properties of deep neural networks (or providing counter-examples). The technique is based on the simplex method, extended to handle the non-convex Rectified Linear Unit (ReLU) activation function, which is a crucial ingredient in many modern neural networks. The verification procedure tackles neural networks as a whole, without making any simplifying assumptions. We evaluated our technique on a prototype deep neural network implementation of the next-generation airborne collision avoidance system for unmanned aircraft (ACAS Xu). Results show that our technique can successfully prove properties of networks that are an order of magnitude larger than the largest networks verified using existing methods.",
isbn="978-3-319-63387-9"
}


@misc{pointwise_robustness,
  doi = {10.48550/ARXIV.1605.07262},
  
  url = {https://arxiv.org/abs/1605.07262},
  
  author = {Bastani, Osbert and Ioannou, Yani and Lampropoulos, Leonidas and Vytiniotis, Dimitrios and Nori, Aditya and Criminisi, Antonio},
  
  keywords = {Machine Learning (cs.LG), Computer Vision and Pattern Recognition (cs.CV), Neural and Evolutionary Computing (cs.NE), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Measuring Neural Net Robustness with Constraints},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@InProceedings{z3,
author="de Moura, Leonardo
and Bj{\o}rner, Nikolaj",
editor="Ramakrishnan, C. R.
and Rehof, Jakob",
title="Z3: An Efficient SMT Solver",
booktitle="Tools and Algorithms for the Construction and Analysis of Systems",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="337--340",
abstract="Satisfiability Modulo Theories (SMT) problem is a decision problem for logical first order formulas with respect to combinations of background theories such as: arithmetic, bit-vectors, arrays, and uninterpreted functions. Z3 is a new and efficient SMT Solver freely available from Microsoft Research. It is used in various software verification and analysis applications.",
isbn="978-3-540-78800-3"
}
@article{rice_theorem,
 ISSN = {00029947},
 URL = {http://www.jstor.org/stable/1990888},
 author = {H. G. Rice},
 journal = {Transactions of the American Mathematical Society},
 number = {2},
 pages = {358--366},
 publisher = {American Mathematical Society},
 title = {Classes of Recursively Enumerable Sets and Their Decision Problems},
 urldate = {2022-09-26},
 volume = {74},
 year = {1953}
}

@book{molnar2022,
  title      = {Interpretable Machine Learning},
  author     = {Christoph Molnar},
  year       = {2022},
  subtitle   = {A Guide for Making Black Box Models Explainable},
  edition    = {2},
  url        = {https://christophm.github.io/interpretable-ml-book}
}

@inproceedings{saliency_map,
  author    = {Karen Simonyan and
               Andrea Vedaldi and
               Andrew Zisserman},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Deep Inside Convolutional Networks: Visualising Image Classification
               Models and Saliency Maps},
  booktitle = {2nd International Conference on Learning Representations, {ICLR} 2014,
               Banff, AB, Canada, April 14-16, 2014, Workshop Track Proceedings},
  year      = {2014},
  url       = {http://arxiv.org/abs/1312.6034},
  timestamp = {Thu, 25 Jul 2019 14:36:46 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SimonyanVZ13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{fgsm,
  doi = {10.48550/ARXIV.1412.6572},
  
  url = {https://arxiv.org/abs/1412.6572},
  
  author = {Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian},
  
  keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Explaining and Harnessing Adversarial Examples},
  
  publisher = {arXiv},
  
  year = {2014},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


 @misc{vnncomp2021, year = {2021},
 title={VNNCOMP},
 author={VNNCOMP},
 url={https://sites.google.com/view/vnn2021}, journal={2nd International Verification of Neural Networks Competition 2021}} 

@inproceedings{lime,
  author    = {Marco Tulio Ribeiro and
               Sameer Singh and
               Carlos Guestrin},
  title     = {"Why Should {I} Trust You?": Explaining the Predictions of Any Classifier},
  booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} International Conference on
               Knowledge Discovery and Data Mining, San Francisco, CA, USA, August
               13-17, 2016},
  pages     = {1135--1144},
  year      = {2016},
}

@inproceedings{nnv,
author = {Tran, Hoang-Dung and Pal, Neelanjana and Musau, Patrick and Lopez, Diego Manzanas and Hamilton, Nathaniel and Yang, Xiaodong and Bak, Stanley and Johnson, Taylor T.},
title = {Robustness Verification of Semantic Segmentation Neural Networks Using Relaxed Reachability},
year = {2021},
isbn = {978-3-030-81684-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-030-81685-8_12},
doi = {10.1007/978-3-030-81685-8_12},
abstract = {This paper introduces robustness verification for semantic segmentation neural networks (in short, semantic segmentation networks [SSNs]), building on and extending recent approaches for robustness verification of image classification neural networks. Despite recent progress in developing verification methods for specifications such as local adversarial robustness in deep neural networks (DNNs) in terms of scalability, precision, and applicability to different network architectures, layers, and activation functions, robustness verification of semantic segmentation has not yet been considered. We address this limitation by developing and applying new robustness analysis methods for several segmentation neural network architectures, specifically by addressing reachability analysis of up-sampling layers, such as transposed convolution and dilated convolution. We consider several definitions of robustness for segmentation, such as the percentage of pixels in the output that can be proven robust under different adversarial perturbations, and a robust variant of intersection-over-union (IoU), the typical performance evaluation measure for segmentation tasks. Our approach is based on a new relaxed reachability method, allowing users to select the percentage of a number of linear programming problems (LPs) to solve when constructing the reachable set, through a relaxation factor percentage. The approach is implemented within NNV, then applied and evaluated on segmentation datasets, such as a multi-digit variant of MNIST known as M2NIST. Thorough experiments show that by using transposed convolution for up-sampling and average-pooling for down-sampling, combined with minimizing the number of ReLU layers in the SSNs, we can obtain SSNs with not only high accuracy (IoU), but also that are more robust to adversarial attacks and amenable to verification. Additionally, using our new relaxed reachability method, we can significantly reduce the verification time for neural networks whose ReLU layers dominate the total analysis time, even in classification tasks.},
booktitle = {Computer Aided Verification: 33rd International Conference, CAV 2021, Virtual Event, July 20–23, 2021, Proceedings, Part I},
pages = {263–286},
numpages = {24}
}

@article{deeppoly,
author = {Singh, Gagandeep and Gehr, Timon and P\"{u}schel, Markus and Vechev, Martin},
title = {An Abstract Domain for Certifying Neural Networks},
year = {2019},
issue_date = {January 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {POPL},
url = {https://doi.org/10.1145/3290354},
doi = {10.1145/3290354},
abstract = {We present a novel method for scalable and precise certification of deep neural networks. The key technical insight behind our approach is a new abstract domain which combines floating point polyhedra with intervals and is equipped with abstract transformers specifically tailored to the setting of neural networks. Concretely, we introduce new transformers for affine transforms, the rectified linear unit (ReLU), sigmoid, tanh, and maxpool functions. We implemented our method in a system called DeepPoly and evaluated it extensively on a range of datasets, neural architectures (including defended networks), and specifications. Our experimental results indicate that DeepPoly is more precise than prior work while scaling to large networks. We also show how to combine DeepPoly with a form of abstraction refinement based on trace partitioning. This enables us to prove, for the first time, the robustness of the network when the input image is subjected to complex perturbations such as rotations that employ linear interpolation.},
journal = {Proc. ACM Program. Lang.},
month = {jan},
articleno = {41},
numpages = {30},
keywords = {Deep Learning, Adversarial attacks, Abstract Interpretation}
}


@inproceedings{cvc5,
  author    = {Haniel Barbosa and
               Clark W. Barrett and
               Martin Brain and
               Gereon Kremer and
               Hanna Lachnitt and
               Makai Mann and
               Abdalrhman Mohamed and
               Mudathir Mohamed and
               Aina Niemetz and
               Andres N{\"{o}}tzli and
               Alex Ozdemir and
               Mathias Preiner and
               Andrew Reynolds and
               Ying Sheng and
               Cesare Tinelli and
               Yoni Zohar},
  editor    = {Dana Fisman and
               Grigore Rosu},
  title     = {cvc5: {A} Versatile and Industrial-Strength {SMT} Solver},
  booktitle = {Tools and Algorithms for the Construction and Analysis of Systems
               - 28th International Conference, {TACAS} 2022, Held as Part of the
               European Joint Conferences on Theory and Practice of Software, {ETAPS}
               2022, Munich, Germany, April 2-7, 2022, Proceedings, Part {I}},
  series    = {Lecture Notes in Computer Science},
  volume    = {13243},
  pages     = {415--442},
  publisher = {Springer},
  year      = {2022},
  url       = {https://doi.org/10.1007/978-3-030-99524-9\_24},
  doi       = {10.1007/978-3-030-99524-9\_24},
  timestamp = {Fri, 01 Apr 2022 15:49:27 +0200},
  biburl    = {https://dblp.org/rec/conf/tacas/BarbosaBBKLMMMN22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
}

@article{abc,
  title={{Beta-CROWN}: Efficient bound propagation with per-neuron split constraints for complete and incomplete neural network verification},
  author={Wang, Shiqi and Zhang, Huan and Xu, Kaidi and Lin, Xue and Jana, Suman and Hsieh, Cho-Jui and Kolter, J Zico},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@book{10.5555/134463,
author = {Geddes, Keith O. and Czapor, Stephen R. and Labahn, George},
title = {Algorithms for Computer Algebra},
year = {1992},
isbn = {0792392590},
publisher = {Kluwer Academic Publishers},
address = {USA}
}
@online{bernd,
author = {Bernd Sturmfels},
title = {Introduction to Grobner Bases},
url = {https://www.youtube.com/watch?v=TNO5WuxuNak&t=263s},
organization = {Youtube},
}

@article{Xu2020AdversarialAA,
  title={Adversarial Attacks and Defenses in Images, Graphs and Text: A Review},
  author={Han Xu and Yao Ma and Haochen Liu and Debayan Deb and Hui Liu and Jiliang Tang and Anil K. Jain},
  journal={International Journal of Automation and Computing},
  year={2020},
  volume={17},
  pages={151-178}
}

@inproceedings{Dalvi,
author = {Dalvi, Nilesh and Domingos, Pedro and Mausam and Sanghai, Sumit and Verma, Deepak},
title = {Adversarial Classification},
year = {2004},
isbn = {1581138881},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1014052.1014066},
doi = {10.1145/1014052.1014066},
abstract = {Essentially all data mining algorithms assume that the data-generating process is independent of the data miner's activities. However, in many domains, including spam detection, intrusion detection, fraud detection, surveillance and counter-terrorism, this is far from the case: the data is actively manipulated by an adversary seeking to make the classifier produce false negatives. In these domains, the performance of a classifier can degrade rapidly after it is deployed, as the adversary learns to defeat it. Currently the only solution to this is repeated, manual, ad hoc reconstruction of the classifier. In this paper we develop a formal framework and algorithms for this problem. We view classification as a game between the classifier and the adversary, and produce a classifier that is optimal given the adversary's optimal strategy. Experiments in a spam detection domain show that this approach can greatly outperform a classifier learned in the standard way, and (within the parameters of the problem) automatically adapt the classifier to the adversary's evolving manipulations.},
booktitle = {Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {99–108},
numpages = {10},
keywords = {integer linear programming, naive Bayes, cost-sensitive learning, game theory, spam detection},
location = {Seattle, WA, USA},
series = {KDD '04}
}

@inproceedings{Szegedy,
title	= {Intriguing properties of neural networks},
author	= {Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and Dumitru Erhan and Ian Goodfellow and Rob Fergus},
year	= {2014},
URL	= {http://arxiv.org/abs/1312.6199},
booktitle	= {International Conference on Learning Representations}
}



@misc{MetzenDetectingAA,
  doi = {10.48550/ARXIV.1702.04267},
  
  url = {https://arxiv.org/abs/1702.04267},
  
  author = {Metzen, Jan Hendrik and Genewein, Tim and Fischer, Volker and Bischoff, Bastian},
  
  keywords = {Machine Learning (stat.ML), Artificial Intelligence (cs.AI), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {On Detecting Adversarial Perturbations},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inbook{Carlini17Detection,
author = {Carlini, Nicholas and Wagner, David},
title = {Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods},
year = {2017},
isbn = {9781450352024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3128572.3140444},
abstract = {Neural networks are known to be vulnerable to adversarial examples: inputs that are close to natural inputs but classified incorrectly. In order to better understand the space of adversarial examples, we survey ten recent proposals that are designed for detection and compare their efficacy. We show that all can be defeated by constructing new loss functions. We conclude that adversarial examples are significantly harder to detect than previously appreciated, and the properties believed to be intrinsic to adversarial examples are in fact not. Finally, we propose several simple guidelines for evaluating future proposed defenses.},
booktitle = {Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security},
pages = {3–14},
numpages = {12}
}
@manual{aflquick,
author = {Max Moroz},
title = {AFL Quick Start Guide},
url = {https://github.com/google/AFL/blob/master/docs/QuickStartGuide.txt},
organization = {Google},
}

@manual{aflwhitepaper,
author = {Michal Zalewski},
title = {AFL Whitepaper},
url = {https://lcamtuf.coredump.cx/afl/technical_details.txt},
organization = {Google},
}
@manual{aflwhitepaper,
author = {Michal Zalewski},
title = {AFL Whitepaper},
url = {https://lcamtuf.coredump.cx/afl/technical_details.txt},
organization = {Google},
}
@manual{rice,
author = {Henry Gordon Rice},
title = {Rice's theorem},
url = {https://en.wikipedia.org/wiki/Rice%27s_theorem},
organization = {Wikipedia}
}
@article{10.1145/1088216.1088219,
author = {Buchberger, B.},
title = {A Theoretical Basis for the Reduction of Polynomials to Canonical Forms},
year = {1976},
issue_date = {August 1976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {3},
issn = {0163-5824},
url = {https://doi.org/10.1145/1088216.1088219},
doi = {10.1145/1088216.1088219},
journal = {SIGSAM Bull.},
month = aug,
pages = {19–29},
numpages = {11}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@article{verified-ai-cacm22,
author = {Seshia, Sanjit A. and Sadigh, Dorsa and Sastry, S. Shankar},
title = {Toward Verified Artificial Intelligence},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {65},
number = {7},
issn = {0001-0782},
url = {https://doi.org/10.1145/3503914},
doi = {10.1145/3503914},
abstract = {Making AI more trustworthy with a formal methods-based approach to AI system verification and validation.},
journal = {Commun. ACM},
month = {jun},
pages = {46–55},
numpages = {10}
}



@article{DBLP:journals/cacm/DietterichH15,
  author    = {Thomas G. Dietterich and
               Eric Horvitz},
  title     = {Rise of concerns about {AI:} reflections and directions},
  journal   = {Commun. {ACM}},
  volume    = {58},
  number    = {10},
  pages     = {38--40},
  year      = {2015}
}


@article{DBLP:journals/cacm/Wing21,
  author    = {Jeannette M. Wing},
  title     = {Trustworthy {AI}},
  journal   = {Commun. {ACM}},
  volume    = {64},
  number    = {10},
  pages     = {64--71},
  year      = {2021}
}


@article{DBLP:journals/computer/Wing90,
  author    = {Jeannette M. Wing},
  title     = {A Specifier's Introduction to Formal Methods},
  journal   = {Computer},
  volume    = {23},
  number    = {9},
  pages     = {8--24},
  year      = {1990}
}


@inproceedings{huang2017cav,
	address = {Cham},
	author = {Huang, Xiaowei and Kwiatkowska, Marta and Wang, Sen and Wu, Min},
	booktitle = {Computer Aided Verification},
	editor = {Majumdar, Rupak and Kun{\v{c}}ak, Viktor},
	isbn = {978-3-319-63387-9},
	pages = {3--29},
	publisher = {Springer International Publishing},
	title = {Safety Verification of Deep Neural Networks},
	year = {2017}}

@article{huang2020csr,
	author = {Xiaowei Huang and Daniel Kroening and Wenjie Ruan and James Sharp and Youcheng Sun and Emese Thamo and Min Wu and Xinping Yi},
	doi = {https://doi.org/10.1016/j.cosrev.2020.100270},
	issn = {1574-0137},
	journal = {Computer Science Review},
	pages = {100270},
	title = {A survey of safety and trustworthiness of deep neural networks: Verification, testing, adversarial attack and defence, and interpretability},
	url = {https://www.sciencedirect.com/science/article/pii/S1574013719302527},
	volume = {37},
	year = {2020},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S1574013719302527},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.cosrev.2020.100270}}





@inproceedings{Marabou,
  author    = {Guy Katz and
               Derek A. Huang and
               Duligur Ibeling and
               Kyle Julian and
               Christopher Lazarus and
               Rachel Lim and
               Parth Shah and
               Shantanu Thakoor and
               Haoze Wu and
               Aleksandar Zeljic and
               David L. Dill and
               Mykel J. Kochenderfer and
               Clark W. Barrett},
  title     = {The Marabou Framework for Verification and Analysis of Deep Neural
               Networks},
  booktitle = {{CAV} {(1)}},
  series    = {Lecture Notes in Computer Science},
  volume    = {11561},
  pages     = {443--452},
  publisher = {Springer},
  year      = {2019}
}



@inproceedings{ReLU,
  author    = {Vinod Nair and
               Geoffrey E. Hinton},
  title     = {Rectified Linear Units Improve Restricted Boltzmann Machines},
  booktitle = {{ICML}},
  pages     = {807--814},
  publisher = {Omnipress},
  year      = {2010}
}






@misc{NAPs1,
  doi = {10.48550/ARXIV.2206.10611},
  
  url = {https://arxiv.org/abs/2206.10611},
  
  author = {Bäuerle, Alex and Jönsson, Daniel and Ropinski, Timo},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Neural Activation Patterns (NAPs): Visual Explainability of Learned Concepts},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{TCAV,
  doi = {10.48550/ARXIV.1711.11279},
  
  url = {https://arxiv.org/abs/1711.11279},
  
  author = {Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and Sayres, Rory},
  
  keywords = {Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}



@inproceedings{Absint,
  title={Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints},
  author={Cousot, Patrick and Cousot, Radhia},
  booktitle={Proceedings of the 4th ACM SIGACT-SIGPLAN symposium on Principles of programming languages},
  pages={238--252},
  year={1977}
}


@inproceedings{absref,
  title={Counterexample-guided abstraction refinement},
  author={Clarke, Edmund and Grumberg, Orna and Jha, Somesh and Lu, Yuan and Veith, Helmut},
  booktitle={International Conference on Computer Aided Verification},
  pages={154--169},
  year={2000},
  organization={Springer}
}


@inproceedings{transformer,
  author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
  title     = {Attention is All you Need},
  booktitle = {{NIPS}},
  pages     = {5998--6008},
  year      = {2017}
}



@article{CNN,
  author    = {Keiron O'Shea and
               Ryan Nash},
  title     = {An Introduction to Convolutional Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1511.08458},
  year      = {2015}
}



@article{RNN,
  author    = {Alex Sherstinsky},
  title     = {Fundamentals of Recurrent Neural Network {(RNN)} and Long Short-Term
               Memory {(LSTM)} Network},
  journal   = {CoRR},
  volume    = {abs/1808.03314},
  year      = {2018}
}

@article{zintgraf2017visualizing,
  title={Visualizing deep neural network decisions: Prediction difference analysis},
  author={Zintgraf, Luisa M and Cohen, Taco S and Adel, Tameem and Welling, Max},
  journal={arXiv preprint arXiv:1702.04595},
  year={2017}
}

@inproceedings{cho2021interpreting,
  title={Interpreting internal activation patterns in deep temporal neural networks by finding prototypes},
  author={Cho, Sohee and Chang, Wonjoon and Lee, Ginkyeng and Choi, Jaesik},
  booktitle={Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
  pages={158--166},
  year={2021}
}

@inproceedings{cheng2019runtime,
  title={Runtime monitoring neuron activation patterns},
  author={Cheng, Chih-Hong and N{\"u}hrenberg, Georg and Yasuoka, Hirotoshi},
  booktitle={2019 Design, Automation \& Test in Europe Conference \& Exhibition (DATE)},
  pages={300--303},
  year={2019},
  organization={IEEE}
}