\begin{thebibliography}{64}
\expandafter\ifx\csname natexlab\endcsname\relax\def\natexlab#1{#1}\fi

\bibitem[{Akiba et~al.(2019)Akiba, Sano, Yanase, Ohta, and
  Koyama}]{akiba2019optuna}
Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori Koyama.
  2019.
\newblock Optuna: A next-generation hyperparameter optimization framework.
\newblock In \emph{Proceedings of the 25th ACM SIGKDD international conference
  on knowledge discovery \& data mining}, pages 2623--2631.

\bibitem[{Augustyniak et~al.(2020)Augustyniak, Rajda, Kajdanowicz, and
  Bernaczyk}]{augustyniak-etal-2020-political}
Lukasz Augustyniak, Krzysztof Rajda, Tomasz Kajdanowicz, and Micha{\l}
  Bernaczyk. 2020.
\newblock \href {https://www.aclweb.org/anthology/2020.winlp-1.28} {Political
  advertising dataset: the use case of the polish 2020 presidential elections}.
\newblock In \emph{Proceedings of the The Fourth Widening Natural Language
  Processing Workshop}, pages 110--114, Seattle, USA. Association for
  Computational Linguistics.

\bibitem[{Biewald(2020)}]{wandb}
Lukas Biewald. 2020.
\newblock \href {https://www.wandb.com/} {Experiment tracking with weights and
  biases}.
\newblock Software available from wandb.com.

\bibitem[{Bingyu and Arefyev(2022)}]{bingyu-arefyev-2022-document}
Zhang Bingyu and Nikolay Arefyev. 2022.
\newblock \href {https://doi.org/10.18653/v1/2022.insights-1.17} {The document
  vectors using cosine similarity revisited}.
\newblock In \emph{Proceedings of the Third Workshop on Insights from Negative
  Results in NLP}, pages 129--133, Dublin, Ireland. Association for
  Computational Linguistics.

\bibitem[{Blinov et~al.(2022)Blinov, Reshetnikova, Nesterov, Zubkova, and
  Kokh}]{blinov2022rumedbench}
Pavel Blinov, Arina Reshetnikova, Aleksandr Nesterov, Galina Zubkova, and
  Vladimir Kokh. 2022.
\newblock Rumedbench: A russian medical language understanding benchmark.
\newblock \emph{arXiv preprint arXiv:2201.06499}.

\bibitem[{Broda et~al.(2012)Broda, Marci{\'n}czuk, Maziarz, Radziszewski, and
  Wardy{\'n}ski}]{broda-etal-2012-kpwr}
Bartosz Broda, Micha{\l} Marci{\'n}czuk, Marek Maziarz, Adam Radziszewski, and
  Adam Wardy{\'n}ski. 2012.
\newblock \href
  {http://www.lrec-conf.org/proceedings/lrec2012/pdf/965_Paper.pdf} {{KPW}r:
  Towards a free corpus of {P}olish}.
\newblock In \emph{Proceedings of the Eighth International Conference on
  Language Resources and Evaluation ({LREC}'12)}, pages 3218--3222, Istanbul,
  Turkey. European Language Resources Association (ELRA).

\bibitem[{Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal,
  Neelakantan, Shyam, Sastry, Askell, Agarwal, Herbert-Voss, Krueger, Henighan,
  Child, Ramesh, Ziegler, Wu, Winter, Hesse, Chen, Sigler, Litwin, Gray, Chess,
  Clark, Berner, McCandlish, Radford, Sutskever, and Amodei}]{Brown2020}
Tom~B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
  Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
  Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,
  Rewon Child, Aditya Ramesh, Daniel~M. Ziegler, Jeffrey Wu, Clemens Winter,
  Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,
  Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford,
  Ilya Sutskever, and Dario Amodei. 2020.
\newblock \href {http://arxiv.org/abs/2005.14165} {{Language models are
  few-shot learners}}.
\newblock \emph{Advances in Neural Information Processing Systems},
  2020-Decem(NeurIPS).

\bibitem[{Cahyawijaya et~al.(2021)Cahyawijaya, Winata, Wilie, Vincentio, Li,
  Kuncoro, Ruder, Lim, Bahar, Khodra et~al.}]{cahyawijaya2021indonlg}
Samuel Cahyawijaya, Genta~Indra Winata, Bryan Wilie, Karissa Vincentio,
  Xiaohong Li, Adhiguna Kuncoro, Sebastian Ruder, Zhi~Yuan Lim, Syafri Bahar,
  Masayu Khodra, et~al. 2021.
\newblock Indonlg: Benchmark and resources for evaluating indonesian natural
  language generation.
\newblock In \emph{Proceedings of the 2021 Conference on Empirical Methods in
  Natural Language Processing}, pages 8875--8898.

\bibitem[{Canete et~al.(2022)Canete, Chaperon, Fuentes, Ho, Kang, and
  P{\'e}rez}]{canete2020spanish}
Jos{\'e} Canete, Gabriel Chaperon, Rodrigo Fuentes, Jou-Hui Ho, Hojin Kang, and
  Jorge P{\'e}rez. 2022.
\newblock Spanish pre-trained bert model and evaluation data.
\newblock In \emph{Proceedings of the Practical Machine Learning for Developing
  Countries @ ICLR 2022}.

\bibitem[{Chen et~al.(2022)Chen, Xu, Fu, Shi, Li, Zhang, Sun, Li, Xiao, and
  Zhou}]{chen2022kar}
Jiangjie Chen, Rui Xu, Ziquan Fu, Wei Shi, Zhongqiao Li, Xinbo Zhang, Changzhi
  Sun, Lei Li, Yanghua Xiao, and Hao Zhou. 2022.
\newblock E-kar: A benchmark for rationalizing natural language analogical
  reasoning.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  ACL 2022}, pages 3941--3955.

\bibitem[{Conneau and Kiela(2018)}]{conneau2018senteval}
Alexis Conneau and Douwe Kiela. 2018.
\newblock Senteval: An evaluation toolkit for universal sentence
  representations.
\newblock \emph{arXiv preprint arXiv:1803.05449}.

\bibitem[{Dumitrescu et~al.(2021)Dumitrescu, Rebeja, Lorincz, Gaman, Avram,
  Ilie, Pruteanu, Stan, Rosia, Iacobescu et~al.}]{dumitrescu2021liro}
Stefan~Daniel Dumitrescu, Petru Rebeja, Beata Lorincz, Mihaela Gaman, Andrei
  Avram, Mihai Ilie, Andrei Pruteanu, Adriana Stan, Lorena Rosia, Cristina
  Iacobescu, et~al. 2021.
\newblock Liro: Benchmark and leaderboard for romanian language tasks.
\newblock In \emph{Thirty-fifth Conference on Neural Information Processing
  Systems Datasets and Benchmarks Track (Round 1)}.

\bibitem[{Ethayarajh and Jurafsky(2020)}]{ethayarajh-jurafsky-2020-utility}
Kawin Ethayarajh and Dan Jurafsky. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.emnlp-main.393} {Utility is
  in the eye of the user: A critique of {NLP} leaderboards}.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 4846--4853, Online. Association
  for Computational Linguistics.

\bibitem[{Fallahnejad and Zarezade(2021)}]{persian-nlp-benchmark}
Zohreh Fallahnejad and Ali Zarezade. 2021.
\newblock Persian nlp benchmark.
\newblock
  \url{https://github.com/Mofid-AI/persian-nlp-benchmark#persian-nlp-benchmark}.

\bibitem[{Fennig et~al.(2022)Fennig, Eberhard, and Simons}]{ethno2022}
Charles Fennig, David Eberhard, and Gary~F. Simons, editors. 2022.
\newblock \href {http://www.ethnologue.com} {\emph{Ethnologue: Languages of the
  World}}, twenty-fifth edition.
\newblock SIL International, Dallas, TX, USA.

\bibitem[{Gehrmann et~al.(2021)Gehrmann, Adewumi, Aggarwal, Ammanamanchi,
  Aremu, Bosselut, Chandu, Clinciu, Das, Dhole et~al.}]{gehrmann2021gem}
Sebastian Gehrmann, Tosin Adewumi, Karmanya Aggarwal, Pawan~Sasanka
  Ammanamanchi, Anuoluwapo Aremu, Antoine Bosselut, Khyathi~Raghavi Chandu,
  Miruna-Adriana Clinciu, Dipanjan Das, Kaustubh Dhole, et~al. 2021.
\newblock The gem benchmark: Natural language generation, its evaluation and
  metrics.
\newblock In \emph{Proceedings of the 1st Workshop on Natural Language
  Generation, Evaluation, and Metrics (GEM 2021)}, pages 96--120.

\bibitem[{Gomes(2020)}]{Gomes2020}
J.~R.~S. Gomes. 2020.
\newblock Plue: Portuguese language understanding evaluation.
\newblock \url{https://github.com/jubs12/PLUE}.

\bibitem[{Gorman and Bedrick(2020)}]{Gorman2020}
Kyle Gorman and Steven Bedrick. 2020.
\newblock \href {https://doi.org/10.18653/v1/p19-1267} {{We need to talk about
  standard splits}}.
\newblock \emph{ACL 2019 - 57th Annual Meeting of the Association for
  Computational Linguistics, Proceedings of the Conference}, pages 2786--2791.

\bibitem[{Guan et~al.(2022)Guan, Feng, Chen, He, Mao, Fan, and
  Huang}]{guan2022lot}
Jian Guan, Zhuoer Feng, Yamei Chen, Ruilin He, Xiaoxi Mao, Changjie Fan, and
  Minlie Huang. 2022.
\newblock Lot: A story-centric benchmark for evaluating chinese long text
  understanding and generation.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  10:434--451.

\bibitem[{Hoffmann et~al.(2022)Hoffmann, Borgeaud, Mensch, Buchatskaya, Cai,
  Rutherford, Casas, Hendricks, Welbl, Clark, Hennigan, Noland, Millican,
  Driessche, Damoc, Guy, Osindero, Simonyan, Elsen, Rae, Vinyals, and
  Sifre}]{Hoffmann2022}
Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor
  Cai, Eliza Rutherford, Diego de~Las Casas, Lisa~Anne Hendricks, Johannes
  Welbl, Aidan Clark, Tom Hennigan, Eric Noland, Katie Millican, George van~den
  Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan, Erich
  Elsen, Jack~W. Rae, Oriol Vinyals, and Laurent Sifre. 2022.
\newblock \href {https://doi.org/10.48550/ARXIV.2203.15556} {Training
  compute-optimal large language models}.

\bibitem[{Hu et~al.(2020)Hu, Ruder, Siddhant, Neubig, Firat, and
  Johnson}]{hu2020xtreme}
Junjie Hu, Sebastian Ruder, Aditya Siddhant, Graham Neubig, Orhan Firat, and
  Melvin Johnson. 2020.
\newblock Xtreme: A massively multilingual multi-task benchmark for evaluating
  cross-lingual generalisation.
\newblock In \emph{International Conference on Machine Learning}, pages
  4411--4421. PMLR.

\bibitem[{Kakwani et~al.(2020)Kakwani, Kunchukuttan, Golla, Gokul,
  Bhattacharyya, Khapra, and Kumar}]{kakwani2020indicnlpsuite}
Divyanshu Kakwani, Anoop Kunchukuttan, Satish Golla, NC~Gokul, Avik
  Bhattacharyya, Mitesh~M Khapra, and Pratyush Kumar. 2020.
\newblock Indicnlpsuite: Monolingual corpora, evaluation benchmarks and
  pre-trained multilingual language models for indian languages.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  EMNLP 2020}, pages 4948--4961.

\bibitem[{Khashabi et~al.(2021)Khashabi, Cohan, Shakeri, Hosseini, Pezeshkpour,
  Alikhani, Aminnaseri, Bitaab, Brahman, Ghazarian
  et~al.}]{khashabi2021parsinlu}
Daniel Khashabi, Arman Cohan, Siamak Shakeri, Pedram Hosseini, Pouya
  Pezeshkpour, Malihe Alikhani, Moin Aminnaseri, Marzieh Bitaab, Faeze Brahman,
  Sarik Ghazarian, et~al. 2021.
\newblock Parsinlu: A suite of language understanding challenges for persian.
\newblock \emph{Transactions of the Association for Computational Linguistics},
  9:1147--1162.

\bibitem[{Kiela et~al.(2021)Kiela, Bartolo, Nie, Kaushik, Geiger, Wu, Vidgen,
  Prasad, Singh, Ringshia et~al.}]{kiela2021dynabench}
Douwe Kiela, Max Bartolo, Yixin Nie, Divyansh Kaushik, Atticus Geiger,
  Zhengxuan Wu, Bertie Vidgen, Grusha Prasad, Amanpreet Singh, Pratik Ringshia,
  et~al. 2021.
\newblock Dynabench: Rethinking benchmarking in nlp.
\newblock In \emph{Proceedings of the 2021 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 4110--4124.

\bibitem[{Kim et~al.(2022)Kim, Jang, Kwon, and Davis}]{kim2022kobest}
Dohyeong Kim, Myeongjun Jang, Deuk~Sin Kwon, and Eric Davis. 2022.
\newblock Kobest: Korean balanced evaluation of significant tasks.
\newblock \emph{arXiv preprint arXiv:2204.04541}.

\bibitem[{Koco{\'n} et~al.(2019)Koco{\'n}, Mi{\l}kowski, and
  Za{\'s}ko-Zieli{\'n}ska}]{kocon-etal-2019-multi}
Jan Koco{\'n}, Piotr Mi{\l}kowski, and Monika Za{\'s}ko-Zieli{\'n}ska. 2019.
\newblock \href {https://doi.org/10.18653/v1/K19-1092} {Multi-level sentiment
  analysis of {P}ol{E}mo 2.0: Extended corpus of multi-domain consumer
  reviews}.
\newblock In \emph{Proceedings of the 23rd Conference on Computational Natural
  Language Learning (CoNLL)}, pages 980--991, Hong Kong, China. Association for
  Computational Linguistics.

\bibitem[{Kocoń et~al.(2021)Kocoń, Radom, Kaczmarz-Wawryk, Wabnic,
  Zajączkowska, and Zaśko-Zielińska}]{Koco2021AspectEmoMC}
Jan Kocoń, Jarema Radom, Ewa Kaczmarz-Wawryk, Kamil Wabnic, Ada Zajączkowska,
  and Monika Zaśko-Zielińska. 2021.
\newblock Aspectemo: Multi-domain corpus of consumer reviews for aspect-based
  sentiment analysis.
\newblock \emph{2021 International Conference on Data Mining Workshops
  (ICDMW)}, pages 166--173.

\bibitem[{Koto et~al.(2020)Koto, Rahimi, Lau, and Baldwin}]{koto2020indolem}
Fajri Koto, Afshin Rahimi, Jey~Han Lau, and Timothy Baldwin. 2020.
\newblock Indolem and indobert: A benchmark dataset and pre-trained language
  model for indonesian nlp.
\newblock In \emph{Proceedings of the 28th International Conference on
  Computational Linguistics}, pages 757--770.

\bibitem[{Kuprieiev et~al.(2022)Kuprieiev, skshetry, Petrov, Redzyński,
  Rowlands, da~Costa-Luis, Schepanovski, Shcheklein, Taskaya, Gao, Orpinel,
  de~la Iglesia~Castro, Santos, Sharma, Zhanibek, Hodovic, Berenbaum, Kodenko,
  Grigorev, Earl, Dash, daniele, Vyshnya, maykulkarni, Hora, Vera, Mangal, and
  Baranowski}]{ruslan_kuprieiev_2022_7020480}
Ruslan Kuprieiev, skshetry, Dmitry Petrov, Paweł Redzyński, Peter Rowlands,
  Casper da~Costa-Luis, Alexander Schepanovski, Ivan Shcheklein, Batuhan
  Taskaya, Gao, Jorge Orpinel, David de~la Iglesia~Castro, Fábio Santos, Aman
  Sharma, Zhanibek, Dani Hodovic, Dave Berenbaum, Nikita Kodenko, Andrew
  Grigorev, Earl, Nabanita Dash, daniele, George Vyshnya, maykulkarni, Max
  Hora, Vera, Sanidhya Mangal, and Wojciech Baranowski. 2022.
\newblock \href {https://doi.org/10.5281/zenodo.7020480} {Dvc: Data version
  control - git for data \& models}.

\bibitem[{Kłeczek(2020)}]{Kleczek2020}
Dariusz Kłeczek. 2020.
\newblock Polbert: Attacking polish nlp tasks with transformers.
\newblock In \emph{Proceedings of the PolEval 2020 Workshop}. Institute of
  Computer Science, Polish Academy of Sciences.

\bibitem[{Lan et~al.(2020)Lan, Chen, Goodman, Gimpel, Sharma, and
  Soricut}]{Lan2020ALBERT}
Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and
  Radu Soricut. 2020.
\newblock \href {https://openreview.net/forum?id=H1eA7AEtvS} {Albert: A lite
  bert for self-supervised learning of language representations}.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Le et~al.(2020)Le, Vial, Frej, Segonne, Coavoux, Lecouteux, Allauzen,
  Crabb{\'e}, Besacier, and Schwab}]{le2020flaubert}
Hang Le, Lo{\"\i}c Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux,
  Benjamin Lecouteux, Alexandre Allauzen, Benoit Crabb{\'e}, Laurent Besacier,
  and Didier Schwab. 2020.
\newblock Flaubert: Unsupervised language model pre-training for french.
\newblock In \emph{Proceedings of the 12th Language Resources and Evaluation
  Conference}, pages 2479--2490.

\bibitem[{Li et~al.(2020)Li, Sun, Meng, Liang, Wu, and Li}]{li-etal-2020-dice}
Xiaoya Li, Xiaofei Sun, Yuxian Meng, Junjun Liang, Fei Wu, and Jiwei Li. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.acl-main.45} {Dice loss for
  data-imbalanced {NLP} tasks}.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pages 465--476, Online. Association for
  Computational Linguistics.

\bibitem[{Liang et~al.(2020)Liang, Duan, Gong, Wu, Guo, Qi, Gong, Shou, Jiang,
  Cao, Fan, Zhang, Agrawal, Cui, Wei, Bharti, Qiao, Chen, Wu, Liu, Yang,
  Campos, Majumder, and Zhou}]{liang-etal-2020-xglue}
Yaobo Liang, Nan Duan, Yeyun Gong, Ning Wu, Fenfei Guo, Weizhen Qi, Ming Gong,
  Linjun Shou, Daxin Jiang, Guihong Cao, Xiaodong Fan, Ruofei Zhang, Rahul
  Agrawal, Edward Cui, Sining Wei, Taroon Bharti, Ying Qiao, Jiun-Hung Chen,
  Winnie Wu, Shuguang Liu, Fan Yang, Daniel Campos, Rangan Majumder, and Ming
  Zhou. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.emnlp-main.484} {{XGLUE}: A
  new benchmark datasetfor cross-lingual pre-training, understanding and
  generation}.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 6008--6018, Online. Association
  for Computational Linguistics.

\bibitem[{Liu et~al.(2021)Liu, Yan, Gong, Qi, Zhang, Jiao, Chen, Fu, Shou, Gong
  et~al.}]{liu2021glge}
Dayiheng Liu, Yu~Yan, Yeyun Gong, Weizhen Qi, Hang Zhang, Jian Jiao, Weizhu
  Chen, Jie Fu, Linjun Shou, Ming Gong, et~al. 2021.
\newblock Glge: A new general language generation evaluation benchmark.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  ACL-IJCNLP 2021}, pages 408--420.

\bibitem[{McCann et~al.(2018)McCann, Keskar, Xiong, and
  Socher}]{mccann2018natural}
Bryan McCann, Nitish~Shirish Keskar, Caiming Xiong, and Richard Socher. 2018.
\newblock The natural language decathlon: Multitask learning as question
  answering.
\newblock \emph{arXiv preprint arXiv:1806.08730}.

\bibitem[{Mroczkowski et~al.(2021)Mroczkowski, Rybak, Wr{\'o}blewska, and
  Gawlik}]{mroczkowski-etal-2021-herbert}
Robert Mroczkowski, Piotr Rybak, Alina Wr{\'o}blewska, and Ireneusz Gawlik.
  2021.
\newblock \href {https://www.aclweb.org/anthology/2021.bsnlp-1.1} {{H}er{BERT}:
  Efficiently pretrained transformer-based language model for {P}olish}.
\newblock In \emph{Proceedings of the 8th Workshop on Balto-Slavic Natural
  Language Processing}, pages 1--10, Kiyv, Ukraine. Association for
  Computational Linguistics.

\bibitem[{Ogrodniczuk and Kope{\'c}(2014)}]{ogrodniczuk-kopec-2014-polish}
Maciej Ogrodniczuk and Mateusz Kope{\'c}. 2014.
\newblock \href
  {http://www.lrec-conf.org/proceedings/lrec2014/pdf/1211_Paper.pdf} {The
  {P}olish summaries corpus}.
\newblock In \emph{Proceedings of the Ninth International Conference on
  Language Resources and Evaluation ({LREC}'14)}, pages 3712--3715, Reykjavik,
  Iceland. European Language Resources Association (ELRA).

\bibitem[{Park et~al.(2021)Park, Moon, Kim, Cho, Han, Park, Song, Kim, Song, Oh
  et~al.}]{park2021klue}
Sungjoon Park, Jihyung Moon, Sungdong Kim, Won~Ik Cho, Jiyoon Han, Jangwon
  Park, Chisung Song, Junseong Kim, Yongsook Song, Taehwan Oh, et~al. 2021.
\newblock Klue: Korean language understanding evaluation.
\newblock \emph{arXiv preprint arXiv:2105.09680}.

\bibitem[{Peters et~al.(2018)Peters, Neumann, Iyyer, Gardner, Clark, Lee, and
  Zettlemoyer}]{peters-etal-2018-deep}
Matthew~E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark,
  Kenton Lee, and Luke Zettlemoyer. 2018.
\newblock \href {https://doi.org/10.18653/v1/N18-1202} {Deep contextualized
  word representations}.
\newblock In \emph{Proceedings of the 2018 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long Papers)}, pages 2227--2237, New Orleans,
  Louisiana. Association for Computational Linguistics.

\bibitem[{Petroni et~al.(2021)Petroni, Piktus, Fan, Lewis, Yazdani, De~Cao,
  Thorne, Jernite, Karpukhin, Maillard et~al.}]{petroni2021kilt}
Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick Lewis, Majid Yazdani,
  Nicola De~Cao, James Thorne, Yacine Jernite, Vladimir Karpukhin, Jean
  Maillard, et~al. 2021.
\newblock Kilt: a benchmark for knowledge intensive language tasks.
\newblock In \emph{Proceedings of the 2021 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 2523--2544.

\bibitem[{Pineau et~al.(2021)Pineau, Vincent-Lamarre, Sinha, Larivi{\'{e}}re,
  Beygelzimer, D'Alch{\'{e}}-Buc, Fox, and Larochelle}]{Pineau2021}
Joelle Pineau, Philippe Vincent-Lamarre, Koustuv Sinha, Vincent
  Larivi{\'{e}}re, Alina Beygelzimer, Florence D'Alch{\'{e}}-Buc, Emily Fox,
  and Hugo Larochelle. 2021.
\newblock \href {http://arxiv.org/abs/2003.12206} {{Improving reproducibility
  in machine learning research (a report from the neurips 2019 reproducibility
  program)}}.
\newblock \emph{Journal of Machine Learning Research}, 22:1--20.

\bibitem[{Przepiórkowski et~al.(2012)Przepiórkowski, Bańko, Górski, and
  Lewandowska-Tomaszczyk}]{przepiorkowski_narodowy_2012}
Adam Przepiórkowski, Mirosław Bańko, Rafał~L. Górski, and Barbara
  Lewandowska-Tomaszczyk, editors. 2012.
\newblock \emph{Narodowy korpus języka polskiego}.
\newblock Wydawnictwo Naukowe PWN.

\bibitem[{Pęzik et~al.(2022)Pęzik, Krawentek, Karasińska, Wilk, Rybińska,
  Peljak-Łapińska, Cichosz, Deckert, and Adamczyk}]{pezik_lrec_2022}
Piotr Pęzik, Gosia Krawentek, Sylwia Karasińska, Paweł Wilk, Paulina
  Rybińska, Angelika Peljak-Łapińska, Anna Cichosz, Mikołaj Deckert, and
  Michał Adamczyk. 2022.
\newblock Diabiz -- an annotated corpus of polish call center dialogs.
\newblock In \emph{{Language Resources and Evaluation Conference} {2022}}.
  European Language Resources Association (ELRA).

\bibitem[{Rae et~al.(2021)Rae, Borgeaud, Cai, Millican, Hoffmann, Song,
  Aslanides, Henderson, Ring, Young, Rutherford, Hennigan, Menick, Cassirer,
  Powell, Driessche, Hendricks, Rauh, Huang, Glaese, Welbl, Dathathri, Huang,
  Uesato, Mellor, Higgins, Creswell, McAleese, Wu, Elsen, Jayakumar,
  Buchatskaya, Budden, Sutherland, Simonyan, Paganini, Sifre, Martens, Li,
  Kuncoro, Nematzadeh, Gribovskaya, Donato, Lazaridou, Mensch, Lespiau,
  Tsimpoukelli, Grigorev, Fritz, Sottiaux, Pajarskas, Pohlen, Gong, Toyama,
  d'Autume, Li, Terzi, Mikulik, Babuschkin, Clark, Casas, Guy, Jones, Bradbury,
  Johnson, Hechtman, Weidinger, Gabriel, Isaac, Lockhart, Osindero, Rimell,
  Dyer, Vinyals, Ayoub, Stanway, Bennett, Hassabis, Kavukcuoglu, and
  Irving}]{Rae2021}
Jack~W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann,
  Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young,
  Eliza Rutherford, Tom Hennigan, Jacob Menick, Albin Cassirer, Richard Powell,
  George van~den Driessche, Lisa~Anne Hendricks, Maribeth Rauh, Po-Sen Huang,
  Amelia Glaese, Johannes Welbl, Sumanth Dathathri, Saffron Huang, Jonathan
  Uesato, John Mellor, Irina Higgins, Antonia Creswell, Nat McAleese, Amy Wu,
  Erich Elsen, Siddhant Jayakumar, Elena Buchatskaya, David Budden, Esme
  Sutherland, Karen Simonyan, Michela Paganini, Laurent Sifre, Lena Martens,
  Xiang~Lorraine Li, Adhiguna Kuncoro, Aida Nematzadeh, Elena Gribovskaya,
  Domenic Donato, Angeliki Lazaridou, Arthur Mensch, Jean-Baptiste Lespiau,
  Maria Tsimpoukelli, Nikolai Grigorev, Doug Fritz, Thibault Sottiaux, Mantas
  Pajarskas, Toby Pohlen, Zhitao Gong, Daniel Toyama, Cyprien de~Masson
  d'Autume, Yujia Li, Tayfun Terzi, Vladimir Mikulik, Igor Babuschkin, Aidan
  Clark, Diego de~Las Casas, Aurelia Guy, Chris Jones, James Bradbury, Matthew
  Johnson, Blake Hechtman, Laura Weidinger, Iason Gabriel, William Isaac,
  Ed~Lockhart, Simon Osindero, Laura Rimell, Chris Dyer, Oriol Vinyals, Kareem
  Ayoub, Jeff Stanway, Lorrayne Bennett, Demis Hassabis, Koray Kavukcuoglu, and
  Geoffrey Irving. 2021.
\newblock \href {https://doi.org/10.48550/ARXIV.2112.11446} {Scaling language
  models: Methods, analysis \& insights from training gopher}.

\bibitem[{Reimers and Gurevych(2019)}]{reimers-2019-sentence-bert}
Nils Reimers and Iryna Gurevych. 2019.
\newblock \href {http://arxiv.org/abs/1908.10084} {Sentence-bert: Sentence
  embeddings using siamese bert-networks}.
\newblock In \emph{Proceedings of the 2019 Conference on Empirical Methods in
  Natural Language Processing}. Association for Computational Linguistics.

\bibitem[{Rybak et~al.(2020)Rybak, Mroczkowski, Tracz, and Gawlik}]{klej}
Piotr Rybak, Robert Mroczkowski, Janusz Tracz, and Ireneusz Gawlik. 2020.
\newblock Klej: Comprehensive benchmark for polish language understanding.
\newblock In \emph{Proceedings of the 58th Annual Meeting of the Association
  for Computational Linguistics}, pages 1191--1201.

\bibitem[{Safaya et~al.(2022)Safaya, Kurtulu{\c{s}}, Goktogan, and
  Yuret}]{safaya2022mukayese}
Ali Safaya, Emirhan Kurtulu{\c{s}}, Arda Goktogan, and Deniz Yuret. 2022.
\newblock Mukayese: Turkish nlp strikes back.
\newblock In \emph{Findings of the Association for Computational Linguistics:
  ACL 2022}, pages 846--863.

\bibitem[{Seelawi et~al.(2021)Seelawi, Tuffaha, Gzawi, Farhan, Talafha, Badawi,
  Sober, Al-Dweik, Freihat, and Al-Natsheh}]{seelawi2021alue}
Haitham Seelawi, Ibraheem Tuffaha, Mahmoud Gzawi, Wael Farhan, Bashar Talafha,
  Riham Badawi, Zyad Sober, Oday Al-Dweik, Abed~Alhakim Freihat, and Hussein
  Al-Natsheh. 2021.
\newblock Alue: Arabic language understanding evaluation.
\newblock In \emph{Proceedings of the Sixth Arabic Natural Language Processing
  Workshop}, pages 173--184.

\bibitem[{Shavrina et~al.(2020)Shavrina, Fenogenova, Anton, Shevelev, Artemova,
  Malykh, Mikhailov, Tikhonova, Chertok, and
  Evlampiev}]{shavrina-etal-2020-russiansuperglue}
Tatiana Shavrina, Alena Fenogenova, Emelyanov Anton, Denis Shevelev, Ekaterina
  Artemova, Valentin Malykh, Vladislav Mikhailov, Maria Tikhonova, Andrey
  Chertok, and Andrey Evlampiev. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.emnlp-main.381}
  {{R}ussian{S}uper{GLUE}: A {R}ussian language understanding evaluation
  benchmark}.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, pages 4717--4726, Online. Association
  for Computational Linguistics.

\bibitem[{Wang et~al.(2019{\natexlab{a}})Wang, Pruksachatkun, Nangia, Singh,
  Michael, Hill, Levy, and Bowman}]{Wang2019}
Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael,
  Felix Hill, Omer Levy, and Samuel Bowman. 2019{\natexlab{a}}.
\newblock \href
  {https://proceedings.neurips.cc/paper/2019/file/4496bf24afe7fab6f046bf4923da8de6-Paper.pdf}
  {Superglue: A stickier benchmark for general-purpose language understanding
  systems}.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32. Curran Associates, Inc.

\bibitem[{Wang et~al.(2019{\natexlab{b}})Wang, Pruksachatkun, Nangia, Singh,
  Michael, Hill, Levy, and Bowman}]{wang2019superglue}
Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael,
  Felix Hill, Omer Levy, and Samuel Bowman. 2019{\natexlab{b}}.
\newblock Superglue: A stickier benchmark for general-purpose language
  understanding systems.
\newblock \emph{Advances in neural information processing systems}, 32.

\bibitem[{Wang et~al.(2018)Wang, Singh, Michael, Hill, Levy, and
  Bowman}]{wang2018glue}
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel~R
  Bowman. 2018.
\newblock Glue: A multi-task benchmark and analysis platform for natural
  language understanding.
\newblock \emph{arXiv preprint arXiv:1804.07461}.

\bibitem[{Wang et~al.(2022)Wang, Shen, Peng, Zhang, Xiao, Liu, Tang, Chen, Wu,
  and Wang}]{wang2022fine}
Lijie Wang, Yaozong Shen, Shuyuan Peng, Shuai Zhang, Xinyan Xiao, Hao Liu,
  Hongxuan Tang, Ying Chen, Hua Wu, and Haifeng Wang. 2022.
\newblock A fine-grained interpretability evaluation benchmark for neural nlp.
\newblock \emph{arXiv preprint arXiv:2205.11097}.

\bibitem[{Wang et~al.(2020)Wang, Ji, Wang, Wu, Lin, Li, Ke, Xiao, Jiang, Xu,
  and Zhou}]{WANG2020103418}
Qiong Wang, Zongcheng Ji, Jingqi Wang, Stephen Wu, Weiyan Lin, Wenzhen Li,
  Li~Ke, Guohong Xiao, Qing Jiang, Hua Xu, and Yi~Zhou. 2020.
\newblock \href {https://doi.org/https://doi.org/10.1016/j.jbi.2020.103418} {A
  study of entity-linking methods for normalizing chinese diagnosis and
  procedure terms to icd codes}.
\newblock \emph{Journal of Biomedical Informatics}, 105:103418.

\bibitem[{Wilie et~al.(2020)Wilie, Vincentio, Winata, Cahyawijaya, Li, Lim,
  Soleman, Mahendra, Fung, Bahar et~al.}]{wilie2020indonlu}
Bryan Wilie, Karissa Vincentio, Genta~Indra Winata, Samuel Cahyawijaya,
  Xiaohong Li, Zhi~Yuan Lim, Sidik Soleman, Rahmad Mahendra, Pascale Fung,
  Syafri Bahar, et~al. 2020.
\newblock Indonlu: Benchmark and resources for evaluating indonesian natural
  language understanding.
\newblock In \emph{Proceedings of the 1st Conference of the Asia-Pacific
  Chapter of the Association for Computational Linguistics and the 10th
  International Joint Conference on Natural Language Processing}, pages
  843--857.

\bibitem[{Wolf et~al.(2020)Wolf, Debut, Sanh, Chaumond, Delangue, Moi, Cistac,
  Rault, Louf, Funtowicz, Davison, Shleifer, von Platen, Ma, Jernite, Plu, Xu,
  Le~Scao, Gugger, Drame, Lhoest, and Rush}]{wolf-etal-2020-transformers}
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
  Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe
  Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
  Plu, Canwen Xu, Teven Le~Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
  and Alexander Rush. 2020.
\newblock \href {https://doi.org/10.18653/v1/2020.emnlp-demos.6} {Transformers:
  State-of-the-art natural language processing}.
\newblock In \emph{Proceedings of the 2020 Conference on Empirical Methods in
  Natural Language Processing: System Demonstrations}, pages 38--45, Online.
  Association for Computational Linguistics.

\bibitem[{Wr{\'o}blewska and
  Krasnowska-Kiera{\'s}(2017)}]{wroblewska-krasnowska-kieras-2017-polish}
Alina Wr{\'o}blewska and Katarzyna Krasnowska-Kiera{\'s}. 2017.
\newblock \href {https://doi.org/10.18653/v1/P17-1073} {{P}olish evaluation
  dataset for compositional distributional semantics models}.
\newblock In \emph{Proceedings of the 55th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 784--792,
  Vancouver, Canada. Association for Computational Linguistics.

\bibitem[{Xu et~al.(2020)Xu, Hu, Zhang, Li, Cao, Li, Xu, Sun, Yu, Yu
  et~al.}]{xu2020clue}
Liang Xu, Hai Hu, Xuanwei Zhang, Lu~Li, Chenjie Cao, Yudong Li, Yechen Xu, Kai
  Sun, Dian Yu, Cong Yu, et~al. 2020.
\newblock Clue: A chinese language understanding evaluation benchmark.
\newblock In \emph{Proceedings of the 28th International Conference on
  Computational Linguistics}, pages 4762--4772.

\bibitem[{Xu et~al.(2021)Xu, Lu, Yuan, Zhang, Xu, Yuan, Wei, Pan, Tian, Qin
  et~al.}]{xu2021fewclue}
Liang Xu, Xiaojing Lu, Chenyang Yuan, Xuanwei Zhang, Huilin Xu, Hu~Yuan, Guoao
  Wei, Xiang Pan, Xin Tian, Libo Qin, et~al. 2021.
\newblock Fewclue: A chinese few-shot learning evaluation benchmark.
\newblock \emph{arXiv preprint arXiv:2107.07498}.

\bibitem[{Yang et~al.(2019)Yang, Dai, Yang, Carbonell, Salakhutdinov, and
  Le}]{NEURIPS2019_dc6a7e65}
Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ~R Salakhutdinov,
  and Quoc~V Le. 2019.
\newblock \href
  {https://proceedings.neurips.cc/paper/2019/file/dc6a7e655d7e5840e66733e9ee67cc69-Paper.pdf}
  {Xlnet: Generalized autoregressive pretraining for language understanding}.
\newblock In \emph{Advances in Neural Information Processing Systems},
  volume~32. Curran Associates, Inc.

\bibitem[{Yao et~al.(2021)Yao, Dong, Guan, Cao, Zhang, Xiao, Wang, Qi, Bao, Nie
  et~al.}]{yao2021cuge}
Yuan Yao, Qingxiu Dong, Jian Guan, Boxi Cao, Zhengyan Zhang, Chaojun Xiao,
  Xiaozhi Wang, Fanchao Qi, Junwei Bao, Jinran Nie, et~al. 2021.
\newblock Cuge: A chinese language understanding and generation evaluation
  benchmark.
\newblock \emph{arXiv preprint arXiv:2112.13610}.

\bibitem[{Ye et~al.(2022)Ye, Lin, Li, and Sun}]{ye-etal-2022-packed}
Deming Ye, Yankai Lin, Peng Li, and Maosong Sun. 2022.
\newblock \href {https://doi.org/10.18653/v1/2022.acl-long.337} {Packed
  levitated marker for entity and relation extraction}.
\newblock In \emph{Proceedings of the 60th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 4904--4917,
  Dublin, Ireland. Association for Computational Linguistics.

\bibitem[{Zhang et~al.(2021)Zhang, Chen, Bi, Liang, Li, Shang, Yin, Tan, Xu,
  Huang et~al.}]{zhang2021cblue}
Ningyu Zhang, Mosha Chen, Zhen Bi, Xiaozhuan Liang, Lei Li, Xin Shang, Kangping
  Yin, Chuanqi Tan, Jian Xu, Fei Huang, et~al. 2021.
\newblock Cblue: A chinese biomedical language understanding evaluation
  benchmark.
\newblock \emph{arXiv preprint arXiv:2106.08087}.

\end{thebibliography}
