\begin{thebibliography}{77}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Mnih et~al.(2013)Mnih, Kavukcuoglu, Silver, Graves, Antonoglou,
  Wierstra, and Riedmiller]{mnih2013playing}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis
  Antonoglou, Daan Wierstra, and Martin Riedmiller.
\newblock Playing atari with deep reinforcement learning.
\newblock {arXiv}:1312.5602, 2013.

\bibitem[Sergey et~al.(2015)Sergey, Wagener, and Abbeel]{sergey2015learning}
Levine Sergey, Nolan Wagener, and Pieter Abbeel.
\newblock Learning contact-rich manipulation skills with guided policy search.
\newblock In \emph{Proceedings of the 2015 IEEE International Conference on
  Robotics and Automation (ICRA), Seattle, WA, USA}, pages 26--30, 2015.

\bibitem[Liu et~al.(2020)Liu, See, Ngiam, Celi, Sun, and Feng]{RL-MIMIC-survey}
Siqi Liu, Kay~Choong See, Kee~Yuan Ngiam, Leo~Anthony Celi, Xingzhi Sun, and
  Mengling Feng.
\newblock Reinforcement learning for clinical decision support in critical
  care: comprehensive review.
\newblock \emph{Journal of Medical Internet Research}, 22\penalty0
  (7):\penalty0 e18477, 2020.

\bibitem[Dulac-Arnold et~al.(2019)Dulac-Arnold, Mankowitz, and
  Hester]{dulac2019challengesRealWorld-RL}
Gabriel Dulac-Arnold, Daniel Mankowitz, and Todd Hester.
\newblock Challenges of real-world reinforcement learning.
\newblock {arXiv}:1904.12901, 2019.

\bibitem[Levine et~al.(2020)Levine, Kumar, Tucker, and Fu]{levine2020offlineRL}
Sergey Levine, Aviral Kumar, George Tucker, and Justin Fu.
\newblock Offline reinforcement learning: Tutorial, review, and perspectives on
  open problems.
\newblock {arXiv}:2005.01643, 2020.

\bibitem[Komorowski et~al.(2018)Komorowski, Celi, Badawi, Gordon, and
  Faisal]{Nature-RL-MIMIC}
Matthieu Komorowski, Leo~A Celi, Omar Badawi, Anthony~C Gordon, and A~Aldo
  Faisal.
\newblock The artificial intelligence clinician learns optimal treatment
  strategies for sepsis in intensive care.
\newblock \emph{Nature medicine}, 24\penalty0 (11):\penalty0 1716--1720, 2018.

\bibitem[Lin et~al.(2018)Lin, Stanley, Ghassemi, and Nemati]{DDPG-RL-MIMIC}
Rongmei Lin, Matthew~D Stanley, Mohammad~M Ghassemi, and Shamim Nemati.
\newblock A deep deterministic policy gradient approach to medication dosing
  and surveillance in the icu.
\newblock In \emph{2018 40th Annual International Conference of the IEEE
  Engineering in Medicine and Biology Society (EMBC)}, pages 4927--4931. IEEE,
  2018.

\bibitem[Kone{\v{c}}n{\`y} et~al.(2016)Kone{\v{c}}n{\`y}, McMahan, Ramage, and
  Richt{\'a}rik]{konevcny2016federated}
Jakub Kone{\v{c}}n{\`y}, H~Brendan McMahan, Daniel Ramage, and Peter
  Richt{\'a}rik.
\newblock Federated optimization: Distributed machine learning for on-device
  intelligence.
\newblock {arXiv}:1610.02527, 2016.

\bibitem[Kairouz et~al.(2019)Kairouz, McMahan, Avent, Bellet, Bennis, Bhagoji,
  Bonawitz, Charles, Cormode, Cummings, et~al.]{kairouz2019FedLearn}
Peter Kairouz, H~Brendan McMahan, Brendan Avent, Aur{\'e}lien Bellet, Mehdi
  Bennis, Arjun~Nitin Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode,
  Rachel Cummings, et~al.
\newblock Advances and open problems in federated learning.
\newblock {arXiv}:1912.04977, 2019.

\bibitem[Li et~al.(2019)Li, Wen, Wu, Hu, Wang, Li, Liu, and He]{li2019survey}
Qinbin Li, Zeyi Wen, Zhaomin Wu, Sixu Hu, Naibo Wang, Yuan Li, Xu~Liu, and
  Bingsheng He.
\newblock A survey on federated learning systems: vision, hype and reality for
  data privacy and protection.
\newblock {arXiv}:1907.09693, 2019.

\bibitem[Li et~al.(2020{\natexlab{a}})Li, Wen, and He]{li2020practical}
Qinbin Li, Zeyi Wen, and Bingsheng He.
\newblock Practical federated gradient boosting decision trees.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~34, pages 4642--4649, 2020{\natexlab{a}}.

\bibitem[Zhuo et~al.(2019)Zhuo, Feng, Xu, Yang, and
  Lin]{zhuo2019federatedRLYangQ}
Hankz~Hankui Zhuo, Wenfeng Feng, Qian Xu, Qiang Yang, and Yufeng Lin.
\newblock Federated reinforcement learning.
\newblock {arXiv}:1901.08277, 2019.

\bibitem[Liang et~al.(2019)Liang, Liu, Chen, Liu, and
  Yang]{liang2019FedRL-for-AV}
Xinle Liang, Yang Liu, Tianjian Chen, Ming Liu, and Qiang Yang.
\newblock Federated transfer reinforcement learning for autonomous driving.
\newblock {arXiv}:1910.06001, 2019.

\bibitem[Nadiger et~al.(2019)Nadiger, Kumar, and
  Abdelhak]{nadiger2019federatedRL}
Chetan Nadiger, Anil Kumar, and Sherine Abdelhak.
\newblock Federated reinforcement learning for fast personalization.
\newblock In \emph{2019 IEEE Second International Conference on Artificial
  Intelligence and Knowledge Engineering (AIKE)}, pages 123--127. IEEE, 2019.

\bibitem[Lim et~al.(2020)Lim, Kim, Heo, and Han]{lim2020federated-Sensors}
Hyun-Kyo Lim, Ju-Bong Kim, Joo-Seong Heo, and Youn-Hee Han.
\newblock Federated reinforcement learning for training control policies on
  multiple iot devices.
\newblock \emph{Sensors}, 20\penalty0 (5):\penalty0 1359, 2020.

\bibitem[Liu et~al.(2019)Liu, Wang, and Liu]{liu2019FedRL-for-robots}
Boyi Liu, Lujia Wang, and Ming Liu.
\newblock Lifelong federated reinforcement learning: a learning architecture
  for navigation in cloud robotic systems.
\newblock \emph{IEEE Robotics and Automation Letters}, 4\penalty0 (4):\penalty0
  4555--4562, 2019.

\bibitem[Yu et~al.(2020)Yu, Chen, Zhou, Gong, and Wu]{yu2020FedRLfor5G}
Shuai Yu, Xu~Chen, Zhi Zhou, Xiaowen Gong, and Di~Wu.
\newblock When deep reinforcement learning meets federated learning:
  Intelligent multi-timescale resource management for multi-access edge
  computing in 5{G} ultra dense network.
\newblock \emph{IEEE Internet of Things Journal}, 2020.

\bibitem[Papini et~al.(2018)Papini, Binaghi, Canonaco, Pirotta, and
  Restelli]{papini2018stochastic}
Matteo Papini, Damiano Binaghi, Giuseppe Canonaco, Matteo Pirotta, and Marcello
  Restelli.
\newblock Stochastic variance-reduced policy gradient.
\newblock {arXiv}:1806.05618, 2018.

\bibitem[Xu et~al.(2020)Xu, Gao, and Gu]{xu2020improvedUAI}
Pan Xu, Felicia Gao, and Quanquan Gu.
\newblock An improved convergence analysis of stochastic variance-reduced
  policy gradient.
\newblock In \emph{Uncertainty in Artificial Intelligence}, pages 541--551.
  PMLR, 2020.

\bibitem[Cao et~al.(2019)Cao, Xiao, Cyr, Zhou, Park, Rampazzi, Chen, Fu, and
  Mao]{cao2019adversarialAttack-AV}
Yulong Cao, Chaowei Xiao, Benjamin Cyr, Yimeng Zhou, Won Park, Sara Rampazzi,
  Qi~Alfred Chen, Kevin Fu, and Z~Morley Mao.
\newblock Adversarial sensor attack on lidar-based perception in autonomous
  driving.
\newblock In \emph{Proceedings of the 2019 ACM SIGSAC Conference on Computer
  and Communications Security}, pages 2267--2281, 2019.

\bibitem[Lamport et~al.(1982)Lamport, SHOSTAK, and PEASE]{lamport1982byzantine}
LESLIE Lamport, ROBERT SHOSTAK, and MARSHALL PEASE.
\newblock The byzantine generals problem.
\newblock \emph{ACM Transactions on Programming Languages and Systems},
  4\penalty0 (3):\penalty0 382--401, 1982.

\bibitem[Lynch(1996)]{distributed-algorithms-book}
Nancy~A. Lynch.
\newblock \emph{Distributed Algorithms}.
\newblock Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 1996.
\newblock ISBN 9780080504704.

\bibitem[Castro and Liskov(1999)]{castro1999practicalByzantine}
Miguel Castro and Barbara Liskov.
\newblock Practical byzantine fault tolerance.
\newblock In \emph{OSDI}, volume~99, pages 173--186, 1999.

\bibitem[Li et~al.(2020{\natexlab{b}})Li, Sahu, Talwalkar, and
  Smith]{li2020federatedSurvey2}
Tian Li, Anit~Kumar Sahu, Ameet Talwalkar, and Virginia Smith.
\newblock Federated learning: Challenges, methods, and future directions.
\newblock \emph{IEEE Signal Processing Magazine}, 37\penalty0 (3):\penalty0
  50--60, 2020{\natexlab{b}}.

\bibitem[Cauchy(1847)]{cauchy1847GD}
Augustin Cauchy.
\newblock M{\'e}thode g{\'e}n{\'e}rale pour la r{\'e}solution des systemes
  dâ€™{\'e}quations simultan{\'e}es.
\newblock \emph{Comp. Rend. Sci. Paris}, 25\penalty0 (1847):\penalty0 536--538,
  1847.

\bibitem[Nesterov(2013)]{nesterov2013introductory}
Yurii Nesterov.
\newblock \emph{Introductory lectures on convex optimization: A basic course},
  volume~87.
\newblock Springer Science \& Business Media, 2013.

\bibitem[Robbins and Monro(1951)]{robbins1951stochastic}
Herbert Robbins and Sutton Monro.
\newblock A stochastic approximation method.
\newblock \emph{The annals of mathematical statistics}, pages 400--407, 1951.

\bibitem[Bottou and Cun(2003)]{bottou2003sgd}
L{\'e}on Bottou and Yann Cun.
\newblock Large scale online learning.
\newblock \emph{Advances in neural information processing systems},
  16:\penalty0 217--224, 2003.

\bibitem[Nemirovsky and Yudin(1983)]{nemirovsky1983sgdConvergence}
Arkadi~Semenovich Nemirovsky and David~Borisovich Yudin.
\newblock Problem complexity and method efficiency in optimization.
\newblock 1983.

\bibitem[Johnson and Zhang(2013)]{johnson2013svrg1}
Rie Johnson and Tong Zhang.
\newblock Accelerating stochastic gradient descent using predictive variance
  reduction.
\newblock In \emph{Advances in neural information processing systems}, pages
  315--323, 2013.

\bibitem[Xiao and Zhang(2014)]{xiao2014svrg4}
Lin Xiao and Tong Zhang.
\newblock A proximal stochastic gradient method with progressive variance
  reduction.
\newblock \emph{SIAM Journal on Optimization}, 24\penalty0 (4):\penalty0
  2057--2075, 2014.

\bibitem[Allen-Zhu and Hazan(2016{\natexlab{a}})]{allen2016svrg2}
Zeyuan Allen-Zhu and Elad Hazan.
\newblock Variance reduction for faster non-convex optimization.
\newblock In \emph{International conference on machine learning}, pages
  699--707, 2016{\natexlab{a}}.

\bibitem[Reddi et~al.(2016)Reddi, Hefny, Sra, Poczos, and
  Smola]{reddi2016svrg3}
Sashank~J Reddi, Ahmed Hefny, Suvrit Sra, Barnabas Poczos, and Alex Smola.
\newblock Stochastic variance reduction for nonconvex optimization.
\newblock In \emph{International conference on machine learning}, pages
  314--323, 2016.

\bibitem[Lei and Jordan(2016)]{lei2016scsg1}
Lihua Lei and Michael~I Jordan.
\newblock Less than a single pass: Stochastically controlled stochastic
  gradient method.
\newblock {arXiv}:1609.03261, 2016.

\bibitem[Lei et~al.(2017)Lei, Ju, Chen, and Jordan]{lei2017scsg2}
Lihua Lei, Cheng Ju, Jianbo Chen, and Michael~I Jordan.
\newblock Non-convex finite-sum optimization via scsg methods.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  2348--2358, 2017.

\bibitem[Sutton and Barto(2018)]{sutton2018reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock \emph{Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem[Schulman et~al.(2015)Schulman, Levine, Abbeel, Jordan, and
  Moritz]{schulman2015TRPO}
John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp
  Moritz.
\newblock Trust region policy optimization.
\newblock In \emph{International conference on machine learning}, pages
  1889--1897, 2015.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and
  Klimov]{schulman2017PPO}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock {arXiv}:1707.06347, 2017.

\bibitem[Williams(1992)]{williams1992REINFORCE}
Ronald~J Williams.
\newblock Simple statistical gradient-following algorithms for connectionist
  reinforcement learning.
\newblock \emph{Machine learning}, 8\penalty0 (3-4):\penalty0 229--256, 1992.

\bibitem[Baxter and Bartlett(2001)]{baxter2001GPOMDP}
Jonathan Baxter and Peter~L Bartlett.
\newblock Infinite-horizon policy-gradient estimation.
\newblock \emph{Journal of Artificial Intelligence Research}, 15:\penalty0
  319--350, 2001.

\bibitem[Du et~al.(2017)Du, Chen, Li, Xiao, and Zhou]{du2017SVRGPolicyEval}
Simon~S Du, Jianshu Chen, Lihong Li, Lin Xiao, and Dengyong Zhou.
\newblock Stochastic variance reduction methods for policy evaluation.
\newblock {arXiv}:1702.07944, 2017.

\bibitem[Peng et~al.(2020)Peng, Touati, Vincent, and Precup]{ijcai2020-0374}
Zilun Peng, Ahmed Touati, Pascal Vincent, and Doina Precup.
\newblock Svrg for policy evaluation with fewer gradient evaluations.
\newblock In \emph{Proceedings of the Twenty-Ninth International Joint
  Conference on Artificial Intelligence, {IJCAI-20}}, pages 2697--2703.
  International Joint Conferences on Artificial Intelligence Organization,
  2020.

\bibitem[Xu et~al.(2017)Xu, Liu, and Peng]{xu2017SVRGTRPO}
Tianbing Xu, Qiang Liu, and Jian Peng.
\newblock Stochastic variance reduction for policy gradient estimation.
\newblock {arXiv}:1710.06034, 2017.

\bibitem[Blanchard et~al.(2017)Blanchard, El~Mhamdi, Guerraoui, and
  Stainer]{blanchard2017machine-Krum}
Peva Blanchard, El~Mahdi El~Mhamdi, Rachid Guerraoui, and Julien Stainer.
\newblock Machine learning with adversaries: Byzantine tolerant gradient
  descent.
\newblock In \emph{Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, pages 118--128, 2017.

\bibitem[Yin et~al.(2018)Yin, Chen, Ramchandran, and
  Bartlett]{yin2018byzantine}
Dong Yin, Yudong Chen, Kannan Ramchandran, and Peter Bartlett.
\newblock Byzantine-robust distributed learning: Towards optimal statistical
  rates.
\newblock {arXiv}:1803.01498, 2018.

\bibitem[Alistarh et~al.(2018)Alistarh, Allen-Zhu, and
  Li]{alistarh2018byzantine}
Dan Alistarh, Zeyuan Allen-Zhu, and Jerry Li.
\newblock Byzantine stochastic gradient descent.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  4613--4623, 2018.

\bibitem[Baruch et~al.(2019)Baruch, Baruch, and
  Goldberg]{baruch2019Byzantine-VA-attack}
Gilad Baruch, Moran Baruch, and Yoav Goldberg.
\newblock A little is enough: Circumventing defenses for distributed learning.
\newblock In H.~Wallach, H.~Larochelle, A.~Beygelzimer, F.~d\textquotesingle
  Alch\'{e}-Buc, E.~Fox, and R.~Garnett, editors, \emph{Advances in Neural
  Information Processing Systems}, volume~32. Curran Associates, Inc., 2019.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2019/file/ec1c59141046cd1866bbbcdfb6ae31d4-Paper.pdf}.

\bibitem[Khanduri et~al.(2019)Khanduri, Bulusu, Sharma, and
  Varshney]{khanduri2019byzantine}
Prashant Khanduri, Saikiran Bulusu, Pranay Sharma, and Pramod~K Varshney.
\newblock Byzantine resilient non-convex svrg with distributed batch gradient
  computations.
\newblock {arXiv}:1912.04531, 2019.

\bibitem[Allen-Zhu et~al.(2020)Allen-Zhu, Ebrahimian, Li, and
  Alistarh]{allen2020byzantine-iclr}
Zeyuan Allen-Zhu, Faeze Ebrahimian, Jerry Li, and Dan Alistarh.
\newblock Byzantine-resilient non-convex stochastic gradient descent.
\newblock {arXiv}:2012.14368, 2020.

\bibitem[Xie et~al.(2019)Xie, Koyejo, and Gupta]{xie2019zeno-byzantine}
Cong Xie, Sanmi Koyejo, and Indranil Gupta.
\newblock Zeno: Distributed stochastic gradient descent with suspicion-based
  fault-tolerance.
\newblock In \emph{International Conference on Machine Learning}, pages
  6893--6901. PMLR, 2019.

\bibitem[Metelli et~al.(2018)Metelli, Papini, Faccio, and
  Restelli]{2018importanceSampling}
Alberto~Maria Metelli, Matteo Papini, Francesco Faccio, and Marcello Restelli.
\newblock Policy optimization via importance sampling.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  5442--5454, 2018.

\bibitem[Pirotta et~al.(2015)Pirotta, Restelli, and
  Bascetta]{pirotta2015Smooth}
Matteo Pirotta, Marcello Restelli, and Luca Bascetta.
\newblock Policy gradient in lipschitz markov decision processes.
\newblock \emph{Machine Learning}, 100\penalty0 (2-3):\penalty0 255--283, 2015.

\bibitem[Allen-Zhu and Hazan(2016{\natexlab{b}})]{allen2016variance}
Zeyuan Allen-Zhu and Elad Hazan.
\newblock Variance reduction for faster non-convex optimization.
\newblock In \emph{International conference on machine learning}, pages
  699--707. PMLR, 2016{\natexlab{b}}.

\bibitem[Albanie(2019)]{albanie2019euclidean}
Samuel Albanie.
\newblock Euclidean distance matrix trick.
\newblock Technical report, 2019.
\newblock URL
  \url{https://www.robots.ox.ac.uk/~albanie/notes/Euclidean_distance_trick.pdf}.

\bibitem[Barto et~al.(1983)Barto, Sutton, and Anderson]{barto1983CartPole}
Andrew~G Barto, Richard~S Sutton, and Charles~W Anderson.
\newblock Neuronlike adaptive elements that can solve difficult learning
  control problems.
\newblock \emph{IEEE transactions on systems, man, and cybernetics}, \penalty0
  (5):\penalty0 834--846, 1983.

\bibitem[Duan et~al.(2016)Duan, Chen, Houthooft, Schulman, and
  Abbeel]{duan2016TasksOnMujoco}
Yan Duan, Xi~Chen, Rein Houthooft, John Schulman, and Pieter Abbeel.
\newblock Benchmarking deep reinforcement learning for continuous control.
\newblock In \emph{International Conference on Machine Learning}, pages
  1329--1338, 2016.

\bibitem[Dubey and Pentland(2020)]{dubey2020differentially}
Abhimanyu Dubey and Alex Pentland.
\newblock Differentially-private federated linear bandits.
\newblock In \emph{Proc. {NeurIPS}}, 2020.

\bibitem[Shi et~al.(2021)Shi, Shen, and Yang]{shi2021federated}
Chengshuai Shi, Cong Shen, and Jing Yang.
\newblock Federated multi-armed bandits with personalization.
\newblock In \emph{Proc. {AISTATS}}, pages 2917--2925. PMLR, 2021.

\bibitem[Zhu et~al.(2021)Zhu, Zhu, Liu, and Liu]{zhu2021federated}
Zhaowei Zhu, Jingxuan Zhu, Ji~Liu, and Yang Liu.
\newblock Federated bandit: {A} gossiping approach.
\newblock In \emph{Abstract Proceedings of the 2021 ACM
  SIGMETRICS/International Conference on Measurement and Modeling of Computer
  Systems}, pages 3--4, 2021.

\bibitem[Dai et~al.(2020)Dai, Low, and Jaillet]{dai2020federated}
Zhongxiang Dai, Bryan Kian~Hsiang Low, and Patrick Jaillet.
\newblock Federated {Bayesian} optimization via {Thompson} sampling.
\newblock In \emph{Proc. {NeurIPS}}, 2020.

\bibitem[Dai et~al.(2021)Dai, Low, and Jaillet]{dai2021differentially}
Zhongxiang Dai, Bryan Kian~Hsiang Low, and Patrick Jaillet.
\newblock Differentially private federated {Bayesian} optimization with
  distributed exploration.
\newblock In \emph{Proc. {NeurIPS}}, 2021.

\bibitem[Sim et~al.(2021)Sim, Zhang, Low, and Jaillet]{sim2021collaborative}
Rachael Hwee~Ling Sim, Yehong Zhang, Bryan Kian~Hsiang Low, and Patrick
  Jaillet.
\newblock Collaborative {Bayesian} optimization with fair regret.
\newblock In \emph{Proc. {ICML}}, pages 9691--9701. PMLR, 2021.

\bibitem[Xu et~al.(2021{\natexlab{a}})Xu, Lyu, Ma, Miao, Foo, and
  Low]{xu2021gradient}
Xinyi Xu, Lingjuan Lyu, Xingjun Ma, Chenglin Miao, Chuan-Sheng Foo, and Bryan
  Kian~Hsiang Low.
\newblock Gradient driven rewards to guarantee fairness in collaborative
  machine learning.
\newblock In \emph{Proc. {NeurIPS}}, 2021{\natexlab{a}}.

\bibitem[Xu et~al.(2021{\natexlab{b}})Xu, Wu, Foo, and Low]{xu2021validation}
Xinyi Xu, Zhaoxuan Wu, Chuan-Sheng Foo, and Bryan Kian~Hsiang Low.
\newblock Validation free and replication robust volume-based data valuation.
\newblock In \emph{Proc. {NeurIPS}}, 2021{\natexlab{b}}.

\bibitem[Hoang et~al.(2021)Hoang, Hong, Xiao, Low, and Sun]{hoang2021aid}
Trong~Nghia Hoang, Shenda Hong, Cao Xiao, Bryan Kian~Hsiang Low, and Jimeng
  Sun.
\newblock Aid: {Active} distillation machine to leverage pre-trained black-box
  models in private data settings.
\newblock In \emph{Proc. {TheWebConf}}, pages 3569--3581, 2021.

\bibitem[Lam et~al.(2021)Lam, Hoang, Low, and Jaillet]{lam2021model}
Thanh~Chi Lam, Nghia Hoang, Bryan Kian~Hsiang Low, and Patrick Jaillet.
\newblock Model fusion for personalized learning.
\newblock In \emph{Proc. {ICML}}, pages 5948--5958. PMLR, 2021.

\bibitem[Sim et~al.(2020)Sim, Zhang, Chan, and Low]{sim2020collaborative}
Rachael Hwee~Ling Sim, Yehong Zhang, Mun~Choon Chan, and Bryan Kian~Hsiang Low.
\newblock Collaborative machine learning with incentive-aware model rewards.
\newblock In \emph{Proc. {ICML}}, pages 8927--8936. PMLR, 2020.

\bibitem[Hoang et~al.(2020)Hoang, Lam, Low, and Jaillet]{hoang2020learning}
Nghia Hoang, Thanh Lam, Bryan Kian~Hsiang Low, and Patrick Jaillet.
\newblock Learning task-agnostic embedding of multiple black-box experts for
  multi-task model fusion.
\newblock In \emph{Proc. {ICML}}, pages 4282--4292. PMLR, 2020.

\bibitem[Ouyang and Low(2020)]{ouyang2020gaussian}
Ruofei Ouyang and Bryan Kian~Hsiang Low.
\newblock Gaussian process decentralized data fusion meets transfer learning in
  large-scale distributed cooperative perception.
\newblock \emph{Autonomous Robots}, 44\penalty0 (3):\penalty0 359--376, 2020.

\bibitem[Hoang et~al.(2019{\natexlab{a}})Hoang, Hoang, Low, and
  Kingsford]{hoang2019collective}
Minh Hoang, Nghia Hoang, Bryan Kian~Hsiang Low, and Carleton Kingsford.
\newblock Collective model fusion for multiple black-box experts.
\newblock In \emph{Proc. {ICML}}, pages 2742--2750. PMLR, 2019{\natexlab{a}}.

\bibitem[Hoang et~al.(2019{\natexlab{b}})Hoang, Hoang, Low, and
  How]{hoang2019collective2}
Trong~Nghia Hoang, Quang~Minh Hoang, Bryan Kian~Hsiang Low, and Jonathan How.
\newblock Collective online learning of {Gaussian} processes in massive
  multi-agent systems.
\newblock In \emph{Proc. {AAAI}}, volume~33, pages 7850--7857,
  2019{\natexlab{b}}.

\bibitem[Ouyang and Low(2018)]{ouyang2018gaussian}
Ruofei Ouyang and Bryan Kian~Hsiang Low.
\newblock Gaussian process decentralized data fusion meets transfer learning in
  large-scale distributed cooperative perception.
\newblock In \emph{Proc. {AAAI}}, 2018.

\bibitem[Chen et~al.(2015)Chen, Low, Yao, and Jaillet]{chen2015gaussian}
Jie Chen, Bryan Kian~Hsiang Low, Yujian Yao, and Patrick Jaillet.
\newblock Gaussian process decentralized data fusion and active sensing for
  spatiotemporal traffic modeling and prediction in mobility-on-demand systems.
\newblock \emph{IEEE Transactions on Automation Science and Engineering},
  12\penalty0 (3):\penalty0 901--921, 2015.

\bibitem[Chen et~al.(2013)Chen, Low, and Tan]{chen2013gaussian}
Jie Chen, Bryan Kian~Hsiang Low, and Colin Keng-Yan Tan.
\newblock Gaussian process-based decentralized data fusion and active sensing
  for mobility-on-demand system.
\newblock In \emph{Proc. {RSS}}, 2013.

\bibitem[Chen et~al.(2012)Chen, Low, Tan, Oran, Jaillet, Dolan, and
  Sukhatme]{chen2012decentralized}
Jie Chen, Bryan Kian~Hsiang Low, Colin Keng-Yan Tan, Ali Oran, Patrick Jaillet,
  John~M Dolan, and Gaurav~S Sukhatme.
\newblock Decentralized data fusion and active sensing with mobile sensors for
  modeling and predicting spatiotemporal traffic phenomena.
\newblock In \emph{Proc. {UAI}}, 2012.

\bibitem[Pinelis(1994)]{pinelis1994optimumMartingale}
Iosif Pinelis.
\newblock Optimum bounds for the distributions of martingales in banach spaces.
\newblock \emph{The Annals of Probability}, pages 1679--1706, 1994.

\bibitem[Kingma and Ba(2014)]{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {arXiv}:1412.6980, 2014.

\end{thebibliography}
