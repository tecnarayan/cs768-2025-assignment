\begin{thebibliography}{49}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bossard et~al.(2014)Bossard, Guillaumin, and Van~Gool]{bossard2014food}
Bossard, L., Guillaumin, M., and Van~Gool, L.
\newblock Food-101--mining discriminative components with random forests.
\newblock In \emph{European Conference on Computer Vision}, pp.\  446--461. Springer, 2014.

\bibitem[Cimpoi et~al.(2014)Cimpoi, Maji, Kokkinos, Mohamed, and Vedaldi]{cimpoi2014describing}
Cimpoi, M., Maji, S., Kokkinos, I., Mohamed, S., and Vedaldi, A.
\newblock Describing textures in the wild.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pp.\  3606--3613, 2014.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and Fei-Fei]{deng2009imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE Conference on Computer Vision and Pattern Recognition}, pp.\  248--255. IEEE, 2009.

\bibitem[Fei-Fei et~al.(2004)Fei-Fei, Fergus, and Perona]{fei2004learning}
Fei-Fei, L., Fergus, R., and Perona, P.
\newblock Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories.
\newblock In \emph{2004 Conference on Computer Vision and Pattern Recognition workshop}, pp.\  178--178. IEEE, 2004.

\bibitem[Goyal et~al.(2023)Goyal, Kumar, Garg, Kolter, and Raghunathan]{goyal2023finetune}
Goyal, S., Kumar, A., Garg, S., Kolter, Z., and Raghunathan, A.
\newblock Finetune like you pretrain: Improved finetuning of zero-shot vision models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  19338--19347, 2023.

\bibitem[Guo et~al.(2017)Guo, Pleiss, Sun, and Weinberger]{guo2017calibration}
Guo, C., Pleiss, G., Sun, Y., and Weinberger, K.~Q.
\newblock On calibration of modern neural networks.
\newblock In \emph{International Conference on Machine Learning}, pp.\  1321--1330. PMLR, 2017.

\bibitem[Helber et~al.(2019)Helber, Bischke, Dengel, and Borth]{helber2019eurosat}
Helber, P., Bischke, B., Dengel, A., and Borth, D.
\newblock Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification.
\newblock \emph{IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 12\penalty0 (7):\penalty0 2217--2226, 2019.

\bibitem[Hu et~al.(2022)Hu, Gan, Wang, Yang, Liu, Lu, and Wang]{hu2022scaling}
Hu, X., Gan, Z., Wang, J., Yang, Z., Liu, Z., Lu, Y., and Wang, L.
\newblock Scaling up vision-language pre-training for image captioning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  17980--17989, 2022.

\bibitem[Jia et~al.(2021)Jia, Yang, Xia, Chen, Parekh, Pham, Le, Sung, Li, and Duerig]{jia2021scaling}
Jia, C., Yang, Y., Xia, Y., Chen, Y.-T., Parekh, Z., Pham, H., Le, Q., Sung, Y.-H., Li, Z., and Duerig, T.
\newblock Scaling up visual and vision-language representation learning with noisy text supervision.
\newblock In \emph{International Conference on Machine Learning}, pp.\  4904--4916. PMLR, 2021.

\bibitem[Jiang et~al.(2018)Jiang, Kim, Guan, and Gupta]{jiang2018trust}
Jiang, H., Kim, B., Guan, M., and Gupta, M.
\newblock To trust or not to trust a classifier.
\newblock \emph{Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem[Jiang et~al.(2024)Jiang, Cheng, Chen, Wang, and Wei]{jiang2024diverse}
Jiang, W., Cheng, H., Chen, M., Wang, C., and Wei, H.
\newblock {DOS}: Diverse outlier sampling for out-of-distribution detection.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.

\bibitem[Joy et~al.(2023)Joy, Pinto, Lim, Torr, and Dokania]{joy2023sample}
Joy, T., Pinto, F., Lim, S.-N., Torr, P.~H., and Dokania, P.~K.
\newblock Sample-dependent adaptive temperature scaling for improved calibration.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~37, pp.\  14919--14926, 2023.

\bibitem[Khattak et~al.(2023{\natexlab{a}})Khattak, Rasheed, Maaz, Khan, and Khan]{khattak2023maple}
Khattak, M.~U., Rasheed, H., Maaz, M., Khan, S., and Khan, F.~S.
\newblock Maple: Multi-modal prompt learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  19113--19122, 2023{\natexlab{a}}.

\bibitem[Khattak et~al.(2023{\natexlab{b}})Khattak, Wasim, Naseer, Khan, Yang, and Khan]{khattak2023self}
Khattak, M.~U., Wasim, S.~T., Naseer, M., Khan, S., Yang, M.-H., and Khan, F.~S.
\newblock Self-regulating prompts: Foundational model adaptation without forgetting.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  15190--15200, 2023{\natexlab{b}}.

\bibitem[Krause et~al.(2013)Krause, Stark, Deng, and Fei-Fei]{krause20133d}
Krause, J., Stark, M., Deng, J., and Fei-Fei, L.
\newblock 3d object representations for fine-grained categorization.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer Vision Workshops}, pp.\  554--561, 2013.

\bibitem[LeVine et~al.(2023)LeVine, Pikus, Raj, and Gil]{levine2023enabling}
LeVine, W., Pikus, B., Raj, P., and Gil, F.~A.
\newblock Enabling calibration in the zero-shot inference of large vision-language models.
\newblock \emph{ICLR workshop on Pitfalls of limited data and computation for Trustworthy ML}, 2023.

\bibitem[Liang et~al.(2022)Liang, Zhang, Kwon, Yeung, and Zou]{liang2022mind}
Liang, V.~W., Zhang, Y., Kwon, Y., Yeung, S., and Zou, J.~Y.
\newblock Mind the gap: Understanding the modality gap in multi-modal contrastive representation learning.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 17612--17625, 2022.

\bibitem[Liu et~al.(2023)Liu, Padhy, Ren, Lin, Wen, Jerfel, Nado, Snoek, Tran, and Lakshminarayanan]{liu2023simple}
Liu, J.~Z., Padhy, S., Ren, J., Lin, Z., Wen, Y., Jerfel, G., Nado, Z., Snoek, J., Tran, D., and Lakshminarayanan, B.
\newblock A simple approach to improve single-model deep uncertainty via distance-awareness.
\newblock \emph{Journal of Machine Learning Research}, 24\penalty0 (42):\penalty0 1--63, 2023.

\bibitem[Lu et~al.(2022)Lu, Liu, Zhang, Liu, and Tian]{lu2022prompt}
Lu, Y., Liu, J., Zhang, Y., Liu, Y., and Tian, X.
\newblock Prompt distribution learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  5206--5215, 2022.

\bibitem[Maji et~al.(2013)Maji, Rahtu, Kannala, Blaschko, and Vedaldi]{maji2013fine}
Maji, S., Rahtu, E., Kannala, J., Blaschko, M., and Vedaldi, A.
\newblock Fine-grained visual classification of aircraft.
\newblock \emph{arXiv preprint arXiv:1306.5151}, 2013.

\bibitem[Minderer et~al.(2021)Minderer, Djolonga, Romijnders, Hubis, Zhai, Houlsby, Tran, and Lucic]{minderer2021revisiting}
Minderer, M., Djolonga, J., Romijnders, R., Hubis, F., Zhai, X., Houlsby, N., Tran, D., and Lucic, M.
\newblock Revisiting the calibration of modern neural networks.
\newblock \emph{Advances in Neural Information Processing Systems}, 34:\penalty0 15682--15694, 2021.

\bibitem[Naeem et~al.(2023)Naeem, Khan, Xian, Afzal, Stricker, Van~Gool, and Tombari]{naeem2023i2mvformer}
Naeem, M.~F., Khan, M. G. Z.~A., Xian, Y., Afzal, M.~Z., Stricker, D., Van~Gool, L., and Tombari, F.
\newblock I2mvformer: Large language model generated multi-view document supervision for zero-shot image classification.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  15169--15179, 2023.

\bibitem[Nilsback \& Zisserman(2008)Nilsback and Zisserman]{nilsback2008automated}
Nilsback, M.-E. and Zisserman, A.
\newblock Automated flower classification over a large number of classes.
\newblock In \emph{2008 Sixth Indian Conference on Computer Vision, Graphics \& Image Processing}, pp.\  722--729. IEEE, 2008.

\bibitem[Nixon et~al.(2019)Nixon, Dusenberry, Zhang, Jerfel, and Tran]{nixon2019measuring}
Nixon, J., Dusenberry, M.~W., Zhang, L., Jerfel, G., and Tran, D.
\newblock Measuring calibration in deep learning.
\newblock In \emph{Computer Vision and Pattern Recognition workshops}, volume~2, 2019.

\bibitem[Oh et~al.(2023)Oh, Kim, Lim, Park, Jeong, Cheng, and Song]{oh2023towards}
Oh, C., Kim, M., Lim, H., Park, J., Jeong, E., Cheng, Z.-Q., and Song, K.
\newblock Towards calibrated robust fine-tuning of vision-language models.
\newblock In \emph{NeurIPS 2023 Workshop on Distribution Shifts: New Frontiers with Foundation Models}, 2023.

\bibitem[Parelli et~al.(2023)Parelli, Delitzas, Hars, Vlassis, Anagnostidis, Bachmann, and Hofmann]{parelli2023clip}
Parelli, M., Delitzas, A., Hars, N., Vlassis, G., Anagnostidis, S., Bachmann, G., and Hofmann, T.
\newblock Clip-guided vision-language pre-training for question answering in 3d scenes.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  5606--5611, 2023.

\bibitem[Parkhi et~al.(2012)Parkhi, Vedaldi, Zisserman, and Jawahar]{parkhi2012cats}
Parkhi, O.~M., Vedaldi, A., Zisserman, A., and Jawahar, C.
\newblock Cats and dogs.
\newblock In \emph{2012 IEEE Conference on Computer Vision and Pattern Recognition}, pp.\  3498--3505. IEEE, 2012.

\bibitem[Radford et~al.(2021)Radford, Kim, Hallacy, Ramesh, Goh, Agarwal, Sastry, Askell, Mishkin, Clark, et~al.]{radford2021learning}
Radford, A., Kim, J.~W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., et~al.
\newblock Learning transferable visual models from natural language supervision.
\newblock In \emph{International Conference on Machine Learning}, pp.\  8748--8763. PMLR, 2021.

\bibitem[Roelofs et~al.(2022)Roelofs, Cain, Shlens, and Mozer]{roelofs2022mitigating}
Roelofs, R., Cain, N., Shlens, J., and Mozer, M.~C.
\newblock Mitigating bias in calibration error estimation.
\newblock In \emph{International Conference on Artificial Intelligence and Statistics}, pp.\  4036--4054. PMLR, 2022.

\bibitem[Shen et~al.(2024)Shen, Yang, Zhang, Zhai, Gonzalez, Keutzer, and Darrell]{shen2024multitask}
Shen, S., Yang, S., Zhang, T., Zhai, B., Gonzalez, J.~E., Keutzer, K., and Darrell, T.
\newblock Multitask vision-language prompt tuning.
\newblock In \emph{Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision}, pp.\  5656--5667, 2024.

\bibitem[Soomro et~al.(2012)Soomro, Zamir, and Shah]{soomro2012ucf101}
Soomro, K., Zamir, A.~R., and Shah, M.
\newblock Ucf101: A dataset of 101 human actions classes from videos in the wild.
\newblock \emph{arXiv preprint arXiv:1212.0402}, 2012.

\bibitem[Sun et~al.(2022)Sun, Ming, Zhu, and Li]{sun2022out}
Sun, Y., Ming, Y., Zhu, X., and Li, Y.
\newblock Out-of-distribution detection with deep nearest neighbors.
\newblock In \emph{International Conference on Machine Learning}, pp.\  20827--20840. PMLR, 2022.

\bibitem[Tomani et~al.(2022)Tomani, Cremers, and Buettner]{tomani2022parameterized}
Tomani, C., Cremers, D., and Buettner, F.
\newblock Parameterized temperature scaling for boosting the expressive power in post-hoc uncertainty calibration.
\newblock In \emph{European Conference on Computer Vision}, pp.\  555--569. Springer, 2022.

\bibitem[Tu et~al.(2023)Tu, Deng, and Gedeon]{tu2023closer}
Tu, W., Deng, W., and Gedeon, T.
\newblock A closer look at the robustness of contrastive language-image pre-training (clip).
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.

\bibitem[Wang et~al.(2023{\natexlab{a}})Wang, Xie, Wu, Jia, and Li]{wang2023controllable}
Wang, N., Xie, J., Wu, J., Jia, M., and Li, L.
\newblock Controllable image captioning via prompting.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~37, pp.\  2617--2625, 2023{\natexlab{a}}.

\bibitem[Wang et~al.(2023{\natexlab{b}})Wang, Bao, Dong, Bjorck, Peng, Liu, Aggarwal, Mohammed, Singhal, Som, et~al.]{wang2023image}
Wang, W., Bao, H., Dong, L., Bjorck, J., Peng, Z., Liu, Q., Aggarwal, K., Mohammed, O.~K., Singhal, S., Som, S., et~al.
\newblock Image as a foreign language: Beit pretraining for vision and vision-language tasks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  19175--19186, 2023{\natexlab{b}}.

\bibitem[Xiao et~al.(2010)Xiao, Hays, Ehinger, Oliva, and Torralba]{xiao2010sun}
Xiao, J., Hays, J., Ehinger, K.~A., Oliva, A., and Torralba, A.
\newblock Sun database: Large-scale scene recognition from abbey to zoo.
\newblock In \emph{2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition}, pp.\  3485--3492. IEEE, 2010.

\bibitem[Xiong et~al.(2023)Xiong, Deng, Koh, Wu, Li, Xu, and Hooi]{xiong2023proximity}
Xiong, M., Deng, A., Koh, P.~W., Wu, J., Li, S., Xu, J., and Hooi, B.
\newblock Proximity-informed calibration for deep neural networks.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.

\bibitem[Yao et~al.(2023)Yao, Zhang, and Xu]{yao2023visual}
Yao, H., Zhang, R., and Xu, C.
\newblock Visual-language prompt tuning with knowledge-guided context optimization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  6757--6767, 2023.

\bibitem[Yu et~al.(2022)Yu, Bates, Ma, and Jordan]{yu2022robust}
Yu, Y., Bates, S., Ma, Y., and Jordan, M.
\newblock Robust calibration with multi-domain temperature scaling.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 27510--27523, 2022.

\bibitem[Yuksekgonul et~al.(2023)Yuksekgonul, Zhang, Zou, and Guestrin]{yuksekgonul2023beyond}
Yuksekgonul, M., Zhang, L., Zou, J., and Guestrin, C.
\newblock Beyond confidence: Reliable models should also consider atypicality.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.

\bibitem[Zadrozny \& Elkan(2001)Zadrozny and Elkan]{zadrozny2001obtaining}
Zadrozny, B. and Elkan, C.
\newblock Obtaining calibrated probability estimates from decision trees and naive bayesian classifiers.
\newblock In \emph{International Conference on Machine Learning}, volume~1, pp.\  609--616, 2001.

\bibitem[Zadrozny \& Elkan(2002)Zadrozny and Elkan]{zadrozny2002transforming}
Zadrozny, B. and Elkan, C.
\newblock Transforming classifier scores into accurate multiclass probability estimates.
\newblock In \emph{Proceedings of the eighth ACM SIGKDD International Conference on Knowledge Discovery and Data mining}, pp.\  694--699, 2002.

\bibitem[Zang et~al.(2022)Zang, Li, Zhou, Huang, and Loy]{zang2022unified}
Zang, Y., Li, W., Zhou, K., Huang, C., and Loy, C.~C.
\newblock Unified vision and language prompt learning.
\newblock \emph{arXiv preprint arXiv:2210.07225}, 2022.

\bibitem[Zhang et~al.(2020)Zhang, Kailkhura, and Han]{zhang2020mix}
Zhang, J., Kailkhura, B., and Han, T. Y.-J.
\newblock Mix-n-match: Ensemble and compositional methods for uncertainty calibration in deep learning.
\newblock In \emph{International Conference on Machine Learning}, pp.\  11117--11128. PMLR, 2020.

\bibitem[Zhang et~al.(2023)Zhang, Huang, Jin, and Lu]{zhang2023vision}
Zhang, J., Huang, J., Jin, S., and Lu, S.
\newblock Vision-language models for vision tasks: A survey.
\newblock \emph{arXiv preprint arXiv:2304.00685}, 2023.

\bibitem[Zhou et~al.(2022{\natexlab{a}})Zhou, Yang, Loy, and Liu]{zhou2022conditional}
Zhou, K., Yang, J., Loy, C.~C., and Liu, Z.
\newblock Conditional prompt learning for vision-language models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pp.\  16816--16825, 2022{\natexlab{a}}.

\bibitem[Zhou et~al.(2022{\natexlab{b}})Zhou, Yang, Loy, and Liu]{zhou2022learning}
Zhou, K., Yang, J., Loy, C.~C., and Liu, Z.
\newblock Learning to prompt for vision-language models.
\newblock \emph{International Journal of Computer Vision}, 130\penalty0 (9):\penalty0 2337--2348, 2022{\natexlab{b}}.

\bibitem[Zhu et~al.(2023)Zhu, Niu, Han, Wu, and Zhang]{zhu2023prompt}
Zhu, B., Niu, Y., Han, Y., Wu, Y., and Zhang, H.
\newblock Prompt-aligned gradient for prompt tuning.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pp.\  15659--15669, 2023.

\end{thebibliography}
