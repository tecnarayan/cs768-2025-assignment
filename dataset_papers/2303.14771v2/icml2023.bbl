\begin{thebibliography}{44}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahn et~al.(2021)Ahn, Kwak, Lim, Bang, Kim, and Moon]{Ahn_2021_ICCV}
Ahn, H., Kwak, J., Lim, S., Bang, H., Kim, H., and Moon, T.
\newblock Ss-il: Separated softmax for incremental learning.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pp.\  844--853, October 2021.

\bibitem[Aljundi et~al.(2016)Aljundi, Chakravarty, and
  Tuytelaars]{aljundi2016expert}
Aljundi, R., Chakravarty, P., and Tuytelaars, T.
\newblock Expert gate: Lifelong learning with a network of experts.
\newblock In \emph{IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2016.

\bibitem[Aljundi et~al.(2019)Aljundi, Caccia, Belilovsky, Caccia, Charlin, and
  Tuytelaars]{aljundi2019online}
Aljundi, R., Caccia, L., Belilovsky, E., Caccia, M., Charlin, L., and
  Tuytelaars, T.
\newblock Online continual learning with maximally interfered retrieval.
\newblock In \emph{Advances in Neural Information Processing (NeurIPS)}, 2019.

\bibitem[Asadi et~al.(2022)Asadi, Mudur, and Belilovsky]{asadi2022tackling}
Asadi, N., Mudur, S., and Belilovsky, E.
\newblock Tackling online one-class incremental learning by removing negative
  contrasts.
\newblock \emph{arXiv preprint arXiv:2203.13307}, 2022.

\bibitem[Barletti et~al.(2022)Barletti, Biondi, Pernici, Bruni, and
  Del~Bimbo]{barletti2022contrastive}
Barletti, T., Biondi, N., Pernici, F., Bruni, M., and Del~Bimbo, A.
\newblock Contrastive supervised distillation for continual representation
  learning.
\newblock In \emph{International Conference on Image Analysis and Processing},
  pp.\  597--609. Springer, 2022.

\bibitem[Boudiaf et~al.(2020)Boudiaf, Rony, Ziko, Granger, Pedersoli,
  Piantanida, and Ayed]{boudiaf2020unifying}
Boudiaf, M., Rony, J., Ziko, I.~M., Granger, E., Pedersoli, M., Piantanida, P.,
  and Ayed, I.~B.
\newblock A unifying mutual information view of metric learning: cross-entropy
  vs. pairwise losses.
\newblock In \emph{European conference on computer vision}, pp.\  548--564.
  Springer, 2020.

\bibitem[Caccia et~al.(2022)Caccia, Aljundi, Asadi, Tuytelaars, Pineau, and
  Belilovsky]{caccia2022new}
Caccia, L., Aljundi, R., Asadi, N., Tuytelaars, T., Pineau, J., and Belilovsky,
  E.
\newblock New insights on reducing abrupt representation change in online
  continual learning.
\newblock \emph{arXiv preprint arXiv:2203.03798}, 2022.

\bibitem[Caccia et~al.(2020)Caccia, Rodriguez, Ostapenko, Normandin, Lin,
  Caccia, Laradji, Rish, Lacoste, Vazquez, et~al.]{caccia2020online}
Caccia, M., Rodriguez, P., Ostapenko, O., Normandin, F., Lin, M., Caccia, L.,
  Laradji, I., Rish, I., Lacoste, A., Vazquez, D., et~al.
\newblock Online fast adaptation and knowledge accumulation: a new approach to
  continual learning.
\newblock \emph{arXiv preprint arXiv:2003.05856}, 2020.

\bibitem[Cha et~al.(2021)Cha, Lee, and Shin]{cha2021co2l}
Cha, H., Lee, J., and Shin, J.
\newblock Co2l: Contrastive continual learning.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  9516--9525, 2021.

\bibitem[Chaudhry et~al.()Chaudhry, Ranzato, Rohrbach, and
  Elhoseiny]{chaudhry2018efficient}
Chaudhry, A., Ranzato, M., Rohrbach, M., and Elhoseiny, M.
\newblock Efficient lifelong learning with a-gem.
\newblock In \emph{ICLR 2019}.

\bibitem[Chaudhry et~al.(2018)Chaudhry, Dokania, Ajanthan, and
  Torr]{chaudhry2018riemannian}
Chaudhry, A., Dokania, P.~K., Ajanthan, T., and Torr, P.~H.
\newblock Riemannian walk for incremental learning: Understanding forgetting
  and intransigence.
\newblock \emph{arXiv preprint arXiv:1801.10112}, 2018.

\bibitem[Chaudhry et~al.(2019)Chaudhry, Rohrbach, Elhoseiny, Ajanthan, Dokania,
  Torr, and Ranzato]{chaudhry2019continual}
Chaudhry, A., Rohrbach, M., Elhoseiny, M., Ajanthan, T., Dokania, P.~K., Torr,
  P.~H., and Ranzato, M.
\newblock Continual learning with tiny episodic memories.
\newblock \emph{arXiv preprint arXiv:1902.10486}, 2019.

\bibitem[Chrabaszcz et~al.(2017)Chrabaszcz, Loshchilov, and
  Hutter]{chrabaszcz2017downsampled}
Chrabaszcz, P., Loshchilov, I., and Hutter, F.
\newblock A downsampled variant of imagenet as an alternative to the cifar
  datasets.
\newblock \emph{arXiv preprint arXiv:1707.08819}, 2017.

\bibitem[Davari et~al.(2022)Davari, Asadi, Mudur, Aljundi, and
  Belilovsky]{davari2022probing}
Davari, M., Asadi, N., Mudur, S., Aljundi, R., and Belilovsky, E.
\newblock Probing representation forgetting in supervised and unsupervised
  continual learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  16712--16721, 2022.

\bibitem[De~Lange \& Tuytelaars(2020)De~Lange and Tuytelaars]{de2020continual}
De~Lange, M. and Tuytelaars, T.
\newblock Continual prototype evolution: Learning online from non-stationary
  data streams.
\newblock \emph{arXiv preprint arXiv:2009.00919}, 2020.

\bibitem[De~Lange \& Tuytelaars(2021)De~Lange and Tuytelaars]{de2021continual}
De~Lange, M. and Tuytelaars, T.
\newblock Continual prototype evolution: Learning online from non-stationary
  data streams.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  8250--8259, 2021.

\bibitem[Deng et~al.(2009)Deng, Dong, Socher, Li, Li, and
  Fei-Fei]{deng2009imagenet}
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In \emph{2009 IEEE conference on computer vision and pattern
  recognition}, pp.\  248--255. Ieee, 2009.

\bibitem[Dohare et~al.(2021)Dohare, Mahmood, and Sutton]{dohare2021continual}
Dohare, S., Mahmood, A.~R., and Sutton, R.~S.
\newblock Continual backprop: Stochastic gradient descent with persistent
  randomness.
\newblock \emph{arXiv preprint arXiv:2108.06325}, 2021.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
He, K., Zhang, X., Ren, S., and Sun, J.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pp.\  770--778, 2016.

\bibitem[Hinton et~al.(2015)Hinton, Vinyals, and Dean]{hinton2015distilling}
Hinton, G., Vinyals, O., and Dean, J.
\newblock Distilling the knowledge in a neural network.
\newblock \emph{arXiv preprint arXiv:1503.02531}, 2015.

\bibitem[Husz{\'a}r(2017)]{huszar2017quadratic}
Husz{\'a}r, F.
\newblock On quadratic penalties in elastic weight consolidation.
\newblock \emph{arXiv preprint arXiv:1712.03847}, 2017.

\bibitem[Javed \& Shafait(2018)Javed and Shafait]{javed2018revisiting}
Javed, K. and Shafait, F.
\newblock Revisiting distillation and incremental classifier learning.
\newblock In \emph{Asian conference on computer vision}, pp.\  3--17. Springer,
  2018.

\bibitem[Ji et~al.(2020)Ji, Henriques, Tuytelaars, and
  Vedaldi]{ji2020automatic}
Ji, X., Henriques, J., Tuytelaars, T., and Vedaldi, A.
\newblock Automatic recall machines: Internal replay, continual learning and
  the brain.
\newblock \emph{arXiv preprint arXiv:2006.12323}, 2020.

\bibitem[Khosla et~al.(2020)Khosla, Teterwak, Wang, Sarna, Tian, Isola,
  Maschinot, Liu, and Krishnan]{khosla2020supervised}
Khosla, P., Teterwak, P., Wang, C., Sarna, A., Tian, Y., Isola, P., Maschinot,
  A., Liu, C., and Krishnan, D.
\newblock Supervised contrastive learning.
\newblock \emph{Advances in Neural Information Processing Systems},
  33:\penalty0 18661--18673, 2020.

\bibitem[Kirkpatrick et~al.(2016)Kirkpatrick, Pascanu, Rabinowitz, Veness,
  Desjardins, Rusu, Milan, Quan, Ramalho, Grabska-Barwinska,
  et~al.]{kirkpatrick2016overcoming}
Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu,
  A.~A., Milan, K., Quan, J., Ramalho, T., Grabska-Barwinska, A., et~al.
\newblock Overcoming catastrophic forgetting in neural networks.
\newblock \emph{arXiv preprint arXiv:1612.00796}, 2016.

\bibitem[Krizhevsky et~al.(2009)Krizhevsky, Hinton,
  et~al.]{krizhevsky2009learning}
Krizhevsky, A., Hinton, G., et~al.
\newblock Learning multiple layers of features from tiny images.
\newblock Technical report, University of Toronto, 2009.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and
  Hinton]{krizhevsky2012imagenet}
Krizhevsky, A., Sutskever, I., and Hinton, G.~E.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  1097--1105, 2012.

\bibitem[Li et~al.(2019)Li, Zhou, Wu, Socher, and Xiong]{li2019learn}
Li, X., Zhou, Y., Wu, T., Socher, R., and Xiong, C.
\newblock Learn to grow: A continual structure learning framework for
  overcoming catastrophic forgetting.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  3925--3934. PMLR, 2019.

\bibitem[Li \& Hoiem(2017)Li and Hoiem]{li2017learning}
Li, Z. and Hoiem, D.
\newblock Learning without forgetting.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 40\penalty0 (12):\penalty0 2935--2947, 2017.

\bibitem[Lopez-Paz et~al.(2017)]{lopez2017gradient}
Lopez-Paz, D. et~al.
\newblock Gradient episodic memory for continual learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  6467--6476, 2017.

\bibitem[McCloskey \& Cohen(1989)McCloskey and
  Cohen]{mccloskey1989catastrophic}
McCloskey, M. and Cohen, N.~J.
\newblock Catastrophic interference in connectionist networks: The sequential
  learning problem.
\newblock \emph{Psychology of learning and motivation}, 24:\penalty0 109--165,
  1989.

\bibitem[Mermillod et~al.(2013)Mermillod, Bugaiska, and
  Bonin]{mermillod2013stability}
Mermillod, M., Bugaiska, A., and Bonin, P.
\newblock The stability-plasticity dilemma: Investigating the continuum from
  catastrophic forgetting to age-limited learning effects, 2013.

\bibitem[Myung(2003)]{myung2003tutorial}
Myung, I.~J.
\newblock Tutorial on maximum likelihood estimation.
\newblock \emph{Journal of mathematical Psychology}, 47\penalty0 (1):\penalty0
  90--100, 2003.

\bibitem[Park et~al.(2019)Park, Kim, Lu, and Cho]{park2019relational}
Park, W., Kim, D., Lu, Y., and Cho, M.
\newblock Relational knowledge distillation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  3967--3976, 2019.

\bibitem[Rebuffi et~al.(2017)Rebuffi, Kolesnikov, Sperl, and
  Lampert]{rebuffi2017icarl}
Rebuffi, S.-A., Kolesnikov, A., Sperl, G., and Lampert, C.~H.
\newblock icarl: Incremental classifier and representation learning.
\newblock In \emph{Proc. CVPR}, 2017.

\bibitem[Rosenfeld \& Tsotsos(2018)Rosenfeld and
  Tsotsos]{rosenfeld2018incremental}
Rosenfeld, A. and Tsotsos, J.~K.
\newblock Incremental learning through deep adaptation.
\newblock \emph{IEEE transactions on pattern analysis and machine
  intelligence}, 42\penalty0 (3):\penalty0 651--663, 2018.

\bibitem[Rusu et~al.(2016)Rusu, Rabinowitz, Desjardins, Soyer, Kirkpatrick,
  Kavukcuoglu, Pascanu, and Hadsell]{rusu2016progressive}
Rusu, A.~A., Rabinowitz, N.~C., Desjardins, G., Soyer, H., Kirkpatrick, J.,
  Kavukcuoglu, K., Pascanu, R., and Hadsell, R.
\newblock Progressive neural networks.
\newblock \emph{arXiv preprint arXiv:1606.04671}, 2016.

\bibitem[Tian et~al.(2019)Tian, Krishnan, and Isola]{tian2019contrastive}
Tian, Y., Krishnan, D., and Isola, P.
\newblock Contrastive representation distillation.
\newblock \emph{arXiv preprint arXiv:1910.10699}, 2019.

\bibitem[Verwimp et~al.(2022)Verwimp, Yang, Parisot, Lanqing, McDonagh,
  P{\'e}rez-Pellitero, De~Lange, and Tuytelaars]{SODA}
Verwimp, E., Yang, K., Parisot, S., Lanqing, H., McDonagh, S.,
  P{\'e}rez-Pellitero, E., De~Lange, M., and Tuytelaars, T.
\newblock Clad: A realistic continual learning benchmark for autonomous
  driving.
\newblock \emph{arXiv preprint arXiv:2210.03482}, 2022.

\bibitem[Vinyals et~al.(2016)Vinyals, Blundell, Lillicrap, Wierstra,
  et~al.]{vinyals2016matching}
Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et~al.
\newblock Matching networks for one shot learning.
\newblock \emph{Advances in neural information processing systems}, 29, 2016.

\bibitem[Wu et~al.(2021)Wu, Gong, and Li]{wu2021striking}
Wu, G., Gong, S., and Li, P.
\newblock Striking a balance between stability and plasticity for
  class-incremental learning.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on
  Computer Vision}, pp.\  1124--1133, 2021.

\bibitem[Yu et~al.(2020)Yu, Twardowski, Liu, Herranz, Wang, Cheng, Jui, and
  Weijer]{yu2020semantic}
Yu, L., Twardowski, B., Liu, X., Herranz, L., Wang, K., Cheng, Y., Jui, S., and
  Weijer, J. v.~d.
\newblock Semantic drift compensation for class-incremental learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  6982--6991, 2020.

\bibitem[Zhu et~al.(2021{\natexlab{a}})Zhu, Zhang, Wang, Yin, and
  Liu]{zhu2021prototype}
Zhu, F., Zhang, X.-Y., Wang, C., Yin, F., and Liu, C.-L.
\newblock Prototype augmentation and self-supervision for incremental learning.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  5871--5880, 2021{\natexlab{a}}.

\bibitem[Zhu et~al.(2021{\natexlab{b}})Zhu, Tang, Chen, Yu, Liu, Rong, Yang,
  and Wang]{zhu2021complementary}
Zhu, J., Tang, S., Chen, D., Yu, S., Liu, Y., Rong, M., Yang, A., and Wang, X.
\newblock Complementary relation contrastive distillation.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  9260--9269, 2021{\natexlab{b}}.

\end{thebibliography}
