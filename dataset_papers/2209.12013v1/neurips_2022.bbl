\begin{thebibliography}{19}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agrawal and Devanur(2016)]{agrawal2016linear}
Shipra Agrawal and Nikhil Devanur.
\newblock Linear contextual bandits with knapsacks.
\newblock \emph{Advances in Neural Information Processing Systems}, 29, 2016.

\bibitem[Agrawal and Devanur(2014)]{agrawal2014bandits}
Shipra Agrawal and Nikhil~R Devanur.
\newblock Bandits with concave rewards and convex knapsacks.
\newblock In \emph{Proceedings of the fifteenth ACM conference on Economics and
  computation}, pages 989--1006, 2014.

\bibitem[Auer et~al.(2002{\natexlab{a}})Auer, Cesa-Bianchi, and
  Fischer]{auer2002finite}
Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer.
\newblock Finite-time analysis of the multiarmed bandit problem.
\newblock \emph{Machine learning}, 47\penalty0 (2):\penalty0 235--256,
  2002{\natexlab{a}}.

\bibitem[Auer et~al.(2002{\natexlab{b}})Auer, Cesa-Bianchi, Freund, and
  Schapire]{auer2002nonstochastic}
Peter Auer, Nicolo Cesa-Bianchi, Yoav Freund, and Robert~E Schapire.
\newblock The nonstochastic multiarmed bandit problem.
\newblock \emph{SIAM journal on computing}, 32\penalty0 (1):\penalty0 48--77,
  2002{\natexlab{b}}.

\bibitem[Badanidiyuru et~al.(2013)Badanidiyuru, Kleinberg, and
  Slivkins]{badanidiyuru2013bandits}
Ashwinkumar Badanidiyuru, Robert Kleinberg, and Aleksandrs Slivkins.
\newblock Bandits with knapsacks.
\newblock In \emph{2013 IEEE 54th Annual Symposium on Foundations of Computer
  Science}, pages 207--216. IEEE, 2013.

\bibitem[Badanidiyuru et~al.(2018)Badanidiyuru, Kleinberg, and
  Slivkins]{badanidiyuru2018bandits}
Ashwinkumar Badanidiyuru, Robert Kleinberg, and Aleksandrs Slivkins.
\newblock Bandits with knapsacks.
\newblock \emph{Journal of the ACM (JACM)}, 65\penalty0 (3):\penalty0 1--55,
  2018.

\bibitem[Bubeck and Cesa{-}Bianchi(2012)]{bubeck2012regret}
S{\'{e}}bastien Bubeck and Nicol{\`{o}} Cesa{-}Bianchi.
\newblock Regret analysis of stochastic and nonstochastic multi-armed bandit
  problems.
\newblock \emph{Found. Trends Mach. Learn.}, 5\penalty0 (1):\penalty0 1--122,
  2012.

\bibitem[Even-Dar et~al.(2002)Even-Dar, Mannor, and Mansour]{evendar2002pac}
Eyal Even-Dar, Shie Mannor, and Yishay Mansour.
\newblock Pac bounds for multi-armed bandit and markov decision processes.
\newblock In \emph{International Conference on Computational Learning Theory},
  pages 255--270. Springer, 2002.

\bibitem[Flajolet and Jaillet(2015)]{flajolet2015logarithmic}
Arthur Flajolet and Patrick Jaillet.
\newblock Logarithmic regret bounds for bandits with knapsacks.
\newblock \emph{arXiv preprint arXiv:1510.01800v4}, 2015.

\bibitem[Immorlica et~al.(2019)Immorlica, Sankararaman, Schapire, and
  Slivkins]{immorlica2019adversarial}
Nicole Immorlica, Karthik~Abinav Sankararaman, Robert Schapire, and Aleksandrs
  Slivkins.
\newblock Adversarial bandits with knapsacks.
\newblock In \emph{2019 IEEE 60th Annual Symposium on Foundations of Computer
  Science (FOCS)}, pages 202--219. IEEE, 2019.

\bibitem[Kleinberg et~al.(2019)Kleinberg, Slivkins, and
  Upfal]{kleinberg2019bandits}
Robert Kleinberg, Aleksandrs Slivkins, and Eli Upfal.
\newblock Bandits and experts in metric spaces.
\newblock \emph{Journal of the ACM (JACM)}, 66\penalty0 (4):\penalty0 1--77,
  2019.

\bibitem[Lai et~al.(1985)Lai, Robbins, et~al.]{lai1985asymptotically}
Tze~Leung Lai, Herbert Robbins, et~al.
\newblock Asymptotically efficient adaptive allocation rules.
\newblock \emph{Advances in applied mathematics}, 6\penalty0 (1):\penalty0
  4--22, 1985.

\bibitem[Lattimore and Szepesv{\'a}ri(2020)]{lattimore2020bandit}
Tor Lattimore and Csaba Szepesv{\'a}ri.
\newblock \emph{Bandit algorithms}.
\newblock Cambridge University Press, 2020.

\bibitem[Li et~al.(2021)Li, Sun, and Ye]{li2021symmetry}
Xiaocheng Li, Chunlin Sun, and Yinyu Ye.
\newblock The symmetry between arms and knapsacks: A primal-dual approach for
  bandits with knapsacks.
\newblock In \emph{International Conference on Machine Learning}, pages
  6483--6492. PMLR, 2021.

\bibitem[Sankararaman and Slivkins(2021)]{sankararaman2021bandits}
Karthik~Abinav Sankararaman and Aleksandrs Slivkins.
\newblock Bandits with knapsacks beyond the worst case.
\newblock \emph{Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem[Slivkins(2011)]{slivkins2011contextual}
Aleksandrs Slivkins.
\newblock Contextual bandits with similarity information.
\newblock In \emph{Proceedings of the 24th annual Conference On Learning
  Theory}, pages 679--702. JMLR Workshop and Conference Proceedings, 2011.

\bibitem[Slivkins(2019)]{slivkins2019introduction}
Aleksandrs Slivkins.
\newblock Introduction to multi-armed bandits.
\newblock \emph{Found. Trends Mach. Learn.}, 12\penalty0 (1-2):\penalty0
  1--286, 2019.

\bibitem[Tran-Thanh et~al.(2010)Tran-Thanh, Chapman, De~Cote, Rogers, and
  Jennings]{tran2010epsilon}
Long Tran-Thanh, Archie Chapman, Enrique~Munoz De~Cote, Alex Rogers, and
  Nicholas~R Jennings.
\newblock Epsilon--first policies for budget--limited multi-armed bandits.
\newblock In \emph{Twenty-Fourth AAAI Conference on Artificial Intelligence},
  2010.

\bibitem[Tran-Thanh et~al.(2012)Tran-Thanh, Chapman, Rogers, and
  Jennings]{tran2012knapsack}
Long Tran-Thanh, Archie Chapman, Alex Rogers, and Nicholas Jennings.
\newblock Knapsack based optimal policies for budget--limited multi--armed
  bandits.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~26, pages 1134--1140, 2012.

\end{thebibliography}
