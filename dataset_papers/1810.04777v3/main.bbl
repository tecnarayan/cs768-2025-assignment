\begin{thebibliography}{26}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bengio et~al.(2013)Bengio, Leonard, and Courville]{StraightThrough}
Bengio, Y., Leonard, N., and Courville, A.
\newblock Estimating or propagating gradients through stochastic neurons for
  conditional computation.
\newblock 2013.
\newblock URL \url{https://arxiv.org/abs/1308.3432}.

\bibitem[Blei et~al.(2017)Blei, Kucukelbir, and McAuliffe]{VI_review}
Blei, D.~M., Kucukelbir, A., and McAuliffe, J.~D.
\newblock Variational inference: A review for statisticians.
\newblock \emph{Journal of the American Statistical Association}, 112\penalty0
  (518):\penalty0 859--877, 2017.

\bibitem[Casella \& Robert(1996)Casella and Robert]{casella1996rao}
Casella, G. and Robert, C.~P.
\newblock Rao-{B}lackwellisation of sampling schemes.
\newblock \emph{Biometrika}, 83\penalty0 (1):\penalty0 81--94, 1996.

\bibitem[Grathwohl et~al.(2018)Grathwohl, Choi, Wu, Roeder, and
  Duvenaud]{grathwohl2018backpropagation}
Grathwohl, W., Choi, D., Wu, Y., Roeder, G., and Duvenaud, D.
\newblock Backpropagation through the void: Optimizing control variates for
  black-box gradient estimation.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Gregor et~al.(2014)Gregor, Mnih, and Wierstra]{GregorDARN2014}
Gregor, K., Mnih, A., and Wierstra, D.
\newblock Deep autoregressive networks.
\newblock In \emph{International Conference on Machine Learning}, 2014.

\bibitem[Gregor et~al.(2015)Gregor, Danihelka, Graves, Rezende, and
  Wierstra]{GregorDRAW}
Gregor, K., Danihelka, I., Graves, A., Rezende, D., and Wierstra, D.
\newblock {DRAW:} a recurrent neural network for image generation.
\newblock In \emph{International Conference on Machine Learning}, 2015.

\bibitem[Gu et~al.(2016)Gu, Levine, Sutskever, and Mnih]{GuMuProp2015}
Gu, S., Levine, S., Sutskever, I., and Mnih, A.
\newblock {M}u{P}rop: Unbiased backpropagation for stochastic neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2016.

\bibitem[Gutmann \& Hyv\"{a}rinen(2012)Gutmann and
  Hyv\"{a}rinen]{GutmannNCE2010}
Gutmann, M. and Hyv\"{a}rinen, A.
\newblock Noise-contrastive estimation: A new estimation principle for
  unnormalized statistical models.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2012.

\bibitem[Jang et~al.(2017)Jang, Gu, and Poole]{jang2017categorical}
Jang, E., Gu, S., and Poole, B.
\newblock Categorical reparameterization with {Gumbel}-softmax.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Kingma \& Welling(2014)Kingma and Welling]{kingma2014auto}
Kingma, D. and Welling, M.
\newblock Auto-encoding variational {B}ayes.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Kingma \& Ba(2015)Kingma and Ba]{KigmaADAM2014}
Kingma, D.~P. and Ba, J.
\newblock Adam: a method for stochastic optimization.
\newblock In \emph{International Conference for Learning Representations},
  2015.

\bibitem[Kingma et~al.(2014)Kingma, Rezende, Mohamed, and
  Welling]{kingma2014semisupervised}
Kingma, D.~P., Rezende, D.~J., Mohamed, S., and Welling, M.
\newblock Semi-supervised learning with deep generative models.
\newblock \emph{CoRR}, abs/1406.5298, 2014.
\newblock URL \url{http://arxiv.org/abs/1406.5298}.

\bibitem[Lecun et~al.(1998)Lecun, Bottou, Bengio, and Haffner]{LecunMNIST}
Lecun, Y., Bottou, L., Bengio, Y., and Haffner, P.
\newblock Gradient-based learning applied to document recognition.
\newblock \emph{Proceedings of the IEEE}, 86\penalty0 (11):\penalty0
  2278--2324, Nov 1998.

\bibitem[Liang et~al.(2018)Liang, Norouzi, Berant, Le, and Lao]{liangMAP2018}
Liang, C., Norouzi, M., Berant, J., Le, Q., and Lao, N.
\newblock Memory augmented policy optimization for program synthesis with
  generalization.
\newblock In \emph{Neural Information Processing Systems}, 2018.

\bibitem[Maddison et~al.(2017)Maddison, Mnih, and Teh]{maddison2017concrete}
Maddison, C.~J., Mnih, A., and Teh, Y.~W.
\newblock The concrete distribution: A continuous relaxation of discrete random
  variables.
\newblock In \emph{International Conference on Learning Representations}, 2017.

\bibitem[Mnih \& Gregor(2014)Mnih and Gregor]{mnih2014neural}
Mnih, A. and Gregor, K.
\newblock Neural variational inference and learning in belief networks.
\newblock In \emph{International Conference on Machine Learning}, 2014.

\bibitem[Mnih \& Rezende(2016)Mnih and Rezende]{mnih2016variational}
Mnih, A. and Rezende, D.~J.
\newblock Variational inference for {M}onte {C}arlo objectives.
\newblock In \emph{International Conference on Machine Learning}, 2016.

\bibitem[Mnih et~al.(2014)Mnih, Heess, Graves, et~al.]{mnihattnmechanism}
Mnih, V., Heess, N., Graves, A., et~al.
\newblock Recurrent models of visual attention.
\newblock In \emph{Advances in Neural Information Processing Systems}, 2014.

\bibitem[Morin \& Bengio(2005)Morin and Bengio]{MorinHierSoftmax2005}
Morin, F. and Bengio, Y.
\newblock Hierarchical probabilistic neural network language model.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2005.

\bibitem[Ranganath et~al.(2014)Ranganath, Gerrish, and Blei]{bbVI}
Ranganath, R., Gerrish, S., and Blei, D.~M.
\newblock Black box variational inference.
\newblock In \emph{International Conference on Artificial Intelligence and
  Statistics}, 2014.

\bibitem[Royle(2004)]{RoyleNmixtureModel}
Royle, J.~A.
\newblock N-mixture models for estimating population size from spatially
  replicated counts.
\newblock \emph{Biometrics}, 60\penalty0 (1):\penalty0 108--115, 2004.

\bibitem[Spall(2003)]{SpallOptimization2003}
Spall, J.~C.
\newblock \emph{Introduction to Stochastic Search and Optimization}.
\newblock John Wiley \& Sons, Inc., New York, NY, USA, 1st edition, 2003.

\bibitem[Titsias~K(2014)]{TitsiasMCwithExhaustiveSearch}
Titsias~K, M.
\newblock Combine {M}onte {C}arlo with exhaustive search: Effective variational
  inference and policy gradient reinforcement learning.
\newblock In \emph{NIPS Workshop: Advances in Approximate Inference}, 2014.

\bibitem[Titsias~K \& L\'{a}zaro-Gredilla(2015)Titsias~K and
  L\'{a}zaro-Gredilla]{TitsiasLocalExpGrads}
Titsias~K, M. and L\'{a}zaro-Gredilla, M.
\newblock Local expectation gradients for black box variational inference.
\newblock In \emph{Neural Information Processing Systems}, 2015.

\bibitem[Tucker et~al.(2017)Tucker, Mnih, Maddison, Lawson, and
  Sohl-Dickstein]{tucker2017rebar}
Tucker, G., Mnih, A., Maddison, C.~J., Lawson, J., and Sohl-Dickstein, J.
\newblock {REBAR}: Low-variance, unbiased gradient estimates for discrete
  latent variable models.
\newblock In \emph{Neural Information Processing Systems}, 2017.

\bibitem[Williams(1992)]{williams1992simple}
Williams, R.~J.
\newblock Simple statistical gradient-following algorithms for connectionist
  reinforcement learning.
\newblock \emph{Machine learning}, 8\penalty0 (3-4):\penalty0 229--256, 1992.

\end{thebibliography}
