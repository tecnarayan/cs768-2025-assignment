\begin{thebibliography}{10}

\bibitem{anderson2007optimal}
Brian D~O Anderson and John~B Moore.
\newblock {\em Optimal control: linear quadratic methods}.
\newblock Courier Corporation, 2007.

\bibitem{araki2017multi}
Brandon Araki, John Strang, Sarah Pohorecky, Celine Qiu, Tobias Naegeli, and
  Daniela Rus.
\newblock Multi-robot path planning for a swarm of robots that can both fly and
  drive.
\newblock In {\em 2017 IEEE International Conference on Robotics and Automation
  (ICRA)}, pages 5575--5582. IEEE, 2017.

\bibitem{bauso2012robust}
Dario Bauso, Hamidou Tembine, and Tamer Ba{\c{s}}ar.
\newblock Robust mean field games with application to production of an
  exhaustible resource.
\newblock {\em IFAC Proceedings Volumes}, 45(13):454--459, 2012.

\bibitem{bensoussan2013mean}
Alain Bensoussan, Jens Frehse, Phillip Yam, et~al.
\newblock {\em Mean field games and mean field type control theory}, volume
  101.
\newblock Springer, 2013.

\bibitem{bertsekas1995dynamic}
Dimitri~P Bertsekas.
\newblock {\em Dynamic programming and optimal control}, volume~1.
\newblock Athena scientific Belmont, MA, 1995.

\bibitem{bu2019global}
Jingjing Bu, Lillian~J Ratliff, and Mehran Mesbahi.
\newblock Global convergence of policy gradient for sequential zero-sum linear
  quadratic dynamic games.
\newblock {\em arXiv preprint arXiv:1911.04672}, 2019.

\bibitem{cardaliaguet2017learning}
Pierre Cardaliaguet and Saeed Hadikhanloo.
\newblock Learning in mean field games: the fictitious play.
\newblock {\em ESAIM: Control, Optimisation and Calculus of Variations},
  23(2):569--591, 2017.

\bibitem{carmona2018probabilistic}
Ren{\'e} Carmona, Fran{\c{c}}ois Delarue, et~al.
\newblock {\em Probabilistic Theory of Mean Field Games with Applications
  I-II}.
\newblock Springer, 2018.

\bibitem{carmona2019linear}
Ren{\'e} Carmona, Mathieu Lauri{\`e}re, and Zongjun Tan.
\newblock Linear-quadratic mean-field reinforcement learning: convergence of
  policy gradient methods.
\newblock {\em arXiv preprint arXiv:1910.04295}, 2019.

\bibitem{de2006learning}
Enrique~Munoz de~Cote, Alessandro Lazaric, and Marcello Restelli.
\newblock Learning to cooperate in multi-agent social dilemmas.
\newblock In {\em Proceedings of the fifth international joint conference on
  Autonomous agents and multiagent systems}, pages 783--785, 2006.

\bibitem{dimarogonas2010stability}
Dimos~V Dimarogonas and Karl~H Johansson.
\newblock Stability analysis for multi-agent systems using the incidence
  matrix: Quantized communication and formation control.
\newblock {\em Automatica}, 46(4):695--700, 2010.

\bibitem{egerstedt2001formation}
Magnus Egerstedt and Xiaoming Hu.
\newblock Formation constrained multi-agent control.
\newblock {\em IEEE transactions on robotics and automation}, 17(6):947--951,
  2001.

\bibitem{elie2020convergence}
Romuald Elie, Julien Perolat, Mathieu Lauri{\`e}re, Matthieu Geist, and Olivier
  Pietquin.
\newblock On the convergence of model free learning in mean field games.
\newblock In {\em AAAI Conference one Artificial Intelligence (AAAI 2020)},
  2020.

\bibitem{elliott2013discrete}
Robert Elliott, Xun Li, and Yuan-Hua Ni.
\newblock Discrete time mean-field stochastic linear-quadratic optimal control
  problems.
\newblock {\em Automatica}, 49(11):3222--3233, 2013.

\bibitem{engwerda2005lq}
Jacob Engwerda.
\newblock {\em LQ dynamic optimization and differential games}.
\newblock John Wiley \& Sons, 2005.

\bibitem{fang2014lqr}
Jian Fang.
\newblock The {LQR} controller design of two-wheeled self-balancing robot based
  on the particle swarm optimization algorithm.
\newblock {\em Mathematical Problems in Engineering}, 2014, 2014.

\bibitem{fazel2018global}
Maryam Fazel, Rong Ge, Sham~M Kakade, and Mehran Mesbahi.
\newblock Global convergence of policy gradient methods for the linear
  quadratic regulator.
\newblock {\em arXiv preprint arXiv:1801.05039}, 2018.

\bibitem{fu2019actor}
Zuyue Fu, Zhuoran Yang, Yongxin Chen, and Zhaoran Wang.
\newblock Actor-critic provably finds {Nash} equilibria of linear-quadratic
  mean-field games.
\newblock {\em arXiv preprint arXiv:1910.07498}, 2019.

\bibitem{guo2019learning}
Xin Guo, Anran Hu, Renyuan Xu, and Junzi Zhang.
\newblock Learning mean-field games.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  4967--4977, 2019.

\bibitem{heinrich2016deep}
Johannes Heinrich and David Silver.
\newblock Deep reinforcement learning from self-play in imperfect-information
  games.
\newblock {\em arXiv preprint arXiv:1603.01121}, 2016.

\bibitem{huang2018linear}
Jianhui Huang and Na~Li.
\newblock Linear--quadratic mean-field game for stochastic delayed systems.
\newblock {\em IEEE Transactions on Automatic Control}, 63(8):2722--2729, 2018.

\bibitem{huang2003individual}
Minyi Huang, Peter~E Caines, and Roland~P Malham{\'e}.
\newblock Individual and mass behaviour in large population stochastic wireless
  power control problems: centralized and {Nash} equilibrium solutions.
\newblock In {\em 42nd IEEE International Conference on Decision and Control
  (IEEE Cat. No. 03CH37475)}, volume~1, pages 98--103. IEEE, 2003.

\bibitem{huang2006large}
Minyi Huang, Roland~P Malham{\'e}, Peter~E Caines, et~al.
\newblock Large population stochastic dynamic games: closed-loop mckean-vlasov
  systems and the {Nash} certainty equivalence principle.
\newblock {\em Communications in Information \& Systems}, 6(3):221--252, 2006.

\bibitem{hughes2018inequity}
Edward Hughes, Joel~Z Leibo, Matthew Phillips, Karl Tuyls, Edgar
  Due{\~n}ez-Guzman, Antonio~Garc{\'\i}a Casta{\~n}eda, Iain Dunning, Tina Zhu,
  Kevin McKee, Raphael Koster, et~al.
\newblock Inequity aversion improves cooperation in intertemporal social
  dilemmas.
\newblock In {\em Advances in neural information processing systems}, pages
  3326--3336, 2018.

\bibitem{kakade2002natural}
Sham~M Kakade.
\newblock A natural policy gradient.
\newblock In {\em Advances in neural information processing systems}, pages
  1531--1538, 2002.

\bibitem{karimi2016linear}
Hamed Karimi, Julie Nutini, and Mark Schmidt.
\newblock Linear convergence of gradient and proximal-gradient methods under
  the polyak-{\l}ojasiewicz condition.
\newblock In {\em Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pages 795--811. Springer, 2016.

\bibitem{lasry2006jeux_a}
Jean-Michel Lasry and Pierre-Louis Lions.
\newblock Jeux {\`a} champ moyen. i--le cas stationnaire.
\newblock {\em Comptes Rendus Math{\'e}matique}, 343(9):619--625, 2006.

\bibitem{lasry2006jeux_b}
Jean-Michel Lasry and Pierre-Louis Lions.
\newblock Jeux {\`a} champ moyen. ii--horizon fini et contr{\^o}le optimal.
\newblock {\em Comptes Rendus Math{\'e}matique}, 343(10):679--684, 2006.

\bibitem{lasry2007mean}
Jean-Michel Lasry and Pierre-Louis Lions.
\newblock Mean field games.
\newblock {\em Japanese journal of mathematics}, 2(1):229--260, 2007.

\bibitem{leibo2017multi}
Joel~Z Leibo, Vinicius Zambaldi, Marc Lanctot, Janusz Marecki, and Thore
  Graepel.
\newblock Multi-agent reinforcement learning in sequential social dilemmas.
\newblock {\em arXiv preprint arXiv:1702.03037}, 2017.

\bibitem{minciardi2011optimal}
Riccardo Minciardi and Roberto Sacile.
\newblock Optimal control in a cooperative network of smart power grids.
\newblock {\em IEEE Systems Journal}, 6(1):126--133, 2011.

\bibitem{mnih2013playing}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis
  Antonoglou, Daan Wierstra, and Martin Riedmiller.
\newblock Playing atari with deep reinforcement learning.
\newblock {\em arXiv preprint arXiv:1312.5602}, 2013.

\bibitem{mohammadi2019convergence}
Hesameddin Mohammadi, Armin Zare, Mahdi Soltanolkotabi, and Mihailo~R
  Jovanovi{\'c}.
\newblock Convergence and sample complexity of gradient methods for the
  model-free linear quadratic regulator problem.
\newblock {\em arXiv preprint arXiv:1912.11899}, 2019.

\bibitem{moravvcik2017deepstack}
Matej Morav{\v{c}}{\'\i}k, Martin Schmid, Neil Burch, Viliam Lis{\`y}, Dustin
  Morrill, Nolan Bard, Trevor Davis, Kevin Waugh, Michael Johanson, and Michael
  Bowling.
\newblock Deepstack: Expert-level artificial intelligence in heads-up no-limit
  poker.
\newblock {\em Science}, 356(6337):508--513, 2017.

\bibitem{OpenAI_dota}
OpenAI.
\newblock Openai five.
\newblock \url{https://blog.openai.com/openai-five/}, 2018.

\bibitem{parsons2002game}
Simon Parsons and Michael Wooldridge.
\newblock Game theory and decision theory in multi-agent systems.
\newblock {\em Autonomous Agents and Multi-Agent Systems}, 5(3):243--254, 2002.

\bibitem{saldi2018markov}
Naci Saldi, Tamer Basar, and Maxim Raginsky.
\newblock {Markov}-{Nash} equilibria in mean-field games with discounted cost.
\newblock {\em SIAM Journal on Control and Optimization}, 56(6):4256--4287,
  2018.

\bibitem{saldi2019approximate}
Naci Saldi, Tamer Ba{\c{s}}ar, and Maxim Raginsky.
\newblock Approximate {Nash} equilibria in partially observed stochastic games
  with mean-field interactions.
\newblock {\em Mathematics of Operations Research}, 44(3):1006--1033, 2019.

\bibitem{semsar2009multi}
Elham Semsar-Kazerooni and Khashayar Khorasani.
\newblock Multi-agent team cooperation: A game theory approach.
\newblock {\em Automatica}, 45(10):2205--2213, 2009.

\bibitem{shalev2016safe}
Shai Shalev-Shwartz, Shaked Shammah, and Amnon Shashua.
\newblock Safe, multi-agent, reinforcement learning for autonomous driving.
\newblock {\em arXiv preprint arXiv:1610.03295}, 2016.

\bibitem{shamma2008cooperative}
Jeff Shamma.
\newblock {\em Cooperative control of distributed multi-agent systems}.
\newblock John Wiley \& Sons, 2008.

\bibitem{silver2016mastering}
David Silver, Aja Huang, Chris~J Maddison, Arthur Guez, Laurent Sifre, George
  Van Den~Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda
  Panneershelvam, Marc Lanctot, et~al.
\newblock Mastering the game of go with deep neural networks and tree search.
\newblock {\em nature}, 529(7587):484, 2016.

\bibitem{silver2014deterministic}
David Silver, Guy Lever, Nicolas Heess, Thomas Degris, Daan Wierstra, and
  Martin Riedmiller.
\newblock Deterministic policy gradient algorithms.
\newblock In Eric~P. Xing and Tony Jebara, editors, {\em Proceedings of the
  31st International Conference on Machine Learning}, volume~32 of {\em
  Proceedings of Machine Learning Research}, pages 387--395, Bejing, China,
  22--24 Jun 2014. PMLR.

\bibitem{silver2017mastering}
David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja
  Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton,
  et~al.
\newblock Mastering the game of go without human knowledge.
\newblock {\em Nature}, 550(7676):354--359, 2017.

\bibitem{sutton2018reinforcement}
Richard~S Sutton and Andrew~G Barto.
\newblock {\em Reinforcement learning: An introduction}.
\newblock MIT press, 2018.

\bibitem{sutton2000policy}
Richard~S Sutton, David~A McAllester, Satinder~P Singh, and Yishay Mansour.
\newblock Policy gradient methods for reinforcement learning with function
  approximation.
\newblock In {\em Advances in neural information processing systems}, pages
  1057--1063, 2000.

\bibitem{tembine2013risk}
Hamidou Tembine, Quanyan Zhu, and Tamer Ba{\c{s}}ar.
\newblock Risk-sensitive mean-field games.
\newblock {\em IEEE Transactions on Automatic Control}, 59(4):835--850, 2013.

\bibitem{vinyals2019alphastar}
Oriol Vinyals, Igor Babuschkin, Junyoung Chung, Michael Mathieu, Max Jaderberg,
  Wojciech~M Czarnecki, Andrew Dudzik, Aja Huang, Petko Georgiev, Richard
  Powell, et~al.
\newblock Alphastar: Mastering the real-time strategy game starcraft ii.
\newblock {\em DeepMind blog}, page~2, 2019.

\bibitem{willems1971least}
Jan Willems.
\newblock Least squares stationary optimal control and the algebraic riccati
  equation.
\newblock {\em IEEE Transactions on Automatic Control}, 16(6):621--634, 1971.

\bibitem{yang2004multiagent}
Erfu Yang and Dongbing Gu.
\newblock Multiagent reinforcement learning for multi-robot systems: A survey.
\newblock Technical report, tech. rep, 2004.

\bibitem{zhang2019policy}
Kaiqing Zhang, Zhuoran Yang, and Tamer Basar.
\newblock Policy optimization provably converges to {Nash} equilibria in
  zero-sum linear quadratic games.
\newblock In {\em Advances in Neural Information Processing Systems}, pages
  11598--11610, 2019.

\bibitem{zhang2005some}
Pingjian Zhang.
\newblock Some results on two-person zero-sum linear quadratic differential
  games.
\newblock {\em SIAM journal on control and optimization}, 43(6):2157--2165,
  2005.

\bibitem{zhou2000continuous}
Xun~Yu Zhou and Duan Li.
\newblock Continuous-time mean-variance portfolio selection: A stochastic lq
  framework.
\newblock {\em Applied Mathematics and Optimization}, 42(1):19--33, 2000.

\end{thebibliography}
