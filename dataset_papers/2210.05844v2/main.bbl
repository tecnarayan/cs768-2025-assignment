\begin{thebibliography}{10}

\bibitem{fcn}
J.~Long, E.~Shelhamer, and T.~Darrell, ``Fully convolutional networks for
  semantic segmentation,'' in {\em Proc. IEEE Conf. Comp. Vis. Patt. Recogn.},
  pp.~3431--3440, 2015.

\bibitem{chen2017deeplabv2}
L.-C. Chen, G.~Papandreou, I.~Kokkinos, K.~Murphy, and A.~Yuille, ``Deeplab:
  Semantic image segmentation with deep convolutional nets, atrous convolution,
  and fully connected {CRFs},'' {\em {IEEE} Trans. Pattern Anal. Mach.
  Intell.}, vol.~40, no.~4, pp.~834--848, 2017.

\bibitem{ocrnet}
Y.~Yuan, X.~Chen, and J.~Wang, ``Object-contextual representations for semantic
  segmentation,'' in {\em Proc. Eur. Conf. Comp. Vis.}, pp.~173--190, Springer,
  2020.

\bibitem{fpn}
T.-Y. Lin, P.~Doll{\'a}r, R.~Girshick, K.~He, B.~Hariharan, and S.~Belongie,
  ``Feature pyramid networks for object detection,'' in {\em Proc. IEEE Conf.
  Comp. Vis. Patt. Recogn.}, pp.~2117--2125, 2017.

\bibitem{vit}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai,
  T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, {\em et~al.},
  ``An image is worth 16x16 words: Transformers for image recognition at
  scale,'' {\em Proc. Int. Conf. Learn. Representations}, 2021.

\bibitem{setr}
S.~Zheng, J.~Lu, H.~Zhao, X.~Zhu, Z.~Luo, Y.~Wang, Y.~Fu, J.~Feng, T.~Xiang,
  P.~H. Torr, {\em et~al.}, ``Rethinking semantic segmentation from a
  sequence-to-sequence perspective with transformers,'' in {\em Proc. IEEE
  Conf. Comp. Vis. Patt. Recogn.}, pp.~6881--6890, 2021.

\bibitem{DPT}
R.~Ranftl, A.~Bochkovskiy, and V.~Koltun, ``Vision transformers for dense
  prediction,'' in {\em Proc. IEEE Int. Conf. Comp. Vis.}, pp.~12179--12188,
  2021.

\bibitem{strudel2021segmenter}
R.~Strudel, R.~Garcia, I.~Laptev, and C.~Schmid, ``Segmenter: Transformer for
  semantic segmentation,'' in {\em Proc. IEEE Int. Conf. Comp. Vis.},
  pp.~7262--7272, 2021.

\bibitem{farabet2012learning}
C.~Farabet, C.~Couprie, L.~Najman, and Y.~LeCun, ``Learning hierarchical
  features for scene labeling,'' {\em {IEEE} Trans. Pattern Anal. Mach.
  Intell.}, vol.~35, no.~8, pp.~1915--1929, 2012.

\bibitem{long2015fully}
J.~Long, E.~Shelhamer, and T.~Darrell, ``Fully convolutional networks for
  semantic segmentation,'' in {\em Proc. IEEE Conf. Comp. Vis. Patt. Recogn.},
  pp.~3431--3440, 2015.

\bibitem{pspnet}
H.~Zhao, J.~Shi, X.~Qi, X.~Wang, and J.~Jia, ``Pyramid scene parsing network,''
  in {\em Proc. IEEE Conf. Comp. Vis. Patt. Recogn.}, 2017.

\bibitem{dv3}
L.-C. Chen, Y.~Zhu, G.~Papandreou, F.~Schroff, and H.~Adam, ``Encoder-decoder
  with atrous separable convolution for semantic image segmentation,'' in {\em
  Proc. Eur. Conf. Comp. Vis.}, pp.~801--818, 2018.

\bibitem{dranet}
J.~Fu, J.~Liu, J.~Jiang, Y.~Li, Y.~Bao, and H.~Lu, ``Scene segmentation with
  dual relation-aware attention network,'' {\em {IEEE} Trans. Neural Netw. \&
  Learn. Syst.}, vol.~32, no.~6, pp.~2547--2560, 2020.

\bibitem{cpnet}
C.~Yu, J.~Wang, C.~Gao, G.~Yu, C.~Shen, and N.~Sang, ``Context prior for scene
  segmentation,'' in {\em Proc. IEEE Conf. Comp. Vis. Patt. Recogn.},
  pp.~12416--12425, 2020.

\bibitem{maskformer}
B.~Cheng, A.~Schwing, and A.~Kirillov, ``Per-pixel classification is not all
  you need for semantic segmentation,'' {\em Proc. Advances in Neural Inf.
  Process. Syst.}, vol.~34, 2021.

\bibitem{knet}
W.~Zhang, J.~Pang, K.~Chen, and C.~C. Loy, ``K-net: Towards unified image
  segmentation,'' {\em Proc. Advances in Neural Inf. Process. Syst.}, vol.~34,
  2021.

\bibitem{pvt}
W.~Wang, E.~Xie, X.~Li, D.-P. Fan, K.~Song, D.~Liang, T.~Lu, P.~Luo, and
  L.~Shao, ``Pyramid vision transformer: A versatile backbone for dense
  prediction without convolutions,'' in {\em Proc. IEEE Int. Conf. Comp. Vis.},
  pp.~568--578, 2021.

\bibitem{liu2021swin}
Z.~Liu, Y.~Lin, Y.~Cao, H.~Hu, Y.~Wei, Z.~Zhang, S.~Lin, and B.~Guo, ``Swin
  transformer: Hierarchical vision transformer using shifted windows,'' in {\em
  Proc. IEEE Int. Conf. Comp. Vis.}, pp.~10012--10022, 2021.

\bibitem{chu2021twins}
X.~Chu, Z.~Tian, Y.~Wang, B.~Zhang, H.~Ren, X.~Wei, H.~Xia, and C.~Shen,
  ``Twins: Revisiting the design of spatial attention in vision transformers,''
  {\em Proc. Advances in Neural Inf. Process. Syst.}, vol.~34, 2021.

\bibitem{xie2021segformer}
E.~Xie, W.~Wang, Z.~Yu, A.~Anandkumar, J.~M. Alvarez, and P.~Luo, ``Segformer:
  Simple and efficient design for semantic segmentation with transformers,''
  {\em Proc. Advances in Neural Inf. Process. Syst.}, vol.~34, 2021.

\bibitem{p2t}
Y.-H. Wu, Y.~Liu, X.~Zhan, and M.-M. Cheng, ``P2t: Pyramid pooling transformer
  for scene understanding,'' {\em {IEEE} Trans. Pattern Anal. Mach. Intell.},
  2022.

\bibitem{lin2017focal}
T.-Y. Lin, P.~Goyal, R.~Girshick, K.~He, and P.~Doll{\'a}r, ``Focal loss for
  dense object detection,'' in {\em Proc. IEEE Int. Conf. Comp. Vis.},
  pp.~2980--2988, 2017.

\bibitem{diceloss}
F.~Milletari, N.~Navab, and S.-A. Ahmadi, ``V-net: Fully convolutional neural
  networks for volumetric medical image segmentation,'' in {\em 3DV},
  pp.~565--571, IEEE, 2016.

\bibitem{detr}
N.~Carion, F.~Massa, G.~Synnaeve, N.~Usunier, A.~Kirillov, and S.~Zagoruyko,
  ``End-to-end object detection with transformers,'' in {\em Proc. Eur. Conf.
  Comp. Vis.}, pp.~213--229, Springer, 2020.

\bibitem{2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  {\L}.~Kaiser, and I.~Polosukhin, ``Attention is all you need,'' {\em Proc.
  Advances in Neural Inf. Process. Syst.}, vol.~30, 2017.

\bibitem{ade20k}
B.~Zhou, H.~Zhao, X.~Puig, S.~Fidler, A.~Barriuso, and A.~Torralba, ``Scene
  parsing through ade20k dataset,'' in {\em Proc. IEEE Conf. Comp. Vis. Patt.
  Recogn.}, pp.~633--641, 2017.

\bibitem{cocostuff}
H.~Caesar, J.~Uijlings, and V.~Ferrari, ``Coco-stuff: Thing and stuff classes
  in context,'' in {\em Proc. IEEE Conf. Comp. Vis. Patt. Recogn.},
  pp.~1209--1218, 2018.

\bibitem{mmseg}
MMSegmentation, ``{MMSegmentation}: {OpenMMLab} semantic segmentation toolbox
  and benchmark.'' \url{https://github.com/open-mmlab/mmsegmentation}, 2020.

\bibitem{pascal_context}
R.~Mottaghi, X.~Chen, X.~Liu, N.-G. Cho, S.-W. Lee, S.~Fidler, R.~Urtasun, and
  A.~Yuille, ``The role of context for object detection and semantic
  segmentation in the wild,'' in {\em Proc. IEEE Conf. Comp. Vis. Patt.
  Recogn.}, pp.~891--898, 2014.

\bibitem{augreg}
A.~Steiner, A.~Kolesnikov, X.~Zhai, R.~Wightman, J.~Uszkoreit, and L.~Beyer,
  ``How to train your vit? data, augmentation, and regularization in vision
  transformers,'' {\em arXiv: Comp. Res. Repository}, 2021.

\bibitem{lin2022structtoken}
F.~Lin, Z.~Liang, J.~He, M.~Zheng, S.~Tian, and K.~Chen, ``Structtoken:
  Rethinking semantic segmentation with structural prior,'' {\em arXiv: Comp.
  Res. Repository}, 2022.

\bibitem{Upernet}
T.~Xiao, Y.~Liu, B.~Zhou, Y.~Jiang, and J.~Sun, ``Unified perceptual parsing
  for scene understanding,'' in {\em Proc. Eur. Conf. Comp. Vis.},
  pp.~418--434, 2018.

\bibitem{MCIBI}
Z.~Jin, T.~Gong, D.~Yu, Q.~Chu, J.~Wang, C.~Wang, and J.~Shao, ``Mining
  contextual information beyond image for semantic segmentation,'' in {\em
  Proc. IEEE Int. Conf. Comp. Vis.}, pp.~7231--7241, 2021.

\bibitem{danet}
J.~Fu, J.~Liu, H.~Tian, Y.~Li, Y.~Bao, Z.~Fang, and H.~Lu, ``Dual attention
  network for scene segmentation,'' in {\em Proc. IEEE Conf. Comp. Vis. Patt.
  Recogn.}, pp.~3146--3154, 2019.

\bibitem{emanet}
X.~Li, Z.~Zhong, J.~Wu, Y.~Yang, Z.~Lin, and H.~Liu, ``Expectation-maximization
  attention networks for semantic segmentation,'' in {\em Proc. IEEE Int. Conf.
  Comp. Vis.}, pp.~9167--9176, 2019.

\bibitem{spygr}
X.~Li, Y.~Yang, Q.~Zhao, T.~Shen, Z.~Lin, and H.~Liu, ``Spatial pyramid based
  graph reasoning for semantic segmentation,'' in {\em Proc. IEEE Conf. Comp.
  Vis. Patt. Recogn.}, pp.~8950--8959, 2020.

\bibitem{wu2020ginet}
T.~Wu, Y.~Lu, Y.~Zhu, C.~Zhang, M.~Wu, Z.~Ma, and G.~Guo, ``Ginet: Graph
  interaction network for scene parsing,'' in {\em Proc. Eur. Conf. Comp.
  Vis.}, pp.~34--51, Springer, 2020.

\bibitem{reconet}
W.~Chen, X.~Zhu, R.~Sun, J.~He, R.~Li, X.~Shen, and B.~Yu, ``Tensor low-rank
  reconstruction for semantic segmentation,'' in {\em Proc. Eur. Conf. Comp.
  Vis.}, pp.~52--69, Springer, 2020.

\bibitem{jin2021isnet}
Z.~Jin, B.~Liu, Q.~Chu, and N.~Yu, ``Isnet: Integrate image-level and
  semantic-level context for semantic segmentation,'' in {\em Proc. IEEE Int.
  Conf. Comp. Vis.}, pp.~7189--7198, 2021.

\bibitem{hrnet}
K.~Sun, Y.~Zhao, B.~Jiang, T.~Cheng, B.~Xiao, D.~Liu, Y.~Mu, X.~Wang, W.~Liu,
  and J.~Wang, ``High-resolution representations for labeling pixels and
  regions,'' {\em arXiv: Comp. Res. Repository}, 2019.

\bibitem{lin2017refinenet}
G.~Lin, A.~Milan, C.~Shen, and I.~Reid, ``{RefineNet}: Multi-path refinement
  networks for high-resolution semantic segmentation,'' in {\em Proc. IEEE
  Conf. Comp. Vis. Patt. Recogn.}, pp.~1925--1934, 2017.

\bibitem{zhou2018unet++}
Z.~Zhou, M.~M.~R. Siddiquee, N.~Tajbakhsh, and J.~Liang, ``{Unet++}: A nested
  {U}-net architecture for medical image segmentation,'' in {\em Proc.\ Deep
  Learning in Medical Image Analysis Workshop}, pp.~3--11, 2018.

\bibitem{ding2018context}
H.~Ding, X.~Jiang, B.~Shuai, A.~Q. Liu, and G.~Wang, ``Context contrasted
  feature and gated multi-scale aggregation for scene segmentation,'' in {\em
  Proc. IEEE Conf. Comp. Vis. Patt. Recogn.}, pp.~2393--2402, 2018.

\bibitem{Encnet}
H.~Zhang, K.~Dana, J.~Shi, Z.~Zhang, X.~Wang, A.~Tyagi, and A.~Agrawal,
  ``Context encoding for semantic segmentation,'' in {\em Proc. IEEE Conf.
  Comp. Vis. Patt. Recogn.}, pp.~7151--7160, 2018.

\bibitem{nrd}
B.~Zhang, Z.~Tian, C.~Shen, {\em et~al.}, ``Dynamic neural representational
  decoders for high-resolution semantic segmentation,'' {\em Proc. Advances in
  Neural Inf. Process. Syst.}, vol.~34, 2021.

\bibitem{li2020gated}
X.~Li, H.~Zhao, L.~Han, Y.~Tong, S.~Tan, and K.~Yang, ``Gated fully fusion for
  semantic segmentation,'' in {\em Proc. {AAAI} Conf. Artificial Intell.},
  vol.~34, pp.~11418--11425, 2020.

\bibitem{liu2020efficientfcn}
J.~Liu, J.~He, J.~Zhang, J.~Ren, and H.~Li, ``{EfficientFCN}:
  Holistically-guided decoding for semantic segmentation,'' in {\em Proc. Eur.
  Conf. Comp. Vis.}, 2020.

\bibitem{cheng2021mask2former}
B.~Cheng, I.~Misra, A.~G. Schwing, A.~Kirillov, and R.~Girdhar,
  ``Masked-attention mask transformer for universal image segmentation,'' 2022.

\end{thebibliography}
