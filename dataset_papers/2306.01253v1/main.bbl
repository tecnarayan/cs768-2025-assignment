\begin{thebibliography}{40}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Alamaniotis et~al.(2013)Alamaniotis, Mattingly, and
  Tsoukalas]{alamaniotis2013kernel}
Alamaniotis, M., Mattingly, J., and Tsoukalas, L.~H.
\newblock Kernel-based machine learning for background estimation of nai
  low-count gamma-ray spectra.
\newblock \emph{IEEE Transactions on Nuclear Science}, 60\penalty0
  (3):\penalty0 2209--2221, 2013.

\bibitem[Bekker \& Davis(2018)Bekker and Davis]{bekker2018estimating}
Bekker, J. and Davis, J.
\newblock Estimating the class prior in positive and unlabeled data through
  decision tree induction.
\newblock In \emph{Thirty-Second AAAI Conference on Artificial Intelligence},
  2018.

\bibitem[Bekker \& Davis(2020)Bekker and Davis]{bekker2020learning}
Bekker, J. and Davis, J.
\newblock Learning from positive and unlabeled data: A survey.
\newblock \emph{Machine Learning}, 109\penalty0 (4):\penalty0 719--760, 2020.

\bibitem[Bekker et~al.(2019)Bekker, Robberechts, and Davis]{bekker2019beyond}
Bekker, J., Robberechts, P., and Davis, J.
\newblock Beyond the selected completely at random assumption for learning from
  positive and unlabeled data.
\newblock In \emph{Joint European Conference on Machine Learning and Knowledge
  Discovery in Databases}, pp.\  71--85. Springer, 2019.

\bibitem[Bickel et~al.(2009)Bickel, Br{\"u}ckner, and
  Scheffer]{bickel2009discriminative}
Bickel, S., Br{\"u}ckner, M., and Scheffer, T.
\newblock Discriminative learning under covariate shift.
\newblock \emph{Journal of Machine Learning Research}, 10\penalty0 (9), 2009.

\bibitem[Blanchard et~al.(2010)Blanchard, Lee, and Scott]{blanchard2010semi}
Blanchard, G., Lee, G., and Scott, C.
\newblock Semi-supervised novelty detection.
\newblock \emph{The Journal of Machine Learning Research}, 11:\penalty0
  2973--3009, 2010.

\bibitem[Blanchard et~al.(2016)Blanchard, Flaska, Handy, Pozzi, Scott,
  et~al.]{blanchard2016classification}
Blanchard, G., Flaska, M., Handy, G., Pozzi, S., Scott, C., et~al.
\newblock Classification with asymmetric label noise: Consistency and maximal
  denoising.
\newblock \emph{Electronic Journal of Statistics}, 10\penalty0 (2):\penalty0
  2780--2824, 2016.

\bibitem[Cai \& Wei(2021)Cai and Wei]{cai2021transfer}
Cai, T.~T. and Wei, H.
\newblock Transfer learning for nonparametric classification: Minimax rate and
  adaptive classifier.
\newblock \emph{The Annals of Statistics}, 49\penalty0 (1):\penalty0 100--128,
  2021.

\bibitem[Cowan(1998)]{cowan1998statistical}
Cowan, G.
\newblock \emph{Statistical data analysis}.
\newblock Oxford university press, 1998.

\bibitem[Du~Plessis \& Sugiyama(2014)Du~Plessis and Sugiyama]{du2014class}
Du~Plessis, M.~C. and Sugiyama, M.
\newblock Class prior estimation from positive and unlabeled data.
\newblock \emph{IEICE TRANSACTIONS on Information and Systems}, 97\penalty0
  (5):\penalty0 1358--1362, 2014.

\bibitem[Du~Plessis et~al.(2014)Du~Plessis, Niu, and Sugiyama]{du2014analysis}
Du~Plessis, M.~C., Niu, G., and Sugiyama, M.
\newblock Analysis of learning from positive and unlabeled data.
\newblock \emph{Advances in neural information processing systems}, 27, 2014.

\bibitem[Elkan \& Noto(2008)Elkan and Noto]{elkan2008learning}
Elkan, C. and Noto, K.
\newblock Learning classifiers from only positive and unlabeled data.
\newblock In \emph{Proceedings of the 14th ACM SIGKDD international conference
  on Knowledge discovery and data mining}, pp.\  213--220, 2008.

\bibitem[Fei et~al.(2013)Fei, Kim, Sahu, Naphade, Mamidipalli, and
  Hutchinson]{fei2013heat}
Fei, H., Kim, Y., Sahu, S., Naphade, M., Mamidipalli, S.~K., and Hutchinson, J.
\newblock Heat pump detection from coarse grained smart meter data with
  positive and unlabeled learning.
\newblock In \emph{Proceedings of the 19th ACM SIGKDD international conference
  on Knowledge discovery and data mining}, pp.\  1330--1338, 2013.

\bibitem[Garg et~al.(2021)Garg, Wu, Smola, Balakrishnan, and
  Lipton]{garg2021mixture}
Garg, S., Wu, Y., Smola, A.~J., Balakrishnan, S., and Lipton, Z.
\newblock Mixture proportion estimation and {PU} learning: A modern approach.
\newblock \emph{Advances in Neural Information Processing Systems},
  34:\penalty0 8532--8544, 2021.

\bibitem[Gong et~al.(2021)Gong, Wang, Liu, Han, You, Yang, and
  Tao]{gong2021instance}
Gong, C., Wang, Q., Liu, T., Han, B., You, J., Yang, J., and Tao, D.
\newblock Instance-dependent positive and unlabeled learning with labeling bias
  estimation.
\newblock \emph{IEEE Transactions on Pattern Analysis and Machine
  Intelligence}, 44\penalty0 (8):\penalty0 4163--4177, 2021.

\bibitem[Gonz{\'a}lez et~al.(2017)Gonz{\'a}lez, Casta{\~n}o, Chawla, and
  Coz]{gonzalez2017review}
Gonz{\'a}lez, P., Casta{\~n}o, A., Chawla, N.~V., and Coz, J. J.~D.
\newblock A review on quantification learning.
\newblock \emph{ACM Computing Surveys (CSUR)}, 50\penalty0 (5):\penalty0 1--40,
  2017.

\bibitem[Gorber et~al.(2009)Gorber, Schofield-Hurwitz, Hardt, Levasseur, and
  Tremblay]{gorber2009accuracy}
Gorber, S.~C., Schofield-Hurwitz, S., Hardt, J., Levasseur, G., and Tremblay,
  M.
\newblock The accuracy of self-reported smoking: a systematic review of the
  relationship between self-reported and cotinine-assessed smoking status.
\newblock \emph{Nicotine \& tobacco research}, 11\penalty0 (1):\penalty0
  12--24, 2009.

\bibitem[Gretton et~al.(2009)Gretton, Smola, Huang, Schmittfull, Borgwardt, and
  Sch{\"o}lkopf]{gretton2009covariate}
Gretton, A., Smola, A., Huang, J., Schmittfull, M., Borgwardt, K., and
  Sch{\"o}lkopf, B.
\newblock Covariate shift by kernel mean matching.
\newblock \emph{Dataset shift in machine learning}, 3\penalty0 (4):\penalty0 5,
  2009.

\bibitem[Heckman(1979)]{heckman1979sample}
Heckman, J.~J.
\newblock Sample selection bias as a specification error.
\newblock \emph{Econometrica: Journal of the econometric society}, pp.\
  153--161, 1979.

\bibitem[Ivanov(2020)]{ivanov2020dedpul}
Ivanov, D.
\newblock {DEDPUL}: Difference-of-estimated-densities-based positive-unlabeled
  learning.
\newblock In \emph{2020 19th IEEE International Conference on Machine Learning
  and Applications (ICMLA)}, pp.\  782--790. IEEE, 2020.

\bibitem[Jain et~al.(2016)Jain, White, Trosset, and
  Radivojac]{jain2016nonparametric}
Jain, S., White, M., Trosset, M.~W., and Radivojac, P.
\newblock Nonparametric semi-supervised learning of class proportions.
\newblock \emph{arXiv preprint arXiv:1601.01944}, 2016.

\bibitem[Kato et~al.(2018)Kato, Teshima, and Honda]{kato2018learning}
Kato, M., Teshima, T., and Honda, J.
\newblock Learning from positive and unlabeled data with a selection bias.
\newblock In \emph{International conference on learning representations}, 2018.

\bibitem[Kiryo et~al.(2017)Kiryo, Niu, Du~Plessis, and
  Sugiyama]{kiryo2017positive}
Kiryo, R., Niu, G., Du~Plessis, M.~C., and Sugiyama, M.
\newblock Positive-unlabeled learning with non-negative risk estimator.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Knoll(2010)]{knoll2010radiation}
Knoll, G.~F.
\newblock \emph{Radiation detection and measurement}.
\newblock John Wiley \& Sons, 2010.

\bibitem[Lawrence \& Sch{\"o}lkopf(2001)Lawrence and
  Sch{\"o}lkopf]{lawrence2001estimating}
Lawrence, N. and Sch{\"o}lkopf, B.
\newblock Estimating a kernel {F}isher discriminant in the presence of label
  noise.
\newblock In \emph{18th International Conference on Machine Learning (ICML
  2001)}, pp.\  306--306. Morgan Kaufmann, 2001.

\bibitem[Li et~al.(2019)Li, Gu, Ge, Li, Tang, Lang, and Hu]{li2019review}
Li, F., Gu, Z., Ge, L., Li, H., Tang, X., Lang, X., and Hu, B.
\newblock Review of recent gamma spectrum unfolding algorithms and their
  application.
\newblock \emph{Results in Physics}, 13:\penalty0 102211, 2019.

\bibitem[MacKay(2003)]{mackay2003information}
MacKay, D.~J.
\newblock \emph{Information theory, inference and learning algorithms}.
\newblock Cambridge university press, 2003.

\bibitem[Maity et~al.(2023)Maity, Dutta, Terhorst, Sun, and
  Banerjee]{maity2021linear}
Maity, S., Dutta, D., Terhorst, J., Sun, Y., and Banerjee, M.
\newblock {A linear adjustment based approach to posterior drift in transfer
  learning}.
\newblock \emph{Biometrika}, 2023.
\newblock URL \url{https://doi.org/10.1093/biomet/asad029}.

\bibitem[Natarajan et~al.(2013)Natarajan, Dhillon, Ravikumar, and
  Tewari]{natarajan2013learning}
Natarajan, N., Dhillon, I.~S., Ravikumar, P.~K., and Tewari, A.
\newblock Learning with noisy labels.
\newblock \emph{Advances in neural information processing systems}, 26, 2013.

\bibitem[Ramaswamy et~al.(2016)Ramaswamy, Scott, and
  Tewari]{ramaswamy2016mixture}
Ramaswamy, H., Scott, C., and Tewari, A.
\newblock Mixture proportion estimation via kernel embeddings of distributions.
\newblock In \emph{International conference on machine learning}, pp.\
  2052--2060. PMLR, 2016.

\bibitem[Saerens et~al.(2002)Saerens, Latinne, and
  Decaestecker]{saerens2002adjusting}
Saerens, M., Latinne, P., and Decaestecker, C.
\newblock Adjusting the outputs of a classifier to new a priori probabilities:
  a simple procedure.
\newblock \emph{Neural computation}, 14\penalty0 (1):\penalty0 21--41, 2002.

\bibitem[Sanderson \& Scott(2014)Sanderson and Scott]{sanderson2014class}
Sanderson, T. and Scott, C.
\newblock Class proportion estimation with application to multiclass anomaly
  rejection.
\newblock In \emph{Artificial Intelligence and Statistics}, pp.\  850--858.
  PMLR, 2014.

\bibitem[Scott(2015)]{scott2015rate}
Scott, C.
\newblock A rate of convergence for mixture proportion estimation, with
  application to learning from noisy labels.
\newblock In \emph{Artificial Intelligence and Statistics}, pp.\  838--846.
  PMLR, 2015.

\bibitem[Scott(2019)]{scott2019generalized}
Scott, C.
\newblock A generalized {N}eyman-{P}earson criterion for optimal domain
  adaptation.
\newblock In \emph{Algorithmic Learning Theory}, pp.\  738--761. PMLR, 2019.

\bibitem[Shanmugam \& Pierson(2021)Shanmugam and
  Pierson]{shanmugam2021quantifying}
Shanmugam, D. and Pierson, E.
\newblock Quantifying inequality in underreported medical conditions.
\newblock \emph{arXiv preprint arXiv:2110.04133}, 2021.

\bibitem[Storkey et~al.(2009)]{storkey2009training}
Storkey, A. et~al.
\newblock When training and test sets are different: characterizing learning
  transfer.
\newblock \emph{Dataset shift in machine learning}, 30:\penalty0 3--28, 2009.

\bibitem[Werner et~al.(2018)Werner, Bull, Solomon, Brown, McKinney, Rising,
  Dixon, Martz, Hughes, Cox, et~al.]{werner2018mcnp6}
Werner, C.~J., Bull, J., Solomon, C., Brown, F., McKinney, G., Rising, M.,
  Dixon, D., Martz, R., Hughes, H., Cox, L., et~al.
\newblock {MCNP} 6.2 release notes.
\newblock \emph{Los Alamos National Laboratory}, 2018.

\bibitem[Yao et~al.(2022)Yao, Liu, Han, Gong, Niu, Sugiyama, and
  Tao]{yao2022rethinking}
Yao, Y., Liu, T., Han, B., Gong, M., Niu, G., Sugiyama, M., and Tao, D.
\newblock Rethinking class-prior estimation for positive-unlabeled learning.
\newblock In \emph{International Conference on Learning Representations}, 2022.
\newblock URL \url{https://openreview.net/forum?id=aYAA-XHKyk}.

\bibitem[Zhang et~al.(2013)Zhang, Sch{\"o}lkopf, Muandet, and
  Wang]{zhang2013domain}
Zhang, K., Sch{\"o}lkopf, B., Muandet, K., and Wang, Z.
\newblock Domain adaptation under target and conditional shift.
\newblock In \emph{International conference on machine learning}, pp.\
  819--827. PMLR, 2013.

\bibitem[Zhang \& Goldman(2001)Zhang and Goldman]{zhang2001dd}
Zhang, Q. and Goldman, S.
\newblock {EM-DD}: An improved multiple-instance learning technique.
\newblock \emph{Advances in neural information processing systems}, 14, 2001.

\end{thebibliography}
