\begin{thebibliography}{26}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Abbeel and Ng(2004)]{Abbeel04}
Pieter Abbeel and Andrew Ng.
\newblock Apprenticeship learning via inverse reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pages 1--8,
  2004.

\bibitem[Amodei et~al.(2016)Amodei, Olah, Steinhardt, Christiano, Schulman, and
  Mané]{AmodeiOlah16}
Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, and
  Dan Mané.
\newblock Concrete problems in {AI} safety.
\newblock \emph{arXiv preprint arXiv:1606.06565}, 2016.

\bibitem[Armstrong and Levinstein(2017)]{Armstrong17}
Stuart Armstrong and Benjamin Levinstein.
\newblock Low impact artificial intelligences.
\newblock \emph{arXiv preprint arXiv:1705.10720}, 2017.

\bibitem[Chow et~al.(2015)Chow, Tamar, Mannor, and Pavone]{Chow15}
Yinlam Chow, Aviv Tamar, Shie Mannor, and Marco Pavone.
\newblock Risk-sensitive and robust decision-making: a {CVaR} optimization
  approach.
\newblock In \emph{Neural Information Processing Systems}, pages 1522--1530,
  2015.

\bibitem[Christiano et~al.(2017)Christiano, Leike, Brown, Martic, Legg, and
  Amodei]{Christiano17}
Paul Christiano, Jan Leike, Tom~B Brown, Miljan Martic, Shane Legg, and Dario
  Amodei.
\newblock Deep reinforcement learning from human preferences.
\newblock In \emph{Neural Information Processing Systems}, 2017.

\bibitem[Eysenbach et~al.(2017)Eysenbach, Gu, Ibarz, and Levine]{Eysenbach17}
Benjamin Eysenbach, Shixiang Gu, Julian Ibarz, and Sergey Levine.
\newblock Leave no {T}race: Learning to reset for safe and autonomous
  reinforcement learning.
\newblock \emph{arXiv preprint arXiv:1711.06782}, 2017.

\bibitem[Hadfield-Menell et~al.(2016)Hadfield-Menell, Dragan, Abbeel, and
  Russell]{Hadfield-Menell16}
Dylan Hadfield-Menell, Anca Dragan, Pieter Abbeel, and Stuart Russell.
\newblock Cooperative inverse reinforcement learning.
\newblock In \emph{Neural Information Processing Systems}, 2016.

\bibitem[Hadfield{-}Menell et~al.(2017)Hadfield{-}Menell, Milli, Abbeel,
  Russell, and Dragan]{Hadfield-Menell17}
Dylan Hadfield{-}Menell, Smitha Milli, Pieter Abbeel, Stuart~J. Russell, and
  Anca~D. Dragan.
\newblock Inverse reward design.
\newblock In \emph{Neural Information Processing Systems}, pages 6768--6777,
  2017.

\bibitem[Klyubin et~al.(2005)Klyubin, Polani, and Nehaniv]{Klyubin05}
Alexander~S. Klyubin, Daniel Polani, and Chrystopher~L. Nehaniv.
\newblock All else being equal be empowered.
\newblock In \emph{European Conference on Artificial Life (ECAL)}, pages
  744--753, 2005.

\bibitem[Krakovna et~al.(2019)Krakovna, Orseau, Kumar, Martic, and
  Legg]{Krakovna19}
Victoria Krakovna, Laurent Orseau, Ramana Kumar, Miljan Martic, and Shane Legg.
\newblock Penalizing side effects using stepwise relative reachability.
\newblock \emph{arXiv preprint arXiv:1806.01186}, 2019.

\bibitem[Krakovna et~al.(2020)Krakovna, Uesato, Mikulik, Rahtz, Everitt, Kumar,
  Kenton, Leike, and Legg]{Krakovna20}
Victoria Krakovna, Jonathan Uesato, Vladimir Mikulik, Matthew Rahtz, Tom
  Everitt, Ramana Kumar, Zac Kenton, Jan Leike, and Shane Legg.
\newblock {Specification gaming: the flip side of AI ingenuity}.
\newblock DeepMind Blog, 2020.

\bibitem[Leech et~al.(2018)Leech, Kubicki, Cooper, and McGrath]{Leech18}
Gavin Leech, Karol Kubicki, Jessica Cooper, and Tom McGrath.
\newblock Preventing {Side}-effects in {Gridworlds}, 2018.
\newblock URL \url{www.gleech.org/grids/}.

\bibitem[Leike et~al.(2017)Leike, Martic, Krakovna, Ortega, Everitt, Lefrancq,
  Orseau, and Legg]{Leike17}
Jan Leike, Miljan Martic, Victoria Krakovna, Pedro~A. Ortega, Tom Everitt,
  Andrew Lefrancq, Laurent Orseau, and Shane Legg.
\newblock {AI} safety gridworlds.
\newblock \emph{arXiv preprint arXiv:1711.09883}, 2017.
\newblock URL \url{github.com/deepmind/ai-safety-gridworlds}.

\bibitem[Lipton et~al.(2016)Lipton, Gao, Li, Chen, and Deng]{Lipton16}
Zachary~C. Lipton, Jianfeng Gao, Lihong Li, Jianshu Chen, and Li~Deng.
\newblock Combating reinforcement learning's {S}isyphean curse with intrinsic
  fear.
\newblock \emph{arXiv preprint arXiv:1611.01211}, 2016.

\bibitem[McCarthy and Hayes(1969)]{Mccarthy69}
John McCarthy and Patrick~J. Hayes.
\newblock Some philosophical problems from the standpoint of artificial
  intelligence.
\newblock In \emph{Machine Intelligence}, pages 463--502. Edinburgh University
  Press, 1969.

\bibitem[Moldovan and Abbeel(2012)]{Moldovan12}
Teodor~Mihai Moldovan and Pieter Abbeel.
\newblock Safe exploration in {M}arkov decision processes.
\newblock In \emph{International Conference on Machine Learning (ICML)}, pages
  1451--1458, 2012.

\bibitem[Ng and Russell(2000)]{Ng00}
Andrew Ng and Stuart Russell.
\newblock Algorithms for inverse reinforcement learning.
\newblock In \emph{International Conference on Machine Learning}, pages
  663--670, 2000.

\bibitem[Salge et~al.(2014)Salge, Glackin, and Polani]{Salge14}
Christoph Salge, Cornelius Glackin, and Daniel Polani.
\newblock Empowerment --- an introduction.
\newblock In \emph{Guided Self-Organization: Inception}, pages 67--114.
  Springer, 2014.

\bibitem[Saunders et~al.(2017)Saunders, Sastry, Stuhlmueller, and
  Evans]{Saunders17}
William Saunders, Girish Sastry, Andreas Stuhlmueller, and Owain Evans.
\newblock Trial without error: Towards safe reinforcement learning via human
  intervention.
\newblock \emph{arXiv preprint arXiv:1707.05173}, 2017.

\bibitem[Schaul et~al.(2015)Schaul, Horgan, Gregor, and Silver]{Schaul15}
Tom Schaul, Daniel Horgan, Karol Gregor, and David Silver.
\newblock Universal value function approximators.
\newblock In Francis Bach and David Blei, editors, \emph{Proceedings of the
  32nd International Conference on Machine Learning}, volume~37, pages
  1312--1320, 2015.

\bibitem[Shah et~al.(2019)Shah, Krasheninnikov, Alexander, Abbeel, and
  Dragan]{Shah19}
Rohin Shah, Dmitrii Krasheninnikov, Jordan Alexander, Pieter Abbeel, and Anca
  Dragan.
\newblock Preferences implicit in the state of the world.
\newblock In \emph{International Conference for Learning Representations
  (ICLR)}, 2019.

\bibitem[Sutton and Barto(2018)]{Sutton18}
Richard Sutton and Andrew Barto.
\newblock \emph{Reinforcement Learning: An Introduction}.
\newblock A Bradford Book, Cambridge, MA, USA, 2018.

\bibitem[Taylor(2016)]{Taylor2016quant}
Jessica Taylor.
\newblock Quantilizers: A safer alternative to maximizers for limited
  optimization.
\newblock In \emph{AAAI Workshop on AI, Ethics, and Society}, pages 1--9, 2016.

\bibitem[Turner et~al.(2020{\natexlab{a}})Turner, Hadfield-Menell, and
  Tadepalli]{Turner20}
Alexander~Matt Turner, Dylan Hadfield-Menell, and Prasad Tadepalli.
\newblock Conservative agency via {A}ttainable {U}tility {P}reservation.
\newblock \emph{Proceedings of the AAAI/ACM Conference on AI, Ethics, and
  Society}, 2020{\natexlab{a}}.

\bibitem[Turner et~al.(2020{\natexlab{b}})Turner, Ratzlaff, and
  Tadepalli]{Turner20complex}
Alexander~Matt Turner, Neale Ratzlaff, and Prasad Tadepalli.
\newblock Avoiding side effects in complex environments.
\newblock In \emph{Neural Information Processing Systems}, 2020{\natexlab{b}}.

\bibitem[Zhang et~al.(2018)Zhang, Durfee, and Singh]{Zhang18}
Shun Zhang, Edmund~H. Durfee, and Satinder~P. Singh.
\newblock Minimax-regret querying on side effects for safe optimality in
  factored {Markov Decision Processes}.
\newblock In \emph{International Joint Conference on Artificial Intelligence
  {(IJCAI)}}, pages 4867--4873, 2018.

\end{thebibliography}
