\begin{thebibliography}{33}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[cal()]{caltrans}
{CalTrans. Pems: California performance measuring system}.
\newblock \url{http://pems.dot.ca.gov/}.
\newblock [Online; accessed 1-May-2018].

\bibitem[Badanidiyuru and Vondr{\'{a}}k(2014)]{Badanidiyuru2014}
Ashwinkumar Badanidiyuru and Jan Vondr{\'{a}}k.
\newblock {Fast algorithms for maximizing submodular functions}.
\newblock In \emph{ACM-SIAM Symposium on Discrete Algorithms (SODA)}, 2014.

\bibitem[Balkanski and Singer(2018)]{Balkanski2018}
Eric Balkanski and Yaron Singer.
\newblock {The adaptive complexity of maximizing a submodular function}.
\newblock In \emph{ACM SIGACT Symposium on Theory of Computing (STOC)}, 2018.

\bibitem[Balkanski et~al.(2018)Balkanski, Breuer, and
  Singer]{DBLP:conf/nips/BalkanskiBS18}
Eric Balkanski, Adam Breuer, and Yaron Singer.
\newblock Non-monotone submodular maximization in exponentially fewer
  iterations.
\newblock In \emph{Advances in Neural Information Processing Systems 31: Annual
  Conference on Neural Information Processing Systems 2018, NeurIPS 2018,
  December 3-8, 2018, Montr{\'{e}}al, Canada}, pages 2359--2370, 2018.

\bibitem[Balkanski et~al.(2019{\natexlab{a}})Balkanski, Rubinstein, and
  Singer]{Balkanski}
Eric Balkanski, Aviad Rubinstein, and Yaron Singer.
\newblock {An Exponential Speedup in Parallel Running Time for Submodular
  Maximization without Loss in Approximation}.
\newblock In \emph{ACM-SIAM Symposium on Discrete Algorithms (SODA)},
  2019{\natexlab{a}}.

\bibitem[Balkanski et~al.(2019{\natexlab{b}})Balkanski, Rubinstein, and
  Singer]{Balkanski2018c}
Eric Balkanski, Aviad Rubinstein, and Yaron Singer.
\newblock {An optimal approximation for submodular maximization under a matroid
  constraint in the adaptive complexity model}.
\newblock In \emph{Proceedings of the Annual ACM Symposium on Theory of
  Computing}, pages 66--77, nov 2019{\natexlab{b}}.

\bibitem[Barbosa et~al.(2015)Barbosa, Ene, {Le Nguyen}, and Ward]{Barbosa2015}
Rafael Barbosa, Alina Ene, Huy {Le Nguyen}, and Justin Ward.
\newblock {The Power of Randomization: Distributed Submodular Maximization on
  Massive Datasets}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2015.

\bibitem[Barbosa et~al.(2016)Barbosa, Ene, Nguyen, and Ward]{Barbosa2016}
Rafael Da~Ponte Barbosa, Alina Ene, Huy~L. Nguyen, and Justin Ward.
\newblock {A New Framework for Distributed Submodular Maximization}.
\newblock In \emph{IEEE Symposium on Foundations of Computer Science (FOCS)},
  2016.

\bibitem[Breuer et~al.(2019)Breuer, Balkanski, and Singer]{Breuer2019}
Adam Breuer, Eric Balkanski, and Yaron Singer.
\newblock {The FAST Algorithm for Submodular Maximization}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2019.

\bibitem[Calinescu et~al.(2007)Calinescu, Chekuri, P{\'{a}}l, and
  Vondr{\'{a}}k]{Calinescu2007}
Gruia Calinescu, Chandra Chekuri, Martin P{\'{a}}l, and Jan Vondr{\'{a}}k.
\newblock {Maximizing a Submodular Set Function subject to a Matroid
  Constraint}.
\newblock In \emph{Integer Programming and Combinatorial Optimization (IPCO)},
  pages 182--196, 2007.

\bibitem[Chekuri and Quanrud(2019)]{Chekuri2018a}
Chandra Chekuri and Kent Quanrud.
\newblock {Submodular function maximization in parallel via the multilinear
  relaxation}.
\newblock In \emph{Proceedings of the Annual ACM-SIAM Symposium on Discrete
  Algorithms (SODA)}, pages 303--322, jul 2019.

\bibitem[Conforti and Cornu{\'{e}}jols(1984)]{Conforti1984}
Michele Conforti and G{\'{e}}rard Cornu{\'{e}}jols.
\newblock {Submodular set functions, matroids and the greedy algorithm: Tight
  worst-case bounds and some generalizations of the Rado-Edmonds theorem}.
\newblock \emph{Discrete Applied Mathematics}, 7\penalty0 (3):\penalty0
  251--274, 1984.

\bibitem[Dean and Ghemawat(2008)]{Dean2008}
Jeffrey Dean and Sanjay Ghemawat.
\newblock {MapReduce: Simplified Data Processing on Large Clusters}.
\newblock \emph{Communications of the ACM}, 51\penalty0 (1):\penalty0 107--113,
  2008.

\bibitem[Ene and Nguyen(2019)]{Ene}
Alina Ene and Huy~L Nguyen.
\newblock {Submodular Maximization with Nearly-optimal Approximation and
  Adaptivity in Nearly-linear Time}.
\newblock In \emph{ACM-SIAM Symposium on Discrete Algorithms (SODA)}, 2019.

\bibitem[Ene and Nguy{\^{e}}n(2020)]{Ene2020}
Alina Ene and Huy~L. Nguy{\^{e}}n.
\newblock {Parallel Algorithm for Non-Monotone DR-Submodular Maximization}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2020.

\bibitem[Epasto et~al.(2017)Epasto, Mirrokni, and Zadimoghaddam]{Epasto2017}
Alessandro Epasto, Vahab Mirrokni, and Morteza Zadimoghaddam.
\newblock {Bicriteria Distributed Submodular Maximization in a Few Rounds}.
\newblock In \emph{Symposium on Parallelism in Algorithms and Architectures
  (SPAA)}, 2017.

\bibitem[Fahrbach et~al.(2019{\natexlab{a}})Fahrbach, Mirrokni, and
  Zadimoghaddam]{Fahrbach2018}
Matthew Fahrbach, Vahab Mirrokni, and Morteza Zadimoghaddam.
\newblock {Submodular Maximization with Nearly Optimal Approximation,
  Adaptivity, and Query Complexity}.
\newblock In \emph{ACM-SIAM Symposium on Discrete Algorithms (SODA)}, pages
  255--273, 2019{\natexlab{a}}.

\bibitem[Fahrbach et~al.(2019{\natexlab{b}})Fahrbach, Mirrokni, and
  Zadimoghaddam]{Fahrbach2018a}
Matthew Fahrbach, Vahab Mirrokni, and Morteza Zadimoghaddam.
\newblock {Non-monotone Submodular Maximization with Nearly Optimal Adaptivity
  Complexity}.
\newblock In \emph{International Conference on Machine Learning (ICML)},
  2019{\natexlab{b}}.

\bibitem[Fahrbach et~al.(2019{\natexlab{c}})Fahrbach, Mirrokni, and
  Zadimoghaddam]{fahrbach2019non}
Matthew Fahrbach, Vahab Mirrokni, and Morteza Zadimoghaddam.
\newblock Non-monotone submodular maximization with nearly optimal adaptivity
  and query complexity.
\newblock In \emph{International Conference on Machine Learning}, pages
  1833--1842. PMLR, 2019{\natexlab{c}}.

\bibitem[Gillenwater et~al.(2012)Gillenwater, Kulesza, and
  Taskar]{Gillenwater2012}
Jennifer Gillenwater, Alex Kulesza, and Ben Taskar.
\newblock {Near-Optimal MAP Inference for Determinantal Point Processes}.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2012.

\bibitem[Horel and Singer(2016)]{Horel2016}
Thibaut Horel and Yaron Singer.
\newblock {Maximization of Approximately Submodular Functions}.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2016.

\bibitem[Kazemi et~al.(2019)Kazemi, Mitrovic, Zadimoghaddam, Lattanzi, and
  Karbasi]{Kazemi2019}
Ehsan Kazemi, Marko Mitrovic, Morteza Zadimoghaddam, Silvio Lattanzi, and Amin
  Karbasi.
\newblock {Submodular Streaming in All its Glory: Tight Approximation, Minimum
  Memory and Low Adaptive Complexity}.
\newblock In \emph{International Conference on Machine Learning (ICML)}, 2019.

\bibitem[Krause and Guestrin(2007)]{Krause2007}
Andreas Krause and Carlos Guestrin.
\newblock {Near-optimal observation selection using submodular functions}.
\newblock \emph{AAAI Conference on Artificial Intelligence}, 2007.

\bibitem[Kuhnle(2021{\natexlab{a}})]{Kuhnle2020a}
Alan Kuhnle.
\newblock {Quick Streaming Algorithms for Maximization of Monotone Submodular
  Functions in Linear Time}.
\newblock In \emph{Artificial Intelligence and Statistics (AISTATS)},
  2021{\natexlab{a}}.

\bibitem[Kuhnle(2021{\natexlab{b}})]{Kuhnle2020b}
Alan Kuhnle.
\newblock {Nearly Linear-Time, Parallelizable Algorithms for Non-Monotone
  Submodular Maximization}.
\newblock In \emph{AAAI Conference on Artificial Intelligence},
  2021{\natexlab{b}}.

\bibitem[Leskovec et~al.(2007)Leskovec, Krause, Guestrin, Faloutsos,
  VanBriesen, and Glance]{Leskovec2007}
Jure Leskovec, Andreas Krause, Carlos Guestrin, Christos Faloutsos, Jeanne
  VanBriesen, and Natalie Glance.
\newblock {Cost-effective Outbreak Detection in Networks}.
\newblock In \emph{ACM SIGKDD International Conference on Knowledge Discovery
  and Data Mining (KDD)}, 2007.

\bibitem[Minoux(1978)]{minoux1978accelerated}
Michel Minoux.
\newblock Accelerated greedy algorithms for maximizing submodular set
  functions.
\newblock In \emph{Optimization techniques}, pages 234--243. Springer, 1978.

\bibitem[Mirrokni and Zadimoghaddam(2015)]{Mirrokni2015}
Vahab Mirrokni and Morteza Zadimoghaddam.
\newblock {Randomized Composable Core-Sets for Distributed Submodular
  Maximization}.
\newblock In \emph{ACM Symposium on Theory of Computing (STOC)}, 2015.

\bibitem[Mirzasoleiman et~al.(2016)Mirzasoleiman, Badanidiyuru, and
  Karbasi]{mirzasoleiman2016fast}
Baharan Mirzasoleiman, Ashwinkumar Badanidiyuru, and Amin Karbasi.
\newblock Fast constrained submodular maximization: Personalized data
  summarization.
\newblock In \emph{International Conference on Machine Learning}, pages
  1358--1367. PMLR, 2016.

\bibitem[Mirzasoleiman et~al.(2018)Mirzasoleiman, Jegelka, and
  Krause]{Mirzasoleiman2018}
Baharan Mirzasoleiman, Stefanie Jegelka, and Andreas Krause.
\newblock {Streaming Non-Monotone Submodular Maximization: Personalized Video
  Summarization on the Fly}.
\newblock In \emph{AAAI Conference on Artificial Intelligence}, 2018.

\bibitem[Mitzenmacher and Upfal(2017)]{mitzenmacher2017probability}
Michael Mitzenmacher and Eli Upfal.
\newblock \emph{Probability and computing: Randomization and probabilistic
  techniques in algorithms and data analysis}.
\newblock Cambridge university press, 2017.

\bibitem[Nemhauser and Wolsey(1978)]{Nemhauser1978a}
G~L Nemhauser and L~A Wolsey.
\newblock {Best Algorithms for Approximating the Maximum of a Submodular Set
  Function}.
\newblock \emph{Mathematics of Operations Research}, 3\penalty0 (3):\penalty0
  177--188, 1978.

\bibitem[Rossi and Ahmed(2015)]{rossi2015network}
Ryan Rossi and Nesreen Ahmed.
\newblock The network data repository with interactive graph analytics and
  visualization.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~29, 2015.

\end{thebibliography}
