\begin{thebibliography}{30}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bebendorf(2008)]{bebendorf2008hierarchical}
Mario Bebendorf.
\newblock \emph{Hierarchical matrices}.
\newblock Springer, 2008.

\bibitem[Chen and Dongarra(2005)]{chen2005condition}
Zizhong Chen and Jack~J Dongarra.
\newblock Condition numbers of {G}aussian random matrices.
\newblock \emph{SIAM Journal on Matrix Analysis and Applications}, 27\penalty0
  (3):\penalty0 603--620, 2005.

\bibitem[Cutajar et~al.(2016)Cutajar, Osborne, Cunningham, and
  Filippone]{cutajar2016preconditioning}
Kurt Cutajar, Michael Osborne, John Cunningham, and Maurizio Filippone.
\newblock Preconditioning kernel matrices.
\newblock In \emph{International conference on machine learning}, pages
  2529--2538. PMLR, 2016.

\bibitem[Dua and Graff(2017)]{Dua2019}
Dheeru Dua and Casey Graff.
\newblock {UCI} machine learning repository, 2017.
\newblock URL \url{http://archive.ics.uci.edu/ml}.

\bibitem[Duchon et~al.(2004)Duchon, Flajolet, Louchard, and Schaeffer]{boltz}
Philippe Duchon, Philippe Flajolet, Guy Louchard, and Gilles Schaeffer.
\newblock Boltzmann samplers for the random generation of combinatorial
  structures.
\newblock \emph{Comb. Probab. Comput.}, 13\penalty0 (4–5):\penalty0
  577–625, jul 2004.
\newblock ISSN 0963-5483.
\newblock \doi{10.1017/S0963548304006315}.

\bibitem[Dutordoir et~al.(2020)Dutordoir, Durrande, and
  Hensman]{dutordoir2020sparse}
Vincent Dutordoir, Nicolas Durrande, and James Hensman.
\newblock Sparse {G}aussian processes with spherical harmonic features.
\newblock In \emph{International Conference on Machine Learning}, pages
  2793--2802. PMLR, 2020.

\bibitem[Feng and Baumgartner(2020)]{dai2020random}
Dai Feng and Richard Baumgartner.
\newblock Random forest {(RF)} kernel for regression, classification and
  survival.
\newblock \emph{CoRR}, abs/2009.00089, 2020.
\newblock URL \url{https://arxiv.org/abs/2009.00089}.

\bibitem[Fletcher(2013)]{fletcher2013practical}
Roger Fletcher.
\newblock \emph{Practical methods of optimization}.
\newblock John Wiley \& Sons, New York, 2nd edition, 2013.

\bibitem[Gardner et~al.(2018)Gardner, Pleiss, Weinberger, Bindel, and
  Wilson]{gardner2018gpytorch}
Jacob Gardner, Geoff Pleiss, Kilian~Q Weinberger, David Bindel, and Andrew~G
  Wilson.
\newblock Gpytorch: Blackbox matrix-matrix {G}aussian process inference with
  gpu acceleration.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Hackbusch(1999)]{hackbusch1999sparse}
Wolfgang Hackbusch.
\newblock A sparse matrix arithmetic based on $\mathcal{H}$-matrices. {P}art
  {I}: Introduction to $\mathcal{H}$-matrices.
\newblock \emph{Computing}, 62\penalty0 (2):\penalty0 89--108, 1999.

\bibitem[Hackbusch et~al.(2004)Hackbusch, Khoromskij, and
  Kriemann]{hackbusch2004hierarchical}
Wolfgang Hackbusch, Boris~N Khoromskij, and Ronald Kriemann.
\newblock Hierarchical matrices based on a weak admissibility criterion.
\newblock \emph{Computing}, 73\penalty0 (3):\penalty0 207--243, 2004.

\bibitem[Hartikainen and S{\"a}rkk{\"a}(2010)]{hartikainen2010kalman}
Jouni Hartikainen and Simo S{\"a}rkk{\"a}.
\newblock Kalman filtering and smoothing solutions to temporal {G}aussian
  process regression models.
\newblock In \emph{2010 IEEE international workshop on machine learning for
  signal processing}, pages 379--384. IEEE, 2010.

\bibitem[Hensman et~al.(2013)Hensman, Fusi, and Lawrence]{hensman13}
James Hensman, Nicol\`{o} Fusi, and Neil~D. Lawrence.
\newblock {G}aussian processes for big data.
\newblock In \emph{Proceedings of the Twenty-Ninth Conference on Uncertainty in
  Artificial Intelligence}, UAI'13, page 282–290, Arlington, Virginia, USA,
  2013. AUAI Press.

\bibitem[Kalman(1960)]{kalman1960new}
RE~Kalman.
\newblock A new approach to linear filtering and prediction problems.
\newblock \emph{Journal of Basic Engineering}, 83\penalty0 (1):\penalty0
  95--108, 1960.

\bibitem[Kapoor et~al.(2021)Kapoor, Finzi, Wang, and
  Wilson]{pmlr-v139-kapoor21a}
Sanyam Kapoor, Marc Finzi, Ke~Alexander Wang, and Andrew Gordon~Gordon Wilson.
\newblock Skiing on simplices: Kernel interpolation on the permutohedral
  lattice for scalable gaussian processes.
\newblock In Marina Meila and Tong Zhang, editors, \emph{Proceedings of the
  38th International Conference on Machine Learning}, volume 139 of
  \emph{Proceedings of Machine Learning Research}, pages 5279--5289. PMLR,
  18--24 Jul 2021.
\newblock URL \url{https://proceedings.mlr.press/v139/kapoor21a.html}.

\bibitem[L{\'a}zaro-Gredilla et~al.(2010)L{\'a}zaro-Gredilla,
  Quinonero-Candela, Rasmussen, and Figueiras-Vidal]{lazaro2010sparse}
Miguel L{\'a}zaro-Gredilla, Joaquin Quinonero-Candela, Carl~Edward Rasmussen,
  and An{\'\i}bal~R Figueiras-Vidal.
\newblock Sparse spectrum {G}aussian process regression.
\newblock \emph{The Journal of Machine Learning Research}, 11:\penalty0
  1865--1881, 2010.

\bibitem[Lévesque et~al.(2017)Lévesque, Durand, Gagné, and
  Sabourin]{levesque2017}
Julien-Charles Lévesque, Audrey Durand, Christian Gagné, and Robert Sabourin.
\newblock {B}ayesian optimization for conditional hyperparameter spaces.
\newblock In \emph{2017 International Joint Conference on Neural Networks
  (IJCNN)}, pages 286--293, 2017.

\bibitem[Ma and Blaschko(2020)]{ma2020}
Xingchen Ma and Matthew Blaschko.
\newblock Additive tree-structured covariance function for conditional
  parameter spaces in {B}ayesian optimization.
\newblock In Silvia Chiappa and Roberto Calandra, editors, \emph{Proceedings of
  the Twenty Third International Conference on Artificial Intelligence and
  Statistics}, volume 108 of \emph{Proceedings of Machine Learning Research},
  pages 1015--1025. PMLR, 26--28 Aug 2020.

\bibitem[Paszke et~al.(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, Desmaison, Kopf, Yang, DeVito, Raison,
  Tejani, Chilamkurthy, Steiner, Fang, Bai, and Chintala]{pytorch}
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
  Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban
  Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
  Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu~Fang, Junjie Bai, and Soumith
  Chintala.
\newblock Pytorch: An imperative style, high-performance deep learning library.
\newblock In \emph{Advances in Neural Information Processing Systems 32}, pages
  8024--8035. Curran Associates, Inc., 2019.
\newblock URL
  \url{http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}.

\bibitem[Poggio et~al.(2019)Poggio, Kur, and Banburski]{poggio2019double}
Tomaso Poggio, Gil Kur, and Andrzej Banburski.
\newblock Double descent in the condition number.
\newblock \emph{arXiv preprint arXiv:1912.06190}, 2019.

\bibitem[Quinonero-Candela and Rasmussen(2005)]{quinonero2005unifying}
Joaquin Quinonero-Candela and Carl~Edward Rasmussen.
\newblock A unifying view of sparse approximate {G}aussian process regression.
\newblock \emph{The Journal of Machine Learning Research}, 6:\penalty0
  1939--1959, 2005.

\bibitem[Snelson and Ghahramani(2005)]{snelson2005}
Edward Snelson and Zoubin Ghahramani.
\newblock Sparse {G}aussian processes using pseudo-inputs.
\newblock In Y.~Weiss, B.~Sch\"{o}lkopf, and J.~Platt, editors, \emph{Advances
  in Neural Information Processing Systems}, volume~18. MIT Press, 2005.

\bibitem[Titsias(2009{\natexlab{a}})]{titsias09}
Michalis Titsias.
\newblock Variational learning of inducing variables in sparse {G}aussian
  processes.
\newblock In David van Dyk and Max Welling, editors, \emph{Proceedings of the
  Twelth International Conference on Artificial Intelligence and Statistics},
  volume~5 of \emph{Proceedings of Machine Learning Research}, pages 567--574,
  Hilton Clearwater Beach Resort, Clearwater Beach, Florida USA, 16--18 Apr
  2009{\natexlab{a}}. PMLR.
\newblock URL \url{https://proceedings.mlr.press/v5/titsias09a.html}.

\bibitem[Titsias(2009{\natexlab{b}})]{titsias2009variational}
Michalis Titsias.
\newblock Variational learning of inducing variables in sparse {G}aussian
  processes.
\newblock In \emph{Artificial intelligence and statistics}, pages 567--574.
  PMLR, 2009{\natexlab{b}}.

\bibitem[Wang et~al.(2019)Wang, Pleiss, Gardner, Tyree, Weinberger, and
  Wilson]{wang2019exact}
Ke~Wang, Geoff Pleiss, Jacob Gardner, Stephen Tyree, Kilian~Q Weinberger, and
  Andrew~Gordon Wilson.
\newblock Exact {G}aussian processes on a million data points.
\newblock \emph{Advances in Neural Information Processing Systems}, 32, 2019.

\bibitem[Wild et~al.(2021)Wild, Kanagawa, and Sejdinovic]{wild2021connections}
Veit Wild, Motonobu Kanagawa, and Dino Sejdinovic.
\newblock Connections and equivalences between the {N}ystr\"{o}m method and
  sparse variational {G}aussian processes.
\newblock \emph{arXiv preprint arXiv:2106.01121}, 2021.

\bibitem[Williams and Seeger(2000)]{williams2000using}
Christopher Williams and Matthias Seeger.
\newblock Using the {N}ystr\"{o}m method to speed up kernel machines.
\newblock In T.~Leen, T.~Dietterich, and V.~Tresp, editors, \emph{Advances in
  Neural Information Processing Systems}, volume~13. MIT Press, 2000.
\newblock URL
  \url{https://proceedings.neurips.cc/paper/2000/file/19de10adbaa1b2ee13f77f679fa1483a-Paper.pdf}.

\bibitem[Williams and Rasmussen(2006)]{williams2006gaussian}
Christopher~K Williams and Carl~Edward Rasmussen.
\newblock \emph{{G}aussian processes for machine learning}, volume~2.
\newblock MIT press Cambridge, MA, 2006.

\bibitem[Wilson and Nickisch(2015)]{wilson2015kernel}
Andrew Wilson and Hannes Nickisch.
\newblock Kernel interpolation for scalable structured gaussian processes
  (kiss-gp).
\newblock In \emph{International conference on machine learning}, pages
  1775--1784. PMLR, 2015.

\bibitem[Zhang et~al.(2005)Zhang, Leithead, and Leith]{zhang2005time}
Yunong Zhang, William~E Leithead, and Douglas~J Leith.
\newblock Time-series {G}aussian process regression based on {T}oeplitz
  computation of ${O}(n^2)$ operations and ${O}(n)$-level storage.
\newblock In \emph{Proceedings of the 44th IEEE Conference on Decision and
  Control}, pages 3711--3716. IEEE, 2005.

\end{thebibliography}
