@article{kassner2020pretrained,
  title={Are Pretrained Language Models Symbolic Reasoners Over Knowledge?},
  author={Kassner, Nora and Krojer, Benno and Sch{\"u}tze, Hinrich},
  journal={CoNLL},
  year={2020},
  url={https://aclanthology.org/2020.conll-1.45.pdf}
}

@article{kassner2019negated,
  title={Negated and misprimed probes for pretrained language models: Birds can talk, but cannot fly},
  author={Kassner, Nora and Sch{\"u}tze, Hinrich},
  journal={ACL},
  year={2019},
  url={https://aclanthology.org/2020.acl-main.698.pdf}
}

@inproceedings{talmor2020leap,
  title={Leap-of-thought: Teaching pre-trained models to systematically reason over implicit knowledge},
  author={Talmor, Alon and Tafjord, Oyvind and Clark, Peter and Goldberg, Yoav and Berant, Jonathan},
  booktitle={NeurIPS},
  year={2020},
  url={http://128.84.4.27/pdf/2006.06609}
}

@inproceedings{loshchilov_decoupled_2017,
  title={Decoupled Weight Decay Regularization},
  author={Ilya Loshchilov and Frank Hutter},
  booktitle={ICLR},
  url={https://arxiv.org/pdf/1711.05101.pdf},
  year={2019}
}

@inproceedings{petroni-etal-2019-language,
    title = "Language Models as Knowledge Bases?",
    author = {Petroni, Fabio  and
      Rockt{\"a}schel, Tim  and
      Riedel, Sebastian  and
      Lewis, Patrick  and
      Bakhtin, Anton  and
      Wu, Yuxiang  and
      Miller, Alexander},
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1250",
    doi = "10.18653/v1/D19-1250",
    pages = "2463--2473",
}

@inproceedings{heinzerling-inui-2021-language,
    title = "Language Models as Knowledge Bases: On Entity Representations, Storage Capacity, and Paraphrased Queries",
    author = "Heinzerling, Benjamin  and
      Inui, Kentaro",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eacl-main.153",
    pages = "1772--1791",
}

@article{wang2021kepler,
  title={KEPLER: A unified model for knowledge embedding and pre-trained language representation},
  author={Wang, Xiaozhi and Gao, Tianyu and Zhu, Zhaocheng and Zhang, Zhengyan and Liu, Zhiyuan and Li, Juanzi and Tang, Jian},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={176--194},
  year={2021},
  publisher={MIT Press},
  url={https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00360/98089/KEPLER-A-Unified-Model-for-Knowledge-Embedding-and}
}

@inproceedings{elsahar-etal-2018-rex,
    title = "{T}-{RE}x: A Large Scale Alignment of Natural Language with Knowledge Base Triples",
    author = "Elsahar, Hady  and
      Vougiouklis, Pavlos  and
      Remaci, Arslen  and
      Gravier, Christophe  and
      Hare, Jonathon  and
      Laforest, Frederique  and
      Simperl, Elena",
    booktitle = "Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018)",
    month = may,
    year = "2018",
    address = "Miyazaki, Japan",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://aclanthology.org/L18-1544",
}

@article{elazar2021measuring,
  title={Measuring and improving consistency in pretrained language models},
  author={Elazar, Yanai and Kassner, Nora and Ravfogel, Shauli and Ravichander, Abhilasha and Hovy, Eduard and Sch{\"u}tze, Hinrich and Goldberg, Yoav},
  year={2021},
  url={https://arxiv.org/pdf/2102.01017.pdf},
  journal={Transactions of the Association for Computational Linguistics},
  volume={9},
  pages={1012-1031}
}

@article{jiang2020can,
  title={How can we know what language models know?},
  author={Jiang, Zhengbao and Xu, Frank F and Araki, Jun and Neubig, Graham},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={423--438},
  year={2020},
  publisher={MIT Press}
}

@inproceedings{hewitt2019designing,
  title={Designing and interpreting probes with control tasks},
  author={Hewitt, John and Liang, Percy},
  booktitle={EMNLP},
  year={2019},
  url={https://arxiv.org/pdf/1909.03368.pdf},
}

@inproceedings{voita2020information,
  title={Information-theoretic probing with minimum description length},
  author={Voita, Elena and Titov, Ivan},
  booktitle={EMNLP},
  year={2020},
  url={https://aclanthology.org/2020.emnlp-main.14.pdf}
}

@article{giannakidou2020linguistic,
  title={A linguistic framework for knowledge, belief, and veridicality judgement},
  journal={HAL},
  author={Giannakidou, Anastasia and Mari, Alda},
  year={2020},
  
  url={https://halshs.archives-ouvertes.fr/halshs-03088697/document},
}

@article{safavi2021relational,
  title={Relational world knowledge representation in contextual language models: A review},
  author={Safavi, Tara and Koutra, Danai},
  journal={arXiv preprint arXiv:2104.05837},
  year={2021},
  url={https://arxiv.org/pdf/2104.05837.pdf}
}

@inproceedings{dai2021knowledge,
  title={Knowledge neurons in pretrained transformers},
  author={Dai, Damai and Dong, Li and Hao, Yaru and Sui, Zhifang and Wei, Furu},
  journal={arXiv preprint arXiv:2104.08696},
  year={2022},
  booktitle={ACL},
  url={https://arxiv.org/pdf/2104.08696.pdf}
}

@inproceedings{de2021editing,
    title = "Editing Factual Knowledge in Language Models",
    author = "De Cao, Nicola  and
      Aziz, Wilker  and
      Titov, Ivan",
    booktitle = "EMNLP",
    month = nov,
    year = "2021",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.522",
    pages = "6491--6506",
}

@inproceedings{sinitsin2020editable,
  title={Editable Neural Networks},
  author={Sinitsin, Anton and Plokhotnyuk, Vsevolod and Pyrkin, Dmitriy and Popov, Sergei and Babenko, Artem},
  booktitle={ICLR},
  year={2020},
  url={https://openreview.net/pdf?id=HJedXaEtvS}
}

@InProceedings{wong2021leveraging,
  title = 	 {Leveraging Sparse Linear Layers for Debuggable Deep Networks},
  author =       {Wong, Eric and Santurkar, Shibani and Madry, Aleksander},
  booktitle = 	 {ICML},
  pages = 	 {11205--11216},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/wong21b/wong21b.pdf},
  url = 	 {http://proceedings.mlr.press/v139/wong21b.html},
}

@inproceedings{lazaridou2021pitfalls,
  title={Mind the Gap: Assessing Temporal Generalization in Neural Language Models},
  author={Lazaridou, Angeliki and Kuncoro, Adhiguna and Gribovskaya, Elena and Agrawal, Devang and Liska, Adam and Terzi, Tayfun and Gimenez, Mai and d'Autume, Cyprien de Masson and Ruder, Sebastian and Yogatama, Dani and others},
  booktitle={NeurIPS},
  year={2021},
  url={https://arxiv.org/pdf/2102.01951.pdf}
}

@article{dennett1995animals,
  title={Do animals have beliefs?},
  author={Dennett, Daniel},
  journal={Comparative approaches to cognitive science},
  volume={111},
  year={1995},
  publisher={MIT press Cambridge, MA},
  url={https://dl.tufts.edu/concern/pdfs/rj430g708}
}

@article{newen2020ascribe,
  title={How to ascribe beliefs to animals},
  author={Newen, Albert and Starzak, Tobias},
  journal={Mind \& Language},
  year={2020},
  publisher={Wiley Online Library},
  url={https://onlinelibrary.wiley.com/doi/full/10.1111/mila.12302}
}

@article{lertvittayakumjorn2021explanation,
  title={Explanation-Based Human Debugging of NLP Models: A Survey},
  author={Lertvittayakumjorn, Piyawat and Toni, Francesca},
  journal={arXiv preprint arXiv:2104.15135},
  year={2021},
  url={https://arxiv.org/pdf/2104.15135.pdf}
}

@article{saha2021explagraphs,
  title={ExplaGraphs: An Explanation Graph Generation Task for Structured Commonsense Reasoning},
  author={Saha, Swarnadeep and Yadav, Prateek and Bauer, Lisa and Bansal, Mohit},
  journal={arXiv preprint arXiv:2104.07644},
  year={2021},
  url={https://arxiv.org/pdf/2104.07644.pdf}
}

@inproceedings{dagan2005pascal,
  title={The pascal recognising textual entailment challenge},
  author={Dagan, Ido and Glickman, Oren and Magnini, Bernardo},
  booktitle={Machine Learning Challenges Workshop},
  pages={177--190},
  year={2005},
  organization={Springer},
  url={https://link.springer.com/chapter/10.1007/11736790_9}
}

@article{manning2006,
    title={LOCAL TEXTUAL INFERENCE: IT’S HARD TO CIRCUMSCRIBE,
BUT YOU KNOW IT WHEN YOU SEE IT – AND NLP NEEDS IT},
    author={Manning, Christopher D.},
    url={http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.510.4207&rep=rep1&type=pdf}
}

@article{pavlick2019inherent,
  title={Inherent disagreements in human textual inferences},
  author={Pavlick, Ellie and Kwiatkowski, Tom},
  journal={Transactions of the Association for Computational Linguistics},
  volume={7},
  pages={677--694},
  year={2019},
  publisher={MIT Press},
  url={https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00293/43531/Inherent-Disagreements-in-Human-Textual-Inferences}
}

@article{bommasani2021opportunities,
  title={On the Opportunities and Risks of Foundation Models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@article{wallat2021bertnesia,
  title={BERTnesia: Investigating the capture and forgetting of knowledge in BERT},
  author={Wallat, Jonas and Singh, Jaspreet and Anand, Avishek},
  journal={arXiv preprint arXiv:2106.02902},
  year={2021},
  url={https://arxiv.org/abs/2010.09313}
}

@inproceedings{wang2021k,
  title={K-adapter: Infusing knowledge into pre-trained models with adapters},
  author={Wang, Ruize and Tang, Duyu and Duan, Nan and Wei, Zhongyu and Huang, Xuanjing and Cao, Guihong and Jiang, Daxin and Zhou, Ming and others},
  booktitle={Findings of ACL},
  year={2021},
  url={https://aclanthology.org/2021.findings-acl.121.pdf}
}

@article{mitchell2021fast,
  title={Fast Model Editing at Scale},
  author={Mitchell, Eric and Lin, Charles and Bosselut, Antoine and Finn, Chelsea and Manning, Christopher D},
  journal={arXiv preprint arXiv:2110.11309},
  year={2021},
  url={https://arxiv.org/pdf/2110.11309.pdf}
}

@article{dhingra2021time,
  title={Time-aware language models as temporal knowledge bases},
  author={Dhingra, Bhuwan and Cole, Jeremy R and Eisenschlos, Julian Martin and Gillick, Daniel and Eisenstein, Jacob and Cohen, William W},
  journal={arXiv preprint arXiv:2106.15110},
  year={2021},
  url={https://arxiv.org/pdf/2106.15110.pdf}
}

@inproceedings{gehman2020realtoxicityprompts,
  title={Realtoxicityprompts: Evaluating neural toxic degeneration in language models},
  author={Gehman, Samuel and Gururangan, Suchin and Sap, Maarten and Choi, Yejin and Smith, Noah A},
  booktitle={Findings of EMNLP},
  year={2020},
  url={https://arxiv.org/pdf/2009.11462.pdf},
}

@inproceedings{bender2021dangers,
  title={On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
  author={Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle={Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  pages={610--623},
  year={2021},
  url={https://dl.acm.org/doi/10.1145/3442188.3445922}
}

@article{lin2021truthfulqa,
  title={TruthfulQA: Measuring How Models Mimic Human Falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  journal={arXiv preprint arXiv:2109.07958},
  year={2021},
  url={https://arxiv.org/pdf/2109.07958.pdf},
}

@article{zhu2020modifying,
  title={Modifying Memories in Transformer Models},
  author={Zhu, Chen and Rawat, Ankit Singh and Zaheer, Manzil and Bhojanapalli, Srinadh and Li, Daliang and Yu, Felix and Kumar, Sanjiv},
  journal={arXiv preprint arXiv:2012.00363},
  year={2020},
  url={https://arxiv.org/pdf/2012.00363.pdf}
}

@article{rogers-etal-2020-primer,
    title = "A Primer in {BERT}ology: What We Know About How {BERT} Works",
    author = "Rogers, Anna  and
      Kovaleva, Olga  and
      Rumshisky, Anna",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "8",
    year = "2020",
    url = "https://aclanthology.org/2020.tacl-1.54",
    doi = "10.1162/tacl_a_00349",
    pages = "842--866",
    abstract = "Transformer-based models have pushed state of the art in many areas of NLP, but our understanding of what is behind their success is still limited. This paper is the first survey of over 150 studies of the popular BERT model. We review the current state of knowledge about how BERT works, what kind of information it learns and how it is represented, common modifications to its training objectives and architecture, the overparameterization issue, and approaches to compression. We then outline directions for future research.",
}

@inproceedings{roberts-etal-2020-much,
    title = "How Much Knowledge Can You Pack Into the Parameters of a Language Model?",
    author = "Roberts, Adam  and
      Raffel, Colin  and
      Shazeer, Noam",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.437",
    doi = "10.18653/v1/2020.emnlp-main.437",
    pages = "5418--5426",
}

@article{kassner2021beliefbank,
  title={BeliefBank: Adding Memory to a Pre-Trained Language Model for a Systematic Notion of Belief},
  author={Kassner, Nora and Tafjord, Oyvind and Sch{\"u}tze, Hinrich and Clark, Peter},
  journal={arXiv preprint arXiv:2109.14723},
  year={2021},
  url={https://arxiv.org/pdf/2109.14723.pdf#page=10&zoom=100,401,869}
}

@article{west2021symbolic,
  title={Symbolic Knowledge Distillation: from General Language Models to Commonsense Models},
  author={West, Peter and Bhagavatula, Chandra and Hessel, Jack and Hwang, Jena D and Jiang, Liwei and Bras, Ronan Le and Lu, Ximing and Welleck, Sean and Choi, Yejin},
  journal={arXiv preprint arXiv:2110.07178},
  year={2021},
  url={https://arxiv.org/pdf/2110.07178.pdf}
}

@inproceedings{lewis2020retrieval,
  author    = {Patrick S. H. Lewis and
               Ethan Perez and
               Aleksandra Piktus and
               Fabio Petroni and
               Vladimir Karpukhin and
               Naman Goyal and
               Heinrich K{\"{u}}ttler and
               Mike Lewis and
               Wen{-}tau Yih and
               Tim Rockt{\"{a}}schel and
               Sebastian Riedel and
               Douwe Kiela},
  editor    = {Hugo Larochelle and
               Marc'Aurelio Ranzato and
               Raia Hadsell and
               Maria{-}Florina Balcan and
               Hsuan{-}Tien Lin},
  title     = {Retrieval-Augmented Generation for Knowledge-Intensive {NLP} Tasks},
  booktitle = {NeurIPS},
  year      = {2020},
  url       = {https://arxiv.org/abs/2005.11401},
  timestamp = {Fri, 04 Dec 2020 15:22:44 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/LewisPPPKGKLYR020.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{hase2021can,
  title={When can models learn from explanations? a formal framework for understanding the roles of explanation data},
  author={Hase, Peter and Bansal, Mohit},
  journal={arXiv preprint arXiv:2102.02201},
  year={2021},
  url={https://arxiv.org/pdf/2102.02201.pdf}
}




@inproceedings{andrychowicz2016learning,
  title={Learning to learn by gradient descent by gradient descent},
  author={Andrychowicz, Marcin and Denil, Misha and Gomez, Sergio and Hoffman, Matthew W and Pfau, David and Schaul, Tom and Shillingford, Brendan and De Freitas, Nando},
  booktitle={NeurIPS},
  pages={3981--3989},
  year={2016},
  url={https://proceedings.neurips.cc/paper/2016/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf}
}

@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={ICML},
  pages={1126--1135},
  year={2017},
  organization={PMLR},
  url={https://arxiv.org/pdf/1703.03400.pdf}
}

@inproceedings{thorne-etal-2018-fever,
    title = "{FEVER}: a Large-scale Dataset for Fact Extraction and {VER}ification",
    author = "Thorne, James  and
      Vlachos, Andreas  and
      Christodoulopoulos, Christos  and
      Mittal, Arpit",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-1074",
    doi = "10.18653/v1/N18-1074",
    pages = "809--819",
}

@inproceedings{levy-etal-2017-zero,
    title = "Zero-Shot Relation Extraction via Reading Comprehension",
    author = "Levy, Omer  and
      Seo, Minjoon  and
      Choi, Eunsol  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 21st Conference on Computational Natural Language Learning ({C}o{NLL} 2017)",
    month = aug,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/K17-1034",
    doi = "10.18653/v1/K17-1034",
    pages = "333--342",
}

@book{efron1994introduction,
 title={An Introduction to the Bootstrap},
 author={Efron, Bradley and Tibshirani, Robert J},
 year={1994},
 publisher={CRC press}
}

@inproceedings{card-etal-2020-little,
    title = "With Little Power Comes Great Responsibility",
    author = "Card, Dallas  and
      Henderson, Peter  and
      Khandelwal, Urvashi  and
      Jia, Robin  and
      Mahowald, Kyle  and
      Jurafsky, Dan",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.745",
    doi = "10.18653/v1/2020.emnlp-main.745",
    pages = "9263--9274",
}

@InCollection{sep-belief,
	author       =	{Schwitzgebel, Eric},
	title        =	{{Belief}},
	booktitle    =	{The {Stanford} Encyclopedia of Philosophy},
	editor       =	{Edward N. Zalta},
	howpublished =	{\url{https://plato.stanford.edu/archives/fall2019/entries/belief/}},
	year         =	{2019},
	edition      =	{{F}all 2019},
	publisher    =	{Metaphysics Research Lab, Stanford University},
	url={https://plato.stanford.edu/entries/belief/}
}

@article{clarkcognizer,
  title={The Cognizer's Innards: A Psychological and Philosophical Perspective on the Development of Thought.},
  author={Clark, Andy and Karmiloff-Smith, Annette},
  url={https://psycnet.apa.org/record/1994-39837-001},
  journal={Mind \& Language, 8(4)},
  pages={487–519},
  year={1993},
}

@article{parisi2019continual,
  title={Continual lifelong learning with neural networks: A review},
  author={Parisi, German I and Kemker, Ronald and Part, Jose L and Kanan, Christopher and Wermter, Stefan},
  journal={Neural Networks},
  volume={113},
  pages={54--71},
  year={2019},
  publisher={Elsevier},
  url={https://www.sciencedirect.com/science/article/pii/S0893608019300231}
}

@inproceedings{petroni-etal-2021-kilt,
    title = "{KILT}: a Benchmark for Knowledge Intensive Language Tasks",
    author = {Petroni, Fabio  and Piktus, Aleksandra  and
      Fan, Angela  and Lewis, Patrick  and
      Yazdani, Majid  and De Cao, Nicola  and
      Thorne, James  and Jernite, Yacine  and
      Karpukhin, Vladimir  and Maillard, Jean  and
      Plachouras, Vassilis  and Rockt{\"a}schel, Tim  and
      Riedel, Sebastian},
    booktitle = "Proceedings of the 2021 Conference of the North American Chapter of the Association 
                 for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.naacl-main.200",
    doi = "10.18653/v1/2021.naacl-main.200",
    pages = "2523--2544",
}

@inproceedings{meng2022locating,
  title={Locating and editing factual knowledge in gpt},
  author={Meng, Kevin and Bau, David and Andonian, Alex and Belinkov, Yonatan},
  booktitle={NeurIPS 2022},
  year={2022},
  url={https://arxiv.org/pdf/2202.05262.pdf}
}

@article{meng2022mass,
  title={Mass-Editing Memory in a Transformer},
  author={Meng, Kevin and Sharma, Arnab Sen and Andonian, Alex and Belinkov, Yonatan and Bau, David},
  journal={arXiv preprint arXiv:2210.07229},
  url={https://arxiv.org/pdf/2210.07229.pdf},
  year={2022}
}

@article{chowdhery2022palm,
  title={PaLM: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022},
  url={https://arxiv.org/pdf/2204.02311.pdf}
}

@inproceedings{geva2020transformer,
  title={Transformer feed-forward layers are key-value memories},
  author={Geva, Mor and Schuster, Roei and Berant, Jonathan and Levy, Omer},
  booktitle={EMNLP},
  year={2021},
  url={https://arxiv.org/pdf/2012.14913.pdf}
}

@article{geva2022transformer,
  title={Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space},
  author={Geva, Mor and Caciularu, Avi and Wang, Kevin Ro and Goldberg, Yoav},
  journal={arXiv preprint arXiv:2203.14680},
  year={2022},
  url={https://arxiv.org/pdf/2203.14680.pdf}
}

@inproceedings{zhao2021non,
  title={Of non-linearity and commutativity in bert},
  author={Zhao, Sumu and Pascual, Dami{\'a}n and Brunner, Gino and Wattenhofer, Roger},
  booktitle={2021 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2021},
  organization={IEEE},
  url={https://arxiv.org/pdf/2101.04547.pdf}
}

@misc{gpt-j,
  author = {Wang, Ben and Komatsuzaki, Aran},
  title = {{GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model}},
  howpublished = {\url{https://github.com/kingoflolz/mesh-transformer-jax}},
  year = 2021,
  month = May
}

@article{hase2021language,
  title={Do language models have beliefs? methods for detecting, updating, and visualizing model beliefs},
  author={Hase, Peter and Diab, Mona and Celikyilmaz, Asli and Li, Xian and Kozareva, Zornitsa and Stoyanov, Veselin and Bansal, Mohit and Iyer, Srinivasan},
  journal={arXiv preprint arXiv:2111.13654},
  year={2021},
  url={https://arxiv.org/pdf/2111.13654.pdf}
}


@InProceedings{kim2018tcav,
  title = 	 {Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors ({TCAV})},
  author =       {Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and sayres, Rory},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {2668--2677},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/kim18d/kim18d.pdf},
  url = 	 {https://proceedings.mlr.press/v80/kim18d.html},
  abstract = 	 {The interpretation of deep learning models is a challenge due to their size, complexity, and often opaque internal state. In addition, many systems, such as image classifiers, operate on low-level features rather than high-level concepts. To address these challenges, we introduce Concept Activation Vectors (CAVs), which provide an interpretation of a neural net’s internal state in terms of human-friendly concepts. The key idea is to view the high-dimensional internal state of a neural net as an aid, not an obstacle. We show how to use CAVs as part of a technique, Testing with CAVs (TCAV), that uses directional derivatives to quantify the degree to which a user-defined concept is important to a classification result–for example, how sensitive a prediction of “zebra” is to the presence of stripes. Using the domain of image classification as a testing ground, we describe how CAVs may be used to explore hypotheses and generate insights for a standard image classification network as well as a medical application.}
}


@article{olah2018the,
  author = {Olah, Chris and Satyanarayan, Arvind and Johnson, Ian and Carter, Shan and Schubert, Ludwig and Ye, Katherine and Mordvintsev, Alexander},
  title = {The Building Blocks of Interpretability},
  journal = {Distill},
  year = {2018},
  note = {https://distill.pub/2018/building-blocks},
  doi = {10.23915/distill.00010}
}

@article{mu2020compositional,
  title={Compositional explanations of neurons},
  author={Mu, Jesse and Andreas, Jacob},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={17153--17163},
  year={2020},
  url={https://proceedings.neurips.cc/paper/2020/file/c74956ffb38ba48ed6ce977af6727275-Paper.pdf}
}

@inproceedings{schneider2021explaining,
  title={Explaining neural networks by decoding layer activations},
  author={Schneider, Johannes and Vlachos, Michalis},
  booktitle={International Symposium on Intelligent Data Analysis},
  pages={63--75},
  year={2021},
  organization={Springer},
  url={https://arxiv.org/pdf/2005.13630.pdf}
}

@article{vig2020causal,
  title={Causal mediation analysis for interpreting neural nlp: The case of gender bias},
  author={Vig, Jesse and Gehrmann, Sebastian and Belinkov, Yonatan and Qian, Sharon and Nevo, Daniel and Sakenis, Simas and Huang, Jason and Singer, Yaron and Shieber, Stuart},
  journal={arXiv preprint arXiv:2004.12265},
  year={2020},
  url={https://arxiv.org/pdf/2004.12265.pdf}
}

@inproceedings{andreas-etal-2017-translating,
    title = "Translating Neuralese",
    author = "Andreas, Jacob  and
      Dragan, Anca  and
      Klein, Dan",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1022",
    doi = "10.18653/v1/P17-1022",
    pages = "232--242",
    abstract = "Several approaches have recently been proposed for learning decentralized deep multiagent policies that coordinate via a differentiable communication channel. While these policies are effective for many tasks, interpretation of their induced communication strategies has remained a challenge. Here we propose to interpret agents{'} messages by translating them. Unlike in typical machine translation problems, we have no parallel data to learn from. Instead we develop a translation model based on the insight that agent messages and natural language strings mean the same thing if they induce the same belief about the world in a listener. We present theoretical guarantees and empirical evidence that our approach preserves both the semantics and pragmatics of messages by ensuring that players communicating through a translation layer do not suffer a substantial loss in reward relative to players with a common language.",
}

@article{bau2020understanding,
  title={Understanding the role of individual units in a deep neural network},
  author={Bau, David and Zhu, Jun-Yan and Strobelt, Hendrik and Lapedriza, Agata and Zhou, Bolei and Torralba, Antonio},
  journal={Proceedings of the National Academy of Sciences},
  volume={117},
  number={48},
  pages={30071--30078},
  year={2020},
  publisher={National Acad Sciences},
  url={https://www.pnas.org/doi/pdf/10.1073/pnas.1907375117}
}

@article{rogers2020primer,
  title={A primer in bertology: What we know about how bert works},
  author={Rogers, Anna and Kovaleva, Olga and Rumshisky, Anna},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={842--866},
  year={2020},
  publisher={MIT Press},
  url={https://arxiv.org/pdf/2002.12327.pdf}
}

@inproceedings{hernandez2022natural,
  title={Natural Language Descriptions of Deep Visual Features},
  author={Hernandez, Evan and Schwettmann, Sarah and Bau, David and Bagashvili, Teona and Torralba, Antonio and Andreas, Jacob},
  booktitle={International Conference on Learning Representations},
  year={2022},
  url={https://openreview.net/pdf?id=NudBMY-tzDr}
}

@article{radford2017learning,
  title={Learning to generate reviews and discovering sentiment},
  author={Radford, Alec and Jozefowicz, Rafal and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1704.01444},
  year={2017},
  url={https://arxiv.org/pdf/1704.01444.pdf}
}

@inproceedings{casper2022graphical,
  title={Graphical Clusterability and Local Specialization in Deep Neural Networks},
  author={Casper, Stephen and Hod, Shlomi and Filan, Daniel and Wild, Cody and Critch, Andrew and Russell, Stuart},
  booktitle={ICLR 2022 Workshop on PAIR},
  year={2022},
  url={https://arxiv.org/pdf/2110.08058v2.pdf}
}

@article{csordas2020neural,
  title={Are neural nets modular? inspecting functional modularity through differentiable weight masks},
  author={Csord{\'a}s, R{\'o}bert and van Steenkiste, Sjoerd and Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:2010.02066},
  year={2020},
  url={https://arxiv.org/pdf/2010.02066.pdf}
}

@inproceedings{de2021sparse,
  title={Sparse Interventions in Language Models with Differentiable Masking},
  author={De Cao, Nicola and Schmid, Leon and Hupkes, Dieuwke and Titov, Ivan},
  booktitle={EMNLP BlackboxNLP Workshop},
  year={2021},
  url={https://arxiv.org/pdf/2112.06837.pdf}
}

@article{bolukbasi2021interpretability,
  title={An interpretability illusion for bert},
  author={Bolukbasi, Tolga and Pearce, Adam and Yuan, Ann and Coenen, Andy and Reif, Emily and Vi{\'e}gas, Fernanda and Wattenberg, Martin},
  journal={arXiv preprint arXiv:2104.07143},
  year={2021},
  url={https://arxiv.org/pdf/2104.07143.pdf}
}

@article{elhage2021mathematical,
   title={A Mathematical Framework for Transformer Circuits},
   author={Elhage, Nelson and Nanda, Neel and Olsson, Catherine and Henighan, Tom and Joseph, Nicholas and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and DasSarma, Nova and Drain, Dawn and Ganguli, Deep and Hatfield-Dodds, Zac and Hernandez, Danny and Jones, Andy and Kernion, Jackson and Lovitt, Liane and Ndousse, Kamal and Amodei, Dario and Brown, Tom and Clark, Jack and Kaplan, Jared and McCandlish, Sam and Olah, Chris},
   year={2021},
   journal={Transformer Circuits Thread},
   note={https://transformer-circuits.pub/2021/framework/index.html}
}

@article{elhage2022superposition,
   title={Toy Models of Superposition},
   author={Elhage, Nelson and Hume, Tristan and Olsson, Catherine and Schiefer, Nicholas and Henighan, Tom and Kravec, Shauna and Hatfield-Dodds, Zac and Lasenby, Robert and Drain, Dawn and Chen, Carol and Grosse, Roger and McCandlish, Sam and Kaplan, Jared and Amodei, Dario and Wattenberg, Martin and Olah, Christopher},
   year={2022},
   journal={Transformer Circuits Thread},
   note={https://transformer-circuits.pub/2022/toy_model/index.html}
}

@inproceedings{mikolov2013efficient,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  booktitle={arXiv preprint arXiv:1301.3781},
  year={2013},
  url={https://arxiv.org/pdf/1301.3781.pdf}
}

@inproceedings{santurkar2021editing,
 author = {Santurkar, Shibani and Tsipras, Dimitris and Elango, Mahalaxmi and Bau, David and Torralba, Antonio and Madry, Aleksander},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {23359--23373},
 publisher = {Curran Associates, Inc.},
 title = {Editing a classifier by rewriting its prediction rules},
 url = {https://proceedings.neurips.cc/paper/2021/file/c46489a2d5a9a9ecfc53b17610926ddd-Paper.pdf},
 volume = {34},
 year = {2021}
}

@inproceedings{bau2020rewriting,
  title={Rewriting a deep generative model},
  author={Bau, David and Liu, Steven and Wang, Tongzhou and Zhu, Jun-Yan and Torralba, Antonio},
  booktitle={European conference on computer vision},
  pages={351--369},
  year={2020},
  organization={Springer},
  url={https://arxiv.org/pdf/2007.15646.pdf}
}

@article{wang2022finding,
  title={Finding Skill Neurons in Pre-trained Transformer-based Language Models},
  author={Wang, Xiaozhi and Wen, Kaiyue and Zhang, Zhengyan and Hou, Lei and Liu, Zhiyuan and Li, Juanzi},
  journal={arXiv preprint arXiv:2211.07349},
  year={2022},
  url={https://arxiv.org/pdf/2211.07349.pdf}
}

@inproceedings{lakretz2019emergence,
  title={The emergence of number and syntax units in LSTM language models},
  author={Lakretz, Yair and Kruszewski, German and Desbordes, Theo and Hupkes, Dieuwke and Dehaene, Stanislas and Baroni, Marco},
  booktitle={NAACL-HLT},
  year={2019},
  url={https://arxiv.org/pdf/1903.07435.pdf}
}

@article{lakretz2021mechanisms,
    author = {Lakretz, Yair and Hupkes, Dieuwke and Vergallito, Alessandra and Marelli, Marco and Baroni, Marco and Dehaene, Stanislas},
    year = {2021},
    month = {04},
    pages = {104699},
    title = {Mechanisms for handling nested dependencies in neural-network language models and humans},
    volume = {213},
    journal = {Cognition},
    doi = {10.1016/j.cognition.2021.104699},
    url={https://arxiv.org/ftp/arxiv/papers/2006/2006.11098.pdf}
}

@article{cui2022local,
  title={Local Relighting of Real Scenes},
  author={Cui, Audrey and Jahanian, Ali and Lapedriza, Agata and Torralba, Antonio and Mahdizadehaghdam, Shahin and Kumar, Rohit and Bau, David},
  journal={arXiv preprint arXiv:2207.02774},
  year={2022},
  url={https://arxiv.org/pdf/2207.02774.pdf}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019},
  url={https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf}
}

@article{chormai2022disentangled,
  title={Disentangled Explanations of Neural Network Predictions by Finding Relevant Subspaces},
  author={Chormai, Pattarawat and Herrmann, Jan and M{\"u}ller, Klaus-Robert and Montavon, Gr{\'e}goire},
  journal={arXiv preprint arXiv:2212.14855},
  year={2022},
  url={https://arxiv.org/pdf/2212.14855.pdf}
}

@inproceedings{zhou2018interpretable,
  title={Interpretable basis decomposition for visual explanation},
  author={Zhou, Bolei and Sun, Yiyou and Bau, David and Torralba, Antonio},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  pages={119--134},
  year={2018},
  url={https://people.csail.mit.edu/bzhou/publication/eccv18-IBD}
}

@article{ghorbani2019towards,
  title={Towards automatic concept-based explanations},
  author={Ghorbani, Amirata and Wexler, James and Zou, James Y and Kim, Been},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019},
  url={https://arxiv.org/pdf/1902.03129.pdf}
}

@inproceedings{zhang2021invertible,
  title={Invertible concept-based explanations for cnn models with non-negative concept activation vectors},
  author={Zhang, Ruihan and Madumal, Prashan and Miller, Tim and Ehinger, Krista A and Rubinstein, Benjamin IP},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2021},
  url={https://arxiv.org/pdf/2006.15417.pdf}
}

@article{zhou2018interpreting,
  title={Interpreting deep visual representations via network dissection},
  author={Zhou, Bolei and Bau, David and Oliva, Aude and Torralba, Antonio},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={9},
  pages={2131--2145},
  year={2018},
  publisher={IEEE},
  url={https://arxiv.org/pdf/1711.05611.pdf}
}

@inproceedings{zeiler2014visualizing,
  title={Visualizing and understanding convolutional networks},
  author={Zeiler, Matthew D and Fergus, Rob},
  booktitle={European conference on computer vision},
  pages={818--833},
  year={2014},
  organization={Springer},
  url={https://arxiv.org/pdf/1311.2901.pdf}
}


@inproceedings{mitchell2022memory,
  title={Memory-based model editing at scale},
  author={Mitchell, Eric and Lin, Charles and Bosselut, Antoine and Manning, Christopher D and Finn, Chelsea},
  booktitle={International Conference on Machine Learning},
  pages={15817--15831},
  year={2022},
  organization={PMLR},
  url={https://arxiv.org/pdf/2206.06520.pdf}
}