@inproceedings{reddi2020adaptive,
  title={Adaptive Federated Optimization},
  author={Reddi, Sashank J and Charles, Zachary and Zaheer, Manzil and Garrett, Zachary and Rush, Keith and Kone{\v{c}}n{\`y}, Jakub and Kumar, Sanjiv and McMahan, Hugh Brendan},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{karimireddy2020scaffold,
  title={Scaffold: Stochastic controlled averaging for federated learning},
  author={Karimireddy, Sai Praneeth and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank and Stich, Sebastian and Suresh, Ananda Theertha},
  booktitle={International Conference on Machine Learning},
  pages={5132--5143},
  year={2020},
  organization={PMLR}
}

@inproceedings{
yoon2021fedmix,
title={FedMix: Approximation of Mixup under Mean Augmented Federated Learning},
author={Tehrim Yoon and Sumin Shin and Sung Ju Hwang and Eunho Yang},
booktitle={International Conference on Learning Representations},
year={2021}
}

@inproceedings{yang2021achieving,
title={Achieving Linear Speedup with Partial Worker Participation in Non-{IID} Federated Learning},
author={Haibo Yang and Minghong Fang and Jia Liu},
booktitle={International Conference on Learning Representations},
year={2021}
}

@article{bubeck2014convex,
  title={Convex optimization: Algorithms and complexity},
  author={Bubeck, S{\'e}bastien},
  journal={arXiv preprint arXiv:1405.4980},
  year={2014}
}

@article{li2018federated,
  title={Federated optimization in heterogeneous networks},
  author={Li, Tian and Sahu, Anit Kumar and Zaheer, Manzil and Sanjabi, Maziar and Talwalkar, Ameet and Smith, Virginia},
  journal={arXiv preprint arXiv:1812.06127},
  year={2018}
}

@inproceedings{Li2020On,
title={On the Convergence of FedAvg on Non-IID Data},
author={Xiang Li and Kaixuan Huang and Wenhao Yang and Shusen Wang and Zhihua Zhang},
booktitle={International Conference on Learning Representations},
year={2020}
}

@inproceedings{reisizadeh2020robust,
  title={Robust Federated Learning: The Case of Affine Distribution Shifts},
  author={Reisizadeh, Amirhossein and Farnia, Farzan and Pedarsani, Ramtin and Jadbabaie, Ali},
  booktitle={NeurIPS},
  year={2020}
}

@inproceedings{mohri2019agnostic,
  title={Agnostic federated learning},
  author={Mohri, Mehryar and Sivek, Gary and Suresh, Ananda Theertha},
  booktitle={International Conference on Machine Learning},
  pages={4615--4625},
  year={2019},
  organization={PMLR}
}

@inproceedings{foret2021sharpnessaware,
title={Sharpness-aware Minimization for Efficiently Improving Generalization},
author={Pierre Foret and Ariel Kleiner and Hossein Mobahi and Behnam Neyshabur},
booktitle={International Conference on Learning Representations},
year={2021}
}

@inproceedings{neyshabur2018pac,
  title={A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks},
  author={Neyshabur, Behnam and Bhojanapalli, Srinadh and Srebro, Nathan},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{bartlett2017spectrally,
  title={Spectrally-normalized margin bounds for neural networks},
  author={Bartlett, Peter L and Foster, Dylan J and Telgarsky, Matus J},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  pages={6240--6249},
  year={2017}
}

@inproceedings{farnia2018generalizable,
  title={Generalizable Adversarial Training via Spectral Normalization},
  author={Farnia, Farzan and Zhang, Jesse and Tse, David},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{chatterji2019intriguing,
  title={The intriguing role of module criticality in the generalization of deep networks},
  author={Chatterji, Niladri and Neyshabur, Behnam and Sedghi, Hanie},
  booktitle={International Conference on Learning Representations},
  year={2019}
}


@article{tropp2012user,
  title={User-friendly tail bounds for sums of random matrices},
  author={Tropp, Joel A},
  journal={Foundations of computational mathematics},
  volume={12},
  number={4},
  pages={389--434},
  year={2012},
  publisher={Springer}
}

@inproceedings{mcmahan2017communication,
  title={Communication-efficient learning of deep networks from decentralized data},
  author={McMahan, Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Aguera},
  booktitle={Artificial intelligence and statistics},
  pages={1273--1282},
  year={2017},
  organization={PMLR}
}

@article{kairouz2019advances,
  title={Advances and open problems in federated learning},
  author={Kairouz, Peter and McMahan, H Brendan and Avent, Brendan and Bellet, Aur{\'e}lien and Bennis, Mehdi and Bhagoji, Arjun Nitin and Bonawitz, Kallista and Charles, Zachary and Cormode, Graham and Cummings, Rachel and others},
  journal={arXiv preprint arXiv:1912.04977},
  year={2019}
}

@article{li2021federated,
  title={Federated learning on non-iid data silos: An experimental study},
  author={Li, Qinbin and Diao, Yiqun and Chen, Quan and He, Bingsheng},
  journal={arXiv preprint arXiv:2102.02079},
  year={2021}
}

@inproceedings{
acar2021federated,
title={Federated Learning Based on Dynamic Regularization},
author={Durmus Alp Emre Acar and Yue Zhao and Ramon Matas and Matthew Mattina and Paul Whatmough and Venkatesh Saligrama},
booktitle={International Conference on Learning Representations},
year={2021}
}

@inproceedings{li2021model,
  title={Model-Contrastive Federated Learning},
  author={Li, Qinbin and He, Bingsheng and Song, Dawn},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10713--10722},
  year={2021}
}

@article{sahu2018convergence,
  title={On the convergence of federated optimization in heterogeneous networks},
  author={Sahu, Anit Kumar and Li, Tian and Sanjabi, Maziar and Zaheer, Manzil and Talwalkar, Ameet and Smith, Virginia},
  journal={arXiv preprint arXiv:1812.06127},
  volume={3},
  pages={3},
  year={2018}
}

@article{xu2021fedcm,
  title={FedCM: Federated Learning with Client-level Momentum},
  author={Xu, Jing and Wang, Sen and Wang, Liwei and Yao, Andrew Chi-Chih},
  journal={arXiv preprint arXiv:2106.10874},
  year={2021}
}

@inproceedings{
zhuang2022surrogate,
title={Surrogate Gap Minimization Improves Sharpness-Aware Training},
author={Juntang Zhuang and Boqing Gong and Liangzhe Yuan and Yin Cui and Hartwig Adam and Nicha C Dvornek and sekhar tatikonda and James s Duncan and Ting Liu},
booktitle={International Conference on Learning Representations},
year={2022}
}


@article{chaudhari2019entropy,
  title={Entropy-sgd: Biasing gradient descent into wide valleys},
  author={Chaudhari, Pratik and Choromanska, Anna and Soatto, Stefano and LeCun, Yann and Baldassi, Carlo and Borgs, Christian and Chayes, Jennifer and Sagun, Levent and Zecchina, Riccardo},
  journal={Journal of Statistical Mechanics: Theory and Experiment},
  volume={2019},
  number={12},
  pages={124018},
  year={2019},
  publisher={IOP Publishing}
}

@inproceedings{karimireddy2021breaking,
  title={Breaking the centralized barrier for cross-device federated learning},
  author={Karimireddy, Sai Praneeth and Jaggi, Martin and Kale, Satyen and Mohri, Mehryar and Reddi, Sashank J and Stich, Sebastian U and Suresh, Ananda Theertha},
  booktitle={Thirty-Fifth Conference on Neural Information Processing Systems},
  year={2021}
}

@article{liu2020accelerating,
  title={Accelerating federated learning via momentum gradient descent},
  author={Liu, Wei and Chen, Li and Chen, Yunfei and Zhang, Wenyi},
  journal={IEEE Transactions on Parallel and Distributed Systems},
  volume={31},
  number={8},
  pages={1754--1766},
  year={2020},
  publisher={IEEE}
}

@inproceedings{wang2019slowmo,
  title={SlowMo: Improving Communication-Efficient Distributed SGD with Slow Momentum},
  author={Wang, Jianyu and Tantia, Vinayak and Ballas, Nicolas and Rabbat, Michael},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{konevcny2016federated,
  title={Federated optimization: Distributed machine learning for on-device intelligence},
  author={Kone{\v{c}}n{\`y}, Jakub and McMahan, H Brendan and Ramage, Daniel and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:1610.02527},
  year={2016}
}

@article{yao2021local,
  title={Local-Global Knowledge Distillation in Heterogeneous Federated Learning with Non-IID Data},
  author={Yao, Dezhong and Pan, Wanning and Dai, Yutong and Wan, Yao and Ding, Xiaofeng and Jin, Hai and Xu, Zheng and Sun, Lichao},
  journal={arXiv preprint arXiv:2107.00051},
  year={2021}
}

@inproceedings{gong2021ensemble,
  title={Ensemble Attention Distillation for Privacy-Preserving Federated Learning},
  author={Gong, Xuan and Sharma, Abhishek and Karanam, Srikrishna and Wu, Ziyan and Chen, Terrence and Doermann, David and Innanje, Arun},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={15076--15086},
  year={2021}
}

@inproceedings{lin2020ensemble,
  title={Ensemble Distillation for Robust Model Fusion in Federated Learning},
  author={Lin, Tao and Kong, Lingjing and Stich, Sebastian U and Jaggi, Martin},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}

@article{zhu2021data,
  title={Data-Free Knowledge Distillation for Heterogeneous Federated Learning},
  author={Zhu, Zhuangdi and Hong, Junyuan and Zhou, Jiayu},
  journal={arXiv preprint arXiv:2105.10056},
  year={2021}
}

@article{fallah2020personalized,
  title={Personalized federated learning with theoretical guarantees: A model-agnostic meta-learning approach},
  author={Fallah, Alireza and Mokhtari, Aryan and Ozdaglar, Asuman},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3557--3568},
  year={2020}
}

@article{t2020personalized,
  title={Personalized Federated Learning with Moreau Envelopes},
  author={T Dinh, Canh and Tran, Nguyen and Nguyen, Tuan Dung},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{singhal2021federated,
title={Federated Reconstruction: Partially Local Federated Learning},
author={Karan Singhal and Hakim Sidahmed and Zachary Garrett and Shanshan Wu and J Keith Rush and Sushant Prakash},
booktitle={Advances in Neural Information Processing Systems},
year={2021}
}

@article{mansour2020three,
  title={Three approaches for personalization with applications to federated learning},
  author={Mansour, Yishay and Mohri, Mehryar and Ro, Jae and Suresh, Ananda Theertha},
  journal={arXiv preprint arXiv:2002.10619},
  year={2020}
}

@article{deng2020adaptive,
  title={Adaptive personalized federated learning},
  author={Deng, Yuyang and Kamani, Mohammad Mahdi and Mahdavi, Mehrdad},
  journal={arXiv preprint arXiv:2003.13461},
  year={2020}
}

@inproceedings{li2021ditto,
  title={Ditto: Fair and robust federated learning through personalization},
  author={Li, Tian and Hu, Shengyuan and Beirami, Ahmad and Smith, Virginia},
  booktitle={International Conference on Machine Learning},
  pages={6357--6368},
  year={2021},
  organization={PMLR}
}

@inproceedings{
khanduri2021stem,
title={{STEM}: A Stochastic Two-Sided Momentum Algorithm Achieving Near-Optimal Sample and Communication Complexities for Federated Learning},
author={Prashant Khanduri and PRANAY SHARMA and Haibo Yang and Mingyi Hong and Jia Liu and Ketan Rajawat and Pramod Varshney},
booktitle={Advances in Neural Information Processing Systems},
year={2021}
}

@inproceedings{khaled2020tighter,
  title={Tighter theory for local SGD on identical and heterogeneous data},
  author={Khaled, Ahmed and Mishchenko, Konstantin and Richt{\'a}rik, Peter},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4519--4529},
  year={2020},
  organization={PMLR}
}

@inproceedings{woodworth2020kernel,
  title={Kernel and rich regimes in overparametrized models},
  author={Woodworth, Blake and Gunasekar, Suriya and Lee, Jason D and Moroshko, Edward and Savarese, Pedro and Golan, Itay and Soudry, Daniel and Srebro, Nathan},
  booktitle={Conference on Learning Theory},
  pages={3635--3673},
  year={2020},
  organization={PMLR}
}

@article{lakshminarayanan2017simple,
  title={Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{ovadia2019can,
  title={Can you trust your model's uncertainty? Evaluating predictive uncertainty under dataset shift},
  author={Ovadia, Yaniv and Fertig, Emily and Ren, Jie and Nado, Zachary and Sculley, D and Nowozin, Sebastian and Dillon, Joshua and Lakshminarayanan, Balaji and Snoek, Jasper},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={13991--14002},
  year={2019}
}

@article{keskar2016large,
  title={On large-batch training for deep learning: Generalization gap and sharp minima},
  author={Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
  journal={arXiv preprint arXiv:1609.04836},
  year={2016}
}


@InProceedings{kwon21b,
  title = 	 {ASAM: Adaptive Sharpness-Aware Minimization for Scale-Invariant Learning of Deep Neural Networks},
  author =       {Kwon, Jungmin and Kim, Jeongseop and Park, Hyunseo and Choi, In Kwon},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {5905--5914},
  year = 	 {2021},
  publisher =    {PMLR}
}

@article{hard2018federated,
  title={Federated learning for mobile keyboard prediction},
  author={Hard, Andrew and Rao, Kanishka and Mathews, Rajiv and Ramaswamy, Swaroop and Beaufays, Fran{\c{c}}oise and Augenstein, Sean and Eichner, Hubert and Kiddon, Chlo{\'e} and Ramage, Daniel},
  journal={arXiv preprint arXiv:1811.03604},
  year={2018}
}

@inproceedings{cohen2017emnist,
  title={EMNIST: Extending MNIST to handwritten letters},
  author={Cohen, Gregory and Afshar, Saeed and Tapson, Jonathan and Van Schaik, Andre},
  booktitle={2017 International Joint Conference on Neural Networks (IJCNN)},
  pages={2921--2926},
  year={2017},
  organization={IEEE}
}

@article{krizhevsky2009learning,
  title={Learning multiple layers of features from tiny images},
  author={Krizhevsky, Alex and Hinton, Geoffrey and others},
  year={2009},
  publisher={Citeseer}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{du2021efficient,
  title={Efficient Sharpness-aware Minimization for Improved Training of Neural Networks},
  author={Du, Jiawei and Yan, Hanshu and Feng, Jiashi and Zhou, Joey Tianyi and Zhen, Liangli and Goh, Rick Siow Mong and Tan, Vincent YF},
  journal={arXiv preprint arXiv:2110.03141},
  year={2021}
}

@article{nesterov2017random,
  title={Random gradient-free minimization of convex functions},
  author={Nesterov, Yurii and Spokoiny, Vladimir},
  journal={Foundations of Computational Mathematics},
  volume={17},
  number={2},
  pages={527--566},
  year={2017},
  publisher={Springer}
}

@article{lian2017can,
  title={Can decentralized algorithms outperform centralized algorithms? a case study for decentralized parallel stochastic gradient descent},
  author={Lian, Xiangru and Zhang, Ce and Zhang, Huan and Hsieh, Cho-Jui and Zhang, Wei and Liu, Ji},
  journal={arXiv preprint arXiv:1705.09056},
  year={2017}
}

@article{goyal2017accurate,
  title={Accurate, large minibatch sgd: Training imagenet in 1 hour},
  author={Goyal, Priya and Doll{\'a}r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  journal={arXiv preprint arXiv:1706.02677},
  year={2017}
}

@article{zagoruyko2016wide,
  title={Wide residual networks},
  author={Zagoruyko, Sergey and Komodakis, Nikos},
  journal={arXiv preprint arXiv:1605.07146},
  year={2016}
}

@article{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={Ieee}
}

@inproceedings{shafahi2020universal,
  title={Universal adversarial training},
  author={Shafahi, Ali and Najibi, Mahyar and Xu, Zheng and Dickerson, John and Davis, Larry S and Goldstein, Tom},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={5636--5643},
  year={2020}
}

@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  pages={8026--8037},
  year={2019}
}

@article{dieuleveut2021federated,
  title={Federated-EM with heterogeneity mitigation and variance reduction},
  author={Dieuleveut, Aymeric and Fort, Gersende and Moulines, Eric and Robin, Genevieve},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{li2018visualizing,
  title={Visualizing the Loss Landscape of Neural Nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{sandler2018mobilenetv2,
  title={Mobilenetv2: Inverted residuals and linear bottlenecks},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4510--4520},
  year={2018}
}

@article{mendieta2021local,
  title={Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning},
  author={Mendieta, Matias and Yang, Taojiannan and Wang, Pu and Lee, Minwoo and Ding, Zhengming and Chen, Chen},
  journal={arXiv preprint arXiv:2111.14213},
  year={2021}
}

@article{yuan2021we,
  title={What Do We Mean by Generalization in Federated Learning?},
  author={Yuan, Honglin and Morningstar, Warren and Ning, Lin and Singhal, Karan},
  journal={arXiv preprint arXiv:2110.14216},
  year={2021}
}

@inproceedings{du2021fairness,
  title={Fairness-aware agnostic federated learning},
  author={Du, Wei and Xu, Depeng and Wu, Xintao and Tong, Hanghang},
  booktitle={Proceedings of the 2021 SIAM International Conference on Data Mining (SDM)},
  pages={181--189},
  year={2021},
  organization={SIAM}
}

@inproceedings{
Li2020Fair,
title={Fair Resource Allocation in Federated Learning},
author={Tian Li and Maziar Sanjabi and Ahmad Beirami and Virginia Smith},
booktitle={International Conference on Learning Representations},
year={2020}
}

@article{caldarola2022improving,
  title={Improving Generalization in Federated Learning by Seeking Flat Minima},
  author={Caldarola, Debora and Caputo, Barbara and Ciccone, Marco},
  journal={arXiv preprint arXiv:2203.11834},
  year={2022}
}
