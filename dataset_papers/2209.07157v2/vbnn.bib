@article{Chen2018,
  title={Metrics for Deep Generative Models},
  author={Nutan Chen and Alexej Klushyn and Richard Kurle and Xueyan Jiang and J. Bayer and P. V. D. Smagt},
  journal={ArXiv},
  year={2018},
  volume={abs/1711.01204}
}

@inproceedings{Kurle2019MSNVI,
  title={Multi-Source Neural Variational Inference},
  author={Richard Kurle and Stephan G{\"u}nnemann aßnd P. V. D. Smagt},
  booktitle={AAAI},
  year={2019}
}

@inproceedings{Klushyn2019,
 author = {Klushyn, Alexej and Chen, Nutan and Kurle, Richard and Cseke, Botond and van der Smagt, Patrick},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {2870--2879},
 publisher = {Curran Associates, Inc.},
 title = {Learning Hierarchical Priors in VAEs},
 volume = {32},
 year = {2019}
}

@inproceedings{Klushyn2021,

	title={Latent Matters: Learning Deep State-Space Models},
	author={Alexej Klushyn and Richard Kurle and Maximilian Soelch and Botond Cseke and Patrick van der Smagt},
	booktitle={Thirty-Fifth Conference on Neural Information Processing Systems},
	year={2021},
}


@inproceedings{Ansari2021,
	title={Deep Explicit Duration Switching Models for Time Series},
	author={Abdul Fatir Ansari and Konstantinos Benidis and Richard Kurle and Ali Caner Turkmen and Harold Soh and Alex Smola and Bernie Wang and Tim Januschowski},
	booktitle={Thirty-Fifth Conference on Neural Information Processing Systems},
	year={2021},
}

@InProceedings{Klushyn2019ICANN,
	author="Klushyn, Alexej
	and Chen, Nutan
	and Cseke, Botond
	and Bayer, Justin
	and van der Smagt, Patrick",
	editor="Tetko, Igor V.
	and K{\r{u}}rkov{\'a}, V{\v{e}}ra
	and Karpov, Pavel
	and Theis, Fabian",
	title="Increasing the Generalisaton Capacity of Conditional VAEs",
	booktitle="Artificial Neural Networks and Machine Learning -- ICANN 2019: Deep Learning",
	year="2019",
	publisher="Springer International Publishing",
	address="Cham",
	pages="779--791",
}

@inproceedings{Kurle2020LLL,
  author    = {Richard Kurle and
               Botond Cseke and
               Alexej Klushyn and
               Patrick van der Smagt and
               Stephan G{\"{u}}nnemann},
  title     = {Continual Learning with {B}ayesian Neural Networks for Non-Stationary
               Data},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  publisher = {OpenReview.net},
  year      = {2020},
}


@inproceedings{Bezenac2020,
 author = {
    de Bezenac, Emmanuel and
    Rangapuram, Syama Sundar and 
    Benidis, Konstantinos and
    Bohlke-Schneider, Michael and
    Kurle, Richard and 
    Stella, Lorenzo and
    Hasson, Hilaf and
    Gallinari, Patrick and
    Januschowski, Tim
 },
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Normalizing Kalman Filters for Multivariate Time Series Analysis},
 volume = {33},
 year = {2020},
}

@inproceedings{Kurle2020RBPF,
 author = {Kurle, Richard and Rangapuram, Syama Sundar and de Bezenac, Emmanuel and Günnemann, Stephan and Gasthaus, Jan},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Deep Rao-Blackwellised Particle Filters for Time Series Forecasting},
 volume = {33},
 year = {2020},
}

@inproceedings{Kurle2021BDL,
	title={On Symmetries in Variational {B}ayesian Neural Nets},
	author={Kurle, Richard and Januschowski, Tim and Gasthaus, Jan and Wang, Bernie},
	booktitle={{B}ayesian Deep Learning NeurIPS workshop},
	year={2021},
}

@inproceedings{Masegosa2020,
	author = {Masegosa, Andrés},
	title = {Learning under Model Misspecification: Applications to Variational and Ensemble methods},
	booktitle = {Advances in Neural Information Processing Systems},
	volume = {33},
	year = {2020},
}

@inproceedings{Karl2017,
	author    = {Maximilian Karl and
	Maximilian S{\"{o}}lch and
	Justin Bayer and
	Patrick van der Smagt},
	title     = {Deep Variational {B}ayes Filters: Unsupervised Learning of State Space
	Models from Raw Data},
	booktitle = {5th International Conference on Learning Representations, {ICLR} 2017,
	Toulon, France, April 24-26, 2017, Conference Track Proceedings},
	publisher = {OpenReview.net},
}

@inproceedings{Krishnan2017,
	author = {Krishnan, Rahul G. and Shalit, Uri and Sontag, David},
	title = {Structured Inference Networks for Nonlinear State Space Models},
	year = {2017},
	publisher = {AAAI Press},
	booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
	pages = {2101–2109},
}

@incollection{Maddison2017,
	title = {Filtering Variational Objectives},
	author = {Maddison, Chris J and Lawson, John and Tucker, George and Heess, Nicolas and Norouzi, Mohammad and Mnih, Andriy and Doucet, Arnaud and Teh, Yee Whye},
	booktitle = {Advances in Neural Information Processing Systems 30},
	editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	pages = {6573--6583},
	year = {2017},
	publisher = {Curran Associates, Inc.},
}

@inproceedings{Naesseth2018,
	title = "Variational Sequential {M}onte {C}arlo",
	author = "Naesseth, {Christian A.} and Linderman, {Scott W.} and Rajesh Ranganath and Blei, {David M.}",
	year = "2018",
	day = "1",
	language = "English (US)",
	pages = "968--977",
	booktitle = "21st International Conference on Artificial Intelligence and Statistics (AISTATS 2018)",
}

@article{Le2017,
	author = {Le, Tuan Anh and Igl, Maximilian and Jin, Tom and Rainforth, Tom and Wood, Frank},
	year = {2017},
	title = {Auto-Encoding Sequential Monte Carlo}
}

@inproceedings{Moretti2020,
	title={Variational Objectives for Markovian Dynamics with Backward Simulation},
	author={A. Moretti and Zi-zhao Wang and Luhuan Wu and Iddo Drori},
	booktitle={ECAI},
	year={2020}
}

@inproceedings{Tomczak2020,
 author = {Tomczak, Marcin B. and Swaroop, Siddharth and Turner, Richard E.},
 booktitle = {Advances in Neural Information Processing Systems},
 title = {Efficient Low Rank Gaussian Variational Inference for Neural Networks},
 volume = {33},
 year = {2020}
}

@inproceedings{Tomczak2021Collapsed,
title={Collapsed Variational Bounds for {B}ayesian Neural Networks},
author={Marcin B. Tomczak and Siddharth Swaroop and Andrew Y. K. Foong and Richard E Turner},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
}


@INPROCEEDINGS{Tishby1989a,
  author={ {Tishby} and  {Levin} and  {Solla}},
  booktitle={International 1989 Joint Conference on Neural Networks}, 
  title={Consistent inference of probabilities in layered networks: predictions and generalizations}, 
  year={1989},
  volume={},
  number={},
  pages={403-409 vol.2},}
  
@incollection{Denker1991a,
title = {Transforming Neural-Net Output Levels to Probability Distributions},
author = {John S. Denker and LeCun, Yann},
booktitle = {Advances in Neural Information Processing Systems 3},
editor = {R. P. Lippmann and J. E. Moody and D. S. Touretzky},
pages = {853--859},
year = {1991},
publisher = {Morgan-Kaufmann},
}

@article{Buntine1991a,
  title={{B}ayesian Back-Propagation},
  author={Wray L. Buntine and A. Weigend},
  journal={Complex Syst.},
  year={1991},
  volume={5}
}

@article{MacKay1992a,
author = {MacKay, David J. C.},
title = {A Practical {B}ayesian Framework for Backpropagation Networks},
year = {1992},
issue_date = {May 1992},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {4},
number = {3},
issn = {0899-7667},
doi = {10.1162/neco.1992.4.3.448},
journal = {Neural Comput.},
pages = {448–472},
numpages = {25}
}

@incollection{Denker1991,
title = {Transforming Neural-Net Output Levels to Probability Distributions},
author = {John S. Denker and LeCun, Yann},
booktitle = {Advances in Neural Information Processing Systems 3},
editor = {R. P. Lippmann and J. E. Moody and D. S. Touretzky},
pages = {853--859},
year = {1991},
publisher = {Morgan-Kaufmann},
}

@incollection{Neal1993a,
title = {{B}ayesian Learning via Stochastic Dynamics},
author = {Radford M. Neal},
booktitle = {Advances in Neural Information Processing Systems 5},
editor = {S. J. Hanson and J. D. Cowan and C. L. Giles},
pages = {475--482},
year = {1993},
publisher = {Morgan-Kaufmann},
}

@inproceedings{Hinton1993a,
author = {Hinton, Geoffrey E. and van Camp, Drew},
title = {Keeping the Neural Networks Simple by Minimizing the Description Length of the Weights},
year = {1993},
isbn = {0897916115},
publisher = {Association for Computing Machinery},
doi = {10.1145/168304.168306},
booktitle = {Proceedings of the Sixth Annual Conference on Computational Learning Theory},
pages = {5–13},
numpages = {9},
location = {Santa Cruz, California, USA},
series = {COLT '93}
}

@inproceedings{Blundell2015a,
author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
title = {Weight Uncertainty in Neural Networks},
year = {2015},
publisher = {JMLR.org},
booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37},
pages = {1613–1622},
numpages = {10},
location = {Lille, France},
series = {ICML'15}
}

@article{Ghahramani2015,
  author    = {Zoubin Ghahramani},
  title     = {Probabilistic machine learning and artificial intelligence},
  journal   = {Nat.},
  volume    = {521},
  number    = {7553},
  pages     = {452--459},
  year      = {2015},
}

@article{Schmidhuber2014,
author = "J. Schmidhuber",
title = "Deep Learning in Neural Networks: An Overview",
journal = "Neural Networks",
pages = "85-117",
volume = "61",
doi = "10.1016/j.neunet.2014.09.003",
note = "Published online 2014; based on TR arXiv:1404.7828 [cs.NE]",
year = "2015"}


@article{Lecun2015,
	title = {Deep learning},
	volume = {521},
	issn = {1476-4687},
	doi = {10.1038/nature14539},
	number = {7553},
	journal = {Nature},
	author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	year = {2015},
	pages = {436--444},
}

@inproceedings{Kingma2013VAE,
  author    = {Diederik P. Kingma and
               Max Welling},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Auto-Encoding Variational {B}ayes},
  booktitle = {2nd International Conference on Learning Representations, {ICLR} 2014,
               Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings},
  year      = {2014},
}

@article{Hoffman2013,
  author  = {Matthew D. Hoffman and David M. Blei and Chong Wang and John Paisley},
  title   = {Stochastic Variational Inference},
  journal = {Journal of Machine Learning Research},
  year    = {2013},
  volume  = {14},
  number  = {4},
  pages   = {1303-1347},
}

@InProceedings{Rezende2014, 
  title = {Stochastic Backpropagation and Approximate Inference in Deep Generative Models},
  author = {Danilo Jimenez Rezende and Shakir Mohamed and Daan Wierstra}, 
  booktitle = {Proceedings of the 31st International Conference on Machine Learning}, 
  pages = {1278--1286}, 
  year = {2014}, editor = {Eric P. Xing and Tony Jebara}, 
  volume = {32}, 
  number = {2}, 
  series = {Proceedings of Machine Learning Research}, 
  address = {Bejing, China}, 
  publisher = {PMLR}, 
  pdf = {http://proceedings.mlr.press/v32/rezende14.pdf},
}

@article{Wang2020,
author = {Wang, Hao and Yeung, Dit-Yan},
title = {A Survey on {B}ayesian Deep Learning},
year = {2020},
issue_date = {October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {5},
issn = {0360-0300},
doi = {10.1145/3409383},
journal = {ACM Comput. Surv.},
numpages = {37},
keywords = {Deep learning, probabilistic graphical models, generative models, {B}ayesian networks}
}

@article{Wilson2020,
  title={The Case for {B}ayesian Deep Learning},
  author={A. Wilson},
  journal={ArXiv},
  year={2020},
  volume={abs/2001.10995}
}

@PhdThesis{Gal2016,
  title={Uncertainty in Deep Learning},
  author={Gal, Yarin},
  year={2016},
  school={University of Cambridge}
}

@article{Neal2011,
  title={MCMC Using Hamiltonian Dynamics},
  author={R. Neal},
  journal={arXiv: Computation},
  year={2011},
  pages={139-188}
}

@inproceedings{Welling2011,
author = {Welling, Max and Teh, Yee Whye},
title = {{B}ayesian Learning via Stochastic Gradient Langevin Dynamics},
year = {2011},
isbn = {9781450306195},
publisher = {Omnipress},
pages = {681–688},
numpages = {8},
location = {Bellevue, Washington, USA},
series = {ICML'11}
}

@inproceedings{Graves2011,
 author = {Graves, Alex},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {J. Shawe-Taylor and R. Zemel and P. Bartlett and F. Pereira and K. Q. Weinberger},
 pages = {2348--2356},
 publisher = {Curran Associates, Inc.},
 title = {Practical Variational Inference for Neural Networks},
 volume = {24},
 year = {2011}
}

@inproceedings{Nowozin2019,
  author    = {Anqi Wu and
               Sebastian Nowozin and
               Edward Meeds and
               Richard E. Turner and
               Jos{\'{e}} Miguel Hern{\'{a}}ndez{-}Lobato and
               Alexander L. Gaunt},
  title     = {Deterministic Variational Inference for Robust {B}ayesian Neural Networks},
  booktitle = {7th International Conference on Learning Representations, {ICLR} 2019,
               New Orleans, LA, USA, May 6-9, 2019},
  publisher = {OpenReview.net},
  year      = {2019},
}


@InProceedings{Dikov2019,
  title = 	 {{B}ayesian Learning of Neural Network Architectures},
  author =       {Dikov, Georgi and Bayer, Justin},
  booktitle = 	 {Proceedings of Machine Learning Research},
  pages = 	 {730--738},
  year = 	 {2019},
  editor = 	 {Kamalika Chaudhuri and Masashi Sugiyama},
  volume = 	 {89},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
}


@InProceedings{Louizos2017,
  title = 	 {Multiplicative Normalizing Flows for Variational {B}ayesian Neural Networks},
  author =       {Christos Louizos and Max Welling},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {2218--2227},
  year = 	 {2017},
  editor = 	 {Doina Precup and Yee Whye Teh},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {International Convention Centre, Sydney, Australia},
  publisher =    {PMLR},
}

@InProceedings{Ghosh2018,
  title = 	 {Structured Variational Learning of {B}ayesian Neural Networks with Horseshoe Priors},
  author =       {Ghosh, Soumya and Yao, Jiayu and Doshi-Velez, Finale},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1744--1753},
  year = 	 {2018},
  editor = 	 {Jennifer Dy and Andreas Krause},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  publisher =    {PMLR},
}

@article{Sun2019,
  title={Functional Variational {B}ayesian Neural Networks},
  author={S. Sun and Guodong Zhang and Jiaxin Shi and Roger B. Grosse},
  journal={ArXiv},
  year={2019},
  volume={abs/1903.05779}
}

@inproceedings{Burt2021Functional,
title={Understanding Variational Inference in Function-Space},
author={David R. Burt and Sebastian W. Ober and Adri{\`a} Garriga-Alonso and Mark van der Wilk},
booktitle={Third Symposium on Advances in Approximate {B}ayesian Inference},
year={2021},
}


@InProceedings{Ma2019Implicit,
  title = 	 {Variational Implicit Processes},
  author =       {Ma, Chao and Li, Yingzhen and Hernandez-Lobato, Jose Miguel},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {4222--4233},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/ma19b/ma19b.pdf},
  abstract = 	 {We introduce the implicit processes (IPs), a stochastic process that places implicitly defined multivariate distributions over any finite collections of random variables. IPs are therefore highly flexible implicit priors over <em>functions</em>, with examples including data simulators, {B}ayesian neural networks and non-linear transformations of stochastic processes. A novel and efficient approximate inference algorithm for IPs, namely the variational implicit processes (VIPs), is derived using generalised wake-sleep updates. This method returns simple update equations and allows scalable hyper-parameter learning with stochastic optimization. Experiments show that VIPs return better uncertainty estimates and lower errors over existing inference methods for challenging models such as {B}ayesian neural networks, and Gaussian processes.}
}


@inproceedings{Wang2018function,
title={Function Space Particle Optimization for {B}ayesian Neural Networks},
author={Ziyu Wang and Tongzheng Ren and Jun Zhu and Bo Zhang},
booktitle={International Conference on Learning Representations},
year={2019},
}

@article{Tran2022GPPrior,
  author  = {Ba-Hien Tran and Simone Rossi and Dimitrios Milios and Maurizio Filippone},
  title   = {All You Need is a Good Functional Prior for {B}ayesian Deep Learning},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {74},
  pages   = {1-56},
}

@inproceedings{FlamShepherd2017MappingGP,
  title={Mapping Gaussian Process Priors to {B}ayesian Neural Networks},
  author={Daniel Flam-Shepherd},
  booktitle={{B}ayesian Deep Learning NeurIPS workshop},
  year={2017}
}

@inproceedings{Swiatkowski2020,
author = {Swiatkowski, Jakub and Roth, Kevin and Veeling, Bastiaan S. and Tran, Linh and Dillon, Joshua V. and Snoek, Jasper and Mandt, Stephan and Salimans, Tim and Jenatton, Rodolphe and Nowozin, Sebastian},
title = {The K-Tied Normal Distribution: A Compact Parameterization of Gaussian Mean Field Posteriors in {B}ayesian Neural Networks},
year = {2020},
publisher = {JMLR.org},
abstract = {Variational {B}ayesian Inference is a popular methodology for approximating posterior distributions over {B}ayesian neural network weights. Recent work developing this class of methods has explored ever richer parameterizations of the approximate posterior in the hope of improving performance. In contrast, here we share a curious experimental finding that suggests instead restricting the variational distribution to a more compact parameterization. For a variety of deep {B}ayesian neural networks trained using Gaussian mean-field variational inference, we find that the posterior standard deviations consistently exhibit strong low-rank structure after convergence. This means that by decomposing these variational parameters into a low-rank factorization, we can make our variational approximation more compact without decreasing the models' performance. Furthermore, we find that such factorized parameterizations improve the signal-to-noise ratio of stochastic gradient estimates of the variational lower bound, resulting in faster convergence.},
booktitle = {Proceedings of the 37th International Conference on Machine Learning},
articleno = {861},
numpages = {11},
series = {ICML'20}
}

@inproceedings{Burda2016,
  author    = {Yuri Burda and
               Roger B. Grosse and
               Ruslan Salakhutdinov},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Importance Weighted Autoencoders},
  booktitle = {4th International Conference on Learning Representations, {ICLR} 2016,
               San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings},
  year      = {2016},
}

@InProceedings{Rezende2015,
  title = 	 {Variational Inference with Normalizing Flows},
  author = 	 {Danilo Rezende and Shakir Mohamed},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1530--1538},
  year = 	 {2015},
  editor = 	 {Francis Bach and David Blei},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  publisher =    {PMLR},
}


@inproceedings{Salimans2015,
author = {Salimans, Tim and Kingma, Diederik P. and Welling, Max},
title = {Markov Chain Monte Carlo and Variational Inference: Bridging the Gap},
year = {2015},
publisher = {JMLR.org},
booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37},
pages = {1218–1226},
numpages = {9},
location = {Lille, France},
series = {ICML'15}
}

@inproceedings{Mescheder2017,
  title = {Adversarial Variational {B}ayes: Unifying Variational Autoencoders and Generative Adversarial Networks},
  author = {Mescheder, L. and Nowozin, S. and Geiger, A.},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  volume = {70},
  series = {Proceedings of Machine Learning Research},
  editors = {Doina Precup, Yee Whye Teh},
  publisher = {PMLR},
  year = {2017},
}

@article{Foong2019,
  title={'In-Between' Uncertainty in {B}ayesian Neural Networks},
  author={Andrew Y. K. Foong and Yingzhen Li and Jos{\'e} Miguel Hern{\'a}ndez-Lobato and R. Turner},
  journal={ArXiv},
  year={2019},
  volume={abs/1906.11537}
}

@inproceedings{Foong2020,
 author = {Foong, Andrew and Burt, David and Li, Yingzhen and Turner, Richard},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {15897--15908},
 publisher = {Curran Associates, Inc.},
 title = {On the Expressiveness of Approximate Inference in {B}ayesian Neural Networks},
 volume = {33},
 year = {2020}
}



@article{Lawrence2000,
author = {Lawrence, Neil},
year = {2000},
pages = {},
title = {Variational inference in probabilistic models}
}

@inproceedings{Ritter2018,
author = {Ritter, H and Botev, A and Barber, D},
year = {2018},
pages = {},
title = {A Scalable Laplace Approximation for Neural Networks}
}

@article{Kirkpatrick2016,
author = {Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and Hassabis, Demis and Clopath, Claudia and Kumaran, Dharshan and Hadsell, Raia},
year = {2016},
pages = {},
title = {Overcoming catastrophic forgetting in neural networks},
volume = {114},
journal = {Proceedings of the National Academy of Sciences},
doi = {10.1073/pnas.1611835114}
}

@book{MacKay2003,
  author = {MacKay, David J. C.},
  keywords = {{B}ayesianinference book informationtheory neuralnetworks patternrecognition probabilitytheory},
  publisher = {Copyright Cambridge University Press},
  timestamp = {2007-05-24T14:43:04.000+0200},
  title = {Information Theory, Inference, and Learning Algorithms},
  year = 2003
}

@book{Owen2013,
   author = {Art B. Owen},
   year = 2013,
   title = {Monte Carlo theory, methods and examples}
}

@book{Sarkka2013, 
    place={Cambridge}, 
    series={Institute of Mathematical Statistics Textbooks}, 
    title={{B}ayesian Filtering and Smoothing}, 
    DOI={10.1017/CBO9781139344203}, 
    publisher={Cambridge University Press}, 
    author={Särkkä, Simo}, 
    year={2013}, 
    collection={Institute of Mathematical Statistics Textbooks}
}

@article{Cox1946,
	author = {Cox,R. T. },
	title = {Probability, Frequency and Reasonable Expectation},
	journal = {American Journal of Physics},
	volume = {14},
	number = {1},
	pages = {1-13},
	year = {1946},
}

@book{Jaynes2003, 
    place={Cambridge}, 
    title={Probability Theory: The Logic of Science}, DOI={10.1017/CBO9780511790423}, 
    publisher={Cambridge University Press}, author={Jaynes, E. T.}, 
    editor={Bretthorst, G. LarryEditor}, 
    year={2003}
}

@book{Pearl1988,
    author = {Pearl, Judea},
    title = {Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference},
    year = {1988},
    isbn = {1558604790},
    publisher = {Morgan Kaufmann Publishers Inc.},
    address = {San Francisco, CA, USA},
}

@book{Murphy2012,
author = {Murphy, Kevin P.},
title = {Machine Learning: A Probabilistic Perspective},
year = {2012},
isbn = {0262018020},
publisher = {The MIT Press},
}

@article{Gruenwald2017,
    author = "Grünwald, Peter and van Ommen, Thijs",
    doi = "10.1214/17-BA1085",
    fjournal = "{B}ayesian Analysis",
    journal = "{B}ayesian Anal.",
    number = "4",
    pages = "1069--1103",
    publisher = "International Society for {B}ayesian Analysis",
    title = "Inconsistency of {B}ayesian Inference for Misspecified Linear Models, and a Proposal for Repairing It",
    volume = "12",
    year = "2017"
}


@article{Dayan1995,
author = {Dayan, Peter and Hinton, Geoffrey E. and Neal, Radford M. and Zemel, Richard S.},
title = {The Helmholtz Machine},
year = {1995},
issue_date = {Sept. 1995},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {7},
number = {5},
journal = {Neural Comput.},
pages = {889–904},
numpages = {16}
}

@article{Saul1996,
author = {Saul, Lawrence K. and Jaakkola, Tommi and Jordan, Michael I.},
title = {Mean Field Theory for Sigmoid Belief Networks},
year = {1996},
issue_date = {Jnauary 1996},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {4},
number = {1},
issn = {1076-9757},
journal = {J. Artif. Int. Res.},
pages = {61–76},
numpages = {16}
}

@article{Dempster1977,
 author = {A. P. Dempster and N. M. Laird and D. B. Rubin},
 journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
 number = {1},
 pages = {1--38},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Maximum Likelihood from Incomplete Data via the EM Algorithm},
 volume = {39},
 year = {1977}
}

@article{Rissanen1978,
title = "Modeling by shortest data description",
journal = "Automatica",
volume = "14",
number = "5",
pages = "465 - 471",
year = "1978",
author = "J. Rissanen",
keywords = "Modeling, parameter estimation, identification, statistics, stochastic systems",
}

@article{Opper2009,
author = {Opper, Manfred and Archambeau, C\'{e}dric},
title = {The Variational Gaussian Approximation Revisited},
year = {2009},
issue_date = {March 2009},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {21},
number = {3},
issn = {0899-7667},
abstract = {The variational approximation of posterior distributions by multivariate gaussians has been much less popular in the machine learning community compared to the corresponding approximation by factorizing distributions. This is for a good reason: the gaussian approximation is in general plagued by an <inline-formula><inline-graphic xlink="neco.2008.08-07-592inline1.gif" mimetype="image" xlink:type="simple"></inline-graphic></inline-formula> number of variational parameters to be optimized, N being the number of random variables. In this letter, we discuss the relationship between the Laplace and the variational approximation, and we show that for models with gaussian priors and factorizing likelihoods, the number of variational parameters is actually <inline-formula><inline-graphic xlink="neco.2008.08-07-592inline7.gif" mimetype="image" xlink:type="simple"></inline-graphic></inline-formula>. The approach is applied to gaussian process regression with nongaussian likelihoods.},
journal = {Neural Comput.},
pages = {786–792},
numpages = {7}
}

@inproceedings{Ghahramani2001,
author = {Ghahramani, Zoubin and Beal, Matthew J.},
title = {Propagation Algorithms for Variational {B}ayesian Learning},
year = {2000},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
pages = {486–492},
numpages = {7},
location = {Denver, CO},
series = {NIPS'00}
}

@article{Jensen1906,
  title={Sur les fonctions convexes et les in{\'e}galit{\'e}s entre les valeurs moyennes},
  author={J. V. Jensen},
  journal={Acta Mathematica},
  volume={30},
  pages={175-193}
}

@inproceedings{Ruiz2016,
author = {Ruiz, Francisco J. R. and Titsias, Michalis K. and Blei, David M.},
title = {The Generalized Reparameterization Gradient},
year = {2016},
isbn = {9781510838819},
publisher = {Curran Associates Inc.},
booktitle = {Proceedings of the 30th International Conference on Neural Information Processing Systems},
pages = {460–468},
numpages = {9},
location = {Barcelona, Spain},
series = {NIPS'16}
}

@inproceedings{Kingma2015LocalReparam,
author = {Kingma, Diederik P. and Salimans, Tim and Welling, Max},
title = {Variational Dropout and the Local Reparameterization Trick},
year = {2015},
publisher = {MIT Press},
booktitle = {Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2},
pages = {2575–2583},
numpages = {9},
location = {Montreal, Canada},
series = {NIPS'15}
}

@article{Kalman1960,
    author = {Kalman, Rudolph Emil},
    title = {A New Approach to Linear Filtering and Prediction Problems},
    journal = {Transactions of the ASME--Journal of Basic Engineering},
    volume = {82},
    number = {Series D},
    pages = {35--45},
    year = {1960}
}

@inproceedings{Doucet2008,
  title={A Tutorial on Particle Filtering and Smoothing: Fifteen years later},
  author={A. Doucet and A. Johansen},
  year={2008}
}

@article{Naesseth2019,
  title={Elements of Sequential Monte Carlo},
  author={C. A. Naesseth and F. Lindsten and Thomas Bo Sch{\"o}n},
  journal={Found. Trends Mach. Learn.},
  year={2019},
  volume={12},
  pages={307-392}
}

@article{Chopin2004,
author = "Chopin, Nicolas",
doi = "10.1214/009053604000000698",
fjournal = "Annals of Statistics",
journal = "Ann. Statist.",
number = "6",
pages = "2385--2411",
publisher = "The Institute of Mathematical Statistics",
title = "Central limit theorem for sequential Monte Carlo methods and its application to {B}ayesian inference",
volume = "32",
year = "2004"
}

@inproceedings{Sohn2015,
	author = {Sohn, Kihyuk and Lee, Honglak and Yan, Xinchen},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
	pages = {3483--3491},
	publisher = {Curran Associates, Inc.},
	title = {Learning Structured Output Representation using Deep Conditional Generative Models},
	volume = {28},
	year = {2015}
}

@article{Blei2016,
	author    = {David M. Blei and
	Alp Kucukelbir and
	Jon D. McAuliffe},
	title     = {Variational Inference: {A} Review for Statisticians},
	journal   = {CoRR},
	volume    = {abs/1601.00670},
	year      = {2016},
	archivePrefix = {arXiv},
}

@article{Jordan1999,
	author = {Jordan, Michael I. and Ghahramani, Zoubin and Jaakkola, Tommi S. and Saul, Lawrence K.},
	title = {An Introduction to Variational Methods for Graphical Models},
	year = {1999},
	issue_date = {Nov.1.1999},
	publisher = {Kluwer Academic Publishers},
	volume = {37},
	number = {2},
	issn = {0885-6125},
	doi = {10.1023/A:1007665907178},
	journal = {Mach. Learn.},
	pages = {183–233},
	numpages = {51},
	keywords = {approximate inference, hidden Markov models, neural networks, variational methods, Boltzmann machines, graphical models, belief networks, mean field methods, {B}ayesian networks, probabilistic inference}
}

@inproceedings{Figurnov2018,
	author = {Figurnov, Michael and Mohamed, Shakir and Mnih, Andriy},
	title = {Implicit Reparameterization Gradients},
	year = {2018},
	publisher = {Curran Associates Inc.},
	booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
	pages = {439–450},
	numpages = {12},
	location = {Montr\'{e}al, Canada},
	series = {NIPS'18}
}

@article{Maddison2016,
	author    = {Chris J. Maddison and
	Andriy Mnih and
	Yee Whye Teh},
	title     = {The Concrete Distribution: {A} Continuous Relaxation of Discrete Random
	Variables},
	journal   = {CoRR},
	volume    = {abs/1611.00712},
	year      = {2016},
	archivePrefix = {arXiv},
}

@book{Maybeck1979,
	title={Stochastic Models, Estimation and Control},
	author={Maybeck, P. S.},
	series={Mathematics in science and engineering},
	year={1982},
	publisher={Academic Press}
}

@article{Arasaratnam2007,
	author={I. {Arasaratnam} and S. {Haykin} and R. J. {Elliott}},
	journal={Proceedings of the IEEE}, 
	title={Discrete-Time Nonlinear Filtering Algorithms Using Gauss–Hermite Quadrature}, 
	year={2007},
	volume={95},
	pages={953-977}
}

@article{Arasaratnam2009,
	author={I. {Arasaratnam} and S. {Haykin}},
	journal={IEEE Transactions on Automatic Control}, 
	title={Cubature Kalman Filters}, 
	year={2009},
	volume={54},
	pages={1254-1269}
}

@phdthesis{minka2001family,
	title={A family of algorithms for approximate {B}ayesian inference},
	author={Minka, Thomas Peter},
	year={2001},
	school={Massachusetts Institute of Technology}
}

@inproceedings{Wan2000,
	author={E. A. {Wan} and R. {Van Der Merwe}},
	booktitle={Proceedings of the IEEE 2000 Adaptive Systems for Signal Processing, Communications, and Control Symposium (Cat. No.00EX373)}, 
	title={The unscented Kalman filter for nonlinear estimation}, 
	year={2000},
	volume={},
	number={},
	pages={153-158}
}

@article{Kitagawa1996,
	author = { Genshiro Kitagawa},
	title = {Monte Carlo Filter and Smoother for Non-Gaussian Nonlinear State Space Models},
	journal = {Journal of Computational and Graphical Statistics},
	volume = {5},
	pages = {1-25},
	year  = {1996},
	publisher = {Taylor & Francis},
}

@article{Gordon1993,
	author = {N.J. Gordon and D.J. Salmond and A.F.M. Smith},
	language = {English},
	title = {Novel approach to nonlinear/non-Gaussian {B}ayesian state estimation},
	journal = {IEE Proceedings F (Radar and Signal Processing)},
	issue = {2},   
	volume = {140},
	year = {1993},
	pages = {107-113(6)},
}

@book{Jazwinski1970,
	address = {New York, NY [u.a.]},
	author = {Jazwinski, {Andrew H.}},
	isbn = {0123815509},
	keywords = {Filtertheorie Stochastischer_Prozess},
	number = 64,
	pagetotal = {XIV, 376},
	ppn_gvk = {021832242},
	publisher = {Acad. Press},
	series = {Mathematics in science and engineering},
	timestamp = {2009-08-21T12:29:38.000+0200},
	title = {Stochastic processes and filtering theory},
	year = 1970,
}

@inproceedings{Roth2011,  
	author={M. {Roth} and F. {Gustafsson}},  
	booktitle={14th International Conference on Information Fusion},   
	title={An efficient implementation of the second order extended Kalman filter},   
	year={2011},  
	volume={},  
	number={},  
	pages={1-6},  
	doi={},
}

@article{Breiman1996,
	title={Bagging predictors},
	author={L. Breiman},
	journal={Machine Learning},
	year={1996},
	volume={24},
	pages={123-140}
}

@article{Schapire1990,
	author = {Schapire, Robert E.},
	title = {The Strength of Weak Learnability},
	year = {1990},
	issue_date = {Jun. 1990},
	publisher = {Kluwer Academic Publishers},
	address = {USA},
	volume = {5},
	number = {2},
	issn = {0885-6125},
	doi = {10.1023/A:1022648800760},
	journal = {Mach. Learn.},
	pages = {197–227},
	numpages = {31},
	keywords = {Machine learning, learnability theory, polynomial-time identification, PAC learning, learning from examples}
}

@book{DelMoral2004,
	author = {Del Moral, Pierre},
	year = {2004},
	title = {Feynman-Kac Formulae: Genealogical and Interacting Particle Systems With Applications},
	journal = {Journal of The American Statistical Association - J AMER STATIST ASSN},
}


@article{Hochreiter1997,
	author = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
	journal = {Neural computation},
	keywords = {lstm rnn},
	number = 8,
	pages = {1735--1780},
	publisher = {MIT Press},
	timestamp = {2016-11-15T08:49:43.000+0100},
	title = {Long short-term memory},
	volume = 9,
	year = 1997
}

@inproceedings{Cho2014,
	title = "Learning Phrase Representations using {RNN} Encoder{--}Decoder for Statistical Machine Translation",
	author = {Cho, Kyunghyun  and
	van Merri{\"e}nboer, Bart  and
	Gulcehre, Caglar  and
	Bahdanau, Dzmitry  and
	Bougares, Fethi  and
	Schwenk, Holger  and
	Bengio, Yoshua},
	booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
	year = "2014",
	address = "Doha, Qatar",
	publisher = "Association for Computational Linguistics",
	pages = "1724--1734",
}



@inproceedings{Vaswani2017,
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	pages = {5998--6008},
	publisher = {Curran Associates, Inc.},
	title = {Attention is All you Need},
	volume = {30},
	year = {2017}
}

@inproceedings{Ioffe2015,
	author = {Ioffe, Sergey and Szegedy, Christian},
	title = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
	year = {2015},
	publisher = {JMLR.org},
	pages = {448–456},
	numpages = {9},
	location = {Lille, France},
	series = {ICML'15}
}

@article{Ba16,
	author    = {Lei Jimmy Ba and
	Jamie Ryan Kiros and
	Geoffrey E. Hinton},
	title     = {Layer Normalization},
	journal   = {CoRR},
	volume    = {abs/1607.06450},
	year      = {2016},
	archivePrefix = {arXiv},
	eprint    = {1607.06450},
}

@article{Srivastava2014,
	title = {Dropout: {A} {Simple} {Way} to {Prevent} {Neural} {Networks} from {Overfitting}},
	volume = {15},
	number = {56},
	journal = {Journal of Machine Learning Research},
	author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	year = {2014},
	pages = {1929--1958},
}

@article{Carpenter1999,
	author={J. {Carpenter} and P. {Clifford} and P. {Fearnhead}},
	journal={IEE Proceedings - Radar, Sonar and Navigation}, 
	title={Improved particle filter for nonlinear problems}, 
	year={1999},
	volume={146},
	pages={2-7}
}

@inproceedings{Sonderby2016,
	author = {S\o{}nderby, Casper Kaae and Raiko, Tapani and Maal\o{}e, Lars and S\o{}nderby, S\o{}ren Kaae and Winther, Ole},
	title = {Ladder Variational Autoencoders},
	year = {2016},
	isbn = {9781510838819},
	publisher = {Curran Associates Inc.},
	booktitle = {Proceedings of the 30th International Conference on Neural Information Processing Systems},
	pages = {3745–3753},
	numpages = {9},
	location = {Barcelona, Spain},
	series = {NIPS'16}
}

@inproceedings{Kingma2014SSL,
	author = {Kingma, Durk P and Mohamed, Shakir and Jimenez Rezende, Danilo and Welling, Max},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {Z. Ghahramani and M. Welling and C. Cortes and N. Lawrence and K. Q. Weinberger},
	pages = {3581--3589},
	publisher = {Curran Associates, Inc.},
	title = {Semi-supervised Learning with Deep Generative Models},
	volume = {27},
	year = {2014}
}

@phdthesis{Beal2003,
	author = {Beal, Matthew J.},
	keywords = {Variationalmethods},
	school = {Gatsby Computational Neuroscience Unit, University College London},
	timestamp = {2010-03-25T16:34:19.000+0100},
	title = {Variational Algorithms for Approximate {B}ayesian Inference},
	year = 2003
}

@inproceedings{Mnih2014,
	author = {Mnih, Andriy and Gregor, Karol},
	title = {Neural Variational Inference and Learning in Belief Networks},
	year = {2014},
	publisher = {JMLR.org},
	booktitle = {Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32},
	pages = {II–1791–II–1799},
	numpages = {9},
	location = {Beijing, China},
	series = {ICML'14}
}

@phdthesis{Neal1995,
	author = {Neal, Radford M.},
	advisor = {Hinton, Geoffrey},
	title = {{B}ayesian Learning for Neural Networks},
	year = {1995},
	isbn = {0612026760},
	publisher = {University of Toronto},
	address = {CAN},
}

@phdthesis{Freitas2003,
	title={{B}ayesian methods for neural networks},
	author={De Freitas, Jo{\~a}o F. G.},
	year={2003},
	school={University of Cambridge}
}

@article{Titterington2004,
	author = "Titterington, D. M.",
	doi = "10.1214/088342304000000099",
	fjournal = "Statistical Science",
	journal = "Statist. Sci.",
	number = "1",
	pages = "128--139",
	publisher = "The Institute of Mathematical Statistics",
	title = "{B}ayesian Methods for Neural Networks and Related Models",
	volume = "19",
	year = "2004"
}

@InProceedings{Chen2014SGHMC,
	title = 	 {Stochastic Gradient Hamiltonian Monte Carlo},
	author = 	 {Tianqi Chen and Emily Fox and Carlos Guestrin},
	booktitle = 	 {Proceedings of the 31st International Conference on Machine Learning},
	pages = 	 {1683--1691},
	year = 	 {2014},
	editor = 	 {Eric P. Xing and Tony Jebara},
	volume = 	 {32},
	number =       {2},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Bejing, China},
	publisher =    {PMLR},
}

@InProceedings{Huang2018,
	title = 	 {Neural Autoregressive Flows},
	author =       {Huang, Chin-Wei and Krueger, David and Lacoste, Alexandre and Courville, Aaron},
	booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
	pages = 	 {2078--2087},
	year = 	 {2018},
	editor = 	 {Jennifer Dy and Andreas Krause},
	volume = 	 {80},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Stockholmsmässan, Stockholm Sweden},
	publisher =    {PMLR},
}

@inproceedings{Kingma2016IAF,
	author = {Kingma, Durk P and Salimans, Tim and Jozefowicz, Rafal and Chen, Xi and Sutskever, Ilya and Welling, Max},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
	pages = {4743--4751},
	publisher = {Curran Associates, Inc.},
	title = {Improved Variational Inference with Inverse Autoregressive Flow},
	volume = {29},
	year = {2016}
}

@article{Papamakarios2019,
	title={Normalizing Flows for Probabilistic Modeling and Inference},
	author={George Papamakarios and Eric T. Nalisnick and Danilo Jimenez Rezende and Shakir Mohamed and Balaji Lakshminarayanan},
	journal={ArXiv},
	year={2019},
	volume={abs/1912.02762}
}

@article{Schmidt2019,
	title = {Recent advances and applications of machine learning in solid-state materials science},
	volume = {5},
	issn = {2057-3960},
	doi = {10.1038/s41524-019-0221-0},
	number = {1},
	journal = {npj Computational Materials},
	author = {Schmidt, Jonathan and Marques, Mário R. G. and Botti, Silvana and Marques, Miguel A. L.},
	year = {2019},
	pages = {83},
}

@article{Andina2018,
	title = {Deep {Learning} for {Computer} {Vision}: {A} {Brief} {Review}},
	volume = {2018},
	issn = {1687-5265},
	doi = {10.1155/2018/7068349},
	journal = {Computational Intelligence and Neuroscience},
	author = {Voulodimos, Athanasios and Doulamis, Nikolaos and Doulamis, Anastasios and Protopapadakis, Eftychios},
	editor = {Andina, Diego},
	year = {2018},
	pages = {7068349},
}

@article{Libbrecht2015,
	title = {Machine learning applications in genetics and genomics},
	volume = {16},
	issn = {1471-0064},
	doi = {10.1038/nrg3920},
	number = {6},
	journal = {Nature Reviews Genetics},
	author = {Libbrecht, Maxwell W. and Noble, William Stafford},
	year = {2015},
	pages = {321--332},
}

@book{Deng2018,
	author = {Deng, Li and Liu, Yang},
	title = {Deep Learning in Natural Language Processing},
	year = {2018},
	isbn = {9789811052088},
	publisher = {Springer Publishing Company, Incorporated},
	edition = {1st},
}

@ARTICLE{Tipping1999,
	author = {Michael E. Tipping and Chris M. Bishop},
	title = {Probabilistic Principal Component Analysis},
	journal = {JOURNAL OF THE ROYAL STATISTICAL SOCIETY, SERIES B},
	year = {1999},
	volume = {61},
	number = {3},
	pages = {611--622}
}

@inproceedings{Roweis1998SPCA,
	author = {Roweis, Sam},
	title = {EM Algorithms for PCA and SPCA},
	year = {1998},
	isbn = {0262100762},
	publisher = {MIT Press},
	booktitle = {Proceedings of the 1997 Conference on Advances in Neural Information Processing Systems 10},
	pages = {626–632},
	numpages = {7},
	location = {Denver, Colorado, USA},
	series = {NIPS '97}
}


@book{Fruchter1954,
	address = {Oxford,  England},
	series = {Introduction to factor analysis.},
	title = {Introduction to factor analysis.},
	abstract = {Requiring a background of only high school mathematics, this textbook provides an elementary presentation of the method of factor analysis. The first four chapters introduce fundamental concepts including matrix algebra and geometry. Factoring by diagonal, centroid, multiple group, and principal-axes methods are explained. Rotation on orthogonal and oblique axes is discussed. Two chapters deal with the interpretation of factors and illustrative uses of the methods. 46-page bibliography. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	publisher = {Van Nostrand},
	author = {Fruchter, Benjamin},
	year = {1954},
}

@book{Harman1976,
	address = {Oxford,  England},
	series = {Modern factor analysis},
	title = {Modern factor analysis},
	publisher = {U Chicago Press},
	author = {Harman, Harry H.},
	year = {1976},
	keywords = {Factor Analysis},
}

@article{Beckmann2004,
	author={C. F. {Beckmann} and S. M. {Smith}},
	journal={IEEE Transactions on Medical Imaging}, 
	title={Probabilistic independent component analysis for functional magnetic resonance imaging}, 
	year={2004},
	volume={23},
	number={2},
	pages={137-152},
	doi={10.1109/TMI.2003.822821},
}

@article{Blei2003,
	author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
	title = {Latent Dirichlet Allocation},
	year = {2003},
	issue_date = {3/1/2003},
	publisher = {JMLR.org},
	volume = {3},
	number = {null},
	issn = {1532-4435},
	journal = {J. Mach. Learn. Res.},
	pages = {993–1022},
	numpages = {30}
}

@article{Neal1992,
	author = {Neal, Radford M.},
	title = {Connectionist Learning of Belief Networks},
	year = {1992},
	issue_date = {July 1992},
	publisher = {Elsevier Science Publishers Ltd.},
	address = {GBR},
	volume = {56},
	number = {1},
	issn = {0004-3702},
	doi = {10.1016/0004-3702(92)90065-6},
	journal = {Artif. Intell.},
	pages = {71–113},
	numpages = {43}
}


@article{Kitagawa1994,
	title = {The two-filter formula for smoothing and an implementation of the {Gaussian}-sum smoother},
	volume = {46},
	issn = {1572-9052},
	doi = {10.1007/BF00773470},
	number = {4},
	journal = {Annals of the Institute of Statistical Mathematics},
	author = {Kitagawa, Genshiro},
	year = {1994},
	pages = {605--623},
}

@article{Rauch1965,
	author = {RAUCH, H. E. and TUNG, F. and STRIEBEL, C. T.},
	doi = {10.2514/3.3166},
	journal = {AIAA Journal},
	keywords = {},
	number = {8},
	pages = {1445-1450},
	title = {Maximum likelihood estimates of linear dynamic systems},
	volume = {3},
	year = {1965}
}

@article{Koopmans1950,
	ISSN = {00034851},
	author = {T. C. Koopmans and O. Reiersol},
	journal = {The Annals of Mathematical Statistics},
	number = {2},
	pages = {165--181},
	publisher = {Institute of Mathematical Statistics},
	title = {The Identification of Structural Characteristics},
	volume = {21},
	year = {1950}
}

@article{Rothenberg1971,
	ISSN = {00129682, 14680262},
	author = {Thomas J. Rothenberg},
	journal = {Econometrica},
	number = {3},
	pages = {577--591},
	publisher = {[Wiley, The Econometric Society]},
	title = {Identification in Parametric Models},
	volume = {39},
	year = {1971}
}

@book{Casella2001,
	author = {Casella, George and Berger, Roger},
	citeulike-article-id = {105644},
	date-added = {2007-09-03 22:45:16 -0500},
	date-modified = {2007-09-03 22:45:16 -0500},
	howpublished = {{Textbook Binding}},
	interhash = {2dd8caad6c0b6fb80e6334986a231a05},
	intrahash = {1597678f36e23439610affbf46adec1c},
	isbn = {0534243126},
	keywords = {methodology probability statistics},
	publisher = {{Duxbury Resource Center}},
	timestamp = {2009-10-28T04:42:57.000+0100},
	title = {Statistical Inference},
	year = 2001
}

@article{Gruenwald2007,
	author = {Gr\"{u}nwald, Peter and Langford, John},
	title = {Suboptimal Behavior of {B}ayes and {MDL} in Classification under Misspecification},
	year = {2007},
	issue_date = {March     2007},
	publisher = {Kluwer Academic Publishers},
	address = {USA},
	volume = {66},
	number = {2–3},
	issn = {0885-6125},
	doi = {10.1007/s10994-007-0716-7},
	journal = {Mach. Learn.},
	pages = {119–149},
	numpages = {31},
	keywords = {Minimum description length, Inconsistency, {B}ayesian statistics, Misspecification, Consistency, Classification}
}

@article{Mueller2013,
	author = {Müller, Ulrich K.},
	title = {Risk of {B}ayesian Inference in Misspecified Models, and the Sandwich Covariance Matrix},
	journal = {Econometrica},
	volume = {81},
	number = {5},
	pages = {1805-1849},
	keywords = {Posterior variance, quasi-likelihood, pseudo-true parameter value, interval estimation},
	doi = {https://doi.org/10.3982/ECTA9097},
	year = {2013}
}

@article{Ghosal2000,
	author = "Ghosal, Subhashis and Ghosh, Jayanta K. and van der Vaart, Aad W.",
	doi = "10.1214/aos/1016218228",
	fjournal = "Annals of Statistics",
	journal = "Ann. Statist.",
	number = "2",
	pages = "500--531",
	publisher = "The Institute of Mathematical Statistics",
	title = "Convergence rates of posterior distributions",
	volume = "28",
	year = "2000"
}

@inproceedings{Wang2019,
	author = {Wang, Yixin and Blei, David},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
	pages = {13357--13367},
	publisher = {Curran Associates, Inc.},
	title = {Variational {B}ayes under Model Misspecification},
	volume = {32},
	year = {2019}
}


@InProceedings{Heide2020,
	title = 	 { Safe-{B}ayesian Generalized Linear Regression},
	author =       {de Heide, Rianne and Kirichenko, Alisa and Grunwald, Peter and Mehta, Nishant},
	booktitle = 	 {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
	pages = 	 {2623--2633},
	year = 	 {2020},
	editor = 	 {Silvia Chiappa and Roberto Calandra},
	volume = 	 {108},
	series = 	 {Proceedings of Machine Learning Research},
	publisher =    {PMLR},
}

@inproceedings{Doob1949,
	added-at = {2010-10-11T23:06:25.000+0200},
	author = {Doob, Joseph L.},
	booktitle = {Actes du Colloque International Le Calcul des Probabilit\'es et ses applications},
	interhash = {5705d9c7de2a1e7c170ce0b51518ed97},
	intrahash = {25cad5e035b7ac5a47ed1fb4858077ef},
	keywords = {imported},
	pages = {23--27},
	timestamp = {2010-10-11T23:06:27.000+0200},
	title = {Application of the Theory of Martingales},
	year = 1949
}

@article{Lijoi2007, 
	title={{B}ayesian consistency for stationary models}, volume={23}, 
	DOI={10.1017/S0266466607070314},
	number={4}, 
	journal={Econometric Theory}, 
	publisher={Cambridge University Press}, 
	author={Lijoi, Antonio and Prünster, Igor and Walker, Stephen G.}, year={2007}, 
	pages={749–759}}

@article{Gelman2013,
	author = {Gelman, Andrew and Shalizi, Cosma Rohilla},
	title = {Philosophy and the practice of {B}ayesian statistics},
	journal = {British Journal of Mathematical and Statistical Psychology},
	volume = {66},
	number = {1},
	pages = {8-38},
	doi = {https://doi.org/10.1111/j.2044-8317.2011.02037.x},
	year = {2013}
}

@book{White1993, 
	place={Cambridge}, 
	series={Econometric Society Monographs}, 
	title={Estimation, Inference and Specification Analysis}, DOI={10.1017/CCOL0521252806}, 
	publisher={Cambridge University Press}, 
	author={White, Halbert}, 
	year={1994}, 
	collection={Econometric Society Monographs},
}

@article{Hornik1989,
	title = "Multilayer feedforward networks are universal approximators",
	journal = "Neural Networks",
	volume = "2",
	number = "5",
	pages = "359 - 366",
	year = "1989",
	issn = "0893-6080",
	doi = "https://doi.org/10.1016/0893-6080(89)90020-8",
}

@article{Cybenko1989,
	author = {Cybenko, George},
	ee = {https://www.wikidata.org/entity/Q56532755},
	interhash = {96aecb02daa11041489259a8edb54070},
	intrahash = {3939efdf3c5dc5d414f6b8b10695daf4},
	journal = {Math. Control. Signals Syst.},
	keywords = {dblp},
	number = 4,
	pages = {303-314},
	timestamp = {2020-09-11T11:42:31.000+0200},
	title = {Approximation by superpositions of a sigmoidal function.},
	volume = 2,
	year = 1989,
}

@INPROCEEDINGS{McKelvey1997,  
	author={T. {McKelvey} and A. {Helmersson}},  
	booktitle={Proceedings of the 36th IEEE Conference on Decision and Control},   title={System identification using an over-parametrized model class-improving the optimization algorithm},   
	year={1997},  
	volume={3}, 
	number={},  
	pages={2984-2989 vol.3},  
	doi={10.1109/CDC.1997.657905},
}


@article{Raue2014,
	title = {Comparison of approaches for parameter identifiability analysis of biological systems},
	volume = {30},
	issn = {1367-4803},
	doi = {10.1093/bioinformatics/btu006},
	number = {10},
	journal = {Bioinformatics},
	author = {Raue, Andreas and Karlsson, Johan and Saccomani, Maria Pia and Jirstrand, Mats and Timmer, Jens},
	year = {2014},
	pages = {1440--1448},
}

@article{Chavent1985,
	title = "On Parameter Identifiability",
	journal = "IFAC Proceedings Volumes",
	volume = "18",
	number = "5",
	pages = "531 - 536",
	year = "1985",
	note = "7th IFAC/IFORS Symposium on Identification and System Parameter Estimation, York, UK, 3-7 July",
	issn = "1474-6670",
	doi = "https://doi.org/10.1016/S1474-6670(17)60614-1",
}

@article{Kokkala2015,
	title = "Sigma-Point Filtering and Smoothing Based Parameter Estimation in Nonlinear Dynamic Systems",
	author = "Juho Kokkala and Arno Solin and Simo S{\"a}rkk{\"a}",
	year = "2016",
	language = "English",
	volume = "11",
	pages = "15--30",
	journal = "JOURNAL OF ADVANCES IN INFORMATION FUSION",
	issn = "1557-6418",
	publisher = "Information Society of Information Fusion",
	number = "1",
}

@inproceedings{Sarkka2010,
	author = {Särkkä, Simo and Hartikainen, Jouni},
	year = {2010},
	pages = {184 - 189},
	title = {Sigma point methods in optimal smoothing of non-linear stochastic state space models},
	journal = {Proceedings of the 2010 IEEE International Workshop on Machine Learning for Signal Processing, MLSP 2010},
	doi = {10.1109/MLSP.2010.5589160}
}

@book{Cappe2005,
	author = {Capp\'{e}, Olivier and Moulines, Eric and Ryden, Tobias},
	title = {Inference in Hidden Markov Models (Springer Series in Statistics)},
	year = {2005},
	isbn = {0387402640},
	publisher = {Springer-Verlag},
	address = {Berlin, Heidelberg}
}

@article{Olsson2007,
	author = {Olsson, Rasmus Kongsgaard and Petersen, Kaare Brandt and Lehn-Schi\o{}ler, Tue},
	title = {State-Space Models: From the EM Algorithm to a Gradient Approach},
	year = {2007},
	issue_date = {April 2007},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA},
	volume = {19},
	number = {4},
	issn = {0899-7667},
	doi = {10.1162/neco.2007.19.4.1097},
	journal = {Neural Comput.},
	pages = {1097–1111},
	numpages = {15}
}

@article{DelMoral2010FW,
	author = {Del Moral, Pierre and Doucet, Arnaud and Singh, Sumeetpal},
	year = {2010},
	pages = {},
	title = {Forward Smoothing using Sequential Monte Carlo}
}

@article{Olsson2017,
	author = "Olsson, Jimmy and Westerborn, Johan",
	doi = "10.3150/16-BEJ801",
	fjournal = "Bernoulli",
	journal = "Bernoulli",
	number = "3",
	pages = "1951--1996",
	publisher = "Bernoulli Society for Mathematical Statistics and Probability",
	title = "Efficient particle-based online smoothing in general hidden Markov models: The PaRIS algorithm",
	volume = "23",
	year = "2017"
}

@ARTICLE{Zeitouni1988,
	author={O. {Zeitouni} and A. {Dembo}},
	journal={IEEE Transactions on Information Theory}, 
	title={Exact filters for the estimation of the number of transitions of finite-state continuous-time Markov processes}, 
	year={1988},
	volume={34},
	number={4},
	pages={890-893},
	doi={10.1109/18.9793}}

@article{Cappe2011,
	ISSN = {10618600},
	author = {Olivier Cappé},
	journal = {Journal of Computational and Graphical Statistics},
	number = {3},
	pages = {728--749},
	publisher = {[American Statistical Association, Taylor & Francis, Ltd., Institute of Mathematical Statistics, Interface Foundation of America]},
	title = {Online EM Algorithm for Hidden Markov Models},
	volume = {20},
	year = {2011}
}

@article{Briers2009,
	title = {Smoothing algorithms for state–space models},
	volume = {62},
	issn = {1572-9052},
	doi = {10.1007/s10463-009-0236-2},
	number = {1},
	journal = {Annals of the Institute of Statistical Mathematics},
	author = {Briers, Mark and Doucet, Arnaud and Maskell, Simon},
	year = {2009},
	pages = {61},
}

@inproceedings{Beal2001,
	title={The variational Kalman smoother},
	author={M. Beal and Zoubin Ghahramani},
	year={2001},
}

@article{Smidl2008,
	author={V. {Smidl} and A. {Quinn}},
	journal={IEEE Transactions on Signal Processing}, 
	title={Variational {B}ayesian Filtering}, 
	year={2008},
	volume={56},
	number={10},
	pages={5020-5030},
	doi={10.1109/TSP.2008.928969},
}

@article{Poyiadjis2011,
	title = {Particle approximations of the score and observed information matrix in state space models with application to parameter estimation},
	volume = {98},
	issn = {0006-3444},
	doi = {10.1093/biomet/asq062},
	number = {1},
	journal = {Biometrika},
	author = {Poyiadjis, George and Doucet, Arnaud and Singh, Sumeetpal S.},
	year = {2011},
	pages = {65--80},
}

@article{Godsill2004,
	author = {Simon J Godsill and Arnaud Doucet and Mike West},
	title = {Monte Carlo Smoothing for Nonlinear Time Series},
	journal = {Journal of the American Statistical Association},
	volume = {99},
	number = {465},
	pages = {156-168},
	year  = {2004},
	publisher = {Taylor & Francis},
	doi = {10.1198/016214504000000151},
}

@INPROCEEDINGS{Nielsen2010,
	author={Nielsen, Frank and Nock, Richard},
	booktitle={2010 IEEE International Conference on Image Processing}, 
	title={Entropies and cross-entropies of exponential families}, 
	year={2010},
	volume={},
	number={},
	pages={3621-3624},
	doi={10.1109/ICIP.2010.5652054},
}


@article{moore2016symvi,
	title     = {Symmetrized Variational Inference},
	author    = {David A. Moore},
	journal = {NIPS Workshop on Advances in Approximate {B}ayesian Inference},
	year      = {2016},
	month     = {December},
	address   = {Barcelona},
}

@inproceedings{orhan2018Skip,
	title={Skip Connections Eliminate Singularities},
	author={Emin Orhan and Xaq Pitkow},
	booktitle={ICLR},
	year={2018}
}

@inproceedings{pourzanjani2017identifiability,
	title={Improving the Identifiability of Neural Networks for {B}ayesian Inference},
	author={A. Pourzanjani and Richard M. Jiang and L. Petzold},
	booktitle={{B}ayesian Deep Learning NeurIPS workshop},
	year={2017}
}



@inproceedings{xing2003distance,
  title={Distance metric learning with application to clustering with side-information},
  author={Xing, Eric P and Jordan, Michael I and Russell, Stuart J and Ng, Andrew Y},
  booktitle={Advances in neural information processing systems (NIPS)},
  pages={521--528},
  year={2003}
}


@inproceedings{GershmanG14,
  author    = {Samuel Gershman and
               Noah D. Goodman},
  title     = {Amortized Inference in Probabilistic Reasoning},
  booktitle = {Proceedings of the 36th Annual Meeting of the Cognitive Science Society,
               CogSci 2014, Quebec City, Canada, July 23-26, 2014},
  year      = {2014},
  timestamp = {Thu, 14 Jul 2016 17:28:19 +0200},
  biburl    = {http://dblp.org/rec/bib/conf/cogsci/GershmanG14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}


@Article{Gelman2017PriorLikelihood,
AUTHOR = {Gelman, Andrew and Simpson, Daniel and Betancourt, Michael},
TITLE = {The Prior Can Often Only Be Understood in the Context of the Likelihood},
JOURNAL = {Entropy},
VOLUME = {19},
YEAR = {2017},
NUMBER = {10},
ARTICLE-NUMBER = {555},
ISSN = {1099-4300},
DOI = {10.3390/e19100555}
}


@inproceedings{Wang2021posterior,
title={Posterior Collapse and Latent Variable Non-identifiability},
author={Yixin Wang and John Patrick Cunningham},
booktitle={Third Symposium on Advances in Approximate {B}ayesian Inference},
year={2021},
}


@article{Nishihara2013DetectingPS,
  title={Detecting Parameter Symmetries in Probabilistic Models},
  author={Robert Nishihara and Thomas P. Minka and Daniel Tarlow},
  journal={arXiv: Machine Learning},
  year={2013}
}


@inproceedings{Coker2022WideMeanField,
  abbr = {AISTATS},
  bibtex_show = {true},
  title = {Wide Mean-Field Variational {B}ayesian Neural Networks Ignore the Data},
  booktitle = {Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS)},
  year = {2022},
  pdf = {https://arxiv.org/pdf/2202.11670.pdf},
  author = {Coker, Beau and Bruinsma, Wessel P. and Burt, David R. and Pan, Weiwei and Doshi-Velez, Finale}
}


@inproceedings{Kendall2017,
 author = {Kendall, Alex and Gal, Yarin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {What Uncertainties Do We Need in {B}ayesian Deep Learning for Computer Vision?},
 volume = {30},
 year = {2017}
}

@inproceedings{Nguyen2018VCL,
title={Variational Continual Learning},
author={Cuong V. Nguyen and Yingzhen Li and Thang D. Bui and Richard E. Turner},
booktitle={International Conference on Learning Representations},
year={2018},
}


@InProceedings{Ghosh2018Horseshoe,
  title = 	 {Structured Variational Learning of {B}ayesian Neural Networks with Horseshoe Priors},
  author =       {Ghosh, Soumya and Yao, Jiayu and Doshi-Velez, Finale},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1744--1753},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/ghosh18a/ghosh18a.pdf},
  abstract = 	 {{B}ayesian Neural Networks ({BNN}s) have recently received increasing attention for their ability to provide well-calibrated posterior uncertainties. However, model selection—even choosing the number of nodes—remains an open question. Recent work has proposed the use of a horseshoe prior over node pre-activations of a {B}ayesian neural network, which effectively turns off nodes that do not help explain the data. In this work, we propose several modeling and inference advances that consistently improve the compactness of the model learned while maintaining predictive performance, especially in smaller-sample settings including reinforcement learning.}
}

<<<<<<< HEAD

@inproceedings{Osawa2019,
 author = {Osawa, Kazuki and Swaroop, Siddharth and Khan, Mohammad Emtiyaz E and Jain, Anirudh and Eschenhagen, Runa and Turner, Richard E and Yokota, Rio},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Practical Deep Learning with {B}ayesian Principles},
 volume = {32},
 year = {2019}
}

@inproceedings{Farquhar2020Depth,
 author = {Farquhar, Sebastian and Smith, Lewis and Gal, Yarin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {4346--4357},
 publisher = {Curran Associates, Inc.},
 title = {Liberty or Depth: Deep {B}ayesian Neural Nets Do Not Need Complex Weight Posterior Approximations},
 volume = {33},
 year = {2020}
}


@inproceedings{Mishkin2018LowRankCov,
  author={Aaron Mishkin and Frederik Kunstner and Didrik Nielsen and Mark W. Schmidt and Mohammad Emtiyaz Khan},
  title={SLANG: Fast Structured Covariance Approximations for {B}ayesian Deep Learning with Natural Gradient},
  year={2018},
  cdate={1514764800000},
  pages={6248-6258},
  booktitle={NeurIPS},
}

@inproceedings{Tomczak2020LowRank,
 author = {Tomczak, Marcin and Swaroop, Siddharth and Turner, Richard},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {4610--4622},
 publisher = {Curran Associates, Inc.},
 title = {Efficient Low Rank Gaussian Variational Inference for Neural Networks},
 volume = {33},
 year = {2020}
}

@inproceedings{Dusenberry2020Rank1Factors,
author = {Dusenberry, Michael W. and Jerfel, Ghassen and Wen, Yeming and Ma, Yi-An and Snoek, Jasper and Heller, Katherine and Lakshminarayanan, Balaji and Tran, Dustin},
title = {Efficient and Scalable {B}ayesian Neural Nets with Rank-1 Factors},
year = {2020},
publisher = {JMLR.org},
abstract = {{B}ayesian neural networks ({BNN}s) demonstrate promising success in improving the robustness and uncertainty quantification of modern deep learning. However, they generally struggle with underfitting at scale and parameter efficiency. On the other hand, deep ensembles have emerged as alternatives for uncertainty quantification that, while outperforming {BNN}s on certain problems, also suffer from efficiency issues. It remains unclear how to combine the strengths of these two approaches and remediate their common issues. To tackle this challenge, we propose a rank-1 parameterization of {BNN}s, where each weight matrix involves only a distribution on a rank-1 subspace. We also revisit the use of mixture approximate posteriors to capture multiple modes, where unlike typical mixtures, this approach admits a significantly smaller memory increase (e.g., only a 0.4% increase for a ResNet-50 mixture of size 10). We perform a systematic empirical study on the choices of prior, variational posterior, and methods to improve training. For ResNet-50 on ImageNet, Wide ResNet 28-10 on CIFAR-10/100, and an RNN on MIMIC-III, rank-1 {BNN}s achieve state-of-the-art performance across log-likelihood, accuracy, and calibration on the test sets and out-of-distribution variants.},
booktitle = {Proceedings of the 37th International Conference on Machine Learning},
articleno = {261},
numpages = {11},
series = {ICML'20}
}

@inproceedings{Wang2021NonIdent,
 author = {Wang, Yixin and Blei, David and Cunningham, John P},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {5443--5455},
 publisher = {Curran Associates, Inc.},
 title = {Posterior Collapse and Latent Variable Non-identifiability},
 volume = {34},
 year = {2021}
}

@inproceedings{Wilson2022Bayesian,
 author = {Wilson, Andrew G and Izmailov, Pavel},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {4697--4708},
 publisher = {Curran Associates, Inc.},
 title = {Bayesian Deep Learning and a Probabilistic Perspective of Generalization},
 volume = {33},
 year = {2020}
}

@InProceedings{Wenzel2020How,
  title = 	 {How Good is the {B}ayes Posterior in Deep Neural Networks Really?},
  author =       {Wenzel, Florian and Roth, Kevin and Veeling, Bastiaan and Swiatkowski, Jakub and Tran, Linh and Mandt, Stephan and Snoek, Jasper and Salimans, Tim and Jenatton, Rodolphe and Nowozin, Sebastian},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {10248--10259},
  year = 	 {2020},
  editor = 	 {III, Hal Daumé and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/wenzel20a/wenzel20a.pdf},
  abstract = 	 {During the past five years the {B}ayesian deep learning community has developed increasingly accurate and efficient approximate inference procedures that allow for {B}ayesian inference in deep neural networks. However, despite this algorithmic progress and the promise of improved uncertainty quantification and sample efficiency there are—as of early 2020—no publicized deployments of {B}ayesian neural networks in industrial practice. In this work we cast doubt on the current understanding of {B}ayes posteriors in popular deep neural networks: we demonstrate through careful MCMC sampling that the posterior predictive induced by the {B}ayes posterior yields systematically worse predictions when compared to simpler methods including point estimates obtained from SGD. Furthermore, we demonstrate that predictive performance is improved significantly through the use of a “cold posterior” that overcounts evidence. Such cold posteriors sharply deviate from the {B}ayesian paradigm but are commonly used as heuristic in {B}ayesian deep learning papers. We put forward several hypotheses that could explain cold posteriors and evaluate the hypotheses through experiments. Our work questions the goal of accurate posterior approximations in {B}ayesian deep learning: If the true {B}ayes posterior is poor, what is the use of more accurate approximations? Instead, we argue that it is timely to focus on understanding the origin of cold posteriors.}
}


@InProceedings{Izmailov2021What,
  title = 	 {What Are {B}ayesian Neural Network Posteriors Really Like?},
  author =       {Izmailov, Pavel and Vikram, Sharad and Hoffman, Matthew D and Wilson, Andrew Gordon Gordon},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {4629--4640},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v139/izmailov21a/izmailov21a.pdf},
  abstract = 	 {The posterior over {B}ayesian neural network ({BNN}) parameters is extremely high-dimensional and non-convex. For computational reasons, researchers approximate this posterior using inexpensive mini-batch methods such as mean-field variational inference or stochastic-gradient Markov chain Monte Carlo (SGMCMC). To investigate foundational questions in {B}ayesian deep learning, we instead use full batch Hamiltonian Monte Carlo (HMC) on modern architectures. We show that (1) {BNN}s can achieve significant performance gains over standard training and deep ensembles; (2) a single long HMC chain can provide a comparable representation of the posterior to multiple shorter chains; (3) in contrast to recent studies, we find posterior tempering is not needed for near-optimal performance, with little evidence for a “cold posterior” effect, which we show is largely an artifact of data augmentation; (4) BMA performance is robust to the choice of prior scale, and relatively similar for diagonal Gaussian, mixture of Gaussian, and logistic priors; (5) {B}ayesian neural networks show surprisingly poor generalization under domain shift; (6) while cheaper alternatives such as deep ensembles and SGMCMC can provide good generalization, their predictive distributions are distinct from HMC. Notably, deep ensemble predictive distributions are similarly close to HMC as standard SGLD, and closer than standard variational inference.}
}

@article{Brea2019WeightspaceSI,
  title={Weight-space symmetry in deep networks gives rise to permutation saddles, connected by equal-loss valleys across the loss landscape},
  author={Johanni Brea and Berfin Simsek and Bernd Illing and Wulfram Gerstner},
  journal={ArXiv},
  year={2019},
  volume={abs/1907.02911}
}

@article{Sussmann1992Permutation,
title = {Uniqueness of the weights for minimal feedforward nets with a given input-output map},
journal = {Neural Networks},
volume = {5},
number = {4},
pages = {589-593},
year = {1992},
issn = {0893-6080},
doi = {https://doi.org/10.1016/S0893-6080(05)80037-1},
author = {Héctor J. Sussmann},
keywords = {Feedforward nets, Uniqueness, Symmetries},
abstract = {Abstract
We show that, for feedforward nets with a single hidden layer, a single output node, and a “transfer function” Tanh s, the net is uniquely determined by its input-output map, up to an obvious finite group of symmetries (permutations of the hidden nodes, and changing the sign of all the weights associated to a particular hidden node), provided that the net is irreducible (i.e., that there does not exist an inner node that makes a zero contribution to the output, and there is no pair of hidden nodes that could be collapsed to a single node without altering the inputoutput map).}
}


@article{Trippe2017,
 author = {Trippe, Brian and Turner, Richard},
 journal = {arXiv preprint arXiv:1801.06230},
 title = {Overpruning in variational {B}ayesian neural networks},
 year = {2018}
}

@book{herbrich2002learningkernelclassifiers,
    author = {Herbrich, Ralf},
    edition = {2nd edition},
    publisher = {The MIT Press},
    title = {Learning Kernel Classifiers: Theory and Algorithms},
    year = {2002}}

@article{Poirier1998revising,
  title={Revising beliefs in nonidentified models},
  author={Poirier, Dale J},
  journal={Econometric Theory},
  volume={14},
  number={4},
  pages={483--509},
  year={1998},
  publisher={Cambridge University Press}
}

@article{Dawid1979Conditional,
 ISSN = {00359246},
 abstract = {Some simple heuristic properties of conditional independence are shown to form a conceptual framework for much of the theory of statistical inference. This framework is illustrated by an examination of the role of conditional independence in several diverse areas of the field of statistics. Topics covered include sufficiency and ancillarity, parameter identification, causal inference, prediction sufficiency, data selection mechanisms, invariant statistical models and a subjectivist approach to model-building.},
 author = {A. P. Dawid},
 journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
 number = {1},
 pages = {1--31},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Conditional Independence in Statistical Theory},
 urldate = {2022-05-19},
 volume = {41},
 year = {1979}
}

@article{Gelfand1999identifiability,
  title={Identifiability, improper priors, and Gibbs sampling for generalized linear models},
  author={Gelfand, Alan E and Sahu, Sujit K},
  journal={Journal of the American Statistical Association},
  volume={94},
  number={445},
  pages={247--253},
  year={1999},
  publisher={Taylor \& Francis}
}

@book{Rao1992identifiability,
author = {Prakasa Rao, B. L. S.},
title = {Identifiability in Stochastic Models},
publisher = {Academic Press},
address = {Oxford},
year = {1992},
}

@article{wainwright2008graphical,
  title={Graphical models, exponential families, and variational inference},
  author={Wainwright, Martin J and Jordan, Michael I and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={1},
  number={1--2},
  pages={1--305},
  year={2008},
  publisher={Now Publishers, Inc.}
}

@InProceedings{AitchisonDKP,
  title =  {Deep Kernel Processes},
  author = {Aitchison, Laurence and Yang, Adam and Ober, Sebastian W},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {130--140},
  year = 	 {2021},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
}

@inproceedings{OberDKP,
 author = {Ober, Sebastian and Aitchison, Laurence},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {6567--6579},
 publisher = {Curran Associates, Inc.},
 title = {A variational approximate posterior for the deep Wishart process},
 volume = {34},
 year = {2021}
}


