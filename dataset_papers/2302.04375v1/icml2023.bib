


@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2137--2143},
  year={2020},
  organization={PMLR}
}

@inproceedings{he2022near,
  title={Near-optimal Policy Optimization Algorithms for Learning Adversarial Linear Mixture MDPs},
  author={He, Jiafan and Zhou, Dongruo and Gu, Quanquan},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={4259--4280},
  year={2022},
  organization={PMLR}
}

@inproceedings{jia2020model,
  title={Model-based reinforcement learning with value-targeted regression},
  author={Jia, Zeyu and Yang, Lin and Szepesvari, Csaba and Wang, Mengdi},
  booktitle={Learning for Dynamics and Control},
  pages={666--686},
  year={2020},
  organization={PMLR}
}

@inproceedings{zhou2021provably,
  title={Provably efficient reinforcement learning for discounted mdps with feature mapping},
  author={Zhou, Dongruo and He, Jiafan and Gu, Quanquan},
  booktitle={International Conference on Machine Learning},
  pages={12793--12802},
  year={2021},
  organization={PMLR}
}

@article{zhou2022computationally,
  title={Computationally Efficient Horizon-Free Reinforcement Learning for Linear Mixture MDPs},
  author={Zhou, Dongruo and Gu, Quanquan},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  year={2022}
}

@article{amani2019linear,
  title={Linear stochastic bandits under safety constraints},
  author={Amani, Sanae and Alizadeh, Mahnoosh and Thrampoulidis, Christos},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{pacchiano2021stochastic,
  title={Stochastic bandits with linear constraints},
  author={Pacchiano, Aldo and Ghavamzadeh, Mohammad and Bartlett, Peter and Jiang, Heinrich},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2827--2835},
  year={2021},
  organization={PMLR}
}

@inproceedings{amani2021safe,
  title={Safe reinforcement learning with linear function approximation},
  author={Amani, Sanae and Thrampoulidis, Christos and Yang, Lin},
  booktitle={International Conference on Machine Learning},
  pages={243--253},
  year={2021},
  organization={PMLR}
}

@inproceedings{wachi2018safe,
  title={Safe exploration and optimization of constrained mdps using gaussian processes},
  author={Wachi, Akifumi and Sui, Yanan and Yue, Yisong and Ono, Masahiro},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={32},
  year={2018}
}

@article{turchetta2016safe,
  title={Safe exploration in finite markov decision processes with gaussian processes},
  author={Turchetta, Matteo and Berkenkamp, Felix and Krause, Andreas},
  journal={Advances in Neural Information Processing Systems},
  volume={29},
  year={2016}
}

@inproceedings{shi2022stability,
  title={Stability constrained reinforcement learning for real-time voltage control},
  author={Shi, Yuanyuan and Qu, Guannan and Low, Steven and Anandkumar, Anima and Wierman, Adam},
  booktitle={2022 American Control Conference (ACC)},
  pages={2715--2721},
  year={2022},
  organization={IEEE}
}

@inproceedings{azar2017minimax,
  title={Minimax regret bounds for reinforcement learning},
  author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={263--272},
  year={2017},
  organization={PMLR}
}

@inproceedings{wu2016conservative,
  title={Conservative bandits},
  author={Wu, Yifan and Shariff, Roshan and Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  booktitle={International Conference on Machine Learning},
  pages={1254--1262},
  year={2016},
  organization={PMLR}
}

@inproceedings{achiam2017constrained,
  title={Constrained policy optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={22--31},
  year={2017},
  organization={PMLR}
}

@article{ghosh2022provably,
  title={Provably efficient model-free constrained rl with linear function approximation},
  author={Ghosh, Arnob and Zhou, Xingyu and Shroff, Ness},
  journal={arXiv preprint arXiv:2206.11889},
  year={2022}
}

@inproceedings{tessler2018reward,
  title={Reward Constrained Policy Optimization},
  author={Tessler, Chen and Mankowitz, Daniel J and Mannor, Shie},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{paternain2022safe,
  title={Safe policies for reinforcement learning via primal-dual methods},
  author={Paternain, Santiago and Calvo-Fullana, Miguel and Chamon, Luiz FO and Ribeiro, Alejandro},
  journal={IEEE Transactions on Automatic Control},
  year={2022},
  publisher={IEEE}
}

@inproceedings{yang2019projection,
  title={Projection-Based Constrained Policy Optimization},
  author={Yang, Tsung-Yen and Rosca, Justinian and Narasimhan, Karthik and Ramadge, Peter J},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{caramanis2014efficient,
  title={Efficient algorithms for budget-constrained Markov decision processes},
  author={Caramanis, Constantine and Dimitrov, Nedialko B and Morton, David P},
  journal={IEEE Transactions on Automatic Control},
  volume={59},
  number={10},
  pages={2813--2817},
  year={2014},
  publisher={IEEE}
}

@inproceedings{wu2018budget,
  title={Budget constrained bidding by model-free reinforcement learning in display advertising},
  author={Wu, Di and Chen, Xiujun and Yang, Xun and Wang, Hao and Tan, Qing and Zhang, Xiaoxun and Xu, Jian and Gai, Kun},
  booktitle={Proceedings of the 27th ACM International Conference on Information and Knowledge Management},
  pages={1443--1451},
  year={2018}
}

@article{agarwal2019reinforcement,
  title={Reinforcement learning: Theory and algorithms},
  author={Agarwal, Alekh and Jiang, Nan and Kakade, Sham M and Sun, Wen},
  journal={CS Dept., UW Seattle, Seattle, WA, USA, Tech. Rep},
  pages={10--4},
  year={2019}
}

@article{jin2018q,
  title={Is Q-learning provably efficient?},
  author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@book{vamvoudakis2021handbook,
  title={Handbook of Reinforcement Learning and Control},
  author={Vamvoudakis, Kyriakos G and Wan, Yan and Lewis, Frank L and Cansever, Derya},
  year={2021},
  publisher={Springer}
}

@article{efroni2020exploration,
  title={Exploration-exploitation in constrained mdps},
  author={Efroni, Yonathan and Mannor, Shie and Pirotta, Matteo},
  journal={arXiv preprint arXiv:2003.02189},
  year={2020}
}

@article{singh2020learning,
  title={Learning in Markov decision processes under constraints},
  author={Singh, Rahul and Gupta, Abhishek and Shroff, Ness B},
  journal={arXiv preprint arXiv:2002.12435},
  year={2020}
}

@article{brantley2020constrained,
  title={Constrained episodic reinforcement learning in concave-convex and knapsack settings},
  author={Brantley, Kiant{\'e} and Dudik, Miro and Lykouris, Thodoris and Miryoosefi, Sobhan and Simchowitz, Max and Slivkins, Aleksandrs and Sun, Wen},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={16315--16326},
  year={2020}
}

@inproceedings{kalagarla2021sample,
  title={A sample-efficient algorithm for episodic finite-horizon mdp with constraints},
  author={Kalagarla, Krishna C and Jain, Rahul and Nuzzo, Pierluigi},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  pages={8030--8037},
  year={2021}
}

@article{liu2021learning,
  title={Learning policies with zero or bounded constraint violation for constrained mdps},
  author={Liu, Tao and Zhou, Ruida and Kalathil, Dileep and Kumar, Panganamala and Tian, Chao},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={17183--17193},
  year={2021}
}

@inproceedings{ding2021provably,
  title={Provably efficient safe exploration via primal-dual policy optimization},
  author={Ding, Dongsheng and Wei, Xiaohan and Yang, Zhuoran and Wang, Zhaoran and Jovanovic, Mihailo},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3304--3312},
  year={2021},
  organization={PMLR}
}

@inproceedings{xu2021crpo,
  title={Crpo: A new approach for safe reinforcement learning with convergence guarantee},
  author={Xu, Tengyu and Liang, Yingbin and Lan, Guanghui},
  booktitle={International Conference on Machine Learning},
  pages={11480--11491},
  year={2021},
  organization={PMLR}
}

@article{ding2020natural,
  title={Natural policy gradient primal-dual method for constrained markov decision processes},
  author={Ding, Dongsheng and Zhang, Kaiqing and Basar, Tamer and Jovanovic, Mihailo},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={8378--8390},
  year={2020}
}

@inproceedings{bai2022achieving,
  title={Achieving zero constraint violation for constrained reinforcement learning via primal-dual approach},
  author={Bai, Qinbo and Bedi, Amrit Singh and Agarwal, Mridul and Koppel, Alec and Aggarwal, Vaneet},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  pages={3682--3689},
  year={2022}
}

@article{wei2021provably,
  title={A provably-efficient model-free algorithm for constrained markov decision processes},
  author={Wei, Honghao and Liu, Xin and Ying, Lei},
  journal={arXiv preprint arXiv:2106.01577},
  year={2021}
}

@article{abbasi2011improved,
  title={Improved algorithms for linear stochastic bandits},
  author={Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@inproceedings{zhou2021nearly,
  title={Nearly minimax optimal reinforcement learning for linear mixture markov decision processes},
  author={Zhou, Dongruo and Gu, Quanquan and Szepesvari, Csaba},
  booktitle={Conference on Learning Theory},
  pages={4532--4576},
  year={2021},
  organization={PMLR}
}

@article{kaufmann2016complexity,
  title={On the complexity of best-arm identification in multi-armed bandit models},
  author={Kaufmann, Emilie and Capp{\'e}, Olivier and Garivier, Aur{\'e}lien},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1--42},
  year={2016},
  publisher={JMLR. org}
}

@book{lattimore2020bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}

