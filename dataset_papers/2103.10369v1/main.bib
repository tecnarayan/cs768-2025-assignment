@article{dulac2019challenges,
  title={Challenges of real-world reinforcement learning},
  author={Dulac-Arnold, Gabriel and Mankowitz, Daniel and Hester, Todd},
  journal={arXiv preprint arXiv:1904.12901},
  year={2019}
}

@book{camacho2013model,
  title={Model predictive control},
  author={Camacho, Eduardo F and Alba, Carlos Bordons},
  year={2013},
  publisher={Springer science \& business media}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@inproceedings{lagoudakis2002value,
  title={Value function approximation in zero-sum {M}arkov games},
  author={Lagoudakis, Michail G and Parr, Ronald},
  booktitle={Conference on Uncertainty in artificial intelligence (UAI)},
  pages={283--292},
  year={2002}
}

@inproceedings{krause2011contextual,
  title={Contextual {G}aussian Process Bandit Optimization.},
  author={Krause, Andreas and Ong, Cheng Soon},
  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},
  pages={2447--2455},
  year={2011}
}

@inproceedings{pinto2017robust,
  title={Robust Adversarial Reinforcement Learning},
  author={Pinto, Lerrel and Davidson, James and Sukthankar, Rahul and Gupta, Abhinav},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={2817--2826},
  year={2017}
}

@inproceedings{bai2020provable,
  title={Provable self-play algorithms for competitive reinforcement learning},
  author={Bai, Yu and Jin, Chi},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={551--560},
  year={2020},
}

@article{zhang2020model,
  title={Model-Based Multi-Agent RL in Zero-Sum Markov Games with Near-Optimal Sample Complexity},
  author={Zhang, Kaiqing and Kakade, Sham and Basar, Tamer and Yang, Lin},
  journal={Conference on Neural Information Processing Systems (NeurIPS)},
  volume={33},
  year={2020}
}

@article{liu2020sharp,
  title={A Sharp Analysis of Model-based Reinforcement Learning with Self-Play},
  author={Liu, Qinghua and Yu, Tiancheng and Bai, Yu and Jin, Chi},
  journal={arXiv preprint arXiv:2010.01604},
  year={2020}
}

@article{daskalakis2020independent,
  title={Independent Policy Gradient Methods for Competitive Reinforcement Learning},
  author={Daskalakis, Constantinos and Foster, Dylan J and Golowich, Noah},
  journal={arXiv preprint arXiv:2101.04233},
  year={2020}
}

@inproceedings{mazumdar2020policy,
  title={Policy-Gradient Algorithms Have No Guarantees of Convergence in Linear Quadratic Games},
  author={Mazumdar, Eric and Ratliff, Lillian J and Jordan, Michael I and Sastry, S Shankar},
  booktitle={International Conference on Autonomous Agents and MultiAgent Systems},
  pages={860--868},
  year={2020}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015},
  organization={PMLR}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{van2016learning,
  title={Learning values across many orders of magnitude},
  author={van Hasselt, Hado and Guez, Arthur and Hessel, Matteo and Mnih, Volodymyr and Silver, David},
  journal={Conference on Neural Information Processing Systems (NeurIPS)},
  pages={4294--4302},
  year={2016}
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}


@inproceedings{tessler2019action,
  title={Action Robust Reinforcement Learning and Applications in Continuous Control},
  author={Tessler, Chen and Efroni, Yonathan and Mannor, Shie},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={6215--6224},
  year={2019}
}

@inproceedings{rajeswaran2016epopt,
  author={Rajeswaran, Aravind  and Ghotra, Sarvjeet and Ravindran, Balaraman and Levine, Sergey},
  title={EPOpt: Learning Robust Neural Network Policies Using Model Ensembles},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2017}
}

@inproceedings{gleave2020adversarial,
    title={Adversarial Policies: Attacking Deep Reinforcement Learning},
    author={Adam Gleave and Michael Dennis and Cody Wild and Neel Kant and Sergey Levine and Stuart Russell},
    booktitle={International Conference on Learning Representations (ICLR)},
    year={2020}
}

@inproceedings{pattanaik2018robust,
  title={Robust Deep Reinforcement Learning with adversarial attacks},
  author={Pattanaik, Anay and Tang, Zhenyi and Liu, Shuijing and Bommannan, Gautham and Chowdhary, Girish},
  booktitle={International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
  pages={2040--2042},
  year={2018}
}

@article{osband2016deep,
  title={Deep exploration via bootstrapped {DQN}},
  author={Osband, Ian and Blundell, Charles and Pritzel, Alexander and Roy, Benjamin Van},
  journal={Conference on Neural Information Processing Systems (NeurIPS)},
  pages={4033--4041},
  year={2016}
}

@article{kamalaruban2020robust,
  title={Robust Reinforcement Learning via Adversarial training with {L}angevin Dynamics},
  author={Kamalaruban, Parameswaran and Huang, Yu-Ting and Hsieh, Ya-Ping and Rolland, Paul and Shi, Cheng and Cevher, Volkan},
  journal={Conference on Neural Information Processing Systems (NeurIPS)},
  volume={33},
  year={2020}
}


@incollection{littman1994markov,
  title={Markov games as a framework for multi-agent reinforcement learning},
  author={Littman, Michael L},
  booktitle={Machine learning proceedings},
  pages={157--163},
  year={1994},
  publisher={Elsevier}
}

@inproceedings{littman1996generalized,
  title={A generalized reinforcement-learning model: Convergence and applications},
  author={Littman, Michael L and Szepesv{\'a}ri, Csaba},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={310--318},
  year={1996}
}

@incollection{bemporad1999robust,
  title={Robust model predictive control: A survey},
  author={Bemporad, Alberto and Morari, Manfred},
  booktitle={Robustness in identification and control},
  pages={207--226},
  year={1999},
  publisher={Springer}
}

@inproceedings{perolat2015approximate,
  title={Approximate dynamic programming for two-player zero-sum {M}arkov games},
  author={Perolat, Julien and Scherrer, Bruno and Piot, Bilal and Pietquin, Olivier},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={1321--1329},
  year={2015}
}

@article{vinitsky2020robust,
  title={Robust Reinforcement Learning using Adversarial Populations},
  author={Vinitsky, Eugene and Du, Yuqing and Parvate, Kanaad and Jang, Kathy and Abbeel, Pieter and Bayen, Alexandre},
  journal={arXiv preprint arXiv:2008.01825},
  year={2020}
}

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@inproceedings{srinivas2010gaussian,
  title={Gaussian process optimization in the bandit setting: no regret and experimental design},
  author={Srinivas, Niranjan and Krause, Andreas and Kakade, Sham and Seeger, Matthias},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={1015--1022},
  year={2010}
}
@article{iyengar2005robust,
  title={Robust dynamic programming},
  author={Iyengar, Garud N},
  journal={Mathematics of Operations Research},
  volume={30},
  number={2},
  pages={257--280},
  year={2005},
  publisher={INFORMS}
}
@article{nilim2005robust,
  title={Robust control of {M}arkov decision processes with uncertain transition matrices},
  author={Nilim, Arnab and El Ghaoui, Laurent},
  journal={Operations Research},
  volume={53},
  number={5},
  pages={780--798},
  year={2005},
  publisher={INFORMS}
}
@article{wiesemann2013robust,
  title={Robust {M}arkov decision processes},
  author={Wiesemann, Wolfram and Kuhn, Daniel and Rustem, Ber{\c{c}}},
  journal={Mathematics of Operations Research},
  volume={38},
  number={1},
  pages={153--183},
  year={2013},
  publisher={INFORMS}
}
@inproceedings{tamar2014scaling,
  title={Scaling up robust {MDP}s using function approximation},
  author={Tamar, Aviv and Mannor, Shie and Xu, Huan},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={181--189},
  year={2014}
}
@inproceedings{chow2015risk,
  title={Risk-sensitive and robust decision-making: a {CV}a{R} optimization approach},
  author={Chow, Yinlam and Tamar, Aviv and Mannor, Shie and Pavone, Marco},
  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},
  pages={1522--1530},
  year={2015}
}

@article{kakade2020information,
  title={Information Theoretic Regret Bounds for Online Nonlinear Control},
  author={Kakade, Sham and Krishnamurthy, Akshay and Lowrey, Kendall and Ohnishi, Motoya and Sun, Wen},
  journal={arXiv preprint arXiv:2006.12466},
  year={2020}
}

@inproceedings{kamthe2018data,
  title={Data-efficient reinforcement learning with probabilistic model predictive control},
  author={Kamthe, Sanket and Deisenroth, Marc},
  booktitle={Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={1701--1710},
  year={2018}
}

@article{desautels2014parallelizing,
  title={Parallelizing exploration-exploitation tradeoffs in {G}aussian process bandit optimization},
  author={Desautels, Thomas and Krause, Andreas and Burdick, Joel W},
  journal={Journal of Machine Learning Research (JMLR)},
  volume={15},
  pages={3873--3923},
  year={2014}
}

@inproceedings{chowdhury2017kernelized,
  title={On kernelized multi-armed bandits},
  author={Chowdhury, Sayak Ray and Gopalan, Aditya},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={844--853},
  year={2017}
}

@article{durand2018streaming,
  title={Streaming kernel regression with provably adaptive mean, variance, and regularization},
  author={Durand, Audrey and Maillard, Odalric-Ambrym and Pineau, Joelle},
  journal={The Journal of Machine Learning Research (JMLR)},
  volume={19},
  number={1},
  pages={650--683},
  year={2018}
}

@misc{rasmussen2005gaussian,
  title={Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning)},
  author={Rasmussen, Carl Edward and Williams, Christopher KI},
  year={2005},
  publisher={The MIT Press}
}

@inproceedings{girard2005gpssm,
 author = {Girard, Agathe and Rasmussen, Carl and Candela, Joaquin Qui\~{n}onero and Murray-Smith, Roderick},
 booktitle = {Conference on Neural Information Processing Systems (NeurIPS)},
 pages = {545--552},
 title = {Gaussian Process Priors with Uncertain Inputs Application to Multiple-Step Ahead Time Series Forecasting},
 year = {2003}
}

@inproceedings{malik2019calibrated,
  title={Calibrated model-based deep reinforcement learning},
  author={Malik, Ali and Kuleshov, Volodymyr and Song, Jiaming and Nemer, Danny and Seymour, Harlan and Ermon, Stefano},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={4314--4323},
  year={2019}
}

@inproceedings{chowdhury2019online,
  title={Online learning in kernelized {M}arkov decision processes},
  author={Chowdhury, Sayak Ray and Gopalan, Aditya},
  booktitle={Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={3197--3205},
  year={2019}
}
@article{neu2020unifying,
  title={A Unifying View of Optimism in Episodic Reinforcement Learning},
  author={Neu, Gergely and Pike-Burke, Ciara},
  journal={arXiv preprint arXiv:2007.01891},
  year={2020}
}

# Applications 
@inproceedings{peng2018sim,
  title={Sim-to-real transfer of robotic control with dynamics randomization},
  author={Peng, Xue Bin and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={IEEE international conference on robotics and automation (ICRA)},
  pages={1--8},
  year={2018},
  organization={IEEE}
}

@inproceedings{goodfellow15explaining,
title	= {Explaining and Harnessing Adversarial Examples},
author	= {Ian Goodfellow and Jonathon Shlens and Christian Szegedy},
year	= {2015},
booktitle	= {International Conference on Learning Representations (ICLR)}
}


# Provably robust
@inproceedings{bogunovic2018adversarially,
  title={Adversarially robust optimization with {G}aussian processes},
  author={Bogunovic, Ilija and Scarlett, Jonathan and Jegelka, Stefanie and Cevher, Volkan},
  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},
  pages={5760--5770},
  year={2018}
}

@inproceedings{kirschner2020distributionally,
  title={Distributionally Robust {B}ayesian Optimization},
  author={Kirschner, Johannes and Bogunovic, Ilija and Jegelka, Stefanie and Krause, Andreas},
  booktitle={Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={2174--2184},
  year={2020},
}

@article{curi2020efficient,
  title={Efficient Model-Based Reinforcement Learning through Optimistic Policy Search and Planning},
  author={Curi, Sebastian and Berkenkamp, Felix and Krause, Andreas},
  journal={Conference on Neural Information Processing Systems (NeurIPS)},
  volume={33},
  year={2020}
}


# MODEL BASED RL 
@article{der2009aleatory,
  title={Aleatory or epistemic? Does it matter?},
  author={Der Kiureghian, Armen and Ditlevsen, Ove},
  journal={Structural safety},
  volume={31},
  number={2},
  pages={105--112},
  year={2009},
  publisher={Elsevier}
}
@article{osband2019deep,
  title={Deep Exploration via Randomized Value Functions.},
  author={Osband, Ian and Van Roy, Benjamin and Russo, Daniel J and Wen, Zheng},
  journal={Journal of Machine Learning Research (JMLR)},
  volume={20},
  number={124},
  pages={1--62},
  year={2019}
}

@inproceedings{curi2020structured,
  title={Structured Variational Inference in Partially Observable Unstable Gaussian Process State Space Models},
  author={Curi, Sebastian and Melchior, Silvan and Berkenkamp, Felix and Krause, Andreas},
  booktitle={Learning for Dynamics and Control},
  pages={147--157},
  year={2020}
}

@article{brafman2002r,
  title={R-max-a general polynomial time algorithm for near-optimal reinforcement learning},
  author={Brafman, Ronen I and Tennenholtz, Moshe},
  journal={Journal of Machine Learning Research (JMLR)},
  volume={3},
  number={Oct},
  pages={213--231},
  year={2002}
} 

@inproceedings{auer2009near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Auer, Peter and Jaksch, Thomas and Ortner, Ronald},
  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},
  pages={89--96},
  year={2009}
}

@inproceedings{chua2018deep,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},
  pages={4754--4765},
  year={2018}
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={International Conference on machine learning (ICML)},
  pages={465--472},
  year={2011}
}

# Robust control 
@book{zhou1996robust,
  title={Robust and optimal control},
  author={Zhou, Kemin and Doyle, John Comstock and Glover, Keith and others},
  volume={40},
  year={1996},
  publisher={Prentice hall New Jersey}
}

@book{bacsar2008h,
  title={H-infinity optimal control and related minimax design problems: a dynamic game approach},
  author={Ba{\c{s}}ar, Tamer and Bernhard, Pierre},
  year={2008},
  publisher={Springer Science \& Business Media}
}

@article{bemporad2003min,
  title={Min-max control of constrained uncertain discrete-time linear systems},
  author={Bemporad, Alberto and Borrelli, Francesco and Morari, Manfred},
  journal={IEEE Transactions on automatic control},
  volume={48},
  number={9},
  pages={1600--1606},
  year={2003},
  publisher={IEEE}
}

@article{delage2010distributionally,
  title={Distributionally robust optimization under moment uncertainty with application to data-driven problems},
  author={Delage, Erick and Ye, Yinyu},
  journal={Operations research},
  volume={58},
  number={3},
  pages={595--612},
  year={2010},
  publisher={INFORMS}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@book{gumbel1948statistical,
  title={Statistical theory of extreme values and some practical applications: a series of lectures},
  author={Gumbel, Emil Julius},
  volume={33},
  year={1948},
  publisher={US Government Printing Office}
}

@article{maddison2016concrete,
  title={The concrete distribution: A continuous relaxation of discrete random variables},
  author={Maddison, Chris J and Mnih, Andriy and Teh, Yee Whye},
  journal={arXiv preprint arXiv:1611.00712},
  year={2016}
}

@inproceedings{tobin2017domain,
  title={Domain randomization for transferring deep neural networks from simulation to the real world},
  author={Tobin, Josh and Fong, Rachel and Ray, Alex and Schneider, Jonas and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={International Conference on Intelligent Robots and Systems (IROS)},
  pages={23--30},
  year={2017},
  organization={IEEE}
}

@article{french1999catastrophic,
  title={Catastrophic forgetting in connectionist networks},
  author={French, Robert M},
  journal={Trends in cognitive sciences},
  volume={3},
  number={4},
  pages={128--135},
  year={1999},
  publisher={Elsevier}
}

@inproceedings{haarnoja2018soft,
  title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={1861--1870},
  year={2018}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{silver2014deterministic,
  title={Deterministic Policy Gradient Algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={387--395},
  year={2014}
}

@inproceedings{antos2008fitted,
  title={Fitted {Q}-iteration in continuous action-space {MDP}s},
  author={Antos, Andr{\'a}s and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  booktitle={Conference on Neural Information Processing Systems (NeurIPS)},
  pages={9--16},
  year={2008}
}

@article{mohamed2019monte,
  title={Monte {C}arlo gradient estimation in machine learning},
  author={Mohamed, Shakir and Rosca, Mihaela and Figurnov, Michael and Mnih, Andriy},
  journal={arXiv preprint arXiv:1906.10652},
  year={2019}
}

@article{cover1991entropy,
  title={Entropy, relative entropy and mutual information},
  author={Cover, Thomas M and Thomas, Joy A},
  journal={Elements of information theory},
  volume={2},
  number={1},
  pages={12--13},
  year={1991},
  publisher={Wiley}
}

@inproceedings{valko2013finite,
  title={Finite-Time Analysis of Kernelised Contextual Bandits},
  author={Valko, Michal and Korda, Nathan and Munos, R{\'e}mi and Flaounas, Ilias and Cristianini, Nello},
  booktitle={Uncertainty in Artificial Intelligence (UAI)},
  pages={654},
  year={2013}
}