\begin{thebibliography}{33}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Agarwal(2013)]{agarwal2013selective}
Alekh Agarwal.
\newblock Selective sampling algorithms for cost-sensitive multiclass
  prediction.
\newblock In \emph{International Conference on Machine Learning}, pages
  1220--1228. PMLR, 2013.

\bibitem[Balcan and Long(2013)]{balcan2013active}
Maria-Florina Balcan and Phil Long.
\newblock Active and passive learning of linear separators under log-concave
  distributions.
\newblock In \emph{Conference on Learning Theory}, pages 288--316. PMLR, 2013.

\bibitem[Balcan et~al.(2007)Balcan, Broder, and Zhang]{balcan2007margin}
Maria-Florina Balcan, Andrei Broder, and Tong Zhang.
\newblock Margin based active learning.
\newblock In \emph{International Conference on Computational Learning Theory},
  pages 35--50. Springer, 2007.

\bibitem[Cavallanti et~al.(2011)Cavallanti, Cesa-Bianchi, and
  Gentile]{cavallanti2011learning}
Giovanni Cavallanti, Nicolo Cesa-Bianchi, and Claudio Gentile.
\newblock Learning noisy linear classifiers via adaptive and selective
  sampling.
\newblock \emph{Machine learning}, 83\penalty0 (1):\penalty0 71--102, 2011.

\bibitem[Cesa-Bianchi et~al.(2009)Cesa-Bianchi, Gentile, and
  Orabona]{cesa2009robust}
Nicolo Cesa-Bianchi, Claudio Gentile, and Francesco Orabona.
\newblock Robust bounds for classification via selective sampling.
\newblock In \emph{Proceedings of the 26th annual international conference on
  machine learning}, pages 121--128, 2009.

\bibitem[Crammer and Singer(2001)]{crammer2001algorithmic}
Koby Crammer and Yoram Singer.
\newblock On the algorithmic implementation of multiclass kernel-based vector
  machines.
\newblock \emph{Journal of machine learning research}, 2\penalty0
  (Dec):\penalty0 265--292, 2001.

\bibitem[Dasgupta et~al.(2005)Dasgupta, Kalai, and
  Monteleoni]{dasgupta2005analysis}
Sanjoy Dasgupta, Adam~Tauman Kalai, and Claire Monteleoni.
\newblock Analysis of perceptron-based active learning.
\newblock In \emph{International conference on computational learning theory},
  pages 249--263. Springer, 2005.

\bibitem[Dekel et~al.(2010)Dekel, Gentile, and Sridharan]{dekel2010robust}
Ofer Dekel, Claudio Gentile, and Karthik Sridharan.
\newblock Robust selective sampling from single and multiple teachers.
\newblock In \emph{COLT}, pages 346--358, 2010.

\bibitem[Hanneke et~al.(2014)]{hanneke2014theory}
Steve Hanneke et~al.
\newblock Theory of disagreement-based active learning.
\newblock \emph{Foundations and Trends{\textregistered} in Machine Learning},
  7\penalty0 (2-3):\penalty0 131--309, 2014.

\bibitem[Hofmann et~al.(2008)Hofmann, Sch{\"o}lkopf, and
  Smola]{hofmann2008kernel}
Thomas Hofmann, Bernhard Sch{\"o}lkopf, and Alexander~J Smola.
\newblock Kernel methods in machine learning.
\newblock \emph{The annals of statistics}, 36\penalty0 (3):\penalty0
  1171--1220, 2008.

\bibitem[Lewis and Gale(1994)]{lewis1994sequential}
David~D Lewis and William~A Gale.
\newblock A sequential algorithm for training text classifiers.
\newblock In \emph{SIGIRâ€™94}, pages 3--12. Springer, 1994.

\bibitem[Lughofer and Pratama(2017)]{lughofer2017online}
Edwin Lughofer and Mahardhika Pratama.
\newblock Online active learning in data stream regression using uncertainty
  sampling based on evolving generalized fuzzy models.
\newblock \emph{IEEE Transactions on fuzzy systems}, 26\penalty0 (1):\penalty0
  292--309, 2017.

\bibitem[Massart and N{\'e}d{\'e}lec(2006)]{massart2006risk}
Pascal Massart and {\'E}lodie N{\'e}d{\'e}lec.
\newblock Risk bounds for statistical learning.
\newblock \emph{The Annals of Statistics}, 34\penalty0 (5):\penalty0
  2326--2366, 2006.

\bibitem[Monarch(2021)]{monarch2021human}
Robert~Munro Monarch.
\newblock \emph{Human-in-the-Loop Machine Learning: Active learning and
  annotation for human-centered AI}.
\newblock Simon and Schuster, 2021.

\bibitem[Mussmann and Liang(2018)]{mussmann2018uncertainty}
Stephen Mussmann and Percy~S Liang.
\newblock Uncertainty sampling is preconditioned stochastic gradient descent on
  zero-one loss.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  6955--6964, 2018.

\bibitem[Nguyen et~al.(2021)Nguyen, Shaker, and
  H{\"u}llermeier]{nguyen2021measure}
Vu-Linh Nguyen, Mohammad~Hossein Shaker, and Eyke H{\"u}llermeier.
\newblock How to measure uncertainty in uncertainty sampling for active
  learning.
\newblock \emph{Machine Learning}, pages 1--34, 2021.

\bibitem[Orabona and Cesa-Bianchi(2011)]{orabona2011better}
Francesco Orabona and Nicolo Cesa-Bianchi.
\newblock Better algorithms for selective sampling.
\newblock In \emph{International conference on machine learning}, pages
  433--440. Omnipress, 2011.

\bibitem[Rahimi et~al.(2007)Rahimi, Recht, et~al.]{rahimi2007random}
Ali Rahimi, Benjamin Recht, et~al.
\newblock Random features for large-scale kernel machines.
\newblock In \emph{NIPS}, volume~3, page~5. Citeseer, 2007.

\bibitem[Roy and McCallum(2001)]{roy2001toward}
Nicholas Roy and Andrew McCallum.
\newblock Toward optimal active learning through monte carlo estimation of
  error reduction.
\newblock \emph{ICML, Williamstown}, 2:\penalty0 441--448, 2001.

\bibitem[Sabato and Hess(2016)]{sabato2016interactive}
Sivan Sabato and Tom Hess.
\newblock Interactive algorithms: from pool to stream.
\newblock In \emph{Conference on Learning Theory}, pages 1419--1439. PMLR,
  2016.

\bibitem[Schohn and Cohn(2000)]{schohn2000less}
Greg Schohn and David Cohn.
\newblock Less is more: Active learning with support vector machines.
\newblock In \emph{ICML}, volume~2, page~6. Citeseer, 2000.

\bibitem[Settles(2012)]{settles2012active}
Burr Settles.
\newblock Active learning: Synthesis lectures on artificial intelligence and
  machine learning.
\newblock \emph{Long Island, NY: Morgan \& Clay Pool}, 2012.

\bibitem[Settles et~al.(2007)Settles, Craven, and Ray]{settles2007multiple}
Burr Settles, Mark Craven, and Soumya Ray.
\newblock Multiple-instance active learning.
\newblock \emph{Advances in neural information processing systems},
  20:\penalty0 1289--1296, 2007.

\bibitem[Seung et~al.(1992)Seung, Opper, and Sompolinsky]{seung1992query}
H~Sebastian Seung, Manfred Opper, and Haim Sompolinsky.
\newblock Query by committee.
\newblock In \emph{Proceedings of the fifth annual workshop on Computational
  learning theory}, pages 287--294, 1992.

\bibitem[Tsochantaridis et~al.(2005)Tsochantaridis, Joachims, Hofmann, Altun,
  and Singer]{tsochantaridis2005large}
Ioannis Tsochantaridis, Thorsten Joachims, Thomas Hofmann, Yasemin Altun, and
  Yoram Singer.
\newblock Large margin methods for structured and interdependent output
  variables.
\newblock \emph{Journal of machine learning research}, 6\penalty0 (9), 2005.

\bibitem[Tsybakov(2004)]{tsybakov2004optimal}
Alexander~B Tsybakov.
\newblock Optimal aggregation of classifiers in statistical learning.
\newblock \emph{The Annals of Statistics}, 32\penalty0 (1):\penalty0 135--166,
  2004.

\bibitem[Vaswani et~al.(2018)Vaswani, Bach, and Schmidt]{vaswani2018fast}
Sharan Vaswani, Francis Bach, and Mark Schmidt.
\newblock Fast and faster convergence of {SGD} for over-parameterized models
  and an accelerated perceptron.
\newblock \emph{arXiv preprint arXiv:1810.07288}, 2018.

\bibitem[Wang et~al.(2017)Wang, Hwang, Rose, and Wallace]{wang2017uncertainty}
Gaoang Wang, Jenq-Neng Hwang, Craig Rose, and Farron Wallace.
\newblock Uncertainty sampling based active learning with diversity constraint
  by sparse selection.
\newblock In \emph{2017 IEEE 19th International Workshop on Multimedia Signal
  Processing (MMSP)}, pages 1--6. IEEE, 2017.

\bibitem[Wang et~al.(2015)Wang, Chow, and Kwong]{wang2015ambiguity}
Ran Wang, Chi-Yin Chow, and Sam Kwong.
\newblock Ambiguity-based multiclass active learning.
\newblock \emph{IEEE Transactions on Fuzzy Systems}, 24\penalty0 (1):\penalty0
  242--248, 2015.

\bibitem[Wang and Singh(2016)]{wang2016noise}
Yining Wang and Aarti Singh.
\newblock Noise-adaptive margin-based active learning and lower bounds under
  tsybakov noise condition.
\newblock In \emph{Thirtieth AAAI Conference on Artificial Intelligence}, 2016.

\bibitem[Yang and Loog(2016)]{yang2016active}
Yazhou Yang and Marco Loog.
\newblock Active learning using uncertainty information.
\newblock In \emph{2016 23rd International Conference on Pattern Recognition
  (ICPR)}, pages 2646--2651. IEEE, 2016.

\bibitem[Yang et~al.(2015)Yang, Ma, Nie, Chang, and Hauptmann]{yang2015multi}
Yi~Yang, Zhigang Ma, Feiping Nie, Xiaojun Chang, and Alexander~G Hauptmann.
\newblock Multi-class active learning by uncertainty sampling with diversity
  maximization.
\newblock \emph{International Journal of Computer Vision}, 113\penalty0
  (2):\penalty0 113--127, 2015.

\bibitem[Zhu et~al.(2008)Zhu, Wang, Yao, and Tsou]{zhu2008active}
Jingbo Zhu, Huizhen Wang, Tianshun Yao, and Benjamin~K Tsou.
\newblock Active learning with sampling by uncertainty and density for word
  sense disambiguation and text classification.
\newblock In \emph{Proceedings of the 22nd International Conference on
  Computational Linguistics (Coling 2008)}, pages 1137--1144, 2008.

\end{thebibliography}
