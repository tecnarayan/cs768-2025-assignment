\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }
\providecommand{\doi}[1]{https://doi.org/#1}

\bibitem{andriushchenko2020square}
Andriushchenko, M., Croce, F., Flammarion, N., Hein, M.: Square attack: a query-efficient black-box adversarial attack via random search. In: European Conference on Computer Vision. pp. 484--501. Springer (2020)

\bibitem{benz2021robustness}
Benz, P., Zhang, C., Karjauv, A., Kweon, I.S.: Robustness may be at odds with fairness: An empirical study on class-wise accuracy. In: NeurIPS 2020 Workshop on Pre-registration in Machine Learning. pp. 325--342. PMLR (2021)

\bibitem{carlini2017towards}
Carlini, N., Wagner, D.: Towards evaluating the robustness of neural networks. In: 2017 ieee symposium on security and privacy (sp). pp. 39--57. IEEE (2017)

\bibitem{croce2020minimally}
Croce, F., Hein, M.: Minimally distorted adversarial examples with a fast adaptive boundary attack. In: International Conference on Machine Learning. pp. 2196--2205. PMLR (2020)

\bibitem{croce2020reliable}
Croce, F., Hein, M.: Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks. In: International conference on machine learning. pp. 2206--2216. PMLR (2020)

\bibitem{girshick2015fast}
Girshick, R.: Fast r-cnn. In: Proceedings of the IEEE international conference on computer vision. pp. 1440--1448 (2015)

\bibitem{goldblum2020adversarially}
Goldblum, M., Fowl, L., Feizi, S., Goldstein, T.: Adversarially robust distillation. In: Proceedings of the AAAI Conference on Artificial Intelligence. vol.~34, pp. 3996--4003 (2020)

\bibitem{goodfellow2014explaining}
Goodfellow, I.J., Shlens, J., Szegedy, C.: Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572  (2014)

\bibitem{gowal2020uncovering}
Gowal, S., Qin, C., Uesato, J., Mann, T., Kohli, P.: Uncovering the limits of adversarial training against norm-bounded adversarial examples. arXiv preprint arXiv:2010.03593  (2020)

\bibitem{he2016deep}
He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 770--778 (2016)

\bibitem{hinton2015distilling}
Hinton, G., Vinyals, O., Dean, J., et~al.: Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531  \textbf{2}(7) (2015)

\bibitem{huang2023boosting}
Huang, B., Chen, M., Wang, Y., Lu, J., Cheng, M., Wang, W.: Boosting accuracy and robustness of student models via adaptive adversarial distillation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 24668--24677 (2023)

\bibitem{jia2022prior}
Jia, X., Zhang, Y., Wei, X., Wu, B., Ma, K., Wang, J., Cao, X.: Prior-guided adversarial initialization for fast adversarial training. In: European Conference on Computer Vision. pp. 567--584. Springer (2022)

\bibitem{jia2023improving}
Jia, X., Zhang, Y., Wei, X., Wu, B., Ma, K., Wang, J., Cao~Sr, X.: Improving fast adversarial training with prior-guided knowledge. arXiv preprint arXiv:2304.00202  (2023)

\bibitem{jia2022adversarial}
Jia, X., Zhang, Y., Wu, B., Ma, K., Wang, J., Cao, X.: Las-at: adversarial training with learnable attack strategy. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 13398--13408 (2022)

\bibitem{krizhevsky2009learning}
Krizhevsky, A., Hinton, G., et~al.: Learning multiple layers of features from tiny images  (2009)

\bibitem{le2015tiny}
Le, Y., Yang, X.: Tiny imagenet visual recognition challenge. CS 231N  \textbf{7}(7), ~3 (2015)

\bibitem{li2023wat}
Li, B., Liu, W.: Wat: improve the worst-class robustness in adversarial training. In: Proceedings of the AAAI Conference on Artificial Intelligence. vol.~37, pp. 14982--14990 (2023)

\bibitem{ma2022tradeoff}
Ma, X., Wang, Z., Liu, W.: On the tradeoff between robustness and fairness. Advances in Neural Information Processing Systems  \textbf{35},  26230--26241 (2022)

\bibitem{madry2017towards}
Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A.: Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083  (2017)

\bibitem{pang2020boosting}
Pang, T., Yang, X., Dong, Y., Xu, K., Zhu, J., Su, H.: Boosting adversarial training with hypersphere embedding. Advances in Neural Information Processing Systems  \textbf{33},  7779--7792 (2020)

\bibitem{rebuffi2021data}
Rebuffi, S.A., Gowal, S., Calian, D.A., Stimberg, F., Wiles, O., Mann, T.A.: Data augmentation can improve robustness. Advances in Neural Information Processing Systems  \textbf{34},  29935--29948 (2021)

\bibitem{rice2020overfitting}
Rice, L., Wong, E., Kolter, Z.: Overfitting in adversarially robust deep learning. In: International Conference on Machine Learning. pp. 8093--8104. PMLR (2020)

\bibitem{ronneberger2015u}
Ronneberger, O., Fischer, P., Brox, T.: U-net: Convolutional networks for biomedical image segmentation. In: Medical Image Computing and Computer-Assisted Intervention--MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18. pp. 234--241. Springer (2015)

\bibitem{ruan2023improving}
Ruan, S., Dong, Y., Su, H., Peng, J., Chen, N., Wei, X.: Improving viewpoint robustness for visual recognition via adversarial training. arXiv preprint arXiv:2307.11528  (2023)

\bibitem{sandler2018mobilenetv2}
Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.C.: Mobilenetv2: Inverted residuals and linear bottlenecks. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 4510--4520 (2018)

\bibitem{sehwag2021robust}
Sehwag, V., Mahloujifar, S., Handina, T., Dai, S., Xiang, C., Chiang, M., Mittal, P.: Robust learning meets generative models: Can proxy distributions improve adversarial robustness? arXiv preprint arXiv:2104.09425  (2021)

\bibitem{sun2023improving}
Sun, C., Xu, C., Yao, C., Liang, S., Wu, Y., Liang, D., Liu, X., Liu, A.: Improving robust fariness via balance adversarial training. In: Proceedings of the AAAI Conference on Artificial Intelligence. vol.~37, pp. 15161--15169 (2023)

\bibitem{szegedy2016rethinking}
Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z.: Rethinking the inception architecture for computer vision. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 2818--2826 (2016)

\bibitem{szegedy2013intriguing}
Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R.: Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199  (2013)

\bibitem{tian2021analysis}
Tian, Q., Kuang, K., Jiang, K., Wu, F., Wang, Y.: Analysis and applications of class-wise robustness in adversarial training. In: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining. pp. 1561--1570 (2021)

\bibitem{wang2019improving}
Wang, Y., Zou, D., Yi, J., Bailey, J., Ma, X., Gu, Q.: Improving adversarial robustness requires revisiting misclassified examples. In: International Conference on Learning Representations (2019)

\bibitem{wei2022adversarial}
Wei, X., Guo, Y., Yu, J.: Adversarial sticker: A stealthy attack method in the physical world. IEEE Transactions on Pattern Analysis and Machine Intelligence  (2022)

\bibitem{wei2022simultaneously}
Wei, X., Guo, Y., Yu, J., Zhang, B.: Simultaneously optimizing perturbations and positions for black-box adversarial patch attacks. IEEE Transactions on Pattern Analysis and Machine Intelligence  (2022)

\bibitem{xingxing2023efficient}
Wei, X., Wang, S., Yan, H.: Efficient robustness assessment via adversarial spatial-temporal focus on videos. IEEE Transactions on Pattern Analysis and Machine Intelligence  (2023)

\bibitem{wei2023cfa}
Wei, Z., Wang, Y., Guo, Y., Wang, Y.: Cfa: Class-wise calibrated fair adversarial training. In: CVPR. pp. 8193--8201 (2023)

\bibitem{wu2021understanding}
Wu, Z., Gao, H., Zhang, S., Gao, Y.: Understanding the robustness-accuracy tradeoff by rethinking robust fairness  (2021)

\bibitem{Yue2023Revisiting}
Xinli, Y., Mou, N., Qian, W., Lingchen, Z.: Revisiting adversarial robustness distillation from the perspective of robust fairness. NeurIPS  (2023)

\bibitem{xu2021robust}
Xu, H., Liu, X., Li, Y., Jain, A., Tang, J.: To be robust or to be fair: Towards fairness in adversarial training. In: International conference on machine learning. pp. 11492--11501. PMLR (2021)

\bibitem{zagoruyko2016wide}
Zagoruyko, S., Komodakis, N.: Wide residual networks. arXiv preprint arXiv:1605.07146  (2016)

\bibitem{zhang2019theoretically}
Zhang, H., Yu, Y., Jiao, J., Xing, E., El~Ghaoui, L., Jordan, M.: Theoretically principled trade-off between robustness and accuracy. In: International conference on machine learning. pp. 7472--7482. PMLR (2019)

\bibitem{zhao2023mitigating}
Zhao, S., Wang, X., Wei, X.: Mitigating the accuracy-robustness trade-off via multi-teacher adversarial distillation. arXiv preprint arXiv:2306.16170  (2023)

\bibitem{zhao2022enhanced}
Zhao, S., Yu, J., Sun, Z., Zhang, B., Wei, X.: Enhanced accuracy and robustness via multi-teacher adversarial distillation. In: Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part IV. pp. 585--602. Springer (2022)

\bibitem{zhu2021reliable}
Zhu, J., Yao, J., Han, B., Zhang, J., Liu, T., Niu, G., Zhou, J., Xu, J., Yang, H.: Reliable adversarial distillation with unreliable teachers. arXiv preprint arXiv:2106.04928  (2021)

\bibitem{zi2021revisiting}
Zi, B., Zhao, S., Ma, X., Jiang, Y.G.: Revisiting adversarial robustness distillation: Robust soft labels make student better. In: International Conference on Computer Vision (2021)

\end{thebibliography}
