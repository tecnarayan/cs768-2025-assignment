@article{chi2018randomized,
  title={Randomized least squares regression: Combining model-and algorithm-induced uncertainties},
  author={Chi, Jocelyn T and Ipsen, Ilse CF},
  journal={Tehnical Report},
  volume={1},
  pages={34},
  year={2018}
}

@article{cockayne2021probabilistic,
  title={Probabilistic iterative methods for linear systems},
  author={Cockayne, Jon and Ipsen, Ilse CF and Oates, Chris J and Reid, Tim W},
  journal={The Journal of Machine Learning Research},
  volume={22},
  number={1},
  pages={10505--10538},
  year={2021},
  publisher={JMLRORG}
}


@article{bartels2019probabilistic,
  title={Probabilistic linear solvers: a unifying view},
  author={Bartels, Simon and Cockayne, Jon and Ipsen, Ilse CF and Hennig, Philipp},
  journal={Statistics and Computing},
  volume={29},
  pages={1249--1263},
  year={2019},
  publisher={Springer}
}
@inproceedings{bach2013sharp,
  title={Sharp analysis of low-rank kernel matrix approximations},
  author={Bach, Francis},
  booktitle={Conference on learning theory},
  pages={185--209},
  year={2013},
  organization={PMLR}
}

@inproceedings{zhang2013divide,
  title={Divide and conquer kernel ridge regression},
  author={Zhang, Yuchen and Duchi, John and Wainwright, Martin},
  booktitle={Conference on learning theory},
  pages={592--617},
  year={2013},
  organization={PMLR}
}
@article{rokhlin2008fast,
  title={A fast randomized algorithm for overdetermined linear least-squares regression},
  author={Rokhlin, Vladimir and Tygert, Mark},
  journal={Proceedings of the National Academy of Sciences},
  volume={105},
  number={36},
  pages={13212--13217},
  year={2008},
  publisher={National Acad Sciences}
}

@article{lacotte2019faster,
  title={Faster least squares optimization},
  author={Lacotte, Jonathan and Pilanci, Mert},
  journal={arXiv preprint arXiv:1911.02675},
  year={2019}
}

@article{derezinski2022sharp,
  title={Sharp Analysis of Sketch-and-Project Methods via a Connection to Randomized Singular Value Decomposition},
  author={Derezi{\'n}ski, Micha{\l} and Rebrova, Elizaveta},
  journal={arXiv preprint arXiv:2208.09585},
  year={2022}
}

@article{hessian-averaging,
  title={Hessian Averaging in Stochastic Newton Methods Achieves Superlinear Convergence},
  author={Na, Sen and Derezi{\'n}ski, Micha{\l} and Mahoney, Michael W},
  journal={arXiv preprint arXiv:2204.09266},
  year={2022},
 note={Accepted for publication, Mathematical Programming.}
}

@inproceedings{gupta2021localnewton,
  title={LocalNewton: Reducing communication rounds for distributed learning},
  author={Gupta, Vipul and Ghosh, Avishek and Derezi{\'n}ski, Micha{\l} and Khanna, Rajiv and Ramchandran, Kannan and Mahoney, Michael W},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={632--642},
  year={2021},
  organization={PMLR}
}
@InProceedings{bet,
  title = 	 {Batch-Expansion Training: An Efficient Optimization Framework},
  author = 	 {Micha{\l} Derezi\'{n}ski and Dhruv Mahajan and S. Sathiya Keerthi and S. V. N. Vishwanathan and Markus Weimer},
  booktitle = 	 {Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics},
  pages = 	 {736--744},
  year = 	 {2018},
}

@BOOK{ChatterjeeHadi88,
  author =       {S.~Chatterjee and A.S.~Hadi},
  title =        {Sensitivity Analysis in Linear Regression},
  publisher =    {John Wiley {\&} Sons},
  year =         {1988},
  address =      {New York},
  series =       {},
}

@inproceedings{lopes2018error,
  title={Error estimation for randomized least-squares algorithms via the bootstrap},
  author={Lopes, Miles and Wang, Shusen and Mahoney, Michael},
  booktitle={International Conference on Machine Learning},
  pages={3217--3226},
  year={2018},
  organization={PMLR}
}

@article{lopes2023bootstrapping,
  title={Bootstrapping the operator norm in high dimensions: Error estimation for covariance matrices and sketching},
  author={Lopes, Miles E and Erichson, N Benjamin and Mahoney, Michael W},
  journal={Bernoulli},
  volume={29},
  number={1},
  pages={428--450},
  year={2023},
  publisher={Bernoulli Society for Mathematical Statistics and Probability}
}

@inproceedings{derezinski2023solving,
  title={Solving Dense Linear Systems Faster than via Preconditioning},
  author={Derezi{\'n}ski, Micha{\l} and Yang, Jiaming},
  booktitle={56th Annual ACM Symposium on Theory of Computing},
  year={2024}
}

@article{ma2022asymptotic,
  title={Asymptotic analysis of sampling estimators for randomized numerical linear algebra algorithms},
  author={Ma, Ping and Chen, Yongkai and Zhang, Xinlian and Xing, Xin and Ma, Jingyi and Mahoney, Michael W},
  journal={The Journal of Machine Learning Research},
  volume={23},
  number={1},
  pages={7970--8014},
  year={2022},
  publisher={JMLRORG}
}

@article{lacotte2022adaptive,
  title={Adaptive and oblivious randomized subspace methods for high-dimensional optimization: Sharp analysis and lower bounds},
  author={Lacotte, Jonathan and Pilanci, Mert},
  journal={IEEE Transactions on Information Theory},
  volume={68},
  number={5},
  pages={3281--3303},
  year={2022},
  publisher={IEEE}
}

@article{lacotte2020optimal,
  title={Optimal iterative sketching methods with the subsampled randomized {H}adamard transform},
  author={Lacotte, Jonathan and Liu, Sifan and Dobriban, Edgar and Pilanci, Mert},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9725--9735},
  year={2020}
}

@TECHREPORT{KLS18_TR,
  author =       {D. Kobak and J. Lomond and B. Sanchez},
  title =        {Optimal ridge penalty for real-world high-dimensional data can be zero or negative due to the implicit ridge regularization},
  note =         {Preprint: arXiv:1805.10939},
  year =         {2018},
}

@article{DobLiu18_TR,
  title={Asymptotics for sketching in least squares regression},
  author={Dobriban, Edgar and Liu, Sifan},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{lejeune2022asymptotics,
  title={Asymptotics of the sketched pseudoinverse},
  author={LeJeune, Daniel and Patil, Pratik and Javadi, Hamid and Baraniuk, Richard G and Tibshirani, Ryan J},
  journal={arXiv preprint arXiv:2211.03751},
  year={2022}
}

@ARTICLE{GarveshMahoney_JMLR,
  author =       {G. Raskutti and M. W. Mahoney}, 
  title =        {A Statistical Perspective on Randomized Sketching for Ordinary Least-Squares},
  journal =      {Journal of Machine Learning Research},
  year =         {2016},
  volume =       {17},
  number =       {214},
  pages =        {1--31},
}

@ARTICLE{BO00,
   author  = {A. Borodin and G. Olshanski}, 
   title   = {Distributions on Partitions, Point Processes, and the Hypergeometric Kernel},
   journal = {Communications in Mathematical Physics},
   year    = {2000},
   volume  = {211}, 
   number  = {2}, 
   pages   = {335--358},
}

@INCOLLECTION{Bor11,
  author =       {A. Borodin},
  title =        {Determinantal point processes},
  booktitle =    {Oxford handbook of random matrix theory},
  year =         {2011},
  pages =        {231--249},
  series =       {},
  publisher =    {Oxford University Press},
}

@article{tropp2011improved,
  title={Improved analysis of the subsampled randomized {H}adamard transform},
  author={Tropp, Joel A},
  journal={Advances in Adaptive Data Analysis},
  volume={3},
  number={01n02},
  pages={115--126},
  year={2011},
  publisher={World Scientific}
}

@BOOK{Mah-mat-rev_BOOK,
  author =       {M.~W.~Mahoney},
  title =        {Randomized algorithms for matrices and data},
  publisher =    {NOW Publishers},
  year =         {2011},
  address =      {Boston},
  series =       {Foundations and Trends in Machine Learning},
}

@ARTICLE{DM16_CACM,
  author =       {P.~Drineas and M.~W.~Mahoney},
  title =        {{RandNLA}: Randomized Numerical Linear Algebra},
  journal =      {Communications of the ACM},
  year =         {2016},
  volume =       {59},
  number =       {},
  pages =        {80--90},
}

@INCOLLECTION{MD16_chapter,
  author =       {M.~W.~Mahoney and P.~Drineas},
  title =        {Structural properties underlying high-quality Randomized Numerical Linear Algebra algorithms},
  booktitle =    {Handbook of Big Data},
  year =         {2016},
  pages =        {137--154},
  series =       {},
  publisher =    {CRC Press},
}

@INCOLLECTION{RandNLA_PCMIchapter_chapter,
  author =       {P. Drineas and M. W. Mahoney},
  title =        {Lectures on Randomized Numerical Linear Algebra},
  booktitle =    {The Mathematics of Data},
  year =         {2018},
  pages =        {1--48},
  series =       {IAS/Park City Mathematics Series},
  publisher =    {AMS/IAS/SIAM},
}

@ARTICLE{KV17_acta,
  author =       {R.~Kannan and S.~Vempala},
  title =        {Randomized algorithms in numerical linear algebra},
  journal =      {Acta Mathematica},
  year =         {2017},
  volume =       {26},
  number =       {},
  pages =        {95--135},
}

@INPROCEEDINGS{NN13,
  author =       {J.~Nelson and H. L. Nguyen},
  title =        {{OSNAP}: Faster numerical linear algebra algorithms via sparser subspace embeddings},
  booktitle =    {Proceedings of the 54th Annual IEEE Symposium on Foundations of Computer Science},
  year =         {2013},
  pages =        {117--126},
}

@article{gautier2018dppy,
abstract = {Determinantal point processes (DPPs) are specific probability distributions over clouds of points that are used as models and computational tools across physics, probability, statistics, and more recently machine learning. Sampling from DPPs is a challenge and therefore we present DPPy, a Python toolbox that gathers known exact and approximate sampling algorithms. The project is hosted on GitHub and equipped with an extensive documentation. This documentation takes the form of a short survey of DPPs and relates each mathematical property with DPPy objects.},
author = {Gautier, Guillaume and Bardenet, R{\'{e}}mi and Valko, Michal},
title = {{DPPy: Sampling determinantal point processes with Python}},
year = {2018},
journal = {https://arxiv.org/abs/1809.07258}
}



@article{diaconis1991geometric,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
author = {Diaconis, Persi and Stroock, Daniel},
doi = {10.1214/aoap/1177005980},
issn = {1050-5164},
journal = {The Annals of Applied Probability},
title = {{Geometric Bounds for Eigenvalues of Markov Chains}},
year = {1991}
}


@inproceedings{erraqabi2016pliable,
abstract = {Rejection sampling is a known technique for sampling from difficult distributions. However, its use is limited due to a high rejection rate. Common adaptive rejection sampling methods either work for very specific distributions or without performance guarantees. In this paper, we present pliable rejection sampling (PRS), a new approach to rejection sampling, where we adapt the sampling envelope using a kernel estimator. Since our method builds on rejection sampling, the samples obtained are i.i.d. and exactly distributed according to f. Another benefit of PRS is that it comes with a guarantee on the number of accepted samples.},
author = {Erraqabi, Akram and Valko, Michal and Carpentier, Alexandra and Maillard, Odalric-Ambrym},
booktitle = {International Conference on Machine Learning},
file = {:Users/valkom/Library/Application Support/Mendeley Desktop/Downloaded/Erraqabi et al. - 2016 - Pliable rejection sampling.pdf:pdf},
title = {{Pliable rejection sampling}},
year = {2016}
}



@article{metropolis1949monte,
abstract = {Abstract We shall present here the motivation and a general description of a method dealing with a class of problems in mathematical physics. The method is, essentially, a statistical approach to the study of differential equations, or more generally, of integro-differential equations that occur in various branches of the natural sciences. Abstract We shall present here the motivation and a general description of a method dealing with a class of problems in mathematical physics. The method is, essentially, a statistical approach to the study of differential equations, or more generally, of integro-differential equations that occur in various branches of the natural sciences.},
author = {Metropolis, Nicholas and Ulam, S.},
journal = {Journal of the American Statistical Association},
number = {247},
pages = {335--341},
title = {{The Monte Carlo method}},
volume = {44},
year = {1949}
}

@article{fill1998interruptible,
abstract = {For a large class of examples arising in statistical physics known as attractive spin systems (e.g., the Ising model), one seeks to sample from a probability distribution $\pi$ on an enormously large state space, but elementary sampling is ruled out by the infeasibility of calculating an appropriate normalizing constant. The same difficulty arises in computer science problems where one seeks to sample randomly from a large finite distributive lattice whose precise size cannot be ascertained in any reasonable amount of time. The Markov chain Monte Carlo (MCMC) approximate sampling approach to such a problem is to construct and run "for a long time" a Markov chain with long-run distribution $\pi$. But determining how long is long enough to get a good approximation can be both analytically and empirically difficult. Recently, Propp and Wilson have devised an ingenious and efficient algorithm to use the same Markov chains to produce perfect (i.e., exact) samples from $\pi$. However, the running time of their algorithm is an unbounded random variable whose order of magnitude is typically unknown a priori and which is not independent of the state sampled, so a naive user with limited patience who aborts a long run of the algorithm will introduce bias. We present a new algorithm which (1) again uses the same Markov chains to produce perfect samples from $\pi$, but is based on a different idea (namely, acceptance/rejection sampling); and (2) eliminates user-impatience bias. Like the Propp-Wilson algorithm, the new algorithm applies to a general class of suitably monotone chains, and also (with modification) to "anti-monotone" chains. When the chain is reversible, naive implementation of the algorithm uses fewer transitions but more space than Propp-Wilson. When fine-tuned and applied with the aid of a typical pseudorandom number generator to an attractive spin system on n sites using a random site updating Gibbs sampler whose mixing time $\tau$ is polynomial in n, the algorithm runs in time of the same order (bound) as Propp-Wilson [expectation O($\tau$ log n)] and uses only logarithmically more space [expectation O(n log n), vs. O(n) for Propp-Wilson].},
author = {Fill, James Allen},
journal = {Annals of Applied Probability},
keywords = {Attractive spin system,Duality,Gibbs sampler,Ising model,Markov chain Monte Carlo,Monotone chain,Partially ordered set,Perfect simulation,Rejection sampling,Separation,Strong stationary time},
number = {1},
pages = {131--162},
title = {{An interruptible algorithm for perfect sampling via Markov chains}},
volume = {8},
year = {1998}
}

@article{andrieu2003introduction,
abstract = {This purpose of this introductory paper is threefold. First, it introduces the Monte Carlo method with emphasis on probabilistic machine learning. Second, it reviews the main building blocks of modern Markov chain Monte Carlo simulation, thereby providing and introduction to the remaining papers of this special issue. Lastly, it discusses new interesting research horizons.},
author = {Andrieu, Christophe and {De Freitas}, Nando and Doucet, Arnaud and Jordan, Michael I.},
journal = {Machine Learning},
keywords = {MCMC,Markov chain Monte Carlo,Sampling,Stochastic algorithms},
number = {1-2},
pages = {5--43},
title = {{An introduction to MCMC for machine learning}},
volume = {50},
year = {2003}
}

@inproceedings{propp1998coupling,
abstract = {The Markov chain Monte Carlo method is a general technique for obtaining samples from a probability distribution. In earlier work, we showed that for many applications one can modify the Markov chain Monte Carlo method so as to remove all bias in the output resulting from the biased choice of an initial state for the chain; we have called this method coupling from the past (CFTP). Here we describe this method in a fashion that should make our ideas accessible to researchers from diverse areas. Our expository strategy is to avoid proofs and focus on sample applications.},
author = {Propp, James and Wilson, David},
booktitle = {Microsurveys in Discrete Probability},
title = {{Coupling from the oast: A user's guide}},
year = {1998}
}


@article{poulson2019high-performance,
abstract = {Determinantal Point Processes (DPPs) were introduced by Mac-chi [1] as a model for repulsive (fermionic) particle distributions. But their recent popularization is largely due to their usefulness for encouraging diversity in the final stage of a recommender system [2]. The standard sampling scheme for finite DPPs is a spectral decomposition followed by an equivalent of a randomly diagonally-pivoted Cholesky factorization of an orthogonal projection, which is only applicable to Hermitian kernels and has an expensive setup cost. Researchers have begun to connect DPP sampling to LDL H factoriza-tions as a means of avoiding the initial spectral decomposition, but existing approaches have only outperformed the spectral decomposition approach in special circumstances, where the number of kept modes is a small percentage of the ground set size. This article proves that trivial modifications of LU and LDL H fac-torizations yield efficient direct sampling schemes for non-Hermitian and Hermitian DPP kernels, respectively. Further, it is experimentally shown that even dynamically-scheduled, shared-memory paralleliza-tions of high-performance dense and sparse-direct factorizations can be trivially modified to yield DPP sampling schemes with essentially identical performance. The software developed as part of this research, Catamari [hodges-tar.com/catamari] is released under the Mozilla Public License v2.0. It contains header-only, C++14 plus OpenMP 4.0 implementations of dense and sparse-direct, Hermitian and non-Hermitian DPP samplers. * jack@hodgestar.com, Hodge Star Scientific Computing},
archivePrefix = {arXiv},
arxivId = {1905.00165v1},
author = {Poulson, Jack},
eprint = {1905.00165v1},
volume    = {ArXive:1905.00165v1},
title = {{High-performance sampling of generic determinantal point processes}},
url = {https://arxiv.org/pdf/1905.00165.pdf},
year = {2019}
}



@inproceedings{gautier2017zonotope,
abstract = {Determinantal point processes (DPPs) are distributions over sets of items that model diversity using kernels. Their applications in machine learning include summary extraction and recommendation systems. Yet, the cost of sampling from a DPP is prohibitive in large-scale applications, which has triggered an effort towards efficient approximate samplers. We build a novel MCMC sampler that combines ideas from combinatorial geometry, linear programming, and Monte Carlo methods to sample from DPPs with a fixed sample cardinality, also called projection DPPs. Our sampler leverages the ability of the hit-and-run MCMC kernel to efficiently move across convex bodies. Previous theoretical results yield a fast mixing time of our chain when targeting a distribution that is close to a projection DPP, but not a DPP in general. Our empirical results demonstrate that this extends to sampling projection DPPs, i.e., our sampler is more sample-efficient than previous approaches which in turn translates to faster convergence when dealing with costly-to-evaluate functions, such as summary extraction in our experiments.},
author = {Gautier, Guillaume and Bardenet, R{\'{e}}mi and Valko, Michal},
booktitle = {International Conference on Machine Learning},
title = {{Zonotope hit-and-run for efficient sampling from projection DPPs}},
year = {2017}
}

@inproceedings{ReKa15,
	Author = {Rebeschini, P and Karbasi, A},
	Booktitle = {Conference on Learning Theory},
	Pages = {1480--1500},
	Title = {Fast Mixing for Discrete Point Processes.},
	Year = {2015}}

@article{hoeffding1956distribution,
  title={On the distribution of the number of successes in independent trials},
  author={Hoeffding, Wassily and others},
  journal={The Annals of Mathematical Statistics},
  volume={27},
  number={3},
  pages={713--721},
  year={1956},
  publisher={Institute of Mathematical Statistics}
}

@article{darroch1964distribution,
  title={On the distribution of the number of successes in independent trials},
  author={Darroch, John N and others},
  journal={The Annals of Mathematical Statistics},
  volume={35},
  number={3},
  pages={1317--1321},
  year={1964},
  publisher={Institute of Mathematical Statistics}
}

@inproceedings{calandriello_disqueak_2017,
	Author = {Calandriello, Daniele and Lazaric, Alessandro and Valko, Michal},
	Booktitle = {{AISTATS}},
	Title = {Distributed Adaptive Sampling for Kernel Matrix Approximation},
	Year = {2017}}

@article{PrWi98JoA,
	Author = {Propp, J G and Wilson, D B},
	Date-Modified = {2017-05-03 17:03:51 +0000},
	Journal = {Journal of Algorithms},
	Number = {2},
	Pages = {170--217},
	Publisher = {Elsevier},
	Title = {{How to get a perfectly random sample from a generic Markov chain and generate a random spanning tree of a directed graph}},
	Volume = {27},
	Year = {1998}}

@inproceedings{Bro89,
	Author = {Broder, A},
	Booktitle = {Foundations of Computer Science, 1989., 30th Annual Symposium on},
	Organization = {IEEE},
	Pages = {442--447},
	Title = {{Generating random spanning trees}},
	Year = {1989}}

@article{Ald90,
	Abstract = {A random walk on a finite graph can be used to construct a uniform random spanning tree. We show how random walk techniques can be applied to the study of several properties of the uniform random spanning tree: the proportion of leaves, the distribution of degrees, and the diameter.},
	Author = {Aldous, David J},
	Doi = {10.1137/0403039},
	File = {:Users/ggautier/Documents/Mendeley{\_}Desktop/Aldous - 1990 - The Random Walk Construction of Uniform Spanning Trees and Uniform Labelled Trees.pdf:pdf},
	Issn = {0895-4801},
	Journal = {SIAM Journal on Discrete Mathematics},
	Keywords = {05c05,05c80,1990,3,450-465,60c05,60j10,abbreviated title,ams,discrete math,mos,random spanning trees,random tree,random walk on graph,siam j,spanning tree,subject classification},
	Number = {4},
	Pages = {450--465},
	Title = {The Random Walk Construction of Uniform Spanning Trees and Uniform Labelled Trees},
	Url = {http://link.aip.org/link/SJDMEC/v3/i4/p450/s1{\&}Agg=doi},
	Volume = {3},
	Year = {1990},
	Bdsk-Url-1 = {http://link.aip.org/link/SJDMEC/v3/i4/p450/s1%7B%5C&%7DAgg=doi},
	Bdsk-Url-2 = {http://dx.doi.org/10.1137/0403039}}

@inproceedings{calandriello_2018_nipskmean,
	Author = {Calandriello, Daniele and Rosasco, Lorenzo},
	Booktitle = {Neural Information Processing Systems},
	Title = {Statistical and Computational Trade-Offs in Kernel K-Means},
	Year = {2018}}

@inproceedings{calandriello_2019_coltgpucb,
	Author = {Calandriello, Daniele and Carratino, Luigi and Lazaric, Alessandro and Valko, Michal and Rosasco, Lorenzo},
	Booktitle = {Conference on Learning Theory},
	Title = {Gaussian Process Optimization with Adaptive Sketching: Scalable and No Regret},
	Year = {2019}}

@inproceedings{calandriello2017efficient,
  title={Efficient second-order online kernel learning with adaptive embedding},
  author={Calandriello, Daniele and Lazaric, Alessandro and Valko, Michal},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6140--6150},
  year={2017}
}

@inproceedings{calandriello_2017_icmlskons,
	Author = {Calandriello, Daniele and Lazaric, Alessandro and Valko, Michal},
	Booktitle = {International Conference on Machine Learning},
	Title = {Second-Order Kernel Online Convex Optimization with Adaptive Sketching},
	Year = {2017}}

@incollection{NIPS2018_7810,
title = {On Fast Leverage Score Sampling and Optimal Learning},
author = {Rudi, Alessandro and Calandriello, Daniele and Carratino, Luigi and Rosasco, Lorenzo},
booktitle = {Advances in Neural Information Processing Systems 31},
pages = {5672--5682},
year = {2018},
}

@article{polynomials,
author = {Branden, Petter},
year = {2014},
month = {10},
pages = {},
title = {Unimodality, Log-concavity, Real-rootedness and Beyond},
journal = {Handbook of Enumerative Combinatorics},
doi = {10.1201/b18255-10}
}



@article{yang2017weighted,
  title={Weighted SGD for lp regression with randomized preconditioning},
  author={Yang, Jiyan and Chow, Yin-Lam and R{\'e}, Christopher and Mahoney, Michael W},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={7811--7853},
  year={2017},
  publisher={JMLR. org}
}

@inproceedings{alv22,
  title={Optimal sublinear sampling of spanning trees and determinantal point processes via average-case entropic independence},
  author={Anari, Nima and Liu, Yang P and Vuong, Thuy-Duong},
  booktitle={2022 IEEE 63rd Annual Symposium on Foundations of Computer Science (FOCS)},
  pages={123--134},
  year={2022},
  organization={IEEE}
}

@article{balabanov2022block,
  title={Block subsampled randomized {H}adamard transform for low-rank approximation on distributed architectures},
  author={Balabanov, Oleg and Beaup{\`e}re, Matthias and Grigori, Laura and Lederer, Victor},
  journal={arXiv preprint arXiv:2210.11295},
  year={2022}
}

@inproceedings{musco2017sublinear,
  title={Sublinear time low-rank approximation of positive semidefinite matrices},
  author={Musco, Cameron and Woodruff, David P},
  booktitle={2017 IEEE 58th Annual Symposium on Foundations of Computer Science (FOCS)},
  pages={672--683},
  year={2017},
  organization={IEEE}
}

@article{bakshi2018sublinear,
  title={Sublinear time low-rank approximation of distance matrices},
  author={Bakshi, Ainesh and Woodruff, David},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{frangella2021randomized,
  title={Randomized {N}ystrom Preconditioning},
  author={Frangella, Zachary and Tropp, Joel A and Udell, Madeleine},
  journal={arXiv preprint arXiv:2110.02820},
  year={2021}
}

@article{avron2017faster,
  title={Faster kernel ridge regression using sketching and preconditioning},
  author={Avron, Haim and Clarkson, Kenneth L and Woodruff, David P},
  journal={SIAM Journal on Matrix Analysis and Applications},
  volume={38},
  number={4},
  pages={1116--1138},
  year={2017},
  publisher={SIAM}
}
@article{rudi2017falkon,
  title={Falkon: An optimal large scale kernel method},
  author={Rudi, Alessandro and Carratino, Luigi and Rosasco, Lorenzo},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{yao2021adahessian,
  title={Adahessian: An adaptive second order optimizer for machine learning},
  author={Yao, Zhewei and Gholami, Amir and Shen, Sheng and Mustafa, Mustafa and Keutzer, Kurt and Mahoney, Michael},
  booktitle={proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  year={2021}
}

@article{svrn,
  title={Stochastic Variance-Reduced Newton: Accelerating Finite-Sum Minimization with Large Batches},
  author={Derezi{\'n}ski, Micha{\l}},
  journal={arXiv preprint arXiv:2206.02702},
  year={2022}
}

@inproceedings{dpp-intermediate,
  author    = {Micha{\l} Derezi\'{n}ski},
  title     = {Fast determinantal point processes via distortion-free intermediate sampling},
  booktitle = {Proceedings of the 32nd Conference on Learning Theory},
  pages     = {1029--1049},
  year      = {2019},
}

@book{optimal-design-pukelsheim,
  author    = {Pukelsheim, Friedrich},
  title     = {Optimal Design of Experiments},
  year      = {2006},
  isbn      = {0898716047},
  publisher = {Society for Industrial and Applied Mathematics},
  address   = {Philadelphia, PA, USA}
}

@book{optimal-design-book,
   title = "Theory of optimal experiments",
   author = "Fedorov, Valerii V",
   series = "Probability and mathematical statistics",
   publisher = "Academic Press",
   address = "New York, NY, USA",
   year = 1972
}
   url = "http://opac.inria.fr/record=b1082555",
   isbn = "0-12-250750-9",

@inproceedings{regression-input-sparsity-time,
 author = {Clarkson, Kenneth L. and Woodruff, David P.},
 title = {Low Rank Approximation and Regression in Input Sparsity Time},
 booktitle = {Proceedings of the Forty-fifth Annual ACM Symposium on Theory of Computing},
 series = {STOC '13},
 year = {2013},
 location = {Palo Alto, California, USA},
 pages = {81--90},
 numpages = {10},
 acmid = {2488620},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {randomized, regression, sketching, leverage scores, low-rank approximation},
} 
 url = {http://doi.acm.org/10.1145/2488608.2488620},
 doi = {10.1145/2488608.2488620},
 isbn = {978-1-4503-2029-0},

@article{randomized-matrix-algorithms,
 author = {Mahoney, Michael W.},
 title = {Randomized Algorithms for Matrices and Data},
 journal = {Found. Trends Mach. Learn.},
 issue_date = {February 2011},
 volume = {3},
 number = {2},
 month = feb,
 year = {2011},
 pages = {123--224},
 numpages = {102},
 acmid = {2185808},
 publisher = {Now Publishers Inc.},
 address = {Hanover, MA, USA},
} 
 url = {http://dx.doi.org/10.1561/2200000035},
 doi = {10.1561/2200000035},
 issn = {1935-8237},

@article{iterative-row-sampling,
author = {Mu Li and Gary L. Miller and Richard Peng},
title = {Iterative Row Sampling},
journal = {2013 IEEE 54th Annual Symposium on Foundations of Computer Science},
volume = {00},
number = {},
issn = {0272-5428},
year = {2014},
pages = {127-136},
doi = {doi.ieeecomputersociety.org/10.1109/FOCS.2013.22},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
}

@article{fast-leverage-scores,
 author = {Drineas, Petros and Magdon-Ismail, Malik and Mahoney, Michael W. and Woodruff, David P.},
 title = {Fast Approximation of Matrix Coherence and Statistical Leverage},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2012},
 volume = {13},
 number = {1},
 year = {2012},
 pages = {3475--3506},
 numpages = {32},
} 

@inproceedings{pca-volume-sampling,
 author = {Deshpande, Amit and Rademacher, Luis and Vempala, Santosh and Wang, Grant},
 title = {Matrix Approximation and Projective Clustering via Volume Sampling},
 booktitle = {Proceedings of the Seventeenth Annual ACM-SIAM Symposium on Discrete Algorithm},
 year = {2006},
 month = {January},
 pages = {1117--1126},
 numpages = {10},
 acmid = {1109681},
}
url = {http://dl.acm.org/citation.cfm?id=1109557.1109681},
 isbn = {0-89871-605-5},


@book{dpp-ml,
 author = {Kulesza, Alex and Taskar, Ben},
 title = {Determinantal Point Processes for Machine Learning},
 year = {2012},
 publisher = {Now Publishers Inc.},
 address = {Hanover, MA, USA},
} 

@inproceedings{dpp-shopping,
 author = {Gartrell, Mike and Paquet, Ulrich and Koenigstein, Noam},
 title = {Bayesian Low-Rank Determinantal Point Processes},
 booktitle = {Proceedings of the 10th ACM Conference on Recommender Systems},
 year = {2016},
 month = {September},
 address = {Boston, MA, USA},
 pages = {349--356},
 numpages = {8},
 acmid = {2959178},
 keywords = {determinantal point processes, mcmc inference, recommender systems},
}
 url = {http://doi.acm.org/10.1145/2959100.2959178},
 doi = {10.1145/2959100.2959178},
 isbn = {978-1-4503-4035-9},


@inproceedings{k-dpp,
	author        = "Alex Kulesza and Ben Taskar",
	booktitle     = "{Proceedings of the 28th International Conference on Machine Learning}",
	pages         = "1193--1200",
	title         = "{k-DPPs: Fixed-Size Determinantal Point Processes}",
	year          = 2011,
	month         = {June},
}

@inproceedings{dpp-clustering,
 author = {Kang, Byungkon},
 title = {Fast Determinantal Point Process Sampling with Application to Clustering},
 booktitle = {Proceedings of the 26th International Conference on Neural Information Processing Systems},
 series = {NIPS'13},
 year = {2013},
 location = {Lake Tahoe, Nevada},
 pages = {2319--2327},
 numpages = {9},
 acmid = {2999871},
 address = {USA},
} 
 url = {http://dl.acm.org/citation.cfm?id=2999792.2999871},

@inproceedings{efficient-volume-sampling,
 author = {Deshpande, Amit and Rademacher, Luis},
 title = {Efficient Volume Sampling for Row/Column Subset Selection},
 booktitle = {Proceedings of the 2010 IEEE 51st Annual Symposium on Foundations of Computer Science},
 year = {2010},
 month = {October},
 pages = {329--338},
 numpages = {10},
 acmid = {1918397},
 address = {Las Vegas, USA},
 keywords = {volume sampling, low-rank matrix approximation, row/column subset selection},
} 
 url = {http://dx.doi.org/10.1109/FOCS.2010.38},
 doi = {10.1109/FOCS.2010.38},
 isbn = {978-0-7695-4244-7},

@article{barycentric-spanners,
 author = {Awerbuch, Baruch and Kleinberg, Robert},
 title = {Online Linear Optimization and Adaptive Routing},
 journal = {J. Comput. Syst. Sci.},
 issue_date = {February, 2008},
 volume = {74},
 number = {1},
 month = feb,
 year = {2008},
 issn = {0022-0000},
 pages = {97--114},
 numpages = {18},
 url = {http://dx.doi.org/10.1016/j.jcss.2007.04.016},
 doi = {10.1016/j.jcss.2007.04.016},
 acmid = {1298839},
 publisher = {Academic Press, Inc.},
 address = {Orlando, FL, USA},
 keywords = {Adaptive routing, Multi-armed bandit problems, Online learning, Online optimization},
} 

@article{na2022hessian,
  title={Hessian averaging in stochastic Newton methods achieves superlinear convergence},
  author={Na, Sen and Derezi{\'n}ski, Micha{\l} and Mahoney, Michael W},
  journal={Mathematical Programming},
  pages={1--48},
  year={2022},
  publisher={Springer}
}

@article{agarwal2017second,
  title={Second-order stochastic optimization for machine learning in linear time},
  author={Agarwal, Naman and Bullins, Brian and Hazan, Elad},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={4148--4187},
  year={2017},
  publisher={JMLR. org}
}

@article{volumetric-spanners,
 author = {Hazan, Elad and Karnin, Zohar},
 title = {Volumetric Spanners: An Efficient Exploration Basis for Learning},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
 issn = {1532-4435},
 pages = {4062--4095},
 numpages = {34},
 url = {http://dl.acm.org/citation.cfm?id=2946645.3007072},
 acmid = {3007072},
 publisher = {JMLR.org},
 keywords = {barycentric spanner, hard margin linear regression, linear bandits, volumetric spanner},
} 

@article{pool-based-active-learning-regression,
 author = {Sugiyama, Masashi and Nakajima, Shinichi},
 title = {Pool-based Active Learning in Approximate Linear Regression},
 journal = {Mach. Learn.},
 issue_date = {June      2009},
 volume = {75},
 number = {3},
 month = jun,
 year = {2009},
 pages = {249--274},
 numpages = {26},
 acmid = {1541690},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 keywords = {ALICE, Approximate linear regression, Covariate shift, Importance-weighted least-squares, Pool-based active learning},
} 
 url = {http://dx.doi.org/10.1007/s10994-009-5100-3},
 doi = {10.1007/s10994-009-5100-3},
 issn = {0885-6125},

@book{bishop-book,
 author = {Bishop, Christopher M.},
 title = {Pattern Recognition and Machine Learning (Information Science and Statistics)},
 year = {2006},
 isbn = {0387310738},
 publisher = {Springer-Verlag New York, Inc.},
 address = {Secaucus, NJ, USA},
 url = {http://dl.acm.org/citation.cfm?id=1162264},
} 

@article{azoury-warmuth-2001,
  added-at = {2011-05-26T00:00:00.000+0200},
  author = {Azoury, Katy S. and Warmuth, Manfred K.},
  biburl = {http://www.bibsonomy.org/bibtex/2e79a543f90048f6af8ba3bd04c1358a3/dblp},
  ee = {http://dx.doi.org/10.1023/A:1010896012157},
  interhash = {aaf7fa49b2b798b6276e781fb338578d},
  intrahash = {e79a543f90048f6af8ba3bd04c1358a3},
  journal = {Machine Learning},
  keywords = {dblp},
  number = 3,
  pages = {211-246},
  timestamp = {2011-05-27T11:34:23.000+0200},
  title = {Relative Loss Bounds for On-Line Density Estimation with the Exponential Family of Distributions.},
  url = {http://dblp.uni-trier.de/db/journals/ml/ml43.html#AzouryW01},
  volume = 43,
  year = 2001
}

@article{forster-warmuth,
 author = {Forster, J\"{u}rgen and Warmuth, Manfred K.},
 title = {Relative Expected Instantaneous Loss Bounds},
 journal = {J. Comput. Syst. Sci.},
 issue_date = {February 2002},
 volume = {64},
 number = {1},
 month = feb,
 year = {2002},
 issn = {0022-0000},
 pages = {76--102},
 numpages = {27},
 url = {http://dx.doi.org/10.1006/jcss.2001.1798},
 doi = {10.1006/jcss.2001.1798},
 acmid = {2943259},
 publisher = {Academic Press, Inc.},
 address = {Orlando, FL, USA},
} 

@article{bach-regression-convergence,
  author    = {Aymeric Dieuleveut and
               Nicolas Flammarion and
               Francis R. Bach},
  title     = {Harder, Better, Faster, Stronger Convergence Rates for Least-Squares Regression},
  journal   = {CoRR},
  volume    = {abs/1602.05419},
  year      = {2016},
  url       = {http://arxiv.org/abs/1602.05419},
  timestamp = {Tue, 01 Mar 2016 00:00:00 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/DieuleveutFB16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{random-matrix-theory,
    author = {Tao, Terence},
    citeulike-article-id = {9502175},
    citeulike-linkout-0 = {http://terrytao.files.wordpress.com/2011/02/matrix-book.pdf},
    journal = {Book By Terry Tao},
    posted-at = {2011-07-04 10:29:25},
    priority = {2},
    title = {{Topics in random matrix theory}},
    url = {http://terrytao.files.wordpress.com/2011/02/matrix-book.pdf},
    year = {2011}
}
@ARTICLE{CLW,
      author = {Cesa-Bianchi, Nicolo and Long, Philip M. and Warmuth,
	  Manfred K.},
      title = {Worst-case quadratic loss bounds for
	    on-line prediction of linear
		        functions by gradient descent},
      journal = {IEEE Transactions on Neural Networks},
      year = {1996},
      volume = {7},
      pages = {604-619},
      number = {2},
      month = may,
      url = {http://dl.acm.org/citation.cfm?id=902864},
}






@InProceedings{minimax-experimental-design,
  title = 	 {Minimax experimental design: Bridging the gap between statistical and worst-case approaches to least squares regression},
  author = 	 {Derezi{\'n}ski, Micha{\l} and Clarkson, Kenneth L. and Mahoney, Michael W. and Warmuth, Manfred K.},
  booktitle = 	 {Proceedings of the Thirty-Second Conference on Learning Theory},
  pages = 	 {1050--1069},
  year = 	 {2019},
}

@inproceedings{minimax-linear-regression,
  author    = {Peter L. Bartlett and
               Wouter M. Koolen and
               Alan Malek and
               Eiji Takimoto and
               Manfred K. Warmuth},
  title     = {Minimax Fixed-Design Linear Regression},
  booktitle = {Proceedings of The 28th Conference on Learning Theory, {COLT} 2015,
               Paris, France, July 3-6, 2015},
  pages     = {226--239},
  year      = {2015},
  url       = {http://jmlr.org/proceedings/papers/v40/Bartlett15.html},
  timestamp = {Tue, 12 Jul 2016 21:51:13 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/colt/BartlettKMTW15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{avron-boutsidis13,
author = {Haim Avron and Christos Boutsidis},
title = {Faster Subset Selection for Matrices and Applications},
journal = {SIAM Journal on Matrix Analysis and Applications},
volume = {34},
number = {4},
pages = {1464-1499},
year = {2013},

}
doi = {10.1137/120867287},
URL = {http://dx.doi.org/10.1137/120867287},



@incollection{symmetric-polynomials,
title = {Elementary Symmetric Polynomials for Optimal Experimental Design},
author = {Mariet, Zelda E. and Sra, Suvrit},
booktitle = {Advances in Neural Information Processing Systems 30},
pages = {2136--2145},
year = {2017},
url = {http://papers.nips.cc/paper/6809-elementary-symmetric-polynomials-for-optimal-experimental-design.pdf}
}


@inproceedings{dual-volume-sampling,
title = {Polynomial time algorithms for dual volume sampling},
author = {Li, Chengtao and Jegelka, Stefanie and Sra, Suvrit},
booktitle = {Advances in Neural Information Processing Systems 30},
pages = {5045--5054},
year = {2017},
}
url = {http://papers.nips.cc/paper/7089-polynomial-time-algorithms-for-dual-volume-sampling.pdf}

@article{erdogdu2015convergence,
  title={Convergence rates of sub-sampled {N}ewton methods},
  author={Erdogdu, Murat A and Montanari, Andrea},
  journal={Advances in Neural Information Processing Systems},
  volume={28},
  pages={3052--3060},
  year={2015}
}

@inproceedings{more-efficient-volume-sampling,
 author = {Guruswami, Venkatesan and Sinop, Ali K.},
 title = {Optimal Column-based Low-rank Matrix Reconstruction},
 booktitle = {Proceedings of the Twenty-third Annual ACM-SIAM Symposium on Discrete Algorithms},
 year = {2012},
 pages = {1207--1214},
 numpages = {8},
}
 url = {http://dl.acm.org/citation.cfm?id=2095116.2095211},

@book{prediction-learning-games,
 author = {Cesa-Bianchi, Nicolo and Lugosi, Gabor},
 title = {Prediction, Learning, and Games},
 year = {2006},
 publisher = {Cambridge University Press},
 address = {New York, NY, USA},
}
 isbn = {0521841089},

@MISC{detderiv,
    author       = "Kaare B. Petersen and Michael S. Pedersen",
    title        = "The Matrix Cookbook",
    year         = "2012",
    month        = "November",
    keywords     = "Matrix identity, matrix relations, inverse, matrix derivative",
    publisher    = "Technical University of Denmark",
    address      = "",
    note         = "Version 20121115",
    url          = "http://www2.imm.dtu.dk/pubdb/p.php?3274",
    abstract     = "Matrix identities, relations and approximations. A desktop reference for quick overview of mathematics of matrices."
}

@article{musco2015randomized,
  title={Randomized block krylov methods for stronger and faster approximate singular value decomposition},
  author={Musco, Cameron and Musco, Christopher},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@inproceedings{rothchild2020fetchsgd,
  title={Fetchsgd: Communication-efficient federated learning with sketching},
  author={Rothchild, Daniel and Panda, Ashwinee and Ullah, Enayat and Ivkin, Nikita and Stoica, Ion and Braverman, Vladimir and Gonzalez, Joseph and Arora, Raman},
  booktitle={International Conference on Machine Learning},
  pages={8253--8265},
  year={2020},
  organization={PMLR}
}

@article{hanzely2018sega,
  title={SEGA: Variance reduction via gradient sketching},
  author={Hanzely, Filip and Mishchenko, Konstantin and Richt{\'a}rik, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{cur-decomposition,
 author = {Drineas, Petros and Mahoney, Michael W. and Muthukrishnan, S.},
 title = {Relative-Error {CUR} Matrix Decompositions},
 journal = {SIAM J. Matrix Anal. Appl.},
 issue_date = {May 2008},
 volume = {30},
 number = {2},
 year = {2008},
 pages = {844--881},
 numpages = {38},
 acmid = {1461889},
 publisher = {Society for Industrial and Applied Mathematics},
 address = {Philadelphia, PA, USA},
 keywords = {\$CUR\$ matrix decomposition, approximate least squares, data analysis, random sampling algorithms},
} 
 url = {https://doi.org/10.1137/07070471X},
 doi = {10.1137/07070471X},
 issn = {0895-4798},


@article{coresets-regression,
  author    = {Christos Boutsidis and
               Petros Drineas and
               Malik Magdon{-}Ismail},
  title     = {Near-Optimal Coresets for Least-Squares Regression},
  journal   = {{IEEE} Trans. Information Theory},
  volume    = {59},
  number    = {10},
  pages     = {6880--6892},
  year      = {2013},
}
  url       = {https://doi.org/10.1109/TIT.2013.2272457},
  doi       = {10.1109/TIT.2013.2272457},
  timestamp = {Sun, 28 May 2017 13:18:52 +0200},
  biburl    = {http://dblp.org/rec/bib/journals/tit/BoutsidisDM13},
  bibsource = {dblp computer science bibliography, http://dblp.org}

@article{regression-correspondence,
  author    = {Daniel Hsu and
               Kevin Shi and
               Xiaorui Sun},
  title     = {Linear regression without correspondence},
  journal   = {CoRR},
  volume    = {abs/1705.07048},
  year      = {2017},
  url       = {http://arxiv.org/abs/1705.07048},
  timestamp = {Thu, 01 Jun 2017 19:31:46 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/HsuSS17},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}


@article{bental-teboulle,
title = "A geometric property of the least squares solution of linear equations",
journal = "Linear Algebra and its Applications",
volume = "139",
number = "",
pages = "165 - 170",
year = "1990",
note = "",
author = "Aharon Ben-Tal and Marc Teboulle",
}

@inproceedings{near-optimal-design,
  title     = {Near-Optimal Design of Experiments via Regret Minimization},
  author    = {Zeyuan Allen-Zhu and Yuanzhi Li and Aarti Singh and Yining Wang},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  pages     = {126--135},
  year      = {2017},
  month     = {August},
  volume    = {70},
  series    = {Proceedings of Machine Learning Research},
  address   = {Sydney, Australia},
  pdf       = {http://proceedings.mlr.press/v70/allen-zhu17e/allen-zhu17e.pdf},
  url       = {http://proceedings.mlr.press/v70/allen-zhu17e.html}
}


@inproceedings{unbiased-estimates,
title = {Unbiased estimates for linear regression via volume sampling},
author = {Derezi\'{n}ski, Micha{\l} and Warmuth, Manfred K.},
booktitle = {Advances in Neural Information Processing Systems 30},
pages = {3087--3096},
year = {2017},
}

@article{geometric-tail-bounds,
title = "Tail bounds for sums of geometric and exponential variables",
journal = "Statistics and Probability Letters",
volume = "135",
pages = "1 - 6",
year = "2018",
author = "Svante Janson",
keywords = "Geometric distribution, Exponential distribution, Tail bounds"
}


@ARTICLE{alias-method,
   author = {A.J. Walker},
   keywords = {sequential numbers;arbitrary frequency distributions;random number generation;},
   title = {An efficient method for generating discrete random variables with general distributions.},
   ISSN = {0013-5194},
   language = {English},
   journal = {Electronics Letters},
   issue = {8},   
   volume = {10},
   year = {1974},
   month = {April},
   pages = {127-128(1)},
   publisher ={Institution of Engineering and Technology},
   copyright = {© The Institution of Electrical Engineers},
   url = {http://digital-library.theiet.org/content/journals/10.1049/el_19740097}
}

@article{updated-sampling-tree,
author = {K. Wong, C and Easton, Malcolm},
year = {1980},
month = {02},
pages = {111-113},
title = {An Efficient Method for Weighted Sampling Without Replacement.},
volume = {9},
booktitle = {SIAM J. Comput.}
}



@article{tractable-experimental-design,
 author = {Wang, Yining and Yu, Adams W. and Singh, Aarti},
 title = {On Computationally Tractable Selection of Experiments in Measurement-constrained Regression Models},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2017},
 volume = {18},
 number = {1},
 month = jan,
 year = {2017},
 issn = {1532-4435},
 pages = {5238--5278},
 numpages = {41},
 url = {http://dl.acm.org/citation.cfm?id=3122009.3208024},
 acmid = {3208024},
 publisher = {JMLR.org},
 keywords = {A-optimality, computationally tractable methods, minimax analysis, optimal selection of experiments},
}


@inproceedings{ridge-leverage-scores,
 author = {Alaoui, Ahmed El and Mahoney, Michael W.},
 title = {Fast Randomized Kernel Ridge Regression with Statistical Guarantees},
 booktitle = {Proceedings of the 28th International Conference on Neural Information Processing Systems},
 year = {2015},
 pages = {775--783},
 numpages = {9},
}

@InProceedings{ridge-uniform,
  title = 	 {Sharp analysis of low-rank  kernel matrix approximations},
  author = 	 {Francis Bach},
  booktitle = 	 {Proceedings of the 26th Annual Conference on Learning Theory},
  pages = 	 {185--209},
  year = 	 {2013},
  address = 	 {Princeton, NJ, USA},
  month = 	 {June},
  pdf = 	 {http://proceedings.mlr.press/v30/Bach13.pdf},
  url = 	 {http://proceedings.mlr.press/v30/Bach13.html},
}

@article{libsvm,
 author = {Chang, Chih-Chung and Lin, Chih-Jen},
 title = {{LIBSVM}: A library for support vector machines},
 journal = {ACM Transactions on Intelligent Systems and Technology},
 volume = {2},
 issue = {3},
 year = {2011},
 pages = {27:1--27:27},
}
 note =	 {Software available at \url{http://www.csie.ntu.edu.tw/~cjlin/libsvm}}

@misc{uci-repository,
author = "M. Lichman",
year = "2013",
title = "{UCI} Machine Learning Repository",
url = "http://archive.ics.uci.edu/ml",
institution = "University of California, Irvine, School of Information and Computer Sciences" }


@inproceedings{sarlos-sketching,
 author = {Sarlos, Tamas},
 title = {Improved Approximation Algorithms for Large Matrices via Random Projections},
 booktitle = {Proceedings of the Symposium on Foundations of Computer Science},
 series = {FOCS '06},
 year = {2006},
 pages = {143--152},
 numpages = {10},
} 

@InProceedings{regularized-volume-sampling,
  title = 	 {Subsampling for Ridge Regression via Regularized Volume Sampling},
  author = 	 {Derezi\'{n}ski, Micha{\l} and Warmuth, Manfred K.},
  booktitle = 	 {Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics},
  pages = 	 {716--725},
  year = 	 {2018},
}


@book{statistical-learning-book,
  added-at = {2008-05-16T16:17:42.000+0200},
  address = {New York, NY, USA},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  biburl = {https://www.bibsonomy.org/bibtex/2f58afc5c9793fcc8ad8389824e57984c/sb3000},
  interhash = {d585aea274f2b9b228fc1629bc273644},
  intrahash = {f58afc5c9793fcc8ad8389824e57984c},
  keywords = {ml statistics},
  publisher = {Springer New York Inc.},
  series = {Springer Series in Statistics},
  timestamp = {2008-05-16T16:17:43.000+0200},
  title = {The Elements of Statistical Learning},
  year = 2001
}

@Article{matrix-tail-bounds,
author="Tropp, Joel A.",
title="User-Friendly Tail Bounds for Sums of Random Matrices",
journal="Foundations of Computational Mathematics",
year="2012",
month={August},
day="01",
volume="12",
number="4",
pages="389--434",
abstract="This paper presents new probability inequalities for sums of independent, random, self-adjoint matrices. These results place simple and easily verifiable hypotheses on the summands, and they deliver strong conclusions about the large-deviation behavior of the maximum eigenvalue of the sum. Tail bounds for the norm of a sum of random rectangular matrices follow as an immediate corollary. The proof techniques also yield some information about matrix-valued martingales.",
}
issn="1615-3383",
doi="10.1007/s10208-011-9099-z",
url="https://doi.org/10.1007/s10208-011-9099-z"

@Unpublished{Hsuprivate
 , author =       "Daniel Hsu"
 , title =        "Leverage scores and linear regression"
 , month =        "March"
 , year =         "2017"
 , note =         "Private communication"
}

@book{randomized-heuristics,
 author = {Auger, Anne and Doerr, Benjamin},
 title = {Theory of Randomized Search Heuristics: Foundations and Recent Developments},
 year = {2011},
 publisher = {World Scientific Publishing Co., Inc.},
 address = {River Edge, NJ, USA},
} 
 isbn = {9789814282666, 9814282669},


@article{general-birthday-problem,
author = {Holst, Lars},
title = {The general birthday problem},
journal = {Random Structures & Algorithms},
volume = {6},
number = {2-3},
publisher = {Wiley Subscription Services, Inc., A Wiley Company},
issn = {1098-2418},
url = {http://dx.doi.org/10.1002/rsa.3240060207},
doi = {10.1002/rsa.3240060207},
pages = {201--208},
year = {1995},
}

@article{coupon-collector-extreme,
  title={Extreme value distributions for random coupon collector and birthday problems},
  author={Holst, Lars},
  journal={Extremes},
  volume={4},
  number={2},
  pages={129--145},
  year={2001},
  publisher={Springer}
}

@article{volume-of-matrices,
title = "A volume associated with m x n matrices",
journal = "Linear Algebra and its Applications",
volume = "167",
number = "Supplement C",
pages = "87 - 111",
year = "1992",
author = "Adi Ben-Israel"
}
issn = "0024-3795",
doi = "https://doi.org/10.1016/0024-3795(92)90340-G",
url = "http://www.sciencedirect.com/science/article/pii/002437959290340G",


@inproceedings{drineas2006sampling,
  title={Sampling algorithms for $\ell_2$ regression and applications},
  author={Drineas, Petros and Mahoney, Michael W and Muthukrishnan, S},
  booktitle={Proceedings of the seventeenth annual ACM-SIAM symposium on Discrete algorithm},
  pages={1127--1136},
  year={2006},
}

@article{woodruff2014sketching,
  title={Sketching as a tool for numerical linear algebra},
  author={Woodruff, David P},
  journal={Foundations and Trends{\textregistered} in Theoretical Computer Science},
  volume={10},
  number={1--2},
  pages={1--157},
  year={2014},
  publisher={Now Publishers, Inc.}
}

@article{pemantle2014concentration,
  title={Concentration of Lipschitz functionals of determinantal and other strong Rayleigh measures},
  author={Pemantle, Robin and Peres, Yuval},
  journal={Combinatorics, Probability and Computing},
  volume={23},
  number={1},
  pages={140--160},
  year={2014},
  publisher={Cambridge University Press}
}

@incollection{loosli-canu-bottou-2006,
  author = {Loosli, Ga\"{e}lle and Canu, St\'{e}phane and Bottou, L\'{e}on},
  title = {Training Invariant Support Vector Machines using Selective Sampling},
  pages = {301-320},
  booktitle = {Large Scale Kernel Machines},
  publisher = {MIT Press},
  address = {Cambridge, MA.},
  year = {2007},
}

@article{panconesi1997randomized,
 author = {Panconesi, Alessandro and Srinivasan, Aravind},
 title = {Randomized Distributed Edge Coloring via an Extension of the Chernoff--Hoeffding Bounds},
 journal = {SIAM J. Comput.},
 issue_date = {April 1997},
 volume = {26},
 number = {2},
 month = apr,
 year = {1997},
 issn = {0097-5397},
 pages = {350--368},
 numpages = {19},
 url = {https://doi.org/10.1137/S0097539793250767},
 doi = {10.1137/S0097539793250767},
 acmid = {249368},
 publisher = {Society for Industrial and Applied Mathematics},
 address = {Philadelphia, PA, USA},
} 

@article{batson2012twice,
  title={Twice-ramanujan sparsifiers},
  author={Batson, Joshua and Spielman, Daniel A and Srivastava, Nikhil},
  journal={SIAM Journal on Computing},
  volume={41},
  number={6},
  pages={1704--1721},
  year={2012},
  publisher={SIAM}
}

@article{song2017relative,
  title={Relative Error Tensor Low Rank Approximation},
  author={Song, Zhao and Woodruff, David P and Zhong, Peilin},
  journal={arXiv preprint arXiv:1704.08246},
  year={2017}
}

@article{hadamard-product-inequality,
author = {Ando, T and A. Horn, Roger and R. Johnson, Charles},
year = {1987},
month = {12},
pages = {345-365},
title = {The Singular Values of a {H}adamard Product: A Basic Inequality},
volume = {21},
booktitle = {Linear & Multilinear Algebra - LINEAR MULTILINEAR ALGEBRA}
}

@article{johnson2013accelerating,
  title={Accelerating stochastic gradient descent using predictive variance reduction},
  author={Johnson, Rie and Zhang, Tong},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}


@inproceedings{harvey2014pipage,
  title={Pipage rounding, pessimistic estimators and matrix concentration},
  author={Harvey, Nicholas JA and Olver, Neil},
  booktitle={Proceedings of the twenty-fifth annual ACM-SIAM symposium on Discrete algorithms},
  pages={926--945},
  year={2014},
  organization={SIAM}
}

@article{uniform-matrix-sampling,
  title={Note on sampling without replacing from a finite collection of matrices},
  author={Gross, David and Nesme, Vincent},
  journal={arXiv preprint arXiv:1001.2738},
  year={2010}
}

@article{hoeffding-with-replacement,
  title={Probability inequalities for sums of bounded random variables},
  author={Hoeffding, Wassily},
  journal={Journal of the American statistical association},
  volume={58},
  number={301},
  pages={13--30},
  year={1963},
  publisher={Taylor \& Francis Group}
}

@ARTICLE{onlineregr,
  author = {N. Cesa-Bianchi and P. M. Long and M. K.
Warmuth},
  title = {Worst-case quadratic loss bounds for on-line
prediction of linear
        functions by gradient descent},
  journal = {IEEE Transactions on Neural Networks},
  year = {1996},
  volume = {7},
  pages = {604--619},
  number = {3},
  note = {Earlier version in 6th COLT, 1993}
}

@article{celis2018fair,
  title={Fair and Diverse DPP-based Data Summarization},
  author={Celis, L Elisa and Keswani, Vijay and Straszak, Damian and Deshpande, Amit and Kathuria, Tarun and Vishnoi, Nisheeth K},
  journal={CoRR},
  volume={abs/1802.04023},
  year={2018}
}

@article{celis2016fair,
  title={How to be Fair and Diverse?},
  author={Celis, L Elisa and Deshpande, Amit and Kathuria, Tarun and Vishnoi, Nisheeth K},
  journal={CoRR},
  volume={abs/1610.07183},
  year={2016}
}

@inproceedings{lee2015constructing,
  title={Constructing linear-sized spectral sparsification in almost-linear time},
  author={Lee, Yin Tat and Sun, He},
  booktitle={Foundations of Computer Science (FOCS), 2015 IEEE 56th Annual Symposium on},
  pages={250--269},
  year={2015},
  organization={IEEE}
}







@InProceedings{chen2017condition,
  title = 	 {Active Regression via Linear-Sample Sparsification},
  author = 	 {Chen, Xue and Price, Eric},
  booktitle = 	 {Proceedings of the 32nd Conference on Learning Theory},
  pages = 	 {663--695},
  year = 	 {2019},
}


@article{ailon2009fast,
  title={The fast {J}ohnson--{L}indenstrauss transform and approximate nearest neighbors},
  author={Ailon, Nir and Chazelle, Bernard},
  journal={SIAM Journal on computing},
  volume={39},
  number={1},
  pages={302--322},
  year={2009},
  publisher={SIAM}
}

@inproceedings{proportional-volume-sampling,
author = {Nikolov, Aleksandar and Singh, Mohit and Tao Tantipongpipat, Uthaipon},
year = {2019},
pages = {1369-1386},
title = {Proportional Volume Sampling and Approximation Algorithms for {A}-Optimal Design},
booktitle =  {Proceedings of the Symposium on Discrete Algorithms},
}

@article{unbiased-estimates-journal,
  author  = {Micha{\l} Derezi{\'n}ski and Manfred K. Warmuth},
  title   = {Reverse Iterative Volume Sampling for Linear Regression},
  journal = {Journal of Machine Learning Research},
  year    = {2018},
  volume  = {19},
  number  = {23},
  pages   = {1-39},
  url     = {http://jmlr.org/papers/v19/17-781.html}
}


@book{matrix-differentials-book,
  author = {Magnus, Jan R. and Neudecker, Heinz},
  biburl = {https://www.bibsonomy.org/bibtex/2c82317ecaf30079fa28c0fd5774e6780/ytyoun},
  edition = {Second},
  interhash = {76bd08d7316ac86cb1a7b88078010d57},
  intrahash = {c82317ecaf30079fa28c0fd5774e6780},
  isbn = {0471986321 9780471986324 047198633X 9780471986331},
  keywords = {calculus economics linear.algebra matrix textbook},
  publisher = {John Wiley},
  refid = {40467399},
  timestamp = {2016-05-31T14:11:33.000+0200},
  title = {Matrix Differential Calculus with Applications in Statistics and Econometrics},
  year = 1999
}

@incollection{structured-dpp,
title = {Structured Determinantal Point Processes},
author = {Kulesza, Alex and Taskar, Ben},
booktitle = {Advances in Neural Information Processing Systems 23},
pages = {1171--1179},
year = {2010},
}

@inproceedings{dpp-minibatch,
  title={Determinantal point processes for mini-batch diversification},
  author={Zhang, Cheng and Kjellstr{\"o}m, Hedvig and Mandt, Stephan},
  booktitle={33rd Conference on Uncertainty in Artificial Intelligence, UAI 2017},
  year={2017},
}

@phdthesis{thethesis,
  author       = {Micha{\l} Derezi\'{n}ski}, 
  title        = {Volume sampling for linear regression},
  school       = {University of California at Santa Cruz},
  address      = {CA, USA},
  month        = {June},
  year         = 2018,
}

@incollection{leveraged-volume-sampling,
title = {Leveraged volume sampling for linear regression},
  author    = {Micha{\l} Derezi\'{n}ski and
               Manfred K. Warmuth and
               Daniel Hsu},
booktitle = {Advances in Neural Information Processing Systems 31},
pages = {2510--2519},
year = {2018},
}

@article{correcting-bias-journal,
  title={Unbiased estimators for random design regression},
  author={Derezi{\'n}ski, Micha{\l} and Warmuth, Manfred K and Hsu, Daniel},
  journal={Journal of Machine Learning Research},
  volume={23},
  pages={1--46},
  year={2022}
}

@inproceedings{correcting-bias,
   author = {Micha{\l} Derezi\'{n}ski and
               Manfred K. Warmuth and
               Daniel Hsu},
    title = "{Correcting the bias in least squares regression with volume-rescaled sampling}",
booktitle = 	 {Proceedings of the 22nd International Conference on Artificial Intelligence and Statistics},
 keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
     year = 2019,
}

@inproceedings{fast-submodular-minimization,
 author = {Jegelka, Stefanie and Lin, Hui and Bilmes, Jeff},
 title = {On Fast Approximate Submodular Minimization},
 booktitle = {Proceedings of the 24th International Conference on Neural Information Processing Systems},
 series = {NIPS'11},
 year = {2011},
 isbn = {978-1-61839-599-3},
 location = {Granada, Spain},
 pages = {460--468},
 numpages = {9},
 url = {http://dl.acm.org/citation.cfm?id=2986459.2986511},
 acmid = {2986511},
 publisher = {Curran Associates Inc.},
 address = {USA},
}

@inproceedings{bss,
  acmid = {1536451},
  added-at = {2011-03-28T23:21:08.000+0200},
  address = {New York, NY, USA},
  author = {Batson, Joshua D. and Spielman, Daniel A. and Srivastava, Nikhil},
  biburl = {https://www.bibsonomy.org/bibtex/24a70d1be2be6686ed5cb53eb1c00b82f/ytyoun},
  booktitle = {Proceedings of the 41st annual ACM symposium on Theory of computing},
  doi = {10.1145/1536414.1536451},
  interhash = {ca9aed22962c62ca09a2eaf38cc9423e},
  intrahash = {4a70d1be2be6686ed5cb53eb1c00b82f},
  isbn = {978-1-60558-506-2},
  keywords = {characteristic courant-fischer eigenvalues expander graph.theory laguerre linear.algebra matrix ramanujan sparsification spectral_graph_theory},
  location = {Bethesda, MD, USA},
  numpages = {8},
  pages = {255--262},
  publisher = {ACM},
  series = {STOC '09},
  timestamp = {2016-10-20T13:29:43.000+0200},
  title = {Twice-{Ramanujan} Sparsifiers},
  year = 2009
}

@article{subsampled-newton,
  title={Sub-sampled Newton methods},
  author={Roosta-Khorasani, Farbod and Mahoney, Michael W},
  journal={Mathematical Programming},
  volume={174},
  pages={293--326},
  year={2019},
  publisher={Springer}
}

@inproceedings{large-scale-tradeoffs,
 author = {Bottou, Leon and Bousquet, Olivier},
 title = {The Tradeoffs of Large Scale Learning},
 booktitle = {Proceedings of the 20th International Conference on Neural Information Processing Systems},
 series = {NIPS'07},
 year = {2007},
 isbn = {978-1-60560-352-0},
 location = {Vancouver, British Columbia, Canada},
 pages = {161--168},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=2981562.2981583},
 acmid = {2981583},
 publisher = {Curran Associates Inc.},
 address = {USA},
} 

@article{distributed-newton,
  title={{GIANT:} Globally improved approximate newton method for distributed optimization},
  author={Wang, Shusen and Roosta, Fred and Xu, Peng and Mahoney, Michael W},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  pages={2332--2342},
  year={2018}
}

@Article{proteinase,
author="Liao, Jun
and Warmuth, Manfred K.
and Govindarajan, Sridhar
and Ness, Jon E.
and Wang, Rebecca P.
and Gustafsson, Claes
and Minshull, Jeremy",
title="Engineering proteinase K using machine learning and synthetic genes",
journal="BMC Biotechnology",
year="2007",
month="Mar",
day="26",
volume="7",
number="1",
pages="16",
}


@article{dpp-independence,
  title={Determinantal processes and independence},
  author={Hough, J Ben and Krishnapur, Manjunath and Peres, Yuval and Vir{\'a}g, B{\'a}lint},
  journal={Probability surveys},
  volume={3},
  pages={206--229},
  year={2006},
  publisher={The Institute of Mathematical Statistics and the Bernoulli Society}
}

@article{dpp-stats,
	author = {R\'emi Bardenet and Fr\'ed\'eric Lavancier and Xavier Mary and Aur\'elien Vasseur}, 
	title = {On a few statistical applications of determinantal point processes},
	DOI= "10.1051/proc/201760180",
	url= "https://doi.org/10.1051/proc/201760180",
	journal = {ESAIM: Procs},
	year = 2017,
	volume = 60,
	pages = "180-202",
}

@article{dpp-physics,
 ISSN = {00018678},
 URL = {http://www.jstor.org/stable/1425855},
 author = {Odile Macchi},
 journal = {Advances in Applied Probability},
 number = {1},
 pages = {83--122},
 publisher = {Applied Probability Trust},
 title = {The Coincidence Approach to Stochastic Point Processes},
 volume = {7},
 year = {1975}
}

@article{gower2019rsn,
  title={Rsn: Randomized subspace newton},
  author={Gower, Robert and Kovalev, Dmitry and Lieder, Felix and Richt{\'a}rik, Peter},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{spanning-trees,
title = "Random spanning tree",
journal = "Journal of Algorithms",
volume = "4",
number = "3",
pages = "214 - 220",
year = "1983",
issn = "0196-6774",
doi = "https://doi.org/10.1016/0196-6774(83)90022-6",
url = "http://www.sciencedirect.com/science/article/pii/0196677483900226",
author = "A Guenoche"
}

@incollection{dpp-video,
title = {Diverse Sequential Subset Selection for Supervised Video Summarization},
author = {Gong, Boqing and Chao, Wei-Lun and Grauman, Kristen and Sha, Fei},
booktitle = {Advances in Neural Information Processing Systems 27},
pages = {2069--2077},
year = {2014},
publisher = {Curran Associates, Inc.},
}

@inproceedings{dpp-summarization,
 author = {Lin, Hui and Bilmes, Jeff},
 title = {A Class of Submodular Functions for Document Summarization},
 booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1},
 series = {HLT '11},
 year = {2011},
 isbn = {978-1-932432-87-9},
 location = {Portland, Oregon},
 pages = {510--520},
 numpages = {11},
 url = {http://dl.acm.org/citation.cfm?id=2002472.2002537},
 acmid = {2002537},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
} 

@inproceedings{dpp-salient-threads,
 author = {Gillenwater, Jennifer and Kulesza, Alex and Taskar, Ben},
 title = {Discovering Diverse and Salient Threads in Document Collections},
 booktitle = {Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning},
 series = {EMNLP-CoNLL '12},
 year = {2012},
 location = {Jeju Island, Korea},
 pages = {710--720},
 numpages = {11},
 url = {http://dl.acm.org/citation.cfm?id=2390948.2391026},
 acmid = {2391026},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
} 

@article{dpp-mcmc,
author = {Bardenet, Rémi and Hardy, Adrien},
year = {2016},
month = {05},
pages = {},
title = {Monte Carlo with Determinantal Point Processes},
volume = {30},
journal = {The Annals of Applied Probability},
}

@ARTICLE{dpp-noeig,
       author = {{Launay}, Claire and {Galerne}, Bruno and {Desolneux}, Agn{\`e}s},
        title = "{Exact Sampling of Determinantal Point Processes without Eigendecomposition}",
      journal = {arXiv e-prints},
     keywords = {Statistics - Machine Learning},
         year = "2018",
        month = "Feb",
          eid = {arXiv:1802.08429},
        pages = {arXiv:1802.08429},
archivePrefix = {arXiv},
       eprint = {1802.08429},
 primaryClass = {stat.ML},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2018arXiv180208429L},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@inproceedings{kdpp-mcmc,
 author = {Li, Chengtao and Jegelka, Stefanie and Sra, Suvrit},
 title = {Fast Mixing Markov Chains for Strongly {R}ayleigh Measures, {DPP}s, and Constrained Sampling},
 booktitle = {Proceedings of the 30th International Conference on Neural Information Processing Systems},
 series = {NIPS'16},
 year = {2016},
 pages = {4195--4203},
 numpages = {9},
} 

@InProceedings{rayleigh-mcmc,
  title = 	 {Monte Carlo Markov Chain Algorithms for Sampling Strongly {R}ayleigh Distributions and Determinantal Point Processes},
  author = 	 {Nima Anari and Shayan Oveis Gharan and Alireza Rezaei},
  booktitle = 	 {29th Annual Conference on Learning Theory},
  pages = 	 {103--115},
  year = 	 {2016},
  month = 	 {23--26 Jun},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v49/anari16.pdf},
  url = 	 {http://proceedings.mlr.press/v49/anari16.html},
}

@inproceedings{schild-trees,
 author = {Schild, Aaron},
 title = {An Almost-linear Time Algorithm for Uniform Random Spanning Tree Generation},
 booktitle = {Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing},
 series = {STOC 2018},
 year = {2018},
 isbn = {978-1-4503-5559-9},
 location = {Los Angeles, CA, USA},
 pages = {214--227},
 numpages = {14},
 url = {http://doi.acm.org/10.1145/3188745.3188852},
 doi = {10.1145/3188745.3188852},
 acmid = {3188852},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Schur complements, random spanning trees, random walks},
}

@InProceedings{volume-sketching,
author="Magen, Avner and Zouzias, Anastasios",
title="Near Optimal Dimensionality Reductions That Preserve Volumes",
booktitle="Approximation, Randomization and Combinatorial Optimization. Algorithms and Techniques",
year="2008",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="523--534",
isbn="978-3-540-85363-3"
}

@InProceedings{dpp-coreset,
  title = 	 {Efficient Sampling for k-Determinantal Point Processes},
  author = 	 {Chengtao Li and Stefanie Jegelka and Suvrit Sra},
  booktitle = 	 {Proceedings of the 19th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {1328--1337},
  year = 	 {2016},
}

@InProceedings{dpp-nystrom,
  title = 	 {Nystrom Approximation for Large-Scale Determinantal Processes},
  author = 	 {Raja Hafiz Affandi and Alex Kulesza and Emily Fox and Ben Taskar},
  booktitle = 	 {Proceedings of the Sixteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {85--98},
  year = 	 {2013},
}

@article{expected-generalized-variance,
author = "van der Vaart, H. Robert",
doi = "10.1214/aoms/1177700006",
fjournal = "The Annals of Mathematical Statistics",
journal = "Ann. Math. Statist.",
month = "08",
number = "4",
pages = "1308--1312",
publisher = "The Institute of Mathematical Statistics",
title = "A Note on Wilks' Internal Scatter",
url = "https://doi.org/10.1214/aoms/1177700006",
volume = "36",
year = "1965"
}

@article{cw-sparse,
 author = {Clarkson, Kenneth L. and Woodruff, David P.},
 title = {Low-Rank Approximation and Regression in Input Sparsity Time},
 journal = {J. ACM},
 issue_date = {February 2017},
 volume = {63},
 number = {6},
 month = jan,
 year = {2017},
 issn = {0004-5411},
 pages = {54:1--54:45},
 articleno = {54},
 numpages = {45},
 url = {http://doi.acm.org/10.1145/3019134},
 doi = {10.1145/3019134},
 acmid = {3019134},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Matrices, approximation, randomized},
} 

@inproceedings{nn-sparse,
 author = {Nelson, Jelani and Nguy\^{e}n, Huy L.},
 title = {OSNAP: Faster Numerical Linear Algebra Algorithms via Sparser Subspace Embeddings},
 booktitle = {Proceedings of the Symposium on Foundations of Computer Science},
 series = {FOCS '13},
 year = {2013},
 pages = {117--126},
 numpages = {10},
}

@inproceedings{mm-sparse,
 author = {Meng, Xiangrui and Mahoney, Michael W.},
 title = {Low-distortion Subspace Embeddings in Input-sparsity Time and Applications to Robust Linear Regression},
 booktitle = {Proceedings of the Symposium on Theory of Computing},
 series = {STOC '13},
 year = {2013},
 pages = {91--100},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2488608.2488621},
 doi = {10.1145/2488608.2488621},
}

@article{dpp-concentration,
title={Concentration of Lipschitz Functionals of Determinantal and Other Strong Rayleigh Measures},
volume={23},
DOI={10.1017/S0963548313000345},
number={1},
journal={Combinatorics, Probability and Computing},
publisher={Cambridge University Press},
author={Pemantle, Robin and Peres, Yuval},
year={2014},
pages={140–160}
}

@article{kant,
  title={Functional analysis and applied mathematics},
  author={Kantorovich, Leonid V.},
  journal={Uspekhi Matematicheskikh Nauk},
  volume={3},
  number={6},
  pages={89--185},
  year={1948},
  publisher={Russian Academy of Sciences, Steklov Mathematical Institute of Russian Academy of Sciences}
}

@INPROCEEDINGS{near-optimal-columns, 
author={Christos Boutsidis and Petros Drineas and Malik Magdon-Ismail}, 
booktitle={2011 IEEE 52nd Annual Symposium on Foundations of Computer Science}, 
title={Near Optimal Column-Based Matrix Reconstruction}, 
year={2011}, 
volume={}, 
number={}, 
pages={305-314}, 
doi={10.1109/FOCS.2011.21}, 
ISSN={0272-5428}, 
month={Oct},
}

@article{indyk2019learning,
  title={Learning-based low-rank approximations},
  author={Indyk, Piotr and Vakilian, Ali and Yuan, Yang},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{indyk2021few,
  title={Few-Shot Data-Driven Algorithms for Low Rank Approximation},
  author={Indyk, Piotr and Wagner, Tal and Woodruff, David},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={10678--10690},
  year={2021}
}


@article{musco2017recursive,
  title={Recursive sampling for the nystrom method},
  author={Musco, Cameron and Musco, Christopher},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{projection-cost-preserving,
 author = {Cohen, Michael B. and Elder, Sam and Musco, Cameron and Musco, Christopher and Persu, Madalina},
 title = {Dimensionality Reduction for k-Means Clustering and Low Rank Approximation},
 booktitle = {Proceedings of the Symposium on Theory of Computing},
 year = {2015},
 pages = {163--172},
} 

@article{optimal-cur,
author = {Boutsidis, Christos and Woodruff, David~P.},
title = {Optimal CUR Matrix Decompositions},
journal = {SIAM Journal on Computing},
volume = {46},
number = {2},
pages = {543-589},
year = {2017},
doi = {10.1137/140977898},
URL = {https://doi.org/10.1137/140977898},
eprint = {https://doi.org/10.1137/140977898}
}

@techreport{poisson-tail,
author = {Cl\'{e}ment Canonne},
title = {A short note on Poisson tail bounds},
institution = {Columbia University},
year = {2017}
}

@unpublished{dppy,
abstract = {Determinantal point processes (DPPs) are specific probability distributions over clouds of points that are used as models and computational tools across physics, probability, statistics, and more recently machine learning. Sampling from DPPs is a challenge and therefore we present DPPy, a Python toolbox that gathers known exact and approximate sampling algorithms. The project is hosted on GitHub and equipped with an extensive documentation. This documentation takes the form of a short survey of DPPs and relates each mathematical property with DPPy objects.},
author = {Gautier, Guillaume and Bardenet, R{\'{e}}mi and Valko, Michal},
title = {{DPPy: Sampling determinantal point processes with Python}},
year = {2018}
}

@inproceedings{dpp-sublinear,
title = {Exact sampling of determinantal point processes with sublinear time preprocessing},
author = {Derezi\'{n}ski, Micha{\l} and Calandriello, Daniele and Valko, Michal},
booktitle = {Advances in Neural Information Processing Systems},
pages = {11542--11554},
year = {2019},
}

@InProceedings{dpp-tree,
  title = 	 {A Tree-Based Method for Fast Repeated Sampling of Determinantal Point Processes},
  author = 	 {Gillenwater, Jennifer and Kulesza, Alex and Mariet, Zelda and Vassilvtiskii, Sergei},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {2260--2268},
  year = 	 {2019},
}


@InProceedings{dpp-continuous,
  title = 	 {A Polynomial Time {MCMC} Method for Sampling from Continuous Determinantal Point Processes},
  author = 	 {Rezaei, Alireza and Gharan, Shayan Oveis},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {5438--5447},
  year = 	 {2019},
}

@incollection{belhadji19,
title = {Kernel quadrature with {DPP}s},
author = {Belhadji, Ayoub and Bardenet, R\'{e}mi and Chainais, Pierre},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {12907--12917},
year = {2019},
}

@incollection{gautier19,
title = {On two ways to use determinantal point processes for {M}onte {C}arlo integration},
author = {Gautier, Guillaume and Bardenet, R\'{e}mi and Valko, Michal},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {7768--7777},
year = {2019},
}

@inproceedings{randomized-newton,
  title={Convergence Analysis of Block Coordinate Algorithms with Determinantal Sampling},
  author={Mutny, Mojmir and Derezi\'nski, Micha{\l} and Krause, Andreas},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3110--3120},
  year={2020}
}

@inproceedings{bayesian-experimental-design,
  title={Bayesian experimental design using regularized determinantal point processes},
  author={Derezinski, Michal and Liang, Feynman and Mahoney, Michael},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3197--3207},
  year={2020}
}

@article{blendenpik,
author = {Avron, Haim and Maymounkov, Petar and Toledo, Sivan},
title = {Blendenpik: Supercharging LAPACK's Least-Squares Solver},
journal = {SIAM Journal on Scientific Computing},
volume = {32},
number = {3},
pages = {1217-1236},
year = {2010},
}

@inproceedings{durfee2018ell_1,
  title={l1 Regression using Lewis Weights Preconditioning and Stochastic Gradient Descent},
  author={Durfee, David and Lai, Kevin A and Sawlani, Saurabh},
  booktitle={Conference On Learning Theory},
  pages={1626--1656},
  year={2018},
  organization={PMLR}
}

@ARTICLE{MSM14_SISC,
  author =       {X. Meng and M. A. Saunders and M. W. Mahoney},
  title =        {{LSRN}: A Parallel Iterative Solver for Strongly Over- or Under-Determined Systems},
  journal =      {SIAM Journal on Scientific Computing},
  year =         {2014},
  volume =       {36},
  number =       {2},
  pages =        {C95--C118},
}

@ARTICLE{MMY15,
  author =       {P.~Ma and M.~W.~Mahoney and B.~Yu},
  title =        {A Statistical Perspective on Algorithmic Leveraging},
  journal =      {Journal of Machine Learning Research},
  year =         {2015},
  volume =       {16},
  number =       {},
  pages =        {861--911},
}

@inproceedings{cohen2015lp,
  title={Lp row sampling by lewis weights},
  author={Cohen, Michael B and Peng, Richard},
  booktitle={Proceedings of the symposium on Theory of computing},
  pages={183--192},
  year={2015}
}

@article{DW15_TR,
  title={High-dimensional asymptotics of prediction: Ridge regression and classification},
  author={Dobriban, Edgar and Wager, Stefan},
  journal={The Annals of Statistics},
  volume={46},
  number={1},
  pages={247--279},
  year={2018},
  publisher={Institute of Mathematical Statistics}
}


@inproceedings{musco2022active,
  title={Active Linear Regression for lp Norms and Beyond},
  author={Musco, Cameron and Musco, Christopher and Woodruff, David P and Yasuda, Taisuke},
  booktitle={2022 IEEE 63rd Annual Symposium on Foundations of Computer Science (FOCS)},
  pages={744--753},
  year={2022},
  organization={IEEE}
}

@inproceedings{chen2021query,
  title={Query complexity of least absolute deviation regression via robust uniform convergence},
  author={Chen, Xue and Derezi\'nski, Micha{\l}},
  booktitle={Conference on Learning Theory},
  pages={1144--1179},
  year={2021},
  organization={PMLR}
}

@inproceedings{chen2022online,
  title={Online active regression},
  author={Chen, Cheng and Li, Yi and Sun, Yiming},
  booktitle={International Conference on Machine Learning},
  pages={3320--3335},
  year={2022},
  organization={PMLR}
}

@article{parulekar2021l1,
  title={L1 Regression with Lewis Weights Subsampling},
  author={Parulekar, Aditya and Parulekar, Advait and Price, Eric},
  journal={Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques},
  year={2021}
}

@TECHREPORT{asymptotic_RandNLA_estimators_TR,
  author =       {P. Ma and X. Zhang and  X. Xing  and J. Ma and M. W. Mahoney},
  title =        {Asymptotic Analysis of Sampling Estimators for Randomized Numerical Linear Algebra Algorithms},
  note =         {Preprint: arXiv:2002.10526},
  year =         {2020},
}

@ARTICLE{DMMS07_FastL2_NM10,
  author =       {P.~Drineas and M.~W.~Mahoney and S.~Muthukrishnan and T.~Sarl\'{o}s},
  title =        {Faster Least Squares Approximation},
  journal =      {Numerische Mathematik},
  year =         {2010},
  volume =       {117},
  number =       {2},
  pages =        {219--249},
}

@INPROCEEDINGS{BMD09_CSSP_SODA,
  author =       {C.~Boutsidis and M.~W.~Mahoney and P.~Drineas},
  title =        {An Improved Approximation Algorithm for the Column Subset Selection Problem},
  booktitle =    {Proceedings of the 20th Annual ACM-SIAM Symposium on Discrete Algorithms},
  year =         {2009},
  pages =        {968--977},
}

@article{drineas2006multiplication,
  author =       {P.~Drineas and R.~Kannan and M.~W.~Mahoney},
  title =        {Fast {Monte Carlo} Algorithms for Matrices {I}: Approximating Matrix Multiplication },
  journal =      {SIAM Journal on Computing},
  year =         {2006},
  volume =       {36},
  number =       {},
  pages =        {132--157},
}
  
@ARTICLE{dkm_matrix2,
  author =       {P.~Drineas and R.~Kannan and M.~W.~Mahoney},
  title =        {Fast {Monte Carlo} Algorithms for Matrices {II}: Computing a Low-Rank Approximation to a Matrix },
  journal =      {SIAM Journal on Computing},
  year =         {2006},
  volume =       {36},
  number =       {},
  pages =        {158--183},
}

@ARTICLE{dkm_matrix3,
  author =       {P.~Drineas and R.~Kannan and M.~W.~Mahoney},
  title =        {Fast {Monte Carlo} Algorithms for Matrices {III}: Computing a Compressed Approximate Matrix Decomposition },
  journal =      {SIAM Journal on Computing},
  year =         {2006},
  volume =       {36},
  number =       {},
  pages =        {184--206},
}


@article{Bach2003,
	author = {Bach, Francis R. and Jordan, Michael I.},
	title = {Kernel Independent Component Analysis},
	journal = {J. Mach. Learn. Res.},
	issue_date = {3/1/2003},
	volume = {3},
	month = mar,
	year = {2003},
	issn = {1532-4435},
	pages = {1--48},
	numpages = {48},
	acmid = {944920},
	publisher = {JMLR.org}
} 
@InProceedings{sparse-variational-gp,
  title = 	 {Rates of Convergence for Sparse Variational {G}aussian Process Regression},
  author = 	 {Burt, David and Rasmussen, Carl Edward and Van Der Wilk, Mark},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {862--871},
  year = 	 {2019},
}

@incollection{Williams01Nystrom,
title = {Using the {N}ystr\"{o}m Method to Speed Up Kernel Machines},
author = {Christopher K. I. Williams and Matthias Seeger},
booktitle = {Advances in Neural Information Processing Systems 13},
pages = {682--688},
year = {2001},
}

@article{nystrom1930,
author = {Nystr\"om, E. J.},
fjournal = "Acta Mathematica",
journal = "Acta Math.",
pages = "185--204",
publisher = "Institut Mittag-Leffler",
title = {\"{U}ber Die Praktische Aufl\"{o}sung von Integralgleichungen mit Anwendungen auf Randwertaufgaben},
volume = "54",
year = "1930"
}

@article{revisiting-nystrom,
 author = {Gittens, Alex and Mahoney, Michael W.},
 title = {Revisiting the {N}ystr\"{o}m Method for Improved Large-scale Machine Learning},
 journal = {J. Mach. Learn. Res.},
 volume = {17},
 number = {1},
 year = {2016},
 issn = {1532-4435},
 pages = {3977--4041},
 numpages = {65},
 acmid = {3007070},
 publisher = {JMLR.org},
 keywords = {Nystr\"{o}m approximation, kernel methods, low-rank approximation, numerical linear algebra, randomized algorithms},
} 

@techreport{MM18_TR,
  author = {C. H. Martin and M. W. Mahoney},
  title  = {Implicit Self-Regularization in Deep Neural Networks: Evidence from Random Matrix Theory and Implications for Learning},
  number = {Preprint: arXiv:1810.01075},
  year   = {2018}
}

@inproceedings{MM19_HTSR_ICML,
  author    = {C. H. Martin and M. W. Mahoney},
  title     = {Traditional and Heavy-Tailed Self Regularization in Neural Network Models},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  year      = {2019},
  pages     = {4284--4293}
}

@techreport{Ney17_TR,
  author = {B. Neyshabur},
  title  = {Implicit Regularization in Deep Learning},
  note   = {Preprint: arXiv:1709.01953},
  year   = {2017}
}

@article{surrogate-design,
  title={Exact expressions for double descent and implicit regularization via surrogate random design},
  author={Derezi{\'n}ski, Micha{\l} and Liang, Feynman T and Mahoney, Michael W},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={5152--5164},
  year={2020}
}

@article{Borcea09,
  title={Negative dependence and the geometry of polynomials},
  author={Borcea, Julius and Br{\"a}nd{\'e}n, Petter and Liggett, Thomas},
  journal={Journal of the American Mathematical Society},
  volume={22},
  number={2},
  pages={521--567},
  year={2009}
}

@article{johnson-lindenstrauss,
  title={Extensions of {L}ipschitz mappings into a {H}ilbert space},
  author={Johnson, William B and Lindenstrauss, Joram},
  journal={Contemporary mathematics},
  volume={26},
  number={189-206},
  pages={1},
  year={1984}
}

@article{achlioptas2003,
  title={Database-friendly random projections: {J}ohnson-{L}indenstrauss with binary coins},
  author={Achlioptas, Dimitris},
  journal={Journal of computer and System Sciences},
  volume={66},
  number={4},
  pages={671--687},
  year={2003},
  publisher={Elsevier}
}

@article{poulson2020,
  title={High-performance sampling of generic determinantal point processes},
  author={Poulson, Jack},
  journal={Philosophical Transactions of the Royal Society A},
  volume={378},
  number={2166},
  pages={20190059},
  year={2020},
}

@inproceedings{nystrom-multiple-descent,
  title={Improved guarantees and a multiple-descent curve for the Column Subset Selection Problem and the Nystr\"om method}, 
  author={Derezi{\'n}ski, Micha{\l} and Khanna, Rajiv and Mahoney, Michael W},
  booktitle = {Advances in Neural Information Processing Systems},
  volume = {33},
 pages = {4953--4964},
  year={2020}
}

@INPROCEEDINGS{Mah12,
  author =       {M.~W.~Mahoney},
  title =        {Approximate Computation and Implicit Regularization for Very Large-scale Data Analysis},
  booktitle =    {Proceedings of the 31st ACM Symposium on Principles of Database Systems},
  year =         {2012},
  pages =        {143--154},
}

@ARTICLE{BHMM19,
  author =       {M. Belkin and D. Hsu and S. Ma and S. Mandal},
  title =        {Reconciling modern machine learning practice and the classical bias-variance trade-off},
  journal =      {Proc. Natl. Acad. Sci. USA},
  year =         {2019},
  volume =       {116},
  number =       {},
  pages =        {15849--15854},
}

@incollection{determinantal-averaging,
title = {Distributed estimation of the inverse {H}essian by determinantal averaging},
author = {Derezi\'{n}ski, Micha{\l} and Mahoney, Michael W},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {11401--11411},
year = {2019},
}

@article {belabbas-wolfe09,
	author = {Belabbas, Mohamed-Ali and Wolfe, Patrick J.},
	title = {Spectral methods in machine learning and new strategies for very large datasets},
	volume = {106},
	number = {2},
	pages = {369--374},
	year = {2009},
	doi = {10.1073/pnas.0810600105},
	publisher = {National Academy of Sciences},
	issn = {0027-8424},
	journal = {Proceedings of the National Academy of Sciences}
}

@article{fanuel2020diversity,
  title={Diversity sampling is an implicit regularization for kernel methods},
  author={Fanuel, Micha{\"e}l and Schreurs, Joachim and Suykens, Johan AK},
  journal={arXiv:2002.08616},
  year={2020}
}

@article{alpha-dpp,
  title={Sampling from a k-DPP without looking at all items},
  author={Calandriello, Daniele and Derezinski, Michal and Valko, Michal},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6889--6899},
  year={2020}
}

@article{isotropy-log-concave,
       author = {Anari, Nima and Derezi{\'n}ski, Micha{\l}},
        title = "{Isotropy and Log-Concave Polynomials: Accelerated Sampling and High-Precision Counting of Matroid Bases}",
	journal = {Proceedings of the 61st Annual Symposium on Foundations of Computer Science},
        year = "2020",
}

@inproceedings{anari2019log,
  title={Log-concave polynomials {II}: high-dimensional walks and an FPRAS for counting bases of a matroid},
  author={Anari, Nima and Liu, Kuikui and Gharan, Shayan Oveis and Vinzant, Cynthia},
  booktitle={Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing},
  pages={1--12},
  year={2019}
}

@article{belhadji2020kernel,
  title={Kernel interpolation with continuous volume sampling},
  author={Belhadji, Ayoub and Bardenet, R{\'e}mi and Chainais, Pierre},
  journal={arXiv preprint arXiv:2002.09677},
  year={2020}
}

@article{bornemann2010numerical,
  title={On the numerical evaluation of {F}redholm determinants},
  author={Bornemann, Folkmar},
  journal={Mathematics of Computation},
  volume={79},
  number={270},
  pages={871--915},
  year={2010}
}

@article{barthelme2020determinantal,
  title={Determinantal Point Processes in the Flat Limit: Extended {L}-ensembles, Partial-Projection DPPs and Universality Classes},
  author={Barthelm{\'e}, Simon and Tremblay, Nicolas and Usevich, Konstantin and Amblard, Pierre-Olivier},
  journal={arXiv preprint arXiv:2007.04117},
  year={2020}
}

@article{gower2021adaptive,
  title={On adaptive sketch-and-project for solving linear systems},
  author={Gower, Robert M and Molitor, Denali and Moorman, Jacob and Needell, Deanna},
  journal={SIAM Journal on Matrix Analysis and Applications},
  volume={42},
  number={2},
  pages={954--989},
  year={2021},
  publisher={SIAM}
}

@article{rebrova2021block,
  title={On block {G}aussian sketching for the Kaczmarz method},
  author={Rebrova, Elizaveta and Needell, Deanna},
  journal={Numerical Algorithms},
  volume={86},
  pages={443--473},
  year={2021},
  publisher={Springer}
}

@article{yuan2022sketched,
  title={Sketched Newton--Raphson},
  author={Yuan, Rui and Lazaric, Alessandro and Gower, Robert M},
  journal={SIAM Journal on Optimization},
  volume={32},
  number={3},
  pages={1555--1583},
  year={2022},
  publisher={SIAM}
}

@inproceedings{hanzely2020stochastic,
  title={Stochastic subspace cubic Newton method},
  author={Hanzely, Filip and Doikov, Nikita and Nesterov, Yurii and Richtarik, Peter},
  booktitle={International Conference on Machine Learning},
  pages={4027--4038},
  year={2020},
  organization={PMLR}
}

@article{martinsson2020randomized,
  title={Randomized numerical linear algebra: Foundations and algorithms},
  author={Martinsson, Per-Gunnar and Tropp, Joel A},
  journal={Acta Numerica},
  volume={29},
  pages={403--572},
  year={2020},
  publisher={Cambridge University Press}
}

@article{tropp2011structure,
  title={Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions},
  author={Halko, Nathan and Martinsson, Per-Gunnar and Tropp, Joel A},
  journal={SIAM review},
  volume={53},
  number={2},
  pages={217--288},
  year={2011},
  publisher={SIAM}
}

@article{debiasing-second-order,
  title={Debiasing distributed second order optimization with surrogate sketching and scaled regularization},
  author={Derezi{\'n}ski, Micha{\l} and Bartan, Burak and Pilanci, Mert and Mahoney, Michael W},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={6684--6695},
  year={2020}
}

@inproceedings{gaussianization,
  title={Algorithmic gaussianization through sketching: Converting data into sub-gaussian random designs},
  author={Derezi{\'n}ski, Micha{\l}},
  booktitle={The Thirty Sixth Annual Conference on Learning Theory},
  pages={3137--3172},
  year={2023},
  organization={PMLR}
}

@article{pilanci2017newton,
  title={Newton sketch: A near linear-time optimization algorithm with linear-quadratic convergence},
  author={Pilanci, Mert and Wainwright, Martin J},
  journal={SIAM Journal on Optimization},
  volume={27},
  number={1},
  pages={205--245},
  year={2017},
  publisher={SIAM}
}

@article{gower2015randomized,
  title={Randomized iterative methods for linear systems},
  author={Gower, Robert M and Richt{\'a}rik, Peter},
  journal={SIAM Journal on Matrix Analysis and Applications},
  volume={36},
  number={4},
  pages={1660--1690},
  year={2015},
  publisher={SIAM}
}

@article{newton-less,
  title={Newton-LESS: Sparsification without Trade-offs for the Sketched Newton Update},
  author={Derezi\'nski, Micha{\l} and Lacotte, Jonathan and Pilanci, Mert and Mahoney, Michael W},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={2835--2847},
  year={2021}
}

@inproceedings{less-embeddings,
  title={Sparse sketches with small inversion bias},
  author={Derezi\'nski, Micha{\l} and Liao, Zhenyu and Dobriban, Edgar and Mahoney, Michael},
  booktitle={Conference on Learning Theory},
  pages={1467--1510},
  year={2021},
  organization={PMLR}
}

@article{precise-expressions,
  title={Precise expressions for random projections: Low-rank approximation and randomized Newton},
  author={Derezi{\'n}ski, Micha{\l} and Liang, Feynman T and Liao, Zhenyu and Mahoney, Michael W},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@TECHREPORT{ZM21_hessian_TR,
  author =       {Z. Liao and M. W. Mahoney},
  title =        {Hessian Eigenspectra of More Realistic Nonlinear Models},
  number =       {Preprint: arXiv:2103.01519},
  year =         {2021},
}

@TECHREPORT{ZCM20_quantized_TR,
  author =       {Z. Liao and R. Couillet and M. W. Mahoney},
  title =        {Sparse Quantized Spectral Clustering},
  number =       {Preprint: arXiv:2010.01376},
  year =         {2020},
}

@article{berahas2020investigation,
  title={An investigation of Newton-sketch and subsampled Newton methods},
  author={Berahas, Albert S and Bollapragada, Raghu and Nocedal, Jorge},
  journal={Optimization Methods and Software},
  volume={35},
  number={4},
  pages={661--680},
  year={2020},
  publisher={Taylor \& Francis}
}


@article{dobriban2021distributed,
  title={Distributed linear regression by averaging},
  author={Dobriban, Edgar and Sheng, Yue},
  journal={The Annals of Statistics},
  volume={49},
  number={2},
  pages={918--943},
  year={2021},
  publisher={Institute of Mathematical Statistics}
}
@article{rudelson2013hanson,
  title     = { {Hanson-Wright} inequality and sub-gaussian concentration},
  author    = {Rudelson, Mark and Vershynin, Roman},
  journal   = {Electronic Communications in Probability},
  volume    = {18},
  year      = {2013},
  publisher = {The Institute of Mathematical Statistics and the Bernoulli Society}
}

@inproceedings{rudelson2010non,
  title={Non-asymptotic theory of random matrices: extreme singular values},
  author={Rudelson, Mark and Vershynin, Roman},
  booktitle={Proceedings of the International Congress of Mathematicians 2010 (ICM 2010) (In 4 Volumes) Vol. I: Plenary Lectures and Ceremonies Vols. II--IV: Invited Lectures},
  pages={1576--1602},
  year={2010},
  organization={World Scientific}
}

@inproceedings{feng2021non,
  title={Non-PSD matrix sketching with applications to regression and optimization},
  author={Feng, Zhili and Roosta, Fred and Woodruff, David P},
  booktitle={Uncertainty in Artificial Intelligence},
  pages={1841--1851},
  year={2021},
  organization={PMLR}
}

@article{dobriban2020wonder,
  title={WONDER: Weighted One-shot Distributed Ridge Regression in High Dimensions},
  author={Dobriban, Edgar and Sheng, Yue},
  journal={J. Mach. Learn. Res.},
  volume={21},
  number={66},
  pages={1--52},
  year={2020}
}

@article{yang2020reduce,
  title={How to reduce dimension with PCA and random projections?},
  author={Yang, Fan and Liu, Sifan and Dobriban, Edgar and Woodruff, David P},
  journal={arXiv preprint arXiv:2005.00511},
  year={2020}
}

@inproceedings{lejeune2020implicit,
  title={The implicit regularization of ordinary least squares ensembles},
  author={LeJeune, Daniel and Javadi, Hamid and Baraniuk, Richard},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3525--3535},
  year={2020},
  organization={PMLR}
}
@article{paschou2007pca,
  title={PCA-correlated SNPs for structure identification in worldwide human populations},
  author={Paschou, Peristera and Ziv, Elad and Burchard, Esteban G and Choudhry, Shweta and Rodriguez-Cintron, William and Mahoney, Michael W and Drineas, Petros},
  journal={PLoS Genet},
  volume={3},
  number={9},
  pages={e160},
  year={2007},
  publisher={Public Library of Science}
}

@article{konecny2016federated1,
  title={Federated optimization: Distributed machine learning for on-device intelligence},
  author={Konecn{\`y}, Jakub and McMahan, H Brendan and Ramage, Daniel and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:1610.02527},
  year={2016}
}

@article{konecny2016federated2,
  title={Federated learning: Strategies for improving communication efficiency},
  author={Konecn{\`y}, Jakub and McMahan, H Brendan and Yu, Felix X and Richt{\'a}rik, Peter and Suresh, Ananda Theertha and Bacon, Dave},
  journal={arXiv preprint arXiv:1610.05492},
  year={2016}
}

@inproceedings{cohen2016nearly,
  title={Nearly tight oblivious subspace embeddings by trace inequalities},
  author={Cohen, Michael B},
  booktitle={Proceedings of the twenty-seventh annual ACM-SIAM symposium on Discrete algorithms},
  pages={278--287},
  year={2016},
  organization={SIAM}
}

@article{mahoney2009cur,
  title={CUR matrix decompositions for improved data analysis},
  author={Mahoney, Michael W and Drineas, Petros},
  journal={Proceedings of the National Academy of Sciences},
  volume={106},
  number={3},
  pages={697--702},
  year={2009},
  publisher={National Acad Sciences}
}

@article{double-descent-condition,
  title   = {Double descent in the condition number},
  author  = {Tomaso Poggio and Gil Kur and Andrzej Banburski},
  year    = {2019},
  journal = {arXiv preprint, arXiv:1912.06190}
}

@article{liang2020multiple,
  title   = {On the Multiple Descent of Minimum-Norm Interpolants and Restricted Lower Isometry of Kernels},
  author  = {Liang, Tengyuan and Rakhlin, Alexander and Zhai, Xiyu},
  journal = {arXiv preprint arXiv:1908.10292 [cs, math, stat]},
  year    = {2020}
}

@techreport{BLLT19_TR,
  author = {P. L. Bartlett and P. M. Long and G. Lugosi and A. Tsigler},
  title  = {Benign Overfitting in Linear Regression},
  number = {Preprint: arXiv:1906.11300},
  year   = {2019}
}

@article{dpps-in-randnla,
  title={Determinantal Point Processes in Randomized Numerical Linear Algebra},
  author={Derezi{\'n}ski, Micha{\l} and Mahoney, Michael W},
  journal = {Notices of the American Mathematical Society},
  year    = {2021},
  volume  = {68},
  number  = {1},
  pages   = {34-45},
}

@BOOK{MotwaniRaghavan95,
  author =       {R. Motwani and P. Raghavan},
  title =        {Randomized Algorithms},
  publisher =    {Cambridge University Press},
  year =         {1995},
  address =      {New York},
  series =       {},
}

@article{lopes2019bootstrap,
  title={A bootstrap method for error estimation in randomized matrix multiplication},
  author={Lopes, Miles E and Wang, Shusen and Mahoney, Michael W},
  journal={The Journal of Machine Learning Research},
  volume={20},
  number={1},
  pages={1434--1473},
  year={2019},
  publisher={JMLR. org}
}

@ARTICLE{CDMMMW16,
  author =       {K. L. Clarkson and P. Drineas and M. Magdon-Ismail and M. W. Mahoney and X. Meng and D. P. Woodruff},
  title =        {The {F}ast {C}auchy {T}ransform and Faster Robust Linear Regression},
  journal =      {SIAM Journal on Computing},
  year =         {2016},
  volume =       {45},
  number =       {},
  pages =        {763--810},
}

@ARTICLE{YMM14_SISC,
  author =       {J. Yang and X. Meng and M.~W.~Mahoney},
  title =        {Quantile Regression for Large-scale Applications},
  journal =      {SIAM Journal on Scientific Computing},
  year =         {2014},
  volume =       {36},
  number =       {},
  pages =        {S78--S110},
}

@TECHREPORT{XYRRM16_TR,
  author =       {P. Xu and J. Yang and F. Roosta-Khorasani and C. Re and M. W. Mahoney},
  title =        {Sub-sampled {N}ewton Methods with Non-uniform Sampling},
  number =       {Preprint: arXiv:1607.00559},
  year =         {2016},
}

@article{PW16_IHS,
  author  = {M. Pilanci and M. J. Wainwright},
  title   = {Iterative {H}essian Sketch: Fast and Accurate Solution Approximation for Constrained Least-Squares},
  journal = {Journal of Machine Learning Research},
  year    = {2016},
  volume  = {17},
  number  = {53},
  pages   = {1-38},
}

@BOOK{NW06,     
  author =       {J. Nocedal and S. Wright},
  title =        {Numerical Optimization},
  publisher =    {Springer},
  year =         {2006},
  address =      {New York},
  series =       {},
}

@TECHREPORT{inexactNewtonCG_TR,
  author =       {Z. Yao and P. Xu and F. Roosta and S. J. Wright and M. W. Mahoney},
  title =        {Inexact {Newton-CG} Algorithms With Complexity Guarantees},
  number =       {Preprint: arXiv:2109.14016}, 
  year =         {2021},
}

@TECHREPORT{fred_newtonMR_TR,
  author =       {F. Roosta and Y. Liu and P. Xu and M. W. Mahoney},
  title =        {{Newton-MR}: {N}ewton's Method Without Smoothness or Convexity},
  number =       {Preprint: arXiv:1810.00303},
  year =         {2018},
}

@TECHREPORT{fred_gpu1_TR,
  author =       {S. B. Kylasa and F. Roosta-Khorasani and M. W. Mahoney and A. Grama},
  title =        {{GPU} Accelerated Sub-Sampled {N}ewton's Method},
  number =       {Preprint: arXiv:1802.09113}, 
  year =         {2018},
}

@TECHREPORT{YXRM18_TR,
  author =       {Z. Yao and P. Xu and F. Roosta-Khorasani and M. W. Mahoney},
  title =        {Inexact Non-Convex {N}ewton-Type Methods},
  number =       {Preprint: arXiv:1802.06925},
  year =         {2018},
}

@TECHREPORT{XRM17_empirical_TR,
  author =       {P. Xu and F. Roosta-Khorasani and M. W. Mahoney},
  title =        {Second-Order Optimization for Non-Convex Machine Learning: An Empirical Study},
  number =       {Preprint: arXiv:1708.07827},
  year =         {2017},
}

@TECHREPORT{XRM17_theory_TR,
  author =       {P. Xu and F. Roosta-Khorasani and M. W. Mahoney},
  title =        {Newton-Type Methods for Non-Convex Optimization Under Inexact {H}essian Information},
  number =       {Preprint: arXiv:1708.07164}, 
  year =         {2017},
}

@TECHREPORT{NewtonADMM_TR,
  author =       {C.-H. Fang and S. B. Kylasa and F. Roosta and M. W. Mahoney and A. Grama},
  title =        {Newton-{ADMM}: A Distributed {GPU}-Accelerated Optimizer for Multiclass Classification Problems},
  number =       {Preprint: arXiv:1807.07132},
  year =         {2018},
}


@TECHREPORT{TrustAttack18_TR,
  author =       {Z. Yao and A. Gholami and P. Xu and K. Keutzer and M. W. Mahoney},
  title =        {Trust Region Based Adversarial Attack on Neural Networks},
  number =       {Preprint: arXiv:1812.06371},
  year =         {2018},
}

@TECHREPORT{failure21_TR,
  author =       {A. S. Krishnapriyan and A. Gholami and S. Zhe and R. M. Kirby and M. W. Mahoney},
  title =        {Characterizing possible failure modes in physics-informed neural networks},
  number =       {Preprint: arXiv:2109.01050},
  year =         {2021},
}

@article{EdwCACM22,
  author =       {C. Edwards},
  title =        {Neural Networks Learn to Speed Up Simulations},
  journal =      {Communications of the ACM},
  year =         {2022},
  volume =       {65},
  number =       {5},
  pages =        {27--29},
}

@TECHREPORT{Erichson_Shallow_19_TR,
  author =       {N. B. Erichson and L. Mathelin and Z. Yao and S. L. Brunton and M. W. Mahoney and J. N. Kutz},
  title =        {Shallow Learning for Fluid Flow Reconstruction with Limited Sensors and Limited Data},
  number =       {Preprint: arXiv:1902.07358},
  year =         {2019},
}

@TECHREPORT{ssqp1_TR22,
  author =       {S. Na and M. W. Mahoney},
  title =        {Asymptotic Convergence Rate and Statistical Inference for Stochastic Sequential Quadratic Programming},
  number =       {Preprint: arXiv:2205.13687},
  year =         {2022},
}

@TECHREPORT{MonoDDGP_TR22,
  author =       {L. Hodgkinson and C. van~der~Heide and F. Roosta and M. W. Mahoney},
  title =        {Monotonicity and Double Descent in Uncertainty Estimation with {G}aussian Processes},
  number =       {Preprint: arXiv:2210.07612},
  year =         {2022},
}

@inproceedings{braverman2020near,
  title={Near optimal linear algebra in the online and sliding window models},
  author={Braverman, Vladimir and Drineas, Petros and Musco, Cameron and Musco, Christopher and Upadhyay, Jalaj and Woodruff, David P and Zhou, Samson},
  booktitle={2020 IEEE 61st Annual Symposium on Foundations of Computer Science (FOCS)},
  pages={517--528},
  year={2020},
  organization={IEEE}
}

@article{jin2021faster,
  title={Faster johnson--lindenstrauss transforms via kronecker products},
  author={Jin, Ruhui and Kolda, Tamara G and Ward, Rachel},
  journal={Information and Inference: A Journal of the IMA},
  volume={10},
  number={4},
  pages={1533--1562},
  year={2021},
  publisher={Oxford University Press}
}

@article{erichson2020randomized,
  title={Randomized CP tensor decomposition},
  author={Erichson, N Benjamin and Manohar, Krithika and Brunton, Steven L and Kutz, J Nathan},
  journal={Machine Learning: Science and Technology},
  volume={1},
  number={2},
  pages={025012},
  year={2020},
  publisher={IOP Publishing}
}

@article{li2017near,
  title={Near optimal sketching of low-rank tensor regression},
  author={Li, Xingguo and Haupt, Jarvis and Woodruff, David},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017}
}

@article{wang2015fast,
  title={Fast and guaranteed tensor decomposition via sketching},
  author={Wang, Yining and Tung, Hsiao-Yu and Smola, Alexander J and Anandkumar, Anima},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}


@article{raissi2019physics,
  title={Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
  author={Raissi, Maziar and Perdikaris, Paris and Karniadakis, George E},
  journal={Journal of Computational Physics},
  volume={378},
  pages={686--707},
  year={2019},
  publisher={Elsevier}
}

@BOOK{Vershynin18,
  author =       {R.~Vershynin},
  title =        {High-Dimensional Probability: An Introduction with Applications in Data Science},
  publisher =    {Cambridge University Press},
  year =         {2018},
  address =      {},
  series =       {},
}

@TECHREPORT{lem21_TR,
  author =       {T. K. Rusch and S. Mishra and N. B. Erichson and M. W. Mahoney},
  title =        {Long Expressive Memory for Sequence Modeling},
  number =       {Preprint: arXiv:2007.04744},
  year =         {2021},
}

@TECHREPORT{randlapack_book_v0_lawn,
  author =       {R. Murray and J. Demmel and M. W. Mahoney and N. B. Erichson and M. Melnichenko and O. A. Malik and L. Grigori and M. Derezi{\'n}ski and M. E. Lopes and T. Liang and H. Luo},
  title =        {{Randomized Numerical Linear Algebra} -- A Perspective on the Field with an Eye to Software},
  number =       {arXiv preprint arXiv:2302.11474},
  year =         {2022},
}

@article{randlapack_book_v1,
  title={Randomized numerical linear algebra: A perspective on the field with an eye to software},
  author={Murray, Riley and Demmel, James and Mahoney, Michael W and Erichson, N Benjamin and Melnichenko, Maksim and Malik, Osman Asif and Grigori, Laura and Luszczek, Piotr and Derezi{\'n}ski, Micha{\l} and Lopes, Miles E and others},
  journal={arXiv preprint arXiv:2302.11474},
  year={2023}
}


@article{WLMD15_TR_JRNL,
  author  = {R. Wang and Y. Li and M. W. Mahoney and E. Darve},
  title   = {{S}tructured {B}lock {B}asis {F}actorization for Scalable Kernel Matrix Evaluation},
  journal = {SIAM Journal on Matrix Analysis and Applications},
  year    = {2019},
  volume  = {40},
  number  = {4},
  pages   = {1497--1526},
}

@ARTICLE{CGMR05,
  author =       {H.~Cheng and Z.~Gimbutas and P.-G.~Martinsson and V.~Rokhlin},
  title =        {On the Compression of Low Rank Matrices},
  journal =      {SIAM Journal on Scientific Computing},
  year =         {2005},
  volume =       {26},
  number =       {4},
  pages =        {1389--1404},
}

@ARTICLE{fred_SSN_JRNL,
  author =       {F. Roosta-Khorasani and M. W. Mahoney},
  title =        {Sub-Sampled {N}ewton Methods},
  journal =      {Mathematical Programming},
  year =         {2019},
  volume =       {174},
  number =       {1-2},
  pages =        {293--326},
}

@ARTICLE{HOG15,
  author =       {P. Hennig and M. A. Osborne and M. Girolami},
  title =        {Probabilistic numerics and uncertainty in computations},
  journal =      {Proceedings of the Royal Society A},
  year =         {2015},
  volume =       {471},
  number =       {2179},
  pages =        {},
}


@TECHREPORT{differentiable_hard_22_TR,
  author =       {G. Negiar and M. W. Mahoney and A. S. Krishnapriyan},
  title =        {Learning differentiable solvers for systems with hard constraints},
  number =       {Preprint: arXiv:2207.08675},
  year =         {2022},
}

@article{oymak2018universality,
  title={Universality laws for randomized dimension reduction, with applications},
  author={Oymak, Samet and Tropp, Joel A},
  journal={Information and Inference: A Journal of the IMA},
  volume={7},
  number={3},
  pages={337--446},
  year={2018},
  publisher={Oxford University Press}
}

@article{cho2023surrogate,
  title={Surrogate-based Autotuning for Randomized Sketching Algorithms in Regression Problems},
  author={Cho, Younghyun and Demmel, James W and Derezi{\'n}ski, Micha{\l} and Li, Haoyun and Luo, Hengrui and Mahoney, Michael W and Murray, Riley J},
  journal={arXiv preprint arXiv:2308.15720},
  year={2023}
}

@article{pilanci2015randomized,
  title={Randomized sketches of convex programs with sharp guarantees},
  author={Pilanci, Mert and Wainwright, Martin J},
  journal={IEEE Transactions on Information Theory},
  volume={61},
  number={9},
  pages={5096--5115},
  year={2015},
  publisher={IEEE}
}

@inproceedings{chenakkod2023optimal,
  title={Optimal Embedding Dimension for Sparse Subspace Embeddings},
  author={Chenakkod, Shabarish and Derezi{\'n}ski, Micha{\l} and Dong, Xiaoyu and Rudelson, Mark},
  booktitle={56th Annual ACM Symposium on Theory of Computing},
  year={2024}
}

@article{needell2014stochastic,
  title={Stochastic gradient descent, weighted sampling, and the randomized Kaczmarz algorithm},
  author={Needell, Deanna and Ward, Rachel and Srebro, Nati},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@inproceedings{lee2013efficient,
  title={Efficient accelerated coordinate descent methods and faster algorithms for solving linear systems},
  author={Lee, Yin Tat and Sidford, Aaron},
  booktitle={2013 ieee 54th annual symposium on foundations of computer science},
  pages={147--156},
  year={2013},
  organization={IEEE}
}

@inproceedings{gonen2016solving,
  title={Solving ridge regression using sketched preconditioned svrg},
  author={Gonen, Alon and Orabona, Francesco and Shalev-Shwartz, Shai},
  booktitle={International conference on machine learning},
  pages={1397--1405},
  year={2016},
  organization={PMLR}
}

@inproceedings{gower2018tracking,
  title={Tracking the gradients using the hessian: A new look at variance reducing stochastic methods},
  author={Gower, Robert and Le Roux, Nicolas and Bach, Francis},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={707--715},
  year={2018},
  organization={PMLR}
}

@inproceedings{liu2019acceleration,
  title={Acceleration of svrg and katyusha x by inexact preconditioning},
  author={Liu, Yanli and Feng, Fei and Yin, Wotao},
  booktitle={International Conference on Machine Learning},
  pages={4003--4012},
  year={2019},
  organization={PMLR}
}

@article{roosta2019sub,
  title={Sub-sampled Newton methods},
  author={Roosta-Khorasani, Farbod and Mahoney, Michael W},
  journal={Mathematical Programming},
  volume={174},
  number={1},
  pages={293--326},
  year={2019},
  publisher={Springer}
}

@article{bollapragada2018exact,
  title={Exact and inexact subsampled Newton methods for optimization},
  author={Bollapragada, Raghu and Byrd, Richard H and Nocedal, Jorge},
  journal={IMA Journal of Numerical Analysis},
  volume={39},
  number={2},
  year={2018},
  publisher={Northwestern Univ., Evanston, IL (United States)}
}

@article{kovalev2019stochastic,
  title={Stochastic Newton and cubic Newton methods with simple local linear-quadratic rates},
  author={Kovalev, Dmitry and Mishchenko, Konstantin and Richt{\'a}rik, Peter},
  journal={arXiv preprint arXiv:1912.01597},
  year={2019}
}

@article{mokhtari2018iqn,
  title={IQN: An incremental quasi-Newton method with local superlinear convergence rate},
  author={Mokhtari, Aryan and Eisen, Mark and Ribeiro, Alejandro},
  journal={SIAM Journal on Optimization},
  volume={28},
  number={2},
  pages={1670--1698},
  year={2018},
  publisher={SIAM}
}

@inproceedings{meyer2021hutch++,
  title={Hutch++: Optimal stochastic trace estimation},
  author={Meyer, Raphael A and Musco, Cameron and Musco, Christopher and Woodruff, David P},
  booktitle={Symposium on Simplicity in Algorithms (SOSA)},
  pages={142--155},
  year={2021},
  organization={SIAM}
}

@inproceedings{yao2020pyhessian,
  title={Pyhessian: Neural networks through the lens of the hessian},
  author={Yao, Zhewei and Gholami, Amir and Keutzer, Kurt and Mahoney, Michael W},
  booktitle={2020 IEEE international conference on big data (Big data)},
  pages={581--590},
  year={2020},
  organization={IEEE}
}

@article{kaczmarz37,
 title={Angenaherte Auflosung von Systemen linearer Gleichungen},
author={M. S. Kaczmarz},
journal={Bulletin International de l’Academie Polonaise des Sciences et des Lettres},
publisher={Classe des Sciences Mathematiques et Naturelles. Serie A, Sciences Mathematiques},
volume={35},
year={1937}, 
pages={355–357},
}

@article{strohmer2009randomized,
  title={A randomized {K}aczmarz algorithm with exponential convergence},
  author={Strohmer, Thomas and Vershynin, Roman},
  journal={Journal of Fourier Analysis and Applications},
  volume={15},
  number={2},
  pages={262--278},
  year={2009},
  publisher={Springer}
}

@article{needell2014paved,
  title={Paved with good intentions: analysis of a randomized block Kaczmarz method},
  author={Needell, Deanna and Tropp, Joel A},
  journal={Linear Algebra and its Applications},
  volume={441},
  pages={199--221},
  year={2014},
  publisher={Elsevier}
}

@article{leventhal2010randomized,
  title={Randomized methods for linear constraints: convergence rates and conditioning},
  author={Leventhal, Dennis and Lewis, Adrian S},
  journal={Mathematics of Operations Research},
  volume={35},
  number={3},
  pages={641--654},
  year={2010},
  publisher={INFORMS}
}

@article{needell2013two,
  title={Two-subspace projection method for coherent overdetermined systems},
  author={Needell, Deanna and Ward, Rachel},
  journal={Journal of Fourier Analysis and Applications},
  volume={19},
  number={2},
  pages={256--269},
  year={2013},
  publisher={Springer}
}

@article{gower2018accelerated,
  title={Accelerated stochastic matrix inversion: general theory and speeding up BFGS rules for faster second-order optimization},
  author={Gower, Robert and Hanzely, Filip and Richt{\'a}rik, Peter and Stich, Sebastian U},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{richtarik2020stochastic,
  title={Stochastic reformulations of linear systems: algorithms and convergence theory},
  author={Richt{\'a}rik, Peter and Tak{\'a}c, Martin},
  journal={SIAM Journal on Matrix Analysis and Applications},
  volume={41},
  number={2},
  pages={487--524},
  year={2020},
  publisher={SIAM}
}

@article{rk20,
  title={A randomized coordinate descent method with volume sampling},
  author={Rodomanov, Anton and Kropotov, Dmitry},
  journal={SIAM Journal on Optimization},
  volume={30},
  number={3},
  pages={1878--1904},
  year={2020},
  publisher={SIAM}
}


@ARTICLE{MM18_TR_JMLRversion,
  author =       {C. H. Martin and M. W. Mahoney},
  title =        {Implicit Self-Regularization in Deep Neural Networks: Evidence from Random Matrix Theory and Implications for Learning},
  journal =      {Journal of Machine Learning Research},
  year =         {2021},
  volume =       {22},
  number =       {165},
  pages =        {1--73},
}

@article{wang2018sketched,
  author  = {S. Wang and A. Gittens and M. W. Mahoney},
  title   = {Sketched Ridge Regression: Optimization Perspective, Statistical Perspective, and Model Averaging},
  journal = {Journal of Machine Learning Research},
  year    = {2018},
  volume  = {18},
  number  = {218},
  pages   = {1--50},
}

@TECHREPORT{KGC17_TR,
  author =    {J. Kukacka and V. Golkov and D. Cremers},
  title =     {Regularization for Deep Learning: A Taxonomy},
  number =    {Preprint: arXiv:1710.10686},
  year =      {2017},
}

@TECHREPORT{Mah16_RLA_TR,
  author =       {M. W. Mahoney},
  title =        {Lecture Notes on Randomized Linear Algebra},
  number =       {Preprint: arXiv:1608.04481}, 
  year =         {2016},
}

@INPROCEEDINGS{FKV98,
  author =       {A. Frieze and R. Kannan and S. Vempala},
  title =        {Fast {Monte-Carlo} algorithms for finding low-rank approximations},
  booktitle =    {Proceedings of the 39th Annual IEEE Symposium on Foundations of Computer Science},
  year =         {1998},
  pages =        {370--378},
}

@ARTICLE{RV07,
  author =       {M.~Rudelson and R.~Vershynin}, 
  title =        {Sampling from large matrices: an approach through geometric functional analysis},
  journal =      {Journal of the ACM},
  year =         {2007},
  volume =       {54},
  number =       {4},
  pages =        {Article 21},
}

@ARTICLE{RST09,
  author =       {V.~Rokhlin and A.~Szlam and M.~Tygert},
  title =        {A randomized algorithm for principal component analysis},
  journal =      {SIAM Journal on Matrix Analysis and Applications},
  year =         {2009},
  volume =       {31},
  number =       {3},
  pages =        {1100--1124},
}

@TECHREPORT{DM10_TR,
  author =       {P.~Drineas and M.W.~Mahoney},
  title =        {Effective Resistances, Statistical Leverage, and Applications to Linear Equation Solving},
  note =         {Preprint: arXiv:1005.3097 (2010)},
}

@BOOK{TroppMatrixConcIneqBOOK2015,
  author =       {J.~A.~Tropp},
  title =        {An introduction to matrix concentration inequalities},
  publisher =    {NOW Publishers},
  year =         {2015},
  address =      {Boston},
  series =       {Foundations and Trends in Machine Learning},
}

@INCOLLECTION{Martinsson_PCMIchapter_chapter,
  author =       {P.-G.~Martinsson},
  title =        {Randomized methods for matrix computations},
  booktitle =    {The Mathematics of Data},
  year =         {2018},
  pages =        {187--230},
  editor =       {M. W. Mahoney and J. C. Duchi and A. C. Gilbert},
  series =       {IAS/Park City Mathematics Series},
  publisher =    {AMS/IAS/SIAM},
}

@ARTICLE{DIKM19_SIMAX,
  author =       {P. Drineas and I. Ipsen and E. Kontopoulou and M. Magdon-Ismail},
  title =        {Structural Convergence Results for Approximations of Dominant Subspaces from Block {K}rylov Spaces},
  journal =      {SIAM Journal on Matrix Analysis and Applications},
  year =         {2018},
  volume =       {39},
  number =       {},
  pages =        {567--586},
}
 
@TECHREPORT{BCIH18_TR,
  author =       {S. Bartels and J. Cockayne and I. C. F. Ipsen and P. Hennig},
  title =        {Probabilistic Linear Solvers: A Unifying View},
  number =       {Preprint: arXiv:1810.03398},
  year =         {2018},
}

