\begin{thebibliography}{10}

\bibitem{abadi2016deep}
Martin Abadi, Andy Chu, Ian Goodfellow, H~Brendan McMahan, Ilya Mironov, Kunal
  Talwar, and Li~Zhang.
\newblock Deep learning with differential privacy.
\newblock In {\em Proceedings of the 2016 ACM SIGSAC conference on computer and
  communications security}, pages 308--318, 2016.

\bibitem{amid2022public}
Ehsan Amid, Arun Ganesh, Rajiv Mathews, Swaroop Ramaswamy, Shuang Song, Thomas
  Steinke, Vinith~M Suriyakumar, Om~Thakkar, and Abhradeep Thakurta.
\newblock Public data-assisted mirror descent for private model training.
\newblock In {\em International Conference on Machine Learning}, pages
  517--535. PMLR, 2022.

\bibitem{bassily2014private}
Raef Bassily, Adam Smith, and Abhradeep Thakurta.
\newblock Private empirical risk minimization: Efficient algorithms and tight
  error bounds.
\newblock In {\em Proceedings of the 2014 IEEE 55th Annual Symposium on
  Foundations of Computer Science}, pages 464--473, 2014.

\bibitem{bernstein2018signsgd}
Jeremy Bernstein, Yu-Xiang Wang, Kamyar Azizzadenesheli, and Animashree
  Anandkumar.
\newblock signsgd: Compressed optimisation for non-convex problems.
\newblock In {\em International Conference on Machine Learning}, pages
  560--569. PMLR, 2018.

\bibitem{berrada2023unlocking}
Leonard Berrada, Soham De, Judy~Hanwen Shen, Jamie Hayes, Robert Stanforth,
  David Stutz, Pushmeet Kohli, Samuel~L Smith, and Borja Balle.
\newblock Unlocking accuracy and fairness in differentially private image
  classification.
\newblock {\em arXiv preprint arXiv:2308.10888}, 2023.

\bibitem{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  et~al.
\newblock Language models are few-shot learners.
\newblock {\em Advances in neural information processing systems},
  33:1877--1901, 2020.

\bibitem{bu2023zero}
Zhiqi Bu, Justin Chiu, Ruixuan Liu, Yu-Xiang Wang, Sheng Zha, and George
  Karypis.
\newblock Zero redundancy distributed learning with differential privacy.
\newblock In {\em ICLR 2023 Workshop on Pitfalls of limited data and
  computation for Trustworthy ML}.

\bibitem{bu2020deep}
Zhiqi Bu, Jinshuo Dong, Qi~Long, and Weijie~J Su.
\newblock Deep learning with gaussian differential privacy.
\newblock {\em Harvard data science review}, 2020(23), 2020.

\bibitem{bu2023accuracy}
Zhiqi Bu, Ruixuan Liu, Yu-Xiang Wang, Sheng Zha, and George Karypis.
\newblock On the accuracy and efficiency of group-wise clipping in
  differentially private optimization.
\newblock {\em arXiv preprint arXiv:2310.19215}, 2023.

\bibitem{bu2022scalable}
Zhiqi Bu, Jialin Mao, and Shiyun Xu.
\newblock Scalable and efficient training of large convolutional neural
  networks with differential privacy.
\newblock {\em Advances in Neural Information Processing Systems},
  35:38305--38318, 2022.

\bibitem{bu2021convergence}
Zhiqi Bu, Hua Wang, Zongyu Dai, and Qi~Long.
\newblock On the convergence and calibration of deep learning with differential
  privacy.
\newblock {\em Transactions on Machine Learning Research}, 2023.

\bibitem{bu2022dpbitfit}
Zhiqi Bu, Yu-Xiang Wang, Sheng Zha, and George Karypis.
\newblock Differentially private bias-term fine-tuning of foundation models.
\newblock In {\em Forty-first International Conference on Machine Learning}.

\bibitem{bu2022differentially}
Zhiqi Bu, Yu-Xiang Wang, Sheng Zha, and George Karypis.
\newblock Differentially private optimization on large model at small cost.
\newblock In {\em International Conference on Machine Learning}, pages
  3192--3218. PMLR, 2023.

\bibitem{bu2022automatic}
Zhiqi Bu, Yu-Xiang Wang, Sheng Zha, and George Karypis.
\newblock Automatic clipping: Differentially private deep learning made easier
  and stronger.
\newblock {\em Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem{bu2022private}
Zhiqi Bu and Yuan Zhang.
\newblock Differentially private optimizers can learn adversarially robust
  models.
\newblock {\em Transactions on Machine Learning Research}, 2023.

\bibitem{carlini2022membership}
Nicholas Carlini, Steve Chien, Milad Nasr, Shuang Song, Andreas Terzis, and
  Florian Tramer.
\newblock Membership inference attacks from first principles.
\newblock In {\em 2022 IEEE Symposium on Security and Privacy (SP)}, pages
  1897--1914. IEEE, 2022.

\bibitem{carlini2022quantifying}
Nicholas Carlini, Daphne Ippolito, Matthew Jagielski, Katherine Lee, Florian
  Tramer, and Chiyuan Zhang.
\newblock Quantifying memorization across neural language models.
\newblock In {\em The Eleventh International Conference on Learning
  Representations}, 2022.

\bibitem{carlini2021extracting}
Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel
  Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Ulfar
  Erlingsson, et~al.
\newblock Extracting training data from large language models.
\newblock In {\em 30th USENIX Security Symposium (USENIX Security 21)}, pages
  2633--2650, 2021.

\bibitem{caron2021emerging}
Mathilde Caron, Hugo Touvron, Ishan Misra, Herv{\'e} J{\'e}gou, Julien Mairal,
  Piotr Bojanowski, and Armand Joulin.
\newblock Emerging properties in self-supervised vision transformers.
\newblock In {\em Proceedings of the IEEE/CVF international conference on
  computer vision}, pages 9650--9660, 2021.

\bibitem{chen2020differential}
Junjie Chen, Wendy~Hui Wang, and Xinghua Shi.
\newblock Differential privacy protection against membership inference attack
  on machine learning for genomic data.
\newblock In {\em BIOCOMPUTING 2021: Proceedings of the Pacific Symposium},
  pages 26--37. World Scientific, 2020.

\bibitem{chen2020understanding}
Xiangyi Chen, Steven~Z Wu, and Mingyi Hong.
\newblock Understanding gradient clipping in private sgd: A geometric
  perspective.
\newblock {\em Advances in Neural Information Processing Systems},
  33:13773--13782, 2020.

\bibitem{DatabricksBlog2023DollyV2}
Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie, Jun Wan, Sam Shah, Ali
  Ghodsi, Patrick Wendell, Matei Zaharia, and Reynold Xin.
\newblock Free dolly: Introducing the world's first truly open
  instruction-tuned llm, 2023.

\bibitem{das2021convergence}
Rudrajit Das, Abolfazl Hashemi, Sujay Sanghavi, and Inderjit~S Dhillon.
\newblock On the convergence of differentially private federated learning on
  non-lipschitz objectives, and with normalized client updates.
\newblock {\em arXiv preprint arXiv:2106.07094}, 2021.

\bibitem{de2022unlocking}
Soham De, Leonard Berrada, Jamie Hayes, Samuel~L Smith, and Borja Balle.
\newblock Unlocking high-accuracy differentially private image classification
  through scale.
\newblock {\em arXiv preprint arXiv:2204.13650}, 2022.

\bibitem{deng2009imagenet}
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee, 2009.

\bibitem{dong2019gaussian}
Jinshuo Dong, Aaron Roth, and Weijie~J Su.
\newblock Gaussian differential privacy.
\newblock {\em Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 84(1):3--37, 2022.

\bibitem{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, et~al.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{du2021self}
Jingfei Du, {\'E}douard Grave, Beliz Gunel, Vishrav Chaudhary, Onur Celebi,
  Michael Auli, Veselin Stoyanov, and Alexis Conneau.
\newblock Self-training improves pre-training for natural language
  understanding.
\newblock In {\em Proceedings of the 2021 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies}, pages 5408--5418, 2021.

\bibitem{dwork2006calibrating}
Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith.
\newblock Calibrating noise to sensitivity in private data analysis.
\newblock In {\em Theory of cryptography conference}, pages 265--284. Springer,
  2006.

\bibitem{ferrando2021combining}
Cecilia Ferrando, Jennifer Gillenwater, and Alex Kulesza.
\newblock Combining public and private data.
\newblock {\em arXiv preprint arXiv:2111.00115}, 2021.

\bibitem{foret2020sharpness}
Pierre Foret, Ariel Kleiner, Hossein Mobahi, and Behnam Neyshabur.
\newblock Sharpness-aware minimization for efficiently improving
  generalization.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{golatkar2022mixed}
Aditya Golatkar, Alessandro Achille, Yu-Xiang Wang, Aaron Roth, Michael Kearns,
  and Stefano Soatto.
\newblock Mixed differential privacy in computer vision.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 8376--8386, 2022.

\bibitem{goodfellow2014explaining}
Ian~J Goodfellow, Jonathon Shlens, and Christian Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock {\em arXiv preprint arXiv:1412.6572}, 2014.

\bibitem{gopi2021numerical}
Sivakanth Gopi, Yin~Tat Lee, and Lukas Wutschitz.
\newblock Numerical composition of differential privacy.
\newblock {\em Advances in Neural Information Processing Systems}, 34, 2021.

\bibitem{guo2017calibration}
Chuan Guo, Geoff Pleiss, Yu~Sun, and Kilian~Q Weinberger.
\newblock On calibration of modern neural networks.
\newblock In {\em International conference on machine learning}, pages
  1321--1330. PMLR, 2017.

\bibitem{gururangan2020don}
Suchin Gururangan, Ana Marasovi{\'c}, Swabha Swayamdipta, Kyle Lo, Iz~Beltagy,
  Doug Downey, and Noah~A Smith.
\newblock Don’t stop pretraining: Adapt language models to domains and tasks.
\newblock In {\em Proceedings of the 58th Annual Meeting of the Association for
  Computational Linguistics}, pages 8342--8360, 2020.

\bibitem{hardt2016equality}
Moritz Hardt, Eric Price, and Nati Srebro.
\newblock Equality of opportunity in supervised learning.
\newblock {\em Advances in neural information processing systems}, 29, 2016.

\bibitem{anonymous2023exploring}
Jiyan He, Xuechen Li, Da~Yu, Huishuai Zhang, Janardhan Kulkarni, Yin~Tat Lee,
  Arturs Backurs, Nenghai Yu, and Jiang Bian.
\newblock Exploring the limits of differentially private deep learning with
  group-wise clipping.
\newblock In {\em The Eleventh International Conference on Learning
  Representations}.

\bibitem{he2016deep}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 770--778, 2016.

\bibitem{hoory2021learning}
Shlomo Hoory, Amir Feder, Avichai Tendler, Sofia Erell, Alon Peled-Cohen, Itay
  Laish, Hootan Nakhost, Uri Stemmer, Ayelet Benjamini, Avinatan Hassidim,
  et~al.
\newblock Learning and evaluating a differentially private pre-trained language
  model.
\newblock In {\em Findings of the Association for Computational Linguistics:
  EMNLP 2021}, pages 1178--1189, 2021.

\bibitem{starcodermem}
Daniel Huynh.
\newblock Starcoder memorization experiment highlights privacy risks of
  fine-tuning on code.
\newblock
  \url{https://huggingface.co/blog/dhuynh95/starcoder-memorization-experiment},
  2023.

\bibitem{inan2021training}
Huseyin~A Inan, Osman Ramadan, Lukas Wutschitz, Daniel Jones, Victor R{\"u}hle,
  James Withers, and Robert Sim.
\newblock Training data leakage analysis in language models.
\newblock {\em arXiv preprint arXiv:2101.05405}, 2021.

\bibitem{ji2023domain}
Shaoxiong Ji, Tianlin Zhang, Kailai Yang, Sophia Ananiadou, Erik Cambria, and
  J{\"o}rg Tiedemann.
\newblock Domain-specific continued pretraining of language models for
  capturing long context in mental health.
\newblock {\em arXiv preprint arXiv:2304.10447}, 2023.

\bibitem{jorgensen2015conservative}
Zach Jorgensen, Ting Yu, and Graham Cormode.
\newblock Conservative or liberal? personalized differential privacy.
\newblock In {\em 2015 IEEE 31St international conference on data engineering},
  pages 1023--1034. IEEE, 2015.

\bibitem{keskar2016large}
Nitish~Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy,
  and Ping Tak~Peter Tang.
\newblock On large-batch training for deep learning: Generalization gap and
  sharp minima.
\newblock In {\em International Conference on Learning Representations}, 2016.

\bibitem{kingma2014adam}
Diederik~P Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock {\em arXiv preprint arXiv:1412.6980}, 2014.

\bibitem{kurakin2022toward}
Alexey Kurakin, Steve Chien, Shuang Song, Roxana Geambasu, Andreas Terzis, and
  Abhradeep Thakurta.
\newblock Toward training at imagenet scale with differential privacy.
\newblock {\em arXiv preprint arXiv:2201.12328}, 2022.

\bibitem{li2022does}
Xuechen Li, Daogao Liu, Tatsunori~B Hashimoto, Huseyin~A Inan, Janardhan
  Kulkarni, Yin-Tat Lee, and Abhradeep Guha~Thakurta.
\newblock When does differentially private learning not suffer in high
  dimensions?
\newblock {\em Advances in Neural Information Processing Systems},
  35:28616--28630, 2022.

\bibitem{li2021large}
Xuechen Li, Florian Tramer, Percy Liang, and Tatsunori Hashimoto.
\newblock Large language models can be strong differentially private learners.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{lin2004rouge}
Chin-Yew Lin.
\newblock Rouge: A package for automatic evaluation of summaries.
\newblock In {\em Text summarization branches out}, pages 74--81, 2004.

\bibitem{liu2023same}
Hong Liu, Sang~Michael Xie, Zhiyuan Li, and Tengyu Ma.
\newblock Same pre-training loss, better downstream: Implicit bias matters for
  language models.
\newblock In {\em International Conference on Machine Learning}, pages
  22188--22214. PMLR, 2023.

\bibitem{liu2023coupling}
Ruixuan Liu, Zhiqi Bu, Yu-xiang Wang, Sheng Zha, and George Karypis.
\newblock Coupling public and private gradient provably helps optimization.
\newblock {\em arXiv preprint arXiv:2310.01304}, 2023.

\bibitem{lukas2023analyzing}
Nils Lukas, Ahmed Salem, Robert Sim, Shruti Tople, Lukas Wutschitz, and
  Santiago Zanella-B{\'e}guelin.
\newblock Analyzing leakage of personally identifiable information in language
  models.
\newblock In {\em 2023 IEEE Symposium on Security and Privacy (SP)}, pages
  346--363. IEEE Computer Society, 2023.

\bibitem{ma2022dimension}
Yi-An Ma, Teodor~Vanislavov Marinov, and Tong Zhang.
\newblock Dimension independent generalization of dp-sgd for overparameterized
  smooth convex optimization.
\newblock {\em arXiv preprint arXiv:2206.01836}, 2022.

\bibitem{mandic2004generalized}
Danilo~P Mandic.
\newblock A generalized normalized gradient descent algorithm.
\newblock {\em IEEE signal processing letters}, 11(2):115--118, 2004.

\bibitem{mandt2017stochastic}
Stephan Mandt, Matthew~D Hoffman, and David~M Blei.
\newblock Stochastic gradient descent as approximate bayesian inference.
\newblock {\em Journal of Machine Learning Research}, 18:1--35, 2017.

\bibitem{mccandlish2018empirical}
Sam McCandlish, Jared Kaplan, Dario Amodei, and OpenAI~Dota Team.
\newblock An empirical model of large-batch training.
\newblock {\em arXiv preprint arXiv:1812.06162}, 2018.

\bibitem{mehta2022large}
Harsh Mehta, Abhradeep Thakurta, Alexey Kurakin, and Ashok Cutkosky.
\newblock Large scale transfer learning for differentially private image
  classification.
\newblock {\em arXiv preprint arXiv:2205.02973}, 2022.

\bibitem{mironov2017renyi}
Ilya Mironov.
\newblock R{\'e}nyi differential privacy.
\newblock In {\em 2017 IEEE 30th computer security foundations symposium
  (CSF)}, pages 263--275. IEEE, 2017.

\bibitem{nakkab2023lit}
Andre Nakkab, Benjamin Feuer, and Chinmay Hegde.
\newblock Lit tuned models for efficient species detection.
\newblock In {\em 2nd AAAI Workshop on AI for Agriculture and Food Systems},
  2023.

\bibitem{nesterov2003introductory}
Yurii Nesterov.
\newblock {\em Introductory lectures on convex optimization: A basic course},
  volume~87.
\newblock Springer Science \& Business Media, 2003.

\bibitem{chatgptpoem}
Lily~Hay Newman and Andy Greenberg.
\newblock Chatgpt spit out sensitive data when told to repeat 'poem' forever.
\newblock
  \url{https://www.wired.com/story/chatgpt-poem-forever-security-roundup/},
  2023.

\bibitem{papernot2020tempered}
Nicolas Papernot, Abhradeep Thakurta, Shuang Song, Steve Chien, and {\'U}lfar
  Erlingsson.
\newblock Tempered sigmoid activations for deep learning with differential
  privacy.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~35, pages 9312--9321, 2021.

\bibitem{Papineni02bleu:a}
Kishore Papineni, Salim Roukos, Todd Ward, and Wei jing Zhu.
\newblock Bleu: a method for automatic evaluation of machine translation.
\newblock pages 311--318, 2002.

\bibitem{paszke2017automatic}
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary
  DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
\newblock Automatic differentiation in pytorch.
\newblock 2017.

\bibitem{ponomareva2023dp}
Natalia Ponomareva, Hussein Hazimeh, Alex Kurakin, Zheng Xu, Carson Denison,
  H~Brendan McMahan, Sergei Vassilvitskii, Steve Chien, and Abhradeep~Guha
  Thakurta.
\newblock How to dp-fy ml: A practical guide to machine learning with
  differential privacy.
\newblock {\em Journal of Artificial Intelligence Research}, 77:1113--1201,
  2023.

\bibitem{Quach_2019}
Katyanna Quach.
\newblock Inside the 1tb imagenet data set used to train the world’s ai:
  Naked kids, drunken frat parties, porno stars, and more, Oct 2019.

\bibitem{radford2019language}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya
  Sutskever, et~al.
\newblock Language models are unsupervised multitask learners.

\bibitem{rahman2018membership}
Md~Atiqur Rahman, Tanzila Rahman, Robert Lagani{\`e}re, Noman Mohammed, and
  Yang Wang.
\newblock Membership inference attack against differentially private deep
  learning model.
\newblock {\em Trans. Data Priv.}, 11(1):61--79, 2018.

\bibitem{ridnik2021imagenet}
Tal Ridnik, Emanuel Ben-Baruch, Asaf Noy, and Lihi Zelnik-Manor.
\newblock Imagenet-21k pretraining for the masses.
\newblock In {\em Thirty-fifth Conference on Neural Information Processing
  Systems Datasets and Benchmarks Track (Round 1)}, 2021.

\bibitem{sander2023tan}
Tom Sander, Pierre Stock, and Alexandre Sablayrolles.
\newblock Tan without a burn: Scaling laws of dp-sgd.
\newblock In {\em International Conference on Machine Learning}, pages
  29937--29949. PMLR, 2023.

\bibitem{song2022multi}
Dezhao Song, Andrew Vold, Kanika Madan, and Frank Schilder.
\newblock Multi-label legal document classification: A deep learning-based
  approach with label-attention and domain-specific pre-training.
\newblock {\em Information Systems}, 106:101718, 2022.

\bibitem{song2021evading}
Shuang Song, Thomas Steinke, Om~Thakkar, and Abhradeep Thakurta.
\newblock Evading the curse of dimensionality in unconstrained private glms.
\newblock In {\em International Conference on Artificial Intelligence and
  Statistics}, pages 2638--2646. PMLR, 2021.

\bibitem{steiner2021train}
Andreas~Peter Steiner, Alexander Kolesnikov, Xiaohua Zhai, Ross Wightman, Jakob
  Uszkoreit, and Lucas Beyer.
\newblock How to train your vit? data, augmentation, and regularization in
  vision transformers.
\newblock {\em Transactions on Machine Learning Research}, 2022.

\bibitem{sun2017revisiting}
Chen Sun, Abhinav Shrivastava, Saurabh Singh, and Abhinav Gupta.
\newblock Revisiting unreasonable effectiveness of data in deep learning era.
\newblock In {\em Proceedings of the IEEE international conference on computer
  vision}, pages 843--852, 2017.

\bibitem{alpaca}
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos
  Guestrin, Percy Liang, and Tatsunori~B. Hashimoto.
\newblock Stanford alpaca: An instruction-following llama model.
\newblock \url{https://github.com/tatsu-lab/stanford_alpaca}, 2023.

\bibitem{touvron2023llama}
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
  Lachaux, Timoth{\'e}e Lacroix, Baptiste Rozi{\`e}re, Naman Goyal, Eric
  Hambro, Faisal Azhar, et~al.
\newblock Llama: Open and efficient foundation language models.
\newblock {\em arXiv preprint arXiv:2302.13971}, 2023.

\bibitem{tramer2020differentially}
Florian Tramer and Dan Boneh.
\newblock Differentially private learning needs better features (or much more
  data).
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{tramer2022considerations}
Florian Tram{\`e}r, Gautam Kamath, and Nicholas Carlini.
\newblock Considerations for differentially private learning with large-scale
  public pretraining.
\newblock {\em arXiv preprint arXiv:2212.06470}, 2022.

\bibitem{van2021benchmarking}
Grant Van~Horn, Elijah Cole, Sara Beery, Kimberly Wilber, Serge Belongie, and
  Oisin Mac~Aodha.
\newblock Benchmarking representation learning for natural world image
  collections.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 12884--12893, 2021.

\bibitem{wang2019differentially}
Di~Wang, Changyou Chen, and Jinhui Xu.
\newblock Differentially private empirical risk minimization with non-convex
  loss functions.
\newblock In {\em International Conference on Machine Learning}, pages
  6526--6535. PMLR, 2019.

\bibitem{wang2019differentially2}
Di~Wang and Jinhui Xu.
\newblock Differentially private empirical risk minimization with smooth
  non-convex loss functions: A non-stationary view.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, volume~33, pages 1182--1189, 2019.

\bibitem{wang2020extending}
Zihan Wang, K~Karthikeyan, Stephen Mayhew, and Dan Roth.
\newblock Extending multilingual bert to low-resource languages.
\newblock In {\em Findings of the Association for Computational Linguistics:
  EMNLP 2020}, pages 2649--2656, 2020.

\bibitem{wei2020federated}
Kang Wei, Jun Li, Ming Ding, Chuan Ma, Howard~H Yang, Farhad Farokhi, Shi Jin,
  Tony~QS Quek, and H~Vincent Poor.
\newblock Federated learning with differential privacy: Algorithms and
  performance analysis.
\newblock {\em IEEE Transactions on Information Forensics and Security},
  15:3454--3469, 2020.

\bibitem{xie2020diffusion}
Zeke Xie, Issei Sato, and Masashi Sugiyama.
\newblock A diffusion theory for deep learning dynamics: Stochastic gradient
  descent exponentially favors flat minima.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{yang2022normalized}
Xiaodong Yang, Huishuai Zhang, Wei Chen, and Tie-Yan Liu.
\newblock Normalized/clipped sgd with perturbation for differentially private
  non-convex optimization.
\newblock {\em arXiv preprint arXiv:2206.13033}, 2022.

\bibitem{you2019large}
Yang You, Jing Li, Sashank Reddi, Jonathan Hseu, Sanjiv Kumar, Srinadh
  Bhojanapalli, Xiaodan Song, James Demmel, Kurt Keutzer, and Cho-Jui Hsieh.
\newblock Large batch optimization for deep learning: Training bert in 76
  minutes.
\newblock In {\em International Conference on Learning Representations}, 2019.

\bibitem{opacus}
Ashkan Yousefpour, Igor Shilov, Alexandre Sablayrolles, Davide Testuggine,
  Karthik Prasad, Mani Malek, John Nguyen, Sayan Ghosh, Akash Bharadwaj,
  Jessica Zhao, Graham Cormode, and Ilya Mironov.
\newblock Opacus: {U}ser-friendly differential privacy library in {PyTorch}.
\newblock {\em arXiv preprint arXiv:2109.12298}, 2021.

\bibitem{yu2021differentially}
Da~Yu, Saurabh Naik, Arturs Backurs, Sivakanth Gopi, Huseyin~A Inan, Gautam
  Kamath, Janardhan Kulkarni, Yin~Tat Lee, Andre Manoel, Lukas Wutschitz,
  et~al.
\newblock Differentially private fine-tuning of language models.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{yu2023vip}
Yaodong Yu, Maziar Sanjabi, Yi~Ma, Kamalika Chaudhuri, and Chuan Guo.
\newblock Vip: A differentially private foundation model for computer vision.
\newblock In {\em Forty-first International Conference on Machine Learning},
  2023.

\bibitem{zhang2019algorithmic}
Guodong Zhang, Lala Li, Zachary Nado, James Martens, Sushant Sachdeva, George
  Dahl, Chris Shallue, and Roger~B Grosse.
\newblock Which algorithmic choices matter at which batch sizes? insights from
  a noisy quadratic model.
\newblock {\em Advances in neural information processing systems}, 32, 2019.

\bibitem{zhang2024disk}
Xinwei Zhang, Zhiqi Bu, Borja Balle, Mingyi Hong, Meisam Razaviyayn, and Vahab
  Mirrokni.
\newblock Disk: Differentially private optimizer with simplified kalman filter
  for noise reduction.
\newblock {\em arXiv preprint arXiv:2410.03883}, 2024.

\bibitem{zhang2024doppler}
Xinwei Zhang, Zhiqi Bu, Mingyi Hong, and Meisam Razaviyayn.
\newblock Doppler: Differentially private optimizers with low-pass filter for
  privacy noise reduction.
\newblock {\em Advances in neural information processing systems}, 2024.

\bibitem{zhang2022understanding}
Xinwei Zhang, Xiangyi Chen, Mingyi Hong, Zhiwei~Steven Wu, and Jinfeng Yi.
\newblock Understanding clipping for federated learning: Convergence and
  client-level differential privacy.
\newblock In {\em International Conference on Machine Learning, ICML 2022},
  2022.

\bibitem{zhou2020bypassing}
Yingxue Zhou, Steven Wu, and Arindam Banerjee.
\newblock Bypassing the ambient dimension: Private sgd with gradient subspace
  identification.
\newblock In {\em International Conference on Learning Representations}, 2020.

\bibitem{zhu2019anisotropic}
Zhanxing Zhu, Jingfeng Wu, Bing Yu, Lei Wu, and Jinwen Ma.
\newblock The anisotropic noise in stochastic gradient descent: Its behavior of
  escaping from sharp minima and regularization effects.
\newblock In {\em International Conference on Machine Learning}, pages
  7654--7663. PMLR, 2019.

\bibitem{zhu2018anisotropic}
Zhanxing Zhu, Jingfeng Wu, Bing Yu, Lei Wu, and Jinwen Ma.
\newblock The anisotropic noise in stochastic gradient descent: Its behavior of
  escaping from sharp minima and regularization effects.
\newblock In {\em International Conference on Machine Learning}, pages
  7654--7663. PMLR, 2019.

\end{thebibliography}
