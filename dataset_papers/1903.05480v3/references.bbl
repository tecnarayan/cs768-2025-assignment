\begin{thebibliography}{43}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Amzal et~al.(2006)Amzal, Bois, Parent, and Robert]{amzal2006bayesian}
Billy Amzal, Fr{\'e}d{\'e}ric~Y Bois, Eric Parent, and Christian~P Robert.
\newblock Bayesian-optimal design via interacting particle systems.
\newblock \emph{Journal of the American Statistical association}, 101\penalty0
  (474):\penalty0 773--785, 2006.

\bibitem[Arrow et~al.(1961)Arrow, Chenery, Minhas, and Solow]{arrow1961capital}
Kenneth~J Arrow, Hollis~B Chenery, Bagicha~S Minhas, and Robert~M Solow.
\newblock Capital-labor substitution and economic efficiency.
\newblock \emph{The review of Economics and Statistics}, pages 225--250, 1961.

\bibitem[Barber and Agakov(2003)]{ba}
David Barber and Felix Agakov.
\newblock The {IM} algorithm: a variational approach to information
  maximization.
\newblock \emph{Advances in Neural Information Processing Systems},
  16:\penalty0 201--208, 2003.

\bibitem[Belghazi et~al.(2018)Belghazi, Rajeswar, Baratin, Hjelm, and
  Courville]{mine}
Ishmael Belghazi, Sai Rajeswar, Aristide Baratin, R~Devon Hjelm, and Aaron
  Courville.
\newblock {MINE}: mutual information neural estimation.
\newblock \emph{arXiv preprint arXiv:1801.04062}, 2018.

\bibitem[Bingham et~al.(2019)Bingham, Chen, Jankowiak, Obermeyer, Pradhan,
  Karaletsos, Singh, Szerlip, Horsfall, and Goodman]{pyro}
Eli Bingham, Jonathan~P Chen, Martin Jankowiak, Fritz Obermeyer, Neeraj
  Pradhan, Theofanis Karaletsos, Rohit Singh, Paul Szerlip, Paul Horsfall, and
  Noah~D Goodman.
\newblock Pyro: Deep universal probabilistic programming.
\newblock \emph{The Journal of Machine Learning Research}, 20\penalty0
  (1):\penalty0 973--978, 2019.

\bibitem[Box et~al.(2005)Box, Hunter, and Hunter]{box2005statistics}
George~EP Box, J~Stuart Hunter, and William~G Hunter.
\newblock Statistics for experimenters.
\newblock In \emph{Wiley Series in Probability and Statistics}. Wiley Hoboken,
  NJ, 2005.

\bibitem[Burda et~al.(2015)Burda, Grosse, and
  Salakhutdinov]{burda2015importance}
Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov.
\newblock Importance weighted autoencoders.
\newblock \emph{arXiv preprint arXiv:1509.00519}, 2015.

\bibitem[Chaloner and Verdinelli(1995)]{chaloner1995}
Kathryn Chaloner and Isabella Verdinelli.
\newblock Bayesian experimental design: A review.
\newblock \emph{Statistical Science}, pages 273--304, 1995.

\bibitem[Cook et~al.(2008)Cook, Gibson, and Gilligan]{cook2008optimal}
Alex~R Cook, Gavin~J Gibson, and Christopher~A Gilligan.
\newblock Optimal observation times in experimental epidemic processes.
\newblock \emph{Biometrics}, 64\penalty0 (3):\penalty0 860--868, 2008.

\bibitem[Dayan et~al.(1995)Dayan, Hinton, Neal, and Zemel]{dayan1995helmholtz}
Peter Dayan, Geoffrey~E Hinton, Radford~M Neal, and Richard~S Zemel.
\newblock The {H}elmholtz machine.
\newblock \emph{Neural computation}, 7\penalty0 (5):\penalty0 889--904, 1995.

\bibitem[Donsker and Varadhan(1975)]{donsker1975asymptotic}
Monroe~D Donsker and SR~Srinivasa Varadhan.
\newblock Asymptotic evaluation of certain {M}arkov process expectations for
  large time.
\newblock \emph{Communications on Pure and Applied Mathematics}, 28\penalty0
  (1):\penalty0 1--47, 1975.

\bibitem[Ehrenfeld(1962)]{ehrenfeld1962some}
Sylvain Ehrenfeld.
\newblock Some experimental design problems in attribute life testing.
\newblock \emph{Journal of the American Statistical Association}, 57\penalty0
  (299):\penalty0 668--679, 1962.

\bibitem[Embretson and Reise(2013)]{embretson2013item}
Susan~E Embretson and Steven~P Reise.
\newblock \emph{Item response theory}.
\newblock Psychology Press, 2013.

\bibitem[Gelman et~al.(2013)Gelman, Stern, Carlin, Dunson, Vehtari, and
  Rubin]{gelman2013bayesian}
Andrew Gelman, Hal~S Stern, John~B Carlin, David~B Dunson, Aki Vehtari, and
  Donald~B Rubin.
\newblock \emph{Bayesian data analysis}.
\newblock Chapman and Hall/CRC, 2013.

\bibitem[Golovin et~al.(2010)Golovin, Krause, and Ray]{golovin2010}
Daniel Golovin, Andreas Krause, and Debajyoti Ray.
\newblock Near-optimal bayesian active learning with noisy observations.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  766--774, 2010.

\bibitem[Hern{\'a}ndez-Lobato et~al.(2014)Hern{\'a}ndez-Lobato, Hoffman, and
  Ghahramani]{hernandez2014}
Jos{\'e}~Miguel Hern{\'a}ndez-Lobato, Matthew~W Hoffman, and Zoubin Ghahramani.
\newblock Predictive entropy search for efficient global optimization of
  black-box functions.
\newblock In \emph{Advances in neural information processing systems}, pages
  918--926, 2014.

\bibitem[Kingma and Welling(2014)]{kingma2014auto}
Diederik~P Kingma and Max Welling.
\newblock Auto-encoding variational {Bayes}.
\newblock In \emph{ICLR}, 2014.

\bibitem[Kleinegesse and Gutmann(2018)]{kleinegesse2018efficient}
Steven Kleinegesse and Michael Gutmann.
\newblock Efficient {B}ayesian experimental design for implicit models.
\newblock \emph{arXiv preprint arXiv:1810.09912}, 2018.

\bibitem[Kohavi et~al.(2009)Kohavi, Longbotham, Sommerfield, and
  Henne]{kohavi2009controlled}
Ron Kohavi, Roger Longbotham, Dan Sommerfield, and Randal~M Henne.
\newblock Controlled experiments on the web: survey and practical guide.
\newblock \emph{Data mining and knowledge discovery}, 18\penalty0 (1):\penalty0
  140--181, 2009.

\bibitem[Kruschke(2014)]{kruschke2014doing}
John Kruschke.
\newblock \emph{Doing Bayesian data analysis: A tutorial with R, JAGS, and
  Stan}.
\newblock Academic Press, 2014.

\bibitem[Le et~al.(2017)Le, Igl, Rainforth, Jin, and Wood]{le2017auto}
Tuan~Anh Le, Maximilian Igl, Tom Rainforth, Tom Jin, and Frank Wood.
\newblock Auto-encoding sequential monte carlo.
\newblock \emph{arXiv preprint arXiv:1705.10306}, 2017.

\bibitem[Lewi et~al.(2009)Lewi, Butera, and Paninski]{lewi2009sequential}
Jeremy Lewi, Robert Butera, and Liam Paninski.
\newblock Sequential optimal design of neurophysiology experiments.
\newblock \emph{Neural Computation}, 21\penalty0 (3):\penalty0 619--687, 2009.

\bibitem[Lindley(1956)]{lindley1956}
Dennis~V Lindley.
\newblock On a measure of the information provided by an experiment.
\newblock \emph{The Annals of Mathematical Statistics}, pages 986--1005, 1956.

\bibitem[Lindley(1972)]{lindley1972}
Dennis~V Lindley.
\newblock \emph{Bayesian statistics, a review}, volume~2.
\newblock SIAM, 1972.

\bibitem[Long et~al.(2013)Long, Scavino, Tempone, and Wang]{long2013}
Quan Long, Marco Scavino, Ra{\'u}l Tempone, and Suojin Wang.
\newblock Fast estimation of expected information gains for {B}ayesian
  experimental designs based on {L}aplace approximations.
\newblock \emph{Computer Methods in Applied Mechanics and Engineering},
  259:\penalty0 24--39, 2013.

\bibitem[Ma et~al.(2018)Ma, Tschiatschek, Palla, Lobato, Nowozin, and
  Zhang]{ma2018eddi}
Chao Ma, Sebastian Tschiatschek, Konstantina Palla, Jose Miguel~Hernandez
  Lobato, Sebastian Nowozin, and Cheng Zhang.
\newblock {EDDI}: Efficient dynamic discovery of high-value information with
  partial {VAE}.
\newblock \emph{arXiv preprint arXiv:1809.11142}, 2018.

\bibitem[MacKay(1992)]{mackay1992information}
David~JC MacKay.
\newblock Information-based objective functions for active data selection.
\newblock \emph{Neural computation}, 4\penalty0 (4):\penalty0 590--604, 1992.

\bibitem[Moulines and Bach(2011)]{moulines2011}
Eric Moulines and Francis~R Bach.
\newblock Non-asymptotic analysis of stochastic approximation algorithms for
  machine learning.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  451--459, 2011.

\bibitem[M{\"u}ller(2005)]{muller2005simulation}
Peter M{\"u}ller.
\newblock Simulation based optimal design.
\newblock \emph{Handbook of Statistics}, 25:\penalty0 509--518, 2005.

\bibitem[Myung et~al.(2013)Myung, Cavagnaro, and Pitt]{myung2013}
Jay~I Myung, Daniel~R Cavagnaro, and Mark~A Pitt.
\newblock A tutorial on adaptive design optimization.
\newblock \emph{Journal of mathematical psychology}, 57\penalty0
  (3-4):\penalty0 53--67, 2013.

\bibitem[Poole et~al.(2018)Poole, Ozair, van~den Oord, Alemi, and
  Tucker]{poole2018variational}
Ben Poole, Sherjil Ozair, A{\"a}ron van~den Oord, Alexander~A Alemi, and George
  Tucker.
\newblock On variational lower bounds of mutual information.
\newblock \emph{NeurIPS Workshop on Bayesian Deep Learning}, 2018.

\bibitem[Rainforth(2017)]{rainforth2017thesis}
Tom Rainforth.
\newblock \emph{Automating Inference, Learning, and Design using Probabilistic
  Programming}.
\newblock PhD thesis, University of Oxford, 2017.

\bibitem[Rainforth et~al.(2018)Rainforth, Cornish, Yang, Warrington, and
  Wood]{nmc}
Tom Rainforth, Robert Cornish, Hongseok Yang, Andrew Warrington, and Frank
  Wood.
\newblock On nesting {Monte Carlo} estimators.
\newblock In \emph{International Conference on Machine Learning}, pages
  4264--4273, 2018.

\bibitem[Rezende et~al.(2014)Rezende, Mohamed, and
  Wierstra]{rezende2014stochastic}
Danilo~Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock In \emph{Proceedings of the 31st International Conference on Machine
  Learning}, volume~32, pages 1278--1286, 2014.

\bibitem[Robbins and Monro(1951)]{robbins1951stochastic}
Herbert Robbins and Sutton Monro.
\newblock A stochastic approximation method.
\newblock \emph{The annals of mathematical statistics}, pages 400--407, 1951.

\bibitem[Samuelson(1948)]{samuelson1948consumption}
Paul~A Samuelson.
\newblock Consumption theory in terms of revealed preference.
\newblock \emph{Economica}, 15\penalty0 (60):\penalty0 243--253, 1948.

\bibitem[Sebastiani and Wynn(2000)]{sebastiani2000maximum}
Paola Sebastiani and Henry~P Wynn.
\newblock Maximum entropy sampling and optimal {B}ayesian experimental design.
\newblock \emph{Journal of the Royal Statistical Society: Series B (Statistical
  Methodology)}, 62\penalty0 (1), 2000.

\bibitem[Shababo et~al.(2013)Shababo, Paige, Pakman, and
  Paninski]{shababo2013bayesian}
Ben Shababo, Brooks Paige, Ari Pakman, and Liam Paninski.
\newblock Bayesian inference and online experimental design for mapping neural
  microcircuits.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  1304--1312, 2013.

\bibitem[Snoek et~al.(2012)Snoek, Larochelle, and Adams]{snoek2012practical}
Jasper Snoek, Hugo Larochelle, and Ryan~P Adams.
\newblock Practical {B}ayesian optimization of machine learning algorithms.
\newblock In \emph{Advances in neural information processing systems}, pages
  2951--2959, 2012.

\bibitem[Stuhlm{\"u}ller et~al.(2013)Stuhlm{\"u}ller, Taylor, and
  Goodman]{stuhlmuller2013learning}
Andreas Stuhlm{\"u}ller, Jacob Taylor, and Noah Goodman.
\newblock Learning stochastic inverses.
\newblock In \emph{Advances in neural information processing systems}, pages
  3048--3056, 2013.

\bibitem[Thomas et~al.(2016)Thomas, Dutta, Corander, Kaski, and
  Gutmann]{dutta2016likelihood}
Owen Thomas, Ritabrata Dutta, Jukka Corander, Samuel Kaski, and Michael~U
  Gutmann.
\newblock Likelihood-free inference by ratio estimation.
\newblock \emph{arXiv preprint arXiv:1611.10242}, 2016.

\bibitem[Vanlier et~al.(2012)Vanlier, Tiemann, Hilbers, and van
  Riel]{vanlier2012}
Joep Vanlier, Christian~A Tiemann, Peter~AJ Hilbers, and Natal~AW van Riel.
\newblock A {B}ayesian approach to targeted experiment design.
\newblock \emph{Bioinformatics}, 28\penalty0 (8):\penalty0 1136--1142, 2012.

\bibitem[Vincent and Rainforth(2017)]{vincent2017}
Benjamin~T Vincent and Tom Rainforth.
\newblock The {DARC} toolbox: automated, flexible, and efficient delayed and
  risky choice experiments using bayesian adaptive design.
\newblock 2017.

\end{thebibliography}
