\begin{thebibliography}{47}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bengio et~al.(2003)Bengio, Ducharme, Vincent, and
  Jauvin]{bengio2003neural}
Yoshua Bengio, R{\'e}jean Ducharme, Pascal Vincent, and Christian Jauvin.
\newblock A neural probabilistic language model.
\newblock \emph{Journal of machine learning research}, 3\penalty0
  (Feb):\penalty0 1137--1155, 2003.

\bibitem[Bradshaw and Howard(2017)]{bradshaw2017troops}
Samantha Bradshaw and Philip Howard.
\newblock Troops, trolls and troublemakers: A global inventory of organized
  social media manipulation.
\newblock Technical report, Oxford Internet Institute, 2017.

\bibitem[Caccia et~al.(2018)Caccia, Caccia, Fedus, Larochelle, Pineau, and
  Charlin]{caccia2018language}
Massimo Caccia, Lucas Caccia, William Fedus, Hugo Larochelle, Joelle Pineau,
  and Laurent Charlin.
\newblock Language gans falling short.
\newblock \emph{arXiv preprint arXiv:1811.02549}, 2018.

\bibitem[Chen et~al.(2017)Chen, Fisch, Weston, and Bordes]{chen2017reading}
Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes.
\newblock Reading wikipedia to answer open-domain questions.
\newblock In \emph{Proceedings of the 55th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 1870--1879,
  2017.

\bibitem[Devlin et~al.(2018)Devlin, Chang, Lee, and Toutanova]{devlin2018bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock Bert: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock \emph{arXiv preprint arXiv:1810.04805}, 2018.

\bibitem[Dicker(2016)]{fakenewslist}
Rachel Dicker.
\newblock {Avoid These Fake News Sites at All Costs}.
\newblock
  \url{https://www.usnews.com/news/national-news/articles/2016-11-14/avoid-these-fake-news-sites-at-all-costs},
  2016.
\newblock [Online; accessed 22-May-2019].

\bibitem[Dwoskin and Romm(2018)]{dwoskin2018facebook}
Elizabeth Dwoskin and Tony Romm.
\newblock Facebook says it has uncovered a coordinated disinformation operation
  ahead of the 2018 midterm elections.
\newblock \emph{The Washington Post}, 2018.

\bibitem[Fan et~al.(2018)Fan, Lewis, and Dauphin]{fan2018hierarchical}
Angela Fan, Mike Lewis, and Yann Dauphin.
\newblock Hierarchical neural story generation.
\newblock In \emph{Proceedings of the 56th Annual Meeting of the Association
  for Computational Linguistics (Volume 1: Long Papers)}, pages 889--898, 2018.

\bibitem[Faris et~al.(2017)Faris, Roberts, Etling, Bourassa, Zuckerman, and
  Benkler]{faris2017partisanship}
Robert Faris, Hal Roberts, Bruce Etling, Nikki Bourassa, Ethan Zuckerman, and
  Yochai Benkler.
\newblock Partisanship, propaganda, and disinformation: Online media and the
  2016 us presidential election.
\newblock \emph{Berkman Klein Center Research Publication 2017-6.}, 2017.

\bibitem[Ghazvininejad et~al.(2019)Ghazvininejad, Levy, Liu, and
  Zettlemoyer]{ghazvininejad2019constant}
Marjan Ghazvininejad, Omer Levy, Yinhan Liu, and Luke Zettlemoyer.
\newblock Constant-time machine translation with conditional masked language
  models.
\newblock \emph{arXiv preprint arXiv:1904.09324}, 2019.

\bibitem[Gu et~al.(2019)Gu, Liu, and Cho]{gu2019insertion}
Jiatao Gu, Qi~Liu, and Kyunghyun Cho.
\newblock Insertion-based decoding with automatically inferred generation
  order.
\newblock \emph{arXiv preprint arXiv:1902.01370}, 2019.

\bibitem[Han and Eisenstein(2019)]{han2019unsupervised}
Xiaochuang Han and Jacob Eisenstein.
\newblock Unsupervised domain adaptation of contextualized embeddings: A case
  study in early modern english.
\newblock \emph{arXiv preprint arXiv:1904.02817}, 2019.

\bibitem[Hashimoto et~al.(2019)Hashimoto, Zhang, and
  Liang]{hashimoto2019unifying}
Tatsunori~B Hashimoto, Hugh Zhang, and Percy Liang.
\newblock Unifying human and statistical evaluation for natural language
  generation.
\newblock \emph{arXiv preprint arXiv:1904.02792}, 2019.

\bibitem[Hecht et~al.(2018)Hecht, Wilcox, Bigham, Sch{\"o}ning, Hoque, Ernnst,
  Bisk, De~Russis, Yarosh, Anjum, Contractor, and Wu]{hecht2018s}
Brent Hecht, Lauren Wilcox, Jeffrey~P. Bigham, Johannes Sch{\"o}ning, Ehsan
  Hoque, Jason Ernnst, Yonatan Bisk, Luigi De~Russis, Lana Yarosh, Bushra
  Anjum, Danish Contractor, and Cathy Wu.
\newblock It's time to do something: Mitigating the negative impacts of
  computing through a change to the peer review process.
\newblock \emph{ACM Future of Computing Blog}, 2018.

\bibitem[Holtzman et~al.(2019)Holtzman, Buys, Forbes, and
  Choi]{holtzman2019curious}
Ari Holtzman, Jan Buys, Maxwell Forbes, and Yejin Choi.
\newblock The curious case of neural text degeneration.
\newblock \emph{arXiv preprint arXiv:1904.09751}, 2019.

\bibitem[Hosseini et~al.(2017)Hosseini, Xiao, Clark, and
  Poovendran]{hosseini2017attacking}
Hossein Hosseini, Baicen Xiao, Andrew Clark, and Radha Poovendran.
\newblock Attacking automatic video analysis algorithms: A case study of google
  cloud video intelligence api.
\newblock In \emph{Proceedings of the 2017 on Multimedia Privacy and Security},
  pages 21--32. ACM, 2017.

\bibitem[Hu et~al.(2017)Hu, Yang, Liang, Salakhutdinov, and Xing]{hu2017toward}
Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, and Eric~P Xing.
\newblock Toward controlled generation of text.
\newblock In \emph{Proceedings of the 34th International Conference on Machine
  Learning-Volume 70}, pages 1587--1596. JMLR. org, 2017.

\bibitem[Joulin et~al.(2017)Joulin, Grave, Bojanowski, and
  Mikolov]{joulin2017bag}
Armand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov.
\newblock Bag of tricks for efficient text classification.
\newblock In \emph{Proceedings of the 15th Conference of the European Chapter
  of the Association for Computational Linguistics: Volume 2, Short Papers},
  volume~2, pages 427--431, 2017.

\bibitem[J{\'o}zefowicz et~al.(2016)J{\'o}zefowicz, Vinyals, Schuster, Shazeer,
  and Wu]{Jzefowicz2016ExploringTL}
Rafal J{\'o}zefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui
  Wu.
\newblock Exploring the limits of language modeling.
\newblock \emph{CoRR}, abs/1602.02410, 2016.

\bibitem[Kingma and Ba(2014)]{Kingma2014AdamAM}
Diederik~P. Kingma and Jimmy Ba.
\newblock Adam: A method for stochastic optimization.
\newblock \emph{CoRR}, abs/1412.6980, 2014.

\bibitem[Melford and Fagan(2019)]{melford2019disinfo}
Clare Melford and Craig Fagan.
\newblock Cutting the funding of disinformation: The ad-tech solution.
\newblock Technical report, The Global Disinformation Index, 2019.

\bibitem[Mosseri(2018)]{mosseri2018news}
Adam Mosseri.
\newblock News feed fyi: Helping ensure news on facebook is from trusted
  sources.
\newblock \emph{Facebook Newsroom}, 19, 2018.

\bibitem[Ott et~al.(2011)Ott, Choi, Cardie, and Hancock]{ott2011finding}
Myle Ott, Yejin Choi, Claire Cardie, and Jeffrey~T Hancock.
\newblock Finding deceptive opinion spam by any stretch of the imagination.
\newblock In \emph{Proceedings of the 49th annual meeting of the association
  for computational linguistics: Human language technologies-volume 1}, pages
  309--319. Association for Computational Linguistics, 2011.

\bibitem[P{\'e}rez-Rosas et~al.(2018)P{\'e}rez-Rosas, Kleinberg, Lefevre, and
  Mihalcea]{perez2018automatic}
Ver{\'o}nica P{\'e}rez-Rosas, Bennett Kleinberg, Alexandra Lefevre, and Rada
  Mihalcea.
\newblock Automatic detection of fake news.
\newblock In \emph{Proceedings of the 27th International Conference on
  Computational Linguistics}, pages 3391--3401, 2018.

\bibitem[Peters et~al.(2018)Peters, Neumann, Iyyer, Gardner, Clark, Lee, and
  Zettlemoyer]{peters2018deep}
Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark,
  Kenton Lee, and Luke Zettlemoyer.
\newblock Deep contextualized word representations.
\newblock In \emph{Proceedings of the 2018 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long Papers)}, volume~1, pages 2227--2237, 2018.

\bibitem[Radford et~al.(2018)Radford, Narasimhan, Salimans, and
  Sutskever]{radford2018improving}
Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever.
\newblock Improving language understanding by generative pre-training.
\newblock Technical report, OpenAI, 2018.
\newblock URL \url{https://blog.openai.com/language-unsupervised/}.

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, and
  Sutskever]{radford2019gpttwo}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
  Sutskever.
\newblock Language models are unsupervised multitask learners.
\newblock Technical report, OpenAI, 2019.

\bibitem[Ranzato et~al.(2016)Ranzato, Chopra, Auli, and
  Zaremba]{Ranzato2016SequenceLT}
Marc'Aurelio Ranzato, Sumit Chopra, Michael Auli, and Wojciech Zaremba.
\newblock Sequence level training with recurrent neural networks.
\newblock In \emph{ICLR}. ICLR, 2016.

\bibitem[Rashkin et~al.(2017)Rashkin, Choi, Jang, Volkova, and
  Choi]{rashkin2017truth}
Hannah Rashkin, Eunsol Choi, Jin~Yea Jang, Svitlana Volkova, and Yejin Choi.
\newblock Truth of varying shades: Analyzing language in fake news and
  political fact-checking.
\newblock In \emph{Proceedings of the 2017 Conference on Empirical Methods in
  Natural Language Processing}, pages 2931--2937, 2017.

\bibitem[Shao et~al.(2016)Shao, Ciampaglia, Flammini, and
  Menczer]{shao2016hoaxy}
Chengcheng Shao, Giovanni~Luca Ciampaglia, Alessandro Flammini, and Filippo
  Menczer.
\newblock Hoaxy: A platform for tracking online misinformation.
\newblock In \emph{Proceedings of the 25th international conference companion
  on world wide web}, pages 745--750. International World Wide Web Conferences
  Steering Committee, 2016.

\bibitem[Shazeer and Stern(2018)]{shazeer2018adafactor}
Noam Shazeer and Mitchell Stern.
\newblock Adafactor: Adaptive learning rates with sublinear memory cost.
\newblock In \emph{International Conference on Machine Learning}, pages
  4603--4611, 2018.

\bibitem[Solaiman et~al.(2019)Solaiman, Brundage, Clark, Askell, Herbert-Voss,
  Wu, Radford, and Wang]{solaiman2019release}
Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss,
  Jeff Wu, Alec Radford, and Jasmine Wang.
\newblock Release strategies and the social impacts of language models.
\newblock \emph{arXiv preprint arXiv:1908.09203}, 2019.

\bibitem[Stern et~al.(2019)Stern, Chan, Kiros, and
  Uszkoreit]{stern2019insertion}
Mitchell Stern, William Chan, Jamie Kiros, and Jakob Uszkoreit.
\newblock Insertion transformer: Flexible sequence generation via insertion
  operations.
\newblock \emph{arXiv preprint arXiv:1902.03249}, 2019.

\bibitem[Strobelt and Gehrmann(2019)]{strobelt2019gltr}
Hendrik Strobelt and Sebastian Gehrmann.
\newblock Catching a unicorn with gltr: A tool to detect automatically
  generated text.
\newblock Technical report, Harvard, 2019.

\bibitem[Swire et~al.(2017)Swire, Ecker, and Lewandowsky]{swire2017role}
Briony Swire, Ullrich~KH Ecker, and Stephan Lewandowsky.
\newblock The role of familiarity in correcting inaccurate information.
\newblock \emph{Journal of experimental psychology: learning, memory, and
  cognition}, 43\penalty0 (12):\penalty0 1948, 2017.

\bibitem[Thorne et~al.(2018)Thorne, Vlachos, Christodoulopoulos, and
  Mittal]{thorne2018fever}
James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal.
\newblock Fever: a large-scale dataset for fact extraction and verification.
\newblock In \emph{Proceedings of the 2018 Conference of the North American
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long Papers)}, pages 809--819, 2018.

\bibitem[Vargo et~al.(2018)Vargo, Guo, and Amazeen]{vargo2018agenda}
Chris~J Vargo, Lei Guo, and Michelle~A Amazeen.
\newblock The agenda-setting power of fake news: A big data analysis of the
  online media landscape from 2014 to 2016.
\newblock \emph{New Media \& Society}, 20\penalty0 (5):\penalty0 2028--2049,
  2018.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez,
  Kaiser, and Polosukhin]{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock In \emph{Proceedings of the 31st International Conference on Neural
  Information Processing Systems}, pages 6000--6010. Curran Associates Inc.,
  2017.

\bibitem[Wang et~al.(2018)Wang, Singh, Michael, Hill, Levy, and
  Bowman]{wang2018glue}
Alex Wang, Amapreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel~R
  Bowman.
\newblock Glue: A multi-task benchmark and analysis platform for natural
  language understanding.
\newblock \emph{arXiv preprint arXiv:1804.07461}, 2018.

\bibitem[Wang(2017)]{wang2017liar}
William~Yang Wang.
\newblock “liar, liar pants on fire”: A new benchmark dataset for fake news
  detection.
\newblock In \emph{Proceedings of the 55th Annual Meeting of the Association
  for Computational Linguistics (Volume 2: Short Papers)}, pages 422--426,
  2017.

\bibitem[Wardle(2017)]{wardle2017fake}
Claire Wardle.
\newblock Fake news. it’s complicated.
\newblock \emph{First Draft News}, 16, 2017.

\bibitem[Wardle and Derakhshan(2017)]{wardle2017information}
Claire Wardle and Hossein Derakhshan.
\newblock Information disorder: Toward an interdisciplinary framework for
  research and policy making.
\newblock \emph{Council of Europe report, DGI (2017)}, 9, 2017.

\bibitem[Zellers(2019)]{zellers2019whywereleasedgrover}
Rowan Zellers.
\newblock Why we released grover.
\newblock Technical report, 2019.
\newblock URL \url{https://thegradient.pub/why-we-released-grover/}.

\bibitem[Zellers et~al.(2018)Zellers, Bisk, Schwartz, and
  Choi]{zellers2018swagaf}
Rowan Zellers, Yonatan Bisk, Roy Schwartz, and Yejin Choi.
\newblock Swag: A large-scale adversarial dataset for grounded commonsense
  inference.
\newblock In \emph{Proceedings of the 2018 Conference on Empirical Methods in
  Natural Language Processing (EMNLP)}, 2018.

\bibitem[Zellers et~al.(2019{\natexlab{a}})Zellers, Bisk, Farhadi, and
  Choi]{zellers2019vcr}
Rowan Zellers, Yonatan Bisk, Ali Farhadi, and Yejin Choi.
\newblock From recognition to cognition: Visual commonsense reasoning.
\newblock In \emph{The IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)}, 2019{\natexlab{a}}.

\bibitem[Zellers et~al.(2019{\natexlab{b}})Zellers, Holtzman, Bisk, Farhadi,
  and Choi]{zellers2018hellaswag}
Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi.
\newblock Hellaswag: Can a machine really finish your sentence?
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association
  for Computational Linguistics}, 2019{\natexlab{b}}.

\bibitem[Zellers et~al.(2019{\natexlab{c}})Zellers, Holtzman, Rashkin, Bisk,
  Farhadi, Roesner, and Choi]{zellers2019blogpost}
Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi,
  Franziska Roesner, and Yejin Choi.
\newblock Counteracting neural disinformation with grover.
\newblock Technical report, 2019{\natexlab{c}}.
\newblock URL
  \url{https://medium.com/ai2-blog/counteracting-neural-disinformation-with-grover-6cf6690d463b}.

\end{thebibliography}
